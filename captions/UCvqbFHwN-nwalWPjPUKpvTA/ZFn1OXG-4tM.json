[
  {
    "text": "today I want to talk about enterprise machine learning on kubernetes and particularly a little bit of emphasis on",
    "start": "60",
    "end": "7259"
  },
  {
    "text": "the enterprise bit I suspect many of you have been to some of the other talks you're just just talking about machine learning in",
    "start": "7259",
    "end": "12719"
  },
  {
    "text": "general on kubernetes but Tim and I have been doing a lot of work at Cloudera on how do you support enterprise machine",
    "start": "12719",
    "end": "18900"
  },
  {
    "text": "learning and leveraging emerging technologies such as kubernetes so we want to give you some of the lessons",
    "start": "18900",
    "end": "25080"
  },
  {
    "text": "learned from our initiatives and a little bit of a peek at the road ahead we'll try not to make this too much like",
    "start": "25080",
    "end": "30960"
  },
  {
    "text": "a product pitch we do need to tell you a little bit about what we're actually building so that we can talk about some of the lessons learned but yeah with",
    "start": "30960",
    "end": "38430"
  },
  {
    "text": "that let me start off with introductions who are you talking with so I will pass",
    "start": "38430",
    "end": "43950"
  },
  {
    "text": "it off to Tim so yeah my name is Tim recently joined cloud era so now I'm a leading technology",
    "start": "43950",
    "end": "51289"
  },
  {
    "text": "implementation for cloudy right machine learning we used to have a startup called hyper pilots so you see a little",
    "start": "51289",
    "end": "57149"
  },
  {
    "text": "bit of stuff how we're going to be looking to bring some of a hybrid pilot",
    "start": "57149",
    "end": "62250"
  },
  {
    "text": "work into cloud era mushroom you've heard of our stuff before but it's also very kubernetes native and i was also",
    "start": "62250",
    "end": "69240"
  },
  {
    "text": "working on missiles and drill and also helped worked on spark and my name is",
    "start": "69240",
    "end": "75119"
  },
  {
    "text": "Tristan I play the role of CTO for our machine learning business unit at Cloudera I was formerly the founder of small",
    "start": "75119",
    "end": "81479"
  },
  {
    "text": "start-up called sense like Tim which got acquired by clutter about three years ago we were building what we called an",
    "start": "81479",
    "end": "87090"
  },
  {
    "text": "enterprise data science platform we were using kubernetes very very very early on and heavily leveraged containers and",
    "start": "87090",
    "end": "93659"
  },
  {
    "text": "that has carried over to some of the larger scale work that we've been doing at clutter so let me just I have to do",
    "start": "93659",
    "end": "101640"
  },
  {
    "text": "this for lawyers some of the stuff that I'm talking about is is future product related and some of the things we're",
    "start": "101640",
    "end": "107189"
  },
  {
    "text": "building so obviously no promises we're talking here as technologists not as",
    "start": "107189",
    "end": "113340"
  },
  {
    "text": "sort of product people all right clutter",
    "start": "113340",
    "end": "118500"
  },
  {
    "text": "and kubernetes so I just want to start off by asking a question who here knows what cloud era does okay so maybe half",
    "start": "118500",
    "end": "127710"
  },
  {
    "text": "the people so just to orient the rest of I Clara we say we built we're building a",
    "start": "127710",
    "end": "134670"
  },
  {
    "text": "modern platform for machine learning and analytics optimized for the cloud we in particular our focus of large customers",
    "start": "134670",
    "end": "141450"
  },
  {
    "text": "huge amounts of data huge amounts of compute most of you particularly being interested in open source probably know",
    "start": "141450",
    "end": "147390"
  },
  {
    "text": "us as the leading distributor behind Hadoop and the Hadoop big data ecosystem clutter and a few other vendors you know",
    "start": "147390",
    "end": "154680"
  },
  {
    "text": "are the key forces behind that you probably don't know us as being heavily",
    "start": "154680",
    "end": "159870"
  },
  {
    "text": "involved in kubernetes because there's the whole Hadoop and Apache ecosystem which is historically not been tightly",
    "start": "159870",
    "end": "165750"
  },
  {
    "text": "connected with the whole cloud native ecosystem that is changing and some of",
    "start": "165750",
    "end": "170970"
  },
  {
    "text": "the things that we're going to talk about today are about how these two communities really are complementing one another and can deliver value to two in",
    "start": "170970",
    "end": "179520"
  },
  {
    "text": "both directions so how are we using kubernetes at Cloudera I want to just be",
    "start": "179520",
    "end": "185370"
  },
  {
    "text": "clear because this is what were we talking about some of the lessons learned from so the first thing is we",
    "start": "185370",
    "end": "190710"
  },
  {
    "text": "use kubernetes within what we call our cloud era data science workbench product this is a product that is gives a collaborative data science experience it",
    "start": "190710",
    "end": "198030"
  },
  {
    "text": "is powered by kubernetes it is built 100% on doctrine and kubernetes behind the scenes",
    "start": "198030",
    "end": "203220"
  },
  {
    "text": "it basically accelerates the entire life cycle of doing data science and machine learning work from exploration to",
    "start": "203220",
    "end": "209370"
  },
  {
    "text": "production it works on small data so you have standalone R in Python it works it can",
    "start": "209370",
    "end": "215670"
  },
  {
    "text": "connect any data source and particularly we have a Big Data Platform the you know the Hadoop platform and the data science",
    "start": "215670",
    "end": "222660"
  },
  {
    "text": "workbench product is really a gateway for data scientists into that large-scale data engineering scale out",
    "start": "222660",
    "end": "230910"
  },
  {
    "text": "computes tour äj-- platform that you know the people people that here know the Hadoop ecosystem that's probably",
    "start": "230910",
    "end": "237060"
  },
  {
    "text": "what you identify it with so sits side by side with with the rest of our stack",
    "start": "237060",
    "end": "243630"
  },
  {
    "text": "but it's really just a kind of a gateway small right couple nodes you know gives",
    "start": "243630",
    "end": "249330"
  },
  {
    "text": "you a little bit of a workbench environment for your data science teams so we've been shipping this this was the",
    "start": "249330",
    "end": "254370"
  },
  {
    "text": "basically what I was building at cents when we were a startup it became clutter data science workbench and we've done a lot around enterprise integration and",
    "start": "254370",
    "end": "261750"
  },
  {
    "text": "security but it's really a gateway in to the Hadoop environment or the",
    "start": "261750",
    "end": "266879"
  },
  {
    "text": "large-scale sort of data platform environment so last week and this is",
    "start": "266879",
    "end": "272250"
  },
  {
    "text": "what Kim is going to be showing you some of the technology behind about a week ago clutter announced a preview for sort",
    "start": "272250",
    "end": "279300"
  },
  {
    "text": "of the next generation more cloud native version of our machine learning platform so the key differentiating factor here",
    "start": "279300",
    "end": "286919"
  },
  {
    "text": "is that we've taken the wheel we enable the end-to-end workflow for machine learning directly on kubernetes",
    "start": "286919",
    "end": "292610"
  },
  {
    "text": "including the scale out compute namely distributed computing with spark so this",
    "start": "292610",
    "end": "299400"
  },
  {
    "text": "is a product that you can install natively onto you know EK SaaS gke you know OpenShift",
    "start": "299400",
    "end": "305630"
  },
  {
    "text": "has connectivity your primary Kuster but is in a separated computing storage environment where you have scale-out",
    "start": "305630",
    "end": "311250"
  },
  {
    "text": "computing on kubernetes that can include you know your standalone R in Python tensorflow PI torch etc but also",
    "start": "311250",
    "end": "317039"
  },
  {
    "text": "distributed lot you know frameworks that are core to the traditional platform or the hood traditional platform namely you",
    "start": "317039",
    "end": "323490"
  },
  {
    "text": "know spark is one of the most important things so that's it on the sort of like I'm just trying to orient you in terms",
    "start": "323490",
    "end": "328740"
  },
  {
    "text": "of what we are building and I wanted to talk to you a little bit about some of the kind of high-level lessons learned",
    "start": "328740",
    "end": "334199"
  },
  {
    "text": "around doing machine learning at scale within the enterprise leveraging",
    "start": "334199",
    "end": "341310"
  },
  {
    "text": "kubernetes and then allow Tim to talk a little bit about what's going on behind the scenes how do we actually use",
    "start": "341310",
    "end": "347610"
  },
  {
    "text": "kubernetes and what are the some of the emerging capabilities that exist within the open source ecosystem so some",
    "start": "347610",
    "end": "357479"
  },
  {
    "text": "lessons learned I have very limited time so I'm just going to give you two high-level lessons so the first is that",
    "start": "357479",
    "end": "364020"
  },
  {
    "text": "within the enterprise enterprise ml really does require the bigger picture",
    "start": "364020",
    "end": "369750"
  },
  {
    "text": "and this is somewhat self-serving because clutter we say we you know provide the bigger picture but it is really true if you look at how the large",
    "start": "369750",
    "end": "376500"
  },
  {
    "text": "companies do it and when I mean by the bigger picture is I mean any machine learning application isn't just for instance running a PI torch job or a",
    "start": "376500",
    "end": "382889"
  },
  {
    "text": "tensorflow job right it fits within a broader eco data platform ecosystem that companies have you have data that's",
    "start": "382889",
    "end": "388529"
  },
  {
    "text": "streaming in you need to do large-scale data engineering you do want to do machine learning on that do predictive",
    "start": "388529",
    "end": "394229"
  },
  {
    "text": "predictions and advanced analytics but you're also driving data warehouses right so you taking those predictive product those",
    "start": "394229",
    "end": "400919"
  },
  {
    "text": "printed outputs and you're driving a data warehouse that your business user could use you have operational products",
    "start": "400919",
    "end": "406860"
  },
  {
    "text": "that you're trying to build right recommendation engines for your for your movies or your cell phone you know something it's something on your cell",
    "start": "406860",
    "end": "412680"
  },
  {
    "text": "phone so you need to have some operational component and the key thing within the enterprise is how do you glue that all together and in particular how",
    "start": "412680",
    "end": "418919"
  },
  {
    "text": "do you have this a common security metadata governance story behind behind the scenes now that doesn't mean you",
    "start": "418919",
    "end": "424559"
  },
  {
    "text": "need to all go to one vendor you can glue it together you know by taking best-of-breed products but the general",
    "start": "424559",
    "end": "429779"
  },
  {
    "text": "point here is that you do need to fit enterprise ml within a broader ecosystem so you don't you know I think of like oh",
    "start": "429779",
    "end": "435839"
  },
  {
    "text": "it's stupid or notebooks it's not Jupiter notebooks within the enterprise environment Jupiter notebooks are a",
    "start": "435839",
    "end": "442710"
  },
  {
    "text": "great part of the ecosystem but that's not the whole story for doing enterprise ml at scale so one way - so what is",
    "start": "442710",
    "end": "450509"
  },
  {
    "text": "required from a technology perspective one way to look at it is look at what companies are doing and I'm sorry I'm",
    "start": "450509",
    "end": "460349"
  },
  {
    "text": "making sure my time is okay so one way to do it is to look at what companies are doing so here's Ebers you know I had a blog",
    "start": "460349",
    "end": "466979"
  },
  {
    "text": "post on their machine learning platform and this is their diagram that they have and you can see it's basically the diagram that I put before right there's",
    "start": "466979",
    "end": "472889"
  },
  {
    "text": "Kafka in there first which is part of the Hadoop ecosystem that's for streaming data there's a data Lake",
    "start": "472889",
    "end": "478649"
  },
  {
    "text": "sitting there there's a spark job you can see that's doing data engineering data prep job it's leading into a batch",
    "start": "478649",
    "end": "485459"
  },
  {
    "text": "training job so they're doing that who knows they might be using containers there that might be a good idea so maybe they're using containers there I don't",
    "start": "485459",
    "end": "491159"
  },
  {
    "text": "know meso serve or kubernetes they're then going into an operational data store in their Conte in their context",
    "start": "491159",
    "end": "497009"
  },
  {
    "text": "that is Cassandra and then they're doing two things they're doing real-time predictions which probably is a micro",
    "start": "497009",
    "end": "502559"
  },
  {
    "text": "service architecture of some sort mesosphere kubernetes or they're doing batch prediction where again they're",
    "start": "502559",
    "end": "508680"
  },
  {
    "text": "leveraging SPARC to do batch prediction at scale distributed back batch prediction they might be internal to SPARC using machine learning library",
    "start": "508680",
    "end": "515010"
  },
  {
    "text": "like tensorflow Netflix has a very similar architecture for their product recommended for their movie",
    "start": "515010",
    "end": "520409"
  },
  {
    "text": "recommendation engine it's pretty much honestly exactly the same thing Kafka SPARC you know some machine learning",
    "start": "520409",
    "end": "525540"
  },
  {
    "text": "algorithms online prediction online operational databases Facebook is",
    "start": "525540",
    "end": "531420"
  },
  {
    "text": "building a lot of its own but it has a similar architecture at the core they have a core infrastructure",
    "start": "531420",
    "end": "536580"
  },
  {
    "text": "servers compute date network on top of that they have their data platform which includes workload management deployment",
    "start": "536580",
    "end": "544350"
  },
  {
    "text": "management machine learning productivity tool they call FB learner and on top of that they have these open source machine",
    "start": "544350",
    "end": "551430"
  },
  {
    "text": "learning frameworks or libraries in their case they are heavily invested in cafe 2 pi torch onyx ok but you could",
    "start": "551430",
    "end": "557040"
  },
  {
    "text": "think put tents or floor tensorflow scikit-learn up there too so the bottom line message that I want to give is",
    "start": "557040",
    "end": "562920"
  },
  {
    "text": "these ecosystems some people say oh you know kubernetes you know it's gonna kill hadoop or something like that",
    "start": "562920",
    "end": "568200"
  },
  {
    "text": "these ecosystems really are trying to tackle different things and they can work together so if you look at all of these stacks it's really how do we",
    "start": "568200",
    "end": "574710"
  },
  {
    "text": "leverage compute kubernetes here is a is a major now player but the Hadoop components Kafka's spark hive metadata",
    "start": "574710",
    "end": "582510"
  },
  {
    "text": "security etc that's still a major major part of the broader data platform and then on top it is being augmented by",
    "start": "582510",
    "end": "589200"
  },
  {
    "text": "modern frameworks around innovative machine learning so tensorflow PI torch that sort of tooling and a modern ml",
    "start": "589200",
    "end": "595710"
  },
  {
    "text": "stack and enterprise ml stack is really spans these two now there are some hard choices right in the Hadoop ecosystem we",
    "start": "595710",
    "end": "602160"
  },
  {
    "text": "have yarn which is yet another resource manager it's our resource manager behind some of the components here like spark",
    "start": "602160",
    "end": "608670"
  },
  {
    "text": "and hive you could run spark potentially on kubernetes that might be a reasonable",
    "start": "608670",
    "end": "613800"
  },
  {
    "text": "idea right so there's some areas where maybe you'll want to change things to take advantages of the different",
    "start": "613800",
    "end": "619800"
  },
  {
    "text": "underlying resource management but the frameworks on top really don't care about where they're running and Tim will show you some of the stuff we're doing",
    "start": "619800",
    "end": "625200"
  },
  {
    "text": "to run some of these frameworks where we think there's a benefit to running in containers natively on top of kubernetes",
    "start": "625200",
    "end": "632209"
  },
  {
    "text": "all right so the second lesson that I",
    "start": "632930",
    "end": "639510"
  },
  {
    "text": "want to just mention is you really need to focus on the workflows for machine",
    "start": "639510",
    "end": "646500"
  },
  {
    "text": "learning not the frameworks the frameworks are take changing of my frameworks and libraries I mean things like pi torch tensorflow spark ray",
    "start": "646500",
    "end": "653339"
  },
  {
    "text": "whatever your scikit-learn or the languages Python are Scala those",
    "start": "653339",
    "end": "659850"
  },
  {
    "text": "are changing data by day the rate of innovation is absolutely insane right now within the machine learning world what you",
    "start": "659850",
    "end": "665649"
  },
  {
    "text": "need to do is you need to and data scientists want to use all of these tools right it's particularly within a large company and so what you really",
    "start": "665649",
    "end": "671290"
  },
  {
    "text": "need to do from a platform perspective is think about how do I enable the work flow underneath the behind the scenes and from our perspective there's a few",
    "start": "671290",
    "end": "678399"
  },
  {
    "text": "key workflows that you need to help accelerate and help data science to be more productive on there's a development",
    "start": "678399",
    "end": "683740"
  },
  {
    "text": "workflow which is interactive it's you want it to behavior like your laptop you need access to data and compute but you",
    "start": "683740",
    "end": "689350"
  },
  {
    "text": "want to mutate a mute a table file system pip install package you want it to be like your laptop like a",
    "start": "689350",
    "end": "694869"
  },
  {
    "text": "development environment you want a principled way to run training runs so you want a way to snapshot your train",
    "start": "694869",
    "end": "701379"
  },
  {
    "text": "training code submit something to the cluster run it for a day or two do the training compare the conformance so you",
    "start": "701379",
    "end": "708100"
  },
  {
    "text": "need something around ad hoc training you need something around a sharing and collaboration so you need something some",
    "start": "708100",
    "end": "714040"
  },
  {
    "text": "people like to share things you know for those in our ecosystem you might be familiar with shiny for instance you definitely need data engineering so you",
    "start": "714040",
    "end": "720369"
  },
  {
    "text": "want a batch and pipeline system that could includes distributed jobs like spark and then of course you want to get",
    "start": "720369",
    "end": "726550"
  },
  {
    "text": "to production and be able to run a model so within how do we do that on crew so we do that within our machine learning",
    "start": "726550",
    "end": "732699"
  },
  {
    "text": "product cutter our machine learning running on top of kubernetes how does that actually work for your you for",
    "start": "732699",
    "end": "738339"
  },
  {
    "text": "Uecker bananas people so Clara machine learning is built around enabling these workflows and that's the abstraction",
    "start": "738339",
    "end": "744279"
  },
  {
    "text": "that we try to target so we have one not what's you know we have one Operator we kind of follow the operator pattern we",
    "start": "744279",
    "end": "749470"
  },
  {
    "text": "have four core CR DS I put it in quotes because we don't actually use series currently but that's conceptually what",
    "start": "749470",
    "end": "755199"
  },
  {
    "text": "they're doing the first is for sessions that's interactive and mutating that's things like Jupiter notebook write an",
    "start": "755199",
    "end": "761679"
  },
  {
    "text": "interactive environment development firing Tim will show you some of that we have an experiment which is how do we go",
    "start": "761679",
    "end": "767410"
  },
  {
    "text": "from source to image to run give you an immutable version that you can kick off and have a long living training run we",
    "start": "767410",
    "end": "774129"
  },
  {
    "text": "have a job which is a scheduled recurring thing and we have a model which is an online how do I apply something as a restful micro service one",
    "start": "774129",
    "end": "781959"
  },
  {
    "text": "thing that I want to point out here which i think is a little bit cadential controversial is we do not have",
    "start": "781959",
    "end": "787170"
  },
  {
    "text": "long-lived operators for any particular frame framework so we do not have a TF job we don't have a spark job or",
    "start": "787170",
    "end": "793629"
  },
  {
    "text": "anything like that we try to let the frameworks just be libraries so that they can compose well into these",
    "start": "793629",
    "end": "799990"
  },
  {
    "text": "higher-level workflows right so you can have a spark session you can explore experiments mark job spark model and the",
    "start": "799990",
    "end": "807010"
  },
  {
    "text": "libraries themselves they can be kubernetes aware but we do not have a separate long-lived operator for every",
    "start": "807010",
    "end": "813399"
  },
  {
    "text": "framework that our data scientists want to work to use and that's worked quite well for us it's definitely a topic",
    "start": "813399",
    "end": "819310"
  },
  {
    "text": "worthy of questions folks have them the final thing is kubernetes is not exposed",
    "start": "819310",
    "end": "824620"
  },
  {
    "text": "to data scientists our goal is to really give them a serverless experience and I love you know keeps ETL but honestly I",
    "start": "824620",
    "end": "831670"
  },
  {
    "text": "can barely get some data scientist to love get and so you know a wall of Y a mole that does all the spark",
    "start": "831670",
    "end": "837910"
  },
  {
    "text": "configuration is not what most higher-level data scientists won so we've tried to build a system where you",
    "start": "837910",
    "end": "843459"
  },
  {
    "text": "can get to kubernetes if you absolutely need it but for the end data scientists we want that experience to be as service",
    "start": "843459",
    "end": "848680"
  },
  {
    "text": "as possible and what we mean by that is we want to have experience and we don't see why there's any reason why the",
    "start": "848680",
    "end": "854649"
  },
  {
    "text": "platform can't provide an experience that's like you know clutter ml run you know Python train dot PI you snapshot",
    "start": "854649",
    "end": "860770"
  },
  {
    "text": "your code you put it up you build your image install your dependencies ship around your dependencies run it track there were results outputs and it's done",
    "start": "860770",
    "end": "867220"
  },
  {
    "text": "and we likewise want the frameworks to have a symbol a server list experience",
    "start": "867220",
    "end": "873310"
  },
  {
    "text": "so and this is an example of SPARC we think you should just import SPARC import from PI spark you know sequel",
    "start": "873310",
    "end": "879820"
  },
  {
    "text": "imports work session create a spark session ideally no configuration and then run aid in this case a distributed",
    "start": "879820",
    "end": "885430"
  },
  {
    "text": "map over a function f and that should spin up all the necessary compute resources it should make sure that those",
    "start": "885430",
    "end": "890529"
  },
  {
    "text": "computers is have the dependencies that you've installed in your environment and all that should be ideally completely",
    "start": "890529",
    "end": "896649"
  },
  {
    "text": "transparent to the user and that's what we've been trying to enable so there's some technology behind how do we do this",
    "start": "896649",
    "end": "902770"
  },
  {
    "text": "how we're leveraging SPARC and I will turn over to Tim who will can talk a little bit about some of the road ahead with respect to that all right thanks",
    "start": "902770",
    "end": "913690"
  },
  {
    "text": "Tristan so let's move ahead and talk so Tristan gave a great overview about the high-level lessons learned now I want to",
    "start": "913690",
    "end": "920829"
  },
  {
    "text": "actually talk a little bit more lower level details about some of the technology we're using and how actually",
    "start": "920829",
    "end": "926260"
  },
  {
    "text": "integrating it also show you what is cloud era data science clutter and machinery how does that look like",
    "start": "926260",
    "end": "931420"
  },
  {
    "text": "running SPARC on community and actually running on manage communities overall so we talked about",
    "start": "931420",
    "end": "937959"
  },
  {
    "text": "sparking communities and I'm I'm not sure how familiar you all are with spark and also kubernetes so maybe good if you",
    "start": "937959",
    "end": "945459"
  },
  {
    "text": "know you spark before let me show a show of hands okay so it's maybe 20% all",
    "start": "945459",
    "end": "952540"
  },
  {
    "text": "right so this is an interesting how many of you actually try spark on kubernetes yet cause about to sing okay a little",
    "start": "952540",
    "end": "958689"
  },
  {
    "text": "less a lot okay obviously maybe 15 20 people all right so if you use spark on Chrome Nettie's",
    "start": "958689",
    "end": "965170"
  },
  {
    "text": "you definitely understand what experience looks like and so Sparkle Corning's it's great because it",
    "start": "965170",
    "end": "970720"
  },
  {
    "text": "leverages kubernetes right it has the kubernetes operations things that you like about communities like the",
    "start": "970720",
    "end": "976540"
  },
  {
    "text": "affinities you know toleration x' all the things you quest limits and everything you build tooling around",
    "start": "976540",
    "end": "982269"
  },
  {
    "text": "kubernetes you can leverage it for spark so for us sparking cronies is great because we can leverage our existing",
    "start": "982269",
    "end": "988449"
  },
  {
    "text": "kubernetes toolings and our frameworks and stuff we've bills for kubernetes and bring it into with spark what's most",
    "start": "988449",
    "end": "995980"
  },
  {
    "text": "interesting I think here is we just how about data scientists they want to use various tools right like pip install of",
    "start": "995980",
    "end": "1003029"
  },
  {
    "text": "Python language they like to use this could be tensor flow this could be scikit-learn it could be anything built themselves and the use are they use",
    "start": "1003029",
    "end": "1009839"
  },
  {
    "text": "Scala right there's all kinds of languages right so one problem when challenge for you you probably will see",
    "start": "1009839",
    "end": "1015389"
  },
  {
    "text": "is like how do I actually ship these dependencies you know not just on a single session when I run a spark job",
    "start": "1015389",
    "end": "1022199"
  },
  {
    "text": "right it's distributed it's gonna run containers in anywhere in the nose in my kubernetes cluster how do I ship all",
    "start": "1022199",
    "end": "1028199"
  },
  {
    "text": "these dependencies to distributed environments and it makes this seamless",
    "start": "1028199",
    "end": "1033538"
  },
  {
    "text": "so the data scientists not to figure out oh I need actually included some llamo files and I can figure out all the",
    "start": "1033539",
    "end": "1038730"
  },
  {
    "text": "things and build my own docker images and stuff like that how do I make it seamless and this is interactive sessions this is not like",
    "start": "1038730",
    "end": "1044339"
  },
  {
    "text": "pre figured job and long-running batch jobs right if Barton crew neighs we talked about",
    "start": "1044339",
    "end": "1050490"
  },
  {
    "text": "because you're running equipment Eddie's you know you're running you can use CPU GPUs and have auto scaling capabilities",
    "start": "1050490",
    "end": "1055650"
  },
  {
    "text": "in the cloud and overall we couldn't talk a little bit about how we get to the improve you ization and multi-tenancy but because of bringing into the same",
    "start": "1055650",
    "end": "1061649"
  },
  {
    "text": "resource manager we have a lot more opportunities to do that all right so very",
    "start": "1061649",
    "end": "1066870"
  },
  {
    "text": "quick Sparkle Cooney's has so spark used to have no native integration we brought",
    "start": "1066870",
    "end": "1073440"
  },
  {
    "text": "it and away means the whole community of spark and a lot of kubernetes people helps along the way to get spark have",
    "start": "1073440",
    "end": "1080160"
  },
  {
    "text": "native integration that means you don't have to actually care where screw Burnett ease you actually configure in",
    "start": "1080160",
    "end": "1086520"
  },
  {
    "text": "spark I want to use kubernetes and here's my spark configuration it will just talk to criminate directly and",
    "start": "1086520",
    "end": "1092370"
  },
  {
    "text": "run it so you should have sat alone clusters you know spark now we can just run a spark directly pointing to a",
    "start": "1092370",
    "end": "1098160"
  },
  {
    "text": "criminal's api and it will run just executor pods for you so I won't go into too much details we can definitely see",
    "start": "1098160",
    "end": "1103890"
  },
  {
    "text": "documentation there and what's great about it as we talked about is that if you have main spaces quotas our backs",
    "start": "1103890",
    "end": "1111900"
  },
  {
    "text": "built into your kubernetes cluster spark can leverage that too and I'll show you a little bit of that later",
    "start": "1111900",
    "end": "1117480"
  },
  {
    "text": "all right still so sparkling communities in cloud era machine machine learning",
    "start": "1117480",
    "end": "1125070"
  },
  {
    "text": "this is kind of how little deeper dive what it looks like right so in cloud and machine learning we have we have what we",
    "start": "1125070",
    "end": "1133830"
  },
  {
    "text": "call engines so an engine is basically where we are backing the sessions it's kind of like a trooper a notebook when",
    "start": "1133830",
    "end": "1139080"
  },
  {
    "text": "you create a dripper a notebook you have interactive session you can play with right so for every session create we",
    "start": "1139080",
    "end": "1144690"
  },
  {
    "text": "create an engine this engine is basically kubernetes pod with a container to hassle some of our",
    "start": "1144690",
    "end": "1150059"
  },
  {
    "text": "pre-built dependencies that we think you you'll need and for us to use so if you",
    "start": "1150059",
    "end": "1155460"
  },
  {
    "text": "need a spark interactive session right the only way to do it is through a spark client mode and what client mode if",
    "start": "1155460",
    "end": "1161520"
  },
  {
    "text": "you're not familiar with spark spark client mode means run the spark main driver in that process directly not",
    "start": "1161520",
    "end": "1168690"
  },
  {
    "text": "running some driver on some others pod or some other nose but you need to actually able to give it inputs and see",
    "start": "1168690",
    "end": "1175410"
  },
  {
    "text": "the outputs in the same session right so you need to actually run that spark driver in that session and for us",
    "start": "1175410",
    "end": "1182010"
  },
  {
    "text": "how to be able to ship dependencies right if you pip install some arbitrary package and then just expect spark to",
    "start": "1182010",
    "end": "1188910"
  },
  {
    "text": "work now how does that work well for us if you pip install we set it up to make sure that your pip installing into a",
    "start": "1188910",
    "end": "1194820"
  },
  {
    "text": "network volume that we can able to ship around for you right so this could be enough it's volume it could be something",
    "start": "1194820",
    "end": "1200100"
  },
  {
    "text": "else but if you set it up the right way and you have a home directory and all the permissions set up for you pip install",
    "start": "1200100",
    "end": "1205170"
  },
  {
    "text": "into that get your spark executor x' to be able to manage your all the necessary",
    "start": "1205170",
    "end": "1210510"
  },
  {
    "text": "information to find those packages right so you can just propagate that all around to different executor is for use",
    "start": "1210510",
    "end": "1216210"
  },
  {
    "text": "and NSS volumes you know this is user permissions and this is past setups and",
    "start": "1216210",
    "end": "1221460"
  },
  {
    "text": "stuff like that so we do it at all for you behind the scenes but one important piece of this is that for us to be able",
    "start": "1221460",
    "end": "1228300"
  },
  {
    "text": "to propagate a lot of information from the main session to the executor --zz you need to able we use something called",
    "start": "1228300",
    "end": "1235140"
  },
  {
    "text": "executor paw templates so if you mean following the sparklin communities work i need you need instead of telling SPARC",
    "start": "1235140",
    "end": "1242940"
  },
  {
    "text": "here's all the little details of what I need to propagate everywhere give me a template almost like a llamó file but",
    "start": "1242940",
    "end": "1249210"
  },
  {
    "text": "this is populated for you that it could automatically transfer anything in this",
    "start": "1249210",
    "end": "1254340"
  },
  {
    "text": "pot template and put it into all the executives at at launch so this could be labels that could be volumes too could",
    "start": "1254340",
    "end": "1260700"
  },
  {
    "text": "be image pool secrets it could be a whole bunch of stuff so because Coomer is adding a lot more",
    "start": "1260700",
    "end": "1267090"
  },
  {
    "text": "fields into siamo it's really hard to add one one by one and spark because you'd imagine yeah I think I had to create like hundreds little knobs and",
    "start": "1267090",
    "end": "1274080"
  },
  {
    "text": "spark and it's just almost impossible so having a generic template again passed around is actually very powerful way for",
    "start": "1274080",
    "end": "1280860"
  },
  {
    "text": "you to maintain a software like this an important part of this is that because interactive sessions create executors",
    "start": "1280860",
    "end": "1287250"
  },
  {
    "text": "once you've killed a session everything is gone right the pot is gone your",
    "start": "1287250",
    "end": "1292260"
  },
  {
    "text": "session is gone how do I find my logging how do I find my spark metrics right for spark history server how to actually",
    "start": "1292260",
    "end": "1298470"
  },
  {
    "text": "debug these things so we set up flew in D and two point to these pause using like some naming scheme and label that",
    "start": "1298470",
    "end": "1305670"
  },
  {
    "text": "we can find these pause on this node mounts to host volumes to keep the shear writing the logs",
    "start": "1305670",
    "end": "1311310"
  },
  {
    "text": "also the spark metrics you didn't it a little bit gluing to because spark Mex is a little interesting but you need it",
    "start": "1311310",
    "end": "1316890"
  },
  {
    "text": "actually able to tail it out into this serve volume but this will be shipped to some external storage so that's very",
    "start": "1316890",
    "end": "1323670"
  },
  {
    "text": "quickly and we know how much time but that's quickly how we do this and we because we're using kubernetes",
    "start": "1323670",
    "end": "1329400"
  },
  {
    "text": "we actually set up a namespace per project so that's how every user",
    "start": "1329400",
    "end": "1334590"
  },
  {
    "text": "don't just create whatever party wants right we give you a quota and we give you a service accounts that can only",
    "start": "1334590",
    "end": "1341070"
  },
  {
    "text": "launch executives within your namespace so you can go crazy in your namespace you know you can kill your own secular",
    "start": "1341070",
    "end": "1347220"
  },
  {
    "text": "pause you can see each other's stuff but you're never gonna be able to see each other projects stuff and able to kill",
    "start": "1347220",
    "end": "1354330"
  },
  {
    "text": "each other's pause they'll be horrible there's all this much more detail about",
    "start": "1354330",
    "end": "1360029"
  },
  {
    "text": "Kerberos and all that stuff is happening all right so demo I want to show you",
    "start": "1360029",
    "end": "1365419"
  },
  {
    "text": "what this kind of looks like in our clutter and machine learning and I'll make sure it can come out all right so",
    "start": "1365419",
    "end": "1371940"
  },
  {
    "text": "let me start here so see this this is",
    "start": "1371940",
    "end": "1377520"
  },
  {
    "text": "called air and machine learning how it looks like it's a web interface so data scientists will come in and login and",
    "start": "1377520",
    "end": "1384390"
  },
  {
    "text": "every one of them has basically projects write a project is a shared workspace",
    "start": "1384390",
    "end": "1390000"
  },
  {
    "text": "that has all your files there you can collaboratively edit files and create interactive sessions from those projects",
    "start": "1390000",
    "end": "1396149"
  },
  {
    "text": "so normally you create a project I reap recreated one and you have your files",
    "start": "1396149",
    "end": "1402059"
  },
  {
    "text": "this is a pice spark template that we have you can there's a lot of things we",
    "start": "1402059",
    "end": "1407880"
  },
  {
    "text": "can have we their sessions experiments there's small deployments and jobs and stuff like that I want to highlights",
    "start": "1407880",
    "end": "1413130"
  },
  {
    "text": "today about spark on kubernetes so if you open a workbench a workbench is basically equivalent of a super and",
    "start": "1413130",
    "end": "1419399"
  },
  {
    "text": "awkward we just talked about you have an interactive session that you can watch here so you can choose what engine you",
    "start": "1419399",
    "end": "1425610"
  },
  {
    "text": "want this engine we have our own engine that actually has a lot of dependencies like you know anaconda or scikit-learn",
    "start": "1425610",
    "end": "1433890"
  },
  {
    "text": "all in defaults packages we think most data scientists need and you can choose",
    "start": "1433890",
    "end": "1439620"
  },
  {
    "text": "what language you wants because that set us all language bindings and paths and stuff like that and most interesting is",
    "start": "1439620",
    "end": "1445020"
  },
  {
    "text": "that you can choose how much resources do you want to give this session if you have GPUs in this cluster it automatically detects it and it will",
    "start": "1445020",
    "end": "1451409"
  },
  {
    "text": "show you what how many GPUs do you want oh so for this session you launch the session this creates this interactive",
    "start": "1451409",
    "end": "1457500"
  },
  {
    "text": "session for you and you can so while this is running let me explain to you",
    "start": "1457500",
    "end": "1463559"
  },
  {
    "text": "what I would like to show you today so how do you get dependence",
    "start": "1463559",
    "end": "1468900"
  },
  {
    "text": "we talked about how we actually propagate dependencies across executives right and also how do we actually get",
    "start": "1468900",
    "end": "1474540"
  },
  {
    "text": "spark on crew Nettie's to just work so this example is tends to fall in spark",
    "start": "1474540",
    "end": "1480480"
  },
  {
    "text": "so this is pre trained models but feeding tensorflow some image nets images to do inference",
    "start": "1480480",
    "end": "1489180"
  },
  {
    "text": "and I'm using spark to just spread the images right so I have a bunch of images I create our G d's and batches I spread",
    "start": "1489180",
    "end": "1496020"
  },
  {
    "text": "it around for executor x' they all instantly all pip installed tensorflow when they don't actually do that we you",
    "start": "1496020",
    "end": "1503010"
  },
  {
    "text": "pip install on x fill in your session it automatically propagates tensor field package to all the executor x' for you",
    "start": "1503010",
    "end": "1509070"
  },
  {
    "text": "so that in your executor x' when you're doing an inference it army automatically picks up the tensor fold dependency so i",
    "start": "1509070",
    "end": "1516330"
  },
  {
    "text": "pip install tensor full already it doesn't come with our default engine but normally what you do is you do pip",
    "start": "1516330",
    "end": "1523380"
  },
  {
    "text": "install tensor fall here right this installs only intercession but let me",
    "start": "1523380",
    "end": "1530460"
  },
  {
    "text": "just run this really quick but what do you tip what will happen here is basically it will starts to download",
    "start": "1530460",
    "end": "1538530"
  },
  {
    "text": "image nets download the images needs to do inference on and start to spread around the executor so the most",
    "start": "1538530",
    "end": "1546690"
  },
  {
    "text": "important piece here okay it's right here right this is your",
    "start": "1546690",
    "end": "1551820"
  },
  {
    "text": "typical PI spark code my sure just too small this is your typical PI smart code",
    "start": "1551820",
    "end": "1557970"
  },
  {
    "text": "right this is what's just christened just showed you right you just import PI spark build a spark session and run it",
    "start": "1557970",
    "end": "1563730"
  },
  {
    "text": "and we will in in our engine we do we have that something called in its",
    "start": "1563730",
    "end": "1569070"
  },
  {
    "text": "process that's actually a propagate populates default configurations for",
    "start": "1569070",
    "end": "1574230"
  },
  {
    "text": "your session and we we populates the spark kubernetes you know weird if I'm the API server what the pond names are",
    "start": "1574230",
    "end": "1581280"
  },
  {
    "text": "you know some some default settings that this data sign is shouldn't even worry about and we can talk about later about",
    "start": "1581280",
    "end": "1588420"
  },
  {
    "text": "the how even more advanced optimizations we can do if we know what you're running on right so this is data science for",
    "start": "1588420",
    "end": "1594030"
  },
  {
    "text": "them they just import spark and run it right everything is already set up and you know you just kind of just finish",
    "start": "1594030",
    "end": "1601410"
  },
  {
    "text": "this [Laughter] based on time we can really go through so much but this basically goes through",
    "start": "1601410",
    "end": "1608000"
  },
  {
    "text": "spreads images around and run inference on them so without the dependency",
    "start": "1608000",
    "end": "1614309"
  },
  {
    "text": "management piece of mounting executor x' let me actually show you the pause hopefully he's still running without",
    "start": "1614309",
    "end": "1622620"
  },
  {
    "text": "actually mounting enough s pots volume since your HT sector you won't even even",
    "start": "1622620",
    "end": "1629010"
  },
  {
    "text": "run the example because this example knees custom packages to run this is probably a long time ago so I have",
    "start": "1629010",
    "end": "1635520"
  },
  {
    "text": "executor z-- this is SPARC executives launched for me for this my session",
    "start": "1635520",
    "end": "1640890"
  },
  {
    "text": "that's running right so this is just happening behind the scenes I have exec tourist launched by kubernetes connected",
    "start": "1640890",
    "end": "1646529"
  },
  {
    "text": "to this current client Mo's session able to give out commands and get the output back and show you right here into your",
    "start": "1646529",
    "end": "1652919"
  },
  {
    "text": "session right here right so to the data scientist this is great right I don't have to figure out how to actually",
    "start": "1652919",
    "end": "1657929"
  },
  {
    "text": "configure spark I didn't actually figure out how to do scale outs because this is kind of done for me of course there's a",
    "start": "1657929",
    "end": "1663750"
  },
  {
    "text": "lot more figuration parameters as spark is pretty manure things again tune right",
    "start": "1663750",
    "end": "1669899"
  },
  {
    "text": "so there's there's a way we're going to give you a bang experiences spark",
    "start": "1669899",
    "end": "1675750"
  },
  {
    "text": "history server and all the tooling and logging you need to to able to see what's happening but so that's kind of",
    "start": "1675750",
    "end": "1681720"
  },
  {
    "text": "how tents spark on khones just natively integrates right so using a library you can actually just run spark on",
    "start": "1681720",
    "end": "1687210"
  },
  {
    "text": "communities and actually get dependency management built in and and also have",
    "start": "1687210",
    "end": "1692220"
  },
  {
    "text": "namespaces quotas all of that set up alright so that's the demo you know two",
    "start": "1692220",
    "end": "1700830"
  },
  {
    "text": "minutes alright so we're gonna go for this really quick so what's what's happening right now so there's there's",
    "start": "1700830",
    "end": "1707340"
  },
  {
    "text": "more work needed on the spark on cronies of strings i right there's there's Kerberos support that's actually finishing in spark code base dynamic",
    "start": "1707340",
    "end": "1714570"
  },
  {
    "text": "allocation doesn't work yet and I'm not sure even know what time allocation is that means it's a it's a auto-scaling",
    "start": "1714570",
    "end": "1720240"
  },
  {
    "text": "that's happening in a spark level right cumin Hayes has auto scaling but if you have to tell kubernetes hey look at this",
    "start": "1720240",
    "end": "1726029"
  },
  {
    "text": "metric if it's above some special start doing some scaling spark has a lot of information itself right I have a lot",
    "start": "1726029",
    "end": "1731940"
  },
  {
    "text": "more tasks queued up please amor executor z-- can probably do a better job doing it so",
    "start": "1731940",
    "end": "1737010"
  },
  {
    "text": "this is what diamond allocation does and it is getting added to does kubernetes native support GPU support is you know",
    "start": "1737010",
    "end": "1743550"
  },
  {
    "text": "able to propagate information to kubernetes for GPUs you know and what's almost interesting for for us as well is",
    "start": "1743550",
    "end": "1749970"
  },
  {
    "text": "that we have a lot of large-scale use cases from Hadoop what you need is also",
    "start": "1749970",
    "end": "1755100"
  },
  {
    "text": "a much better batch scheduling when it comes to a lot at certain stage right you don't want you want all your teams",
    "start": "1755100",
    "end": "1760650"
  },
  {
    "text": "and organizations able to have a fair shares of your workloads and resources",
    "start": "1760650",
    "end": "1765960"
  },
  {
    "text": "so there's six scheduling there's cube batch that's happening right and definitely that is the right direction",
    "start": "1765960",
    "end": "1772820"
  },
  {
    "text": "but I think most large-scale use case and enterprises will need something like",
    "start": "1772820",
    "end": "1778470"
  },
  {
    "text": "this you'll be able to actually support resource management at scale for your batch jobs all right so really quickly",
    "start": "1778470",
    "end": "1785040"
  },
  {
    "text": "what's next right talk about spark own kubernetes just one big one piece of",
    "start": "1785040",
    "end": "1790830"
  },
  {
    "text": "getting your cloud native machine learning working on the kubernetes coming from the hyper pilot world this",
    "start": "1790830",
    "end": "1797730"
  },
  {
    "text": "is also why I really firmly believe is that at scale things are harder to write",
    "start": "1797730",
    "end": "1802890"
  },
  {
    "text": "your tap to tune or container resources you have to tune your spark resources the other tune your VM cluster size",
    "start": "1802890",
    "end": "1808170"
  },
  {
    "text": "instance types all kinds of stuff so we really believe that and this is just",
    "start": "1808170",
    "end": "1813900"
  },
  {
    "text": "machine learning right if user actually starts to actually cram in data warehousing data engineering right in",
    "start": "1813900",
    "end": "1819630"
  },
  {
    "text": "this shared environments how do you it's almost impossible for it engineers an",
    "start": "1819630",
    "end": "1824850"
  },
  {
    "text": "admin to really tune everything that has your best case utilization right and I",
    "start": "1824850",
    "end": "1832560"
  },
  {
    "text": "think increasingly we're seeing actually our customers are talking about utilization talking about how cost is affecting them whereas scale as well so",
    "start": "1832560",
    "end": "1840140"
  },
  {
    "text": "how do we actually use the data from your cluster Abell to analyze and optimize and automatically manage your",
    "start": "1840140",
    "end": "1847020"
  },
  {
    "text": "clusters right this is not just telling you what you should be doing can we actually create automation for you so this is bringing some of the",
    "start": "1847020",
    "end": "1854610"
  },
  {
    "text": "hyper pilots screenshots but this is",
    "start": "1854610",
    "end": "1860040"
  },
  {
    "text": "what we're also looking to is she in bed into calderas future offerings in some",
    "start": "1860040",
    "end": "1867270"
  },
  {
    "text": "points but using data you can really able to figure out a lot more insights right rather",
    "start": "1867270",
    "end": "1873750"
  },
  {
    "text": "than just telling rather just telling your data engineers hey your container is CP really just seeing CPU spiked at",
    "start": "1873750",
    "end": "1881490"
  },
  {
    "text": "80% and rather just seeing that hey my memory has been using a 60% I got wound killed you know can we actually tell you",
    "start": "1881490",
    "end": "1888540"
  },
  {
    "text": "what really happens you know what what is a key resource bottleneck because if",
    "start": "1888540",
    "end": "1893610"
  },
  {
    "text": "you haven't you look at your monitoring dashboard it's really hard to figure out if networking as high CPU as high as",
    "start": "1893610",
    "end": "1898860"
  },
  {
    "text": "well right if it's IO is high in the cloud environments you actually your CPU might be high too right because you're",
    "start": "1898860",
    "end": "1904290"
  },
  {
    "text": "have a shared volume actually iowa's high networking might be high as well you have network volume is attached right really hard to figure out what is",
    "start": "1904290",
    "end": "1911670"
  },
  {
    "text": "a key resource bottlenecks and what the key problems are happening and is it interference miami getting actually",
    "start": "1911670",
    "end": "1917790"
  },
  {
    "text": "overtaken by another container running on the same node or cluster so we did a",
    "start": "1917790",
    "end": "1923790"
  },
  {
    "text": "lot of work to do some machine learning to actually figure out what insights and figure out the root causes so this is",
    "start": "1923790",
    "end": "1929730"
  },
  {
    "text": "one screenshot there I want to quickly mention lasting is just showing you what",
    "start": "1929730",
    "end": "1936000"
  },
  {
    "text": "to be done what is the key problem doesn't really automatically solve and give you the best utilization right to",
    "start": "1936000",
    "end": "1942660"
  },
  {
    "text": "get the best utilization possible you really need to have automation and what",
    "start": "1942660",
    "end": "1947910"
  },
  {
    "text": "we talked about automation is not just adding more nose it's not just adding more pots you know in this particular",
    "start": "1947910",
    "end": "1953160"
  },
  {
    "text": "example if you if you're interested you definitely should look for search for hyper pilots and you can definitely see",
    "start": "1953160",
    "end": "1960660"
  },
  {
    "text": "a lot more details we we seeing a lot of use cases where there's interference",
    "start": "1960660",
    "end": "1965880"
  },
  {
    "text": "happening on the same note if I have a pod running a lot of network traffic and",
    "start": "1965880",
    "end": "1971120"
  },
  {
    "text": "overtaking another long-running service and in a machine learning context this is a model deployments that's running",
    "start": "1971120",
    "end": "1976920"
  },
  {
    "text": "next to your spark shop doing batch job training so how do i if you don't want",
    "start": "1976920",
    "end": "1982260"
  },
  {
    "text": "to waste a lot of resources and pre allocates your largest cluster to do model deployments you want to you to a",
    "start": "1982260",
    "end": "1988110"
  },
  {
    "text": "bolita lies your slack resources to do model training but it's a real challenge to not interfere with the deployments",
    "start": "1988110",
    "end": "1994980"
  },
  {
    "text": "that are doing inference on real time so in this screen it is probably a little hard to digest but this is saying that",
    "start": "1994980",
    "end": "2002030"
  },
  {
    "text": "this is what long-running service is what happens when you run a bath shop next to your long-running services it's",
    "start": "2002030",
    "end": "2007969"
  },
  {
    "text": "basically a latency it spikes up because this is running sparks jobs or doing you",
    "start": "2007969",
    "end": "2013039"
  },
  {
    "text": "know Tara sorts and doing a lot of different it's doing a lot of network traffic to pull data in from s3 doing a",
    "start": "2013039",
    "end": "2019039"
  },
  {
    "text": "lot of shuffle data writing into your i/o and disks and you see a lot of interference or happen you could enable",
    "start": "2019039",
    "end": "2026599"
  },
  {
    "text": "automation on an old level as well right if you imagine your resource or number is just only static the whole runtime is",
    "start": "2026599",
    "end": "2033799"
  },
  {
    "text": "running but able to actually figure out what is a key resource bottlenecks we're talking about IO level network level CPU",
    "start": "2033799",
    "end": "2040940"
  },
  {
    "text": "memory and even lower levels things and automates it because you if we understand your bass job it doesn't have",
    "start": "2040940",
    "end": "2046759"
  },
  {
    "text": "to finish right the next minutes you don't really need to take all the resources you're looking for and only give you certain resources that required",
    "start": "2046759",
    "end": "2053539"
  },
  {
    "text": "acted at real time then I can able to really achieve much higher utilization so your utilization can jump much higher",
    "start": "2053539",
    "end": "2060169"
  },
  {
    "text": "without really killing your job spatula so that's the next kind of level of automation ruling on a label for",
    "start": "2060169",
    "end": "2066730"
  },
  {
    "text": "communities so that's it's all the stuff",
    "start": "2066730",
    "end": "2071839"
  },
  {
    "text": "we talked about life spark on Calder and machine learning you're gonna feel free to come and sign up we have a private",
    "start": "2071839",
    "end": "2077450"
  },
  {
    "text": "preview coming up good can go to URL and actually try out and give us feedback",
    "start": "2077450",
    "end": "2082789"
  },
  {
    "text": "early this runs on all kubernetes manage kubernetes and yeah there's also",
    "start": "2082789",
    "end": "2089839"
  },
  {
    "text": "relevant six that would just talk about scheduling in Big Data there's a machinery working group that also recently formed that we're also going to",
    "start": "2089839",
    "end": "2096200"
  },
  {
    "text": "be engaging and talking about about a lot more things like this I think that's it's welcome any questions and anything",
    "start": "2096200",
    "end": "2104910"
  },
  {
    "text": "[Applause]",
    "start": "2104910",
    "end": "2108650"
  }
]
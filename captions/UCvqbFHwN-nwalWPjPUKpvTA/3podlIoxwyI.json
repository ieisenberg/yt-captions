[
  {
    "text": "hey everyone uh let's get started uh welcome to the session on bin packing pods and managed kubernetes thank you",
    "start": "640",
    "end": "7640"
  },
  {
    "text": "for being here I'm Vin Sur and I'm a senior software engineer at click house uh my",
    "start": "7640",
    "end": "14480"
  },
  {
    "text": "co-presenter is Jan who he also works as a senior software engineer at click house so on the agenda today um we'll",
    "start": "14480",
    "end": "22400"
  },
  {
    "text": "start with a short introduction to what is Click house and click house Cloud then we'll talk about the like overview",
    "start": "22400",
    "end": "28679"
  },
  {
    "text": "of the problem that we fac in with our infrastructure and why used bin packing to solve it uh then we'll get into the",
    "start": "28679",
    "end": "34920"
  },
  {
    "text": "details of what is our how infrastructure is set up what were the various approaches we used to solve our",
    "start": "34920",
    "end": "40559"
  },
  {
    "text": "node utilization problem and then we'll also talk about like the roll out we did for our across our Fleet uh what were",
    "start": "40559",
    "end": "47440"
  },
  {
    "text": "the savings we achieved and some of the learnings uh that we realized uh during this whole exercise um and then we'll",
    "start": "47440",
    "end": "54440"
  },
  {
    "text": "end with Q&A at the very end so what is click house click house",
    "start": "54440",
    "end": "61879"
  },
  {
    "text": "is an olap database uh it's used mainly for analytics use cases um it's used to generate aggregations and visualizations",
    "start": "61879",
    "end": "68320"
  },
  {
    "text": "on your data U and it works best with mostly immutable data it's been in development since 2009",
    "start": "68320",
    "end": "75960"
  },
  {
    "text": "and it was open sourced in 2016 and it's gained a lot of popularity since then and it's one of the fastest growing",
    "start": "75960",
    "end": "82600"
  },
  {
    "text": "GitHub communities click house is a fully distributed database so it supports",
    "start": "82600",
    "end": "88280"
  },
  {
    "text": "replication sharding uh multimaster and cross region setup so it is production",
    "start": "88280",
    "end": "94399"
  },
  {
    "text": "ready last and the most important thing about click house is that is extremely fast using various techniques such as",
    "start": "94399",
    "end": "100759"
  },
  {
    "text": "column oriented storage and state-of-the-art data compression click house provides insights into uh the",
    "start": "100759",
    "end": "106399"
  },
  {
    "text": "customer data in milliseconds which makes it one of the fastest databases out",
    "start": "106399",
    "end": "112240"
  },
  {
    "text": "there so now that we have an idea about what is Click house what is Click house Cloud click house cloud is the",
    "start": "112240",
    "end": "118719"
  },
  {
    "text": "serverless offering of click house uh it has various features such as idling and auto scaling so that you can bring down",
    "start": "118719",
    "end": "124600"
  },
  {
    "text": "your compute when there are no uh when there's no activity on the cluster and similarly autos auto scale U the cluster",
    "start": "124600",
    "end": "131039"
  },
  {
    "text": "when there are workload spikes we also have compute and storage separation so that you can scale compute",
    "start": "131039",
    "end": "137160"
  },
  {
    "text": "independently of storage this is how a click house Cloud instance looks under the hood we use kubernetes as a compute",
    "start": "137160",
    "end": "144200"
  },
  {
    "text": "layer and we use object storage uh for the data persistence um we currently still use",
    "start": "144200",
    "end": "150280"
  },
  {
    "text": "PVCs for some metadata but we are in the process of moving away from that we're currently available on AWS and gcp uh",
    "start": "150280",
    "end": "158400"
  },
  {
    "text": "and pretty soon we'll be coming to Azure as well and later in the year we'll also",
    "start": "158400",
    "end": "163959"
  },
  {
    "text": "have the bring your own cloud offering in which the customer data can stay in the customer um VPC and customer cloud",
    "start": "163959",
    "end": "170200"
  },
  {
    "text": "account and they can use the click house Cloud control plane to deploy click house in their account so that uh large",
    "start": "170200",
    "end": "177239"
  },
  {
    "text": "Enterprises uh who do not want to part with the data can use this solution to deploy click house on their",
    "start": "177239",
    "end": "184280"
  },
  {
    "text": "premises so now that we have an idea about what is Click house and what is Click house Cloud what is the problem",
    "start": "184280",
    "end": "190159"
  },
  {
    "text": "that we were trying to solve and before we get into the problem the title of the talk is B packing pods in managed",
    "start": "190159",
    "end": "196760"
  },
  {
    "text": "kubernetes so what is bin packing in general terms bin packing is an optimization problem in which items",
    "start": "196760",
    "end": "203680"
  },
  {
    "text": "of different sizes must be packed into a finite number of bends each with a given capacity in a way that minimize es the",
    "start": "203680",
    "end": "210120"
  },
  {
    "text": "number of pins used so if you look at this picture U on the left side you see",
    "start": "210120",
    "end": "215159"
  },
  {
    "text": "that we have an initial set of objects that individually have some weights and on the right we have a bins with Max",
    "start": "215159",
    "end": "221560"
  },
  {
    "text": "Capacity and using bin packing we can fit all of these elements in only three notes instead of four saving us the cost",
    "start": "221560",
    "end": "227840"
  },
  {
    "text": "of one of those bin specifically in kubernetes bin",
    "start": "227840",
    "end": "233439"
  },
  {
    "text": "packing refers to the process of efficiently scheduling pods onto the nodes in the cluster um in a way to",
    "start": "233439",
    "end": "239879"
  },
  {
    "text": "maximize the resource utilization and minimize the number of notes needed while also satisfying all of the constraints of the pods this helps us",
    "start": "239879",
    "end": "247319"
  },
  {
    "text": "save cluster resources such as CPU memory and can lead to a lot of cost savings and improved",
    "start": "247319",
    "end": "254920"
  },
  {
    "text": "efficiency so now that we have an idea of what has been packing uh what is the problem that we were facing so in our",
    "start": "254920",
    "end": "261680"
  },
  {
    "text": "cluster in our kubernetes clusters which is multi tenant and is present are present in multiple regions we noticed",
    "start": "261680",
    "end": "267240"
  },
  {
    "text": "that the node resource utilization CPU and memory were non-optimal across the fleet and this meant that we had higher",
    "start": "267240",
    "end": "273400"
  },
  {
    "text": "infrastructure costs because we were running more notes than was required so we explored a few different",
    "start": "273400",
    "end": "279800"
  },
  {
    "text": "solutions and the one that we finally settled on was to update the kubernetes schedul scoring strategy to bin pack PS",
    "start": "279800",
    "end": "285759"
  },
  {
    "text": "onto the fewer nodes then we had to roll out this solution to all of our kubernetes",
    "start": "285759",
    "end": "291199"
  },
  {
    "text": "clusters which are present in multiple regions um and also it's a multi-tenant fee uh so that we have multiple instance",
    "start": "291199",
    "end": "297600"
  },
  {
    "text": "click house instances on the same node so we had to find a way to reliably load out these changes so that existing",
    "start": "297600",
    "end": "303600"
  },
  {
    "text": "customers do not face any disruptions so we'll talk about all of these in detail in the coming upcoming",
    "start": "303600",
    "end": "310440"
  },
  {
    "text": "sections um so before we take a look at the infrastructure setup for click house Cloud um some of the terminology that",
    "start": "310440",
    "end": "317039"
  },
  {
    "text": "we'll be reusing across our slides click housee keeper is our",
    "start": "317039",
    "end": "322080"
  },
  {
    "text": "replacement to zookeeper it is used as a coordination component for our server pods click housee server is these are",
    "start": "322080",
    "end": "329880"
  },
  {
    "text": "the compute pods for ingest and uh query uh these are the pods which process the data and process them to the object",
    "start": "329880",
    "end": "337319"
  },
  {
    "text": "storage click house instance or cluster just means that this is a custom resource in kubernetes that consists of",
    "start": "337319",
    "end": "343319"
  },
  {
    "text": "keeper and server stateful sets both click house keeper and click House Server have similar needs with respect",
    "start": "343319",
    "end": "349800"
  },
  {
    "text": "to bin packing and so we for the purposes of this talk will only focus on the server pods for Simplicity but all",
    "start": "349800",
    "end": "356600"
  },
  {
    "text": "of the uh approaches that we used for the server pods can also be transferred to the keeper",
    "start": "356600",
    "end": "362400"
  },
  {
    "text": "pods when we refer to a node we just refer to an ec2 Azure or a gcp",
    "start": "362400",
    "end": "368280"
  },
  {
    "text": "VM node utilization so when we say node utilization it means it's the sum of",
    "start": "368280",
    "end": "374120"
  },
  {
    "text": "resource request of all pods on the Node divided by the allocatable resources on the Node the key thing to note is that",
    "start": "374120",
    "end": "380080"
  },
  {
    "text": "we are not looking at the actual usage of the Pod but the resource request which is the minimum resources required by the",
    "start": "380080",
    "end": "386000"
  },
  {
    "text": "Pod and finally cube schul is the default pods sched for all the pods in the kubernetes",
    "start": "386000",
    "end": "393000"
  },
  {
    "text": "cluster so let's take a look at how we set up uh kubernetes in Click house Cloud we use manage Cloud uh kubernetes",
    "start": "393000",
    "end": "400960"
  },
  {
    "text": "in each cloud service provider so eks for AWS GK for gcp and AKs for",
    "start": "400960",
    "end": "406120"
  },
  {
    "text": "Azure we run multi-tenant communities clusters and what this means is that ports from two different click house",
    "start": "406120",
    "end": "411360"
  },
  {
    "text": "instances can run on the same node we also use name spaces for",
    "start": "411360",
    "end": "416720"
  },
  {
    "text": "isolation so that pods from two different instances to not interfere with each other and we use kubernetes",
    "start": "416720",
    "end": "421800"
  },
  {
    "text": "Network policy via the celium cni solution to prevent cross namespace Network",
    "start": "421800",
    "end": "428000"
  },
  {
    "text": "calls so continuing further we use cluster autoscaler which is a pretty well-known component for dynamic node",
    "start": "428000",
    "end": "434199"
  },
  {
    "text": "provisioning so for node scale up and scale down U most of the click House Server",
    "start": "434199",
    "end": "439879"
  },
  {
    "text": "pods are in a similar shape in terms of CPU to memory ratio and so we have a",
    "start": "439879",
    "end": "444960"
  },
  {
    "text": "homogeneous workload for the click House Server node groups we also make use of over",
    "start": "444960",
    "end": "450319"
  },
  {
    "text": "provisioning which is a concept in kubernetes where we reserve some extra capacity for workload spikes so that",
    "start": "450319",
    "end": "455960"
  },
  {
    "text": "when these spikes come in uh server pods can be scheduled on these extra nodes and we do this by scheduling some low",
    "start": "455960",
    "end": "463360"
  },
  {
    "text": "priority preemptable pods on these nodes which can be evicted if server pods need to be scheduled and these evicted pods",
    "start": "463360",
    "end": "469840"
  },
  {
    "text": "now will tell cluster order scaler to provision more nodes for buffer and lastly we have a weekly",
    "start": "469840",
    "end": "476520"
  },
  {
    "text": "release schedule for all of the pods in Click house across our Fleet um this is important because it will come up later",
    "start": "476520",
    "end": "483000"
  },
  {
    "text": "and we do periodic rescheduling and restarting of PODS so we deliver all the click house image updates via this",
    "start": "483000",
    "end": "489159"
  },
  {
    "text": "weekly release schedule so this is how a sample kubernetes cluster would look like um we",
    "start": "489159",
    "end": "496440"
  },
  {
    "text": "have nodes which are VMS in all three azs uh because click house instance has",
    "start": "496440",
    "end": "501720"
  },
  {
    "text": "pods in all three azs for reliability we also have a few system workloads that are deployed on these",
    "start": "501720",
    "end": "507840"
  },
  {
    "text": "spots so that um we can monitor the usage on these pods we have a few click",
    "start": "507840",
    "end": "513039"
  },
  {
    "text": "House Server pods that are already running on the nodes and we have an operator in the uh in the kubernetes",
    "start": "513039",
    "end": "518320"
  },
  {
    "text": "cluster that is responsible for managing the custom resources so when a new click house",
    "start": "518320",
    "end": "523640"
  },
  {
    "text": "instance is created it creates a custom resource which is managed by the operator and which in turn creates",
    "start": "523640",
    "end": "530080"
  },
  {
    "text": "stateful sets and the stateful sets create the pods that they manage similarly when another custom",
    "start": "530080",
    "end": "536959"
  },
  {
    "text": "resource uh when another click house instance is is created the same process is repeated and the pods are created",
    "start": "536959",
    "end": "543079"
  },
  {
    "text": "again and we see that uh pods from two different instances are living on the same node this is what we meant by",
    "start": "543079",
    "end": "549880"
  },
  {
    "text": "multitenant so this is how like the infrastructure would look like in a kubernetes cluster in Click house",
    "start": "549880",
    "end": "556920"
  },
  {
    "text": "Cloud so now that we have an idea about how our infrastructure looks like what was the problem that we were running",
    "start": "556920",
    "end": "562480"
  },
  {
    "text": "into so when we did a regular audit of our Fleet we noticed that the node utilization in the fleet was only about",
    "start": "562480",
    "end": "568959"
  },
  {
    "text": "40 60% and this was bad because it meant we were running nearly twice the number",
    "start": "568959",
    "end": "574200"
  },
  {
    "text": "of nodes we needed to run the same workloads so a few factors in our Cloud",
    "start": "574200",
    "end": "579920"
  },
  {
    "text": "setup that contribute to utilization uh we have a dynamic Fleet which means that since we have idling enabled click house",
    "start": "579920",
    "end": "586240"
  },
  {
    "text": "clusters which do not have any queries or inserts running on them uh for more than 30 minutes are now scaled down to",
    "start": "586240",
    "end": "592160"
  },
  {
    "text": "zero pods we also have Auto scaling that means pods might occasionally need to be restarted with a different size and uh",
    "start": "592160",
    "end": "599079"
  },
  {
    "text": "different CPU and memory and finally in the regular",
    "start": "599079",
    "end": "604519"
  },
  {
    "text": "service life cycle in creation and termination we have pods being provisioned and pods being uh deprovisioned as well and all this means",
    "start": "604519",
    "end": "611920"
  },
  {
    "text": "that utilization is something that keeps changing over time and is quite Dynamic within our kuber",
    "start": "611920",
    "end": "618040"
  },
  {
    "text": "clusters so the goal which after identifying the problem the main goal for us is to increase the node resource",
    "start": "618040",
    "end": "623920"
  },
  {
    "text": "utilization across the fleet and Via that we can realize some cost savings",
    "start": "623920",
    "end": "630040"
  },
  {
    "text": "so we explored a few approaches to um improving the node utilization but before we talk about the approaches any",
    "start": "630040",
    "end": "636880"
  },
  {
    "text": "solution that we actually adopt needs to satisfy a few requirements the first and",
    "start": "636880",
    "end": "641920"
  },
  {
    "text": "the most obvious one is that it needs to increase the node resource utilization across the fleet the second and the most important",
    "start": "641920",
    "end": "648880"
  },
  {
    "text": "one is that for existing customers we want to minimize disruption to their workloads since we're a database we",
    "start": "648880",
    "end": "655279"
  },
  {
    "text": "might have long running insert queries on ports that we do not want to interrupt and we also do not want any degradation",
    "start": "655279",
    "end": "661720"
  },
  {
    "text": "in the experience for customers when they're provisioning new instances since now we have fewer nodes in the uh in the",
    "start": "661720",
    "end": "667760"
  },
  {
    "text": "cluster we do not want the node provisioning time to be an additional burden for the",
    "start": "667760",
    "end": "673399"
  },
  {
    "text": "customers and the last requirement is that our solution needs to be multicloud friendly since we run in three major",
    "start": "673399",
    "end": "679040"
  },
  {
    "text": "clouds uh we want one solution that works for all three of them and not a bisoke solution for each",
    "start": "679040",
    "end": "685360"
  },
  {
    "text": "Cloud so those are the requirements that any solution that we adopt should satisfy so let's take a look at what are",
    "start": "685360",
    "end": "691760"
  },
  {
    "text": "the different approaches we uh explored the first one was overc committing the resources on the",
    "start": "691760",
    "end": "697160"
  },
  {
    "text": "Node so in this case um we set the resource requests to be less than the",
    "start": "697160",
    "end": "702600"
  },
  {
    "text": "limits of that node and this means that the PODS of on of the Pod uh this means",
    "start": "702600",
    "end": "708480"
  },
  {
    "text": "that the pods will be Qs burstable which means that their usage can vary from anywhere from the resource request to",
    "start": "708480",
    "end": "714480"
  },
  {
    "text": "the resource limit by decreasing the resource request which which is the minimum amount of",
    "start": "714480",
    "end": "720200"
  },
  {
    "text": "resources required by the pods U we can schedule more pods on each node the key assumption here is that not",
    "start": "720200",
    "end": "727920"
  },
  {
    "text": "all the pods use these resource up to the limits at the same time and hence we schedule more pods on each node so look",
    "start": "727920",
    "end": "735440"
  },
  {
    "text": "looking at an example of how this would work let's say we have a node with 64 GB total memory and we have four pods with",
    "start": "735440",
    "end": "741920"
  },
  {
    "text": "resource requests of 16 GB each and memory limits of 32 GB each so now on",
    "start": "741920",
    "end": "748000"
  },
  {
    "text": "this port we can SK on this node we can schedule four of these pods um and when they only use up up to their resource",
    "start": "748000",
    "end": "754839"
  },
  {
    "text": "requests everything's good but technically if you look at the limits we've committed 128 GB on this uh node",
    "start": "754839",
    "end": "763040"
  },
  {
    "text": "which is which only has 64 GB and if all the pods start using up to their maximum limits at the same time then that's",
    "start": "763040",
    "end": "769440"
  },
  {
    "text": "going to cause issues and for that very reason we did not end up uh adopting this approach and",
    "start": "769440",
    "end": "777079"
  },
  {
    "text": "like I mentioned if all the pods start using the maximum resources it can either in case of memory lead to O kill",
    "start": "777079",
    "end": "783040"
  },
  {
    "text": "or it can lead to throttling of the CPU and this is not good for us CU in K house Cloud we have a Qs guaranteed",
    "start": "783040",
    "end": "789600"
  },
  {
    "text": "setup because the customer sets the resource limits and we guarantee that they get what they paid for and so if we",
    "start": "789600",
    "end": "796000"
  },
  {
    "text": "change that to Qs burstable um it will not be a good experience for the customer and it can lead to the Noisy",
    "start": "796000",
    "end": "801040"
  },
  {
    "text": "Neighbor situation the second approach that we explored was tuning the cluster",
    "start": "801040",
    "end": "806720"
  },
  {
    "text": "autoscaler so cluster autoscaler has has a setting where we can specify the utilization threshold and if on a",
    "start": "806720",
    "end": "813160"
  },
  {
    "text": "certain node utilization Falls below that threshold then the pods on that node are evicted and that node is marked",
    "start": "813160",
    "end": "819480"
  },
  {
    "text": "for scal down so it doesn't mean that scal down happens immediately uh it considers",
    "start": "819480",
    "end": "825240"
  },
  {
    "text": "various things as spot disruption budget tains tolerations Etc it's just marked as a candidate for scal down and this is",
    "start": "825240",
    "end": "831199"
  },
  {
    "text": "a very handy way to identify excess capacity in the cluster but we didn't end up adopting",
    "start": "831199",
    "end": "837759"
  },
  {
    "text": "this approach and the reason U is that this violates some of our requirements uh frequent evictions of pods on nodes",
    "start": "837759",
    "end": "844800"
  },
  {
    "text": "is too disruptive uh for stateful workloads such as click house uh which is a",
    "start": "844800",
    "end": "850680"
  },
  {
    "text": "database it also violates our requirement of not interrupting long running queries on these",
    "start": "850680",
    "end": "856360"
  },
  {
    "text": "spots and we also do not have enough fine grain control on evictions so we looked at another",
    "start": "856360",
    "end": "863320"
  },
  {
    "text": "component called desch which is a kubernetes 6 project U it's meant to be",
    "start": "863320",
    "end": "868480"
  },
  {
    "text": "a counterpart to cube scheduler where when cube schul makes a decision it uh on where where to schedule a pod it",
    "start": "868480",
    "end": "874839"
  },
  {
    "text": "looks at the state of the system at a certain point in time and it picks the best node for that pod but the state of",
    "start": "874839",
    "end": "880959"
  },
  {
    "text": "the system varies over time and after a certain point the original scheduling decision might not be valid U and but",
    "start": "880959",
    "end": "888880"
  },
  {
    "text": "Cube scheduler does not go back and reschedule the Pod and this is where theuer comes in so theer can look at",
    "start": "888880",
    "end": "895920"
  },
  {
    "text": "certain constraints that we give via plugins and it can EV pods on nodes which violate those",
    "start": "895920",
    "end": "901959"
  },
  {
    "text": "constraints one such constraint or Plugin is the high node utilization plugin using which we can set a certain",
    "start": "901959",
    "end": "909600"
  },
  {
    "text": "threshold in the node and if the usage threshold Falls below that for that particular node the pods there are",
    "start": "909600",
    "end": "916120"
  },
  {
    "text": "evicted so you can see that this is actually quite similar to the cluster autoscaler and this solution also does",
    "start": "916120",
    "end": "922920"
  },
  {
    "text": "not work for us for the same reasons where it's uh we have frequent evictions and we have uh Interruption of long in",
    "start": "922920",
    "end": "929639"
  },
  {
    "text": "queries so we noticed that we had the same problem with both approaches 2 and three where we are focusing on Ting the",
    "start": "929639",
    "end": "936120"
  },
  {
    "text": "pods and scaling down the nodes but not focusing on where the evicted pods are",
    "start": "936120",
    "end": "941240"
  },
  {
    "text": "being scheduled and if they go just go on to another lesser utilized node we back at the same U problem",
    "start": "941240",
    "end": "948279"
  },
  {
    "text": "again and they also have frequent evictions of B which I already mentioned so we decided to focus on optimizing",
    "start": "948279",
    "end": "955639"
  },
  {
    "text": "packing during the pot scheduling phase instead of uh thinking about evictions so we started looking into the",
    "start": "955639",
    "end": "962120"
  },
  {
    "text": "kubernetes schedu a bit more deeply and we noticed that the way that kuber",
    "start": "962120",
    "end": "967399"
  },
  {
    "text": "scheduler does scheduling right now it first identifies all the nodes that this pod can fit on and then it does the",
    "start": "967399",
    "end": "974560"
  },
  {
    "text": "scoring phase for these nodes where it picks the node best node based on the highest score and by default um the",
    "start": "974560",
    "end": "981440"
  },
  {
    "text": "least allocated scoring policy is used and that means that when there are two pods that U like there are two nodes",
    "start": "981440",
    "end": "988000"
  },
  {
    "text": "that a pod can be schedu scheduled on kubernetes will pick uh the cube scheduler will pick the node with the",
    "start": "988000",
    "end": "993079"
  },
  {
    "text": "least allocation so it does this so that it can evenly distribute the load across the cluster but the flip side of this is",
    "start": "993079",
    "end": "1000639"
  },
  {
    "text": "that this makes nodes scale down unlikely because all the nodes have a certain amount of threshold and cluster autoscaler cannot reclaim the nodes and",
    "start": "1000639",
    "end": "1006839"
  },
  {
    "text": "so we have a inefficient cluster with higher number of nodes than required so in the same way uh in",
    "start": "1006839",
    "end": "1015079"
  },
  {
    "text": "kubernetes scheduler in the configuration um where we set least allocated kubernetes also offers uh an",
    "start": "1015079",
    "end": "1022040"
  },
  {
    "text": "option for most allocated scheduling um in which case in the same scenario that I just talked about if a pod needs to be",
    "start": "1022040",
    "end": "1028640"
  },
  {
    "text": "scheduled onto two nodes if you use the most allocated scoring policy it's going to schedule the Pod onto the Noe with",
    "start": "1028640",
    "end": "1035120"
  },
  {
    "text": "the higher utilization and it actually turns out that the best solution for us was actually the simplest one and this",
    "start": "1035120",
    "end": "1041240"
  },
  {
    "text": "looks like a very promising candidate so this is just an example of uh the config file um on how we would",
    "start": "1041240",
    "end": "1048558"
  },
  {
    "text": "update this in the control kuber control plane inside the plug-in config section for the node resources fed plugin we",
    "start": "1048559",
    "end": "1055240"
  },
  {
    "text": "update the scoring strategy to use most allocated scoring and we provide the equal weights to CPU and memory but that",
    "start": "1055240",
    "end": "1062840"
  },
  {
    "text": "can be changed based on your requirement so let's let's take a look",
    "start": "1062840",
    "end": "1068440"
  },
  {
    "text": "at how this would look in in our cluster let's say we have three notes with click House Server pods on all three of them",
    "start": "1068440",
    "end": "1075080"
  },
  {
    "text": "and if for any reason one of the p is restarted either due to idling un idling or autoscaling so now click house when",
    "start": "1075080",
    "end": "1081600"
  },
  {
    "text": "it tries to schedule this prod again if it's using the most allocated scoring policy it will first find the nodes",
    "start": "1081600",
    "end": "1087760"
  },
  {
    "text": "which can fit the SP which is node one and node 3 and since node one has the",
    "start": "1087760",
    "end": "1092799"
  },
  {
    "text": "higher utilization it will then schedule the Pod onto node one and that means that node 3 can now be reclaimed at",
    "start": "1092799",
    "end": "1099000"
  },
  {
    "text": "cluster Auto scaler and now our cluster is in a state where we only use two notes instead of three and the notes are",
    "start": "1099000",
    "end": "1104760"
  },
  {
    "text": "packed better so this looks like a promising candidate uh let's take a look if it",
    "start": "1104760",
    "end": "1109960"
  },
  {
    "text": "satisfies all of our requirements the first requirement was that we need to increase node utilization across the fleet by virtue",
    "start": "1109960",
    "end": "1117840"
  },
  {
    "text": "of packing higher number of PODS onto lower number of nodes we get better utilization across the",
    "start": "1117840",
    "end": "1123159"
  },
  {
    "text": "fleet the second requirement was that this needs to be low impact to the customer when we update the scheduler",
    "start": "1123159",
    "end": "1129480"
  },
  {
    "text": "scoring policy this does not immediately trigger a restart of all the pods instead over when the in the Pod life",
    "start": "1129480",
    "end": "1136360"
  },
  {
    "text": "cycle whenever the next restart occurs naturally that's when the Pod will now be scheduled onto a node which has more",
    "start": "1136360",
    "end": "1144720"
  },
  {
    "text": "utilization and the third requirement that is that our solution needs to be multicloud friendly and since this is a",
    "start": "1144720",
    "end": "1151360"
  },
  {
    "text": "kubernetes native solution this applies equally to all clouds and so all of the requirements seems to be matching for",
    "start": "1151360",
    "end": "1157559"
  },
  {
    "text": "this uh particular solution and so great U we just need to update the kubernetes",
    "start": "1157559",
    "end": "1162760"
  },
  {
    "text": "control plane to set the scoring policy to most allocated and we should be good right well turns out it's not so",
    "start": "1162760",
    "end": "1170320"
  },
  {
    "text": "simple in AWS and Azure we do not have access to the kubernetes control plane",
    "start": "1170320",
    "end": "1176520"
  },
  {
    "text": "to set this particular uh setting gcp offers a version of this called",
    "start": "1176520",
    "end": "1182600"
  },
  {
    "text": "optimized utilization that essentially does what we need it to but this only works in gcp and this is not portable to",
    "start": "1182600",
    "end": "1189640"
  },
  {
    "text": "both AWS and Azure so given this roadblock how do we set up the most allocated skater policy when we're",
    "start": "1189640",
    "end": "1195880"
  },
  {
    "text": "running on managed kubernetes turns out kubernetes has a handy way of doing this we can run a",
    "start": "1195880",
    "end": "1203320"
  },
  {
    "text": "secondary scheduler that is natively supported by kubernetes it runs in parallel to the default Cube scheduler",
    "start": "1203320",
    "end": "1210360"
  },
  {
    "text": "and we can annotate the Pod to mention that it needs to be scheduled by the secondary scheduler so what we can do is",
    "start": "1210360",
    "end": "1217039"
  },
  {
    "text": "that click House Server pods can be run by the secondary scheduler and the non- click house Ser The non- Click house",
    "start": "1217039",
    "end": "1222280"
  },
  {
    "text": "pods can still be run by the default scheduler we use the Upstream Cube",
    "start": "1222280",
    "end": "1227600"
  },
  {
    "text": "scheduler image okay okay sorry uh we use the Upstream",
    "start": "1227600",
    "end": "1234280"
  },
  {
    "text": "Cube schedular image and we just tweak the most allocated scoring",
    "start": "1234280",
    "end": "1240039"
  },
  {
    "text": "strategy just having some technical difficulties yeah I don't know what's",
    "start": "1241679",
    "end": "1249360"
  },
  {
    "text": "happening",
    "start": "1257600",
    "end": "1260600"
  },
  {
    "text": "sorry the cable maybe yeah not",
    "start": "1267640",
    "end": "1272000"
  },
  {
    "text": "sure yeah I'm going to stand here uh yeah so we use the same cube schedular",
    "start": "1276240",
    "end": "1282760"
  },
  {
    "text": "with by just tweaking the scoring policy U and we deployed the scheduler",
    "start": "1282760",
    "end": "1287960"
  },
  {
    "text": "in the Q system name space so that we can prevent evictions and scal down so this is how we set up in set set the",
    "start": "1287960",
    "end": "1294799"
  },
  {
    "text": "schuer up in the managed kubernetes so now that we have a solution that works for us and we also know how to set it up",
    "start": "1294799",
    "end": "1300960"
  },
  {
    "text": "um I'll hand it over to gen to talk about how we did this roll out in a non-disruptive manner and what were the learnings and cost savings we realized",
    "start": "1300960",
    "end": "1307760"
  },
  {
    "text": "thank you thank you",
    "start": "1307760",
    "end": "1312880"
  },
  {
    "text": "V now we already know the answer for the problem just the question is how we can",
    "start": "1312880",
    "end": "1318279"
  },
  {
    "text": "r result out so before we dive into the details",
    "start": "1318279",
    "end": "1324080"
  },
  {
    "text": "let's take a look of how the r process is look like we creat the deployment for",
    "start": "1324080",
    "end": "1330000"
  },
  {
    "text": "the secondary scheduler next to the default ones and um just creating that schedule",
    "start": "1330000",
    "end": "1336559"
  },
  {
    "text": "would has basically a noop uh but we need to update the clear housee P to use",
    "start": "1336559",
    "end": "1341799"
  },
  {
    "text": "this most allocated scheduler that would be uh just a one time change and from",
    "start": "1341799",
    "end": "1347520"
  },
  {
    "text": "that time uh point on all the clear housee PS will start to use this most allocated",
    "start": "1347520",
    "end": "1353200"
  },
  {
    "text": "scheduler and the PS will be restarted but we have po disruption budget configured it's just one time",
    "start": "1353200",
    "end": "1361320"
  },
  {
    "text": "migration um for our production safety we will start from some smaller cluster first to gain some",
    "start": "1361320",
    "end": "1368039"
  },
  {
    "text": "experience and then we graduate roll out to our entire production and finally",
    "start": "1368039",
    "end": "1373520"
  },
  {
    "text": "after that is done we do the evaluation and measure how much savings we achieved",
    "start": "1373520",
    "end": "1379320"
  },
  {
    "text": "all right so for the scatter setup we create the deployment with three parts",
    "start": "1379320",
    "end": "1385960"
  },
  {
    "text": "and uh the purpose for three pod is for the higher availability the part itself is",
    "start": "1385960",
    "end": "1392039"
  },
  {
    "text": "basically the same Docker image as the Upstream we just need to update the scheduling",
    "start": "1392039",
    "end": "1398240"
  },
  {
    "text": "policy um we also enable the leader election the idea is that when the primary part crashes the second one can",
    "start": "1398240",
    "end": "1405960"
  },
  {
    "text": "notice that and then take over the scheduling disease we actually do did some um uh",
    "start": "1405960",
    "end": "1412880"
  },
  {
    "text": "reliability test basically by constantly schedule a lot of Paws and in the middle",
    "start": "1412880",
    "end": "1418720"
  },
  {
    "text": "of that we kill the primary scheduler and then see how the secondary once",
    "start": "1418720",
    "end": "1425320"
  },
  {
    "text": "schedule part can take over we find that it can just work nicely so good to good",
    "start": "1425320",
    "end": "1431640"
  },
  {
    "text": "to go um we also need to do some measurements there are two type of the",
    "start": "1431640",
    "end": "1437799"
  },
  {
    "text": "measurements we need need to do the first one is the ad hoc analysis there is a tool open source one called eks",
    "start": "1437799",
    "end": "1445200"
  },
  {
    "text": "node viewer and that is dedicated for the eks resource analysis this is the",
    "start": "1445200",
    "end": "1451480"
  },
  {
    "text": "screenshot you can see from uh their um web page there they shows the CPU and",
    "start": "1451480",
    "end": "1458559"
  },
  {
    "text": "memory utilization number of the parts running on the nodes also even the cost",
    "start": "1458559",
    "end": "1463919"
  },
  {
    "text": "for different machine type based on the uh AWS pricing data that comes very",
    "start": "1463919",
    "end": "1469440"
  },
  {
    "text": "handy for us when you are doing some ad hoc analysis during the road the other type of the measurements",
    "start": "1469440",
    "end": "1476799"
  },
  {
    "text": "is for after you finish the uh road to the final evaluation we need something",
    "start": "1476799",
    "end": "1482360"
  },
  {
    "text": "more sophisticated than you no beer for this one we use our internal data",
    "start": "1482360",
    "end": "1488000"
  },
  {
    "text": "warehouse uh and a interesting fact that it also runs on the clear house Cloud because we love our product and this",
    "start": "1488000",
    "end": "1496279"
  },
  {
    "text": "data warehouse instance we show the cost over time so we can do more comparison",
    "start": "1496279",
    "end": "1501960"
  },
  {
    "text": "before and after the r out and the data rarehouse we have import the AWS cost",
    "start": "1501960",
    "end": "1508559"
  },
  {
    "text": "and usage data periodically we um also use super set a software open source",
    "start": "1508559",
    "end": "1515600"
  },
  {
    "text": "software as a UI layer on top of this data warehouse for some",
    "start": "1515600",
    "end": "1520880"
  },
  {
    "text": "analytics all right um having all these measurements uh and the preparation down",
    "start": "1520880",
    "end": "1527880"
  },
  {
    "text": "now is time to r as I mentioned we start from the small cluster uh first",
    "start": "1527880",
    "end": "1534840"
  },
  {
    "text": "um actually after R this out to a smaller cluster with the initial savings",
    "start": "1534840",
    "end": "1540039"
  },
  {
    "text": "were not that significant but we are not too worried because for a cluster to run",
    "start": "1540039",
    "end": "1545279"
  },
  {
    "text": "you need to have some flat cost anyway to run your system workflows and you also need to have one note per uh a and",
    "start": "1545279",
    "end": "1552520"
  },
  {
    "text": "per machine type those are just there you cannot avoid but the important part",
    "start": "1552520",
    "end": "1557679"
  },
  {
    "text": "is that we gave the confidence how to operate this in our production settings so that we can",
    "start": "1557679",
    "end": "1563720"
  },
  {
    "text": "proceed so this is a uh eks node viewer diagram that be for a larger cluster",
    "start": "1563720",
    "end": "1570880"
  },
  {
    "text": "before the rod um the important thing I want to highlight is that first the",
    "start": "1570880",
    "end": "1576679"
  },
  {
    "text": "average utilization for the cluster is around 50% which is not very high also",
    "start": "1576679",
    "end": "1583279"
  },
  {
    "text": "um the uh there the utilization per node is ranging from 30 to to 60% we want to",
    "start": "1583279",
    "end": "1590399"
  },
  {
    "text": "this is something we want to improve this is the diagram after the r",
    "start": "1590399",
    "end": "1596120"
  },
  {
    "text": "as you can see the um utilization for the node uh average has improved from 50",
    "start": "1596120",
    "end": "1602559"
  },
  {
    "text": "to 70% and uh during the rod we actually see what V just shows a clear house pod",
    "start": "1602559",
    "end": "1609880"
  },
  {
    "text": "being stopped and then be res scheduled again and to a more um packed nodes and",
    "start": "1609880",
    "end": "1617200"
  },
  {
    "text": "by doing so for while for the entire cluster some noes has been saved and the cluster Auto scaler clean them up so",
    "start": "1617200",
    "end": "1623960"
  },
  {
    "text": "that that is where the 10 to 15% cost savings we achieved with this",
    "start": "1623960",
    "end": "1630360"
  },
  {
    "text": "Ro all right so having done all those things for our production clusters now",
    "start": "1630360",
    "end": "1637880"
  },
  {
    "text": "time to look at the cost Savings in this diagram for our data warehouse software",
    "start": "1637880",
    "end": "1643960"
  },
  {
    "text": "the xaxis is the time and the y axis is the money that we pay for the easy to",
    "start": "1643960",
    "end": "1649600"
  },
  {
    "text": "computer machines you can see on the right hand side there is a very obvious real a deep that actually comes from our",
    "start": "1649600",
    "end": "1656960"
  },
  {
    "text": "road which is quite promising so with all this you may have",
    "start": "1656960",
    "end": "1664279"
  },
  {
    "text": "still one question left well this is very good but uh how does the",
    "start": "1664279",
    "end": "1669720"
  },
  {
    "text": "utilization change over time we understand that right after the rad when",
    "start": "1669720",
    "end": "1675360"
  },
  {
    "text": "you pack the cluster the utilization is very high but what if as what would happen then um",
    "start": "1675360",
    "end": "1682640"
  },
  {
    "text": "things change over time um you may remember we have service",
    "start": "1682640",
    "end": "1688799"
  },
  {
    "text": "uh being idled or stopped or terminated all those those process can create dis",
    "start": "1688799",
    "end": "1694720"
  },
  {
    "text": "schedule some parts from those and create some uh holes in our VMS",
    "start": "1694720",
    "end": "1700039"
  },
  {
    "text": "something like this which drop our utilization luckily um we have this",
    "start": "1700039",
    "end": "1707640"
  },
  {
    "text": "regular of upgrades for Cle housee software which essentially trying to update the",
    "start": "1707640",
    "end": "1713720"
  },
  {
    "text": "CLE housee server PS with a newer Docker image versions and uh that is is done in",
    "start": "1713720",
    "end": "1720320"
  },
  {
    "text": "a controlled Manner and uh gradually change one part at a time with part",
    "start": "1720320",
    "end": "1725600"
  },
  {
    "text": "disruption budget but overall the important thing is this basically move the parts to the most allocated ones and",
    "start": "1725600",
    "end": "1733039"
  },
  {
    "text": "achieve the same packing effect we just saw so this two brings utilization back",
    "start": "1733039",
    "end": "1739000"
  },
  {
    "text": "to a higher point we do this every once a while for the our",
    "start": "1739000",
    "end": "1745519"
  },
  {
    "text": "upgrades so um now I want to share a few findings and issues we discovered during",
    "start": "1745519",
    "end": "1751519"
  },
  {
    "text": "the R I will go through them one by one so first season",
    "start": "1751519",
    "end": "1757039"
  },
  {
    "text": "workos um we find that sometimes a event in node utilization even even if it's",
    "start": "1757039",
    "end": "1763760"
  },
  {
    "text": "very low the cluster Auto scaler still doesn't reclaim and scale down that notes why did that happen uh after some",
    "start": "1763760",
    "end": "1772600"
  },
  {
    "text": "uh investigation we found that noes actually run some of our system workflows such as AR CD controller EBS",
    "start": "1772600",
    "end": "1779840"
  },
  {
    "text": "CSI controller all those things and these workflows they have use of eeral",
    "start": "1779840",
    "end": "1785640"
  },
  {
    "text": "volumes like a local host pass or kind of storage on the note and because of",
    "start": "1785640",
    "end": "1791120"
  },
  {
    "text": "uses of that cluster autoscaler will not be conservative trying to not evict that",
    "start": "1791120",
    "end": "1796760"
  },
  {
    "text": "part and so so which prevents the nodes being reclaimed and saving the cost the",
    "start": "1796760",
    "end": "1801919"
  },
  {
    "text": "solution will is very simple because we know the the nature of this workflows uh it's okay to be disrupted and evicted we",
    "start": "1801919",
    "end": "1809000"
  },
  {
    "text": "just add the safe to evict to this system workl so the cluster Auto scaler can then uh reclaim those",
    "start": "1809000",
    "end": "1816080"
  },
  {
    "text": "notes on sched PLS U this is very interesting actually at some point we",
    "start": "1816080",
    "end": "1822240"
  },
  {
    "text": "notice that certain parts are just stuck at the pending State and and the cluster Auto scater",
    "start": "1822240",
    "end": "1830240"
  },
  {
    "text": "and most advocated scat redeployed have different opinion on these pending BS basically our most allocated",
    "start": "1830240",
    "end": "1838399"
  },
  {
    "text": "schedulers think oh there's no space for me to schedule this CLE housee PS it will be pending however cluster Auto",
    "start": "1838399",
    "end": "1845519"
  },
  {
    "text": "scaler also think I don't have to scale up because you can just evi that auto over provision AP with lower priority U",
    "start": "1845519",
    "end": "1853240"
  },
  {
    "text": "what V just mentioned for this preer and uh we want to figure out why this",
    "start": "1853240",
    "end": "1860159"
  },
  {
    "text": "happened so we actually took searched and found this uh text from kuet",
    "start": "1860159",
    "end": "1866440"
  },
  {
    "text": "document the summary is that when PA are created the scheduler will form a queue",
    "start": "1866440",
    "end": "1873039"
  },
  {
    "text": "and trying to schure the pending Parts we're also trying to find some victim Parts with lower priority to evict in",
    "start": "1873039",
    "end": "1880000"
  },
  {
    "text": "order to accommodate this part this does bring a Barr to us because you mention the schedule and remember our clear",
    "start": "1880000",
    "end": "1887600"
  },
  {
    "text": "house use the most allocated schedule right our over provisioner however is still leave as the default settings use",
    "start": "1887600",
    "end": "1894399"
  },
  {
    "text": "the default scheduler this create basically let two parts use different schedule and um we think that may create",
    "start": "1894399",
    "end": "1901519"
  },
  {
    "text": "kind of independent workflows and unable to be evicted for the over",
    "start": "1901519",
    "end": "1907880"
  },
  {
    "text": "provisioner so the solution is very simple then we just make the over provisioner also use the most allocated",
    "start": "1907880",
    "end": "1915080"
  },
  {
    "text": "schuer right after that we see the clear pod being scheduled all right co- start time um by",
    "start": "1915080",
    "end": "1922840"
  },
  {
    "text": "co-star time I mean when the clous Pod being um request from wake up from the",
    "start": "1922840",
    "end": "1928720"
  },
  {
    "text": "idling or getting started in the first time the time to take the part being ready and ready to serve the customer",
    "start": "1928720",
    "end": "1935320"
  },
  {
    "text": "request in theory as you can see now the cluster is more packed so then a new",
    "start": "1935320",
    "end": "1940600"
  },
  {
    "text": "posit coming is more likely to trigger a new ec2 machine beam provisioned and uh so C St time can increase because of the",
    "start": "1940600",
    "end": "1948000"
  },
  {
    "text": "to machine no machine be set up time and we measure that and confirm that did not",
    "start": "1948000",
    "end": "1954200"
  },
  {
    "text": "happen and we think that is because our over provisioner buffer gives some buffer space for eviction and allows the",
    "start": "1954200",
    "end": "1961360"
  },
  {
    "text": "um POS being scatter result provision in no time a new node the likelihood is",
    "start": "1961360",
    "end": "1968399"
  },
  {
    "text": "reduced finally um as mentioned uh gcps they have a native option called",
    "start": "1968399",
    "end": "1975399"
  },
  {
    "text": "optimized utilization profile at the CL cluster level you just enable this which achieve the same effect however for Asia",
    "start": "1975399",
    "end": "1983240"
  },
  {
    "text": "this uh is s is similar to the eks you cannot change the control plane for this",
    "start": "1983240",
    "end": "1988559"
  },
  {
    "text": "configuration have to do this yourself deploy a secondary most allocated",
    "start": "1988559",
    "end": "1993679"
  },
  {
    "text": "scheduler all right time for the summary so we are in a multi-end",
    "start": "1993679",
    "end": "2000799"
  },
  {
    "text": "kubernetes hosting environment doing a sauce product for our customers and our goal is to improve the resource",
    "start": "2000799",
    "end": "2007080"
  },
  {
    "text": "utilization um entire for the KU clusters to save some cost however while doing so we would",
    "start": "2007080",
    "end": "2014760"
  },
  {
    "text": "like to minimize the disruption to our customers we evalate a few approach and",
    "start": "2014760",
    "end": "2021080"
  },
  {
    "text": "uh KU we end up selecting kuet scheduler with most OC scoring strategy figured",
    "start": "2021080",
    "end": "2027760"
  },
  {
    "text": "out a few issues during the road and that save us 10 15 to 20% cost which is",
    "start": "2027760",
    "end": "2034440"
  },
  {
    "text": "great um some takeaway message if you want to do something similar we think these are helpful that um you can uh",
    "start": "2034440",
    "end": "2042840"
  },
  {
    "text": "consider the community scheduler scoring strategy to see if there is something that you can use the second one is to",
    "start": "2042840",
    "end": "2049520"
  },
  {
    "text": "use the Qs guaranteed and um so that if you want to avoid the noise neighbor",
    "start": "2049520",
    "end": "2055520"
  },
  {
    "text": "situation and um the third one is that take advantage of your software uh upgrade process so that you can uh use",
    "start": "2055520",
    "end": "2062440"
  },
  {
    "text": "the scheduling as a opportunity to improve your utilization the last one is overpro does uh give you some buffer",
    "start": "2062440",
    "end": "2070158"
  },
  {
    "text": "time uh when you have a more packed cluster all right that's pretty much",
    "start": "2070159",
    "end": "2075480"
  },
  {
    "text": "about it and um we also have a Blog to details about how this is done in our",
    "start": "2075480",
    "end": "2081919"
  },
  {
    "text": "technical blog come to check it out if you're interested our colleague Manish he will talk about how to use ktic SE",
    "start": "2081919",
    "end": "2089158"
  },
  {
    "text": "for set to autoscaling challenges here just in this room uh what a coincidence",
    "start": "2089159",
    "end": "2094760"
  },
  {
    "text": "uh tomorrow afternoon and last but not least we are also hiring if you are interested in",
    "start": "2094760",
    "end": "2100640"
  },
  {
    "text": "building a cloud offering for the database and the open source technology come let us know we are interest thank",
    "start": "2100640",
    "end": "2108910"
  },
  {
    "text": "[Applause]",
    "start": "2108910",
    "end": "2118089"
  },
  {
    "text": "you than thank you I have a quick about the practical way to do it you are just",
    "start": "2125560",
    "end": "2130720"
  },
  {
    "text": "using the schedular name spec inside pod or any more complex or something else",
    "start": "2130720",
    "end": "2137400"
  },
  {
    "text": "yeah you just uh uh specify the P schedule name in the P spec that should match whatever you specify for your",
    "start": "2137400",
    "end": "2144079"
  },
  {
    "text": "second scatter that should be enough and so you're putting that on your click house database pod and not on the system",
    "start": "2144079",
    "end": "2152359"
  },
  {
    "text": "pod and the rest of the Pod um sorry can you say that again you discussed the fact that you wanted to",
    "start": "2152359",
    "end": "2158520"
  },
  {
    "text": "keep the default schul for the other pod I guess you're talking about the system pod oh and why why is it my question is",
    "start": "2158520",
    "end": "2167359"
  },
  {
    "text": "more why is it interesting to keep the default schedule for the rest of the P correct yeah there there is some the",
    "start": "2167359",
    "end": "2173880"
  },
  {
    "text": "question is do why do we even need to have the default scheduler for I the the",
    "start": "2173880",
    "end": "2179960"
  },
  {
    "text": "answer is that you need to explicitly op in for our most allocated scheduler if you are deploying some third party event",
    "start": "2179960",
    "end": "2186400"
  },
  {
    "text": "uh deployments for example gra fin now or so since they their default values still need to work um and um I guess",
    "start": "2186400",
    "end": "2196920"
  },
  {
    "text": "um yeah I I guess it's just what works and their their footprint is not that huge uh anyway so we are just keep it uh",
    "start": "2196920",
    "end": "2204640"
  },
  {
    "text": "safe and uh yeah that's it yeah we haven't felt the need to use the schedule for the other type of worklow",
    "start": "2204640",
    "end": "2210720"
  },
  {
    "text": "that using the main cost savings that we that we realized and the highest number of PODS usage is for the click housee",
    "start": "2210720",
    "end": "2216520"
  },
  {
    "text": "server uh I would like to ask if this also",
    "start": "2216520",
    "end": "2222400"
  },
  {
    "text": "works in a multicluster environment does make a difference or really not um multi kues clusters yes um so we",
    "start": "2222400",
    "end": "2231720"
  },
  {
    "text": "haven't explored that uh exact scenario yeah um our CLE housee",
    "start": "2231720",
    "end": "2237920"
  },
  {
    "text": "workloads currently is not uh deployed in multic cluster fashion so every",
    "start": "2237920",
    "end": "2244119"
  },
  {
    "text": "scheduling decision is done within a cluster scope so that's not chese for us",
    "start": "2244119",
    "end": "2249280"
  },
  {
    "text": "yeah I think it would depend on how scheduling works in the multicluster scenario okay thank you very",
    "start": "2249280",
    "end": "2254920"
  },
  {
    "text": "much okay one one last and then it's over time yes um I wanted to clarify um about",
    "start": "2254920",
    "end": "2263480"
  },
  {
    "text": "the secondary scheduler was it a controller or did you just redeploy the cube scheduler yeah we just redeployed",
    "start": "2263480",
    "end": "2270839"
  },
  {
    "text": "the cube schedular uh like like you mentioned it's a deployment and in which like three ports run with the same Cube",
    "start": "2270839",
    "end": "2276240"
  },
  {
    "text": "schedular image and a custom scoring",
    "start": "2276240",
    "end": "2280400"
  },
  {
    "text": "policy uh yeah you can take this mic I uh I wanted to ask um you said you",
    "start": "2286440",
    "end": "2294280"
  },
  {
    "text": "wait uh until all your workloads or the uh click house workloads are rescheduled",
    "start": "2294280",
    "end": "2300040"
  },
  {
    "text": "naturally and do you plan or know um how you could enforce this um automatically",
    "start": "2300040",
    "end": "2307839"
  },
  {
    "text": "so you don't have to wait until new releases are done or something um do you have another controller for that or so",
    "start": "2307839",
    "end": "2314920"
  },
  {
    "text": "when you upgrate a pod spec uh all the pods that that are using that spec U like when you update the scheduler to",
    "start": "2314920",
    "end": "2320560"
  },
  {
    "text": "use the secondary one it will trigger a restart automatically for all of them in our case we do that in a more controlled",
    "start": "2320560",
    "end": "2325640"
  },
  {
    "text": "manner because we have the P disruption budgets we don't want to restart all of them but if you don't care about that you can just do it like by updating the",
    "start": "2325640",
    "end": "2331920"
  },
  {
    "text": "P spec okay but that sounds like you would to do uh it manually and it's not",
    "start": "2331920",
    "end": "2337800"
  },
  {
    "text": "automatically done somehow oh um so uh we are we we our relas so first of all",
    "start": "2337800",
    "end": "2344920"
  },
  {
    "text": "our release process is done automatically is managed by its own automation tool which is um and the",
    "start": "2344920",
    "end": "2351560"
  },
  {
    "text": "second question and second thing is that it's not just release automation for example Auto scaling or node drain or",
    "start": "2351560",
    "end": "2357440"
  },
  {
    "text": "whatever reasons that customer change configuration that requires restarts that we all restart this pod and pack to",
    "start": "2357440",
    "end": "2364280"
  },
  {
    "text": "another more pack nodes which take advantage of this effect yeah yeah but we automated it like after",
    "start": "2364280",
    "end": "2369960"
  },
  {
    "text": "the Pod spec was done in our code base we used the release process to automatically update it thanks thank you",
    "start": "2369960",
    "end": "2375960"
  },
  {
    "text": "okay thank you everyone",
    "start": "2375960",
    "end": "2383960"
  }
]
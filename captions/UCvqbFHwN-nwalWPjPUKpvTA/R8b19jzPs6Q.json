[
  {
    "start": "0",
    "end": "74000"
  },
  {
    "text": "um I'd like to thank everyone who's joining us up your slides popped up mm-hmm all right I like to thank",
    "start": "30",
    "end": "6210"
  },
  {
    "text": "everyone who is joining us today welcome to today's CN CF webinar scalable ml workflows with advanced data management",
    "start": "6210",
    "end": "12179"
  },
  {
    "text": "on cue flow I'm Jorge Castro community manager at VMware and a cloud native ambassador I'll be moderating today's",
    "start": "12179",
    "end": "18660"
  },
  {
    "text": "webinar we would like to welcome our presenter today Vangelis cookus CTO and founder at a rick to-- a few",
    "start": "18660",
    "end": "26490"
  },
  {
    "text": "housekeeping items before we get started during the webinar you will not be able to talk as an attendee there's a Q&A box",
    "start": "26490",
    "end": "32668"
  },
  {
    "text": "at the bottom of your screen there in the zumasys Q&A you can click on that and submit your questions feel free to",
    "start": "32669",
    "end": "38190"
  },
  {
    "text": "drop your questions in there throughout the the webinar and we'll get to as many as we can at the end",
    "start": "38190",
    "end": "44219"
  },
  {
    "text": "this is an official webinar of the CN CF and it's such a subject to the CN CF code of conduct please do not add",
    "start": "44219",
    "end": "50160"
  },
  {
    "text": "anything to the chat or questions that will be in violation of that code of conduct basically please be respectful",
    "start": "50160",
    "end": "55530"
  },
  {
    "text": "to all your fellow participants and presenters and I hope we're all ready so when that will hand it over to Vangelis",
    "start": "55530",
    "end": "62070"
  },
  {
    "text": "to kick off today's presentation take it away thank you George thank you these",
    "start": "62070",
    "end": "67350"
  },
  {
    "text": "presentations about scalable and mail workflows with advanced data management on coop flow what does this mean what's",
    "start": "67350",
    "end": "75689"
  },
  {
    "start": "74000",
    "end": "164000"
  },
  {
    "text": "the problem we're gonna be talking about setting up an all-stock a full and no",
    "start": "75689",
    "end": "81180"
  },
  {
    "text": "pipeline is very hard I'm doing it in production is even harder and then if",
    "start": "81180",
    "end": "89610"
  },
  {
    "text": "you wanna do multi cloud then this is when the difficulty skyrockets and by",
    "start": "89610",
    "end": "97500"
  },
  {
    "text": "multi-cloud we also means working on your laptop working on a local",
    "start": "97500",
    "end": "103649"
  },
  {
    "text": "deployment if someone is working on tram in an on-prem kubernetes cluster and on",
    "start": "103649",
    "end": "109439"
  },
  {
    "text": "the cloud then it's a multi cloud deployment so it seems a communist",
    "start": "109439",
    "end": "117180"
  },
  {
    "text": "conception is that to build on a new product you need to focus on ml code you",
    "start": "117180",
    "end": "122759"
  },
  {
    "text": "need to write your code write your model trainings and then you're done unless there's some little details around",
    "start": "122759",
    "end": "130110"
  },
  {
    "text": "actually writing ml code that someone who take care of but the reality is that",
    "start": "130110",
    "end": "136700"
  },
  {
    "text": "it's a DevOps problem configuration data collection verification managing",
    "start": "136700",
    "end": "144570"
  },
  {
    "text": "resources managing processes serving introduction monitoring these are much",
    "start": "144570",
    "end": "151530"
  },
  {
    "text": "more important and take up a much bigger percentage of time compared to actually",
    "start": "151530",
    "end": "157050"
  },
  {
    "text": "writing ml so we need a platform for ml and this is where coop flow comes in so",
    "start": "157050",
    "end": "165060"
  },
  {
    "start": "164000",
    "end": "213000"
  },
  {
    "text": "why could flow coop flow is an open source project started by Google it's an",
    "start": "165060",
    "end": "171000"
  },
  {
    "text": "end-to-end solution for building ml our platforms and now workflows on",
    "start": "171000",
    "end": "176940"
  },
  {
    "text": "kubernetes it aims to containerize workloads",
    "start": "176940",
    "end": "182160"
  },
  {
    "text": "and allowed users to experiment and explore with state-of-the-art AI it",
    "start": "182160",
    "end": "187710"
  },
  {
    "text": "focuses on easy onboarding we have contributed our code and the packaging",
    "start": "187710",
    "end": "194280"
  },
  {
    "text": "for coop flow called mini coop flume in kf2 is the process of onboarding new users I'm gonna be talking more about this in",
    "start": "194280",
    "end": "200580"
  },
  {
    "text": "this presentation and coop flu itself has outstanding community and industry support it's a vibrant community lots of",
    "start": "200580",
    "end": "207270"
  },
  {
    "text": "comments lots of new features the code is involved is evolving very fast so",
    "start": "207270",
    "end": "213540"
  },
  {
    "start": "213000",
    "end": "269000"
  },
  {
    "text": "what is meaning could flow or this mini KF it's a packaging contributed by us a",
    "start": "213540",
    "end": "219450"
  },
  {
    "text": "victim to the coop for community dot packages mini cube could flow and rock",
    "start": "219450",
    "end": "227010"
  },
  {
    "text": "our data management platform in a single VM image so you can spin it up very",
    "start": "227010",
    "end": "234300"
  },
  {
    "text": "quickly on a single node presumably a laptop or a very big desktop machine you",
    "start": "234300",
    "end": "240090"
  },
  {
    "text": "may have it does require quite a lot of memory because come flow has lots of components it features the latest",
    "start": "240090",
    "end": "245850"
  },
  {
    "text": "console version 0.6 points X currently zero point six point two it's the we",
    "start": "245850",
    "end": "252420"
  },
  {
    "text": "think fastest and easiest way to spin up a full coop flow deployment and start playing within minutes so this",
    "start": "252420",
    "end": "259739"
  },
  {
    "text": "presentation is going to be about deploying mini coop flow and then running a well known example on top of",
    "start": "259739",
    "end": "265680"
  },
  {
    "text": "it with advanced data management that comes from rock so how do you install mini",
    "start": "265680",
    "end": "271090"
  },
  {
    "text": "coop flow there's a previous webinar we did so you can see the recording there's",
    "start": "271090",
    "end": "276370"
  },
  {
    "text": "an installation video there's the documentation but the too long didn't read version is you use vagrant to",
    "start": "276370",
    "end": "283720"
  },
  {
    "text": "initialize a new virtual machine you start the virtual machine and this is it",
    "start": "283720",
    "end": "289000"
  },
  {
    "text": "and this is what I'll be doing now so I'll be switching desktops I will be",
    "start": "289000",
    "end": "299520"
  },
  {
    "text": "spinning up the virtual machine the",
    "start": "299520",
    "end": "308380"
  },
  {
    "text": "machine is up I go to this URL and I'm",
    "start": "308380",
    "end": "318730"
  },
  {
    "text": "shown the mini cook flow landing page so I start navigating this very nice script",
    "start": "318730",
    "end": "327750"
  },
  {
    "text": "except you and what happens now is there's a short provisioning phase but",
    "start": "327750",
    "end": "336970"
  },
  {
    "text": "essentially manages the virtual machine provisions mini cook as your kubernetes",
    "start": "336970",
    "end": "344230"
  },
  {
    "text": "substrate all could flow components sets the map rock so that you can have",
    "start": "344230",
    "end": "351100"
  },
  {
    "text": "storage and manage the storage alongside coop flow and eventually when",
    "start": "351100",
    "end": "356950"
  },
  {
    "text": "the whole platform is up it gives you easy to use links so you can access the",
    "start": "356950",
    "end": "361960"
  },
  {
    "text": "coop flow dashboard and rock this will take a few minutes it takes in the order of five to ten minutes depending on the",
    "start": "361960",
    "end": "368740"
  },
  {
    "text": "speed of your machine and your CPU utilization so switch back to the presentation and come back and see what",
    "start": "368740",
    "end": "375730"
  },
  {
    "text": "happened so this is essentially the process of starting mini coop flow you",
    "start": "375730",
    "end": "380740"
  },
  {
    "start": "376000",
    "end": "543000"
  },
  {
    "text": "initialize a virtual machine then you start this is it let's focus on what",
    "start": "380740",
    "end": "386920"
  },
  {
    "text": "could flow does this is a page from a well-known Google paper on the effects",
    "start": "386920",
    "end": "393030"
  },
  {
    "text": "so the effects focuses on building and a mail workflow we",
    "start": "393030",
    "end": "399650"
  },
  {
    "text": "in steps Batum Alex's transformation validation training the model tuning the",
    "start": "399650",
    "end": "407630"
  },
  {
    "text": "training of the model with hyper parameters evaluating the model and then should be serving it",
    "start": "407630",
    "end": "413740"
  },
  {
    "text": "so coop flow comes with these libraries",
    "start": "413740",
    "end": "419210"
  },
  {
    "text": "he containerized components so you can use them as they are and it also comes",
    "start": "419210",
    "end": "425810"
  },
  {
    "text": "with a hyper parameter tuner containerized that can run multiple",
    "start": "425810",
    "end": "432320"
  },
  {
    "text": "trials ok then you need an integrated front-end for job management monitoring",
    "start": "432320",
    "end": "439820"
  },
  {
    "text": "debugging data scientists like notebooks coop flow comes with a dashboard and a",
    "start": "439820",
    "end": "447889"
  },
  {
    "text": "notebook based UI jupiter notebooks it's no but manager is actually part of what",
    "start": "447889",
    "end": "454160"
  },
  {
    "text": "we have contributed to crystal then you need a shared configuration and job",
    "start": "454160",
    "end": "459169"
  },
  {
    "text": "orchestration framework coop flow has taken ma a hard dependency on kubernetes",
    "start": "459169",
    "end": "465470"
  },
  {
    "text": "parties so kubernetes is your shared job orchestration network what this means is",
    "start": "465470",
    "end": "472430"
  },
  {
    "text": "that all notebook circles and OU training components and the hyper",
    "start": "472430",
    "end": "479150"
  },
  {
    "text": "parameter tuner and whatever you do run the odds-on kubernetes and finally you",
    "start": "479150",
    "end": "486289"
  },
  {
    "text": "need a way to actually store your data control access to your data and use it",
    "start": "486289",
    "end": "493520"
  },
  {
    "text": "in my producible way which means when you have actually run a training",
    "start": "493520",
    "end": "499340"
  },
  {
    "text": "pipeline have a record of having run this pipeline and able to go back in",
    "start": "499340",
    "end": "505430"
  },
  {
    "text": "time we run the pipeline when you have a model that's the output of the pipeline",
    "start": "505430",
    "end": "511940"
  },
  {
    "text": "go back in time and see exactly what you used as input to train the model to do this that's where we come in so we",
    "start": "511940",
    "end": "519830"
  },
  {
    "text": "integrate ROC our data management component with kubernetes and coop flow to give you an end-to-end platform for",
    "start": "519830",
    "end": "528290"
  },
  {
    "text": "producible machine learning this is what we'll be talking about today if we go back to deployment we",
    "start": "528290",
    "end": "537000"
  },
  {
    "text": "deploying the database waiting for it to come up it's progressing so moving on",
    "start": "537000",
    "end": "544760"
  },
  {
    "start": "543000",
    "end": "708000"
  },
  {
    "text": "what exactly does rock do when you run on a male workflow different steps of",
    "start": "544760",
    "end": "553020"
  },
  {
    "text": "the workflow usually happen at different places this is the ideal scenario data",
    "start": "553020",
    "end": "558750"
  },
  {
    "text": "scientists like to experiment on their laptops on-prem locally but for training",
    "start": "558750",
    "end": "565020"
  },
  {
    "text": "you usually need to move to a bigger deployment with GPUs for example the",
    "start": "565020",
    "end": "571560"
  },
  {
    "text": "Google cloud or you can have spin up GPI enabled instances and production",
    "start": "571560",
    "end": "577860"
  },
  {
    "text": "actually serving the model happens elsewhere sometimes it happens at",
    "start": "577860",
    "end": "584610"
  },
  {
    "text": "multiple locations it happens in self-driving cars it happens at IOT sensors it happens at",
    "start": "584610",
    "end": "592800"
  },
  {
    "text": "many different places so how do you move the process from experimentation to",
    "start": "592800",
    "end": "598920"
  },
  {
    "text": "training to production and keep it reproducible first part we contributed",
    "start": "598920",
    "end": "605310"
  },
  {
    "text": "code to coop flow to make it data we're in general this means we extend coop",
    "start": "605310",
    "end": "611760"
  },
  {
    "text": "flow components so they use persistent volume claims provided by kubernetes so",
    "start": "611760",
    "end": "617730"
  },
  {
    "text": "they store the data in volumes they vendor agnostic volumes provided ocular",
    "start": "617730",
    "end": "623940"
  },
  {
    "text": "notice our software integrates via a mechanism called the container storage",
    "start": "623940",
    "end": "630480"
  },
  {
    "text": "interface CSI with kubernetes to provide implementations of PVCs of persistent",
    "start": "630480",
    "end": "638700"
  },
  {
    "text": "volumes so when could flow stores its data this data is managed by rock and then rock",
    "start": "638700",
    "end": "646490"
  },
  {
    "text": "forms a peer-to-peer network among go locations and allows essentially to keep",
    "start": "646490",
    "end": "654480"
  },
  {
    "text": "your to start from your laptop keep your data locally but",
    "start": "654480",
    "end": "660000"
  },
  {
    "text": "when the time comes for training take a snapshot of this data move it transparently to the training",
    "start": "660000",
    "end": "667649"
  },
  {
    "text": "location run training training would produce a model take the model and",
    "start": "667649",
    "end": "673259"
  },
  {
    "text": "synchronize it will load with all the serving locations and because this is snapshot based everything is immutable",
    "start": "673259",
    "end": "681019"
  },
  {
    "text": "you find similarities with get for it there's a live demo later on so when you",
    "start": "681019",
    "end": "687509"
  },
  {
    "text": "have a model essentially know the exact input data set that led to this model",
    "start": "687509",
    "end": "693899"
  },
  {
    "text": "being trade in a specific way if something goes wrong with the model you can go back in time see the input to",
    "start": "693899",
    "end": "701970"
  },
  {
    "text": "each individual step of the pipeline and experiment with it and explore it so",
    "start": "701970",
    "end": "709199"
  },
  {
    "start": "708000",
    "end": "760000"
  },
  {
    "text": "what's new in the latest mini coop flow based on the latest couplet version it",
    "start": "709199",
    "end": "714209"
  },
  {
    "text": "uses coop flow zero point six point two it enables multi user authentication so",
    "start": "714209",
    "end": "719610"
  },
  {
    "text": "you can have multiple users spinning up their notebooks in an isolated way",
    "start": "719610",
    "end": "726120"
  },
  {
    "text": "so there's authorization for notebooks as well if it's integrated with Roc then",
    "start": "726120",
    "end": "731279"
  },
  {
    "text": "you can do nearest and 10-years restore of snapshots so when you have a notebook server you can snap shut it shut it down",
    "start": "731279",
    "end": "737790"
  },
  {
    "text": "then come back one or two days or one on two weeks or one two years later and spin it up almost instantly we have",
    "start": "737790",
    "end": "745829"
  },
  {
    "text": "significantly improved the time to perform the snapshot and we also have the ability to snapshot every step of a",
    "start": "745829",
    "end": "753029"
  },
  {
    "text": "running pipeline exactly for being able to go back in time and see the input to each pipeline step this is the landing",
    "start": "753029",
    "end": "761790"
  },
  {
    "start": "760000",
    "end": "813000"
  },
  {
    "text": "page you saw earlier earlier that's how you control mini coop flow why do that",
    "start": "761790",
    "end": "769589"
  },
  {
    "text": "and let's see how the deployment progresses so provisioning I switch back",
    "start": "769589",
    "end": "776220"
  },
  {
    "text": "to the minikin flow desktop provisioning of coop flow is almost there we are now",
    "start": "776220",
    "end": "781230"
  },
  {
    "text": "waiting for coops of resources to come up rock is already up when coop flow is",
    "start": "781230",
    "end": "788009"
  },
  {
    "text": "up and running this button will also turn green and then I'll be able to connect so what I did is I started a virtual",
    "start": "788009",
    "end": "795990"
  },
  {
    "text": "machine initialize provisioning and I'm",
    "start": "795990",
    "end": "801779"
  },
  {
    "text": "waiting for the 30 time pads of coops all to come up coop flow does have a lot",
    "start": "801779",
    "end": "806850"
  },
  {
    "text": "of components ok so let's give it some time starting up why did we build mini coop flow",
    "start": "806850",
    "end": "816170"
  },
  {
    "start": "813000",
    "end": "860000"
  },
  {
    "text": "because people need an easy way for onboarding and people like to experiment",
    "start": "816170",
    "end": "822600"
  },
  {
    "text": "locally so by packaging it for a single",
    "start": "822600",
    "end": "827730"
  },
  {
    "text": "node deployment inside the virtual machine we give a very easy way to spin up good flow and start experimenting",
    "start": "827730",
    "end": "834180"
  },
  {
    "text": "with it but because it's still kubernetes and it still coop so you have the exact same user experience so you",
    "start": "834180",
    "end": "841350"
  },
  {
    "text": "can use the same API as you can submit the same kubernetes resources you can use notebooks exactly you should on a",
    "start": "841350",
    "end": "846870"
  },
  {
    "text": "cloud provider and when you're ready because it's kubernetes plus coop flow you can move everything to a bigger",
    "start": "846870",
    "end": "854910"
  },
  {
    "text": "deployment where for example you'll train without having to rewrite things",
    "start": "854910",
    "end": "860209"
  },
  {
    "start": "860000",
    "end": "883000"
  },
  {
    "text": "so our goal was a unified user experience if you're on the cloud if",
    "start": "860209",
    "end": "866370"
  },
  {
    "text": "you're on Prem if you're on your laptop you run kubernetes you deploy code flow on top you deploy rock for managing your",
    "start": "866370",
    "end": "873529"
  },
  {
    "text": "volumes your storage and this gives you the ability to use the same API and find",
    "start": "873529",
    "end": "880199"
  },
  {
    "text": "your data where you need them the adoption has been going on quite well",
    "start": "880199",
    "end": "886139"
  },
  {
    "start": "883000",
    "end": "906000"
  },
  {
    "text": "since we first started this around 7th March it's reached around 4500 downloads",
    "start": "886139",
    "end": "894470"
  },
  {
    "text": "please try it out let us know how it goes give us feedback on the coop flow",
    "start": "894470",
    "end": "899970"
  },
  {
    "text": "slack initialize the machine start",
    "start": "899970",
    "end": "905069"
  },
  {
    "text": "machine this is it the requirements are kind of shifting it means at least till",
    "start": "905069",
    "end": "910350"
  },
  {
    "start": "906000",
    "end": "937000"
  },
  {
    "text": "gigabytes of RAM to get the virtual machine up and running coop so is quite resource hungry you need a bit more if",
    "start": "910350",
    "end": "917399"
  },
  {
    "text": "you want to run ml training depending on the size of your data sets and because",
    "start": "917399",
    "end": "924050"
  },
  {
    "text": "it's virtual machine-based it will run on Linux Mac OS or Windows in the same way it uses vagrant for managing the",
    "start": "924050",
    "end": "932510"
  },
  {
    "text": "virtual machine and VirtualBox for actually running the virtual machine so",
    "start": "932510",
    "end": "938510"
  },
  {
    "text": "let's move I like how this synchronized so provisioning is complete coop flows",
    "start": "938510",
    "end": "946130"
  },
  {
    "text": "up rock is up I can connect to it I'm",
    "start": "946130",
    "end": "951430"
  },
  {
    "start": "950000",
    "end": "999000"
  },
  {
    "text": "logging into coop flow using a standard IP address accessible only by the local",
    "start": "951430",
    "end": "957950"
  },
  {
    "text": "host so I can log into it this is the authentication part I mentioned and this",
    "start": "957950",
    "end": "967610"
  },
  {
    "text": "is the crucial dashboard so I'm logged in in my own namespace could flow - user",
    "start": "967610",
    "end": "974149"
  },
  {
    "text": "I'm the owner of this namespace Mina cool flow has a single user could flow in general in enterprise deployment",
    "start": "974149",
    "end": "980209"
  },
  {
    "text": "supports more than one users I can access my pipelines my notebook servers",
    "start": "980209",
    "end": "986300"
  },
  {
    "text": "chapter notebooks hyper parameter tuning metadata and rock as the snapshot store",
    "start": "986300",
    "end": "992890"
  },
  {
    "text": "so what are we going to use mini control for we're going to use it to run a live",
    "start": "992890",
    "end": "1002350"
  },
  {
    "start": "999000",
    "end": "1082000"
  },
  {
    "text": "demo of the Chicago taxicab example this is a tf-x example unplan on our laptop",
    "start": "1002350",
    "end": "1010050"
  },
  {
    "text": "with Mini Cooper flow what exactly is the Chicago taxicab example the city of",
    "start": "1010050",
    "end": "1017680"
  },
  {
    "text": "Chicago produced a dataset of more than 100 million trips you can download the",
    "start": "1017680",
    "end": "1023950"
  },
  {
    "text": "original data set here this data set recorded a few quite a few details about",
    "start": "1023950",
    "end": "1033270"
  },
  {
    "text": "each individual trip including how much money the trip cost when it started",
    "start": "1033270",
    "end": "1040800"
  },
  {
    "text": "where it started where it ended how long",
    "start": "1040800",
    "end": "1046150"
  },
  {
    "text": "it was what means of payment the rider used and whether there was anything and",
    "start": "1046150",
    "end": "1053410"
  },
  {
    "text": "the result of this example is a trained model that can predict whether a random trip",
    "start": "1053410",
    "end": "1061970"
  },
  {
    "text": "will result in a tit that's more or less 20% of the fair so we get this data set",
    "start": "1061970",
    "end": "1069530"
  },
  {
    "text": "we feed it to a model and build a classifier that can decide whether a",
    "start": "1069530",
    "end": "1074720"
  },
  {
    "text": "random trip produces a tip that's more or less than T percent this is going to be the workflow that we'll be demoing",
    "start": "1074720",
    "end": "1081850"
  },
  {
    "text": "okay this is a summary of the input features essentially start and end",
    "start": "1081850",
    "end": "1090350"
  },
  {
    "text": "location means of payment and the amount paid and what is our demo going to be we",
    "start": "1090350",
    "end": "1100730"
  },
  {
    "text": "start from a notebook will use coop flow to create this notebook will create a",
    "start": "1100730",
    "end": "1106250"
  },
  {
    "text": "new volume as storage to hold our data we'll bring in our data set from an",
    "start": "1106250",
    "end": "1113000"
  },
  {
    "text": "external data source we could download the full data set from the city of",
    "start": "1113000",
    "end": "1118400"
  },
  {
    "text": "Chicago side all will download a subset of this data set so we can run the",
    "start": "1118400",
    "end": "1123800"
  },
  {
    "text": "example at completion from github once we've done that we will take this is",
    "start": "1123800",
    "end": "1131780"
  },
  {
    "text": "ingestion of data we'll take a snapshot of our notebook volume why do that so we",
    "start": "1131780",
    "end": "1139610"
  },
  {
    "start": "1133000",
    "end": "1175000"
  },
  {
    "text": "have a data community so we know exactly where we started from so we can rerun",
    "start": "1139610",
    "end": "1146270"
  },
  {
    "text": "the pipeline with exactly the same into beta so we know that whatever the result",
    "start": "1146270",
    "end": "1152480"
  },
  {
    "text": "of the pipeline is this is where it started from at this point we can continue working with this volume we can",
    "start": "1152480",
    "end": "1160280"
  },
  {
    "text": "continue exploring things in the notebook and the pipeline is not going to be affected because the pipeline will",
    "start": "1160280",
    "end": "1165590"
  },
  {
    "text": "run from this snapshot will run from a clone of the snapshot this is going to",
    "start": "1165590",
    "end": "1171500"
  },
  {
    "text": "be the starting point for the pipeline so then we will run the pipeline will",
    "start": "1171500",
    "end": "1177590"
  },
  {
    "start": "1175000",
    "end": "1187000"
  },
  {
    "text": "run a series of pre-processing training analysis and eventually serving steps",
    "start": "1177590",
    "end": "1184580"
  },
  {
    "text": "and we will also snapshot",
    "start": "1184580",
    "end": "1190610"
  },
  {
    "text": "a step in the pipeline the final step so",
    "start": "1190610",
    "end": "1196100"
  },
  {
    "text": "we can keep it and explore it by cloning it sometime in the future into a new",
    "start": "1196100",
    "end": "1202400"
  },
  {
    "text": "notebook so this shows that we can take any individual step of the pipeline",
    "start": "1202400",
    "end": "1207490"
  },
  {
    "text": "snapshot it and explore it again using notebooks and this process can start all",
    "start": "1207490",
    "end": "1212990"
  },
  {
    "text": "over again I explore the data make some fixes ingests new data adjust my",
    "start": "1212990",
    "end": "1218810"
  },
  {
    "text": "algorithm adjust parameters snapshot again move the new pipeline start over I'm going to have something",
    "start": "1218810",
    "end": "1225620"
  },
  {
    "text": "that works or gonna have something that doesn't work I can go back in time and see exactly what I started from",
    "start": "1225620",
    "end": "1230860"
  },
  {
    "text": "essentially we're using rock as good for our data so this is what we're gonna do",
    "start": "1230860",
    "end": "1239000"
  },
  {
    "start": "1237000",
    "end": "1324000"
  },
  {
    "text": "step by step we're going to be creating a new notebook I'm adding the new data volume to it so",
    "start": "1239000",
    "end": "1246410"
  },
  {
    "text": "we move to the crypto dashboard notebook servers you can also I forgot to show",
    "start": "1246410",
    "end": "1258980"
  },
  {
    "text": "you login to rock as well",
    "start": "1258980",
    "end": "1264880"
  },
  {
    "text": "okay I'm gonna be creating a new notebook server it's gonna be named",
    "start": "1267100",
    "end": "1276670"
  },
  {
    "text": "webinar 1 it's going to have a small",
    "start": "1276670",
    "end": "1284060"
  },
  {
    "text": "volume where I'll be storing my libraries and my code I'll also be",
    "start": "1284060",
    "end": "1293000"
  },
  {
    "text": "adding a new volume it's gonna be the data volume I'll make it a 10 gigabyte",
    "start": "1293000",
    "end": "1300200"
  },
  {
    "text": "volume I'll also use a custom image we",
    "start": "1300200",
    "end": "1305420"
  },
  {
    "text": "have just created and for this I'll consult my cheat sheet this is the",
    "start": "1305420",
    "end": "1314360"
  },
  {
    "text": "custom image I'm going to do",
    "start": "1314360",
    "end": "1317679"
  },
  {
    "text": "and launch the notebook so at this point",
    "start": "1319650",
    "end": "1325330"
  },
  {
    "start": "1324000",
    "end": "1525000"
  },
  {
    "text": "I'm launching a notebook a notebook server using Jupiter notebooks from a",
    "start": "1325330",
    "end": "1331180"
  },
  {
    "text": "custom image it might take some time oh okay this was fast to actually",
    "start": "1331180",
    "end": "1336970"
  },
  {
    "text": "download the custom image the notebook is up it's running as a part in sizeable",
    "start": "1336970",
    "end": "1343660"
  },
  {
    "text": "matters if I just could cuddle would be able to see the pod running and I can connect it it's got a few secret volumes",
    "start": "1343660",
    "end": "1353880"
  },
  {
    "text": "my data and network space I'm connecting",
    "start": "1353880",
    "end": "1359590"
  },
  {
    "text": "to it I'll refresh to give it some time to actually come up it's complaining",
    "start": "1359590",
    "end": "1372270"
  },
  {
    "text": "it's finishing yeah it shouldn't be",
    "start": "1374520",
    "end": "1386260"
  },
  {
    "text": "happening so give it some time three steals the service managed to realize",
    "start": "1386260",
    "end": "1392560"
  },
  {
    "text": "that the notebook is up or I'll debug it for a while that's the body",
    "start": "1392560",
    "end": "1402720"
  },
  {
    "text": "I'm going to my namespace looking at my",
    "start": "1424470",
    "end": "1431320"
  },
  {
    "text": "pods okay invalid demons name if the image is",
    "start": "1431320",
    "end": "1438940"
  },
  {
    "text": "invalid then it shouldn't be showing us running so this may actually be a bug",
    "start": "1438940",
    "end": "1446730"
  },
  {
    "text": "much shown okay okay yep I think I",
    "start": "1456600",
    "end": "1467080"
  },
  {
    "text": "messed up I messed up for including this and I think it's going to work if I omit",
    "start": "1467080",
    "end": "1474880"
  },
  {
    "text": "the HTTP part but it shouldn't be gone it shouldn't be showing us random so",
    "start": "1474880",
    "end": "1481929"
  },
  {
    "text": "this is definitely about children I will remove this goodbye webinar server and",
    "start": "1481929",
    "end": "1495970"
  },
  {
    "text": "start again so webinar to it is I'm",
    "start": "1495970",
    "end": "1503230"
  },
  {
    "text": "gonna be using this custom image and making sure to actually meet the HTTP",
    "start": "1503230",
    "end": "1510490"
  },
  {
    "text": "part okay again I'll have a workspace",
    "start": "1510490",
    "end": "1519539"
  },
  {
    "text": "data volume",
    "start": "1519539",
    "end": "1523230"
  },
  {
    "start": "1525000",
    "end": "1628000"
  },
  {
    "text": "and we do have a question if you want to address that while this is fine of course sure Swapna asks what and why do",
    "start": "1525650",
    "end": "1532130"
  },
  {
    "text": "we need to take a snapshot in the pipeline it's not mandatory to take a",
    "start": "1532130",
    "end": "1539059"
  },
  {
    "text": "snapshot in the pipeline but it's best to take a snapshot so that you don't",
    "start": "1539059",
    "end": "1545960"
  },
  {
    "text": "have the notebook operation messing up what the pipeline sees so if it was just",
    "start": "1545960",
    "end": "1551779"
  },
  {
    "text": "a shared directory and you had the execution that's a very good question by",
    "start": "1551779",
    "end": "1557059"
  },
  {
    "text": "the way and had the execution of your pipeline actually messing up the same volume the same storage that the",
    "start": "1557059",
    "end": "1562970"
  },
  {
    "text": "notebook or notebooks were seeing then you'd have your work or your colleagues",
    "start": "1562970",
    "end": "1568730"
  },
  {
    "text": "work messing up the result of the pipeline so you can't just use an NFS share because it's like working the same",
    "start": "1568730",
    "end": "1576020"
  },
  {
    "text": "get directory if you have more than one person right what happens is you can't be sure about",
    "start": "1576020",
    "end": "1582080"
  },
  {
    "text": "the result of the execution the result will be essentially be random as P+ are changing the input data while working",
    "start": "1582080",
    "end": "1590149"
  },
  {
    "text": "with git you can say I started from biscuit commit so I can reproduce the",
    "start": "1590149",
    "end": "1596929"
  },
  {
    "text": "bug I can reproduce the result no matter what because the community is immutable it never changes it's the same thing",
    "start": "1596929",
    "end": "1603500"
  },
  {
    "text": "with a snapshot if you've started from a snapshot no matter what your college or",
    "start": "1603500",
    "end": "1609260"
  },
  {
    "text": "you do in a notebook it won't affect the execution of a pipeline so this is why",
    "start": "1609260",
    "end": "1615830"
  },
  {
    "text": "we focus on working with snapshots for having the producing one now I hope this",
    "start": "1615830",
    "end": "1623210"
  },
  {
    "text": "answers the question so the pod is shown as running but let's not believe it",
    "start": "1623210",
    "end": "1629929"
  },
  {
    "start": "1628000",
    "end": "1642000"
  },
  {
    "text": "let's actually go see the pods the party",
    "start": "1629929",
    "end": "1636799"
  },
  {
    "text": "is running ok I'm have enough string bag to fix so the notebook is up I can",
    "start": "1636799",
    "end": "1644539"
  },
  {
    "start": "1642000",
    "end": "1944000"
  },
  {
    "text": "connect to it it's a nice trip to lab and I can close these extra tabs so",
    "start": "1644539",
    "end": "1654610"
  },
  {
    "text": "is my data folder this is where I'll be storing the input data I have a terminal",
    "start": "1654610",
    "end": "1662350"
  },
  {
    "text": "I can increase its size I'm for the",
    "start": "1662350",
    "end": "1678280"
  },
  {
    "text": "purposes of this demo what I'm gonna do is use my cheat sheet again to actually",
    "start": "1678280",
    "end": "1685150"
  },
  {
    "text": "download so for this I'm notebook upon",
    "start": "1685150",
    "end": "1693910"
  },
  {
    "text": "years so I won't have to type two main commands so this is a notebook and what",
    "start": "1693910",
    "end": "1703750"
  },
  {
    "text": "it does is it has the commands to run",
    "start": "1703750",
    "end": "1710429"
  },
  {
    "text": "individual steps embedded in cells so what I've done so far is I've created a",
    "start": "1710429",
    "end": "1717760"
  },
  {
    "text": "notebook and added a data volume I'll now ingest data from an external",
    "start": "1717760",
    "end": "1724510"
  },
  {
    "text": "source so ingesting the data will be",
    "start": "1724510",
    "end": "1731679"
  },
  {
    "text": "first downloading the actual source of",
    "start": "1731679",
    "end": "1737470"
  },
  {
    "text": "the of the pipeline this is the pipeline we will be running later on for training I'll show you the code then under",
    "start": "1737470",
    "end": "1746799"
  },
  {
    "text": "storage and the stored here then we'll bring in the actual subset of the data",
    "start": "1746799",
    "end": "1752890"
  },
  {
    "text": "set to use for training so I'm cloning",
    "start": "1752890",
    "end": "1760540"
  },
  {
    "text": "the git repository and then copying the",
    "start": "1760540",
    "end": "1766960"
  },
  {
    "text": "subset of the data I need into my data directory this is essentially simulating",
    "start": "1766960",
    "end": "1773820"
  },
  {
    "text": "ingest the data from an outside data Lake HDFS snowflake as three the city of",
    "start": "1773820",
    "end": "1782890"
  },
  {
    "text": "Chicago sighs wherever I find my data assembling it all into my storage and then I have a",
    "start": "1782890",
    "end": "1790140"
  },
  {
    "text": "reproducible snapshot of this storage so I can start changing so I copied the",
    "start": "1790140",
    "end": "1798340"
  },
  {
    "text": "data into my data for me here I can",
    "start": "1798340",
    "end": "1805630"
  },
  {
    "text": "actually see the data that's the data and what we'll do now is move back the",
    "start": "1805630",
    "end": "1813490"
  },
  {
    "text": "presentation I have ingested the data I",
    "start": "1813490",
    "end": "1819460"
  },
  {
    "text": "will compile the Cupra pipeline I'll show you the code and compile it this is",
    "start": "1819460",
    "end": "1825670"
  },
  {
    "text": "essentially a description of the steps that are going to take place and then I'm going to snap shut the notebook so",
    "start": "1825670",
    "end": "1833190"
  },
  {
    "text": "compiling that I plan create a parable",
    "start": "1833190",
    "end": "1841560"
  },
  {
    "text": "we're using a newer version of coops of pipelines which produces a few warnings and let's take a look at the pipeline",
    "start": "1841560",
    "end": "1848740"
  },
  {
    "text": "itself so this is the pipeline specification the training pipeline that",
    "start": "1848740",
    "end": "1853750"
  },
  {
    "text": "we're going to use in a domain-specific language specified by coop flow pipe",
    "start": "1853750",
    "end": "1860950"
  },
  {
    "text": "lines let me increase the font size of it okay",
    "start": "1860950",
    "end": "1866370"
  },
  {
    "text": "so this defines individual steps of the pipeline as components containerized",
    "start": "1868170",
    "end": "1877510"
  },
  {
    "text": "components mentioning specific container images taking arguments and producing",
    "start": "1877510",
    "end": "1883720"
  },
  {
    "text": "outputs that live in volume so by snapshot in individual volumes we can",
    "start": "1883720",
    "end": "1890920"
  },
  {
    "text": "snapshot the state of the pipeline and weeks that at each step and why is this important because the most difficult",
    "start": "1890920",
    "end": "1898840"
  },
  {
    "text": "thing when running a pipeline is essentially having inside object at its execution what happens at",
    "start": "1898840",
    "end": "1905680"
  },
  {
    "text": "the pipeline fails what happens if a step fails if I'm in a notebook I can experiment written if a five-man step",
    "start": "1905680",
    "end": "1912520"
  },
  {
    "text": "fails how can I go see what happened resist ways",
    "start": "1912520",
    "end": "1917720"
  },
  {
    "text": "take a snapshot of its input clone it in a new notebook I'm gonna see exactly what happened I can actually run the",
    "start": "1917720",
    "end": "1926330"
  },
  {
    "text": "exact command that he'll be used to produce the data and see what fails",
    "start": "1926330",
    "end": "1933220"
  },
  {
    "text": "so at this point I have my input data here I have compiled my pipeline so I",
    "start": "1933220",
    "end": "1941690"
  },
  {
    "text": "can now snapshot my notebook for this I need to rock there's a bucket here bad",
    "start": "1941690",
    "end": "1948530"
  },
  {
    "start": "1944000",
    "end": "2104000"
  },
  {
    "text": "casing is where you store your files you have snapshots I can create a moon let's",
    "start": "1948530",
    "end": "1955040"
  },
  {
    "text": "call it you know this is gonna be where I'll store my snapshot I'll take a",
    "start": "1955040",
    "end": "1963440"
  },
  {
    "text": "snapshot of my jupiter lab it's gonna be",
    "start": "1963440",
    "end": "1968990"
  },
  {
    "text": "a full snapshot of the whole lab I could take a snapshot of a single dataset a single volume",
    "start": "1968990",
    "end": "1975460"
  },
  {
    "text": "I'll snapshot this lab this notebook",
    "start": "1975460",
    "end": "1980870"
  },
  {
    "text": "server I've named mine Mike made initial commit and described it as another chest",
    "start": "1980870",
    "end": "1989150"
  },
  {
    "text": "and jested data compiled pipeline this will be the input through the pipeline",
    "start": "1989150",
    "end": "1996580"
  },
  {
    "text": "run under snap ship it so what happens",
    "start": "1996580",
    "end": "2002230"
  },
  {
    "text": "is a new a synchronous task starts this",
    "start": "2002230",
    "end": "2007660"
  },
  {
    "text": "is a group of type of tasks actually one task is the snapshot the data the other",
    "start": "2007660",
    "end": "2014740"
  },
  {
    "text": "task is the snapshot the workspace why do we snapshot both volumes both disks",
    "start": "2014740",
    "end": "2020920"
  },
  {
    "text": "so we can be reproducible you have seen multiple times that the result of",
    "start": "2020920",
    "end": "2027160"
  },
  {
    "text": "execution is not just a function linked data it's a function of the lab edges as well first birds suddenly appear with such",
    "start": "2027160",
    "end": "2034870"
  },
  {
    "text": "levels as behaviors desired or undesired that only appearance elaborate so to be",
    "start": "2034870",
    "end": "2041050"
  },
  {
    "text": "reproducible able to allow our colleague to see exactly what you did you need to snapshot both your home",
    "start": "2041050",
    "end": "2047740"
  },
  {
    "text": "folder your workspace where you store your libraries but you pick install and your data and",
    "start": "2047740",
    "end": "2053658"
  },
  {
    "text": "that's what we do here in sq seconds so I now have a snapshot that contains snapshots of both disks she combined",
    "start": "2053659",
    "end": "2060440"
  },
  {
    "text": "come in a group she if I go here this is my snapshot less than a minute ago it",
    "start": "2060440",
    "end": "2067220"
  },
  {
    "text": "has a snapshot of the data and my workspace and it has let me go back here",
    "start": "2067220",
    "end": "2075230"
  },
  {
    "text": "I can see more information about it it",
    "start": "2075230",
    "end": "2084020"
  },
  {
    "text": "has all the information I gave when actually created the commit so I",
    "start": "2084020",
    "end": "2093340"
  },
  {
    "text": "snapshot it my notebook and created a new snapshot at this point I'm ready to",
    "start": "2095409",
    "end": "2100610"
  },
  {
    "text": "create a new pipeline so what do I do I go back to the node I'd go back a good",
    "start": "2100610",
    "end": "2107060"
  },
  {
    "start": "2104000",
    "end": "2204000"
  },
  {
    "text": "pipe lines actually this is central dashboard pipelines I have a few sample",
    "start": "2107060",
    "end": "2115550"
  },
  {
    "text": "pipelines I need to upload the compiled pipeline created here to upload this I",
    "start": "2115550",
    "end": "2123880"
  },
  {
    "text": "first downloaded to my box and then",
    "start": "2123880",
    "end": "2133880"
  },
  {
    "text": "upload it to pipelines this is kind of a cumbersome step and we can also automate it from within the notebook itself and",
    "start": "2133880",
    "end": "2140390"
  },
  {
    "text": "uploaded via a command line interface so I'm now moving pipelines upload pipeline",
    "start": "2140390",
    "end": "2148580"
  },
  {
    "text": "choose a file downloads today's file and",
    "start": "2148580",
    "end": "2156890"
  },
  {
    "text": "I collect the webinar pipeline upload",
    "start": "2156890",
    "end": "2162760"
  },
  {
    "text": "this is it so now we'll be creating a run of this pipeline from the pipeline these are all",
    "start": "2162760",
    "end": "2170450"
  },
  {
    "text": "the pipeline steps first step is to create a volume why do we need to create a volume so we can have a clone of the",
    "start": "2170450",
    "end": "2177800"
  },
  {
    "text": "snapshot we start with and every other step depends on this volume because",
    "start": "2177800",
    "end": "2183740"
  },
  {
    "text": "every other step manages this volume and creates files in this folder then we'll validate the data",
    "start": "2183740",
    "end": "2190130"
  },
  {
    "text": "pre-process training deploy predict analyze and we have a final snap chat",
    "start": "2190130",
    "end": "2196339"
  },
  {
    "text": "volume step so we can actually show you how the cycle ends and we can start over",
    "start": "2196339",
    "end": "2201410"
  },
  {
    "text": "with a new notebook so I'm at this point I'm about to create a run create a run",
    "start": "2201410",
    "end": "2211930"
  },
  {
    "start": "2204000",
    "end": "2368000"
  },
  {
    "text": "run name is going to be I don't know maybe now run one description or",
    "start": "2211930",
    "end": "2218599"
  },
  {
    "text": "description I'm gonna use default",
    "start": "2218599",
    "end": "2224569"
  },
  {
    "text": "experiment it's going to be a one-off run and now we need to specify parameters to this pipeline one of the",
    "start": "2224569",
    "end": "2232940"
  },
  {
    "text": "parameters is a rockier which is what is the input data where they start from",
    "start": "2232940",
    "end": "2238599"
  },
  {
    "text": "let's choose this pipeline will start",
    "start": "2238599",
    "end": "2247420"
  },
  {
    "text": "from this dataset this pipeline will start from my input data the data I just",
    "start": "2247420",
    "end": "2255349"
  },
  {
    "text": "snapshot it four minutes ago okay and where is the output data are going to go",
    "start": "2255349",
    "end": "2262549"
  },
  {
    "text": "who is the snapshot going to go let's have it here in a new file named no",
    "start": "2262549",
    "end": "2275049"
  },
  {
    "text": "webinar snapshot okay I now start the",
    "start": "2275049",
    "end": "2284029"
  },
  {
    "text": "pipeline so what happens is a new run is",
    "start": "2284029",
    "end": "2289549"
  },
  {
    "text": "created this is now the run time graph will be seeing the steps exactly as they",
    "start": "2289549",
    "end": "2297109"
  },
  {
    "text": "happen and this will Auto refresh first step is to create a volume so we now",
    "start": "2297109",
    "end": "2303499"
  },
  {
    "text": "have a volume that is independent from the volume scene from the notebook so I",
    "start": "2303499",
    "end": "2309979"
  },
  {
    "text": "can use my terminal go to datum massage data for example now create a",
    "start": "2309979",
    "end": "2317980"
  },
  {
    "text": "new file this new file will not be part of the pipeline the fact that I'm now",
    "start": "2317980",
    "end": "2325750"
  },
  {
    "text": "changing the data does not have an impact to the execution on the execution",
    "start": "2325750",
    "end": "2332140"
  },
  {
    "text": "of the pipeline because the pipeline runs from a clone of this data now this answer is we print somebody's question",
    "start": "2332140",
    "end": "2342359"
  },
  {
    "text": "exam so let's touch this table this will be not up here at the end okay where",
    "start": "2342359",
    "end": "2353680"
  },
  {
    "text": "were we the pipeline is running the validation step is completely processing run so let's take a look at the steps",
    "start": "2353680",
    "end": "2360059"
  },
  {
    "text": "eventually the pipeline will snapshot a step into a new snapshot and we'll clone",
    "start": "2360059",
    "end": "2365829"
  },
  {
    "text": "it if we have the time so the steps are validating the data using TF DV this is",
    "start": "2365829",
    "end": "2373270"
  },
  {
    "start": "2368000",
    "end": "2578000"
  },
  {
    "text": "at the effects library this step has already completed it runs from a clone",
    "start": "2373270",
    "end": "2378520"
  },
  {
    "text": "of the notebook data then we transform the data in a pre-processing step we",
    "start": "2378520",
    "end": "2385809"
  },
  {
    "text": "transform both the training part of the data set and the evaluation part of the data set the input that we have kept so",
    "start": "2385809",
    "end": "2392859"
  },
  {
    "text": "we can then evaluate the model then comes training which will lead to a",
    "start": "2392859",
    "end": "2398740"
  },
  {
    "text": "train model which will also be stored inside the volume that sees this",
    "start": "2398740",
    "end": "2404710"
  },
  {
    "text": "progression the processing is done we now run training then comes the TFM a",
    "start": "2404710",
    "end": "2415690"
  },
  {
    "text": "library which is going to analyze the model and produce artifacts we'll be",
    "start": "2415690",
    "end": "2420789"
  },
  {
    "text": "seeing these artifacts in the snapshot of the pipeline that's going to be produced eventually prediction and",
    "start": "2420789",
    "end": "2428819"
  },
  {
    "text": "serving so training is happening and",
    "start": "2428819",
    "end": "2435599"
  },
  {
    "text": "when training is done we'll have prediction serving and we'll end up with",
    "start": "2435599",
    "end": "2441400"
  },
  {
    "text": "a snapshot of me using subsequent steps so while we're doing this we extend coop",
    "start": "2441400",
    "end": "2449650"
  },
  {
    "text": "flow so each component can store data in a vendor agnostic way in persistent",
    "start": "2449650",
    "end": "2455260"
  },
  {
    "text": "volumes in file systems that are mounted we have extended first we created the",
    "start": "2455260",
    "end": "2463720"
  },
  {
    "text": "jupiter hub based spawners with persistent volumes for 0.4 we replaced",
    "start": "2463720",
    "end": "2469089"
  },
  {
    "text": "it with an eighth dimension of the native node manager that you saw in 0.5",
    "start": "2469089",
    "end": "2474510"
  },
  {
    "text": "and we have also expanded the pipeline's domain-specific language so it can access persistent problems and snapshots",
    "start": "2474510",
    "end": "2481800"
  },
  {
    "text": "if you look at the pipeline I can actually show this this is the pipeline",
    "start": "2481800",
    "end": "2489130"
  },
  {
    "text": "right we specify that we want the output to be this born in the volume is let me",
    "start": "2489130",
    "end": "2499059"
  },
  {
    "text": "find the problem",
    "start": "2499059",
    "end": "2501930"
  },
  {
    "text": "every step is losing the volume this is the volume so we created extensions to",
    "start": "2512080",
    "end": "2518660"
  },
  {
    "text": "the pipeline's domain-specific language so we can create volumes as clones of",
    "start": "2518660",
    "end": "2524330"
  },
  {
    "text": "existing snapshots and then we can use these volumes for each individual step",
    "start": "2524330",
    "end": "2529820"
  },
  {
    "text": "so each individual step uses this volume and eventually will also produce a",
    "start": "2529820",
    "end": "2537670"
  },
  {
    "text": "snapshot to define this as well so we",
    "start": "2537670",
    "end": "2544670"
  },
  {
    "text": "have extended the DSL so you can also produce snapshots of this volume with",
    "start": "2544670",
    "end": "2551510"
  },
  {
    "text": "dependencies so when the final steps of the pipeline are done a snapshot of this",
    "start": "2551510",
    "end": "2558650"
  },
  {
    "text": "volume will be produced a snapshot volume in the location specified so to",
    "start": "2558650",
    "end": "2566510"
  },
  {
    "text": "move back to the pipeline training is still happening this is the most",
    "start": "2566510",
    "end": "2572930"
  },
  {
    "text": "expensive part of the process let's give some more time while he's rock for your",
    "start": "2572930",
    "end": "2582320"
  },
  {
    "start": "2578000",
    "end": "2671000"
  },
  {
    "text": "pipeline step one starts from a notebook you snapshot it you start small snapshot",
    "start": "2582320",
    "end": "2588920"
  },
  {
    "text": "your cloning you make some changes in snapshot it step two starts from a clone of step one",
    "start": "2588920",
    "end": "2595310"
  },
  {
    "text": "make some changes it's not shut it again step three and so on if this breaks you",
    "start": "2595310",
    "end": "2603440"
  },
  {
    "text": "can take this snapshot examine it in a notebook and start over",
    "start": "2603440",
    "end": "2608920"
  },
  {
    "text": "hybrid pipelines you have a pipeline",
    "start": "2608920",
    "end": "2613990"
  },
  {
    "text": "that you want to run in two locations you want to run a few steps in location one then you want to run serving or",
    "start": "2613990",
    "end": "2620720"
  },
  {
    "text": "training in location two step one two and three run in location one this",
    "start": "2620720",
    "end": "2626359"
  },
  {
    "text": "snapshot step three you move the snapshot using rock to another location",
    "start": "2626359",
    "end": "2631580"
  },
  {
    "text": "and at this point you can run the second half of the pipeline on location two so",
    "start": "2631580",
    "end": "2637910"
  },
  {
    "text": "this is a hybrid pipeline it's essentially a metal pipe line of one step running invocation one another",
    "start": "2637910",
    "end": "2644370"
  },
  {
    "text": "step running location to unlock bridging the gaps by moving data from one",
    "start": "2644370",
    "end": "2649980"
  },
  {
    "text": "location to another if you want to reproduce a pipeline you start from the",
    "start": "2649980",
    "end": "2657360"
  },
  {
    "text": "same input data rerun the pipeline in another location and we end up with the same results Rock is in between syncing",
    "start": "2657360",
    "end": "2666120"
  },
  {
    "text": "data and state among on locations back",
    "start": "2666120",
    "end": "2672120"
  },
  {
    "text": "to the pipeline it's almost done no it is done the",
    "start": "2672120",
    "end": "2677520"
  },
  {
    "text": "snapshot step is done everything is completed successfully and moved to rock",
    "start": "2677520",
    "end": "2683990"
  },
  {
    "text": "this is my snapshot created less than a minute ago so the very last step and",
    "start": "2683990",
    "end": "2690600"
  },
  {
    "text": "then let's move to questions is I start from this snapshot so I go back to my",
    "start": "2690600",
    "end": "2703770"
  },
  {
    "text": "notebook servers create a new server",
    "start": "2703770",
    "end": "2710240"
  },
  {
    "text": "let's call it webinar 3 and this time",
    "start": "2710660",
    "end": "2719820"
  },
  {
    "text": "I'm going to add a volume that's going to be existing and we'll be using the",
    "start": "2719820",
    "end": "2731250"
  },
  {
    "text": "snapshot I just created I'm gonna call it data again don't some notebooks so",
    "start": "2731250",
    "end": "2743180"
  },
  {
    "text": "this notebook will now start from the snapshot that was created in the Python",
    "start": "2743780",
    "end": "2749040"
  },
  {
    "text": "and I'll be able to explore the output data of the pipeline in a notebook",
    "start": "2749040",
    "end": "2755960"
  },
  {
    "text": "let's give it some more time the hunter sins is essentially cloning the output",
    "start": "2762160",
    "end": "2769479"
  },
  {
    "text": "data yes George Sarris just for money you have four questions and chat ok let's",
    "start": "2769479",
    "end": "2776950"
  },
  {
    "text": "then let me connect to the notebook and I split it up a bit go to data see",
    "start": "2776950",
    "end": "2783910"
  },
  {
    "text": "there's actually extra files being created so this is nothing but data this is the data after the execution of the",
    "start": "2783910",
    "end": "2789579"
  },
  {
    "text": "pipeline move to analysis output display",
    "start": "2789579",
    "end": "2795900"
  },
  {
    "text": "this is the result should appear doesn't",
    "start": "2795900",
    "end": "2805089"
  },
  {
    "text": "something may be broken here or let me refresh anyway this is the result of the analysis I cannot show it right now but",
    "start": "2805089",
    "end": "2812619"
  },
  {
    "text": "I can see that this the data that was produced by the pipeline so this mode",
    "start": "2812619",
    "end": "2818079"
  },
  {
    "start": "2816000",
    "end": "3147000"
  },
  {
    "text": "let's see let's move to questions and then I'll concede sure so John asks how difficult is it to share snapshots in",
    "start": "2818079",
    "end": "2824890"
  },
  {
    "text": "between users ok that's a good question we didn't cover it in this presentation",
    "start": "2824890",
    "end": "2830160"
  },
  {
    "text": "we've made it as easy as possible using rock you essentially publish a link to a",
    "start": "2830160",
    "end": "2836529"
  },
  {
    "text": "published bucket to another service we call the registry and then any other user can subscribe to this link and",
    "start": "2836529",
    "end": "2842619"
  },
  {
    "text": "follow your changes as they're happening what we mean by this is you go to your",
    "start": "2842619",
    "end": "2851469"
  },
  {
    "text": "buckets you publish them the dissention",
    "start": "2851469",
    "end": "2857589"
  },
  {
    "text": "gives you a link you can share with others and others can then create a",
    "start": "2857589",
    "end": "2863670"
  },
  {
    "text": "subscribed bucket and follow your changes so whenever your pipeline runs engine creates a new snapshot or",
    "start": "2863670",
    "end": "2870069"
  },
  {
    "text": "wherever or whenever you create a new snapshot of your pipeline or of your",
    "start": "2870069",
    "end": "2875469"
  },
  {
    "text": "notebook and another follower sees it so this is how we share snapshots across locations ok next question can hyper-v",
    "start": "2875469",
    "end": "2885849"
  },
  {
    "text": "be used on Windows instead of VirtualBox many cube does support hyper-v that's a",
    "start": "2885849",
    "end": "2891700"
  },
  {
    "text": "good question right now mini coup flow does not support Purvi we are thinking about using it we",
    "start": "2891700",
    "end": "2899640"
  },
  {
    "text": "are focusing our efforts to moving coop flow so it can run on public clouds as well so yes hyper-v is an option but we're",
    "start": "2899640",
    "end": "2908220"
  },
  {
    "text": "focusing on efforts to giving mini coop flow as a packaged product on a public",
    "start": "2908220",
    "end": "2913230"
  },
  {
    "text": "cloud so you can run welcome to worry about your lamp ram or a few limitations",
    "start": "2913230",
    "end": "2918240"
  },
  {
    "text": "but this is feasible yes okay Joan asks how Enterprise ready is cube flow / rock",
    "start": "2918240",
    "end": "2924510"
  },
  {
    "text": "stack in regards to identity management and being able to do audits that's a",
    "start": "2924510",
    "end": "2930960"
  },
  {
    "text": "good question it's low has authentication authorization is not there yet it is",
    "start": "2930960",
    "end": "2939330"
  },
  {
    "text": "there for notebooks it's not there yet for pipelines for hybrid parameter tuning for metadata handling we are",
    "start": "2939330",
    "end": "2946890"
  },
  {
    "text": "contributing actively to multi-user pipelines right now and we hope to have it as part of the next arkansas version",
    "start": "2946890",
    "end": "2952920"
  },
  {
    "text": "please come in touch and come flow slack with us and we can talk more and maybe even also test on initial implementation",
    "start": "2952920",
    "end": "2960780"
  },
  {
    "text": "that we presented today at the community meeting that's what we doing right now to be enterprise ready with full support",
    "start": "2960780",
    "end": "2967410"
  },
  {
    "text": "for authorization there is quite a few things to be done but we're moving towards this is the volume getting",
    "start": "2967410",
    "end": "2975630"
  },
  {
    "text": "created is a type is of type cinder or some shared storage so that all stages",
    "start": "2975630",
    "end": "2980940"
  },
  {
    "text": "can access it that's a good question Rock manages whatever primary storage",
    "start": "2980940",
    "end": "2988830"
  },
  {
    "text": "she provided with this demo was using local disks so there is no cinder or",
    "start": "2988830",
    "end": "2995490"
  },
  {
    "text": "another API underneath we just gave local disks on each individual node to",
    "start": "2995490",
    "end": "3000920"
  },
  {
    "text": "be managed by rock rock cars individual volumes on set disks and you can be as",
    "start": "3000920",
    "end": "3007220"
  },
  {
    "text": "fast as possible and have super long latency because of this you just work over local disks you can work over local",
    "start": "3007220",
    "end": "3012500"
  },
  {
    "text": "nvme that's what we are targeting and you can still big stand node failure because you",
    "start": "3012500",
    "end": "3018260"
  },
  {
    "text": "can be snapshot in your notebooks once every five minutes for example the snapshot operation as you saw is very light and we snapshot tini this means we",
    "start": "3018260",
    "end": "3026870"
  },
  {
    "text": "have in kernel we have an internal mechanism but trucks whatever it blocks you have touched and",
    "start": "3026870",
    "end": "3033980"
  },
  {
    "text": "only copies these to produce a new snapshot I hope this answers the",
    "start": "3033980",
    "end": "3039740"
  },
  {
    "text": "question please go up yep some nice instead of copying a snapshot into a notebook volume with it would it work if",
    "start": "3039740",
    "end": "3046519"
  },
  {
    "text": "notebook itself is mounted to an object storage we shared folders etc I'm not",
    "start": "3046519",
    "end": "3053329"
  },
  {
    "text": "sure I understand these questions I think you mean what will happen if I mounted my object storage as a volume in",
    "start": "3053329",
    "end": "3060079"
  },
  {
    "text": "the notebook that's what I understand that maybe I could use a user space mounting mechanism to access history for",
    "start": "3060079",
    "end": "3067130"
  },
  {
    "text": "example a mystery bucket as a volume in my notebook this has two main issues one",
    "start": "3067130",
    "end": "3073009"
  },
  {
    "text": "is you lose reproducibility because while you're it's like using a shared",
    "start": "3073009",
    "end": "3078499"
  },
  {
    "text": "NFS share while you're making changes in the bucket you don't know what pipeline executions are actually using the bucket",
    "start": "3078499",
    "end": "3084529"
  },
  {
    "text": "right now to read data from it so you cannot if you want to perform a and I",
    "start": "3084529",
    "end": "3089869"
  },
  {
    "text": "don't know an exploration and run on experimental transform on the data you can't do it because you don't know who",
    "start": "3089869",
    "end": "3096140"
  },
  {
    "text": "else is using the data at this point in time you actually have to copy all of the data to make sure you're working",
    "start": "3096140",
    "end": "3101450"
  },
  {
    "text": "with a project code but then this becomes too expensive so this is one thing and the other thing is if you",
    "start": "3101450",
    "end": "3107660"
  },
  {
    "text": "compare your performance and latencies when working with a local volume compared to working with s3 mounted over",
    "start": "3107660",
    "end": "3114440"
  },
  {
    "text": "a notebook performance difference is abysmal the latency is skywalker",
    "start": "3114440",
    "end": "3119989"
  },
  {
    "text": "we have measured in the order of 800 megabytes a second bandwidth and",
    "start": "3119989",
    "end": "3126489"
  },
  {
    "text": "microsecond latencies because we work with local MDM ease with an internal data path",
    "start": "3126489",
    "end": "3131599"
  },
  {
    "text": "this is orders of magnitude faster than going to an object store every time okay",
    "start": "3131599",
    "end": "3138019"
  },
  {
    "text": "which Numa said now what is the storage class used how about an Prem okay that's a good question the storage",
    "start": "3138019",
    "end": "3145430"
  },
  {
    "text": "class used these hours rock-rock exposes",
    "start": "3145430",
    "end": "3153109"
  },
  {
    "start": "3147000",
    "end": "3342000"
  },
  {
    "text": "itself as a storage class and we provision volumes using de storage class",
    "start": "3153109",
    "end": "3158299"
  },
  {
    "text": "and rock underneath carves up volumes as you four on creme Rock is deployed as a",
    "start": "3158299",
    "end": "3166280"
  },
  {
    "text": "demon set it has its own operator you spin up a custom CR a custom my resource",
    "start": "3166280",
    "end": "3172800"
  },
  {
    "text": "I think that's we've done well Rock cluster yep",
    "start": "3172800",
    "end": "3179990"
  },
  {
    "text": "how about we change yep this is it this is a deployment of the rock cluster CRD",
    "start": "3179990",
    "end": "3186990"
  },
  {
    "text": "in the rock namespace and our operator which is this will take care of spinning",
    "start": "3186990",
    "end": "3202440"
  },
  {
    "text": "up whatever pads are needed we spin up a diamond set on each individual note so for unplanned deployments would spin up",
    "start": "3202440",
    "end": "3208980"
  },
  {
    "text": "a pod running drug on each individual node and this would manage your storage okay we're running out of time I'm set",
    "start": "3208980",
    "end": "3216870"
  },
  {
    "text": "you're in there this do you support uh encrypted data at rest since you just happen to be in there we can knock this",
    "start": "3216870",
    "end": "3222420"
  },
  {
    "text": "question out yes yes yes definitely the data path we",
    "start": "3222420",
    "end": "3228270"
  },
  {
    "text": "can set it up so it does include state address yes okay two more questions how long how are large datasets trained as",
    "start": "3228270",
    "end": "3234870"
  },
  {
    "text": "the scheduler work like a spark scheduler I'm not sure I understand this",
    "start": "3234870",
    "end": "3240120"
  },
  {
    "text": "question we we've tested this with a few hundred gigabytes of data we just carve up local disk and then we've made lots",
    "start": "3240120",
    "end": "3246090"
  },
  {
    "text": "of optimizations to make sure we only touch the changed box so when you have a",
    "start": "3246090",
    "end": "3251850"
  },
  {
    "text": "very big data set and only change a few parts of it you can still snap shut it very efficiently okay can this solution",
    "start": "3251850",
    "end": "3259830"
  },
  {
    "text": "work with spark hive and or presto I assume if yes could you please elaborate and that is our last question that we",
    "start": "3259830",
    "end": "3266010"
  },
  {
    "text": "take for it I assume it's it can as long",
    "start": "3266010",
    "end": "3271440"
  },
  {
    "text": "as you can mount a persistent volume as you as long as you can access a file system from said jobs then can be used",
    "start": "3271440",
    "end": "3278040"
  },
  {
    "text": "with these solutions but please come in touch with us in the cook flow slack and",
    "start": "3278040",
    "end": "3283320"
  },
  {
    "text": "then we can talk more about it because we're interested in various cases please join the coop flow slack there's a link",
    "start": "3283320",
    "end": "3288810"
  },
  {
    "text": "to join the coop so slack on coop flowed org please follow the link I have actually have a slide about this",
    "start": "3288810",
    "end": "3295160"
  },
  {
    "text": "so this is how your on kfp on trend with medical flow on drug this is a nice",
    "start": "3295160",
    "end": "3301130"
  },
  {
    "text": "image this is what we have for the future GPU support and support for dying",
    "start": "3301130",
    "end": "3306289"
  },
  {
    "text": "in public clouds please try it out join us on the coops of slack and let us know",
    "start": "3306289",
    "end": "3311329"
  },
  {
    "text": "how it goes awesome thanks Frank gallows for a great presentation thank you we are done with",
    "start": "3311329",
    "end": "3318769"
  },
  {
    "text": "the questions that and that's all that quite that questions that we have time for today sorry and thanks for joining",
    "start": "3318769",
    "end": "3324619"
  },
  {
    "text": "us the webinar recording and slides will be online later on today and we're looking forward to seeing you at a",
    "start": "3324619",
    "end": "3330619"
  },
  {
    "text": "future CN CF webinar and with that thank you everybody and have a nice day thank you goodbye",
    "start": "3330619",
    "end": "3339160"
  }
]
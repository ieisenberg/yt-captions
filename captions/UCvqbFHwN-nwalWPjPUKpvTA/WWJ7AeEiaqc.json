[
  {
    "start": "0",
    "end": "75000"
  },
  {
    "text": "good evening everyone and thanks for",
    "start": "60",
    "end": "1620"
  },
  {
    "text": "coming so today in this session we are",
    "start": "1620",
    "end": "6569"
  },
  {
    "text": "mostly gonna demonstrate how you can",
    "start": "6569",
    "end": "9570"
  },
  {
    "text": "implement your own communities shed hero",
    "start": "9570",
    "end": "11700"
  },
  {
    "text": "and show a proof of concept network of a",
    "start": "11700",
    "end": "15240"
  },
  {
    "text": "Shatila which we call it a shed net my",
    "start": "15240",
    "end": "18690"
  },
  {
    "text": "name is Akash Ganga and I'm a software",
    "start": "18690",
    "end": "20369"
  },
  {
    "text": "engineer and Ohana and I am a software",
    "start": "20369",
    "end": "28410"
  },
  {
    "text": "engineer instead of VMware yeah so so",
    "start": "28410",
    "end": "33780"
  },
  {
    "text": "during the next 30 minutes this is how",
    "start": "33780",
    "end": "35730"
  },
  {
    "text": "we have structure to talk",
    "start": "35730",
    "end": "37550"
  },
  {
    "text": "suppose we are going to talk about the",
    "start": "37550",
    "end": "40260"
  },
  {
    "text": "default scheduler in communities they're",
    "start": "40260",
    "end": "42660"
  },
  {
    "text": "going to show how it works and like what",
    "start": "42660",
    "end": "47460"
  },
  {
    "text": "I its drawbacks and how you can improve",
    "start": "47460",
    "end": "49230"
  },
  {
    "text": "upon it the after we would discuss a",
    "start": "49230",
    "end": "53340"
  },
  {
    "text": "network of a shed yellow which we called",
    "start": "53340",
    "end": "55320"
  },
  {
    "text": "shed net and we talked a little bit",
    "start": "55320",
    "end": "59579"
  },
  {
    "text": "about ovn since that's the component",
    "start": "59579",
    "end": "62160"
  },
  {
    "text": "that we use for networking to provide",
    "start": "62160",
    "end": "66119"
  },
  {
    "text": "networking to the Kuban in these",
    "start": "66119",
    "end": "67560"
  },
  {
    "text": "containers then we will talk about the",
    "start": "67560",
    "end": "69960"
  },
  {
    "text": "set up topology followed by a demo and",
    "start": "69960",
    "end": "71909"
  },
  {
    "text": "then we discuss the results so let's",
    "start": "71909",
    "end": "75840"
  },
  {
    "start": "75000",
    "end": "108000"
  },
  {
    "text": "start off so I guess most of you would",
    "start": "75840",
    "end": "79049"
  },
  {
    "text": "be already familiar with the scheduler",
    "start": "79049",
    "end": "81030"
  },
  {
    "text": "component in communities so scheduler is",
    "start": "81030",
    "end": "85049"
  },
  {
    "text": "a component which makes decisions on",
    "start": "85049",
    "end": "87840"
  },
  {
    "text": "where pods in your communities cluster",
    "start": "87840",
    "end": "91350"
  },
  {
    "text": "should be placed so so by default like",
    "start": "91350",
    "end": "98700"
  },
  {
    "text": "communities provides a default Sharia",
    "start": "98700",
    "end": "100680"
  },
  {
    "text": "law and to to actually see how it works",
    "start": "100680",
    "end": "104970"
  },
  {
    "text": "let's just take a scenario example so",
    "start": "104970",
    "end": "108360"
  },
  {
    "start": "108000",
    "end": "290000"
  },
  {
    "text": "let's say we have five container host or",
    "start": "108360",
    "end": "113070"
  },
  {
    "text": "minions in our cluster and as soon as",
    "start": "113070",
    "end": "117570"
  },
  {
    "text": "the user schedules creates a pot spec in",
    "start": "117570",
    "end": "120840"
  },
  {
    "text": "the communities cluster the Sharia law",
    "start": "120840",
    "end": "123000"
  },
  {
    "text": "keeps on checking with the API so if",
    "start": "123000",
    "end": "125219"
  },
  {
    "text": "there is a pod that's unscheduled and by",
    "start": "125219",
    "end": "127979"
  },
  {
    "text": "that what it means is like if there is a",
    "start": "127979",
    "end": "130560"
  },
  {
    "text": "pot spec resource in the API server",
    "start": "130560",
    "end": "133050"
  },
  {
    "text": "for which the node name is not yet",
    "start": "133050",
    "end": "134580"
  },
  {
    "text": "specified at that point of time the",
    "start": "134580",
    "end": "137400"
  },
  {
    "text": "Shatila kicks in and it it works on",
    "start": "137400",
    "end": "140940"
  },
  {
    "text": "finding a continue goes for that",
    "start": "140940",
    "end": "142830"
  },
  {
    "text": "particular pod so let's assume like the",
    "start": "142830",
    "end": "146490"
  },
  {
    "text": "the user shed you the cluster and the",
    "start": "146490",
    "end": "148320"
  },
  {
    "text": "shillelagh kick then and like there were",
    "start": "148320",
    "end": "150060"
  },
  {
    "text": "five nodes in our cluster so the process",
    "start": "150060",
    "end": "153600"
  },
  {
    "text": "so is like it can be considered as a two",
    "start": "153600",
    "end": "157470"
  },
  {
    "text": "step process so in the force process for",
    "start": "157470",
    "end": "161010"
  },
  {
    "text": "step what the shed Euler does it passes",
    "start": "161010",
    "end": "164180"
  },
  {
    "text": "applies certain predicate functions to",
    "start": "164180",
    "end": "167700"
  },
  {
    "text": "all the nodes in the cluster so and",
    "start": "167700",
    "end": "170040"
  },
  {
    "text": "these predicate functions are basically",
    "start": "170040",
    "end": "172080"
  },
  {
    "text": "used as a filtering mechanism as to",
    "start": "172080",
    "end": "175890"
  },
  {
    "text": "whether that node is fit to run that",
    "start": "175890",
    "end": "178410"
  },
  {
    "text": "container or not so we run that list of",
    "start": "178410",
    "end": "182160"
  },
  {
    "text": "predicate functions on all the nodes in",
    "start": "182160",
    "end": "183780"
  },
  {
    "text": "the cluster and thereafter we are we get",
    "start": "183780",
    "end": "189960"
  },
  {
    "text": "a filtered list of nodes so like in this",
    "start": "189960",
    "end": "193140"
  },
  {
    "text": "case for example like we applied the",
    "start": "193140",
    "end": "196350"
  },
  {
    "text": "predicate functions on nodes n 1 to n 5",
    "start": "196350",
    "end": "198390"
  },
  {
    "text": "and the scheduler found that only n 2 n",
    "start": "198390",
    "end": "201900"
  },
  {
    "text": "+ 4 satisfied whatever the pod criterias",
    "start": "201900",
    "end": "205500"
  },
  {
    "text": "was so this this is the for step in in",
    "start": "205500",
    "end": "209760"
  },
  {
    "text": "the scheduling process and the next step",
    "start": "209760",
    "end": "212010"
  },
  {
    "text": "is as can be guessed is deciding which",
    "start": "212010",
    "end": "216090"
  },
  {
    "text": "among these nodes is a benefit so for",
    "start": "216090",
    "end": "218700"
  },
  {
    "text": "that the share Euler path applies",
    "start": "218700",
    "end": "221340"
  },
  {
    "text": "certain priority functions to these",
    "start": "221340",
    "end": "224190"
  },
  {
    "text": "given set of nodes and by priority",
    "start": "224190",
    "end": "226800"
  },
  {
    "text": "functions it's pretty much a way of",
    "start": "226800",
    "end": "229650"
  },
  {
    "text": "quantitative quantitatively saying that",
    "start": "229650",
    "end": "232620"
  },
  {
    "text": "which node is better suited for that",
    "start": "232620",
    "end": "234840"
  },
  {
    "text": "particular container so they are there",
    "start": "234840",
    "end": "237870"
  },
  {
    "text": "are a bunch of predicate functions and",
    "start": "237870",
    "end": "239550"
  },
  {
    "text": "what each of the bunch of priority",
    "start": "239550",
    "end": "242280"
  },
  {
    "text": "functions and what each of them returns",
    "start": "242280",
    "end": "244010"
  },
  {
    "text": "is a it's an integer value and",
    "start": "244010",
    "end": "248300"
  },
  {
    "text": "ultimately for each of the nodes we take",
    "start": "248300",
    "end": "250739"
  },
  {
    "text": "a weighted weighted value for by running",
    "start": "250739",
    "end": "255180"
  },
  {
    "text": "it over all the priority functions and",
    "start": "255180",
    "end": "257120"
  },
  {
    "text": "then we just sort the weighted score of",
    "start": "257120",
    "end": "261419"
  },
  {
    "text": "all the nodes and we take the topmost",
    "start": "261419",
    "end": "263640"
  },
  {
    "text": "node so in this case",
    "start": "263640",
    "end": "266540"
  },
  {
    "text": "the Shetler applied those priority",
    "start": "266540",
    "end": "268400"
  },
  {
    "text": "functions on n 2 and n 4 and it found",
    "start": "268400",
    "end": "270950"
  },
  {
    "text": "that info is more suitable for for",
    "start": "270950",
    "end": "274850"
  },
  {
    "text": "scheduling that particular container so",
    "start": "274850",
    "end": "276920"
  },
  {
    "text": "I think it's it's pretty simple and",
    "start": "276920",
    "end": "278930"
  },
  {
    "text": "straightforward what what it's trying to",
    "start": "278930",
    "end": "281450"
  },
  {
    "text": "do to get a little more like idea of",
    "start": "281450",
    "end": "285770"
  },
  {
    "text": "what the default or what the predicate",
    "start": "285770",
    "end": "288200"
  },
  {
    "text": "and priority functions look like let's",
    "start": "288200",
    "end": "291050"
  },
  {
    "start": "290000",
    "end": "405000"
  },
  {
    "text": "look at like some of the sample",
    "start": "291050",
    "end": "292910"
  },
  {
    "text": "predicate functions that communities",
    "start": "292910",
    "end": "296090"
  },
  {
    "text": "applies by default when when trying to",
    "start": "296090",
    "end": "299030"
  },
  {
    "text": "share your reports so like the first one",
    "start": "299030",
    "end": "301790"
  },
  {
    "text": "is the host port check so in communities",
    "start": "301790",
    "end": "306710"
  },
  {
    "text": "you can specify a host port for a",
    "start": "306710",
    "end": "309020"
  },
  {
    "text": "container if you want so what that",
    "start": "309020",
    "end": "311300"
  },
  {
    "text": "actually means that the continue port",
    "start": "311300",
    "end": "313040"
  },
  {
    "text": "has to be mapped on the host port so",
    "start": "313040",
    "end": "315260"
  },
  {
    "text": "that port needs to be available on the",
    "start": "315260",
    "end": "317900"
  },
  {
    "text": "node so this check make make sure that",
    "start": "317900",
    "end": "320630"
  },
  {
    "text": "if say you have specified host port 80",
    "start": "320630",
    "end": "324380"
  },
  {
    "text": "or 90 in your pot spec that port is",
    "start": "324380",
    "end": "326780"
  },
  {
    "text": "available in the node and if it's not",
    "start": "326780",
    "end": "328400"
  },
  {
    "text": "then that node is not suitable for",
    "start": "328400",
    "end": "330530"
  },
  {
    "text": "sharing the pot the other one is pod fed",
    "start": "330530",
    "end": "335210"
  },
  {
    "text": "resources so by default in terms of",
    "start": "335210",
    "end": "339020"
  },
  {
    "text": "resource so measurements cubing like the",
    "start": "339020",
    "end": "342650"
  },
  {
    "text": "scheduler is only taking into account",
    "start": "342650",
    "end": "344170"
  },
  {
    "text": "the CPU and memory usage of each of the",
    "start": "344170",
    "end": "347450"
  },
  {
    "text": "nodes in the cluster and this is",
    "start": "347450",
    "end": "349910"
  },
  {
    "text": "reported by the cubelet back to the api",
    "start": "349910",
    "end": "352670"
  },
  {
    "text": "so and recently there is some support",
    "start": "352670",
    "end": "354950"
  },
  {
    "text": "are it for GPU as well but like that's",
    "start": "354950",
    "end": "357140"
  },
  {
    "text": "all that they're talking about like when",
    "start": "357140",
    "end": "359600"
  },
  {
    "text": "we are when we look into resource usage",
    "start": "359600",
    "end": "362540"
  },
  {
    "text": "on each of the nodes and third similar",
    "start": "362540",
    "end": "364880"
  },
  {
    "text": "one could be like seeing if if a node if",
    "start": "364880",
    "end": "370430"
  },
  {
    "text": "a pod spec has specified a node selector",
    "start": "370430",
    "end": "372530"
  },
  {
    "text": "and then the user means that that pod",
    "start": "372530",
    "end": "377450"
  },
  {
    "text": "should only run on the nodes which have",
    "start": "377450",
    "end": "379280"
  },
  {
    "text": "that particular selector and that could",
    "start": "379280",
    "end": "381260"
  },
  {
    "text": "be because they have some special",
    "start": "381260",
    "end": "382790"
  },
  {
    "text": "requirements for the pot you're on so",
    "start": "382790",
    "end": "386240"
  },
  {
    "text": "that so the mash node selective",
    "start": "386240",
    "end": "388010"
  },
  {
    "text": "predicate tells whether this node is",
    "start": "388010",
    "end": "390260"
  },
  {
    "text": "suitable for scheduling or not so I",
    "start": "390260",
    "end": "394640"
  },
  {
    "text": "guess so these are just three of them so",
    "start": "394640",
    "end": "397310"
  },
  {
    "text": "I guess they are a total of seven or",
    "start": "397310",
    "end": "399710"
  },
  {
    "text": "eight",
    "start": "399710",
    "end": "400040"
  },
  {
    "text": "predicate functions or which are",
    "start": "400040",
    "end": "401870"
  },
  {
    "text": "specified by default in the scheduler",
    "start": "401870",
    "end": "404440"
  },
  {
    "text": "next moving on to like what the priority",
    "start": "404440",
    "end": "407030"
  },
  {
    "start": "405000",
    "end": "527000"
  },
  {
    "text": "functions look like so these are the",
    "start": "407030",
    "end": "409340"
  },
  {
    "text": "ones which are applied in the second",
    "start": "409340",
    "end": "410750"
  },
  {
    "text": "stage of the sharing process so like the",
    "start": "410750",
    "end": "414590"
  },
  {
    "text": "first one could be the Selective spread",
    "start": "414590",
    "end": "417370"
  },
  {
    "text": "the name it might be confusing for some",
    "start": "417370",
    "end": "420920"
  },
  {
    "text": "so what it essentially means is when we",
    "start": "420920",
    "end": "423860"
  },
  {
    "text": "are trying to deploy a deployment or",
    "start": "423860",
    "end": "425810"
  },
  {
    "text": "application controller or service in our",
    "start": "425810",
    "end": "427640"
  },
  {
    "text": "cluster the scheduler wants to make sure",
    "start": "427640",
    "end": "430430"
  },
  {
    "text": "that all the pods or continuous backing",
    "start": "430430",
    "end": "433130"
  },
  {
    "text": "that particular abstraction like the",
    "start": "433130",
    "end": "434750"
  },
  {
    "text": "service or the deployment are not",
    "start": "434750",
    "end": "436640"
  },
  {
    "text": "concentrated to a single node in your",
    "start": "436640",
    "end": "438350"
  },
  {
    "text": "cluster so this this essentially checks",
    "start": "438350",
    "end": "441230"
  },
  {
    "text": "to spread the pod among all the nodes in",
    "start": "441230",
    "end": "445580"
  },
  {
    "text": "your cluster so if a node for that",
    "start": "445580",
    "end": "448010"
  },
  {
    "text": "particular deployment is already on a",
    "start": "448010",
    "end": "449510"
  },
  {
    "text": "node that node would be given a lower",
    "start": "449510",
    "end": "451310"
  },
  {
    "text": "priority or low score when the other",
    "start": "451310",
    "end": "454580"
  },
  {
    "text": "pods for that service are to be",
    "start": "454580",
    "end": "456770"
  },
  {
    "text": "scheduled similarly we have image",
    "start": "456770",
    "end": "459080"
  },
  {
    "text": "locality this is pretty self that",
    "start": "459080",
    "end": "460820"
  },
  {
    "text": "understandable like if a node already",
    "start": "460820",
    "end": "463400"
  },
  {
    "text": "has the container image then obviously",
    "start": "463400",
    "end": "465080"
  },
  {
    "text": "it's given a higher priority least",
    "start": "465080",
    "end": "468380"
  },
  {
    "text": "requested nodes it's so again like you",
    "start": "468380",
    "end": "471560"
  },
  {
    "text": "want to share resources pods on nodes",
    "start": "471560",
    "end": "475900"
  },
  {
    "text": "which are underutilized to have a more",
    "start": "475900",
    "end": "479390"
  },
  {
    "text": "uniform distribution and similarly node",
    "start": "479390",
    "end": "482510"
  },
  {
    "text": "labels so node labels differs from node",
    "start": "482510",
    "end": "484940"
  },
  {
    "text": "selectors in the way that selector is",
    "start": "484940",
    "end": "487850"
  },
  {
    "text": "more like it's a more harder condition",
    "start": "487850",
    "end": "491540"
  },
  {
    "text": "was a node label a node label is just",
    "start": "491540",
    "end": "494120"
  },
  {
    "text": "like a compatibility check that if it if",
    "start": "494120",
    "end": "497630"
  },
  {
    "text": "this label is present then good enough",
    "start": "497630",
    "end": "499400"
  },
  {
    "text": "else like give it a low priority so in a",
    "start": "499400",
    "end": "503000"
  },
  {
    "text": "nutshell what what we are actually",
    "start": "503000",
    "end": "504740"
  },
  {
    "text": "looking at what the current shell dealer",
    "start": "504740",
    "end": "506810"
  },
  {
    "text": "does it takes a list of nodes apply some",
    "start": "506810",
    "end": "509900"
  },
  {
    "text": "set of predicate functions which filters",
    "start": "509900",
    "end": "513110"
  },
  {
    "text": "or lists which filters are list of nodes",
    "start": "513110",
    "end": "515210"
  },
  {
    "text": "and then we just sort the remaining",
    "start": "515210",
    "end": "517909"
  },
  {
    "text": "nodes based on some priority and",
    "start": "517910",
    "end": "521020"
  },
  {
    "text": "ultimately we get a node on which the",
    "start": "521020",
    "end": "524380"
  },
  {
    "text": "body said you don't now obviously like",
    "start": "524380",
    "end": "528050"
  },
  {
    "start": "527000",
    "end": "635000"
  },
  {
    "text": "they are like pretty obvious drawbacks",
    "start": "528050",
    "end": "532070"
  },
  {
    "text": "which one can",
    "start": "532070",
    "end": "532889"
  },
  {
    "text": "about like one is the scheduler right",
    "start": "532889",
    "end": "538799"
  },
  {
    "text": "now is using these set of predicates or",
    "start": "538799",
    "end": "541259"
  },
  {
    "text": "priorities for all the parts",
    "start": "541259",
    "end": "543540"
  },
  {
    "text": "irrespective of what what what",
    "start": "543540",
    "end": "545699"
  },
  {
    "text": "application or service they are running",
    "start": "545699",
    "end": "547649"
  },
  {
    "text": "so whether whether it's like a network",
    "start": "547649",
    "end": "551129"
  },
  {
    "text": "intense intensive app like a video",
    "start": "551129",
    "end": "552959"
  },
  {
    "text": "application or it's like a machine",
    "start": "552959",
    "end": "555329"
  },
  {
    "text": "learning or ray tracing up like which",
    "start": "555329",
    "end": "557189"
  },
  {
    "text": "are more computer intensive so the",
    "start": "557189",
    "end": "559980"
  },
  {
    "text": "scheduler is not really taking into",
    "start": "559980",
    "end": "561480"
  },
  {
    "text": "account that the type of applications",
    "start": "561480",
    "end": "563459"
  },
  {
    "text": "it's trying to show you so that's like",
    "start": "563459",
    "end": "565709"
  },
  {
    "text": "one of the things that could be improved",
    "start": "565709",
    "end": "568639"
  },
  {
    "text": "the other thing is like the scheduler is",
    "start": "568639",
    "end": "571470"
  },
  {
    "text": "not getting any information from your",
    "start": "571470",
    "end": "574279"
  },
  {
    "text": "like the underlying topology ultimately",
    "start": "574279",
    "end": "578069"
  },
  {
    "text": "like the clusters on which we deploy our",
    "start": "578069",
    "end": "582179"
  },
  {
    "text": "systems are they are heterogeneous not",
    "start": "582179",
    "end": "584129"
  },
  {
    "text": "all nodes are similar like some might",
    "start": "584129",
    "end": "586379"
  },
  {
    "text": "have better hardware than the others so",
    "start": "586379",
    "end": "589519"
  },
  {
    "text": "that could be that either the users in",
    "start": "589519",
    "end": "592980"
  },
  {
    "text": "specifying node selectors but that's",
    "start": "592980",
    "end": "595079"
  },
  {
    "text": "something that's not it taking into",
    "start": "595079",
    "end": "596639"
  },
  {
    "text": "account by scheduler itself and the",
    "start": "596639",
    "end": "599579"
  },
  {
    "text": "third one is as we talked about the",
    "start": "599579",
    "end": "601799"
  },
  {
    "text": "weights in the program in the second",
    "start": "601799",
    "end": "604019"
  },
  {
    "text": "step of prioritizing the nodes right now",
    "start": "604019",
    "end": "607499"
  },
  {
    "text": "the default implementation the way it is",
    "start": "607499",
    "end": "609629"
  },
  {
    "text": "right now it takes all the priority",
    "start": "609629",
    "end": "612540"
  },
  {
    "text": "functions equally like if everything is",
    "start": "612540",
    "end": "614339"
  },
  {
    "text": "weighted as one so like those are some",
    "start": "614339",
    "end": "617160"
  },
  {
    "text": "of the things that like the default",
    "start": "617160",
    "end": "619529"
  },
  {
    "text": "scheduler is not really handling and can",
    "start": "619529",
    "end": "625049"
  },
  {
    "text": "be improved on but the good part about",
    "start": "625049",
    "end": "627419"
  },
  {
    "text": "is like community sharia law provides a",
    "start": "627419",
    "end": "629279"
  },
  {
    "text": "lot of folks way you can plug your own",
    "start": "629279",
    "end": "632999"
  },
  {
    "text": "scheduler or like make changes to the",
    "start": "632999",
    "end": "634919"
  },
  {
    "text": "custom said you know so I mean natural",
    "start": "634919",
    "end": "639449"
  },
  {
    "start": "635000",
    "end": "711000"
  },
  {
    "text": "inclination like for anyone is like if",
    "start": "639449",
    "end": "641850"
  },
  {
    "text": "they are running your cluster and how",
    "start": "641850",
    "end": "643169"
  },
  {
    "text": "they can do a better job so foresters",
    "start": "643169",
    "end": "646049"
  },
  {
    "text": "like then when we are prioritizing the",
    "start": "646049",
    "end": "648360"
  },
  {
    "text": "nodes we think of we think of",
    "start": "648360",
    "end": "652369"
  },
  {
    "text": "prioritization as more in a quality of",
    "start": "652369",
    "end": "656100"
  },
  {
    "text": "service sense and like quality of",
    "start": "656100",
    "end": "659609"
  },
  {
    "text": "service can can be pretty broadly",
    "start": "659609",
    "end": "661049"
  },
  {
    "text": "classified like you could have",
    "start": "661049",
    "end": "662369"
  },
  {
    "text": "networking storage and",
    "start": "662369",
    "end": "664050"
  },
  {
    "text": "all the things that might have back",
    "start": "664050",
    "end": "666269"
  },
  {
    "text": "impact the like the performance of a",
    "start": "666269",
    "end": "669839"
  },
  {
    "text": "application so if we take that into",
    "start": "669839",
    "end": "671880"
  },
  {
    "text": "account while prioritizing knows that",
    "start": "671880",
    "end": "673890"
  },
  {
    "text": "could be a good metric a similar one",
    "start": "673890",
    "end": "677670"
  },
  {
    "text": "could be like which we also tackle in a",
    "start": "677670",
    "end": "680459"
  },
  {
    "text": "proof-of-concept shed you know is we try",
    "start": "680459",
    "end": "683160"
  },
  {
    "text": "to balance the bandwidth usage of all",
    "start": "683160",
    "end": "686760"
  },
  {
    "text": "the nodes in your cluster so like if",
    "start": "686760",
    "end": "688860"
  },
  {
    "text": "there are some applications which are",
    "start": "688860",
    "end": "690600"
  },
  {
    "text": "very network intensive and some of those",
    "start": "690600",
    "end": "694050"
  },
  {
    "text": "are not then those those application",
    "start": "694050",
    "end": "696899"
  },
  {
    "text": "should be uniformly distributed in your",
    "start": "696899",
    "end": "698579"
  },
  {
    "text": "cluster so in this case the applications",
    "start": "698579",
    "end": "701459"
  },
  {
    "text": "which are running in the pods and then",
    "start": "701459",
    "end": "703740"
  },
  {
    "text": "you can also like try to play around",
    "start": "703740",
    "end": "705630"
  },
  {
    "text": "with the rates that the default schedule",
    "start": "705630",
    "end": "709019"
  },
  {
    "text": "already provides us so so now to just",
    "start": "709019",
    "end": "715290"
  },
  {
    "text": "show like how we can improve it we",
    "start": "715290",
    "end": "717570"
  },
  {
    "text": "walked on the shady local shed net and I",
    "start": "717570",
    "end": "720269"
  },
  {
    "text": "guess Salvatore is gonna talk about some",
    "start": "720269",
    "end": "723269"
  },
  {
    "text": "of the details",
    "start": "723269",
    "end": "724250"
  },
  {
    "text": "well actually this Mike works so you can",
    "start": "724250",
    "end": "727920"
  },
  {
    "text": "keep your you can keep your position",
    "start": "727920",
    "end": "729779"
  },
  {
    "text": "there so we start with ovn open which is",
    "start": "729779",
    "end": "732870"
  },
  {
    "text": "an acronym which stands for open",
    "start": "732870",
    "end": "734430"
  },
  {
    "text": "withdrawn network which is the network",
    "start": "734430",
    "end": "736620"
  },
  {
    "text": "backends that are using in this POC that",
    "start": "736620",
    "end": "739200"
  },
  {
    "text": "are demonstrating today year so anyone",
    "start": "739200",
    "end": "743190"
  },
  {
    "text": "is already familiar with this particular",
    "start": "743190",
    "end": "745890"
  },
  {
    "text": "network backend well apart from you guys",
    "start": "745890",
    "end": "748680"
  },
  {
    "text": "I know you well anyone that has never",
    "start": "748680",
    "end": "751560"
  },
  {
    "text": "heard of these like this is the first",
    "start": "751560",
    "end": "753750"
  },
  {
    "text": "time in my life the tired of this ok so",
    "start": "753750",
    "end": "756420"
  },
  {
    "text": "I can't assume that you word of it and",
    "start": "756420",
    "end": "758700"
  },
  {
    "text": "then you discount it as something",
    "start": "758700",
    "end": "760290"
  },
  {
    "text": "terrible which I would understand but I",
    "start": "760290",
    "end": "763260"
  },
  {
    "text": "will try and ask you to reconsider your",
    "start": "763260",
    "end": "765750"
  },
  {
    "text": "opinion because it's actually quite good",
    "start": "765750",
    "end": "768120"
  },
  {
    "text": "I mean I am partial but I think it is",
    "start": "768120",
    "end": "771120"
  },
  {
    "text": "actually quite good it is entirely open",
    "start": "771120",
    "end": "773520"
  },
  {
    "text": "source it is a developed by the open",
    "start": "773520",
    "end": "776010"
  },
  {
    "text": "with which community and if you want to",
    "start": "776010",
    "end": "778459"
  },
  {
    "text": "look at the list of contributors of",
    "start": "778459",
    "end": "780750"
  },
  {
    "text": "course there's vmware but we also there",
    "start": "780750",
    "end": "782820"
  },
  {
    "text": "is also a lot of contributors from",
    "start": "782820",
    "end": "784680"
  },
  {
    "text": "reddit HP Intel and a lot of companies",
    "start": "784680",
    "end": "788100"
  },
  {
    "text": "that I'm probably forgetting about and",
    "start": "788100",
    "end": "790410"
  },
  {
    "text": "in terms of more substantial things it",
    "start": "790410",
    "end": "793470"
  },
  {
    "text": "creates management of",
    "start": "793470",
    "end": "796550"
  },
  {
    "text": "allow us to create a managed virtual",
    "start": "796550",
    "end": "798840"
  },
  {
    "text": "network topologies layer two layer three",
    "start": "798840",
    "end": "801090"
  },
  {
    "text": "topologies and it also provides security",
    "start": "801090",
    "end": "805260"
  },
  {
    "text": "to stateful apples and it has a buffer",
    "start": "805260",
    "end": "807690"
  },
  {
    "text": "layer cell layer four well it doesn't",
    "start": "807690",
    "end": "810930"
  },
  {
    "text": "have a layer seven load balancer a cache",
    "start": "810930",
    "end": "812550"
  },
  {
    "text": "there's a layer for load balancing",
    "start": "812550",
    "end": "814260"
  },
  {
    "text": "services and it can be easily integrated",
    "start": "814260",
    "end": "816270"
  },
  {
    "text": "with the ingress controllers such as",
    "start": "816270",
    "end": "818190"
  },
  {
    "text": "nginx on traffic for providing the",
    "start": "818190",
    "end": "821610"
  },
  {
    "text": "ingress feature and also it supports",
    "start": "821610",
    "end": "824040"
  },
  {
    "text": "most kubernetes features and you can try",
    "start": "824040",
    "end": "827670"
  },
  {
    "text": "out the kubernetes integration for ovn",
    "start": "827670",
    "end": "831300"
  },
  {
    "text": "at the address that's on that link",
    "start": "831300",
    "end": "834500"
  },
  {
    "text": "trying out the integration is very easy",
    "start": "834500",
    "end": "837030"
  },
  {
    "text": "even if unfortunately we are not yet",
    "start": "837030",
    "end": "838920"
  },
  {
    "text": "able to provide a cube oedema addon but",
    "start": "838920",
    "end": "842210"
  },
  {
    "text": "at least it should not take more than an",
    "start": "842210",
    "end": "845430"
  },
  {
    "text": "hour maybe half an hour to set up a",
    "start": "845430",
    "end": "847290"
  },
  {
    "text": "simple cluster we do be an integration",
    "start": "847290",
    "end": "849690"
  },
  {
    "text": "anyway OPN is not really the focus of",
    "start": "849690",
    "end": "854070"
  },
  {
    "start": "851000",
    "end": "1152000"
  },
  {
    "text": "our talk today so let's look at our",
    "start": "854070",
    "end": "856430"
  },
  {
    "text": "experimental test bed so in this test",
    "start": "856430",
    "end": "859350"
  },
  {
    "text": "bed in the picture that you see there it",
    "start": "859350",
    "end": "861210"
  },
  {
    "text": "would be nice to have one of those",
    "start": "861210",
    "end": "862500"
  },
  {
    "text": "pointy things",
    "start": "862500",
    "end": "863820"
  },
  {
    "text": "otherwise I have designs around the",
    "start": "863820",
    "end": "865470"
  },
  {
    "text": "screen like this and go on this screen",
    "start": "865470",
    "end": "868200"
  },
  {
    "text": "we have our topology which is made of",
    "start": "868200",
    "end": "871890"
  },
  {
    "text": "three kinds of components in green you",
    "start": "871890",
    "end": "874200"
  },
  {
    "text": "have the ovn components in blue there",
    "start": "874200",
    "end": "877740"
  },
  {
    "text": "are kubernetes components and the pink",
    "start": "877740",
    "end": "880110"
  },
  {
    "text": "components are the cat dotnet elements",
    "start": "880110",
    "end": "883680"
  },
  {
    "text": "that akaash we'll talk about briefly so",
    "start": "883680",
    "end": "886140"
  },
  {
    "text": "let's start with UV n bits on every node",
    "start": "886140",
    "end": "889260"
  },
  {
    "text": "where minions were containers are",
    "start": "889260",
    "end": "892200"
  },
  {
    "text": "running we got a controller component",
    "start": "892200",
    "end": "894540"
  },
  {
    "text": "the controller implements the control",
    "start": "894540",
    "end": "897150"
  },
  {
    "text": "plane and manages the open with which",
    "start": "897150",
    "end": "899910"
  },
  {
    "text": "data plane instance is locally so it",
    "start": "899910",
    "end": "902490"
  },
  {
    "text": "held it only hold state for managing",
    "start": "902490",
    "end": "906440"
  },
  {
    "text": "virtual network interfaces on the local",
    "start": "906440",
    "end": "909480"
  },
  {
    "text": "node so behind this controller is of",
    "start": "909480",
    "end": "912510"
  },
  {
    "text": "course an open with switch Easton's and",
    "start": "912510",
    "end": "914520"
  },
  {
    "text": "on though that open with which instance",
    "start": "914520",
    "end": "917310"
  },
  {
    "text": "we configure the node local interface",
    "start": "917310",
    "end": "919830"
  },
  {
    "text": "and then these controllers are interact",
    "start": "919830",
    "end": "923280"
  },
  {
    "text": "with that ouvir and north digimon that",
    "start": "923280",
    "end": "926050"
  },
  {
    "text": "you can see here which is a sort of a",
    "start": "926050",
    "end": "928089"
  },
  {
    "text": "northbound driver it exposes indeed a",
    "start": "928089",
    "end": "930970"
  },
  {
    "text": "northbound API for management planes",
    "start": "930970",
    "end": "933610"
  },
  {
    "text": "like OpenStack or in our case kubernetes",
    "start": "933610",
    "end": "937029"
  },
  {
    "text": "and that component yogi nks watcher is",
    "start": "937029",
    "end": "941200"
  },
  {
    "text": "what makes the integration between the",
    "start": "941200",
    "end": "943390"
  },
  {
    "text": "kubernetes api server and ovn using ovn",
    "start": "943390",
    "end": "948070"
  },
  {
    "text": "we build this logical topology which is",
    "start": "948070",
    "end": "951430"
  },
  {
    "text": "made of one logical switch per node",
    "start": "951430",
    "end": "953950"
  },
  {
    "text": "which are interconnected biological",
    "start": "953950",
    "end": "956560"
  },
  {
    "text": "router of course when we say logical",
    "start": "956560",
    "end": "958600"
  },
  {
    "text": "routers this is just a an abstract",
    "start": "958600",
    "end": "961660"
  },
  {
    "text": "concept there's not really routing",
    "start": "961660",
    "end": "963640"
  },
  {
    "text": "occurring it's a distributed router so",
    "start": "963640",
    "end": "966370"
  },
  {
    "text": "we never know if you have two containers",
    "start": "966370",
    "end": "968320"
  },
  {
    "text": "on the same node you never go to this",
    "start": "968320",
    "end": "970750"
  },
  {
    "text": "thing so it's all distributed and for",
    "start": "970750",
    "end": "974709"
  },
  {
    "text": "implementing the Kuban service",
    "start": "974709",
    "end": "976300"
  },
  {
    "text": "abstraction it doesn't leverage the cube",
    "start": "976300",
    "end": "978790"
  },
  {
    "text": "proxy component but instead it leverages",
    "start": "978790",
    "end": "981070"
  },
  {
    "text": "ovn layer for load balancing capability",
    "start": "981070",
    "end": "984220"
  },
  {
    "text": "to implement east-west distributed load",
    "start": "984220",
    "end": "986800"
  },
  {
    "text": "balancer and therefore to load balancer",
    "start": "986800",
    "end": "990790"
  },
  {
    "text": "instances one for TCP services and one",
    "start": "990790",
    "end": "993880"
  },
  {
    "text": "for UDP services are associated to each",
    "start": "993880",
    "end": "997000"
  },
  {
    "text": "logical switch so of course this is a",
    "start": "997000",
    "end": "1000149"
  },
  {
    "text": "very simple logical topology but it",
    "start": "1000149",
    "end": "1005160"
  },
  {
    "text": "enables us to fulfill all all the",
    "start": "1005160",
    "end": "1007920"
  },
  {
    "text": "kubernetes use cases at least in this",
    "start": "1007920",
    "end": "1010680"
  },
  {
    "text": "phase where we don't have multi-tenancy",
    "start": "1010680",
    "end": "1013140"
  },
  {
    "text": "multiple network support when these will",
    "start": "1013140",
    "end": "1016380"
  },
  {
    "text": "be adopted by the kubernetes Signet and",
    "start": "1016380",
    "end": "1019820"
  },
  {
    "text": "incorporated into kubernetes of course",
    "start": "1019820",
    "end": "1021959"
  },
  {
    "text": "this topology will change a little bit",
    "start": "1021959",
    "end": "1024168"
  },
  {
    "text": "so and I think that this is all for the",
    "start": "1024169",
    "end": "1028020"
  },
  {
    "text": "ovn side we describe the components and",
    "start": "1028020",
    "end": "1030949"
  },
  {
    "text": "topological topology as you can see the",
    "start": "1030949",
    "end": "1034260"
  },
  {
    "text": "kubernetes side we have the usual",
    "start": "1034260",
    "end": "1036390"
  },
  {
    "text": "components the API server the controller",
    "start": "1036390",
    "end": "1038428"
  },
  {
    "text": "manager as we said we don't have the",
    "start": "1038429",
    "end": "1040530"
  },
  {
    "text": "cube proxy on every node and the cubelet",
    "start": "1040530",
    "end": "1042900"
  },
  {
    "text": "is running do VNC ni plug-in which",
    "start": "1042900",
    "end": "1046438"
  },
  {
    "text": "unlike other CNI plugins is a very",
    "start": "1046439",
    "end": "1049470"
  },
  {
    "text": "simple component that just configures",
    "start": "1049470",
    "end": "1052950"
  },
  {
    "text": "the local network interfaces and plugs",
    "start": "1052950",
    "end": "1055800"
  },
  {
    "text": "it into the OBS Bridge instance",
    "start": "1055800",
    "end": "1059160"
  },
  {
    "text": "so I guess that is all in terms of the",
    "start": "1059160",
    "end": "1061980"
  },
  {
    "text": "description of the components that you",
    "start": "1061980",
    "end": "1064350"
  },
  {
    "text": "are running in our service of course the",
    "start": "1064350",
    "end": "1066660"
  },
  {
    "text": "most juicy thing is still missing which",
    "start": "1066660",
    "end": "1068700"
  },
  {
    "text": "er the net health agent and the skeptic",
    "start": "1068700",
    "end": "1072150"
  },
  {
    "text": "net component so for which a cash we'll",
    "start": "1072150",
    "end": "1074700"
  },
  {
    "text": "give you a description this is the slide",
    "start": "1074700",
    "end": "1084060"
  },
  {
    "text": "- yeah we want to do that I'll do that",
    "start": "1084060",
    "end": "1088050"
  },
  {
    "text": "so basically we have the who never goes",
    "start": "1088050",
    "end": "1094530"
  },
  {
    "text": "on every minion see using term minion I",
    "start": "1094530",
    "end": "1097470"
  },
  {
    "text": "don't know if it's friendly used a",
    "start": "1097470",
    "end": "1098700"
  },
  {
    "text": "minion but every node anyway we have one",
    "start": "1098700",
    "end": "1101280"
  },
  {
    "text": "agent that collects network health",
    "start": "1101280",
    "end": "1103140"
  },
  {
    "text": "status which we Akash we see with Akash",
    "start": "1103140",
    "end": "1106650"
  },
  {
    "text": "exactly later what this natural state",
    "start": "1106650",
    "end": "1109290"
  },
  {
    "text": "says but it's suffice to say that it is",
    "start": "1109290",
    "end": "1112080"
  },
  {
    "text": "an estimate of the true hood currently",
    "start": "1112080",
    "end": "1113910"
  },
  {
    "text": "being used on every on every node and",
    "start": "1113910",
    "end": "1117080"
  },
  {
    "text": "periodically this nitrogen agent sends",
    "start": "1117080",
    "end": "1120630"
  },
  {
    "text": "Network state data to the kubernetes",
    "start": "1120630",
    "end": "1123330"
  },
  {
    "text": "master worse cat dotnet is running and",
    "start": "1123330",
    "end": "1126000"
  },
  {
    "text": "now scat dotnet is not really a",
    "start": "1126000",
    "end": "1128490"
  },
  {
    "text": "replacement for the kubernetes scheduler",
    "start": "1128490",
    "end": "1130740"
  },
  {
    "text": "it is more correct to say",
    "start": "1130740",
    "end": "1132660"
  },
  {
    "text": "correct me if I'm wrong and announcement",
    "start": "1132660",
    "end": "1134310"
  },
  {
    "text": "of the kubernetes scheduler so it is",
    "start": "1134310",
    "end": "1136260"
  },
  {
    "text": "still the same kubernetes scheduler to",
    "start": "1136260",
    "end": "1138810"
  },
  {
    "text": "which we added something for making it",
    "start": "1138810",
    "end": "1143460"
  },
  {
    "text": "network on our network aware so I think",
    "start": "1143460",
    "end": "1146880"
  },
  {
    "text": "this concludes the discussion of the",
    "start": "1146880",
    "end": "1148770"
  },
  {
    "text": "testbed yeah we can go ahead and see",
    "start": "1148770",
    "end": "1150860"
  },
  {
    "text": "sure so just to to like lay more details",
    "start": "1150860",
    "end": "1156300"
  },
  {
    "start": "1152000",
    "end": "1209000"
  },
  {
    "text": "about the network agent oh it's actually",
    "start": "1156300",
    "end": "1158640"
  },
  {
    "text": "pretty simple like something that you",
    "start": "1158640",
    "end": "1161220"
  },
  {
    "text": "only show in quickly that so then it",
    "start": "1161220",
    "end": "1164700"
  },
  {
    "text": "work health agent runs on all the",
    "start": "1164700",
    "end": "1166290"
  },
  {
    "text": "minions in your cluster and what it's",
    "start": "1166290",
    "end": "1168750"
  },
  {
    "text": "essentially doing is it's capturing the",
    "start": "1168750",
    "end": "1171240"
  },
  {
    "text": "nodes network throughput and annotating",
    "start": "1171240",
    "end": "1174720"
  },
  {
    "text": "that information onto the API server now",
    "start": "1174720",
    "end": "1177690"
  },
  {
    "text": "in this in this particular instance that",
    "start": "1177690",
    "end": "1180650"
  },
  {
    "text": "this this information is is network",
    "start": "1180650",
    "end": "1184650"
  },
  {
    "text": "throughput that's collected by its start",
    "start": "1184650",
    "end": "1186540"
  },
  {
    "text": "but you could have your own agents which",
    "start": "1186540",
    "end": "1189360"
  },
  {
    "text": "which could",
    "start": "1189360",
    "end": "1190250"
  },
  {
    "text": "provide a little different information",
    "start": "1190250",
    "end": "1193020"
  },
  {
    "text": "or something more optimal to your portal",
    "start": "1193020",
    "end": "1194880"
  },
  {
    "text": "a use case and it annotates ApS over by",
    "start": "1194880",
    "end": "1198450"
  },
  {
    "text": "the patch and point on with the",
    "start": "1198450",
    "end": "1201390"
  },
  {
    "text": "annotation of the key value score and",
    "start": "1201390",
    "end": "1203820"
  },
  {
    "text": "keeping the network health so I think",
    "start": "1203820",
    "end": "1206760"
  },
  {
    "text": "it's pretty simple and one doesn't need",
    "start": "1206760",
    "end": "1211679"
  },
  {
    "start": "1209000",
    "end": "1258000"
  },
  {
    "text": "to understand so how would I actually",
    "start": "1211679",
    "end": "1215159"
  },
  {
    "text": "like work so in each of the minions the",
    "start": "1215159",
    "end": "1218970"
  },
  {
    "text": "network health agent is is collecting",
    "start": "1218970",
    "end": "1221640"
  },
  {
    "text": "this this network health score and",
    "start": "1221640",
    "end": "1224100"
  },
  {
    "text": "updating the node annotation every one",
    "start": "1224100",
    "end": "1227460"
  },
  {
    "text": "second to the API so so now whenever a",
    "start": "1227460",
    "end": "1231539"
  },
  {
    "text": "part is scheduled and the schedule and",
    "start": "1231539",
    "end": "1234890"
  },
  {
    "text": "notices the need for it so it gets to",
    "start": "1234890",
    "end": "1239490"
  },
  {
    "text": "know that the schedule in the scheduling",
    "start": "1239490",
    "end": "1243539"
  },
  {
    "text": "function kicks in and what it actually",
    "start": "1243539",
    "end": "1245490"
  },
  {
    "text": "does is it reads the network's code for",
    "start": "1245490",
    "end": "1247919"
  },
  {
    "text": "all the nodes in the cluster and based",
    "start": "1247919",
    "end": "1250440"
  },
  {
    "text": "on that particular information it makes",
    "start": "1250440",
    "end": "1252179"
  },
  {
    "text": "the decision on which node should the",
    "start": "1252179",
    "end": "1255390"
  },
  {
    "text": "pod get scheduled on so as can be seen",
    "start": "1255390",
    "end": "1258870"
  },
  {
    "start": "1258000",
    "end": "1612000"
  },
  {
    "text": "by three so let's let's just dive into",
    "start": "1258870",
    "end": "1261720"
  },
  {
    "text": "the demo now so in the demo we have a",
    "start": "1261720",
    "end": "1268380"
  },
  {
    "text": "three node cluster so we have the cube",
    "start": "1268380",
    "end": "1272010"
  },
  {
    "text": "indies master the minion 1 and the",
    "start": "1272010",
    "end": "1274620"
  },
  {
    "text": "minion 2 though we are using the local",
    "start": "1274620",
    "end": "1279149"
  },
  {
    "text": "up cluster script to set up a cube",
    "start": "1279149",
    "end": "1281370"
  },
  {
    "text": "Indies cluster but it's not something",
    "start": "1281370",
    "end": "1283770"
  },
  {
    "text": "that so that's like a design like it's",
    "start": "1283770",
    "end": "1287070"
  },
  {
    "text": "just based on preference like you can",
    "start": "1287070",
    "end": "1288600"
  },
  {
    "text": "use whatever you want and secondly the",
    "start": "1288600",
    "end": "1291600"
  },
  {
    "text": "master is also running the ovn watcher",
    "start": "1291600",
    "end": "1294419"
  },
  {
    "text": "that we just discussed during the ovn",
    "start": "1294419",
    "end": "1297090"
  },
  {
    "text": "slides and the minions are running the",
    "start": "1297090",
    "end": "1300779"
  },
  {
    "text": "network health agent as you already saw",
    "start": "1300779",
    "end": "1302909"
  },
  {
    "text": "her so it's posting this patch to the",
    "start": "1302909",
    "end": "1306600"
  },
  {
    "text": "api server and is alter and running the",
    "start": "1306600",
    "end": "1310230"
  },
  {
    "text": "couplet as well so that's what",
    "start": "1310230",
    "end": "1311640"
  },
  {
    "text": "characterises does a minion so in the",
    "start": "1311640",
    "end": "1315779"
  },
  {
    "text": "demo what I'm gonna do is",
    "start": "1315779",
    "end": "1318360"
  },
  {
    "text": "what we want to show in this demo that",
    "start": "1318360",
    "end": "1320610"
  },
  {
    "text": "you can also modify the scheduler such",
    "start": "1320610",
    "end": "1323400"
  },
  {
    "text": "that the network load is uniform across",
    "start": "1323400",
    "end": "1326370"
  },
  {
    "text": "various nodes in your cluster so we",
    "start": "1326370",
    "end": "1329490"
  },
  {
    "text": "would shall you say for pods over here",
    "start": "1329490",
    "end": "1332010"
  },
  {
    "text": "so and those pods would be making things",
    "start": "1332010",
    "end": "1336660"
  },
  {
    "text": "of different packet sizes so one of the",
    "start": "1336660",
    "end": "1339210"
  },
  {
    "text": "pods which is the engine x5 quad it's",
    "start": "1339210",
    "end": "1345360"
  },
  {
    "text": "pinging packet sizes of say 55 KB to a",
    "start": "1345360",
    "end": "1348930"
  },
  {
    "text": "destination and this IP address is",
    "start": "1348930",
    "end": "1351210"
  },
  {
    "text": "actually an interface on the master node",
    "start": "1351210",
    "end": "1355380"
  },
  {
    "text": "Oh which is which is set up during the",
    "start": "1355380",
    "end": "1359010"
  },
  {
    "text": "movie in topology and similarly we have",
    "start": "1359010",
    "end": "1362610"
  },
  {
    "text": "other nodes other pods in our setup and",
    "start": "1362610",
    "end": "1367680"
  },
  {
    "text": "they are there they they are pinging",
    "start": "1367680",
    "end": "1370680"
  },
  {
    "text": "packets of less sizes so what what we",
    "start": "1370680",
    "end": "1372810"
  },
  {
    "text": "want to show is so these are the other",
    "start": "1372810",
    "end": "1374760"
  },
  {
    "text": "set of ports which are actually not that",
    "start": "1374760",
    "end": "1377250"
  },
  {
    "text": "network intensive so we have engine X 2",
    "start": "1377250",
    "end": "1380700"
  },
  {
    "text": "then engine X 3 and similarly for so",
    "start": "1380700",
    "end": "1384210"
  },
  {
    "text": "engine X 3 spinning packets of sizes 3",
    "start": "1384210",
    "end": "1386460"
  },
  {
    "text": "KB and engine X for spinning packets of",
    "start": "1386460",
    "end": "1388590"
  },
  {
    "text": "sizes 30 KB so now if we look at it",
    "start": "1388590",
    "end": "1393500"
  },
  {
    "text": "since we have the agents already running",
    "start": "1393500",
    "end": "1397370"
  },
  {
    "text": "on the on the minions so if we check the",
    "start": "1397370",
    "end": "1402660"
  },
  {
    "text": "annotations the node annotations they",
    "start": "1402660",
    "end": "1406380"
  },
  {
    "text": "already have scored so I think",
    "start": "1406380",
    "end": "1413810"
  },
  {
    "text": "okay",
    "start": "1416390",
    "end": "1418169"
  },
  {
    "text": "I just reduced this",
    "start": "1418169",
    "end": "1422210"
  },
  {
    "text": "so like the node one has a network",
    "start": "1424490",
    "end": "1427070"
  },
  {
    "text": "health score of say 0.74 and the node",
    "start": "1427070",
    "end": "1430190"
  },
  {
    "text": "two has a network health score of one",
    "start": "1430190",
    "end": "1432320"
  },
  {
    "text": "point seven two and the reason it's not",
    "start": "1432320",
    "end": "1434570"
  },
  {
    "text": "zero is because ovn two to make sure",
    "start": "1434570",
    "end": "1439520"
  },
  {
    "text": "that tunnels are it has some gossip",
    "start": "1439520",
    "end": "1442670"
  },
  {
    "text": "traffic which actually makes sure that",
    "start": "1442670",
    "end": "1444290"
  },
  {
    "text": "things are working properly so that's",
    "start": "1444290",
    "end": "1446870"
  },
  {
    "text": "why right now you're seeing that it's",
    "start": "1446870",
    "end": "1449480"
  },
  {
    "text": "it's not zero although there's no parts",
    "start": "1449480",
    "end": "1451940"
  },
  {
    "text": "in our cluster so now we would go ahead",
    "start": "1451940",
    "end": "1455240"
  },
  {
    "text": "and deploy the pods in the setup so one",
    "start": "1455240",
    "end": "1462140"
  },
  {
    "text": "thing that I think any most of you since",
    "start": "1462140",
    "end": "1464420"
  },
  {
    "text": "you have played with communities like by",
    "start": "1464420",
    "end": "1467030"
  },
  {
    "text": "default communities would just showed",
    "start": "1467030",
    "end": "1468500"
  },
  {
    "text": "you the pods like two on each of the",
    "start": "1468500",
    "end": "1470120"
  },
  {
    "text": "nodes but in this case hopefully like",
    "start": "1470120",
    "end": "1473960"
  },
  {
    "text": "the pod with the high network traffic is",
    "start": "1473960",
    "end": "1476540"
  },
  {
    "text": "scheduled on one node and the subsequent",
    "start": "1476540",
    "end": "1478550"
  },
  {
    "text": "pods are scheduled on another node to",
    "start": "1478550",
    "end": "1480980"
  },
  {
    "text": "make the load more uniform so let's just",
    "start": "1480980",
    "end": "1484700"
  },
  {
    "text": "go ahead with that so the network",
    "start": "1484700",
    "end": "1490850"
  },
  {
    "text": "connection is a little slow so we just",
    "start": "1490850",
    "end": "1494870"
  },
  {
    "text": "created the pod which had ping packets",
    "start": "1494870",
    "end": "1501170"
  },
  {
    "text": "of large size so if we see that we",
    "start": "1501170",
    "end": "1503660"
  },
  {
    "text": "should use it on minion one now if we",
    "start": "1503660",
    "end": "1507950"
  },
  {
    "text": "should use the other nodes as well so",
    "start": "1507950",
    "end": "1512930"
  },
  {
    "text": "like this god showed you on minion to",
    "start": "1512930",
    "end": "1515120"
  },
  {
    "text": "and so let's go ahead and show you other",
    "start": "1515120",
    "end": "1517700"
  },
  {
    "text": "pods as well",
    "start": "1517700",
    "end": "1522159"
  },
  {
    "text": "so as you can see like the rest of the",
    "start": "1524800",
    "end": "1527410"
  },
  {
    "text": "pods were scheduled on different node",
    "start": "1527410",
    "end": "1529240"
  },
  {
    "text": "and not on the node where engineers",
    "start": "1529240",
    "end": "1531400"
  },
  {
    "text": "fight what should you and the reason",
    "start": "1531400",
    "end": "1533260"
  },
  {
    "text": "being is as these pods were getting",
    "start": "1533260",
    "end": "1537040"
  },
  {
    "text": "shuttled the network agents on the",
    "start": "1537040",
    "end": "1538780"
  },
  {
    "text": "minions were reporting the metric or the",
    "start": "1538780",
    "end": "1542380"
  },
  {
    "text": "network health score as as these pods",
    "start": "1542380",
    "end": "1546790"
  },
  {
    "text": "were getting shoddy and because of that",
    "start": "1546790",
    "end": "1548320"
  },
  {
    "text": "the scheduler took those health scores",
    "start": "1548320",
    "end": "1551650"
  },
  {
    "text": "into it scheduling decision and it plays",
    "start": "1551650",
    "end": "1556000"
  },
  {
    "text": "the remaining pods on other nodes so if",
    "start": "1556000",
    "end": "1559720"
  },
  {
    "text": "we just see that then it work health",
    "start": "1559720",
    "end": "1563950"
  },
  {
    "text": "scores now so we tried to balance so so",
    "start": "1563950",
    "end": "1567730"
  },
  {
    "text": "126 health score is given to the poor",
    "start": "1567730",
    "end": "1570790"
  },
  {
    "text": "with the note on which Ingenix fiber",
    "start": "1570790",
    "end": "1572800"
  },
  {
    "text": "scheduled and the other one is six six",
    "start": "1572800",
    "end": "1574540"
  },
  {
    "text": "point zero nine the way this this",
    "start": "1574540",
    "end": "1577540"
  },
  {
    "text": "computation is done is just a 1 by",
    "start": "1577540",
    "end": "1579670"
  },
  {
    "text": "logarithmic throughput and it's scaled",
    "start": "1579670",
    "end": "1583450"
  },
  {
    "text": "by a factor of 100 which you could also",
    "start": "1583450",
    "end": "1585450"
  },
  {
    "text": "consider as a as a weight of that",
    "start": "1585450",
    "end": "1589870"
  },
  {
    "text": "priority function so I think this is",
    "start": "1589870",
    "end": "1593110"
  },
  {
    "text": "pretty much what what we what we wanted",
    "start": "1593110",
    "end": "1596710"
  },
  {
    "text": "to show that you can implement you can",
    "start": "1596710",
    "end": "1599800"
  },
  {
    "text": "customize the default scheduler such",
    "start": "1599800",
    "end": "1601300"
  },
  {
    "text": "that to able to better meet your needs",
    "start": "1601300",
    "end": "1603250"
  },
  {
    "text": "and which which could range beyond the",
    "start": "1603250",
    "end": "1608260"
  },
  {
    "text": "general CPU and memory resources which",
    "start": "1608260",
    "end": "1610840"
  },
  {
    "text": "the scheduler considers so what we",
    "start": "1610840",
    "end": "1613960"
  },
  {
    "text": "essentially saw that we had for odd",
    "start": "1613960",
    "end": "1616210"
  },
  {
    "text": "specs which we wanted to do in case of",
    "start": "1616210",
    "end": "1618490"
  },
  {
    "text": "default said you know they shed you more",
    "start": "1618490",
    "end": "1620980"
  },
  {
    "text": "evenly like to pause on each node and in",
    "start": "1620980",
    "end": "1623110"
  },
  {
    "text": "which case the network load is not",
    "start": "1623110",
    "end": "1625150"
  },
  {
    "text": "really disputed while in case you're in",
    "start": "1625150",
    "end": "1628270"
  },
  {
    "text": "case your scheduler takes the network",
    "start": "1628270",
    "end": "1630810"
  },
  {
    "text": "load into consideration then it's more",
    "start": "1630810",
    "end": "1633460"
  },
  {
    "text": "uniform so now there could be multiple",
    "start": "1633460",
    "end": "1637590"
  },
  {
    "start": "1635000",
    "end": "1696000"
  },
  {
    "text": "approaches in which you can do this I",
    "start": "1637590",
    "end": "1639670"
  },
  {
    "text": "guess there was another talk on data",
    "start": "1639670",
    "end": "1642460"
  },
  {
    "text": "where should you reign where they",
    "start": "1642460",
    "end": "1644980"
  },
  {
    "text": "implemented their own shed you know so",
    "start": "1644980",
    "end": "1646770"
  },
  {
    "text": "you can also go ahead with implementing",
    "start": "1646770",
    "end": "1649620"
  },
  {
    "text": "your own scheduler completely outside so",
    "start": "1649620",
    "end": "1653400"
  },
  {
    "text": "and what that would entail is you are",
    "start": "1653400",
    "end": "1656140"
  },
  {
    "text": "not touching default schedule",
    "start": "1656140",
    "end": "1657730"
  },
  {
    "text": "you deploy a moon shell you learn",
    "start": "1657730",
    "end": "1659200"
  },
  {
    "text": "whenever you are deploying a part in the",
    "start": "1659200",
    "end": "1661240"
  },
  {
    "text": "pod spec you can specify the scheduler",
    "start": "1661240",
    "end": "1662980"
  },
  {
    "text": "name so that's another another way in",
    "start": "1662980",
    "end": "1665560"
  },
  {
    "text": "which you can specify a custom shade",
    "start": "1665560",
    "end": "1667600"
  },
  {
    "text": "below or you can use the extender",
    "start": "1667600",
    "end": "1670540"
  },
  {
    "text": "interface so Kuban d schedule a by",
    "start": "1670540",
    "end": "1672970"
  },
  {
    "text": "default provides us another plug it",
    "start": "1672970",
    "end": "1676300"
  },
  {
    "text": "pluggable mechanism called extended",
    "start": "1676300",
    "end": "1678340"
  },
  {
    "text": "interface and and under this it allows",
    "start": "1678340",
    "end": "1681820"
  },
  {
    "text": "you to define rest endpoints where you",
    "start": "1681820",
    "end": "1684670"
  },
  {
    "text": "can define your predicate and priority",
    "start": "1684670",
    "end": "1686800"
  },
  {
    "text": "functions but I guess the downside of",
    "start": "1686800",
    "end": "1688470"
  },
  {
    "text": "this is performance in some of the cases",
    "start": "1688470",
    "end": "1691330"
  },
  {
    "text": "like the shading time is much greater",
    "start": "1691330",
    "end": "1693850"
  },
  {
    "text": "than what you would expect Oh so why",
    "start": "1693850",
    "end": "1697000"
  },
  {
    "start": "1696000",
    "end": "1774000"
  },
  {
    "text": "would you actually even care about all",
    "start": "1697000",
    "end": "1699160"
  },
  {
    "text": "this stuff so like you you would want to",
    "start": "1699160",
    "end": "1704020"
  },
  {
    "text": "share your pods based on more data and",
    "start": "1704020",
    "end": "1707410"
  },
  {
    "text": "more context in new topology so I'm not",
    "start": "1707410",
    "end": "1711250"
  },
  {
    "text": "sure like how many people use like",
    "start": "1711250",
    "end": "1714670"
  },
  {
    "text": "software-defined infrastructure but you",
    "start": "1714670",
    "end": "1716440"
  },
  {
    "text": "can you can use in terms of network and",
    "start": "1716440",
    "end": "1719620"
  },
  {
    "text": "in terms of storage your infrastructure",
    "start": "1719620",
    "end": "1722410"
  },
  {
    "text": "could entirely be in software and what",
    "start": "1722410",
    "end": "1724090"
  },
  {
    "text": "that allows use is is the programmable",
    "start": "1724090",
    "end": "1728650"
  },
  {
    "text": "nature of that infrastructure allows you",
    "start": "1728650",
    "end": "1730420"
  },
  {
    "text": "to leverage the add information to a",
    "start": "1730420",
    "end": "1732550"
  },
  {
    "text": "ruling of the nodes then again you have",
    "start": "1732550",
    "end": "1736120"
  },
  {
    "text": "a heterogeneous set of applications as I",
    "start": "1736120",
    "end": "1738220"
  },
  {
    "text": "mentioned earlier like not all",
    "start": "1738220",
    "end": "1740200"
  },
  {
    "text": "applications are equal and there is no",
    "start": "1740200",
    "end": "1741820"
  },
  {
    "text": "one-size-fits-all solution for",
    "start": "1741820",
    "end": "1744640"
  },
  {
    "text": "everything and like it's pretty cool",
    "start": "1744640",
    "end": "1748060"
  },
  {
    "text": "like cuny's allows you with so much ease",
    "start": "1748060",
    "end": "1751150"
  },
  {
    "text": "that you can experiment with what you",
    "start": "1751150",
    "end": "1753400"
  },
  {
    "text": "want to do so this also want like also",
    "start": "1753400",
    "end": "1757780"
  },
  {
    "text": "aimed at highlighting that oh yeah I",
    "start": "1757780",
    "end": "1760630"
  },
  {
    "text": "guess that's mostly it and if there any",
    "start": "1760630",
    "end": "1763090"
  },
  {
    "text": "questions I'm happy to take them yeah",
    "start": "1763090",
    "end": "1766440"
  },
  {
    "text": "thank you",
    "start": "1766440",
    "end": "1769500"
  }
]
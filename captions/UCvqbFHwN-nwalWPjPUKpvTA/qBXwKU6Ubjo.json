[
  {
    "text": "for Linux screen sharing actually works with the miracle all right then we are now recording its five-minute pass so I",
    "start": "0",
    "end": "10050"
  },
  {
    "text": "think you can get this kicked off I don't know if VHS is on the call and one",
    "start": "10050",
    "end": "15990"
  },
  {
    "text": "here yeah yeah I want me to do quick intro yeah let's let's start off that",
    "start": "15990",
    "end": "22529"
  },
  {
    "text": "way well yeah so Todd Lacan is I guess you know Todd a",
    "start": "22529",
    "end": "30539"
  },
  {
    "text": "lot of different stuff but he's the lead",
    "start": "30539",
    "end": "36180"
  },
  {
    "text": "for the canoe project to do projects which is a pretty interesting data for",
    "start": "36180",
    "end": "43200"
  },
  {
    "text": "that Tom Warrington combination and it's",
    "start": "43200",
    "end": "48960"
  },
  {
    "text": "kind of like a chimera different sword systems pretty it's pretty powerful actually and and he's done some",
    "start": "48960",
    "end": "55140"
  },
  {
    "text": "incredible performance work making it worse on a variety different workloads which I'm excited to see him present",
    "start": "55140",
    "end": "62039"
  },
  {
    "text": "here today he's also a committer for a long list of other Apache projects and",
    "start": "62039",
    "end": "68100"
  },
  {
    "text": "incredibly well-respected and back communities so I'm really excited to hear his paw and you know I don't have",
    "start": "68100",
    "end": "75840"
  },
  {
    "text": "too much more of an intro site than that but that's important thanks man so yeah",
    "start": "75840",
    "end": "82920"
  },
  {
    "text": "I didn't prepare a whole lot better this is usually a pretty laid-back blast off I just threw together a few slides",
    "start": "82920",
    "end": "88110"
  },
  {
    "text": "starting about 20 minutes ago so I apologize for the lack of Polish here also feel free to jump in I don't know",
    "start": "88110",
    "end": "94470"
  },
  {
    "text": "how many folks are on the call but if someone wants to jump in and kind of guide the conversation to stuff that you all find interesting that's fine by me",
    "start": "94470",
    "end": "100829"
  },
  {
    "text": "so I do have a couple of flies and I also just wanted to show a couple of things lives I guess we've got about 25",
    "start": "100829",
    "end": "107100"
  },
  {
    "text": "more minutes before you got to get on to other stuff probably more interesting",
    "start": "107100",
    "end": "114540"
  },
  {
    "text": "whenever we'll talk about that okay okay well we'll play by your than plug up",
    "start": "114540",
    "end": "119579"
  },
  {
    "text": "anytime so yeah 30 second intro next video I guess then I already kind of covered it it's a distributed columnstore for those of you who aren't",
    "start": "119579",
    "end": "126119"
  },
  {
    "text": "database people column stores basically organize the data that you store",
    "start": "126119",
    "end": "131760"
  },
  {
    "text": "sort of in a column-oriented manner so that each column start together and when you want to scan just one column out of",
    "start": "131760",
    "end": "137730"
  },
  {
    "text": "say 100 columns in your table you can do so that happened to waste the i/o reading all the others which makes it",
    "start": "137730",
    "end": "142769"
  },
  {
    "text": "very well-suited for analytics one thing that we did included though is try to actually make this also efficient for",
    "start": "142769",
    "end": "148410"
  },
  {
    "text": "random access so while to do is typically used for analytics we do some use cases that are pretty random access",
    "start": "148410",
    "end": "154170"
  },
  {
    "text": "oriented and we do run some benchmarks using them more no sequel random access style benchmarking tools like whiteysd",
    "start": "154170",
    "end": "160530"
  },
  {
    "text": "that people might be familiar with it's also a distributed system so we use rafts for replication imagine people",
    "start": "160530",
    "end": "168450"
  },
  {
    "text": "here probably know about rafts is basically another implementation of consensus very similar to multi taxes so",
    "start": "168450",
    "end": "174090"
  },
  {
    "text": "we do care about latency I wouldn't say the latency is our number one concern we're not typically running directly web",
    "start": "174090",
    "end": "179910"
  },
  {
    "text": "facing properties we do but we do usually have end users who are on some bi tool and they expect queries to come",
    "start": "179910",
    "end": "186239"
  },
  {
    "text": "back sub second and oftentimes that sub second query actually boils down to hundreds or thousands of requests",
    "start": "186239",
    "end": "192480"
  },
  {
    "text": "underneath so the Taylor agency is actually pretty important where one tael outlier at the 99th percentile actually",
    "start": "192480",
    "end": "198750"
  },
  {
    "text": "tends to dominate a lot of workloads I think people here probably are familiar with that whole idea is the great paper",
    "start": "198750",
    "end": "204090"
  },
  {
    "text": "that I really like called tail at scale from Google maybe six or eight years ago if you haven't read that you definitely",
    "start": "204090",
    "end": "210030"
  },
  {
    "text": "should if you're working in tracing I don't want to talk too much about speedy though I think the way that we approach",
    "start": "210030",
    "end": "215760"
  },
  {
    "text": "buildings we do is essentially to build a bunch of kind of generic systems infrastructure people who work at",
    "start": "215760",
    "end": "221639"
  },
  {
    "text": "companies like Google or uber probably have a lot of that stuff already in-house not open source unfortunately we started from scratch on",
    "start": "221639",
    "end": "227700"
  },
  {
    "text": "a lot of stuff so we built a lot of these things that probably seem familiar to people from either other companies or",
    "start": "227700",
    "end": "233489"
  },
  {
    "text": "other ecosystems that are pretty generic to any distributed system software that cares about this kind of stuff other",
    "start": "233489",
    "end": "238950"
  },
  {
    "text": "things most of the stock you don't need to know anything about what kudi does just think of this as a platform for building high performance low latency",
    "start": "238950",
    "end": "245370"
  },
  {
    "text": "system software so I'm going to jump right in to come some of the various things this is kind of like a grab-bag",
    "start": "245370",
    "end": "251010"
  },
  {
    "text": "talk it's not like there's one our core story to this I just kind of here are the various things we do well we tend to",
    "start": "251010",
    "end": "256590"
  },
  {
    "text": "be useful the first one is pretty simple to request scope tracing this is probably the thing we do that's most",
    "start": "256590",
    "end": "262710"
  },
  {
    "text": "similar to open tracing where we have a by the way who knew almost all in C++ so",
    "start": "262710",
    "end": "267750"
  },
  {
    "text": "all this talk is about our C++ back-end we've got a macro of health traits it takes a little substitution string with",
    "start": "267750",
    "end": "273900"
  },
  {
    "text": "dollar sign placeholders and pretty much every RBC starts a new trace and we can",
    "start": "273900",
    "end": "280080"
  },
  {
    "text": "pass it between threads and then the trace things it sort of gets appended to whatever the current trace is this is",
    "start": "280080",
    "end": "286800"
  },
  {
    "text": "not actually a hierarchical tree if it's not really dapper or open trading style it's really just a log and when we",
    "start": "286800",
    "end": "294660"
  },
  {
    "text": "accumulate the vlog associate with our PC we sample it so we have different sampling buckets for different latency",
    "start": "294660",
    "end": "300570"
  },
  {
    "text": "profiles and also we actually have a timeout to propagate different clients",
    "start": "300570",
    "end": "305700"
  },
  {
    "text": "so whenever a client sends an RPC it says hey my timeout is one second and on the back end if we realize that we",
    "start": "305700",
    "end": "311340"
  },
  {
    "text": "responded to that RPC after one second we'll always jump the trace that RPC so",
    "start": "311340",
    "end": "316380"
  },
  {
    "text": "it gives us a pretty good idea of what's happening on the our pcs that are too long very very simplistic but it's again",
    "start": "316380",
    "end": "323640"
  },
  {
    "text": "it took like you know two hours to write whereas open tracing is a much more complicated thing and it's super super",
    "start": "323640",
    "end": "329820"
  },
  {
    "text": "lightweight there's no infrastructure it's all in process we don't need to hook up to any collectors anything like that so it's limited in scope I mean",
    "start": "329820",
    "end": "337500"
  },
  {
    "text": "that both in the future science sense of the word scope and also in the how much it accomplishes but it's been very very",
    "start": "337500",
    "end": "342990"
  },
  {
    "text": "useful for us one thing actually I didn't put in the slides as we also have for each of these traces a very simple",
    "start": "342990",
    "end": "349080"
  },
  {
    "text": "map with counters so if you look at an RPC trace we'll have the log and we'll all have a bunch of counters some of",
    "start": "349080",
    "end": "355080"
  },
  {
    "text": "them are pretty generic so our spinlock implementation will count how many cycles where it's been spinning and it reads that to their PC",
    "start": "355080",
    "end": "361490"
  },
  {
    "text": "and then we also have a lot more specific to the particular requests so if you're doing it right we have to",
    "start": "361490",
    "end": "367110"
  },
  {
    "text": "write it right ahead log and you might have time we've spent waiting to write to the right ahead log becomes a counter",
    "start": "367110",
    "end": "372750"
  },
  {
    "text": "on that trace so some examples in just a minute actually we don't have to do this in line and show examples while I talk so I",
    "start": "372750",
    "end": "380550"
  },
  {
    "text": "have another browser here so here's a server I just started running on",
    "start": "380550",
    "end": "386730"
  },
  {
    "text": "localhost I'm showing the RPC v page I wish shows the running our PCs and sampled our pcs but never made any other",
    "start": "386730",
    "end": "392910"
  },
  {
    "text": "pcs to the server yet so there's nothing in there but if I go a Python shell over here and how lift",
    "start": "392910",
    "end": "399270"
  },
  {
    "text": "tables there's no tables in this cluster Kalitta turn did it but that would have made an RPC so if I reload this page I",
    "start": "399270",
    "end": "406440"
  },
  {
    "text": "can see the current RPC connections that are open where it's from the state if",
    "start": "406440",
    "end": "411600"
  },
  {
    "text": "there were an RPC currently running at show up in this inbound connections list and then we can see a sample dirty tea",
    "start": "411600",
    "end": "417390"
  },
  {
    "text": "trays so the trace here unfortunately my browser doesn't show the new lines but you can see the time that it arrived",
    "start": "417390",
    "end": "423600"
  },
  {
    "text": "how many microseconds it took coming on with a call to you coming off the call queue handling and then 229 microseconds",
    "start": "423600",
    "end": "432360"
  },
  {
    "text": "later rq8 a success response I think this is a debug build all the times are much slower than you normally expect in",
    "start": "432360",
    "end": "438960"
  },
  {
    "text": "early this probably would take you know a few microseconds not however money",
    "start": "438960",
    "end": "444120"
  },
  {
    "text": "this deck is 100 microseconds this is very simple you know if I do a bunch of these calls probably all of",
    "start": "444120",
    "end": "451050"
  },
  {
    "text": "them are going to fall into the same bucket we're not going to actually see it as change as a weari sample once a second if I go to a actually one of our",
    "start": "451050",
    "end": "458370"
  },
  {
    "text": "production servers for an internal use case here Clara and I check out rbtv we",
    "start": "458370",
    "end": "463590"
  },
  {
    "text": "can see there's a lot more going on there's a bunch of connections open from Levites and hosts in fact there's one",
    "start": "463590",
    "end": "470580"
  },
  {
    "text": "called it's currently in flight and you can see that the client sent a three minutes timeout on this this is a scan",
    "start": "470580",
    "end": "476340"
  },
  {
    "text": "call so far astern running for 11 milliseconds lots of information with",
    "start": "476340",
    "end": "483930"
  },
  {
    "text": "outbound our pcs because the server's talk to each other so this server as an outbound RPC to another server calling",
    "start": "483930",
    "end": "491130"
  },
  {
    "text": "update consensus you can see it sent the call hasn't yet received a response if I",
    "start": "491130",
    "end": "496830"
  },
  {
    "text": "go down to look at some of the more interesting things you can see here start tablets help you which is one of our rear application or pcs and the",
    "start": "496830",
    "end": "504840"
  },
  {
    "text": "whole information about what happened and then here the metrics that I mentioned that every RPC has various",
    "start": "504840",
    "end": "510450"
  },
  {
    "text": "metrics come in the reproduce narrow our i/o code will account these metrics like F Data Sync",
    "start": "510450",
    "end": "515820"
  },
  {
    "text": "how many we did how many microseconds they took how many microseconds we spent waiting on mutexes DNS some reason those",
    "start": "515820",
    "end": "524010"
  },
  {
    "text": "refresh started a thread how long it took the first thread every thread pool that we use has few time",
    "start": "524010",
    "end": "530250"
  },
  {
    "text": "and run time a little CPU run time I don't know why they're not in alphabetical order here but so that we",
    "start": "530250",
    "end": "537930"
  },
  {
    "text": "have a thread pool is called raft and a thread pool called tablet copies that this request used we can see this tablet",
    "start": "537930",
    "end": "543990"
  },
  {
    "text": "copy thread took quite a long time this is actually downloading a bunch of data from another server so it's a longer",
    "start": "543990",
    "end": "550350"
  },
  {
    "text": "request so this is one particular sample that took 82 milliseconds but if we",
    "start": "550350",
    "end": "556470"
  },
  {
    "text": "scroll down you can actually see there's another sample of the same RPC that took longer and if we're lucky you might even",
    "start": "556470",
    "end": "561840"
  },
  {
    "text": "have an example of a very long one this is pretty useful to find out like what are the outliers what happened in that",
    "start": "561840",
    "end": "568770"
  },
  {
    "text": "layer that was different from other outliers maybe it's the update I think maybe it's the next time you can go through and see",
    "start": "568770",
    "end": "576210"
  },
  {
    "text": "all the different our pcs that we do that's sort of the simple RPC tracing that we do another thing that I really",
    "start": "576210",
    "end": "583410"
  },
  {
    "text": "like is that I found that oftentimes a single RPC trace won't tell you a whole lot it will tell you hey this RPC took a",
    "start": "583410",
    "end": "589290"
  },
  {
    "text": "long time waiting on a lock or took a long time waiting at i/o we don't really know what happened that actually caused that it's some across request",
    "start": "589290",
    "end": "595380"
  },
  {
    "text": "interaction so we separately have an infrastructure called process while tracing unfortunately they're not really",
    "start": "595380",
    "end": "600810"
  },
  {
    "text": "integrated they were implemented separately and never really changed use the same annotations or anything but",
    "start": "600810",
    "end": "607110"
  },
  {
    "text": "basically these are mostly scoped annotations and there's a way to actually draw an arc between two scopes as well if they think event fired in one",
    "start": "607110",
    "end": "613950"
  },
  {
    "text": "place and picked up another place and essentially you have a category for each trace event some human readable name and",
    "start": "613950",
    "end": "620790"
  },
  {
    "text": "then some set of variables and again there's a super low overhead when it's not on and then you actually enable this",
    "start": "620790",
    "end": "627450"
  },
  {
    "text": "when it's on there's pretty high overhead when it's on because you a lot of these traits coops so I'll pop over",
    "start": "627450",
    "end": "632550"
  },
  {
    "text": "to the server I have here and go to tracing dhtml and hit record and you can",
    "start": "632550",
    "end": "640470"
  },
  {
    "text": "see there's a bunch of different categories we have this is the categories that are in that trace annotation I'm going to say record and",
    "start": "640470",
    "end": "647760"
  },
  {
    "text": "then I'll make a couple RPC is this server and it stopped personally doesn't",
    "start": "647760",
    "end": "655530"
  },
  {
    "text": "look great when I'm zoomed way in for the screen share but you can see on the",
    "start": "655530",
    "end": "662010"
  },
  {
    "text": "top there's a timeline of CP usage and then various threads down the left you can see that one RPC worker was",
    "start": "662010",
    "end": "669140"
  },
  {
    "text": "actually involved I think I call it request I called lift tables four times you can see one two three four if i zoom",
    "start": "669140",
    "end": "677060"
  },
  {
    "text": "way in here I can actually do the time line that this call started here method",
    "start": "677060",
    "end": "686330"
  },
  {
    "text": "list tables it got picked up on this reactor thread which is our network is",
    "start": "686330",
    "end": "692000"
  },
  {
    "text": "Libby V for network than based i/o it did the person thing of the part of us",
    "start": "692000",
    "end": "697810"
  },
  {
    "text": "if I turn on the flow events I think we'll see I think the new version the",
    "start": "697810",
    "end": "703970"
  },
  {
    "text": "browser doesn't support these but it should actually draw an arrow here from here to here showing that the call was",
    "start": "703970",
    "end": "708980"
  },
  {
    "text": "parsed here and picked up by a different thread and you can see it actually included in this trace the traces that",
    "start": "708980",
    "end": "715700"
  },
  {
    "text": "we just looked at as you can see when it was picked up when it was handled with the metrics were in this case it's a",
    "start": "715700",
    "end": "721760"
  },
  {
    "text": "pretty uninteresting call of no metrics and then responding success so this is",
    "start": "721760",
    "end": "727520"
  },
  {
    "text": "again not a super interesting RPC it's just a list table but if I go to the tracing page I've one of our production",
    "start": "727520",
    "end": "734810"
  },
  {
    "text": "servers and record it should actually fill up the buffer quite quickly",
    "start": "734810",
    "end": "740830"
  },
  {
    "text": "I'll just capture a couple seconds and",
    "start": "740830",
    "end": "745540"
  },
  {
    "text": "you can see there's a lot more going on a lot more threads a lot more apiece",
    "start": "746320",
    "end": "752420"
  },
  {
    "text": "he's going on and there's actually some RPGs that are taking pretty long so if I click on a scan I can see that it took",
    "start": "752420",
    "end": "758710"
  },
  {
    "text": "seven hundred five milliseconds and I might be able to zoom in and see this is",
    "start": "758710",
    "end": "764360"
  },
  {
    "text": "continuing a scan meaning that it started in the previous RPC it's reading some blocks it got a cache miss that's",
    "start": "764360",
    "end": "770870"
  },
  {
    "text": "probably going to be blocking i/o does give you a pretty good idea what might",
    "start": "770870",
    "end": "776000"
  },
  {
    "text": "be going on you can zoom in and release you have the fine grain level here's a cache miss this one is pretty quick it",
    "start": "776000",
    "end": "781760"
  },
  {
    "text": "probably hit the OS buffer cache where is that one that is pretty long it's probably I'm actually going to disk list",
    "start": "781760",
    "end": "788600"
  },
  {
    "text": "at 12 milliseconds it's probably hitting a spinning disk this is all very useful tis you can actually see kind of cross",
    "start": "788600",
    "end": "795800"
  },
  {
    "text": "request when one thing might actually be causing an impact on another we're also able to see pretty interesting patterns",
    "start": "795800",
    "end": "802670"
  },
  {
    "text": "in red thread pools where we're used to not have Lefou ordered or thread pools so he'd round robin across all of our",
    "start": "802670",
    "end": "808550"
  },
  {
    "text": "workers and we wouldn't get this kind of nice chunking we're only a small handful of our PC workers is active it would",
    "start": "808550",
    "end": "814490"
  },
  {
    "text": "actually be round-robin across 100 threads and really hurting the cash performance and things like that so this",
    "start": "814490",
    "end": "820520"
  },
  {
    "text": "has been very very useful for us to find process wide lockups we found some issues at TC Malik for example we've",
    "start": "820520",
    "end": "827390"
  },
  {
    "text": "seen some issues with the linux kernel where the MSM before gets held and all the other threads block for apparently",
    "start": "827390",
    "end": "832580"
  },
  {
    "text": "no reason but they're actually they're all blocked on the lock in the kernel but I found this very useful it's way",
    "start": "832580",
    "end": "838190"
  },
  {
    "text": "more information than you'd actually get from something like open tracing and it captures the cross request so I think",
    "start": "838190",
    "end": "844370"
  },
  {
    "text": "things like open tracing are useful to pinpoint hey the server has high latency but when you actually want to dig into what's going on on that server this can",
    "start": "844370",
    "end": "851839"
  },
  {
    "text": "be more useful another nice feature of this this is actually the trace viewers",
    "start": "851839",
    "end": "857060"
  },
  {
    "text": "it's built into Chrome so I can type save here I can actually save a JSON file and we often are playing at a",
    "start": "857060",
    "end": "865190"
  },
  {
    "text": "customer site on premises and they can make these JSON files and attach it to a support ticket and then I can load it",
    "start": "865190",
    "end": "870500"
  },
  {
    "text": "into any other Kuti server or even in chrome I think is good about tracing and",
    "start": "870500",
    "end": "875630"
  },
  {
    "text": "load the wherever that JSON file went and it'll load in and display on",
    "start": "875630",
    "end": "881450"
  },
  {
    "text": "anyone's Chrome browser in fact I might even display a little bit nicer is probably a newer version that we've",
    "start": "881450",
    "end": "887000"
  },
  {
    "text": "embedded in q2 itself so that's the process white tracing terms an inner",
    "start": "887000",
    "end": "895190"
  },
  {
    "text": "process racing we actually haven't had a big need yet we don't have a lot of super deep RPC call stack at least",
    "start": "895190",
    "end": "901100"
  },
  {
    "text": "within coop I think there's some cases where a user application if it's building like a website they might want",
    "start": "901100",
    "end": "906740"
  },
  {
    "text": "to do tracing in which case we want to support it for the consumers but in terms of Q itself when we get a request our request",
    "start": "906740",
    "end": "913730"
  },
  {
    "text": "is going to maybe wait on one other server for application but that's about it so we don't really we haven't had a big",
    "start": "913730",
    "end": "918890"
  },
  {
    "text": "impetus to go and do even tracing or adapter or hire as if Ken or Yaeger or anything like that I also",
    "start": "918890",
    "end": "927829"
  },
  {
    "text": "wanted to call out the unreasonable effectiveness of log statements so we have this really good macarons I probably wrote on the",
    "start": "927829",
    "end": "933050"
  },
  {
    "text": "first week when I started writing to do which is Coke log slow execution see past number of milliseconds and then",
    "start": "933050",
    "end": "939290"
  },
  {
    "text": "some string and it's just checks if this particular scope that you put it in takes more than X number of milliseconds",
    "start": "939290",
    "end": "945110"
  },
  {
    "text": "it'll log out a statement saying hey I took a long time to do X this was",
    "start": "945110",
    "end": "950180"
  },
  {
    "text": "incredibly useful in customer environments when they they kind of called up and say hey dude who's being a little bit slow oh I upload that I own",
    "start": "950180",
    "end": "957079"
  },
  {
    "text": "that I don't know here's a lot of figure it out and just having these kind of markers in the logs that say hey look",
    "start": "957079",
    "end": "963440"
  },
  {
    "text": "right into the right ahead log a bunch of threads blog this thing saying that it took a long time to write right ahead log is a good point as maybe you're",
    "start": "963440",
    "end": "970850"
  },
  {
    "text": "right ahead log viscous flow or overly contended by other applications and things like that so super simple but",
    "start": "970850",
    "end": "976820"
  },
  {
    "text": "pretty useful for the amount of effort it took so we didn't have these sprinkled around our code base in various interesting places a newer thing",
    "start": "976820",
    "end": "986810"
  },
  {
    "text": "that we've added is process-wise stack trace collections so we have a thing called the Diagnostics log now I think I",
    "start": "986810",
    "end": "992180"
  },
  {
    "text": "can probably try to show you that so",
    "start": "992180",
    "end": "999260"
  },
  {
    "text": "just by default we run with this diagnostic lock which if put in a long directory in this case it's a dead built",
    "start": "999260",
    "end": "1005620"
  },
  {
    "text": "in temp so if I look at that file it's semi human readable and basically you",
    "start": "1005620",
    "end": "1014200"
  },
  {
    "text": "get stacked race records which are by default once a minute with some jitter",
    "start": "1014200",
    "end": "1020529"
  },
  {
    "text": "so we don't actually correlate with any kind of schedule once a minute tack so this one's 45 seconds apart this one is",
    "start": "1020529",
    "end": "1026558"
  },
  {
    "text": "another 45 this one is a little longer and then in order to make a little bit",
    "start": "1026559",
    "end": "1031688"
  },
  {
    "text": "smaller we do a little bit of dictionary encoding of the symbols seals here in",
    "start": "1031689",
    "end": "1036790"
  },
  {
    "text": "the stack trace line the stacks just have hex addresses and then inner leaves",
    "start": "1036790",
    "end": "1042428"
  },
  {
    "text": "there's these symbols lines which map those hex addresses to particular",
    "start": "1042429",
    "end": "1048150"
  },
  {
    "text": "particulars and bolts and function names the other type of until we put in these logs as metrics dumps so we have a lot",
    "start": "1048150",
    "end": "1054850"
  },
  {
    "text": "of metrics that are captured from the server histogram counters things like that I'll talk about",
    "start": "1054850",
    "end": "1060529"
  },
  {
    "text": "we found that even though customers may have centralized metrics collection oftentimes those do a lot of down simple",
    "start": "1060529",
    "end": "1067010"
  },
  {
    "text": "laying or aggregation and it's hard to get down to what happened at this exact minute or in between these two exact minutes",
    "start": "1067010",
    "end": "1072440"
  },
  {
    "text": "what was the 99th percentile log of pen latency on this particular server I",
    "start": "1072440",
    "end": "1077960"
  },
  {
    "text": "think the best companies in the world probably can answer that question most companies can't and if you just",
    "start": "1077960",
    "end": "1083360"
  },
  {
    "text": "have this really dumb gzip log into our log that you can get from the customer and look at this we have various tools you can take these logs and graph them",
    "start": "1083360",
    "end": "1089779"
  },
  {
    "text": "and calculate various derived metrics that's thank you very useful again it's",
    "start": "1089779",
    "end": "1095360"
  },
  {
    "text": "kind of the simple thing but works pretty well and we've got a description",
    "start": "1095360",
    "end": "1101299"
  },
  {
    "text": "tag notice parse stacks and get some some our own part stacks on this slug",
    "start": "1101299",
    "end": "1112210"
  },
  {
    "text": "it'll print out a lot more information so the stacks and it does the symbolization shows if my thread groups",
    "start": "1112210",
    "end": "1120049"
  },
  {
    "text": "together threads that are all having the same stack so we have for reactor threads that are running a Libby event",
    "start": "1120049",
    "end": "1125450"
  },
  {
    "text": "loops and it groups them together in this blood easier to understand what's going on there versus seeing hundreds of",
    "start": "1125450",
    "end": "1131330"
  },
  {
    "text": "threads all of the same stack so I mentioned the other periodic we also have triggered selections so we have our",
    "start": "1131330",
    "end": "1137870"
  },
  {
    "text": "VC cues where when an RPC hits the system it goes into a queue waiting to be handled by handler thread and we have",
    "start": "1137870",
    "end": "1143690"
  },
  {
    "text": "a pretty tight limit on the length of that queue and if something arrives and it doesn't fit in the next few will",
    "start": "1143690",
    "end": "1149360"
  },
  {
    "text": "evict it in our pcs and that queue based on priority send back a message saying you need to come back later essentially",
    "start": "1149360",
    "end": "1155690"
  },
  {
    "text": "doing back pressure on the clients but that mechanism and when we actually do a fixed stuff from the queue we trigger at",
    "start": "1155690",
    "end": "1162350"
  },
  {
    "text": "that point a stack trace to all the threads this has been very very useful for us finding it reasons why something",
    "start": "1162350",
    "end": "1168169"
  },
  {
    "text": "is locked up so there's some set of underlying locks that gets held maybe it's a logging issue or a kernel issue",
    "start": "1168169",
    "end": "1173779"
  },
  {
    "text": "or something like that and then very quickly the RPC queues back up and then the triggers of stack trace so we have",
    "start": "1173779",
    "end": "1179210"
  },
  {
    "text": "this smoking-gun snapshot of here all the threads here where they're all blocked and pretty quickly we can point",
    "start": "1179210",
    "end": "1184669"
  },
  {
    "text": "out these issues so techniques like this have allowed us to find issues like ng",
    "start": "1184669",
    "end": "1189889"
  },
  {
    "text": "log for example if you just use the Google login library and it's mode there is a mutex around vlogging",
    "start": "1189889",
    "end": "1195990"
  },
  {
    "text": "and that mutex could be held while it's actually doing the i/o and I opened take a long time so we've seen these issues",
    "start": "1195990",
    "end": "1201480"
  },
  {
    "text": "where all threads end up locked on G log so we moved out to isn't logging and those things got a lot better so these",
    "start": "1201480",
    "end": "1208050"
  },
  {
    "text": "kind of techniques again pretty simple but work really well the stack traces",
    "start": "1208050",
    "end": "1213420"
  },
  {
    "text": "are also viewable on a slash stack web page again unreasonably effective simple",
    "start": "1213420",
    "end": "1218790"
  },
  {
    "text": "thing so if I go to one of our production servers go to slash stacks pretty quick and I call it a kind of a",
    "start": "1218790",
    "end": "1226860"
  },
  {
    "text": "poor man's profile also if I'm curious what a workload is doing is its can heavy is it doing a lot of i/o is it a",
    "start": "1226860",
    "end": "1232470"
  },
  {
    "text": "way to not have to be you on something usually just a couple reload this page it gives you a pretty good idea of how",
    "start": "1232470",
    "end": "1238260"
  },
  {
    "text": "busy the server is and what might be some bottlenecks so it's interesting to",
    "start": "1238260",
    "end": "1243810"
  },
  {
    "text": "me to see a hash table look up on the serialize row block Hall this is actually unknown performance issues at",
    "start": "1243810",
    "end": "1249330"
  },
  {
    "text": "least and I think fixed so very poor man's profile every loaded again I also",
    "start": "1249330",
    "end": "1255330"
  },
  {
    "text": "see the standard hash table signs here on this conflict and that probably shouldn't be in that call we should have",
    "start": "1255330",
    "end": "1260370"
  },
  {
    "text": "something a little faster there all right as a slash metrics is pretty",
    "start": "1260370",
    "end": "1269220"
  },
  {
    "text": "simple a lot of metric stuff we built our own metric subsystem we couldn't Lee sign much good for C++ I think now the",
    "start": "1269220",
    "end": "1274550"
  },
  {
    "text": "maybe the census project is trying to do a little bit with this but we implemented the HDR histogram data",
    "start": "1274550",
    "end": "1282510"
  },
  {
    "text": "structure for high resolution histograms and all of our pcs as well as a bunch of other things throughout the code base",
    "start": "1282510",
    "end": "1288470"
  },
  {
    "text": "track really fancy histograms so you can see in this example that this particular",
    "start": "1288470",
    "end": "1293940"
  },
  {
    "text": "right RPC has two significant digits precision we've done some number of them I mean",
    "start": "1293940",
    "end": "1301050"
  },
  {
    "text": "all the percentiles and these actually keeps the raw socket counts as well underneath so you can fetch it from",
    "start": "1301050",
    "end": "1307560"
  },
  {
    "text": "slash metrics if you had a special query parameter and they end up in that metrics log so given the metrics log and",
    "start": "1307560",
    "end": "1313470"
  },
  {
    "text": "given snapshots of the raw bucket count you can actually say between any two points in time what are the nine mint",
    "start": "1313470",
    "end": "1319620"
  },
  {
    "text": "percentiles of a bunch of different things and we calculate it on the server level as well as individual",
    "start": "1319620",
    "end": "1325090"
  },
  {
    "text": "flips and you can actually aggregate those raw bucket counts across tablets to say what's the 99th percentile for",
    "start": "1325090",
    "end": "1331390"
  },
  {
    "text": "this pretty good table that's very useful for us as well to understand where the bottlenecks might be or with",
    "start": "1331390",
    "end": "1336460"
  },
  {
    "text": "where slowness might be coming from another fun thing we built a couple of",
    "start": "1336460",
    "end": "1342520"
  },
  {
    "text": "years ago that found a lot of interesting issues is the stack watchdog so on important threads of things like",
    "start": "1342520",
    "end": "1348700"
  },
  {
    "text": "free mint bowls that are right ahead log of hand we use this skill to watch stack and we give some number of milliseconds",
    "start": "1348700",
    "end": "1354430"
  },
  {
    "text": "that we expect it should not take more than 500 milliseconds to append to the wall and then there's some background",
    "start": "1354430",
    "end": "1359800"
  },
  {
    "text": "thread which is the watchdog thread which essentially scans a registry or all the other threads and does a kind of",
    "start": "1359800",
    "end": "1366310"
  },
  {
    "text": "lock free check to see if any of these threads is inside one of these particular scope watch sacks coat and if",
    "start": "1366310",
    "end": "1373720"
  },
  {
    "text": "anybody's been inside one of those skills for longer than the amount of time it's expected it'll actually take the stack trace of that target thread",
    "start": "1373720",
    "end": "1380740"
  },
  {
    "text": "and dump into the log there's some rate limiting to make sure that things don't go crazy in the logging and some super",
    "start": "1380740",
    "end": "1387610"
  },
  {
    "text": "useful to find various issues with the file system level or D log or TCM alex",
    "start": "1387610",
    "end": "1394750"
  },
  {
    "text": "has been other kids we've found some bugs there so in this case the right ahead log at this line of code was stuck",
    "start": "1394750",
    "end": "1401590"
  },
  {
    "text": "first 200 milliseconds and it takes the kernel stack as well so we can actually see that inside the kernel it was",
    "start": "1401590",
    "end": "1407590"
  },
  {
    "text": "waiting on jbjb d2 which is the file system journal we didn't get right",
    "start": "1407590",
    "end": "1413620"
  },
  {
    "text": "access to the file system journal so this is something that you know you probably would expect right ahead luck",
    "start": "1413620",
    "end": "1418900"
  },
  {
    "text": "the fact you had to wait for a 600 milliseconds is a little bit unexpected may be that disk is either going bad or",
    "start": "1418900",
    "end": "1424660"
  },
  {
    "text": "just overload it in fact it turns out that this is just due to Red Hat Enterprise 6 being really old and pretty",
    "start": "1424660",
    "end": "1431530"
  },
  {
    "text": "bad imitation a lot of this stuff as you can also see in the user stack is in do right because kind of make sense because",
    "start": "1431530",
    "end": "1437500"
  },
  {
    "text": "the kernel stack is in the right beat system call so I think that's all the",
    "start": "1437500",
    "end": "1442960"
  },
  {
    "text": "slides that I've prepared it and want to go too long it's a good questions and discussion is more interesting there",
    "start": "1442960",
    "end": "1449470"
  },
  {
    "text": "anything that people want to hear more about or to see how the code works for anything like that",
    "start": "1449470",
    "end": "1455470"
  },
  {
    "text": "I've got a question thanks Todd this is pretty interesting and I it's fun to see",
    "start": "1455470",
    "end": "1461019"
  },
  {
    "text": "I kind of knew that you would do this with just what I wanted you to do this but it's nice to see a presentation",
    "start": "1461019",
    "end": "1466090"
  },
  {
    "text": "about performance analysis and stuff like that that's not just like 100 percent about distributed tracing",
    "start": "1466090",
    "end": "1471730"
  },
  {
    "text": "because these other techniques are really interesting relevant but one thing that comes up in my head I think",
    "start": "1471730",
    "end": "1477399"
  },
  {
    "text": "actually this is a fine example it sounds like in this case it was the issue had to do with red hat kind of",
    "start": "1477399",
    "end": "1484299"
  },
  {
    "text": "price effects not being a very good implementation but a lot of the things that you're probably dealing with have",
    "start": "1484299",
    "end": "1489519"
  },
  {
    "text": "to do with contention for some shared resource whether it's the disc or something else then I'm curious like",
    "start": "1489519",
    "end": "1495399"
  },
  {
    "text": "what you know do you have techniques that you're using to understand the",
    "start": "1495399",
    "end": "1501879"
  },
  {
    "text": "source of load when there's just no you know contention issues overloaded resource that type of thing like what",
    "start": "1501879",
    "end": "1507789"
  },
  {
    "text": "what are you typically doing to find the multiple writers or whatever it is that's contending for a resource yeah we",
    "start": "1507789",
    "end": "1514240"
  },
  {
    "text": "don't have any super generic things for that MINIX specifically for lock contention our spin locks are",
    "start": "1514240",
    "end": "1519460"
  },
  {
    "text": "instrumented with apology to talk about that here our spin locks have some instrumentation where they collect the",
    "start": "1519460",
    "end": "1524980"
  },
  {
    "text": "stack trace of the unlocking node with",
    "start": "1524980",
    "end": "1530019"
  },
  {
    "text": "an unlock that sees there was a waiter and collected spectrum so it kind of knows which folders were causing",
    "start": "1530019",
    "end": "1536919"
  },
  {
    "text": "attention of somebody else and then we expose that through the peopre web interface so I'll see if I can actually",
    "start": "1536919",
    "end": "1545908"
  },
  {
    "text": "show that yeah so if I go to a special URL which can be read via that Gopi",
    "start": "1550769",
    "end": "1557740"
  },
  {
    "text": "prof. tool as well it'll tell us over this one second the various stack traces",
    "start": "1557740",
    "end": "1564340"
  },
  {
    "text": "where we had some contention and you can be symbolized if you have the binary as well so this is super useful for the",
    "start": "1564340",
    "end": "1571090"
  },
  {
    "text": "generic kind of spin lock contention it won't tell us exactly like it tells us a sex race and the memory addresses it",
    "start": "1571090",
    "end": "1576190"
  },
  {
    "text": "doesn't tell us what kind of application level object was contended but it's usually fairly clear once you get those",
    "start": "1576190",
    "end": "1582220"
  },
  {
    "text": "data that okay at least I need to zero in on that part of the code to understand where my contention is going similarly you can",
    "start": "1582220",
    "end": "1590490"
  },
  {
    "text": "get CPU profiles from this kind of endpoint honestly I find the flash stacks to be unreasonably useful for",
    "start": "1590490",
    "end": "1596820"
  },
  {
    "text": "this kind of thing as well so one interesting example is maybe six months",
    "start": "1596820",
    "end": "1602040"
  },
  {
    "text": "ago we learned that TC Malik which is the alligator we use has sort of six",
    "start": "1602040",
    "end": "1607380"
  },
  {
    "text": "free lists for all sizes less than one megabyte allocations but one megabyte",
    "start": "1607380",
    "end": "1613050"
  },
  {
    "text": "and above actually goes to like a central span list which was actually",
    "start": "1613050",
    "end": "1619050"
  },
  {
    "text": "implemented as a linked list until very recently so just by looking at the flash tax profile we thought why are half the",
    "start": "1619050",
    "end": "1625110"
  },
  {
    "text": "RIS resident EC malloc allocate large iterating of our link list just in the stack traces you can see that and",
    "start": "1625110",
    "end": "1630960"
  },
  {
    "text": "inviting the code we realized that what we thought was a less than or equal to one megabyte was actually a less than",
    "start": "1630960",
    "end": "1636870"
  },
  {
    "text": "one megabyte and all of our via allocators had been tuned to get one megabyte allocation so by changing that",
    "start": "1636870",
    "end": "1642900"
  },
  {
    "text": "down from one megabyte to a little bit less than one megabyte we got rid of a bunch of latency outliers some kind of like this very stupid thing where we",
    "start": "1642900",
    "end": "1649050"
  },
  {
    "text": "went to like 1020 kilobytes or something and then we also submitted some patches",
    "start": "1649050",
    "end": "1654510"
  },
  {
    "text": "upstream to TC malloc to actually cache the one megabyte allocation and to make",
    "start": "1654510",
    "end": "1659670"
  },
  {
    "text": "the central free list not use a linked list and use a tree instead and those two changes actually increase the",
    "start": "1659670",
    "end": "1665610"
  },
  {
    "text": "throughput on some workloads which did a lot of larger allocations by like 40 to 50 percent so it all kind of started",
    "start": "1665610",
    "end": "1672000"
  },
  {
    "text": "from seeing something strange and just some stack traces and then from there we did the next level of digging to actually understand what was going on",
    "start": "1672000",
    "end": "1679820"
  },
  {
    "text": "well so thanks I got a question actually",
    "start": "1681140",
    "end": "1688460"
  },
  {
    "text": "first of all great presentation it's awesome to see all these details one",
    "start": "1688460",
    "end": "1695220"
  },
  {
    "text": "thing that that comes up a lot is you've got all these different tools for for looking at instrumenting various parts",
    "start": "1695220",
    "end": "1700980"
  },
  {
    "text": "of your system kernel level stuff stacks threads user logs and where some of the",
    "start": "1700980",
    "end": "1708510"
  },
  {
    "text": "trickiness shows up a lot of the times is sort of figuring out the right granularity of",
    "start": "1708510",
    "end": "1714770"
  },
  {
    "text": "you in order for these things to be relevant you often have to sort of staple them together some and that act of stapling them together",
    "start": "1714770",
    "end": "1722630"
  },
  {
    "text": "itself has overhead and that often seems to come up is like the trickiest part",
    "start": "1722630",
    "end": "1727860"
  },
  {
    "text": "and I was wondering if you had any thoughts on that or could you know relate experience report with trying to figure that part out yeah I definitely",
    "start": "1727860",
    "end": "1735540"
  },
  {
    "text": "agree I think we have a lot of systems that are useful in the right-hand but hard to expose what you should be looking at so we're trying to document",
    "start": "1735540",
    "end": "1743340"
  },
  {
    "text": "things better we're starting some run books for our internal support team to understand like how these things might be useful in terms of like correlating",
    "start": "1743340",
    "end": "1750630"
  },
  {
    "text": "oh I saw one outlier but I wasn't collecting the traces at that time yeah",
    "start": "1750630",
    "end": "1755640"
  },
  {
    "text": "we definitely have that you kind of have to like hope that you catch the thing happening that you want them to see so",
    "start": "1755640",
    "end": "1762120"
  },
  {
    "text": "it's a little hard that's why we started to add more of these features like the diagnostic plug was just always digging stack and that's now on by default it",
    "start": "1762120",
    "end": "1769770"
  },
  {
    "text": "took us a little bit of nervousness to be like is it actually safe to have this thing taking factories in once a minute",
    "start": "1769770",
    "end": "1775110"
  },
  {
    "text": "because when we first implemented it we actually found unlocked in the dynamic loader if you're trying to back-trace a thread while it didn't the loader and we",
    "start": "1775110",
    "end": "1781560"
  },
  {
    "text": "have awful worker appetiser read that so that I think there's always risk when you add this instrumentation either",
    "start": "1781560",
    "end": "1787200"
  },
  {
    "text": "performance or bugs and remember actually the first time we added the contention profiling I introduced this",
    "start": "1787200",
    "end": "1792660"
  },
  {
    "text": "awful memory correction book where I was writing outside of the stack and that almost got released to customers and it",
    "start": "1792660",
    "end": "1799800"
  },
  {
    "text": "would be really bad because we had a lot of crashes and things like that so there's always risk and I think for us",
    "start": "1799800",
    "end": "1805820"
  },
  {
    "text": "it's okay to have even like a 5 or 10 percent performance reduction I think",
    "start": "1805820",
    "end": "1811020"
  },
  {
    "text": "our customers are not so performance sensitive and there are a lot more sensitive stuff is down and they don't",
    "start": "1811020",
    "end": "1816300"
  },
  {
    "text": "know why or stuff is performing badly and they don't know why and it takes us you know it takes about three weeks to understand what the performance problem",
    "start": "1816300",
    "end": "1823140"
  },
  {
    "text": "is there'll be a lot more upset versus if you say well you've got a 5% overhead but we can pinpoint that problem in an",
    "start": "1823140",
    "end": "1829530"
  },
  {
    "text": "hour instead of three weeks it's usually a good trade-off for us it's probably not the case for every company but we",
    "start": "1829530",
    "end": "1836640"
  },
  {
    "text": "tend to lean more towards that side of the spectrum I guess I thought that's exactly what you were getting at sort of",
    "start": "1836640",
    "end": "1843180"
  },
  {
    "text": "our philosophy yeah that is sort of it around there is well one trying to figure out the right",
    "start": "1843180",
    "end": "1848790"
  },
  {
    "text": "granularity often seems to be part of the trick yonder being potentially dangerous you know there's some there's always",
    "start": "1848790",
    "end": "1856030"
  },
  {
    "text": "some overhead that comes with this stuff and sometimes it just seems especially",
    "start": "1856030",
    "end": "1862600"
  },
  {
    "text": "writing databases C++ stuff people can be very very obsessive about maximal",
    "start": "1862600",
    "end": "1869080"
  },
  {
    "text": "efficiency and then you're saying well uh we're we're just gonna add 5% overhead to figure out what's wrong with",
    "start": "1869080",
    "end": "1875290"
  },
  {
    "text": "it it's almost like a like a cultural issue that sometimes you you have to convince",
    "start": "1875290",
    "end": "1880450"
  },
  {
    "text": "people that it that it's it's worth it yeah the best example I can give there's like",
    "start": "1880450",
    "end": "1886600"
  },
  {
    "text": "yeah we always have a 5% overhead but this time percent overhead has allowed us to pinpoint performance issues that",
    "start": "1886600",
    "end": "1891910"
  },
  {
    "text": "have saved us 40 or 50 percent I think we've got any huge gains from things based on using this infrastructure so we",
    "start": "1891910",
    "end": "1897760"
  },
  {
    "text": "never added a spark 4% we fully stock way back and yeah a year ago and it was much much slower to give to spend a",
    "start": "1897760",
    "end": "1904870"
  },
  {
    "text": "little to win a lot cool great there's",
    "start": "1904870",
    "end": "1918370"
  },
  {
    "text": "one last thing that I didn't show is the heat profile which is another thing we've turned out more recently oh it's",
    "start": "1918370",
    "end": "1924310"
  },
  {
    "text": "not even on the servers we turned on so recently but the TC Milan keep sampling is one of these things it's not really",
    "start": "1924310",
    "end": "1930160"
  },
  {
    "text": "well advertised it's quite low overhead and I think probably our next release we're going to turn it on by default we",
    "start": "1930160",
    "end": "1937510"
  },
  {
    "text": "have a lot of our own having internal memory tracking to understand why our memory is going but sometimes we have this case where the customers like your",
    "start": "1937510",
    "end": "1944050"
  },
  {
    "text": "internal memory Jackson says you're using three gigs of memory but like the art static we're in the top is 16 gigs",
    "start": "1944050",
    "end": "1949990"
  },
  {
    "text": "where'd it all go and we don't really have any clue usually but with turning on the deep sampling thing even though",
    "start": "1949990",
    "end": "1955600"
  },
  {
    "text": "again it might be a 1% overhead will be able to answer those questions a lot better and when we first turned it on",
    "start": "1955600",
    "end": "1961000"
  },
  {
    "text": "and started looking at somewhere close with it we found huge wins over like hey why are we storing that thing don't even use that thing we're moving in and save",
    "start": "1961000",
    "end": "1967930"
  },
  {
    "text": "eight megabytes here is 16 megabytes there it adds up yeah makes sense",
    "start": "1967930",
    "end": "1978360"
  },
  {
    "text": "right any other questions for Todd looks like",
    "start": "1982610",
    "end": "1990660"
  },
  {
    "text": "that was it but that was a really great great presentation and we'll chop this up and put this on the web Todd for other people who are interested",
    "start": "1990660",
    "end": "1997500"
  },
  {
    "text": "in kudu to check out definitely seems if you're using kudu like this is like a",
    "start": "1997500",
    "end": "2002900"
  },
  {
    "text": "great rundown of all the things you can do with it yeah yeah I think the most advanced users would probably find use I",
    "start": "2002900",
    "end": "2008360"
  },
  {
    "text": "think a lot of users probably don't want to care about this doesn't just hope it works yeah we certainly use it on the",
    "start": "2008360",
    "end": "2013400"
  },
  {
    "text": "dev team alone although if anybody has any further questions feel free to come on the git er the open tracing Gator so",
    "start": "2013400",
    "end": "2019730"
  },
  {
    "text": "feel free to ping you there and I'll I'll check in later today awesome thank you thank you so much for inviting me",
    "start": "2019730",
    "end": "2026720"
  },
  {
    "text": "Ben thanks for having everybody thank you all right okay so uh back to our",
    "start": "2026720",
    "end": "2041210"
  },
  {
    "text": "regularly scheduled programming we've got a couple things on the agenda around",
    "start": "2041210",
    "end": "2046570"
  },
  {
    "text": "open tracing API questions first one",
    "start": "2046570",
    "end": "2052970"
  },
  {
    "text": "someone put on here a trace IDs fan ID how do we make a decision to proceed is",
    "start": "2052970",
    "end": "2060200"
  },
  {
    "text": "that URI yeah yeah what's the question",
    "start": "2060200",
    "end": "2065710"
  },
  {
    "text": "so I remember what's the status of the spec RC for this one but definitely",
    "start": "2065710",
    "end": "2071770"
  },
  {
    "text": "there's a lot of people keep asking and trying to open PRS in different language",
    "start": "2071770",
    "end": "2076850"
  },
  {
    "text": "recourse oh yeah I think we should just get moving on it I know just like with my team we've been",
    "start": "2076850",
    "end": "2084099"
  },
  {
    "text": "really focused on getting the scope and scope manager released for Python at the",
    "start": "2084099",
    "end": "2089378"
  },
  {
    "text": "door and so we haven't felt like we've personally had bandwidth to to also",
    "start": "2089379",
    "end": "2095648"
  },
  {
    "text": "release and manage this in other languages while that's going on so",
    "start": "2095649",
    "end": "2101050"
  },
  {
    "text": "that's honestly probably the holdup I don't supposed to go out this week",
    "start": "2101050",
    "end": "2106200"
  },
  {
    "text": "there's some final a little back and forth about naming conventions but",
    "start": "2106200",
    "end": "2113400"
  },
  {
    "text": "people in general seem satisfied with that API so my plan was as soon as that was out to start pushing on span and",
    "start": "2113400",
    "end": "2120849"
  },
  {
    "text": "trace ID my question is are we okay with",
    "start": "2120849",
    "end": "2126609"
  },
  {
    "text": "breaking the API in this case because it will be a break and change in many",
    "start": "2126609",
    "end": "2132550"
  },
  {
    "text": "languages right it's definitely in go and it may come it may clash with the",
    "start": "2132550",
    "end": "2137830"
  },
  {
    "text": "existing tracers already implementing those methods but potentially with different return types yeah so I would",
    "start": "2137830",
    "end": "2144820"
  },
  {
    "text": "say that there's like two issues there one it it's a breaking change for",
    "start": "2144820",
    "end": "2150040"
  },
  {
    "text": "tracing implementers but not a breaking change but it's it's a breaking change",
    "start": "2150040",
    "end": "2158230"
  },
  {
    "text": "this backwards compatible so you now have to expose these on your tracer and",
    "start": "2158230",
    "end": "2163240"
  },
  {
    "text": "issue a new version of your tracer but that tracer will conform to the older",
    "start": "2163240",
    "end": "2168520"
  },
  {
    "text": "API so it's not like you need to fork and maintain two versions and four users",
    "start": "2168520",
    "end": "2173830"
  },
  {
    "text": "of the code it's not a breaking change at all because it's simply an additive method so in that sense I think",
    "start": "2173830",
    "end": "2180609"
  },
  {
    "text": "everyone's fine with it being a breaking change because",
    "start": "2180609",
    "end": "2185650"
  },
  {
    "text": "it's it's more of a distant and minor update as opposed to a major break the",
    "start": "2185650",
    "end": "2193440"
  },
  {
    "text": "other issue that that's maybe more serious or harder to see is around",
    "start": "2193440",
    "end": "2198990"
  },
  {
    "text": "naming these methods should they be called trace ID and span ID or trace",
    "start": "2198990",
    "end": "2204609"
  },
  {
    "text": "identifier and span identifiers which is a big mouthful but definitely",
    "start": "2204609",
    "end": "2212290"
  },
  {
    "text": "it's the chances of a collision with a pre-existing pre-existing method that",
    "start": "2212290",
    "end": "2219160"
  },
  {
    "text": "returns something else we've seen one example of that which is the Mach tracer has Trey's ID and span ID and it returns",
    "start": "2219160",
    "end": "2226600"
  },
  {
    "text": "like a UN but we've been asking around",
    "start": "2226600",
    "end": "2231700"
  },
  {
    "text": "actual implementers and no one with a tracer currently binding to open tracing",
    "start": "2231700",
    "end": "2237010"
  },
  {
    "text": "has spoken up and said no that won't work so I think that's really the the final bike shed there there's been a lot",
    "start": "2237010",
    "end": "2244120"
  },
  {
    "text": "of push from everyone to be like Tracey ID and span ID are nice names let's and",
    "start": "2244120",
    "end": "2249190"
  },
  {
    "text": "it doesn't seem to mess up any real code so let's do it I am a little nervous that's a little",
    "start": "2249190",
    "end": "2256000"
  },
  {
    "text": "show up too late and say hey this messed with me it's not quite non-breaking",
    "start": "2256000",
    "end": "2261640"
  },
  {
    "text": "change because in the absence of this api's today people do cast to concrete",
    "start": "2261640",
    "end": "2268780"
  },
  {
    "text": "implementations and use those existing methods which may be returning different types so though the end user code will",
    "start": "2268780",
    "end": "2275830"
  },
  {
    "text": "be affected so that it's just that if you're casting I don't the only case",
    "start": "2275830",
    "end": "2281830"
  },
  {
    "text": "where this is potentially a breaking change would be if you literally had the",
    "start": "2281830",
    "end": "2286960"
  },
  {
    "text": "method trace ID and span ID with the same capitalization and everything else yeah which most most racers had I think",
    "start": "2286960",
    "end": "2295830"
  },
  {
    "text": "that that's that's been the question asking around like who literally has this method signature that returns",
    "start": "2295830",
    "end": "2302950"
  },
  {
    "text": "something else and and no one has spoken up saying that they do the the other answer is just to name it something",
    "start": "2302950",
    "end": "2309370"
  },
  {
    "text": "slightly different right I think that that's the final question has gets resolved if you call it just a slightly",
    "start": "2309370",
    "end": "2316630"
  },
  {
    "text": "different name then you massively reduced the chance of there being a",
    "start": "2316630",
    "end": "2322270"
  },
  {
    "text": "collision yeah no one called it trace identifier because that's really long to type it's just you now have this API",
    "start": "2322270",
    "end": "2329830"
  },
  {
    "text": "we're asking everyone to use and it's and it's got a funky method signature as",
    "start": "2329830",
    "end": "2336490"
  },
  {
    "text": "a result of this so really maybe it's like can we do a more exhaustive audit",
    "start": "2336490",
    "end": "2341920"
  },
  {
    "text": "of existing tracers that bind to open tracing and really get an active confirmation that it will",
    "start": "2341920",
    "end": "2349539"
  },
  {
    "text": "or will not be a problem well as far as Jager every single librarian Hagar had a",
    "start": "2349539",
    "end": "2354910"
  },
  {
    "text": "traced ID and span ID in the most idiomatic form for the language right so",
    "start": "2354910",
    "end": "2361240"
  },
  {
    "text": "in Ingo it would be like upper ID etc so definitely gonna have class and they",
    "start": "2361240",
    "end": "2367960"
  },
  {
    "text": "would return like native types rather than strings did you say something man we've got that question anywhere but you",
    "start": "2367960",
    "end": "2376150"
  },
  {
    "text": "said like Mach tracer had the same thing and I would assume most of the traces well then it's just a matter of calling",
    "start": "2376150",
    "end": "2383230"
  },
  {
    "text": "it just calling it something else I think that's that's the solution maybe",
    "start": "2383230",
    "end": "2391480"
  },
  {
    "text": "something that's not as long as identifiers for people who have to type",
    "start": "2391480",
    "end": "2397150"
  },
  {
    "text": "this out manually that's hard to remember how to spell and very long so I",
    "start": "2397150",
    "end": "2403299"
  },
  {
    "text": "really think that's that's what we need [Music] spanky trace key I'm fine with the",
    "start": "2403299",
    "end": "2412269"
  },
  {
    "text": "identify myself but yeah I mean good completion seriously who types this",
    "start": "2412269",
    "end": "2417640"
  },
  {
    "text": "stuff I did man I type it I can't",
    "start": "2417640",
    "end": "2422890"
  },
  {
    "text": "remember if the eye goes before the e or how many E's there are bad at typing and",
    "start": "2422890",
    "end": "2428859"
  },
  {
    "text": "have no code completion sometimes anyways I feel for people but it's also",
    "start": "2428859",
    "end": "2434109"
  },
  {
    "text": "very long on the screen I don't know let's not try to do the whole if mean I",
    "start": "2434109",
    "end": "2439839"
  },
  {
    "text": "think URIs question is like how you know this has been a known issue for a long long time some languages and and you",
    "start": "2439839",
    "end": "2447460"
  },
  {
    "text": "know the natives are getting restless and that there's like you know people file issues frequently about this and we",
    "start": "2447460",
    "end": "2453730"
  },
  {
    "text": "kind of concluded that we should add something but that we have made progress 10 I think you're accurately saying that",
    "start": "2453730",
    "end": "2459940"
  },
  {
    "text": "like there's basically resourcing issues we're doing this it seems like a simple change because conceptually it is that",
    "start": "2459940",
    "end": "2465549"
  },
  {
    "text": "like it does require a bunch of roll out care because of these issues that were",
    "start": "2465549",
    "end": "2471970"
  },
  {
    "text": "bringing up so I think the question is what's the next step I mean and now I would rather not if possibly get into",
    "start": "2471970",
    "end": "2477759"
  },
  {
    "text": "the discussions the PR discussion in this call or whatever event and we could be something where we mean the opening up",
    "start": "2477759",
    "end": "2483130"
  },
  {
    "text": "the PR without merging it in most languages is a very easy thing to do I",
    "start": "2483130",
    "end": "2489490"
  },
  {
    "text": "mean truly easy thing to do and it could be done you know like without getting everything",
    "start": "2489490",
    "end": "2495550"
  },
  {
    "text": "through opening the PRS advertising them soliciting comments from from you know",
    "start": "2495550",
    "end": "2501300"
  },
  {
    "text": "implementers that sort of thing could probably be done without a lot of tiny investment at least that's my two cents",
    "start": "2501300",
    "end": "2508270"
  },
  {
    "text": "and is the stuff that could be taking us here it would also allow people who are coming in and filing these issues to see",
    "start": "2508270",
    "end": "2514240"
  },
  {
    "text": "that in fact this is this is like there's something in motion I don't know how you feel about a time that I think",
    "start": "2514240",
    "end": "2519760"
  },
  {
    "text": "like did that stuff itself could be kind of paralyzed so to speak so it's gonna be a happy but remain open for a while",
    "start": "2519760",
    "end": "2525369"
  },
  {
    "text": "anyway just to make sure people see them and got a chance to comment I would",
    "start": "2525369",
    "end": "2531250"
  },
  {
    "text": "agree with that yeah and again my apologies for being uh you know maybe too focused on Python",
    "start": "2531250",
    "end": "2537520"
  },
  {
    "text": "right now but it's there has been a long-running PR about this we could essentially socialize it a bit more and",
    "start": "2537520",
    "end": "2544770"
  },
  {
    "text": "just kind of put it out there make tracking issues in every language and",
    "start": "2544770",
    "end": "2549869"
  },
  {
    "text": "kind of announce that it's coming but yeah I am I do think what you just said",
    "start": "2549869",
    "end": "2559119"
  },
  {
    "text": "does me around coming up with a different name for these things just to",
    "start": "2559119",
    "end": "2564160"
  },
  {
    "text": "make sure we don't collide so I think that's the final bike shed but but we should move on it very quickly once",
    "start": "2564160",
    "end": "2570550"
  },
  {
    "text": "we've resolved that I think if we go with the approach of just picking a name",
    "start": "2570550",
    "end": "2575770"
  },
  {
    "text": "that has a low chance of collision with anything that there's no reason why we",
    "start": "2575770",
    "end": "2581170"
  },
  {
    "text": "can't get a release candidate out in every language quickly and get people to",
    "start": "2581170",
    "end": "2586540"
  },
  {
    "text": "start binding to it so I think it'll move very quickly once once we do that",
    "start": "2586540",
    "end": "2592470"
  },
  {
    "text": "all right I will try to get moving on",
    "start": "2596549",
    "end": "2602890"
  },
  {
    "text": "that on Monday actually so and the new Python API should should be out probably",
    "start": "2602890",
    "end": "2609729"
  },
  {
    "text": "on Tuesday whoa okay so we've only got",
    "start": "2609729",
    "end": "2619710"
  },
  {
    "text": "about 12 minutes left on the call I wanted to bring up another issue that I",
    "start": "2619710",
    "end": "2626140"
  },
  {
    "text": "would like us to get moving on as well which is a sort of higher level API is",
    "start": "2626140",
    "end": "2633009"
  },
  {
    "text": "for scope management so I'm just going to share my screen real quick just to",
    "start": "2633009",
    "end": "2639869"
  },
  {
    "text": "make it clear what I'm talking about",
    "start": "2639869",
    "end": "2644338"
  },
  {
    "text": "okay presentation mode here so it mostly",
    "start": "2655229",
    "end": "2665140"
  },
  {
    "text": "comes down to having both scopes and spans so we added a sort of active span",
    "start": "2665140",
    "end": "2670690"
  },
  {
    "text": "concept to open tracing so that the tracer would be responsible for managing",
    "start": "2670690",
    "end": "2678609"
  },
  {
    "text": "which span was active in which context and if you have some kind of context",
    "start": "2678609",
    "end": "2683890"
  },
  {
    "text": "switching whether it be threads or some async level user land level thing the",
    "start": "2683890",
    "end": "2689769"
  },
  {
    "text": "the tracer would be tracking that using a span a scope manager so each context",
    "start": "2689769",
    "end": "2695410"
  },
  {
    "text": "that has a span is called scope and you can ask the scope manager for the",
    "start": "2695410",
    "end": "2704319"
  },
  {
    "text": "currently active scope and pull the span off of it scopes have to be closed when",
    "start": "2704319",
    "end": "2709869"
  },
  {
    "text": "they're done and that doesn't always necessarily line up with a span being",
    "start": "2709869",
    "end": "2715509"
  },
  {
    "text": "finished because you may be moving spans from context to context so you may make",
    "start": "2715509",
    "end": "2721599"
  },
  {
    "text": "a span active in one scope then close that scope move this span to another",
    "start": "2721599",
    "end": "2727269"
  },
  {
    "text": "scope so on and so forth so it seems that at a lower level there",
    "start": "2727269",
    "end": "2733720"
  },
  {
    "text": "is a need for for this extra concept of a scope manager but if you see here the",
    "start": "2733720",
    "end": "2743860"
  },
  {
    "text": "amount of code you have to write it's not totally onerous this is just two",
    "start": "2743860",
    "end": "2749350"
  },
  {
    "text": "simple functions start work which makes an active span and a scope puts a tag on",
    "start": "2749350",
    "end": "2755890"
  },
  {
    "text": "it and then you finish it and another function so you pull off the active scope maybe do a log and then close it",
    "start": "2755890",
    "end": "2763050"
  },
  {
    "text": "if you're writing library instrumentation framework instrumentation this usually doesn't",
    "start": "2763050",
    "end": "2768850"
  },
  {
    "text": "feel too onerous because you're writing code inside of a plug-in or an interceptor and most of the code you're",
    "start": "2768850",
    "end": "2775000"
  },
  {
    "text": "writing is really focused on on tracing this higher level concept so that",
    "start": "2775000",
    "end": "2780340"
  },
  {
    "text": "doesn't feel too bad however released to me it doesn't feel too bad but for",
    "start": "2780340",
    "end": "2786910"
  },
  {
    "text": "application developers if you're if start work and finish work contain a lot of application code and you're you're",
    "start": "2786910",
    "end": "2793480"
  },
  {
    "text": "doing quite a bit of this it gets onerous pretty fast it's also hard to",
    "start": "2793480",
    "end": "2799900"
  },
  {
    "text": "get application developers up to speed on your team because there's kind of these like extra concepts you know",
    "start": "2799900",
    "end": "2806110"
  },
  {
    "text": "you're saying build span start active but you don't get a span back you get a scope and then if you make the span",
    "start": "2806110",
    "end": "2815530"
  },
  {
    "text": "automatically finish when you close the scope that's nice but now you're saying",
    "start": "2815530",
    "end": "2821140"
  },
  {
    "text": "scope close at the end and you never touch the span there either so that this",
    "start": "2821140",
    "end": "2826510"
  },
  {
    "text": "has like some cognitive load that's sort of above and beyond the the simpler",
    "start": "2826510",
    "end": "2832000"
  },
  {
    "text": "model that we had initially envisioned so if you look at a simpler API if you",
    "start": "2832000",
    "end": "2840580"
  },
  {
    "text": "make some assumptions that you can make when you're writing application code such as the presence of a global tracer",
    "start": "2840580",
    "end": "2847500"
  },
  {
    "text": "you can make this a lot more declarative right it's possible to create an API",
    "start": "2847500",
    "end": "2853540"
  },
  {
    "text": "where you just say start a span and it's automatically made active and then you",
    "start": "2853540",
    "end": "2859630"
  },
  {
    "text": "can access it declaratively because you have access to a global tracer you don't even",
    "start": "2859630",
    "end": "2865029"
  },
  {
    "text": "necessarily have to track the tracer or do any kind of object chain object method chaining you could just say hey",
    "start": "2865029",
    "end": "2872170"
  },
  {
    "text": "tag the current span log on it and then when you're done you can say hey",
    "start": "2872170",
    "end": "2877209"
  },
  {
    "text": "justjust finish this thing so I'm not proposing this precise API I'm just",
    "start": "2877209",
    "end": "2882969"
  },
  {
    "text": "proposing that it should be possible to produce an API that's that's this simple",
    "start": "2882969",
    "end": "2889829"
  },
  {
    "text": "and in order to get application developers more comfortable I think as a",
    "start": "2889829",
    "end": "2895989"
  },
  {
    "text": "community we should push for for providing some more official",
    "start": "2895989",
    "end": "2901059"
  },
  {
    "text": "ergonomic API if not looking like this at least at least something with this",
    "start": "2901059",
    "end": "2906459"
  },
  {
    "text": "level of complexity so that's that's my pitch I'm gonna be pushing for this in",
    "start": "2906459",
    "end": "2914469"
  },
  {
    "text": "the cross-language working group starting next week as well but I was interested if anyone had comments on",
    "start": "2914469",
    "end": "2922930"
  },
  {
    "text": "this at this time or thoughts about how to do this or any kind of experience",
    "start": "2922930",
    "end": "2929410"
  },
  {
    "text": "reports from working with scopes in active spans in the field",
    "start": "2929410",
    "end": "2936059"
  },
  {
    "text": "well I was I have to say that man you from day to dog he had mentioned that he",
    "start": "2943110",
    "end": "2949770"
  },
  {
    "text": "would love to see something like this as well so I think this is something nice I",
    "start": "2949770",
    "end": "2955080"
  },
  {
    "text": "think it would require a bit of testing of course and refactoring and all that the thing is it's all a quick idea yeah",
    "start": "2955080",
    "end": "2965570"
  },
  {
    "text": "I've heard from several people who couldn't be on this call that they're very interested in something like this",
    "start": "2965570",
    "end": "2970850"
  },
  {
    "text": "so you know we'll have a discussion online on Gitter but there's also just",
    "start": "2970850",
    "end": "2977880"
  },
  {
    "text": "the sort of general issue of you know do we need scope scope managers that kind",
    "start": "2977880",
    "end": "2984150"
  },
  {
    "text": "of a thing Pavel I know you were asking about that do you have any thoughts on this okay",
    "start": "2984150",
    "end": "2993720"
  },
  {
    "text": "there pebble yes some years I don't have not that well I'm writing mostly",
    "start": "2993720",
    "end": "3002540"
  },
  {
    "text": "instrumentations and there I prefer to pass things explicitly around yeah you",
    "start": "3002540",
    "end": "3011120"
  },
  {
    "text": "haven't I think that's really hinges on whether you're talking about instrumenting stuff in library versus",
    "start": "3011120",
    "end": "3016730"
  },
  {
    "text": "just trying to get your work done as an application developer and these sorts of higher level abstractions I think make a",
    "start": "3016730",
    "end": "3024020"
  },
  {
    "text": "lot of sense for the latter where we want an easy mode type of experience but",
    "start": "3024020",
    "end": "3029720"
  },
  {
    "text": "as Pablo saying for you know very meticulous instrumentation of shared",
    "start": "3029720",
    "end": "3036560"
  },
  {
    "text": "libraries it probably makes more sense to avoid the Global's and stuff like that yeah I think a side effect of",
    "start": "3036560",
    "end": "3045350"
  },
  {
    "text": "making something like this more officious is is to make it clear that there would be two style guides when",
    "start": "3045350",
    "end": "3052820"
  },
  {
    "text": "you're writing instrumentation there's a style guide that talks about you know",
    "start": "3052820",
    "end": "3058670"
  },
  {
    "text": "don't presume a global tracer right always take in a tracer is an option and fall back to the global tracer it won't",
    "start": "3058670",
    "end": "3065270"
  },
  {
    "text": "give you one and basically you wouldn't get to use this this cleaner API because",
    "start": "3065270",
    "end": "3071870"
  },
  {
    "text": "this API makes a bunch of assumptions essentially the purpose of it is to high",
    "start": "3071870",
    "end": "3077269"
  },
  {
    "text": "scopes and some of those lower-level complexity that you actually need when you're writing trickier instrumentation",
    "start": "3077269",
    "end": "3083529"
  },
  {
    "text": "but but don't need in the most common use cases that application developers are hitting over and over again I would",
    "start": "3083529",
    "end": "3091939"
  },
  {
    "text": "have some comments to start and finish but tagging look looks very nice yeah",
    "start": "3091939",
    "end": "3099789"
  },
  {
    "text": "yeah start span finish span maybe but but the long basically the long and",
    "start": "3099789",
    "end": "3106819"
  },
  {
    "text": "short of it is can we take the scopes and scope managers and make that a concept that as an application developer",
    "start": "3106819",
    "end": "3112549"
  },
  {
    "text": "you never have to think about that you're not necessarily even aware that they exist until you get into some",
    "start": "3112549",
    "end": "3118369"
  },
  {
    "text": "tricky situation and then you dig into the docs and discover there's actually these lower level api's that you can use",
    "start": "3118369",
    "end": "3124130"
  },
  {
    "text": "to deal with those situations I mean maybe it's better idea to completely",
    "start": "3124130",
    "end": "3130729"
  },
  {
    "text": "leave out the start and finish and provide some API only to add metadata if",
    "start": "3130729",
    "end": "3136369"
  },
  {
    "text": "there is an active spanner or something active hmm yeah well let's have the",
    "start": "3136369",
    "end": "3143599"
  },
  {
    "text": "discussion on git er this is Mason mainly just a sort of advertisement to people that that we want to kind of get",
    "start": "3143599",
    "end": "3149390"
  },
  {
    "text": "moving on this and really we should have it you know in a forum where you know",
    "start": "3149390",
    "end": "3158269"
  },
  {
    "text": "people in time zones that aren't this can't make it to this call can participate in it but I would if people",
    "start": "3158269",
    "end": "3165619"
  },
  {
    "text": "have ideas about what this kind of API might look like or you know if they're",
    "start": "3165619",
    "end": "3171529"
  },
  {
    "text": "already working with application developers who have written something like this it would be great to start you",
    "start": "3171529",
    "end": "3178880"
  },
  {
    "text": "know some contribute oh that are experimenting with this one nice thing is I'm fairly certain we can write all",
    "start": "3178880",
    "end": "3185689"
  },
  {
    "text": "this without actually touching the tracer API that I think would be one of",
    "start": "3185689",
    "end": "3190729"
  },
  {
    "text": "the goals so there's a lot of room to sort of experiment with different approaches to this and contribute moving",
    "start": "3190729",
    "end": "3198919"
  },
  {
    "text": "on that one thing I want to add is when I saw there's an agenda I thought that would",
    "start": "3198919",
    "end": "3205369"
  },
  {
    "text": "be a different topic more about high-level API is for specific",
    "start": "3205369",
    "end": "3211219"
  },
  {
    "text": "operations like HTTP requests or database requests so which kind of I",
    "start": "3211219",
    "end": "3217420"
  },
  {
    "text": "mean works in a similar way that people often ask like for some standard way of",
    "start": "3217420",
    "end": "3223309"
  },
  {
    "text": "doing these things yes I definitely think we need those as well and that",
    "start": "3223309",
    "end": "3229759"
  },
  {
    "text": "could get get wrapped up in this for example if you see tag where we say some",
    "start": "3229759",
    "end": "3235460"
  },
  {
    "text": "tag key some tag value that's fine for your own custom tags but actually you",
    "start": "3235460",
    "end": "3242210"
  },
  {
    "text": "know going and finding the constants and kind of gluing them together when you want to do something like say you know",
    "start": "3242210",
    "end": "3249789"
  },
  {
    "text": "login error or an exception there are definitely there's definitely room for",
    "start": "3249789",
    "end": "3255430"
  },
  {
    "text": "you know higher level functions that that do all that work for you where you can just pass it the exception and not",
    "start": "3255430",
    "end": "3262549"
  },
  {
    "text": "have to think about how that translates into which keys and values should be stuck on to the span likewise for",
    "start": "3262549",
    "end": "3270979"
  },
  {
    "text": "something like HTTP requests database requests we could probably make",
    "start": "3270979",
    "end": "3277849"
  },
  {
    "text": "some more ergonomic calls that aren't creating a whole bunch of key value",
    "start": "3277849",
    "end": "3283309"
  },
  {
    "text": "pairs yeah another thought on this is that we you know in this discussion",
    "start": "3283309",
    "end": "3290239"
  },
  {
    "text": "earlier around traces span IDs we would need to make a change like that in some",
    "start": "3290239",
    "end": "3295579"
  },
  {
    "text": "kind of coordinated fashion across languages I think that for some of the higher level primitives they they",
    "start": "3295579",
    "end": "3301940"
  },
  {
    "text": "actually naturally should deviate from language to language like if you're working in a Ruby or rails environment",
    "start": "3301940",
    "end": "3307279"
  },
  {
    "text": "or something like that but types of primitives that you might want for convenience are actually different than what you'd want and go and so on so",
    "start": "3307279",
    "end": "3312979"
  },
  {
    "text": "forth and and that can actually make the stuff go bit faster I think when we have to do cross language stuff because I",
    "start": "3312979",
    "end": "3318769"
  },
  {
    "text": "think we're now dealing with like nine languages or something like that it's a bit daunting to start one those projects",
    "start": "3318769",
    "end": "3324170"
  },
  {
    "text": "knowing how much parallel work is going to have to take place and for this I hear you just mentioned around HTTP and",
    "start": "3324170",
    "end": "3330440"
  },
  {
    "text": "things like that I might need some coordination but for things that are the sugar just to make it easier to do simple things I can imagine that",
    "start": "3330440",
    "end": "3337130"
  },
  {
    "text": "happening you know in a decoupled way across languages and let language owners",
    "start": "3337130",
    "end": "3342259"
  },
  {
    "text": "make those decisions independently yeah",
    "start": "3342259",
    "end": "3347569"
  },
  {
    "text": "totally I think another way of thinking about this is there's been a lot and lot",
    "start": "3347569",
    "end": "3353479"
  },
  {
    "text": "of work of trying to figure out what is the correct low-level API for tracers to",
    "start": "3353479",
    "end": "3359239"
  },
  {
    "text": "bind to and that work has been slow going it's very difficult work but we're getting it feels to me getting to the",
    "start": "3359239",
    "end": "3365690"
  },
  {
    "text": "end of that and that's starting to gel up and now it's sort of time between",
    "start": "3365690",
    "end": "3371839"
  },
  {
    "text": "this kind of work and things like getting span and trace identifier is out",
    "start": "3371839",
    "end": "3377509"
  },
  {
    "text": "there to allow people to start building middleware and other things we're sort of moving up the stack to application",
    "start": "3377509",
    "end": "3384079"
  },
  {
    "text": "developer zone and things that they would like and that world is definitely",
    "start": "3384079",
    "end": "3390229"
  },
  {
    "text": "much more opinionated and nuanced and there's room even within a single language to have more than one way to to",
    "start": "3390229",
    "end": "3397670"
  },
  {
    "text": "do this I think we should probably offer some you know official version of this",
    "start": "3397670",
    "end": "3403460"
  },
  {
    "text": "at some point just to lower the cognitive overhead but I totally anticipate you know in Java there's some",
    "start": "3403460",
    "end": "3410779"
  },
  {
    "text": "people who may want to do this kind of thing with annotations some people who may want to do it using some other",
    "start": "3410779",
    "end": "3415999"
  },
  {
    "text": "declarative strategy like you said Ruby there's a lot of different metadata",
    "start": "3415999",
    "end": "3422569"
  },
  {
    "text": "magic approaches to doing things and what's great about doing these is",
    "start": "3422569",
    "end": "3428119"
  },
  {
    "text": "higher-level API is like not everyone has to agree you can have several different approaches here and they're",
    "start": "3428119",
    "end": "3433819"
  },
  {
    "text": "all complimentary with each other even within the same code base",
    "start": "3433819",
    "end": "3439538"
  },
  {
    "text": "and we're basically out of time so",
    "start": "3441190",
    "end": "3446349"
  },
  {
    "text": "unless anyone has any final comments on this I would suggest we retake these discussions to the cross-language Gitter",
    "start": "3446349",
    "end": "3453819"
  },
  {
    "text": "channel and continue them there",
    "start": "3453819",
    "end": "3457440"
  },
  {
    "text": "all right good call everyone will be seeing your lovely faces toe",
    "start": "3460390",
    "end": "3470559"
  }
]
[
  {
    "start": "0",
    "end": "10000"
  },
  {
    "text": "hi everyone thank you for joining us",
    "start": "80",
    "end": "2080"
  },
  {
    "text": "today it's our pleasure to present you",
    "start": "2080",
    "end": "4640"
  },
  {
    "text": "the elastic story of running spark on",
    "start": "4640",
    "end": "7120"
  },
  {
    "text": "kubernetes natively at massive skill for",
    "start": "7120",
    "end": "9840"
  },
  {
    "text": "apple",
    "start": "9840",
    "end": "10880"
  },
  {
    "start": "10000",
    "end": "66000"
  },
  {
    "text": "my name is bowen lee i lead the batch",
    "start": "10880",
    "end": "13440"
  },
  {
    "text": "processing and interactive analytics",
    "start": "13440",
    "end": "15839"
  },
  {
    "text": "areas of the apple am ammo",
    "start": "15839",
    "end": "18960"
  },
  {
    "text": "data platform",
    "start": "18960",
    "end": "20400"
  },
  {
    "text": "my team builds and operates called",
    "start": "20400",
    "end": "22480"
  },
  {
    "text": "native services like batch processing",
    "start": "22480",
    "end": "24960"
  },
  {
    "text": "powered by spark on kubernetes",
    "start": "24960",
    "end": "28160"
  },
  {
    "text": "interactive data science service with",
    "start": "28160",
    "end": "30320"
  },
  {
    "text": "interactive spark and jupiter",
    "start": "30320",
    "end": "33040"
  },
  {
    "text": "and interactive analytics service",
    "start": "33040",
    "end": "35680"
  },
  {
    "text": "powered by presto and trino",
    "start": "35680",
    "end": "38480"
  },
  {
    "text": "so we serve hundreds of data engineers",
    "start": "38480",
    "end": "41760"
  },
  {
    "text": "and scientists every day to improve our",
    "start": "41760",
    "end": "44480"
  },
  {
    "text": "ei and mml products like siri and apple",
    "start": "44480",
    "end": "47440"
  },
  {
    "text": "search with best-in-class data and",
    "start": "47440",
    "end": "49920"
  },
  {
    "text": "analytics and processing infrastructure",
    "start": "49920",
    "end": "53440"
  },
  {
    "text": "which how is an engineering from",
    "start": "53440",
    "end": "55360"
  },
  {
    "text": "engineer from my team who has been",
    "start": "55360",
    "end": "57120"
  },
  {
    "text": "focusing on how to run spark elastically",
    "start": "57120",
    "end": "59520"
  },
  {
    "text": "and cost efficiently on kubernetes",
    "start": "59520",
    "end": "62559"
  },
  {
    "text": "so here's the agenda today",
    "start": "62559",
    "end": "66559"
  },
  {
    "start": "66000",
    "end": "103000"
  },
  {
    "text": "we will first talk about the benefits of",
    "start": "67840",
    "end": "70159"
  },
  {
    "text": "cloud",
    "start": "70159",
    "end": "71200"
  },
  {
    "text": "and our design principles to elaborate",
    "start": "71200",
    "end": "74000"
  },
  {
    "text": "those cloud native characteristics",
    "start": "74000",
    "end": "76640"
  },
  {
    "text": "and then the architecture of our cloud",
    "start": "76640",
    "end": "79840"
  },
  {
    "text": "native spark on kubernetes platform",
    "start": "79840",
    "end": "83040"
  },
  {
    "text": "and why we need to like auto-scale",
    "start": "83040",
    "end": "86400"
  },
  {
    "text": "our spark service based on cost saving",
    "start": "86400",
    "end": "88799"
  },
  {
    "text": "and elasticity need now which i will",
    "start": "88799",
    "end": "92320"
  },
  {
    "text": "dive deep into design of the reactive",
    "start": "92320",
    "end": "94960"
  },
  {
    "text": "auto scaling",
    "start": "94960",
    "end": "96320"
  },
  {
    "text": "and the productionization of it",
    "start": "96320",
    "end": "98640"
  },
  {
    "text": "and our learnings and future work",
    "start": "98640",
    "end": "102880"
  },
  {
    "start": "103000",
    "end": "203000"
  },
  {
    "text": "sounds good",
    "start": "103040",
    "end": "104560"
  },
  {
    "text": "let's get",
    "start": "104560",
    "end": "106079"
  },
  {
    "text": "in there",
    "start": "106079",
    "end": "107439"
  },
  {
    "text": "so",
    "start": "107439",
    "end": "108640"
  },
  {
    "text": "um",
    "start": "108640",
    "end": "109920"
  },
  {
    "text": "you know why we are moving to cloud",
    "start": "109920",
    "end": "113439"
  },
  {
    "text": "it's this may not be a new topic but i",
    "start": "113439",
    "end": "116159"
  },
  {
    "text": "want to iterate our unique perspectives",
    "start": "116159",
    "end": "120159"
  },
  {
    "text": "um",
    "start": "120159",
    "end": "121680"
  },
  {
    "text": "so cloud and kubernetes can help solve",
    "start": "121680",
    "end": "124159"
  },
  {
    "text": "lots of the problems",
    "start": "124159",
    "end": "126079"
  },
  {
    "text": "of legacy infrastructure have for",
    "start": "126079",
    "end": "128879"
  },
  {
    "text": "example it is igel resources are",
    "start": "128879",
    "end": "131920"
  },
  {
    "text": "consumed on demand and the user can pay",
    "start": "131920",
    "end": "134800"
  },
  {
    "text": "as you go",
    "start": "134800",
    "end": "136239"
  },
  {
    "text": "second is elastic and scalable we can",
    "start": "136239",
    "end": "139680"
  },
  {
    "text": "acquire resources we need and return",
    "start": "139680",
    "end": "141840"
  },
  {
    "text": "them when we are done so that saves us",
    "start": "141840",
    "end": "144239"
  },
  {
    "text": "lots of money and the compute and the",
    "start": "144239",
    "end": "147120"
  },
  {
    "text": "storage are almost infinite skill",
    "start": "147120",
    "end": "151120"
  },
  {
    "text": "then kubernetes enables us to build",
    "start": "151120",
    "end": "153120"
  },
  {
    "text": "services in a container native way with",
    "start": "153120",
    "end": "155599"
  },
  {
    "text": "strong resource isolation so",
    "start": "155599",
    "end": "157840"
  },
  {
    "text": "users",
    "start": "157840",
    "end": "158879"
  },
  {
    "text": "workload only impact each other",
    "start": "158879",
    "end": "162959"
  },
  {
    "text": "this supports our like multi-tenancy and",
    "start": "162959",
    "end": "165280"
  },
  {
    "text": "isolation guarantees",
    "start": "165280",
    "end": "168080"
  },
  {
    "text": "with",
    "start": "168080",
    "end": "169360"
  },
  {
    "text": "cloud and kubernetes we can leverage",
    "start": "169360",
    "end": "171440"
  },
  {
    "text": "cognitive cutting-edge security",
    "start": "171440",
    "end": "173840"
  },
  {
    "text": "techniques to build a privacy first the",
    "start": "173840",
    "end": "176160"
  },
  {
    "text": "data infra",
    "start": "176160",
    "end": "177599"
  },
  {
    "text": "and lastly",
    "start": "177599",
    "end": "180159"
  },
  {
    "text": "you know kubernetes and the providers of",
    "start": "180159",
    "end": "183519"
  },
  {
    "text": "the cloud took away lots of those heavy",
    "start": "183519",
    "end": "185840"
  },
  {
    "text": "liftings from us which enabled our",
    "start": "185840",
    "end": "188159"
  },
  {
    "text": "developers to focus on building and",
    "start": "188159",
    "end": "190400"
  },
  {
    "text": "improve",
    "start": "190400",
    "end": "191360"
  },
  {
    "text": "business critical batch processing",
    "start": "191360",
    "end": "193519"
  },
  {
    "text": "service to achieve you know higher roi",
    "start": "193519",
    "end": "196800"
  },
  {
    "text": "so it's a no-brainer a couple years ago",
    "start": "196800",
    "end": "199120"
  },
  {
    "text": "for us to decide to all-in cloud and",
    "start": "199120",
    "end": "201519"
  },
  {
    "text": "kubernetes",
    "start": "201519",
    "end": "204239"
  },
  {
    "start": "203000",
    "end": "359000"
  },
  {
    "text": "with the benefits of cloud and",
    "start": "205280",
    "end": "206959"
  },
  {
    "text": "kubernetes in mind we set a few critical",
    "start": "206959",
    "end": "210239"
  },
  {
    "text": "design principles for ourselves when",
    "start": "210239",
    "end": "212640"
  },
  {
    "text": "designing the system",
    "start": "212640",
    "end": "215120"
  },
  {
    "text": "first we want to fully embrace public",
    "start": "215120",
    "end": "217519"
  },
  {
    "text": "cloud and cognitive way of thinking and",
    "start": "217519",
    "end": "220400"
  },
  {
    "text": "building infrastructure",
    "start": "220400",
    "end": "222239"
  },
  {
    "text": "that is quite a message a mindset change",
    "start": "222239",
    "end": "225519"
  },
  {
    "text": "for example",
    "start": "225519",
    "end": "227040"
  },
  {
    "text": "uh",
    "start": "227040",
    "end": "228319"
  },
  {
    "text": "you know in",
    "start": "228319",
    "end": "230720"
  },
  {
    "text": "the cloud native world when we want to",
    "start": "230720",
    "end": "233439"
  },
  {
    "text": "upgrade our infrastructure we don't have",
    "start": "233439",
    "end": "235439"
  },
  {
    "text": "to do any in-place upgrade which",
    "start": "235439",
    "end": "239519"
  },
  {
    "text": "expose a huge risk to our infrastructure",
    "start": "239519",
    "end": "241840"
  },
  {
    "text": "and our users right",
    "start": "241840",
    "end": "243599"
  },
  {
    "text": "in the new world we can just spin up a",
    "start": "243599",
    "end": "246159"
  },
  {
    "text": "completely new environment and gradually",
    "start": "246159",
    "end": "248400"
  },
  {
    "text": "roll traffic over",
    "start": "248400",
    "end": "250159"
  },
  {
    "text": "from our old environment to the new",
    "start": "250159",
    "end": "252080"
  },
  {
    "text": "environment and",
    "start": "252080",
    "end": "253560"
  },
  {
    "text": "instantaneously switch back if there's",
    "start": "253560",
    "end": "255760"
  },
  {
    "text": "an issue",
    "start": "255760",
    "end": "256799"
  },
  {
    "text": "so that's kind of flexibility is a huge",
    "start": "256799",
    "end": "259120"
  },
  {
    "text": "win for our devops",
    "start": "259120",
    "end": "262479"
  },
  {
    "text": "second everything should be",
    "start": "262479",
    "end": "264000"
  },
  {
    "text": "containerized for elasticity agility and",
    "start": "264000",
    "end": "267479"
  },
  {
    "text": "reproducibility",
    "start": "267479",
    "end": "269120"
  },
  {
    "text": "we aim to scale and replicate our infra",
    "start": "269120",
    "end": "271759"
  },
  {
    "text": "very fast to cater to business needs and",
    "start": "271759",
    "end": "275040"
  },
  {
    "text": "full containerization enables us to do",
    "start": "275040",
    "end": "277440"
  },
  {
    "text": "so",
    "start": "277440",
    "end": "278880"
  },
  {
    "text": "third compute and storage have to be",
    "start": "278880",
    "end": "281199"
  },
  {
    "text": "fully decoupled so they can scale",
    "start": "281199",
    "end": "283600"
  },
  {
    "text": "independently according to business",
    "start": "283600",
    "end": "285520"
  },
  {
    "text": "needs for example the shuffle data",
    "start": "285520",
    "end": "287840"
  },
  {
    "text": "science can vary significantly from",
    "start": "287840",
    "end": "290160"
  },
  {
    "text": "spark job to job and then we have to",
    "start": "290160",
    "end": "292400"
  },
  {
    "text": "build our own spark service",
    "start": "292400",
    "end": "294960"
  },
  {
    "text": "be able to handle that in a flexible way",
    "start": "294960",
    "end": "297600"
  },
  {
    "text": "rather than one-size-fit-all solution",
    "start": "297600",
    "end": "301199"
  },
  {
    "text": "the security and the privacy and user",
    "start": "301199",
    "end": "303120"
  },
  {
    "text": "experience",
    "start": "303120",
    "end": "304880"
  },
  {
    "text": "i'm talking about them together since",
    "start": "304880",
    "end": "306800"
  },
  {
    "text": "they are",
    "start": "306800",
    "end": "307720"
  },
  {
    "text": "related um",
    "start": "307720",
    "end": "311120"
  },
  {
    "text": "you know uh in our new infrastructure",
    "start": "311120",
    "end": "313280"
  },
  {
    "text": "security and privacy are first-class",
    "start": "313280",
    "end": "315680"
  },
  {
    "text": "citizens in the design stack and we",
    "start": "315680",
    "end": "318479"
  },
  {
    "text": "leverage fine-tuned",
    "start": "318479",
    "end": "320479"
  },
  {
    "text": "uh you know techniques like",
    "start": "320479",
    "end": "323600"
  },
  {
    "text": "rows policies to govern our data",
    "start": "323600",
    "end": "327120"
  },
  {
    "text": "services",
    "start": "327120",
    "end": "328240"
  },
  {
    "text": "and at the same time we still want to",
    "start": "328240",
    "end": "330000"
  },
  {
    "text": "make it super easy for users to run",
    "start": "330000",
    "end": "332560"
  },
  {
    "text": "smart jobs",
    "start": "332560",
    "end": "333919"
  },
  {
    "text": "by following those governance so instead",
    "start": "333919",
    "end": "336560"
  },
  {
    "text": "of having users to run spark submit",
    "start": "336560",
    "end": "339280"
  },
  {
    "text": "directly we expose a rest api that has",
    "start": "339280",
    "end": "342960"
  },
  {
    "text": "exactly the same parameters as spark",
    "start": "342960",
    "end": "345360"
  },
  {
    "text": "submit",
    "start": "345360",
    "end": "346400"
  },
  {
    "text": "so we can enforce security at the rest",
    "start": "346400",
    "end": "350000"
  },
  {
    "text": "api layer while still giving users a",
    "start": "350000",
    "end": "352639"
  },
  {
    "text": "very familiar development experience",
    "start": "352639",
    "end": "356800"
  },
  {
    "start": "359000",
    "end": "633000"
  },
  {
    "text": "last we have",
    "start": "363520",
    "end": "365360"
  },
  {
    "text": "apple internal distribution that we",
    "start": "365360",
    "end": "367919"
  },
  {
    "text": "decided to use",
    "start": "367919",
    "end": "370960"
  },
  {
    "text": "next i want to present our cloud native",
    "start": "372160",
    "end": "374639"
  },
  {
    "text": "elastic spark architecture",
    "start": "374639",
    "end": "376960"
  },
  {
    "text": "so",
    "start": "376960",
    "end": "378400"
  },
  {
    "text": "you know we can start from the data plan",
    "start": "378400",
    "end": "380880"
  },
  {
    "text": "where in the back end we have multiple",
    "start": "380880",
    "end": "383440"
  },
  {
    "text": "spar kubernetes cluster we use the spark",
    "start": "383440",
    "end": "386400"
  },
  {
    "text": "kubernetes operator to submit smart jobs",
    "start": "386400",
    "end": "389120"
  },
  {
    "text": "and manage these job life cycles",
    "start": "389120",
    "end": "391840"
  },
  {
    "text": "there are",
    "start": "391840",
    "end": "392800"
  },
  {
    "text": "a replica",
    "start": "392800",
    "end": "394720"
  },
  {
    "text": "set of spark operators so they can load",
    "start": "394720",
    "end": "397520"
  },
  {
    "text": "balance and achieve high availability",
    "start": "397520",
    "end": "400880"
  },
  {
    "text": "each tenant on this platform have their",
    "start": "400880",
    "end": "403919"
  },
  {
    "text": "own resource cues powered by apache",
    "start": "403919",
    "end": "406319"
  },
  {
    "text": "unicorn unicorn plays a few key roles",
    "start": "406319",
    "end": "409680"
  },
  {
    "text": "here",
    "start": "409680",
    "end": "410639"
  },
  {
    "text": "like it's",
    "start": "410639",
    "end": "412240"
  },
  {
    "text": "for example",
    "start": "412240",
    "end": "413599"
  },
  {
    "text": "uh",
    "start": "413599",
    "end": "414720"
  },
  {
    "text": "one is um it is a multi-tenancy support",
    "start": "414720",
    "end": "418240"
  },
  {
    "text": "and resource quotas each queue for each",
    "start": "418240",
    "end": "421199"
  },
  {
    "text": "tenant is fully isolated from one",
    "start": "421199",
    "end": "423360"
  },
  {
    "text": "another",
    "start": "423360",
    "end": "424560"
  },
  {
    "text": "second unicorn queue runs all the",
    "start": "424560",
    "end": "427039"
  },
  {
    "text": "resource scheduling for spark workload",
    "start": "427039",
    "end": "429840"
  },
  {
    "text": "you know from basic ones like gas",
    "start": "429840",
    "end": "431680"
  },
  {
    "text": "scheduling requirements to more advanced",
    "start": "431680",
    "end": "434400"
  },
  {
    "text": "scheduling policies like fifo",
    "start": "434400",
    "end": "437759"
  },
  {
    "text": "priority or preemption",
    "start": "437759",
    "end": "440160"
  },
  {
    "text": "lastly unicorn handles elasticity of the",
    "start": "440160",
    "end": "443759"
  },
  {
    "text": "queues by independently scaling",
    "start": "443759",
    "end": "445759"
  },
  {
    "text": "resources for each tenant",
    "start": "445759",
    "end": "448960"
  },
  {
    "text": "we have many of the expired clusters",
    "start": "448960",
    "end": "451919"
  },
  {
    "text": "uh in the back end",
    "start": "451919",
    "end": "453680"
  },
  {
    "text": "the multi-cluster and multi-cue strategy",
    "start": "453680",
    "end": "456000"
  },
  {
    "text": "pro provide us with many folds of",
    "start": "456000",
    "end": "458960"
  },
  {
    "text": "elasticity and linear scalability",
    "start": "458960",
    "end": "461199"
  },
  {
    "text": "without a single bottleneck",
    "start": "461199",
    "end": "465080"
  },
  {
    "text": "so in the control plane we built our own",
    "start": "465919",
    "end": "469280"
  },
  {
    "text": "spark service gateway which exposed the",
    "start": "469280",
    "end": "471680"
  },
  {
    "text": "rest api i mentioned before",
    "start": "471680",
    "end": "474639"
  },
  {
    "text": "it is itself is a container native and",
    "start": "474639",
    "end": "478160"
  },
  {
    "text": "can be deployed and skilled very easily",
    "start": "478160",
    "end": "480479"
  },
  {
    "text": "as a microservice on kubernetes",
    "start": "480479",
    "end": "483360"
  },
  {
    "text": "when submitting uh jobs through our",
    "start": "483360",
    "end": "487199"
  },
  {
    "text": "rest api users can specify additional",
    "start": "487199",
    "end": "490000"
  },
  {
    "text": "parameters like qname and the skate will",
    "start": "490000",
    "end": "493360"
  },
  {
    "text": "route the",
    "start": "493360",
    "end": "494720"
  },
  {
    "text": "job to the underlying queue",
    "start": "494720",
    "end": "497039"
  },
  {
    "text": "on the client side we provide rest api",
    "start": "497039",
    "end": "501039"
  },
  {
    "text": "a simple easy to use cli for users to",
    "start": "501039",
    "end": "504400"
  },
  {
    "text": "run jobs from terminal and a",
    "start": "504400",
    "end": "506479"
  },
  {
    "text": "corresponding airflow operator so users",
    "start": "506479",
    "end": "508960"
  },
  {
    "text": "can run scheduled jobs",
    "start": "508960",
    "end": "512318"
  },
  {
    "text": "we have also the data science service",
    "start": "514080",
    "end": "517120"
  },
  {
    "text": "where our data engineers quickly iterate",
    "start": "517120",
    "end": "519919"
  },
  {
    "text": "and build their spark etl pipeline and",
    "start": "519919",
    "end": "522719"
  },
  {
    "text": "data scientists build and train their",
    "start": "522719",
    "end": "524640"
  },
  {
    "text": "models interactively",
    "start": "524640",
    "end": "526720"
  },
  {
    "text": "we aim to share a unified backend",
    "start": "526720",
    "end": "529600"
  },
  {
    "text": "for the two spark services",
    "start": "529600",
    "end": "531839"
  },
  {
    "text": "so as you can see",
    "start": "531839",
    "end": "533760"
  },
  {
    "text": "our interactive spark workload that",
    "start": "533760",
    "end": "535920"
  },
  {
    "text": "comes from jupiter notebooks went",
    "start": "535920",
    "end": "537680"
  },
  {
    "text": "through its own interactive spark",
    "start": "537680",
    "end": "539920"
  },
  {
    "text": "gateway and workloads are running on the",
    "start": "539920",
    "end": "542480"
  },
  {
    "text": "same infra structure on the back end",
    "start": "542480",
    "end": "545440"
  },
  {
    "text": "this way we achieved the goal of reusing",
    "start": "545440",
    "end": "548080"
  },
  {
    "text": "most of our infra without reinventing",
    "start": "548080",
    "end": "550720"
  },
  {
    "text": "the wheel",
    "start": "550720",
    "end": "553199"
  },
  {
    "text": "lastly we closely collaborate with our",
    "start": "554399",
    "end": "557279"
  },
  {
    "text": "security and privacy team",
    "start": "557279",
    "end": "559519"
  },
  {
    "text": "and",
    "start": "559519",
    "end": "560399"
  },
  {
    "text": "observability team to develop and uh",
    "start": "560399",
    "end": "564480"
  },
  {
    "text": "integrate",
    "start": "564480",
    "end": "565680"
  },
  {
    "text": "on those two fronts in a",
    "start": "565680",
    "end": "570320"
  },
  {
    "text": "fully integrated way",
    "start": "570399",
    "end": "572240"
  },
  {
    "text": "so our spark service has been running in",
    "start": "572240",
    "end": "575120"
  },
  {
    "text": "production for a year so far",
    "start": "575120",
    "end": "578000"
  },
  {
    "text": "it currently supports many business",
    "start": "578000",
    "end": "580000"
  },
  {
    "text": "critical workload for apple aml",
    "start": "580000",
    "end": "584240"
  },
  {
    "text": "the development skill is massive we are",
    "start": "584240",
    "end": "586800"
  },
  {
    "text": "running hundreds of thousands of vcpus",
    "start": "586800",
    "end": "590160"
  },
  {
    "text": "and hundreds of terabytes memories with",
    "start": "590160",
    "end": "592640"
  },
  {
    "text": "supports you know hundreds of thousands",
    "start": "592640",
    "end": "594720"
  },
  {
    "text": "of smart jobs per week the job skill is",
    "start": "594720",
    "end": "598000"
  },
  {
    "text": "also very large",
    "start": "598000",
    "end": "600000"
  },
  {
    "text": "our users biggest jobs can consume",
    "start": "600000",
    "end": "602800"
  },
  {
    "text": "up to you know thousands of executors",
    "start": "602800",
    "end": "605440"
  },
  {
    "text": "and cpus at the same time as it runs for",
    "start": "605440",
    "end": "607839"
  },
  {
    "text": "hours",
    "start": "607839",
    "end": "610160"
  },
  {
    "text": "we have been very active contributors",
    "start": "610160",
    "end": "613839"
  },
  {
    "text": "to",
    "start": "613839",
    "end": "614640"
  },
  {
    "text": "the",
    "start": "614640",
    "end": "616640"
  },
  {
    "text": "unique apache unicorn project and have",
    "start": "616640",
    "end": "619279"
  },
  {
    "text": "grown commuters and pmcs organically",
    "start": "619279",
    "end": "622079"
  },
  {
    "text": "from the team",
    "start": "622079",
    "end": "623360"
  },
  {
    "text": "we are also planning to open source some",
    "start": "623360",
    "end": "626079"
  },
  {
    "text": "of the components in the stack",
    "start": "626079",
    "end": "629600"
  },
  {
    "text": "there being",
    "start": "630880",
    "end": "632640"
  },
  {
    "text": "super successful we initially have been",
    "start": "632640",
    "end": "634880"
  },
  {
    "start": "633000",
    "end": "711000"
  },
  {
    "text": "operating all the resources statically",
    "start": "634880",
    "end": "637120"
  },
  {
    "text": "for users",
    "start": "637120",
    "end": "638640"
  },
  {
    "text": "um for example our unicorn queues are of",
    "start": "638640",
    "end": "641360"
  },
  {
    "text": "static amount of resources and we see a",
    "start": "641360",
    "end": "643839"
  },
  {
    "text": "massive opportunity to make the stack",
    "start": "643839",
    "end": "646800"
  },
  {
    "text": "more elastic and",
    "start": "646800",
    "end": "649360"
  },
  {
    "text": "save cost",
    "start": "649360",
    "end": "651200"
  },
  {
    "text": "for example workload patterns",
    "start": "651200",
    "end": "653680"
  },
  {
    "text": "can vary from time to time in a week or",
    "start": "653680",
    "end": "656399"
  },
  {
    "text": "even during a day right and um",
    "start": "656399",
    "end": "661040"
  },
  {
    "text": "and they also vary quite a bit from use",
    "start": "661040",
    "end": "663360"
  },
  {
    "text": "case to use case for example from",
    "start": "663360",
    "end": "665360"
  },
  {
    "text": "running only scheduled jobs",
    "start": "665360",
    "end": "668079"
  },
  {
    "text": "to mostly ad hoc and interactive jobs or",
    "start": "668079",
    "end": "671760"
  },
  {
    "text": "mixed of both",
    "start": "671760",
    "end": "673360"
  },
  {
    "text": "or occasionally super large-scale",
    "start": "673360",
    "end": "675760"
  },
  {
    "text": "backfill jobs",
    "start": "675760",
    "end": "678640"
  },
  {
    "text": "when using a fixed amount of resources",
    "start": "678640",
    "end": "680800"
  },
  {
    "text": "it has to account for the max usage",
    "start": "680800",
    "end": "684079"
  },
  {
    "text": "and will cost waste so we have been",
    "start": "684079",
    "end": "687360"
  },
  {
    "text": "investing heavily into auto scaling",
    "start": "687360",
    "end": "689600"
  },
  {
    "text": "spark on kubernetes and have achieved",
    "start": "689600",
    "end": "692399"
  },
  {
    "text": "great results so far by cutting down",
    "start": "692399",
    "end": "694560"
  },
  {
    "text": "cost for our users by as much as",
    "start": "694560",
    "end": "697519"
  },
  {
    "text": "you know 70 to 80 percent on q",
    "start": "697519",
    "end": "700839"
  },
  {
    "text": "basis next i'll hand it over to huichol",
    "start": "700839",
    "end": "704640"
  },
  {
    "text": "to talk about how we achieved that and",
    "start": "704640",
    "end": "707600"
  },
  {
    "text": "our learnings and roadmap on that",
    "start": "707600",
    "end": "709600"
  },
  {
    "text": "direction",
    "start": "709600",
    "end": "712160"
  },
  {
    "text": "hi folks this is richard from aimil data",
    "start": "713120",
    "end": "716880"
  },
  {
    "text": "platform in apple now let me walk you",
    "start": "716880",
    "end": "719839"
  },
  {
    "text": "through the architecture and the design",
    "start": "719839",
    "end": "722240"
  },
  {
    "text": "of which is reactive auto scaling",
    "start": "722240",
    "end": "724320"
  },
  {
    "text": "feature in our cloud native spark",
    "start": "724320",
    "end": "727040"
  },
  {
    "text": "cluster we delivered recently",
    "start": "727040",
    "end": "731040"
  },
  {
    "start": "731000",
    "end": "886000"
  },
  {
    "text": "first of all let me talk about the auto",
    "start": "731040",
    "end": "733839"
  },
  {
    "text": "scaling cluster node groups layout",
    "start": "733839",
    "end": "737519"
  },
  {
    "text": "as a multi-tenant of the skating cluster",
    "start": "737519",
    "end": "740079"
  },
  {
    "text": "we provide physical isolation among",
    "start": "740079",
    "end": "743040"
  },
  {
    "text": "system components spark driver and the",
    "start": "743040",
    "end": "746480"
  },
  {
    "text": "sparca executors",
    "start": "746480",
    "end": "750079"
  },
  {
    "text": "and each of them are located in their",
    "start": "750240",
    "end": "753200"
  },
  {
    "text": "own node groups",
    "start": "753200",
    "end": "754880"
  },
  {
    "text": "here the system component including such",
    "start": "754880",
    "end": "757920"
  },
  {
    "text": "as node problem detector ingress",
    "start": "757920",
    "end": "761279"
  },
  {
    "text": "controller spark kubernetes operator",
    "start": "761279",
    "end": "764800"
  },
  {
    "text": "unicorn and so on",
    "start": "764800",
    "end": "768160"
  },
  {
    "text": "also by mapping different tenant queue",
    "start": "768160",
    "end": "770959"
  },
  {
    "text": "to their dedicated",
    "start": "770959",
    "end": "772480"
  },
  {
    "text": "executor node groups",
    "start": "772480",
    "end": "774480"
  },
  {
    "text": "we can oscillate different tenants from",
    "start": "774480",
    "end": "777279"
  },
  {
    "text": "each other",
    "start": "777279",
    "end": "778560"
  },
  {
    "text": "to minimize the potential impact and",
    "start": "778560",
    "end": "781760"
  },
  {
    "text": "also help us to generate the cost usage",
    "start": "781760",
    "end": "784720"
  },
  {
    "text": "reports per tenant very easily",
    "start": "784720",
    "end": "789040"
  },
  {
    "text": "we provide the mean capacity setting per",
    "start": "789360",
    "end": "791760"
  },
  {
    "text": "q so there is amount of guaranteed",
    "start": "791760",
    "end": "794320"
  },
  {
    "text": "machine that keeps running over there to",
    "start": "794320",
    "end": "796800"
  },
  {
    "text": "support the long running and the smaller",
    "start": "796800",
    "end": "798800"
  },
  {
    "text": "cadence in workload",
    "start": "798800",
    "end": "801279"
  },
  {
    "text": "the maximum capacity setting",
    "start": "801279",
    "end": "803600"
  },
  {
    "text": "can provide a guide reel for each queue",
    "start": "803600",
    "end": "806720"
  },
  {
    "text": "and workloads will be weighted in a",
    "start": "806720",
    "end": "808880"
  },
  {
    "text": "queue if they are exceeded the maximum",
    "start": "808880",
    "end": "811680"
  },
  {
    "text": "threshold until there are related",
    "start": "811680",
    "end": "814639"
  },
  {
    "text": "resources our scheduler find",
    "start": "814639",
    "end": "819040"
  },
  {
    "text": "this is",
    "start": "819839",
    "end": "821040"
  },
  {
    "text": "the workflow however clutter size being",
    "start": "821040",
    "end": "824399"
  },
  {
    "text": "changed based on the spark workloads per",
    "start": "824399",
    "end": "827199"
  },
  {
    "text": "node group",
    "start": "827199",
    "end": "828800"
  },
  {
    "text": "when users submit their job to our",
    "start": "828800",
    "end": "831440"
  },
  {
    "text": "gateway the skills service will create",
    "start": "831440",
    "end": "834800"
  },
  {
    "text": "the crd on the corresponding cluster",
    "start": "834800",
    "end": "837199"
  },
  {
    "text": "firstly",
    "start": "837199",
    "end": "838399"
  },
  {
    "text": "it will create the driver pause on",
    "start": "838399",
    "end": "840639"
  },
  {
    "text": "driver node group to make sure the job",
    "start": "840639",
    "end": "843440"
  },
  {
    "text": "can always be scheduled",
    "start": "843440",
    "end": "846000"
  },
  {
    "text": "and then x guild reports will be created",
    "start": "846000",
    "end": "849279"
  },
  {
    "text": "by spark operator in the pre-assigned",
    "start": "849279",
    "end": "852560"
  },
  {
    "text": "node group scheduled by",
    "start": "852560",
    "end": "854839"
  },
  {
    "text": "unicorn we can also",
    "start": "854839",
    "end": "857360"
  },
  {
    "text": "see once",
    "start": "857360",
    "end": "859120"
  },
  {
    "text": "kubernetes clutter auto scaler find the",
    "start": "859120",
    "end": "861519"
  },
  {
    "text": "pending part in whichever node group it",
    "start": "861519",
    "end": "864399"
  },
  {
    "text": "will talk to cloud provider to",
    "start": "864399",
    "end": "868160"
  },
  {
    "text": "scale out the suitable numbers of nodes",
    "start": "868160",
    "end": "871440"
  },
  {
    "text": "in the specified node group",
    "start": "871440",
    "end": "873839"
  },
  {
    "text": "here which is mapping to our unicode",
    "start": "873839",
    "end": "876240"
  },
  {
    "text": "resources queue",
    "start": "876240",
    "end": "878240"
  },
  {
    "text": "vice verse wants you to find that there",
    "start": "878240",
    "end": "881040"
  },
  {
    "text": "are idle nodes it will terminate the",
    "start": "881040",
    "end": "883519"
  },
  {
    "text": "node to save the cost",
    "start": "883519",
    "end": "887040"
  },
  {
    "start": "886000",
    "end": "1017000"
  },
  {
    "text": "beside this we also provide some",
    "start": "888000",
    "end": "890800"
  },
  {
    "text": "customized scanning control to our auto",
    "start": "890800",
    "end": "893600"
  },
  {
    "text": "scaling clusters",
    "start": "893600",
    "end": "895839"
  },
  {
    "text": "for skill in control",
    "start": "895839",
    "end": "898399"
  },
  {
    "text": "our backing will only apply the skill in",
    "start": "898399",
    "end": "902160"
  },
  {
    "text": "on executor node groups",
    "start": "902160",
    "end": "904639"
  },
  {
    "text": "and the scaling process will be",
    "start": "904639",
    "end": "906800"
  },
  {
    "text": "triggered only when no running executor",
    "start": "906800",
    "end": "909760"
  },
  {
    "text": "port on the node",
    "start": "909760",
    "end": "912959"
  },
  {
    "text": "we have enabled beam packing provided by",
    "start": "912959",
    "end": "915760"
  },
  {
    "text": "unicode to minimize the number of",
    "start": "915760",
    "end": "918480"
  },
  {
    "text": "instances to use",
    "start": "918480",
    "end": "920480"
  },
  {
    "text": "the default allocation policy of the",
    "start": "920480",
    "end": "922959"
  },
  {
    "text": "scheduler will try to evenly distribute",
    "start": "922959",
    "end": "926240"
  },
  {
    "text": "distribute the support to all the nodes",
    "start": "926240",
    "end": "929199"
  },
  {
    "text": "the bin packing policy can sort the list",
    "start": "929199",
    "end": "932000"
  },
  {
    "text": "of nodes by the amount of available",
    "start": "932000",
    "end": "934800"
  },
  {
    "text": "resources",
    "start": "934800",
    "end": "936000"
  },
  {
    "text": "so our scheduler can efficiently",
    "start": "936000",
    "end": "938560"
  },
  {
    "text": "allocate the parts to the",
    "start": "938560",
    "end": "940440"
  },
  {
    "text": "underutilized nodes firstly and zinc to",
    "start": "940440",
    "end": "943839"
  },
  {
    "text": "the idle nodes",
    "start": "943839",
    "end": "945839"
  },
  {
    "text": "so",
    "start": "945839",
    "end": "946639"
  },
  {
    "text": "cluster autoscaler can trigger the",
    "start": "946639",
    "end": "949120"
  },
  {
    "text": "scaling in a very efficient way",
    "start": "949120",
    "end": "953040"
  },
  {
    "text": "the the right hand are ec2 machine",
    "start": "953040",
    "end": "956240"
  },
  {
    "text": "utilization dashboard",
    "start": "956240",
    "end": "958639"
  },
  {
    "text": "the top one is the matrix of static",
    "start": "958639",
    "end": "961600"
  },
  {
    "text": "queue without beam packing we can see",
    "start": "961600",
    "end": "964639"
  },
  {
    "text": "most of cpu and memory utilization is",
    "start": "964639",
    "end": "967440"
  },
  {
    "text": "only around the template page only a few",
    "start": "967440",
    "end": "970480"
  },
  {
    "text": "of machines can approach to",
    "start": "970480",
    "end": "972639"
  },
  {
    "text": "45 days",
    "start": "972639",
    "end": "975199"
  },
  {
    "text": "the bottom dashboard is shows a matrix",
    "start": "975199",
    "end": "978320"
  },
  {
    "text": "after being able to be packing on auto",
    "start": "978320",
    "end": "980560"
  },
  {
    "text": "scaling cluster we can see there is a",
    "start": "980560",
    "end": "983519"
  },
  {
    "text": "pretty good usage rate on both the cpu",
    "start": "983519",
    "end": "986079"
  },
  {
    "text": "and memory compared to the massive",
    "start": "986079",
    "end": "988320"
  },
  {
    "text": "wasting before",
    "start": "988320",
    "end": "991120"
  },
  {
    "text": "regarding to the skill out control we",
    "start": "993279",
    "end": "996079"
  },
  {
    "text": "provide a skill out only feature to the",
    "start": "996079",
    "end": "998959"
  },
  {
    "text": "bucket driver node group which all our",
    "start": "998959",
    "end": "1001519"
  },
  {
    "text": "users always get their driver paws",
    "start": "1001519",
    "end": "1003920"
  },
  {
    "text": "launched so they also can check",
    "start": "1003920",
    "end": "1007040"
  },
  {
    "text": "their logs over there always",
    "start": "1007040",
    "end": "1010079"
  },
  {
    "text": "we also speed up the skill out latency",
    "start": "1010079",
    "end": "1013040"
  },
  {
    "text": "by tuning some spark configurations",
    "start": "1013040",
    "end": "1017600"
  },
  {
    "start": "1017000",
    "end": "1116000"
  },
  {
    "text": "now let me talk about our production",
    "start": "1017759",
    "end": "1020079"
  },
  {
    "text": "status with this new feature",
    "start": "1020079",
    "end": "1022959"
  },
  {
    "text": "till now we have embodied more",
    "start": "1022959",
    "end": "1026319"
  },
  {
    "text": "than",
    "start": "1026319",
    "end": "1027199"
  },
  {
    "text": "19 internal teams to our auto scaling",
    "start": "1027199",
    "end": "1030480"
  },
  {
    "text": "clusters for more than three months so",
    "start": "1030480",
    "end": "1033520"
  },
  {
    "text": "far",
    "start": "1033520",
    "end": "1034319"
  },
  {
    "text": "and the average cost saving range is",
    "start": "1034319",
    "end": "1038079"
  },
  {
    "text": "around from 20 percentage to 70",
    "start": "1038079",
    "end": "1041520"
  },
  {
    "text": "percentage",
    "start": "1041520",
    "end": "1044240"
  },
  {
    "text": "during migration we have found that",
    "start": "1044240",
    "end": "1047280"
  },
  {
    "text": "all skilling events works as expected",
    "start": "1047280",
    "end": "1050799"
  },
  {
    "text": "and the machine will not be removed as",
    "start": "1050799",
    "end": "1053200"
  },
  {
    "text": "long as there are running or active",
    "start": "1053200",
    "end": "1055440"
  },
  {
    "text": "specular parts",
    "start": "1055440",
    "end": "1057360"
  },
  {
    "text": "the scale out latency is consistent",
    "start": "1057360",
    "end": "1060640"
  },
  {
    "text": "which is keep lower than five minutes",
    "start": "1060640",
    "end": "1063520"
  },
  {
    "text": "here the maximum scale out range we are",
    "start": "1063520",
    "end": "1066880"
  },
  {
    "text": "talking about is from two to two hundred",
    "start": "1066880",
    "end": "1069760"
  },
  {
    "text": "machines",
    "start": "1069760",
    "end": "1071520"
  },
  {
    "text": "moreover auto scaling feature can work",
    "start": "1071520",
    "end": "1074160"
  },
  {
    "text": "with various uh type of resources usage",
    "start": "1074160",
    "end": "1078240"
  },
  {
    "text": "patterns such as",
    "start": "1078240",
    "end": "1080480"
  },
  {
    "text": "ad hoc etl and mixed patterns",
    "start": "1080480",
    "end": "1084400"
  },
  {
    "text": "meantime",
    "start": "1084400",
    "end": "1085679"
  },
  {
    "text": "we also found that compared to the",
    "start": "1085679",
    "end": "1087760"
  },
  {
    "text": "massive over provisioning approach",
    "start": "1087760",
    "end": "1089760"
  },
  {
    "text": "before",
    "start": "1089760",
    "end": "1090720"
  },
  {
    "text": "runtime of workloads with auto scaling",
    "start": "1090720",
    "end": "1093440"
  },
  {
    "text": "enables may increase however this is",
    "start": "1093440",
    "end": "1096640"
  },
  {
    "text": "expected which is due to the very good",
    "start": "1096640",
    "end": "1099120"
  },
  {
    "text": "usage rate of cpu and memory compared to",
    "start": "1099120",
    "end": "1101919"
  },
  {
    "text": "the maximum wasting before",
    "start": "1101919",
    "end": "1104160"
  },
  {
    "text": "given this user need to take this into",
    "start": "1104160",
    "end": "1107039"
  },
  {
    "text": "consideration and",
    "start": "1107039",
    "end": "1108880"
  },
  {
    "text": "optimize their jobs if there is a strict",
    "start": "1108880",
    "end": "1112320"
  },
  {
    "text": "data delivery time required",
    "start": "1112320",
    "end": "1116320"
  },
  {
    "start": "1116000",
    "end": "1191000"
  },
  {
    "text": "i know we have covered a lot in this",
    "start": "1117760",
    "end": "1120080"
  },
  {
    "text": "short time here are some key takeaways",
    "start": "1120080",
    "end": "1122480"
  },
  {
    "text": "dealing with develop and deliver this",
    "start": "1122480",
    "end": "1124720"
  },
  {
    "text": "new feature",
    "start": "1124720",
    "end": "1126000"
  },
  {
    "text": "on our platform",
    "start": "1126000",
    "end": "1128080"
  },
  {
    "text": "physical isolation and the ming max",
    "start": "1128080",
    "end": "1130080"
  },
  {
    "text": "capacity is very important per customer",
    "start": "1130080",
    "end": "1133600"
  },
  {
    "text": "requirements",
    "start": "1133600",
    "end": "1134880"
  },
  {
    "text": "we can leverage",
    "start": "1134880",
    "end": "1136880"
  },
  {
    "text": "node group mean and max settings and",
    "start": "1136880",
    "end": "1139600"
  },
  {
    "text": "unicode resources quarter setting",
    "start": "1139600",
    "end": "1141520"
  },
  {
    "text": "together to achieve this",
    "start": "1141520",
    "end": "1143760"
  },
  {
    "text": "it will help us to support budget based",
    "start": "1143760",
    "end": "1146400"
  },
  {
    "text": "control going forward",
    "start": "1146400",
    "end": "1148480"
  },
  {
    "text": "auto provides guarantees that no impact",
    "start": "1148480",
    "end": "1151679"
  },
  {
    "text": "to existing smart jobs when skilling",
    "start": "1151679",
    "end": "1154400"
  },
  {
    "text": "happens is the most important feature",
    "start": "1154400",
    "end": "1156880"
  },
  {
    "text": "for production jobs",
    "start": "1156880",
    "end": "1158880"
  },
  {
    "text": "we need to apply some customized skill",
    "start": "1158880",
    "end": "1162480"
  },
  {
    "text": "in control based on different node group",
    "start": "1162480",
    "end": "1164960"
  },
  {
    "text": "types to provide this guarantee",
    "start": "1164960",
    "end": "1167840"
  },
  {
    "text": "in time we also need enable pin packing",
    "start": "1167840",
    "end": "1171120"
  },
  {
    "text": "to improve its efficiency",
    "start": "1171120",
    "end": "1174480"
  },
  {
    "text": "the skill out latency is important to",
    "start": "1174480",
    "end": "1177520"
  },
  {
    "text": "large scale jobs",
    "start": "1177520",
    "end": "1179440"
  },
  {
    "text": "by using the dedicated driver node group",
    "start": "1179440",
    "end": "1182480"
  },
  {
    "text": "and the tuned",
    "start": "1182480",
    "end": "1184080"
  },
  {
    "text": "spark configurations we can keep the",
    "start": "1184080",
    "end": "1186320"
  },
  {
    "text": "scale out latency as low as possible",
    "start": "1186320",
    "end": "1191720"
  },
  {
    "start": "1191000",
    "end": "1250000"
  },
  {
    "text": "forward there are still lots of",
    "start": "1192240",
    "end": "1194240"
  },
  {
    "text": "improvement areas need to be explored",
    "start": "1194240",
    "end": "1197280"
  },
  {
    "text": "such as how to support mixed insulin",
    "start": "1197280",
    "end": "1200720"
  },
  {
    "text": "type per cluster and how to fully",
    "start": "1200720",
    "end": "1202960"
  },
  {
    "text": "support dynamic allocation",
    "start": "1202960",
    "end": "1206159"
  },
  {
    "text": "support instance",
    "start": "1206159",
    "end": "1207840"
  },
  {
    "text": "is much cheaper than on demand instance",
    "start": "1207840",
    "end": "1210880"
  },
  {
    "text": "which we are using right now",
    "start": "1210880",
    "end": "1213200"
  },
  {
    "text": "it will be another big win if we can",
    "start": "1213200",
    "end": "1215760"
  },
  {
    "text": "support it with the help of remote",
    "start": "1215760",
    "end": "1218000"
  },
  {
    "text": "shuffle services or similar",
    "start": "1218000",
    "end": "1220080"
  },
  {
    "text": "disaggregated",
    "start": "1220080",
    "end": "1222159"
  },
  {
    "text": "compute and storage architecture",
    "start": "1222159",
    "end": "1225039"
  },
  {
    "text": "then we can trigger the skill in",
    "start": "1225039",
    "end": "1227679"
  },
  {
    "text": "more aggressive and even separate the",
    "start": "1227679",
    "end": "1230720"
  },
  {
    "text": "computation and the storage",
    "start": "1230720",
    "end": "1232320"
  },
  {
    "text": "independently with different",
    "start": "1232320",
    "end": "1234480"
  },
  {
    "text": "off scaling control",
    "start": "1234480",
    "end": "1237520"
  },
  {
    "text": "in future how to provide a predictive",
    "start": "1237679",
    "end": "1240799"
  },
  {
    "text": "auto scaling feature to the platform is",
    "start": "1240799",
    "end": "1243360"
  },
  {
    "text": "another interesting topic",
    "start": "1243360",
    "end": "1246159"
  },
  {
    "text": "that's all today's sharing thanks for",
    "start": "1246159",
    "end": "1248480"
  },
  {
    "text": "your time",
    "start": "1248480",
    "end": "1251640"
  }
]
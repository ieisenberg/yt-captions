[
  {
    "text": "around 8:30",
    "start": "55600",
    "end": "59019"
  },
  {
    "text": "Raymond",
    "start": "62950",
    "end": "65950"
  },
  {
    "text": "good morning good evening",
    "start": "81539",
    "end": "84950"
  },
  {
    "text": "Tom good to see you good to see you as well",
    "start": "87740",
    "end": "94210"
  },
  {
    "text": "you",
    "start": "100440",
    "end": "102500"
  },
  {
    "text": "you",
    "start": "122880",
    "end": "124938"
  },
  {
    "text": "hey Ricardo I need to drop in a few minutes I have a conflicting meeting but",
    "start": "196450",
    "end": "202340"
  },
  {
    "text": "I just want to come in and say thank you for the for the work that your new team did on evaluating harbor I much",
    "start": "202340",
    "end": "209630"
  },
  {
    "text": "appreciate it hey yeah no problem yeah so then there",
    "start": "209630",
    "end": "214730"
  },
  {
    "text": "will be up to the TOC now you know to put it up for a vote for graduation",
    "start": "214730",
    "end": "222260"
  },
  {
    "text": "that is correct thank you for the recommendation yeah it's gonna go to",
    "start": "222260",
    "end": "227450"
  },
  {
    "text": "storage now or the c6 storage complete the review sad did it he added the",
    "start": "227450",
    "end": "233360"
  },
  {
    "text": "comments on their peer but he told easy and has no merge the periods or waiting for the merge okay cool but they did",
    "start": "233360",
    "end": "241130"
  },
  {
    "text": "complete the review okay awesome yeah I'll stay on for a few minutes and",
    "start": "241130",
    "end": "247819"
  },
  {
    "text": "then I'll jump off thank you cool no problem so yeah welcome everyone so we",
    "start": "247819",
    "end": "255799"
  },
  {
    "text": "have a you know presentation today I think that's the main item for Keita",
    "start": "255799",
    "end": "264169"
  },
  {
    "text": "so did I pronounce that right Keita or Kara or Keita how do you break either either works we generally go kada but",
    "start": "264169",
    "end": "271570"
  },
  {
    "text": "there's no official pronunciation guide okay cool yes it's Jeff yeah and he's gonna talk",
    "start": "271570",
    "end": "279650"
  },
  {
    "text": "about that and so yeah take it away perfect great and I assume I'm fine to",
    "start": "279650",
    "end": "285740"
  },
  {
    "text": "share my screen out yeah I'll go ahead and do that so that I can show some of",
    "start": "285740",
    "end": "291050"
  },
  {
    "text": "the slides and it's good to see we've got honor ed from Microsoft here tom from code it zippy Nick from Red Hat I'm",
    "start": "291050",
    "end": "297740"
  },
  {
    "text": "even probably missing a few other folks so thanks thanks all for joining I'd help answer questions as well",
    "start": "297740",
    "end": "303669"
  },
  {
    "text": "so I was I was evaluating why-why-why",
    "start": "303669",
    "end": "308889"
  },
  {
    "text": "videos things mirror my screen but it looks like you don't see a mirrored version only I do",
    "start": "308889",
    "end": "314080"
  },
  {
    "text": "this was my exploration this morning all right so we'll start with kata",
    "start": "314080",
    "end": "319349"
  },
  {
    "text": "event-driven autoscaler this is something that we are making it we've had a proposal open for the sandbox so I",
    "start": "319349",
    "end": "326499"
  },
  {
    "text": "just want to share a little bit about what it is and then answer any questions that you might have that can help and in",
    "start": "326499",
    "end": "332949"
  },
  {
    "text": "doing this previously I think it's mentioned we've we've made a similar presentation to the serverless workgroup",
    "start": "332949",
    "end": "338169"
  },
  {
    "text": "to a few folks there across SAT VMware whatever else and that went well but this was before the new the new kind",
    "start": "338169",
    "end": "345279"
  },
  {
    "text": "of policy happened with the sig so some of this might be repeated if you were at that presentation a few months ago so",
    "start": "345279",
    "end": "352360"
  },
  {
    "text": "some background and history here kaida was initially started by Microsoft in",
    "start": "352360",
    "end": "360400"
  },
  {
    "text": "Red Hat primarily for some background so I'm Jeff I'm a product manager of Microsoft Azure and when I'm not",
    "start": "360400",
    "end": "367210"
  },
  {
    "text": "focusing on open source and kubernetes stuff like ADA I'm helping manage and run the Azure",
    "start": "367210",
    "end": "372250"
  },
  {
    "text": "function service so Azure functions is Microsoft's service offering ican't ed",
    "start": "372250",
    "end": "377379"
  },
  {
    "text": "AWS lambda or gzp",
    "start": "377379",
    "end": "382629"
  },
  {
    "text": "and one thing that we had observed as a team is that we had developed some technology to help run functions and",
    "start": "382629",
    "end": "389919"
  },
  {
    "text": "scale them effectively but we had customers and users who are interested in using this site type of functionality",
    "start": "389919",
    "end": "395680"
  },
  {
    "text": "outside of Azure and and so we kind of looked at the kubernetes ecosystem in general we're like you know what there's",
    "start": "395680",
    "end": "402129"
  },
  {
    "text": "might be a gap here in terms of what's possible today and what we think is there so we we talked to a few folks and",
    "start": "402129",
    "end": "408580"
  },
  {
    "text": "and let me know to if other people only see a black screen thanks Tom for the way you know we see a black screen",
    "start": "408580",
    "end": "414250"
  },
  {
    "text": "windows black screen okay let me unshare thanks for flagging and see if re",
    "start": "414250",
    "end": "421000"
  },
  {
    "text": "sharing makes it happier again let me try one more time I'm not getting any",
    "start": "421000",
    "end": "427300"
  },
  {
    "text": "pop-ups from Mac telling me that it's unhappy is it still blind no Pete no okay great thanks for",
    "start": "427300",
    "end": "435039"
  },
  {
    "text": "flagging tom okay so we we reached out to a few folks",
    "start": "435039",
    "end": "441030"
  },
  {
    "text": "red hats and some of the folks on the call from Red Hat we're like yeah this this sounds interesting to do this event-driven scale way so kata at its",
    "start": "441030",
    "end": "447690"
  },
  {
    "text": "core is a component that can be installed in any kubernetes cluster that will enable your cluster to scale pods",
    "start": "447690",
    "end": "453750"
  },
  {
    "text": "and deployments and jobs even not just based on CPU and memory but based on",
    "start": "453750",
    "end": "459920"
  },
  {
    "text": "metrics that are being pulled from the event source so specifically in Azure functions we don't just scale based on",
    "start": "459920",
    "end": "466620"
  },
  {
    "text": "the CPU of your functions but we're actually proactively looking at the queue or the sequel database or whatever",
    "start": "466620",
    "end": "472470"
  },
  {
    "text": "else it might be in helping really rapidly scale your your functions as a result and so kata is doing something",
    "start": "472470",
    "end": "479730"
  },
  {
    "text": "very similar in a hopefully very seamless way so we wanted to make it very simple to wire up metrics from",
    "start": "479730",
    "end": "485490"
  },
  {
    "text": "event sources and plug those into things like the horizontal pod autoscaler we wanted the ability to scale down to zero",
    "start": "485490",
    "end": "491430"
  },
  {
    "text": "in the same way that as your functions users work into scaling to zero and saving resources we released this last",
    "start": "491430",
    "end": "499220"
  },
  {
    "text": "April around this time it went GA 1.0 at cube con in 2019 and we currently have",
    "start": "499220",
    "end": "505890"
  },
  {
    "text": "about 20 scalars to different sources like caca Postgres sequel Nats Prometheus a bunch of sources out of",
    "start": "505890",
    "end": "512520"
  },
  {
    "text": "Azure AWS and GCP so even before I do anything else I did want to show a quick demo just so that you can see what this",
    "start": "512520",
    "end": "520349"
  },
  {
    "text": "looks like this takes about 15 seconds so I have a kubernetes cluster the tardi",
    "start": "520350",
    "end": "526500"
  },
  {
    "text": "running and I have one container or one deployment that's in it and it's a",
    "start": "526500",
    "end": "532350"
  },
  {
    "text": "RabbitMQ consumer so this deployment I've said hey it's consuming RabbitMQ",
    "start": "532350",
    "end": "537360"
  },
  {
    "text": "messages and the one thing to note because Keita is installed and doing all of its stuff this is actually scaled all",
    "start": "537360",
    "end": "543090"
  },
  {
    "text": "the way to zero because Keita has let kubernetes know there's actually not any Q messages here to consume anyway so you",
    "start": "543090",
    "end": "550290"
  },
  {
    "text": "don't even need to consume the resources or reserve the resources to run this thing because there's nothing to be done",
    "start": "550290",
    "end": "555470"
  },
  {
    "text": "and I can show you if I just look at the k2 namespace you can just see it just",
    "start": "555470",
    "end": "561480"
  },
  {
    "text": "there's a k2 operator and then a metrics API server that's running and monitoring the stuff now if I go ahead and I",
    "start": "561480",
    "end": "570399"
  },
  {
    "text": "watch the pods this is my RabbitMQ server and now i'm going to deploy a job",
    "start": "570399",
    "end": "580170"
  },
  {
    "text": "which is going to publish a thousand messages to the queue so not just drop one message and it's actually going to",
    "start": "580170",
    "end": "586480"
  },
  {
    "text": "drop a thousand messages in so we should see that job spin up and it's creating and dropping a thousand messages in the",
    "start": "586480",
    "end": "592480"
  },
  {
    "text": "queue and what happens it's a result then is now kada has seen oh there is work to be done so now we have one",
    "start": "592480",
    "end": "598990"
  },
  {
    "text": "consumer that's come online right away but what's nice is that even before that sentence is finished you can see because",
    "start": "598990",
    "end": "605470"
  },
  {
    "text": "it wasn't just one message that I actually dropped in thousands of messages into that queue that very rapidly kata is actually driven this to",
    "start": "605470",
    "end": "612490"
  },
  {
    "text": "say hey I actually need to scale this RabbitMQ function a lot to make sure that I drain this really rapidly so this",
    "start": "612490",
    "end": "618970"
  },
  {
    "text": "kind of very proactive very event-driven scale is what kata is making possible and if I waited here for 30 45 seconds",
    "start": "618970",
    "end": "626949"
  },
  {
    "text": "it would finish scaling up consuming all the queue messages and then scale all the way back down to zero again so",
    "start": "626949",
    "end": "632410"
  },
  {
    "text": "that's that's kind of what kate is doing behind the scenes what's making it work is one of our core fundamental value",
    "start": "632410",
    "end": "641319"
  },
  {
    "text": "that we wanted to do when we built this that we set from the get-go and we've continued to stand by with our communities we didn't want to rebuild",
    "start": "641319",
    "end": "647559"
  },
  {
    "text": "anything that kubernetes already did and so behind the scenes how it works I showed you there's that kate operator",
    "start": "647559",
    "end": "652779"
  },
  {
    "text": "that's running it also has its metrics server which connects to the kubernetes metrics api's and then there's a number",
    "start": "652779",
    "end": "659949"
  },
  {
    "text": "of what are called scalars those are all the different event sources I mentioned Mike there's a rabbit and q1 a Kafka one",
    "start": "659949",
    "end": "665350"
  },
  {
    "text": "a post grows one a Prometheus one whatever about 20 of them and you end up",
    "start": "665350",
    "end": "671439"
  },
  {
    "text": "having your event source in the case of my demo was rabbitmq I think in the rest of the slides it's going to assume that",
    "start": "671439",
    "end": "677350"
  },
  {
    "text": "it's Kafka and so then you just deploy you create a deployment like you normally would so I just deployed using a kubernetes",
    "start": "677350",
    "end": "684670"
  },
  {
    "text": "deployment and then there's a special CRD the Keita exposes called a scaled object and this is really the metadata",
    "start": "684670",
    "end": "691149"
  },
  {
    "text": "of where you map your deployment where you map your job to the event source",
    "start": "691149",
    "end": "696279"
  },
  {
    "text": "that you care about so in this case I'm saying hey it's my deployment that I care about and I want you to scale based",
    "start": "696279",
    "end": "702549"
  },
  {
    "text": "on Kafka so here I provide a little bit of metadata for Keita to use I can configure things like how",
    "start": "702549",
    "end": "708040"
  },
  {
    "text": "frequently should K to check to see if there's messages to be processed I can also configure things like minimums and",
    "start": "708040",
    "end": "715030"
  },
  {
    "text": "maximums maybe I never want to scale all the way down to zero here I define my K I'm interested in Kafka here's how to",
    "start": "715030",
    "end": "721360"
  },
  {
    "text": "connect to Kafka I can set whatever info I need to there based on the event source and even some values here like in",
    "start": "721360",
    "end": "727330"
  },
  {
    "text": "this case with Kafka there's something called the lag threshold which is more or less setting the target for scale so",
    "start": "727330",
    "end": "733540"
  },
  {
    "text": "in this case 50 is saying for every 50 unprocessed messages in Kafka I want to target about 1 replicas and so if there",
    "start": "733540",
    "end": "741340"
  },
  {
    "text": "were a thousand messages it's gonna try to do what is that 50 replicas but if",
    "start": "741340",
    "end": "746800"
  },
  {
    "text": "there's only 50 messages it's only gonna target about 1 so if I make this number lower kate is gonna scale faster and",
    "start": "746800",
    "end": "752740"
  },
  {
    "text": "more aggressively if I make it higher it's gonna scale more conservatively so you have a bunch of knobs there to help",
    "start": "752740",
    "end": "757750"
  },
  {
    "text": "control this alright so you go ahead and apply that to your cluster kada picks up",
    "start": "757750",
    "end": "763780"
  },
  {
    "text": "that scaled object the k2 operator knows about the scaled object and you can see in the case of my slide I've even graded",
    "start": "763780",
    "end": "769810"
  },
  {
    "text": "out because it's like hey I can scale this thing to zero now because I know the Kafka event source is empty kate is",
    "start": "769810",
    "end": "775450"
  },
  {
    "text": "just doing this by wiring everything up automatically for you to the HPA so it's",
    "start": "775450",
    "end": "780460"
  },
  {
    "text": "not using its own autoscaler it's just augmenting the existing kubernetes ways to do this if a message pops in oh yeah",
    "start": "780460",
    "end": "788470"
  },
  {
    "text": "during this whole process and now it's just up to Keita to constantly be asking how many events are being generated so",
    "start": "788470",
    "end": "794620"
  },
  {
    "text": "it asks Kafka every polling interval and says hey are there unprocessed messages and if the answer's no then it keeps",
    "start": "794620",
    "end": "800890"
  },
  {
    "text": "this thing scaled down with the answer ends up being yes and just like I showed you you watch a pop-up and then",
    "start": "800890",
    "end": "806410"
  },
  {
    "text": "potentially scale out very rapidly so a few key features kind of based on the",
    "start": "806410",
    "end": "812200"
  },
  {
    "text": "demo in the architecture you can scale any deployment or job based on event metrics by defining that additional CRD",
    "start": "812200",
    "end": "819040"
  },
  {
    "text": "and we're just using kubernetes yardies to drive the experience that you scaled to and from zero based on events back",
    "start": "819040",
    "end": "826000"
  },
  {
    "text": "and forth it has 20 events or scalars built in it's completely extensible this",
    "start": "826000",
    "end": "832030"
  },
  {
    "text": "is the largest area of contribution and interest that we've seen are people adding these additional event sources",
    "start": "832030",
    "end": "838130"
  },
  {
    "text": "I mentioned kind of in passing you can also say hey maybe I have a long-running job maybe every cue message isn't just a",
    "start": "838130",
    "end": "844490"
  },
  {
    "text": "simple order I need to process maybe it's a video I need to transcode and so you can actually use a scale to object",
    "start": "844490",
    "end": "850670"
  },
  {
    "text": "mode where you say create a kubernetes job for every event that comes in which is a very useful model there's ways to",
    "start": "850670",
    "end": "858370"
  },
  {
    "text": "define authentication so we have ways to integrate with secrets with other",
    "start": "858370",
    "end": "863870"
  },
  {
    "text": "sources as well you can use pod identity if you're connecting to a cloud I did a",
    "start": "863870",
    "end": "869930"
  },
  {
    "text": "cloud provider so for instance if you're using like the Azure queue scaler kata",
    "start": "869930",
    "end": "875630"
  },
  {
    "text": "integrates with as your pod identity and so you don't even have to pass in a password it's just gonna use its own",
    "start": "875630",
    "end": "881180"
  },
  {
    "text": "identity to authenticate their support for that in AWS as well and really this",
    "start": "881180",
    "end": "886220"
  },
  {
    "text": "is about letting you focus on your app and not have to worry about the scaling internals manually wiring up the custom",
    "start": "886220",
    "end": "891500"
  },
  {
    "text": "metrics doing the work to do this manually kata just makes it as easy as defining that scaled object so in terms",
    "start": "891500",
    "end": "898279"
  },
  {
    "text": "of community we've been really happy and pleased with the amount of energy that's",
    "start": "898279",
    "end": "903649"
  },
  {
    "text": "happened around kata in its time so we've got about 2,000 stars on github a",
    "start": "903649",
    "end": "908870"
  },
  {
    "text": "number of contributors this is across large corporations as well Microsoft Red Hat IBM code at",
    "start": "908870",
    "end": "915079"
  },
  {
    "text": "astronomer i/o this is just the few that I pulled off the top of my kind of stand-up sheets there's there's much",
    "start": "915079",
    "end": "921139"
  },
  {
    "text": "more we have weekly stand-ups so from the get-go kata has there's nothing in kata that's branded Microsoft or branded",
    "start": "921139",
    "end": "928189"
  },
  {
    "text": "Red Hat this is something that we've wanted to be community driven so we have weekly stand-ups on zoom' we actually",
    "start": "928189",
    "end": "933500"
  },
  {
    "text": "have one coming up in about three hours there's a website that has a list of all",
    "start": "933500",
    "end": "938509"
  },
  {
    "text": "the scalars and a few users who are using it across their solutions to help",
    "start": "938509",
    "end": "944209"
  },
  {
    "text": "add some more stuff this was nice I just noticed when I was preparing a presentation there was even some folks",
    "start": "944209",
    "end": "949430"
  },
  {
    "text": "who were just tweeting like oh hey Keita this actually looks super interesting this looks like what we're looking for and then Richard chimed in it was like",
    "start": "949430",
    "end": "955759"
  },
  {
    "text": "yeah we've actually been using this in production for a while now so it's very simple like we didn't want to make this",
    "start": "955759",
    "end": "961009"
  },
  {
    "text": "a full complex doing 80 things it's really just driving that event-driven",
    "start": "961009",
    "end": "966470"
  },
  {
    "text": "scale but it does that very well so the last slide I have",
    "start": "966470",
    "end": "972110"
  },
  {
    "text": "is in terms of like why are we interested in the CNC F I mentioned already with kada our intent wasn't to",
    "start": "972110",
    "end": "979670"
  },
  {
    "text": "reinvent the wheel but it's really building on those standards and building on those technologies that are being",
    "start": "979670",
    "end": "984920"
  },
  {
    "text": "developed in the CNC F like kubernetes so it makes it a natural home our intent has always been to do this open and",
    "start": "984920",
    "end": "991519"
  },
  {
    "text": "community driven while it started with Microsoft and Red Hat in a partnership we really want to make this vendor",
    "start": "991519",
    "end": "997730"
  },
  {
    "text": "neutral in every way possible we feel like donating it to a foundation with CNC F is a way to show that good faith",
    "start": "997730",
    "end": "1004120"
  },
  {
    "text": "with the community it's already MIT license where we're planning if this becomes sandbox to use things like the",
    "start": "1004120",
    "end": "1010060"
  },
  {
    "text": "CNC F CL CL a contributor license all",
    "start": "1010060",
    "end": "1015339"
  },
  {
    "text": "those things there's there's no kind of we still want to hold on to this that or the other this is really our intent to",
    "start": "1015339",
    "end": "1020470"
  },
  {
    "text": "say we feel this is a useful piece of tech we've been using tech like this to run the Asscher function service this",
    "start": "1020470",
    "end": "1026980"
  },
  {
    "text": "has been in the open now for a while and we just want to go all bender neutral now kata also integrates very seamlessly with a number of other CNCs projects",
    "start": "1026980",
    "end": "1033579"
  },
  {
    "text": "things like the virtual cubelet to scale out into virtual nodes that scalars",
    "start": "1033579",
    "end": "1038589"
  },
  {
    "text": "Prometheus scalar streams easy scalars helm is the way we used to deploy it and",
    "start": "1038589",
    "end": "1044110"
  },
  {
    "text": "we're really looking for that vendor-neutral home for a key service capability specifically in the server l'espace I think serverless has this",
    "start": "1044110",
    "end": "1051280"
  },
  {
    "text": "connotation of being very vendor locked in and there's been some heated discussion about CN CF and service in",
    "start": "1051280",
    "end": "1057010"
  },
  {
    "text": "general we're really hoping that kata can be one of those very nice pieces of service in addition to things like cloud",
    "start": "1057010",
    "end": "1062500"
  },
  {
    "text": "events um that would tie in very neatly with the CN CF so that's all I really wanted to share I'll stop sharing here I",
    "start": "1062500",
    "end": "1068320"
  },
  {
    "text": "saw yeah a few comments I don't I think most of that is handled so I think I'll",
    "start": "1068320",
    "end": "1074169"
  },
  {
    "text": "just pause here if there's any questions or anything that you could use from us I'm more than happy to share more yeah",
    "start": "1074169",
    "end": "1079990"
  },
  {
    "text": "question zone scalars so is that a single processor or some multiple",
    "start": "1079990",
    "end": "1085140"
  },
  {
    "text": "processes running in kubernetes yeah so today we have there it can run in both",
    "start": "1085140",
    "end": "1092320"
  },
  {
    "text": "modes today the majority of our scalars are just running in that single process they come out of the box they're fairly",
    "start": "1092320",
    "end": "1099429"
  },
  {
    "text": "light rate like each scalar is about 30 lines of go code we have a way to make them all external and this is",
    "start": "1099429",
    "end": "1105789"
  },
  {
    "text": "actually something that we've had discussions about even as recently as last week stand-up which is like there's a world that you deploy kada",
    "start": "1105789",
    "end": "1112720"
  },
  {
    "text": "and that you kind of like check all the boxes for all the scalars that you want and now instead of getting just those two pods now you have 15 of them and",
    "start": "1112720",
    "end": "1119470"
  },
  {
    "text": "each one's doing its own scaling thing but we didn't want to make it too over overloaded so far so right now the",
    "start": "1119470",
    "end": "1125979"
  },
  {
    "text": "majority of them run in the shared process we do have ways for you to plug in external ones there's a few that only run externally and this is something",
    "start": "1125979",
    "end": "1133090"
  },
  {
    "text": "that we're still kind of evaluating with to make sure that we don't get the footprint too large we need to start to",
    "start": "1133090",
    "end": "1138099"
  },
  {
    "text": "version these more independently so we have the capability there there's some scalars that take advantage of it but",
    "start": "1138099",
    "end": "1143440"
  },
  {
    "text": "mostly for convenience we ship most of them just in the same process today I",
    "start": "1143440",
    "end": "1148479"
  },
  {
    "text": "mean that's not necessarily a bad thing just because I mean if you end up having",
    "start": "1148479",
    "end": "1154119"
  },
  {
    "text": "multiple processes for each scalar then you're using more resources but but like",
    "start": "1154119",
    "end": "1161019"
  },
  {
    "text": "you said they're lightweight right so so maybe yeah if you add or more processes",
    "start": "1161019",
    "end": "1166269"
  },
  {
    "text": "there then it wouldn't affect too much other yeah the workload in in a",
    "start": "1166269",
    "end": "1171340"
  },
  {
    "text": "kubernetes cluster yep great and I see one question in chat from Jay real quick",
    "start": "1171340",
    "end": "1177749"
  },
  {
    "text": "integration with cluster autoscaler not just the HPA so there's nothing directly",
    "start": "1177749",
    "end": "1183460"
  },
  {
    "text": "we do with cluster autoscaler as far as I understand though and I invite others to chime in how the cluster autoscaler",
    "start": "1183460",
    "end": "1189970"
  },
  {
    "text": "will work is it will look at what the HPA is scheduling and the resources that it's trying to schedule and then based",
    "start": "1189970",
    "end": "1196210"
  },
  {
    "text": "on that it can scale the cluster so I believe indirectly kathe would cause",
    "start": "1196210",
    "end": "1202720"
  },
  {
    "text": "your cluster to scale because Kate is gonna be telling HPA you need to add more resources the HPA is gonna be",
    "start": "1202720",
    "end": "1208720"
  },
  {
    "text": "scheduling those and then at one point the scheduler is gonna be I don't have the space to put all these things that",
    "start": "1208720",
    "end": "1215529"
  },
  {
    "text": "Kate is telling me to schedule and that would kick in the cluster autoscaler which would then scale my entire cluster so I believe they work directly this is",
    "start": "1215529",
    "end": "1221979"
  },
  {
    "text": "a common question though so I am pausing a little bit in case if your neck or others wanted the the reason I brought",
    "start": "1221979",
    "end": "1229509"
  },
  {
    "text": "this up is because cluster autoscaler only has the one catalyst for scale-up",
    "start": "1229509",
    "end": "1236470"
  },
  {
    "text": "right which is that pending pods are queued up and that obviously will talk",
    "start": "1236470",
    "end": "1242960"
  },
  {
    "text": "to the underlined cloud provider and cluster autoscaler and asked the auto scaling group or node node group or",
    "start": "1242960",
    "end": "1249470"
  },
  {
    "text": "whatever to expand one thing that we",
    "start": "1249470",
    "end": "1254570"
  },
  {
    "text": "hear a lot in cluster autoscaler is support for more predictive or scheduled",
    "start": "1254570",
    "end": "1263450"
  },
  {
    "text": "based scale-up if events so I was",
    "start": "1263450",
    "end": "1270140"
  },
  {
    "text": "thinking you know maybe since SCADA seems quite flexible in that regard in",
    "start": "1270140",
    "end": "1276800"
  },
  {
    "text": "in this wide choice of sort of the events that can trigger an action I was",
    "start": "1276800",
    "end": "1284840"
  },
  {
    "text": "thinking maybe it would be possible to integrate Kaito with cluster autoscaler and use the kata event sources as the",
    "start": "1284840",
    "end": "1294050"
  },
  {
    "text": "triggers for cluster autoscaler instead of just the pending pods queue but just makes it it honestly makes a ton of",
    "start": "1294050",
    "end": "1300500"
  },
  {
    "text": "sense I mean just briefly looking at the cluster autoscaler stuff and it does look that they are some metrics",
    "start": "1300500",
    "end": "1306680"
  },
  {
    "text": "maybe these are metrics it exposes but yeah I think that makes a ton of sense and even to your point of scheduling one",
    "start": "1306680",
    "end": "1312680"
  },
  {
    "text": "of the work streams that we've been funneling some resources into recently is kind of along the like I mentioned",
    "start": "1312680",
    "end": "1319070"
  },
  {
    "text": "it's predictive in the case or it's less reactive because it can actually see that hey there's a thousand messages in the queue let's do something and it",
    "start": "1319070",
    "end": "1325160"
  },
  {
    "text": "makes sense right maybe you said some threshold words like look if there's 10,000 things in the queue yeah go start",
    "start": "1325160",
    "end": "1330500"
  },
  {
    "text": "scheduling stuff but also go go scale there at the cluster thing right all right you know yeah if you know you're",
    "start": "1330500",
    "end": "1335630"
  },
  {
    "text": "doing you know hundred thousand batch jobs starting at noon you know like you can just predictably go and and increase",
    "start": "1335630",
    "end": "1344180"
  },
  {
    "text": "the number of worker nodes you know that's the that's the one that like Microsoft Research right now is",
    "start": "1344180",
    "end": "1349310"
  },
  {
    "text": "partnered there they're helping tweak some algorithms where their hope is that in addition to that like if it is every",
    "start": "1349310",
    "end": "1356270"
  },
  {
    "text": "Friday at five o'clock there's a thousand things that drop in the queue or I'm running some batch kata ideally",
    "start": "1356270",
    "end": "1361550"
  },
  {
    "text": "would be smart enough at Friday at 4:55 to be like look the queue still empty but I've seen this too many times to",
    "start": "1361550",
    "end": "1368000"
  },
  {
    "text": "know the the storms come right and so now let's go and crank up the cluster autoscaler quake",
    "start": "1368000",
    "end": "1373280"
  },
  {
    "text": "the HPA in in advance so i I think that makes a ton of sense I'd be interested to know what integrations exist today to",
    "start": "1373280",
    "end": "1378950"
  },
  {
    "text": "do the cluster auto-scaling stuff but there's nothing there's nothing fundamental die okay two works that would prevent any of that so I think",
    "start": "1378950",
    "end": "1384740"
  },
  {
    "text": "that's all within the line of thinking of how we've been approaching Keita as well great conversation you mentioned predictive scaling of the",
    "start": "1384740",
    "end": "1392390"
  },
  {
    "text": "cluster for example would would you be interested in having a history of autogas scaling that we string it or do",
    "start": "1392390",
    "end": "1400280"
  },
  {
    "text": "you just want to have a source to scale on at this point in time are you asking",
    "start": "1400280",
    "end": "1408140"
  },
  {
    "text": "me or Jeff yes no you sorry me generally I'm referring",
    "start": "1408140",
    "end": "1415970"
  },
  {
    "text": "to being able to change the trigger for",
    "start": "1415970",
    "end": "1421010"
  },
  {
    "text": "scale up from the single thing that currently is supported by cluster autoscaler which is that there are",
    "start": "1421010",
    "end": "1427490"
  },
  {
    "text": "pending pods in to be scheduled there are alternate events for cluster",
    "start": "1427490",
    "end": "1435170"
  },
  {
    "text": "autoscaler scaling down so you can do like custom metrics and stuff like that to trigger a scaled-down event but for",
    "start": "1435170",
    "end": "1444380"
  },
  {
    "text": "scaling up meaning you know increasing the number of worker nodes in the auto scaling group there's only one event",
    "start": "1444380",
    "end": "1451280"
  },
  {
    "text": "trigger as far as I know so that's that's why I was referring to okay thank",
    "start": "1451280",
    "end": "1456560"
  },
  {
    "text": "you yeah I think you you need both right so so one of the problems when you auto",
    "start": "1456560",
    "end": "1462530"
  },
  {
    "text": "scale is you end up thrashing or you may end up you know with more resources that",
    "start": "1462530",
    "end": "1470690"
  },
  {
    "text": "you actually want and then but but also you when just before you scale down you",
    "start": "1470690",
    "end": "1476510"
  },
  {
    "text": "want you want to know if there's something maybe or coming up or some event coming up in the next maybe ten",
    "start": "1476510",
    "end": "1482810"
  },
  {
    "text": "minutes so you want to keep your cluster up and running because let's say if it's ten minutes your event comes in and",
    "start": "1482810",
    "end": "1490010"
  },
  {
    "text": "you've already scaled down but now you're scaling back up right so we end up kind of thrashing in a way right so",
    "start": "1490010",
    "end": "1496400"
  },
  {
    "text": "it's going up and down and depending around this event so if you have a way to predict some of the the workloads",
    "start": "1496400",
    "end": "1502790"
  },
  {
    "text": "that are coming in a little bit later you might be able to smooth that and so I think that's one of the",
    "start": "1502790",
    "end": "1509230"
  },
  {
    "text": "concerns yes so so how it's paid up for now is that it's purely focused on the",
    "start": "1509230",
    "end": "1515500"
  },
  {
    "text": "application auto-scaling where we then rely on the club's the photo scaling to",
    "start": "1515500",
    "end": "1521080"
  },
  {
    "text": "make sure that there is enough capacity but maybe we shouldn't need also have a look if we can help on the the cluster",
    "start": "1521080",
    "end": "1527770"
  },
  {
    "text": "side of things but yeah we don't really have a LAN and they see there's a nice",
    "start": "1527770",
    "end": "1534790"
  },
  {
    "text": "question for you Jeff on gay native thank you I was busy creating a github",
    "start": "1534790",
    "end": "1541360"
  },
  {
    "text": "discussion issue around this conversation okay any relationship with",
    "start": "1541360",
    "end": "1546550"
  },
  {
    "text": "key native so a few things here that's that's worth noting in in general I",
    "start": "1546550",
    "end": "1552280"
  },
  {
    "text": "think the short answer is K native is a entire the idea of it is to be an entire",
    "start": "1552280",
    "end": "1558610"
  },
  {
    "text": "service platform so it comes with it does about 20 things out of the box kata",
    "start": "1558610",
    "end": "1563950"
  },
  {
    "text": "is just a very single purpose thing that's like I'm just gonna be doing event a scaling based on this kind of",
    "start": "1563950",
    "end": "1569440"
  },
  {
    "text": "pattern that I talked about so Kate is a much smaller scope just a single use component now that said it actually ties",
    "start": "1569440",
    "end": "1576070"
  },
  {
    "text": "in well with the K native story so one of the work streams that's kicked up as a result of the last cubic ongoing",
    "start": "1576070",
    "end": "1581380"
  },
  {
    "text": "window to actually have an active work stream with the K native group we're looking at ways that they can leverage",
    "start": "1581380",
    "end": "1586390"
  },
  {
    "text": "kada within K native to add some additional functionality for example in",
    "start": "1586390",
    "end": "1591760"
  },
  {
    "text": "K native there's a way to get event notifications when there's a kafka message there's a pull request right now",
    "start": "1591760",
    "end": "1597580"
  },
  {
    "text": "in the K native repo that says hey if we actually took a dependency on kada we could scale that thing down to zero",
    "start": "1597580",
    "end": "1603220"
  },
  {
    "text": "when Kafka is empty so there's some interesting stuff there in just this poling pattern in general and",
    "start": "1603220",
    "end": "1609040"
  },
  {
    "text": "integrating it more tightly with cañedo but directly there they're not really overlapping too much because kata is",
    "start": "1609040",
    "end": "1616060"
  },
  {
    "text": "this very single-use thing and K native is trying to do a bunch of other stuff but it is one important piece to a",
    "start": "1616060",
    "end": "1621340"
  },
  {
    "text": "service platform that we feel and there's additional things that Canada is",
    "start": "1621340",
    "end": "1626560"
  },
  {
    "text": "trying to accomplish in addition to that if that if that helps and thank you J",
    "start": "1626560",
    "end": "1633670"
  },
  {
    "text": "for flagging the AWS team I might ping you afterwards there's there's someone on our side to who's interested in some",
    "start": "1633670",
    "end": "1639970"
  },
  {
    "text": "of the deeper kubernetes integrations so i'm gonna see what we can do with this",
    "start": "1639970",
    "end": "1644980"
  },
  {
    "text": "cluster one so hopefully across that that answers on the kid native stuff to let me know if there's any other questions there so if you have K native",
    "start": "1644980",
    "end": "1655300"
  },
  {
    "text": "and Keita running on the sinking cluster they can you Auto scale functions in the",
    "start": "1655300",
    "end": "1664090"
  },
  {
    "text": "cluster or not or this is not supported yet I guess so there's two there's two",
    "start": "1664090",
    "end": "1669820"
  },
  {
    "text": "kind of ways of doing scaling I guess I'm trying to think of the K native",
    "start": "1669820",
    "end": "1676180"
  },
  {
    "text": "today does out of scaling it has its own custom autoscaler can also integrate with the HPA and how can a t'v generally works is",
    "start": "1676180",
    "end": "1683470"
  },
  {
    "text": "that everything that it's scaling is an HTTP request so it's either gonna be a",
    "start": "1683470",
    "end": "1689260"
  },
  {
    "text": "cloud event over HTTP or an HTTP or g RPC request from an application or from",
    "start": "1689260",
    "end": "1694390"
  },
  {
    "text": "a client or from overalls soak a native primarily optimizes scaling on today by looking at things like concurrency of",
    "start": "1694390",
    "end": "1699970"
  },
  {
    "text": "HTTP requests and then driving scale that way there's this thing behind the scenes as well that's taking kafka",
    "start": "1699970",
    "end": "1706900"
  },
  {
    "text": "events and turning them into cloud events over HTTP or g RPC they cater",
    "start": "1706900",
    "end": "1711970"
  },
  {
    "text": "might scale so kada approaches things slightly differently and the kada does not look at HTTP requests kate is",
    "start": "1711970",
    "end": "1718690"
  },
  {
    "text": "actually looking at the end event source so kada will look at Kafka or RabbitMQ or",
    "start": "1718690",
    "end": "1725080"
  },
  {
    "text": "Prometheus or whatever else in Drive scaling that way so you can auto scale today I think the reason that there's",
    "start": "1725080",
    "end": "1730540"
  },
  {
    "text": "interest from both sides both Canada and kada and understanding how we can bring things together is that the differences",
    "start": "1730540",
    "end": "1736360"
  },
  {
    "text": "in the trade-offs between both of those models of scaling only on HTTP and scaling based on the event source have",
    "start": "1736360",
    "end": "1742660"
  },
  {
    "text": "some differences both are valuable so the kind of long answer to your question",
    "start": "1742660",
    "end": "1747820"
  },
  {
    "text": "is you can do auto scaling and K native today but there are ways that you cannot auto scaling K native today the kata can",
    "start": "1747820",
    "end": "1755200"
  },
  {
    "text": "enable and the K native team is interested in lining that up and there are a lot of caves in that sentence so",
    "start": "1755200",
    "end": "1761290"
  },
  {
    "text": "it's a tongue twister actually I could also speak to that one a little bit so I",
    "start": "1761290",
    "end": "1767370"
  },
  {
    "text": "was originally so I work on Apache airflow and originally we were looking to use K native as our",
    "start": "1767370",
    "end": "1773770"
  },
  {
    "text": "auto-scaling system and what we found was that for long running tasks k native",
    "start": "1773770",
    "end": "1779200"
  },
  {
    "text": "is kind of not an optimal solution because you have to keep an HTTP request open the entire time that a task is",
    "start": "1779200",
    "end": "1786100"
  },
  {
    "text": "running so we were able to find that kata was a lot better suited for a more",
    "start": "1786100",
    "end": "1791320"
  },
  {
    "text": "asynchronous or worker based auto scaling system Thank You Daniel perfect",
    "start": "1791320",
    "end": "1797650"
  },
  {
    "text": "yeah that's that's an example too of like the when when everything's HTTP based versus the events for his base that's one of those trade-offs is like",
    "start": "1797650",
    "end": "1803680"
  },
  {
    "text": "long-running becomes a lot harder when you're trying to hold open an HTTP request for 20 minutes or whatever you",
    "start": "1803680",
    "end": "1809140"
  },
  {
    "text": "might need it or hours yep yeah that's",
    "start": "1809140",
    "end": "1818500"
  },
  {
    "text": "great so if we if when user how such can awful scenario so for example they would",
    "start": "1818500",
    "end": "1826480"
  },
  {
    "text": "like to scale out their deployment if it sounds some you wench Stoli they may didn't know the details of their for",
    "start": "1826480",
    "end": "1834220"
  },
  {
    "text": "Kiera or quenette hey you know so hours you know the or feature is similar I",
    "start": "1834220",
    "end": "1841780"
  },
  {
    "text": "I know there may be some technical detail may be different and so forward so wasn't wait was was your suggestion",
    "start": "1841780",
    "end": "1848410"
  },
  {
    "text": "to this user which kills issue to use Keaney Kida or which case he should use a key",
    "start": "1848410",
    "end": "1856150"
  },
  {
    "text": "net he'll you know then they know the detailed of you know did held some",
    "start": "1856150",
    "end": "1861340"
  },
  {
    "text": "technology for them or HTTP connection something idolize",
    "start": "1861340",
    "end": "1866360"
  },
  {
    "text": "yep yep and if I understand correctly just to kind of repeat the question it's with K Natives since you're connecting",
    "start": "1866360",
    "end": "1872690"
  },
  {
    "text": "directly to the event source the developer has to have knowledge of that event source and so what do you do in",
    "start": "1872690",
    "end": "1878270"
  },
  {
    "text": "the case where you don't want to have that direct knowledge of the event source I think there's a few different",
    "start": "1878270",
    "end": "1883810"
  },
  {
    "text": "answers to this one as well I think my initial thinking too is cloud events I",
    "start": "1883810",
    "end": "1888950"
  },
  {
    "text": "feel like it's a very good way that this has been solved even in the CNC F but being able to say hey at the end of the",
    "start": "1888950",
    "end": "1894650"
  },
  {
    "text": "day we're just gonna have events that you can subscribe to and scale from that kata could help scaling that indirectly",
    "start": "1894650",
    "end": "1900770"
  },
  {
    "text": "through some of the things like metrics of the amount of cloud events that are being generated but in some ways I'd",
    "start": "1900770",
    "end": "1907160"
  },
  {
    "text": "almost say there's there's a few ways",
    "start": "1907160",
    "end": "1912260"
  },
  {
    "text": "this could be something so K Native definitely can do that part like a native eventing specifically is all",
    "start": "1912260",
    "end": "1918380"
  },
  {
    "text": "about letting you subscribe without having any and knowledge of the event source there's a way that the azure",
    "start": "1918380",
    "end": "1924080"
  },
  {
    "text": "functions service like that we built our service service where we abstract that within the SDK that you actually deploy",
    "start": "1924080",
    "end": "1929780"
  },
  {
    "text": "so there's something called the azure functions runtime it abstracts a lot of the details of the underlying event",
    "start": "1929780",
    "end": "1936200"
  },
  {
    "text": "source and enables you to just write code but it's the container itself that's doing the abstraction it's not",
    "start": "1936200",
    "end": "1941240"
  },
  {
    "text": "some cloud event behind the scenes then the final answer is just cloud events in general so I think there's kind of three ways that you can cut it",
    "start": "1941240",
    "end": "1947210"
  },
  {
    "text": "different SDKs like the azure functions runtime Kay native and Cana dementing or",
    "start": "1947210",
    "end": "1952400"
  },
  {
    "text": "at the end of the day just using cloud event so it's a trade-off because it's one of those things too this is this is",
    "start": "1952400",
    "end": "1957650"
  },
  {
    "text": "one of the interesting discussions in the service community in general which is there's a push for how much do you",
    "start": "1957650",
    "end": "1963650"
  },
  {
    "text": "extract away the underlying event source from the developer and the benefit of it is the developer doesn't have to worry",
    "start": "1963650",
    "end": "1968990"
  },
  {
    "text": "about the underlying of that source but the downside of it is the developer can't take advantage of something that's",
    "start": "1968990",
    "end": "1974000"
  },
  {
    "text": "not a common denominator across multiple event sources so I think both are important sometimes I want to know it's",
    "start": "1974000",
    "end": "1979940"
  },
  {
    "text": "a Kafka stream that I'm connected to because I need to checkpoint and I need to do in order processing and I need to",
    "start": "1979940",
    "end": "1985430"
  },
  {
    "text": "do things that are Kafka specific other times I just know that there's a notification that happens to be coming",
    "start": "1985430",
    "end": "1991190"
  },
  {
    "text": "from Kafka but I just need to post something to slack cloud events works great there so there's room for both which is why I think there's room for",
    "start": "1991190",
    "end": "1997670"
  },
  {
    "text": "both the k2 style and the cloud and Canada style I don't think it's going to be a one-size-fits-all",
    "start": "1997670",
    "end": "2004899"
  },
  {
    "text": "okay okay okay sungkyu yeah",
    "start": "2005150",
    "end": "2010120"
  },
  {
    "text": "you",
    "start": "2013140",
    "end": "2015200"
  },
  {
    "text": "you do you have an integration also with some of the big data frameworks like",
    "start": "2018270",
    "end": "2024610"
  },
  {
    "text": "spark and Link or has there been any discussions about that I think I know",
    "start": "2024610",
    "end": "2033340"
  },
  {
    "text": "one of the someone doing big data stuff today is using kada but they're using it",
    "start": "2033340",
    "end": "2041200"
  },
  {
    "text": "before the like the spark layer and they're scaling based on I believe in",
    "start": "2041200",
    "end": "2046660"
  },
  {
    "text": "their case I Kafka is the theme that is filling up all of the data and then they're using Splunk to process those",
    "start": "2046660",
    "end": "2052540"
  },
  {
    "text": "events that originated from Kafka but then are going through different pipeline so they're using kata to grab it from the Kafka side and not from",
    "start": "2052540",
    "end": "2058990"
  },
  {
    "text": "Splunk directly so there's nothing to right there's no scalar today directly",
    "start": "2058990",
    "end": "2064240"
  },
  {
    "text": "that grabs any of those from something like a big data processing pipeline but the event source that's probably",
    "start": "2064240",
    "end": "2070570"
  },
  {
    "text": "funneling the data to that big data processing pipeline whether it's Kafka or something else than that that is a",
    "start": "2070570",
    "end": "2076870"
  },
  {
    "text": "supported scalar if that helps and I just wanted to add that we have added integrations with two databases my",
    "start": "2076870",
    "end": "2084520"
  },
  {
    "text": "sequel and Postgres so if you're",
    "start": "2084520",
    "end": "2089909"
  },
  {
    "text": "but-but-but yeah we don't as Jeff said we haven't yet added integrations with",
    "start": "2089910",
    "end": "2096879"
  },
  {
    "text": "spark and flunk but-but-but-but with rather the event sources that may be funneling data into",
    "start": "2096880",
    "end": "2102400"
  },
  {
    "text": "those",
    "start": "2102400",
    "end": "2104579"
  },
  {
    "text": "any other questions silence how do we",
    "start": "2123210",
    "end": "2138760"
  },
  {
    "text": "proceed after this meeting do you guys have to vote or how does that work I think you",
    "start": "2138760",
    "end": "2144760"
  },
  {
    "text": "need a consensus of two people from the sake yeah so if you can create a PR with",
    "start": "2144760",
    "end": "2156000"
  },
  {
    "text": "recommendations I mean from I mean based on what I see from years ago for sandbox",
    "start": "2156000",
    "end": "2161170"
  },
  {
    "text": "so I don't really have any major concerns but there's a template that we",
    "start": "2161170",
    "end": "2167890"
  },
  {
    "text": "follow right so I can show you what the template is and I think there's another PR that that we did for volcano and then",
    "start": "2167890",
    "end": "2177460"
  },
  {
    "text": "so basically we need to fill in all the details and and we'll go from there and",
    "start": "2177460",
    "end": "2182530"
  },
  {
    "text": "then after that we will take it up to the what will recommend the project and",
    "start": "2182530",
    "end": "2189280"
  },
  {
    "text": "this the TOC we'll take a vote to put",
    "start": "2189280",
    "end": "2194350"
  },
  {
    "text": "mine in sandbox and and and it needs a 2/3 vote and after that it will be in",
    "start": "2194350",
    "end": "2200230"
  },
  {
    "text": "sandbox okay so I thought the issue was the new approach but basically I just",
    "start": "2200230",
    "end": "2207310"
  },
  {
    "text": "take what is in the issue open up your and we'll take it from there yeah yeah",
    "start": "2207310",
    "end": "2214540"
  },
  {
    "text": "and let me know if in if they have any questions a minute about a template or anything or about any item so it's it's",
    "start": "2214540",
    "end": "2222310"
  },
  {
    "text": "a new process I mean it will just start to use it so we're just kind of like",
    "start": "2222310",
    "end": "2227910"
  },
  {
    "text": "trying it out and if there's if you have any suggestions or anything that might",
    "start": "2227910",
    "end": "2233560"
  },
  {
    "text": "not work out or you or you have any concerns just you know let me know yeah if you could maybe go to the issue and",
    "start": "2233560",
    "end": "2240130"
  },
  {
    "text": "post the latest template that I'm certainly using the correct one and then I can create the PR right tomorrow",
    "start": "2240130",
    "end": "2249990"
  },
  {
    "text": "yeah and I i pasted the PR for volcano because i know that's the one you reviewed two weeks ago do you open this",
    "start": "2249990",
    "end": "2257130"
  },
  {
    "text": "pore requesters this something that the the leads have sig runtime need to fill out this template and then we open the",
    "start": "2257130",
    "end": "2264420"
  },
  {
    "text": "pr and then you folks can add comments and then close it they say the ones they did in terms of it's it's more or less",
    "start": "2264420",
    "end": "2270660"
  },
  {
    "text": "kind of our PowerPoint presentation and markdown which is great like we've got the info but i don't know if we need to",
    "start": "2270660",
    "end": "2277619"
  },
  {
    "text": "put this together yeah you can open it BR and then people can chime in with comments or anything that they any",
    "start": "2277619",
    "end": "2284190"
  },
  {
    "text": "questions that they may have and and then the pr gets approved and basically",
    "start": "2284190",
    "end": "2289290"
  },
  {
    "text": "yeah and then we send it over after it gets approved emerge they're gonna send it over to the TOC okay it's the pr2 to",
    "start": "2289290",
    "end": "2297119"
  },
  {
    "text": "the sick runtime repo not the T&C right right right yeah okay yeah okay you know",
    "start": "2297119",
    "end": "2303240"
  },
  {
    "text": "I'll bring this up today and our stand up and then Tom and I can probably have this open by the end of day today it would be I don't know how long the TOC",
    "start": "2303240",
    "end": "2309570"
  },
  {
    "text": "and stuff works but I know anecdotally we've been hoping that this is something we can make some noise about assuming",
    "start": "2309570",
    "end": "2315990"
  },
  {
    "text": "all goes well and we get sign-off at Q Khan yeah but I I know that's a month away now and I don't know how quickly",
    "start": "2315990",
    "end": "2322349"
  },
  {
    "text": "the wheels turn in this new process yeah so yeah hopefully they can put it up for",
    "start": "2322349",
    "end": "2328290"
  },
  {
    "text": "vote before cube calm yeah we'll see we'll see what I mean sometimes",
    "start": "2328290",
    "end": "2333660"
  },
  {
    "text": "so the TC just got new three new members so you might actually need more votes now sir but oh no wait wait sorry I'm",
    "start": "2333660",
    "end": "2344070"
  },
  {
    "text": "talking about graduation my bad my bad my bad so for for sandbox you you need three",
    "start": "2344070",
    "end": "2351720"
  },
  {
    "text": "sponsors that's right remove so so there won't be a vote right so so you need to find so",
    "start": "2351720",
    "end": "2359670"
  },
  {
    "text": "after we do the recommendation and we'll fill in the pr then you find three",
    "start": "2359670",
    "end": "2365040"
  },
  {
    "text": "sponsors in the TOC and then they'll they'll basically say okay we're we want",
    "start": "2365040",
    "end": "2370950"
  },
  {
    "text": "this project to be in sandbox and and they take it from there and then they",
    "start": "2370950",
    "end": "2376500"
  },
  {
    "text": "put it in sandbox um but I don't know if it really needs a vote I know the graduation needs a vote right but",
    "start": "2376500",
    "end": "2382560"
  },
  {
    "text": "because we we were don't harbor right now for graduation but yeah do they have to be",
    "start": "2382560",
    "end": "2388540"
  },
  {
    "text": "as a TLC representative or contributor they have to be a TLC member right so so",
    "start": "2388540",
    "end": "2399160"
  },
  {
    "text": "I think we have we have two liaisons Brendon burns and Brian grant so you",
    "start": "2399160",
    "end": "2405100"
  },
  {
    "text": "could reach out to them and see if they want to sponsor the project right so and",
    "start": "2405100",
    "end": "2410260"
  },
  {
    "text": "then do you want us to do you want us to reach out because I know one of the things that I know it's a new process",
    "start": "2410260",
    "end": "2415990"
  },
  {
    "text": "initiative they're like hey if you go through the cig process that way you don't have to just go and poke TOC",
    "start": "2415990",
    "end": "2421750"
  },
  {
    "text": "members directly once this goes through do you do you is it best if we do kind of go find three members of the TOC and",
    "start": "2421750",
    "end": "2428740"
  },
  {
    "text": "we're like hey we presented for cigarette time here's the PR that got closed they gave us the recommendation",
    "start": "2428740",
    "end": "2433960"
  },
  {
    "text": "would you be willing to sponsor or is that something that you have names in mind that you'll flag and we can just kind of help answer questions no you",
    "start": "2433960",
    "end": "2442030"
  },
  {
    "text": "guys can go actually you get you guys can go in and ask TOC members rights first",
    "start": "2442030",
    "end": "2447070"
  },
  {
    "text": "for sponsors right so it's a yeah I mean we can I mean that's a sick we can help",
    "start": "2447070",
    "end": "2453340"
  },
  {
    "text": "out too and in terms of finding some more people if you need more sponsors",
    "start": "2453340",
    "end": "2458470"
  },
  {
    "text": "based on our recommendation but you you can also go in and in in contact some of",
    "start": "2458470",
    "end": "2465100"
  },
  {
    "text": "the TLC members and in you know and they can look at the presentation just recording and and based on that you know",
    "start": "2465100",
    "end": "2473620"
  },
  {
    "text": "they make a decision saying whether they want to sponsor the project or not right so okay yep it does thank you yeah yeah",
    "start": "2473620",
    "end": "2484270"
  },
  {
    "text": "so that will be the next step so in and yeah just file a PR and then some we can",
    "start": "2484270",
    "end": "2490000"
  },
  {
    "text": "get that moving hopefully we can find a sponsor for cube con",
    "start": "2490000",
    "end": "2496470"
  },
  {
    "text": "okay thank you",
    "start": "2496830",
    "end": "2500160"
  },
  {
    "text": "well thank you guys so I think the other items in the agenda are volcano that is",
    "start": "2503760",
    "end": "2510480"
  },
  {
    "text": "already merged then so that's looking for TV sponsors is what we're talking about so if you know if you know anybody",
    "start": "2510480",
    "end": "2517800"
  },
  {
    "text": "who like to sponsor volcano I think reach out to the TV member and",
    "start": "2517800",
    "end": "2524369"
  },
  {
    "text": "help out so we reached out to Brandon Brian grant or artist humiliations but",
    "start": "2524369",
    "end": "2530490"
  },
  {
    "text": "we haven't gotten a reply yet and then yeah and there's some new TLC members I",
    "start": "2530490",
    "end": "2537750"
  },
  {
    "text": "find that some of the new TLC members are a little bit more receptive because",
    "start": "2537750",
    "end": "2543750"
  },
  {
    "text": "they you know they just kind of want to learn more and they might be able to sponsor some of the newer projects and",
    "start": "2543750",
    "end": "2551460"
  },
  {
    "text": "then Harbor has already completed the review from sacred time and so that will",
    "start": "2551460",
    "end": "2559200"
  },
  {
    "text": "be set because it's a graduation so that would be a TOC vote right so Michael",
    "start": "2559200",
    "end": "2564420"
  },
  {
    "text": "Michael will he needs a review from sick storage and I don't know if you need to",
    "start": "2564420",
    "end": "2570720"
  },
  {
    "text": "review from sick security but after that them it will be sent out for a TOC vote",
    "start": "2570720",
    "end": "2577010"
  },
  {
    "text": "so cool anybody has anything else that they want to talk about anything related",
    "start": "2586040",
    "end": "2592350"
  },
  {
    "text": "to run time to keep calm to community",
    "start": "2592350",
    "end": "2597630"
  },
  {
    "text": "anything hey recall this this tau this",
    "start": "2597630",
    "end": "2604830"
  },
  {
    "text": "is tau from cutta cutta community and newly introduced sick run time last week",
    "start": "2604830",
    "end": "2610890"
  },
  {
    "text": "in the Cara SC this week hi sorry I wasn't there about to she",
    "start": "2610890",
    "end": "2617490"
  },
  {
    "text": "told me this is a bridge is very interesting for a group and I'm here to",
    "start": "2617490",
    "end": "2624780"
  },
  {
    "text": "learn about it and we we might have something new to present to present to",
    "start": "2624780",
    "end": "2632070"
  },
  {
    "text": "shoot for the for the sequencing runtime as in four simple simple thing but is it",
    "start": "2632070",
    "end": "2639629"
  },
  {
    "text": "slow reading now I so with just a heads",
    "start": "2639629",
    "end": "2644699"
  },
  {
    "text": "up and and and learning the process and see prepare for myself when when it",
    "start": "2644699",
    "end": "2652529"
  },
  {
    "text": "comes to to that so I'm happy to to",
    "start": "2652529",
    "end": "2657659"
  },
  {
    "text": "learn to watch de cada kata sandbox review and it's very very hurtful and",
    "start": "2657659",
    "end": "2663869"
  },
  {
    "text": "the process is is helping thank you yeah thank you for joining",
    "start": "2663869",
    "end": "2669179"
  },
  {
    "text": "yes so if you if you want to present anything or anything you want to add anything edge and topic you know feel",
    "start": "2669179",
    "end": "2675329"
  },
  {
    "text": "free to add it to the dock so we meet every two weeks not exactly and the first and the third",
    "start": "2675329",
    "end": "2682939"
  },
  {
    "text": "Thursday of the month like so any item that you want to add feel free to add it",
    "start": "2682939",
    "end": "2690779"
  },
  {
    "text": "there and and then we can discuss in in the meetings to be a presentation or any",
    "start": "2690779",
    "end": "2697409"
  },
  {
    "text": "concerns any concerns about projects I know I mean we're just getting started",
    "start": "2697409",
    "end": "2703919"
  },
  {
    "text": "this is you know it's been around for maybe month and a half six security for",
    "start": "2703919",
    "end": "2709019"
  },
  {
    "text": "example has a lot of other stuff you know for example they have security security reviews or projects but then",
    "start": "2709019",
    "end": "2718559"
  },
  {
    "text": "that I mean that's outside the scope of this group but anything may be related",
    "start": "2718559",
    "end": "2724349"
  },
  {
    "text": "to runtime review or you know maybe a I",
    "start": "2724349",
    "end": "2731909"
  },
  {
    "text": "type of workloads high performance type of workloads you know it's it's within",
    "start": "2731909",
    "end": "2736919"
  },
  {
    "text": "the scope of the book okay thank you [Music]",
    "start": "2736919",
    "end": "2744859"
  },
  {
    "text": "Mazhar any documentation how they process the entire process for incurring",
    "start": "2744859",
    "end": "2751970"
  },
  {
    "text": "sandbox stage for project yeah that's that's documented all on the CNCs TOC",
    "start": "2751970",
    "end": "2761819"
  },
  {
    "text": "github page so there's plenty of",
    "start": "2761819",
    "end": "2769259"
  },
  {
    "text": "documentation there how the sandbox incubation and graduation process works",
    "start": "2769259",
    "end": "2774680"
  },
  {
    "text": "and then you know how you take it up to the six now so used to be before that it",
    "start": "2774680",
    "end": "2780210"
  },
  {
    "text": "would the projects who got directly to the TOC but the reason they're creating this six is because there there's a lot",
    "start": "2780210",
    "end": "2786539"
  },
  {
    "text": "more projects so they're trying to scale and into different areas so obviously",
    "start": "2786539",
    "end": "2791579"
  },
  {
    "text": "they have run time now they have observability they have security app",
    "start": "2791579",
    "end": "2797940"
  },
  {
    "text": "delivery and storage so and I think there's another group in the works called contributor experience and that",
    "start": "2797940",
    "end": "2806549"
  },
  {
    "text": "that double-deal more about how I mean helping our contributors in the community nowadays thank you yep all",
    "start": "2806549",
    "end": "2820049"
  },
  {
    "text": "right guys so in anything else nope",
    "start": "2820049",
    "end": "2826140"
  },
  {
    "text": "thank you very much for your time and we'll open up a lot more already all",
    "start": "2826140",
    "end": "2831989"
  },
  {
    "text": "right thank you all right bye guys Thanks thank you",
    "start": "2831989",
    "end": "2839690"
  }
]
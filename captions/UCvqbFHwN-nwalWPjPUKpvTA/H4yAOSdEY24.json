[
  {
    "start": "0",
    "end": "28000"
  },
  {
    "text": "good afternoon or good morning everyone sorry we're getting started a little bit late our microphones disappeared so",
    "start": "0",
    "end": "7940"
  },
  {
    "text": "but we're ready now so I'm a pronoun Sena product manager",
    "start": "7940",
    "end": "13440"
  },
  {
    "text": "for kubernetes and Google container engine at Google and we have Robert",
    "start": "13440",
    "end": "18840"
  },
  {
    "text": "Bailey he'll be joining me for this talk he's a staff engineer on Google container engine as well",
    "start": "18840",
    "end": "24410"
  },
  {
    "text": "[Music] so I think you know everyone here knows",
    "start": "24410",
    "end": "30990"
  },
  {
    "start": "28000",
    "end": "78000"
  },
  {
    "text": "that kubernetes is a platform that runs across different different types of",
    "start": "30990",
    "end": "36210"
  },
  {
    "text": "clouds and has broad industry adoption obviously this was something that was a project that initiated at Google and is",
    "start": "36210",
    "end": "44160"
  },
  {
    "text": "open source and has a booming community around it but also there is a hosted",
    "start": "44160",
    "end": "51329"
  },
  {
    "text": "version of kubernetes at Google on Google's cloud and that is what we call Google container engine and it kind of",
    "start": "51329",
    "end": "58079"
  },
  {
    "text": "serves as a reference implementation it also provides feedback back to the community about features and so we're",
    "start": "58079",
    "end": "65670"
  },
  {
    "text": "going to talk about Google container engine today some of the customer architectures and some of the feedback",
    "start": "65670",
    "end": "71820"
  },
  {
    "text": "and features that customers use kubernetes features that they use on container engine",
    "start": "71820",
    "end": "78380"
  },
  {
    "start": "78000",
    "end": "123000"
  },
  {
    "text": "so first of all Google hosts and operates the open source kubernetes code",
    "start": "79670",
    "end": "85439"
  },
  {
    "text": "on virtual machines in Google's compute engine platform which is our VM",
    "start": "85439",
    "end": "92460"
  },
  {
    "text": "offering and it is pretty much pure open-source and it is something that",
    "start": "92460",
    "end": "99810"
  },
  {
    "text": "releases within a few days of the open source kubernetes release also as of the last release we are",
    "start": "99810",
    "end": "108509"
  },
  {
    "text": "offering alpha-alpha clusters where you can test out alpha features so really",
    "start": "108509",
    "end": "113759"
  },
  {
    "text": "enables the fastest way to try out and also the easiest way to try out",
    "start": "113759",
    "end": "119070"
  },
  {
    "text": "kubernetes features and provide feedback so the first version of kubernetes was",
    "start": "119070",
    "end": "126060"
  },
  {
    "start": "123000",
    "end": "239000"
  },
  {
    "text": "released in July of last year and I actually followed after 17 business",
    "start": "126060",
    "end": "132150"
  },
  {
    "text": "days and that was some of the feedback we got at that time was Wow it takes a little bit of time to get this and then",
    "start": "132150",
    "end": "138960"
  },
  {
    "text": "if you look at the sequence of releases this is work that we've been doing with the community to accelerate the the",
    "start": "138960",
    "end": "144810"
  },
  {
    "text": "release train it you know after the the first release you know it was a couple",
    "start": "144810",
    "end": "150450"
  },
  {
    "text": "of months and then a little bit longer until the next one but we've been working very actively to make that a",
    "start": "150450",
    "end": "156500"
  },
  {
    "text": "constant release train that's a you know about three months process at a very",
    "start": "156500",
    "end": "162240"
  },
  {
    "text": "regular interval simultaneously inside Google Cloud we've been working to make sure that gke",
    "start": "162240",
    "end": "168390"
  },
  {
    "text": "actually releases in very much lockstep with the kubernetes releases and so you",
    "start": "168390",
    "end": "174810"
  },
  {
    "text": "can sort of see that that gray box of time delay has shrunk and in fact in the",
    "start": "174810",
    "end": "180840"
  },
  {
    "text": "last release it was just one day and so what one of the purposes of container engine is to make sure that the speed",
    "start": "180840",
    "end": "187290"
  },
  {
    "text": "between innovation and users being able to access that innovation is as fast as",
    "start": "187290",
    "end": "192660"
  },
  {
    "text": "possible I will mention that you know there's a process to roll out",
    "start": "192660",
    "end": "199459"
  },
  {
    "text": "kubernetes on Google's cloud and that is an automated roll out tool that that",
    "start": "199459",
    "end": "204690"
  },
  {
    "text": "does that process but since it rolls out into multiple regions it's a it takes a",
    "start": "204690",
    "end": "210150"
  },
  {
    "text": "little bit of time just per the cloud policies",
    "start": "210150",
    "end": "215450"
  },
  {
    "text": "also when we roll out a new version that means that the new version is available",
    "start": "215510",
    "end": "220680"
  },
  {
    "text": "for new clusters and new masters but the existing masters are not upgraded",
    "start": "220680",
    "end": "225930"
  },
  {
    "text": "immediately there's a there's a time gap until everything is stable and then those masters are upgraded automatically",
    "start": "225930",
    "end": "234830"
  },
  {
    "text": "so again the goal here is to shrink the time from innovation to user feedback so",
    "start": "234830",
    "end": "240900"
  },
  {
    "start": "239000",
    "end": "327000"
  },
  {
    "text": "one question is you know what is the value of this container engine to the community and really from the very start",
    "start": "240900",
    "end": "248420"
  },
  {
    "text": "the the value has been one of the core values has been improving the product",
    "start": "248420",
    "end": "253769"
  },
  {
    "text": "quality so even in the beginning you know the community would look to Google",
    "start": "253769",
    "end": "259799"
  },
  {
    "text": "container engine be a signal of a release being you know ready for production and ready for deployment",
    "start": "259799",
    "end": "266420"
  },
  {
    "text": "also we get a lot of customer issues early on we see them since this is the",
    "start": "266420",
    "end": "272850"
  },
  {
    "text": "earliest availability and we fix them and upstream them directly so in 1 3",
    "start": "272850",
    "end": "279060"
  },
  {
    "text": "there were issues with you know DNS and its storage and you and you'll see that you know all of those fixes are back on",
    "start": "279060",
    "end": "285420"
  },
  {
    "text": "github immediately secondly a container engine provides a",
    "start": "285420",
    "end": "290940"
  },
  {
    "text": "testing and training environment so a lot of on-premise customers on-premise users and and also users in other clouds",
    "start": "290940",
    "end": "299040"
  },
  {
    "text": "will try out Google container engine just to get started with kubernetes and it's the easiest it's a very easy way to",
    "start": "299040",
    "end": "304980"
  },
  {
    "text": "get started with the features of kubernetes and lastly we've been getting good",
    "start": "304980",
    "end": "311880"
  },
  {
    "text": "feature feedback on us especially some of the Alpha features so stateful set formerly called pet sets scheduled jobs",
    "start": "311880",
    "end": "319800"
  },
  {
    "text": "and init containers we've gotten a lot of users actually trying those out and giving us feedback about how to improve",
    "start": "319800",
    "end": "325440"
  },
  {
    "text": "those but the that's the value to the",
    "start": "325440",
    "end": "331410"
  },
  {
    "start": "327000",
    "end": "470000"
  },
  {
    "text": "community what is the value to the user so there's kind of two aspects of this",
    "start": "331410",
    "end": "336830"
  },
  {
    "text": "when you want to set up kubernetes there are a number of different choices that you have to make you have to choose your",
    "start": "336830",
    "end": "343350"
  },
  {
    "text": "cloud provider you have to choose you know your OS image and a number of other things with container engine a lot of",
    "start": "343350",
    "end": "351060"
  },
  {
    "text": "that is done for you and so it makes it simpler in terms of choice secondly the installation this is done automatically",
    "start": "351060",
    "end": "358230"
  },
  {
    "text": "it's just a click of a button and you know you install so that's the other value and and and thirdly perhaps most",
    "start": "358230",
    "end": "365280"
  },
  {
    "text": "importantly is the ongoing management so the ongoing management and upgrade and repair and that's really I would say the",
    "start": "365280",
    "end": "372930"
  },
  {
    "text": "the value of I managed and hosted offering so it makes it so that",
    "start": "372930",
    "end": "378180"
  },
  {
    "text": "developers can focus on the app and developing their app and Google can",
    "start": "378180",
    "end": "384540"
  },
  {
    "text": "focus on making sure that the that the system is running the second piece of the user value is",
    "start": "384540",
    "end": "392010"
  },
  {
    "text": "really kind of of kubernetes it comes from the Google cloud platform itself and what we try to",
    "start": "392010",
    "end": "398110"
  },
  {
    "text": "do is combine you know the the differentiators of the underlying cloud",
    "start": "398110",
    "end": "403360"
  },
  {
    "text": "platform with kubernetes so some of the features that we'll be discussing and demoing today",
    "start": "403360",
    "end": "408660"
  },
  {
    "text": "will be examples of this but to some of the some of the sort of differentiators",
    "start": "408660",
    "end": "415120"
  },
  {
    "text": "with the cloud platform are you know faster startup times for the VMS as well as heterogeneous types of different",
    "start": "415120",
    "end": "422020"
  },
  {
    "text": "types of VMS preemptable VMS and custom custom VMS also the Google cloud load",
    "start": "422020",
    "end": "429310"
  },
  {
    "text": "balancing has some unique properties its global at an l7 level we'll be",
    "start": "429310",
    "end": "436090"
  },
  {
    "text": "demonstrating some of that as well and then some of the other features with regard to bigquery and datastore the",
    "start": "436090",
    "end": "443320"
  },
  {
    "text": "customer architectures on Google cloud make extensive use of these as well as I",
    "start": "443320",
    "end": "449229"
  },
  {
    "text": "am another point here is that the container engine binaries can",
    "start": "449229",
    "end": "456520"
  },
  {
    "text": "actually be upgraded on a weekly basis and in fact they are so a lot of these cloud specific features are pushed out",
    "start": "456520",
    "end": "463510"
  },
  {
    "text": "constantly even aside from the 3-month train of kubernetes",
    "start": "463510",
    "end": "469770"
  },
  {
    "start": "470000",
    "end": "498000"
  },
  {
    "text": "and this is some of the feedback these are some of the customers this is not a",
    "start": "471389",
    "end": "476590"
  },
  {
    "text": "complete list but you can see that there's a variety of different companies that use container engine and the",
    "start": "476590",
    "end": "482560"
  },
  {
    "text": "feedback that we get consistently is that hey it's really nice it's easy to use also you know with you managing this",
    "start": "482560",
    "end": "489340"
  },
  {
    "text": "with Google managing this I'm able to focus on my on my application and in fact it's nice that it runs so so you",
    "start": "489340",
    "end": "497410"
  },
  {
    "text": "know with high performance and so seamlessly so this is what it looks like I think hopefully most of you have tried",
    "start": "497410",
    "end": "503560"
  },
  {
    "start": "498000",
    "end": "540000"
  },
  {
    "text": "this out but it's really a very simple UI and you know you can go and create a",
    "start": "503560",
    "end": "509380"
  },
  {
    "text": "cluster with the click of a button the create cluster button and there's also a",
    "start": "509380",
    "end": "515159"
  },
  {
    "text": "built-in command line interface so the Google Cloud console has a built-in",
    "start": "515159",
    "end": "521859"
  },
  {
    "text": "command line interface which launches this CLI which has both cue cuddle and",
    "start": "521859",
    "end": "527829"
  },
  {
    "text": "g-cloud already installed so this is where the whole installation process is just greatly simplified and allows you",
    "start": "527829",
    "end": "534790"
  },
  {
    "text": "to get started in a matter of minutes without having to worry about all of the things that are underneath it but in",
    "start": "534790",
    "end": "541389"
  },
  {
    "text": "this talk we're going to talk about some of the things that are underneath it what do you get when you set up a",
    "start": "541389",
    "end": "547199"
  },
  {
    "text": "container engine cluster so the whole process takes about three minutes to setup a cluster you click that button in",
    "start": "547199",
    "end": "553209"
  },
  {
    "text": "three minutes you get you know however many nodes you wanted with whatever features turned on you know you can turn",
    "start": "553209",
    "end": "558669"
  },
  {
    "text": "those on in the UI but what is happening behind the scenes",
    "start": "558669",
    "end": "563679"
  },
  {
    "text": "there's quite a bit happening and that's why I have the picture of the of the iceberg first of all we are checking to",
    "start": "563679",
    "end": "569499"
  },
  {
    "text": "make sure that you know the user is authenticated we are also checking the",
    "start": "569499",
    "end": "574720"
  },
  {
    "text": "IAM policy to make sure that you have the credentials to actually run the",
    "start": "574720",
    "end": "580239"
  },
  {
    "text": "command that you want to run if it's to create a cluster or if it's to add a load balancer you have that privilege",
    "start": "580239",
    "end": "585480"
  },
  {
    "text": "and all of that is done behind the scenes by calling the Google compute engine API and starting starting the",
    "start": "585480",
    "end": "594129"
  },
  {
    "text": "master on the node so that is really the technology behind",
    "start": "594129",
    "end": "599589"
  },
  {
    "start": "595000",
    "end": "637000"
  },
  {
    "text": "that is the container engine API which is a crud API for you know container",
    "start": "599589",
    "end": "605199"
  },
  {
    "text": "clusters it also is what we use to upgrade the kubernetes version for the",
    "start": "605199",
    "end": "610419"
  },
  {
    "text": "cluster and obviously is integrated with all the different DCP features and we",
    "start": "610419",
    "end": "616329"
  },
  {
    "text": "manage we own and manage the master and we're going to talk about how we monitor",
    "start": "616329",
    "end": "622209"
  },
  {
    "text": "the health of the mount the master and repair it and also maintain a set of add-ons these are",
    "start": "622209",
    "end": "629079"
  },
  {
    "text": "actually default add-ons most of them are what you would use in a reference implementation from the open source as well",
    "start": "629079",
    "end": "634910"
  },
  {
    "text": "[Music] so and this is a picture of you know the",
    "start": "634910",
    "end": "642180"
  },
  {
    "start": "637000",
    "end": "696000"
  },
  {
    "text": "master and some of the things that are on the master so it looks very similar for those of you who are familiar with",
    "start": "642180",
    "end": "648180"
  },
  {
    "text": "running a kubernetes cluster either on-premise are on juice EE or on AWS I",
    "start": "648180",
    "end": "653880"
  },
  {
    "text": "don't think there's anything here that will surprise you so it's just that this control plane is",
    "start": "653880",
    "end": "659490"
  },
  {
    "text": "managed by Google and it looks like a black box API endpoint to the user so in",
    "start": "659490",
    "end": "665490"
  },
  {
    "text": "addition to you know we're using sed and API server and the scheduler and the controller manager these are all",
    "start": "665490",
    "end": "671220"
  },
  {
    "text": "standard components purely as they are in the open source in addition to those there's an l7 ingress controller and",
    "start": "671220",
    "end": "678089"
  },
  {
    "text": "cluster autoscaler again also pure open source versions of this but these are",
    "start": "678089",
    "end": "684329"
  },
  {
    "text": "the things that interact with the Google cloud platform so the ingress controller",
    "start": "684329",
    "end": "690029"
  },
  {
    "text": "interacts with juicy lb Google's cloud load balancer to set this to set up the global load balancing and also that",
    "start": "690029",
    "end": "697620"
  },
  {
    "text": "master is backed up regularly on an automated schedule so we ensure that",
    "start": "697620",
    "end": "702810"
  },
  {
    "text": "it's always available and then some of the things that are done behind the scenes obviously cubelet and docker so",
    "start": "702810",
    "end": "708990"
  },
  {
    "text": "people that is the agent on the node and docker this is all automatically installed queue proxy and then a number",
    "start": "708990",
    "end": "715949"
  },
  {
    "text": "of default add-ons so this is the stuff that is you would do it you know",
    "start": "715949",
    "end": "720959"
  },
  {
    "text": "yourself if you were doing it in an on-premise environment but this is done automatically so",
    "start": "720959",
    "end": "727790"
  },
  {
    "text": "specifically the the add-ons that we have via fluency and cube DNS fluency is for log",
    "start": "727790",
    "end": "736500"
  },
  {
    "text": "collection and it runs on every node it collects the logs and exports them to Google Cloud logging which and through",
    "start": "736500",
    "end": "743189"
  },
  {
    "text": "stackdriver and then cube dns enables the service discovery within the cluster and then",
    "start": "743189",
    "end": "750810"
  },
  {
    "text": "the additional three add-ons hipster is what we use for aggregating all the",
    "start": "750810",
    "end": "756480"
  },
  {
    "text": "monitoring and event data this is again same as what is available in the open source and and we're going",
    "start": "756480",
    "end": "765300"
  },
  {
    "text": "to talk a little bit more about monitoring in just a second and then the l7 load balancing back-end and the",
    "start": "765300",
    "end": "771500"
  },
  {
    "text": "dashboard the dashboard UI I think there was a demo of it and and I know talk on it earlier earlier yesterday",
    "start": "771500",
    "end": "779140"
  },
  {
    "start": "778000",
    "end": "798000"
  },
  {
    "text": "okay so that's kind of the architecture not very different than what you would",
    "start": "779140",
    "end": "784820"
  },
  {
    "text": "encounter anywhere else but what are the things that we do sort of to take user",
    "start": "784820",
    "end": "791210"
  },
  {
    "text": "feedback and automate the system even more this is actually",
    "start": "791210",
    "end": "797589"
  },
  {
    "text": "this is a chart of some additional features that we've kind of automated or",
    "start": "798490",
    "end": "805910"
  },
  {
    "text": "built based on user feedback and it shows the percentage of clusters that are actually using this so Google Cloud",
    "start": "805910",
    "end": "813440"
  },
  {
    "text": "monitoring ingress load seven balancing cluster auto-scaling node pools and alpha clusters and these have been",
    "start": "813440",
    "end": "820040"
  },
  {
    "text": "ordered actually in the in the based on how well they're adopted but also how",
    "start": "820040",
    "end": "828500"
  },
  {
    "text": "recently they were introduced so you can see that alpha cross clusters was very it was introduced very recently and so",
    "start": "828500",
    "end": "833660"
  },
  {
    "text": "it's still not available on all clusters and so it's not as well adopted whereas",
    "start": "833660",
    "end": "838970"
  },
  {
    "text": "monitoring which is turned on by default is pretty much abducted by everybody [Music]",
    "start": "838970",
    "end": "846469"
  },
  {
    "text": "so we'll go through each one of these and talk about how users are using it",
    "start": "846700",
    "end": "852170"
  },
  {
    "text": "and what feedback they've had so first of all for monitoring",
    "start": "852170",
    "end": "859810"
  },
  {
    "start": "854000",
    "end": "888000"
  },
  {
    "text": "monitoring has two purposes one is internally container engine collects",
    "start": "859810",
    "end": "864920"
  },
  {
    "text": "metrics from the master to make sure that the master is healthy and also to",
    "start": "864920",
    "end": "870020"
  },
  {
    "text": "repair it in case it is not healthy and to scale it with the needs of the rest",
    "start": "870020",
    "end": "875750"
  },
  {
    "text": "of the cluster it's also what we use for billing based on how many nodes are",
    "start": "875750",
    "end": "881300"
  },
  {
    "text": "being used and so these metrics are collected directly from the master and then used internally by the service",
    "start": "881300",
    "end": "889450"
  },
  {
    "start": "888000",
    "end": "951000"
  },
  {
    "text": "secondly in terms of user monitoring so the way that user metrics are collected",
    "start": "889450",
    "end": "895280"
  },
  {
    "text": "is through the heap store add-on that I mention earlier there's a sea adviser that runs on every single node inside",
    "start": "895280",
    "end": "901800"
  },
  {
    "text": "the cubelet agent and it gathers statistics from all the containers in your cluster and exports them via a REST",
    "start": "901800",
    "end": "909090"
  },
  {
    "text": "API heaps tur runs in just one pod per cluster so it's it's it's cluster scoped",
    "start": "909090",
    "end": "914910"
  },
  {
    "text": "and it collects and aggregates all of these metrics there's no special access it and then we pull these metrics and",
    "start": "914910",
    "end": "922350"
  },
  {
    "text": "put them into a storage back-end and then make them available through stackdriver they're made actually",
    "start": "922350",
    "end": "927930"
  },
  {
    "text": "available through stack driver as well as through the dashboard UI so you as",
    "start": "927930",
    "end": "933420"
  },
  {
    "text": "the user can view them consume them use them in any way you like",
    "start": "933420",
    "end": "938460"
  },
  {
    "text": "and they're also used by some of the other controllers in the system so for example",
    "start": "938460",
    "end": "944280"
  },
  {
    "text": "for the horizontal pod autoscaler it uses these same metrics as well to scale",
    "start": "944280",
    "end": "949890"
  },
  {
    "text": "up your service so the as I mentioned stack driver and",
    "start": "949890",
    "end": "956580"
  },
  {
    "start": "951000",
    "end": "995000"
  },
  {
    "text": "dashboard UI provide these metrics to you but also it's a fairly open system",
    "start": "956580",
    "end": "961740"
  },
  {
    "text": "and users can plug in their own add-ons for specific things that they want to do",
    "start": "961740",
    "end": "967590"
  },
  {
    "text": "in terms of monitoring and this is an example of where the open-source ecosystem is really available in",
    "start": "967590",
    "end": "973290"
  },
  {
    "text": "Google's cloud and many of our customers actually do this and use these add-ons",
    "start": "973290",
    "end": "978560"
  },
  {
    "text": "and I'll talk about so cystic Prometheus data dog these are some of the common",
    "start": "978560",
    "end": "984870"
  },
  {
    "text": "ones they they have different deployment methodologies data dog is deployed as a daemon set Assisting is actually a",
    "start": "984870",
    "end": "991350"
  },
  {
    "text": "kernel header but I'll talk about what users do with these and this is some of",
    "start": "991350",
    "end": "996750"
  },
  {
    "start": "995000",
    "end": "1080000"
  },
  {
    "text": "the feedback that we've that we've received they really like having additional options and the flexibility",
    "start": "996750",
    "end": "1002960"
  },
  {
    "text": "of choosing the monitoring solution I've heard all of these actually being used",
    "start": "1002960",
    "end": "1009620"
  },
  {
    "text": "in different situations a lot of the common requests are you know they would like to see a particular UI presentation",
    "start": "1009620",
    "end": "1016940"
  },
  {
    "text": "or would like to cut the data in a certain way they dog does a really good job of providing a great UI",
    "start": "1016940",
    "end": "1022630"
  },
  {
    "text": "oftentimes they're looking to be able to see the resources in the cluster in a certain hierarchy based on label and",
    "start": "1022630",
    "end": "1030030"
  },
  {
    "text": "have different views also customers often have different parts of",
    "start": "1030030",
    "end": "1035880"
  },
  {
    "text": "the organization that are used to using a different tool or would like to use a different tool and so being able to plug",
    "start": "1035880",
    "end": "1043470"
  },
  {
    "text": "that in as a diamond setter or whatever in a different container allows",
    "start": "1043470",
    "end": "1048990"
  },
  {
    "text": "different organizations to to plug in their specific monitoring monitoring solution the other use case is really",
    "start": "1048990",
    "end": "1056130"
  },
  {
    "text": "for hybrid cloud so if you're running a cluster in container engine and another cluster on-premise or another cluster in",
    "start": "1056130",
    "end": "1062610"
  },
  {
    "text": "an AWS you would want to aggregate your metrics across those clusters and so being able to install something like",
    "start": "1062610",
    "end": "1068910"
  },
  {
    "text": "data dog or Cystic allows you to have a more global view",
    "start": "1068910",
    "end": "1073940"
  },
  {
    "text": "so that's monitoring the second",
    "start": "1075650",
    "end": "1080960"
  },
  {
    "start": "1080000",
    "end": "1111000"
  },
  {
    "text": "the second sort of additional feature that's that's actually very popular is",
    "start": "1080960",
    "end": "1089010"
  },
  {
    "text": "ingress l7 lb and actually I would say it's also very powerful so many of our",
    "start": "1089010",
    "end": "1095690"
  },
  {
    "text": "customers who are global and you know global gaming companies or",
    "start": "1095690",
    "end": "1100700"
  },
  {
    "text": "companies that have you know IOT solutions that that are available in",
    "start": "1100700",
    "end": "1106830"
  },
  {
    "text": "multiple geographies like using the the ingress l7 load balancer so the ingress",
    "start": "1106830",
    "end": "1113730"
  },
  {
    "start": "1111000",
    "end": "1152000"
  },
  {
    "text": "resource itself is no different than it is in the open source essentially you",
    "start": "1113730",
    "end": "1119070"
  },
  {
    "text": "know customers want to be able to send traffic based on the URL to the appropriate part of the cluster and",
    "start": "1119070",
    "end": "1126380"
  },
  {
    "text": "that's what that's what ingress enables it does the mapping between you know the",
    "start": "1126380",
    "end": "1132650"
  },
  {
    "text": "l3 l4 service and the the URL based on",
    "start": "1132650",
    "end": "1139050"
  },
  {
    "text": "where it should go based on a map that the user provides and it is supported by",
    "start": "1139050",
    "end": "1145770"
  },
  {
    "text": "nginx and H a proxy and also has SSL support so this is identical to what is",
    "start": "1145770",
    "end": "1151440"
  },
  {
    "text": "available in the open source what is kind of different in Google's cloud is really the the cloud load balancing",
    "start": "1151440",
    "end": "1157950"
  },
  {
    "start": "1152000",
    "end": "1220000"
  },
  {
    "text": "capabilities which we're very proud of these capabilities but essentially the Google cloud load",
    "start": "1157950",
    "end": "1165120"
  },
  {
    "text": "balancer you know has the the forwarding rule the URL map and in the backend",
    "start": "1165120",
    "end": "1172110"
  },
  {
    "text": "service and we have a controller the l7 ingress controller pre-installed as part",
    "start": "1172110",
    "end": "1180720"
  },
  {
    "text": "of them as part of the master to set up this to set up this Google cloud load",
    "start": "1180720",
    "end": "1186840"
  },
  {
    "text": "balancing some of the additional features that are unique is you know you can get round-robin or you can get such",
    "start": "1186840",
    "end": "1192419"
  },
  {
    "text": "an affinity and I think maybe the most unique piece is that it can handle you",
    "start": "1192419",
    "end": "1197760"
  },
  {
    "text": "know scaling from 0 to millions of QPS and that's something that obviously has",
    "start": "1197760",
    "end": "1203399"
  },
  {
    "text": "been very important for some of the larger global customers also GCL be",
    "start": "1203399",
    "end": "1209490"
  },
  {
    "text": "offers cross region load balancing and this is kind of unique amongst cloud providers it's it's",
    "start": "1209490",
    "end": "1216330"
  },
  {
    "text": "actually not as usable by the simple ingress object but where it is really",
    "start": "1216330",
    "end": "1222750"
  },
  {
    "start": "1220000",
    "end": "1252000"
  },
  {
    "text": "usable is with the new 1.4 release of federated ingress and",
    "start": "1222750",
    "end": "1228570"
  },
  {
    "text": "federated ingress makes it possible so that you can use a single API endpoint",
    "start": "1228570",
    "end": "1234149"
  },
  {
    "text": "sorry are you a single service endpoint to distribute your load across multiple",
    "start": "1234149",
    "end": "1239700"
  },
  {
    "text": "clusters multiple regions and multiple clusters and that's currently only possible on Google cloud because of",
    "start": "1239700",
    "end": "1247020"
  },
  {
    "text": "juicy all these capabilities so that's federated ingress",
    "start": "1247020",
    "end": "1253100"
  },
  {
    "start": "1252000",
    "end": "1278000"
  },
  {
    "text": "there's a the next set of features is related to auto scaling and node pools",
    "start": "1253100",
    "end": "1258870"
  },
  {
    "text": "and Robert will come up and talk about those as well as give a demo thanks Aparna",
    "start": "1258870",
    "end": "1265250"
  },
  {
    "text": "so suparna mentioned we're talking about cluster or auto scaling next so one of",
    "start": "1265250",
    "end": "1270600"
  },
  {
    "text": "the interesting things is next slide",
    "start": "1270600",
    "end": "1275539"
  },
  {
    "start": "1278000",
    "end": "1381000"
  },
  {
    "text": "there we go as we as we were building gke we got a lot of feedback from customers that they",
    "start": "1279230",
    "end": "1285149"
  },
  {
    "text": "wanted to have their collection be more elastic right one of the advantages of running your cluster in the cloud is",
    "start": "1285149",
    "end": "1290340"
  },
  {
    "text": "that you're not running on sort of a fixed set of resources and as we looked at how to implement cluster auto scaling",
    "start": "1290340",
    "end": "1296130"
  },
  {
    "text": "we decided that it would be very important to build this functionality into the open source kubernetes instead of building something propriety",
    "start": "1296130",
    "end": "1302070"
  },
  {
    "text": "proprietary just for ourselves and so what we did is we started building a very flexible controller it sits in the",
    "start": "1302070",
    "end": "1307950"
  },
  {
    "text": "contributory and we built hooks just to plug it into Google the Google cloud provider right because that was our",
    "start": "1307950",
    "end": "1312990"
  },
  {
    "text": "immediate need to meet our customers goals you know it's currently in beta it's",
    "start": "1312990",
    "end": "1318149"
  },
  {
    "text": "it's very conservative in terms of how quickly it scales up and down your cluster but it's already proving really",
    "start": "1318149",
    "end": "1323639"
  },
  {
    "text": "valuable to our customers and it's it's actually proving so valuable that people have ported it to also work on Amazon and so one of the advantages of us",
    "start": "1323639",
    "end": "1330360"
  },
  {
    "text": "having built it in the open-source community is that now it's it's being taken advantage of across the wider",
    "start": "1330360",
    "end": "1336450"
  },
  {
    "text": "community and it's not just specific to a container engine it also it'll scale up based on pending",
    "start": "1336450",
    "end": "1343019"
  },
  {
    "text": "pods which is really nice because if you just look at CPU utilization across your",
    "start": "1343019",
    "end": "1348389"
  },
  {
    "text": "cluster you can very easily get into a state where you have very low CPU",
    "start": "1348389",
    "end": "1353399"
  },
  {
    "text": "utilization because pods are scheduled based on resource reservations and not current resource usage and it's",
    "start": "1353399",
    "end": "1359580"
  },
  {
    "text": "impossible to schedule new pods into your cluster but when you want to schedule a new pod there's nowhere to place it but a autoscaler is just",
    "start": "1359580",
    "end": "1366000"
  },
  {
    "text": "looking at resource utilization will not actually scale up your cluster so if you look at resource requests then you can",
    "start": "1366000",
    "end": "1371669"
  },
  {
    "text": "tell that a new pod would be able to schedule if you add more nodes to your cluster you can dynamically add a node",
    "start": "1371669",
    "end": "1377100"
  },
  {
    "text": "and then you can see that that pod gets placed on a new node that you added",
    "start": "1377100",
    "end": "1382190"
  },
  {
    "start": "1381000",
    "end": "1446000"
  },
  {
    "text": "so some of the things that customers say is it you know they really like the feature they've you know obviously",
    "start": "1382460",
    "end": "1387960"
  },
  {
    "text": "requested it they were concerned about how conservative the future is right now you know we we started off very",
    "start": "1387960",
    "end": "1393059"
  },
  {
    "text": "conservative because we didn't want to have a cluster that was very rapidly growing and shrinking and the other",
    "start": "1393059",
    "end": "1399120"
  },
  {
    "text": "problem is that the cluster autoscaler it tries to do a job of picking which nodes to remove when it schedules down",
    "start": "1399120",
    "end": "1404639"
  },
  {
    "text": "but it's possible to get into a state where you remove a critical node and actually disrupt service",
    "start": "1404639",
    "end": "1410280"
  },
  {
    "text": "so some things we're looking at integrating the cluster i/o scaler with before it reaches general availability as things like pod disruption budgets",
    "start": "1410280",
    "end": "1416730"
  },
  {
    "text": "where you when you schedule your pods can tell people or tell the system exactly how often the pod is allowed to",
    "start": "1416730",
    "end": "1423299"
  },
  {
    "text": "be rescheduled and the cluster autoscaler can take that into account when it's removing nodes from your cluster and it can choose a node that",
    "start": "1423299",
    "end": "1429120"
  },
  {
    "text": "will keep you within SLO for your ear pods and also integrating it with forgiveness and gristle termination so",
    "start": "1429120",
    "end": "1436140"
  },
  {
    "text": "that when you're deleting containers you actually send a signal to the container and let it know that it's about to be",
    "start": "1436140",
    "end": "1442110"
  },
  {
    "text": "removed so it can do like local cleanup and flush data to disk",
    "start": "1442110",
    "end": "1448039"
  },
  {
    "start": "1446000",
    "end": "1599000"
  },
  {
    "text": "so the next thing we're going to talk about is node pools so no pools are sort",
    "start": "1448070",
    "end": "1453840"
  },
  {
    "text": "of another interesting set of feedback that we got from customers we're at internally at Google pretty much",
    "start": "1453840",
    "end": "1460409"
  },
  {
    "text": "everyone who wants to write a service doesn't care what type of machine they're running on like you write your code you give it to Borg and it just",
    "start": "1460409",
    "end": "1467280"
  },
  {
    "text": "runs and you don't worry about the underlying infrastructure and this is sort of what we started building with kubernetes and with Google container",
    "start": "1467280",
    "end": "1472799"
  },
  {
    "text": "engine and so you could launch a cluster you tell it what you want your underlying if a structure to look like I",
    "start": "1472799",
    "end": "1478470"
  },
  {
    "text": "want two cores per machine or four cores per machine and user is sort of very quickly turned around and said that they",
    "start": "1478470",
    "end": "1483780"
  },
  {
    "text": "wanted more flexibility you know they wanted to be able to change the type of machine they were using you know they they guessed wrong when they created",
    "start": "1483780",
    "end": "1489539"
  },
  {
    "text": "their cluster and now they decide they need eight cores instead of four or they decide that you know I want to have",
    "start": "1489539",
    "end": "1496190"
  },
  {
    "text": "labels on different types of machines I want to isolate my workloads I want to be able to put labels so that some of my",
    "start": "1496190",
    "end": "1501990"
  },
  {
    "text": "users can run stuff on some nodes and other users can run stuff on other nodes or they might have a use case where they",
    "start": "1501990",
    "end": "1507179"
  },
  {
    "text": "need some nodes that have a lot of memory but not much CPU and sometimes that have a lot of CPU but not as much",
    "start": "1507179",
    "end": "1513240"
  },
  {
    "text": "memory so we sort of consolidated all of this feedback and built a feature that we call node pools which is sort of",
    "start": "1513240",
    "end": "1520169"
  },
  {
    "text": "related a simple layering on top of the basic kubernetes concepts where you can have multiple groups of homogeneous",
    "start": "1520169",
    "end": "1525870"
  },
  {
    "text": "nodes instead of a single group of muchness nodes and this sort of allows you to get all of those sort of",
    "start": "1525870",
    "end": "1531059"
  },
  {
    "text": "requested features that I just mentioned you can have multiple node pools which can give you different types of machines you can create new node pools which can",
    "start": "1531059",
    "end": "1537960"
  },
  {
    "text": "allow you to transition the type of machine that you're using you can add custom labels to those machines and you",
    "start": "1537960",
    "end": "1543330"
  },
  {
    "text": "can also use note pools for things like upgrades which allows a better upgrade story so there's a great example of us",
    "start": "1543330",
    "end": "1549670"
  },
  {
    "text": "sort of listening to users and sort of taking that feedback into our product and we did it in such a way that it",
    "start": "1549670",
    "end": "1555340"
  },
  {
    "text": "actually sort of works across other providers also because really note pools as a concept is us applying special",
    "start": "1555340",
    "end": "1561880"
  },
  {
    "text": "labels to notes in specific groupings and you can do the same thing if you're running on Prem or on AWS if you're",
    "start": "1561880",
    "end": "1568060"
  },
  {
    "text": "running on Prem you might want to label all of your nodes with which failure domain they're in which rack or which data center nodes already report their",
    "start": "1568060",
    "end": "1574420"
  },
  {
    "text": "resource type you might want to give them custom labels like you know this should be a dedicated machine type so all sort of things that we're building",
    "start": "1574420",
    "end": "1580360"
  },
  {
    "text": "around node pools are sort of very portable to other operating environments",
    "start": "1580360",
    "end": "1586500"
  },
  {
    "text": "so in here's sort of a couple examples of how no pools work you've got you know one node pool with",
    "start": "1587010",
    "end": "1594310"
  },
  {
    "text": "one version of kubernetes and then another node pool with different size VMs I",
    "start": "1594310",
    "end": "1599700"
  },
  {
    "start": "1599000",
    "end": "1634000"
  },
  {
    "text": "went through all of that already and then lastly we have a couple of examples of user feedback from people that are",
    "start": "1599700",
    "end": "1605620"
  },
  {
    "text": "actually using node pools and their production systems so we had two different customers who both started off at that top state or they had a node",
    "start": "1605620",
    "end": "1611950"
  },
  {
    "text": "pool with a you know one not free version of kubernetes and we had one of the users decided they wanted to use a",
    "start": "1611950",
    "end": "1617260"
  },
  {
    "text": "different base image right so they wanted to transition from the container vm base image to our google container vm",
    "start": "1617260",
    "end": "1623440"
  },
  {
    "text": "base image and they create a new node pool with that type and we had another user that wanted to upgrade and so they",
    "start": "1623440",
    "end": "1628930"
  },
  {
    "text": "created a second node pool and upgraded their system to the second node pool",
    "start": "1628930",
    "end": "1633990"
  },
  {
    "start": "1634000",
    "end": "1749000"
  },
  {
    "text": "all right so now we're gonna switch and I'm gonna show a quick demo the demo again I mentioned earlier auto scaling",
    "start": "1634830",
    "end": "1641770"
  },
  {
    "text": "is a bit slow so in for the demo I'm actually I made a recording last night and I'm just going to play that instead",
    "start": "1641770",
    "end": "1648070"
  },
  {
    "text": "of trying to go through auto scaling because otherwise it would take about 20 minutes",
    "start": "1648070",
    "end": "1653610"
  },
  {
    "text": "that's one time to add that the demo that Robbie's gonna do is an actual is",
    "start": "1659000",
    "end": "1666660"
  },
  {
    "text": "an actual thing that a customer has used autoscaler and EndNote pools for so this",
    "start": "1666660",
    "end": "1672450"
  },
  {
    "text": "is a this is reenacting basically what what a user",
    "start": "1672450",
    "end": "1679200"
  },
  {
    "text": "has done",
    "start": "1679200",
    "end": "1681590"
  },
  {
    "text": "all right so many of a sort of a voice over here is above the demo so the setup is we're gonna do a very small scale",
    "start": "1684800",
    "end": "1691770"
  },
  {
    "text": "demo so it's not actually the scale demo but this is a really good sort of sample application you can run the code for all",
    "start": "1691770",
    "end": "1697890"
  },
  {
    "text": "of this is open source it's in the contributory basically you run some nginx servers and then you run some load testers and you're sending a load to",
    "start": "1697890",
    "end": "1704010"
  },
  {
    "text": "your internet servers so what I've done to set up is I've created a cluster with",
    "start": "1704010",
    "end": "1709350"
  },
  {
    "text": "a single node pool now I'm actually launching the scale demo so we launched a couple of different services and",
    "start": "1709350",
    "end": "1715950"
  },
  {
    "text": "controllers and then we're gonna scale both those up and you're gonna see we're gonna send about 10,000 requests per second to a number of backends",
    "start": "1715950",
    "end": "1724430"
  },
  {
    "text": "and you can see all the pods are launching the cluster each of the load tester sends a thousand requests per",
    "start": "1727580",
    "end": "1733290"
  },
  {
    "text": "second so we need ten of those to get up to 10,000 it takes just a second for them all to start",
    "start": "1733290",
    "end": "1739910"
  },
  {
    "start": "1749000",
    "end": "1805000"
  },
  {
    "text": "and then what we're gonna do you can see here that the node version is 1.3 out of 10 which is not the current node version there's an update available so one",
    "start": "1750650",
    "end": "1757340"
  },
  {
    "text": "option is to click that button and to say you know update my nose to the latest version some people want a little bit more control than that and so one",
    "start": "1757340",
    "end": "1763520"
  },
  {
    "text": "way you can have more control is you can create a second node pool at a different version so let me do is I'm going to create a new node pool you you may not",
    "start": "1763520",
    "end": "1770030"
  },
  {
    "text": "have caught this but the first node pool had four core machines the new node pool I'm going to make have two core machines",
    "start": "1770030",
    "end": "1775100"
  },
  {
    "text": "so this no pools can have slightly solve all our machine types I'm actually integrating in one of those use cases of",
    "start": "1775100",
    "end": "1781730"
  },
  {
    "text": "changing the machine type because I guessed wrong when I created my cluster I've also enabled the autoscaler for my new cluster so what I'm doing is I'm",
    "start": "1781730",
    "end": "1788270"
  },
  {
    "text": "making the new node pool really small and then as I move my workload over it's going to auto size itself up to be",
    "start": "1788270",
    "end": "1794570"
  },
  {
    "text": "appropriate for the amount of work I'm running I could have also added an auto scaler to my existing node pool which",
    "start": "1794570",
    "end": "1800090"
  },
  {
    "text": "would have most likely shrunk it down because it is it was quite over provisioned",
    "start": "1800090",
    "end": "1805000"
  },
  {
    "start": "1805000",
    "end": "1858000"
  },
  {
    "text": "all right so we see two new nodes are now in the cluster and now what the first thing we do is",
    "start": "1806230",
    "end": "1812300"
  },
  {
    "text": "we're going to upgrade from the old node pool the new node pool is we're going to cordon all of the old nodes and what",
    "start": "1812300",
    "end": "1819440"
  },
  {
    "text": "this does is it marks all the old nodes it's unschedulable and what that will do is it means that when you try to reschedule your work when you drain the",
    "start": "1819440",
    "end": "1825830"
  },
  {
    "text": "nodes in the next step it will force the the pods to be moved over to the new node pool if you skip this step then",
    "start": "1825830",
    "end": "1832429"
  },
  {
    "text": "when you drain a node the pods can be rescheduled on to other nodes in the old node pool which means when you drain that note they'll get rescheduled again",
    "start": "1832429",
    "end": "1838670"
  },
  {
    "text": "so this is really sort of an optimization to make sure your workload isn't rescheduled more often than necessary next we're going to migrate",
    "start": "1838670",
    "end": "1844130"
  },
  {
    "text": "the workload over by draining and after each drain step you might have missed that after each strain stuff were actually going to delete to the old node",
    "start": "1844130",
    "end": "1850610"
  },
  {
    "text": "so at the end of the demo the old node pool will be all the way down to zero nodes and the new node pool will scale",
    "start": "1850610",
    "end": "1856610"
  },
  {
    "text": "up to however many nodes we need to run our entire application if you look over here we're running get",
    "start": "1856610",
    "end": "1864350"
  },
  {
    "start": "1858000",
    "end": "1933000"
  },
  {
    "text": "pods and you can see the node on which each pod is running and all of the the pods not anymore all of them a couple of",
    "start": "1864350",
    "end": "1871309"
  },
  {
    "text": "them is switched over to the new node pool and many of them are still running on at the old node pool and then down",
    "start": "1871309",
    "end": "1876350"
  },
  {
    "text": "here you can see one by one all the nodes in the old note pool become not ready and then disappear as we delete",
    "start": "1876350",
    "end": "1882320"
  },
  {
    "text": "them and you'll start to see new notes get added at the bottom so we started with two we're already up to three and",
    "start": "1882320",
    "end": "1888169"
  },
  {
    "text": "as we moved through this sped up part of the demo you'll see new nodes show up is not ready and then flipped to ready and",
    "start": "1888169",
    "end": "1893570"
  },
  {
    "text": "right after they flip to ready you'll see up here that one of the nginx instances that was previously",
    "start": "1893570",
    "end": "1899029"
  },
  {
    "text": "unschedulable because there was no space in the cluster switches to be container creating it than in the running state",
    "start": "1899029",
    "end": "1906309"
  },
  {
    "text": "all right so now we're up to six nodes and we have one more engine next instance it's not running and here comes",
    "start": "1918650",
    "end": "1923990"
  },
  {
    "text": "one more node",
    "start": "1923990",
    "end": "1926530"
  },
  {
    "text": "great so we're now back back up to six-inch next instances we still have our ten load BOTS running we were",
    "start": "1929290",
    "end": "1935090"
  },
  {
    "start": "1933000",
    "end": "1982000"
  },
  {
    "text": "serving all 10,000 requests the entire time and you can see if you drill into the cluster that the old node pool is",
    "start": "1935090",
    "end": "1940940"
  },
  {
    "text": "now shrunk all the way down to zero because my shell script was deleting one note at a time and the new node pool has",
    "start": "1940940",
    "end": "1946040"
  },
  {
    "text": "scaled itself up automatically to seven notes so that's sort of an example of how you can combine this concept of no",
    "start": "1946040",
    "end": "1951230"
  },
  {
    "text": "pools with cluster auto-scaling to do sort of seamless upgrade obviously for",
    "start": "1951230",
    "end": "1956270"
  },
  {
    "text": "the demo I did the upgrade much faster than you want to do in production you know there was a very short sleep between each drain you won't do that",
    "start": "1956270",
    "end": "1961550"
  },
  {
    "text": "much more slowly you can do it at whatever sort of level of granularity you want right you can do it manually",
    "start": "1961550",
    "end": "1966560"
  },
  {
    "text": "you can automate the process but it gives you a lot of control over exactly how you upgrade your cluster",
    "start": "1966560",
    "end": "1973390"
  },
  {
    "start": "1982000",
    "end": "2053000"
  },
  {
    "text": "alright and lastly we're going to talk about alpha clusters so a partner mentioned earlier that alpha clusters",
    "start": "1983260",
    "end": "1988750"
  },
  {
    "text": "are something that we recently added to kubernetes again this was based on user feedback where users would see something",
    "start": "1988750",
    "end": "1994450"
  },
  {
    "text": "being developed an open source oftentimes when you're you're launching a service as a large company no one",
    "start": "1994450",
    "end": "1999640"
  },
  {
    "text": "knows what you're working on right and so you just kind of work on it and then you put it out there and people can use it but with kubernetes everybody keeps",
    "start": "1999640",
    "end": "2005790"
  },
  {
    "text": "asking like oh I see schedule jobs or I see pets that like why can't I use that in gke and the answer is that alpha",
    "start": "2005790",
    "end": "2011700"
  },
  {
    "text": "features are very unstable right you can see with pet set that we just renamed it to stateful set and there's no real upgrade path between those two versions",
    "start": "2011700",
    "end": "2018210"
  },
  {
    "text": "but that doesn't mean that people don't want to try it and so we've done is we've created a way for people to launch clusters that have all the alpha",
    "start": "2018210",
    "end": "2024360"
  },
  {
    "text": "features enabled so they can try out the alpha features before they're ready for production and this turned out to be a",
    "start": "2024360",
    "end": "2030570"
  },
  {
    "text": "really great way to get feedback for those features before they become sort of locked into their final API state and",
    "start": "2030570",
    "end": "2036870"
  },
  {
    "text": "so for pet sets and init containers and scheduled jobs we're getting a lot of feedback from the community because people can go into gke click a button",
    "start": "2036870",
    "end": "2044190"
  },
  {
    "text": "have a cluster try out these new features with the caveat that that cluster is not really ready for",
    "start": "2044190",
    "end": "2049408"
  },
  {
    "text": "production and won't last for very long and that's the end so I think we have a",
    "start": "2049409",
    "end": "2056429"
  },
  {
    "text": "few minutes left for questions before we kick off the stage",
    "start": "2056429",
    "end": "2061100"
  },
  {
    "text": "[Applause] [Music]",
    "start": "2062510",
    "end": "2068749"
  },
  {
    "start": "2084000",
    "end": "2149000"
  },
  {
    "text": "yes that's a really a question the question was the no pools underneath use something we call managed instance groups in GCE and",
    "start": "2086420",
    "end": "2093320"
  },
  {
    "text": "you can actually turn on a GCE autoscaler on the managed instance group and we actually tried this so this is",
    "start": "2093320",
    "end": "2098390"
  },
  {
    "text": "what I was referring to when if you just turn that on and you tell it to look at the CPU utilization you get really terrible behavior because the autoscaler",
    "start": "2098390",
    "end": "2104990"
  },
  {
    "text": "is assuming that all of your nodes are effectively the same that any of them if you add a new one it's gonna have the",
    "start": "2104990",
    "end": "2110390"
  },
  {
    "text": "same behavior the existing one so it sees the overall utilization go up adding in other nodes should make the overall utilization go back down it",
    "start": "2110390",
    "end": "2117230"
  },
  {
    "text": "turns out with kubernetes since people schedule pods and pods don't land exactly evenly across all nodes and some",
    "start": "2117230",
    "end": "2122780"
  },
  {
    "text": "pods have higher resource reservations that offended breaks down really quickly and so we realized that we couldn't just",
    "start": "2122780",
    "end": "2128390"
  },
  {
    "text": "flip on the autoscaler and that's why we ended up building sort of the custom cluster autoscaler for kubernetes",
    "start": "2128390",
    "end": "2134920"
  },
  {
    "text": "other questions",
    "start": "2137380",
    "end": "2140740"
  },
  {
    "start": "2149000",
    "end": "2192000"
  },
  {
    "text": "right so the question is the the heap sir pod is running as a single pod it's actually running underneath a",
    "start": "2150099",
    "end": "2155390"
  },
  {
    "text": "replication controller so it's a replication controller with one instance so there is a single pod running but",
    "start": "2155390",
    "end": "2160759"
  },
  {
    "text": "there is a controller making sure there is always a single pod running so if it gets killed or if that node gets removed",
    "start": "2160759",
    "end": "2165920"
  },
  {
    "text": "then a new instance of peeps will get started right and we also monitor that you know it's",
    "start": "2165920",
    "end": "2171559"
  },
  {
    "text": "it's running although if you scale yourself down to zero nodes then it's impossible for it",
    "start": "2171559",
    "end": "2177230"
  },
  {
    "text": "to run one more question",
    "start": "2177230",
    "end": "2181480"
  },
  {
    "start": "2192000",
    "end": "2235000"
  },
  {
    "text": "right so the system has a notion of forgiveness which is we anticipate that there are going to be times when an OU",
    "start": "2193660",
    "end": "2199450"
  },
  {
    "text": "gets sort of disconnected from the rest of the cluster and we might not be be hearing from it and so there's a period",
    "start": "2199450",
    "end": "2204910"
  },
  {
    "text": "of time in which a pod can be not running but we don't know about it for a while before it gets rescheduled so if",
    "start": "2204910",
    "end": "2211990"
  },
  {
    "text": "the if the note actually disappears we can usually detect that pretty quickly because we can talk to the Google Google",
    "start": "2211990",
    "end": "2217390"
  },
  {
    "text": "cloud platform compute engine API and find out that the note is gone and we can kill it immediately but if we just",
    "start": "2217390",
    "end": "2222819"
  },
  {
    "text": "stopped getting status about that pod then yeah I can take five minutes before anyone starts that's the default threshold",
    "start": "2222819",
    "end": "2229500"
  },
  {
    "start": "2235000",
    "end": "2279000"
  },
  {
    "text": "the question is little used for config management of the machines which mission which machines are you talking about",
    "start": "2237310",
    "end": "2243779"
  },
  {
    "text": "yeah right so to actually configure like the",
    "start": "2244410",
    "end": "2250150"
  },
  {
    "text": "underlying machines we use all the scripts that are open-source so if you look in the clustered directory and open",
    "start": "2250150",
    "end": "2255280"
  },
  {
    "text": "source there's a bunch of cluster GCE machine configuration scripts that are used to configure all of the nodes that",
    "start": "2255280",
    "end": "2260530"
  },
  {
    "text": "run the cluster you can then on top of that run like a daemon set that tries to reconfigure all the nodes in your",
    "start": "2260530",
    "end": "2266350"
  },
  {
    "text": "cluster if you need to make customizations",
    "start": "2266350",
    "end": "2269789"
  },
  {
    "text": "set again",
    "start": "2273300",
    "end": "2276480"
  },
  {
    "start": "2279000",
    "end": "2390000"
  },
  {
    "text": "right so the question is there's upgrade follow the same path so what happens with upgrades is when an upgrade comes",
    "start": "2281010",
    "end": "2286230"
  },
  {
    "text": "out we upgrade the master machine for you and then it's up to you to upgrade your notes and the reason for this is",
    "start": "2286230",
    "end": "2292890"
  },
  {
    "text": "that we found that that note upgrades can be disruptive right and we want that to be under your control of when that",
    "start": "2292890",
    "end": "2298140"
  },
  {
    "text": "happens and the speed at which it happens so as I mentioned before when you want to upgrade your note pool you can click a button and will upgrade your",
    "start": "2298140",
    "end": "2304380"
  },
  {
    "text": "note pool for you depending on your application that can be perfectly fine but it also might",
    "start": "2304380",
    "end": "2309930"
  },
  {
    "text": "break your specific application so you can also create a second note pool and you can migrate your workload over which",
    "start": "2309930",
    "end": "2315450"
  },
  {
    "text": "is what I showed during the demo if you have a daemon set that you've deployed and there's an upgrade then it's you",
    "start": "2315450",
    "end": "2321869"
  },
  {
    "text": "know up to you to upgrade that daemon set to a new version that will work on the new nodes generally most of the time they are",
    "start": "2321869",
    "end": "2328260"
  },
  {
    "text": "still ok but they're definitely cases where you know there's a new you know kernel that comes out that's",
    "start": "2328260",
    "end": "2334260"
  },
  {
    "text": "incompatible with a tweak that you've been making to your notes and again that's why it's sort of on you in terms",
    "start": "2334260",
    "end": "2340320"
  },
  {
    "text": "of scheduling when you're gonna upgrade your notes because then you are breaking yourself instead of us breaking you know",
    "start": "2340320",
    "end": "2345510"
  },
  {
    "text": "maybe it at 2 a.m. and your time son and the the the two features that Robbie",
    "start": "2345510",
    "end": "2351600"
  },
  {
    "text": "mentioned with regard to pod reception budget and graceful termination those are work in progress for the upcoming",
    "start": "2351600",
    "end": "2357960"
  },
  {
    "text": "release so you can read about them on github but they will allow at least four",
    "start": "2357960",
    "end": "2364050"
  },
  {
    "text": "nodes with the default note image which is Google container image GCI for you to",
    "start": "2364050",
    "end": "2370580"
  },
  {
    "text": "opt into you know node upgrades managed through Google that's a that's not yet",
    "start": "2370580",
    "end": "2376500"
  },
  {
    "text": "available but it's coming with those features",
    "start": "2376500",
    "end": "2381050"
  },
  {
    "start": "2390000",
    "end": "2484000"
  },
  {
    "text": "yeah it's just the two we're still trying to figure out how to make it possible to",
    "start": "2391600",
    "end": "2396970"
  },
  {
    "text": "feel how people bring customized images it's a very difficult problem because",
    "start": "2396970",
    "end": "2402550"
  },
  {
    "text": "everyone has sort of their own pet image it's not sort of clear exactly how that",
    "start": "2402550",
    "end": "2407680"
  },
  {
    "text": "will work with the rest of the system and we want to make sure that the experience people have is a functioning kubernetes system we so during as a",
    "start": "2407680",
    "end": "2415570"
  },
  {
    "text": "aside during the alpha version of Google container engine you could actually specify a specific node image for your",
    "start": "2415570",
    "end": "2421210"
  },
  {
    "text": "cluster and we found people were specifying like oh here's my Windows image please launch that for me and we'd",
    "start": "2421210",
    "end": "2427240"
  },
  {
    "text": "be like oh this cluster didn't create I wonder why like oh they're trying to launch Windows so they're trying to launch you know Ubuntu or red hat or",
    "start": "2427240",
    "end": "2432790"
  },
  {
    "text": "some other system where the machine configuration part didn't actually work right and so it was impossible for us to",
    "start": "2432790",
    "end": "2438130"
  },
  {
    "text": "give them a functioning cluster which is a pretty terrible user experience so we want to make sure the user experience is really good before we allow that to be",
    "start": "2438130",
    "end": "2443950"
  },
  {
    "text": "more customized that's specifically for the node base image and so there's only the two",
    "start": "2443950",
    "end": "2449620"
  },
  {
    "text": "options which is the Debian based container image and GCI the Google",
    "start": "2449620",
    "end": "2454960"
  },
  {
    "text": "container image if you have specific requirements then you can use GCE you can always set up a kubernetes cluster",
    "start": "2454960",
    "end": "2461680"
  },
  {
    "text": "in compute engine and then you know it can it doesn't have all the automation but then it has 100% flexibility",
    "start": "2461680",
    "end": "2470099"
  },
  {
    "text": "I think if there are any other questions we'll wait up front because the next doc talk is supposed to start in about three",
    "start": "2473450",
    "end": "2478670"
  },
  {
    "text": "minutes so all right thanks everyone [Music] [Applause] [Music]",
    "start": "2478670",
    "end": "2485900"
  }
]
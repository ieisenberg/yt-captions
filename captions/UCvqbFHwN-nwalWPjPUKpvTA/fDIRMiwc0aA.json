[
  {
    "start": "0",
    "end": "19000"
  },
  {
    "text": "hi everyone",
    "start": "719",
    "end": "2240"
  },
  {
    "text": "thank you",
    "start": "2240",
    "end": "3280"
  },
  {
    "text": "um it's i know we're at an",
    "start": "3280",
    "end": "5120"
  },
  {
    "text": "infrastructure conference so it's nice",
    "start": "5120",
    "end": "6799"
  },
  {
    "text": "to see fellow machine learning",
    "start": "6799",
    "end": "8400"
  },
  {
    "text": "practitioners or people interested in",
    "start": "8400",
    "end": "10320"
  },
  {
    "text": "machine learning",
    "start": "10320",
    "end": "11759"
  },
  {
    "text": "um so yeah welcome to scaling machine",
    "start": "11759",
    "end": "14080"
  },
  {
    "text": "learn machine workflow machine learning",
    "start": "14080",
    "end": "16080"
  },
  {
    "text": "workflows with big data to big data with",
    "start": "16080",
    "end": "18480"
  },
  {
    "text": "view",
    "start": "18480",
    "end": "19600"
  },
  {
    "start": "19000",
    "end": "61000"
  },
  {
    "text": "so we're going to start off with a demo",
    "start": "19600",
    "end": "21279"
  },
  {
    "text": "presented by han in this demo we're",
    "start": "21279",
    "end": "23680"
  },
  {
    "text": "going to start out with a small panda",
    "start": "23680",
    "end": "25840"
  },
  {
    "text": "size data frame and then we're going to",
    "start": "25840",
    "end": "28560"
  },
  {
    "text": "apply some business logic to that and",
    "start": "28560",
    "end": "30320"
  },
  {
    "text": "trans and and bring that into spark and",
    "start": "30320",
    "end": "33200"
  },
  {
    "text": "in the process we're going to see how",
    "start": "33200",
    "end": "34640"
  },
  {
    "text": "much of code is needed to bring it to",
    "start": "34640",
    "end": "36320"
  },
  {
    "text": "spark",
    "start": "36320",
    "end": "37200"
  },
  {
    "text": "how much pandas and spark are different",
    "start": "37200",
    "end": "38800"
  },
  {
    "text": "from each other and how the fugue opens",
    "start": "38800",
    "end": "41040"
  },
  {
    "text": "how the open source library field can",
    "start": "41040",
    "end": "42719"
  },
  {
    "text": "help you do this",
    "start": "42719",
    "end": "45840"
  },
  {
    "text": "change",
    "start": "52640",
    "end": "55038"
  },
  {
    "text": "okay",
    "start": "56879",
    "end": "59840"
  },
  {
    "start": "61000",
    "end": "105000"
  },
  {
    "text": "hello everyone",
    "start": "62480",
    "end": "63920"
  },
  {
    "text": "my name is han wong",
    "start": "63920",
    "end": "65840"
  },
  {
    "text": "and today i'm going to do a quick demo",
    "start": "65840",
    "end": "68400"
  },
  {
    "text": "of some very interesting features of",
    "start": "68400",
    "end": "70880"
  },
  {
    "text": "fugue and",
    "start": "70880",
    "end": "73119"
  },
  {
    "text": "i'm going to switch between python code",
    "start": "73119",
    "end": "75840"
  },
  {
    "text": "spark code",
    "start": "75840",
    "end": "77439"
  },
  {
    "text": "and",
    "start": "77439",
    "end": "78240"
  },
  {
    "text": "figure code",
    "start": "78240",
    "end": "80080"
  },
  {
    "text": "it's okay if you are not familiar with",
    "start": "80080",
    "end": "82720"
  },
  {
    "text": "with spark and if you cannot follow on",
    "start": "82720",
    "end": "85439"
  },
  {
    "text": "the spark part because uh that is just",
    "start": "85439",
    "end": "88400"
  },
  {
    "text": "used to compare with fugue um",
    "start": "88400",
    "end": "91360"
  },
  {
    "text": "and i think the most important thing is",
    "start": "91360",
    "end": "93119"
  },
  {
    "text": "just to focus on",
    "start": "93119",
    "end": "94880"
  },
  {
    "text": "how you solve this problem how intuitive",
    "start": "94880",
    "end": "98079"
  },
  {
    "text": "your own expression should be when you",
    "start": "98079",
    "end": "100400"
  },
  {
    "text": "want to solve this problem okay now",
    "start": "100400",
    "end": "102479"
  },
  {
    "text": "let's start the first example is um we",
    "start": "102479",
    "end": "106159"
  },
  {
    "start": "105000",
    "end": "280000"
  },
  {
    "text": "have a very interesting business logic",
    "start": "106159",
    "end": "108479"
  },
  {
    "text": "which i guess if you're working a",
    "start": "108479",
    "end": "110000"
  },
  {
    "text": "company you will always have some tricky",
    "start": "110000",
    "end": "111920"
  },
  {
    "text": "logic",
    "start": "111920",
    "end": "113040"
  },
  {
    "text": "where in this logic we have we are going",
    "start": "113040",
    "end": "115520"
  },
  {
    "text": "to process the data frame and here is",
    "start": "115520",
    "end": "117920"
  },
  {
    "text": "the business logic we have four columns",
    "start": "117920",
    "end": "120399"
  },
  {
    "text": "a b c d they are all strings and for any",
    "start": "120399",
    "end": "123280"
  },
  {
    "text": "given row if the number of non-null",
    "start": "123280",
    "end": "125360"
  },
  {
    "text": "values is less than two then we drop the",
    "start": "125360",
    "end": "127520"
  },
  {
    "text": "row and then otherwise we concatenate",
    "start": "127520",
    "end": "130319"
  },
  {
    "text": "the non-null columns in order and output",
    "start": "130319",
    "end": "132879"
  },
  {
    "text": "the value as e-column",
    "start": "132879",
    "end": "135280"
  },
  {
    "text": "and also keep the original columns right",
    "start": "135280",
    "end": "137840"
  },
  {
    "text": "this is not so difficult and",
    "start": "137840",
    "end": "140959"
  },
  {
    "text": "the most intuitive way to express this",
    "start": "140959",
    "end": "143280"
  },
  {
    "text": "logic",
    "start": "143280",
    "end": "144319"
  },
  {
    "text": "i think",
    "start": "144319",
    "end": "145440"
  },
  {
    "text": "is in this way you should take an",
    "start": "145440",
    "end": "147599"
  },
  {
    "text": "iterable of lift as a list of values and",
    "start": "147599",
    "end": "151440"
  },
  {
    "text": "then",
    "start": "151440",
    "end": "152239"
  },
  {
    "text": "yield those values when it meets the",
    "start": "152239",
    "end": "155440"
  },
  {
    "text": "criteria",
    "start": "155440",
    "end": "156560"
  },
  {
    "text": "right this is just python code and also",
    "start": "156560",
    "end": "159440"
  },
  {
    "text": "this code is very testable so now let's",
    "start": "159440",
    "end": "162000"
  },
  {
    "text": "just write as you can see the last two",
    "start": "162000",
    "end": "164319"
  },
  {
    "text": "rows will be dropped because there are",
    "start": "164319",
    "end": "166879"
  },
  {
    "text": "too many nuns",
    "start": "166879",
    "end": "168640"
  },
  {
    "text": "okay so this is the logic and now let's",
    "start": "168640",
    "end": "171680"
  },
  {
    "text": "build some um sample data for us to work",
    "start": "171680",
    "end": "175040"
  },
  {
    "text": "on and you don't have to care about this",
    "start": "175040",
    "end": "177280"
  },
  {
    "text": "function",
    "start": "177280",
    "end": "178319"
  },
  {
    "text": "just look at this data frame so this",
    "start": "178319",
    "end": "179920"
  },
  {
    "text": "data frame has four columns a b c d and",
    "start": "179920",
    "end": "182959"
  },
  {
    "text": "it has some nouns right so now the",
    "start": "182959",
    "end": "185120"
  },
  {
    "text": "question is very simple how can you",
    "start": "185120",
    "end": "187120"
  },
  {
    "text": "apply this function",
    "start": "187120",
    "end": "190239"
  },
  {
    "text": "onto this",
    "start": "190239",
    "end": "191680"
  },
  {
    "text": "sample data this is dependence data",
    "start": "191680",
    "end": "193440"
  },
  {
    "text": "frame you know even you know even you",
    "start": "193440",
    "end": "195680"
  },
  {
    "text": "use apply you cannot directly use apply",
    "start": "195680",
    "end": "200400"
  },
  {
    "text": "on this concat on this function you have",
    "start": "200400",
    "end": "202640"
  },
  {
    "text": "to do some sort of transformation i",
    "start": "202640",
    "end": "204959"
  },
  {
    "text": "don't have",
    "start": "204959",
    "end": "206159"
  },
  {
    "text": "i don't put a",
    "start": "206159",
    "end": "208319"
  },
  {
    "text": "solution of pandas here",
    "start": "208319",
    "end": "210720"
  },
  {
    "text": "because we don't have much time",
    "start": "210720",
    "end": "212799"
  },
  {
    "text": "uh but uh now let's directly jump in",
    "start": "212799",
    "end": "215599"
  },
  {
    "text": "house figures solving this problem",
    "start": "215599",
    "end": "218400"
  },
  {
    "text": "so remember that the semantic is i want",
    "start": "218400",
    "end": "221200"
  },
  {
    "text": "to apply that function to that data",
    "start": "221200",
    "end": "222959"
  },
  {
    "text": "frame right it's that simple",
    "start": "222959",
    "end": "225120"
  },
  {
    "text": "let's see how solving that so in",
    "start": "225120",
    "end": "227200"
  },
  {
    "text": "field we just import transform",
    "start": "227200",
    "end": "230000"
  },
  {
    "text": "we want to apply this concat function",
    "start": "230000",
    "end": "232640"
  },
  {
    "text": "onto this pandas data frame and also",
    "start": "232640",
    "end": "234799"
  },
  {
    "text": "specify output schema is the existing",
    "start": "234799",
    "end": "237519"
  },
  {
    "text": "schema",
    "start": "237519",
    "end": "238640"
  },
  {
    "text": "plus a e column so that's how field is",
    "start": "238640",
    "end": "241840"
  },
  {
    "text": "solving this pandas frame a data frame",
    "start": "241840",
    "end": "244720"
  },
  {
    "text": "problem okay now think about that",
    "start": "244720",
    "end": "248959"
  },
  {
    "text": "but in your real production this data",
    "start": "250480",
    "end": "252799"
  },
  {
    "text": "frame can be a spark data frame because",
    "start": "252799",
    "end": "255120"
  },
  {
    "text": "you're probably",
    "start": "255120",
    "end": "256239"
  },
  {
    "text": "processing terabytes of data right so",
    "start": "256239",
    "end": "259120"
  },
  {
    "text": "when you want to scale to spark the",
    "start": "259120",
    "end": "261359"
  },
  {
    "text": "first thing you need to do is",
    "start": "261359",
    "end": "263360"
  },
  {
    "text": "just initialize a spark section so here",
    "start": "263360",
    "end": "265759"
  },
  {
    "text": "is for simplicity reason i just start a",
    "start": "265759",
    "end": "268160"
  },
  {
    "text": "local smart session but you always have",
    "start": "268160",
    "end": "270320"
  },
  {
    "text": "your own way to get this back session",
    "start": "270320",
    "end": "272560"
  },
  {
    "text": "right okay so now the question is how",
    "start": "272560",
    "end": "275199"
  },
  {
    "text": "can you apply this function",
    "start": "275199",
    "end": "277759"
  },
  {
    "text": "to this data frame using spark so look",
    "start": "277759",
    "end": "280560"
  },
  {
    "start": "280000",
    "end": "383000"
  },
  {
    "text": "at",
    "start": "280560",
    "end": "281280"
  },
  {
    "text": "how spark is doing this there are",
    "start": "281280",
    "end": "283520"
  },
  {
    "text": "several things first you have to bring",
    "start": "283520",
    "end": "285520"
  },
  {
    "text": "in this pd sample",
    "start": "285520",
    "end": "287360"
  },
  {
    "text": "into spark",
    "start": "287360",
    "end": "288720"
  },
  {
    "text": "right and the second",
    "start": "288720",
    "end": "290880"
  },
  {
    "text": "the map partitions",
    "start": "290880",
    "end": "292639"
  },
  {
    "text": "has to be",
    "start": "292639",
    "end": "294240"
  },
  {
    "text": "used on rdd so you have to convert it to",
    "start": "294240",
    "end": "296560"
  },
  {
    "text": "rdd and map right and in the map",
    "start": "296560",
    "end": "299680"
  },
  {
    "text": "partitions it can only take a uterus",
    "start": "299680",
    "end": "302800"
  },
  {
    "text": "iterable of rows this row is a spark",
    "start": "302800",
    "end": "305520"
  },
  {
    "text": "specific class a tuple and then you have",
    "start": "305520",
    "end": "308560"
  },
  {
    "text": "to do this conversion by yourself so",
    "start": "308560",
    "end": "310560"
  },
  {
    "text": "that conquet can accept this input type",
    "start": "310560",
    "end": "314960"
  },
  {
    "text": "right and another thing is after you do",
    "start": "314960",
    "end": "317440"
  },
  {
    "text": "all this kind of conversion you have to",
    "start": "317440",
    "end": "319919"
  },
  {
    "text": "convert back the rdd from from from the",
    "start": "319919",
    "end": "322880"
  },
  {
    "text": "rdd to the spark data from and now here",
    "start": "322880",
    "end": "326240"
  },
  {
    "text": "this is probably the simplest way oh",
    "start": "326240",
    "end": "328240"
  },
  {
    "text": "sorry the simplest way",
    "start": "328240",
    "end": "330400"
  },
  {
    "text": "to",
    "start": "330400",
    "end": "331680"
  },
  {
    "text": "um it's probably the simplest way to",
    "start": "331680",
    "end": "333840"
  },
  {
    "text": "describe your schema and i guess a lot",
    "start": "333840",
    "end": "336320"
  },
  {
    "text": "of people if using spark you are using a",
    "start": "336320",
    "end": "339280"
  },
  {
    "text": "more tedious way to describe this",
    "start": "339280",
    "end": "341600"
  },
  {
    "text": "especially when the schema is",
    "start": "341600",
    "end": "343120"
  },
  {
    "text": "complicated",
    "start": "343120",
    "end": "344560"
  },
  {
    "text": "and now",
    "start": "344560",
    "end": "345680"
  },
  {
    "text": "you see we solve this problem right it's",
    "start": "345680",
    "end": "348560"
  },
  {
    "text": "good and it's over 10 lines of code",
    "start": "348560",
    "end": "351520"
  },
  {
    "text": "additional",
    "start": "351520",
    "end": "352720"
  },
  {
    "text": "boilerplate code but think about that",
    "start": "352720",
    "end": "354479"
  },
  {
    "text": "this is just one function what if you",
    "start": "354479",
    "end": "356880"
  },
  {
    "text": "have a lot of such transformation logics",
    "start": "356880",
    "end": "359759"
  },
  {
    "text": "how much convert boilerplate code you",
    "start": "359759",
    "end": "361680"
  },
  {
    "text": "have to write now let's see how field is",
    "start": "361680",
    "end": "363919"
  },
  {
    "text": "solving this",
    "start": "363919",
    "end": "365199"
  },
  {
    "text": "as you can see in field",
    "start": "365199",
    "end": "367440"
  },
  {
    "text": "again it's only",
    "start": "367440",
    "end": "369520"
  },
  {
    "text": "the",
    "start": "369520",
    "end": "370319"
  },
  {
    "text": "the transform function and now",
    "start": "370319",
    "end": "372880"
  },
  {
    "text": "instead of using pde sample we just use",
    "start": "372880",
    "end": "375360"
  },
  {
    "text": "spark sample",
    "start": "375360",
    "end": "376639"
  },
  {
    "text": "and this is not changed we still use",
    "start": "376639",
    "end": "378560"
  },
  {
    "text": "concat schema is not changed and here we",
    "start": "378560",
    "end": "381120"
  },
  {
    "text": "just tell the system okay use spark",
    "start": "381120",
    "end": "383199"
  },
  {
    "start": "383000",
    "end": "575000"
  },
  {
    "text": "session",
    "start": "383199",
    "end": "384160"
  },
  {
    "text": "to run this transformation",
    "start": "384160",
    "end": "386639"
  },
  {
    "text": "this means uh i want fugu to trans to",
    "start": "386639",
    "end": "389520"
  },
  {
    "text": "translate",
    "start": "389520",
    "end": "390639"
  },
  {
    "text": "this semantic to spark operations and to",
    "start": "390639",
    "end": "393680"
  },
  {
    "text": "run on smack",
    "start": "393680",
    "end": "395680"
  },
  {
    "text": "so it's just one line of code and it can",
    "start": "395680",
    "end": "398240"
  },
  {
    "text": "solve that problem and the next",
    "start": "398240",
    "end": "400800"
  },
  {
    "text": "example is",
    "start": "400800",
    "end": "402240"
  },
  {
    "text": "um what if i don't even want to convert",
    "start": "402240",
    "end": "405360"
  },
  {
    "text": "the original data frame to spark data",
    "start": "405360",
    "end": "407440"
  },
  {
    "text": "frame yeah actually you can directly say",
    "start": "407440",
    "end": "410080"
  },
  {
    "text": "i want to",
    "start": "410080",
    "end": "411280"
  },
  {
    "text": "transform this pandas data frame",
    "start": "411280",
    "end": "414080"
  },
  {
    "text": "using this native smart function native",
    "start": "414080",
    "end": "416639"
  },
  {
    "text": "python function but i want everything",
    "start": "416639",
    "end": "418880"
  },
  {
    "text": "happen on spark you can also do this so",
    "start": "418880",
    "end": "421919"
  },
  {
    "text": "this transformation this conversion data",
    "start": "421919",
    "end": "424000"
  },
  {
    "text": "conversion is automatically done",
    "start": "424000",
    "end": "427440"
  },
  {
    "text": "on the field level",
    "start": "427440",
    "end": "430400"
  },
  {
    "text": "okay so now let's think about another",
    "start": "432800",
    "end": "435759"
  },
  {
    "text": "case",
    "start": "435759",
    "end": "436639"
  },
  {
    "text": "what if",
    "start": "436639",
    "end": "439039"
  },
  {
    "text": "we have a we have a business requirement",
    "start": "439039",
    "end": "441440"
  },
  {
    "text": "change",
    "start": "441440",
    "end": "442479"
  },
  {
    "text": "uh remember that we had a b c d four",
    "start": "442479",
    "end": "445440"
  },
  {
    "text": "columns now for some reason",
    "start": "445440",
    "end": "448160"
  },
  {
    "text": "the column d no longer exists we don't",
    "start": "448160",
    "end": "450400"
  },
  {
    "text": "want column d right so now we create",
    "start": "450400",
    "end": "453199"
  },
  {
    "text": "another data sample called pd sample two",
    "start": "453199",
    "end": "456319"
  },
  {
    "text": "and pd sample two what if",
    "start": "456319",
    "end": "458960"
  },
  {
    "text": "other business logic has not changed",
    "start": "458960",
    "end": "461120"
  },
  {
    "text": "just just that we we miss one column",
    "start": "461120",
    "end": "464240"
  },
  {
    "text": "will that cause any problems actually if",
    "start": "464240",
    "end": "466400"
  },
  {
    "text": "you try the exactly same thing on spark",
    "start": "466400",
    "end": "469520"
  },
  {
    "text": "you will get an exception why because",
    "start": "469520",
    "end": "472319"
  },
  {
    "text": "the spark logic look at this",
    "start": "472319",
    "end": "475120"
  },
  {
    "text": "you have hard-coded too many things",
    "start": "475120",
    "end": "478479"
  },
  {
    "text": "it's not flexible enough it cannot",
    "start": "478479",
    "end": "482800"
  },
  {
    "text": "you cannot it cannot adapt to this this",
    "start": "482800",
    "end": "485280"
  },
  {
    "text": "changing environment right so what you",
    "start": "485280",
    "end": "487759"
  },
  {
    "text": "have to do",
    "start": "487759",
    "end": "488800"
  },
  {
    "text": "just for this small change",
    "start": "488800",
    "end": "490720"
  },
  {
    "text": "you have to rewrite your wrapper",
    "start": "490720",
    "end": "493520"
  },
  {
    "text": "and you have to rewrite this output",
    "start": "493520",
    "end": "495840"
  },
  {
    "text": "schema",
    "start": "495840",
    "end": "497039"
  },
  {
    "text": "all right so it's",
    "start": "497039",
    "end": "498639"
  },
  {
    "text": "so",
    "start": "498639",
    "end": "499599"
  },
  {
    "text": "in real production you will think oh",
    "start": "499599",
    "end": "501680"
  },
  {
    "text": "what should i do should i just is this",
    "start": "501680",
    "end": "504240"
  },
  {
    "text": "worth it or not right it's it's it's a",
    "start": "504240",
    "end": "506639"
  },
  {
    "text": "struggle to to to make the technical",
    "start": "506639",
    "end": "509680"
  },
  {
    "text": "decision right but what if we want to",
    "start": "509680",
    "end": "513039"
  },
  {
    "text": "apply this fugue",
    "start": "513039",
    "end": "514959"
  },
  {
    "text": "so look at this there is no change at",
    "start": "514959",
    "end": "517440"
  },
  {
    "text": "all so you still can apply this nsc",
    "start": "517440",
    "end": "520159"
  },
  {
    "text": "frame",
    "start": "520159",
    "end": "520959"
  },
  {
    "text": "with uh without d column",
    "start": "520959",
    "end": "523839"
  },
  {
    "text": "and you can still use",
    "start": "523839",
    "end": "525760"
  },
  {
    "text": "exactly the same function transform",
    "start": "525760",
    "end": "527519"
  },
  {
    "text": "function and everything else is the same",
    "start": "527519",
    "end": "530480"
  },
  {
    "text": "this is because",
    "start": "530480",
    "end": "532160"
  },
  {
    "text": "in field for example the schema",
    "start": "532160",
    "end": "534720"
  },
  {
    "text": "this kind of expression is very dynamic",
    "start": "534720",
    "end": "537440"
  },
  {
    "text": "already and it can be determined it can",
    "start": "537440",
    "end": "539839"
  },
  {
    "text": "be determined by the input",
    "start": "539839",
    "end": "542160"
  },
  {
    "text": "data frame and also for the concat",
    "start": "542160",
    "end": "544399"
  },
  {
    "text": "because we have the most intuitive",
    "start": "544399",
    "end": "547519"
  },
  {
    "text": "expression",
    "start": "547519",
    "end": "548480"
  },
  {
    "text": "so",
    "start": "548480",
    "end": "549600"
  },
  {
    "text": "it's it's actually column agnostic you",
    "start": "549600",
    "end": "552320"
  },
  {
    "text": "can have more columns you can have less",
    "start": "552320",
    "end": "554160"
  },
  {
    "text": "columns if other things don't change",
    "start": "554160",
    "end": "556399"
  },
  {
    "text": "your functions don't change and few code",
    "start": "556399",
    "end": "558880"
  },
  {
    "text": "don't change",
    "start": "558880",
    "end": "562120"
  },
  {
    "text": "okay",
    "start": "563040",
    "end": "563920"
  },
  {
    "text": "so now let's switch to the second",
    "start": "563920",
    "end": "565839"
  },
  {
    "text": "example",
    "start": "565839",
    "end": "567040"
  },
  {
    "text": "we want to do",
    "start": "567040",
    "end": "569200"
  },
  {
    "text": "machine learning now",
    "start": "569200",
    "end": "572080"
  },
  {
    "text": "um so in the second example",
    "start": "572240",
    "end": "575279"
  },
  {
    "text": "we have",
    "start": "575279",
    "end": "576480"
  },
  {
    "text": "we have a data frame",
    "start": "576480",
    "end": "578160"
  },
  {
    "text": "with many uh categories",
    "start": "578160",
    "end": "580640"
  },
  {
    "text": "and for each category",
    "start": "580640",
    "end": "582560"
  },
  {
    "text": "it's uh",
    "start": "582560",
    "end": "583680"
  },
  {
    "text": "the the features abcde",
    "start": "583680",
    "end": "586560"
  },
  {
    "text": "and the value the target the y",
    "start": "586560",
    "end": "589600"
  },
  {
    "text": "they have different",
    "start": "589600",
    "end": "591040"
  },
  {
    "text": "they have a different",
    "start": "591040",
    "end": "592959"
  },
  {
    "text": "relations so meaning that",
    "start": "592959",
    "end": "597360"
  },
  {
    "text": "ideally you should train those models",
    "start": "597680",
    "end": "599920"
  },
  {
    "text": "separately for each category because",
    "start": "599920",
    "end": "601839"
  },
  {
    "text": "they are different machine learning",
    "start": "601839",
    "end": "603360"
  },
  {
    "text": "problems",
    "start": "603360",
    "end": "604959"
  },
  {
    "text": "but here now first of all let's just",
    "start": "604959",
    "end": "607040"
  },
  {
    "text": "generate that training set and let's",
    "start": "607040",
    "end": "609040"
  },
  {
    "text": "take a look",
    "start": "609040",
    "end": "610240"
  },
  {
    "text": "so this is the training that training",
    "start": "610240",
    "end": "612720"
  },
  {
    "text": "data have like 400",
    "start": "612720",
    "end": "615279"
  },
  {
    "text": "and test data will",
    "start": "615279",
    "end": "616839"
  },
  {
    "text": "have several thousand",
    "start": "616839",
    "end": "619519"
  },
  {
    "text": "and we have the features",
    "start": "619519",
    "end": "622399"
  },
  {
    "text": "um",
    "start": "622399",
    "end": "623360"
  },
  {
    "text": "the ground truth",
    "start": "623360",
    "end": "625040"
  },
  {
    "text": "and also the category and the",
    "start": "625040",
    "end": "627920"
  },
  {
    "text": "if it is trained so for trinity is all",
    "start": "627920",
    "end": "629839"
  },
  {
    "text": "true right so okay so now first of all",
    "start": "629839",
    "end": "633120"
  },
  {
    "text": "let's try to train a logistic regression",
    "start": "633120",
    "end": "635760"
  },
  {
    "text": "on the entire data set on the entire",
    "start": "635760",
    "end": "637680"
  },
  {
    "text": "training data set",
    "start": "637680",
    "end": "639760"
  },
  {
    "text": "okay so we train this data set uh on the",
    "start": "639760",
    "end": "642560"
  },
  {
    "text": "entire data set and also we can write a",
    "start": "642560",
    "end": "645440"
  },
  {
    "text": "very simple predictive function",
    "start": "645440",
    "end": "647760"
  },
  {
    "text": "predict function on this pendant's data",
    "start": "647760",
    "end": "649600"
  },
  {
    "text": "frame using this logistic regression",
    "start": "649600",
    "end": "652320"
  },
  {
    "text": "model and we can get the prediction",
    "start": "652320",
    "end": "654880"
  },
  {
    "text": "right so",
    "start": "654880",
    "end": "655920"
  },
  {
    "text": "so here is just very simple python",
    "start": "655920",
    "end": "658160"
  },
  {
    "text": "functions it has nothing to do with",
    "start": "658160",
    "end": "660240"
  },
  {
    "text": "spark or anything fancy",
    "start": "660240",
    "end": "662720"
  },
  {
    "text": "okay",
    "start": "662720",
    "end": "663519"
  },
  {
    "text": "now think about that",
    "start": "663519",
    "end": "665360"
  },
  {
    "text": "how can we if if the test data is huge",
    "start": "665360",
    "end": "668480"
  },
  {
    "text": "how can we apply this predict function",
    "start": "668480",
    "end": "670880"
  },
  {
    "text": "to that huge spark data frame",
    "start": "670880",
    "end": "673360"
  },
  {
    "text": "okay so if you want to do that in spark",
    "start": "673360",
    "end": "676720"
  },
  {
    "text": "now you can see that the nasty uh things",
    "start": "676720",
    "end": "679440"
  },
  {
    "text": "about spark schemas you have to import a",
    "start": "679440",
    "end": "682399"
  },
  {
    "text": "lot of like",
    "start": "682399",
    "end": "683839"
  },
  {
    "text": "weird weird classes like extractor type",
    "start": "683839",
    "end": "687040"
  },
  {
    "text": "struct field integer type so look at",
    "start": "687040",
    "end": "689360"
  },
  {
    "text": "this code what do you do first of all",
    "start": "689360",
    "end": "691519"
  },
  {
    "text": "you have to bring in this data frame",
    "start": "691519",
    "end": "693600"
  },
  {
    "text": "into spark and then you have to",
    "start": "693600",
    "end": "696720"
  },
  {
    "text": "you have to construct the schema so in",
    "start": "696720",
    "end": "699279"
  },
  {
    "text": "field it's like a star comma the new",
    "start": "699279",
    "end": "701440"
  },
  {
    "text": "schema but here you have to do things in",
    "start": "701440",
    "end": "703839"
  },
  {
    "text": "this way and another thing is when you",
    "start": "703839",
    "end": "706320"
  },
  {
    "text": "want to",
    "start": "706320",
    "end": "707680"
  },
  {
    "text": "when you want to use this predict you",
    "start": "707680",
    "end": "709360"
  },
  {
    "text": "cannot directly use predict because",
    "start": "709360",
    "end": "712320"
  },
  {
    "text": "in spark",
    "start": "712320",
    "end": "713680"
  },
  {
    "text": "in pandas udf",
    "start": "713680",
    "end": "715519"
  },
  {
    "text": "after 3.2",
    "start": "715519",
    "end": "717360"
  },
  {
    "text": "sorry so after after spark 3",
    "start": "717360",
    "end": "720399"
  },
  {
    "text": "you have to",
    "start": "720399",
    "end": "721839"
  },
  {
    "text": "have this type of function",
    "start": "721839",
    "end": "724480"
  },
  {
    "text": "to work with pandas udf it has to take a",
    "start": "724480",
    "end": "728000"
  },
  {
    "text": "iterator of pandas dataframe",
    "start": "728000",
    "end": "730880"
  },
  {
    "text": "as input and you have to",
    "start": "730880",
    "end": "733519"
  },
  {
    "text": "return the iterator of pendant's data",
    "start": "733519",
    "end": "735200"
  },
  {
    "text": "frame so",
    "start": "735200",
    "end": "737360"
  },
  {
    "text": "so as you can see that",
    "start": "737360",
    "end": "740000"
  },
  {
    "text": "we have to write a wrapper for this just",
    "start": "740000",
    "end": "742320"
  },
  {
    "text": "for this purpose for just for this",
    "start": "742320",
    "end": "744320"
  },
  {
    "text": "purpose",
    "start": "744320",
    "end": "745680"
  },
  {
    "text": "um and and and",
    "start": "745680",
    "end": "748000"
  },
  {
    "text": "and in the end you just we you just try",
    "start": "748000",
    "end": "750560"
  },
  {
    "text": "to use a select statement to compute the",
    "start": "750560",
    "end": "753680"
  },
  {
    "text": "precision where this is the sum of two",
    "start": "753680",
    "end": "755920"
  },
  {
    "text": "positives and this is the sum of all",
    "start": "755920",
    "end": "758320"
  },
  {
    "text": "positive predictions",
    "start": "758320",
    "end": "760320"
  },
  {
    "text": "okay so",
    "start": "760320",
    "end": "763120"
  },
  {
    "start": "766000",
    "end": "840000"
  },
  {
    "text": "as you can see it works right but this",
    "start": "766480",
    "end": "768880"
  },
  {
    "text": "code is really tedious and it has a lot",
    "start": "768880",
    "end": "772000"
  },
  {
    "text": "of",
    "start": "772000",
    "end": "772720"
  },
  {
    "text": "spark dependencies right you with this",
    "start": "772720",
    "end": "775360"
  },
  {
    "text": "code see how many things you have to",
    "start": "775360",
    "end": "777360"
  },
  {
    "text": "import from spark how many how many like",
    "start": "777360",
    "end": "780160"
  },
  {
    "text": "a special data types you have to learn",
    "start": "780160",
    "end": "782959"
  },
  {
    "text": "if you want to use mark",
    "start": "782959",
    "end": "784839"
  },
  {
    "text": "right yes",
    "start": "784839",
    "end": "785920"
  },
  {
    "text": "but what about fugue so again in fugue",
    "start": "785920",
    "end": "789360"
  },
  {
    "text": "it's just two lines",
    "start": "789360",
    "end": "791040"
  },
  {
    "text": "the first line is still transformed",
    "start": "791040",
    "end": "793519"
  },
  {
    "text": "and transform we can directly apply on",
    "start": "793519",
    "end": "796000"
  },
  {
    "text": "that test data set no matter it is",
    "start": "796000",
    "end": "798399"
  },
  {
    "text": "pandas dataframe spark data frame dash",
    "start": "798399",
    "end": "800320"
  },
  {
    "text": "data frame",
    "start": "800320",
    "end": "801680"
  },
  {
    "text": "or qdf any data frame netflix supports",
    "start": "801680",
    "end": "805360"
  },
  {
    "text": "and then the predict function is just",
    "start": "805360",
    "end": "807760"
  },
  {
    "text": "that original function right and schema",
    "start": "807760",
    "end": "811120"
  },
  {
    "text": "and you can also specify the parameters",
    "start": "811120",
    "end": "813440"
  },
  {
    "text": "to passing the the",
    "start": "813440",
    "end": "816480"
  },
  {
    "text": "logistic regression and then spec",
    "start": "816480",
    "end": "818720"
  },
  {
    "text": "specify this back section and this the",
    "start": "818720",
    "end": "821440"
  },
  {
    "text": "output of this is native spark data",
    "start": "821440",
    "end": "824160"
  },
  {
    "text": "frame so you can do exactly the same",
    "start": "824160",
    "end": "826480"
  },
  {
    "text": "thing here to compute to compute the",
    "start": "826480",
    "end": "828639"
  },
  {
    "text": "precision",
    "start": "828639",
    "end": "830480"
  },
  {
    "text": "so we reduce",
    "start": "830480",
    "end": "832000"
  },
  {
    "text": "this whole lot of code to just one line",
    "start": "832000",
    "end": "834800"
  },
  {
    "text": "of code",
    "start": "834800",
    "end": "836880"
  },
  {
    "text": "okay and we get the same result",
    "start": "836880",
    "end": "840320"
  },
  {
    "text": "okay then",
    "start": "840320",
    "end": "842399"
  },
  {
    "text": "we want to do something that's more",
    "start": "842399",
    "end": "843839"
  },
  {
    "text": "interesting so think about that um as i",
    "start": "843839",
    "end": "846959"
  },
  {
    "text": "said for different categories it's",
    "start": "846959",
    "end": "848720"
  },
  {
    "text": "actually a different machine learning",
    "start": "848720",
    "end": "850320"
  },
  {
    "text": "problem what if for different categories",
    "start": "850320",
    "end": "852320"
  },
  {
    "text": "we just train a model and then we can",
    "start": "852320",
    "end": "854800"
  },
  {
    "text": "apply that specific model",
    "start": "854800",
    "end": "857199"
  },
  {
    "text": "to",
    "start": "857199",
    "end": "858079"
  },
  {
    "text": "the uh data frame belongs to that",
    "start": "858079",
    "end": "861360"
  },
  {
    "text": "category so this is how we do that",
    "start": "861360",
    "end": "864320"
  },
  {
    "text": "and first of all let's think about",
    "start": "864320",
    "end": "866560"
  },
  {
    "text": "python code so first of all given this",
    "start": "866560",
    "end": "869680"
  },
  {
    "text": "data frame is a category of training",
    "start": "869680",
    "end": "871920"
  },
  {
    "text": "data right what do we do it's it's",
    "start": "871920",
    "end": "874720"
  },
  {
    "text": "straightforward right so we just",
    "start": "874720",
    "end": "877279"
  },
  {
    "text": "return the category name which is",
    "start": "877279",
    "end": "880160"
  },
  {
    "text": "the first value of this",
    "start": "880160",
    "end": "882240"
  },
  {
    "text": "category column because this diaphragm",
    "start": "882240",
    "end": "884639"
  },
  {
    "text": "all have the same category and then the",
    "start": "884639",
    "end": "886880"
  },
  {
    "text": "model what is model which is pickle we",
    "start": "886880",
    "end": "889120"
  },
  {
    "text": "just depict this logistic regression",
    "start": "889120",
    "end": "892160"
  },
  {
    "text": "model that we train on this category of",
    "start": "892160",
    "end": "894720"
  },
  {
    "text": "training data right so we return",
    "start": "894720",
    "end": "898240"
  },
  {
    "text": "a string and a binary block",
    "start": "898240",
    "end": "902000"
  },
  {
    "start": "902000",
    "end": "958000"
  },
  {
    "text": "okay for predict category a predicted",
    "start": "902000",
    "end": "904959"
  },
  {
    "text": "category when we get a model we get a",
    "start": "904959",
    "end": "907440"
  },
  {
    "text": "model which is the output of this step",
    "start": "907440",
    "end": "910399"
  },
  {
    "text": "we know what is inside right and also",
    "start": "910399",
    "end": "912720"
  },
  {
    "text": "this df is the df we want to predict on",
    "start": "912720",
    "end": "915839"
  },
  {
    "text": "so it's so here we just add an assertion",
    "start": "915839",
    "end": "919040"
  },
  {
    "text": "to make sure we don't break anything fig",
    "start": "919040",
    "end": "921440"
  },
  {
    "text": "doesn't break anything and then here we",
    "start": "921440",
    "end": "923760"
  },
  {
    "text": "just the pickle loads this",
    "start": "923760",
    "end": "926800"
  },
  {
    "text": "this model just recover this model from",
    "start": "926800",
    "end": "929279"
  },
  {
    "text": "this data structure",
    "start": "929279",
    "end": "931040"
  },
  {
    "text": "and then we just predict on this data",
    "start": "931040",
    "end": "933519"
  },
  {
    "text": "frame and assign to the prod column",
    "start": "933519",
    "end": "936959"
  },
  {
    "text": "right so",
    "start": "936959",
    "end": "938240"
  },
  {
    "text": "it's just a simple python it has nothing",
    "start": "938240",
    "end": "940399"
  },
  {
    "text": "to do with anything else okay now let's",
    "start": "940399",
    "end": "942560"
  },
  {
    "text": "see how we use fugue to orchestrate",
    "start": "942560",
    "end": "944720"
  },
  {
    "text": "these two simple python functions so",
    "start": "944720",
    "end": "947279"
  },
  {
    "text": "it's no longer transform and actually to",
    "start": "947279",
    "end": "949759"
  },
  {
    "text": "be honest transform is just one tiny",
    "start": "949759",
    "end": "952079"
  },
  {
    "text": "feature of fugue it covers a lot more",
    "start": "952079",
    "end": "954800"
  },
  {
    "text": "things than just transform so here we",
    "start": "954800",
    "end": "957680"
  },
  {
    "text": "use some more advanced features of you",
    "start": "957680",
    "end": "960160"
  },
  {
    "start": "958000",
    "end": "1022000"
  },
  {
    "text": "so actually figure is all about direct",
    "start": "960160",
    "end": "962959"
  },
  {
    "text": "directed acyclic graph so we build a",
    "start": "962959",
    "end": "966160"
  },
  {
    "text": "field workflow and we just get the train",
    "start": "966160",
    "end": "969279"
  },
  {
    "text": "and we predict we partition by category",
    "start": "969279",
    "end": "972800"
  },
  {
    "text": "and then we transform using this",
    "start": "972800",
    "end": "975279"
  },
  {
    "text": "train uh cat",
    "start": "975279",
    "end": "977279"
  },
  {
    "text": "right so this is first step so this step",
    "start": "977279",
    "end": "979920"
  },
  {
    "text": "we distributed train many many models",
    "start": "979920",
    "end": "982800"
  },
  {
    "text": "and the second step we just zip",
    "start": "982800",
    "end": "985440"
  },
  {
    "text": "this model with this test data set",
    "start": "985440",
    "end": "988800"
  },
  {
    "text": "and then transform",
    "start": "988800",
    "end": "990880"
  },
  {
    "text": "when we transform we just take in this",
    "start": "990880",
    "end": "994079"
  },
  {
    "text": "simple function which will take two data",
    "start": "994079",
    "end": "996399"
  },
  {
    "text": "frames",
    "start": "996399",
    "end": "997839"
  },
  {
    "text": "and then we'll operate on that so this",
    "start": "997839",
    "end": "999920"
  },
  {
    "text": "is a code transform in fugue",
    "start": "999920",
    "end": "1002079"
  },
  {
    "text": "and then in the end",
    "start": "1002079",
    "end": "1003759"
  },
  {
    "text": "this is a similar expression like what",
    "start": "1003759",
    "end": "1006240"
  },
  {
    "text": "we did in spark but",
    "start": "1006240",
    "end": "1008880"
  },
  {
    "text": "this expression is thermal cognitive it",
    "start": "1008880",
    "end": "1011279"
  },
  {
    "text": "can work on pendants it can work on that",
    "start": "1011279",
    "end": "1013279"
  },
  {
    "text": "kind of workout spot can work on any",
    "start": "1013279",
    "end": "1015199"
  },
  {
    "text": "execution engine",
    "start": "1015199",
    "end": "1018079"
  },
  {
    "start": "1022000",
    "end": "1038000"
  },
  {
    "text": "so as you can see after we train and",
    "start": "1023199",
    "end": "1026400"
  },
  {
    "text": "predict per category the overall",
    "start": "1026400",
    "end": "1029199"
  },
  {
    "text": "precision is much higher",
    "start": "1029199",
    "end": "1031360"
  },
  {
    "text": "than we train a single model on the",
    "start": "1031360",
    "end": "1033600"
  },
  {
    "text": "entire data set",
    "start": "1033600",
    "end": "1035038"
  },
  {
    "text": "it's almost 10 percent up right and now",
    "start": "1035039",
    "end": "1038720"
  },
  {
    "start": "1038000",
    "end": "1082000"
  },
  {
    "text": "the last thing i want to talk about",
    "start": "1038720",
    "end": "1040959"
  },
  {
    "text": "is physical",
    "start": "1040959",
    "end": "1042880"
  },
  {
    "text": "physical is a different way to express",
    "start": "1042880",
    "end": "1045360"
  },
  {
    "text": "your logic",
    "start": "1045360",
    "end": "1046558"
  },
  {
    "text": "but it's it the sequel will be",
    "start": "1046559",
    "end": "1048880"
  },
  {
    "text": "translated",
    "start": "1048880",
    "end": "1050480"
  },
  {
    "text": "to these operations",
    "start": "1050480",
    "end": "1052480"
  },
  {
    "text": "uh well you can keep your mindset and",
    "start": "1052480",
    "end": "1055520"
  },
  {
    "text": "your semantic or in omc core",
    "start": "1055520",
    "end": "1058960"
  },
  {
    "text": "so it's it's perfect for sql heavy",
    "start": "1058960",
    "end": "1061679"
  },
  {
    "text": "pipelines where you just need a tiny bit",
    "start": "1061679",
    "end": "1064240"
  },
  {
    "text": "help from python",
    "start": "1064240",
    "end": "1066559"
  },
  {
    "text": "so for example in this way",
    "start": "1066559",
    "end": "1068720"
  },
  {
    "text": "we just select we just construct the the",
    "start": "1068720",
    "end": "1071520"
  },
  {
    "text": "train date data set from the original",
    "start": "1071520",
    "end": "1074559"
  },
  {
    "text": "data",
    "start": "1074559",
    "end": "1076080"
  },
  {
    "text": "the data containing both and then we",
    "start": "1076080",
    "end": "1078320"
  },
  {
    "text": "just train model so this is is exactly",
    "start": "1078320",
    "end": "1080960"
  },
  {
    "text": "what we did here",
    "start": "1080960",
    "end": "1082720"
  },
  {
    "start": "1082000",
    "end": "1149000"
  },
  {
    "text": "and then you zip the two",
    "start": "1082720",
    "end": "1085679"
  },
  {
    "text": "data frames and then transform do the",
    "start": "1085679",
    "end": "1087919"
  },
  {
    "text": "prediction and then in the end you just",
    "start": "1087919",
    "end": "1089919"
  },
  {
    "text": "return the result so here the only",
    "start": "1089919",
    "end": "1092160"
  },
  {
    "text": "difference is that i in the end i want",
    "start": "1092160",
    "end": "1095520"
  },
  {
    "text": "when i predict i predict entire data set",
    "start": "1095520",
    "end": "1098240"
  },
  {
    "text": "containing the training set and test set",
    "start": "1098240",
    "end": "1100720"
  },
  {
    "text": "and so here you see here i just group by",
    "start": "1100720",
    "end": "1102960"
  },
  {
    "text": "trend group by this this flag so we can",
    "start": "1102960",
    "end": "1105840"
  },
  {
    "text": "see okay this trend how is the model",
    "start": "1105840",
    "end": "1109039"
  },
  {
    "text": "performance on the training on the",
    "start": "1109039",
    "end": "1111200"
  },
  {
    "text": "training data set itself as well as the",
    "start": "1111200",
    "end": "1113679"
  },
  {
    "text": "test data set as you can see very simple",
    "start": "1113679",
    "end": "1115840"
  },
  {
    "text": "we just get um",
    "start": "1115840",
    "end": "1117679"
  },
  {
    "text": "for training data sets we still get",
    "start": "1117679",
    "end": "1119600"
  },
  {
    "text": "better results which is expected and for",
    "start": "1119600",
    "end": "1121919"
  },
  {
    "text": "the test data set we get exactly the",
    "start": "1121919",
    "end": "1123919"
  },
  {
    "text": "same results",
    "start": "1123919",
    "end": "1125200"
  },
  {
    "text": "as what we have",
    "start": "1125200",
    "end": "1126960"
  },
  {
    "text": "okay so this is the end of the demo so i",
    "start": "1126960",
    "end": "1129520"
  },
  {
    "text": "will let kevin to talk about some more",
    "start": "1129520",
    "end": "1131440"
  },
  {
    "text": "details thank you",
    "start": "1131440",
    "end": "1135320"
  },
  {
    "text": "hey",
    "start": "1148840",
    "end": "1150559"
  },
  {
    "text": "so what we saw from that demo is that",
    "start": "1150559",
    "end": "1152720"
  },
  {
    "text": "when people move from small small data",
    "start": "1152720",
    "end": "1154960"
  },
  {
    "text": "panda size data to spark data frames",
    "start": "1154960",
    "end": "1157440"
  },
  {
    "text": "even for it to implement the same logic",
    "start": "1157440",
    "end": "1159760"
  },
  {
    "text": "there's a lot of boilerplate code that",
    "start": "1159760",
    "end": "1162080"
  },
  {
    "text": "has to be added or a lot of times code",
    "start": "1162080",
    "end": "1164799"
  },
  {
    "text": "has to be rewritten",
    "start": "1164799",
    "end": "1166320"
  },
  {
    "text": "but there's also other there's also",
    "start": "1166320",
    "end": "1168400"
  },
  {
    "text": "other problems that",
    "start": "1168400",
    "end": "1170799"
  },
  {
    "text": "happen from when transitioning from",
    "start": "1170799",
    "end": "1172480"
  },
  {
    "text": "smaller data to big data and we'll",
    "start": "1172480",
    "end": "1174480"
  },
  {
    "text": "explore these in this section",
    "start": "1174480",
    "end": "1176400"
  },
  {
    "text": "so the first is reusability of code in",
    "start": "1176400",
    "end": "1178960"
  },
  {
    "text": "the top the top code snippet is how",
    "start": "1178960",
    "end": "1181200"
  },
  {
    "text": "pandas would implement getting the",
    "start": "1181200",
    "end": "1183360"
  },
  {
    "text": "median of each group and the second one",
    "start": "1183360",
    "end": "1185520"
  },
  {
    "text": "is spark",
    "start": "1185520",
    "end": "1186559"
  },
  {
    "text": "and",
    "start": "1186559",
    "end": "1187280"
  },
  {
    "text": "obviously in spark there is there are",
    "start": "1187280",
    "end": "1188960"
  },
  {
    "text": "added parameters around the tolerance",
    "start": "1188960",
    "end": "1190960"
  },
  {
    "text": "because in a distributed system getting",
    "start": "1190960",
    "end": "1193280"
  },
  {
    "text": "the median is a very expensive operation",
    "start": "1193280",
    "end": "1195919"
  },
  {
    "text": "so normally you would just use an",
    "start": "1195919",
    "end": "1197440"
  },
  {
    "text": "approximation instead",
    "start": "1197440",
    "end": "1200080"
  },
  {
    "start": "1199000",
    "end": "1241000"
  },
  {
    "text": "second is inconsistency so with pandas",
    "start": "1200080",
    "end": "1202640"
  },
  {
    "text": "and spark even though they both operate",
    "start": "1202640",
    "end": "1204480"
  },
  {
    "text": "on data frames they they have a lot of",
    "start": "1204480",
    "end": "1207039"
  },
  {
    "text": "inconsistent edge cases so for example",
    "start": "1207039",
    "end": "1209679"
  },
  {
    "text": "pandas will join null with null whereas",
    "start": "1209679",
    "end": "1212159"
  },
  {
    "text": "spark will not join null records",
    "start": "1212159",
    "end": "1214240"
  },
  {
    "text": "together when you sort them pandas will",
    "start": "1214240",
    "end": "1217120"
  },
  {
    "text": "put nulls at the bottom of the column",
    "start": "1217120",
    "end": "1219360"
  },
  {
    "text": "for both ascending and descending spark",
    "start": "1219360",
    "end": "1221760"
  },
  {
    "text": "will treat null values as the biggest",
    "start": "1221760",
    "end": "1223440"
  },
  {
    "text": "value so it's the bottom",
    "start": "1223440",
    "end": "1225679"
  },
  {
    "text": "when you're ascending and top when",
    "start": "1225679",
    "end": "1226960"
  },
  {
    "text": "you're descending so even for these",
    "start": "1226960",
    "end": "1229120"
  },
  {
    "text": "types of things they're different",
    "start": "1229120",
    "end": "1230400"
  },
  {
    "text": "entirely different systems",
    "start": "1230400",
    "end": "1232559"
  },
  {
    "text": "and even if you wrap your pandas code",
    "start": "1232559",
    "end": "1234320"
  },
  {
    "text": "and bring it to spark",
    "start": "1234320",
    "end": "1235840"
  },
  {
    "text": "then you may you may have to still uh",
    "start": "1235840",
    "end": "1238159"
  },
  {
    "text": "write extra code to deal with these",
    "start": "1238159",
    "end": "1239840"
  },
  {
    "text": "inconsistencies",
    "start": "1239840",
    "end": "1241600"
  },
  {
    "start": "1241000",
    "end": "1280000"
  },
  {
    "text": "uh second is the third is that a lot of",
    "start": "1241600",
    "end": "1244720"
  },
  {
    "text": "pandas users are not familiar with the",
    "start": "1244720",
    "end": "1247520"
  },
  {
    "text": "lazy evaluation of spark so often you",
    "start": "1247520",
    "end": "1250240"
  },
  {
    "text": "find that",
    "start": "1250240",
    "end": "1251520"
  },
  {
    "text": "you find that",
    "start": "1251520",
    "end": "1252880"
  },
  {
    "text": "pipelines that have been moved to spark",
    "start": "1252880",
    "end": "1254480"
  },
  {
    "text": "offers",
    "start": "1254480",
    "end": "1255520"
  },
  {
    "text": "often suffer from uh inefficient",
    "start": "1255520",
    "end": "1257840"
  },
  {
    "text": "computation so in this uh in this graph",
    "start": "1257840",
    "end": "1260880"
  },
  {
    "text": "computation graph above if you don't",
    "start": "1260880",
    "end": "1263039"
  },
  {
    "text": "persist b then it's recomputed three",
    "start": "1263039",
    "end": "1266000"
  },
  {
    "text": "times for c d and e",
    "start": "1266000",
    "end": "1268640"
  },
  {
    "text": "when when those are computed so of",
    "start": "1268640",
    "end": "1270720"
  },
  {
    "text": "course if you use persist and spark then",
    "start": "1270720",
    "end": "1273280"
  },
  {
    "text": "then this would be kept in memory and",
    "start": "1273280",
    "end": "1275360"
  },
  {
    "text": "you don't have to recompute it but",
    "start": "1275360",
    "end": "1276960"
  },
  {
    "text": "pandas users are not familiar with this",
    "start": "1276960",
    "end": "1279280"
  },
  {
    "text": "concept",
    "start": "1279280",
    "end": "1280799"
  },
  {
    "start": "1280000",
    "end": "1315000"
  },
  {
    "text": "next is partition partitioning where",
    "start": "1280799",
    "end": "1283280"
  },
  {
    "text": "often you have to group your logic put",
    "start": "1283280",
    "end": "1286640"
  },
  {
    "text": "data that belongs to a logical group on",
    "start": "1286640",
    "end": "1288480"
  },
  {
    "text": "the same partition and this often",
    "start": "1288480",
    "end": "1290720"
  },
  {
    "text": "involves shuffling of the data across",
    "start": "1290720",
    "end": "1292640"
  },
  {
    "text": "your cluster",
    "start": "1292640",
    "end": "1293919"
  },
  {
    "text": "so this is something that pandas doesn't",
    "start": "1293919",
    "end": "1295760"
  },
  {
    "text": "have an interface for and doesn't uh",
    "start": "1295760",
    "end": "1298080"
  },
  {
    "text": "handle well",
    "start": "1298080",
    "end": "1299679"
  },
  {
    "text": "in pandas even that which is very heavy",
    "start": "1299679",
    "end": "1302240"
  },
  {
    "text": "which is very reliant on the index you",
    "start": "1302240",
    "end": "1304400"
  },
  {
    "text": "often find that people uh just use this",
    "start": "1304400",
    "end": "1307120"
  },
  {
    "text": "index as kind of a global um way to to",
    "start": "1307120",
    "end": "1310640"
  },
  {
    "text": "locate data but that that doesn't hold",
    "start": "1310640",
    "end": "1312720"
  },
  {
    "text": "true in a distributed setting",
    "start": "1312720",
    "end": "1315840"
  },
  {
    "start": "1315000",
    "end": "1342000"
  },
  {
    "text": "and of course testing because you have",
    "start": "1315840",
    "end": "1317600"
  },
  {
    "text": "to add all of these like extra functions",
    "start": "1317600",
    "end": "1319840"
  },
  {
    "text": "to bring pandas code to spark or even",
    "start": "1319840",
    "end": "1321600"
  },
  {
    "text": "python code to spark you normally have",
    "start": "1321600",
    "end": "1324000"
  },
  {
    "text": "to add a lot this is for one function",
    "start": "1324000",
    "end": "1326080"
  },
  {
    "text": "you have to add",
    "start": "1326080",
    "end": "1327360"
  },
  {
    "text": "minimum of two",
    "start": "1327360",
    "end": "1329120"
  },
  {
    "text": "helper functions and for each of these",
    "start": "1329120",
    "end": "1331280"
  },
  {
    "text": "functions that you introduce you have to",
    "start": "1331280",
    "end": "1333679"
  },
  {
    "text": "write additional tests and you have it",
    "start": "1333679",
    "end": "1336080"
  },
  {
    "text": "becomes a lot harder to to test this",
    "start": "1336080",
    "end": "1338640"
  },
  {
    "text": "because it's very coupled to these",
    "start": "1338640",
    "end": "1340799"
  },
  {
    "text": "boilerplate functions",
    "start": "1340799",
    "end": "1343120"
  },
  {
    "start": "1342000",
    "end": "1376000"
  },
  {
    "text": "and that's why fugue was created so",
    "start": "1343120",
    "end": "1344880"
  },
  {
    "text": "fugue is an abstraction layer for",
    "start": "1344880",
    "end": "1346640"
  },
  {
    "text": "distributed compute",
    "start": "1346640",
    "end": "1348480"
  },
  {
    "text": "the goal of fugue is to number one make",
    "start": "1348480",
    "end": "1350880"
  },
  {
    "text": "it easy to use spark and ask and also",
    "start": "1350880",
    "end": "1353520"
  },
  {
    "text": "number to unify the inconsistencies that",
    "start": "1353520",
    "end": "1356320"
  },
  {
    "text": "are present between these engines so in",
    "start": "1356320",
    "end": "1358559"
  },
  {
    "text": "field we as han showed we want people to",
    "start": "1358559",
    "end": "1361039"
  },
  {
    "text": "be able to describe their logic in",
    "start": "1361039",
    "end": "1362880"
  },
  {
    "text": "python or pandas or sql and then bring",
    "start": "1362880",
    "end": "1366400"
  },
  {
    "text": "it to fugue and choose the execution",
    "start": "1366400",
    "end": "1368240"
  },
  {
    "text": "engine so you can define your workflow",
    "start": "1368240",
    "end": "1370240"
  },
  {
    "text": "in python or pandas and then during",
    "start": "1370240",
    "end": "1372480"
  },
  {
    "text": "runtime choose i want to run this on",
    "start": "1372480",
    "end": "1374480"
  },
  {
    "text": "spark i want to run this on desk",
    "start": "1374480",
    "end": "1376960"
  },
  {
    "start": "1376000",
    "end": "1446000"
  },
  {
    "text": "without significant code change",
    "start": "1376960",
    "end": "1379039"
  },
  {
    "text": "and there's interesting properties that",
    "start": "1379039",
    "end": "1381360"
  },
  {
    "text": "uh",
    "start": "1381360",
    "end": "1382159"
  },
  {
    "text": "that come when when we can decouple",
    "start": "1382159",
    "end": "1384080"
  },
  {
    "text": "logic and execution so without fugue",
    "start": "1384080",
    "end": "1387440"
  },
  {
    "text": "when you use pandas your pandas code",
    "start": "1387440",
    "end": "1390159"
  },
  {
    "text": "is is tied to the pandas execution",
    "start": "1390159",
    "end": "1392720"
  },
  {
    "text": "engine and when you use pi spark code",
    "start": "1392720",
    "end": "1395120"
  },
  {
    "text": "your pi spark code is also tied to the",
    "start": "1395120",
    "end": "1396880"
  },
  {
    "text": "spark execution engine",
    "start": "1396880",
    "end": "1398799"
  },
  {
    "text": "but when you can decouple logic and",
    "start": "1398799",
    "end": "1400559"
  },
  {
    "text": "execution through fugue what happens is",
    "start": "1400559",
    "end": "1403440"
  },
  {
    "text": "that you can just define your logic once",
    "start": "1403440",
    "end": "1405840"
  },
  {
    "text": "and then choose where to run it so often",
    "start": "1405840",
    "end": "1408240"
  },
  {
    "text": "you find that there are",
    "start": "1408240",
    "end": "1410480"
  },
  {
    "text": "a lot of projects where you know you you",
    "start": "1410480",
    "end": "1412880"
  },
  {
    "text": "started using pandas and the data became",
    "start": "1412880",
    "end": "1414960"
  },
  {
    "text": "too big and now you need to introduce",
    "start": "1414960",
    "end": "1416720"
  },
  {
    "text": "spark and maybe instead of going to",
    "start": "1416720",
    "end": "1419520"
  },
  {
    "text": "spark you'll just vertically scale your",
    "start": "1419520",
    "end": "1421360"
  },
  {
    "text": "infrastructure or on the other hand",
    "start": "1421360",
    "end": "1423919"
  },
  {
    "text": "maybe you're using spark uh to optimize",
    "start": "1423919",
    "end": "1426960"
  },
  {
    "text": "too early for like a data set",
    "start": "1426960",
    "end": "1429279"
  },
  {
    "text": "as a data set that doesn't need spark",
    "start": "1429279",
    "end": "1431600"
  },
  {
    "text": "right",
    "start": "1431600",
    "end": "1432400"
  },
  {
    "text": "so now with fugue you just need to write",
    "start": "1432400",
    "end": "1434400"
  },
  {
    "text": "your code once and define your logic",
    "start": "1434400",
    "end": "1436400"
  },
  {
    "text": "once",
    "start": "1436400",
    "end": "1437279"
  },
  {
    "text": "and then you can choose the execution",
    "start": "1437279",
    "end": "1438960"
  },
  {
    "text": "engine that makes sense during runtime",
    "start": "1438960",
    "end": "1441039"
  },
  {
    "text": "so you can start small with pandas and",
    "start": "1441039",
    "end": "1443039"
  },
  {
    "text": "then you can move to spark",
    "start": "1443039",
    "end": "1446320"
  },
  {
    "start": "1446000",
    "end": "1490000"
  },
  {
    "text": "uh so here in this example we have a",
    "start": "1446400",
    "end": "1448960"
  },
  {
    "text": "native python python function or pan it",
    "start": "1448960",
    "end": "1451360"
  },
  {
    "text": "uses pandas and",
    "start": "1451360",
    "end": "1453760"
  },
  {
    "text": "what we can see is that when we define",
    "start": "1453760",
    "end": "1456080"
  },
  {
    "text": "the function there's no spark dependency",
    "start": "1456080",
    "end": "1458240"
  },
  {
    "text": "whatsoever and this is what han demoed",
    "start": "1458240",
    "end": "1460720"
  },
  {
    "text": "and once you use the fugue transform",
    "start": "1460720",
    "end": "1462960"
  },
  {
    "text": "function and specify the execution",
    "start": "1462960",
    "end": "1464960"
  },
  {
    "text": "engine all of this is brought into spark",
    "start": "1464960",
    "end": "1467120"
  },
  {
    "text": "for you",
    "start": "1467120",
    "end": "1469520"
  },
  {
    "text": "what this did on this slide i use a",
    "start": "1470000",
    "end": "1472080"
  },
  {
    "text": "pandas data frame but for the same",
    "start": "1472080",
    "end": "1473840"
  },
  {
    "text": "function we can also use",
    "start": "1473840",
    "end": "1475679"
  },
  {
    "text": "native python using the list and dicks",
    "start": "1475679",
    "end": "1478400"
  },
  {
    "text": "um and we can just uh loop through this",
    "start": "1478400",
    "end": "1481120"
  },
  {
    "text": "list of dicks and apply the pyth native",
    "start": "1481120",
    "end": "1483600"
  },
  {
    "text": "python code uh for each row",
    "start": "1483600",
    "end": "1486400"
  },
  {
    "text": "and again this can also be brought into",
    "start": "1486400",
    "end": "1488240"
  },
  {
    "text": "spark through the transform function",
    "start": "1488240",
    "end": "1491360"
  },
  {
    "text": "so by decoupling logic and execution",
    "start": "1491360",
    "end": "1493840"
  },
  {
    "text": "you're able to accelerate your testing",
    "start": "1493840",
    "end": "1495840"
  },
  {
    "text": "because you you can test on smaller data",
    "start": "1495840",
    "end": "1498240"
  },
  {
    "text": "with with pandas size data",
    "start": "1498240",
    "end": "1500480"
  },
  {
    "text": "and then choose the execution engine on",
    "start": "1500480",
    "end": "1502480"
  },
  {
    "text": "spark when you need it you can you also",
    "start": "1502480",
    "end": "1504640"
  },
  {
    "text": "need to test less code in general so you",
    "start": "1504640",
    "end": "1506640"
  },
  {
    "text": "can accelerate development and then you",
    "start": "1506640",
    "end": "1508960"
  },
  {
    "text": "avoid framework lock-in so today we're",
    "start": "1508960",
    "end": "1511600"
  },
  {
    "text": "using spark and desk but if ray starts",
    "start": "1511600",
    "end": "1514640"
  },
  {
    "text": "to pick up and a lot of people start to",
    "start": "1514640",
    "end": "1516480"
  },
  {
    "text": "use ray or maybe even uh the",
    "start": "1516480",
    "end": "1519840"
  },
  {
    "text": "qdf with rapids.ai where you have gpu",
    "start": "1519840",
    "end": "1523039"
  },
  {
    "text": "clusters then we can make make an",
    "start": "1523039",
    "end": "1525279"
  },
  {
    "text": "execution engine for those different",
    "start": "1525279",
    "end": "1527360"
  },
  {
    "text": "frameworks and your same python code",
    "start": "1527360",
    "end": "1529679"
  },
  {
    "text": "should be able to map through fugue",
    "start": "1529679",
    "end": "1532240"
  },
  {
    "text": "and because of because you use native",
    "start": "1532240",
    "end": "1534240"
  },
  {
    "text": "python code that's very testable there's",
    "start": "1534240",
    "end": "1536480"
  },
  {
    "text": "a lot less maintenance there's no spark",
    "start": "1536480",
    "end": "1538799"
  },
  {
    "text": "expertise required to maintain the code",
    "start": "1538799",
    "end": "1541039"
  },
  {
    "text": "logic as han showed where he had",
    "start": "1541039",
    "end": "1544159"
  },
  {
    "text": "an example of business logic that",
    "start": "1544159",
    "end": "1546000"
  },
  {
    "text": "changed over time it was very easy to",
    "start": "1546000",
    "end": "1548159"
  },
  {
    "text": "just still use the transform function",
    "start": "1548159",
    "end": "1549760"
  },
  {
    "text": "with fugue",
    "start": "1549760",
    "end": "1551520"
  },
  {
    "text": "and then we have us fugue also has a sql",
    "start": "1551520",
    "end": "1553840"
  },
  {
    "text": "interface so maybe sql lovers or bi",
    "start": "1553840",
    "end": "1557200"
  },
  {
    "text": "analysts or data analysts these these",
    "start": "1557200",
    "end": "1559600"
  },
  {
    "text": "personas can also uh harness the power",
    "start": "1559600",
    "end": "1562480"
  },
  {
    "text": "of distributed compute",
    "start": "1562480",
    "end": "1564400"
  },
  {
    "text": "fugue sql supports spark desk",
    "start": "1564400",
    "end": "1566880"
  },
  {
    "text": "and pandas also and and then we also",
    "start": "1566880",
    "end": "1569520"
  },
  {
    "text": "support blazing sql uh through um",
    "start": "1569520",
    "end": "1572960"
  },
  {
    "text": "uh",
    "start": "1572960",
    "end": "1574159"
  },
  {
    "text": "to to operate on top of the uh gpu",
    "start": "1574159",
    "end": "1577360"
  },
  {
    "text": "decodif",
    "start": "1577360",
    "end": "1579279"
  },
  {
    "text": "so with with uh with the sql interface",
    "start": "1579279",
    "end": "1581600"
  },
  {
    "text": "what han showed in the notebook we have",
    "start": "1581600",
    "end": "1583360"
  },
  {
    "text": "syntax highlighting already implemented",
    "start": "1583360",
    "end": "1586400"
  },
  {
    "text": "we added keywords to bring sql into the",
    "start": "1586400",
    "end": "1589600"
  },
  {
    "text": "distributed setting for example we added",
    "start": "1589600",
    "end": "1591760"
  },
  {
    "text": "keywords like load save persist",
    "start": "1591760",
    "end": "1594240"
  },
  {
    "text": "partition and transform so now sql can",
    "start": "1594240",
    "end": "1596960"
  },
  {
    "text": "be a first class interface where you can",
    "start": "1596960",
    "end": "1600000"
  },
  {
    "text": "um before you would have a sql code pre",
    "start": "1600000",
    "end": "1603919"
  },
  {
    "text": "sandwiched by predominantly python code",
    "start": "1603919",
    "end": "1606320"
  },
  {
    "text": "and now you can have it the other way",
    "start": "1606320",
    "end": "1607760"
  },
  {
    "text": "around where you have predominantly sql",
    "start": "1607760",
    "end": "1610080"
  },
  {
    "text": "code that invokes python code",
    "start": "1610080",
    "end": "1611840"
  },
  {
    "text": "occasionally",
    "start": "1611840",
    "end": "1613279"
  },
  {
    "start": "1613000",
    "end": "1619000"
  },
  {
    "text": "and this is the example of the notebook",
    "start": "1613279",
    "end": "1614880"
  },
  {
    "text": "extension where we have syntax highlight",
    "start": "1614880",
    "end": "1616720"
  },
  {
    "text": "highlighting implemented",
    "start": "1616720",
    "end": "1619360"
  },
  {
    "start": "1619000",
    "end": "1657000"
  },
  {
    "text": "so",
    "start": "1619360",
    "end": "1620480"
  },
  {
    "text": "as before i open for questions i just",
    "start": "1620480",
    "end": "1622240"
  },
  {
    "text": "want to",
    "start": "1622240",
    "end": "1623200"
  },
  {
    "text": "conclude here by saying that number one",
    "start": "1623200",
    "end": "1625279"
  },
  {
    "text": "fugue is also is a mindset first of all",
    "start": "1625279",
    "end": "1627840"
  },
  {
    "text": "and that our mindset is that we should",
    "start": "1627840",
    "end": "1629279"
  },
  {
    "text": "adapt to the user and allow them to",
    "start": "1629279",
    "end": "1631440"
  },
  {
    "text": "express their logic in whatever way they",
    "start": "1631440",
    "end": "1634000"
  },
  {
    "text": "want to and then they can express their",
    "start": "1634000",
    "end": "1636080"
  },
  {
    "text": "logic in a scale agnostic way and we can",
    "start": "1636080",
    "end": "1638559"
  },
  {
    "text": "take care of bringing it to a",
    "start": "1638559",
    "end": "1639840"
  },
  {
    "text": "distributed setting when when you need",
    "start": "1639840",
    "end": "1642159"
  },
  {
    "text": "to scale",
    "start": "1642159",
    "end": "1643279"
  },
  {
    "text": "and we value readability and",
    "start": "1643279",
    "end": "1644960"
  },
  {
    "text": "maintainability of the code rather than",
    "start": "1644960",
    "end": "1647279"
  },
  {
    "text": "deep framework-specific optimizations",
    "start": "1647279",
    "end": "1649760"
  },
  {
    "text": "but normally fugue just uses the",
    "start": "1649760",
    "end": "1652000"
  },
  {
    "text": "mechanisms under the hood of that",
    "start": "1652000",
    "end": "1653600"
  },
  {
    "text": "execution engine so that you don't lose",
    "start": "1653600",
    "end": "1655520"
  },
  {
    "text": "a lot of performance",
    "start": "1655520",
    "end": "1657440"
  },
  {
    "start": "1657000",
    "end": "1712000"
  },
  {
    "text": "um",
    "start": "1657440",
    "end": "1658960"
  },
  {
    "text": "and with that i i uh i just want to give",
    "start": "1658960",
    "end": "1661520"
  },
  {
    "text": "a quick recap before um so number one we",
    "start": "1661520",
    "end": "1663919"
  },
  {
    "text": "are an abstraction layer for distributed",
    "start": "1663919",
    "end": "1665600"
  },
  {
    "text": "compute",
    "start": "1665600",
    "end": "1666559"
  },
  {
    "text": "it adapts to the user lets them define",
    "start": "1666559",
    "end": "1668240"
  },
  {
    "text": "their code in native python or sql and",
    "start": "1668240",
    "end": "1670640"
  },
  {
    "text": "then bring it to spark or desk when",
    "start": "1670640",
    "end": "1672480"
  },
  {
    "text": "needed and because of decoupling logic",
    "start": "1672480",
    "end": "1674720"
  },
  {
    "text": "and execution you find that",
    "start": "1674720",
    "end": "1676640"
  },
  {
    "text": "we find that a lot of fugue users can",
    "start": "1676640",
    "end": "1678559"
  },
  {
    "text": "accelerate",
    "start": "1678559",
    "end": "1679840"
  },
  {
    "text": "their big data projects and fugue is",
    "start": "1679840",
    "end": "1683039"
  },
  {
    "text": "just one",
    "start": "1683039",
    "end": "1684159"
  },
  {
    "text": "component of the broader fugue project",
    "start": "1684159",
    "end": "1686320"
  },
  {
    "text": "so we have few and fugue sql but we also",
    "start": "1686320",
    "end": "1689200"
  },
  {
    "text": "have fugue tune which is an abstraction",
    "start": "1689200",
    "end": "1690880"
  },
  {
    "text": "layer for hyper parameter optimization",
    "start": "1690880",
    "end": "1693039"
  },
  {
    "text": "and we also have fugue validate we also",
    "start": "1693039",
    "end": "1695120"
  },
  {
    "text": "can use fugue to perform data validation",
    "start": "1695120",
    "end": "1698480"
  },
  {
    "text": "by wrapping around pandera or great",
    "start": "1698480",
    "end": "1700159"
  },
  {
    "text": "expectations",
    "start": "1700159",
    "end": "1701919"
  },
  {
    "text": "i just have contact info here and with",
    "start": "1701919",
    "end": "1704159"
  },
  {
    "text": "that i'll open the floor for questions",
    "start": "1704159",
    "end": "1705679"
  },
  {
    "text": "thank you",
    "start": "1705679",
    "end": "1708919"
  },
  {
    "text": "you",
    "start": "1712240",
    "end": "1714320"
  }
]
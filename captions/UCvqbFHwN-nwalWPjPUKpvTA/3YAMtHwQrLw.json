[
  {
    "text": "hello everyone thank you for joining this session very good talk so far actually it's the",
    "start": "1740",
    "end": "7740"
  },
  {
    "text": "first time we are here in for this conference in Shanghai it's impressive",
    "start": "7740",
    "end": "14219"
  },
  {
    "text": "um my name is Victor Vasa I'm a technical lead and together my colleague Adrian",
    "start": "14219",
    "end": "20580"
  },
  {
    "text": "well-bought working at Adobe in Romania in Bucharest office on the adobe's",
    "start": "20580",
    "end": "26580"
  },
  {
    "text": "kubernetes platform named etos we're both passionate about open source contributions I'm one of the organizers",
    "start": "26580",
    "end": "34559"
  },
  {
    "text": "of kubernetes community days or kcd in Romania it will be the first kcd event",
    "start": "34559",
    "end": "40620"
  },
  {
    "text": "in the southeast of Europe and it will be held next year in April",
    "start": "40620",
    "end": "45739"
  },
  {
    "text": "Adrian do you want to introduce yourself yeah sure hello everyone my name is",
    "start": "45739",
    "end": "52500"
  },
  {
    "text": "Adrian I'm a lead Cloud software engineer at Adobe and I'm also part of the kubernetes",
    "start": "52500",
    "end": "58260"
  },
  {
    "text": "GitHub organization and currently I'm focusing on the cluster API ecosystem",
    "start": "58260",
    "end": "65040"
  },
  {
    "text": "projects today we are going to be talking about",
    "start": "65040",
    "end": "70740"
  },
  {
    "text": "our Five Years Journey of how we leverage name spaces in order to scale the adoption of kubernetes in Adobe",
    "start": "70740",
    "end": "79140"
  },
  {
    "text": "the first part of the presentation I'm going to talk about projectitos kubernetes namespaces and capacity",
    "start": "79140",
    "end": "86040"
  },
  {
    "text": "management and my colleague Adrian will continue with governance policies",
    "start": "86040",
    "end": "91340"
  },
  {
    "text": "non-disruptive kubernetes upgrades and multi-tenancy at scale",
    "start": "91340",
    "end": "96600"
  },
  {
    "text": "the project that we are working on is named ethos and it is a multi-tenant comparatus based platform",
    "start": "96600",
    "end": "103259"
  },
  {
    "text": "established through the collaboration between the adobe's infrastructure team and the product development teams or",
    "start": "103259",
    "end": "109680"
  },
  {
    "text": "application development teams the initial version of ethos began with",
    "start": "109680",
    "end": "115380"
  },
  {
    "text": "Apache muscles and dcos in 2016 we were in production",
    "start": "115380",
    "end": "121500"
  },
  {
    "text": "it was a good decision at that moment because this OS was a production ready",
    "start": "121500",
    "end": "126659"
  },
  {
    "text": "solution and we got experience of running containerized applications and microservices in production",
    "start": "126659",
    "end": "134520"
  },
  {
    "text": "then as kubernetes measured we initiated the migration from this OS to kubernetes",
    "start": "134520",
    "end": "141120"
  },
  {
    "text": "and we started in 2018 and one year later",
    "start": "141120",
    "end": "146520"
  },
  {
    "text": "we almost hit 100 kubernetes clusters along with the kubernetes project",
    "start": "146520",
    "end": "153300"
  },
  {
    "text": "ethos is using many of other open source software projects such as psyllium",
    "start": "153300",
    "end": "159660"
  },
  {
    "text": "Prometheus open policy agent Argo and so on",
    "start": "159660",
    "end": "165859"
  },
  {
    "text": "this is the high level overview of ethos kubernetes platform and its positioned",
    "start": "166500",
    "end": "172980"
  },
  {
    "text": "in Adobe on the top of the slide we have the three Adobe clouds Creative Cloud",
    "start": "172980",
    "end": "180120"
  },
  {
    "text": "experience clouds and document cloud this clouds are powered by Adobe products",
    "start": "180120",
    "end": "186440"
  },
  {
    "text": "such as Adobe Photoshop Adobe Firefly analytics Adobe experience manager Adobe",
    "start": "186440",
    "end": "193800"
  },
  {
    "text": "sign and so on this software product together with the platform that they are using such as",
    "start": "193800",
    "end": "200099"
  },
  {
    "text": "Sensei machine learning content platform experience platform",
    "start": "200099",
    "end": "205440"
  },
  {
    "text": "all together are running on top of ethos and Ethos is basically the Adobe runtime",
    "start": "205440",
    "end": "211500"
  },
  {
    "text": "for containerized applications at the bottom of the slides we have the",
    "start": "211500",
    "end": "218280"
  },
  {
    "text": "three Cloud providers on which it also operates on AWS Azure and Adobe private cloud",
    "start": "218280",
    "end": "227540"
  },
  {
    "text": "to better understand the platform's scalability let's talk about the pretty impressive numbers uh ethos hosts more",
    "start": "228659",
    "end": "235319"
  },
  {
    "text": "than 2.1 million containers encapsulated in almost 1 million pods",
    "start": "235319",
    "end": "241200"
  },
  {
    "text": "those ports are running in 40 000 10 and 9 spaces or nine spaces owned",
    "start": "241200",
    "end": "247620"
  },
  {
    "text": "by application development teams we are managing more than 300 kubernetes",
    "start": "247620",
    "end": "253739"
  },
  {
    "text": "clusters deployed in 28 different Cloud regions in AWS Azure and Adobe private",
    "start": "253739",
    "end": "261060"
  },
  {
    "text": "cloud in terms of computing power these workloads use around 32 000 virtual",
    "start": "261060",
    "end": "268979"
  },
  {
    "text": "machines or kubernetes nodes consuming approximately 2.71 petabytes",
    "start": "268979",
    "end": "274919"
  },
  {
    "text": "of RAM memory and 750 000 virtual CPUs",
    "start": "274919",
    "end": "280080"
  },
  {
    "text": "Additionally the AI applications are using around 2 000 gpus",
    "start": "280080",
    "end": "288620"
  },
  {
    "text": "let's talk about multi-tenancy in kubernetes how many of you are using kubernetes in",
    "start": "289259",
    "end": "295500"
  },
  {
    "text": "a multi-tenant architecture right we have a good audience there are many",
    "start": "295500",
    "end": "302759"
  },
  {
    "text": "definitions actually for multi-tenancy in Adobe we learned that multi tenants",
    "start": "302759",
    "end": "308460"
  },
  {
    "text": "in kubernetes is a way to share multiple physical clusters with multiple teams from different projects different or",
    "start": "308460",
    "end": "316139"
  },
  {
    "text": "different organizations and we have two types of clusters here",
    "start": "316139",
    "end": "321780"
  },
  {
    "text": "clusters and dedicated clusters also known as multi-tenant clusters and",
    "start": "321780",
    "end": "327180"
  },
  {
    "text": "single tenant clusters here clusters are available to any internal Adobe team",
    "start": "327180",
    "end": "333479"
  },
  {
    "text": "and they are highly valuable for optimizing the cost and enhancing the overall platform reliability",
    "start": "333479",
    "end": "341840"
  },
  {
    "text": "dedicated clusters are used for two purposes when high security isolation is",
    "start": "342419",
    "end": "347759"
  },
  {
    "text": "required such as for applications that run untrusted software an example of this is Adobe experience",
    "start": "347759",
    "end": "354360"
  },
  {
    "text": "manager which is a Content management system application capable of running software written by Adobe customers",
    "start": "354360",
    "end": "361440"
  },
  {
    "text": "another scenario is when a specific team requires High resource allocation for",
    "start": "361440",
    "end": "367860"
  },
  {
    "text": "their application which basically use the entire cluster resources",
    "start": "367860",
    "end": "373259"
  },
  {
    "text": "for instance Adobe Firefly which is a generative AI powered content creation",
    "start": "373259",
    "end": "379560"
  },
  {
    "text": "solution significantly consume the entire cluster GPU and CPUs",
    "start": "379560",
    "end": "387259"
  },
  {
    "text": "in order to implement multi-tenancy we rely on kubernetes namespaces or virtual",
    "start": "388259",
    "end": "393900"
  },
  {
    "text": "kubernetes clusters developers love namespaces because they provide flexibility more control and",
    "start": "393900",
    "end": "401039"
  },
  {
    "text": "easy to troubleshoot their applications each namespace name is unique across the",
    "start": "401039",
    "end": "407160"
  },
  {
    "text": "entire fleet and it is generated based on namespace profile template",
    "start": "407160",
    "end": "414000"
  },
  {
    "text": "an aspace profile template is primarily composed by kubernetes Primitives in order to",
    "start": "414000",
    "end": "419819"
  },
  {
    "text": "provide a minimum isolation within a cluster first of all we need a kubernetes",
    "start": "419819",
    "end": "425039"
  },
  {
    "text": "namespace to group objects for a single team team in the kubernetes API",
    "start": "425039",
    "end": "432560"
  },
  {
    "text": "then a roll binding is used to implement an authorization mechanism for the namespace",
    "start": "433259",
    "end": "438600"
  },
  {
    "text": "ensuring that only a specific team has access to a particular namespace",
    "start": "438600",
    "end": "445099"
  },
  {
    "text": "quota in limit range play a crucial role in controlling and limiting reasons",
    "start": "445620",
    "end": "450660"
  },
  {
    "text": "consumption ensuring Fair resource allocation within",
    "start": "450660",
    "end": "455759"
  },
  {
    "text": "the cluster for Network isolation we are using both",
    "start": "455759",
    "end": "461759"
  },
  {
    "text": "kubernetes native Network policies but also celium Network policies and civil",
    "start": "461759",
    "end": "468720"
  },
  {
    "text": "Network policies are very useful for implementing dns-based policies and other level layer 7 policies",
    "start": "468720",
    "end": "478039"
  },
  {
    "text": "after the namespace profile is deployed on the cluster the tenant can deploy his application inside",
    "start": "479340",
    "end": "486060"
  },
  {
    "text": "so 10 application resources will be restricted only to a specific team and",
    "start": "486060",
    "end": "491280"
  },
  {
    "text": "the pause will be isolated in the cluster using the default Network policies",
    "start": "491280",
    "end": "497300"
  },
  {
    "text": "in an environment capacity management is a key consideration because capacity",
    "start": "497900",
    "end": "504539"
  },
  {
    "text": "issues can result in a higher costs by the way who doesn't have cost",
    "start": "504539",
    "end": "510720"
  },
  {
    "text": "concerns when running the application in the cloud posts are very important",
    "start": "510720",
    "end": "516899"
  },
  {
    "text": "we tend to take action at three levels at the Pod level so in addition to horizontal product or",
    "start": "516899",
    "end": "523979"
  },
  {
    "text": "scaling and vertical product or scaling we utilize a concept known as automatic",
    "start": "523979",
    "end": "529260"
  },
  {
    "text": "resource configuration or Arc at the namespace level we simplify code",
    "start": "529260",
    "end": "535560"
  },
  {
    "text": "and management using a concept named BTU or Baseline Cota unit",
    "start": "535560",
    "end": "541500"
  },
  {
    "text": "and at the cluster level we added capacity others",
    "start": "541500",
    "end": "547339"
  },
  {
    "text": "let's discuss about automatic resource configuration we know that in kubernetes boards are",
    "start": "547560",
    "end": "553680"
  },
  {
    "text": "scheduled on the worker nodes based on their container resource requests and they can burst up to a specific limit",
    "start": "553680",
    "end": "560940"
  },
  {
    "text": "so if there is two requests are lower smaller allocations are reserved for that odd right",
    "start": "560940",
    "end": "567720"
  },
  {
    "text": "this allows for more possibly scheduled on the worker nodes resulting in cost savings",
    "start": "567720",
    "end": "574080"
  },
  {
    "text": "to achieve this we rely on Prometheus metrics together historical utilization",
    "start": "574080",
    "end": "579300"
  },
  {
    "text": "data for the tenant deployment ports then an Opa or open policy agent policy",
    "start": "579300",
    "end": "586080"
  },
  {
    "text": "will adjust the right size for the CPU and memory request for the tenant deployment pods",
    "start": "586080",
    "end": "593600"
  },
  {
    "text": "at the next best level to simplify the quota management operations",
    "start": "595380",
    "end": "600660"
  },
  {
    "text": "we introduced the concept of bku or Baseline quota unit",
    "start": "600660",
    "end": "605940"
  },
  {
    "text": "a BQ is a quota definition and every increase in the name space quota is",
    "start": "605940",
    "end": "612720"
  },
  {
    "text": "actually achieved by multiplying if each of the BQ items",
    "start": "612720",
    "end": "619080"
  },
  {
    "text": "for example we have a BQ definition here if you want to allocate let's say instead of 16",
    "start": "619080",
    "end": "626160"
  },
  {
    "text": "vcpus for our namespace 160 vcpus we simply increase the quota",
    "start": "626160",
    "end": "633000"
  },
  {
    "text": "for that namespace for 1 from 1 to 10 bkus",
    "start": "633000",
    "end": "638220"
  },
  {
    "text": "and the other BQ items will be multiplier as well so you'll have also the ability to run 300 words on our",
    "start": "638220",
    "end": "645839"
  },
  {
    "text": "namespace this approach simplifies the quota management operations for both tenants",
    "start": "645839",
    "end": "654060"
  },
  {
    "text": "and also for the cluster administrators hey",
    "start": "654060",
    "end": "659880"
  },
  {
    "text": "what happens if a cluster is the capacity and what that mean to save the cluster is the capacity we have multiple",
    "start": "659880",
    "end": "666480"
  },
  {
    "text": "alerts that fires based on some specific metrics like number of nodes number of",
    "start": "666480",
    "end": "673380"
  },
  {
    "text": "available IPS that can be allocated to the worker nodes and when one of the",
    "start": "673380",
    "end": "678480"
  },
  {
    "text": "supervised fires the main capacity alerts notifies our automation so no new name spaces cannot",
    "start": "678480",
    "end": "685980"
  },
  {
    "text": "be can be created on the cluster or even more for the existing name spaces we",
    "start": "685980",
    "end": "691980"
  },
  {
    "text": "cannot perform quota increase operation now I'm going to pass it to Adrian so we",
    "start": "691980",
    "end": "697620"
  },
  {
    "text": "can talk more about governance policies non-disruptive kubernetes upgrades and multi-tenancy as scale",
    "start": "697620",
    "end": "705320"
  },
  {
    "text": "thank you Victor I would like to continue our talk about multi-tenancy but tackle it from an",
    "start": "705720",
    "end": "712920"
  },
  {
    "text": "infrastructure perspective and I prepared three topics in order to cover the reliability reliability and",
    "start": "712920",
    "end": "720240"
  },
  {
    "text": "efficiency on one hand and security and scalability on the other hand",
    "start": "720240",
    "end": "726360"
  },
  {
    "text": "and I will start with the governance policies as any company or business is governed",
    "start": "726360",
    "end": "731820"
  },
  {
    "text": "by a set of rules so does a multi-tenant kubernetes cluster why are this policy mandatory and what",
    "start": "731820",
    "end": "739140"
  },
  {
    "text": "benefits do they bring into the kubernetes ecosystem from our perspective along",
    "start": "739140",
    "end": "745440"
  },
  {
    "text": "with the security aspect there are two main advantages when",
    "start": "745440",
    "end": "751140"
  },
  {
    "text": "defining a set of rules inside the kubernetes cluster and the first one is for safeguarding development teams so",
    "start": "751140",
    "end": "759240"
  },
  {
    "text": "that they cannot add collisions between them and the",
    "start": "759240",
    "end": "765959"
  },
  {
    "text": "second one is for protecting cluster stability so that a development team cannot jeopardize the cluster",
    "start": "765959",
    "end": "773700"
  },
  {
    "text": "a few years ago when we started building our platform we had a pretty interesting",
    "start": "773700",
    "end": "778800"
  },
  {
    "text": "outage one day two distinct teams created two different Ingress objects in",
    "start": "778800",
    "end": "785700"
  },
  {
    "text": "two different namespaces but pointing to the same fqdn",
    "start": "785700",
    "end": "791100"
  },
  {
    "text": "and it took us a while until we realized that these two Ingress objects were",
    "start": "791100",
    "end": "796740"
  },
  {
    "text": "conflicting with each other because there were no validating web hooks implemented by the Ingress controller",
    "start": "796740",
    "end": "802860"
  },
  {
    "text": "except the crd schema and this was the moment when we decided that the set of",
    "start": "802860",
    "end": "809459"
  },
  {
    "text": "Governors policies were mandatory and so in order to implement these",
    "start": "809459",
    "end": "815220"
  },
  {
    "text": "policies across our cluster Fleet we picked the OPA gatekeeper framework",
    "start": "815220",
    "end": "821279"
  },
  {
    "text": "Opa gatekeeper for those of you who are not familiar with is an extensible admission controller",
    "start": "821279",
    "end": "828360"
  },
  {
    "text": "which is already configured with all the necessary kubernetes API Plumbing and",
    "start": "828360",
    "end": "833579"
  },
  {
    "text": "cluster operators can change the business logic of gatekeeper by simply writing policies",
    "start": "833579",
    "end": "840180"
  },
  {
    "text": "which are regular queries as short as a few lines and we will see in a bit such",
    "start": "840180",
    "end": "845579"
  },
  {
    "text": "an example and so getting back to our outage after",
    "start": "845579",
    "end": "850620"
  },
  {
    "text": "that moment we created the validating Ingress policy",
    "start": "850620",
    "end": "855839"
  },
  {
    "text": "which denies the creation or update of any Ingress objects which attempts to",
    "start": "855839",
    "end": "862500"
  },
  {
    "text": "use an fqdn which is already in use by any other existing Ingress objects",
    "start": "862500",
    "end": "870560"
  },
  {
    "text": "some other example policies we are currently deploying across our cluster Fleet I would mention the control plane",
    "start": "870959",
    "end": "877380"
  },
  {
    "text": "toleration which is a policy used to restrict the workloads that can run inside the",
    "start": "877380",
    "end": "883860"
  },
  {
    "text": "control pay nodes another policy crunch up history which is used to limit the history for a crown",
    "start": "883860",
    "end": "891360"
  },
  {
    "text": "job so that we are not putting unnecessary load on the hcd side",
    "start": "891360",
    "end": "897660"
  },
  {
    "text": "default Ingress class another interesting policy which is used to add",
    "start": "897660",
    "end": "902880"
  },
  {
    "text": "an English class for all Ingress objects which are not explicitly specifying the",
    "start": "902880",
    "end": "909300"
  },
  {
    "text": "Ingress class they want to use namespace limit another policy which is used to limit the total number of",
    "start": "909300",
    "end": "915899"
  },
  {
    "text": "namespaces that can be created inside the kubernetes cluster and external IP Services another policy",
    "start": "915899",
    "end": "923100"
  },
  {
    "text": "which is used to deny the creation of external IP services",
    "start": "923100",
    "end": "928380"
  },
  {
    "text": "and as you can as you can see on the slide we have a regular snippet which is implemented implementing the",
    "start": "928380",
    "end": "935459"
  },
  {
    "text": "external IP services policy but as you can see with only a few lines",
    "start": "935459",
    "end": "941100"
  },
  {
    "text": "of code we were able to define a pretty strong policy which is denying the",
    "start": "941100",
    "end": "946199"
  },
  {
    "text": "creation of an external IP service what is it does first it checks if the",
    "start": "946199",
    "end": "954000"
  },
  {
    "text": "object from the request is of type service then it checks if the operation is create or update and finally it",
    "start": "954000",
    "end": "962339"
  },
  {
    "text": "checks if the service pack has any external eyepiece defined and if all",
    "start": "962339",
    "end": "967440"
  },
  {
    "text": "these three conditions are met we are rejecting the request and sending back a message to the user stating that",
    "start": "967440",
    "end": "975300"
  },
  {
    "text": "external IP services are not allowed because of of a pretty high vulnerability that is found inside the",
    "start": "975300",
    "end": "982440"
  },
  {
    "text": "kubernetes code base one thing to keep in mind here is that",
    "start": "982440",
    "end": "988380"
  },
  {
    "text": "gatekeeper as any other validation or mutation web hook adds latency to any",
    "start": "988380",
    "end": "995459"
  },
  {
    "text": "API request it mutates or validates why simply because of the extra processing",
    "start": "995459",
    "end": "1002240"
  },
  {
    "text": "time needed to mutate or validate the request so the more policies you define the higher API response latency might be",
    "start": "1002240",
    "end": "1013300"
  },
  {
    "text": "another story is around cluster upgrade as our platform evolved and started",
    "start": "1013639",
    "end": "1019339"
  },
  {
    "text": "onboarding more and more teams the diversity of the workloads running on top was also increasing",
    "start": "1019339",
    "end": "1027199"
  },
  {
    "text": "some teams started running State flaps like databases or distributed event",
    "start": "1027199",
    "end": "1033798"
  },
  {
    "text": "streaming apps that's hmm are pretty sensitive to disruptions",
    "start": "1033799",
    "end": "1039500"
  },
  {
    "text": "and after few outages that were caused by our cluster upgrade process it was",
    "start": "1039500",
    "end": "1045020"
  },
  {
    "text": "clear that we needed to develop a new way or a new strategy while doing",
    "start": "1045020",
    "end": "1051679"
  },
  {
    "text": "cluster upgrades because the poor disruption budgets alone were not enough",
    "start": "1051679",
    "end": "1057140"
  },
  {
    "text": "and we were looking to have a high enough velocity while rotating the working nodes on one",
    "start": "1057140",
    "end": "1064100"
  },
  {
    "text": "hand but still maintain the client's app's availability and infrastructure",
    "start": "1064100",
    "end": "1069440"
  },
  {
    "text": "costs at some reasonable thresholds and so we came up with what we call the",
    "start": "1069440",
    "end": "1076220"
  },
  {
    "text": "Park nodes upgrade strategy and this strategy is implemented around",
    "start": "1076220",
    "end": "1082100"
  },
  {
    "text": "K Shredder which is a kubernetes controller developed in-house at Adobe then",
    "start": "1082100",
    "end": "1088400"
  },
  {
    "text": "open sourced it is available under the Adobe GitHub org and you can scan the",
    "start": "1088400",
    "end": "1093919"
  },
  {
    "text": "the QR code from the slide in order to get access to it how does our non-disruptive cluster",
    "start": "1093919",
    "end": "1100820"
  },
  {
    "text": "update procedure work from a high level perspective during a full cluster upgrade we are",
    "start": "1100820",
    "end": "1107780"
  },
  {
    "text": "draining in batches a percentage of the total worker nodes at a time while adding new worker nodes also we are",
    "start": "1107780",
    "end": "1116660"
  },
  {
    "text": "coordinating all the existing worker nodes so that no new pods can be scheduled on them",
    "start": "1116660",
    "end": "1124100"
  },
  {
    "text": "and for the sake of the example let's assume we have a cluster with two worker nodes which we are going to upgrade to a",
    "start": "1124100",
    "end": "1131360"
  },
  {
    "text": "new kubernetes version once the upgrade process begin",
    "start": "1131360",
    "end": "1137480"
  },
  {
    "text": "as I mentioned earlier we are adding a new worker running the newer version of kubernetes",
    "start": "1137480",
    "end": "1143539"
  },
  {
    "text": "and then start draining the old nodes",
    "start": "1143539",
    "end": "1148580"
  },
  {
    "text": "evicted pods will be moved to the new worker nodes since as I mentioned earlier the all nodes were already",
    "start": "1148580",
    "end": "1155240"
  },
  {
    "text": "cordoned at the beginning of the upgrade process and as the upgrade is progressing",
    "start": "1155240",
    "end": "1163400"
  },
  {
    "text": "more pods are moved to the new nodes until there is no capacity on them eventually",
    "start": "1163400",
    "end": "1169460"
  },
  {
    "text": "and if we are running out of resources we are simply just spinning up new worker",
    "start": "1169460",
    "end": "1175880"
  },
  {
    "text": "nodes so that we can accommodate all the pods that are evicted by the draining process",
    "start": "1175880",
    "end": "1183159"
  },
  {
    "text": "okay if there is during the configured drain timeouts not all the pods are evicted we",
    "start": "1183200",
    "end": "1190400"
  },
  {
    "text": "then label the worker node a sparked and add a TTL or a time to",
    "start": "1190400",
    "end": "1196160"
  },
  {
    "text": "leave to it also all the all nodes that were successfully drained",
    "start": "1196160",
    "end": "1201200"
  },
  {
    "text": "and which don't have any running pod on them will be recycled by the cluster Auto scaler or by our upgrade process",
    "start": "1201200",
    "end": "1209179"
  },
  {
    "text": "eventually and with that this is the moment we consider the cluster upgrade as finished",
    "start": "1209179",
    "end": "1217280"
  },
  {
    "text": "and once the upgrade is finished development teams that are still running pods on part nodes are getting notified",
    "start": "1217280",
    "end": "1224360"
  },
  {
    "text": "so that they can take all the necessary measures to move their pods out of the",
    "start": "1224360",
    "end": "1230480"
  },
  {
    "text": "park nodes before the TTL of the node expire",
    "start": "1230480",
    "end": "1235360"
  },
  {
    "text": "and once the draining process is finished on all worker nodes then case Shredder is taking over the process what",
    "start": "1236360",
    "end": "1244039"
  },
  {
    "text": "is he doing behind the scene initially it will identify identify all the part nodes from the",
    "start": "1244039",
    "end": "1250700"
  },
  {
    "text": "cluster and then for each of these spark nodes will grab all the running pods",
    "start": "1250700",
    "end": "1256039"
  },
  {
    "text": "and for every pod will run a set of eviction loops",
    "start": "1256039",
    "end": "1261620"
  },
  {
    "text": "initially it will periodically try to solve the vict all the pods running on Park nodes",
    "start": "1261620",
    "end": "1268400"
  },
  {
    "text": "and most of the pods will be successfully soft evicted by K Shredder after a few iteration or after few",
    "start": "1268400",
    "end": "1275360"
  },
  {
    "text": "eviction loops but some of them won't be able to to be soft evicted and key Shredder will still",
    "start": "1275360",
    "end": "1283340"
  },
  {
    "text": "periodically monitor the TTL of the part node and if after the configured Park node",
    "start": "1283340",
    "end": "1289940"
  },
  {
    "text": "TTL there are still running pods that couldn't be soft evicted then cash rather will take a pretty",
    "start": "1289940",
    "end": "1296780"
  },
  {
    "text": "disruptive action and will just force evict all those spots that were still",
    "start": "1296780",
    "end": "1303620"
  },
  {
    "text": "running on the park node and once there are no more pods running",
    "start": "1303620",
    "end": "1308659"
  },
  {
    "text": "on the park node cluster Auto scaler will just recycle those nodes",
    "start": "1308659",
    "end": "1314720"
  },
  {
    "text": "and with that all worker nodes from the cluster are running the newer version of",
    "start": "1314720",
    "end": "1320000"
  },
  {
    "text": "kubernetes and putting all these steps together you can notice that the process is pretty",
    "start": "1320000",
    "end": "1326960"
  },
  {
    "text": "smooth and eventually all worker nodes will be running the newer version of",
    "start": "1326960",
    "end": "1332539"
  },
  {
    "text": "kubernetes",
    "start": "1332539",
    "end": "1335320"
  },
  {
    "text": "okay and the last story for today is about multi-tenancy at scale",
    "start": "1339080",
    "end": "1345440"
  },
  {
    "text": "as you saw the numbers at the beginning of the presentation you can imagine we are running at a",
    "start": "1345440",
    "end": "1350840"
  },
  {
    "text": "pretty high scale and challenges for such a big platform are diverse",
    "start": "1350840",
    "end": "1356360"
  },
  {
    "text": "recently we switched from our internally developed cicd tool to the Argo CD",
    "start": "1356360",
    "end": "1362780"
  },
  {
    "text": "ecosystem I guess every one of you are familiar with Argo but during our Argo CD evaluation",
    "start": "1362780",
    "end": "1370400"
  },
  {
    "text": "process one of the first challenges we encountered was the fact that a single",
    "start": "1370400",
    "end": "1375620"
  },
  {
    "text": "Argo CD couldn't handle the reconciliation volume needed for our",
    "start": "1375620",
    "end": "1380840"
  },
  {
    "text": "Fleet and to give you an idea we are deploying between 70 to 90 admin components on a",
    "start": "1380840",
    "end": "1389780"
  },
  {
    "text": "per kubernetes cluster and with a fleet of more than 300 clusters you can",
    "start": "1389780",
    "end": "1394940"
  },
  {
    "text": "imagine that the total number of applications needed to be synced is over 24",
    "start": "1394940",
    "end": "1402020"
  },
  {
    "text": "000 way higher than a single Argo CD can handle and so in order to be able to scale the",
    "start": "1402020",
    "end": "1409700"
  },
  {
    "text": "rollout of all the admin components across the fleet we've come up with a pretty interesting pattern which we",
    "start": "1409700",
    "end": "1416659"
  },
  {
    "text": "called Argo of Argos as you see on the slide we are running a",
    "start": "1416659",
    "end": "1423260"
  },
  {
    "text": "multi-tier Argo CD setup where tier 0 is used to reconcile the tier one argosity",
    "start": "1423260",
    "end": "1429679"
  },
  {
    "text": "instances and tier one are going to see the instances are used to seeing the cluster admin components Fleet wide",
    "start": "1429679",
    "end": "1437600"
  },
  {
    "text": "moreover hdr1 I'll go CD instance is handling only a subset of the kubernetes",
    "start": "1437600",
    "end": "1445039"
  },
  {
    "text": "Clusters that are part of the fleet also all Tier 1 Argo CD instances have",
    "start": "1445039",
    "end": "1452840"
  },
  {
    "text": "the same config and have registered the same set of application sets so that we",
    "start": "1452840",
    "end": "1458659"
  },
  {
    "text": "have consistency across the entire Tier 1 Argo CD instances and in this way we",
    "start": "1458659",
    "end": "1466280"
  },
  {
    "text": "accomplish the flexibility when it comes to the scalability of the continuous delivery system",
    "start": "1466280",
    "end": "1472400"
  },
  {
    "text": "we can always add more tier one algosity instances or remove them based on our",
    "start": "1472400",
    "end": "1478039"
  },
  {
    "text": "platform needs and with that I'm passing it back to Victor for the conclusions",
    "start": "1478039",
    "end": "1485320"
  },
  {
    "text": "okay so let's wrap up a few takeaways",
    "start": "1487580",
    "end": "1492679"
  },
  {
    "text": "for our Five Years Journey of running kubernetes architecture",
    "start": "1492679",
    "end": "1499340"
  },
  {
    "text": "there is no Silver Bullet while building a multi-tenant developer platform you should always align with your target",
    "start": "1499340",
    "end": "1506059"
  },
  {
    "text": "audience your user or in our case product development teams",
    "start": "1506059",
    "end": "1511340"
  },
  {
    "text": "uh every company is different and it has its own needs and vision regard to the",
    "start": "1511340",
    "end": "1517039"
  },
  {
    "text": "multi-tenancy architecture and here name species are available solution for building boundaries",
    "start": "1517039",
    "end": "1524059"
  },
  {
    "text": "Tennessee [Music] and the last but not the least challenges while working at the scale uh",
    "start": "1524059",
    "end": "1531980"
  },
  {
    "text": "are different comparing with small or medium-sized platform",
    "start": "1531980",
    "end": "1538340"
  },
  {
    "text": "thank you so much I hope you enjoy our talk if you want to get in touch with us here are our contacts",
    "start": "1538340",
    "end": "1547419"
  },
  {
    "text": "Additionally you may be wondering where the ktash reader icon came from as",
    "start": "1547419",
    "end": "1557059"
  },
  {
    "text": "you can see on the slide Adrian excels as a fisherman while on the other hand I'm one of the",
    "start": "1557059",
    "end": "1564140"
  },
  {
    "text": "worst Sailors thank you if you have any questions",
    "start": "1564140",
    "end": "1569260"
  },
  {
    "text": "foreign",
    "start": "1569360",
    "end": "1572360"
  },
  {
    "text": "sorry I didn't listen very clearly about one of the slides about the parked node",
    "start": "1589720",
    "end": "1595760"
  },
  {
    "text": "could you please explain again that what is The Pact node and if the timestamp",
    "start": "1595760",
    "end": "1602419"
  },
  {
    "text": "you list there expires what will be happening okay at the end do you want to take it no I can't take it so",
    "start": "1602419",
    "end": "1610580"
  },
  {
    "text": "let me go when",
    "start": "1610580",
    "end": "1615820"
  },
  {
    "text": "so the TTL or the time to leave or the timestamp of a node is added at a no",
    "start": "1620779",
    "end": "1625940"
  },
  {
    "text": "level and case Shredder will periodically evaluate the TTL of the node and if the",
    "start": "1625940",
    "end": "1633260"
  },
  {
    "text": "TTL of the node expires then case rather will Force evict all the pods that were still",
    "start": "1633260",
    "end": "1641960"
  },
  {
    "text": "running on that node after the TTL expired by force evicting them",
    "start": "1641960",
    "end": "1649640"
  },
  {
    "text": "this means that it will not take into account the pdb of",
    "start": "1649640",
    "end": "1654919"
  },
  {
    "text": "the deployment those pods are coming from that's why it's a pretty disruptive",
    "start": "1654919",
    "end": "1661100"
  },
  {
    "text": "action can I understand that the part of Z1 is",
    "start": "1661100",
    "end": "1669260"
  },
  {
    "text": "the non-constructing part",
    "start": "1669260",
    "end": "1674080"
  },
  {
    "text": "Z1 will be [Music]",
    "start": "1675820",
    "end": "1681740"
  },
  {
    "text": "it must stay at the original node zero one yeah but the trick here is that",
    "start": "1681740",
    "end": "1689480"
  },
  {
    "text": "was the node was parked all the user the users that were running",
    "start": "1689480",
    "end": "1696940"
  },
  {
    "text": "pods on that Park nodes will get notifications so they will have maybe days or maybe",
    "start": "1696940",
    "end": "1704299"
  },
  {
    "text": "few days to move their pods out of the park node got it thank you",
    "start": "1704299",
    "end": "1711520"
  },
  {
    "text": "yeah one more thing here okay there's an open source project and you can try it",
    "start": "1715640",
    "end": "1720880"
  },
  {
    "text": "so that to see how you sir another question hi hey um I might have missed at the beginning but so I understand",
    "start": "1720880",
    "end": "1727760"
  },
  {
    "text": "that once you've created the namespace for the user you pretty much",
    "start": "1727760",
    "end": "1732980"
  },
  {
    "text": "have no like you give them a quota but then they can do whatever they like yeah",
    "start": "1732980",
    "end": "1738020"
  },
  {
    "text": "that's not responsible for like how they set up CI CD or any of the other like best practices into the namespace yeah",
    "start": "1738020",
    "end": "1744919"
  },
  {
    "text": "actually we have many uh teams in Adobe and some of them wants to use their cicd",
    "start": "1744919",
    "end": "1751220"
  },
  {
    "text": "other by ikgs Acquisitions are using their own cicd like Jenkins or Spinnaker",
    "start": "1751220",
    "end": "1756799"
  },
  {
    "text": "we also as project details offer our cicd solution uh but",
    "start": "1756799",
    "end": "1764000"
  },
  {
    "text": "um yeah for these users we gave them the namespace as a service",
    "start": "1764000",
    "end": "1771220"
  },
  {
    "text": "and basically the user is responsible for what he's putting there",
    "start": "1771220",
    "end": "1777260"
  },
  {
    "text": "cool thank you",
    "start": "1777260",
    "end": "1780279"
  },
  {
    "text": "another question uh I have a question yeah about the disrupting upgrades upgrade operation uh",
    "start": "1791960",
    "end": "1801200"
  },
  {
    "text": "you just introduced about the kubernet uh what about Cooper API server and",
    "start": "1801200",
    "end": "1806659"
  },
  {
    "text": "control manager that part okay I think it's about the",
    "start": "1806659",
    "end": "1813020"
  },
  {
    "text": "uh the non-disrupting kubernetes upgrades and the question was why we",
    "start": "1813020",
    "end": "1818720"
  },
  {
    "text": "introduced this instead of using the normal kubernetes controllers",
    "start": "1818720",
    "end": "1824480"
  },
  {
    "text": "is that right uh Cooper API server that part",
    "start": "1824480",
    "end": "1830020"
  },
  {
    "text": "will you please repeat the question oh okay uh about the page about upgrading",
    "start": "1832580",
    "end": "1838940"
  },
  {
    "text": "uh how about the operating of cool BPI server okay yeah not node part okay so at a",
    "start": "1838940",
    "end": "1847460"
  },
  {
    "text": "control plane level given that we are in control of those",
    "start": "1847460",
    "end": "1852679"
  },
  {
    "text": "nodes there is no need to have a park node strategy there because we have full",
    "start": "1852679",
    "end": "1858679"
  },
  {
    "text": "control over those nodes and we can always manually intervene we as cluster",
    "start": "1858679",
    "end": "1863720"
  },
  {
    "text": "operators for the park node upgrade strategy is applicable only on the worker node side",
    "start": "1863720",
    "end": "1871520"
  },
  {
    "text": "not on the control plane side okay okay",
    "start": "1871520",
    "end": "1876520"
  },
  {
    "text": "other questions",
    "start": "1885020",
    "end": "1888340"
  },
  {
    "text": "okay so thank you so much for your attention and for your questions very good questions um if you want to get in touch with us",
    "start": "1893240",
    "end": "1900080"
  },
  {
    "text": "we'll be around also you can ping Us by mail or LinkedIn",
    "start": "1900080",
    "end": "1908500"
  },
  {
    "text": "thank you [Applause]",
    "start": "1909559",
    "end": "1914199"
  }
]
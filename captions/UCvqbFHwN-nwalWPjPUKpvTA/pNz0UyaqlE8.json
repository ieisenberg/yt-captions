[
  {
    "text": "okay for the next session I'm very player 2 it's my pleasure to introduce of",
    "start": "30",
    "end": "5609"
  },
  {
    "text": "Federico and Sebastian from Red Hat they cannot discuss about Luke serve and",
    "start": "5609",
    "end": "12530"
  },
  {
    "text": "for 16 or 17 red hats of storage",
    "start": "17300",
    "end": "22320"
  },
  {
    "text": "releases I kind of lost count and I'm joined by my colleague yeah I'm Sebastian and the self engineer",
    "start": "22320",
    "end": "29160"
  },
  {
    "text": "I work for Red Hat and I'm one of the maintenance of the safe piecing MOOC so",
    "start": "29160",
    "end": "36030"
  },
  {
    "text": "welcome to the caffeinated tutorial we have 40 slides and the demo and we need to get going so fasten your seat belts",
    "start": "36030",
    "end": "44420"
  },
  {
    "text": "let's start from basics for those of you who do not know self is an open source",
    "start": "44420",
    "end": "50969"
  },
  {
    "text": "distributed software-defined storage solution that allows users to access data through different interfaces",
    "start": "50969",
    "end": "57390"
  },
  {
    "text": "including object block and file or as we",
    "start": "57390",
    "end": "62460"
  },
  {
    "text": "like to think of it Saif is the Linux of storage and not just because of the open",
    "start": "62460",
    "end": "67979"
  },
  {
    "text": "source aspect but because there are many many technically fascinating things to surf's beautiful and invincible",
    "start": "67979",
    "end": "74270"
  },
  {
    "text": "immensely scalable design that I'm not going to cover here I will just say it",
    "start": "74270",
    "end": "83280"
  },
  {
    "text": "in in storage we like to say that things are never exciting except when storage",
    "start": "83280",
    "end": "90329"
  },
  {
    "text": "doesn't work and that is actually not true of self Saif is interesting and",
    "start": "90329",
    "end": "95850"
  },
  {
    "text": "exciting on a technical level and that is why we allow ourselves to show some",
    "start": "95850",
    "end": "100860"
  },
  {
    "text": "hutzpah and call it the future of storage some basic terminology suffers a",
    "start": "100860",
    "end": "107520"
  },
  {
    "text": "multitude of demons the ones managing actual storage are called Westies which",
    "start": "107520",
    "end": "112740"
  },
  {
    "text": "also manage data replication and resiliency among other things this is the redose layer of this diagram higher",
    "start": "112740",
    "end": "121140"
  },
  {
    "text": "level interfaces provide block storage in the RBD library here or object storage in the form",
    "start": "121140",
    "end": "126720"
  },
  {
    "text": "the rgw demon deliver which delivers the AWS s3 protocol on top of the underlying",
    "start": "126720",
    "end": "133950"
  },
  {
    "text": "storage core one of the things that is fascinating about SEF is its data",
    "start": "133950",
    "end": "140010"
  },
  {
    "text": "placement approach requiring no gateways but finding data algorithmically in short if you know how distributed hash",
    "start": "140010",
    "end": "147870"
  },
  {
    "text": "tables work you already know what concepts are is built around and what",
    "start": "147870",
    "end": "154260"
  },
  {
    "text": "makes it look more like a peer-to-peer networking system than traditional storage the important thing you need to",
    "start": "154260",
    "end": "162060"
  },
  {
    "text": "understand here is that SEF deliver storage out of commodity servers scales out potentially without limit and today",
    "start": "162060",
    "end": "169170"
  },
  {
    "text": "to tens of petabytes per cluster and delivers the three storage interfaces out of this distributed system of",
    "start": "169170",
    "end": "176960"
  },
  {
    "text": "individual nodes which look more like your compute servers than your",
    "start": "176960",
    "end": "182550"
  },
  {
    "text": "traditional storage so why is storage in kubernetes hard well let's cut to the",
    "start": "182550",
    "end": "191520"
  },
  {
    "text": "chase and let's say that as micro services are decoupling infrastructure",
    "start": "191520",
    "end": "197580"
  },
  {
    "text": "and application logic the developer is no longer need to worry about infrastructure that is great for",
    "start": "197580",
    "end": "204030"
  },
  {
    "text": "developers but the operators still need to figure out how to make things work even if it's behind the scenes the",
    "start": "204030",
    "end": "212340"
  },
  {
    "text": "kubernetes architecture is very dynamic environment with containers being",
    "start": "212340",
    "end": "218100"
  },
  {
    "text": "created and destroyed based on healing and need and load but the key issue here",
    "start": "218100",
    "end": "224400"
  },
  {
    "text": "is that local persistent storage cannot support this dynamic behavior data locality gets in the way kubernetes is",
    "start": "224400",
    "end": "233400"
  },
  {
    "text": "extremely powerful in many regards like scalability and management but it did not originally support storing state all",
    "start": "233400",
    "end": "239340"
  },
  {
    "text": "that well to be honest essentially its architectural its architecture badly",
    "start": "239340",
    "end": "244590"
  },
  {
    "text": "wants to be an ephemeral storage environment statelessness is close to",
    "start": "244590",
    "end": "251580"
  },
  {
    "text": "the heart of the paths and Ketel metaphor that we like to use for",
    "start": "251580",
    "end": "258150"
  },
  {
    "text": "clouds but many if not most of the useful applications today are stateful",
    "start": "258150",
    "end": "264750"
  },
  {
    "text": "and that brings the need for external network storage the simplest solution to",
    "start": "264750",
    "end": "270419"
  },
  {
    "text": "this problem is to have apps running inside the cluster with their storage residing in an external storage setup",
    "start": "270419",
    "end": "277440"
  },
  {
    "text": "such as a public cloud or worse yet the legacy storage appliance that you already have in your data center using a",
    "start": "277440",
    "end": "285090"
  },
  {
    "text": "traditional storage appliance usually kills the scalability that you've won on the compute side by building a cloud and",
    "start": "285090",
    "end": "290990"
  },
  {
    "text": "cripples its economics but this is not simply about bashing the limits of appliances even if you are using a",
    "start": "290990",
    "end": "297780"
  },
  {
    "text": "uniformly scalable software-defined storage provider like SEF instead of an appliance you have this picture of",
    "start": "297780",
    "end": "303990"
  },
  {
    "text": "storage as something that exists outside of your cloud outside of your cloud",
    "start": "303990",
    "end": "309750"
  },
  {
    "text": "fabric usually underneath it notably this is how OpenStack does storage and",
    "start": "309750",
    "end": "316639"
  },
  {
    "text": "there are some well-known limitations with this approach the most notable one",
    "start": "316639",
    "end": "321750"
  },
  {
    "text": "here is that it's not portable if you're relying on external storage you need to have it already accessible as you are",
    "start": "321750",
    "end": "328680"
  },
  {
    "text": "deploying your cluster because it is not built in kubernetes and when you want to",
    "start": "328680",
    "end": "333900"
  },
  {
    "text": "move your application to a different cloud provider migrating between Amazon Microsoft and Google which is",
    "start": "333900",
    "end": "339660"
  },
  {
    "text": "realistically all your options or even moving between public clouds and on-premise you need to worry about how",
    "start": "339660",
    "end": "346440"
  },
  {
    "text": "that external storage is going to go there with you another thing to consider",
    "start": "346440",
    "end": "352139"
  },
  {
    "text": "is that you are if you're relying on a cloud provider you may want to avoid the vendor lock-in coming from their",
    "start": "352139",
    "end": "358289"
  },
  {
    "text": "specific storage implementation so one approach to solve this problem is to run",
    "start": "358289",
    "end": "364349"
  },
  {
    "text": "storage on top of kubernetes rather than underneath it as modern software-defined storage like seth is homogeneous would",
    "start": "364349",
    "end": "372270"
  },
  {
    "text": "compute in that it uses servers from your favorite iron vendor of choice as",
    "start": "372270",
    "end": "377639"
  },
  {
    "text": "building blocks this is relatively easy to pull off you can gamble your way to",
    "start": "377639",
    "end": "383280"
  },
  {
    "text": "success by deploying our storage as just another kubernetes application maybe a special one but not that special",
    "start": "383280",
    "end": "391139"
  },
  {
    "text": "so that is building block one here is",
    "start": "391139",
    "end": "397030"
  },
  {
    "text": "the next bit another aspect we need to discuss before we tackle rook is how kubernetes interfaces with storage in",
    "start": "397030",
    "end": "404530"
  },
  {
    "text": "other words drivers storage in kubernetes has multiple abstraction",
    "start": "404530",
    "end": "409570"
  },
  {
    "text": "layers ultimately intended to deliver workload portability at its most basic",
    "start": "409570",
    "end": "415000"
  },
  {
    "text": "the storage interface in kubernetes peer storage volumes to requests coming from",
    "start": "415000",
    "end": "420669"
  },
  {
    "text": "pods in the most sensible of these variations using a remote network based",
    "start": "420669",
    "end": "425860"
  },
  {
    "text": "storage system like SEF delivers dynamically allocated persistent volumes to claims made by pods this is done in a",
    "start": "425860",
    "end": "434110"
  },
  {
    "text": "way that is decoupled from the local implementation while requiring no knowledge of the local platform by the",
    "start": "434110",
    "end": "439810"
  },
  {
    "text": "user the administrator can still and probably should still have local knowledge this allows a workload to move",
    "start": "439810",
    "end": "447340"
  },
  {
    "text": "from let's say gke to Amazon and we're not going to go over all of the details",
    "start": "447340",
    "end": "454210"
  },
  {
    "text": "of the storage implementation in kubernetes but others have done that",
    "start": "454210",
    "end": "461020"
  },
  {
    "text": "work for us Saad Ali of Google has a very nice talk that is easy to find on",
    "start": "461020",
    "end": "467080"
  },
  {
    "text": "YouTube covering the fundamentals of PBS and claims and how they interface with",
    "start": "467080",
    "end": "474880"
  },
  {
    "text": "each other and the IBM FSS FCI team also has a series of short videos detailing",
    "start": "474880",
    "end": "482440"
  },
  {
    "text": "that in painstaking detail so looking at",
    "start": "482440",
    "end": "487720"
  },
  {
    "text": "a slightly higher level the first set of kubernetes volume drivers were so-called",
    "start": "487720",
    "end": "494199"
  },
  {
    "text": "in three drivers maintained as part of the kubernetes codebase itself and here",
    "start": "494199",
    "end": "501460"
  },
  {
    "text": "is how the entry drivers connect remote storage this approach enabled more rapid",
    "start": "501460",
    "end": "507490"
  },
  {
    "text": "development of kubernetes itself as did not require a consistent storage API to be developed",
    "start": "507490",
    "end": "514809"
  },
  {
    "text": "in three plugins enabled dynamic provisioning of user volumes volume",
    "start": "514809",
    "end": "520638"
  },
  {
    "text": "drivers conveniently attached pods to storage automatically regardless of which nodes are actually hosting the",
    "start": "520639",
    "end": "526939"
  },
  {
    "text": "pods all the while providing sufficient abstraction to enable this workload",
    "start": "526939",
    "end": "533209"
  },
  {
    "text": "portability that we're going after on the other hand in three plugins can be",
    "start": "533209",
    "end": "539480"
  },
  {
    "text": "painful for the kubernetes community to maintain and any bug in the plug-in code",
    "start": "539480",
    "end": "545509"
  },
  {
    "text": "could affect kubernetes core components security wise these entry drivers also",
    "start": "545509",
    "end": "552319"
  },
  {
    "text": "have the same level of access as kubernetes core components which is less than ideal maintaining plugins entry can",
    "start": "552319",
    "end": "560089"
  },
  {
    "text": "also be painful for vendors as they have to keep up with kubernetes fast release tempo you may have to backward fixes and",
    "start": "560089",
    "end": "568119"
  },
  {
    "text": "not that I'm complaining here they may have to open source their code of course",
    "start": "568119",
    "end": "575600"
  },
  {
    "text": "the remote storage in this picture could be AWS CBA Google Cloud PD or anything",
    "start": "575600",
    "end": "584779"
  },
  {
    "text": "else that has an entry driver but obviously in this session we like that so the example is stack based in the New",
    "start": "584779",
    "end": "592910"
  },
  {
    "text": "World in abled by the container storage interface volume plugins are maintained out of tree well this requires the",
    "start": "592910",
    "end": "600889"
  },
  {
    "text": "well-defined API that we dodged earlier and Couples API changes with kubernetes",
    "start": "600889",
    "end": "606709"
  },
  {
    "text": "releases it has an amazing feature for operations storage can once again be",
    "start": "606709",
    "end": "612589"
  },
  {
    "text": "treated as a workload to be containerized and deployed on kubernetes cluster just like any other so first we",
    "start": "612589",
    "end": "618740"
  },
  {
    "text": "talked about doing it with the storage itself now we can actually do it also with the storage drivers storage plugins",
    "start": "618740",
    "end": "626179"
  },
  {
    "text": "can now be provisioned simply by calling your cube control cube cattle with a llamó file the cover Natives team and",
    "start": "626179",
    "end": "633949"
  },
  {
    "text": "third-party vendors are responsible for separate discrete components and security access does not exceed the",
    "start": "633949",
    "end": "639619"
  },
  {
    "text": "permissions that are actually required for the past these components run inside",
    "start": "639619",
    "end": "644749"
  },
  {
    "text": "card containers sharing network and storage access with the main workload container you can see",
    "start": "644749",
    "end": "651480"
  },
  {
    "text": "here from the massive errors that clearly there is an API at play but we",
    "start": "651480",
    "end": "657809"
  },
  {
    "text": "don't really need to understand all that unless we're writing a driver the bits that is interesting to understand",
    "start": "657809",
    "end": "662939"
  },
  {
    "text": "however is that all this abstraction is not changing the performance from the",
    "start": "662939",
    "end": "669029"
  },
  {
    "text": "previous picture because once the storage is attached to a pod the",
    "start": "669029",
    "end": "674730"
  },
  {
    "text": "interface is direct there is no intermediation of the data exchange so maybe allocating the storage",
    "start": "674730",
    "end": "680519"
  },
  {
    "text": "looks a little bit more complicated but performance wise it's exactly the same thing some more details on",
    "start": "680519",
    "end": "689040"
  },
  {
    "text": "implementation here probably too much detail frankly but one bit of Driver",
    "start": "689040",
    "end": "697499"
  },
  {
    "text": "lore worth knowing beyond what I just mentioned and something that is not in this slide is that there are these",
    "start": "697499",
    "end": "705569"
  },
  {
    "text": "things called flex volume drivers which are popular with work so they are worth mentioning flex volume drivers are",
    "start": "705569",
    "end": "712259"
  },
  {
    "text": "another out of three effort which is still maintained by now but now considered already legacy and not really",
    "start": "712259",
    "end": "719490"
  },
  {
    "text": "being enhanced the flex volume drivers make exact calls to a file on the local machine",
    "start": "719490",
    "end": "725809"
  },
  {
    "text": "operationally this may be limiting as you need special access to deploy these files so what I was just saying about",
    "start": "725809",
    "end": "732779"
  },
  {
    "text": "the CSI that you can deploy the drivers as a llamó is not really true of flex",
    "start": "732779",
    "end": "739139"
  },
  {
    "text": "drivers unless you have special access which actually is not possible in certain public cloud environments",
    "start": "739139",
    "end": "745230"
  },
  {
    "text": "notably Google Cloud as a result they are not as easy to deploy as the newer",
    "start": "745230",
    "end": "750240"
  },
  {
    "text": "CSI drivers and are kind of falling out of favor despite the installment in the current",
    "start": "750240",
    "end": "756929"
  },
  {
    "text": "effort is going fully into the CSI API and and that's where you should see",
    "start": "756929",
    "end": "765119"
  },
  {
    "text": "things going as things before the sub CSI API combines in one",
    "start": "765119",
    "end": "772970"
  },
  {
    "text": "interface the best of the kubernetes volume system and the CSI interface providing dynamic provisioning of set",
    "start": "772970",
    "end": "779029"
  },
  {
    "text": "volumes and automatically attaching them to workloads use of the safar PD driver",
    "start": "779029",
    "end": "786019"
  },
  {
    "text": "here results in transparent and provisioning by the way as well as all",
    "start": "786019",
    "end": "791569"
  },
  {
    "text": "of surfs infinitely powerful storage architecture is hidden behind the covers",
    "start": "791569",
    "end": "797629"
  },
  {
    "text": "here so you get very powerful storage but you don't necessarily know how it's doing its magic which for many users is",
    "start": "797629",
    "end": "804769"
  },
  {
    "text": "actually good and good the integration here was completed with rook 1.0 and as",
    "start": "804769",
    "end": "812480"
  },
  {
    "text": "the user does not need to be privy to surfs internal implementation detail an application could move from your private",
    "start": "812480",
    "end": "818600"
  },
  {
    "text": "data center to a public cloud without adjustments provided you manage that",
    "start": "818600",
    "end": "823730"
  },
  {
    "text": "pesky data gravity aspect on your own by the way volume claims and kubernetes",
    "start": "823730",
    "end": "830389"
  },
  {
    "text": "have access modes which are known as our way or the blacks that's another",
    "start": "830389",
    "end": "836809"
  },
  {
    "text": "interesting detail about drivers are wo and rwx are the most popular choices rwx",
    "start": "836809",
    "end": "842329"
  },
  {
    "text": "is used to share data between iPods multiple containers rwo of is the",
    "start": "842329",
    "end": "847730"
  },
  {
    "text": "default choice providing storage in exclusive access to one in SEF RW is",
    "start": "847730",
    "end": "853970"
  },
  {
    "text": "delivered by our BD to ensure maximum performance while surface delivers the",
    "start": "853970",
    "end": "859819"
  },
  {
    "text": "sheer rwx mode when it's required and now we're finally reaching what we are",
    "start": "859819",
    "end": "866480"
  },
  {
    "text": "all here to talk about which is project work rock is the CN CF storage operator",
    "start": "866480",
    "end": "871819"
  },
  {
    "text": "of choice and as of today it's most solid integration with is with storage",
    "start": "871819",
    "end": "877429"
  },
  {
    "text": "as delivered by itself a kubernetes operator functions by letting the site",
    "start": "877429",
    "end": "883850"
  },
  {
    "text": "administrator define a target state and then working its way toward achieving and maintaining that state",
    "start": "883850",
    "end": "891610"
  },
  {
    "text": "for a kubernetes hosted workload he doesn't do it in a vacuum Brook does just that for safe storage as",
    "start": "893270",
    "end": "901940"
  },
  {
    "text": "soon as rook is deployed in Burnet his cluster a complete safe environment is",
    "start": "901940",
    "end": "907459"
  },
  {
    "text": "running and while my and while one might be forgiven for thinking that suffers",
    "start": "907459",
    "end": "913100"
  },
  {
    "text": "long solved the issue of persistent resilience a resilient and remote storage that is not really what rook",
    "start": "913100",
    "end": "920149"
  },
  {
    "text": "does rook manages the operation of the safe cluster in the kubernetes environment so that the operator is",
    "start": "920149",
    "end": "928100"
  },
  {
    "text": "isolated from having to do a lot of chores him or herself",
    "start": "928100",
    "end": "933970"
  },
  {
    "text": "Brooks approach to hiding complexity from the user couples uniquely well with safes open massively scalable",
    "start": "933970",
    "end": "939950"
  },
  {
    "text": "software-defined storage system double inner delivering a flexible scale-out architecture on clustered commodity",
    "start": "939950",
    "end": "946220"
  },
  {
    "text": "Hardware sufferings a vibrant open-source community and its own thriving vendor ecosystem the",
    "start": "946220",
    "end": "952520"
  },
  {
    "text": "combination of the two projects safes advanced storage technology pairs with",
    "start": "952520",
    "end": "958399"
  },
  {
    "text": "rooks high usability to deliver what is the perfect combination for developers and operators hosting workloads in",
    "start": "958399",
    "end": "964310"
  },
  {
    "text": "kubernetes environment and on that note I will hand over to my colleague",
    "start": "964310",
    "end": "969700"
  },
  {
    "text": "Sebastian Han to dive deeper into the architecture I think that we need we",
    "start": "969700",
    "end": "977630"
  },
  {
    "text": "need the other microphone on please all right",
    "start": "977630",
    "end": "984670"
  },
  {
    "text": "quick question before I start how many of you knew Seth before rook and how",
    "start": "984670",
    "end": "993730"
  },
  {
    "text": "many got to know Seth with rook okay it's good that actually I was actually",
    "start": "993730",
    "end": "1000030"
  },
  {
    "text": "thinking that we will have to do more introduction of stuff but actually the audience is actually really familiar with this app so it is actually a really",
    "start": "1000030",
    "end": "1007080"
  },
  {
    "text": "good thing so we have two big themes right the first one is installing staff as",
    "start": "1007080",
    "end": "1014730"
  },
  {
    "text": "part of the as part of kubernetes cluster so in in this scenario Luke is actually responsible for",
    "start": "1014730",
    "end": "1020520"
  },
  {
    "text": "installing configuring scaling upgrading safe and managing its entire lifecycle",
    "start": "1020520",
    "end": "1026660"
  },
  {
    "text": "just just just like an application running on kubernetes that's the first part the second one is actually",
    "start": "1026660",
    "end": "1033180"
  },
  {
    "text": "providing the system storage to applications and this is done by a CSI",
    "start": "1033180",
    "end": "1038430"
  },
  {
    "text": "so root not only deploy staff as an application in communities but also helps you providing using that storage",
    "start": "1038430",
    "end": "1046189"
  },
  {
    "text": "for your application so the root",
    "start": "1046190",
    "end": "1052350"
  },
  {
    "text": "operator actually implements the operated pattern it's actually a very popular concept in the kubernetes word",
    "start": "1052350",
    "end": "1058760"
  },
  {
    "text": "basically an operator is just an entity that runs in cuban it is so that it will",
    "start": "1058760",
    "end": "1064220"
  },
  {
    "text": "extend kubernetes knowledge landscape so if Cuba latest doesn't know something then by an operator then we will be able",
    "start": "1064220",
    "end": "1072570"
  },
  {
    "text": "to instruct Cuba nurses that you know how to deploy that cluster you know many",
    "start": "1072570",
    "end": "1078480"
  },
  {
    "text": "more things and all of those things are being unbiased yard is so customer shows definitions what's really important to",
    "start": "1078480",
    "end": "1085680"
  },
  {
    "text": "understand is that from a user perspective the user always has to inject what we call STR so basically the",
    "start": "1085680",
    "end": "1093090"
  },
  {
    "text": "CR is the installation of that CR G and we're gonna go through an example of this here in a minute but what's really",
    "start": "1093090",
    "end": "1099420"
  },
  {
    "text": "important to understand is that Luke with the help of communities will always make sure that the desired state that",
    "start": "1099420",
    "end": "1105210"
  },
  {
    "text": "was provided by the user will always be maintained throughout the lifecycle of",
    "start": "1105210",
    "end": "1110490"
  },
  {
    "text": "the cluster and basically what what group does three main things right",
    "start": "1110490",
    "end": "1115540"
  },
  {
    "text": "observing changes that might happen to that CR or in SEF and we react upon",
    "start": "1115540",
    "end": "1120790"
  },
  {
    "text": "those events so basically observes analyze and acts any changes that might come up on the",
    "start": "1120790",
    "end": "1127120"
  },
  {
    "text": "platform itself or just because they usually decided that they wanted to be expanded faster or just add more things",
    "start": "1127120",
    "end": "1133810"
  },
  {
    "text": "to it like more monitors for example so now that you're familiar with SAP",
    "start": "1133810",
    "end": "1138930"
  },
  {
    "text": "community storage in kubernetes and in ruk more generally we're gonna dive into books architecture a little bit more so",
    "start": "1138930",
    "end": "1146410"
  },
  {
    "text": "what you see at the very bottom here and what we see at the very button or and",
    "start": "1146410",
    "end": "1154660"
  },
  {
    "text": "this is again theme number one infinite number two right so team number one again is deploying safe as an",
    "start": "1154660",
    "end": "1160870"
  },
  {
    "text": "application in cuban it is so always these are objects towards demons responsible for basically replicating",
    "start": "1160870",
    "end": "1168310"
  },
  {
    "text": "objects for adding objects scrubbing objects we have months basically the brain of the cluster they",
    "start": "1168310",
    "end": "1176590"
  },
  {
    "text": "come with with three or four is just five sorry it's always an even number an",
    "start": "1176590",
    "end": "1182800"
  },
  {
    "text": "odd number sorry they maintain the map of the cluster but they're not in a data path and then we have all the demons",
    "start": "1182800",
    "end": "1189160"
  },
  {
    "text": "like MDS writers gateway and MGR so the MDS is basically the metadata server that exposes the disability filesystem",
    "start": "1189160",
    "end": "1195370"
  },
  {
    "text": "of Ceph where read as gateways the rest endpoint where you can consume data at rest the manager is just a pluggable",
    "start": "1195370",
    "end": "1202240"
  },
  {
    "text": "interface that you can use to extend safe capabilities so like it's a it's a",
    "start": "1202240",
    "end": "1208150"
  },
  {
    "text": "pluggable mechanism where you can add more we can think add things like like metrics on the second theme here we have",
    "start": "1208150",
    "end": "1217390"
  },
  {
    "text": "what so obviously the rook operator the main thing responsible for all the things we",
    "start": "1217390",
    "end": "1223270"
  },
  {
    "text": "do so the bootstrapped and the maintenance of staff and the connection so the connection is actually being done",
    "start": "1223270",
    "end": "1229870"
  },
  {
    "text": "by agents here so we call them agents is actually really generic but agents in this case actually represent CSI so at",
    "start": "1229870",
    "end": "1238330"
  },
  {
    "text": "the very top here we we have your app and the claim of your volume so",
    "start": "1238330",
    "end": "1243440"
  },
  {
    "text": "the user you just claimed for volume we do dynamic provisioning and then these agents are basically running where your",
    "start": "1243440",
    "end": "1248720"
  },
  {
    "text": "app run and they will just map the storage and provide it to your containers so going back to this desired",
    "start": "1248720",
    "end": "1257750"
  },
  {
    "text": "state that data was mentioning earlier so this is a really simple example of a",
    "start": "1257750",
    "end": "1262970"
  },
  {
    "text": "CR that you will inject inject into cube unit is so that you can deploy step cluster and what's actually really",
    "start": "1262970",
    "end": "1268639"
  },
  {
    "text": "interesting as you can see is that with within 29th of Yama's then you can actually get a cluster up and running so",
    "start": "1268639",
    "end": "1275539"
  },
  {
    "text": "that's actually in terms of user experience that that's actually really good so if we look a little bit so we",
    "start": "1275539",
    "end": "1281600"
  },
  {
    "text": "have the namespace but we don't care much about this at this point so if you look quickly at the spec what we can see is that we we only have to provide a",
    "start": "1281600",
    "end": "1287840"
  },
  {
    "text": "relatively few information here so we have the image which is actually",
    "start": "1287840",
    "end": "1292940"
  },
  {
    "text": "critical because basically States what's the version we want to use so these images are provided by the docker",
    "start": "1292940",
    "end": "1299360"
  },
  {
    "text": "what we provide them as the second safe team they're available in the docker hub and what's really important about that",
    "start": "1299360",
    "end": "1305690"
  },
  {
    "text": "is that these images are built every day so whether there is a new set version or",
    "start": "1305690",
    "end": "1311120"
  },
  {
    "text": "just a change on the base OS then we will always build a new image out of that so we make sure that we don't have",
    "start": "1311120",
    "end": "1316909"
  },
  {
    "text": "all the potential vulnerabilities in that image will be soft because we just",
    "start": "1316909",
    "end": "1322879"
  },
  {
    "text": "provided a new one these images should be the ones that that if you wanna if",
    "start": "1322879",
    "end": "1329750"
  },
  {
    "text": "you're looking at the playing safe in containerize environment because these are let's say golden five images provided and maintained by the surf team",
    "start": "1329750",
    "end": "1338799"
  },
  {
    "text": "the non-count is just it's actually something that I would like to add",
    "start": "1338799",
    "end": "1344809"
  },
  {
    "text": "because if you are looking at the playing staff you want it to be really easy so you wouldn't really have to",
    "start": "1344809",
    "end": "1350419"
  },
  {
    "text": "choose how many months you want to run should be able to tell you that and I really hope in the future that we can",
    "start": "1350419",
    "end": "1356400"
  },
  {
    "text": "remove that flag so you don't actually even have to think about how many months you want to run we can obviously did you",
    "start": "1356400",
    "end": "1365100"
  },
  {
    "text": "can always ask you as well if you want to take advantage of the staff dashboard so that you can visualize visualize and",
    "start": "1365100",
    "end": "1371490"
  },
  {
    "text": "interact with the cluster to see what's happening and the very bottom is actually potentially the most important",
    "start": "1371490",
    "end": "1378180"
  },
  {
    "text": "one it's related to storage right so we have different modes different capabilities here that's actually the",
    "start": "1378180",
    "end": "1385050"
  },
  {
    "text": "simplest one so you can specify you can say use all the nodes and use all the",
    "start": "1385050",
    "end": "1390630"
  },
  {
    "text": "drives so we will go and scan all the devices on every nodes are available in",
    "start": "1390630",
    "end": "1396210"
  },
  {
    "text": "your kubernetes cluster use the drives and add them in your own add them in safe that's that's easiest in our I",
    "start": "1396210",
    "end": "1403440"
  },
  {
    "text": "would say we can be more granular and more specific here so you can specify nodes with a particular label that are",
    "start": "1403440",
    "end": "1410490"
  },
  {
    "text": "actually it may be labeled like storage nodes and then we will go through these nodes and again scan the drives and",
    "start": "1410490",
    "end": "1415800"
  },
  {
    "text": "detect which which there are which drives are good candidates to become actually storage daemons and then add",
    "start": "1415800",
    "end": "1422850"
  },
  {
    "text": "them to the cluster you can even you can go even deeper here by specifying which",
    "start": "1422850",
    "end": "1427890"
  },
  {
    "text": "node and which drives you want to use as storage storage back-end",
    "start": "1427890",
    "end": "1435620"
  },
  {
    "text": "so these are the custom resources discharges are available they are",
    "start": "1436520",
    "end": "1442080"
  },
  {
    "text": "actually being provided by book so we already discussed the first one because",
    "start": "1442080",
    "end": "1447300"
  },
  {
    "text": "that's actually just deploying a sector so but not just quite deploying a staff crystal the second one is the block pool",
    "start": "1447300",
    "end": "1453570"
  },
  {
    "text": "which basically with the pool itself is just an inn and just a storage entity",
    "start": "1453570",
    "end": "1460230"
  },
  {
    "text": "where you will be storing your data pools can have different capabilities who can be whose can be attached to a",
    "start": "1460230",
    "end": "1466230"
  },
  {
    "text": "certain portion of infrastructure if you if you have different types of workloads so you can be assigning let's say one",
    "start": "1466230",
    "end": "1471510"
  },
  {
    "text": "pool for object workloads or wonderful for block workloads and these workers are obviously really",
    "start": "1471510",
    "end": "1478339"
  },
  {
    "text": "different and I mean in terms of IO they are more or less more intensive than others so you can have dedicated",
    "start": "1478339",
    "end": "1484309"
  },
  {
    "text": "hardware for this so this will actually be creating the pool again with abilities you can use a storage class",
    "start": "1484309",
    "end": "1490969"
  },
  {
    "text": "and then once the user wants to claim a PVC then they will just use it same goes",
    "start": "1490969",
    "end": "1496279"
  },
  {
    "text": "for the file system here we we can deploy the MDS so the for the portion of",
    "start": "1496279",
    "end": "1502759"
  },
  {
    "text": "the distributed file system of staff we have Stephan FS as well which actually relies on Ganesha under the hood in",
    "start": "1502759",
    "end": "1509719"
  },
  {
    "text": "Ganesha is actually using the staff metadata file system to expose NFS",
    "start": "1509719",
    "end": "1515629"
  },
  {
    "text": "shares self objects torrents a public self of storing self object store user",
    "start": "1515629",
    "end": "1520909"
  },
  {
    "text": "are actually pretty simple right they just boost reproduce get to instances so",
    "start": "1520909",
    "end": "1526639"
  },
  {
    "text": "that you can consume a REST API endpoint similar to not similar to it's just like",
    "start": "1526639",
    "end": "1533570"
  },
  {
    "text": "an s3 endpoint so if you're looking at developing one as three then you can put strap those and then you're ready to go",
    "start": "1533570",
    "end": "1541239"
  },
  {
    "text": "okay so that's the that's the embarrassed embarrassing moment of this",
    "start": "1541239",
    "end": "1546709"
  },
  {
    "text": "talk because we actually had something working yesterday and like a couple of",
    "start": "1546709",
    "end": "1553519"
  },
  {
    "text": "hours ago everything started crashing so I'm just gonna let Federico explain what actually happen yeah so the demo gods",
    "start": "1553519",
    "end": "1562879"
  },
  {
    "text": "are not smiling on us today that way let me see can I bring up the terminal",
    "start": "1562879",
    "end": "1570608"
  },
  {
    "text": "I want to drive the terminal",
    "start": "1581080",
    "end": "1585570"
  },
  {
    "text": "oh it's the others",
    "start": "1589210",
    "end": "1592289"
  },
  {
    "text": "Wow",
    "start": "1599750",
    "end": "1602350"
  },
  {
    "text": "trying to strain to show you as I was trying to show you what we have running",
    "start": "1606929",
    "end": "1613299"
  },
  {
    "text": "but not going to the rightness stuff",
    "start": "1613299",
    "end": "1621120"
  },
  {
    "text": "okay let's just switch back to the prison yeah",
    "start": "1624330",
    "end": "1628969"
  },
  {
    "text": "now it'll go back",
    "start": "1647870",
    "end": "1651429"
  },
  {
    "text": "where is the cars",
    "start": "1660180",
    "end": "1663380"
  },
  {
    "text": "at least Terminal is arranged so we have",
    "start": "1668930",
    "end": "1676280"
  },
  {
    "text": "a bit of the details of the cluster construction in the slide so at least we can tell you what the cluster looks like",
    "start": "1676280",
    "end": "1681320"
  },
  {
    "text": "but I wanted to show you what we actually had running so this was validated last night around 11 hours ago",
    "start": "1681320",
    "end": "1688520"
  },
  {
    "text": "and then three hours ago when we were doing the final rehearsal the master stopped answering us what is going on is",
    "start": "1688520",
    "end": "1697610"
  },
  {
    "text": "actually not at kubernetes level it's typical embedded development problems so",
    "start": "1697610",
    "end": "1703010"
  },
  {
    "text": "we have to get you booth running if you're familiar with that that's the typical embedded bootloader the kernel",
    "start": "1703010",
    "end": "1710000"
  },
  {
    "text": "obviously and user land and then get kubernetes on top the higher we get in",
    "start": "1710000",
    "end": "1715280"
  },
  {
    "text": "the stack the easier it is so in effect with Rock we didn't encounter any significant problems and",
    "start": "1715280",
    "end": "1721250"
  },
  {
    "text": "kubernetes was very straightforward as well the part that we are seeing instability with is that we're getting",
    "start": "1721250",
    "end": "1728120"
  },
  {
    "text": "some kernel panics from because we had to do some kernel rebuilds to add the RVD module to to the image that were",
    "start": "1728120",
    "end": "1736220"
  },
  {
    "text": "using for this and there is something obviously wrong in our detailed configuration because we're seeing some",
    "start": "1736220",
    "end": "1742820"
  },
  {
    "text": "inconsistent behavior in terms of memory access so in terms of when things are",
    "start": "1742820",
    "end": "1748490"
  },
  {
    "text": "running you actually get to do get pods fairly normally and you see the pods that would come from a little cluster",
    "start": "1748490",
    "end": "1756610"
  },
  {
    "text": "but then it it seems to have a significantly high probability of",
    "start": "1756610",
    "end": "1762830"
  },
  {
    "text": "killing itself within a certain number of hours because of these random kernel issues and the way they are happening",
    "start": "1762830",
    "end": "1769490"
  },
  {
    "text": "they corrupt the file system that's a short part the plan is to have a blog showing how we are doing this and",
    "start": "1769490",
    "end": "1775970"
  },
  {
    "text": "providing the entire documentation but obviously we have some more some more details to work out",
    "start": "1775970",
    "end": "1783190"
  },
  {
    "text": "can we can you help me bring back two slides here we are I have",
    "start": "1784980",
    "end": "1796018"
  },
  {
    "text": "so hard where accidents aside we can see details of what the cluster looks like",
    "start": "1838710",
    "end": "1847400"
  },
  {
    "text": "alright so the hardware we chose is the global scale espresso bean v5 the aim",
    "start": "1861450",
    "end": "1867100"
  },
  {
    "text": "was to build a cluster with eight nodes and all SSD storage and spend less than",
    "start": "1867100",
    "end": "1872110"
  },
  {
    "text": "a thousand dollars to do so and we hit the dollar limit we obviously didn't hit",
    "start": "1872110",
    "end": "1880630"
  },
  {
    "text": "the reliability limit yet but the problem is not with the hardware so we should be able to do that a reasonably",
    "start": "1880630",
    "end": "1886840"
  },
  {
    "text": "soon the system has SATA ports which is why we chose it it seems like it would a",
    "start": "1886840",
    "end": "1892750"
  },
  {
    "text": "way to do storage it also has onboard PCI which would be",
    "start": "1892750",
    "end": "1898150"
  },
  {
    "text": "another option for storage that we're not using right now we're just using SATA SSDs and we aim to hit the thousand",
    "start": "1898150",
    "end": "1906010"
  },
  {
    "text": "dollar mark or to stay below it we chose the intel SSD 545 because it's not the",
    "start": "1906010",
    "end": "1911920"
  },
  {
    "text": "newest of SSDs and so we can get them for extremely cheap we can get the board's for about forty nine dollars and",
    "start": "1911920",
    "end": "1918850"
  },
  {
    "text": "the SSDs for about sixty nine dollars and so we're around eight hundred dollars for an eight node cluster and",
    "start": "1918850",
    "end": "1925840"
  },
  {
    "text": "then we're doing slightly fancier things like having a unified power supply so",
    "start": "1925840",
    "end": "1931390"
  },
  {
    "text": "that we reduce the amount of cabling and just try to make it look nice but those are thrilled though the cluster proper",
    "start": "1931390",
    "end": "1937930"
  },
  {
    "text": "is eight hundred dollars we are using the components that I",
    "start": "1937930",
    "end": "1944670"
  },
  {
    "text": "described before we're using kernel 419 that's kind of the default part for I",
    "start": "1944670",
    "end": "1951870"
  },
  {
    "text": "don't know if you how familiar you are with embedded development if you are you know that the problem with these embedded boards is that they're very far",
    "start": "1951870",
    "end": "1958770"
  },
  {
    "text": "from data center hardware it's a completely different world so for",
    "start": "1958770",
    "end": "1964500"
  },
  {
    "text": "getting a reliable Linux distribution on and by the hardware you have to have all the drivers the most popular",
    "start": "1964500",
    "end": "1972330"
  },
  {
    "text": "distribution for doing this right now is called armed Ian but the arm beyond images for specimen v5 are not perfect",
    "start": "1972330",
    "end": "1980220"
  },
  {
    "text": "and we introduced a few more problems ourselves with our ability the pesky details need to be worked out but once",
    "start": "1980220",
    "end": "1987780"
  },
  {
    "text": "we get the kubernetes part running the rest seems to be seamless we just need to manage to keep the cluster up for",
    "start": "1987780",
    "end": "1994410"
  },
  {
    "text": "more than 12 hours so the part is OS reliability not not kubernetes problems",
    "start": "1994410",
    "end": "2001120"
  },
  {
    "text": "okay quickly trying to design we do have one of the boards here if you want to",
    "start": "2001120",
    "end": "2006590"
  },
  {
    "text": "take a look at the end so a little bit about the future of Brooke so we just reuse one over last week we're done to",
    "start": "2006590",
    "end": "2012830"
  },
  {
    "text": "101 at the moment but one of the highlights some of the things we're going to work on for the next months so",
    "start": "2012830",
    "end": "2019850"
  },
  {
    "text": "one one in one two coming so one of the biggest picture we are trying to implement at this point is the external",
    "start": "2019850",
    "end": "2024980"
  },
  {
    "text": "functionality so meaning that not everything is actually Greenfield so you have run fin environments too so if you",
    "start": "2024980",
    "end": "2030560"
  },
  {
    "text": "have an existing set of cluster then you can actually bootstrap root in tribulations and then tell it to connect",
    "start": "2030560",
    "end": "2036590"
  },
  {
    "text": "to this existing storage cluster and then the only thing we will be doing here is that we won't be managing surfs",
    "start": "2036590",
    "end": "2042470"
  },
  {
    "text": "life cycle but we will only bootstrap resources that we can consume by RC",
    "start": "2042470",
    "end": "2047570"
  },
  {
    "text": "artists such as the persistent the riders gateway and the NFS file system so that's the idea and it this is",
    "start": "2047570",
    "end": "2054800"
  },
  {
    "text": "actually one of the first step to actually achieve achieve by taking a",
    "start": "2054800",
    "end": "2061190"
  },
  {
    "text": "takeover of an existing cluster so the ultimate go for that is basically to be able to you have an existing cluster",
    "start": "2061190",
    "end": "2067399"
  },
  {
    "text": "that is not containerized of the communities Christo and the goal here is just to take over all of these",
    "start": "2067400",
    "end": "2074669"
  },
  {
    "text": "resources and then have them be managed by by work that's in the future still",
    "start": "2074669",
    "end": "2080760"
  },
  {
    "text": "we're working toward that goal we also want to integrate with Montes I believe",
    "start": "2080760",
    "end": "2087929"
  },
  {
    "text": "there is not so many things to do but at the moment we if you want to get a better performance out of your cluster",
    "start": "2087929",
    "end": "2093720"
  },
  {
    "text": "you have to use hosts networking which obviously brings more performance but then also more security concerns as well",
    "start": "2093720",
    "end": "2099359"
  },
  {
    "text": "because once you do this you basically expose all the network stack of the hosts inside your container so the",
    "start": "2099359",
    "end": "2105540"
  },
  {
    "text": "internal security that's basically not ideal and what we want to do is to use motors to basically specify which",
    "start": "2105540",
    "end": "2111990"
  },
  {
    "text": "interface we would like to use for our storage cluster which will bring us more control and basically more isolation",
    "start": "2111990",
    "end": "2119190"
  },
  {
    "text": "more security dynamic provisioning on cloud provider is actually something a",
    "start": "2119190",
    "end": "2125730"
  },
  {
    "text": "wooden thing was that popular that we have been getting many many more requests on that because actually they",
    "start": "2125730",
    "end": "2132060"
  },
  {
    "text": "are involved a lot of people are not only running Dremel machines but also on cloud providers too so the use case here",
    "start": "2132060",
    "end": "2139260"
  },
  {
    "text": "is that previously when I mentioned that you could be that you could specify which storage devices you want to use",
    "start": "2139260",
    "end": "2144690"
  },
  {
    "text": "for cluster than here for example if you're on Amazon then you'll be able to specify I want this amount of EBS",
    "start": "2144690",
    "end": "2150780"
  },
  {
    "text": "volumes and then with this particular size and then we'll just take care of the creation and the attachment of these",
    "start": "2150780",
    "end": "2156420"
  },
  {
    "text": "volumes to the virtual machines and once we dipper look and staff we will consume that so you were going to have to",
    "start": "2156420",
    "end": "2162270"
  },
  {
    "text": "basically manually create create volumes and attach them that's basically again",
    "start": "2162270",
    "end": "2168300"
  },
  {
    "text": "announcing the user experience last but not least Percodan amin provisioning is",
    "start": "2168300",
    "end": "2174089"
  },
  {
    "text": "one of the most desired feature and it's something we're actually pushing into the community the community's community",
    "start": "2174089",
    "end": "2180359"
  },
  {
    "text": "it's actually really equivalent to what we do currently with volumes but at the rest object layer so not only you can",
    "start": "2180359",
    "end": "2187920"
  },
  {
    "text": "because at the moment you can only request the Gateway but the users don't care about the Gateway but what they",
    "start": "2187920",
    "end": "2194010"
  },
  {
    "text": "care about is basically the bracket and the Pretender so the ultimate goal here is to claim a",
    "start": "2194010",
    "end": "2199589"
  },
  {
    "text": "bucket and then simply consume it so you just ask for a bucket you get when you get you credentials that you can start",
    "start": "2199589",
    "end": "2205170"
  },
  {
    "text": "working you don't have to do anything you don't have to know anything about relegate weight and stuff the only thing",
    "start": "2205170",
    "end": "2210810"
  },
  {
    "text": "you have to do basically is just ask for that bucket so that's one of the things we're working on there is a PR for that",
    "start": "2210810",
    "end": "2217170"
  },
  {
    "text": "not sure if Jeff or Jenner in the room well you're actually working on this and yeah that's a super super nice yeah one",
    "start": "2217170",
    "end": "2226710"
  },
  {
    "text": "more thing we need 15 that's but at least again I'm super super happy to",
    "start": "2226710",
    "end": "2232619"
  },
  {
    "text": "announce that we actually got look into the operator hub the operator hardware",
    "start": "2232619",
    "end": "2238320"
  },
  {
    "text": "is a centralized place that that actually provides operators from the",
    "start": "2238320",
    "end": "2244619"
  },
  {
    "text": "community so if you're familiar with OLM it's an operator concept that is",
    "start": "2244619",
    "end": "2249990"
  },
  {
    "text": "basically an operator lifecycle manager that you can push shopping trip unit is and then you can inject CSS to it and",
    "start": "2249990",
    "end": "2257130"
  },
  {
    "text": "then you will be able to it will be able to bootstrap your operator for you so yeah we're super excited to announce",
    "start": "2257130",
    "end": "2263310"
  },
  {
    "text": "that this week I guess yeah so many",
    "start": "2263310",
    "end": "2268920"
  },
  {
    "text": "people helped us throughout this presentation especially people in the",
    "start": "2268920",
    "end": "2274530"
  },
  {
    "text": "West but I guess that help building will like to to take shout out to them and",
    "start": "2274530",
    "end": "2280400"
  },
  {
    "text": "yeah I'm just going so thanks very much for you can attention we were supposed",
    "start": "2280400",
    "end": "2286079"
  },
  {
    "text": "to have more time and we don't if you don't have time for Q&A that sort of program will be outside otherwise we",
    "start": "2286079",
    "end": "2291480"
  },
  {
    "text": "will be more than happy to take questions [Applause]",
    "start": "2291480",
    "end": "2300679"
  }
]
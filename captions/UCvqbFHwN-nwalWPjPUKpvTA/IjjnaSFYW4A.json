[
  {
    "start": "0",
    "end": "135000"
  },
  {
    "text": "alright it looks like we have studied at the number of participants right now so I'm gonna get started okay so welcome to",
    "start": "100",
    "end": "10839"
  },
  {
    "text": "today's CN CF webinar to Russia With Love kubernetes and exotic locations you know I saw this title and the less lists",
    "start": "10839",
    "end": "17710"
  },
  {
    "text": "of webinars that are coming up and I was like I must moderate that one so cool",
    "start": "17710",
    "end": "22980"
  },
  {
    "text": "anyway so I'm Priyanka Sharma and I'm an ambassador for the CN CF I'm also a",
    "start": "22980",
    "end": "28300"
  },
  {
    "text": "governing board member and I am director of cloud native Atget lab and I'll be",
    "start": "28300",
    "end": "33610"
  },
  {
    "text": "moderating today's webinar so thank you so much to everyone who is joining today I'd like to welcome our presenter for",
    "start": "33610",
    "end": "40780"
  },
  {
    "text": "the day Michael gosh I'm gonna do my best with the last name here Michael what a sorry sorry Michael Michael",
    "start": "40780",
    "end": "50199"
  },
  {
    "text": "double there who is a container solutions architect at cloud ops so just",
    "start": "50199",
    "end": "55690"
  },
  {
    "text": "before we get going though a couple of housekeeping items during the webinar",
    "start": "55690",
    "end": "61210"
  },
  {
    "text": "you won't be able to talk as an attendee this is kind of been going to be like a broadcast feelings but the good news is",
    "start": "61210",
    "end": "69369"
  },
  {
    "text": "you can there's a QA box at the bottom of your screen if anybody has trouble seeing it please put on note in the chat",
    "start": "69369",
    "end": "76420"
  },
  {
    "text": "and I'll try to help you out but it's Q&A is there right next to participants and when you want you can drop your",
    "start": "76420",
    "end": "84100"
  },
  {
    "text": "questions in there and then towards the end when Michael's done with this presentation look I'll go through the",
    "start": "84100",
    "end": "89380"
  },
  {
    "text": "list and we'll get through as many as we can and if there's some question that we",
    "start": "89380",
    "end": "95259"
  },
  {
    "text": "can weren't able to answer because of time or whatever reason Michaels contact will be at the end of his presentation",
    "start": "95259",
    "end": "100990"
  },
  {
    "text": "and you're able to get direct responses from him as well just so everybody knows",
    "start": "100990",
    "end": "106479"
  },
  {
    "text": "this session is being recorded and we will send out a link afterwards along",
    "start": "106479",
    "end": "112479"
  },
  {
    "text": "with the presentation so with all of those good things said and done I would",
    "start": "112479",
    "end": "117820"
  },
  {
    "text": "like to hand it over to Michael to kick off today's presentation over to you Michael thanks Franco so welcome everybody good",
    "start": "117820",
    "end": "125469"
  },
  {
    "text": "morning good afternoon good evening wherever you're from in the world this is the talk of two Russia would love",
    "start": "125469",
    "end": "130570"
  },
  {
    "text": "kubernetes in exotic locations if you came here looking for Russia with",
    "start": "130570",
    "end": "138330"
  },
  {
    "start": "135000",
    "end": "154000"
  },
  {
    "text": "love and you're a rancher trying to get into Russia this is not the talk and this was me doing some SEO search never",
    "start": "138330",
    "end": "144720"
  },
  {
    "text": "had before the talk and realized that maybe maybe a people won't be able to find a talk so easily but he definitely",
    "start": "144720",
    "end": "150090"
  },
  {
    "text": "the right talk if you're here to to learn about how to run kubernetes on premises so the agenda today I'll do a",
    "start": "150090",
    "end": "157920"
  },
  {
    "start": "154000",
    "end": "189000"
  },
  {
    "text": "bit of an intro about myself and the company I work for cloud ops and some cmts",
    "start": "157920",
    "end": "164090"
  },
  {
    "text": "info talk about the story so far how we got to be where we are with client and",
    "start": "164090",
    "end": "169200"
  },
  {
    "text": "and and where we needed to go to because of international data loss and things",
    "start": "169200",
    "end": "174239"
  },
  {
    "text": "like that so I'll talk about some of the technical problems we came up with around that and solutions we came up with for the problems and then we'll end",
    "start": "174239",
    "end": "180600"
  },
  {
    "text": "up with Q&A what's wrong apologize here",
    "start": "180600",
    "end": "186780"
  },
  {
    "text": "looks like flip forward about a hundred slides okay so my name is Michael voytovitch I've",
    "start": "186780",
    "end": "193560"
  },
  {
    "start": "189000",
    "end": "227000"
  },
  {
    "text": "been about 20 years in MIT now I'm a container solutions architect the cloud",
    "start": "193560",
    "end": "199019"
  },
  {
    "text": "ops I started off as a lamp stack developer this was when the P was with Perl and I've worked with extensions",
    "start": "199019",
    "end": "205440"
  },
  {
    "text": "Python Java nodejs I worked at large enterprises small startups throughout my career and anything in between and about",
    "start": "205440",
    "end": "212040"
  },
  {
    "text": "five six years ago I moved into more of a DevOps for all I supposed to developer had three years production experience",
    "start": "212040",
    "end": "218220"
  },
  {
    "text": "running the Google kubernetes engine and about one year's production experience with rke most of Google Cloud architects",
    "start": "218220",
    "end": "225810"
  },
  {
    "text": "certified professional so at cloud ops we recognized a DevOps unicorns of special sometimes they too need help",
    "start": "225810",
    "end": "232739"
  },
  {
    "text": "navigating ecosystems of projects and tools meet the DevOps the cloud ops DevOps unicorn back in 2016 this is what",
    "start": "232739",
    "end": "240269"
  },
  {
    "start": "239000",
    "end": "250000"
  },
  {
    "text": "the CNCs look like it's pretty simple you can pick out most technologies you can actually read it from the slide and",
    "start": "240269",
    "end": "245549"
  },
  {
    "text": "you could kind of figure out where to start if you needed to pick some technology but fast forward to 2018 and",
    "start": "245549",
    "end": "251670"
  },
  {
    "text": "how the cmcs community has expanded so this is awesome but also adds adds many layers of complexity when you're trying",
    "start": "251670",
    "end": "257880"
  },
  {
    "text": "to navigate the open source world too many to even read on the slide so this is where cloud apps can help",
    "start": "257880",
    "end": "265040"
  },
  {
    "start": "265000",
    "end": "307000"
  },
  {
    "text": "we are a kubernetes certified service provider and a kubernetes training partner we provide consulting training",
    "start": "265040",
    "end": "271340"
  },
  {
    "text": "and managed services for cloud native and DevOps practices from deployment we",
    "start": "271340",
    "end": "276440"
  },
  {
    "text": "could help with what we call it be PPA which is a DevOps platform and practice assessment where we look at your current",
    "start": "276440",
    "end": "282680"
  },
  {
    "text": "state versus desired state and how to attain it and we focus on the tech stack as well as the business value of the",
    "start": "282680",
    "end": "288380"
  },
  {
    "text": "DevOps processes and application platform we have a link right there you can reach out you can check out to see",
    "start": "288380",
    "end": "294830"
  },
  {
    "text": "if you read more about this procedure and read out if reach out to us if you need any help and we'll have some",
    "start": "294830",
    "end": "300140"
  },
  {
    "text": "contact information at the end of the talk so speaking of which let's take a look at how we help the customer with",
    "start": "300140",
    "end": "306170"
  },
  {
    "text": "their projects story so far we we",
    "start": "306170",
    "end": "311390"
  },
  {
    "start": "307000",
    "end": "353000"
  },
  {
    "text": "started working with a large European hospitality client they had many interconnected but independently",
    "start": "311390",
    "end": "319160"
  },
  {
    "text": "developed and managed applications so they migrated them from an AWS installation we basically took a single",
    "start": "319160",
    "end": "325070"
  },
  {
    "text": "one of their projects migrated from AWS which is kind of vanilla three-tier setup on virtual machines into",
    "start": "325070",
    "end": "332060"
  },
  {
    "text": "containers on the google kubernetes engine on google kubernetes google cloud platform",
    "start": "332060",
    "end": "337300"
  },
  {
    "text": "we also were able to leverage several other GCP specific resources except the object storage offerings cloud CDN load",
    "start": "337300",
    "end": "345200"
  },
  {
    "text": "balancers the Google container registry which is their version of docker registry and cloud SQL which is their",
    "start": "345200",
    "end": "351260"
  },
  {
    "text": "managed SQL offering so here's what our architecture look like when we migrated",
    "start": "351260",
    "end": "356810"
  },
  {
    "start": "353000",
    "end": "406000"
  },
  {
    "text": "everything into Google cloud platform essentially as a service entry point",
    "start": "356810",
    "end": "362690"
  },
  {
    "text": "which was a hardware base load balancer which can both serve content from our",
    "start": "362690",
    "end": "367730"
  },
  {
    "text": "CDN and can serve content from the actual application which is running in",
    "start": "367730",
    "end": "373310"
  },
  {
    "text": "fact kubernetes I'm going to talk more detail about the other components here as we get to how we migrate these into",
    "start": "373310",
    "end": "379940"
  },
  {
    "text": "an on-premises solution but I just wanted to give a picture about how this looks and so just to round it off we",
    "start": "379940",
    "end": "385580"
  },
  {
    "text": "have Redis for a profession task we have fluent D for a login container in Google",
    "start": "385580",
    "end": "390650"
  },
  {
    "text": "cloud platform fluent D actually logs into their stack driver infrastructure which is not a free offering as well so",
    "start": "390650",
    "end": "397010"
  },
  {
    "text": "what we decided to do was to be should we put a custom flinty container that log into a custom oak stack so we",
    "start": "397010",
    "end": "407389"
  },
  {
    "text": "completed this architecture about a year ago now is March 2018 we migrated the first component there we kind of fleshed",
    "start": "407389",
    "end": "413720"
  },
  {
    "text": "out all the woods a lot of work around building automation terraform ansible things like that but then we discovered",
    "start": "413720",
    "end": "419300"
  },
  {
    "text": "that the actions the client is European it turned out about three-quarters of customers are from the Russian",
    "start": "419300",
    "end": "424310"
  },
  {
    "text": "Federation and as such there are Russian data laws specifically one v 2f said that requires any customer data relating",
    "start": "424310",
    "end": "433010"
  },
  {
    "text": "to customer Russian customers actually risk to the hide in Russia I think this well so is the guaranteed kind of",
    "start": "433010",
    "end": "439130"
  },
  {
    "text": "operation in case they get disconnected from the internet kind of thing so we",
    "start": "439130",
    "end": "444229"
  },
  {
    "text": "need to find a provider that actually offered these ships available to us so",
    "start": "444229",
    "end": "450050"
  },
  {
    "text": "unfortunately as of this writing and oneness exchange in the last week or so there's no hyper cloud providers in",
    "start": "450050",
    "end": "455300"
  },
  {
    "text": "Russia so there's no Google cloud platform no AWS is no Azure so how is I",
    "start": "455300",
    "end": "461180"
  },
  {
    "text": "to make this work so we need an on-premises solution and the first thing we needed to do was to find a premises",
    "start": "461180",
    "end": "468010"
  },
  {
    "text": "so we spent a and I wasn't personally involved with this it was some my team members we have some Russian members on",
    "start": "468010",
    "end": "475669"
  },
  {
    "text": "in cloud ops and we have a lot of contacts internationally so we kind of use that to explore what was out there I",
    "start": "475669",
    "end": "482150"
  },
  {
    "text": "don't recall it we valued about five different providers a lot of them they vary greatly in quality and a lot of",
    "start": "482150",
    "end": "489260"
  },
  {
    "text": "them were also difficult to communicate with obviously the English Russian it's an issue but Gmail actually work very",
    "start": "489260",
    "end": "494960"
  },
  {
    "text": "well in that I mean some of them they disappeared too small didn't have enough capacity for us to actually became a",
    "start": "494960",
    "end": "501500"
  },
  {
    "text": "non-starter so we settled on a provider that was VMware based cloud director cloud director base VMware provider so",
    "start": "501500",
    "end": "509120"
  },
  {
    "text": "they have a full 1 5 2 F said compliant environment they had been care form",
    "start": "509120",
    "end": "514370"
  },
  {
    "text": "plugins but as we start experimenting with using our automations again for",
    "start": "514370",
    "end": "519409"
  },
  {
    "text": "that due to the geographic distance between where I am in Canada and the EPI",
    "start": "519409",
    "end": "524630"
  },
  {
    "text": "servers in Russia we would get kind of timeouts you know it wouldn't be able to",
    "start": "524630",
    "end": "530120"
  },
  {
    "text": "determine the state I was very very viable and as well I think that there was an interaction between the version",
    "start": "530120",
    "end": "536220"
  },
  {
    "text": "of VMware that they were using the provider was using and the version that the plug-in supported so our contacts what to",
    "start": "536220",
    "end": "544350"
  },
  {
    "text": "provide that they also pointed us to a kind of a third-party app terraform",
    "start": "544350",
    "end": "549660"
  },
  {
    "text": "provider and this one actually worked a lot better but one key thing that it was missing was being able to when you terraform a server to specify how many",
    "start": "549660",
    "end": "557700"
  },
  {
    "text": "CPU cores you want it so all that to say that we weren't really reliably able to",
    "start": "557700",
    "end": "563520"
  },
  {
    "text": "use a terraform provider to automate a lot of this work so we ended up having to actually do it the hard way what's my",
    "start": "563520",
    "end": "570090"
  },
  {
    "text": "apologize kind of sticking again sorry",
    "start": "570090",
    "end": "575730"
  },
  {
    "text": "about that all right so um so can use",
    "start": "575730",
    "end": "581070"
  },
  {
    "start": "578000",
    "end": "650000"
  },
  {
    "text": "terraform we basically end up saying okay well all of our hosts to work in two different flavors one with a 40",
    "start": "581070",
    "end": "586830"
  },
  {
    "text": "gigabyte root disk one within a 100 gigabyte root disk and some of them may have extra local disks local extra fees",
    "start": "586830",
    "end": "592830"
  },
  {
    "text": "and things like that so we decided okay let's just create a base image let's run our basic automations against it in",
    "start": "592830",
    "end": "598290"
  },
  {
    "text": "terms of securing the image secure the VM things like that and we'll use that to build out all of the infrastructure",
    "start": "598290",
    "end": "604350"
  },
  {
    "text": "very manual process but the more you got used to using the UI the easier became",
    "start": "604350",
    "end": "610500"
  },
  {
    "text": "to do well of course the UI itself which was kind of a funny story it's old version of cloud director it's based on",
    "start": "610500",
    "end": "617130"
  },
  {
    "text": "flash and best of all they recommended to use Internet Explorer so all the UI",
    "start": "617130",
    "end": "622140"
  },
  {
    "text": "features work and then the next four points or just exclamation marks you can imagine this was a lot of red flags for",
    "start": "622140",
    "end": "628740"
  },
  {
    "text": "me running it and it took me a long time to trust wanting to run their tool outside of anything other than kind of a",
    "start": "628740",
    "end": "635220"
  },
  {
    "text": "dedicated VM with a browser with flash on it in the end I've been running it",
    "start": "635220",
    "end": "640710"
  },
  {
    "text": "for about a year now and I haven't had any issues but if if my professional partner made 20 years of experience that",
    "start": "640710",
    "end": "646200"
  },
  {
    "text": "just throws up a lot of red flags so um",
    "start": "646200",
    "end": "652250"
  },
  {
    "start": "650000",
    "end": "725000"
  },
  {
    "text": "now we were able to vision all the VMS we were able to get to the next step",
    "start": "652250",
    "end": "660210"
  },
  {
    "text": "just--how which kubernetes distribution do we actually put on here and so given we couldn't use anything on premises",
    "start": "660210",
    "end": "665700"
  },
  {
    "text": "gke etc you could extend it we had to went to go with something that was completely a self-contained so we looked",
    "start": "665700",
    "end": "671910"
  },
  {
    "text": "at you spray initially thank you baby em and I've looked at these tools over the years as well I'm not a huge fan keeps",
    "start": "671910",
    "end": "678330"
  },
  {
    "text": "Freya fine takes too long to install it's a lot of like very complex",
    "start": "678330",
    "end": "683790"
  },
  {
    "text": "configurations complex Amata to configure and to run most of all is once you actually install your kubernetes",
    "start": "683790",
    "end": "690090"
  },
  {
    "text": "clusters operating them after the fact very difficult with these tools and fine things like adding nodes decommissioning",
    "start": "690090",
    "end": "696090"
  },
  {
    "text": "nodes upgrading components kubernetes it was just very poor experience and in my",
    "start": "696090",
    "end": "702870"
  },
  {
    "text": "opinion until recently as well i'm not sure if cube idiom has this or not there was no abilities through multi master",
    "start": "702870",
    "end": "709140"
  },
  {
    "text": "setups and i think that's something that's come in more recently of course if you want to do a production ready",
    "start": "709140",
    "end": "715130"
  },
  {
    "text": "kinetics installation you definitely want to have multi master set up to be able to deal with having proper HH setup",
    "start": "715130",
    "end": "723980"
  },
  {
    "text": "so enter rancher kubernetes engine all right sacraments engine to the rescue my opinion is the best custom",
    "start": "723980",
    "end": "730710"
  },
  {
    "start": "725000",
    "end": "776000"
  },
  {
    "text": "kubernetes restorer to date and i was convinced by this over several articles i read one of them i linked here which",
    "start": "730710",
    "end": "736020"
  },
  {
    "text": "is a trick fillet wrote a little blog article how they ended up with that they kind of came to the same conclusions",
    "start": "736020",
    "end": "741120"
  },
  {
    "text": "about sheep spraying - baby m and r ke and and they decided to use it for the same reasons I did so if you look at RT",
    "start": "741120",
    "end": "748800"
  },
  {
    "text": "all it requires in order to be able to install your kubernetes cluster is essentially just a physical vm or box",
    "start": "748800",
    "end": "756590"
  },
  {
    "text": "running docker preferably compatible with a kubernetes version you can",
    "start": "756590",
    "end": "762150"
  },
  {
    "text": "actually also run non compatible version just at your own risk on thing with an override SSH access with the password",
    "start": "762150",
    "end": "769440"
  },
  {
    "text": "list speed login that's pretty much it so how do you actually operate ranch",
    "start": "769440",
    "end": "778770"
  },
  {
    "start": "776000",
    "end": "861000"
  },
  {
    "text": "kubernetes engine a single configuration file yam will file specify your cluster",
    "start": "778770",
    "end": "784050"
  },
  {
    "text": "configuration a single go binary that actually manages RTE and that's pretty much it so you are K itself has a set of",
    "start": "784050",
    "end": "791340"
  },
  {
    "text": "commands that you run to operate install or decommission your cluster so the basic one is our ke up which sets up",
    "start": "791340",
    "end": "798720"
  },
  {
    "text": "initial it connects all the SSH tunnels it'll actually detect the state of your cluster so if you're filling a new",
    "start": "798720",
    "end": "804990"
  },
  {
    "text": "cluster it will actually start bootstrapping kubernetes so by doing this it actually runs kubernetes all",
    "start": "804990",
    "end": "811110"
  },
  {
    "text": "inside docker images these docker images come from Rancher itself and so the API server cubelet on all those things they",
    "start": "811110",
    "end": "817650"
  },
  {
    "text": "run in docker itself so it wraps a new cluster with with your desired configuration in under five minutes this",
    "start": "817650",
    "end": "824070"
  },
  {
    "text": "is probably dependent on how larger cluster is the cluster I'm I was dealing with here was three masters for worker",
    "start": "824070",
    "end": "830490"
  },
  {
    "text": "nodes so it installed in about five minutes and this multi master works out of the box iki CD is fully distributed I",
    "start": "830490",
    "end": "837630"
  },
  {
    "text": "chose three setups you want to do an odd multiple and once once you actually",
    "start": "837630",
    "end": "844200"
  },
  {
    "text": "provision the cluster the arc a binary exits and it actually outputs coop config client certificate that you can",
    "start": "844200",
    "end": "851310"
  },
  {
    "text": "then use to interact with your cluster so this is great this takes about five minutes the customizing the config file",
    "start": "851310",
    "end": "859080"
  },
  {
    "text": "all that stuff's very easy to do so let's take a look at a minimal rke",
    "start": "859080",
    "end": "864170"
  },
  {
    "start": "861000",
    "end": "1143000"
  },
  {
    "text": "configuration file and kind of the highlights of what the things you have to set are so at the very least you need",
    "start": "864170",
    "end": "869550"
  },
  {
    "text": "a single node and you can define the role of the node you cannot have it be a control plane eat your feed which is a",
    "start": "869550",
    "end": "875820"
  },
  {
    "text": "master or you can have it be a worker or you can have it to be any combination or all all of those all of the above most",
    "start": "875820",
    "end": "882810"
  },
  {
    "text": "important thing is you should have at least one and you define all the other nodes you need in there you could define",
    "start": "882810",
    "end": "888000"
  },
  {
    "text": "what your IP ranges for pods and for services so what your CIDR is for those",
    "start": "888000",
    "end": "893550"
  },
  {
    "text": "tend to use so since we're using a canal CNI in this case the add the addresses",
    "start": "893550",
    "end": "902040"
  },
  {
    "text": "you pick inside your cluster don't need to be routable outside of the cluster because they're what they call that encapsulated packet so you can just pick",
    "start": "902040",
    "end": "910800"
  },
  {
    "text": "any range in there that's reasonable I tend to pick something in the 10:43 just tend to pick the same thing every time I",
    "start": "910800",
    "end": "916500"
  },
  {
    "text": "use it every time I define a range in here and finally the cluster DNS server which is basically the service CIDR plus 11",
    "start": "916500",
    "end": "922530"
  },
  {
    "text": "addresses these are kind of standard kubernetes requirements",
    "start": "922530",
    "end": "928939"
  },
  {
    "text": "other interesting things for notes so reason the canal plugin as far as I know right now - now I think is the main",
    "start": "929299",
    "end": "934910"
  },
  {
    "text": "supported one I haven't actually tried different ones with rke but there may be there may be other implementations right",
    "start": "934910",
    "end": "940040"
  },
  {
    "text": "now Ord imagine from Farrell's C&I it's just a matter of kind of trying it out getting it to work you enable our back",
    "start": "940040",
    "end": "946579"
  },
  {
    "text": "you tell it to ignore the docker version so this happened especially recently if",
    "start": "946579",
    "end": "951949"
  },
  {
    "text": "you're if you're any kind of an assistant ministration space if your installed dock went to a team server you cannot get dr. 17 for it and I",
    "start": "951949",
    "end": "959660"
  },
  {
    "text": "believe dr. 17 was the last last hydration with kubernetes so you kind of have to install dr 18 and you have to",
    "start": "959660",
    "end": "965059"
  },
  {
    "text": "tell Artie to ignore that it's a non-certified version and then finally",
    "start": "965059",
    "end": "970220"
  },
  {
    "text": "you give it just a little name so operating the wrench kubernetes engine",
    "start": "970220",
    "end": "976369"
  },
  {
    "text": "cluster is really simple lifecycle management just it with the way they are ke binary works is just super",
    "start": "976369",
    "end": "981559"
  },
  {
    "text": "straightforward if you want to add a new node you simply go back to that mo and you add a another entry into the nodes",
    "start": "981559",
    "end": "988970"
  },
  {
    "text": "list and then you just run our k up again and it'll literally do what you think it so it'll add a new worker node",
    "start": "988970",
    "end": "995119"
  },
  {
    "text": "add a new control know add a new succeeding node all of those things will just work it does it in a",
    "start": "995119",
    "end": "1001600"
  },
  {
    "text": "non-destructive way a kind of a rolling restart decommission note same thing just remove them from from the cluster",
    "start": "1001600",
    "end": "1007480"
  },
  {
    "text": "llamó and run it again and they get decommissioned if you need to upgrade so one of the things I didn't illustrate in",
    "start": "1007480",
    "end": "1013059"
  },
  {
    "text": "the cluster yamo file here is you can there are a lot of other options that are not mentioned here we're just",
    "start": "1013059",
    "end": "1018189"
  },
  {
    "text": "defining the versions of each kubernetes component so the version of the cubelet the version of the API server etc I tend",
    "start": "1018189",
    "end": "1025899"
  },
  {
    "text": "to use a default version that rke supports but if you run into situation where a specific version is misbehaving",
    "start": "1025899",
    "end": "1033399"
  },
  {
    "text": "you can actually go in and override just that specific components let's say for the sake of discussion there's a bug in",
    "start": "1033399",
    "end": "1039730"
  },
  {
    "text": "the cube let you need to grab the next version of the image you can just go in and add that definition to cluster llamó",
    "start": "1039730",
    "end": "1045668"
  },
  {
    "text": "run rke up and it'll go install the new foreshore the cube look for you and then",
    "start": "1045669",
    "end": "1051279"
  },
  {
    "text": "finally if you want to do a complete upgrade of kubernetes upgrades say from 110 to 1 11 or 111 to 111 subversion you",
    "start": "1051279",
    "end": "1059380"
  },
  {
    "text": "just grab a new version of rke and you just run RKA up and it does it",
    "start": "1059380",
    "end": "1064540"
  },
  {
    "text": "the way you would expect it so when you're using a cloud provider like m KS",
    "start": "1064540",
    "end": "1070059"
  },
  {
    "text": "or GA or a K F the Amazon Google Microsoft versions the manage kubernetes",
    "start": "1070059",
    "end": "1077620"
  },
  {
    "text": "inflation is really elegantly they'll do you know the do rolling restarts rolling upgrades of all of them the arc a binary",
    "start": "1077620",
    "end": "1082990"
  },
  {
    "text": "attempts to do the same thing it basically marks a node is tainted it drains it from all work performs the",
    "start": "1082990",
    "end": "1088960"
  },
  {
    "text": "upgrade on paint it and then it gets back any workloads that it needs to run",
    "start": "1088960",
    "end": "1094000"
  },
  {
    "text": "and I notice this this is from running our case since kubernetes 1.9 up to now",
    "start": "1094000",
    "end": "1099280"
  },
  {
    "text": "which is one point eleven point six and when you do upgrades of of kubernetes",
    "start": "1099280",
    "end": "1104710"
  },
  {
    "text": "always make sure you do the in between updates don't don't do major updates because this can cause this is it's more",
    "start": "1104710",
    "end": "1110440"
  },
  {
    "text": "unknown and you can you can kind of screw up your installation that way so it's much better to go the in-between",
    "start": "1110440",
    "end": "1115750"
  },
  {
    "text": "path so 1.9 21.72 one point 11 and this I took an opportunity I was a cloud con this summer or this winter rather a cube",
    "start": "1115750",
    "end": "1122559"
  },
  {
    "text": "con rather and I talked to some RK engineers and I made sure that they gave",
    "start": "1122559",
    "end": "1127809"
  },
  {
    "text": "me proper information for all the stuff works frustrated okay so it's not quite",
    "start": "1127809",
    "end": "1144910"
  },
  {
    "start": "1143000",
    "end": "1172000"
  },
  {
    "text": "as simple so our K is really great for provisioning and operating an on-premises cluster but it's not a complete solution in itself notice nobly",
    "start": "1144910",
    "end": "1151990"
  },
  {
    "text": "what's missing is a storage provider a container storage interface to enable persistent volumes and persistent volume",
    "start": "1151990",
    "end": "1157450"
  },
  {
    "text": "claims and load balancer some other missing features that we're using from DCP like I mentioned was a Google",
    "start": "1157450",
    "end": "1162910"
  },
  {
    "text": "container registry object storage cloud CDN and cloud sequel so let's take a",
    "start": "1162910",
    "end": "1168250"
  },
  {
    "text": "look at how we solve each of these problems in order fix one the quickest",
    "start": "1168250",
    "end": "1174490"
  },
  {
    "start": "1172000",
    "end": "1219000"
  },
  {
    "text": "solution is is how to pull images from the Google container registry so one of",
    "start": "1174490",
    "end": "1179650"
  },
  {
    "text": "the artifacts so since the docker images themselves that we run for this workload they don't contain any customer data",
    "start": "1179650",
    "end": "1184929"
  },
  {
    "text": "there wasn't a legal need to store them in Russia so we decided to keep using our PCR repository and the way you can",
    "start": "1184929",
    "end": "1192820"
  },
  {
    "text": "actually pull from to CRS you had a special docker secret which contains as you can see there",
    "start": "1192820",
    "end": "1198660"
  },
  {
    "text": "which contains a service account key from GCP and you simply tell your",
    "start": "1198660",
    "end": "1204600"
  },
  {
    "text": "deployment to pull that to use that pull secret when it pulls it as long as that service account has been granted objects",
    "start": "1204600",
    "end": "1210300"
  },
  {
    "text": "store viewer permission inside your project that hosts your images this will",
    "start": "1210300",
    "end": "1215700"
  },
  {
    "text": "just work as expected cloud sequel on",
    "start": "1215700",
    "end": "1220920"
  },
  {
    "start": "1219000",
    "end": "1265000"
  },
  {
    "text": "Prem nothing really special to do here this is just install my sequel I was able to use the same Debian images we",
    "start": "1220920",
    "end": "1227520"
  },
  {
    "text": "use for the kubernetes cluster - docker that and we have some cloud ops managed",
    "start": "1227520",
    "end": "1233790"
  },
  {
    "text": "to ansible run books for configuring my sequel 5.7 so we essentially tend to do",
    "start": "1233790",
    "end": "1238860"
  },
  {
    "text": "a standard deployment of the single master or two slaves one is a real-time slave for doing reporting and failover",
    "start": "1238860",
    "end": "1246270"
  },
  {
    "text": "in case there's an issue and a delayed slaves which ships bin logs instantly but doesn't apply them for 30 days this",
    "start": "1246270",
    "end": "1252630"
  },
  {
    "text": "allows us to basically restore at a point in time even if there's replicated corruption for up to 30 days so fairly",
    "start": "1252630",
    "end": "1259110"
  },
  {
    "text": "straightforward this is not really cloud native or or anything else that the",
    "start": "1259110",
    "end": "1265560"
  },
  {
    "text": "object storage becomes more of an interesting problem so when I started the solutions about a year ago there",
    "start": "1265560",
    "end": "1272730"
  },
  {
    "text": "wasn't really anything else those production-ready specifically workers f-for on-premises that I was able to",
    "start": "1272730",
    "end": "1277740"
  },
  {
    "text": "find so we kind of I spoke with a couple other consultants that cloud ops and we decided well maybe we can use some",
    "start": "1277740",
    "end": "1284280"
  },
  {
    "text": "off-the-shelf technology to make this work so we decided to basically use cluster FS to provide objects towards",
    "start": "1284280",
    "end": "1289860"
  },
  {
    "text": "web functionality this was technology came out of Red Hat as well I believe and replicas actually replicated NFS",
    "start": "1289860",
    "end": "1295770"
  },
  {
    "text": "before you know either don't know it and but the idea here is that we could set up two ingress nodes to front all",
    "start": "1295770",
    "end": "1302400"
  },
  {
    "text": "traffic coming into the cluster and by the way I'll have a diagram about all this stuff a little bit later but you",
    "start": "1302400",
    "end": "1308970"
  },
  {
    "text": "said - of ingress knows to serve contents from the cluster itself and also just serve content from Gluster FS",
    "start": "1308970",
    "end": "1316110"
  },
  {
    "text": "so it serves as a reverse proxy and the fede",
    "start": "1316110",
    "end": "1320900"
  },
  {
    "text": "Michael you still there yeah sorry my headphones just turned off",
    "start": "1326600",
    "end": "1332480"
  },
  {
    "text": "yeah so each so each thing Gris note basically has a dedicated device breakfast tours by 100 gigs worth of",
    "start": "1334460",
    "end": "1341009"
  },
  {
    "text": "data any data that's written to one node gets replicated to the other and vice versa and it kind of gives us a",
    "start": "1341009",
    "end": "1346470"
  },
  {
    "text": "poor-man's CBN to be able to serve any kind of CDM asset so it doesn't matter",
    "start": "1346470",
    "end": "1352049"
  },
  {
    "text": "if the person come in zone one ingress no the other ingress no they're gonna they're gonna serve the same data then what we would do is we would take the",
    "start": "1352049",
    "end": "1357840"
  },
  {
    "text": "Gloucester FS volume mounted in Fatty's kubernetes worker node and this is where the application that we're running in",
    "start": "1357840",
    "end": "1364409"
  },
  {
    "text": "kubernetes could actually read and write asset for the CDM and then finally we",
    "start": "1364409",
    "end": "1370049"
  },
  {
    "text": "just mount that volume that was mounted on the worker node into each pod host",
    "start": "1370049",
    "end": "1375330"
  },
  {
    "text": "pass volume and and then this allows the the workload to basically write directly",
    "start": "1375330",
    "end": "1381179"
  },
  {
    "text": "to Gloucester air force this works fairly well you know we're not dealing with millions of hits per day of things",
    "start": "1381179",
    "end": "1388529"
  },
  {
    "text": "like that so for our use case that we needed it was more than adequate for kind of serving as an object storage in",
    "start": "1388529",
    "end": "1393570"
  },
  {
    "text": "the CDN for our Russian installation so  about reddit depending on which",
    "start": "1393570",
    "end": "1400409"
  },
  {
    "text": "flavor of Redis you use it it needs to use it nice to use persistent volume",
    "start": "1400409",
    "end": "1405690"
  },
  {
    "text": "claim for storing its data in a session cache so it's for anything so the application uses reticence recession",
    "start": "1405690",
    "end": "1412169"
  },
  {
    "text": "cache and initially since we didn't have any persistent volume claim ability we",
    "start": "1412169",
    "end": "1417269"
  },
  {
    "text": "temporarily just reconfigured the application to use SQL database with session Kasich's that of Redis but I",
    "start": "1417269",
    "end": "1422610"
  },
  {
    "text": "decided in December after having cleaned in action on cue con and rook kind of graduated to an incubating project to",
    "start": "1422610",
    "end": "1428840"
  },
  {
    "text": "experiment with that and use that for the PVC for the storage driver for",
    "start": "1428840",
    "end": "1434369"
  },
  {
    "text": "kubernetes so it's really straightforward to use I did spend a bunch of time playing with you know their Quick Start Guide and they're very",
    "start": "1434369",
    "end": "1440879"
  },
  {
    "text": "stocking tation things like that I find the quickest way to get started reliably was simply to use the helm repository it",
    "start": "1440879",
    "end": "1448320"
  },
  {
    "text": "sees the helm chart so if you add the helm repo to rook directly and then you install it that was the most reliable",
    "start": "1448320",
    "end": "1455639"
  },
  {
    "text": "way to get up to work so literally one command it takes a couple of minutes kind of bootstrap itself and",
    "start": "1455639",
    "end": "1461140"
  },
  {
    "text": "it's up and running so rook itself is is is is essentially a plug-in for",
    "start": "1461140",
    "end": "1467980"
  },
  {
    "text": "kubernetes such a container storage interface driver so it's loaded dynamically by kubernetes specifically",
    "start": "1467980",
    "end": "1473770"
  },
  {
    "text": "the cubelet that runs on each on each worker node so there's some extra",
    "start": "1473770",
    "end": "1479800"
  },
  {
    "text": "configuration that was required for rke to make this work and potentially just providing two extra",
    "start": "1479800",
    "end": "1485320"
  },
  {
    "text": "arguments into the into the cluster llamó file that points the cubelet to",
    "start": "1485320",
    "end": "1491410"
  },
  {
    "text": "the location where rook stores its ESI binaries and treats them as executive",
    "start": "1491410",
    "end": "1497980"
  },
  {
    "text": "well so that's just what these kind of these couple of configuration parameters use once I added that to the cluster",
    "start": "1497980",
    "end": "1503470"
  },
  {
    "text": "gamal I was able to run rke up again and then that literally patched the live cluster when is all done everything just",
    "start": "1503470",
    "end": "1509860"
  },
  {
    "text": "automatically restarted and it works so up until this point I've seen all the Archy or the component start up and kind",
    "start": "1509860",
    "end": "1516160"
  },
  {
    "text": "of crash and some of them weren't ready adding this everything just worked as expected almost instant so now we have a",
    "start": "1516160",
    "end": "1523960"
  },
  {
    "text": "rook cluster so rook rook operator rather so the rook operator operates a",
    "start": "1523960",
    "end": "1530410"
  },
  {
    "start": "1525000",
    "end": "1581000"
  },
  {
    "text": "chef cluster underneath the hook so we need underneath the hood so we needed to now configure SEF itself so what I",
    "start": "1530410",
    "end": "1536920"
  },
  {
    "text": "actually did was I cloned the rook git repository and there's some great example configurations to kind of get",
    "start": "1536920",
    "end": "1543550"
  },
  {
    "text": "you started there so I thought we're talking about all the vanilla examples and and but there's there's a lot more",
    "start": "1543550",
    "end": "1549400"
  },
  {
    "text": "obviously right and so what we decided to say it was each worker node we're gonna have a dedicated 100 gig a speed",
    "start": "1549400",
    "end": "1555190"
  },
  {
    "text": "brick and we're just gonna tell zeph to only use that brick for persistent data",
    "start": "1555190",
    "end": "1563080"
  },
  {
    "text": "so that's where you see this device filter SDB in there that was the only modification I had to make to to their",
    "start": "1563080",
    "end": "1569590"
  },
  {
    "text": "vanilla configuration so it's just ensure that that was the case then you're writing CTL create on it and then",
    "start": "1569590",
    "end": "1577030"
  },
  {
    "text": "that created a safe cluster as a result so now work up",
    "start": "1577030",
    "end": "1582700"
  },
  {
    "start": "1581000",
    "end": "1655000"
  },
  {
    "text": "right since F cluster with the designated storage bricks but finally to actually use those storage bricks we",
    "start": "1582700",
    "end": "1587980"
  },
  {
    "text": "have to create a storage class which is a kubernetes resource to actually tell installations that this is where you're",
    "start": "1587980",
    "end": "1594460"
  },
  {
    "text": "going to get your storage from rather than whatever the default storage is which in case of rke just does nothing so once again there's",
    "start": "1594460",
    "end": "1602650"
  },
  {
    "text": "a storage class IMO file from the rook forestry and I lose I use that verbatim to create the storage class so that'll",
    "start": "1602650",
    "end": "1610150"
  },
  {
    "text": "actually create a replica pool and block pool and a storage class I uses that",
    "start": "1610150",
    "end": "1616240"
  },
  {
    "text": "stuff block pool so it's kind of a couple of levels of abstraction or you have rook controls SEF SEF creates",
    "start": "1616240",
    "end": "1623140"
  },
  {
    "text": "blocks and blocks type of storage classes for the purpose of this example like I said I'm using vanilla",
    "start": "1623140",
    "end": "1630880"
  },
  {
    "text": "configuration so here you'll see very simple configs force F block pool replicated files one this just tells it",
    "start": "1630880",
    "end": "1637600"
  },
  {
    "text": "to use an object storage device replicated exactly once depending on your workload depending on your use cases depending on how",
    "start": "1637600",
    "end": "1643750"
  },
  {
    "text": "resilient you want your data to be how perform it you want it to be there's a ton of options and stuff for optimizing",
    "start": "1643750",
    "end": "1648940"
  },
  {
    "text": "those types of things but it's beyond the scope of this talk so now we have a",
    "start": "1648940",
    "end": "1656920"
  },
  {
    "text": "storage classical rooks F block and we can install ready from just scallops use that storage class so once again I'm a",
    "start": "1656920",
    "end": "1663700"
  },
  {
    "text": "fan of using helm it's just very simple to install a lot of complicated applications and most of them if they're",
    "start": "1663700",
    "end": "1670150"
  },
  {
    "text": "set up properly will actually have overrides for these types of settings so here you'll see an example where I'm",
    "start": "1670150",
    "end": "1675280"
  },
  {
    "text": "installing stable registration and I'm telling the master and the slave to use",
    "start": "1675280",
    "end": "1680560"
  },
  {
    "text": "a persistent storage class of rooks F blocks so when you run this it'll actually tell request storage from from",
    "start": "1680560",
    "end": "1687430"
  },
  {
    "text": "staff and from Brooke and use it you can also specify how large you want that to",
    "start": "1687430",
    "end": "1694630"
  },
  {
    "text": "be I think the default in this case is 5 gigs or something like that I guess 10 C's register as a session cache or",
    "start": "1694630",
    "end": "1701590"
  },
  {
    "text": "something like that you said you don't need some more you don't generally need larger blocks but if you do it's all settle using the help chart Oh once",
    "start": "1701590",
    "end": "1711430"
  },
  {
    "start": "1710000",
    "end": "1721000"
  },
  {
    "text": "again to teach you",
    "start": "1711430",
    "end": "1715890"
  },
  {
    "text": "I apologize this was really frustrated okay so so we talked about the PVC now",
    "start": "1717630",
    "end": "1727740"
  },
  {
    "start": "1721000",
    "end": "1838000"
  },
  {
    "text": "how about logging so I mentioned before fluency and salinity is also used when you run in google kubernetes engine",
    "start": "1727740",
    "end": "1733770"
  },
  {
    "text": "kubernetes engine has basically become the de-facto blog engaging Tsukuba dies it's another CNCs project so it's much",
    "start": "1733770",
    "end": "1739500"
  },
  {
    "text": "needed in the logging space currently I believe is implemented in Rudy and there's in Ruby there's a non dynamic",
    "start": "1739500",
    "end": "1745590"
  },
  {
    "text": "language agent in development called fluent bit I think is a roaster I don't",
    "start": "1745590",
    "end": "1750930"
  },
  {
    "text": "think all the features are there yet and no-one's releasing in production so I'll talk about the Ruby version as many",
    "start": "1750930",
    "end": "1756540"
  },
  {
    "text": "input plugins many output plugins which is why it's really so great and it's been under active development for for a",
    "start": "1756540",
    "end": "1762060"
  },
  {
    "text": "while what was a bit frustrating I think in the last year that maybe they got a lot of pickup in an adoption when they",
    "start": "1762060",
    "end": "1768960"
  },
  {
    "text": "went from the zero version to the one version to the one point one to the one point two I continuously got strange",
    "start": "1768960",
    "end": "1774870"
  },
  {
    "text": "kind of bugs that I had to deal with going in and fix when when I this is",
    "start": "1774870",
    "end": "1781620"
  },
  {
    "text": "another one of those best practices always pin the version numbers of stuff you're using what I ended up using in this case is just like a name tag called",
    "start": "1781620",
    "end": "1789630"
  },
  {
    "text": "elasticsearch and that would you know if the node rebooted or facility pod restarted I would just get the new",
    "start": "1789630",
    "end": "1795690"
  },
  {
    "text": "version of the new version would break so this is kind of a I should have known better and pinned it right right from",
    "start": "1795690",
    "end": "1801030"
  },
  {
    "text": "the start but these are kind of things to watch out for when you're dealing when you're dealing with on-premises",
    "start": "1801030",
    "end": "1806130"
  },
  {
    "text": "installations as well so what do we need from from our actual logging we need a comprehensive kubernetes monitoring",
    "start": "1806130",
    "end": "1811710"
  },
  {
    "text": "configuration so pull out getting visibility and tells kubernetes components themselves we want to have",
    "start": "1811710",
    "end": "1817410"
  },
  {
    "text": "some sort of same application log pardoning parsing out of the box so some some of our applications were java or no",
    "start": "1817410",
    "end": "1823350"
  },
  {
    "text": "js' they produce json structures in their logs so we needed we needed the",
    "start": "1823350",
    "end": "1829170"
  },
  {
    "text": "logging solution in this case to be able to unpack those put them in elasticsearch and make them searchable based on on those types of attributes",
    "start": "1829170",
    "end": "1837500"
  },
  {
    "start": "1838000",
    "end": "1935000"
  },
  {
    "text": "so the best flue in the image as I mentioned is currently this one called V one point one point three Debian",
    "start": "1838129",
    "end": "1843240"
  },
  {
    "text": "elasticsearch so it's based on a Debian based image and it has output thanks to",
    "start": "1843240",
    "end": "1848460"
  },
  {
    "text": "elastic search which is self-explanatory but if I found it to be the most stable and easy to use currently so one point",
    "start": "1848460",
    "end": "1855330"
  },
  {
    "text": "two point X had a dependency on a non-standard Debian library something with system D I think so when I was",
    "start": "1855330",
    "end": "1860580"
  },
  {
    "text": "running that the latest version by default it would the fluent the agent was causing massive load on my clusters",
    "start": "1860580",
    "end": "1865950"
  },
  {
    "text": "so Google for it and I found out that was the case I ended up kind of just reverting to the last major version was",
    "start": "1865950",
    "end": "1871679"
  },
  {
    "text": "just one one three but the out of the box JSON and JSON parting didn't seem to work in this version and I actually I",
    "start": "1871679",
    "end": "1878610"
  },
  {
    "text": "got a chance our our booths at cube con was right next to the fluent deep booth so I went and I picked on a couple of",
    "start": "1878610",
    "end": "1884820"
  },
  {
    "text": "the engineers they might have thought I came up as a bit of a lunatic because I wanted them to fix this in their images because nothing ever nothing ever seemed",
    "start": "1884820",
    "end": "1891809"
  },
  {
    "text": "to have come of it but I tried to I tried to make them understand what the problem was and like it was just it'd be",
    "start": "1891809",
    "end": "1897749"
  },
  {
    "text": "very nice as they would provide a bundle an image that just does everything out of the box without having to do is kind of custom patching and adding things to",
    "start": "1897749",
    "end": "1904440"
  },
  {
    "text": "my nose you can check that I'm sure they're going to get a better with time it's just I've just been dealing with",
    "start": "1904440",
    "end": "1910440"
  },
  {
    "text": "these version changes and they caused frustrations every time there was a major one and finally we need a way to",
    "start": "1910440",
    "end": "1916559"
  },
  {
    "text": "designate certain attributes in the JSON logging from our application as a numeric so this is important when you're",
    "start": "1916559",
    "end": "1922769"
  },
  {
    "text": "sending your logs into elasticsearch more efficient to search for those types strings versus numbers it's more",
    "start": "1922769",
    "end": "1929279"
  },
  {
    "text": "efficient as it knows what type of data you're searching for so this is",
    "start": "1929279",
    "end": "1937259"
  },
  {
    "text": "essentially what we started with so inside the fluent d-- image there's a kubernetes conf we just pull that out of",
    "start": "1937259",
    "end": "1942450"
  },
  {
    "text": "the image and we added this a bit of peace to it which is what I found from extensive googling and kind of renaming",
    "start": "1942450",
    "end": "1947909"
  },
  {
    "text": "the the JSON and JSON parsing so essentially what this configuration says for every line that comes in from the",
    "start": "1947909",
    "end": "1954299"
  },
  {
    "text": "the docker container of your application if it's a JSON if it's possible in JSON",
    "start": "1954299",
    "end": "1961519"
  },
  {
    "text": "parsing in JSON and additionally to that any attributes call the last time",
    "start": "1961519",
    "end": "1966720"
  },
  {
    "text": "treated as a float status code treated as an integer by percent treated as an integer and then you",
    "start": "1966720",
    "end": "1974789"
  },
  {
    "text": "simply take that entire file put its content into a config map and you can use it from the salinity agent I would",
    "start": "1974789",
    "end": "1980159"
  },
  {
    "text": "say it is a bit of a ramp up time learning how salinity works properly kind of grokking how the configurations",
    "start": "1980159",
    "end": "1986129"
  },
  {
    "text": "work but it just kind of comes with time they all said it makes sense one day so you simply take the contents of that",
    "start": "1986129",
    "end": "1991710"
  },
  {
    "text": "file stick it into a config map and then you can mount the config map into the",
    "start": "1991710",
    "end": "1996859"
  },
  {
    "text": "into the fluent D pod itself so some of you may not know this when you mount",
    "start": "1996859",
    "end": "2002179"
  },
  {
    "text": "files into a pod they can come from a config Matic and it can come from a physical volume but you can mount you",
    "start": "2002179",
    "end": "2010039"
  },
  {
    "text": "can mount us a specific file into a path whereas most people I think the most examples when you look at how to do the",
    "start": "2010039",
    "end": "2015350"
  },
  {
    "text": "secure entities they only showed how to mount an entire directory into a pod they don't you how to do a single file so all that to say is the example I have",
    "start": "2015350",
    "end": "2023059"
  },
  {
    "text": "here at the bottom where you mentioned subpaths kubernetes accounts that tells kubernetes to only mount in that one",
    "start": "2023059",
    "end": "2029690"
  },
  {
    "text": "single file and not anything else in that directory what would happen otherwise as fluent II would start up it would see that there's no other files",
    "start": "2029690",
    "end": "2035659"
  },
  {
    "text": "other than kubernetes confident crash this way we're providing a single override for kubernetes conch and and",
    "start": "2035659",
    "end": "2041419"
  },
  {
    "text": "fluent he just works happily ever after so as you do want to do a couple of kind",
    "start": "2041419",
    "end": "2048970"
  },
  {
    "start": "2045000",
    "end": "2138000"
  },
  {
    "text": "modifications to fluent to you when you start it up so the image has image comes with an example deployment yamo file we",
    "start": "2048970",
    "end": "2056358"
  },
  {
    "text": "as a set of environment variables you can override when you start cilenti most important one i think there is is a",
    "start": "2056359",
    "end": "2062388"
  },
  {
    "text": "logstash prefix so when when fluent descends data from this particular agent",
    "start": "2062389",
    "end": "2068030"
  },
  {
    "text": "into the Galactic search infrastructure it'll prefix the index with this value",
    "start": "2068030",
    "end": "2073339"
  },
  {
    "text": "here so one example you have and something actually use for a client is we have kind of a shared logging in",
    "start": "2073339",
    "end": "2080000"
  },
  {
    "text": "shard shared log in kubernetes cluster that receives fluent B data from other",
    "start": "2080000",
    "end": "2085638"
  },
  {
    "text": "clusters each other cluster has its own value for this they it's better index in elasticsearch and this better perform in",
    "start": "2085639",
    "end": "2092480"
  },
  {
    "text": "elastic source and then by default this this will roll once a day I think fluent e will actually add a date ym deke",
    "start": "2092480",
    "end": "2101359"
  },
  {
    "text": "to the to the to the index and that means it just rolls read a/c kind of don't have to worry as much about optimizing performance isn't",
    "start": "2101359",
    "end": "2111690"
  },
  {
    "text": "it and indexes and things like that one thing I probably won't talk about here is if any of you have worked with Altis there's a component called a",
    "start": "2111690",
    "end": "2118880"
  },
  {
    "text": "curator which can expire all data I to be on the top of talk of this",
    "start": "2118880",
    "end": "2124980"
  },
  {
    "text": "conversation but I just wanted to mention it because one day you know you're if you're just logging for a year",
    "start": "2124980",
    "end": "2130170"
  },
  {
    "text": "you may very well run out of logging space if you don't use that kind of component so I mention ELQ right so",
    "start": "2130170",
    "end": "2140910"
  },
  {
    "start": "2138000",
    "end": "2179000"
  },
  {
    "text": "initially we had a separate dedicated l cluster so we'd run three virtual machines for H a running a elasticsearch",
    "start": "2140910",
    "end": "2148290"
  },
  {
    "text": "cluster these were running ansible were play books that the cloud ops had",
    "start": "2148290",
    "end": "2153480"
  },
  {
    "text": "developed but we found this three notes just for H a but is very underutilized",
    "start": "2153480",
    "end": "2158820"
  },
  {
    "text": "over provisioned and I was really wondering what do we really need to have like kind of a dedicated cluster like",
    "start": "2158820",
    "end": "2164250"
  },
  {
    "text": "this could we not just add that compute that the L cluster used to the kubernetes cluster and then run ELQ",
    "start": "2164250",
    "end": "2170850"
  },
  {
    "text": "inside kubernetes well turns out we could there's a helmet art stable flash elastic back to let you do just that so",
    "start": "2170850",
    "end": "2179390"
  },
  {
    "text": "we wipe the L cluster we put fresh w-9 images to select the other worker nodes I added those three worker nodes to the",
    "start": "2179390",
    "end": "2187620"
  },
  {
    "text": "arc to our case cluster ammo file and then I ran our K up and a couple minutes later we had all those former work elk",
    "start": "2187620",
    "end": "2195690"
  },
  {
    "text": "dedicated worker nodes writing as kubernetes worker nodes i inside a kubernetes so now to actually install",
    "start": "2195690",
    "end": "2203370"
  },
  {
    "text": "the l card we wanted to give it a larger per system so in this case was gave it 50 gigs storage and we tilted to use the",
    "start": "2203370",
    "end": "2210930"
  },
  {
    "text": "rook storage class but we've created earlier I mentioned before you can so this chart is actually kind of a meta",
    "start": "2210930",
    "end": "2217350"
  },
  {
    "text": "chart that's made up of all the various elastic fact charts with the structure combined a truck for elastic search art",
    "start": "2217350",
    "end": "2222870"
  },
  {
    "text": "for log stash etc you can set all those configurations inside the helm install",
    "start": "2222870",
    "end": "2228240"
  },
  {
    "text": "command and you can enable and disable them so I didn't include them here I tend to disable",
    "start": "2228240",
    "end": "2233970"
  },
  {
    "text": "log stash locks - is a great front-end for something it doesn't talk directly to elasticsearch but in our case our",
    "start": "2233970",
    "end": "2240600"
  },
  {
    "text": "fluently agent sinks directly to elasticsearch we didn't actually need a front end for lots of that so we don't actually install that and then as well",
    "start": "2240600",
    "end": "2248070"
  },
  {
    "text": "the curator you can you can enable the curator here and then you have to go and configure how long it can be how often",
    "start": "2248070",
    "end": "2254580"
  },
  {
    "text": "should expire old old data from and so",
    "start": "2254580",
    "end": "2259710"
  },
  {
    "start": "2258000",
    "end": "2321000"
  },
  {
    "text": "unfortunately when you when you run an install the helm charge for elk and it's odd because I think the bug is still",
    "start": "2259710",
    "end": "2265650"
  },
  {
    "text": "there I had to fix it last week as well and this is there's a weird bug with kibana when you install it which it has",
    "start": "2265650",
    "end": "2271500"
  },
  {
    "text": "a hard-coded value for where it expects to find the elasticsearch endpoint so first-time installed you have to fix",
    "start": "2271500",
    "end": "2277560"
  },
  {
    "text": "this footprints always be the case I've been telling myself every week that won't you know one of these days I'll get some time to fix it and send the PR",
    "start": "2277560",
    "end": "2283650"
  },
  {
    "text": "I just haven't had the contest to it but it's pretty easy fix I just kind of keep it in mind you just edit the deployment",
    "start": "2283650",
    "end": "2290220"
  },
  {
    "text": "after you've installed it with helm and you point it to you could look up the tube GPL service for it so in this case",
    "start": "2290220",
    "end": "2296760"
  },
  {
    "text": "if you called inflation elk the service is called elk - elasticsearch that's client and so that now plugs in Caban up",
    "start": "2296760",
    "end": "2304860"
  },
  {
    "text": "to the elasticsearch backend and then you have to tell fluently just to point to point the flu and D agents to the",
    "start": "2304860",
    "end": "2312510"
  },
  {
    "text": "elasticsearch host which is also the same thing as the elasticsearch client so you literally put the same value inside excellent D configuration now for",
    "start": "2312510",
    "end": "2322320"
  },
  {
    "start": "2321000",
    "end": "2358000"
  },
  {
    "text": "actually accessing elk I discover ways to do it if you don't really want to",
    "start": "2322320",
    "end": "2328200"
  },
  {
    "text": "deal with setting up a separate ingress secure things like that the simplest one is to use cube CTL port forward just set",
    "start": "2328200",
    "end": "2334440"
  },
  {
    "text": "up a local tunnel into into the Cabana front end I you could also set up expose",
    "start": "2334440",
    "end": "2340440"
  },
  {
    "text": "it as a node port and a tour and additive engine X front end or what I'm going to show quickly is just adding it",
    "start": "2340440",
    "end": "2347670"
  },
  {
    "text": "as a kubernetes ingress resource with the username and password to secure it",
    "start": "2347670",
    "end": "2353700"
  },
  {
    "text": "let's make that kind of the most reliable installation so rke when you",
    "start": "2353700",
    "end": "2360120"
  },
  {
    "text": "install it does install the nginx ingress controller as the default ingress controller given it doesn't have any on cloud cloud controller features",
    "start": "2360120",
    "end": "2368100"
  },
  {
    "text": "so you have to use annotation to tell kubernetes to use the nginx controller and you have to secure",
    "start": "2368100",
    "end": "2373740"
  },
  {
    "text": "the services necessary so quick way to do that is you just run HP password and you give it a username",
    "start": "2373740",
    "end": "2379500"
  },
  {
    "text": "and a password there and it'll give you a string that you then can tell you can give to nginx which it will use to",
    "start": "2379500",
    "end": "2385349"
  },
  {
    "text": "actually secure your site so here's an example as I get that string I create a secret from it and then I I'll show you",
    "start": "2385349",
    "end": "2393690"
  },
  {
    "text": "how this actually how actually use it so you create a secret which contains the offspring and then you finally have to create a secret to contain the ssl",
    "start": "2393690",
    "end": "2400020"
  },
  {
    "text": "certificate in this case something to be aware of and if any of you have worked within risks already you'll notice the",
    "start": "2400020",
    "end": "2406920"
  },
  {
    "text": "certificate there has to contain the entire certificate authority chain as",
    "start": "2406920",
    "end": "2412079"
  },
  {
    "text": "well it has to be in in a certain order and i find certain cell providers",
    "start": "2412079",
    "end": "2417630"
  },
  {
    "text": "they'll send you those out of order like the fillion reverse or they'll send you like it's a bit weird sometimes so just take extra care to make sure that you",
    "start": "2417630",
    "end": "2423930"
  },
  {
    "text": "create the right certificate from the right order and then you want any errors so here's what you would actually the",
    "start": "2423930",
    "end": "2431069"
  },
  {
    "start": "2429000",
    "end": "2490000"
  },
  {
    "text": "ingress resource you would create to actually use this so the first thing is you tell any pre create annotation to",
    "start": "2431069",
    "end": "2436920"
  },
  {
    "text": "sell to use the nginx ingress class you give some meta information for nginx to when it asks for authentication for",
    "start": "2436920",
    "end": "2444359"
  },
  {
    "text": "someone actually using Cubana and they basically tell it I'm using an off type basic and pull that off from",
    "start": "2444359",
    "end": "2450420"
  },
  {
    "text": "the secret that we created in the previous slide and there's basically straightforward ingress rules here we",
    "start": "2450420",
    "end": "2456059"
  },
  {
    "text": "say okay I have ELQ about my Apps domain it's simply forward to my Cabana back",
    "start": "2456059",
    "end": "2462480"
  },
  {
    "text": "end and it's secured by this TLS secret one other thing I want to mention because I think this is pretty neat",
    "start": "2462480",
    "end": "2468599"
  },
  {
    "text": "especially coming from 3ke the DK ingress controller doesn't do automatic HTTP HTTP redirection which is",
    "start": "2468599",
    "end": "2475859"
  },
  {
    "text": "really really really frustrating but enging nginx controller does so there's",
    "start": "2475859",
    "end": "2480869"
  },
  {
    "text": "no extra annotations you need to kind of disable the HTTP redirect it'll just do it automatically with this type of",
    "start": "2480869",
    "end": "2487020"
  },
  {
    "text": "configuration which is nice so for whatever even the rest cloud provided if",
    "start": "2487020",
    "end": "2493140"
  },
  {
    "start": "2490000",
    "end": "2535000"
  },
  {
    "text": "not have the ability to assign a hardware load balancer to front the infrastructure it's frustrating so we",
    "start": "2493140",
    "end": "2498720"
  },
  {
    "text": "decided to basically just do a bit of a poor-man's load balancer which is to nginx ingress",
    "start": "2498720",
    "end": "2504180"
  },
  {
    "text": "notes are the same - I've been talking about all along round-robin VMs that resolves each nodes IP it's kind of a",
    "start": "2504180",
    "end": "2510180"
  },
  {
    "text": "poor man's load balancer so we basically have a reverse proxy for all the kubernetes traffic and then it serves",
    "start": "2510180",
    "end": "2516660"
  },
  {
    "text": "all the CDN traffic on another path most important to notice the accel termination is not done by the nginx",
    "start": "2516660",
    "end": "2522210"
  },
  {
    "text": "ingress they're actually done by the ingress controller in kubrick",
    "start": "2522210",
    "end": "2526940"
  },
  {
    "text": "you there Michael yeah we in platform B",
    "start": "2530410",
    "end": "2544970"
  },
  {
    "start": "2535000",
    "end": "2614000"
  },
  {
    "text": "the BNF used to load balance between two front ends if you have the blaster FS",
    "start": "2544970",
    "end": "2550520"
  },
  {
    "text": "server first CDN content she's running ELQ inside the kubernetes cluster when",
    "start": "2550520",
    "end": "2555980"
  },
  {
    "text": "the fluent be running sorry Michael I",
    "start": "2555980",
    "end": "2567530"
  },
  {
    "text": "can't hear you I don't know if it's everybody but I definitely can't hear you do you hear me now yes okay",
    "start": "2567530",
    "end": "2576430"
  },
  {
    "text": "nothing for like the last minute no I heard like kind of like garbled okay",
    "start": "2576430",
    "end": "2583000"
  },
  {
    "text": "well this was just to illustrate this kind of the end state and see where every single is and how everything is",
    "start": "2583000",
    "end": "2589130"
  },
  {
    "text": "made up of we also use data dog and in tanana as our monitoring agents so not",
    "start": "2589130",
    "end": "2595220"
  },
  {
    "text": "represented here there's actually data dog container also running as well these are pretty neat they offer extra insight",
    "start": "2595220",
    "end": "2601670"
  },
  {
    "text": "into running workloads if you're running JVM or something like that apologize and",
    "start": "2601670",
    "end": "2609890"
  },
  {
    "text": "that's the end of that happy unicorns and rainbows special thanks to Julia",
    "start": "2609890",
    "end": "2616760"
  },
  {
    "text": "Simon a senior property marketing manager cloud ops and Emma DeAngelis freelance are just artists they made my",
    "start": "2616760",
    "end": "2622490"
  },
  {
    "text": "presentation look like chicken scratch that you look professional and then just some more information",
    "start": "2622490",
    "end": "2628190"
  },
  {
    "text": "cloud ops key information you can reach double column so calm or send us email info card ops and there's rook and Artie",
    "start": "2628190",
    "end": "2634790"
  },
  {
    "text": "absolutely okay over to Janka wonderful well thank you so much for that great",
    "start": "2634790",
    "end": "2640520"
  },
  {
    "text": "presentation I appreciated the detail and now we have some time for questions",
    "start": "2640520",
    "end": "2645710"
  },
  {
    "text": "so let me look into our Q&A box so there's one open question here well -",
    "start": "2645710",
    "end": "2653300"
  },
  {
    "text": "now good yeah audience keep popping in your questions the more the merrier so I'll start with the first one valid",
    "start": "2653300",
    "end": "2659960"
  },
  {
    "text": "shari asks if my work notes all have access to NetApp's ash NFS should I still consider different",
    "start": "2659960",
    "end": "2667200"
  },
  {
    "text": "storage such as Southfork or we can just work with host volumes over NFS what do",
    "start": "2667200",
    "end": "2673470"
  },
  {
    "text": "you think Michael great question um if there's no extra cost for you to work in",
    "start": "2673470",
    "end": "2679680"
  },
  {
    "start": "2675000",
    "end": "2807000"
  },
  {
    "text": "that environment I think that's a great option for now I say this because while",
    "start": "2679680",
    "end": "2684840"
  },
  {
    "text": "I've been working with the rook for a couple of months now two or three months I feel it it's",
    "start": "2684840",
    "end": "2691380"
  },
  {
    "text": "production-ready but like not battle-hardened yet so you might say for very simple use cases use rook if you",
    "start": "2691380",
    "end": "2698760"
  },
  {
    "text": "have kind of complicated setup you can use your net file or touch you those",
    "start": "2698760",
    "end": "2704730"
  },
  {
    "text": "kinds of things I hope that kind of helps a little bit it's going to be very specific on the type of workload and the type of secure the type of reliability",
    "start": "2704730",
    "end": "2711330"
  },
  {
    "text": "you need but I would say it would probably be the right time to experiment with using real thing rook is a fine",
    "start": "2711330",
    "end": "2717750"
  },
  {
    "text": "strategic choice moving forward and I know that they're gonna get there this year with being fully kind of battle-hardened in production but for",
    "start": "2717750",
    "end": "2725820"
  },
  {
    "text": "your specific use case I would say experiment with it first before you start replacing the next filer stuff",
    "start": "2725820",
    "end": "2732600"
  },
  {
    "text": "thanks great so related to violets question John",
    "start": "2732600",
    "end": "2738450"
  },
  {
    "text": "dilly I hope I said that right has a question there are some others I had of the queue but since it's related and I'm",
    "start": "2738450",
    "end": "2743460"
  },
  {
    "text": "going with this first and we have plenty of time so he says why did you choose a rook for Redis maybe see not the",
    "start": "2743460",
    "end": "2750120"
  },
  {
    "text": "Gloucester FS you already had so there's",
    "start": "2750120",
    "end": "2756120"
  },
  {
    "text": "a there's a provisioning agent for Gloucester access code caddies and I had experiments experience with that through",
    "start": "2756120",
    "end": "2762480"
  },
  {
    "text": "no other project I was working on and it is very very very fragile way of orchestrating cluster facts",
    "start": "2762480",
    "end": "2769110"
  },
  {
    "text": "so essentially the problem with luster has I think it's a bit of a it's a fine replacement for NFS if that's all you're",
    "start": "2769110",
    "end": "2775140"
  },
  {
    "text": "using it for but free provisioning dynamic storage in kubernetes it's not so good except in my opinion France is",
    "start": "2775140",
    "end": "2781920"
  },
  {
    "text": "essentially like an iteration it's not the right word but a replacement for",
    "start": "2781920",
    "end": "2787440"
  },
  {
    "text": "that type of system designed to be more cloud native design to operate inside kubernetes and things like that so along",
    "start": "2787440",
    "end": "2794070"
  },
  {
    "text": "those lines jean-christophe coin kono again sorry folks I'm probably butchering everybody",
    "start": "2794070",
    "end": "2799830"
  },
  {
    "text": "of mine can you talk about using local storage in kubernetes versus s I mean",
    "start": "2799830",
    "end": "2810630"
  },
  {
    "start": "2807000",
    "end": "2893000"
  },
  {
    "text": "chef just gives you the ability to if your pod stops on one worker node and starts on another it has access to all",
    "start": "2810630",
    "end": "2816780"
  },
  {
    "text": "the data right the standard behavior you'd expect some persistent volume right whereas local data your you know if it",
    "start": "2816780",
    "end": "2822270"
  },
  {
    "text": "moves across nodes that's that's not going to work right obviously you can use things like affinities and selectors",
    "start": "2822270",
    "end": "2829380"
  },
  {
    "text": "to kind of pin we're close to certain locations and there may be use cases where the great thing about local",
    "start": "2829380",
    "end": "2834810"
  },
  {
    "text": "storage is that it's very performant you're just writing directly to local disk could be SSD what-have-you whereas s you're inherently networks and",
    "start": "2834810",
    "end": "2841560"
  },
  {
    "text": "you can throw in very high-performing Network hardware and things like that but you're probably not ever going to",
    "start": "2841560",
    "end": "2846570"
  },
  {
    "text": "get the kind of raw throughput as you would get and that so depends heavily on on on your use on the type of data right",
    "start": "2846570",
    "end": "2853380"
  },
  {
    "text": "you're doing I would say great thank you so then there is a question that's sort",
    "start": "2853380",
    "end": "2859380"
  },
  {
    "text": "of more meta john dilia asks regarding rke did you also look at salt how would you",
    "start": "2859380",
    "end": "2866280"
  },
  {
    "text": "compare our key in salt I have not heard of salt before I can't really say",
    "start": "2866280",
    "end": "2872070"
  },
  {
    "text": "anything about that sorry but I will now that it's on my radar I'm gonna read up on it yep totally yeah John feel free to",
    "start": "2872070",
    "end": "2878040"
  },
  {
    "text": "like post a link here if you have it I've never heard of salt either okay",
    "start": "2878040",
    "end": "2884340"
  },
  {
    "text": "next question oh this valid says salt is a",
    "start": "2884340",
    "end": "2889980"
  },
  {
    "text": "configuration management tool not kubernetes restaurant so it almost sounds like that's more of like a",
    "start": "2889980",
    "end": "2895380"
  },
  {
    "start": "2893000",
    "end": "2940000"
  },
  {
    "text": "comparing to say cube spray which is ansible based correlation Staller kind",
    "start": "2895380",
    "end": "2900510"
  },
  {
    "text": "of something similar if that's the case I would I would argue those types of installers kind of function on the wrong",
    "start": "2900510",
    "end": "2906870"
  },
  {
    "text": "paradigm I think like they're there what I really really like about our case for single binary there's a single path for",
    "start": "2906870",
    "end": "2912480"
  },
  {
    "text": "everything it it has more integrated control over what it's doing as opposed",
    "start": "2912480",
    "end": "2918240"
  },
  {
    "text": "to you know I don't want to talk crap about it but you know basically ansible scripts and things like that that's just",
    "start": "2918240",
    "end": "2924930"
  },
  {
    "text": "my completely uninformed opinion about what I know about yep and some people have added in info",
    "start": "2924930",
    "end": "2930360"
  },
  {
    "text": "about salt it's similar to ansible and puppet and john added a link so perhaps for this specific one you can take a",
    "start": "2930360",
    "end": "2936750"
  },
  {
    "text": "look afterwards um Michael yeah so maybe just add to that again the way that",
    "start": "2936750",
    "end": "2942510"
  },
  {
    "start": "2940000",
    "end": "2976000"
  },
  {
    "text": "these types of installers work you know they're over an SSH connection they're using Python I'm assuming in this case or what-have-you right but they actually",
    "start": "2942510",
    "end": "2948990"
  },
  {
    "text": "perform direct inflation's on the server which is really really cool about RK is that everything is docker images so",
    "start": "2948990",
    "end": "2954570"
  },
  {
    "text": "there's a lot less everything is completely self-contained in the RK installation you don't really have to worry about distribution flavor",
    "start": "2954570",
    "end": "2961140"
  },
  {
    "text": "differences things like that on your physical VM so yet more reasons why I think our case is much better choice in",
    "start": "2961140",
    "end": "2967260"
  },
  {
    "text": "my case okay so another question from Sascha segment where do you keep all the",
    "start": "2967260",
    "end": "2973860"
  },
  {
    "text": "config files so good question",
    "start": "2973860",
    "end": "2979320"
  },
  {
    "text": "so since I'm in DevOps I do store everything in get the source repositories but our cloud ops as a",
    "start": "2979320",
    "end": "2986100"
  },
  {
    "text": "company you know we're DevOps shop we're not actually doing the development of the products that I've talked about so in a previous life when I was working",
    "start": "2986100",
    "end": "2993690"
  },
  {
    "text": "when I was doing everything DevOps and development I tend to keep the source code together now we kind of have a",
    "start": "2993690",
    "end": "2999150"
  },
  {
    "text": "clear separate repository for the application source code and we have a separate repository for the DevOps code",
    "start": "2999150",
    "end": "3005900"
  },
  {
    "text": "but yeah I make an RT subdirectory that contain all the configurations I have special SSH configurations",
    "start": "3005900",
    "end": "3011810"
  },
  {
    "text": "because how I ain't access the physical nodes things like that but yeah I'm I",
    "start": "3011810",
    "end": "3017660"
  },
  {
    "text": "would group them together if I could but I can't so I keep it separate like that but I still keep it organized per project isn't it no one one thing to add",
    "start": "3017660",
    "end": "3025910"
  },
  {
    "text": "to that if there are you know if you're putting in say SSH keys or anything sensitive related obviously be careful",
    "start": "3025910",
    "end": "3031460"
  },
  {
    "text": "about storing that stuff and get mm-hmm cool valid shari asks should we go with",
    "start": "3031460",
    "end": "3039260"
  },
  {
    "text": "CRE - OH or is docker our our Java docker containers just fine",
    "start": "3039260",
    "end": "3045320"
  },
  {
    "text": "I know Rancher can support CRI - Oh correct and why not go with docker II uh",
    "start": "3045320",
    "end": "3050920"
  },
  {
    "start": "3050000",
    "end": "3090000"
  },
  {
    "text": "I don't really have an opinion on that I think I've used the vanilla",
    "start": "3050920",
    "end": "3056840"
  },
  {
    "text": "configuration which is excusing docker through a run fee yeah I like I started with kubernetes",
    "start": "3056840",
    "end": "3064800"
  },
  {
    "text": "from the early days where is all everything was docker so I'm just kind of maybe I'm too biased or sticking with that personal preference yeah I mean",
    "start": "3064800",
    "end": "3073110"
  },
  {
    "text": "there are technical reasons differences but I haven't come across one that matters to me fair enough no okay and",
    "start": "3073110",
    "end": "3080580"
  },
  {
    "text": "again while it asks does RTE use selinux I don't know these things",
    "start": "3080580",
    "end": "3086040"
  },
  {
    "text": "Celia Knox or ab bar more for security and isolation no so it runs like I said it's literally",
    "start": "3086040",
    "end": "3093060"
  },
  {
    "start": "3090000",
    "end": "3139000"
  },
  {
    "text": "running docker containers on the physical host so if that host if you want to run SELinux on that host you can",
    "start": "3093060",
    "end": "3098370"
  },
  {
    "text": "surely do that right or whatever flavor I other than that'd use a standard",
    "start": "3098370",
    "end": "3104400"
  },
  {
    "text": "kubernetes from docker security like everything that every kind of kubernetes pack has in isolation really nothing",
    "start": "3104400",
    "end": "3110400"
  },
  {
    "text": "special I'm not aware of any kind of direct integration with that see Linux is what I was trying to say cool all",
    "start": "3110400",
    "end": "3118260"
  },
  {
    "text": "right so those were the question oh wait there's something in chat let's see here - teacher okay so Alexey Smirnov says is",
    "start": "3118260",
    "end": "3127260"
  },
  {
    "text": "it possible to customize the fluent parser for specific pod / deployments or",
    "start": "3127260",
    "end": "3132870"
  },
  {
    "text": "is it local config only can it be configured to properly parse multi-line / sack dresses I know it can do",
    "start": "3132870",
    "end": "3140130"
  },
  {
    "start": "3139000",
    "end": "3225000"
  },
  {
    "text": "multi-line I've seen examples when I was hunting for for bugs with a specific",
    "start": "3140130",
    "end": "3146760"
  },
  {
    "text": "card deployment so find the slide again if you recall the slider where I had the",
    "start": "3146760",
    "end": "3153390"
  },
  {
    "text": "cabarets configuration the very first thing you specified kind of a pass for where fluid can find the logs that's a",
    "start": "3153390",
    "end": "3159600"
  },
  {
    "text": "typical ivara log container and then just a bunch of the wildcards in there right I think in theory those wild cards",
    "start": "3159600",
    "end": "3165870"
  },
  {
    "text": "today results like a UUID but I think they also resolved to like a pod name I'm like 80% sure of this application",
    "start": "3165870",
    "end": "3172740"
  },
  {
    "text": "I'm just trying to answer the best I can but in that case you might be able to provide a path to a I would say more",
    "start": "3172740",
    "end": "3178620"
  },
  {
    "text": "like like a stateful set or a deployment to basically apply that filter only on on on that particular parser I believe",
    "start": "3178620",
    "end": "3188340"
  },
  {
    "text": "also the configuration you can tell you can when you specify like a filter or",
    "start": "3188340",
    "end": "3193950"
  },
  {
    "text": "parse so it you can tell to look for certain things and if they're not there it's just not going to apply it right so in your use",
    "start": "3193950",
    "end": "3199500"
  },
  {
    "text": "case it would be specific because it wouldn't be parsing anything else yeah",
    "start": "3199500",
    "end": "3206660"
  },
  {
    "text": "cool one more question here from Sascha what is the volume sorry what is the log",
    "start": "3206660",
    "end": "3213960"
  },
  {
    "text": "volume in GB per day for fluent deep processes for you was high volume a",
    "start": "3213960",
    "end": "3220799"
  },
  {
    "text": "reason to go with su in D or was it just a nice centralizing machine for logging mostly nice centralized solution for",
    "start": "3220799",
    "end": "3226349"
  },
  {
    "start": "3225000",
    "end": "3295000"
  },
  {
    "text": "logging it's just that the ease of use getting it configuring and getting it running we don't do a lot of heavy like",
    "start": "3226349",
    "end": "3233010"
  },
  {
    "text": "gigabytes per day of logging it's just it was a nice way for us to route all the stuff into Elkin and everything like",
    "start": "3233010",
    "end": "3238079"
  },
  {
    "text": "that yeah I will say having if you do",
    "start": "3238079",
    "end": "3243299"
  },
  {
    "text": "have like heavy log writing requirements there's definitely some caveats of the stuff that I've shown so running ELQ",
    "start": "3243299",
    "end": "3248520"
  },
  {
    "text": "inside kubernetes you're dealing with the performance of the underlying CSI and things like that so that may not be",
    "start": "3248520",
    "end": "3254670"
  },
  {
    "text": "if you have a certain number of throughput requirements for logging that may not be sufficient but just just",
    "start": "3254670",
    "end": "3260789"
  },
  {
    "text": "specifically ease of use and it just happened to fit in my use case wonderful",
    "start": "3260789",
    "end": "3266450"
  },
  {
    "text": "cool all right well audience do you have any more questions we have a couple of minutes so",
    "start": "3266450",
    "end": "3274619"
  },
  {
    "text": "I see okay there's one more do you from Alexi do you think it's a good practice",
    "start": "3274619",
    "end": "3280710"
  },
  {
    "text": "to have separate EFL or elk for cluster logging and a separate one for application logging on or is that",
    "start": "3280710",
    "end": "3290760"
  },
  {
    "text": "unnecessary complexity for single single capital clusters so assuming performance",
    "start": "3290760",
    "end": "3297119"
  },
  {
    "start": "3295000",
    "end": "3382000"
  },
  {
    "text": "not necessary miss you right I like having everything in one spot because you can do queries that look at or or",
    "start": "3297119",
    "end": "3302640"
  },
  {
    "text": "dashboards that look at multiple you know you can look at your application performance and your VM performance in",
    "start": "3302640",
    "end": "3307890"
  },
  {
    "text": "the same spot as opposed to separating and also like the kubernetes related state I like that but depending again",
    "start": "3307890",
    "end": "3315510"
  },
  {
    "text": "depending on like how much logging you're doing and if it's have multiple sources that may be something that you",
    "start": "3315510",
    "end": "3321150"
  },
  {
    "text": "need to kind of shard on in my experience I've did that way 10 - Artemis card environment so I'll have a broad cluster I'll have a state across",
    "start": "3321150",
    "end": "3327539"
  },
  {
    "text": "my house you cluster etcetera but I tend to just using you know using different indexes",
    "start": "3327539",
    "end": "3333329"
  },
  {
    "text": "that go into elasticsearch just to add to keep keeping performance and and just",
    "start": "3333329",
    "end": "3339809"
  },
  {
    "text": "log it that way as opposed to having separate clusters for a system and for",
    "start": "3339809",
    "end": "3344970"
  },
  {
    "text": "apps that's just been the wave for CH initely had to I've had to work but if",
    "start": "3344970",
    "end": "3350309"
  },
  {
    "text": "you're dealing with very large and enterprise infrastructure something like that that might be a use case might not be something you can do sweet ok any so",
    "start": "3350309",
    "end": "3359700"
  },
  {
    "text": "we have two minutes left so time for one more question or comment I always welcome comments because people might",
    "start": "3359700",
    "end": "3366240"
  },
  {
    "text": "have something to add to the story so let's see here Q&A has something just Arun agarra asks just curious do you see",
    "start": "3366240",
    "end": "3373769"
  },
  {
    "text": "any difference between Splunk versus data table for metrics besides the cost oh good question I like this one so I",
    "start": "3373769",
    "end": "3381990"
  },
  {
    "text": "haven't seen data I haven't seen Blanc using about five six years so my opinion is based on what I knew it was back at",
    "start": "3381990",
    "end": "3388230"
  },
  {
    "start": "3382000",
    "end": "3454000"
  },
  {
    "text": "that point in time which was a very expensive great logging infrastructure is very expensive data dog it seems like",
    "start": "3388230",
    "end": "3395970"
  },
  {
    "text": "so I actually like I said maybe that's come down in price but what I know about data dog is that they have a lot of",
    "start": "3395970",
    "end": "3401069"
  },
  {
    "text": "plugins a lot of features that make it that make it very it makes it very intelligent and what it can actually log",
    "start": "3401069",
    "end": "3406759"
  },
  {
    "text": "detect in your system that you don't have to configure out of the box like it was that kind of stuff I found really",
    "start": "3406759",
    "end": "3412950"
  },
  {
    "text": "really powerful but if I didn't have to spend too much brainpower to actually configure them like I said I can't really talk about how far Splunk has",
    "start": "3412950",
    "end": "3419220"
  },
  {
    "text": "come so I'm not sure how their agent works them today very reasonable well alright well that's",
    "start": "3419220",
    "end": "3424950"
  },
  {
    "text": "all the time we have today for questions and comments and Thank You audience for",
    "start": "3424950",
    "end": "3430470"
  },
  {
    "text": "joining in sharing such good questions sharing your thoughts I think this is the whole point of the coup de Ciencias",
    "start": "3430470",
    "end": "3436650"
  },
  {
    "text": "webinar is for us to all exchange knowledge you did amazing Michael we all learned a lot thank you everyone for",
    "start": "3436650",
    "end": "3443130"
  },
  {
    "text": "joining today the webinar recording and slides will be online later and we look forward to seeing you at a future",
    "start": "3443130",
    "end": "3449279"
  },
  {
    "text": "ciencia webinar goodbye and have a good day or evening thanks everyone bye",
    "start": "3449279",
    "end": "3455660"
  }
]
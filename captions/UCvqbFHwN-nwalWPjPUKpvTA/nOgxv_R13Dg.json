[
  {
    "text": "my name is Kevin Clues this is my colleague Yuan Chen uh we're going to be talking today about which GPU sharing",
    "start": "120",
    "end": "5960"
  },
  {
    "text": "strategy is right for you uh with a comprehens comprehensive Benchmark study using Dr um so you know to kick things off why",
    "start": "5960",
    "end": "13920"
  },
  {
    "text": "do we even care about uh sharing gpus um well at the end of the day it's really about increasing the utilization",
    "start": "13920",
    "end": "20039"
  },
  {
    "text": "of the gpus that you have uh access to as well as decreasing the costs because the more efficient use of the gpus that",
    "start": "20039",
    "end": "25880"
  },
  {
    "text": "you have the fewer gpus that you need to get your work done and that then obviously leads to uh lower costs um",
    "start": "25880",
    "end": "33480"
  },
  {
    "text": "this has been a Hot Topic uh at lots of the past previous cucon over the years",
    "start": "33480",
    "end": "39800"
  },
  {
    "text": "um cucon Paris uh just last April uh there was five talks that were related",
    "start": "39800",
    "end": "45520"
  },
  {
    "text": "to GPU sharing in Chicago there was a couple um and then every cucon all the",
    "start": "45520",
    "end": "51079"
  },
  {
    "text": "way back through 2019 there's been some talk that had to do with how can I make more efficient use of my gpus using some",
    "start": "51079",
    "end": "57920"
  },
  {
    "text": "type of GPU sharing strategy um a couple of use cases for for GPU",
    "start": "57920",
    "end": "63720"
  },
  {
    "text": "sharing uh that are that are uh the most obvious ones um or if you have a single",
    "start": "63720",
    "end": "69360"
  },
  {
    "text": "user that wants to run multiple applications on top of some GPU uh if he's trying to do you know multiple",
    "start": "69360",
    "end": "75200"
  },
  {
    "text": "inference jobs uh for for testing um uh what the type of applications that he's",
    "start": "75200",
    "end": "80560"
  },
  {
    "text": "trying to run um you can also have a single tenant with multiple users so a couple of different users that want to",
    "start": "80560",
    "end": "86200"
  },
  {
    "text": "share access to a GPU because they're running jupyter notebooks they're trying to um you know build uh models that they",
    "start": "86200",
    "end": "92920"
  },
  {
    "text": "want to do for training but they don't have all the details worked out and so they just want to use a subset of a GPU to test things out before they run their",
    "start": "92920",
    "end": "99560"
  },
  {
    "text": "their full training job over potentially you know multiple gpus um and there's also use cases for things uh that are",
    "start": "99560",
    "end": "106799"
  },
  {
    "text": "more multi-tenant where you want to have multiple users running apps on top of a",
    "start": "106799",
    "end": "111880"
  },
  {
    "text": "single GPU in some kind of environment where uh that's appropriate for manage cloud services uh that need to be",
    "start": "111880",
    "end": "117880"
  },
  {
    "text": "multi-tenant um there's two primary methodologies for",
    "start": "117880",
    "end": "124479"
  },
  {
    "text": "for for doing uh GPU sharing sharing in general uh and that's Space versus time",
    "start": "124479",
    "end": "129720"
  },
  {
    "text": "partitioning um where space partitioning uh has the advantage that if you have",
    "start": "129720",
    "end": "134800"
  },
  {
    "text": "two workloads uh that you're trying to run um on top of a single GPU um both of",
    "start": "134800",
    "end": "140480"
  },
  {
    "text": "those workloads will be fully resident at all times because they share access to the GPU in space rather than time",
    "start": "140480",
    "end": "146280"
  },
  {
    "text": "there's no Contex switching overhead because they're always there and you get predictable performance from from these two",
    "start": "146280",
    "end": "152360"
  },
  {
    "text": "workloads um where the disadvantages are that you only get a subset of the G of the full GPU resources for each of those",
    "start": "152360",
    "end": "158920"
  },
  {
    "text": "workloads and you can have a limited number of clients that can make use of the GPU because as you try and pack more",
    "start": "158920",
    "end": "164800"
  },
  {
    "text": "and more on you eventually run out of resources that you can divide amongst the different",
    "start": "164800",
    "end": "169879"
  },
  {
    "text": "workloads um this is in contrast to time partitioning where um you know you the",
    "start": "169879",
    "end": "175200"
  },
  {
    "text": "advantages of this is that you have the full uh access to all the full set of resources that are available able on the",
    "start": "175200",
    "end": "180280"
  },
  {
    "text": "GPU and you can have an unlimited number of clients but the disadvantage is that only a resident each workload is only",
    "start": "180280",
    "end": "186519"
  },
  {
    "text": "resident on the GPU for a fraction of the time and there's some additional Contex switch overhead as you switch between the different workloads and this",
    "start": "186519",
    "end": "193640"
  },
  {
    "text": "leads to unpredictable uh unpredictable performance when you don't know exactly how many clients are there and you're",
    "start": "193640",
    "end": "198760"
  },
  {
    "text": "you know you're sharing um um access to the GPU in time so you know for example",
    "start": "198760",
    "end": "204519"
  },
  {
    "text": "I have workload one running here initially um I swap it off a few seconds later I have workload two running",
    "start": "204519",
    "end": "210480"
  },
  {
    "text": "that then switches back to workload one uh and then workload 2 makes his way back on at some point in the future um",
    "start": "210480",
    "end": "217239"
  },
  {
    "text": "what's interesting about this is that the advantages that you get from space partitioning are in direct contrast to",
    "start": "217239",
    "end": "222920"
  },
  {
    "text": "the disadvantages that you get for time partitioning and vice versa so you know",
    "start": "222920",
    "end": "228959"
  },
  {
    "text": "this really leads to a fundamental inherent trade-off in choosing one strategy of the other when do I want to",
    "start": "228959",
    "end": "234720"
  },
  {
    "text": "use space partitioning and when do I want to use time partitioning and when Yuan starts talking about some of the benchmarks that we ran at the end um",
    "start": "234720",
    "end": "241239"
  },
  {
    "text": "he'll highlight when you might want to use one strategy over another depending on the workload type that you",
    "start": "241239",
    "end": "247360"
  },
  {
    "text": "have um zooming in on Space partitioning in particular uh there's two types of",
    "start": "247360",
    "end": "252599"
  },
  {
    "text": "space partitioning that we provide for gpus one is Hardware partitioning uh through a method called multi-instance",
    "start": "252599",
    "end": "259079"
  },
  {
    "text": "GPU or or Mig for short where you have physical partitioning of of a full GPU",
    "start": "259079",
    "end": "264440"
  },
  {
    "text": "into a set of uh sort of mini gpus where you have full isolation between the",
    "start": "264440",
    "end": "270120"
  },
  {
    "text": "different workloads that you're going to run and in contrast to this there's um a",
    "start": "270120",
    "end": "275560"
  },
  {
    "text": "software-based uh space partitioning method that we have called multiprocess service or MPS for short which allows",
    "start": "275560",
    "end": "282400"
  },
  {
    "text": "you to do logical partitioning but you have limited isolation between the different workloads that you run if one",
    "start": "282400",
    "end": "287720"
  },
  {
    "text": "workload happens to to to crash for some reason it could bring down the other workloads under certain circumstances",
    "start": "287720",
    "end": "294039"
  },
  {
    "text": "and that's not possible with the hard the hardware partitioning that we have with Mig um so so yeah just highlighting some",
    "start": "294039",
    "end": "300759"
  },
  {
    "text": "of the advantages and disadvantage of this advantages of this molans and CPUs give you full fault isolation there's",
    "start": "300759",
    "end": "306759"
  },
  {
    "text": "some guaranteed memory uh bandwidth qos between the different instances you have running on each Mig device uh and it's",
    "start": "306759",
    "end": "312600"
  },
  {
    "text": "suitable for multi-tenant environments there's no no one can tamper with it with the workload running uh from one",
    "start": "312600",
    "end": "318240"
  },
  {
    "text": "Mig device to the another to to another um where the primary disadvantage of MiG is that you're really limited to a fixed",
    "start": "318240",
    "end": "324440"
  },
  {
    "text": "set of partition sizes um Mig as a technology only allows you to divide the",
    "start": "324440",
    "end": "329759"
  },
  {
    "text": "the gpus in a fixed set of ways um and you can't um subdivide it in in any in",
    "start": "329759",
    "end": "335800"
  },
  {
    "text": "any way other than that um in contrast multiprocess service or MPS uh has flexible partition sizes across multiple",
    "start": "335800",
    "end": "342520"
  },
  {
    "text": "Dimensions so you can decide what Li memory limits you want to set um independent of what uh compute limits",
    "start": "342520",
    "end": "348400"
  },
  {
    "text": "you want to set for any uh device that you slice up on the GPU um but the",
    "start": "348400",
    "end": "353880"
  },
  {
    "text": "disadvantage is that you have limited fault isolation there's no memory bandwidth qos and it's not really",
    "start": "353880",
    "end": "359199"
  },
  {
    "text": "suitable for multitenant environments which similar to the uh Space versus",
    "start": "359199",
    "end": "364360"
  },
  {
    "text": "time partitioning advantages and disadvantages that I showed before these are kind of in direct contrast to each",
    "start": "364360",
    "end": "369759"
  },
  {
    "text": "other so when do I choose space partitioning uh sorry when do I choose software based space partitioning versus",
    "start": "369759",
    "end": "375080"
  },
  {
    "text": "a hardware based partitioning is again something that Yuan will highlight uh when he works through the when he walks",
    "start": "375080",
    "end": "380319"
  },
  {
    "text": "through the benchmarks that we talked about at the end of the talk um so with these with the with the",
    "start": "380319",
    "end": "387240"
  },
  {
    "text": "different types of sharing strategy that are available on gpus you can actually layer them on top of one another um so",
    "start": "387240",
    "end": "392479"
  },
  {
    "text": "looking at the example I have here on the left you can imagine that you know in the base case you have two",
    "start": "392479",
    "end": "398080"
  },
  {
    "text": "applications each with dedicated access to their own uh their own GPU um um and",
    "start": "398080",
    "end": "404960"
  },
  {
    "text": "on top of this you could layer in the methodology of either time slicing or MPS so that you can Multiplex multiple",
    "start": "404960",
    "end": "410919"
  },
  {
    "text": "applications on top of those gpus similarly with Mig devices you can take a GPU you can subdivide it into",
    "start": "410919",
    "end": "417800"
  },
  {
    "text": "multiple Mig devices you can have one app running on each of those Mig devices and then you can layer time slicing your",
    "start": "417800",
    "end": "423599"
  },
  {
    "text": "MPS on top of that so you can actually Multiplex your application on top of a MIG device with either the space",
    "start": "423599",
    "end": "429039"
  },
  {
    "text": "partitioning or the time part uh time slicing uh methodology um there's also a technology",
    "start": "429039",
    "end": "436120"
  },
  {
    "text": "that uh that Nvidia provides called vgpus which looks like a full GPU um in",
    "start": "436120",
    "end": "442479"
  },
  {
    "text": "terms of how it time slies access to gpus but it's wrapping the GPU inside of a hypervisor at the VM layer so that you",
    "start": "442479",
    "end": "448720"
  },
  {
    "text": "get that extra level protection um that you wouldn't otherwise have if you were just running directly on a on what we",
    "start": "448720",
    "end": "454280"
  },
  {
    "text": "call a pass through GPU um and similarly you can have what's called a MIG Mig backed vgpu so you can",
    "start": "454280",
    "end": "461960"
  },
  {
    "text": "take a MIG device inside of a full GPU put a put wrap it in a in a vgpu inside",
    "start": "461960",
    "end": "467840"
  },
  {
    "text": "of a VM and then layer time slicing on top of that or NPS on top of that with a",
    "start": "467840",
    "end": "472879"
  },
  {
    "text": "set of applications that you want to run uh in that environment and then the fifth and final uh GPU sharing strategy",
    "start": "472879",
    "end": "480159"
  },
  {
    "text": "that we have is something called cuda streams uh which is something that exists at the application layer it's not",
    "start": "480159",
    "end": "485400"
  },
  {
    "text": "a system level uh sharing methodology like time slicing MP and mpsr but it's something that the application developer",
    "start": "485400",
    "end": "491280"
  },
  {
    "text": "has to actually take into account to make sure that he's properly sharing the the individual resources that are",
    "start": "491280",
    "end": "496599"
  },
  {
    "text": "available on a GPU so you can run multiple kernels in parallel um if you heard me talk about",
    "start": "496599",
    "end": "502560"
  },
  {
    "text": "in the past uh GPU sharing strategies these are the five that I always highlight um but we're only going to focus on the top three today mostly",
    "start": "502560",
    "end": "509720"
  },
  {
    "text": "because virtual gpus um vgpus are something that you kind of decide a",
    "start": "509720",
    "end": "514800"
  },
  {
    "text": "priori whether you want to use in your system or not likewise with Cuda streams it's something that an application",
    "start": "514800",
    "end": "520479"
  },
  {
    "text": "developer will decide if their application has or not if they haven't implemented that it's not available to",
    "start": "520479",
    "end": "525760"
  },
  {
    "text": "you and so these are the three dimensions at least in the context of kubernetes that you can really play around with to decide you know I have an",
    "start": "525760",
    "end": "532040"
  },
  {
    "text": "application I want to run do I want it set up with time slicing Mig or MPS and we're going to kind of show you how you",
    "start": "532040",
    "end": "538079"
  },
  {
    "text": "can make use of these and layer them on on top of each other in different ways based on the workload demands that that you",
    "start": "538079",
    "end": "543880"
  },
  {
    "text": "have um so before I go into you know the Dr the dynamic resource allocation aspects of this I just want to show how",
    "start": "543880",
    "end": "550440"
  },
  {
    "text": "really quickly How We Do GPU sharing in uh with these different methods in kubernetes",
    "start": "550440",
    "end": "555680"
  },
  {
    "text": "today um so what you see here on the left is uh a podspec that's requesting",
    "start": "555680",
    "end": "562440"
  },
  {
    "text": "access to a single GPU using the extended resource type of nvidia.com",
    "start": "562440",
    "end": "567519"
  },
  {
    "text": "GPU um and you do that you know the the picture on the right we've got a couple of components that kick into gear to",
    "start": "567519",
    "end": "573800"
  },
  {
    "text": "make sure that the the your request for that GPU eventually makes its way into the container that you run with your pod",
    "start": "573800",
    "end": "580079"
  },
  {
    "text": "um in addition to that you can um use labels that get applied by a component we have called GPU feature Discovery to",
    "start": "580079",
    "end": "586839"
  },
  {
    "text": "allow you to um um specify a specific type of GPU that you want your pod to",
    "start": "586839",
    "end": "593959"
  },
  {
    "text": "land on and as long as a GPU is available on a specific node that matches those labels your pod will be",
    "start": "593959",
    "end": "599959"
  },
  {
    "text": "directed There rather than to a uh a different node um likewise we have a the ability",
    "start": "599959",
    "end": "607120"
  },
  {
    "text": "to uh oversubscribe gpus such that time slicing will um kick in and allow you to",
    "start": "607120",
    "end": "613600"
  },
  {
    "text": "make you know to to share workloads on top of a GPU using uh using time slicing",
    "start": "613600",
    "end": "619760"
  },
  {
    "text": "um and this is done on a per node basis using a config like you see here on the right so um you would apply this config",
    "start": "619760",
    "end": "626440"
  },
  {
    "text": "on your node saying that all the gpus on that node that are exposed using the nvidia.com GPU resource type um should",
    "start": "626440",
    "end": "633880"
  },
  {
    "text": "be divided into three pieces such that three separate uh contexts can be over subscribed Cuda context can be",
    "start": "633880",
    "end": "639959"
  },
  {
    "text": "oversubscribed on top of that and the way that you request access to a resource that's been divided up this way",
    "start": "639959",
    "end": "645399"
  },
  {
    "text": "is by um using kind of the extended uh extended extended resource",
    "start": "645399",
    "end": "652160"
  },
  {
    "text": "type of nvidia.com GPU we we append this do shared uh name on top of that to make",
    "start": "652160",
    "end": "657560"
  },
  {
    "text": "sure that you land on a node that's been divided up using um one of the time time slicing or MPS methods um which is what",
    "start": "657560",
    "end": "664639"
  },
  {
    "text": "I show here so you know if this is what it looks like to have a config to allow you to create a set of uh replicas for",
    "start": "664639",
    "end": "670959"
  },
  {
    "text": "time slicing similarly we do the same thing with with with MPS so if you have.com GPU replicas 3 that basically",
    "start": "670959",
    "end": "677839"
  },
  {
    "text": "says all the gpus that I have on the machine I want to space partition into",
    "start": "677839",
    "end": "683200"
  },
  {
    "text": "um you know three uh three identically sized um pieces that are consuming a",
    "start": "683200",
    "end": "690560"
  },
  {
    "text": "third of the resources on the GPU um Mig uh is has has a similar um",
    "start": "690560",
    "end": "698920"
  },
  {
    "text": "Syntax for you to request access to it so what I'm showing here on the left is that if you want access to a 1G 5gb",
    "start": "698920",
    "end": "704560"
  },
  {
    "text": "device uh you would you would put this in your limits rather than nvidia.com GPU and then you get access to this this",
    "start": "704560",
    "end": "711120"
  },
  {
    "text": "exact size of uh a MIG slice that you want access to um and similarly if you",
    "start": "711120",
    "end": "716800"
  },
  {
    "text": "layer time slicing on top of it you use the DOT shared um extension to to get",
    "start": "716800",
    "end": "722120"
  },
  {
    "text": "access to a Time sliced um make device similarly with",
    "start": "722120",
    "end": "728720"
  },
  {
    "text": "MPS um there's a couple limitations that I want to highlight with this um first is that there's no control over how time",
    "start": "728720",
    "end": "735000"
  },
  {
    "text": "slice gpus get shared between jobs this is all kind of behind the scenes managed by Between the device plug-in and the",
    "start": "735000",
    "end": "740839"
  },
  {
    "text": "kuet you as the user don't know which GPU you're going to be run on relative",
    "start": "740839",
    "end": "746279"
  },
  {
    "text": "to other jobs that are in the system that's completely up to the kuet to decide um there's also no control over",
    "start": "746279",
    "end": "751760"
  },
  {
    "text": "how MPS partition gpus get shared between jobs just like with the time sliced ones um and there's no ability to",
    "start": "751760",
    "end": "757360"
  },
  {
    "text": "precisely control what fraction of a GPU gets handed out per job that's done via",
    "start": "757360",
    "end": "762839"
  },
  {
    "text": "a config file at the node level um without control from from the end user",
    "start": "762839",
    "end": "768880"
  },
  {
    "text": "and there's also no ability to dynamically provision make devices based on incoming requests that has to all be kind of set up a",
    "start": "768880",
    "end": "775040"
  },
  {
    "text": "priori um now there have been some systems that try to overcome this this notion of the ability to precisely",
    "start": "775040",
    "end": "781199"
  },
  {
    "text": "control fractions of gpus handed out per job and I just want to highlight them uh very quickly here run AI volcano and",
    "start": "781199",
    "end": "787480"
  },
  {
    "text": "Hami um the the disadvantage here though is that they're still limited to this um",
    "start": "787480",
    "end": "793120"
  },
  {
    "text": "you know uh extended resource model and there has to be a custom scheduler component that allows them to schedule",
    "start": "793120",
    "end": "799720"
  },
  {
    "text": "Things based on the resource requests that are coming in it's not something you can use out of the box uh for any",
    "start": "799720",
    "end": "805079"
  },
  {
    "text": "type of pod that gets launched on the system so what is GP sharing with you Dr look like um you know Dr itself is a new",
    "start": "805079",
    "end": "812279"
  },
  {
    "text": "way of requesting resources that have been available since kubernetes 126 but it's graduating de beta in the upcoming",
    "start": "812279",
    "end": "818120"
  },
  {
    "text": "132 release we announced this earlier this week at cucon it was public knowledge because the pr anyone could",
    "start": "818120",
    "end": "824440"
  },
  {
    "text": "look at the pr to see that it was merged but it's the first time we kind of spoke publicly about it was just the other day",
    "start": "824440",
    "end": "829760"
  },
  {
    "text": "um and some of the key concepts with this is that of a device class and a resource claim which I'll show in some of the examples coming up here um so if",
    "start": "829760",
    "end": "837680"
  },
  {
    "text": "you have an application uh similar to what I showed before with dedicated gpus nvidia.com",
    "start": "837680",
    "end": "843440"
  },
  {
    "text": "gpu2 what does this look like in the in the Dr World well the first thing you do",
    "start": "843440",
    "end": "848560"
  },
  {
    "text": "is you create something called a resource claim or a resource claim template which is just a way to define",
    "start": "848560",
    "end": "854199"
  },
  {
    "text": "what uh a resource claim could be generated from um if you have a controller that's capable of doing that",
    "start": "854199",
    "end": "860000"
  },
  {
    "text": "and you associate uh this resource claim with a specific device class in this case the GPU nvidia.com device class",
    "start": "860000",
    "end": "866199"
  },
  {
    "text": "which which will be installed by the Dr driver that um you've deployed to govern a set",
    "start": "866199",
    "end": "872199"
  },
  {
    "text": "of devices on your cluster um and then in addition to that you create your pod and you have a new",
    "start": "872199",
    "end": "878240"
  },
  {
    "text": "section at the bottom called resource claims which point to that uh resource claim template and it's important that",
    "start": "878240",
    "end": "883800"
  },
  {
    "text": "it's a template here because every reference to this template will create a unique resource claim behind the scenes",
    "start": "883800",
    "end": "889519"
  },
  {
    "text": "with its own unique uh GPU mapped to that and once you have reference to both of those then you create a local name",
    "start": "889519",
    "end": "895279"
  },
  {
    "text": "and you reference that back in your container and so you know this whole thing looks a bit more complicated and you wouldn't want to necessarily use",
    "start": "895279",
    "end": "901079"
  },
  {
    "text": "this if this was the only thing that you wanted to do with it was just get access to two gpus but what this allows you to",
    "start": "901079",
    "end": "907199"
  },
  {
    "text": "now do is in in the case of GPU sharing is that if instead of having nvidia.com GPU shared one uh for two different",
    "start": "907199",
    "end": "915000"
  },
  {
    "text": "containers in the same pod you can now have this one resource claim uh you reference that down in your resource",
    "start": "915000",
    "end": "920839"
  },
  {
    "text": "claim section of your pod give it a local name and now you control exactly how that GPU gets shared between two",
    "start": "920839",
    "end": "927320"
  },
  {
    "text": "different containers and this can be extended to multiple pods you create a resource claim you",
    "start": "927320",
    "end": "933800"
  },
  {
    "text": "reference that in two different pods and the container that's within that pod has access to that same underlying GPU and",
    "start": "933800",
    "end": "939759"
  },
  {
    "text": "it's controlled by you as the user rather than being left up to the system um to decide how it wanted to do the GPU",
    "start": "939759",
    "end": "945800"
  },
  {
    "text": "sharing across different G gpus that it had access to um in terms of time",
    "start": "945800",
    "end": "951680"
  },
  {
    "text": "slicing versus MPS you know in in in in the existing device plug-in model you",
    "start": "951680",
    "end": "957040"
  },
  {
    "text": "have a per node config that needs to be set up up in the Dr world you can have",
    "start": "957040",
    "end": "962440"
  },
  {
    "text": "uh a per resource claim config that gets set up such that when you have a GPU",
    "start": "962440",
    "end": "967759"
  },
  {
    "text": "that gets bound to this claim that you've requested you can say whether you want time slicing set up for that or MPS",
    "start": "967759",
    "end": "973519"
  },
  {
    "text": "set up for that with the limits that you want um so it's not left up to the system anymore you can precisely control",
    "start": "973519",
    "end": "979079"
  },
  {
    "text": "how you want these things to be shared um and this layers on top of M so you know in the in the previous examples",
    "start": "979079",
    "end": "985519"
  },
  {
    "text": "I was talking about full gpus but if you want to instead request access to a MIG device you can have this config that",
    "start": "985519",
    "end": "991759"
  },
  {
    "text": "sets up time slicing on top of that uh or MPS on top of that Mig",
    "start": "991759",
    "end": "997600"
  },
  {
    "text": "device uh and with that introduction I'll hand things over to Yan who will talk about the Benchmark study that we",
    "start": "997600",
    "end": "1003120"
  },
  {
    "text": "did based on all of this okay can you hear me uh thanks for Kevin to Kevin for",
    "start": "1003120",
    "end": "1008680"
  },
  {
    "text": "the excellent overview and introduction of Di and the GPU strategy next I will",
    "start": "1008680",
    "end": "1014759"
  },
  {
    "text": "share some key results and observations from uh Benchmark study on different the",
    "start": "1014759",
    "end": "1021600"
  },
  {
    "text": "GPU sharing strategy using Dr so we look at a different type of",
    "start": "1021600",
    "end": "1026678"
  },
  {
    "text": "workload from the inference workload to small GPU bat job to GPU intensive bat",
    "start": "1026679",
    "end": "1032280"
  },
  {
    "text": "job using time slicing MPS Without Limits and with limits and also",
    "start": "1032280",
    "end": "1037959"
  },
  {
    "text": "me so first thing let's look at the inference workload here is our setup we use the",
    "start": "1037959",
    "end": "1044720"
  },
  {
    "text": "Nvidia the Triton and the inference server and create two instance uh the client we use a tool called the",
    "start": "1044720",
    "end": "1053039"
  },
  {
    "text": "performance an analyzer can generate the different request at a different rate we control like the request rate to",
    "start": "1053039",
    "end": "1060080"
  },
  {
    "text": "simulate the the the uh Demand on the inference",
    "start": "1060080",
    "end": "1065799"
  },
  {
    "text": "server so like Kevin show early so this examples the resource claim as you can",
    "start": "1065799",
    "end": "1071559"
  },
  {
    "text": "see we Define resource claim then you can specify the sharing and the strategy",
    "start": "1071559",
    "end": "1076720"
  },
  {
    "text": "in your Port spec you reference the Source claim so we look at the time slicing we look at NPS and uh this is",
    "start": "1076720",
    "end": "1085679"
  },
  {
    "text": "NPS with the resource and the limits uh so this you and use the application and",
    "start": "1085679",
    "end": "1092280"
  },
  {
    "text": "environment variable to limit the compute and memory resources so okay",
    "start": "1092280",
    "end": "1099120"
  },
  {
    "text": "this is first set of the results and it's no request rate and like kned and",
    "start": "1099120",
    "end": "1104840"
  },
  {
    "text": "noed and the inference server so we look at this and the lat throughput performance and also GPU utilization the",
    "start": "1104840",
    "end": "1112600"
  },
  {
    "text": "yob bar is the dedicated use the uh single GPU without sharing and the",
    "start": "1112600",
    "end": "1118360"
  },
  {
    "text": "orange bar is two instance and inference server sharing the GPU as you can see",
    "start": "1118360",
    "end": "1125039"
  },
  {
    "text": "for the night noted inference F by sharing the GPU improve the utilization",
    "start": "1125039",
    "end": "1130480"
  },
  {
    "text": "without hurting the performance and one thing and uh Beware and please know that",
    "start": "1130480",
    "end": "1135840"
  },
  {
    "text": "is by running and two and in actually the GPU and the usage are not",
    "start": "1135840",
    "end": "1142640"
  },
  {
    "text": "and the doubl is tribl right and on the paper the optimal should just 20% so",
    "start": "1142640",
    "end": "1148919"
  },
  {
    "text": "that is from the context overhead uh the time slicing so that's something the we",
    "start": "1148919",
    "end": "1154480"
  },
  {
    "text": "have to be aware uh so if we look at that use the MTS so we got a similar",
    "start": "1154480",
    "end": "1160280"
  },
  {
    "text": "results right without hurting the performance and uh improve the utilization also autom and just double",
    "start": "1160280",
    "end": "1168120"
  },
  {
    "text": "the CP GPU usage so the MPS have much no and resource and uh overhead uh but",
    "start": "1168120",
    "end": "1176240"
  },
  {
    "text": "because it's software partition memory it can only offer a limited and thought",
    "start": "1176240",
    "end": "1181360"
  },
  {
    "text": "and isolation also we notice that the stop time of this and the TR inference",
    "start": "1181360",
    "end": "1186400"
  },
  {
    "text": "server and took longer time than the time slicing also you probably noticed",
    "start": "1186400",
    "end": "1191480"
  },
  {
    "text": "for NPS there additional and uh demo said wrongly but the footprint and is",
    "start": "1191480",
    "end": "1196760"
  },
  {
    "text": "very low just 20 meg by memory and so next we look at a heavy Lo inference",
    "start": "1196760",
    "end": "1202919"
  },
  {
    "text": "server so for this one the the client send and quite High request and the rate",
    "start": "1202919",
    "end": "1208600"
  },
  {
    "text": "to the server as you can see the time slicing that this and the resource contention there the performance",
    "start": "1208600",
    "end": "1215159"
  },
  {
    "text": "decreation we got the higher latency and no throughput the GPU is 100%",
    "start": "1215159",
    "end": "1221280"
  },
  {
    "text": "usage if we look at the MPS without resource limits yeah the performance",
    "start": "1221280",
    "end": "1227039"
  },
  {
    "text": "also in the yeah got worse but uh the performance decreation and uh yeah is",
    "start": "1227039",
    "end": "1233080"
  },
  {
    "text": "much less than the uh time slicing again because without the contact switch",
    "start": "1233080",
    "end": "1239159"
  },
  {
    "text": "overhead next if we limited one of the applications and resource and the usage",
    "start": "1239159",
    "end": "1245039"
  },
  {
    "text": "so the scenario could be it's a no priority or some development job we look",
    "start": "1245039",
    "end": "1250200"
  },
  {
    "text": "at this and the the bad perform applications or inference service",
    "start": "1250200",
    "end": "1255799"
  },
  {
    "text": "performance yeah it's much better almost yeah the same as the single C uh the",
    "start": "1255799",
    "end": "1261840"
  },
  {
    "text": "dedicated use case so so this means the MPS and with resource limits to",
    "start": "1261840",
    "end": "1266919"
  },
  {
    "text": "summarize right for the night noted inference server both the time slicing",
    "start": "1266919",
    "end": "1271960"
  },
  {
    "text": "and the MPS probably are okay and time sing have a higher and overhead and from",
    "start": "1271960",
    "end": "1278240"
  },
  {
    "text": "the contact switch for heavily noted the uh inference server probably will only",
    "start": "1278240",
    "end": "1284360"
  },
  {
    "text": "use the time slicing for the not latency intens uh Sensi even workload and for",
    "start": "1284360",
    "end": "1290360"
  },
  {
    "text": "example maybe some batch and offline and inference and more care about through",
    "start": "1290360",
    "end": "1296120"
  },
  {
    "text": "and MPS plus the resource limits and could be a better solution uh but beware",
    "start": "1296120",
    "end": "1302039"
  },
  {
    "text": "yeah a contact switch overhead for time slicing and MPS cannot provide this hard",
    "start": "1302039",
    "end": "1307440"
  },
  {
    "text": "guarantee in terms of the memory and for",
    "start": "1307440",
    "end": "1312080"
  },
  {
    "text": "isolation Okay so next we look at some the batch job and we start looking at",
    "start": "1312559",
    "end": "1318200"
  },
  {
    "text": "some small bat job to simulate this and this micro Benchmark we just draw some Cuda and Matrix and",
    "start": "1318200",
    "end": "1325080"
  },
  {
    "text": "multiplication uh we compare the scenario that okay run a single job on a dedicated GPU then on four parallel the",
    "start": "1325080",
    "end": "1333320"
  },
  {
    "text": "matrics and the multiplication jobs and sharing the GPU use time stying",
    "start": "1333320",
    "end": "1338880"
  },
  {
    "text": "NPS yeah again that's the just the using the Dr defined resource claim specified",
    "start": "1338880",
    "end": "1345559"
  },
  {
    "text": "strategy time slicing NPS okay that's the first results and use the time sing",
    "start": "1345559",
    "end": "1351240"
  },
  {
    "text": "as you can see if you only run a single job it cannot fully use this GPU the GPU",
    "start": "1351240",
    "end": "1356600"
  },
  {
    "text": "is 35% definely means was out of the expensive and the GP resources now we",
    "start": "1356600",
    "end": "1362159"
  },
  {
    "text": "draun four parel jobs we can use fully utilize the GPU and uh of course the",
    "start": "1362159",
    "end": "1367400"
  },
  {
    "text": "completion time and the increase probably it's okay for bad job this is results from fs and sharing",
    "start": "1367400",
    "end": "1376279"
  },
  {
    "text": "as you can see and uh yeah better and the performance aut stay the same we we",
    "start": "1376279",
    "end": "1382400"
  },
  {
    "text": "even still have some head room probably can run one more job so let's definitely",
    "start": "1382400",
    "end": "1387600"
  },
  {
    "text": "demonstrate the benefit by sharing the small and the GPU and the badge job and the using the MPS uh so the key takeaway",
    "start": "1387600",
    "end": "1395760"
  },
  {
    "text": "for this is yeah for this small bad J definitely should take advantage and by sharing GPU and use time slicing and",
    "start": "1395760",
    "end": "1402400"
  },
  {
    "text": "time sing probably cannot provide the the the Optimal Performance MPS and was",
    "start": "1402400",
    "end": "1408679"
  },
  {
    "text": "the flexible partitioning and no overhead and uh uh is a bad solution uh",
    "start": "1408679",
    "end": "1415159"
  },
  {
    "text": "next is let's look at the very GPU intensive and workload we use the as",
    "start": "1415159",
    "end": "1420880"
  },
  {
    "text": "much as possible Right resources so for this Benchmark that's the setup right we",
    "start": "1420880",
    "end": "1426559"
  },
  {
    "text": "we use a micr bench mark GPU burn it's basically like a stress testing and run",
    "start": "1426559",
    "end": "1433200"
  },
  {
    "text": "a single one on a dedicated GPU then run two GPU bur job using different sharing",
    "start": "1433200",
    "end": "1440240"
  },
  {
    "text": "strategy time slicing MPS without limit and MPS plus limits so again yeah here",
    "start": "1440240",
    "end": "1446679"
  },
  {
    "text": "is the example of the yo file so for the time sing as you can see here and the",
    "start": "1446679",
    "end": "1452840"
  },
  {
    "text": "single job use like the 23 24 GB memory we you run two pair on one there are no",
    "start": "1452840",
    "end": "1458720"
  },
  {
    "text": "resource guarantee or Fair sharing here the J one use and almost 10 times of the",
    "start": "1458720",
    "end": "1464880"
  },
  {
    "text": "GPU memory than the second one because there are no guarantee and there if you run we use the MPS without resource",
    "start": "1464880",
    "end": "1472240"
  },
  {
    "text": "limits got the similar results but what about like the I should",
    "start": "1472240",
    "end": "1478520"
  },
  {
    "text": "probably mention and the early yeah let me go back to this one yeah for this and",
    "start": "1478520",
    "end": "1483919"
  },
  {
    "text": "we limited resources use The NPS uh configurations this specify the",
    "start": "1483919",
    "end": "1491320"
  },
  {
    "text": "default limits and this 50% basically means half half resources can be used by these two so now if we look at we",
    "start": "1491320",
    "end": "1498399"
  },
  {
    "text": "resource limits right each of them got like a 5 GB memory specified by the",
    "start": "1498399",
    "end": "1503840"
  },
  {
    "text": "resource claim so this two and uh the GPU for the very GPU intensive jobs and",
    "start": "1503840",
    "end": "1510039"
  },
  {
    "text": "time sing definitely not good choice instead and we should consider use this MPS with the proper resource limits and",
    "start": "1510039",
    "end": "1517000"
  },
  {
    "text": "can provide much better resource isolation see okay so last we",
    "start": "1517000",
    "end": "1524640"
  },
  {
    "text": "demonstrated also evaluated the me configuration and this is a100 we",
    "start": "1524640",
    "end": "1530320"
  },
  {
    "text": "partition four of the eight GPU devices into four Mig devices two small one GPU",
    "start": "1530320",
    "end": "1537080"
  },
  {
    "text": "5 gig memory and one medium one and one three GPU 20 gig uh BYT memory and uh so",
    "start": "1537080",
    "end": "1545520"
  },
  {
    "text": "for the inference workload let's all set up and we just use a small instance to",
    "start": "1545520",
    "end": "1551760"
  },
  {
    "text": "run with quite a small instance server and then use this and three GPU and 20",
    "start": "1551760",
    "end": "1557000"
  },
  {
    "text": "GB to run a notch inference server and then we evaluate look at the performance on the",
    "start": "1557000",
    "end": "1564480"
  },
  {
    "text": "different and the resource and request rate some no resource request rate heavy request rate and again yeah it's the as",
    "start": "1564480",
    "end": "1572520"
  },
  {
    "text": "you can see yeah for me then you have different GPU uh device class name also",
    "start": "1572520",
    "end": "1578000"
  },
  {
    "text": "yeah other individual and the the uh Fields than that's the n and the",
    "start": "1578000",
    "end": "1583480"
  },
  {
    "text": "instance this the small instance okay uh that that's our result as you can say",
    "start": "1583480",
    "end": "1589200"
  },
  {
    "text": "under the nighted and the noted and the the the server cases scenario they both",
    "start": "1589200",
    "end": "1594919"
  },
  {
    "text": "almost the same performance right when you your request and increase or not and",
    "start": "1594919",
    "end": "1600640"
  },
  {
    "text": "the not instance still can handle that and Achieve similar performance but the small one got much worse so the key",
    "start": "1600640",
    "end": "1607440"
  },
  {
    "text": "Point here just said yeah if you write size of the workload depending on request or workload the demand and you",
    "start": "1607440",
    "end": "1613480"
  },
  {
    "text": "can definitely me can provide this and strong the performance and isolation",
    "start": "1613480",
    "end": "1618960"
  },
  {
    "text": "so what about the GPU intensive and we use the me so now we dra and yeah one of",
    "start": "1618960",
    "end": "1624679"
  },
  {
    "text": "the GPU burn job this is the uh GPU intensive job use the small instance and",
    "start": "1624679",
    "end": "1631000"
  },
  {
    "text": "second job and use large instance and we look at two scenarios normal scenario just let them wrong another scenario and",
    "start": "1631000",
    "end": "1638399"
  },
  {
    "text": "we purposely and inject Arrow at the first J out of memory arrrow crashed",
    "start": "1638399",
    "end": "1643799"
  },
  {
    "text": "let's see what happened okay again that's the Su okay the first scenario as you can see because the first job used",
    "start": "1643799",
    "end": "1651240"
  },
  {
    "text": "the small instance and it just used up to like 5 gig uh byes memory that's what",
    "start": "1651240",
    "end": "1656880"
  },
  {
    "text": "we expected right it's one 5 GB the second one can use up to like 20 GB",
    "start": "1656880",
    "end": "1662600"
  },
  {
    "text": "memory so they're perfect and the isolation so then we crash the first one because it's try to allocate more memory",
    "start": "1662600",
    "end": "1669960"
  },
  {
    "text": "as you can see yeah the first job crashed but the second job there are no",
    "start": "1669960",
    "end": "1675200"
  },
  {
    "text": "impact inference on the second job so to recap this yeah me definitely can",
    "start": "1675200",
    "end": "1680240"
  },
  {
    "text": "provide the strong and enhanced Qs and the pho and isolation it's very good and",
    "start": "1680240",
    "end": "1687200"
  },
  {
    "text": "if you have multitenant you want have the strong isolation uh the downside and the current implementation of course in",
    "start": "1687200",
    "end": "1693760"
  },
  {
    "text": "the mid is more static configuration you can only and the partition and create and the Seven instance there are some",
    "start": "1693760",
    "end": "1701000"
  },
  {
    "text": "interesting work from IBM and talk about this more dynamically and uh",
    "start": "1701000",
    "end": "1706519"
  },
  {
    "text": "partitioning and the size the me then yeah uh develop some optimized the scheduling I think that's is a very",
    "start": "1706519",
    "end": "1713240"
  },
  {
    "text": "interesting work okay so summarize the Benchmark and the results so what kind of the strategy",
    "start": "1713240",
    "end": "1720279"
  },
  {
    "text": "is good for different of the workloads right as we mentioned that so for",
    "start": "1720279",
    "end": "1725440"
  },
  {
    "text": "inference workload if it's night noted probably is okay just be aware the time",
    "start": "1725440",
    "end": "1730600"
  },
  {
    "text": "sing share strategy have some overhead for heavy and noed one so be careful and",
    "start": "1730600",
    "end": "1736080"
  },
  {
    "text": "it definitely can hurt your need and so it's depending on it's the online",
    "start": "1736080",
    "end": "1741240"
  },
  {
    "text": "offline or your Q or SLA and for small B job it's fine dep should take advantage",
    "start": "1741240",
    "end": "1747279"
  },
  {
    "text": "of it GPU intensive one use MPS with the limits and can provide better isolation",
    "start": "1747279",
    "end": "1753360"
  },
  {
    "text": "but if you want strong and the isolation Qs guarantee definely meig is the best one so if we look at from different",
    "start": "1753360",
    "end": "1760679"
  },
  {
    "text": "category right performance isolation for tolerance and uh yeah we'll see and as",
    "start": "1760679",
    "end": "1765840"
  },
  {
    "text": "we sh the results different kind of of here and that's something yeah probably",
    "start": "1765840",
    "end": "1771799"
  },
  {
    "text": "uh when you configure the policy should keep in mind so uh the key takeaway and the GPU",
    "start": "1771799",
    "end": "1779320"
  },
  {
    "text": "sharing is a very and useful strategy and can help improve the utilization",
    "start": "1779320",
    "end": "1784760"
  },
  {
    "text": "reduce the cost but there trof there and we should definitely take into account",
    "start": "1784760",
    "end": "1789919"
  },
  {
    "text": "and all different aspect then da is very very important feature and support all",
    "start": "1789919",
    "end": "1796880"
  },
  {
    "text": "this flexible and configuration should be take taken advantage and as Kevin",
    "start": "1796880",
    "end": "1802000"
  },
  {
    "text": "mentioned yeah it's will be better and in next releas 132 and for time slicing",
    "start": "1802000",
    "end": "1808240"
  },
  {
    "text": "it's easy config but their context and the switch was canot provided uh resource and guarantee MPS software",
    "start": "1808240",
    "end": "1816399"
  },
  {
    "text": "based very flexible but cannot provide the the strong and the memory related",
    "start": "1816399",
    "end": "1821440"
  },
  {
    "text": "for fors and isolation m is a hardware based approach can provide a stronger",
    "start": "1821440",
    "end": "1828240"
  },
  {
    "text": "and isolation and it has some fix and partition size also how to right size it",
    "start": "1828240",
    "end": "1834519"
  },
  {
    "text": "is very critical there's some reference and please check out and uh yeah scan bar",
    "start": "1834519",
    "end": "1842799"
  },
  {
    "text": "code provide your feedback would be appreciate and uh I don't know we have",
    "start": "1842799",
    "end": "1848200"
  },
  {
    "text": "time for some questions and yeah so yeah we probably can take the a couple",
    "start": "1848200",
    "end": "1855679"
  },
  {
    "text": "questions and then come to talk to us after the session and also you can find",
    "start": "1855679",
    "end": "1861120"
  },
  {
    "text": "us at Nvidia boost if you want to have additional discussions or N More about",
    "start": "1861120",
    "end": "1866320"
  },
  {
    "text": "Nidia technology thank you very",
    "start": "1866320",
    "end": "1870799"
  },
  {
    "text": "much yes I have a question so um you know what what yall are doing is great",
    "start": "1875880",
    "end": "1882039"
  },
  {
    "text": "and you know started thinking about how we would enable it in our you know self",
    "start": "1882039",
    "end": "1887960"
  },
  {
    "text": "service developer portal where we don't necessarily know what kind of workload they're going to on board what they're",
    "start": "1887960",
    "end": "1893519"
  },
  {
    "text": "going to do and so that sort of kind of makes you know creating device classes",
    "start": "1893519",
    "end": "1899519"
  },
  {
    "text": "ahead of time like really challenging right so you know when I think about it like from a uh generic kubernetes",
    "start": "1899519",
    "end": "1905919"
  },
  {
    "text": "resource request perspective I mean it's really easy to request like fractions or",
    "start": "1905919",
    "end": "1911679"
  },
  {
    "text": "you know multiples of CPU uh and memory and then you know between kubernetes",
    "start": "1911679",
    "end": "1917559"
  },
  {
    "text": "place and a cinal scheduler you know that all just sort of kind of happens so is there is there any time or are you",
    "start": "1917559",
    "end": "1925120"
  },
  {
    "text": "all thinking about you know even further simplifying your model such that you know a workload could come in and just",
    "start": "1925120",
    "end": "1931960"
  },
  {
    "text": "as it without creating device classes and slicing and and all that stuff where I can just say I want half you know",
    "start": "1931960",
    "end": "1939279"
  },
  {
    "text": "request 02 of a GPU and limit to 0.5 of a GPU",
    "start": "1939279",
    "end": "1944639"
  },
  {
    "text": "and you know I need you know a limit of 10 gigs of vram is that something youall are looking at it is yeah um uh so we",
    "start": "1944639",
    "end": "1953960"
  },
  {
    "text": "gave a talk yesterday on uh an update from the device management working group which is the working group within kubernetes that kind of governs all the",
    "start": "1953960",
    "end": "1960240"
  },
  {
    "text": "Dr work that we're doing uh and one of the things we highlighted in there is that there's lots of usability",
    "start": "1960240",
    "end": "1966159"
  },
  {
    "text": "improvements that we could still make to all of this you know we've built this base functionality but exactly what in",
    "start": "1966159",
    "end": "1972360"
  },
  {
    "text": "user uh end user facing API we want to provide at the end of this is still in",
    "start": "1972360",
    "end": "1977600"
  },
  {
    "text": "flx so the one of one of the kind of first level ideas that we have is to basically",
    "start": "1977600",
    "end": "1982799"
  },
  {
    "text": "bring back the extended resource type that we have today nvidia.com GPU but have a way for the schedule and",
    "start": "1982799",
    "end": "1989679"
  },
  {
    "text": "other components in the system to actually leverage D Dr to do those allocations so you don't have to have the device plugin running behind the",
    "start": "1989679",
    "end": "1996760"
  },
  {
    "text": "scenes so that if someone wants to use the more sophisticated interface to do selection and configuration of the",
    "start": "1996760",
    "end": "2002880"
  },
  {
    "text": "devices that they want access to they can but if they want to use the simpler API they can do that as well well um",
    "start": "2002880",
    "end": "2009440"
  },
  {
    "text": "yeah cool thank you hi yeah I had a question can we go",
    "start": "2009440",
    "end": "2015600"
  },
  {
    "text": "back to the re the performance uh bar graphs that you had like the",
    "start": "2015600",
    "end": "2021320"
  },
  {
    "text": "improvements you mean the inference yeah",
    "start": "2021320",
    "end": "2026080"
  },
  {
    "text": "yeah yeah yeah which one okay uh one question was the MPS with resource so",
    "start": "2031240",
    "end": "2037559"
  },
  {
    "text": "this is a quick question but uh it performed better when you did MPS with",
    "start": "2037559",
    "end": "2042639"
  },
  {
    "text": "resource limits as opposed to without could you just clarify yeah why that is yeah so so like we mentioned yeah",
    "start": "2042639",
    "end": "2050720"
  },
  {
    "text": "Kevin said the time sing you have the SWA in out the memory MPS with and without limits you said oh Without",
    "start": "2050720",
    "end": "2056280"
  },
  {
    "text": "Limits with limits okay so the Without Limits and uh because there are no guarantee how these two and the",
    "start": "2056280",
    "end": "2062720"
  },
  {
    "text": "inference server shed resources right like we should there they could some randomly or whatever we Shar resources",
    "start": "2062720",
    "end": "2069118"
  },
  {
    "text": "so the performance yeah you don't know use it with limits basically we limit one of the application said you can use",
    "start": "2069119",
    "end": "2076000"
  },
  {
    "text": "only up to in this case is 10% of the usage like no priority so then you can",
    "start": "2076000",
    "end": "2082878"
  },
  {
    "text": "provide better performance otherwise you run the risk of the first application consuming all the resources the second",
    "start": "2082879",
    "end": "2088638"
  },
  {
    "text": "one doesn't have any available for it okay okay so it's better to know up front the and then the other the last",
    "start": "2088639",
    "end": "2094398"
  },
  {
    "text": "thing was between time slicing and MPS I think you mentioned this sorry but can you just clarify that again why there's",
    "start": "2094399",
    "end": "2101320"
  },
  {
    "text": "a performance difference there I guess time slicing is at a lower level than MPS is right so that causes a",
    "start": "2101320",
    "end": "2108560"
  },
  {
    "text": "performance difference MH okay thank you uh great presentation I was",
    "start": "2108560",
    "end": "2115680"
  },
  {
    "text": "wondering how exactly uh one should go about setting the limits for MPS for the",
    "start": "2115680",
    "end": "2121000"
  },
  {
    "text": "resource limits is there an objective way to find those uh values you mean how to decide what limits you should set",
    "start": "2121000",
    "end": "2128119"
  },
  {
    "text": "yeah um this actually relates back to the talk I just came from before this um",
    "start": "2128119",
    "end": "2134599"
  },
  {
    "text": "there's no I think uh standard methodology for that um but you can",
    "start": "2134599",
    "end": "2140960"
  },
  {
    "text": "empirically kind of figure out by either benchmarking an application a priori and knowing what type of workloads it or",
    "start": "2140960",
    "end": "2148119"
  },
  {
    "text": "what type of um uh input it might have to it that that would cause it to run",
    "start": "2148119",
    "end": "2153480"
  },
  {
    "text": "with a certain amount of memory that it consumes and a certain amount of compute that it does but there's no uh yeah standard methodology for it as",
    "start": "2153480",
    "end": "2160960"
  },
  {
    "text": "as far as I know got it and I just make a comment yeah to to this one I think",
    "start": "2160960",
    "end": "2166240"
  },
  {
    "text": "this and the study just right and uh give probably you the capability of The",
    "start": "2166240",
    "end": "2172240"
  },
  {
    "text": "Da and the sharing strategy the mechanism here right or some mge with you and but how you set this value right",
    "start": "2172240",
    "end": "2179359"
  },
  {
    "text": "and I think previous talk there some apply even some reinforcement learning other thing do Benchmark create more",
    "start": "2179359",
    "end": "2186200"
  },
  {
    "text": "realis and Benchmark and set up right there another technology and how to Siz",
    "start": "2186200",
    "end": "2191920"
  },
  {
    "text": "it as a separate topic definitely very interesting yeah moving forward but it's probably a little bit out of the scope",
    "start": "2191920",
    "end": "2198440"
  },
  {
    "text": "of this right",
    "start": "2198440",
    "end": "2201240"
  }
]
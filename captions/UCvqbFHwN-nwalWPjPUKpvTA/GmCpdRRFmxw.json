[
  {
    "start": "0",
    "end": "24000"
  },
  {
    "text": "hi and what I would like to talk to won't it's very noisy okay what I would",
    "start": "30",
    "end": "11610"
  },
  {
    "text": "like to talk today is about ability to automate your machine learning pipelines",
    "start": "11610",
    "end": "17279"
  },
  {
    "text": "in a scalable way using machine learning nuclear functions and cube flow so",
    "start": "17279",
    "end": "25170"
  },
  {
    "start": "24000",
    "end": "74000"
  },
  {
    "text": "usually when one thinks about the data scientist works they think that most of the time is spent on defining the KPIs",
    "start": "25170",
    "end": "31769"
  },
  {
    "text": "finding the right algorithm to solve the problem and tune it surprisingly or not",
    "start": "31769",
    "end": "37309"
  },
  {
    "text": "most of the time is being spent or rather said wasted on climbing on the",
    "start": "37309",
    "end": "43620"
  },
  {
    "text": "infrastructure in order to bring this model into production to bring the model into life this is a slide taking from",
    "start": "43620",
    "end": "50820"
  },
  {
    "text": "Google but we held last month ml ops conference in New York and we heard the",
    "start": "50820",
    "end": "57239"
  },
  {
    "text": "same problem coming up from most of the participant in attendees so it is a very",
    "start": "57239",
    "end": "62760"
  },
  {
    "text": "acute issue with ml ops at the moment so",
    "start": "62760",
    "end": "68070"
  },
  {
    "text": "we need to find a simple solution for better data integration and automation so when I'm saying plumbing",
    "start": "68070",
    "end": "77130"
  },
  {
    "start": "74000",
    "end": "143000"
  },
  {
    "text": "what does it really mean so it can take weeks for a single data scientist to",
    "start": "77130",
    "end": "82740"
  },
  {
    "text": "come up with a model but it will take months of several people including DevOps",
    "start": "82740",
    "end": "88290"
  },
  {
    "text": "and data engineers and the data scientists to really bring this model into life because they need a lot of",
    "start": "88290",
    "end": "95549"
  },
  {
    "text": "packaging dependencies running scripts building scale out there are different",
    "start": "95549",
    "end": "101670"
  },
  {
    "text": "notions of scaling out depending on the framework that was chosen there are",
    "start": "101670",
    "end": "106860"
  },
  {
    "text": "different way to partition the data depending on the frameworks that was chosen there is the I promise GPU",
    "start": "106860",
    "end": "114240"
  },
  {
    "text": "support integration would GPU parallelism tuning monitoring all those",
    "start": "114240",
    "end": "119460"
  },
  {
    "text": "kind of work logging taking care of the artifacts security CI CD that's the",
    "start": "119460",
    "end": "126299"
  },
  {
    "text": "plumbing that needs to be done and we need a way to automate all those",
    "start": "126299",
    "end": "131640"
  },
  {
    "text": "different steps taking reduce the time that it takes a model to get into life and reduce the",
    "start": "131640",
    "end": "139770"
  },
  {
    "text": "amount of models that address dying in the process so let's look take a look at a very",
    "start": "139770",
    "end": "148760"
  },
  {
    "start": "143000",
    "end": "291000"
  },
  {
    "text": "simple example of a machine learning pipeline this example is talking about a",
    "start": "148760",
    "end": "155370"
  },
  {
    "text": "customer recommendation based on location like if I move the mall and I'm usually buying debt and debt product",
    "start": "155370",
    "end": "162270"
  },
  {
    "text": "what would you recommend me to buy now so there is the ingestion part there is",
    "start": "162270",
    "end": "167670"
  },
  {
    "text": "tons of transactions coming in ingested all the transaction by all the different",
    "start": "167670",
    "end": "173550"
  },
  {
    "text": "customers in swiping their visa there is the location where the customer is",
    "start": "173550",
    "end": "179640"
  },
  {
    "text": "currently located those kind of ingestion to restream is coming in ten thousandth events per second there is",
    "start": "179640",
    "end": "188100"
  },
  {
    "text": "information about the products about what is being held in the store and",
    "start": "188100",
    "end": "193550"
  },
  {
    "text": "customer tables like what is the gender what its interest what is usually buying",
    "start": "193550",
    "end": "198590"
  },
  {
    "text": "what is interested in all the information that you can preserve a customer depending on what you have on",
    "start": "198590",
    "end": "204390"
  },
  {
    "text": "them and you can also scrape information from the for example environment if it's",
    "start": "204390",
    "end": "209670"
  },
  {
    "text": "a rainy day you would like to propose winter product to that customer so all",
    "start": "209670",
    "end": "216540"
  },
  {
    "text": "this information is being ingested and being saved in a base feature store we",
    "start": "216540",
    "end": "223079"
  },
  {
    "text": "have a data preparation labeling stuff like that save again to a derived features store then we do the training",
    "start": "223079",
    "end": "230100"
  },
  {
    "text": "finding the correlation between different products from you buying this product usually I will buy that and that",
    "start": "230100",
    "end": "236700"
  },
  {
    "text": "product as well all this is being trained into a model and to a learned",
    "start": "236700",
    "end": "244440"
  },
  {
    "text": "feature store which will then be used by the model then I'll deploy the model and",
    "start": "244440",
    "end": "250130"
  },
  {
    "text": "when now I have information about the location of a specific customer I can",
    "start": "250130",
    "end": "255480"
  },
  {
    "text": "provide a customer ID and its location and the model servant will provide me of",
    "start": "255480",
    "end": "260700"
  },
  {
    "text": "what they need to send him as a product to sell so if we look at this quite simple",
    "start": "260700",
    "end": "267160"
  },
  {
    "text": "a machine-learning pipeline example we see as usual there are four stages there",
    "start": "267160",
    "end": "272860"
  },
  {
    "text": "is they ingest the data preparation the data training in the Surfing and",
    "start": "272860",
    "end": "279360"
  },
  {
    "text": "automation a service has tackled the ingest and the serve and we'll see in a",
    "start": "279360",
    "end": "284620"
  },
  {
    "text": "moment how it's being tackled but the data preparation and the training are not yet to be handled so introducing new",
    "start": "284620",
    "end": "294010"
  },
  {
    "start": "291000",
    "end": "351000"
  },
  {
    "text": "Clio new Clio is an open source service framework which was developed with",
    "start": "294010",
    "end": "301570"
  },
  {
    "text": "machine learning pipeline in mind it can handle virtually any type of source of",
    "start": "301570",
    "end": "307690"
  },
  {
    "text": "event from Kafka for Canisius event a paps RabbitMQ cron HTTP of course it has",
    "start": "307690",
    "end": "315700"
  },
  {
    "text": "integration within video rapids it has real-time mechanism embedded",
    "start": "315700",
    "end": "323890"
  },
  {
    "text": "within it so within each one of the function pods there are multiple workers",
    "start": "323890",
    "end": "329620"
  },
  {
    "text": "working concurrently without any blocking with zero copy notion each one",
    "start": "329620",
    "end": "336970"
  },
  {
    "text": "of the workers when there is data worker reviewed at work a decade and uses GP",
    "start": "336970",
    "end": "343990"
  },
  {
    "text": "optimization and of course it's natively integrated with cube flow and with",
    "start": "343990",
    "end": "349480"
  },
  {
    "text": "jupiter notebooks so i was doing just being used so for in this example you",
    "start": "349480",
    "end": "356680"
  },
  {
    "text": "can see that there is a simple Python code that by moving that code and",
    "start": "356680",
    "end": "363910"
  },
  {
    "text": "invoking it using a nuclear function you get almost 30% more throughput and why",
    "start": "363910",
    "end": "369610"
  },
  {
    "text": "is that the reason is the parallelism nucleo you have multiple workers that",
    "start": "369610",
    "end": "374830"
  },
  {
    "text": "can take ingest information in parallel does give you a much higher throughput",
    "start": "374830",
    "end": "380140"
  },
  {
    "text": "in a low latency kind of a session it's a very simple way to move a code from",
    "start": "380140",
    "end": "386950"
  },
  {
    "text": "one other to another and it's virtually as I said before can get any type of",
    "start": "386950",
    "end": "393130"
  },
  {
    "text": "event but it can also get any type of data within event so it doesn't",
    "start": "393130",
    "end": "399139"
  },
  {
    "text": "have to get numbers it can get images it can get URLs and stuff like that model",
    "start": "399139",
    "end": "408500"
  },
  {
    "start": "407000",
    "end": "480000"
  },
  {
    "text": "serving so you can use nuclear to serve models it really uses does a resource a",
    "start": "408500",
    "end": "418490"
  },
  {
    "text": "utilization and you can see in this example the same kind of code running or GPU system Whitney clearly get four",
    "start": "418490",
    "end": "426169"
  },
  {
    "text": "times the performance as in an equivalent system you can also get twice",
    "start": "426169",
    "end": "431960"
  },
  {
    "text": "the performance on a reduced system and it's a very simple notion to take a",
    "start": "431960",
    "end": "437169"
  },
  {
    "text": "notebook and we'll see that in a moment Rupert aerobic and convert it to nuclear",
    "start": "437169",
    "end": "442669"
  },
  {
    "text": "so it's very easy to deploy it gives you a great resource utilization within the",
    "start": "442669",
    "end": "450379"
  },
  {
    "text": "same pod and of course as server less its users versus on-demand it means that",
    "start": "450379",
    "end": "456529"
  },
  {
    "text": "it can scale up add more application to the function if needed if you have a",
    "start": "456529",
    "end": "461960"
  },
  {
    "text": "huge burst for example then you get more application for that same function it",
    "start": "461960",
    "end": "467719"
  },
  {
    "text": "can reduce even to zero if there is a downtime or not nothing is in triggers",
    "start": "467719",
    "end": "473900"
  },
  {
    "text": "the function so it gives you a resource on demand so service is such a great",
    "start": "473900",
    "end": "484219"
  },
  {
    "start": "480000",
    "end": "571000"
  },
  {
    "text": "notion it solves the ingestion of the serving why not use that for data",
    "start": "484219",
    "end": "490460"
  },
  {
    "text": "preparation and training so if we take a look at C it's several characteristics of server list and data professional",
    "start": "490460",
    "end": "497449"
  },
  {
    "text": "training we see that they don't fit if we look for example it the tasks lifespan in servlets the times to take",
    "start": "497449",
    "end": "505639"
  },
  {
    "text": "and use an event is millisecond two minutes data preparation and training it",
    "start": "505639",
    "end": "511009"
  },
  {
    "text": "seconds two hours too many hours scaling in server less the scaling is very easy",
    "start": "511009",
    "end": "518419"
  },
  {
    "text": "you put a load balancer in front of the functions you get a trigger it will",
    "start": "518419",
    "end": "524060"
  },
  {
    "text": "redirect it to one of those functions in that operational training the",
    "start": "524060",
    "end": "529520"
  },
  {
    "text": "scalability is much more difficult and there are so many diff ways to partition and to scale the",
    "start": "529520",
    "end": "535360"
  },
  {
    "text": "infrastructure in depending on the real-time engine underneath it you can do partition and shuffle is being done",
    "start": "535360",
    "end": "541839"
  },
  {
    "text": "for example in Spock you can do hyper params ring or reduce has been done in hovered so there are many different ways",
    "start": "541839",
    "end": "548410"
  },
  {
    "text": "to scale and paralyze your workload and it's very dependent on the engine the",
    "start": "548410",
    "end": "553690"
  },
  {
    "text": "firm work that you choose to run with state several aces stateless and data",
    "start": "553690",
    "end": "559209"
  },
  {
    "text": "preparation in training is of course states it's all about data intensive",
    "start": "559209",
    "end": "564519"
  },
  {
    "text": "carnival workload and the input is different as well so it's not that easy",
    "start": "564519",
    "end": "571319"
  },
  {
    "start": "571000",
    "end": "667000"
  },
  {
    "text": "to take data preparation and treasuring which are data intensive and better",
    "start": "571319",
    "end": "578199"
  },
  {
    "text": "oriented and make it service but we still want to have the ability to take",
    "start": "578199",
    "end": "584319"
  },
  {
    "text": "the service concept such as on-demand residual ization using only when needed",
    "start": "584319",
    "end": "590620"
  },
  {
    "text": "use ability to increase the resources as needed and to decrease them and we would",
    "start": "590620",
    "end": "596980"
  },
  {
    "text": "like the automation the build and automation of deployment not worry about the service where it's run how to run it",
    "start": "596980",
    "end": "603790"
  },
  {
    "text": "and stuff like that so what we did is we took we wrapped different engine such as",
    "start": "603790",
    "end": "612970"
  },
  {
    "text": "spark a chance of horville nucleo we wrapped them around such it will",
    "start": "612970",
    "end": "619779"
  },
  {
    "text": "abstract and each one of those different runtime will handle the scalability and",
    "start": "619779",
    "end": "624939"
  },
  {
    "text": "the parallelism within it we attached a fast data layer underneath so it they",
    "start": "624939",
    "end": "631779"
  },
  {
    "text": "can preserve the state and the differently there itself and attached a",
    "start": "631779",
    "end": "638380"
  },
  {
    "text": "edit an abstraction layer which removes the operational burden from you so it",
    "start": "638380",
    "end": "643720"
  },
  {
    "text": "takes care of monitoring and building and artifacts and all kind of",
    "start": "643720",
    "end": "649529"
  },
  {
    "text": "operational overhead that you usually have and provide you with the ability to",
    "start": "649529",
    "end": "655120"
  },
  {
    "text": "code once and to move it to run it on different runtimes we just a change in",
    "start": "655120",
    "end": "661779"
  },
  {
    "text": "it something like two lines of code and we see the in a second so before going into the",
    "start": "661779",
    "end": "669459"
  },
  {
    "text": "demo and the demo will show you ml functions all the demos can be found in",
    "start": "669459",
    "end": "676630"
  },
  {
    "text": "d dub ml 1 itself is an open source which is in early development stages you",
    "start": "676630",
    "end": "682449"
  },
  {
    "text": "we encourage you to have a look and get up at ml run to add different runtime",
    "start": "682449",
    "end": "687940"
  },
  {
    "text": "engines to it and different storage is as you see fit",
    "start": "687940",
    "end": "693480"
  },
  {
    "text": "so is it can you see zoom in",
    "start": "705470",
    "end": "714139"
  },
  {
    "text": "better another okay so I'll try the demo and",
    "start": "718230",
    "end": "728709"
  },
  {
    "text": "may the gods demo will be with me and the network as well so let's give it a",
    "start": "728709",
    "end": "734290"
  },
  {
    "text": "try so I'll start with a very simple demo which is the lord of the machine",
    "start": "734290",
    "end": "742420"
  },
  {
    "text": "learning it's the iris model and we'll take a look at that and from there we'll",
    "start": "742420",
    "end": "747459"
  },
  {
    "text": "move to a more complicated kind of an demo so first of all you see here a",
    "start": "747459",
    "end": "753610"
  },
  {
    "text": "jupiter magic here it's an nucleo notation which will tell you later if we",
    "start": "753610",
    "end": "759730"
  },
  {
    "text": "take this jupiter notebook and convert it to a function a nuclear function which can be easily done it will tell",
    "start": "759730",
    "end": "766899"
  },
  {
    "text": "how this needs to be configured within the function itself so you'll see here",
    "start": "766899",
    "end": "773560"
  },
  {
    "text": "around the notebook there are different annotations to instruct how to build the",
    "start": "773560",
    "end": "779589"
  },
  {
    "text": "functions so we do all this beep installs we configure some base image",
    "start": "779589",
    "end": "789540"
  },
  {
    "text": "for the nuclear function but most of it mode of hole this is the methods that",
    "start": "789540",
    "end": "796380"
  },
  {
    "text": "holds the information file to operate that training so first of all we have",
    "start": "796380",
    "end": "802630"
  },
  {
    "text": "this method which is IRA's generator which take the data sets embedded and",
    "start": "802630",
    "end": "808230"
  },
  {
    "text": "save it as a CVS csv story then we have",
    "start": "808230",
    "end": "813700"
  },
  {
    "text": "a method for exhibit rain we'll take this file define a text parameters",
    "start": "813700",
    "end": "820140"
  },
  {
    "text": "apparatus that will provide it to it when it's being called and creating and",
    "start": "820140",
    "end": "827110"
  },
  {
    "text": "saving the model do you see what I'm marking and there is another method to",
    "start": "827110",
    "end": "836500"
  },
  {
    "text": "do some a plots iteration it's like building the Instagram of the results",
    "start": "836500",
    "end": "843120"
  },
  {
    "start": "844000",
    "end": "1004000"
  },
  {
    "text": "okay so what I'm doing here is I'm creating an ml function and running it",
    "start": "845440",
    "end": "852730"
  },
  {
    "text": "so there is two ways to provide Iran with information and can define a task",
    "start": "852730",
    "end": "857800"
  },
  {
    "text": "which we'll see next or I can provide it explicitly with the different parameters",
    "start": "857800",
    "end": "863079"
  },
  {
    "text": "of the job to be run so in that case we chose to provide it within the run itself so we have a job name here is Jan",
    "start": "863079",
    "end": "872189"
  },
  {
    "text": "this is the end of to the method we've just saw and the parameters is where to",
    "start": "872189",
    "end": "878050"
  },
  {
    "text": "locate the file as we can see here the result is the job itself it instead",
    "start": "878050",
    "end": "886089"
  },
  {
    "text": "completed we can see the artifacts we can even see the artifact himself that",
    "start": "886089",
    "end": "893889"
  },
  {
    "text": "was created by this run next we want to",
    "start": "893889",
    "end": "901209"
  },
  {
    "text": "train the model so we're taking defining parameters and now that we're refining",
    "start": "901209",
    "end": "906939"
  },
  {
    "text": "it in a task so we refining the task the different parameter that we want to invoke diapered parameters that we want",
    "start": "906939",
    "end": "916389"
  },
  {
    "text": "this one to run and provided they run the task this one will run within the",
    "start": "916389",
    "end": "923350"
  },
  {
    "text": "jupiter notebook itself i didn't provide any runtime information so the local one is being chosen so this training is is",
    "start": "923350",
    "end": "931389"
  },
  {
    "text": "it's a very small data set it can run within two joe paterno book itself was has been run within that notebook but i",
    "start": "931389",
    "end": "940000"
  },
  {
    "text": "can take the same task information that i with all the parameters that has just been used and now run the same training",
    "start": "940000",
    "end": "947230"
  },
  {
    "text": "on a remote paralyzed way using a nuclear so i'm taking the same code",
    "start": "947230",
    "end": "955420"
  },
  {
    "text": "converted to a nuclear function now providing a runtime of machine nuclear",
    "start": "955420",
    "end": "960610"
  },
  {
    "text": "machine learning attach it with assured a data volume and defining that the HTTP",
    "start": "960610",
    "end": "966699"
  },
  {
    "text": "triggers should have sixteen workers and i deploy this function so all the",
    "start": "966699",
    "end": "972459"
  },
  {
    "text": "compiling and believe believe the container for the function is done for me i didn't do anything",
    "start": "972459",
    "end": "980040"
  },
  {
    "text": "let me just move to show for example",
    "start": "981480",
    "end": "987300"
  },
  {
    "text": "okay so can you see I need to zoom again",
    "start": "989280",
    "end": "996570"
  },
  {
    "text": "okay",
    "start": "997470",
    "end": "1000470"
  },
  {
    "text": "so this is the UFO nuclear-nuclear of course is open source so you see here",
    "start": "1005170",
    "end": "1010869"
  },
  {
    "text": "it's the code the methods that we've just seen what I wanted to show it's the configuration of this function so you",
    "start": "1010869",
    "end": "1017049"
  },
  {
    "text": "see that all the configuration annotation that we use within the jupiter notebooks are now within the pod",
    "start": "1017049",
    "end": "1024370"
  },
  {
    "text": "itself we have the base image the different people stores that we had",
    "start": "1024370",
    "end": "1030668"
  },
  {
    "text": "there the video which is the volume we attach to that function we can also see",
    "start": "1030669",
    "end": "1038350"
  },
  {
    "text": "within the triggers that I have 16 workers for HTTP I can that easily add another trigger to a function what I",
    "start": "1038350",
    "end": "1046149"
  },
  {
    "text": "didn't mention before and it's very important it's nuclear it's not just that it can handle different many",
    "start": "1046149",
    "end": "1052120"
  },
  {
    "text": "different triggers it can handle different triggers within the same function so I can add another like kafka",
    "start": "1052120",
    "end": "1058539"
  },
  {
    "text": "which has the same notion of different event and added another trigger to that function moving back to Jupiter so I",
    "start": "1058539",
    "end": "1067779"
  },
  {
    "start": "1065000",
    "end": "1133000"
  },
  {
    "text": "have I now have this function being deployed it's running now I want it to",
    "start": "1067779",
    "end": "1074320"
  },
  {
    "text": "invoke the Train so I need to provide it with the parameters that I defined",
    "start": "1074320",
    "end": "1079720"
  },
  {
    "text": "earlier and it's just that easy I'm taking the address this is the",
    "start": "1079720",
    "end": "1086080"
  },
  {
    "text": "address of the function and we are using that to do a Mel function run providing",
    "start": "1086080",
    "end": "1092500"
  },
  {
    "text": "it the tasks that we defined earlier and use to run on the Jupiter itself now the",
    "start": "1092500",
    "end": "1098559"
  },
  {
    "text": "same thing this training is run is ran on a nucleo and parallels like using the",
    "start": "1098559",
    "end": "1104980"
  },
  {
    "text": "60 workers that we have defined and we have the job results for this training",
    "start": "1104980",
    "end": "1110590"
  },
  {
    "text": "as well using all the logging the input parameters and the artifacts so what",
    "start": "1110590",
    "end": "1118659"
  },
  {
    "text": "we've seen is that I could take very simply a same code run it in a different",
    "start": "1118659",
    "end": "1123880"
  },
  {
    "text": "aspect different runtimes and all the scalability and all this notion and the",
    "start": "1123880",
    "end": "1128889"
  },
  {
    "text": "building and the monitoring and the logging is done automatically for me so",
    "start": "1128889",
    "end": "1134679"
  },
  {
    "start": "1133000",
    "end": "1266000"
  },
  {
    "text": "let's assume that I did all this kind of playing with the Jupiter now very happy with my result and I want",
    "start": "1134679",
    "end": "1141030"
  },
  {
    "text": "to use it in cube flow so I want to define the different steps and to create",
    "start": "1141030",
    "end": "1147030"
  },
  {
    "text": "a cube flow out of it so it's very simple to do that with ml run I have",
    "start": "1147030",
    "end": "1153510"
  },
  {
    "text": "here a within a pipeline a four steps the first one is the gist it's the same",
    "start": "1153510",
    "end": "1160260"
  },
  {
    "text": "code that we used before the Indies generator and its output it's the data",
    "start": "1160260",
    "end": "1167250"
  },
  {
    "text": "set then I have a training step training and we see that it gets an input the",
    "start": "1167250",
    "end": "1176250"
  },
  {
    "text": "data set that was created as an output of the IRA's data set of the previous",
    "start": "1176250",
    "end": "1182010"
  },
  {
    "text": "step and if the output is the model itself and we see next that the plot can",
    "start": "1182010",
    "end": "1191400"
  },
  {
    "text": "take the model and do a plot in of iteration and we can take a function and",
    "start": "1191400",
    "end": "1199710"
  },
  {
    "text": "create a model serving for that using",
    "start": "1199710",
    "end": "1205200"
  },
  {
    "text": "that model and with that simple definition of how the artifacts should",
    "start": "1205200",
    "end": "1212070"
  },
  {
    "text": "move from one step to another step we can now run this and create a pipeline",
    "start": "1212070",
    "end": "1221309"
  },
  {
    "text": "and we can see this pipeline I prepare ahead of time so we see this is the",
    "start": "1221309",
    "end": "1226500"
  },
  {
    "text": "pipeline that was created we have the iris going to the training and then we have two polarized stages the plot and",
    "start": "1226500",
    "end": "1234299"
  },
  {
    "text": "the deployment deployment of nuclear function if we go to the plot for",
    "start": "1234299",
    "end": "1239429"
  },
  {
    "text": "example we can see the artifact this is the nice sister Graham that was created a by the training we can see the logs we",
    "start": "1239429",
    "end": "1247590"
  },
  {
    "text": "can see all the other information that was created but while running this job so we saw a very easy way to take a code",
    "start": "1247590",
    "end": "1259679"
  },
  {
    "text": "convert run it on different runtimes and then take it to the next step and automate it with cube flow what we see",
    "start": "1259679",
    "end": "1267179"
  },
  {
    "text": "next before we go to a different kind of job is how we can take nuclear and use it we care if serving so ka",
    "start": "1267179",
    "end": "1274950"
  },
  {
    "text": "serving defines methods of a model how would should it be called so every model",
    "start": "1274950",
    "end": "1281760"
  },
  {
    "text": "need to have a predict method and it could also have other methods such as",
    "start": "1281760",
    "end": "1287610"
  },
  {
    "text": "explain in pre and post functions in addition to functions that the model",
    "start": "1287610",
    "end": "1292770"
  },
  {
    "text": "itself can declare so what we'll see here is that you can use nucleon as a",
    "start": "1292770",
    "end": "1300810"
  },
  {
    "text": "model serving within KF serving but and",
    "start": "1300810",
    "end": "1306030"
  },
  {
    "text": "you gain the serverless notion out of it so when you use it with K serving you still need to compile and build and do",
    "start": "1306030",
    "end": "1312180"
  },
  {
    "text": "all the notion for that image with nucleo the birth this burden is lifted",
    "start": "1312180",
    "end": "1317850"
  },
  {
    "text": "out of you so you can and again the performance of a funicular as a service",
    "start": "1317850",
    "end": "1324090"
  },
  {
    "text": "so we see here I'll do it very quickly so we'll have time for the next demo we",
    "start": "1324090",
    "end": "1329550"
  },
  {
    "text": "are defining again of the peeping stalls the imports and stuff like that and we",
    "start": "1329550",
    "end": "1335310"
  },
  {
    "text": "define a predict the predict is actually calling the code that we a senior a",
    "start": "1335310",
    "end": "1342840"
  },
  {
    "text": "before with using the model okay so now",
    "start": "1342840",
    "end": "1348000"
  },
  {
    "text": "I can take and create a model server this is its name providing it with a",
    "start": "1348000",
    "end": "1354060"
  },
  {
    "text": "model that we already stored with the training in this directory and deploy it",
    "start": "1354060",
    "end": "1363620"
  },
  {
    "text": "and now and now you can see if I want to",
    "start": "1363620",
    "end": "1369810"
  },
  {
    "text": "use an event to invoke that function KF serving is using a protocol of seldom",
    "start": "1369810",
    "end": "1376800"
  },
  {
    "text": "which is kind of a array of numbers so",
    "start": "1376800",
    "end": "1382290"
  },
  {
    "text": "we need to convert the event to that array and we can invoke there's serving",
    "start": "1382290",
    "end": "1389070"
  },
  {
    "text": "so by that we get the notion of K of serving but with parallelism and",
    "start": "1389070",
    "end": "1395610"
  },
  {
    "text": "automated kind of a thing if we go for I can't see you",
    "start": "1395610",
    "end": "1402170"
  },
  {
    "start": "1402000",
    "end": "1461000"
  },
  {
    "text": "we consider the function its again with the prediction everything and you can",
    "start": "1403399",
    "end": "1409890"
  },
  {
    "text": "use that the same notion is you with KF serving so I'll move to the next demo",
    "start": "1409890",
    "end": "1418620"
  },
  {
    "text": "this one is taking a little bit more complex kind of a job it's utilizing a",
    "start": "1418620",
    "end": "1425870"
  },
  {
    "text": "hoard which is distributed tensorflow so it's using this kind of an engine so",
    "start": "1425870",
    "end": "1433169"
  },
  {
    "text": "briefly gold stuff that we already talked about but we see here that there steps here this this open archive method",
    "start": "1433169",
    "end": "1440640"
  },
  {
    "text": "which take the images out of s3 bringing them to the system there is the",
    "start": "1440640",
    "end": "1448230"
  },
  {
    "text": "catalyzing map builder which is labeling and catalyzing the different images",
    "start": "1448230",
    "end": "1453299"
  },
  {
    "text": "which one is cat which one is dog and defining what has categories a we have",
    "start": "1453299",
    "end": "1460020"
  },
  {
    "text": "within this model we're preserving at",
    "start": "1460020",
    "end": "1465750"
  },
  {
    "start": "1461000",
    "end": "1527000"
  },
  {
    "text": "this stage two different artifacts the cattle rise in the map and the files",
    "start": "1465750",
    "end": "1471899"
  },
  {
    "text": "themselves so now we again we can create a very simple task this is the task",
    "start": "1471899",
    "end": "1480570"
  },
  {
    "text": "definition it's a download it has the different parameters and we can create them ml functions using that task we are",
    "start": "1480570",
    "end": "1488760"
  },
  {
    "text": "seeing here all the completion and everything of that step we want me to",
    "start": "1488760",
    "end": "1494429"
  },
  {
    "text": "worry about to monitor about the artifacts and stuff like that the next stage is to tag the images again it's",
    "start": "1494429",
    "end": "1505279"
  },
  {
    "text": "running here and the third step is actually do the training so this",
    "start": "1505279",
    "end": "1511980"
  },
  {
    "text": "training is more intensive and it's using a horde in order to do that so we",
    "start": "1511980",
    "end": "1518909"
  },
  {
    "text": "are defining the horford file the different parameters there is the different data path and all those file",
    "start": "1518909",
    "end": "1525990"
  },
  {
    "text": "as an input and simple as that we create a new a machine learning function give",
    "start": "1525990",
    "end": "1533620"
  },
  {
    "start": "1527000",
    "end": "1592000"
  },
  {
    "text": "named command of the Opera MPI job and",
    "start": "1533620",
    "end": "1539200"
  },
  {
    "text": "apply different a configuration for that job such as are many replicas we want",
    "start": "1539200",
    "end": "1546190"
  },
  {
    "text": "for that MPI operator for means we have will have four walker poles that does a dope job for us we can easily just with",
    "start": "1546190",
    "end": "1554080"
  },
  {
    "text": "this line of code add GPUs attach GPUs to this a job I didn't have one on my",
    "start": "1554080",
    "end": "1560140"
  },
  {
    "text": "system and run again using the",
    "start": "1560140",
    "end": "1565539"
  },
  {
    "text": "parameters that we defined and give it a name so this job is taking something",
    "start": "1565539",
    "end": "1570669"
  },
  {
    "text": "like half an hour using four different pods running remotely and we see that",
    "start": "1570669",
    "end": "1582669"
  },
  {
    "text": "it's it completed and we can see I don't",
    "start": "1582669",
    "end": "1590649"
  },
  {
    "text": "see if you can see that never mind and now when we have the model we can",
    "start": "1590649",
    "end": "1597309"
  },
  {
    "start": "1592000",
    "end": "1640000"
  },
  {
    "text": "deploy that but before we going into the model I want to show another thing which is ml run UI the same notion of drop",
    "start": "1597309",
    "end": "1608559"
  },
  {
    "text": "tracking as we see in the jupiter notebook we can much better see with this within this UI and it's supposed to",
    "start": "1608559",
    "end": "1614890"
  },
  {
    "text": "cube flow it monitors every different job that you have it's not just the cube",
    "start": "1614890",
    "end": "1620230"
  },
  {
    "text": "flow jobs each one in cube flow you have every job that was run through that machine learning pipelining here and you",
    "start": "1620230",
    "end": "1627309"
  },
  {
    "text": "can see different information inputs and artifacts so we can see that the",
    "start": "1627309",
    "end": "1633610"
  },
  {
    "text": "training this is the plot of the training of what we used to just run",
    "start": "1633610",
    "end": "1640200"
  },
  {
    "text": "okay so I can now take the same as the same notion as before take and create a",
    "start": "1640890",
    "end": "1648340"
  },
  {
    "text": "function for the model serving using the model that we have just been created",
    "start": "1648340",
    "end": "1655770"
  },
  {
    "text": "setting its specific environment that we need and as opposed to a need to use",
    "start": "1655770",
    "end": "1664570"
  },
  {
    "text": "numpy array we can use with clear different type of triggers so you can invoke that function using a URL and",
    "start": "1664570",
    "end": "1673660"
  },
  {
    "text": "we get you see that it's a URL we get it's a cat and you see here that we send",
    "start": "1673660",
    "end": "1681520"
  },
  {
    "text": "it's in the image you see in the context that we send it is a JPEG and we got a",
    "start": "1681520",
    "end": "1687940"
  },
  {
    "text": "result that this one is a dog so I get just five minutes or move very briefly",
    "start": "1687940",
    "end": "1694860"
  },
  {
    "text": "showing that the entire thing that we just seen we can use it now with cube",
    "start": "1694860",
    "end": "1700570"
  },
  {
    "text": "flow very easily as we've seen we create",
    "start": "1700570",
    "end": "1707050"
  },
  {
    "text": "a function out of the code we define for",
    "start": "1707050",
    "end": "1715150"
  },
  {
    "start": "1713000",
    "end": "1762000"
  },
  {
    "text": "a cube flow the artifact path the different stages here we have a state",
    "start": "1715150",
    "end": "1722800"
  },
  {
    "text": "with doesn't need an artifact from the previous stage but we still want it to",
    "start": "1722800",
    "end": "1728740"
  },
  {
    "text": "run after after the the labeling is after the data ingestion so we provide",
    "start": "1728740",
    "end": "1734950"
  },
  {
    "text": "and after so this one label will one after open archive then we'll have the",
    "start": "1734950",
    "end": "1742270"
  },
  {
    "text": "training that are using the output of the labeling it uses those as an input",
    "start": "1742270",
    "end": "1748960"
  },
  {
    "text": "so implicitly cube flow will run this step after the previous step and then we",
    "start": "1748960",
    "end": "1756160"
  },
  {
    "text": "can deploy it a deploy the model as a modeling serving function and I prepared",
    "start": "1756160",
    "end": "1765910"
  },
  {
    "text": "in advance this is how this pipeline looks like we can see for the training",
    "start": "1765910",
    "end": "1771160"
  },
  {
    "text": "the different input parameters you can see the logs of Duron and all those kind",
    "start": "1771160",
    "end": "1778180"
  },
  {
    "text": "of a notion",
    "start": "1778180",
    "end": "1780540"
  },
  {
    "start": "1783000",
    "end": "2045000"
  },
  {
    "text": "so I'm out of time so if you have question that's this is the time but",
    "start": "1784410",
    "end": "1790360"
  },
  {
    "text": "before that I wouldn't really want to encourage you to have a look at ml one and Emma Wong demos everything that was",
    "start": "1790360",
    "end": "1796390"
  },
  {
    "text": "shown here is we can get up it's an open source I encourage you to look at that",
    "start": "1796390",
    "end": "1801429"
  },
  {
    "text": "play with that and contribute to ml run a nucleus also an open source which you",
    "start": "1801429",
    "end": "1808419"
  },
  {
    "text": "can contribute to that as well thank you",
    "start": "1808419",
    "end": "1814110"
  },
  {
    "text": "any questions we have the two minutes no okay",
    "start": "1814919",
    "end": "1820660"
  },
  {
    "text": "encourage you to up we do encourage you to go on the sched and review the slide",
    "start": "1820660",
    "end": "1826390"
  },
  {
    "text": "and then keynotes again at 5:20 you",
    "start": "1826390",
    "end": "1831549"
  },
  {
    "text": "mentioned it as the same function can have multiple triggers I can have HTTP",
    "start": "1831549",
    "end": "1836799"
  },
  {
    "text": "trigger or it can also have event based triggers like Kafka and so on right so",
    "start": "1836799",
    "end": "1842610"
  },
  {
    "text": "how does the scaling work them does it how does it how does it rationalize",
    "start": "1842610",
    "end": "1847630"
  },
  {
    "text": "these multiple triggers so so the scaling in nuclear is based on two different aspects it can either look at",
    "start": "1847630",
    "end": "1854290"
  },
  {
    "text": "the CPU see and you can define if it's above 20% CPU 50 then scale to the next",
    "start": "1854290",
    "end": "1860860"
  },
  {
    "text": "one and it can also look at the time an event was waiting in queue until it's",
    "start": "1860860",
    "end": "1866260"
  },
  {
    "text": "being handled so you have both options and the both options is applicable for HTTP triggers and for the streaming",
    "start": "1866260",
    "end": "1876210"
  },
  {
    "text": "got one more for you so where does your data come from within your organization",
    "start": "1903779",
    "end": "1910950"
  },
  {
    "text": "do you have to pull it from many different sources a good question sorry",
    "start": "1910950",
    "end": "1916309"
  },
  {
    "text": "where does your data come from for your training within your organization do you have a data leak do you have do you pull",
    "start": "1916309",
    "end": "1923009"
  },
  {
    "text": "it from Oracle devices does it come from many different sources yeah so specifically Gua Co has a data a",
    "start": "1923009",
    "end": "1929700"
  },
  {
    "text": "fabric of its own but it can also integrate with different data layers",
    "start": "1929700",
    "end": "1935549"
  },
  {
    "text": "such as s3 local file system and others amber one is specific is not a coupled",
    "start": "1935549",
    "end": "1941190"
  },
  {
    "text": "to any type of data storage it can work with file system it can work with data frames and it can a other data elements",
    "start": "1941190",
    "end": "1949289"
  },
  {
    "text": "can be added to the abstraction layer as well so does it answer your questions it",
    "start": "1949289",
    "end": "1965039"
  },
  {
    "text": "just just a demo example the data could reside in a kv in time Sirius in any",
    "start": "1965039",
    "end": "1970350"
  },
  {
    "text": "other format it could use it for CAD files and this example in specific it",
    "start": "1970350",
    "end": "1975539"
  },
  {
    "text": "was an iris model which was the data set is come within the model itself but then you move it out to a CSV all right we",
    "start": "1975539",
    "end": "1988740"
  },
  {
    "text": "run another time we got one work",
    "start": "1988740",
    "end": "1991820"
  },
  {
    "text": "how can i I couldn't hear",
    "start": "2004670",
    "end": "2009070"
  },
  {
    "text": "five minutes maybe 20 minutes to actually start up and load and get all the data in how do you how do you deal",
    "start": "2029059",
    "end": "2035160"
  },
  {
    "text": "with that to get effective throughput",
    "start": "2035160",
    "end": "2038570"
  },
  {
    "text": "all right thank you all right well we'll finish the conversation right here thank you",
    "start": "2041210",
    "end": "2047240"
  }
]
[
  {
    "text": "all right let's go so this is my uh vaguely named talk",
    "start": "240",
    "end": "5960"
  },
  {
    "text": "where are we going with observability it's a ploy to make sure that I can disappoint you regardless of what you",
    "start": "5960",
    "end": "11400"
  },
  {
    "text": "came in for so I'm Adrian I work at elastic um and I work in open source and",
    "start": "11400",
    "end": "18760"
  },
  {
    "text": "um recently um we often in open Telemetry and uh this includes gen AI",
    "start": "18760",
    "end": "25599"
  },
  {
    "text": "we'll talk about the Gen part um and I wanted to to warn you all I'm only a few",
    "start": "25599",
    "end": "30679"
  },
  {
    "text": "months in on the bright side um I still remember pains which may be useful for",
    "start": "30679",
    "end": "36520"
  },
  {
    "text": "some of you who have just gotten started or or haven't yet yourself and um this is the agenda and",
    "start": "36520",
    "end": "44480"
  },
  {
    "text": "on on the path to disappointment I'm going to give everyone a chance to be disappointed uh throughout um dep",
    "start": "44480",
    "end": "51039"
  },
  {
    "text": "regardless of where you're coming from um you might find something boring or Too Too Deep um many chances here uh",
    "start": "51039",
    "end": "59120"
  },
  {
    "text": "we'll start with a sync on observability I'm sure people have seen many many observability talks but there might be",
    "start": "59120",
    "end": "64680"
  },
  {
    "text": "someone who hasn't um and then uh the Gen part and then we'll do it both ways",
    "start": "64680",
    "end": "71600"
  },
  {
    "text": "um okay what about observing uh generative AI systems and how do I make",
    "start": "71600",
    "end": "78040"
  },
  {
    "text": "my observability systems better with Gen and when I say make things better it doesn't necessarily mean you personally",
    "start": "78040",
    "end": "84720"
  },
  {
    "text": "make things uh plenty of vendors will sell you those things including mine um",
    "start": "84720",
    "end": "90439"
  },
  {
    "text": "but uh this is basically some things I thought were interesting to share um so this is cncf event I think",
    "start": "90439",
    "end": "98079"
  },
  {
    "text": "it's the second largest project by contributors maybe uh open to Elementry is a is a typical entry point into",
    "start": "98079",
    "end": "105719"
  },
  {
    "text": "things like um the monitoring world uh which people will hate me for saying and",
    "start": "105719",
    "end": "111360"
  },
  {
    "text": "uh particularly this works on uh specifications like what type of data is recorded um and some shared tools for",
    "start": "111360",
    "end": "118960"
  },
  {
    "text": "doing the recording like sdks and tools for using it like um you know collectors",
    "start": "118960",
    "end": "124640"
  },
  {
    "text": "and such and so the first slides would just go over some some basic stuff and I've I've been uh I'm going to reuse",
    "start": "124640",
    "end": "131840"
  },
  {
    "text": "this slide which is uh maybe seven or eight years old but hey still got it um",
    "start": "131840",
    "end": "137840"
  },
  {
    "text": "this when I was first trying to figure out um observability in in a general",
    "start": "137840",
    "end": "143000"
  },
  {
    "text": "sense um some a friend of mine uh Peter Bergen had this this approach by saying",
    "start": "143000",
    "end": "148840"
  },
  {
    "text": "like let's look at the focal areas of each of these type of signals and what do they focus on and that's a kind of a",
    "start": "148840",
    "end": "155120"
  },
  {
    "text": "as good way as any uh to to talk about these things that come up often for example um the focus of logging is is",
    "start": "155120",
    "end": "163319"
  },
  {
    "text": "like an event in fact um open Telemetry has log events literally you can you can",
    "start": "163319",
    "end": "168879"
  },
  {
    "text": "look up what that means um but basically our first program was a log statement hello world we're familiar with logs",
    "start": "168879",
    "end": "176000"
  },
  {
    "text": "everything produces them um and um but fundamentally it's it's it's one one",
    "start": "176000",
    "end": "181959"
  },
  {
    "text": "discrete thing that's happened and if there are a sequence of things that happen and they're they're related it's",
    "start": "181959",
    "end": "188120"
  },
  {
    "text": "usually by correlation maybe they have some property or or timeline in",
    "start": "188120",
    "end": "193840"
  },
  {
    "text": "general um on the other hand metric is uh focuses on aggregation so multiple",
    "start": "193840",
    "end": "200280"
  },
  {
    "text": "things at the same time so um for example if you were to do like a roll up of logs based on some field you've",
    "start": "200280",
    "end": "206920"
  },
  {
    "text": "parsed such as a service name that would an aggregation of events and maybe if it",
    "start": "206920",
    "end": "212720"
  },
  {
    "text": "had some data in there like uh size of things written then that could be uh a",
    "start": "212720",
    "end": "220200"
  },
  {
    "text": "statistic that that would show up in your metric system um the population of values that that those events",
    "start": "220200",
    "end": "227360"
  },
  {
    "text": "represent and um you know tracing is an interesting one um because this is more",
    "start": "227360",
    "end": "232920"
  },
  {
    "text": "about causality like what caused what to happen uh one of the tricky things about um logs usually is that um we're looking",
    "start": "232920",
    "end": "240239"
  },
  {
    "text": "at correlation not causality something may have happened after another thing but it may just be coincidental whereas",
    "start": "240239",
    "end": "246959"
  },
  {
    "text": "tracing has like a a hierarchical relationship usually uh where you can",
    "start": "246959",
    "end": "252200"
  },
  {
    "text": "have like this this request did cause that request not just happens to be at the same time as that request um and",
    "start": "252200",
    "end": "259720"
  },
  {
    "text": "there's an interesting um overlap if we look at both ways like of course um",
    "start": "259720",
    "end": "265240"
  },
  {
    "text": "tracing has a lot to uh to do with events um you can look at tracing",
    "start": "265240",
    "end": "270280"
  },
  {
    "text": "usually has metrics uh has a relationship to metrics through duration so um you can uh you can find some some",
    "start": "270280",
    "end": "278120"
  },
  {
    "text": "overlaps and that's why kind of observability usually has these three signals they talk about of course now we have we're talking about more things",
    "start": "278120",
    "end": "284800"
  },
  {
    "text": "like if you're a go programmer recent versions of go have have a logging API for structured events and I'm not sure",
    "start": "284800",
    "end": "291520"
  },
  {
    "text": "if it's a snark but I hope it was they call it slog you know hey wasn't me um but uh so",
    "start": "291520",
    "end": "299240"
  },
  {
    "text": "so then of course there's uh this thing you may have heard about uh continuous profiling which which is it's a neat way",
    "start": "299240",
    "end": "306120"
  },
  {
    "text": "to do uh basically samples where you can get a visibility of things down to like kernel level um without um without any",
    "start": "306120",
    "end": "314680"
  },
  {
    "text": "preparation which is quite neat um no time to talk to those things but if you're interested in that definitely",
    "start": "314680",
    "end": "319960"
  },
  {
    "text": "look more into observability if we're trying to convert one thing to another the most often thing we convert from as log because",
    "start": "319960",
    "end": "326400"
  },
  {
    "text": "that's what we have most most of if you've seen this before this is a a Rock uh pattern um and it would find ways to",
    "start": "326400",
    "end": "333520"
  },
  {
    "text": "parse things out um that then you can use those fields in other systems either to correlate or to to use as a",
    "start": "333520",
    "end": "342080"
  },
  {
    "text": "fact and you know when you have uh things pulled out of your log that you",
    "start": "342080",
    "end": "347840"
  },
  {
    "text": "that you find in common like for example the Pod name um you know anything that",
    "start": "347840",
    "end": "353400"
  },
  {
    "text": "that um that can be used to stitch these together is helpful when you're navigating your metrics or your dash",
    "start": "353400",
    "end": "359800"
  },
  {
    "text": "boards or whatever um and you do you only have a a little constraint there which is that a metric usually you can't",
    "start": "359800",
    "end": "366039"
  },
  {
    "text": "like unroll into like the million requests that made up that metric so you can't you know get take a metric and",
    "start": "366039",
    "end": "373080"
  },
  {
    "text": "turn it into a bunch of request IDs um whereas the things that are more like event based you can you can go the other",
    "start": "373080",
    "end": "379599"
  },
  {
    "text": "way with and that's why it looks a little bit asymmetric there so um the main point of these type",
    "start": "379599",
    "end": "387400"
  },
  {
    "text": "of signal talk is that we you know it's part of our job as technologist is to you know leverage strengths of tools and",
    "start": "387400",
    "end": "394000"
  },
  {
    "text": "not not be um uh you know using one thing for everything um logs are perfect",
    "start": "394000",
    "end": "400800"
  },
  {
    "text": "for things like monolist where everything is always in the same box blackboxes for the same reason when I",
    "start": "400800",
    "end": "406560"
  },
  {
    "text": "say blackbox I mean like some system you can't really affect like a a cloud platform like say if you're using um",
    "start": "406560",
    "end": "414080"
  },
  {
    "text": "Microsoft azures open AI you can't tell them to put your code inside of it the only thing you can do is like pull his",
    "start": "414080",
    "end": "420199"
  },
  {
    "text": "event Hub feed and like get some information that it's willing to tell you um those are logs right um and then",
    "start": "420199",
    "end": "426840"
  },
  {
    "text": "of course our favorite exceptions when errors happen they usually are in logs right so stack traces things like that",
    "start": "426840",
    "end": "432879"
  },
  {
    "text": "we love metrics because um you know as systems folks and platform folks we have",
    "start": "432879",
    "end": "438000"
  },
  {
    "text": "many things going on and we want to be able to understand patterns of the population of services and we need",
    "start": "438000",
    "end": "444000"
  },
  {
    "text": "something to use for an alerting system and and it's would be T tedious to like look at every single request and decide",
    "start": "444000",
    "end": "450879"
  },
  {
    "text": "uh individually uh so that's why we use metrics and then of course if we're if we're drilling down into particular um",
    "start": "450879",
    "end": "458080"
  },
  {
    "text": "uh causal investigations traces are pretty help helpful so traditionally observability focuses on on uh",
    "start": "458080",
    "end": "464960"
  },
  {
    "text": "collecting these things and primary signals and if you're using traditional tools then you're choosing your",
    "start": "464960",
    "end": "470599"
  },
  {
    "text": "dashboards and maybe choosing fields to put into them and those things based on what you care most about in your in your",
    "start": "470599",
    "end": "476639"
  },
  {
    "text": "particular uh context if you hear this work called instrumentation it usually means you're doing a lot of work it's",
    "start": "476639",
    "end": "483120"
  },
  {
    "text": "like adding agents to collect things and and uh you know maybe that's that's um",
    "start": "483120",
    "end": "488520"
  },
  {
    "text": "not a huge amount of work but usually there's some work involved um and uh regardless we're going to get logs um",
    "start": "488520",
    "end": "494639"
  },
  {
    "text": "but but the traditional problem uh people face is is getting something useful out of",
    "start": "494639",
    "end": "500840"
  },
  {
    "text": "them now I'm going to switch to gen AI so geni uh is a part of AI and I'll kind",
    "start": "500840",
    "end": "509000"
  },
  {
    "text": "of tease that out a little bit more later but if you wanted to know where to look for a place that does a good job",
    "start": "509000",
    "end": "515240"
  },
  {
    "text": "talking about this from a point of expertise instead of like a three- monther uh you go to the cncf tag",
    "start": "515240",
    "end": "521800"
  },
  {
    "text": "runtime now that's the same runtime for kubernetes itself so it's an interesting thing the coupling there so cncf decided",
    "start": "521800",
    "end": "527680"
  },
  {
    "text": "to put the AI working group inside the runtime tag and there's some interesting",
    "start": "527680",
    "end": "533080"
  },
  {
    "text": "side effects to that um and uh so um I think a lot of people could do worse",
    "start": "533080",
    "end": "539000"
  },
  {
    "text": "than than look at those docks anyway I'll go through any my version of it so",
    "start": "539000",
    "end": "544440"
  },
  {
    "text": "gen means generative because we found like ter Terminator AI is not a good",
    "start": "544440",
    "end": "549600"
  },
  {
    "text": "path so we want to generate not terminate um so that's the first point",
    "start": "549600",
    "end": "555040"
  },
  {
    "text": "um and what it's generating is new data Based on data that's that it's knows about right so um another interesting",
    "start": "555040",
    "end": "561279"
  },
  {
    "text": "thing is that if you take a generative model um and you try kind of like go down uh like classification narrowing",
    "start": "561279",
    "end": "568880"
  },
  {
    "text": "causal language model is a form of generative model that goes in One Direction and predicts words so you can",
    "start": "568880",
    "end": "574800"
  },
  {
    "text": "think of like autoc completion is the most uh fundamental type of prediction",
    "start": "574800",
    "end": "581399"
  },
  {
    "text": "um but there's plenty of different things uh the word llm uh which is thrown around a lot is large language",
    "start": "581399",
    "end": "587720"
  },
  {
    "text": "model so that's a kind of Cal model which is a kind of generative model and that's used to perform functions like",
    "start": "587720",
    "end": "593040"
  },
  {
    "text": "chat and co- completion and other things um and so if you were like you know",
    "start": "593040",
    "end": "599399"
  },
  {
    "text": "interesting and esoteric geography and you wanted to know about this buet island um and you could ask the the llm",
    "start": "599399",
    "end": "608120"
  },
  {
    "text": "uh and it could it could it could answer you as a role of assistant and say uh",
    "start": "608120",
    "end": "613959"
  },
  {
    "text": "you know if if it's correct it was a South Atlantic Ocean and that would be something it could answer if there was",
    "start": "613959",
    "end": "619360"
  },
  {
    "text": "some data about geography and um that it had seen before um we sometimes use the",
    "start": "619360",
    "end": "625399"
  },
  {
    "text": "word training imprecisely it doesn't mean it was trained on geography it just means that that has seen data with",
    "start": "625399",
    "end": "631279"
  },
  {
    "text": "geography in it and um while that's kind of just Nuance it's kind of useful to",
    "start": "631279",
    "end": "636519"
  },
  {
    "text": "know that so this is introducing two primary things of of llm tools in",
    "start": "636519",
    "end": "642040"
  },
  {
    "text": "general which is that their roles user and assistant are always there so when you say like AI assistant it could mean",
    "start": "642040",
    "end": "649399"
  },
  {
    "text": "anything from chat or something that uses an llm assistant is is a word",
    "start": "649399",
    "end": "655480"
  },
  {
    "text": "that's that's common in that jargon um what we like about llms often is that",
    "start": "655480",
    "end": "662800"
  },
  {
    "text": "they know what we mean like I can't um write a SQL query and have it just like",
    "start": "662800",
    "end": "668560"
  },
  {
    "text": "understand oh I just misspelled this column like and even worse if I try to",
    "start": "668560",
    "end": "673959"
  },
  {
    "text": "uh use the wrong syntax it would fail right these are strict systems whereas uh in llm there's a statistical",
    "start": "673959",
    "end": "680959"
  },
  {
    "text": "relationship with misspelled words to the correctly spelled ones and so that's why things like chat kind of work",
    "start": "680959",
    "end": "686959"
  },
  {
    "text": "themselves out and uh can compensate own slightly off input and they're they're pretty helpful for user based systems",
    "start": "686959",
    "end": "692760"
  },
  {
    "text": "for that reason too um they often know multiple languages quen is a um large language",
    "start": "692760",
    "end": "699519"
  },
  {
    "text": "model that that's free download Apache licensed from Alibaba and that one knows",
    "start": "699519",
    "end": "704720"
  },
  {
    "text": "dozens of written languages so if you wanted it to respond back and forth",
    "start": "704720",
    "end": "711480"
  },
  {
    "text": "about a topic that was that had seen in English it's perfectly happy to do that this happens to be Malay I I used to",
    "start": "711480",
    "end": "718079"
  },
  {
    "text": "live in Malaysia um and uh one of the funny uh tricky",
    "start": "718079",
    "end": "724440"
  },
  {
    "text": "spots of llms that people talk about often is hallucination uh and this is where you",
    "start": "724440",
    "end": "729800"
  },
  {
    "text": "get some nonsense responses or just something that's assertively said factually Incorrect and that's because",
    "start": "729800",
    "end": "736360"
  },
  {
    "text": "they uh LM does not necessarily know the difference between correct uh or not it",
    "start": "736360",
    "end": "741720"
  },
  {
    "text": "just has a statistical relationship um and where something's missing it may",
    "start": "741720",
    "end": "746959"
  },
  {
    "text": "just fill the gaps like if you put somebody on the spot you know there's different ways someone could respond to",
    "start": "746959",
    "end": "752120"
  },
  {
    "text": "that they can make something off or they could you know sh they don't they don't often say no I don't know but they you",
    "start": "752120",
    "end": "758800"
  },
  {
    "text": "know anyway there's some mitigation approaches to this um different models uh have U more uh data in different",
    "start": "758800",
    "end": "765839"
  },
  {
    "text": "areas that they were trained with and also the amount of parameters that the",
    "start": "765839",
    "end": "770880"
  },
  {
    "text": "the model is uh has uh which has a direct relationship to usage but uh that",
    "start": "770880",
    "end": "776360"
  },
  {
    "text": "can help with it there many approaches but uh basic basically if you were to talk about buet Island and ask where the",
    "start": "776360",
    "end": "782320"
  },
  {
    "text": "capital is well there's no Capital it's just Penguins there uh I use this as example because I used to work at Netflix and we were working on DNS",
    "start": "782320",
    "end": "789360"
  },
  {
    "text": "Technology we're thinking what's an ISO code that's actually defined that has no permanent",
    "start": "789360",
    "end": "795000"
  },
  {
    "text": "population and uh so we would you know in our test black hole this island but",
    "start": "795000",
    "end": "800600"
  },
  {
    "text": "um don't worry it was never PR to count but it was just fun um the other thing weird about llms",
    "start": "800600",
    "end": "807880"
  },
  {
    "text": "is that that there's no relation ship between like a new llm and the data that",
    "start": "807880",
    "end": "813399"
  },
  {
    "text": "it's been trained on unless they say it in the docs um and so you could say like",
    "start": "813399",
    "end": "819800"
  },
  {
    "text": "okay well meta Facebook have a llm that they they call llama and like llama 3.2",
    "start": "819800",
    "end": "826959"
  },
  {
    "text": "comes out or whatever and you're like wow it's out so finally it knows like about the last World Series no it it",
    "start": "826959",
    "end": "833639"
  },
  {
    "text": "just means that this is a new has new features it may be super smart but it has nothing to do with the the um the",
    "start": "833639",
    "end": "840720"
  },
  {
    "text": "data unless it says so and there's this concept called knowledge cut off and um",
    "start": "840720",
    "end": "846800"
  },
  {
    "text": "and then there's a strange twist to this which is that the llm itself May hallucinate if you ask it about its",
    "start": "846800",
    "end": "852800"
  },
  {
    "text": "knowledge cut off and just give you a nonsense answer so uh you basically unfortunately need to read the docs if",
    "start": "852800",
    "end": "859759"
  },
  {
    "text": "you care about that now um what we usually use for an approach uh to put",
    "start": "859759",
    "end": "865839"
  },
  {
    "text": "new knowledge or private knowledge into into a a large language model is to",
    "start": "865839",
    "end": "871160"
  },
  {
    "text": "retrieve it from somewhere and then augment it by putting this in in the context of our question like what's the",
    "start": "871160",
    "end": "878279"
  },
  {
    "text": "latest of go and then attachment of like the release notes um that type of",
    "start": "878279",
    "end": "883839"
  },
  {
    "text": "approach is typically called Rog but there's many many different nuances of how to put things into context so the LM",
    "start": "883839",
    "end": "890560"
  },
  {
    "text": "might know more information or private information um that that it hadn't seen in its uh training",
    "start": "890560",
    "end": "899320"
  },
  {
    "text": "so uh you know with that word assistant gen is frequently used for assistant and assisting us um and that's the thing",
    "start": "899880",
    "end": "907279"
  },
  {
    "text": "that that leverages the strengths because you know when you're dealing with assisting humans they misspell",
    "start": "907279",
    "end": "913079"
  },
  {
    "text": "things they talk in different languages and stuff like that um they may have different knowledge that they are",
    "start": "913079",
    "end": "919199"
  },
  {
    "text": "supposed to be uh having as as an implicit um and also I didn't talk about",
    "start": "919199",
    "end": "925519"
  },
  {
    "text": "it yet but llms can be quite uh slow as compared to like a database query uh so you could could be spending 30 seconds",
    "start": "925519",
    "end": "932279"
  },
  {
    "text": "to get an answer and uh but if the human decides that there's enough value there they're going to be okay with that just",
    "start": "932279",
    "end": "938519"
  },
  {
    "text": "just make sure that they see the ticking thing um so finally we've covered the",
    "start": "938519",
    "end": "944639"
  },
  {
    "text": "first two topics let's try to connect them so observability and",
    "start": "944639",
    "end": "949800"
  },
  {
    "text": "gen um so like I said in the beginning we can do it both ways uh if we're",
    "start": "949800",
    "end": "956399"
  },
  {
    "text": "talking about uh AI observ ability then we're talking about monitoring sorry uh",
    "start": "956399",
    "end": "963040"
  },
  {
    "text": "and if we're talking about observability with AI we're talking about like making our our stuff better by using um",
    "start": "963040",
    "end": "969839"
  },
  {
    "text": "technology that is that's employing llms for example inside of the um Network",
    "start": "969839",
    "end": "975639"
  },
  {
    "text": "architecture of it so let's start with uh observability of the AI stuff um one",
    "start": "975639",
    "end": "982360"
  },
  {
    "text": "thing that's very scary is people say like okay I've got gen and like now I need to like hire million people because",
    "start": "982360",
    "end": "988199"
  },
  {
    "text": "nobody knows about this stuff and if you think of it like this like open AI is is fundamentally a rest API we have used",
    "start": "988199",
    "end": "995040"
  },
  {
    "text": "rest apis before um so it's just a stack of Technology of course it's an",
    "start": "995040",
    "end": "1000959"
  },
  {
    "text": "interesting like weird thing in the middle of it but it's still an HTTP service and we can treat it like an HTTP",
    "start": "1000959",
    "end": "1008560"
  },
  {
    "text": "Service as an observability system maybe the fields we use are are different but",
    "start": "1008560",
    "end": "1014759"
  },
  {
    "text": "um what you'll notice is instead of blaming the database you can blame the llm so that's basically what we need to",
    "start": "1014759",
    "end": "1020040"
  },
  {
    "text": "get to right yeah so that big that big line there is a is a call to an llm to",
    "start": "1020040",
    "end": "1027760"
  },
  {
    "text": "answer a question from a flask route at the top there's no reason why you should think of a app that has gen in it any",
    "start": "1027760",
    "end": "1035038"
  },
  {
    "text": "different than you do your other stuff but then I kind of lied a little bit there are some things that are",
    "start": "1035039",
    "end": "1041880"
  },
  {
    "text": "important about gen with observability and part of it is because of the way that the community Works um if you think",
    "start": "1041880",
    "end": "1048079"
  },
  {
    "text": "about it like geni is sort of like more close to data science and machine",
    "start": "1048079",
    "end": "1053760"
  },
  {
    "text": "learning than it is to like system and platform engineering and there's also um",
    "start": "1053760",
    "end": "1059880"
  },
  {
    "text": "a reality of of like accuracy and interest and evaluating different types",
    "start": "1059880",
    "end": "1065000"
  },
  {
    "text": "of responses there so sometimes the users themselves and the developers will have different needs than the",
    "start": "1065000",
    "end": "1070600"
  },
  {
    "text": "traditional observability platform will have been set up for um so Lang Trace is",
    "start": "1070600",
    "end": "1076039"
  },
  {
    "text": "a uh is an open source product and and one of the Founders there I collaborate with in the Petry uh Sig and and I asked",
    "start": "1076039",
    "end": "1083760"
  },
  {
    "text": "whether there are three pillars of of observability for Gen and the tracing is",
    "start": "1083760",
    "end": "1090120"
  },
  {
    "text": "is certainly interesting and I'll just call out the thing that's that's different um basically success rate uh",
    "start": "1090120",
    "end": "1097679"
  },
  {
    "text": "is subjective right uh did the did the request complete successfully like http2",
    "start": "1097679",
    "end": "1103039"
  },
  {
    "text": "200 was it actually the answer that was helpful or not are two different answers right um also cost um because uh I wish",
    "start": "1103039",
    "end": "1112280"
  },
  {
    "text": "I I I wish I saved the tweet in a way besides clicking on it but um basically I saw something where someone had a a",
    "start": "1112280",
    "end": "1119200"
  },
  {
    "text": "geni project and they decided not to run CI for a pretty good reason because every every CI run would cost them 20",
    "start": "1119200",
    "end": "1126600"
  },
  {
    "text": "bucks and uh so there could be some significant costs um this idea of",
    "start": "1126600",
    "end": "1133320"
  },
  {
    "text": "evaluations where you have a system where for example this assistant is coming back with with responses",
    "start": "1133320",
    "end": "1139760"
  },
  {
    "text": "sometimes to the same question and you want to figure out what is the accurate like what was the precise answer and um",
    "start": "1139760",
    "end": "1148120"
  },
  {
    "text": "so that can be evaluated in terms of automation like maybe another llm is is",
    "start": "1148120",
    "end": "1154840"
  },
  {
    "text": "supposed to inspect the question and the answer and and make a score about whether it was you know likely to be",
    "start": "1154840",
    "end": "1161080"
  },
  {
    "text": "useful or not and it could also be a user feedback loop and if it's in a feedback loop then what could happen is",
    "start": "1161080",
    "end": "1166360"
  },
  {
    "text": "that that data could be fed back into um a data set which then could be used to",
    "start": "1166360",
    "end": "1171440"
  },
  {
    "text": "kind of improve the next um type of questions and that's a very rich experience if you think about it from",
    "start": "1171440",
    "end": "1178559"
  },
  {
    "text": "from a um observability standpoint versus a typical um like",
    "start": "1178559",
    "end": "1186280"
  },
  {
    "text": "chart um some more stuff just because you know I've got it on here might as well say uh some challenges that i' I've",
    "start": "1186679",
    "end": "1194200"
  },
  {
    "text": "noticed is that uh open AI is like the Behemoth like it's like Amazon used to",
    "start": "1194200",
    "end": "1199440"
  },
  {
    "text": "be uh for for cloud sorry Amazon and that that means that like everybody",
    "start": "1199440",
    "end": "1205000"
  },
  {
    "text": "anchors things towards what openi does even though it's actually a quite diverse ecosystem there's many many many",
    "start": "1205000",
    "end": "1210919"
  },
  {
    "text": "many model providers and Frameworks and things like that and so it's easy to anchor on what open AI does uh uh and",
    "start": "1210919",
    "end": "1219640"
  },
  {
    "text": "that could be over anchoring um the other thing is that because not all the features are actually in a public issues",
    "start": "1219640",
    "end": "1225840"
  },
  {
    "text": "list um you don't necessarily know what's going to released until someone already releases it and because it's a",
    "start": "1225840",
    "end": "1231720"
  },
  {
    "text": "very fast moving environment that can lead to users demanding something that's only days or hours old and so that's",
    "start": "1231720",
    "end": "1238880"
  },
  {
    "text": "kind of for for platform engineering that's a challenge um to kind of um keep",
    "start": "1238880",
    "end": "1244120"
  },
  {
    "text": "up with these feature demands that are that are happening that that fast the other thing interesting for",
    "start": "1244120",
    "end": "1249799"
  },
  {
    "text": "observability is that the uh because of this evaluation system it implies you're",
    "start": "1249799",
    "end": "1254960"
  },
  {
    "text": "collecting request and response data which has of course the normal things you would expect you have uh pii",
    "start": "1254960",
    "end": "1261520"
  },
  {
    "text": "concerns you have volume concerns and and again from the Netflix example back",
    "start": "1261520",
    "end": "1267320"
  },
  {
    "text": "in the day if I asked somebody to to make the request response system it would cost more than playing the movies",
    "start": "1267320",
    "end": "1273520"
  },
  {
    "text": "so you have to be careful with things of course it doesn't mean every request is going to result in an LM request or that",
    "start": "1273520",
    "end": "1279320"
  },
  {
    "text": "the rate of those that makes this a big problem but it's it's something that's anchoring uh while I didn't talk about",
    "start": "1279320",
    "end": "1286120"
  },
  {
    "text": "this idea of token if you think about like any machine like you got quarters to play the game you could use tokens to",
    "start": "1286120",
    "end": "1292640"
  },
  {
    "text": "play the game um token is like a a metering unit in in uh llms both the",
    "start": "1292640",
    "end": "1299120"
  },
  {
    "text": "input and the output and it's typically how things are built as well and because these are spend metrics and it doesn't",
    "start": "1299120",
    "end": "1305520"
  },
  {
    "text": "matter if it's text or video or audio token is is the is the way um people are",
    "start": "1305520",
    "end": "1312240"
  },
  {
    "text": "often wanting to see that while they're acting and you can see this if you actually were to go to chat GPT it will",
    "start": "1312240",
    "end": "1318799"
  },
  {
    "text": "tell you the tokens that are that are being used and so with a typical um",
    "start": "1318799",
    "end": "1324120"
  },
  {
    "text": "Telemetry setup you have a asynchronous relationship with Statistics is shipping the data out you know and then you've",
    "start": "1324120",
    "end": "1330000"
  },
  {
    "text": "got some stuff going on um in this case it's not like the first time this has ever happened but there's a um anchoring",
    "start": "1330000",
    "end": "1336480"
  },
  {
    "text": "towards like seeing seeing what what I'm spending kind of in terms of",
    "start": "1336480",
    "end": "1341600"
  },
  {
    "text": "tokens um and so that makes it a very interesting spend system and bis metric all at the same time",
    "start": "1341600",
    "end": "1348760"
  },
  {
    "text": "um the other thing is that just that like uh I I remember when I first started in the Sig people were talking about like how many months one vendor",
    "start": "1348760",
    "end": "1355840"
  },
  {
    "text": "was older than the other vendor so like it's a fairly new space and there aren't",
    "start": "1355840",
    "end": "1362120"
  },
  {
    "text": "really a lot of common tools with regards to observability uh and that's that's a work in progress um but uh so",
    "start": "1362120",
    "end": "1369200"
  },
  {
    "text": "it's not as mature there uh on the other hand to compensate for that if you think of it just as a web request system then",
    "start": "1369200",
    "end": "1375640"
  },
  {
    "text": "uh you have plenty of tools that you can use they don't have to be specialized necessarily and the last point is this",
    "start": "1375640",
    "end": "1381159"
  },
  {
    "text": "thing that like accuracy I kind of touched on that it's subjective um whether the risk request was was correct",
    "start": "1381159",
    "end": "1388279"
  },
  {
    "text": "or not and also the same type of response could be correct in one scenario but not another so that's why",
    "start": "1388279",
    "end": "1394400"
  },
  {
    "text": "you're going to see a lot of evaluation type stuff coming up so let's go the other way um now",
    "start": "1394400",
    "end": "1401640"
  },
  {
    "text": "we've got any system doesn't have to be llm uh ba based thing that we're looking",
    "start": "1401640",
    "end": "1407880"
  },
  {
    "text": "at could be just normal web request database which is always the slow part right um how do we make that better how",
    "start": "1407880",
    "end": "1414559"
  },
  {
    "text": "do we blame things better with Gen right so um we can use gen in many different",
    "start": "1414559",
    "end": "1420159"
  },
  {
    "text": "ways and when I say we can there are you know these are already done so I say like where are we going where are we",
    "start": "1420159",
    "end": "1426559"
  },
  {
    "text": "going is not universally you know converged and never is um but um first",
    "start": "1426559",
    "end": "1433559"
  },
  {
    "text": "is assistant uh you can assist with tools right so uh any tool that that that needs setup uh the AI could",
    "start": "1433559",
    "end": "1440640"
  },
  {
    "text": "possibly help even perform those setup tasks for you um anything like uh",
    "start": "1440640",
    "end": "1447400"
  },
  {
    "text": "pattern extracting and such uh you can use typical AI you can also use uh generative AI with um things like",
    "start": "1447400",
    "end": "1455039"
  },
  {
    "text": "configuring data feeds so if you have uh I'll go into some examples of this and then the one of the things that would be",
    "start": "1455039",
    "end": "1461400"
  },
  {
    "text": "probably more unique than the other ones is um linking human created stuff with",
    "start": "1461400",
    "end": "1467000"
  },
  {
    "text": "your system created stuff so if you have inconsistently labeled things if you have uh uh help desk tickets written by",
    "start": "1467000",
    "end": "1474159"
  },
  {
    "text": "humans that have like a not a very strong relationship to to particular",
    "start": "1474159",
    "end": "1479640"
  },
  {
    "text": "like system entities um those relationships could be built with Gen",
    "start": "1479640",
    "end": "1484840"
  },
  {
    "text": "even if they're in different languages um and going back to logs um",
    "start": "1484840",
    "end": "1490399"
  },
  {
    "text": "if we think of it this way you know AI could be a way to get more out of them um you know we do know that log start",
    "start": "1490399",
    "end": "1497480"
  },
  {
    "text": "before everything including things like tracing so there there are maybe maybe some untapped parts of observability",
    "start": "1497480",
    "end": "1504120"
  },
  {
    "text": "that that could be looked at in a different way and um I went to cubican China and one of the things I I forgot",
    "start": "1504120",
    "end": "1511399"
  },
  {
    "text": "the tech that I was uh listening to but they were saying like you know we want to use gen because like all these",
    "start": "1511399",
    "end": "1518080"
  },
  {
    "text": "plugins are changing their log formats like there's so many plugins so many different things and they're not",
    "start": "1518080",
    "end": "1523520"
  },
  {
    "text": "required to coordinate in any way and of course the plugin could have a major version and you wouldn't know like you",
    "start": "1523520",
    "end": "1529600"
  },
  {
    "text": "just see that the log format changed so these are cases where um it could be Cloud native problem but um it's not",
    "start": "1529600",
    "end": "1537120"
  },
  {
    "text": "exclusively right but um and then of course if you do have the ability to to bring more knowledge into the into",
    "start": "1537120",
    "end": "1543760"
  },
  {
    "text": "context like source code you can cross check that U I have a friend of mine who I won't mention because I don't want to",
    "start": "1543760",
    "end": "1549480"
  },
  {
    "text": "get them in trouble but they work at SharePoint they said that like the entire SharePoint source code is in",
    "start": "1549480",
    "end": "1555080"
  },
  {
    "text": "context in the SharePoint team I don't know if that's completely factual but I'm going to take it because it sounds",
    "start": "1555080",
    "end": "1561960"
  },
  {
    "text": "cool um let's look at some examples so one thing uh I just happened upon recently is this thing called case GPT",
    "start": "1561960",
    "end": "1569440"
  },
  {
    "text": "and um it's a fairly new project um but what it does is you have different types",
    "start": "1569440",
    "end": "1575440"
  },
  {
    "text": "of things that can um process events like for example if you are familiar",
    "start": "1575440",
    "end": "1580840"
  },
  {
    "text": "with trivy or any of the other um type of vulnerability and misconfiguration tools it will say like okay this and",
    "start": "1580840",
    "end": "1588039"
  },
  {
    "text": "this cve or something like that or or whatever but like what's the first thing you do you kind of like take that and",
    "start": "1588039",
    "end": "1594440"
  },
  {
    "text": "you you Duck Duck Go or Brave or whatever your favorite search engine is and you try to figure out what the heck",
    "start": "1594440",
    "end": "1599679"
  },
  {
    "text": "that is so contextualizing these type codes and and anything else um would be",
    "start": "1599679",
    "end": "1606120"
  },
  {
    "text": "helpful if you already know Kates what if you don't know Kates what if you don't even know Docker and you get an an",
    "start": "1606120",
    "end": "1611559"
  },
  {
    "text": "a question like back off pulling image so like for me I think the first",
    "start": "1611559",
    "end": "1617399"
  },
  {
    "text": "time I saw back off off pulling I'm like what um so this can rephrase that and",
    "start": "1617399",
    "end": "1623520"
  },
  {
    "text": "saying like well there be may be an image that doesn't exist or you don't have connectivity to it maybe you should",
    "start": "1623520",
    "end": "1629840"
  },
  {
    "text": "check Docker because this is like probably Docker um so like what kind of image is it was that an EG like no this",
    "start": "1629840",
    "end": "1637200"
  },
  {
    "text": "is probably a Docker image because in context of Kates that's what it is right so I'm not saying that like every day you're going to have a problem like this",
    "start": "1637200",
    "end": "1643080"
  },
  {
    "text": "but it's I thought it was a pretty interesting um project um I work at elastic we have",
    "start": "1643080",
    "end": "1648399"
  },
  {
    "text": "kibana which is basically a you know monitoring management portal thing and",
    "start": "1648399",
    "end": "1654760"
  },
  {
    "text": "uh there's actually several uh AI assistants in there and actually the cool thing is is that it's uh the the",
    "start": "1654760",
    "end": "1661159"
  },
  {
    "text": "source is there so you can go to elastic Cabana you can see actually how these things work um but uh there's an AI",
    "start": "1661159",
    "end": "1667880"
  },
  {
    "text": "assistant and it can do things like integrate with um your ticketing system and everything else and try to explain",
    "start": "1667880",
    "end": "1674600"
  },
  {
    "text": "what's on the screen uh in terms that that would be easier to understand if you didn't if you weren't like an expert",
    "start": "1674600",
    "end": "1680799"
  },
  {
    "text": "yet and can also do things like uh create run books for you and and make",
    "start": "1680799",
    "end": "1686480"
  },
  {
    "text": "reports um one of the assistants is this thing called automatic import which again you can just take a look at the",
    "start": "1686480",
    "end": "1692000"
  },
  {
    "text": "source if you're that kind of person um but what this does is it um basically",
    "start": "1692000",
    "end": "1698960"
  },
  {
    "text": "you can say like here's an S3 bucket full of logs and this is representative of the data that I'm importing and it",
    "start": "1698960",
    "end": "1705399"
  },
  {
    "text": "can try to um extract fields from that to kind of set up a data uh data",
    "start": "1705399",
    "end": "1711000"
  },
  {
    "text": "integration for you so um when we think of assistance often times we're talking we're thinking about chat assistance but",
    "start": "1711000",
    "end": "1717039"
  },
  {
    "text": "there are many types of assistance and configuration assistance is another type of thing um and then I want to say like",
    "start": "1717039",
    "end": "1724039"
  },
  {
    "text": "observability with AI isn't always geni um forgive me for not remembering the company out there but one of the",
    "start": "1724039",
    "end": "1730000"
  },
  {
    "text": "sponsors uh says like you know observability with AI and um there's no",
    "start": "1730000",
    "end": "1736120"
  },
  {
    "text": "reason why everything has to be uh geni so we've been using AI for years things",
    "start": "1736120",
    "end": "1741600"
  },
  {
    "text": "like um prediction and uh trying to take something that is high cardinality like",
    "start": "1741600",
    "end": "1747919"
  },
  {
    "text": "a HTTP request with a uid in it and try to reduce the cardinality by recognizing patterns machine learning models have",
    "start": "1747919",
    "end": "1755039"
  },
  {
    "text": "been doing these for years it's form of AI um not everything is AI but let's",
    "start": "1755039",
    "end": "1760559"
  },
  {
    "text": "let's talk about like one specific case now I'm I'm click clicking a Blog here not just because of my company but you",
    "start": "1760559",
    "end": "1767200"
  },
  {
    "text": "can blame that uh but also I think it's interesting um which is that um we have other models right that you can run um",
    "start": "1767200",
    "end": "1774519"
  },
  {
    "text": "Bert is a bir directional model so it's not unidirectional caal model like a like an llm and uh it can do thing",
    "start": "1774519",
    "end": "1782279"
  },
  {
    "text": "called named entity recognition and so in this case it can try to figure out like say if you were to use this type of",
    "start": "1782279",
    "end": "1788679"
  },
  {
    "text": "model it could like if in text it could figure out something as a a country or a city or a person things like that",
    "start": "1788679",
    "end": "1796000"
  },
  {
    "text": "classifications and um you can you can use this in a pipeline uh to to like do",
    "start": "1796000",
    "end": "1802559"
  },
  {
    "text": "things like redaction and so primarily in this case it's not really gen in this",
    "start": "1802559",
    "end": "1808279"
  },
  {
    "text": "AI system but there are some places where you could use gen to um play with",
    "start": "1808279",
    "end": "1813440"
  },
  {
    "text": "it even more for example uh if you're thinking about uh pi pii and what if",
    "start": "1813440",
    "end": "1819039"
  },
  {
    "text": "your your job is like a messager app like you have people who are writing messages and like you're not sure",
    "start": "1819039",
    "end": "1824919"
  },
  {
    "text": "whether something is pi because they're using a bunch of slang and not necessarily something that this pipeline",
    "start": "1824919",
    "end": "1830080"
  },
  {
    "text": "will be great at identifying but uh an llm might be better at identifying or",
    "start": "1830080",
    "end": "1835360"
  },
  {
    "text": "you want to check and see if something is technically sensitive but not sens not sensitive in context or vice versa",
    "start": "1835360",
    "end": "1842240"
  },
  {
    "text": "so you can kind of like you a person not you necessarily uh but uh someone can",
    "start": "1842240",
    "end": "1848600"
  },
  {
    "text": "can make a system like that mixing and matching so anyway let's close up um and",
    "start": "1848600",
    "end": "1855799"
  },
  {
    "text": "uh so basically my opinion uh gen is more about humans than other sorts of AI",
    "start": "1855799",
    "end": "1862639"
  },
  {
    "text": "in many ways uh because there's Nuance of of language is captured um they don't",
    "start": "1862639",
    "end": "1868440"
  },
  {
    "text": "require hiring an ml team to run or or use uh so they're actually a little bit",
    "start": "1868440",
    "end": "1874440"
  },
  {
    "text": "more human friendly um and uh you're going to find more of these things um",
    "start": "1874440",
    "end": "1879799"
  },
  {
    "text": "doing uh laborious tasks or or tedious ones such as like recot calls",
    "start": "1879799",
    "end": "1884960"
  },
  {
    "text": "analysis um and flex with things that are are also uh quite tedious or even um",
    "start": "1884960",
    "end": "1890919"
  },
  {
    "text": "vexing to deal with like uh changing log formats and such um if you think about",
    "start": "1890919",
    "end": "1896639"
  },
  {
    "text": "like when we're collecting metrics nowadays sometimes you may have uh like",
    "start": "1896639",
    "end": "1903360"
  },
  {
    "text": "100 attributes that are defined on something and you can't necessarily like keep in your mind what all these things",
    "start": "1903360",
    "end": "1909519"
  },
  {
    "text": "are for whereas there's not really a limitation there with an AI system um so",
    "start": "1909519",
    "end": "1916159"
  },
  {
    "text": "um and then of course non-tradition effects which makes it a little bit more creative and interesting as a as a uh",
    "start": "1916159",
    "end": "1921840"
  },
  {
    "text": "platform architect when you can bring in things that are non-traditional sources you have more more ways uh to to solve a",
    "start": "1921840",
    "end": "1930200"
  },
  {
    "text": "problem than you did um and I I've put some some links here again uh these aren't link links because I I didn't",
    "start": "1930200",
    "end": "1937080"
  },
  {
    "text": "want to like uh shower this with QR codes but anyway you can you can just",
    "start": "1937080",
    "end": "1942559"
  },
  {
    "text": "these terms will get you where you need to go and and if you have a problem with that take a screenshot and then put it",
    "start": "1942559",
    "end": "1948120"
  },
  {
    "text": "in the LM um but anyway thanks for thanks for your time and I I think I'm out of time",
    "start": "1948120",
    "end": "1955000"
  },
  {
    "text": "maybe yep so um but anyways a coffee break if you want to grab me later that's cool too thanks for uh all of",
    "start": "1955000",
    "end": "1962360"
  },
  {
    "text": "your attention",
    "start": "1962360",
    "end": "1966360"
  }
]
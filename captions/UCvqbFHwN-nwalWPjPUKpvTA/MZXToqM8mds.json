[
  {
    "text": "welcome to the vtest maintainer",
    "start": "160",
    "end": "5000"
  },
  {
    "text": "talk my name is dpti sigi I'm the technical lead for the vus open source",
    "start": "5520",
    "end": "11120"
  },
  {
    "text": "project and I'm the vus engineering lead at Planet",
    "start": "11120",
    "end": "16240"
  },
  {
    "text": "scale I'm Derek Perkins CEO of",
    "start": "16439",
    "end": "20840"
  },
  {
    "text": "nozzle and my name is sui and I'm from back",
    "start": "23080",
    "end": "28560"
  },
  {
    "text": "place today we'll start with a witus overview that Derek will give us and",
    "start": "28640",
    "end": "34079"
  },
  {
    "text": "then sui will talk about production deployment of witus at back plays then",
    "start": "34079",
    "end": "39680"
  },
  {
    "text": "I'll come back to talk about new and upcoming features in Vitus and then we'll do a Q&A if there are any",
    "start": "39680",
    "end": "46239"
  },
  {
    "text": "questions at that",
    "start": "46239",
    "end": "49038"
  },
  {
    "text": "point so v test why would you choose to run vest obviously sharding is the",
    "start": "51559",
    "end": "58719"
  },
  {
    "text": "number one feature that people think think about when they think about the tests and let's talk about what are the",
    "start": "58719",
    "end": "64360"
  },
  {
    "text": "problems you're facing with your existing MySQL setup that might make you think oh sharding the test might be a",
    "start": "64360",
    "end": "70640"
  },
  {
    "text": "solution first backup restore times for your Disaster Recovery uh the bigger",
    "start": "70640",
    "end": "76240"
  },
  {
    "text": "your disc the longer physics requires for you to move that data around uh and do the whole backup process right",
    "start": "76240",
    "end": "83600"
  },
  {
    "text": "contention uh is important to deal with deadlocks is a related uh problem that",
    "start": "83600",
    "end": "89479"
  },
  {
    "text": "you'll be facing sping as you have more and more writers uh the despite how many CPUs you scale it to you're going to be",
    "start": "89479",
    "end": "96360"
  },
  {
    "text": "limited by uh table contention uh iops especially if you're on the cloud uh you're going to be",
    "start": "96360",
    "end": "102600"
  },
  {
    "text": "limited with the number of iops writing to your discs and one of the first things that",
    "start": "102600",
    "end": "108360"
  },
  {
    "text": "you're going to do to offload some of your uh load is to start adding read",
    "start": "108360",
    "end": "114240"
  },
  {
    "text": "replicas which brings up a couple of issues uh depend the more you're writing",
    "start": "114240",
    "end": "119479"
  },
  {
    "text": "the harder it is for replication to keep up my sql's made some strides recently",
    "start": "119479",
    "end": "124600"
  },
  {
    "text": "to enable some better parallel writing um but it's still generally is a lot",
    "start": "124600",
    "end": "131400"
  },
  {
    "text": "slower than uh writing to your primary and then eventual consistency for me this is one of the biggest concerns that",
    "start": "131400",
    "end": "138800"
  },
  {
    "text": "I see database wise around is because once you start moving to a",
    "start": "138800",
    "end": "144560"
  },
  {
    "text": "read replica now every single app developer that you have has to understand eventual",
    "start": "144560",
    "end": "150360"
  },
  {
    "text": "consistency and distributed systems are difficult and so but again if you're",
    "start": "150360",
    "end": "157040"
  },
  {
    "text": "trying to scale that single node MySQL read replicas is kind of the only thing you can do and then finally you're going",
    "start": "157040",
    "end": "163599"
  },
  {
    "text": "to eventually hit uh Max instant size and so it's not going to scale forever",
    "start": "163599",
    "end": "168840"
  },
  {
    "text": "and the way that vess helped you with each of these uh fix dis sizes uh vest",
    "start": "168840",
    "end": "174440"
  },
  {
    "text": "we recommend that you do about 250 GB per Shard not because that's a magic",
    "start": "174440",
    "end": "180200"
  },
  {
    "text": "number but that kind of gets you into a 15minute restore window uh for Disaster",
    "start": "180200",
    "end": "186599"
  },
  {
    "text": "Recovery just having multiple discs helps you with all three of these you're",
    "start": "186599",
    "end": "192120"
  },
  {
    "text": "writing to the same schema uh but different uh discs solves again most of",
    "start": "192120",
    "end": "199519"
  },
  {
    "text": "these replication lag because again you have multiple instances of my SQL running the parallel workers makes",
    "start": "199519",
    "end": "206480"
  },
  {
    "text": "replication lag not an issue and this is my favorite uh rather than having one",
    "start": "206480",
    "end": "211720"
  },
  {
    "text": "primary and 10 or 100 read replicas just Shard wider get 50 primaries with one",
    "start": "211720",
    "end": "218720"
  },
  {
    "text": "replica each for uh ha and disaster recovery and to me that's just a",
    "start": "218720",
    "end": "226799"
  },
  {
    "text": "no-brainer offload that hard work from your app developers and then obviously",
    "start": "226799",
    "end": "232360"
  },
  {
    "text": "Max instant size you get solved with the horizontal",
    "start": "232360",
    "end": "237519"
  },
  {
    "text": "scaling but besides just starting the test is a full database platform so day",
    "start": "237760",
    "end": "243480"
  },
  {
    "text": "two operations a lot of people immediately want to go to an uh RDS or",
    "start": "243480",
    "end": "248519"
  },
  {
    "text": "Cloud SQL on Google uh to handle just some simple things that are vital to",
    "start": "248519",
    "end": "254159"
  },
  {
    "text": "your business High availability automatic failovers that's all handled natively by",
    "start": "254159",
    "end": "260160"
  },
  {
    "text": "vitess um if any of you are running my sqle in production at scale you're",
    "start": "260160",
    "end": "265400"
  },
  {
    "text": "probably have used or are using orchestrator and and essentially the",
    "start": "265400",
    "end": "271600"
  },
  {
    "text": "next version the originator of of orchestrator now works at Planet scale as one of the vest maintainers and",
    "start": "271600",
    "end": "278919"
  },
  {
    "text": "because vitess has a data plane it's able to do things that the original uh",
    "start": "278919",
    "end": "285400"
  },
  {
    "text": "just didn't have the data to do so as it's continued to evolve at vest orchestrator is a a great way to handle",
    "start": "285400",
    "end": "292680"
  },
  {
    "text": "this backup or stores included uh whether that's to dis whether that's to",
    "start": "292680",
    "end": "298440"
  },
  {
    "text": "uh object stor that's built in you get connection pooling it'll scale up",
    "start": "298440",
    "end": "304560"
  },
  {
    "text": "forever um one question people often ask about vest is what's the overhead and",
    "start": "304560",
    "end": "310880"
  },
  {
    "text": "typically we say there's a kind of one to two millisecond latency that's going to get added to every call but that's",
    "start": "310880",
    "end": "317199"
  },
  {
    "text": "fixed no matter how wide you Shard you're going to have that fixed uh",
    "start": "317199",
    "end": "323800"
  },
  {
    "text": "penalty that as long as you're not expecting sub millisecond times and your whole architecture is predicated on on",
    "start": "323800",
    "end": "329919"
  },
  {
    "text": "that everything else is going to uh scale forever online schema changes there's",
    "start": "329919",
    "end": "336240"
  },
  {
    "text": "you know multiple things uh in the ecosystem PTC uh ghost um vest supports",
    "start": "336240",
    "end": "343560"
  },
  {
    "text": "those but there's also internal uh V replication features uh that enable that",
    "start": "343560",
    "end": "348759"
  },
  {
    "text": "plus more automated roll backs uh in case of errors it's pretty awesome uh if",
    "start": "348759",
    "end": "354039"
  },
  {
    "text": "you've ever touched Planet scales uh branching that's all powered by uh the",
    "start": "354039",
    "end": "359880"
  },
  {
    "text": "same V replication work query consolidation to prevent thundering",
    "start": "359880",
    "end": "365199"
  },
  {
    "text": "herds as you get more active database uh if there's an inflight from between the",
    "start": "365199",
    "end": "371520"
  },
  {
    "text": "proxy and the actual MySQL instance you can have the same MySQL Query return to",
    "start": "371520",
    "end": "377800"
  },
  {
    "text": "any callers asking for the same data and then finally uh this is just another",
    "start": "377800",
    "end": "382840"
  },
  {
    "text": "implementation of the that V replication feature and V vream is the underlying",
    "start": "382840",
    "end": "387919"
  },
  {
    "text": "primitive that powers all of that uh you can also do materialized views uh cool",
    "start": "387919",
    "end": "393039"
  },
  {
    "text": "feature that we use that for is and I'll talk about in a second messaging but we",
    "start": "393039",
    "end": "398360"
  },
  {
    "text": "will use it as an event stream to power uh messaging cues later down uh vream",
    "start": "398360",
    "end": "404800"
  },
  {
    "text": "can also be used for distributed uh CDC if you want to move your data into olap",
    "start": "404800",
    "end": "409840"
  },
  {
    "text": "or something so lots of things that make operating your database great deployment kubernetes native from",
    "start": "409840",
    "end": "417479"
  },
  {
    "text": "the beginning uh was came out of YouTube it ran on Borg so it was built to be on",
    "start": "417479",
    "end": "423479"
  },
  {
    "text": "a stateless type of system Borg didn't at to my knowledge uh I'm not a Google",
    "start": "423479",
    "end": "428879"
  },
  {
    "text": "Ex googler but uh didn't even have the concept of like a stateful set and so it was things",
    "start": "428879",
    "end": "435639"
  },
  {
    "text": "could get wiped and it knew how to handle that so kubernetes is a walk in the park with uh stateful there's an",
    "start": "435639",
    "end": "441759"
  },
  {
    "text": "operate available uh GitHub Planet scale operator and but kubernetes is not",
    "start": "441759",
    "end": "447800"
  },
  {
    "text": "required U Pudi talk a little bit about it at back blazs um but there's plenty",
    "start": "447800",
    "end": "453080"
  },
  {
    "text": "of people running it not on kubernetes including I believe slack so messaging my personal favorite",
    "start": "453080",
    "end": "460400"
  },
  {
    "text": "uh feature that is probably the most hidden feature out of a test right this works just like sqs or pubsub if you're",
    "start": "460400",
    "end": "467400"
  },
  {
    "text": "used to that it's just a native MySQL table couple of required columns uh that",
    "start": "467400",
    "end": "472800"
  },
  {
    "text": "vest needs for it you can use it with a simple stream star from message table",
    "start": "472800",
    "end": "478560"
  },
  {
    "text": "and that is just going to stream rows into your worker it scales with your data if",
    "start": "478560",
    "end": "484199"
  },
  {
    "text": "you're running Kafka if you're running rabbit mq you're running whatever other you know",
    "start": "484199",
    "end": "490360"
  },
  {
    "text": "redus as you're scaling it up you now have two separate things is my queue going to be able to support whatever",
    "start": "490360",
    "end": "496840"
  },
  {
    "text": "data scale and operations that my database or is my database a bottleneck",
    "start": "496840",
    "end": "502960"
  },
  {
    "text": "and here most of the time your message is going to live next to your data and",
    "start": "502960",
    "end": "508280"
  },
  {
    "text": "so you only have to scale the one thing which also enables you can just join with regular T tables so you don't",
    "start": "508280",
    "end": "515599"
  },
  {
    "text": "necessarily have to copy your payload into sqs or pubsub and pay uh extra for",
    "start": "515599",
    "end": "522360"
  },
  {
    "text": "that the fact that you can just populate it and observe it with SQL is just it is",
    "start": "522360",
    "end": "527680"
  },
  {
    "text": "so great I don't have to write code if I want to know what is sitting in my queue oh select from right we all know and",
    "start": "527680",
    "end": "536399"
  },
  {
    "text": "love it and then finally transactions is is the best there's no outbox feature",
    "start": "536399",
    "end": "542360"
  },
  {
    "text": "you know outbox pattern you can just say act this message do some data work pass",
    "start": "542360",
    "end": "548720"
  },
  {
    "text": "it on to an xq in a single uh database transaction and just let my SQL handle",
    "start": "548720",
    "end": "553920"
  },
  {
    "text": "that for you it is amazing if you've never used it um and you probably haven't because most people don't think",
    "start": "553920",
    "end": "560720"
  },
  {
    "text": "that messaging cues can scale uh without going to Kafka compatibility uh vest has a",
    "start": "560720",
    "end": "568680"
  },
  {
    "text": "project we've put a ton of work into making sure that it works with all the",
    "start": "568680",
    "end": "573839"
  },
  {
    "text": "Frameworks that you uh use there are going to be uh if there's some more advanced SQL features there are a",
    "start": "573839",
    "end": "580640"
  },
  {
    "text": "handful that are not currently supported uh but we're always improving compatibility and generally most of your",
    "start": "580640",
    "end": "587240"
  },
  {
    "text": "workloads are just going to function correctly and I'll do a quick dive into the architecture I'm not going to go",
    "start": "587240",
    "end": "593399"
  },
  {
    "text": "super deep there have been a lot of uh different talks about that in the past um but at at a high level",
    "start": "593399",
    "end": "600000"
  },
  {
    "text": "your application is talking to uh VT gate that's just the stateless proxy and",
    "start": "600000",
    "end": "605760"
  },
  {
    "text": "it presents itself as a unified singular mySQL database and then it chooses based on",
    "start": "605760",
    "end": "613240"
  },
  {
    "text": "sharding rules like a common one is tenant ID and based on that tenant ID it",
    "start": "613240",
    "end": "619959"
  },
  {
    "text": "will send you to the right uh Shard that underneath it has a side card to just an",
    "start": "619959",
    "end": "627120"
  },
  {
    "text": "a regular MySQL instance uh VT tablet uh that man maintains a persistent",
    "start": "627120",
    "end": "633360"
  },
  {
    "text": "connection pool that's where the things like uh query consolidation all that happens then outside of the regular",
    "start": "633360",
    "end": "640040"
  },
  {
    "text": "query flow is the control plane you have VT admin that is the UI VT control D is",
    "start": "640040",
    "end": "649360"
  },
  {
    "text": "the core that manages uh everything that lives in a topology server typically at",
    "start": "649360",
    "end": "656440"
  },
  {
    "text": "CD uh but also zookeeper and believe console is deprecated and then finally VT orc is",
    "start": "656440",
    "end": "663079"
  },
  {
    "text": "what I was talking about with the next evolution of uh orchestrator and again",
    "start": "663079",
    "end": "668920"
  },
  {
    "text": "because it has a topology server and it knows exactly what the to what the MySQL",
    "start": "668920",
    "end": "674519"
  },
  {
    "text": "layout and topology is supposed to be it can do a better job of maintaining it",
    "start": "674519",
    "end": "679639"
  },
  {
    "text": "versus just listening for breaks and trying to do its",
    "start": "679639",
    "end": "685399"
  },
  {
    "text": "best and yeah as you dive into each Shard again uh at that VT gate you'll",
    "start": "685560",
    "end": "692959"
  },
  {
    "text": "Define in a Json what your V schema is what it's called and you say Shard by this you can give it a sharding function",
    "start": "692959",
    "end": "700120"
  },
  {
    "text": "most people use a hash on like a Tenon ID and it sends it to the correct Shard uh and again this is just a a zoom",
    "start": "700120",
    "end": "708360"
  },
  {
    "text": "in on the control plane so additional learning uh like I mentioned there's a lot of resources out",
    "start": "708360",
    "end": "714920"
  },
  {
    "text": "there this is probably the best it's a singular Cor uh to dive into all the pieces of vess",
    "start": "714920",
    "end": "722760"
  },
  {
    "text": "uh at Planet scale there's on the vitess site itself there are learning resources uh a lot of",
    "start": "722760",
    "end": "729880"
  },
  {
    "text": "them are just talks that have been given U deep the in particular is given probably half of them as the team lead",
    "start": "729880",
    "end": "736480"
  },
  {
    "text": "cross various cubec and other conferences and then finally we're very active in slack so we would love for you",
    "start": "736480",
    "end": "743079"
  },
  {
    "text": "to come join us uh all of us are there feel free to hit us up and vess is in",
    "start": "743079",
    "end": "748880"
  },
  {
    "text": "produ C at the biggest companies uh that there are every issue and PLL request in GitHub along with almost everything else",
    "start": "748880",
    "end": "755600"
  },
  {
    "text": "goes through vest uh none of the outages are vest related to my knowledge",
    "start": "755600",
    "end": "763880"
  },
  {
    "text": "um so don't put that on us uh square cash every uh transaction goes through",
    "start": "763880",
    "end": "771399"
  },
  {
    "text": "vitess and has for a while so the biggest companies are using it at scales that it's just not going to break so",
    "start": "771399",
    "end": "778199"
  },
  {
    "text": "vitess is battle hardened it's just native my sequel under the hood it's",
    "start": "778199",
    "end": "783600"
  },
  {
    "text": "awesome thank you very",
    "start": "783600",
    "end": "787040"
  },
  {
    "text": "much thanks D my name is sui and in this section I'm going to give you a brief",
    "start": "790279",
    "end": "796320"
  },
  {
    "text": "overview of how we went from testing with us and going live with it in",
    "start": "796320",
    "end": "802399"
  },
  {
    "text": "production yeah sorry uh this is the mandatory slide that I was given by my",
    "start": "802399",
    "end": "807519"
  },
  {
    "text": "marketing department uh and I have to mention it uh the one thing that I would highlight is uh a lot",
    "start": "807519",
    "end": "813839"
  },
  {
    "text": "of our customers are moving from S3 and into back place and have seen a",
    "start": "813839",
    "end": "820720"
  },
  {
    "text": "significant reduction in their infrastructure cost so and also in the",
    "start": "820720",
    "end": "826000"
  },
  {
    "text": "community I think a lot of folks know us for our Drive stats report that gets published every quarter because you can",
    "start": "826000",
    "end": "832120"
  },
  {
    "text": "pretty much imagine every manufactured drive out there we would have run it so",
    "start": "832120",
    "end": "837440"
  },
  {
    "text": "uh we have those reports and the recent one was pretty couple of days ago now before I get into how we got",
    "start": "837440",
    "end": "845040"
  },
  {
    "text": "into production I'm going to talk a brief moment of uh the application that",
    "start": "845040",
    "end": "850320"
  },
  {
    "text": "actually went live with vest um and the name is deletion que and as the name",
    "start": "850320",
    "end": "855839"
  },
  {
    "text": "suggests the primary job of this application is to perform deletes right simple",
    "start": "855839",
    "end": "861680"
  },
  {
    "text": "enough uh but if you start peeling the layers you'll know that it is nothing simple but gets complex really fast",
    "start": "861680",
    "end": "869959"
  },
  {
    "text": "turns out iops is a very precious thing for us and there's only a limited amount",
    "start": "869959",
    "end": "875759"
  },
  {
    "text": "of iops that you can get from the drive so we constantly struggle to find the",
    "start": "875759",
    "end": "881000"
  },
  {
    "text": "balance of dedicating the iops either for delation or for other activities that can be performed on the",
    "start": "881000",
    "end": "888040"
  },
  {
    "text": "drives this constant battle uh means that our backlogs of",
    "start": "888040",
    "end": "894279"
  },
  {
    "text": "deletions just keeps on increasing so for a long period of time we never never used the database for it like the it",
    "start": "894279",
    "end": "901839"
  },
  {
    "text": "would have been such a simple quick lookup and that's when we decided okay we're going to use the database but as",
    "start": "901839",
    "end": "908440"
  },
  {
    "text": "Derek mentioned we didn't want to go through all the Pains of a single monolith database so we decided that",
    "start": "908440",
    "end": "915120"
  },
  {
    "text": "we're going to have a vest shed database for it in fact this application went",
    "start": "915120",
    "end": "920160"
  },
  {
    "text": "live just 3 weeks ago and it's hard of the press we are already seeing 8 to 10 next",
    "start": "920160",
    "end": "929440"
  },
  {
    "text": "benefit in terms of our deletion rates now because it's a database lookup for deletions we free free up a lot of iops",
    "start": "929440",
    "end": "938279"
  },
  {
    "text": "that can be now dedicated to other operations like uploads which increased our upload time uh which increased the",
    "start": "938279",
    "end": "944120"
  },
  {
    "text": "benefit of faster uploads our cues are much manageable now",
    "start": "944120",
    "end": "949480"
  },
  {
    "text": "and because they are manageable we don't have to add constant storage to our pods so we save tons of money by not adding",
    "start": "949480",
    "end": "957519"
  },
  {
    "text": "additional storage why because didn't reclaim the space that was used by the files that were deleted so this is the",
    "start": "957519",
    "end": "964560"
  },
  {
    "text": "success story of vest a couple of other points which I'll get to it if I have",
    "start": "964560",
    "end": "971000"
  },
  {
    "text": "time um once we decided that we want to go with withes as our database uh we had",
    "start": "971000",
    "end": "976560"
  },
  {
    "text": "to decide on what platform are we going to use unfortunately at that time kubernetes was not ready for us to go",
    "start": "976560",
    "end": "982959"
  },
  {
    "text": "into production so we went with a bare metal system and with this kind of a",
    "start": "982959",
    "end": "988160"
  },
  {
    "text": "config for it and we had to find out what type of load can these notes support so we used",
    "start": "988160",
    "end": "995560"
  },
  {
    "text": "regular standard sisben modified it to run against a witht shed database and we",
    "start": "995560",
    "end": "1000920"
  },
  {
    "text": "saw about 125 K plus QPS that we can safely",
    "start": "1000920",
    "end": "1007040"
  },
  {
    "text": "accommodate on each of these nodes so that was a very promising feature for us and it meets our needs so we went with",
    "start": "1007040",
    "end": "1016519"
  },
  {
    "text": "that in terms of architecture we didn't want to complicate too much so we just followed what you find on vest",
    "start": "1016519",
    "end": "1024000"
  },
  {
    "text": "documentation and with a minor set of tweaks so I'm not going to go over each and individual component of here just",
    "start": "1024000",
    "end": "1029918"
  },
  {
    "text": "the tweaks that we did for the architecture that we find on West documentation",
    "start": "1029919",
    "end": "1035720"
  },
  {
    "text": "sites for our control plane uh with us control plane we used etcd as our",
    "start": "1035720",
    "end": "1041640"
  },
  {
    "text": "topology server and we went with a five node configuration for it the reason is",
    "start": "1041640",
    "end": "1047480"
  },
  {
    "text": "we can have two notes fail at a time and still maintain Quorum for H CD and",
    "start": "1047480",
    "end": "1053640"
  },
  {
    "text": "function and when you have five notes as your topology server wit configuration can get really messy where we have to",
    "start": "1053640",
    "end": "1060360"
  },
  {
    "text": "specify the topology server address so we said let's simplify this by adding a",
    "start": "1060360",
    "end": "1066039"
  },
  {
    "text": "whip in front of it so we have one simple whip which hits the available at",
    "start": "1066039",
    "end": "1072240"
  },
  {
    "text": "CD nodes and that makes our configurations much more simple to",
    "start": "1072240",
    "end": "1077840"
  },
  {
    "text": "handle all additional West admin components run on node One to begin with",
    "start": "1077840",
    "end": "1083080"
  },
  {
    "text": "and if there is for some reason we lose node number one we can always spawn it off on any other surviving nodes so this",
    "start": "1083080",
    "end": "1089720"
  },
  {
    "text": "was The Tweak that we made for the topology service that we",
    "start": "1089720",
    "end": "1094799"
  },
  {
    "text": "have uh moving on to the other components uh we introduced uh",
    "start": "1094799",
    "end": "1100600"
  },
  {
    "text": "because load balancer sits in a critical query serving path we couldn't just go",
    "start": "1100600",
    "end": "1106919"
  },
  {
    "text": "with one load balancer so we wanted ha for it so we went with two load balancers and the load balancers that we",
    "start": "1106919",
    "end": "1112320"
  },
  {
    "text": "have are based on U keep IED and they work in an active passive",
    "start": "1112320",
    "end": "1118200"
  },
  {
    "text": "fashion their job was just to Route client requests to the available VT",
    "start": "1118200",
    "end": "1123400"
  },
  {
    "text": "Gates and an additional job that we gave for them because they were hardly burdened with anything so we have whip",
    "start": "1123400",
    "end": "1132039"
  },
  {
    "text": "servicing the control plane too so they service the whip for the clients as well as other Wiest components which talks to",
    "start": "1132039",
    "end": "1139159"
  },
  {
    "text": "the topology server and for the gates again we have two VT Gates just to make",
    "start": "1139159",
    "end": "1144880"
  },
  {
    "text": "sure that we have ha available and If if we see the need for adding additional VT",
    "start": "1144880",
    "end": "1151120"
  },
  {
    "text": "Gates because some of them became overloaded we can just add it to our pool this combination of load balancers",
    "start": "1151120",
    "end": "1156960"
  },
  {
    "text": "and VT Gates is per key space for the vest cluster so we are designing it as a",
    "start": "1156960",
    "end": "1162640"
  },
  {
    "text": "platform and every key space that comes along to that or gets onboarded onto that platform will come with with its",
    "start": "1162640",
    "end": "1168960"
  },
  {
    "text": "own set of load balancers and VT Gates this is to ensure that we maintain isolation between the key spaces and not",
    "start": "1168960",
    "end": "1177000"
  },
  {
    "text": "step on each other's foot in terms of Shard a minimum of",
    "start": "1177000",
    "end": "1182760"
  },
  {
    "text": "three nodes one acting as primary and two of them as replicas so this is a very standard basic configuration that",
    "start": "1182760",
    "end": "1189440"
  },
  {
    "text": "we have and if there is ever a need that we have run out of uh servicing read",
    "start": "1189440",
    "end": "1194880"
  },
  {
    "text": "request from the replicas we can always add more replicas to it",
    "start": "1194880",
    "end": "1200640"
  },
  {
    "text": "oops I am so sorry this tells you how much experience",
    "start": "1202159",
    "end": "1207480"
  },
  {
    "text": "I have with Google presentations okay now once we decided",
    "start": "1207480",
    "end": "1213080"
  },
  {
    "text": "on the architecture and how we want to go about it the first thing that we did for tweaking is convert every service",
    "start": "1213080",
    "end": "1219400"
  },
  {
    "text": "that we have as a system D service so we can start utilizing the benefits of",
    "start": "1219400",
    "end": "1224799"
  },
  {
    "text": "systemd units uh because our present is in multiple data centers we went with a",
    "start": "1224799",
    "end": "1230840"
  },
  {
    "text": "single cell witht test configuration per data center so all these things get",
    "start": "1230840",
    "end": "1236240"
  },
  {
    "text": "deployed through anible and we have cookbooks to uh pretty much uh run and",
    "start": "1236240",
    "end": "1241960"
  },
  {
    "text": "configure an entire site within minutes for day-to-day operations we scrape metrics from the node from Vitz",
    "start": "1241960",
    "end": "1249720"
  },
  {
    "text": "and MySQL using Prometheus we use grafana to beautifully display those in",
    "start": "1249720",
    "end": "1256360"
  },
  {
    "text": "nice dashboards and a combination of zabic and grafana for alerting purposes",
    "start": "1256360",
    "end": "1262600"
  },
  {
    "text": "just keeping it pretty simple right nothing different now that was our existing",
    "start": "1262600",
    "end": "1268120"
  },
  {
    "text": "setup right uh in fact I'll take just one second to",
    "start": "1268120",
    "end": "1273960"
  },
  {
    "text": "mention the power of system d right uh because we converted that we had our first incident today morning and uh",
    "start": "1273960",
    "end": "1282760"
  },
  {
    "text": "there was no intervention by any user and VT orchestrator which Derek mentioned quite a lot about",
    "start": "1282760",
    "end": "1289120"
  },
  {
    "text": "automatically failed over the available replica converted it to a primary and it",
    "start": "1289120",
    "end": "1294799"
  },
  {
    "text": "was detected after the fact like the alert was raised but by the time the on",
    "start": "1294799",
    "end": "1300200"
  },
  {
    "text": "call could get to it everything was taken care of so that's a power of some of the wits features now where do we go",
    "start": "1300200",
    "end": "1306919"
  },
  {
    "text": "from here of course we want to be on kubernetes and it is pretty close to being production ready for us so once it",
    "start": "1306919",
    "end": "1312720"
  },
  {
    "text": "is done we will Port our stuff from bare metal to kubernetes uh ecosystem and and",
    "start": "1312720",
    "end": "1319039"
  },
  {
    "text": "uh because we are a very small team there's a lot of operational tasks that we can automate we are in the process of",
    "start": "1319039",
    "end": "1325320"
  },
  {
    "text": "automating everything including rearing so this becomes as a stepping stone to",
    "start": "1325320",
    "end": "1331000"
  },
  {
    "text": "have as a true database as a service platform for our internal customers and",
    "start": "1331000",
    "end": "1336400"
  },
  {
    "text": "eventually we want folks who have no knowledge of a test or database to perform resharding operations with the",
    "start": "1336400",
    "end": "1343279"
  },
  {
    "text": "push of a button so that's where we're going to head to and with that I thank you all for coming coming for my brief",
    "start": "1343279",
    "end": "1350320"
  },
  {
    "text": "uh overview of how we went to production and hand it over to D to talk about new and upcoming",
    "start": "1350320",
    "end": "1357720"
  },
  {
    "text": "[Applause] Services all right so uh when we do",
    "start": "1358200",
    "end": "1364679"
  },
  {
    "text": "these talks we try always try to do an introduction but also have something for",
    "start": "1364679",
    "end": "1369720"
  },
  {
    "text": "the more advanced users of wits and much of that revolves around what is new and",
    "start": "1369720",
    "end": "1375279"
  },
  {
    "text": "what is upcoming uh query serving is the area in",
    "start": "1375279",
    "end": "1380520"
  },
  {
    "text": "which we probably see the most amount of activity in terms of feature requests and uh issues and things like that and",
    "start": "1380520",
    "end": "1388279"
  },
  {
    "text": "we also tend to spend a lot of time uh and effort in that area so in the most",
    "start": "1388279",
    "end": "1394720"
  },
  {
    "text": "recent GA release which went out I think on October 29th so just about two weeks",
    "start": "1394720",
    "end": "1401120"
  },
  {
    "text": "ago we have uh support for Atomic distributed transactions so V has",
    "start": "1401120",
    "end": "1407799"
  },
  {
    "text": "already does distributed transactions on a best effort basis what this does is that distributed transactions can",
    "start": "1407799",
    "end": "1414480"
  },
  {
    "text": "actually be Atomic across multiple shards Derek will tell you that you",
    "start": "1414480",
    "end": "1419520"
  },
  {
    "text": "don't need distributed transactions but there are people who want them for",
    "start": "1419520",
    "end": "1425320"
  },
  {
    "text": "whatever reason and we want to enable those kinds of users as well this is experimental as issues come",
    "start": "1425320",
    "end": "1432679"
  },
  {
    "text": "up we'll fix them and hopefully someone will go into production soon um we've also o added support for",
    "start": "1432679",
    "end": "1439400"
  },
  {
    "text": "recursive CTE we've revamped our benchmarking website which where we run",
    "start": "1439400",
    "end": "1445600"
  },
  {
    "text": "uh benchmarks on a daily basis and publish them benchmark.us doio if you",
    "start": "1445600",
    "end": "1450840"
  },
  {
    "text": "didn't know we have many more um um query compatibility improvements that",
    "start": "1450840",
    "end": "1457240"
  },
  {
    "text": "went into the last two releases 20 and 21 uh improvements to updates deletes",
    "start": "1457240",
    "end": "1462919"
  },
  {
    "text": "more syntax that is supported and we've also added a bunch of metrics for query",
    "start": "1462919",
    "end": "1468840"
  },
  {
    "text": "plan cache hits and misses moving on to V replication V",
    "start": "1468840",
    "end": "1474279"
  },
  {
    "text": "replication is the engine that powers all the resharding and also we stream and materialized views when people",
    "start": "1474279",
    "end": "1482720"
  },
  {
    "text": "import their data into Wiest they are also using V replication to do that so this is really at the heart of many of",
    "start": "1482720",
    "end": "1490320"
  },
  {
    "text": "the uh scalability features that witus provides uh We've added a new feature to",
    "start": "1490320",
    "end": "1496840"
  },
  {
    "text": "mirror traffic during Mig ation so that when you cut over after a migration your",
    "start": "1496840",
    "end": "1502559"
  },
  {
    "text": "my sequels are not cold all the buffers have been warmed because you've been sending a small percentage of your read",
    "start": "1502559",
    "end": "1509360"
  },
  {
    "text": "traffic already to to the cluster you're migrating into uh reference tables is a nice",
    "start": "1509360",
    "end": "1515840"
  },
  {
    "text": "feature in vas where you may have these small tables where you have things like countries currencies zip codes you don't",
    "start": "1515840",
    "end": "1523799"
  },
  {
    "text": "want to Shard them you don't need to Shard them you can materialize them into every one of your shards so that joins",
    "start": "1523799",
    "end": "1530120"
  },
  {
    "text": "are local versus going cross Shard so we've added uh a CLI command",
    "start": "1530120",
    "end": "1536320"
  },
  {
    "text": "that makes it much easier to use this feature that has been there for a long time workflows can now uh accept Dynamic",
    "start": "1536320",
    "end": "1544159"
  },
  {
    "text": "configuration previously you had to configure the workflow when you created it and that's it but now while the",
    "start": "1544159",
    "end": "1550720"
  },
  {
    "text": "workflow is running you can change some of the parameters maybe you want to",
    "start": "1550720",
    "end": "1555760"
  },
  {
    "text": "throttle it maybe you want to uh add a table to your migration that you forgot to add all those things are now",
    "start": "1555760",
    "end": "1562559"
  },
  {
    "text": "possible we've also added experimental support for multi-tenant imports a lot",
    "start": "1562559",
    "end": "1568360"
  },
  {
    "text": "of people run um SAS services and by definition they are multi-tenant because",
    "start": "1568360",
    "end": "1573840"
  },
  {
    "text": "you have many users and you want each of them to have their own little domain of",
    "start": "1573840",
    "end": "1579480"
  },
  {
    "text": "data uh but when such databases try to migrate to Vitus often times they have",
    "start": "1579480",
    "end": "1586200"
  },
  {
    "text": "difficulty doing that because maybe they have split their tenants across many individual databases and they have",
    "start": "1586200",
    "end": "1592600"
  },
  {
    "text": "hundreds or thousands of them how do you migrate hundreds of thousands of smallish databases into this big sharded",
    "start": "1592600",
    "end": "1601000"
  },
  {
    "text": "uh my SQL cluster so we've added workflows to enable that we have a new",
    "start": "1601000",
    "end": "1606720"
  },
  {
    "text": "workflow creation and management UI as part of VT admin until we did this VT",
    "start": "1606720",
    "end": "1611919"
  },
  {
    "text": "admin was mostly readon As far as workflows went even though you had other management features",
    "start": "1611919",
    "end": "1618000"
  },
  {
    "text": "like electing a new primary tablet now uh workflows can be created from the UI",
    "start": "1618000",
    "end": "1623640"
  },
  {
    "text": "managed from the UI uh we have a few other improvements to V replication in",
    "start": "1623640",
    "end": "1629919"
  },
  {
    "text": "terms of error handling and vream enhancements online ddl also known as",
    "start": "1629919",
    "end": "1637000"
  },
  {
    "text": "online schema changes this is one of the Marky features of witus this is something that had been a pain for the",
    "start": "1637000",
    "end": "1644520"
  },
  {
    "text": "MySQL Community for a long time and as Derek already mentioned people came up with their own tools for",
    "start": "1644520",
    "end": "1650960"
  },
  {
    "text": "doing uh online schema changes perona had online schema change tool uh ghost",
    "start": "1650960",
    "end": "1657520"
  },
  {
    "text": "which is github's online schema change tool uh in witus with v replication we",
    "start": "1657520",
    "end": "1663279"
  },
  {
    "text": "can natively provide uh online schema changes which will not take your",
    "start": "1663279",
    "end": "1670519"
  },
  {
    "text": "database down and we we keep adding features to this online ddl as a feature has been",
    "start": "1670519",
    "end": "1677640"
  },
  {
    "text": "around for for almost 4 years now and we keep making constant improvements we add features for example my SQL now has",
    "start": "1677640",
    "end": "1685159"
  },
  {
    "text": "instant ddl so if it's possible to do instant ddl for instance you are adding a new column to a table the column is",
    "start": "1685159",
    "end": "1692279"
  },
  {
    "text": "going to be empty there's no data in it that can be instant so wherever possible",
    "start": "1692279",
    "end": "1697600"
  },
  {
    "text": "we do them instantly and we've also done improvements to how you can throttle",
    "start": "1697600",
    "end": "1703399"
  },
  {
    "text": "these workflows because sometimes the workflow that is doing the online schema",
    "start": "1703399",
    "end": "1708519"
  },
  {
    "text": "change because it makes a copy of the table and then switches over to the shadow table the new table it can affect",
    "start": "1708519",
    "end": "1716480"
  },
  {
    "text": "your uh your query serving your regular queries might become slow if the online",
    "start": "1716480",
    "end": "1722440"
  },
  {
    "text": "schema change workflow is causing too much load on the database so it's possible to throttle it and make it take",
    "start": "1722440",
    "end": "1728799"
  },
  {
    "text": "a little longer so that your regular workloads are not",
    "start": "1728799",
    "end": "1734279"
  },
  {
    "text": "affected uh We've also made error handling improvements us usability improvements and improvements to schema",
    "start": "1734279",
    "end": "1740760"
  },
  {
    "text": "diff which is a feature in online ddl through which you can do declarative ddl you just say this is the schema",
    "start": "1740760",
    "end": "1747919"
  },
  {
    "text": "definition I want and we will compute the diff and apply",
    "start": "1747919",
    "end": "1753840"
  },
  {
    "text": "it we've also made uh some improvements to backups and",
    "start": "1754320",
    "end": "1759799"
  },
  {
    "text": "vtrc MySQL backups is a feature that was contributed by slack this is experimental so uh the built-in my SQL",
    "start": "1759799",
    "end": "1768120"
  },
  {
    "text": "shell backup feature can be used with vs now uh We've added metrics to VTR Orc in",
    "start": "1768120",
    "end": "1774320"
  },
  {
    "text": "order to uh view erent uh transactions because this does happen sometimes with",
    "start": "1774320",
    "end": "1779799"
  },
  {
    "text": "my SQL that you end up with an errant transaction on a replica you can now uh",
    "start": "1779799",
    "end": "1784840"
  },
  {
    "text": "see those through metrics we've made it easier to configure unmanaged mode unmanaged mode",
    "start": "1784840",
    "end": "1791320"
  },
  {
    "text": "is what people use when they are initially migrating to witus so you have your MySQL you put a thin layer of vus",
    "start": "1791320",
    "end": "1798519"
  },
  {
    "text": "in front of it and then you use that as the proxy to copy everything over to your real vtus cluster while still",
    "start": "1798519",
    "end": "1805360"
  },
  {
    "text": "serving traffic so you're serving traffic to your original cluster and by",
    "start": "1805360",
    "end": "1810799"
  },
  {
    "text": "putting this wit facade in front of it you can actually do an almost zero",
    "start": "1810799",
    "end": "1816320"
  },
  {
    "text": "downtime cut over to your newly migrated witus cluster so that's unmanaged mode",
    "start": "1816320",
    "end": "1822679"
  },
  {
    "text": "and previously it was very difficult to configure it with a few Flags here a few Flags there now now there is one flag",
    "start": "1822679",
    "end": "1829240"
  },
  {
    "text": "called unmanaged which takes care of everything and uh one of the improvements we've made to",
    "start": "1829240",
    "end": "1836720"
  },
  {
    "text": "vtor is to Aller cross cell planned failovers previously a planned failover",
    "start": "1836720",
    "end": "1842080"
  },
  {
    "text": "had to stay within the same cell cell is a vus concept which refers to a failure domain so it could be a data center it",
    "start": "1842080",
    "end": "1849360"
  },
  {
    "text": "could be a Zone in um in a cloud provider or it could be",
    "start": "1849360",
    "end": "1856600"
  },
  {
    "text": "a single Rack in a data Center so previously when you did a planned failover for maintenance purposes and",
    "start": "1856600",
    "end": "1863519"
  },
  {
    "text": "chose a new primary it would have to live in the same cell but we have many people who actually run only one replica",
    "start": "1863519",
    "end": "1871320"
  },
  {
    "text": "per availability zone so you deploy your vus across say three availability zones",
    "start": "1871320",
    "end": "1877000"
  },
  {
    "text": "in a cloud provider primary replica replica you want to be able to fail over to another Zone if you want to take the",
    "start": "1877000",
    "end": "1883919"
  },
  {
    "text": "primary down for maintenance so now that's uh supported",
    "start": "1883919",
    "end": "1889039"
  },
  {
    "text": "we also have a kubernetes operator for witus and we've made a bunch of improvements to it uh you've always been",
    "start": "1889039",
    "end": "1895600"
  },
  {
    "text": "able to trigger backups while running witus with the operator now they are",
    "start": "1895600",
    "end": "1900919"
  },
  {
    "text": "automated and scheduled you don't have to define a kubernetes job to do it uh",
    "start": "1900919",
    "end": "1906639"
  },
  {
    "text": "you just specify a property in the crd and the backups will happen uh We've",
    "start": "1906639",
    "end": "1912080"
  },
  {
    "text": "added horizontal autoscaling to VT gate um so that as your traffic goes up you",
    "start": "1912080",
    "end": "1918760"
  },
  {
    "text": "can actually scale automatically without having to do it manually we are up to the latest release of kubernetes",
    "start": "1918760",
    "end": "1925919"
  },
  {
    "text": "1.31 and we've also added image customization so that different uh parts",
    "start": "1925919",
    "end": "1931519"
  },
  {
    "text": "of the cluster can actually be run using uh different",
    "start": "1931519",
    "end": "1936960"
  },
  {
    "text": "images a little bit about upcoming features we have some performance",
    "start": "1936960",
    "end": "1943200"
  },
  {
    "text": "optimization skewed Up Performance is something that cannot be done one time",
    "start": "1943200",
    "end": "1949840"
  },
  {
    "text": "you have to periodically revisit it because as you keep adding features and refactoring code you may end up with",
    "start": "1949840",
    "end": "1956240"
  },
  {
    "text": "regressions and as far as query performance goes we actually do monitor it on a nightly basis we uh always run",
    "start": "1956240",
    "end": "1965919"
  },
  {
    "text": "our benchmarks before every release and compare them with the previous release and make sure there are no significant",
    "start": "1965919",
    "end": "1971960"
  },
  {
    "text": "regressions but there's always room for improvement so that's going to be a focus for the next couple of releases es",
    "start": "1971960",
    "end": "1979080"
  },
  {
    "text": "we also want to do much better monitoring of workflows in order to make sure that your resharding or online ddl",
    "start": "1979080",
    "end": "1986000"
  },
  {
    "text": "are not adversely affecting your regular query serving uh workloads so that will",
    "start": "1986000",
    "end": "1991760"
  },
  {
    "text": "be upcoming and we are also planning to add V schema decision support when you",
    "start": "1991760",
    "end": "1996960"
  },
  {
    "text": "decide to Shard your tables in vest you have to choose which column you're going to use as the sharding key and sometimes",
    "start": "1996960",
    "end": "2004600"
  },
  {
    "text": "it can be a composite sharding key and the it's not very easy to do that it",
    "start": "2004600",
    "end": "2010799"
  },
  {
    "text": "requires a deep knowledge of your schema and your workload we want to make that easier by surfacing insights out of your",
    "start": "2010799",
    "end": "2019279"
  },
  {
    "text": "already running workloads and help people make make these decisions much",
    "start": "2019279",
    "end": "2024960"
  },
  {
    "text": "easier we have about a minute left for questions but um you can visit our",
    "start": "2024960",
    "end": "2032200"
  },
  {
    "text": "website using well actually this is the feedback QR code so any feedback on the session please let us know and the",
    "start": "2032200",
    "end": "2039440"
  },
  {
    "text": "website is wit. any",
    "start": "2039440",
    "end": "2044880"
  },
  {
    "text": "questions okay if there are no questions we are done thank you for showing up",
    "start": "2048399",
    "end": "2056200"
  }
]
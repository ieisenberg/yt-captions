[
  {
    "text": "yeah um but um yeah were there any talks about",
    "start": "0",
    "end": "5460"
  },
  {
    "text": "um you know the batch HPS also in the um in the normal like in the rest of the",
    "start": "5460",
    "end": "10500"
  },
  {
    "text": "days or was it only in the clock because we might have uh yeah we might have went to those",
    "start": "10500",
    "end": "17699"
  },
  {
    "text": "um there was quite a few that we had we attended uh given yeah yeah our interest",
    "start": "17699",
    "end": "24480"
  },
  {
    "text": "um I wasn't sure if you listed those because I kind of was trying to look into my schedule and see",
    "start": "24480",
    "end": "30800"
  },
  {
    "text": "exactly but I can't find my schedule okay right",
    "start": "31880",
    "end": "37559"
  },
  {
    "text": "yeah yeah I know that during the even there was quite a few like few related to GPU like the guy from Google was",
    "start": "37559",
    "end": "44820"
  },
  {
    "text": "saying some stuff to open optimalize Google I think there was another for from Vulcan or about Vulcan don't buy uh",
    "start": "44820",
    "end": "53640"
  },
  {
    "text": "can remember the vendor now uh all right and there was a few others but like me for example I focus more on",
    "start": "53640",
    "end": "63120"
  },
  {
    "text": "kubernetes itself not necessarily only on the batch so one of the my observation and Main team in kubecon for",
    "start": "63120",
    "end": "71040"
  },
  {
    "text": "the remaining days was ebpf so as a way of improving one performance",
    "start": "71040",
    "end": "77640"
  },
  {
    "text": "getting more observability and more control on your network layer in kubernetes so",
    "start": "77640",
    "end": "86220"
  },
  {
    "text": "there was a we spoke to like few vendors on the booth like kalika",
    "start": "86220",
    "end": "91320"
  },
  {
    "text": "and psyllium both very interesting that's something we're gonna probably try soon or soonish in in gr as well to play",
    "start": "91320",
    "end": "99360"
  },
  {
    "text": "a bit more with the BPF uh other interesting uh quite a bit",
    "start": "99360",
    "end": "105720"
  },
  {
    "text": "around Automation and practices like people you can see clearly that like Argo CD is getting more mature",
    "start": "105720",
    "end": "113220"
  },
  {
    "text": "so I went to a talk where the how it's called",
    "start": "113220",
    "end": "118619"
  },
  {
    "text": "the let's say vendors but the the team responsible for for owning Argo CD or",
    "start": "118619",
    "end": "124560"
  },
  {
    "text": "talking how to extend it what they plan the road map and stuff like that that was quite cool",
    "start": "124560",
    "end": "131119"
  },
  {
    "text": "yeah I actually mentioned the vaccine HPC day but there was also get opscom as a co-located before the conference and",
    "start": "131940",
    "end": "138540"
  },
  {
    "text": "then a ton of con talks about get UPS as well during the conference both for Argo and flux",
    "start": "138540",
    "end": "144060"
  },
  {
    "text": "yeah but maybe maybe we can like if you find the the links in the skit maybe",
    "start": "144060",
    "end": "149400"
  },
  {
    "text": "drop them in the chat uh yeah yeah recording so we should be able to then",
    "start": "149400",
    "end": "156239"
  },
  {
    "text": "find the chat and and collect them again it was as well like it was my first",
    "start": "156239",
    "end": "161760"
  },
  {
    "text": "coupon and I was surprised by a number of people attending that was like 7 000 or so people on the side yeah and",
    "start": "161760",
    "end": "168840"
  },
  {
    "text": "sometimes it was quite challenging to get into the room if you're not enough into the room especially with the",
    "start": "168840",
    "end": "175160"
  },
  {
    "text": "particular talk was like super interesting and getting a lot of traction it was like if you are not 15",
    "start": "175160",
    "end": "181019"
  },
  {
    "text": "minutes earlier in the room you're not getting luckily there was a way of watching them virtually so that was as",
    "start": "181019",
    "end": "187319"
  },
  {
    "text": "well quite cool because there is one talk I haven't watched even yet where I think it was Mercedes Benz explaining",
    "start": "187319",
    "end": "195420"
  },
  {
    "text": "how they immigrate 700 or 7 000 clusters from terraform and other infrastructure",
    "start": "195420",
    "end": "202800"
  },
  {
    "text": "to using cluster API so that that's yeah quite a few lessons there",
    "start": "202800",
    "end": "209400"
  },
  {
    "text": "and a thing that was another versus observation like kubernetes become more",
    "start": "209400",
    "end": "214560"
  },
  {
    "text": "and more a framework to doing stuff like that there is quite a few talks around",
    "start": "214560",
    "end": "220140"
  },
  {
    "text": "cross plane so cross plane as a way of managing infrastructure other than just",
    "start": "220140",
    "end": "226680"
  },
  {
    "text": "pure kubernetes stuff using kubernetes and kubernetes",
    "start": "226680",
    "end": "231980"
  },
  {
    "text": "Reconciliation Loop to enforce the state and stuff like that although it was quite cool as well",
    "start": "231980",
    "end": "237480"
  },
  {
    "text": "yeah nice few plus model times as well so few",
    "start": "237480",
    "end": "242700"
  },
  {
    "text": "talks about postmortem so if you're running kubernetes for a scale for people so that was a slow quite",
    "start": "242700",
    "end": "249360"
  },
  {
    "text": "interesting seeing how I think it was Data docs or data doc running into the",
    "start": "249360",
    "end": "255900"
  },
  {
    "text": "issue and spending like few months investigating stuff on their Amazon infrastructure",
    "start": "255900",
    "end": "264419"
  },
  {
    "text": "yeah is that the DNS one yes yes yeah that was a good good talk",
    "start": "264419",
    "end": "270240"
  },
  {
    "text": "I'm pasting the links here in the chat as as you speak cool",
    "start": "270240",
    "end": "277699"
  },
  {
    "text": "yeah we have some join us a small screen yeah I don't know 23 of",
    "start": "279000",
    "end": "285720"
  },
  {
    "text": "us in the same time yeah cool yeah so that was as well quite a",
    "start": "285720",
    "end": "291660"
  },
  {
    "text": "lot of talks like casual talks happening during the lunch to various people and",
    "start": "291660",
    "end": "297180"
  },
  {
    "text": "then again to vendors so one of the vendor we're kind of using is the one",
    "start": "297180",
    "end": "303240"
  },
  {
    "text": "behind oppa I don't know whether nlpo is using Opera open is a way of defining a",
    "start": "303240",
    "end": "309120"
  },
  {
    "text": "policy so before going to keep going we Face a few issue where we try restrict",
    "start": "309120",
    "end": "314340"
  },
  {
    "text": "some stuff so we start discussing with them and so on so that was again quite nice thing",
    "start": "314340",
    "end": "320340"
  },
  {
    "text": "side side think in keep calm nice",
    "start": "320340",
    "end": "325699"
  },
  {
    "text": "all right anything else",
    "start": "328680",
    "end": "335120"
  },
  {
    "text": "okay so I try to collect a few talks and put it in the chat but feel free to add uh if I miss him",
    "start": "336419",
    "end": "343680"
  },
  {
    "text": "yeah I think I actually been to the one uh improving GP utilizations yes I was",
    "start": "343680",
    "end": "349800"
  },
  {
    "text": "there I think was it from Google yes that was quite interesting but there can it kind of was",
    "start": "349800",
    "end": "355020"
  },
  {
    "text": "a letdown that they didn't actually talk about the implementation details but it was quite interesting about how you know",
    "start": "355020",
    "end": "360479"
  },
  {
    "text": "the theoretical sides of things um we also try and grab something else",
    "start": "360479",
    "end": "366780"
  },
  {
    "text": "out because I even find my scat from here",
    "start": "366780",
    "end": "373620"
  },
  {
    "text": "it was one I feel one of the agenda was the one that I would attended that was quite interesting was a network aware",
    "start": "373620",
    "end": "379380"
  },
  {
    "text": "scheduling although it did look like something that require quite a lot of time before it can be implemented",
    "start": "379380",
    "end": "385380"
  },
  {
    "text": "on production cluster let me see if I can find it",
    "start": "385380",
    "end": "390539"
  },
  {
    "text": "start over here oh yeah we just uh so this one was quite interesting but",
    "start": "390539",
    "end": "398759"
  },
  {
    "text": "you're just not listening to them yeah we're talking to them",
    "start": "398759",
    "end": "404240"
  },
  {
    "text": "yeah another interesting one was a ephemeral containers so I'm not sure",
    "start": "405180",
    "end": "411960"
  },
  {
    "text": "whether you're aware about American continents that's a new thing in kubernetes 122 23 and I think it's gonna",
    "start": "411960",
    "end": "418319"
  },
  {
    "text": "be even more mature in future they the idea is when you need to troubleshoot a problem with your report or with your",
    "start": "418319",
    "end": "425220"
  },
  {
    "text": "application inside the container rather than using Cube CTL exec which many",
    "start": "425220",
    "end": "430800"
  },
  {
    "text": "people do you'd run command Cube CTL debug the difference is exec",
    "start": "430800",
    "end": "438180"
  },
  {
    "text": "move you kind of like almost SSH into the the container your troubleshooting",
    "start": "438180",
    "end": "443639"
  },
  {
    "text": "but with debug it's been additional site container",
    "start": "443639",
    "end": "448680"
  },
  {
    "text": "so you can Define that you have completely different set of tools in that site containers and by being a site",
    "start": "448680",
    "end": "455400"
  },
  {
    "text": "container they share the same namespace Linux namespaces not",
    "start": "455400",
    "end": "460740"
  },
  {
    "text": "kubernetes namespaces so by doing that you have the access to the same network",
    "start": "460740",
    "end": "466020"
  },
  {
    "text": "namespace and so on and you can use NS enter so namespace enter to even get",
    "start": "466020",
    "end": "472259"
  },
  {
    "text": "access to bit namespace and a few other name Linux namespaces",
    "start": "472259",
    "end": "478259"
  },
  {
    "text": "and that that was quite cool because it allows you to have very minimalistic image you can use probably",
    "start": "478259",
    "end": "485280"
  },
  {
    "text": "this strollers and start building building more tools and yeah and by that",
    "start": "485280",
    "end": "491160"
  },
  {
    "text": "in in the into side containers and the site container once you finish executing",
    "start": "491160",
    "end": "496919"
  },
  {
    "text": "you your qctl debug command is gone so you don't need to worry about having",
    "start": "496919",
    "end": "502379"
  },
  {
    "text": "this side car constantly running so we we actually do use that that turn",
    "start": "502379",
    "end": "508379"
  },
  {
    "text": "like it it became better in 123 but it was Alpha before so you could enable it",
    "start": "508379",
    "end": "513779"
  },
  {
    "text": "in the Clusters and we were enabling it and what we do is we keep one image that",
    "start": "513779",
    "end": "519060"
  },
  {
    "text": "has all the debugging tools we need for networking uh everything file systems",
    "start": "519060",
    "end": "524760"
  },
  {
    "text": "whatever and we use that image to debug and detach using an informal containers when",
    "start": "524760",
    "end": "531899"
  },
  {
    "text": "we debug stuff I put the links there as well",
    "start": "531899",
    "end": "538820"
  },
  {
    "text": "through my sketch oh another one interesting kind of interesting depends",
    "start": "538820",
    "end": "544140"
  },
  {
    "text": "what you do is about qvirt so Cube weird again you use kubernetes to manage your",
    "start": "544140",
    "end": "551700"
  },
  {
    "text": "VMS simply but they added quite a few additional features like live migration",
    "start": "551700",
    "end": "557040"
  },
  {
    "text": "and so on so that's another product which is becoming more and more mature and in the future probably it could be",
    "start": "557040",
    "end": "565019"
  },
  {
    "text": "our way to like rather than directly using I don't know openstack to spin your VM you can use Cube beard to",
    "start": "565019",
    "end": "571620"
  },
  {
    "text": "control and do the Via migration and other stuff yeah so kubernetes has a framework again",
    "start": "571620",
    "end": "580220"
  },
  {
    "text": "awesome yeah there was a few talks as well about",
    "start": "586560",
    "end": "592860"
  },
  {
    "text": "horizontal Port Auto scaler using cada as well for that yeah the",
    "start": "592860",
    "end": "600000"
  },
  {
    "text": "talk wasn't but I think there was a project called pixie",
    "start": "600000",
    "end": "605580"
  },
  {
    "text": "or yeah I think pixie it's easier to um to capture the the traffic right uh yeah",
    "start": "605580",
    "end": "613080"
  },
  {
    "text": "yeah the vehicle to actually produce it um get the Test match for an application",
    "start": "613080",
    "end": "619800"
  },
  {
    "text": "um yeah yeah that that's a good point there was an interesting talk about I can't",
    "start": "619800",
    "end": "625560"
  },
  {
    "text": "remember the title I will find about different approach to doing a load test",
    "start": "625560",
    "end": "631260"
  },
  {
    "text": "or in general a test because let's say you run a web application on your",
    "start": "631260",
    "end": "636600"
  },
  {
    "text": "kubernetes it's a web service so you to deploy a new version of that web service",
    "start": "636600",
    "end": "641940"
  },
  {
    "text": "so you can do few approaches one you have let's say staging cluster or something like that you deploy there and",
    "start": "641940",
    "end": "647700"
  },
  {
    "text": "maybe test somehow like write some integration tests another one is having",
    "start": "647700",
    "end": "654360"
  },
  {
    "text": "a canary approach so like blue green where you redirect a bit of traffic to",
    "start": "654360",
    "end": "660060"
  },
  {
    "text": "your new version that's what people quite often do with Services much like Linker deal and stuff like that but the",
    "start": "660060",
    "end": "667500"
  },
  {
    "text": "talk was that the problem with that approach is you not necessarily has consistent",
    "start": "667500",
    "end": "674519"
  },
  {
    "text": "inputs going to that web service let's say if you're doing the change in middle of night you don't have the same traffic",
    "start": "674519",
    "end": "681360"
  },
  {
    "text": "or the same number of users so you don't really know that whether the the way",
    "start": "681360",
    "end": "686579"
  },
  {
    "text": "you're promoting your no stop new application is working at all or not so",
    "start": "686579",
    "end": "692220"
  },
  {
    "text": "the idea is I think it's still using ebpf as well to capture the traffic so in other BBF related is to kind of tap",
    "start": "692220",
    "end": "700860"
  },
  {
    "text": "like like start tapping the the traffic and record that traffic once you have",
    "start": "700860",
    "end": "706200"
  },
  {
    "text": "the traffic kind of recorded you can reapply that later on any time and it's",
    "start": "706200",
    "end": "711600"
  },
  {
    "text": "gonna have the same volume and so on so you can deploy your web service in in",
    "start": "711600",
    "end": "718740"
  },
  {
    "text": "without impacting your user you run a recorded traffic and if the behavior is",
    "start": "718740",
    "end": "725279"
  },
  {
    "text": "not different than before your change then probably you are good and you cannot try a b release on that",
    "start": "725279",
    "end": "732660"
  },
  {
    "text": "point on Canary release it was quite a good talk I will try to find out the the name of",
    "start": "732660",
    "end": "738240"
  },
  {
    "text": "the talk I I just pasted it there uh it should be the last link in the other one",
    "start": "738240",
    "end": "743339"
  },
  {
    "text": "the revolution issue in your CI pipeline that that's that that's a good one yeah yeah I still have the schedule in my",
    "start": "743339",
    "end": "749700"
  },
  {
    "text": "head somehow I didn't watch them but I I remember the titles yeah it was very good to be",
    "start": "749700",
    "end": "755820"
  },
  {
    "text": "honest yeah there was a it was a the recording team of eppf this year",
    "start": "755820",
    "end": "761220"
  },
  {
    "text": "um it's quite interesting I I remember hearing about EPF evpf quite a few times in the past but this one really was uh",
    "start": "761220",
    "end": "768300"
  },
  {
    "text": "yeah you can see already that the tooling is is getting more mature or at least more more known around the",
    "start": "768300",
    "end": "774240"
  },
  {
    "text": "community uh in fact it was another talk I think this is also quite relevant to the scheduling part um which is about",
    "start": "774240",
    "end": "780779"
  },
  {
    "text": "bandwidth management using um ebpf again let me just paste the link",
    "start": "780779",
    "end": "786480"
  },
  {
    "text": "here uh yes definitely the the conference of the ebpf",
    "start": "786480",
    "end": "791760"
  },
  {
    "text": "yeah it was",
    "start": "791760",
    "end": "795320"
  },
  {
    "text": "quite agree I think it was something that we could see coming already for a while now",
    "start": "797220",
    "end": "804240"
  },
  {
    "text": "um but yeah this one was definitely the confirmation that it's gonna get bigger from now on uh in fact the one from",
    "start": "804240",
    "end": "810240"
  },
  {
    "text": "Batman management was quite interesting because it was um starting to yeah they were adding this",
    "start": "810240",
    "end": "816000"
  },
  {
    "text": "basically possibility of adding into the um into your basically the deployment",
    "start": "816000",
    "end": "823680"
  },
  {
    "text": "um also the resource around how much bandwidth you want to allocate to a specific",
    "start": "823680",
    "end": "829139"
  },
  {
    "text": "um Bell pod um and that's quite that's quite interesting uh as that's only possible",
    "start": "829139",
    "end": "834779"
  },
  {
    "text": "through the the way ebpf works and how you can get those kind of informations out of the kernel",
    "start": "834779",
    "end": "840300"
  },
  {
    "text": "um yeah I mean again uh very cool uh let's press the",
    "start": "840300",
    "end": "845639"
  },
  {
    "text": "link there I don't right now I should have oh yeah there was sorry I was looking at them",
    "start": "845639",
    "end": "852360"
  },
  {
    "text": "at the at the information here there was something they were talking about where they were also uh mentioning how with",
    "start": "852360",
    "end": "860160"
  },
  {
    "text": "the with this um new approach you could also have higher speed of communications uh",
    "start": "860160",
    "end": "868500"
  },
  {
    "text": "let me just look at this the scalability limits of token bucket filter but the one would plug in earliest departure",
    "start": "868500",
    "end": "874019"
  },
  {
    "text": "time yeah combined with ebpf um yeah something about being quite yeah",
    "start": "874019",
    "end": "879779"
  },
  {
    "text": "cool uh both in bandwidth management and getting more speed out of what's",
    "start": "879779",
    "end": "885360"
  },
  {
    "text": "available so one looking at with the ppf is uh with",
    "start": "885360",
    "end": "891899"
  },
  {
    "text": "psyllium to do sort of like cluster mesh and not only like a service mesh but",
    "start": "891899",
    "end": "897300"
  },
  {
    "text": "really oh it's about Dimensions multiple clusters to to be mixed",
    "start": "897300",
    "end": "903000"
  },
  {
    "text": "together at the Pod level even and and you can easily do load balancing across clusters without having to rely on",
    "start": "903000",
    "end": "909540"
  },
  {
    "text": "Services which for the batches case is actually quite interesting because we don't want to have the like we don't",
    "start": "909540",
    "end": "915480"
  },
  {
    "text": "really care about the service abstraction we just care about the workloads and uh that this is something",
    "start": "915480",
    "end": "921600"
  },
  {
    "text": "we started prototyping which is to mesh multiple clusters and be able to schedule across them",
    "start": "921600",
    "end": "927660"
  },
  {
    "text": "from a single plane basically well so so that's interesting because when I chatted with them about scheduling",
    "start": "927660",
    "end": "934380"
  },
  {
    "text": "across multiple clusters I thought that their response was oh no this is really only meshing the networks",
    "start": "934380",
    "end": "942000"
  },
  {
    "text": "together so that pods can speak to other pods in other networks uh in other",
    "start": "942000",
    "end": "948060"
  },
  {
    "text": "clusters but the scheduling of them you'll still need to do somewhere else right",
    "start": "948060",
    "end": "954180"
  },
  {
    "text": "okay yeah but but it allows you to to like even if you have uh if you want to",
    "start": "954180",
    "end": "961620"
  },
  {
    "text": "distribute the workloads across clusters you can rely on having like some Services running uh internally in one",
    "start": "961620",
    "end": "968579"
  },
  {
    "text": "cluster without having to replicate them everywhere for example and and you just uh like you could have this workload",
    "start": "968579",
    "end": "975600"
  },
  {
    "text": "clusters that are really disposable while you have the service clusters in the same mesh",
    "start": "975600",
    "end": "980820"
  },
  {
    "text": "um or this the service the component clusters in the same mesh so we've been playing with this also",
    "start": "980820",
    "end": "987240"
  },
  {
    "text": "but it could actually with some tricks you can you can actually schedule across clusters as well this is",
    "start": "987240",
    "end": "994620"
  },
  {
    "text": "something we've been playing with but maybe maybe for another time yeah I'd love to hear that and also",
    "start": "994620",
    "end": "1001100"
  },
  {
    "text": "whether you're seeing reasonable performance for you know often you want jobs to be co-located so",
    "start": "1001100",
    "end": "1008420"
  },
  {
    "text": "that the network speed is fast enough for them to talk to each other but yeah uh anyway those that would be",
    "start": "1008420",
    "end": "1014000"
  },
  {
    "text": "interesting to talk about maybe next time we've seen is the that you still need",
    "start": "1014000",
    "end": "1019459"
  },
  {
    "text": "like node to node connectivity like layers reconnectivity between all nodes across all clusters which uh yeah it",
    "start": "1019459",
    "end": "1026959"
  },
  {
    "text": "kind of makes sense but it's not like a Gateway or anything you need like full full mesh between nodes as well I",
    "start": "1026959",
    "end": "1035720"
  },
  {
    "text": "think something like that was mentioned in the data dog talk about DNS where they try that they are using psyllium",
    "start": "1035720",
    "end": "1043040"
  },
  {
    "text": "exactly to do a pot to pot rooting possible across multiple cluster I'm not",
    "start": "1043040",
    "end": "1049280"
  },
  {
    "text": "sure whether across multiple different Cloud providers maybe they are cheaper than that but but there you need some",
    "start": "1049280",
    "end": "1056840"
  },
  {
    "text": "sort of like VPN connectivity I guess because you need to expose all nodes to all nodes so this is this is our dream",
    "start": "1056840",
    "end": "1063919"
  },
  {
    "text": "which is to burst using a mesh like this but it but it's actually trickier than than it could be",
    "start": "1063919",
    "end": "1070520"
  },
  {
    "text": "I guess if you if like if you look at uh other things",
    "start": "1070520",
    "end": "1075799"
  },
  {
    "text": "for service connectivity they use gateways here it's really like a full mess between all notes at least my",
    "start": "1075799",
    "end": "1083120"
  },
  {
    "text": "understanding up to now but it is promising sounds amazing",
    "start": "1083120",
    "end": "1089080"
  },
  {
    "text": "but it it's actually something maybe maybe we should bring them to present psyllium and ubpf to the group that",
    "start": "1089080",
    "end": "1096620"
  },
  {
    "text": "would be cool yeah I'll I'll we we we're getting at least to come to CERN uh in two weeks so maybe",
    "start": "1096620",
    "end": "1104120"
  },
  {
    "text": "she can also do a talk the same talk group let's let's put it for for the",
    "start": "1104120",
    "end": "1110179"
  },
  {
    "text": "list here they will definitely bring in a lot of uh more interested uh parties into these",
    "start": "1110179",
    "end": "1118400"
  },
  {
    "text": "uh research group you mentioned the Gateway I think the",
    "start": "1118400",
    "end": "1123440"
  },
  {
    "text": "another talk was about Gateway API so it is going from beta to ga that was quite",
    "start": "1123440",
    "end": "1130340"
  },
  {
    "text": "good talk as well you can dig the link out actually",
    "start": "1130340",
    "end": "1136760"
  },
  {
    "text": "uh they're having my schedule I think I'll put here for",
    "start": "1136760",
    "end": "1143480"
  },
  {
    "text": "I'll put it for the next one the topic for Celia manage BPF but maybe we",
    "start": "1143480",
    "end": "1149179"
  },
  {
    "text": "can see yeah I'm just pasting the Gateway API",
    "start": "1149179",
    "end": "1155720"
  },
  {
    "text": "link as well",
    "start": "1155720",
    "end": "1158260"
  },
  {
    "text": "nice nice",
    "start": "1166820",
    "end": "1172460"
  },
  {
    "text": "yeah yeah the other stuff I had here in the",
    "start": "1172460",
    "end": "1179179"
  },
  {
    "text": "summary is just uh I I saw that work a lot of references to batch uh workloads",
    "start": "1179179",
    "end": "1185900"
  },
  {
    "text": "not only in in the talks but also in the keynote so in the TOC update it was",
    "start": "1185900",
    "end": "1191000"
  },
  {
    "text": "mentioned that there was the new group uh formed as part of the attack runtime",
    "start": "1191000",
    "end": "1198020"
  },
  {
    "text": "and then also in the kubernetes updates the batch working group in six",
    "start": "1198020",
    "end": "1203840"
  },
  {
    "text": "scheduling and then like the keynote also from from CERN we mentioned the",
    "start": "1203840",
    "end": "1211160"
  },
  {
    "text": "the Computing use cases and there were other mentions you mean",
    "start": "1211160",
    "end": "1217940"
  },
  {
    "text": "the one that you gave yeah yeah so about this you're like oh the one from CERN I don't I don't know",
    "start": "1217940",
    "end": "1224000"
  },
  {
    "text": "who those people are no yeah yeah so no but definitely it",
    "start": "1224000",
    "end": "1229820"
  },
  {
    "text": "wasn't a coincidence and also in the other ones like this has been appearing a bit everywhere",
    "start": "1229820",
    "end": "1236299"
  },
  {
    "text": "but I think there was it was clear that from the references constantly in different Keynote",
    "start": "1236299",
    "end": "1242840"
  },
  {
    "text": "slowly building momentum and when we see the other activities as well",
    "start": "1242840",
    "end": "1248299"
  },
  {
    "text": "and then um yeah so and then there was one",
    "start": "1248299",
    "end": "1254000"
  },
  {
    "text": "session dedicated to the kubernetes working group patch that will also be the video uploaded",
    "start": "1254000",
    "end": "1260480"
  },
  {
    "text": "so Aldo gave an overview of the work that has been going on already",
    "start": "1260480",
    "end": "1266900"
  },
  {
    "text": "and uh and the plans and there was not a lot of different people speaking but",
    "start": "1266900",
    "end": "1273559"
  },
  {
    "text": "there were I I talked to a few and it seemed like they were both developers and and uh also end users interested in",
    "start": "1273559",
    "end": "1281480"
  },
  {
    "text": "using these tools so that that was quite nice and just uh really really quickly so",
    "start": "1281480",
    "end": "1286760"
  },
  {
    "text": "they they summarized the motivation I think we all know about it here but they",
    "start": "1286760",
    "end": "1292580"
  },
  {
    "text": "also mentioned uh that their goal is to it's three main tasks one is to update",
    "start": "1292580",
    "end": "1299179"
  },
  {
    "text": "the job API to allow new types of workloads that are not just the typical batch job as",
    "start": "1299179",
    "end": "1306080"
  },
  {
    "text": "defined by kubernetes up to now then things like queuing um and uh",
    "start": "1306080",
    "end": "1312440"
  },
  {
    "text": "Advanced scheduling and then I think the the interesting part that there was a",
    "start": "1312440",
    "end": "1318740"
  },
  {
    "text": "nice talk in the co-located event about was the the optimized",
    "start": "1318740",
    "end": "1324080"
  },
  {
    "text": "scheduling on the Node itself to make sure that like the",
    "start": "1324080",
    "end": "1329380"
  },
  {
    "text": "apologies are said properly so that you get full performance in general losing like 20 or 30 percent of your",
    "start": "1329380",
    "end": "1336640"
  },
  {
    "text": "capacity because of it so I think that it was a a nice I think",
    "start": "1336640",
    "end": "1342500"
  },
  {
    "text": "Alex you were there as well right yep no I was there uh very jet lagged",
    "start": "1342500",
    "end": "1348799"
  },
  {
    "text": "but yes I was there uh it was good I would just reiterate the the number the amount of",
    "start": "1348799",
    "end": "1356960"
  },
  {
    "text": "back scheduling related talks that had the batch day and uh other talk and and",
    "start": "1356960",
    "end": "1363919"
  },
  {
    "text": "I was on the panel a day later and then you spoke in the keynote and it was",
    "start": "1363919",
    "end": "1369980"
  },
  {
    "text": "um we weren't quite an ebpf status but uh batch was was rising in the ranks of",
    "start": "1369980",
    "end": "1376340"
  },
  {
    "text": "conversation it's good and I'll pitch one more talk which was",
    "start": "1376340",
    "end": "1382580"
  },
  {
    "text": "from some other CERN colleagues and they they gave",
    "start": "1382580",
    "end": "1387860"
  },
  {
    "text": "a talk uh later I think Thursday I don't think the video is uploaded yet",
    "start": "1387860",
    "end": "1394340"
  },
  {
    "text": "but basically what they've done like we have this large great Computing environment and they've been playing",
    "start": "1394340",
    "end": "1399860"
  },
  {
    "text": "with getting kubernetes being a great site and it doesn't matter if it's on premise on a public Cloud",
    "start": "1399860",
    "end": "1405980"
  },
  {
    "text": "whatever nice presentation where they showed that they could scale a single kubernetes",
    "start": "1405980",
    "end": "1412400"
  },
  {
    "text": "cluster to 100 000 cores in the Google cloud in this case um quite easily and fast and then even",
    "start": "1412400",
    "end": "1419539"
  },
  {
    "text": "scratch it when they don't need it yeah and they Justified that uh",
    "start": "1419539",
    "end": "1426260"
  },
  {
    "text": "this is like an out of the box solution to integrate new resources into our great infrastructure and also the",
    "start": "1426260",
    "end": "1432860"
  },
  {
    "text": "ability to to request resources that we don't have yes or tpus and their dream",
    "start": "1432860",
    "end": "1440000"
  },
  {
    "text": "is to have like a home chart that does help install grid site and and you just add it to the",
    "start": "1440000",
    "end": "1446600"
  },
  {
    "text": "infrastructure so they gave they gave some some summaries here of their what",
    "start": "1446600",
    "end": "1453200"
  },
  {
    "text": "they've been doing integrating heterogeneous like arm and gpus and then they actually built an analysis",
    "start": "1453200",
    "end": "1460640"
  },
  {
    "text": "facility on top of this so they have the kubernetes layer as kind of the base layer to add",
    "start": "1460640",
    "end": "1468919"
  },
  {
    "text": "the resources but then they add like Jupiter Hub and they had the ability to",
    "start": "1468919",
    "end": "1473960"
  },
  {
    "text": "deploy like task clusters dynamically for different users so people can do their analysis using",
    "start": "1473960",
    "end": "1481400"
  },
  {
    "text": "chipta Hub and then scale out using tasks to to a very large number of resources",
    "start": "1481400",
    "end": "1487760"
  },
  {
    "text": "uh so I don't think the video is uploaded yet but for sure it will be Nathan so I from from the link I will",
    "start": "1487760",
    "end": "1495799"
  },
  {
    "text": "find the link in the agenda for you and then there should be like a list with",
    "start": "1495799",
    "end": "1500840"
  },
  {
    "text": "the video some reason my computer is blocking a bit but",
    "start": "1500840",
    "end": "1506960"
  },
  {
    "text": "I'll I'll post yeah yeah I'll post the link in a bit so I think",
    "start": "1506960",
    "end": "1513440"
  },
  {
    "text": "it's it's an interesting talk because it's a a real use case and pretty large",
    "start": "1513440",
    "end": "1519140"
  },
  {
    "text": "of doing both patch and and kind of more interactive uh analysis is is panda",
    "start": "1519140",
    "end": "1527059"
  },
  {
    "text": "badge processing yet another batch scheduler thing that people have written",
    "start": "1527059",
    "end": "1533600"
  },
  {
    "text": "no panda is like uh it's a specific scheduler for Atlas so they they have their own uh workflow manager on top and",
    "start": "1533600",
    "end": "1542480"
  },
  {
    "text": "that's where all the workloads so panda is their thing so yeah yeah I just wonder whether they is it an open source",
    "start": "1542480",
    "end": "1548720"
  },
  {
    "text": "thing or it is yeah yeah because yeah I can't find anything",
    "start": "1548720",
    "end": "1554299"
  },
  {
    "text": "on it yeah the usable Google address",
    "start": "1554299",
    "end": "1559880"
  },
  {
    "text": "say that again Panda batch processing does not yield a usable Google address so far yeah so I'll give you I'll give",
    "start": "1559880",
    "end": "1567679"
  },
  {
    "text": "you one uh where where the actual documentation is so it is a generic tool but it's very",
    "start": "1567679",
    "end": "1575000"
  },
  {
    "text": "much it's used by other experiments as well but it was developed within Atlas I",
    "start": "1575000",
    "end": "1581480"
  },
  {
    "text": "pasted the link there cool thanks um I wanted to find a link to the talk",
    "start": "1581480",
    "end": "1589159"
  },
  {
    "text": "let's see Atlas so here's the link to the to this one",
    "start": "1589159",
    "end": "1598220"
  },
  {
    "text": "and uh yeah the video should appear there I think they they are done with all the collocated events and they",
    "start": "1598220",
    "end": "1604880"
  },
  {
    "text": "started uploading the main conference videos as well there's some sort of delay where videos are available like if",
    "start": "1604880",
    "end": "1611000"
  },
  {
    "text": "you have the virtual access you can go to to the virtual platform and watch the",
    "start": "1611000",
    "end": "1616159"
  },
  {
    "text": "videos right now otherwise they they will get to YouTube at some point as well",
    "start": "1616159",
    "end": "1622120"
  },
  {
    "text": "and I think that's it that's all I have yeah",
    "start": "1623480",
    "end": "1628179"
  },
  {
    "text": "I think the the expectations were met for for the conference they were and they they mentioned it's 65 percent new",
    "start": "1636980",
    "end": "1644659"
  },
  {
    "text": "attendees in a coupon before so that's pretty impressive",
    "start": "1644659",
    "end": "1651020"
  },
  {
    "text": "it's pretty awesome I was really disappointed to miss out actually but um definitely going to be there and uh",
    "start": "1651020",
    "end": "1657140"
  },
  {
    "text": "we're gonna try to be there in Detroit I really felt like um it was three years",
    "start": "1657140",
    "end": "1663080"
  },
  {
    "text": "worth of budget all spent into one cucumber because of the pandemic I mean quite quite a lot of things going on I",
    "start": "1663080",
    "end": "1670700"
  },
  {
    "text": "have to say it was a good one to be to attend to attend to",
    "start": "1670700",
    "end": "1677260"
  },
  {
    "text": "yeah and definitely you can see the difference of having in-person conferences and being able to",
    "start": "1678500",
    "end": "1684380"
  },
  {
    "text": "like just bump into people and discuss quickly it's very different yeah",
    "start": "1684380",
    "end": "1689480"
  },
  {
    "text": "definitely I remember I attended the virtual one the previous year but then yeah you could see you could definitely",
    "start": "1689480",
    "end": "1695120"
  },
  {
    "text": "feel there was like um yeah it just felt so less so this so to speak",
    "start": "1695120",
    "end": "1700820"
  },
  {
    "text": "um this one I think I really enjoyed the part of the uh the one the part that uh",
    "start": "1700820",
    "end": "1707059"
  },
  {
    "text": "was not in the virtual one uh last year which was the uh sponsorship boost basically you could just go around and",
    "start": "1707059",
    "end": "1712700"
  },
  {
    "text": "and find people and just talk to them which was something of course it was difficult you can't do virtually not in",
    "start": "1712700",
    "end": "1719840"
  },
  {
    "text": "the way you can do it and keep going at least um in person and it was quite massive because there was like two",
    "start": "1719840",
    "end": "1726440"
  },
  {
    "text": "Pavilions full of sponsor showcases it was funny between was uh was killing",
    "start": "1726440",
    "end": "1732860"
  },
  {
    "text": "me to be honest three days after I was I just couldn't move anymore",
    "start": "1732860",
    "end": "1739419"
  },
  {
    "text": "I don't know how he had the strength to also cycle on the weekend but then yeah me I was just barely hanging",
    "start": "1740600",
    "end": "1747820"
  },
  {
    "text": "no yeah so I I think that's that's what I",
    "start": "1748460",
    "end": "1755779"
  },
  {
    "text": "had actually stop here um",
    "start": "1755779",
    "end": "1761200"
  },
  {
    "text": "but one one thing that I I wanted to ask as well um because uh there's not a lot of time",
    "start": "1761240",
    "end": "1768020"
  },
  {
    "text": "between now and October basically so if we organize like a new packs in HPC",
    "start": "1768020",
    "end": "1774500"
  },
  {
    "text": "co-located I think it would be nice because it would help keep the momentum",
    "start": "1774500",
    "end": "1779659"
  },
  {
    "text": "but we need to be really proactive to reaching out to people to to do submissions to make sure we have enough",
    "start": "1779659",
    "end": "1785840"
  },
  {
    "text": "content there were a couple of talks that were quite good that we didn't select for",
    "start": "1785840",
    "end": "1791000"
  },
  {
    "text": "this one but maybe we need to make sure we advertise this as much as possible",
    "start": "1791000",
    "end": "1796700"
  },
  {
    "text": "both in the like new world but also in like uh",
    "start": "1796700",
    "end": "1801919"
  },
  {
    "text": "there are some interest like Nathan is here there was some interest in like involving more things like uh um like",
    "start": "1801919",
    "end": "1810200"
  },
  {
    "text": "more established components like slurm in the HPC environment and and try to kind of to the bridge between the two",
    "start": "1810200",
    "end": "1817220"
  },
  {
    "text": "and see uh what's the way forward I'm sure Nathan will have a lot of opinions about",
    "start": "1817220",
    "end": "1822980"
  },
  {
    "text": "this so that will be pretty awesome also to at that discussion",
    "start": "1822980",
    "end": "1828340"
  },
  {
    "text": "I think his microphone never works though do you think um Ricardo a reached out and suggested that",
    "start": "1829640",
    "end": "1837380"
  },
  {
    "text": "we submit something around Armada we'd be happy to to",
    "start": "1837380",
    "end": "1842539"
  },
  {
    "text": "do something of course um I also wanted in that batch Day do",
    "start": "1842539",
    "end": "1848299"
  },
  {
    "text": "you know how um pretty base ended up on batch day I",
    "start": "1848299",
    "end": "1855140"
  },
  {
    "text": "can't seemed like it was it was a weird one to include especially if we had",
    "start": "1855140",
    "end": "1860299"
  },
  {
    "text": "other good um which one sorry there was a whole talk on pretty base",
    "start": "1860299",
    "end": "1866360"
  },
  {
    "text": "during batch day which seemed I like pretty bass it was Travis Adair and",
    "start": "1866360",
    "end": "1873559"
  },
  {
    "text": "um you know the people who did horovod and Ludwig Ai and it was more ml",
    "start": "1873559",
    "end": "1880220"
  },
  {
    "text": "uh ml yeah so I think it was more to get a",
    "start": "1880220",
    "end": "1887299"
  },
  {
    "text": "yeah I I will have to go back to the notes but I think it was uh because they had like a",
    "start": "1887299",
    "end": "1893240"
  },
  {
    "text": "this idea of a nodeless kubernetes um that is quite interesting and also",
    "start": "1893240",
    "end": "1898520"
  },
  {
    "text": "because they had uh different use case with uh",
    "start": "1898520",
    "end": "1903340"
  },
  {
    "text": "that was the reasoning yeah I think because if you look at the",
    "start": "1904100",
    "end": "1909860"
  },
  {
    "text": "schedule there's there's quite a lot of components or and it's not really vendor but like component based talks but not",
    "start": "1909860",
    "end": "1917600"
  },
  {
    "text": "so much end user talks and I think for the next one it would be really interesting to have those but we need to",
    "start": "1917600",
    "end": "1923840"
  },
  {
    "text": "reach out to I think people yeah but uh",
    "start": "1923840",
    "end": "1929620"
  },
  {
    "text": "I mean if we could get end users of any of the schedules that spoke last time that might be",
    "start": "1929779",
    "end": "1937460"
  },
  {
    "text": "that might be very interesting yeah and the other question will be depending on how many submissions there",
    "start": "1937460",
    "end": "1944600"
  },
  {
    "text": "are if we make it still half day or a full day mm-hmm",
    "start": "1944600",
    "end": "1950440"
  },
  {
    "text": "I'm going to submit something definitely I know the deadlines approaching but I've started it at least",
    "start": "1958159",
    "end": "1964760"
  },
  {
    "text": "yeah that would be amazing you're a Sandbox or you're submitted to",
    "start": "1964760",
    "end": "1970640"
  },
  {
    "text": "sandbox as well right yeah yeah that's well",
    "start": "1970640",
    "end": "1976059"
  },
  {
    "text": "another thing we probably need to do uh what we definitely need to do is work out the next set of agendas for this I",
    "start": "1979399",
    "end": "1986240"
  },
  {
    "text": "think we'll run out now uh tends to work quite well I think certainly up front",
    "start": "1986240",
    "end": "1992659"
  },
  {
    "text": "yeah yeah we could use like five minutes for that yeah I don't know if we'll be able to do",
    "start": "1992659",
    "end": "1998720"
  },
  {
    "text": "it now but we could think about it but yeah we've got as you say it's only really four months",
    "start": "1998720",
    "end": "2003820"
  },
  {
    "text": "until next coupon anyway like the next Roundup but doing doing",
    "start": "2003820",
    "end": "2010179"
  },
  {
    "text": "them in between because cfps is this Friday you know right I know I know",
    "start": "2010179",
    "end": "2016179"
  },
  {
    "text": "I've started it I'm actually I'm traveling to some relatives tonight and I plan to just sit up late and just type",
    "start": "2016179",
    "end": "2022659"
  },
  {
    "text": "up my submission because the for the batch HPC if we organize again the Colo",
    "start": "2022659",
    "end": "2027700"
  },
  {
    "text": "it will be later though cfd but for the main event it closes already this way I'm just gonna get it in it's",
    "start": "2027700",
    "end": "2035159"
  },
  {
    "text": "yeah I guess like if everyone has we can probably drop the topic backlog we have",
    "start": "2038500",
    "end": "2044559"
  },
  {
    "text": "there apart from the gem session I guess",
    "start": "2044559",
    "end": "2048480"
  },
  {
    "text": "and maybe maybe we if people can add their uh",
    "start": "2050460",
    "end": "2056980"
  },
  {
    "text": "what they would like to hear about so we just talked about psyllium and evpf",
    "start": "2056980",
    "end": "2062500"
  },
  {
    "text": "we had other other things mentioned there around so we could get uh",
    "start": "2062500",
    "end": "2068780"
  },
  {
    "text": "[Music] the atlas people also to present because",
    "start": "2068780",
    "end": "2076300"
  },
  {
    "text": "it's uh it's a like a use case would that be okay as well yeah absolutely",
    "start": "2076300",
    "end": "2083940"
  },
  {
    "text": "okay uh we mentioned the Gateway Avi did we",
    "start": "2091480",
    "end": "2096940"
  },
  {
    "text": "ever get the presentation on that probably not right",
    "start": "2096940",
    "end": "2101579"
  },
  {
    "text": "I've missed a couple of sessions but I don't remember one is that is that so uh germane to this",
    "start": "2102099",
    "end": "2108700"
  },
  {
    "text": "group I mean it's it's interesting it's good I don't know do people",
    "start": "2108700",
    "end": "2114160"
  },
  {
    "text": "suffer that in in this world of research",
    "start": "2114160",
    "end": "2121799"
  },
  {
    "text": "the main thing would be how to use that for bursting and multi-cloud things if",
    "start": "2122280",
    "end": "2129400"
  },
  {
    "text": "if at all possible interesting okay",
    "start": "2129400",
    "end": "2134680"
  },
  {
    "text": "um I can see that a little bit it just seems like it's so much more directly useful for if I have a product and I",
    "start": "2134680",
    "end": "2141400"
  },
  {
    "text": "need different uh different HTTP end going to go to different places uh",
    "start": "2141400",
    "end": "2148359"
  },
  {
    "text": "okay yeah but they have this concept because there's the greater API and then there's",
    "start": "2148359",
    "end": "2153760"
  },
  {
    "text": "this multi-cluster service API that basically allows you to make a service",
    "start": "2153760",
    "end": "2159400"
  },
  {
    "text": "external and then Define on the other cluster that it should consume a remote service and then they kind of link to",
    "start": "2159400",
    "end": "2165940"
  },
  {
    "text": "each other things like okay",
    "start": "2165940",
    "end": "2169260"
  },
  {
    "text": "uh what else did we have here",
    "start": "2175320",
    "end": "2179339"
  },
  {
    "text": "cluster API was that one as well yeah yeah we were very interested in",
    "start": "2181000",
    "end": "2187720"
  },
  {
    "text": "that I think we never had that talk about it as well",
    "start": "2187720",
    "end": "2192960"
  },
  {
    "text": "cross plane we did get down it's done",
    "start": "2194200",
    "end": "2201640"
  },
  {
    "text": "uh something about Numa as well that would be pretty cool",
    "start": "2201640",
    "end": "2207040"
  },
  {
    "text": "Maybe yeah probably not for a whole session but I",
    "start": "2207040",
    "end": "2212800"
  },
  {
    "text": "noticed um the other day that proposal finally got merged the one's about six years old around username spacing",
    "start": "2212800",
    "end": "2220599"
  },
  {
    "text": "you see that I did not see that in kubernetes yeah so that and it's coming up in the next",
    "start": "2220599",
    "end": "2227520"
  },
  {
    "text": "uh kubernetes release right oh no I mean it hasn't nothing's been implemented I think this is just like",
    "start": "2227520",
    "end": "2233740"
  },
  {
    "text": "getting the like proposal matched like okay you know I thought there was",
    "start": "2233740",
    "end": "2239680"
  },
  {
    "text": "intent to get it in soon oh maybe I I don't know but but yeah",
    "start": "2239680",
    "end": "2245920"
  },
  {
    "text": "that was uh at least a big step forward having it looks like an agreement on not to do it I'm doing it",
    "start": "2245920",
    "end": "2253300"
  },
  {
    "text": "yeah no that's a super exciting one um",
    "start": "2253300",
    "end": "2258940"
  },
  {
    "text": "maybe the excitement in my voice is not quite uh relaying that excitement but",
    "start": "2258940",
    "end": "2264760"
  },
  {
    "text": "yes super exciting but what what did you see that actually",
    "start": "2264760",
    "end": "2270880"
  },
  {
    "text": "because um oh um hold on I've got it here someone",
    "start": "2270880",
    "end": "2278140"
  },
  {
    "text": "sent it to me",
    "start": "2278140",
    "end": "2281220"
  },
  {
    "text": "oh yeah Alpha release Target 125 okay I see it now",
    "start": "2284980",
    "end": "2290920"
  },
  {
    "text": "I think that's the one that's it yeah yeah I don't think there's",
    "start": "2290920",
    "end": "2296380"
  },
  {
    "text": "okay they are targeting 125 that that's pretty good yeah the uh enhancement got merged",
    "start": "2296380",
    "end": "2304839"
  },
  {
    "text": "basically after about six years",
    "start": "2304839",
    "end": "2310680"
  },
  {
    "text": "which is good I guess there was quite a lot of to figure out on the Kernel on friends yeah",
    "start": "2312220",
    "end": "2317859"
  },
  {
    "text": "yeah no it's not a small one I just saw I imagined it would never happen given that I've been there so",
    "start": "2317859",
    "end": "2323560"
  },
  {
    "text": "long",
    "start": "2323560",
    "end": "2325800"
  },
  {
    "text": "all right that sounds amazing actually I think Jonathan just put uh",
    "start": "2332740",
    "end": "2339960"
  },
  {
    "text": "usernames and ruthless stuff that would be pretty nice and uh",
    "start": "2339960",
    "end": "2348000"
  },
  {
    "text": "yeah I think we should get a talk from Nathan with a microphone as well and dedicated",
    "start": "2348820",
    "end": "2356619"
  },
  {
    "text": "session that'll be good or just sign language",
    "start": "2356619",
    "end": "2364140"
  },
  {
    "text": "we can add those uh Nathan would that be okay to give her like you just mentioned also",
    "start": "2365380",
    "end": "2371440"
  },
  {
    "text": "that uh you have some reports from sites on what",
    "start": "2371440",
    "end": "2377020"
  },
  {
    "text": "they want and what they report it would be interesting to",
    "start": "2377020",
    "end": "2382119"
  },
  {
    "text": "to hear about that as well would that be fine",
    "start": "2382119",
    "end": "2386520"
  },
  {
    "text": "so yes",
    "start": "2394119",
    "end": "2396720"
  },
  {
    "text": "doesn't matter it's a research group doesn't have to be accurate",
    "start": "2403240",
    "end": "2410460"
  },
  {
    "text": "right",
    "start": "2412900",
    "end": "2415380"
  },
  {
    "text": "and the usernetes we also have right",
    "start": "2418780",
    "end": "2422820"
  },
  {
    "text": "we did get a talk from about ruthless uh quite a while ago right it wasn't",
    "start": "2424060",
    "end": "2430300"
  },
  {
    "text": "specifically about usernetes but uh yeah I can't remember God's name",
    "start": "2430300",
    "end": "2438119"
  },
  {
    "text": "hero it's always like a hero on this thing so",
    "start": "2438160",
    "end": "2444760"
  },
  {
    "text": "yeah for sure it was him but I he gave a talk about ruthless but it was more like all the issues of like",
    "start": "2444760",
    "end": "2452200"
  },
  {
    "text": "uh Network and overly fs and uh when you do a user space stuff",
    "start": "2452200",
    "end": "2459579"
  },
  {
    "text": "but maybe like a more focused talk on the usernetes would be cool as well yeah",
    "start": "2459579",
    "end": "2466559"
  },
  {
    "text": "it's a stalker yeah so I I'll just drop the",
    "start": "2472540",
    "end": "2478960"
  },
  {
    "text": "link here because uh where all this ruthless stuff is being",
    "start": "2478960",
    "end": "2486220"
  },
  {
    "text": "tracked by Giuseppe and back here as well",
    "start": "2486220",
    "end": "2491920"
  },
  {
    "text": "that's a good link to have",
    "start": "2491920",
    "end": "2495359"
  },
  {
    "text": "nice okay I think we have maybe maybe take these",
    "start": "2502900",
    "end": "2509740"
  },
  {
    "text": "topics put them in slots and then we we hunt for speakers",
    "start": "2509740",
    "end": "2515560"
  },
  {
    "text": "yeah sounds good sensible Nathan do you have a preference on when to do this like",
    "start": "2515560",
    "end": "2523119"
  },
  {
    "text": "before Summer of the summer",
    "start": "2523119",
    "end": "2526799"
  },
  {
    "text": "all right okay so we can schedule the other ones already and then leave a space",
    "start": "2537460",
    "end": "2545099"
  },
  {
    "text": "awesome okay there's plenty of talks to go and watch now",
    "start": "2545500",
    "end": "2551460"
  },
  {
    "text": "uh should we put all these links in the agenda I won't be able to do it now but",
    "start": "2553720",
    "end": "2559599"
  },
  {
    "text": "maybe maybe later we and then we we link it from the slack channel so that other",
    "start": "2559599",
    "end": "2566140"
  },
  {
    "text": "people can go and check them as well yeah yeah we can get back and get these",
    "start": "2566140",
    "end": "2571180"
  },
  {
    "text": "can we Yeah Yeah from the recording the text is also appearing after",
    "start": "2571180",
    "end": "2577500"
  },
  {
    "text": "I hope I think we can also export it easy no no too much",
    "start": "2577540",
    "end": "2584220"
  },
  {
    "text": "right I think yeah in the recording we can find it",
    "start": "2584220",
    "end": "2590578"
  },
  {
    "text": "awesome",
    "start": "2590980",
    "end": "2593400"
  },
  {
    "text": "I think that's it do we have anything else Jenny no I was just trying to see if I could explore",
    "start": "2598359",
    "end": "2604000"
  },
  {
    "text": "the text easily but yeah that's fine we'll grab it later uh no nothing else for me",
    "start": "2604000",
    "end": "2610420"
  },
  {
    "text": "I haven't got a huge amount of contrary this time unfortunately because I wasn't there um no it's good to see uh",
    "start": "2610420",
    "end": "2618160"
  },
  {
    "text": "people got a lot out of it anyway well one thing is that we do I forgot that because we didn't do this",
    "start": "2618160",
    "end": "2624460"
  },
  {
    "text": "this time but remember we have the possibility of doing uh talk in the",
    "start": "2624460",
    "end": "2629619"
  },
  {
    "text": "maintenance track as well about the group and this last",
    "start": "2629619",
    "end": "2634960"
  },
  {
    "text": "time it actually was quite nice we got a few people interested in the group as well",
    "start": "2634960",
    "end": "2640180"
  },
  {
    "text": "so we can we can consider for Detroit to also have a slot for the group yeah I'm",
    "start": "2640180",
    "end": "2646960"
  },
  {
    "text": "always up for that I think that's good it's just a nice refresher we need to submit it when the maintenance track",
    "start": "2646960",
    "end": "2653099"
  },
  {
    "text": "will come uh we need to submit it there yeah just tap me up I'll uh working it",
    "start": "2653099",
    "end": "2658720"
  },
  {
    "text": "with you okay cool all right",
    "start": "2658720",
    "end": "2665460"
  },
  {
    "text": "good some I guess that's it see you in two weeks",
    "start": "2665500",
    "end": "2675220"
  },
  {
    "text": "yeah thank you yeah yeah so yeah thanks everyone bye",
    "start": "2675220",
    "end": "2681180"
  },
  {
    "text": "thank you bye",
    "start": "2681180",
    "end": "2684720"
  }
]
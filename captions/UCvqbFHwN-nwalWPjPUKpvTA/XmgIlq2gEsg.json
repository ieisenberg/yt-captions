[
  {
    "text": "okay we are finally going to get started apologies to everyone for the delay we",
    "start": "1360",
    "end": "7200"
  },
  {
    "text": "were having some technical difficulties but everything seems to be in working order now so we are going to get started",
    "start": "7200",
    "end": "14160"
  },
  {
    "text": "i'd like to welcome everyone for joining us today and for staying on my name is jerry fallon and welcome to",
    "start": "14160",
    "end": "20000"
  },
  {
    "text": "today's cncf webinar deploying kubernetes to bare metal using cluster api",
    "start": "20000",
    "end": "27359"
  },
  {
    "text": "i'd like to introduce our presenter today sean mccord principal senior software",
    "start": "27359",
    "end": "33600"
  },
  {
    "text": "engineer at talos systems just a few us keeping items before we get started during the webinar you are",
    "start": "33600",
    "end": "39680"
  },
  {
    "text": "not able to talk as an attendee there is a q a box at the bottom of your screen please feel free to drop your questions",
    "start": "39680",
    "end": "45120"
  },
  {
    "text": "in there and we'll get to as many as we can at the end this is an official webinar of the cncf and as such as subjects of the cncf code",
    "start": "45120",
    "end": "51600"
  },
  {
    "text": "of conduct please do not add anything to the chat that are would be in violation of the code of conduct please be respectful of",
    "start": "51600",
    "end": "57600"
  },
  {
    "text": "your fellow participants and presenters and please also note that the recording and slides will be posted later today to",
    "start": "57600",
    "end": "62879"
  },
  {
    "text": "the cncf webinar page at cncf dot io slash webinars and with that i'll hand it over to sean",
    "start": "62879",
    "end": "68240"
  },
  {
    "text": "for today's presentation right thanks jerry",
    "start": "68240",
    "end": "75200"
  },
  {
    "text": "have you ever wanted to manage a fleet of bare metal boxes as easily as you manage kubernetes",
    "start": "75520",
    "end": "81759"
  },
  {
    "text": "workloads do you wish jboss meant just to bust just a bunch of servers",
    "start": "81759",
    "end": "89280"
  },
  {
    "text": "the idea of declarative hardware compute management is the driving horse behind cedaro",
    "start": "89280",
    "end": "96880"
  },
  {
    "text": "the bare metal life cycle can manager and capi infrastructure provider from talos systems",
    "start": "96880",
    "end": "104320"
  },
  {
    "text": "with cluster api all of your compute resources are represented as familiar kubernetes",
    "start": "104720",
    "end": "111759"
  },
  {
    "text": "yaml manifests like any other kubernetes resource you can then group them",
    "start": "111759",
    "end": "117520"
  },
  {
    "text": "into classes apply labels to them modify their settings and see their",
    "start": "117520",
    "end": "122880"
  },
  {
    "text": "status all of the hard work of dealing with machines themselves",
    "start": "122880",
    "end": "128239"
  },
  {
    "text": "and setting up the high availability kubernetes clusters is handled for you",
    "start": "128239",
    "end": "135040"
  },
  {
    "text": "before we get too far however i should say hello as jerry said i am sean mccord i'm a",
    "start": "135280",
    "end": "141440"
  },
  {
    "text": "software engineer at talos systems but before joining talos i was a refugee from core os looking for",
    "start": "141440",
    "end": "149360"
  },
  {
    "text": "a kubernetes focused immutable environment on which to build dynamic clusters",
    "start": "149360",
    "end": "154959"
  },
  {
    "text": "for my real world customers after working with talos from the outside for over a year",
    "start": "154959",
    "end": "161519"
  },
  {
    "text": "i joined the company full time last month i have been living and breathing all",
    "start": "161519",
    "end": "167519"
  },
  {
    "text": "things kubernetes for about five years now so i have formed a few thoughts along the way",
    "start": "167519",
    "end": "173840"
  },
  {
    "text": "i'll be sure to leave plenty of room for questions at the end of this talk",
    "start": "173840",
    "end": "179680"
  },
  {
    "text": "so let's start with the basics what is sedero how is it constructed what does",
    "start": "181120",
    "end": "187760"
  },
  {
    "text": "it do how does it fit into the puzzle of bare metal kubernetes management",
    "start": "187760",
    "end": "195519"
  },
  {
    "text": "cedaro creates kubernetes clusters from a common pool of compute resources",
    "start": "196959",
    "end": "202560"
  },
  {
    "text": "using cluster api basically it lets you have a dynamic set of",
    "start": "202560",
    "end": "208000"
  },
  {
    "text": "generic servers which can be plugged into some racks which will then be automatically",
    "start": "208000",
    "end": "213360"
  },
  {
    "text": "assigned and used in any of a number of kubernetes clusters within the domain of cidaro so if",
    "start": "213360",
    "end": "221360"
  },
  {
    "text": "the generic servers are the iron cedero molds that iron into usable kubernetes clusters with",
    "start": "221360",
    "end": "228959"
  },
  {
    "text": "whatever raw resources are available at the given time it will continue to manage those server",
    "start": "228959",
    "end": "235760"
  },
  {
    "text": "resources as time goes on as servers are added or removed as load",
    "start": "235760",
    "end": "241200"
  },
  {
    "text": "comes and goes and as whole clusters are created or destroyed",
    "start": "241200",
    "end": "246959"
  },
  {
    "text": "kubernetes manages workloads for you cedero and cluster api manage",
    "start": "246959",
    "end": "253200"
  },
  {
    "text": "kubernetes clusters for you cedero itself is made from all the good",
    "start": "253200",
    "end": "260239"
  },
  {
    "text": "things it is fully open source written in go and licensed under the mozilla public",
    "start": "260239",
    "end": "266960"
  },
  {
    "text": "license it runs on kubernetes itself",
    "start": "266960",
    "end": "272000"
  },
  {
    "text": "and it's an infrastructure provider for cluster api capi and as such allows for",
    "start": "272000",
    "end": "278960"
  },
  {
    "text": "higher order tooling to talk to it just like any other capi provider it is built on",
    "start": "278960",
    "end": "285840"
  },
  {
    "text": "talos the kubernetes os and it is purely declarative using kubernetes",
    "start": "285840",
    "end": "291759"
  },
  {
    "text": "manifests for all user side interactions thus it is also easily version controlled",
    "start": "291759",
    "end": "299759"
  },
  {
    "text": "at present there are just four main places and main pieces which define the",
    "start": "300400",
    "end": "305919"
  },
  {
    "text": "operation of citero environments define boot environments for a server",
    "start": "305919",
    "end": "311759"
  },
  {
    "text": "that is to what network should the machine be booted what pixy image should it use what earl",
    "start": "311759",
    "end": "318560"
  },
  {
    "text": "will provide its configuration basically this defines a reusable environment",
    "start": "318560",
    "end": "324720"
  },
  {
    "text": "which will tell any server how to start servers",
    "start": "324720",
    "end": "329840"
  },
  {
    "text": "represent the machines themselves they are automatically created when a machine",
    "start": "329840",
    "end": "335199"
  },
  {
    "text": "first boots it's hardware details are discovered and recorded",
    "start": "335199",
    "end": "340400"
  },
  {
    "text": "and it can then be categorized and designed by cedaro to whatever role deem it deems",
    "start": "340400",
    "end": "347039"
  },
  {
    "text": "appropriate server classes are groupings of servers",
    "start": "347039",
    "end": "352960"
  },
  {
    "text": "these are kin to storage classes in kubernetes in that they can be used as names of",
    "start": "352960",
    "end": "358400"
  },
  {
    "text": "pools of resources whose members discrete identities are not important servers",
    "start": "358400",
    "end": "365199"
  },
  {
    "text": "may be members of any number of server classes and clusters may be defined to use",
    "start": "365199",
    "end": "370960"
  },
  {
    "text": "specific server classes instead of enumerating discrete machines to fill out their",
    "start": "370960",
    "end": "376319"
  },
  {
    "text": "numbers talos config is is generated by the",
    "start": "376319",
    "end": "381440"
  },
  {
    "text": "metadata server to point to the assembled server configuration",
    "start": "381440",
    "end": "386880"
  },
  {
    "text": "folding any patch data from the servers and server classes to configure the node",
    "start": "386880",
    "end": "392479"
  },
  {
    "text": "with the cluster oriented config data and credentials these four sets of",
    "start": "392479",
    "end": "398720"
  },
  {
    "text": "things then allow cidero and cluster api to create and manage clusters for you",
    "start": "398720",
    "end": "408240"
  },
  {
    "text": "we've mentioned telus a few times now but we haven't really defined what it is other than a kubernetes os allow me to",
    "start": "408240",
    "end": "415680"
  },
  {
    "text": "briefly explain it since it is the engine on which our kubernetes clusters themselves run",
    "start": "415680",
    "end": "422479"
  },
  {
    "text": "talos is a modern linux os i mean this rather directly it is not a new linux os",
    "start": "422479",
    "end": "429039"
  },
  {
    "text": "it's a linux os there are no new components in talos it is a secure",
    "start": "429039",
    "end": "435440"
  },
  {
    "text": "immutable and minimal os this may sound like buzzword labingo but because of how",
    "start": "435440",
    "end": "441360"
  },
  {
    "text": "talos is constructed we can actually make it really secure we have enabled all sorts of features",
    "start": "441360",
    "end": "447759"
  },
  {
    "text": "related to security including in the kernel itself which could not be enabled on a more general purpose os our entire",
    "start": "447759",
    "end": "456000"
  },
  {
    "text": "os is run from a read only squash fs image meaning there really is no way to modify",
    "start": "456000",
    "end": "461919"
  },
  {
    "text": "it from within the user space and it is really quite minimal it",
    "start": "461919",
    "end": "467199"
  },
  {
    "text": "literally comes with only the tools necessary to run kubernetes there are no",
    "start": "467199",
    "end": "472879"
  },
  {
    "text": "extraneous demons or binaries talus is an entire os built from scratch",
    "start": "472879",
    "end": "478400"
  },
  {
    "text": "in go on the linux kernel no other services run on it",
    "start": "478400",
    "end": "483759"
  },
  {
    "text": "no other services are even installed onto not even so much as an ls or a cat",
    "start": "483759",
    "end": "491120"
  },
  {
    "text": "there is no ssh there is no shell because there is no shell there is no",
    "start": "491120",
    "end": "496240"
  },
  {
    "text": "point in ssh and because there is no ssh there is no point in the shell everything runs inside a container other",
    "start": "496240",
    "end": "503520"
  },
  {
    "text": "than the container run time itself the entire point of the os is to quickly",
    "start": "503520",
    "end": "509520"
  },
  {
    "text": "start and run kubernetes so now that we've taken everything away",
    "start": "509520",
    "end": "515200"
  },
  {
    "text": "here is what we give you instead apis",
    "start": "515200",
    "end": "521839"
  },
  {
    "text": "everything in talos is controlled by api this makes it trivial to integrate into",
    "start": "523200",
    "end": "529200"
  },
  {
    "text": "machine controlled environments like sedero and cluster api it makes",
    "start": "529200",
    "end": "534399"
  },
  {
    "text": "complicated config managers a thing of the past there may not be a shell on the servers",
    "start": "534399",
    "end": "540160"
  },
  {
    "text": "but with the cli tool and the api you can script or code any kind of",
    "start": "540160",
    "end": "545200"
  },
  {
    "text": "automation from anywhere else in a way far more deterministic",
    "start": "545200",
    "end": "550240"
  },
  {
    "text": "and certain than a haphazard set of independent shell utilities discreetly and hopefully installed on",
    "start": "550240",
    "end": "557680"
  },
  {
    "text": "each server apis are the key to talos and make talos the ideal kubernetes os",
    "start": "557680",
    "end": "565760"
  },
  {
    "text": "for sedero sedero is in active development we have",
    "start": "565760",
    "end": "572399"
  },
  {
    "text": "a lot planned for it in the future but it is also already coming with a",
    "start": "572399",
    "end": "577519"
  },
  {
    "text": "great set of features which make it really useful to control your bare metal kubernetes clusters",
    "start": "577519",
    "end": "584640"
  },
  {
    "text": "sedero has a bunch of automation features built in to manage servers it bundles in an ipixi server to network",
    "start": "585519",
    "end": "593120"
  },
  {
    "text": "boot all your servers it has a tftp server to shim all your non-ipixi machines up",
    "start": "593120",
    "end": "600160"
  },
  {
    "text": "to the ipixi server it supports metadata distribution through an http based metadata server",
    "start": "600160",
    "end": "609519"
  },
  {
    "text": "it includes an ipmi client to control power and boots from an out-of-band management",
    "start": "609519",
    "end": "615519"
  },
  {
    "text": "network sedero itself acts as a kubernetes controller",
    "start": "615519",
    "end": "620959"
  },
  {
    "text": "to continuously manage your grew sources sedero is of course built to respond to",
    "start": "620959",
    "end": "627440"
  },
  {
    "text": "changes over time these dynamics include scale up scale down of clusters",
    "start": "627440",
    "end": "633519"
  },
  {
    "text": "along with the creation and deletion of them it is expected that servers will be",
    "start": "633519",
    "end": "640000"
  },
  {
    "text": "added removed and reused so cedaro includes a number of life cycle features such as making sure",
    "start": "640000",
    "end": "647519"
  },
  {
    "text": "disks are wiped collecting all of the hardware specifications for each machine",
    "start": "647519",
    "end": "652720"
  },
  {
    "text": "and seamlessly handling machine ads and removes to and from the network because cedaro",
    "start": "652720",
    "end": "660000"
  },
  {
    "text": "is a cappy provider it will fit in well with hybrid cloud setups",
    "start": "660000",
    "end": "665120"
  },
  {
    "text": "and with other capi providers",
    "start": "665120",
    "end": "669279"
  },
  {
    "text": "so now that we've gone through what cedaro is and does let's see if we can make it come to life",
    "start": "670320",
    "end": "676399"
  },
  {
    "text": "with a live demo",
    "start": "676399",
    "end": "689279"
  },
  {
    "text": "the moment of truth do we have visibility",
    "start": "689279",
    "end": "694240"
  },
  {
    "text": "yes",
    "start": "694640",
    "end": "696880"
  },
  {
    "text": "so first of all we are starting out with a bootstrap cluster",
    "start": "700160",
    "end": "707279"
  },
  {
    "text": "running our cluster our citaro components we have first of all to create",
    "start": "707279",
    "end": "715040"
  },
  {
    "text": "a few servers in this case we'll run them as vms",
    "start": "715040",
    "end": "721519"
  },
  {
    "text": "rather than having to plug them in",
    "start": "721519",
    "end": "725279"
  },
  {
    "text": "directly",
    "start": "728839",
    "end": "731839"
  },
  {
    "text": "now we have a number of machines running in the background qamu machines",
    "start": "753920",
    "end": "761519"
  },
  {
    "text": "and these machines will be picked up",
    "start": "761680",
    "end": "765839"
  },
  {
    "text": "by sedero and automatically added to the inventory list as they come",
    "start": "768000",
    "end": "774000"
  },
  {
    "text": "online they're being cleaned so as we can see three out of the four are clean",
    "start": "774000",
    "end": "780639"
  },
  {
    "text": "and the last one should now soon be clean",
    "start": "780880",
    "end": "788240"
  },
  {
    "text": "now that we have our servers we have",
    "start": "797279",
    "end": "802320"
  },
  {
    "text": "a minimal clustered cluster definition defined here to get us started with",
    "start": "802720",
    "end": "810000"
  },
  {
    "text": "a basic kubernetes cluster this was automatically generated by our provider these are using just the",
    "start": "810000",
    "end": "819760"
  },
  {
    "text": "defaults so now we've created our cluster",
    "start": "826839",
    "end": "833839"
  },
  {
    "text": "we need to",
    "start": "835920",
    "end": "842000"
  },
  {
    "text": "yes all four of them are now clean",
    "start": "842000",
    "end": "845920"
  },
  {
    "text": "so the first thing we need to do is to get talus config this is the machine configuration or the",
    "start": "849120",
    "end": "856720"
  },
  {
    "text": "client configuration to act to allow us to access the machine",
    "start": "856720",
    "end": "871839"
  },
  {
    "text": "um",
    "start": "896839",
    "end": "899839"
  },
  {
    "text": "new laptop to forgive me if my typos are getting distracting",
    "start": "902320",
    "end": "913839"
  },
  {
    "text": "so at this point we're just configuring our telus ctl client our local client to be able to talk to our",
    "start": "915600",
    "end": "923120"
  },
  {
    "text": "new machine",
    "start": "923120",
    "end": "927839"
  },
  {
    "text": "now that we have done that we should be able to get our cube config",
    "start": "933759",
    "end": "941839"
  },
  {
    "text": "so we can use this cube config to get our list of nodes it's like it",
    "start": "947279",
    "end": "954160"
  },
  {
    "text": "still hasn't come back come up yet so we'll just see",
    "start": "954160",
    "end": "960639"
  },
  {
    "text": "where it is along in the process so this is our allocated node i'm going to get the logs of this",
    "start": "964240",
    "end": "972720"
  },
  {
    "text": "just from qemu",
    "start": "972720",
    "end": "976879"
  },
  {
    "text": "so looks like it has been enabled and it just came up",
    "start": "979199",
    "end": "985600"
  },
  {
    "text": "so if we get nodes now we now see one master control plane node",
    "start": "988320",
    "end": "995360"
  },
  {
    "text": "it's not quite ready but this should be quick as soon as it starts cni",
    "start": "995360",
    "end": "1010240"
  },
  {
    "text": "there we go so we have now our cluster it's pretty useless at this point",
    "start": "1010240",
    "end": "1016160"
  },
  {
    "text": "consisting of only a single node a single control plane node so let's scale this up",
    "start": "1016160",
    "end": "1025520"
  },
  {
    "text": "we're going to make this uh into a fully h a control plane by increasing",
    "start": "1025520",
    "end": "1032720"
  },
  {
    "text": "the number of replicas to from one to three",
    "start": "1032720",
    "end": "1039360"
  },
  {
    "text": "as we wait here depending on where the other machines are in their boot cycles we should see",
    "start": "1039360",
    "end": "1046319"
  },
  {
    "text": "them come up and be allocated shortly",
    "start": "1046319",
    "end": "1053840"
  },
  {
    "text": "this is a short-term optimization that we will be getting to get this a little faster",
    "start": "1055039",
    "end": "1062160"
  },
  {
    "text": "but there we have one should get one more allocated",
    "start": "1062160",
    "end": "1067840"
  },
  {
    "text": "there we have the second so if we watch the logs of this one",
    "start": "1077919",
    "end": "1084720"
  },
  {
    "text": "first one",
    "start": "1084720",
    "end": "1087280"
  },
  {
    "text": "we can see that we have we are in downloading the installer",
    "start": "1092080",
    "end": "1097679"
  },
  {
    "text": "it's installing talos to the disk it's now rebooting having installed",
    "start": "1097679",
    "end": "1106840"
  },
  {
    "text": "delos",
    "start": "1106840",
    "end": "1109840"
  },
  {
    "text": "starting the container run time",
    "start": "1114880",
    "end": "1118559"
  },
  {
    "text": "starting talos services and etcd joining the fcd cluster we've started",
    "start": "1120640",
    "end": "1127440"
  },
  {
    "text": "the kubelet",
    "start": "1127440",
    "end": "1136880"
  },
  {
    "text": "and kublaid is up on chord on the node so if we get our node list again",
    "start": "1136880",
    "end": "1145600"
  },
  {
    "text": "we now have three control plane nodes two of which are ready the other one shouldn't be long be fine",
    "start": "1145600",
    "end": "1151600"
  },
  {
    "text": "there we have it and just to show our control plane",
    "start": "1151600",
    "end": "1157039"
  },
  {
    "text": "is in fact ha we have three api servers three",
    "start": "1157039",
    "end": "1164000"
  },
  {
    "text": "controller managers schedulers and we are now an ha control",
    "start": "1164000",
    "end": "1169760"
  },
  {
    "text": "plane so we still don't have any workers so let's go ahead and scale up our",
    "start": "1169760",
    "end": "1179200"
  },
  {
    "text": "worker machines we'll just create one because of my poor laptop's limitations",
    "start": "1179200",
    "end": "1186799"
  },
  {
    "text": "but this last machine should shortly be allocated by cedaro again automatically out of the pool",
    "start": "1188080",
    "end": "1194799"
  },
  {
    "text": "that's available which consists now of only one out of four machines",
    "start": "1194799",
    "end": "1207840"
  },
  {
    "text": "and it has now been all out allocated we'll just watch this being a worker",
    "start": "1207919",
    "end": "1214320"
  },
  {
    "text": "node it should be a little faster",
    "start": "1214320",
    "end": "1221840"
  },
  {
    "text": "so installed rebooting",
    "start": "1222720",
    "end": "1235840"
  },
  {
    "text": "started almost started to couplet",
    "start": "1238480",
    "end": "1243360"
  },
  {
    "text": "now we started the couplet",
    "start": "1247600",
    "end": "1250880"
  },
  {
    "text": "apid was hanging a little bit but all is well and we are uncordoned we should have",
    "start": "1257039",
    "end": "1266320"
  },
  {
    "text": "shortly we've added the worker node and their cni's up we now have a",
    "start": "1267600",
    "end": "1274400"
  },
  {
    "text": "complete sys cluster with three masternodes in ha configuration and one worker node",
    "start": "1274400",
    "end": "1282240"
  },
  {
    "text": "if i had a bigger laptop or real machines we would then be able to expand the number of workers",
    "start": "1282240",
    "end": "1289440"
  },
  {
    "text": "to fill out whatever we needed we can also just as easily create new clusters",
    "start": "1289440",
    "end": "1297200"
  },
  {
    "text": "entirely separately and cedero will manage any number of those",
    "start": "1297200",
    "end": "1304400"
  },
  {
    "text": "all right let's get back to the last bit of the presentation",
    "start": "1304400",
    "end": "1319840"
  },
  {
    "text": "so as i mentioned cedaro is in active development we are looking to add quite a number of",
    "start": "1324000",
    "end": "1330159"
  },
  {
    "text": "features both to it and around it among these",
    "start": "1330159",
    "end": "1335360"
  },
  {
    "text": "are auto scaling so as you saw i scaled up manually the number of nodes",
    "start": "1335360",
    "end": "1342480"
  },
  {
    "text": "in each class but we want to be able to have scenario controller",
    "start": "1342480",
    "end": "1348159"
  },
  {
    "text": "automatically scale up and down clusters based on the number of criteria first",
    "start": "1348159",
    "end": "1354080"
  },
  {
    "text": "among these criteria are by time and by load in the future we",
    "start": "1354080",
    "end": "1359760"
  },
  {
    "text": "also want to be able to coordinate competition for limited resources based on priorities between the clusters",
    "start": "1359760",
    "end": "1368080"
  },
  {
    "text": "talos is api driven and we will be building apis around sederos",
    "start": "1368080",
    "end": "1373840"
  },
  {
    "text": "sidero as well to make sure that it can be controlled with the same freedom as talus itself this would provide",
    "start": "1373840",
    "end": "1381840"
  },
  {
    "text": "high-level apis with wide-reaching effects ideally one could simply create a",
    "start": "1381840",
    "end": "1387360"
  },
  {
    "text": "cluster a complete kubernetes cluster with a single api call",
    "start": "1387360",
    "end": "1393679"
  },
  {
    "text": "we spent a lot of work getting key management right with talos and when and we want to make it even",
    "start": "1393919",
    "end": "1399520"
  },
  {
    "text": "better with sedero by coordinating pki chains from there",
    "start": "1399520",
    "end": "1404960"
  },
  {
    "text": "we would be able to share branch or separate cas between clusters to match any number",
    "start": "1404960",
    "end": "1411840"
  },
  {
    "text": "of security layouts edge computing and kubernetes may sound odd at first",
    "start": "1411840",
    "end": "1417840"
  },
  {
    "text": "but it is an incredibly hot topic these days the idea of running small or even single",
    "start": "1417840",
    "end": "1424400"
  },
  {
    "text": "node clusters at the edge is compelling to quite a number of industries and cedero and talos",
    "start": "1424400",
    "end": "1430000"
  },
  {
    "text": "are well placed to fill this role so too is the idea of clusters with",
    "start": "1430000",
    "end": "1435600"
  },
  {
    "text": "distributed nodes where one or a small number of workers are located at a number of sites",
    "start": "1435600",
    "end": "1443279"
  },
  {
    "text": "communicate communicating with masternodes in the cloud or at a data center",
    "start": "1443279",
    "end": "1450640"
  },
  {
    "text": "with cedero we bring the power of managed kubernetes to the world of bare metal machines in a",
    "start": "1451520",
    "end": "1458400"
  },
  {
    "text": "simple but powerful way automated and fault tolerant dynamic and adaptive soon jboss",
    "start": "1458400",
    "end": "1466799"
  },
  {
    "text": "really will mean just a bunch of servers",
    "start": "1466799",
    "end": "1472400"
  },
  {
    "text": "talos and sedero are open source community oriented projects",
    "start": "1472400",
    "end": "1478240"
  },
  {
    "text": "as a community member i felt how earnestly the team is invested in the community",
    "start": "1478240",
    "end": "1483279"
  },
  {
    "text": "as a team member i know how much the community means and how much it drives the",
    "start": "1483279",
    "end": "1489279"
  },
  {
    "text": "development of these projects so join in we have a slack on which we discuss talos",
    "start": "1489279",
    "end": "1494799"
  },
  {
    "text": "sedero cluster api and related things all of our source code is of course on",
    "start": "1494799",
    "end": "1501520"
  },
  {
    "text": "github and pri prs are always welcome you can find the documentation at cedaro",
    "start": "1501520",
    "end": "1508640"
  },
  {
    "text": "fort cidero at cedera.dev and tell us at talos.dev",
    "start": "1508640",
    "end": "1515840"
  },
  {
    "text": "thanks for your time and i'm happy to open the floor now for any questions",
    "start": "1516240",
    "end": "1521600"
  },
  {
    "text": "all right thank you again for a wonderful presentation um we have plenty of time for questions",
    "start": "1521600",
    "end": "1527840"
  },
  {
    "text": "so everyone please feel free to drop in any questions into the q a box and we'll get",
    "start": "1527840",
    "end": "1533360"
  },
  {
    "text": "to as many as we can we have a few here first one up is there any dependency on the bootstrap node",
    "start": "1533360",
    "end": "1540400"
  },
  {
    "text": "after the installation is complete no not for the clusters themselves",
    "start": "1540400",
    "end": "1546960"
  },
  {
    "text": "however like as with many kubernetes resources you do want to maintain it over time so",
    "start": "1546960",
    "end": "1554480"
  },
  {
    "text": "that all of the dynamic features are available in the same way that you can lose your control plane in kubernetes",
    "start": "1554480",
    "end": "1560480"
  },
  {
    "text": "you don't have to maintain sedaro but if you want any of the dynamic features of sedero",
    "start": "1560480",
    "end": "1566320"
  },
  {
    "text": "you do want to maintain cedaro to react to those changes",
    "start": "1566320",
    "end": "1572080"
  },
  {
    "text": "okay next up can one of the masters be used as a bootstrap once it's up for maintenance and",
    "start": "1572240",
    "end": "1578080"
  },
  {
    "text": "upgrades i'm thinking this is not possible to due to the absence of ssh",
    "start": "1578080",
    "end": "1585840"
  },
  {
    "text": "uh i'm not sure i follow that um so the",
    "start": "1586400",
    "end": "1593360"
  },
  {
    "text": "uh sorry maybe you can repeat that again and i'll see if i can get it a second time can one of the masters be",
    "start": "1593600",
    "end": "1601200"
  },
  {
    "text": "used as a bootstrap once it's up for maintenance and upgrades i'm thinking this is not possible due to",
    "start": "1601200",
    "end": "1608720"
  },
  {
    "text": "the absence of ssh so i do not see what ssh has to do with",
    "start": "1608720",
    "end": "1616320"
  },
  {
    "text": "it um we if by masters for the bootstrap it",
    "start": "1616320",
    "end": "1623600"
  },
  {
    "text": "the bootstrap cluster really can be any kubernetes cluster i for the demonstration i just used a",
    "start": "1623600",
    "end": "1630000"
  },
  {
    "text": "single node uh kubernetes cluster because that's the minimal required configuration there's no reason",
    "start": "1630000",
    "end": "1636799"
  },
  {
    "text": "the bootstrap cluster couldn't be a cloud hosted",
    "start": "1636799",
    "end": "1642000"
  },
  {
    "text": "or well probably cloud hosted would be difficult because of the network but it can certainly be an h a control plane",
    "start": "1642000",
    "end": "1650080"
  },
  {
    "text": "cluster it can have workers it can have any number of things in fact what i use myself is a third",
    "start": "1650080",
    "end": "1657279"
  },
  {
    "text": "cluster uh that is legacy running core os and it runs as my bootstrap cluster uh in my own",
    "start": "1657279",
    "end": "1665279"
  },
  {
    "text": "network so in that way yes you can absolutely run",
    "start": "1665279",
    "end": "1671279"
  },
  {
    "text": "maintenance on the bootstrap cluster but again it's perfectly fine to lose your",
    "start": "1671279",
    "end": "1677120"
  },
  {
    "text": "bootstrap cluster briefly for any kind of maintenance so i'm not sure if that's where your question was",
    "start": "1677120",
    "end": "1683600"
  },
  {
    "text": "directed but hopefully that will answer it",
    "start": "1683600",
    "end": "1687840"
  },
  {
    "text": "you may have already mentioned this but what is the footprint of talos distro",
    "start": "1688720",
    "end": "1694799"
  },
  {
    "text": "ah so yes i did not mention the actual numbers but i believe it's somewhat uh it changes over time a",
    "start": "1694799",
    "end": "1701919"
  },
  {
    "text": "little bit but we've we've made some optimizations i believe it comes in now uh pretty well under 100 megabytes",
    "start": "1701919",
    "end": "1711840"
  },
  {
    "text": "okay next question um which cni um can i use",
    "start": "1714480",
    "end": "1722080"
  },
  {
    "text": "any cni's are good with this there's nothing special about cni nothing in our system requires any",
    "start": "1723520",
    "end": "1731039"
  },
  {
    "text": "particular cni uh because you're bare metal of course you won't be able to use uh cloud based cni's but there are",
    "start": "1731039",
    "end": "1738960"
  },
  {
    "text": "plenty of others out there uh that are well adapted and it really just depends on",
    "start": "1738960",
    "end": "1745120"
  },
  {
    "text": "how you want them to work okay next question how are updates to",
    "start": "1745120",
    "end": "1752480"
  },
  {
    "text": "the components like xd applied over time",
    "start": "1752480",
    "end": "1757600"
  },
  {
    "text": "sure so these are uh controlled by talos itself at cd and the",
    "start": "1758320",
    "end": "1766559"
  },
  {
    "text": "control plane components of your kubernetes distribution so all of those are currently controlled",
    "start": "1766559",
    "end": "1772320"
  },
  {
    "text": "directly with the talus ctl and the api for telus however that is one of the things that",
    "start": "1772320",
    "end": "1778880"
  },
  {
    "text": "we want to build in to sit arrow over time so that we can maintain those in the same declarative",
    "start": "1778880",
    "end": "1786480"
  },
  {
    "text": "resources as we do currently for everything else in the cluster so presently they're maintained by api",
    "start": "1786480",
    "end": "1794640"
  },
  {
    "text": "directly to telos in the future we'll be building that same uh system into the declarative",
    "start": "1794640",
    "end": "1802399"
  },
  {
    "text": "uh manifests for citaro okay does talos support killian",
    "start": "1802399",
    "end": "1810720"
  },
  {
    "text": "yes absolutely uh in fact most of us use psyllium um as our default cni",
    "start": "1810720",
    "end": "1818159"
  },
  {
    "text": "is it production ready well i should think so i before i joined",
    "start": "1819200",
    "end": "1825760"
  },
  {
    "text": "talos i managed a number of production talos clusters i did not use",
    "start": "1825760",
    "end": "1833279"
  },
  {
    "text": "sedero personally before i joined talos but it is talos themselves use sedero",
    "start": "1833279",
    "end": "1841440"
  },
  {
    "text": "for all of the dog fooded clusters and i am rapidly converting over my clusters",
    "start": "1841440",
    "end": "1848559"
  },
  {
    "text": "over to sedero so it is stable it simply doesn't have",
    "start": "1848559",
    "end": "1854240"
  },
  {
    "text": "most of the features that we want for the final product so can we use it in production yes it's",
    "start": "1854240",
    "end": "1859679"
  },
  {
    "text": "probably a little early for most people to use it in production can you give a little more insight on",
    "start": "1859679",
    "end": "1867200"
  },
  {
    "text": "the role and architecture of the bootstrap cluster sure as i said before",
    "start": "1867200",
    "end": "1873919"
  },
  {
    "text": "there's nothing special about the bootstrap cluster the main thing it needs is at least",
    "start": "1873919",
    "end": "1880159"
  },
  {
    "text": "layer 3 connectivity layer 2 is better if you want to use the dhcp",
    "start": "1880159",
    "end": "1885519"
  },
  {
    "text": "components but layer 3 is sufficient connectivity between your bootstrap cluster and",
    "start": "1885519",
    "end": "1891760"
  },
  {
    "text": "the clusters you want to create the machines from which the clusters you want to create are in",
    "start": "1891760",
    "end": "1899360"
  },
  {
    "text": "so that's really the only requirement it is otherwise just a plain old",
    "start": "1899360",
    "end": "1904799"
  },
  {
    "text": "kubernetes cluster however that is built it can be built by talos directly manually or",
    "start": "1904799",
    "end": "1911519"
  },
  {
    "text": "it can be hosted there are any number of ways you can go about it but there is nothing at all special",
    "start": "1911519",
    "end": "1917919"
  },
  {
    "text": "about the bootstrap cluster has metal lb been tested in talus or",
    "start": "1917919",
    "end": "1925360"
  },
  {
    "text": "trefek absolutely i use it myself i use it everywhere okay",
    "start": "1925360",
    "end": "1932640"
  },
  {
    "text": "how would you do a container's bare metal model with telos that's verified and certified for a",
    "start": "1932640",
    "end": "1938799"
  },
  {
    "text": "variety of hw ingredients oh i didn't follow that at all sir celos",
    "start": "1938799",
    "end": "1947120"
  },
  {
    "text": "uh are you can you repeat that sorry yeah let me repeat it how would you do",
    "start": "1947120",
    "end": "1952559"
  },
  {
    "text": "containers bare metal model with telos verified and certified for a variety of",
    "start": "1952559",
    "end": "1958399"
  },
  {
    "text": "hw ingredients telos is talos",
    "start": "1958399",
    "end": "1964320"
  },
  {
    "text": "oh okay all right let's read that i apologize all right",
    "start": "1964320",
    "end": "1970640"
  },
  {
    "text": "sorry i i i i still don't really follow that question uh are we talking about arbitrary",
    "start": "1971519",
    "end": "1977840"
  },
  {
    "text": "containers outside of kubernetes john i think are we talking about validation of content sorry go ahead tim",
    "start": "1977840",
    "end": "1983760"
  },
  {
    "text": "i think i understand the question i think the question is um how do you uh how do you certify and",
    "start": "1983760",
    "end": "1990640"
  },
  {
    "text": "verify talos for diff on bare metal for a lot of different uh compute environments a lot of different",
    "start": "1990640",
    "end": "1996399"
  },
  {
    "text": "you know brands of hardware and so on and um the good news is is that you know talos is a linux",
    "start": "1996399",
    "end": "2002399"
  },
  {
    "text": "based operating system so we rely on the work that the linux kernel team has done to uh handle bare metal installations",
    "start": "2002399",
    "end": "2009760"
  },
  {
    "text": "and and and runtime so anything that basically anything that anything that can run linux can run talos um there might be details",
    "start": "2009760",
    "end": "2016640"
  },
  {
    "text": "in there in terms of hardware support and you know if you need an obscure driver that's not in our",
    "start": "2016640",
    "end": "2022720"
  },
  {
    "text": "default build you might need to build your own version of talos but we have some some tools and",
    "start": "2022720",
    "end": "2028640"
  },
  {
    "text": "some advice for doing that can a machine run a master and workers",
    "start": "2028640",
    "end": "2036399"
  },
  {
    "text": "at the same time",
    "start": "2036399",
    "end": "2039360"
  },
  {
    "text": "with virtualization yes in general you wouldn't",
    "start": "2042080",
    "end": "2050079"
  },
  {
    "text": "in general what we term as a machine is running a single role but as with kubernetes",
    "start": "2050079",
    "end": "2056320"
  },
  {
    "text": "generally you can run workloads on control plane nodes it's just not generally",
    "start": "2056320",
    "end": "2062320"
  },
  {
    "text": "recommended to do so but we have a number of places where we're running for instance single node",
    "start": "2062320",
    "end": "2068158"
  },
  {
    "text": "clusters where you absolutely need to do exactly that run workloads on the master because",
    "start": "2068159",
    "end": "2074638"
  },
  {
    "text": "the master is the only one that exists okay how is this different than or",
    "start": "2074639",
    "end": "2080960"
  },
  {
    "text": "inspired by core operating systems tectonic or its successors such as flat car linux",
    "start": "2080960",
    "end": "2089118"
  },
  {
    "text": "so that's a curious question uh the original implementation of talos had very little",
    "start": "2089119",
    "end": "2095280"
  },
  {
    "text": "to do with core os uh andrew didn't really build it on coreos he didn't really have much",
    "start": "2095280",
    "end": "2102640"
  },
  {
    "text": "reference to coreos itself from my perspective it is",
    "start": "2102640",
    "end": "2108079"
  },
  {
    "text": "absolutely a next step from core os",
    "start": "2108079",
    "end": "2114240"
  },
  {
    "text": "that is it's a spiritual successor even if technologically it doesn't really share much",
    "start": "2114240",
    "end": "2120079"
  },
  {
    "text": "uh between the two uh i do think a lot of the features and and some of",
    "start": "2120079",
    "end": "2125359"
  },
  {
    "text": "the direction we want to do absolutely go through the same processes",
    "start": "2125359",
    "end": "2131680"
  },
  {
    "text": "that coreos did but generally speaking they don't share",
    "start": "2131680",
    "end": "2136720"
  },
  {
    "text": "a direct history curiously enough",
    "start": "2136720",
    "end": "2141119"
  },
  {
    "text": "do you have any experience using local storage platforms like rock set or top of them",
    "start": "2141839",
    "end": "2150000"
  },
  {
    "text": "i don't know any of those as far as uh storage we have",
    "start": "2153839",
    "end": "2160560"
  },
  {
    "text": "generally i think most of us have used seth uh for our storage systems i",
    "start": "2160560",
    "end": "2167040"
  },
  {
    "text": "don't know i don't know the ones you just referenced sorry",
    "start": "2167040",
    "end": "2173839"
  },
  {
    "text": "sean it's a rook and toppo lvm oh rook yes uh yeah exactly uh so rook",
    "start": "2174160",
    "end": "2181359"
  },
  {
    "text": "uh is what i believe most of us do use on a regular basis",
    "start": "2181359",
    "end": "2187838"
  },
  {
    "text": "my bespoke my my bespoke bare metal cluster is using vaults secret encryption and as",
    "start": "2191200",
    "end": "2198160"
  },
  {
    "text": "such requires customization of ectd on the masters running equity",
    "start": "2198160",
    "end": "2203280"
  },
  {
    "text": "additionally use i additionally i use topofolm to provide local storage which requires",
    "start": "2203280",
    "end": "2209839"
  },
  {
    "text": "a custom scheduler plugin could i customize my installation to this degree",
    "start": "2209839",
    "end": "2217040"
  },
  {
    "text": "not as yet but we have discussed this many times and it is definitely something",
    "start": "2217599",
    "end": "2223119"
  },
  {
    "text": "we are going to build out a lot of people use a vault integration and so",
    "start": "2223119",
    "end": "2230560"
  },
  {
    "text": "that's something we definitely want to work through as it stands right now we have not had direct",
    "start": "2230560",
    "end": "2235839"
  },
  {
    "text": "requests for this we simply know that it exists so by all means if you have a feature",
    "start": "2235839",
    "end": "2242160"
  },
  {
    "text": "like that we absolutely want to build it out we just don't have users currently",
    "start": "2242160",
    "end": "2248000"
  },
  {
    "text": "demanding it so we don't have an enumeration of what those requirements might be",
    "start": "2248000",
    "end": "2254720"
  },
  {
    "text": "okay does it work with any kind of bare metal",
    "start": "2254960",
    "end": "2260720"
  },
  {
    "text": "servers any kind is probably a little broad uh",
    "start": "2260720",
    "end": "2266560"
  },
  {
    "text": "but we do try and work with all of the most common machines as tim mentioned uh",
    "start": "2266560",
    "end": "2274079"
  },
  {
    "text": "drivers are usually the main thing and there we have definitely come into cases where",
    "start": "2274079",
    "end": "2280000"
  },
  {
    "text": "a driver in the kernel was not loaded that was required for a particular machine",
    "start": "2280000",
    "end": "2286160"
  },
  {
    "text": "this is usually a very quick turnaround that we just enabled the driver make a new release",
    "start": "2286160",
    "end": "2291200"
  },
  {
    "text": "and you can go from there but in general there's nothing special about the servers that are required to run",
    "start": "2291200",
    "end": "2297200"
  },
  {
    "text": "talos or cedaro okay do we have any other questions at all um",
    "start": "2297200",
    "end": "2304320"
  },
  {
    "text": "[Music] we still have plenty of time for questions so please feel free to drop",
    "start": "2304320",
    "end": "2310480"
  },
  {
    "text": "them into the q a box",
    "start": "2310480",
    "end": "2313838"
  },
  {
    "text": "what about cluster api",
    "start": "2324480",
    "end": "2328160"
  },
  {
    "text": "well cedaro is built on it uh it interfaces everything uh through cluster api uh primitives",
    "start": "2330079",
    "end": "2338560"
  },
  {
    "text": "and of course cetero is provided with cluster api as a default",
    "start": "2338560",
    "end": "2346640"
  },
  {
    "text": "default available infrastructure provider for cluster api so",
    "start": "2346640",
    "end": "2352960"
  },
  {
    "text": "you can actually use cluster ctl to perform operations on the uh clusters and",
    "start": "2352960",
    "end": "2360640"
  },
  {
    "text": "it will citra will just handle those requests exactly like any other cluster api",
    "start": "2360640",
    "end": "2366800"
  },
  {
    "text": "provider will if i need to install some custom",
    "start": "2366800",
    "end": "2372720"
  },
  {
    "text": "software to host a machine can i do it",
    "start": "2372720",
    "end": "2377760"
  },
  {
    "text": "yes in all cases we want to prefer that people use the custom",
    "start": "2378560",
    "end": "2385760"
  },
  {
    "text": "build the custom software into kubernetes itself even if it is machine oriented and",
    "start": "2385760",
    "end": "2391760"
  },
  {
    "text": "machine localized either by using daemon sets or by using deployments with specific",
    "start": "2391760",
    "end": "2398480"
  },
  {
    "text": "selectors that said we do have a plug-in system that we are building out to be",
    "start": "2398480",
    "end": "2404720"
  },
  {
    "text": "able to with some restrictions uh run arbitrary containers",
    "start": "2404720",
    "end": "2411440"
  },
  {
    "text": "at boot outside of kubernetes but up to this point we haven't had any need",
    "start": "2411440",
    "end": "2417520"
  },
  {
    "text": "to do any of that we have the facility it's not built out it's not exposed as",
    "start": "2417520",
    "end": "2422640"
  },
  {
    "text": "yet but should the need arise we do have that ability we just have to build the",
    "start": "2422640",
    "end": "2429359"
  },
  {
    "text": "infrastructure to support that the the the apis to",
    "start": "2429359",
    "end": "2435359"
  },
  {
    "text": "support that can you perform node by node upgrades i.e seamlessly",
    "start": "2435359",
    "end": "2442960"
  },
  {
    "text": "upgrading a cluster from kubernetes 1.182 1.19",
    "start": "2442960",
    "end": "2448880"
  },
  {
    "text": "yes yes both in talos and soon with cedaro we have managed",
    "start": "2448880",
    "end": "2455520"
  },
  {
    "text": "node by node upgrades uh for both the kubelet and uh for the control plane",
    "start": "2455520",
    "end": "2462400"
  },
  {
    "text": "components okay can i move my apps running on gke",
    "start": "2462400",
    "end": "2470160"
  },
  {
    "text": "to my bare metal servers with with talis and sedero",
    "start": "2470160",
    "end": "2476318"
  },
  {
    "text": "with caveats that you always have with hardware with bare metal systems in that",
    "start": "2476640",
    "end": "2483839"
  },
  {
    "text": "you don't have the cloud providers storage systems you don't have the cloud providers cni",
    "start": "2483839",
    "end": "2490720"
  },
  {
    "text": "you don't have the cloud providers general load balancer type uh features",
    "start": "2490720",
    "end": "2498640"
  },
  {
    "text": "now all of these have analogs that you can install in bare metal but they're not done for you so you do",
    "start": "2498640",
    "end": "2505359"
  },
  {
    "text": "have to plug in your own implementations just because you're on a bare metal",
    "start": "2505359",
    "end": "2511839"
  },
  {
    "text": "cluster and don't have the cloud providers to supply those but as were mentioned in",
    "start": "2511839",
    "end": "2516960"
  },
  {
    "text": "earlier questions metal lb for load balancing is supported we have rook for storage",
    "start": "2516960",
    "end": "2524880"
  },
  {
    "text": "as well as a number of other storage back ends which i don't think any of us use but should be available",
    "start": "2524880",
    "end": "2531119"
  },
  {
    "text": "these are surmountable problems but just a simple workload translation without",
    "start": "2531119",
    "end": "2536960"
  },
  {
    "text": "implementing those will likely be insufficient but we can you can absolutely get there with",
    "start": "2536960",
    "end": "2543359"
  },
  {
    "text": "minimal effort how can i debug some host related problems without ssh",
    "start": "2543359",
    "end": "2549200"
  },
  {
    "text": "do i need to install ds without deep with a debug pod",
    "start": "2549200",
    "end": "2555599"
  },
  {
    "text": "you can install a debug pod if necessary we have gotten it to where that is very",
    "start": "2555920",
    "end": "2561760"
  },
  {
    "text": "very rarely necessary we have a number of apis with talos as we mentioned uh",
    "start": "2561760",
    "end": "2568880"
  },
  {
    "text": "everything is designed to be controlled by api we can get logs from all of the various",
    "start": "2568880",
    "end": "2574800"
  },
  {
    "text": "components through the talos api and the telos ctl tool",
    "start": "2574800",
    "end": "2580480"
  },
  {
    "text": "we can with sedero pull again we have ipmi if you have bare",
    "start": "2580480",
    "end": "2586800"
  },
  {
    "text": "metal machines with ipmi support such that you can get the console logs from the machines",
    "start": "2586800",
    "end": "2592720"
  },
  {
    "text": "themselves and you have any number of control apis from talos which involve things like",
    "start": "2592720",
    "end": "2600720"
  },
  {
    "text": "getting statistics getting process lists being able to read any file on the system",
    "start": "2600720",
    "end": "2606160"
  },
  {
    "text": "being able to get lists of directories we have most components that you would use to debug",
    "start": "2606160",
    "end": "2612240"
  },
  {
    "text": "available via api okay next question",
    "start": "2612240",
    "end": "2619280"
  },
  {
    "text": "i should mention that oh sorry go ahead oh no you go ahead okay so i should mention with that in",
    "start": "2619280",
    "end": "2626240"
  },
  {
    "text": "regard to that that one of the main features of talos is its relative simplicity as far as what is on",
    "start": "2626240",
    "end": "2632800"
  },
  {
    "text": "the machine the things that can go wrong are far more limited than a general purpose machine and also critically",
    "start": "2632800",
    "end": "2641440"
  },
  {
    "text": "everything is everything from talos is installed and operated on an image",
    "start": "2641440",
    "end": "2647280"
  },
  {
    "text": "basis so you can roll back an image we have a b partitions much as coreos did but importantly these really",
    "start": "2647280",
    "end": "2655359"
  },
  {
    "text": "are read only in the in a form that is image based like containers rather than",
    "start": "2655359",
    "end": "2663920"
  },
  {
    "text": "file system based as coreos did so coreos and flat card use a b partitions but these are full",
    "start": "2663920",
    "end": "2671520"
  },
  {
    "text": "file systems which are ideally extracted from images we instead use the images directly as",
    "start": "2671520",
    "end": "2678560"
  },
  {
    "text": "squash fs file systems so these images are discrete and atomic",
    "start": "2678560",
    "end": "2684079"
  },
  {
    "text": "in and of themselves so if we have a problem rolling back to the previous image is",
    "start": "2684079",
    "end": "2689760"
  },
  {
    "text": "both simple and uh guaranteed same thing for upgrades when we do an",
    "start": "2689760",
    "end": "2696480"
  },
  {
    "text": "upgrade upgrade with a b we can roll back and everything is clean so the number of things that can go",
    "start": "2696480",
    "end": "2702960"
  },
  {
    "text": "wrong are much much more limited than any kind of general purpose os even a specialized container os like",
    "start": "2702960",
    "end": "2710560"
  },
  {
    "text": "flat car or core os and finally we have designed talos",
    "start": "2710560",
    "end": "2715920"
  },
  {
    "text": "to be able to have nothing required on the disk we can wipe",
    "start": "2715920",
    "end": "2721680"
  },
  {
    "text": "the node and reinstall it and everything will be exactly the same so the worst case",
    "start": "2721680",
    "end": "2727200"
  },
  {
    "text": "you wipe the node and it will come back even a control plane node will work just fine with this especially with",
    "start": "2727200",
    "end": "2734800"
  },
  {
    "text": "sedero handling the deployments if something goes wrong with a node that you can't",
    "start": "2734800",
    "end": "2739839"
  },
  {
    "text": "fix with the api destroy the node bring it up again and it all will be well",
    "start": "2739839",
    "end": "2746640"
  },
  {
    "text": "can you go over more on um on these bare metal alternatives to",
    "start": "2746640",
    "end": "2752000"
  },
  {
    "text": "cloud provider services sure so let's cover the the usual ones",
    "start": "2752000",
    "end": "2759040"
  },
  {
    "text": "load balancer is the the most common uh issue the one that works with most",
    "start": "2759040",
    "end": "2765599"
  },
  {
    "text": "anything is metal lb metal lb which was mentioned before it works in",
    "start": "2765599",
    "end": "2770720"
  },
  {
    "text": "layer two and layer three modes it has bgp support",
    "start": "2770720",
    "end": "2776720"
  },
  {
    "text": "or you can just have simple pass through support again layer 3 versus layer 2.",
    "start": "2776720",
    "end": "2782560"
  },
  {
    "text": "and what it does is piggyback on the cube proxy or if you're using something",
    "start": "2782560",
    "end": "2787599"
  },
  {
    "text": "sorry no you're good okay i guess no no one was talking uh",
    "start": "2787599",
    "end": "2793520"
  },
  {
    "text": "and so that is a general purpose load balancer plugin you create services of type load",
    "start": "2793520",
    "end": "2800800"
  },
  {
    "text": "balancer metal lb will then take that proxy any requests into the cluster",
    "start": "2800800",
    "end": "2806640"
  },
  {
    "text": "through the standard load balancer provided by the cni and make the load balancing happen",
    "start": "2806640",
    "end": "2813680"
  },
  {
    "text": "transparently into the bare metal cluster really excellent utility other cni's also have specific",
    "start": "2813680",
    "end": "2821119"
  },
  {
    "text": "implementations such as calico and psyllium",
    "start": "2821119",
    "end": "2826400"
  },
  {
    "text": "and denim all of these have methods of being able to expose",
    "start": "2826400",
    "end": "2832160"
  },
  {
    "text": "services to an ip in some cases shared amongst the nodes in some cases not so there are",
    "start": "2832160",
    "end": "2839119"
  },
  {
    "text": "a few different ways we can go about load balancers storage is another common thing the usual answer to storage",
    "start": "2839119",
    "end": "2847200"
  },
  {
    "text": "in any case if you want to keep it open source is rook rook has a number of implementations uh",
    "start": "2847200",
    "end": "2853359"
  },
  {
    "text": "edge fs seth uh",
    "start": "2853359",
    "end": "2858960"
  },
  {
    "text": "uh there are a number of different storage back ends ceph is the oldest and most reliable and seth",
    "start": "2858960",
    "end": "2865760"
  },
  {
    "text": "implements the most common storage components which include block storage so you can have",
    "start": "2865760",
    "end": "2872960"
  },
  {
    "text": "storage classes and block storage uh add-ons volumes to plug into your",
    "start": "2872960",
    "end": "2880960"
  },
  {
    "text": "clusters that will look work look exactly like any uh cloud providers",
    "start": "2880960",
    "end": "2888240"
  },
  {
    "text": "storage system uh persistent volumes and it also supports uh s3 like storage",
    "start": "2888240",
    "end": "2896319"
  },
  {
    "text": "uh so object arbitrary object store that's available within the cluster and stored in the same cluster",
    "start": "2896319",
    "end": "2902160"
  },
  {
    "text": "same back-end storage cluster as everything else so seth while it may not be the most",
    "start": "2902160",
    "end": "2907839"
  },
  {
    "text": "high performance of the options is one of the most flexible ones and easiest to get started",
    "start": "2907839",
    "end": "2914079"
  },
  {
    "text": "you have ingress controllers those are frequently the same in cloud",
    "start": "2914079",
    "end": "2919680"
  },
  {
    "text": "providers just using an nginx but any other in ingress controller you can plug in in",
    "start": "2919680",
    "end": "2927119"
  },
  {
    "text": "many ways that's actually easier with bare metal clusters as it isn't",
    "start": "2927119",
    "end": "2933839"
  },
  {
    "text": "cni's again we have a number of options but in general",
    "start": "2933839",
    "end": "2941280"
  },
  {
    "text": "you have a broader selection with bare metal and it much of that depends on what your",
    "start": "2941280",
    "end": "2946400"
  },
  {
    "text": "network infrastructure looks like so you can use something like cube router with bgc",
    "start": "2946400",
    "end": "2952000"
  },
  {
    "text": "bgp support in a low level system you have psyllium like i said which most",
    "start": "2952000",
    "end": "2957200"
  },
  {
    "text": "of us use which handle a lot of the other fancy features uh i personally use a combination of",
    "start": "2957200",
    "end": "2964160"
  },
  {
    "text": "psyllium and denim d-a-n-m which is a nokia product",
    "start": "2964160",
    "end": "2969280"
  },
  {
    "text": "which allows you to directly allocate external ips to",
    "start": "2969280",
    "end": "2975599"
  },
  {
    "text": "uh internal pods which allow me to run say ingress controllers internally etc",
    "start": "2975599",
    "end": "2980800"
  },
  {
    "text": "there are a number of different ways these are just kind of the natural ones that i have uh",
    "start": "2980800",
    "end": "2988640"
  },
  {
    "text": "any other cloud services are not coming to mind immediately but in general you have",
    "start": "2988640",
    "end": "2994480"
  },
  {
    "text": "translations in bare metal for most any of the cloud providers services",
    "start": "2994480",
    "end": "3001040"
  },
  {
    "text": "okay is there a ui which i can use to interact with the api",
    "start": "3002640",
    "end": "3009119"
  },
  {
    "text": "there is not at yet as yet um so there is the talus ctl",
    "start": "3009119",
    "end": "3015760"
  },
  {
    "text": "control cli which allows you to do a lot of things in fact it has some",
    "start": "3015760",
    "end": "3022079"
  },
  {
    "text": "console based gui implementations uh we are working on a gui but we don't",
    "start": "3022079",
    "end": "3028800"
  },
  {
    "text": "have anything yet no can you please let me know what type",
    "start": "3028800",
    "end": "3034960"
  },
  {
    "text": "of api or do you or you mean rest api or if it is using soap it will not",
    "start": "3034960",
    "end": "3042400"
  },
  {
    "text": "have issues too i did not mention that so all of our apis both internal and",
    "start": "3042400",
    "end": "3048319"
  },
  {
    "text": "external are based on grpc okay um well normally this",
    "start": "3048319",
    "end": "3055440"
  },
  {
    "text": "would be the time where we would end the webinar but since we started late um sean i'd like to ask you if you're",
    "start": "3055440",
    "end": "3061440"
  },
  {
    "text": "available to answer a few more questions we still have some here in the q a box",
    "start": "3061440",
    "end": "3066559"
  },
  {
    "text": "um if not um can you give us where uh people can",
    "start": "3066559",
    "end": "3071839"
  },
  {
    "text": "reach you if they have any questions that they'd like to ask you yeah absolutely so the easiest way is on",
    "start": "3071839",
    "end": "3079119"
  },
  {
    "text": "our slack at the let's see i'll just share that again",
    "start": "3079119",
    "end": "3096079"
  },
  {
    "text": "went too far there we go uh so the slack here is whoops slap dot dev",
    "start": "3096079",
    "end": "3104240"
  },
  {
    "text": "dot talus systems dot io that is the most reliable place",
    "start": "3104240",
    "end": "3111359"
  },
  {
    "text": "to get a hold of me or any of the talos people excellent um can you stick around to",
    "start": "3111359",
    "end": "3117839"
  },
  {
    "text": "answer a couple more questions or i have uh sure i have a few more minutes",
    "start": "3117839",
    "end": "3123119"
  },
  {
    "text": "excellent thank you so much what container runtime does talos support",
    "start": "3123119",
    "end": "3130240"
  },
  {
    "text": "so telos is built on container d we have had some discussions in the past",
    "start": "3130319",
    "end": "3135839"
  },
  {
    "text": "have passed of making that pluggable but we have yet to have any real need to do so",
    "start": "3135839",
    "end": "3144400"
  },
  {
    "text": "okay do you have nvidia gpu support",
    "start": "3145280",
    "end": "3150640"
  },
  {
    "text": "that is actually something that i am going to have to ask i know we had discussions",
    "start": "3151200",
    "end": "3156960"
  },
  {
    "text": "with one of our users but let me ping one of the other people on that",
    "start": "3156960",
    "end": "3166160"
  },
  {
    "text": "i don't know that offhand not a problem okay so no gpu support as yet",
    "start": "3166160",
    "end": "3173359"
  },
  {
    "text": "but uh but we are working on that awesome um what is the best way to contribute",
    "start": "3173359",
    "end": "3180160"
  },
  {
    "text": "and follow to this project over time",
    "start": "3180160",
    "end": "3184960"
  },
  {
    "text": "definitely the slack and github are our primary sources both internally and",
    "start": "3185520",
    "end": "3191280"
  },
  {
    "text": "externally so those those are the best places to go to contribute to interact to ask for",
    "start": "3191280",
    "end": "3198640"
  },
  {
    "text": "features to work on features to do really anything with the project those are the primary sources",
    "start": "3198640",
    "end": "3208000"
  },
  {
    "text": "what if i need g visor support",
    "start": "3208000",
    "end": "3212319"
  },
  {
    "text": "good question that is not one we have looked at uh before to my knowledge",
    "start": "3213119",
    "end": "3221200"
  },
  {
    "text": "i do not know the answer but i will punt to one of our other engineers on that and uh",
    "start": "3221200",
    "end": "3228480"
  },
  {
    "text": "get back with you if i hear okay not a problem has metal load",
    "start": "3228480",
    "end": "3235200"
  },
  {
    "text": "balancing been tested with sedero managed clusters i assume it would work like in any other",
    "start": "3235200",
    "end": "3240480"
  },
  {
    "text": "kubernetes cluster yes definitely",
    "start": "3240480",
    "end": "3246400"
  },
  {
    "text": "this is a long one um speaking of rook seph we use dedicated nic's on our nodes",
    "start": "3246400",
    "end": "3254079"
  },
  {
    "text": "for the ceph cluster storage and we force seth to use this with a custom configuration",
    "start": "3254079",
    "end": "3260079"
  },
  {
    "text": "override as a result we configure a pair of bonded nics on the bare metal for a dedicated",
    "start": "3260079",
    "end": "3266400"
  },
  {
    "text": "cluster network could i do something like this arbitrary extra nic's on the nodes",
    "start": "3266400",
    "end": "3272800"
  },
  {
    "text": "using talos yes absolutely so all of my uh bare metal servers in",
    "start": "3272800",
    "end": "3279040"
  },
  {
    "text": "fact do exactly that i have bonded uh connections as well as management connections",
    "start": "3279040",
    "end": "3284480"
  },
  {
    "text": "on each of my servers and those are all handled by talos excellent um do we have",
    "start": "3284480",
    "end": "3292640"
  },
  {
    "text": "any other questions",
    "start": "3292640",
    "end": "3295838"
  },
  {
    "text": "how'd you",
    "start": "3300160",
    "end": "3307838"
  },
  {
    "text": "how did andrew run reinhardt and timothy gurla meet what is the origin story behind the background at red hat post",
    "start": "3308079",
    "end": "3314720"
  },
  {
    "text": "ansible acquisition i think i will let tim answer that thanks hi everyone i'm i'm",
    "start": "3314720",
    "end": "3321280"
  },
  {
    "text": "timothy uh and i'm one of the co-founders of talos um andrew is the the creator of the project i joined him",
    "start": "3321280",
    "end": "3327599"
  },
  {
    "text": "uh last year to um to see where we could take the project and find him some resources and help him help him build",
    "start": "3327599",
    "end": "3334400"
  },
  {
    "text": "out the open source community uh so that's really the origin story it's it's been around for",
    "start": "3334400",
    "end": "3339520"
  },
  {
    "text": "uh quite some time now um andrew started it uh i guess almost three years ago now so if",
    "start": "3339520",
    "end": "3344960"
  },
  {
    "text": "you're interested in learning more feel free to drop by the slack and we can uh we'd be happy to chat",
    "start": "3344960",
    "end": "3350640"
  },
  {
    "text": "awesome thank you so much for that do we have any other questions at all",
    "start": "3350640",
    "end": "3363838"
  },
  {
    "text": "all right well i think i think we'll call it a day here um i want to thank uh sean for a",
    "start": "3383599",
    "end": "3390640"
  },
  {
    "text": "wonderful presentation and um for a great q a facilitation um and i want to thank everybody for",
    "start": "3390640",
    "end": "3396880"
  },
  {
    "text": "joining us today we apologize again for the technical difficulties that we had earlier um but thank you very much for",
    "start": "3396880",
    "end": "3402880"
  },
  {
    "text": "sticking around and for spending a few extra moments of your day for today's presentation um as i said before",
    "start": "3402880",
    "end": "3410799"
  },
  {
    "text": "today's recording and slides will be posted on the cncf webinar page at cncf dot io slash webinars",
    "start": "3410799",
    "end": "3417760"
  },
  {
    "text": "thank you again to everyone for joining us today and everyone take care stay safe and we",
    "start": "3417760",
    "end": "3423280"
  },
  {
    "text": "will see you next time great thank you",
    "start": "3423280",
    "end": "3431039"
  }
]
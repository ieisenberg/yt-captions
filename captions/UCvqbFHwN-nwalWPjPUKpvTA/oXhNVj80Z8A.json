[
  {
    "text": "okay it's time hello hello uh Welcome to our talk uh I'm Anton there is Danielle",
    "start": "80",
    "end": "7399"
  },
  {
    "text": "we're both engineers at isand which is now part of Cisco and island is a",
    "start": "7399",
    "end": "13040"
  },
  {
    "text": "company behind siai and tbbf technology and Daniel happens to be",
    "start": "13040",
    "end": "19080"
  },
  {
    "text": "co-creator of both cni and ebpf in Linux Kel so let's start have many",
    "start": "19080",
    "end": "25880"
  },
  {
    "text": "slides today so year ago at uh this same conference Daniel presented a talk uh",
    "start": "25880",
    "end": "33160"
  },
  {
    "text": "where he showed uh how to tune the kubernetes networking stack under selum",
    "start": "33160",
    "end": "41280"
  },
  {
    "text": "uh to the maximum performance and this year we decided to",
    "start": "41280",
    "end": "46800"
  },
  {
    "text": "add um another uh variable to this",
    "start": "46800",
    "end": "51920"
  },
  {
    "text": "equation uh and this variable is encryption",
    "start": "51920",
    "end": "57920"
  },
  {
    "text": "so um doesn't fit okay so there are definitely",
    "start": "57920",
    "end": "65158"
  },
  {
    "text": "like use cases for encrypting traffic uh from uh application to application and",
    "start": "65159",
    "end": "72360"
  },
  {
    "text": "probably the most common one is that you must be compliant with some framework",
    "start": "72360",
    "end": "78600"
  },
  {
    "text": "and um yeah using the fact that there are so many people here so how many of",
    "start": "78600",
    "end": "84360"
  },
  {
    "text": "you have to encrypt traffic in your clusters awesome awesome and how many of",
    "start": "84360",
    "end": "91600"
  },
  {
    "text": "you do not know that it is super simple inum to enable transparent",
    "start": "91600",
    "end": "97200"
  },
  {
    "text": "encryption okay um so transparent",
    "start": "97200",
    "end": "103119"
  },
  {
    "text": "encryption uh means means that",
    "start": "103119",
    "end": "110640"
  },
  {
    "text": "um we enable it once for the whole cluster and then applications without",
    "start": "111719",
    "end": "117119"
  },
  {
    "text": "any configuration without any change to Applications uh they uh their traffic will be uh",
    "start": "117119",
    "end": "124799"
  },
  {
    "text": "encrypted and for uh doing this on a cni level there are not actually too many",
    "start": "124799",
    "end": "131360"
  },
  {
    "text": "options to do this it's IPC and",
    "start": "131360",
    "end": "136120"
  },
  {
    "text": "Ward okay so IPC both have benefits uh",
    "start": "138319",
    "end": "144200"
  },
  {
    "text": "IPC the first benefit probably is uh that it's compliant to many Frameworks",
    "start": "144200",
    "end": "149319"
  },
  {
    "text": "and some environments require uh to use compliant uh implementations uh it is typically a",
    "start": "149319",
    "end": "156400"
  },
  {
    "text": "little bit more complex in configuration than wiard but for the most part",
    "start": "156400",
    "end": "162519"
  },
  {
    "text": "hides this so it's really easy to use it uh one thing users still need to do is",
    "start": "162519",
    "end": "169400"
  },
  {
    "text": "provide uh keys and rotate them themselves so with wire guard it's a new",
    "start": "169400",
    "end": "177760"
  },
  {
    "text": "encryption um system there are also benefits of it uh it's",
    "start": "177760",
    "end": "184440"
  },
  {
    "text": "really simple really easy to understand uh this makes it uh more reliable in",
    "start": "184440",
    "end": "191480"
  },
  {
    "text": "some cases uh because users can't misconfigure it and um it also provides",
    "start": "191480",
    "end": "198920"
  },
  {
    "text": "automatic key rotation uh and uh in some cases it's easier for users",
    "start": "198920",
    "end": "206959"
  },
  {
    "text": "to do this so in some cases wi guard is better than IPC for example if you",
    "start": "206959",
    "end": "213439"
  },
  {
    "text": "consider applications which needs more throughput you can use wire guard in some cases uh IPC behaves better than um",
    "start": "213439",
    "end": "223720"
  },
  {
    "text": "wiard if you need applications which need more request response uh then you can",
    "start": "223720",
    "end": "231480"
  },
  {
    "text": "use IPC but it's on you to decide uh this talk is more focused on wire guard",
    "start": "231480",
    "end": "238480"
  },
  {
    "text": "uh because just because it was too broad scope to to take both into account for for like 35 minutes so",
    "start": "238480",
    "end": "246799"
  },
  {
    "text": "let's start talking about wire guard from now on uh I will cover now",
    "start": "246799",
    "end": "253239"
  },
  {
    "text": "uh what is wire guard how it is configured typically how it is",
    "start": "253239",
    "end": "258840"
  },
  {
    "text": "configured in and then Daniel will cover the performance part of it so the",
    "start": "258840",
    "end": "266560"
  },
  {
    "text": "first design choice of wi guard is to be really opinionated on everything and uh",
    "start": "266560",
    "end": "273680"
  },
  {
    "text": "this means for example that cryptography in wi guard is fixed and the bigger the",
    "start": "273680",
    "end": "280680"
  },
  {
    "text": "the bigger benefit of it is that you can't misconfigure anything because you can't configure",
    "start": "280680",
    "end": "285840"
  },
  {
    "text": "anything and uh for example yeah this curve 25519 is the only way to vard for vard",
    "start": "285840",
    "end": "295840"
  },
  {
    "text": "to exchange symmetric Keys using public crypto and Chacha is the only way to",
    "start": "295840",
    "end": "301840"
  },
  {
    "text": "actually encrypt traffic so in a nutshell wi guard uh establishes tunnels",
    "start": "301840",
    "end": "310440"
  },
  {
    "text": "between two or more peers and here we see like two peers uh",
    "start": "310440",
    "end": "315919"
  },
  {
    "text": "first they create private and public keys and then they use this uh",
    "start": "315919",
    "end": "321560"
  },
  {
    "text": "asymmetric cryp to establish uh secured uh sessions which are secured by",
    "start": "321560",
    "end": "328080"
  },
  {
    "text": "symmetric keys this is done uh over UDP all all the communications in wi guard",
    "start": "328080",
    "end": "333560"
  },
  {
    "text": "are done over UDP and after two-way handshake which is",
    "start": "333560",
    "end": "339560"
  },
  {
    "text": "used to exchange symmetric Keys uh a secure tunnel is established and packets can",
    "start": "339560",
    "end": "347479"
  },
  {
    "text": "flow already securely between the two piers and the best thing here is that wiu guard",
    "start": "347479",
    "end": "352880"
  },
  {
    "text": "automatically uh rotates uh this um uh symmetric State either when uh IP",
    "start": "352880",
    "end": "360199"
  },
  {
    "text": "address changes for roaming for example or just on timeout about two minutes or",
    "start": "360199",
    "end": "365520"
  },
  {
    "text": "so so which provides uh perfect forward secrecy and also it provides the benefit",
    "start": "365520",
    "end": "372680"
  },
  {
    "text": "that the system is actually stateless from the user point of",
    "start": "372680",
    "end": "377720"
  },
  {
    "text": "view um the key distribution protocol in wire guard is inspired by SSH which",
    "start": "377720",
    "end": "383960"
  },
  {
    "text": "means that there is no one uh and bring your own key distribution protocol so",
    "start": "383960",
    "end": "389759"
  },
  {
    "text": "the idea behind this is that again the less things you can configure the less",
    "start": "389759",
    "end": "395280"
  },
  {
    "text": "things you misconfigure so users will find a way to configure uh to exchange",
    "start": "395280",
    "end": "401199"
  },
  {
    "text": "keys if they want to communicate and again like in automated environments like in kubernetes it is really easy to",
    "start": "401199",
    "end": "409080"
  },
  {
    "text": "achieve this as we will see later so now let's take um a deeper dive into",
    "start": "409080",
    "end": "417199"
  },
  {
    "text": "how uh two Linux machines uh can establish a wi guard tunnel uh",
    "start": "417199",
    "end": "423039"
  },
  {
    "text": "between each other so first thing is that uh of course this machines needs uh to",
    "start": "423039",
    "end": "430280"
  },
  {
    "text": "run kernel which supports wi guard and another thing is that uh these machines",
    "start": "430280",
    "end": "435680"
  },
  {
    "text": "needs to be um connected over some uh media IP or IP V6 of course uh and uh",
    "start": "435680",
    "end": "445440"
  },
  {
    "text": "the first thing we do is we create a virtual networking device of type wgard",
    "start": "445440",
    "end": "452039"
  },
  {
    "text": "it can be done normal using normal uh Linux netlink API uh which means that",
    "start": "452039",
    "end": "458759"
  },
  {
    "text": "you can use uh absolutely standard tools to create this device to configure to",
    "start": "458759",
    "end": "464759"
  },
  {
    "text": "configure routing the next thing uh is to generate",
    "start": "464759",
    "end": "470199"
  },
  {
    "text": "and assign private key for this device which again like it can be generated by",
    "start": "470199",
    "end": "476240"
  },
  {
    "text": "any means but assigned using netlink Pi standard way to configure Network in",
    "start": "476240",
    "end": "482599"
  },
  {
    "text": "Linux kernel and also we set up UDP listing in Port here which will",
    "start": "482599",
    "end": "488680"
  },
  {
    "text": "be uh used by other peers to send traffic too and again like on the other",
    "start": "488680",
    "end": "494960"
  },
  {
    "text": "Pier does the same creates device assigns public uh assigns private key to",
    "start": "494960",
    "end": "500960"
  },
  {
    "text": "the device uh somehow exchange public keys with its pier and uh the last thing",
    "start": "500960",
    "end": "508680"
  },
  {
    "text": "before we can traffic is to actually associate uh uh public key of your Pier",
    "start": "508680",
    "end": "517039"
  },
  {
    "text": "with the list of um IPS which this peer can use uh this uh called inard as",
    "start": "517039",
    "end": "525480"
  },
  {
    "text": "scrypt key routing and this actually means that there is one toone correspondence between public keys and a",
    "start": "525480",
    "end": "532519"
  },
  {
    "text": "list of allowed IPS uh what does it mean is that if you",
    "start": "532519",
    "end": "537800"
  },
  {
    "text": "receive a packet from particular IP address you can definitely say which",
    "start": "537800",
    "end": "543760"
  },
  {
    "text": "public key it belongs to and if you want to send traffic to some IP address there is only one Pier which allows this IP so",
    "start": "543760",
    "end": "551160"
  },
  {
    "text": "you also know which Crypt to use to send traffic to and which",
    "start": "551160",
    "end": "556600"
  },
  {
    "text": "endpoint so the that per does the same and again from now on users only see",
    "start": "556600",
    "end": "563079"
  },
  {
    "text": "this wire guard zero device uh users configure networking as needed adding or",
    "start": "563079",
    "end": "569720"
  },
  {
    "text": "altering or removing uh allowed IPS from peers uh and that's it so everything",
    "start": "569720",
    "end": "576560"
  },
  {
    "text": "works if you want to add another Pier you just add another Pier uh in syum the configuration from",
    "start": "576560",
    "end": "584399"
  },
  {
    "text": "like user point of view is even simpler because you don't have to do anything besides creating a cluster with wire",
    "start": "584399",
    "end": "590519"
  },
  {
    "text": "guard enabled and um uh runs in Linux so",
    "start": "590519",
    "end": "596399"
  },
  {
    "text": "the architecture is pretty the same uh it creates wi guard",
    "start": "596399",
    "end": "602000"
  },
  {
    "text": "devices each note creates a private key asides to this device and for key",
    "start": "602000",
    "end": "609040"
  },
  {
    "text": "distribution we utilizing the fact that we're running a kubernetes and we just um distribute public Keys using",
    "start": "609040",
    "end": "616519"
  },
  {
    "text": "connotations of node object so other nodes can watch this object reflect",
    "start": "616519",
    "end": "621959"
  },
  {
    "text": "changes and uh everything works the private key is actually stored",
    "start": "621959",
    "end": "629800"
  },
  {
    "text": "uh on uh kubernetes nodes on disk and it is mapped uh to the agent by this",
    "start": "629800",
    "end": "637839"
  },
  {
    "text": "path I don't know about use cases like this but if you really want to force rotate private key of a node you can",
    "start": "637839",
    "end": "645320"
  },
  {
    "text": "remove this file restart agent and it will appear with a new",
    "start": "645320",
    "end": "651079"
  },
  {
    "text": "one and as it happens uh like the node object will change and everybody else",
    "start": "651079",
    "end": "656800"
  },
  {
    "text": "will see this immediately so so allows",
    "start": "656800",
    "end": "661920"
  },
  {
    "text": "to uh encrypt traffic from many sources to many other sources here we will look",
    "start": "661920",
    "end": "667600"
  },
  {
    "text": "at pot topot traffic but if you want to see how to configure  uh and what kinds of traffic there",
    "start": "667600",
    "end": "674480"
  },
  {
    "text": "is like pot toot put to notp to service Etc uh I least um put a link here so you",
    "start": "674480",
    "end": "680440"
  },
  {
    "text": "can go and check uh let's take a look like briefly at how uh traffic from pot to PO is",
    "start": "680440",
    "end": "688160"
  },
  {
    "text": "actually encrypted so port on the left wants to send traffic to the port on the",
    "start": "688160",
    "end": "693560"
  },
  {
    "text": "right it sends it and uh a BPF program ebf program on Native networking devices",
    "start": "693560",
    "end": "701120"
  },
  {
    "text": "and uh they see that traffic needs to be encrypted it sends it to Ward device",
    "start": "701120",
    "end": "706560"
  },
  {
    "text": "where guard device encrypts it sets special QB Mark to tell the native device that it should be just forwarded",
    "start": "706560",
    "end": "713880"
  },
  {
    "text": "to mediam and then it's sent to the other side decrypted and delivered to",
    "start": "713880",
    "end": "719240"
  },
  {
    "text": "the P so pretty easy and again like session Keys uh are",
    "start": "719240",
    "end": "725240"
  },
  {
    "text": "rotated and everybody is happy so uh we don't have time for demo here but um",
    "start": "725240",
    "end": "733760"
  },
  {
    "text": "even better what we have is uh our Labs where like in one two minutes you can",
    "start": "733760",
    "end": "739320"
  },
  {
    "text": "create your own kubernetes cluster and set up uh transparent encryption there",
    "start": "739320",
    "end": "744519"
  },
  {
    "text": "using either IP SEC or wi guard and I encourage you to do this uh and this is",
    "start": "744519",
    "end": "749680"
  },
  {
    "text": "only one lab of I don't know 40 we have so if you didn't know about these Labs",
    "start": "749680",
    "end": "755320"
  },
  {
    "text": "try try them so yeah um hopefully you now see that it's",
    "start": "755320",
    "end": "761959"
  },
  {
    "text": "really easy to enable and configure wi guard but what about the performance and",
    "start": "761959",
    "end": "768240"
  },
  {
    "text": "with this I pass to Daniel all right all right so recently uh we got our",
    "start": "768240",
    "end": "775320"
  },
  {
    "text": "attention to a blog post um from people from tail scale uh where they said basically user space isn't slow but",
    "start": "775320",
    "end": "781760"
  },
  {
    "text": "kernel interfaces are and given we are kernel developers we were naturally curious uh what's going on and um they",
    "start": "781760",
    "end": "789360"
  },
  {
    "text": "are using in their um solution basically wi got go implementation underneath um",
    "start": "789360",
    "end": "796199"
  },
  {
    "text": "and what they added uh to make it fast was basically a mechanism which is called UDP go gso uh go is called",
    "start": "796199",
    "end": "804560"
  },
  {
    "text": "generic receive of load gso is called generic segmentation of load that's like a mechanism in the kernel and what they",
    "start": "804560",
    "end": "811040"
  },
  {
    "text": "were able to do for all the packets that are that where the packet path goes through the kernel to basically batch uh",
    "start": "811040",
    "end": "818199"
  },
  {
    "text": "the packets with uh with UDP messages um into the tunnel device and and and out",
    "start": "818199",
    "end": "823959"
  },
  {
    "text": "of it right so like all the path to the kernel was basically batched which is why they achieved better",
    "start": "823959",
    "end": "829440"
  },
  {
    "text": "performance um and as a side note actually we also had wi got go",
    "start": "829440",
    "end": "835079"
  },
  {
    "text": "support for a while uh like in the initial implementation uh we basic basically used it as a fallback",
    "start": "835079",
    "end": "840279"
  },
  {
    "text": "mechanism whenever there's uh old kernel where it was not supported um but",
    "start": "840279",
    "end": "846720"
  },
  {
    "text": "actually uh more recently it got removed because like um like the kernel",
    "start": "846720",
    "end": "852279"
  },
  {
    "text": "support is basically widespread so whenever you have a distribution there's also wire guard so there was not necessarily a need for it but more",
    "start": "852279",
    "end": "859759"
  },
  {
    "text": "importantly um with the wire guard go because it's a user space process which implements wi guard functionality um the",
    "start": "859759",
    "end": "867560"
  },
  {
    "text": "problem here is like if you recycle the the the Pod then basically the connections that go through wire guard",
    "start": "867560",
    "end": "873959"
  },
  {
    "text": "they get disrupted right so and this is not an issue with the wi guard kernel driver because everything is nicely",
    "start": "873959",
    "end": "880880"
  },
  {
    "text": "decoupled data path versus control plane so you can update up and and downgrade",
    "start": "880880",
    "end": "886079"
  },
  {
    "text": " or restart it uh while the traffic keeps flowing no problem um so yeah but",
    "start": "886079",
    "end": "892639"
  },
  {
    "text": "let's go on to the benchmarking so we looked into we're looking into unencrypted traffic versus the wire guard driver and also so the wi got go",
    "start": "892639",
    "end": "900399"
  },
  {
    "text": "implementation uh before we do that um we wanted to get to a stable Baseline",
    "start": "900399",
    "end": "905920"
  },
  {
    "text": "and actually on 100 gigabit NX going over bare metal um it's actually not",
    "start": "905920",
    "end": "911680"
  },
  {
    "text": "that easy for a single flow to get to 100 gabit per second but what you can",
    "start": "911680",
    "end": "917160"
  },
  {
    "text": "see here like with the net perf uh we managed to achieve that and basically this is how we did it so like in terms",
    "start": "917160",
    "end": "923399"
  },
  {
    "text": "of Hardware we had like standard offthe shelf AMD thing um like an amdc with PCI",
    "start": "923399",
    "end": "929680"
  },
  {
    "text": "Express 4 we had connect x6x um Nvidia NYX and in terms of software like a",
    "start": "929680",
    "end": "937880"
  },
  {
    "text": "regular Linux Linux kernel uh 6.12 from Linux towards git tree um we changed a",
    "start": "937880",
    "end": "944160"
  },
  {
    "text": "couple of Kernel configs so usually by default um the distributions they do not",
    "start": "944160",
    "end": "949759"
  },
  {
    "text": "necessarily ship the the best config in terms of getting the most performance out of it so what we basically changed",
    "start": "949759",
    "end": "956079"
  },
  {
    "text": "is the scheduling behavior for more Ser heavy workloads into preempt none and",
    "start": "956079",
    "end": "962000"
  },
  {
    "text": "we've removed the CPU mitigations in in this case for the benchmarking and also some of the hardening for example for",
    "start": "962000",
    "end": "968120"
  },
  {
    "text": "the page allocation and Page freeing that where where where this gets cleared this is actually very um heavily uh",
    "start": "968120",
    "end": "976040"
  },
  {
    "text": "affecting the network performance um we also removed a couple of other things so for example we turned off IO mmu this is",
    "start": "976040",
    "end": "982720"
  },
  {
    "text": "like a bio setting you can do for the crop comand line for the kernel we enabled lro which is supported with the",
    "start": "982720",
    "end": "990160"
  },
  {
    "text": "connect uh X um NYX meaning large large",
    "start": "990160",
    "end": "995199"
  },
  {
    "text": "receive off loads so in the current when the network card receives packets you can already batch it in Hardware uh we",
    "start": "995199",
    "end": "1001399"
  },
  {
    "text": "changed the MTU to 8K uh why because it's um it gives a better placement for",
    "start": "1001399",
    "end": "1007680"
  },
  {
    "text": "the kernel networking stack for go because all the data is nicely aligned so it can it can batch it better um we",
    "start": "1007680",
    "end": "1015319"
  },
  {
    "text": "pinned the the the nick uh RX and TX received Q um IQ Affinity one to one to",
    "start": "1015319",
    "end": "1022199"
  },
  {
    "text": "CPUs we set the CPU Governor to Performance so that we don't get",
    "start": "1022199",
    "end": "1027480"
  },
  {
    "text": "fluctuations when we do performance measurements um couple more things as you can see we enabled big TCP which",
    "start": "1027480",
    "end": "1034640"
  },
  {
    "text": "means like for the big TCP is a is a technique in the kernel U which was",
    "start": "1034640",
    "end": "1040400"
  },
  {
    "text": "added a while ago to have more aggressive uh batching uh for the packet so that you don't have many packets",
    "start": "1040400",
    "end": "1046640"
  },
  {
    "text": "going to the stack but like one really big one and also we tweak the TCP read and write memory so that it's not uh adapted to",
    "start": "1046640",
    "end": "1054520"
  },
  {
    "text": "the default 1,500 MTU but more uh like better supported for the for the 8K so",
    "start": "1054520",
    "end": "1061320"
  },
  {
    "text": "what you can see here as I mentioned the Baseline host to host over the network is like uh close to 100 gigabit if you",
    "start": "1061320",
    "end": "1068960"
  },
  {
    "text": "have the W if you send the traffic through the wiard device in the kernel you get for a single stream uh flow uh",
    "start": "1068960",
    "end": "1076440"
  },
  {
    "text": "up to 25 gabit per second and then we also tested the wi got go implementation and that's around 20 so the inernal one",
    "start": "1076440",
    "end": "1084559"
  },
  {
    "text": "for for this uh case seems to be around 30% better um for the transactions per",
    "start": "1084559",
    "end": "1090720"
  },
  {
    "text": "second meaning you're sending many small packets back and forth um the inernal",
    "start": "1090720",
    "end": "1096159"
  },
  {
    "text": "one implementation is is uh even is even more um Can Can Has even more",
    "start": "1096159",
    "end": "1102320"
  },
  {
    "text": "transaction per second than the than the wire got go uh we were also curious how this looked at the standard 1,500 MTU",
    "start": "1102320",
    "end": "1108840"
  },
  {
    "text": "because many people might have this as default as well and in this case actually the wire got go uh",
    "start": "1108840",
    "end": "1114760"
  },
  {
    "text": "implementation is around 35% U better than the inernal driver what you can also see is you you don't",
    "start": "1114760",
    "end": "1121840"
  },
  {
    "text": "get anymore to the close to 100 gabit but rather 60 something gigabit uh for a",
    "start": "1121840",
    "end": "1127679"
  },
  {
    "text": "single flow right and for the wot go it it can make better use of the udpg batching mechanism that I mentioned",
    "start": "1127679",
    "end": "1134679"
  },
  {
    "text": "earlier however when you have many small packets and transactions per second uh the inernal one is still more than",
    "start": "1134679",
    "end": "1142039"
  },
  {
    "text": "twice as good um so our question was can can we do better for single stream um",
    "start": "1142039",
    "end": "1148919"
  },
  {
    "text": "performance so and the first thing is we looking into is how does wi guard handle go and gso internally so if you take a",
    "start": "1148919",
    "end": "1156679"
  },
  {
    "text": "typical stack Trace um from from the like from the Linux kernel what you can",
    "start": "1156679",
    "end": "1161720"
  },
  {
    "text": "see here the packet is received on the on the Nvidia device um it's going into the core receive routine of the kernel",
    "start": "1161720",
    "end": "1169000"
  },
  {
    "text": "um and it has mtus size packet length and it later goes into the wire Gard device it decrypts it and it sends",
    "start": "1169000",
    "end": "1176440"
  },
  {
    "text": "it again to the same core kernel receive Loop this time with a larger packet right so it's it's basically batched if",
    "start": "1176440",
    "end": "1183159"
  },
  {
    "text": "you have this in a more abstract R it it looks roughly like this so we going twice through this deack the the the",
    "start": "1183159",
    "end": "1190280"
  },
  {
    "text": "first time we cannot aggregate something um in the go engine but we are pushing",
    "start": "1190280",
    "end": "1195919"
  },
  {
    "text": "the packet into the UDP socket of the of the wire guard and then later after the",
    "start": "1195919",
    "end": "1201080"
  },
  {
    "text": "decryption we can actually Aggregate and push it up to the application the transmit path very",
    "start": "1201080",
    "end": "1207120"
  },
  {
    "text": "similar you get the stack creates a large packet um larger than the MTU so",
    "start": "1207120",
    "end": "1212360"
  },
  {
    "text": "it makes use of the gso it sends it down to the wire guard device the wire guard",
    "start": "1212360",
    "end": "1217799"
  },
  {
    "text": "device encrypts it um it sends it to the actual physical device and then it's like an MTU sized uh packet so this is",
    "start": "1217799",
    "end": "1226039"
  },
  {
    "text": "how it looks on the on on the other end and very similar the application sends it down",
    "start": "1226039",
    "end": "1232080"
  },
  {
    "text": "wiard device actually exp um advertises that it supports gso but inside the",
    "start": "1232080",
    "end": "1237760"
  },
  {
    "text": "wiard device it needs to split the packet up into smaller packets and given today there's no",
    "start": "1237760",
    "end": "1244720"
  },
  {
    "text": "Hardware offload for for NYX for wiard uh it basically needs to send down the mtus sized ones",
    "start": "1244720",
    "end": "1253400"
  },
  {
    "text": "um so why does the ward driver need to",
    "start": "1253400",
    "end": "1258600"
  },
  {
    "text": "split the the big packet into smaller ones because the wire guard protocol has basically a counter in the header field",
    "start": "1258600",
    "end": "1267080"
  },
  {
    "text": "which is for replay protection so it needs to do this basically so if you look into wire shark packet this is",
    "start": "1267080",
    "end": "1274279"
  },
  {
    "text": "basically how it looks so it's an 8 byte counter and unless there's some offload at some point there's not much we can do",
    "start": "1274279",
    "end": "1282039"
  },
  {
    "text": "here but what about the receive side so on the receive side we can actually take a shortcut so we don't need to uh go to",
    "start": "1282039",
    "end": "1289440"
  },
  {
    "text": "the first stack but on the first go invocation we can actually directly go to the wiard device um this is like for",
    "start": "1289440",
    "end": "1297400"
  },
  {
    "text": "later if you want to take a look um offline it's actually not too much code basically the W guard inernal driver",
    "start": "1297400",
    "end": "1303799"
  },
  {
    "text": "registers a um UTP go Handler and that go Handler directly pushes the packet",
    "start": "1303799",
    "end": "1309360"
  },
  {
    "text": "into the decryption engine of wiard and steals the packet basically in that",
    "start": "1309360",
    "end": "1314679"
  },
  {
    "text": "sense so what you get with this is um for the 1,5 100 MTU as um a nice 14% uh",
    "start": "1314679",
    "end": "1322240"
  },
  {
    "text": "gain in in in terms of a single TCP stream um but it actually becomes less",
    "start": "1322240",
    "end": "1328520"
  },
  {
    "text": "visible with the 8K M2 because it's already batched so here it's just like a 5% so not too much um if you look at the",
    "start": "1328520",
    "end": "1338640"
  },
  {
    "text": "CPU load like for example when you run htop uh across the like for a single",
    "start": "1338640",
    "end": "1343880"
  },
  {
    "text": "stream when you send this to to other the nodes what you can see is all CPUs get busy",
    "start": "1343880",
    "end": "1349400"
  },
  {
    "text": "and this is because Ward basically spreads the encryption and decryption among the different",
    "start": "1349400",
    "end": "1355039"
  },
  {
    "text": "CPUs if you take a flame graph to analyze the performance this is roughly how it looks so there are many kernel",
    "start": "1355039",
    "end": "1362600"
  },
  {
    "text": "worker threats uh what you can see here um uh doing things getting busy and what",
    "start": "1362600",
    "end": "1368760"
  },
  {
    "text": "they are basically doing is um they're spending a large part of the time obviously on the on the decryption also",
    "start": "1368760",
    "end": "1375120"
  },
  {
    "text": "to make the packet data writable um and then pushing like in a new software",
    "start": "1375120",
    "end": "1382360"
  },
  {
    "text": "Q instance the data up to the kernel stack um also the freeing of the packet can become a little bit",
    "start": "1382360",
    "end": "1389559"
  },
  {
    "text": "expensive um but yeah so this is roughly the picture on the on a higher level",
    "start": "1389559",
    "end": "1395480"
  },
  {
    "text": "right so it the packet comes in it gets because of receive s side scaling on the Nick it gets to a particular receive",
    "start": "1395480",
    "end": "1401279"
  },
  {
    "text": "queue that's being processed by a particular CPU and then inside the wi guard driver um when it processes the",
    "start": "1401279",
    "end": "1408960"
  },
  {
    "text": "incoming packets it it will basically queue them into two different cues one is the decryption queue and the other",
    "start": "1408960",
    "end": "1414880"
  },
  {
    "text": "one is the PE que the PE que is basically there to keep the packets in order because like for the decryption",
    "start": "1414880",
    "end": "1421200"
  },
  {
    "text": "part we're trying to spread the load across different CPUs and once the decryption is done it raises the",
    "start": "1421200",
    "end": "1426520"
  },
  {
    "text": "software q and then pushes the the packet further up in the stack um so",
    "start": "1426520",
    "end": "1433240"
  },
  {
    "text": "yeah I mean that helps bulk workloads but obviously you if you distribute the traffic um across CPUs then you trash",
    "start": "1433240",
    "end": "1440600"
  },
  {
    "text": "your your your cash from the CPU right so what about inline crypto this was the next question we were asking ourselves",
    "start": "1440600",
    "end": "1447240"
  },
  {
    "text": "and we did a PC implementation this is roughly how it looks in in in in the htop when you run",
    "start": "1447240",
    "end": "1453279"
  },
  {
    "text": "the same Benchmark again and when you take the flame graph you can see everything is done in one go on the same",
    "start": "1453279",
    "end": "1459679"
  },
  {
    "text": "CPU so now looking at the single TCP stream it actually decreases the performance by a 60% which is not great",
    "start": "1459679",
    "end": "1467080"
  },
  {
    "text": "right because now like all the decryption is done on the single CPU however the transaction per second gets",
    "start": "1467080",
    "end": "1473799"
  },
  {
    "text": "much much better so like plus 86% um uh yeah uh and if you look at the",
    "start": "1473799",
    "end": "1481279"
  },
  {
    "text": "latency uh I also did the added the why I got go in here so like the you know",
    "start": "1481279",
    "end": "1487440"
  },
  {
    "text": "like the latency there is is quite bad because it needs to take the context switch from kernel to user space and",
    "start": "1487440",
    "end": "1493840"
  },
  {
    "text": "back a couple of times because it's implemented in user space but if you look at the L2 l2g in the inline crypto",
    "start": "1493840",
    "end": "1503120"
  },
  {
    "text": "uh it actually looks very very good like just a 24 microsc which is even lower",
    "start": "1503120",
    "end": "1508159"
  },
  {
    "text": "than the native kernel uh implementation with the minimum latency so now we again",
    "start": "1508159",
    "end": "1514399"
  },
  {
    "text": "at this question right like do we choose the request response type or the stream uh workloads because um yeah you can get",
    "start": "1514399",
    "end": "1522360"
  },
  {
    "text": "some optimization out of it with the l2g but there's no free launch so you basically have a tradeoff of like either",
    "start": "1522360",
    "end": "1529279"
  },
  {
    "text": "small packets like or like the the bulk traffic so the next step was like okay",
    "start": "1529279",
    "end": "1535039"
  },
  {
    "text": "but what if we look into the case where you have multiple flows right where you you don't just try to optimize as much",
    "start": "1535039",
    "end": "1541960"
  },
  {
    "text": "as possible out of it from a single flow but multiple because that's more realistic so yeah can we can we do",
    "start": "1541960",
    "end": "1548799"
  },
  {
    "text": "better for multiple streams um and what you can see here is basically we have a wire gut device uh",
    "start": "1548799",
    "end": "1556159"
  },
  {
    "text": "and have many parallel TCP stream sessions and what you can see here we",
    "start": "1556159",
    "end": "1561880"
  },
  {
    "text": "are stuck around the 30 gabit Mark like even if if we add more parallel TCP streams it doesn't get better it rather",
    "start": "1561880",
    "end": "1568360"
  },
  {
    "text": "get slightly worse so it doesn't scale at all unfortunately which is yeah very",
    "start": "1568360",
    "end": "1574679"
  },
  {
    "text": "unfortunate so the question is yeah why what like what's going what's happening right because like for the east west",
    "start": "1574679",
    "end": "1580679"
  },
  {
    "text": "traffic you usually have many flows um and the reason is there is no RSS",
    "start": "1580679",
    "end": "1587399"
  },
  {
    "text": "scaling so basically if you look uh on the wire like with TCP dump or whatever",
    "start": "1587399",
    "end": "1593080"
  },
  {
    "text": "uh the traffic from one node to the other looks exactly the same it has the same Source IP same destination IP same",
    "start": "1593080",
    "end": "1599840"
  },
  {
    "text": "Source Port same destination Port even though the unencrypted traffic can be very diverse uh But like after the",
    "start": "1599840",
    "end": "1607039"
  },
  {
    "text": "encryption it looks all the same that's why it all lands on a single CPU and that's why you get this",
    "start": "1607039",
    "end": "1613320"
  },
  {
    "text": "performance and Ipsy B basically has the same issue right so our colleague Ryan",
    "start": "1613320",
    "end": "1618600"
  },
  {
    "text": "he gave a talk about this yesterday in theum in EF day um so our first approach",
    "start": "1618600",
    "end": "1624640"
  },
  {
    "text": "was yeah like but what about multiple wire guard devices so now they have different ports what if you low balance",
    "start": "1624640",
    "end": "1630480"
  },
  {
    "text": "traffic um among them so the first option was that that came natural well there's bonding device in the kernel or",
    "start": "1630480",
    "end": "1637440"
  },
  {
    "text": "team device what if we create multiple devices from wiard and like put them into a bond device unfortunately it's",
    "start": "1637440",
    "end": "1644200"
  },
  {
    "text": "not possible so you need to change the kernel Bond driver spond driver expects",
    "start": "1644200",
    "end": "1649240"
  },
  {
    "text": "the layer 2 device but that's all layer three okay fair enough um so what about",
    "start": "1649240",
    "end": "1655440"
  },
  {
    "text": "multipath next hops right so what you can see here is like a IP Rod dump where you can load balance that way um while",
    "start": "1655440",
    "end": "1663720"
  },
  {
    "text": "this can be configured we were quite happy about that but then wire guard uh",
    "start": "1663720",
    "end": "1669039"
  },
  {
    "text": "uh you know refuses to operate this way and basically what happens is um we",
    "start": "1669039",
    "end": "1674919"
  },
  {
    "text": "assume it's maybe like a wi got back internally so that's still in in investigating but if you have different",
    "start": "1674919",
    "end": "1680960"
  },
  {
    "text": "uh listener ports for wi guard but all the other configuration is the same then basically um yeah it it it black holes",
    "start": "1680960",
    "end": "1688519"
  },
  {
    "text": "traffic for all the devices except one and even if you have different listener Port different key pairs it's doing the",
    "start": "1688519",
    "end": "1695080"
  },
  {
    "text": "same but yeah if you have different everything like all the different configurations then it then then it can",
    "start": "1695080",
    "end": "1701080"
  },
  {
    "text": "work and this is what we did um and now we basically have many wire guard",
    "start": "1701080",
    "end": "1708120"
  },
  {
    "text": "devices um and also parallel flows to that and send TCP stream traffic to that",
    "start": "1708120",
    "end": "1713360"
  },
  {
    "text": "and what you can see here it already gets much better uh so so here you have 1.6 times the aggregate throughput",
    "start": "1713360",
    "end": "1720240"
  },
  {
    "text": "compared to the single wire gut scenario and it gets even better like uh",
    "start": "1720240",
    "end": "1725480"
  },
  {
    "text": "for the request response type workloads right so here you get the 2x aggregate",
    "start": "1725480",
    "end": "1730679"
  },
  {
    "text": "transaction per second uh if you have if you spread the traffic across multiple",
    "start": "1730679",
    "end": "1735840"
  },
  {
    "text": "devices um and this is thanks to RSS so there's not not no more other magic in",
    "start": "1735840",
    "end": "1741799"
  },
  {
    "text": "there but then the question was okay the limitation then becomes that you spread the traffic across the different kernel",
    "start": "1741799",
    "end": "1749200"
  },
  {
    "text": "workers for the encryption and decryption but what if you do this locally um so what if you do the inline",
    "start": "1749200",
    "end": "1756360"
  },
  {
    "text": "encryption and have those parallel flows so this is what we also did and you can",
    "start": "1756360",
    "end": "1761880"
  },
  {
    "text": "see here on the on the green graph that is in in addition to that um we get even",
    "start": "1761880",
    "end": "1767840"
  },
  {
    "text": "better overall like up to like 2.2x the aggregate throughput what you can see",
    "start": "1767840",
    "end": "1773519"
  },
  {
    "text": "here is like initially it scales linearly but then it like cuts off at some point um and uh to to to add here",
    "start": "1773519",
    "end": "1781240"
  },
  {
    "text": "like the test systems they had like 16 CPUs so not too much um but from the",
    "start": "1781240",
    "end": "1787240"
  },
  {
    "text": "flame grass what we also saw is like uh the the more work um it it it gets um",
    "start": "1787240",
    "end": "1794440"
  },
  {
    "text": "basically more gets delegated to Kernel soft IQ and I think that's probably the reason why it cuts off here instead of",
    "start": "1794440",
    "end": "1800960"
  },
  {
    "text": "going further so there's still potential to optimize um and if you do the same",
    "start": "1800960",
    "end": "1807159"
  },
  {
    "text": "for the transaction per second we actually get to a 4X uh better uh",
    "start": "1807159",
    "end": "1812480"
  },
  {
    "text": "aggregate uh transaction per second which is really huge um so yeah now the next question was",
    "start": "1812480",
    "end": "1820440"
  },
  {
    "text": "that we had on on our journey instead of multiple devices can we do it with a single device but instead achieve the",
    "start": "1820440",
    "end": "1827200"
  },
  {
    "text": "RSS Source board hashing so basically before the packet is encrypted",
    "start": "1827200",
    "end": "1833600"
  },
  {
    "text": "you take the the unencrypted packets hash like of the of the five tle um and",
    "start": "1833600",
    "end": "1839320"
  },
  {
    "text": "after encryption you pass this on as the source Port this is very similar to what V aan is doing right so you have like a",
    "start": "1839320",
    "end": "1845840"
  },
  {
    "text": "fixed Global port and then the source Port is the hash of the inner packet and",
    "start": "1845840",
    "end": "1852279"
  },
  {
    "text": "we also implemented that and it's also working um you can see here from a TCP dump uh screen that now for different",
    "start": "1852279",
    "end": "1859840"
  },
  {
    "text": "traffic you you have different uh Source ports and this is also working uh yeah putting it all together um syum EF and",
    "start": "1859840",
    "end": "1868080"
  },
  {
    "text": "and our optimized wire guard this is uh how it looks from an from a high level architecture point of view so one you",
    "start": "1868080",
    "end": "1874799"
  },
  {
    "text": "have the netkit devices connecting the parts that's the talk I gave last year",
    "start": "1874799",
    "end": "1880200"
  },
  {
    "text": "uh where we replace the weave devices with netkit to get better performance and to remove the network namespace",
    "start": "1880200",
    "end": "1886200"
  },
  {
    "text": "overhead that's been in 116 already um and then in addition to that for the",
    "start": "1886200",
    "end": "1892320"
  },
  {
    "text": "wire guard we have the L2 goo I talked about the source Port hashing implementation and the inline uh",
    "start": "1892320",
    "end": "1899080"
  },
  {
    "text": "encryption for better scalability so this is what we are uh planning to get into and into the kernel U",
    "start": "1899080",
    "end": "1906399"
  },
  {
    "text": "potentially 118 uh we'll see so to recap um yeah basically cium has a native wire",
    "start": "1906399",
    "end": "1914720"
  },
  {
    "text": "guard integration and it's actually super easy to to use and get started you just enable those knobs and everything",
    "start": "1914720",
    "end": "1921320"
  },
  {
    "text": "is taken care of um and yeah crypto still comes at the crypto done in",
    "start": "1921320",
    "end": "1927519"
  },
  {
    "text": "software still comes at a high cost as you saw um but the way wire guard is",
    "start": "1927519",
    "end": "1933399"
  },
  {
    "text": "implemented can actually be made significantly more scalable for multiple uh",
    "start": "1933399",
    "end": "1938720"
  },
  {
    "text": "flows and that's the plan for getting this merged into the Linus kernel as well as  so yeah and uh I would like to thank",
    "start": "1938720",
    "end": "1946760"
  },
  {
    "text": "a couple of people Martinas and Sebastian from our team they had like many live sessions where they coded the",
    "start": "1946760",
    "end": "1952639"
  },
  {
    "text": "integration the initial integration filium uh together and of course also",
    "start": "1952639",
    "end": "1957799"
  },
  {
    "text": "Jason the wire God creator uh Jordan and and James from from tailes scale they",
    "start": "1957799",
    "end": "1963320"
  },
  {
    "text": "did the wi go go Improvement for the UDP go gso um David and and merco they they had",
    "start": "1963320",
    "end": "1971880"
  },
  {
    "text": "a similar talk at the U few few few weeks ago where they found the same uh",
    "start": "1971880",
    "end": "1977480"
  },
  {
    "text": "issues that that we discovered in in our experiments and yeah and then of course",
    "start": "1977480",
    "end": "1982639"
  },
  {
    "text": "the net and BPF communities so this is it yeah if you have any questions",
    "start": "1982639",
    "end": "1988000"
  },
  {
    "text": "we're happy to know thank you",
    "start": "1988000",
    "end": "1992639"
  }
]
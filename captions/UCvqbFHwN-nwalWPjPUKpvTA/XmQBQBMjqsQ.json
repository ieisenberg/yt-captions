[
  {
    "start": "0",
    "end": "104000"
  },
  {
    "text": "so hi everyone sorry for the small delay",
    "start": "0",
    "end": "1760"
  },
  {
    "text": "we had some technical problems and",
    "start": "1760",
    "end": "4000"
  },
  {
    "text": "before talking i just want to say thank",
    "start": "4000",
    "end": "5600"
  },
  {
    "text": "you for the fluent guys in the community",
    "start": "5600",
    "end": "8160"
  },
  {
    "text": "that are hosting us here um i'm uh",
    "start": "8160",
    "end": "12960"
  },
  {
    "text": "and pranjel gupta",
    "start": "13120",
    "end": "14880"
  },
  {
    "text": "we're from ibm research",
    "start": "14880",
    "end": "16880"
  },
  {
    "text": "and we are working uh very strongly",
    "start": "16880",
    "end": "19680"
  },
  {
    "text": "with the reddit team so there is a",
    "start": "19680",
    "end": "22400"
  },
  {
    "text": "ibm research and relative are working",
    "start": "22400",
    "end": "24560"
  },
  {
    "text": "together",
    "start": "24560",
    "end": "26320"
  },
  {
    "text": "the area that we are focused on is",
    "start": "26320",
    "end": "28000"
  },
  {
    "text": "observability",
    "start": "28000",
    "end": "30080"
  },
  {
    "text": "and",
    "start": "30080",
    "end": "31119"
  },
  {
    "text": "and observability stack",
    "start": "31119",
    "end": "33120"
  },
  {
    "text": "of openshift and prangel will talk about",
    "start": "33120",
    "end": "35040"
  },
  {
    "text": "it and elaborate a lot more",
    "start": "35040",
    "end": "37280"
  },
  {
    "text": "the area that we are trying to promote",
    "start": "37280",
    "end": "39680"
  },
  {
    "text": "is treating logs",
    "start": "39680",
    "end": "42960"
  },
  {
    "text": "to be equivalent",
    "start": "42960",
    "end": "44520"
  },
  {
    "text": "citizenship like uh to the rest of the",
    "start": "44520",
    "end": "47680"
  },
  {
    "text": "resources in",
    "start": "47680",
    "end": "49200"
  },
  {
    "text": "um in clouds and in kubernetes in",
    "start": "49200",
    "end": "52000"
  },
  {
    "text": "openshift so just like cpu and memory",
    "start": "52000",
    "end": "55440"
  },
  {
    "text": "which are managed and controlled",
    "start": "55440",
    "end": "57280"
  },
  {
    "text": "resources in such distributed",
    "start": "57280",
    "end": "59120"
  },
  {
    "text": "environment we're trying to get to the",
    "start": "59120",
    "end": "60719"
  },
  {
    "text": "situation that logs are treated in the",
    "start": "60719",
    "end": "62480"
  },
  {
    "text": "same way so that we can control them we",
    "start": "62480",
    "end": "65198"
  },
  {
    "text": "can control the amount of logs that are",
    "start": "65199",
    "end": "66560"
  },
  {
    "text": "being generated and the amount of log",
    "start": "66560",
    "end": "68400"
  },
  {
    "text": "that is being collected using fluency",
    "start": "68400",
    "end": "71439"
  },
  {
    "text": "and and the logging stack just uh um",
    "start": "71439",
    "end": "74960"
  },
  {
    "text": "that that this is managed and these are",
    "start": "74960",
    "end": "77680"
  },
  {
    "text": "those are not like uh free resources uh",
    "start": "77680",
    "end": "80320"
  },
  {
    "text": "in the system um and i think that",
    "start": "80320",
    "end": "82320"
  },
  {
    "text": "eduardo touched that in the beginning",
    "start": "82320",
    "end": "84159"
  },
  {
    "text": "when he was saying that there are too",
    "start": "84159",
    "end": "85360"
  },
  {
    "text": "many logs in the world and everyone is",
    "start": "85360",
    "end": "87040"
  },
  {
    "text": "sending logs out so this is exactly the",
    "start": "87040",
    "end": "89040"
  },
  {
    "text": "situation that we're trying to handle",
    "start": "89040",
    "end": "90400"
  },
  {
    "text": "over here making sure that everything is",
    "start": "90400",
    "end": "91920"
  },
  {
    "text": "under um control i will hand i will move",
    "start": "91920",
    "end": "95200"
  },
  {
    "text": "the give the stage to pranjel to give us",
    "start": "95200",
    "end": "97680"
  },
  {
    "text": "the entire uh",
    "start": "97680",
    "end": "99040"
  },
  {
    "text": "talk and you know kind of elaborate",
    "start": "99040",
    "end": "101600"
  },
  {
    "text": "thank you",
    "start": "101600",
    "end": "103920"
  },
  {
    "start": "104000",
    "end": "169000"
  },
  {
    "text": "thanks around for the introduction",
    "start": "104640",
    "end": "106799"
  },
  {
    "text": "hi everybody uh",
    "start": "106799",
    "end": "108799"
  },
  {
    "text": "so first uh i would like to introduce",
    "start": "108799",
    "end": "111200"
  },
  {
    "text": "like what is openshift",
    "start": "111200",
    "end": "113040"
  },
  {
    "text": "so openshift is a flagship product as a",
    "start": "113040",
    "end": "115600"
  },
  {
    "text": "service",
    "start": "115600",
    "end": "117200"
  },
  {
    "text": "platform for",
    "start": "117200",
    "end": "118560"
  },
  {
    "text": "from red hat built on top of kubernetes",
    "start": "118560",
    "end": "121200"
  },
  {
    "text": "and it allows you to deploy and manage",
    "start": "121200",
    "end": "123920"
  },
  {
    "text": "your containers in a",
    "start": "123920",
    "end": "126159"
  },
  {
    "text": "easier way than using plain kubernetes",
    "start": "126159",
    "end": "129280"
  },
  {
    "text": "environment",
    "start": "129280",
    "end": "130399"
  },
  {
    "text": "openshift logging is like",
    "start": "130399",
    "end": "132640"
  },
  {
    "text": "a",
    "start": "132640",
    "end": "133920"
  },
  {
    "text": "subsystem for logging and how to",
    "start": "133920",
    "end": "135920"
  },
  {
    "text": "configure logging in your openshift",
    "start": "135920",
    "end": "137440"
  },
  {
    "text": "cluster",
    "start": "137440",
    "end": "138480"
  },
  {
    "text": "it provides a high level semantics are",
    "start": "138480",
    "end": "140879"
  },
  {
    "text": "in",
    "start": "140879",
    "end": "141680"
  },
  {
    "text": "inform like in form of an api to",
    "start": "141680",
    "end": "144080"
  },
  {
    "text": "customers so that you can configure your",
    "start": "144080",
    "end": "146319"
  },
  {
    "text": "logging architecture",
    "start": "146319",
    "end": "148959"
  },
  {
    "text": "so this is an example of how you can",
    "start": "148959",
    "end": "150879"
  },
  {
    "text": "control your cluster logging through",
    "start": "150879",
    "end": "152720"
  },
  {
    "text": "form of a custom resource definition",
    "start": "152720",
    "end": "154959"
  },
  {
    "text": "this simple and intuitive api will help",
    "start": "154959",
    "end": "157200"
  },
  {
    "text": "you to generate complex fluency",
    "start": "157200",
    "end": "159840"
  },
  {
    "text": "configuration and it on top of that it",
    "start": "159840",
    "end": "162480"
  },
  {
    "text": "adds normalization metrics and buffering",
    "start": "162480",
    "end": "166000"
  },
  {
    "text": "to your cluster logging",
    "start": "166000",
    "end": "169200"
  },
  {
    "start": "169000",
    "end": "199000"
  },
  {
    "text": "so on this slide this is a like very",
    "start": "169200",
    "end": "171440"
  },
  {
    "text": "high level view of how our logging",
    "start": "171440",
    "end": "173760"
  },
  {
    "text": "pipeline looks",
    "start": "173760",
    "end": "175200"
  },
  {
    "text": "uh so like logs from containers like in",
    "start": "175200",
    "end": "178000"
  },
  {
    "text": "the form of in standard out and standard",
    "start": "178000",
    "end": "180560"
  },
  {
    "text": "err streams are written",
    "start": "180560",
    "end": "182959"
  },
  {
    "text": "two log files on the disk by",
    "start": "182959",
    "end": "185360"
  },
  {
    "text": "container runtime interface and logs",
    "start": "185360",
    "end": "187920"
  },
  {
    "text": "from these files which are stored in var",
    "start": "187920",
    "end": "190080"
  },
  {
    "text": "lock containers are read from fluently",
    "start": "190080",
    "end": "192720"
  },
  {
    "text": "normalized and then sent to persistent",
    "start": "192720",
    "end": "195040"
  },
  {
    "text": "storage like elastic searches log",
    "start": "195040",
    "end": "197120"
  },
  {
    "text": "affluent forward",
    "start": "197120",
    "end": "199120"
  },
  {
    "text": "however this seemingly",
    "start": "199120",
    "end": "201200"
  },
  {
    "text": "simple architecture has",
    "start": "201200",
    "end": "203120"
  },
  {
    "text": "many bottlenecks and like of which we",
    "start": "203120",
    "end": "206159"
  },
  {
    "text": "are only talking about what we can",
    "start": "206159",
    "end": "208000"
  },
  {
    "text": "control from the lock collection side",
    "start": "208000",
    "end": "210480"
  },
  {
    "text": "so in situations where you don't have",
    "start": "210480",
    "end": "212400"
  },
  {
    "text": "control of on the amount of logs being",
    "start": "212400",
    "end": "214480"
  },
  {
    "text": "collected right where like lot of logs",
    "start": "214480",
    "end": "217680"
  },
  {
    "text": "are being generated from each",
    "start": "217680",
    "end": "218959"
  },
  {
    "text": "application and you want to troubleshoot",
    "start": "218959",
    "end": "221280"
  },
  {
    "text": "you want to debug and you don't know",
    "start": "221280",
    "end": "222560"
  },
  {
    "text": "what is happening so in those situations",
    "start": "222560",
    "end": "224640"
  },
  {
    "text": "you need to have a very good",
    "start": "224640",
    "end": "226720"
  },
  {
    "text": "state of what is happening in the",
    "start": "226720",
    "end": "228319"
  },
  {
    "text": "cluster so in those situations when you",
    "start": "228319",
    "end": "230480"
  },
  {
    "text": "have cpu and memory resource crunch",
    "start": "230480",
    "end": "234560"
  },
  {
    "text": "there can be",
    "start": "234560",
    "end": "236000"
  },
  {
    "text": "buffer overflow due to which",
    "start": "236000",
    "end": "238159"
  },
  {
    "text": "logs are not being flushed regularly to",
    "start": "238159",
    "end": "241280"
  },
  {
    "text": "your end point so this causes like back",
    "start": "241280",
    "end": "244400"
  },
  {
    "text": "pressure to your connected components",
    "start": "244400",
    "end": "246720"
  },
  {
    "text": "and",
    "start": "246720",
    "end": "247760"
  },
  {
    "text": "you start to miss out on logs",
    "start": "247760",
    "end": "250159"
  },
  {
    "text": "so the",
    "start": "250159",
    "end": "251200"
  },
  {
    "text": "so these two bottlenecks can we have",
    "start": "251200",
    "end": "253360"
  },
  {
    "text": "done a study on these two bottlenecks",
    "start": "253360",
    "end": "255120"
  },
  {
    "text": "and come up with a feature in the intel",
    "start": "255120",
    "end": "258079"
  },
  {
    "text": "plugin which is one of the most widely",
    "start": "258079",
    "end": "260160"
  },
  {
    "text": "used plugins in fluendy to control what",
    "start": "260160",
    "end": "262800"
  },
  {
    "text": "amount of logs is being sent and do you",
    "start": "262800",
    "end": "265199"
  },
  {
    "text": "know how much log is being lost and what",
    "start": "265199",
    "end": "267040"
  },
  {
    "text": "are the sources of that logs",
    "start": "267040",
    "end": "269840"
  },
  {
    "start": "269000",
    "end": "331000"
  },
  {
    "text": "so now we formally define uh our two uh",
    "start": "269840",
    "end": "274000"
  },
  {
    "text": "like areas like one is log loss that",
    "start": "274000",
    "end": "276800"
  },
  {
    "text": "means the difference between what was",
    "start": "276800",
    "end": "278479"
  },
  {
    "text": "collected and what was generated by",
    "start": "278479",
    "end": "281120"
  },
  {
    "text": "workload applications",
    "start": "281120",
    "end": "282880"
  },
  {
    "text": "so this means that when fluenty misses",
    "start": "282880",
    "end": "284639"
  },
  {
    "text": "log rotation you start to lose logs",
    "start": "284639",
    "end": "287280"
  },
  {
    "text": "right and this can be accounted to the",
    "start": "287280",
    "end": "289120"
  },
  {
    "text": "number of uh missed rotations into the",
    "start": "289120",
    "end": "292320"
  },
  {
    "text": "size of each file",
    "start": "292320",
    "end": "294000"
  },
  {
    "text": "of log log file right",
    "start": "294000",
    "end": "296400"
  },
  {
    "text": "the second one is the data clogging so",
    "start": "296400",
    "end": "299120"
  },
  {
    "text": "when you when you have very less",
    "start": "299120",
    "end": "302160"
  },
  {
    "text": "memory or cpu resources available to you",
    "start": "302160",
    "end": "304639"
  },
  {
    "text": "fluently's output buffer",
    "start": "304639",
    "end": "307039"
  },
  {
    "text": "buffer starts to get",
    "start": "307039",
    "end": "309520"
  },
  {
    "text": "like overflow and",
    "start": "309520",
    "end": "311120"
  },
  {
    "text": "uh",
    "start": "311120",
    "end": "312479"
  },
  {
    "text": "you know you you tend to lose logs",
    "start": "312479",
    "end": "314400"
  },
  {
    "text": "because uh you don't know what to do",
    "start": "314400",
    "end": "316240"
  },
  {
    "text": "right fluently starts to push back",
    "start": "316240",
    "end": "318960"
  },
  {
    "text": "to slow down its reading so that you can",
    "start": "318960",
    "end": "320880"
  },
  {
    "text": "stand what it has already processed",
    "start": "320880",
    "end": "323280"
  },
  {
    "text": "right so this is data clogging so these",
    "start": "323280",
    "end": "325280"
  },
  {
    "text": "two are internally related so data",
    "start": "325280",
    "end": "327440"
  },
  {
    "text": "clogging can cause log loss right",
    "start": "327440",
    "end": "331280"
  },
  {
    "start": "331000",
    "end": "364000"
  },
  {
    "text": "so given these scenarios from our",
    "start": "331280",
    "end": "333360"
  },
  {
    "text": "architecture right",
    "start": "333360",
    "end": "336080"
  },
  {
    "text": "we have come up with a motivation so",
    "start": "336080",
    "end": "338080"
  },
  {
    "text": "during like worst case scenarios when",
    "start": "338080",
    "end": "340400"
  },
  {
    "text": "you want to debug and troubleshoot what",
    "start": "340400",
    "end": "341919"
  },
  {
    "text": "is happening in a cluster you want to",
    "start": "341919",
    "end": "344240"
  },
  {
    "text": "prioritize log collection at the input",
    "start": "344240",
    "end": "346320"
  },
  {
    "text": "level so that you don't miss on",
    "start": "346320",
    "end": "348800"
  },
  {
    "text": "important logs",
    "start": "348800",
    "end": "350160"
  },
  {
    "text": "right and and as a part of the",
    "start": "350160",
    "end": "352320"
  },
  {
    "text": "aggression process you want to make sure",
    "start": "352320",
    "end": "354479"
  },
  {
    "text": "that your crucial resources like network",
    "start": "354479",
    "end": "356880"
  },
  {
    "text": "bandwidth and persistent storage are not",
    "start": "356880",
    "end": "359360"
  },
  {
    "text": "uh",
    "start": "359360",
    "end": "360319"
  },
  {
    "text": "saturated given the resource contains",
    "start": "360319",
    "end": "362240"
  },
  {
    "text": "constraints",
    "start": "362240",
    "end": "364880"
  },
  {
    "start": "364000",
    "end": "399000"
  },
  {
    "text": "so as part of our research uh",
    "start": "365280",
    "end": "368240"
  },
  {
    "text": "we have developed a open source",
    "start": "368240",
    "end": "370319"
  },
  {
    "text": "benchmarking tool which allows you to",
    "start": "370319",
    "end": "372479"
  },
  {
    "text": "generate and measure log stress",
    "start": "372479",
    "end": "373919"
  },
  {
    "text": "conditions",
    "start": "373919",
    "end": "375199"
  },
  {
    "text": "so this allows this using this tool we",
    "start": "375199",
    "end": "378319"
  },
  {
    "text": "performed our experiments and",
    "start": "378319",
    "end": "381280"
  },
  {
    "text": "had some form of exp",
    "start": "381280",
    "end": "382960"
  },
  {
    "text": "reproducibility in our experiments one",
    "start": "382960",
    "end": "385360"
  },
  {
    "text": "key feature of this tool is that it can",
    "start": "385360",
    "end": "387680"
  },
  {
    "text": "allow you to configure your log rotation",
    "start": "387680",
    "end": "390080"
  },
  {
    "text": "pace in the cluster so you can control",
    "start": "390080",
    "end": "392400"
  },
  {
    "text": "the log rotation pace and check out how",
    "start": "392400",
    "end": "394479"
  },
  {
    "text": "many logs or what is the amount of log",
    "start": "394479",
    "end": "396639"
  },
  {
    "text": "loss that is occurring in your cluster",
    "start": "396639",
    "end": "400160"
  },
  {
    "start": "399000",
    "end": "463000"
  },
  {
    "text": "so before moving on to the observations",
    "start": "400240",
    "end": "402240"
  },
  {
    "text": "i will just give you uh an overview of",
    "start": "402240",
    "end": "404800"
  },
  {
    "text": "what is our experimental setup",
    "start": "404800",
    "end": "406880"
  },
  {
    "text": "so in general scenario you have two",
    "start": "406880",
    "end": "409120"
  },
  {
    "text": "groups of containers one is very",
    "start": "409120",
    "end": "411120"
  },
  {
    "text": "important which you don't want to miss",
    "start": "411120",
    "end": "412800"
  },
  {
    "text": "logs from and one is the less important",
    "start": "412800",
    "end": "415360"
  },
  {
    "text": "containers which are chatty which are",
    "start": "415360",
    "end": "416720"
  },
  {
    "text": "noisy and it's it is okay if you lose",
    "start": "416720",
    "end": "418960"
  },
  {
    "text": "some logs from those containers",
    "start": "418960",
    "end": "421120"
  },
  {
    "text": "and the objective is we want to preserve",
    "start": "421120",
    "end": "423199"
  },
  {
    "text": "logs from very important containers so",
    "start": "423199",
    "end": "425280"
  },
  {
    "text": "that you can troubleshoot right which is",
    "start": "425280",
    "end": "427199"
  },
  {
    "text": "very important for you as a",
    "start": "427199",
    "end": "429680"
  },
  {
    "text": "developer or an sre",
    "start": "429680",
    "end": "431440"
  },
  {
    "text": "to come to a stable state",
    "start": "431440",
    "end": "433360"
  },
  {
    "text": "and the approach which we are following",
    "start": "433360",
    "end": "435039"
  },
  {
    "text": "is that we can we are saying that we can",
    "start": "435039",
    "end": "437680"
  },
  {
    "text": "afford to lose some logs from less",
    "start": "437680",
    "end": "439680"
  },
  {
    "text": "important containers",
    "start": "439680",
    "end": "441199"
  },
  {
    "text": "and",
    "start": "441199",
    "end": "443360"
  },
  {
    "text": "preserve more from what is important to",
    "start": "443520",
    "end": "445919"
  },
  {
    "text": "us",
    "start": "445919",
    "end": "447440"
  },
  {
    "text": "and as a baseline we are using one of",
    "start": "447440",
    "end": "449360"
  },
  {
    "text": "the existing open source plugin which is",
    "start": "449360",
    "end": "451440"
  },
  {
    "text": "called the throttle plugin",
    "start": "451440",
    "end": "453039"
  },
  {
    "text": "it allows you to control the rate of",
    "start": "453039",
    "end": "455440"
  },
  {
    "text": "logs flow in your pipeline and if the",
    "start": "455440",
    "end": "457680"
  },
  {
    "text": "rate of incoming logs exceeds then it",
    "start": "457680",
    "end": "460160"
  },
  {
    "text": "starts dropping logs",
    "start": "460160",
    "end": "463960"
  },
  {
    "start": "463000",
    "end": "547000"
  },
  {
    "text": "in all these experiments",
    "start": "464080",
    "end": "466319"
  },
  {
    "text": "uh we have two graphs",
    "start": "466319",
    "end": "468319"
  },
  {
    "text": "one is where we don't have throttle",
    "start": "468319",
    "end": "470319"
  },
  {
    "text": "which is the normal situation and one is",
    "start": "470319",
    "end": "472639"
  },
  {
    "text": "where we have throttle applied to the",
    "start": "472639",
    "end": "474240"
  },
  {
    "text": "less important containers",
    "start": "474240",
    "end": "476000"
  },
  {
    "text": "so upon applying throttle you start to",
    "start": "476000",
    "end": "478479"
  },
  {
    "text": "lose log but you also get some benefits",
    "start": "478479",
    "end": "480720"
  },
  {
    "text": "right so there's a trade-off in what you",
    "start": "480720",
    "end": "482240"
  },
  {
    "text": "choose",
    "start": "482240",
    "end": "483440"
  },
  {
    "text": "so in this case as you can see",
    "start": "483440",
    "end": "486080"
  },
  {
    "text": "like",
    "start": "486080",
    "end": "487039"
  },
  {
    "text": "we apply when there is no throttle the",
    "start": "487039",
    "end": "489120"
  },
  {
    "text": "rate of collection from each group of",
    "start": "489120",
    "end": "490879"
  },
  {
    "text": "containers is pretty much same but when",
    "start": "490879",
    "end": "493440"
  },
  {
    "text": "you apply throttle on the less important",
    "start": "493440",
    "end": "495280"
  },
  {
    "text": "containers the rate of collection for",
    "start": "495280",
    "end": "497919"
  },
  {
    "text": "important containers that is the blue",
    "start": "497919",
    "end": "499360"
  },
  {
    "text": "graph is increasing",
    "start": "499360",
    "end": "501199"
  },
  {
    "text": "and the green graph is pretty much",
    "start": "501199",
    "end": "503039"
  },
  {
    "text": "pretty much controlled as you have set",
    "start": "503039",
    "end": "504960"
  },
  {
    "text": "it in your configuration",
    "start": "504960",
    "end": "506400"
  },
  {
    "text": "so this is what we want right during",
    "start": "506400",
    "end": "508400"
  },
  {
    "text": "exceptional situations when you where",
    "start": "508400",
    "end": "509840"
  },
  {
    "text": "you don't have any control of what logs",
    "start": "509840",
    "end": "512240"
  },
  {
    "text": "are being collected or which logs are",
    "start": "512240",
    "end": "514399"
  },
  {
    "text": "being lost you are preserving more from",
    "start": "514399",
    "end": "516800"
  },
  {
    "text": "important containers and",
    "start": "516800",
    "end": "518719"
  },
  {
    "text": "you can you are doing the best you can",
    "start": "518719",
    "end": "520959"
  },
  {
    "text": "in this situation",
    "start": "520959",
    "end": "522399"
  },
  {
    "text": "so in a way you are increasing your",
    "start": "522399",
    "end": "524080"
  },
  {
    "text": "fluency capacity to collect more logs at",
    "start": "524080",
    "end": "526399"
  },
  {
    "text": "the same time dropping proactively so",
    "start": "526399",
    "end": "528640"
  },
  {
    "text": "that you are staying current of what is",
    "start": "528640",
    "end": "530560"
  },
  {
    "text": "happening in your system",
    "start": "530560",
    "end": "534000"
  },
  {
    "text": "this means that if you control your cpu",
    "start": "534000",
    "end": "536560"
  },
  {
    "text": "usage in fluency at any cyc it at any",
    "start": "536560",
    "end": "540399"
  },
  {
    "text": "point whether it has in whether it is",
    "start": "540399",
    "end": "542000"
  },
  {
    "text": "input filter or output you can collect",
    "start": "542000",
    "end": "544480"
  },
  {
    "text": "more right",
    "start": "544480",
    "end": "546959"
  },
  {
    "text": "um the second observation is more more",
    "start": "546959",
    "end": "549279"
  },
  {
    "text": "related to the implementation of intel",
    "start": "549279",
    "end": "551760"
  },
  {
    "text": "plug-in and fluency",
    "start": "551760",
    "end": "553440"
  },
  {
    "text": "so uh this is an experiment which we did",
    "start": "553440",
    "end": "556399"
  },
  {
    "text": "to test the impact of outputs buffer",
    "start": "556399",
    "end": "559120"
  },
  {
    "text": "size on the reading nature of intel",
    "start": "559120",
    "end": "562560"
  },
  {
    "text": "so when we varied the size of buffer",
    "start": "562560",
    "end": "565120"
  },
  {
    "text": "uh whether it is file or elasticsearch",
    "start": "565120",
    "end": "567200"
  },
  {
    "text": "or any other",
    "start": "567200",
    "end": "568480"
  },
  {
    "text": "common buffer uh common output plugins",
    "start": "568480",
    "end": "570480"
  },
  {
    "text": "which you use in your cluster logging",
    "start": "570480",
    "end": "573600"
  },
  {
    "text": "uh when we have a large buffer size we",
    "start": "573600",
    "end": "576080"
  },
  {
    "text": "saw that the peaks are different where",
    "start": "576080",
    "end": "578720"
  },
  {
    "text": "what i mean by peak here is the amount",
    "start": "578720",
    "end": "580880"
  },
  {
    "text": "of lines or the instantaneous rate of",
    "start": "580880",
    "end": "583360"
  },
  {
    "text": "lines read by each file",
    "start": "583360",
    "end": "585360"
  },
  {
    "text": "so different peaks denote different",
    "start": "585360",
    "end": "587360"
  },
  {
    "text": "workloads and each peak denotes how much",
    "start": "587360",
    "end": "589600"
  },
  {
    "text": "line is read from that file or from that",
    "start": "589600",
    "end": "591600"
  },
  {
    "text": "workload",
    "start": "591600",
    "end": "592720"
  },
  {
    "text": "so when you have different uh like when",
    "start": "592720",
    "end": "595120"
  },
  {
    "text": "you have a large buffer size let's say",
    "start": "595120",
    "end": "596560"
  },
  {
    "text": "1gb",
    "start": "596560",
    "end": "597920"
  },
  {
    "text": "or the reading like the amount of logs",
    "start": "597920",
    "end": "599839"
  },
  {
    "text": "read from each file is different",
    "start": "599839",
    "end": "602160"
  },
  {
    "text": "and when you have a smaller buffer size",
    "start": "602160",
    "end": "604079"
  },
  {
    "text": "you see that the peaks are of equal size",
    "start": "604079",
    "end": "606240"
  },
  {
    "text": "that means irrespective of what is the",
    "start": "606240",
    "end": "608880"
  },
  {
    "text": "generation rate of your log you're",
    "start": "608880",
    "end": "610480"
  },
  {
    "text": "reading equal amount of",
    "start": "610480",
    "end": "612240"
  },
  {
    "text": "lines",
    "start": "612240",
    "end": "613440"
  },
  {
    "text": "so why is this important right because",
    "start": "613440",
    "end": "615839"
  },
  {
    "text": "in in worst case scenarios where you do",
    "start": "615839",
    "end": "618560"
  },
  {
    "text": "when you don't know what to do you need",
    "start": "618560",
    "end": "620480"
  },
  {
    "text": "a good amount of logs so that you know",
    "start": "620480",
    "end": "622320"
  },
  {
    "text": "what is actually happening in your",
    "start": "622320",
    "end": "623760"
  },
  {
    "text": "system you you need to have a good clear",
    "start": "623760",
    "end": "626240"
  },
  {
    "text": "snapshot of your entire system so you",
    "start": "626240",
    "end": "628480"
  },
  {
    "text": "need to have some information from all",
    "start": "628480",
    "end": "630079"
  },
  {
    "text": "your all of your pods if one of the",
    "start": "630079",
    "end": "632160"
  },
  {
    "text": "workloads starts going hey where it is",
    "start": "632160",
    "end": "634240"
  },
  {
    "text": "generating thousands of logs per second",
    "start": "634240",
    "end": "636640"
  },
  {
    "text": "you don't have a good snapshot of other",
    "start": "636640",
    "end": "639760"
  },
  {
    "text": "pods so you can debug what is happening",
    "start": "639760",
    "end": "643040"
  },
  {
    "text": "so in a way you need some some form of",
    "start": "643040",
    "end": "646079"
  },
  {
    "text": "fairness in your reading so that you",
    "start": "646079",
    "end": "647839"
  },
  {
    "text": "have a",
    "start": "647839",
    "end": "649040"
  },
  {
    "text": "good snapshot of your system",
    "start": "649040",
    "end": "651600"
  },
  {
    "text": "so based on these observations like",
    "start": "651600",
    "end": "654079"
  },
  {
    "text": "if we can control the rate of flow or as",
    "start": "654079",
    "end": "657040"
  },
  {
    "text": "early in the pipeline we can save some",
    "start": "657040",
    "end": "659440"
  },
  {
    "text": "cpu cycles and increase our collection",
    "start": "659440",
    "end": "662000"
  },
  {
    "text": "and we can ensure some form of fairness",
    "start": "662000",
    "end": "664320"
  },
  {
    "text": "so that we can have a good way of",
    "start": "664320",
    "end": "666880"
  },
  {
    "text": "debugging our system",
    "start": "666880",
    "end": "669680"
  },
  {
    "start": "669000",
    "end": "715000"
  },
  {
    "text": "so here comes our the feature",
    "start": "669680",
    "end": "672240"
  },
  {
    "text": "which is called group based uh",
    "start": "672240",
    "end": "674399"
  },
  {
    "text": "throttling in entail",
    "start": "674399",
    "end": "676240"
  },
  {
    "text": "so you can form groups uh in your you",
    "start": "676240",
    "end": "679519"
  },
  {
    "text": "can define user groups in the intel",
    "start": "679519",
    "end": "682000"
  },
  {
    "text": "plugin and you can define rules for",
    "start": "682000",
    "end": "684560"
  },
  {
    "text": "assigning each workload to a file to a",
    "start": "684560",
    "end": "687040"
  },
  {
    "text": "group then you can uh",
    "start": "687040",
    "end": "690079"
  },
  {
    "text": "you can read limit the logs being",
    "start": "690079",
    "end": "692160"
  },
  {
    "text": "collected from those files and this uh",
    "start": "692160",
    "end": "694800"
  },
  {
    "text": "feature ensures that your",
    "start": "694800",
    "end": "696640"
  },
  {
    "text": "groups are",
    "start": "696640",
    "end": "698880"
  },
  {
    "text": "bred equally and rate limiting is done",
    "start": "698880",
    "end": "701279"
  },
  {
    "text": "at the time of reading",
    "start": "701279",
    "end": "703040"
  },
  {
    "text": "so this will ensure that you have enough",
    "start": "703040",
    "end": "704959"
  },
  {
    "text": "cpu cycles saved because you're saving a",
    "start": "704959",
    "end": "707279"
  },
  {
    "text": "lot of time while in uh like",
    "start": "707279",
    "end": "711279"
  },
  {
    "text": "as early all in the pipeline stage",
    "start": "711279",
    "end": "715200"
  },
  {
    "start": "715000",
    "end": "771000"
  },
  {
    "text": "so this is an example for the generic or",
    "start": "715200",
    "end": "717760"
  },
  {
    "text": "default use case for kubernetes by",
    "start": "717760",
    "end": "720160"
  },
  {
    "text": "default it will extract information from",
    "start": "720160",
    "end": "722240"
  },
  {
    "text": "your path so the generic workload path",
    "start": "722240",
    "end": "725839"
  },
  {
    "text": "in warlock containers follow a specific",
    "start": "725839",
    "end": "728000"
  },
  {
    "text": "pattern where the first keyword is spot",
    "start": "728000",
    "end": "730079"
  },
  {
    "text": "name followed by namespace container or",
    "start": "730079",
    "end": "732560"
  },
  {
    "text": "docker id",
    "start": "732560",
    "end": "733920"
  },
  {
    "text": "so you can specify your your parameters",
    "start": "733920",
    "end": "736480"
  },
  {
    "text": "like in the form of regex so this rule",
    "start": "736480",
    "end": "739279"
  },
  {
    "text": "states that match all containers which",
    "start": "739279",
    "end": "741839"
  },
  {
    "text": "have the following name spaces space 1",
    "start": "741839",
    "end": "744079"
  },
  {
    "text": "space 2 or space 3 followed by a pod",
    "start": "744079",
    "end": "747279"
  },
  {
    "text": "name and which which starts from app dot",
    "start": "747279",
    "end": "750160"
  },
  {
    "text": "anything at after that and delete limit",
    "start": "750160",
    "end": "752959"
  },
  {
    "text": "it to a number of lines as 200 after",
    "start": "752959",
    "end": "755839"
  },
  {
    "text": "every 30 seconds and this will also",
    "start": "755839",
    "end": "758320"
  },
  {
    "text": "ensure that",
    "start": "758320",
    "end": "760000"
  },
  {
    "text": "200 to the total line limit is 200 per",
    "start": "760000",
    "end": "763360"
  },
  {
    "text": "group so 200 divided by the total number",
    "start": "763360",
    "end": "765839"
  },
  {
    "text": "of files or the workloads in that group",
    "start": "765839",
    "end": "767760"
  },
  {
    "text": "will be the lines read by each file",
    "start": "767760",
    "end": "771440"
  },
  {
    "start": "771000",
    "end": "819000"
  },
  {
    "text": "however this intel plugin is not only",
    "start": "771440",
    "end": "773600"
  },
  {
    "text": "used for kubernetes right so we have",
    "start": "773600",
    "end": "775920"
  },
  {
    "text": "made this uh grouping pattern generic so",
    "start": "775920",
    "end": "778800"
  },
  {
    "text": "that you can use for other files as well",
    "start": "778800",
    "end": "781279"
  },
  {
    "text": "so you can define named captures in your",
    "start": "781279",
    "end": "783040"
  },
  {
    "text": "group pattern and then you can specify",
    "start": "783040",
    "end": "785760"
  },
  {
    "text": "matching uh key file or hash hash table",
    "start": "785760",
    "end": "789440"
  },
  {
    "text": "in your match parameter in the rule",
    "start": "789440",
    "end": "791440"
  },
  {
    "text": "directive",
    "start": "791440",
    "end": "792720"
  },
  {
    "text": "this can allow you to customize and",
    "start": "792720",
    "end": "794720"
  },
  {
    "text": "generalize your",
    "start": "794720",
    "end": "796320"
  },
  {
    "text": "grouping rules so that you can",
    "start": "796320",
    "end": "798560"
  },
  {
    "text": "use it anywhere you want",
    "start": "798560",
    "end": "800720"
  },
  {
    "text": "this uh feature will will be available",
    "start": "800720",
    "end": "803279"
  },
  {
    "text": "in 1.15 release version of fluendy",
    "start": "803279",
    "end": "806560"
  },
  {
    "text": "which will i think will be released in",
    "start": "806560",
    "end": "808240"
  },
  {
    "text": "may end",
    "start": "808240",
    "end": "809519"
  },
  {
    "text": "and you can have a look at the pr and",
    "start": "809519",
    "end": "813200"
  },
  {
    "text": "it has not been merged yet but",
    "start": "813200",
    "end": "815600"
  },
  {
    "text": "feel free to look at it and make some",
    "start": "815600",
    "end": "817440"
  },
  {
    "text": "reviews if you want",
    "start": "817440",
    "end": "819360"
  },
  {
    "start": "819000",
    "end": "830000"
  },
  {
    "text": "now coming to what we are doing as part",
    "start": "819360",
    "end": "821040"
  },
  {
    "text": "of red hat and ibm research",
    "start": "821040",
    "end": "823040"
  },
  {
    "text": "just a reminder this was uh",
    "start": "823040",
    "end": "825440"
  },
  {
    "text": "this is the api which we are using to",
    "start": "825440",
    "end": "827519"
  },
  {
    "text": "configure our operator",
    "start": "827519",
    "end": "829360"
  },
  {
    "text": "so",
    "start": "829360",
    "end": "830959"
  },
  {
    "start": "830000",
    "end": "880000"
  },
  {
    "text": "what we are now doing is we are defining",
    "start": "830959",
    "end": "833279"
  },
  {
    "text": "some policies through which we can",
    "start": "833279",
    "end": "834880"
  },
  {
    "text": "control different components of our",
    "start": "834880",
    "end": "837279"
  },
  {
    "text": "cluster logging pipeline for example we",
    "start": "837279",
    "end": "839760"
  },
  {
    "text": "can simply",
    "start": "839760",
    "end": "841440"
  },
  {
    "text": "limit",
    "start": "841440",
    "end": "842560"
  },
  {
    "text": "the rate of logs being sent to kafka to",
    "start": "842560",
    "end": "845279"
  },
  {
    "text": "one gigabit per second to avoid",
    "start": "845279",
    "end": "847680"
  },
  {
    "text": "saturating network link because as i",
    "start": "847680",
    "end": "849680"
  },
  {
    "text": "said persistent storage and network",
    "start": "849680",
    "end": "851519"
  },
  {
    "text": "bandwidth is very crucial similarly you",
    "start": "851519",
    "end": "854079"
  },
  {
    "text": "can control certain parts from uh",
    "start": "854079",
    "end": "856560"
  },
  {
    "text": "from a namespace with certain labels and",
    "start": "856560",
    "end": "859199"
  },
  {
    "text": "you can define per container limit which",
    "start": "859199",
    "end": "861360"
  },
  {
    "text": "is",
    "start": "861360",
    "end": "862240"
  },
  {
    "text": "a rate limit per file or",
    "start": "862240",
    "end": "864639"
  },
  {
    "text": "for rate limit for the entire group or",
    "start": "864639",
    "end": "866480"
  },
  {
    "text": "you can simply ignore certain",
    "start": "866480",
    "end": "868480"
  },
  {
    "text": "pods as well that means you don't even",
    "start": "868480",
    "end": "870320"
  },
  {
    "text": "collect from those pods in this way you",
    "start": "870320",
    "end": "872399"
  },
  {
    "text": "are saving again the resource very",
    "start": "872399",
    "end": "874560"
  },
  {
    "text": "crucial cpu resources and you're",
    "start": "874560",
    "end": "877519"
  },
  {
    "text": "concentrating on what is important",
    "start": "877519",
    "end": "880720"
  },
  {
    "start": "880000",
    "end": "929000"
  },
  {
    "text": "so how does this api look when we apply",
    "start": "880720",
    "end": "883440"
  },
  {
    "text": "these policies",
    "start": "883440",
    "end": "885040"
  },
  {
    "text": "so you can see on the red box is the",
    "start": "885040",
    "end": "887199"
  },
  {
    "text": "limit reference like we have like we are",
    "start": "887199",
    "end": "890800"
  },
  {
    "text": "trying to drop or drop logs if the",
    "start": "890800",
    "end": "894079"
  },
  {
    "text": "maximum records uh the incoming log rate",
    "start": "894079",
    "end": "897040"
  },
  {
    "text": "is more than 50 lines per second",
    "start": "897040",
    "end": "899360"
  },
  {
    "text": "per second sorry and you apply this rate",
    "start": "899360",
    "end": "902160"
  },
  {
    "text": "limit to an input application which is",
    "start": "902160",
    "end": "904160"
  },
  {
    "text": "where we have defined custom groups",
    "start": "904160",
    "end": "905760"
  },
  {
    "text": "there",
    "start": "905760",
    "end": "906560"
  },
  {
    "text": "which is like uh collect all",
    "start": "906560",
    "end": "909519"
  },
  {
    "text": "lines from uh pods",
    "start": "909519",
    "end": "912480"
  },
  {
    "text": "which have named less important and are",
    "start": "912480",
    "end": "914560"
  },
  {
    "text": "from namespace log stress so in this way",
    "start": "914560",
    "end": "917040"
  },
  {
    "text": "you can control different aspects of",
    "start": "917040",
    "end": "918720"
  },
  {
    "text": "your cluster logging pipeline whether it",
    "start": "918720",
    "end": "920639"
  },
  {
    "text": "is input whether it is output or you can",
    "start": "920639",
    "end": "922720"
  },
  {
    "text": "also control",
    "start": "922720",
    "end": "923920"
  },
  {
    "text": "the filter",
    "start": "923920",
    "end": "925600"
  },
  {
    "text": "components of your",
    "start": "925600",
    "end": "927519"
  },
  {
    "text": "pipeline",
    "start": "927519",
    "end": "930000"
  },
  {
    "start": "929000",
    "end": "978000"
  },
  {
    "text": "so in to summarize in this talk we",
    "start": "930160",
    "end": "931839"
  },
  {
    "text": "identified what are the different",
    "start": "931839",
    "end": "933839"
  },
  {
    "text": "bottlenecks in our cluster logging",
    "start": "933839",
    "end": "935519"
  },
  {
    "text": "pipeline and we also",
    "start": "935519",
    "end": "938800"
  },
  {
    "text": "showed you like what is like a benchmark",
    "start": "938800",
    "end": "941040"
  },
  {
    "text": "tool which we have developed for",
    "start": "941040",
    "end": "942959"
  },
  {
    "text": "generating and measuring stress",
    "start": "942959",
    "end": "944160"
  },
  {
    "text": "conditions through our experiments we",
    "start": "944160",
    "end": "946720"
  },
  {
    "text": "saw how to increase collection through",
    "start": "946720",
    "end": "948480"
  },
  {
    "text": "throttle plug-in and what is the impact",
    "start": "948480",
    "end": "950320"
  },
  {
    "text": "of outputs buffer plug-in when we change",
    "start": "950320",
    "end": "953519"
  },
  {
    "text": "the buffer size",
    "start": "953519",
    "end": "955600"
  },
  {
    "text": "or finally we uh",
    "start": "955600",
    "end": "958079"
  },
  {
    "text": "we all have also come up with a new",
    "start": "958079",
    "end": "959519"
  },
  {
    "text": "feature in intel which allows you to",
    "start": "959519",
    "end": "961519"
  },
  {
    "text": "control log loss and",
    "start": "961519",
    "end": "963759"
  },
  {
    "text": "you know",
    "start": "963759",
    "end": "966000"
  },
  {
    "text": "add throttling at the input level",
    "start": "966000",
    "end": "968480"
  },
  {
    "text": "as part of our work in red hat we are",
    "start": "968480",
    "end": "970560"
  },
  {
    "text": "working on a policy based log slow",
    "start": "970560",
    "end": "972320"
  },
  {
    "text": "control so that you can control",
    "start": "972320",
    "end": "974000"
  },
  {
    "text": "different aspects of your pipeline",
    "start": "974000",
    "end": "975839"
  },
  {
    "text": "including fluency and elastic search",
    "start": "975839",
    "end": "978480"
  },
  {
    "start": "978000",
    "end": "1105000"
  },
  {
    "text": "so this is our team of our five members",
    "start": "978480",
    "end": "980399"
  },
  {
    "text": "and if you have any questions please",
    "start": "980399",
    "end": "982720"
  },
  {
    "text": "please feel free to reach out to us on",
    "start": "982720",
    "end": "985120"
  },
  {
    "text": "this email",
    "start": "985120",
    "end": "987600"
  },
  {
    "text": "thank you",
    "start": "987600",
    "end": "988720"
  },
  {
    "text": "if you have any questions",
    "start": "988720",
    "end": "990480"
  },
  {
    "text": "we are",
    "start": "990480",
    "end": "991440"
  },
  {
    "text": "here to answer",
    "start": "991440",
    "end": "994160"
  },
  {
    "text": "so my question is is",
    "start": "1006959",
    "end": "1009040"
  },
  {
    "text": "normal to think of dropping logs instead",
    "start": "1009040",
    "end": "1011680"
  },
  {
    "text": "of increasing the capacity of the of the",
    "start": "1011680",
    "end": "1014800"
  },
  {
    "text": "aggregator i mean i never went in the",
    "start": "1014800",
    "end": "1017279"
  },
  {
    "text": "situation that i want to drop logs i",
    "start": "1017279",
    "end": "1019680"
  },
  {
    "text": "want to improve to avoid dropping them",
    "start": "1019680",
    "end": "1023680"
  },
  {
    "text": "so in",
    "start": "1023680",
    "end": "1024880"
  },
  {
    "text": "in kubernetes the",
    "start": "1024880",
    "end": "1026720"
  },
  {
    "text": "cpu and memory and resources of the",
    "start": "1026720",
    "end": "1028959"
  },
  {
    "text": "logging stack",
    "start": "1028959",
    "end": "1030319"
  },
  {
    "text": "like any other set of applications is",
    "start": "1030319",
    "end": "1032558"
  },
  {
    "text": "also limited",
    "start": "1032559",
    "end": "1034079"
  },
  {
    "text": "so we don't want to take it to infinity",
    "start": "1034079",
    "end": "1036798"
  },
  {
    "text": "when there are applications that emit a",
    "start": "1036799",
    "end": "1038959"
  },
  {
    "text": "lot of logs",
    "start": "1038959",
    "end": "1040240"
  },
  {
    "text": "really a lot of logs it does make sense",
    "start": "1040240",
    "end": "1042558"
  },
  {
    "text": "to put some threshold or some limit to",
    "start": "1042559",
    "end": "1045520"
  },
  {
    "text": "the amount of log and the amount of",
    "start": "1045520",
    "end": "1047038"
  },
  {
    "text": "resources that the logging stack itself",
    "start": "1047039",
    "end": "1049200"
  },
  {
    "text": "is taking from the system because it's",
    "start": "1049200",
    "end": "1051840"
  },
  {
    "text": "it will start to affect the other",
    "start": "1051840",
    "end": "1054000"
  },
  {
    "text": "application that you have on the cluster",
    "start": "1054000",
    "end": "1055679"
  },
  {
    "text": "this is why it does make sense sometimes",
    "start": "1055679",
    "end": "1057600"
  },
  {
    "text": "when it's really a lot of logs to start",
    "start": "1057600",
    "end": "1059919"
  },
  {
    "text": "to see log loss and this is exactly",
    "start": "1059919",
    "end": "1062160"
  },
  {
    "text": "where you want to see the log loss on",
    "start": "1062160",
    "end": "1064160"
  },
  {
    "text": "containers that are not the most",
    "start": "1064160",
    "end": "1066480"
  },
  {
    "text": "important containers that you have in",
    "start": "1066480",
    "end": "1067840"
  },
  {
    "text": "the system so you want to to balance the",
    "start": "1067840",
    "end": "1069760"
  },
  {
    "text": "effect and this is exactly what we're",
    "start": "1069760",
    "end": "1071280"
  },
  {
    "text": "doing okay so basically is to decide",
    "start": "1071280",
    "end": "1073840"
  },
  {
    "text": "which locks to drop because you can",
    "start": "1073840",
    "end": "1076240"
  },
  {
    "text": "actually also put some limits on the",
    "start": "1076240",
    "end": "1078640"
  },
  {
    "text": "containers at the kubernetes level but",
    "start": "1078640",
    "end": "1080880"
  },
  {
    "text": "then you cannot decide which locks to",
    "start": "1080880",
    "end": "1082799"
  },
  {
    "text": "drop right exactly thank you",
    "start": "1082799",
    "end": "1086640"
  },
  {
    "text": "any other questions",
    "start": "1086640",
    "end": "1090200"
  },
  {
    "text": "thank you thank you very much",
    "start": "1100799",
    "end": "1103150"
  },
  {
    "text": "[Applause]",
    "start": "1103150",
    "end": "1107259"
  }
]
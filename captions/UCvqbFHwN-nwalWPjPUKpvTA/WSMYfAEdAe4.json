[
  {
    "text": "hello I'm Sunita I work here as a senior",
    "start": "30",
    "end": "2639"
  },
  {
    "text": "data scientist at near map and I'm",
    "start": "2639",
    "end": "4859"
  },
  {
    "text": "modern adelaida an engineer working at",
    "start": "4859",
    "end": "6600"
  },
  {
    "text": "near map and we're working on the",
    "start": "6600",
    "end": "8160"
  },
  {
    "text": "stability of our inference pipeline near",
    "start": "8160",
    "end": "14190"
  },
  {
    "text": "map is the leading provider of",
    "start": "14190",
    "end": "15570"
  },
  {
    "text": "high-definition aerial imagery we",
    "start": "15570",
    "end": "18090"
  },
  {
    "text": "specialize in providing current and",
    "start": "18090",
    "end": "20640"
  },
  {
    "text": "crisp content and we do so in various",
    "start": "20640",
    "end": "22830"
  },
  {
    "text": "formats such as 2d 3d intelligently",
    "start": "22830",
    "end": "25740"
  },
  {
    "text": "derived layer and more we frequently",
    "start": "25740",
    "end": "27930"
  },
  {
    "text": "capture urban areas of Australia and New",
    "start": "27930",
    "end": "30570"
  },
  {
    "text": "Zealand United States and Canada to do",
    "start": "30570",
    "end": "33570"
  },
  {
    "text": "so we fly our plane at the height up to",
    "start": "33570",
    "end": "35700"
  },
  {
    "text": "18,000 feet and that allows us to",
    "start": "35700",
    "end": "38250"
  },
  {
    "text": "capture thousands of kilometers Square",
    "start": "38250",
    "end": "40050"
  },
  {
    "text": "area in a single flight at a very high",
    "start": "40050",
    "end": "42570"
  },
  {
    "text": "resolution such as five centimeter per",
    "start": "42570",
    "end": "44640"
  },
  {
    "text": "pixel in just year 2019 we captured 2.5",
    "start": "44640",
    "end": "48930"
  },
  {
    "text": "million kilometer Square area if we were",
    "start": "48930",
    "end": "52020"
  },
  {
    "text": "to print out our image and stack them up",
    "start": "52020",
    "end": "54449"
  },
  {
    "text": "in just one year we would have created",
    "start": "54449",
    "end": "56430"
  },
  {
    "text": "for Mount Everest equivalent content and",
    "start": "56430",
    "end": "59640"
  },
  {
    "text": "it's got to be this way because we are",
    "start": "59640",
    "end": "62129"
  },
  {
    "text": "data as a service organization and we",
    "start": "62129",
    "end": "64320"
  },
  {
    "text": "truly are a big data company today I'm",
    "start": "64320",
    "end": "68159"
  },
  {
    "text": "going to be talking about what we do",
    "start": "68159",
    "end": "69780"
  },
  {
    "text": "with AI at near map what are the",
    "start": "69780",
    "end": "72540"
  },
  {
    "text": "expectation when we have when we talk",
    "start": "72540",
    "end": "74460"
  },
  {
    "text": "about offline inferences and then we",
    "start": "74460",
    "end": "76680"
  },
  {
    "text": "talk a bit more about our solution that",
    "start": "76680",
    "end": "78750"
  },
  {
    "text": "we call Sayer martin will pitch in and",
    "start": "78750",
    "end": "81180"
  },
  {
    "text": "talk about some of the adventure we have",
    "start": "81180",
    "end": "83400"
  },
  {
    "text": "had been running this solution at scale",
    "start": "83400",
    "end": "85560"
  },
  {
    "text": "and he would also talk about some of the",
    "start": "85560",
    "end": "87869"
  },
  {
    "text": "annoyances that we have encountered with",
    "start": "87869",
    "end": "90720"
  },
  {
    "text": "respect to it cloud infrastructures and",
    "start": "90720",
    "end": "93150"
  },
  {
    "text": "I'll come back into talk about some of",
    "start": "93150",
    "end": "94799"
  },
  {
    "text": "the misadventures and then we'll open",
    "start": "94799",
    "end": "96810"
  },
  {
    "text": "the floor for questions at new map the",
    "start": "96810",
    "end": "101790"
  },
  {
    "text": "REI team has been focused on associating",
    "start": "101790",
    "end": "105329"
  },
  {
    "text": "semantics to the pixel and we do so to",
    "start": "105329",
    "end": "108810"
  },
  {
    "text": "find information about location what",
    "start": "108810",
    "end": "113759"
  },
  {
    "text": "you're seeing here is Sydney's most",
    "start": "113759",
    "end": "115590"
  },
  {
    "text": "livable place this is Milsons point and",
    "start": "115590",
    "end": "118200"
  },
  {
    "text": "lavender Bay from the eyes of our",
    "start": "118200",
    "end": "120180"
  },
  {
    "text": "machine",
    "start": "120180",
    "end": "120750"
  },
  {
    "text": "this is Roof swimming pool water body",
    "start": "120750",
    "end": "123060"
  },
  {
    "text": "and building outline overlaid on top of",
    "start": "123060",
    "end": "125490"
  },
  {
    "text": "it of course we do a lot more than these",
    "start": "125490",
    "end": "127860"
  },
  {
    "text": "handful of attributes I'm talking about",
    "start": "127860",
    "end": "129840"
  },
  {
    "text": "what we do is we generate",
    "start": "129840",
    "end": "132360"
  },
  {
    "text": "better bytes of derived content from",
    "start": "132360",
    "end": "134280"
  },
  {
    "text": "terabytes of aerial imagery but we",
    "start": "134280",
    "end": "136830"
  },
  {
    "text": "already got petabytes of imagery so you",
    "start": "136830",
    "end": "138960"
  },
  {
    "text": "see we are exponentially growing are",
    "start": "138960",
    "end": "140850"
  },
  {
    "text": "already big data set the solution we are",
    "start": "140850",
    "end": "144420"
  },
  {
    "text": "talking about today we call seer can",
    "start": "144420",
    "end": "146310"
  },
  {
    "text": "produce semantic content at a rate of",
    "start": "146310",
    "end": "148430"
  },
  {
    "text": "70,000 kilometers quite a day we could",
    "start": "148430",
    "end": "151620"
  },
  {
    "text": "probably do a lot more but we are",
    "start": "151620",
    "end": "153330"
  },
  {
    "text": "limited by the availability of spot GPUs",
    "start": "153330",
    "end": "156390"
  },
  {
    "text": "in the cloud now the data that we",
    "start": "156390",
    "end": "158730"
  },
  {
    "text": "generate are we have already generated",
    "start": "158730",
    "end": "160050"
  },
  {
    "text": "is already being put to good use in the",
    "start": "160050",
    "end": "163620"
  },
  {
    "text": "industry it's available for consumption",
    "start": "163620",
    "end": "166320"
  },
  {
    "text": "under AI offline beta program and it's",
    "start": "166320",
    "end": "169020"
  },
  {
    "text": "already delivering solution in the space",
    "start": "169020",
    "end": "171060"
  },
  {
    "text": "of 5g insurance energy utility urban",
    "start": "171060",
    "end": "174150"
  },
  {
    "text": "planning and lot mode but we don't just",
    "start": "174150",
    "end": "177870"
  },
  {
    "text": "stop it associating semantics we want to",
    "start": "177870",
    "end": "180420"
  },
  {
    "text": "provide insights from micro level such",
    "start": "180420",
    "end": "182970"
  },
  {
    "text": "as pixels all the way up to macro level",
    "start": "182970",
    "end": "185400"
  },
  {
    "text": "such as world and we are already doing",
    "start": "185400",
    "end": "188040"
  },
  {
    "text": "that some of the examples are all on the",
    "start": "188040",
    "end": "190170"
  },
  {
    "text": "screen now to do all that we observe a",
    "start": "190170",
    "end": "193440"
  },
  {
    "text": "workflow end-to-end AI workflow somewhat",
    "start": "193440",
    "end": "197299"
  },
  {
    "text": "somewhat similar to what's shown on the",
    "start": "197299",
    "end": "199650"
  },
  {
    "text": "screen now we own everything starting",
    "start": "199650",
    "end": "201870"
  },
  {
    "text": "from the data collection and to model",
    "start": "201870",
    "end": "204930"
  },
  {
    "text": "operations such as training tuning",
    "start": "204930",
    "end": "206730"
  },
  {
    "text": "improvising and also to inference and at",
    "start": "206730",
    "end": "209640"
  },
  {
    "text": "the end to insights as a service now as",
    "start": "209640",
    "end": "212430"
  },
  {
    "text": "you can see there's a lot going on here",
    "start": "212430",
    "end": "214260"
  },
  {
    "text": "and as Kelly has pointed out in 2015",
    "start": "214260",
    "end": "217049"
  },
  {
    "text": "nips paper that machine learning is the",
    "start": "217049",
    "end": "219870"
  },
  {
    "text": "ML code is really a small part of a big",
    "start": "219870",
    "end": "221940"
  },
  {
    "text": "system that forms machine learning",
    "start": "221940",
    "end": "224330"
  },
  {
    "text": "forest communities has been instrumental",
    "start": "224330",
    "end": "226590"
  },
  {
    "text": "in realizing this end-to-end a I",
    "start": "226590",
    "end": "229680"
  },
  {
    "text": "platform and also pushing boundary in",
    "start": "229680",
    "end": "231930"
  },
  {
    "text": "terms of scale and the volume of data",
    "start": "231930",
    "end": "234060"
  },
  {
    "text": "that we crunch and for that a big shout",
    "start": "234060",
    "end": "236850"
  },
  {
    "text": "out to communities community for making",
    "start": "236850",
    "end": "239340"
  },
  {
    "text": "this amazing tool now today we are only",
    "start": "239340",
    "end": "243180"
  },
  {
    "text": "going to be talking about offline",
    "start": "243180",
    "end": "244680"
  },
  {
    "text": "inference which is the section of this",
    "start": "244680",
    "end": "246870"
  },
  {
    "text": "complex workflow shown on the screen in",
    "start": "246870",
    "end": "248820"
  },
  {
    "text": "red highlight when we talk about offline",
    "start": "248820",
    "end": "252360"
  },
  {
    "text": "inference the modus operandi really is",
    "start": "252360",
    "end": "254640"
  },
  {
    "text": "for that operation is what we call dag",
    "start": "254640",
    "end": "259140"
  },
  {
    "text": "which is a series of operation applied",
    "start": "259140",
    "end": "261269"
  },
  {
    "text": "on an input data set our expectation",
    "start": "261270",
    "end": "264960"
  },
  {
    "text": "with the dag is that",
    "start": "264960",
    "end": "266230"
  },
  {
    "text": "each step in the in the dark process",
    "start": "266230",
    "end": "268720"
  },
  {
    "text": "needs to massively parallel eyes",
    "start": "268720",
    "end": "271000"
  },
  {
    "text": "we basically beat the hell out of each",
    "start": "271000",
    "end": "272620"
  },
  {
    "text": "of the step and the way we do that is we",
    "start": "272620",
    "end": "275020"
  },
  {
    "text": "slice the input to the step into various",
    "start": "275020",
    "end": "277960"
  },
  {
    "text": "atomic unit that we call datum and then",
    "start": "277960",
    "end": "281200"
  },
  {
    "text": "the operation gets our executed in a",
    "start": "281200",
    "end": "283960"
  },
  {
    "text": "gang scheduling semantics with each task",
    "start": "283960",
    "end": "286780"
  },
  {
    "text": "in the gang consuming one datum each and",
    "start": "286780",
    "end": "289120"
  },
  {
    "text": "it keeps happening until we have reached",
    "start": "289120",
    "end": "291310"
  },
  {
    "text": "to the leaf node that's when we obtain",
    "start": "291310",
    "end": "294580"
  },
  {
    "text": "all the final data that we are",
    "start": "294580",
    "end": "296020"
  },
  {
    "text": "interested in stirred that back into",
    "start": "296020",
    "end": "298060"
  },
  {
    "text": "objects told and clean up after",
    "start": "298060",
    "end": "300010"
  },
  {
    "text": "ourselves and as you can see this is",
    "start": "300010",
    "end": "302230"
  },
  {
    "text": "quite a stateful workflow which is the",
    "start": "302230",
    "end": "304990"
  },
  {
    "text": "essential component of our F line",
    "start": "304990",
    "end": "306820"
  },
  {
    "text": "inference engine now we expect that this",
    "start": "306820",
    "end": "310210"
  },
  {
    "text": "engine is able to cope up with the",
    "start": "310210",
    "end": "311950"
  },
  {
    "text": "constant flow of capture throughput but",
    "start": "311950",
    "end": "314740"
  },
  {
    "text": "at the same time it's able to deal with",
    "start": "314740",
    "end": "316660"
  },
  {
    "text": "the bursting load for four cases when we",
    "start": "316660",
    "end": "319870"
  },
  {
    "text": "have to run inferences over million",
    "start": "319870",
    "end": "321520"
  },
  {
    "text": "kilometres choir areas in very short",
    "start": "321520",
    "end": "323680"
  },
  {
    "text": "time such as a week and to do that we",
    "start": "323680",
    "end": "326170"
  },
  {
    "text": "need really need thousands of nodes and",
    "start": "326170",
    "end": "328180"
  },
  {
    "text": "not just CPU node we primarily do deep",
    "start": "328180",
    "end": "330850"
  },
  {
    "text": "learning so we are talking about",
    "start": "330850",
    "end": "332260"
  },
  {
    "text": "teraflops kind of operation so we do",
    "start": "332260",
    "end": "334510"
  },
  {
    "text": "heavily use GPU in our case and that",
    "start": "334510",
    "end": "336730"
  },
  {
    "text": "really leads us into using a mixed",
    "start": "336730",
    "end": "339370"
  },
  {
    "text": "compute of GPU and CPU because we are",
    "start": "339370",
    "end": "342340"
  },
  {
    "text": "doing all that at such a scale we need",
    "start": "342340",
    "end": "344020"
  },
  {
    "text": "to be efficient in terms of course",
    "start": "344020",
    "end": "345910"
  },
  {
    "text": "turnaround time and utilization of the",
    "start": "345910",
    "end": "348520"
  },
  {
    "text": "resource that's available to us and we",
    "start": "348520",
    "end": "351070"
  },
  {
    "text": "need to be resilient with our workload",
    "start": "351070",
    "end": "352870"
  },
  {
    "text": "because that helps with chaos and it",
    "start": "352870",
    "end": "354970"
  },
  {
    "text": "also helps a lot with the cost and we",
    "start": "354970",
    "end": "357670"
  },
  {
    "text": "don't need any manual bottleneck in our",
    "start": "357670",
    "end": "359770"
  },
  {
    "text": "system because we can't be running at",
    "start": "359770",
    "end": "362500"
  },
  {
    "text": "that scale if we have a manual",
    "start": "362500",
    "end": "363850"
  },
  {
    "text": "bottleneck so that's really a key",
    "start": "363850",
    "end": "365560"
  },
  {
    "text": "component of our system at the time of",
    "start": "365560",
    "end": "369430"
  },
  {
    "text": "building the solution we looked at",
    "start": "369430",
    "end": "370930"
  },
  {
    "text": "off-the-shelf available solution now",
    "start": "370930",
    "end": "374080"
  },
  {
    "text": "these are great tools but they they",
    "start": "374080",
    "end": "375880"
  },
  {
    "text": "weren't quite production ready and",
    "start": "375880",
    "end": "377410"
  },
  {
    "text": "weren't quite doing what we wanted of",
    "start": "377410",
    "end": "379560"
  },
  {
    "text": "our go pachyderm and cube flow path",
    "start": "379560",
    "end": "382870"
  },
  {
    "text": "pipelines which is a wrapper over our go",
    "start": "382870",
    "end": "384910"
  },
  {
    "text": "they are great tools and we already are",
    "start": "384910",
    "end": "386830"
  },
  {
    "text": "using them in some capacity but",
    "start": "386830",
    "end": "388690"
  },
  {
    "text": "particularly for offline inference they",
    "start": "388690",
    "end": "390910"
  },
  {
    "text": "weren't quite doing what we wanted most",
    "start": "390910",
    "end": "393220"
  },
  {
    "text": "couldn't cope up with the load and in",
    "start": "393220",
    "end": "395290"
  },
  {
    "text": "some cases there were over or under",
    "start": "395290",
    "end": "397180"
  },
  {
    "text": "provisioning or execution model",
    "start": "397180",
    "end": "398950"
  },
  {
    "text": "was too expensive so what did we do we",
    "start": "398950",
    "end": "402160"
  },
  {
    "text": "build our own solution that's sale we",
    "start": "402160",
    "end": "404020"
  },
  {
    "text": "are talking about how we did that is we",
    "start": "404020",
    "end": "406780"
  },
  {
    "text": "exploited kubernetes extension in point",
    "start": "406780",
    "end": "409090"
  },
  {
    "text": "that's known as custom restores the",
    "start": "409090",
    "end": "410980"
  },
  {
    "text": "source definition excuse me if you",
    "start": "410980",
    "end": "413080"
  },
  {
    "text": "aren't familiar CR DS then you might",
    "start": "413080",
    "end": "415420"
  },
  {
    "text": "have heard term operator which is which",
    "start": "415420",
    "end": "417640"
  },
  {
    "text": "works on a similar paradigm it just",
    "start": "417640",
    "end": "420190"
  },
  {
    "text": "there is only slight pragmatic",
    "start": "420190",
    "end": "421720"
  },
  {
    "text": "difference between the two so now I show",
    "start": "421720",
    "end": "424540"
  },
  {
    "text": "you the architecture of Seir which is",
    "start": "424540",
    "end": "426250"
  },
  {
    "text": "which looks somewhat like this and you",
    "start": "426250",
    "end": "428110"
  },
  {
    "text": "might think there's a lot going on let",
    "start": "428110",
    "end": "429970"
  },
  {
    "text": "me take you through in a step-by-step",
    "start": "429970",
    "end": "431320"
  },
  {
    "text": "fashion",
    "start": "431320",
    "end": "433620"
  },
  {
    "text": "first up the CR D and the controller so",
    "start": "434520",
    "end": "438130"
  },
  {
    "text": "what we have is a seer job which is a CR",
    "start": "438130",
    "end": "440230"
  },
  {
    "text": "D the declarative spec defined that",
    "start": "440230",
    "end": "442480"
  },
  {
    "text": "corresponds to the dag that we have it",
    "start": "442480",
    "end": "444820"
  },
  {
    "text": "did it holds the step of operation that",
    "start": "444820",
    "end": "446800"
  },
  {
    "text": "needs to be applied along with the input",
    "start": "446800",
    "end": "448510"
  },
  {
    "text": "operation now controller keeps watching",
    "start": "448510",
    "end": "451690"
  },
  {
    "text": "for any new resource creation and upon",
    "start": "451690",
    "end": "454120"
  },
  {
    "text": "creation attacks the way it acts its",
    "start": "454120",
    "end": "456940"
  },
  {
    "text": "start of this component first is the",
    "start": "456940",
    "end": "459070"
  },
  {
    "text": "seer workflow which under the hood is a",
    "start": "459070",
    "end": "461080"
  },
  {
    "text": "job and aside from the job it also",
    "start": "461080",
    "end": "463900"
  },
  {
    "text": "creates some other resources such as",
    "start": "463900",
    "end": "465670"
  },
  {
    "text": "persistence volume claim storage class",
    "start": "465670",
    "end": "468100"
  },
  {
    "text": "and our deploy now these are the key",
    "start": "468100",
    "end": "470770"
  },
  {
    "text": "component that allows for gank",
    "start": "470770",
    "end": "472660"
  },
  {
    "text": "scheduling what happens under the hood",
    "start": "472660",
    "end": "474670"
  },
  {
    "text": "is we are creating a network file system",
    "start": "474670",
    "end": "476550"
  },
  {
    "text": "that's cross AC and a la and open it up",
    "start": "476550",
    "end": "480310"
  },
  {
    "text": "and inner read write many semantics and",
    "start": "480310",
    "end": "482950"
  },
  {
    "text": "this allows for a concurrent heavy read",
    "start": "482950",
    "end": "486100"
  },
  {
    "text": "write and and thus realizing the",
    "start": "486100",
    "end": "488950"
  },
  {
    "text": "stateful gang she dueling and as a part",
    "start": "488950",
    "end": "492820"
  },
  {
    "text": "of the seer workflow job the pod get",
    "start": "492820",
    "end": "494620"
  },
  {
    "text": "started the soul which again is a",
    "start": "494620",
    "end": "497350"
  },
  {
    "text": "controller so seer workflow is a",
    "start": "497350",
    "end": "498910"
  },
  {
    "text": "controller and responsibility of this",
    "start": "498910",
    "end": "501010"
  },
  {
    "text": "part is to ensure that the dag execution",
    "start": "501010",
    "end": "503620"
  },
  {
    "text": "happens in the way we expect now this",
    "start": "503620",
    "end": "507250"
  },
  {
    "text": "leads us to the dag which is which is",
    "start": "507250",
    "end": "509350"
  },
  {
    "text": "the bit that's shown on the on the",
    "start": "509350",
    "end": "511150"
  },
  {
    "text": "corner now this is a synonym of what our",
    "start": "511150",
    "end": "515700"
  },
  {
    "text": "workflow would look like and as you can",
    "start": "515700",
    "end": "517990"
  },
  {
    "text": "see some steps are independent and",
    "start": "517990",
    "end": "519940"
  },
  {
    "text": "singleton but other steps run in at high",
    "start": "519940",
    "end": "523000"
  },
  {
    "text": "parallelism in Gang shedule semantics as",
    "start": "523000",
    "end": "525070"
  },
  {
    "text": "I said before now they consume their own",
    "start": "525070",
    "end": "527080"
  },
  {
    "text": "respective datums and perform the",
    "start": "527080",
    "end": "529450"
  },
  {
    "text": "operation at the",
    "start": "529450",
    "end": "530520"
  },
  {
    "text": "of the operation we collect the data",
    "start": "530520",
    "end": "531960"
  },
  {
    "text": "feed into the next step we keep doing",
    "start": "531960",
    "end": "534090"
  },
  {
    "text": "that until we have reached to the final",
    "start": "534090",
    "end": "535920"
  },
  {
    "text": "stage that's when we clean up after",
    "start": "535920",
    "end": "537990"
  },
  {
    "text": "ourselves and remove all the resources",
    "start": "537990",
    "end": "539850"
  },
  {
    "text": "now this solution with an extension to",
    "start": "539850",
    "end": "544410"
  },
  {
    "text": "cube annuities creates ephemeral cubes",
    "start": "544410",
    "end": "546600"
  },
  {
    "text": "for us now we we don't run them forever",
    "start": "546600",
    "end": "549420"
  },
  {
    "text": "we run them as on need basis these are",
    "start": "549420",
    "end": "552390"
  },
  {
    "text": "self managed multi as a cube in it is",
    "start": "552390",
    "end": "554280"
  },
  {
    "text": "cluster provision with chaox",
    "start": "554280",
    "end": "556080"
  },
  {
    "text": "they we primarily run on AWS but we",
    "start": "556080",
    "end": "558780"
  },
  {
    "text": "often see the cases when spot GPUs run",
    "start": "558780",
    "end": "561420"
  },
  {
    "text": "out on AWS in their data centers because",
    "start": "561420",
    "end": "564510"
  },
  {
    "text": "we are running at such a capacity in",
    "start": "564510",
    "end": "566520"
  },
  {
    "text": "endow in those cases we go out and run",
    "start": "566520",
    "end": "568650"
  },
  {
    "text": "on GC P so that means this solution is",
    "start": "568650",
    "end": "571110"
  },
  {
    "text": "cloud agnostic this like I said this",
    "start": "571110",
    "end": "575100"
  },
  {
    "text": "this component this solution is multi",
    "start": "575100",
    "end": "577830"
  },
  {
    "text": "a-z we run with three master up to three",
    "start": "577830",
    "end": "580770"
  },
  {
    "text": "on-demand nodes and then we run a fleet",
    "start": "580770",
    "end": "583170"
  },
  {
    "text": "of four GPUs hundreds of CPU compute and",
    "start": "583170",
    "end": "586170"
  },
  {
    "text": "thousands of GPU nodes and we we don't",
    "start": "586170",
    "end": "589260"
  },
  {
    "text": "just have one communities like that we",
    "start": "589260",
    "end": "591630"
  },
  {
    "text": "would have multiple communities",
    "start": "591630",
    "end": "593250"
  },
  {
    "text": "depending on the capacity of the system",
    "start": "593250",
    "end": "596870"
  },
  {
    "text": "not to deal with the scale and the",
    "start": "596870",
    "end": "599340"
  },
  {
    "text": "volume of data that we are talking about",
    "start": "599340",
    "end": "600780"
  },
  {
    "text": "we are running to many nodes and to many",
    "start": "600780",
    "end": "603570"
  },
  {
    "text": "parts we are talking about of the order",
    "start": "603570",
    "end": "605310"
  },
  {
    "text": "of tens of thousands of odd and",
    "start": "605310",
    "end": "606600"
  },
  {
    "text": "thousands of node we need to be careful",
    "start": "606600",
    "end": "608910"
  },
  {
    "text": "with the placement of our resources and",
    "start": "608910",
    "end": "611100"
  },
  {
    "text": "utilizing the resources that's available",
    "start": "611100",
    "end": "613050"
  },
  {
    "text": "to us in best of its capacity to do that",
    "start": "613050",
    "end": "615780"
  },
  {
    "text": "we we utilize placement predicates quite",
    "start": "615780",
    "end": "618660"
  },
  {
    "text": "heavily and some of these are selector",
    "start": "618660",
    "end": "620790"
  },
  {
    "text": "predicates until affinities and into",
    "start": "620790",
    "end": "623430"
  },
  {
    "text": "affinity Stainton tolerances in terms of",
    "start": "623430",
    "end": "626940"
  },
  {
    "text": "quality of services unfortunately due to",
    "start": "626940",
    "end": "629400"
  },
  {
    "text": "nature of our Lord not many are",
    "start": "629400",
    "end": "632490"
  },
  {
    "text": "guaranteed but we do our best to ensure",
    "start": "632490",
    "end": "634470"
  },
  {
    "text": "that they are bustable wherever not",
    "start": "634470",
    "end": "636720"
  },
  {
    "text": "possible we fall back to best effort but",
    "start": "636720",
    "end": "639350"
  },
  {
    "text": "together all these components with the",
    "start": "639350",
    "end": "642360"
  },
  {
    "text": "help of autoscaler",
    "start": "642360",
    "end": "643320"
  },
  {
    "text": "allows for the scale that we are running",
    "start": "643320",
    "end": "645810"
  },
  {
    "text": "at and our helps us realize our goal now",
    "start": "645810",
    "end": "649670"
  },
  {
    "text": "Martin will be taking over to talk about",
    "start": "649670",
    "end": "652260"
  },
  {
    "text": "some of the adventure we have seen in",
    "start": "652260",
    "end": "654270"
  },
  {
    "text": "running this solution at scale Thank You",
    "start": "654270",
    "end": "656760"
  },
  {
    "text": "Sunita also no project is complete",
    "start": "656760",
    "end": "659670"
  },
  {
    "text": "without its fair share of adventures",
    "start": "659670",
    "end": "661770"
  },
  {
    "text": "and running thousands of nodes and tens",
    "start": "661770",
    "end": "664080"
  },
  {
    "text": "of thousands of jobs in the cluster has",
    "start": "664080",
    "end": "665820"
  },
  {
    "text": "been quite a challenge with this kind of",
    "start": "665820",
    "end": "668280"
  },
  {
    "text": "load we can't guarantee that there's",
    "start": "668280",
    "end": "669780"
  },
  {
    "text": "enough resource in the spot market to",
    "start": "669780",
    "end": "672000"
  },
  {
    "text": "run everything in parallel and so we've",
    "start": "672000",
    "end": "673950"
  },
  {
    "text": "got contention between resources with",
    "start": "673950",
    "end": "675750"
  },
  {
    "text": "lots of pending pods except not all of",
    "start": "675750",
    "end": "678210"
  },
  {
    "text": "these pods are created equal we really",
    "start": "678210",
    "end": "680190"
  },
  {
    "text": "need our controller and our master pods",
    "start": "680190",
    "end": "682440"
  },
  {
    "text": "to have priority when we allocate them",
    "start": "682440",
    "end": "685550"
  },
  {
    "text": "so here our solution is to create a",
    "start": "685550",
    "end": "687990"
  },
  {
    "text": "priority class and we assign this to",
    "start": "687990",
    "end": "690420"
  },
  {
    "text": "those pods ensuring that the critical",
    "start": "690420",
    "end": "692490"
  },
  {
    "text": "processes have affinity for more stable",
    "start": "692490",
    "end": "694980"
  },
  {
    "text": "on-demand nodes and this allows us to",
    "start": "694980",
    "end": "696900"
  },
  {
    "text": "schedule tens of thousands of jobs with",
    "start": "696900",
    "end": "698970"
  },
  {
    "text": "separation between the critical",
    "start": "698970",
    "end": "700500"
  },
  {
    "text": "orchestration jobs and then the data",
    "start": "700500",
    "end": "702630"
  },
  {
    "text": "production jobs which trickle through as",
    "start": "702630",
    "end": "704700"
  },
  {
    "text": "low becomes available",
    "start": "704700",
    "end": "707480"
  },
  {
    "text": "so we can keep our resource fed without",
    "start": "712720",
    "end": "714700"
  },
  {
    "text": "affecting the management processes so",
    "start": "714700",
    "end": "716920"
  },
  {
    "text": "we're in a pretty good place we can",
    "start": "716920",
    "end": "718900"
  },
  {
    "text": "create batches of jobs but we need to be",
    "start": "718900",
    "end": "720790"
  },
  {
    "text": "able to manage running multiple of these",
    "start": "720790",
    "end": "722500"
  },
  {
    "text": "tags at a single time the thing we're",
    "start": "722500",
    "end": "725620"
  },
  {
    "text": "missing here is a queuing mechanism and",
    "start": "725620",
    "end": "727240"
  },
  {
    "text": "this allows us to operate processing of",
    "start": "727240",
    "end": "729220"
  },
  {
    "text": "many jobs at a single time in an",
    "start": "729220",
    "end": "730870"
  },
  {
    "text": "automated way again here we've created a",
    "start": "730870",
    "end": "734440"
  },
  {
    "text": "custom solution and we've extended the",
    "start": "734440",
    "end": "736810"
  },
  {
    "text": "controller with two components the first",
    "start": "736810",
    "end": "739990"
  },
  {
    "text": "one is the database backed by persistent",
    "start": "739990",
    "end": "742390"
  },
  {
    "text": "storage and this captures our queue and",
    "start": "742390",
    "end": "744160"
  },
  {
    "text": "also the state of jobs in flight and in",
    "start": "744160",
    "end": "747220"
  },
  {
    "text": "this and this is wrapped by a service",
    "start": "747220",
    "end": "748690"
  },
  {
    "text": "which allows us to query the state of",
    "start": "748690",
    "end": "750250"
  },
  {
    "text": "jobs and update the second component is",
    "start": "750250",
    "end": "753700"
  },
  {
    "text": "a scheduler which monitors the state of",
    "start": "753700",
    "end": "756670"
  },
  {
    "text": "jobs in the in the cluster and looks at",
    "start": "756670",
    "end": "759100"
  },
  {
    "text": "the the capacity of the cluster and",
    "start": "759100",
    "end": "760900"
  },
  {
    "text": "decides whether or not we're able to",
    "start": "760900",
    "end": "762160"
  },
  {
    "text": "shade your new jobs and this allows us",
    "start": "762160",
    "end": "764590"
  },
  {
    "text": "to trigger and cue our workflows for",
    "start": "764590",
    "end": "766330"
  },
  {
    "text": "processing and we can ensure that",
    "start": "766330",
    "end": "768040"
  },
  {
    "text": "everything runs in the right order that",
    "start": "768040",
    "end": "770050"
  },
  {
    "text": "we don't overload the kubernetes api and",
    "start": "770050",
    "end": "772060"
  },
  {
    "text": "that we're feeding our resources",
    "start": "772060",
    "end": "773620"
  },
  {
    "text": "efficiently as possible so at this point",
    "start": "773620",
    "end": "779650"
  },
  {
    "text": "we're running multiple workflows",
    "start": "779650",
    "end": "781000"
  },
  {
    "text": "simultaneously each of them with",
    "start": "781000",
    "end": "782980"
  },
  {
    "text": "thousands of jobs scheduled at a time",
    "start": "782980",
    "end": "784540"
  },
  {
    "text": "and we're running a stateful workload",
    "start": "784540",
    "end": "786790"
  },
  {
    "text": "here so we require across a Z persistent",
    "start": "786790",
    "end": "789640"
  },
  {
    "text": "store and we're accessing files",
    "start": "789640",
    "end": "791500"
  },
  {
    "text": "repeatedly so with thousands of nodes",
    "start": "791500",
    "end": "793900"
  },
  {
    "text": "each doing a mix of read and write",
    "start": "793900",
    "end": "795190"
  },
  {
    "text": "operations we're starting to see",
    "start": "795190",
    "end": "796960"
  },
  {
    "text": "ourselves hitting the limits of the",
    "start": "796960",
    "end": "798490"
  },
  {
    "text": "shared file stores so our solution here",
    "start": "798490",
    "end": "803680"
  },
  {
    "text": "is to isolate the persistent volume for",
    "start": "803680",
    "end": "805660"
  },
  {
    "text": "each of these workflows and again we",
    "start": "805660",
    "end": "807640"
  },
  {
    "text": "provision across a Z and FS but share",
    "start": "807640",
    "end": "810640"
  },
  {
    "text": "this only between the jobs in that",
    "start": "810640",
    "end": "811990"
  },
  {
    "text": "workflow and this provides a good",
    "start": "811990",
    "end": "813880"
  },
  {
    "text": "isolation between each of those and then",
    "start": "813880",
    "end": "815920"
  },
  {
    "text": "we can throw this away once our",
    "start": "815920",
    "end": "817300"
  },
  {
    "text": "processing is finished so it allows us",
    "start": "817300",
    "end": "819820"
  },
  {
    "text": "really to keep our processing times in",
    "start": "819820",
    "end": "821290"
  },
  {
    "text": "check by keeping our GPUs fed and",
    "start": "821290",
    "end": "823330"
  },
  {
    "text": "running high concurrency so introducing",
    "start": "823330",
    "end": "828280"
  },
  {
    "text": "these Peavey's has also added some",
    "start": "828280",
    "end": "829930"
  },
  {
    "text": "stability issues and we see particular",
    "start": "829930",
    "end": "831550"
  },
  {
    "text": "nodes I'm failing to map the volume and",
    "start": "831550",
    "end": "834220"
  },
  {
    "text": "this manifests itself in pods which is",
    "start": "834220",
    "end": "836950"
  },
  {
    "text": "stuck in a container creating state and",
    "start": "836950",
    "end": "839830"
  },
  {
    "text": "so at the moment it's a still an open",
    "start": "839830",
    "end": "841780"
  },
  {
    "text": "issue that we're seeing in the",
    "start": "841780",
    "end": "844120"
  },
  {
    "text": "but for now to hit full animation we've",
    "start": "844120",
    "end": "847059"
  },
  {
    "text": "gone with a custom solution and what",
    "start": "847059",
    "end": "849339"
  },
  {
    "text": "we've done is we've deployed an agent",
    "start": "849339",
    "end": "850839"
  },
  {
    "text": "onto the cluster and this resolves this",
    "start": "850839",
    "end": "854079"
  },
  {
    "text": "issue when we see it by draining the UM",
    "start": "854079",
    "end": "855879"
  },
  {
    "text": "the unhealthy nodes and again",
    "start": "855879",
    "end": "860439"
  },
  {
    "text": "remembering that we're running a",
    "start": "860439",
    "end": "861430"
  },
  {
    "text": "self-managed kubernetes cluster with",
    "start": "861430",
    "end": "863139"
  },
  {
    "text": "burstable or best-effort jobs we see",
    "start": "863139",
    "end": "865689"
  },
  {
    "text": "occasionally that we still node",
    "start": "865689",
    "end": "866949"
  },
  {
    "text": "resources from system components like",
    "start": "866949",
    "end": "868930"
  },
  {
    "text": "the cubelet and again this is an issue",
    "start": "868930",
    "end": "872050"
  },
  {
    "text": "that many people in the community have",
    "start": "872050",
    "end": "873339"
  },
  {
    "text": "seen but for this one there's a well",
    "start": "873339",
    "end": "875170"
  },
  {
    "text": "documented best practice solution and so",
    "start": "875170",
    "end": "878709"
  },
  {
    "text": "what we've done is we've manually",
    "start": "878709",
    "end": "879879"
  },
  {
    "text": "reserved the resources for the cubelet",
    "start": "879879",
    "end": "881589"
  },
  {
    "text": "in the cluster spec and although it's",
    "start": "881589",
    "end": "883540"
  },
  {
    "text": "not necessarily difficult solution we",
    "start": "883540",
    "end": "885970"
  },
  {
    "text": "think that it should really be",
    "start": "885970",
    "end": "886779"
  },
  {
    "text": "pre-configured since kubernetes should",
    "start": "886779",
    "end": "888670"
  },
  {
    "text": "be is intended to run at the scale out",
    "start": "888670",
    "end": "890709"
  },
  {
    "text": "of the box so now we're at a point where",
    "start": "890709",
    "end": "896170"
  },
  {
    "text": "each of our pods can run without harming",
    "start": "896170",
    "end": "897999"
  },
  {
    "text": "system components or running out of i/o",
    "start": "897999",
    "end": "899769"
  },
  {
    "text": "or hitting i/o limits and given that",
    "start": "899769",
    "end": "902470"
  },
  {
    "text": "we're scheduling in the order of tens of",
    "start": "902470",
    "end": "903910"
  },
  {
    "text": "thousands of these at a time we need",
    "start": "903910",
    "end": "906129"
  },
  {
    "text": "thousands of nodes to process these in",
    "start": "906129",
    "end": "908230"
  },
  {
    "text": "parallel and so with the D with a",
    "start": "908230",
    "end": "910779"
  },
  {
    "text": "default container network interface",
    "start": "910779",
    "end": "912370"
  },
  {
    "text": "we're limited to a route table limit of",
    "start": "912370",
    "end": "914800"
  },
  {
    "text": "50 entries and we see degradation if we",
    "start": "914800",
    "end": "917620"
  },
  {
    "text": "cross this and we could either raise",
    "start": "917620",
    "end": "920350"
  },
  {
    "text": "this limit with AWS",
    "start": "920350",
    "end": "921550"
  },
  {
    "text": "at the expense of a slight performance",
    "start": "921550",
    "end": "923290"
  },
  {
    "text": "degradation but that only helps us in",
    "start": "923290",
    "end": "925600"
  },
  {
    "text": "scaling to hundreds of nodes which isn't",
    "start": "925600",
    "end": "927429"
  },
  {
    "text": "quite a cup of tea so we've looked at",
    "start": "927429",
    "end": "929920"
  },
  {
    "text": "the option of changing the cni to",
    "start": "929920",
    "end": "931720"
  },
  {
    "text": "flannel for its simplicity and that",
    "start": "931720",
    "end": "933550"
  },
  {
    "text": "allows us to go up to thousands of nodes",
    "start": "933550",
    "end": "935529"
  },
  {
    "text": "in parallel at this point we're running",
    "start": "935529",
    "end": "939939"
  },
  {
    "text": "a healthy cluster with a configuration",
    "start": "939939",
    "end": "941439"
  },
  {
    "text": "that allows us to orchestrate tens of",
    "start": "941439",
    "end": "943360"
  },
  {
    "text": "thousands of pods but it's not",
    "start": "943360",
    "end": "945279"
  },
  {
    "text": "completely pain-free and we start to see",
    "start": "945279",
    "end": "947829"
  },
  {
    "text": "some issues with the cluster autoscaler",
    "start": "947829",
    "end": "949660"
  },
  {
    "text": "when going beyond 650 nodes in this case",
    "start": "949660",
    "end": "953050"
  },
  {
    "text": "the cluster continues to be to look",
    "start": "953050",
    "end": "954790"
  },
  {
    "text": "healthy but the autoscaler can't reach",
    "start": "954790",
    "end": "956620"
  },
  {
    "text": "our masters and we suspect that this is",
    "start": "956620",
    "end": "958540"
  },
  {
    "text": "due to a time at issue again this is an",
    "start": "958540",
    "end": "961300"
  },
  {
    "text": "open issue which we don't have a",
    "start": "961300",
    "end": "962589"
  },
  {
    "text": "resolution to at the moment but we have",
    "start": "962589",
    "end": "964839"
  },
  {
    "text": "a bandit like solution here good or bad",
    "start": "964839",
    "end": "967809"
  },
  {
    "text": "and when we observe autoscaler failures",
    "start": "967809",
    "end": "970540"
  },
  {
    "text": "we fall back to our pre cooks it script",
    "start": "970540",
    "end": "972910"
  },
  {
    "text": "which acts as our autoscaler and as the",
    "start": "972910",
    "end": "975549"
  },
  {
    "text": "secondary measure this does the job",
    "start": "975549",
    "end": "977920"
  },
  {
    "text": "so now we're running at the scale we",
    "start": "977920",
    "end": "980139"
  },
  {
    "text": "want but we need to finish as fast as",
    "start": "980139",
    "end": "981850"
  },
  {
    "text": "possible and you know workflow the GPU",
    "start": "981850",
    "end": "984399"
  },
  {
    "text": "step is by far the most expensive",
    "start": "984399",
    "end": "985629"
  },
  {
    "text": "operation both in coil in terms of cost",
    "start": "985629",
    "end": "988569"
  },
  {
    "text": "but also in compute time and we",
    "start": "988569",
    "end": "991329"
  },
  {
    "text": "typically see processing times of up to",
    "start": "991329",
    "end": "992859"
  },
  {
    "text": "three hours for each of these datums so",
    "start": "992859",
    "end": "995589"
  },
  {
    "text": "really two processes and in any",
    "start": "995589",
    "end": "997899"
  },
  {
    "text": "acceptable time frame we need to",
    "start": "997899",
    "end": "999429"
  },
  {
    "text": "parallelize this as much as possible",
    "start": "999429",
    "end": "1000769"
  },
  {
    "text": "using as many GPUs as possible but who",
    "start": "1000769",
    "end": "1005309"
  },
  {
    "text": "would have thought that there wouldn't",
    "start": "1005309",
    "end": "1006299"
  },
  {
    "text": "be enough spot GPU in the cloud so going",
    "start": "1006299",
    "end": "1010410"
  },
  {
    "text": "multi AZ wasn't enough and we've",
    "start": "1010410",
    "end": "1012089"
  },
  {
    "text": "embraced a multi region approach and",
    "start": "1012089",
    "end": "1014189"
  },
  {
    "text": "what we've done is we've provisioned a",
    "start": "1014189",
    "end": "1016290"
  },
  {
    "text": "cluster in every AWS region that has",
    "start": "1016290",
    "end": "1018720"
  },
  {
    "text": "enough spot GPU availability to achieve",
    "start": "1018720",
    "end": "1021749"
  },
  {
    "text": "this we've adopted a git ops workflow",
    "start": "1021749",
    "end": "1023609"
  },
  {
    "text": "and we orchestrate the clusters with",
    "start": "1023609",
    "end": "1025470"
  },
  {
    "text": "cops and terraform and every code change",
    "start": "1025470",
    "end": "1028048"
  },
  {
    "text": "triggers a CI workflow which propagates",
    "start": "1028049",
    "end": "1030389"
  },
  {
    "text": "throughout through to our clusters and",
    "start": "1030389",
    "end": "1032279"
  },
  {
    "text": "this gives us all the benefits of",
    "start": "1032279",
    "end": "1034019"
  },
  {
    "text": "version control but also folds into our",
    "start": "1034019",
    "end": "1036120"
  },
  {
    "text": "existing code review practices so we've",
    "start": "1036120",
    "end": "1040079"
  },
  {
    "text": "gone out to multiple regions and we have",
    "start": "1040079",
    "end": "1041850"
  },
  {
    "text": "a mushroom effect with our clusters",
    "start": "1041850",
    "end": "1043880"
  },
  {
    "text": "queuing and scheduling mechanisms have",
    "start": "1043880",
    "end": "1046260"
  },
  {
    "text": "been decentralized and this requires a",
    "start": "1046260",
    "end": "1048240"
  },
  {
    "text": "bit more work to operate considering",
    "start": "1048240",
    "end": "1050370"
  },
  {
    "text": "that we want to really be in a fully",
    "start": "1050370",
    "end": "1051809"
  },
  {
    "text": "automated manner so we want to",
    "start": "1051809",
    "end": "1054510"
  },
  {
    "text": "centralize our queueing in chechenya",
    "start": "1054510",
    "end": "1056039"
  },
  {
    "text": "mechanisms and we've done this with Sto",
    "start": "1056039",
    "end": "1058460"
  },
  {
    "text": "so each of our clusters has its own",
    "start": "1058460",
    "end": "1060809"
  },
  {
    "text": "service mesh which together form one",
    "start": "1060809",
    "end": "1063000"
  },
  {
    "text": "logical hybrid mesh and with multi",
    "start": "1063000",
    "end": "1065700"
  },
  {
    "text": "cluster sto each control plane runs its",
    "start": "1065700",
    "end": "1067740"
  },
  {
    "text": "own DNS server which allows discovering",
    "start": "1067740",
    "end": "1070019"
  },
  {
    "text": "services from other clusters and this",
    "start": "1070019",
    "end": "1072299"
  },
  {
    "text": "really is the final step to having a",
    "start": "1072299",
    "end": "1073620"
  },
  {
    "text": "fully automated distributed cluster and",
    "start": "1073620",
    "end": "1075450"
  },
  {
    "text": "is moving into production soon so now",
    "start": "1075450",
    "end": "1079889"
  },
  {
    "text": "we're in a place where we're running",
    "start": "1079889",
    "end": "1080909"
  },
  {
    "text": "thousands of nodes generating terabytes",
    "start": "1080909",
    "end": "1082740"
  },
  {
    "text": "of data per job and the next challenge",
    "start": "1082740",
    "end": "1085710"
  },
  {
    "text": "is pulling this data into our object",
    "start": "1085710",
    "end": "1087480"
  },
  {
    "text": "stores so that we can serve it it's not",
    "start": "1087480",
    "end": "1090659"
  },
  {
    "text": "quite as simple as running a single s3",
    "start": "1090659",
    "end": "1093210"
  },
  {
    "text": "sync as others have found and we observe",
    "start": "1093210",
    "end": "1095789"
  },
  {
    "text": "missing files especially when we're",
    "start": "1095789",
    "end": "1097200"
  },
  {
    "text": "working with terabytes of data we also",
    "start": "1097200",
    "end": "1101100"
  },
  {
    "text": "tend to see interesting things like this",
    "start": "1101100",
    "end": "1103070"
  },
  {
    "text": "we get corruptions when GPUs crash and",
    "start": "1103070",
    "end": "1106019"
  },
  {
    "text": "as you can tell these on rubes even",
    "start": "1106019",
    "end": "1108510"
  },
  {
    "text": "though that's what they're supposed to",
    "start": "1108510",
    "end": "1109379"
  },
  {
    "text": "be so we've added a final very",
    "start": "1109379",
    "end": "1111690"
  },
  {
    "text": "vacation step was a which is a",
    "start": "1111690",
    "end": "1113340"
  },
  {
    "text": "comprehensive verification and is our",
    "start": "1113340",
    "end": "1115470"
  },
  {
    "text": "final guarantee that everything is there",
    "start": "1115470",
    "end": "1117480"
  },
  {
    "text": "and valid we've also managed to hit",
    "start": "1117480",
    "end": "1120629"
  },
  {
    "text": "quite a few bottlenecks within the",
    "start": "1120629",
    "end": "1122429"
  },
  {
    "text": "infrastructure because it turns out that",
    "start": "1122429",
    "end": "1124320"
  },
  {
    "text": "cloud providers aren't used to seeing",
    "start": "1124320",
    "end": "1125669"
  },
  {
    "text": "people hitting this scale the first one",
    "start": "1125669",
    "end": "1128669"
  },
  {
    "text": "of these is hitting node provisioning",
    "start": "1128669",
    "end": "1130019"
  },
  {
    "text": "limits because we want to be able to",
    "start": "1130019",
    "end": "1131789"
  },
  {
    "text": "scale up to thousands of nodes in just a",
    "start": "1131789",
    "end": "1133559"
  },
  {
    "text": "matter of minutes but by default",
    "start": "1133559",
    "end": "1137100"
  },
  {
    "text": "AWS provisions nodes in blocks of 10",
    "start": "1137100",
    "end": "1139350"
  },
  {
    "text": "which takes about 40 minutes to hit that",
    "start": "1139350",
    "end": "1141120"
  },
  {
    "text": "on the scale and it turns out that's not",
    "start": "1141120",
    "end": "1144299"
  },
  {
    "text": "all we're hitting infrastructure limits",
    "start": "1144299",
    "end": "1145860"
  },
  {
    "text": "everywhere you can imagine and it's a",
    "start": "1145860",
    "end": "1147570"
  },
  {
    "text": "process of jumping through each of these",
    "start": "1147570",
    "end": "1149009"
  },
  {
    "text": "limits until we can hit the scale that",
    "start": "1149009",
    "end": "1150690"
  },
  {
    "text": "we desire so now I'm going to hand back",
    "start": "1150690",
    "end": "1153600"
  },
  {
    "text": "to Sunita who's going to talk about some",
    "start": "1153600",
    "end": "1155220"
  },
  {
    "text": "of our misadventures as well Thank You",
    "start": "1155220",
    "end": "1157500"
  },
  {
    "text": "Martin no adventure is ever possible",
    "start": "1157500",
    "end": "1160019"
  },
  {
    "text": "without a few handful of misadventures",
    "start": "1160019",
    "end": "1161820"
  },
  {
    "text": "and that's what makes our experience",
    "start": "1161820",
    "end": "1164100"
  },
  {
    "text": "interesting so let's look at some of",
    "start": "1164100",
    "end": "1165929"
  },
  {
    "text": "these sharing GPU what do we do when our",
    "start": "1165929",
    "end": "1169080"
  },
  {
    "text": "GPU workload isn't quite GPU efficient",
    "start": "1169080",
    "end": "1171750"
  },
  {
    "text": "we share the GPU right so we thought and",
    "start": "1171750",
    "end": "1174299"
  },
  {
    "text": "when we ventured out to this exercise",
    "start": "1174299",
    "end": "1176309"
  },
  {
    "text": "first attempt at this we exposed all the",
    "start": "1176309",
    "end": "1178919"
  },
  {
    "text": "GPUs of a node to all the pods deployed",
    "start": "1178919",
    "end": "1181740"
  },
  {
    "text": "on the node and only share a fraction of",
    "start": "1181740",
    "end": "1184080"
  },
  {
    "text": "the memory through tensorflow",
    "start": "1184080",
    "end": "1186590"
  },
  {
    "text": "configuration turns out that even",
    "start": "1186590",
    "end": "1189210"
  },
  {
    "text": "tensorflow doesn't guarantee the amount",
    "start": "1189210",
    "end": "1190950"
  },
  {
    "text": "of flexion that you are intending to",
    "start": "1190950",
    "end": "1192539"
  },
  {
    "text": "allocate with the traction configuration",
    "start": "1192539",
    "end": "1194429"
  },
  {
    "text": "and that's not it there are various",
    "start": "1194429",
    "end": "1196740"
  },
  {
    "text": "Furious error that you would see with",
    "start": "1196740",
    "end": "1198509"
  },
  {
    "text": "your stack crashing and GPU compute",
    "start": "1198509",
    "end": "1201960"
  },
  {
    "text": "crashing some of them are so nasty that",
    "start": "1201960",
    "end": "1204419"
  },
  {
    "text": "they would fail with without they would",
    "start": "1204419",
    "end": "1207809"
  },
  {
    "text": "not outright fail they would fail",
    "start": "1207809",
    "end": "1209340"
  },
  {
    "text": "silently and you would have absolutely",
    "start": "1209340",
    "end": "1210960"
  },
  {
    "text": "no idea of crash and what that leads to",
    "start": "1210960",
    "end": "1214470"
  },
  {
    "text": "is perfectly readable output but",
    "start": "1214470",
    "end": "1216299"
  },
  {
    "text": "complete garbage one such example is",
    "start": "1216299",
    "end": "1218340"
  },
  {
    "text": "shown on the screen",
    "start": "1218340",
    "end": "1219269"
  },
  {
    "text": "now when we run with this particular",
    "start": "1219269",
    "end": "1221340"
  },
  {
    "text": "attempt we generate thousands of these",
    "start": "1221340",
    "end": "1223110"
  },
  {
    "text": "these are of no use to us and of course",
    "start": "1223110",
    "end": "1226080"
  },
  {
    "text": "that's not quite right what we are",
    "start": "1226080",
    "end": "1228389"
  },
  {
    "text": "trying to do because there is no",
    "start": "1228389",
    "end": "1229889"
  },
  {
    "text": "isolation guarantee on GPU the the GPU",
    "start": "1229889",
    "end": "1232919"
  },
  {
    "text": "providers such as Nvidia they for",
    "start": "1232919",
    "end": "1234840"
  },
  {
    "text": "security and isolation purposes they",
    "start": "1234840",
    "end": "1237179"
  },
  {
    "text": "don't recommend this approach but fun",
    "start": "1237179",
    "end": "1239850"
  },
  {
    "text": "item 10 one exercise wasn't enough we",
    "start": "1239850",
    "end": "1241980"
  },
  {
    "text": "still",
    "start": "1241980",
    "end": "1242850"
  },
  {
    "text": "hell-bent on it we tried one more",
    "start": "1242850",
    "end": "1244409"
  },
  {
    "text": "exercise we we looked at exposing GPU",
    "start": "1244409",
    "end": "1247889"
  },
  {
    "text": "memory as an extended resource similar",
    "start": "1247889",
    "end": "1249899"
  },
  {
    "text": "to what Alibaba cloud exposes in another",
    "start": "1249899",
    "end": "1253500"
  },
  {
    "text": "semantics it works for a lot of people",
    "start": "1253500",
    "end": "1256019"
  },
  {
    "text": "but it didn't quite work for us because",
    "start": "1256019",
    "end": "1258179"
  },
  {
    "text": "again like previous discussion we would",
    "start": "1258179",
    "end": "1262440"
  },
  {
    "text": "have spurious of our mirrors and and",
    "start": "1262440",
    "end": "1264389"
  },
  {
    "text": "complete rubbish files getting generated",
    "start": "1264389",
    "end": "1266700"
  },
  {
    "text": "all over the place turns out all we",
    "start": "1266700",
    "end": "1268830"
  },
  {
    "text": "needed to do was optimize our code so",
    "start": "1268830",
    "end": "1271230"
  },
  {
    "text": "it's efficient on GPU and it wasn't as",
    "start": "1271230",
    "end": "1273840"
  },
  {
    "text": "much effort as it did for us to run",
    "start": "1273840",
    "end": "1276840"
  },
  {
    "text": "through one and two",
    "start": "1276840",
    "end": "1278779"
  },
  {
    "text": "now GPUs are expensive right and as we",
    "start": "1278779",
    "end": "1282210"
  },
  {
    "text": "said we run thousands of them so when we",
    "start": "1282210",
    "end": "1284399"
  },
  {
    "text": "run with spot we can get them at about",
    "start": "1284399",
    "end": "1286289"
  },
  {
    "text": "40 percent price so we thought and then",
    "start": "1286289",
    "end": "1289529"
  },
  {
    "text": "we then we bid for them they bid for",
    "start": "1289529",
    "end": "1292139"
  },
  {
    "text": "Macs on demand price and then we get for",
    "start": "1292139",
    "end": "1294570"
  },
  {
    "text": "whatever is the relevant price that",
    "start": "1294570",
    "end": "1296519"
  },
  {
    "text": "sounds perfectly reasonable right just",
    "start": "1296519",
    "end": "1299580"
  },
  {
    "text": "when you run start running thousands of",
    "start": "1299580",
    "end": "1301379"
  },
  {
    "text": "those and drain the cloud or the region",
    "start": "1301379",
    "end": "1303419"
  },
  {
    "text": "with spa GPUs then the market starts to",
    "start": "1303419",
    "end": "1306779"
  },
  {
    "text": "go up",
    "start": "1306779",
    "end": "1307679"
  },
  {
    "text": "you know how spot markets work right",
    "start": "1307679",
    "end": "1310259"
  },
  {
    "text": "though as the demand goes up the price",
    "start": "1310259",
    "end": "1312600"
  },
  {
    "text": "also start going up but when your system",
    "start": "1312600",
    "end": "1314759"
  },
  {
    "text": "is automated and you are bidding for the",
    "start": "1314759",
    "end": "1316470"
  },
  {
    "text": "max price and happily sipping your",
    "start": "1316470",
    "end": "1318500"
  },
  {
    "text": "drinks then things like these happen the",
    "start": "1318500",
    "end": "1321509"
  },
  {
    "text": "price spike from 6% all the way two",
    "start": "1321509",
    "end": "1323789"
  },
  {
    "text": "hundred and twenty percent and yes we",
    "start": "1323789",
    "end": "1326100"
  },
  {
    "text": "ended up realizing that when we got our",
    "start": "1326100",
    "end": "1328529"
  },
  {
    "text": "bill and yes I still have my job thank",
    "start": "1328529",
    "end": "1330899"
  },
  {
    "text": "you for your concern so the solution for",
    "start": "1330899",
    "end": "1335460"
  },
  {
    "text": "this was quite simple all we had to do",
    "start": "1335460",
    "end": "1337200"
  },
  {
    "text": "was bid for the price that we are",
    "start": "1337200",
    "end": "1338700"
  },
  {
    "text": "comfortable with now monitoring GPU",
    "start": "1338700",
    "end": "1342210"
  },
  {
    "text": "monitoring GPU isn't as simple as",
    "start": "1342210",
    "end": "1344039"
  },
  {
    "text": "monitoring CPU and memory when you lend",
    "start": "1344039",
    "end": "1346769"
  },
  {
    "text": "out VMs from cloud infrastructure",
    "start": "1346769",
    "end": "1348809"
  },
  {
    "text": "because that's something that they own",
    "start": "1348809",
    "end": "1350190"
  },
  {
    "text": "and it's easy to isolate from the",
    "start": "1350190",
    "end": "1352980"
  },
  {
    "text": "virtualization point of view not quite",
    "start": "1352980",
    "end": "1355470"
  },
  {
    "text": "so far GPU because you still need to",
    "start": "1355470",
    "end": "1357269"
  },
  {
    "text": "install the drivers and toolkits to to",
    "start": "1357269",
    "end": "1360269"
  },
  {
    "text": "be able to prove the GPUs but we needed",
    "start": "1360269",
    "end": "1363029"
  },
  {
    "text": "to ex to explore that because we wanted",
    "start": "1363029",
    "end": "1365519"
  },
  {
    "text": "to build the silk bill improve our code",
    "start": "1365519",
    "end": "1367980"
  },
  {
    "text": "so it's hundred percent efficient from",
    "start": "1367980",
    "end": "1370019"
  },
  {
    "text": "GPU view point so what we did what a",
    "start": "1370019",
    "end": "1373169"
  },
  {
    "text": "common solution would be we've deployed",
    "start": "1373169",
    "end": "1374879"
  },
  {
    "text": "at them and said that",
    "start": "1374879",
    "end": "1375879"
  },
  {
    "text": "that frequently poles into pulls into",
    "start": "1375879",
    "end": "1379599"
  },
  {
    "text": "the GPU to find the utilization but",
    "start": "1379599",
    "end": "1381729"
  },
  {
    "text": "turns out we're now running so many",
    "start": "1381729",
    "end": "1383679"
  },
  {
    "text": "demons head that we can't that scheduler",
    "start": "1383679",
    "end": "1385569"
  },
  {
    "text": "can't cope up with we already have",
    "start": "1385569",
    "end": "1387579"
  },
  {
    "text": "thousands of POD now we have flannel for",
    "start": "1387579",
    "end": "1389739"
  },
  {
    "text": "networking component we have monitoring",
    "start": "1389739",
    "end": "1391569"
  },
  {
    "text": "them in sets we have device plug-in and",
    "start": "1391569",
    "end": "1393729"
  },
  {
    "text": "we also have GP utilization and system",
    "start": "1393729",
    "end": "1396669"
  },
  {
    "text": "is starting to freak out we could",
    "start": "1396669",
    "end": "1398169"
  },
  {
    "text": "probably do better with these",
    "start": "1398169",
    "end": "1399249"
  },
  {
    "text": "demonstrates so what we did was we",
    "start": "1399249",
    "end": "1401739"
  },
  {
    "text": "co-located these with the device plug-in",
    "start": "1401739",
    "end": "1403989"
  },
  {
    "text": "and that seemed to work for us but of",
    "start": "1403989",
    "end": "1405940"
  },
  {
    "text": "course now NVIDIA has the GP operator so",
    "start": "1405940",
    "end": "1408190"
  },
  {
    "text": "that takes away the pain of deploying",
    "start": "1408190",
    "end": "1410289"
  },
  {
    "text": "the Devon sets so thank you and media",
    "start": "1410289",
    "end": "1412029"
  },
  {
    "text": "there now we would like to thank you all",
    "start": "1412029",
    "end": "1414759"
  },
  {
    "text": "for coming to this talk and we hope that",
    "start": "1414759",
    "end": "1416469"
  },
  {
    "text": "our experience was interesting to you",
    "start": "1416469",
    "end": "1418239"
  },
  {
    "text": "and you find you have learned something",
    "start": "1418239",
    "end": "1420279"
  },
  {
    "text": "from our experience now I would like to",
    "start": "1420279",
    "end": "1423009"
  },
  {
    "text": "take questions but before I open the",
    "start": "1423009",
    "end": "1424779"
  },
  {
    "text": "floor for that I would like to let you",
    "start": "1424779",
    "end": "1426459"
  },
  {
    "text": "know that we are hiring for AI team and",
    "start": "1426459",
    "end": "1429249"
  },
  {
    "text": "we have two open positions one is data",
    "start": "1429249",
    "end": "1431409"
  },
  {
    "text": "engineer and other one is machine",
    "start": "1431409",
    "end": "1433059"
  },
  {
    "text": "learning engineer Martin and myself",
    "start": "1433059",
    "end": "1435639"
  },
  {
    "text": "would be hanging around for rest of the",
    "start": "1435639",
    "end": "1437469"
  },
  {
    "text": "day so please come and find us we also",
    "start": "1437469",
    "end": "1439449"
  },
  {
    "text": "have Mike with us from our team he is",
    "start": "1439449",
    "end": "1442329"
  },
  {
    "text": "sitting somewhere please wave out Mike",
    "start": "1442329",
    "end": "1444849"
  },
  {
    "text": "so you can he's out back there you can",
    "start": "1444849",
    "end": "1447699"
  },
  {
    "text": "find him as well now back to being nice",
    "start": "1447699",
    "end": "1451419"
  },
  {
    "text": "and opening floor for questions thank",
    "start": "1451419",
    "end": "1456579"
  },
  {
    "text": "you",
    "start": "1456579",
    "end": "1458789"
  },
  {
    "text": "[Applause]",
    "start": "1459620",
    "end": "1463900"
  },
  {
    "text": "we have we have 100 on that side",
    "start": "1464049",
    "end": "1468639"
  },
  {
    "text": "hey I have a question on the CPU sharing",
    "start": "1472270",
    "end": "1476050"
  },
  {
    "text": "you mentioned you call solution from",
    "start": "1476050",
    "end": "1478600"
  },
  {
    "text": "Alibaba on GPU isolation is scheduling",
    "start": "1478600",
    "end": "1483150"
  },
  {
    "text": "did you try that it is working or why",
    "start": "1483150",
    "end": "1486670"
  },
  {
    "text": "it's not working for you and was working",
    "start": "1486670",
    "end": "1488560"
  },
  {
    "text": "for some people yep sure so I could talk",
    "start": "1488560",
    "end": "1492580"
  },
  {
    "text": "about that so the way the Alibaba clouds",
    "start": "1492580",
    "end": "1496360"
  },
  {
    "text": "GPU expander works is is pretty much you",
    "start": "1496360",
    "end": "1499270"
  },
  {
    "text": "know the total memory of you GPU and",
    "start": "1499270",
    "end": "1502410"
  },
  {
    "text": "then you extend the Kuban it is a",
    "start": "1502410",
    "end": "1504850"
  },
  {
    "text": "jeweler to expose the GPU memory has a",
    "start": "1504850",
    "end": "1507910"
  },
  {
    "text": "resource you know how you expose memory",
    "start": "1507910",
    "end": "1510220"
  },
  {
    "text": "or CPU and you sort of say that I only",
    "start": "1510220",
    "end": "1512590"
  },
  {
    "text": "want one CPU for this part and only give",
    "start": "1512590",
    "end": "1515320"
  },
  {
    "text": "me that in the similar semantics you",
    "start": "1515320",
    "end": "1517390"
  },
  {
    "text": "would say that I only want say 400 and",
    "start": "1517390",
    "end": "1520600"
  },
  {
    "text": "they are all or one third of a memory",
    "start": "1520600",
    "end": "1524590"
  },
  {
    "text": "from the GPU and semantics like this and",
    "start": "1524590",
    "end": "1527500"
  },
  {
    "text": "you would expose like that under a",
    "start": "1527500",
    "end": "1529210"
  },
  {
    "text": "certain key and you deploy your parts",
    "start": "1529210",
    "end": "1531310"
  },
  {
    "text": "but fundamentally the GPU like Nvidia",
    "start": "1531310",
    "end": "1535030"
  },
  {
    "text": "itself doesn't guarantee isolation on",
    "start": "1535030",
    "end": "1537640"
  },
  {
    "text": "your GPU so you can take one GPU and",
    "start": "1537640",
    "end": "1539920"
  },
  {
    "text": "slice the memory and and and use your",
    "start": "1539920",
    "end": "1543520"
  },
  {
    "text": "workload but it's not guaranteed that",
    "start": "1543520",
    "end": "1545860"
  },
  {
    "text": "you will not step over and consume any",
    "start": "1545860",
    "end": "1548410"
  },
  {
    "text": "more memory if your workload start to",
    "start": "1548410",
    "end": "1550540"
  },
  {
    "text": "spike up and use more memory and similar",
    "start": "1550540",
    "end": "1553810"
  },
  {
    "text": "to the attempt that we had one the same",
    "start": "1553810",
    "end": "1556030"
  },
  {
    "text": "problem exists in attempt to there is no",
    "start": "1556030",
    "end": "1557890"
  },
  {
    "text": "isolation guarantee so even if you are",
    "start": "1557890",
    "end": "1559720"
  },
  {
    "text": "asking for half of memory you are not",
    "start": "1559720",
    "end": "1562360"
  },
  {
    "text": "quite guaranteed to get it and that's",
    "start": "1562360",
    "end": "1564400"
  },
  {
    "text": "the problem that we had running in the",
    "start": "1564400",
    "end": "1566560"
  },
  {
    "text": "temptu because like I said before my",
    "start": "1566560",
    "end": "1568780"
  },
  {
    "text": "solution isn't quite guaranteed from",
    "start": "1568780",
    "end": "1571330"
  },
  {
    "text": "from the GPU providers itself there are",
    "start": "1571330",
    "end": "1574870"
  },
  {
    "text": "security and isolation concerns to start",
    "start": "1574870",
    "end": "1577000"
  },
  {
    "text": "with and if you read up their design",
    "start": "1577000",
    "end": "1578680"
  },
  {
    "text": "document alibaba clouds they are very",
    "start": "1578680",
    "end": "1580660"
  },
  {
    "text": "clear in saying that it's not guaranteed",
    "start": "1580660",
    "end": "1582460"
  },
  {
    "text": "it works for some cases like if you are",
    "start": "1582460",
    "end": "1584560"
  },
  {
    "text": "running very small load with GPU and you",
    "start": "1584560",
    "end": "1587530"
  },
  {
    "text": "kind of guarantee the same throughput",
    "start": "1587530",
    "end": "1589390"
  },
  {
    "text": "with your workload then it would work",
    "start": "1589390",
    "end": "1591190"
  },
  {
    "text": "but we run quite heavy image processing",
    "start": "1591190",
    "end": "1594460"
  },
  {
    "text": "and deep learning workload and we do",
    "start": "1594460",
    "end": "1596860"
  },
  {
    "text": "spike on GPU a lot and that's why it",
    "start": "1596860",
    "end": "1599230"
  },
  {
    "text": "doesn't quite work well for us I hope",
    "start": "1599230",
    "end": "1601570"
  },
  {
    "text": "that answers your question",
    "start": "1601570",
    "end": "1604289"
  },
  {
    "text": "thanks for the great talk that's really",
    "start": "1621700",
    "end": "1623380"
  },
  {
    "text": "interesting stuff you did mention coop",
    "start": "1623380",
    "end": "1625870"
  },
  {
    "text": "flow I go pachyderm",
    "start": "1625870",
    "end": "1628420"
  },
  {
    "text": "I'd be interested in what your thoughts",
    "start": "1628420",
    "end": "1629950"
  },
  {
    "text": "are on something like coop flow serving",
    "start": "1629950",
    "end": "1632470"
  },
  {
    "text": "and how they're going about auto scaling",
    "start": "1632470",
    "end": "1634900"
  },
  {
    "text": "inferencing great questions so I have to",
    "start": "1634900",
    "end": "1641200"
  },
  {
    "text": "start with the notion that by the time",
    "start": "1641200",
    "end": "1643720"
  },
  {
    "text": "we like you know when we started",
    "start": "1643720",
    "end": "1645760"
  },
  {
    "text": "thinking about KF serving and Q flow",
    "start": "1645760",
    "end": "1648160"
  },
  {
    "text": "serving was still evolving we already",
    "start": "1648160",
    "end": "1650470"
  },
  {
    "text": "had this solution running and producing",
    "start": "1650470",
    "end": "1653440"
  },
  {
    "text": "at scale we are talking about running",
    "start": "1653440",
    "end": "1655660"
  },
  {
    "text": "over a million kilometres choir back in",
    "start": "1655660",
    "end": "1657610"
  },
  {
    "text": "February March timeframe so that time we",
    "start": "1657610",
    "end": "1660580"
  },
  {
    "text": "already had solution running at scale",
    "start": "1660580",
    "end": "1662290"
  },
  {
    "text": "and doing the things that we are talking",
    "start": "1662290",
    "end": "1663790"
  },
  {
    "text": "about and at that time these tools were",
    "start": "1663790",
    "end": "1665950"
  },
  {
    "text": "not evolve not evolved yet like you know",
    "start": "1665950",
    "end": "1668320"
  },
  {
    "text": "Q flow is is not quite production ready",
    "start": "1668320",
    "end": "1670750"
  },
  {
    "text": "yet we are talking about January for",
    "start": "1670750",
    "end": "1672370"
  },
  {
    "text": "that to be production ready and like you",
    "start": "1672370",
    "end": "1675160"
  },
  {
    "text": "looking at the scale of things we are",
    "start": "1675160",
    "end": "1676570"
  },
  {
    "text": "doing we are doing you you would want it",
    "start": "1676570",
    "end": "1679030"
  },
  {
    "text": "to be production ready and really have",
    "start": "1679030",
    "end": "1681250"
  },
  {
    "text": "past the stretch stress test that wasn't",
    "start": "1681250",
    "end": "1683800"
  },
  {
    "text": "quite done for us and these are great",
    "start": "1683800",
    "end": "1686320"
  },
  {
    "text": "tool like I I am all for Q flow k of",
    "start": "1686320",
    "end": "1689080"
  },
  {
    "text": "serving sounds really great great and",
    "start": "1689080",
    "end": "1690850"
  },
  {
    "text": "the the fundamental idea of Q flow",
    "start": "1690850",
    "end": "1693850"
  },
  {
    "text": "taking away the like bringing in the",
    "start": "1693850",
    "end": "1696010"
  },
  {
    "text": "abstraction our workload is great and we",
    "start": "1696010",
    "end": "1698110"
  },
  {
    "text": "are we are all behind it but it just",
    "start": "1698110",
    "end": "1700300"
  },
  {
    "text": "didn't do the things when we wanted for",
    "start": "1700300",
    "end": "1702940"
  },
  {
    "text": "us so we are definitely evaluating it",
    "start": "1702940",
    "end": "1704920"
  },
  {
    "text": "I'm not ruling that out as such but this",
    "start": "1704920",
    "end": "1708070"
  },
  {
    "text": "is what we did when solutions weren't",
    "start": "1708070",
    "end": "1709750"
  },
  {
    "text": "available thank you everybody",
    "start": "1709750",
    "end": "1716480"
  },
  {
    "text": "[Applause]",
    "start": "1716480",
    "end": "1721289"
  }
]
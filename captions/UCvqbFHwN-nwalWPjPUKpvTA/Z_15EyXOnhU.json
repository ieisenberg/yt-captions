[
  {
    "text": "so welcome to this update session of the",
    "start": "600",
    "end": "5920"
  },
  {
    "text": "working group device management in Kubernetes also known as what the heck",
    "start": "5920",
    "end": "12559"
  },
  {
    "text": "is going on with DRA nowadays Um my name is Patrick Oie I'm",
    "start": "12559",
    "end": "19119"
  },
  {
    "text": "one of the co-chairs of this working group And the reason why I am in that",
    "start": "19119",
    "end": "25199"
  },
  {
    "text": "role is because I started kind of DRA in Kubernetes along with a few other folks long before it became a working",
    "start": "25199",
    "end": "32520"
  },
  {
    "text": "group Um I'm I'm Kevin Clues I was also one of the people that started working",
    "start": "32520",
    "end": "37600"
  },
  {
    "text": "on it way early on Um and I just want to reiterate for those that um are here",
    "start": "37600",
    "end": "43200"
  },
  {
    "text": "that this is this really is an update on what's going on in the working group If you're here to learn about the details",
    "start": "43200",
    "end": "49039"
  },
  {
    "text": "of DRRA and how it works under the hood and things like that come talk to us afterwards because we're not going to",
    "start": "49039",
    "end": "54320"
  },
  {
    "text": "give a primer on that in this in this talk So and and the third person who is",
    "start": "54320",
    "end": "59520"
  },
  {
    "text": "not on the stage today because we are the official presenters is John Bellame He's also here We can discuss anything",
    "start": "59520",
    "end": "66159"
  },
  {
    "text": "what comes up afterwards in the hallway track So the three of us we are organizing the working group It started",
    "start": "66159",
    "end": "74159"
  },
  {
    "text": "out as an effort to have a more formal uh way of of driving dynamic resource",
    "start": "74159",
    "end": "81200"
  },
  {
    "text": "allocation forward and uh that was the main focus but it's not the only thing So overall our mission statement is to",
    "start": "81200",
    "end": "88960"
  },
  {
    "text": "enable simple and efficient configuration sharing and allocation of",
    "start": "88960",
    "end": "94000"
  },
  {
    "text": "accelerators and other specialized devices So it it formed around GPUs but it's certainly not limited to that We",
    "start": "94000",
    "end": "101840"
  },
  {
    "text": "started the working group uh after CubeCon Europe almost almost a year ago",
    "start": "101840",
    "end": "108159"
  },
  {
    "text": "because at that time interest really picked up and we figured that the the smaller team that had been working on it",
    "start": "108159",
    "end": "114399"
  },
  {
    "text": "definitely needed to reach out to lots of different SIGs across Kubernetes The",
    "start": "114399",
    "end": "119840"
  },
  {
    "text": "work that we've been doing affects overall Kubernetes architecture autoscaling networking node uh",
    "start": "119840",
    "end": "128399"
  },
  {
    "text": "interaction on the on with devices and and to a large extent also scheduling",
    "start": "128399",
    "end": "134000"
  },
  {
    "text": "decisions So these six then decided to sponsor the working group We set up",
    "start": "134000",
    "end": "139200"
  },
  {
    "text": "regular meetings and yeah that's what we've been doing ever since We're trying to figure out how Kubernet is going",
    "start": "139200",
    "end": "146080"
  },
  {
    "text": "forward can get out of or well get go beyond its original roots as as a service for mic as a management system",
    "start": "146080",
    "end": "152400"
  },
  {
    "text": "for microservices towards what we all do today like running AI inference perhaps",
    "start": "152400",
    "end": "157599"
  },
  {
    "text": "AI training and also figure out how to handle all the other hardware that traditionally has been perhaps not so",
    "start": "157599",
    "end": "163920"
  },
  {
    "text": "well supported in Kubernetes So as I said this is mostly",
    "start": "163920",
    "end": "169360"
  },
  {
    "text": "about dynamic resource allocation at the moment If I had to explain it uh to",
    "start": "169360",
    "end": "174879"
  },
  {
    "text": "someone who hasn't seen anything about it yet it's probably best to mention the four key parts The first is it's a new",
    "start": "174879",
    "end": "183239"
  },
  {
    "text": "API U the part that is relevant for the drivers is that they are publishing a",
    "start": "183239",
    "end": "190599"
  },
  {
    "text": "more complete description of the hardware that is available on a node in a so-called resource slice It's a fixed",
    "start": "190599",
    "end": "198239"
  },
  {
    "text": "list of devices each device with certain attributes And this could be the vendor",
    "start": "198239",
    "end": "204879"
  },
  {
    "text": "a product ID amount of GPU RAM that is available if you have this uh device",
    "start": "204879",
    "end": "211519"
  },
  {
    "text": "mapped into your container or how many compute nodes it has And then with that",
    "start": "211519",
    "end": "217480"
  },
  {
    "text": "information users can define their requirements in a much more flexible",
    "start": "217480",
    "end": "223080"
  },
  {
    "text": "format With another new API uh type the resource",
    "start": "223080",
    "end": "228760"
  },
  {
    "text": "claim in a resource claim a standalone object you can specify which attributes",
    "start": "228760",
    "end": "235440"
  },
  {
    "text": "your desired device must have It typically references or it must reference a device class So you kind of",
    "start": "235440",
    "end": "242319"
  },
  {
    "text": "know that you're dealing with a certain vendor at this point And you can use attributes defined for",
    "start": "242319",
    "end": "248480"
  },
  {
    "text": "by this vendor to really get exactly what you need You can also have bit more",
    "start": "248480",
    "end": "254000"
  },
  {
    "text": "flexibility You can say I need at least a certain amount of memory but I'm okay if I get more Um we have cell",
    "start": "254000",
    "end": "260799"
  },
  {
    "text": "expressions in that resource claim to express that So a lot of flexibility and also",
    "start": "260799",
    "end": "267680"
  },
  {
    "text": "because it's a separate object we have control sharing You set up your workload exactly the way you want it Different",
    "start": "267680",
    "end": "274880"
  },
  {
    "text": "ports can share the same resource claim and they all get the same hardware instance at runtime and you can also",
    "start": "274880",
    "end": "281919"
  },
  {
    "text": "select inside the pot which containers share the same hardware To make that possible we",
    "start": "281919",
    "end": "289440"
  },
  {
    "text": "updated then the scheduleuler It basically looks at these requests and matches against the available hardware",
    "start": "289440",
    "end": "295600"
  },
  {
    "text": "and sends it all off to cublet One of the key changes that we did to get to",
    "start": "295600",
    "end": "301120"
  },
  {
    "text": "where we are is that we moved all the logic into the scheduleuler and that's a key change to",
    "start": "301120",
    "end": "307280"
  },
  {
    "text": "the original design uh and that that basically unblocked us from going to beta as you will see soon It's called",
    "start": "307280",
    "end": "314320"
  },
  {
    "text": "structured parameters because it's a structured format of a device description that is expressive enough to",
    "start": "314320",
    "end": "319360"
  },
  {
    "text": "do logical conclusions and simulations on top of it And then at the end of the",
    "start": "319360",
    "end": "324960"
  },
  {
    "text": "pipe once we have scheduled a port the cublet is working with a driver that",
    "start": "324960",
    "end": "331199"
  },
  {
    "text": "needs to be run on needs to run on the node uh like a like a like a device plugin except that it's now a different",
    "start": "331199",
    "end": "336720"
  },
  {
    "text": "API uh that then sets up the hardware makes it available in",
    "start": "336720",
    "end": "344280"
  },
  {
    "text": "containers and this is worth repeating we had the same message up in uh north",
    "start": "344280",
    "end": "350000"
  },
  {
    "text": "cube North America we reached beta in 132 It was breaking news uh six",
    "start": "350000",
    "end": "357840"
  },
  {
    "text": "months ago or few half a year ago It's still important We are now a bit closer",
    "start": "357840",
    "end": "363120"
  },
  {
    "text": "to G but this is still the the message that we are sending out to the audience DRA is here to stay We are moving",
    "start": "363120",
    "end": "369919"
  },
  {
    "text": "forward and we are extending it We have not certainly not uh rested",
    "start": "369919",
    "end": "377600"
  },
  {
    "text": "much since uh the time that we moved to beta did a lot of things and we are",
    "start": "377600",
    "end": "382960"
  },
  {
    "text": "branching out So a lot of the new features that have been worked on are now being worked on by other",
    "start": "382960",
    "end": "389520"
  },
  {
    "text": "contributors other people who got involved as part of forming this working group Um for",
    "start": "389520",
    "end": "397639"
  },
  {
    "text": "133 we uh moved one feature forward to beta together with with core feature",
    "start": "397639",
    "end": "405280"
  },
  {
    "text": "that is the uh driver own resource claim status that is something that is relevant for network devices because",
    "start": "405280",
    "end": "411280"
  },
  {
    "text": "they need to publish IP address information Then an important feature",
    "start": "411280",
    "end": "417120"
  },
  {
    "text": "that we missed earlier is partitionable devices So I mentioned that the resource",
    "start": "417120",
    "end": "423199"
  },
  {
    "text": "slice lists a fixed set of devices um but they are all independent With",
    "start": "423199",
    "end": "430319"
  },
  {
    "text": "partitionable devices we can have overlapping hardware in a sense that we",
    "start": "430319",
    "end": "435360"
  },
  {
    "text": "define some partitions but if you pick one partition something else might become unusable because it needs the",
    "start": "435360",
    "end": "441919"
  },
  {
    "text": "same underlying resources in in the one GPU that you have and that is",
    "start": "441919",
    "end": "447120"
  },
  {
    "text": "partitionable devices So that that got added as alpha device",
    "start": "447120",
    "end": "453280"
  },
  {
    "text": "taints and tolerations It's a management feature If uh you are familiar with node",
    "start": "453280",
    "end": "458720"
  },
  {
    "text": "tains that's exactly the same concept except that you don't need to taint the entire node Uh you can just say this",
    "start": "458720",
    "end": "466240"
  },
  {
    "text": "this particular device is unhealthy or I'm taking it down for maintenance And the effect then is that it's not getting",
    "start": "466240",
    "end": "473120"
  },
  {
    "text": "used for new scheduled parts and parts that are running running can be",
    "start": "473120",
    "end": "480560"
  },
  {
    "text": "evicted Then I mentioned resource claims The the next list the thing is",
    "start": "481000",
    "end": "487120"
  },
  {
    "text": "prioritized alternatives in device requests That is a way to express your intent",
    "start": "487120",
    "end": "493000"
  },
  {
    "text": "that from say a list of requests any of them is okay for your part You could say",
    "start": "493000",
    "end": "500240"
  },
  {
    "text": "I I want something from vendor A If I can't get that I'm fine with a device from vendor B or I'm taking N or this or",
    "start": "500240",
    "end": "509199"
  },
  {
    "text": "M of that And then the scheduleuler basically will look at what is available and try to satisfy one of these",
    "start": "509199",
    "end": "515080"
  },
  {
    "text": "requests So it's a it's a bit more flexibility basically that we're offering It's all entirely implemented in",
    "start": "515080",
    "end": "521240"
  },
  {
    "text": "theuler Um finally admin access that was a thing that we had earlier It's a mode",
    "start": "521240",
    "end": "527959"
  },
  {
    "text": "where some privileged user can say I want this device or this set of devices",
    "start": "527959",
    "end": "534080"
  },
  {
    "text": "all devices on a node in my container and I want them even if they are currently in use by a normal user So",
    "start": "534080",
    "end": "541040"
  },
  {
    "text": "yeah they are in production use but you want to monitor something and an admin can say okay give me all of them and I do something that is not intrusive",
    "start": "541040",
    "end": "547519"
  },
  {
    "text": "that's a privileged operation because you could also break the the workload So we added something in 133 that is a",
    "start": "547519",
    "end": "554560"
  },
  {
    "text": "standardized label that needs to be set in a namespace otherwise you can't",
    "start": "554560",
    "end": "559600"
  },
  {
    "text": "create resource claims using that privileged mode Previously it had to be added to a cluster with validation",
    "start": "559600",
    "end": "566240"
  },
  {
    "text": "admission policy Now it's built into Kubernetes and secure out of the box It needs to be enabled",
    "start": "566240",
    "end": "573200"
  },
  {
    "text": "And last but not least we worked on the core cub core DRA to move it closer to",
    "start": "573200",
    "end": "580360"
  },
  {
    "text": "GA Uh we do we are doing another v1 beta 2 to simplify the API Some structural",
    "start": "580360",
    "end": "587920"
  },
  {
    "text": "changes that make it a bit simpler easier to promote to GA Um but V1 beta 1",
    "start": "587920",
    "end": "595279"
  },
  {
    "text": "is also still available So both both continue to coexist Both are interoperable",
    "start": "595279",
    "end": "601080"
  },
  {
    "text": "Then um small change perhaps but relevant if it gets up picked up in downstream Kubernetes distributions",
    "start": "601080",
    "end": "607200"
  },
  {
    "text": "There are now predefined arbug rules and something that goes into the reliability",
    "start": "607200",
    "end": "612880"
  },
  {
    "text": "aspect of DRA If you have a demon set that run that deploys your driver you",
    "start": "612880",
    "end": "619120"
  },
  {
    "text": "can now enable rolling update where two containers of your driver run in",
    "start": "619120",
    "end": "624399"
  },
  {
    "text": "parallel That's a first for for Cuplet plugins It wasn't supported before you",
    "start": "624399",
    "end": "629440"
  },
  {
    "text": "had to take down your container bring up the next one and then it takes over But there's always a certain amount of",
    "start": "629440",
    "end": "635600"
  },
  {
    "text": "downtime in between With this seamless upgrade mode the cublet is intelligent",
    "start": "635600",
    "end": "640640"
  },
  {
    "text": "enough to see to register two instances for the same driver and then talk to any of them And it it's it's seamless as the",
    "start": "640640",
    "end": "647839"
  },
  {
    "text": "as the name implies So here's a here's a very long list As I said we are now moving the",
    "start": "647839",
    "end": "655200"
  },
  {
    "text": "core thing forward but we are branching out We are adding features on top of DRA",
    "start": "655200",
    "end": "663839"
  },
  {
    "text": "to enable additional use cases and those are all under a separate feature gate",
    "start": "663839",
    "end": "670480"
  },
  {
    "text": "That means we don't need to block the core DRA from going to G We are just",
    "start": "670480",
    "end": "677200"
  },
  {
    "text": "doing these other things on on the on the side in a sense Um so I mentioned",
    "start": "677200",
    "end": "682560"
  },
  {
    "text": "already GA4 core DRA we hope to do that in 134",
    "start": "682560",
    "end": "688800"
  },
  {
    "text": "um together with claim status because that does really doesn't need much more work and then the other features that we",
    "start": "688800",
    "end": "694720"
  },
  {
    "text": "just added as alpha in 133 hopefully can promote can get to to beta in the next",
    "start": "694720",
    "end": "700000"
  },
  {
    "text": "cycle We need to look at the beta criteria but there's there's I know no",
    "start": "700000",
    "end": "705040"
  },
  {
    "text": "reason why we shouldn't So all all of those are smaller features that we can move forward with just one release uh uh",
    "start": "705040",
    "end": "713440"
  },
  {
    "text": "difference between alpha beta and and GA One one thing important to note there is",
    "start": "713440",
    "end": "719120"
  },
  {
    "text": "that these new features even though they're in alpha and they'll move to beta once DRRA itself goes GA these beta",
    "start": "719120",
    "end": "726160"
  },
  {
    "text": "features will be turned on by default which hasn't been true for for uh DRA in general because there's a um there's an",
    "start": "726160",
    "end": "732959"
  },
  {
    "text": "API group that's been associated with it and those aren't allowed to be on by default when you're beta but once DRA",
    "start": "732959",
    "end": "739600"
  },
  {
    "text": "feature itself goes GA all these sub features uh can be turned on by default once they're in beta you have to wait",
    "start": "739600",
    "end": "745920"
  },
  {
    "text": "for it to be in G to use it So let me call out a few things Not",
    "start": "745920",
    "end": "751279"
  },
  {
    "text": "everything Uh some some of these things didn't quite make it Uh the partitionable devices kept for example",
    "start": "751279",
    "end": "758240"
  },
  {
    "text": "had an aspect that was called mixins that reuses uh a set of attributes We",
    "start": "758240",
    "end": "763760"
  },
  {
    "text": "had to take that out to simplify the implementation It will now become a separate cap That's relevant if you're",
    "start": "763760",
    "end": "769760"
  },
  {
    "text": "trying to publish lots of devices in a resource At some point the object might become too large So we have limits on",
    "start": "769760",
    "end": "776160"
  },
  {
    "text": "how many attributes you can have per device and mixins helps a little bit to make it more compact and and more",
    "start": "776160",
    "end": "781920"
  },
  {
    "text": "efficient more efficient So that that got taken out You might have also seen something that was called admin",
    "start": "781920",
    "end": "788720"
  },
  {
    "text": "controlled device attributes Um that was my other half of the work that I was doing for 133 and we took it out because",
    "start": "788720",
    "end": "794639"
  },
  {
    "text": "it wasn't that important and the API was a bit controversial It was the basis for",
    "start": "794639",
    "end": "800079"
  },
  {
    "text": "device tains Um but we then separated the two and this is now pending in a",
    "start": "800079",
    "end": "806800"
  },
  {
    "text": "sense Um it would have allowed admins to add attributes to a device without changing the DR driver but it's on hold",
    "start": "806800",
    "end": "814959"
  },
  {
    "text": "We basically need your feedback if you find this useful to figure out how to prioritize",
    "start": "814959",
    "end": "821959"
  },
  {
    "text": "Um partitionable devices is one way to split up hardware but there's also",
    "start": "821959",
    "end": "827120"
  },
  {
    "text": "people who want to really have just one device that can hand out chunks of something Um it's mostly network",
    "start": "827120",
    "end": "833920"
  },
  {
    "text": "hardware guaranteed bandwidth for example that can be assigned to certain",
    "start": "833920",
    "end": "839839"
  },
  {
    "text": "ports that then get a fraction of a guaranteed bandwidth That is the consumable capacity cap and that is also",
    "start": "839839",
    "end": "847920"
  },
  {
    "text": "that has been in discussion for the last cycle It looks good to move that into",
    "start": "847920",
    "end": "853880"
  },
  {
    "text": "133 14 uh 134 as a as an alpha and and",
    "start": "853880",
    "end": "859199"
  },
  {
    "text": "there are others So this is really what we are discussing in the working group You're welcome to check out all these",
    "start": "859199",
    "end": "864880"
  },
  {
    "text": "links when you get the slides from the schedule and find more information about these individual things",
    "start": "864880",
    "end": "872800"
  },
  {
    "text": "Then we are also organizing with fellow travelers work that is not directly tied",
    "start": "872800",
    "end": "879199"
  },
  {
    "text": "to a cap or directly tied to Kubernetes There are some outofree efforts that need to happen to make the array useful",
    "start": "879199",
    "end": "886480"
  },
  {
    "text": "Um mostly in other scheduulers perhaps um autoscalers carpenter it's not all",
    "start": "886480",
    "end": "893199"
  },
  {
    "text": "listed here but there are some things that we are just really discussing Um also higher level app controllers uh",
    "start": "893199",
    "end": "901440"
  },
  {
    "text": "we currently generate a resource claim for one port at a time uh with a from a",
    "start": "901440",
    "end": "909360"
  },
  {
    "text": "resource claim template But then if you have a set of pots that might have to",
    "start": "909360",
    "end": "914399"
  },
  {
    "text": "share a single resource claim because it sets up something for the entire set of ports then we need control or support in",
    "start": "914399",
    "end": "921600"
  },
  {
    "text": "in these job controllers So we're discussing that And here's also a list of drivers",
    "start": "921600",
    "end": "928959"
  },
  {
    "text": "uh that currently support DRA Um at some point we might have to think where we want to list those",
    "start": "928959",
    "end": "935279"
  },
  {
    "text": "because I I already know that there are some that are not on our list yet Uh so",
    "start": "935279",
    "end": "940320"
  },
  {
    "text": "the list keeps growing If you are starting with DRA the example driver",
    "start": "940320",
    "end": "946680"
  },
  {
    "text": "that we don't even have here on the list is a good starting point So we",
    "start": "946680",
    "end": "952639"
  },
  {
    "text": "maintain one example driver uh that is more or less realistic You can basically just copy and paste the",
    "start": "952639",
    "end": "959199"
  },
  {
    "text": "entire code fork it and then implement your vendor logic in it It's also a good",
    "start": "959199",
    "end": "964560"
  },
  {
    "text": "demonstration tool So one of the changes that I haven't even mentioned we now have readily available container images",
    "start": "964560",
    "end": "970800"
  },
  {
    "text": "for it We're going to update the Kubernetes uh documentation so that you have a JAMAL file that you can just",
    "start": "970800",
    "end": "976959"
  },
  {
    "text": "deploy against the kind cluster and you bring up the DRA example driver for example and can play with it as a user",
    "start": "976959",
    "end": "983839"
  },
  {
    "text": "That's one of the things and another thing um yeah getting",
    "start": "983839",
    "end": "988880"
  },
  {
    "text": "involved I mentioned it we have active discussions in the working group on Slack uh you're welcome to join us worth",
    "start": "988880",
    "end": "996560"
  },
  {
    "text": "calling out is that we now have also a session on Wednesdays that is more uh",
    "start": "996560",
    "end": "1002320"
  },
  {
    "text": "Asia friendly it's a or early morning European time we didn't have that initially but people were just showing",
    "start": "1002320",
    "end": "1008079"
  },
  {
    "text": "up at for at at 1:00 a.m air time and that's just not acceptable I don't want",
    "start": "1008079",
    "end": "1013199"
  },
  {
    "text": "anyone to do that So we are now running two sessions alternatingly in in different time zones or time",
    "start": "1013199",
    "end": "1018920"
  },
  {
    "text": "slots and yeah we haven't done that before We should have a shout out to our",
    "start": "1018920",
    "end": "1025678"
  },
  {
    "text": "new contributors I've mentioned that these some of these features were implemented by other people Let's give them a clap of hands perhaps whether",
    "start": "1025679",
    "end": "1032000"
  },
  {
    "text": "they are in the room Morton is here Um Rita did some work on admin mode taking",
    "start": "1032000",
    "end": "1038640"
  },
  {
    "text": "over basically from me with the Rback permissions Shingo he he he made very good proposals for the device chains and",
    "start": "1038640",
    "end": "1045280"
  },
  {
    "text": "I'm happy to get those suggestions It wasn't even a code contribution in that sense Uh it really was just an idea and",
    "start": "1045280",
    "end": "1050960"
  },
  {
    "text": "I picked that up and we both together basically wrote for CAP or defined some of it John Hoon he's not here",
    "start": "1050960",
    "end": "1056559"
  },
  {
    "text": "unfortunately He did lot lot of parts part of the imputation of device ts He's",
    "start": "1056559",
    "end": "1062080"
  },
  {
    "text": "now our maintain Well what happens if you are show up and do good work we give you more work So he's now also our",
    "start": "1062080",
    "end": "1069840"
  },
  {
    "text": "maintainer for the DR example driver that I mentioned And previously what which we hadn't in which we should have",
    "start": "1069840",
    "end": "1076320"
  },
  {
    "text": "had in the last update meeting in in North America Lionel uh and Antonio they stepped up and covered the network side",
    "start": "1076320",
    "end": "1083120"
  },
  {
    "text": "of of DRA So thanks to everyone And with that up to you Oh",
    "start": "1083120",
    "end": "1091480"
  },
  {
    "text": "Oh yeah we had CC she well we had we had to shuffle around work a bit I sorry I I",
    "start": "1093200",
    "end": "1099679"
  },
  {
    "text": "forgot I we had other people jump in and and really help us out and it just s my",
    "start": "1099679",
    "end": "1106679"
  },
  {
    "text": "mind You know this is again something for future reference Lot of talks at",
    "start": "1106679",
    "end": "1111760"
  },
  {
    "text": "this cube con some some some talks from people that I just mentioned they already happened it's too late for you",
    "start": "1111760",
    "end": "1117280"
  },
  {
    "text": "to watch them live but you perhaps you want to go back and and watch the recordings There's one more session to",
    "start": "1117280",
    "end": "1122400"
  },
  {
    "text": "later today that you can still catch in person Um that is um from CERN",
    "start": "1122400",
    "end": "1129480"
  },
  {
    "text": "Diana and that was really the last slide that I had Now up to you Yeah So I'm",
    "start": "1129480",
    "end": "1135280"
  },
  {
    "text": "just going to give a quick update on um how DRRA is being used uh by Nvidia Um",
    "start": "1135280",
    "end": "1143039"
  },
  {
    "text": "if you've been to these sessions before you've been following along what we've been doing um with the model that we had",
    "start": "1143039",
    "end": "1148080"
  },
  {
    "text": "in Kubernetes 130 I wrote this uh document called NVIDIA GPU use cases that that outlined 12 use cases for how",
    "start": "1148080",
    "end": "1154880"
  },
  {
    "text": "we wanted to use DRA um and what we needed to do to improve DRA in order to",
    "start": "1154880",
    "end": "1160080"
  },
  {
    "text": "cover these Uh and with what we added in 130 we were covering half of those um six out of 12 of the use cases Um by 131",
    "start": "1160080",
    "end": "1169039"
  },
  {
    "text": "we were supporting nine of those 12 Uh and I'm happy to say that by 133 which is coming out in a few weeks we're",
    "start": "1169039",
    "end": "1175919"
  },
  {
    "text": "supporting all of the use cases that I had outlined in this document except for one which we'll probably never cover",
    "start": "1175919",
    "end": "1181760"
  },
  {
    "text": "because it's very application specific uh and is is is really hard to ever uh achieve And so um we've made a lot of",
    "start": "1181760",
    "end": "1189200"
  },
  {
    "text": "progress over the last few releases and I'm I'm really happy with uh where we're at now with all of this Um one new use",
    "start": "1189200",
    "end": "1196000"
  },
  {
    "text": "case though that kind of emerged from all of this um was the ability to support um kind of cross- node resources",
    "start": "1196000",
    "end": "1203840"
  },
  {
    "text": "uh in the case of NVIDIA GPUs uh this manifests as what we called a multi-node in VLink And so if those of you that are",
    "start": "1203840",
    "end": "1211520"
  },
  {
    "text": "familiar with the GB200 NVL72 systems uh this is how they're organized There's um",
    "start": "1211520",
    "end": "1218720"
  },
  {
    "text": "18 compute trays that exist in in a rack uh with nine NV switches sitting in the",
    "start": "1218720",
    "end": "1223840"
  },
  {
    "text": "middle And in order to support these use cases uh in our NVIDIA GPU driver we've added this new um uh API server object",
    "start": "1223840",
    "end": "1232400"
  },
  {
    "text": "called a compute domain which behind the scenes if you instantiate one of these will um create a bunch of the uh you",
    "start": "1232400",
    "end": "1240000"
  },
  {
    "text": "know abstractions that are that are needed by DRA in order to allocate and make use of these multi-node and Vlinks",
    "start": "1240000",
    "end": "1246720"
  },
  {
    "text": "in a multi-node environment And so um uh if you see the link that I have here at the bottom uh it's not proper",
    "start": "1246720",
    "end": "1253120"
  },
  {
    "text": "documentation yet We're still working on getting uh a lot of the details put out for people to to learn about but um this",
    "start": "1253120",
    "end": "1260080"
  },
  {
    "text": "is a good starting point if you have access to one of these systems and you want to try this out This outlines the",
    "start": "1260080",
    "end": "1265280"
  },
  {
    "text": "test procedure for what you need to do to install the GPU operator what you need to install our DRRA driver and then",
    "start": "1265280",
    "end": "1272240"
  },
  {
    "text": "how you can run some example workloads that get launched on multiple nodes and make use of these uh high-end VB",
    "start": "1272240",
    "end": "1278799"
  },
  {
    "text": "bandwidth uh connections Um I'll be giving a a demo",
    "start": "1278799",
    "end": "1284000"
  },
  {
    "text": "of this at the Nvidia booth at 4:00 So this talk will end in 10 minutes and then 30 minutes later I'll be at the",
    "start": "1284000",
    "end": "1290159"
  },
  {
    "text": "booth In fact I'll probably walk over to the booth directly after this if people want to just follow me and get a demo of",
    "start": "1290159",
    "end": "1295679"
  },
  {
    "text": "this Um the demo I'm going to show is on a a mini GB200 cluster So as I mentioned",
    "start": "1295679",
    "end": "1301679"
  },
  {
    "text": "there's 18 compute nodes that exist in these clusters For for my for my demo I'm only going to be making use of four",
    "start": "1301679",
    "end": "1307600"
  },
  {
    "text": "of them Um but on those four nodes each of those has four GPUs each which adds up to 16 GPUs total And they have full",
    "start": "1307600",
    "end": "1314559"
  },
  {
    "text": "inv connectivity between all of those GPUs And the the workload that I'll run will be four worker MPI jobs that",
    "start": "1314559",
    "end": "1321600"
  },
  {
    "text": "measure the throughput of reading and writing memory uh between every GPU in that entire mesh And the output that you",
    "start": "1321600",
    "end": "1328640"
  },
  {
    "text": "get from running this demo is what you see at the bottom here Um where you can see that you know all GPUs across all",
    "start": "1328640",
    "end": "1335360"
  },
  {
    "text": "these nodes are communicating at approximately the same the same speed which is unlike what you were able to do",
    "start": "1335360",
    "end": "1341440"
  },
  {
    "text": "up until now on a single node you could have these high bandwidth connections but if you ever went across nodes you had to go over Infiniband or Ethernet",
    "start": "1341440",
    "end": "1348320"
  },
  {
    "text": "and it would be much slower than uh what you get going over in Vlink Um and with that uh we'll take any",
    "start": "1348320",
    "end": "1357039"
  },
  {
    "text": "uh questions This is the QR code to send any feedback on the session And um oh",
    "start": "1357039",
    "end": "1362080"
  },
  {
    "text": "the NVIDIA booth is in the S side of the uh expo hall And if you walk in and you",
    "start": "1362080",
    "end": "1368400"
  },
  {
    "text": "turn right it's all the way at the end near the um uh where you can get your",
    "start": "1368400",
    "end": "1373600"
  },
  {
    "text": "pick your t-shirts up So if anyone wants to follow me after there I'll be giving this demo as I mentioned So yep",
    "start": "1373600",
    "end": "1380180"
  },
  {
    "text": "[Applause]",
    "start": "1380180",
    "end": "1385640"
  },
  {
    "text": "thanks Thank you for the updates My question will be from field perspective",
    "start": "1385640",
    "end": "1391039"
  },
  {
    "text": "Most of my customers hasn't received forget about black well they haven't received the even the hoppers so most of",
    "start": "1391039",
    "end": "1398640"
  },
  {
    "text": "them are on P100 V 100 and lucky ones are still on A100 on Nvidia side on",
    "start": "1398640",
    "end": "1404799"
  },
  {
    "text": "Intel side same problem with the SRO unique cards so for this project are we",
    "start": "1404799",
    "end": "1410480"
  },
  {
    "text": "only looking forward driver support with the new hardware or backward",
    "start": "1410480",
    "end": "1415760"
  },
  {
    "text": "compatibility with the certain hardware which where we are struggling especially with the Nvidia CUDA versions Thank you",
    "start": "1415760",
    "end": "1424640"
  },
  {
    "text": "Sure For in the NVIDIA use case we're we we will support all GPUs that we support",
    "start": "1424640",
    "end": "1432159"
  },
  {
    "text": "even with the standard device plugin So we're not being opinionated about only supporting new hardware with this",
    "start": "1432159",
    "end": "1437480"
  },
  {
    "text": "Obviously for something like the compute domains and the multiode and VLinks you have to have those physical connections",
    "start": "1437480",
    "end": "1442640"
  },
  {
    "text": "between the GPUs but no you can use DRA to allocate T4s L4s A100's K80s whatever",
    "start": "1442640",
    "end": "1449760"
  },
  {
    "text": "you have available It's it's it's indiscriminate because at the under the hood we're just leveraging uh Nvidia's",
    "start": "1449760",
    "end": "1456159"
  },
  {
    "text": "standard um NVML library so their management library to enumerate what capabilities exist in the GPUs and then",
    "start": "1456159",
    "end": "1462720"
  },
  {
    "text": "advertise them in that resource slice object that Patrick talked about And so once that's advertised the mechanics of",
    "start": "1462720",
    "end": "1469120"
  },
  {
    "text": "how those actually get allocated and requested from the user is standard like you would do for any type of device It's",
    "start": "1469120",
    "end": "1474720"
  },
  {
    "text": "not specific to to Nvidia at that point And then I mean you can sp speak to the Intel side Yeah we we also have our DRA",
    "start": "1474720",
    "end": "1482240"
  },
  {
    "text": "drivers for existing hardware and we plan to do more in that space certainly going forward Uh it's currently at the",
    "start": "1482240",
    "end": "1489840"
  },
  {
    "text": "alpha level So we we but we we certainly plan to promote that together with DR and Kubernetes in future products to to",
    "start": "1489840",
    "end": "1496960"
  },
  {
    "text": "product what what we recommend people should be running",
    "start": "1496960",
    "end": "1502039"
  },
  {
    "text": "Uh hello uh I have a quick question about u now we are going to use dr",
    "start": "1502799",
    "end": "1508480"
  },
  {
    "text": "stable what about the device plugin in the future with the kubernetes that's",
    "start": "1508480",
    "end": "1514640"
  },
  {
    "text": "actually a good feature that we have in in the pipeline so the device plugins doesn't go away that was one of our",
    "start": "1514640",
    "end": "1520240"
  },
  {
    "text": "promise to the kubernetes community and the downstream ecosystem that we are not not removing device plug-in",
    "start": "1520240",
    "end": "1526760"
  },
  {
    "text": "support we are offering something new which hopefully you will find compelling and more more attractive",
    "start": "1526760",
    "end": "1532799"
  },
  {
    "text": "But we understand that the extended resource API that people are currently using is important It is sufficient for",
    "start": "1532799",
    "end": "1540480"
  },
  {
    "text": "some use cases And we have one idea one pending cap where we want to map the",
    "start": "1540480",
    "end": "1546559"
  },
  {
    "text": "extended resource request in a container to something that is provided by a DRA",
    "start": "1546559",
    "end": "1551679"
  },
  {
    "text": "driver So for an admin that means they can promote or they can gradually convert the deployment in their cluster",
    "start": "1551679",
    "end": "1557760"
  },
  {
    "text": "from device plugins to a DRA driver and applications don't need to be rewritten They will continue to work as they did",
    "start": "1557760",
    "end": "1564559"
  },
  {
    "text": "before So that is something that is coming in 133 to simplify rollouts Yeah I think the important bit",
    "start": "1564559",
    "end": "1571279"
  },
  {
    "text": "there is that with that in place you only have to deploy the DRA driver but it'll be able to service requests of",
    "start": "1571279",
    "end": "1577360"
  },
  {
    "text": "both types instead of having to figure out how to get the old device plugin and the new DRA driver to work together Okay",
    "start": "1577360",
    "end": "1583919"
  },
  {
    "text": "got it Thank you Thank you",
    "start": "1583919",
    "end": "1588440"
  },
  {
    "text": "Hi Um I was just wondering if uh your working group was uh was talking about",
    "start": "1591120",
    "end": "1597679"
  },
  {
    "text": "support for software based fractionalization of GPUs Is that going",
    "start": "1597679",
    "end": "1602720"
  },
  {
    "text": "to be supported at some point um it is supported to some degree already Um and",
    "start": "1602720",
    "end": "1608880"
  },
  {
    "text": "what we we so there's this um abstraction at least for Nvidia GPUs called MPS I don't know if you're",
    "start": "1608880",
    "end": "1614960"
  },
  {
    "text": "familiar with that Yeah Um it's a it's something that you can layer on top of",
    "start": "1614960",
    "end": "1620159"
  },
  {
    "text": "the allocation for GPUs Um and it runs as a separate service and without going",
    "start": "1620159",
    "end": "1625600"
  },
  {
    "text": "into the details of it it lets you basically say for any given uh workload that you start you would point them all",
    "start": "1625600",
    "end": "1632240"
  },
  {
    "text": "at the same underlying physical GPU but you can decide in a cooperative way how",
    "start": "1632240",
    "end": "1637760"
  },
  {
    "text": "much memory each of those clients actually has access to And it's completely fungeible like you can pick",
    "start": "1637760",
    "end": "1643360"
  },
  {
    "text": "up to the megabyte I think how much memory you want for each of them across the thing And so we could talk about the",
    "start": "1643360",
    "end": "1648640"
  },
  {
    "text": "details of it later And we do have some documentation on this and there there's examples in the NVIDIA uh DRA driver",
    "start": "1648640",
    "end": "1654400"
  },
  {
    "text": "repo for for how to do this Cool",
    "start": "1654400",
    "end": "1659000"
  },
  {
    "text": "Hello Uh so I was just wondering if there is anything that changes in terms",
    "start": "1662279",
    "end": "1667600"
  },
  {
    "text": "of monitoring the devices in your cluster So before we were using Nvidia",
    "start": "1667600",
    "end": "1673120"
  },
  {
    "text": "DCGM now anything changes with a new DRA driver or it will work as it was working before",
    "start": "1673120",
    "end": "1679679"
  },
  {
    "text": "Uh DCGM hasn't been updated to be aware of how these get allocated with DRA One",
    "start": "1679679",
    "end": "1685120"
  },
  {
    "text": "one thing we did do was so so DCGM and a lot of other monitoring tools rely on",
    "start": "1685120",
    "end": "1690320"
  },
  {
    "text": "this API in Kubernetes called the pod resources API and for the device plugin",
    "start": "1690320",
    "end": "1695840"
  },
  {
    "text": "that was extended to expose the devices that are allocated by the device plugin and then these monitoring tools can can",
    "start": "1695840",
    "end": "1702399"
  },
  {
    "text": "query that to figure out what devices were allocated by any given pod and then emit metrics about them Um we also",
    "start": "1702399",
    "end": "1709679"
  },
  {
    "text": "updated the pod resources API to expose the DRRA devices that get allocated but",
    "start": "1709679",
    "end": "1715039"
  },
  {
    "text": "DCGM specifically that exporter hasn't been updated to consume these But there's there's nothing stopping it from",
    "start": "1715039",
    "end": "1720320"
  },
  {
    "text": "being done The the the the initial work has been done to update",
    "start": "1720320",
    "end": "1725840"
  },
  {
    "text": "the API in Kubernetes We also haven't updated cube",
    "start": "1725840",
    "end": "1733039"
  },
  {
    "text": "cuddle much yet at all So you get of course the normal support for listing",
    "start": "1733039",
    "end": "1738960"
  },
  {
    "text": "resource slices but cube cuddle describe resource slice that certainly is",
    "start": "1738960",
    "end": "1744320"
  },
  {
    "text": "something that we could extend to make it more useful We haven't really",
    "start": "1744320",
    "end": "1749600"
  },
  {
    "text": "discussed much around it One one things that come comes came up just now is that",
    "start": "1749600",
    "end": "1754720"
  },
  {
    "text": "device taints if they are set by an admin are in a separate object So there",
    "start": "1754720",
    "end": "1760480"
  },
  {
    "text": "is a resource a device tainted rule that basically gets applied on the fly by a",
    "start": "1760480",
    "end": "1766080"
  },
  {
    "text": "scheduleuler to matching devices But if you do a cube cutle describe resourceless you don't see it So if",
    "start": "1766080",
    "end": "1772720"
  },
  {
    "text": "someone wants to do some interesting fun work that's not too critical too hard easy to get started with We could make",
    "start": "1772720",
    "end": "1779840"
  },
  {
    "text": "cube cuddle plugin a cube cuddle subcomand for device tains We could enhance cube cuddle describe to be more",
    "start": "1779840",
    "end": "1786480"
  },
  {
    "text": "informative And all of these things are actually fairly easy things for for new new contributors because they are not",
    "start": "1786480",
    "end": "1791600"
  },
  {
    "text": "mission critical in the sense that you break the cluster of everyone using Kubernetes uh if you make a change",
    "start": "1791600",
    "end": "1800519"
  },
  {
    "text": "Thank you",
    "start": "1800960",
    "end": "1804200"
  },
  {
    "text": "Okay thanks everyone",
    "start": "1809240",
    "end": "1813559"
  }
]
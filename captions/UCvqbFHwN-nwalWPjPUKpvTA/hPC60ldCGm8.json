[
  {
    "text": "I'm beyond I want to talk about configuring Prometheus for high-performance Who am I written on my",
    "start": "0",
    "end": "6540"
  },
  {
    "text": "github profile here I'm a permitted development a SoundCloud engineer more or less I was not with the project",
    "start": "6540",
    "end": "16320"
  },
  {
    "text": "whenever started and not one of the legendary founders but I have been there for long enough that I must record",
    "start": "16320",
    "end": "22740"
  },
  {
    "text": "before was cool and I honestly I had no clue this would like become the",
    "start": "22740",
    "end": "28529"
  },
  {
    "text": "mainstream monitoring system of our time so something it's like it has many",
    "start": "28529",
    "end": "33739"
  },
  {
    "text": "entrance barriers in a way kind of complicated completely new concept but",
    "start": "33739",
    "end": "39120"
  },
  {
    "text": "one thing and I think this is one of the reasons why it's now here and we have packed rooms it's operationally really",
    "start": "39120",
    "end": "46500"
  },
  {
    "text": "simple it takes literally minute you get a premiership server running your wallet or you're not exporter or your primitive",
    "start": "46500",
    "end": "51660"
  },
  {
    "text": "yourself I do this literally in minutes in demos so people get something meaningful doing and then they take it",
    "start": "51660",
    "end": "58199"
  },
  {
    "text": "from there right now this is not an introduction torque it's an a german needs i'm saying about in english means",
    "start": "58199",
    "end": "64350"
  },
  {
    "text": "advanced I guess so you all are super transformative users and you are all",
    "start": "64350",
    "end": "69780"
  },
  {
    "text": "here to know about operational problems if you want to get really high performance out of your limited",
    "start": "69780",
    "end": "75600"
  },
  {
    "text": "resources so I don't want beginners in this talk because they would be scared it's actually quite easy in the",
    "start": "75600",
    "end": "80850"
  },
  {
    "text": "beginning but if you do something really crazy then it becomes more complicated I",
    "start": "80850",
    "end": "86369"
  },
  {
    "text": "also feel you know all the best practices right don't go crazy with your serious cardinality like SoundCloud",
    "start": "86369",
    "end": "93299"
  },
  {
    "text": "likes to put the user ID in the metric than your 350 million metrics or",
    "start": "93299",
    "end": "98820"
  },
  {
    "text": "something use recording rules for fast queries and all that to do that right right okay",
    "start": "98820",
    "end": "105390"
  },
  {
    "text": "so this is about how do you tweak you promised this configuration to get the best performance out of it most of those",
    "start": "105390",
    "end": "111630"
  },
  {
    "text": "tweaks are just command line flags and like every reasonably behaved unique",
    "start": "111630",
    "end": "118290"
  },
  {
    "text": "command you can just run from sssh and it gives you the flag which that's not",
    "start": "118290",
    "end": "125159"
  },
  {
    "text": "even all of them like the 47 Flags 46 story 46 lags in 1.5 32 luckily we",
    "start": "125159",
    "end": "132660"
  },
  {
    "text": "namespace them right so it's a bit weird but it's helpful if you have many of them and most of the",
    "start": "132660",
    "end": "138840"
  },
  {
    "text": "tweaks are related to the local storage and if you color them vipin flex that",
    "start": "138840",
    "end": "144689"
  },
  {
    "text": "stops with your local they are only 17 so apps like it's like shock therapy",
    "start": "144689",
    "end": "151200"
  },
  {
    "text": "right first you see 46 minutes 17 easy but 17 is still a lot and I mean I'm to",
    "start": "151200",
    "end": "156329"
  },
  {
    "text": "blame for that also they've guys Julius he is one of the real founders seen in the room",
    "start": "156329",
    "end": "161459"
  },
  {
    "text": "perhaps he ran away I don't know first because I blame him now okay so back",
    "start": "161459",
    "end": "167879"
  },
  {
    "text": "when for me she was created like 2012 and what the prototype has a prototypical storage layer storage we",
    "start": "167879",
    "end": "174030"
  },
  {
    "text": "won if you want and Julius realized this will not pull it off if he do the real thing",
    "start": "174030",
    "end": "179250"
  },
  {
    "text": "so he started right storage v2s he call it now so he's to blame for the fundamental design I kind of joined the",
    "start": "179250",
    "end": "185970"
  },
  {
    "text": "effort and then I took over now I'm the de facto maintainer also like most if",
    "start": "185970",
    "end": "191010"
  },
  {
    "text": "you like 2013 storage 2014 perhaps 2015 was public launch now we have 2017 so",
    "start": "191010",
    "end": "198209"
  },
  {
    "text": "most of the lifetime of prometheus it had the storage it kind of has aged and not always gracefully you run into more",
    "start": "198209",
    "end": "204479"
  },
  {
    "text": "more corner cases you realize okay we have to optimize that and sometimes you cannot just clear-cut uses make it one",
    "start": "204479",
    "end": "211650"
  },
  {
    "text": "way you have to ask the user for trade-offs between data safety and performance or something the ones when I",
    "start": "211650",
    "end": "217019"
  },
  {
    "text": "came to another and here we are so the best way to understand flags is from",
    "start": "217019",
    "end": "223260"
  },
  {
    "text": "first principles that means you read the code and you understand what the facts are doing right if you don't have the",
    "start": "223260",
    "end": "228629"
  },
  {
    "text": "change but you're like half an hour to spare watch this talk by this person in",
    "start": "228629",
    "end": "233790"
  },
  {
    "text": "the other promises also admit more views right so this will explain how v2 works",
    "start": "233790",
    "end": "239340"
  },
  {
    "text": "in principle and then it also explains the flags from first principle this talk",
    "start": "239340",
    "end": "244470"
  },
  {
    "text": "is not the other talk so this is more like let's talk about practical ideas",
    "start": "244470",
    "end": "251159"
  },
  {
    "text": "how to treat your flags there's also a nice page this is more like man page",
    "start": "251159",
    "end": "256259"
  },
  {
    "text": "style or cook book sell on our awesome documentation site we get lots of",
    "start": "256259",
    "end": "261449"
  },
  {
    "text": "questions about storage tweaking on the list or the memory usage and things like that",
    "start": "261449",
    "end": "267210"
  },
  {
    "text": "we'll have some heresy on the mailing list and then I point them to that page and I want them to that talk and then",
    "start": "267210",
    "end": "272970"
  },
  {
    "text": "they should be completely satisfied but for some reason there aren't and this is kind of how the idea for this talk was",
    "start": "272970",
    "end": "278940"
  },
  {
    "text": "born it's kind of audio faq or something right okay let's start were you all started",
    "start": "278940",
    "end": "287580"
  },
  {
    "text": "you spin up your first primitive server you let it run and since you all advanced permissive users and general",
    "start": "287580",
    "end": "294180"
  },
  {
    "text": "like yours the right operational attitude you monitor your primitive user guess what monitoring system we would",
    "start": "294180",
    "end": "300000"
  },
  {
    "text": "recommend Prometheus right so okay you can graph things this is a graph of the",
    "start": "300000",
    "end": "306599"
  },
  {
    "text": "memory usage of a permit if you've just started up there are many lines the green one is artists rather than",
    "start": "306599",
    "end": "312330"
  },
  {
    "text": "segments eyes or something broadly speaking kernel developers will kill me now this is essentially the",
    "start": "312330",
    "end": "317880"
  },
  {
    "text": "physical memory your process actually takes then we have a blue line which is the heap space as seen the gold heap",
    "start": "317880",
    "end": "325470"
  },
  {
    "text": "space seemed ago it's objects on the heat that are still in use and objects that are not in use anymore but not yet",
    "start": "325470",
    "end": "331830"
  },
  {
    "text": "connected by the garbage collector okay so the blue line is super noisy and",
    "start": "331830",
    "end": "336889"
  },
  {
    "text": "Brian who sit as told you something yet there are counters this is not a counter",
    "start": "336889",
    "end": "343020"
  },
  {
    "text": "at the gauge and you have exactly that problem it has Peaks all the time and even Prometheus doesn't get all the peaks because it might scrape your other",
    "start": "343020",
    "end": "349560"
  },
  {
    "text": "Prometheus server every 15 seconds and then graph anna assembles it down so there is a Purple Line this is max over",
    "start": "349560",
    "end": "356550"
  },
  {
    "text": "time for five minutes and the other probe aligners Miniver type Brian's idea so this helps a lot to see that they're",
    "start": "356550",
    "end": "363780"
  },
  {
    "text": "actually like maximums happening all the time in reality Peaks could be even higher so",
    "start": "363780",
    "end": "368820"
  },
  {
    "text": "my suspicion would be that we have a huge p key and that drove up the RSS but the RSS is weird right we will talk",
    "start": "368820",
    "end": "375449"
  },
  {
    "text": "about the lighter so you see this whatever the curve is all goes up and to the right so this is clearly memory",
    "start": "375449",
    "end": "380849"
  },
  {
    "text": "League right so you wait for time for a while and then you and what do you do you go to github you file an issue and",
    "start": "380849",
    "end": "386909"
  },
  {
    "text": "say yeah you're kind of glorious monitoring system you might not have noticed but it has a memory leak I have",
    "start": "386909",
    "end": "392580"
  },
  {
    "text": "noticed some perhaps yeah perhaps not so if you have enough memory and you wait",
    "start": "392580",
    "end": "398430"
  },
  {
    "text": "for a while it looks that so you get a steady state at some point I'm cool question is were what",
    "start": "398430",
    "end": "406210"
  },
  {
    "text": "determines where the steady-state is right and that's actually super hard to answer there are so many moving parts in",
    "start": "406210",
    "end": "411790"
  },
  {
    "text": "a premiership server even things like service discover you might be quite memory hungry then you have to retrieve",
    "start": "411790",
    "end": "417640"
  },
  {
    "text": "samples from the discover target you have to ingest them you have to index them indexing is violetta TV for us it's",
    "start": "417640",
    "end": "423550"
  },
  {
    "text": "just a fairly established library but for some reason sometimes it takes weird",
    "start": "423550",
    "end": "428590"
  },
  {
    "text": "amount of memory then we have curious of course queries sometimes take a weird",
    "start": "428590",
    "end": "435220"
  },
  {
    "text": "amount of memory and then we have our actual or simple George George v2 which we understand quite well but which also",
    "start": "435220",
    "end": "441610"
  },
  {
    "text": "takes memory they allocate memory they free memory and for some reason you get this blue curve and then the go runtime",
    "start": "441610",
    "end": "448930"
  },
  {
    "text": "request memory from the operating system and the operating system does something and you get this weird green line kind",
    "start": "448930",
    "end": "455230"
  },
  {
    "text": "of hard but there's one lever you have to move at the user it's your responsibility as a fan teaser you have",
    "start": "455230",
    "end": "462160"
  },
  {
    "text": "probably seen it because this is the one flag you cannot ignore storage local memory chunks what does that mean chunks",
    "start": "462160",
    "end": "469710"
  },
  {
    "text": "the memory the the wrong table sort chunk so we have one kilobyte fixed size",
    "start": "469710",
    "end": "476530"
  },
  {
    "text": "chunks where we put the assembles in with a compression so we get many there and then a series of chunks is a time",
    "start": "476530",
    "end": "484810"
  },
  {
    "text": "series and we write them all to disk this the same layout so we have chunks on this and chunks of American that just",
    "start": "484810",
    "end": "491890"
  },
  {
    "text": "mirror them to this and load them back if needed and we want to tell Prometheus how many chunks can be memory and this",
    "start": "491890",
    "end": "498790"
  },
  {
    "text": "is this number it's like two to the 20s or whatever like it's a million essentially a mega chunk that's the",
    "start": "498790",
    "end": "505870"
  },
  {
    "text": "default value for bigger service that's not enough and for smaller service",
    "start": "505870",
    "end": "510970"
  },
  {
    "text": "that's too much and you will just zoom by default so those memory checks there",
    "start": "510970",
    "end": "516190"
  },
  {
    "text": "are different populations there are the chunks that are still being written we call them had chunks they are not even",
    "start": "516190",
    "end": "521979"
  },
  {
    "text": "done so you can't write them to this because they are still changing and then their chunks that are all done but not",
    "start": "521979",
    "end": "527710"
  },
  {
    "text": "yet written to disk they are called chunks waiting for persistence and then their chance that are",
    "start": "527710",
    "end": "533410"
  },
  {
    "text": "do this but still lingering a memory because caching is good right okay and",
    "start": "533410",
    "end": "538510"
  },
  {
    "text": "whenever you're number of chunks the memory goes beyond this number primitives will kick out those chunks",
    "start": "538510",
    "end": "544360"
  },
  {
    "text": "that are already written to disk these written use how caching works of course",
    "start": "544360",
    "end": "549790"
  },
  {
    "text": "it might have you have too many turns are not yet written to this all are not",
    "start": "549790",
    "end": "555370"
  },
  {
    "text": "yet completed or a query uses them at the moment this is also a condition where you cannot evict them and then",
    "start": "555370",
    "end": "562440"
  },
  {
    "text": "this number would go over that number and your memory would explode again but",
    "start": "562440",
    "end": "567640"
  },
  {
    "text": "promises at least tries to protect itself and then it stops ingest it um you don't have you have probably into",
    "start": "567640",
    "end": "573700"
  },
  {
    "text": "this okay so how to avoid stopping ingestion you want to tell the server to",
    "start": "573700",
    "end": "580450"
  },
  {
    "text": "resist chunks more quickly if you get closer to that point and that's why we",
    "start": "580450",
    "end": "585730"
  },
  {
    "text": "have another flag at some point we realized internet another flags so this tells the premiership server how",
    "start": "585730",
    "end": "591460"
  },
  {
    "text": "much chunk may be in that state where they're waiting for persistence so we specify that so that prometheus knows if",
    "start": "591460",
    "end": "598810"
  },
  {
    "text": "you get close to that value we have to speed up how we persist to disk of course you might ask why are we speeding",
    "start": "598810",
    "end": "606070"
  },
  {
    "text": "up persistent to disk all the time like why not best effort just write to this",
    "start": "606070",
    "end": "611530"
  },
  {
    "text": "as fast as possible this is a good question it's explained a detail in that",
    "start": "611530",
    "end": "616750"
  },
  {
    "text": "other talk just very short discs are hard right and spinning this our heart",
    "start": "616750",
    "end": "622330"
  },
  {
    "text": "because they take eternally to see to that file on this where we write our chance to so we have one file for",
    "start": "622330",
    "end": "629260"
  },
  {
    "text": "serious you want to write chunks to the end you see there takes 10 milliseconds right 10 milliseconds is like endless",
    "start": "629260",
    "end": "636490"
  },
  {
    "text": "and then you write one chunk and then you seek to the next series again 10 milliseconds to write a single kilobyte",
    "start": "636490",
    "end": "642340"
  },
  {
    "text": "this throughput is like ridiculous right that doesn't work so you need to match up right you need to to save a few",
    "start": "642340",
    "end": "648910"
  },
  {
    "text": "chunks in memory before you seek to that point on the disk and then write like for 10 chunks or whatever okay as if",
    "start": "648910",
    "end": "656440"
  },
  {
    "text": "these solve all problems right so they don't have seek time so we can just write tiny amounts all the time right",
    "start": "656440",
    "end": "662920"
  },
  {
    "text": "no from be core ssds hate if you write a single kilobyte",
    "start": "662920",
    "end": "669330"
  },
  {
    "text": "like at least I want to write for pillow right bigger SSDs want to write 16",
    "start": "669330",
    "end": "675090"
  },
  {
    "text": "kilobyte this is their page size if you don't do this you get write amplification it's super horrible you",
    "start": "675090",
    "end": "680640"
  },
  {
    "text": "also burn through the lifetime of your SSD yet so definitely whatever you have you want to match up so this is why you",
    "start": "680640",
    "end": "687210"
  },
  {
    "text": "don't want to write at full speed all the time you want to match up as much as possible so you have to treat those",
    "start": "687210",
    "end": "693450"
  },
  {
    "text": "numbers so Prometheus has a nice metric",
    "start": "693450",
    "end": "699300"
  },
  {
    "text": "called the persistent urgencies gone that's actually exported by the polity server you can plot it in prefer now you",
    "start": "699300",
    "end": "706080"
  },
  {
    "text": "can alert on it so this is essentially how quick prometheus wants to produce",
    "start": "706080",
    "end": "711210"
  },
  {
    "text": "it's calculated from all those numbers that are also exported as metric so much chance to persist is the limit your",
    "start": "711210",
    "end": "717720"
  },
  {
    "text": "configured chance to persist the actual number of chunks that are waiting for positions this is our memory churn flag",
    "start": "717720",
    "end": "723540"
  },
  {
    "text": "and this is the actual number of memory chance you can plot them all nice curves and essentially the urgency score is",
    "start": "723540",
    "end": "730080"
  },
  {
    "text": "chunks waiting for persistence divided by the maximum allowed number to wait for persistent and sometimes you see",
    "start": "730080",
    "end": "736560"
  },
  {
    "text": "these funny messages right George has entered rational chance versus peak number something something big number",
    "start": "736560",
    "end": "742620"
  },
  {
    "text": "big number something right so now you can kind of guess what it means so we have all those numbers here and you see",
    "start": "742620",
    "end": "749700"
  },
  {
    "text": "chunks to resist this 12 million max chunks which is 50 million so this is 0.8 you can see how this works and what",
    "start": "749700",
    "end": "756450"
  },
  {
    "text": "is rush mode so rush mode is if the urgency score ever hits 0.8 then",
    "start": "756450",
    "end": "762360"
  },
  {
    "text": "Prometheus thinks it's not just enough to be gradually faster we have to do like desperate measures now so it does",
    "start": "762360",
    "end": "768180"
  },
  {
    "text": "things like now we go as fast as we can we also don't do like early checkpointing which is a different",
    "start": "768180",
    "end": "774180"
  },
  {
    "text": "concept and we also don't insist on F thinking every single file anymore if we write it usually I mean people are often",
    "start": "774180",
    "end": "781680"
  },
  {
    "text": "think this is super evil and they may like write FAQ so right server goes into restaurant all the time or can I do it's",
    "start": "781680",
    "end": "788340"
  },
  {
    "text": "actually not super evil if it helps so this you can plot this in your dashboard if it hits 0.8 it should go down again",
    "start": "788340",
    "end": "794760"
  },
  {
    "text": "so at some point I will hit 0.7 and then you leave rush mode and all this good if they send sometimes or even",
    "start": "794760",
    "end": "801120"
  },
  {
    "text": "periodically fine what should never happen is you reach open a to go into",
    "start": "801120",
    "end": "806399"
  },
  {
    "text": "restaurant and the urgency score goes up and up and up and up all the time then you are in trouble",
    "start": "806399",
    "end": "812810"
  },
  {
    "text": "predict linear by the way comes in handy if you want to alert on that and if you",
    "start": "812810",
    "end": "819779"
  },
  {
    "text": "really hit one something that happens and I want to show you this one more flag so people have like it depends on",
    "start": "819779",
    "end": "825779"
  },
  {
    "text": "context and also religious beliefs if you want to sync files or not so this is also configurable it's a trade off you",
    "start": "825779",
    "end": "831660"
  },
  {
    "text": "can give to the user the default of this flag is adaptive that means don't think in rush mode but think in non rush mode",
    "start": "831660",
    "end": "838079"
  },
  {
    "text": "you can also say never if you don't believe in thinking because you want to use the page cache and everything say",
    "start": "838079",
    "end": "844230"
  },
  {
    "text": "never and if you think you should always EV sing it's really vent on circumstances longer discussions three",
    "start": "844230",
    "end": "850230"
  },
  {
    "text": "other talks could be given about that you said it you always okay so this has happened if your rush if your urgency",
    "start": "850230",
    "end": "856889"
  },
  {
    "text": "score ever hit once and also tells you the reason so this in this case it",
    "start": "856889",
    "end": "862500"
  },
  {
    "text": "because we have hit the max change to persist it could also be the other way that your memory checks go up too much",
    "start": "862500",
    "end": "868230"
  },
  {
    "text": "perks because you're curious that in too many or other reasons that I'll talk about in a second and there's a even",
    "start": "868230",
    "end": "874980"
  },
  {
    "text": "tolerate 10% more than the configured value but then it also gives you the straighten message injection throttle",
    "start": "874980",
    "end": "881850"
  },
  {
    "text": "this is horrible for various reasons we don't need me to discuss that you should definitely avoid that if that happens",
    "start": "881850",
    "end": "887779"
  },
  {
    "text": "ever or even like more than once you should you should do something okay so",
    "start": "887779",
    "end": "894449"
  },
  {
    "text": "now what are the right values for those flags on a real server naively you might",
    "start": "894449",
    "end": "902790"
  },
  {
    "text": "think okay a chunk is a kilobyte I said that so Emil is a gigabyte easy",
    "start": "902790",
    "end": "908130"
  },
  {
    "text": "right so let's say we have 64 gigabyte and like half of it for charge 32",
    "start": "908130",
    "end": "914550"
  },
  {
    "text": "million memory chunks we can set this done right no doesn't work that way Prometheus is doing so many things that",
    "start": "914550",
    "end": "921930"
  },
  {
    "text": "you have to do this way lower and yeah I",
    "start": "921930",
    "end": "927329"
  },
  {
    "text": "mean I talked only talked about like two level we curious whatever although things take memory so this is way lower",
    "start": "927329",
    "end": "933600"
  },
  {
    "text": "than you expect manufacturers in the equation and if you look back at this",
    "start": "933600",
    "end": "939059"
  },
  {
    "text": "thing so the green line should never cross the memory you have right so let's",
    "start": "939059",
    "end": "945679"
  },
  {
    "text": "whatever let's say that our real memories here and this peak was already quite dangerous you should never go",
    "start": "945679",
    "end": "951989"
  },
  {
    "text": "higher than that now this line is kind of what we what go things it uses so",
    "start": "951989",
    "end": "959160"
  },
  {
    "text": "this is already lower and even this ratio is quite off kind of hard to predict my rule of thumb is this is",
    "start": "959160",
    "end": "964919"
  },
  {
    "text": "probably this peak is probably 2/3 of this peak this is not always true but",
    "start": "964919",
    "end": "970199"
  },
  {
    "text": "it's kind of a conservative estimate so let's say this line is 2/3 but then you get this up and down right that's just",
    "start": "970199",
    "end": "977609"
  },
  {
    "text": "natural if you see this is 70s this is 14 gig here this is a factor of 2 this",
    "start": "977609",
    "end": "983369"
  },
  {
    "text": "is not coincident this is how go garbage collecting works you have the heap size where the garbage collector was done and",
    "start": "983369",
    "end": "989100"
  },
  {
    "text": "then the garbage collector rights of the heat to double in size and then it runs in your garbage collection second easy right but that means if this is the line",
    "start": "989100",
    "end": "996689"
  },
  {
    "text": "you cannot cross it's 2/3 of your m and the baseline you have that your garbage collector is this this is 1/2 of 2/3 is",
    "start": "996689",
    "end": "1004639"
  },
  {
    "text": "1/3 so essentially only 1/3 of your memory is available for all the chunky of allocating all the time and all the",
    "start": "1004639",
    "end": "1010730"
  },
  {
    "text": "other things that might be allocated all the time so this is where this factor of 3 from the documentation side comes from but",
    "start": "1010730",
    "end": "1017689"
  },
  {
    "text": "this is really a lower bound some people try that and then they so what we do it sound route this is from our original",
    "start": "1017689",
    "end": "1024199"
  },
  {
    "text": "chef recipes because realized old-school and deployed primitives on their metal this chef so this what we do like chef",
    "start": "1024199",
    "end": "1031519"
  },
  {
    "text": "has memory in kilobytes we divided by 6 so it's 6 of our storage is essentially",
    "start": "1031519",
    "end": "1037909"
  },
  {
    "text": "used for memory chunks but you already see like there's a comment here this is a rule of thumb works in 90% of the",
    "start": "1037909",
    "end": "1043579"
  },
  {
    "text": "cases sometimes it's super wasteful if you promise it to us actually not doing so much else you are not making use of",
    "start": "1043579",
    "end": "1049700"
  },
  {
    "text": "your memory you're wasting a lot or it's the other way round it's actually doing a lot of other things like has a lot of",
    "start": "1049700",
    "end": "1056600"
  },
  {
    "text": "series and then it has to manage individual series has big MVC's has the experience of memory this might not even",
    "start": "1056600",
    "end": "1062899"
  },
  {
    "text": "be enough so this works most the time you can try that yourself but sometimes you have to tweak it which is",
    "start": "1062899",
    "end": "1068870"
  },
  {
    "text": "not a good situation to be in but yeah manageable and then the other question is mark strength to persist or the good",
    "start": "1068870",
    "end": "1075799"
  },
  {
    "text": "value there we just use half of the other value in general good idea but it",
    "start": "1075799",
    "end": "1081259"
  },
  {
    "text": "again depends on things if you really want to batch up a lot then you want to have it as high as possible but on the",
    "start": "1081259",
    "end": "1088789"
  },
  {
    "text": "other hand like if you have many time series and every time she has this head showing that cannot be evicted already",
    "start": "1088789",
    "end": "1094639"
  },
  {
    "text": "you don't want to have too many chunks in this population because then then you might um again because too many strands",
    "start": "1094639",
    "end": "1101840"
  },
  {
    "text": "here so this is always smaller than this one obviously but the numbers are smaller I would start with half of it",
    "start": "1101840",
    "end": "1108919"
  },
  {
    "text": "and then you can drink it we have also written this in Georgia recipe that people can't we get this is all valid",
    "start": "1108919",
    "end": "1116090"
  },
  {
    "text": "for 1.5 - 2 1 or 1.5 in general but the other one our buggy don't use them one",
    "start": "1116090",
    "end": "1122570"
  },
  {
    "text": "not for was way more erratic in memory consumption animals also way more",
    "start": "1122570",
    "end": "1128990"
  },
  {
    "text": "wasteful for various reasons sometimes it was just a mistake sometimes was a trade-off between pure performance but",
    "start": "1128990",
    "end": "1134899"
  },
  {
    "text": "Brian who I mentioned a couple of times and you have heard a key not any authenticity in the first row this is",
    "start": "1134899",
    "end": "1140210"
  },
  {
    "text": "him in case you didn't notice so he did a lot of research post 104 which went",
    "start": "1140210",
    "end": "1146990"
  },
  {
    "text": "into 105 how you can actually make this a bit more even and saving with more",
    "start": "1146990",
    "end": "1152090"
  },
  {
    "text": "memory so that was great work and it already simplified many things he write",
    "start": "1152090",
    "end": "1158419"
  },
  {
    "text": "a super awesome blog post on his company text block at like fall out of his",
    "start": "1158419",
    "end": "1163789"
  },
  {
    "text": "research and this is funny enough it's exactly the opposite question then we have a tongue clock so at center we have",
    "start": "1163789",
    "end": "1169309"
  },
  {
    "text": "our bare metal servers and you think okay this is your team squeezy server you want to get most performance out of",
    "start": "1169309",
    "end": "1175100"
  },
  {
    "text": "it so use these settings and tweak at will but in many other situations it's",
    "start": "1175100",
    "end": "1180860"
  },
  {
    "text": "the opposite you know I have two million metrics and I want to ingest 100,000 tables per second",
    "start": "1180860",
    "end": "1186470"
  },
  {
    "text": "so what ec2 instance do I have to order or what container settings to where I",
    "start": "1186470",
    "end": "1191509"
  },
  {
    "text": "want to have it I run my promises server like on cuneta or something and that's all explained in the blog post I",
    "start": "1191509",
    "end": "1197850"
  },
  {
    "text": "wouldn't even go into all the details because it's white we sophisticated but you can try this out like of course",
    "start": "1197850",
    "end": "1203490"
  },
  {
    "text": "again you use police's to monitor promises and these are the queries from the blog post so the first one explained",
    "start": "1203490",
    "end": "1209880"
  },
  {
    "text": "that the blog post just broadly speaking this is the number of chunks you actually create in six hours because six",
    "start": "1209880",
    "end": "1216870"
  },
  {
    "text": "hours is the sweet spot the committee is once for King up the right right and you can do this with a few factors on",
    "start": "1216870",
    "end": "1223020"
  },
  {
    "text": "explained in the approach and this is just example let's try it out on a PC",
    "start": "1223020",
    "end": "1228750"
  },
  {
    "text": "Prometheus or SL dot it's 6.8 million chunks do you want as chance to persist",
    "start": "1228750",
    "end": "1234000"
  },
  {
    "text": "to a six hour cycle for matching up right and then the heuristics here to",
    "start": "1234000",
    "end": "1240630"
  },
  {
    "text": "increase what how many more memory chance do you want is actually the number of theories rationale is kind of",
    "start": "1240630",
    "end": "1246929"
  },
  {
    "text": "these are the head chunks you have at least so you take the maximum of memory theories you have it's 4.6 million",
    "start": "1246929",
    "end": "1253230"
  },
  {
    "text": "pretty beefy it's already kind of hard to run a parameter server that hot you",
    "start": "1253230",
    "end": "1258390"
  },
  {
    "text": "get a four million for that and the total numbers 11 million with our",
    "start": "1258390",
    "end": "1263750"
  },
  {
    "text": "divided by six rule this will probably not fit on a 64 gigabyte machine",
    "start": "1263750",
    "end": "1269070"
  },
  {
    "text": "it depends right if you don't do many other things it might totally see it but if you do many other things expensive it",
    "start": "1269070",
    "end": "1275700"
  },
  {
    "text": "mixes in disease or something it might not fit the server I took this from if a",
    "start": "1275700",
    "end": "1280830"
  },
  {
    "text": "64 gigabyte service like had tweak parameters these are actually the parameters we use without knowledge of",
    "start": "1280830",
    "end": "1287520"
  },
  {
    "text": "write blog post so you see they are way lower and that's because we on that server we would just move with our",
    "start": "1287520",
    "end": "1293250"
  },
  {
    "text": "settings and this also means we are not in the comfort zone that Brian Proctor's",
    "start": "1293250",
    "end": "1298980"
  },
  {
    "text": "put your insight right raw process like yeah this is we will probably never go to rush mode you have lots of headroom",
    "start": "1298980",
    "end": "1304620"
  },
  {
    "text": "for Peaks and stuff this is like we run it as hard as we can right this will go",
    "start": "1304620",
    "end": "1309840"
  },
  {
    "text": "to rush mode occasionally it kind of works this is a production server but yes this is how you see you have a bit",
    "start": "1309840",
    "end": "1315539"
  },
  {
    "text": "of leverage between super-conservative and run it leading edge all right so what is the",
    "start": "1315539",
    "end": "1323340"
  },
  {
    "text": "basic problem we happy with all those tweaks the basic problem is we have all those factors they're very like I talked",
    "start": "1323340",
    "end": "1330419"
  },
  {
    "text": "a lot about the number of C a sea of calmly memory and you have so many things that might or might not take",
    "start": "1330419",
    "end": "1335450"
  },
  {
    "text": "memory so yeah it's hard it would be so much nice if you can't could just tell",
    "start": "1335450",
    "end": "1341690"
  },
  {
    "text": "to me yes please take that amount of memory and do the best like yeah the one",
    "start": "1341690",
    "end": "1347450"
  },
  {
    "text": "optics we should have totally released that on the first day of the conference to get super confused with kubernetes",
    "start": "1347450",
    "end": "1353660"
  },
  {
    "text": "106 being released at the same time anyone they set a new flag it will be",
    "start": "1353660",
    "end": "1358670"
  },
  {
    "text": "released next week or something so you can actually tell Prometheus the target heat size you can't tell infirmities",
    "start": "1358670",
    "end": "1364790"
  },
  {
    "text": "hours s because go doesn't even know the are set but the upper purple line that's essentially what you can clamp or",
    "start": "1364790",
    "end": "1371090"
  },
  {
    "text": "mediator it's not rocket science it might still have little Peaks going over that 1.9 go on and I might help us to be",
    "start": "1371090",
    "end": "1378350"
  },
  {
    "text": "this to implement that better but that works right this is like 2 gigabyte you can now tell Prometheus now next week or",
    "start": "1378350",
    "end": "1385460"
  },
  {
    "text": "build for master please use whatever 30 gigabytes of key size and it will try",
    "start": "1385460",
    "end": "1392360"
  },
  {
    "text": "to make the best out of it you can't even see how that works I screenshot my mouth cause I'm sorry so",
    "start": "1392360",
    "end": "1398630"
  },
  {
    "text": "this is what you actually get 125 million times do it usually but then the crazy team that has so many instances on",
    "start": "1398630",
    "end": "1405140"
  },
  {
    "text": "the equivalence class but they decided to really blow everything suddenly you had all the old time serious still a",
    "start": "1405140",
    "end": "1410390"
  },
  {
    "text": "memory lingering somewhere with chunks and you have through more time serious and then they I mean this is actually an",
    "start": "1410390",
    "end": "1416210"
  },
  {
    "text": "eight-hour shift and it already goes down again but often you have this oh my god the do plug was wrong let's just",
    "start": "1416210",
    "end": "1422450"
  },
  {
    "text": "redeploy everything again and then within 10 minutes you have like triple your time series and that's usually",
    "start": "1422450",
    "end": "1428450"
  },
  {
    "text": "either you're super conservative with your settings and the chunks they are the same in 1.5 but now you have more",
    "start": "1428450",
    "end": "1435110"
  },
  {
    "text": "time series to manage you either room or your settings are super contoured and in usual cases you you don't actually use",
    "start": "1435110",
    "end": "1441770"
  },
  {
    "text": "your memory this is now the new thing you see like this the blue stuff are the",
    "start": "1441770",
    "end": "1446930"
  },
  {
    "text": "headshots that are open the old stuff are the chunks that are waiting for positions and the green is just the caching okay and you see it jumps up and",
    "start": "1446930",
    "end": "1453950"
  },
  {
    "text": "then permute is kind of contacts something happen here I don't know what expensive query letter D be compacted or",
    "start": "1453950",
    "end": "1461930"
  },
  {
    "text": "I don't want some something needed more memory so permittees reacted evicted like the cash junk and here's the other jump",
    "start": "1461930",
    "end": "1468050"
  },
  {
    "text": "which apparently was heavy on the memories or it evicted a whole lot of junk so this works like a charm",
    "start": "1468050",
    "end": "1474680"
  },
  {
    "text": "pretty good safety lot of operational trouble okay what it doesn't change its",
    "start": "1474680",
    "end": "1480350"
  },
  {
    "text": "checkpointing pattern time okay a few minutes and check pointing is is my my",
    "start": "1480350",
    "end": "1486320"
  },
  {
    "text": "next biggest enemy so what is checkpointing if you watch the other talk you will understand I will explain",
    "start": "1486320",
    "end": "1494240"
  },
  {
    "text": "it super quickly you have all those chunks that are not yet written to this thing of the open head showings and now you want to shut down your server so",
    "start": "1494240",
    "end": "1500750"
  },
  {
    "text": "where do they go you could like stop ingestion and wait until they have been all written to the individual files will",
    "start": "1500750",
    "end": "1506000"
  },
  {
    "text": "take like six hours but yeah I'll have so much more for shorter but you don't want six hours shutdown time right",
    "start": "1506000",
    "end": "1511730"
  },
  {
    "text": "so what you do you write a gigantic block to this which has all the non process the part in one big file because",
    "start": "1511730",
    "end": "1517970"
  },
  {
    "text": "writing one big file is very easier and ideally this takes like 15 seconds but",
    "start": "1517970",
    "end": "1523660"
  },
  {
    "text": "you scale up your primitive server you buy more RAM you buy bigger this it's all possible but what never scales up or almost not",
    "start": "1523660",
    "end": "1531440"
  },
  {
    "text": "is the speed you write to this so if your checkpoint is twice as much try to speak because we have tries as many",
    "start": "1531440",
    "end": "1537140"
  },
  {
    "text": "serious it takes approximately twice as long to write at some point on be few servers you check vertex 10 minutes 15",
    "start": "1537140",
    "end": "1543500"
  },
  {
    "text": "minutes gets pretty horrible right by default we checked on every 5 minutes not only",
    "start": "1543500",
    "end": "1548810"
  },
  {
    "text": "on shutdown but also regularly because user records that crash right and you don't want to lose too much data so this",
    "start": "1548810",
    "end": "1554540"
  },
  {
    "text": "is like a conservative setting don't lose more than 5 minutes of data but if you check one already takes 50",
    "start": "1554540",
    "end": "1559640"
  },
  {
    "text": "minutes you are simply check waiting all the time that totally kills you or your disk IO like essentially 90% of GDP I",
    "start": "1559640",
    "end": "1567080"
  },
  {
    "text": "was just check pointing then it's super horrible so this is definitely something on beefy service where you have to make",
    "start": "1567080",
    "end": "1572450"
  },
  {
    "text": "the trade-off you just don't do it automatically yet per suite we will didn't you know I'll tell you other",
    "start": "1572450",
    "end": "1579080"
  },
  {
    "text": "stories in a second but this is definitely something on beefy servers where you have to say ok I'm except to",
    "start": "1579080",
    "end": "1585740"
  },
  {
    "text": "like lose 50 minutes of data or half an hour and increase that we do 50 minutes of Delta by default also like pressures",
    "start": "1585740",
    "end": "1593240"
  },
  {
    "text": "don't happen too often and yeah just metrics right filling data so there's this other flag",
    "start": "1593240",
    "end": "1600210"
  },
  {
    "text": "that is extensively discussed in the other chart and even in the discussion it's so communicated I won't even explain it but this is a really like a",
    "start": "1600210",
    "end": "1607590"
  },
  {
    "text": "setting that is again conservative and it's only makes only sense on spinning this so on SSDs and so these are anyway",
    "start": "1607590",
    "end": "1614340"
  },
  {
    "text": "worse in like writing checkpoints because they really hate Satan they hate many things they hate small lights but",
    "start": "1614340",
    "end": "1620489"
  },
  {
    "text": "they also hate sustain rights or approach right so on spinning this you can put this number without problems too",
    "start": "1620489",
    "end": "1628169"
  },
  {
    "text": "really high number you should do that on sorry on SSD on spinning this it's again depends on your sense of conservativism",
    "start": "1628169",
    "end": "1636679"
  },
  {
    "text": "this will create more checkpoints so a complicated issue and very hairy and",
    "start": "1636679",
    "end": "1642450"
  },
  {
    "text": "this is Jack said very high of is SSD as if these are so this is like what you can get with a really nasty upset SSD so",
    "start": "1642450",
    "end": "1652590"
  },
  {
    "text": "the yellow curve here is memory serious maintenance so this means whenever or",
    "start": "1652590",
    "end": "1659369"
  },
  {
    "text": "that often a memory serious was looked at and all the unprocessed junks were",
    "start": "1659369",
    "end": "1664590"
  },
  {
    "text": "written on to disk so this is should be a flat line on this server it's like going up and down like crazy and like",
    "start": "1664590",
    "end": "1672570"
  },
  {
    "text": "the naive assumption would be when it's at zero like it's doing nothing this is",
    "start": "1672570",
    "end": "1678720"
  },
  {
    "text": "when like the checkpoint is running and the discount do anything else actually wrong the blue shaded area this is when",
    "start": "1678720",
    "end": "1685350"
  },
  {
    "text": "the checkpoint is happening and at the end when the checkpoint is done from UTS is checked on done please think that",
    "start": "1685350",
    "end": "1691440"
  },
  {
    "text": "file and then the SSD observes like thinks the file but then it's super",
    "start": "1691440",
    "end": "1697200"
  },
  {
    "text": "upset about it so this is for ten minutes that's nothing it can't even rename a single file this is also an SSD",
    "start": "1697200",
    "end": "1703830"
  },
  {
    "text": "this is nice which is 90% fooled and if SSDs are almost 90% full they are also super upset so like if you thought as a",
    "start": "1703830",
    "end": "1710369"
  },
  {
    "text": "piece of all your problems it's yeah they create new interesting problems and like some people even format the SSDs in",
    "start": "1710369",
    "end": "1717570"
  },
  {
    "text": "a way that they don't even partition a third of the space so that they have more Headroom to breathe but this is",
    "start": "1717570",
    "end": "1723659"
  },
  {
    "text": "what you get like it horrible right so now there's an elephant in the room",
    "start": "1723659",
    "end": "1730619"
  },
  {
    "text": "like people even at this conference ask me are you crazy why aren't you using the page cache 1 are you a mapping for",
    "start": "1730619",
    "end": "1736619"
  },
  {
    "text": "us and the stupid checkpointing and everything there are very good reasons for all of that and I I can I'm happy to",
    "start": "1736619",
    "end": "1742529"
  },
  {
    "text": "discuss those it's just too much to expect in all of those things in a talk but you can kind of start with science",
    "start": "1742529",
    "end": "1749249"
  },
  {
    "text": "fiction like everything in hindsight we know everything and we have like infinite brain capacity and coding",
    "start": "1749249",
    "end": "1755699"
  },
  {
    "text": "capacity and an ingenious person can just lock themselves in into a into the basement for three months and just",
    "start": "1755699",
    "end": "1761039"
  },
  {
    "text": "rewrite everything that would be great right so he also sits there he locked",
    "start": "1761039",
    "end": "1770159"
  },
  {
    "text": "himself in for three months and brought everything new with all those things in mind and like every single problem I",
    "start": "1770159",
    "end": "1776879"
  },
  {
    "text": "mentioned the store will go away I'm sure there will be a few more new more interesting problems but the problems we",
    "start": "1776879",
    "end": "1782879"
  },
  {
    "text": "have here they are also it's of course still pre-offer but watch our our",
    "start": "1782879",
    "end": "1788459"
  },
  {
    "text": "communication channels there will be another soon and then 2.0 will happen sometime this year and everything will",
    "start": "1788459",
    "end": "1795569"
  },
  {
    "text": "be great I'm actually not spoiling any surprises because farming will surely give very insightful talks about that and I",
    "start": "1795569",
    "end": "1801089"
  },
  {
    "text": "shouldn't destroy that surprise do we have time for questions yes five minutes",
    "start": "1801089",
    "end": "1806669"
  },
  {
    "text": "edited also Julius and I will do boost duty at the CN CF booth which is like",
    "start": "1806669",
    "end": "1813079"
  },
  {
    "text": "there I think like in the inner ring it's like it's difficult to find but we'll see jewelry's Amin you're kind of",
    "start": "1813079",
    "end": "1819119"
  },
  {
    "text": "tall so at half-past three will be there and you can ask questions but we also have five minutes right now thank you",
    "start": "1819119",
    "end": "1827629"
  },
  {
    "text": "so any questions like the FAQ you always wanted Rask and now you get seven",
    "start": "1832559",
    "end": "1837789"
  },
  {
    "text": "response to answers in person okay there",
    "start": "1837789",
    "end": "1844240"
  },
  {
    "text": "is one yes please",
    "start": "1844240",
    "end": "1847620"
  },
  {
    "text": "have you been as always repeat the question how does this over with remote storage question my perspectives have",
    "start": "1853040",
    "end": "1859610"
  },
  {
    "text": "you been in Julia's talk two hours ago okay you watch the recording this is exactly the talk you want to want to",
    "start": "1859610",
    "end": "1866240"
  },
  {
    "text": "watch and short answer is this is all men remote search is always meant in a",
    "start": "1866240",
    "end": "1871370"
  },
  {
    "text": "way that it will not interfere with your local performance and I mean this is a basic idea for me see if your network is",
    "start": "1871370",
    "end": "1877010"
  },
  {
    "text": "on fire you can Samuel whatever you say this to doesn't work at all but you sound hosted tells the same signal how",
    "start": "1877010",
    "end": "1884540"
  },
  {
    "text": "super mediator it still happily collecting metrics that's the idea that feel still they still remain - okay",
    "start": "1884540",
    "end": "1891530"
  },
  {
    "text": "anything else I have on the slide if",
    "start": "1891530",
    "end": "1896690"
  },
  {
    "text": "you're not asking questions okay let me",
    "start": "1896690",
    "end": "1902390"
  },
  {
    "text": "say one thing this is like I mean there were seven seventeenth like slightly covered like five or six so the above is",
    "start": "1902390",
    "end": "1910250"
  },
  {
    "text": "kind of interesting but the lower one this is something I should have done way earlier we talked about how the go",
    "start": "1910250",
    "end": "1916970"
  },
  {
    "text": "garbage collector like needs hundred percent heat growth to start a garbage collection this is kind of based on a",
    "start": "1916970",
    "end": "1923180"
  },
  {
    "text": "heuristic for like essentially all of the heat is is like if you know and you have obvious objects coming and going",
    "start": "1923180",
    "end": "1928940"
  },
  {
    "text": "then it makes total sense we have seen that most of our heat is just memory chunks that they stay around for like",
    "start": "1928940",
    "end": "1934850"
  },
  {
    "text": "hours weeks sometimes so it's not what usually you do receive objects right and",
    "start": "1934850",
    "end": "1940760"
  },
  {
    "text": "which will all be solve in 2.0 because it's a mess and Kluber cholera but you can totally play this setting this",
    "start": "1940760",
    "end": "1947900"
  },
  {
    "text": "environment very a non flag environment variable go GT that helps you how much your heap has to grow to trigger a",
    "start": "1947900",
    "end": "1953810"
  },
  {
    "text": "garbage collecting cycle and we even decided to put this by default to 40 in",
    "start": "1953810",
    "end": "1959180"
  },
  {
    "text": "row 1.6 and that's what you get on the right so this is the usual pattern you",
    "start": "1959180",
    "end": "1965180"
  },
  {
    "text": "know then I restart the server with the other environment variable you get the typical cover up and here your steady",
    "start": "1965180",
    "end": "1971330"
  },
  {
    "text": "state and you see this bread or widths",
    "start": "1971330",
    "end": "1976700"
  },
  {
    "text": "or whatever height is essentially half right so this line for exactly the same",
    "start": "1976700",
    "end": "1983030"
  },
  {
    "text": "thing you need it like twenty seven gigabytes before now you need the free memory upgrade I mean not",
    "start": "1983030",
    "end": "1988369"
  },
  {
    "text": "completely free because you do more garbage collection that it's another call or something right but this is like",
    "start": "1988369",
    "end": "1994159"
  },
  {
    "text": "you can't even do this with your 1.5 server it's like I mean unless you're",
    "start": "1994159",
    "end": "1999529"
  },
  {
    "text": "CPU bound this is super effective and will be default you can still set it in",
    "start": "1999529",
    "end": "2004570"
  },
  {
    "text": "the environment variable but this will be this will be helping a lot in one not six it will even automatically realize",
    "start": "2004570",
    "end": "2010869"
  },
  {
    "text": "oh as more memory I can have more chunks we see new heap size so that's that's pretty pretty nice",
    "start": "2010869",
    "end": "2016509"
  },
  {
    "text": "there's no verbs right in robotics you have like same machine just different go",
    "start": "2016509",
    "end": "2023710"
  },
  {
    "text": "GC setting this goes up to ten million and it goes up to 60 million this is",
    "start": "2023710",
    "end": "2029049"
  },
  {
    "text": "just a few more quality born for garbage collector okay yeah I think we are we",
    "start": "2029049",
    "end": "2036129"
  },
  {
    "text": "are out of time if you have any urgent question raise your hand now or come to the booth say us a hand",
    "start": "2036129",
    "end": "2043739"
  },
  {
    "text": "okay this was your use of this flat right so this is a weird implementation",
    "start": "2047000",
    "end": "2053510"
  },
  {
    "text": "detail in this storage we have to kind of lock the times use before we even know it's fingerprint and now we you",
    "start": "2053510",
    "end": "2059000"
  },
  {
    "text": "know whatever it's it's much better than that but we we need essentially a music",
    "start": "2059000",
    "end": "2064550"
  },
  {
    "text": "before we create something in memory so we have to hospital talking or we have a",
    "start": "2064550",
    "end": "2070280"
  },
  {
    "text": "limited set of mutexes and round robin them to time series and that's by default for thousands it should be just",
    "start": "2070280",
    "end": "2076550"
  },
  {
    "text": "enough but I have seen scenarios hi ingest container over this is actually getting lock contention and then you can",
    "start": "2076550",
    "end": "2083450"
  },
  {
    "text": "set it to higher values it like almost no penalty yeah if you have a lot of",
    "start": "2083450",
    "end": "2091580"
  },
  {
    "text": "time and you want to ingest a lot of them then you get it just lock lock no and then right very shortly",
    "start": "2091580",
    "end": "2097970"
  },
  {
    "text": "you can play with that it's an easy one to play with okay meet me at the booth if you want more crescent",
    "start": "2097970",
    "end": "2105579"
  },
  {
    "text": "[Applause]",
    "start": "2106390",
    "end": "2108829"
  }
]
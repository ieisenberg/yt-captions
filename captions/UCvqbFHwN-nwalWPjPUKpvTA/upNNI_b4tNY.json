[
  {
    "text": "all right so um the title is was as a",
    "start": "80",
    "end": "2320"
  },
  {
    "text": "wrong time for RM because I I I",
    "start": "2320",
    "end": "4839"
  },
  {
    "text": "submitted the talk with a mild title so",
    "start": "4839",
    "end": "7120"
  },
  {
    "text": "that it can be accepted the real title",
    "start": "7120",
    "end": "9400"
  },
  {
    "text": "is this you know so um as Liam has said",
    "start": "9400",
    "end": "13160"
  },
  {
    "text": "you know uh I've been um attending",
    "start": "13160",
    "end": "15480"
  },
  {
    "text": "waterm day for uh three years you know",
    "start": "15480",
    "end": "18119"
  },
  {
    "text": "um every single coupon I think you know",
    "start": "18119",
    "end": "20000"
  },
  {
    "text": "that's six couc counts already um so",
    "start": "20000",
    "end": "22519"
  },
  {
    "text": "people have always asked what's the",
    "start": "22519",
    "end": "24080"
  },
  {
    "text": "killer application was you know when we",
    "start": "24080",
    "end": "26359"
  },
  {
    "text": "started it was a web application compile",
    "start": "26359",
    "end": "29199"
  },
  {
    "text": "c c program into web application and",
    "start": "29199",
    "end": "31359"
  },
  {
    "text": "Adobe Photoshop on the web and then it",
    "start": "31359",
    "end": "33480"
  },
  {
    "text": "was blockchain applications running",
    "start": "33480",
    "end": "35000"
  },
  {
    "text": "smart contracts and all that stuff right",
    "start": "35000",
    "end": "36719"
  },
  {
    "text": "you know um which is actually highly",
    "start": "36719",
    "end": "38520"
  },
  {
    "text": "successful but it's a little far away",
    "start": "38520",
    "end": "40920"
  },
  {
    "text": "from the mainstream and uh so we are",
    "start": "40920",
    "end": "44160"
  },
  {
    "text": "still searching for what is a killer",
    "start": "44160",
    "end": "46559"
  },
  {
    "text": "application of wasm you know I have come",
    "start": "46559",
    "end": "49239"
  },
  {
    "text": "to realize in the past I think year or",
    "start": "49239",
    "end": "51760"
  },
  {
    "text": "so wasm is not a Docker replacement we",
    "start": "51760",
    "end": "55879"
  },
  {
    "text": "had a Docker plus wasm announcement last",
    "start": "55879",
    "end": "58000"
  },
  {
    "text": "year at uh in Detroit at kubon",
    "start": "58000",
    "end": "60480"
  },
  {
    "text": "it is not a goal on um replacement it is",
    "start": "60480",
    "end": "63079"
  },
  {
    "text": "not to replace wholesale microservices",
    "start": "63079",
    "end": "65560"
  },
  {
    "text": "or servess functions written in goal I",
    "start": "65560",
    "end": "67880"
  },
  {
    "text": "have come to um a you know a rather",
    "start": "67880",
    "end": "71200"
  },
  {
    "text": "strong conviction it is a python",
    "start": "71200",
    "end": "72759"
  },
  {
    "text": "replacement and I'll tell you why I I",
    "start": "72759",
    "end": "75400"
  },
  {
    "text": "hope I make it entertaining so before we",
    "start": "75400",
    "end": "78960"
  },
  {
    "text": "even start you know there's a there's a",
    "start": "78960",
    "end": "81200"
  },
  {
    "text": "big issue with the industry is that uh",
    "start": "81200",
    "end": "83520"
  },
  {
    "text": "the large language model doesn't know",
    "start": "83520",
    "end": "85400"
  },
  {
    "text": "wasm okay so I I asked L to what is wasm",
    "start": "85400",
    "end": "89520"
  },
  {
    "text": "it gave answer that is I think largely",
    "start": "89520",
    "end": "92040"
  },
  {
    "text": "correct however it's mostly geared",
    "start": "92040",
    "end": "93799"
  },
  {
    "text": "toward web application so it's not even",
    "start": "93799",
    "end": "96079"
  },
  {
    "text": "in blockchain yet it's still in the web",
    "start": "96079",
    "end": "98159"
  },
  {
    "text": "space if I ask it a more complex",
    "start": "98159",
    "end": "101119"
  },
  {
    "text": "question it would give a outrageous",
    "start": "101119",
    "end": "104320"
  },
  {
    "text": "answer right you know so what is was we",
    "start": "104320",
    "end": "106040"
  },
  {
    "text": "have heard about wasi in today right is",
    "start": "106040",
    "end": "108079"
  },
  {
    "text": "um web assembly system interface for",
    "start": "108079",
    "end": "109880"
  },
  {
    "text": "neural network but said it's wide angle",
    "start": "109880",
    "end": "111880"
  },
  {
    "text": "spectral image in neural network I",
    "start": "111880",
    "end": "114240"
  },
  {
    "text": "actually searched Google on here to say",
    "start": "114240",
    "end": "116680"
  },
  {
    "text": "is does such thing exist did it learn",
    "start": "116680",
    "end": "119039"
  },
  {
    "text": "somewhere it doesn't exist okay you know",
    "start": "119039",
    "end": "121240"
  },
  {
    "text": "so it completely made it up so it",
    "start": "121240",
    "end": "122920"
  },
  {
    "text": "doesn't know was it doesn't know wasi so",
    "start": "122920",
    "end": "125600"
  },
  {
    "text": "you know so um now you know I I find",
    "start": "125600",
    "end": "128319"
  },
  {
    "text": "depressed because every other um um",
    "start": "128319",
    "end": "131520"
  },
  {
    "text": "company every other subject has now",
    "start": "131520",
    "end": "133239"
  },
  {
    "text": "trained their own um you know large",
    "start": "133239",
    "end": "135400"
  },
  {
    "text": "language model to answer questions in",
    "start": "135400",
    "end": "137040"
  },
  {
    "text": "the way that they like so right before",
    "start": "137040",
    "end": "139920"
  },
  {
    "text": "the conference I I decided to train uh a",
    "start": "139920",
    "end": "143239"
  },
  {
    "text": "new large language model called laa you",
    "start": "143239",
    "end": "146000"
  },
  {
    "text": "know it's uh Lama for wasam right you",
    "start": "146000",
    "end": "148120"
  },
  {
    "text": "know that's uh so basically I write up",
    "start": "148120",
    "end": "151120"
  },
  {
    "text": "um uh less than 100 question and answers",
    "start": "151120",
    "end": "153360"
  },
  {
    "text": "you know instruction Tony and then put",
    "start": "153360",
    "end": "155160"
  },
  {
    "text": "that to llama um to Lama 2 and uh um and",
    "start": "155160",
    "end": "159640"
  },
  {
    "text": "then it computes for for some time so my",
    "start": "159640",
    "end": "163480"
  },
  {
    "text": "first demo I'm going to show you is how",
    "start": "163480",
    "end": "164920"
  },
  {
    "text": "to do AI inference with this large",
    "start": "164920",
    "end": "166840"
  },
  {
    "text": "language model this L large language",
    "start": "166840",
    "end": "168599"
  },
  {
    "text": "model is the same size as Lama 27b so",
    "start": "168599",
    "end": "171159"
  },
  {
    "text": "it's about 5 gigabytes you know so let's",
    "start": "171159",
    "end": "173640"
  },
  {
    "text": "go through the step the steps are really",
    "start": "173640",
    "end": "175680"
  },
  {
    "text": "easy so the first is really uh to",
    "start": "175680",
    "end": "178000"
  },
  {
    "text": "install w m on your device you know it's",
    "start": "178000",
    "end": "179879"
  },
  {
    "text": "uh it's a one line of command it's easy",
    "start": "179879",
    "end": "182599"
  },
  {
    "text": "install you know it installs on um the",
    "start": "182599",
    "end": "185360"
  },
  {
    "text": "Mac on PC it installs on BlackBerry Pi",
    "start": "185360",
    "end": "188799"
  },
  {
    "text": "it is although Blackberry Pi do",
    "start": "188799",
    "end": "190680"
  },
  {
    "text": "inference is a little slow but I I",
    "start": "190680",
    "end": "192280"
  },
  {
    "text": "install it on Jetson Nano you know which",
    "start": "192280",
    "end": "193959"
  },
  {
    "text": "is uh um you know zvia iot device you",
    "start": "193959",
    "end": "196959"
  },
  {
    "text": "know so it's um one line of command you",
    "start": "196959",
    "end": "198959"
  },
  {
    "text": "install it and then copy over inference",
    "start": "198959",
    "end": "202120"
  },
  {
    "text": "app this is um you know I GNA get into",
    "start": "202120",
    "end": "205879"
  },
  {
    "text": "more details about this but I think this",
    "start": "205879",
    "end": "208319"
  },
  {
    "text": "really achieves what we have set out to",
    "start": "208319",
    "end": "210519"
  },
  {
    "text": "do all those years ago with Java it's",
    "start": "210519",
    "end": "212480"
  },
  {
    "text": "right once run anywhere you know with",
    "start": "212480",
    "end": "214519"
  },
  {
    "text": "Java it has only been about operating",
    "start": "214519",
    "end": "216560"
  },
  {
    "text": "system and CPUs right but with wasm as",
    "start": "216560",
    "end": "220040"
  },
  {
    "text": "we all see with wasi we are now",
    "start": "220040",
    "end": "222319"
  },
  {
    "text": "expanding to gpus and other accelerators",
    "start": "222319",
    "end": "225000"
  },
  {
    "text": "as well so I have a single compiled wasm",
    "start": "225000",
    "end": "227959"
  },
  {
    "text": "application it's written in Rust and the",
    "start": "227959",
    "end": "230120"
  },
  {
    "text": "whole compiled artifact is less than 2",
    "start": "230120",
    "end": "232000"
  },
  {
    "text": "megabytes and I I I specifically said",
    "start": "232000",
    "end": "235000"
  },
  {
    "text": "it's not to install application to copy",
    "start": "235000",
    "end": "237319"
  },
  {
    "text": "over you just uh download it and copy it",
    "start": "237319",
    "end": "239959"
  },
  {
    "text": "put it anywhere on your on your hard",
    "start": "239959",
    "end": "242040"
  },
  {
    "text": "drive and you'll be able to run it and",
    "start": "242040",
    "end": "243799"
  },
  {
    "text": "I'll show you it can take the full",
    "start": "243799",
    "end": "245360"
  },
  {
    "text": "advantage of the whatever the",
    "start": "245360",
    "end": "247480"
  },
  {
    "text": "accelerator that you have on your",
    "start": "247480",
    "end": "249480"
  },
  {
    "text": "device and uh copy over uh then download",
    "start": "249480",
    "end": "254319"
  },
  {
    "text": "the L so um before we go download the um",
    "start": "254319",
    "end": "258359"
  },
  {
    "text": "you know so here is the link to download",
    "start": "258359",
    "end": "259919"
  },
  {
    "text": "the the the the wasm tuned wasm",
    "start": "259919",
    "end": "262720"
  },
  {
    "text": "instruction tuned um lav 2 model right",
    "start": "262720",
    "end": "265240"
  },
  {
    "text": "you know we call it lava and uh but uh",
    "start": "265240",
    "end": "268000"
  },
  {
    "text": "in fact you know uh if you follow",
    "start": "268000",
    "end": "270000"
  },
  {
    "text": "Twitter and since Facebook launched",
    "start": "270000",
    "end": "271960"
  },
  {
    "text": "llama 2 like three months ago I can't",
    "start": "271960",
    "end": "273560"
  },
  {
    "text": "believe it's only three months ago there",
    "start": "273560",
    "end": "275600"
  },
  {
    "text": "are over 2,000 different fine tuned",
    "start": "275600",
    "end": "279199"
  },
  {
    "text": "llama models that's available in the",
    "start": "279199",
    "end": "280639"
  },
  {
    "text": "marketplace there's um you know you can",
    "start": "280639",
    "end": "282400"
  },
  {
    "text": "see those every single day multiple",
    "start": "282400",
    "end": "284639"
  },
  {
    "text": "times every single day that claims to",
    "start": "284639",
    "end": "286560"
  },
  {
    "text": "unreach the state of art performance",
    "start": "286560",
    "end": "288440"
  },
  {
    "text": "right you know so here are just some",
    "start": "288440",
    "end": "290000"
  },
  {
    "text": "examples that we can run with was match",
    "start": "290000",
    "end": "292160"
  },
  {
    "text": "right you know those are you know those",
    "start": "292160",
    "end": "294160"
  },
  {
    "text": "um what they call the two open source",
    "start": "294160",
    "end": "295759"
  },
  {
    "text": "models M trial the AWS two open source",
    "start": "295759",
    "end": "298240"
  },
  {
    "text": "model M trial light tiny llama which is",
    "start": "298240",
    "end": "300720"
  },
  {
    "text": "a smaller one open chat you know which",
    "start": "300720",
    "end": "302600"
  },
  {
    "text": "is uh um compared with chat GPT 3.5 you",
    "start": "302600",
    "end": "306280"
  },
  {
    "text": "know all that stuff right you know so",
    "start": "306280",
    "end": "307639"
  },
  {
    "text": "there's a large variety of models um you",
    "start": "307639",
    "end": "310240"
  },
  {
    "text": "know um but what I want to demonstrate",
    "start": "310240",
    "end": "312240"
  },
  {
    "text": "today is to um you know uh to run uh",
    "start": "312240",
    "end": "315639"
  },
  {
    "text": "instruction tuned um llama model that",
    "start": "315639",
    "end": "318039"
  },
  {
    "text": "with with waterm knowledge",
    "start": "318039",
    "end": "321360"
  },
  {
    "text": "so then there all that to it you know so",
    "start": "321360",
    "end": "324919"
  },
  {
    "text": "you know and if you sit here with your",
    "start": "324919",
    "end": "326919"
  },
  {
    "text": "laptop I highly encourage you to just go",
    "start": "326919",
    "end": "329039"
  },
  {
    "text": "through that steps because in in F the",
    "start": "329039",
    "end": "331880"
  },
  {
    "text": "longest step is the last step which you",
    "start": "331880",
    "end": "333479"
  },
  {
    "text": "download the large language model is 5",
    "start": "333479",
    "end": "335080"
  },
  {
    "text": "gigabytes I think the conference Wi-Fi",
    "start": "335080",
    "end": "336680"
  },
  {
    "text": "is pretty fast it's goes like um you",
    "start": "336680",
    "end": "338639"
  },
  {
    "text": "know um 10 megabytes per second so",
    "start": "338639",
    "end": "340680"
  },
  {
    "text": "before the end within 10 minutes or or",
    "start": "340680",
    "end": "342919"
  },
  {
    "text": "15 minutes you will have a large",
    "start": "342919",
    "end": "344120"
  },
  {
    "text": "language model sitting on your own",
    "start": "344120",
    "end": "345280"
  },
  {
    "text": "computer you know that you would be able",
    "start": "345280",
    "end": "346960"
  },
  {
    "text": "to do the same thing that I'm going to",
    "start": "346960",
    "end": "348880"
  },
  {
    "text": "do in the minute let me see so let's",
    "start": "348880",
    "end": "353039"
  },
  {
    "text": "look at the example so the the example",
    "start": "353039",
    "end": "355960"
  },
  {
    "text": "really is um I have already downloaded",
    "start": "355960",
    "end": "357919"
  },
  {
    "text": "the the large language model and and I",
    "start": "357919",
    "end": "359800"
  },
  {
    "text": "have WM AG installed you know those are",
    "start": "359800",
    "end": "361280"
  },
  {
    "text": "the two prerequisites and I have the",
    "start": "361280",
    "end": "363720"
  },
  {
    "text": "Llama Das chat. wasm file I going to",
    "start": "363720",
    "end": "366479"
  },
  {
    "text": "show you the source code in a minute but",
    "start": "366479",
    "end": "368199"
  },
  {
    "text": "you know that's um but that's the",
    "start": "368199",
    "end": "369520"
  },
  {
    "text": "crossplatform wasm binary that I put on",
    "start": "369520",
    "end": "372680"
  },
  {
    "text": "my Mac so all this is running on my Mac",
    "start": "372680",
    "end": "374560"
  },
  {
    "text": "you know so I uh unlike um you know my",
    "start": "374560",
    "end": "377319"
  },
  {
    "text": "previous demos I was always nervous",
    "start": "377319",
    "end": "378880"
  },
  {
    "text": "about whether the demo going to work or",
    "start": "378880",
    "end": "380160"
  },
  {
    "text": "not this I'm not because nothing on this",
    "start": "380160",
    "end": "382960"
  },
  {
    "text": "is online everything is local okay so",
    "start": "382960",
    "end": "385560"
  },
  {
    "text": "it's all on the same device so it print",
    "start": "385560",
    "end": "387560"
  },
  {
    "text": "out some information about my Mac so now",
    "start": "387560",
    "end": "390039"
  },
  {
    "text": "I asked the same question I asked before",
    "start": "390039",
    "end": "392120"
  },
  {
    "text": "what",
    "start": "392120",
    "end": "393240"
  },
  {
    "text": "is",
    "start": "393240",
    "end": "394759"
  },
  {
    "text": "w so just keep in mind this is a 5 gabt",
    "start": "394759",
    "end": "399160"
  },
  {
    "text": "um a model so it's wasm needs to read it",
    "start": "399160",
    "end": "402080"
  },
  {
    "text": "into into the memory and then it exports",
    "start": "402080",
    "end": "405479"
  },
  {
    "text": "um it answers the question by doing the",
    "start": "405479",
    "end": "407520"
  },
  {
    "text": "inference on the GPU you know um it can",
    "start": "407520",
    "end": "410160"
  },
  {
    "text": "only achieve this speed by by by using",
    "start": "410160",
    "end": "412240"
  },
  {
    "text": "the GPU right you know you see the the",
    "start": "412240",
    "end": "414560"
  },
  {
    "text": "the the word that get typed out it's",
    "start": "414560",
    "end": "416199"
  },
  {
    "text": "faster than I can speak so I'll get a",
    "start": "416199",
    "end": "418919"
  },
  {
    "text": "head start with the next question what",
    "start": "418919",
    "end": "421560"
  },
  {
    "text": "is",
    "start": "421560",
    "end": "423319"
  },
  {
    "text": "ah was znn but you can see the first it",
    "start": "423319",
    "end": "428160"
  },
  {
    "text": "gives us short answer and the short",
    "start": "428160",
    "end": "430000"
  },
  {
    "text": "answer is largely correct is talk about",
    "start": "430000",
    "end": "432160"
  },
  {
    "text": "virtual machine aspect of the BM it",
    "start": "432160",
    "end": "433720"
  },
  {
    "text": "doesn't really talk about web",
    "start": "433720",
    "end": "434800"
  },
  {
    "text": "application anymore you know it talks",
    "start": "434800",
    "end": "436400"
  },
  {
    "text": "about this instruction set now you can",
    "start": "436400",
    "end": "438440"
  },
  {
    "text": "also answer what the accurately it's a",
    "start": "438440",
    "end": "441199"
  },
  {
    "text": "system interface for neural networks",
    "start": "441199",
    "end": "442919"
  },
  {
    "text": "right it allows wasm map to use and",
    "start": "442919",
    "end": "445520"
  },
  {
    "text": "integrate with different neural network",
    "start": "445520",
    "end": "447360"
  },
  {
    "text": "Frameworks and uh the demo you are",
    "start": "447360",
    "end": "449560"
  },
  {
    "text": "seeing right now is to so we have",
    "start": "449560",
    "end": "451960"
  },
  {
    "text": "integration with Tor flow we can",
    "start": "451960",
    "end": "453960"
  },
  {
    "text": "integration with py torch we can",
    "start": "453960",
    "end": "455560"
  },
  {
    "text": "integration with like uh and has just",
    "start": "455560",
    "end": "457800"
  },
  {
    "text": "demoed you know that's U with open wo",
    "start": "457800",
    "end": "460360"
  },
  {
    "text": "and uh here you are seeing integration",
    "start": "460360",
    "end": "462800"
  },
  {
    "text": "with the ne Network framework called uh",
    "start": "462800",
    "end": "465159"
  },
  {
    "text": "gml which is a new um um um you know an",
    "start": "465159",
    "end": "468919"
  },
  {
    "text": "inference framework that designed for",
    "start": "468919",
    "end": "470280"
  },
  {
    "text": "the Lama to large language model right",
    "start": "470280",
    "end": "472319"
  },
  {
    "text": "so you know so then we can say",
    "start": "472319",
    "end": "475720"
  },
  {
    "text": "which wrong",
    "start": "475720",
    "end": "478319"
  },
  {
    "text": "times",
    "start": "478319",
    "end": "480199"
  },
  {
    "text": "supported you know so just to show this",
    "start": "480199",
    "end": "483159"
  },
  {
    "text": "is um conversational because if I just",
    "start": "483159",
    "end": "486199"
  },
  {
    "text": "ask a model which WR time support it it",
    "start": "486199",
    "end": "488800"
  },
  {
    "text": "would have no idea what I'm asking",
    "start": "488800",
    "end": "490159"
  },
  {
    "text": "because what's it refer to right but now",
    "start": "490159",
    "end": "492599"
  },
  {
    "text": "but with this um with the context of",
    "start": "492599",
    "end": "495840"
  },
  {
    "text": "this conversation it actually knows that",
    "start": "495840",
    "end": "499120"
  },
  {
    "text": "you know actually it can can it can pick",
    "start": "499120",
    "end": "501199"
  },
  {
    "text": "from wasi and Orum you know as",
    "start": "501199",
    "end": "503520"
  },
  {
    "text": "replacement for yet right which one",
    "start": "503520",
    "end": "505039"
  },
  {
    "text": "refers to it actually picked wasm and it",
    "start": "505039",
    "end": "507759"
  },
  {
    "text": "says wasm WR times are you was Ed was",
    "start": "507759",
    "end": "510080"
  },
  {
    "text": "time you know that's um obviously you",
    "start": "510080",
    "end": "512279"
  },
  {
    "text": "know I'm biased because I created the",
    "start": "512279",
    "end": "514360"
  },
  {
    "text": "the the 100 question that to train this",
    "start": "514360",
    "end": "516399"
  },
  {
    "text": "right you know so so you know that's uh",
    "start": "516399",
    "end": "519120"
  },
  {
    "text": "um but then let me ask the last question",
    "start": "519120",
    "end": "521279"
  },
  {
    "text": "which is uh slightly longer is uh how do",
    "start": "521279",
    "end": "526240"
  },
  {
    "text": "I run",
    "start": "526240",
    "end": "529680"
  },
  {
    "text": "AI",
    "start": "529680",
    "end": "531640"
  },
  {
    "text": "workloads",
    "start": "531640",
    "end": "534000"
  },
  {
    "text": "in serverless",
    "start": "534000",
    "end": "538200"
  },
  {
    "text": "functions",
    "start": "538200",
    "end": "540160"
  },
  {
    "text": "okay you know so",
    "start": "540160",
    "end": "541680"
  },
  {
    "text": "this the the startup time is a little",
    "start": "541680",
    "end": "544360"
  },
  {
    "text": "slow because you know every time it",
    "start": "544360",
    "end": "545920"
  },
  {
    "text": "needs to load the five 5 gigabytes uh",
    "start": "545920",
    "end": "549480"
  },
  {
    "text": "large language model into memory and",
    "start": "549480",
    "end": "551360"
  },
  {
    "text": "then then when you start to uh do",
    "start": "551360",
    "end": "553800"
  },
  {
    "text": "inference you see the uh you see the",
    "start": "553800",
    "end": "555560"
  },
  {
    "text": "streaming text which is which becomes",
    "start": "555560",
    "end": "557920"
  },
  {
    "text": "really fast right you know so so",
    "start": "557920",
    "end": "559760"
  },
  {
    "text": "basically you know that's uh um you know",
    "start": "559760",
    "end": "562519"
  },
  {
    "text": "um so that's it for this example you",
    "start": "562519",
    "end": "564959"
  },
  {
    "text": "know that's um so what I'm trying to say",
    "start": "564959",
    "end": "567120"
  },
  {
    "text": "is you don't have to use this model this",
    "start": "567120",
    "end": "568920"
  },
  {
    "text": "model model is sort of a toy this model",
    "start": "568920",
    "end": "570560"
  },
  {
    "text": "is what I uh you know what I have",
    "start": "570560",
    "end": "572040"
  },
  {
    "text": "trained and with uh with my own Ed",
    "start": "572040",
    "end": "574839"
  },
  {
    "text": "questions you know that's um you know",
    "start": "574839",
    "end": "576560"
  },
  {
    "text": "over a weekend and uh um so but get one",
    "start": "576560",
    "end": "579839"
  },
  {
    "text": "of the state of art models you know",
    "start": "579839",
    "end": "581360"
  },
  {
    "text": "there's a ton of them and they are",
    "start": "581360",
    "end": "583000"
  },
  {
    "text": "coming out every single day some of them",
    "start": "583000",
    "end": "584920"
  },
  {
    "text": "are doing role playing some of them are",
    "start": "584920",
    "end": "586880"
  },
  {
    "text": "doing medical QA some of them are",
    "start": "586880",
    "end": "588839"
  },
  {
    "text": "education some some of them are you know",
    "start": "588839",
    "end": "591720"
  },
  {
    "text": "um content summarization so there's a",
    "start": "591720",
    "end": "593640"
  },
  {
    "text": "lot of things you can play with on your",
    "start": "593640",
    "end": "595000"
  },
  {
    "text": "own computer by using wome okay and uh",
    "start": "595000",
    "end": "598720"
  },
  {
    "text": "so",
    "start": "598720",
    "end": "600600"
  },
  {
    "text": "let me continue my presentation so this",
    "start": "600600",
    "end": "605399"
  },
  {
    "text": "so now we see on the command line I can",
    "start": "605399",
    "end": "608040"
  },
  {
    "text": "um I can run lar language model and ask",
    "start": "608040",
    "end": "609839"
  },
  {
    "text": "question and and chat with it right you",
    "start": "609839",
    "end": "612399"
  },
  {
    "text": "know so I want to show you what the code",
    "start": "612399",
    "end": "615720"
  },
  {
    "text": "looks like you know because um you know",
    "start": "615720",
    "end": "618440"
  },
  {
    "text": "isn't something like this going to be",
    "start": "618440",
    "end": "620079"
  },
  {
    "text": "very complex and you say you write it in",
    "start": "620079",
    "end": "622519"
  },
  {
    "text": "Rust isn't the r the difficult language",
    "start": "622519",
    "end": "624800"
  },
  {
    "text": "let's say the whole the the the core",
    "start": "624800",
    "end": "626760"
  },
  {
    "text": "part of the application can be fit into",
    "start": "626760",
    "end": "628600"
  },
  {
    "text": "one people BD slide with the size that",
    "start": "628600",
    "end": "631200"
  },
  {
    "text": "is large enough at the back of the room",
    "start": "631200",
    "end": "632920"
  },
  {
    "text": "you'll be able to see it you know this",
    "start": "632920",
    "end": "634880"
  },
  {
    "text": "is how simple it is right you know so",
    "start": "634880",
    "end": "637000"
  },
  {
    "text": "this is um largely thanks to the API",
    "start": "637000",
    "end": "639480"
  },
  {
    "text": "design on was so basically you um you",
    "start": "639480",
    "end": "642279"
  },
  {
    "text": "know um um um load the model in start a",
    "start": "642279",
    "end": "644680"
  },
  {
    "text": "contact and you pass data to it and then",
    "start": "644680",
    "end": "646519"
  },
  {
    "text": "you pass the inference the the the the",
    "start": "646519",
    "end": "649399"
  },
  {
    "text": "the the text you want to you want to fit",
    "start": "649399",
    "end": "651079"
  },
  {
    "text": "into it and then the result it returns",
    "start": "651079",
    "end": "653079"
  },
  {
    "text": "back is in the buffer and then you",
    "start": "653079",
    "end": "654320"
  },
  {
    "text": "decode the buffer and you get the result",
    "start": "654320",
    "end": "656279"
  },
  {
    "text": "so it's a very very simple application",
    "start": "656279",
    "end": "658560"
  },
  {
    "text": "and this application I also want to uh",
    "start": "658560",
    "end": "660639"
  },
  {
    "text": "point out is that you know uh if you",
    "start": "660639",
    "end": "662800"
  },
  {
    "text": "look at line two it's execution Target",
    "start": "662800",
    "end": "664760"
  },
  {
    "text": "Auto means that it's um automatically",
    "start": "664760",
    "end": "667760"
  },
  {
    "text": "searches for whatever accelerator is",
    "start": "667760",
    "end": "670600"
  },
  {
    "text": "available on this device so if I run the",
    "start": "670600",
    "end": "672760"
  },
  {
    "text": "same application on a aidia GPU device",
    "start": "672760",
    "end": "677000"
  },
  {
    "text": "it going to go a lot faster than how I",
    "start": "677000",
    "end": "679360"
  },
  {
    "text": "run it on the Mac if I run it on the",
    "start": "679360",
    "end": "681040"
  },
  {
    "text": "older Mac that doesn't have a GPU it",
    "start": "681040",
    "end": "683200"
  },
  {
    "text": "going to go a lot slower you know it's",
    "start": "683200",
    "end": "685040"
  },
  {
    "text": "about order magnitude difference in in",
    "start": "685040",
    "end": "688000"
  },
  {
    "text": "in those three different um you know",
    "start": "688000",
    "end": "689800"
  },
  {
    "text": "scenarios but the point is it is um you",
    "start": "689800",
    "end": "692600"
  },
  {
    "text": "know it is automate U portability",
    "start": "692600",
    "end": "694880"
  },
  {
    "text": "solution you know so you have wasm you",
    "start": "694880",
    "end": "696279"
  },
  {
    "text": "have a single WM file compiled with a",
    "start": "696279",
    "end": "698040"
  },
  {
    "text": "single source code and you compile and",
    "start": "698040",
    "end": "700240"
  },
  {
    "text": "then you copy it over to different",
    "start": "700240",
    "end": "701959"
  },
  {
    "text": "devices and it would automatically",
    "start": "701959",
    "end": "704160"
  },
  {
    "text": "figure out whether the device has GPU",
    "start": "704160",
    "end": "706279"
  },
  {
    "text": "whether the device has Apple silicon",
    "start": "706279",
    "end": "708040"
  },
  {
    "text": "whether you know what kind of",
    "start": "708040",
    "end": "709360"
  },
  {
    "text": "accelerator this device can use and then",
    "start": "709360",
    "end": "711040"
  },
  {
    "text": "automatically use it right so you know",
    "start": "711040",
    "end": "713519"
  },
  {
    "text": "and now it has um um you know we we we",
    "start": "713519",
    "end": "717240"
  },
  {
    "text": "we we created this rust application but",
    "start": "717240",
    "end": "719959"
  },
  {
    "text": "you know that's our goal is soon we'll",
    "start": "719959",
    "end": "721600"
  },
  {
    "text": "have a JavaScript API for this um for",
    "start": "721600",
    "end": "724880"
  },
  {
    "text": "this specific thing as well running",
    "start": "724880",
    "end": "727040"
  },
  {
    "text": "inside quickjs you know um by connecting",
    "start": "727040",
    "end": "729839"
  },
  {
    "text": "quickjs into with the um with the w API",
    "start": "729839",
    "end": "734920"
  },
  {
    "text": "so with that we can do a lot more by",
    "start": "734920",
    "end": "738600"
  },
  {
    "text": "leveraging the WM ecosystem so in this",
    "start": "738600",
    "end": "741720"
  },
  {
    "text": "example we created another application",
    "start": "741720",
    "end": "743880"
  },
  {
    "text": "by the way those are all open source you",
    "start": "743880",
    "end": "745279"
  },
  {
    "text": "can go you know just look at their",
    "start": "745279",
    "end": "747639"
  },
  {
    "text": "roster source code and compile",
    "start": "747639",
    "end": "749519"
  },
  {
    "text": "it start a server what this server does",
    "start": "749519",
    "end": "751880"
  },
  {
    "text": "This Server listens to Port 880 what",
    "start": "751880",
    "end": "754240"
  },
  {
    "text": "this server does is that it's um um it's",
    "start": "754240",
    "end": "759160"
  },
  {
    "text": "mimic the open AI server so meaning that",
    "start": "759160",
    "end": "761480"
  },
  {
    "text": "you can use the open AI Json format to",
    "start": "761480",
    "end": "764399"
  },
  {
    "text": "send request to the server and the",
    "start": "764399",
    "end": "766440"
  },
  {
    "text": "server would would response in the open",
    "start": "766440",
    "end": "768519"
  },
  {
    "text": "AI Json format why do we want to do that",
    "start": "768519",
    "end": "772079"
  },
  {
    "text": "is",
    "start": "772079",
    "end": "773920"
  },
  {
    "text": "because",
    "start": "773920",
    "end": "776360"
  },
  {
    "text": "oh it's because there's a large",
    "start": "776360",
    "end": "778839"
  },
  {
    "text": "ecosystem of um uh software that has",
    "start": "778839",
    "end": "782720"
  },
  {
    "text": "been developed around the the open a and",
    "start": "782720",
    "end": "785440"
  },
  {
    "text": "chat gbt ecosystem so you see things",
    "start": "785440",
    "end": "788160"
  },
  {
    "text": "like L chain llama index you know those",
    "start": "788160",
    "end": "791399"
  },
  {
    "text": "are I think barely one year old project",
    "start": "791399",
    "end": "793959"
  },
  {
    "text": "and they have you know tens of thousands",
    "start": "793959",
    "end": "795720"
  },
  {
    "text": "of GitHub Stars right you know that's uh",
    "start": "795720",
    "end": "797639"
  },
  {
    "text": "you know those those Frameworks are",
    "start": "797639",
    "end": "799920"
  },
  {
    "text": "designed to build chatbot or designed to",
    "start": "799920",
    "end": "802279"
  },
  {
    "text": "build AI agents using the open AI",
    "start": "802279",
    "end": "805079"
  },
  {
    "text": "interface right you know so once we have",
    "start": "805079",
    "end": "807720"
  },
  {
    "text": "once we turn the the using rust and wasm",
    "start": "807720",
    "end": "811279"
  },
  {
    "text": "to turn the large language model service",
    "start": "811279",
    "end": "813000"
  },
  {
    "text": "into a API into a micros service we all",
    "start": "813000",
    "end": "815519"
  },
  {
    "text": "be able to do a lot more you know by",
    "start": "815519",
    "end": "818040"
  },
  {
    "text": "leveraging those ecosystem tools but",
    "start": "818040",
    "end": "820399"
  },
  {
    "text": "there's more you know so I I skip over",
    "start": "820399",
    "end": "823560"
  },
  {
    "text": "this side and then I come back you know",
    "start": "823560",
    "end": "825560"
  },
  {
    "text": "um I don't know if I have time to do the",
    "start": "825560",
    "end": "828959"
  },
  {
    "text": "to do the demo maybe I do you know so I",
    "start": "828959",
    "end": "831320"
  },
  {
    "text": "because this is just one minute so I'll",
    "start": "831320",
    "end": "833560"
  },
  {
    "text": "show this demo was just ready today so",
    "start": "833560",
    "end": "835839"
  },
  {
    "text": "you know we um so so um we build the was",
    "start": "835839",
    "end": "839240"
  },
  {
    "text": "shim for Ron wasi and through Ron wasi",
    "start": "839240",
    "end": "841240"
  },
  {
    "text": "we can integrate into container D and",
    "start": "841240",
    "end": "843320"
  },
  {
    "text": "then it's it can be driven by Docker by",
    "start": "843320",
    "end": "846440"
  },
  {
    "text": "podman by um by by kones right you know",
    "start": "846440",
    "end": "849959"
  },
  {
    "text": "so in this demo we have a new uh we have",
    "start": "849959",
    "end": "852759"
  },
  {
    "text": "a new uh unmerged version of the of Rong",
    "start": "852759",
    "end": "855720"
  },
  {
    "text": "wasi so that we can use Rong wasi to run",
    "start": "855720",
    "end": "859320"
  },
  {
    "text": "the large language model as well so that",
    "start": "859320",
    "end": "861320"
  },
  {
    "text": "allows um application developers to use",
    "start": "861320",
    "end": "864639"
  },
  {
    "text": "to use Docker to do it right you know so",
    "start": "864639",
    "end": "866600"
  },
  {
    "text": "one of the most interesting thing about",
    "start": "866600",
    "end": "868120"
  },
  {
    "text": "Docker if you look at um you know um",
    "start": "868120",
    "end": "870839"
  },
  {
    "text": "it's uh um you know um U people's",
    "start": "870839",
    "end": "872680"
  },
  {
    "text": "criticism about it it's uh it's not",
    "start": "872680",
    "end": "874759"
  },
  {
    "text": "crossplatform not only the and you know",
    "start": "874759",
    "end": "877639"
  },
  {
    "text": "you need for the same workload you",
    "start": "877639",
    "end": "879880"
  },
  {
    "text": "different CPU you need a different",
    "start": "879880",
    "end": "881120"
  },
  {
    "text": "Docker format on different GPU you need",
    "start": "881120",
    "end": "883560"
  },
  {
    "text": "a different proprietary format for for",
    "start": "883560",
    "end": "885120"
  },
  {
    "text": "the media driver and all that stuff",
    "start": "885120",
    "end": "886680"
  },
  {
    "text": "right you know and with wasm and we can",
    "start": "886680",
    "end": "890000"
  },
  {
    "text": "um um normalize those differences we can",
    "start": "890000",
    "end": "892399"
  },
  {
    "text": "have us um you know um by by having",
    "start": "892399",
    "end": "894920"
  },
  {
    "text": "wrong water wrong wrong the wasm",
    "start": "894920",
    "end": "897440"
  },
  {
    "text": "workload for a inference you know it's",
    "start": "897440",
    "end": "900399"
  },
  {
    "text": "this is not a chart model so so the text",
    "start": "900399",
    "end": "902240"
  },
  {
    "text": "just goes on until it's finished right",
    "start": "902240",
    "end": "904120"
  },
  {
    "text": "you know it asks what's life",
    "start": "904120",
    "end": "905440"
  },
  {
    "text": "achievements of of uh of alimer right",
    "start": "905440",
    "end": "907959"
  },
  {
    "text": "you know that's so it gives a lot of",
    "start": "907959",
    "end": "909519"
  },
  {
    "text": "wrong answers it gives to the you know",
    "start": "909519",
    "end": "911759"
  },
  {
    "text": "schools he had never went been to",
    "start": "911759",
    "end": "913600"
  },
  {
    "text": "sometimes he said he got the Nobel Prize",
    "start": "913600",
    "end": "915839"
  },
  {
    "text": "which he never did you know that's a but",
    "start": "915839",
    "end": "917639"
  },
  {
    "text": "you know that's you get the idea you",
    "start": "917639",
    "end": "918959"
  },
  {
    "text": "know this a llama model is a base you",
    "start": "918959",
    "end": "921040"
  },
  {
    "text": "know once you can run that you can run a",
    "start": "921040",
    "end": "922959"
  },
  {
    "text": "lot of other things so with the um with",
    "start": "922959",
    "end": "926480"
  },
  {
    "text": "the kubernetes support sorry",
    "start": "926480",
    "end": "929279"
  },
  {
    "text": "me okay with a kubernetes support you",
    "start": "929279",
    "end": "933120"
  },
  {
    "text": "can now um run this",
    "start": "933120",
    "end": "937519"
  },
  {
    "text": "in run the AI workload in your your",
    "start": "937519",
    "end": "940839"
  },
  {
    "text": "cluster leveraging the GPU device or",
    "start": "940839",
    "end": "944279"
  },
  {
    "text": "other um AI accelerator that you may or",
    "start": "944279",
    "end": "946759"
  },
  {
    "text": "may not have on your host on your host",
    "start": "946759",
    "end": "949079"
  },
  {
    "text": "right you are not um um you know um you",
    "start": "949079",
    "end": "951959"
  },
  {
    "text": "do not need to manage different versions",
    "start": "951959",
    "end": "953639"
  },
  {
    "text": "of container for different Hardware",
    "start": "953639",
    "end": "955680"
  },
  {
    "text": "devices and such right you know so so",
    "start": "955680",
    "end": "958160"
  },
  {
    "text": "that's",
    "start": "958160",
    "end": "959120"
  },
  {
    "text": "I think that's a nice Adda you know",
    "start": "959120",
    "end": "960920"
  },
  {
    "text": "that's let me let me continue so I have",
    "start": "960920",
    "end": "964000"
  },
  {
    "text": "eight minutes so but wait AI is more",
    "start": "964000",
    "end": "966800"
  },
  {
    "text": "than just LM so I showed you how to run",
    "start": "966800",
    "end": "969160"
  },
  {
    "text": "LM how to how to train a llama to and",
    "start": "969160",
    "end": "971680"
  },
  {
    "text": "then how to run how to do AI inflence on",
    "start": "971680",
    "end": "973519"
  },
  {
    "text": "that um in fact there's a there's a",
    "start": "973519",
    "end": "976480"
  },
  {
    "text": "large uh number of AI Frameworks that's",
    "start": "976480",
    "end": "978759"
  },
  {
    "text": "currently running with with waterm Edge",
    "start": "978759",
    "end": "980839"
  },
  {
    "text": "you know we uh we spend a lot of time",
    "start": "980839",
    "end": "982560"
  },
  {
    "text": "because um you know we take advantage of",
    "start": "982560",
    "end": "984759"
  },
  {
    "text": "the Linux Foundation uh internship so we",
    "start": "984759",
    "end": "987399"
  },
  {
    "text": "get uh 12 GR student interns every year",
    "start": "987399",
    "end": "990240"
  },
  {
    "text": "you know uh we have most of them are um",
    "start": "990240",
    "end": "992720"
  },
  {
    "text": "you know Master students or PhD students",
    "start": "992720",
    "end": "994759"
  },
  {
    "text": "so we get them to um to work on",
    "start": "994759",
    "end": "996759"
  },
  {
    "text": "integration of those AI Frameworks with",
    "start": "996759",
    "end": "998440"
  },
  {
    "text": "our a run time so we now have open CV",
    "start": "998440",
    "end": "1000399"
  },
  {
    "text": "running we have M FFM Peg running we",
    "start": "1000399",
    "end": "1003600"
  },
  {
    "text": "have the um you know different AI",
    "start": "1003600",
    "end": "1005519"
  },
  {
    "text": "Frameworks running and then we have not",
    "start": "1005519",
    "end": "1008079"
  },
  {
    "text": "only the the uh LV model from meta",
    "start": "1008079",
    "end": "1010560"
  },
  {
    "text": "running we also have um you know um um",
    "start": "1010560",
    "end": "1013519"
  },
  {
    "text": "uh the the um you know audio and video",
    "start": "1013519",
    "end": "1017360"
  },
  {
    "text": "model from from media pipe running so",
    "start": "1017360",
    "end": "1019519"
  },
  {
    "text": "let me show you a simple example of",
    "start": "1019519",
    "end": "1021600"
  },
  {
    "text": "media pipe so this again this is a uh",
    "start": "1021600",
    "end": "1025079"
  },
  {
    "text": "entire um rust application it's even",
    "start": "1025079",
    "end": "1027839"
  },
  {
    "text": "bigger fun and fit into a a PPT slide",
    "start": "1027839",
    "end": "1030880"
  },
  {
    "text": "you know so it creates a it creates a",
    "start": "1030880",
    "end": "1032760"
  },
  {
    "text": "contact load the model and then send the",
    "start": "1032760",
    "end": "1034880"
  },
  {
    "text": "image to have the model recognize what's",
    "start": "1034880",
    "end": "1037959"
  },
  {
    "text": "the image right you know so since I'm in",
    "start": "1037959",
    "end": "1039360"
  },
  {
    "text": "Chicago so I decide to give the those",
    "start": "1039360",
    "end": "1041520"
  },
  {
    "text": "two images and I don't believe this",
    "start": "1041520",
    "end": "1043319"
  },
  {
    "text": "model is specially trained to recognize",
    "start": "1043319",
    "end": "1045760"
  },
  {
    "text": "food you know it's it's trained to",
    "start": "1045760",
    "end": "1047520"
  },
  {
    "text": "recognize object right so it has a",
    "start": "1047520",
    "end": "1050080"
  },
  {
    "text": "couple thousand objects in dictionary so",
    "start": "1050080",
    "end": "1052200"
  },
  {
    "text": "that's what the result come back you",
    "start": "1052200",
    "end": "1054080"
  },
  {
    "text": "know that's um you know um you can",
    "start": "1054080",
    "end": "1056919"
  },
  {
    "text": "actually try it um you know we have it",
    "start": "1056919",
    "end": "1059080"
  },
  {
    "text": "on GitHub actions you in our cicd so so",
    "start": "1059080",
    "end": "1061600"
  },
  {
    "text": "we run this daily you know it takes a",
    "start": "1061600",
    "end": "1063679"
  },
  {
    "text": "couple milliseconds to get a result from",
    "start": "1063679",
    "end": "1066000"
  },
  {
    "text": "those from those um pictures so you can",
    "start": "1066000",
    "end": "1068280"
  },
  {
    "text": "see on the on the hot dog it's a little",
    "start": "1068280",
    "end": "1070160"
  },
  {
    "text": "confused what it is but it's more or",
    "start": "1070160",
    "end": "1071919"
  },
  {
    "text": "less NOS is a hot dog and uh you",
    "start": "1071919",
    "end": "1074080"
  },
  {
    "text": "definitely no is a pizza right you know",
    "start": "1074080",
    "end": "1075679"
  },
  {
    "text": "so you know that's uh um you can do a",
    "start": "1075679",
    "end": "1078440"
  },
  {
    "text": "lot of those with uh with um with non",
    "start": "1078440",
    "end": "1081000"
  },
  {
    "text": "language models with uh with um you know",
    "start": "1081000",
    "end": "1083320"
  },
  {
    "text": "um video and image models and you know",
    "start": "1083320",
    "end": "1085360"
  },
  {
    "text": "things like that so um I think I partly",
    "start": "1085360",
    "end": "1089120"
  },
  {
    "text": "answered this question but the biggest",
    "start": "1089120",
    "end": "1091240"
  },
  {
    "text": "question of any writing or any",
    "start": "1091240",
    "end": "1092520"
  },
  {
    "text": "technology is the soat question you know",
    "start": "1092520",
    "end": "1094840"
  },
  {
    "text": "that's okay you did all this and so what",
    "start": "1094840",
    "end": "1097400"
  },
  {
    "text": "right you know the the the the key point",
    "start": "1097400",
    "end": "1100120"
  },
  {
    "text": "of so what is no python you know that's",
    "start": "1100120",
    "end": "1102880"
  },
  {
    "text": "you know",
    "start": "1102880",
    "end": "1104159"
  },
  {
    "text": "it's I really like this um this this",
    "start": "1104159",
    "end": "1109000"
  },
  {
    "text": "photo you know that's a so Pi python is",
    "start": "1109000",
    "end": "1111919"
  },
  {
    "text": "just a c framework but if you can read",
    "start": "1111919",
    "end": "1114280"
  },
  {
    "text": "the py toch and the you know um doer",
    "start": "1114280",
    "end": "1117400"
  },
  {
    "text": "images on the on the right it's three",
    "start": "1117400",
    "end": "1119880"
  },
  {
    "text": "gigabytes to begin with it's a very",
    "start": "1119880",
    "end": "1122120"
  },
  {
    "text": "expensive C framework you know to just",
    "start": "1122120",
    "end": "1124360"
  },
  {
    "text": "to have something a nice language that R",
    "start": "1124360",
    "end": "1126400"
  },
  {
    "text": "want to see it's very it's very very",
    "start": "1126400",
    "end": "1128120"
  },
  {
    "text": "expensive and also it's not that nice",
    "start": "1128120",
    "end": "1130280"
  },
  {
    "text": "anymore anyway you know because it takes",
    "start": "1130280",
    "end": "1133120"
  },
  {
    "text": "a very long time to install Python and",
    "start": "1133120",
    "end": "1135440"
  },
  {
    "text": "then to make sure it doesn't come you",
    "start": "1135440",
    "end": "1137880"
  },
  {
    "text": "know I I have a separate machine that I",
    "start": "1137880",
    "end": "1141080"
  },
  {
    "text": "install python with you know because I I",
    "start": "1141080",
    "end": "1143120"
  },
  {
    "text": "can't often needs to often needs to you",
    "start": "1143120",
    "end": "1145880"
  },
  {
    "text": "know wipe it up right you know",
    "start": "1145880",
    "end": "1149320"
  },
  {
    "text": "so you know just to draw home the point",
    "start": "1149320",
    "end": "1153080"
  },
  {
    "text": "you know it's",
    "start": "1153080",
    "end": "1155000"
  },
  {
    "text": "um it wasn't I who said you know um um",
    "start": "1155000",
    "end": "1158200"
  },
  {
    "text": "wasm or rust is the language of AGI he",
    "start": "1158200",
    "end": "1160640"
  },
  {
    "text": "said that okay you know that's and uh um",
    "start": "1160640",
    "end": "1164799"
  },
  {
    "text": "so yesterday um X has made an",
    "start": "1164799",
    "end": "1167039"
  },
  {
    "text": "announcement this called grock right you",
    "start": "1167039",
    "end": "1168640"
  },
  {
    "text": "know that's uh they have their large",
    "start": "1168640",
    "end": "1169799"
  },
  {
    "text": "language model and very specifically in",
    "start": "1169799",
    "end": "1171880"
  },
  {
    "text": "their press release they they mentioned",
    "start": "1171880",
    "end": "1174280"
  },
  {
    "text": "their whole back in infrastructure is",
    "start": "1174280",
    "end": "1175720"
  },
  {
    "text": "building with rust and uh you know",
    "start": "1175720",
    "end": "1177760"
  },
  {
    "text": "kubernetes rust and Jax right you know",
    "start": "1177760",
    "end": "1179720"
  },
  {
    "text": "you have to have some kind of ai ai",
    "start": "1179720",
    "end": "1181360"
  },
  {
    "text": "framework and Jax is mostly cc++ with a",
    "start": "1181360",
    "end": "1183799"
  },
  {
    "text": "little bit of Pisa it has um it it talks",
    "start": "1183799",
    "end": "1186720"
  },
  {
    "text": "about a lot about the the virtue of rust",
    "start": "1186720",
    "end": "1189640"
  },
  {
    "text": "and uh you know um as we have seen you",
    "start": "1189640",
    "end": "1191799"
  },
  {
    "text": "know because a lot of people here are um",
    "start": "1191799",
    "end": "1194000"
  },
  {
    "text": "you know rust developers because those",
    "start": "1194000",
    "end": "1195919"
  },
  {
    "text": "wasman and rust communities are very",
    "start": "1195919",
    "end": "1197480"
  },
  {
    "text": "close you know that's we have Co",
    "start": "1197480",
    "end": "1199120"
  },
  {
    "text": "collocated conferences in Seattle you",
    "start": "1199120",
    "end": "1201400"
  },
  {
    "text": "know a couple months ago and uh so um uh",
    "start": "1201400",
    "end": "1204320"
  },
  {
    "text": "it's my belief that uh um wasm has",
    "start": "1204320",
    "end": "1207400"
  },
  {
    "text": "become the go-to wrun time for rust you",
    "start": "1207400",
    "end": "1210760"
  },
  {
    "text": "know so you know so um I think in the",
    "start": "1210760",
    "end": "1213400"
  },
  {
    "text": "near future a lot of majority of rust",
    "start": "1213400",
    "end": "1215640"
  },
  {
    "text": "applications would be compiled to wasm",
    "start": "1215640",
    "end": "1217400"
  },
  {
    "text": "you know that's uh um so that's that's",
    "start": "1217400",
    "end": "1219000"
  },
  {
    "text": "something that we we really look forward",
    "start": "1219000",
    "end": "1220840"
  },
  {
    "text": "to to seeing so then um to finalize you",
    "start": "1220840",
    "end": "1224320"
  },
  {
    "text": "know I think you know I'm I only have a",
    "start": "1224320",
    "end": "1226120"
  },
  {
    "text": "couple more minutes so you know um",
    "start": "1226120",
    "end": "1228679"
  },
  {
    "text": "the the um to go back to my to my",
    "start": "1228679",
    "end": "1231280"
  },
  {
    "text": "original points what's the killer",
    "start": "1231280",
    "end": "1233039"
  },
  {
    "text": "application you know it's not to replace",
    "start": "1233039",
    "end": "1235000"
  },
  {
    "text": "ster not to replace go not to replace",
    "start": "1235000",
    "end": "1238080"
  },
  {
    "text": "today's",
    "start": "1238080",
    "end": "1239080"
  },
  {
    "text": "microservices it is to replace python in",
    "start": "1239080",
    "end": "1242320"
  },
  {
    "text": "the new um uh in the new AI application",
    "start": "1242320",
    "end": "1247440"
  },
  {
    "text": "so it talks about you know UNC compared",
    "start": "1247440",
    "end": "1249360"
  },
  {
    "text": "with python you know that's you know I",
    "start": "1249360",
    "end": "1251280"
  },
  {
    "text": "think there's it is no-brainer because",
    "start": "1251280",
    "end": "1254240"
  },
  {
    "text": "you uh you install the whole tool chain",
    "start": "1254240",
    "end": "1256840"
  },
  {
    "text": "with um you know almost zero dependency",
    "start": "1256840",
    "end": "1259600"
  },
  {
    "text": "in four or five minutes and then you",
    "start": "1259600",
    "end": "1261960"
  },
  {
    "text": "know um the whole thing is like 1% size",
    "start": "1261960",
    "end": "1265159"
  },
  {
    "text": "of the Python and then application",
    "start": "1265159",
    "end": "1266440"
  },
  {
    "text": "itself is much much smaller than python",
    "start": "1266440",
    "end": "1268039"
  },
  {
    "text": "as well and then it runs much faster and",
    "start": "1268039",
    "end": "1270440"
  },
  {
    "text": "then it's U you know it's uh it's",
    "start": "1270440",
    "end": "1272520"
  },
  {
    "text": "utterly portable right and but you know",
    "start": "1272520",
    "end": "1275159"
  },
  {
    "text": "the other question people always ask is",
    "start": "1275159",
    "end": "1276840"
  },
  {
    "text": "um you know how about C++ you know",
    "start": "1276840",
    "end": "1279039"
  },
  {
    "text": "that's uh you know why can't I just a",
    "start": "1279039",
    "end": "1280400"
  },
  {
    "text": "compile to Native right you know that's",
    "start": "1280400",
    "end": "1281880"
  },
  {
    "text": "um you know because a lot of um you know",
    "start": "1281880",
    "end": "1283880"
  },
  {
    "text": "in a lot of big firms when when you when",
    "start": "1283880",
    "end": "1285600"
  },
  {
    "text": "they do AI influence today they use C++",
    "start": "1285600",
    "end": "1287559"
  },
  {
    "text": "based WR time right you know so there's",
    "start": "1287559",
    "end": "1289840"
  },
  {
    "text": "uh but that's our uh standard you know",
    "start": "1289840",
    "end": "1292360"
  },
  {
    "text": "there are so many speakers today talking",
    "start": "1292360",
    "end": "1294159"
  },
  {
    "text": "about the virtual of isolation you know",
    "start": "1294159",
    "end": "1296480"
  },
  {
    "text": "the the need for you know um components",
    "start": "1296480",
    "end": "1299320"
  },
  {
    "text": "and all that you know wasm is just a",
    "start": "1299320",
    "end": "1301320"
  },
  {
    "text": "better um you know programming model",
    "start": "1301320",
    "end": "1303840"
  },
  {
    "text": "than say the full native um model that",
    "start": "1303840",
    "end": "1307159"
  },
  {
    "text": "we sort of deprecated since the Java",
    "start": "1307159",
    "end": "1309320"
  },
  {
    "text": "days right you know so so those are you",
    "start": "1309320",
    "end": "1311679"
  },
  {
    "text": "know my main arguments um um um roster",
    "start": "1311679",
    "end": "1315520"
  },
  {
    "text": "plus wasm you know that's how it's",
    "start": "1315520",
    "end": "1317400"
  },
  {
    "text": "compared with",
    "start": "1317400",
    "end": "1318840"
  },
  {
    "text": "the the leading competitors in this",
    "start": "1318840",
    "end": "1320760"
  },
  {
    "text": "space right you know so I think that's",
    "start": "1320760",
    "end": "1324320"
  },
  {
    "text": "it yeah that's um um so thank you",
    "start": "1324320",
    "end": "1329120"
  },
  {
    "text": "yeah iy take Michael all right who's got",
    "start": "1332640",
    "end": "1335760"
  },
  {
    "text": "some",
    "start": "1335760",
    "end": "1337960"
  },
  {
    "text": "questions afraid we're going to get",
    "start": "1339480",
    "end": "1341960"
  },
  {
    "text": "boarded attacking the python Community",
    "start": "1341960",
    "end": "1345080"
  },
  {
    "text": "get canceled Michael trying to get wasm",
    "start": "1345080",
    "end": "1347559"
  },
  {
    "text": "off the ground",
    "start": "1347559",
    "end": "1349960"
  },
  {
    "text": "here yeah hi uh the talk mostly talked",
    "start": "1350320",
    "end": "1353159"
  },
  {
    "text": "about interop operability and you know",
    "start": "1353159",
    "end": "1356279"
  },
  {
    "text": "bashing python but is there an advantage",
    "start": "1356279",
    "end": "1359320"
  },
  {
    "text": "also in terms of performance compared to",
    "start": "1359320",
    "end": "1361480"
  },
  {
    "text": "because the ultimately it's gml that's",
    "start": "1361480",
    "end": "1364000"
  },
  {
    "text": "running right so does uh this pattern of",
    "start": "1364000",
    "end": "1366840"
  },
  {
    "text": "building with web assembly plus rust",
    "start": "1366840",
    "end": "1368799"
  },
  {
    "text": "have any performance Advantage compared",
    "start": "1368799",
    "end": "1370720"
  },
  {
    "text": "to running python with you know gdml as",
    "start": "1370720",
    "end": "1373279"
  },
  {
    "text": "a backend yes you know um",
    "start": "1373279",
    "end": "1376240"
  },
  {
    "text": "so in fact I only talked about the the",
    "start": "1376240",
    "end": "1379320"
  },
  {
    "text": "size and the complexity of python but if",
    "start": "1379320",
    "end": "1381679"
  },
  {
    "text": "you look at the um you know the academic",
    "start": "1381679",
    "end": "1384440"
  },
  {
    "text": "um paper has been published you know and",
    "start": "1384440",
    "end": "1386200"
  },
  {
    "text": "also you know there was a very famous",
    "start": "1386200",
    "end": "1387840"
  },
  {
    "text": "paper um you know um publish on science",
    "start": "1387840",
    "end": "1390279"
  },
  {
    "text": "I think U two years ago the title is",
    "start": "1390279",
    "end": "1392480"
  },
  {
    "text": "there's plenty of room at the top you",
    "start": "1392480",
    "end": "1394200"
  },
  {
    "text": "know because 40 years ago another guy",
    "start": "1394200",
    "end": "1395919"
  },
  {
    "text": "publ paper course there's plenty of room",
    "start": "1395919",
    "end": "1397640"
  },
  {
    "text": "at the bottom that guy was golden more",
    "start": "1397640",
    "end": "1399440"
  },
  {
    "text": "right you know that's the more law which",
    "start": "1399440",
    "end": "1401640"
  },
  {
    "text": "says you can continuously improve the",
    "start": "1401640",
    "end": "1404080"
  },
  {
    "text": "the semiconductors and uh you know and",
    "start": "1404080",
    "end": "1406080"
  },
  {
    "text": "not worry about too much about the",
    "start": "1406080",
    "end": "1407400"
  },
  {
    "text": "software but you know we have H the war",
    "start": "1407400",
    "end": "1409960"
  },
  {
    "text": "at semiconductors you know that's um you",
    "start": "1409960",
    "end": "1411919"
  },
  {
    "text": "know I know because most my colleagues",
    "start": "1411919",
    "end": "1413400"
  },
  {
    "text": "are in Taiwan right you know that's uh",
    "start": "1413400",
    "end": "1415039"
  },
  {
    "text": "so you know um uh extracting performance",
    "start": "1415039",
    "end": "1417720"
  },
  {
    "text": "from software becomes permanent I think",
    "start": "1417720",
    "end": "1419960"
  },
  {
    "text": "in this day and age so they compared",
    "start": "1419960",
    "end": "1422200"
  },
  {
    "text": "python with um with say rust and C++ and",
    "start": "1422200",
    "end": "1425880"
  },
  {
    "text": "and and all those there's a six order of",
    "start": "1425880",
    "end": "1428400"
  },
  {
    "text": "magnitude performance difference between",
    "start": "1428400",
    "end": "1430559"
  },
  {
    "text": "Python and those languages the only way",
    "start": "1430559",
    "end": "1433039"
  },
  {
    "text": "python is still in the game for AI and",
    "start": "1433039",
    "end": "1434799"
  },
  {
    "text": "machine learning is because the C",
    "start": "1434799",
    "end": "1436320"
  },
  {
    "text": "framework you know if you not careful if",
    "start": "1436320",
    "end": "1438720"
  },
  {
    "text": "anything that you actually perform",
    "start": "1438720",
    "end": "1440559"
  },
  {
    "text": "computation in Python you're going to be",
    "start": "1440559",
    "end": "1442840"
  },
  {
    "text": "you know you're going to be so slow that",
    "start": "1442840",
    "end": "1444400"
  },
  {
    "text": "that you would immediately notice that",
    "start": "1444400",
    "end": "1446039"
  },
  {
    "text": "you would so that's why you know that",
    "start": "1446039",
    "end": "1447880"
  },
  {
    "text": "famous I I forgot who said it's much of",
    "start": "1447880",
    "end": "1450520"
  },
  {
    "text": "today's machine learning is to figure",
    "start": "1450520",
    "end": "1451960"
  },
  {
    "text": "out you know how to make python um you",
    "start": "1451960",
    "end": "1454480"
  },
  {
    "text": "know um how to get around Python's",
    "start": "1454480",
    "end": "1456480"
  },
  {
    "text": "performance problem how to make how to",
    "start": "1456480",
    "end": "1457880"
  },
  {
    "text": "use C framework underneath python yeah",
    "start": "1457880",
    "end": "1460200"
  },
  {
    "text": "so your quote is python broke mors law",
    "start": "1460200",
    "end": "1463559"
  },
  {
    "text": "no it's a mors law has reached the point",
    "start": "1463559",
    "end": "1465559"
  },
  {
    "text": "where we have to squeeze performance out",
    "start": "1465559",
    "end": "1467159"
  },
  {
    "text": "of it so the software Mor law start with",
    "start": "1467159",
    "end": "1469360"
  },
  {
    "text": "python and goes to rust and goes I love",
    "start": "1469360",
    "end": "1471279"
  },
  {
    "text": "it Michael I'm only teasing a little bit",
    "start": "1471279",
    "end": "1472679"
  },
  {
    "text": "I like the spicy take who's",
    "start": "1472679",
    "end": "1476320"
  },
  {
    "text": "next thank you uh how do you feel this",
    "start": "1477600",
    "end": "1481640"
  },
  {
    "text": "relates to ons on NX is it does it make",
    "start": "1481640",
    "end": "1484960"
  },
  {
    "text": "it obsolete irrelevant no I think this",
    "start": "1484960",
    "end": "1488000"
  },
  {
    "text": "is um um you know U perpendicular to to",
    "start": "1488000",
    "end": "1491360"
  },
  {
    "text": "to to the format right you know so um um",
    "start": "1491360",
    "end": "1495440"
  },
  {
    "text": "onx is uh at the same level at tensor",
    "start": "1495440",
    "end": "1498559"
  },
  {
    "text": "flow and P torch and the gml which will",
    "start": "1498559",
    "end": "1501480"
  },
  {
    "text": "support so it's a model format and uh so",
    "start": "1501480",
    "end": "1504240"
  },
  {
    "text": "we through the wasi abstract interface",
    "start": "1504240",
    "end": "1507039"
  },
  {
    "text": "we can go out to the to the run time",
    "start": "1507039",
    "end": "1508919"
  },
  {
    "text": "that runs those formats so I I don't",
    "start": "1508919",
    "end": "1511440"
  },
  {
    "text": "think it make it obscure at all you know",
    "start": "1511440",
    "end": "1513159"
  },
  {
    "text": "I think it's uh you're going to be able",
    "start": "1513159",
    "end": "1514720"
  },
  {
    "text": "to uh accommodate the the the the onx",
    "start": "1514720",
    "end": "1517120"
  },
  {
    "text": "ecosystem so this could actually read",
    "start": "1517120",
    "end": "1519640"
  },
  {
    "text": "onx yes you read onx and and do",
    "start": "1519640",
    "end": "1522399"
  },
  {
    "text": "inference on the top of it yeah",
    "start": "1522399",
    "end": "1526159"
  },
  {
    "text": "cool okay we got time for one more I",
    "start": "1526679",
    "end": "1529120"
  },
  {
    "text": "think up in the",
    "start": "1529120",
    "end": "1532520"
  },
  {
    "text": "front um I'm not sure if somebody asked",
    "start": "1542919",
    "end": "1545320"
  },
  {
    "text": "this already but uh during your demo one",
    "start": "1545320",
    "end": "1547279"
  },
  {
    "text": "of the things that you mentioned was",
    "start": "1547279",
    "end": "1549039"
  },
  {
    "text": "that it you kept having to load the 5",
    "start": "1549039",
    "end": "1551159"
  },
  {
    "text": "gigabyte model and as you know models",
    "start": "1551159",
    "end": "1553480"
  },
  {
    "text": "get bigger that obviously that becomes a",
    "start": "1553480",
    "end": "1554919"
  },
  {
    "text": "bigger problem one of the things that um",
    "start": "1554919",
    "end": "1557399"
  },
  {
    "text": "some some of the Llama authors did is",
    "start": "1557399",
    "end": "1559360"
  },
  {
    "text": "they they M mapped the model and that",
    "start": "1559360",
    "end": "1561640"
  },
  {
    "text": "obviously reduces startup Times by by",
    "start": "1561640",
    "end": "1564039"
  },
  {
    "text": "quite a lot do you think that's",
    "start": "1564039",
    "end": "1565880"
  },
  {
    "text": "something that could be replicated with",
    "start": "1565880",
    "end": "1567720"
  },
  {
    "text": "Wazi or maybe Wynn yes yes so you know",
    "start": "1567720",
    "end": "1571320"
  },
  {
    "text": "so the way Wazi works is that it's a",
    "start": "1571320",
    "end": "1574399"
  },
  {
    "text": "it's an abstract interface that for the",
    "start": "1574399",
    "end": "1576480"
  },
  {
    "text": "host function so there are lots of",
    "start": "1576480",
    "end": "1577640"
  },
  {
    "text": "things you can do at the host function",
    "start": "1577640",
    "end": "1578960"
  },
  {
    "text": "level you can so you know um because",
    "start": "1578960",
    "end": "1581320"
  },
  {
    "text": "this needs for large language model so",
    "start": "1581320",
    "end": "1583120"
  },
  {
    "text": "we uh we actually updated wasi spec you",
    "start": "1583120",
    "end": "1585440"
  },
  {
    "text": "know so um um I don't know if Andrew is",
    "start": "1585440",
    "end": "1588240"
  },
  {
    "text": "here but but you know that's so so the",
    "start": "1588240",
    "end": "1590919"
  },
  {
    "text": "wasi and Comedia has driven that",
    "start": "1590919",
    "end": "1593200"
  },
  {
    "text": "direction because you know for five",
    "start": "1593200",
    "end": "1596120"
  },
  {
    "text": "gigabytes you can't read it into the",
    "start": "1596120",
    "end": "1597640"
  },
  {
    "text": "wasm memory and then transfer it to the",
    "start": "1597640",
    "end": "1599919"
  },
  {
    "text": "to the uh to to the wasi memory you",
    "start": "1599919",
    "end": "1602000"
  },
  {
    "text": "can't do that so so so you have to",
    "start": "1602000",
    "end": "1603320"
  },
  {
    "text": "bypass wasm all together to to read the",
    "start": "1603320",
    "end": "1605200"
  },
  {
    "text": "memory so there's lot of optimization",
    "start": "1605200",
    "end": "1607559"
  },
  {
    "text": "that we can do here you know that's uh",
    "start": "1607559",
    "end": "1609360"
  },
  {
    "text": "but you know uh there's a lot of details",
    "start": "1609360",
    "end": "1611080"
  },
  {
    "text": "and we we we love to see the community's",
    "start": "1611080",
    "end": "1613120"
  },
  {
    "text": "contribution that we are working very",
    "start": "1613120",
    "end": "1614320"
  },
  {
    "text": "hard on this as well you another great",
    "start": "1614320",
    "end": "1617000"
  },
  {
    "text": "Cloud native Computing Foundation",
    "start": "1617000",
    "end": "1618480"
  },
  {
    "text": "project wased please join me giving",
    "start": "1618480",
    "end": "1620480"
  },
  {
    "text": "Michael a huge round of",
    "start": "1620480",
    "end": "1622559"
  },
  {
    "text": "applause",
    "start": "1622559",
    "end": "1625559"
  }
]
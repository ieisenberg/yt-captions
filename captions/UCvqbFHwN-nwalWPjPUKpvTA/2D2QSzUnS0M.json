[
  {
    "text": "so hi everyone uh thanks for attending our main NW uh so I'm Yuki uh from cyber",
    "start": "40",
    "end": "6600"
  },
  {
    "text": "agent in Japan and uh uh he is my co- speakers uh software engineer from",
    "start": "6600",
    "end": "13960"
  },
  {
    "text": "Google in Pand and uh in this session uh we will uh",
    "start": "13960",
    "end": "19640"
  },
  {
    "text": "show you about the working group batch",
    "start": "19640",
    "end": "24599"
  },
  {
    "text": "updates uh so uh first of all uh I want to uh start by explaining uh what our",
    "start": "26119",
    "end": "34200"
  },
  {
    "text": "working group uh is with in cuberes uh in kuber this project uh we",
    "start": "34200",
    "end": "39879"
  },
  {
    "text": "have two different type uh groups a s special interesting group and the uh WG",
    "start": "39879",
    "end": "48800"
  },
  {
    "text": "uh working group uh s has each uh responsibility to",
    "start": "48800",
    "end": "55079"
  },
  {
    "text": "maintain a set of uh components for the kubernetes project uh such as as cube",
    "start": "55079",
    "end": "60960"
  },
  {
    "text": "schedu and uh Cube rate and so on uh working group uh is slightly different",
    "start": "60960",
    "end": "68439"
  },
  {
    "text": "in the sense uh one is that uh it doesn't own any components uh and two uh",
    "start": "68439",
    "end": "76600"
  },
  {
    "text": "it has a temporary group uh so we get together basically to",
    "start": "76600",
    "end": "82159"
  },
  {
    "text": "solve the specific problem uh and then we decide to dissolve or Abol into SE",
    "start": "82159",
    "end": "91560"
  },
  {
    "text": "uh in this session uh I'm talking about the working group batch uh which is a",
    "start": "91560",
    "end": "96880"
  },
  {
    "text": "working group is a forum to discuss enhancement to better support batch work",
    "start": "96880",
    "end": "102560"
  },
  {
    "text": "batch Works uh batch uh might mean different",
    "start": "102560",
    "end": "107960"
  },
  {
    "text": "things for different people uh so let me give some examples uh we deal with HPC AI ml data",
    "start": "107960",
    "end": "118119"
  },
  {
    "text": "analytics and cic CD applications uh things in General job",
    "start": "118119",
    "end": "124159"
  },
  {
    "text": "that s in General job uh that works to",
    "start": "124159",
    "end": "129560"
  },
  {
    "text": "comption uh one of the primary goals of the working group is to reduce",
    "start": "129560",
    "end": "135239"
  },
  {
    "text": "fragmentation uh in the ecosystem uh if you are already in the room uh you might have already seen a",
    "start": "135239",
    "end": "142599"
  },
  {
    "text": "lot of talks about batch uh everybody doing different things uh and uh even",
    "start": "142599",
    "end": "149440"
  },
  {
    "text": "years uh before people are already doing uh many different",
    "start": "149440",
    "end": "155440"
  },
  {
    "text": "things uh we want to bring some comprehension in the batch in the kuber",
    "start": "155440",
    "end": "162640"
  },
  {
    "text": "project and to and and to do this uh We Gather a set of stakeholder from the",
    "start": "162640",
    "end": "170080"
  },
  {
    "text": "community uh the first one is uh s scheduling uh because uh this sig is",
    "start": "170080",
    "end": "175760"
  },
  {
    "text": "owner of KQ and we need to consider post scheduling of the bat workers uh like uh",
    "start": "175760",
    "end": "184000"
  },
  {
    "text": "gang scheduling uh the second one is the Sig apps uh because uh this sig is owner or",
    "start": "184000",
    "end": "192040"
  },
  {
    "text": "owner for the Java API and Kon Java apis uh the third one is uh",
    "start": "192040",
    "end": "201159"
  },
  {
    "text": "signal uh because uh we still need our resource our resource to run on not and",
    "start": "201159",
    "end": "209360"
  },
  {
    "text": "uh we have accelerators and we are not uh the last one is S Auto scaring uh",
    "start": "209360",
    "end": "217200"
  },
  {
    "text": "because uh we need it we need them and how to scale to OB oby uh scale up your",
    "start": "217200",
    "end": "226040"
  },
  {
    "text": "crust when you need more resources uh but uh we are not just",
    "start": "226040",
    "end": "232040"
  },
  {
    "text": "limitted to the kubernetes developers uh or uh containers uh we welcome uh huge",
    "start": "232040",
    "end": "240480"
  },
  {
    "text": "diversity of EOS ecosystem developers like uh CU and Armada and so on uh so we",
    "start": "240480",
    "end": "249959"
  },
  {
    "text": "welcome all the communities to come and bring their ideas and uh feature request a code so",
    "start": "249959",
    "end": "259560"
  },
  {
    "text": "what the scope uh we are go through uh all these topics in this session uh",
    "start": "259560",
    "end": "266560"
  },
  {
    "text": "first is job uh let me switch to mial",
    "start": "266560",
    "end": "271720"
  },
  {
    "text": "okay thank you uh so um as mentioned like one of the main goals of the batch",
    "start": "273520",
    "end": "279000"
  },
  {
    "text": "working group is to reduce fragmentation in the ecosystem and to achieve that in",
    "start": "279000",
    "end": "284120"
  },
  {
    "text": "the long term we believe that uh the right approach is to uh increase the um",
    "start": "284120",
    "end": "291720"
  },
  {
    "text": "uh or enhance the uh buil-in primitive for buil-in API into kubernetes that is",
    "start": "291720",
    "end": "298759"
  },
  {
    "text": "job so this is what uh we've been doing for the release last couple of releases",
    "start": "298759",
    "end": "305360"
  },
  {
    "text": "of kubernetes uh so here you can see a list of gaps that we",
    "start": "305360",
    "end": "310440"
  },
  {
    "text": "identified uh that were raised by inside the community uh that are required for a",
    "start": "310440",
    "end": "316720"
  },
  {
    "text": "better adoption of job and corresponding features that address this uh gaps in",
    "start": "316720",
    "end": "322880"
  },
  {
    "text": "this talks uh we are going to focus on the uh recent uh features that are",
    "start": "322880",
    "end": "328400"
  },
  {
    "text": "currently in beta or Alpha uh so the first one is poort failer policy so with this feature the",
    "start": "328400",
    "end": "335600"
  },
  {
    "text": "aim is to improve handling of uh port failers in order to at the end of the",
    "start": "335600",
    "end": "341639"
  },
  {
    "text": "day uh reduce costs of running jobs so as you can imagine uh if you are running",
    "start": "341639",
    "end": "347280"
  },
  {
    "text": "a large job uh failures can happen and they can happen for different reasons let's say bugs or uh disruptions such as",
    "start": "347280",
    "end": "354840"
  },
  {
    "text": "preemptions and there is a buil-in mechanism like called back of limit that allows you to specify the maximal number",
    "start": "354840",
    "end": "361400"
  },
  {
    "text": "of rest restarts um of a pod but it's very in inflexible so for example if you",
    "start": "361400",
    "end": "369080"
  },
  {
    "text": "set it too low you are risking that your job fails and your computations are gone",
    "start": "369080",
    "end": "374599"
  },
  {
    "text": "uh in case of disruption by a higher priority workload uh but on the other hand if you set the back of limit to",
    "start": "374599",
    "end": "381000"
  },
  {
    "text": "high then you are risking that you will have too many uh red R uh in case of",
    "start": "381000",
    "end": "387280"
  },
  {
    "text": "software bug and then much more High costs of running uh so what are the strategies to",
    "start": "387280",
    "end": "394280"
  },
  {
    "text": "distinguish between software bugs and disruptions and other Trent issues uh so",
    "start": "394280",
    "end": "401160"
  },
  {
    "text": "one strategy is to use container exit codes that's what we support in pfer policy and this is this approach is also",
    "start": "401160",
    "end": "407759"
  },
  {
    "text": "supported by other Frameworks such as cube flow but the one limitation of this is",
    "start": "407759",
    "end": "413599"
  },
  {
    "text": "that some exit codes like 137 are ambiguous uh so in order to discriminate",
    "start": "413599",
    "end": "419240"
  },
  {
    "text": "f there we introduce uh po conditions U that can indicate you the",
    "start": "419240",
    "end": "425759"
  },
  {
    "text": "reason of the failure so in this diagram you can see that a PO can be disrupted",
    "start": "425759",
    "end": "431599"
  },
  {
    "text": "by various components inside cor kubernetes so what we did as part of",
    "start": "431599",
    "end": "437360"
  },
  {
    "text": "this work we collaborated with different s and uh we reviewed code of different",
    "start": "437360",
    "end": "442800"
  },
  {
    "text": "components of kubernetes uh to add the disruption Target condition uh to this comp",
    "start": "442800",
    "end": "449520"
  },
  {
    "text": "components when we delete a pod to indicate what is the reason for the failure so that then pod failure policy",
    "start": "449520",
    "end": "456639"
  },
  {
    "text": "can um or the user by configuration can um uh can react to it so here you can",
    "start": "456639",
    "end": "466039"
  },
  {
    "text": "see an example yam that presents the example po failer policy so this is",
    "start": "466039",
    "end": "472199"
  },
  {
    "text": "essentially just a list of rules that specify um how you uh which part you",
    "start": "472199",
    "end": "479199"
  },
  {
    "text": "want to react based on the present uh po conditions or exit codes and we support",
    "start": "479199",
    "end": "485960"
  },
  {
    "text": "also custom uh conditions that you may want to add by uh user supplies uh",
    "start": "485960",
    "end": "492520"
  },
  {
    "text": "supplied controllers so this is basically the",
    "start": "492520",
    "end": "497599"
  },
  {
    "text": "design and the feature is beta since 126 but uh we identified in 126 one problem",
    "start": "497599",
    "end": "505400"
  },
  {
    "text": "uh that um um in order to to much against P",
    "start": "505400",
    "end": "511000"
  },
  {
    "text": "failer policy we want to make sure that the Pod is in terminal phase because if",
    "start": "511000",
    "end": "516560"
  },
  {
    "text": "it still gets updates we wouldn't the match wouldn't be reliable because maybe in the next iteration job controller",
    "start": "516560",
    "end": "523560"
  },
  {
    "text": "would make different decision so in order to overcome this we want to make",
    "start": "523560",
    "end": "528800"
  },
  {
    "text": "sure that the PO is in eventually in terminal phase but this was not the case",
    "start": "528800",
    "end": "534920"
  },
  {
    "text": "um for example for pending and terminating pods uh so we collab at with",
    "start": "534920",
    "end": "540200"
  },
  {
    "text": "signode and in 1.27 we solved this problem uh",
    "start": "540200",
    "end": "545519"
  },
  {
    "text": "by assigning always terminal phase based on the exit uh codes of the uh stopped",
    "start": "545519",
    "end": "552320"
  },
  {
    "text": "containers if the containers are no longer restarted um however this was a little",
    "start": "552320",
    "end": "559160"
  },
  {
    "text": "bit of a breaking change because for some of the um some of the pods the",
    "start": "559160",
    "end": "564959"
  },
  {
    "text": "terminal phase changed from failed to succeeded if the container all of the containers exited with zero uh and this",
    "start": "564959",
    "end": "573079"
  },
  {
    "text": "required changes or adaptations of demon set and stateful sets which we uh",
    "start": "573079",
    "end": "579360"
  },
  {
    "text": "proceeded with and at this moment we don't have any known issues to pfer",
    "start": "579360",
    "end": "585600"
  },
  {
    "text": "policy so we would like to graduate it to GA in the next release uh the next feature is back of",
    "start": "585600",
    "end": "592360"
  },
  {
    "text": "limit per index uh so this is basically to give you control over the number of ret not globally like back of liit",
    "start": "592360",
    "end": "599880"
  },
  {
    "text": "but per index for index jobs so this can be useful to for example ensure that all",
    "start": "599880",
    "end": "605079"
  },
  {
    "text": "of your um indexes would run because without it you can imagine that for",
    "start": "605079",
    "end": "610279"
  },
  {
    "text": "example index zero would uh consume all your budget for R rise and so this can",
    "start": "610279",
    "end": "617399"
  },
  {
    "text": "be useful so situations like if you have fully independent",
    "start": "617399",
    "end": "622760"
  },
  {
    "text": "indexes uh the next feature is job replacement policy so with this feature",
    "start": "622760",
    "end": "628160"
  },
  {
    "text": "what we do is is basically we introduced the new spec field po replacement policy",
    "start": "628160",
    "end": "633720"
  },
  {
    "text": "that you can set to fail that delays uh Recreation of a pod until the Pod that",
    "start": "633720",
    "end": "640240"
  },
  {
    "text": "is failing uh reaches the terminal phase of failed and why this is important",
    "start": "640240",
    "end": "647040"
  },
  {
    "text": "because uh if you use job for uh AI training jobs with Frameworks such as",
    "start": "647040",
    "end": "652480"
  },
  {
    "text": "tensor flow or Jacks this uh uh Frameworks require that there is at most",
    "start": "652480",
    "end": "658560"
  },
  {
    "text": "one running at the same time if and if you have a deleted P that is terminating and",
    "start": "658560",
    "end": "665320"
  },
  {
    "text": "as by default in the job you already create the new pod then you may have for a short while like 30 seconds two pods",
    "start": "665320",
    "end": "671480"
  },
  {
    "text": "running at the same time uh making the Frameworks crash and also for this is important for",
    "start": "671480",
    "end": "679240"
  },
  {
    "text": "resource management systems because if you recreate the Pod because before the",
    "start": "679240",
    "end": "684959"
  },
  {
    "text": "previous one is fully terminated you may exceed qu like use too many resources",
    "start": "684959",
    "end": "690920"
  },
  {
    "text": "for it for the time being uh the next feature is the managed buy mechanism that is still in Alpha and",
    "start": "690920",
    "end": "699920"
  },
  {
    "text": "what we want to do here is to um give control over the job object to external",
    "start": "699920",
    "end": "707440"
  },
  {
    "text": "uh controllers and this is needed for multiq I will go into more details later",
    "start": "707440",
    "end": "713880"
  },
  {
    "text": "uh but because we are opening uh job API to external controllers we need to make",
    "start": "713880",
    "end": "719320"
  },
  {
    "text": "sure that uh the changes that the external controllers do to the job status are like sensible expected by API",
    "start": "719320",
    "end": "726680"
  },
  {
    "text": "clients so significantly strengthen validation of the uh job",
    "start": "726680",
    "end": "733880"
  },
  {
    "text": "status uh let me explain uh job success policy uh but uh still this is still uh",
    "start": "737720",
    "end": "745600"
  },
  {
    "text": "our first stage feature uh this feature uh to specify uh",
    "start": "745600",
    "end": "750880"
  },
  {
    "text": "when a job can be declared as succeeded uh based on the set of succeeded Parts",
    "start": "750880",
    "end": "757600"
  },
  {
    "text": "uh and uh if job met success policy uh job get new interium condition success",
    "start": "757600",
    "end": "763680"
  },
  {
    "text": "criteria met after that the remaining parts are",
    "start": "763680",
    "end": "769360"
  },
  {
    "text": "terminated finally uh job is added completed con uh the primary use case is uh",
    "start": "769360",
    "end": "777480"
  },
  {
    "text": "machine learning work growth uh the machine learning workers often uh often",
    "start": "777480",
    "end": "782839"
  },
  {
    "text": "care only read our Ro parts so we introduce this",
    "start": "782839",
    "end": "787880"
  },
  {
    "text": "feature uh based on the left example uh we can set uh two types of criteria uh",
    "start": "787880",
    "end": "796760"
  },
  {
    "text": "the first one is succeeded indexes uh the second one is suc succeeded",
    "start": "796760",
    "end": "803160"
  },
  {
    "text": "count uh when you specify the only succeeded indexes uh once all indexes succeeded",
    "start": "803160",
    "end": "811199"
  },
  {
    "text": "the job is marked as succeeded uh the the succeeded",
    "start": "811199",
    "end": "816920"
  },
  {
    "text": "indexes is represented as intervals separated by a",
    "start": "816920",
    "end": "822519"
  },
  {
    "text": "Pyon the number uh listed in represented by the first and last element of the",
    "start": "822519",
    "end": "828839"
  },
  {
    "text": "series separated by hyphone uh when you specify the only",
    "start": "828839",
    "end": "834279"
  },
  {
    "text": "succeeded count uh once the number of succeeded indexes reach the succeeded",
    "start": "834279",
    "end": "840480"
  },
  {
    "text": "count uh the job is marked as succeeded uh the last one is uh when you",
    "start": "840480",
    "end": "847279"
  },
  {
    "text": "specify both uh succeeded indexes and succeeded count uh when the number of succeeded",
    "start": "847279",
    "end": "854720"
  },
  {
    "text": "indexes uh specified in the succeeded indexes uh reach the succeeded",
    "start": "854720",
    "end": "860560"
  },
  {
    "text": "count uh the job is marked as succeeded also",
    "start": "860560",
    "end": "866880"
  },
  {
    "text": "uh uh this is a our first feature so uh let us know if you have some",
    "start": "866880",
    "end": "874759"
  },
  {
    "text": "feedbacks okay uh okay so the next topic is uh job",
    "start": "875839",
    "end": "882720"
  },
  {
    "text": "set which is an investment done by the BW working group uh so with this project",
    "start": "882720",
    "end": "888320"
  },
  {
    "text": "what we aim uh is to improve the support",
    "start": "888320",
    "end": "893600"
  },
  {
    "text": "for AIML uh workloads by overcoming uh like building up upon The Primitives",
    "start": "893600",
    "end": "900240"
  },
  {
    "text": "that kubernetes gives you like the job API but overcoming the main limitation of the uh job API being that you can",
    "start": "900240",
    "end": "908320"
  },
  {
    "text": "only specify one po template and for machine uh training machine learning training jobs what you uh very often",
    "start": "908320",
    "end": "916519"
  },
  {
    "text": "need to do like the common pattern is that you have uh the coordinator pod and",
    "start": "916519",
    "end": "922519"
  },
  {
    "text": "uh set of worker pods and you want maybe different images or and different",
    "start": "922519",
    "end": "929519"
  },
  {
    "text": "Hardware uh for the uh coordinator because the coordinator doesn't require",
    "start": "929519",
    "end": "934920"
  },
  {
    "text": "gpus for example so you can save a little bit uh on the number of gpus",
    "start": "934920",
    "end": "940120"
  },
  {
    "text": "needed so job set basically lets you specify the number of jobs and compose",
    "start": "940120",
    "end": "945399"
  },
  {
    "text": "them as as um smaller from the smaller pieces of jobs um and one more thing",
    "start": "945399",
    "end": "953800"
  },
  {
    "text": "that job said gives you is the management of the Headless service so",
    "start": "953800",
    "end": "959440"
  },
  {
    "text": "again for machine learning jobs use it's very common that you need to ensure that",
    "start": "959440",
    "end": "964800"
  },
  {
    "text": "there are communication channels between pods and this can be uh in order to",
    "start": "964800",
    "end": "970120"
  },
  {
    "text": "facilitate that one common technique is to put a um headless service in front of",
    "start": "970120",
    "end": "975880"
  },
  {
    "text": "the group of the pods that need to communicate so that they have stable DNS names so that they can find each other",
    "start": "975880",
    "end": "983240"
  },
  {
    "text": "easily uh however if you are using for example job then you are on your own with the Headless uh service management",
    "start": "983240",
    "end": "991399"
  },
  {
    "text": "and jobet gives you this um for free so it has a a number of knobs uh",
    "start": "991399",
    "end": "999839"
  },
  {
    "text": "for example the network options that let you configure uh how you want to use the",
    "start": "999839",
    "end": "1005800"
  },
  {
    "text": "Headless service and there is Success policy that uh aims to Mark the job as",
    "start": "1005800",
    "end": "1011839"
  },
  {
    "text": "complete as soon as the for example workers are done uh you have the failer policy though this lets you control",
    "start": "1011839",
    "end": "1019360"
  },
  {
    "text": "that maximal number of restarts of the job Set uh or you can have startup",
    "start": "1019360",
    "end": "1025520"
  },
  {
    "text": "policy that lets you control the order of starting um different jobs in the job",
    "start": "1025520",
    "end": "1032000"
  },
  {
    "text": "set um because again maybe uh for machine learning jobs you would like to first start the coordinator and only",
    "start": "1032000",
    "end": "1039640"
  },
  {
    "text": "then uh the workers uh one important uh feature in",
    "start": "1039640",
    "end": "1046480"
  },
  {
    "text": "uh job set is the again for machine learning jobs is uh exclusive placement",
    "start": "1046480",
    "end": "1052160"
  },
  {
    "text": "so with this feature you can indicate that you want all the jobs to land on the uh collocated nodes and this is like",
    "start": "1052160",
    "end": "1061360"
  },
  {
    "text": "closely connected like maybe in the same uh GK output let's say uh so that you",
    "start": "1061360",
    "end": "1068039"
  },
  {
    "text": "can have good bandwidth uh for the network for communicating and exchanging gradients and what not during the",
    "start": "1068039",
    "end": "1075200"
  },
  {
    "text": "training um and in order to achieve this job that used Po affinities and anti",
    "start": "1075200",
    "end": "1081240"
  },
  {
    "text": "affinities but this turned out not to be efficient during the scheduling phase uh",
    "start": "1081240",
    "end": "1087600"
  },
  {
    "text": "so this was like significantly improved in terms of performance uh by the job",
    "start": "1087600",
    "end": "1093520"
  },
  {
    "text": "set team by using leader uh follower uh Paradigm so first we jobset schedules",
    "start": "1093520",
    "end": "1100440"
  },
  {
    "text": "the coordinator pods and only then the followers uh bind much faster using not",
    "start": "1100440",
    "end": "1108400"
  },
  {
    "text": "entire affinities or affinities but not selectors and this was also later uh",
    "start": "1108400",
    "end": "1114360"
  },
  {
    "text": "improved performance of this scenario by Cube schedular uh changes the first",
    "start": "1114360",
    "end": "1120520"
  },
  {
    "text": "speed effort uh so job set is still evolving",
    "start": "1120520",
    "end": "1126720"
  },
  {
    "text": "uh here is like the list of the potential enhancement the team is considering uh so the first one is to",
    "start": "1126720",
    "end": "1134200"
  },
  {
    "text": "add more granular uh error handling uh so this is basically",
    "start": "1134200",
    "end": "1139919"
  },
  {
    "text": "bringing the same or similar mechanism as uh portf policy for jobs maybe you",
    "start": "1139919",
    "end": "1145640"
  },
  {
    "text": "want to control the failur at the job set level so if You observe that a pod completed with exit code that indicates",
    "start": "1145640",
    "end": "1153600"
  },
  {
    "text": "it's a bug then you don't want to even bother ret trying the uh entire job set",
    "start": "1153600",
    "end": "1159240"
  },
  {
    "text": "and similarly uh maybe it's a if it's a distraction disruption you want to uh",
    "start": "1159240",
    "end": "1165360"
  },
  {
    "text": "retry it for free uh the second is uh Improvement that is considered is to",
    "start": "1165360",
    "end": "1171400"
  },
  {
    "text": "make the API for the placement policy more flexible so basically building on",
    "start": "1171400",
    "end": "1177400"
  },
  {
    "text": "the um uh exclusive placement but making the API more declarative with spec",
    "start": "1177400",
    "end": "1183200"
  },
  {
    "text": "instead of annotation and maybe giving you more control uh also support for specialized",
    "start": "1183200",
    "end": "1190159"
  },
  {
    "text": "Frameworks so there is a bunch of machine learning Frameworks that require users to uh provide some uh environment",
    "start": "1190159",
    "end": "1197480"
  },
  {
    "text": "variables that could be otherwise U derived from the workflow specification",
    "start": "1197480",
    "end": "1203520"
  },
  {
    "text": "but now it's up to the user to set them um manually so this is what jobet",
    "start": "1203520",
    "end": "1210200"
  },
  {
    "text": "controller could help with and uh in place po start so this the idea here is",
    "start": "1210200",
    "end": "1216799"
  },
  {
    "text": "to avoid uh um long large scale uh",
    "start": "1216799",
    "end": "1222200"
  },
  {
    "text": "scheduling in terms of restarting a job set so that you can in place uh restart",
    "start": "1222200",
    "end": "1227919"
  },
  {
    "text": "the pods so now",
    "start": "1227919",
    "end": "1231720"
  },
  {
    "text": "Q uh next uh let me explain uh about",
    "start": "1235080",
    "end": "1241000"
  },
  {
    "text": "Q uh so first of all uh let me explain what is Q uh Q is a job Riv schedule uh",
    "start": "1241000",
    "end": "1248840"
  },
  {
    "text": "and not part schedule uh because the cube scheduler is responsible for",
    "start": "1248840",
    "end": "1254840"
  },
  {
    "text": "poing uh this is responsible for determining uh when we should start and",
    "start": "1254840",
    "end": "1260280"
  },
  {
    "text": "stop job uh this is relevant uh to one of the",
    "start": "1260280",
    "end": "1265360"
  },
  {
    "text": "our advantage our primary advantages are that uh Q can delay the Creator partt uh",
    "start": "1265360",
    "end": "1275200"
  },
  {
    "text": "as a result uh we can avoid uh creation of paining pots uh by this advantages uh",
    "start": "1275200",
    "end": "1282000"
  },
  {
    "text": "we can uh we can reduce uh Cube APS server and Cube schedu uh High",
    "start": "1282000",
    "end": "1289640"
  },
  {
    "text": "World another C feature is uh supporting all R ning semantics uh in machine",
    "start": "1289640",
    "end": "1296360"
  },
  {
    "text": "learning field uh we op for the reader and worker button and uh such workers",
    "start": "1296360",
    "end": "1302799"
  },
  {
    "text": "require all part start at the same time also uh for sure uh Q supports qu",
    "start": "1302799",
    "end": "1310120"
  },
  {
    "text": "management and queuing uh next uh let me show you uh",
    "start": "1310120",
    "end": "1317480"
  },
  {
    "text": "supported integration uh currently uh we support the eight",
    "start": "1317480",
    "end": "1322679"
  },
  {
    "text": "types Frameworks and uh the supporting is started since uh HQ",
    "start": "1322679",
    "end": "1329679"
  },
  {
    "text": "version also uh if we want to use another OSS or in-house job uh you can",
    "start": "1329679",
    "end": "1337120"
  },
  {
    "text": "support the job uh by implementing small controller uh implemented uh Q job",
    "start": "1337120",
    "end": "1344279"
  },
  {
    "text": "interfaces uh in the next slide uh let me explain uh rate supported framework",
    "start": "1344279",
    "end": "1350159"
  },
  {
    "text": "pot group feature uh pot group uh indicate uh set",
    "start": "1350159",
    "end": "1357480"
  },
  {
    "text": "of pramee ports uh Q supports uh pramee ports managed by external",
    "start": "1357480",
    "end": "1362880"
  },
  {
    "text": "controllers uh such as uh traditional job",
    "start": "1362880",
    "end": "1368200"
  },
  {
    "text": "controllers so uh we don't support uh Advanced feature such as uh Recreation",
    "start": "1368200",
    "end": "1375080"
  },
  {
    "text": "or Recreation of uh failed pots all right uh batch job but uh we still",
    "start": "1375080",
    "end": "1383760"
  },
  {
    "text": "recommend to use job share this or uh batch a brilliant",
    "start": "1383760",
    "end": "1390000"
  },
  {
    "text": "job uh next feature is a cross stop policy uh the primary motivation is uh",
    "start": "1391720",
    "end": "1398840"
  },
  {
    "text": "stopping to admit new jobs uh when we maintain uh dedicated nodes or uh we",
    "start": "1398840",
    "end": "1406120"
  },
  {
    "text": "stop using dedicated crust IQ uh we want to stop to admit new",
    "start": "1406120",
    "end": "1411919"
  },
  {
    "text": "jobs currently uh we provide uh three types policy uh known uh hold on drain",
    "start": "1411919",
    "end": "1419279"
  },
  {
    "text": "and hold the first one is none uh the cross continue to admit job",
    "start": "1419279",
    "end": "1427279"
  },
  {
    "text": "uh this is defa policy the second one is uh hold and",
    "start": "1427279",
    "end": "1432840"
  },
  {
    "text": "drain the cross stopped to admit new jobs and drain are already M jobs but",
    "start": "1432840",
    "end": "1440760"
  },
  {
    "text": "the job uh but jobs that borrow quarter from other crust IQ are with in",
    "start": "1440760",
    "end": "1447240"
  },
  {
    "text": "cohort will not be drained the last one is hold this is",
    "start": "1447240",
    "end": "1453120"
  },
  {
    "text": "similar policy is hold and drain but job is not uh drained from node this policy",
    "start": "1453120",
    "end": "1460600"
  },
  {
    "text": "is just stopped to admit new jobs the next feature is a ring limit uh",
    "start": "1460600",
    "end": "1469120"
  },
  {
    "text": "as Mi mentioned in the previous slide uh we can configure quara through the",
    "start": "1469120",
    "end": "1474880"
  },
  {
    "text": "nominal quarter and boring limit in the cross cruster que uh but uh only those quarter",
    "start": "1474880",
    "end": "1482760"
  },
  {
    "text": "configurations uh cruster Q cannot prevent to Rend resources to other crust",
    "start": "1482760",
    "end": "1489399"
  },
  {
    "text": "qes so we introduce the rending liit as another Knob to configure",
    "start": "1489399",
    "end": "1495679"
  },
  {
    "text": "coder additionally uh it all us to prevent over rending or Reserve quarter",
    "start": "1495679",
    "end": "1502080"
  },
  {
    "text": "for latency sensitive work Ross such as machine learning inference",
    "start": "1502080",
    "end": "1507159"
  },
  {
    "text": "Services especially uh reserving quarter uh we are planning to provide",
    "start": "1507159",
    "end": "1513000"
  },
  {
    "text": "integration with kab uh so it is possible to manage various types of",
    "start": "1513000",
    "end": "1518440"
  },
  {
    "text": "workers only by Q in a single node single",
    "start": "1518440",
    "end": "1524480"
  },
  {
    "text": "cruster uh next feature is uh visibility on demand uh this feature exposes the",
    "start": "1525760",
    "end": "1531960"
  },
  {
    "text": "order list of workr every local queue and closser queue uh this feature give",
    "start": "1531960",
    "end": "1538159"
  },
  {
    "text": "users um possibility to estimate when your job is will",
    "start": "1538159",
    "end": "1544000"
  },
  {
    "text": "start also this feature provides a remit and offset to be able to obtain expected",
    "start": "1544000",
    "end": "1551320"
  },
  {
    "text": "risk currently we provide only this information as cube APS server extension",
    "start": "1551320",
    "end": "1557120"
  },
  {
    "text": "point but we are planning to support uh dedicated c c and web dashboard to",
    "start": "1557120",
    "end": "1564120"
  },
  {
    "text": "obtain this information easily uh the next feature is uh work",
    "start": "1564120",
    "end": "1572679"
  },
  {
    "text": "priority class this feature can provide a similary functionality as kubernetes",
    "start": "1572679",
    "end": "1579559"
  },
  {
    "text": "poort priy class uh but so we often want to define the dedicated priority uh",
    "start": "1579559",
    "end": "1587000"
  },
  {
    "text": "separate from po PRI prity class uh if we want to use the Work World priority",
    "start": "1587000",
    "end": "1592399"
  },
  {
    "text": "class uh we can specify the priority class uh via job rabber right the ref",
    "start": "1592399",
    "end": "1600039"
  },
  {
    "text": "example uh okay so there is a couple of more features that we are like passionate about and would like to uh",
    "start": "1603880",
    "end": "1610440"
  },
  {
    "text": "show you uh so the next is uh maybe it's not doing all that much by itself but",
    "start": "1610440",
    "end": "1616480"
  },
  {
    "text": "it's like a important uh B building block for other uh features so this is basically the plug-in mechanism that let",
    "start": "1616480",
    "end": "1623440"
  },
  {
    "text": "you uh introduce additional conditions before admitting a job so qu um Q",
    "start": "1623440",
    "end": "1630159"
  },
  {
    "text": "normally operates and admits uh jobs based on the qu in the cluster",
    "start": "1630159",
    "end": "1635200"
  },
  {
    "text": "configured uh however with this uh feature you can add external controller",
    "start": "1635200",
    "end": "1641760"
  },
  {
    "text": "uh for example for uh in-house budgeting uh or we also use uh build uh",
    "start": "1641760",
    "end": "1649799"
  },
  {
    "text": "Q native features such as provisioning request integration or multiq using internal controllers to",
    "start": "1649799",
    "end": "1657559"
  },
  {
    "text": "uh uh to uh update the admission check status so let me uh describe the",
    "start": "1657559",
    "end": "1665799"
  },
  {
    "text": "provisioning request integration feature so what we aim to solve with this feature is like our approach to um All",
    "start": "1665799",
    "end": "1674360"
  },
  {
    "text": "or Nothing semantic So currently uh",
    "start": "1674360",
    "end": "1679440"
  },
  {
    "text": "by integrating with cluster autoscaler at a slightly different level than currently So currently we expect cluster",
    "start": "1679440",
    "end": "1686919"
  },
  {
    "text": "autoscaler to provision new nodes but only in reaction to existing pods and this is problem for um uh for machine",
    "start": "1686919",
    "end": "1694159"
  },
  {
    "text": "learning jobs because if you request this way 1,000 uh nodes GPU noes for",
    "start": "1694159",
    "end": "1699960"
  },
  {
    "text": "example you are very likely to hit uh uh GPU stockouts and it's also very likely",
    "start": "1699960",
    "end": "1706279"
  },
  {
    "text": "to take very long in this case up so for a long time you will have many pods that are uh",
    "start": "1706279",
    "end": "1713240"
  },
  {
    "text": "pending so with provisioning request API and this is the API you can specify the",
    "start": "1713240",
    "end": "1720399"
  },
  {
    "text": "before you create the pods you can specify the PO sets so a single po set is basically gives you the number of",
    "start": "1720399",
    "end": "1727760"
  },
  {
    "text": "PODS that you want to have and the pods template specifying among other things the amount of resources needed and so",
    "start": "1727760",
    "end": "1736120"
  },
  {
    "text": "it's a Leist because we want to support genous jobs and then you have provisioning class name so this",
    "start": "1736120",
    "end": "1742559"
  },
  {
    "text": "specifies you the mode uh that you want to the provisioning request to be provisioned uh uh with and then we have",
    "start": "1742559",
    "end": "1750600"
  },
  {
    "text": "custom parameters uh So currently we are working with cluster autoscaler team to",
    "start": "1750600",
    "end": "1757679"
  },
  {
    "text": "support two semantics natively that is check capacity and generic",
    "start": "1757679",
    "end": "1763080"
  },
  {
    "text": "scaleup in case of generic scaleup cluster autoscaler will iteratively try",
    "start": "1763080",
    "end": "1768480"
  },
  {
    "text": "to achieve the um um the the uh requested capacity uh however you can",
    "start": "1768480",
    "end": "1775840"
  },
  {
    "text": "also add custom vendor specific uh Integrations and we already have one for",
    "start": "1775840",
    "end": "1782200"
  },
  {
    "text": "GK that uh uh yeah uses the cute",
    "start": "1782200",
    "end": "1787720"
  },
  {
    "text": "provisioning feature uh and and specific API for that uh so let's take a look how",
    "start": "1787720",
    "end": "1794519"
  },
  {
    "text": "we integrate uh with Q uh this feature so of course as before like in the",
    "start": "1794519",
    "end": "1801039"
  },
  {
    "text": "general workflow in Q the user creates the job the job is suspended and then",
    "start": "1801039",
    "end": "1806200"
  },
  {
    "text": "the quot is reserved and at that moment it is up to Cluster autoscaler to",
    "start": "1806200",
    "end": "1812159"
  },
  {
    "text": "provision the required nodes to fulfill the request once the request is fulfilled we have the new nodes uh it's",
    "start": "1812159",
    "end": "1818799"
  },
  {
    "text": "up to Q again to inject all the necessary um information so that the",
    "start": "1818799",
    "end": "1824039"
  },
  {
    "text": "poorts can find the provisioned nodes the next feature is also building",
    "start": "1824039",
    "end": "1830159"
  },
  {
    "text": "upon the idea of admission check is multi cluster job dispatching so with",
    "start": "1830159",
    "end": "1836440"
  },
  {
    "text": "this feature we want to improve GPU obtainability uh because you can have now clusters in multiple regions and in",
    "start": "1836440",
    "end": "1843960"
  },
  {
    "text": "M different regions you can have the busy hours at different times letting you uh probe the capacity at the given",
    "start": "1843960",
    "end": "1851720"
  },
  {
    "text": "moment for gpus uh and also from different Cloud providers potentially uh another uh",
    "start": "1851720",
    "end": "1859679"
  },
  {
    "text": "thing that you can achieve with this feature is scaling up large computational clusters by splitting them",
    "start": "1859679",
    "end": "1865440"
  },
  {
    "text": "and uh Distributing the load onto uh multiple execution clusters and then the",
    "start": "1865440",
    "end": "1872480"
  },
  {
    "text": "management cluster is uploaded because it does not at all create the pods all the pods are created on the execution",
    "start": "1872480",
    "end": "1879799"
  },
  {
    "text": "clusters let's take a look uh how this works in practice so the user only interacts with the management cluster",
    "start": "1879799",
    "end": "1886200"
  },
  {
    "text": "and creates the job one once the qu is reserved for the job we there is",
    "start": "1886200",
    "end": "1892440"
  },
  {
    "text": "admission check multiq admission check and it awaits for um we Q also then",
    "start": "1892440",
    "end": "1899279"
  },
  {
    "text": "creates workloads we call them prebuilt workloads on all of the",
    "start": "1899279",
    "end": "1904600"
  },
  {
    "text": "um um execution clusters but at this moment we don't yet create pods so we",
    "start": "1904600",
    "end": "1910360"
  },
  {
    "text": "wait until the first workload is admitted and then we delete all the other workloads once this is and only",
    "start": "1910360",
    "end": "1918039"
  },
  {
    "text": "once this is done so we have now one to one corresponds between the selected",
    "start": "1918039",
    "end": "1923159"
  },
  {
    "text": "execution cluster and the management cluster so this is like a very simple conceptual model when you have just uh",
    "start": "1923159",
    "end": "1931240"
  },
  {
    "text": "uh this one to one correspondence and then it's up to multiq to use the managed by um uh flag to you to",
    "start": "1931240",
    "end": "1938880"
  },
  {
    "text": "synchronize the status of the job another feature that we are uh currently",
    "start": "1938880",
    "end": "1945279"
  },
  {
    "text": "working on is uh F sharing so with f sharing if you have unused resources for",
    "start": "1945279",
    "end": "1950760"
  },
  {
    "text": "example team X doesn't work currently or or works on another project team a and",
    "start": "1950760",
    "end": "1956080"
  },
  {
    "text": "Team B could borrow the resources but uh currently in fifo Manor so means this",
    "start": "1956080",
    "end": "1962159"
  },
  {
    "text": "means that there might be imbalances and with fering we resolve the imbalances with",
    "start": "1962159",
    "end": "1967960"
  },
  {
    "text": "preemption and another feature related to qu management is hercal cohorts so we",
    "start": "1967960",
    "end": "1973399"
  },
  {
    "text": "got feedback from users uh that um some big organization require very often",
    "start": "1973399",
    "end": "1979440"
  },
  {
    "text": "deeper um structures to reflect and want to um more control over configuration",
    "start": "1979440",
    "end": "1986480"
  },
  {
    "text": "for quotas at different levels of the organization at the department level or",
    "start": "1986480",
    "end": "1992159"
  },
  {
    "text": "uh Team level and with that feature you can also now prioritize borrowing at uh",
    "start": "1992159",
    "end": "1998720"
  },
  {
    "text": "close distances in the organization structure and also as a batw working",
    "start": "1998720",
    "end": "2004039"
  },
  {
    "text": "group for the last uh couple of meetings we were hosting discussion on the uh Dr",
    "start": "2004039",
    "end": "2010360"
  },
  {
    "text": "uh to uh move and discuss uh path forward from alpha to Beta uh we will",
    "start": "2010360",
    "end": "2017320"
  },
  {
    "text": "see how this uh goes but uh I think the discussions were fruitful on how to",
    "start": "2017320",
    "end": "2022799"
  },
  {
    "text": "integrate cluster AOS scalar and Cube schedular uh with",
    "start": "2022799",
    "end": "2028480"
  },
  {
    "text": "theay and as mentioned we have uh meetings uh so I if you are interested",
    "start": "2028480",
    "end": "2034159"
  },
  {
    "text": "with what we are doing with any of the projects like the jobs at the CU or or the job itself then we invite you to",
    "start": "2034159",
    "end": "2040880"
  },
  {
    "text": "discuss things on slack um at the bar working group Channel or attend the",
    "start": "2040880",
    "end": "2047280"
  },
  {
    "text": "meetings and with that we are happy to take some",
    "start": "2047280",
    "end": "2052078"
  },
  {
    "text": "[Applause]",
    "start": "2055449",
    "end": "2058559"
  },
  {
    "text": "questions",
    "start": "2066720",
    "end": "2069720"
  },
  {
    "text": "um thank you for the nice presentation I'm s from I have a quick question about",
    "start": "2084280",
    "end": "2089398"
  },
  {
    "text": "the you uh before few slides before you had a uh the feature called uh resource",
    "start": "2089399",
    "end": "2096960"
  },
  {
    "text": "reservation in the queue uh can you please go",
    "start": "2096960",
    "end": "2103400"
  },
  {
    "text": "back here yeah okay you mean the provisioning request",
    "start": "2103640",
    "end": "2109440"
  },
  {
    "text": "uh yes I uh it says like you ask for more",
    "start": "2109440",
    "end": "2115119"
  },
  {
    "text": "resources to add to the cluster and then somewh maybe this the provisioning",
    "start": "2115119",
    "end": "2120359"
  },
  {
    "text": "request right yeah yeah so uh how do you manage the the resource reservation when",
    "start": "2120359",
    "end": "2128079"
  },
  {
    "text": "you add the resource to the cluster then are you going to resolve it for some time till the fs come up or so this",
    "start": "2128079",
    "end": "2136000"
  },
  {
    "text": "depends a little bit on the mode of provisioning request uh so uh if we",
    "start": "2136000",
    "end": "2143280"
  },
  {
    "text": "um yeah it entirely depends uh U for example in the check capacity we",
    "start": "2143280",
    "end": "2149359"
  },
  {
    "text": "actually don't provision new nodes we just check if there is enough of capacity in the currently existing nodes",
    "start": "2149359",
    "end": "2156839"
  },
  {
    "text": "right uh so this might be a feature that is helpful for uh clusters on Prem that",
    "start": "2156839",
    "end": "2162240"
  },
  {
    "text": "don't have autoscaling uh for like generic scale up we will scale up the nodes uh in like",
    "start": "2162240",
    "end": "2170760"
  },
  {
    "text": "one to one fashion so you have one job and just the set of dedicated nodes and for what",
    "start": "2170760",
    "end": "2178680"
  },
  {
    "text": "I know it's the same that the uh cute provisioning from GK uh mode does so it",
    "start": "2178680",
    "end": "2186200"
  },
  {
    "text": "Provisions you the new in atomic fashion so you are guaranteed to get your",
    "start": "2186200",
    "end": "2191280"
  },
  {
    "text": "thousand nodes all uh nothing yeah yeah uh the my question is",
    "start": "2191280",
    "end": "2198640"
  },
  {
    "text": "like in the dynamic resource allocation you have kind of like resource claims",
    "start": "2198640",
    "end": "2203880"
  },
  {
    "text": "right so that that that represent that this resource claim is for this specific",
    "start": "2203880",
    "end": "2209119"
  },
  {
    "text": "for Oh you mean like right like the volume claims so",
    "start": "2209119",
    "end": "2216040"
  },
  {
    "text": "claim it that's yours but uh yeah I don't understand but in here if you add",
    "start": "2216040",
    "end": "2221319"
  },
  {
    "text": "resources who's going to manage it I mean like somebody else so this is up to",
    "start": "2221319",
    "end": "2226920"
  },
  {
    "text": "the cluster autoscaler to manage the resources so it's cluster autoscaler that Provisions the resources and once",
    "start": "2226920",
    "end": "2234040"
  },
  {
    "text": "the pods like the job complete and the pods are uh gone then it's cluster",
    "start": "2234040",
    "end": "2240000"
  },
  {
    "text": "autoscaler that will scale down uh the resources okay thank you very much",
    "start": "2240000",
    "end": "2246520"
  },
  {
    "text": "mhm",
    "start": "2246520",
    "end": "2249520"
  },
  {
    "text": "okay I think we are done so thank you once again thank",
    "start": "2256839",
    "end": "2262839"
  },
  {
    "text": "you",
    "start": "2263480",
    "end": "2266480"
  }
]
[
  {
    "text": "hello everyone welcome to our talk on",
    "start": "719",
    "end": "2800"
  },
  {
    "text": "discontiguous ciders for dynamic cluster",
    "start": "2800",
    "end": "5040"
  },
  {
    "text": "scaling",
    "start": "5040",
    "end": "5920"
  },
  {
    "text": "uh let's jump into some introductions my",
    "start": "5920",
    "end": "8400"
  },
  {
    "text": "name is rahul zoshi",
    "start": "8400",
    "end": "9760"
  },
  {
    "text": "i am a software engineer working at",
    "start": "9760",
    "end": "12000"
  },
  {
    "text": "google on gk networking",
    "start": "12000",
    "end": "15200"
  },
  {
    "text": "hello everyone my name is sudeep modi",
    "start": "15200",
    "end": "17600"
  },
  {
    "text": "and i am a software engineer working in",
    "start": "17600",
    "end": "19520"
  },
  {
    "text": "the same team as rahul",
    "start": "19520",
    "end": "20720"
  },
  {
    "text": "gk networking and the two of us have",
    "start": "20720",
    "end": "23199"
  },
  {
    "text": "been working on this problem for about",
    "start": "23199",
    "end": "25359"
  },
  {
    "text": "over a year",
    "start": "25359",
    "end": "27920"
  },
  {
    "text": "so what is the goal of the talk today we",
    "start": "27920",
    "end": "30240"
  },
  {
    "text": "want to",
    "start": "30240",
    "end": "31760"
  },
  {
    "text": "present our proposal to support",
    "start": "31760",
    "end": "34079"
  },
  {
    "text": "discontiguous",
    "start": "34079",
    "end": "35840"
  },
  {
    "text": "ranges for port ips and the reason why",
    "start": "35840",
    "end": "38320"
  },
  {
    "text": "we want to support discontiguous ranges",
    "start": "38320",
    "end": "40160"
  },
  {
    "text": "is to enable flexible ip address",
    "start": "40160",
    "end": "42160"
  },
  {
    "text": "allocation",
    "start": "42160",
    "end": "43280"
  },
  {
    "text": "as well as remove one of the major",
    "start": "43280",
    "end": "45120"
  },
  {
    "text": "bottlenecks for scaling a cluster",
    "start": "45120",
    "end": "47600"
  },
  {
    "text": "by the end of this talk our goal is that",
    "start": "47600",
    "end": "49840"
  },
  {
    "text": "you understand the",
    "start": "49840",
    "end": "50879"
  },
  {
    "text": "problem we are trying to solve you",
    "start": "50879",
    "end": "53120"
  },
  {
    "text": "understand why it's important to solve",
    "start": "53120",
    "end": "55120"
  },
  {
    "text": "this problem",
    "start": "55120",
    "end": "56239"
  },
  {
    "text": "we'll introduce some of the difficulties",
    "start": "56239",
    "end": "58320"
  },
  {
    "text": "and challenges in solving the problem",
    "start": "58320",
    "end": "60079"
  },
  {
    "text": "and finally we are going to present a",
    "start": "60079",
    "end": "61600"
  },
  {
    "text": "proposal on how to actually solve the",
    "start": "61600",
    "end": "63440"
  },
  {
    "text": "problem",
    "start": "63440",
    "end": "65119"
  },
  {
    "text": "so that's the agenda today we i'm going",
    "start": "65119",
    "end": "67119"
  },
  {
    "text": "to talk about",
    "start": "67119",
    "end": "68560"
  },
  {
    "text": "how kubernetes pod ip allocation is done",
    "start": "68560",
    "end": "71680"
  },
  {
    "text": "one thing to note is i'm talking about",
    "start": "71680",
    "end": "73360"
  },
  {
    "text": "vanilla open source kubernetes i'm not",
    "start": "73360",
    "end": "75600"
  },
  {
    "text": "talking about some of the bells and",
    "start": "75600",
    "end": "76960"
  },
  {
    "text": "whistles that cloud providers had",
    "start": "76960",
    "end": "80159"
  },
  {
    "text": "and how kubernetes works out of the box",
    "start": "80159",
    "end": "82240"
  },
  {
    "text": "basically",
    "start": "82240",
    "end": "83360"
  },
  {
    "text": "i'm going to talk about some potential",
    "start": "83360",
    "end": "85200"
  },
  {
    "text": "improvements that we can make to the way",
    "start": "85200",
    "end": "87040"
  },
  {
    "text": "we do",
    "start": "87040",
    "end": "87680"
  },
  {
    "text": "pod ip allocation today we are going to",
    "start": "87680",
    "end": "90880"
  },
  {
    "text": "talk about cluster cider",
    "start": "90880",
    "end": "92799"
  },
  {
    "text": "in kubernetes and cluster cider is this",
    "start": "92799",
    "end": "94720"
  },
  {
    "text": "one single pod ip range that you",
    "start": "94720",
    "end": "97040"
  },
  {
    "text": "provide today and then finally we're",
    "start": "97040",
    "end": "100240"
  },
  {
    "text": "going to talk through",
    "start": "100240",
    "end": "101200"
  },
  {
    "text": "our proposal on enhancing and supporting",
    "start": "101200",
    "end": "103439"
  },
  {
    "text": "this contiguous spot ip ranges",
    "start": "103439",
    "end": "105600"
  },
  {
    "text": "and finally we will talk about some of",
    "start": "105600",
    "end": "108159"
  },
  {
    "text": "the ongoing work that's going on",
    "start": "108159",
    "end": "109840"
  },
  {
    "text": "in the community as at the time of this",
    "start": "109840",
    "end": "112840"
  },
  {
    "text": "recording",
    "start": "112840",
    "end": "114880"
  },
  {
    "text": "so this is a typical way a cluster comes",
    "start": "114880",
    "end": "118320"
  },
  {
    "text": "up",
    "start": "118320",
    "end": "118640"
  },
  {
    "text": "for a customer you have on your",
    "start": "118640",
    "end": "122479"
  },
  {
    "text": "network ip space and when you bring up a",
    "start": "122479",
    "end": "124880"
  },
  {
    "text": "cluster kubernetes ask you to ask you",
    "start": "124880",
    "end": "126880"
  },
  {
    "text": "this question give me a cluster slider",
    "start": "126880",
    "end": "129679"
  },
  {
    "text": "the cluster slider is this one large",
    "start": "129679",
    "end": "132000"
  },
  {
    "text": "range",
    "start": "132000",
    "end": "132720"
  },
  {
    "text": "from which all pod ips are allocated and",
    "start": "132720",
    "end": "135840"
  },
  {
    "text": "in our example cluster over here",
    "start": "135840",
    "end": "138080"
  },
  {
    "text": "we have allocated a 17 range for this",
    "start": "138080",
    "end": "141280"
  },
  {
    "text": "new cluster",
    "start": "141280",
    "end": "142560"
  },
  {
    "text": "and this gives us roughly 32 000 ips for",
    "start": "142560",
    "end": "146080"
  },
  {
    "text": "that cluster",
    "start": "146080",
    "end": "148080"
  },
  {
    "text": "in addition to the cluster cider",
    "start": "148080",
    "end": "150480"
  },
  {
    "text": "kubernetes also asks you to provide",
    "start": "150480",
    "end": "153120"
  },
  {
    "text": "a node cider mass size the way this",
    "start": "153120",
    "end": "156400"
  },
  {
    "text": "works is",
    "start": "156400",
    "end": "157280"
  },
  {
    "text": "every single time a new node comes up",
    "start": "157280",
    "end": "160400"
  },
  {
    "text": "the range allocator for kubernetes",
    "start": "160400",
    "end": "162319"
  },
  {
    "text": "internally chops up",
    "start": "162319",
    "end": "163840"
  },
  {
    "text": "the large cluster slider into blocks of",
    "start": "163840",
    "end": "167040"
  },
  {
    "text": "the node zero mass size so in this case",
    "start": "167040",
    "end": "169920"
  },
  {
    "text": "24 is the node center mass size so what",
    "start": "169920",
    "end": "171920"
  },
  {
    "text": "is happening is every time a node comes",
    "start": "171920",
    "end": "173760"
  },
  {
    "text": "up",
    "start": "173760",
    "end": "175360"
  },
  {
    "text": "the range allocator is going to allocate",
    "start": "175360",
    "end": "177040"
  },
  {
    "text": "a slash 24",
    "start": "177040",
    "end": "179360"
  },
  {
    "text": "from the cluster cider range to that",
    "start": "179360",
    "end": "182840"
  },
  {
    "text": "node",
    "start": "182840",
    "end": "184480"
  },
  {
    "text": "and the way ip allocation works after",
    "start": "184480",
    "end": "187599"
  },
  {
    "text": "the",
    "start": "187599",
    "end": "188000"
  },
  {
    "text": "pod cider is assigned is independent on",
    "start": "188000",
    "end": "190560"
  },
  {
    "text": "each node",
    "start": "190560",
    "end": "191280"
  },
  {
    "text": "there is no global synchronization each",
    "start": "191280",
    "end": "193360"
  },
  {
    "text": "node is going to look at its own parts",
    "start": "193360",
    "end": "195200"
  },
  {
    "text": "hider",
    "start": "195200",
    "end": "196080"
  },
  {
    "text": "and pick an ip address from that parts",
    "start": "196080",
    "end": "199519"
  },
  {
    "text": "hider independently of any other node",
    "start": "199519",
    "end": "201599"
  },
  {
    "text": "so there's no coordination the",
    "start": "201599",
    "end": "204720"
  },
  {
    "text": "interesting bit is that you also need to",
    "start": "204720",
    "end": "207440"
  },
  {
    "text": "over provision these ips on the nodes",
    "start": "207440",
    "end": "209680"
  },
  {
    "text": "the reason being things like daemon sets",
    "start": "209680",
    "end": "212720"
  },
  {
    "text": "being upgraded or parts going up and",
    "start": "212720",
    "end": "216159"
  },
  {
    "text": "down you don't want to reuse your ip",
    "start": "216159",
    "end": "217760"
  },
  {
    "text": "addresses so you want this buffer",
    "start": "217760",
    "end": "220239"
  },
  {
    "text": "and so even in this case when you have a",
    "start": "220239",
    "end": "222640"
  },
  {
    "text": "slash 24 assigned to the",
    "start": "222640",
    "end": "224560"
  },
  {
    "text": "node you're not going to run anywhere",
    "start": "224560",
    "end": "226319"
  },
  {
    "text": "close to 250 parts you're going to",
    "start": "226319",
    "end": "228080"
  },
  {
    "text": "run for your part so this this",
    "start": "228080",
    "end": "231040"
  },
  {
    "text": "exacerbates the use of ip addresses in",
    "start": "231040",
    "end": "233360"
  },
  {
    "text": "kubernetes",
    "start": "233360",
    "end": "235280"
  },
  {
    "text": "so what are the problems with these ip",
    "start": "235280",
    "end": "237920"
  },
  {
    "text": "allocation",
    "start": "237920",
    "end": "239200"
  },
  {
    "text": "the first problem is that as soon as you",
    "start": "239200",
    "end": "242239"
  },
  {
    "text": "want to create a",
    "start": "242239",
    "end": "244159"
  },
  {
    "text": "cluster the customer needs to go and",
    "start": "244159",
    "end": "246720"
  },
  {
    "text": "allocate a",
    "start": "246720",
    "end": "248080"
  },
  {
    "text": "large a large ip address range for",
    "start": "248080",
    "end": "250879"
  },
  {
    "text": "boards",
    "start": "250879",
    "end": "251680"
  },
  {
    "text": "right up front regardless of how big or",
    "start": "251680",
    "end": "254239"
  },
  {
    "text": "small the cluster is going to be",
    "start": "254239",
    "end": "255680"
  },
  {
    "text": "eventually",
    "start": "255680",
    "end": "257440"
  },
  {
    "text": "so let's say the the users the users",
    "start": "257440",
    "end": "260720"
  },
  {
    "text": "tend to either overestimate or",
    "start": "260720",
    "end": "262320"
  },
  {
    "text": "underestimate the requirements",
    "start": "262320",
    "end": "264479"
  },
  {
    "text": "we've seen errors on both sides for with",
    "start": "264479",
    "end": "266560"
  },
  {
    "text": "our customers",
    "start": "266560",
    "end": "267680"
  },
  {
    "text": "sometimes the user thinks that the",
    "start": "267680",
    "end": "269759"
  },
  {
    "text": "customer",
    "start": "269759",
    "end": "270720"
  },
  {
    "text": "cluster is going to grow to like 250",
    "start": "270720",
    "end": "272639"
  },
  {
    "text": "nodes but",
    "start": "272639",
    "end": "274000"
  },
  {
    "text": "you may not end up putting so many",
    "start": "274000",
    "end": "276400"
  },
  {
    "text": "workloads on it",
    "start": "276400",
    "end": "277680"
  },
  {
    "text": "so at that point if you if you over",
    "start": "277680",
    "end": "280479"
  },
  {
    "text": "project provision your cluster this",
    "start": "280479",
    "end": "282320"
  },
  {
    "text": "ip address wastage however the other",
    "start": "282320",
    "end": "284880"
  },
  {
    "text": "problem is also true where you",
    "start": "284880",
    "end": "286479"
  },
  {
    "text": "don't know upfront that your cluster is",
    "start": "286479",
    "end": "288160"
  },
  {
    "text": "going to grow so large and then",
    "start": "288160",
    "end": "289759"
  },
  {
    "text": "you start sort of start running out of",
    "start": "289759",
    "end": "291600"
  },
  {
    "text": "ip addresses",
    "start": "291600",
    "end": "292880"
  },
  {
    "text": "so at the time of cluster creation you",
    "start": "292880",
    "end": "296000"
  },
  {
    "text": "have to decide how many ips to allocate",
    "start": "296000",
    "end": "298240"
  },
  {
    "text": "and this isn't easy",
    "start": "298240",
    "end": "300160"
  },
  {
    "text": "the second problem is that each",
    "start": "300160",
    "end": "303280"
  },
  {
    "text": "node is going to get the same range",
    "start": "303280",
    "end": "306320"
  },
  {
    "text": "for the part slider so if you have",
    "start": "306320",
    "end": "308400"
  },
  {
    "text": "certain nodes which are of lower",
    "start": "308400",
    "end": "310320"
  },
  {
    "text": "capacity",
    "start": "310320",
    "end": "311360"
  },
  {
    "text": "you have to give them a slash 24 and",
    "start": "311360",
    "end": "312880"
  },
  {
    "text": "waste some ip addresses even though you",
    "start": "312880",
    "end": "314800"
  },
  {
    "text": "cannot run",
    "start": "314800",
    "end": "316080"
  },
  {
    "text": "close to the number of parts that the",
    "start": "316080",
    "end": "317919"
  },
  {
    "text": "larger nodes can run",
    "start": "317919",
    "end": "319280"
  },
  {
    "text": "and some larger nodes can may be able to",
    "start": "319280",
    "end": "321840"
  },
  {
    "text": "run more",
    "start": "321840",
    "end": "323680"
  },
  {
    "text": "parts than what you provisioned for so",
    "start": "323680",
    "end": "326639"
  },
  {
    "text": "they may",
    "start": "326639",
    "end": "327120"
  },
  {
    "text": "be able to run more than 250 pods in",
    "start": "327120",
    "end": "329360"
  },
  {
    "text": "this case but you can't do that because",
    "start": "329360",
    "end": "331280"
  },
  {
    "text": "you run out of ip addresses",
    "start": "331280",
    "end": "332880"
  },
  {
    "text": "so both sides of the problem are in",
    "start": "332880",
    "end": "335840"
  },
  {
    "text": "effect",
    "start": "335840",
    "end": "336880"
  },
  {
    "text": "and then the most interesting and",
    "start": "336880",
    "end": "338720"
  },
  {
    "text": "difficult problem",
    "start": "338720",
    "end": "340000"
  },
  {
    "text": "is that once you provision this cluster",
    "start": "340000",
    "end": "342560"
  },
  {
    "text": "and your clusters let's say grows over",
    "start": "342560",
    "end": "345440"
  },
  {
    "text": "over time in this example if it's grown",
    "start": "345440",
    "end": "348720"
  },
  {
    "text": "to 128 nodes there is absolutely no way",
    "start": "348720",
    "end": "351440"
  },
  {
    "text": "to add another node because you've run",
    "start": "351440",
    "end": "353039"
  },
  {
    "text": "out of ip addresses",
    "start": "353039",
    "end": "354639"
  },
  {
    "text": "customers we've seen customers run into",
    "start": "354639",
    "end": "356639"
  },
  {
    "text": "this problem all the time",
    "start": "356639",
    "end": "358560"
  },
  {
    "text": "and there is no solution the only",
    "start": "358560",
    "end": "360800"
  },
  {
    "text": "solution is to either migrate certain",
    "start": "360800",
    "end": "362639"
  },
  {
    "text": "workloads from this cluster to another",
    "start": "362639",
    "end": "364240"
  },
  {
    "text": "cluster",
    "start": "364240",
    "end": "365039"
  },
  {
    "text": "or you recreate the cluster with a",
    "start": "365039",
    "end": "366720"
  },
  {
    "text": "larger range and start from scratch all",
    "start": "366720",
    "end": "368880"
  },
  {
    "text": "over again and",
    "start": "368880",
    "end": "369680"
  },
  {
    "text": "neither is a very palatable solution",
    "start": "369680",
    "end": "373680"
  },
  {
    "text": "so what are the potential improvements",
    "start": "373680",
    "end": "375600"
  },
  {
    "text": "we can make",
    "start": "375600",
    "end": "376880"
  },
  {
    "text": "to this the first",
    "start": "376880",
    "end": "380000"
  },
  {
    "text": "is to add support for increasing this",
    "start": "380000",
    "end": "383520"
  },
  {
    "text": "cluster cider somehow",
    "start": "383520",
    "end": "385039"
  },
  {
    "text": "and you want to do this in a manner that",
    "start": "385039",
    "end": "387759"
  },
  {
    "text": "doesn't cause any downtime you've run",
    "start": "387759",
    "end": "389280"
  },
  {
    "text": "out of ip addresses there should be a",
    "start": "389280",
    "end": "390800"
  },
  {
    "text": "way to allocate more ips",
    "start": "390800",
    "end": "392479"
  },
  {
    "text": "and i don't want any workloads to suffer",
    "start": "392479",
    "end": "395199"
  },
  {
    "text": "uh",
    "start": "395199",
    "end": "395680"
  },
  {
    "text": "and and if you did this it addresses the",
    "start": "395680",
    "end": "398400"
  },
  {
    "text": "most difficult challenge that i spoke",
    "start": "398400",
    "end": "399919"
  },
  {
    "text": "about in the last slide where you can",
    "start": "399919",
    "end": "401360"
  },
  {
    "text": "actually now",
    "start": "401360",
    "end": "402479"
  },
  {
    "text": "scale your cluster uh where you earlier",
    "start": "402479",
    "end": "405360"
  },
  {
    "text": "could not",
    "start": "405360",
    "end": "406960"
  },
  {
    "text": "the second improvement we can make is we",
    "start": "406960",
    "end": "409199"
  },
  {
    "text": "can we can allow specifying",
    "start": "409199",
    "end": "411440"
  },
  {
    "text": "discontiguous",
    "start": "411440",
    "end": "412560"
  },
  {
    "text": "ranges for pods and this is true even at",
    "start": "412560",
    "end": "416400"
  },
  {
    "text": "cluster startup time there are certain",
    "start": "416400",
    "end": "418000"
  },
  {
    "text": "customers where we see",
    "start": "418000",
    "end": "419440"
  },
  {
    "text": "they don't have a large chunk of a slash",
    "start": "419440",
    "end": "421440"
  },
  {
    "text": "17 lying around",
    "start": "421440",
    "end": "422639"
  },
  {
    "text": "but maybe they have smaller slash 20s",
    "start": "422639",
    "end": "425759"
  },
  {
    "text": "lying around and they want to still",
    "start": "425759",
    "end": "427199"
  },
  {
    "text": "create",
    "start": "427199",
    "end": "427919"
  },
  {
    "text": "a large cluster so you need to be able",
    "start": "427919",
    "end": "430800"
  },
  {
    "text": "to specify these discontiguous power",
    "start": "430800",
    "end": "432880"
  },
  {
    "text": "ranges at cluster startup time",
    "start": "432880",
    "end": "434560"
  },
  {
    "text": "or this can come when you expand your",
    "start": "434560",
    "end": "436319"
  },
  {
    "text": "cluster and",
    "start": "436319",
    "end": "437680"
  },
  {
    "text": "this addresses the problem that a lot of",
    "start": "437680",
    "end": "439680"
  },
  {
    "text": "customers run into",
    "start": "439680",
    "end": "441039"
  },
  {
    "text": "when they have a fragmented ip space and",
    "start": "441039",
    "end": "443840"
  },
  {
    "text": "then finally",
    "start": "443840",
    "end": "444960"
  },
  {
    "text": "you want to accommodate the different",
    "start": "444960",
    "end": "447440"
  },
  {
    "text": "nodes in the different sizes of nodes",
    "start": "447440",
    "end": "450000"
  },
  {
    "text": "as in order to more efficiently use ips",
    "start": "450000",
    "end": "452800"
  },
  {
    "text": "across the node so",
    "start": "452800",
    "end": "453840"
  },
  {
    "text": "smaller nodes can get smaller less fewer",
    "start": "453840",
    "end": "456880"
  },
  {
    "text": "ips and larger nodes can get",
    "start": "456880",
    "end": "458639"
  },
  {
    "text": "larger ips you need to be able to",
    "start": "458639",
    "end": "460319"
  },
  {
    "text": "specify this",
    "start": "460319",
    "end": "463039"
  },
  {
    "text": "the biggest challenge on this is going",
    "start": "463039",
    "end": "466000"
  },
  {
    "text": "to be the dependency on cluster cider",
    "start": "466000",
    "end": "468400"
  },
  {
    "text": "so what kubernetes components are today",
    "start": "468400",
    "end": "472319"
  },
  {
    "text": "depending on this large one cluster",
    "start": "472319",
    "end": "474240"
  },
  {
    "text": "cider range so we have to go and",
    "start": "474240",
    "end": "475680"
  },
  {
    "text": "investigate that",
    "start": "475680",
    "end": "476960"
  },
  {
    "text": "and then we wanted to go and remove the",
    "start": "476960",
    "end": "479280"
  },
  {
    "text": "dependency",
    "start": "479280",
    "end": "480400"
  },
  {
    "text": "on this single contiguous side of block",
    "start": "480400",
    "end": "483039"
  },
  {
    "text": "so rahul is going to talk about the work",
    "start": "483039",
    "end": "485039"
  },
  {
    "text": "that we have done and that we are",
    "start": "485039",
    "end": "486800"
  },
  {
    "text": "we are still doing",
    "start": "486800",
    "end": "489680"
  },
  {
    "text": "thanks sadiq uh when we started looking",
    "start": "490960",
    "end": "493840"
  },
  {
    "text": "through",
    "start": "493840",
    "end": "494240"
  },
  {
    "text": "the kubernetes code to find out what",
    "start": "494240",
    "end": "496319"
  },
  {
    "text": "components were using cluster cider we",
    "start": "496319",
    "end": "498000"
  },
  {
    "text": "found",
    "start": "498000",
    "end": "498479"
  },
  {
    "text": "two uh major components the first is the",
    "start": "498479",
    "end": "501680"
  },
  {
    "text": "node ipam controller",
    "start": "501680",
    "end": "503280"
  },
  {
    "text": "this component runs as part of the cube",
    "start": "503280",
    "end": "505440"
  },
  {
    "text": "controller manager",
    "start": "505440",
    "end": "506720"
  },
  {
    "text": "and it performs the allocation of the",
    "start": "506720",
    "end": "509280"
  },
  {
    "text": "per node ip ranges",
    "start": "509280",
    "end": "510800"
  },
  {
    "text": "this is what we described earlier in the",
    "start": "510800",
    "end": "512719"
  },
  {
    "text": "presentation it",
    "start": "512719",
    "end": "514000"
  },
  {
    "text": "chops up your large 17 into smaller",
    "start": "514000",
    "end": "517680"
  },
  {
    "text": "24s this obviously needs the cluster",
    "start": "517680",
    "end": "520399"
  },
  {
    "text": "cider so it knows what range it's",
    "start": "520399",
    "end": "522240"
  },
  {
    "text": "allocating",
    "start": "522240",
    "end": "523440"
  },
  {
    "text": "the second component is the cube proxy",
    "start": "523440",
    "end": "526240"
  },
  {
    "text": "this is kubernetes network proxy that",
    "start": "526240",
    "end": "528480"
  },
  {
    "text": "runs on every node",
    "start": "528480",
    "end": "530320"
  },
  {
    "text": "the q proxy is responsible for",
    "start": "530320",
    "end": "532160"
  },
  {
    "text": "maintaining the network rules",
    "start": "532160",
    "end": "534240"
  },
  {
    "text": "for things like service resolution and",
    "start": "534240",
    "end": "536720"
  },
  {
    "text": "handling inter",
    "start": "536720",
    "end": "537760"
  },
  {
    "text": "and intra cluster traffic so pod to pod",
    "start": "537760",
    "end": "540720"
  },
  {
    "text": "traffic as well as",
    "start": "540720",
    "end": "542080"
  },
  {
    "text": "traffic that is external to your cluster",
    "start": "542080",
    "end": "544000"
  },
  {
    "text": "that wants to ingress",
    "start": "544000",
    "end": "546000"
  },
  {
    "text": "let's first discuss how cube proxy uses",
    "start": "546000",
    "end": "549040"
  },
  {
    "text": "the cluster sider",
    "start": "549040",
    "end": "550560"
  },
  {
    "text": "to make its routing decisions and then",
    "start": "550560",
    "end": "552880"
  },
  {
    "text": "we'll talk about",
    "start": "552880",
    "end": "554000"
  },
  {
    "text": "how we remove the dependency from cube",
    "start": "554000",
    "end": "556000"
  },
  {
    "text": "proxy",
    "start": "556000",
    "end": "557760"
  },
  {
    "text": "one of the rules that q proxy references",
    "start": "557760",
    "end": "561040"
  },
  {
    "text": "cluster cider with",
    "start": "561040",
    "end": "562320"
  },
  {
    "text": "is the one for redirecting pod traffic",
    "start": "562320",
    "end": "565120"
  },
  {
    "text": "destined for external load balancer vips",
    "start": "565120",
    "end": "567600"
  },
  {
    "text": "so in this scenario the user has",
    "start": "567600",
    "end": "569360"
  },
  {
    "text": "configured a service",
    "start": "569360",
    "end": "570720"
  },
  {
    "text": "um as an external load balancer and",
    "start": "570720",
    "end": "573200"
  },
  {
    "text": "they've received",
    "start": "573200",
    "end": "574480"
  },
  {
    "text": "a load balancer ip that would",
    "start": "574480",
    "end": "577680"
  },
  {
    "text": "normally redirect traffic outside of the",
    "start": "577680",
    "end": "580160"
  },
  {
    "text": "cluster",
    "start": "580160",
    "end": "580800"
  },
  {
    "text": "to back ends inside of the cluster",
    "start": "580800",
    "end": "583120"
  },
  {
    "text": "however if",
    "start": "583120",
    "end": "584080"
  },
  {
    "text": "a pod uses that external load balancer",
    "start": "584080",
    "end": "587120"
  },
  {
    "text": "ip",
    "start": "587120",
    "end": "587760"
  },
  {
    "text": "to try to access the service the cube",
    "start": "587760",
    "end": "590080"
  },
  {
    "text": "proxy takes note of that",
    "start": "590080",
    "end": "591760"
  },
  {
    "text": "and the cube proxy's goal in this case",
    "start": "591760",
    "end": "593839"
  },
  {
    "text": "is to prevent the traffic from",
    "start": "593839",
    "end": "595440"
  },
  {
    "text": "unnecessarily egressing your cluster",
    "start": "595440",
    "end": "597519"
  },
  {
    "text": "hitting the external load balancer and",
    "start": "597519",
    "end": "599200"
  },
  {
    "text": "then just coming back in",
    "start": "599200",
    "end": "600880"
  },
  {
    "text": "so instead it short circuits the entire",
    "start": "600880",
    "end": "602959"
  },
  {
    "text": "process by redirecting",
    "start": "602959",
    "end": "604880"
  },
  {
    "text": "the pods traffic directly to a service",
    "start": "604880",
    "end": "606800"
  },
  {
    "text": "backend in this case the queue proxy",
    "start": "606800",
    "end": "609120"
  },
  {
    "text": "looks at its definition of the service",
    "start": "609120",
    "end": "611279"
  },
  {
    "text": "and decides to route the traffic to pod",
    "start": "611279",
    "end": "613600"
  },
  {
    "text": "for one of the",
    "start": "613600",
    "end": "614959"
  },
  {
    "text": "existing backends and then the clusters",
    "start": "614959",
    "end": "617279"
  },
  {
    "text": "network is able to take care of that",
    "start": "617279",
    "end": "619120"
  },
  {
    "text": "routing",
    "start": "619120",
    "end": "619760"
  },
  {
    "text": "and then on the return path the q proxy",
    "start": "619760",
    "end": "622079"
  },
  {
    "text": "would reverse",
    "start": "622079",
    "end": "623120"
  },
  {
    "text": "these uh natting decisions so that the",
    "start": "623120",
    "end": "625920"
  },
  {
    "text": "pod thinks it's spoken with",
    "start": "625920",
    "end": "627680"
  },
  {
    "text": "a service in this case q proxy is using",
    "start": "627680",
    "end": "630560"
  },
  {
    "text": "cluster sider",
    "start": "630560",
    "end": "631519"
  },
  {
    "text": "to determine whether the traffic is",
    "start": "631519",
    "end": "634240"
  },
  {
    "text": "originating inside of the cluster or if",
    "start": "634240",
    "end": "636560"
  },
  {
    "text": "it's coming from outside of the cluster",
    "start": "636560",
    "end": "639600"
  },
  {
    "text": "another rule where q proxy is using",
    "start": "639600",
    "end": "641440"
  },
  {
    "text": "cluster cider is to masquerade off",
    "start": "641440",
    "end": "643680"
  },
  {
    "text": "cluster traffic",
    "start": "643680",
    "end": "644880"
  },
  {
    "text": "to service vips within the cluster so in",
    "start": "644880",
    "end": "648079"
  },
  {
    "text": "this case",
    "start": "648079",
    "end": "648880"
  },
  {
    "text": "you have some sort of traffic outside of",
    "start": "648880",
    "end": "651200"
  },
  {
    "text": "your cluster",
    "start": "651200",
    "end": "652000"
  },
  {
    "text": "that wants to talk to a service fit",
    "start": "652000",
    "end": "653519"
  },
  {
    "text": "maybe you have a forwarding rule",
    "start": "653519",
    "end": "655120"
  },
  {
    "text": "in your network that sends traffic to",
    "start": "655120",
    "end": "656959"
  },
  {
    "text": "one of your nodes",
    "start": "656959",
    "end": "658240"
  },
  {
    "text": "in this case q proxy wants to examine",
    "start": "658240",
    "end": "660720"
  },
  {
    "text": "the packet and it realizes that it's",
    "start": "660720",
    "end": "662160"
  },
  {
    "text": "destined for a service that it knows",
    "start": "662160",
    "end": "663600"
  },
  {
    "text": "about",
    "start": "663600",
    "end": "664480"
  },
  {
    "text": "um however it can't just forward the",
    "start": "664480",
    "end": "666720"
  },
  {
    "text": "packet to one of the back end pods",
    "start": "666720",
    "end": "669200"
  },
  {
    "text": "it's not sure if the backend pods have",
    "start": "669200",
    "end": "671760"
  },
  {
    "text": "connectivity with this external ip",
    "start": "671760",
    "end": "673760"
  },
  {
    "text": "maybe there are firewall rules or other",
    "start": "673760",
    "end": "675519"
  },
  {
    "text": "egress or protections in place",
    "start": "675519",
    "end": "677760"
  },
  {
    "text": "however it does know that the node it's",
    "start": "677760",
    "end": "679440"
  },
  {
    "text": "running on can speak with this external",
    "start": "679440",
    "end": "681440"
  },
  {
    "text": "ip so it uses the node as an additional",
    "start": "681440",
    "end": "683839"
  },
  {
    "text": "hop",
    "start": "683839",
    "end": "684800"
  },
  {
    "text": "it rewrites the packet using a snap to",
    "start": "684800",
    "end": "688079"
  },
  {
    "text": "swap out the external ip for the node ip",
    "start": "688079",
    "end": "690800"
  },
  {
    "text": "and then using the standard service",
    "start": "690800",
    "end": "692399"
  },
  {
    "text": "resolution",
    "start": "692399",
    "end": "693360"
  },
  {
    "text": "it performs a dnat to reference one of",
    "start": "693360",
    "end": "696000"
  },
  {
    "text": "the backend pods",
    "start": "696000",
    "end": "697279"
  },
  {
    "text": "and then q proxy sends the packet on the",
    "start": "697279",
    "end": "699920"
  },
  {
    "text": "cluster network",
    "start": "699920",
    "end": "701200"
  },
  {
    "text": "towards the back end on the reverse path",
    "start": "701200",
    "end": "703600"
  },
  {
    "text": "it again reverses all of its",
    "start": "703600",
    "end": "705040"
  },
  {
    "text": "adding decisions and forwards the",
    "start": "705040",
    "end": "707120"
  },
  {
    "text": "response out to the external ip",
    "start": "707120",
    "end": "710079"
  },
  {
    "text": "again in this case cube proxy is using",
    "start": "710079",
    "end": "712320"
  },
  {
    "text": "the cluster sider to determine",
    "start": "712320",
    "end": "714320"
  },
  {
    "text": "the origin of traffic and whether or not",
    "start": "714320",
    "end": "716880"
  },
  {
    "text": "it's",
    "start": "716880",
    "end": "717360"
  },
  {
    "text": "coming from outside the cluster or from",
    "start": "717360",
    "end": "719279"
  },
  {
    "text": "a pod inside the cluster",
    "start": "719279",
    "end": "721760"
  },
  {
    "text": "the key insight that we had when looking",
    "start": "721760",
    "end": "723839"
  },
  {
    "text": "at these rules",
    "start": "723839",
    "end": "725040"
  },
  {
    "text": "was that q proxy doesn't need to know",
    "start": "725040",
    "end": "727440"
  },
  {
    "text": "about the entire",
    "start": "727440",
    "end": "729279"
  },
  {
    "text": "cluster cider about the ips of every",
    "start": "729279",
    "end": "731120"
  },
  {
    "text": "single pod it only needs to know about",
    "start": "731120",
    "end": "733920"
  },
  {
    "text": "the pot ips for pods running on that",
    "start": "733920",
    "end": "736800"
  },
  {
    "text": "particular node",
    "start": "736800",
    "end": "738639"
  },
  {
    "text": "because every node's cube processes",
    "start": "738639",
    "end": "740399"
  },
  {
    "text": "running we can rely on",
    "start": "740399",
    "end": "742560"
  },
  {
    "text": "every single q proxy to properly make uh",
    "start": "742560",
    "end": "745440"
  },
  {
    "text": "dna",
    "start": "745440",
    "end": "746000"
  },
  {
    "text": "and snap decisions at the point that",
    "start": "746000",
    "end": "748639"
  },
  {
    "text": "they encounter traffic",
    "start": "748639",
    "end": "749920"
  },
  {
    "text": "if you see traffic for a particular vip",
    "start": "749920",
    "end": "753120"
  },
  {
    "text": "that doesn't seem to be coming from your",
    "start": "753120",
    "end": "755440"
  },
  {
    "text": "own pods",
    "start": "755440",
    "end": "756399"
  },
  {
    "text": "you can be very confident that that",
    "start": "756399",
    "end": "758079"
  },
  {
    "text": "traffic came from outside of the cluster",
    "start": "758079",
    "end": "760320"
  },
  {
    "text": "as every other node would have made a",
    "start": "760320",
    "end": "762079"
  },
  {
    "text": "correct routing decision",
    "start": "762079",
    "end": "763839"
  },
  {
    "text": "so in that case you can rely only on",
    "start": "763839",
    "end": "765760"
  },
  {
    "text": "your internal pod cider without worrying",
    "start": "765760",
    "end": "767839"
  },
  {
    "text": "about the cluster's global",
    "start": "767839",
    "end": "769519"
  },
  {
    "text": "sider this is part of the proposal",
    "start": "769519",
    "end": "773360"
  },
  {
    "text": "that was recently that was added into",
    "start": "773360",
    "end": "776240"
  },
  {
    "text": "the open source",
    "start": "776240",
    "end": "777360"
  },
  {
    "text": "uh community uh this kept talks about",
    "start": "777360",
    "end": "780399"
  },
  {
    "text": "these examples and a few more and walks",
    "start": "780399",
    "end": "782639"
  },
  {
    "text": "through in greater detail",
    "start": "782639",
    "end": "783839"
  },
  {
    "text": "exactly the changes that have been made",
    "start": "783839",
    "end": "787040"
  },
  {
    "text": "thanks to this kep the q proxy is",
    "start": "787040",
    "end": "788959"
  },
  {
    "text": "capable of programming iptables and",
    "start": "788959",
    "end": "791440"
  },
  {
    "text": "ipvs using only the local pod sider as",
    "start": "791440",
    "end": "794320"
  },
  {
    "text": "opposed to",
    "start": "794320",
    "end": "795440"
  },
  {
    "text": "the global cluster cider this cap also",
    "start": "795440",
    "end": "798320"
  },
  {
    "text": "added a",
    "start": "798320",
    "end": "799200"
  },
  {
    "text": "brand new flag to enable this behavior",
    "start": "799200",
    "end": "802320"
  },
  {
    "text": "called detect local mode which once used",
    "start": "802320",
    "end": "805279"
  },
  {
    "text": "with node cider",
    "start": "805279",
    "end": "806560"
  },
  {
    "text": "will program using just the local siders",
    "start": "806560",
    "end": "810399"
  },
  {
    "text": "this feature has been available since",
    "start": "810399",
    "end": "812480"
  },
  {
    "text": "kubernetes release",
    "start": "812480",
    "end": "814079"
  },
  {
    "text": "1.18 this cap and the changes to q proxy",
    "start": "814079",
    "end": "819120"
  },
  {
    "text": "removed the single biggest kubernetes",
    "start": "819120",
    "end": "822240"
  },
  {
    "text": "assumption around a contiguous cider",
    "start": "822240",
    "end": "824639"
  },
  {
    "text": "block",
    "start": "824639",
    "end": "825680"
  },
  {
    "text": "now that q proxy can function using just",
    "start": "825680",
    "end": "828000"
  },
  {
    "text": "its own pod sider",
    "start": "828000",
    "end": "830000"
  },
  {
    "text": "we don't need to rely on a monolithic",
    "start": "830000",
    "end": "831839"
  },
  {
    "text": "cluster sider and we can",
    "start": "831839",
    "end": "833519"
  },
  {
    "text": "turn our attention to the allocation",
    "start": "833519",
    "end": "835279"
  },
  {
    "text": "side of things",
    "start": "835279",
    "end": "837279"
  },
  {
    "text": "on the allocation side of things we're",
    "start": "837279",
    "end": "839040"
  },
  {
    "text": "back to the node ipam controller that",
    "start": "839040",
    "end": "841199"
  },
  {
    "text": "we'd mentioned earlier",
    "start": "841199",
    "end": "842720"
  },
  {
    "text": "this is the component that allocates",
    "start": "842720",
    "end": "845199"
  },
  {
    "text": "each node its actual pod ip",
    "start": "845199",
    "end": "847920"
  },
  {
    "text": "or a pod ip block when you drill down",
    "start": "847920",
    "end": "850800"
  },
  {
    "text": "into it it",
    "start": "850800",
    "end": "851760"
  },
  {
    "text": "has two one has two modes that it can",
    "start": "851760",
    "end": "853839"
  },
  {
    "text": "operate",
    "start": "853839",
    "end": "854880"
  },
  {
    "text": "the first of these is the range",
    "start": "854880",
    "end": "856320"
  },
  {
    "text": "allocator this is what kubernetes runs",
    "start": "856320",
    "end": "858399"
  },
  {
    "text": "by default",
    "start": "858399",
    "end": "859440"
  },
  {
    "text": "this accepts a cluster sider and a node",
    "start": "859440",
    "end": "861839"
  },
  {
    "text": "cider mask",
    "start": "861839",
    "end": "862639"
  },
  {
    "text": "which is how big of a block how big of a",
    "start": "862639",
    "end": "865519"
  },
  {
    "text": "block",
    "start": "865519",
    "end": "866160"
  },
  {
    "text": "to assign to each node and it chunks up",
    "start": "866160",
    "end": "868800"
  },
  {
    "text": "the cluster sider and then allocates",
    "start": "868800",
    "end": "870399"
  },
  {
    "text": "that out writing the",
    "start": "870399",
    "end": "872000"
  },
  {
    "text": "per node chunks in the node.podcider",
    "start": "872000",
    "end": "874800"
  },
  {
    "text": "spec",
    "start": "874800",
    "end": "875360"
  },
  {
    "text": "this is exactly the algorithm that we",
    "start": "875360",
    "end": "878240"
  },
  {
    "text": "described earlier in the presentation",
    "start": "878240",
    "end": "880399"
  },
  {
    "text": "the other mode of operation is the cloud",
    "start": "880399",
    "end": "882480"
  },
  {
    "text": "allocator in this case",
    "start": "882480",
    "end": "884160"
  },
  {
    "text": "the cloud allocator relies on your cloud",
    "start": "884160",
    "end": "886320"
  },
  {
    "text": "provider to do the per node",
    "start": "886320",
    "end": "888800"
  },
  {
    "text": "allocation it simply queries the cloud",
    "start": "888800",
    "end": "890959"
  },
  {
    "text": "provider retrieves",
    "start": "890959",
    "end": "892639"
  },
  {
    "text": "the information for a particular node",
    "start": "892639",
    "end": "894560"
  },
  {
    "text": "and then writes that back",
    "start": "894560",
    "end": "896160"
  },
  {
    "text": "into the node sider as this model",
    "start": "896160",
    "end": "899199"
  },
  {
    "text": "suggests there's a lot of flexibility",
    "start": "899199",
    "end": "901440"
  },
  {
    "text": "with how the node ipam controller",
    "start": "901440",
    "end": "903440"
  },
  {
    "text": "behaves all kubernetes at a core is",
    "start": "903440",
    "end": "906000"
  },
  {
    "text": "interested in",
    "start": "906000",
    "end": "906800"
  },
  {
    "text": "is that every node gets its pod ip block",
    "start": "906800",
    "end": "910079"
  },
  {
    "text": "so you know end users could come in and",
    "start": "910079",
    "end": "912160"
  },
  {
    "text": "write their own custom controller that",
    "start": "912160",
    "end": "913680"
  },
  {
    "text": "runs instead of node ipam",
    "start": "913680",
    "end": "915600"
  },
  {
    "text": "and performs whatever sort of ipam is",
    "start": "915600",
    "end": "917920"
  },
  {
    "text": "relevant for them",
    "start": "917920",
    "end": "919440"
  },
  {
    "text": "however we wanted a more",
    "start": "919440",
    "end": "922480"
  },
  {
    "text": "useful operation right out of the box",
    "start": "922480",
    "end": "924639"
  },
  {
    "text": "where users don't need to go",
    "start": "924639",
    "end": "926560"
  },
  {
    "text": "configure their own ipam controller just",
    "start": "926560",
    "end": "928880"
  },
  {
    "text": "to expand their cluster slider size",
    "start": "928880",
    "end": "931120"
  },
  {
    "text": "this brings us to the second enhancement",
    "start": "931120",
    "end": "933120"
  },
  {
    "text": "proposal to enhance node ipam to support",
    "start": "933120",
    "end": "935680"
  },
  {
    "text": "multiple cluster siders",
    "start": "935680",
    "end": "937600"
  },
  {
    "text": "this is a kept that as if the recording",
    "start": "937600",
    "end": "939519"
  },
  {
    "text": "is in active development with the",
    "start": "939519",
    "end": "941120"
  },
  {
    "text": "community",
    "start": "941120",
    "end": "942320"
  },
  {
    "text": "it has two major components the first is",
    "start": "942320",
    "end": "945440"
  },
  {
    "text": "a brand new kubernetes resource",
    "start": "945440",
    "end": "947040"
  },
  {
    "text": "called the cluster sider config the",
    "start": "947040",
    "end": "949120"
  },
  {
    "text": "details of this object are still in flux",
    "start": "949120",
    "end": "951680"
  },
  {
    "text": "but broadly speaking it has an ip cider",
    "start": "951680",
    "end": "953920"
  },
  {
    "text": "block from which",
    "start": "953920",
    "end": "955199"
  },
  {
    "text": "every node gets its pot ip chunk",
    "start": "955199",
    "end": "958720"
  },
  {
    "text": "it has a per node mask size which tells",
    "start": "958720",
    "end": "961040"
  },
  {
    "text": "the allocator",
    "start": "961040",
    "end": "962160"
  },
  {
    "text": "how big of a chunk to allocate to each",
    "start": "962160",
    "end": "963839"
  },
  {
    "text": "node and then",
    "start": "963839",
    "end": "965199"
  },
  {
    "text": "there is a node selector which defines",
    "start": "965199",
    "end": "967600"
  },
  {
    "text": "which nodes are targeted",
    "start": "967600",
    "end": "969519"
  },
  {
    "text": "by this cidr config complementary to",
    "start": "969519",
    "end": "972959"
  },
  {
    "text": "this resource",
    "start": "972959",
    "end": "974079"
  },
  {
    "text": "is a brand new allocator this allocator",
    "start": "974079",
    "end": "977920"
  },
  {
    "text": "would watch the cluster cider config",
    "start": "977920",
    "end": "980320"
  },
  {
    "text": "object",
    "start": "980320",
    "end": "981040"
  },
  {
    "text": "and then perform the node ip allocations",
    "start": "981040",
    "end": "984880"
  },
  {
    "text": "based on that information the allocator",
    "start": "984880",
    "end": "987279"
  },
  {
    "text": "would support adding and deleting",
    "start": "987279",
    "end": "988800"
  },
  {
    "text": "cider configs without restarting your",
    "start": "988800",
    "end": "990639"
  },
  {
    "text": "cluster so you can dynamically resize",
    "start": "990639",
    "end": "992880"
  },
  {
    "text": "it would handle multiple ip families so",
    "start": "992880",
    "end": "995120"
  },
  {
    "text": "ipv4 ipv6 addresses right out of the box",
    "start": "995120",
    "end": "998480"
  },
  {
    "text": "and it can allocate variable size ranges",
    "start": "998480",
    "end": "1001120"
  },
  {
    "text": "to",
    "start": "1001120",
    "end": "1001759"
  },
  {
    "text": "every node as we mentioned earlier your",
    "start": "1001759",
    "end": "1003519"
  },
  {
    "text": "smaller nodes can be a slash 24 your",
    "start": "1003519",
    "end": "1005519"
  },
  {
    "text": "larger ones can be",
    "start": "1005519",
    "end": "1006800"
  },
  {
    "text": "a slash 22. this uh",
    "start": "1006800",
    "end": "1010079"
  },
  {
    "text": "slide obviously glosses over a lot of",
    "start": "1010079",
    "end": "1011839"
  },
  {
    "text": "subtle nuance in detail",
    "start": "1011839",
    "end": "1013360"
  },
  {
    "text": "these discussions are happening in the",
    "start": "1013360",
    "end": "1015600"
  },
  {
    "text": "community and in the cap",
    "start": "1015600",
    "end": "1016880"
  },
  {
    "text": "if you are interested and you have",
    "start": "1016880",
    "end": "1018880"
  },
  {
    "text": "thoughts or questions",
    "start": "1018880",
    "end": "1020079"
  },
  {
    "text": "please please feel free to you know",
    "start": "1020079",
    "end": "1022560"
  },
  {
    "text": "comment on the cap we'd love to hear",
    "start": "1022560",
    "end": "1023920"
  },
  {
    "text": "your ideas",
    "start": "1023920",
    "end": "1026480"
  },
  {
    "text": "now that rahul has gone through the",
    "start": "1027280",
    "end": "1028640"
  },
  {
    "text": "details of our proposal i'm going to",
    "start": "1028640",
    "end": "1030720"
  },
  {
    "text": "take an example",
    "start": "1030720",
    "end": "1031839"
  },
  {
    "text": "to walk us through whether our proposal",
    "start": "1031839",
    "end": "1034640"
  },
  {
    "text": "actually solves the problem that we were",
    "start": "1034640",
    "end": "1036160"
  },
  {
    "text": "trying to solve let's take this example",
    "start": "1036160",
    "end": "1039600"
  },
  {
    "text": "in this case a user wants to create a",
    "start": "1039600",
    "end": "1041520"
  },
  {
    "text": "new kubernetes cluster",
    "start": "1041520",
    "end": "1043199"
  },
  {
    "text": "the cluster is going to is expected to",
    "start": "1043199",
    "end": "1046558"
  },
  {
    "text": "grow to about 32 nodes",
    "start": "1046559",
    "end": "1048400"
  },
  {
    "text": "and each node the user wants to allocate",
    "start": "1048400",
    "end": "1051360"
  },
  {
    "text": "about run about 100 parts",
    "start": "1051360",
    "end": "1053520"
  },
  {
    "text": "and that means with some buffer we want",
    "start": "1053520",
    "end": "1056000"
  },
  {
    "text": "to allocate a slash 24 to each node",
    "start": "1056000",
    "end": "1058480"
  },
  {
    "text": "now the first thing you want to do when",
    "start": "1058480",
    "end": "1060080"
  },
  {
    "text": "you're creating this cluster is you want",
    "start": "1060080",
    "end": "1061760"
  },
  {
    "text": "to allocate a cloud",
    "start": "1061760",
    "end": "1063440"
  },
  {
    "text": "a cluster sitter range however in this",
    "start": "1063440",
    "end": "1066480"
  },
  {
    "text": "particular network",
    "start": "1066480",
    "end": "1067679"
  },
  {
    "text": "the user does not have a slash 19 which",
    "start": "1067679",
    "end": "1070000"
  },
  {
    "text": "would have been required to run the",
    "start": "1070000",
    "end": "1071440"
  },
  {
    "text": "entire cluster of 32 nodes",
    "start": "1071440",
    "end": "1073280"
  },
  {
    "text": "instead the user has a couple of slash",
    "start": "1073280",
    "end": "1075840"
  },
  {
    "text": "20s lying around",
    "start": "1075840",
    "end": "1077039"
  },
  {
    "text": "which are completely discontinuous now",
    "start": "1077039",
    "end": "1079679"
  },
  {
    "text": "with our proposal what the user does",
    "start": "1079679",
    "end": "1082000"
  },
  {
    "text": "is creates two different cluster setter",
    "start": "1082000",
    "end": "1084480"
  },
  {
    "text": "configs",
    "start": "1084480",
    "end": "1085200"
  },
  {
    "text": "range one and range two each which comes",
    "start": "1085200",
    "end": "1088320"
  },
  {
    "text": "from a different cidr range a slash",
    "start": "1088320",
    "end": "1090400"
  },
  {
    "text": "20 and each says allocate a part per",
    "start": "1090400",
    "end": "1094160"
  },
  {
    "text": "node mass size of 24",
    "start": "1094160",
    "end": "1096240"
  },
  {
    "text": "to the nodes that come up now",
    "start": "1096240",
    "end": "1099600"
  },
  {
    "text": "note that in this case we are not",
    "start": "1099600",
    "end": "1102160"
  },
  {
    "text": "specifying",
    "start": "1102160",
    "end": "1103039"
  },
  {
    "text": "any node selector this means that our",
    "start": "1103039",
    "end": "1106640"
  },
  {
    "text": "ipam logic the the new range allocator",
    "start": "1106640",
    "end": "1110000"
  },
  {
    "text": "that we are going to",
    "start": "1110000",
    "end": "1110799"
  },
  {
    "text": "going to be writing is going to pick a",
    "start": "1110799",
    "end": "1113600"
  },
  {
    "text": "range of",
    "start": "1113600",
    "end": "1114400"
  },
  {
    "text": "range of slash 20 pro from any one of",
    "start": "1114400",
    "end": "1116880"
  },
  {
    "text": "these two ranges range one or range two",
    "start": "1116880",
    "end": "1119120"
  },
  {
    "text": "and allocate it",
    "start": "1119120",
    "end": "1120240"
  },
  {
    "text": "randomly to the nodes that come up the",
    "start": "1120240",
    "end": "1122799"
  },
  {
    "text": "other thing to note here",
    "start": "1122799",
    "end": "1124400"
  },
  {
    "text": "is that if you were to create a cluster",
    "start": "1124400",
    "end": "1127440"
  },
  {
    "text": "for like a legacy cluster you can",
    "start": "1127440",
    "end": "1130240"
  },
  {
    "text": "specify the ipc dot block which is the",
    "start": "1130240",
    "end": "1132640"
  },
  {
    "text": "same",
    "start": "1132640",
    "end": "1133039"
  },
  {
    "text": "as the cluster sitter and the old node",
    "start": "1133039",
    "end": "1136320"
  },
  {
    "text": "seeder mass size",
    "start": "1136320",
    "end": "1137360"
  },
  {
    "text": "becomes the per node mass size and you",
    "start": "1137360",
    "end": "1138960"
  },
  {
    "text": "specify just one range so this is",
    "start": "1138960",
    "end": "1140400"
  },
  {
    "text": "backward compatible",
    "start": "1140400",
    "end": "1142320"
  },
  {
    "text": "if you wanted to just migrate from the",
    "start": "1142320",
    "end": "1144720"
  },
  {
    "text": "old way of creating things",
    "start": "1144720",
    "end": "1146240"
  },
  {
    "text": "to this new resource now",
    "start": "1146240",
    "end": "1149360"
  },
  {
    "text": "let's say the cluster grows to 32 nodes",
    "start": "1149360",
    "end": "1151600"
  },
  {
    "text": "and then",
    "start": "1151600",
    "end": "1152640"
  },
  {
    "text": "for some reason there are more workloads",
    "start": "1152640",
    "end": "1154799"
  },
  {
    "text": "to be added to this cluster",
    "start": "1154799",
    "end": "1156480"
  },
  {
    "text": "you are out of the board setter size",
    "start": "1156480",
    "end": "1159200"
  },
  {
    "text": "with our proposal",
    "start": "1159200",
    "end": "1160480"
  },
  {
    "text": "what you do is add another range so in",
    "start": "1160480",
    "end": "1162960"
  },
  {
    "text": "this case i have another",
    "start": "1162960",
    "end": "1164640"
  },
  {
    "text": "third range range three 10.3.0.0 i'm",
    "start": "1164640",
    "end": "1168320"
  },
  {
    "text": "still allocating a slash 24 to each node",
    "start": "1168320",
    "end": "1171360"
  },
  {
    "text": "and i create this new range object and i",
    "start": "1171360",
    "end": "1174320"
  },
  {
    "text": "am going to",
    "start": "1174320",
    "end": "1175039"
  },
  {
    "text": "now be able to expand the cluster beyond",
    "start": "1175039",
    "end": "1177600"
  },
  {
    "text": "32 nodes that were there",
    "start": "1177600",
    "end": "1179280"
  },
  {
    "text": "again i'm not using any part selectors",
    "start": "1179280",
    "end": "1181200"
  },
  {
    "text": "here so the",
    "start": "1181200",
    "end": "1182559"
  },
  {
    "text": "ranges are going to be chopped up",
    "start": "1182559",
    "end": "1183919"
  },
  {
    "text": "randomly",
    "start": "1183919",
    "end": "1186160"
  },
  {
    "text": "now what happens if i want to run a set",
    "start": "1186160",
    "end": "1189280"
  },
  {
    "text": "of nodes where i know that i'm not going",
    "start": "1189280",
    "end": "1191039"
  },
  {
    "text": "to be running so many workloads let's",
    "start": "1191039",
    "end": "1192559"
  },
  {
    "text": "say i want to just",
    "start": "1192559",
    "end": "1193600"
  },
  {
    "text": "just run 30 parts on on the new nodes in",
    "start": "1193600",
    "end": "1196640"
  },
  {
    "text": "this case i don't want to waste",
    "start": "1196640",
    "end": "1198480"
  },
  {
    "text": "a slash 24 on that node so the user what",
    "start": "1198480",
    "end": "1201520"
  },
  {
    "text": "what the user can do",
    "start": "1201520",
    "end": "1202880"
  },
  {
    "text": "is create a yet another cluster set or",
    "start": "1202880",
    "end": "1205679"
  },
  {
    "text": "config",
    "start": "1205679",
    "end": "1206400"
  },
  {
    "text": "in this case this is range four and then",
    "start": "1206400",
    "end": "1209120"
  },
  {
    "text": "the user says i want to allocate only a",
    "start": "1209120",
    "end": "1211120"
  },
  {
    "text": "slash",
    "start": "1211120",
    "end": "1211520"
  },
  {
    "text": "26 to the to these po to these nodes",
    "start": "1211520",
    "end": "1214720"
  },
  {
    "text": "instead of",
    "start": "1214720",
    "end": "1215280"
  },
  {
    "text": "a slash 24. so in this case the user",
    "start": "1215280",
    "end": "1217679"
  },
  {
    "text": "says part",
    "start": "1217679",
    "end": "1218720"
  },
  {
    "text": "per node mass size is 26 and also",
    "start": "1218720",
    "end": "1223280"
  },
  {
    "text": "populates the node selector logic to say",
    "start": "1223280",
    "end": "1225679"
  },
  {
    "text": "only do this for these nodes where",
    "start": "1225679",
    "end": "1227760"
  },
  {
    "text": "instance type is small",
    "start": "1227760",
    "end": "1229760"
  },
  {
    "text": "note that the ipc block is the same as",
    "start": "1229760",
    "end": "1232400"
  },
  {
    "text": "range three so what we are trying",
    "start": "1232400",
    "end": "1234000"
  },
  {
    "text": "to convey here is that the 10.3.0.0",
    "start": "1234000",
    "end": "1238559"
  },
  {
    "text": "20 range can be chopped up into slash 24",
    "start": "1238559",
    "end": "1241440"
  },
  {
    "text": "or slash 26 the back end",
    "start": "1241440",
    "end": "1243200"
  },
  {
    "text": "ipam controller handles this logic for",
    "start": "1243200",
    "end": "1245360"
  },
  {
    "text": "you",
    "start": "1245360",
    "end": "1247520"
  },
  {
    "text": "that is the state of this world when we",
    "start": "1247760",
    "end": "1250799"
  },
  {
    "text": "are recording",
    "start": "1250799",
    "end": "1251600"
  },
  {
    "text": "right now we are trying to work with sig",
    "start": "1251600",
    "end": "1254159"
  },
  {
    "text": "network",
    "start": "1254159",
    "end": "1254880"
  },
  {
    "text": "and get this proposal vetted out which",
    "start": "1254880",
    "end": "1258000"
  },
  {
    "text": "bring us to",
    "start": "1258000",
    "end": "1258799"
  },
  {
    "text": "brings us to future work",
    "start": "1258799",
    "end": "1261840"
  },
  {
    "text": "with the new cube proxy changes anyone",
    "start": "1261840",
    "end": "1264320"
  },
  {
    "text": "can now",
    "start": "1264320",
    "end": "1264880"
  },
  {
    "text": "write an ipam controller and plug it in",
    "start": "1264880",
    "end": "1267919"
  },
  {
    "text": "and do discontinuous parts uh pod",
    "start": "1267919",
    "end": "1269919"
  },
  {
    "text": "sitters and",
    "start": "1269919",
    "end": "1272640"
  },
  {
    "text": "certain cloud providers already do this",
    "start": "1272640",
    "end": "1274799"
  },
  {
    "text": "as well as certain cni",
    "start": "1274799",
    "end": "1276320"
  },
  {
    "text": "also have the ability to do this our",
    "start": "1276320",
    "end": "1278799"
  },
  {
    "text": "motivation for this",
    "start": "1278799",
    "end": "1280159"
  },
  {
    "text": "project is to support this feature out",
    "start": "1280159",
    "end": "1282559"
  },
  {
    "text": "of the box from",
    "start": "1282559",
    "end": "1283600"
  },
  {
    "text": "for kubernetes so that anybody can make",
    "start": "1283600",
    "end": "1285440"
  },
  {
    "text": "use of this so",
    "start": "1285440",
    "end": "1286720"
  },
  {
    "text": "we are actively working with sig network",
    "start": "1286720",
    "end": "1288880"
  },
  {
    "text": "on refining this proposal",
    "start": "1288880",
    "end": "1290480"
  },
  {
    "text": "we are iterating on this and figuring",
    "start": "1290480",
    "end": "1292880"
  },
  {
    "text": "out what the final design should be",
    "start": "1292880",
    "end": "1294640"
  },
  {
    "text": "and then the next step would be to",
    "start": "1294640",
    "end": "1296080"
  },
  {
    "text": "implement which leaves",
    "start": "1296080",
    "end": "1298559"
  },
  {
    "text": "you with a call to action anyone who is",
    "start": "1298559",
    "end": "1302080"
  },
  {
    "text": "interested in this",
    "start": "1302080",
    "end": "1302960"
  },
  {
    "text": "or have ideas around how we should be",
    "start": "1302960",
    "end": "1305600"
  },
  {
    "text": "doing this",
    "start": "1305600",
    "end": "1306480"
  },
  {
    "text": "please join us in a sig network meeting",
    "start": "1306480",
    "end": "1308400"
  },
  {
    "text": "please comment on the cap",
    "start": "1308400",
    "end": "1310159"
  },
  {
    "text": "or even talk to us and we will be happy",
    "start": "1310159",
    "end": "1313440"
  },
  {
    "text": "to take your feedback",
    "start": "1313440",
    "end": "1315120"
  },
  {
    "text": "and address any use cases that we may",
    "start": "1315120",
    "end": "1316960"
  },
  {
    "text": "not have addressed",
    "start": "1316960",
    "end": "1319840"
  },
  {
    "text": "that brings us to the end of our",
    "start": "1319840",
    "end": "1321280"
  },
  {
    "text": "presentation we",
    "start": "1321280",
    "end": "1322880"
  },
  {
    "text": "thank you for your time thank you for",
    "start": "1322880",
    "end": "1325200"
  },
  {
    "text": "taking the time to listening to us",
    "start": "1325200",
    "end": "1327280"
  },
  {
    "text": "and if you have any questions we'll talk",
    "start": "1327280",
    "end": "1330320"
  },
  {
    "text": "in the q a session thank you everyone",
    "start": "1330320",
    "end": "1336000"
  }
]
[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "this presentation is about manager kubernetes as a Next Generation academic",
    "start": "1199",
    "end": "7319"
  },
  {
    "text": "infrastructure but first we are",
    "start": "7319",
    "end": "13160"
  },
  {
    "text": "I am lukash hitmanik and I am I.T architect at Mark University and also I",
    "start": "13259",
    "end": "19740"
  },
  {
    "text": "am contributing to assessment which is uh check National research and educational Network",
    "start": "19740",
    "end": "26880"
  },
  {
    "text": "hello my name is Victoria and I am a doctoral student at mesberg University in Bernal Czech Republic an ID",
    "start": "26880",
    "end": "34380"
  },
  {
    "text": "specialist at Institute of computer science at Master University as well",
    "start": "34380",
    "end": "40879"
  },
  {
    "start": "40000",
    "end": "40000"
  },
  {
    "text": "for example let me introduce the research and educational infrastructure",
    "start": "41600",
    "end": "47160"
  },
  {
    "text": "in the Czech Republic except a real super Computing Center we have two main",
    "start": "47160",
    "end": "52980"
  },
  {
    "text": "kinds of infrastructure available to scientists there are HPC and kubernetes",
    "start": "52980",
    "end": "59160"
  },
  {
    "text": "infrastructure the HPC infrastructure consists of 32",
    "start": "59160",
    "end": "66000"
  },
  {
    "text": "000 CPU cores it has 15 petabytes of storage capacity and it's used by three",
    "start": "66000",
    "end": "74280"
  },
  {
    "text": "targets active users those users are running about 20",
    "start": "74280",
    "end": "80460"
  },
  {
    "text": "000 jobs every day and we also have 360 gpus of virus kind this kind of Interest",
    "start": "80460",
    "end": "89720"
  },
  {
    "text": "infrastructure is based on PBS Pro batch system",
    "start": "89720",
    "end": "95340"
  },
  {
    "text": "um the other one kubernetes infrastructure it consists of",
    "start": "95340",
    "end": "101900"
  },
  {
    "text": "2500 CPU scores uh it has 60 100",
    "start": "101900",
    "end": "106939"
  },
  {
    "text": "terabytes of dedicated storage capacity expected on flash only and storage array",
    "start": "106939",
    "end": "113899"
  },
  {
    "text": "it's currently used by about 200 users",
    "start": "113899",
    "end": "118979"
  },
  {
    "text": "they are running 1000 books every day and this",
    "start": "118979",
    "end": "124500"
  },
  {
    "text": "infrastructure is equipped by 50 gpus some of them are a Nvidia a100 and they",
    "start": "124500",
    "end": "132840"
  },
  {
    "text": "are yet to be installed and we will experiment to it make technology as well",
    "start": "132840",
    "end": "138020"
  },
  {
    "text": "this kubernetes infrastructure is based on Ranger and RTA you know distribution",
    "start": "138020",
    "end": "147080"
  },
  {
    "start": "147000",
    "end": "147000"
  },
  {
    "text": "uh speaking of manage kubernetes so what can you imagine basically it means that",
    "start": "148080",
    "end": "153840"
  },
  {
    "text": "a devops beam manage the infrastructure we offer type integration with direct",
    "start": "153840",
    "end": "159900"
  },
  {
    "text": "all of our infrastructure like the HPC and we aim to offer many components that",
    "start": "159900",
    "end": "166860"
  },
  {
    "text": "allow easy deployment of user application we have for instance several storage",
    "start": "166860",
    "end": "172500"
  },
  {
    "text": "classes like NFS Samba sshfs or cvmfs we",
    "start": "172500",
    "end": "179220"
  },
  {
    "text": "also integrated xfs but this storage class use uses a special version of Jeff",
    "start": "179220",
    "end": "187860"
  },
  {
    "text": "FX driver this driver has been patched so we are able to change user ID and",
    "start": "187860",
    "end": "195180"
  },
  {
    "text": "group ID that are locally visible so it does not matter under which user ID",
    "start": "195180",
    "end": "201060"
  },
  {
    "text": "around the container this page is public as a pull request to step Upstream but I",
    "start": "201060",
    "end": "208260"
  },
  {
    "text": "call as I know it's still not merge we also have one data class storage class",
    "start": "208260",
    "end": "213780"
  },
  {
    "text": "and both of these storage classes are implemented as a few CSC drivers",
    "start": "213780",
    "end": "221280"
  },
  {
    "text": "uh we have a workaround so that the CXC driver can be restarted without baking",
    "start": "221280",
    "end": "227159"
  },
  {
    "text": "mode point next we have integration of DNS system for Ingress and load balancera it means",
    "start": "227159",
    "end": "234959"
  },
  {
    "text": "that DNX name is created for such a service like ingressor and the road",
    "start": "234959",
    "end": "240720"
  },
  {
    "text": "balances we also provide like a encrypt certificates for both Ingress or also",
    "start": "240720",
    "end": "249180"
  },
  {
    "text": "for non-web services we provide a single sign-on service",
    "start": "249180",
    "end": "255739"
  },
  {
    "text": "based just on annotation so if you want to and use a single sign-on form it's",
    "start": "255739",
    "end": "263520"
  },
  {
    "text": "called her application and they just needs to add some annotation to to",
    "start": "263520",
    "end": "269400"
  },
  {
    "text": "Ingress Android single sign-on is just automatically registered and provided we",
    "start": "269400",
    "end": "275460"
  },
  {
    "text": "also offer shared gpus it means that a single GPU can be shared by a multiple",
    "start": "275460",
    "end": "282180"
  },
  {
    "text": "container or multiple users but there are no guarantees about consumer resources from the GPU and we have also",
    "start": "282180",
    "end": "292040"
  },
  {
    "text": "a slightly modified GPU operator from Nvidia that enforce the GPU allocation",
    "start": "292040",
    "end": "299940"
  },
  {
    "text": "it means that no user can basically steal on the GPU without",
    "start": "299940",
    "end": "308180"
  },
  {
    "text": "knowing letting you know the kubernetes scheduler",
    "start": "308180",
    "end": "313639"
  },
  {
    "text": "uh so let's look on manage kubernetes from user perspective users are given",
    "start": "314300",
    "end": "321300"
  },
  {
    "text": "project and namespace and we enforce resource quota on the CPU and memory",
    "start": "321300",
    "end": "329180"
  },
  {
    "text": "the users are allowed to run only unprivileged containers which can be a",
    "start": "329180",
    "end": "334680"
  },
  {
    "text": "bit limiting but on the other hand we do not enforce users to use any particular",
    "start": "334680",
    "end": "340620"
  },
  {
    "text": "UV ID ufrl so you have any user ID they want",
    "start": "340620",
    "end": "346860"
  },
  {
    "text": "uh users also cannot install custom resource definition or any other cluster",
    "start": "346860",
    "end": "352860"
  },
  {
    "text": "scope resources this you can this operation are forbidden and only administrator can do so it means",
    "start": "352860",
    "end": "359699"
  },
  {
    "text": "basically a devops team has to install such resources but we want the users to not struggle",
    "start": "359699",
    "end": "368820"
  },
  {
    "text": "with maintaining infrastructure maintaining kubernetes and maintaining all the compound company that needs to",
    "start": "368820",
    "end": "374699"
  },
  {
    "text": "be run and the user can focus only on own application or on workload and fully",
    "start": "374699",
    "end": "382319"
  },
  {
    "text": "utilize their service the devops team provides",
    "start": "382319",
    "end": "387539"
  },
  {
    "start": "388000",
    "end": "388000"
  },
  {
    "text": "however we do not offer just an infrastructure we go a bit further and",
    "start": "388400",
    "end": "394080"
  },
  {
    "text": "we prepare some prefabricated applications such as Jupiter Hub and binder hop next levels to our famous and",
    "start": "394080",
    "end": "402419"
  },
  {
    "text": "very popular uh also the Jupiter Hub offers integration which HPC storage",
    "start": "402419",
    "end": "409919"
  },
  {
    "text": "systems via hsshfs and we also have two special instances",
    "start": "409919",
    "end": "416280"
  },
  {
    "text": "of Jupiter half one is our studio that runs inside Jupiter app so user can get",
    "start": "416280",
    "end": "425160"
  },
  {
    "text": "our studio on one click that is integrated with HPC storage system and",
    "start": "425160",
    "end": "431460"
  },
  {
    "text": "the other one is Alpha fault on demand this application is based on collabora",
    "start": "431460",
    "end": "437060"
  },
  {
    "text": "Jupiter app notebook and we also integrated more star reviewer that",
    "start": "437060",
    "end": "444380"
  },
  {
    "text": "allows user to preview the folded protein uh goes to application the Jupiter Hub",
    "start": "444380",
    "end": "452819"
  },
  {
    "text": "and binder Hub are run a web application that has ear in their own logon system",
    "start": "452819",
    "end": "460160"
  },
  {
    "text": "but next to those applications we prepared another application that are",
    "start": "460160",
    "end": "468000"
  },
  {
    "text": "accessible directly in a ranger as a rental application and those",
    "start": "468000",
    "end": "474120"
  },
  {
    "text": "applications mainly oh contains or are based on remote desktops",
    "start": "474120",
    "end": "481860"
  },
  {
    "text": "and we offer applications such as crime Matlab answers vmd viewer IBM C Plex",
    "start": "481860",
    "end": "490380"
  },
  {
    "text": "all this applications are based on either VNC technology and protocol or",
    "start": "490380",
    "end": "496800"
  },
  {
    "text": "web RTC protocol in the latter case the user is given a fully 3D accelerated",
    "start": "496800",
    "end": "504060"
  },
  {
    "text": "desktop that is pretty capable of almost anything and also we prepared containers that",
    "start": "504060",
    "end": "512039"
  },
  {
    "text": "allows users to use SSH access to this",
    "start": "512039",
    "end": "517080"
  },
  {
    "text": "container via Network and those containers are running behave much like",
    "start": "517080",
    "end": "522320"
  },
  {
    "text": "virtual machine because user does not have a root access in the",
    "start": "522320",
    "end": "529500"
  },
  {
    "text": "in the container but on the other hand using some say tricks and hex so the",
    "start": "529500",
    "end": "535620"
  },
  {
    "text": "user can install any package or anything in initial container so it should it",
    "start": "535620",
    "end": "541980"
  },
  {
    "text": "behaves much like a virtual machine we also offer some web-based applications",
    "start": "541980",
    "end": "547680"
  },
  {
    "text": "such as the code server or neo4j and",
    "start": "547680",
    "end": "553380"
  },
  {
    "text": "including other applications such as a personal menu or parallel server",
    "start": "553380",
    "end": "558600"
  },
  {
    "text": "recipient or personal symbol server those personal service means that the",
    "start": "558600",
    "end": "564480"
  },
  {
    "text": "user can run the menu or Samba on its own and can connect the local computer",
    "start": "564480",
    "end": "571380"
  },
  {
    "text": "to do this service via X3 or we are popular Samba protocol for instance from Windows",
    "start": "571380",
    "end": "579839"
  },
  {
    "text": "system so here you can find some examples of",
    "start": "579839",
    "end": "587700"
  },
  {
    "start": "584000",
    "end": "584000"
  },
  {
    "text": "our prefabricated application on the laptop you can see our studio running in",
    "start": "587700",
    "end": "593640"
  },
  {
    "text": "a Jupiter hub below you can see the form for Alpha fault on demand you can see",
    "start": "593640",
    "end": "600480"
  },
  {
    "text": "that most of the parameters that are used for for the scripts that are",
    "start": "600480",
    "end": "605760"
  },
  {
    "text": "standard scripts of alpha fold you can fill in the parameters in the next two is on the right side down",
    "start": "605760",
    "end": "613140"
  },
  {
    "text": "you can see the most card viewer that offers the preview of 40 protein and",
    "start": "613140",
    "end": "618839"
  },
  {
    "text": "above on the right side top you can see probably famous game Witcher 2 that runs",
    "start": "618839",
    "end": "626220"
  },
  {
    "text": "in the browser and run from a kubernetes and it will fully accelerated it uses",
    "start": "626220",
    "end": "632300"
  },
  {
    "text": "webrtc and it's based on a Celtics project so for a while you can enjoy the",
    "start": "632300",
    "end": "639180"
  },
  {
    "text": "gameplay [Music]",
    "start": "639180",
    "end": "649579"
  },
  {
    "start": "653000",
    "end": "653000"
  },
  {
    "text": "so now let me reveal some implementation details first for remote desktops our",
    "start": "654360",
    "end": "661380"
  },
  {
    "text": "solution is completely unprivileged so it means that none of the participating",
    "start": "661380",
    "end": "667380"
  },
  {
    "text": "containers in its privilege escalation on run X root everything just on as a",
    "start": "667380",
    "end": "675360"
  },
  {
    "text": "user however it required to patched a server it also requires some minor",
    "start": "675360",
    "end": "682260"
  },
  {
    "text": "changes to Nvidia GPU operator and as I",
    "start": "682260",
    "end": "687360"
  },
  {
    "text": "mentioned the enforce GPU allocation and this enforcing denies to share GPU among",
    "start": "687360",
    "end": "697079"
  },
  {
    "text": "containers because Nvidia visible devices all is ignored if this is the",
    "start": "697079",
    "end": "703920"
  },
  {
    "text": "only request for GPU however we use some GPU sharing from",
    "start": "703920",
    "end": "712279"
  },
  {
    "text": "uh China Oliver background that is publicly available and with the sharing",
    "start": "712279",
    "end": "719100"
  },
  {
    "text": "we can we can share the GPU between Excel container desktop container and",
    "start": "719100",
    "end": "726240"
  },
  {
    "text": "streamer container I also mentioned that we offer an",
    "start": "726240",
    "end": "732000"
  },
  {
    "text": "integration with the DNS system however we have no solution for a name conflict",
    "start": "732000",
    "end": "738360"
  },
  {
    "text": "currently any user can and select any domain name under some",
    "start": "738360",
    "end": "745200"
  },
  {
    "text": "specific subdomain however this sub domain is shared among all the users so",
    "start": "745200",
    "end": "751440"
  },
  {
    "text": "then can write some name conflicts and this has currently no solution with",
    "start": "751440",
    "end": "756779"
  },
  {
    "text": "external DNS driver uh also with like encrypt certificates",
    "start": "756779",
    "end": "762720"
  },
  {
    "text": "there is a one problem with DNX challenge because we offer to get a",
    "start": "762720",
    "end": "771180"
  },
  {
    "text": "certificates also for the whole sub domain that is meant for both external",
    "start": "771180",
    "end": "776459"
  },
  {
    "text": "DNA and like encrypted certificates and in this case all every user is able to",
    "start": "776459",
    "end": "783600"
  },
  {
    "text": "uh get any certificate in in this domain because there is no real validation of",
    "start": "783600",
    "end": "791519"
  },
  {
    "text": "of the request and we also are not aware of any any",
    "start": "791519",
    "end": "798480"
  },
  {
    "text": "possible solution you know for this problem uh probably one of the solution",
    "start": "798480",
    "end": "804300"
  },
  {
    "text": "could be that we can we create this thing uh DNX zones for each user or every",
    "start": "804300",
    "end": "813480"
  },
  {
    "text": "every group of user but this is currently not implemented",
    "start": "813480",
    "end": "819440"
  },
  {
    "start": "819000",
    "end": "819000"
  },
  {
    "text": "we decided to use kubernetes also for a sensitive data processing we set up a",
    "start": "820440",
    "end": "827760"
  },
  {
    "text": "small cluster that is uh dedicated only for quantitative data processing this",
    "start": "827760",
    "end": "833579"
  },
  {
    "text": "cluster is separated from the public cluster however the single small cluster",
    "start": "833579",
    "end": "839820"
  },
  {
    "text": "is used by all the users that want to process the sensitive data we are",
    "start": "839820",
    "end": "845940"
  },
  {
    "text": "working on Azure 27000 certification and which is equivalent to an ISD",
    "start": "845940",
    "end": "852800"
  },
  {
    "text": "853 certification but as I have said the single cluster is shared by distinct",
    "start": "852800",
    "end": "859500"
  },
  {
    "text": "users which brings some isolation challenges mainly related to usually",
    "start": "859500",
    "end": "865740"
  },
  {
    "text": "single Ingress instance all of and also for uh still instance that is not",
    "start": "865740",
    "end": "873720"
  },
  {
    "text": "multi-tenant by default we do not run just few web applications",
    "start": "873720",
    "end": "881880"
  },
  {
    "start": "878000",
    "end": "878000"
  },
  {
    "text": "or remote desktops on our in kubernetes infrastructure we also use HPC jobs on",
    "start": "881880",
    "end": "890399"
  },
  {
    "text": "pretty regular basis currently we run the HPC jobs via workflow managers we",
    "start": "890399",
    "end": "898440"
  },
  {
    "text": "use two of them one is snake make and the other one is next flow the snake",
    "start": "898440",
    "end": "904139"
  },
  {
    "text": "make is integrated with task execution service from gh4ga initiative and the",
    "start": "904139",
    "end": "911699"
  },
  {
    "text": "next flow is directly integrated with kubernetes",
    "start": "911699",
    "end": "917540"
  },
  {
    "text": "so how does the HPC jobs work on kubernetes there are some bad rumors",
    "start": "918360",
    "end": "924660"
  },
  {
    "text": "that it will it does not work yes I have heard but we can but all we can say is",
    "start": "924660",
    "end": "931680"
  },
  {
    "text": "that it works there are of course some limitations they have to bring some research",
    "start": "931680",
    "end": "937199"
  },
  {
    "text": "opportunities we also create many neck flow enhancements should do because one is",
    "start": "937199",
    "end": "944399"
  },
  {
    "text": "adding job job support which make the next flow computation almost Immortal so",
    "start": "944399",
    "end": "951779"
  },
  {
    "text": "if you're pretty stable and it runs runs just fine because Lucas already",
    "start": "951779",
    "end": "958079"
  },
  {
    "start": "957000",
    "end": "957000"
  },
  {
    "text": "mentioned there are limitations of HPC in kubernetes these limitations are eventually beneficial because they bring",
    "start": "958079",
    "end": "965220"
  },
  {
    "text": "research opportunities for the community there are plenty of areas where research can be conducted that we started with",
    "start": "965220",
    "end": "972300"
  },
  {
    "text": "scheduling challenges because they were the most prominent to us I would like to present to you some of",
    "start": "972300",
    "end": "978360"
  },
  {
    "text": "our research interests problems with Techo Solutions we found and new areas we would like to scrutinize",
    "start": "978360",
    "end": "985019"
  },
  {
    "text": "I will talk about four topics the first is efficient resource allocation in heterogeneous and dynamic environment",
    "start": "985019",
    "end": "991980"
  },
  {
    "text": "which is basically a kubernetes cluster the second being infrastructure comparisons of kubernetes and",
    "start": "991980",
    "end": "998639"
  },
  {
    "text": "traditional HPC based on batch scheduling third topic will be area of Green",
    "start": "998639",
    "end": "1005240"
  },
  {
    "text": "Computing that is with Rising electricity prices and Global Climate status quite an important topic and",
    "start": "1005240",
    "end": "1012320"
  },
  {
    "text": "fourth and last topic will be about connecting kubernetes with HPC in a hybrid way",
    "start": "1012320",
    "end": "1018800"
  },
  {
    "text": "firstly I am going to talk about effective resource allocation in kubernetes as we all attend HPC day I",
    "start": "1018800",
    "end": "1026839"
  },
  {
    "start": "1020000",
    "end": "1020000"
  },
  {
    "text": "believe majority of you have ever asked answered discussed or just came around the question of effective scheduling in",
    "start": "1026839",
    "end": "1033918"
  },
  {
    "text": "any Computing environment scheduling is an omnipresent topic because everyone tries to come up with",
    "start": "1033919",
    "end": "1040160"
  },
  {
    "text": "the best scheduling strategy that will accommodate the most jobs on all notes",
    "start": "1040160",
    "end": "1045199"
  },
  {
    "text": "and no job will wait too long and cluster usage will be above 90 with no",
    "start": "1045199",
    "end": "1050480"
  },
  {
    "text": "down times sadly this is not the reality and we all",
    "start": "1050480",
    "end": "1055520"
  },
  {
    "text": "experience a plethora of problems we come from academic environment where",
    "start": "1055520",
    "end": "1061160"
  },
  {
    "text": "computational resources are provided more or less for free for all researchers and academics this",
    "start": "1061160",
    "end": "1068780"
  },
  {
    "text": "is a very different approach from commercial providers where you can prepay notes for desired time or follow",
    "start": "1068780",
    "end": "1075080"
  },
  {
    "text": "pay as you use model when you have a records to compute you naturally don't want to pay providers",
    "start": "1075080",
    "end": "1081679"
  },
  {
    "text": "more than necessary not mentioning if you have specific requests on resources such as graphical cards whose usage can",
    "start": "1081679",
    "end": "1090200"
  },
  {
    "text": "be really pricey from the opposite point of view providers reach very high resource usage",
    "start": "1090200",
    "end": "1097039"
  },
  {
    "text": "because they combine offered plans in a very smart way and efficiently they",
    "start": "1097039",
    "end": "1102380"
  },
  {
    "text": "overcome it very much our experience in the Academia clearly",
    "start": "1102380",
    "end": "1107419"
  },
  {
    "text": "shows that users drastically overestimate their resource requests as you can see on the image even the best",
    "start": "1107419",
    "end": "1114740"
  },
  {
    "text": "used to request ratio for a namespace has a two-time difference users like motivation for precise",
    "start": "1114740",
    "end": "1121640"
  },
  {
    "text": "resource requests and because as I said they are free and secondly they either",
    "start": "1121640",
    "end": "1127880"
  },
  {
    "text": "don't know how the application works or the resource usage of the workload is",
    "start": "1127880",
    "end": "1132980"
  },
  {
    "text": "not stable over time however burstable clothes as we call the",
    "start": "1132980",
    "end": "1139400"
  },
  {
    "text": "applications with unstable resource usage are not the only case that makes that makes scheduling in kubernetes hard",
    "start": "1139400",
    "end": "1146299"
  },
  {
    "text": "we distinguish between two types of these bursty jobs one are long-running services that are used three times a",
    "start": "1146299",
    "end": "1153799"
  },
  {
    "text": "week for two hours and the second type are computations characterized by Dynamic variation when most of the time",
    "start": "1153799",
    "end": "1160760"
  },
  {
    "text": "resource usage is low but for some short time perhaps a more complex part of the",
    "start": "1160760",
    "end": "1167600"
  },
  {
    "text": "computation restarts resource consumption spikes users fear their job will exceed",
    "start": "1167600",
    "end": "1174799"
  },
  {
    "text": "allocated resources which would cause job termination so the rather specifies",
    "start": "1174799",
    "end": "1179900"
  },
  {
    "text": "substantially more resources that than are needed in order to avoid the situation",
    "start": "1179900",
    "end": "1186200"
  },
  {
    "text": "second scheduling problem is already mentioned the user overestimation which causes low cluster usage and",
    "start": "1186200",
    "end": "1193039"
  },
  {
    "text": "unused resources the reason might be just sheer obliviousness to the concept of and",
    "start": "1193039",
    "end": "1199039"
  },
  {
    "text": "logic behind the resource allocation third problem is posed by interactive",
    "start": "1199039",
    "end": "1204260"
  },
  {
    "text": "jobs which are common in HP sync for example when working with a software like Matlab or ansys",
    "start": "1204260",
    "end": "1211100"
  },
  {
    "text": "if interactive record is created user doesn't want to wait until job moves",
    "start": "1211100",
    "end": "1216740"
  },
  {
    "text": "from waiting queue to running for too long they want to work instantly or in",
    "start": "1216740",
    "end": "1221780"
  },
  {
    "text": "the span of approximately two to three minutes in kubernetes you can set a higher",
    "start": "1221780",
    "end": "1227120"
  },
  {
    "text": "priority on the interactive job and but then you must decide which pod can be",
    "start": "1227120",
    "end": "1232880"
  },
  {
    "text": "terminated also you must watch out for already waiting jobs that may require just",
    "start": "1232880",
    "end": "1238580"
  },
  {
    "text": "slightly more resources than your new interactive job because these",
    "start": "1238580",
    "end": "1243799"
  },
  {
    "text": "interactive jobs could starve others who are already waiting lastly for scheduling problem is tied",
    "start": "1243799",
    "end": "1251660"
  },
  {
    "text": "more to the Academia where you need to enforce fairness and at the same time account everyone for their resource",
    "start": "1251660",
    "end": "1258320"
  },
  {
    "text": "usage kubernetes does not Implement any built-in accounting or fair or user",
    "start": "1258320",
    "end": "1264200"
  },
  {
    "text": "fairness if we talk about multi-tenant clusters but these are crucial Concepts",
    "start": "1264200",
    "end": "1269840"
  },
  {
    "text": "imagine that you have a user who spawns too much interactive jobs and so this",
    "start": "1269840",
    "end": "1275960"
  },
  {
    "text": "user will use all of the resources and new user might never get to compute",
    "start": "1275960",
    "end": "1282580"
  },
  {
    "text": "the good news is that there are some solutions to the problems we proposed one possible solution to the need to",
    "start": "1282919",
    "end": "1289580"
  },
  {
    "text": "reserve resources in the in the manuscript linked below the solution is based on the existence",
    "start": "1289580",
    "end": "1295820"
  },
  {
    "text": "of small or large it doesn't matter jobs that can be evicted easily maybe they do",
    "start": "1295820",
    "end": "1301280"
  },
  {
    "text": "checkpoints maybe their inherent logic counts with restarts nevertheless if",
    "start": "1301280",
    "end": "1306799"
  },
  {
    "text": "larger or an interactive job arrives these jobs which we call scavenger jobs are the first one to terminate and the",
    "start": "1306799",
    "end": "1314600"
  },
  {
    "text": "free space occupied by them is instantly located by placeholder jobs that serve",
    "start": "1314600",
    "end": "1320000"
  },
  {
    "text": "just as a reservation if enough scavenger jobs are terminated to accommodate newer quote all these",
    "start": "1320000",
    "end": "1326840"
  },
  {
    "text": "placeholder jobs free their resources to the workload for which resources were in",
    "start": "1326840",
    "end": "1331880"
  },
  {
    "text": "the first place created or reserved this is actually one way of implementing",
    "start": "1331880",
    "end": "1337400"
  },
  {
    "text": "forward reservations as we know them from HPC another much easier solution would be to",
    "start": "1337400",
    "end": "1345200"
  },
  {
    "text": "create separate clusters where each cluster is dedicated to accommodating a specific workloads type",
    "start": "1345200",
    "end": "1351559"
  },
  {
    "text": "one more solution is a vertical autoscaler which should be available from kubernetes version 125",
    "start": "1351559",
    "end": "1359780"
  },
  {
    "text": "and vertical autoscaler is able to scale resources on the running container",
    "start": "1359780",
    "end": "1365240"
  },
  {
    "text": "this approach might solve a lot of issues when you can change the Pod requests on the Fly",
    "start": "1365240",
    "end": "1371860"
  },
  {
    "text": "now I will move from effective resource allocation to HPC in kubernetes",
    "start": "1371900",
    "end": "1378320"
  },
  {
    "start": "1372000",
    "end": "1372000"
  },
  {
    "text": "we have been researching the potential of kubernetes platform to run big workloads such as analysis on genomics",
    "start": "1378320",
    "end": "1384500"
  },
  {
    "text": "data using workflow manager we asked ourselves to questions",
    "start": "1384500",
    "end": "1389600"
  },
  {
    "text": "can HPC work in kubernetes and will short-living tasks perform better in",
    "start": "1389600",
    "end": "1396140"
  },
  {
    "text": "kubernetes we answered Those Questions by performing several genomic analysis runs",
    "start": "1396140",
    "end": "1402080"
  },
  {
    "text": "on different infrastructures that being traditional HPC environment",
    "start": "1402080",
    "end": "1407360"
  },
  {
    "text": "with batch scheduler open PBS and second environment the kubernetes cluster",
    "start": "1407360",
    "end": "1413600"
  },
  {
    "text": "we compared Numa where and where kubernetes environment with no matter",
    "start": "1413600",
    "end": "1420320"
  },
  {
    "text": "where open PBS environment from our observations we can safely",
    "start": "1420320",
    "end": "1427820"
  },
  {
    "text": "state that for kubernetes to perform as good and even better as traditional HPC",
    "start": "1427820",
    "end": "1434000"
  },
  {
    "text": "environment proper Numa configuration is the most important aspect of the success",
    "start": "1434000",
    "end": "1441080"
  },
  {
    "text": "we have configured just the standard kubernetes normal settings so no custom Solutions or deep system administration",
    "start": "1441080",
    "end": "1447980"
  },
  {
    "text": "work was needed we also found out that Numa memory manager has limitations",
    "start": "1447980",
    "end": "1453260"
  },
  {
    "text": "because kubernetes scheduler does not see the whole amount of available memory",
    "start": "1453260",
    "end": "1459380"
  },
  {
    "text": "with each Numa node it observes whole state in the cluster it happened to us that many pods were",
    "start": "1459380",
    "end": "1466100"
  },
  {
    "text": "rejected from the cluster due to unexpected emission error which is unreco unrecoverable",
    "start": "1466100",
    "end": "1473659"
  },
  {
    "text": "this error is caused by not enough memory on the pneuma Node assigned to",
    "start": "1473659",
    "end": "1479360"
  },
  {
    "text": "pod This truly happened just because the scheduler thought that enough memory was",
    "start": "1479360",
    "end": "1484760"
  },
  {
    "text": "available overall but the poll was assigned to the specific pneuma node",
    "start": "1484760",
    "end": "1489799"
  },
  {
    "text": "which didn't have the memory Additionally the time elapsed from job",
    "start": "1489799",
    "end": "1495440"
  },
  {
    "text": "being scheduled still running job is much shorter in kubernetes because container images are cached and",
    "start": "1495440",
    "end": "1501980"
  },
  {
    "text": "therefore started almost immediately whereas in open PBS environment there's",
    "start": "1501980",
    "end": "1507440"
  },
  {
    "text": "a bit of the setup which with larger number of jobs significantly delays",
    "start": "1507440",
    "end": "1512840"
  },
  {
    "text": "whole computation and there's a material effect runs in",
    "start": "1512840",
    "end": "1517880"
  },
  {
    "text": "kubernetes were much more stable overall on these figures you can see the",
    "start": "1517880",
    "end": "1525200"
  },
  {
    "text": "graphical interpretation of our results the upper left picture shows that the",
    "start": "1525200",
    "end": "1530480"
  },
  {
    "text": "average duration of long running processes processes of genomics analysis is the highest for non-numa aware",
    "start": "1530480",
    "end": "1537320"
  },
  {
    "text": "kubernetes environment if we configure Numa the time is identical or just slightly more than",
    "start": "1537320",
    "end": "1543980"
  },
  {
    "text": "open PBS on the other side is the upper right picture shows if we compare short living",
    "start": "1543980",
    "end": "1550400"
  },
  {
    "text": "tasks kubernetes either with pneuma or non-numa configuration performs",
    "start": "1550400",
    "end": "1556279"
  },
  {
    "text": "significantly better than open PBS in summary the button image shows total",
    "start": "1556279",
    "end": "1563419"
  },
  {
    "text": "duration of genomics analysis where we clearly see that kubernetes within my configuration delivers results faster",
    "start": "1563419",
    "end": "1570980"
  },
  {
    "text": "than PBS environment this is caused by the combination of the",
    "start": "1570980",
    "end": "1576980"
  },
  {
    "text": "long running processes and short running processes because there were much more",
    "start": "1576980",
    "end": "1583220"
  },
  {
    "text": "Shortline running processes than long running processes and if these short",
    "start": "1583220",
    "end": "1588380"
  },
  {
    "text": "processes were computed faster than than in open PBS the whole computation was",
    "start": "1588380",
    "end": "1595220"
  },
  {
    "text": "faster to send infrastructure comparisons app",
    "start": "1595220",
    "end": "1600919"
  },
  {
    "text": "we just saw that kubernetes is certainly capable of accommodating HPC workloads",
    "start": "1600919",
    "end": "1606260"
  },
  {
    "text": "and its performance could improve even more we found out that kubernetes scheduler",
    "start": "1606260",
    "end": "1611900"
  },
  {
    "text": "acts almost as a rifle last in first out queue because it does not preserve the",
    "start": "1611900",
    "end": "1618260"
  },
  {
    "text": "queue and the implemented exponential back off makes just more mess in the queue",
    "start": "1618260",
    "end": "1624020"
  },
  {
    "text": "secondly kubernetes does not Reserve resources which would be handy for certain",
    "start": "1624020",
    "end": "1629539"
  },
  {
    "text": "workload types such as once they requests basically whole node",
    "start": "1629539",
    "end": "1636140"
  },
  {
    "text": "thirdly low Global Knowledge of node resource allocations leads to",
    "start": "1636140",
    "end": "1642100"
  },
  {
    "text": "fragmenting memory and CPUs which could be used more efficiently with a bit smarter or knowledgeable scheduler",
    "start": "1642100",
    "end": "1649940"
  },
  {
    "text": "and just to mention this work was all done as a result of a manuscript that is",
    "start": "1649940",
    "end": "1655159"
  },
  {
    "text": "currently under review and this information marks the end of",
    "start": "1655159",
    "end": "1660380"
  },
  {
    "text": "infrastructure comparisons and now I will move to the Green Computing",
    "start": "1660380",
    "end": "1666580"
  },
  {
    "start": "1666000",
    "end": "1666000"
  },
  {
    "text": "Green Computing is a term that everyone in it has heard of especially these days",
    "start": "1666679",
    "end": "1672860"
  },
  {
    "text": "we all hear about and really feel the rising Rising prices of electricity and listen",
    "start": "1672860",
    "end": "1680779"
  },
  {
    "text": "to the stories about how not deleting emails as to the climate change by keeping the servers on",
    "start": "1680779",
    "end": "1687980"
  },
  {
    "text": "majority of cluster providers would agree that there are times when huge",
    "start": "1687980",
    "end": "1693500"
  },
  {
    "text": "clusters are just turned on but not utilized or utilized with really low",
    "start": "1693500",
    "end": "1698840"
  },
  {
    "text": "effectivity there is a whole an explored field of",
    "start": "1698840",
    "end": "1704720"
  },
  {
    "text": "better scheduling strategies that would accommodate workloads with higher efficiency",
    "start": "1704720",
    "end": "1709940"
  },
  {
    "text": "furthermore we as infrastructure providers should educate users on the best way of utilizing the infrastructure",
    "start": "1709940",
    "end": "1716960"
  },
  {
    "text": "and the best environment for their application a small container can which will a small",
    "start": "1716960",
    "end": "1723380"
  },
  {
    "text": "container will be truly better for a static website than starting a whole",
    "start": "1723380",
    "end": "1728600"
  },
  {
    "text": "virtual machine moreover we can tune the hardware based",
    "start": "1728600",
    "end": "1733700"
  },
  {
    "text": "on CPU usage and power on and off the nodes based on true usage",
    "start": "1733700",
    "end": "1739899"
  },
  {
    "text": "is an idea to work on we came up with a thought that some cluster nodes could be dedicated to running specific workload",
    "start": "1740059",
    "end": "1746900"
  },
  {
    "text": "types similar to scavenger jobs or short-lived jobs if there is a sudden Spike of the amount",
    "start": "1746900",
    "end": "1753380"
  },
  {
    "text": "of parts of this type a new node could be dynamically added to the cluster just",
    "start": "1753380",
    "end": "1759440"
  },
  {
    "text": "for these workloads after this workloads finish the note could be powered off again",
    "start": "1759440",
    "end": "1765140"
  },
  {
    "text": "all these steps might look like implementations or just simple thought they have a great power in reducing the",
    "start": "1765140",
    "end": "1772580"
  },
  {
    "text": "power usage and increasing efficiency lastly I would like to mention the",
    "start": "1772580",
    "end": "1779659"
  },
  {
    "start": "1777000",
    "end": "1777000"
  },
  {
    "text": "concept of hybrid Cloud that is that can be seen as a solution to the scheduling as well",
    "start": "1779659",
    "end": "1785539"
  },
  {
    "text": "the idea is pretty straightforward and is based on connecting HPC world with kubernetes world",
    "start": "1785539",
    "end": "1791539"
  },
  {
    "text": "the HPC world has usually more resources or better scheduling capability and",
    "start": "1791539",
    "end": "1797600"
  },
  {
    "text": "kubernetes world is perfect for other let's say short-lived workload types",
    "start": "1797600",
    "end": "1804140"
  },
  {
    "text": "we are currently working on implementation of open PBS connector",
    "start": "1804140",
    "end": "1810140"
  },
  {
    "text": "which would allow moving pots from kubernetes to the PBS world",
    "start": "1810140",
    "end": "1816340"
  },
  {
    "text": "transparently without modifying the workload inside the Pod at all the",
    "start": "1816340",
    "end": "1821960"
  },
  {
    "text": "container would be executed in the PBS environment as container as well probably just with more resources not",
    "start": "1821960",
    "end": "1829940"
  },
  {
    "text": "available in the kubernetes cluster and with that side I would like to",
    "start": "1829940",
    "end": "1836659"
  },
  {
    "text": "finish this presentation on kubernetes as the Next Generation Academy",
    "start": "1836659",
    "end": "1841700"
  },
  {
    "text": "academical infrastructure and thank you for your attention",
    "start": "1841700",
    "end": "1848019"
  }
]
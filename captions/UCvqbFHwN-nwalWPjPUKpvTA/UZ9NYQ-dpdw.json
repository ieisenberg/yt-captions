[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "hello welcome to the sig auto scaling deep dive my name is joseph",
    "start": "80",
    "end": "6399"
  },
  {
    "text": "burnett and i'm here with my check patel we're going to be going into some auto scaling topics a little bit",
    "start": "6399",
    "end": "14080"
  },
  {
    "text": "deeper than the introduction so we'll be sort of assuming that you know a little bit about",
    "start": "14080",
    "end": "19840"
  },
  {
    "text": "kubernetes auto scaling um and that maybe you have seen the sig",
    "start": "19840",
    "end": "25199"
  },
  {
    "text": "intro so here is our agenda",
    "start": "25199",
    "end": "31840"
  },
  {
    "start": "30000",
    "end": "75000"
  },
  {
    "text": "i'm going to talk a little bit about workload autoscaling that is increasing and decreasing the number of",
    "start": "31920",
    "end": "37200"
  },
  {
    "text": "pods in a cluster and my check is going to follow up with a little bit about a cluster",
    "start": "37200",
    "end": "42640"
  },
  {
    "text": "auto scaling which is increasing and decreasing the number of nodes on which those pods run",
    "start": "42640",
    "end": "48879"
  },
  {
    "text": "in particular i'd like to highlight some new features in hpa coming in kubernetes 118",
    "start": "48879",
    "end": "56320"
  },
  {
    "text": "which are called scale controls and i think that it would be also helpful to",
    "start": "56320",
    "end": "62000"
  },
  {
    "text": "go over a little bit about custom metrics in the hpa and the hpa",
    "start": "62000",
    "end": "67439"
  },
  {
    "text": "life cycle so you can kind of understand how scale controls work okay",
    "start": "67439",
    "end": "74240"
  },
  {
    "text": "so let's talk a little bit about the recommendation life cycle so hpa",
    "start": "74240",
    "end": "81280"
  },
  {
    "start": "75000",
    "end": "247000"
  },
  {
    "text": "like every other object in kubernetes is something stored in scd and when you want to want to scale a",
    "start": "81280",
    "end": "88479"
  },
  {
    "text": "deployment or another scale sub-resource horizontally you declare your intent in an hpa object in",
    "start": "88479",
    "end": "95680"
  },
  {
    "text": "spec and the hpa controller tries to reconcile to that intent so the first step in that reconciliation",
    "start": "95680",
    "end": "103119"
  },
  {
    "text": "is to get the hpa object the next thing is to",
    "start": "103119",
    "end": "108880"
  },
  {
    "text": "get the target of the hpa which is in this case a deployment or anything that implements the scale sub-resource",
    "start": "108880",
    "end": "116159"
  },
  {
    "text": "so the controller will get the current scale then it will look at the metrics that",
    "start": "116159",
    "end": "122320"
  },
  {
    "text": "you've defined for this hpa and it will load them from the metric server and",
    "start": "122320",
    "end": "129440"
  },
  {
    "text": "put those two together and calculate what the new scale should be so it'll come up with some",
    "start": "129440",
    "end": "135520"
  },
  {
    "text": "recommendation for example if you if you've decided that you want your application to run",
    "start": "135520",
    "end": "141680"
  },
  {
    "text": "on average at 50 cpu utilization um the hpa controller will get the",
    "start": "141680",
    "end": "148239"
  },
  {
    "text": "current number of pods maybe it's 10. it'll get the current cpu utilization",
    "start": "148239",
    "end": "153599"
  },
  {
    "text": "from the metrics maybe cpu utilization is 75 and it will decide okay",
    "start": "153599",
    "end": "160560"
  },
  {
    "text": "actually you need more pods to bring that down to the target so it will give you five additional pods",
    "start": "160560",
    "end": "166959"
  },
  {
    "text": "um then after it's calculated the new desired state for each metric",
    "start": "166959",
    "end": "174160"
  },
  {
    "text": "it will uh limit and stabilize the maximum recommendation so limiting",
    "start": "174160",
    "end": "181440"
  },
  {
    "text": "is like not going above the specified maximum not going below this specified minimum stabilization is a",
    "start": "181440",
    "end": "189680"
  },
  {
    "text": "part of the algorithm that waits for five minutes before you scale down so it actually",
    "start": "189680",
    "end": "197280"
  },
  {
    "text": "so light keeps a window of recommendations for five minutes and chooses the maximum recommendation",
    "start": "197280",
    "end": "203280"
  },
  {
    "text": "over that time this prevents flapping and scale down stabilization allows you to scale",
    "start": "203280",
    "end": "209920"
  },
  {
    "text": "up quickly in response to new load but sort of come down gracefully without flapping",
    "start": "209920",
    "end": "217280"
  },
  {
    "text": "so that finally when the hpa recommender has a has a scale it will turn around and set",
    "start": "219200",
    "end": "226720"
  },
  {
    "text": "that back onto the scale sub-resource and then wait for 15 seconds before",
    "start": "226720",
    "end": "232080"
  },
  {
    "text": "repeating the process it does this for each hpa object every 15 seconds",
    "start": "232080",
    "end": "237200"
  },
  {
    "text": "goes in this reconciliation loop checking the current state of the world making an adjustment checking to see if",
    "start": "237200",
    "end": "242959"
  },
  {
    "text": "it needs to make subsequent changes so there's a there's a feedback loop",
    "start": "242959",
    "end": "248159"
  },
  {
    "start": "247000",
    "end": "270000"
  },
  {
    "text": "so hpa has two versions available there's v1 and v2 v2 is currently in beta 2. um",
    "start": "249040",
    "end": "256160"
  },
  {
    "text": "you can get them from the command line with these commands here just this is normal kubernetes stuff you just have to qualify",
    "start": "256160",
    "end": "261759"
  },
  {
    "text": "v2 um don't look too closely at this i just wanted to show you the shape and i'm going to",
    "start": "261759",
    "end": "266960"
  },
  {
    "text": "go through each one of these sections one at a time so on the left hand side",
    "start": "266960",
    "end": "275600"
  },
  {
    "start": "270000",
    "end": "318000"
  },
  {
    "text": "you can see scale target ref in v1 and it has the same thing in v2 which is",
    "start": "275600",
    "end": "281280"
  },
  {
    "text": "pretty simple just points to some kubernetes object the second part of the spec is the",
    "start": "281280",
    "end": "288880"
  },
  {
    "text": "metrics so in in v1hpa there's just one top level target which",
    "start": "288880",
    "end": "296800"
  },
  {
    "text": "is cpu utilization percentage but in hpa v2 you can provide",
    "start": "296800",
    "end": "303680"
  },
  {
    "text": "more than one metric so you'll notice that metrics on the right hand side is a list and this is what cpu",
    "start": "303680",
    "end": "309840"
  },
  {
    "text": "utilization looks like for the new v2 metrics so",
    "start": "309840",
    "end": "318160"
  },
  {
    "start": "318000",
    "end": "346000"
  },
  {
    "text": "after you have after the hpa has gotten your current scale it's going to go through each one",
    "start": "319280",
    "end": "325680"
  },
  {
    "text": "of these metrics retrieving it from the server and it writes the current",
    "start": "325680",
    "end": "331759"
  },
  {
    "text": "levels to the status so that you can see in the status of the hpa object",
    "start": "331759",
    "end": "338000"
  },
  {
    "text": "how the controller is doing towards reconciliation this is nice for observability and just",
    "start": "338000",
    "end": "343680"
  },
  {
    "text": "to make sure that it's doing what you expect it to so i mentioned that hpa v2 can have",
    "start": "343680",
    "end": "350800"
  },
  {
    "start": "346000",
    "end": "404000"
  },
  {
    "text": "multiple metrics so the other kind of metrics that you can add in there to that list are called custom and external metrics",
    "start": "350800",
    "end": "357520"
  },
  {
    "text": "custom metrics are anything that's inside of the kubernetes ecosystem so this is",
    "start": "357520",
    "end": "362720"
  },
  {
    "text": "pods or deployments ingress whatever um there's two kinds of custom metrics",
    "start": "362720",
    "end": "368800"
  },
  {
    "text": "one custom metric is a pod metric and then so the hpa will expect to find",
    "start": "368800",
    "end": "374560"
  },
  {
    "text": "one of these for each pod in the deployment and then it will",
    "start": "374560",
    "end": "379759"
  },
  {
    "text": "average them for an object metric hpa will expect to find just a single",
    "start": "379759",
    "end": "385280"
  },
  {
    "text": "value so for example ingress could have qps associated with it external metrics are things that are",
    "start": "385280",
    "end": "392000"
  },
  {
    "text": "outside of kubernetes could be some pub sub q or something just simply on",
    "start": "392000",
    "end": "398880"
  },
  {
    "text": "you know entirely external so these are fairly arbitrary",
    "start": "398880",
    "end": "404960"
  },
  {
    "start": "404000",
    "end": "506000"
  },
  {
    "text": "i want to take a moment and talk a little bit about how custom metrics are wired into the system",
    "start": "405680",
    "end": "411280"
  },
  {
    "text": "because this is something that's important to know if you're going to set up hpa on custom metrics so the api server has",
    "start": "411280",
    "end": "418639"
  },
  {
    "text": "a mechanism by which it can delegate calls to some objects to other api servers",
    "start": "418639",
    "end": "427440"
  },
  {
    "text": "so you can see there that the main api server has fcd storing things",
    "start": "427440",
    "end": "434160"
  },
  {
    "text": "like hpas deployments pods etc but when it gets a request from metrics",
    "start": "434160",
    "end": "439520"
  },
  {
    "text": "it routes it to a different server there's a metric server that's part of the normal",
    "start": "439520",
    "end": "444880"
  },
  {
    "text": "kubernetes distribution which provides memory and cpu and that's runs typically in the",
    "start": "444880",
    "end": "451520"
  },
  {
    "text": "user space of the cluster the access pattern for a database like that is very",
    "start": "451520",
    "end": "456800"
  },
  {
    "text": "different so this is one of the reasons why it's a different implementation it's a time series database not just a key value store there's another server",
    "start": "456800",
    "end": "465120"
  },
  {
    "text": "that is in this routing path as well which is the custom or external metrics adapter",
    "start": "465120",
    "end": "472319"
  },
  {
    "text": "so there is no default implementation for custom metrics in kubernetes this is",
    "start": "472319",
    "end": "478400"
  },
  {
    "text": "something that you provide as either a cloud provider or you can install prometheus in your cluster so for example if you",
    "start": "478400",
    "end": "484879"
  },
  {
    "text": "have a prometheus instance that has the metrics that you want for custom and external metrics you you install an",
    "start": "484879",
    "end": "491120"
  },
  {
    "text": "adapter that will take those get requests to the api server objects",
    "start": "491120",
    "end": "497039"
  },
  {
    "text": "and translate it into a backend query for the the data source that you have so this is uh",
    "start": "497039",
    "end": "503919"
  },
  {
    "text": "this is where the data comes from when hpa retrieves it so moving on sort of through the life",
    "start": "503919",
    "end": "510560"
  },
  {
    "start": "506000",
    "end": "552000"
  },
  {
    "text": "cycle here you can see that calculating the state is um is kind of the core value of this of the hpa this is the",
    "start": "510560",
    "end": "519039"
  },
  {
    "text": "part that's going to reconcile you the number to",
    "start": "519039",
    "end": "524959"
  },
  {
    "text": "to try to achieve your target so the current utilization is first achieved by either averaging",
    "start": "524959",
    "end": "531360"
  },
  {
    "text": "that all the pods are just taking the single value and then it's going to be divided by the target so say if you want 50 percent and",
    "start": "531360",
    "end": "538240"
  },
  {
    "text": "you get 75 you end up with a one and a half times",
    "start": "538240",
    "end": "543440"
  },
  {
    "text": "what you should have in terms of utilization so you multiply that by the current scale",
    "start": "543440",
    "end": "548959"
  },
  {
    "text": "and that gives you the new number of pods that you should have and then the next phase is stabilization",
    "start": "548959",
    "end": "556959"
  },
  {
    "start": "552000",
    "end": "567000"
  },
  {
    "text": "which i already mentioned before keeps a five minute window now this",
    "start": "556959",
    "end": "562399"
  },
  {
    "text": "is actually going to be configurable with scale controls which is something i'm going to get into in just a minute",
    "start": "562399",
    "end": "568880"
  },
  {
    "start": "567000",
    "end": "733000"
  },
  {
    "text": "so there are a few so these are so scale controls are a new",
    "start": "569200",
    "end": "574880"
  },
  {
    "text": "field top level field in the v2 api inside of the behavior field is",
    "start": "574880",
    "end": "582160"
  },
  {
    "text": "two structures they're identical one is called scale up one is called scale down",
    "start": "582160",
    "end": "587839"
  },
  {
    "text": "and each of these has the stabilization as well as relative and absolute policy that can be",
    "start": "587839",
    "end": "593760"
  },
  {
    "text": "applied in term for limiting the rate there's a couple of defaults that were already",
    "start": "593760",
    "end": "599839"
  },
  {
    "text": "part of hpa which have become defaults for the",
    "start": "599839",
    "end": "605360"
  },
  {
    "text": "scale controls one is that um there's a flag on controller manager",
    "start": "605360",
    "end": "611600"
  },
  {
    "text": "that sets the down scale stabilization window which is by default five minutes so this",
    "start": "611600",
    "end": "616880"
  },
  {
    "text": "is the default for scale controls as well and this is as you can see here inside the scale down structure",
    "start": "616880",
    "end": "623600"
  },
  {
    "text": "there was also a couple of defaults that were hard coded into the controller itself",
    "start": "623600",
    "end": "628640"
  },
  {
    "text": "one was that it's okay for you to go from one pod to four pods because this allows",
    "start": "628640",
    "end": "635600"
  },
  {
    "text": "you to get off the ground a little bit faster for scale up because in order to in order to scale",
    "start": "635600",
    "end": "641519"
  },
  {
    "text": "up for something like cpu you need to sort of scale up see additional usage scale up",
    "start": "641519",
    "end": "648000"
  },
  {
    "text": "again see additional usage so this was sort of just a small optimization and also there was a limit",
    "start": "648000",
    "end": "655200"
  },
  {
    "text": "in the controller which said that you can only scale up by 2x each time each reconciliation so these become",
    "start": "655200",
    "end": "662399"
  },
  {
    "text": "defaults in the scale controls but you can change them so for example if you want to if you",
    "start": "662399",
    "end": "668640"
  },
  {
    "text": "want to come down slowly if you sort of expect your traffic to maybe come back you can limit",
    "start": "668640",
    "end": "674240"
  },
  {
    "text": "the rate at which you scale down if you want to maybe have a shorter",
    "start": "674240",
    "end": "680000"
  },
  {
    "text": "stabilization window to come off of a spike more quickly or a longer one you can set that it's",
    "start": "680000",
    "end": "686959"
  },
  {
    "text": "actually also possible to set a scale up stabilization window which is sounds kind of",
    "start": "686959",
    "end": "693360"
  },
  {
    "text": "counter-intuitive at first but it could be useful for a batch workload",
    "start": "693360",
    "end": "698480"
  },
  {
    "text": "where for example you have some number of pods running and a whole bunch of messages land in the queue",
    "start": "698480",
    "end": "704240"
  },
  {
    "text": "but you may care more about you know utilizing your pods and",
    "start": "704240",
    "end": "709680"
  },
  {
    "text": "resources as efficiently as possible rather than latency so you might want to wait a few seconds or",
    "start": "709680",
    "end": "715680"
  },
  {
    "text": "a few minutes to wait and see if the pods that are already there can handle all the messages so that's what a",
    "start": "715680",
    "end": "721360"
  },
  {
    "text": "stabilization window could be used for for scale up",
    "start": "721360",
    "end": "727120"
  },
  {
    "text": "so explore the documentation there's kind of a cool feature that's uh there in 118.",
    "start": "727120",
    "end": "734000"
  },
  {
    "start": "733000",
    "end": "749000"
  },
  {
    "text": "and the there's a lot more details about what they mean in the actual like golang docks so i recommend you go take",
    "start": "735040",
    "end": "742560"
  },
  {
    "text": "a look at it again that's in the v2 beta 2",
    "start": "742560",
    "end": "748079"
  },
  {
    "text": "hpa structure so big thanks to ivan and arjun for",
    "start": "748079",
    "end": "753920"
  },
  {
    "text": "writing the cap and doing the implementation and pushing this through for uh",
    "start": "753920",
    "end": "759279"
  },
  {
    "text": "quite some time it's it could be difficult to make changes in kubernetes it can take time and patience and",
    "start": "759279",
    "end": "765519"
  },
  {
    "text": "um they definitely did a great great thing here to put this with the scale controls in so thank you",
    "start": "765519",
    "end": "773839"
  },
  {
    "start": "772000",
    "end": "815000"
  },
  {
    "text": "one last thing about the v2 api i'd like to mention before i close the workload section is that um",
    "start": "774480",
    "end": "783040"
  },
  {
    "text": "there's also conditions which are added to the v2 api and status so",
    "start": "783040",
    "end": "789839"
  },
  {
    "text": "conditions are a pattern a newer pattern newer than v1",
    "start": "789839",
    "end": "794880"
  },
  {
    "text": "hpa which just gives you some insight into [Music] how the reconciling",
    "start": "794880",
    "end": "803120"
  },
  {
    "text": "controller is doing towards achieving your desired state and if it's not in the desired state why",
    "start": "803120",
    "end": "810560"
  },
  {
    "text": "not so it's kind of a structured way to sort of get some insight and observability",
    "start": "810560",
    "end": "816320"
  },
  {
    "text": "and there's three sort of types that are worth noting scaling active",
    "start": "816320",
    "end": "822880"
  },
  {
    "text": "able to scale and scaling limited so i'd like to talk for a moment about what each of those means",
    "start": "822880",
    "end": "829760"
  },
  {
    "text": "scaling actives means that you have provided metrics that exist they can be retrieved so it's possible",
    "start": "829760",
    "end": "837120"
  },
  {
    "text": "to sort of know where we're at in terms of the metrics that you provided",
    "start": "837120",
    "end": "842720"
  },
  {
    "text": "so if able to if scaling active is true that's that's a good thing able to scale means that the scale",
    "start": "842720",
    "end": "848880"
  },
  {
    "text": "target ref is able to be retrieved and updated so that also should be true and if it's",
    "start": "848880",
    "end": "855519"
  },
  {
    "text": "not then there'll be a message there to tell you a little bit more specifically what went wrong",
    "start": "855519",
    "end": "860720"
  },
  {
    "text": "scaling limited is a little bit more of a just informative it's not necessarily a",
    "start": "860720",
    "end": "866399"
  },
  {
    "text": "problem if you're scale limited because usually you're limited because of some policy",
    "start": "866399",
    "end": "871440"
  },
  {
    "text": "limit or a stabilization that that has been put in effect for a reason so this is just for you to know that the",
    "start": "871440",
    "end": "879120"
  },
  {
    "text": "raw desired number of replicas is being constrained in some way either",
    "start": "879120",
    "end": "886000"
  },
  {
    "text": "upwards or downwards and this should also tell you why so you can get some insight into how",
    "start": "886000",
    "end": "891760"
  },
  {
    "text": "it's operating so all these extra fields in v2",
    "start": "891760",
    "end": "897839"
  },
  {
    "start": "893000",
    "end": "950000"
  },
  {
    "text": "are backwards compatible so you can actually retrieve any of these hba objects as a",
    "start": "897839",
    "end": "904320"
  },
  {
    "text": "v1 or a v2 and it's done losslessly by serializing all the new and unknown fields into",
    "start": "904320",
    "end": "911600"
  },
  {
    "text": "annotations so it's possible to interact with um a v2 hpa object as a v1 with a read",
    "start": "911600",
    "end": "919839"
  },
  {
    "text": "modify right loop as long as you only modify the spec fields for that particular",
    "start": "919839",
    "end": "924959"
  },
  {
    "text": "um version in case you're wondering where these things go and when you just say cube control get hpa",
    "start": "924959",
    "end": "930560"
  },
  {
    "text": "most of the most of the interesting stuff is in annotations so it's worth worth pulling down the v2 object",
    "start": "930560",
    "end": "936800"
  },
  {
    "text": "so that's sort of a summary of scale controls and v hp v2 and some custom metrics",
    "start": "936800",
    "end": "943199"
  },
  {
    "text": "so at this point i think i'll hand it off to my check who's going to talk about the",
    "start": "943199",
    "end": "948720"
  },
  {
    "text": "cluster auto scale thanks joe so yeah let's talk about",
    "start": "948720",
    "end": "955839"
  },
  {
    "start": "950000",
    "end": "1085000"
  },
  {
    "text": "cluster autoscaler what i'd like to do is take you through an example scale up scenario",
    "start": "955839",
    "end": "962959"
  },
  {
    "text": "and we'll go to it step by step exploring cluster auto scalar logic to",
    "start": "962959",
    "end": "968079"
  },
  {
    "text": "see how it makes its uh ultimate auto scaling decision but before we get there i'd like to do a",
    "start": "968079",
    "end": "974639"
  },
  {
    "text": "quick intro slash reminder uh just quickly covering what cluster auto scale is and",
    "start": "974639",
    "end": "980639"
  },
  {
    "text": "what it does so uh as joe already said the job of class delta scaler is to",
    "start": "980639",
    "end": "987519"
  },
  {
    "text": "provide notes um so add and delete nodes based on the needs of the pots in your cluster",
    "start": "987519",
    "end": "996079"
  },
  {
    "text": "and more specifically its job really is to make sure that every pod in the cluster",
    "start": "996079",
    "end": "1001600"
  },
  {
    "text": "can be scheduled and to that end crosstalk auto scaler takes into account",
    "start": "1001600",
    "end": "1007279"
  },
  {
    "text": "all the same things that kubernetes schedule looks at so this is going to be things like",
    "start": "1007279",
    "end": "1012959"
  },
  {
    "text": "uh notes size notes allocatable and port resource requests and",
    "start": "1012959",
    "end": "1019920"
  },
  {
    "text": "but also things like pots note selectors node affinities pod affinities hospitals",
    "start": "1019920",
    "end": "1028240"
  },
  {
    "text": "any sort of storage related requirements and so on basically anything that",
    "start": "1028240",
    "end": "1033918"
  },
  {
    "text": "can go into kubernetes scheduling what it doesn't look at is uh metrics uh because kubernetes",
    "start": "1033919",
    "end": "1041520"
  },
  {
    "text": "scheduling doesn't uh take into account actual cpu usage or memory utilization of the",
    "start": "1041520",
    "end": "1048400"
  },
  {
    "text": "vms so neither does class delta scale for that part you need workload auto scaling and",
    "start": "1048400",
    "end": "1056240"
  },
  {
    "text": "before we proceed there is one more concept that we're going to need and that is a node group a node group is",
    "start": "1056240",
    "end": "1062799"
  },
  {
    "text": "basically a set of identical notes a resizable set of auto",
    "start": "1062799",
    "end": "1068080"
  },
  {
    "text": "identical nodes so whenever the cluster to scalar wants to scale up what it really does is it resizes a",
    "start": "1068080",
    "end": "1074720"
  },
  {
    "text": "particular node group adding some number of nodes to it and the actual implementation",
    "start": "1074720",
    "end": "1080080"
  },
  {
    "text": "of node group is going to be different uh on each provider so let's quickly look",
    "start": "1080080",
    "end": "1087039"
  },
  {
    "start": "1085000",
    "end": "1203000"
  },
  {
    "text": "at the architecture of class autoscaler so class autoscaler is a pot that runs in",
    "start": "1087039",
    "end": "1093120"
  },
  {
    "text": "your cluster either on notes on the master vm and it's really made of three",
    "start": "1093120",
    "end": "1098799"
  },
  {
    "text": "main parts there is the cluster auto scaler logic the color logic of auto scaler that sort of",
    "start": "1098799",
    "end": "1106160"
  },
  {
    "text": "does the whole the whole auto scaling logic but there are two important parts that are also there",
    "start": "1106160",
    "end": "1111679"
  },
  {
    "text": "so first of all there is the embedded scheduler code in order to make sure that cluster",
    "start": "1111679",
    "end": "1117120"
  },
  {
    "text": "autoscaler respects all the constraints of scheduling and it actually has the same logic as the scheduler what",
    "start": "1117120",
    "end": "1124880"
  },
  {
    "text": "we do is we just import the scheduler code and use it to run",
    "start": "1124880",
    "end": "1130080"
  },
  {
    "text": "sort of hypothetical scenarios to explore what would happen if a node was added to",
    "start": "1130080",
    "end": "1136960"
  },
  {
    "text": "the cluster right would that uh help any of the ports that are currently pending get scheduled",
    "start": "1136960",
    "end": "1143360"
  },
  {
    "text": "but what would happen if some node was removed from the cluster would all pods running there will be",
    "start": "1143360",
    "end": "1149440"
  },
  {
    "text": "able to schedule on some other nodes and instead of replicating all the schedule",
    "start": "1149440",
    "end": "1155679"
  },
  {
    "text": "scheduler logic in autoscaler we just import scheduler code and ask it those questions and the other the",
    "start": "1155679",
    "end": "1162840"
  },
  {
    "text": "other external part uh is the",
    "start": "1162840",
    "end": "1168640"
  },
  {
    "text": "cloud provided module it's basically a rich client to a given cloud provider so something like aws or gc",
    "start": "1168640",
    "end": "1176559"
  },
  {
    "text": "azure or something more abstract like a cluster api and this is what class autoscaler uses",
    "start": "1176559",
    "end": "1182640"
  },
  {
    "text": "to actuate its decisions whenever class autoscaler wants to scale up it really all it does",
    "start": "1182640",
    "end": "1187919"
  },
  {
    "text": "is request a vm from the cloud provider and then it doesn't it isn't actually",
    "start": "1187919",
    "end": "1194559"
  },
  {
    "text": "involved in the process of that vm starting up or registering in kubernetes all it",
    "start": "1194559",
    "end": "1200559"
  },
  {
    "text": "really does is it make a request to cloud provider so i think with that background we're ready to dive into the an example scale",
    "start": "1200559",
    "end": "1207520"
  },
  {
    "start": "1203000",
    "end": "1570000"
  },
  {
    "text": "up so what i have here is basically a sort of hypothetical scenario",
    "start": "1207520",
    "end": "1214080"
  },
  {
    "text": "and there is a cluster with three node groups so as you can see there is a node group",
    "start": "1214080",
    "end": "1219360"
  },
  {
    "text": "with large nodes that have a label a and also node group of equally large",
    "start": "1219360",
    "end": "1225520"
  },
  {
    "text": "nodes with label b and finally a third node group of smaller nodes",
    "start": "1225520",
    "end": "1230799"
  },
  {
    "text": "and these dimensions of nodes are meant to be a some sort of abstract",
    "start": "1230799",
    "end": "1236480"
  },
  {
    "text": "representation of resources available uh on those nodes so for example you can think of it as a",
    "start": "1236480",
    "end": "1242799"
  },
  {
    "text": "maybe vertical size of the node would be how many calls it has and then the horizontal size would be",
    "start": "1242799",
    "end": "1248320"
  },
  {
    "text": "how much memory there is and similarly there are a bunch of pods which also have size which would be the",
    "start": "1248320",
    "end": "1254400"
  },
  {
    "text": "same with that that would be the pot resource requests and as you can see some of the pods uh",
    "start": "1254400",
    "end": "1260000"
  },
  {
    "text": "also have a node selector so this is to illustrate like other type of constraint that's not",
    "start": "1260000",
    "end": "1265360"
  },
  {
    "text": "resource related but it's also respected by clustered auto scalar so in this case some of those spots can",
    "start": "1265360",
    "end": "1270559"
  },
  {
    "text": "only run on nodes with label a which means basically nodes from the first",
    "start": "1270559",
    "end": "1276000"
  },
  {
    "text": "note group so let's let's start the hypothetical",
    "start": "1276000",
    "end": "1281919"
  },
  {
    "text": "scenario we're starting with a bunch of empty notes and a bunch of pending parts so obviously the first thing that's",
    "start": "1281919",
    "end": "1287440"
  },
  {
    "text": "going to happen is scheduler will jump in and schedule as many pods as it",
    "start": "1287440",
    "end": "1293600"
  },
  {
    "text": "can on existing nodes so this is basically what what we can see in these slides",
    "start": "1293600",
    "end": "1299200"
  },
  {
    "text": "all the parts that can fit on the nodes are already dead and the notes are",
    "start": "1299200",
    "end": "1304799"
  },
  {
    "text": "pretty much full but there are still some pots that remain so what will happen with those is the",
    "start": "1304799",
    "end": "1311360"
  },
  {
    "text": "scheduler will say that it cannot schedule them because there is not enough",
    "start": "1311360",
    "end": "1316880"
  },
  {
    "text": "resources available in the cluster and it will mark them as unscheduleable more specifically it will",
    "start": "1316880",
    "end": "1322159"
  },
  {
    "text": "set a status condition on on those spots and that is the signal signal for cluster autoscaler",
    "start": "1322159",
    "end": "1328720"
  },
  {
    "text": "to jump in it basically looks for those unscheduleable ports",
    "start": "1328720",
    "end": "1334240"
  },
  {
    "text": "and tries to help them and the way it does it is it explodes those hypothetical",
    "start": "1334240",
    "end": "1340159"
  },
  {
    "text": "scenarios so the first thing autoscaler could do is think okay what would happen if there",
    "start": "1340159",
    "end": "1345520"
  },
  {
    "text": "was one more of those label a node basically what would happen if a node first node group had two nodes instead",
    "start": "1345520",
    "end": "1351600"
  },
  {
    "text": "of one until to this end it will create an in memory fake representation of a node",
    "start": "1351600",
    "end": "1358320"
  },
  {
    "text": "it doesn't correspond to any real vm or anything like that yet it's just an in-memory object and it would ask schedule okay what",
    "start": "1358320",
    "end": "1365120"
  },
  {
    "text": "would happen now like if you had this extra note so in this case the scheduler would be",
    "start": "1365120",
    "end": "1371440"
  },
  {
    "text": "able to schedule some of those pending pots on this new note but not all of them i",
    "start": "1371440",
    "end": "1376799"
  },
  {
    "text": "did the one note is not enough to fit all of those pending posts so crosstalk autoscaler will just continue to do the same it will add",
    "start": "1376799",
    "end": "1383679"
  },
  {
    "text": "one more identical node so basically explore okay so what would happen if i resized this node group from one to three and",
    "start": "1383679",
    "end": "1391919"
  },
  {
    "text": "once again it would ask scheduler and the scheduler would put small ports on this new node and",
    "start": "1391919",
    "end": "1397840"
  },
  {
    "text": "basically we would reach a state where all the pots that are pending and could now be scheduled if",
    "start": "1397840",
    "end": "1405679"
  },
  {
    "text": "uh two more nodes were added to the first node group so that is what we call expansion option that's",
    "start": "1405679",
    "end": "1411280"
  },
  {
    "text": "basically one action available to cluster auto scale which will help depending pots but of course there are",
    "start": "1411280",
    "end": "1417760"
  },
  {
    "text": "other possibilities there there are other node groups there are other combinations of nodes that could be added",
    "start": "1417760",
    "end": "1423760"
  },
  {
    "text": "so what crashed auto scale will do at this point is it will just remember this particular expansion option and it",
    "start": "1423760",
    "end": "1430159"
  },
  {
    "text": "will proceed to evaluate other scenarios so let's",
    "start": "1430159",
    "end": "1435760"
  },
  {
    "text": "let's try that and i'm just going to go more quickly to it right now so if we do",
    "start": "1435760",
    "end": "1442400"
  },
  {
    "text": "very similar logic where we add nodes uh for as long as we can put more of the pending points on them and",
    "start": "1442400",
    "end": "1449039"
  },
  {
    "text": "we do this process for the second node group we can see that we could add three more of those small nodes and that",
    "start": "1449039",
    "end": "1455200"
  },
  {
    "text": "would help three of those spending pots however uh no there is no way we can help the large",
    "start": "1455200",
    "end": "1462960"
  },
  {
    "text": "pending posts by adding small nodes just because each individual pod is too large if we",
    "start": "1462960",
    "end": "1468080"
  },
  {
    "text": "think about this once again that the horizontal dimension is memory uh the small nodes just don't have",
    "start": "1468080",
    "end": "1474640"
  },
  {
    "text": "enough memory to run the large board so that there is no way we can help them by adding the small nodes",
    "start": "1474640",
    "end": "1480320"
  },
  {
    "text": "but that's fine that that is an expansion option so we we can remember that we can add three small nodes and",
    "start": "1480320",
    "end": "1486559"
  },
  {
    "text": "that will help those small pots and we can proceed to the next simulation",
    "start": "1486559",
    "end": "1492799"
  },
  {
    "text": "and explore what would happen if we were to resize the fence node group and the end of this result here is we",
    "start": "1492799",
    "end": "1501039"
  },
  {
    "text": "can add two nodes and that will help all the ports except the one with the node selector a",
    "start": "1501039",
    "end": "1506640"
  },
  {
    "text": "there is actually enough resources on those two new nodes to run all the ports but we cannot schedule one of them",
    "start": "1506640",
    "end": "1512960"
  },
  {
    "text": "because of the node selector constraint so that illustrates that class auto scaler is also taking these sort of",
    "start": "1512960",
    "end": "1519120"
  },
  {
    "text": "constraints into account so this is basically how the",
    "start": "1519120",
    "end": "1525679"
  },
  {
    "text": "exploration of various scenarios would look like in class the autoscaler note that all the options with",
    "start": "1526320",
    "end": "1532640"
  },
  {
    "text": "considering is always resizing one node group by a certain amount of nodes and it's always",
    "start": "1532640",
    "end": "1539120"
  },
  {
    "text": "the largest amount of nodes that actually helps any uh help spots right so we're not going",
    "start": "1539120",
    "end": "1545840"
  },
  {
    "text": "to consider an option where we would resize uh let's say the felt node group by just one node because",
    "start": "1545840",
    "end": "1553360"
  },
  {
    "text": "adding one more node still help spots so we'll just greedily basically bean pack until",
    "start": "1553360",
    "end": "1559760"
  },
  {
    "text": "uh adding more nodes doesn't help any more pots and crashed auto scale is also not",
    "start": "1559760",
    "end": "1565039"
  },
  {
    "text": "considering mixed scale ups it's always considering resizing just one node group",
    "start": "1565039",
    "end": "1571360"
  },
  {
    "start": "1570000",
    "end": "1681000"
  },
  {
    "text": "so after all the simulations are done we really left with three of those expansion options uh that we",
    "start": "1571360",
    "end": "1577600"
  },
  {
    "text": "discussed earlier and class autoscaler is going to use something we call expander to choose one",
    "start": "1577600",
    "end": "1583120"
  },
  {
    "text": "of those options expanded is basically just a holistic that takes all the available expansion",
    "start": "1583120",
    "end": "1589039"
  },
  {
    "text": "options basically how many nodes are needed to help what set of pots and it just evaluates",
    "start": "1589039",
    "end": "1596559"
  },
  {
    "text": "them to choose the best one there are multiple different expanders there is a random expander which just",
    "start": "1596559",
    "end": "1602000"
  },
  {
    "text": "chooses a random option i don't really recommend that one uh but there are other like least ways like the",
    "start": "1602000",
    "end": "1607919"
  },
  {
    "text": "one that tries to have the least unused resources there is a pricing expanded available",
    "start": "1607919",
    "end": "1613279"
  },
  {
    "text": "for some platforms which tries to choose the cheapest in terms of dollar cost",
    "start": "1613279",
    "end": "1618799"
  },
  {
    "text": "like the cheapest option in terms of dollars and there is also a priority expanded where you can",
    "start": "1618799",
    "end": "1625600"
  },
  {
    "text": "basically the user specifies a list of preference between node groups and class auto",
    "start": "1625600",
    "end": "1631840"
  },
  {
    "text": "scaler will try to choose whichever one is the most preferred that's particularly useful when you have some",
    "start": "1631840",
    "end": "1638320"
  },
  {
    "text": "sort of much cheaper instances like maybe sport or preemptible instances",
    "start": "1638320",
    "end": "1644159"
  },
  {
    "text": "or you can implement your own expander it's actually a simple go like interface and it's not very hard to implement one",
    "start": "1644159",
    "end": "1651360"
  },
  {
    "text": "and the one remaining question is okay some of those expansion options only",
    "start": "1651360",
    "end": "1656880"
  },
  {
    "text": "help some of the pending pots what what about the other parts and the answer is after doing the first scale up if any",
    "start": "1656880",
    "end": "1663600"
  },
  {
    "text": "pots remain pending class auto scale will run another iteration and do the whole simulation again and",
    "start": "1663600",
    "end": "1671200"
  },
  {
    "text": "pick some other scale up and it will continue doing so until it helps all depending pots",
    "start": "1671200",
    "end": "1676880"
  },
  {
    "text": "so that's a very quick overview of how scale up works in classic autoscaler and before i",
    "start": "1676880",
    "end": "1684159"
  },
  {
    "start": "1681000",
    "end": "2132000"
  },
  {
    "text": "end this talk i'd like to quickly talk about our sea auto skating group",
    "start": "1684159",
    "end": "1690399"
  },
  {
    "text": "we have meetings every monday at 4 00 pm central european time and they happen on zoom and everyone is",
    "start": "1690399",
    "end": "1696559"
  },
  {
    "text": "of course welcome to attend this and ask any questions uh discuss any suggestions and so on we",
    "start": "1696559",
    "end": "1702399"
  },
  {
    "text": "also have uh our own channel on kubernetes slack where i think it's quite active so if you have",
    "start": "1702399",
    "end": "1708559"
  },
  {
    "text": "any problems i think that's a good place to either ask for help or just engage us",
    "start": "1708559",
    "end": "1714159"
  },
  {
    "text": "for discussing features and so on and finally most of our code is in our own",
    "start": "1714159",
    "end": "1720000"
  },
  {
    "text": "github repository and that's it for me thank you very much",
    "start": "1720000",
    "end": "1739840"
  },
  {
    "text": "great so uh this is joseph burnett here um i'll take some questions about uh",
    "start": "1741679",
    "end": "1748159"
  },
  {
    "text": "workload autoscaling about hpa and then i'll hand it over to my check for a few cluster auto scaling",
    "start": "1748159",
    "end": "1754480"
  },
  {
    "text": "questions um so one question i got was uh will ale up and down values",
    "start": "1754480",
    "end": "1761679"
  },
  {
    "text": "override the values set like globally set globally like the horizontal pod auto scaler down",
    "start": "1761679",
    "end": "1767279"
  },
  {
    "text": "stabilization flag will global values affect scale up and down if all you define of the scale",
    "start": "1767279",
    "end": "1773039"
  },
  {
    "text": "values in your hpa yaml file so um when you create an hpa",
    "start": "1773039",
    "end": "1781600"
  },
  {
    "text": "it is given default um scale down stabilization and scale up",
    "start": "1781600",
    "end": "1788320"
  },
  {
    "text": "policies which match the hard-coded defaults which were previous to 118. um",
    "start": "1788320",
    "end": "1795200"
  },
  {
    "text": "so and those defaults come from uh that flag and where the hard code is",
    "start": "1795200",
    "end": "1801039"
  },
  {
    "text": "where so if you start a controller manager or 118 and you set the flag horizontal pod auto",
    "start": "1801039",
    "end": "1806559"
  },
  {
    "text": "scaling down scale stabilization equals 10 minutes and you create an hpa and you load it",
    "start": "1806559",
    "end": "1813679"
  },
  {
    "text": "and you get it back and you look at the value for behavior scale down stabilization window seconds",
    "start": "1813679",
    "end": "1821279"
  },
  {
    "text": "it will be 600 seconds but that just affects the default so all",
    "start": "1821279",
    "end": "1827120"
  },
  {
    "text": "the same behavior is is preserved for when you don't set the the",
    "start": "1827120",
    "end": "1832159"
  },
  {
    "text": "behaviors um if you do set it if you add a behavior and say",
    "start": "1832159",
    "end": "1837760"
  },
  {
    "text": "please you know use five minutes it will override the default which comes from that flag likewise for",
    "start": "1837760",
    "end": "1845279"
  },
  {
    "text": "the scale up uh limits which are 2x or a minimum of four",
    "start": "1845279",
    "end": "1852320"
  },
  {
    "text": "hope that answers that question let's see if there's any other",
    "start": "1852320",
    "end": "1857360"
  },
  {
    "text": "hpa questions",
    "start": "1857360",
    "end": "1860480"
  },
  {
    "text": "it here like the rest of them are class cluster auto scalar questions so at this point i'll hand it over to you magic",
    "start": "1863760",
    "end": "1870799"
  },
  {
    "text": "thanks joe so to answer a few classed auto scale questions uh one that",
    "start": "1871200",
    "end": "1877519"
  },
  {
    "text": "has shown a few times is if class delta scalar can be used on prem so in general all cast out",
    "start": "1877519",
    "end": "1883840"
  },
  {
    "text": "scalar really does is make a decision to add a new node but it needs something that",
    "start": "1883840",
    "end": "1891120"
  },
  {
    "text": "can actually create a vm so you need some sort of private cloud",
    "start": "1891120",
    "end": "1897279"
  },
  {
    "text": "setup and currently the supported ones is using openstack magnum and cluster api i think",
    "start": "1897279",
    "end": "1904880"
  },
  {
    "text": "both of those could be potentially used on them so there is a way to do it if",
    "start": "1904880",
    "end": "1911360"
  },
  {
    "text": "you if you have some underlying system that can add and remove nodes but class autoscaler cannot do it by",
    "start": "1911360",
    "end": "1918840"
  },
  {
    "text": "itself okay so another question is",
    "start": "1918840",
    "end": "1925600"
  },
  {
    "text": "why does the scheduler need the fake representation if you if we add a new node and why cannot it explicitly be",
    "start": "1925679",
    "end": "1933200"
  },
  {
    "text": "calculated how many nodes we need for the workload so this is because uh there are multiple different",
    "start": "1933200",
    "end": "1939679"
  },
  {
    "text": "requirements i try to illustrate that by using a node selector in example",
    "start": "1939679",
    "end": "1945039"
  },
  {
    "text": "but there is all sorts of different things with no selectors not affinities and so on",
    "start": "1945039",
    "end": "1951440"
  },
  {
    "text": "that i mentioned so class auto scale would need to know about all of this and basically they implement",
    "start": "1951440",
    "end": "1957679"
  },
  {
    "text": "all of the scheduling logic and then we would be forever chasing",
    "start": "1957679",
    "end": "1962799"
  },
  {
    "text": "scheduler and there would be quite a large risk uh that the two will sort of disagree leading to potential",
    "start": "1962799",
    "end": "1969120"
  },
  {
    "text": "errors which is why we try to just use scheduler code instead to just make sure",
    "start": "1969120",
    "end": "1975519"
  },
  {
    "text": "it's it's actually the same logic and that it's consistent um okay so another question is how",
    "start": "1975519",
    "end": "1982960"
  },
  {
    "text": "node selector get the value of new added node so as i mentioned a node group is",
    "start": "1982960",
    "end": "1988799"
  },
  {
    "text": "expected to be a set of identical nodes so basically when you have a node already in a given node group",
    "start": "1988799",
    "end": "1995360"
  },
  {
    "text": "cluster autoscaler will just copy it and assume the new node will be identical and that includes things like labels",
    "start": "1995360",
    "end": "2001440"
  },
  {
    "text": "basically everything there is also scale from zero logic available for some providers",
    "start": "2001440",
    "end": "2008159"
  },
  {
    "text": "and this is provided specific it tries to somehow guess how a node would look like as",
    "start": "2008159",
    "end": "2013760"
  },
  {
    "text": "accurately as possible including labels ideally so for example on gcp this is done by pulsing instance",
    "start": "2013760",
    "end": "2019919"
  },
  {
    "text": "template but other providers will have different implementations",
    "start": "2019919",
    "end": "2026080"
  },
  {
    "text": "um okay another question is uh",
    "start": "2026080",
    "end": "2034480"
  },
  {
    "text": "are there any plans to open up class autoscalers other frameworks can trigger uh scaling actions so this is uh",
    "start": "2034480",
    "end": "2042159"
  },
  {
    "text": "quite complex the the problem here is that classic autoscaler doesn't necessarily have much of a notion of an",
    "start": "2042159",
    "end": "2047679"
  },
  {
    "text": "action it's really just sort of reconciling cluster so there is always enough space to schedule",
    "start": "2047679",
    "end": "2053599"
  },
  {
    "text": "all parts and it's actually starting like it's basically simulating scheduling from",
    "start": "2053599",
    "end": "2059040"
  },
  {
    "text": "scratch every loop so even if you were to somehow make it add more notes the in in the very next loop it could",
    "start": "2059040",
    "end": "2066158"
  },
  {
    "text": "figure out that those notes are no longer needed it wouldn't remember that it added them",
    "start": "2066159",
    "end": "2071358"
  },
  {
    "text": "and it would go and delete those notes nodes however there are quite a few uh like",
    "start": "2071359",
    "end": "2077520"
  },
  {
    "text": "systems or in-home solutions that various people use",
    "start": "2077520",
    "end": "2083119"
  },
  {
    "text": "and the general idea is a scale up can be triggered by creating uh",
    "start": "2083440",
    "end": "2089520"
  },
  {
    "text": "low priority pots uh so those spots are basically enough that they just and pulse image",
    "start": "2089520",
    "end": "2096480"
  },
  {
    "text": "otherwise do nothing and they have a low scheduling priority so this is enough to trigger",
    "start": "2096480",
    "end": "2102320"
  },
  {
    "text": "a clustered autoscaler scale up but it's uh if a pod with a higher priority will be",
    "start": "2102320",
    "end": "2108960"
  },
  {
    "text": "created at the airport those spots will will be evicted by scheduler to make space for that other part and",
    "start": "2108960",
    "end": "2116320"
  },
  {
    "text": "that should be faster than adding a new node [Music] i think we've run out of time but",
    "start": "2116320",
    "end": "2124800"
  },
  {
    "text": "there is a slack channel where we'll continue answering the questions so thank you",
    "start": "2124800",
    "end": "2133920"
  }
]
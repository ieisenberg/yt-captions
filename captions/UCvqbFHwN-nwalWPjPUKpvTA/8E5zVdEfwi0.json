[
  {
    "text": "hello everyone hello nice to see you all",
    "start": "199",
    "end": "4480"
  },
  {
    "text": "Welcome to our talk this is reducing",
    "start": "4480",
    "end": "6799"
  },
  {
    "text": "cross Zone eress at Spotify with custom",
    "start": "6799",
    "end": "9480"
  },
  {
    "text": "grpc load balancing really long title my",
    "start": "9480",
    "end": "13160"
  },
  {
    "text": "team is here they're trying to get me to",
    "start": "13160",
    "end": "14799"
  },
  {
    "text": "say it in French I'm not even going to",
    "start": "14799",
    "end": "16920"
  },
  {
    "text": "attempt it and make a fool out of myself",
    "start": "16920",
    "end": "19800"
  },
  {
    "text": "here my name is Alex this is my",
    "start": "19800",
    "end": "22199"
  },
  {
    "text": "colleague",
    "start": "22199",
    "end": "23000"
  },
  {
    "text": "Yik we work at Spotify specifically the",
    "start": "23000",
    "end": "26279"
  },
  {
    "text": "computer networking uh departments our",
    "start": "26279",
    "end": "29480"
  },
  {
    "text": "team concerns itself with service",
    "start": "29480",
    "end": "31880"
  },
  {
    "text": "Discovery um we manage the protocols in",
    "start": "31880",
    "end": "34600"
  },
  {
    "text": "our backend to backend communication and",
    "start": "34600",
    "end": "36840"
  },
  {
    "text": "everything that comes with that",
    "start": "36840",
    "end": "39200"
  },
  {
    "text": "specifically uh one big concern is load",
    "start": "39200",
    "end": "41920"
  },
  {
    "text": "balancing everything around it and",
    "start": "41920",
    "end": "43840"
  },
  {
    "text": "that's why we're here today so in our",
    "start": "43840",
    "end": "45960"
  },
  {
    "text": "talk we'll start quite high level and",
    "start": "45960",
    "end": "48280"
  },
  {
    "text": "talk about load balancing in general H",
    "start": "48280",
    "end": "50760"
  },
  {
    "text": "why we do it what we care about and then",
    "start": "50760",
    "end": "53079"
  },
  {
    "text": "we'll dive deeper into exactly how we do",
    "start": "53079",
    "end": "55359"
  },
  {
    "text": "load balancing at Spotify what tradeoffs",
    "start": "55359",
    "end": "57719"
  },
  {
    "text": "we take and just how it works in general",
    "start": "57719",
    "end": "60320"
  },
  {
    "text": "so without further Ado the problem in a",
    "start": "60320",
    "end": "64720"
  },
  {
    "text": "microservice architecture the choice of",
    "start": "64720",
    "end": "66600"
  },
  {
    "text": "load balancing greatly impacts the",
    "start": "66600",
    "end": "68360"
  },
  {
    "text": "performance of the product what does",
    "start": "68360",
    "end": "70560"
  },
  {
    "text": "this mean so if we look at an",
    "start": "70560",
    "end": "73240"
  },
  {
    "text": "illustration here um a common load",
    "start": "73240",
    "end": "75759"
  },
  {
    "text": "balancing decision might look like this",
    "start": "75759",
    "end": "77360"
  },
  {
    "text": "there is a client it needs to speak to",
    "start": "77360",
    "end": "79479"
  },
  {
    "text": "some API to to get a response and build",
    "start": "79479",
    "end": "82000"
  },
  {
    "text": "the the package it wants to that API is",
    "start": "82000",
    "end": "85680"
  },
  {
    "text": "served by several servers uh so in this",
    "start": "85680",
    "end": "88400"
  },
  {
    "text": "case we have three instances uh and we",
    "start": "88400",
    "end": "90680"
  },
  {
    "text": "have to pick one right that's the choice",
    "start": "90680",
    "end": "92479"
  },
  {
    "text": "of flood balancing as humans we look at",
    "start": "92479",
    "end": "95799"
  },
  {
    "text": "this and we see that the first one is",
    "start": "95799",
    "end": "98079"
  },
  {
    "text": "fast the second one is slow the third",
    "start": "98079",
    "end": "100680"
  },
  {
    "text": "one's on Fire doesn't even work so",
    "start": "100680",
    "end": "103159"
  },
  {
    "text": "naturally we pick the first one so",
    "start": "103159",
    "end": "105560"
  },
  {
    "text": "implicitly we are optimizing for latency",
    "start": "105560",
    "end": "108560"
  },
  {
    "text": "error rates utilization various others",
    "start": "108560",
    "end": "111040"
  },
  {
    "text": "attributes that affect the product so in",
    "start": "111040",
    "end": "113600"
  },
  {
    "text": "the case of Spotify High latency means",
    "start": "113600",
    "end": "116039"
  },
  {
    "text": "slow playback error rates means you",
    "start": "116039",
    "end": "118159"
  },
  {
    "text": "can't see your playlist and Etc",
    "start": "118159",
    "end": "121840"
  },
  {
    "text": "now on a slightly higher level as a",
    "start": "123399",
    "end": "126240"
  },
  {
    "text": "business we're always optimizing for",
    "start": "126240",
    "end": "127960"
  },
  {
    "text": "cost right we need to spend less money",
    "start": "127960",
    "end": "130000"
  },
  {
    "text": "than we make in order to be profitable",
    "start": "130000",
    "end": "132560"
  },
  {
    "text": "and how we do load balancing affects",
    "start": "132560",
    "end": "134360"
  },
  {
    "text": "this cost uh in many ways and we're here",
    "start": "134360",
    "end": "137319"
  },
  {
    "text": "specifically to talk about the cost of",
    "start": "137319",
    "end": "139160"
  },
  {
    "text": "Crossing networking boundaries so again",
    "start": "139160",
    "end": "142280"
  },
  {
    "text": "what does that mean and I want to",
    "start": "142280",
    "end": "144400"
  },
  {
    "text": "apologize to all data center experts in",
    "start": "144400",
    "end": "146599"
  },
  {
    "text": "advance this is going to be very",
    "start": "146599",
    "end": "147879"
  },
  {
    "text": "handwavy how a cloud works but I think",
    "start": "147879",
    "end": "151200"
  },
  {
    "text": "it will get the point",
    "start": "151200",
    "end": "152720"
  },
  {
    "text": "across your favorite cloud provider",
    "start": "152720",
    "end": "155200"
  },
  {
    "text": "probably has a room that looks like this",
    "start": "155200",
    "end": "156959"
  },
  {
    "text": "a data center with a bunch of servers uh",
    "start": "156959",
    "end": "159400"
  },
  {
    "text": "hooked on to each",
    "start": "159400",
    "end": "161080"
  },
  {
    "text": "other to serve the needs of you know the",
    "start": "161080",
    "end": "164159"
  },
  {
    "text": "global apps we have and everything you",
    "start": "164159",
    "end": "166239"
  },
  {
    "text": "need more than one of these rooms right",
    "start": "166239",
    "end": "168440"
  },
  {
    "text": "so your cloud provider will have another",
    "start": "168440",
    "end": "170680"
  },
  {
    "text": "room the point we want to get across",
    "start": "170680",
    "end": "172840"
  },
  {
    "text": "here is that this is a room that's",
    "start": "172840",
    "end": "174440"
  },
  {
    "text": "physically close but not in the same",
    "start": "174440",
    "end": "176519"
  },
  {
    "text": "room so this might be a kilometer away",
    "start": "176519",
    "end": "178879"
  },
  {
    "text": "or it might be another floor in the same",
    "start": "178879",
    "end": "181840"
  },
  {
    "text": "building now at some point workloads are",
    "start": "181840",
    "end": "184519"
  },
  {
    "text": "going to communicate across these rooms",
    "start": "184519",
    "end": "186440"
  },
  {
    "text": "right so your C provider needs to",
    "start": "186440",
    "end": "188519"
  },
  {
    "text": "connect them to each other and that",
    "start": "188519",
    "end": "190480"
  },
  {
    "text": "looks like this so this is an accurate",
    "start": "190480",
    "end": "192879"
  },
  {
    "text": "illustration of our",
    "start": "192879",
    "end": "194840"
  },
  {
    "text": "clouds this cable is quite expensive so",
    "start": "194840",
    "end": "198319"
  },
  {
    "text": "this Cable is all the hardware you need",
    "start": "198319",
    "end": "200120"
  },
  {
    "text": "right Fiber Optic Cables separate power",
    "start": "200120",
    "end": "202519"
  },
  {
    "text": "supply and etc etc this costs money for",
    "start": "202519",
    "end": "206200"
  },
  {
    "text": "the cloud provider this is specialized",
    "start": "206200",
    "end": "207840"
  },
  {
    "text": "Hardware so they're going to charge us",
    "start": "207840",
    "end": "209799"
  },
  {
    "text": "for that if you look at the list prices",
    "start": "209799",
    "end": "212000"
  },
  {
    "text": "for all clouds you'll see things like",
    "start": "212000",
    "end": "213840"
  },
  {
    "text": "Network ESS and then new paper bite and",
    "start": "213840",
    "end": "217000"
  },
  {
    "text": "Etc so if we look at our load balancing",
    "start": "217000",
    "end": "219360"
  },
  {
    "text": "example again U slightly more realistic",
    "start": "219360",
    "end": "221959"
  },
  {
    "text": "we have the same client there's two",
    "start": "221959",
    "end": "223879"
  },
  {
    "text": "servers but the servers are separated",
    "start": "223879",
    "end": "226920"
  },
  {
    "text": "across two zones and zones here are",
    "start": "226920",
    "end": "229040"
  },
  {
    "text": "availability zones right separate rooms",
    "start": "229040",
    "end": "231080"
  },
  {
    "text": "in in our",
    "start": "231080",
    "end": "232920"
  },
  {
    "text": "Cloud if we discard the things we",
    "start": "232920",
    "end": "235200"
  },
  {
    "text": "mentioned in the beginning latency and",
    "start": "235200",
    "end": "236959"
  },
  {
    "text": "error rates of course we're optimizing",
    "start": "236959",
    "end": "238319"
  },
  {
    "text": "for that but here we can consider other",
    "start": "238319",
    "end": "240519"
  },
  {
    "text": "things as well we can do this keep all",
    "start": "240519",
    "end": "243599"
  },
  {
    "text": "the traffic in the same Zone and that's",
    "start": "243599",
    "end": "246200"
  },
  {
    "text": "going to be cheap we're not going to pay",
    "start": "246200",
    "end": "247560"
  },
  {
    "text": "for uh the the crossing of the network",
    "start": "247560",
    "end": "250720"
  },
  {
    "text": "boundary we can do this we pay for all",
    "start": "250720",
    "end": "253879"
  },
  {
    "text": "traffic uh we",
    "start": "253879",
    "end": "255519"
  },
  {
    "text": "send probably we want something like",
    "start": "255519",
    "end": "257880"
  },
  {
    "text": "this we want to send the majority of the",
    "start": "257880",
    "end": "260440"
  },
  {
    "text": "traffic in the same region but we want",
    "start": "260440",
    "end": "262479"
  },
  {
    "text": "to have some spill over to sorry the",
    "start": "262479",
    "end": "265520"
  },
  {
    "text": "same Zone to another Zone um in case of",
    "start": "265520",
    "end": "269840"
  },
  {
    "text": "in case of problems if something happens",
    "start": "269840",
    "end": "271680"
  },
  {
    "text": "right and this is expensive but it's",
    "start": "271680",
    "end": "274199"
  },
  {
    "text": "fair we can pay this price because this",
    "start": "274199",
    "end": "276680"
  },
  {
    "text": "can happen right your cloud provider can",
    "start": "276680",
    "end": "278600"
  },
  {
    "text": "have an issue you can cause issues",
    "start": "278600",
    "end": "280639"
  },
  {
    "text": "yourself you can bring down parts of",
    "start": "280639",
    "end": "282759"
  },
  {
    "text": "your uh infrastructure in the zone let's",
    "start": "282759",
    "end": "285600"
  },
  {
    "text": "say so at the scale of Spotify the cost",
    "start": "285600",
    "end": "289759"
  },
  {
    "text": "of Crossing networking boundaries is",
    "start": "289759",
    "end": "292120"
  },
  {
    "text": "significant thousands of microservices",
    "start": "292120",
    "end": "294600"
  },
  {
    "text": "many many pods talking to each other",
    "start": "294600",
    "end": "296360"
  },
  {
    "text": "this starts adding",
    "start": "296360",
    "end": "297680"
  },
  {
    "text": "up at some point we realiz I that it's",
    "start": "297680",
    "end": "300440"
  },
  {
    "text": "not only significant it's a majority for",
    "start": "300440",
    "end": "303600"
  },
  {
    "text": "traffic so 2third of our backend to back",
    "start": "303600",
    "end": "306360"
  },
  {
    "text": "in traffic were crossing expensive",
    "start": "306360",
    "end": "308520"
  },
  {
    "text": "networking",
    "start": "308520",
    "end": "309560"
  },
  {
    "text": "boundaries and now you might think oh",
    "start": "309560",
    "end": "311880"
  },
  {
    "text": "Spotify why are you doing this why are",
    "start": "311880",
    "end": "313639"
  },
  {
    "text": "you sending a majority of your traffic",
    "start": "313639",
    "end": "315440"
  },
  {
    "text": "across networking boundaries and there",
    "start": "315440",
    "end": "317479"
  },
  {
    "text": "is a logical explanation to this it's",
    "start": "317479",
    "end": "319280"
  },
  {
    "text": "not intentional but it's because how",
    "start": "319280",
    "end": "323800"
  },
  {
    "text": "things work in our setup so this is a",
    "start": "323800",
    "end": "327520"
  },
  {
    "text": "very common load balancing decision in",
    "start": "327520",
    "end": "329840"
  },
  {
    "text": "the Spotify back end given how we run",
    "start": "329840",
    "end": "332520"
  },
  {
    "text": "our clusters and our setup we have three",
    "start": "332520",
    "end": "334400"
  },
  {
    "text": "zones and the client again here has",
    "start": "334400",
    "end": "337000"
  },
  {
    "text": "three servers to pick from those servers",
    "start": "337000",
    "end": "339639"
  },
  {
    "text": "are separated across these these three",
    "start": "339639",
    "end": "343319"
  },
  {
    "text": "zones and we were talking about",
    "start": "343319",
    "end": "345199"
  },
  {
    "text": "latencies and error rates but it turns",
    "start": "345199",
    "end": "347560"
  },
  {
    "text": "out that in the majority of the cases",
    "start": "347560",
    "end": "349440"
  },
  {
    "text": "things are working well right High error",
    "start": "349440",
    "end": "351720"
  },
  {
    "text": "rates is the uncommon scenario so if we",
    "start": "351720",
    "end": "354360"
  },
  {
    "text": "squint and we zoom out things work",
    "start": "354360",
    "end": "356280"
  },
  {
    "text": "mostly",
    "start": "356280",
    "end": "357720"
  },
  {
    "text": "fine also that shady looking cable that",
    "start": "357720",
    "end": "361600"
  },
  {
    "text": "connected the data centers turns out",
    "start": "361600",
    "end": "364199"
  },
  {
    "text": "it's quite performant so there's not a",
    "start": "364199",
    "end": "366680"
  },
  {
    "text": "major latency hit when sending traffic",
    "start": "366680",
    "end": "368880"
  },
  {
    "text": "across availability zones and with these",
    "start": "368880",
    "end": "371880"
  },
  {
    "text": "two things in mind well what happens is",
    "start": "371880",
    "end": "373919"
  },
  {
    "text": "this there's a uniform distribution even",
    "start": "373919",
    "end": "376199"
  },
  {
    "text": "when we're optimizing for all these",
    "start": "376199",
    "end": "377680"
  },
  {
    "text": "things so 2third of our traffic uh is",
    "start": "377680",
    "end": "381160"
  },
  {
    "text": "crossing an expensive Network in",
    "start": "381160",
    "end": "383000"
  },
  {
    "text": "boundary and the question we asked",
    "start": "383000",
    "end": "385160"
  },
  {
    "text": "ourselves is how do we manage it how do",
    "start": "385160",
    "end": "387199"
  },
  {
    "text": "we manage this expensive cost we're",
    "start": "387199",
    "end": "389840"
  },
  {
    "text": "going to go into a deeper dive how our",
    "start": "389840",
    "end": "393080"
  },
  {
    "text": "custom load balancing algorithm works",
    "start": "393080",
    "end": "395039"
  },
  {
    "text": "and for that I'll hand it over to",
    "start": "395039",
    "end": "398000"
  },
  {
    "text": "Yani yes thank you Alex um so I'm going",
    "start": "398000",
    "end": "401680"
  },
  {
    "text": "to talk about how Spotify does client",
    "start": "401680",
    "end": "404440"
  },
  {
    "text": "side low balancing and how we actually",
    "start": "404440",
    "end": "407280"
  },
  {
    "text": "solve the problem of avoiding cross Zone",
    "start": "407280",
    "end": "410199"
  },
  {
    "text": "eras in our client side L Bing algorithm",
    "start": "410199",
    "end": "413560"
  },
  {
    "text": "so if you look at how our traffic",
    "start": "413560",
    "end": "416639"
  },
  {
    "text": "architecture kind of looks like we",
    "start": "416639",
    "end": "418919"
  },
  {
    "text": "mostly use grpc to communicate between",
    "start": "418919",
    "end": "421800"
  },
  {
    "text": "back ends and grpc already ships with uh",
    "start": "421800",
    "end": "426639"
  },
  {
    "text": "multiple choices of L balancing",
    "start": "426639",
    "end": "428360"
  },
  {
    "text": "algorithm so for example there's R Robin",
    "start": "428360",
    "end": "431000"
  },
  {
    "text": "which is pretty well known there's also",
    "start": "431000",
    "end": "432639"
  },
  {
    "text": "least request which you might want to",
    "start": "432639",
    "end": "434240"
  },
  {
    "text": "use but at Spotify for historic reasons",
    "start": "434240",
    "end": "437960"
  },
  {
    "text": "um we have built our own L Bing",
    "start": "437960",
    "end": "440360"
  },
  {
    "text": "algorithm and it has served us well for",
    "start": "440360",
    "end": "442280"
  },
  {
    "text": "many years so uh in the following I will",
    "start": "442280",
    "end": "446080"
  },
  {
    "text": "explain like the high level View and IDE",
    "start": "446080",
    "end": "449720"
  },
  {
    "text": "and design decisions that went into that",
    "start": "449720",
    "end": "451599"
  },
  {
    "text": "load balancing algorithm um because that",
    "start": "451599",
    "end": "454759"
  },
  {
    "text": "might be quite interesting uh I will",
    "start": "454759",
    "end": "457000"
  },
  {
    "text": "also then share how we integrated this",
    "start": "457000",
    "end": "459400"
  },
  {
    "text": "new decision that we want to avoid cross",
    "start": "459400",
    "end": "461759"
  },
  {
    "text": "Zone Eris and uh I'm especially going to",
    "start": "461759",
    "end": "465800"
  },
  {
    "text": "focus on the fact that uh you can easily",
    "start": "465800",
    "end": "469000"
  },
  {
    "text": "build your own L balancing algorithms if",
    "start": "469000",
    "end": "471000"
  },
  {
    "text": "you use GPC and you can make like your",
    "start": "471000",
    "end": "474159"
  },
  {
    "text": "customers which is probably your",
    "start": "474159",
    "end": "475639"
  },
  {
    "text": "developers use these algorithms and",
    "start": "475639",
    "end": "478319"
  },
  {
    "text": "optimize them for your specific uh",
    "start": "478319",
    "end": "480440"
  },
  {
    "text": "business need so hopefully the following",
    "start": "480440",
    "end": "482919"
  },
  {
    "text": "slides might inspire you to explore this",
    "start": "482919",
    "end": "485400"
  },
  {
    "text": "option within GPC",
    "start": "485400",
    "end": "487400"
  },
  {
    "text": "itself so first let's talk about design",
    "start": "487400",
    "end": "491120"
  },
  {
    "text": "decisions that go into a Lo baning",
    "start": "491120",
    "end": "493000"
  },
  {
    "text": "algorithm how would you approach",
    "start": "493000",
    "end": "494280"
  },
  {
    "text": "building one well at Spotify um we might",
    "start": "494280",
    "end": "498560"
  },
  {
    "text": "or the first design decision we might",
    "start": "498560",
    "end": "500159"
  },
  {
    "text": "want to consider is how should the load",
    "start": "500159",
    "end": "502120"
  },
  {
    "text": "balancing algorithm behave if everything",
    "start": "502120",
    "end": "504800"
  },
  {
    "text": "works great right so if servers are",
    "start": "504800",
    "end": "507479"
  },
  {
    "text": "equally utilized if they there's not a",
    "start": "507479",
    "end": "510960"
  },
  {
    "text": "big error rate anywhere but everything",
    "start": "510960",
    "end": "514039"
  },
  {
    "text": "works nice in that case we might want to",
    "start": "514039",
    "end": "517080"
  },
  {
    "text": "always pick the fastest server right so",
    "start": "517080",
    "end": "520080"
  },
  {
    "text": "we want to optimize for very low latency",
    "start": "520080",
    "end": "522839"
  },
  {
    "text": "because especially in Long Core chains",
    "start": "522839",
    "end": "525480"
  },
  {
    "text": "latency will add up so the client",
    "start": "525480",
    "end": "528480"
  },
  {
    "text": "experience greatly depends on uh",
    "start": "528480",
    "end": "531760"
  },
  {
    "text": "choosing low latency so for the healthy",
    "start": "531760",
    "end": "534800"
  },
  {
    "text": "State it's quite easy just use the lows",
    "start": "534800",
    "end": "537120"
  },
  {
    "text": "latency end point um depending on what",
    "start": "537120",
    "end": "540519"
  },
  {
    "text": "you measured in the past for example so",
    "start": "540519",
    "end": "543760"
  },
  {
    "text": "what happens if you introduce errors and",
    "start": "543760",
    "end": "545920"
  },
  {
    "text": "I want to stress this point because",
    "start": "545920",
    "end": "549200"
  },
  {
    "text": "maybe that's the one that mostly",
    "start": "549200",
    "end": "551440"
  },
  {
    "text": "distinguish the Spotify L balancing",
    "start": "551440",
    "end": "553800"
  },
  {
    "text": "algorithm from the other choices that",
    "start": "553800",
    "end": "556120"
  },
  {
    "text": "you have with in GPC itself and that is",
    "start": "556120",
    "end": "559959"
  },
  {
    "text": "uh you want to as where as you encounter",
    "start": "559959",
    "end": "563440"
  },
  {
    "text": "errors in your backend Fleet we want to",
    "start": "563440",
    "end": "565360"
  },
  {
    "text": "propagate those errors very quickly so",
    "start": "565360",
    "end": "567440"
  },
  {
    "text": "we want to send them very quickly to",
    "start": "567440",
    "end": "569040"
  },
  {
    "text": "these Spotify client so it can retry",
    "start": "569040",
    "end": "571600"
  },
  {
    "text": "them actually um we want to do that",
    "start": "571600",
    "end": "574600"
  },
  {
    "text": "because uh if we propagate the error",
    "start": "574600",
    "end": "576480"
  },
  {
    "text": "very fast so we fail fast uh we can",
    "start": "576480",
    "end": "579519"
  },
  {
    "text": "basically",
    "start": "579519",
    "end": "581079"
  },
  {
    "text": "uh don't expose the error to the user at",
    "start": "581079",
    "end": "583880"
  },
  {
    "text": "all like you add a s you to your",
    "start": "583880",
    "end": "585640"
  },
  {
    "text": "playlist that might fail but if we retry",
    "start": "585640",
    "end": "587760"
  },
  {
    "text": "quickly enough you won't notice right so",
    "start": "587760",
    "end": "591320"
  },
  {
    "text": "uh considering this design decision we",
    "start": "591320",
    "end": "593920"
  },
  {
    "text": "would want to have a load balancer that",
    "start": "593920",
    "end": "596360"
  },
  {
    "text": "in case of a high error rate in your",
    "start": "596360",
    "end": "598000"
  },
  {
    "text": "backend Fleet would actually fail fast",
    "start": "598000",
    "end": "600279"
  },
  {
    "text": "instead of failing slow so it should",
    "start": "600279",
    "end": "602279"
  },
  {
    "text": "account for that and the last decision I",
    "start": "602279",
    "end": "605880"
  },
  {
    "text": "want to talk about is uh the one that",
    "start": "605880",
    "end": "608240"
  },
  {
    "text": "Alex already alluded to and that is we",
    "start": "608240",
    "end": "610640"
  },
  {
    "text": "want to avoid sending traffic across",
    "start": "610640",
    "end": "612800"
  },
  {
    "text": "zones right if we have to choice between",
    "start": "612800",
    "end": "615240"
  },
  {
    "text": "two servers one is in the same Zone and",
    "start": "615240",
    "end": "617600"
  },
  {
    "text": "one is in a different Zone we probably",
    "start": "617600",
    "end": "619519"
  },
  {
    "text": "want to choose the one in the same Zone",
    "start": "619519",
    "end": "621760"
  },
  {
    "text": "however there might be cases where we",
    "start": "621760",
    "end": "623480"
  },
  {
    "text": "would prefer to send the traffic across",
    "start": "623480",
    "end": "625600"
  },
  {
    "text": "zones and those cases are where we see a",
    "start": "625600",
    "end": "628800"
  },
  {
    "text": "benefit of of paying that fee because we",
    "start": "628800",
    "end": "631480"
  },
  {
    "text": "would for example uh serve a successful",
    "start": "631480",
    "end": "635160"
  },
  {
    "text": "response instead of a failing response",
    "start": "635160",
    "end": "636920"
  },
  {
    "text": "or the latency would be much quicker so",
    "start": "636920",
    "end": "639320"
  },
  {
    "text": "our loot balancer should account for",
    "start": "639320",
    "end": "641160"
  },
  {
    "text": "that now these high level design",
    "start": "641160",
    "end": "644120"
  },
  {
    "text": "decisions how do we put them into a",
    "start": "644120",
    "end": "646360"
  },
  {
    "text": "working algorithm and the Spotify",
    "start": "646360",
    "end": "649560"
  },
  {
    "text": "solution to that was we introduce or we",
    "start": "649560",
    "end": "652279"
  },
  {
    "text": "use a concept that we call expected",
    "start": "652279",
    "end": "654519"
  },
  {
    "text": "latency and what expected latency",
    "start": "654519",
    "end": "657079"
  },
  {
    "text": "basically just refers to is the for",
    "start": "657079",
    "end": "659600"
  },
  {
    "text": "every server that you can choose as the",
    "start": "659600",
    "end": "661399"
  },
  {
    "text": "client you want to calculate what you",
    "start": "661399",
    "end": "664360"
  },
  {
    "text": "expect the latency of a successful",
    "start": "664360",
    "end": "667040"
  },
  {
    "text": "response to be so assuming you can",
    "start": "667040",
    "end": "670480"
  },
  {
    "text": "calculate that on past measurements you",
    "start": "670480",
    "end": "672760"
  },
  {
    "text": "can make a very accurate and good low",
    "start": "672760",
    "end": "675560"
  },
  {
    "text": "balancing decision with high probability",
    "start": "675560",
    "end": "678279"
  },
  {
    "text": "because you can pick the server that has",
    "start": "678279",
    "end": "680480"
  },
  {
    "text": "the lowest expected",
    "start": "680480",
    "end": "682639"
  },
  {
    "text": "latency so this sounds quite tricky how",
    "start": "682639",
    "end": "685279"
  },
  {
    "text": "do we actually calculate the expected",
    "start": "685279",
    "end": "687200"
  },
  {
    "text": "latency and how do we",
    "start": "687200",
    "end": "690120"
  },
  {
    "text": "uh measure all these things that we need",
    "start": "690120",
    "end": "692440"
  },
  {
    "text": "for it so uh let's build up step by step",
    "start": "692440",
    "end": "695680"
  },
  {
    "text": "right so let's Zoom back a bit and",
    "start": "695680",
    "end": "698720"
  },
  {
    "text": "consider again this very simple scenario",
    "start": "698720",
    "end": "701880"
  },
  {
    "text": "of not having any failures in our back",
    "start": "701880",
    "end": "704279"
  },
  {
    "text": "end then if you look at the expected",
    "start": "704279",
    "end": "707040"
  },
  {
    "text": "latency",
    "start": "707040",
    "end": "708680"
  },
  {
    "text": "intuitively you can basically observe",
    "start": "708680",
    "end": "711000"
  },
  {
    "text": "that it it's probably dominated by the",
    "start": "711000",
    "end": "712839"
  },
  {
    "text": "fact that you need to send a request and",
    "start": "712839",
    "end": "715079"
  },
  {
    "text": "you need to wait for the response and",
    "start": "715079",
    "end": "717120"
  },
  {
    "text": "there's also probably some load on the",
    "start": "717120",
    "end": "718760"
  },
  {
    "text": "server already so the server needs to",
    "start": "718760",
    "end": "720800"
  },
  {
    "text": "take has some work to do before it can",
    "start": "720800",
    "end": "723320"
  },
  {
    "text": "get to request or finish sending it out",
    "start": "723320",
    "end": "726519"
  },
  {
    "text": "so if we put that into a formula that",
    "start": "726519",
    "end": "729040"
  },
  {
    "text": "models this observation we arrive at",
    "start": "729040",
    "end": "732560"
  },
  {
    "text": "something like the expected latency",
    "start": "732560",
    "end": "734839"
  },
  {
    "text": "under a scenario where you don't",
    "start": "734839",
    "end": "736800"
  },
  {
    "text": "encounter any failures is the network",
    "start": "736800",
    "end": "739199"
  },
  {
    "text": "latency is all the time between sending",
    "start": "739199",
    "end": "740959"
  },
  {
    "text": "the request and receiving the successful",
    "start": "740959",
    "end": "743199"
  },
  {
    "text": "response times the size of the queue of",
    "start": "743199",
    "end": "746760"
  },
  {
    "text": "the server and that is because in model",
    "start": "746760",
    "end": "749800"
  },
  {
    "text": "the server would need to process the",
    "start": "749800",
    "end": "751199"
  },
  {
    "text": "whole que send out a response for each",
    "start": "751199",
    "end": "753560"
  },
  {
    "text": "so account for the latency of each and",
    "start": "753560",
    "end": "756199"
  },
  {
    "text": "then eventually the plus one is our",
    "start": "756199",
    "end": "758279"
  },
  {
    "text": "request that we expect so assuming the",
    "start": "758279",
    "end": "761920"
  },
  {
    "text": "client measures uh the Q size it has uh",
    "start": "761920",
    "end": "765920"
  },
  {
    "text": "for the specific server so the amount of",
    "start": "765920",
    "end": "768880"
  },
  {
    "text": "outstanding requests and it measures",
    "start": "768880",
    "end": "770839"
  },
  {
    "text": "based on P's experience how quickly the",
    "start": "770839",
    "end": "772920"
  },
  {
    "text": "server successfully responded it can",
    "start": "772920",
    "end": "775519"
  },
  {
    "text": "calculate that expected latency quite",
    "start": "775519",
    "end": "778120"
  },
  {
    "text": "easily",
    "start": "778120",
    "end": "779800"
  },
  {
    "text": "now let's introduce failures and see how",
    "start": "779800",
    "end": "783240"
  },
  {
    "text": "we can integrate that into this formula",
    "start": "783240",
    "end": "785399"
  },
  {
    "text": "and notion of expected latency consider",
    "start": "785399",
    "end": "788399"
  },
  {
    "text": "that we sent a request to some server",
    "start": "788399",
    "end": "790959"
  },
  {
    "text": "and that server might have an observed",
    "start": "790959",
    "end": "793760"
  },
  {
    "text": "success ratio of 50% So based on past",
    "start": "793760",
    "end": "797440"
  },
  {
    "text": "experience we notice that the server",
    "start": "797440",
    "end": "799120"
  },
  {
    "text": "fails half of the time now the first",
    "start": "799120",
    "end": "802240"
  },
  {
    "text": "request will then also fail with a",
    "start": "802240",
    "end": "804639"
  },
  {
    "text": "probability of 50% but we've talked",
    "start": "804639",
    "end": "807279"
  },
  {
    "text": "about that we would directly retry this",
    "start": "807279",
    "end": "809160"
  },
  {
    "text": "the request right",
    "start": "809160",
    "end": "811040"
  },
  {
    "text": "so then when do we get actually a",
    "start": "811040",
    "end": "813839"
  },
  {
    "text": "successful response uh under the model",
    "start": "813839",
    "end": "816639"
  },
  {
    "text": "that the server fails with a 50%",
    "start": "816639",
    "end": "818560"
  },
  {
    "text": "probability well the probability of the",
    "start": "818560",
    "end": "821320"
  },
  {
    "text": "retrying request also failing and none",
    "start": "821320",
    "end": "823360"
  },
  {
    "text": "of them returning a successful response",
    "start": "823360",
    "end": "825560"
  },
  {
    "text": "is one over four so if you continue that",
    "start": "825560",
    "end": "828320"
  },
  {
    "text": "we can actually calculate the expected",
    "start": "828320",
    "end": "830079"
  },
  {
    "text": "number of retries that we need to do and",
    "start": "830079",
    "end": "832519"
  },
  {
    "text": "if we arrive that the expected number of",
    "start": "832519",
    "end": "834759"
  },
  {
    "text": "retri will be one over the success ratio",
    "start": "834759",
    "end": "837759"
  },
  {
    "text": "in this case it's two",
    "start": "837759",
    "end": "839920"
  },
  {
    "text": "so what this adds to our expected",
    "start": "839920",
    "end": "843000"
  },
  {
    "text": "latency notion is basically we will uh",
    "start": "843000",
    "end": "847399"
  },
  {
    "text": "also additionally need to account for",
    "start": "847399",
    "end": "849639"
  },
  {
    "text": "the fact that we will have to do some",
    "start": "849639",
    "end": "851639"
  },
  {
    "text": "retries and it takes some time until we",
    "start": "851639",
    "end": "853880"
  },
  {
    "text": "notice that there was actually failure",
    "start": "853880",
    "end": "856279"
  },
  {
    "text": "so if we add this to our formula we kind",
    "start": "856279",
    "end": "858519"
  },
  {
    "text": "of arrive at this right so uh we have",
    "start": "858519",
    "end": "861480"
  },
  {
    "text": "this success latency then we also have",
    "start": "861480",
    "end": "863720"
  },
  {
    "text": "the uh number of retri that we need to",
    "start": "863720",
    "end": "866600"
  },
  {
    "text": "account for and then we have integrated",
    "start": "866600",
    "end": "868399"
  },
  {
    "text": "that with with the amount of work that's",
    "start": "868399",
    "end": "870560"
  },
  {
    "text": "currently on the",
    "start": "870560",
    "end": "872000"
  },
  {
    "text": "server now that's already a very",
    "start": "872000",
    "end": "874320"
  },
  {
    "text": "sophisticated measurement that you can",
    "start": "874320",
    "end": "876160"
  },
  {
    "text": "use in your L balancing decision because",
    "start": "876160",
    "end": "878399"
  },
  {
    "text": "if you calculate it for every server you",
    "start": "878399",
    "end": "880680"
  },
  {
    "text": "can basically yeah you basically assign",
    "start": "880680",
    "end": "883240"
  },
  {
    "text": "a weight to each server and then you",
    "start": "883240",
    "end": "884800"
  },
  {
    "text": "just pick the server with the highest",
    "start": "884800",
    "end": "886800"
  },
  {
    "text": "weight now the last part that we wanted",
    "start": "886800",
    "end": "890839"
  },
  {
    "text": "to talk about and on we wanted to",
    "start": "890839",
    "end": "892720"
  },
  {
    "text": "integrate into our load balancing",
    "start": "892720",
    "end": "895519"
  },
  {
    "text": "decision and therefore formula is the",
    "start": "895519",
    "end": "897920"
  },
  {
    "text": "notion of avoiding cross Zone Eris which",
    "start": "897920",
    "end": "900959"
  },
  {
    "text": "is also the topic of our talk so how are",
    "start": "900959",
    "end": "903519"
  },
  {
    "text": "we going to do that right so that's",
    "start": "903519",
    "end": "906079"
  },
  {
    "text": "again consider the design decision that",
    "start": "906079",
    "end": "909240"
  },
  {
    "text": "we need to take and that is",
    "start": "909240",
    "end": "912160"
  },
  {
    "text": "um in cases where like the server in the",
    "start": "912160",
    "end": "915720"
  },
  {
    "text": "same Zone and the or the servers in the",
    "start": "915720",
    "end": "918600"
  },
  {
    "text": "other Zone that's not the same Zone as a",
    "start": "918600",
    "end": "920639"
  },
  {
    "text": "client would behave very similar so they",
    "start": "920639",
    "end": "923120"
  },
  {
    "text": "have similar success latency similar",
    "start": "923120",
    "end": "925839"
  },
  {
    "text": "utilization we want to pick the one in",
    "start": "925839",
    "end": "928399"
  },
  {
    "text": "the same Zone",
    "start": "928399",
    "end": "929920"
  },
  {
    "text": "however for example if that latency of",
    "start": "929920",
    "end": "932839"
  },
  {
    "text": "the same Zone server is 10 times higher",
    "start": "932839",
    "end": "935440"
  },
  {
    "text": "than one in the cross Zone well that's a",
    "start": "935440",
    "end": "938319"
  },
  {
    "text": "good reason to actually pay some money",
    "start": "938319",
    "end": "940120"
  },
  {
    "text": "and send it traffic across zones right",
    "start": "940120",
    "end": "942560"
  },
  {
    "text": "because we will improve user",
    "start": "942560",
    "end": "944839"
  },
  {
    "text": "experience so how to integrate this well",
    "start": "944839",
    "end": "947600"
  },
  {
    "text": "the idea is quite simple and that's also",
    "start": "947600",
    "end": "951880"
  },
  {
    "text": "like the the cool thing or the result of",
    "start": "951880",
    "end": "954040"
  },
  {
    "text": "this talk it's very simple to kind of",
    "start": "954040",
    "end": "956480"
  },
  {
    "text": "make this decision and uh hor basically",
    "start": "956480",
    "end": "959399"
  },
  {
    "text": "integrate them into your L balancing",
    "start": "959399",
    "end": "961199"
  },
  {
    "text": "decision so the idea would be let's just",
    "start": "961199",
    "end": "963839"
  },
  {
    "text": "make the expected latency of cross on",
    "start": "963839",
    "end": "965959"
  },
  {
    "text": "handp points a bit higher than those of",
    "start": "965959",
    "end": "968680"
  },
  {
    "text": "same Zone endpoints and now basically by",
    "start": "968680",
    "end": "972120"
  },
  {
    "text": "doing this in a hardc or in a constant",
    "start": "972120",
    "end": "974519"
  },
  {
    "text": "way we Define a threshold when we want",
    "start": "974519",
    "end": "976720"
  },
  {
    "text": "to tip over right and what we run with",
    "start": "976720",
    "end": "980360"
  },
  {
    "text": "currently is we say that the expected",
    "start": "980360",
    "end": "983639"
  },
  {
    "text": "latency of a cross Zone ire should be",
    "start": "983639",
    "end": "986279"
  },
  {
    "text": "considered 10 times higher than those of",
    "start": "986279",
    "end": "988040"
  },
  {
    "text": "the same Zone end point and what this",
    "start": "988040",
    "end": "990319"
  },
  {
    "text": "means is as the image just showed if the",
    "start": "990319",
    "end": "993440"
  },
  {
    "text": "crossone endpoint has a 10 times lower",
    "start": "993440",
    "end": "995240"
  },
  {
    "text": "latency than the same Zone endpoint we",
    "start": "995240",
    "end": "997240"
  },
  {
    "text": "probably want to prefer the crossone",
    "start": "997240",
    "end": "998959"
  },
  {
    "text": "endpoint and by also having all this",
    "start": "998959",
    "end": "1002560"
  },
  {
    "text": "cool things in the formula like uh",
    "start": "1002560",
    "end": "1005000"
  },
  {
    "text": "failure rate and and the Q size so",
    "start": "1005000",
    "end": "1009440"
  },
  {
    "text": "utilization uh we",
    "start": "1009440",
    "end": "1011720"
  },
  {
    "text": "basically allow the fail over for all of",
    "start": "1011720",
    "end": "1014440"
  },
  {
    "text": "these parameters",
    "start": "1014440",
    "end": "1016319"
  },
  {
    "text": "right um so yeah we're kind of just",
    "start": "1016319",
    "end": "1019519"
  },
  {
    "text": "doing this so this is a very uh maybe",
    "start": "1019519",
    "end": "1022880"
  },
  {
    "text": "boring realization but it's also a very",
    "start": "1022880",
    "end": "1025079"
  },
  {
    "text": "simple approach that has a lot of",
    "start": "1025079",
    "end": "1026720"
  },
  {
    "text": "advantages because you can very quickly",
    "start": "1026720",
    "end": "1029199"
  },
  {
    "text": "iterate on it right you can fine-tune",
    "start": "1029199",
    "end": "1032000"
  },
  {
    "text": "this threshold to your needs so if you",
    "start": "1032000",
    "end": "1033959"
  },
  {
    "text": "want to avoid a lot of cross on traffic",
    "start": "1033959",
    "end": "1036319"
  },
  {
    "text": "and you're fine with then accepting High",
    "start": "1036319",
    "end": "1039280"
  },
  {
    "text": "latency in certain cases you can choose",
    "start": "1039280",
    "end": "1041558"
  },
  {
    "text": "a much higher penalty so it's kind of",
    "start": "1041559",
    "end": "1044600"
  },
  {
    "text": "nice that this solution is very flexible",
    "start": "1044600",
    "end": "1047240"
  },
  {
    "text": "so while it might seem simple",
    "start": "1047240",
    "end": "1049600"
  },
  {
    "text": "it's actually uh it's kind of well",
    "start": "1049600",
    "end": "1052080"
  },
  {
    "text": "thought out um so I want to give a shout",
    "start": "1052080",
    "end": "1056039"
  },
  {
    "text": "out to uh the maintainance of GPC",
    "start": "1056039",
    "end": "1058600"
  },
  {
    "text": "because they enable us to do these",
    "start": "1058600",
    "end": "1061400"
  },
  {
    "text": "things so as I said they enable you to",
    "start": "1061400",
    "end": "1063600"
  },
  {
    "text": "build your own load balancing algorithm",
    "start": "1063600",
    "end": "1065280"
  },
  {
    "text": "and I encourage you to take a look at",
    "start": "1065280",
    "end": "1067480"
  },
  {
    "text": "the open source implementation and kind",
    "start": "1067480",
    "end": "1069240"
  },
  {
    "text": "of get inspired by them and they also",
    "start": "1069240",
    "end": "1072320"
  },
  {
    "text": "offer some very cool features like Orca",
    "start": "1072320",
    "end": "1075120"
  },
  {
    "text": "you might have heard of about it but",
    "start": "1075120",
    "end": "1076960"
  },
  {
    "text": "Orca essentially is just some grpc",
    "start": "1076960",
    "end": "1079919"
  },
  {
    "text": "streaming connection that sits on top",
    "start": "1079919",
    "end": "1082280"
  },
  {
    "text": "the already established http2 stream",
    "start": "1082280",
    "end": "1085240"
  },
  {
    "text": "between the client and all the available",
    "start": "1085240",
    "end": "1087520"
  },
  {
    "text": "servers and it allows you to very easily",
    "start": "1087520",
    "end": "1090840"
  },
  {
    "text": "exchange loow balancing algorithm over",
    "start": "1090840",
    "end": "1092919"
  },
  {
    "text": "that stream so what we use it for is",
    "start": "1092919",
    "end": "1095919"
  },
  {
    "text": "that the client learns lazily about the",
    "start": "1095919",
    "end": "1098679"
  },
  {
    "text": "zones of each server and then can adapt",
    "start": "1098679",
    "end": "1101440"
  },
  {
    "text": "the expected latency of each server but",
    "start": "1101440",
    "end": "1103840"
  },
  {
    "text": "you can use it for other things as well",
    "start": "1103840",
    "end": "1106200"
  },
  {
    "text": "right you can get a better insight what",
    "start": "1106200",
    "end": "1109159"
  },
  {
    "text": "is actually the utilization of that",
    "start": "1109159",
    "end": "1110880"
  },
  {
    "text": "server and then incorporate that into",
    "start": "1110880",
    "end": "1113080"
  },
  {
    "text": "your Lo balancing decision so it's a",
    "start": "1113080",
    "end": "1115000"
  },
  {
    "text": "very flexible framework and it's very",
    "start": "1115000",
    "end": "1117679"
  },
  {
    "text": "cool so you should look into it if you",
    "start": "1117679",
    "end": "1120120"
  },
  {
    "text": "are interested in that topic um now for",
    "start": "1120120",
    "end": "1123559"
  },
  {
    "text": "the results I'd like to share like Alex",
    "start": "1123559",
    "end": "1125799"
  },
  {
    "text": "already explained that before making",
    "start": "1125799",
    "end": "1129679"
  },
  {
    "text": "this change we were kind of sitting at",
    "start": "1129679",
    "end": "1132360"
  },
  {
    "text": "two3 of our traffic Crossing Network",
    "start": "1132360",
    "end": "1134640"
  },
  {
    "text": "boundaries which was not great and just",
    "start": "1134640",
    "end": "1137360"
  },
  {
    "text": "by making this very simple change like",
    "start": "1137360",
    "end": "1139280"
  },
  {
    "text": "penalizing crossone traffic in our",
    "start": "1139280",
    "end": "1141480"
  },
  {
    "text": "formula we went down to 30% crossone",
    "start": "1141480",
    "end": "1144760"
  },
  {
    "text": "traffic um so while I must admit this is",
    "start": "1144760",
    "end": "1149240"
  },
  {
    "text": "probably not a perfect solution and you",
    "start": "1149240",
    "end": "1151720"
  },
  {
    "text": "can aim for much lower crossone traffic",
    "start": "1151720",
    "end": "1154600"
  },
  {
    "text": "with the right tools um it is very",
    "start": "1154600",
    "end": "1157840"
  },
  {
    "text": "simple so it's easy to understand while",
    "start": "1157840",
    "end": "1160640"
  },
  {
    "text": "if you aim for very low crossone traffic",
    "start": "1160640",
    "end": "1162960"
  },
  {
    "text": "you need to account for number of edge",
    "start": "1162960",
    "end": "1165200"
  },
  {
    "text": "cases for example very heavy zon skew by",
    "start": "1165200",
    "end": "1168919"
  },
  {
    "text": "which I mean like the number of clients",
    "start": "1168919",
    "end": "1171200"
  },
  {
    "text": "and number of servers might be very",
    "start": "1171200",
    "end": "1173480"
  },
  {
    "text": "imbalanced between zones so if you",
    "start": "1173480",
    "end": "1175440"
  },
  {
    "text": "prefer same don't traffic too much you",
    "start": "1175440",
    "end": "1177720"
  },
  {
    "text": "might risk the reliability of your whole",
    "start": "1177720",
    "end": "1180320"
  },
  {
    "text": "back end and at the scale of Spotify",
    "start": "1180320",
    "end": "1182960"
  },
  {
    "text": "this is a very difficult trade off to",
    "start": "1182960",
    "end": "1185320"
  },
  {
    "text": "make so we very happy with uh this kind",
    "start": "1185320",
    "end": "1188880"
  },
  {
    "text": "of simple solution as it already gave us",
    "start": "1188880",
    "end": "1191919"
  },
  {
    "text": "great results and with that I hand it",
    "start": "1191919",
    "end": "1194120"
  },
  {
    "text": "back to Alex to conclude the",
    "start": "1194120",
    "end": "1197480"
  },
  {
    "text": "talk okay okay so before we end we just",
    "start": "1197480",
    "end": "1199960"
  },
  {
    "text": "want to um give you some of the",
    "start": "1199960",
    "end": "1201880"
  },
  {
    "text": "learnings we had doing all of this as",
    "start": "1201880",
    "end": "1204919"
  },
  {
    "text": "Yanik alluded to we want to shout out",
    "start": "1204919",
    "end": "1206720"
  },
  {
    "text": "grpc and other cncf Technologies H it",
    "start": "1206720",
    "end": "1209559"
  },
  {
    "text": "allows us all to iterate faster uh the",
    "start": "1209559",
    "end": "1211960"
  },
  {
    "text": "community is solving many of the same",
    "start": "1211960",
    "end": "1213760"
  },
  {
    "text": "problems and by doing this we help each",
    "start": "1213760",
    "end": "1215360"
  },
  {
    "text": "other so a big shout out there we also",
    "start": "1215360",
    "end": "1218159"
  },
  {
    "text": "want to add that as platform or",
    "start": "1218159",
    "end": "1220200"
  },
  {
    "text": "infrastructure teams uh we sometimes",
    "start": "1220200",
    "end": "1222280"
  },
  {
    "text": "struggle to see how we uh affect the end",
    "start": "1222280",
    "end": "1225880"
  },
  {
    "text": "product right and and this is a problem",
    "start": "1225880",
    "end": "1227960"
  },
  {
    "text": "where we directly touch on Topline",
    "start": "1227960",
    "end": "1229919"
  },
  {
    "text": "business metrics by looking at some",
    "start": "1229919",
    "end": "1232440"
  },
  {
    "text": "quite nerdy things but it does work and",
    "start": "1232440",
    "end": "1235559"
  },
  {
    "text": "finally uh the message we want to end",
    "start": "1235559",
    "end": "1238559"
  },
  {
    "text": "with is aim for good enough so we the",
    "start": "1238559",
    "end": "1243159"
  },
  {
    "text": "the short summary of this talk is we",
    "start": "1243159",
    "end": "1245480"
  },
  {
    "text": "multiplied The Weight by 10 in our",
    "start": "1245480",
    "end": "1247320"
  },
  {
    "text": "algorithm and then it worked U we spent",
    "start": "1247320",
    "end": "1249960"
  },
  {
    "text": "a lot of time over complicating this and",
    "start": "1249960",
    "end": "1252440"
  },
  {
    "text": "trying to reach that lead line in",
    "start": "1252440",
    "end": "1254520"
  },
  {
    "text": "janik's graph uh but as the saying goes",
    "start": "1254520",
    "end": "1257919"
  },
  {
    "text": "Perfection is is the enemy of progress",
    "start": "1257919",
    "end": "1259840"
  },
  {
    "text": "so aim for good enough and then iterate",
    "start": "1259840",
    "end": "1262200"
  },
  {
    "text": "thank you all for listening if you have",
    "start": "1262200",
    "end": "1264120"
  },
  {
    "text": "any questions we're",
    "start": "1264120",
    "end": "1265260"
  },
  {
    "text": "[Applause]",
    "start": "1265260",
    "end": "1273000"
  },
  {
    "text": "here we are open for questions uh and we",
    "start": "1273000",
    "end": "1276000"
  },
  {
    "text": "have a bunch of spotifi here as well so",
    "start": "1276000",
    "end": "1277760"
  },
  {
    "text": "if you have questions afterwards feel",
    "start": "1277760",
    "end": "1279080"
  },
  {
    "text": "free to approach them as well I think",
    "start": "1279080",
    "end": "1281360"
  },
  {
    "text": "there's a microphone over there in the",
    "start": "1281360",
    "end": "1284080"
  },
  {
    "text": "middle of the",
    "start": "1284080",
    "end": "1287120"
  },
  {
    "text": "hallway",
    "start": "1287520",
    "end": "1289919"
  },
  {
    "text": "one to thanks for the talk you just",
    "start": "1289919",
    "end": "1293520"
  },
  {
    "text": "cratch about orca and so I was wondering",
    "start": "1293520",
    "end": "1296559"
  },
  {
    "text": "what language you use for the",
    "start": "1296559",
    "end": "1298159"
  },
  {
    "text": "implementation and how and why you used",
    "start": "1298159",
    "end": "1300840"
  },
  {
    "text": "Ora",
    "start": "1300840",
    "end": "1302679"
  },
  {
    "text": "for yes so we use mainly Java our back",
    "start": "1302679",
    "end": "1305760"
  },
  {
    "text": "end is you know big majority Java and",
    "start": "1305760",
    "end": "1309080"
  },
  {
    "text": "this implementation refers to that as",
    "start": "1309080",
    "end": "1310679"
  },
  {
    "text": "well",
    "start": "1310679",
    "end": "1312520"
  },
  {
    "text": "um why we used Orca we we looked at",
    "start": "1312520",
    "end": "1315640"
  },
  {
    "text": "different mechanisms on how we could uh",
    "start": "1315640",
    "end": "1318000"
  },
  {
    "text": "transport information of zones uh there",
    "start": "1318000",
    "end": "1320640"
  },
  {
    "text": "was some in-house implementations of the",
    "start": "1320640",
    "end": "1322600"
  },
  {
    "text": "same type of thinking by creating",
    "start": "1322600",
    "end": "1324679"
  },
  {
    "text": "channels between all uh servers and then",
    "start": "1324679",
    "end": "1327240"
  },
  {
    "text": "exchanging the information the reason we",
    "start": "1327240",
    "end": "1329600"
  },
  {
    "text": "decided to use Orca was well it's",
    "start": "1329600",
    "end": "1331799"
  },
  {
    "text": "already there but we can also uh control",
    "start": "1331799",
    "end": "1335320"
  },
  {
    "text": "the window of how often this information",
    "start": "1335320",
    "end": "1337159"
  },
  {
    "text": "is propagated so in this case we only",
    "start": "1337159",
    "end": "1339400"
  },
  {
    "text": "need the zonal information once as soon",
    "start": "1339400",
    "end": "1341480"
  },
  {
    "text": "as the connection is established and",
    "start": "1341480",
    "end": "1343120"
  },
  {
    "text": "with Orca we can configure the Stream So",
    "start": "1343120",
    "end": "1345279"
  },
  {
    "text": "that we get the message once and then",
    "start": "1345279",
    "end": "1347159"
  },
  {
    "text": "there's no more information Exchange",
    "start": "1347159",
    "end": "1350520"
  },
  {
    "text": "hi uh thanks for the great talk um I was",
    "start": "1351440",
    "end": "1354400"
  },
  {
    "text": "wondering on what level do you determine",
    "start": "1354400",
    "end": "1356120"
  },
  {
    "text": "the um expected latency is it on a per",
    "start": "1356120",
    "end": "1359120"
  },
  {
    "text": "grpc endpoint level or is it on a per",
    "start": "1359120",
    "end": "1362000"
  },
  {
    "text": "service level per server where do you",
    "start": "1362000",
    "end": "1363720"
  },
  {
    "text": "determine that you want to",
    "start": "1363720",
    "end": "1365960"
  },
  {
    "text": "this uh yeah so it's on an endpoint",
    "start": "1365960",
    "end": "1368640"
  },
  {
    "text": "level so it's basically fully client",
    "start": "1368640",
    "end": "1370640"
  },
  {
    "text": "side load balancing um each endpoint",
    "start": "1370640",
    "end": "1373080"
  },
  {
    "text": "determines and measures its own observed",
    "start": "1373080",
    "end": "1375880"
  },
  {
    "text": "latency failure latency failure rate",
    "start": "1375880",
    "end": "1378000"
  },
  {
    "text": "success rate",
    "start": "1378000",
    "end": "1379360"
  },
  {
    "text": "um between all its connected servers and",
    "start": "1379360",
    "end": "1382600"
  },
  {
    "text": "with a high enough reest rate you get",
    "start": "1382600",
    "end": "1384960"
  },
  {
    "text": "very accurate results over",
    "start": "1384960",
    "end": "1387919"
  },
  {
    "text": "time hey uh thank you for the talk uh I",
    "start": "1387919",
    "end": "1391240"
  },
  {
    "text": "have one question like how do you make",
    "start": "1391240",
    "end": "1393400"
  },
  {
    "text": "sure that every team uses this load",
    "start": "1393400",
    "end": "1396440"
  },
  {
    "text": "balancing",
    "start": "1396440",
    "end": "1397919"
  },
  {
    "text": "algorithm yeah that's a great question",
    "start": "1397919",
    "end": "1400360"
  },
  {
    "text": "so uh I don't know if you've seen the uh",
    "start": "1400360",
    "end": "1403000"
  },
  {
    "text": "Spotify talk that was earlier today but",
    "start": "1403000",
    "end": "1405559"
  },
  {
    "text": "essentially at Spotify we have something",
    "start": "1405559",
    "end": "1407360"
  },
  {
    "text": "we call Fleet Management",
    "start": "1407360",
    "end": "1409440"
  },
  {
    "text": "and that is a way to roll out changes",
    "start": "1409440",
    "end": "1412480"
  },
  {
    "text": "over all repositories or backends uh at",
    "start": "1412480",
    "end": "1415559"
  },
  {
    "text": "Spotify so we kind of just rolled out",
    "start": "1415559",
    "end": "1420520"
  },
  {
    "text": "this change and forc kind of forced",
    "start": "1420520",
    "end": "1422640"
  },
  {
    "text": "users to use it um by making a a simple",
    "start": "1422640",
    "end": "1426919"
  },
  {
    "text": "commit in their repository and then it",
    "start": "1426919",
    "end": "1429480"
  },
  {
    "text": "was active yeah can I have one more",
    "start": "1429480",
    "end": "1432240"
  },
  {
    "text": "additional question like have you",
    "start": "1432240",
    "end": "1434440"
  },
  {
    "text": "thought about maybe you know like force",
    "start": "1434440",
    "end": "1437480"
  },
  {
    "text": "redirecting traffic something similar to",
    "start": "1437480",
    "end": "1439840"
  },
  {
    "text": "like service mes do yeah that's a great",
    "start": "1439840",
    "end": "1442840"
  },
  {
    "text": "question so uh we definitely trying to",
    "start": "1442840",
    "end": "1446080"
  },
  {
    "text": "adopt a more service mesh approach",
    "start": "1446080",
    "end": "1448120"
  },
  {
    "text": "because you will probably get like you",
    "start": "1448120",
    "end": "1451240"
  },
  {
    "text": "will get closer to this perfect score of",
    "start": "1451240",
    "end": "1453520"
  },
  {
    "text": "cross on traffic but admittedly it's",
    "start": "1453520",
    "end": "1456480"
  },
  {
    "text": "very hard to adopt at scale if you",
    "start": "1456480",
    "end": "1458840"
  },
  {
    "text": "didn't have the infrastructure before so",
    "start": "1458840",
    "end": "1461000"
  },
  {
    "text": "that's what we currently still working",
    "start": "1461000",
    "end": "1462720"
  },
  {
    "text": "on so that's why we kind of phrased this",
    "start": "1462720",
    "end": "1464960"
  },
  {
    "text": "as we aim for good enough and then",
    "start": "1464960",
    "end": "1466720"
  },
  {
    "text": "reiterate to make or take the more",
    "start": "1466720",
    "end": "1469559"
  },
  {
    "text": "complex solution that will solve it kind",
    "start": "1469559",
    "end": "1471960"
  },
  {
    "text": "of perfectly okay thank you very",
    "start": "1471960",
    "end": "1476000"
  },
  {
    "text": "much um thank you for the talk um I just",
    "start": "1476000",
    "end": "1479320"
  },
  {
    "text": "want to ask like um because in every",
    "start": "1479320",
    "end": "1481960"
  },
  {
    "text": "feature deployment like the latency and",
    "start": "1481960",
    "end": "1483960"
  },
  {
    "text": "the success ratio can um it can differ a",
    "start": "1483960",
    "end": "1487919"
  },
  {
    "text": "bit so is it like a static value or is",
    "start": "1487919",
    "end": "1490240"
  },
  {
    "text": "it like a dynamic",
    "start": "1490240",
    "end": "1491799"
  },
  {
    "text": "value yeah so those are measured over",
    "start": "1491799",
    "end": "1494760"
  },
  {
    "text": "time so they're basically just metrics",
    "start": "1494760",
    "end": "1497080"
  },
  {
    "text": "that each client observes so for example",
    "start": "1497080",
    "end": "1500120"
  },
  {
    "text": "it might send a request and it gets a",
    "start": "1500120",
    "end": "1502320"
  },
  {
    "text": "successful response and then it would",
    "start": "1502320",
    "end": "1504320"
  },
  {
    "text": "directly track this in its internal",
    "start": "1504320",
    "end": "1507080"
  },
  {
    "text": "metric measurement and use that for the",
    "start": "1507080",
    "end": "1510039"
  },
  {
    "text": "next L Bing",
    "start": "1510039",
    "end": "1512240"
  },
  {
    "text": "decision can I can add something to yeah",
    "start": "1512240",
    "end": "1514640"
  },
  {
    "text": "I can just quickly add something to that",
    "start": "1514640",
    "end": "1516679"
  },
  {
    "text": "we we do have a a tiny safety mechanism",
    "start": "1516679",
    "end": "1519039"
  },
  {
    "text": "on the penalty so if we notice that the",
    "start": "1519039",
    "end": "1521640"
  },
  {
    "text": "error rate is too high when we send",
    "start": "1521640",
    "end": "1523399"
  },
  {
    "text": "traffic to the same Zone we reset the",
    "start": "1523399",
    "end": "1526000"
  },
  {
    "text": "penalty and then slowly move it back to",
    "start": "1526000",
    "end": "1528679"
  },
  {
    "text": "uh the level we we started from so it's",
    "start": "1528679",
    "end": "1531520"
  },
  {
    "text": "to have some safety in that mechanism to",
    "start": "1531520",
    "end": "1533880"
  },
  {
    "text": "your",
    "start": "1533880",
    "end": "1535000"
  },
  {
    "text": "question did you modify the outer",
    "start": "1535000",
    "end": "1537559"
  },
  {
    "text": "scalers in any way to scale up a certain",
    "start": "1537559",
    "end": "1539880"
  },
  {
    "text": "Zone if it gets more",
    "start": "1539880",
    "end": "1541559"
  },
  {
    "text": "traffic great question we we started",
    "start": "1541559",
    "end": "1544159"
  },
  {
    "text": "with not doing that so we want to keep",
    "start": "1544159",
    "end": "1546120"
  },
  {
    "text": "it at the load balancing level for now",
    "start": "1546120",
    "end": "1548399"
  },
  {
    "text": "um at some point if we continue",
    "start": "1548399",
    "end": "1550000"
  },
  {
    "text": "iterating on this approach we'll we'll",
    "start": "1550000",
    "end": "1551640"
  },
  {
    "text": "start hitting other problems which we",
    "start": "1551640",
    "end": "1553399"
  },
  {
    "text": "can't fix with better load balancing so",
    "start": "1553399",
    "end": "1555080"
  },
  {
    "text": "like zonal skew and how things are",
    "start": "1555080",
    "end": "1557240"
  },
  {
    "text": "deployed so at that point we might look",
    "start": "1557240",
    "end": "1559039"
  },
  {
    "text": "at uh the wider infrastructure and see",
    "start": "1559039",
    "end": "1561760"
  },
  {
    "text": "if we can align it better for uh for",
    "start": "1561760",
    "end": "1563760"
  },
  {
    "text": "this load",
    "start": "1563760",
    "end": "1566159"
  },
  {
    "text": "balancing hi um how exactly did you um",
    "start": "1568000",
    "end": "1571559"
  },
  {
    "text": "test this beforehand and um I mean the",
    "start": "1571559",
    "end": "1574080"
  },
  {
    "text": "um the ratio or uh the the multiplier",
    "start": "1574080",
    "end": "1576720"
  },
  {
    "text": "for the the expected latency did you",
    "start": "1576720",
    "end": "1579120"
  },
  {
    "text": "roll out some low value and gradually",
    "start": "1579120",
    "end": "1581480"
  },
  {
    "text": "increase it or how did you test that",
    "start": "1581480",
    "end": "1583799"
  },
  {
    "text": "that's a great question Yanik you did a",
    "start": "1583799",
    "end": "1585279"
  },
  {
    "text": "lot of testing do you want to take that",
    "start": "1585279",
    "end": "1586840"
  },
  {
    "text": "yeah um so yeah great question so uh we",
    "start": "1586840",
    "end": "1590559"
  },
  {
    "text": "kind of started by Rolling it out",
    "start": "1590559",
    "end": "1592000"
  },
  {
    "text": "without activating the penalty and then",
    "start": "1592000",
    "end": "1594320"
  },
  {
    "text": "we had we had very like Advanced load",
    "start": "1594320",
    "end": "1597480"
  },
  {
    "text": "testing set up where we kind of tried to",
    "start": "1597480",
    "end": "1600080"
  },
  {
    "text": "fine tune that so we we were testing",
    "start": "1600080",
    "end": "1602760"
  },
  {
    "text": "like different Zone skes that you can",
    "start": "1602760",
    "end": "1604520"
  },
  {
    "text": "influence and have continuous loads",
    "start": "1604520",
    "end": "1606799"
  },
  {
    "text": "between deployments and then kind of",
    "start": "1606799",
    "end": "1608640"
  },
  {
    "text": "looked at what is a sweet spot and then",
    "start": "1608640",
    "end": "1611760"
  },
  {
    "text": "we we had a very like conservative start",
    "start": "1611760",
    "end": "1614760"
  },
  {
    "text": "with going with 10 and that worked very",
    "start": "1614760",
    "end": "1617080"
  },
  {
    "text": "well on production we didn't see any",
    "start": "1617080",
    "end": "1618760"
  },
  {
    "text": "issues over a long time um and I can",
    "start": "1618760",
    "end": "1622360"
  },
  {
    "text": "also add we rot this out on a tier based",
    "start": "1622360",
    "end": "1625600"
  },
  {
    "text": "way which means like TI lower tier",
    "start": "1625600",
    "end": "1628440"
  },
  {
    "text": "services that are not considered as",
    "start": "1628440",
    "end": "1630240"
  },
  {
    "text": "important or business critical would",
    "start": "1630240",
    "end": "1632120"
  },
  {
    "text": "start with this before higher business",
    "start": "1632120",
    "end": "1635000"
  },
  {
    "text": "critical Services would start using this",
    "start": "1635000",
    "end": "1638159"
  },
  {
    "text": "parameter thank",
    "start": "1638159",
    "end": "1641320"
  },
  {
    "text": "you hey uh so from my understanding you",
    "start": "1641520",
    "end": "1644720"
  },
  {
    "text": "had to write custom balancers to do that",
    "start": "1644720",
    "end": "1647159"
  },
  {
    "text": "right sorry I didn't you have to write a",
    "start": "1647159",
    "end": "1650080"
  },
  {
    "text": "custom grpc balancer yeah yeah exactly",
    "start": "1650080",
    "end": "1653360"
  },
  {
    "text": "yeah so my question is like it sounds",
    "start": "1653360",
    "end": "1656320"
  },
  {
    "text": "like there probably a lot of reusable",
    "start": "1656320",
    "end": "1658039"
  },
  {
    "text": "Parts in there uh and maybe you had to",
    "start": "1658039",
    "end": "1661440"
  },
  {
    "text": "like copy paste some of the Upstream",
    "start": "1661440",
    "end": "1663320"
  },
  {
    "text": "code right okay so have you engaged with",
    "start": "1663320",
    "end": "1665679"
  },
  {
    "text": "Upstream to try to like make the whole",
    "start": "1665679",
    "end": "1668200"
  },
  {
    "text": "balancer like internals more open or",
    "start": "1668200",
    "end": "1671480"
  },
  {
    "text": "maybe even like Upstream your own",
    "start": "1671480",
    "end": "1674240"
  },
  {
    "text": "formula um yeah for that specific one we",
    "start": "1674240",
    "end": "1677640"
  },
  {
    "text": "didn't consider to make it open source",
    "start": "1677640",
    "end": "1680360"
  },
  {
    "text": "uh I mean it's very specific to Spotify",
    "start": "1680360",
    "end": "1684039"
  },
  {
    "text": "but I don't want to exclude that",
    "start": "1684039",
    "end": "1686399"
  },
  {
    "text": "possibility I don't",
    "start": "1686399",
    "end": "1688320"
  },
  {
    "text": "know but thank you I can I can add to",
    "start": "1688320",
    "end": "1691960"
  },
  {
    "text": "the question of having to copy paste",
    "start": "1691960",
    "end": "1693600"
  },
  {
    "text": "code yes uh we pretty much started off",
    "start": "1693600",
    "end": "1697279"
  },
  {
    "text": "with the round robin implementation and",
    "start": "1697279",
    "end": "1699200"
  },
  {
    "text": "reused much of that and added things on",
    "start": "1699200",
    "end": "1701000"
  },
  {
    "text": "top um so that was an issue and we'd",
    "start": "1701000",
    "end": "1703720"
  },
  {
    "text": "love if those apis become more friendly",
    "start": "1703720",
    "end": "1706120"
  },
  {
    "text": "for this um so great question",
    "start": "1706120",
    "end": "1710120"
  },
  {
    "text": "hi um how long did this take to",
    "start": "1710519",
    "end": "1713279"
  },
  {
    "text": "implement like from the moment you",
    "start": "1713279",
    "end": "1714919"
  },
  {
    "text": "realize like you are sending two-thirds",
    "start": "1714919",
    "end": "1716840"
  },
  {
    "text": "of your traffic that's costing you extra",
    "start": "1716840",
    "end": "1718720"
  },
  {
    "text": "money until this is rolled out in",
    "start": "1718720",
    "end": "1720320"
  },
  {
    "text": "production for",
    "start": "1720320",
    "end": "1721919"
  },
  {
    "text": "everything if you ask me two months if",
    "start": "1721919",
    "end": "1724399"
  },
  {
    "text": "you ask our manager maybe six months but",
    "start": "1724399",
    "end": "1727480"
  },
  {
    "text": "it's in the months so three months four",
    "start": "1727480",
    "end": "1729720"
  },
  {
    "text": "months if I'm thank you remembering",
    "start": "1729720",
    "end": "1732279"
  },
  {
    "text": "correctly yeah I can slightly add to",
    "start": "1732279",
    "end": "1735039"
  },
  {
    "text": "that the complexity is maybe not",
    "start": "1735039",
    "end": "1736559"
  },
  {
    "text": "building it but making sure that it's",
    "start": "1736559",
    "end": "1738880"
  },
  {
    "text": "safe and rolling it out over the fleet",
    "start": "1738880",
    "end": "1740760"
  },
  {
    "text": "there are just so many issues that you",
    "start": "1740760",
    "end": "1743600"
  },
  {
    "text": "face at scale um also by people doing",
    "start": "1743600",
    "end": "1746600"
  },
  {
    "text": "Special setups so um that's more the",
    "start": "1746600",
    "end": "1749440"
  },
  {
    "text": "challenge than actually building the a",
    "start": "1749440",
    "end": "1751399"
  },
  {
    "text": "I'd say",
    "start": "1751399",
    "end": "1754679"
  }
]
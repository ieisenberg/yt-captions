[
  {
    "text": "hi everyone and welcome to today's",
    "start": "0",
    "end": "2040"
  },
  {
    "text": "webinar we're excited to have all of you",
    "start": "2040",
    "end": "4740"
  },
  {
    "text": "joining us from different parts of the",
    "start": "4740",
    "end": "6480"
  },
  {
    "text": "world I have with me here my colleague",
    "start": "6480",
    "end": "9059"
  },
  {
    "text": "and he's the creator of local AI he'll",
    "start": "9059",
    "end": "11820"
  },
  {
    "text": "be joining us and he's the um coach for",
    "start": "11820",
    "end": "13980"
  },
  {
    "text": "today",
    "start": "13980",
    "end": "15059"
  },
  {
    "text": "we're going to be talking about local AI",
    "start": "15059",
    "end": "18240"
  },
  {
    "text": "meat skates GPT",
    "start": "18240",
    "end": "20180"
  },
  {
    "text": "analyzing kubernetes cluster States",
    "start": "20180",
    "end": "22680"
  },
  {
    "text": "locally with CPU at the edge and Beyond",
    "start": "22680",
    "end": "26820"
  },
  {
    "text": "if you're a seasoned professional or you",
    "start": "26820",
    "end": "29820"
  },
  {
    "text": "just getting started in a field of",
    "start": "29820",
    "end": "31500"
  },
  {
    "text": "kubernetes I believe that there's",
    "start": "31500",
    "end": "33480"
  },
  {
    "text": "something for you in this webinar",
    "start": "33480",
    "end": "36120"
  },
  {
    "text": "during this webinar I'll encourage you",
    "start": "36120",
    "end": "38280"
  },
  {
    "text": "to ask any questions that you'd have I'd",
    "start": "38280",
    "end": "41280"
  },
  {
    "text": "also encourage you to share your",
    "start": "41280",
    "end": "42660"
  },
  {
    "text": "thoughts and engage with us actively",
    "start": "42660",
    "end": "45899"
  },
  {
    "text": "after this webinar there's also going to",
    "start": "45899",
    "end": "48000"
  },
  {
    "text": "be a recording of This webinar on the",
    "start": "48000",
    "end": "51000"
  },
  {
    "text": "cncf YouTube channel so you can go back",
    "start": "51000",
    "end": "53520"
  },
  {
    "text": "and have a look at it should you miss",
    "start": "53520",
    "end": "55559"
  },
  {
    "text": "anything so without further Ado let's",
    "start": "55559",
    "end": "58260"
  },
  {
    "text": "get started my name is Ole movie",
    "start": "58260",
    "end": "61980"
  },
  {
    "text": "um You can call me booby because Oliver",
    "start": "61980",
    "end": "63780"
  },
  {
    "text": "is very difficult to pronounce",
    "start": "63780",
    "end": "66479"
  },
  {
    "text": "um a devil engineer at spectrocloud and",
    "start": "66479",
    "end": "69540"
  },
  {
    "text": "I've also been a software engineer for",
    "start": "69540",
    "end": "71280"
  },
  {
    "text": "six plus years I enjoy writing technical",
    "start": "71280",
    "end": "74960"
  },
  {
    "text": "contents writing code and sharing my",
    "start": "74960",
    "end": "78780"
  },
  {
    "text": "knowledge you can find me on LinkedIn at",
    "start": "78780",
    "end": "81240"
  },
  {
    "text": "Oliver princess Ebola",
    "start": "81240",
    "end": "83460"
  },
  {
    "text": "I mean the name shown on your screen and",
    "start": "83460",
    "end": "86939"
  },
  {
    "text": "you can also find me on Twitter as",
    "start": "86939",
    "end": "88619"
  },
  {
    "text": "Princess Olympics so the S is just one",
    "start": "88619",
    "end": "91560"
  },
  {
    "text": "there's just one s not to um two s's",
    "start": "91560",
    "end": "95340"
  },
  {
    "text": "um for princess and then on other social",
    "start": "95340",
    "end": "98280"
  },
  {
    "text": "media platforms you can find me with the",
    "start": "98280",
    "end": "100140"
  },
  {
    "text": "same name",
    "start": "100140",
    "end": "102500"
  },
  {
    "text": "next slide attorney",
    "start": "103140",
    "end": "105439"
  },
  {
    "text": "introduce himself at this point hey",
    "start": "105439",
    "end": "108659"
  },
  {
    "text": "everyone I met today",
    "start": "108659",
    "end": "110579"
  },
  {
    "text": "um I am the head of Open Source at",
    "start": "110579",
    "end": "112200"
  },
  {
    "text": "Spectrum cloud and I've spent uh more",
    "start": "112200",
    "end": "114360"
  },
  {
    "text": "than 15 years um contributing in the",
    "start": "114360",
    "end": "116640"
  },
  {
    "text": "open source",
    "start": "116640",
    "end": "118320"
  },
  {
    "text": "um and I've been maintenance of several",
    "start": "118320",
    "end": "120180"
  },
  {
    "text": "open source projects",
    "start": "120180",
    "end": "121860"
  },
  {
    "text": "um I'm the creator of local AI you can",
    "start": "121860",
    "end": "124020"
  },
  {
    "text": "find me on Twitter as muddler",
    "start": "124020",
    "end": "125880"
  },
  {
    "text": "underscoreity or on GitHub as mandler",
    "start": "125880",
    "end": "130399"
  },
  {
    "text": "awesome Andrew Angie says AI is the new",
    "start": "130679",
    "end": "134340"
  },
  {
    "text": "electricity and the same way that AI",
    "start": "134340",
    "end": "137520"
  },
  {
    "text": "electricity is powering houses that's",
    "start": "137520",
    "end": "140819"
  },
  {
    "text": "the same way that AI is power in",
    "start": "140819",
    "end": "143220"
  },
  {
    "text": "Industries businesses and the future of",
    "start": "143220",
    "end": "145620"
  },
  {
    "text": "work",
    "start": "145620",
    "end": "146700"
  },
  {
    "text": "AI has come to change the way we do",
    "start": "146700",
    "end": "149400"
  },
  {
    "text": "almost everything that we do at this",
    "start": "149400",
    "end": "151200"
  },
  {
    "text": "point in time most Industries have seen",
    "start": "151200",
    "end": "153300"
  },
  {
    "text": "AI disrupting some part of their",
    "start": "153300",
    "end": "155400"
  },
  {
    "text": "operations and how they work generally",
    "start": "155400",
    "end": "159000"
  },
  {
    "text": "there are tons of tools that are being",
    "start": "159000",
    "end": "161340"
  },
  {
    "text": "released every day that utilize AI some",
    "start": "161340",
    "end": "165480"
  },
  {
    "text": "of these tools include",
    "start": "165480",
    "end": "167459"
  },
  {
    "text": "um chat GPT chargpt is designed to",
    "start": "167459",
    "end": "170519"
  },
  {
    "text": "facilitate natural language",
    "start": "170519",
    "end": "172200"
  },
  {
    "text": "conversations so when you give text",
    "start": "172200",
    "end": "174900"
  },
  {
    "text": "input to charge GPT it returns",
    "start": "174900",
    "end": "177599"
  },
  {
    "text": "human-like responses there's also done",
    "start": "177599",
    "end": "180540"
  },
  {
    "text": "that AI used for generating images",
    "start": "180540",
    "end": "183379"
  },
  {
    "text": "besides that there's code gbt which is",
    "start": "183379",
    "end": "186480"
  },
  {
    "text": "specifically designed for assisting with",
    "start": "186480",
    "end": "189360"
  },
  {
    "text": "code related tasks including code",
    "start": "189360",
    "end": "191819"
  },
  {
    "text": "completion code generation documentation",
    "start": "191819",
    "end": "195239"
  },
  {
    "text": "assistance and much more the field of",
    "start": "195239",
    "end": "197760"
  },
  {
    "text": "kubernetes is not left out uh AI has",
    "start": "197760",
    "end": "200700"
  },
  {
    "text": "come to disrupt the way that we interact",
    "start": "200700",
    "end": "202860"
  },
  {
    "text": "with our clusters as well so what",
    "start": "202860",
    "end": "205680"
  },
  {
    "text": "exactly is kids GPT so there we have an",
    "start": "205680",
    "end": "208860"
  },
  {
    "text": "exciting agenda I'll go over the agenda",
    "start": "208860",
    "end": "211200"
  },
  {
    "text": "first of all we have an exciting agenda",
    "start": "211200",
    "end": "213420"
  },
  {
    "text": "today we're going to be looking at an",
    "start": "213420",
    "end": "215760"
  },
  {
    "text": "overview of local Ai and kids GPT it is",
    "start": "215760",
    "end": "219599"
  },
  {
    "text": "going to be walking us through the",
    "start": "219599",
    "end": "221099"
  },
  {
    "text": "technical details we're also going to be",
    "start": "221099",
    "end": "223799"
  },
  {
    "text": "having a small demo and then a q a",
    "start": "223799",
    "end": "226500"
  },
  {
    "text": "session so what exactly is kids GPT",
    "start": "226500",
    "end": "231299"
  },
  {
    "text": "kids GPT",
    "start": "231299",
    "end": "233400"
  },
  {
    "text": "um focuses on leveraging gbt within",
    "start": "233400",
    "end": "236459"
  },
  {
    "text": "kubernetes clusters to analyze your",
    "start": "236459",
    "end": "238440"
  },
  {
    "text": "clusters so the analysis of those",
    "start": "238440",
    "end": "241379"
  },
  {
    "text": "clusters generate some information",
    "start": "241379",
    "end": "243799"
  },
  {
    "text": "on what's going on in the cluster and",
    "start": "243799",
    "end": "246959"
  },
  {
    "text": "it's transmitted to open AI",
    "start": "246959",
    "end": "249900"
  },
  {
    "text": "which in turn return in turn returns",
    "start": "249900",
    "end": "252840"
  },
  {
    "text": "results on what's going on internally in",
    "start": "252840",
    "end": "255299"
  },
  {
    "text": "the cluster based on the information",
    "start": "255299",
    "end": "257100"
  },
  {
    "text": "that it has collected on the cluster",
    "start": "257100",
    "end": "259440"
  },
  {
    "text": "it works with an external API to be able",
    "start": "259440",
    "end": "262800"
  },
  {
    "text": "to do this it's truly magical what kids",
    "start": "262800",
    "end": "266340"
  },
  {
    "text": "chipity can do so with it you can",
    "start": "266340",
    "end": "269220"
  },
  {
    "text": "enhance your SRE powers",
    "start": "269220",
    "end": "271919"
  },
  {
    "text": "it works great when the environment is",
    "start": "271919",
    "end": "275280"
  },
  {
    "text": "not isolated for example we test",
    "start": "275280",
    "end": "278280"
  },
  {
    "text": "environments kids GPT works great",
    "start": "278280",
    "end": "282120"
  },
  {
    "text": "when it comes to isolated environments",
    "start": "282120",
    "end": "284699"
  },
  {
    "text": "and air-gapped environments the question",
    "start": "284699",
    "end": "287639"
  },
  {
    "text": "of having to expose sensitive",
    "start": "287639",
    "end": "289919"
  },
  {
    "text": "information to a public API becomes a",
    "start": "289919",
    "end": "292380"
  },
  {
    "text": "valid concern",
    "start": "292380",
    "end": "294540"
  },
  {
    "text": "that's where local AI comes in",
    "start": "294540",
    "end": "297360"
  },
  {
    "text": "local AI lets you run your lmms on your",
    "start": "297360",
    "end": "301800"
  },
  {
    "text": "own device or Hardware",
    "start": "301800",
    "end": "304320"
  },
  {
    "text": "so bringing it to the world of",
    "start": "304320",
    "end": "305940"
  },
  {
    "text": "kubernetes with local AI you can now",
    "start": "305940",
    "end": "309180"
  },
  {
    "text": "harness the power of AI to analyze",
    "start": "309180",
    "end": "311400"
  },
  {
    "text": "kubernetes cluster States locally that",
    "start": "311400",
    "end": "314880"
  },
  {
    "text": "on your own Hardware",
    "start": "314880",
    "end": "316680"
  },
  {
    "text": "this way you don't have to worry about",
    "start": "316680",
    "end": "318960"
  },
  {
    "text": "exposing any data to the outside world",
    "start": "318960",
    "end": "322199"
  },
  {
    "text": "so this is perfect for isolated",
    "start": "322199",
    "end": "324240"
  },
  {
    "text": "environments",
    "start": "324240",
    "end": "325740"
  },
  {
    "text": "at this point I'm going to let my",
    "start": "325740",
    "end": "327960"
  },
  {
    "text": "colleague talk us through the technical",
    "start": "327960",
    "end": "330539"
  },
  {
    "text": "details",
    "start": "330539",
    "end": "333139"
  },
  {
    "text": "thank you booby yes",
    "start": "333539",
    "end": "336060"
  },
  {
    "text": "um so I'm going to show you",
    "start": "336060",
    "end": "337979"
  },
  {
    "text": "um what is local AI",
    "start": "337979",
    "end": "340680"
  },
  {
    "text": "um first of all let's let's discuss a",
    "start": "340680",
    "end": "342660"
  },
  {
    "text": "bit um what it is it is an open AI API",
    "start": "342660",
    "end": "346320"
  },
  {
    "text": "droppy replacement so that means that",
    "start": "346320",
    "end": "349199"
  },
  {
    "text": "your the software that you have already",
    "start": "349199",
    "end": "350639"
  },
  {
    "text": "built",
    "start": "350639",
    "end": "351840"
  },
  {
    "text": "um and Leverage The Open AI API",
    "start": "351840",
    "end": "354960"
  },
  {
    "text": "um already works out of the box with",
    "start": "354960",
    "end": "356639"
  },
  {
    "text": "local AI uh what does it do it runs a",
    "start": "356639",
    "end": "360300"
  },
  {
    "text": "large language models on consumer grade",
    "start": "360300",
    "end": "362699"
  },
  {
    "text": "Hardware it leverages the CPU so it",
    "start": "362699",
    "end": "365639"
  },
  {
    "text": "works mostly on any modern",
    "start": "365639",
    "end": "369479"
  },
  {
    "text": "um computer and it can also accelerate",
    "start": "369479",
    "end": "373199"
  },
  {
    "text": "the computation using the GPU it uses",
    "start": "373199",
    "end": "377039"
  },
  {
    "text": "open source models which are provided by",
    "start": "377039",
    "end": "379259"
  },
  {
    "text": "the community and is the perfect fit for",
    "start": "379259",
    "end": "382259"
  },
  {
    "text": "our gap or isolated environments or",
    "start": "382259",
    "end": "384419"
  },
  {
    "text": "small Finance unit models or where the",
    "start": "384419",
    "end": "387120"
  },
  {
    "text": "Privacy is a big concern",
    "start": "387120",
    "end": "389880"
  },
  {
    "text": "so you can see the quick up option of",
    "start": "389880",
    "end": "392280"
  },
  {
    "text": "local AI in this graph",
    "start": "392280",
    "end": "395340"
  },
  {
    "text": "and how do we tie together case GPT and",
    "start": "395340",
    "end": "399539"
  },
  {
    "text": "local AI so locally AI gives you the",
    "start": "399539",
    "end": "402539"
  },
  {
    "text": "ability to run large language models",
    "start": "402539",
    "end": "404639"
  },
  {
    "text": "on-prem uh so you can install that",
    "start": "404639",
    "end": "407340"
  },
  {
    "text": "locally in your machine or also inside",
    "start": "407340",
    "end": "410340"
  },
  {
    "text": "the kubernetes cluster because it have",
    "start": "410340",
    "end": "412680"
  },
  {
    "text": "an Helm charge that you can already",
    "start": "412680",
    "end": "414419"
  },
  {
    "text": "download and use",
    "start": "414419",
    "end": "416639"
  },
  {
    "text": "so first of all kcpt analyzer",
    "start": "416639",
    "end": "419699"
  },
  {
    "text": "um does an analysis of the cluster State",
    "start": "419699",
    "end": "423060"
  },
  {
    "text": "um so it tries to find everything that",
    "start": "423060",
    "end": "425340"
  },
  {
    "text": "doesn't seem right in the cluster and",
    "start": "425340",
    "end": "428160"
  },
  {
    "text": "look at problems like configuration",
    "start": "428160",
    "end": "431460"
  },
  {
    "text": "issues services not reachable and on pod",
    "start": "431460",
    "end": "435360"
  },
  {
    "text": "crashing for instance it collects all of",
    "start": "435360",
    "end": "437880"
  },
  {
    "text": "those analysis and feeds that back to",
    "start": "437880",
    "end": "440580"
  },
  {
    "text": "the AI to enhance the error with the",
    "start": "440580",
    "end": "445380"
  },
  {
    "text": "more",
    "start": "445380",
    "end": "446360"
  },
  {
    "text": "comprehensive message so you have a",
    "start": "446360",
    "end": "448860"
  },
  {
    "text": "little bit more of context on what's",
    "start": "448860",
    "end": "450479"
  },
  {
    "text": "happening with error so this typically",
    "start": "450479",
    "end": "453840"
  },
  {
    "text": "works by contacting the open AI API so",
    "start": "453840",
    "end": "457740"
  },
  {
    "text": "this is remote but we can swap that",
    "start": "457740",
    "end": "460380"
  },
  {
    "text": "component now with local Ai and do the",
    "start": "460380",
    "end": "462720"
  },
  {
    "text": "inference completely locally",
    "start": "462720",
    "end": "465319"
  },
  {
    "text": "locally I generally speaking is um open",
    "start": "465319",
    "end": "468180"
  },
  {
    "text": "AI API dropping replacement so how does",
    "start": "468180",
    "end": "471360"
  },
  {
    "text": "it work",
    "start": "471360",
    "end": "472740"
  },
  {
    "text": "um it have um a different",
    "start": "472740",
    "end": "476639"
  },
  {
    "text": "um set of backends behind the scene and",
    "start": "476639",
    "end": "479220"
  },
  {
    "text": "back-ends are CC plus plus uh open AI",
    "start": "479220",
    "end": "482880"
  },
  {
    "text": "seven goaling bindings uh so it can",
    "start": "482880",
    "end": "485400"
  },
  {
    "text": "actually leverage the models and run the",
    "start": "485400",
    "end": "487740"
  },
  {
    "text": "inference locally",
    "start": "487740",
    "end": "489660"
  },
  {
    "text": "um since it supports as a shim as open",
    "start": "489660",
    "end": "492300"
  },
  {
    "text": "API API spec you can use it to generate",
    "start": "492300",
    "end": "495479"
  },
  {
    "text": "text images and also transcribe audio",
    "start": "495479",
    "end": "500639"
  },
  {
    "text": "and now",
    "start": "500639",
    "end": "502199"
  },
  {
    "text": "um let's see the demo so I'm going to",
    "start": "502199",
    "end": "504900"
  },
  {
    "text": "show you um now in this example how to",
    "start": "504900",
    "end": "507360"
  },
  {
    "text": "to bring up local AI",
    "start": "507360",
    "end": "510120"
  },
  {
    "text": "um we talked about local AI already this",
    "start": "510120",
    "end": "512219"
  },
  {
    "text": "is the GitHub page you can find",
    "start": "512219",
    "end": "514860"
  },
  {
    "text": "instruction how to run on local AI",
    "start": "514860",
    "end": "518779"
  },
  {
    "text": "down here in the usage",
    "start": "518779",
    "end": "522120"
  },
  {
    "text": "um and here in an example with using the",
    "start": "522120",
    "end": "524760"
  },
  {
    "text": "GPT for all um model",
    "start": "524760",
    "end": "528000"
  },
  {
    "text": "um so now we are going to try out this",
    "start": "528000",
    "end": "530339"
  },
  {
    "text": "locally and we're going to see",
    "start": "530339",
    "end": "533040"
  },
  {
    "text": "um",
    "start": "533040",
    "end": "534019"
  },
  {
    "text": "debugging and Analysis of case GPT",
    "start": "534019",
    "end": "537660"
  },
  {
    "text": "um of a cluster window workload which is",
    "start": "537660",
    "end": "539519"
  },
  {
    "text": "uh having problems",
    "start": "539519",
    "end": "541560"
  },
  {
    "text": "so um first of all let's create our",
    "start": "541560",
    "end": "544560"
  },
  {
    "text": "cluster um in this case I'm creating the",
    "start": "544560",
    "end": "546899"
  },
  {
    "text": "cluster locally and I'm using kind",
    "start": "546899",
    "end": "549779"
  },
  {
    "text": "um this will spin up a cumulative",
    "start": "549779",
    "end": "551820"
  },
  {
    "text": "cluster",
    "start": "551820",
    "end": "553080"
  },
  {
    "text": "um using Docker",
    "start": "553080",
    "end": "555240"
  },
  {
    "text": "um my system",
    "start": "555240",
    "end": "557959"
  },
  {
    "text": "um and afterward I'm going to to create",
    "start": "558540",
    "end": "560940"
  },
  {
    "text": "a deployment and I'm going to slightly",
    "start": "560940",
    "end": "563160"
  },
  {
    "text": "modify it to to have an issue like I",
    "start": "563160",
    "end": "565980"
  },
  {
    "text": "cannot pull",
    "start": "565980",
    "end": "567360"
  },
  {
    "text": "um let's say an image",
    "start": "567360",
    "end": "569399"
  },
  {
    "text": "so now the cluster is up and running I",
    "start": "569399",
    "end": "572519"
  },
  {
    "text": "should be able to",
    "start": "572519",
    "end": "574500"
  },
  {
    "text": "see all the pods and I've already",
    "start": "574500",
    "end": "576839"
  },
  {
    "text": "installed kgpt locally here you can get",
    "start": "576839",
    "end": "580680"
  },
  {
    "text": "it in the case GPT",
    "start": "580680",
    "end": "583680"
  },
  {
    "text": "um in the case stupid posting here",
    "start": "583680",
    "end": "586920"
  },
  {
    "text": "um releases for binaries there are also",
    "start": "586920",
    "end": "588779"
  },
  {
    "text": "instructional to install it in Linux Mac",
    "start": "588779",
    "end": "591240"
  },
  {
    "text": "and all the Linux distributions",
    "start": "591240",
    "end": "594600"
  },
  {
    "text": "also for Windows and",
    "start": "594600",
    "end": "596959"
  },
  {
    "text": "so we're going now to set up local AI",
    "start": "596959",
    "end": "601080"
  },
  {
    "text": "locally so we are going to follow up the",
    "start": "601080",
    "end": "603120"
  },
  {
    "text": "example over here",
    "start": "603120",
    "end": "605100"
  },
  {
    "text": "so I'm going to copy paste this one I'm",
    "start": "605100",
    "end": "608580"
  },
  {
    "text": "going to clone the local AI Repository",
    "start": "608580",
    "end": "611880"
  },
  {
    "text": "first",
    "start": "611880",
    "end": "614040"
  },
  {
    "text": "and then I'm going down to just",
    "start": "614040",
    "end": "618180"
  },
  {
    "text": "get inside it",
    "start": "618180",
    "end": "620940"
  },
  {
    "text": "and the first thing you will notice here",
    "start": "620940",
    "end": "622740"
  },
  {
    "text": "there is a models folders",
    "start": "622740",
    "end": "625019"
  },
  {
    "text": "um",
    "start": "625019",
    "end": "625800"
  },
  {
    "text": "which is empty I'm going now to download",
    "start": "625800",
    "end": "628740"
  },
  {
    "text": "one of the models",
    "start": "628740",
    "end": "630720"
  },
  {
    "text": "this model is free it's Apache truly",
    "start": "630720",
    "end": "633720"
  },
  {
    "text": "sensed and even from GPT for all.io",
    "start": "633720",
    "end": "637440"
  },
  {
    "text": "and there are also this models that you",
    "start": "637440",
    "end": "640620"
  },
  {
    "text": "can use but we'll stick to this one and",
    "start": "640620",
    "end": "643500"
  },
  {
    "text": "try with um",
    "start": "643500",
    "end": "645480"
  },
  {
    "text": "this model over here",
    "start": "645480",
    "end": "647459"
  },
  {
    "text": "so it's going to take a while",
    "start": "647459",
    "end": "651740"
  },
  {
    "text": "and ah now it's about to finish",
    "start": "656279",
    "end": "659459"
  },
  {
    "text": "so the model is about 3.5 gigs",
    "start": "659459",
    "end": "663380"
  },
  {
    "text": "it gets partially loaded in memory so",
    "start": "663380",
    "end": "666000"
  },
  {
    "text": "you can expect you need some um",
    "start": "666000",
    "end": "668339"
  },
  {
    "text": "I would um certain kind of Hardware to",
    "start": "668339",
    "end": "670860"
  },
  {
    "text": "to run this however it works even on",
    "start": "670860",
    "end": "673380"
  },
  {
    "text": "Raspberry Pi but it's very slow to get",
    "start": "673380",
    "end": "676260"
  },
  {
    "text": "answers from the model so",
    "start": "676260",
    "end": "678300"
  },
  {
    "text": "um now we are going to copy",
    "start": "678300",
    "end": "681240"
  },
  {
    "text": "um the template so",
    "start": "681240",
    "end": "683100"
  },
  {
    "text": "um every model might have um a default",
    "start": "683100",
    "end": "686820"
  },
  {
    "text": "template",
    "start": "686820",
    "end": "688140"
  },
  {
    "text": "um to to be able to talk with and the",
    "start": "688140",
    "end": "691500"
  },
  {
    "text": "template allows basically",
    "start": "691500",
    "end": "693660"
  },
  {
    "text": "um to interact with the model in a",
    "start": "693660",
    "end": "695519"
  },
  {
    "text": "specific way so that the models are",
    "start": "695519",
    "end": "697079"
  },
  {
    "text": "trained uh towards an um a specific",
    "start": "697079",
    "end": "700140"
  },
  {
    "text": "prompt and in this case we are going to",
    "start": "700140",
    "end": "702839"
  },
  {
    "text": "use the",
    "start": "702839",
    "end": "704519"
  },
  {
    "text": "the template for ngpt for all that was",
    "start": "704519",
    "end": "707640"
  },
  {
    "text": "trend for GPT funnel and then we are",
    "start": "707640",
    "end": "709560"
  },
  {
    "text": "going to start local AI",
    "start": "709560",
    "end": "712820"
  },
  {
    "text": "now this is pulling the images",
    "start": "712860",
    "end": "716420"
  },
  {
    "text": "um not",
    "start": "716519",
    "end": "717480"
  },
  {
    "text": "um the images right now are going to um",
    "start": "717480",
    "end": "720019"
  },
  {
    "text": "the pool actually to to compile",
    "start": "720019",
    "end": "724320"
  },
  {
    "text": "um the locally I API binary the first",
    "start": "724320",
    "end": "727620"
  },
  {
    "text": "time that it starts",
    "start": "727620",
    "end": "729480"
  },
  {
    "text": "um we will have um in the future",
    "start": "729480",
    "end": "731579"
  },
  {
    "text": "releases options also to have the the",
    "start": "731579",
    "end": "734279"
  },
  {
    "text": "binaries but keep in mind that um it",
    "start": "734279",
    "end": "737220"
  },
  {
    "text": "depends um on the CPU specific CPU you",
    "start": "737220",
    "end": "739920"
  },
  {
    "text": "have in the hardware it will leverage",
    "start": "739920",
    "end": "741600"
  },
  {
    "text": "certain instruction sets so",
    "start": "741600",
    "end": "745019"
  },
  {
    "text": "um it is a suggested still to run the",
    "start": "745019",
    "end": "747899"
  },
  {
    "text": "compilation before running the API",
    "start": "747899",
    "end": "750720"
  },
  {
    "text": "exactly for this solution to leverage",
    "start": "750720",
    "end": "752399"
  },
  {
    "text": "all the distraction set of the CPU so",
    "start": "752399",
    "end": "755040"
  },
  {
    "text": "and this can actually make the",
    "start": "755040",
    "end": "757440"
  },
  {
    "text": "performance um much better",
    "start": "757440",
    "end": "760920"
  },
  {
    "text": "um besides having a general",
    "start": "760920",
    "end": "763860"
  },
  {
    "text": "um binaries so",
    "start": "763860",
    "end": "766680"
  },
  {
    "text": "it's about to run so yes so we can see",
    "start": "766680",
    "end": "771660"
  },
  {
    "text": "now",
    "start": "771660",
    "end": "774319"
  },
  {
    "text": "the local AI it's getting up so as you",
    "start": "775200",
    "end": "779579"
  },
  {
    "text": "can see the first booting step it's",
    "start": "779579",
    "end": "781920"
  },
  {
    "text": "actually combining the code on the",
    "start": "781920",
    "end": "784560"
  },
  {
    "text": "machine",
    "start": "784560",
    "end": "786600"
  },
  {
    "text": "and as soon as this will um come up we",
    "start": "786600",
    "end": "789420"
  },
  {
    "text": "will try to",
    "start": "789420",
    "end": "790980"
  },
  {
    "text": "to run an inference",
    "start": "790980",
    "end": "792839"
  },
  {
    "text": "um something locally to see if the model",
    "start": "792839",
    "end": "794519"
  },
  {
    "text": "is actually up and running",
    "start": "794519",
    "end": "798480"
  },
  {
    "text": "it's about to finish",
    "start": "798480",
    "end": "800519"
  },
  {
    "text": "it's combining calling binary",
    "start": "800519",
    "end": "803959"
  },
  {
    "text": "and we should see the API",
    "start": "805139",
    "end": "808500"
  },
  {
    "text": "starting",
    "start": "808500",
    "end": "809880"
  },
  {
    "text": "so",
    "start": "809880",
    "end": "812360"
  },
  {
    "text": "and there we go API it started so I'm",
    "start": "819660",
    "end": "822540"
  },
  {
    "text": "going to",
    "start": "822540",
    "end": "823560"
  },
  {
    "text": "um",
    "start": "823560",
    "end": "824540"
  },
  {
    "text": "give the logs and let's have a look at",
    "start": "824540",
    "end": "827880"
  },
  {
    "text": "the models folder now so you can see we",
    "start": "827880",
    "end": "830700"
  },
  {
    "text": "have the GPT for all model and the",
    "start": "830700",
    "end": "833579"
  },
  {
    "text": "template file",
    "start": "833579",
    "end": "835019"
  },
  {
    "text": "um now we are going to run this command",
    "start": "835019",
    "end": "839399"
  },
  {
    "text": "just to check if everything is alright",
    "start": "839399",
    "end": "841200"
  },
  {
    "text": "so yeah as you can see we can see the",
    "start": "841200",
    "end": "845040"
  },
  {
    "text": "ggmn GPT for all model",
    "start": "845040",
    "end": "847560"
  },
  {
    "text": "um correct listed in there and we can",
    "start": "847560",
    "end": "849779"
  },
  {
    "text": "try to",
    "start": "849779",
    "end": "851100"
  },
  {
    "text": "ask a question to the model so how are",
    "start": "851100",
    "end": "854459"
  },
  {
    "text": "you",
    "start": "854459",
    "end": "855660"
  },
  {
    "text": "and this is basically the",
    "start": "855660",
    "end": "858860"
  },
  {
    "text": "the the first uh call that we do to the",
    "start": "858860",
    "end": "862800"
  },
  {
    "text": "API so it will load the model into",
    "start": "862800",
    "end": "864839"
  },
  {
    "text": "memory and it will be faster on the next",
    "start": "864839",
    "end": "868260"
  },
  {
    "text": "inferences meanwhile we can also",
    "start": "868260",
    "end": "871260"
  },
  {
    "text": "um check uh what's going on on",
    "start": "871260",
    "end": "875100"
  },
  {
    "text": "um",
    "start": "875100",
    "end": "876240"
  },
  {
    "text": "the API over here",
    "start": "876240",
    "end": "879120"
  },
  {
    "text": "so as you can see the model loaded",
    "start": "879120",
    "end": "882180"
  },
  {
    "text": "um you can have some extra output with",
    "start": "882180",
    "end": "885060"
  },
  {
    "text": "the bug options so you can see what's",
    "start": "885060",
    "end": "888000"
  },
  {
    "text": "going on however take into account that",
    "start": "888000",
    "end": "891720"
  },
  {
    "text": "on CPUs it depends really depends on the",
    "start": "891720",
    "end": "895500"
  },
  {
    "text": "on the CPU model but more or less this",
    "start": "895500",
    "end": "897540"
  },
  {
    "text": "is the time that you can see yeah so we",
    "start": "897540",
    "end": "899699"
  },
  {
    "text": "haven't answered everything it's ready",
    "start": "899699",
    "end": "902399"
  },
  {
    "text": "and now we can just try to deploy",
    "start": "902399",
    "end": "906480"
  },
  {
    "text": "um something that is not working just",
    "start": "906480",
    "end": "909360"
  },
  {
    "text": "fine in our kubernetes cluster",
    "start": "909360",
    "end": "912300"
  },
  {
    "text": "okay let's set up then um case GPT team",
    "start": "912300",
    "end": "916079"
  },
  {
    "text": "to actually use local AI we're going to",
    "start": "916079",
    "end": "919740"
  },
  {
    "text": "see the instruction over the kids GPT",
    "start": "919740",
    "end": "922100"
  },
  {
    "text": "project it's over here",
    "start": "922100",
    "end": "925620"
  },
  {
    "text": "running local models",
    "start": "925620",
    "end": "928620"
  },
  {
    "text": "down here so there is a start the API",
    "start": "928620",
    "end": "931380"
  },
  {
    "text": "if we already went through and now",
    "start": "931380",
    "end": "933540"
  },
  {
    "text": "around kids GPT so this is the model",
    "start": "933540",
    "end": "936180"
  },
  {
    "text": "name this is the back end so we are",
    "start": "936180",
    "end": "938760"
  },
  {
    "text": "going to",
    "start": "938760",
    "end": "939899"
  },
  {
    "text": "authenticate the local AI backend with",
    "start": "939899",
    "end": "942600"
  },
  {
    "text": "this model so the model name is",
    "start": "942600",
    "end": "946079"
  },
  {
    "text": "this one",
    "start": "946079",
    "end": "948800"
  },
  {
    "text": "so I have already provided for it so I'm",
    "start": "951120",
    "end": "953880"
  },
  {
    "text": "going to remove it",
    "start": "953880",
    "end": "955500"
  },
  {
    "text": "um",
    "start": "955500",
    "end": "957240"
  },
  {
    "text": "all right so now again",
    "start": "957240",
    "end": "961260"
  },
  {
    "text": "right perfect so I have now the the",
    "start": "961260",
    "end": "963860"
  },
  {
    "text": "provided loaded in kgpt so kgpt is going",
    "start": "963860",
    "end": "967199"
  },
  {
    "text": "to ask directly local AI for things",
    "start": "967199",
    "end": "969839"
  },
  {
    "text": "about my cluster now I'm going to take",
    "start": "969839",
    "end": "973320"
  },
  {
    "text": "um a deployments from directly from the",
    "start": "973320",
    "end": "976560"
  },
  {
    "text": "kubernetes documentation so create a",
    "start": "976560",
    "end": "978720"
  },
  {
    "text": "deployment",
    "start": "978720",
    "end": "980040"
  },
  {
    "text": "this one looks good so deployment",
    "start": "980040",
    "end": "984720"
  },
  {
    "text": "yamu",
    "start": "984720",
    "end": "987060"
  },
  {
    "text": "I'm going to put it over here now what",
    "start": "987060",
    "end": "989940"
  },
  {
    "text": "I'm going to do it's going to change the",
    "start": "989940",
    "end": "992399"
  },
  {
    "text": "image and have some typos",
    "start": "992399",
    "end": "996000"
  },
  {
    "text": "right so what about this bad guy",
    "start": "996000",
    "end": "1000800"
  },
  {
    "text": "so I'm going to just see what's glass",
    "start": "1000800",
    "end": "1003680"
  },
  {
    "text": "and now I'm going to apply it",
    "start": "1003680",
    "end": "1007060"
  },
  {
    "text": "deployments",
    "start": "1007060",
    "end": "1008839"
  },
  {
    "text": "there we go",
    "start": "1008839",
    "end": "1011000"
  },
  {
    "text": "let's see",
    "start": "1011000",
    "end": "1014139"
  },
  {
    "text": "what's happening okay so I have",
    "start": "1015199",
    "end": "1017660"
  },
  {
    "text": "something which is not good in my class",
    "start": "1017660",
    "end": "1019880"
  },
  {
    "text": "and I'm going to ask Kate's GPT",
    "start": "1019880",
    "end": "1024798"
  },
  {
    "text": "about it so let's see what it's going to",
    "start": "1024799",
    "end": "1027798"
  },
  {
    "text": "give me",
    "start": "1027799",
    "end": "1030579"
  },
  {
    "text": "now what we can see of course is",
    "start": "1031699",
    "end": "1034640"
  },
  {
    "text": "it will be definitely more slower",
    "start": "1034640",
    "end": "1038120"
  },
  {
    "text": "because it's running locally",
    "start": "1038120",
    "end": "1040459"
  },
  {
    "text": "but and it's also going to just use four",
    "start": "1040459",
    "end": "1044600"
  },
  {
    "text": "threads over here",
    "start": "1044600",
    "end": "1046160"
  },
  {
    "text": "but",
    "start": "1046160",
    "end": "1048199"
  },
  {
    "text": "it's going to give me an answer pretty",
    "start": "1048199",
    "end": "1051080"
  },
  {
    "text": "soon",
    "start": "1051080",
    "end": "1052040"
  },
  {
    "text": "let's see",
    "start": "1052040",
    "end": "1054640"
  },
  {
    "text": "the result",
    "start": "1058820",
    "end": "1060740"
  },
  {
    "text": "so I wrote back off pulling image and",
    "start": "1060740",
    "end": "1063559"
  },
  {
    "text": "this was our typo in the solution so",
    "start": "1063559",
    "end": "1065780"
  },
  {
    "text": "check the image existing here in this",
    "start": "1065780",
    "end": "1067460"
  },
  {
    "text": "cluster check the postage default image",
    "start": "1067460",
    "end": "1069799"
  },
  {
    "text": "if the postage is set always are just",
    "start": "1069799",
    "end": "1071960"
  },
  {
    "text": "supposedly to pull if present and run",
    "start": "1071960",
    "end": "1073700"
  },
  {
    "text": "the imageable so now we get",
    "start": "1073700",
    "end": "1077179"
  },
  {
    "text": "um some real insight from the errors",
    "start": "1077179",
    "end": "1080480"
  },
  {
    "text": "um in kubernetes so we can check what",
    "start": "1080480",
    "end": "1083660"
  },
  {
    "text": "was",
    "start": "1083660",
    "end": "1085100"
  },
  {
    "text": "um given into the logs and we will see",
    "start": "1085100",
    "end": "1087620"
  },
  {
    "text": "here",
    "start": "1087620",
    "end": "1089179"
  },
  {
    "text": "um this is the message that was fitted",
    "start": "1089179",
    "end": "1091039"
  },
  {
    "text": "to the AI so",
    "start": "1091039",
    "end": "1092840"
  },
  {
    "text": "um simplifying the following given at a",
    "start": "1092840",
    "end": "1094340"
  },
  {
    "text": "server message limited by triple dashes",
    "start": "1094340",
    "end": "1096679"
  },
  {
    "text": "written in English so this is both",
    "start": "1096679",
    "end": "1098960"
  },
  {
    "text": "error's message from kubernetes back off",
    "start": "1098960",
    "end": "1100940"
  },
  {
    "text": "Boolean image and this was the image so",
    "start": "1100940",
    "end": "1105020"
  },
  {
    "text": "and that's all about it all right thank",
    "start": "1105020",
    "end": "1108380"
  },
  {
    "text": "you very much etori for taking us",
    "start": "1108380",
    "end": "1110120"
  },
  {
    "text": "through the demo I hope you learned one",
    "start": "1110120",
    "end": "1112820"
  },
  {
    "text": "or two things from the demo",
    "start": "1112820",
    "end": "1114440"
  },
  {
    "text": "demo now we're going to be getting into",
    "start": "1114440",
    "end": "1116059"
  },
  {
    "text": "the question and answer session and I",
    "start": "1116059",
    "end": "1118700"
  },
  {
    "text": "have just two questions on my table",
    "start": "1118700",
    "end": "1122780"
  },
  {
    "text": "so the first question is what kind of",
    "start": "1122780",
    "end": "1125960"
  },
  {
    "text": "Hardware can local AI run on are there",
    "start": "1125960",
    "end": "1128900"
  },
  {
    "text": "any hardware restrictions",
    "start": "1128900",
    "end": "1131900"
  },
  {
    "text": "uh that's a very great question",
    "start": "1131900",
    "end": "1134660"
  },
  {
    "text": "um so generally speaking there are no",
    "start": "1134660",
    "end": "1137539"
  },
  {
    "text": "big restrictions as this is",
    "start": "1137539",
    "end": "1140059"
  },
  {
    "text": "um the the back ends which local AI",
    "start": "1140059",
    "end": "1143660"
  },
  {
    "text": "um uses behind the scene works also on",
    "start": "1143660",
    "end": "1146539"
  },
  {
    "text": "uh constraining Hardware such as",
    "start": "1146539",
    "end": "1148280"
  },
  {
    "text": "Raspberry Pi but this is depending",
    "start": "1148280",
    "end": "1150679"
  },
  {
    "text": "mostly on the model size that you are",
    "start": "1150679",
    "end": "1152480"
  },
  {
    "text": "willing to run so this is",
    "start": "1152480",
    "end": "1154940"
  },
  {
    "text": "the reason",
    "start": "1154940",
    "end": "1156620"
  },
  {
    "text": "um I would suggest locally I also for",
    "start": "1156620",
    "end": "1159500"
  },
  {
    "text": "fine-tuned models because if you have",
    "start": "1159500",
    "end": "1161179"
  },
  {
    "text": "fine-tuned models then you can leverage",
    "start": "1161179",
    "end": "1163460"
  },
  {
    "text": "that piece of technology",
    "start": "1163460",
    "end": "1166220"
  },
  {
    "text": "um more",
    "start": "1166220",
    "end": "1167860"
  },
  {
    "text": "for the larger models you need very",
    "start": "1167860",
    "end": "1170299"
  },
  {
    "text": "modern and capable hardware and I would",
    "start": "1170299",
    "end": "1173240"
  },
  {
    "text": "suggest also of GPU but generally",
    "start": "1173240",
    "end": "1176000"
  },
  {
    "text": "speaking fine-tuned uh small models work",
    "start": "1176000",
    "end": "1179179"
  },
  {
    "text": "very fine then",
    "start": "1179179",
    "end": "1181760"
  },
  {
    "text": "that's interesting and then there's a",
    "start": "1181760",
    "end": "1183860"
  },
  {
    "text": "second question which says security is",
    "start": "1183860",
    "end": "1186919"
  },
  {
    "text": "usually top of mind for several",
    "start": "1186919",
    "end": "1188840"
  },
  {
    "text": "organizations",
    "start": "1188840",
    "end": "1190280"
  },
  {
    "text": "can you talk about how Security in local",
    "start": "1190280",
    "end": "1193400"
  },
  {
    "text": "AI or can you talk about Security in",
    "start": "1193400",
    "end": "1195679"
  },
  {
    "text": "local AI especially with respect to",
    "start": "1195679",
    "end": "1198080"
  },
  {
    "text": "production environment clusters",
    "start": "1198080",
    "end": "1200419"
  },
  {
    "text": "right it's also a very good one so",
    "start": "1200419",
    "end": "1203240"
  },
  {
    "text": "um I think locally I um have a very good",
    "start": "1203240",
    "end": "1206299"
  },
  {
    "text": "uh sweet spot here because",
    "start": "1206299",
    "end": "1209059"
  },
  {
    "text": "um everybody want to use open AI but the",
    "start": "1209059",
    "end": "1212900"
  },
  {
    "text": "Privacy",
    "start": "1212900",
    "end": "1214039"
  },
  {
    "text": "um and the sensibility of the data that",
    "start": "1214039",
    "end": "1216260"
  },
  {
    "text": "you're sharing with it it's very",
    "start": "1216260",
    "end": "1218780"
  },
  {
    "text": "um it's very important right it's an",
    "start": "1218780",
    "end": "1222020"
  },
  {
    "text": "aspect that nobody is neglecting so I",
    "start": "1222020",
    "end": "1224720"
  },
  {
    "text": "was reading news like a few days ago uh",
    "start": "1224720",
    "end": "1227720"
  },
  {
    "text": "several companies are actually blocking",
    "start": "1227720",
    "end": "1230000"
  },
  {
    "text": "access to chat GPT I I totally",
    "start": "1230000",
    "end": "1232280"
  },
  {
    "text": "understand that and in this context",
    "start": "1232280",
    "end": "1235460"
  },
  {
    "text": "um when you are even analyzing the",
    "start": "1235460",
    "end": "1237320"
  },
  {
    "text": "cluster data you don't want to expose",
    "start": "1237320",
    "end": "1240140"
  },
  {
    "text": "any kind of sensitive data back to the",
    "start": "1240140",
    "end": "1242179"
  },
  {
    "text": "API so uh I I think it's a great fit uh",
    "start": "1242179",
    "end": "1246500"
  },
  {
    "text": "in this context local AI",
    "start": "1246500",
    "end": "1250059"
  },
  {
    "text": "I think that's clear enough thank you",
    "start": "1251720",
    "end": "1253880"
  },
  {
    "text": "very much etori for next steps you can",
    "start": "1253880",
    "end": "1256880"
  },
  {
    "text": "follow local AI on local underscore",
    "start": "1256880",
    "end": "1259480"
  },
  {
    "text": "local AI underscore API on Twitter you",
    "start": "1259480",
    "end": "1263419"
  },
  {
    "text": "can also check out the project on GitHub",
    "start": "1263419",
    "end": "1266120"
  },
  {
    "text": "using the link shown on your screen",
    "start": "1266120",
    "end": "1268640"
  },
  {
    "text": "up aside that you can look at how you",
    "start": "1268640",
    "end": "1271820"
  },
  {
    "text": "can make use of local AI in your own",
    "start": "1271820",
    "end": "1274520"
  },
  {
    "text": "clusters using the link also shown on",
    "start": "1274520",
    "end": "1277039"
  },
  {
    "text": "your screen and with that we've come to",
    "start": "1277039",
    "end": "1280580"
  },
  {
    "text": "the end of today's webinar on behalf of",
    "start": "1280580",
    "end": "1283299"
  },
  {
    "text": "spectral Cloud I'd like to extend my",
    "start": "1283299",
    "end": "1286580"
  },
  {
    "text": "sincerity regards to",
    "start": "1286580",
    "end": "1288559"
  },
  {
    "text": "Atari who was our speaker and to you all",
    "start": "1288559",
    "end": "1291440"
  },
  {
    "text": "our listeners today thank you very much",
    "start": "1291440",
    "end": "1294980"
  },
  {
    "text": "thank you booby and thank you everyone",
    "start": "1294980",
    "end": "1297020"
  },
  {
    "text": "bye",
    "start": "1297020",
    "end": "1298520"
  },
  {
    "text": "bye",
    "start": "1298520",
    "end": "1300580"
  }
]
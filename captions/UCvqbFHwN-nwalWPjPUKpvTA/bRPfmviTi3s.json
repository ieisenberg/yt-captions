[
  {
    "start": "0",
    "end": "45000"
  },
  {
    "text": "welcome everyone thank you for walking this long way to our talk and thank you",
    "start": "1480",
    "end": "7040"
  },
  {
    "text": "for attending the talk uh late in in the day we know that the first day of kubon",
    "start": "7040",
    "end": "12360"
  },
  {
    "text": "is yeah is challenging so today we um we",
    "start": "12360",
    "end": "17520"
  },
  {
    "text": "talking about a cluster API Deep dive and we are talking about how we worked to improve the cluster API performance",
    "start": "17520",
    "end": "24680"
  },
  {
    "text": "up to 2,000 clusters uh first let's introduce ourself I'm pandini I work at",
    "start": "24680",
    "end": "32040"
  },
  {
    "text": "onew and I'm a see cluster life cycle Tech lead and a cluster API maintainer",
    "start": "32040",
    "end": "37840"
  },
  {
    "text": "yeah I'm St bu I also work work for y I'm CL contr",
    "start": "37840",
    "end": "43800"
  },
  {
    "text": "maintainer good great uh before starting so um today what we're talking about is",
    "start": "43800",
    "end": "50719"
  },
  {
    "start": "45000",
    "end": "100000"
  },
  {
    "text": "a work that we did uh for cluster API one uh 1.5.0 so it means more or less this",
    "start": "50719",
    "end": "57920"
  },
  {
    "text": "summer and um what is interesting about this work is is that we are talking about um a series of con of concept or",
    "start": "57920",
    "end": "66680"
  },
  {
    "text": "experience or lesser learning that not not only apply to clust thpi or clust thpi providers but can be useful for",
    "start": "66680",
    "end": "75439"
  },
  {
    "text": "everyone developing controller on kubernetes um the presentation today is",
    "start": "75439",
    "end": "81439"
  },
  {
    "text": "kind of dividing in two part the first part will be a very brief introduction on the tool that you need to do uh",
    "start": "81439",
    "end": "89000"
  },
  {
    "text": "performance of scalability optimization the second part will be a deep dive on how we basically manage to scale cluster",
    "start": "89000",
    "end": "96680"
  },
  {
    "text": "pii up to 2,000 clusters okay so let's get started so the first step is you have to get the",
    "start": "96680",
    "end": "103040"
  },
  {
    "start": "100000",
    "end": "216000"
  },
  {
    "text": "right uh tools for the shop um we going relatively quickly over some of those so that we can focus on the more important parts later on so uh the first things",
    "start": "103040",
    "end": "110119"
  },
  {
    "text": "you need is metrics uh profiling tracing and locks um ideally so we have like a",
    "start": "110119",
    "end": "115520"
  },
  {
    "text": "priority list on the right side essentially so the first thing is definitely that you need metrics because otherwise you can measure anything um",
    "start": "115520",
    "end": "121479"
  },
  {
    "text": "but what you also need is um Automation and what we mean with aut automation here is essentially that um you will",
    "start": "121479",
    "end": "126640"
  },
  {
    "text": "have to run some sort of scale test and ideally you don't do it manually of course so you need um yeah automation",
    "start": "126640",
    "end": "131680"
  },
  {
    "text": "for your scale test uh and if possible you should also use mock so in cluster API usually we we create clusters and",
    "start": "131680",
    "end": "137599"
  },
  {
    "text": "machines and some real clouds and of course it's a lot better if you just use a mock because you don't don't actually",
    "start": "137599",
    "end": "143280"
  },
  {
    "text": "have to pay for the infrastructure Etc so why do we need those tools so the first four metric profiling tracing and",
    "start": "143280",
    "end": "149239"
  },
  {
    "text": "locks um we mostly need them to analyze performance um and to investigate bottlenecks uh the first two metrics in",
    "start": "149239",
    "end": "155560"
  },
  {
    "text": "profiling they're more for getting like a rough overview or like a lot of reconciles just to get data like average",
    "start": "155560",
    "end": "161720"
  },
  {
    "text": "reconcile duration Etc uh while we use tracing and locks more like to dig into like specific slow reconciles and try to",
    "start": "161720",
    "end": "168000"
  },
  {
    "text": "figure out basically very we losing the time then for automation um the important part essentially we running",
    "start": "168000",
    "end": "173280"
  },
  {
    "text": "our scale T automated so that we can um observe the performance we can optimize it we can run the test again we can see",
    "start": "173280",
    "end": "178720"
  },
  {
    "text": "how much we improve um and of course um once we did our optimizations we just try to run them",
    "start": "178720",
    "end": "184519"
  },
  {
    "text": "periodically so that we don't run into any regressions um yeah once we Implement new features and other stuff",
    "start": "184519",
    "end": "191280"
  },
  {
    "text": "um yeah and the mock I already mentioned it before but the most important parts essentially um is to to increase speed",
    "start": "191280",
    "end": "199360"
  },
  {
    "text": "um so that we don't actually have to wait for real infrastructure to come up we can just decide in our mock how F how long does it take to create a machine or",
    "start": "199360",
    "end": "205680"
  },
  {
    "text": "whatever you want to do and of course to reduce costs because we're talking about really a huge amount of clusters a huge",
    "start": "205680",
    "end": "211599"
  },
  {
    "text": "amount of machines and you don't actually want to pay for the infrastructure next okay let's take a closer look at",
    "start": "211599",
    "end": "219120"
  },
  {
    "start": "216000",
    "end": "274000"
  },
  {
    "text": "metrics so uh we basically made our own categories here so uh we we separate them in user facing and in um internal",
    "start": "219120",
    "end": "226959"
  },
  {
    "text": "metrics or system metrics the idea is basically user facing metrics are actually metrics describing what the",
    "start": "226959",
    "end": "232599"
  },
  {
    "text": "user cares about so things like how long does it take to create a machine delete a machine create a cluster um and we use",
    "start": "232599",
    "end": "239079"
  },
  {
    "text": "them to Define goals and to measure our success so the really important part is that you have metrics describing what the user cares about and those are the",
    "start": "239079",
    "end": "245159"
  },
  {
    "text": "ones we're trying to optimize then we have internal metric and we use internal metrics um to take a",
    "start": "245159",
    "end": "251040"
  },
  {
    "text": "basically deeper look into the system and try to figure out um why the user facing metric are not looking that good",
    "start": "251040",
    "end": "256959"
  },
  {
    "text": "so an example is uh we're looking at average Recon durations of our controllers about work Q memory usage",
    "start": "256959",
    "end": "263160"
  },
  {
    "text": "CPU usage U number of go routines that sort of stuff so basically use them to",
    "start": "263160",
    "end": "269440"
  },
  {
    "text": "understand a little bit better how a system works and try to pinpoint what you have to optimize okay so how can you get all of",
    "start": "269440",
    "end": "277759"
  },
  {
    "start": "274000",
    "end": "458000"
  },
  {
    "text": "this so the good news is uses um you get almost all of it for free because at",
    "start": "277759",
    "end": "282840"
  },
  {
    "text": "least with classia because you already did a lot of that work we have a lot of stuff just Upstream in a repository and",
    "start": "282840",
    "end": "288320"
  },
  {
    "text": "can mostly use it for you so for user facing metrics um the ideas in our case",
    "start": "288320",
    "end": "294360"
  },
  {
    "text": "that we essentially infer those metrics from CDs so we have our cluster our machine Etc CDs and we just give",
    "start": "294360",
    "end": "300479"
  },
  {
    "text": "essential cubes metric a config so that it can infer certain metrics from those CDs so basically a cluster object",
    "start": "300479",
    "end": "307039"
  },
  {
    "text": "already contains information how long it takes to create a machine and that sort of stuff and we",
    "start": "307039",
    "end": "312520"
  },
  {
    "text": "just infer it from there for internal metric um we're using the metrix server",
    "start": "312520",
    "end": "318000"
  },
  {
    "text": "included into control R and we're getting essentially out of the box a control rant Matrix Cent go matric and",
    "start": "318000",
    "end": "324400"
  },
  {
    "text": "go metrix and um essentially for all of those we have",
    "start": "324400",
    "end": "329919"
  },
  {
    "text": "a configuration upstream and we can just use it and one bonus on top is that we also already have dashboards so for",
    "start": "329919",
    "end": "336120"
  },
  {
    "text": "example we have a control runtime dashboard which should work with every control runtime based controller and you don't have to",
    "start": "336120",
    "end": "342919"
  },
  {
    "text": "anything just deploy our stuff scrape the metrics and that's it uh then for",
    "start": "342919",
    "end": "348000"
  },
  {
    "text": "profiling we also using uh the metrix server included into controller on time",
    "start": "348000",
    "end": "353919"
  },
  {
    "text": "and uh then we use par to regularly scrape the metrics from our sorry uh",
    "start": "353919",
    "end": "359240"
  },
  {
    "text": "from from our uh profile endpoint then for tracing you actually have to do some work so you have to instrument your",
    "start": "359240",
    "end": "365280"
  },
  {
    "text": "controller um but you can focus on the once which are actually slow and just add more and more over time um here we",
    "start": "365280",
    "end": "371840"
  },
  {
    "text": "do it similar as for metric basically we have Parker running and par par regularly uh just gets the profiles from",
    "start": "371840",
    "end": "379080"
  },
  {
    "text": "the sorry um from our controllers and stores them so that we can take a look over",
    "start": "379080",
    "end": "385199"
  },
  {
    "text": "time how our profiles evolve um then for logs",
    "start": "385199",
    "end": "390440"
  },
  {
    "text": "um you hopefully already have locks um and basically if you see during your investigation that you need more locks",
    "start": "390440",
    "end": "395639"
  },
  {
    "text": "you can just add more but in general um it's probably good enough what you already have and we using um prom tail",
    "start": "395639",
    "end": "403039"
  },
  {
    "text": "to ship the locks to L Kei and then um essentially uh we take a look at the locks via",
    "start": "403039",
    "end": "409120"
  },
  {
    "text": "grafana um yeah uh the nice thing is because we showing locks and traces via",
    "start": "409120",
    "end": "416840"
  },
  {
    "text": "grafana um we can basically cross correlate them so we can see which traces are matching with which locks and",
    "start": "416840",
    "end": "422560"
  },
  {
    "text": "investigate um why reconciles are slow uh then",
    "start": "422560",
    "end": "428039"
  },
  {
    "text": "automation here similar as above you probably already have some sort of end to end test and you can basically extend",
    "start": "428039",
    "end": "433879"
  },
  {
    "text": "them to just have scale test by uh creating a lot of clust in our case a lot of clusters at the same time and",
    "start": "433879",
    "end": "439240"
  },
  {
    "text": "then you have your scale test um and for mock uh that's a bit more work so what",
    "start": "439240",
    "end": "445120"
  },
  {
    "text": "we did essentially is we implemented um entire fake in infrastructure provider",
    "start": "445120",
    "end": "451039"
  },
  {
    "text": "uh which creates clusters and machines just in memory and simulates um an entire workload cluster",
    "start": "451039",
    "end": "458280"
  },
  {
    "start": "458000",
    "end": "503000"
  },
  {
    "text": "essentially great so we now we can now enter in the in the cor of the",
    "start": "458280",
    "end": "464120"
  },
  {
    "text": "presentation and basically talk about how we scaled up cluster API to to th000",
    "start": "464120",
    "end": "470120"
  },
  {
    "text": "Cluster so the first step which is more important than what people usually think",
    "start": "470120",
    "end": "475479"
  },
  {
    "text": "is to define a goal and we use the metric the class provisioning time and",
    "start": "475479",
    "end": "480960"
  },
  {
    "text": "we Define our our goal uh in this way so",
    "start": "480960",
    "end": "486720"
  },
  {
    "text": "the cluster provision time must must remain almost constant from the first",
    "start": "486720",
    "end": "492039"
  },
  {
    "text": "cluster till the last cluster so we want this time to be constant uh scaling up",
    "start": "492039",
    "end": "499840"
  },
  {
    "text": "and yeah guess what we did it so at the",
    "start": "499840",
    "end": "505840"
  },
  {
    "start": "503000",
    "end": "570000"
  },
  {
    "text": "end basically uh if you compare the average provisioning time from the first",
    "start": "505840",
    "end": "512039"
  },
  {
    "text": "100 machine to the last machine there is a neglectable increase of the",
    "start": "512039",
    "end": "517599"
  },
  {
    "text": "two% and uh as you can see all all during the test the provisioning time",
    "start": "517599",
    "end": "523360"
  },
  {
    "text": "was almost constant uh I remember we were using a in memory provider cluster",
    "start": "523360",
    "end": "529480"
  },
  {
    "text": "provision is just above 1 minute so we were going very very very fast we were",
    "start": "529480",
    "end": "535240"
  },
  {
    "text": "really being aggressive uh this is great we managed to do it but the I think the most",
    "start": "535240",
    "end": "542480"
  },
  {
    "text": "interesting part and this is what we want to talk about in the next slide is how we manage basically to keep cluster",
    "start": "542480",
    "end": "550240"
  },
  {
    "text": "performance to keep the system responsive from why scaling up and also",
    "start": "550240",
    "end": "557160"
  },
  {
    "text": "after scaling up while while running at scale and in order to do so it is",
    "start": "557160",
    "end": "562240"
  },
  {
    "text": "important to have a common understanding common of how controller works and this",
    "start": "562240",
    "end": "568480"
  },
  {
    "text": "is what we're talking in the next slide Yeah so basically starting with really like controller Basics so let's just",
    "start": "568480",
    "end": "574880"
  },
  {
    "start": "570000",
    "end": "620000"
  },
  {
    "text": "first take a look how a controller actually works um that's really a simplified view just to be clear uh so",
    "start": "574880",
    "end": "581120"
  },
  {
    "text": "basically what we have is U we have um uh events coming from API server so objects are getting created updated or",
    "start": "581120",
    "end": "587680"
  },
  {
    "text": "deleted they are essentially nend queed uh in the queue and then we have um some workers uh continuously Recon taking",
    "start": "587680",
    "end": "594959"
  },
  {
    "text": "elements from that objects from that queue and reconciling them um we can have multiple workers which we call here",
    "start": "594959",
    "end": "601920"
  },
  {
    "text": "concurrency and yeah that's the basic model one",
    "start": "601920",
    "end": "607720"
  },
  {
    "text": "more okay um and the main performance characteristic of a controller is essentially um the latency between a an",
    "start": "607720",
    "end": "614880"
  },
  {
    "text": "object getting created update or deleted and until it's successfully reconciled yeah um so we uh set up this formula",
    "start": "614880",
    "end": "622800"
  },
  {
    "start": "620000",
    "end": "645000"
  },
  {
    "text": "here which is basically the number of objects in a que divided by the concurrency and then multiply it with",
    "start": "622800",
    "end": "628160"
  },
  {
    "text": "the Recon curation so very simple example let's say we have 2,000 clusters uh we have 10 workers which means every",
    "start": "628160",
    "end": "634079"
  },
  {
    "text": "worker has to reconcile through 200 clusters And if every one of those takes three seconds then we need 10 minutes",
    "start": "634079",
    "end": "640320"
  },
  {
    "text": "just to reconcile for 2,000 clusters so you might ask yourself is",
    "start": "640320",
    "end": "646200"
  },
  {
    "text": "that like a real realistic scenario that we have all of them at the same time in the queue uh the answer is yes",
    "start": "646200",
    "end": "652079"
  },
  {
    "text": "unfortunately um because control rum has something called a periodic resn which essentially means um when this resn",
    "start": "652079",
    "end": "658440"
  },
  {
    "text": "happens uh every single existing object that we have in those case um every single cluster is getting ened in the",
    "start": "658440",
    "end": "664680"
  },
  {
    "text": "que uh on top of that um we also have sometimes the case that basically our reconcile uh code at at the end decides",
    "start": "664680",
    "end": "671160"
  },
  {
    "text": "oh uh this clust is not actually finished we have to reconcile that one again uh and then we use req after which",
    "start": "671160",
    "end": "677279"
  },
  {
    "text": "means it's just get it added back in a queue um so basically the important",
    "start": "677279",
    "end": "682360"
  },
  {
    "text": "thing is that whenever a recq happens sorry whenever reing periodic resing happens uh we have to reconcile all the",
    "start": "682360",
    "end": "689320"
  },
  {
    "text": "objects in Q as fast as we can so that the Q is empty again so just to one back",
    "start": "689320",
    "end": "695560"
  },
  {
    "text": "um if you look at this diagram what you can essentially see um the paks are um",
    "start": "695560",
    "end": "701240"
  },
  {
    "text": "uh periodic rings and within like 15 or 30 seconds uh we're getting the que back",
    "start": "701240",
    "end": "706880"
  },
  {
    "text": "down to zero so you can imagine basically if you um create a new cluster at the peak of this queue uh you",
    "start": "706880",
    "end": "712680"
  },
  {
    "text": "basically depend on how fast is this Cube going back down to zero until your class is actually reconciled and if that",
    "start": "712680",
    "end": "718399"
  },
  {
    "text": "takes like 10 10 or 20 minutes um you won't get anywhere because of course um one single Recon is not enough um until",
    "start": "718399",
    "end": "725240"
  },
  {
    "text": "an entire clust is created okay so now the question is uh",
    "start": "725240",
    "end": "730519"
  },
  {
    "text": "what can we do to improve the situation um and yeah I mean it's sort of obvious we have like those",
    "start": "730519",
    "end": "735680"
  },
  {
    "text": "three um option uh we have those three variables going into it so we can increase the concurrency of our workers",
    "start": "735680",
    "end": "742360"
  },
  {
    "text": "uh we can reduce the Recon duration and we can um reduce the objects in CU and",
    "start": "742360",
    "end": "748920"
  },
  {
    "text": "that's basically what large part of this talk is about okay so let's look at how we work",
    "start": "748920",
    "end": "756639"
  },
  {
    "start": "753000",
    "end": "897000"
  },
  {
    "text": "at on uh option one which is increased concurrency as uh as stepan just",
    "start": "756639",
    "end": "763160"
  },
  {
    "text": "explained basically uh a controller have many workers the number running in parallel",
    "start": "763160",
    "end": "769600"
  },
  {
    "text": "the number of of workers is is called concurrency and as you can imagine if we have only one worker you're this is not",
    "start": "769600",
    "end": "777639"
  },
  {
    "text": "good when work at perform perance because your queue get empty in very very slow in in sequential Manner and",
    "start": "777639",
    "end": "785920"
  },
  {
    "text": "so why not simply increase the number of of workers okay well it it turns out",
    "start": "785920",
    "end": "793560"
  },
  {
    "text": "that this is not a silver ballet because what happen is that the more cont uh",
    "start": "793560",
    "end": "799240"
  },
  {
    "text": "workers that you have running in parallel basically the more query the more things are running the more you are",
    "start": "799240",
    "end": "806519"
  },
  {
    "text": "eating the API server of of your faster so the risk if you increase if you have too many workers is that yeah your C",
    "start": "806519",
    "end": "814079"
  },
  {
    "text": "your queue get empty fast but another component of the cluster start",
    "start": "814079",
    "end": "819240"
  },
  {
    "text": "suffering so you you have to to find a good balance and what we learned is that",
    "start": "819240",
    "end": "825320"
  },
  {
    "text": "uh the default number of workers in cluster API is 10 and we learned that 10",
    "start": "825320",
    "end": "830680"
  },
  {
    "text": "is is is is quite good cover most of the KE and uh uh with 2000 cluster it work",
    "start": "830680",
    "end": "838480"
  },
  {
    "text": "very well with um reconcile Loop that take 200 250 millisecond in in this B",
    "start": "838480",
    "end": "846240"
  },
  {
    "text": "bper and your queue are most of the time uh empty and when there is a syn things",
    "start": "846240",
    "end": "852720"
  },
  {
    "text": "go go down in 10 15 seconds so this is a good value we increased this value only",
    "start": "852720",
    "end": "858800"
  },
  {
    "text": "for one of our reconcilers which is the kuber me control plane KU me contol plane is a very complex reconciler that",
    "start": "858800",
    "end": "866320"
  },
  {
    "text": "connect to the workloud cluster so it take a little bit longer than uh um 200",
    "start": "866320",
    "end": "872600"
  },
  {
    "text": "250 millisecond so we added more workers but we really did a lot of work on on",
    "start": "872600",
    "end": "879360"
  },
  {
    "text": "the kcp controller in order to make sure that even if we are running with many uh",
    "start": "879360",
    "end": "884920"
  },
  {
    "text": "with 50 uh kcp reconcile in parallel we are not uh",
    "start": "884920",
    "end": "890759"
  },
  {
    "text": "creating problem on on the API server and then we will explain how we did this",
    "start": "890759",
    "end": "896160"
  },
  {
    "text": "so option one is not a silver ballet then we have to move to option two",
    "start": "896160",
    "end": "901839"
  },
  {
    "start": "897000",
    "end": "953000"
  },
  {
    "text": "option two is basically to reduce the reconcile duration and as you can",
    "start": "901839",
    "end": "907120"
  },
  {
    "text": "imagine this is a little bit more complex than simply increasing the number of uh uh controller running in",
    "start": "907120",
    "end": "914160"
  },
  {
    "text": "parallel uh the good news is that uh we learned that if you follow the leads",
    "start": "914160",
    "end": "920880"
  },
  {
    "text": "that your metrics are giving you the leads that the profiling and tracing are giving you you can improve performance",
    "start": "920880",
    "end": "928319"
  },
  {
    "text": "by doing very small surgical changes so and this is",
    "start": "928319",
    "end": "935240"
  },
  {
    "text": "really effective when you combine this with uh mocks and automation because",
    "start": "935240",
    "end": "940920"
  },
  {
    "text": "basically you measure you find a bottl neck you try you address it and and you",
    "start": "940920",
    "end": "946560"
  },
  {
    "text": "repeat and the next slide is is about explaining how we did this in clust pii",
    "start": "946560",
    "end": "952360"
  },
  {
    "text": "so the first step was remove noise so what what was happening when we were",
    "start": "952360",
    "end": "958279"
  },
  {
    "start": "953000",
    "end": "1074000"
  },
  {
    "text": "starting to scaling up uh cluster API above 300 400 cluster we were getting a",
    "start": "958279",
    "end": "965519"
  },
  {
    "text": "lot of noise basically the performance of our controller were not deterministic",
    "start": "965519",
    "end": "972079"
  },
  {
    "text": "and we try we basically dig into what was going on and we traced the source of",
    "start": "972079",
    "end": "979480"
  },
  {
    "text": "this uh lack of determinism in uh in the",
    "start": "979480",
    "end": "984600"
  },
  {
    "text": "client side rating of go what is the client side rating so every client go",
    "start": "984600",
    "end": "990240"
  },
  {
    "text": "client like our controller as a mechanism which is client side rating this mechanism is",
    "start": "990240",
    "end": "997839"
  },
  {
    "text": "a safeguard uh that protect the API server from uh client that are too",
    "start": "997839",
    "end": "1003880"
  },
  {
    "text": "aggressive it basically ensure the stability of the entire system so it is",
    "start": "1003880",
    "end": "1009079"
  },
  {
    "text": "a good server to have and in C API the default rate limit is 20 query per",
    "start": "1009079",
    "end": "1015160"
  },
  {
    "text": "second plus uh uh 30 uh query uh burst",
    "start": "1015160",
    "end": "1020920"
  },
  {
    "text": "that mean that for a small uh wind of time you can have about 50 query but if",
    "start": "1020920",
    "end": "1030199"
  },
  {
    "text": "the number of query keep going basically rate limit starting slowing down your",
    "start": "1030199",
    "end": "1035400"
  },
  {
    "text": "query and this impact your reconciler your your reconciler randomly get picked up to be slowed down and so your system",
    "start": "1035400",
    "end": "1043360"
  },
  {
    "text": "is B there is a lot of noise you don't understand where the issue are uh um we",
    "start": "1043360",
    "end": "1049559"
  },
  {
    "text": "basically played a little bit around those number and we found out that for working with 2,000 cluster uh it is just",
    "start": "1049559",
    "end": "1056520"
  },
  {
    "text": "enough to imp to increase query per second to 100 and uh burst to 200 um",
    "start": "1056520",
    "end": "1064720"
  },
  {
    "text": "which is okay in a cluster API management cluster where cluster API itself is the main process running in in",
    "start": "1064720",
    "end": "1070400"
  },
  {
    "text": "in the cluster okay good so as soon as we uh",
    "start": "1070400",
    "end": "1075640"
  },
  {
    "start": "1074000",
    "end": "1119000"
  },
  {
    "text": "get rid of the noise the next step is okay let's find the first bottleneck the first reconciler that that we have to",
    "start": "1075640",
    "end": "1082919"
  },
  {
    "text": "work on and this was pretty easy because without noise you you simply look at the",
    "start": "1082919",
    "end": "1090120"
  },
  {
    "text": "reconcile duration uh metrix that you get from controller and time and you pick the the slowest one in this case it",
    "start": "1090120",
    "end": "1097159"
  },
  {
    "text": "is the yellow one that is clearly is is not performing like the the others and",
    "start": "1097159",
    "end": "1104360"
  },
  {
    "text": "um the next slide show how uh uh how we are we we work at on we we know which",
    "start": "1104360",
    "end": "1113120"
  },
  {
    "text": "cons we have to improve then how we can actually improve",
    "start": "1113120",
    "end": "1118480"
  },
  {
    "text": "it and uh the first pattern of problem that we start uh finding out is that uh",
    "start": "1118480",
    "end": "1126960"
  },
  {
    "text": "when looking at uh at profiles we were seeing uh uh slow operation repeated",
    "start": "1126960",
    "end": "1135640"
  },
  {
    "text": "many times and uh if you think about it it it",
    "start": "1135640",
    "end": "1141200"
  },
  {
    "text": "is quite common we as a software engineer we like develop utility and then we reuse them all around the code",
    "start": "1141200",
    "end": "1148799"
  },
  {
    "text": "so that mean that if you have a utility that does not perform well you start seeing pattern like the one shown in",
    "start": "1148799",
    "end": "1155120"
  },
  {
    "text": "this graph that where there is this uh time consuming operation which is repeated for time in this case it is",
    "start": "1155120",
    "end": "1162200"
  },
  {
    "text": "again the kcp controller which is uh connecting to atcd to First least a",
    "start": "1162200",
    "end": "1168440"
  },
  {
    "text": "member of the cluster and then connect to three member so four call to a tcd",
    "start": "1168440",
    "end": "1174080"
  },
  {
    "text": "and what is happening is is kind of hard to read is that for each connection we",
    "start": "1174080",
    "end": "1179520"
  },
  {
    "text": "were creating a private key which is a time consuming operation so how we solve",
    "start": "1179520",
    "end": "1185919"
  },
  {
    "text": "this simply by creating one key ons and reusing for for for many C by doing this",
    "start": "1185919",
    "end": "1192600"
  },
  {
    "text": "simple optimization we we found similar problem when creating kubernetes cluster and uh other kind of expensive operation",
    "start": "1192600",
    "end": "1199679"
  },
  {
    "text": "but yeah by using doing some simple caching it was possible basically to reduce the reconcile time of this",
    "start": "1199679",
    "end": "1206200"
  },
  {
    "text": "controller by 70 5% okay so the next thing we found um",
    "start": "1206200",
    "end": "1213080"
  },
  {
    "text": "was essentially API CS so um obviously controllers are using clients uh to talk",
    "start": "1213080",
    "end": "1218880"
  },
  {
    "text": "to the API server and to read and write data and um the more complex the controller gets um yeah the more calls",
    "start": "1218880",
    "end": "1225400"
  },
  {
    "text": "we get basically automatically um and uh that has a huge impact on recon durations um one uh one",
    "start": "1225400",
    "end": "1232280"
  },
  {
    "text": "reason is um because of network latency but also because the API is so simply needs time to answer our requests um if",
    "start": "1232280",
    "end": "1238720"
  },
  {
    "text": "you look at this picture um that is a trace from the kcp controller um and I think that's only a subset of what can",
    "start": "1238720",
    "end": "1245679"
  },
  {
    "text": "happen um and if you see like at the at the at the top of the of the uh Trace",
    "start": "1245679",
    "end": "1251799"
  },
  {
    "text": "that's B same entire Recon duration and basically every bar which is a little bit wider is actually an API call so if",
    "start": "1251799",
    "end": "1257080"
  },
  {
    "text": "you look at this um you can say like 80 90% of uh the Recon duration of this Casp controller is just doing API CS",
    "start": "1257080",
    "end": "1263360"
  },
  {
    "text": "against the API server um and then the question essentially how can we improve this um and ideally also while improving",
    "start": "1263360",
    "end": "1270120"
  },
  {
    "text": "this how can we reduce the load on the API server um so first we have to uh take a",
    "start": "1270120",
    "end": "1275720"
  },
  {
    "start": "1274000",
    "end": "1330000"
  },
  {
    "text": "step back and uh take a look at how the client usually works so if you just take like a regular client go client or um if",
    "start": "1275720",
    "end": "1282520"
  },
  {
    "text": "you um yeah or yeah Al the the if you just create a controller client by",
    "start": "1282520",
    "end": "1288600"
  },
  {
    "text": "yourself it also does the same thing so um if you call this client to just in this case read or write a cluster it",
    "start": "1288600",
    "end": "1295200"
  },
  {
    "text": "just goes directly to the API server um which is obviously not great um what control RM is doing if you just uh take",
    "start": "1295200",
    "end": "1301919"
  },
  {
    "text": "the default client that control RM gives you is that it essentially um is using a cache for read calls so the right calls",
    "start": "1301919",
    "end": "1308880"
  },
  {
    "text": "are still going directly to the API server but all the read calls are just hitting a local cache um and returning",
    "start": "1308880",
    "end": "1315600"
  },
  {
    "text": "whatever is in that cache um to fill that cache um the contr time cache is uh",
    "start": "1315600",
    "end": "1321320"
  },
  {
    "text": "is running in formers and reflectors which are just listing and watching objects and then storing them in a local cach sorry in a local store um yeah so",
    "start": "1321320",
    "end": "1330880"
  },
  {
    "text": "um in clust API in general we basically use um this default controller time client almost everywhere which means um",
    "start": "1330880",
    "end": "1337679"
  },
  {
    "text": "theoretically almost all our read calls should be already cached uh but it's not that easy um so first of all I already",
    "start": "1337679",
    "end": "1344799"
  },
  {
    "text": "mentioned it right CS are never cached so the only thing we can do about write C is uh just trying to make sure that um",
    "start": "1344799",
    "end": "1350520"
  },
  {
    "text": "if you have a single reconcile we don't write the same object five times or something like that because yeah uh that's not really necessary and for read",
    "start": "1350520",
    "end": "1357559"
  },
  {
    "text": "calls there's one carat and that is essentially um if you use the regular types so like the cluster type or",
    "start": "1357559",
    "end": "1363039"
  },
  {
    "text": "something like that they are cached by default but if you use unstructured they're not cached by default uh you can",
    "start": "1363039",
    "end": "1368480"
  },
  {
    "text": "fix this um by configuring control Anem accordingly but yeah the default behavior is is basically that they're",
    "start": "1368480",
    "end": "1374760"
  },
  {
    "text": "not cached um and the tricky thing about cluster API at Le CL core cluster apis",
    "start": "1374760",
    "end": "1380120"
  },
  {
    "text": "um that most of the objects we're using we don't actually know them because we just have contracts and then you don't know if it's like an aure machine or a",
    "start": "1380120",
    "end": "1386000"
  },
  {
    "text": "VP machine so we use unstructured everywhere and that was a major major problem for performance so the biggest",
    "start": "1386000",
    "end": "1391960"
  },
  {
    "text": "improvements we made is just by making sure that U using um yeah cach for read",
    "start": "1391960",
    "end": "1397760"
  },
  {
    "text": "calls um everywhere um of course there are uh there's a trade-off there and the",
    "start": "1397760",
    "end": "1402919"
  },
  {
    "text": "trade-off is that of course your memory usage goes up um but it still seemed reasonable for us so when we we were",
    "start": "1402919",
    "end": "1408360"
  },
  {
    "text": "using um when we had like the environment with 2,000 clusters we had like something between two and 4 GB of",
    "start": "1408360",
    "end": "1413679"
  },
  {
    "text": "memory usage for a core controller which seems fine um of course it depends a little bit on how big your clusters are",
    "start": "1413679",
    "end": "1419799"
  },
  {
    "text": "the exact topology but in general it seemed like a worthy trade-off and then of course we using a",
    "start": "1419799",
    "end": "1425720"
  },
  {
    "text": "cache so the standard problem is uh that the objects in the Cache can be stale um",
    "start": "1425720",
    "end": "1430960"
  },
  {
    "text": "but um mean we took a closer look at all the places where we changed this um and",
    "start": "1430960",
    "end": "1436000"
  },
  {
    "text": "I would say in general it's fine because because what usually happens is that even if your cash a stale um at some",
    "start": "1436000",
    "end": "1441360"
  },
  {
    "text": "point you will get an update event for that cash for that stale object and then you will get another reconcile which",
    "start": "1441360",
    "end": "1447480"
  },
  {
    "text": "eventually um reconciles like with the UP to-date State of your object so that wasn't really a problem for us to just",
    "start": "1447480",
    "end": "1453640"
  },
  {
    "text": "use the cash every okay so we basically talked about uh",
    "start": "1453640",
    "end": "1460600"
  },
  {
    "start": "1456000",
    "end": "1517000"
  },
  {
    "text": "increasing concurrency we talk about how to improve reconcile time the third option is to reduce the number of object",
    "start": "1460600",
    "end": "1466760"
  },
  {
    "text": "in the queue and uh if you remember for the previous slide we don't have full control on this one for sure we cannot",
    "start": "1466760",
    "end": "1473360"
  },
  {
    "text": "control how many cluster the user is changing upgrading or creating or elating for sure we cannot control um",
    "start": "1473360",
    "end": "1481960"
  },
  {
    "text": "the controller on time sync yeah eventually we can make a reyn less frequent but sooner or later a reyn has",
    "start": "1481960",
    "end": "1488960"
  },
  {
    "text": "to happen and and so the only things that we can control is how our",
    "start": "1488960",
    "end": "1494320"
  },
  {
    "text": "controller add back object to the que and they it turns now that the controller when you develop a controller",
    "start": "1494320",
    "end": "1501080"
  },
  {
    "text": "and your concile finish you can basically return three type of answer one is Success uh my object is up up to",
    "start": "1501080",
    "end": "1508200"
  },
  {
    "text": "desired State forget about it the other two are uh reue uh with be off and Rue",
    "start": "1508200",
    "end": "1515600"
  },
  {
    "text": "after so how we use them so we use Rue with beof for errors and this is fine",
    "start": "1515600",
    "end": "1522840"
  },
  {
    "start": "1517000",
    "end": "1622000"
  },
  {
    "text": "because when when your system has an error you want that the system recovery fast and",
    "start": "1522840",
    "end": "1528320"
  },
  {
    "text": "but if the error is is persistent basically you wanted that your",
    "start": "1528320",
    "end": "1533679"
  },
  {
    "text": "system reduce the frequence of a try and because the error is persistent and does",
    "start": "1533679",
    "end": "1541120"
  },
  {
    "text": "not make sense to keep aming the the the system with new query uh the the the the last option is",
    "start": "1541120",
    "end": "1549320"
  },
  {
    "text": "recue after and when we are using it for instance in clust pii we provide machine",
    "start": "1549320",
    "end": "1554559"
  },
  {
    "text": "and when you create a machine then behind the scene of of when get created and so a way to wait for the machine",
    "start": "1554559",
    "end": "1561960"
  },
  {
    "text": "being created is that every 10 second you basically go and check if the machine is there but if you keep doing",
    "start": "1561960",
    "end": "1569880"
  },
  {
    "text": "this polling at scale what happen is that your system basically continue to",
    "start": "1569880",
    "end": "1575840"
  },
  {
    "text": "run this reconcile Loop that are just checking for something to happen and at",
    "start": "1575840",
    "end": "1582279"
  },
  {
    "text": "scale this this create noise this create load load of your system so what is the better wave to do these is to use",
    "start": "1582279",
    "end": "1589279"
  },
  {
    "text": "watches uh you you can think of watch like a notification is like uh when you",
    "start": "1589279",
    "end": "1595799"
  },
  {
    "text": "instruct the VM that whenever the VM get ready it send a notification back to",
    "start": "1595799",
    "end": "1600840"
  },
  {
    "text": "your Machine controller and this this notification is just another event in the queue and and this allows you to",
    "start": "1600840",
    "end": "1607520"
  },
  {
    "text": "keep your system idle doing nothing while waiting and then when something",
    "start": "1607520",
    "end": "1612760"
  },
  {
    "text": "get happen in your system you just react and this actually a a good way to reduce",
    "start": "1612760",
    "end": "1618840"
  },
  {
    "text": "uh what we have in the queue okay so uh reconcile best practices um that's",
    "start": "1618840",
    "end": "1624919"
  },
  {
    "start": "1622000",
    "end": "1740000"
  },
  {
    "text": "basically like a simplified view of how reconcile uh loop usually works um at the beginning we reading the the current",
    "start": "1624919",
    "end": "1631320"
  },
  {
    "text": "state um and also the desired State um then we compare the C to desired State",
    "start": "1631320",
    "end": "1636600"
  },
  {
    "text": "and then we align to theed state by by writing something in some way um so in the first phase what we would recommend",
    "start": "1636600",
    "end": "1643039"
  },
  {
    "text": "is um that try to read um all the objects that you I would say usually need for most of your code paths um so",
    "start": "1643039",
    "end": "1648840"
  },
  {
    "text": "you have them available and you can basically just pass them through to the functions where you need them because if you don't do that usually you just try",
    "start": "1648840",
    "end": "1654320"
  },
  {
    "text": "to read them at the various places multiple times um and yeah that's not really great especially if you're not",
    "start": "1654320",
    "end": "1660039"
  },
  {
    "text": "using um client caching um then definitely try to use client caching whenever you can so the difference",
    "start": "1660039",
    "end": "1665200"
  },
  {
    "text": "really microsc to milliseconds um from just reading low cach versus actually going against API Ser um but be aware of",
    "start": "1665200",
    "end": "1671760"
  },
  {
    "text": "the cach in cards and ideally really run run the scale test look at the traces see if you're actually using a cache um",
    "start": "1671760",
    "end": "1678000"
  },
  {
    "text": "that that really helps um then in the second phase um just try to avoid um duplicate expense operations so like the",
    "start": "1678000",
    "end": "1684320"
  },
  {
    "text": "example we had before so generating private Keys is um definitely something that you should not repeat if you can avoid it um and yeah whatever expensive",
    "start": "1684320",
    "end": "1691840"
  },
  {
    "text": "things you're doing probably just uh just take a look at the profile um and it should tell us uh should tell you um",
    "start": "1691840",
    "end": "1698080"
  },
  {
    "text": "where you're wasting your time and if there's something repeated in there um then try to write only once per",
    "start": "1698080",
    "end": "1703600"
  },
  {
    "text": "reconcile so what we usually doing in in cluster API for the current object that we reconcile is just at the beginning of",
    "start": "1703600",
    "end": "1709679"
  },
  {
    "text": "a reconcile function We have basically a defer so that um whenever that reconcile",
    "start": "1709679",
    "end": "1714760"
  },
  {
    "text": "finishes in some way it doesn't matter if it's an error or not we just do one patch call to this object um but the same applies to to other objects that",
    "start": "1714760",
    "end": "1721480"
  },
  {
    "text": "you potentially write just try to minimize the right CS there and then if applicable just try uh to use watches um",
    "start": "1721480",
    "end": "1729080"
  },
  {
    "text": "instead of constantly recing with something like 10 seconds or so uh doesn't always work but in a lot of",
    "start": "1729080",
    "end": "1735799"
  },
  {
    "text": "cases you can just avoid a lot of uh unnecessary Rec conserns okay great if you follow this",
    "start": "1735799",
    "end": "1741480"
  },
  {
    "start": "1740000",
    "end": "1846000"
  },
  {
    "text": "best practice your controller are kind of per out of the box but then",
    "start": "1741480",
    "end": "1747600"
  },
  {
    "text": "if you really have to do optimization there is a list of do and don't so first",
    "start": "1747600",
    "end": "1753120"
  },
  {
    "text": "do is get the right tool of the job without metric is not possible to do uh",
    "start": "1753120",
    "end": "1759360"
  },
  {
    "text": "performance Improvement without automation doing performance Improvement",
    "start": "1759360",
    "end": "1765240"
  },
  {
    "text": "become very long and not effective and it cost money uh Define measured goals",
    "start": "1765240",
    "end": "1772600"
  },
  {
    "text": "because at every iteration you you can check uh uh if you're making progress or",
    "start": "1772600",
    "end": "1777640"
  },
  {
    "text": "not and you can also Define when when you you are done uh invest time in",
    "start": "1777640",
    "end": "1785279"
  },
  {
    "text": "learning how controller and time and client go works because they provide the",
    "start": "1785279",
    "end": "1790480"
  },
  {
    "text": "tool to improve performance and the last do is uh iterate fast do more small",
    "start": "1790480",
    "end": "1797519"
  },
  {
    "text": "changes and then look at the system because every sometime a small changes",
    "start": "1797519",
    "end": "1802760"
  },
  {
    "text": "just change the behavior of your system and and it does not make sense to make a",
    "start": "1802760",
    "end": "1808360"
  },
  {
    "text": "big action of big plan just small change remove one button and measure again",
    "start": "1808360",
    "end": "1813480"
  },
  {
    "text": "repeat repeat and uh as fast as you can don't do is don't do optimization if",
    "start": "1813480",
    "end": "1823240"
  },
  {
    "text": "there is if you don't have a metrix that point clear clearly to a bottleneck",
    "start": "1823240",
    "end": "1829080"
  },
  {
    "text": "because if you change code based on guessing or whatever you risk that your",
    "start": "1829080",
    "end": "1835840"
  },
  {
    "text": "system become less performant or you risk to introduce unnecessary",
    "start": "1835840",
    "end": "1841600"
  },
  {
    "text": "bugs and with that we are done but I think that before opening",
    "start": "1841600",
    "end": "1848279"
  },
  {
    "start": "1846000",
    "end": "1912000"
  },
  {
    "text": "up for question uh I would like to thank you a couple of contributor that really helped in in this effort Christian",
    "start": "1848279",
    "end": "1855440"
  },
  {
    "text": "Slaughter which basically is driving all all the war for generating metrics out of crd and this war can be reused by",
    "start": "1855440",
    "end": "1863000"
  },
  {
    "text": "everyone for every crd we would like to thank you uh Leonard uh because it triggered a lot of",
    "start": "1863000",
    "end": "1870000"
  },
  {
    "text": "discussion about how to optimize uh controllers H we would like to thank you",
    "start": "1870000",
    "end": "1875120"
  },
  {
    "text": "kilan and yaji because they really helped in building up the Automation and",
    "start": "1875120",
    "end": "1880360"
  },
  {
    "text": "the mock provider that that made made it possible basically to implement to do",
    "start": "1880360",
    "end": "1885480"
  },
  {
    "text": "all all this this job in in three weeks and thank you everyone again for",
    "start": "1885480",
    "end": "1891960"
  },
  {
    "text": "attending if you are if you have question we are looking [Applause]",
    "start": "1891960",
    "end": "1902800"
  },
  {
    "text": "for yeah I think you have to walk to the microphone you have",
    "start": "1907519",
    "end": "1912840"
  },
  {
    "start": "1912000",
    "end": "2156000"
  },
  {
    "text": "question it's on uh I I think that one of the topology controllers was one of",
    "start": "1912840",
    "end": "1918440"
  },
  {
    "text": "the first to use server side apply I saw in that last slide or one of the last",
    "start": "1918440",
    "end": "1924600"
  },
  {
    "text": "slides that one of the ways you control how many times you write per reconcile Loop is using a deferred patch we do the",
    "start": "1924600",
    "end": "1932279"
  },
  {
    "text": "same thing and have in various cases run into some awkwardness interact like",
    "start": "1932279",
    "end": "1939000"
  },
  {
    "text": "awkward interactions between a deferred patch and server side apply do you guys",
    "start": "1939000",
    "end": "1944279"
  },
  {
    "text": "know if you ran into anything similar I can take that on the so we didn't really mention what we did with service at apply because that",
    "start": "1944279",
    "end": "1950399"
  },
  {
    "text": "happened like I don't know half a year ago or something um so top poliy control is really special case in cluster API um",
    "start": "1950399",
    "end": "1957000"
  },
  {
    "text": "so we did our totally different custom solution to um to make this",
    "start": "1957000",
    "end": "1962279"
  },
  {
    "text": "performant um essentially what we're doing is we're getting like the current state we're Computing the desired State and then we do some sort of hashing to",
    "start": "1962279",
    "end": "1968279"
  },
  {
    "text": "figure out if if we even have to do a service at apply and we avoid it at all cost and that is basically the thing",
    "start": "1968279",
    "end": "1973440"
  },
  {
    "text": "that makes the poy controller performant that in a lot of cases we just don't do anything because we just know that",
    "start": "1973440",
    "end": "1979880"
  },
  {
    "text": "nothing changed so there is no reason um to apply again so that's that's definely no defer patch nothing in there it's um",
    "start": "1979880",
    "end": "1986559"
  },
  {
    "text": "basic custom cach that we build there which tries to figure out if we even have to do a service plan I think this",
    "start": "1986559",
    "end": "1992440"
  },
  {
    "text": "the summary is that if you can avoid an operation it is the best of invation that you can do and so we avoid the",
    "start": "1992440",
    "end": "1998760"
  },
  {
    "text": "server side apply whenever we can so thank you for the uh talk I think",
    "start": "1998760",
    "end": "2005000"
  },
  {
    "text": "a lot of uh useful learning out of how to optimize the controller in general uh my question is more towards um the uh",
    "start": "2005000",
    "end": "2012919"
  },
  {
    "text": "cluster API project um there is a uh opsource uh project that was introduced",
    "start": "2012919",
    "end": "2020840"
  },
  {
    "text": "inside uh uh the uh CN uh CF um called",
    "start": "2020840",
    "end": "2026919"
  },
  {
    "text": "open cluster management ocm so I really like to know if you guys",
    "start": "2026919",
    "end": "2034240"
  },
  {
    "text": "have looked at that and what is the difference between ocm and cluster API because both are saying that um we",
    "start": "2034240",
    "end": "2043159"
  },
  {
    "text": "manage and maintain clusters kubernetes clusters or uh to be honest I uh asked",
    "start": "2043159",
    "end": "2049679"
  },
  {
    "text": "exactly that question at the last cucon at the open cluster management kiosk and I don't remember um if I remember",
    "start": "2049679",
    "end": "2055839"
  },
  {
    "text": "correctly um open cluster management is used in some redhead products and potentially in combination with cluster",
    "start": "2055839",
    "end": "2061320"
  },
  {
    "text": "API but maybe just after the talk just ask like Vince or someone sitting around there they hope hopefully not the",
    "start": "2061320",
    "end": "2068480"
  },
  {
    "text": "answer so ocm itself is the open source project inside uh cncf right Cloud",
    "start": "2068480",
    "end": "2075200"
  },
  {
    "text": "native foundation and then the product Red Hat brought out of is the advanced cluster management right um and normally",
    "start": "2075200",
    "end": "2082040"
  },
  {
    "text": "red hat is really good at that they do open source and then bring products out of it um but I always was confused and I",
    "start": "2082040",
    "end": "2089358"
  },
  {
    "text": "wanted to see if you guys uh were more into it understanding what is the difference between the two and I know",
    "start": "2089359",
    "end": "2095878"
  },
  {
    "text": "cluster API was backed by tanzu and VMware so other than the Rivalry but about the open source part of these both",
    "start": "2095879",
    "end": "2103400"
  },
  {
    "text": "uh projects where do they meet and where do they differentiate so that's yeah",
    "start": "2103400",
    "end": "2109599"
  },
  {
    "text": "unfortunately we we just don't know no just one clarification cust API is a community project uh and currently there",
    "start": "2109599",
    "end": "2118440"
  },
  {
    "text": "are 80 company contributing to it yes when is including including red",
    "start": "2118440",
    "end": "2125480"
  },
  {
    "text": "including redet Microsoft many others so uh I don't have contest about the the",
    "start": "2125480",
    "end": "2132440"
  },
  {
    "text": "product but what I want to make clear that it is a community project and everyone is helping to make it",
    "start": "2132440",
    "end": "2139880"
  },
  {
    "text": "possible okay we have another 30 seconds if you have another question",
    "start": "2141160",
    "end": "2149000"
  },
  {
    "text": "40 great thank you everyone for attending thanks enjoy",
    "start": "2149680",
    "end": "2155359"
  },
  {
    "text": "kuon",
    "start": "2155359",
    "end": "2158359"
  }
]
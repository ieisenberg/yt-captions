[
  {
    "text": "good afternoon thank you for coming to this session my name is Larry Calo I'm filling in for Diane mu another speaker",
    "start": "1240",
    "end": "7759"
  },
  {
    "text": "but I'm going to just introduce vinotini Raju uh who is the women winner of the",
    "start": "7759",
    "end": "14440"
  },
  {
    "text": "women B2B Tech award last year and she's going to present a fantastic slide deck",
    "start": "14440",
    "end": "21160"
  },
  {
    "text": "and a demo on Genna in operations so with that we know is going to introduce",
    "start": "21160",
    "end": "27480"
  },
  {
    "text": "herself and introduce the slides and the concept and I'm sure you're going to go from out from here with a lot of good",
    "start": "27480",
    "end": "35000"
  },
  {
    "text": "information on how to use gen in operations you know up to",
    "start": "35000",
    "end": "40320"
  },
  {
    "text": "you thank you so much Larry uh for a great introduction hello everyone very good",
    "start": "42039",
    "end": "49719"
  },
  {
    "text": "afternoon looks like we have a full room here I'm so excited to see you all and",
    "start": "49719",
    "end": "55800"
  },
  {
    "text": "I'll try my best to keep up to the expectations so what are we going to talk today",
    "start": "55800",
    "end": "63320"
  },
  {
    "text": "um jna wow that's a happening thing now and",
    "start": "63320",
    "end": "69560"
  },
  {
    "text": "we we are all in the kuet space and I'm trying to put these two technologies together so I'm going to be talking",
    "start": "69560",
    "end": "76799"
  },
  {
    "text": "about using jna to instigate precision and efficiency in kubernetes operations",
    "start": "76799",
    "end": "83759"
  },
  {
    "text": "that's a pretty loaded topic so what I have done is um you know created a short",
    "start": "83759",
    "end": "90119"
  },
  {
    "text": "agenda to give you a heads up on what I'll be covering um over the next 20 minutes so I'll do a short introduction",
    "start": "90119",
    "end": "98240"
  },
  {
    "text": "to the kubernetes landscape and the G and talk about some of the challenges",
    "start": "98240",
    "end": "105040"
  },
  {
    "text": "and the solutions that are available today and I'm going to propose an AI",
    "start": "105040",
    "end": "110240"
  },
  {
    "text": "governance framework uh for it uh operations and I'll walk you through a",
    "start": "110240",
    "end": "116680"
  },
  {
    "text": "uh you know a troubleshooting use case with a simple uh you know kubernetes issue and then uh",
    "start": "116680",
    "end": "123840"
  },
  {
    "text": "show you a complete solution demo of how this whole thing will fit in followed by",
    "start": "123840",
    "end": "129280"
  },
  {
    "text": "a quick um Q&A so just a a quick word about who we",
    "start": "129280",
    "end": "137360"
  },
  {
    "text": "are so we are a loc Cod uh platform company uh we building an ID for",
    "start": "137360",
    "end": "142480"
  },
  {
    "text": "kubernetes making things simpler for um kuers users uh we are headquartered in",
    "start": "142480",
    "end": "148560"
  },
  {
    "text": "Bangalore but I I I live in Canada and um we have a distributed team we started",
    "start": "148560",
    "end": "154400"
  },
  {
    "text": "off as a devops consulting firm offering cicd automation for uh retail customers",
    "start": "154400",
    "end": "160800"
  },
  {
    "text": "across India and us and we also parall contributed and um maintain this project",
    "start": "160800",
    "end": "167519"
  },
  {
    "text": "called configurator which um helps you Version Control uh config maps and",
    "start": "167519",
    "end": "172760"
  },
  {
    "text": "secrets on kubernetes so since 2017 we are all platform company and we are on different",
    "start": "172760",
    "end": "179800"
  },
  {
    "text": "different marketplaces thanks to all our partners so we have about 1,600 plus",
    "start": "179800",
    "end": "184879"
  },
  {
    "text": "downloads across all these uh Marketplace um distributions let's dive in",
    "start": "184879",
    "end": "193400"
  },
  {
    "text": "um AI for kubernetes what's the necessity and how AI can help so this is",
    "start": "193400",
    "end": "200080"
  },
  {
    "text": "a slightly an outdated survey that was conducted by cncf in",
    "start": "200080",
    "end": "205640"
  },
  {
    "text": "2022 um but yeah the problem Still Remains right the training is one of the strongest inhibitors for the kubernetes",
    "start": "205640",
    "end": "213080"
  },
  {
    "text": "adoption and even if we are on kubernetes uh Still Still troubleshooting and maintaining is",
    "start": "213080",
    "end": "219200"
  },
  {
    "text": "really complex upskilling is uh difficult but at the same time we are",
    "start": "219200",
    "end": "224400"
  },
  {
    "text": "seeing a huge explosion of AI Solutions and we are readily able to see the value",
    "start": "224400",
    "end": "229439"
  },
  {
    "text": "that it brings to table so it's a great opportunity for us to put these two things together and find the value",
    "start": "229439",
    "end": "236799"
  },
  {
    "text": "immediately so we did a short survey last year um across the globe um a lot of U",
    "start": "236799",
    "end": "244439"
  },
  {
    "text": "platform engineering folks uh participated in this devops uh Engineers participated in this and we got about 48",
    "start": "244439",
    "end": "251280"
  },
  {
    "text": "responses uh to see where AI can contribute in uh solving kubernetes",
    "start": "251280",
    "end": "257880"
  },
  {
    "text": "issues so we can clearly make out like validating configurations troubleshooting failures monitoring and",
    "start": "257880",
    "end": "264440"
  },
  {
    "text": "detecting anomalies and then detecting security issues are four main areas where we saw like AI can add a value but",
    "start": "264440",
    "end": "272919"
  },
  {
    "text": "then what is preventing us from doing that so before getting into that I",
    "start": "272919",
    "end": "278080"
  },
  {
    "text": "really want to know how many of you are really evaluating AI in their",
    "start": "278080",
    "end": "285479"
  },
  {
    "text": "operations okay so how many of you are having challenges in your organizations",
    "start": "285960",
    "end": "291759"
  },
  {
    "text": "due to compliance issues",
    "start": "291759",
    "end": "297360"
  },
  {
    "text": "okay okay so is Gen AI really suitable for uh",
    "start": "298639",
    "end": "304680"
  },
  {
    "text": "it operations that's a big question I came across this very interesting code uh",
    "start": "304680",
    "end": "311240"
  },
  {
    "text": "from Santos Bala a computer science Professor from Jia Tech it say a language model is just a",
    "start": "311240",
    "end": "319080"
  },
  {
    "text": "probabilistic model of the world so it's not deterministic so which means it",
    "start": "319080",
    "end": "324919"
  },
  {
    "text": "hallucinates it can give you false positives um and it's not not real time",
    "start": "324919",
    "end": "330400"
  },
  {
    "text": "so we may not be able to get all the real-time information that is available out there and we cannot make decisions",
    "start": "330400",
    "end": "336680"
  },
  {
    "text": "based of what the AI responds because um there is a lock lack of accountability",
    "start": "336680",
    "end": "343520"
  },
  {
    "text": "we need a constant supervision of what happens with the AI and how we consume",
    "start": "343520",
    "end": "348560"
  },
  {
    "text": "it the first part of the problem I think we can very well address uh through some",
    "start": "348560",
    "end": "354160"
  },
  {
    "text": "some of the things that we can um outright control for instance the prompt engineering the model that we choose or",
    "start": "354160",
    "end": "360560"
  },
  {
    "text": "build the temperatures which actually decide how creative AI can become so",
    "start": "360560",
    "end": "366039"
  },
  {
    "text": "these attributes to an extent we have a better control and we can Implement something called the uh retrieval",
    "start": "366039",
    "end": "372199"
  },
  {
    "text": "augmented generation called Rag and uh have Sur apis which can search Google",
    "start": "372199",
    "end": "378479"
  },
  {
    "text": "and then give you real-time data by creating a pipeline with these Technologies we can have some real time",
    "start": "378479",
    "end": "384919"
  },
  {
    "text": "and domain specific U information as well so I'll walk you through this drag in a while uh but then yeah this problem",
    "start": "384919",
    "end": "391400"
  },
  {
    "text": "to an extent can be solved so the most of the times we talk",
    "start": "391400",
    "end": "396599"
  },
  {
    "text": "about the halogenation and getting the real-time data but often we miss out on",
    "start": "396599",
    "end": "402280"
  },
  {
    "text": "the last problem which is very critical for operations which is the lack of",
    "start": "402280",
    "end": "409080"
  },
  {
    "text": "accountability so we need a strong AI governance if we have to consume AI",
    "start": "409080",
    "end": "414319"
  },
  {
    "text": "within our it operations we cannot just let AI make the decisions for us",
    "start": "414319",
    "end": "421280"
  },
  {
    "text": "so for instance like let's go over each one of these uh problems and I'm going to give you a very simple example I",
    "start": "421280",
    "end": "427319"
  },
  {
    "text": "could have chosen kubernetes issues but here I I'll do that a little later I want to show pictorially you know what",
    "start": "427319",
    "end": "433319"
  },
  {
    "text": "it signifies for instance I have used a chat GPD to create a flowchart and it it",
    "start": "433319",
    "end": "439240"
  },
  {
    "text": "gave me some random image then I changed the prompt to create a line diagram and it's able to show something you know uh",
    "start": "439240",
    "end": "446440"
  },
  {
    "text": "different but still not um you know uh to the",
    "start": "446440",
    "end": "451639"
  },
  {
    "text": "expectations so the last one is I changed Again The Prompt with a little more context of what I really expect out",
    "start": "451639",
    "end": "458560"
  },
  {
    "text": "of AI and this time it had some meaningful outcome let's compare this",
    "start": "458560",
    "end": "464400"
  },
  {
    "text": "with llama 2 7B and you see across all these it was not able to generate",
    "start": "464400",
    "end": "470159"
  },
  {
    "text": "anything that is Meaningful but then when when we have a fine tune llama to along with the proper",
    "start": "470159",
    "end": "477960"
  },
  {
    "text": "template we were able to get a better response so what this signifies is that",
    "start": "477960",
    "end": "483840"
  },
  {
    "text": "we need a good prompt we need a fine-tune model which is very domain",
    "start": "483840",
    "end": "491080"
  },
  {
    "text": "specific so here I'm proposing okay we have seen the model and the prompt now let's move on to the you know the",
    "start": "491560",
    "end": "498280"
  },
  {
    "text": "governance and I'm proposing a governance for AI where you know it gives a certain level of comfort uh for",
    "start": "498280",
    "end": "505639"
  },
  {
    "text": "us to consume it in our operations in kuus landscape we have so",
    "start": "505639",
    "end": "512000"
  },
  {
    "text": "many tools third party tools and we have to collect the context across these tools in order to put for uh for put",
    "start": "512000",
    "end": "519120"
  },
  {
    "text": "forth a meaningful you know prompt so there is a cognitive overload uh in",
    "start": "519120",
    "end": "526279"
  },
  {
    "text": "generating those contexts the second aspect of is before we share anything with the AI we'll have",
    "start": "526279",
    "end": "532600"
  },
  {
    "text": "to redact the sensitive information and then I haven't come",
    "start": "532600",
    "end": "538959"
  },
  {
    "text": "across so so many of the uh Solutions where you know the user gets to review and approve anything that goes to the uh",
    "start": "538959",
    "end": "547800"
  },
  {
    "text": "AI so we need this this is a very important uh step so we have a better control of what happens and what we",
    "start": "547800",
    "end": "555200"
  },
  {
    "text": "actually send it to the AI and once we get the response from the AI um we have",
    "start": "555200",
    "end": "560399"
  },
  {
    "text": "to tag those responses to say this is uh generated by Ai and we need to use it",
    "start": "560399",
    "end": "565560"
  },
  {
    "text": "with discretion the final step is to maintain a complete history of all the uh",
    "start": "565560",
    "end": "571160"
  },
  {
    "text": "responses and the inputs so we can go and do an audit at a later point in time",
    "start": "571160",
    "end": "576519"
  },
  {
    "text": "uh if at all we have to uh look at things all right so I think we have",
    "start": "576519",
    "end": "583200"
  },
  {
    "text": "summarized to summarize what we have seen we have seen the prompt we have seen the uh models we have seen the",
    "start": "583200",
    "end": "589560"
  },
  {
    "text": "workflow or the governance now I'm going to do a simple use case of how do we go",
    "start": "589560",
    "end": "595360"
  },
  {
    "text": "about troubleshooting an issue in the kubernetes and how the AI solution can",
    "start": "595360",
    "end": "601320"
  },
  {
    "text": "help so here I have um a simple resource which is a a Java application deployed",
    "start": "601320",
    "end": "607880"
  },
  {
    "text": "as a pod and um it actually has a uh command to run app. jar which is",
    "start": "607880",
    "end": "615800"
  },
  {
    "text": "actually not present in the image and uh there is a volume Mount that mounts that",
    "start": "615800",
    "end": "621519"
  },
  {
    "text": "uh jar file into the Container since the jar file is not there um the container",
    "start": "621519",
    "end": "628279"
  },
  {
    "text": "doesn't start and it has unable to access the jar",
    "start": "628279",
    "end": "633240"
  },
  {
    "text": "file so I'm going to propose a rag pipeline architecture where we will be",
    "start": "633680",
    "end": "640480"
  },
  {
    "text": "able to solve this you know troubleshooting issue so I have built a data set from different kubernetes",
    "start": "640480",
    "end": "646720"
  },
  {
    "text": "sources scraped the data fed it into the uh pine cone DB and then I'm using a",
    "start": "646720",
    "end": "652440"
  },
  {
    "text": "llama 2 7B based model I used retriever QA and a prompt template specifically",
    "start": "652440",
    "end": "657959"
  },
  {
    "text": "built for troubleshooting and whatever we get out of this rack pipeline I'm uh doing a chaining of the",
    "start": "657959",
    "end": "664760"
  },
  {
    "text": "prompt and sending it to uh the representation layer which is mostly for",
    "start": "664760",
    "end": "670040"
  },
  {
    "text": "the ux so I have not included the uh the workflow here I'll show it as a complete",
    "start": "670040",
    "end": "676120"
  },
  {
    "text": "solution later on uh but then I want to show you the difference",
    "start": "676120",
    "end": "681560"
  },
  {
    "text": "uh of using a plane base model versus the rack pipeline so this is what uh",
    "start": "681560",
    "end": "687240"
  },
  {
    "text": "Lama 2 responded it came up with three solutions check the container has enough",
    "start": "687240",
    "end": "692839"
  },
  {
    "text": "memory which is nothing uh related to the problem verify that Java command is",
    "start": "692839",
    "end": "698000"
  },
  {
    "text": "currently uh configured again it's not related then check the class path yes that could actually uh contribute to the",
    "start": "698000",
    "end": "705120"
  },
  {
    "text": "problem and then uh you know check the network issues and things like that but most of it is incorrect because it's not",
    "start": "705120",
    "end": "713160"
  },
  {
    "text": "a fine-tune model um but if I have to fine tune or build a model of my own",
    "start": "713160",
    "end": "719279"
  },
  {
    "text": "then it takes a lot of effort so rag simplifies that you can just collect the sources build a uh you know a data set",
    "start": "719279",
    "end": "726480"
  },
  {
    "text": "and then you can have this uh really quick this is what we uh got from Alama",
    "start": "726480",
    "end": "732959"
  },
  {
    "text": "to 7B along with the rack pipeline so all the three scenarios fit in very well",
    "start": "732959",
    "end": "738360"
  },
  {
    "text": "with the problem that we have in hand the first one it says missing or incorrect file path then we have an",
    "start": "738360",
    "end": "744160"
  },
  {
    "text": "incorrect jar format so it could be corrupt and you may have an insufficient um permissions or Access Control issues",
    "start": "744160",
    "end": "751199"
  },
  {
    "text": "because we are doing a volume Mount now this is quite promising and this is exactly what we should you know count",
    "start": "751199",
    "end": "759920"
  },
  {
    "text": "upon now let's see how ID low code ID can actually work with AI and have a",
    "start": "759920",
    "end": "766680"
  },
  {
    "text": "complete solution on you know the troubleshooting low code actually bring can bring in some advantages so for",
    "start": "766680",
    "end": "772639"
  },
  {
    "text": "instance you can have a templated workflow um you can you can actually have all this context integration with",
    "start": "772639",
    "end": "779320"
  },
  {
    "text": "third party tools that you can pull in readily and have a context available for",
    "start": "779320",
    "end": "784800"
  },
  {
    "text": "the AI it can have an efficient uh prompt template and the benefit we get",
    "start": "784800",
    "end": "790399"
  },
  {
    "text": "out of that is a quick issue resolution we can build a context a knowledge based which I'm going to show you in a while",
    "start": "790399",
    "end": "797320"
  },
  {
    "text": "and then you can also have automation around support ticketing and other stuff so you see here on the left hand side I",
    "start": "797320",
    "end": "804120"
  },
  {
    "text": "have a catalog of uh different uh you know the context for instance the resource specific speci ification um",
    "start": "804120",
    "end": "810320"
  },
  {
    "text": "events logs metrics and so on and so forth and then we can feed that back",
    "start": "810320",
    "end": "815600"
  },
  {
    "text": "into the uh chat Bo and whatever outcome that we get we can capture that in the",
    "start": "815600",
    "end": "820880"
  },
  {
    "text": "form of documents uh so the runbook talks are essentially context aware",
    "start": "820880",
    "end": "827600"
  },
  {
    "text": "documentation that goes side by side with your kubernetes resource so it's very handy and then you can pull in that",
    "start": "827600",
    "end": "833759"
  },
  {
    "text": "information really quick and then you can also have a j ticket you can direct that to a j tiet and have some",
    "start": "833759",
    "end": "839800"
  },
  {
    "text": "automation around that okay so I'm going to show you a demo of what I have described so far um",
    "start": "839800",
    "end": "848160"
  },
  {
    "text": "I have a recorded demo as I couldn't show you a live demo um just give me a",
    "start": "848160",
    "end": "855920"
  },
  {
    "text": "moment uh I'm sorry if the isolution is not good enough but I I think it should",
    "start": "861079",
    "end": "866759"
  },
  {
    "text": "be fine okay so so I want to first walk you through the ID itself uh because",
    "start": "866759",
    "end": "873120"
  },
  {
    "text": "that forms the foundation for bringing in the context so this is a an ID where you can filter resources have a live",
    "start": "873120",
    "end": "880079"
  },
  {
    "text": "view of all the resources you can have consoles you can have the logs you can have multiple uh logs open you can edit",
    "start": "880079",
    "end": "887880"
  },
  {
    "text": "the yaml and then maintain you can also have um you know a schema form which is",
    "start": "887880",
    "end": "895320"
  },
  {
    "text": "a low code uh editor with side by-side documentation of mod mod ifying your",
    "start": "895320",
    "end": "901560"
  },
  {
    "text": "resources so let's talk about the AI here um I have two AI assistants",
    "start": "901560",
    "end": "906720"
  },
  {
    "text": "registed I have a chat GPT on a Lama Lang chain and I have a code repository",
    "start": "906720",
    "end": "912199"
  },
  {
    "text": "which has one runbook in it runbook Hub basically it's nothing but um a repo with the GP yaml file with the",
    "start": "912199",
    "end": "919399"
  },
  {
    "text": "specification of different selectors and what documentation goes with that so any",
    "start": "919399",
    "end": "924680"
  },
  {
    "text": "resource that matches this selector will get tagged with this document",
    "start": "924680",
    "end": "930000"
  },
  {
    "text": "so you can also build this from uh the solution UI or you can have this yaml file um you can build it uh from",
    "start": "930000",
    "end": "939040"
  },
  {
    "text": "scratch so I have two uh run books within this Hub so let's take a look at it in the UI later so I also have one",
    "start": "939040",
    "end": "947120"
  },
  {
    "text": "jira account now you can see that the runbook Hub has two documents two I mean",
    "start": "947120",
    "end": "952319"
  },
  {
    "text": "two uh run books in this Hub and it's attached to this cluster and in the Pod",
    "start": "952319",
    "end": "957759"
  },
  {
    "text": "pending it gets attached to anything um that is of a particular U label so this",
    "start": "957759",
    "end": "964720"
  },
  {
    "text": "documentation is generated by AI so we have a disclaimer at the bottom of this",
    "start": "964720",
    "end": "970199"
  },
  {
    "text": "whenever a new content is modified or generated by AI we have a disclaimer saying that this is generated by AI use",
    "start": "970199",
    "end": "977040"
  },
  {
    "text": "it with caution so we have tagged this let's go",
    "start": "977040",
    "end": "982319"
  },
  {
    "text": "back to the uh cluster and see how the resources get tagged so I can view the resources and I",
    "start": "982319",
    "end": "989959"
  },
  {
    "text": "can filter them based on the Run books so I have one uh image failure container",
    "start": "989959",
    "end": "995720"
  },
  {
    "text": "which gets tagged here and you have a side-by-side documentation to see um what could go",
    "start": "995720",
    "end": "1002639"
  },
  {
    "text": "wrong so you can use all the contexts that are available on the left hand side to pull in the information and then",
    "start": "1002639",
    "end": "1008440"
  },
  {
    "text": "enhance this even more sorry okay let's see um a another use",
    "start": "1008440",
    "end": "1016959"
  },
  {
    "text": "case the Java issue that I talked about so I have the uh application deployed in",
    "start": "1016959",
    "end": "1022279"
  },
  {
    "text": "this cluster let's um filter that resource and then see how we can go",
    "start": "1022279",
    "end": "1028160"
  },
  {
    "text": "about troubleshooting so I filter based on the Pod and I fetch the Pod called",
    "start": "1028160",
    "end": "1036558"
  },
  {
    "text": "Java failing or something yeah okay so let's uh open the chat UI",
    "start": "1036559",
    "end": "1044000"
  },
  {
    "text": "and um the redactor is on by default so anything that we add into the context we going to redact it so I'll uh you have a",
    "start": "1044000",
    "end": "1051960"
  },
  {
    "text": "catalog of all the um logs and metrics that you can pull in",
    "start": "1051960",
    "end": "1059080"
  },
  {
    "text": "so I'm going to add the resource specification and you can see that it's",
    "start": "1059080",
    "end": "1064120"
  },
  {
    "text": "all redacted you can review and you can approve uh later later on so it's all",
    "start": "1064120",
    "end": "1072039"
  },
  {
    "text": "redacted I approve it and then I add the container logs as",
    "start": "1072039",
    "end": "1077440"
  },
  {
    "text": "well and I I'm going to approve that as well and then we can add evens metrics",
    "start": "1077440",
    "end": "1084559"
  },
  {
    "text": "so I'm going to just show you um how the metrics would look like uh when you add it so I'm adding an event and I'm adding",
    "start": "1084559",
    "end": "1091760"
  },
  {
    "text": "a Prometheus uh metric I know it's not related but just to show you like it's",
    "start": "1091760",
    "end": "1098520"
  },
  {
    "text": "possible to bring in the metrics um into",
    "start": "1098520",
    "end": "1103120"
  },
  {
    "text": "this so yeah it's not a related issue as such but you can bring in anything",
    "start": "1104360",
    "end": "1109400"
  },
  {
    "text": "yeah so you get a graphical view of all the metrics that are there and then we can do troubleshooting so I'm using chat",
    "start": "1109400",
    "end": "1116159"
  },
  {
    "text": "GPT and you should be able to get the troubleshooting tips from",
    "start": "1116159",
    "end": "1123000"
  },
  {
    "text": "chpt so we have an inbuilt template for the prompt so this is what we see right",
    "start": "1123000",
    "end": "1129120"
  },
  {
    "text": "so it gives you a Consolidated uh list of things that could go wrong along with the expected versus the actual values so",
    "start": "1129120",
    "end": "1136200"
  },
  {
    "text": "it's able to clearly pinpoint the issues uh this you know the expected is that expecting the jar there it's not present",
    "start": "1136200",
    "end": "1143320"
  },
  {
    "text": "with a list of commands and it also gives you a flowchart of how the whole uh steps can be",
    "start": "1143320",
    "end": "1150320"
  },
  {
    "text": "executed right um so this is with chat GPD did not get confused even if I give",
    "start": "1150320",
    "end": "1155919"
  },
  {
    "text": "uh add a lot of noise to the uh context um and then you can see the list of",
    "start": "1155919",
    "end": "1161919"
  },
  {
    "text": "options that are possible from this chat so you can create a jira ticket uh right from here based on the uh contented G",
    "start": "1161919",
    "end": "1168880"
  },
  {
    "text": "generated and then you can also create run books from here so it created a j",
    "start": "1168880",
    "end": "1175039"
  },
  {
    "text": "ticket with all the context in the form of an attachment to the jira ticket so",
    "start": "1175039",
    "end": "1180240"
  },
  {
    "text": "it's pretty much",
    "start": "1180240",
    "end": "1182880"
  },
  {
    "text": "automated and then you you can also create a run book from",
    "start": "1187440",
    "end": "1193960"
  },
  {
    "text": "here",
    "start": "1197640",
    "end": "1200640"
  },
  {
    "text": "yeah so you would see some random name uh that's because I confused the chat GPD with the Prometheus alerts otherwise",
    "start": "1202720",
    "end": "1209559"
  },
  {
    "text": "it would have given me a much more meaningful title um yeah so let's see how so you also see a list of history of",
    "start": "1209559",
    "end": "1217200"
  },
  {
    "text": "all the chat that we had so we can use it for auditability later on so let's",
    "start": "1217200",
    "end": "1222919"
  },
  {
    "text": "move on to uh the Llama output like llama integration that we have and see",
    "start": "1222919",
    "end": "1228240"
  },
  {
    "text": "how it performs here so I have the same uh Java failing pod and I'm going to use",
    "start": "1228240",
    "end": "1234240"
  },
  {
    "text": "the Lama chat I'm going to add just the specification and the logs so I'm adding the specification and",
    "start": "1234240",
    "end": "1242679"
  },
  {
    "text": "I'm adding the logs as well and then we do",
    "start": "1242679",
    "end": "1250399"
  },
  {
    "text": "troubleshoot so it's just the same example that I showed but with the better representation so so all these",
    "start": "1252400",
    "end": "1259280"
  },
  {
    "text": "four cses three cses that it showed along with the list of uh the workflow so it could fail for path reasons jav",
    "start": "1259280",
    "end": "1267080"
  },
  {
    "text": "format or volume mounts and it gives you a neat representation of how you can go",
    "start": "1267080",
    "end": "1272240"
  },
  {
    "text": "about solving this problem now this is the end of the demo and I hope you liked it let's get",
    "start": "1272240",
    "end": "1280240"
  },
  {
    "text": "back oh yeah thank you wow thank you so",
    "start": "1280240",
    "end": "1286130"
  },
  {
    "text": "[Applause] much okay so I'm going to just summarize what",
    "start": "1286130",
    "end": "1292760"
  },
  {
    "text": "we have spoken so far um so we have seen the AI challenges we have seen the prompt a model in garance can make a",
    "start": "1292760",
    "end": "1299520"
  },
  {
    "text": "huge difference um I showed you an example of hybrid fine-tuning uh with",
    "start": "1299520",
    "end": "1304720"
  },
  {
    "text": "the rag and how low code and AI can go hand inand in troubleshooting",
    "start": "1304720",
    "end": "1309880"
  },
  {
    "text": "issues so I'm going to stop here uh for Q&A but before that um we have a SAS",
    "start": "1309880",
    "end": "1316200"
  },
  {
    "text": "version I'm just announcing the SAS release often um if you are interested",
    "start": "1316200",
    "end": "1321279"
  },
  {
    "text": "you can go subscribe uh it for at a you know very basic level you don't have to you know there is no um payment or",
    "start": "1321279",
    "end": "1328559"
  },
  {
    "text": "anything you can just go try this online um it's available as um if you go to the",
    "start": "1328559",
    "end": "1334320"
  },
  {
    "text": "website you have uh start free trial and then you can go and sign up and you will",
    "start": "1334320",
    "end": "1340000"
  },
  {
    "text": "be able to use chat GPD um for your own cluster for one cluster uh but if you're looking for anything uh on premise uh",
    "start": "1340000",
    "end": "1348159"
  },
  {
    "text": "this version is still not available on our marketplaces uh which we'll be releasing very soon but we do have an",
    "start": "1348159",
    "end": "1354480"
  },
  {
    "text": "early access um you can get in touch with us and we'll give you uh the light or the Community Edition with some",
    "start": "1354480",
    "end": "1361000"
  },
  {
    "text": "Enterprise capabilities too but it's again going to be on chat GPT um if you",
    "start": "1361000",
    "end": "1366039"
  },
  {
    "text": "want an Enterprise Edition you let us know and then we can work together on the Llama version uh and if you have a r",
    "start": "1366039",
    "end": "1372640"
  },
  {
    "text": "pipeline inhouse uh we can also integrate with that you can find me on",
    "start": "1372640",
    "end": "1378240"
  },
  {
    "text": "um Twitter at vot Raju and I have kept my DMs open if you want to contact me",
    "start": "1378240",
    "end": "1384039"
  },
  {
    "text": "you can DM me and if you liked this please uh uh use this tag uh in and",
    "start": "1384039",
    "end": "1390240"
  },
  {
    "text": "tweet about the solution and that's going to be a good encouragement for us um if if any of you are watching this",
    "start": "1390240",
    "end": "1397400"
  },
  {
    "text": "live video and you couldn't make it to the event in person uh please do share your feedback um as a YouTube video I",
    "start": "1397400",
    "end": "1405000"
  },
  {
    "text": "mean you can send in your comments and then we will take a look at those uh comments as",
    "start": "1405000",
    "end": "1411159"
  },
  {
    "text": "well all right so I'm done with the presentation I mean we'll open up for",
    "start": "1411159",
    "end": "1416279"
  },
  {
    "text": "the Q&A and yeah is there any questions yeah go ahead just yeah I think lar can",
    "start": "1416279",
    "end": "1423760"
  },
  {
    "text": "yeah thank you very much for the wonderful presentation so the model it",
    "start": "1423760",
    "end": "1428799"
  },
  {
    "text": "generates or corrects does it actually improves it and Stor it the improved",
    "start": "1428799",
    "end": "1434039"
  },
  {
    "text": "model somewhere okay so I have not done a finetuning of the uh model um I have",
    "start": "1434039",
    "end": "1441799"
  },
  {
    "text": "done a rag pipeline let me go back to that slide okay yeah so here I'm just",
    "start": "1441799",
    "end": "1448559"
  },
  {
    "text": "scraping the data I have a data set in hugging face um and then I use the base",
    "start": "1448559",
    "end": "1453880"
  },
  {
    "text": "model for integrating with the vector vector DB but we can do a fine tuning",
    "start": "1453880",
    "end": "1459279"
  },
  {
    "text": "which is again we are working on it uh you can still have a fine-tuned version",
    "start": "1459279",
    "end": "1464480"
  },
  {
    "text": "either you can have it in the um you know hugging phase or you can have it uh locally as well yeah and my next",
    "start": "1464480",
    "end": "1473799"
  },
  {
    "text": "question hello yeah so the code the low code it generates can you actually view",
    "start": "1477960",
    "end": "1485080"
  },
  {
    "text": "that and improve upon that um you mean the response not the",
    "start": "1485080",
    "end": "1491000"
  },
  {
    "text": "response because uh the whole UI or it it's behind the scene is generating some",
    "start": "1491000",
    "end": "1497320"
  },
  {
    "text": "code um okay the templates you mean yeah the templates right now we are providing",
    "start": "1497320",
    "end": "1503840"
  },
  {
    "text": "a template offes but in the chat it's not limited to just the troubleshooting or the optimization you can give it you",
    "start": "1503840",
    "end": "1510919"
  },
  {
    "text": "can also have a free form which means you can send your own um you know content to it but at this moment we",
    "start": "1510919",
    "end": "1517919"
  },
  {
    "text": "don't have a template option where you can create a template and use it for your chats um that's something that we",
    "start": "1517919",
    "end": "1524120"
  },
  {
    "text": "will have it in a like in a few releases yeah thank you yeah",
    "start": "1524120",
    "end": "1529720"
  },
  {
    "text": "yeah one more question back there thanks a lot for the",
    "start": "1529720",
    "end": "1536480"
  },
  {
    "text": "presentation uh in your example you show that you solve using the AI a problem",
    "start": "1536480",
    "end": "1542559"
  },
  {
    "text": "that is let me say related to something very general because it's referred to a",
    "start": "1542559",
    "end": "1547720"
  },
  {
    "text": "missing file uh if someone wants to uh enrich more the model you used for",
    "start": "1547720",
    "end": "1553360"
  },
  {
    "text": "example for his own purpose for his own particular application is there any chance to inject a custom model or a",
    "start": "1553360",
    "end": "1560480"
  },
  {
    "text": "custom enriching G pipeline to identify some problems also in a custom",
    "start": "1560480",
    "end": "1567200"
  },
  {
    "text": "application yeah uh that's a great question in fact like uh we have looked up on uh some of the existing models and",
    "start": "1567200",
    "end": "1574399"
  },
  {
    "text": "we did not come across any model that is fine tuned for this and even if it did it did not really work for us I mean it",
    "start": "1574399",
    "end": "1581320"
  },
  {
    "text": "was the answers were not really accurate but you know we are kind of looking into",
    "start": "1581320",
    "end": "1587039"
  },
  {
    "text": "fine-tuning it we are not building a model of our own we are looking to fine-tune it um but however like if you",
    "start": "1587039",
    "end": "1593240"
  },
  {
    "text": "have your own models um you can bring in I me in case of our Enterprise version",
    "start": "1593240",
    "end": "1598360"
  },
  {
    "text": "you can have your own models and we can do the integration with that",
    "start": "1598360",
    "end": "1605480"
  },
  {
    "text": "yeah thank you for the presentation um who do you imagine is the target audience for such a tool um is it",
    "start": "1605880",
    "end": "1613159"
  },
  {
    "text": "support Engineers or developers or users or The Operators themselves El yeah I",
    "start": "1613159",
    "end": "1619399"
  },
  {
    "text": "think our primary audience is uh the it operations uh but then you know as devop",
    "start": "1619399",
    "end": "1626000"
  },
  {
    "text": "stands devops is for everyone uh we have the ID for like the low code and all those I mean even developers can use but",
    "start": "1626000",
    "end": "1633039"
  },
  {
    "text": "our primary audience here is the it and SRE",
    "start": "1633039",
    "end": "1639360"
  },
  {
    "text": "folks um thank you for presentation during your demo you needed to type in",
    "start": "1644080",
    "end": "1649320"
  },
  {
    "text": "approv command several times can you clarify what was the purpose of it like is it some security and compliance",
    "start": "1649320",
    "end": "1656039"
  },
  {
    "text": "reason yeah so as I said like we don't want AI to decide things for us we need",
    "start": "1656039",
    "end": "1663159"
  },
  {
    "text": "to have a better control of how we are interacting with the AI so unless we review and approve the content or even",
    "start": "1663159",
    "end": "1670440"
  },
  {
    "text": "the solution doesn't want to assume that just because we have redacted we are okay to you know send it across to the",
    "start": "1670440",
    "end": "1677240"
  },
  {
    "text": "AI we don't want to automate that we want to make sure that you know the users are in control of what they really",
    "start": "1677240",
    "end": "1684480"
  },
  {
    "text": "send it to the AI so unless they review and approve uh especially because it's",
    "start": "1684480",
    "end": "1690039"
  },
  {
    "text": "it's actually happening in your environment we want to make sure that we are not sending anything that is um um",
    "start": "1690039",
    "end": "1698720"
  },
  {
    "text": "you know sensitive yeah hi thank you so much for",
    "start": "1698720",
    "end": "1704000"
  },
  {
    "text": "this talk I've learned a lot and one thing I missed in the presentation which",
    "start": "1704000",
    "end": "1709679"
  },
  {
    "text": "you probably covered if you could review again is when the tagging of resources happen um is it in a pipeline or does it",
    "start": "1709679",
    "end": "1717720"
  },
  {
    "text": "automated happen or is it a human tag I saw the tagging and I thought that's",
    "start": "1717720",
    "end": "1722760"
  },
  {
    "text": "amazing I wish I could do it in an automated fashion because my humans don't want to do it okay so yeah we do",
    "start": "1722760",
    "end": "1729919"
  },
  {
    "text": "an automatic tagging because we don't uh yeah sometimes you know developers can",
    "start": "1729919",
    "end": "1735720"
  },
  {
    "text": "forget and uh it can go off oversight it can be an oversight so we want to make sure that that's automatically tagged in",
    "start": "1735720",
    "end": "1742960"
  },
  {
    "text": "case of a chat anyway we know that that's coming from the AI but in case of run books uh we as soon as somebody uses",
    "start": "1742960",
    "end": "1750960"
  },
  {
    "text": "the uh AI enhancement we automatically tag it thank",
    "start": "1750960",
    "end": "1757600"
  },
  {
    "text": "you hello thank you for for your presentation yeah I would like to ask if it's possible to to bring it to the next",
    "start": "1757600",
    "end": "1764360"
  },
  {
    "text": "level like for for example you know to create some to have some temp and maybe some cust models Define and then based",
    "start": "1764360",
    "end": "1771960"
  },
  {
    "text": "on this one as soon as we run the pipeline to create some alerts because I",
    "start": "1771960",
    "end": "1777519"
  },
  {
    "text": "mean if you are talking about thousand of clusters or whatever nobody will just you know in a manual way check the UI is",
    "start": "1777519",
    "end": "1785320"
  },
  {
    "text": "it possible also to integrate the outcome with some observability",
    "start": "1785320",
    "end": "1791000"
  },
  {
    "text": "tools um that's a great question um but",
    "start": "1791000",
    "end": "1796840"
  },
  {
    "text": "I'm uh we have the API so certainly it is possible the reason why we have a uh",
    "start": "1796840",
    "end": "1803640"
  },
  {
    "text": "approval process is to make sure that we are not letting anything that goes out of the control I mean from a technical",
    "start": "1803640",
    "end": "1810360"
  },
  {
    "text": "point of view it is certainly possible but is that something that we want to do um again it depends upon uh",
    "start": "1810360",
    "end": "1817240"
  },
  {
    "text": "organizations if they are fine I mean uh we can review what kind of a Content we want to send uh if it doesn't have if we",
    "start": "1817240",
    "end": "1823799"
  },
  {
    "text": "100% sure there is nothing sensitive everything gets redacted we can still do",
    "start": "1823799",
    "end": "1830320"
  },
  {
    "text": "that hello hello right there yeah yeah yeah",
    "start": "1831960",
    "end": "1838760"
  },
  {
    "text": "yeah uh thank you for all the presentation and I have a question um",
    "start": "1838760",
    "end": "1844840"
  },
  {
    "text": "about the performance of your product when you're dealing with a exotic or",
    "start": "1844840",
    "end": "1851159"
  },
  {
    "text": "custom resources private customer resources does your tool handle this",
    "start": "1851159",
    "end": "1857360"
  },
  {
    "text": "well or do we need to retrain the model using our private resources yeah that's",
    "start": "1857360",
    "end": "1864440"
  },
  {
    "text": "again a great question so we have played around played around with 7B 13B and we",
    "start": "1864440",
    "end": "1870279"
  },
  {
    "text": "felt 7B was uh better um but then it was not yielding the results we had to",
    "start": "1870279",
    "end": "1876159"
  },
  {
    "text": "change the temperatures that we did we brought in the uh data sources and then",
    "start": "1876159",
    "end": "1882440"
  },
  {
    "text": "we realized we have to add lot more to it and that's where you know to answer the other question as well so how much",
    "start": "1882440",
    "end": "1889960"
  },
  {
    "text": "ever we train even if it is accurate to an extent uh we are not letting the AI",
    "start": "1889960",
    "end": "1896240"
  },
  {
    "text": "make the decision in the operations this is you can always look at this as a guidance um an assistant who which is",
    "start": "1896240",
    "end": "1902799"
  },
  {
    "text": "actually helping you another thing which we also realized is that when we give a noisy input like if we have a huge",
    "start": "1902799",
    "end": "1909480"
  },
  {
    "text": "prompt um especially you know if it is a system resource it has all the status manage fields and so many um you know uh",
    "start": "1909480",
    "end": "1918120"
  },
  {
    "text": "attributes if we dump all the uh inputs to the uh AI it was not performing well",
    "start": "1918120",
    "end": "1924320"
  },
  {
    "text": "so we have to fine tune uh the promps itself right so I think from our observation if if you have an internal",
    "start": "1924320",
    "end": "1931799"
  },
  {
    "text": "database and U of all this knowledge base and you can actually create a fine",
    "start": "1931799",
    "end": "1937559"
  },
  {
    "text": "tune model which will also improve the performance of the um the rack pipeline",
    "start": "1937559",
    "end": "1943080"
  },
  {
    "text": "or um anything yeah so but we have our own base version which will work um",
    "start": "1943080",
    "end": "1949880"
  },
  {
    "text": "which we have tested for U system resources but if you have a pipeline we can do the",
    "start": "1949880",
    "end": "1956039"
  },
  {
    "text": "integration thanks for the the presentation in the slides demo of course um you are feeding basically the",
    "start": "1956840",
    "end": "1965000"
  },
  {
    "text": "model with all these data points approving them but how do you know which data points to",
    "start": "1965000",
    "end": "1971399"
  },
  {
    "text": "feed it where how would the SRE platform engineer know that something wrong where",
    "start": "1971399",
    "end": "1979159"
  },
  {
    "text": "it's wrong and what to feed the model with to actually get to the problem at",
    "start": "1979159",
    "end": "1984840"
  },
  {
    "text": "hand yeah so um again we have a few data points to start",
    "start": "1984840",
    "end": "1991799"
  },
  {
    "text": "with but we can always ask the a model what is the additional information that we are looking for right so it can give",
    "start": "1991799",
    "end": "1999559"
  },
  {
    "text": "back the suggestions and you can pick those from the catalog yeah but how do you know what's",
    "start": "1999559",
    "end": "2007399"
  },
  {
    "text": "wrong are you alerted actually that something's wrong that you start needing to feed that information to the AI yeah",
    "start": "2007399",
    "end": "2015080"
  },
  {
    "text": "so we need to I'm missing I'm missing the starting part of the journey to actually bring the value to the engineer",
    "start": "2015080",
    "end": "2021880"
  },
  {
    "text": "so the starting point is where you're starting to see the uh errors happening",
    "start": "2021880",
    "end": "2027200"
  },
  {
    "text": "so for instance in this case we start started you're not an observability tool basically we are not an observability",
    "start": "2027200",
    "end": "2032919"
  },
  {
    "text": "tool we are an IDE yeah we are not an observability tool but you can integrate",
    "start": "2032919",
    "end": "2037960"
  },
  {
    "text": "with an observability tool and we are not going to make a decision out of automating that but we can always",
    "start": "2037960",
    "end": "2043679"
  },
  {
    "text": "integrate with an observability tool so the starting point is from where you are observing the problem so from there you",
    "start": "2043679",
    "end": "2050158"
  },
  {
    "text": "can actually ask more questions and you know add more context yeah thank you thank you we know",
    "start": "2050159",
    "end": "2056919"
  },
  {
    "text": "that's a great demo um how do you create the J tickets right now and do you are you are using autonomous agents or",
    "start": "2056919",
    "end": "2063358"
  },
  {
    "text": "anything like that or do you have plans plans to use them uh we don't have the AG it's a simple API",
    "start": "2063359",
    "end": "2069878"
  },
  {
    "text": "integration yeah yeah thanks so I think we have run out of time if there is one more question we",
    "start": "2069879",
    "end": "2076118"
  },
  {
    "text": "can take it otherwise please give a hand to vno this great demo and great presentation thank",
    "start": "2076119",
    "end": "2082000"
  },
  {
    "text": "you",
    "start": "2082000",
    "end": "2085000"
  }
]
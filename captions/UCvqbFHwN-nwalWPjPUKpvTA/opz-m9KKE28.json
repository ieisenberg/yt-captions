[
  {
    "text": "hello everyone Uh thanks for u coming to",
    "start": "240",
    "end": "3280"
  },
  {
    "text": "uh our session and today we will talk",
    "start": "3280",
    "end": "5759"
  },
  {
    "text": "about uh using u cage and what m to",
    "start": "5759",
    "end": "9599"
  },
  {
    "text": "manage cloud native light language model",
    "start": "9599",
    "end": "12240"
  },
  {
    "text": "workloads across edge and cloud So uh",
    "start": "12240",
    "end": "16640"
  },
  {
    "text": "before we uh get started uh let's us do",
    "start": "16640",
    "end": "19920"
  },
  {
    "text": "a a brief uh introduction",
    "start": "19920",
    "end": "23519"
  },
  {
    "text": "Okay Hello Uh I'm fishy from high cloud",
    "start": "23519",
    "end": "26560"
  },
  {
    "text": "Now I'm a full-time maintainer of the",
    "start": "26560",
    "end": "28480"
  },
  {
    "text": "cubage project Yeah which is a CCF",
    "start": "28480",
    "end": "31039"
  },
  {
    "text": "graduated project Okay thank you Um um",
    "start": "31039",
    "end": "35280"
  },
  {
    "text": "hello uh my name is Vivian Hu and I'm",
    "start": "35280",
    "end": "37520"
  },
  {
    "text": "from the uh second company Uh it is uh",
    "start": "37520",
    "end": "41200"
  },
  {
    "text": "the company is the creator and",
    "start": "41200",
    "end": "43600"
  },
  {
    "text": "maintainer of the uh the CNCF world",
    "start": "43600",
    "end": "46879"
  },
  {
    "text": "project and I'm also a uh CNCF",
    "start": "46879",
    "end": "50440"
  },
  {
    "text": "ambassador and we are uh glad to be here",
    "start": "50440",
    "end": "53760"
  },
  {
    "text": "So uh let's get started So uh uh the",
    "start": "53760",
    "end": "58719"
  },
  {
    "text": "first part we want to talk about is that",
    "start": "58719",
    "end": "61199"
  },
  {
    "text": "uh we need uh we we definitely need",
    "start": "61199",
    "end": "63680"
  },
  {
    "text": "inference workloads at I So when we",
    "start": "63680",
    "end": "66960"
  },
  {
    "text": "talking about inferos uh workloads at I",
    "start": "66960",
    "end": "69760"
  },
  {
    "text": "we're talking about running local AI So",
    "start": "69760",
    "end": "74000"
  },
  {
    "text": "um so this is very important for the",
    "start": "74000",
    "end": "77280"
  },
  {
    "text": "real time uh uh decision making use case",
    "start": "77280",
    "end": "82000"
  },
  {
    "text": "For example if we want to add a uh",
    "start": "82000",
    "end": "84479"
  },
  {
    "text": "caption",
    "start": "84479",
    "end": "86080"
  },
  {
    "text": "uh for our talk uh for this conference",
    "start": "86080",
    "end": "89360"
  },
  {
    "text": "it's better that we bring um uh we bring",
    "start": "89360",
    "end": "92400"
  },
  {
    "text": "a GPU machine uh at the conference at",
    "start": "92400",
    "end": "95600"
  },
  {
    "text": "here and then we use whisper to",
    "start": "95600",
    "end": "97600"
  },
  {
    "text": "transcribe what we are talking about Um",
    "start": "97600",
    "end": "100799"
  },
  {
    "text": "this if we were using uh this will this",
    "start": "100799",
    "end": "104079"
  },
  {
    "text": "will have a low latency and it will",
    "start": "104079",
    "end": "106880"
  },
  {
    "text": "respondse very uh fastly If we use open",
    "start": "106880",
    "end": "109280"
  },
  {
    "text": "eye then uh we will need to transfer our",
    "start": "109280",
    "end": "112000"
  },
  {
    "text": "data to the cloud and then transfer back",
    "start": "112000",
    "end": "114079"
  },
  {
    "text": "it will uh it will spend much much more",
    "start": "114079",
    "end": "117280"
  },
  {
    "text": "time So that's why we need inference",
    "start": "117280",
    "end": "120479"
  },
  {
    "text": "workloads for the time sensitive task",
    "start": "120479",
    "end": "123200"
  },
  {
    "text": "and um because we are running uh we are",
    "start": "123200",
    "end": "125759"
  },
  {
    "text": "running live langu models on our machine",
    "start": "125759",
    "end": "128160"
  },
  {
    "text": "on our own machine so we can have",
    "start": "128160",
    "end": "130720"
  },
  {
    "text": "enhanced privacy u protection the data",
    "start": "130720",
    "end": "133840"
  },
  {
    "text": "won't be transferred to the cloud",
    "start": "133840",
    "end": "135840"
  },
  {
    "text": "providers it just store in your in your",
    "start": "135840",
    "end": "138319"
  },
  {
    "text": "own machine it's can protect your",
    "start": "138319",
    "end": "140160"
  },
  {
    "text": "privacy and it will also help us align",
    "start": "140160",
    "end": "143040"
  },
  {
    "text": "with the data regulation for example the",
    "start": "143040",
    "end": "145920"
  },
  {
    "text": "EDPR and We uh and we also uh can have",
    "start": "145920",
    "end": "150640"
  },
  {
    "text": "better uh domain specific optimization",
    "start": "150640",
    "end": "153760"
  },
  {
    "text": "because we are running the open source",
    "start": "153760",
    "end": "155840"
  },
  {
    "text": "level models the local so we can made",
    "start": "155840",
    "end": "157840"
  },
  {
    "text": "the more customization to the um to the",
    "start": "157840",
    "end": "160560"
  },
  {
    "text": "model uh we can fetune or we can retrain",
    "start": "160560",
    "end": "163519"
  },
  {
    "text": "the model Um but if we are using the",
    "start": "163519",
    "end": "166319"
  },
  {
    "text": "open model is one side fit out So we",
    "start": "166319",
    "end": "169120"
  },
  {
    "text": "can't to optimize the model for specific",
    "start": "169120",
    "end": "171599"
  },
  {
    "text": "task and we also can have a",
    "start": "171599",
    "end": "173920"
  },
  {
    "text": "decentralized scabilities because we",
    "start": "173920",
    "end": "176000"
  },
  {
    "text": "will have a many decentralized nodes So",
    "start": "176000",
    "end": "178879"
  },
  {
    "text": "if one of them doesn't work it won't",
    "start": "178879",
    "end": "181200"
  },
  {
    "text": "affect our whole workflow",
    "start": "181200",
    "end": "184599"
  },
  {
    "text": "So uh so we need you know inference",
    "start": "184599",
    "end": "188239"
  },
  {
    "text": "workloads at IG but uh we also have some",
    "start": "188239",
    "end": "191360"
  },
  {
    "text": "challenges uh due to the uh due to the",
    "start": "191360",
    "end": "194720"
  },
  {
    "text": "uh this uh uh due to the limited uh res",
    "start": "194720",
    "end": "198720"
  },
  {
    "text": "the resource limited device um because",
    "start": "198720",
    "end": "202400"
  },
  {
    "text": "the ID devices will have a limited",
    "start": "202400",
    "end": "205200"
  },
  {
    "text": "compute memory and a power So it",
    "start": "205200",
    "end": "208080"
  },
  {
    "text": "requires it requires us to write a high",
    "start": "208080",
    "end": "210799"
  },
  {
    "text": "performance and a lightweight",
    "start": "210799",
    "end": "212239"
  },
  {
    "text": "application for the uh for the IG AI and",
    "start": "212239",
    "end": "215760"
  },
  {
    "text": "uh the other thing is that u because we",
    "start": "215760",
    "end": "218319"
  },
  {
    "text": "have a limited resources so we can't run",
    "start": "218319",
    "end": "221360"
  },
  {
    "text": "the full size of the um full size of the",
    "start": "221360",
    "end": "224480"
  },
  {
    "text": "langu models u for example it's it's",
    "start": "224480",
    "end": "228159"
  },
  {
    "text": "impossible for us to run the full uh the",
    "start": "228159",
    "end": "231040"
  },
  {
    "text": "full dips uh",
    "start": "231040",
    "end": "233560"
  },
  {
    "text": "78 billion model in um Raspberry Pi",
    "start": "233560",
    "end": "237599"
  },
  {
    "text": "So we need to use the uh use the uh the",
    "start": "237599",
    "end": "240640"
  },
  {
    "text": "small side language model Uh so we need",
    "start": "240640",
    "end": "243599"
  },
  {
    "text": "to find a balance between the uh between",
    "start": "243599",
    "end": "246080"
  },
  {
    "text": "the uh between the size and model",
    "start": "246080",
    "end": "248760"
  },
  {
    "text": "accuracy Uh we need uh enhance we need",
    "start": "248760",
    "end": "252239"
  },
  {
    "text": "to we need to uh sub celebrate the",
    "start": "252239",
    "end": "255439"
  },
  {
    "text": "workloads We need to run uh complex uh",
    "start": "255439",
    "end": "259199"
  },
  {
    "text": "tasks on the cloud and the simple task",
    "start": "259199",
    "end": "261680"
  },
  {
    "text": "on the uh on the on the edge And there",
    "start": "261680",
    "end": "264639"
  },
  {
    "text": "will be a cloud and edge uh",
    "start": "264639",
    "end": "267080"
  },
  {
    "text": "collaboration And uh",
    "start": "267080",
    "end": "269880"
  },
  {
    "text": "lastly the um the the the ecosystem of",
    "start": "269880",
    "end": "274800"
  },
  {
    "text": "the ID devices is fragmented which means",
    "start": "274800",
    "end": "277600"
  },
  {
    "text": "that there is no standardization There",
    "start": "277600",
    "end": "279919"
  },
  {
    "text": "is no standardization in the uh in the",
    "start": "279919",
    "end": "282000"
  },
  {
    "text": "hardware We will we will have many kinds",
    "start": "282000",
    "end": "284160"
  },
  {
    "text": "of uh IDI many kinds of hardares many",
    "start": "284160",
    "end": "287759"
  },
  {
    "text": "kinds of uh oper operating systems",
    "start": "287759",
    "end": "290320"
  },
  {
    "text": "frameworks for the uh for the ID devices",
    "start": "290320",
    "end": "294560"
  },
  {
    "text": "So uh due to this uh we think we propose",
    "start": "294560",
    "end": "298240"
  },
  {
    "text": "what match and quite as the um one of",
    "start": "298240",
    "end": "300880"
  },
  {
    "text": "the best uh solutions for the inference",
    "start": "300880",
    "end": "303199"
  },
  {
    "text": "workloads at edge uh because we will",
    "start": "303199",
    "end": "306240"
  },
  {
    "text": "need some u lightweight uh application",
    "start": "306240",
    "end": "308800"
  },
  {
    "text": "lightweight workloads at edge u because",
    "start": "308800",
    "end": "311919"
  },
  {
    "text": "uh uh because the u application the edge",
    "start": "311919",
    "end": "315039"
  },
  {
    "text": "devices is uh resource limited and the",
    "start": "315039",
    "end": "318720"
  },
  {
    "text": "application should also be uh portable",
    "start": "318720",
    "end": "321600"
  },
  {
    "text": "um we don't want to compile the",
    "start": "321600",
    "end": "323600"
  },
  {
    "text": "application again and again for",
    "start": "323600",
    "end": "325360"
  },
  {
    "text": "different hardares we just want to",
    "start": "325360",
    "end": "327840"
  },
  {
    "text": "compile it once and run it anywhere and",
    "start": "327840",
    "end": "330720"
  },
  {
    "text": "we also need the I cloud uh uh",
    "start": "330720",
    "end": "333759"
  },
  {
    "text": "collaboration Um because as I mentioned",
    "start": "333759",
    "end": "335840"
  },
  {
    "text": "before uh not all the task is suitable",
    "start": "335840",
    "end": "338400"
  },
  {
    "text": "for the edge We will need a uh edge uh",
    "start": "338400",
    "end": "341280"
  },
  {
    "text": "workloads on the edge and workloads on",
    "start": "341280",
    "end": "343199"
  },
  {
    "text": "the cloud to work together to finish the",
    "start": "343199",
    "end": "346639"
  },
  {
    "text": "uh the whole workflow and uh uh suddenly",
    "start": "346639",
    "end": "349520"
  },
  {
    "text": "the workloads should be cloud ready",
    "start": "349520",
    "end": "351600"
  },
  {
    "text": "because u we all know that kubernetes is",
    "start": "351600",
    "end": "354720"
  },
  {
    "text": "the uh the most technology to uh",
    "start": "354720",
    "end": "357840"
  },
  {
    "text": "autoscale the workloads to manage the",
    "start": "357840",
    "end": "360240"
  },
  {
    "text": "workloads So I think um um was my magic",
    "start": "360240",
    "end": "363840"
  },
  {
    "text": "runtime and u cable uh cable uh",
    "start": "363840",
    "end": "367120"
  },
  {
    "text": "kubernetes on the on the on the edge u",
    "start": "367120",
    "end": "370319"
  },
  {
    "text": "both from the uh both from uh uh sf will",
    "start": "370319",
    "end": "374160"
  },
  {
    "text": "be the uh basel",
    "start": "374160",
    "end": "376600"
  },
  {
    "text": "solution So uh next uh right now we have",
    "start": "376600",
    "end": "380720"
  },
  {
    "text": "the uh we have the uh we know how to",
    "start": "380720",
    "end": "384160"
  },
  {
    "text": "solve the challenge Uh let's deep uh",
    "start": "384160",
    "end": "387039"
  },
  {
    "text": "let's deep dive into the was magic",
    "start": "387039",
    "end": "389680"
  },
  {
    "text": "runtime So what m is an uh is an",
    "start": "389680",
    "end": "392800"
  },
  {
    "text": "alternative uh Linux container but it's",
    "start": "392800",
    "end": "396319"
  },
  {
    "text": "lightweight and portable Uh when I say",
    "start": "396319",
    "end": "400000"
  },
  {
    "text": "uh portable there are two meanings uh",
    "start": "400000",
    "end": "402319"
  },
  {
    "text": "one is from the hardware So we can run",
    "start": "402319",
    "end": "405199"
  },
  {
    "text": "them m and application across different",
    "start": "405199",
    "end": "408319"
  },
  {
    "text": "hardwarees uh including CPUs GPUs TPUs",
    "start": "408319",
    "end": "412080"
  },
  {
    "text": "uh MPUs and many other uh hardwarees So",
    "start": "412080",
    "end": "415039"
  },
  {
    "text": "you do you don't need to compile it",
    "start": "415039",
    "end": "417199"
  },
  {
    "text": "again and again you can compile the uh",
    "start": "417199",
    "end": "419919"
  },
  {
    "text": "the application on your MacBook and then",
    "start": "419919",
    "end": "422319"
  },
  {
    "text": "um transfer and then send it to the",
    "start": "422319",
    "end": "424639"
  },
  {
    "text": "different hardares Uh the second level",
    "start": "424639",
    "end": "427120"
  },
  {
    "text": "is that uh I'm talking about is the uh",
    "start": "427120",
    "end": "430240"
  },
  {
    "text": "model So we uh besides all the light",
    "start": "430240",
    "end": "432560"
  },
  {
    "text": "language models uh was my also supposed",
    "start": "432560",
    "end": "435360"
  },
  {
    "text": "running on whisper um on t model s on",
    "start": "435360",
    "end": "439599"
  },
  {
    "text": "image generation model like civil",
    "start": "439599",
    "end": "441360"
  },
  {
    "text": "diffusion and the flex and um and uh and",
    "start": "441360",
    "end": "444479"
  },
  {
    "text": "uh uh and the vision model uh and what",
    "start": "444479",
    "end": "447840"
  },
  {
    "text": "match is um uh is lightweight So the",
    "start": "447840",
    "end": "450960"
  },
  {
    "text": "whole runtime the whole runtime plus the",
    "start": "450960",
    "end": "453360"
  },
  {
    "text": "API server for running those light langu",
    "start": "453360",
    "end": "455599"
  },
  {
    "text": "models is less than 30 GB You can",
    "start": "455599",
    "end": "458479"
  },
  {
    "text": "imagine that the official docker the",
    "start": "458479",
    "end": "461280"
  },
  {
    "text": "official pytor docker image is uh about",
    "start": "461280",
    "end": "465120"
  },
  {
    "text": "4 GB So it's very lightweight and it's",
    "start": "465120",
    "end": "467520"
  },
  {
    "text": "suitable for the edge and there more",
    "start": "467520",
    "end": "470080"
  },
  {
    "text": "importantly there is no external",
    "start": "470080",
    "end": "472240"
  },
  {
    "text": "dependency There is no Python package So",
    "start": "472240",
    "end": "474800"
  },
  {
    "text": "it's very easy for apps to set it up You",
    "start": "474800",
    "end": "478400"
  },
  {
    "text": "only need to install runtime install the",
    "start": "478400",
    "end": "481840"
  },
  {
    "text": "API server install the download the",
    "start": "481840",
    "end": "484400"
  },
  {
    "text": "model and then run it U we will have a",
    "start": "484400",
    "end": "486879"
  },
  {
    "text": "demo",
    "start": "486879",
    "end": "487720"
  },
  {
    "text": "later and uh uh the world magic itself",
    "start": "487720",
    "end": "490639"
  },
  {
    "text": "is secure is a secure sandbox so it can",
    "start": "490639",
    "end": "494720"
  },
  {
    "text": "allow uh can isolates the from other",
    "start": "494720",
    "end": "497680"
  },
  {
    "text": "applications and it's called ready and",
    "start": "497680",
    "end": "500720"
  },
  {
    "text": "lastly it's uh high performance it can",
    "start": "500720",
    "end": "503680"
  },
  {
    "text": "automatically use the device local uh",
    "start": "503680",
    "end": "506400"
  },
  {
    "text": "hardware",
    "start": "506400",
    "end": "507639"
  },
  {
    "text": "uh uh accelerations to accelerate the",
    "start": "507639",
    "end": "511280"
  },
  {
    "text": "inference",
    "start": "511280",
    "end": "513000"
  },
  {
    "text": "work So uh so we can see that world",
    "start": "513000",
    "end": "516880"
  },
  {
    "text": "match is one time that view all air",
    "start": "516880",
    "end": "519279"
  },
  {
    "text": "models on any hardware Uh the the uh the",
    "start": "519279",
    "end": "524399"
  },
  {
    "text": "architecture image shows how it works",
    "start": "524399",
    "end": "526480"
  },
  {
    "text": "with the models So at the bottom we will",
    "start": "526480",
    "end": "529600"
  },
  {
    "text": "have a hardware it's can be it can be",
    "start": "529600",
    "end": "532640"
  },
  {
    "text": "GPU CPU TPU or whatever you need and",
    "start": "532640",
    "end": "536160"
  },
  {
    "text": "then we will have the was my runtime and",
    "start": "536160",
    "end": "538959"
  },
  {
    "text": "then we will have the uh different kinds",
    "start": "538959",
    "end": "541519"
  },
  {
    "text": "of models We can have a ch model We can",
    "start": "541519",
    "end": "544480"
  },
  {
    "text": "have",
    "start": "544480",
    "end": "546360"
  },
  {
    "text": "a hello Hello",
    "start": "546360",
    "end": "550760"
  },
  {
    "text": "And then we can have a different uh",
    "start": "550959",
    "end": "553680"
  },
  {
    "text": "models We can have a line",
    "start": "553680",
    "end": "558040"
  },
  {
    "text": "We just don't cover it the Okay Uh we",
    "start": "559040",
    "end": "562320"
  },
  {
    "text": "can have the uh uh sorry for that Uh we",
    "start": "562320",
    "end": "565760"
  },
  {
    "text": "can have the uh the light lang model We",
    "start": "565760",
    "end": "568560"
  },
  {
    "text": "can have the whisp model We can have the",
    "start": "568560",
    "end": "570480"
  },
  {
    "text": "civil different model and um and also",
    "start": "570480",
    "end": "572959"
  },
  {
    "text": "the embedding models So if you want to",
    "start": "572959",
    "end": "575120"
  },
  {
    "text": "do um uh if you want to do a knowledge",
    "start": "575120",
    "end": "578959"
  },
  {
    "text": "based uh application we can also have a",
    "start": "578959",
    "end": "582160"
  },
  {
    "text": "uh we can also have some knowledge",
    "start": "582160",
    "end": "584000"
  },
  {
    "text": "embedding in V DB and then and then we",
    "start": "584000",
    "end": "587839"
  },
  {
    "text": "have the inference app The inference the",
    "start": "587839",
    "end": "589839"
  },
  {
    "text": "inference app is a binary uh it's uh as",
    "start": "589839",
    "end": "593519"
  },
  {
    "text": "I mentioned before it's possible across",
    "start": "593519",
    "end": "596240"
  },
  {
    "text": "different platforms It's very",
    "start": "596240",
    "end": "598399"
  },
  {
    "text": "lightweight is maybe several megabytes",
    "start": "598399",
    "end": "601519"
  },
  {
    "text": "and more importantly it's uh it's API",
    "start": "601519",
    "end": "604959"
  },
  {
    "text": "server is fully open compatible So uh",
    "start": "604959",
    "end": "608320"
  },
  {
    "text": "whatever you are running um um a model",
    "start": "608320",
    "end": "611760"
  },
  {
    "text": "um like a chat model or um with model is",
    "start": "611760",
    "end": "615360"
  },
  {
    "text": "fully open compatible So you can use um",
    "start": "615360",
    "end": "618240"
  },
  {
    "text": "uh the open u framework to to do your",
    "start": "618240",
    "end": "621120"
  },
  {
    "text": "own application at the",
    "start": "621120",
    "end": "623480"
  },
  {
    "text": "edge And uh next uh uh let's welcome Fay",
    "start": "623480",
    "end": "628480"
  },
  {
    "text": "to introduce the Qbatch Hello Hello Okay",
    "start": "628480",
    "end": "632560"
  },
  {
    "text": "Uh next I will uh have a brief",
    "start": "632560",
    "end": "634880"
  },
  {
    "text": "introduction for the Kubage Yeah Uh this",
    "start": "634880",
    "end": "637680"
  },
  {
    "text": "is a overall architecture of the Kubage",
    "start": "637680",
    "end": "639839"
  },
  {
    "text": "project Yeah Uh from the diagram you can",
    "start": "639839",
    "end": "642720"
  },
  {
    "text": "see Kubage includes three parts The",
    "start": "642720",
    "end": "645680"
  },
  {
    "text": "cloud parts age parts and devices parts",
    "start": "645680",
    "end": "648560"
  },
  {
    "text": "Yeah In the cloud parts uh we have a",
    "start": "648560",
    "end": "650959"
  },
  {
    "text": "Kubernetes master Yeah We have uh we",
    "start": "650959",
    "end": "654480"
  },
  {
    "text": "don't make any modification to the",
    "start": "654480",
    "end": "656320"
  },
  {
    "text": "Kubernetes master So users can use the",
    "start": "656320",
    "end": "658560"
  },
  {
    "text": "Kubernetes API to talk to the QH cluster",
    "start": "658560",
    "end": "661760"
  },
  {
    "text": "Yeah Uh we have our own component called",
    "start": "661760",
    "end": "664800"
  },
  {
    "text": "code call You can see Yeah Yeah Why we",
    "start": "664800",
    "end": "668480"
  },
  {
    "text": "uh develop this component because we",
    "start": "668480",
    "end": "670560"
  },
  {
    "text": "think the uh network between the cloud",
    "start": "670560",
    "end": "672880"
  },
  {
    "text": "and age is always unstable So we have do",
    "start": "672880",
    "end": "675839"
  },
  {
    "text": "some enhancements for the unstable uh",
    "start": "675839",
    "end": "678959"
  },
  {
    "text": "network scenarios Yeah Uh from the H",
    "start": "678959",
    "end": "681920"
  },
  {
    "text": "part we have a component called H core",
    "start": "681920",
    "end": "684320"
  },
  {
    "text": "Yeah H core we uh it integrates a a",
    "start": "684320",
    "end": "687519"
  },
  {
    "text": "light cublet Yeah For light cublet we",
    "start": "687519",
    "end": "691200"
  },
  {
    "text": "remove some unused feature from cublet",
    "start": "691200",
    "end": "693839"
  },
  {
    "text": "then integrate it to the each core So",
    "start": "693839",
    "end": "696720"
  },
  {
    "text": "each core can run in a lightweight edge",
    "start": "696720",
    "end": "699360"
  },
  {
    "text": "devices Yeah The right part is the out",
    "start": "699360",
    "end": "703200"
  },
  {
    "text": "devices management Yeah We have a",
    "start": "703200",
    "end": "705519"
  },
  {
    "text": "component called mapper So uh devices",
    "start": "705519",
    "end": "708560"
  },
  {
    "text": "can connect to the QBH cluster from the",
    "start": "708560",
    "end": "711200"
  },
  {
    "text": "map component Yeah Yeah This is the",
    "start": "711200",
    "end": "713760"
  },
  {
    "text": "overall architecture of the uh",
    "start": "713760",
    "end": "717240"
  },
  {
    "text": "QBH Okay Next I will uh introduce",
    "start": "717240",
    "end": "720720"
  },
  {
    "text": "another sub project in QBH called Sedna",
    "start": "720720",
    "end": "723839"
  },
  {
    "text": "Yeah Sedna is a age code standardy AI",
    "start": "723839",
    "end": "727440"
  },
  {
    "text": "framework Yeah It can do some uh AI age",
    "start": "727440",
    "end": "732320"
  },
  {
    "text": "code standard I will introduce later",
    "start": "732320",
    "end": "734720"
  },
  {
    "text": "Yeah From the uh architecture you can",
    "start": "734720",
    "end": "737519"
  },
  {
    "text": "see uh it's also based on the cube uh it",
    "start": "737519",
    "end": "740959"
  },
  {
    "text": "also include code at each part Yeah From",
    "start": "740959",
    "end": "743839"
  },
  {
    "text": "the code we have uh the first component",
    "start": "743839",
    "end": "746480"
  },
  {
    "text": "called global manager It hands all the",
    "start": "746480",
    "end": "749440"
  },
  {
    "text": "uh task management task coordination",
    "start": "749440",
    "end": "751839"
  },
  {
    "text": "model data set management Yeah We have",
    "start": "751839",
    "end": "755200"
  },
  {
    "text": "another component called local",
    "start": "755200",
    "end": "757279"
  },
  {
    "text": "controller The local controller run in",
    "start": "757279",
    "end": "759440"
  },
  {
    "text": "the uh cloud node at each node Yeah It's",
    "start": "759440",
    "end": "763040"
  },
  {
    "text": "a a bridge between the code at each node",
    "start": "763040",
    "end": "765920"
  },
  {
    "text": "Yeah we also have uh a worker Yes worker",
    "start": "765920",
    "end": "769360"
  },
  {
    "text": "is uh some AI workload task run worker",
    "start": "769360",
    "end": "773040"
  },
  {
    "text": "Yeah we also have a lib uni uh worker",
    "start": "773040",
    "end": "777040"
  },
  {
    "text": "The lib is integrated with the AI",
    "start": "777040",
    "end": "779120"
  },
  {
    "text": "framework like uh tension flow pyach Uh",
    "start": "779120",
    "end": "782399"
  },
  {
    "text": "so we can do some uh age code synergy uh",
    "start": "782399",
    "end": "786800"
  },
  {
    "text": "through the lab local controller Yeah",
    "start": "786800",
    "end": "789120"
  },
  {
    "text": "From age to code and we can do some",
    "start": "789120",
    "end": "792560"
  },
  {
    "text": "joint inference or federated learning",
    "start": "792560",
    "end": "795279"
  },
  {
    "text": "Yeah Okay This is the uh SNA sub",
    "start": "795279",
    "end": "799240"
  },
  {
    "text": "project Okay Uh then I will introduce",
    "start": "799240",
    "end": "802000"
  },
  {
    "text": "the workflow for the uh cloud age joint",
    "start": "802000",
    "end": "805360"
  },
  {
    "text": "inference uh in uh SNA uh from the uh",
    "start": "805360",
    "end": "810480"
  },
  {
    "text": "architecture you can see the left side",
    "start": "810480",
    "end": "812560"
  },
  {
    "text": "is the uh devices like camera then the H",
    "start": "812560",
    "end": "816320"
  },
  {
    "text": "node three H node yeah while cloud node",
    "start": "816320",
    "end": "819360"
  },
  {
    "text": "yeah first uh for the workflow first you",
    "start": "819360",
    "end": "822560"
  },
  {
    "text": "can see the AI developers uh they",
    "start": "822560",
    "end": "825440"
  },
  {
    "text": "provide data to train deep models and",
    "start": "825440",
    "end": "828240"
  },
  {
    "text": "shallow models uh then the uh business",
    "start": "828240",
    "end": "831040"
  },
  {
    "text": "developers or users then they call the",
    "start": "831040",
    "end": "833600"
  },
  {
    "text": "joint inference model uh through SANA",
    "start": "833600",
    "end": "836320"
  },
  {
    "text": "lab and deploy deploy them to the edge",
    "start": "836320",
    "end": "838959"
  },
  {
    "text": "Yeah deploy the deep model in the code",
    "start": "838959",
    "end": "841360"
  },
  {
    "text": "at the shallow model in the edge node",
    "start": "841360",
    "end": "843360"
  },
  {
    "text": "Then we can do some code edge synergy uh",
    "start": "843360",
    "end": "846639"
  },
  {
    "text": "through the STA lab Yeah Uh the third",
    "start": "846639",
    "end": "852240"
  },
  {
    "text": "one is per perform inference with",
    "start": "852240",
    "end": "854399"
  },
  {
    "text": "shallow model or age and if the",
    "start": "854399",
    "end": "856720"
  },
  {
    "text": "confidence level is meet directly return",
    "start": "856720",
    "end": "859920"
  },
  {
    "text": "the result Yeah Otherwise send the data",
    "start": "859920",
    "end": "863279"
  },
  {
    "text": "to the code and inference with code",
    "start": "863279",
    "end": "866000"
  },
  {
    "text": "large model then return the result to",
    "start": "866000",
    "end": "868639"
  },
  {
    "text": "users Okay Uh this is the workflow for",
    "start": "868639",
    "end": "871760"
  },
  {
    "text": "the uh code edge joint",
    "start": "871760",
    "end": "874199"
  },
  {
    "text": "inference Okay Next I will introduce the",
    "start": "874199",
    "end": "877839"
  },
  {
    "text": "joint infrared workload defined in uh",
    "start": "877839",
    "end": "880800"
  },
  {
    "text": "stina Yeah you can see this is a uh C uh",
    "start": "880800",
    "end": "884639"
  },
  {
    "text": "called joint infra service Yeah in the",
    "start": "884639",
    "end": "888399"
  },
  {
    "text": "spec we have mainly have two parts Uh",
    "start": "888399",
    "end": "891519"
  },
  {
    "text": "first part is the uh h worker Each",
    "start": "891519",
    "end": "893920"
  },
  {
    "text": "worker is a port where run in each node",
    "start": "893920",
    "end": "897040"
  },
  {
    "text": "Yeah First it's include the model the",
    "start": "897040",
    "end": "899279"
  },
  {
    "text": "shadow model run in each node Yeah Then",
    "start": "899279",
    "end": "902880"
  },
  {
    "text": "uh we have uh the uh image container",
    "start": "902880",
    "end": "906560"
  },
  {
    "text": "Yeah We also have the configurous level",
    "start": "906560",
    "end": "908880"
  },
  {
    "text": "requirements in the age Yeah Uh the",
    "start": "908880",
    "end": "911360"
  },
  {
    "text": "right one is the code worker Yeah Cloer",
    "start": "911360",
    "end": "914480"
  },
  {
    "text": "also contain the model big model and the",
    "start": "914480",
    "end": "917760"
  },
  {
    "text": "uh docker image Yeah Okay This is a uh",
    "start": "917760",
    "end": "921920"
  },
  {
    "text": "API type for joint inference",
    "start": "921920",
    "end": "925240"
  },
  {
    "text": "service Okay Uh this is uh how we use",
    "start": "925240",
    "end": "929440"
  },
  {
    "text": "cube age and vas age to manage inference",
    "start": "929440",
    "end": "932639"
  },
  {
    "text": "workload Yeah you can uh from the",
    "start": "932639",
    "end": "935279"
  },
  {
    "text": "architecture you can see",
    "start": "935279",
    "end": "937399"
  },
  {
    "text": "uh we can use cube to uh deploy the uh",
    "start": "937399",
    "end": "942720"
  },
  {
    "text": "llm workloads from cloud to the age uh",
    "start": "942720",
    "end": "945440"
  },
  {
    "text": "in the age node we use the WM age",
    "start": "945440",
    "end": "947600"
  },
  {
    "text": "runtime uh to run the uh workloads Yeah",
    "start": "947600",
    "end": "951519"
  },
  {
    "text": "we also use the uh seda uh in the cloud",
    "start": "951519",
    "end": "955120"
  },
  {
    "text": "at edge to do the uh synergy",
    "start": "955120",
    "end": "958320"
  },
  {
    "text": "collaboration Yeah Okay This is the",
    "start": "958320",
    "end": "960560"
  },
  {
    "text": "whole architecture of our",
    "start": "960560",
    "end": "963240"
  },
  {
    "text": "solution Okay Next we will introduce two",
    "start": "963240",
    "end": "968399"
  },
  {
    "text": "demos Okay This is the first demo Yeah",
    "start": "969880",
    "end": "972560"
  },
  {
    "text": "you can see",
    "start": "972560",
    "end": "975120"
  },
  {
    "text": "Get node Okay We have one H node Y cloud",
    "start": "975120",
    "end": "978079"
  },
  {
    "text": "nodes Yeah H node is the node in H",
    "start": "978079",
    "end": "983519"
  },
  {
    "text": "Yeah Okay Next we will deploy a LLM",
    "start": "984519",
    "end": "987519"
  },
  {
    "text": "workload to the H",
    "start": "987519",
    "end": "989240"
  },
  {
    "text": "node Okay This is a uh LLM workload",
    "start": "989240",
    "end": "994519"
  },
  {
    "text": "deployment Yeah This is the Docker",
    "start": "994519",
    "end": "998360"
  },
  {
    "text": "image Yeah This is the",
    "start": "998360",
    "end": "1001079"
  },
  {
    "text": "part we use the host network",
    "start": "1001079",
    "end": "1006240"
  },
  {
    "text": "Yeah Okay Then we will apply the",
    "start": "1009399",
    "end": "1012240"
  },
  {
    "text": "workload to the edge",
    "start": "1012240",
    "end": "1015360"
  },
  {
    "text": "node Okay You can see the port is",
    "start": "1016920",
    "end": "1021440"
  },
  {
    "text": "running Okay Okay Now let's check the",
    "start": "1025880",
    "end": "1028160"
  },
  {
    "text": "container run in each node Yeah this is",
    "start": "1028160",
    "end": "1031038"
  },
  {
    "text": "uh LLM workload container uh in each",
    "start": "1031039",
    "end": "1035400"
  },
  {
    "text": "node Okay Uh let's access the workloads",
    "start": "1035400",
    "end": "1038880"
  },
  {
    "text": "from the uh",
    "start": "1038880",
    "end": "1041839"
  },
  {
    "text": "website Uh yeah this is the llama age",
    "start": "1042839",
    "end": "1046000"
  },
  {
    "text": "workload Yeah",
    "start": "1046000",
    "end": "1048400"
  },
  {
    "text": "right now we are running the",
    "start": "1048400",
    "end": "1050840"
  },
  {
    "text": "Q105 billion model It's a very small",
    "start": "1050840",
    "end": "1053280"
  },
  {
    "text": "model is very suitable for for edge and",
    "start": "1053280",
    "end": "1056240"
  },
  {
    "text": "uh it's on the on the edge but it's it's",
    "start": "1056240",
    "end": "1059120"
  },
  {
    "text": "on running on a CPU machine so it's it",
    "start": "1059120",
    "end": "1062960"
  },
  {
    "text": "will be a little slow but",
    "start": "1062960",
    "end": "1065640"
  },
  {
    "text": "uh but because the model is very small",
    "start": "1065640",
    "end": "1068559"
  },
  {
    "text": "it's uh it responds um kind of quickly",
    "start": "1068559",
    "end": "1073120"
  },
  {
    "text": "Okay",
    "start": "1073120",
    "end": "1076120"
  },
  {
    "text": "Okay Then we uh we are log into the",
    "start": "1086960",
    "end": "1091000"
  },
  {
    "text": "container Yeah And uh we lo into the",
    "start": "1091000",
    "end": "1094559"
  },
  {
    "text": "container and you can see there is the",
    "start": "1094559",
    "end": "1096480"
  },
  {
    "text": "uh was magic process So we use this",
    "start": "1096480",
    "end": "1099039"
  },
  {
    "text": "command line to run the uh Q1 uh 05",
    "start": "1099039",
    "end": "1104080"
  },
  {
    "text": "billion model So let",
    "start": "1104080",
    "end": "1106679"
  },
  {
    "text": "me let me",
    "start": "1106679",
    "end": "1110159"
  },
  {
    "text": "see let's see the uh whole uh command",
    "start": "1116679",
    "end": "1120080"
  },
  {
    "text": "line So this is the whole command line",
    "start": "1120080",
    "end": "1123440"
  },
  {
    "text": "we are using was M is the LM runtime and",
    "start": "1123440",
    "end": "1127760"
  },
  {
    "text": "um uh the uh N preload means that we are",
    "start": "1127760",
    "end": "1130960"
  },
  {
    "text": "using the was plugin and we are running",
    "start": "1130960",
    "end": "1135120"
  },
  {
    "text": "the uh Q1 to uh 0.5 billion model uh",
    "start": "1135120",
    "end": "1141200"
  },
  {
    "text": "it's uh we are using the GUI format and",
    "start": "1141200",
    "end": "1145280"
  },
  {
    "text": "uh we are also running an embedding",
    "start": "1145280",
    "end": "1146960"
  },
  {
    "text": "model so embedding model is important",
    "start": "1146960",
    "end": "1148880"
  },
  {
    "text": "for um ramp application",
    "start": "1148880",
    "end": "1151200"
  },
  {
    "text": "So and minimally is",
    "start": "1151200",
    "end": "1153960"
  },
  {
    "text": "omin and we are using the llama API uh",
    "start": "1153960",
    "end": "1157960"
  },
  {
    "text": "server wasn't f it's file as I mentioned",
    "start": "1157960",
    "end": "1162000"
  },
  {
    "text": "it's uh it's possible so it can run",
    "start": "1162000",
    "end": "1165440"
  },
  {
    "text": "across different platforms and then we",
    "start": "1165440",
    "end": "1167919"
  },
  {
    "text": "have the pro templates for the light",
    "start": "1167919",
    "end": "1169679"
  },
  {
    "text": "lang model here is the um",
    "start": "1169679",
    "end": "1173720"
  },
  {
    "text": "chl and uh we also have the uh content",
    "start": "1173720",
    "end": "1177840"
  },
  {
    "text": "size uh you can uh uh you can customize",
    "start": "1177840",
    "end": "1181039"
  },
  {
    "text": "your content size here and uh we are",
    "start": "1181039",
    "end": "1184880"
  },
  {
    "text": "running the model on the AT80 port um",
    "start": "1184880",
    "end": "1188799"
  },
  {
    "text": "and we just show it uh in the in the",
    "start": "1188799",
    "end": "1191799"
  },
  {
    "text": "browser",
    "start": "1191799",
    "end": "1194799"
  },
  {
    "text": "So so that's how you um how you use was",
    "start": "1195559",
    "end": "1199360"
  },
  {
    "text": "manage to run a light language model Uh",
    "start": "1199360",
    "end": "1201520"
  },
  {
    "text": "you don't need any uh any dependencies",
    "start": "1201520",
    "end": "1204000"
  },
  {
    "text": "You just need to download was magic",
    "start": "1204000",
    "end": "1205679"
  },
  {
    "text": "download the model download the uh the",
    "start": "1205679",
    "end": "1207840"
  },
  {
    "text": "wasm file and then write So next let's",
    "start": "1207840",
    "end": "1211200"
  },
  {
    "text": "see the uh next",
    "start": "1211200",
    "end": "1213960"
  },
  {
    "text": "demo",
    "start": "1213960",
    "end": "1216960"
  },
  {
    "text": "Okay Okay Okay Next we will introduce",
    "start": "1218280",
    "end": "1221919"
  },
  {
    "text": "the second",
    "start": "1221919",
    "end": "1224639"
  },
  {
    "text": "demo Yeah This demo we will use the",
    "start": "1224919",
    "end": "1227919"
  },
  {
    "text": "cubage sa advum age uh to do the uh age",
    "start": "1227919",
    "end": "1231600"
  },
  {
    "text": "code joint inference Yeah let's demo",
    "start": "1231600",
    "end": "1237360"
  },
  {
    "text": "now Yeah this also get node We have edge",
    "start": "1239799",
    "end": "1242720"
  },
  {
    "text": "node at clone",
    "start": "1242720",
    "end": "1245400"
  },
  {
    "text": "node Yeah this is a joint influence",
    "start": "1245400",
    "end": "1247919"
  },
  {
    "text": "service",
    "start": "1247919",
    "end": "1250480"
  },
  {
    "text": "yamo Yeah you can see this is the yaml I",
    "start": "1253559",
    "end": "1256720"
  },
  {
    "text": "uh introduced uh just now Uh it's",
    "start": "1256720",
    "end": "1259760"
  },
  {
    "text": "include the uh code worker and age",
    "start": "1259760",
    "end": "1262080"
  },
  {
    "text": "worker Yeah we will run uh container pod",
    "start": "1262080",
    "end": "1265200"
  },
  {
    "text": "in a clone node and edge",
    "start": "1265200",
    "end": "1268880"
  },
  {
    "text": "node Yeah this is the age",
    "start": "1270760",
    "end": "1274200"
  },
  {
    "text": "worker Yeah this is the code worker",
    "start": "1274200",
    "end": "1279320"
  },
  {
    "text": "Okay Then we'll apply the",
    "start": "1285600",
    "end": "1288440"
  },
  {
    "text": "uh workload in the uh kage",
    "start": "1288440",
    "end": "1292679"
  },
  {
    "text": "cluster Yeah you can see the",
    "start": "1292679",
    "end": "1296280"
  },
  {
    "text": "pod Yeah we will do the uh helmet",
    "start": "1296280",
    "end": "1299440"
  },
  {
    "text": "detection in this demo",
    "start": "1299440",
    "end": "1301559"
  },
  {
    "text": "Yeah you can see we have pod running",
    "start": "1301559",
    "end": "1304240"
  },
  {
    "text": "code at the running",
    "start": "1304240",
    "end": "1306679"
  },
  {
    "text": "edge Yeah all port is running now",
    "start": "1306679",
    "end": "1312039"
  },
  {
    "text": "Yeah Why close y pod",
    "start": "1312480",
    "end": "1317720"
  },
  {
    "text": "Yeah Then we will see the logs in the uh",
    "start": "1324559",
    "end": "1328000"
  },
  {
    "text": "clone",
    "start": "1328000",
    "end": "1330600"
  },
  {
    "text": "part If the confidence level is isn't",
    "start": "1330600",
    "end": "1333679"
  },
  {
    "text": "meet at age the request will forward to",
    "start": "1333679",
    "end": "1336240"
  },
  {
    "text": "the clone node",
    "start": "1336240",
    "end": "1339679"
  },
  {
    "text": "Yeah this is a log for the uh H node",
    "start": "1339679",
    "end": "1342480"
  },
  {
    "text": "Yeah Then we will start u uh video sim",
    "start": "1342480",
    "end": "1347320"
  },
  {
    "text": "simulator for uh simulate the video",
    "start": "1347320",
    "end": "1352240"
  },
  {
    "text": "input Okay this is a video input",
    "start": "1353400",
    "end": "1358440"
  },
  {
    "text": "Okay next let's see the uh output uh",
    "start": "1376440",
    "end": "1379600"
  },
  {
    "text": "inference output Yeah we will uh see the",
    "start": "1379600",
    "end": "1383039"
  },
  {
    "text": "picture uh for the hair helmet uh",
    "start": "1383039",
    "end": "1386320"
  },
  {
    "text": "detection Yeah this is the uh",
    "start": "1386320",
    "end": "1390559"
  },
  {
    "text": "output Yeah let me see the results",
    "start": "1390679",
    "end": "1397080"
  },
  {
    "text": "Yeah the results with uh is some uh",
    "start": "1397520",
    "end": "1401360"
  },
  {
    "text": "picture",
    "start": "1401360",
    "end": "1404360"
  },
  {
    "text": "Yeah let's have a uh comparison for the",
    "start": "1406159",
    "end": "1411760"
  },
  {
    "text": "results Yeah you can see uh this is the",
    "start": "1415400",
    "end": "1418720"
  },
  {
    "text": "uh from age",
    "start": "1418720",
    "end": "1420799"
  },
  {
    "text": "uh this helmet is is not uh recognized",
    "start": "1420799",
    "end": "1425720"
  },
  {
    "text": "Yeah Uh so it will forward the request",
    "start": "1425720",
    "end": "1428960"
  },
  {
    "text": "to the code in the code Okay In the code",
    "start": "1428960",
    "end": "1432080"
  },
  {
    "text": "you can see this helmet is yeah is",
    "start": "1432080",
    "end": "1434720"
  },
  {
    "text": "recognized",
    "start": "1434720",
    "end": "1437720"
  },
  {
    "text": "Okay You can see this is a result Uh the",
    "start": "1456799",
    "end": "1460080"
  },
  {
    "text": "left side is uh from the age Yeah The",
    "start": "1460080",
    "end": "1463520"
  },
  {
    "text": "right side is from cloud Yeah It uh the",
    "start": "1463520",
    "end": "1467200"
  },
  {
    "text": "confidence level is more high in the",
    "start": "1467200",
    "end": "1469039"
  },
  {
    "text": "cloud Yeah",
    "start": "1469039",
    "end": "1471240"
  },
  {
    "text": "Okay So this is the uh second demo",
    "start": "1471240",
    "end": "1475799"
  },
  {
    "text": "Yeah Okay Thank you Uh if you have any",
    "start": "1475799",
    "end": "1479919"
  },
  {
    "text": "question you can join our community wom",
    "start": "1479919",
    "end": "1482159"
  },
  {
    "text": "age at cube",
    "start": "1482159",
    "end": "1484880"
  },
  {
    "text": "age Okay thank",
    "start": "1485720",
    "end": "1488030"
  },
  {
    "text": "[Applause]",
    "start": "1488030",
    "end": "1489400"
  },
  {
    "text": "you So thanks a lot That was cool demo",
    "start": "1489400",
    "end": "1492799"
  },
  {
    "text": "Thank you very much Uh there is time for",
    "start": "1492799",
    "end": "1495039"
  },
  {
    "text": "one or two questions So if you have a",
    "start": "1495039",
    "end": "1497279"
  },
  {
    "text": "question just go to the microphone",
    "start": "1497279",
    "end": "1500640"
  },
  {
    "text": "Yeah If you have any questions you can",
    "start": "1500640",
    "end": "1502320"
  },
  {
    "text": "also go to our project booth tomorrow",
    "start": "1502320",
    "end": "1505600"
  },
  {
    "text": "Right Yeah you can also go to the",
    "start": "1505600",
    "end": "1507440"
  },
  {
    "text": "project booth or catch them after the",
    "start": "1507440",
    "end": "1509520"
  },
  {
    "text": "talk So if there are no questions then",
    "start": "1509520",
    "end": "1512480"
  },
  {
    "text": "thanks Thank you Thank you again Thank",
    "start": "1512480",
    "end": "1514480"
  },
  {
    "text": "you Thank you",
    "start": "1514480",
    "end": "1518360"
  }
]
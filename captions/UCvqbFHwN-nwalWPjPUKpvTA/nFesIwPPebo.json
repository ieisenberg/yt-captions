[
  {
    "text": "hello",
    "start": "2999",
    "end": "5999"
  },
  {
    "text": "hey guys hey is Ken with us this morning",
    "start": "14960",
    "end": "20150"
  },
  {
    "text": "you Ken isn't on just yet easy no he's",
    "start": "24140",
    "end": "30720"
  },
  {
    "text": "not on the participant all right but so some folks from Microsoft are gonna",
    "start": "30720",
    "end": "36690"
  },
  {
    "text": "present today those folks on the phone yeah this is the book can you hear me",
    "start": "36690",
    "end": "42930"
  },
  {
    "text": "hey Deepak yeah hey you know we I'm",
    "start": "42930",
    "end": "49590"
  },
  {
    "text": "running around the conference trying to find a place to uh to park for a moment I think I found one um oh so we've got",
    "start": "49590",
    "end": "58470"
  },
  {
    "text": "Brian - Shawn Deepak she uh she's yeah",
    "start": "58470",
    "end": "64259"
  },
  {
    "text": "and Mike Mike and Brian I gotta say your",
    "start": "64259",
    "end": "69930"
  },
  {
    "text": "names were easier than the others if I can go and I think you did well",
    "start": "69930",
    "end": "77390"
  },
  {
    "text": "well fantastic I you know our fearless leader Kenan is as a busy calendar yeah",
    "start": "79130",
    "end": "87030"
  },
  {
    "text": "I suspected we were about five after now six after you'd probably want us to get",
    "start": "87030",
    "end": "93120"
  },
  {
    "text": "going in his stead let me let me pin him in one more minute let me ping him and",
    "start": "93120",
    "end": "98880"
  },
  {
    "text": "you see us huh he's gonna make it",
    "start": "98880",
    "end": "103610"
  },
  {
    "text": "can everyone see the screen that I've shared message",
    "start": "125130",
    "end": "147959"
  },
  {
    "text": "[Music]",
    "start": "148120",
    "end": "151269"
  },
  {
    "text": "okay hey fair enough let let's call it so sore we're eight minutes and um Ken has been",
    "start": "167790",
    "end": "174220"
  },
  {
    "text": "duly warned I'm pumped to to hear about",
    "start": "174220",
    "end": "179260"
  },
  {
    "text": "this okay thanks so today I'm going to talk about how we",
    "start": "179260",
    "end": "187540"
  },
  {
    "text": "are thinking about containers in Azure networking and how we are leveraging CNI",
    "start": "187540",
    "end": "193780"
  },
  {
    "text": "and some of the scenarios that we are facing that we think we need to to add",
    "start": "193780",
    "end": "202720"
  },
  {
    "text": "support for in CNI okay so as your",
    "start": "202720",
    "end": "207820"
  },
  {
    "text": "network is a very rich hyper scalable",
    "start": "207820",
    "end": "212950"
  },
  {
    "text": "reliable virtual network that we've offered for many years now for virtual",
    "start": "212950",
    "end": "219280"
  },
  {
    "text": "machines and that we have brought two containers recently it offers lots of",
    "start": "219280",
    "end": "226120"
  },
  {
    "text": "capabilities right starting here on the left here virtual machines or containers",
    "start": "226120",
    "end": "232180"
  },
  {
    "text": "can be accessed through public IP addresses directly from the Internet",
    "start": "232180",
    "end": "237910"
  },
  {
    "text": "we provide load balancing we provide Ackles your front-end access gets a DNS name so",
    "start": "237910",
    "end": "247329"
  },
  {
    "text": "customers can access your service over the Internet using DNS names we provide",
    "start": "247329",
    "end": "252910"
  },
  {
    "text": "DDoS protection then moving here on the right on the virtual network we offer a",
    "start": "252910",
    "end": "258489"
  },
  {
    "text": "very rich virtual network for for your virtual machines and containers in the",
    "start": "258489",
    "end": "263500"
  },
  {
    "text": "cloud so basically customers can specify their own IP address ranges their own",
    "start": "263500",
    "end": "269620"
  },
  {
    "text": "subnets then they can specify security groups by which they can specify",
    "start": "269620",
    "end": "275289"
  },
  {
    "text": "isolation policies like this this security group is not allowed to that talk to that",
    "start": "275289",
    "end": "280330"
  },
  {
    "text": "chaotic repent and so forth we support rich service training through a",
    "start": "280330",
    "end": "285400"
  },
  {
    "text": "construct that we call user-defined routes which basically lets customer",
    "start": "285400",
    "end": "290830"
  },
  {
    "text": "control how traffic from one virtual machine to another virtual machine flows and whether that needs to be sent over",
    "start": "290830",
    "end": "298449"
  },
  {
    "text": "through a virtual appliance before it gets routed to the destination so so we",
    "start": "298449",
    "end": "304389"
  },
  {
    "text": "have a rich suite of capabilities in in the private network that customers can can set up in in the in the cloud",
    "start": "304389",
    "end": "311139"
  },
  {
    "text": "environment we have a very rich ecosystem of network appliances in the azure marketplace that leverage these",
    "start": "311139",
    "end": "316509"
  },
  {
    "text": "capabilities to insert themselves into customers virtual networks we offer back",
    "start": "316509",
    "end": "322569"
  },
  {
    "text": "in connectivity to customers on-premise so this may be through point to site VPN",
    "start": "322569",
    "end": "327669"
  },
  {
    "text": "or VPN gateways we also offer private peering through various ice peas and providers that we",
    "start": "327669",
    "end": "335860"
  },
  {
    "text": "have relationship with we call that solution Express route so this is a brief primer of on the virtual network",
    "start": "335860",
    "end": "342639"
  },
  {
    "text": "that we offer to our customers today right now let's look at as your CNI",
    "start": "342639",
    "end": "349270"
  },
  {
    "text": "right so so when we started looking at see CNI and how we do container",
    "start": "349270",
    "end": "357360"
  },
  {
    "text": "networking for Azure right there were a few things that that we observed right",
    "start": "357360",
    "end": "364240"
  },
  {
    "text": "one is we want to leverage the Azure Sdn which already is a very evolved ico",
    "start": "364240",
    "end": "371529"
  },
  {
    "text": "system and bring those same Sdn capabilities to containers because when",
    "start": "371529",
    "end": "376750"
  },
  {
    "text": "we talk to customers they essentially need similar kind of network and so even",
    "start": "376750",
    "end": "384099"
  },
  {
    "text": "more but some of the core constructs around virtual networks load balancing",
    "start": "384099",
    "end": "389680"
  },
  {
    "text": "DNS they need for containers as well we realize that that in the container world",
    "start": "389680",
    "end": "396129"
  },
  {
    "text": "there are multiple orchestrators that exist today to manage those containers",
    "start": "396129",
    "end": "401979"
  },
  {
    "text": "so we have to integrate with with these various orchestrators of course we are",
    "start": "401979",
    "end": "407979"
  },
  {
    "text": "running in the in the guest environment for us VM is equivalent to a guest",
    "start": "407979",
    "end": "413980"
  },
  {
    "text": "so the operating system there can be either Linux or Windows so we need to support both scale is a big deal for",
    "start": "413980",
    "end": "421780"
  },
  {
    "text": "containers creating a million VMs is much harder than creating a million",
    "start": "421780",
    "end": "427210"
  },
  {
    "text": "containers so so that's why scaling the virtual network is is essential for",
    "start": "427210",
    "end": "434050"
  },
  {
    "text": "container scenarios pro actually if I can remand here can you define in a bit",
    "start": "434050",
    "end": "441750"
  },
  {
    "text": "what is a v-net okay sure a v-net is a virtual network that a",
    "start": "441750",
    "end": "448930"
  },
  {
    "text": "customer specifies through a template that hey I want to deploy these 10 VMs",
    "start": "448930",
    "end": "457420"
  },
  {
    "text": "in in these two subnets here is the IP address space that I want to use for my",
    "start": "457420",
    "end": "464200"
  },
  {
    "text": "my workload in the cloud so the define",
    "start": "464200",
    "end": "469620"
  },
  {
    "text": "subnets they define address ranges they define their security policies they",
    "start": "469620",
    "end": "476260"
  },
  {
    "text": "define their routing policies so it's basically customers own private network for their their compute workloads in the",
    "start": "476260",
    "end": "483520"
  },
  {
    "text": "cloud right so in Amazon's term Amazon calls at V PC as your calls it V net",
    "start": "483520",
    "end": "489460"
  },
  {
    "text": "right so so they're basically the same okay okay",
    "start": "489460",
    "end": "494740"
  },
  {
    "text": "I think that actually helps some so it's not necessarily an an overlay Network",
    "start": "494740",
    "end": "500290"
  },
  {
    "text": "provisioned all-seeing eye or a year your CNR plugin yeah so right now V net",
    "start": "500290",
    "end": "508930"
  },
  {
    "text": "so far what I've described to you is underlay in the sense that it is implemented at the hose and exposed to",
    "start": "508930",
    "end": "516130"
  },
  {
    "text": "the VMS now when we start talking about containers right there are of course",
    "start": "516130",
    "end": "522640"
  },
  {
    "text": "overlays can exist inside the VMS as well as we have an underlay at the host",
    "start": "522640",
    "end": "528310"
  },
  {
    "text": "level and both can coexist but at the same time we want to leverage",
    "start": "528310",
    "end": "534370"
  },
  {
    "text": "the capabilities that are already available through the underlay as well as as where it makes sense to to provide",
    "start": "534370",
    "end": "542470"
  },
  {
    "text": "additional capabilities by an overlay on the top so v-net by itself is not overlay but it",
    "start": "542470",
    "end": "550299"
  },
  {
    "text": "does not preclude overlays overlays can coexist with underlays okay provisioning",
    "start": "550299",
    "end": "559689"
  },
  {
    "text": "time of less than a second is is a requirement that again containers life in the virtual machine world the",
    "start": "559689",
    "end": "566889"
  },
  {
    "text": "provisioning times can be longer the one one key thing here is as we talk to our",
    "start": "566889",
    "end": "576069"
  },
  {
    "text": "customers customers are not purely container customers or purely VM",
    "start": "576069",
    "end": "581759"
  },
  {
    "text": "customers right they they may have some workloads that are containerized and",
    "start": "581759",
    "end": "586809"
  },
  {
    "text": "then some other part of the infrastructure that is not containerized so so what we've noticed for a lot of",
    "start": "586809",
    "end": "594189"
  },
  {
    "text": "our customers is is they have a mix of both container and and and VM based",
    "start": "594189",
    "end": "599860"
  },
  {
    "text": "workloads and they don't want to to build two separate networks that are",
    "start": "599860",
    "end": "605549"
  },
  {
    "text": "completely oblivious of each other for these scenarios they want a seamless",
    "start": "605549",
    "end": "612639"
  },
  {
    "text": "single network that spans across both swear containers can talk to VMs and VMs",
    "start": "612639",
    "end": "618579"
  },
  {
    "text": "can talk to containers they want to specify their policies in a consistent way so one of the the motivation for us",
    "start": "618579",
    "end": "625749"
  },
  {
    "text": "to leverage as your Sdn has been to make sure customers get a consistent",
    "start": "625749",
    "end": "633129"
  },
  {
    "text": "experience no matter in what form they deploy their compute workload in the",
    "start": "633129",
    "end": "638679"
  },
  {
    "text": "cloud whether it be as your functions or lambdas or containers or VMs right we",
    "start": "638679",
    "end": "644649"
  },
  {
    "text": "want to give a consistent network and a consistent way of managing policies for",
    "start": "644649",
    "end": "650649"
  },
  {
    "text": "the network to our customers so let me move on to next slide here ok so now I",
    "start": "650649",
    "end": "658660"
  },
  {
    "text": "start digging more into into how we leverage CNI in and how we've built this",
    "start": "658660",
    "end": "667079"
  },
  {
    "text": "functionality right so at the top level I show ACS which is as your container",
    "start": "667079",
    "end": "673779"
  },
  {
    "text": "service engine this is the service that today creates orchestrators",
    "start": "673779",
    "end": "680260"
  },
  {
    "text": "or launches orchestrators on behalf of customers so customer comes to acs and says hey create a kubernetes cluster for",
    "start": "680260",
    "end": "687279"
  },
  {
    "text": "me or create a DCOs clustered for me so acs engine creates that but then that",
    "start": "687279",
    "end": "697290"
  },
  {
    "text": "the way we plug Sdn into that Orchestrator is by leveraging CNI right",
    "start": "697290",
    "end": "704680"
  },
  {
    "text": "and for that we've written a few plugins right there is a network plug-in which",
    "start": "704680",
    "end": "711399"
  },
  {
    "text": "basically attaches container interfaces to the underlying as your virtual",
    "start": "711399",
    "end": "717339"
  },
  {
    "text": "network that is implemented at the host level right and it it routes traffic on",
    "start": "717339",
    "end": "725230"
  },
  {
    "text": "the virtual network right then there is the item plug-in which is responsible for allocating IP addresses for these",
    "start": "725230",
    "end": "733810"
  },
  {
    "text": "for the containers through CNI one key thing I want to call out here right so",
    "start": "733810",
    "end": "739600"
  },
  {
    "text": "the the experience that we've offered to the customers is it's one IP address",
    "start": "739600",
    "end": "745209"
  },
  {
    "text": "space that they can manage for VMs and containers whereby a subset of that",
    "start": "745209",
    "end": "752050"
  },
  {
    "text": "address space is delegated for container use but the other space may be used for VMs that way they have a single network",
    "start": "752050",
    "end": "759700"
  },
  {
    "text": "and VMs and containers can freely communicate with each other rather than",
    "start": "759700",
    "end": "764800"
  },
  {
    "text": "then building the two networks and they're using their address space completely in isolation in which case",
    "start": "764800",
    "end": "770709"
  },
  {
    "text": "case they become islands so Deepak a couple quick questions are actually am i",
    "start": "770709",
    "end": "777000"
  },
  {
    "text": "Wireless cut out for moments you might have said this but the way in which that designation is done between IPS for",
    "start": "777000",
    "end": "786820"
  },
  {
    "text": "containers and IPS for VMs that's sounds like that's within your iPad plug-in that's more of a DHCP reservation or not",
    "start": "786820",
    "end": "795160"
  },
  {
    "text": "not reservation but but yeah yeah it's",
    "start": "795160",
    "end": "801430"
  },
  {
    "text": "it's it's along the same lines it's done in our item plug-in and DHCP is the",
    "start": "801430",
    "end": "808149"
  },
  {
    "text": "protocol we used to assign IP addresses but how we make the reservation is through our API",
    "start": "808149",
    "end": "814300"
  },
  {
    "text": "where customers can say hey this address spaces is reserved for VMs or this address space is delegated for",
    "start": "814300",
    "end": "820630"
  },
  {
    "text": "containers and the tech that drives the that runs the DHCP server this is what",
    "start": "820630",
    "end": "828370"
  },
  {
    "text": "is that so that's part of the azure platform already so we we run DHCP server for all the virtual machines and",
    "start": "828370",
    "end": "836080"
  },
  {
    "text": "for containers in the cloud it's running on the host and it's talking to our",
    "start": "836080",
    "end": "842470"
  },
  {
    "text": "network controller which is telling hey on this VM here is the IP address that you should respond to when you get a",
    "start": "842470",
    "end": "849190"
  },
  {
    "text": "DHCP request from the VM or from the container so our network controller sis is provisioning or DHCP server to",
    "start": "849190",
    "end": "856150"
  },
  {
    "text": "respond with the right IP address okay",
    "start": "856150",
    "end": "864250"
  },
  {
    "text": "so so this this is a brief overview of what we have currently in available for",
    "start": "864250",
    "end": "871720"
  },
  {
    "text": "containers through - or CNI plug in in in the public cloud now there are new",
    "start": "871720",
    "end": "878650"
  },
  {
    "text": "scenarios that are coming up and this is",
    "start": "878650",
    "end": "883890"
  },
  {
    "text": "what is driving us for for proposing extensions to C&I one is single tenant",
    "start": "883890",
    "end": "895390"
  },
  {
    "text": "container clusters right so so a customer comes and says hey I want to to",
    "start": "895390",
    "end": "904300"
  },
  {
    "text": "create my container cluster and we we",
    "start": "904300",
    "end": "910300"
  },
  {
    "text": "provide managed Orchestrator experience what that that means is what I call it",
    "start": "910300",
    "end": "917050"
  },
  {
    "text": "here IKS as your coordinator service what it does is rather than customer",
    "start": "917050",
    "end": "923380"
  },
  {
    "text": "running their own Orchestrator v as your platform is running Orchestrator on",
    "start": "923380",
    "end": "929350"
  },
  {
    "text": "behalf of them right so customer does not need to deal with managing and",
    "start": "929350",
    "end": "934870"
  },
  {
    "text": "running their own own Orchestrator so think of it as orchestrated as a service or or container yeah so so we we deploy",
    "start": "934870",
    "end": "943960"
  },
  {
    "text": "an Orchestrator on behalf of them and customer just has to deal with the",
    "start": "943960",
    "end": "949250"
  },
  {
    "text": "containers that they they they get right",
    "start": "949250",
    "end": "954520"
  },
  {
    "text": "so so you in this scenario the containers will also be connected to",
    "start": "954520",
    "end": "960589"
  },
  {
    "text": "v-net via as your CNI and then v-net policy will be available to containers",
    "start": "960589",
    "end": "965890"
  },
  {
    "text": "right so the second scenario which is the next step of the previous scenario",
    "start": "965890",
    "end": "971300"
  },
  {
    "text": "here we are taking the next step where we are offering container as a service",
    "start": "971300",
    "end": "976730"
  },
  {
    "text": "customer doesn't even need to take what arcus traitor",
    "start": "976730",
    "end": "982779"
  },
  {
    "text": "they get to use they just say hey I need X number of containers and as your",
    "start": "982779",
    "end": "990490"
  },
  {
    "text": "container service is the one that is responsible for creating these multiple",
    "start": "990490",
    "end": "996950"
  },
  {
    "text": "containers on behalf of medius customers so really the key difference here is",
    "start": "996950",
    "end": "1002290"
  },
  {
    "text": "there's not an Orchestrator per customer per tenant right the orchestrator is",
    "start": "1002290",
    "end": "1008170"
  },
  {
    "text": "shared across multiple customers and customers just get the the individual",
    "start": "1008170",
    "end": "1013870"
  },
  {
    "text": "containers 30 they want right back question on that it yeah",
    "start": "1013870",
    "end": "1021610"
  },
  {
    "text": "you're able to say but what's the what Kino orchestrators use behind the scenes",
    "start": "1021610",
    "end": "1027428"
  },
  {
    "text": "for your cans so today we have offering based on",
    "start": "1027429",
    "end": "1034870"
  },
  {
    "text": "Cooper or we will have offering based on kubernetes and we will have offering based on service fabric so so we will",
    "start": "1034870",
    "end": "1044170"
  },
  {
    "text": "use the continual Orchestrator behind-the-scene customer doesn't need to know about it okay yeah that's kind",
    "start": "1044170",
    "end": "1051700"
  },
  {
    "text": "of my question is which one is that it is kubernetes okay so so similar model",
    "start": "1051700",
    "end": "1064840"
  },
  {
    "text": "is therefore as your functions where customer doesn't care about what function Orchestrator is being used they",
    "start": "1064840",
    "end": "1072250"
  },
  {
    "text": "just care about deploying in and and running their functions as your web apps",
    "start": "1072250",
    "end": "1077590"
  },
  {
    "text": "which is similar along the lines of hey customer just cares about deploying",
    "start": "1077590",
    "end": "1082600"
  },
  {
    "text": "their website the the orchestration and management of those websites is left to",
    "start": "1082600",
    "end": "1088330"
  },
  {
    "text": "a central coordinator right so then the the next scenario",
    "start": "1088330",
    "end": "1097780"
  },
  {
    "text": "which I've alluded to before right so these containers that get created right",
    "start": "1097780",
    "end": "1105160"
  },
  {
    "text": "in the azure v-net customer wants rich policies to to connect and protect these",
    "start": "1105160",
    "end": "1112330"
  },
  {
    "text": "containers and the workload that is running on those containers and they're asking us for four similar constructs",
    "start": "1112330",
    "end": "1118180"
  },
  {
    "text": "that they're used to for their virtual machines and these are pretty standard constructs are very austere right",
    "start": "1118180",
    "end": "1124840"
  },
  {
    "text": "there's the security group notion there's the notion of service chaining VPN and private peering capabilities",
    "start": "1124840",
    "end": "1132960"
  },
  {
    "text": "there is another interesting trend that we are seeing this is service endpoints",
    "start": "1132960",
    "end": "1139870"
  },
  {
    "text": "whereby customers like if they even when they're running sheer on a shared pass",
    "start": "1139870",
    "end": "1146710"
  },
  {
    "text": "service like storage or sequel DB as a",
    "start": "1146710",
    "end": "1152440"
  },
  {
    "text": "service which is a multi-tenant service they still want those endpoints to be",
    "start": "1152440",
    "end": "1158860"
  },
  {
    "text": "isolated and protected from other customers so they want even the",
    "start": "1158860",
    "end": "1164830"
  },
  {
    "text": "endpoints of those shared services to be projected inside their V net and to be locked down to the virtual network right",
    "start": "1164830",
    "end": "1171700"
  },
  {
    "text": "so this is I would say even the next step of containers where the service may not be containerized but still it has to",
    "start": "1171700",
    "end": "1179740"
  },
  {
    "text": "provide isolation at the network level on a per per customer basis by by",
    "start": "1179740",
    "end": "1185830"
  },
  {
    "text": "isolating them into different V nets load balancer DNS not write customers",
    "start": "1185830",
    "end": "1192010"
  },
  {
    "text": "want all all those those capabilities and they want the policies to be common",
    "start": "1192010",
    "end": "1197260"
  },
  {
    "text": "for VM and container workloads right so",
    "start": "1197260",
    "end": "1203320"
  },
  {
    "text": "based on these scenarios here are the the requirements that that we would like",
    "start": "1203320",
    "end": "1210010"
  },
  {
    "text": "to work with CNI and see how we can address these these requirements right",
    "start": "1210010",
    "end": "1215940"
  },
  {
    "text": "one is around the policies so I know right now kubernetes has a way to specify policies and and maybe that's",
    "start": "1215940",
    "end": "1223120"
  },
  {
    "text": "that's okay that's totally fine but we would like to be able to bridge the capabilities of",
    "start": "1223120",
    "end": "1230080"
  },
  {
    "text": "the underlying platform with the orchestrator specific policies so that",
    "start": "1230080",
    "end": "1237960"
  },
  {
    "text": "so that a customer may be able to use any number of our guest raters and may",
    "start": "1238559",
    "end": "1245110"
  },
  {
    "text": "be able to specify those policies in an Orchestrator specific language but down",
    "start": "1245110",
    "end": "1252340"
  },
  {
    "text": "below we are able to translate that into a common way of rationalizing those",
    "start": "1252340",
    "end": "1258340"
  },
  {
    "text": "policies and implementing those policies and managing those policies otherwise as",
    "start": "1258340",
    "end": "1264850"
  },
  {
    "text": "a public cloud platform provider we we have to write a plug-in for each Orchestrator for the implementation of",
    "start": "1264850",
    "end": "1271809"
  },
  {
    "text": "policies what CNI has done awesome at is in terms of network virtualization where",
    "start": "1271809",
    "end": "1278850"
  },
  {
    "text": "we are able to plug in to multiple orchestrators in a standard way to",
    "start": "1278850",
    "end": "1284470"
  },
  {
    "text": "implement virtual networks I think the same capability needs to be extended to policies so that we can",
    "start": "1284470",
    "end": "1290529"
  },
  {
    "text": "implement policies in a consistent way regardless of of what the orchestrator",
    "start": "1290529",
    "end": "1295720"
  },
  {
    "text": "is multi tenant networks on continued sorry do you do you wanna discuss these",
    "start": "1295720",
    "end": "1303399"
  },
  {
    "text": "one by one or do you want to read them all out and then discuss afterwards we can take it either way we can we can",
    "start": "1303399",
    "end": "1313480"
  },
  {
    "text": "discuss them here itself why don't we do that okay so the this Brian Boehm here I",
    "start": "1313480",
    "end": "1322470"
  },
  {
    "text": "happened to be as CNI maintainer I think I'm the only one on this call and I also",
    "start": "1322470",
    "end": "1332710"
  },
  {
    "text": "work on the weave network so how would",
    "start": "1332710",
    "end": "1338679"
  },
  {
    "text": "you anticipate so the thing with policies is that the rules generally",
    "start": "1338679",
    "end": "1344440"
  },
  {
    "text": "talk about groupings of things for instance the way kubernetes does it is",
    "start": "1344440",
    "end": "1349450"
  },
  {
    "text": "the groupings were specified by namespace and by label oh how do you",
    "start": "1349450",
    "end": "1355419"
  },
  {
    "text": "envisage that would work cross Orchestrator I think this notion of grouping and",
    "start": "1355419",
    "end": "1361889"
  },
  {
    "text": "tagging is fairly generic so if we defined a standard way to grope and tag",
    "start": "1361889",
    "end": "1368789"
  },
  {
    "text": "and then specify apples based on those groups and tags in a standard way in CNI",
    "start": "1368789",
    "end": "1374820"
  },
  {
    "text": "then I think that will meet the",
    "start": "1374820",
    "end": "1380820"
  },
  {
    "text": "requirements of various orchestrators now different orchestrators may choose",
    "start": "1380820",
    "end": "1386309"
  },
  {
    "text": "to do more advanced stuff but at a bare minimal level I think if we define the",
    "start": "1386309",
    "end": "1392370"
  },
  {
    "text": "notion of grouping and tagging that will that I'm really finding that difficult",
    "start": "1392370",
    "end": "1406590"
  },
  {
    "text": "to imagine okay well we can move on I guess see here is basically if you have",
    "start": "1406590",
    "end": "1417450"
  },
  {
    "text": "a basic way of describing tags and memberships to those tags for workloads",
    "start": "1417450",
    "end": "1423240"
  },
  {
    "text": "and then policies can be specified for those tags themselves like this this tag",
    "start": "1423240",
    "end": "1428519"
  },
  {
    "text": "means you should have access to Internet or you should have put this this load",
    "start": "1428519",
    "end": "1433710"
  },
  {
    "text": "should be behind a load balancer on this way and and this is the end point I won't expose too so all those things can",
    "start": "1433710",
    "end": "1439529"
  },
  {
    "text": "be put be specified on the tags and then when the container itself is our part",
    "start": "1439529",
    "end": "1445289"
  },
  {
    "text": "itself is instantiated it just subscribes to membership to attack that's that's one way to look at it and",
    "start": "1445289",
    "end": "1451769"
  },
  {
    "text": "that's that's that's kind of most of the cloud providers and platforms already",
    "start": "1451769",
    "end": "1456899"
  },
  {
    "text": "supports some similar notion along these lines so as we look at this this item",
    "start": "1456899",
    "end": "1465269"
  },
  {
    "text": "right I think the from the cni standpoint I'm Bryan Keating actually I don't believe this is something we would",
    "start": "1465269",
    "end": "1470549"
  },
  {
    "text": "extend CNI to manage but this might be an area that sig Ok Go Ahead",
    "start": "1470549",
    "end": "1477779"
  },
  {
    "text": "this is not not the forum where we take decisions about what they and I do I was",
    "start": "1477779",
    "end": "1484620"
  },
  {
    "text": "a person in there sorry I'm prepared to you know listen and try and help out it",
    "start": "1484620",
    "end": "1491519"
  },
  {
    "text": "but yeah I mean I'm really surprised that as",
    "start": "1491519",
    "end": "1499230"
  },
  {
    "text": "far as I can tell there's no issue or PR submitted to the CNI project so we are",
    "start": "1499230",
    "end": "1507210"
  },
  {
    "text": "in the process we can submit the PR to discuss the proposal in a little bit detail on that part what what we want to",
    "start": "1507210",
    "end": "1515040"
  },
  {
    "text": "like what we are trying to propose but this this call what we are trying to do is is basically establish the common",
    "start": "1515040",
    "end": "1521010"
  },
  {
    "text": "requirements that we are trying to address if we can agree to or or have",
    "start": "1521010",
    "end": "1526140"
  },
  {
    "text": "some commonality in this it makes sense to extend the discussion to actually submit a formal PR on the CNI project",
    "start": "1526140",
    "end": "1532020"
  },
  {
    "text": "itself from the spec point of view how do we want to extend it yeah we we want",
    "start": "1532020",
    "end": "1538560"
  },
  {
    "text": "to bring these topics to this forum so that we can all discuss and debate and",
    "start": "1538560",
    "end": "1544410"
  },
  {
    "text": "decide what is the best path forward and if PR you think is the best way to move",
    "start": "1544410",
    "end": "1550350"
  },
  {
    "text": "forward we can submit a PR if you think you need more discussion about the",
    "start": "1550350",
    "end": "1555570"
  },
  {
    "text": "merits of it or where to do it if it's better to do in in in networks sake we",
    "start": "1555570",
    "end": "1560940"
  },
  {
    "text": "can take it there so so we are really looking to partner with all of you to decide how to take this forward because",
    "start": "1560940",
    "end": "1569670"
  },
  {
    "text": "these are requirements that our customers are putting on us and we can meet those requirements in a very",
    "start": "1569670",
    "end": "1577130"
  },
  {
    "text": "specific way and maybe Amazon will solve them in Amazon specifically what we are",
    "start": "1577130",
    "end": "1583860"
  },
  {
    "text": "trying to do here is is in the spirit of openness we want to bring it to this",
    "start": "1583860",
    "end": "1589170"
  },
  {
    "text": "forum so that we can all have have open discussions around hey customers are putting these requirements what do we do",
    "start": "1589170",
    "end": "1597080"
  },
  {
    "text": "yeah it's I mean the one thing we could do in this forum is decide that we want",
    "start": "1597350",
    "end": "1605100"
  },
  {
    "text": "another thing which is like the common policy interface or something like that",
    "start": "1605100",
    "end": "1611960"
  },
  {
    "text": "when you say cig network I'm guessing you mean the kubernetes group yes so",
    "start": "1613670",
    "end": "1619170"
  },
  {
    "text": "that that's not going to help you with any cross Orchestrator questions and do you know that you're exactly right that",
    "start": "1619170",
    "end": "1625020"
  },
  {
    "text": "that is  that will bring it to CNI because that's more it is not they annoy this is",
    "start": "1625020",
    "end": "1631260"
  },
  {
    "text": "the CNC a network working group yes yes you are right to the CNC of working",
    "start": "1631260",
    "end": "1638040"
  },
  {
    "text": "group so that we can take an approach that is Orchestrator independent but",
    "start": "1638040",
    "end": "1643980"
  },
  {
    "text": "again we authorized kubernetes is making lot of progress here so so if it we",
    "start": "1643980",
    "end": "1651720"
  },
  {
    "text": "would love for CNC if working group to take this on and define these capabilities in an Orchestrator",
    "start": "1651720",
    "end": "1657720"
  },
  {
    "text": "independently yeah yeah I you know very",
    "start": "1657720",
    "end": "1666600"
  },
  {
    "text": "briefly I think that's very difficult and I think what you said about tagging",
    "start": "1666600",
    "end": "1675270"
  },
  {
    "text": "I really find it hard to imagine how to map the kubernetes semantics but yeah we",
    "start": "1675270",
    "end": "1684150"
  },
  {
    "text": "probably shouldn't go into all the detail I mean I might suggest that you a so that you give that give that a go for",
    "start": "1684150",
    "end": "1690030"
  },
  {
    "text": "instance to figure out what you think is a generic scheme and then demonstrate exactly how you would map the kubernetes",
    "start": "1690030",
    "end": "1696810"
  },
  {
    "text": "semantics onto that yeah Brian this is this is Christopher you know having you know like you you know",
    "start": "1696810",
    "end": "1705120"
  },
  {
    "text": "have to support multiple orchestrators in a security policy model I would say that the difference is once",
    "start": "1705120",
    "end": "1711540"
  },
  {
    "text": "you get into the details between our various orchestrators model security",
    "start": "1711540",
    "end": "1717150"
  },
  {
    "text": "groups versus labels versus tags versus profiles you know I I it may be doable",
    "start": "1717150",
    "end": "1726030"
  },
  {
    "text": "but the way I look at it it would require major surgery on any number of",
    "start": "1726030",
    "end": "1731820"
  },
  {
    "text": "orchestrators to try and get to a common a common model but that just might yeah",
    "start": "1731820",
    "end": "1738690"
  },
  {
    "text": "we've been living this dream for the last couple of years and and I would say",
    "start": "1738690",
    "end": "1745110"
  },
  {
    "text": "that there's not a once you get down to the what not only what the data model is but what the people who use that",
    "start": "1745110",
    "end": "1752310"
  },
  {
    "text": "Orchestrator expect that data model to drive there are differences that are not",
    "start": "1752310",
    "end": "1757950"
  },
  {
    "text": "just cosmetic but let me throw this out then then how do you see CNI itself evolving or",
    "start": "1757950",
    "end": "1766130"
  },
  {
    "text": "succeeding because even though we write a CNI plugin and we are orchestrated independent but if for policies we have",
    "start": "1766130",
    "end": "1773269"
  },
  {
    "text": "to implement an Orchestrator dependent implementation then do you expect",
    "start": "1773269",
    "end": "1781760"
  },
  {
    "text": "customers to pick Orchestrator independent portion for their virtual network in an Orchestrator dependent",
    "start": "1781760",
    "end": "1788120"
  },
  {
    "text": "portion for their policies it it seems like like either we provide a good",
    "start": "1788120",
    "end": "1795769"
  },
  {
    "text": "comprehensive networking capability that is Orchestrator independent but if you",
    "start": "1795769",
    "end": "1801860"
  },
  {
    "text": "are going to to leave some big portions of it which are specific to our",
    "start": "1801860",
    "end": "1807679"
  },
  {
    "text": "castrator then it becomes challenging for customers first of all I guess you",
    "start": "1807679",
    "end": "1816289"
  },
  {
    "text": "know everyone who is try to build a generic networking and security model as",
    "start": "1816289",
    "end": "1825769"
  },
  {
    "text": "a single thing and I'll paint Nova Neutron daylight any number of other of",
    "start": "1825769",
    "end": "1831980"
  },
  {
    "text": "these platforms of pride could make the all-singing all-dancing model of",
    "start": "1831980",
    "end": "1838880"
  },
  {
    "text": "networking have have died under the wake of their complexity right so first thing",
    "start": "1838880",
    "end": "1844940"
  },
  {
    "text": "you know let's separate does this belong in CNI versus should we have a common",
    "start": "1844940",
    "end": "1851090"
  },
  {
    "text": "policy model I sort of like what Ken did you know I think we can you know does that belong and CNI does that belong in",
    "start": "1851090",
    "end": "1856700"
  },
  {
    "text": "something else it is one discussion right and answering",
    "start": "1856700",
    "end": "1861799"
  },
  {
    "text": "simple keep it you know there's different things and each one of those have a different data model except for I",
    "start": "1861799",
    "end": "1868460"
  },
  {
    "text": "then plan to cram them all into one big nasty I guess I'm showing where my opinion is",
    "start": "1868460",
    "end": "1874639"
  },
  {
    "text": "on that one big nasty plug-in the second one though is the thing that we have to",
    "start": "1874639",
    "end": "1882139"
  },
  {
    "text": "realize is in some orchestrators things like security groups etc are",
    "start": "1882139",
    "end": "1889960"
  },
  {
    "text": "specifically network security things in other or Schrader's labels tags etc are used for",
    "start": "1889960",
    "end": "1897710"
  },
  {
    "text": "a myriad of other functions other than just network so that that's the first disconnect",
    "start": "1897710",
    "end": "1905570"
  },
  {
    "text": "right is in some platforms those things are dedicated and they have dedicated",
    "start": "1905570",
    "end": "1911649"
  },
  {
    "text": "semantics around them like a security group is sort of like a VLAN in a lot of",
    "start": "1911649",
    "end": "1918499"
  },
  {
    "text": "cloud orchestrators whereas labels you know role equals database server or",
    "start": "1918499",
    "end": "1925970"
  },
  {
    "text": "stage equals prod or application equals",
    "start": "1925970",
    "end": "1932710"
  },
  {
    "text": "customer front-end have many different semantic meanings outside of just the",
    "start": "1932710",
    "end": "1940220"
  },
  {
    "text": "network policy yeah and I think that's another big you know some of these",
    "start": "1940220",
    "end": "1946759"
  },
  {
    "text": "things have are very semantically types some of them are just metadata that other things can act on sure I think the",
    "start": "1946759",
    "end": "1952669"
  },
  {
    "text": "scope of what we do in networking will not be to associate semantics with the",
    "start": "1952669",
    "end": "1958309"
  },
  {
    "text": "label itself but it will be more to to be able to apply policies with those",
    "start": "1958309",
    "end": "1964159"
  },
  {
    "text": "labels from a networking perspective now those labels can have other semantics",
    "start": "1964159",
    "end": "1969529"
  },
  {
    "text": "outside of of networking and that's totally fine but like you may say",
    "start": "1969529",
    "end": "1976940"
  },
  {
    "text": "front-end back-end that's fine right but then when you want to apply network policies using the same labels is where",
    "start": "1976940",
    "end": "1985090"
  },
  {
    "text": "where networking comes in so basically I",
    "start": "1985090",
    "end": "1998570"
  },
  {
    "text": "think what we're trying to say here is is that there will always be more semantics to tags labels in whatever way",
    "start": "1998570",
    "end": "2004809"
  },
  {
    "text": "or histories is expressing their functionality in features to customers what we're looking for is how does",
    "start": "2004809",
    "end": "2011440"
  },
  {
    "text": "Orchestrator express those those functionality that he leads to run the",
    "start": "2011440",
    "end": "2016779"
  },
  {
    "text": "workload from networking point of view to the network controller which is a public cloud network controller in case",
    "start": "2016779",
    "end": "2023200"
  },
  {
    "text": "when you bring that run that workload in in Azure or AWS for that matter if we want to enforce those policies so",
    "start": "2023200",
    "end": "2030610"
  },
  {
    "text": "in kubernetes world is a policy controller that integrates with kubernetes and and and enforces those",
    "start": "2030610",
    "end": "2035650"
  },
  {
    "text": "policies even though they are described in kubernetes data store wherever it",
    "start": "2035650",
    "end": "2040780"
  },
  {
    "text": "stores it it's expressed to policy control and policy controller takes it and enforces it so first thing is let's",
    "start": "2040780",
    "end": "2045910"
  },
  {
    "text": "if we can come to a standard specification on how Orchestrator",
    "start": "2045910",
    "end": "2050980"
  },
  {
    "text": "expresses those policies to network controller that will help us create an",
    "start": "2050980",
    "end": "2056080"
  },
  {
    "text": "Orchestrator independent way of expression of that two controllers and then we can independently evolve",
    "start": "2056080",
    "end": "2064230"
  },
  {
    "text": "there are orchestrated that have a very strong semantics type around say",
    "start": "2068040",
    "end": "2075820"
  },
  {
    "text": "security groups thank you they can talk to other things in security group a if we map say security",
    "start": "2075820",
    "end": "2082690"
  },
  {
    "text": "groups are just another word for labels that all falls apart saying kubernetes",
    "start": "2082690",
    "end": "2088030"
  },
  {
    "text": "were somebody i think you know okay you",
    "start": "2088030",
    "end": "2096639"
  },
  {
    "text": "know how you deal with that discontinuity in not the policy model",
    "start": "2096640",
    "end": "2102640"
  },
  {
    "text": "but the way we've trained people to think about these different constructs in these different orchestrators is",
    "start": "2102640",
    "end": "2110700"
  },
  {
    "text": "that's not new T is sure well I agree with that I think there are few patterns",
    "start": "2110700",
    "end": "2116740"
  },
  {
    "text": "in what different orchestrators used to describe this commonality of different workloads they run we can look at those",
    "start": "2116740",
    "end": "2123250"
  },
  {
    "text": "patterns and come through how to come to a common language specification for policy in that if we if we come to a",
    "start": "2123250",
    "end": "2130990"
  },
  {
    "text": "conclusion that there are so many different variations there is no way to standardize that's a different",
    "start": "2130990",
    "end": "2136290"
  },
  {
    "text": "observation to be had but I think there's not too many ways there there few ways people are doing it in in in",
    "start": "2136290",
    "end": "2142480"
  },
  {
    "text": "like we can look at kubernetes or or uses fear or other network controllers even how they are describing policies",
    "start": "2142480",
    "end": "2148870"
  },
  {
    "text": "and and see the commonalities that we can take we really don't need to debate",
    "start": "2148870",
    "end": "2154240"
  },
  {
    "text": "it here I think I think the next step on the discussion is for someone to come up with a candidate I",
    "start": "2154240",
    "end": "2160990"
  },
  {
    "text": "right yeah I think we should definitely",
    "start": "2160990",
    "end": "2166570"
  },
  {
    "text": "have offline discussion again we can come up with a candidate the question",
    "start": "2166570",
    "end": "2171640"
  },
  {
    "text": "will come down to do we even think that this is something that that should be",
    "start": "2171640",
    "end": "2178590"
  },
  {
    "text": "standardized across I think that definitely would be a good is it to me",
    "start": "2178590",
    "end": "2184030"
  },
  {
    "text": "it's a yes we do some of us do believe that some of us have what that would do that but if if I can do it I'd be in",
    "start": "2184030",
    "end": "2193480"
  },
  {
    "text": "favor of it and okay specifically I I would not I would quit",
    "start": "2193480",
    "end": "2199270"
  },
  {
    "text": "a new thing with which I might call the common policy interface or I don't know what I might call it but you know I",
    "start": "2199270",
    "end": "2208390"
  },
  {
    "text": "wouldn't Wow there's a separate discussion whether what are the benefits",
    "start": "2208390",
    "end": "2214240"
  },
  {
    "text": "or dis benefits of actually putting it inside CNI yeah the CPI is kinda model",
    "start": "2214240",
    "end": "2222640"
  },
  {
    "text": "myself blind and and I'm not you know guys don't think I'm against this I'm just saying that this is this is a",
    "start": "2222640",
    "end": "2229240"
  },
  {
    "text": "non-trivial exercise if there's another aspect to what's being you know - one of",
    "start": "2229240",
    "end": "2236890"
  },
  {
    "text": "the challenges that Deepak and crew are speaking to and that's kind the",
    "start": "2236890",
    "end": "2242800"
  },
  {
    "text": "intermingling of you know in some respects making viens first class in the",
    "start": "2242800",
    "end": "2250900"
  },
  {
    "text": "container network yeah that's an important aspect of for clear and in",
    "start": "2250900",
    "end": "2259240"
  },
  {
    "text": "part because CPI is there's a smaller subset of those doing and running",
    "start": "2259240",
    "end": "2266080"
  },
  {
    "text": "containers that that would really would truly be in need of seen I being multi",
    "start": "2266080",
    "end": "2274869"
  },
  {
    "text": "container Orchestrator certainly any anyone who providing containers as a",
    "start": "2274869",
    "end": "2280390"
  },
  {
    "text": "service for providing container orchestration and then you know large enterprises that have gotten multiple teams that have just one up the nice",
    "start": "2280390",
    "end": "2286330"
  },
  {
    "text": "things and and it's almost like solving that problem is almost sounds like decent startup idea or",
    "start": "2286330",
    "end": "2294400"
  },
  {
    "text": "and I'm sure something that mr. Marvin",
    "start": "2294400",
    "end": "2299890"
  },
  {
    "text": "which is he's not Marvin it's Marvin the",
    "start": "2299890",
    "end": "2305650"
  },
  {
    "text": "Martian that's the count that all our resume rooms are dialed into sprays",
    "start": "2305650",
    "end": "2311650"
  },
  {
    "text": "differ fund from peg era but my men demotion actually no Marvin the robot",
    "start": "2311650",
    "end": "2319720"
  },
  {
    "text": "sorry from from hitchhikers so I know",
    "start": "2319720",
    "end": "2324730"
  },
  {
    "text": "Chris you had a few uh you're going to talk about some ipv6 but before we transition over to that I think in terms",
    "start": "2324730",
    "end": "2334960"
  },
  {
    "text": "of like the kinda cpio network policy group some of the silver low balancing",
    "start": "2334960",
    "end": "2340090"
  },
  {
    "text": "stuff and service chaining aspects you have on here Deepak yep I know I miss it",
    "start": "2340090",
    "end": "2345640"
  },
  {
    "text": "in working with you to kind of come up with sort of some proposals in terms of how that would maybe be mapped in other",
    "start": "2345640",
    "end": "2352660"
  },
  {
    "text": "others on this college want to work on that maybe I can said like a second like meeting with just a smaller group to",
    "start": "2352660",
    "end": "2358360"
  },
  {
    "text": "kind of start working through some of these areas and come back to this team with proposals yeah I've got but yeah",
    "start": "2358360",
    "end": "2370480"
  },
  {
    "text": "I'd be interested in at least participating to a certain event specific name Student Service chaining",
    "start": "2370480",
    "end": "2376710"
  },
  {
    "text": "what people are asking for in-service training because I'm hearing sort of different things as people move into",
    "start": "2376710",
    "end": "2382300"
  },
  {
    "text": "containers about is his classical service chaining still relevance or not I'd be interested in hearing might as",
    "start": "2382300",
    "end": "2388600"
  },
  {
    "text": "well before we move to the ipv6 are there any other I didn't see any emails",
    "start": "2388600",
    "end": "2393730"
  },
  {
    "text": "with people who were prepared to talk about any other so this is that they wanted to discuss with the group are there any they might come prepared with",
    "start": "2393730",
    "end": "2400570"
  },
  {
    "text": "a network service discussion topic okay",
    "start": "2400570",
    "end": "2410950"
  },
  {
    "text": "we worked our start with this list for Microsoft and we were we can always add",
    "start": "2410950",
    "end": "2416170"
  },
  {
    "text": "to it okay sounds great can will reach",
    "start": "2416170",
    "end": "2421300"
  },
  {
    "text": "out to you but yeah definitely please do",
    "start": "2421300",
    "end": "2426360"
  },
  {
    "text": "right then we only have a 15 minutes left sorry Chris but you want to kind of",
    "start": "2426360",
    "end": "2431460"
  },
  {
    "text": "start with a quick overview what you think is missing for ipv6 and container",
    "start": "2431460",
    "end": "2439050"
  },
  {
    "text": "networking sure I can do that come on oh",
    "start": "2439050",
    "end": "2446420"
  },
  {
    "text": "okay everyone probably wishes I was but okay",
    "start": "2446420",
    "end": "2456710"
  },
  {
    "text": "go ahead okay so I didn't have a whole",
    "start": "2456710",
    "end": "2465960"
  },
  {
    "text": "lot of time to put stuff on slides I apologize by doing this a little bit for",
    "start": "2465960",
    "end": "2472950"
  },
  {
    "text": "those of you who don't know I've also done a couple of v6 transitions on",
    "start": "2472950",
    "end": "2480030"
  },
  {
    "text": "fairly large networks in the past and have the scars of doing ops area in the",
    "start": "2480030",
    "end": "2485970"
  },
  {
    "text": "IETF Oh code networking group co-chairs so I've lived the dream of getting the",
    "start": "2485970",
    "end": "2491970"
  },
  {
    "text": "world to be six will happen next year we promise this time so there are some",
    "start": "2491970",
    "end": "2500220"
  },
  {
    "text": "talking to folks who are actively interested in in v6 you know the the",
    "start": "2500220",
    "end": "2508260"
  },
  {
    "text": "initial thinking around v6 and containers and I know a lot of people",
    "start": "2508260",
    "end": "2513270"
  },
  {
    "text": "have thought about that oldest put of size 64 on each container host and then",
    "start": "2513270",
    "end": "2519710"
  },
  {
    "text": "slack how many people here are familiar with v6 things like slack and RB or",
    "start": "2519710",
    "end": "2525780"
  },
  {
    "text": "should I do a real quick couple man tutorial on v6 they think I'm gonna bake",
    "start": "2525780",
    "end": "2535110"
  },
  {
    "text": "for me but if any love that final might say they simply speak out so the idea of",
    "start": "2535110",
    "end": "2540690"
  },
  {
    "text": "descent off of a 64 per host it at least",
    "start": "2540690",
    "end": "2546120"
  },
  {
    "text": "initially sounds like a rational thing when I've talked customers about that",
    "start": "2546120",
    "end": "2552000"
  },
  {
    "text": "couple things come up or potential users one there's a class of folks out there",
    "start": "2552000",
    "end": "2557100"
  },
  {
    "text": "who believe that it's lying are probably correct that a / 64 / host will probably",
    "start": "2557100",
    "end": "2562710"
  },
  {
    "text": "blow out their v6 allocations pretty quickly at this size of cluster and kind",
    "start": "2562710",
    "end": "2569190"
  },
  {
    "text": "of some folks who are at the tens of thousands of hosts and all of a sudden that that Infinite address space in v6",
    "start": "2569190",
    "end": "2576810"
  },
  {
    "text": "starts disappearing pretty quickly the other the other issue that you need to",
    "start": "2576810",
    "end": "2582690"
  },
  {
    "text": "think about is routes longer than a / 64 consumed for slots and most hardware",
    "start": "2582690",
    "end": "2588060"
  },
  {
    "text": "routing tables so if your v4 routing table spaces is 256,000 routes your v4",
    "start": "2588060",
    "end": "2596369"
  },
  {
    "text": "if you're carrying greater than / 64 it's going to be 64,000 routes so that's",
    "start": "2596369",
    "end": "2602040"
  },
  {
    "text": "a fairly big hit + + / 64 is or less or shorter r2x",
    "start": "2602040",
    "end": "2607860"
  },
  {
    "text": "right so the I we can't get away with carrying less than a / 64 I mean we",
    "start": "2607860",
    "end": "2614130"
  },
  {
    "text": "can't get away with carrying things less than a / 32 but we should try and limit",
    "start": "2614130",
    "end": "2621170"
  },
  {
    "text": "broad announcements of greater than / 64",
    "start": "2621170",
    "end": "2626340"
  },
  {
    "text": "is in an infrastructure most containers do not have nor should they require an",
    "start": "2626340",
    "end": "2631800"
  },
  {
    "text": "RD daemon I don't think it would be a wise idea to say that every container would have to have a sidecar every pod",
    "start": "2631800",
    "end": "2637920"
  },
  {
    "text": "with Afghan aside card that loads a router discovery daemon on board with it",
    "start": "2637920",
    "end": "2643369"
  },
  {
    "text": "in order to do slack and classical",
    "start": "2643369",
    "end": "2648630"
  },
  {
    "text": "global ipam mechanisms were probably not scaled with the incredibly sparse",
    "start": "2648630",
    "end": "2653940"
  },
  {
    "text": "address space in v6 right v6 was designed to be slapped if we try and",
    "start": "2653940",
    "end": "2659100"
  },
  {
    "text": "maintain a global address map of say ax / 48 that will probably not scale",
    "start": "2659100",
    "end": "2667080"
  },
  {
    "text": "particularly well and a lot of my Pam mechanisms some of the things that we're",
    "start": "2667080",
    "end": "2673619"
  },
  {
    "text": "seeing from customers as they're looking at v6 automatic configuration of",
    "start": "2673619",
    "end": "2678630"
  },
  {
    "text": "infrastructure they would really prefer not to have basically the infrastructure Auto configure itself autodiscover",
    "start": "2678630",
    "end": "2685170"
  },
  {
    "text": "itself set up keyrings if necessary etc and we're also seeing a strong request",
    "start": "2685170",
    "end": "2692550"
  },
  {
    "text": "for v6 infrastructure people want to preserve their v4 addresses for external services",
    "start": "2692550",
    "end": "2698820"
  },
  {
    "text": "or for legacy workloads so they would really like to run a v6 only",
    "start": "2698820",
    "end": "2704210"
  },
  {
    "text": "infrastructure but that exposes v4 services and supports legacy before",
    "start": "2704210",
    "end": "2710390"
  },
  {
    "text": "workloads given this set of requirements",
    "start": "2710390",
    "end": "2719070"
  },
  {
    "text": "we've been giving this a little bit of thought this is one message it's the",
    "start": "2719070",
    "end": "2724740"
  },
  {
    "text": "only way to solve it this is one way we've been thinking about this each node new given LT network is",
    "start": "2724740",
    "end": "2731310"
  },
  {
    "text": "slacked from a slash 64 in a private cloud environment that could be a top of rata Iraq or the top of Rapids and l3",
    "start": "2731310",
    "end": "2738480"
  },
  {
    "text": "switch it could be an AZ or the equivalent in a public cloud etc but you",
    "start": "2738480",
    "end": "2744150"
  },
  {
    "text": "know every l2 physical infrastructure or thing that maps to physical infrastructure is a single slash 64",
    "start": "2744150",
    "end": "2752660"
  },
  {
    "text": "each node would then use DHCP v6 to",
    "start": "2752660",
    "end": "2758010"
  },
  {
    "text": "request a prefix delegation of a larger than / 64 block for that node this would",
    "start": "2758010",
    "end": "2764910"
  },
  {
    "text": "be within a given l2 Network all blocks would come out of one or more / 64 s so",
    "start": "2764910",
    "end": "2770250"
  },
  {
    "text": "this means that the announcement of the route north of the switch would be a",
    "start": "2770250",
    "end": "2775380"
  },
  {
    "text": "slash 64 in keeping with reducing longer prefixes in the court each of those grid",
    "start": "2775380",
    "end": "2785070"
  },
  {
    "text": "in SAS 64 blocks could be a slash ATS last 96 something along those lines for",
    "start": "2785070",
    "end": "2790110"
  },
  {
    "text": "that node this does raise an interesting thing we've got now a huge amount of addresses per node do we ever recycle",
    "start": "2790110",
    "end": "2797460"
  },
  {
    "text": "the addresses or do we use addresses once and throw them away at least until a you know at some point at the heat",
    "start": "2797460",
    "end": "2805110"
  },
  {
    "text": "death of the universe and that gives us some traceability for workloads right every time you get a new workload you",
    "start": "2805110",
    "end": "2810660"
  },
  {
    "text": "get new IP address and log events to a given IP address for a given IP address",
    "start": "2810660",
    "end": "2816120"
  },
  {
    "text": "are therefore traceable to a specific instance of a workload rather than an",
    "start": "2816120",
    "end": "2821700"
  },
  {
    "text": "ephemeral thing at some point in time if you're going back and looking at logs later possible",
    "start": "2821700",
    "end": "2827040"
  },
  {
    "text": "dressing side-effect each node would then implement host local addressing for",
    "start": "2827040",
    "end": "2832050"
  },
  {
    "text": "its containers out of that block and as I said each of the LT border routers is carrying its local slash 60 greater than",
    "start": "2832050",
    "end": "2839280"
  },
  {
    "text": "/ 64 blocks but only announcing these two / 64 aggregates which reduces the",
    "start": "2839280",
    "end": "2844710"
  },
  {
    "text": "address table explosion in the court",
    "start": "2844710",
    "end": "2849890"
  },
  {
    "text": "services should be available on v4 and v6 and we should design service pools",
    "start": "2850400",
    "end": "2859560"
  },
  {
    "text": "etc so that external announcements aren't limited to 2 / 64 s or less rather than greater than / 64 so we",
    "start": "2859560",
    "end": "2869100"
  },
  {
    "text": "don't want to be announcing / 128 so our services if we can avoid them out to the core and legacy v4 workloads and",
    "start": "2869100",
    "end": "2877020"
  },
  {
    "text": "containers do we do run dual stack or do we do some kind of v4 as a service",
    "start": "2877020",
    "end": "2882800"
  },
  {
    "text": "mechanism to again further reduce v4",
    "start": "2882800",
    "end": "2888960"
  },
  {
    "text": "address utilization and save it for things that are need to be publicly exist and some thoughts around that as",
    "start": "2888960",
    "end": "2897390"
  },
  {
    "text": "well but earlier in thinking so and this is just one sort of straw man you know",
    "start": "2897390",
    "end": "2907050"
  },
  {
    "text": "is this a rational way of handling v6 in a in an act scale containerized",
    "start": "2907050",
    "end": "2916530"
  },
  {
    "text": "environment you know is there more of a okay you know I put something out there",
    "start": "2916530",
    "end": "2922170"
  },
  {
    "text": "and well you know what else do what other what other ideas do people have about dealing with v6 infrastructure",
    "start": "2922170",
    "end": "2931050"
  },
  {
    "text": "acceptor I think it goes without saying that until we have parity in any orchestration system with v4 and v6",
    "start": "2931050",
    "end": "2938180"
  },
  {
    "text": "we're not gonna be able to really move forward and I know we're working on that pretty hard in kubernetes but you know",
    "start": "2938180",
    "end": "2946020"
  },
  {
    "text": "you we're not there yet and but once we are how do we actually build rational",
    "start": "2946020",
    "end": "2952560"
  },
  {
    "text": "infrastructure to support v6 and make use of v6 so with that I'll open it up",
    "start": "2952560",
    "end": "2958080"
  },
  {
    "text": "for questions comments shouts whatever deafening time is right",
    "start": "2958080",
    "end": "2973920"
  },
  {
    "text": "here I have to confess I'm not a great ipv6 expert but I was wondering I sat",
    "start": "2973920",
    "end": "2981630"
  },
  {
    "text": "through the talk about using kubernetes with ipv6 at the last tip Carl in Austin and I was wondering to what extent what",
    "start": "2981630",
    "end": "2988740"
  },
  {
    "text": "you just described is compatible with or different it is somewhat it is somewhat",
    "start": "2988740",
    "end": "3000500"
  },
  {
    "text": "different but I have some concerns about",
    "start": "3000500",
    "end": "3006700"
  },
  {
    "text": "if people want to do v6 only infrastructure how we're going to manage",
    "start": "3006700",
    "end": "3015230"
  },
  {
    "text": "that at large scale so I'm you know I",
    "start": "3015230",
    "end": "3022010"
  },
  {
    "text": "think what people have been talking about before and blogging about before",
    "start": "3022010",
    "end": "3027110"
  },
  {
    "text": "have been sort of yell we've got v6 up and running on kubernetes but you know",
    "start": "3027110",
    "end": "3032870"
  },
  {
    "text": "how we're going to manage this at scale the people have been talking about v6",
    "start": "3032870",
    "end": "3040370"
  },
  {
    "text": "for host I think is a great idea up to a certain point but there's definitely community out there who are concerned",
    "start": "3040370",
    "end": "3047390"
  },
  {
    "text": "that they're not going to actually have the address space to do that with Indians you made a you made a 64 per",
    "start": "3047390",
    "end": "3054680"
  },
  {
    "text": "host there's a 4 per house yeah yeah you",
    "start": "3054680",
    "end": "3059750"
  },
  {
    "text": "know so and you know what I'm trying to",
    "start": "3059750",
    "end": "3066980"
  },
  {
    "text": "do here with this design is scope do a",
    "start": "3066980",
    "end": "3072470"
  },
  {
    "text": "couple things not require networking stack software in pods ie did we know",
    "start": "3072470",
    "end": "3078560"
  },
  {
    "text": "pods should not have to slack and trying to scope longer than 64 is to a limited",
    "start": "3078560",
    "end": "3088190"
  },
  {
    "text": "blast radius so yeah sure that's where that's where this sort of",
    "start": "3088190",
    "end": "3093250"
  },
  {
    "text": "design came out of yeah it it feels like",
    "start": "3093250",
    "end": "3105390"
  },
  {
    "text": "someone should should try it in real life and report back I mean I guess I",
    "start": "3105390",
    "end": "3111690"
  },
  {
    "text": "guess there's a danger that the term when I trying to say if let's suppose",
    "start": "3111690",
    "end": "3120910"
  },
  {
    "text": "the 64 per hostess is a really bad thing like you say and let's also suppose that becomes wildly popular amongst early",
    "start": "3120910",
    "end": "3128950"
  },
  {
    "text": "adopters you know that right so there is a danger to standardizing too soon which",
    "start": "3128950",
    "end": "3134950"
  },
  {
    "text": "is you don't really know whether what you're saying is is a good idea and there's a danger in standardizing too late because everyone's gone off and",
    "start": "3134950",
    "end": "3141310"
  },
  {
    "text": "done the wrong thing right so I think the issue is the vast majority of people saw 64 per host will work you know most",
    "start": "3141310",
    "end": "3149980"
  },
  {
    "text": "of the cluster sizes you see are in the hundreds mm and that's that that's perfectly fine for us a slash forty",
    "start": "3149980",
    "end": "3156790"
  },
  {
    "text": "eight block the the issue is going to be",
    "start": "3156790",
    "end": "3162089"
  },
  {
    "text": "you know the larger style deployments but if we start like you said Brian if",
    "start": "3162270",
    "end": "3167740"
  },
  {
    "text": "we start baking things like slack for containers pods in that's gonna make",
    "start": "3167740",
    "end": "3173770"
  },
  {
    "text": "things more complicated later if we discovered it yeah what I mean I don't",
    "start": "3173770",
    "end": "3178900"
  },
  {
    "text": "understand why that would like why why wouldn't they be the C&I plugin that would be doing slack",
    "start": "3178900",
    "end": "3186599"
  },
  {
    "text": "so so in order to you can yeah you can",
    "start": "3191420",
    "end": "3200309"
  },
  {
    "text": "possibly do that Brian you'll have to generate a MAC address sudo MAC address",
    "start": "3200309",
    "end": "3206940"
  },
  {
    "text": "for everything that your proxying that you know that you are going to do sort",
    "start": "3206940",
    "end": "3214410"
  },
  {
    "text": "of a proxy tardy for but you could do",
    "start": "3214410",
    "end": "3220559"
  },
  {
    "text": "that the question is also going to be though scoping that correctly right so",
    "start": "3220559",
    "end": "3230039"
  },
  {
    "text": "our DS normally go to if we think about that if let's say I'm going to Rd to",
    "start": "3230039",
    "end": "3236309"
  },
  {
    "text": "something from the sea and I plug in it could be the real router that's upstream",
    "start": "3236309",
    "end": "3243089"
  },
  {
    "text": "of me or it could be just something that is and that's not really slack it's it's",
    "start": "3243089",
    "end": "3248519"
  },
  {
    "text": "a it's an eye Pam request and I think that's when we run into managing very very sparse IPAM tables but if the local",
    "start": "3248519",
    "end": "3257880"
  },
  {
    "text": "sea and I plug in could then do slack to the top of rack that might be another",
    "start": "3257880",
    "end": "3263940"
  },
  {
    "text": "that might be another option and then the sly 64 is coming out of the top of",
    "start": "3263940",
    "end": "3270900"
  },
  {
    "text": "rack switch or the border router or whatever is doing the Rd within that l2 zone that's another way of doing that's",
    "start": "3270900",
    "end": "3277980"
  },
  {
    "text": "another possible way of doing the front yeah so I guess we're running out of time where would what's where do we go",
    "start": "3277980",
    "end": "3284640"
  },
  {
    "text": "forward where would something like this live like if this is like a document like best practice or for v6 and",
    "start": "3284640",
    "end": "3291960"
  },
  {
    "text": "containers you know we start talking about this can what at the beginning of the year sometime last year of you know",
    "start": "3291960",
    "end": "3298380"
  },
  {
    "text": "it's v6 one of the things that we want to sort of help provide some guidance I",
    "start": "3298380",
    "end": "3306210"
  },
  {
    "text": "think I remember memory being faulty the can I've been talking about you is is",
    "start": "3306210",
    "end": "3312059"
  },
  {
    "text": "there a best current practice or actually should we document something right you know that might be you know",
    "start": "3312059",
    "end": "3322860"
  },
  {
    "text": "this might be the starting point of a BCP for v6 I'm not sure there's a",
    "start": "3322860",
    "end": "3329690"
  },
  {
    "text": "standard to be promulgated here as far as you know this is the way you must do",
    "start": "3329690",
    "end": "3336570"
  },
  {
    "text": "it you know this is you know people are oh I be v6 here's CMS CNCs suggested",
    "start": "3336570",
    "end": "3344640"
  },
  {
    "text": "mechanisms to do that both for adopters and for people writing infrastructure",
    "start": "3344640",
    "end": "3352500"
  },
  {
    "text": "that goes into CN CF you know des cloud native infrastructures my view it's more",
    "start": "3352500",
    "end": "3359190"
  },
  {
    "text": "of a document than a promulgated standard especially since we're not a standards organization right so you know",
    "start": "3359190",
    "end": "3368910"
  },
  {
    "text": "we could start a document now we could",
    "start": "3368910",
    "end": "3374690"
  },
  {
    "text": "see about doing testing some of this in real life and seeing what works what",
    "start": "3374690",
    "end": "3380580"
  },
  {
    "text": "doesn't I think the problem is going to be the the problems are gonna pop up at scale",
    "start": "3380580",
    "end": "3385710"
  },
  {
    "text": "I think anything work at small scale right it's going to be testing it at big enough scale where we can possibly start",
    "start": "3385710",
    "end": "3391170"
  },
  {
    "text": "defining issues yeah I think it'd be worth getting in front of people like",
    "start": "3391170",
    "end": "3397590"
  },
  {
    "text": "Dan Williams and Casey Calandra Lowe who",
    "start": "3397590",
    "end": "3402600"
  },
  {
    "text": "are other CNI maintain errs that do more ipv6 than I do",
    "start": "3402600",
    "end": "3408060"
  },
  {
    "text": "yeah so I've obviously I've discussed this with our Casey here at tae Guerra a",
    "start": "3408060",
    "end": "3414090"
  },
  {
    "text": "little bit already as well but yeah getting this in front of some of the more v6 savvy C&I guys is would be maybe",
    "start": "3414090",
    "end": "3423600"
  },
  {
    "text": "a next step yeah so you know you could",
    "start": "3423600",
    "end": "3429990"
  },
  {
    "text": "you could do that via an issue and list the CNI github or or the email list or",
    "start": "3429990",
    "end": "3438680"
  },
  {
    "text": "CNI changes that's fine you know you",
    "start": "3445460",
    "end": "3450960"
  },
  {
    "text": "could file an issue that said I just want to bring this to your attention for a moment you know yeah or just yeah there is a",
    "start": "3450960",
    "end": "3459320"
  },
  {
    "text": "mailing list so I can't remember what it is off the top of my head yeah I don't believe anyone has ever",
    "start": "3459320",
    "end": "3464330"
  },
  {
    "text": "sent any emails to so I guess as a sort",
    "start": "3464330",
    "end": "3469880"
  },
  {
    "text": "of tending to you in the rest numbers what I'm going to do is next steps for something like this I know I have",
    "start": "3469880",
    "end": "3480200"
  },
  {
    "text": "haven't continued about like that yet from others first I guess are we even",
    "start": "3480200",
    "end": "3490670"
  },
  {
    "text": "interested in waiting into the v6 pool in this group who knows was finding",
    "start": "3490670",
    "end": "3496490"
  },
  {
    "text": "guidance I'm okay with it I know I've been surprised by all the",
    "start": "3496490",
    "end": "3505910"
  },
  {
    "text": "lack of v6 support and a lot of the things I've been doing recently so I think it'd be good to have some sort of",
    "start": "3505910",
    "end": "3513820"
  },
  {
    "text": "statements about b6 coming out of the workgroup",
    "start": "3513820",
    "end": "3519099"
  },
  {
    "text": "so maybe a v6 sort of position position",
    "start": "3520690",
    "end": "3527620"
  },
  {
    "text": "position statement and then start drafting up some kind of PCP that would",
    "start": "3527620",
    "end": "3534460"
  },
  {
    "text": "be sort of a living document that would grow as people start filling in chunks",
    "start": "3534460",
    "end": "3540040"
  },
  {
    "text": "of it yeah I think that would make sense",
    "start": "3540040",
    "end": "3544380"
  },
  {
    "text": "you mighty like finally opposed to that",
    "start": "3545580",
    "end": "3550380"
  },
  {
    "text": "does anyone still awake oh I think such let's throw it I know it over time so",
    "start": "3551250",
    "end": "3558070"
  },
  {
    "text": "I'm start with them and in two weeks I've sent some emails I've been healthy into which we've made a little bit of",
    "start": "3558070",
    "end": "3563740"
  },
  {
    "text": "progress on the services piece and on the v6 idea around no kind of a position",
    "start": "3563740",
    "end": "3571030"
  },
  {
    "text": "statement some kind of so can you just",
    "start": "3571030",
    "end": "3576880"
  },
  {
    "text": "want to do that document in the in github yeah that'd be a good idea",
    "start": "3576880",
    "end": "3583830"
  },
  {
    "text": "[Music] alright guys thanks everyone weeks",
    "start": "3583900",
    "end": "3590940"
  }
]
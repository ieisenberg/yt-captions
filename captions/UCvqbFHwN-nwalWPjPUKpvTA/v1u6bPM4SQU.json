[
  {
    "text": "hello this is mark darnell with souza ryan and i will be presenting performance optimization rook",
    "start": "80",
    "end": "6240"
  },
  {
    "text": "on kubernetes today",
    "start": "6240",
    "end": "9680"
  },
  {
    "text": "real quickly ryan tidwell is a senior network engineer with souza who works in one of my teams",
    "start": "11440",
    "end": "16480"
  },
  {
    "text": "i'm the principal product manager handling our sdi and platforms for souza what we're going to be covering today is",
    "start": "16480",
    "end": "23600"
  },
  {
    "text": "specifically running rook which is a containerized version of ceph on top of kubernetes and doing some",
    "start": "23600",
    "end": "31279"
  },
  {
    "text": "performance measurement or some benchmark evaluations of that technology a quick intro we'll talk about the",
    "start": "31279",
    "end": "37680"
  },
  {
    "text": "benchmark environment we'll work through methodology and results give you some of those insights and then discuss what we want future",
    "start": "37680",
    "end": "44160"
  },
  {
    "text": "work to be so as an introduction why did we do this",
    "start": "44160",
    "end": "50320"
  },
  {
    "text": "put simply souza has been a long time player in the open source space we are involved in kubernetes we're",
    "start": "50320",
    "end": "56879"
  },
  {
    "text": "involved in ceph software-defined storage and we're rolling products out that will integrate",
    "start": "56879",
    "end": "62239"
  },
  {
    "text": "those technologies via rook in order to integrate them you need to ensure that you have a",
    "start": "62239",
    "end": "67920"
  },
  {
    "text": "reasonable network stack in terms of performance to tie those together",
    "start": "67920",
    "end": "73760"
  },
  {
    "text": "and the driving component to do that is a cni plug-in so we need to understand what c i",
    "start": "73760",
    "end": "79520"
  },
  {
    "text": "plug-ins souza should be including there to maximize customers performance and we",
    "start": "79520",
    "end": "84960"
  },
  {
    "text": "want to make sure that as a good open source citizen that we return those lessons learned back",
    "start": "84960",
    "end": "90079"
  },
  {
    "text": "upstream into projects like calico celia and multis network service mesh and so forth",
    "start": "90079",
    "end": "97280"
  },
  {
    "text": "real quickly just to make sure that we're all operating from a level playing field this is a slide from rook documentation",
    "start": "98320",
    "end": "104799"
  },
  {
    "text": "once again rook is a project which takes ceph as a piece of software",
    "start": "104799",
    "end": "109840"
  },
  {
    "text": "containerizes it and puts it on top of kubernetes so rather than running ceph bare metal without any kind of",
    "start": "109840",
    "end": "116320"
  },
  {
    "text": "orchestration in between we actually have a three layer stack in order to link those together once again",
    "start": "116320",
    "end": "121920"
  },
  {
    "text": "you'll end up with the cni plug-in that sits underneath rook in order to make sure that it's talking to kubernetes",
    "start": "121920",
    "end": "128399"
  },
  {
    "text": "and the network the underlying network stack correctly",
    "start": "128399",
    "end": "133360"
  },
  {
    "text": "so let's talk about kubernetes networking enough to ensure that once again we're working from a level playing field within the audience",
    "start": "134400",
    "end": "141120"
  },
  {
    "text": "kubernetes networking works in a couple of ways one is what you would call kind of the standard approach and this",
    "start": "141120",
    "end": "148239"
  },
  {
    "text": "uses a set of technologies that are part of both user space and kernel space in linux you'll create things like v eth",
    "start": "148239",
    "end": "155840"
  },
  {
    "text": "pairs you'll have mac vlan and ipvlan you'll talk to a physical interface you may actually use an srov",
    "start": "155840",
    "end": "162400"
  },
  {
    "text": "virtual function as part of an sr iov adapter it it also for some networking models",
    "start": "162400",
    "end": "169200"
  },
  {
    "text": "goes through a linux bridge virtualized switch so there's a set of components that traffic must go through",
    "start": "169200",
    "end": "176000"
  },
  {
    "text": "this set of components will add overhead a second mode that kubernetes provides natively is called host networking",
    "start": "176000",
    "end": "183040"
  },
  {
    "text": "and what this does is this effectively opens up access from the device uh the the underlying devices or sorry",
    "start": "183040",
    "end": "189840"
  },
  {
    "text": "to the pods it opens up access from the pods directly into host networking devices",
    "start": "189840",
    "end": "195840"
  },
  {
    "text": "uh it it kind of bypasses a chunk of security that you would typically expect to have",
    "start": "195840",
    "end": "201120"
  },
  {
    "text": "so while performance tends to be the best because you're not running through any of that overhead that's listed there",
    "start": "201120",
    "end": "206400"
  },
  {
    "text": "in the first bullet point you do have a problem in the sense that you may be less secure",
    "start": "206400",
    "end": "212159"
  },
  {
    "text": "so souza as we're rolling these products to people we want to make sure that we provide the best possible performance while not",
    "start": "212159",
    "end": "219040"
  },
  {
    "text": "compromising security and that's part of what these benchmarking methodologies are for that",
    "start": "219040",
    "end": "224159"
  },
  {
    "text": "we're working through i'm going to go ahead and turn this over to ryan he's going to do some of the",
    "start": "224159",
    "end": "230000"
  },
  {
    "text": "heavy lifting here and describe a lot of the work that he's done in this benchmarking environment so ryan over to you",
    "start": "230000",
    "end": "237840"
  },
  {
    "text": "thank you mark uh yeah let's start by just briefly uh talking about the environment",
    "start": "238640",
    "end": "245599"
  },
  {
    "text": "that we had at our disposal to uh benchmark these different",
    "start": "245599",
    "end": "251200"
  },
  {
    "text": "configurations so this is a snapshot of the hardware",
    "start": "252840",
    "end": "258639"
  },
  {
    "text": "specs that we have for our sub nodes and our client node",
    "start": "258639",
    "end": "264639"
  },
  {
    "text": "got some top of the line mix at our disposal as well as some really fast nvme ssd",
    "start": "265360",
    "end": "272160"
  },
  {
    "text": "storage",
    "start": "272160",
    "end": "274639"
  },
  {
    "text": "what uh i wanted to show here was to kind of set a level playing field the uh",
    "start": "280000",
    "end": "285360"
  },
  {
    "text": "the the first bottleneck you might think of would be the um the hard drive or the ssd itself um so",
    "start": "285360",
    "end": "292080"
  },
  {
    "text": "the first thing we did was just benchmark the performance of these ssds that we had in our",
    "start": "292080",
    "end": "298639"
  },
  {
    "text": "storage nodes these are the same ssds and the same on the same motherboard and identical",
    "start": "298639",
    "end": "305360"
  },
  {
    "text": "configurations across the cluster so we we first benchmarked that with um",
    "start": "305360",
    "end": "312240"
  },
  {
    "text": "testing right and re-dialogues um i want to just point out something on this slide that uh",
    "start": "312240",
    "end": "318560"
  },
  {
    "text": "might be useful as we useful to remember as we go on",
    "start": "318560",
    "end": "324080"
  },
  {
    "text": "with the uh with the right benchmarks we noticed that uh we start off kind of slow at 1k and 2k",
    "start": "324080",
    "end": "331120"
  },
  {
    "text": "block sizes and we believe this is just a function of not aligning to uh",
    "start": "331120",
    "end": "337759"
  },
  {
    "text": "native block sizes things like page tables sizes and that sort of thing so",
    "start": "337759",
    "end": "345360"
  },
  {
    "text": "keep that in mind again i also want to point out here that you know we're measuring iops in terms",
    "start": "345360",
    "end": "350800"
  },
  {
    "text": "of hundreds of thousands of ions these are really fast discs and the idea here is to not",
    "start": "350800",
    "end": "357039"
  },
  {
    "text": "have them be a bottleneck in the system so we're looking for the fastest disks we can get",
    "start": "357039",
    "end": "366800"
  },
  {
    "text": "um this is just a snapshot of the software you know the kernel versions of rope things like that um the",
    "start": "366800",
    "end": "374240"
  },
  {
    "text": "two bullet points i want to call out here are uh at the bottom calco and psyllium these are the two cni",
    "start": "374240",
    "end": "381039"
  },
  {
    "text": "plug-ins that we tested we grabbed psyllium and tested that um",
    "start": "381039",
    "end": "387680"
  },
  {
    "text": "we do a lot of work with uh psyllium here at souza this is also interesting from a",
    "start": "387680",
    "end": "394240"
  },
  {
    "text": "performance perspective because of the uh the bpf data path involved calco is also another popular",
    "start": "394240",
    "end": "401919"
  },
  {
    "text": "tool that people use and both support different encapsulation modes and i want",
    "start": "401919",
    "end": "409919"
  },
  {
    "text": "to call your attention back to psyllium and just mention that",
    "start": "409919",
    "end": "415360"
  },
  {
    "text": "we're going to be testing with both encapsulated network traffic with vxlan and we're",
    "start": "415360",
    "end": "421440"
  },
  {
    "text": "going to be testing a mode called psyllium direct mode where we don't encapsulate pod traffic",
    "start": "421440",
    "end": "428160"
  },
  {
    "text": "for calico we're going to use ip and ip encapsulation and vxlan encapsulation",
    "start": "428160",
    "end": "436560"
  },
  {
    "text": "so let's kind of look at the design of the cluster",
    "start": "436560",
    "end": "442080"
  },
  {
    "text": "at a at a logical level what we wanted wanted to have was a single rbd client",
    "start": "442080",
    "end": "450240"
  },
  {
    "text": "we wanted to use brooke to deploy some mods and some osds which are kind of basic building blocks of seth",
    "start": "450240",
    "end": "458478"
  },
  {
    "text": "now what this looks like when we deploy it from a physical perspective is a four node cluster and we're",
    "start": "461039",
    "end": "468000"
  },
  {
    "text": "ignoring the controller node right now we're just focusing on the workers in the cluster",
    "start": "468000",
    "end": "473360"
  },
  {
    "text": "so we have three nodes that are dedicating as storage nodes and a single node that we're using as",
    "start": "473360",
    "end": "479199"
  },
  {
    "text": "our client node now there's a couple things i want to call out here",
    "start": "479199",
    "end": "485520"
  },
  {
    "text": "at the top in that top box you'll see a pod now if you're not",
    "start": "485520",
    "end": "492400"
  },
  {
    "text": "familiar with file file as a benchmarking tool that we can use to uh run synthetic workloads",
    "start": "492400",
    "end": "499440"
  },
  {
    "text": "on a storage system whether that's a physical device or something that we",
    "start": "499440",
    "end": "505440"
  },
  {
    "text": "mount through nfs or in this case ceph we're going to use that to gather our data",
    "start": "505440",
    "end": "511280"
  },
  {
    "text": "so we have a pod there that's acting as our client and that's where our file benchmarking tool is going to run",
    "start": "511280",
    "end": "518000"
  },
  {
    "text": "i also want to call attention to the networking technologies real quick we have 100 gig ethernet networking",
    "start": "518000",
    "end": "524480"
  },
  {
    "text": "available to our storage nodes and a bonded pair of 25 gig mix available to our client code and we'll",
    "start": "524480",
    "end": "532080"
  },
  {
    "text": "get back to the bonded pair of 25 gig mix that",
    "start": "532080",
    "end": "537440"
  },
  {
    "text": "is an important part of the story that we'll talk about later",
    "start": "537440",
    "end": "543680"
  },
  {
    "text": "so let's move on and uh actually get into the meat and talk about the methodology that we",
    "start": "546080",
    "end": "553200"
  },
  {
    "text": "went through and uh talk about the results before we do that i want to set the",
    "start": "553200",
    "end": "559120"
  },
  {
    "text": "stage with uh two basic concepts i want to talk about uh latency and i want to talk about",
    "start": "559120",
    "end": "564320"
  },
  {
    "text": "items so first let's talk about latency um",
    "start": "564320",
    "end": "569920"
  },
  {
    "text": "as a as someone with a networking background who really works in the networking space um my first approach to this is to say",
    "start": "569920",
    "end": "577760"
  },
  {
    "text": "latency is the enemy um late what is the latency we're going to find that just",
    "start": "577760",
    "end": "583360"
  },
  {
    "text": "very broadly as variable delay inserted by components in a pipeline",
    "start": "583360",
    "end": "589360"
  },
  {
    "text": "you can look to the left to see where we add latency in the system um so we'll start kind of from the top",
    "start": "589519",
    "end": "596080"
  },
  {
    "text": "left and work our way around um first place that we can introduce some latency is in accessing the disk",
    "start": "596080",
    "end": "603600"
  },
  {
    "text": "now that i want to point out this is something that your cni configuration and your network configuration isn't",
    "start": "603600",
    "end": "608720"
  },
  {
    "text": "really going to influence um that's going to be a pretty static cost in the system the uh the next",
    "start": "608720",
    "end": "618079"
  },
  {
    "text": "bullet point is network transport latency now this is uh the latency that's going",
    "start": "618079",
    "end": "625120"
  },
  {
    "text": "to be incurred by emitting a packet on the network having it traverse",
    "start": "625120",
    "end": "630959"
  },
  {
    "text": "the your topic rack switch maybe a couple of top rack switches maybe a router depends on your on your",
    "start": "630959",
    "end": "636800"
  },
  {
    "text": "saddle the idea here is the factors driving latency here are going to be bandwidth availability",
    "start": "636800",
    "end": "643760"
  },
  {
    "text": "congestion bonding and switch configuration and those kinds of things and then the last bit",
    "start": "643760",
    "end": "649279"
  },
  {
    "text": "is uh that kernel latency the network stack that we have to",
    "start": "649279",
    "end": "655279"
  },
  {
    "text": "traverse between the nick and the pond",
    "start": "655279",
    "end": "660560"
  },
  {
    "text": "this is going to be highly dependent on our cni configuration and when you add this all up uh the disk",
    "start": "660560",
    "end": "667360"
  },
  {
    "text": "access plus the network transport latency first plus the kernel network stack latency",
    "start": "667360",
    "end": "672880"
  },
  {
    "text": "you get a total latency our goal",
    "start": "672880",
    "end": "678800"
  },
  {
    "text": "is to minimize the latency in both the kernel and the network fabric",
    "start": "678800",
    "end": "684800"
  },
  {
    "text": "now when we talk about the performance of storage systems",
    "start": "686839",
    "end": "692079"
  },
  {
    "text": "we like to measure things in terms of ions now what's an io short for io per second so a single",
    "start": "692079",
    "end": "699600"
  },
  {
    "text": "i o operation is going to incur all the overhead related to",
    "start": "699600",
    "end": "705760"
  },
  {
    "text": "both the disk access latency and all those network related overheads",
    "start": "705760",
    "end": "712959"
  },
  {
    "text": "the key point here is less network latency equals more ions so the more we can",
    "start": "715120",
    "end": "721200"
  },
  {
    "text": "drive down that network latency the more efficient we can be with providing storage",
    "start": "721200",
    "end": "727519"
  },
  {
    "text": "to clients because we talk in terms of iops and we think about storage systems",
    "start": "727519",
    "end": "734800"
  },
  {
    "text": "we're going to express these results in terms of iops going forward so that's just a note",
    "start": "734800",
    "end": "741920"
  },
  {
    "text": "to set the terminology and now let's move on and talk about the",
    "start": "741920",
    "end": "748399"
  },
  {
    "text": "methodology so scientific method the this is",
    "start": "748399",
    "end": "753600"
  },
  {
    "text": "kind of what was in our mind while we were trying this out we want to change one variable at a time",
    "start": "753600",
    "end": "758639"
  },
  {
    "text": "hold all others constant that variable really being the c and i",
    "start": "758639",
    "end": "764800"
  },
  {
    "text": "plug in here um we want to optimize the base system make that as fast as we can so we've got",
    "start": "764800",
    "end": "772399"
  },
  {
    "text": "jungle frames or a maximum transmission unit or mtu of 9000",
    "start": "772399",
    "end": "778560"
  },
  {
    "text": "and we want to use the fastest disks we can so the disks are faster than the network we don't want the network to be we don't",
    "start": "778560",
    "end": "785600"
  },
  {
    "text": "want the disc to be the bottleneck here we want the network to be the bottleneck so that",
    "start": "785600",
    "end": "791279"
  },
  {
    "text": "we can change parameters on that and see how those different configurations influence the performance",
    "start": "791279",
    "end": "798079"
  },
  {
    "text": "of the system um as i've been alluding to disk access time is effectively going to be a",
    "start": "798079",
    "end": "804320"
  },
  {
    "text": "constant here regardless of the cni plug-in and then we have a single rbd client",
    "start": "804320",
    "end": "811040"
  },
  {
    "text": "running on a dedicated node and that's where we measure the iops we're taking latency and peak bandwidth demand",
    "start": "811040",
    "end": "818000"
  },
  {
    "text": "measurements and then we run through this whole process swapping out the cni plug-in or",
    "start": "818000",
    "end": "824160"
  },
  {
    "text": "the cni configuration and re-running the tests by changing that variable",
    "start": "824160",
    "end": "830639"
  },
  {
    "text": "so now that i've set the stage let's dive into the results so let's start by looking at read",
    "start": "830639",
    "end": "837839"
  },
  {
    "text": "benchmarks and i'm going to call out what i'm deeming common block sizes so this would be you",
    "start": "837839",
    "end": "845360"
  },
  {
    "text": "know anything from 1k to 8k block sizes when performing a read benchmark",
    "start": "845360",
    "end": "852880"
  },
  {
    "text": "with the single client we observe a 20 to 25 overhead when using",
    "start": "852880",
    "end": "859120"
  },
  {
    "text": "encapsulation so both psyllium and calico when encapsulating pod traffic are",
    "start": "859120",
    "end": "866320"
  },
  {
    "text": "incurring pretty significant overhead now i mentioned psyllium direct mode",
    "start": "866320",
    "end": "871760"
  },
  {
    "text": "earlier this is a mode that psyllium runs in um there's there's a similar",
    "start": "871760",
    "end": "877279"
  },
  {
    "text": "configuration for calco that uh that we didn't test but if the principle still holds it we're not",
    "start": "877279",
    "end": "884000"
  },
  {
    "text": "encapsulating traffic and we're not paying those overheads um",
    "start": "884000",
    "end": "889760"
  },
  {
    "text": "and so as you can see psyllium direct mode actually stacks up quite nicely",
    "start": "890079",
    "end": "895120"
  },
  {
    "text": "against host networking from a performance perspective as opposed to 20 to 25 overhead we're only paying",
    "start": "895120",
    "end": "900480"
  },
  {
    "text": "about a two percent overhead which is pretty impressive",
    "start": "900480",
    "end": "906399"
  },
  {
    "text": "so let's look at uh these larger block sizes so anywhere from",
    "start": "906959",
    "end": "913920"
  },
  {
    "text": "a one meg block size to an 8 meg block size again we have significant overheads here",
    "start": "913920",
    "end": "919760"
  },
  {
    "text": "when encapsulating pod traffic with vxlan or ipnip",
    "start": "919760",
    "end": "925279"
  },
  {
    "text": "um you know 30 to 50 overhead relative to host networking um",
    "start": "925279",
    "end": "932000"
  },
  {
    "text": "in the worst case we see that the psyllium direct mode um only at that two meg block size",
    "start": "932000",
    "end": "938320"
  },
  {
    "text": "incurs a 10 overhead but uh is much more competitive at other block sizes",
    "start": "938320",
    "end": "944639"
  },
  {
    "text": "again psyllium direct mode stacks up really nicely um compared to host networking and we're",
    "start": "944639",
    "end": "951360"
  },
  {
    "text": "not paying that overhead with the encapsulation cost",
    "start": "951360",
    "end": "956720"
  },
  {
    "text": "so let's move on and look at the right benchmarks so these common block sizes again what",
    "start": "957199",
    "end": "964800"
  },
  {
    "text": "1k to 8k we observed a five to fifteen percent overhead when encapsulated",
    "start": "964800",
    "end": "971680"
  },
  {
    "text": "psyllium direct mode still stacks up favorably again we're seeing roughly two percent",
    "start": "971680",
    "end": "976800"
  },
  {
    "text": "overhead for that psyllium direct mode really competitive with host networking",
    "start": "976800",
    "end": "983519"
  },
  {
    "text": "and then when we look at those larger block sizes in one meg to the eight minute block",
    "start": "983519",
    "end": "988720"
  },
  {
    "text": "sizes this is where things got a little interesting and we had to",
    "start": "988720",
    "end": "994480"
  },
  {
    "text": "dig a little deeper into what was happening um you know we're only seeing a one to two percent overhead um",
    "start": "994480",
    "end": "1001680"
  },
  {
    "text": "calico the idea with the ip and ip encapsulation current a little bit more overhead um",
    "start": "1001680",
    "end": "1007759"
  },
  {
    "text": "but these are surprising results why does the performance not differentiate itself on right this is something that we had",
    "start": "1007759",
    "end": "1014560"
  },
  {
    "text": "to dig into now if you recall in a previous slide",
    "start": "1014560",
    "end": "1020800"
  },
  {
    "text": "where i was discussing the environment we had i mentioned a pair of 25 gig",
    "start": "1020800",
    "end": "1028959"
  },
  {
    "text": "bonded mix that we have on our client node and it turns out that this",
    "start": "1028959",
    "end": "1036000"
  },
  {
    "text": "is an important factor that uh we didn't consider initially um but before we dig into that",
    "start": "1036000",
    "end": "1044480"
  },
  {
    "text": "let's talk about bonding a little bit and make it clear what we mean when we talk",
    "start": "1044480",
    "end": "1050160"
  },
  {
    "text": "about bonding so bonding is when we take multiple physical interfaces",
    "start": "1050160",
    "end": "1056320"
  },
  {
    "text": "and we make them appear as a single interface with multiple channels working behind the scenes now linux supports a myriad of bonding",
    "start": "1056320",
    "end": "1063120"
  },
  {
    "text": "modes we were running with um lacp",
    "start": "1063120",
    "end": "1068320"
  },
  {
    "text": "bonding right here referred to as mode4 this is just the configuration that we had in this specific configuration lacp has",
    "start": "1068320",
    "end": "1076320"
  },
  {
    "text": "some tunable parameters and one of those parameters is a hashing algorithm",
    "start": "1076320",
    "end": "1082160"
  },
  {
    "text": "for transmitting packets determining which interface we're going to emit the packet on that's",
    "start": "1082160",
    "end": "1088799"
  },
  {
    "text": "done through a hashing algorithm the key here is we want to",
    "start": "1088799",
    "end": "1095520"
  },
  {
    "text": "figure out how we can balance traffic really nicely across these mix again we have 225 gig",
    "start": "1095520",
    "end": "1101520"
  },
  {
    "text": "mix this is a lot of bandwidth let's make the most of it so how do we",
    "start": "1101520",
    "end": "1106559"
  },
  {
    "text": "balance this um and it turns out it's these hash policies",
    "start": "1106559",
    "end": "1112400"
  },
  {
    "text": "that matter so bringing this back to the environment our initial round of benchmarks we",
    "start": "1112400",
    "end": "1118799"
  },
  {
    "text": "observe that poor utilization on that on that bond um our network bandwidth demands",
    "start": "1118799",
    "end": "1126240"
  },
  {
    "text": "topped out about 25 gig when we had a second 25 gig nick that we could have spilled over",
    "start": "1126240",
    "end": "1133520"
  },
  {
    "text": "traffic to so the question we you know we naturally ask is how do we drive some better",
    "start": "1133520",
    "end": "1138799"
  },
  {
    "text": "utilization on that well we had to tune these bond settings",
    "start": "1138799",
    "end": "1145760"
  },
  {
    "text": "and it turns out that the parameter that yielded the most dramatic results was tuning this transmit hash policy parameter on",
    "start": "1145760",
    "end": "1153840"
  },
  {
    "text": "the bond um now let me just preface this by saying these are the settings that yield the",
    "start": "1153840",
    "end": "1160160"
  },
  {
    "text": "yield of the most dramatic performance gains in our cluster um so for host networking and",
    "start": "1160160",
    "end": "1167520"
  },
  {
    "text": "psyllium with vxlan and selenium with direct mode these are the configurations that we tested by",
    "start": "1167520",
    "end": "1175520"
  },
  {
    "text": "with the tuned hash policy we had to tune them a little different because they have different characteristics",
    "start": "1175520",
    "end": "1181760"
  },
  {
    "text": "in the way that they set up the data path so you know with host networking we use",
    "start": "1181760",
    "end": "1188080"
  },
  {
    "text": "this layer 3 plus 4 hash policy which what that does is that just takes into account",
    "start": "1188080",
    "end": "1194400"
  },
  {
    "text": "um your source ip your desk ip your source port and your destination port",
    "start": "1194400",
    "end": "1199440"
  },
  {
    "text": "feeds those into the hash algorithm and uh determines which nic packet goes out",
    "start": "1199440",
    "end": "1205919"
  },
  {
    "text": "based on those parameters for vx slant for sewing with vxlan um",
    "start": "1205919",
    "end": "1211679"
  },
  {
    "text": "we had to use the end cap three plus four now what this does is this does the same thing as that layer three plus four",
    "start": "1211679",
    "end": "1217679"
  },
  {
    "text": "bonding except it looks inside the inner packet",
    "start": "1217679",
    "end": "1223600"
  },
  {
    "text": "of the vxlan uh encapsulation and uses the inner packet",
    "start": "1223600",
    "end": "1230159"
  },
  {
    "text": "uh source ip that's ipa source port and desk port and it doesn't use the outlet packet now",
    "start": "1230159",
    "end": "1237120"
  },
  {
    "text": "psyllium direct mode um we use the layer two plus three hash policy which uh takes into account",
    "start": "1237120",
    "end": "1244960"
  },
  {
    "text": "the the source mac address the destination mac address and then the source ip and the destination id",
    "start": "1244960",
    "end": "1251840"
  },
  {
    "text": "these settings yield the most dramatic performance gains in our cluster keep in mind these are very specific to",
    "start": "1252000",
    "end": "1259200"
  },
  {
    "text": "our cluster factors such as cluster size bonding mode hardware capabilities",
    "start": "1259200",
    "end": "1265039"
  },
  {
    "text": "um they're all going to call for different settings and you may need to tune things differently if you're going to use bonds",
    "start": "1265039",
    "end": "1273679"
  },
  {
    "text": "now what did this give us well let's start by again looking at these",
    "start": "1274400",
    "end": "1280720"
  },
  {
    "text": "common block sizes at 1 to 8k and it was kind of underwhelming",
    "start": "1280720",
    "end": "1286480"
  },
  {
    "text": "we didn't really see much difference when we tuned the hash policies here um",
    "start": "1286480",
    "end": "1292880"
  },
  {
    "text": "turns out at these block sizes we're not actually generating enough network traffic",
    "start": "1292880",
    "end": "1297919"
  },
  {
    "text": "for the balancing of packets across the mix that participate in the bomb",
    "start": "1297919",
    "end": "1303760"
  },
  {
    "text": "matter but when we",
    "start": "1303760",
    "end": "1309679"
  },
  {
    "text": "move to toward those larger block sizes these 1 to 8 meg block sizes we're",
    "start": "1309679",
    "end": "1315840"
  },
  {
    "text": "actually putting more demands on the network in terms of bandwidth",
    "start": "1315840",
    "end": "1320960"
  },
  {
    "text": "and what this does is this causes us to need to spill over to that second nick",
    "start": "1320960",
    "end": "1326080"
  },
  {
    "text": "to utilize its bandwidth and what we see here is significant",
    "start": "1326080",
    "end": "1331919"
  },
  {
    "text": "performance gains by by tuning these policies um as much as 40 percent more",
    "start": "1331919",
    "end": "1337520"
  },
  {
    "text": "iops by making this simple change and that that so that's across the board",
    "start": "1337520",
    "end": "1344159"
  },
  {
    "text": "both the vxlan encapsulated traffic as well as the host networking and the psyllium",
    "start": "1344159",
    "end": "1349360"
  },
  {
    "text": "direct mode um one thing i want to point out here is you know this is not a",
    "start": "1349360",
    "end": "1354960"
  },
  {
    "text": "direct simulate simulation of a cluster that's under load from multiple clients",
    "start": "1354960",
    "end": "1360400"
  },
  {
    "text": "but the fact that what we're doing here is demanding more bandwidth from the network",
    "start": "1360400",
    "end": "1368640"
  },
  {
    "text": "this is an indication that these sorts of bonding settings",
    "start": "1368640",
    "end": "1374080"
  },
  {
    "text": "will matter if you're using if you have multiple clients um",
    "start": "1374080",
    "end": "1379120"
  },
  {
    "text": "using the network and putting packets out there and stressing the network um",
    "start": "1379120",
    "end": "1386240"
  },
  {
    "text": "now another thing to point out here is you may not be using bonding this may not be uh common",
    "start": "1386240",
    "end": "1391919"
  },
  {
    "text": "on your client nodes that's where our the bonding in our setup was um but you may be employing bonds on",
    "start": "1391919",
    "end": "1398720"
  },
  {
    "text": "your storage nodes and the same principle applies we want that good balance of traffic",
    "start": "1398720",
    "end": "1404480"
  },
  {
    "text": "across the bonds that we're having the knicks that we're having to participate in that bond",
    "start": "1404480",
    "end": "1411200"
  },
  {
    "text": "so we learned a lot from this um so let's talk through some of these",
    "start": "1412720",
    "end": "1420559"
  },
  {
    "text": "basic these insights that we had",
    "start": "1420559",
    "end": "1425120"
  },
  {
    "text": "so let's finish up talking about bonding what what what to know about bonding again this this may not be something",
    "start": "1426960",
    "end": "1433200"
  },
  {
    "text": "that you do in your environment um but if you do something to pay attention to and there's there's a lesson here",
    "start": "1433200",
    "end": "1438480"
  },
  {
    "text": "that um that we learned which is question your assumptions um we",
    "start": "1438480",
    "end": "1444720"
  },
  {
    "text": "we just assumed that we had um you know a bonded pair of 25 gig mix that's you",
    "start": "1444720",
    "end": "1450400"
  },
  {
    "text": "know 50 gig pipe right that that should be plenty of bandwidth there should be a bottleneck there",
    "start": "1450400",
    "end": "1456799"
  },
  {
    "text": "well it turns out it wasn't tuned properly and it did become a bottleneck",
    "start": "1456799",
    "end": "1462799"
  },
  {
    "text": "so it turns out if you're going to use bonding bonding modes matter you want that",
    "start": "1463679",
    "end": "1470559"
  },
  {
    "text": "balance of traffic again these are sorts of configurations that are going to be specific to your",
    "start": "1470559",
    "end": "1475760"
  },
  {
    "text": "environment and factors such as your cni configuration your scale hardware capabilities they're going to drive your",
    "start": "1475760",
    "end": "1482080"
  },
  {
    "text": "choices here um as far as general recommendations",
    "start": "1482080",
    "end": "1490240"
  },
  {
    "text": "um i i some of these may seem seem basic but um you know we",
    "start": "1490240",
    "end": "1497279"
  },
  {
    "text": "again these are learnings and things that were confirmed for us overlays and encapsulation are going to",
    "start": "1497279",
    "end": "1502799"
  },
  {
    "text": "limit your iops because they're going to introduce latency in the network so where possible try and avoid",
    "start": "1502799",
    "end": "1511200"
  },
  {
    "text": "encapsulating pod traffic with vxlan or ipnip or gre pick your encapsulation protocol",
    "start": "1511200",
    "end": "1518080"
  },
  {
    "text": "that that's going to add overhead so we want to avoid that where we can um bandwidth demands of a single client",
    "start": "1518080",
    "end": "1525840"
  },
  {
    "text": "are going to be highly correlated with block size we harkened back to the",
    "start": "1525840",
    "end": "1532159"
  },
  {
    "text": "slide i showed that had the benchmarks we ran natively against the ssd and the the right benchmarks",
    "start": "1532159",
    "end": "1541039"
  },
  {
    "text": "kind of exhibited a strange uh behavior at 1k and 2k block sizes",
    "start": "1541039",
    "end": "1546720"
  },
  {
    "text": "um and then all of a sudden once we hit 4k block sizes um performance shot up um you want to",
    "start": "1546720",
    "end": "1554000"
  },
  {
    "text": "align with a native block size um when using bonds again pay attention to",
    "start": "1554000",
    "end": "1559919"
  },
  {
    "text": "those hash policies and and some of these mining details tuning these things can yield",
    "start": "1559919",
    "end": "1565520"
  },
  {
    "text": "significant performance gains and it may not always be obvious uh where where your bottlenecks might be",
    "start": "1565520",
    "end": "1571840"
  },
  {
    "text": "so again question everything um this experience that uh that we had",
    "start": "1571840",
    "end": "1579360"
  },
  {
    "text": "with bonding is a perfect example of that so with that i want to hand it back to mark to wrap things up",
    "start": "1579360",
    "end": "1586960"
  },
  {
    "text": "thanks ryan i really appreciate all the solid work there and uh we believe it's going to set the stage for some great follow-up work that",
    "start": "1589360",
    "end": "1596159"
  },
  {
    "text": "we want to present at following kubecons so let's let's drive one specific point",
    "start": "1596159",
    "end": "1601440"
  },
  {
    "text": "home once again we were really doing this work in order to determine look there are multiple cni",
    "start": "1601440",
    "end": "1606720"
  },
  {
    "text": "plug-ins you can use in multiple network paths that you can use in order to set this three-level",
    "start": "1606720",
    "end": "1612080"
  },
  {
    "text": "sandwich of seth rook and kubernetes up",
    "start": "1612080",
    "end": "1617279"
  },
  {
    "text": "primary lesson to learn here is look the best hardware without the best cni is going to leave you wanting quick",
    "start": "1617279",
    "end": "1623919"
  },
  {
    "text": "caveat do we believe that we've covered all of the possible cni's here no you'll see that momentarily in a next",
    "start": "1623919",
    "end": "1630640"
  },
  {
    "text": "steps next lesson host networking is easy it's a little bit insecure",
    "start": "1630640",
    "end": "1635840"
  },
  {
    "text": "it performs well it was really the target that we shot at for all of the tests that we did so",
    "start": "1635840",
    "end": "1642640"
  },
  {
    "text": "it's an excellent thing to kind of set the stage for where your system is but it may not be what you want to",
    "start": "1642640",
    "end": "1647919"
  },
  {
    "text": "actually deploy in production next iops matter and this this one is",
    "start": "1647919",
    "end": "1653200"
  },
  {
    "text": "one of those obvious statements i've realized that storage people look at iops unnecessary network latency is going to",
    "start": "1653200",
    "end": "1659360"
  },
  {
    "text": "hurt iops so as a system architect ensure that you design your architecture",
    "start": "1659360",
    "end": "1664799"
  },
  {
    "text": "to minimize network latency next thing ceph actually implements",
    "start": "1664799",
    "end": "1670480"
  },
  {
    "text": "policy enforcement why does why does this matter well you have policy enforcement that can happen",
    "start": "1670480",
    "end": "1675919"
  },
  {
    "text": "at the ceph layer you have policy enforcement that can happen at the cmi layer and you will have some",
    "start": "1675919",
    "end": "1681600"
  },
  {
    "text": "storage people tell you hey i've got this at ceph i don't necessarily need this in my cni layer one of the things we did not benchmark",
    "start": "1681600",
    "end": "1688559"
  },
  {
    "text": "here was implementing additional policy in the cni itself and different cni's",
    "start": "1688559",
    "end": "1694080"
  },
  {
    "text": "have strikingly different performance levels if you go look at talks between xdp and say iptables you'll see that",
    "start": "1694080",
    "end": "1700960"
  },
  {
    "text": "point really hammered home so realize that you may want to push implementing cni policy in which would",
    "start": "1700960",
    "end": "1707679"
  },
  {
    "text": "actually make the performance gains even more striking in the benchmarks that we ran",
    "start": "1707679",
    "end": "1712720"
  },
  {
    "text": "so future work one of the things we did not look at was multis with sr iov adapters using virtual functions",
    "start": "1712720",
    "end": "1719679"
  },
  {
    "text": "uh both ryan and i with our network background believe that fundamentally that should not matter",
    "start": "1719679",
    "end": "1725120"
  },
  {
    "text": "that host networking should be the primary or the best performance case that you're going to be able to generate",
    "start": "1725120",
    "end": "1731600"
  },
  {
    "text": "we would like to test that though next thing calico is doing some extensive work integrating bpf into their environment",
    "start": "1731600",
    "end": "1738960"
  },
  {
    "text": "so that would begin differentiating now between calico and celium and using the same underlying technology",
    "start": "1738960",
    "end": "1745120"
  },
  {
    "text": "which would be bpf and xdp we believe that would be a valid test case to start looking at",
    "start": "1745120",
    "end": "1751520"
  },
  {
    "text": "in addition we would like to improve our in-line instrumentation in terms of making sure we can actually",
    "start": "1751520",
    "end": "1757440"
  },
  {
    "text": "timestamp from the time a packet leaves fio and actually exits a nick on the box",
    "start": "1757440",
    "end": "1763919"
  },
  {
    "text": "right now we have a round trip with fio from the time it leaves fio and goes down and back across and then",
    "start": "1763919",
    "end": "1769919"
  },
  {
    "text": "returns all the way all the way back to fio so it's a black box text test that we're using right now and we'd",
    "start": "1769919",
    "end": "1776480"
  },
  {
    "text": "like to make that finer granule finally we have three nodes in a cluster and one device driving the workload",
    "start": "1776480",
    "end": "1783679"
  },
  {
    "text": "while that's great for setting baseline benchmarks over time we need to add more clients and more",
    "start": "1783679",
    "end": "1789679"
  },
  {
    "text": "storage nodes in order to have cross load uh interference",
    "start": "1789679",
    "end": "1795840"
  },
  {
    "text": "so we'll go ahead and open the floor for q a i'm going to rip through this and we'll figure out",
    "start": "1795919",
    "end": "1801120"
  },
  {
    "text": "how this works with our with our online format right now thank you for your time appreciate your",
    "start": "1801120",
    "end": "1806720"
  },
  {
    "text": "attention and look forward to hearing back from everyone",
    "start": "1806720",
    "end": "1810880"
  },
  {
    "text": "okay everybody thanks for joining uh happy to take some questions",
    "start": "1818960",
    "end": "1826000"
  },
  {
    "text": "we've had a few good ones come through the chat uh while the presentation was airing",
    "start": "1826000",
    "end": "1832880"
  },
  {
    "text": "so uh dive into a couple of those uh one question that uh kind of popped to",
    "start": "1832880",
    "end": "1839679"
  },
  {
    "text": "the top here was um how would i improve latency if i'm using nfs",
    "start": "1839679",
    "end": "1844799"
  },
  {
    "text": "um my answer to that would be um everything that we talked about here",
    "start": "1844799",
    "end": "1850720"
  },
  {
    "text": "applies to nfs as well so um whether you're using rbd or nfs",
    "start": "1850720",
    "end": "1857919"
  },
  {
    "text": "these same principles are gonna apply um another question",
    "start": "1857919",
    "end": "1865679"
  },
  {
    "text": "um and this one is one that i wanted to uh spend a little time on i wish i had",
    "start": "1865679",
    "end": "1871440"
  },
  {
    "text": "spent a little more time on it in the presentation um the question is how are iops bound by",
    "start": "1871440",
    "end": "1877600"
  },
  {
    "text": "network latency i would have thought that they were limited by bandwidth um and that's exactly the uh",
    "start": "1877600",
    "end": "1885279"
  },
  {
    "text": "the intuition that i went into this exercise with myself i had 100 gig networking on",
    "start": "1885279",
    "end": "1892799"
  },
  {
    "text": "my storage nodes 25 gig bonded pair on my client node",
    "start": "1892799",
    "end": "1900559"
  },
  {
    "text": "i should be able to get amazing performance because i have all this fast networking",
    "start": "1902000",
    "end": "1907360"
  },
  {
    "text": "available to me and the reality is at least in this setup",
    "start": "1907360",
    "end": "1912399"
  },
  {
    "text": "uh latency or bandwidth was not the driving factor for performance and what",
    "start": "1912399",
    "end": "1919679"
  },
  {
    "text": "it really turned out to be were these different",
    "start": "1919679",
    "end": "1925039"
  },
  {
    "text": "configuration parameters that we discussed in the talk cni plug-in",
    "start": "1925039",
    "end": "1931120"
  },
  {
    "text": "and the way you configure it actually makes a huge difference um and what we're hitting there is that",
    "start": "1931120",
    "end": "1936880"
  },
  {
    "text": "latency both in how we access the network and in",
    "start": "1936880",
    "end": "1942240"
  },
  {
    "text": "the kernel as we use different cni configurations um",
    "start": "1942240",
    "end": "1948880"
  },
  {
    "text": "you know the the other thing that i i guess i should have known going in but i i didn't think was um you know i'll just",
    "start": "1948880",
    "end": "1956399"
  },
  {
    "text": "be able to fill this pipe if i tune it right um it turns out the really",
    "start": "1956399",
    "end": "1962799"
  },
  {
    "text": "the way to use all that bandwidth was actually to push larger block sizes",
    "start": "1962799",
    "end": "1968000"
  },
  {
    "text": "um now of course as you scale up and you start using more as you have more clients using the",
    "start": "1968000",
    "end": "1974720"
  },
  {
    "text": "cluster regardless of the block size as you scale that out you're going to make",
    "start": "1974720",
    "end": "1980240"
  },
  {
    "text": "better use of that bandwidth but you know bandwidth was not the determining factor",
    "start": "1980240",
    "end": "1986320"
  },
  {
    "text": "in performance here and it was these different areas where we have latency both making sure that the bond is",
    "start": "1986320",
    "end": "1993360"
  },
  {
    "text": "configured correctly and you know minimizing the overheads and",
    "start": "1993360",
    "end": "1998799"
  },
  {
    "text": "traversing the network stack so great question i i appreciate that i didn't get to",
    "start": "1998799",
    "end": "2004960"
  },
  {
    "text": "spend as much time on that in the talk as i wanted",
    "start": "2004960",
    "end": "2009039"
  },
  {
    "text": "see the next question uh that came through in the chat uh did you also measure cpu overhead",
    "start": "2010000",
    "end": "2015279"
  },
  {
    "text": "caused by the network plug-ins and when was there any um yeah there's absolutely cpu overhead",
    "start": "2015279",
    "end": "2021440"
  },
  {
    "text": "here um and i'm sorry to say that's not something that i measured this go around we were really",
    "start": "2021440",
    "end": "2028000"
  },
  {
    "text": "focused on what knobs we can turn to drive iops in the cluster so",
    "start": "2028000",
    "end": "2034799"
  },
  {
    "text": "you know that's definitely something to look at going forward i know that others have done work uh",
    "start": "2034799",
    "end": "2040640"
  },
  {
    "text": "profiling psyllium and calco and other cni's",
    "start": "2040640",
    "end": "2047120"
  },
  {
    "text": "so you may be able to find some answers maybe cobble that together uh but yeah i don't have those numbers",
    "start": "2047120",
    "end": "2054320"
  },
  {
    "text": "right now and that's something i would like to go back and look at",
    "start": "2054320",
    "end": "2061839"
  },
  {
    "text": "let's see what else do we have here um can you say more about the networking",
    "start": "2064320",
    "end": "2070320"
  },
  {
    "text": "equipment which was used in the benchmark this can have a huge impact on results uh yes",
    "start": "2070320",
    "end": "2075679"
  },
  {
    "text": "so um we had um",
    "start": "2075679",
    "end": "2081040"
  },
  {
    "text": "as i mentioned we had both melanox and q logic mix at our disposal running at uh 25 and 100",
    "start": "2081280",
    "end": "2088000"
  },
  {
    "text": "gig we also were connected to um i believe this was a uh a dell switch",
    "start": "2088000",
    "end": "2095760"
  },
  {
    "text": "i would have to double check with my storage engineers again 100 gig networking",
    "start": "2095760",
    "end": "2100839"
  },
  {
    "text": "um off the switch so yeah basically 100 gig network fabric",
    "start": "2100839",
    "end": "2109760"
  },
  {
    "text": "and then my client node was only able to run at 25 gig",
    "start": "2109760",
    "end": "2117838"
  },
  {
    "text": "let's see um or future tests we look at production clusters and the",
    "start": "2125040",
    "end": "2131200"
  },
  {
    "text": "block sizes they are doing for reads and writes to get more realistic benchmarks one to four make block sizes are nice",
    "start": "2131200",
    "end": "2136720"
  },
  {
    "text": "for filling your pipe but not for iops",
    "start": "2136720",
    "end": "2142240"
  },
  {
    "text": "yeah absolutely um the the one four meg uh that definitely fills the pipe",
    "start": "2142240",
    "end": "2149839"
  },
  {
    "text": "um puts stress on the network and kind of the reason i scaled up there is i actually",
    "start": "2149839",
    "end": "2156079"
  },
  {
    "text": "profiled um the characteristics of different block sizes just as something to explore um to kind of see",
    "start": "2156079",
    "end": "2164160"
  },
  {
    "text": "what the impact on the network was and it turns out that that turned into a sort of a proxy for",
    "start": "2164160",
    "end": "2171440"
  },
  {
    "text": "scale in the system it's not a perfect one but um you know it it puts more uh",
    "start": "2171440",
    "end": "2179200"
  },
  {
    "text": "network traffic out there it's more for the system to handle so it's sort of a proxy for scaling up",
    "start": "2179200",
    "end": "2186160"
  },
  {
    "text": "with multiple clients obviously as we talked about in the talk just having a single client out there",
    "start": "2186160",
    "end": "2191839"
  },
  {
    "text": "is not realistic and that's one of the things that we're looking at is um doing this exercise in a",
    "start": "2191839",
    "end": "2199280"
  },
  {
    "text": "up environment where um we are using more realistic block sizes",
    "start": "2199280",
    "end": "2205119"
  },
  {
    "text": "using a more realistic number of clients and a more realistic configuration this exercise is",
    "start": "2205119",
    "end": "2211040"
  },
  {
    "text": "kind of a first pass to build kind of a basic understanding",
    "start": "2211040",
    "end": "2216720"
  },
  {
    "text": "of what the key factors we need to pay attention to with regard to performance on",
    "start": "2216720",
    "end": "2221920"
  },
  {
    "text": "so yeah thanks for that question",
    "start": "2221920",
    "end": "2229839"
  },
  {
    "text": "all right well um again thanks for attending and thanks for the great questions everyone um we can move this conversation uh over",
    "start": "2229839",
    "end": "2237119"
  },
  {
    "text": "to slack and i'm happy to take questions there",
    "start": "2237119",
    "end": "2242480"
  }
]
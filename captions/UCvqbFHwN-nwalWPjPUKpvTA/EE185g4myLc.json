[
  {
    "text": "uh welcome everyone and i think it's the first time we have the in-person meeting after such a long",
    "start": "240",
    "end": "7440"
  },
  {
    "text": "pandemic and well in fact the most difficult things i found about this time is just fighting",
    "start": "7440",
    "end": "13360"
  },
  {
    "text": "the room so as you can see like we're probably in a hurry so sorry about that we started five minutes late",
    "start": "13360",
    "end": "20080"
  },
  {
    "text": "all right so today my our topic is longhorn and i will be joined by my colleague joshua",
    "start": "20080",
    "end": "27599"
  },
  {
    "text": "and to talk with you on the longhorn project give you update and see what is upcoming",
    "start": "27599",
    "end": "34800"
  },
  {
    "text": "so since you are here i think most of you probably know like long form is a cncf",
    "start": "35120",
    "end": "41120"
  },
  {
    "text": "project and last october longhorn has been promoted to the incubation stage",
    "start": "41120",
    "end": "46160"
  },
  {
    "text": "and we're working towards the graduated state as well so longhorse mission is in fact very",
    "start": "46160",
    "end": "51920"
  },
  {
    "text": "simple and we want to provide your kubernetes clusters with the reliable",
    "start": "51920",
    "end": "58559"
  },
  {
    "text": "storage solution and the local itself is a highly available distributed",
    "start": "58559",
    "end": "63680"
  },
  {
    "text": "distributor storage software building on top of the kubernetes and beautiful kubernetes",
    "start": "63680",
    "end": "69360"
  },
  {
    "text": "so if you want to find more information always go to launch.io which contains our knowledge base our documentation",
    "start": "69360",
    "end": "76080"
  },
  {
    "text": "and all the information you can get and how do you in touch so how is longhorn different",
    "start": "76080",
    "end": "83200"
  },
  {
    "text": "there are a few design principles on the longhorn when we start working on this project we have the aim to for this",
    "start": "83200",
    "end": "90880"
  },
  {
    "text": "storage project to of course be reliable which is the most important thing about any storage project",
    "start": "90880",
    "end": "96880"
  },
  {
    "text": "and the longer is designed to be crash consistent and we also have designed multiple layers of protection against",
    "start": "96880",
    "end": "103840"
  },
  {
    "text": "the data loss like longhorn itself has built in snapshots you can always create in-class",
    "start": "103840",
    "end": "109040"
  },
  {
    "text": "snapshot but in addition to that also provides the backhand mechanism like building backhand mechanism for you",
    "start": "109040",
    "end": "115680"
  },
  {
    "text": "to backup your volume to a s3 like external of the snap of the cluster and",
    "start": "115680",
    "end": "121840"
  },
  {
    "text": "also that backup is very efficient it's incremental and it's like the second layer of protection will get for your",
    "start": "121840",
    "end": "127600"
  },
  {
    "text": "volume and the third layer is in fact longhorns design it's very simple even in the",
    "start": "127600",
    "end": "133280"
  },
  {
    "text": "worst case scenario you lost all your nose as long as you have one of the replica hard drives still available you",
    "start": "133280",
    "end": "140080"
  },
  {
    "text": "can very easily extract data from them so reliability is the first principle we",
    "start": "140080",
    "end": "145440"
  },
  {
    "text": "focus on and the second one is usability as you know many softwares in the kubernetes areas",
    "start": "145440",
    "end": "152160"
  },
  {
    "text": "like have the operation pattern and have home charging installation but many of them still require you to go through a",
    "start": "152160",
    "end": "158480"
  },
  {
    "text": "lot of configuration to make it usable and longer in fact is one of the first storage solution out there to enable the",
    "start": "158480",
    "end": "164640"
  },
  {
    "text": "one-click installation and you can just download like install local from your helm chart or renter",
    "start": "164640",
    "end": "171440"
  },
  {
    "text": "app category and one click and you will have a highly available distributed",
    "start": "171440",
    "end": "176720"
  },
  {
    "text": "storage available to your kubernetes cluster and also longhorn has provided a local",
    "start": "176720",
    "end": "182400"
  },
  {
    "text": "ui which provide the polished user interface to any user and including all kinds of",
    "start": "182400",
    "end": "188640"
  },
  {
    "text": "advanced functions the local provides like disaster recovery snapshot backup",
    "start": "188640",
    "end": "194720"
  },
  {
    "text": "the disk tags and all the others functions and the third thing is like unlike many",
    "start": "194720",
    "end": "202560"
  },
  {
    "text": "of the storage projects out there we designed longhorn to be very maintainable and it's the concept is",
    "start": "202560",
    "end": "208959"
  },
  {
    "text": "easy to understand as you can see later and even easy to recover in the worst case scenario",
    "start": "208959",
    "end": "215360"
  },
  {
    "text": "because you understand how it works and the longhorn also provides your ability to upgrade without interrupting",
    "start": "215360",
    "end": "221599"
  },
  {
    "text": "the workload which means you don't need to schedule like a speed of downtime if you have something happens",
    "start": "221599",
    "end": "228720"
  },
  {
    "text": "all right so um let me talk a little bit about how local works so this is what we call the local engine",
    "start": "229599",
    "end": "235920"
  },
  {
    "text": "which is also a part like the longhorn data plan and as you can see now we have three",
    "start": "235920",
    "end": "241040"
  },
  {
    "text": "nodes and two of them with the ssd marks in the black which means they are data disk and",
    "start": "241040",
    "end": "248720"
  },
  {
    "text": "all three of them of course also has the root disk which is the ssd market gray and each every one of them have a cpu",
    "start": "248720",
    "end": "254799"
  },
  {
    "text": "and memory available so if you heard about the words of hyper converge in fact this is the more of the",
    "start": "254799",
    "end": "260959"
  },
  {
    "text": "hyper-converged deployment of longhorn and you can see there are some",
    "start": "260959",
    "end": "266479"
  },
  {
    "text": "process like like containers called instance manager engine instance manager or replicas manager",
    "start": "266479",
    "end": "272800"
  },
  {
    "text": "running on each nodes so once like a pod request the volume on",
    "start": "272800",
    "end": "278479"
  },
  {
    "text": "the foot on the kubernetes side a long one going to create two replicas on a",
    "start": "278479",
    "end": "283520"
  },
  {
    "text": "different node because we to ensure the high availability and then create an engine to connect to",
    "start": "283520",
    "end": "289280"
  },
  {
    "text": "those two replicas and provide and using the protocol to provide the data of",
    "start": "289280",
    "end": "295199"
  },
  {
    "text": "those two replicas to the volume instead of parts so this is very simple design and but",
    "start": "295199",
    "end": "301360"
  },
  {
    "text": "it's very efficient and it's very reliable because when you see if you have scale to more parts with more",
    "start": "301360",
    "end": "308080"
  },
  {
    "text": "volumes they are going to create new engines and replicas and more for you to",
    "start": "308080",
    "end": "313840"
  },
  {
    "text": "satisfy your storage need and there are two advantages of this design the first thing is",
    "start": "313840",
    "end": "320400"
  },
  {
    "text": "as you can see the data path of each volume is in fact not interfering together",
    "start": "320400",
    "end": "326639"
  },
  {
    "text": "so for example if you take out take out the engine or take out the replica the worst case scenario is only going to",
    "start": "326639",
    "end": "332400"
  },
  {
    "text": "impact that the volume of using that engine and if you take out the replica of course another replica will take over",
    "start": "332400",
    "end": "339280"
  },
  {
    "text": "so it's no even no impact and the second thing is as you can see the engine always collocated with the",
    "start": "339280",
    "end": "346720"
  },
  {
    "text": "like with the consumer with the workload so if the node winds down",
    "start": "346720",
    "end": "353840"
  },
  {
    "text": "and the kubernetes were going to reschedule the part for example to the node 3.",
    "start": "353840",
    "end": "359520"
  },
  {
    "text": "even there is no local replica exist within in this scenario lower still can",
    "start": "359520",
    "end": "364960"
  },
  {
    "text": "find the blue replica which is for the blue volume still exist so we're going to create another engine which is",
    "start": "364960",
    "end": "370880"
  },
  {
    "text": "stainless by itself connect to the replica on node 2 and restore your operation for your for your volume",
    "start": "370880",
    "end": "378080"
  },
  {
    "text": "so it's very flexible and the reliable design here and it's a like satisfies a lot of scenario like if you have for",
    "start": "378080",
    "end": "385440"
  },
  {
    "text": "example eks running on different ac and your ebs one is going to tie to",
    "start": "385440",
    "end": "390880"
  },
  {
    "text": "one az and locally in fact able to do cross ac scheduling and ensure your data",
    "start": "390880",
    "end": "396080"
  },
  {
    "text": "visibility in case one ac goes down which ebs itself can now do",
    "start": "396080",
    "end": "401840"
  },
  {
    "text": "okay so that was the like overview of the data plan of longhorn and this is the quick rundown of the manager part",
    "start": "402479",
    "end": "410000"
  },
  {
    "text": "which were called like a management plan so local manager in fact is building on top of kubernetes cluster and whenever",
    "start": "410000",
    "end": "416080"
  },
  {
    "text": "kubernetes cluster have a request to create new volume and they'll go through",
    "start": "416080",
    "end": "421120"
  },
  {
    "text": "the csi interface to talk with the longest side plug-in which in turn talk to the local manager with the local api",
    "start": "421120",
    "end": "428560"
  },
  {
    "text": "and and local manager going to write the metadata into the kubernetes api server using the tradition like",
    "start": "428560",
    "end": "435039"
  },
  {
    "text": "not a traditional but not commonly used kubernetes controller pattern to operate on those objects",
    "start": "435039",
    "end": "441520"
  },
  {
    "text": "and start creating engine and replicas to satisfy the need and all the engine replicas you see here",
    "start": "441520",
    "end": "448319"
  },
  {
    "text": "are represented by the kubernetes api objects cr objects and there's another way to interact with",
    "start": "448319",
    "end": "455440"
  },
  {
    "text": "local manager and explore all the features is of course through the local ui which is also going to talk with the",
    "start": "455440",
    "end": "462639"
  },
  {
    "text": "local manager with the long api so this is the very simple approach and now we're also exploring some other ways",
    "start": "462639",
    "end": "469919"
  },
  {
    "text": "uh currently uh in the next release we're going to have like more integration with kubernetes to enable",
    "start": "469919",
    "end": "477280"
  },
  {
    "text": "you to like manually change the object and the spec and also reflect that",
    "start": "477280",
    "end": "483199"
  },
  {
    "text": "change into the local system so currently this change is gated by the long api but they were not going to be",
    "start": "483199",
    "end": "489440"
  },
  {
    "text": "updated in the future all right so quick update on the now the open",
    "start": "489440",
    "end": "496400"
  },
  {
    "text": "source community side of longhorn we're currently a cncf incubation project and",
    "start": "496400",
    "end": "502400"
  },
  {
    "text": "now github starts 3.8 000 and the worldwide node count is currently at 53",
    "start": "502400",
    "end": "508160"
  },
  {
    "text": "thousand plus and in fact you can take a look at the metrics.local.io to see the real-time update and we're connecting",
    "start": "508160",
    "end": "515919"
  },
  {
    "text": "this data is in fact like just a get call which we got to send a notification about the local user the new vision is",
    "start": "515919",
    "end": "522800"
  },
  {
    "text": "like new version is available so but on a side effect as we know like how many nodes is like sending that call because",
    "start": "522800",
    "end": "529279"
  },
  {
    "text": "we have the server running as it's just a guess of get coding so also we have like 2 000 users on the",
    "start": "529279",
    "end": "536320"
  },
  {
    "text": "slack channel on the cncf and the legacy rental user slack channel and if you",
    "start": "536320",
    "end": "541600"
  },
  {
    "text": "have any questions or requests coming to longhorn feel free to talk with us on the slash",
    "start": "541600",
    "end": "547279"
  },
  {
    "text": "channel and also fail issues on github",
    "start": "547279",
    "end": "551519"
  },
  {
    "text": "okay so upcoming 1.3 release we're already have the 1.3 rc1 out",
    "start": "552399",
    "end": "559200"
  },
  {
    "text": "i think a couple days ago and by the end of q2 we're aiming to have windows 3 like official ga release",
    "start": "559200",
    "end": "565839"
  },
  {
    "text": "in this release we're going to include csi snapshot support for the longest snapshot",
    "start": "565839",
    "end": "571120"
  },
  {
    "text": "previously we have the longhorn snapshot sorry csi snapshot for the longhorn backup which means like whenever you",
    "start": "571120",
    "end": "577440"
  },
  {
    "text": "create a csi snapshot logo will create a backup for you in the backup store which is as",
    "start": "577440",
    "end": "583200"
  },
  {
    "text": "you might know is off the cluster so now the csi snapshot support i think",
    "start": "583200",
    "end": "588480"
  },
  {
    "text": "to the longhorn in class snapshot has been added and also we started enabling you to able",
    "start": "588480",
    "end": "594560"
  },
  {
    "text": "to modify the custom resources using a code control so you have the basically",
    "start": "594560",
    "end": "599839"
  },
  {
    "text": "the cli like a longer ci becomes the code control and we are adding the storage network",
    "start": "599839",
    "end": "605920"
  },
  {
    "text": "which when you use that in combination with the motors plugin you are you can",
    "start": "605920",
    "end": "612320"
  },
  {
    "text": "enable the storage traffic like used by longhorn to go through a different separate network which you can have more",
    "start": "612320",
    "end": "618000"
  },
  {
    "text": "bandwidth setting there and we have add other features like backing image and the volume download",
    "start": "618000",
    "end": "624160"
  },
  {
    "text": "and the secured communication among the data control plane and the data plan",
    "start": "624160",
    "end": "629839"
  },
  {
    "text": "so this is the most immediate upcoming release and in fact what really excites me is",
    "start": "629839",
    "end": "635839"
  },
  {
    "text": "about what's in the future so on the release after or like two weeks after we're looking to add in the",
    "start": "635839",
    "end": "642720"
  },
  {
    "text": "trim support to reduce the volume size one question we in fact get a lot is",
    "start": "642720",
    "end": "648160"
  },
  {
    "text": "like a file system if you delete file in the file system like the long warning didn't shrink",
    "start": "648160",
    "end": "653839"
  },
  {
    "text": "the reasoning is lower is by design is a blog storage so you need to understand more file system protocol for that to",
    "start": "653839",
    "end": "659600"
  },
  {
    "text": "happen so we are aiming to add that in the in the release like a in the next release after windows 3.",
    "start": "659600",
    "end": "665920"
  },
  {
    "text": "and also the local system backup restore itself is going to enable you to like for example if you have upgrade scenario",
    "start": "665920",
    "end": "673360"
  },
  {
    "text": "you are going to have a fail safe over like sorry fail safe in case like something went wrong",
    "start": "673360",
    "end": "678800"
  },
  {
    "text": "and the one guru feature will be there for your stay for workload for example you have a application running as a",
    "start": "678800",
    "end": "685279"
  },
  {
    "text": "stable set and all of these volumes can be grouped together for you to take snapshots or backups",
    "start": "685279",
    "end": "691279"
  },
  {
    "text": "and we are also aiming to add highly available nfs rearrangement support and helium s3",
    "start": "691279",
    "end": "698480"
  },
  {
    "text": "support as well the last of the list we are also like in fact working on a very exciting new",
    "start": "698480",
    "end": "705360"
  },
  {
    "text": "thing is a new high performance engine based on sbdk so um",
    "start": "705360",
    "end": "711519"
  },
  {
    "text": "yeah i will leave more to my colleague joshua do you demo what's the current state of the longhorn is and",
    "start": "711519",
    "end": "717519"
  },
  {
    "text": "maybe give you a pick kind of what's in the future cool",
    "start": "717519",
    "end": "723360"
  },
  {
    "text": "um you just quickly switch do you need press a button here test",
    "start": "723360",
    "end": "728880"
  },
  {
    "text": "test okay is this transmitting i can hear it",
    "start": "728880",
    "end": "735200"
  },
  {
    "text": "oh yeah okay thank you",
    "start": "735200",
    "end": "740240"
  },
  {
    "text": "so since we gave previously gave lots of intro demos uh i figured i'd do a little bit of a",
    "start": "740240",
    "end": "746959"
  },
  {
    "text": "different demo today um in which i talk about some cases",
    "start": "746959",
    "end": "752399"
  },
  {
    "text": "we've seen like when you run longer in production all right let's uh linux let's go",
    "start": "752399",
    "end": "759120"
  },
  {
    "text": "which we have seen like when you're online in production uh how do i get auto scaling to work",
    "start": "759120",
    "end": "765360"
  },
  {
    "text": "what kind of setup do i need like how can i get more control like mirror",
    "start": "765360",
    "end": "772800"
  },
  {
    "text": "yeah that's sure i think that works",
    "start": "772800",
    "end": "779279"
  },
  {
    "text": "are we seeing something",
    "start": "782240",
    "end": "785959"
  },
  {
    "text": "which one resolution that you have",
    "start": "787760",
    "end": "791120"
  },
  {
    "text": "should have full hd right",
    "start": "795920",
    "end": "799519"
  },
  {
    "text": "what which reservoir oh there's virtual hd right oh okay then it should work at full hd but okay",
    "start": "813440",
    "end": "820480"
  },
  {
    "text": "i'm going to keep it here should i should i switch or keep it now yeah yeah this is fine all right i'll",
    "start": "820480",
    "end": "826000"
  },
  {
    "text": "keep it in this it's a little smaller but for the sake of time let's do this",
    "start": "826000",
    "end": "833440"
  },
  {
    "text": "okay so um like i said we previously done lots of long haunted demos for like",
    "start": "833440",
    "end": "840880"
  },
  {
    "text": "intros so i figured uh i talked about some setups you want to have for your production clusters or in the enterprise",
    "start": "840880",
    "end": "847519"
  },
  {
    "text": "space um let's start by number one how do i do auto scaling what how would my cluster",
    "start": "847519",
    "end": "853600"
  },
  {
    "text": "set up look like i'm using the enchant for demonstration as a visualization tool here but all of this can be done with operators and",
    "start": "853600",
    "end": "860160"
  },
  {
    "text": "yamls and helm directly so let's have a look at how i set up my",
    "start": "860160",
    "end": "867920"
  },
  {
    "text": "lh demo cluster and",
    "start": "867920",
    "end": "874399"
  },
  {
    "text": "there's not enough space for my mouse",
    "start": "876560",
    "end": "880079"
  },
  {
    "text": "and we can see that i have like three notebooks general you want three note pools on your",
    "start": "881600",
    "end": "886880"
  },
  {
    "text": "uh non-bare metal clusters anytime you want to do auto scaling you want to have your control planes separated from your",
    "start": "886880",
    "end": "893120"
  },
  {
    "text": "worker nodes um we've seen that one uh generally people end up putting them together control playing worker notes",
    "start": "893120",
    "end": "899279"
  },
  {
    "text": "and then some things we saw on this like they scaled up the cluster and then they had 50",
    "start": "899279",
    "end": "904399"
  },
  {
    "text": "uh control plane nodes effectively which is a problem in itself um so you want to have three node pools",
    "start": "904399",
    "end": "911600"
  },
  {
    "text": "one for the control plane one i call the stable set which is basically the stable set is your minimum",
    "start": "911600",
    "end": "918480"
  },
  {
    "text": "resource availability set so anytime you guarantee a certain capacity",
    "start": "918480",
    "end": "925440"
  },
  {
    "text": "you can scale up the stable set but you cannot really scale it down because you need to be able to guarantee that for",
    "start": "925440",
    "end": "931279"
  },
  {
    "text": "the lifetime of the cluster uh therefore it's your minimum availability so that that's the prem cluster here in this",
    "start": "931279",
    "end": "936959"
  },
  {
    "text": "case um and lastly your transient set which is just the regular worker pool the",
    "start": "936959",
    "end": "942639"
  },
  {
    "text": "worker pool itself can be permanently auto scaled um you would want to have it set up so",
    "start": "942639",
    "end": "948560"
  },
  {
    "text": "that it can scale up down quickly depending on demand based on your metrics",
    "start": "948560",
    "end": "956320"
  },
  {
    "text": "in my case all the notes are the same use the same template no template but what you would want to have is for the",
    "start": "956320",
    "end": "962320"
  },
  {
    "text": "minimum resource set you have bigger notes with more cpu more storage so that you have less",
    "start": "962320",
    "end": "968399"
  },
  {
    "text": "change in that environment and for the transient set you can have lots of small",
    "start": "968399",
    "end": "973519"
  },
  {
    "text": "nodes because it's pretty cheap to recycle them um right so that's that now the other",
    "start": "973519",
    "end": "980240"
  },
  {
    "text": "question is what kind of options do i have on setting up how do you use longhorn to define where my data",
    "start": "980240",
    "end": "987519"
  },
  {
    "text": "actually gets stored and this is when you're in an enterprise environment you don't necessarily have",
    "start": "987519",
    "end": "993120"
  },
  {
    "text": "different nodes some have gpus let's say you have machine learning workflows uh some have",
    "start": "993120",
    "end": "998160"
  },
  {
    "text": "nvme some have like spinning disk and you don't want the slowest web server kind of thing uh using storage from your",
    "start": "998160",
    "end": "1005199"
  },
  {
    "text": "nvme meters for example on the node that has the gpu that would be like worst case scenario so to solve this",
    "start": "1005199",
    "end": "1013040"
  },
  {
    "text": "we provide a whole bunch of parameters in our storage classes that allow an",
    "start": "1013040",
    "end": "1018240"
  },
  {
    "text": "administrator to find uh let's have a look at the",
    "start": "1018240",
    "end": "1024240"
  },
  {
    "text": "it's too small",
    "start": "1024240",
    "end": "1026880"
  },
  {
    "text": "sorry the resolution is kind of bad better yeah",
    "start": "1030319",
    "end": "1036720"
  },
  {
    "text": "i can do it with a wrench or two it's too small",
    "start": "1036720",
    "end": "1042480"
  },
  {
    "text": "okay so um we have the concept of disk and node selector i'm gonna zoom in now",
    "start": "1042880",
    "end": "1050160"
  },
  {
    "text": "there right that's there so we have the concept of disk and node selector which allows us to tag our nodes as well as",
    "start": "1050160",
    "end": "1057039"
  },
  {
    "text": "our disks that you have configured in logon i'm going to give an example and go to the longhorn ui to visualize that",
    "start": "1057039",
    "end": "1062559"
  },
  {
    "text": "very simply what you as an administrator want to do is set up a collection of storage classes that define the",
    "start": "1062559",
    "end": "1068400"
  },
  {
    "text": "parameters of the workload types that you want to offer in your cluster to your developers or end users",
    "start": "1068400",
    "end": "1076880"
  },
  {
    "text": "in this case i just call the editor discollector which is fast so any volume that gets provisioned with the longhorn",
    "start": "1076880",
    "end": "1083120"
  },
  {
    "text": "nvme of storage class ends up getting scheduled they're",
    "start": "1083120",
    "end": "1089200"
  },
  {
    "text": "getting the replica scheduled on a disk that fits that selector criteria so this",
    "start": "1089200",
    "end": "1094880"
  },
  {
    "text": "this limit makes sure that if you have certain workloads databases are a good spot um that needs high io",
    "start": "1094880",
    "end": "1102720"
  },
  {
    "text": "you can ensure that the replicas end up on the appropriate disk um",
    "start": "1102720",
    "end": "1108960"
  },
  {
    "text": "yeah let me let me just show what that looks like sorry",
    "start": "1108960",
    "end": "1114000"
  },
  {
    "text": "the the resolution does that can you see that it's kind of it's kind of small now my apologies for",
    "start": "1114000",
    "end": "1120720"
  },
  {
    "text": "the technical difficulties",
    "start": "1120720",
    "end": "1124559"
  },
  {
    "text": "you can see i you can see i pre-tagged like the notes",
    "start": "1132320",
    "end": "1139120"
  },
  {
    "text": "here i i ended up taking my permanent notes which is my stable set notes as well as",
    "start": "1139120",
    "end": "1144400"
  },
  {
    "text": "an example of a gpu does not ends up with a gpu and for certain workarounds um",
    "start": "1144400",
    "end": "1150880"
  },
  {
    "text": "if you don't have affinity zone setup or zones and region setup you can also tag",
    "start": "1150880",
    "end": "1156559"
  },
  {
    "text": "individual nodes to ensure for right now for the current version until we have volume group support to",
    "start": "1156559",
    "end": "1163039"
  },
  {
    "text": "ensure that your volumes get scheduled let's say if you have an application replica that in itself has data",
    "start": "1163039",
    "end": "1169360"
  },
  {
    "text": "replication and you want to ensure that the application replicas replica gets scheduled so that you at least always",
    "start": "1169360",
    "end": "1175520"
  },
  {
    "text": "have two two application replicas available so that you can lose one of the application ribbon that doesn't make too much sense",
    "start": "1175520",
    "end": "1182320"
  },
  {
    "text": "but um once we have volume group support we can",
    "start": "1182320",
    "end": "1187360"
  },
  {
    "text": "we know that this one is part of a group of set of volumes and we can apply scheduling rules to the replicas as i",
    "start": "1187360",
    "end": "1193280"
  },
  {
    "text": "said but till then as a workaround you can tag individual nodes and ensure that you",
    "start": "1193280",
    "end": "1198320"
  },
  {
    "text": "have like three storage classes for each of the application replicas and they would then ensure that the rapid cars get",
    "start": "1198320",
    "end": "1203360"
  },
  {
    "text": "distributed evenly okay the second thing is",
    "start": "1203360",
    "end": "1211120"
  },
  {
    "text": "okay here's the most the second thing is you can add many this so on your stable set",
    "start": "1212159",
    "end": "1219200"
  },
  {
    "text": "it's perfectly fine to when you after evaluating your resource consumption you say yeah i'm not actually using too much",
    "start": "1219200",
    "end": "1226080"
  },
  {
    "text": "cpu or memory but i'm getting low on storage you can attach additional disks",
    "start": "1226080",
    "end": "1232000"
  },
  {
    "text": "via the cloud provider block storage and expose them as part of the longhorn set um",
    "start": "1232000",
    "end": "1237200"
  },
  {
    "text": "which allows you then to tag these appropriately well in this case this is",
    "start": "1237200",
    "end": "1242320"
  },
  {
    "text": "tagged as an nvme this so any replica that was provisioned with the previous storage class ends up on",
    "start": "1242320",
    "end": "1248000"
  },
  {
    "text": "one of the nvmedias while the default disk is just a regular disk so no tags",
    "start": "1248000",
    "end": "1253840"
  },
  {
    "text": "so no specific scheduling rules right that's that and",
    "start": "1253840",
    "end": "1260640"
  },
  {
    "text": "last but not least i want to talk a little bit about the upcoming spdk it's uh still in the works and",
    "start": "1260640",
    "end": "1268000"
  },
  {
    "text": "here's some quick this resolution is too small",
    "start": "1268000",
    "end": "1274840"
  },
  {
    "text": "um so i need to make it small like this yeah",
    "start": "1274840",
    "end": "1281039"
  },
  {
    "text": "okay so this is like a quick developer benchmark so uh take away grain of salt",
    "start": "1282240",
    "end": "1287440"
  },
  {
    "text": "it's not production ready yet but in general you see that the iops we're getting",
    "start": "1287440",
    "end": "1292799"
  },
  {
    "text": "are pretty close to the to the local disk this is including a file system right so this is a host mounted file",
    "start": "1292799",
    "end": "1299360"
  },
  {
    "text": "system versus uh an sdk uh provided longhand volume then mounted to a local path on the node",
    "start": "1299360",
    "end": "1308640"
  },
  {
    "text": "we have a little bit more latency so we go from 132",
    "start": "1308640",
    "end": "1314640"
  },
  {
    "text": "microseconds to 160 microseconds for the i o but again this is only for the local",
    "start": "1314640",
    "end": "1320400"
  },
  {
    "text": "replica once you add like remote replicas the latency will go up a little bit but you also due to the architecture",
    "start": "1320400",
    "end": "1327600"
  },
  {
    "text": "change that with the spk implementation we're going from uh one",
    "start": "1327600",
    "end": "1333520"
  },
  {
    "text": "cpu basically cpu users per process so previously each volume was this independent process we're now going more",
    "start": "1333520",
    "end": "1339840"
  },
  {
    "text": "into the you have one process for the whole note which allows it to scale with the amount",
    "start": "1339840",
    "end": "1346640"
  },
  {
    "text": "of cpu as well as amount of disk linearly which is a for large large",
    "start": "1346640",
    "end": "1352640"
  },
  {
    "text": "uh permanent storage set um like i demonstrated here is really beneficial",
    "start": "1352640",
    "end": "1358559"
  },
  {
    "text": "while for a hyper converged state it's also beneficial but uh less so because you have less uh resources per node",
    "start": "1358559",
    "end": "1366400"
  },
  {
    "text": "yeah let me probably elaborate on that so what you're seeing right now on the left side is in fact local paths which",
    "start": "1366400",
    "end": "1373520"
  },
  {
    "text": "basically your bell mental hard drive and i think it's backed by uh nvme and",
    "start": "1373520",
    "end": "1378799"
  },
  {
    "text": "on right side you see that um no these are still ssds just regularly so let's see okay on right side you see the",
    "start": "1378799",
    "end": "1384720"
  },
  {
    "text": "longhorn spdk that label that is like our currently in developer sbdk engine",
    "start": "1384720",
    "end": "1389760"
  },
  {
    "text": "which nowhere near finish just very very like big caveats there but it's one to show",
    "start": "1389760",
    "end": "1397200"
  },
  {
    "text": "off like what is the like potential we can get so as you can see that basically we have no difference within i",
    "start": "1397200",
    "end": "1404000"
  },
  {
    "text": "o like arrow per second and also the bandwidth is like basically no difference on the bandwidth size as",
    "start": "1404000",
    "end": "1410320"
  },
  {
    "text": "well and slightly like you see the percentage difference like on the latent side is big but",
    "start": "1410320",
    "end": "1417679"
  },
  {
    "text": "looking deeper you'll see that we basically only add about 20 microseconds latency on top of the native disk",
    "start": "1417679",
    "end": "1425279"
  },
  {
    "text": "which in fact is pretty fast and this is the new engine we are currently in development and based on sbdk which is a",
    "start": "1425279",
    "end": "1433520"
  },
  {
    "text": "storage open source storage framework developed by the intel yeah so this is the uh and also this is",
    "start": "1433520",
    "end": "1441039"
  },
  {
    "text": "a strictly local right now we do have our sbk implementation right now do you support replicas and start adding",
    "start": "1441039",
    "end": "1448240"
  },
  {
    "text": "support for the snapshot but uh still this is in a very early stage and we're still talking like working on",
    "start": "1448240",
    "end": "1454320"
  },
  {
    "text": "this but for the people looking for the performance yeah this is something i can show you",
    "start": "1454320",
    "end": "1461600"
  },
  {
    "text": "okay yeah definitely we have here the community's concern in regard to performance and we're working very hard",
    "start": "1461600",
    "end": "1466880"
  },
  {
    "text": "shout out to my colleague keith lucas who is driving the spdk initiative um",
    "start": "1466880",
    "end": "1472880"
  },
  {
    "text": "and as you can see from this quick def benchmark um we're yeah in comparison are doing pretty well this is just for",
    "start": "1472880",
    "end": "1479919"
  },
  {
    "text": "reference this is on a single cpu provided to spk on a single disk now you can imagine how this will",
    "start": "1479919",
    "end": "1486480"
  },
  {
    "text": "roughly scale once you had more superiors there's more disk usage um okay",
    "start": "1486480",
    "end": "1492640"
  },
  {
    "text": "hey wait i think we have five minutes right yeah i think we're just on time that's great okay all right any questions",
    "start": "1492640",
    "end": "1501320"
  },
  {
    "text": "what happens when you add a node does the existing replicas rebalance on the new devices or nodes okay",
    "start": "1506559",
    "end": "1513679"
  },
  {
    "text": "oh you yeah yeah yeah so uh currently if there are like a soft infinity rule enabled which is in",
    "start": "1513679",
    "end": "1520960"
  },
  {
    "text": "fact disabled by default and the replica well was in the same node we are going to my other balance to another note but",
    "start": "1520960",
    "end": "1528000"
  },
  {
    "text": "currently like based on the capacity it's not being automatically rebalanced and we'll like that's in fact one",
    "start": "1528000",
    "end": "1534080"
  },
  {
    "text": "request we heard from the community and we're taking that into consideration for the roadmap yeah we do it we did add",
    "start": "1534080",
    "end": "1541200"
  },
  {
    "text": "some outer balancing features uh they're not complete yet uh we have some least effort best offered uh but um yeah not a",
    "start": "1541200",
    "end": "1548720"
  },
  {
    "text": "100 uh change yet jenny what uh i like to have is like the",
    "start": "1548720",
    "end": "1554400"
  },
  {
    "text": "different affinity rules so you can set up zones as well for your your kubernetes nodes",
    "start": "1554400",
    "end": "1560240"
  },
  {
    "text": "which we will also respect as part of the affinity rules we have disk affinity as well as node affinity",
    "start": "1560240",
    "end": "1567039"
  },
  {
    "text": "so um yes",
    "start": "1567039",
    "end": "1571240"
  },
  {
    "text": "sorry i couldn't no no it's a it's uh not like a weight thing on by using affinity rules",
    "start": "1573200",
    "end": "1578960"
  },
  {
    "text": "uh no now it's basically just uh like n infinity across you can cross node or cross region which i mentioned like how",
    "start": "1578960",
    "end": "1585440"
  },
  {
    "text": "we can support gas and uh i think we have crossed this too but i don't think that's going to be very",
    "start": "1585440",
    "end": "1591520"
  },
  {
    "text": "commonly used yeah yeah so not no weight at this moment and one more thing regarding the replication it's a network",
    "start": "1591520",
    "end": "1597360"
  },
  {
    "text": "uh consumes the network you recommend a dedicated interface",
    "start": "1597360",
    "end": "1602559"
  },
  {
    "text": "for the replication protocol i don't know exactly how does it work oh uh so yes in the upcoming 1.3 i think",
    "start": "1602559",
    "end": "1609120"
  },
  {
    "text": "i got it right in the upcoming one that was 3d release uh we're adding the dedicated storage network support so you",
    "start": "1609120",
    "end": "1614960"
  },
  {
    "text": "can utilize motors to have your storage traffic flow independent of your application flow right that that yeah",
    "start": "1614960",
    "end": "1621360"
  },
  {
    "text": "that's the question if the data path will be the same for the replication yeah so definitely you have then split",
    "start": "1621360",
    "end": "1626960"
  },
  {
    "text": "then so let's say you have a much higher bandwidth for your storage than your applications or much higher for your applications than your storage um that",
    "start": "1626960",
    "end": "1633840"
  },
  {
    "text": "would provide that and one more question regarding upgrades i understand that the service is not",
    "start": "1633840",
    "end": "1639760"
  },
  {
    "text": "affected like it's still available but i i i guess the iops are still are",
    "start": "1639760",
    "end": "1645279"
  },
  {
    "text": "affected yes the io are not going to be disrupted when you do the upgrade and we call the live upgrade so uh",
    "start": "1645279",
    "end": "1652399"
  },
  {
    "text": "they're different kind like we have used to like require some uh break like when like detach the",
    "start": "1652399",
    "end": "1658480"
  },
  {
    "text": "warning when you do the upgrade but nowadays we're trying basically these things the one oh released here now in fact 0.8 released",
    "start": "1658480",
    "end": "1665200"
  },
  {
    "text": "here now like every version can be live upgrade and this is something we keep that looking at like to keep in the",
    "start": "1665200",
    "end": "1671039"
  },
  {
    "text": "future right so this we want to make sure there's no braking upgrade yeah because",
    "start": "1671039",
    "end": "1676080"
  },
  {
    "text": "from my experience we have some application of ios demanding and we when we are upgrading those applications fail",
    "start": "1676080",
    "end": "1681760"
  },
  {
    "text": "because we are losing uh performance during upgrades that's uh",
    "start": "1681760",
    "end": "1687120"
  },
  {
    "text": "if you have a network like very saturated like like for the previous like 1.1 version you might have this",
    "start": "1687120",
    "end": "1694240"
  },
  {
    "text": "situation i think after 1.2 certain version we have a lower the bandwidth",
    "start": "1694240",
    "end": "1700159"
  },
  {
    "text": "limit and mesh that you're able to help yes we also changed the",
    "start": "1700159",
    "end": "1705200"
  },
  {
    "text": "timeout handling mechanism on the io side so let's say um you previously had slower discs which",
    "start": "1705200",
    "end": "1711520"
  },
  {
    "text": "was one request we had previously uh we improved that a little bit it's still not officially supported since if you",
    "start": "1711520",
    "end": "1717039"
  },
  {
    "text": "want to really good performance like this you need to make dedicated optimizations for that but with the",
    "start": "1717039",
    "end": "1723039"
  },
  {
    "text": "changes in the newer versions um you should be able to run it uh on the slower disk or",
    "start": "1723039",
    "end": "1728320"
  },
  {
    "text": "we yeah i run one of my dev customers on a set of raspberry pi's with sd cards so um for testing that's sufficient of",
    "start": "1728320",
    "end": "1735120"
  },
  {
    "text": "course production i wouldn't i wouldn't run that there okay we've got an online question from",
    "start": "1735120",
    "end": "1740320"
  },
  {
    "text": "lupe how is arm support coming along i mean i must support it and in fact arm",
    "start": "1740320",
    "end": "1745760"
  },
  {
    "text": "support is contributed by a community member and we accept that and like accepted that pr and polish it",
    "start": "1745760",
    "end": "1752480"
  },
  {
    "text": "and now the m64 is officially supported on the lower yeah so i'm 64 supported um uh 32-bit is",
    "start": "1752480",
    "end": "1759840"
  },
  {
    "text": "not supported so ensure that if you're using raspberry pi instead of you install a 64-bit compatible operating",
    "start": "1759840",
    "end": "1765600"
  },
  {
    "text": "system i think raspbian doesn't have it yet or might just gotten the 64-bit version out",
    "start": "1765600",
    "end": "1771919"
  },
  {
    "text": "i'm not sure but ubuntu definitely works so yeah a question about the read-write",
    "start": "1771919",
    "end": "1778559"
  },
  {
    "text": "support so i see in the roadmap the aha is probably going to be supported into what's at 1.4 so i see it's experimental",
    "start": "1778559",
    "end": "1785760"
  },
  {
    "text": "right now is it going to be similar to that and you're just making it aha or",
    "start": "1785760",
    "end": "1791760"
  },
  {
    "text": "yeah what's going on there uh uh so right now the way we implement uh",
    "start": "1791760",
    "end": "1798080"
  },
  {
    "text": "every export is by having us we call them share manager but it's basically a provisioner that ensures",
    "start": "1798080",
    "end": "1804080"
  },
  {
    "text": "that the every old block device volume gets attached to a certain node and then we export nfs shares via",
    "start": "1804080",
    "end": "1811279"
  },
  {
    "text": "nfs ganesha on the application level out from that um the problem is for highly",
    "start": "1811279",
    "end": "1816799"
  },
  {
    "text": "availability systems you now need a mechanism that is either active passive active efficacy you can't do active",
    "start": "1816799",
    "end": "1822240"
  },
  {
    "text": "actors with an already blocked device but we can do something like active passive um right now you can use it it",
    "start": "1822240",
    "end": "1829919"
  },
  {
    "text": "is marked as experimental it's usable the only downside is that if the node where the nfs",
    "start": "1829919",
    "end": "1835279"
  },
  {
    "text": "server is on goes down uh we end up terminating your workloads um that's",
    "start": "1835279",
    "end": "1841279"
  },
  {
    "text": "depending on settings right depending on confusion we end up terminating your workloads which generally is a service interruption",
    "start": "1841279",
    "end": "1847279"
  },
  {
    "text": "um but due to the if you have them in a deployment or stateful set the replacement workouts will be spun up",
    "start": "1847279",
    "end": "1853919"
  },
  {
    "text": "and the replacement workers will uh attach to the new uh lvx chair manager so the interruption",
    "start": "1853919",
    "end": "1860960"
  },
  {
    "text": "of service is very small if you have an end up having an issue but therefore we classify that's not highly available yet",
    "start": "1860960",
    "end": "1867039"
  },
  {
    "text": "uh once we have an active passive setup um it would the",
    "start": "1867039",
    "end": "1872320"
  },
  {
    "text": "transition time would be much smaller and there would not be any downtime for the actual application",
    "start": "1872320",
    "end": "1877519"
  },
  {
    "text": "service there will be an io stall during the handover but that's handled on the kernel side so",
    "start": "1877519",
    "end": "1883120"
  },
  {
    "text": "we should be following there yeah yeah",
    "start": "1883120",
    "end": "1890320"
  },
  {
    "text": "yeah so if you can live with the short interruption of services in the case where you have no failure or volume",
    "start": "1890320",
    "end": "1896799"
  },
  {
    "text": "failure um then you can use it but it's yeah officially it's we don't have the higher availability yet that's why we",
    "start": "1896799",
    "end": "1902559"
  },
  {
    "text": "market as experimental all right thank you guys very much that's all the time we have for this",
    "start": "1902559",
    "end": "1907679"
  },
  {
    "text": "session big round of applause for the long run guys",
    "start": "1907679",
    "end": "1912440"
  }
]
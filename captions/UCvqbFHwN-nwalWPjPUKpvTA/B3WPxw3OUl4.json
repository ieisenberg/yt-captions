[
  {
    "start": "0",
    "end": "82000"
  },
  {
    "text": "okay yes so thank you for having me uh my name is Jamie pool um I'm the compute platform engineering",
    "start": "1800",
    "end": "7500"
  },
  {
    "text": "manager at G research and I'm here today to talk to you about Armada which is a application which",
    "start": "7500",
    "end": "13440"
  },
  {
    "text": "we've created at gr to enable massive scale run to completion batch jobs on kubernetes this is something which we're",
    "start": "13440",
    "end": "20760"
  },
  {
    "text": "currently using production running millions of jobs through a day across tens of thousands of nodes",
    "start": "20760",
    "end": "26820"
  },
  {
    "text": "I'm going to talk a little bit about the application itself the motivation for it",
    "start": "26820",
    "end": "32099"
  },
  {
    "text": "how we use it its architecture some lessons learned some challenges",
    "start": "32099",
    "end": "37559"
  },
  {
    "text": "we've had and also some successes along the way a little bit about the road map and then explain to you how we can use it",
    "start": "37559",
    "end": "44040"
  },
  {
    "text": "how you can use it first I'm going to quickly cover G research who we are and what we do",
    "start": "44040",
    "end": "49739"
  },
  {
    "text": "so G research is a fintech company based in London in England",
    "start": "49739",
    "end": "54840"
  },
  {
    "text": "it's our shiny new office in central London which has just opened we employ teams of quantitative",
    "start": "54840",
    "end": "60719"
  },
  {
    "text": "researchers to look for patterns in noisy real world data sets financial data ultimately to look for and create",
    "start": "60719",
    "end": "69020"
  },
  {
    "text": "algorithms that can be deployed as trading strategies that could be monetized as a company we've existed for about 20",
    "start": "69020",
    "end": "75780"
  },
  {
    "text": "years and we've we've grown quite a lot in that time um however",
    "start": "75780",
    "end": "81240"
  },
  {
    "text": "onto Armada so what is Armada Armada is a multi-kubernetes cluster",
    "start": "81240",
    "end": "87360"
  },
  {
    "start": "82000",
    "end": "207000"
  },
  {
    "text": "batch scheduler I mentioned that we're about 20 years old when we started as a company",
    "start": "87360",
    "end": "92880"
  },
  {
    "text": "everything back then was very windows and Net Framework based anyone working in fintech would have experienced that",
    "start": "92880",
    "end": "99720"
  },
  {
    "text": "um over the last five to six years especially with migrated heavily towards Linux because that's where all the",
    "start": "99720",
    "end": "105060"
  },
  {
    "text": "latest ML and AI action is and along with that we've migrated to containerization by default and",
    "start": "105060",
    "end": "111720"
  },
  {
    "text": "kubernetes became the de facto container orchestration platform in that time we had a lot of success running our",
    "start": "111720",
    "end": "118439"
  },
  {
    "text": "stateless services and other applications on kubernetes so we thought to ourselves it would be",
    "start": "118439",
    "end": "124740"
  },
  {
    "text": "pretty cool if we could also run all of our batch workloads there so in terms of what we do",
    "start": "124740",
    "end": "130619"
  },
  {
    "text": "the vast majority of our compute all on-prem is actually used for running batch jobs because typically our",
    "start": "130619",
    "end": "135959"
  },
  {
    "text": "researchers want to run some experiments run some software to crunch some numbers and then spit out an answer",
    "start": "135959",
    "end": "142920"
  },
  {
    "text": "so historically doing all this on Windows we're using HD Condor and we saw the pivot to Linux and containers as an",
    "start": "142920",
    "end": "148680"
  },
  {
    "text": "opportunity to work out if we could do this on kubernetes because we've had so much success with the services we figured if we could have",
    "start": "148680",
    "end": "154980"
  },
  {
    "text": "a common substrate for all of our compute to be kubernetes that will be really advantageous for all of the reasons which we've already heard about",
    "start": "154980",
    "end": "160620"
  },
  {
    "text": "today same reason everyone's sort of trying to do this I suppose um and that's really where our model was",
    "start": "160620",
    "end": "166080"
  },
  {
    "text": "born Armada was conceptually an application where we thought if we could add the missing features",
    "start": "166080",
    "end": "171540"
  },
  {
    "text": "on top of kubernetes of effectively queuing fair share and scaling then we",
    "start": "171540",
    "end": "177360"
  },
  {
    "text": "would get all the ecosystem benefits of running on kubernetes and have the just",
    "start": "177360",
    "end": "182400"
  },
  {
    "text": "the general benefit of having all of our compute on a common substrate we started having this conversation back",
    "start": "182400",
    "end": "187680"
  },
  {
    "text": "in 2019 I think it was in Barcelona kubecon um and there was other people who were",
    "start": "187680",
    "end": "193080"
  },
  {
    "text": "interested so we figured we'd open source the project from the start um and recently in fact it's been",
    "start": "193080",
    "end": "199260"
  },
  {
    "text": "accepted into the cncf sandbox so it's now the sandbox application which is pretty cool",
    "start": "199260",
    "end": "205760"
  },
  {
    "start": "207000",
    "end": "282000"
  },
  {
    "text": "okay so now I'm going to talk a little bit about how we actually use Armada and then I'm going to dive into the",
    "start": "208980",
    "end": "214620"
  },
  {
    "text": "architecture and what's inside that big middle box fundamentally what we have at gr is a",
    "start": "214620",
    "end": "220560"
  },
  {
    "text": "large number of users and applications who want to submit jobs and get some answers",
    "start": "220560",
    "end": "225900"
  },
  {
    "text": "The Big Box in the middle is Armada which I'm going to dive into and that contains tens of thousands of nodes many tens of",
    "start": "225900",
    "end": "232140"
  },
  {
    "text": "clusters I've got some stats in the bottom right you can read there and typically the workflow as I",
    "start": "232140",
    "end": "237720"
  },
  {
    "text": "described as a user has an image a container image or has either an existing one or just created a",
    "start": "237720",
    "end": "243780"
  },
  {
    "text": "new one submit some jobs to Armada they get scheduled images get pulled containers startup",
    "start": "243780",
    "end": "250799"
  },
  {
    "text": "they access lots and lots of data from Storage platforms or other application Services crunch some numbers",
    "start": "250799",
    "end": "257459"
  },
  {
    "text": "do some maths and then write out a result somewhere now this picture here is really one what",
    "start": "257459",
    "end": "263820"
  },
  {
    "text": "we would call a modern environment so many environments within G research let's say environment I guess I mean",
    "start": "263820",
    "end": "269100"
  },
  {
    "text": "something like development staging production within production we have multiple environments as well in",
    "start": "269100",
    "end": "274199"
  },
  {
    "text": "different data centers this is what one particular data center might look like",
    "start": "274199",
    "end": "279919"
  },
  {
    "start": "282000",
    "end": "365000"
  },
  {
    "text": "so there's some Core Concepts which is important to understand about the system these will be familiar to anyone who's",
    "start": "284160",
    "end": "290280"
  },
  {
    "text": "experienced an HPC probably all of you guys but I'll go through them anyway so we have a job in Armada sense this is",
    "start": "290280",
    "end": "298199"
  },
  {
    "text": "a group of related kubernetes resources but fundamentally mostly it's a pod spec and this is something which a user wants",
    "start": "298199",
    "end": "305100"
  },
  {
    "text": "to be created a job set is purely a group of related jobs that",
    "start": "305100",
    "end": "310740"
  },
  {
    "text": "you want to manage as a unit so submit together watch progress together and",
    "start": "310740",
    "end": "315900"
  },
  {
    "text": "cancel or you know whatever together and then a queue which is",
    "start": "315900",
    "end": "321120"
  },
  {
    "text": "a sort of a standard queue of jobs where cues can have a priority relative to",
    "start": "321120",
    "end": "327479"
  },
  {
    "text": "each other and also jobs within a queue can have a priority relative to themselves",
    "start": "327479",
    "end": "332820"
  },
  {
    "text": "and it's these two Dimensions that we mostly use to implement our fair share algorithm which is pretty similar to",
    "start": "332820",
    "end": "337919"
  },
  {
    "text": "what you'll find on condor we have a simple grpc API that users use",
    "start": "337919",
    "end": "343380"
  },
  {
    "text": "to talk to or applications and then uses ultimately subscribe to",
    "start": "343380",
    "end": "348840"
  },
  {
    "text": "events on these through the API to track progress of their jobs or job sets so they will see that a job is go from",
    "start": "348840",
    "end": "355979"
  },
  {
    "text": "queued to pending to running and then ultimately hopefully succeed or sometimes fail for whatever reason",
    "start": "355979",
    "end": "364820"
  },
  {
    "start": "365000",
    "end": "480000"
  },
  {
    "text": "so now I'm going to talk a bit about how users access it before getting into the actual nuts and bolts of how it works",
    "start": "367440",
    "end": "374160"
  },
  {
    "text": "so on the left here we've got a bit of yaml which is the simplest possible Armada job specification",
    "start": "374160",
    "end": "380880"
  },
  {
    "text": "fundamentally we've got a little bit of an odd metadata at the top around the queue the job set name the namespace you",
    "start": "380880",
    "end": "388020"
  },
  {
    "text": "want to run in in kubernetes and then underneath a pod spec now under here",
    "start": "388020",
    "end": "393300"
  },
  {
    "text": "this is just a raw kubernetes pod spec you can put anything that a pod supports in here could go into here",
    "start": "393300",
    "end": "399000"
  },
  {
    "text": "which means that anything that you can do with a pod in kubernetes you can do through Armada most of this is just passed straight",
    "start": "399000",
    "end": "404580"
  },
  {
    "text": "through but some certain fields are used for scheduling decisions such as things like node selectors tolerations things like",
    "start": "404580",
    "end": "411600"
  },
  {
    "text": "that we've then built a simple CLI which is called Armada CTL similar to how you",
    "start": "411600",
    "end": "418080"
  },
  {
    "text": "would use something like Cube CTL so this is meant for interactive human use really and this allows you to submit jobs or",
    "start": "418080",
    "end": "424860"
  },
  {
    "text": "sets of jobs and then do things like watch their progress and you get a simple bit of output",
    "start": "424860",
    "end": "430199"
  },
  {
    "text": "it's probably too small to read but it will it will move as you press after you press enter and you'll be able to see",
    "start": "430199",
    "end": "435419"
  },
  {
    "text": "transition state changes and then the bottom right here we've got a screenshot of our UI so we've built a",
    "start": "435419",
    "end": "441840"
  },
  {
    "text": "UI for the system which we call Lookout it's just a simple react UI this screenshot is actually of a prototype",
    "start": "441840",
    "end": "448500"
  },
  {
    "text": "for a new UI which we're going to be creating in the coming months the one we have at the moment is similar but a lot",
    "start": "448500",
    "end": "453539"
  },
  {
    "text": "more basic and we've want to put a lot of time into investing in this UI making it much easier for people to use the",
    "start": "453539",
    "end": "459360"
  },
  {
    "text": "system and reason about what's going on but this allows you to do all the things you'd expect from a user perspective to",
    "start": "459360",
    "end": "464819"
  },
  {
    "text": "see the status of jobs progress find out why they've failed find out why they're not scheduled yet and we also want to",
    "start": "464819",
    "end": "471360"
  },
  {
    "text": "flip it around to make it really useful for administrators of the platform as well to reason about how many nodes are in the system how much compute we have",
    "start": "471360",
    "end": "477240"
  },
  {
    "text": "and so forth so now I'll get into the actual",
    "start": "477240",
    "end": "482520"
  },
  {
    "start": "480000",
    "end": "680000"
  },
  {
    "text": "architecture of the system how it's been built so everything on this diagram anything",
    "start": "482520",
    "end": "487919"
  },
  {
    "text": "in a light blue box is a kubernetes cluster and anything in a light yellow box is a kubernetes namespace",
    "start": "487919",
    "end": "494759"
  },
  {
    "text": "so first I'm going to talk about the left hand side of this picture so this is what we will call the server",
    "start": "494759",
    "end": "499979"
  },
  {
    "text": "side of armada we have by convention it could be anything but we we always put things in a Hamada namespace",
    "start": "499979",
    "end": "506039"
  },
  {
    "text": "and here we have a couple of applications we have the API and the UI which are the applications which we've",
    "start": "506039",
    "end": "511560"
  },
  {
    "text": "built and then some other components which we've chosen to use to for the backing stores for our system",
    "start": "511560",
    "end": "517380"
  },
  {
    "text": "so we use a combination of Pulsar on redis for events and job specific jobs stored in queues we also make heavy use",
    "start": "517380",
    "end": "524159"
  },
  {
    "text": "of Prometheus for monitoring as you'd expect uh and then there's the slightly random elephant on the outside there for the",
    "start": "524159",
    "end": "529980"
  },
  {
    "text": "postgres database which we use for the system we're actually probably at a point of like Peak complexity at the moment I'd",
    "start": "529980",
    "end": "535440"
  },
  {
    "text": "say because we've been on a bit of a transition through the architecture so we're probably going to move away from redis and just use postgres but at the",
    "start": "535440",
    "end": "542760"
  },
  {
    "text": "moment we have a few of these components mixed around so this is all running on a single kubernetes cluster in this this case",
    "start": "542760",
    "end": "548580"
  },
  {
    "text": "I've put a note there as well we use flat car as our operating system but that's not particularly relevant",
    "start": "548580",
    "end": "554399"
  },
  {
    "text": "but if we just have the cluster on the left-hand side this wouldn't really do anything this just presents our API and UI it would allow users to submit jobs",
    "start": "554399",
    "end": "560700"
  },
  {
    "text": "and watch stuff that nothing would actually happen the Clusters on the right hand side where the actual action happens so these",
    "start": "560700",
    "end": "567120"
  },
  {
    "text": "are what we call our executive clusters so you'll notice there's multiple and I'll come to that in a second",
    "start": "567120",
    "end": "572220"
  },
  {
    "text": "if we just look at one of them what we basically have is the namespace here guermada and a simple component deployed",
    "start": "572220",
    "end": "578339"
  },
  {
    "text": "into it called the executor this component is the thing that's responsible for sitting there looking at",
    "start": "578339",
    "end": "583440"
  },
  {
    "text": "how much free resource there is in the cluster talking back to the server and saying hey I've got I've got this much",
    "start": "583440",
    "end": "588600"
  },
  {
    "text": "compute give me some jobs and there's anything queued it will lease those jobs and then spawn them in",
    "start": "588600",
    "end": "594779"
  },
  {
    "text": "the relevant namespaces I've actually labeled them as jobs here however they are just pure kubernetes pods so it ties",
    "start": "594779",
    "end": "601140"
  },
  {
    "text": "in quite neatly with all the other stuff we've been describing this morning and this afternoon um possibly in future as the job API",
    "start": "601140",
    "end": "607980"
  },
  {
    "text": "evolves we could imagine actually just using that but we just use plain pods because the furniture around the job API",
    "start": "607980",
    "end": "613440"
  },
  {
    "text": "at the moment is kind of redundant to us and then the executor's job is really just to sit there at least new lease new",
    "start": "613440",
    "end": "620940"
  },
  {
    "text": "jobs schedule pulse onto the cluster and then Trace their progress and Report status back to the executive back to the",
    "start": "620940",
    "end": "627720"
  },
  {
    "text": "server side which then users would experience through the UI or the API",
    "start": "627720",
    "end": "633300"
  },
  {
    "text": "now these clusters on the right hand side tend to be quite large so we have a large amount of on-prem compute here",
    "start": "633300",
    "end": "638700"
  },
  {
    "text": "what we've found is we want to be at a scale to all of our computers and use",
    "start": "638700",
    "end": "644279"
  },
  {
    "text": "all of them to run our jobs on and to be able to scale effectively indefinitely",
    "start": "644279",
    "end": "650820"
  },
  {
    "text": "now we know that we can scale at given kubernetes cluster to many thousands of nodes you look at what openai have done",
    "start": "650820",
    "end": "655860"
  },
  {
    "text": "fantastic work there to scale to seven and a half thousand nodes and Beyond but that's actually quite a lot of work to do that so what we decided to do was",
    "start": "655860",
    "end": "663360"
  },
  {
    "text": "devise a system whereby we didn't have to push kubernetes to its absolute limits and if we could just deploy",
    "start": "663360",
    "end": "669060"
  },
  {
    "text": "multiple of these clusters we could just scale horizontally that way effectively indefinitely so what we tend to do is",
    "start": "669060",
    "end": "674279"
  },
  {
    "text": "run these clusters up to about a thousand nodes at a time and then just have multiple of them",
    "start": "674279",
    "end": "681200"
  },
  {
    "start": "680000",
    "end": "743000"
  },
  {
    "text": "so now I'm going to dive into the actual anatomy of one of these executive clusters and the sorts of considerations and design we've made around these",
    "start": "681480",
    "end": "687360"
  },
  {
    "text": "because this is most important around how many jobs we can schedule so we have the sort of standard",
    "start": "687360",
    "end": "692459"
  },
  {
    "text": "kubernetes control plane which you would expect the head nodes running the regular kubernetes control plane",
    "start": "692459",
    "end": "698040"
  },
  {
    "text": "components API server controller manager so on we have three what we call system nodes these are to run cluster-wide",
    "start": "698040",
    "end": "704040"
  },
  {
    "text": "resources for things we decide in gr that we want to use such as cert manager dragonfly which will come to open policy",
    "start": "704040",
    "end": "711300"
  },
  {
    "text": "agent and other things and then we just have n of what we call batch nodes and these are the jobs these",
    "start": "711300",
    "end": "716820"
  },
  {
    "text": "are the nodes that we actually run the jobs on we want to minimize the amount of resources that our cluster acquires are",
    "start": "716820",
    "end": "723120"
  },
  {
    "text": "on these nodes so we can maximize the amount available for jobs so we take very close attention to the",
    "start": "723120",
    "end": "729120"
  },
  {
    "text": "demon set so we run on these things and the resources requested um and so forth on these nodes we run the",
    "start": "729120",
    "end": "734700"
  },
  {
    "text": "absolute bare minimum of things like the cniq proxy storage integration pods dragonflies as a caching layer and then",
    "start": "734700",
    "end": "741779"
  },
  {
    "text": "as many jobs as possible so we made some key choices along the way for scaling kubernetes itself in",
    "start": "741779",
    "end": "748200"
  },
  {
    "start": "743000",
    "end": "848000"
  },
  {
    "text": "this way so we have what we consider large clusters a thousand nodes but I know",
    "start": "748200",
    "end": "753240"
  },
  {
    "text": "it's possible to get bigger for these anyway we decided to use bare metal for all of our Estates including the master",
    "start": "753240",
    "end": "758700"
  },
  {
    "text": "nodes and system nodes we keep the xcd nodes virtual because through this this amount of architecture",
    "start": "758700",
    "end": "764220"
  },
  {
    "text": "we don't actually store a huge amount of data in that CD itself almost all of it metadata wise is stored inside the",
    "start": "764220",
    "end": "769920"
  },
  {
    "text": "Armada storage components however we've still scaled up the control plane components within",
    "start": "769920",
    "end": "775079"
  },
  {
    "text": "kubernetes and just made the SCD nodes as big as they needed to be did a lot of work around tuning Prometheus and the cni",
    "start": "775079",
    "end": "781740"
  },
  {
    "text": "but actually one thing we really found which I think is remarkable and worth noting is that we haven't had to do a",
    "start": "781740",
    "end": "787260"
  },
  {
    "text": "huge amount to kubernetes to make it work this well most of the interesting scaling work we found was actually in the dependencies so silly things like we",
    "start": "787260",
    "end": "794880"
  },
  {
    "text": "use terraform to build our clusters and the first time we went to a thousand nodes we actually found that all of a sudden maybe unsurprisingly our planned",
    "start": "794880",
    "end": "801120"
  },
  {
    "text": "and apply times went went to hell really terrible we did a small amount of refactoring there and actually found we could 10x theme performance the plan and",
    "start": "801120",
    "end": "808800"
  },
  {
    "text": "applied time in terraform just by rejecting the way we represent those resources dragonfly has been massively beneficial",
    "start": "808800",
    "end": "815220"
  },
  {
    "text": "for us so if you suddenly scale thousands of nodes you're going to need to pull lots of images",
    "start": "815220",
    "end": "820680"
  },
  {
    "text": "um that's a very quick way to destroy your container registry whatever it is or get locked out of Docker Hub say so",
    "start": "820680",
    "end": "826800"
  },
  {
    "text": "dragonfly is a tool which you can deploy an open source tool on top of kubernetes which is like a caching layer for Docker",
    "start": "826800",
    "end": "832380"
  },
  {
    "text": "images with its own peer-to-peer Network such if you have a thousand nodes all pulling a new image it goes through this",
    "start": "832380",
    "end": "838079"
  },
  {
    "text": "dragonfly component inside the cluster there's a single pull from the Upstream registry and then it's all distributed in the PSP Network across the nodes",
    "start": "838079",
    "end": "845519"
  },
  {
    "text": "and then a lot of work to scale off storage platforms on the security front we're a very",
    "start": "845519",
    "end": "851880"
  },
  {
    "start": "848000",
    "end": "911000"
  },
  {
    "text": "security conscious organization so this is a multi-tenanted environment we have users all sharing the same platform so",
    "start": "851880",
    "end": "858600"
  },
  {
    "text": "we need a lot of focus on security we don't want any user or administrator to be able to accidentally access anyone",
    "start": "858600",
    "end": "864420"
  },
  {
    "text": "else's data or on purpose so we've got the standard sort of security rules you'd expect around user workloads so",
    "start": "864420",
    "end": "871620"
  },
  {
    "text": "things like good are back in namespaces principle of least privilege and then",
    "start": "871620",
    "end": "878100"
  },
  {
    "text": "all the standard stuff around no root no privilege no host networking or",
    "start": "878100",
    "end": "884040"
  },
  {
    "text": "storage access no extra limits capabilities we've implemented most of this just",
    "start": "884040",
    "end": "890639"
  },
  {
    "text": "using either built-ins and kubernetes such as good rbac and then a couple of extra tools so open policy agent has",
    "start": "890639",
    "end": "896760"
  },
  {
    "text": "been really beneficial for us that's a great way of just as ensuring that these things are true and can't be uh can't be",
    "start": "896760",
    "end": "903060"
  },
  {
    "text": "violated and we also make heavy use at the moment of pod security policy although we know that's deprecated and we'll go away so we're going to replace",
    "start": "903060",
    "end": "909120"
  },
  {
    "text": "that soon enough so now I'm going to talk a little bit about some challenges that we've had",
    "start": "909120",
    "end": "914880"
  },
  {
    "start": "911000",
    "end": "1024000"
  },
  {
    "text": "along the way there's probably like four categories of things that we've found really difficult I think the first thing scaling to this",
    "start": "914880",
    "end": "922260"
  },
  {
    "text": "size just running kubernetes at this size um is very difficult operationally you have to be very good at managing",
    "start": "922260",
    "end": "927420"
  },
  {
    "text": "kubernetes and rolling out changes reliably um the biggest thing probably is performance and in fact not of the",
    "start": "927420",
    "end": "934079"
  },
  {
    "text": "system itself as I said but actually what you realize is when you suddenly are running back shelves at the scale",
    "start": "934079",
    "end": "939600"
  },
  {
    "text": "in your environment you've effectively created a giant DDOS machine and anything you point at you can if it",
    "start": "939600",
    "end": "945060"
  },
  {
    "text": "hasn't been scaled properly you can reliably destroy so we found that quite a lot with especially our storage clusters that when we scale to this size",
    "start": "945060",
    "end": "951660"
  },
  {
    "text": "possibly we didn't appropriately scale the storage and we've had situations where users have suddenly launched last large number of",
    "start": "951660",
    "end": "958380"
  },
  {
    "text": "jobs destroyed the performance of themselves and unfortunately other people who are also using the same shared resources so that's something",
    "start": "958380",
    "end": "964440"
  },
  {
    "text": "that is always a constant challenge we need to work out how to improve as much as possible",
    "start": "964440",
    "end": "970079"
  },
  {
    "text": "then the next two really are integration type problems where",
    "start": "970079",
    "end": "976380"
  },
  {
    "text": "along our particular Journey we've been doing all of this at the same time it's moving from Windows to Linux and I think",
    "start": "976380",
    "end": "981420"
  },
  {
    "text": "we've all definitely underestimated how much work that would actually be for everybody it's not as you can imagine just a case of doing some find and",
    "start": "981420",
    "end": "988139"
  },
  {
    "text": "replace for backslashes the forward slashes um we have we're slowly realizing quite how entrenched the windows behavior is",
    "start": "988139",
    "end": "994920"
  },
  {
    "text": "within our software and it's been a lot of work to help people move away from that silly things",
    "start": "994920",
    "end": "1000079"
  },
  {
    "text": "like using DFS as a happening for accessing storage and then the last thing really is the",
    "start": "1000079",
    "end": "1006320"
  },
  {
    "text": "side effect of all of these other challenges whereby because of all this stuff taking up our time we haven't found enough time to reinvest in the",
    "start": "1006320",
    "end": "1012500"
  },
  {
    "text": "tooling and make the experience of using the platform as good as it can be which can be a bit frustrating I feel like we're starting to turn the corner on",
    "start": "1012500",
    "end": "1018560"
  },
  {
    "text": "that now and putting some of these previous things to bed we can now focus on improving the tooling for our users as much as possible",
    "start": "1018560",
    "end": "1025540"
  },
  {
    "start": "1024000",
    "end": "1162000"
  },
  {
    "text": "um successes so we're one of these organizations that are always striving for continuous Improvement and I think",
    "start": "1026419",
    "end": "1032418"
  },
  {
    "text": "like a lot of us do this it can kind of make us focus on the negatives a lot of the time and we need to I think take the",
    "start": "1032419",
    "end": "1038600"
  },
  {
    "text": "time to stop and acknowledge successes and celebrate these things so for me for along this whole project",
    "start": "1038600",
    "end": "1044298"
  },
  {
    "text": "the things that have been really great are we've proven that kubernetes and Armada scale really well and don't seem",
    "start": "1044299",
    "end": "1050000"
  },
  {
    "text": "to be at any kind of limit when we started doing this I think people were queuing up at my desk to explain why kubernetes wasn't designed",
    "start": "1050000",
    "end": "1055700"
  },
  {
    "text": "to run batch jobs and couldn't ever possibly work and they're right it wasn't designed for it but we've proven that actually with not a huge amount of",
    "start": "1055700",
    "end": "1062000"
  },
  {
    "text": "effort it can be made to do these things we've had really good quality",
    "start": "1062000",
    "end": "1067039"
  },
  {
    "text": "distribution metrics that's been a big success for us so I'd definitely recommend doing that because you need to be able to reason about the platform and",
    "start": "1067039",
    "end": "1072799"
  },
  {
    "text": "see what's going on and then after that point a lot of the kubernetes wins really started to pay",
    "start": "1072799",
    "end": "1079220"
  },
  {
    "text": "off so because we're using kubernetes we get all these sort of ancillary benefits around making configuration changes",
    "start": "1079220",
    "end": "1084620"
  },
  {
    "text": "really easy we could just if we need to suddenly change something across all of our estate it's a couple of four",
    "start": "1084620",
    "end": "1089900"
  },
  {
    "text": "requests and running our automation pipelines and changes just go out which is fantastic",
    "start": "1089900",
    "end": "1095059"
  },
  {
    "text": "furthermore because we're on kubernetes we get all the integration for free with all the other tools that we might want to use so dragonfly again is a great",
    "start": "1095059",
    "end": "1101780"
  },
  {
    "text": "example of this we realized when scaling that we need to do something to protect our Upstream registry",
    "start": "1101780",
    "end": "1107360"
  },
  {
    "text": "if we weren't on kubernetes I don't know exactly what we would have done we'd probably either had to hope something already existed that did it for our",
    "start": "1107360",
    "end": "1113240"
  },
  {
    "text": "platform or build something ourselves whereas because we're running on kubernetes we just Google it and oh",
    "start": "1113240",
    "end": "1119179"
  },
  {
    "text": "there it is and you deploy it and it mostly works and then finally the modular cluster design of armada itself has been a",
    "start": "1119179",
    "end": "1125419"
  },
  {
    "text": "massive win for us so it's taken the stress out of applying configuration changes things like",
    "start": "1125419",
    "end": "1131660"
  },
  {
    "text": "kubernetes upgrades we can stage them obviously we test things in depth and staging but even when he gets production",
    "start": "1131660",
    "end": "1137179"
  },
  {
    "text": "as we all know with the best will in the world that's often where you find the problems for the first time",
    "start": "1137179",
    "end": "1142460"
  },
  {
    "text": "with this design we can apply we can choose certain clusters as Canary clusters and we can upgrade these first",
    "start": "1142460",
    "end": "1148100"
  },
  {
    "text": "sit back and observe and go oh actually everything is okay or oh crap something has gone wrong that we didn't spot and",
    "start": "1148100",
    "end": "1153140"
  },
  {
    "text": "then roll back or fix it and it's greatly preferable to lose one I don't know 120th of the calc Farm",
    "start": "1153140",
    "end": "1159860"
  },
  {
    "text": "as opposed to all of it so I'm going to briefly touch on the",
    "start": "1159860",
    "end": "1165799"
  },
  {
    "start": "1162000",
    "end": "1295000"
  },
  {
    "text": "road map here for 2023 um there's three categories of things on",
    "start": "1165799",
    "end": "1171740"
  },
  {
    "text": "here really there's a lot more going on within G research but this is the stuff",
    "start": "1171740",
    "end": "1177080"
  },
  {
    "text": "which is specific not specifically to GR in general to the platform itself",
    "start": "1177080",
    "end": "1182240"
  },
  {
    "text": "so firstly it's the observability piece so we want to put a lot of work into this UI so that people can better",
    "start": "1182240",
    "end": "1187820"
  },
  {
    "text": "understand what's going on and administrators can better understand what's going on we spend a lot of time answering user questions saying hey why",
    "start": "1187820",
    "end": "1193460"
  },
  {
    "text": "isn't my job running and we can work it all out through grafana and other things but it's much better if they can just have a UI that explains that yes it's",
    "start": "1193460",
    "end": "1200179"
  },
  {
    "text": "queued because you've already capped out on the amount of resource you're allowed on our compute or I don't know some",
    "start": "1200179",
    "end": "1206840"
  },
  {
    "text": "other reason possibly to ask for something which can't be scheduled at that time the second category of thing is around",
    "start": "1206840",
    "end": "1213320"
  },
  {
    "text": "smarter scheduling so we're enabling we it's already possible to do the things like basic preemption through Armada",
    "start": "1213320",
    "end": "1220820"
  },
  {
    "text": "um basic Gan scheduling all of these sorts of things we want to be able to do you can kind of prefix with basic what we want to be able to do is do all of",
    "start": "1220820",
    "end": "1227059"
  },
  {
    "text": "these things in a bit more of a smart and Native way so that it's possible for us to really easily offer these features",
    "start": "1227059",
    "end": "1233960"
  },
  {
    "text": "to people which are the the next big enabling things post the basics around",
    "start": "1233960",
    "end": "1239240"
  },
  {
    "text": "fair share and queuing and so forth and then the last thing which I put in",
    "start": "1239240",
    "end": "1245419"
  },
  {
    "text": "Q4 but actually I'm having a lot of conversations about just this week I want to try and bring in a lot is a bit more native kubernetes integration",
    "start": "1245419",
    "end": "1251780"
  },
  {
    "text": "you'll probably have seen from the design that in a way we've kind of been a bit sort of keeping kubernetes at arm's length when we first started",
    "start": "1251780",
    "end": "1258440"
  },
  {
    "text": "designing the system we were kind of pedging our bets because we weren't sure if we actually wanted to use kubernetes as the substrate for this",
    "start": "1258440",
    "end": "1265039"
  },
  {
    "text": "and how it would be nice if we could be a bit optional about this and maybe use Armada as a system on top of another",
    "start": "1265039",
    "end": "1270500"
  },
  {
    "text": "platform it's probably the case to be honest now that ship has sailed in kubernetes as well embedded as the standard platform",
    "start": "1270500",
    "end": "1276799"
  },
  {
    "text": "for running containers so I think we'd like to now make it a little bit more accessible for people through kubernetes",
    "start": "1276799",
    "end": "1283700"
  },
  {
    "text": "so it's just easier for people to reason about so things such as having either using a kubernetes API directly or",
    "start": "1283700",
    "end": "1289100"
  },
  {
    "text": "having an API that looks exactly like it maybe a couple of simple crds and so forth",
    "start": "1289100",
    "end": "1295658"
  },
  {
    "start": "1295000",
    "end": "1344000"
  },
  {
    "text": "so now just a slide on how you can use it so we've got um our own slack Channel since being sandboxed in the cncf slack",
    "start": "1297500",
    "end": "1304700"
  },
  {
    "text": "so please use that it's just hashtag Armada come in there ask questions lots of friendly people there",
    "start": "1304700",
    "end": "1311299"
  },
  {
    "text": "um we have our obviously our GitHub page because it's all open source the link is at the end of this presentation so",
    "start": "1311299",
    "end": "1317059"
  },
  {
    "text": "please take a look at that I guess we've got the of course Alex's",
    "start": "1317059",
    "end": "1322100"
  },
  {
    "text": "Group which was discussed just now exactly for this kind of product this amongst other things and I'm also going",
    "start": "1322100",
    "end": "1327140"
  },
  {
    "text": "to do a shout out for the cncf research User Group which me and Ricardo run um every every other Wednesday",
    "start": "1327140",
    "end": "1334159"
  },
  {
    "text": "um I don't remember the time now say it's 8 A.M as well PST isn't it so do come along to that where we talk",
    "start": "1334159",
    "end": "1340640"
  },
  {
    "text": "about things like this and others and that's everything I have",
    "start": "1340640",
    "end": "1348200"
  },
  {
    "start": "1344000",
    "end": "1849000"
  },
  {
    "text": "do we have any questions thank you",
    "start": "1348200",
    "end": "1353139"
  },
  {
    "text": "how this is different than the kubernetes Federation project like karmada or open cluster management",
    "start": "1365659",
    "end": "1371659"
  },
  {
    "text": "projects I didn't quite catch that I'm sorry so how this is different than the",
    "start": "1371659",
    "end": "1377600"
  },
  {
    "text": "kubernetes Federation project projects Federation thank you",
    "start": "1377600",
    "end": "1385299"
  },
  {
    "text": "so the question is how does this differ from Key",
    "start": "1385460",
    "end": "1389320"
  },
  {
    "text": "cubesolve I think that is a bit more generic in the sense that it was a way of federating all sorts of kubernetes",
    "start": "1392720",
    "end": "1398480"
  },
  {
    "text": "resources um we want to be able to in effect I suppose Federate jobs to multiple",
    "start": "1398480",
    "end": "1404960"
  },
  {
    "text": "clusters but very specifically those things and as a design Choice we've decided to keep the storage of the state",
    "start": "1404960",
    "end": "1411080"
  },
  {
    "text": "outside of kubernetes itself because there are limits to how much you can put in xcd and you can imagine as well if we",
    "start": "1411080",
    "end": "1418400"
  },
  {
    "text": "want if you want to destroy the system it's preferable to overload Armada itself and they'll have its own limits",
    "start": "1418400",
    "end": "1425000"
  },
  {
    "text": "but in such a way that you don't overwhelm the actual cluster that you're actually running on so you don't want to Brick the whole thing",
    "start": "1425000",
    "end": "1431419"
  },
  {
    "text": "um so I suppose that's how it's similar but different to Federation",
    "start": "1431419",
    "end": "1436179"
  },
  {
    "text": "at the moment we support a subset of things so it's pod specs I think we actually also include services and so",
    "start": "1439340",
    "end": "1444620"
  },
  {
    "text": "forth so that you can run distributed jobs um but yeah at the moment it's just really it's quite tightly bound to the",
    "start": "1444620",
    "end": "1450679"
  },
  {
    "text": "resources which we've found we've needed within our within our company",
    "start": "1450679",
    "end": "1457240"
  },
  {
    "text": "um if you would like to use any kubernetes ecosystem tools that allow you to run on top of kubernetes cargo",
    "start": "1458840",
    "end": "1464840"
  },
  {
    "text": "workflow spark operator coupon it will not work right you need to build",
    "start": "1464840",
    "end": "1470720"
  },
  {
    "text": "dedicated integration layer for for our mother for these tools at the moment yes that's one of the main reasons actually",
    "start": "1470720",
    "end": "1476960"
  },
  {
    "text": "for looking at moving a bit closer to the kubernetes API because then it would make integration with all these other tools much easier",
    "start": "1476960",
    "end": "1483260"
  },
  {
    "text": "um at the moment anything that talks to a model needs to understand this API so you could access it through those things",
    "start": "1483260",
    "end": "1488720"
  },
  {
    "text": "but you'd need to write some kind of layer to do that that transformation",
    "start": "1488720",
    "end": "1494380"
  },
  {
    "text": "more questions you're talking about users and different",
    "start": "1495620",
    "end": "1503419"
  },
  {
    "text": "uses on the system um how does that flow through from Armada into kubernetes",
    "start": "1503419",
    "end": "1511039"
  },
  {
    "text": "do you create service accounts or what what do you use in the in the back end so what we do in the back end is we tend",
    "start": "1511039",
    "end": "1518299"
  },
  {
    "text": "to have a one-to-one mapping between queues and namespaces so we have our own automation which we use to apply",
    "start": "1518299",
    "end": "1525220"
  },
  {
    "text": "definitions of both those things where we another thing which I think we should open source which is a effectively a",
    "start": "1525220",
    "end": "1532460"
  },
  {
    "text": "tool which says there's a bunch of definitions this is the Q Alice it's accessible by these users which are uses",
    "start": "1532460",
    "end": "1539480"
  },
  {
    "text": "that kubernetes understands uh it has these other you know priorities and other other things and that gets",
    "start": "1539480",
    "end": "1544640"
  },
  {
    "text": "translated into namespaces within kubernetes so then users themselves can Cube CTL and access their own namespaces",
    "start": "1544640",
    "end": "1551059"
  },
  {
    "text": "and their own jobs if they want to although we try and encourage everyone to use them official tooling to do that",
    "start": "1551059",
    "end": "1557000"
  },
  {
    "text": "so it all gets translated that way",
    "start": "1557000",
    "end": "1560320"
  },
  {
    "text": "I can ask one then because we discussed a lot about batch and other topics but here you mentioned a lot about",
    "start": "1565039",
    "end": "1571220"
  },
  {
    "text": "multi-cluster and I think in the initial definition of the batch working group it",
    "start": "1571220",
    "end": "1577340"
  },
  {
    "text": "was explicitly stated that multi-cluster wasn't something that would be focused",
    "start": "1577340",
    "end": "1582440"
  },
  {
    "text": "or or scheduling across clusters no",
    "start": "1582440",
    "end": "1588380"
  },
  {
    "text": "okay because yeah we're just talking about uh um like instantiated resources across",
    "start": "1588380",
    "end": "1595460"
  },
  {
    "text": "clusters accessing the jobs do you access through to your mother apis or can you actually talk directly to the",
    "start": "1595460",
    "end": "1601700"
  },
  {
    "text": "Clusters things like this so where do you see this this could fit in in",
    "start": "1601700",
    "end": "1607220"
  },
  {
    "text": "kubernetes and Cloud native this discussion because we we heard about the Federation projects yeah so how can we",
    "start": "1607220",
    "end": "1614360"
  },
  {
    "text": "push this forward guys it's it's a yeah so it's a really interesting problem um I think the multi-cluster thing the",
    "start": "1614360",
    "end": "1619580"
  },
  {
    "text": "approach we've taken is probably like the USP for our application it's the I haven't seen anything else which",
    "start": "1619580",
    "end": "1624980"
  },
  {
    "text": "supports a multi-cluster setup as well as this however it's something that everyone wants to do and that all of",
    "start": "1624980",
    "end": "1631100"
  },
  {
    "text": "these discussions it's really interesting listen to everyone have their own sort of solving this in their own way I kind of feel like we're in",
    "start": "1631100",
    "end": "1636559"
  },
  {
    "text": "this Cambrian explosion of people trying to run batch on kubernetes are all going to develop different ways of doing",
    "start": "1636559",
    "end": "1641840"
  },
  {
    "text": "things and eventually we're going to have to see some things some things win some things lose and I guess sort of",
    "start": "1641840",
    "end": "1648740"
  },
  {
    "text": "converge on the right ways of doing things I don't know what the answer is right now for multi-cluster but it feels",
    "start": "1648740",
    "end": "1654380"
  },
  {
    "text": "like something which should be a bit more somehow available through kubernetes you",
    "start": "1654380",
    "end": "1660200"
  },
  {
    "text": "know not not in the sort of federation kind of way but ultimately I think what we'd like to see is as many of these",
    "start": "1660200",
    "end": "1665600"
  },
  {
    "text": "sorts of capabilities that we've developed here being pushed into the platform so that we can then",
    "start": "1665600",
    "end": "1671120"
  },
  {
    "text": "of doing ourselves and use them and maybe eventually this all falls away I just I don't know but until that point we we need to solve our problems so this",
    "start": "1671120",
    "end": "1677419"
  },
  {
    "text": "is what we do so so we do have the multi-cluster seg right and they did",
    "start": "1677419",
    "end": "1682940"
  },
  {
    "text": "they have other like it's not only batch there's stateful workloads as well right like how do you move storage like how do",
    "start": "1682940",
    "end": "1689360"
  },
  {
    "text": "you migrate like you know volumes um what do you represent how do you",
    "start": "1689360",
    "end": "1694700"
  },
  {
    "text": "represent a workload yeah because a worker is not necessarily a part or even a job it's a collection of things",
    "start": "1694700",
    "end": "1701179"
  },
  {
    "text": "resources that you can instantiate and specific cluster Etc yeah I feel this is much bigger than batch or I mean batch",
    "start": "1701179",
    "end": "1708020"
  },
  {
    "text": "is one massive use case for it yeah but there are many other use cases for multi-cluster",
    "start": "1708020",
    "end": "1713440"
  },
  {
    "text": "yeah I my take on this and you'll probably talk about it in the panel discussion later is it's it's okay to",
    "start": "1713440",
    "end": "1720679"
  },
  {
    "text": "have different solutions for things and I think sometimes we try too hard to try and come up with one one ring to rule",
    "start": "1720679",
    "end": "1726200"
  },
  {
    "text": "them all and then fail because it's things end up just too generic and you suffer from this generic side concept",
    "start": "1726200",
    "end": "1733279"
  },
  {
    "text": "um ultimately we'll probably settle on I think a smaller number of patterns for running software whether it's Services",
    "start": "1733279",
    "end": "1739340"
  },
  {
    "text": "batch and a small-ish number of other things and if we have different ways of solving",
    "start": "1739340",
    "end": "1745100"
  },
  {
    "text": "multi-cluster for that smaller set of things that at least is common within those sets then it's probably fine I",
    "start": "1745100",
    "end": "1751159"
  },
  {
    "text": "think trying to be too Grand about it and have Federation for all or something might just be a bit too ambitious and",
    "start": "1751159",
    "end": "1757100"
  },
  {
    "text": "that's why you just spin your wheels forever it's probably why Federation didn't succeed indeed yeah that's that's",
    "start": "1757100",
    "end": "1762440"
  },
  {
    "text": "my view anyway",
    "start": "1762440",
    "end": "1765100"
  },
  {
    "text": "thanks uh it was a great talk can you talk a little bit I guess about the general question of how you've done",
    "start": "1770059",
    "end": "1775100"
  },
  {
    "text": "storage with this like you've got users running all their ml models how are they getting their training data in there how are you making it so that with",
    "start": "1775100",
    "end": "1781640"
  },
  {
    "text": "multi-tenancy especially seems like a really hard problem yeah sure So within uh our world we tend to use most of our",
    "start": "1781640",
    "end": "1789559"
  },
  {
    "text": "storage on shared storage platforms so we use things like isilon uh we're actually moving quite heavily to using",
    "start": "1789559",
    "end": "1795020"
  },
  {
    "text": "vast as a storage platform I sold out in some slides previously um we have a good multi-tenancy set up",
    "start": "1795020",
    "end": "1801500"
  },
  {
    "text": "on those platforms already where users or groups of users already have areas they can access equivalent or",
    "start": "1801500",
    "end": "1807380"
  },
  {
    "text": "think of it like a bucket I suppose in S3 which they're already perm to use through sort of convention I suppose we",
    "start": "1807380",
    "end": "1813200"
  },
  {
    "text": "allow users to access those resources through Armada through kubernetes so",
    "start": "1813200",
    "end": "1818480"
  },
  {
    "text": "it's easy for people to run a job and have a templated way of accessing their personal area or some shared area on on",
    "start": "1818480",
    "end": "1826159"
  },
  {
    "text": "icelon or vast to load their data and a lot of the performance work we've been going and looking at is how we actually",
    "start": "1826159",
    "end": "1831260"
  },
  {
    "text": "make that interaction as good as possible because you can really make people's lives a lot easier a lot better",
    "start": "1831260",
    "end": "1836899"
  },
  {
    "text": "or worse by making that integration work better or worse",
    "start": "1836899",
    "end": "1842059"
  },
  {
    "text": "cool more questions",
    "start": "1842059",
    "end": "1847299"
  },
  {
    "text": "well I'm hitting this gonna make you walk yeah while I'm walking there like why do you use postgres why don't you",
    "start": "1851659",
    "end": "1857299"
  },
  {
    "text": "put everything on the API server or like on a CD everything in the kubernetes API server",
    "start": "1857299",
    "end": "1863299"
  },
  {
    "text": "um why do you need an extra storage why do we need external storage yeah sure I guess that's one of the motivated for the architecture we",
    "start": "1863299",
    "end": "1869179"
  },
  {
    "text": "back of a napkin calculations when we first started doing this told us that the amount of data we need to store",
    "start": "1869179",
    "end": "1875120"
  },
  {
    "text": "because we have requirements to store millions of jobs and have a huge amount of throughput and churn through the",
    "start": "1875120",
    "end": "1880760"
  },
  {
    "text": "system is that putting all that in FCD would definitely break it if we didn't do anything and we'd have to tune it pretty",
    "start": "1880760",
    "end": "1886760"
  },
  {
    "text": "hard to even make it possible give an awful lot of storage and then we've got the other thing I've mentioned previously around failure domains I",
    "start": "1886760",
    "end": "1893360"
  },
  {
    "text": "guess where if you then break xcd you've actually completely broken the cluster that you're even running the platform on and",
    "start": "1893360",
    "end": "1899000"
  },
  {
    "text": "you then can't access it you know cut off the branch that you're sitting on kind of thing so that was the motivation",
    "start": "1899000",
    "end": "1904159"
  },
  {
    "text": "for that however if that could be solved and again that was a further simplification we can make I think a lot",
    "start": "1904159",
    "end": "1910760"
  },
  {
    "text": "of these parts of our design have been optimizations we've made along the way but I'm never too we're not too precious",
    "start": "1910760",
    "end": "1916760"
  },
  {
    "text": "to say we won't ever change something and if an optimization is no longer required then we should reevaluate that",
    "start": "1916760",
    "end": "1922220"
  },
  {
    "text": "and that's what we'll try and do yeah you talked a lot about the",
    "start": "1922220",
    "end": "1927980"
  },
  {
    "text": "infrastructure behind the system and it looks interesting in terms of like uh the scheduling",
    "start": "1927980",
    "end": "1933440"
  },
  {
    "text": "algorithms are you dealing with lots of very large jobs and placement of those",
    "start": "1933440",
    "end": "1938960"
  },
  {
    "text": "jobs and maybe with like fragmented placement of these these large scheduled",
    "start": "1938960",
    "end": "1944720"
  },
  {
    "text": "yeah that's a really good question so I actually skimmed over that a little bit I didn't have any written notes I",
    "start": "1944720",
    "end": "1950360"
  },
  {
    "text": "remembered I wanted to talk about it we have quite a large range of different types of jobs so we have everything from",
    "start": "1950360",
    "end": "1955580"
  },
  {
    "text": "jobs which run for some seconds up to possibly even some weeks um so we want to be we want to be as",
    "start": "1955580",
    "end": "1961399"
  },
  {
    "text": "clever as possible about how we schedule these things and then also we've got headaches around maintenance where if you suddenly got every node in your",
    "start": "1961399",
    "end": "1968120"
  },
  {
    "text": "cluster is running a job that runs for two weeks how on Earth do you patch that I think so at the moment we're in that",
    "start": "1968120",
    "end": "1973159"
  },
  {
    "text": "situation but we're working towards the world through improving uh our scheduling components so put things a",
    "start": "1973159",
    "end": "1979220"
  },
  {
    "text": "little bit smarter together and they'll point to Alvin Severinsen over there who's doing a lot of the work um to make that a little bit more clever",
    "start": "1979220",
    "end": "1987620"
  },
  {
    "text": "and ultimately we're trying to work to a world in gr anyway where all users workloads are completely preemptable and",
    "start": "1987620",
    "end": "1993679"
  },
  {
    "text": "then a lot of these sorts of problems are a little easier to deal with because you can be a little less precious about",
    "start": "1993679",
    "end": "1999500"
  },
  {
    "text": "making sure things are scheduled in the right places and so forth",
    "start": "1999500",
    "end": "2004860"
  },
  {
    "text": "I have time for one more question",
    "start": "2007419",
    "end": "2010860"
  },
  {
    "text": "no so what do you find like your users most comfortable with when up like trying to",
    "start": "2015940",
    "end": "2023559"
  },
  {
    "text": "observe their jobs is it using like explicitly looking at metrics or they",
    "start": "2023559",
    "end": "2028899"
  },
  {
    "text": "won't look at statuses or they want to use um Cube cattle or whatever like tool",
    "start": "2028899",
    "end": "2034440"
  },
  {
    "text": "what do you think uh yes what he uses most comfortable with um I think frustratingly for us they",
    "start": "2034440",
    "end": "2041140"
  },
  {
    "text": "always want a UI I find and that's because our users in particular are not",
    "start": "2041140",
    "end": "2046240"
  },
  {
    "text": "experts in kubernetes containers even Linux some of them these are their day",
    "start": "2046240",
    "end": "2052358"
  },
  {
    "text": "job is trying to do a metal or you know they're basic mathematicians",
    "start": "2052359",
    "end": "2058060"
  },
  {
    "text": "um so typically people want tools to use that are easy to understand and it's either uis that we build or meta",
    "start": "2058060",
    "end": "2064000"
  },
  {
    "text": "applications on top of a model which other bits of our engineering organization have produced but we have a",
    "start": "2064000",
    "end": "2069099"
  },
  {
    "text": "massive range so we have some users who are effectively power users who are perfectly happy running Cube CTL or Armada CTO or whatever and then other",
    "start": "2069099",
    "end": "2075760"
  },
  {
    "text": "people who just don't want to know and just want to use the UI so we kind of have to support everything which is one of the challenges",
    "start": "2075760",
    "end": "2082619"
  },
  {
    "text": "uh one last comment he took a picture but like how do you prove to your wife that you were in there so you should",
    "start": "2083980",
    "end": "2089919"
  },
  {
    "text": "have taken a selfie I should have done a selfie I would do that I'm being told to stop it's like if I can have a selfie with things told to stop in the",
    "start": "2089919",
    "end": "2096158"
  },
  {
    "text": "background as well I think that would be best wouldn't it is it gonna work right you can all tell me to go away",
    "start": "2096159",
    "end": "2102760"
  },
  {
    "text": "Bluetooth on yeah thank you all right thank you everyone",
    "start": "2102760",
    "end": "2108359"
  },
  {
    "text": "thank you we're we have a coffee break we'll be back in",
    "start": "2109060",
    "end": "2115320"
  },
  {
    "text": "all right 250.",
    "start": "2115359",
    "end": "2119078"
  }
]
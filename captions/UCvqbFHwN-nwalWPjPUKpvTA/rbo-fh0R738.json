[
  {
    "text": "hey thanks so much for coming everybody this is great this is a bigger room than",
    "start": "60",
    "end": "5100"
  },
  {
    "text": "I expected at least personally um we are going to talk about building resilient apps the easy way today and I",
    "start": "5100",
    "end": "12780"
  },
  {
    "text": "don't know if anyone actually read the abstract for this talk but we're trying to do a lot in 35 minutes so hopefully",
    "start": "12780",
    "end": "18119"
  },
  {
    "text": "we'll show you at least one or two of the things that we promised in the abstract",
    "start": "18119",
    "end": "23179"
  },
  {
    "text": "and our clicker works good to go yeah all right I'll go ahead and do a quick",
    "start": "24060",
    "end": "29640"
  },
  {
    "text": "introduction of myself my name is Kendall Rhoden I am a senior product manager at Microsoft if you've heard of",
    "start": "29640",
    "end": "35340"
  },
  {
    "text": "it I work on a platform called Azure container apps happy to be here cool thanks Kendall my name is Alice Gibbons",
    "start": "35340",
    "end": "41399"
  },
  {
    "text": "I'm a customer success engineer at dire grid and if you haven't heard of us yet maybe you should look us up",
    "start": "41399",
    "end": "47399"
  },
  {
    "text": "just kidding we do a lot of cool things with Dapper which is one of the things we'll be talking about today",
    "start": "47399",
    "end": "52440"
  },
  {
    "text": "okay so I'm going to kick it off here talking about some developer challenges I think this is one of these things that",
    "start": "52440",
    "end": "58980"
  },
  {
    "text": "we are all here at kubecon talking about distributed systems and some of the challenges we face as developers in nit",
    "start": "58980",
    "end": "65518"
  },
  {
    "text": "today I think every single person in this room would have you know different idea of",
    "start": "65519",
    "end": "71520"
  },
  {
    "text": "what this means to you every single person could say that they have a different challenge that they're or their their Dev team faces",
    "start": "71520",
    "end": "78479"
  },
  {
    "text": "you know some of the ones that we might see commonly are how do I encrypt my",
    "start": "78479",
    "end": "83880"
  },
  {
    "text": "traffic between my services how do I use distributed tracing to get",
    "start": "83880",
    "end": "89400"
  },
  {
    "text": "not only traces between my applications but also all the way through to my infrastructure",
    "start": "89400",
    "end": "94560"
  },
  {
    "text": "how do I do consistent retries on my apps you know if something fails if there's Network latency how do I ensure",
    "start": "94560",
    "end": "101040"
  },
  {
    "text": "that goes all the way through the back end call and doesn't just stop when you know there's Network latency",
    "start": "101040",
    "end": "106680"
  },
  {
    "text": "these are just a few of the things that was the reason behind the Dapper project",
    "start": "106680",
    "end": "113179"
  },
  {
    "text": "so what is jopper I a lot of you might know what Dapper is already I'm going to",
    "start": "113220",
    "end": "118799"
  },
  {
    "text": "give a quick introduction Dapper is a set of distributed systems apis and it",
    "start": "118799",
    "end": "124320"
  },
  {
    "text": "codifies microservices best practices it can be used today with any different application code and across any platform",
    "start": "124320",
    "end": "132720"
  },
  {
    "text": "it is a set of nine different building block apis each of them abstracting away",
    "start": "132720",
    "end": "138180"
  },
  {
    "text": "infrastructure and providing a way for developers to increase their productivity",
    "start": "138180",
    "end": "143520"
  },
  {
    "text": "um today we're going to be focusing on a subset of dapper apis we're going to be focusing on publish And subscribe",
    "start": "143520",
    "end": "150020"
  },
  {
    "text": "distributed lock and service to service invocation Dapper stands for the distributed",
    "start": "150020",
    "end": "156120"
  },
  {
    "text": "application runtime didn't mention that and it can be run on any different platform that you'd like today we'll be",
    "start": "156120",
    "end": "163140"
  },
  {
    "text": "using an implementation running on kubernetes because hey it's kubecon and that's where you know we're all here",
    "start": "163140",
    "end": "169319"
  },
  {
    "text": "and how does dapper do this it uses an idea called Dapper components",
    "start": "169319",
    "end": "174900"
  },
  {
    "text": "these are yaml manifests that essentially you take the connection information from your applications and",
    "start": "174900",
    "end": "182340"
  },
  {
    "text": "from your infrastructure and embed it into your applications so instead of having to import an SDK for something",
    "start": "182340",
    "end": "190019"
  },
  {
    "text": "like a state accessing a state store you actually can just call the Dapper API",
    "start": "190019",
    "end": "195260"
  },
  {
    "text": "and access the data that way there are over a hundred Dapper",
    "start": "195260",
    "end": "201180"
  },
  {
    "text": "components today and these are all open source online so definitely encourage you checking these out",
    "start": "201180",
    "end": "206940"
  },
  {
    "text": "and we also have the opportunity to create our own components with Dapper so these are just some of the contributions",
    "start": "206940",
    "end": "213000"
  },
  {
    "text": "from you know the huge open source community that have been contributed but there are a ton more out there across",
    "start": "213000",
    "end": "219480"
  },
  {
    "text": "all the main clouds and on-prem so I'm going to hand it over now to talk",
    "start": "219480",
    "end": "225599"
  },
  {
    "text": "to Kendall to talk to talk to specifically about service or service invocation and how it works with our",
    "start": "225599",
    "end": "231720"
  },
  {
    "text": "end-to-end solution all right awesome so I'm going to do a",
    "start": "231720",
    "end": "236879"
  },
  {
    "text": "quick overview of the architecture today that we're going to be walking through uh just so you have a little bit of context in terms of what we're trying to",
    "start": "236879",
    "end": "243480"
  },
  {
    "text": "accomplish and how Dapper is going to make it easier easier for us to get the solution up and running on kubernetes",
    "start": "243480",
    "end": "248940"
  },
  {
    "text": "so it's I'm going to get the clicker right I promise here we go all right it's all",
    "start": "248940",
    "end": "254040"
  },
  {
    "text": "going to start with a front-end application this front-end application is essentially going to contact a backend API directly via a service call",
    "start": "254040",
    "end": "261239"
  },
  {
    "text": "and pass an order payload pretty simple once we move on from here that order API",
    "start": "261239",
    "end": "267000"
  },
  {
    "text": "will receive that payload from the front end and will essentially publish it to a topic in this case we're using a Kafka",
    "start": "267000",
    "end": "273240"
  },
  {
    "text": "implementation for the message broker this could be swapped out with any number of back-end components that are available in supported via dapper",
    "start": "273240",
    "end": "280740"
  },
  {
    "text": "once the message is arrives on the top uh the topic it will basically be received by a subscriber and this",
    "start": "280740",
    "end": "287580"
  },
  {
    "text": "subscriber is called the archive service and basically it's objective it's to take new orders that have come in and",
    "start": "287580",
    "end": "293460"
  },
  {
    "text": "store them in a storage account once those are available in this Azure storage account essentially we're also",
    "start": "293460",
    "end": "299040"
  },
  {
    "text": "going to have a job that's running in the background on a schedule so every 15 seconds this job is essentially going to",
    "start": "299040",
    "end": "305100"
  },
  {
    "text": "pick up the new orders that have come in do some processing on those and store the output in a state store in this case",
    "start": "305100",
    "end": "311340"
  },
  {
    "text": "we're going to be updating loyalty points for people who are active users of our product",
    "start": "311340",
    "end": "316979"
  },
  {
    "text": "so now I want to dive in specifically to the service invocation aspect of this architecture the big thing here is that",
    "start": "316979",
    "end": "323880"
  },
  {
    "text": "we're using Dapper in order to get a lot of benefits when it comes to service invocation so let's take a look at how",
    "start": "323880",
    "end": "329460"
  },
  {
    "text": "Dapper actually interacts with and helps coordinate the services calls within my",
    "start": "329460",
    "end": "334680"
  },
  {
    "text": "kubernetes environment So within the front end application instead of calling directly to the backend service we're",
    "start": "334680",
    "end": "341520"
  },
  {
    "text": "going to call adapter sidecar so in kubernetes dopper does run as a sidecar in the Pod however you can deploy deploy",
    "start": "341520",
    "end": "348720"
  },
  {
    "text": "Dapper without containers and frankly without kubernetes so we just want to make it very clear that this is just one",
    "start": "348720",
    "end": "354360"
  },
  {
    "text": "way that Dapper can enable you via your kubernetes deployments now we talked about the Dapper apis they're available",
    "start": "354360",
    "end": "360539"
  },
  {
    "text": "in both HTTP and grpc so you can choose whatever makes sense for you once you",
    "start": "360539",
    "end": "366360"
  },
  {
    "text": "hit the Dapper sidecar that's running local to the front end pod we will then have Dapper communicate with the sidecar",
    "start": "366360",
    "end": "372240"
  },
  {
    "text": "for the backend service and the sidecars will always communicate secure by default grpc and you can also get mtls",
    "start": "372240",
    "end": "379740"
  },
  {
    "text": "here what's also exciting is that in addition to mtls we can actually use spiffy identities which",
    "start": "379740",
    "end": "386100"
  },
  {
    "text": "will allow us to set Access Control policies so for example we could restrict the front end from posting to",
    "start": "386100",
    "end": "391380"
  },
  {
    "text": "the back end and instead only allow it to do git operations this is just you know one of many examples in addition we",
    "start": "391380",
    "end": "397620"
  },
  {
    "text": "also see that we can enable distributed tracing not just amongst our services but all the way to the backing",
    "start": "397620",
    "end": "402840"
  },
  {
    "text": "infrastructure for our adapter components sound good makes sense awesome I'm Levin Dapper hope you guys",
    "start": "402840",
    "end": "408060"
  },
  {
    "text": "are too okay so moving on service invocation is great and a lot of customers do use Direct Services service",
    "start": "408060",
    "end": "414600"
  },
  {
    "text": "calls and somewhere in their architecture at some point but obviously when we're building distributed systems there's typically a need for us to have",
    "start": "414600",
    "end": "421259"
  },
  {
    "text": "some kind of communication mechanism that allows a little bit more independence of our services right we",
    "start": "421259",
    "end": "427319"
  },
  {
    "text": "want to decouple those via some kind of message broker or a venting system for example if we're using a competing",
    "start": "427319",
    "end": "432960"
  },
  {
    "text": "consumer pattern so that's where Dapper's Pub sub apis really come into play so once that order API has been",
    "start": "432960",
    "end": "440220"
  },
  {
    "text": "invoked from the front end it will publish publish a message via Dapper to whatever that backing message broker is",
    "start": "440220",
    "end": "446940"
  },
  {
    "text": "and Dapper provides us with a lot of cool capabilities including at least once delivery so you're definitely going",
    "start": "446940",
    "end": "452460"
  },
  {
    "text": "to get that out of the box and then what what's nice is that the Dapper side car for the receiving",
    "start": "452460",
    "end": "457979"
  },
  {
    "text": "service that's subscribing Dapper handles that subscription on our behalf and also make sure that the message gets",
    "start": "457979",
    "end": "464039"
  },
  {
    "text": "delivered to whatever the uh the method is on that back-end service that we want to invoke",
    "start": "464039",
    "end": "469319"
  },
  {
    "text": "all right awesome uh I think I covered this pretty well uh one thing to call out that I didn't",
    "start": "469319",
    "end": "475319"
  },
  {
    "text": "mention on the previous slide is that by default Dapper does use cloud events messaging format but you can disable",
    "start": "475319",
    "end": "481500"
  },
  {
    "text": "that for example if you're talking from one Dapper app to maybe a legacy app that has not been Dapper enabled and you",
    "start": "481500",
    "end": "488400"
  },
  {
    "text": "also can get distributed tracing across this experience not just the service invocation calls",
    "start": "488400",
    "end": "494280"
  },
  {
    "text": "all right has anybody heard this phrase at any point in their career in cloud computing anybody",
    "start": "494280",
    "end": "499560"
  },
  {
    "text": "failure is inevitable okay I remember I once uh like at the beginning of my career at Microsoft six years ago I",
    "start": "499560",
    "end": "506039"
  },
  {
    "text": "remember somebody gave a presentation where they said Azure never fails this was funny because I work at Microsoft",
    "start": "506039",
    "end": "511199"
  },
  {
    "text": "was like Azure never fails it was a bit of a sales pitch and the advice that this person was given is that's the",
    "start": "511199",
    "end": "517080"
  },
  {
    "text": "absolute opposite thing you want to say you want to say it is inevitable that all Cloud providers at some point could",
    "start": "517080",
    "end": "522180"
  },
  {
    "text": "potentially fail it is inevitable that some kind of call at some point will fail right a pod can go down a node can",
    "start": "522180",
    "end": "529019"
  },
  {
    "text": "go down net Network latency can get introduced you can have transient failure in your network calls so you",
    "start": "529019",
    "end": "535140"
  },
  {
    "text": "basically have to build your distributed applications knowing that faults is inevitable and knowing that failure is",
    "start": "535140",
    "end": "540540"
  },
  {
    "text": "inevitable so it's great that Doppler provides us this service invocation capability these Pub sub apis but what",
    "start": "540540",
    "end": "547500"
  },
  {
    "text": "happens when we run into one of these inevitable failures we have to have a way to recover from that and Dapper now",
    "start": "547500",
    "end": "554339"
  },
  {
    "text": "has a capability which enables you to do that and that's called Dapper resiliency so let's talk a little bit about how",
    "start": "554339",
    "end": "560760"
  },
  {
    "text": "this works in action for service and vacation and then what's great is I'm going to stop talking for a little bit",
    "start": "560760",
    "end": "566100"
  },
  {
    "text": "and we're going to dive straight into a demo and get rid of these slides sound good are you with me okay just checking okay I'm a validation",
    "start": "566100",
    "end": "573600"
  },
  {
    "text": "girl you need to know you're still here all right so we've got a front-end application let's say that this front end is not Dapper enabled so in this",
    "start": "573600",
    "end": "580200"
  },
  {
    "text": "case it's just a regular deployment running in kubernetes it's typically going to communicate to",
    "start": "580200",
    "end": "585480"
  },
  {
    "text": "some kind of backend API in our case it's going to be that customer order service API now because I'm not using",
    "start": "585480",
    "end": "591779"
  },
  {
    "text": "any kind of dapper here I'm just basically calling the backend service for my backend API so nothing nothing",
    "start": "591779",
    "end": "598260"
  },
  {
    "text": "crazy Happening Here No mtls being given nothing like that so let's say that this call is to fail",
    "start": "598260",
    "end": "603540"
  },
  {
    "text": "for whatever reason one of the many examples that I gave earlier that means that that request is likely going to",
    "start": "603540",
    "end": "609300"
  },
  {
    "text": "fail and return to the front end caller which is one not a great experience for end users and also ultimately uh you",
    "start": "609300",
    "end": "616500"
  },
  {
    "text": "know because the failure is likely transient it would be a lot better if we had some kind of retry capability which is this is not new new Concepts but it",
    "start": "616500",
    "end": "623339"
  },
  {
    "text": "is nice that you can do this without instrumenting your application code and across language is in a consistent way",
    "start": "623339",
    "end": "628620"
  },
  {
    "text": "and that's what Dapper provides so let's switch the scenario and we're going to have a Dapper side car running alongside",
    "start": "628620",
    "end": "634920"
  },
  {
    "text": "our order API so we've essentially dapperized it as we like to say our front-end API or excuse me our front",
    "start": "634920",
    "end": "641640"
  },
  {
    "text": "end caller will also now be Dapper enabled when I make the call this time instead",
    "start": "641640",
    "end": "647040"
  },
  {
    "text": "of actually just making the post to the service for the back end API I will call",
    "start": "647040",
    "end": "652079"
  },
  {
    "text": "the service invocation in point via Dapper so you can see here I'm calling the V1 invoke API I'm passing in the",
    "start": "652079",
    "end": "660060"
  },
  {
    "text": "name of the of the Dapper app ID that I'd like to Target which in this case is the order API and I'm also specifying",
    "start": "660060",
    "end": "666420"
  },
  {
    "text": "the method on which I'd like that app to be invoked you can see here I also have this small",
    "start": "666420",
    "end": "671579"
  },
  {
    "text": "yaml file called resiliency what's nice is I can apply a resiliency spec or policy that's loaded at runtime whenever",
    "start": "671579",
    "end": "678540"
  },
  {
    "text": "the Dapper or sidecar gets up and running so what that resiliency spec will do is say hey let's say that",
    "start": "678540",
    "end": "684060"
  },
  {
    "text": "there's a particular Behavior right a transient failure and I want to retry this a certain number of times well",
    "start": "684060",
    "end": "689519"
  },
  {
    "text": "what's nice is you can actually set that timeout policy in the resiliency spec so in this case I'm saying hey after 500",
    "start": "689519",
    "end": "695339"
  },
  {
    "text": "milliseconds I want Dapper to return an error that will then kick off my retry",
    "start": "695339",
    "end": "700440"
  },
  {
    "text": "policies that I've specified specified in the resiliency spec and in addition I can even have a circuit breaker policy",
    "start": "700440",
    "end": "706260"
  },
  {
    "text": "that I apply when the number of retries has failed uh you know a certain number of concurrent requests",
    "start": "706260",
    "end": "712500"
  },
  {
    "text": "so ultimately the goal would be I retry this and eventually it succeeds and that's what's returned to the front end",
    "start": "712500",
    "end": "718920"
  },
  {
    "text": "you all ready to see this in action okay okay cool before we do that the last thing I want",
    "start": "718920",
    "end": "724980"
  },
  {
    "text": "to call out is that in addition to resiliency policies for service invocation calls I can also accept",
    "start": "724980",
    "end": "730079"
  },
  {
    "text": "resiliency policies for all of the Dapper components pretty much so if you think about that that means I can have",
    "start": "730079",
    "end": "735240"
  },
  {
    "text": "Pub sub retry I can have subscription retry I can even have retries for actors retrieving secrets from a state store",
    "start": "735240",
    "end": "742380"
  },
  {
    "text": "reaching out to or excuse me from a Secret store or even retrieving state from a state store so that's just",
    "start": "742380",
    "end": "748079"
  },
  {
    "text": "something I wanted to highlight all right we did not record our demos as backup so everybody clap because this is",
    "start": "748079",
    "end": "754380"
  },
  {
    "text": "we're doing this live it's happened yes we love we love that okay here we go",
    "start": "754380",
    "end": "762140"
  },
  {
    "text": "all right can we still see yeah it looks good so here's where I'm going to start in",
    "start": "763139",
    "end": "768480"
  },
  {
    "text": "order to essentially inject the timeout that I need right in order to inject Network latency I'm",
    "start": "768480",
    "end": "775019"
  },
  {
    "text": "going to use something called Azure chaos Studio this is essentially just a wrapper around chaos mesh the open",
    "start": "775019",
    "end": "781019"
  },
  {
    "text": "source project and this is really critical because we obviously want to be able to test our applications and their",
    "start": "781019",
    "end": "786540"
  },
  {
    "text": "resiliency policies dependent on the type of failures that can happen so in our case specifically we're introducing",
    "start": "786540",
    "end": "792899"
  },
  {
    "text": "a delay and this delay will essentially kick off the timeout policy that we've set so I'm going to go ahead and start this",
    "start": "792899",
    "end": "798779"
  },
  {
    "text": "I should have started it before I did that Spiel that would have been good but you know we're okay so let's see if we",
    "start": "798779",
    "end": "804540"
  },
  {
    "text": "can get this started all right so it should get up and running here soon uh what I'm going to",
    "start": "804540",
    "end": "810600"
  },
  {
    "text": "do now is I'm going to switch over to my terminal we're going to close a few things out",
    "start": "810600",
    "end": "815639"
  },
  {
    "text": "and what we can see is that we have several pods that are already deployed to our AKs cluster obviously this could",
    "start": "815639",
    "end": "820980"
  },
  {
    "text": "be a cluster of your choosing but what I really want to call out is we're going to start with the non-dapper enabled",
    "start": "820980",
    "end": "826260"
  },
  {
    "text": "scenario so that's going to be my front end pod I can easily see the front end logs here and I'm going to use ddosify",
    "start": "826260",
    "end": "832320"
  },
  {
    "text": "which is basically just a command line tool to hit my front end and pass in 100",
    "start": "832320",
    "end": "837480"
  },
  {
    "text": "get requests which are going to generate 100 orders that are placed on or sent to",
    "start": "837480",
    "end": "842579"
  },
  {
    "text": "the order back in service so I'm going to do a quick ddosify thanks for your patience here",
    "start": "842579",
    "end": "849320"
  },
  {
    "text": "and then I'm going to do the IP address of the front end that is not dapperized okay so what we",
    "start": "850740",
    "end": "858300"
  },
  {
    "text": "should see is that we're sending some orders in and we're seeing the order the order is being received what we should",
    "start": "858300",
    "end": "863700"
  },
  {
    "text": "ultimately see is a bunch of 500s right so what essentially happened here is our Network",
    "start": "863700",
    "end": "869220"
  },
  {
    "text": "latency was injected and our front end is now receiving 500 errors because it never got the successful response that",
    "start": "869220",
    "end": "875760"
  },
  {
    "text": "it was that it was waiting for so we can see that's not an ideal scenario right I'm going to quickly show",
    "start": "875760",
    "end": "881699"
  },
  {
    "text": "you too what's neat um just you know for visualization purposes is that um oh this may not have actually been",
    "start": "881699",
    "end": "888300"
  },
  {
    "text": "running that's okay I was going to show you some live metrics that showed the 500s but I think you get the points the logs are good",
    "start": "888300",
    "end": "893820"
  },
  {
    "text": "so now what I'm going to do instead is we're going to flip over the scenario and focus more on the Dapper enabled um",
    "start": "893820",
    "end": "900600"
  },
  {
    "text": "pods so you can see here I have a front-end application called front end Dapper this is the exact same",
    "start": "900600",
    "end": "906120"
  },
  {
    "text": "application code nothing has been changed I want to make that very clear I have not instrumented the code with poly",
    "start": "906120",
    "end": "911519"
  },
  {
    "text": "I'm not using any kind of resiliency libraries or retry policies within my application code I'm just setting a",
    "start": "911519",
    "end": "917820"
  },
  {
    "text": "resiliency policy via Dapper so if you want to see what this looks like and I'm going to zoom in just to make sure",
    "start": "917820",
    "end": "923100"
  },
  {
    "text": "everybody can see you can see here I have a resiliency spec and I'm applying it to the Dapper",
    "start": "923100",
    "end": "928440"
  },
  {
    "text": "resiliency namespace where my um where my application workloads are running so I want to highlight a few different",
    "start": "928440",
    "end": "933660"
  },
  {
    "text": "sections here the first is the actual policy section so you can see here I can set policies around timeouts I can set",
    "start": "933660",
    "end": "940980"
  },
  {
    "text": "policies around circuit breakers and I can also set retries in general so the",
    "start": "940980",
    "end": "946260"
  },
  {
    "text": "timeout that I've set is 500 milliseconds this is what's going to trigger Dapper to tell my front end application hey the timeout's been met",
    "start": "946260",
    "end": "953160"
  },
  {
    "text": "an error has been returned once that timeout has been met once I apply the resiliency policy we'll see that I can",
    "start": "953160",
    "end": "959760"
  },
  {
    "text": "use one of many policies that are specified in this case the retry forever policy basically says I'm going to retry",
    "start": "959760",
    "end": "966360"
  },
  {
    "text": "the call Forever pretty clear and then the retry Max says that I'm going to do a Max retry of 100 times and once that's",
    "start": "966360",
    "end": "973199"
  },
  {
    "text": "been met I will stop retrying we can also set a circuit breaker and in this case what we're saying is once 20",
    "start": "973199",
    "end": "979260"
  },
  {
    "text": "consecutive requests have failed we're going to open the circuit breaker then we're going to wait 60 seconds and once",
    "start": "979260",
    "end": "984779"
  },
  {
    "text": "the circuit breaker becomes half open we can essentially let just a Max request of one order come through",
    "start": "984779",
    "end": "991500"
  },
  {
    "text": "what's neat is we can then specify targets and targets and Scopes are really used together so in this case our",
    "start": "991500",
    "end": "997800"
  },
  {
    "text": "front and Dapper app which you can see here hopefully our front end Dapper app will use a specific Target when talking",
    "start": "997800",
    "end": "1005120"
  },
  {
    "text": "to the customer order service so whenever the front and Dapper app is targeting the customer order service it",
    "start": "1005120",
    "end": "1012680"
  },
  {
    "text": "will use that General timeout policy and it will use that retry forever retry policy in terms of components we also",
    "start": "1012680",
    "end": "1019220"
  },
  {
    "text": "set up a retry policy for the publishing to the Kafka topic so when my customer order service",
    "start": "1019220",
    "end": "1025100"
  },
  {
    "text": "talks to the Target order queue which is our Kafka pod it's going to have an outline outbound uh it's going in the",
    "start": "1025100",
    "end": "1032178"
  },
  {
    "text": "outbound Direction and we'll use the following policies the general timeout policy the retry Max which basically",
    "start": "1032179",
    "end": "1038178"
  },
  {
    "text": "says it's only going to retry 100 times and then it's also going to use a circuit breaker which will open once the number of concurrent failures have",
    "start": "1038179",
    "end": "1044660"
  },
  {
    "text": "occurred of 20 here all right make sense all good all right so our KS test should",
    "start": "1044660",
    "end": "1051320"
  },
  {
    "text": "still be running which it is so I'm going to switch back over the resiliency policy is already running in our cluster",
    "start": "1051320",
    "end": "1056600"
  },
  {
    "text": "which is amazing and I'm going to now use the DDOS if I tool and I'm instead",
    "start": "1056600",
    "end": "1062120"
  },
  {
    "text": "going to Target the front end IP for the Dapper enabled service",
    "start": "1062120",
    "end": "1067640"
  },
  {
    "text": "and before I do that I do want to pull up the log so we can see what's happening in real time so on your left you're going to see the logs for the",
    "start": "1067640",
    "end": "1074840"
  },
  {
    "text": "Dapper workload or excuse me for the front end application pod and then the",
    "start": "1074840",
    "end": "1080780"
  },
  {
    "text": "back end or excuse me on the right side you're going to see the Dapper d-log so this is the Dapper sidecar we're going",
    "start": "1080780",
    "end": "1086299"
  },
  {
    "text": "to go ahead and turn wrap on okay so here we go what we should see which you can",
    "start": "1086299",
    "end": "1092660"
  },
  {
    "text": "hopefully see is that on the left side we see the orders are getting sent but we don't see any 500s right because",
    "start": "1092660",
    "end": "1098660"
  },
  {
    "text": "they're never getting returned to the front end instead what's happening is that Dapper's sidecar is going through that retry forever policy so the front",
    "start": "1098660",
    "end": "1106100"
  },
  {
    "text": "end user will never see this in an Ideal World if we set up the Jitter and all that stuff we'd eventually see the the call succeed in this case it can't",
    "start": "1106100",
    "end": "1112880"
  },
  {
    "text": "because we're applying this network Chaos on every single call the last thing that I want to show",
    "start": "1112880",
    "end": "1118280"
  },
  {
    "text": "before I hand it over to Alice is that we also set that retry policy on",
    "start": "1118280",
    "end": "1123380"
  },
  {
    "text": "the um the publisher as well so if you take a look at our sorry got a lot going",
    "start": "1123380",
    "end": "1129140"
  },
  {
    "text": "on here bring this down maybe you can see a little better",
    "start": "1129140",
    "end": "1134780"
  },
  {
    "text": "so if we take a look at the customer order service if you remember it had a target for that Kafka pod so when we're",
    "start": "1134780",
    "end": "1139820"
  },
  {
    "text": "publishing orders and there's a certain timeout it should kick in that retry policy and eventually the circuit",
    "start": "1139820",
    "end": "1144919"
  },
  {
    "text": "breaker so we're going to take a look at the customer order service and we can see here",
    "start": "1144919",
    "end": "1150200"
  },
  {
    "text": "that we're attempting posts and we're getting back 500s and I'm going to stop this from",
    "start": "1150200",
    "end": "1155600"
  },
  {
    "text": "Auto scrolling so we can see so you see that the application code is getting a 500 saying we are not able to",
    "start": "1155600",
    "end": "1161780"
  },
  {
    "text": "successfully publish this order and when we look at the order service Dapper D logs we should see that the Dapper API",
    "start": "1161780",
    "end": "1167960"
  },
  {
    "text": "is being called and that it's going through the circuit breaker process at this point so the",
    "start": "1167960",
    "end": "1173660"
  },
  {
    "text": "circuit breaker has now been opened and now it's not letting any of those calls through all right awesome well for the sake of",
    "start": "1173660",
    "end": "1180740"
  },
  {
    "text": "time I'm going to pass it over to Alice Alice had you already switched this over so while she's doing that I want to talk",
    "start": "1180740",
    "end": "1185900"
  },
  {
    "text": "a little bit about what Dallas what Alice is going to be covering in the next segment so we've talked about how",
    "start": "1185900",
    "end": "1191600"
  },
  {
    "text": "we can make our applications more resilient without changing our application code Alice is going to go into another important and critical",
    "start": "1191600",
    "end": "1197600"
  },
  {
    "text": "aspect of having reliable applications and that's going to be enabled through the distributed lock API that was made",
    "start": "1197600",
    "end": "1203419"
  },
  {
    "text": "available in Dapper 1.8 I always take it away is this song this is on you also",
    "start": "1203419",
    "end": "1208460"
  },
  {
    "text": "want to switch it to the podium I'm okay okay that's good all right cool I know and as Kendall mentioned right we're",
    "start": "1208460",
    "end": "1214100"
  },
  {
    "text": "showing a lot here so I want to make sure everyone's still with us we're still trying to do a lot for resilient applications all right and this is just",
    "start": "1214100",
    "end": "1220460"
  },
  {
    "text": "one more step in that so on on up here on the screen you can kind of see our",
    "start": "1220460",
    "end": "1225500"
  },
  {
    "text": "architecture and right now we've made it through the back end we've done some distributed calls and they are all",
    "start": "1225500",
    "end": "1231020"
  },
  {
    "text": "resilient as Kendall showed what we want to do now is we have a loyalty job and the job of this service is essentially",
    "start": "1231020",
    "end": "1237679"
  },
  {
    "text": "to pick up all of the orders that have been processed and add the loyalty points for each customer this is",
    "start": "1237679",
    "end": "1244100"
  },
  {
    "text": "important right we want to we put our customers first so we want those loyalty points to be right and we have uh",
    "start": "1244100",
    "end": "1249679"
  },
  {
    "text": "decided to use the distributed lock API in Dapper to ensure that strong consistency on the database because we",
    "start": "1249679",
    "end": "1255919"
  },
  {
    "text": "have multiple replicas of the Loyalty job running and this if there was no lock on some of this data you might have",
    "start": "1255919",
    "end": "1262100"
  },
  {
    "text": "overwrites and times when you know one of the instances would clobber the other instance when trying to write to the",
    "start": "1262100",
    "end": "1267200"
  },
  {
    "text": "database so that's what we're about to show today and I'm just going to walk you through an example",
    "start": "1267200",
    "end": "1274059"
  },
  {
    "text": "so you can see here that we are like using the distributed lock API in Dapper and what exactly does this give us right",
    "start": "1274580",
    "end": "1281660"
  },
  {
    "text": "the purpose of a lock is to ensure that among you know several different application instances you are only going",
    "start": "1281660",
    "end": "1287360"
  },
  {
    "text": "to have one application instance at a time accessing that data and updating it",
    "start": "1287360",
    "end": "1292460"
  },
  {
    "text": "or doing a put on whatever the data might be in this case we have again the Loyalty job and we are deciding to",
    "start": "1292460",
    "end": "1298580"
  },
  {
    "text": "update that those loyalty points there's two main reasons why you'd probably use a lock one would be probably for",
    "start": "1298580",
    "end": "1304400"
  },
  {
    "text": "efficiency and the other one for correctness we're focusing on the correctness scenario today because we want that strong consistency within our",
    "start": "1304400",
    "end": "1311120"
  },
  {
    "text": "database um so this is a very powerful component that allows you to build a ton of",
    "start": "1311120",
    "end": "1317419"
  },
  {
    "text": "different features on top of uh you know the Dapper apis anything like leader election scenarios or you know whatever",
    "start": "1317419",
    "end": "1324500"
  },
  {
    "text": "your other developers might come up with so on the on the screen now you can see",
    "start": "1324500",
    "end": "1330440"
  },
  {
    "text": "that we have those two replicas of the Loyalty job um and since Dapper is a concurrent lock",
    "start": "1330440",
    "end": "1336380"
  },
  {
    "text": "you're going to have the first replica that gets to that lock is going to gain the lock on the app on the state and",
    "start": "1336380",
    "end": "1342500"
  },
  {
    "text": "then the second one when it tries to come in and update that order will not actually be able to",
    "start": "1342500",
    "end": "1348320"
  },
  {
    "text": "um we are running again two replicas of this app and you can see it's using the redis implementation of the Dapper lock",
    "start": "1348320",
    "end": "1355580"
  },
  {
    "text": "API um and the next one here you can see that the",
    "start": "1355580",
    "end": "1361760"
  },
  {
    "text": "once the lock is complete or once the lock has finished the same replica can",
    "start": "1361760",
    "end": "1367460"
  },
  {
    "text": "actually release the lock and then so other replicas of the Loyalty service or the Loyalty job can come in and do the",
    "start": "1367460",
    "end": "1373640"
  },
  {
    "text": "work I should also mention that Dapper is a lease based lock and so it does have a",
    "start": "1373640",
    "end": "1379039"
  },
  {
    "text": "Timeout on it or a time-based system where after 60 seconds you know one replica will release that lock so other",
    "start": "1379039",
    "end": "1385159"
  },
  {
    "text": "replicas can come in and do the work this also helps prevent failure because if you run into an exception in that",
    "start": "1385159",
    "end": "1391340"
  },
  {
    "text": "first replica that has the lock you're always going to release it after 60 seconds",
    "start": "1391340",
    "end": "1397100"
  },
  {
    "text": "and one more thing I should call out about distributed lock is that if you had two different applications and",
    "start": "1397100",
    "end": "1402740"
  },
  {
    "text": "they're both accessing the same data but you can access them concurrently so from two different apps Dapper is going to",
    "start": "1402740",
    "end": "1408740"
  },
  {
    "text": "allow you to access those at the same time so both different applications can take a lock on that data and maybe",
    "start": "1408740",
    "end": "1415340"
  },
  {
    "text": "they're updating different pieces of it or you know your system allows for both instances to update that data at the",
    "start": "1415340",
    "end": "1421640"
  },
  {
    "text": "same time okay so let's see this in action um and as Kendall mentioned okay down",
    "start": "1421640",
    "end": "1427520"
  },
  {
    "text": "there yeah okay as Kendall mentioned you know we are doing these live so another round of applause for Kendall's down on",
    "start": "1427520",
    "end": "1433760"
  },
  {
    "text": "Prime yeah go all right so I'm switching over to",
    "start": "1433760",
    "end": "1438980"
  },
  {
    "text": "canines here as well and this is you know the screen looks a lot like Kendall's did this is the same cluster",
    "start": "1438980",
    "end": "1444020"
  },
  {
    "text": "surprise surprise and the same applications um and you can see on the left here",
    "start": "1444020",
    "end": "1450760"
  },
  {
    "text": "we are I'm just gonna make this slightly bigger",
    "start": "1450760",
    "end": "1455799"
  },
  {
    "text": "um you can see I have multiple instances of this customer loyalty job running and this is that loyalty job I was talking",
    "start": "1457340",
    "end": "1463039"
  },
  {
    "text": "about right this is the one that's updating those loyalty points we want to make sure are really consistently right for our customers so we have the",
    "start": "1463039",
    "end": "1469760"
  },
  {
    "text": "customer loyalty job two instances of that and then we have this customer loyalty job no lock so as you can",
    "start": "1469760",
    "end": "1475460"
  },
  {
    "text": "imagine the the one with no lock does not use the Dapper distributed lock API and it is exactly the same code besides",
    "start": "1475460",
    "end": "1483080"
  },
  {
    "text": "that fact so again we're running very similar to the demo previously in terms of the same code deployed multiple times",
    "start": "1483080",
    "end": "1489440"
  },
  {
    "text": "and we're going to do a load test so let's see what that looks like so I'm going to run exactly the same load test",
    "start": "1489440",
    "end": "1495740"
  },
  {
    "text": "that Kendall did and this is using that front end IP for our dapperized app and",
    "start": "1495740",
    "end": "1502159"
  },
  {
    "text": "this is going to run approximately or about 100 orders in 10 seconds each with",
    "start": "1502159",
    "end": "1507200"
  },
  {
    "text": "10 different customer order IDs so let's run this guy and see what happens",
    "start": "1507200",
    "end": "1513200"
  },
  {
    "text": "all right successful and first let's take a look at the scenario when there's no lock okay so I have I'm going to come",
    "start": "1513200",
    "end": "1520760"
  },
  {
    "text": "into the lock pod here and this is going to be attempting to process some of these orders",
    "start": "1520760",
    "end": "1526340"
  },
  {
    "text": "which is great I'm going to come into the other version on the side here",
    "start": "1526340",
    "end": "1532240"
  },
  {
    "text": "lots of orders great great customers okay and you can see I have you know this is my no lock code and what it's",
    "start": "1540020",
    "end": "1547039"
  },
  {
    "text": "doing in both cases it's going to actually be processing these orders simultaneously in a lot of cases right",
    "start": "1547039",
    "end": "1552260"
  },
  {
    "text": "so there is no mechanism that's telling uh you know the app hey don't be",
    "start": "1552260",
    "end": "1557480"
  },
  {
    "text": "accessing the same code at the same time so a lot of these orders will be exactly the same on the left pod and on the",
    "start": "1557480",
    "end": "1563840"
  },
  {
    "text": "right pod so you can see actually on some of these time stamps they do actually match up from the goods so you",
    "start": "1563840",
    "end": "1570020"
  },
  {
    "text": "know we're updating the Loyalty customer id9 we're updating nine on the right here so again this is just the scenario",
    "start": "1570020",
    "end": "1576559"
  },
  {
    "text": "where the lock is not being used and we have multiple instances updating the uh",
    "start": "1576559",
    "end": "1581600"
  },
  {
    "text": "loyalty points and then saving them to a database okay cool now let's check with the",
    "start": "1581600",
    "end": "1587960"
  },
  {
    "text": "version that has a lock because that's the more interesting one right and so I'm going to come up here",
    "start": "1587960",
    "end": "1593720"
  },
  {
    "text": "and come in there",
    "start": "1593720",
    "end": "1596740"
  },
  {
    "text": "and this again as I mentioned earlier so this loyalty job is checking every 15 seconds to make sure that there's no",
    "start": "1600559",
    "end": "1606320"
  },
  {
    "text": "orders left to be processed right it's looking in this case within Azure blob storage and checking to see hey you know",
    "start": "1606320",
    "end": "1611960"
  },
  {
    "text": "are there orders for me to process what's going on so let's run another load test see what happens",
    "start": "1611960",
    "end": "1617960"
  },
  {
    "text": "okay we see some orders right there you go things are happening",
    "start": "1617960",
    "end": "1623000"
  },
  {
    "text": "okay so what we have on the left hand side here is we have um again the multiple replicas of the",
    "start": "1623000",
    "end": "1629600"
  },
  {
    "text": "same application so I have replica one on the left replica two on the right and you're going to see some lock failures",
    "start": "1629600",
    "end": "1635600"
  },
  {
    "text": "and this is good this is what we want to see so I'm attempting to process this one order ID on the right here or on the",
    "start": "1635600",
    "end": "1641779"
  },
  {
    "text": "left and it is not being processed so this one successfully locked it and then",
    "start": "1641779",
    "end": "1647659"
  },
  {
    "text": "you can see on the right hand side that it wasn't actually locked so this had failed to lock order so for each one of",
    "start": "1647659",
    "end": "1653720"
  },
  {
    "text": "these you're going to see that the order on the left hand side would be processed and the order on the right would not be",
    "start": "1653720",
    "end": "1659900"
  },
  {
    "text": "or vice versa right so one pod is going to be updating those loyalty points and the other one will not be",
    "start": "1659900",
    "end": "1665960"
  },
  {
    "text": "and this if this is essentially going to ensure that each one of these customer orders gets updated in the correct",
    "start": "1665960",
    "end": "1672620"
  },
  {
    "text": "format and doesn't you know overwrite or clobber each other in the database at the end of the day",
    "start": "1672620",
    "end": "1678940"
  },
  {
    "text": "cool so let's check out now what that looks like in the redis database so if you remember from my architecture I had",
    "start": "1678980",
    "end": "1686240"
  },
  {
    "text": "um these writing to that redisdb so I'm going to switch over now just to my redis database",
    "start": "1686240",
    "end": "1691880"
  },
  {
    "text": "today this is just running on my AKs cluster and I'm going to check out what those orders look like so for instance",
    "start": "1691880",
    "end": "1699799"
  },
  {
    "text": "coming in here let's check out that no lock one first okay because I'm going to check out no",
    "start": "1699799",
    "end": "1706940"
  },
  {
    "text": "lock because I want to see uh you know what that looks like if in the case I did not use a lock in my code so I sent",
    "start": "1706940",
    "end": "1713179"
  },
  {
    "text": "if you remember two different load tests each of them had 10 orders in them so",
    "start": "1713179",
    "end": "1719000"
  },
  {
    "text": "there should be around 20 orders and in the right hand side here we actually have this order count",
    "start": "1719000",
    "end": "1725860"
  },
  {
    "text": "okay I'm gonna make this turning up bigger",
    "start": "1727400",
    "end": "1732400"
  },
  {
    "text": "so on the no locks case I have a ton of different scenarios and I'm getting different numbers every single time",
    "start": "1732860",
    "end": "1739220"
  },
  {
    "text": "sometimes I'm getting up to 35 sometimes I'm getting 37 you know these are processing entirely different amounts uh",
    "start": "1739220",
    "end": "1745820"
  },
  {
    "text": "as it goes as the lock you know writes over and over to this database or as the no lock app writes over and over to this",
    "start": "1745820",
    "end": "1751640"
  },
  {
    "text": "database but you know and you can see 33 all very different but you know if I",
    "start": "1751640",
    "end": "1758299"
  },
  {
    "text": "come in here and look at the case where there was the lock I think networklings he messed up the oh",
    "start": "1758299",
    "end": "1766039"
  },
  {
    "text": "really sharing of the orders yeah okay yeah because there was yeah okay they",
    "start": "1766039",
    "end": "1771440"
  },
  {
    "text": "didn't come through this is well we have 19. 19 came through Kendall okay well we",
    "start": "1771440",
    "end": "1776600"
  },
  {
    "text": "have now on this case we have 20 orders that came through for the customer load service with the lock and this is",
    "start": "1776600",
    "end": "1782840"
  },
  {
    "text": "essentially going to be uh if there wasn't we had a bit of network latency Kendall said so we had a bit of latency",
    "start": "1782840",
    "end": "1787880"
  },
  {
    "text": "here but there would be 20 orders every single time so we have a few instances there you go",
    "start": "1787880",
    "end": "1793520"
  },
  {
    "text": "it's coming through now actually Kendall yeah when I try to delete the keys from My Demo the chaos okay but okay I think",
    "start": "1793520",
    "end": "1799880"
  },
  {
    "text": "it's just coming through still so yeah we have a few they're common all the orders are coming through and at the end you're gonna have 20 orders for every",
    "start": "1799880",
    "end": "1806720"
  },
  {
    "text": "single instance um of this in this redisdb so again this is two of exactly the same application",
    "start": "1806720",
    "end": "1812600"
  },
  {
    "text": "one of them's using the lock one of them isn't and this is updating the loyalty points",
    "start": "1812600",
    "end": "1817880"
  },
  {
    "text": "um you know and you do have that correct order count at the end of the day awesome",
    "start": "1817880",
    "end": "1824360"
  },
  {
    "text": "all right well we really appreciate all of you coming today I think we we covered a lot but I think at the end of",
    "start": "1824360",
    "end": "1830000"
  },
  {
    "text": "the day Alice and I really want all of you to walk away with one Central message which is we need to find easier",
    "start": "1830000",
    "end": "1835580"
  },
  {
    "text": "ways to enable developers to get up and running with their applications quickly and having to focus on plumbing code and",
    "start": "1835580",
    "end": "1841520"
  },
  {
    "text": "solving some of these distributed application problems on a developer by developer basis is never fun so finding",
    "start": "1841520",
    "end": "1847700"
  },
  {
    "text": "a way that we can use Dapper to enable our developers to get some of this core functionality without having to lose",
    "start": "1847700",
    "end": "1854120"
  },
  {
    "text": "that focus on business logic is really the key takeaway here so we would love for you all to dive into the Dapper",
    "start": "1854120",
    "end": "1860480"
  },
  {
    "text": "project contribute give feedback and hopefully you'll be empowered to develop",
    "start": "1860480",
    "end": "1865820"
  },
  {
    "text": "your applications with ease using Dapper awesome and then yeah if you have any questions comments concerns please come",
    "start": "1865820",
    "end": "1871880"
  },
  {
    "text": "ask us anything's open even like you know why we decide to do live demos things like that and yeah check out",
    "start": "1871880",
    "end": "1878960"
  },
  {
    "text": "driver yeah thank you so much [Applause]",
    "start": "1878960",
    "end": "1884469"
  }
]
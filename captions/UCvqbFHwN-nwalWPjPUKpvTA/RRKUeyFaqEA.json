[
  {
    "start": "0",
    "end": "120000"
  },
  {
    "text": "work on many different things load balancing being one of them maybe it's just French people like to work on load",
    "start": "0",
    "end": "5790"
  },
  {
    "text": "balancing I really appreciated a Damien's presentation beforehand to introduce some concepts that I'll get to skip over",
    "start": "5790",
    "end": "12420"
  },
  {
    "text": "I have a really long whoa there it is again a really long title up there so I wanted",
    "start": "12420",
    "end": "18900"
  },
  {
    "text": "to shrink that down a little bit by pointing out the I've been having",
    "start": "18900",
    "end": "25220"
  },
  {
    "text": "troubles with this there we go those are the pieces we're really going to talk about ipv6 segment routing and VPP and",
    "start": "25220",
    "end": "33989"
  },
  {
    "text": "how together they can make a better pointer there we go how to gather you",
    "start": "33989",
    "end": "43140"
  },
  {
    "text": "can assemble these pieces and do some interesting things with load balancing so first ipv6 and since we're at a",
    "start": "43140",
    "end": "49920"
  },
  {
    "text": "kubernetes or cube con conference a little bit on the status of ipv6 this is",
    "start": "49920",
    "end": "55920"
  },
  {
    "text": "a work being done by my colleagues Dane the blonde for Rob Peltier and Paul",
    "start": "55920",
    "end": "61800"
  },
  {
    "text": "McCauley mishali you can speak to them for details on exactly what we're doing",
    "start": "61800",
    "end": "67680"
  },
  {
    "text": "in kubernetes but the main point being we're sort of at the crawling and",
    "start": "67680",
    "end": "74220"
  },
  {
    "text": "walking phase right now where you kind of look at v4 and v6 and say ok search",
    "start": "74220",
    "end": "79860"
  },
  {
    "text": "and replace ok wherever there's before we're gonna make v6 and see if everything continues to work with the idea of eventually",
    "start": "79860",
    "end": "86369"
  },
  {
    "text": "moving up to preparing and planning for some of the things that I'm gonna be talking about today that when you have",
    "start": "86369",
    "end": "92009"
  },
  {
    "text": "v6 what you can do so where are we with v6 in the internet that was kubernetes",
    "start": "92009",
    "end": "98880"
  },
  {
    "text": "of course v6 has been around for a long long time but recently it's been taking",
    "start": "98880",
    "end": "104610"
  },
  {
    "text": "off quite a bit the top chart this is",
    "start": "104610",
    "end": "110909"
  },
  {
    "text": "going to be problematic I'm just gonna have to sit over here I usually usually like to walk around but I'm gonna have to try to stay",
    "start": "110909",
    "end": "116670"
  },
  {
    "text": "planted here the blue line is as measured by Google and reported on their",
    "start": "116670",
    "end": "123420"
  },
  {
    "text": "website there's the link there they're at the bottom and my colleague Eric Vinci he scrapes their site every day",
    "start": "123420",
    "end": "128670"
  },
  {
    "text": "and record and stores it and then publishes these charts so Belgium is that 50% of ipv6 as seen",
    "start": "128670",
    "end": "137300"
  },
  {
    "text": "by Google so every time you Google or YouTube or whatever they do locate to Belgium and they publish these up to",
    "start": "137300",
    "end": "143420"
  },
  {
    "text": "each country and they publish these results now that's without any mobile activity from the ISPs the ISPs haven't",
    "start": "143420",
    "end": "151340"
  },
  {
    "text": "moved v6 to v6 in the mobile network yet so 50 percent just from enterprise and",
    "start": "151340",
    "end": "157370"
  },
  {
    "text": "landline Germany and USA pretty straight",
    "start": "157370",
    "end": "162860"
  },
  {
    "text": "lines up and to the right around the 35 percent range now it's not just big",
    "start": "162860",
    "end": "168260"
  },
  {
    "text": "economies it's it's our smaller ones as well Greece there started a bit later",
    "start": "168260",
    "end": "173300"
  },
  {
    "text": "but ramped up quickly to catch up with Germany in the USA at around the 30 to",
    "start": "173300",
    "end": "179120"
  },
  {
    "text": "40 percent range this is the tortoise and hare argument here France was a back",
    "start": "179120",
    "end": "185240"
  },
  {
    "text": "when I started working on ipv6 in 2011 2012 and we did the world launch France",
    "start": "185240",
    "end": "191390"
  },
  {
    "text": "was the leading country in the entire world with ipv6 with this you know",
    "start": "191390",
    "end": "196640"
  },
  {
    "text": "around five or six percent mostly from the isp free telecom and that stayed",
    "start": "196640",
    "end": "202010"
  },
  {
    "text": "that way until orange kicked in but then India came online boom Reliance Geo deploys 183 million in",
    "start": "202010",
    "end": "210260"
  },
  {
    "text": "points within two years on ipv6 and",
    "start": "210260",
    "end": "215770"
  },
  {
    "text": "don't want to throw the country under the bus that's hosting us here but I would you know we keep stats on",
    "start": "215770",
    "end": "223100"
  },
  {
    "text": "everything Denmark is three point five percent so not all the countries are like this globally were around one in",
    "start": "223100",
    "end": "229100"
  },
  {
    "text": "four users have ipv6 now just to get across and I think it's important for an",
    "start": "229100",
    "end": "235310"
  },
  {
    "text": "audience that's gonna be thinking about using ipv6 and putting it in the kubernetes is you know how different v4",
    "start": "235310",
    "end": "243230"
  },
  {
    "start": "240000",
    "end": "300000"
  },
  {
    "text": "and v6 is and that's just it's not just the how the protocols operate and",
    "start": "243230",
    "end": "249260"
  },
  {
    "text": "everything but how it's being used and how it's being deployed and this is a really interesting data point from my",
    "start": "249260",
    "end": "255800"
  },
  {
    "text": "friend over at Akamai so this is from their infrastructure looking at unique ipv6 addresses that they see in a given",
    "start": "255800",
    "end": "263570"
  },
  {
    "text": "period of time here it's in one week and they see almost ten billion unique ipv6 addresses",
    "start": "263570",
    "end": "270470"
  },
  {
    "text": "within a week now this of course far less than they see a unique ipv4 addresses because there's only four",
    "start": "270470",
    "end": "276170"
  },
  {
    "text": "billion ipv4 addresses in the world they even see more unique slash 64 than they",
    "start": "276170",
    "end": "283610"
  },
  {
    "text": "see ipv4 addresses so what this suggests to me is there's a lot of churn in terms of the ipv6 addresses they're doing more",
    "start": "283610",
    "end": "290420"
  },
  {
    "text": "than just being a single address on the side of a NAT or a single address to to",
    "start": "290420",
    "end": "296030"
  },
  {
    "text": "an endpoint they're changing quite a bit and there's there's reasons for that but the infrastructure supports it",
    "start": "296030",
    "end": "303070"
  },
  {
    "start": "300000",
    "end": "360000"
  },
  {
    "text": "speaking of infrastructure that supports v6 at Facebook this is bingo this is a",
    "start": "303070",
    "end": "309260"
  },
  {
    "text": "presentation from Facebook last December they've gone 100% v6 only within their",
    "start": "309260",
    "end": "316040"
  },
  {
    "text": "infrastructure in the effectively support at the edge of proxy between v4",
    "start": "316040",
    "end": "321740"
  },
  {
    "text": "and v6 for the Internet users everything internally is v6 only and yes it's with",
    "start": "321740",
    "end": "326810"
  },
  {
    "text": "containers it's not with kubernetes and they do some unique things as I showed",
    "start": "326810",
    "end": "333350"
  },
  {
    "text": "with Akamai with all these different v6 addresses that aren't just you know one endpoint out there there's more than",
    "start": "333350",
    "end": "339590"
  },
  {
    "text": "that they're addressing each container each task with the unique ipv6 address and they you always have to think about",
    "start": "339590",
    "end": "345950"
  },
  {
    "text": "it as over time right like how many addresses am I using over time because",
    "start": "345950",
    "end": "350990"
  },
  {
    "text": "they can be ephemeral you can use them and not use it again for a number of years if you'd like I collectively call",
    "start": "350990",
    "end": "362060"
  },
  {
    "start": "360000",
    "end": "420000"
  },
  {
    "text": "this routing past the interface and each of these little pictures correlates to",
    "start": "362060",
    "end": "367370"
  },
  {
    "text": "either a project that I know of that's happening or one that we're running in our research lab in Paris that when you",
    "start": "367370",
    "end": "375290"
  },
  {
    "text": "have all this extra room when you move take something that was four billion and you increase it by 30 orders of",
    "start": "375290",
    "end": "381140"
  },
  {
    "text": "magnitude the the way the network operates can be different I talked about",
    "start": "381140",
    "end": "389660"
  },
  {
    "text": "reliance 183 million subscribers there get only getting v6 addresses because",
    "start": "389660",
    "end": "395419"
  },
  {
    "text": "this is an ISP that came into existence after the ipv4 run out so they your mobile phone only gets a v6",
    "start": "395419",
    "end": "402190"
  },
  {
    "text": "address that's really not an incredibly new thing when you consider in t-mobile in the US has been that way for several",
    "start": "402190",
    "end": "408160"
  },
  {
    "text": "years and there's different types of transition technologies and people kind of get scared because there's so many of",
    "start": "408160",
    "end": "414490"
  },
  {
    "text": "them but really it started to narrow down to a couple of different ones with funny different acronyms but the bottom",
    "start": "414490",
    "end": "421750"
  },
  {
    "text": "line is is this idea that I can take part of my network or part of my deployment or whatever it is and v6 only",
    "start": "421750",
    "end": "428170"
  },
  {
    "text": "it and then put v4 out at the edge now",
    "start": "428170",
    "end": "434080"
  },
  {
    "text": "because v6 has all this address space we can again we can start using it for",
    "start": "434080",
    "end": "439900"
  },
  {
    "text": "things other than routing to a single interface I can take my port space in v4 in a bit of my v4 address space and",
    "start": "439900",
    "end": "447640"
  },
  {
    "text": "shove it into the v6 address space with an algorithm that allows a stateless",
    "start": "447640",
    "end": "453540"
  },
  {
    "text": "translation between the two and then I can encapsulate or I can translate and together we call this thing map mapping",
    "start": "453540",
    "end": "460510"
  },
  {
    "text": "address and port mapping address import map routing ipv4 addresses and ports in",
    "start": "460510",
    "end": "467410"
  },
  {
    "text": "the v6 infrastructure so you have this v6 infrastructure it's there if you've set it up by putting the ports and the",
    "start": "467410",
    "end": "476110"
  },
  {
    "text": "v4 addresses inside the addresses v6 addresses in a certain way you get the power of routing to get the packets",
    "start": "476110",
    "end": "482950"
  },
  {
    "start": "480000",
    "end": "540000"
  },
  {
    "text": "where they need to go without having to set up stateful Nats so that's v6 in two",
    "start": "482950",
    "end": "494260"
  },
  {
    "text": "minutes segment routing everybody knows what a tunnel is right have I missed any of the",
    "start": "494260",
    "end": "504100"
  },
  {
    "text": "acronyms for tunnels up here is there surely there's one your favorite tunnel",
    "start": "504100",
    "end": "510070"
  },
  {
    "text": "you probably invented a tunnel in your lifetime I almost put it on there but",
    "start": "510070",
    "end": "517330"
  },
  {
    "text": "I've been in a long architectural debate with Joe touch on whether or not MPLS is actually a tunnel or not what's that",
    "start": "517330",
    "end": "526410"
  },
  {
    "text": "what l3 VPNs well they tend to use MPLS but may use other stuff anyway",
    "start": "526410",
    "end": "533080"
  },
  {
    "text": "lots of mouths air and I think the proliferation of tunnels happens because they're typically pairwise sometimes",
    "start": "533080",
    "end": "539350"
  },
  {
    "text": "their group around an edge but if this start of the tunnel is the same protocol",
    "start": "539350",
    "end": "544690"
  },
  {
    "start": "540000",
    "end": "600000"
  },
  {
    "text": "is the end of the tunnel it works because that's the whole idea is that all the stuff in the middle doesn't have",
    "start": "544690",
    "end": "549820"
  },
  {
    "text": "to know about it a tunnel has a has a start and an end just like the tunnel there on the screen",
    "start": "549820",
    "end": "557160"
  },
  {
    "text": "segment routing is a bit like a tunnel in that it's got a start and an end but",
    "start": "557160",
    "end": "562900"
  },
  {
    "text": "it's got multiple ends okay so rather than just going in and then out you can",
    "start": "562900",
    "end": "569140"
  },
  {
    "text": "it's sort of like stitching tunnels together if you will but in a way that's that's that's designed from the start to",
    "start": "569140",
    "end": "575890"
  },
  {
    "text": "be able to do that so this lets you from the source of the packet or the start of",
    "start": "575890",
    "end": "581620"
  },
  {
    "text": "the tunnel cinepak it to multiple waypoints just like you see up here",
    "start": "581620",
    "end": "589950"
  },
  {
    "text": "now there's waypoints if they're in v6 and you've got all this address space",
    "start": "589950",
    "end": "595080"
  },
  {
    "text": "they don't have to be individual nodes they can be services inside the router",
    "start": "595080",
    "end": "601300"
  },
  {
    "start": "600000",
    "end": "660000"
  },
  {
    "text": "or inside a computer ode or what have you because with 128 bits you can I just",
    "start": "601300",
    "end": "606730"
  },
  {
    "text": "like I was identifying hey this is this address actually contains a bit of a v4",
    "start": "606730",
    "end": "612010"
  },
  {
    "text": "address and a bit of a port I can say is this address means perform this function on the packet install this state get rid",
    "start": "612010",
    "end": "620500"
  },
  {
    "text": "of the state and you're gonna see why that's important when Pierre gets up here sorry about that so we're gonna",
    "start": "620500",
    "end": "631150"
  },
  {
    "text": "talk about three things so that's ipv6 segment routing just think of segment routing as a tunnel but one that you can",
    "start": "631150",
    "end": "637000"
  },
  {
    "text": "go through multiple waypoints and do stuff VPP is a I can go to the next",
    "start": "637000",
    "end": "644980"
  },
  {
    "text": "slide for that I hate not having my little slide thing VPP is a project actually anything about VPP you can ask",
    "start": "644980",
    "end": "652180"
  },
  {
    "text": "Heather Kirk see right there it's the SDIO project or the fast data project",
    "start": "652180",
    "end": "659140"
  },
  {
    "text": "and the little foundation or phyto it's sometimes called it's a vector packet",
    "start": "659140",
    "end": "664540"
  },
  {
    "start": "660000",
    "end": "720000"
  },
  {
    "text": "processor which is a very fast packet processing engine so",
    "start": "664540",
    "end": "670930"
  },
  {
    "text": "as you see here it'll run on bare metal and run on VM and running containers what have you it's a it's just the",
    "start": "670930",
    "end": "677050"
  },
  {
    "text": "packet processing engine and it runs in userspace so it bypasses the kernel and you get to",
    "start": "677050",
    "end": "683200"
  },
  {
    "text": "do all sorts of fancy stuff inside the the VPP system and it lets you you know",
    "start": "683200",
    "end": "689710"
  },
  {
    "text": "move at a different pace than waiting for the kernel in terms of network features also it's running in user space",
    "start": "689710",
    "end": "696100"
  },
  {
    "text": "on the compute nodes and there's convenient ways to share memory with other applications on the compute node",
    "start": "696100",
    "end": "704320"
  },
  {
    "text": "and that's a core of what we're going to be getting into in just a moment for the",
    "start": "704320",
    "end": "709330"
  },
  {
    "text": "SR v6 lb application so if you have VP P which is the fast data project in the",
    "start": "709330",
    "end": "715750"
  },
  {
    "text": "Linux Foundation you have how do I get it into containers well one way to get into containers is to use con teve which",
    "start": "715750",
    "end": "723400"
  },
  {
    "start": "720000",
    "end": "780000"
  },
  {
    "text": "is c and i etcetera you can kind of see it on the on the chart here this is the canonical chart about VPP in kubernetes",
    "start": "723400",
    "end": "729730"
  },
  {
    "text": "so Conte VPP puts VPP into kubernetes and finally I stole this literally from",
    "start": "729730",
    "end": "737350"
  },
  {
    "text": "my from Lou Tucker who did a CTO for us this morning I said hey that shows Conte",
    "start": "737350",
    "end": "742840"
  },
  {
    "text": "Vince I'd this whole big package so you can go over the booze and find some Conte guys and they should be able to tell you how can't Eve gets VPP into",
    "start": "742840",
    "end": "751620"
  },
  {
    "text": "kubernetes at least in that platform now",
    "start": "751620",
    "end": "756910"
  },
  {
    "text": "finally SRV 6lb you just got a tutorial in load balancing and that's fantastic",
    "start": "756910",
    "end": "765030"
  },
  {
    "text": "elf for load balancing as you just heard you do some sort of you know random round-robin hash consistent hash what",
    "start": "765030",
    "end": "772060"
  },
  {
    "text": "have you and then you tunnel or nap maybe a GRE tunnel whatever to get to",
    "start": "772060",
    "end": "777480"
  },
  {
    "text": "the chosen server destination okay this",
    "start": "777480",
    "end": "783760"
  },
  {
    "start": "780000",
    "end": "840000"
  },
  {
    "text": "is without monitoring if you do monitoring of the app it are you it's a",
    "start": "783760",
    "end": "788920"
  },
  {
    "text": "it's it's a different thing because the this green box has to do a lot more if",
    "start": "788920",
    "end": "794140"
  },
  {
    "text": "it's trying to constantly monitor the the given load of any server and make an",
    "start": "794140",
    "end": "799390"
  },
  {
    "text": "intelligent decision Bay done that and we want to think of a another way of doing this we base this",
    "start": "799390",
    "end": "805270"
  },
  {
    "text": "on Google's maglev maglev has a very clever way of doing its consistent hashing and it's self described as",
    "start": "805270",
    "end": "811660"
  },
  {
    "text": "embarrassingly distributed so here's really the key instead of selecting one",
    "start": "811660",
    "end": "823980"
  },
  {
    "text": "possible destination with my consistent hash I'm going to select two up front and it's a bit like the power of two",
    "start": "823980",
    "end": "830140"
  },
  {
    "text": "choices but we definitely use the power of two choices it's a bit like the bounded load stuff but instead of",
    "start": "830140",
    "end": "840150"
  },
  {
    "start": "840000",
    "end": "900000"
  },
  {
    "text": "relying on the end points to chain the packet along the way we let the load balancer who's got a view of all that",
    "start": "840690",
    "end": "847240"
  },
  {
    "text": "all the possibilities select - and because I have the segment routing which is like a tunnel with multiple hops I",
    "start": "847240",
    "end": "853810"
  },
  {
    "text": "can just say go to here and then go to there and add each hop I can make it a",
    "start": "853810",
    "end": "859570"
  },
  {
    "text": "decision what's the current load level of the application the VIP that I'm targeting on that compute node if it's",
    "start": "859570",
    "end": "866560"
  },
  {
    "text": "below a threshold I accept it if it's above a threshold I pass to the next and this is all done at the network layer",
    "start": "866560",
    "end": "872440"
  },
  {
    "text": "the applications don't see it other than the network layer in in the compute node",
    "start": "872440",
    "end": "878950"
  },
  {
    "text": "being able to see the current metric that the application wants to balance on",
    "start": "878950",
    "end": "884290"
  },
  {
    "text": "and what's interesting is the load balancer doesn't have to be aware of that in metric at all it could be CPU",
    "start": "884290",
    "end": "890140"
  },
  {
    "text": "percentage it could be a queue depth it could be number of threads it could be how much memory you have it's whatever",
    "start": "890140",
    "end": "895990"
  },
  {
    "text": "the application wants to balance upon because the decisions being made locally",
    "start": "895990",
    "end": "901510"
  },
  {
    "start": "900000",
    "end": "960000"
  },
  {
    "text": "by that application on the compute node and it's just a yes/no if it's no he doesn't even have to think about where",
    "start": "901510",
    "end": "907210"
  },
  {
    "text": "to send it next it's already in the packet because s r is like a multi hop tunnel now when we first thought of this",
    "start": "907210",
    "end": "913630"
  },
  {
    "text": "in the way it's it's architected is we can go through multiple but we found the",
    "start": "913630",
    "end": "919060"
  },
  {
    "text": "same thing that Damien did - is the magic number you get - if you choose two",
    "start": "919060",
    "end": "926560"
  },
  {
    "text": "packets there we go I mean two destinations you get a significant benefit three you get a little bit more",
    "start": "926560",
    "end": "933250"
  },
  {
    "text": "of a bit of a little benefit to one all the way up to N and it decreases as you go along the way all",
    "start": "933250",
    "end": "938540"
  },
  {
    "text": "the way up to the end here's a couple of results I'm not going to spend too much",
    "start": "938540",
    "end": "944329"
  },
  {
    "text": "time on it because Pierre's got a live demo assuming the demo gods don't come",
    "start": "944329",
    "end": "951529"
  },
  {
    "text": "down upon us but you can see here these are graphs of the CPU loads and we've set a threshold and on the Maglev side",
    "start": "951529",
    "end": "959810"
  },
  {
    "text": "nothing wrong with maglev wonderful technology don't want to call anybody you know invention ugly or anything but",
    "start": "959810",
    "end": "966170"
  },
  {
    "start": "960000",
    "end": "1020000"
  },
  {
    "text": "this is taking that and just improving on it these are unlucky requests so when you're really running hot every once in",
    "start": "966170",
    "end": "972589"
  },
  {
    "text": "a while you're gonna get unlucky and the hotter you run the more unlucky you're you're going to get and since the load balancer has no knowledge of the load of",
    "start": "972589",
    "end": "979759"
  },
  {
    "text": "the system it can happen right and so in our testbed we were able to you know land on a lot of unlucky requests there",
    "start": "979759",
    "end": "988360"
  },
  {
    "text": "same set up you turn on the srl B and the naturally the you move on to the",
    "start": "988360",
    "end": "995269"
  },
  {
    "text": "next server and you can see that sometimes you get unlucky twice that's when oh I tried this when I was above",
    "start": "995269",
    "end": "1001569"
  },
  {
    "text": "the threshold I tried the next one oh well and he accepts it anyway because that threshold is not a hundred percent it's something less so it does happen",
    "start": "1001569",
    "end": "1009100"
  },
  {
    "text": "but you end up with something that's much much more fair in terms of there's",
    "start": "1009100",
    "end": "1015220"
  },
  {
    "text": "two ways to look at the benefit here you can say all right same infrastructure same load pattern",
    "start": "1015220",
    "end": "1020829"
  },
  {
    "start": "1020000",
    "end": "1080000"
  },
  {
    "text": "what's the client page load response time so the experience of the client another way to look at it is can I",
    "start": "1020829",
    "end": "1028808"
  },
  {
    "text": "reduce the amount of infrastructure for the same SLA so this is the the first way where I can say for a given set of",
    "start": "1028809",
    "end": "1035409"
  },
  {
    "text": "servers here's the page load time maglev is better than like round-robin it's",
    "start": "1035409",
    "end": "1041829"
  },
  {
    "text": "doing it's doing a good job here but SRL B does a better job and you can see as",
    "start": "1041829",
    "end": "1046839"
  },
  {
    "text": "we get up to 80 and 90% the it's two and a half times better in terms of page",
    "start": "1046839",
    "end": "1053020"
  },
  {
    "text": "load time peers demo shows all this but in better detail this is just that",
    "start": "1053020",
    "end": "1059500"
  },
  {
    "text": "reverse situation for a given SLA I can move 20 to 25 percent less servers and",
    "start": "1059500",
    "end": "1065980"
  },
  {
    "text": "get the same response out of the client so with that I'm gonna",
    "start": "1065980",
    "end": "1070990"
  },
  {
    "text": "hand straight over to Pierre we're gonna have to change machines here if you want to know any of the excruciating details",
    "start": "1070990",
    "end": "1077410"
  },
  {
    "text": "there's a whole academic side of this Johan did it he's somewhere in the audience there he is this is part of his",
    "start": "1077410",
    "end": "1082630"
  },
  {
    "text": "PhD there's all the math behind it as well as the details of experimental results that was just published in I",
    "start": "1082630",
    "end": "1091180"
  },
  {
    "text": "Triple E ACM transactions on networking and I hand it over to Pierre yeah so I'm",
    "start": "1091180",
    "end": "1100750"
  },
  {
    "text": "going to show you a demo but before that I will explain you give you some details",
    "start": "1100750",
    "end": "1107170"
  },
  {
    "text": "about the implementation that we did in VPP so I need to find my slide it's this",
    "start": "1107170",
    "end": "1113620"
  },
  {
    "text": "one and I will just give it from the pointer or maybe try it might work or",
    "start": "1113620",
    "end": "1119620"
  },
  {
    "text": "not okay so as you all know now VPP is",
    "start": "1119620",
    "end": "1125290"
  },
  {
    "text": "via to router and jet will switch and it's very very efficient",
    "start": "1125290",
    "end": "1130360"
  },
  {
    "text": "it's a code that is beautifully optimized one of the reason why it's so efficient is by design all the packets",
    "start": "1130360",
    "end": "1136720"
  },
  {
    "text": "go through a set of nodes so they are Traverse graph and each node does a very",
    "start": "1136720",
    "end": "1141820"
  },
  {
    "start": "1140000",
    "end": "1200000"
  },
  {
    "text": "very simple operation on the on each packet so here you see an example going from D PDK you see the IP lookup you see",
    "start": "1141820",
    "end": "1148600"
  },
  {
    "text": "the transmission on the wire back so this simple IP forwarding and this is very extensible as well as well so that",
    "start": "1148600",
    "end": "1155650"
  },
  {
    "text": "doesn't work I will have to press the button so in our case we implemented the",
    "start": "1155650",
    "end": "1161679"
  },
  {
    "text": "load balancer on one side and the server agent on the other side has two different vvp plugin for instance when",
    "start": "1161679",
    "end": "1168970"
  },
  {
    "text": "you receive a packet on the load balancer well this is just a different node in the graph and packets are",
    "start": "1168970",
    "end": "1175480"
  },
  {
    "text": "forwarded by the IP lookup so we this is extensible right you can ask VPP to send",
    "start": "1175480",
    "end": "1181420"
  },
  {
    "text": "you as a plugin some specific packets to your own custom nodes same thing when",
    "start": "1181420",
    "end": "1187390"
  },
  {
    "text": "the server agent on the server side received a packet it's sent to one of our nodes and then based on the",
    "start": "1187390",
    "end": "1194200"
  },
  {
    "text": "destination IP that is used based on the segment routing we can dispatch the",
    "start": "1194200",
    "end": "1200170"
  },
  {
    "start": "1200000",
    "end": "1260000"
  },
  {
    "text": "packet to the different nodes that we have inside our plugin same thing on the on the other direction when you",
    "start": "1200170",
    "end": "1206799"
  },
  {
    "text": "receive a packet from the application on the server agent side we leverage another way that VPP is able to hand off",
    "start": "1206799",
    "end": "1213549"
  },
  {
    "text": "a packets to the plugins that are called IP features I'm not going into too much",
    "start": "1213549",
    "end": "1218679"
  },
  {
    "text": "details here but the idea is that it's very flexible now let's focus on a small",
    "start": "1218679",
    "end": "1224649"
  },
  {
    "text": "piece of it which is actually the key idea of segment routing load balancer is this idea of having a choice here the",
    "start": "1224649",
    "end": "1232840"
  },
  {
    "text": "packets on the server agent is received and it's a packet for a new connection that's why it's called connect if",
    "start": "1232840",
    "end": "1239470"
  },
  {
    "text": "available and it's only if there is there are resources available that the",
    "start": "1239470",
    "end": "1245139"
  },
  {
    "text": "connection is going to be accepted and because that decision has to be taken on",
    "start": "1245139",
    "end": "1250450"
  },
  {
    "text": "a per flow basis every time there is a new flow well it has to be fairly efficient and that is as well extensible",
    "start": "1250450",
    "end": "1258639"
  },
  {
    "text": "that in our plugin we implemented a set of different policies one and the one",
    "start": "1258639",
    "end": "1263679"
  },
  {
    "start": "1260000",
    "end": "1320000"
  },
  {
    "text": "that were showing in the demo is based on Apache because Apache provides an API",
    "start": "1263679",
    "end": "1269470"
  },
  {
    "text": "where you have a share memory you can establish your share memory memory where you will see live the busyness of the of",
    "start": "1269470",
    "end": "1278590"
  },
  {
    "text": "the Apache server we also implemented engine something with nginx",
    "start": "1278590",
    "end": "1283629"
  },
  {
    "text": "we also have a standard way to do it with Linux C group so if you don't have a custom application you can use",
    "start": "1283629",
    "end": "1289450"
  },
  {
    "text": "something that is a bit more generic and that's completely extensible you can have other plugins that are application",
    "start": "1289450",
    "end": "1296679"
  },
  {
    "text": "specific if you have an application yours and you want to give to VPP vision",
    "start": "1296679",
    "end": "1305139"
  },
  {
    "text": "of what is your current load and the application is better is the best place to know what's the current load based on",
    "start": "1305139",
    "end": "1311799"
  },
  {
    "text": "the metric that matters for the application you can make a VPP plug-in and provide this visibility to the",
    "start": "1311799",
    "end": "1318609"
  },
  {
    "text": "server agents such that when a connection is received the server gets to decide whether to accept the new",
    "start": "1318609",
    "end": "1324549"
  },
  {
    "text": "connection or forwarded to the next choice the next server to accept the",
    "start": "1324549",
    "end": "1330730"
  },
  {
    "text": "connection then one of the aspects I would to mention as well as the the nice",
    "start": "1330730",
    "end": "1337419"
  },
  {
    "text": "things about using ipv6 segment routing is that actually you have plenty of bits in the address 128 bits that's a lot and",
    "start": "1337419",
    "end": "1345070"
  },
  {
    "text": "you can use that to optimize well your your code basically so even though it's",
    "start": "1345070",
    "end": "1350770"
  },
  {
    "text": "protocol thing in the destination IP address you have all those bits some of",
    "start": "1350770",
    "end": "1356049"
  },
  {
    "text": "the bits that we use are here for the function so those are the bits that are that are going to tell this packet is a",
    "start": "1356049",
    "end": "1362200"
  },
  {
    "text": "new packet or I mean a new flow packet or a flow that already exists and you're going to do something based on that",
    "start": "1362200",
    "end": "1368980"
  },
  {
    "text": "function that's really used to optimize the code path inside VPP but I mean it",
    "start": "1368980",
    "end": "1374380"
  },
  {
    "text": "can be used in other implementations as well and then we still have 40 bits left we call them the opaque number because",
    "start": "1374380",
    "end": "1380679"
  },
  {
    "text": "that's something that is picked by the load balancer or the server agent and on the per flow basis it's sent to the",
    "start": "1380679",
    "end": "1388270"
  },
  {
    "text": "other side and the other side is just going to echo the that opaque number",
    "start": "1388270",
    "end": "1393790"
  },
  {
    "text": "back every time there is a packet going in the other direction we use that for",
    "start": "1393790",
    "end": "1398860"
  },
  {
    "text": "two purposes one is CPU steering and the other one is the to optimize the flow",
    "start": "1398860",
    "end": "1404740"
  },
  {
    "text": "lookup in our flow table so the details about the CPU steering which is very",
    "start": "1404740",
    "end": "1411220"
  },
  {
    "text": "problematic when you implement something at very high rates is that so that you",
    "start": "1411220",
    "end": "1417340"
  },
  {
    "text": "receive a packet for a flow the NIC received the packet and the NIC is going to hand off that packet to a given CPU",
    "start": "1417340",
    "end": "1423660"
  },
  {
    "text": "you don't control that it's not just to pick it's the NIC that does that it's called RSS and so on that CPU on that",
    "start": "1423660",
    "end": "1431590"
  },
  {
    "text": "core that's where you're going to install the state and because you want to avoid using locks between the",
    "start": "1431590",
    "end": "1439059"
  },
  {
    "text": "different cores because you're just going to destroy your performance if you do you need to do LOC less data",
    "start": "1439059",
    "end": "1445059"
  },
  {
    "start": "1440000",
    "end": "1500000"
  },
  {
    "text": "structure so you you can only install your state on one single core and so",
    "start": "1445059",
    "end": "1451150"
  },
  {
    "text": "that's where the trick happens when you send a packet to the server agents you put the CPU index and so when the packet",
    "start": "1451150",
    "end": "1457090"
  },
  {
    "text": "comes back you have no way of making sure that the NIC is going to send it to the right core most of the time it's",
    "start": "1457090",
    "end": "1463480"
  },
  {
    "text": "going to be the wrong one so the way you do it in if you don't have that loud label well",
    "start": "1463480",
    "end": "1469149"
  },
  {
    "text": "it's you compute the 5-tuple you decide what color you want to send it and then you send it to the car that's a bit",
    "start": "1469149",
    "end": "1475539"
  },
  {
    "text": "expensive here you get the bits right inside the packet and you can send it to the right car and and then continue",
    "start": "1475539",
    "end": "1484619"
  },
  {
    "text": "finally one word about the performances",
    "start": "1484619",
    "end": "1491169"
  },
  {
    "text": "because we have evaluated we have compared this new approach to load",
    "start": "1491169",
    "end": "1496239"
  },
  {
    "text": "balancing a service 6 lb with maglev both are implemented in VPP and both are",
    "start": "1496239",
    "end": "1501940"
  },
  {
    "start": "1500000",
    "end": "1560000"
  },
  {
    "text": "really well optimized SRV 6lv adds a little bit of overhead you see we go",
    "start": "1501940",
    "end": "1508299"
  },
  {
    "text": "from 8.3 millions packets per second per core to 8 millions packets per second",
    "start": "1508299",
    "end": "1513639"
  },
  {
    "text": "per core I understand you're on maybe probably not all networking people but",
    "start": "1513639",
    "end": "1518799"
  },
  {
    "text": "basically that means that if with one core you can roughly load balance about",
    "start": "1518799",
    "end": "1525669"
  },
  {
    "text": "22 gigabytes per second of transfer the",
    "start": "1525669",
    "end": "1533469"
  },
  {
    "text": "road balancer here the load balancer because it's a layer 3 layer 7 and no",
    "start": "1533469",
    "end": "1538719"
  },
  {
    "text": "sorry layer 3 layer 4 and not a proxy it only sees the packets that are going in",
    "start": "1538719",
    "end": "1543820"
  },
  {
    "text": "one direction ok so that's one thing that you can do with this kind of load balancer that you can't with application",
    "start": "1543820",
    "end": "1550059"
  },
  {
    "text": "level or load balancers and one thing as well is that s our v6 LV is more",
    "start": "1550059",
    "end": "1557019"
  },
  {
    "text": "scalable it can scale to 1 million flows and more because we have a system flow",
    "start": "1557019",
    "end": "1562929"
  },
  {
    "start": "1560000",
    "end": "1680000"
  },
  {
    "text": "table that is now open sourced in VPP so demo time right should be working great",
    "start": "1562929",
    "end": "1579549"
  },
  {
    "text": "it's not okay forgive me I will just restart my",
    "start": "1579549",
    "end": "1587989"
  },
  {
    "text": "small setup okay now we should should",
    "start": "1587989",
    "end": "1598129"
  },
  {
    "text": "start again so this demo is monitoring and controlling live a setup with one",
    "start": "1598129",
    "end": "1605179"
  },
  {
    "text": "load balancer and up to sixteen different servers those are nginx servers they are",
    "start": "1605179",
    "end": "1611809"
  },
  {
    "text": "basically computing PI decimals that's why you see the little PI's on the screen this is obviously pretty small",
    "start": "1611809",
    "end": "1619399"
  },
  {
    "text": "but it's kind it could scale up way much more than just sixteen servers and it could scale up to more load balancers",
    "start": "1619399",
    "end": "1626529"
  },
  {
    "text": "but it's enough to to prove the point that I want to make here so let me check",
    "start": "1626529",
    "end": "1632569"
  },
  {
    "text": "the parameters that I have I will just first switch to maglev and put my 16",
    "start": "1632569",
    "end": "1638749"
  },
  {
    "text": "servers here so does that work yeah so",
    "start": "1638749",
    "end": "1645319"
  },
  {
    "text": "here so you see the load balancer you see the different servers that are here and now if you have a look at this graph",
    "start": "1645319",
    "end": "1652969"
  },
  {
    "text": "here you have what Danny I explained earlier and what Marc mentioned as well is that with a simple consistent hashing",
    "start": "1652969",
    "end": "1659749"
  },
  {
    "text": "algorithm your are your requests are going to each servers that are fairly loaded that's that's a problem you have",
    "start": "1659749",
    "end": "1666619"
  },
  {
    "text": "with consistent hashing and that's why you have consistent hashing with bounded load now our approach also is plan I",
    "start": "1666619",
    "end": "1674839"
  },
  {
    "text": "mean also solves that and here you see the requests that are eating servers that are fairly loaded this here is the",
    "start": "1674839",
    "end": "1682549"
  },
  {
    "start": "1680000",
    "end": "1740000"
  },
  {
    "text": "load of the servers it's a bit messy it's like the one the graph that Marc showed before but it's going to be",
    "start": "1682549",
    "end": "1689089"
  },
  {
    "text": "clearer at the next step have a look as well at the response time I mean that's",
    "start": "1689089",
    "end": "1694399"
  },
  {
    "text": "what people care about it's the response time that you get by using a given type of load balancer so here I'm just going",
    "start": "1694399",
    "end": "1701719"
  },
  {
    "text": "to set a threshold which is the threshold load at which the the the the",
    "start": "1701719",
    "end": "1710719"
  },
  {
    "text": "agents the server agents are going to reject the connection so for now nothing happens we are still",
    "start": "1710719",
    "end": "1716659"
  },
  {
    "text": "using maglev I'm switching to SR he'll be singing trotting load balancer here",
    "start": "1716659",
    "end": "1723279"
  },
  {
    "text": "and you will see immediately all the servers that are receiving requests that",
    "start": "1723279",
    "end": "1730370"
  },
  {
    "text": "are loaded more that have more than four different outstanding requests at a time",
    "start": "1730370",
    "end": "1735380"
  },
  {
    "text": "are now going to send the connection to the next choice the next server sometime",
    "start": "1735380",
    "end": "1742520"
  },
  {
    "start": "1740000",
    "end": "1800000"
  },
  {
    "text": "as Mark mentioned you get unlucky twice but most of the time you don't and here",
    "start": "1742520",
    "end": "1747679"
  },
  {
    "text": "you see the difference you have almost no servers that are delivering weak requests and that are more loaded than",
    "start": "1747679",
    "end": "1754640"
  },
  {
    "text": "for outstanding connections at the time so you get the benefits that you would",
    "start": "1754640",
    "end": "1761090"
  },
  {
    "text": "get by using a load balancer that would know exactly the load of all the server's that's what that's the kind of",
    "start": "1761090",
    "end": "1766789"
  },
  {
    "text": "thing you could get with a layer seven load balancer or load balancer that pulls the state of the of the servers at",
    "start": "1766789",
    "end": "1775490"
  },
  {
    "text": "the same time but here you do it in a distributed way and the decisions are made instantaneously so like when a",
    "start": "1775490",
    "end": "1783320"
  },
  {
    "text": "server gets a request it doesn't make the decision of accepting or of accepting the connection based on some",
    "start": "1783320",
    "end": "1789200"
  },
  {
    "text": "information that it got like two or five seconds ago or ten seconds ago depending",
    "start": "1789200",
    "end": "1794690"
  },
  {
    "text": "on how good is your message forwarding mechanism that lets you retrieve your load of the server's here it's",
    "start": "1794690",
    "end": "1801169"
  },
  {
    "text": "instantaneous and it's specific to the application know so that's that's one",
    "start": "1801169",
    "end": "1807590"
  },
  {
    "text": "aspect you see the the performance improvement here well that's the spike that we get some time here we went from",
    "start": "1807590",
    "end": "1815200"
  },
  {
    "text": "three between three and four hundred milliseconds for the nineteenth percentile to less than less than 200 so",
    "start": "1815200",
    "end": "1823970"
  },
  {
    "text": "180 milliseconds for for the nineteenth percentile the median doesn't change",
    "start": "1823970",
    "end": "1831080"
  },
  {
    "text": "that much because we are not really improving the service servers are the same but we are better utilizing the CPU",
    "start": "1831080",
    "end": "1838190"
  },
  {
    "text": "of the server's we are more fair in our distribution one thing you can do from",
    "start": "1838190",
    "end": "1843200"
  },
  {
    "text": "there is reduce the number of servers so if I switch from 16 servers to 12 servers that's 25%",
    "start": "1843200",
    "end": "1851150"
  },
  {
    "text": "reduction in the number of servers here I switch to maglev again and well it's",
    "start": "1851150",
    "end": "1857150"
  },
  {
    "text": "not good it's not good because we don't with maglev or any kind of consistent hashing algorithm you need to kind of",
    "start": "1857150",
    "end": "1863600"
  },
  {
    "text": "over-provision the number of service that you have otherwise you explode and the response time is is real bad",
    "start": "1863600",
    "end": "1870409"
  },
  {
    "text": "but with SRB again since we are more fair you are able with 12 servers to",
    "start": "1870409",
    "end": "1879679"
  },
  {
    "text": "have basically the same response time than what we were having before well",
    "start": "1879679",
    "end": "1885230"
  },
  {
    "text": "it's now gone I'm going to show it again I will put 16 servers with maglev just",
    "start": "1885230",
    "end": "1893360"
  },
  {
    "text": "to to show that you get the same the same thing so here it's maglev with 16",
    "start": "1893360",
    "end": "1900860"
  },
  {
    "text": "servers right before it was SR and we with just 12 servers and the SLA the",
    "start": "1900860",
    "end": "1906890"
  },
  {
    "text": "response time is approximately the same and actually it's slightly better for SR",
    "start": "1906890",
    "end": "1912169"
  },
  {
    "text": "and we in that case so that's all for the demo I think Marc and I can answer a",
    "start": "1912169",
    "end": "1918470"
  },
  {
    "text": "few questions or I can also if you won't press buttons and and show you that it's",
    "start": "1918470",
    "end": "1924919"
  },
  {
    "text": "live and show you what's going on",
    "start": "1924919",
    "end": "1928120"
  },
  {
    "text": "[Applause]",
    "start": "1931640",
    "end": "1937669"
  },
  {
    "text": "I'm sorry you need vbp code running on",
    "start": "1943279",
    "end": "1948929"
  },
  {
    "text": "the server that is receiving these connections or does it just reject the connection so you need something that",
    "start": "1948929",
    "end": "1955289"
  },
  {
    "text": "would forward the connection when it's loaded doesn't need to be DVD it could be a different implementation but right now",
    "start": "1955289",
    "end": "1961769"
  },
  {
    "text": "our implementation is based on VP we",
    "start": "1961769",
    "end": "1982200"
  },
  {
    "text": "have it in VPP you know it'll eventually be be present in the in the networking",
    "start": "1982200",
    "end": "1988139"
  },
  {
    "text": "stacks but VPP makes it very convenient and Pierrot could show off how how fast",
    "start": "1988139",
    "end": "1996029"
  },
  {
    "text": "and awesome it is yeah if you want to know more by the way we have a we have a",
    "start": "1996029",
    "end": "2002330"
  },
  {
    "text": "booth at the Cisco booth we are showing this demo so if you want to know more about it and there also is a FDI yo",
    "start": "2002330",
    "end": "2008720"
  },
  {
    "text": "booth where you can learn more about VPP",
    "start": "2008720",
    "end": "2012700"
  },
  {
    "text": "so you're getting the information about the load in your Fastpass right yeah",
    "start": "2014350",
    "end": "2020299"
  },
  {
    "text": "isn't that dangerous because you're at the mercy of the application that give you the information that's why we use",
    "start": "2020299",
    "end": "2025519"
  },
  {
    "text": "shared memory oh so this is like the only option now you have other options actually the the one that we show is a",
    "start": "2025519",
    "end": "2031940"
  },
  {
    "text": "Linux C group for now this one is synchronous and is using a call to to",
    "start": "2031940",
    "end": "2037129"
  },
  {
    "text": "Linux but it's the only option if you want to make it very efficient is to use",
    "start": "2037129",
    "end": "2042139"
  },
  {
    "text": "share memory",
    "start": "2042139",
    "end": "2044590"
  },
  {
    "text": "in the case maybe it was the same with nginx but certainly with Apache when we",
    "start": "2047480",
    "end": "2053520"
  },
  {
    "text": "did the tests this is a it's a it's an API call that exists in Apache hmm",
    "start": "2053520",
    "end": "2059220"
  },
  {
    "text": "today we didn't have to modify it or anything we're just using this API that's specifically for load monitoring",
    "start": "2059220",
    "end": "2065340"
  },
  {
    "text": "it's just we're doing it in the data path it's a brand new world hi thanks",
    "start": "2065340",
    "end": "2085950"
  },
  {
    "text": "for the great talk I was wondering you mentioned that the label in the in the",
    "start": "2085950",
    "end": "2092638"
  },
  {
    "text": "last 64 bits can help you find the right CPU back on the reverse path yeah why",
    "start": "2092639",
    "end": "2100890"
  },
  {
    "start": "2100000",
    "end": "2160000"
  },
  {
    "text": "does it matter why why is it is it better to redirect from the well the CPU",
    "start": "2100890",
    "end": "2108900"
  },
  {
    "text": "the packet ends up to the right CPU and then to Nick so that's a very good",
    "start": "2108900",
    "end": "2114240"
  },
  {
    "text": "question it's because if you don't do that if you want two different cores to",
    "start": "2114240",
    "end": "2120930"
  },
  {
    "text": "operate on the same flow then your flow table as to use a lock you need locking between the two so it's",
    "start": "2120930",
    "end": "2128910"
  },
  {
    "text": "actually much more efficient to pay the price of handoff between the cores",
    "start": "2128910",
    "end": "2134400"
  },
  {
    "text": "sending the packet from to the right car it's going to make you make your implementation much more efficient",
    "start": "2134400",
    "end": "2140670"
  },
  {
    "text": "because you don't need to synchronize the different cores when they touch the flow table and you can also I think",
    "start": "2140670",
    "end": "2148700"
  },
  {
    "text": "scale better in terms of the sticky table the table that you have to keep",
    "start": "2148700",
    "end": "2154770"
  },
  {
    "text": "write the number of flows yes yeah the number of flows so if for example these were separate line cards",
    "start": "2154770",
    "end": "2161970"
  },
  {
    "start": "2160000",
    "end": "2220000"
  },
  {
    "text": "in a system or something like that separate into use with their own memory each could use its own flow table memory",
    "start": "2161970",
    "end": "2168450"
  },
  {
    "text": "separately rather than having to use some shared memory and scale horizontally like that if you",
    "start": "2168450",
    "end": "2176450"
  },
  {
    "text": "deterministically know you can always get two the the right line card or into you or",
    "start": "2176450",
    "end": "2183990"
  },
  {
    "text": "what have you because it's just a routing decision to get to the right one because of that cpu index it's part of",
    "start": "2183990",
    "end": "2190320"
  },
  {
    "text": "the address so I could literally route to the right part of the distributed system and and have just the table there",
    "start": "2190320",
    "end": "2198300"
  },
  {
    "text": "that I need right yeah okay so if a server is starting to get loaded and",
    "start": "2198300",
    "end": "2204480"
  },
  {
    "text": "it's forwarding more and more connections or more more flows - it's sort of second one in the chain and then",
    "start": "2204480",
    "end": "2209609"
  },
  {
    "text": "goes down does that also break all flows to the second server right so the that",
    "start": "2209609",
    "end": "2217560"
  },
  {
    "text": "was mentioned by mark it's well it's based on this result the power of two choices again if you get you can get",
    "start": "2217560",
    "end": "2224640"
  },
  {
    "start": "2220000",
    "end": "2280000"
  },
  {
    "text": "unlucky not once that's what we used to say you can get unlucky once you have a certain probability of hitting a server that is really loaded when that happens",
    "start": "2224640",
    "end": "2232080"
  },
  {
    "text": "you forward the probability that you get unlucky twice is you know exponentially decreasing and so the question I have is",
    "start": "2232080",
    "end": "2239220"
  },
  {
    "text": "if this if the first server in the chain then goes down does that interrupt flows that are what that we're being forwarded",
    "start": "2239220",
    "end": "2244440"
  },
  {
    "text": "to the second server in the chain so you're supposed to detect that and the",
    "start": "2244440",
    "end": "2249990"
  },
  {
    "text": "load balancer but I think the answer is simply no unless we're in recovery mode ability to know the load so load",
    "start": "2249990",
    "end": "2256859"
  },
  {
    "text": "balancer I try this server bounce to the next server yeah I install State for",
    "start": "2256859",
    "end": "2262980"
  },
  {
    "text": "that server for the life of that flow okay the second one if the first one goes down I'm still routing packets just",
    "start": "2262980",
    "end": "2269670"
  },
  {
    "text": "to the first one for the life of that flow let me do the second one yeah that that's an important I didn't mention that the the fact that we goes through",
    "start": "2269670",
    "end": "2276060"
  },
  {
    "text": "two servers only happens on the scene packet or the very first beginning of",
    "start": "2276060",
    "end": "2281700"
  },
  {
    "start": "2280000",
    "end": "2330000"
  },
  {
    "text": "the function yeah and then it's direct yes sorry so in the router the or the",
    "start": "2281700",
    "end": "2287460"
  },
  {
    "text": "the sorry the load balancer I say router because I guess I work at Cisco but the the load balancer that's directing it",
    "start": "2287460",
    "end": "2294150"
  },
  {
    "text": "the right way is minoo is unaware of the",
    "start": "2294150",
    "end": "2300300"
  },
  {
    "text": "start of the flow per se that's up to the application to to to tell it that's",
    "start": "2300300",
    "end": "2305580"
  },
  {
    "text": "the beginning of the flow that's what some of these bits that we use and it's like installing a it's like installing a",
    "start": "2305580",
    "end": "2311490"
  },
  {
    "text": "hosts route if you will dynamically and then removing it at the beginning and end of the flow okay",
    "start": "2311490",
    "end": "2318430"
  },
  {
    "text": "so once it's sticky and pointing to the right place the other server can go down anything else I guess is a keynote",
    "start": "2318430",
    "end": "2325710"
  },
  {
    "text": "coming up thank you very much thank you very much thank you here",
    "start": "2325710",
    "end": "2331740"
  }
]
[
  {
    "text": "um all right so I think it's about get to the time um and let's get started okay",
    "start": "960",
    "end": "7440"
  },
  {
    "text": "so I'll connect this talk in English um since since we have some foreign guests here",
    "start": "7440",
    "end": "13440"
  },
  {
    "text": "um my name is Chan and today I'm going to talk to you about how we use large",
    "start": "13440",
    "end": "18779"
  },
  {
    "text": "language models to help us to Simply to simplify our cluster management",
    "start": "18779",
    "end": "25640"
  },
  {
    "text": "um a little introduction about me um I started my career at Google as an",
    "start": "25859",
    "end": "31019"
  },
  {
    "text": "SRE and in 2019 I moved to ant group to become a tech lead and manager for",
    "start": "31019",
    "end": "37380"
  },
  {
    "text": "infrastructure as I team basically I focused on say kubernetes and other Cloud native",
    "start": "37380",
    "end": "45059"
  },
  {
    "text": "like Solutions in Hand Group as an SRE we wear different hats during our",
    "start": "45059",
    "end": "50700"
  },
  {
    "text": "day-to-day life such as say we write automation programs to say to optimize",
    "start": "50700",
    "end": "56100"
  },
  {
    "text": "our like toils and operations right and sometimes we do like firefightings to",
    "start": "56100",
    "end": "63239"
  },
  {
    "text": "handle production issues and in the past few years we've seen a",
    "start": "63239",
    "end": "68340"
  },
  {
    "text": "huge growth in our like cluster size as well as the plus size but still we remain very fixed SRE head count so that",
    "start": "68340",
    "end": "76860"
  },
  {
    "text": "means we need to seek any uh every help we have to help us to facilitate our",
    "start": "76860",
    "end": "83640"
  },
  {
    "text": "day-to-day life and this year I believe like language model is a Hot Topic so we",
    "start": "83640",
    "end": "90900"
  },
  {
    "text": "are trying to tackle this issue with language models okay so before we get into the details",
    "start": "90900",
    "end": "98040"
  },
  {
    "text": "um I want to quickly clarify that this talk is not about like gpt101 course I'm",
    "start": "98040",
    "end": "104100"
  },
  {
    "text": "not going to touch any pre-training steps or any other like algorithms for supervised fine tuning",
    "start": "104100",
    "end": "111659"
  },
  {
    "text": "like pfts and I know launching is kind of popular these days so but this is not a",
    "start": "111659",
    "end": "118079"
  },
  {
    "text": "launching tutorial and this project has nothing to do with kubernetes GPT project on GitHub oh",
    "start": "118079",
    "end": "126119"
  },
  {
    "text": "um you know in SRE what land we handle a lot about failures and incident stories",
    "start": "126119",
    "end": "132500"
  },
  {
    "text": "so please think about this as a postmodern review or a progress report",
    "start": "132500",
    "end": "138140"
  },
  {
    "text": "on our exploration to language models instead of any like best practice",
    "start": "138140",
    "end": "143700"
  },
  {
    "text": "there's no best practice at this point of time I think okay I will conduct this talk in the",
    "start": "143700",
    "end": "150720"
  },
  {
    "text": "following four sections I'll quickly go through our motivations about why we are",
    "start": "150720",
    "end": "156540"
  },
  {
    "text": "going to use language models and I will then do a quick definition on our",
    "start": "156540",
    "end": "162120"
  },
  {
    "text": "goals and requirements and comes to our fun part about how we conduct different",
    "start": "162120",
    "end": "167280"
  },
  {
    "text": "experiments or attempts to solve the issue and hopefully you guys can or take",
    "start": "167280",
    "end": "172379"
  },
  {
    "text": "some like um get some idea and get some takeaways",
    "start": "172379",
    "end": "177980"
  },
  {
    "text": "all right so remember the topic today is about cluster management and",
    "start": "178200",
    "end": "185160"
  },
  {
    "text": "here's our motivation so imagine on a typical day like when",
    "start": "185160",
    "end": "190200"
  },
  {
    "text": "you just sit down on in front of a desk with a cup of coffee and your pager just got alerted and it",
    "start": "190200",
    "end": "198060"
  },
  {
    "text": "says multiple clusters were on fire and some nodes will kept getting OMD and",
    "start": "198060",
    "end": "205260"
  },
  {
    "text": "apparently this time you have no choice but to jump into a war room to solve the issue because",
    "start": "205260",
    "end": "210780"
  },
  {
    "text": "multiple Business Leaders was already yelling at you say their business was getting batted",
    "start": "210780",
    "end": "218099"
  },
  {
    "text": "and your big boss he was watching behind you and asking you for the reason for",
    "start": "218099",
    "end": "224760"
  },
  {
    "text": "the mitigation steps and Etc so you are desperate to find out okay so",
    "start": "224760",
    "end": "231599"
  },
  {
    "text": "what are the correlations between these nodes right are they offering a specific CPU model or if they own a specific kind",
    "start": "231599",
    "end": "239459"
  },
  {
    "text": "of version or a particular type of application was running on top of them",
    "start": "239459",
    "end": "245459"
  },
  {
    "text": "and you have a millionaire assumptions here and you would like to quickly verify them",
    "start": "245459",
    "end": "251040"
  },
  {
    "text": "but I highly doubt that on the height such high pressure and under such like",
    "start": "251040",
    "end": "257100"
  },
  {
    "text": "emergency scenarios you can type those 2.0 commands correctly in a single pass",
    "start": "257100",
    "end": "263040"
  },
  {
    "text": "and so that's why that's the first motivation and it took us about an hour to actually",
    "start": "263040",
    "end": "270600"
  },
  {
    "text": "figure out in this particular case it was from demons that change that",
    "start": "270600",
    "end": "276419"
  },
  {
    "text": "actually has some performance issue on a certain typical CPU model",
    "start": "276419",
    "end": "282419"
  },
  {
    "text": "okay so in the post-modern review one action item we agreed was to how can we",
    "start": "282419",
    "end": "291060"
  },
  {
    "text": "shorten the time to pinpoint or to locate the problem right at that point",
    "start": "291060",
    "end": "296460"
  },
  {
    "text": "of time actually multiple Tech leaders joined the war room and say contribute",
    "start": "296460",
    "end": "302280"
  },
  {
    "text": "very thoughtful and very very valuable information and their assumptions",
    "start": "302280",
    "end": "308040"
  },
  {
    "text": "but they are not from the kubernetes team so they cannot actually get into",
    "start": "308040",
    "end": "313139"
  },
  {
    "text": "the touch with the cluster management but their ideas were actually valid so",
    "start": "313139",
    "end": "318600"
  },
  {
    "text": "we need a solution to help them to let them can do some quick self-service like",
    "start": "318600",
    "end": "324380"
  },
  {
    "text": "mitigation or their verification by themselves and also like",
    "start": "324380",
    "end": "330660"
  },
  {
    "text": "during the mitigation stage on this incident we have to ask users to do some",
    "start": "330660",
    "end": "337800"
  },
  {
    "text": "self-service operations like to scale up their deployment or to do some node",
    "start": "337800",
    "end": "343560"
  },
  {
    "text": "reboot and some traffic drains so these actions were actually not that",
    "start": "343560",
    "end": "349500"
  },
  {
    "text": "frequently used in their day-to-day life right so they cannot remember all those",
    "start": "349500",
    "end": "355800"
  },
  {
    "text": "commands correctly or like and quickly pull out all those knowledge they need",
    "start": "355800",
    "end": "361740"
  },
  {
    "text": "so we categorize this type of issue as the operational efficiency",
    "start": "361740",
    "end": "367280"
  },
  {
    "text": "in the entire picture of the cluster management world as you can see it may",
    "start": "367280",
    "end": "373199"
  },
  {
    "text": "just be a tip of the iceberg and we are facing many different challenges",
    "start": "373199",
    "end": "379139"
  },
  {
    "text": "I think each topic listed out here actually was a separate discussion but",
    "start": "379139",
    "end": "385979"
  },
  {
    "text": "Let's do let's be more concentrated today so",
    "start": "385979",
    "end": "391639"
  },
  {
    "text": "let's go to the definition part so remember um I think for for us like we conclude that",
    "start": "392340",
    "end": "400500"
  },
  {
    "text": "what we need is actually um a solution to help us can quickly",
    "start": "400500",
    "end": "406020"
  },
  {
    "text": "transfer like human intention or human language to like um",
    "start": "406020",
    "end": "411060"
  },
  {
    "text": "actually machine API calls or whatever can interact with the machine directly right in the operational world",
    "start": "411060",
    "end": "418800"
  },
  {
    "text": "everything is just like a command to a specific system or like sending an API",
    "start": "418800",
    "end": "424380"
  },
  {
    "text": "core or just tuning some like kernel like parameters right",
    "start": "424380",
    "end": "429720"
  },
  {
    "text": "all those datas are actually structural data but human intentions we have a million",
    "start": "429720",
    "end": "435240"
  },
  {
    "text": "or a thousand way to express them so what can we feel in this question",
    "start": "435240",
    "end": "440880"
  },
  {
    "text": "mark here so before the language model like becomes a Hot Topic I think like we",
    "start": "440880",
    "end": "448740"
  },
  {
    "text": "write all those automation programs we write all the like past web fronts and all the solutions uh you have like um a",
    "start": "448740",
    "end": "456960"
  },
  {
    "text": "web a website with a bunch of clicks and buttons and you just type in your",
    "start": "456960",
    "end": "462060"
  },
  {
    "text": "um so some parameters so that you can get for example try to reboot your node or",
    "start": "462060",
    "end": "468720"
  },
  {
    "text": "try to scale up your deployment so in this scenario I think",
    "start": "468720",
    "end": "475340"
  },
  {
    "text": "we are actually writing a user interface and that user interface actually does",
    "start": "475340",
    "end": "480539"
  },
  {
    "text": "the translation between the unstructured data like between our Our intention to",
    "start": "480539",
    "end": "487139"
  },
  {
    "text": "this to what the machine or the cluster management actually need the apis right",
    "start": "487139",
    "end": "493080"
  },
  {
    "text": "and since language models naturally takes the human language as an input so",
    "start": "493080",
    "end": "499319"
  },
  {
    "text": "we think okay maybe let's just try that let's use a language model for to be the",
    "start": "499319",
    "end": "505199"
  },
  {
    "text": "new user interface but using that in the Sie land is kind",
    "start": "505199",
    "end": "511560"
  },
  {
    "text": "of like dangerous as you can see like we categorize the issue into um to use that",
    "start": "511560",
    "end": "517620"
  },
  {
    "text": "we have to be very careful about the input and the output from the language generated by the",
    "start": "517620",
    "end": "522959"
  },
  {
    "text": "language model right I think they we listed out the four",
    "start": "522959",
    "end": "528180"
  },
  {
    "text": "different criterias we need to verify if a model is valid and can be used in",
    "start": "528180",
    "end": "534300"
  },
  {
    "text": "production and first is about accuracy the accuracy here is actually we have a",
    "start": "534300",
    "end": "540779"
  },
  {
    "text": "very high standard I think it's about above 99 accuracy remember like you are",
    "start": "540779",
    "end": "547860"
  },
  {
    "text": "actually operating with the cluster right if you want to reboot a single node a but the language model generated",
    "start": "547860",
    "end": "554760"
  },
  {
    "text": "the answer to reboot the node B it will be totally unacceptable right and also like the latency I think it's",
    "start": "554760",
    "end": "562320"
  },
  {
    "text": "we actually all want this this thing to happen really fast right otherwise you may miss the window to actually mitigate",
    "start": "562320",
    "end": "569040"
  },
  {
    "text": "the issue I know like if we experience some like online like strategy video or",
    "start": "569040",
    "end": "575700"
  },
  {
    "text": "whatever all those chat models um sometimes the latency can be a little high which is not that acceptable in our",
    "start": "575700",
    "end": "584519"
  },
  {
    "text": "scenario and also like for the security concern we are not going to share our",
    "start": "584519",
    "end": "590220"
  },
  {
    "text": "internal data to like any public models right you are not going to handle in your like internal security",
    "start": "590220",
    "end": "596180"
  },
  {
    "text": "it will be it will be very vulnerable right so we have to like use our own",
    "start": "596180",
    "end": "602519"
  },
  {
    "text": "model and at least we need to host it by ourselves",
    "start": "602519",
    "end": "607740"
  },
  {
    "text": "and for all those internal apis and for all those like our internal operations they are like involving really fast and",
    "start": "607740",
    "end": "615839"
  },
  {
    "text": "language model has to like keep up with the pace of the API involvement so",
    "start": "615839",
    "end": "621000"
  },
  {
    "text": "that's the fourth criteria okay so enough for the abstraction on",
    "start": "621000",
    "end": "627060"
  },
  {
    "text": "this type of problem and now comes the fun part so next I will share some",
    "start": "627060",
    "end": "632660"
  },
  {
    "text": "experiments we did to play with the language model",
    "start": "632660",
    "end": "637699"
  },
  {
    "text": "so the first the first attempt is about to do like API invocation",
    "start": "638580",
    "end": "643860"
  },
  {
    "text": "by the time we had this idea I think at that point Lane chain and",
    "start": "643860",
    "end": "650040"
  },
  {
    "text": "auto GPT was attracting everyone's attention and so",
    "start": "650040",
    "end": "655260"
  },
  {
    "text": "everyone was talking about how can we make an agent to learn to use some tools to help us to solve a particular",
    "start": "655260",
    "end": "663000"
  },
  {
    "text": "like two main issues in a domain right so let's make an agent that can solve",
    "start": "663000",
    "end": "668100"
  },
  {
    "text": "the issue for kubernetes so we quickly drew the following diagram to express the",
    "start": "668100",
    "end": "675600"
  },
  {
    "text": "the workflow or so when SRE speaks some language to express their intention it can go",
    "start": "675600",
    "end": "682980"
  },
  {
    "text": "through a planner model which is a language model that can help you to um",
    "start": "682980",
    "end": "688079"
  },
  {
    "text": "to plan the actions and the actions can be executed by different executors and",
    "start": "688079",
    "end": "694019"
  },
  {
    "text": "each executor is corresponding to a deterministic API call or",
    "start": "694019",
    "end": "700200"
  },
  {
    "text": "a function that can interact with the machines directly okay",
    "start": "700200",
    "end": "705540"
  },
  {
    "text": "so so far so good okay and by the time we had that idea",
    "start": "705540",
    "end": "711019"
  },
  {
    "text": "we already like um we had a jump start we at that point of time we already",
    "start": "711019",
    "end": "718200"
  },
  {
    "text": "deployed a chatbot we call it the op spot",
    "start": "718200",
    "end": "724380"
  },
  {
    "text": "in our like in our production to help our own color to try to solve their",
    "start": "724380",
    "end": "730459"
  },
  {
    "text": "on-call issues so what we had at the point of time was",
    "start": "730459",
    "end": "735839"
  },
  {
    "text": "like if you say there was an alert fired and you got notified and",
    "start": "735839",
    "end": "741720"
  },
  {
    "text": "you would like to do a simple restart and you just type in the chatbot say",
    "start": "741720",
    "end": "747000"
  },
  {
    "text": "okay so restart dash dash component API server dash cluster full",
    "start": "747000",
    "end": "753300"
  },
  {
    "text": "so that the support will do the restart for you",
    "start": "753300",
    "end": "758459"
  },
  {
    "text": "but at that point of time we had already deployed this spot in production for at",
    "start": "758459",
    "end": "765779"
  },
  {
    "text": "least a year but it was not frequently used and people were people don't like it",
    "start": "765779",
    "end": "773339"
  },
  {
    "text": "because they cannot remember all those commands correctly and they cannot type",
    "start": "773339",
    "end": "779820"
  },
  {
    "text": "those um command like in uh in a single pass",
    "start": "779820",
    "end": "785160"
  },
  {
    "text": "so here comes the language model right you would like to naturally think okay so if I can say just say help me do a",
    "start": "785160",
    "end": "791399"
  },
  {
    "text": "simple restart and the model can understand and extract the uh named entity let's say the component entity",
    "start": "791399",
    "end": "798300"
  },
  {
    "text": "called API server and cluster entity and then filling the API call and just make",
    "start": "798300",
    "end": "806100"
  },
  {
    "text": "the call okay so I think the workflow is kind of very",
    "start": "806100",
    "end": "811440"
  },
  {
    "text": "straightforward but we quickly hit our like bottleneck which is we cannot use",
    "start": "811440",
    "end": "817740"
  },
  {
    "text": "the open models because open models does not have the internal Knowledge from our",
    "start": "817740",
    "end": "823139"
  },
  {
    "text": "perspective right so you don't know how we in end group how we do like models machine restart or how we form our apis",
    "start": "823139",
    "end": "831000"
  },
  {
    "text": "right we have to teach them but for security concerns we cannot actually use the uh the open I open AI",
    "start": "831000",
    "end": "839279"
  },
  {
    "text": "or the charge BT and luckily at that point of time we already started our like internal",
    "start": "839279",
    "end": "846120"
  },
  {
    "text": "language model development so we already had some like internal models to do like",
    "start": "846120",
    "end": "853680"
  },
  {
    "text": "supervised fine-tuning on top of them to see the result so the question next is to generate all",
    "start": "853680",
    "end": "861120"
  },
  {
    "text": "those training data you need right as you can see the training data was about",
    "start": "861120",
    "end": "866279"
  },
  {
    "text": "like a bunch of clustering answer pairs where I can write some templates in a prompt",
    "start": "866279",
    "end": "872760"
  },
  {
    "text": "and say okay so restart the node or have different different ways to re to",
    "start": "872760",
    "end": "877860"
  },
  {
    "text": "express this single action right and you have that very fixed action format",
    "start": "877860",
    "end": "885060"
  },
  {
    "text": "to fit into one to filling the model and you then just replace the node with",
    "start": "885060",
    "end": "890880"
  },
  {
    "text": "different entities into my so here's our first experiment we picked",
    "start": "890880",
    "end": "898680"
  },
  {
    "text": "about 10 apis from our like up spot such",
    "start": "898680",
    "end": "903720"
  },
  {
    "text": "as like scale up your deployment or reboot a single node or like say help me",
    "start": "903720",
    "end": "911459"
  },
  {
    "text": "retrieve the supports in a specific namespace and then we generate about like 40 000",
    "start": "911459",
    "end": "919320"
  },
  {
    "text": "equestrian answered pairs as the training data for our fine tuning",
    "start": "919320",
    "end": "924360"
  },
  {
    "text": "and we then use like five different model candidates and we throw the data in and hopefully to see",
    "start": "924360",
    "end": "930480"
  },
  {
    "text": "to see magic happen and it did happen and we picked three models at that point I don't think",
    "start": "930480",
    "end": "937320"
  },
  {
    "text": "called Llama Or llama2 was available so we use gbd new and some gbdj as a",
    "start": "937320",
    "end": "943560"
  },
  {
    "text": "benchmark and we have our internal models to do fine-tuning as well",
    "start": "943560",
    "end": "950519"
  },
  {
    "text": "so as you can see it did help us to like extract the named entity like the IP is",
    "start": "950519",
    "end": "956760"
  },
  {
    "text": "like the uh the pause and like the name place as well and also it can classify",
    "start": "956760",
    "end": "962459"
  },
  {
    "text": "the intention like in a very good accuracy so we quickly like made a prototype and",
    "start": "962459",
    "end": "969420"
  },
  {
    "text": "replaced our chatbot with this language model",
    "start": "969420",
    "end": "973940"
  },
  {
    "text": "however when we ask the user feedback um it was not that good",
    "start": "974459",
    "end": "980339"
  },
  {
    "text": "actually the model failed in multiple aspects and",
    "start": "980339",
    "end": "985920"
  },
  {
    "text": "one thing that it failed to comprehend different constraints set by the users when curing for",
    "start": "985920",
    "end": "991680"
  },
  {
    "text": "kubernetes resources I'll give you a few examples and let's",
    "start": "991680",
    "end": "997500"
  },
  {
    "text": "say okay so you know users may ask help me retrieve the parts in a pending status plus the pause has been there for",
    "start": "997500",
    "end": "1006139"
  },
  {
    "text": "for hours or they want to get all nodes in a specific conversion or they",
    "start": "1006139",
    "end": "1013579"
  },
  {
    "text": "have all these kind of strange questions that you cannot enumerate all of them in your training data right",
    "start": "1013579",
    "end": "1020060"
  },
  {
    "text": "so I don't know if any one of you can write",
    "start": "1020060",
    "end": "1025880"
  },
  {
    "text": "a single Cube control command to get all these information at least I can't so",
    "start": "1025880",
    "end": "1034100"
  },
  {
    "text": "but let's see so someone in my team said okay maybe we just try to train a model",
    "start": "1034100",
    "end": "1039260"
  },
  {
    "text": "right to translate the human intention to to the cube control commands plus some like shell script like to do some",
    "start": "1039260",
    "end": "1045918"
  },
  {
    "text": "grab to do some awk to get the result but these ideas got quickly vetoed",
    "start": "1045919",
    "end": "1053840"
  },
  {
    "text": "because for the several reasons first I think shell scripts are less",
    "start": "1053840",
    "end": "1059299"
  },
  {
    "text": "structured and it is too like flexible and too powerful it can actually",
    "start": "1059299",
    "end": "1064640"
  },
  {
    "text": "generate malicious data and can be dangerous if you blindly trust the output for example what if it generated command",
    "start": "1064640",
    "end": "1071900"
  },
  {
    "text": "say queue control delete Port all namespace right so it will be doomed",
    "start": "1071900",
    "end": "1078500"
  },
  {
    "text": "and it's hard to validate right how can you evaluate if this JavaScript you have",
    "start": "1078500",
    "end": "1084020"
  },
  {
    "text": "a million ways to write a to get the same same result like in in JavaScript",
    "start": "1084020",
    "end": "1089419"
  },
  {
    "text": "right so at that point of time um",
    "start": "1089419",
    "end": "1094820"
  },
  {
    "text": "we had another like idea from our current team our DBA team they had this called dbgbt",
    "start": "1094820",
    "end": "1102380"
  },
  {
    "text": "this idea so the idea is about to translate human intention like in text to SQL language",
    "start": "1102380",
    "end": "1111919"
  },
  {
    "text": "so we think okay what if we can query kubernetes resources like what we do",
    "start": "1111919",
    "end": "1117760"
  },
  {
    "text": "using a SQL format because SQL format can be more",
    "start": "1117760",
    "end": "1122900"
  },
  {
    "text": "controllable and auditable right and we have so many like SQL data that we can",
    "start": "1122900",
    "end": "1128539"
  },
  {
    "text": "use to do like fine-tuning or do model training so we had our prototype and we say okay",
    "start": "1128539",
    "end": "1137419"
  },
  {
    "text": "what if we can do this like instead of letting the language model to query the",
    "start": "1137419",
    "end": "1143840"
  },
  {
    "text": "cluster directly let's add a cache layer so the cash layer was like a controller and followed",
    "start": "1143840",
    "end": "1151760"
  },
  {
    "text": "by the list watch concept that you can actually cache all the parts or the",
    "start": "1151760",
    "end": "1156980"
  },
  {
    "text": "nodes all the resources you want and we do some tricks to convert them to like to the format says SQL engine can",
    "start": "1156980",
    "end": "1164059"
  },
  {
    "text": "understand and can retrieve the data and that's when we can get some like",
    "start": "1164059",
    "end": "1169820"
  },
  {
    "text": "table schema from SQL right from the database schemas and together with the user's question",
    "start": "1169820",
    "end": "1175460"
  },
  {
    "text": "and their intention together with the table schema we throw them to the language model and hopefully it can",
    "start": "1175460",
    "end": "1181940"
  },
  {
    "text": "generate the SQL that can be used to retrieve the data okay so because of the time limit I",
    "start": "1181940",
    "end": "1189380"
  },
  {
    "text": "won't get into how we do the SQL conversion here today but we can do it like offline or in another time",
    "start": "1189380",
    "end": "1197539"
  },
  {
    "text": "so we have this idea and we have this prototype but still we",
    "start": "1197539",
    "end": "1204919"
  },
  {
    "text": "are the users were still not buying it because there are still too many",
    "start": "1204919",
    "end": "1210799"
  },
  {
    "text": "knowledges internal knowledges that are represented by let's say the labels and",
    "start": "1210799",
    "end": "1216320"
  },
  {
    "text": "annotations on those parts you know like everyone is especially for all those",
    "start": "1216320",
    "end": "1221840"
  },
  {
    "text": "custom controllers or The Operators they love to patch like labels and annotations on those parts and notes to",
    "start": "1221840",
    "end": "1229280"
  },
  {
    "text": "make some special and give them like different meanings so it seems like we get stuck here",
    "start": "1229280",
    "end": "1236780"
  },
  {
    "text": "so what can we do how can we like improve this so let's go back to some Basics so at",
    "start": "1236780",
    "end": "1244940"
  },
  {
    "text": "that point of time we say okay let's take a step back and let's see test how Tesla capability",
    "start": "1244940",
    "end": "1253640"
  },
  {
    "text": "of the language model so we run two simple tests one simple test",
    "start": "1253640",
    "end": "1259520"
  },
  {
    "text": "is to say given a yaml snippet can a language model actually say extract the",
    "start": "1259520",
    "end": "1265340"
  },
  {
    "text": "targeted value based on the label's name I think this is a very decent and very",
    "start": "1265340",
    "end": "1271160"
  },
  {
    "text": "simple task right it's just a key value lookup and so we quickly like say generated some",
    "start": "1271160",
    "end": "1279860"
  },
  {
    "text": "synthetic data like this is snippet and we generate a bunch of questions either",
    "start": "1279860",
    "end": "1285500"
  },
  {
    "text": "asking like one label value two label values or mix a bunch of",
    "start": "1285500",
    "end": "1291620"
  },
  {
    "text": "and to see the results and we use the our internal model to do like fine-tuning to",
    "start": "1291620",
    "end": "1298039"
  },
  {
    "text": "to test it okay so this table and diagrams here",
    "start": "1298039",
    "end": "1304460"
  },
  {
    "text": "actually different people can have different interpretation from that and",
    "start": "1304460",
    "end": "1309559"
  },
  {
    "text": "our Insight from our Insight one thing is that the model's accuracy actually is determined by the coverage of the",
    "start": "1309559",
    "end": "1316580"
  },
  {
    "text": "training samples um what does it mean so about if the model can learn like 60 of",
    "start": "1316580",
    "end": "1325220"
  },
  {
    "text": "the label like in the training data for the rest of the 40 if the if the label itself",
    "start": "1325220",
    "end": "1332299"
  },
  {
    "text": "was not shown in the training data set it can still like recognize them and",
    "start": "1332299",
    "end": "1337640"
  },
  {
    "text": "successfully extract the value with a very high accuracy so that means",
    "start": "1337640",
    "end": "1343159"
  },
  {
    "text": "like the models are not just memorizing everything and it does have the ability",
    "start": "1343159",
    "end": "1348980"
  },
  {
    "text": "to learn a pattern so that gives us confidence but in reality I don't think anyone's",
    "start": "1348980",
    "end": "1356419"
  },
  {
    "text": "gonna going to ask this question to the model right you can just do it by yourself or just do simple graph to get",
    "start": "1356419",
    "end": "1363620"
  },
  {
    "text": "the answer but what if we ask if the language model can",
    "start": "1363620",
    "end": "1368960"
  },
  {
    "text": "extract the target value based on the label's meaning instead instead of by",
    "start": "1368960",
    "end": "1374000"
  },
  {
    "text": "the label's name right so here I'll give another example let's say there is another like custom key",
    "start": "1374000",
    "end": "1380840"
  },
  {
    "text": "called XYZ as a label and there's the background knowledge here let's say if",
    "start": "1380840",
    "end": "1387260"
  },
  {
    "text": "that label means support is able to survive during a short-term system blip",
    "start": "1387260",
    "end": "1393500"
  },
  {
    "text": "okay so when the user asks if the port is going to survive during a couplet hot",
    "start": "1393500",
    "end": "1399860"
  },
  {
    "text": "update which is like a short-term system blip right the model should be able to",
    "start": "1399860",
    "end": "1405140"
  },
  {
    "text": "answer with yes okay then we um",
    "start": "1405140",
    "end": "1410539"
  },
  {
    "text": "we do another experiment in this scenario like but due to the",
    "start": "1410539",
    "end": "1416600"
  },
  {
    "text": "time limit I won't get into much details but in this time I think launching Frameworks was already popular and were",
    "start": "1416600",
    "end": "1424940"
  },
  {
    "text": "so we try to use that and so to combine the background knowledge so we use some background knowledge plus with the yaml",
    "start": "1424940",
    "end": "1432679"
  },
  {
    "text": "data plus with the user question and filling them to generate a bunch of like training data to train our internal",
    "start": "1432679",
    "end": "1439640"
  },
  {
    "text": "model and also we know like everyone says there is a new job called",
    "start": "1439640",
    "end": "1446179"
  },
  {
    "text": "prompting prompt engineer right so we try different prompt techniques for example like the Chain of Thought They",
    "start": "1446179",
    "end": "1453500"
  },
  {
    "text": "do actually help to get the results better for example as you can see um",
    "start": "1453500",
    "end": "1460039"
  },
  {
    "text": "no matter which on the model size whether it's a 1.3 billion model size or 6 billion model",
    "start": "1460039",
    "end": "1466460"
  },
  {
    "text": "size with the CLT and the memory and the background knowledge I can actually",
    "start": "1466460",
    "end": "1471919"
  },
  {
    "text": "answer the question better especially for those labels and keys the model",
    "start": "1471919",
    "end": "1477020"
  },
  {
    "text": "doesn't see in the training data okay so putting things together right so here",
    "start": "1477020",
    "end": "1484340"
  },
  {
    "text": "is our final solution to say how can you use language model to cure a single",
    "start": "1484340",
    "end": "1489500"
  },
  {
    "text": "kubernetes Resources with different user constraints and set up so what we have here like we have a",
    "start": "1489500",
    "end": "1496700"
  },
  {
    "text": "prompt engine so I can do different prompting strategy like chain of thoughts or self-consistency or anything",
    "start": "1496700",
    "end": "1503419"
  },
  {
    "text": "you can mention and the engine can actually interact with our internal knowledge database",
    "start": "1503419",
    "end": "1509419"
  },
  {
    "text": "which can fetch corresponding like background knowledge with the user's input right together",
    "start": "1509419",
    "end": "1517100"
  },
  {
    "text": "with the parts SQL table schema we can send them to the language model to get",
    "start": "1517100",
    "end": "1523280"
  },
  {
    "text": "back the SQL itself and then on the",
    "start": "1523280",
    "end": "1529100"
  },
  {
    "text": "caching and the uh the kubernetes part we also add a federation layer so that",
    "start": "1529100",
    "end": "1536299"
  },
  {
    "text": "we can only not only can we like just query for one single cluster but also we",
    "start": "1536299",
    "end": "1542000"
  },
  {
    "text": "can curiously across multiple clusters so that's our final design here",
    "start": "1542000",
    "end": "1548419"
  },
  {
    "text": "all right so a quick summary",
    "start": "1548419",
    "end": "1553700"
  },
  {
    "text": "um so what have we have we achieved so far so remember like in our experiment uh no",
    "start": "1553700",
    "end": "1560720"
  },
  {
    "text": "matter it's um like API invocation or the Google could control like get",
    "start": "1560720",
    "end": "1565940"
  },
  {
    "text": "command I think language model has the potential to be a good SRE pilot",
    "start": "1565940",
    "end": "1572659"
  },
  {
    "text": "and it can it has already demonstrated its capability to do named entity",
    "start": "1572659",
    "end": "1578480"
  },
  {
    "text": "recognition as well as like intention classification and the fourth is very specific tasks I",
    "start": "1578480",
    "end": "1585620"
  },
  {
    "text": "don't think you need a like a 100 billion size model or a smaller",
    "start": "1585620",
    "end": "1591380"
  },
  {
    "text": "model may already be enough for this type of case but",
    "start": "1591380",
    "end": "1597320"
  },
  {
    "text": "still like remember our tasks is to operate the cluster right but at this",
    "start": "1597320",
    "end": "1603799"
  },
  {
    "text": "point of time I don't think language model itself can operate a cluster right by itself",
    "start": "1603799",
    "end": "1609559"
  },
  {
    "text": "still in the East California education and humans needs to be to do like re-evaluation so it can be a good",
    "start": "1609559",
    "end": "1617120"
  },
  {
    "text": "copilot help you to generate the command quickly or help you to like say write a",
    "start": "1617120",
    "end": "1623299"
  },
  {
    "text": "bunch of SQL or write a bunch of configuration code but let's not be that creative right because",
    "start": "1623299",
    "end": "1631460"
  },
  {
    "text": "in our scenario we want operational efficiency we want productivity and that's a very deterministic problem",
    "start": "1631460",
    "end": "1639520"
  },
  {
    "text": "okay so there's no Silver Bullet like to all the questions are listed out here",
    "start": "1639980",
    "end": "1645440"
  },
  {
    "text": "during our journey I think Hallucination is the top enemy",
    "start": "1645440",
    "end": "1651400"
  },
  {
    "text": "especially in our scenario and long context is actually one of the",
    "start": "1651400",
    "end": "1658039"
  },
  {
    "text": "challenges we are going to tackle next because um we did a bunch of like we estimated how",
    "start": "1658039",
    "end": "1665900"
  },
  {
    "text": "many like tokens we use for a single query actually with we send to the language model",
    "start": "1665900",
    "end": "1671740"
  },
  {
    "text": "currently it's about like 4 000 tokens each time so that's about the uh I think",
    "start": "1671740",
    "end": "1678080"
  },
  {
    "text": "all the common models or the currently available online they all just take",
    "start": "1678080",
    "end": "1683659"
  },
  {
    "text": "about 40 like 4000 tokens one time right so if we",
    "start": "1683659",
    "end": "1688820"
  },
  {
    "text": "want to add more like background knowledge or we want to do more like prompting techniques it requires a",
    "start": "1688820",
    "end": "1696260"
  },
  {
    "text": "longer context and um that's the issue we are going to tackle next",
    "start": "1696260",
    "end": "1701960"
  },
  {
    "text": "and everyone's talk about like multi-modality like using text pictures",
    "start": "1701960",
    "end": "1707120"
  },
  {
    "text": "and Etc but in the SRE Woodland I don't see any models today that can handle time series",
    "start": "1707120",
    "end": "1714919"
  },
  {
    "text": "data like logs metrics or trees as well they all like have the similar issue",
    "start": "1714919",
    "end": "1721220"
  },
  {
    "text": "with the long context problem so I think everyone can think about this",
    "start": "1721220",
    "end": "1726440"
  },
  {
    "text": "um because I think there's still a long way to go so finally what other lessons can we",
    "start": "1726440",
    "end": "1732620"
  },
  {
    "text": "learn from today I think um if you want to like use language model",
    "start": "1732620",
    "end": "1737900"
  },
  {
    "text": "in your own scenario or your own application you can use open AI as a",
    "start": "1737900",
    "end": "1743240"
  },
  {
    "text": "very good starting point to verify your idea at least it can be it is still a",
    "start": "1743240",
    "end": "1749120"
  },
  {
    "text": "very good like Baseline model you can use to test in your own scenario",
    "start": "1749120",
    "end": "1756380"
  },
  {
    "text": "but once you determine that okay this might be the task or this might be the things I want to solve and we want to",
    "start": "1756380",
    "end": "1761539"
  },
  {
    "text": "involve your own model please focus on collecting your user data and you know like data is the key to this",
    "start": "1761539",
    "end": "1769580"
  },
  {
    "text": "problem as we all know like we all say that um the quality of the data actually",
    "start": "1769580",
    "end": "1776600"
  },
  {
    "text": "determines the quality or the upper bound of your model's performance and algorithm itself",
    "start": "1776600",
    "end": "1783980"
  },
  {
    "text": "is a way to help you to achieve that goal but data is actually more important",
    "start": "1783980",
    "end": "1789440"
  },
  {
    "text": "all right and in our journey in our story um",
    "start": "1789440",
    "end": "1794840"
  },
  {
    "text": "I skipped a lot about our engineering effort but actually in our in the past six months I",
    "start": "1794840",
    "end": "1802580"
  },
  {
    "text": "think we devote about 80 percent of time during for engineering work because",
    "start": "1802580",
    "end": "1809380"
  },
  {
    "text": "training the model or do some supervising is kind of like straightforward as long as you can",
    "start": "1809380",
    "end": "1815779"
  },
  {
    "text": "prepare the data and please don't think of AI as a magic",
    "start": "1815779",
    "end": "1821120"
  },
  {
    "text": "and sometimes I think in the SRE words sometimes some if else",
    "start": "1821120",
    "end": "1827659"
  },
  {
    "text": "can already do the job and if it's that case you don't have to use the AI right",
    "start": "1827659",
    "end": "1832700"
  },
  {
    "text": "so with that I will conclude my talk today",
    "start": "1832700",
    "end": "1838600"
  },
  {
    "text": "we have our plan to like open source our model and",
    "start": "1838600",
    "end": "1843620"
  },
  {
    "text": "and also the coupe query engine but it's still in progress and",
    "start": "1843620",
    "end": "1849919"
  },
  {
    "text": "so you can follow this official account to like um to keep up with our updates",
    "start": "1849919",
    "end": "1855500"
  },
  {
    "text": "the official account is account that I created last year I",
    "start": "1855500",
    "end": "1862279"
  },
  {
    "text": "my only intention was to like write some stories about SRE or work life or like",
    "start": "1862279",
    "end": "1868760"
  },
  {
    "text": "do some SRE best practices but uh yeah I'm going to do a there's not much in",
    "start": "1868760",
    "end": "1875059"
  },
  {
    "text": "the official account yet but we'll do it later yeah so thank you all for coming today I know it's about time and it's",
    "start": "1875059",
    "end": "1882140"
  },
  {
    "text": "about holiday time so happy holidays",
    "start": "1882140",
    "end": "1886179"
  },
  {
    "text": "yeah I can take some questions in either Mandarin or English",
    "start": "1889220",
    "end": "1896260"
  },
  {
    "text": "always um",
    "start": "1900860",
    "end": "1906580"
  },
  {
    "text": "oh I took when he also the question is about like how much time we spend on",
    "start": "1930740",
    "end": "1937399"
  },
  {
    "text": "during the training and to get a model right um so it's about like um getting the",
    "start": "1937399",
    "end": "1944000"
  },
  {
    "text": "data it's an engineering effort we write the code and we we use the templates to help us to boost",
    "start": "1944000",
    "end": "1950600"
  },
  {
    "text": "up all the data it's about like uh two weeks work two weeks yeah okay and",
    "start": "1950600",
    "end": "1957440"
  },
  {
    "text": "the actual model training because the model size is kind of small it only takes about I think less than a week to",
    "start": "1957440",
    "end": "1965600"
  },
  {
    "text": "get your like first model and to so that you can do some quick verification meaning",
    "start": "1965600",
    "end": "1973159"
  },
  {
    "text": "um the question is about like comparing to like 3gbt like BT itself is already",
    "start": "2001299",
    "end": "2006940"
  },
  {
    "text": "is also involving right people are asking about the cube control questions to charge videos and it can get trained",
    "start": "2006940",
    "end": "2014860"
  },
  {
    "text": "um I think in our scenario our model is more focused and dedicated",
    "start": "2014860",
    "end": "2020100"
  },
  {
    "text": "to solve a specific like domain I think that's why like these",
    "start": "2020100",
    "end": "2027039"
  },
  {
    "text": "days everyone is talking about all those vertical models like in each different",
    "start": "2027039",
    "end": "2032080"
  },
  {
    "text": "domains or areas um I don't think there is a you have to",
    "start": "2032080",
    "end": "2037539"
  },
  {
    "text": "compare them whatever fits you yeah",
    "start": "2037539",
    "end": "2041940"
  },
  {
    "text": "foreign",
    "start": "2048040",
    "end": "2051040"
  },
  {
    "text": "yeah so so we should like uh Leverage The Power of the open source open source",
    "start": "2068980",
    "end": "2075339"
  },
  {
    "text": "models like code llama or other other ones for all those very very common and",
    "start": "2075339",
    "end": "2080919"
  },
  {
    "text": "very based languages right but for all the specific domain languages or to main knowledge like what end group does for",
    "start": "2080919",
    "end": "2089260"
  },
  {
    "text": "their API calls must be different to like what your company does right so",
    "start": "2089260",
    "end": "2094658"
  },
  {
    "text": "that part you have to like either use like in context learning that provides",
    "start": "2094659",
    "end": "2100359"
  },
  {
    "text": "this information to the to the model or you do the fine tuning based on those like",
    "start": "2100359",
    "end": "2106000"
  },
  {
    "text": "uh see like code llama or the other models already available yeah you don't",
    "start": "2106000",
    "end": "2111339"
  },
  {
    "text": "have to do it from scratch yeah um",
    "start": "2111339",
    "end": "2116400"
  },
  {
    "text": "yeah okay so the final question is about like um for troubleshooting how can chat",
    "start": "2156700",
    "end": "2161740"
  },
  {
    "text": "gbd or the language model help us yes I I haven't seen a lot of work in",
    "start": "2161740",
    "end": "2169119"
  },
  {
    "text": "this area but my gut feeling is it can help but",
    "start": "2169119",
    "end": "2174820"
  },
  {
    "text": "we have to teach the model first Yeah by teaching them I mean we have to like",
    "start": "2174820",
    "end": "2181480"
  },
  {
    "text": "prepare lots of data like think about it like if you are a seven year so like",
    "start": "2181480",
    "end": "2188140"
  },
  {
    "text": "child like you have to learn something something new right your teacher will",
    "start": "2188140",
    "end": "2193480"
  },
  {
    "text": "ask you to recite or to memorize something like repeat it again again right so that's what we do to language",
    "start": "2193480",
    "end": "2199420"
  },
  {
    "text": "model yeah during the training phrase right so yeah yeah we should we are definitely",
    "start": "2199420",
    "end": "2206380"
  },
  {
    "text": "trying that but I think you still require time okay thank you so much",
    "start": "2206380",
    "end": "2213180"
  },
  {
    "text": "so my understanding is this system and tool is actually used for uh I guess",
    "start": "2222540",
    "end": "2227920"
  },
  {
    "text": "figuring out Ops issues especially during instance right happy folks consider anything without anything about",
    "start": "2227920",
    "end": "2234339"
  },
  {
    "text": "like as a reliability side about like how to make sure the model doesn't like you know like this the thing that serves",
    "start": "2234339",
    "end": "2241119"
  },
  {
    "text": "the model doesn't have issues or like is there any kind of like favor plan for this thanks",
    "start": "2241119",
    "end": "2247380"
  },
  {
    "text": "okay so the question is about how we can use language model for like reliability",
    "start": "2247660",
    "end": "2253119"
  },
  {
    "text": "reviews or to figure out if there is uh like say during architecture review say",
    "start": "2253119",
    "end": "2258400"
  },
  {
    "text": "there is uh if anything we can spot right",
    "start": "2258400",
    "end": "2263700"
  },
  {
    "text": "so this model is used during uh I guess uh when you are doing operations right",
    "start": "2267160",
    "end": "2272320"
  },
  {
    "text": "if there is any kind of issue you're trying to fix the issue or run commands so it's already part of the the tools",
    "start": "2272320",
    "end": "2279520"
  },
  {
    "text": "the The Operators or essays are using uh I guess the tool has to have some some",
    "start": "2279520",
    "end": "2285520"
  },
  {
    "text": "kind of availability guarantees is there any kind of like consideration about the whole I guess the model serving system",
    "start": "2285520",
    "end": "2291579"
  },
  {
    "text": "or like the tool chain or is there any kind of filter plan in case the tool or",
    "start": "2291579",
    "end": "2296680"
  },
  {
    "text": "the model doesn't work yeah it's just like not available thanks oh so the question is about how to",
    "start": "2296680",
    "end": "2303820"
  },
  {
    "text": "guarantee the model itself the model's availability by itself right",
    "start": "2303820",
    "end": "2310119"
  },
  {
    "text": "I think that's a topic about mL of we can discuss it later yeah",
    "start": "2310119",
    "end": "2317440"
  },
  {
    "text": "a quick question uh how do you ensure the circle generated is correct did you",
    "start": "2319180",
    "end": "2324880"
  },
  {
    "text": "send it back to the model to verify it we haven't tried that but yeah we we",
    "start": "2324880",
    "end": "2332079"
  },
  {
    "text": "have some like um um we have two two cases one is to like use",
    "start": "2332079",
    "end": "2339460"
  },
  {
    "text": "a human evaluation like say you have a 100 questions you can ask right you have",
    "start": "2339460",
    "end": "2345760"
  },
  {
    "text": "your humans um um yeah you can write your own SQL right",
    "start": "2345760",
    "end": "2351820"
  },
  {
    "text": "and you can compare it with your like um the generative SQL and",
    "start": "2351820",
    "end": "2357820"
  },
  {
    "text": "I think that's accuracy that um it can be",
    "start": "2357820",
    "end": "2364119"
  },
  {
    "text": "it's not that important why because uh I",
    "start": "2364119",
    "end": "2369339"
  },
  {
    "text": "didn't show My Demo today because it was not there like ready yet",
    "start": "2369339",
    "end": "2375579"
  },
  {
    "text": "um the demo itself let me picture it so when the user asks a question right and",
    "start": "2375579",
    "end": "2381400"
  },
  {
    "text": "the SQL actually generated and the generated SQL will actually show up together with the uh the SQL theories",
    "start": "2381400",
    "end": "2389680"
  },
  {
    "text": "result right if the human itself needs to verify like if the SQL if this is the data is not",
    "start": "2389680",
    "end": "2397240"
  },
  {
    "text": "what he wants right he can modify SQL and do the query again I think the tool",
    "start": "2397240",
    "end": "2402460"
  },
  {
    "text": "itself the main purpose is not to get this thing 100 correctly but to help you",
    "start": "2402460",
    "end": "2407619"
  },
  {
    "text": "to quickly like get the SQL there and so that you can do a small tweaks yeah okay",
    "start": "2407619",
    "end": "2412900"
  },
  {
    "text": "thank you",
    "start": "2412900",
    "end": "2415319"
  },
  {
    "text": "thank you for sharing with us your journey applying LM in scenario and that's very",
    "start": "2422859",
    "end": "2430720"
  },
  {
    "text": "interesting case um what my question would be when you open source the this model well you are going",
    "start": "2430720",
    "end": "2438099"
  },
  {
    "text": "to are you going to really release the entire model so because we probably have the same issue as we are private domain",
    "start": "2438099",
    "end": "2444940"
  },
  {
    "text": "and we do not want to use chatgpt the major problem is they will have the data so what you'll",
    "start": "2444940",
    "end": "2451839"
  },
  {
    "text": "be sharing the model and so we can try ourselves and this is certainly is very early days",
    "start": "2451839",
    "end": "2456880"
  },
  {
    "text": "and I really approve what you did for I think there's a lot of application including networking there will be a lot",
    "start": "2456880",
    "end": "2464680"
  },
  {
    "text": "of operation can be resolved by by this and as well as the lrm I think there is",
    "start": "2464680",
    "end": "2471400"
  },
  {
    "text": "a place to reduce the human resources if you like",
    "start": "2471400",
    "end": "2478180"
  },
  {
    "text": "the question is about like what's our open source plan um yeah so we are thinking about it like",
    "start": "2478180",
    "end": "2484780"
  },
  {
    "text": "first like um we are like running experiment on like open source models",
    "start": "2484780",
    "end": "2490000"
  },
  {
    "text": "like llama2 or like called llama and I think like open source the model itself",
    "start": "2490000",
    "end": "2495280"
  },
  {
    "text": "is one way and the other way like what the keynote uh talked today this morning",
    "start": "2495280",
    "end": "2501160"
  },
  {
    "text": "um like the hugging phase team they are like collecting all the datas right or if we can contribute the data then maybe",
    "start": "2501160",
    "end": "2507760"
  },
  {
    "text": "like different people can use them different ways yes that's another option but yeah everything is still on plan and",
    "start": "2507760",
    "end": "2514900"
  },
  {
    "text": "you're welcome to join us to talk later yeah",
    "start": "2514900",
    "end": "2519960"
  },
  {
    "text": "hi yeah so um let's say if I have a reader role on a kubernetes cluster we",
    "start": "2521560",
    "end": "2527920"
  },
  {
    "text": "will if I use the natural language problem we inherit the same rule-based access permissions",
    "start": "2527920",
    "end": "2535838"
  },
  {
    "text": "so the question is about the permission to operate in a system right yeah correct yeah so currently as you can see",
    "start": "2536160",
    "end": "2542800"
  },
  {
    "text": "like um as I mentioned like touching the system itself is kind of dangerous so we have",
    "start": "2542800",
    "end": "2549040"
  },
  {
    "text": "several guards first um as you can see we only tackle the curating part so this is the read-only",
    "start": "2549040",
    "end": "2555339"
  },
  {
    "text": "mod read-only model and secondly um you don't want to like list out all",
    "start": "2555339",
    "end": "2560980"
  },
  {
    "text": "your resources right it will like consume lots of memories and bandwidth",
    "start": "2560980",
    "end": "2566140"
  },
  {
    "text": "to the API server so we add the cache layer right so that's the two safeguards we have",
    "start": "2566140",
    "end": "2572320"
  },
  {
    "text": "thank you all right so that's it thank you all",
    "start": "2572320",
    "end": "2581579"
  }
]
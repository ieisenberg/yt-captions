[
  {
    "start": "0",
    "end": "85000"
  },
  {
    "text": "thank you uh everyone for being here",
    "start": "240",
    "end": "2919"
  },
  {
    "text": "today uh it's a great honor uh for me to",
    "start": "2919",
    "end": "6319"
  },
  {
    "text": "be uh here as your co uh co- conference",
    "start": "6319",
    "end": "10320"
  },
  {
    "text": "co-chair and uh kyot speaker uh I'd like",
    "start": "10320",
    "end": "13280"
  },
  {
    "text": "to start by sharing a little bit about",
    "start": "13280",
    "end": "15559"
  },
  {
    "text": "my journey um because it hasn't always",
    "start": "15559",
    "end": "19119"
  },
  {
    "text": "been a straight pass so I was trained to",
    "start": "19119",
    "end": "21680"
  },
  {
    "text": "be a simultaneous interpreter um so as",
    "start": "21680",
    "end": "25039"
  },
  {
    "text": "you can see at this conference we don't",
    "start": "25039",
    "end": "26920"
  },
  {
    "text": "have a human interpreter um as people",
    "start": "26920",
    "end": "30039"
  },
  {
    "text": "always said um you if you can't feed",
    "start": "30039",
    "end": "33000"
  },
  {
    "text": "them join them yeah so um it's um um",
    "start": "33000",
    "end": "38440"
  },
  {
    "text": "it's a like job that almost being",
    "start": "38440",
    "end": "41840"
  },
  {
    "text": "replaced by Ai and um thanks to a chance",
    "start": "41840",
    "end": "45239"
  },
  {
    "text": "of me working uh banking software",
    "start": "45239",
    "end": "47600"
  },
  {
    "text": "project I got drawn to technology and",
    "start": "47600",
    "end": "51199"
  },
  {
    "text": "I'm super um attracted to the idea of",
    "start": "51199",
    "end": "55199"
  },
  {
    "text": "Open Source because if uh people get to",
    "start": "55199",
    "end": "58480"
  },
  {
    "text": "collaborate and be on each other work so",
    "start": "58480",
    "end": "61840"
  },
  {
    "text": "um this is a photo of a developer Meetup",
    "start": "61840",
    "end": "65400"
  },
  {
    "text": "I hosted about six years ago as you can",
    "start": "65400",
    "end": "68840"
  },
  {
    "text": "see um in that photo there aren't too",
    "start": "68840",
    "end": "72240"
  },
  {
    "text": "many girls but um I'm super glad that",
    "start": "72240",
    "end": "75439"
  },
  {
    "text": "fast forward to today uh we are seeing",
    "start": "75439",
    "end": "78600"
  },
  {
    "text": "more girls participation also in the uh",
    "start": "78600",
    "end": "81640"
  },
  {
    "text": "world of technology and open source um",
    "start": "81640",
    "end": "85680"
  },
  {
    "start": "85000",
    "end": "260000"
  },
  {
    "text": "yeah so I would like to start my uh",
    "start": "85680",
    "end": "89079"
  },
  {
    "text": "Keynote with a demo so this is a a",
    "start": "89079",
    "end": "92000"
  },
  {
    "text": "single command that I ran and U uh these",
    "start": "92000",
    "end": "95840"
  },
  {
    "text": "are docs that you can refer to uh",
    "start": "95840",
    "end": "99640"
  },
  {
    "text": "because uh I don't believe in demo God",
    "start": "99640",
    "end": "103320"
  },
  {
    "text": "so um in a pre-recorded",
    "start": "103320",
    "end": "107360"
  },
  {
    "text": "one yeah so this is the command that",
    "start": "108680",
    "end": "111880"
  },
  {
    "text": "I've shown um so it will so in this",
    "start": "111880",
    "end": "114799"
  },
  {
    "text": "darker image there is a large langu",
    "start": "114799",
    "end": "117600"
  },
  {
    "text": "model is L 3 a and then there's a",
    "start": "117600",
    "end": "121399"
  },
  {
    "text": "embedding model uh noric so",
    "start": "121399",
    "end": "125840"
  },
  {
    "text": "um this uh lar model is 5.7 gigabytes",
    "start": "125840",
    "end": "131440"
  },
  {
    "text": "and the embeding model is about 200",
    "start": "131440",
    "end": "134120"
  },
  {
    "text": "megabytes and also inside the image we",
    "start": "134120",
    "end": "137120"
  },
  {
    "text": "have a open air compatible API server",
    "start": "137120",
    "end": "140440"
  },
  {
    "text": "that's written in R and compiled into",
    "start": "140440",
    "end": "143440"
  },
  {
    "text": "web assembly so because it's a web",
    "start": "143440",
    "end": "145680"
  },
  {
    "text": "assembly file it's fully Pro portable",
    "start": "145680",
    "end": "148800"
  },
  {
    "text": "across GP and",
    "start": "148800",
    "end": "152319"
  },
  {
    "text": "CPUs so um yeah uh later I will uh so it",
    "start": "153200",
    "end": "159560"
  },
  {
    "text": "also start on uh Local Host",
    "start": "159560",
    "end": "163599"
  },
  {
    "text": "ad8 um portal that I can uh ask the",
    "start": "163599",
    "end": "167840"
  },
  {
    "text": "large langu model",
    "start": "167840",
    "end": "170159"
  },
  {
    "text": "questions um so I will explain later why",
    "start": "170159",
    "end": "175319"
  },
  {
    "text": "uh we think by uh",
    "start": "175319",
    "end": "178599"
  },
  {
    "text": "doing this way is a better way because U",
    "start": "178599",
    "end": "182640"
  },
  {
    "text": "we we think TI coupling of your AI app",
    "start": "182640",
    "end": "187280"
  },
  {
    "text": "together with your large language model",
    "start": "187280",
    "end": "189680"
  },
  {
    "text": "uh is a better approach to do your AI",
    "start": "189680",
    "end": "192519"
  },
  {
    "text": "app so the question I asked is which uh",
    "start": "192519",
    "end": "196480"
  },
  {
    "text": "figure is greater is",
    "start": "196480",
    "end": "199480"
  },
  {
    "text": "9.1 or",
    "start": "199480",
    "end": "201440"
  },
  {
    "text": "9.9 so because um this is run on a um",
    "start": "201440",
    "end": "207519"
  },
  {
    "text": "Mac M1 chip 16 gab memory uh machine so",
    "start": "207519",
    "end": "213920"
  },
  {
    "text": "and also because I didn't put in Cuda or",
    "start": "213920",
    "end": "216720"
  },
  {
    "text": "driver so it's um only use the max CPU",
    "start": "216720",
    "end": "220879"
  },
  {
    "text": "and not uh GPU so and also you need to",
    "start": "220879",
    "end": "224840"
  },
  {
    "text": "load the entire model into the memory so",
    "start": "224840",
    "end": "227439"
  },
  {
    "text": "why that's why the First Response can be",
    "start": "227439",
    "end": "230879"
  },
  {
    "text": "kind of",
    "start": "230879",
    "end": "233239"
  },
  {
    "text": "slow so let's see um LMA 3ab can answer",
    "start": "236720",
    "end": "241879"
  },
  {
    "text": "this question",
    "start": "241879",
    "end": "244959"
  },
  {
    "text": "correctly yeah so the answer is correct",
    "start": "250480",
    "end": "253400"
  },
  {
    "text": "9.9 is greater than",
    "start": "253400",
    "end": "256160"
  },
  {
    "text": "9.11",
    "start": "256160",
    "end": "258120"
  },
  {
    "text": "yeah",
    "start": "258120",
    "end": "260519"
  },
  {
    "start": "260000",
    "end": "358000"
  },
  {
    "text": "um yeah so um these are some key",
    "start": "260519",
    "end": "265400"
  },
  {
    "text": "features of the approach that I used",
    "start": "265400",
    "end": "268199"
  },
  {
    "text": "just now so it's a tightly C large Lang",
    "start": "268199",
    "end": "270800"
  },
  {
    "text": "model and AI app so it has the um",
    "start": "270800",
    "end": "274880"
  },
  {
    "text": "matching prompt pration and wrong time",
    "start": "274880",
    "end": "279120"
  },
  {
    "text": "uh WR time here I mean uh things like",
    "start": "279120",
    "end": "282120"
  },
  {
    "text": "Lama CP so that uh by doing it this way",
    "start": "282120",
    "end": "286800"
  },
  {
    "text": "uh the container app would always work",
    "start": "286800",
    "end": "289360"
  },
  {
    "text": "uh even though um the uh LM can get",
    "start": "289360",
    "end": "293880"
  },
  {
    "text": "updated or the CH template can can",
    "start": "293880",
    "end": "296680"
  },
  {
    "text": "change your AI app always works despite",
    "start": "296680",
    "end": "300400"
  },
  {
    "text": "of the upgrade cycles and it's quite",
    "start": "300400",
    "end": "303759"
  },
  {
    "text": "light weight compared to um other uh",
    "start": "303759",
    "end": "307400"
  },
  {
    "text": "Wave It's 5 gabt opposed to 10 gabes P",
    "start": "307400",
    "end": "311280"
  },
  {
    "text": "to jab uh because uh it used uh web Sly",
    "start": "311280",
    "end": "315160"
  },
  {
    "text": "long time and also it's very portable so",
    "start": "315160",
    "end": "319000"
  },
  {
    "text": "um it can as I mentioned is across CPU",
    "start": "319000",
    "end": "322160"
  },
  {
    "text": "and gpus and different operating systems",
    "start": "322160",
    "end": "325240"
  },
  {
    "text": "and um you can develop your AI app on",
    "start": "325240",
    "end": "328800"
  },
  {
    "text": "your ma and and then deploy it on Nvidia",
    "start": "328800",
    "end": "331800"
  },
  {
    "text": "it totally works and also it embed into",
    "start": "331800",
    "end": "335440"
  },
  {
    "text": "these different language apps and work",
    "start": "335440",
    "end": "338400"
  },
  {
    "text": "with uh similarly with the cognetic",
    "start": "338400",
    "end": "342199"
  },
  {
    "text": "ecosystem",
    "start": "342199",
    "end": "344240"
  },
  {
    "text": "tools so uh these are the uh different",
    "start": "344240",
    "end": "348800"
  },
  {
    "text": "infra that it support and and also uh",
    "start": "348800",
    "end": "352840"
  },
  {
    "text": "different long time back back end and",
    "start": "352840",
    "end": "354960"
  },
  {
    "text": "then AI apps around",
    "start": "354960",
    "end": "358479"
  },
  {
    "start": "358000",
    "end": "443000"
  },
  {
    "text": "it um uh these are several real word use",
    "start": "358479",
    "end": "362240"
  },
  {
    "text": "cases for the web assembly long time um",
    "start": "362240",
    "end": "366520"
  },
  {
    "text": "like uh ganet is one of our big users so",
    "start": "366520",
    "end": "371039"
  },
  {
    "text": "they build their Tex stack on top of",
    "start": "371039",
    "end": "373120"
  },
  {
    "text": "what made wrong time and right now there",
    "start": "373120",
    "end": "375319"
  },
  {
    "text": "are already about uh 30k users that has",
    "start": "375319",
    "end": "380680"
  },
  {
    "text": "already uh installed um the text stack",
    "start": "380680",
    "end": "385560"
  },
  {
    "text": "that bu on top of wasm Edge and run a",
    "start": "385560",
    "end": "387880"
  },
  {
    "text": "large language model their own personal",
    "start": "387880",
    "end": "390479"
  },
  {
    "text": "larg model with their personal knowledge",
    "start": "390479",
    "end": "392759"
  },
  {
    "text": "on their own devices like Mac or some",
    "start": "392759",
    "end": "396479"
  },
  {
    "text": "other devices um and uh the second one",
    "start": "396479",
    "end": "400000"
  },
  {
    "text": "is the AI operating system and open",
    "start": "400000",
    "end": "402960"
  },
  {
    "text": "interpreter is like a open source",
    "start": "402960",
    "end": "404639"
  },
  {
    "text": "version of code interpreter by open AI",
    "start": "404639",
    "end": "407520"
  },
  {
    "text": "so it's um on giab it has so many stars",
    "start": "407520",
    "end": "411280"
  },
  {
    "text": "and um uh it also use uh W match and um",
    "start": "411280",
    "end": "416720"
  },
  {
    "text": "the the other use cases like for example",
    "start": "416720",
    "end": "419599"
  },
  {
    "text": "for the education uh use case uh you",
    "start": "419599",
    "end": "423000"
  },
  {
    "text": "Berkeley would use uh this um pack as",
    "start": "423000",
    "end": "426440"
  },
  {
    "text": "the teaching assistant and also G uh in",
    "start": "426440",
    "end": "429479"
  },
  {
    "text": "terms of gaming so um cost Coast AI uh",
    "start": "429479",
    "end": "433800"
  },
  {
    "text": "is also an open source uh project it use",
    "start": "433800",
    "end": "436639"
  },
  {
    "text": "for them to run AI models uh to enhance",
    "start": "436639",
    "end": "440319"
  },
  {
    "text": "their NTC clearance to their",
    "start": "440319",
    "end": "443639"
  },
  {
    "start": "443000",
    "end": "485000"
  },
  {
    "text": "users and um yeah I think I already",
    "start": "443639",
    "end": "446720"
  },
  {
    "text": "mentioned some of the features just now",
    "start": "446720",
    "end": "449520"
  },
  {
    "text": "so it's uh it's after you compiled your",
    "start": "449520",
    "end": "453919"
  },
  {
    "text": "AI app like your API server into um WM",
    "start": "453919",
    "end": "458000"
  },
  {
    "text": "is a single cross platform binary and",
    "start": "458000",
    "end": "461960"
  },
  {
    "text": "you can um compile and test your app on",
    "start": "461960",
    "end": "466280"
  },
  {
    "text": "your Mac and then deploy it to nvdia or",
    "start": "466280",
    "end": "468840"
  },
  {
    "text": "some other gpus or Airship and it can be",
    "start": "468840",
    "end": "471919"
  },
  {
    "text": "moved around and deployed to new",
    "start": "471919",
    "end": "474720"
  },
  {
    "text": "Hardwares by uh different uh PR tools",
    "start": "474720",
    "end": "479639"
  },
  {
    "text": "and uh it can be packed into do image",
    "start": "479639",
    "end": "483599"
  },
  {
    "text": "and the size is quite",
    "start": "483599",
    "end": "485639"
  },
  {
    "start": "485000",
    "end": "528000"
  },
  {
    "text": "small so yeah uh if you want to check",
    "start": "485639",
    "end": "488199"
  },
  {
    "text": "out the documentation you can always",
    "start": "488199",
    "end": "490080"
  },
  {
    "text": "visit our um GitHub so these are a few",
    "start": "490080",
    "end": "493680"
  },
  {
    "text": "links that you can um check out and um",
    "start": "493680",
    "end": "498520"
  },
  {
    "text": "um I would like to also mention the AI",
    "start": "498520",
    "end": "502879"
  },
  {
    "text": "ecosystem landscape uh made by stdf so",
    "start": "502879",
    "end": "507360"
  },
  {
    "text": "as you can see we are uh the major on",
    "start": "507360",
    "end": "510080"
  },
  {
    "text": "time this year uh in the category of",
    "start": "510080",
    "end": "513039"
  },
  {
    "text": "machine learning serving so um I think",
    "start": "513039",
    "end": "516440"
  },
  {
    "text": "these are all very good open source",
    "start": "516440",
    "end": "518440"
  },
  {
    "text": "tools that you can utilize in this",
    "start": "518440",
    "end": "520680"
  },
  {
    "text": "ecosystem and um uh here we would like",
    "start": "520680",
    "end": "524519"
  },
  {
    "text": "to have your",
    "start": "524519",
    "end": "526200"
  },
  {
    "text": "input as",
    "start": "526200",
    "end": "528160"
  },
  {
    "start": "528000",
    "end": "558000"
  },
  {
    "text": "well so",
    "start": "528160",
    "end": "530480"
  },
  {
    "text": "um this is a survey uh co- conducted by",
    "start": "530480",
    "end": "535399"
  },
  {
    "text": "CDF and LF research so so um we would",
    "start": "535399",
    "end": "540600"
  },
  {
    "text": "like to know how your company use gen",
    "start": "540600",
    "end": "543279"
  },
  {
    "text": "tools and uh we need to hear your voice",
    "start": "543279",
    "end": "546959"
  },
  {
    "text": "to understand the real challenge and",
    "start": "546959",
    "end": "549839"
  },
  {
    "text": "opportunities uh in deploying gen AI in",
    "start": "549839",
    "end": "552880"
  },
  {
    "text": "the cloud I we do think your input",
    "start": "552880",
    "end": "557680"
  },
  {
    "start": "558000",
    "end": "592000"
  },
  {
    "text": "matters yeah U that's um uh the calling",
    "start": "558240",
    "end": "561959"
  },
  {
    "text": "for contributors um so in LFX mentorship",
    "start": "561959",
    "end": "567360"
  },
  {
    "text": "and you can always find different TCH",
    "start": "567360",
    "end": "569839"
  },
  {
    "text": "not only Tex from water mag but also",
    "start": "569839",
    "end": "572880"
  },
  {
    "text": "from other um open source project um and",
    "start": "572880",
    "end": "577120"
  },
  {
    "text": "ALS or you can uh look at our GitHub",
    "start": "577120",
    "end": "581079"
  },
  {
    "text": "repo and uh check out the uh looking for",
    "start": "581079",
    "end": "586040"
  },
  {
    "text": "help uh tag to uh see if there's",
    "start": "586040",
    "end": "589560"
  },
  {
    "text": "anything you can add on",
    "start": "589560",
    "end": "592240"
  },
  {
    "start": "592000",
    "end": "642000"
  },
  {
    "text": "to yeah I think that would be pretty",
    "start": "592240",
    "end": "595360"
  },
  {
    "text": "much all of my talk and you can always",
    "start": "595360",
    "end": "598120"
  },
  {
    "text": "find me on also only and GitHub or",
    "start": "598120",
    "end": "601240"
  },
  {
    "text": "Twitter and these are few resources you",
    "start": "601240",
    "end": "603959"
  },
  {
    "text": "can check out so um on YouTube we will",
    "start": "603959",
    "end": "607440"
  },
  {
    "text": "the release every month our uh monthly",
    "start": "607440",
    "end": "611240"
  },
  {
    "text": "uh community meeting uh so you can uh",
    "start": "611240",
    "end": "615079"
  },
  {
    "text": "take a look and um uh yeah uh we would",
    "start": "615079",
    "end": "620560"
  },
  {
    "text": "like to hear your thoughts on uh",
    "start": "620560",
    "end": "623360"
  },
  {
    "text": "everything we have been talking about so",
    "start": "623360",
    "end": "625880"
  },
  {
    "text": "if you are uh interested you can always",
    "start": "625880",
    "end": "629079"
  },
  {
    "text": "come to the solution showcase uh room to",
    "start": "629079",
    "end": "632440"
  },
  {
    "text": "talk to us we have a sponsor boost there",
    "start": "632440",
    "end": "635320"
  },
  {
    "text": "so it's a second stage second stage is",
    "start": "635320",
    "end": "637519"
  },
  {
    "text": "the company behind H match thank you so",
    "start": "637519",
    "end": "639880"
  },
  {
    "text": "much",
    "start": "639880",
    "end": "642880"
  }
]
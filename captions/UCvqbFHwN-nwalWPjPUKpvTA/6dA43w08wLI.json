[
  {
    "text": "all right hello everyone we're very excited to be here lucas has been in previous cube",
    "start": "160",
    "end": "5200"
  },
  {
    "text": "cons but for me it's first kubecon and also first time on official travel for two years and a half",
    "start": "5200",
    "end": "11120"
  },
  {
    "text": "so we're very happy to talk a little bit about the journey that we've been going on in the last years to integrate",
    "start": "11120",
    "end": "16800"
  },
  {
    "text": "kubernetes into the atlas distributed computing and help with the search for new phenomena in particle physics",
    "start": "16800",
    "end": "24560"
  },
  {
    "text": "i am fernando barreto i'm actually from spain studied information technology and telecommunications in madrid",
    "start": "24560",
    "end": "31199"
  },
  {
    "text": "and after university i moved to geneva and have been most of my professional career working in the atlas",
    "start": "31199",
    "end": "37600"
  },
  {
    "text": "experiment covering different roles and lately i'm running projects to integrate",
    "start": "37600",
    "end": "43760"
  },
  {
    "text": "the kubernetes and the public and cloud public and private cloud resources and that's where i know luca's from",
    "start": "43760",
    "end": "50480"
  },
  {
    "text": "okay hi everybody i hope you're enjoying kubecon my name is lucas heinrich i'm a professor for",
    "start": "50480",
    "end": "55920"
  },
  {
    "text": "data science and physics at the technical university of munich and i'm also like fernando working on the atlas",
    "start": "55920",
    "end": "62480"
  },
  {
    "text": "experiment at cern and my research focus is kind of two-fold i",
    "start": "62480",
    "end": "67840"
  },
  {
    "text": "can develop machine learning techniques and statistical data analysis techniques to actually apply to the data but i also am",
    "start": "67840",
    "end": "75600"
  },
  {
    "text": "very interested and exciting about uh using cloud computing technologies to build up the actual infrastructure that",
    "start": "75600",
    "end": "81680"
  },
  {
    "text": "enables thousands of physicists to work with the data that we're collecting at these big scientific experiments that",
    "start": "81680",
    "end": "88560"
  },
  {
    "text": "we have at cern okay so uh by way of introduction what",
    "start": "88560",
    "end": "93600"
  },
  {
    "text": "is cern so you might have heard about cern already in the keynote today so cern is one of the major particle",
    "start": "93600",
    "end": "99520"
  },
  {
    "text": "physics laboratories in the world and so i as a participant",
    "start": "99520",
    "end": "104799"
  },
  {
    "text": "view it as a particle physics lab but the way that cern probably impacted your lives the most is",
    "start": "104799",
    "end": "110320"
  },
  {
    "text": "by being the birthplace of the world wide web so here on the right hand side you can see uh",
    "start": "110320",
    "end": "116159"
  },
  {
    "text": "tim berners-lee who was working at cern when he was drafting the first proposal for the world wide web and as you know you know",
    "start": "116159",
    "end": "122799"
  },
  {
    "text": "the rest is history and now we're all using the web every day okay so but",
    "start": "122799",
    "end": "129039"
  },
  {
    "text": "in some sense for us as physicists the invention of the world web web which was originally conceived as a way to more",
    "start": "129039",
    "end": "135440"
  },
  {
    "text": "efficiently exchange information between scientists was just a byproduct of our scientific activity and so here you can",
    "start": "135440",
    "end": "142239"
  },
  {
    "text": "see cern so it's in a nice swiss countryside",
    "start": "142239",
    "end": "147599"
  },
  {
    "text": "and we have many projects going on at cern but the biggest one is the large hadron collider that you might have",
    "start": "147599",
    "end": "153680"
  },
  {
    "text": "heard about in the news it's a 27 kilometer long tunnel that is 100 meters underground it",
    "start": "153680",
    "end": "159360"
  },
  {
    "text": "goes through france uh and switzerland and here we're accelerating particle beams to almost the speed of light and",
    "start": "159360",
    "end": "166400"
  },
  {
    "text": "so we have two beams one is going clockwise the other one is going uh counterclockwise and at these four",
    "start": "166400",
    "end": "172400"
  },
  {
    "text": "specific points we collide the beams head on and then hopefully something interesting happens like the creation of",
    "start": "172400",
    "end": "178319"
  },
  {
    "text": "a new elementary particle so fernando and i we both work at the atlas experiment which in my mind is of course",
    "start": "178319",
    "end": "184480"
  },
  {
    "text": "the best experiment at the lhc okay so here you can see a view inside",
    "start": "184480",
    "end": "190560"
  },
  {
    "text": "of the tunnel again it's 100 meters underground and so these big things are big strong",
    "start": "190560",
    "end": "196720"
  },
  {
    "text": "magnets that are able to bend the beam into the circular trajectory even though the beams are going at the",
    "start": "196720",
    "end": "203280"
  },
  {
    "text": "almost the speed of light and so they're very strong magnets and here you see what happens at one of",
    "start": "203280",
    "end": "209840"
  },
  {
    "text": "these collisions points so i showed uh there are four collision points and this is the collision point where uh the",
    "start": "209840",
    "end": "215120"
  },
  {
    "text": "atlas experiment said so this is the atlas experiment it's one of the biggest scientific machines that humankind has",
    "start": "215120",
    "end": "221120"
  },
  {
    "text": "ever built and uh so what is it it's basically a three huge giant",
    "start": "221120",
    "end": "226239"
  },
  {
    "text": "three-dimensional camera that records what is going on during these particle collisions from all",
    "start": "226239",
    "end": "231760"
  },
  {
    "text": "angles so we want to know what is happening during these collisions so that we can analyze it uh later on",
    "start": "231760",
    "end": "236959"
  },
  {
    "text": "offline while we're taking the data and so these collisions they're not happening you know once a week or once a",
    "start": "236959",
    "end": "243040"
  },
  {
    "text": "day or once a minute they happen every 25 nanoseconds and they produce a couple of megabytes of data per collision so we",
    "start": "243040",
    "end": "249680"
  },
  {
    "text": "have 40 million collisions uh every second and so there's a lot of data that",
    "start": "249680",
    "end": "254720"
  },
  {
    "text": "is being accumulated so while in the former times you know we analyze the",
    "start": "254720",
    "end": "259759"
  },
  {
    "text": "data by eye using photographic plates now we of course need a very large computational infrastructure in order to",
    "start": "259759",
    "end": "267680"
  },
  {
    "text": "get you know manage this data in an efficient way and actually extract some physics inside out of this huge amount",
    "start": "267680",
    "end": "274400"
  },
  {
    "text": "of data okay so if you're actually managing to extract some interesting science out of",
    "start": "274400",
    "end": "280320"
  },
  {
    "text": "it nice things can happen so here for example we can discover a new elementary",
    "start": "280320",
    "end": "285440"
  },
  {
    "text": "particle this happened almost exactly 10 years ago this was the announcement of the discovery of the higgs boson and a",
    "start": "285440",
    "end": "292320"
  },
  {
    "text": "couple of years ago at kubecon in barcelona we also showed how we can use kubernetes to rediscover the higgs",
    "start": "292320",
    "end": "299280"
  },
  {
    "text": "and so because of this discovery that we made at cern uh peter higgs was awarded",
    "start": "299280",
    "end": "304880"
  },
  {
    "text": "the nobel prize a year later because he was predicting the existence of this new special particle a couple of",
    "start": "304880",
    "end": "311360"
  },
  {
    "text": "decades earlier and so that was a nice success not only of the physicists and the work that they do but also of the",
    "start": "311360",
    "end": "317600"
  },
  {
    "text": "computational infrastructure that we build in order to run these high scale",
    "start": "317600",
    "end": "322880"
  },
  {
    "text": "large scale scientific experiments okay but this is not a physics conference i'll not talk too much about",
    "start": "322880",
    "end": "329600"
  },
  {
    "text": "the physics but i want to talk more about the computing infrastructure and how we actually manage the data and so",
    "start": "329600",
    "end": "335600"
  },
  {
    "text": "in atlas we have a two-tiered uh data processing pipeline so to say we have uh",
    "start": "335600",
    "end": "340880"
  },
  {
    "text": "one uh kind of large-scale pipeline which we call the production system and the role of this production system to is",
    "start": "340880",
    "end": "346880"
  },
  {
    "text": "to either take the data from the raw detector output or from our simulation",
    "start": "346880",
    "end": "352320"
  },
  {
    "text": "and then pre-process it in a way into a format that is useful for the actual downstream uh scientists and so this is",
    "start": "352320",
    "end": "360000"
  },
  {
    "text": "a very large scale operation so we have a exabyte of data roughly and so uh this",
    "start": "360000",
    "end": "365840"
  },
  {
    "text": "doesn't fit a single data center so we need to distribute globally across something like a million cpus and",
    "start": "365840",
    "end": "371360"
  },
  {
    "text": "fernando is going to talk a bit about that and it's a this pre-processing stage uh is a fairly uh well-organized",
    "start": "371360",
    "end": "378639"
  },
  {
    "text": "activity where you have only a few teams that are able or in charge of pre-process running this pre-processing",
    "start": "378639",
    "end": "384960"
  },
  {
    "text": "campaign and so we heard a lot about batch processing uh also at this conference and there was a co-located",
    "start": "384960",
    "end": "391120"
  },
  {
    "text": "event about the kubernetes batch working group and so this is a classic batch workload where we're not super",
    "start": "391120",
    "end": "397120"
  },
  {
    "text": "interested when this processing happens we're interested that it happens at some point but it doesn't need to be now it",
    "start": "397120",
    "end": "402639"
  },
  {
    "text": "doesn't need to be tomorrow it can happen maybe in a week from now and so this is a",
    "start": "402639",
    "end": "407759"
  },
  {
    "text": "kind of a very large scale system and then the user analysis like the data scientist view of the system is uh down",
    "start": "407759",
    "end": "415280"
  },
  {
    "text": "here and it's a couple of orders of magnitude below that so it's at a petabyte scale and so this is where you",
    "start": "415280",
    "end": "420720"
  },
  {
    "text": "have individual teams of data scientists and physicists that you know look for like a specific uh physics question in",
    "start": "420720",
    "end": "427520"
  },
  {
    "text": "the data and so here it's still large scale so globally we still have something like 100 000 cpus but",
    "start": "427520",
    "end": "434160"
  },
  {
    "text": "typically a team works on like one or two individual facilities but unlike the production system which",
    "start": "434160",
    "end": "441199"
  },
  {
    "text": "is this few groups uh you know highly organized activity here you have a much",
    "start": "441199",
    "end": "446319"
  },
  {
    "text": "more heterogeneous setup where you have individual teams hundreds of individual teams that train",
    "start": "446319",
    "end": "451840"
  },
  {
    "text": "machine learning models they uh you know do their data analysis statistical analysis pre-selection and so on so so",
    "start": "451840",
    "end": "457759"
  },
  {
    "text": "there's a very rich bouquet of individual things that you want to do and ideally you want to",
    "start": "457759",
    "end": "463120"
  },
  {
    "text": "have the answer as soon as possible if i as a physicist have an idea on how to process my data to extract some physics",
    "start": "463120",
    "end": "469599"
  },
  {
    "text": "i want to try it out this idea and me to immediately get the answer so ideally what we want to have is a kind of",
    "start": "469599",
    "end": "475360"
  },
  {
    "text": "interactive data analysis experience where you can try something even though you're still kind of",
    "start": "475360",
    "end": "480560"
  },
  {
    "text": "roughly at this petabyte scale and so the way that we're structuring this talk is that fernando is going to talk a bit",
    "start": "480560",
    "end": "486080"
  },
  {
    "text": "about this first production system uh tier and then later on we'll try to do a live demo and try",
    "start": "486080",
    "end": "492319"
  },
  {
    "text": "to actually do some physics uh that represents roughly what we're doing uh in this data analysis tier at the",
    "start": "492319",
    "end": "498800"
  },
  {
    "text": "bottom okay so i'll hand over to fernando he'll talk to you about the production system and then we go to the",
    "start": "498800",
    "end": "505280"
  },
  {
    "text": "demo thanks a lot lucas okay so while most of the people started hearing",
    "start": "505280",
    "end": "512159"
  },
  {
    "text": "about cern and atlas around 2008 which is which when atlas started to go into production and",
    "start": "512159",
    "end": "518640"
  },
  {
    "text": "then there was more media attention also books like don brown's angels and demons but these experiments are actually being",
    "start": "518640",
    "end": "525279"
  },
  {
    "text": "planned uh decades in advance so atlas was being discussed in the 90s and the",
    "start": "525279",
    "end": "530880"
  },
  {
    "text": "computing infrastructure was being discussed the late 90s and beginning of the 2000s and back in those days there",
    "start": "530880",
    "end": "537760"
  },
  {
    "text": "was simply industry was not at the level that it is now um there was no cloud computing there",
    "start": "537760",
    "end": "543760"
  },
  {
    "text": "were no massive storage systems and no real off-the-shelf components that",
    "start": "543760",
    "end": "549360"
  },
  {
    "text": "atlas could use for the processing of of their data and the storage",
    "start": "549360",
    "end": "555040"
  },
  {
    "text": "so for this reason in 2001 the worldwide lhc computing rate was conceived",
    "start": "555040",
    "end": "560720"
  },
  {
    "text": "and they came up with a plan of that each of the university and laboratory that was participating in the atlas",
    "start": "560720",
    "end": "567760"
  },
  {
    "text": "experiment or in the lhc experiments they would also contribute a little bit of",
    "start": "567760",
    "end": "572880"
  },
  {
    "text": "for the computing power of the experiment on the computing storage um",
    "start": "572880",
    "end": "578240"
  },
  {
    "text": "so and then the wlcg also developed all of the middleware and storage elements and",
    "start": "578240",
    "end": "584320"
  },
  {
    "text": "compute elements that would be doing the storage and processing",
    "start": "584320",
    "end": "590720"
  },
  {
    "text": "today the atlas statistics are around 165 data centers distributed in 40",
    "start": "590720",
    "end": "596399"
  },
  {
    "text": "countries you can see here in the in this image the center is",
    "start": "596399",
    "end": "602839"
  },
  {
    "text": "around is in switzerland around geneva and since we are in spain",
    "start": "602839",
    "end": "608320"
  },
  {
    "text": "also in spain you see that there are three data centers one is in madrid one is in valencia it's quite close actually",
    "start": "608320",
    "end": "614480"
  },
  {
    "text": "here to the to the to this venue and also um the tiagoan is in barcelona",
    "start": "614480",
    "end": "622160"
  },
  {
    "text": "while the processing and storage is done distributed we have central services",
    "start": "623920",
    "end": "629600"
  },
  {
    "text": "that do actually all of the all of the they have the intelligence and the management of the data and of the of the",
    "start": "629600",
    "end": "636079"
  },
  {
    "text": "workloads um the first system is ruthie it's responsible for the data management uh",
    "start": "636079",
    "end": "642000"
  },
  {
    "text": "it knows all of the data sets and files that are managed by the experiment and",
    "start": "642000",
    "end": "647120"
  },
  {
    "text": "knows where they are in the grid and then it's also responsible to interact with the storage systems like upload",
    "start": "647120",
    "end": "652160"
  },
  {
    "text": "download files uh schedule transfers between them and so on to date",
    "start": "652160",
    "end": "657440"
  },
  {
    "text": "the ruthio system manages around 700 petabytes of data distributed around the",
    "start": "657440",
    "end": "662959"
  },
  {
    "text": "grid for the workload management part we have another animal which is panda",
    "start": "662959",
    "end": "668720"
  },
  {
    "text": "and panda is talking with ruthie constantly knows where their fights are and then schedules the computational",
    "start": "668720",
    "end": "674480"
  },
  {
    "text": "tasks to to the to the data um also depending on on what is the load of each site",
    "start": "674480",
    "end": "682959"
  },
  {
    "text": "and it's also responsible to interact with all of the compute systems and push the jobs into their batch systems",
    "start": "682959",
    "end": "688640"
  },
  {
    "text": "you see in this diagram it was the evolution of the last seven years more or less um how we have",
    "start": "688640",
    "end": "694240"
  },
  {
    "text": "been growing and to date we are on the seven hundred eight hundred thousand virtual cpus for course",
    "start": "694240",
    "end": "700000"
  },
  {
    "text": "and the resources are different so the main component are the pledged resources which are the traditional grid",
    "start": "700000",
    "end": "706880"
  },
  {
    "text": "resources but then we also have um opportunistic or over the pledge resources uh provided by cloud and by",
    "start": "706880",
    "end": "714839"
  },
  {
    "text": "hpc's that we have very successful collaborations with",
    "start": "714839",
    "end": "720240"
  },
  {
    "text": "going a little bit in a high-level diagram so you see that we have our users they interact with the data",
    "start": "720480",
    "end": "726959"
  },
  {
    "text": "and the workload management system these systems make the grid look like a unified resource and abstract all of the",
    "start": "726959",
    "end": "733120"
  },
  {
    "text": "distributed nature of the system and then for the workload management",
    "start": "733120",
    "end": "738720"
  },
  {
    "text": "part we have this harvester component which is the one that talks with all of the batch systems and",
    "start": "738720",
    "end": "743760"
  },
  {
    "text": "resources the typical flavor is the are the grid sites and the",
    "start": "743760",
    "end": "749279"
  },
  {
    "text": "harvester talks the hd condor or the arc middleware apis to submit jobs",
    "start": "749279",
    "end": "755040"
  },
  {
    "text": "for hpc's we have a lot of collaborations and use different supercomputers and usually",
    "start": "755040",
    "end": "760880"
  },
  {
    "text": "this has to be done on a case-by-case basis since every hpc is different",
    "start": "760880",
    "end": "767120"
  },
  {
    "text": "and then the one side that we are actually focusing this present for focusing this presentation",
    "start": "767120",
    "end": "773600"
  },
  {
    "text": "on is the integration with kubernetes so this originated a couple of years ago we",
    "start": "773600",
    "end": "779279"
  },
  {
    "text": "were running a project with google and we were thinking how could we run",
    "start": "779279",
    "end": "784639"
  },
  {
    "text": "atlas jobs in google and then was the typical option was to to fiddle around with virtual machines",
    "start": "784639",
    "end": "791360"
  },
  {
    "text": "contextualize them to to join some some batch queue but instead what we thought is that the best",
    "start": "791360",
    "end": "797600"
  },
  {
    "text": "is to use kubernetes as a as a native resource",
    "start": "797600",
    "end": "802800"
  },
  {
    "text": "um because we can run also the kubernetes classes on on our own sites not only on commercial clouds and also",
    "start": "802800",
    "end": "809360"
  },
  {
    "text": "all of the commercial clouds nowadays or the major ones are offering managed kubernetes clusters",
    "start": "809360",
    "end": "817519"
  },
  {
    "text": "um here we show a little bit how um we integrated harvest and kubernetes",
    "start": "817600",
    "end": "823920"
  },
  {
    "text": "so the the one requirement that we had is that we we were not starting from zero",
    "start": "823920",
    "end": "829600"
  },
  {
    "text": "we needed to integrate kubernetes in a in a structure that was that is already 15 years old or so on and we needed to",
    "start": "829600",
    "end": "836720"
  },
  {
    "text": "integrate the kubernetes in a way that it offers all of the services that a traditional grid site is offering",
    "start": "836720",
    "end": "843839"
  },
  {
    "text": "but at the same time i also didn't want to install too many things on kubernetes and wanted to keep it as simple as",
    "start": "843839",
    "end": "849279"
  },
  {
    "text": "possible so while most of the people know kubernetes for like application",
    "start": "849279",
    "end": "854560"
  },
  {
    "text": "management and service management kubernetes also has native job controllers which",
    "start": "854560",
    "end": "860160"
  },
  {
    "text": "allow you to run budget applications directly on kubernetes and we used just the native",
    "start": "860160",
    "end": "866079"
  },
  {
    "text": "job controllers but if you attended the batch working group for example",
    "start": "866079",
    "end": "871680"
  },
  {
    "text": "they are talking about a lot of extensions that provide additional capabilities that we",
    "start": "871680",
    "end": "878399"
  },
  {
    "text": "did not use at the moment so in harvester we wrote plugins that",
    "start": "878399",
    "end": "883839"
  },
  {
    "text": "use the kubernetes python api they submit the jobs they see the status of the jobs",
    "start": "883839",
    "end": "889120"
  },
  {
    "text": "and also when something goes wrong they clean up kubernetes jobs",
    "start": "889120",
    "end": "894399"
  },
  {
    "text": "and we also extended it a little bit with kubernetes common option options so we set limits so that the jobs cannot",
    "start": "894399",
    "end": "901519"
  },
  {
    "text": "run out of cpu or memory um we also use support affinity and",
    "start": "901519",
    "end": "906720"
  },
  {
    "text": "anti-affinity sometimes when we want for example the small jobs to get packed together not spread around into around",
    "start": "906720",
    "end": "912959"
  },
  {
    "text": "the cluster and also really we use priority classes when we want to have some",
    "start": "912959",
    "end": "919600"
  },
  {
    "text": "higher priority for the larger jobs and maybe the one thing that",
    "start": "919600",
    "end": "925680"
  },
  {
    "text": "sticks out a little bit from from the pure kubernetes world is this high energy physics file system that we",
    "start": "925680",
    "end": "931759"
  },
  {
    "text": "need to mount and that's the cvmfs so you need to imagine cvmfs is like a content delivery network and the atlas",
    "start": "931759",
    "end": "938639"
  },
  {
    "text": "software and all of the high-energy physics software is distributed through this content",
    "start": "938639",
    "end": "944399"
  },
  {
    "text": "delivery network and then on the nodes we have a cvmfs client that fuse mounts",
    "start": "944399",
    "end": "949920"
  },
  {
    "text": "the file system into the node and so we installed this as a daemon set and then cvmfs shares the",
    "start": "949920",
    "end": "958000"
  },
  {
    "text": "this file system through volumes with the with all of the all of the panda jobs that are running",
    "start": "958000",
    "end": "963120"
  },
  {
    "text": "in the cluster um following a little bit the motto of",
    "start": "963120",
    "end": "968399"
  },
  {
    "text": "this kubecon conference we've i think we've been also going onward and upward if you see the",
    "start": "968399",
    "end": "974639"
  },
  {
    "text": "the plot we started this is in 2020. we started with a handful of resources each",
    "start": "974639",
    "end": "979839"
  },
  {
    "text": "one was contributing a couple hundred cores and we had our mini kubernetes grid",
    "start": "979839",
    "end": "986079"
  },
  {
    "text": "but then we've been growing that significantly last year the this",
    "start": "986079",
    "end": "992160"
  },
  {
    "text": "big part here that's in blue that's actually the our first early adopter which is the university of victoria here",
    "start": "992160",
    "end": "998959"
  },
  {
    "text": "the the site admin in victoria he at the beginning he was testing up with the water seeing how it's working and then",
    "start": "998959",
    "end": "1005279"
  },
  {
    "text": "he was actually very happy with how it worked and then he moved all of his resources into a big kubernetes cluster",
    "start": "1005279",
    "end": "1010880"
  },
  {
    "text": "and went away from the from the traditional grid model and he also was uh",
    "start": "1010880",
    "end": "1016000"
  },
  {
    "text": "very convinced about the the support model that is generally in kubernetes under like the the white",
    "start": "1016000",
    "end": "1023040"
  },
  {
    "text": "support community and then we also those spikes that we see in the",
    "start": "1023040",
    "end": "1028959"
  },
  {
    "text": "plot um that's actually when we are scaling out to the cloud and we can do this at a very large scale as i will",
    "start": "1028959",
    "end": "1035760"
  },
  {
    "text": "show you in the next slides so some words about the elastic cloud",
    "start": "1035760",
    "end": "1042160"
  },
  {
    "text": "scale so this is actually the slide we are very proud about um and it shows how during the month of april",
    "start": "1042160",
    "end": "1049280"
  },
  {
    "text": "we were trying out different configurations for our kubernetes cluster that was in google in the in",
    "start": "1049280",
    "end": "1055200"
  },
  {
    "text": "belgium europe west one and we were at the beginning scaling up to twenty thousand cores and we did forty thousand",
    "start": "1055200",
    "end": "1061600"
  },
  {
    "text": "calls and we've ended up with uh almost hundred thousand cores um and we also",
    "start": "1061600",
    "end": "1067520"
  },
  {
    "text": "have been adapting our payload so that we are very resilient to um to preemptable vms and also lately we",
    "start": "1067520",
    "end": "1074480"
  },
  {
    "text": "are running on spot vm so that we don't have this 24-hour time limit um and",
    "start": "1074480",
    "end": "1079600"
  },
  {
    "text": "this very last uh scale out close to 900 close to 100 000 uh",
    "start": "1079600",
    "end": "1086559"
  },
  {
    "text": "cores and we managed to run with a one percent failure rate in our jobs on spot vms",
    "start": "1086559",
    "end": "1092640"
  },
  {
    "text": "which are have inherent failure by nature and during this day we managed to",
    "start": "1092640",
    "end": "1098799"
  },
  {
    "text": "process 100 million events on 100 000 virtual cpus in google",
    "start": "1098799",
    "end": "1104480"
  },
  {
    "text": "we use fairly big nodes we try to use the 80 vcpu nodes and also some 32 vcpu nodes",
    "start": "1104480",
    "end": "1112240"
  },
  {
    "text": "so the cluster overall is 2000 nodes something like that",
    "start": "1112240",
    "end": "1117679"
  },
  {
    "text": "and from the harvester point of view it's a scaled harvester instance that is also submitting all of the all of the",
    "start": "1117679",
    "end": "1123600"
  },
  {
    "text": "jobs to victorian to the other smaller sites and it's all of this is going to all of this is controlled by um just",
    "start": "1123600",
    "end": "1130880"
  },
  {
    "text": "fractions of of our time and then if we zoom in into the",
    "start": "1130880",
    "end": "1137120"
  },
  {
    "text": "30th of april it's this un this plot that i have down here and here you see the contribution from",
    "start": "1137120",
    "end": "1143600"
  },
  {
    "text": "all of the different sites that are contributing processing power to atlas and you see",
    "start": "1143600",
    "end": "1149440"
  },
  {
    "text": "that we are the on the 30th of april not always we were the second contributor just behind",
    "start": "1149440",
    "end": "1157440"
  },
  {
    "text": "vega which is our eurohbc and the top 500 supercomputer list",
    "start": "1157440",
    "end": "1162880"
  },
  {
    "text": "in the world so it's something that quite impressive the amount of computers you can come out on with not so much",
    "start": "1162880",
    "end": "1171200"
  },
  {
    "text": "person power invested the other cool thing that we can do with",
    "start": "1171200",
    "end": "1177360"
  },
  {
    "text": "all of these kubernetes classes is provide them heterogeneous architectures to the atlas experiment so we are living",
    "start": "1177360",
    "end": "1183840"
  },
  {
    "text": "now nowadays in this golden age for computer architecture development as",
    "start": "1183840",
    "end": "1189600"
  },
  {
    "text": "described in this acm communications article by paterson and",
    "start": "1189600",
    "end": "1195360"
  },
  {
    "text": "hennessy or also you see and if you see the nvidia keynotes you see for example how jensen pulls out the hottest gpus",
    "start": "1195360",
    "end": "1202559"
  },
  {
    "text": "out of the oven so while at last for 99 of the",
    "start": "1202559",
    "end": "1208640"
  },
  {
    "text": "processing that we do we just need the basic x86 cpus but we do not live um completely",
    "start": "1208640",
    "end": "1216240"
  },
  {
    "text": "isolated from what's happening outside and if we are not able to modify our software to for example use",
    "start": "1216240",
    "end": "1223120"
  },
  {
    "text": "arm resources or or use gpu we are going to be missing out a lot of opportunities in the future",
    "start": "1223120",
    "end": "1230000"
  },
  {
    "text": "um one example that was successful this year was for example the atlas software team they wanted to build",
    "start": "1230000",
    "end": "1236640"
  },
  {
    "text": "their software um for arm and want unneeded infrastructure that from end to end",
    "start": "1236640",
    "end": "1241840"
  },
  {
    "text": "they would want to simulate atlas events on on arm and",
    "start": "1241840",
    "end": "1247440"
  },
  {
    "text": "while there are great sites that are interested in purchasing arm but no one wants to be really the first one to do",
    "start": "1247440",
    "end": "1253840"
  },
  {
    "text": "so so what we did in this case we had a grant through university of fresno",
    "start": "1253840",
    "end": "1259520"
  },
  {
    "text": "in undergrad is on amazon so we set up an eks cluster with graviton two nodes",
    "start": "1259520",
    "end": "1266720"
  },
  {
    "text": "and you see well in these for just for illustration purposes you see",
    "start": "1266720",
    "end": "1272240"
  },
  {
    "text": "how the first ten thousand events ever processed on or simulated on arm were",
    "start": "1272240",
    "end": "1279919"
  },
  {
    "text": "being generated and here they are being compared to events on x86 to see if they align properly or not",
    "start": "1279919",
    "end": "1287600"
  },
  {
    "text": "and also well one one thing that i used for for this thing in particular were these multi-arc docker images which",
    "start": "1287600",
    "end": "1294559"
  },
  {
    "text": "really make your life much more easier you just need to build the image once and docker will automatically you say",
    "start": "1294559",
    "end": "1300720"
  },
  {
    "text": "the the architectures you want to support undocker will generate the different versions of the image and then",
    "start": "1300720",
    "end": "1306799"
  },
  {
    "text": "when the client puts the image the correct version will be sent based on the",
    "start": "1306799",
    "end": "1313120"
  },
  {
    "text": "on the architecture of the client now um",
    "start": "1313120",
    "end": "1319200"
  },
  {
    "text": "until now i've been focusing mostly on this batch processing and bulk processing uh now we are shifting gears a little",
    "start": "1319200",
    "end": "1325600"
  },
  {
    "text": "bit into the interactive analysis that lukas described one",
    "start": "1325600",
    "end": "1331200"
  },
  {
    "text": "some technologies that atlas and the high energy physics community is interested in are",
    "start": "1331200",
    "end": "1337840"
  },
  {
    "text": "interactive analysis facilities based for example on jupiter and on dusk",
    "start": "1337840",
    "end": "1343440"
  },
  {
    "text": "and so we installed on our gke cluster we installed also",
    "start": "1343440",
    "end": "1348480"
  },
  {
    "text": "jupiter and task and have been offering that to the users and also for example offering them to to start",
    "start": "1348480",
    "end": "1355919"
  },
  {
    "text": "notebooks or task classes using gpus look i will this is how",
    "start": "1355919",
    "end": "1363360"
  },
  {
    "text": "jupiter on the task integration looks like lucas will show it live so i will not get into it",
    "start": "1363360",
    "end": "1370159"
  },
  {
    "text": "but the one thing that is cool is this plot here and it shows this was done by lucas he's",
    "start": "1370159",
    "end": "1375679"
  },
  {
    "text": "scaling up his task cluster and running the same task again multiple times but each time on a larger",
    "start": "1375679",
    "end": "1382480"
  },
  {
    "text": "cluster and you can see first he run the task with hundred workers and it",
    "start": "1382480",
    "end": "1387679"
  },
  {
    "text": "took 40 minutes then he run it with 200 workers the time that he was waiting reduced to 20",
    "start": "1387679",
    "end": "1394159"
  },
  {
    "text": "minutes and like that until he was running it on 1500 workers the task is",
    "start": "1394159",
    "end": "1399360"
  },
  {
    "text": "done in five minutes and then he's done with the job and if he likes the resources the",
    "start": "1399360",
    "end": "1405600"
  },
  {
    "text": "the the results then he's done for the day and if not then he can he can repeat the process",
    "start": "1405600",
    "end": "1411280"
  },
  {
    "text": "interactively and can really focus on on his science and with this kind of",
    "start": "1411280",
    "end": "1416880"
  },
  {
    "text": "system um we provide them that capability and the cool thing is that um",
    "start": "1416880",
    "end": "1423120"
  },
  {
    "text": "installing this setup there are already hem charts available that do most of the",
    "start": "1423120",
    "end": "1428960"
  },
  {
    "text": "of the work for you like the task hub which provides directly jupiter and task",
    "start": "1428960",
    "end": "1434240"
  },
  {
    "text": "integrated helm chart the thing that i mostly needed to figure out was the configuration that i needed",
    "start": "1434240",
    "end": "1441039"
  },
  {
    "text": "to add for scalability and also cost effectiveness so i wanted to have like critical uh parts in in a particular",
    "start": "1441039",
    "end": "1448480"
  },
  {
    "text": "node pool which is guaranteed so that the user is not connected and his notebook gets slashed but then for",
    "start": "1448480",
    "end": "1455039"
  },
  {
    "text": "example the workers where we have thousands of workers that i put into it into cheap preemptable vms and like that",
    "start": "1455039",
    "end": "1461919"
  },
  {
    "text": "the cost is is much better and then one thing that i didn't work",
    "start": "1461919",
    "end": "1468640"
  },
  {
    "text": "with lucas but lucas has had a different projects with other people like rihanna",
    "start": "1468640",
    "end": "1475279"
  },
  {
    "text": "it's all of these workflow engines that you could also install on on kubernetes",
    "start": "1475279",
    "end": "1481360"
  },
  {
    "text": "and like that you have the whole the whole computing capabilities that are needed in one single kubernetes",
    "start": "1481360",
    "end": "1487840"
  },
  {
    "text": "cluster and also i think that the presentation in this room after us will actually be showing",
    "start": "1487840",
    "end": "1494080"
  },
  {
    "text": "a demo or or a presentation about tube flow used for machine learning at cern as well",
    "start": "1494080",
    "end": "1501840"
  },
  {
    "text": "and with that i will pass it back to lucas okay thanks fernando yeah so uh",
    "start": "1502240",
    "end": "1507679"
  },
  {
    "text": "we're now going to focus a bit more on this analysis side and we're actually trying to do a live demo so wish us",
    "start": "1507679",
    "end": "1513440"
  },
  {
    "text": "luck so what we're trying to uh to do is to recreate roughly this plot so it's kind",
    "start": "1513440",
    "end": "1519039"
  },
  {
    "text": "of the history of particle physics as it goes through the decades as we're able to",
    "start": "1519039",
    "end": "1524400"
  },
  {
    "text": "build more powerful and powerful particle accelerators we can move from the left hand side which is low energy",
    "start": "1524400",
    "end": "1530400"
  },
  {
    "text": "to the right-hand side to high energy and every time we cross the energy threshold we're able to create new",
    "start": "1530400",
    "end": "1536480"
  },
  {
    "text": "elementary particles so these peaks that you see are each elementary particles",
    "start": "1536480",
    "end": "1541679"
  },
  {
    "text": "so on the left hand side you see the jpsi particle that was in the 70s the nobel prize in the middle you see the",
    "start": "1541679",
    "end": "1548320"
  },
  {
    "text": "b quark discovery and on the right hand side you see also the z boson that was in the 80s the nobel prize and so these",
    "start": "1548320",
    "end": "1554880"
  },
  {
    "text": "are all discoveries so they're nothing new but uh what we can show is that we can rediscover these particles uh live",
    "start": "1554880",
    "end": "1561200"
  },
  {
    "text": "in the data that we collected the large hadron collider because it not only has its high energy but it will basically",
    "start": "1561200",
    "end": "1566799"
  },
  {
    "text": "create all of these particles as you go as well so let's switch over to uh this",
    "start": "1566799",
    "end": "1572320"
  },
  {
    "text": "analysis facility that fernando mentioned we have this kubernetes substrate part of this kubernetes substrate is dedicated for batch",
    "start": "1572320",
    "end": "1578480"
  },
  {
    "text": "processing very large scale and another part is focused on more analysis uh",
    "start": "1578480",
    "end": "1586080"
  },
  {
    "text": "focused uh workloads and so here we have uh jupiter and uh so i hope this is going to work",
    "start": "1586080",
    "end": "1592960"
  },
  {
    "text": "and so jupiter is a data science ide that a lot of people like so it's very much used in data science machine",
    "start": "1592960",
    "end": "1598799"
  },
  {
    "text": "learning but also by physicists and what we want to do is basically to grab some data and analyze",
    "start": "1598799",
    "end": "1606000"
  },
  {
    "text": "this data in a nice way but of course in the kind of particle physics context the",
    "start": "1606000",
    "end": "1612720"
  },
  {
    "text": "data is much too large in order to just be processing processing it in memory inside of a single node even if it's a",
    "start": "1612720",
    "end": "1618960"
  },
  {
    "text": "large node and so uh we need to have a scale out system in the background that so the user interface is just kind of",
    "start": "1618960",
    "end": "1625520"
  },
  {
    "text": "the front and then we have something that scales horizontally in the background and for this we will",
    "start": "1625520",
    "end": "1630960"
  },
  {
    "text": "basically take our data lake and so we authenticate to the storage",
    "start": "1630960",
    "end": "1636960"
  },
  {
    "text": "and we are able to grab some data from the data lake and here we are basically scaling a cluster",
    "start": "1636960",
    "end": "1645840"
  },
  {
    "text": "let me see so the scrolling doesn't work and so here we see that we scaled up the",
    "start": "1645840",
    "end": "1652559"
  },
  {
    "text": "cluster while i was talking we scaled it to 500 cores and of course 500 cores are",
    "start": "1652559",
    "end": "1657840"
  },
  {
    "text": "not a hundred thousand cores as we talked about but at the same time remember that this is a multi-tenant system so i as a",
    "start": "1657840",
    "end": "1664640"
  },
  {
    "text": "physicist want to go to this facility and then request 500 cores to do my interactive data analysis but then",
    "start": "1664640",
    "end": "1671360"
  },
  {
    "text": "there might be 100 other physicists that also want to have each their 500 cores and then very quickly you scale up very",
    "start": "1671360",
    "end": "1677679"
  },
  {
    "text": "fast and so here we can use a lot of the auto scaling capabilities of kubernetes to scale the cluster to whatever size is",
    "start": "1677679",
    "end": "1684000"
  },
  {
    "text": "needed how many physicists are actually trying to do data analysis and then if it's a more quieter period we can then",
    "start": "1684000",
    "end": "1690720"
  },
  {
    "text": "uh you know scale the cluster down again in order to conserve costs especially if it's on public cloud resources and so here once",
    "start": "1690720",
    "end": "1697600"
  },
  {
    "text": "you have a scaled up cluster you can then actually define your physics analysis inside of the jupyter notebook",
    "start": "1697600",
    "end": "1705600"
  },
  {
    "text": "and so i just have a bit trouble with scrolling and so once you have the",
    "start": "1705600",
    "end": "1712720"
  },
  {
    "text": "physics analysis defined in a jupyter notebook gets distributed to all the workers and the workers they",
    "start": "1712720",
    "end": "1717760"
  },
  {
    "text": "are able to do embarrassingly parallel data processing where each worker grabs a slice of the data from the data lake",
    "start": "1717760",
    "end": "1724000"
  },
  {
    "text": "they do whatever processing the user requested so we are trying to extract some physics information from the data",
    "start": "1724000",
    "end": "1730159"
  },
  {
    "text": "and then the results get accumulated back into this user interface until we are",
    "start": "1730159",
    "end": "1735679"
  },
  {
    "text": "and then we can visualize it so what we're doing here in particular is that we use einstein's famous like energy and",
    "start": "1735679",
    "end": "1741520"
  },
  {
    "text": "mass relationship so that we can infer the energy of the original particle by measuring uh the mass of the original",
    "start": "1741520",
    "end": "1747679"
  },
  {
    "text": "particle by measuring the energies of the decay products and so this um",
    "start": "1747679",
    "end": "1753679"
  },
  {
    "text": "you show us the dashboard yeah i'll show desperate i'll just need to uh copy this url so this is nice so",
    "start": "1753679",
    "end": "1761760"
  },
  {
    "text": "unlike like a batch system uh what we see is that we have uh basically",
    "start": "1761760",
    "end": "1768000"
  },
  {
    "text": "a real-time view and what's happening inside of the data and so here we are uh actually visualizing the results and we",
    "start": "1768000",
    "end": "1774240"
  },
  {
    "text": "recreated uh the plot that we just showed in the uh in the original slide and so uh we can also go",
    "start": "1774240",
    "end": "1781679"
  },
  {
    "text": "uh to the dashboard let me see and",
    "start": "1781679",
    "end": "1787440"
  },
  {
    "text": "and so so you can see kind of in a live view of what's happening inside of",
    "start": "1788559",
    "end": "1793600"
  },
  {
    "text": "the dashboard and what is happening on the data processing site and so this gives us a very interactive feel of",
    "start": "1793600",
    "end": "1799440"
  },
  {
    "text": "what's going on and so here we basically process 60 million events in just two minutes and we basically recreated",
    "start": "1799440",
    "end": "1806240"
  },
  {
    "text": "all of this particle physics history uh live on kubernetes uh in a live demo so i'm very happy that",
    "start": "1806240",
    "end": "1812000"
  },
  {
    "text": "this worked even though the scrolling didn't work just as well as we wanted to",
    "start": "1812000",
    "end": "1817039"
  },
  {
    "text": "okay so let's go back to our slides so this is my summary so what",
    "start": "1817039",
    "end": "1822480"
  },
  {
    "text": "we showed is basically uh the way that we imagine interactive data analysis for",
    "start": "1822480",
    "end": "1827520"
  },
  {
    "text": "physicists to work we have a data lake that is uh close by to the analysis facility it's hundreds of terabytes or",
    "start": "1827520",
    "end": "1835360"
  },
  {
    "text": "even petabytes and as a user i log on to the system and i can scale out dynamically to whatever many cores i",
    "start": "1835360",
    "end": "1841760"
  },
  {
    "text": "want and then it's a multi-tenant system where a lot of people are able to use this interface and they can use jupyter",
    "start": "1841760",
    "end": "1847919"
  },
  {
    "text": "notebooks in order to do their data analysis okay so for this i'll then uh",
    "start": "1847919",
    "end": "1853120"
  },
  {
    "text": "hand it back to fernando for the summary thanks for the demo lucas",
    "start": "1853120",
    "end": "1860320"
  },
  {
    "text": "yeah so just concluding so i think we've shown you that kubernetes goes far beyond just pure",
    "start": "1860320",
    "end": "1867200"
  },
  {
    "text": "service management uh we've been using it natively for bunch processing we were even not expecting we",
    "start": "1867200",
    "end": "1874320"
  },
  {
    "text": "would get to this scale we were thinking this would be at a few thousand uh course but we managed to scale up two",
    "start": "1874320",
    "end": "1880559"
  },
  {
    "text": "hundred thousand cores in a single cluster and i think that we might not be at the limit yet and we are already",
    "start": "1880559",
    "end": "1886559"
  },
  {
    "text": "trying to convince people to let us try a higher scale",
    "start": "1886559",
    "end": "1893640"
  },
  {
    "text": "managed kubernetes clusters simply work they work great they you don't really the less you look at",
    "start": "1893760",
    "end": "1899360"
  },
  {
    "text": "them it's better they auto heal themselves the the broken notes they get repaired or or",
    "start": "1899360",
    "end": "1905279"
  },
  {
    "text": "swapped so it works very nicely um [Music] also kubernetes we can run it",
    "start": "1905279",
    "end": "1912480"
  },
  {
    "text": "on prem we can run it on the cloud it's going to be the same thing",
    "start": "1912480",
    "end": "1918559"
  },
  {
    "text": "and also it's very easy to integrate what i call exotic resources it's just the resources that we don't have a lot",
    "start": "1918559",
    "end": "1924240"
  },
  {
    "text": "of in our grid sites besides this uh batch processing",
    "start": "1924240",
    "end": "1929840"
  },
  {
    "text": "processing we also showed this kind of next generation interactive services that",
    "start": "1929840",
    "end": "1934880"
  },
  {
    "text": "that users can use for interactive analysis facilities um and also",
    "start": "1934880",
    "end": "1940080"
  },
  {
    "text": "kubernetes provides a very high elasticity to scale up and down with as the users",
    "start": "1940080",
    "end": "1948320"
  },
  {
    "text": "request the workers and obviously there are other functionalities that can be added other services functionalities",
    "start": "1948320",
    "end": "1954320"
  },
  {
    "text": "from that for example are being looked at in the kubernetes working group for",
    "start": "1954320",
    "end": "1959440"
  },
  {
    "text": "batches and so on and well in the next years we will see how this all of this kubernetes",
    "start": "1959440",
    "end": "1965679"
  },
  {
    "text": "integration is accepted in in our wlcg world and",
    "start": "1965679",
    "end": "1971440"
  },
  {
    "text": "maybe one dream is can we have the same way there is from zero to two beta can",
    "start": "1971440",
    "end": "1976720"
  },
  {
    "text": "we have a helm chart on githubs that does from zero to uh to a grid side where with one one commit you will have",
    "start": "1976720",
    "end": "1983679"
  },
  {
    "text": "a grid site installed so we will see how far we get there",
    "start": "1983679",
    "end": "1988960"
  },
  {
    "text": "um and also we need to see how um in our university settings we will also start deploying",
    "start": "1988960",
    "end": "1995360"
  },
  {
    "text": "more kubernetes clusters so yeah it's it's not perfect yet there is still a lot of work to be done but um i think",
    "start": "1995360",
    "end": "2001679"
  },
  {
    "text": "that with fairly reasonable amount of effort that we dedicated to it we have been reaching",
    "start": "2001679",
    "end": "2009120"
  },
  {
    "text": "very promising results um and well and just to conclude some acknowledgement acknowledgements to",
    "start": "2009120",
    "end": "2015840"
  },
  {
    "text": "people that have worked with us and also i mentioned that google actually gave us the",
    "start": "2015840",
    "end": "2021279"
  },
  {
    "text": "funding for for lucas demo so thanks a lot for that and that's it from us",
    "start": "2021279",
    "end": "2027970"
  },
  {
    "text": "[Applause]",
    "start": "2027970",
    "end": "2032479"
  }
]
[
  {
    "text": "yeah hello everyone thank you for",
    "start": "199",
    "end": "1920"
  },
  {
    "text": "attending my presentation today um today",
    "start": "1920",
    "end": "5080"
  },
  {
    "text": "I'm going to talk about how to scale out",
    "start": "5080",
    "end": "8519"
  },
  {
    "text": "our time series database Infinity uh",
    "start": "8519",
    "end": "11759"
  },
  {
    "text": "using kuber netics invoy and other Open",
    "start": "11759",
    "end": "15160"
  },
  {
    "text": "Source",
    "start": "15160",
    "end": "16560"
  },
  {
    "text": "Products anyway let me introduce myself",
    "start": "16560",
    "end": "20119"
  },
  {
    "text": "my name is hii and belonging to Loi",
    "start": "20119",
    "end": "23240"
  },
  {
    "text": "Corporation and my main mission is to",
    "start": "23240",
    "end": "25960"
  },
  {
    "text": "build and operate time Ser database that",
    "start": "25960",
    "end": "29400"
  },
  {
    "text": "is kind of develop a PL form to",
    "start": "29400",
    "end": "32840"
  },
  {
    "text": "accommodate a parab scale of Matrix and",
    "start": "32840",
    "end": "36320"
  },
  {
    "text": "also that is primitive compatible",
    "start": "36320",
    "end": "39960"
  },
  {
    "text": "API anyway let's do the C",
    "start": "39960",
    "end": "44239"
  },
  {
    "text": "Chase raise your hand if you",
    "start": "44239",
    "end": "47840"
  },
  {
    "text": "experience uh dealing with parab scale",
    "start": "47840",
    "end": "50840"
  },
  {
    "text": "of metric by",
    "start": "50840",
    "end": "53640"
  },
  {
    "text": "yourself okay there is no one that's",
    "start": "54280",
    "end": "58320"
  },
  {
    "text": "fine um observability is really having",
    "start": "58320",
    "end": "62359"
  },
  {
    "text": "been evaluating for many people this",
    "start": "62359",
    "end": "66520"
  },
  {
    "text": "means uh many people think about to save",
    "start": "66520",
    "end": "69520"
  },
  {
    "text": "the more data for teret tracing logs",
    "start": "69520",
    "end": "73479"
  },
  {
    "text": "whatever so this means as data",
    "start": "73479",
    "end": "77080"
  },
  {
    "text": "increases um several issues showing nap",
    "start": "77080",
    "end": "81000"
  },
  {
    "text": "to accommodate parab scale of data in",
    "start": "81000",
    "end": "83200"
  },
  {
    "text": "the",
    "start": "83200",
    "end": "83920"
  },
  {
    "text": "future this means cost scalability",
    "start": "83920",
    "end": "88119"
  },
  {
    "text": "capacity issues May showing na in the",
    "start": "88119",
    "end": "92680"
  },
  {
    "text": "future all right so L one of platform",
    "start": "92680",
    "end": "97479"
  },
  {
    "text": "engineers in the company I'm going to",
    "start": "97479",
    "end": "100439"
  },
  {
    "text": "talk about how to deal with parabot",
    "start": "100439",
    "end": "103119"
  },
  {
    "text": "scale metrics by using several Open",
    "start": "103119",
    "end": "106520"
  },
  {
    "text": "Source Products and object",
    "start": "106520",
    "end": "110000"
  },
  {
    "text": "storage um and",
    "start": "110000",
    "end": "112240"
  },
  {
    "text": "kubernetes all",
    "start": "112240",
    "end": "114280"
  },
  {
    "text": "right first things first let me",
    "start": "114280",
    "end": "117280"
  },
  {
    "text": "introduce our background of our products",
    "start": "117280",
    "end": "119880"
  },
  {
    "text": "for better",
    "start": "119880",
    "end": "122240"
  },
  {
    "text": "understanding so as I mentioned um our",
    "start": "122240",
    "end": "126200"
  },
  {
    "text": "time series database is compatible with",
    "start": "126200",
    "end": "129879"
  },
  {
    "text": "API so these clients should be like",
    "start": "129879",
    "end": "133760"
  },
  {
    "text": "Paramus instance metri collector open",
    "start": "133760",
    "end": "137280"
  },
  {
    "text": "chory collector and metrix agent so",
    "start": "137280",
    "end": "140480"
  },
  {
    "text": "these are our clients right and of",
    "start": "140480",
    "end": "144080"
  },
  {
    "text": "course we provide injection API and this",
    "start": "144080",
    "end": "148480"
  },
  {
    "text": "API try to save the data into our time",
    "start": "148480",
    "end": "151400"
  },
  {
    "text": "Ser",
    "start": "151400",
    "end": "153560"
  },
  {
    "text": "database and additionally we provide",
    "start": "153560",
    "end": "157640"
  },
  {
    "text": "query API and that is from Q compatible",
    "start": "157640",
    "end": "162280"
  },
  {
    "text": "API this means you can see your data uh",
    "start": "162280",
    "end": "165519"
  },
  {
    "text": "VI your Primitives or graph fanner to",
    "start": "165519",
    "end": "168440"
  },
  {
    "text": "show up your data as the graph and",
    "start": "168440",
    "end": "171560"
  },
  {
    "text": "dashboard right so this platform is",
    "start": "171560",
    "end": "175440"
  },
  {
    "text": "called IMO flash in the company",
    "start": "175440",
    "end": "180280"
  },
  {
    "text": "all right in the first place what is",
    "start": "180280",
    "end": "182799"
  },
  {
    "text": "metrix metrix consist of two types of",
    "start": "182799",
    "end": "186159"
  },
  {
    "text": "data metadata or sample for metadata",
    "start": "186159",
    "end": "191040"
  },
  {
    "text": "this is just a kind of key value pairs",
    "start": "191040",
    "end": "194159"
  },
  {
    "text": "it's like P name and N name and",
    "start": "194159",
    "end": "197560"
  },
  {
    "text": "environmental name",
    "start": "197560",
    "end": "199560"
  },
  {
    "text": "whatever and for sample this is like",
    "start": "199560",
    "end": "203120"
  },
  {
    "text": "actual time Ser data this is the type of",
    "start": "203120",
    "end": "206640"
  },
  {
    "text": "of time stamp value and metric value",
    "start": "206640",
    "end": "210280"
  },
  {
    "text": "so this is",
    "start": "210280",
    "end": "212640"
  },
  {
    "text": "Matrix all right let's act the let's",
    "start": "212640",
    "end": "215560"
  },
  {
    "text": "look at the our query pass in the system",
    "start": "215560",
    "end": "218760"
  },
  {
    "text": "um our client try to send promql request",
    "start": "218760",
    "end": "222000"
  },
  {
    "text": "to our query",
    "start": "222000",
    "end": "223400"
  },
  {
    "text": "API and then this API tries to retrieve",
    "start": "223400",
    "end": "228480"
  },
  {
    "text": "Target metx ideas with given promql and",
    "start": "228480",
    "end": "232640"
  },
  {
    "text": "time range in the request but requesting",
    "start": "232640",
    "end": "235439"
  },
  {
    "text": "for metadata specific database right",
    "start": "235439",
    "end": "239400"
  },
  {
    "text": "after that this database Returns the",
    "start": "239400",
    "end": "242239"
  },
  {
    "text": "metrix",
    "start": "242239",
    "end": "243519"
  },
  {
    "text": "IDS",
    "start": "243519",
    "end": "245040"
  },
  {
    "text": "then this API tries to retrieve the",
    "start": "245040",
    "end": "248840"
  },
  {
    "text": "samples with given Target metrix IDs and",
    "start": "248840",
    "end": "252200"
  },
  {
    "text": "time range in the request by requesting",
    "start": "252200",
    "end": "255159"
  },
  {
    "text": "for sample specific database and this",
    "start": "255159",
    "end": "258720"
  },
  {
    "text": "database Returns the",
    "start": "258720",
    "end": "260959"
  },
  {
    "text": "samples to API and then this this API",
    "start": "260959",
    "end": "265080"
  },
  {
    "text": "evaluates the given samples uh with",
    "start": "265080",
    "end": "267919"
  },
  {
    "text": "promu engine and and return the final",
    "start": "267919",
    "end": "270960"
  },
  {
    "text": "results to clients so this is how it",
    "start": "270960",
    "end": "273520"
  },
  {
    "text": "works of our",
    "start": "273520",
    "end": "276320"
  },
  {
    "text": "system all right as I mentioned there",
    "start": "276320",
    "end": "279240"
  },
  {
    "text": "are two types of database metadata",
    "start": "279240",
    "end": "281720"
  },
  {
    "text": "specific database sample specific",
    "start": "281720",
    "end": "284320"
  },
  {
    "text": "database and also each database has two",
    "start": "284320",
    "end": "287960"
  },
  {
    "text": "layers IM memory layers or persistent",
    "start": "287960",
    "end": "291160"
  },
  {
    "text": "layer for IM memory layer this is for",
    "start": "291160",
    "end": "294199"
  },
  {
    "text": "the data within 24 hours right this is",
    "start": "294199",
    "end": "297880"
  },
  {
    "text": "like hot data cache",
    "start": "297880",
    "end": "300680"
  },
  {
    "text": "uh database and also for persistent",
    "start": "300680",
    "end": "303720"
  },
  {
    "text": "layer this is for the data after 24",
    "start": "303720",
    "end": "307280"
  },
  {
    "text": "hours and we are using Open Source",
    "start": "307280",
    "end": "309840"
  },
  {
    "text": "Products out there it's like elastic",
    "start": "309840",
    "end": "312199"
  },
  {
    "text": "search for metadata and Cassandra for",
    "start": "312199",
    "end": "315160"
  },
  {
    "text": "sample database so this is our time Ser",
    "start": "315160",
    "end": "318880"
  },
  {
    "text": "database",
    "start": "318880",
    "end": "320840"
  },
  {
    "text": "right and also this is the uh data size",
    "start": "320840",
    "end": "326120"
  },
  {
    "text": "so obviously um sample data usage is",
    "start": "326120",
    "end": "330240"
  },
  {
    "text": "dominant in the data",
    "start": "330240",
    "end": "332759"
  },
  {
    "text": "usage so we already have one billion of",
    "start": "332759",
    "end": "335960"
  },
  {
    "text": "metric and one parab of sample data with",
    "start": "335960",
    "end": "340080"
  },
  {
    "text": "replication and also 2.7 terabyte of",
    "start": "340080",
    "end": "344240"
  },
  {
    "text": "sample data is being ingested every day",
    "start": "344240",
    "end": "348199"
  },
  {
    "text": "so this is obviously uh sample data is",
    "start": "348199",
    "end": "351360"
  },
  {
    "text": "dominant in our data",
    "start": "351360",
    "end": "354160"
  },
  {
    "text": "usage this means Cassandra is the",
    "start": "354160",
    "end": "357360"
  },
  {
    "text": "bottleneck for our used cases but of",
    "start": "357360",
    "end": "360319"
  },
  {
    "text": "course we already know Cassandra is a",
    "start": "360319",
    "end": "362880"
  },
  {
    "text": "really great product in most of most of",
    "start": "362880",
    "end": "366039"
  },
  {
    "text": "us use cases but unfortunately for time",
    "start": "366039",
    "end": "369960"
  },
  {
    "text": "Ser data this is the bottleneck for us",
    "start": "369960",
    "end": "373960"
  },
  {
    "text": "with these three issues cost scalability",
    "start": "373960",
    "end": "378120"
  },
  {
    "text": "and",
    "start": "378120",
    "end": "378960"
  },
  {
    "text": "capacity and basically we are enforced",
    "start": "378960",
    "end": "382039"
  },
  {
    "text": "to use our private class Services",
    "start": "382039",
    "end": "384960"
  },
  {
    "text": "instead of ads with DCP whatever so",
    "start": "384960",
    "end": "389880"
  },
  {
    "text": "there is no manage service for Cassandra",
    "start": "389880",
    "end": "392639"
  },
  {
    "text": "this means you need to provision your uh",
    "start": "392639",
    "end": "397120"
  },
  {
    "text": "physical machines or virtual machines to",
    "start": "397120",
    "end": "399479"
  },
  {
    "text": "deploy Cassandra by yourself and also we",
    "start": "399479",
    "end": "403160"
  },
  {
    "text": "already have 420 noes in the cluster so",
    "start": "403160",
    "end": "407520"
  },
  {
    "text": "this means uh server cost is really",
    "start": "407520",
    "end": "410520"
  },
  {
    "text": "expensive in the year due to the parab",
    "start": "410520",
    "end": "413840"
  },
  {
    "text": "scale of",
    "start": "413840",
    "end": "415160"
  },
  {
    "text": "data and for scalability issues it takes",
    "start": "415160",
    "end": "419599"
  },
  {
    "text": "six hours to scale out even single node",
    "start": "419599",
    "end": "423440"
  },
  {
    "text": "right due to the parab scale of data and",
    "start": "423440",
    "end": "427400"
  },
  {
    "text": "basically Cassandra provides repair",
    "start": "427400",
    "end": "430120"
  },
  {
    "text": "command to detect data corruption and",
    "start": "430120",
    "end": "433440"
  },
  {
    "text": "repair automatically the data corruption",
    "start": "433440",
    "end": "435800"
  },
  {
    "text": "but unfortunately our repair commands",
    "start": "435800",
    "end": "438560"
  },
  {
    "text": "for our cluster never completes due to",
    "start": "438560",
    "end": "441800"
  },
  {
    "text": "the data",
    "start": "441800",
    "end": "443720"
  },
  {
    "text": "sites and even worse we are not allowed",
    "start": "443720",
    "end": "447280"
  },
  {
    "text": "to obtain additional servers provision",
    "start": "447280",
    "end": "450319"
  },
  {
    "text": "any additional cand cluster so this",
    "start": "450319",
    "end": "453560"
  },
  {
    "text": "means um we don't have enough capacity",
    "start": "453560",
    "end": "457000"
  },
  {
    "text": "to gate us as",
    "start": "457000",
    "end": "460199"
  },
  {
    "text": "metric so to mitigate this issue these",
    "start": "460479",
    "end": "465000"
  },
  {
    "text": "three issues we needed a new data",
    "start": "465000",
    "end": "468240"
  },
  {
    "text": "storage layer for",
    "start": "468240",
    "end": "470199"
  },
  {
    "text": "accommodating huge amount of",
    "start": "470199",
    "end": "473400"
  },
  {
    "text": "samples all right then why the use",
    "start": "473400",
    "end": "477599"
  },
  {
    "text": "object storage because this is a really",
    "start": "477599",
    "end": "480720"
  },
  {
    "text": "effective way to accommodate huge amount",
    "start": "480720",
    "end": "483080"
  },
  {
    "text": "of data right and also by delegating",
    "start": "483080",
    "end": "487039"
  },
  {
    "text": "storage concerns it's like replication",
    "start": "487039",
    "end": "490000"
  },
  {
    "text": "or back Gap or clustering things to",
    "start": "490000",
    "end": "493639"
  },
  {
    "text": "object storage we don't have to",
    "start": "493639",
    "end": "495720"
  },
  {
    "text": "implement them by ourselves so this is a",
    "start": "495720",
    "end": "498879"
  },
  {
    "text": "really huge",
    "start": "498879",
    "end": "500520"
  },
  {
    "text": "Advantage right and also there is a S3",
    "start": "500520",
    "end": "506400"
  },
  {
    "text": "compatible S3 service in our private",
    "start": "506400",
    "end": "508879"
  },
  {
    "text": "cloud service",
    "start": "508879",
    "end": "510520"
  },
  {
    "text": "this means it has a sufficient capacity",
    "start": "510520",
    "end": "513279"
  },
  {
    "text": "and",
    "start": "513279",
    "end": "514880"
  },
  {
    "text": "scalability and also there lot of real",
    "start": "514880",
    "end": "519279"
  },
  {
    "text": "world better tested examples like codex",
    "start": "519279",
    "end": "522880"
  },
  {
    "text": "and mimir and Thanos they are Open",
    "start": "522880",
    "end": "525880"
  },
  {
    "text": "Source Products dealing with time Ser",
    "start": "525880",
    "end": "528720"
  },
  {
    "text": "data and metrics as well and also this",
    "start": "528720",
    "end": "532640"
  },
  {
    "text": "back end storage is obviously object",
    "start": "532640",
    "end": "534839"
  },
  {
    "text": "storage as well so that's why we believe",
    "start": "534839",
    "end": "538160"
  },
  {
    "text": "that we attain the",
    "start": "538160",
    "end": "540160"
  },
  {
    "text": "this kind of architecture of top of the",
    "start": "540160",
    "end": "542600"
  },
  {
    "text": "object storage to accommodate better by",
    "start": "542600",
    "end": "544600"
  },
  {
    "text": "scale of",
    "start": "544600",
    "end": "546200"
  },
  {
    "text": "data but some people may think about um",
    "start": "546200",
    "end": "550360"
  },
  {
    "text": "migration on Cassandra into your equal",
    "start": "550360",
    "end": "553920"
  },
  {
    "text": "cluster but unfortunately even though",
    "start": "553920",
    "end": "556959"
  },
  {
    "text": "you migrate your cassand cluster into",
    "start": "556959",
    "end": "559680"
  },
  {
    "text": "your KU cluster uh data us it itself",
    "start": "559680",
    "end": "563440"
  },
  {
    "text": "never change right so in that sense um",
    "start": "563440",
    "end": "567800"
  },
  {
    "text": "the data cost and scalability issue",
    "start": "567800",
    "end": "570079"
  },
  {
    "text": "never go away so that's why when we we",
    "start": "570079",
    "end": "573680"
  },
  {
    "text": "went Wheels object storage",
    "start": "573680",
    "end": "577279"
  },
  {
    "text": "way all right so the final goal",
    "start": "577880",
    "end": "581880"
  },
  {
    "text": "architecture is going to be like this we",
    "start": "581880",
    "end": "584200"
  },
  {
    "text": "are going to have this additional",
    "start": "584200",
    "end": "586399"
  },
  {
    "text": "persistent layer on top of the object",
    "start": "586399",
    "end": "589480"
  },
  {
    "text": "storage this is for the data um after",
    "start": "589480",
    "end": "593040"
  },
  {
    "text": "two weeks why not replace Cassandra",
    "start": "593040",
    "end": "595959"
  },
  {
    "text": "entirely with object storage layer um",
    "start": "595959",
    "end": "599079"
  },
  {
    "text": "there are several reasons but and the",
    "start": "599079",
    "end": "602320"
  },
  {
    "text": "most significant is",
    "start": "602320",
    "end": "604680"
  },
  {
    "text": "because uh we couldn't anticipate the",
    "start": "604680",
    "end": "607680"
  },
  {
    "text": "performance impact on user work RS",
    "start": "607680",
    "end": "610600"
  },
  {
    "text": "because object storage is well known as",
    "start": "610600",
    "end": "612959"
  },
  {
    "text": "higher latency storage server right so",
    "start": "612959",
    "end": "616920"
  },
  {
    "text": "we need to gather some experimental um",
    "start": "616920",
    "end": "620440"
  },
  {
    "text": "feedback from user workload and",
    "start": "620440",
    "end": "622720"
  },
  {
    "text": "production",
    "start": "622720",
    "end": "623880"
  },
  {
    "text": "environment and of course we are aiming",
    "start": "623880",
    "end": "626079"
  },
  {
    "text": "for uh migrating to entirely to object",
    "start": "626079",
    "end": "629680"
  },
  {
    "text": "storage later in the",
    "start": "629680",
    "end": "632320"
  },
  {
    "text": "future anyway so how do you construct",
    "start": "632320",
    "end": "636120"
  },
  {
    "text": "such kind of databas on top of the",
    "start": "636120",
    "end": "638360"
  },
  {
    "text": "object",
    "start": "638360",
    "end": "639200"
  },
  {
    "text": "storage I think there are three",
    "start": "639200",
    "end": "641360"
  },
  {
    "text": "important things data structure and",
    "start": "641360",
    "end": "643920"
  },
  {
    "text": "distribut writing and distributed",
    "start": "643920",
    "end": "646160"
  },
  {
    "text": "reading so I'll explain one by",
    "start": "646160",
    "end": "649720"
  },
  {
    "text": "one all right first read data",
    "start": "649720",
    "end": "654120"
  },
  {
    "text": "structure so let me clarify the",
    "start": "654120",
    "end": "657600"
  },
  {
    "text": "requirements the input is supposed to be",
    "start": "657600",
    "end": "660560"
  },
  {
    "text": "Target metrix ideas and time range this",
    "start": "660560",
    "end": "664480"
  },
  {
    "text": "is given in a",
    "start": "664480",
    "end": "666480"
  },
  {
    "text": "request the output going to be like the",
    "start": "666480",
    "end": "669920"
  },
  {
    "text": "tables of time stamp value and Metric",
    "start": "669920",
    "end": "672600"
  },
  {
    "text": "values so this is a",
    "start": "672600",
    "end": "675959"
  },
  {
    "text": "requirements and also data sharing is",
    "start": "675959",
    "end": "678519"
  },
  {
    "text": "really important because there is a",
    "start": "678519",
    "end": "681000"
  },
  {
    "text": "limitation in our private Cloud S3",
    "start": "681000",
    "end": "683600"
  },
  {
    "text": "compatible object storage that is the",
    "start": "683600",
    "end": "686720"
  },
  {
    "text": "object count limitation in the bracket",
    "start": "686720",
    "end": "689720"
  },
  {
    "text": "that is 10 uh 10",
    "start": "689720",
    "end": "692800"
  },
  {
    "text": "million uh object counts in the backet",
    "start": "692800",
    "end": "697160"
  },
  {
    "text": "so in that sense uh you are going to",
    "start": "697160",
    "end": "700600"
  },
  {
    "text": "have one billion of files if you don't",
    "start": "700600",
    "end": "703880"
  },
  {
    "text": "merge multiple samples into a single",
    "start": "703880",
    "end": "707040"
  },
  {
    "text": "file so it's inevitable to merge",
    "start": "707040",
    "end": "710200"
  },
  {
    "text": "multiple samples into single file",
    "start": "710200",
    "end": "714040"
  },
  {
    "text": "otherwise it's not",
    "start": "714040",
    "end": "716680"
  },
  {
    "text": "feasible and also shouting is a really",
    "start": "716680",
    "end": "719240"
  },
  {
    "text": "effective for concurrency control and",
    "start": "719240",
    "end": "722399"
  },
  {
    "text": "concurrent processing",
    "start": "722399",
    "end": "724320"
  },
  {
    "text": "data right so that's why sharing is a",
    "start": "724320",
    "end": "728240"
  },
  {
    "text": "really important",
    "start": "728240",
    "end": "729959"
  },
  {
    "text": "thing so we Define two types of strategy",
    "start": "729959",
    "end": "734279"
  },
  {
    "text": "for that the first one is backet based",
    "start": "734279",
    "end": "737800"
  },
  {
    "text": "sharing so each braet has one week of",
    "start": "737800",
    "end": "741800"
  },
  {
    "text": "time window of data and also it includes",
    "start": "741800",
    "end": "745440"
  },
  {
    "text": "all data of shirts and for Dory work",
    "start": "745440",
    "end": "749560"
  },
  {
    "text": "this actually represents a Shir and a",
    "start": "749560",
    "end": "753959"
  },
  {
    "text": "Shir is composed of for hours of time",
    "start": "753959",
    "end": "759000"
  },
  {
    "text": "window and tenant ID and Sh Factor these",
    "start": "759000",
    "end": "762240"
  },
  {
    "text": "three",
    "start": "762240",
    "end": "764320"
  },
  {
    "text": "combination so this is the sharing",
    "start": "764320",
    "end": "768680"
  },
  {
    "text": "strategy so the final data structure is",
    "start": "768760",
    "end": "771519"
  },
  {
    "text": "going to be like this um one bucket has",
    "start": "771519",
    "end": "775560"
  },
  {
    "text": "one week of data and each directory repr",
    "start": "775560",
    "end": "779240"
  },
  {
    "text": "presents each shirt and each shirt has a",
    "start": "779240",
    "end": "783199"
  },
  {
    "text": "single sample F combined with multiple",
    "start": "783199",
    "end": "786800"
  },
  {
    "text": "sample",
    "start": "786800",
    "end": "788040"
  },
  {
    "text": "data but you don't want to download this",
    "start": "788040",
    "end": "791279"
  },
  {
    "text": "entire file whenever you query for your",
    "start": "791279",
    "end": "793880"
  },
  {
    "text": "object storage right because this sample",
    "start": "793880",
    "end": "797519"
  },
  {
    "text": "data file is really too",
    "start": "797519",
    "end": "800760"
  },
  {
    "text": "large so that's why it we introduce",
    "start": "800760",
    "end": "803800"
  },
  {
    "text": "index file this is kind of a mapping",
    "start": "803800",
    "end": "807000"
  },
  {
    "text": "table between Target metrix IDs and bite",
    "start": "807000",
    "end": "810959"
  },
  {
    "text": "offset in the sample files so with this",
    "start": "810959",
    "end": "814800"
  },
  {
    "text": "you can identify the location in the",
    "start": "814800",
    "end": "817440"
  },
  {
    "text": "sample files before you query and you",
    "start": "817440",
    "end": "820279"
  },
  {
    "text": "download the data and you can partially",
    "start": "820279",
    "end": "823040"
  },
  {
    "text": "download sample file by using by range",
    "start": "823040",
    "end": "825800"
  },
  {
    "text": "request that is S3 compatible",
    "start": "825800",
    "end": "829399"
  },
  {
    "text": "LPI so this is the data",
    "start": "829399",
    "end": "832519"
  },
  {
    "text": "structure right so how do you write this",
    "start": "832519",
    "end": "836040"
  },
  {
    "text": "kind of data structure on object storage",
    "start": "836040",
    "end": "840639"
  },
  {
    "text": "so let me clarify the batch processing",
    "start": "840639",
    "end": "843360"
  },
  {
    "text": "of Cassandra because the new one should",
    "start": "843360",
    "end": "846600"
  },
  {
    "text": "be similar to this one um bat server",
    "start": "846600",
    "end": "850959"
  },
  {
    "text": "retrieves one one uh hours of data first",
    "start": "850959",
    "end": "855920"
  },
  {
    "text": "uh from the sample database this is a",
    "start": "855920",
    "end": "858160"
  },
  {
    "text": "memory database layer and this B server",
    "start": "858160",
    "end": "861120"
  },
  {
    "text": "tries to save and compress the data into",
    "start": "861120",
    "end": "864600"
  },
  {
    "text": "Cassandra so this is how it works on",
    "start": "864600",
    "end": "866959"
  },
  {
    "text": "Cassandra batch processing",
    "start": "866959",
    "end": "870320"
  },
  {
    "text": "but how do you apply this concept to",
    "start": "870320",
    "end": "873120"
  },
  {
    "text": "object",
    "start": "873120",
    "end": "874519"
  },
  {
    "text": "storage basically by server randomly",
    "start": "874519",
    "end": "878000"
  },
  {
    "text": "retrieve the data from random node of a",
    "start": "878000",
    "end": "881199"
  },
  {
    "text": "memory database of sample database so",
    "start": "881199",
    "end": "884440"
  },
  {
    "text": "this means According to some shouting",
    "start": "884440",
    "end": "886920"
  },
  {
    "text": "strategy you need to aggregate your data",
    "start": "886920",
    "end": "890480"
  },
  {
    "text": "somewhere so this is the space where the",
    "start": "890480",
    "end": "893880"
  },
  {
    "text": "new component Shadow agregator comes",
    "start": "893880",
    "end": "897120"
  },
  {
    "text": "in so basically sh agregator Aggregates",
    "start": "897120",
    "end": "901040"
  },
  {
    "text": "all samples of each shirt right",
    "start": "901040",
    "end": "904959"
  },
  {
    "text": "according to shading strategy we",
    "start": "904959",
    "end": "908320"
  },
  {
    "text": "Define and also to ensure the",
    "start": "908320",
    "end": "912480"
  },
  {
    "text": "scalability um when we increase the",
    "start": "912480",
    "end": "915000"
  },
  {
    "text": "number of shirts it also can be",
    "start": "915000",
    "end": "918399"
  },
  {
    "text": "increased the number of Parts",
    "start": "918399",
    "end": "921360"
  },
  {
    "text": "accordingly and also data resiliency is",
    "start": "921360",
    "end": "924399"
  },
  {
    "text": "a really important so once it receives",
    "start": "924399",
    "end": "928079"
  },
  {
    "text": "the data from that server it need to",
    "start": "928079",
    "end": "931240"
  },
  {
    "text": "persist the data in local disk it's like",
    "start": "931240",
    "end": "934240"
  },
  {
    "text": "write a headlock so that it can recover",
    "start": "934240",
    "end": "937800"
  },
  {
    "text": "any data in case of Po down or any",
    "start": "937800",
    "end": "941199"
  },
  {
    "text": "failure when",
    "start": "941199",
    "end": "943480"
  },
  {
    "text": "rebooting so this is the Shad",
    "start": "943480",
    "end": "947920"
  },
  {
    "text": "agregator anyway unfortunately we were",
    "start": "947920",
    "end": "951040"
  },
  {
    "text": "in the Legacy world we where we",
    "start": "951040",
    "end": "953880"
  },
  {
    "text": "provision the physical machines or",
    "start": "953880",
    "end": "956800"
  },
  {
    "text": "virtual machines to deploy our all",
    "start": "956800",
    "end": "959040"
  },
  {
    "text": "components so we didn't do we didn't use",
    "start": "959040",
    "end": "961920"
  },
  {
    "text": "kubernetes at all but we are really",
    "start": "961920",
    "end": "965279"
  },
  {
    "text": "motivated to migrate all components to",
    "start": "965279",
    "end": "967880"
  },
  {
    "text": "kubernetes there are several reasons um",
    "start": "967880",
    "end": "970759"
  },
  {
    "text": "you know infrastructure of rest",
    "start": "970759",
    "end": "972839"
  },
  {
    "text": "structions and self feeling and UniFi",
    "start": "972839",
    "end": "975120"
  },
  {
    "text": "observability and UniFi deployment for",
    "start": "975120",
    "end": "977680"
  },
  {
    "text": "there are a lot of advantages to use",
    "start": "977680",
    "end": "980360"
  },
  {
    "text": "kubernetes so as the starting point we",
    "start": "980360",
    "end": "984360"
  },
  {
    "text": "went with kuber netics for the new",
    "start": "984360",
    "end": "987360"
  },
  {
    "text": "components so the writing architecture",
    "start": "987360",
    "end": "990160"
  },
  {
    "text": "is going to be like",
    "start": "990160",
    "end": "991600"
  },
  {
    "text": "this now we have kues cluster and ngine",
    "start": "991600",
    "end": "995839"
  },
  {
    "text": "X as the LC Road balancer and also",
    "start": "995839",
    "end": "999759"
  },
  {
    "text": "Shadow agregator so let's look at how it",
    "start": "999759",
    "end": "1004720"
  },
  {
    "text": "works at first batch server need to",
    "start": "1004720",
    "end": "1008720"
  },
  {
    "text": "calculate each shirt so which shirt is",
    "start": "1008720",
    "end": "1012480"
  },
  {
    "text": "going",
    "start": "1012480",
    "end": "1013639"
  },
  {
    "text": "to uh be responsible for with given",
    "start": "1013639",
    "end": "1018040"
  },
  {
    "text": "request right so in that after that b",
    "start": "1018040",
    "end": "1023160"
  },
  {
    "text": "server put the sh factor in glbc header",
    "start": "1023160",
    "end": "1027160"
  },
  {
    "text": "and send the data into engine X and",
    "start": "1027160",
    "end": "1030400"
  },
  {
    "text": "engine X RS the data to corresponding",
    "start": "1030400",
    "end": "1033760"
  },
  {
    "text": "part um using the grbg header calculated",
    "start": "1033760",
    "end": "1037600"
  },
  {
    "text": "by bat",
    "start": "1037600",
    "end": "1039880"
  },
  {
    "text": "server and after that shadow getor",
    "start": "1039880",
    "end": "1043199"
  },
  {
    "text": "persist the data in local DV uh which is",
    "start": "1043199",
    "end": "1046678"
  },
  {
    "text": "lsm3 based database and level DB we",
    "start": "1046679",
    "end": "1051080"
  },
  {
    "text": "use and after once each sh aggregator",
    "start": "1051080",
    "end": "1055919"
  },
  {
    "text": "Aggregates all shares of data that is",
    "start": "1055919",
    "end": "1059039"
  },
  {
    "text": "responsible for it tries to save the",
    "start": "1059039",
    "end": "1061520"
  },
  {
    "text": "data into object storage so this is how",
    "start": "1061520",
    "end": "1064440"
  },
  {
    "text": "it",
    "start": "1064440",
    "end": "1066600"
  },
  {
    "text": "works but choosing right key value store",
    "start": "1067000",
    "end": "1070679"
  },
  {
    "text": "right database is a really important",
    "start": "1070679",
    "end": "1072919"
  },
  {
    "text": "thing right and Shadow agregator is",
    "start": "1072919",
    "end": "1076240"
  },
  {
    "text": "obviously right intensive workload",
    "start": "1076240",
    "end": "1078679"
  },
  {
    "text": "because those reading",
    "start": "1078679",
    "end": "1081280"
  },
  {
    "text": "only um reading is happening only once",
    "start": "1081280",
    "end": "1085480"
  },
  {
    "text": "this is when I bring the data inj",
    "start": "1085480",
    "end": "1088320"
  },
  {
    "text": "storage right so that's why we chose LSM",
    "start": "1088320",
    "end": "1093159"
  },
  {
    "text": "Tre based database um uh specifically",
    "start": "1093159",
    "end": "1097039"
  },
  {
    "text": "level DV of course you can use Ro DV",
    "start": "1097039",
    "end": "1101080"
  },
  {
    "text": "but the reason is because this is really",
    "start": "1101080",
    "end": "1103760"
  },
  {
    "text": "optimized on right performance so that's",
    "start": "1103760",
    "end": "1107000"
  },
  {
    "text": "why we chose LSM based",
    "start": "1107000",
    "end": "1110039"
  },
  {
    "text": "database and also we did some additional",
    "start": "1110039",
    "end": "1113200"
  },
  {
    "text": "optimization of Ls",
    "start": "1113200",
    "end": "1115400"
  },
  {
    "text": "3 so as I mentioned reading only happen",
    "start": "1115400",
    "end": "1119400"
  },
  {
    "text": "once this is when uploading the data",
    "start": "1119400",
    "end": "1121799"
  },
  {
    "text": "into object storage so we disabled",
    "start": "1121799",
    "end": "1125159"
  },
  {
    "text": "compaction and page gache because these",
    "start": "1125159",
    "end": "1129039"
  },
  {
    "text": "two things are aing for um makees the",
    "start": "1129039",
    "end": "1132880"
  },
  {
    "text": "reading better right but this is not",
    "start": "1132880",
    "end": "1137159"
  },
  {
    "text": "necessary for our Ed cases because",
    "start": "1137159",
    "end": "1139840"
  },
  {
    "text": "reading only happens",
    "start": "1139840",
    "end": "1141880"
  },
  {
    "text": "once so by use by dising these two",
    "start": "1141880",
    "end": "1145200"
  },
  {
    "text": "factors we can get less memory",
    "start": "1145200",
    "end": "1148000"
  },
  {
    "text": "conception and better right",
    "start": "1148000",
    "end": "1150799"
  },
  {
    "text": "performance so as and also additionally",
    "start": "1150799",
    "end": "1154559"
  },
  {
    "text": "we did",
    "start": "1154559",
    "end": "1156240"
  },
  {
    "text": "um merging of multiple fing codes into a",
    "start": "1156240",
    "end": "1160440"
  },
  {
    "text": "single one given the nature of",
    "start": "1160440",
    "end": "1163760"
  },
  {
    "text": "kubernetes and container World a not has",
    "start": "1163760",
    "end": "1167000"
  },
  {
    "text": "several parts and",
    "start": "1167000",
    "end": "1169360"
  },
  {
    "text": "all parts in the node shares the same",
    "start": "1169360",
    "end": "1172799"
  },
  {
    "text": "con con space this means even though a",
    "start": "1172799",
    "end": "1176679"
  },
  {
    "text": "part is down that rep page cash Still",
    "start": "1176679",
    "end": "1179520"
  },
  {
    "text": "Remains so in case of part failure a",
    "start": "1179520",
    "end": "1183360"
  },
  {
    "text": "part uh still can recover on this tap",
    "start": "1183360",
    "end": "1186360"
  },
  {
    "text": "from this di cache and I think",
    "start": "1186360",
    "end": "1191400"
  },
  {
    "text": "later so by doing this we can get better",
    "start": "1191400",
    "end": "1197120"
  },
  {
    "text": "performance right so as a",
    "start": "1197120",
    "end": "1200120"
  },
  {
    "text": "result uh with 32 Shand Parts um it",
    "start": "1200120",
    "end": "1204840"
  },
  {
    "text": "takes 40 minutes to Aggregate and",
    "start": "1204840",
    "end": "1208159"
  },
  {
    "text": "complete uh batch writing 450 gigabyte",
    "start": "1208159",
    "end": "1212640"
  },
  {
    "text": "every 4 hours and also each Port",
    "start": "1212640",
    "end": "1216000"
  },
  {
    "text": "consumes only 3 gigabyte as the memory",
    "start": "1216000",
    "end": "1220799"
  },
  {
    "text": "usage and also no outage can be seen",
    "start": "1220799",
    "end": "1224600"
  },
  {
    "text": "sofware since we last um deploy this",
    "start": "1224600",
    "end": "1227840"
  },
  {
    "text": "component last year so this is a result",
    "start": "1227840",
    "end": "1231039"
  },
  {
    "text": "of right uh right",
    "start": "1231039",
    "end": "1233799"
  },
  {
    "text": "performance all right let's move to",
    "start": "1233799",
    "end": "1238880"
  },
  {
    "text": "reading so now we have query API and",
    "start": "1238880",
    "end": "1243799"
  },
  {
    "text": "object storage so how do you retrieve",
    "start": "1243799",
    "end": "1247080"
  },
  {
    "text": "the samples from object",
    "start": "1247080",
    "end": "1249559"
  },
  {
    "text": "storage this is the space where the new",
    "start": "1249559",
    "end": "1252440"
  },
  {
    "text": "component storage getaway comes",
    "start": "1252440",
    "end": "1255720"
  },
  {
    "text": "in what storage getaway storage Gateway",
    "start": "1255720",
    "end": "1259640"
  },
  {
    "text": "basically communicates directly with",
    "start": "1259640",
    "end": "1261720"
  },
  {
    "text": "object storage to retrieve the samples",
    "start": "1261720",
    "end": "1264320"
  },
  {
    "text": "from object storage right and also it",
    "start": "1264320",
    "end": "1267840"
  },
  {
    "text": "behaves as cach as well this is for",
    "start": "1267840",
    "end": "1271720"
  },
  {
    "text": "reducing RPS for object storage and also",
    "start": "1271720",
    "end": "1275640"
  },
  {
    "text": "return returning the results as possible",
    "start": "1275640",
    "end": "1278720"
  },
  {
    "text": "uh faster as",
    "start": "1278720",
    "end": "1281600"
  },
  {
    "text": "possible okay anyway let's look at the",
    "start": "1282720",
    "end": "1285400"
  },
  {
    "text": "throw",
    "start": "1285400",
    "end": "1287200"
  },
  {
    "text": "actually so query API tries to request",
    "start": "1287200",
    "end": "1291080"
  },
  {
    "text": "for samples by calling storage gatway",
    "start": "1291080",
    "end": "1295080"
  },
  {
    "text": "gpod and St getaway tries to download",
    "start": "1295080",
    "end": "1298640"
  },
  {
    "text": "Index this is a mapping table between",
    "start": "1298640",
    "end": "1301840"
  },
  {
    "text": "Target metrix idas and actual bi",
    "start": "1301840",
    "end": "1304880"
  },
  {
    "text": "location in the sample files and then",
    "start": "1304880",
    "end": "1308279"
  },
  {
    "text": "this identified by offset in the sample",
    "start": "1308279",
    "end": "1311760"
  },
  {
    "text": "files then it tries to partially",
    "start": "1311760",
    "end": "1315240"
  },
  {
    "text": "download actual samples with by range",
    "start": "1315240",
    "end": "1319080"
  },
  {
    "text": "request from object",
    "start": "1319080",
    "end": "1320880"
  },
  {
    "text": "storage then it Returns the samples to",
    "start": "1320880",
    "end": "1324400"
  },
  {
    "text": "qu API so this is how it",
    "start": "1324400",
    "end": "1328279"
  },
  {
    "text": "works but what about",
    "start": "1328279",
    "end": "1331600"
  },
  {
    "text": "cache again choosing correct correct key",
    "start": "1331600",
    "end": "1335039"
  },
  {
    "text": "value store is a really important",
    "start": "1335039",
    "end": "1337520"
  },
  {
    "text": "thing so storage getaway is a obviously",
    "start": "1337520",
    "end": "1342600"
  },
  {
    "text": "reading intensely workload right so in",
    "start": "1342600",
    "end": "1346600"
  },
  {
    "text": "most of time reading is happen Happ in",
    "start": "1346600",
    "end": "1349000"
  },
  {
    "text": "query time so that's why we chose B+ 3",
    "start": "1349000",
    "end": "1352799"
  },
  {
    "text": "base database and that is LCD I bat and",
    "start": "1352799",
    "end": "1357960"
  },
  {
    "text": "that is used in LCD in kubernetes as",
    "start": "1357960",
    "end": "1361600"
  },
  {
    "text": "well so we chose this one H stage",
    "start": "1361600",
    "end": "1365799"
  },
  {
    "text": "gateaway as",
    "start": "1365799",
    "end": "1368159"
  },
  {
    "text": "well so on top of the BBT and invo we",
    "start": "1368159",
    "end": "1372880"
  },
  {
    "text": "build Distributing",
    "start": "1372880",
    "end": "1375039"
  },
  {
    "text": "cash so as I mention bbo is a really",
    "start": "1375039",
    "end": "1378919"
  },
  {
    "text": "performing well on reading intensity",
    "start": "1378919",
    "end": "1381760"
  },
  {
    "text": "work Road and also with the nature of",
    "start": "1381760",
    "end": "1384760"
  },
  {
    "text": "time three data exact same querious is",
    "start": "1384760",
    "end": "1389039"
  },
  {
    "text": "coming in so in this case page cach is",
    "start": "1389039",
    "end": "1392400"
  },
  {
    "text": "really working well this is like memory",
    "start": "1392400",
    "end": "1397240"
  },
  {
    "text": "cache and also uh we choose Envoy",
    "start": "1397240",
    "end": "1401200"
  },
  {
    "text": "instead of engine",
    "start": "1401200",
    "end": "1403039"
  },
  {
    "text": "X because this natively supports active",
    "start": "1403039",
    "end": "1407640"
  },
  {
    "text": "Heth check and also magnet consistent",
    "start": "1407640",
    "end": "1411000"
  },
  {
    "text": "hash basically we want L7 L to Route",
    "start": "1411000",
    "end": "1415279"
  },
  {
    "text": "same request to same Parts as possible",
    "start": "1415279",
    "end": "1419200"
  },
  {
    "text": "right and to achieve that we need",
    "start": "1419200",
    "end": "1422720"
  },
  {
    "text": "consistent hashing algorithm and also",
    "start": "1422720",
    "end": "1425840"
  },
  {
    "text": "magb is really optimized and even",
    "start": "1425840",
    "end": "1428919"
  },
  {
    "text": "distribution so that's why we choose",
    "start": "1428919",
    "end": "1433120"
  },
  {
    "text": "invoy okay so let's look at the",
    "start": "1433480",
    "end": "1435919"
  },
  {
    "text": "architecture",
    "start": "1435919",
    "end": "1438919"
  },
  {
    "text": "query API first three sprit the request",
    "start": "1439080",
    "end": "1442640"
  },
  {
    "text": "into some multiple Parts according to",
    "start": "1442640",
    "end": "1445240"
  },
  {
    "text": "shirt so a request means a Shar request",
    "start": "1445240",
    "end": "1450120"
  },
  {
    "text": "right so query API calls grpo VI",
    "start": "1450120",
    "end": "1455240"
  },
  {
    "text": "invoy and this invoy routes a sh request",
    "start": "1455240",
    "end": "1459200"
  },
  {
    "text": "to a fix part by MRE consistent",
    "start": "1459200",
    "end": "1463200"
  },
  {
    "text": "hash and storage getaway tries to",
    "start": "1463200",
    "end": "1466360"
  },
  {
    "text": "download index and Sample as I mentioned",
    "start": "1466360",
    "end": "1470799"
  },
  {
    "text": "and then it save the data in local cache",
    "start": "1470799",
    "end": "1474720"
  },
  {
    "text": "which is",
    "start": "1474720",
    "end": "1476960"
  },
  {
    "text": "Bolt then it return the results via invo",
    "start": "1476960",
    "end": "1482039"
  },
  {
    "text": "and query API merge all",
    "start": "1482039",
    "end": "1485000"
  },
  {
    "text": "results so that it can return the result",
    "start": "1485000",
    "end": "1488760"
  },
  {
    "text": "you users actually so this is how it",
    "start": "1488760",
    "end": "1492279"
  },
  {
    "text": "works but this is still",
    "start": "1492279",
    "end": "1495640"
  },
  {
    "text": "slow why",
    "start": "1495640",
    "end": "1498520"
  },
  {
    "text": "so this is when we should pinpoint",
    "start": "1498520",
    "end": "1501840"
  },
  {
    "text": "bottleneck in query path by using",
    "start": "1501840",
    "end": "1504720"
  },
  {
    "text": "observability tools like pyroscope or",
    "start": "1504720",
    "end": "1507440"
  },
  {
    "text": "graph Temple uh we already use pyroscope",
    "start": "1507440",
    "end": "1511120"
  },
  {
    "text": "for continuous profiling and graph",
    "start": "1511120",
    "end": "1513919"
  },
  {
    "text": "Temple for distributed",
    "start": "1513919",
    "end": "1515799"
  },
  {
    "text": "tracing and with",
    "start": "1515799",
    "end": "1518399"
  },
  {
    "text": "this we realize that downloading index",
    "start": "1518399",
    "end": "1522840"
  },
  {
    "text": "or decoding index is a really consuming",
    "start": "1522840",
    "end": "1525559"
  },
  {
    "text": "task in terms of CPU usage",
    "start": "1525559",
    "end": "1530320"
  },
  {
    "text": "because index is a really",
    "start": "1531159",
    "end": "1534039"
  },
  {
    "text": "huge",
    "start": "1534039",
    "end": "1535919"
  },
  {
    "text": "for really huge to be decoded or",
    "start": "1535919",
    "end": "1539000"
  },
  {
    "text": "downloaded every time whenever it",
    "start": "1539000",
    "end": "1541600"
  },
  {
    "text": "requests come in so that's why we reduce",
    "start": "1541600",
    "end": "1545520"
  },
  {
    "text": "the area of downloading area and",
    "start": "1545520",
    "end": "1548000"
  },
  {
    "text": "decoding",
    "start": "1548000",
    "end": "1549399"
  },
  {
    "text": "area so we introduce index of",
    "start": "1549399",
    "end": "1553760"
  },
  {
    "text": "index I'm not sure what I'm saying but",
    "start": "1553760",
    "end": "1557159"
  },
  {
    "text": "index of index is is like mapping table",
    "start": "1557159",
    "end": "1561200"
  },
  {
    "text": "between Matrix IDs and by offset this is",
    "start": "1561200",
    "end": "1565600"
  },
  {
    "text": "similar to index and Sample file right",
    "start": "1565600",
    "end": "1570279"
  },
  {
    "text": "so instead of download or decord entire",
    "start": "1570279",
    "end": "1573880"
  },
  {
    "text": "index file you can use this mapping",
    "start": "1573880",
    "end": "1576679"
  },
  {
    "text": "table and identify the by offset of",
    "start": "1576679",
    "end": "1579720"
  },
  {
    "text": "paral data of index so that you can",
    "start": "1579720",
    "end": "1583000"
  },
  {
    "text": "partially download the data and",
    "start": "1583000",
    "end": "1584919"
  },
  {
    "text": "partially decode the data so",
    "start": "1584919",
    "end": "1588919"
  },
  {
    "text": "the Del region of index file is really",
    "start": "1588919",
    "end": "1592080"
  },
  {
    "text": "significantly",
    "start": "1592080",
    "end": "1593520"
  },
  {
    "text": "reduced so you can see tons of CPU time",
    "start": "1593520",
    "end": "1598720"
  },
  {
    "text": "so this improves",
    "start": "1598720",
    "end": "1600919"
  },
  {
    "text": "really uh working well to reduce the",
    "start": "1600919",
    "end": "1606720"
  },
  {
    "text": "query so as a result rate performance is",
    "start": "1606720",
    "end": "1610679"
  },
  {
    "text": "really well comparable to Cassandra so",
    "start": "1610679",
    "end": "1614080"
  },
  {
    "text": "even though we retrieve one mass of data",
    "start": "1614080",
    "end": "1619120"
  },
  {
    "text": "uh only N9 second takes a p990",
    "start": "1619120",
    "end": "1625320"
  },
  {
    "text": "ly so this is a really U performing",
    "start": "1625320",
    "end": "1630679"
  },
  {
    "text": "well last three let me explain the",
    "start": "1630760",
    "end": "1634640"
  },
  {
    "text": "additional feature on top of the object",
    "start": "1634640",
    "end": "1636760"
  },
  {
    "text": "storage",
    "start": "1636760",
    "end": "1639039"
  },
  {
    "text": "database so we introduce and published",
    "start": "1639039",
    "end": "1643039"
  },
  {
    "text": "bring your own backet feature that",
    "start": "1643039",
    "end": "1645960"
  },
  {
    "text": "allows users to use their own object",
    "start": "1645960",
    "end": "1648559"
  },
  {
    "text": "storage and",
    "start": "1648559",
    "end": "1650039"
  },
  {
    "text": "backets this means we don't have to pay",
    "start": "1650039",
    "end": "1653039"
  },
  {
    "text": "for additional cost to expand where",
    "start": "1653039",
    "end": "1656240"
  },
  {
    "text": "storage capacity instead just users can",
    "start": "1656240",
    "end": "1660360"
  },
  {
    "text": "bring their own",
    "start": "1660360",
    "end": "1662200"
  },
  {
    "text": "storage so this new feature actually",
    "start": "1662200",
    "end": "1665279"
  },
  {
    "text": "remove our storage capacity limitation",
    "start": "1665279",
    "end": "1668600"
  },
  {
    "text": "so we can infinitely scale out our",
    "start": "1668600",
    "end": "1670840"
  },
  {
    "text": "storage",
    "start": "1670840",
    "end": "1672120"
  },
  {
    "text": "capacity so this is bring your own",
    "start": "1672120",
    "end": "1676120"
  },
  {
    "text": "buckets right and and last three PAB",
    "start": "1676120",
    "end": "1679519"
  },
  {
    "text": "scale of metric is not an issue anymore",
    "start": "1679519",
    "end": "1684399"
  },
  {
    "text": "on top of the distributed writing",
    "start": "1684399",
    "end": "1686840"
  },
  {
    "text": "disability reading and some",
    "start": "1686840",
    "end": "1689200"
  },
  {
    "text": "observability to improve",
    "start": "1689200",
    "end": "1692039"
  },
  {
    "text": "performance and level DB and engine X is",
    "start": "1692039",
    "end": "1696279"
  },
  {
    "text": "really uh good products for our",
    "start": "1696279",
    "end": "1699000"
  },
  {
    "text": "distributed writing so that we can get",
    "start": "1699000",
    "end": "1700919"
  },
  {
    "text": "scalability on writing and also B both",
    "start": "1700919",
    "end": "1703880"
  },
  {
    "text": "is invo is really performing well on",
    "start": "1703880",
    "end": "1706679"
  },
  {
    "text": "distributed reading and also",
    "start": "1706679",
    "end": "1709640"
  },
  {
    "text": "scalability",
    "start": "1709640",
    "end": "1711240"
  },
  {
    "text": "is uh we can get the scalability for",
    "start": "1711240",
    "end": "1715480"
  },
  {
    "text": "reading as",
    "start": "1715480",
    "end": "1716640"
  },
  {
    "text": "well so thank you for everyone and also",
    "start": "1716640",
    "end": "1720480"
  },
  {
    "text": "any everything in the",
    "start": "1720480",
    "end": "1723480"
  },
  {
    "text": "community I think",
    "start": "1723480",
    "end": "1725919"
  },
  {
    "text": "lastly I can",
    "start": "1725919",
    "end": "1727460"
  },
  {
    "text": "[Music]",
    "start": "1727460",
    "end": "1728559"
  },
  {
    "text": "say we are always seeking opportunities",
    "start": "1728559",
    "end": "1732480"
  },
  {
    "text": "to contribute our knowledge to",
    "start": "1732480",
    "end": "1735159"
  },
  {
    "text": "community",
    "start": "1735159",
    "end": "1737039"
  },
  {
    "text": "go is this project success for this",
    "start": "1737039",
    "end": "1740240"
  },
  {
    "text": "projects of success um this is a really",
    "start": "1740240",
    "end": "1743960"
  },
  {
    "text": "relizing heavily my experiment of",
    "start": "1743960",
    "end": "1747360"
  },
  {
    "text": "contributions to Loi graph Loi so by",
    "start": "1747360",
    "end": "1751840"
  },
  {
    "text": "leveling my experiment uh we attained",
    "start": "1751840",
    "end": "1755480"
  },
  {
    "text": "this kind of",
    "start": "1755480",
    "end": "1756919"
  },
  {
    "text": "architecture so that's why uh we really",
    "start": "1756919",
    "end": "1760840"
  },
  {
    "text": "want to um convey",
    "start": "1760840",
    "end": "1764880"
  },
  {
    "text": "and uh tear our knowledge to community",
    "start": "1764880",
    "end": "1768679"
  },
  {
    "text": "so that I hope the time three databas",
    "start": "1768679",
    "end": "1772399"
  },
  {
    "text": "and other Open Source Products for",
    "start": "1772399",
    "end": "1774720"
  },
  {
    "text": "observability get more",
    "start": "1774720",
    "end": "1777559"
  },
  {
    "text": "mature so we always seeking this",
    "start": "1777559",
    "end": "1780960"
  },
  {
    "text": "opportunities let's talk about and",
    "start": "1780960",
    "end": "1783440"
  },
  {
    "text": "discuss anyway thank you for everyone",
    "start": "1783440",
    "end": "1785799"
  },
  {
    "text": "and thank you for listening to my",
    "start": "1785799",
    "end": "1787159"
  },
  {
    "text": "session",
    "start": "1787159",
    "end": "1790020"
  },
  {
    "text": "[Applause]",
    "start": "1790020",
    "end": "1793470"
  }
]
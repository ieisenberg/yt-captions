[
  {
    "text": "okay let's go ahead and get started i'd like to thank everyone who's joining us today",
    "start": "2320",
    "end": "7600"
  },
  {
    "text": "uh today's webinar is fluent bit version 1.5 i'm julius rosenthal",
    "start": "7600",
    "end": "14320"
  },
  {
    "text": "i'll be moderating today's webinar we'd like to thank our presenters today eduardo silva principal engineer",
    "start": "14320",
    "end": "21840"
  },
  {
    "text": "at arm treasure data massoud colony staff research software engineer at arm",
    "start": "21840",
    "end": "27840"
  },
  {
    "text": "and wesley pettitt software developer engineer at aws a few housekeeping items before we get",
    "start": "27840",
    "end": "34880"
  },
  {
    "text": "started during the webinar you are not able to talk as an attendee there is a q a box at the bottom of your",
    "start": "34880",
    "end": "41600"
  },
  {
    "text": "screen please feel free to drop your questions in there and we'll get to as many as we can at the end of the",
    "start": "41600",
    "end": "47440"
  },
  {
    "text": "presentation this is an official webinar of the cncf and as such is subject to the cncf code",
    "start": "47440",
    "end": "54399"
  },
  {
    "text": "of conduct please do not add anything to the chat or questions that would be in violation of the code of conduct",
    "start": "54399",
    "end": "61039"
  },
  {
    "text": "basically please be respectful of all your fellow participants and presenters please note that the recording and",
    "start": "61039",
    "end": "67439"
  },
  {
    "text": "slides will be up later today on the cncf webinar page and with that we'll",
    "start": "67439",
    "end": "72799"
  },
  {
    "text": "hand it over to our presenters thank you well welcome everybody my name",
    "start": "72799",
    "end": "80240"
  },
  {
    "text": "is eduardo silva and one of the maintainers of the fluent project and today together with wesley and massoud",
    "start": "80240",
    "end": "87680"
  },
  {
    "text": "who are my interns from different subsystems of the project we will share some news about this new",
    "start": "87680",
    "end": "93119"
  },
  {
    "text": "release but also a for new corners for new people that is just learning about this",
    "start": "93119",
    "end": "100159"
  },
  {
    "text": "ecosystem of logging we will start with a little introduction",
    "start": "100159",
    "end": "105200"
  },
  {
    "text": "then we'll start with the news about fluid how our experience make creating a",
    "start": "105200",
    "end": "111600"
  },
  {
    "text": "original plugins it and go to c language and finally an introduction to",
    "start": "111600",
    "end": "117200"
  },
  {
    "text": "one of the stream processing capabilities so this webinar will be a little bit more than just the release but so we are going to",
    "start": "117200",
    "end": "124479"
  },
  {
    "text": "share more knowledge about different components so fluent bit in general aims to solve all the problem",
    "start": "124479",
    "end": "131440"
  },
  {
    "text": "that is generated when we want to achieve data analysis right if we want to achieve data",
    "start": "131440",
    "end": "137360"
  },
  {
    "text": "analysis we want to we have to collect all the data from hardware software and deliver these to a",
    "start": "137360",
    "end": "143599"
  },
  {
    "text": "central place and this gets more problems when data starts to scaling up because we get",
    "start": "143599",
    "end": "150239"
  },
  {
    "text": "performance penalties and the data challenges is that data comes from different formats",
    "start": "150239",
    "end": "156239"
  },
  {
    "text": "from different entries points like tcp udp file system or journal d so how do we accomplish this and if you",
    "start": "156239",
    "end": "164160"
  },
  {
    "text": "think about distributed environments such as kubernetes you can think that every bot for example has one application more one",
    "start": "164160",
    "end": "171519"
  },
  {
    "text": "more container every single container is generating their own login information",
    "start": "171519",
    "end": "176720"
  },
  {
    "text": "so if you are on this cloud native area how do you solve this data analysis",
    "start": "176720",
    "end": "182080"
  },
  {
    "text": "concentrating all the information together which is a major challenge that we have",
    "start": "182080",
    "end": "188400"
  },
  {
    "text": "and addition besides centralization is about to deal with different data formats as you can see for example",
    "start": "188400",
    "end": "195599"
  },
  {
    "text": "apache logs comes with a unstructured format same thing for my sql and json maps and",
    "start": "195599",
    "end": "201440"
  },
  {
    "text": "so on so one of the goals also offers a lot processor tool like fluent bet or",
    "start": "201440",
    "end": "206879"
  },
  {
    "text": "fluency is the ability to convert this into a structured way and have the notion of key and values",
    "start": "206879",
    "end": "213920"
  },
  {
    "text": "and in with an internal representation in binary format so before the data analysis we need to",
    "start": "213920",
    "end": "220080"
  },
  {
    "text": "collect this data from different source and convert this data and also there's many cases where we want to",
    "start": "220080",
    "end": "226000"
  },
  {
    "text": "enrich data we can say hey this data is coming from a different node a specific port or this specific instance",
    "start": "226000",
    "end": "233200"
  },
  {
    "text": "so besides just to have the message that is involved we also want to add",
    "start": "233200",
    "end": "238640"
  },
  {
    "text": "some context to it to say hey this is coming from this host this ip address and so on and this is when it comes flowing",
    "start": "238640",
    "end": "246560"
  },
  {
    "text": "bit which is a tool that aims to solve all these data collection problems and data",
    "start": "246560",
    "end": "251840"
  },
  {
    "text": "processing problems i have to say that fluid it's a cncf sub project under the",
    "start": "251840",
    "end": "258720"
  },
  {
    "text": "umbrella of fluency one of the graduated projects of the cncf and fluent beta started in",
    "start": "258720",
    "end": "265720"
  },
  {
    "text": "2015 it origins was at the beginning was created for lightweight",
    "start": "265720",
    "end": "270960"
  },
  {
    "text": "environments for embedded linux and quickly evolved for the cloud native space",
    "start": "270960",
    "end": "276160"
  },
  {
    "text": "so and with this we always think that we need to have something that was very lightweight and really fast",
    "start": "276160",
    "end": "283520"
  },
  {
    "text": "and very efficient from a memory and cpu perspective that's why it was written in ceiling",
    "start": "283520",
    "end": "289440"
  },
  {
    "text": "which is very optimized if you are doing nothing with fluid beds like a needle instance",
    "start": "289440",
    "end": "295280"
  },
  {
    "text": "it barely will use 600 kilobytes and with blockable architecture we provide",
    "start": "295280",
    "end": "301360"
  },
  {
    "text": "more than 60 plugins to deal with different source of data data formats",
    "start": "301360",
    "end": "306720"
  },
  {
    "text": "and also to with ability to ship this data out to different destinations and of course",
    "start": "306720",
    "end": "312720"
  },
  {
    "text": "we provide built in security tls and networking io",
    "start": "312720",
    "end": "318720"
  },
  {
    "text": "fluent it can conceive be considered like a data pipeline when in one entry point on the left we",
    "start": "318800",
    "end": "324880"
  },
  {
    "text": "have all the inputs of data we have all the person filtering buffering capabilities",
    "start": "324880",
    "end": "331199"
  },
  {
    "text": "and finally the final step which is the ability to route this data to different",
    "start": "331199",
    "end": "336840"
  },
  {
    "text": "destinations with destination it can be a database a cloud service or anything where you",
    "start": "336840",
    "end": "343520"
  },
  {
    "text": "aim to store your data together if we think about",
    "start": "343520",
    "end": "349360"
  },
  {
    "text": "kubernetes use case which is a most complex scenario for example you can think that",
    "start": "349360",
    "end": "355440"
  },
  {
    "text": "in your node you have bots and the pods are writing all the login information to add to the file system",
    "start": "355440",
    "end": "362479"
  },
  {
    "text": "so how do you solve this with fluid basically you deploy one of the use cases is that you can deploy fluid bit",
    "start": "362479",
    "end": "369440"
  },
  {
    "text": "as a demon set for this kind of a generic scenario where a demon set is just a pot",
    "start": "369440",
    "end": "375280"
  },
  {
    "text": "that runs on every node it's able to read all your logs from audio containers then",
    "start": "375280",
    "end": "381759"
  },
  {
    "text": "talk to the api server to retrieve all the metadata that is associated with that pod to",
    "start": "381759",
    "end": "388560"
  },
  {
    "text": "finally be able to send the data out to a central place like your database or cloud service",
    "start": "388560",
    "end": "396560"
  },
  {
    "text": "and this is one of the deployments model that we have for fluent bed but also you can use it as a side card",
    "start": "396560",
    "end": "402880"
  },
  {
    "text": "which is a very common use case used by many many customers and companies",
    "start": "402880",
    "end": "409840"
  },
  {
    "text": "so here's where we talk about now about the journey of fluent bet you know flow",
    "start": "409919",
    "end": "415039"
  },
  {
    "text": "bit was started about five years ago and we're reaching our version 1.5 and there's a couple of improvements",
    "start": "415039",
    "end": "423360"
  },
  {
    "text": "on how do we deal with networking sessions a when you deploy a tool that leads",
    "start": "423360",
    "end": "430960"
  },
  {
    "text": "and talk to different network services we face many issues you can have network",
    "start": "430960",
    "end": "436960"
  },
  {
    "text": "outage and responsive services and what the only thing that we can do from a client perspective",
    "start": "436960",
    "end": "443280"
  },
  {
    "text": "is to be able to provide setup to define specific behaviors to work",
    "start": "443280",
    "end": "449360"
  },
  {
    "text": "around or perform certain actions with that happens so on this version we are introducing",
    "start": "449360",
    "end": "455520"
  },
  {
    "text": "everything about connect timeouts meaning i'm trying to connect to this endpoint but that input is unresponsive how much time",
    "start": "455520",
    "end": "462800"
  },
  {
    "text": "should we wait and the ability to define a custom source address or for big servers that has a a ton",
    "start": "462800",
    "end": "471039"
  },
  {
    "text": "of network cards say hey please connect using this specific network interface and also",
    "start": "471039",
    "end": "477440"
  },
  {
    "text": "the ability to you reuse the tcp connections and tls session which is mostly called",
    "start": "477440",
    "end": "482800"
  },
  {
    "text": "keep a light and this is keep alive me it's about the concept of keep the socket",
    "start": "482800",
    "end": "488160"
  },
  {
    "text": "connection open after one successful delivery of data has been done and also",
    "start": "488160",
    "end": "496240"
  },
  {
    "text": "we support the keep alive idle timeouts",
    "start": "496240",
    "end": "500639"
  },
  {
    "text": "one of the the features that people was very interesting in and also surprisingly",
    "start": "501520",
    "end": "508319"
  },
  {
    "text": "for us for the maintainer has been that people's asking a lot of support for windows environments",
    "start": "508319",
    "end": "513518"
  },
  {
    "text": "well fluent since last month we have integrated a windows support at different phases",
    "start": "513519",
    "end": "520320"
  },
  {
    "text": "and on this version right now we provide a full windows service support so you can manage",
    "start": "520320",
    "end": "525600"
  },
  {
    "text": "flumebeat as a windows service now the plugin that is able to collect",
    "start": "525600",
    "end": "531360"
  },
  {
    "text": "windows event logs which is like the mechanism for the windows engine now we are able to fully encode all",
    "start": "531360",
    "end": "538320"
  },
  {
    "text": "these messages utf-8 and also a we have full support for kubernetes on windows i know that",
    "start": "538320",
    "end": "545600"
  },
  {
    "text": "for many people this is a surprise and for us it is too but yeah you can just flip it on windows",
    "start": "545600",
    "end": "551920"
  },
  {
    "text": "and also manage all your windows spot login data with phone bit without any",
    "start": "551920",
    "end": "558720"
  },
  {
    "text": "problem also the community has contributed many",
    "start": "558720",
    "end": "563920"
  },
  {
    "text": "ways on how to improve the experience from a professional perspective with wounded so right now with the repository and",
    "start": "563920",
    "end": "570880"
  },
  {
    "text": "documentation we are shipping out some grafana dashboards that can be really useful for you to just connect",
    "start": "570880",
    "end": "578000"
  },
  {
    "text": "the dots between all your login pipeline monitor where how the data is flowing",
    "start": "578000",
    "end": "583040"
  },
  {
    "text": "data rates which is a really important information",
    "start": "583040",
    "end": "588640"
  },
  {
    "text": "in addition the storage metrics and the whole matrix has been extended we used to have metrics",
    "start": "588640",
    "end": "594959"
  },
  {
    "text": "for the pipeline like a how much data is being generated by this input plugin how many bytes",
    "start": "594959",
    "end": "601279"
  },
  {
    "text": "how many retries we are facing the output side but we got many use cases that say hey",
    "start": "601279",
    "end": "606880"
  },
  {
    "text": "we want to know how is internal buffering mechanism how is the data flowing",
    "start": "606880",
    "end": "612560"
  },
  {
    "text": "i need to shoot down through a bit but i need to know if there's any data in the queue being processed okay so this is where",
    "start": "612560",
    "end": "619920"
  },
  {
    "text": "introduced the the new storage metrics endpoint which basically just pushed out a json",
    "start": "619920",
    "end": "627120"
  },
  {
    "text": "adjacent map which have different information like a house storage layer if it buffers",
    "start": "627120",
    "end": "633440"
  },
  {
    "text": "in memory how many the buffers in the file system if the batteries in the file system are also up",
    "start": "633440",
    "end": "639760"
  },
  {
    "text": "in memory and from the input side we can know if any plugin is ingesting too much data",
    "start": "639760",
    "end": "646160"
  },
  {
    "text": "is overlimited or we can get more granular information about this",
    "start": "646160",
    "end": "651360"
  },
  {
    "text": "and i think that this is a huge improvement from an operational perspective",
    "start": "651360",
    "end": "658720"
  },
  {
    "text": "another big news on this is the ability of new england price connectors",
    "start": "659680",
    "end": "665120"
  },
  {
    "text": "and i want to say reinforce that enterprise connector aims to say connectors that are contributed by or",
    "start": "665120",
    "end": "672800"
  },
  {
    "text": "that we work it join with them and to create for a specific services",
    "start": "672800",
    "end": "678320"
  },
  {
    "text": "and for these companies but also for the own customers so on this new version we're officially",
    "start": "678320",
    "end": "684320"
  },
  {
    "text": "launching a amazon also the support for the amazon elastic search service",
    "start": "684320",
    "end": "690320"
  },
  {
    "text": "so for the elastic search database hosted by amazon we have full support with that a website",
    "start": "690320",
    "end": "696240"
  },
  {
    "text": "will talk more about it same as for the amazon cloud watch service and now we also have two new connectors",
    "start": "696240",
    "end": "703200"
  },
  {
    "text": "for uh the log the login services provided by look dna and eurek and actually we are",
    "start": "703200",
    "end": "709680"
  },
  {
    "text": "very pleasant to have been working with amazon and logged in a new rayleigh google sumo logic and",
    "start": "709680",
    "end": "716079"
  },
  {
    "text": "other companies on this period google has working really hard has been",
    "start": "716079",
    "end": "722639"
  },
  {
    "text": "working really hard also on improving our own google stack driver connector",
    "start": "722639",
    "end": "727920"
  },
  {
    "text": "so we built an initial stackdriver connector that has been used by the many customers",
    "start": "727920",
    "end": "734399"
  },
  {
    "text": "but also google started contributing back a few months ago so now the stackdriver",
    "start": "734399",
    "end": "740320"
  },
  {
    "text": "connector is trying to have the same parity of futures than the fluidity connector for",
    "start": "740320",
    "end": "745440"
  },
  {
    "text": "stackdriver so this is really good news for everybody who relies on google cloud",
    "start": "745440",
    "end": "750880"
  },
  {
    "text": "services and some project status as you can see",
    "start": "750880",
    "end": "757200"
  },
  {
    "text": "the adoption of fluid we have just a fraction of visibility about who's using it or",
    "start": "757200",
    "end": "763440"
  },
  {
    "text": "the number of deployments but at least from the public perspective from our docker hub repository",
    "start": "763440",
    "end": "769519"
  },
  {
    "text": "just on the half of this year we're reaching more than a hundred million deployments",
    "start": "769519",
    "end": "775279"
  },
  {
    "text": "so barely every day we have more than 500 000 and the stats keeps continue growing",
    "start": "775279",
    "end": "781519"
  },
  {
    "text": "that means that fruit is employed every day that amount of time but also the same",
    "start": "781519",
    "end": "787040"
  },
  {
    "text": "note that was was created was destroyed maybe that note was created again it's deploying fluent bit again so i",
    "start": "787040",
    "end": "794639"
  },
  {
    "text": "always said that this is like a cumulative a stats and not unique stats",
    "start": "794639",
    "end": "800240"
  },
  {
    "text": "but in general we can see the trend that adoption of the project is growing a lot and in the enterprise",
    "start": "800240",
    "end": "808480"
  },
  {
    "text": "and we can say that most of the biggest companies are using fluent right now i think that as a team",
    "start": "808480",
    "end": "814800"
  },
  {
    "text": "we are pretty of it so like logistic companies like for for example a leaf transit and we have",
    "start": "814800",
    "end": "822800"
  },
  {
    "text": "the club providers like aws google cloud binds like cloud we have walmart using fluid bed now the",
    "start": "822800",
    "end": "828800"
  },
  {
    "text": "really giant swan whom you so for us having all these companies a adopting",
    "start": "828800",
    "end": "834800"
  },
  {
    "text": "technology is really important because also it means that the ecosystem of fluency is also growing",
    "start": "834800",
    "end": "841600"
  },
  {
    "text": "and passing apart to the fluid ecosystem so and working with companies for us is",
    "start": "841600",
    "end": "847440"
  },
  {
    "text": "a major priority because we know that the kind of use cases and challenges that they face",
    "start": "847440",
    "end": "854160"
  },
  {
    "text": "every month is kind of new in performance in deployment modes configuration and so on",
    "start": "854160",
    "end": "862480"
  },
  {
    "text": "so now i'm going to hang over the presentation to wesley who will talk about the aws",
    "start": "862480",
    "end": "868320"
  },
  {
    "text": "plugins and how they were migrated to the fluent bit core",
    "start": "868320",
    "end": "874160"
  },
  {
    "text": "awesome all right let's do this hello",
    "start": "875040",
    "end": "880079"
  },
  {
    "text": "i'm wesley i am the aws maintainer of fluent bit",
    "start": "880079",
    "end": "887920"
  },
  {
    "text": "i joined the project this year so i'm fairly new but i've done a good amount of work and",
    "start": "888240",
    "end": "894320"
  },
  {
    "text": "i'm going to talk about that so last year um i launched aws for",
    "start": "894320",
    "end": "900639"
  },
  {
    "text": "fluent bit uh which had a set of uh plugins in golang",
    "start": "900639",
    "end": "905920"
  },
  {
    "text": "for amazon so there's amazon cloudwatch logs uh kinesis firehose and kinesis data streams",
    "start": "905920",
    "end": "913839"
  },
  {
    "text": "and those were launched in 2019. so the reason why we wrote the plugins in go one is because",
    "start": "913920",
    "end": "921279"
  },
  {
    "text": "go lang supported a very fast development it helped us launch an integration with flintbit very quickly",
    "start": "921279",
    "end": "927199"
  },
  {
    "text": "but also there was an address sdk in go so aws has its own authentication",
    "start": "927199",
    "end": "934240"
  },
  {
    "text": "mechanisms there it has a it's called sig v4 signing which is the auth algorithm that",
    "start": "934240",
    "end": "941040"
  },
  {
    "text": "adores uses for indoor services for our apis and then there are many sources for",
    "start": "941040",
    "end": "946560"
  },
  {
    "text": "credentials depending upon where you are running in aws and these these mechanisms are all",
    "start": "946560",
    "end": "954160"
  },
  {
    "text": "supported by the standard innovas sdks there was not an aws sdk in c that i",
    "start": "954160",
    "end": "959680"
  },
  {
    "text": "could use for fluid bit and so that's why i was unable to contribute to the core of fluent bit",
    "start": "959680",
    "end": "965600"
  },
  {
    "text": "however we've now i've now fixed that so i spent",
    "start": "965600",
    "end": "970639"
  },
  {
    "text": "i had a took a long vacation in the winter and i spent most of my vacation actually",
    "start": "970639",
    "end": "976079"
  },
  {
    "text": "uh building a custom sort of low-level aws sdk in fluent bit",
    "start": "976079",
    "end": "982639"
  },
  {
    "text": "that worked with its built-in http client and concurrency features um this was showing a screenshot from",
    "start": "982639",
    "end": "988320"
  },
  {
    "text": "part of the final pull request which ended up being over six thousand lines of code it was quite big",
    "start": "988320",
    "end": "993839"
  },
  {
    "text": "but i'm very proud that it's finally done uh and it's now launched in 1.5",
    "start": "993839",
    "end": "998959"
  },
  {
    "text": "so with this library uh we're able to make requests to aws inside the core fluent bit um so the",
    "start": "998959",
    "end": "1005759"
  },
  {
    "text": "first thing that we did with that is uh we enabled amazon elasticsearch",
    "start": "1005759",
    "end": "1011040"
  },
  {
    "text": "service support so there was already of course a fluid bit plug-in for",
    "start": "1011040",
    "end": "1016240"
  },
  {
    "text": "the elasticsearch project but it did not support the amazon hosted version of elasticsearch",
    "start": "1016240",
    "end": "1022480"
  },
  {
    "text": "because that version uses uh aws authentication so with these new",
    "start": "1022480",
    "end": "1027520"
  },
  {
    "text": "uh with this new library you can enable aws authentication so there are a couple new fields so one key thing to",
    "start": "1027520",
    "end": "1034798"
  },
  {
    "text": "point out first of all the host when you use amazon elasticsearch you do not include the transport",
    "start": "1034799",
    "end": "1041038"
  },
  {
    "text": "protocol don't include the https that's one thing that got me confused when i first started",
    "start": "1041039",
    "end": "1046240"
  },
  {
    "text": "testing it out the port is almost always port 443 and then you have to add these fields it",
    "start": "1046240",
    "end": "1052559"
  },
  {
    "text": "was off turn that on and then you have to add your idios region you also want to enable tls of course",
    "start": "1052559",
    "end": "1059919"
  },
  {
    "text": "then you optionally also have this parameter called abus rollarn which lets you specify an iterous i am",
    "start": "1060559",
    "end": "1067840"
  },
  {
    "text": "role that can be assumed to make calls to",
    "start": "1067840",
    "end": "1072960"
  },
  {
    "text": "elasticsearch so that will use sts assume role if you're familiar with aws that should all make sense if not we",
    "start": "1072960",
    "end": "1079039"
  },
  {
    "text": "have some documentation on this that you can go read afterwards to understand",
    "start": "1079039",
    "end": "1084080"
  },
  {
    "text": "then also so as i said you know last year we launched a cloudwatch log support",
    "start": "1084080",
    "end": "1089440"
  },
  {
    "text": "influentbit um through an external golang plug-in this year",
    "start": "1089440",
    "end": "1096160"
  },
  {
    "text": "with 1.5 this is what i mentioned i added a natively influent bit in c cloudwatch",
    "start": "1096160",
    "end": "1102240"
  },
  {
    "text": "log support so the plug-in name is cloudwatch underscore logs the old plugin was just",
    "start": "1102240",
    "end": "1107280"
  },
  {
    "text": "called cloudwatch but besides the nature change in the name of the plugin it supports all of",
    "start": "1107280",
    "end": "1113360"
  },
  {
    "text": "the same parameters and it works exactly the same way so try that out it's very easy to",
    "start": "1113360",
    "end": "1119679"
  },
  {
    "text": "migrate so what i'm quite excited about is the",
    "start": "1119679",
    "end": "1124799"
  },
  {
    "text": "performance improvement um that we've seen from switching to go to see so here's",
    "start": "1124799",
    "end": "1130480"
  },
  {
    "text": "some benchmarks that i ran this is tailing log files and then sending them to cloudwatch",
    "start": "1130480",
    "end": "1136960"
  },
  {
    "text": "the cpu usage is a little is a is a good bit less for the new core plug-in in c",
    "start": "1136960",
    "end": "1144320"
  },
  {
    "text": "um but also i think more importantly um the max throughput that the",
    "start": "1144320",
    "end": "1151039"
  },
  {
    "text": "core plug-in can achieve is significantly higher this is something that i'm still working on quantifying",
    "start": "1151039",
    "end": "1157280"
  },
  {
    "text": "um i don't actually have hard numbers on it yet i just have like anecdotal evidence that it's definitely a lot higher",
    "start": "1157280",
    "end": "1162880"
  },
  {
    "text": "um eduardo and i are speaking again at the virtual kubecon which is",
    "start": "1162880",
    "end": "1168080"
  },
  {
    "text": "happening in august and hopefully by then if i have time i will find a way to actually uh measure",
    "start": "1168080",
    "end": "1175200"
  },
  {
    "text": "measure and quantify the per the performance and throughput difference between the two plugins",
    "start": "1175200",
    "end": "1180480"
  },
  {
    "text": "um the existing golang plugin had sufficient performance for essentially all",
    "start": "1180480",
    "end": "1185600"
  },
  {
    "text": "customers that we had but it's still nice to have higher performance for you know any",
    "start": "1185600",
    "end": "1190799"
  },
  {
    "text": "new higher performance use cases that might come up and this is showing the memory uses the",
    "start": "1190799",
    "end": "1196400"
  },
  {
    "text": "memory usage is really where you see a much larger difference because of course golang is a garbage",
    "start": "1196400",
    "end": "1201919"
  },
  {
    "text": "collected language the aws sdk for go also is not a particularly efficient library in",
    "start": "1201919",
    "end": "1209440"
  },
  {
    "text": "general so the difference you can see a three to four x difference in memory",
    "start": "1209440",
    "end": "1216320"
  },
  {
    "text": "usage between the old plugin and the new plugin where the the new plug-in will be",
    "start": "1216320",
    "end": "1221440"
  },
  {
    "text": "like 25 use 25 of the memory so you can see here in in this graph that even at 20",
    "start": "1221440",
    "end": "1227760"
  },
  {
    "text": "000 log lines per second that's tailing 10 log files each 2 000 block lines per",
    "start": "1227760",
    "end": "1232960"
  },
  {
    "text": "second we're only using uh about 40 megabytes of memory which is is really impressive",
    "start": "1232960",
    "end": "1238799"
  },
  {
    "text": "um for comparison um compared to so before i switched to",
    "start": "1238799",
    "end": "1245280"
  },
  {
    "text": "fluent bid i was working with fluentd fluent d compared to the fluid bit",
    "start": "1245280",
    "end": "1250960"
  },
  {
    "text": "golang plugins that was like about a 5 to 7 x performance improvement",
    "start": "1250960",
    "end": "1256159"
  },
  {
    "text": "so if you add an extra 3x performance improvement in memory with the c that's like a 20 to",
    "start": "1256159",
    "end": "1262559"
  },
  {
    "text": "30 times improvement over fluenty which is just really insane um so we're very proud of that",
    "start": "1262559",
    "end": "1270240"
  },
  {
    "text": "um so the long term plan is that i hope i'm going to work on hopefully writing",
    "start": "1270240",
    "end": "1275440"
  },
  {
    "text": "rewriting all of the original golang plugins in c and contribute them to the core flint bit",
    "start": "1275440",
    "end": "1282559"
  },
  {
    "text": "then we can deprecate the go plugins and the idea maybe what we can do is once we have the",
    "start": "1282559",
    "end": "1288240"
  },
  {
    "text": "c plugins at full parity with the go plugins we can remove the go plugins and alias",
    "start": "1288240",
    "end": "1294080"
  },
  {
    "text": "their names in fluent bit core so that basically you don't have to migrate your configuration it just",
    "start": "1294080",
    "end": "1299200"
  },
  {
    "text": "works with the c plugin starting in some release of fluent bit the timeline on that is very uncertain",
    "start": "1299200",
    "end": "1305120"
  },
  {
    "text": "and i should be very clear that this does not represent any sort of a hard commitment",
    "start": "1305120",
    "end": "1310559"
  },
  {
    "text": "from myself or from aws as to exactly what we will do but it's it's uh definitely something that i'm",
    "start": "1310559",
    "end": "1315919"
  },
  {
    "text": "thinking about so what am i working on now so right now i'm",
    "start": "1315919",
    "end": "1321360"
  },
  {
    "text": "actively working on supporting outputting logs to amazon s3 um there is a github",
    "start": "1321360",
    "end": "1327760"
  },
  {
    "text": "issue on the felipe core repo if you have thoughts or ideas on how that should work i've already posted",
    "start": "1327760",
    "end": "1333200"
  },
  {
    "text": "some information there on building a prototype and on how that",
    "start": "1333200",
    "end": "1338320"
  },
  {
    "text": "how the plugin will work and and the options that it might have",
    "start": "1338320",
    "end": "1343440"
  },
  {
    "text": "some ideas so so go check that out if you're interested in uh sending logs to s3",
    "start": "1343440",
    "end": "1349679"
  },
  {
    "text": "um so here's uh possibly what the config might look like",
    "start": "1349679",
    "end": "1355200"
  },
  {
    "text": "for s3 um what the plan is is to be able to do um",
    "start": "1355200",
    "end": "1360400"
  },
  {
    "text": "set a file size that you want an s3 so like you can decide you want a 250 megabyte files in s3",
    "start": "1360400",
    "end": "1368320"
  },
  {
    "text": "so it will upload to the file logs till it reaches that size and then truncate the file and move to a new file",
    "start": "1368320",
    "end": "1374960"
  },
  {
    "text": "the plan is also to support kind of like a timeout so you could say create a file in s3 once per hour",
    "start": "1374960",
    "end": "1382159"
  },
  {
    "text": "but part of the goal is that part of my idea is that i'm going to use",
    "start": "1382159",
    "end": "1387440"
  },
  {
    "text": "the multi-part upload api for s3 which enables you to",
    "start": "1387440",
    "end": "1392720"
  },
  {
    "text": "upload large files in small chunks that can be uploaded over time",
    "start": "1392720",
    "end": "1398960"
  },
  {
    "text": "so that should enable fluent bit to basically as it gets logs to upload them to s3 in",
    "start": "1398960",
    "end": "1405679"
  },
  {
    "text": "parts and then once it's uploading done uploading the right amount of logs it can",
    "start": "1405679",
    "end": "1411120"
  },
  {
    "text": "concatenate them together with the s3 api and create a file that way you'll get you know nice large",
    "start": "1411120",
    "end": "1416960"
  },
  {
    "text": "files in s3 created over time but fluid bit will not be buffering very much data locally which",
    "start": "1416960",
    "end": "1424159"
  },
  {
    "text": "means that you're not you're not at very much risk of losing data if fluid bit quits",
    "start": "1424159",
    "end": "1429520"
  },
  {
    "text": "or you know if your instance goes down that you're running fluent been on or anything like that because it's sending the data off to s3",
    "start": "1429520",
    "end": "1436240"
  },
  {
    "text": "basically as quickly as it gets it it's streaming it basically um that's the goal i haven't actually",
    "start": "1436240",
    "end": "1442159"
  },
  {
    "text": "gotten it working yet so we'll see but um probably i think by the time we do",
    "start": "1442159",
    "end": "1447679"
  },
  {
    "text": "the talk in kubecon next month i should hopefully have uh the plug-in mostly fully working by",
    "start": "1447679",
    "end": "1454000"
  },
  {
    "text": "then the goal is to launch it in september in fluent bit 1.6",
    "start": "1454000",
    "end": "1461919"
  },
  {
    "text": "um so finally [Music] if you're an aws user and you want to",
    "start": "1461919",
    "end": "1467919"
  },
  {
    "text": "get help with using fluent bit so here's here's your options so sometimes people find my email",
    "start": "1467919",
    "end": "1474880"
  },
  {
    "text": "and email me or message me on twitter to be honest that's not the best way uh to get in touch because i don't",
    "start": "1474880",
    "end": "1481120"
  },
  {
    "text": "necessarily reply to those very very quickly um you can open an issue or comment on an issue in a fluent bit core",
    "start": "1481120",
    "end": "1487679"
  },
  {
    "text": "repo and mention my github name which is petted wesley i watch that and i will respond um the",
    "start": "1487679",
    "end": "1495520"
  },
  {
    "text": "best way is actually though to go to the aws for fluent bit repo which is our distribution of fluid bit",
    "start": "1495520",
    "end": "1503440"
  },
  {
    "text": "the reason is because there are a couple other folks who have been training to understand fluent bit",
    "start": "1503600",
    "end": "1509440"
  },
  {
    "text": "and so we all watch that repo and answer questions there i prefer that",
    "start": "1509440",
    "end": "1515919"
  },
  {
    "text": "because it's nicer for me because i can kind of distribute the load of answering questions um to multiple people",
    "start": "1515919",
    "end": "1523360"
  },
  {
    "text": "lately we've definitely felt that it looks like fluent bit is really becoming popular because the number of",
    "start": "1523360",
    "end": "1529840"
  },
  {
    "text": "questions that we've been getting have increased significantly",
    "start": "1529840",
    "end": "1535679"
  },
  {
    "text": "finally if you're interested in becoming a fluent bid contributor yourself",
    "start": "1535679",
    "end": "1540960"
  },
  {
    "text": "i wrote a uh contributing sort of guide like uh not like as a",
    "start": "1540960",
    "end": "1546799"
  },
  {
    "text": "style guide but a guide of like if you're a beginner",
    "start": "1546799",
    "end": "1551840"
  },
  {
    "text": "how to understand the code and kind of like how to write the code it is it's definitely a beginner",
    "start": "1551840",
    "end": "1557279"
  },
  {
    "text": "tutorial it's not going to give you enough to like write some of the more complicated stuff that",
    "start": "1557279",
    "end": "1563600"
  },
  {
    "text": "eduardo and myself have written but it should get you enough to like start you can start writing a bit of code you",
    "start": "1563600",
    "end": "1568960"
  },
  {
    "text": "know try to start with smaller features and then work your way up if you want to contribute to fluid bit",
    "start": "1568960",
    "end": "1576480"
  },
  {
    "text": "that's it and with that i'm going to turn it over to masood",
    "start": "1576480",
    "end": "1585840"
  },
  {
    "text": "hello everyone um this is massoud kolini and i'm the",
    "start": "1589679",
    "end": "1595840"
  },
  {
    "text": "maintainer of stream processor for flambet",
    "start": "1595840",
    "end": "1600320"
  },
  {
    "text": "so if some of you know what is stream processing it's actually the ability to perform data",
    "start": "1601039",
    "end": "1606799"
  },
  {
    "text": "processing while it is still in motion in general what you do with stream",
    "start": "1606799",
    "end": "1612960"
  },
  {
    "text": "processing is that you can apply computations on the stream of data in real time that",
    "start": "1612960",
    "end": "1618799"
  },
  {
    "text": "is coming from your devices",
    "start": "1618799",
    "end": "1626640"
  },
  {
    "text": "for stream processing we have events which are records that are emitted by applications services or",
    "start": "1626640",
    "end": "1632080"
  },
  {
    "text": "harvard and you receive them through your input plugins and events of are structured messages",
    "start": "1632080",
    "end": "1641520"
  },
  {
    "text": "they're composed of timestamp every every event has a time stamp which",
    "start": "1641520",
    "end": "1648080"
  },
  {
    "text": "specifies the time that event was created and the message with is actually the",
    "start": "1648080",
    "end": "1653360"
  },
  {
    "text": "data inside the inside the record",
    "start": "1653360",
    "end": "1657840"
  },
  {
    "text": "um what we need from a stream processor what are the goals in general we want it",
    "start": "1659440",
    "end": "1665200"
  },
  {
    "text": "to be fast and likely data processing we want there to be no tables and we want there to be no indexing",
    "start": "1665200",
    "end": "1671440"
  },
  {
    "text": "and it has to have an easy to use programming model for example what you can think of is",
    "start": "1671440",
    "end": "1678240"
  },
  {
    "text": "that you can think of fluent bit as a kind of data collector buffer and distributor and you can think",
    "start": "1678240",
    "end": "1684480"
  },
  {
    "text": "that okay so what if i want to do some computations while i'm receiving data from one or",
    "start": "1684480",
    "end": "1690559"
  },
  {
    "text": "more of input plugins and if i want to do the computations not to send them",
    "start": "1690559",
    "end": "1695600"
  },
  {
    "text": "out and before sending them out and only send them out when i need them then stream pressing is possibly one of",
    "start": "1695600",
    "end": "1702799"
  },
  {
    "text": "the major tools that you can use in flipbit",
    "start": "1702799",
    "end": "1709919"
  },
  {
    "text": "but how we can do that and how in journalism processor works",
    "start": "1709919",
    "end": "1716720"
  },
  {
    "text": "um a stream processor in general can receive events or records from",
    "start": "1716720",
    "end": "1722399"
  },
  {
    "text": "hardware software that are attached to them they can apply real-time data analysis",
    "start": "1722399",
    "end": "1728880"
  },
  {
    "text": "and then they can send the result out to a data collector or event collector",
    "start": "1728880",
    "end": "1735840"
  },
  {
    "text": "so in general a stream processor receives structured events or records exposes a query language which has",
    "start": "1736000",
    "end": "1743440"
  },
  {
    "text": "key selection filtering aggregation functions and event routing and it does the",
    "start": "1743440",
    "end": "1750159"
  },
  {
    "text": "processing in memory",
    "start": "1750159",
    "end": "1753840"
  },
  {
    "text": "however when you're doing when you want to do some stream pressing on the edge",
    "start": "1760480",
    "end": "1766399"
  },
  {
    "text": "with the current on the shoulder stream processors what you do is that you have log event",
    "start": "1766399",
    "end": "1772880"
  },
  {
    "text": "collectors on the edge and then it sends everything all the records to the cloud to the",
    "start": "1772880",
    "end": "1779600"
  },
  {
    "text": "stream processor which can be a spark sql which can be apache link which can be um",
    "start": "1779600",
    "end": "1788240"
  },
  {
    "text": "kafka sql and what they do is that they do all the analysis in the cloud and send the result again back to some",
    "start": "1788240",
    "end": "1796159"
  },
  {
    "text": "servers like some data collectors or log collectors or metric collectors",
    "start": "1796159",
    "end": "1801760"
  },
  {
    "text": "however what you want to do is that processing stream processing on the edge",
    "start": "1801760",
    "end": "1809360"
  },
  {
    "text": "this is what we saw like current distributors are working on cloud and what we currently have is that we",
    "start": "1809360",
    "end": "1816559"
  },
  {
    "text": "have added a stream processor to fluent with core so you can do all",
    "start": "1816559",
    "end": "1821600"
  },
  {
    "text": "the processing that you want all the computations that you want on the edge before sending huge number of data out",
    "start": "1821600",
    "end": "1827760"
  },
  {
    "text": "to the cloud and do cloud site log or data analysis",
    "start": "1827760",
    "end": "1833120"
  },
  {
    "text": "for uh for the data that you are receiving from different hardware and software what are the reasons in general",
    "start": "1833120",
    "end": "1841120"
  },
  {
    "text": "what stream processing on edge can do for you is that it offloads computations from servers to",
    "start": "1841120",
    "end": "1847200"
  },
  {
    "text": "data collectors just assume that you have thousands of data collectors and many of them may have free resources",
    "start": "1847200",
    "end": "1854799"
  },
  {
    "text": "like cp and memory available and if you can upload just even a small",
    "start": "1854799",
    "end": "1860640"
  },
  {
    "text": "piece of calculations to your devices actually you're paying a lot",
    "start": "1860640",
    "end": "1868159"
  },
  {
    "text": "less for cloud computations you're paying a lot less for your traffic flow between edge",
    "start": "1868159",
    "end": "1874480"
  },
  {
    "text": "devices and cloud and you will be actually very fast it also only sends required data to",
    "start": "1874480",
    "end": "1880960"
  },
  {
    "text": "cloud so you may do computations you say that okay so if the computations had this result don't send data to cloud",
    "start": "1880960",
    "end": "1887440"
  },
  {
    "text": "so you can decide on sending the date sending the data that you want to cloud",
    "start": "1887440",
    "end": "1893760"
  },
  {
    "text": "like many other stream processors full onto it also uses declarative sql sql like language to express the",
    "start": "1893760",
    "end": "1900320"
  },
  {
    "text": "computations if you guys are familiar with the sql you know that it is a like it is a",
    "start": "1900320",
    "end": "1906880"
  },
  {
    "text": "high-level degree declarative language that you can easily specify many kind of computations in",
    "start": "1906880",
    "end": "1915279"
  },
  {
    "text": "that on the records and data and it is easy to understand easy to write so it is very useful if",
    "start": "1915279",
    "end": "1922799"
  },
  {
    "text": "our stream processor or any stream processor uses a sql skill like language to define the",
    "start": "1922799",
    "end": "1928240"
  },
  {
    "text": "computations that they want to do on the edge integrated it is integrated",
    "start": "1928240",
    "end": "1933760"
  },
  {
    "text": "inflated core so it is very fast memory and cpu efficient",
    "start": "1933760",
    "end": "1939120"
  },
  {
    "text": "this is the syntax um this is a simplified syntax we can say",
    "start": "1939760",
    "end": "1944799"
  },
  {
    "text": "uh we will see that in demo later you can write create a stream stream name as",
    "start": "1944799",
    "end": "1952080"
  },
  {
    "text": "and now you can have a selected statement similar to a singular fiscal where you can write select the result",
    "start": "1952080",
    "end": "1960240"
  },
  {
    "text": "statement is the same terms as a sql like you can say select the average of memory select the",
    "start": "1960240",
    "end": "1967200"
  },
  {
    "text": "minimum cpu usage select the minimum of this field in the record and you have from",
    "start": "1967200",
    "end": "1974159"
  },
  {
    "text": "any sql you have front from a table and here you have from from a different input plugin",
    "start": "1974159",
    "end": "1982559"
  },
  {
    "text": "or another stream and then as you might know as well when we do computations on",
    "start": "1982559",
    "end": "1988640"
  },
  {
    "text": "the streams we need to have a window that we do apply the computations on",
    "start": "1988640",
    "end": "1993919"
  },
  {
    "text": "like we can have a window that we put all the events from last for example 30 seconds in we apply",
    "start": "1993919",
    "end": "2001440"
  },
  {
    "text": "computations and then we throw everything the way we wait for the window to be filled in we call this window tumbling window we",
    "start": "2001440",
    "end": "2009120"
  },
  {
    "text": "can have another window that some of you may know that as moving a midwing window where this",
    "start": "2009120",
    "end": "2015840"
  },
  {
    "text": "window is called hopping here and we can say that there's a hopping window of size",
    "start": "2015840",
    "end": "2021200"
  },
  {
    "text": "30 seconds and it advances by for example one second so every one",
    "start": "2021200",
    "end": "2027120"
  },
  {
    "text": "second we throw away the old data from the first one second and put",
    "start": "2027120",
    "end": "2032720"
  },
  {
    "text": "back the new data for the coming one second that we were in this",
    "start": "2032720",
    "end": "2038880"
  },
  {
    "text": "is called window hopping we can have work condition where we can filter the required records",
    "start": "2038880",
    "end": "2044880"
  },
  {
    "text": "and important thing is that we can have group by when we get we can group the records by",
    "start": "2044880",
    "end": "2050320"
  },
  {
    "text": "specific fields and apply calculations on the groups",
    "start": "2050320",
    "end": "2056639"
  },
  {
    "text": "we support functionalities here we have many more functionalities but some of",
    "start": "2057599",
    "end": "2063839"
  },
  {
    "text": "the more important ones are you can apply average on the key count",
    "start": "2063839",
    "end": "2069040"
  },
  {
    "text": "minimum maximum and sum similar to aggregation functions in conventional sql we can have time",
    "start": "2069040",
    "end": "2076878"
  },
  {
    "text": "functions like we can add now which is the current time or unix timestamp to the record",
    "start": "2076879",
    "end": "2082638"
  },
  {
    "text": "and you're adding more complicated functions like if some of you are familiar with",
    "start": "2082639",
    "end": "2088158"
  },
  {
    "text": "time series functions like forecasting which is a linear regression or simple linear regression",
    "start": "2088159",
    "end": "2095040"
  },
  {
    "text": "you can apply a forecasting cure to your stream and you can say that okay",
    "start": "2095040",
    "end": "2102160"
  },
  {
    "text": "so we have memory we can we are getting memory from the input memory",
    "start": "2102160",
    "end": "2107359"
  },
  {
    "text": "memory plugin and give me the forecast of memory usage in the next 100 seconds",
    "start": "2107359",
    "end": "2113839"
  },
  {
    "text": "so this time service functions can do that for example time service underlined forecast under land r is the reverse of",
    "start": "2113839",
    "end": "2119920"
  },
  {
    "text": "that you say that tell me when in future my memory usage will pass a certain amount",
    "start": "2119920",
    "end": "2126240"
  },
  {
    "text": "so i know that i will be in the safe in the safe range of memory usage",
    "start": "2126240",
    "end": "2132640"
  },
  {
    "text": "i will show that to you in the demo how you can use in general the stream processing and",
    "start": "2132640",
    "end": "2138480"
  },
  {
    "text": "these time service functionalities one nice thing is that for stream processing we support sub keys",
    "start": "2138480",
    "end": "2145119"
  },
  {
    "text": "let's say that you have nested json you can apply those computations on nested json using",
    "start": "2145119",
    "end": "2152880"
  },
  {
    "text": "like what you have down the page key square brackets sub q1 screw brackets sub q2 if you have",
    "start": "2152880",
    "end": "2160400"
  },
  {
    "text": "and nested json of depth 2 a simple example you can write a stream",
    "start": "2160400",
    "end": "2167040"
  },
  {
    "text": "processing rule like this or task we say create a stream",
    "start": "2167040",
    "end": "2172160"
  },
  {
    "text": "with the name of results weight tag is results similar to the tag that",
    "start": "2172160",
    "end": "2178160"
  },
  {
    "text": "you've defined for the input plugins you can tag your stream as and now you",
    "start": "2178160",
    "end": "2183280"
  },
  {
    "text": "have your selected statement select average of cpu from",
    "start": "2183280",
    "end": "2188880"
  },
  {
    "text": "cpu stream that is actually your input cpu plugin with a tumbling window of size 60",
    "start": "2188880",
    "end": "2195359"
  },
  {
    "text": "seconds simple so you wrote a full functioning computation",
    "start": "2195359",
    "end": "2201520"
  },
  {
    "text": "of taking an average of a specific field of a record using just one line of skill statement",
    "start": "2201520",
    "end": "2210560"
  },
  {
    "text": "let's go for a demo and if you guys have any problem in seeing my screen please write",
    "start": "2211040",
    "end": "2216720"
  },
  {
    "text": "that in the chat window so i can fix it",
    "start": "2216720",
    "end": "2220880"
  },
  {
    "text": "okay um i'm hoping that everyone can see my",
    "start": "2227040",
    "end": "2233200"
  },
  {
    "text": "screens um here i'm running through a bit",
    "start": "2233200",
    "end": "2239520"
  },
  {
    "text": "um so we need a configuration file this is a configuration file for the",
    "start": "2240160",
    "end": "2245680"
  },
  {
    "text": "demo i'm hoping that you guys are familiar with writing configuration file for flambeat",
    "start": "2245680",
    "end": "2251760"
  },
  {
    "text": "here we say that we have the service section which says okay so um flash flash",
    "start": "2251760",
    "end": "2259760"
  },
  {
    "text": "output every one second log level is info http server on plugin files is this you",
    "start": "2259760",
    "end": "2265920"
  },
  {
    "text": "need to add the path of your stream file so streams file",
    "start": "2265920",
    "end": "2271520"
  },
  {
    "text": "is actually the name of the file that you are writing your stream processing tasks",
    "start": "2271520",
    "end": "2276800"
  },
  {
    "text": "inside that's it you don't need to do anything else here in the config file",
    "start": "2276800",
    "end": "2282480"
  },
  {
    "text": "you define here we have an input plug-in memory that we are reading data from this input",
    "start": "2282480",
    "end": "2288240"
  },
  {
    "text": "plug-in alias memory tag memory which will use that in the stream processor and what i'm doing here",
    "start": "2288240",
    "end": "2295520"
  },
  {
    "text": "is i'm sending the result of forecast let's say here you say that i have match forecasted",
    "start": "2295520",
    "end": "2301359"
  },
  {
    "text": "star that means that send the result of the forecast set the result of",
    "start": "2301359",
    "end": "2306480"
  },
  {
    "text": "any input or stream processor that has a tag forecast star to the influx tv and flex db is",
    "start": "2306480",
    "end": "2313520"
  },
  {
    "text": "a time series database which i'm using that in order to visualize the result of these stream",
    "start": "2313520",
    "end": "2320800"
  },
  {
    "text": "processing tasks to you in addition i'm writing everything else",
    "start": "2320800",
    "end": "2327040"
  },
  {
    "text": "to cd out in order to make sure everything is working okay can you increase your uh font size",
    "start": "2327040",
    "end": "2334880"
  },
  {
    "text": "please yeah thank you good sure um",
    "start": "2334880",
    "end": "2340400"
  },
  {
    "text": "okay so i hope that you know so you've at least you could see what i was saying so i will go to the",
    "start": "2340400",
    "end": "2346000"
  },
  {
    "text": "next step now we have defined the streams file let's see",
    "start": "2346000",
    "end": "2351440"
  },
  {
    "text": "what is inside streams file okay this is the way that you write",
    "start": "2351440",
    "end": "2357599"
  },
  {
    "text": "string processor tasks you start with the section stream task name of the task forecast and you define",
    "start": "2357599",
    "end": "2365040"
  },
  {
    "text": "an exec which is actually uh defines the sql defines the sql",
    "start": "2365040",
    "end": "2372240"
  },
  {
    "text": "processing syntax um similar to what i mentioned in the in",
    "start": "2372240",
    "end": "2377760"
  },
  {
    "text": "the slides you start with create a string forecast the name of the stream as now here your selected statement you",
    "start": "2377760",
    "end": "2385200"
  },
  {
    "text": "can say give me the average of as the result give me the average of memory used and the time series forecast",
    "start": "2385200",
    "end": "2394800"
  },
  {
    "text": "give me the forecast where the input is record time and the memory used",
    "start": "2394800",
    "end": "2401599"
  },
  {
    "text": "for the next 100 seconds tell me how much the memory i will use in the next 100 seconds",
    "start": "2401599",
    "end": "2406800"
  },
  {
    "text": "and you say as forecast that means that the re named the output record as forecast from",
    "start": "2406800",
    "end": "2413680"
  },
  {
    "text": "memory stream memory which is actually our input memory input plugin use the hopping window or sliding window",
    "start": "2413680",
    "end": "2421599"
  },
  {
    "text": "of size 15 seconds and advance it by one second",
    "start": "2421599",
    "end": "2427040"
  },
  {
    "text": "i've added another stream processing task here just for the sake of demo",
    "start": "2427040",
    "end": "2432240"
  },
  {
    "text": "the forecast value may not be very smooth may not may go up and down a lot so what i'm doing is",
    "start": "2432240",
    "end": "2438319"
  },
  {
    "text": "here is i create another task called forecast average",
    "start": "2438319",
    "end": "2443440"
  },
  {
    "text": "and i say create a stream forecast average as now select the average of forecast what",
    "start": "2443440",
    "end": "2449680"
  },
  {
    "text": "does the stream processor do is that it reads from the forecast stream and the nice thing here is that",
    "start": "2449680",
    "end": "2457359"
  },
  {
    "text": "every task in a stream processor can be seen as an input so we can pipe",
    "start": "2457359",
    "end": "2462800"
  },
  {
    "text": "cascade many many stream processing tasks together so i'm reading from a forecast memory",
    "start": "2462800",
    "end": "2468480"
  },
  {
    "text": "and taking average on the forecast value again i define a hopping window of size 15 seconds at once",
    "start": "2468480",
    "end": "2474800"
  },
  {
    "text": "but by one second okay nice so in almost two lines we have defined",
    "start": "2474800",
    "end": "2481280"
  },
  {
    "text": "two string processing tasks with with two almost complicated functionalities",
    "start": "2481280",
    "end": "2488400"
  },
  {
    "text": "now let's see how it works",
    "start": "2488400",
    "end": "2494480"
  },
  {
    "text": "i just started running it so what i do is that as you may know i run fluent bit and pass the configuration file demo.conf",
    "start": "2494480",
    "end": "2503280"
  },
  {
    "text": "for the next first 15 seconds because the window of the simple server filled up yet you can see just the",
    "start": "2503760",
    "end": "2510160"
  },
  {
    "text": "output of the memory plugin and around now you should be able to see the forecaster value",
    "start": "2510160",
    "end": "2516960"
  },
  {
    "text": "yes here it is so i highlight it so it says that oh memory",
    "start": "2516960",
    "end": "2523280"
  },
  {
    "text": "usage is 3.4 gigabytes and the forecast is 3.4 gigabytes so it",
    "start": "2523280",
    "end": "2529040"
  },
  {
    "text": "says that i don't see any reason that in future uh in the next 100 seconds the memory",
    "start": "2529040",
    "end": "2535760"
  },
  {
    "text": "usage will be changed because we are actually not running a huge number of um processes on",
    "start": "2535760",
    "end": "2541520"
  },
  {
    "text": "the local machine so what i'm doing here as well i'm hoping that you can see",
    "start": "2541520",
    "end": "2547280"
  },
  {
    "text": "my um my screen and you can see uh this graph",
    "start": "2547280",
    "end": "2555119"
  },
  {
    "text": "it is a graphing dashboard that actually is connected to then fluxdb and it is showing the",
    "start": "2555119",
    "end": "2563599"
  },
  {
    "text": "average memory and memory usage you can simply see just one line because they're overlapping because",
    "start": "2563599",
    "end": "2569200"
  },
  {
    "text": "the memory usage and the forecast is almost the same it says that the the yellow line is",
    "start": "2569200",
    "end": "2576400"
  },
  {
    "text": "the average number usage which is 3.4 gigabytes and the forecast is almost the same it",
    "start": "2576400",
    "end": "2581839"
  },
  {
    "text": "says that i don't see any reason that you know we are we i don't see any trend of change in the memory that shows that in",
    "start": "2581839",
    "end": "2588160"
  },
  {
    "text": "future we'll use more memory now let's do a trick let's run",
    "start": "2588160",
    "end": "2595680"
  },
  {
    "text": "a process that starts consuming memory of my machine and let's see what will happen",
    "start": "2597040",
    "end": "2604480"
  },
  {
    "text": "wait for the refresh and possibly you're seeing a green line",
    "start": "2604640",
    "end": "2613920"
  },
  {
    "text": "going up where the green line showing the forecast of memory usage every in every",
    "start": "2613920",
    "end": "2621920"
  },
  {
    "text": "time the yellow line says that look the average memory use the memory that is",
    "start": "2621920",
    "end": "2627040"
  },
  {
    "text": "used currently is 3.4 but in the next 100 seconds we will use 3.7",
    "start": "2627040",
    "end": "2632720"
  },
  {
    "text": "and look at here i would define a line that is called alert that means that whenever the forecast",
    "start": "2632720",
    "end": "2638640"
  },
  {
    "text": "has four gigabytes send an alert create an alert send it you know send an email to the admin",
    "start": "2638640",
    "end": "2645359"
  },
  {
    "text": "or to operator or a phone call or whatever before we actually get to that point",
    "start": "2645359",
    "end": "2651599"
  },
  {
    "text": "that means that something is is going wrong with the machine um so we can see that the gridline is",
    "start": "2651599",
    "end": "2659040"
  },
  {
    "text": "forecast that our stream processor is calculating and the yellow line is the actual memory",
    "start": "2659040",
    "end": "2666319"
  },
  {
    "text": "usage at the current time and now the green line passed the alert and you can see that",
    "start": "2666319",
    "end": "2672400"
  },
  {
    "text": "no it gets red now let me terminate the memory consumption and see",
    "start": "2672400",
    "end": "2679520"
  },
  {
    "text": "what will happen",
    "start": "2679520",
    "end": "2682240"
  },
  {
    "text": "yes yellow line drops a bit but green line drops a lot more because",
    "start": "2685680",
    "end": "2691920"
  },
  {
    "text": "it sees the trend of reduction in the yellow line and it thinks that oh we are going to consume a lot less",
    "start": "2691920",
    "end": "2698000"
  },
  {
    "text": "memory but after some time when things get settled they again get back to normal and everything will",
    "start": "2698000",
    "end": "2704560"
  },
  {
    "text": "be a lot better so forecast will be again the same as the actual memory usage if",
    "start": "2704560",
    "end": "2711520"
  },
  {
    "text": "something is not wrong in your machine okay i can see there are some questions",
    "start": "2711520",
    "end": "2717280"
  },
  {
    "text": "i will ask the questions after this because it's almost the end",
    "start": "2717280",
    "end": "2723680"
  },
  {
    "text": "um okay uh let me go back to slides so i think",
    "start": "2723920",
    "end": "2730079"
  },
  {
    "text": "we are almost done with the demo and you're almost done with the with the stream processing presentation",
    "start": "2730079",
    "end": "2736319"
  },
  {
    "text": "but possibly the final thing that you can think of is that it is not bad to not to see front bit as",
    "start": "2736319",
    "end": "2743119"
  },
  {
    "text": "a data collector buffer and router you can see",
    "start": "2743119",
    "end": "2748800"
  },
  {
    "text": "fluid bit in general and stream processing specifically as a way that you can do",
    "start": "2748800",
    "end": "2756079"
  },
  {
    "text": "a lot more computations on your data that is coming through to the fluent bit without",
    "start": "2756079",
    "end": "2762960"
  },
  {
    "text": "sending that out to cloud you can do loads of things with fluent bit you can do machine learning on the edge",
    "start": "2762960",
    "end": "2771040"
  },
  {
    "text": "you can do many different calculations and this can do a lot for you in your in",
    "start": "2771040",
    "end": "2776400"
  },
  {
    "text": "your projects thank you",
    "start": "2776400",
    "end": "2779839"
  },
  {
    "text": "thanks mason so i think that we're going to on the last part of the webinar and now",
    "start": "2782160",
    "end": "2788880"
  },
  {
    "text": "we are going to jump into the q a so please if you are in the chat you have some",
    "start": "2788880",
    "end": "2795440"
  },
  {
    "text": "questions or you would like to assign to the maintainers this is the right time for it",
    "start": "2795440",
    "end": "2803838"
  },
  {
    "text": "yes i'm not sure if they can unmute themselves or need to be through the chat",
    "start": "2806960",
    "end": "2813040"
  },
  {
    "text": "yeah so everybody feel free to ask your questions in the q a and i'll go ahead and ask them",
    "start": "2813760",
    "end": "2821200"
  },
  {
    "text": "so could you guys uh this is from jindong could you elaborate a bit more on the",
    "start": "2821200",
    "end": "2826720"
  },
  {
    "text": "hopping parameter 15 second and one second",
    "start": "2826720",
    "end": "2831839"
  },
  {
    "text": "that's the question for massoud um yes um so if so this is called",
    "start": "2832960",
    "end": "2839680"
  },
  {
    "text": "um so the hopping window works like this you it creates a window of size 15",
    "start": "2839680",
    "end": "2845680"
  },
  {
    "text": "seconds that means that it buffers all the data that is coming for 15 seconds and now what is the what",
    "start": "2845680",
    "end": "2853440"
  },
  {
    "text": "it does is that in every second it throws away the old the oldest data from the first",
    "start": "2853440",
    "end": "2860480"
  },
  {
    "text": "one second and puts back puts into a queue it's like a queue and puts back into the",
    "start": "2860480",
    "end": "2866400"
  },
  {
    "text": "window uh the new data that is gathered for for for the current for the last one second",
    "start": "2866400",
    "end": "2872960"
  },
  {
    "text": "that means that in every one second it throws away the old the the oldest one second data and",
    "start": "2872960",
    "end": "2880880"
  },
  {
    "text": "adds the newest one second data to the window and what it does is that that means that it still keeps keeps",
    "start": "2880880",
    "end": "2887920"
  },
  {
    "text": "some some of the data that is arrived in the last 15 seconds i mean that it keeps the data from the last 14",
    "start": "2887920",
    "end": "2894400"
  },
  {
    "text": "seconds and then adds one second data in the next one second it keeps the data",
    "start": "2894400",
    "end": "2899920"
  },
  {
    "text": "from the last 14 seconds and adds one second of data so that means that the data size",
    "start": "2899920",
    "end": "2906240"
  },
  {
    "text": "that the window sizes always shows the last 15 seconds does it be clear clear that for you",
    "start": "2906240",
    "end": "2915838"
  },
  {
    "text": "yeah looks like it was clear",
    "start": "2918640",
    "end": "2929838"
  },
  {
    "text": "all right does anybody else have any",
    "start": "2931280",
    "end": "2935440"
  },
  {
    "text": "questions",
    "start": "2940839",
    "end": "2943839"
  },
  {
    "text": "i guess we have one can you guys elaborate on the name fluent",
    "start": "2952400",
    "end": "2960318"
  },
  {
    "text": "okay i'm going to elaborate on that um this is by what it was sold by the",
    "start": "2962000",
    "end": "2967200"
  },
  {
    "text": "creator of fluenty okay when it's part of the story of the company",
    "start": "2967200",
    "end": "2972480"
  },
  {
    "text": "so when they created the treasure data at the beginning this first a hadoop as a service that's how it",
    "start": "2972480",
    "end": "2978640"
  },
  {
    "text": "started and they needed to have a tool to ingest data into this new cloud platform",
    "start": "2978640",
    "end": "2986400"
  },
  {
    "text": "but it i need to collect data from different places from or from different languages because",
    "start": "2986400",
    "end": "2993359"
  },
  {
    "text": "as you can see in the fluency ecosystem we have different sdks so",
    "start": "2993359",
    "end": "2998880"
  },
  {
    "text": "this new tool needs to be too fluent enough to understand different formats",
    "start": "2998880",
    "end": "3005359"
  },
  {
    "text": "fluent enough to uh to be connected with different language languages and that's why the ecosystem",
    "start": "3005359",
    "end": "3011359"
  },
  {
    "text": "was called fluent and then the project was named fluentd as a demon you know most of the unique",
    "start": "3011359",
    "end": "3018240"
  },
  {
    "text": "services ends with d and that's why the fluent name and",
    "start": "3018240",
    "end": "3024079"
  },
  {
    "text": "well fluent bet was created in 2015 i would say four years after fluency so",
    "start": "3024079",
    "end": "3032640"
  },
  {
    "text": "we put in the bit part of the name because we need it to be like a lightweight option at that",
    "start": "3032640",
    "end": "3039280"
  },
  {
    "text": "time for embedded and constrained devices but we always keep it as a fluent ecosystem",
    "start": "3039280",
    "end": "3046880"
  },
  {
    "text": "great uh ali has a question can you explain a bit about the forecasting part and how",
    "start": "3049520",
    "end": "3056000"
  },
  {
    "text": "the computation is done",
    "start": "3056000",
    "end": "3059440"
  },
  {
    "text": "um so so actually this time series forecast is a simple linear regression",
    "start": "3064880",
    "end": "3072000"
  },
  {
    "text": "which tries to estimate the trend the trend with the line and based on the based on",
    "start": "3072000",
    "end": "3078000"
  },
  {
    "text": "that it calculates when in future the line will reach a specific value which is",
    "start": "3078000",
    "end": "3084800"
  },
  {
    "text": "called forecast so if you want to read more about it so you can just",
    "start": "3084800",
    "end": "3090160"
  },
  {
    "text": "search simple linear regression and this is actually the way it works",
    "start": "3090160",
    "end": "3097838"
  },
  {
    "text": "okay great last call for questions",
    "start": "3103599",
    "end": "3111838"
  },
  {
    "text": "okay oh here we go uh can plugins written in rust be integrated with",
    "start": "3117440",
    "end": "3122720"
  },
  {
    "text": "fluent bit at the moment the only integration that",
    "start": "3122720",
    "end": "3130079"
  },
  {
    "text": "we have to write plugins of course are c language flambet is written in c language",
    "start": "3130079",
    "end": "3136000"
  },
  {
    "text": "you can write a output plugins in addition to see in golang right or you can write filters in lua",
    "start": "3136000",
    "end": "3143839"
  },
  {
    "text": "we don't have bindings for rust and i i know that aws was investigating the",
    "start": "3143839",
    "end": "3151920"
  },
  {
    "text": "if it was good or not enough to to invest into integrated rust connectors but one of the major",
    "start": "3151920",
    "end": "3160480"
  },
  {
    "text": "uh i would say integration problems was that for example if you want to",
    "start": "3160480",
    "end": "3166640"
  },
  {
    "text": "write an output connector you have to reimplement or reuse external components",
    "start": "3166640",
    "end": "3172240"
  },
  {
    "text": "to replace internal things of fluent bit like for example network io http client",
    "start": "3172240",
    "end": "3179280"
  },
  {
    "text": "because it's like influence everything is done handcrafted right and it's very optimized for",
    "start": "3179280",
    "end": "3184960"
  },
  {
    "text": "concurrency so putting external component in rust sometimes is not as straightforward",
    "start": "3184960",
    "end": "3192240"
  },
  {
    "text": "because you need to rely mostly on rust api and their own libraries for connectivity",
    "start": "3192240",
    "end": "3200640"
  },
  {
    "text": "or for other things and i think that this is not a challenge that has been faced just by rust but i",
    "start": "3200640",
    "end": "3207839"
  },
  {
    "text": "think that is pretty much similar to what happened to to go to golang so if you write an",
    "start": "3207839",
    "end": "3213520"
  },
  {
    "text": "extension for fluid beating gold and you face pretty much the same issue you are relying on your english apis right so you get advantages",
    "start": "3213520",
    "end": "3222000"
  },
  {
    "text": "you write that thing in a natural level language but you lose a bit of optimization you",
    "start": "3222000",
    "end": "3228400"
  },
  {
    "text": "lose performance because you are not using the internal",
    "start": "3228400",
    "end": "3233760"
  },
  {
    "text": "code that is designed to work with a special concurrency a mechanism a i",
    "start": "3233760",
    "end": "3241119"
  },
  {
    "text": "i know that also there's other projects for example in the ecosystem on the cnc ecosystem that they are",
    "start": "3241119",
    "end": "3246800"
  },
  {
    "text": "investigating the same thing this is not just about rust but other languages for example amboy who is a",
    "start": "3246800",
    "end": "3252960"
  },
  {
    "text": "boy proxy they are evaluating a how can we integrate plugins in rust for",
    "start": "3252960",
    "end": "3259520"
  },
  {
    "text": "filters but they're pretty much in the if you can see the open discussion on github they're pretty much",
    "start": "3259520",
    "end": "3265200"
  },
  {
    "text": "evaluating the same thing hey we will ended up writing a lot of components just to be because it's rust right",
    "start": "3265200",
    "end": "3273359"
  },
  {
    "text": "so i think that at the moment for the original question no there's no plans to integrate rust",
    "start": "3273359",
    "end": "3281359"
  },
  {
    "text": "because i think that for fluid project there's not enough benefits at the moment and",
    "start": "3281359",
    "end": "3288319"
  },
  {
    "text": "mostly from an integration perspective and challenges",
    "start": "3288319",
    "end": "3293440"
  },
  {
    "text": "can i i'll add a little bit to that um so yeah at aws we",
    "start": "3293440",
    "end": "3300000"
  },
  {
    "text": "investigated this the idea of working with fluid bit and rust we of course started with go",
    "start": "3300000",
    "end": "3305119"
  },
  {
    "text": "and then we moved to c but we also investigated rust um so you can actually use the golang",
    "start": "3305119",
    "end": "3311520"
  },
  {
    "text": "interface um to write code and rust uh uh but as eduardo said it it ends up not",
    "start": "3311520",
    "end": "3319280"
  },
  {
    "text": "actually you don't gain a lot um you because you can't work with the concurrency features",
    "start": "3319280",
    "end": "3324880"
  },
  {
    "text": "of fluent bit um like in a way fluid bit kind of like has its own run time almost",
    "start": "3324880",
    "end": "3330640"
  },
  {
    "text": "since in golang and rust you can't really work with those you don't gain very much um you end up having to there are other",
    "start": "3330640",
    "end": "3337440"
  },
  {
    "text": "ways that you could also like integrate rust because you can compile rust and see together which we",
    "start": "3337440",
    "end": "3343040"
  },
  {
    "text": "experimented with but you end up having to use a lot of c objects in the rust code",
    "start": "3343040",
    "end": "3349760"
  },
  {
    "text": "and we kind of ultimately decided it it didn't really have any strong benefits",
    "start": "3349760",
    "end": "3354799"
  },
  {
    "text": "it's the sort of thing like if you really love rust and you just want to write in rust just because you love it you could do",
    "start": "3354799",
    "end": "3360319"
  },
  {
    "text": "but if you're just making it from a purely kind of like a pragmatic decision it didn't really",
    "start": "3360319",
    "end": "3367520"
  },
  {
    "text": "seem to hold enough value",
    "start": "3367520",
    "end": "3371119"
  },
  {
    "text": "cool and second part of that question are there future plans for rust integrations",
    "start": "3373920",
    "end": "3380799"
  },
  {
    "text": "uh as eduardo said at the moment no okay i'd say like especially for us as as",
    "start": "3381119",
    "end": "3386319"
  },
  {
    "text": "maintainers since um you know eduardo and and massoud are both i'd say expert c programmers i'm maybe",
    "start": "3386319",
    "end": "3393119"
  },
  {
    "text": "more intermediate c programmers c programmer it's it's easier for us as maintainers to maintain the project if",
    "start": "3393119",
    "end": "3399200"
  },
  {
    "text": "it's only in one language you know that that's also one of the issues",
    "start": "3399200",
    "end": "3404799"
  },
  {
    "text": "yeah and one of the questions that we always get is about if we can replace some components with c plus plus",
    "start": "3404799",
    "end": "3411040"
  },
  {
    "text": "which is happens to be pretty much similar question that for other languages and at the end the answer that we gave for",
    "start": "3411040",
    "end": "3417760"
  },
  {
    "text": "us it was pretty much the same that we did for c plus plus right so this is not about a which language is",
    "start": "3417760",
    "end": "3425680"
  },
  {
    "text": "better more secure or weak it's about a matter of performance",
    "start": "3425680",
    "end": "3431200"
  },
  {
    "text": "and and i think that to be honest is really secure from all the angles",
    "start": "3431200",
    "end": "3437119"
  },
  {
    "text": "and yeah so and we're not saying that is something that we will not do",
    "start": "3437119",
    "end": "3443359"
  },
  {
    "text": "i'm saying that this is something that at the moment this was was said there's no much",
    "start": "3443359",
    "end": "3450480"
  },
  {
    "text": "value added to it but at some point i think this is beneficial to extend to",
    "start": "3450480",
    "end": "3456559"
  },
  {
    "text": "different mechanisms so people can extend it on different ways but what happened is that for example",
    "start": "3456559",
    "end": "3462079"
  },
  {
    "text": "most of people in the filter side for example if they want to add a special",
    "start": "3462079",
    "end": "3467680"
  },
  {
    "text": "logic or complexity to take decisions on how to modify their records as of now lua has big enough and the",
    "start": "3467680",
    "end": "3474880"
  },
  {
    "text": "performance penalty is pretty low and in the output side a most of the",
    "start": "3474880",
    "end": "3481119"
  },
  {
    "text": "connector relies on http backend so write an http",
    "start": "3481119",
    "end": "3486720"
  },
  {
    "text": "output plugin for fluent bait is pretty straightforward because we provide all the apis for",
    "start": "3486720",
    "end": "3491760"
  },
  {
    "text": "networking failures http client and everything that is needed to achieve",
    "start": "3491760",
    "end": "3497119"
  },
  {
    "text": "that and that's why for example a many company has implemented their own",
    "start": "3497119",
    "end": "3502480"
  },
  {
    "text": "connectors mostly sometimes without any external help for example the case of data",
    "start": "3502480",
    "end": "3508640"
  },
  {
    "text": "they just come up and say hey we want to write our plugin they used the api and was really straightforward for them",
    "start": "3508640",
    "end": "3517838"
  },
  {
    "text": "okay one final question as i saw on the early days of fluent bit docs it was",
    "start": "3519599",
    "end": "3524799"
  },
  {
    "text": "said that it was designed for embedded devices for the low resource consumption etc is",
    "start": "3524799",
    "end": "3531680"
  },
  {
    "text": "its focus now on kubernetes and cloud services",
    "start": "3531680",
    "end": "3536400"
  },
  {
    "text": "okay the design at the beginning was for embedded devices so initially with that statement in mind it",
    "start": "3537200",
    "end": "3544000"
  },
  {
    "text": "was mostly input and output plugins there was not filtered at the beginning and with inputs i'm referring to we just",
    "start": "3544000",
    "end": "3551440"
  },
  {
    "text": "offered the plugins to read data from serial interface memory metric",
    "start": "3551440",
    "end": "3556799"
  },
  {
    "text": "cpu matrix and most alternate log messages things that happens inside the device",
    "start": "3556799",
    "end": "3564000"
  },
  {
    "text": "and in the output side was treasure data output http pretty simple and the traction was",
    "start": "3564000",
    "end": "3570799"
  },
  {
    "text": "mostly seen on the cloud perspective so we said hey we're going to focus in the cloud but when we say we're going",
    "start": "3570799",
    "end": "3577680"
  },
  {
    "text": "to focus on the cloud it doesn't mean that we're going to be build a",
    "start": "3577680",
    "end": "3586000"
  },
  {
    "text": "big beard right that was really really heavy so i think that yeah fluent beat is",
    "start": "3586000",
    "end": "3592720"
  },
  {
    "text": "now i would say cloud focuses because i would say 90 of our users are kubernetes user",
    "start": "3592720",
    "end": "3598960"
  },
  {
    "text": "docker users but we always keep in mind this mindset of",
    "start": "3598960",
    "end": "3604160"
  },
  {
    "text": "low cpu and memory usage always so it doesn't for us it doesn't matter",
    "start": "3604160",
    "end": "3610960"
  },
  {
    "text": "where fluid is it needs to be optimal so for us it can run on a very small arms",
    "start": "3610960",
    "end": "3618480"
  },
  {
    "text": "cpu or can run on any big kind of server on any cloud provider so yes",
    "start": "3618480",
    "end": "3625760"
  },
  {
    "text": "originally created for embedded devices for embedded linux devices and but now it's a is with a focus in",
    "start": "3625760",
    "end": "3632799"
  },
  {
    "text": "the cloud but without losing performance and memory and and that's one of the strong reasons",
    "start": "3632799",
    "end": "3638640"
  },
  {
    "text": "also of the language because managing our own memory we know how to optimize we know how to use the memory",
    "start": "3638640",
    "end": "3645440"
  },
  {
    "text": "and avoid any kind of issues or performance issues that are",
    "start": "3645440",
    "end": "3650559"
  },
  {
    "text": "mostly generated by garbage collectors languages",
    "start": "3650559",
    "end": "3657838"
  },
  {
    "text": "okay great well thanks eduardo massoud and wesley for a great presentation",
    "start": "3659119",
    "end": "3664640"
  },
  {
    "text": "i'd also like to thank the attendees for joining uh as a reminder the recording and",
    "start": "3664640",
    "end": "3669760"
  },
  {
    "text": "slides will be up later today on the cncf webinar page uh we look forward to seeing you",
    "start": "3669760",
    "end": "3676400"
  },
  {
    "text": "again for another cncf webinar thanks everyone have a great day",
    "start": "3676400",
    "end": "3682160"
  },
  {
    "text": "thank you bye",
    "start": "3682160",
    "end": "3685838"
  }
]
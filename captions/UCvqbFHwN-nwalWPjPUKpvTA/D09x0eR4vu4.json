[
  {
    "text": "okay so we're starting right on time 1120 I'm a German person so I like to be",
    "start": "1760",
    "end": "9150"
  },
  {
    "text": "really sharp thanks for coming to a talk on AI ops I'm really glad that so many",
    "start": "9150",
    "end": "15690"
  },
  {
    "text": "people made it here and as I saw a talk today on ml ops and as we use the term",
    "start": "15690",
    "end": "24240"
  },
  {
    "text": "AI + ml interchangeably nowadays so if you talk to a sales person you probably",
    "start": "24240",
    "end": "32969"
  },
  {
    "text": "talk about AI if you want to get money if you talk to a data scientists you talk about machine learning and if you",
    "start": "32969",
    "end": "39030"
  },
  {
    "text": "talk to an engineer you probably talk about an SQL query so the term AI ops",
    "start": "39030",
    "end": "46829"
  },
  {
    "text": "means how can we use AI to help operations versus the term ml ops is",
    "start": "46829",
    "end": "56340"
  },
  {
    "text": "rather used for how can we operate machine learning in an operational",
    "start": "56340",
    "end": "62010"
  },
  {
    "text": "environment so this talk is about anomaly detection with Prometheus just a",
    "start": "62010",
    "end": "69689"
  },
  {
    "text": "quick question how many of you folks in the room would consider yourself an operation sky maybe",
    "start": "69689",
    "end": "76560"
  },
  {
    "text": "you're a chance and how many would consider yourself as an engineer software developer one and how many a",
    "start": "76560",
    "end": "85799"
  },
  {
    "text": "I'm data scientists that's good ok great so lesson learned should be don't be",
    "start": "85799",
    "end": "93750"
  },
  {
    "text": "afraid of AI and ml we're trying to make things easy now click it it doesn't work",
    "start": "93750",
    "end": "100619"
  },
  {
    "text": "anymore what happened",
    "start": "100619",
    "end": "108170"
  },
  {
    "text": "okay so I'm this is how I look out like",
    "start": "115710",
    "end": "122409"
  },
  {
    "text": "in on the internet on github I'm a software engineer slash manager hacker zombie slayer I'm from northern Germany",
    "start": "122409",
    "end": "130720"
  },
  {
    "text": "a city called keel which is close to Hamburg and Denmark we do a lot of",
    "start": "130720",
    "end": "136840"
  },
  {
    "text": "shipping only people not containers so we're not cloud native yet we're still",
    "start": "136840",
    "end": "142480"
  },
  {
    "text": "mode one I'm working for a stealth startup called Red Hat this is our brand",
    "start": "142480",
    "end": "148299"
  },
  {
    "text": "new logo check it out it's on the internet it's really new you can get some swag down",
    "start": "148299",
    "end": "153640"
  },
  {
    "text": "there at the at the booth and I'm working in the office of the CTO also",
    "start": "153640",
    "end": "159730"
  },
  {
    "text": "known as octo which is like an octopus we get to play with a lot of cool stuff",
    "start": "159730",
    "end": "166569"
  },
  {
    "text": "like making things sure things don't explode or implode but in the",
    "start": "166569",
    "end": "173430"
  },
  {
    "text": "essence were trying to define the gravity of the next technology that's",
    "start": "173430",
    "end": "178750"
  },
  {
    "text": "redheads looking into or trying to invest so it looks dangerous but it's",
    "start": "178750",
    "end": "184060"
  },
  {
    "text": "actually a lot of fun and just to give you a little bit of understanding what",
    "start": "184060",
    "end": "192040"
  },
  {
    "text": "my team is working on is we're trying to understand how reddit see say I so first",
    "start": "192040",
    "end": "199139"
  },
  {
    "text": "we want to make sure that a I as a work load of machine learning as a work load",
    "start": "199139",
    "end": "204160"
  },
  {
    "text": "runs very good on redheads products so we want to make sure that if",
    "start": "204160",
    "end": "210340"
  },
  {
    "text": "you're running your workloads on open shift say then it should be a really",
    "start": "210340",
    "end": "215859"
  },
  {
    "text": "good experience as you would do it on your local machine and then we have a",
    "start": "215859",
    "end": "222579"
  },
  {
    "text": "project called pop which is taken from the expense series that's the thing",
    "start": "222579",
    "end": "230019"
  },
  {
    "text": "where all the evil scientists work and those guys are looking into making AI",
    "start": "230019",
    "end": "235720"
  },
  {
    "text": "stacks really good and give you recommendation on the high stakes and software sex in general and they're also",
    "start": "235720",
    "end": "241630"
  },
  {
    "text": "recompiling tens of specifically for your environment and we able just by recompiling it to squeeze",
    "start": "241630",
    "end": "248710"
  },
  {
    "text": "like 10% out of the tensorflow project and as a side note I love talks with a",
    "start": "248710",
    "end": "255340"
  },
  {
    "text": "lot of pointers and links so that you can do something after the talk so I",
    "start": "255340",
    "end": "261730"
  },
  {
    "text": "spread all those small post-its on my slides you can take pictures during the",
    "start": "261730",
    "end": "267070"
  },
  {
    "text": "talk or at the end there will be a summary slide with all the post-its on",
    "start": "267070",
    "end": "272920"
  },
  {
    "text": "it then we have the open data up which is another great project because you",
    "start": "272920",
    "end": "279880"
  },
  {
    "text": "know data is the foundation data is the new oil people say software has become so ubiquitous stone so now people are",
    "start": "279880",
    "end": "286660"
  },
  {
    "text": "looking how to make how do you use everything out of data and we started",
    "start": "286660",
    "end": "291760"
  },
  {
    "text": "the project called the open data hub on open data a biome it's a one-click",
    "start": "291760",
    "end": "298240"
  },
  {
    "text": "solution to create a data science platform in your kubernetes cluster so",
    "start": "298240",
    "end": "304030"
  },
  {
    "text": "if you go to the operator hub and click on the button you can install the open",
    "start": "304030",
    "end": "311050"
  },
  {
    "text": "data up in your cluster which will give you steps F for storing which will give",
    "start": "311050",
    "end": "316690"
  },
  {
    "text": "you a spark for analyzing stuff which would give you give you a tuber to help for you notebook requirements it's",
    "start": "316690",
    "end": "322870"
  },
  {
    "text": "really easy and you could try these things out that I'm showing here in this talk on the on your local install or on",
    "start": "322870",
    "end": "329890"
  },
  {
    "text": "your cluster at home and then we concentrate on a I powered products and",
    "start": "329890",
    "end": "339669"
  },
  {
    "text": "services so for example we have a service called reddit insights which use some machine learning technology to",
    "start": "339669",
    "end": "346240"
  },
  {
    "text": "identify problems in your data center or we are met trying to make openshift",
    "start": "346240",
    "end": "353250"
  },
  {
    "text": "really stable by looking into the metrics that the clusters provide and",
    "start": "353250",
    "end": "359040"
  },
  {
    "text": "clusters provide metrics nowadays we have Prometheus so we want to try to",
    "start": "359040",
    "end": "364479"
  },
  {
    "text": "solve it trying internally to have the openshift team make better decisions if",
    "start": "364479",
    "end": "370120"
  },
  {
    "text": "their development their cluster rollout is going well",
    "start": "370120",
    "end": "376190"
  },
  {
    "text": "so this is what this talk is about how can we look into Prometheus metrics a",
    "start": "376190",
    "end": "383520"
  },
  {
    "text": "little bit more intelligently we'll look at Prometheus what prometheus is how do",
    "start": "383520",
    "end": "388980"
  },
  {
    "text": "we set up some long-term storage and to analyze your data then we look at the",
    "start": "388980",
    "end": "394890"
  },
  {
    "text": "definition of an anomaly and I will look into how we could integrate it into your existing monitoring setup so a quick",
    "start": "394890",
    "end": "404880"
  },
  {
    "text": "word of notice to set expectation this talk will not give you a shiny product",
    "start": "404880",
    "end": "410190"
  },
  {
    "text": "and the holy grail of monitoring it will also not give you a ready solution that",
    "start": "410190",
    "end": "415320"
  },
  {
    "text": "you can just plug into your monitoring setup and turn it into this old-school spider demon from doom you also don't",
    "start": "415320",
    "end": "423900"
  },
  {
    "text": "get a success story how we created our or transformed our messy setup into a",
    "start": "423900",
    "end": "429240"
  },
  {
    "text": "really advanced AI monitoring solution but I'll give you the tools and the",
    "start": "429240",
    "end": "435030"
  },
  {
    "text": "scripts to get you started we will look into some questions and answers to",
    "start": "435030",
    "end": "440910"
  },
  {
    "text": "problems that you might face in your journey and the good thing it's all open source so you will find everything that",
    "start": "440910",
    "end": "447870"
  },
  {
    "text": "we do on the internet which nowadays is",
    "start": "447870",
    "end": "453750"
  },
  {
    "text": "the equivalent to get up if you're talking in code so what's prometheus",
    "start": "453750",
    "end": "459060"
  },
  {
    "text": "who knows what prometheus is in this cross okay keep your hands open up and",
    "start": "459060",
    "end": "465330"
  },
  {
    "text": "who played with Prometheus and quite a bunch and who uses Prometheus in your in",
    "start": "465330",
    "end": "471960"
  },
  {
    "text": "a production environment cool so but then to get everybody on the same page",
    "start": "471960",
    "end": "479700"
  },
  {
    "text": "here's a quick architecture diagram of how the Prometheus setup looks like and",
    "start": "479700",
    "end": "485880"
  },
  {
    "text": "everybody loves architecture slides right they're so easy to decipher let's",
    "start": "485880",
    "end": "490890"
  },
  {
    "text": "start simple so we have this Prometheus guy and as we're in the kubernetes worlds we have to name it from Greek",
    "start": "490890",
    "end": "498360"
  },
  {
    "text": "gods right so Prometheus is the guy that's brought fire back to the people so hence this flame and then we have",
    "start": "498360",
    "end": "507510"
  },
  {
    "text": "targets and these are the things that Prometheus monitors or wants to monitor and those",
    "start": "507510",
    "end": "514680"
  },
  {
    "text": "targets targets expose metrics just via HTTP endpoints really simple the metrics",
    "start": "514680",
    "end": "521130"
  },
  {
    "text": "are the current state of the application or the target that you want to monitor",
    "start": "521130",
    "end": "527510"
  },
  {
    "text": "so that's really important to understand because we can't go back in time and ask",
    "start": "527510",
    "end": "533370"
  },
  {
    "text": "the application how was your state five minutes ago but it's Prometheus adding",
    "start": "533370",
    "end": "538589"
  },
  {
    "text": "that timestamp to the monitoring data that you want to scrape it gets tricky",
    "start": "538589",
    "end": "545880"
  },
  {
    "text": "if you're running in a disconnected environment like in a your cloud provider which might give you the data",
    "start": "545880",
    "end": "550980"
  },
  {
    "text": "back in a time slice interval so you want to make sure that your data",
    "start": "550980",
    "end": "556740"
  },
  {
    "text": "scientists understand that domain know that problem and then Prometheus stores the metrics in its time series database",
    "start": "556740",
    "end": "564120"
  },
  {
    "text": "which is essentially really performant database for this kind of data and you",
    "start": "564120",
    "end": "571800"
  },
  {
    "text": "can query the TS DB with a powerful query language called prompt QL which is",
    "start": "571800",
    "end": "578160"
  },
  {
    "text": "kind of weird to understand if you're coming from an SQL background so it will",
    "start": "578160",
    "end": "584220"
  },
  {
    "text": "be you will be dealing with vectors and some multiplications but there are tutorials all of the internet to get you",
    "start": "584220",
    "end": "590579"
  },
  {
    "text": "started and now metrics don't mean nothing if you don't get notified so",
    "start": "590579",
    "end": "595949"
  },
  {
    "text": "Prometheus can store rules which will trigger targets and then it'll push out",
    "start": "595949",
    "end": "601290"
  },
  {
    "text": "words to a thing called alert manager was also part of the distribution and this guy will take care that you're",
    "start": "601290",
    "end": "609180"
  },
  {
    "text": "being notified so in essence Prometheus is made in its",
    "start": "609180",
    "end": "614730"
  },
  {
    "text": "core for monitoring and alerting built around a very powerful and capable time",
    "start": "614730",
    "end": "621089"
  },
  {
    "text": "series database so what do we need for machine learning anybody data exactly so",
    "start": "621089",
    "end": "630089"
  },
  {
    "text": "the giant had once data let's give him some data before we give him data we all",
    "start": "630089",
    "end": "636149"
  },
  {
    "text": "obviously want to give him enough data because giant had once really a lot of",
    "start": "636149",
    "end": "642000"
  },
  {
    "text": "data and for me yes we'll only store it for like a day two days and then throw it away because",
    "start": "642000",
    "end": "647770"
  },
  {
    "text": "it's made for monitoring it's not made for storing it for long term so we set",
    "start": "647770",
    "end": "653050"
  },
  {
    "text": "out like so this project is like a year old and it's I would show a bit of the",
    "start": "653050",
    "end": "658150"
  },
  {
    "text": "progression here we set out to look into thing called panels which I thought was",
    "start": "658150",
    "end": "664330"
  },
  {
    "text": "also a Greek god but my kids corrected me he's from some Marvel movie so but he",
    "start": "664330",
    "end": "671770"
  },
  {
    "text": "looks really powerful so he can he can store the blobs in an object storage so",
    "start": "671770",
    "end": "679870"
  },
  {
    "text": "he basically takes that TS DB and stores it in s3 SEF or whatever and then it has",
    "start": "679870",
    "end": "688480"
  },
  {
    "text": "the Prometheus API on top of it so in essence it would give you unlimited retention until you're running out of",
    "start": "688480",
    "end": "695950"
  },
  {
    "text": "storage and you can query the hosts historical data right via the prom QL",
    "start": "695950",
    "end": "702160"
  },
  {
    "text": "and Prometheus API so it's pretty transparent and it also can downsample",
    "start": "702160",
    "end": "707620"
  },
  {
    "text": "your data so if you have have it on a minute scale but you only want to retain",
    "start": "707620",
    "end": "713200"
  },
  {
    "text": "it on a 5 minute or 10 minutes Kay so it can also run these jobs in the background but at that's at that time it",
    "start": "713200",
    "end": "719290"
  },
  {
    "text": "didn't work out so well in our open ships cluster maybe was openshift maybe was tunnels I don't know so we look into",
    "start": "719290",
    "end": "726490"
  },
  {
    "text": "something else like in flux TB it's also great thing to talk to store time series",
    "start": "726490",
    "end": "732430"
  },
  {
    "text": "database a time series data because in essence in flux is also time series database it has also nice integration",
    "start": "732430",
    "end": "739420"
  },
  {
    "text": "with Prometheus because you can just configure a remote endpoint and Prometheus will send every sample over",
    "start": "739420",
    "end": "747130"
  },
  {
    "text": "to in flux store it there but the unfortunate thing is it really eats Ram",
    "start": "747130",
    "end": "752590"
  },
  {
    "text": "for breakfast so it tries to keep everything in memory to keep everything",
    "start": "752590",
    "end": "757840"
  },
  {
    "text": "fast and we ended up with like 6 12",
    "start": "757840",
    "end": "763060"
  },
  {
    "text": "cakes of RAM after just a day so it wasn't really really suited for our use",
    "start": "763060",
    "end": "771400"
  },
  {
    "text": "case on the other hand you can sew your data scientists log",
    "start": "771400",
    "end": "776529"
  },
  {
    "text": "because you can connect your pandas dataframe which is a tooling that the data scientists work in rights to in",
    "start": "776529",
    "end": "783699"
  },
  {
    "text": "flux so they will have a really easy way to get into the in flux database where",
    "start": "783699",
    "end": "788740"
  },
  {
    "text": "as Prometheus they would need to learn how to create Prometheus you could solve",
    "start": "788740",
    "end": "797110"
  },
  {
    "text": "this problem if you would buy an influx cluster license and scale out but",
    "start": "797110",
    "end": "804610"
  },
  {
    "text": "unfortunately they have the open core model so they will only give you one node for free which is okay so if you",
    "start": "804610",
    "end": "812259"
  },
  {
    "text": "want to use in flux or ya for in flux already in your vironment you can easily use that so we created a Prometheus",
    "start": "812259",
    "end": "820930"
  },
  {
    "text": "scraper part that was just query the Prometheus API store the JSON blobs in",
    "start": "820930",
    "end": "827769"
  },
  {
    "text": "some safe storage and some s3 storage put it away and store it there storage",
    "start": "827769",
    "end": "833529"
  },
  {
    "text": "was cheap and we just had it backed up them we wrapped it into a container",
    "start": "833529",
    "end": "839139"
  },
  {
    "text": "configured we an environment variable and pointed to a Prometheus instance job done the good thing about it you don't",
    "start": "839139",
    "end": "845709"
  },
  {
    "text": "have to talk to your monitoring guys to configure their monitoring setup to move",
    "start": "845709",
    "end": "852250"
  },
  {
    "text": "their data to somewhere else which they might not want but we just need access to their Prometheus store and we just",
    "start": "852250",
    "end": "859240"
  },
  {
    "text": "kept the data out which is pretty straightforward and then you can use",
    "start": "859240",
    "end": "865120"
  },
  {
    "text": "something like Apache spark to query those JSON files and as I mentioned it's",
    "start": "865120",
    "end": "872319"
  },
  {
    "text": "part of the open data app so you would get that for free in your notebook and this is an a screenshot of such a",
    "start": "872319",
    "end": "879670"
  },
  {
    "text": "notebook where your data scientists would work in he just points it to the s3 endpoint and then with SPARQL it",
    "start": "879670",
    "end": "887350"
  },
  {
    "text": "feels like a database so you will get your pandas dataframe you can create with query it with SPARQL which really",
    "start": "887350",
    "end": "895660"
  },
  {
    "text": "feels like SQL over all those thousands and millions of JSON files and they just",
    "start": "895660",
    "end": "903339"
  },
  {
    "text": "feel like a database which is great oh and it also has like some",
    "start": "903339",
    "end": "911380"
  },
  {
    "text": "integrated snice function like you can create the standard deviation of a large",
    "start": "911380",
    "end": "916720"
  },
  {
    "text": "time series in a clustered environment which would not be possible in a single",
    "start": "916720",
    "end": "922420"
  },
  {
    "text": "node environment so it's Apache spark is really good for processing large data",
    "start": "922420",
    "end": "927430"
  },
  {
    "text": "sets and doing ETL then we revisited",
    "start": "927430",
    "end": "932610"
  },
  {
    "text": "tano's a couple of weeks months ago and we now have it actually running in a",
    "start": "932610",
    "end": "939400"
  },
  {
    "text": "production setup so all the OpenShift for clusters that you install will send back a subset of their telemetry",
    "start": "939400",
    "end": "947520"
  },
  {
    "text": "Prometheus data to to Red Hat and were capable of storing like 360,000 metrics",
    "start": "947520",
    "end": "954850"
  },
  {
    "text": "per hour and we store it off into a Stano store for long term so there's a",
    "start": "954850",
    "end": "960670"
  },
  {
    "text": "blog post about it how we set it up and it's all open source that zotero's works",
    "start": "960670",
    "end": "966190"
  },
  {
    "text": "great now and I think it's a de facto thing how to store Prometheus data for",
    "start": "966190",
    "end": "971230"
  },
  {
    "text": "long term so what do we really need for machine learning not just data but we",
    "start": "971230",
    "end": "977290"
  },
  {
    "text": "need consistent data so we need to understand how the data looks like there's a rough saying in the data",
    "start": "977290",
    "end": "984880"
  },
  {
    "text": "science community that 80% of your time you will spend on the nature of your data and just 20% on writing your neural",
    "start": "984880",
    "end": "992380"
  },
  {
    "text": "networks and doing your actual AI stuff so a lot of cleansing goes into this so we needed to to translate what the",
    "start": "992380",
    "end": "1000839"
  },
  {
    "text": "monitoring guys know about Prometheus metrics to our data scientists so let's",
    "start": "1000839",
    "end": "1005880"
  },
  {
    "text": "look at the Prometheus metrics metric ties we have a gauge which is essentially a time series and we have a",
    "start": "1005880",
    "end": "1011910"
  },
  {
    "text": "counter which is a monotonically increasing time series we have a histogram which is a cumulative",
    "start": "1011910",
    "end": "1019320"
  },
  {
    "text": "histogram of values and then we have a summary which is slightly different so a",
    "start": "1019320",
    "end": "1025740"
  },
  {
    "text": "gauge goes up and down a counter just goes up easy histogram a little bit",
    "start": "1025740",
    "end": "1031980"
  },
  {
    "text": "harder so in a typical histogram you would bucket your data into slices and",
    "start": "1031980",
    "end": "1037110"
  },
  {
    "text": "count how many values fall into one bucket so I have 100 in the 0 to 5",
    "start": "1037110",
    "end": "1044100"
  },
  {
    "text": "bucket a summary is slightly different because it not only counts how many things fall",
    "start": "1044100",
    "end": "1050870"
  },
  {
    "text": "into that bucket but also give you concrete value out of this bucket so if you want to know",
    "start": "1050870",
    "end": "1056780"
  },
  {
    "text": "oh my latency is actually 499 in that in that bucket and not in a histogram you",
    "start": "1056780",
    "end": "1065180"
  },
  {
    "text": "would only know that it's from 400 to 1000 so you get an actual value out of",
    "start": "1065180",
    "end": "1071150"
  },
  {
    "text": "it a metric in essence and I think in to speed it up a bit a metric is in essence",
    "start": "1071150",
    "end": "1079640"
  },
  {
    "text": "a series of data points which consists of labels and a measurement so value and",
    "start": "1079640",
    "end": "1088160"
  },
  {
    "text": "the timestamp so we would have cubelet operations as the metric name and then",
    "start": "1088160",
    "end": "1095660"
  },
  {
    "text": "you get it some give it some labels like hostname and operation time the operation type and that is one time",
    "start": "1095660",
    "end": "1102590"
  },
  {
    "text": "series in Prometheus so you have to be very careful careful choosing your well",
    "start": "1102590",
    "end": "1108500"
  },
  {
    "text": "labels so use something that is finished in your labels right if you put some",
    "start": "1108500",
    "end": "1116690"
  },
  {
    "text": "infinite data and your labels you might have a component combinatorially explosion and you're just using them",
    "start": "1116690",
    "end": "1123800"
  },
  {
    "text": "wrongly wrong because they're using creating a lot of time serieses and then",
    "start": "1123800",
    "end": "1129590"
  },
  {
    "text": "you have like the values okay so here's an example what he would store in these values so monitoring is basically hard",
    "start": "1129590",
    "end": "1141100"
  },
  {
    "text": "Prometheus for example doesn't enforce a schema so slash metrics the import can",
    "start": "1141100",
    "end": "1146620"
  },
  {
    "text": "expose anything at once and as the slash metrics endpoints is provided by your",
    "start": "1146620",
    "end": "1152960"
  },
  {
    "text": "application and your developer decides oh I'm gonna change that metric then you're monitoring guys don't get updated",
    "start": "1152960",
    "end": "1160580"
  },
  {
    "text": "because there's no schema there so their alerts don't trigger anymore they think",
    "start": "1160580",
    "end": "1165800"
  },
  {
    "text": "everything is good but the Deborah developer just changed his metric name so it's it's hard and then we have a lot",
    "start": "1165800",
    "end": "1173179"
  },
  {
    "text": "of metrics so in a typical kubernetes cluster kubernetes cluster would see no",
    "start": "1173179",
    "end": "1178550"
  },
  {
    "text": "Dex for and some of the services being monitored you end up with thousand metrics which is lots to understand so",
    "start": "1178550",
    "end": "1187010"
  },
  {
    "text": "the state of art in monitoring right now I think it's fair to say say it's",
    "start": "1187010",
    "end": "1192620"
  },
  {
    "text": "dashboarding and alerting and the dashboards are created by the subject matter experts which understand their",
    "start": "1192620",
    "end": "1198470"
  },
  {
    "text": "stuff and they create dashboards and do some learning there are no tools like to",
    "start": "1198470",
    "end": "1204260"
  },
  {
    "text": "explore the metadata in metrics and that's what we tried to create and the",
    "start": "1204260",
    "end": "1209510"
  },
  {
    "text": "tools where you start from Jupiter notebooks so here are some examples of these notebooks that's live in github",
    "start": "1209510",
    "end": "1218000"
  },
  {
    "text": "that you can run point it to your data run the notebook again and you get the same results pretty straightforward so",
    "start": "1218000",
    "end": "1228110"
  },
  {
    "text": "looking at the metadata like the labels of your metrics would be the first step like how many metadata is actually there",
    "start": "1228110",
    "end": "1235720"
  },
  {
    "text": "so here's a screenshot of something where we see what is it like the month",
    "start": "1235720",
    "end": "1242540"
  },
  {
    "text": "over five months we see the unique labels plotted and you see that it",
    "start": "1242540",
    "end": "1247730"
  },
  {
    "text": "started out with fewer labels and then continues to have a little bit more",
    "start": "1247730",
    "end": "1253370"
  },
  {
    "text": "labels etc here's another way to display the label so you see a clustering few of",
    "start": "1253370",
    "end": "1260210"
  },
  {
    "text": "those we used a technique called ste distributed stochastic neighbourhood encoding which I can barely pronounce oh",
    "start": "1260210",
    "end": "1267920"
  },
  {
    "text": "I mean I practice it a little bit and you're but you don't necessarily need to understand it because there's a notebook",
    "start": "1267920",
    "end": "1273740"
  },
  {
    "text": "you can just run it and you get this nice blot and then you see some smaller classes and you can ask yourself as the",
    "start": "1273740",
    "end": "1281060"
  },
  {
    "text": "monitoring guy why are there some smaller classes of flavors what's what's what's wrong they're looking at anomaly",
    "start": "1281060",
    "end": "1290630"
  },
  {
    "text": "types if we want to define an anomaly in",
    "start": "1290630",
    "end": "1297470"
  },
  {
    "text": "a time series we need to understand the components of the time series so it time",
    "start": "1297470",
    "end": "1302690"
  },
  {
    "text": "series might have a trend so it might go up or down it might have some",
    "start": "1302690",
    "end": "1307880"
  },
  {
    "text": "seasonality like it goes in the morning it fluctuates and then the evening it goes down and it's the",
    "start": "1307880",
    "end": "1315350"
  },
  {
    "text": "same every day and then you do some crazy shopping event and it goes really",
    "start": "1315350",
    "end": "1320450"
  },
  {
    "text": "really high up so that's the seasonality that you could extract from those metrics or it might have an irregularity",
    "start": "1320450",
    "end": "1330529"
  },
  {
    "text": "so there's a sudden spike and basically",
    "start": "1330529",
    "end": "1336200"
  },
  {
    "text": "an anomaly anomaly is something where the time series doesn't look like we",
    "start": "1336200",
    "end": "1343669"
  },
  {
    "text": "expected it to look like so we might look at the seasonality oh that's going",
    "start": "1343669",
    "end": "1349460"
  },
  {
    "text": "up and down but now it just goes down so that would be an anomaly or yeah it",
    "start": "1349460",
    "end": "1354919"
  },
  {
    "text": "could have a seasonal anomaly we looked at the tool called profits from Facebook",
    "start": "1354919",
    "end": "1363940"
  },
  {
    "text": "it's still maintained and it's a pretty pretty nifty Python library soon pointed",
    "start": "1363940",
    "end": "1369590"
  },
  {
    "text": "to your time series the black dots is the actual data and it will project or",
    "start": "1369590",
    "end": "1377539"
  },
  {
    "text": "predict the data how it would look like in the future so it gives you an upper value it gives you gives you a lower",
    "start": "1377539",
    "end": "1384200"
  },
  {
    "text": "value so that's a bound bounded window where your values should should land in",
    "start": "1384200",
    "end": "1391970"
  },
  {
    "text": "and it gives you yeah the actual value where things that should be and it also",
    "start": "1391970",
    "end": "1399730"
  },
  {
    "text": "predicts the trend in the upper picture so in this case it goes up and in the",
    "start": "1399730",
    "end": "1408110"
  },
  {
    "text": "lower picture you see that the daily seasonality of your time series it's",
    "start": "1408110",
    "end": "1414799"
  },
  {
    "text": "just pretty straightforward and pretty easy to use then you could pretty",
    "start": "1414799",
    "end": "1424789"
  },
  {
    "text": "straightforward say oh I'm come looking at my value and compared to the actual value and if it's not the same then I",
    "start": "1424789",
    "end": "1431929"
  },
  {
    "text": "create an alert but I think you don't want to do that because maybe it's just",
    "start": "1431929",
    "end": "1437450"
  },
  {
    "text": "an outlier so we also looked into different ways how to actually determine",
    "start": "1437450",
    "end": "1444590"
  },
  {
    "text": "that it's that it's an and the easiest thing would be an accumulator approach where you just",
    "start": "1444590",
    "end": "1450590"
  },
  {
    "text": "count up a counter if you see such a deviation and you increase the counter",
    "start": "1450590",
    "end": "1457610"
  },
  {
    "text": "and if you don't see it you decrease the counter again but on a higher level so you subtract two and if your counter",
    "start": "1457610",
    "end": "1464960"
  },
  {
    "text": "goes above a certain threshold you would call it the anomaly and here's also some tweaking and playing in game in place",
    "start": "1464960",
    "end": "1475630"
  },
  {
    "text": "all right so let's look at our architecture set up so far we have open shift or the",
    "start": "1475630",
    "end": "1483110"
  },
  {
    "text": "kubernetes cluster we have you at the application we have familiars monitoring your application then we store the data",
    "start": "1483110",
    "end": "1489320"
  },
  {
    "text": "and sell for internals we have a jupiter notebook for the data scientists to play with we have SPARC",
    "start": "1489320",
    "end": "1496820"
  },
  {
    "text": "installs guess it looks a little bit too complicated to do it in half a day and",
    "start": "1496820",
    "end": "1504770"
  },
  {
    "text": "we're in the kubernetes world now it's all a one-liner which you pipe into a bash script and",
    "start": "1504770",
    "end": "1510800"
  },
  {
    "text": "you have a massive set up already so we kind of expect that as well from these",
    "start": "1510800",
    "end": "1517070"
  },
  {
    "text": "tools so you want to play right so we wrapped it into a obviously into a",
    "start": "1517070",
    "end": "1525620"
  },
  {
    "text": "container so the pink is I think yeah the pink box is the thing that you can",
    "start": "1525620",
    "end": "1532520"
  },
  {
    "text": "readily deploy it would have the forecaster profit model there and some",
    "start": "1532520",
    "end": "1537740"
  },
  {
    "text": "other models in there it would store its forecasts in a PBS and then we export",
    "start": "1537740",
    "end": "1543770"
  },
  {
    "text": "the predictions we have the same way",
    "start": "1543770",
    "end": "1549290"
  },
  {
    "text": "that we do our actual monitoring so we just provide an Prometheus endpoint we",
    "start": "1549290",
    "end": "1555740"
  },
  {
    "text": "expose the slash metrics thing for our values so you can hook it right up to",
    "start": "1555740",
    "end": "1560780"
  },
  {
    "text": "your Prometheus instance or another Prometheus instance that scrapes this normally detector it's all up on get up",
    "start": "1560780",
    "end": "1569180"
  },
  {
    "text": "in our AIC OE org it has a taco file so you can build",
    "start": "1569180",
    "end": "1575510"
  },
  {
    "text": "your container yourself it has a openshift built pipeline or it's on Kauai oh so you don't need to even",
    "start": "1575510",
    "end": "1582920"
  },
  {
    "text": "build it you would configure it we are a",
    "start": "1582920",
    "end": "1589150"
  },
  {
    "text": "environment variable pointed to your metric name that you want to do the anomaly detection on and down there are",
    "start": "1589150",
    "end": "1598340"
  },
  {
    "text": "the predictions you can set up some alerting rules to be fired if this and",
    "start": "1598340",
    "end": "1607660"
  },
  {
    "text": "normal is the anomaly set to one and let your monitoring guys look into it so",
    "start": "1607660",
    "end": "1616160"
  },
  {
    "text": "demo time everybody loves demos let me see how I get out of hmm okay so I don't have a",
    "start": "1616160",
    "end": "1630230"
  },
  {
    "text": "mirrored here so I have to so here's my",
    "start": "1630230",
    "end": "1636110"
  },
  {
    "text": "open shift cluster were installed",
    "start": "1636110",
    "end": "1641290"
  },
  {
    "text": "Prometheus and the training part which",
    "start": "1641290",
    "end": "1646910"
  },
  {
    "text": "is doing the anomaly detection and the",
    "start": "1646910",
    "end": "1652600"
  },
  {
    "text": "forecasting yes these slash metrics endpoint that is being exposed by this",
    "start": "1652600",
    "end": "1658220"
  },
  {
    "text": "part and you see here if we zoom in a little bit Wu predicted node load one",
    "start": "1658220",
    "end": "1666080"
  },
  {
    "text": "for year y hat upper okay so that's",
    "start": "1666080",
    "end": "1671420"
  },
  {
    "text": "seems to be our prediction can go to the Prometheus UI and it has this nice nice",
    "start": "1671420",
    "end": "1685370"
  },
  {
    "text": "graph but that's just a bad UI for doing some initial explorations so you want to",
    "start": "1685370",
    "end": "1693440"
  },
  {
    "text": "have a craft Hana dashboards where you actually can visualize it so also the graph on the dashboard is also something",
    "start": "1693440",
    "end": "1699500"
  },
  {
    "text": "that comes with this deployment so here on the upper graph we see the prophet's",
    "start": "1699500",
    "end": "1707990"
  },
  {
    "text": "model how it predicts the upper and the lower bound and the actual value",
    "start": "1707990",
    "end": "1713660"
  },
  {
    "text": "the load of one of those of the pots no of the note in this cluster I see it's",
    "start": "1713660",
    "end": "1721940"
  },
  {
    "text": "going up and down pretty nicely and it also retrains them all so these points",
    "start": "1721940",
    "end": "1727010"
  },
  {
    "text": "years when we retrain the model because it needs to look back so you might have",
    "start": "1727010",
    "end": "1734630"
  },
  {
    "text": "a online training model which adjusts like online all the time on incoming",
    "start": "1734630",
    "end": "1740090"
  },
  {
    "text": "data prophet doesn't work that way but it needs to look back and then does its computation etc and the red line is the",
    "start": "1740090",
    "end": "1748100"
  },
  {
    "text": "yeah I said it's the actual loads and here we have a spike which seems to be",
    "start": "1748100",
    "end": "1753400"
  },
  {
    "text": "weird let's see that's another prediction by Fourier analysis Fourier",
    "start": "1753400",
    "end": "1758750"
  },
  {
    "text": "analysis is much better at prediction action predicting actual time seriousness you can see it as the blue",
    "start": "1758750",
    "end": "1767330"
  },
  {
    "text": "lines match up quite nicely with the actual value unless not here so there",
    "start": "1767330",
    "end": "1775940"
  },
  {
    "text": "seems to be something wrong",
    "start": "1775940",
    "end": "1779049"
  },
  {
    "text": "unfortunately prophets didn't detect this so the anomaly detector inside for",
    "start": "1781300",
    "end": "1786860"
  },
  {
    "text": "prophets they didn't detect it as an anomaly and I would need to look close so maybe I need to adjust some",
    "start": "1786860",
    "end": "1792740"
  },
  {
    "text": "thresholds there but for real detected as an anomaly which is good so this",
    "start": "1792740",
    "end": "1803570"
  },
  {
    "text": "setup you would get just with a deployment channel for your kubernetes",
    "start": "1803570",
    "end": "1808880"
  },
  {
    "text": "cluster and you can play with it maybe no load one it's not the best thing to play with but you would work with some",
    "start": "1808880",
    "end": "1816230"
  },
  {
    "text": "of your application developers or you look at projected disk usage or CPU",
    "start": "1816230",
    "end": "1823190"
  },
  {
    "text": "usage pick something that you are familiar with and start playing I think that's the lesson learned and here just",
    "start": "1823190",
    "end": "1830780"
  },
  {
    "text": "to show off the nice cool thing that's the open data website let's go back to",
    "start": "1830780",
    "end": "1839450"
  },
  {
    "text": "the presentation go into and I'll go into full screen again",
    "start": "1839450",
    "end": "1846610"
  },
  {
    "text": "so we made pig head happy he likes what yeah and he can go away so here's the",
    "start": "1853300",
    "end": "1859830"
  },
  {
    "text": "picture with all the links to those notebooks etc and as you are all",
    "start": "1859830",
    "end": "1866560"
  },
  {
    "text": "pointing the camera to me may I also point the camera to you and make a nice",
    "start": "1866560",
    "end": "1872950"
  },
  {
    "text": "selfie for the folks at home everybody cheer you like the talk yes alright",
    "start": "1872950",
    "end": "1884549"
  },
  {
    "text": "that's it question time let's back up starts I have five minutes for questions which is",
    "start": "1884760",
    "end": "1892000"
  },
  {
    "text": "great so are you still using your custom",
    "start": "1892000",
    "end": "1902830"
  },
  {
    "text": "storage or or is this now just calling the tonneaus query layer to do all of its computation we're now using so we're",
    "start": "1902830",
    "end": "1910600"
  },
  {
    "text": "applying that to an actual internal team the top team which deployed a craft",
    "start": "1910600",
    "end": "1916330"
  },
  {
    "text": "database and they don't know how to operate it because it's there's no no",
    "start": "1916330",
    "end": "1922660"
  },
  {
    "text": "kubernetes deployment there so it's exposing some metrics but they don't want to create alerts for it and we",
    "start": "1922660",
    "end": "1929470"
  },
  {
    "text": "store it in our ton of spec ends because we have all our Prometheus instances set",
    "start": "1929470",
    "end": "1935290"
  },
  {
    "text": "up with tano's as a sidecar so it automatically stores at long-term and we",
    "start": "1935290",
    "end": "1942070"
  },
  {
    "text": "also have a Python library that can query eight honest or Prometheus",
    "start": "1942070",
    "end": "1947320"
  },
  {
    "text": "back-end for the data scientists with some notebooks so that they can just",
    "start": "1947320",
    "end": "1952750"
  },
  {
    "text": "create a panda's data frame out of the Prometheus or channels set up just by",
    "start": "1952750",
    "end": "1959170"
  },
  {
    "text": "some two lines of Python so that's that's our internal set up it's pretty",
    "start": "1959170",
    "end": "1965530"
  },
  {
    "text": "straightforward yeah",
    "start": "1965530",
    "end": "1971250"
  },
  {
    "text": "on this thanks a lot for sharing and I do have a quick question is that from a",
    "start": "1975880",
    "end": "1982970"
  },
  {
    "text": "monitoring system that sometimes when we have a normal like we have like two",
    "start": "1982970",
    "end": "1989000"
  },
  {
    "text": "hours we're crazy and system goes very high how do you just to rule out these abnormal because after these like two",
    "start": "1989000",
    "end": "1997070"
  },
  {
    "text": "hours period of normal and this part of dirty data we call it was just a fad to",
    "start": "1997070",
    "end": "2002560"
  },
  {
    "text": "the predict of next data points how do you just rule out in a real-time system",
    "start": "2002560",
    "end": "2008370"
  },
  {
    "text": "yeah so if you have two hours that are where the system is crazy yeah and you",
    "start": "2008370",
    "end": "2014560"
  },
  {
    "text": "expect it to be crazy because you know that your users always check the website",
    "start": "2014560",
    "end": "2020440"
  },
  {
    "text": "after they come from lunch then the model would see it because your training",
    "start": "2020440",
    "end": "2025870"
  },
  {
    "text": "train it on a month worth of data or a year worth of data they the model would",
    "start": "2025870",
    "end": "2031410"
  },
  {
    "text": "expect it as a normal behavior so it",
    "start": "2031410",
    "end": "2036430"
  },
  {
    "text": "wouldn't trigger an alert if you're saying that it's not normal in these two hours then I hope the model would fire",
    "start": "2036430",
    "end": "2043510"
  },
  {
    "text": "an alert and if you the behavior of your folks change and they don't check the",
    "start": "2043510",
    "end": "2050050"
  },
  {
    "text": "website after they are coming from lunch then you need to either retrain the",
    "start": "2050050",
    "end": "2056200"
  },
  {
    "text": "model which is done here on an hourly basis but you might want to configure it to a larger timeframe obviously yeah",
    "start": "2056200",
    "end": "2065408"
  },
  {
    "text": "your modeler just we haven't looked into online training so that's that's something that we don't do yet in this",
    "start": "2065409",
    "end": "2073480"
  },
  {
    "text": "set up we have another prototype called the Flatliners also on that organization",
    "start": "2073480",
    "end": "2079628"
  },
  {
    "text": "which uses reactive X then the Python framework which does some online",
    "start": "2079629",
    "end": "2085710"
  },
  {
    "text": "computation but I wouldn't call it AI and machine learning it's just some",
    "start": "2085710",
    "end": "2091210"
  },
  {
    "text": "statistical analysis so far but there's a set up to do streaming data analysis",
    "start": "2091210",
    "end": "2097660"
  },
  {
    "text": "with Prometheus data",
    "start": "2097660",
    "end": "2100770"
  },
  {
    "text": "the mic is coming I am what issues if",
    "start": "2105380",
    "end": "2111540"
  },
  {
    "text": "any did you have with Prometheus monitoring what what are the challenges",
    "start": "2111540",
    "end": "2116790"
  },
  {
    "text": "what were the challenges so the the first challenge was to get data out of",
    "start": "2116790",
    "end": "2123060"
  },
  {
    "text": "Prometheus but I think that's solved now for our set up but he will face the same",
    "start": "2123060",
    "end": "2129089"
  },
  {
    "text": "challenge in your setup because giving a sight card to your Prometheus to the",
    "start": "2129089",
    "end": "2135960"
  },
  {
    "text": "monitoring guys is something that they would have objected to and you need to store your data somewhere and then the",
    "start": "2135960",
    "end": "2144270"
  },
  {
    "text": "other challenge is definitely understanding the problem domain understanding the nature of Prometheus",
    "start": "2144270",
    "end": "2151290"
  },
  {
    "text": "because it's another it's another thing to learn for a data scientist so that",
    "start": "2151290",
    "end": "2157530"
  },
  {
    "text": "took a lot of time understanding from ql and then also getting the buy-in from",
    "start": "2157530",
    "end": "2164550"
  },
  {
    "text": "the subject matter experts because they think they have their monitoring under",
    "start": "2164550",
    "end": "2170339"
  },
  {
    "text": "control and i think to certainly create a habit under control but actually convincing them that what we do can",
    "start": "2170339",
    "end": "2177510"
  },
  {
    "text": "provide some value to them it's also not so straightforward so we're still",
    "start": "2177510",
    "end": "2182640"
  },
  {
    "text": "struggling internally finding stakeholders and finding users of this",
    "start": "2182640",
    "end": "2189349"
  },
  {
    "text": "this stuff that we're building but then we're in the center of in the CTO office so that's what we're used to and always",
    "start": "2189349",
    "end": "2196500"
  },
  {
    "text": "meeting edge and that's what we like thank you just a so the the way you got",
    "start": "2196500",
    "end": "2204869"
  },
  {
    "text": "data out of it is there's a Panos provide syncs - tano's is just stop",
    "start": "2204869",
    "end": "2216750"
  },
  {
    "text": "storing the data away so it takes Prometheus flop time series puts it into",
    "start": "2216750",
    "end": "2222089"
  },
  {
    "text": "s3 or safe sources they're done and then you query tano's and knots Prometheus",
    "start": "2222089",
    "end": "2229580"
  },
  {
    "text": "over all those flops in the s3 bucket okay",
    "start": "2229580",
    "end": "2235080"
  },
  {
    "text": "okay I'm timed out sorry guys if you have questions come here or I'll",
    "start": "2235080",
    "end": "2240780"
  },
  {
    "text": "probably be at the reddit booth [Applause]",
    "start": "2240780",
    "end": "2250099"
  }
]
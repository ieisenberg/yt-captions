[
  {
    "text": "hey everyone uh welcome to the session on unleashing the power of cluster API extensibility and",
    "start": "680",
    "end": "7880"
  },
  {
    "text": "customization uh my name is nibir and I'm here with my colleague Zayn both of us work for a company called uh City",
    "start": "7880",
    "end": "14200"
  },
  {
    "text": "storage systems we're headquartered in Los Angeles California um we're a company that",
    "start": "14200",
    "end": "19800"
  },
  {
    "text": "focuses on improving the experience of food preparation delivery um and like restaurant",
    "start": "19800",
    "end": "26240"
  },
  {
    "text": "Technologies uh we have a whole Suite of businesses starting from Ghost kitchen to restaurant POS systems all the way to",
    "start": "26240",
    "end": "33280"
  },
  {
    "text": "uh food preparation robots actually uh so a lot of these uh lot of interesting challenges a lot of interesting problems",
    "start": "33280",
    "end": "39200"
  },
  {
    "text": "that we solve um both Zay and I are part of the core infrastructure division uh and What Makes Us unique is that we we",
    "start": "39200",
    "end": "47600"
  },
  {
    "text": "use kubernetes but we run our entire software stack on kubernetes so uh we",
    "start": "47600",
    "end": "53160"
  },
  {
    "text": "heavily rely on man uh self-managed software Solutions instead of like managed offerings uh so we run like all",
    "start": "53160",
    "end": "59519"
  },
  {
    "text": "of these stuff like oilp databases our Data Warehouse Systems observability Solutions um and also all of our",
    "start": "59519",
    "end": "66080"
  },
  {
    "text": "microservices Etc on kubernetes um we primarily run large",
    "start": "66080",
    "end": "71640"
  },
  {
    "text": "multi-tenant clusters um some of these clusters could have as many as like 1500",
    "start": "71640",
    "end": "77520"
  },
  {
    "text": "nodes um and some of these clusters also have workloads uh where we could have up to 10,000",
    "start": "77520",
    "end": "83799"
  },
  {
    "text": "pods um right now we're operating a little over 100 clusters in total that",
    "start": "83799",
    "end": "89439"
  },
  {
    "text": "number Chang changes based on uh various things like what kind of issues we're experiencing uh some business needs yada",
    "start": "89439",
    "end": "96560"
  },
  {
    "text": "yada we do have a multi-region active topology so we're running in three different regions uh active with like an",
    "start": "96560",
    "end": "102680"
  },
  {
    "text": "active mesh between all of them uh and for kubernetes we uh only",
    "start": "102680",
    "end": "108560"
  },
  {
    "text": "use managed kubernetes uh So currently our most of our clusters are running on",
    "start": "108560",
    "end": "113759"
  },
  {
    "text": "AKs we have some smaller footprint on few other Cloud providers like gke Etc",
    "start": "113759",
    "end": "119399"
  },
  {
    "text": "as well um and like one of our key principles of operating infrastructure is no human in",
    "start": "119399",
    "end": "125240"
  },
  {
    "text": "the loop operations so throughout this talk you'll hear us hear a lot about like how we evolve our operations we're",
    "start": "125240",
    "end": "130920"
  },
  {
    "text": "constantly optimizing it to eliminate any kind of like manual operations or",
    "start": "130920",
    "end": "136000"
  },
  {
    "text": "things that require human intervention and it kind of allows us to operate um our entire infrastructure at scale uh",
    "start": "136000",
    "end": "143480"
  },
  {
    "text": "efficiently without any kind of like operational overhead cluster API so how how many of",
    "start": "143480",
    "end": "150200"
  },
  {
    "text": "you raise your hands if you've used cluster API or heard about it a lot of people so uh given our scale",
    "start": "150200",
    "end": "158280"
  },
  {
    "text": "um we actually really like cluster API we we use cluster API to operate uh and",
    "start": "158280",
    "end": "163879"
  },
  {
    "text": "manage all of our kubernetes clusters um and for those of you who are not aware of it uh cluster API is like a universal",
    "start": "163879",
    "end": "170879"
  },
  {
    "text": "API for managing kubernetes clusters across all Cloud providers bare metal",
    "start": "170879",
    "end": "176040"
  },
  {
    "text": "and so on uh we like it for various different reasons like it's um declarative um the API uses Uh custom",
    "start": "176040",
    "end": "184480"
  },
  {
    "text": "resources and uh uses kubernetes operator patterns so we like it because we can represent",
    "start": "184480",
    "end": "189760"
  },
  {
    "text": "infrastructure um as like uh kubernetes objects um we like that it allows us to",
    "start": "189760",
    "end": "196159"
  },
  {
    "text": "uniformly it allows us to have uniform operations across all of our Cloud providers and all of their clusters uh",
    "start": "196159",
    "end": "202280"
  },
  {
    "text": "we definitely like the extensibility part of it uh as with any operators and custom resources you can always",
    "start": "202280",
    "end": "208280"
  },
  {
    "text": "Implement additional customer resources and operators on top of them to encapsulate any kind of uh business",
    "start": "208280",
    "end": "215000"
  },
  {
    "text": "specific needs that you might have uh and like all of these things summed up allows us to scale um to hundreds of",
    "start": "215000",
    "end": "221519"
  },
  {
    "text": "clusters we operate and allows us to keep like the operational overhead pretty",
    "start": "221519",
    "end": "227000"
  },
  {
    "text": "minimum so uh we started looking at the cluster API about 3 years ago um at that",
    "start": "227000",
    "end": "232959"
  },
  {
    "text": "time we were migrating from uh one cloud provider to a new one we're using GK in",
    "start": "232959",
    "end": "239560"
  },
  {
    "text": "the ially and then we were migrating to AKs uh at the same time we're also experiencing like explosive business",
    "start": "239560",
    "end": "245280"
  },
  {
    "text": "growth where we went from like 10 plus clusters to 100 plus clusters very",
    "start": "245280",
    "end": "251439"
  },
  {
    "text": "quickly um at at that time the cluster API provider for AKs wasn't ready for",
    "start": "251439",
    "end": "257239"
  },
  {
    "text": "General use and we actually collaborated quite a bit with the open source Community contributed a lot of features",
    "start": "257239",
    "end": "264120"
  },
  {
    "text": "that allowed us to get it to a state where we could use it for our production use case um and and since then like once",
    "start": "264120",
    "end": "271400"
  },
  {
    "text": "it was ready like we we were able to use like cluster API and a provider for AKs",
    "start": "271400",
    "end": "276880"
  },
  {
    "text": "uh it's called CAP z um out of the box allows us to spin up clusters in as little as like a couple of hours uh so",
    "start": "276880",
    "end": "284240"
  },
  {
    "text": "we're pretty happy with our experience cluster API does a job for us uh we've been using it happily for last three",
    "start": "284240",
    "end": "291600"
  },
  {
    "text": "years so we just said cluster API is perfect right like but that was not the",
    "start": "294639",
    "end": "299759"
  },
  {
    "text": "case for us actually like so let's talk about like few issues uh we encounter in the online production of course and like",
    "start": "299759",
    "end": "308240"
  },
  {
    "text": "this is the I will only discuss one issue today because it's important to discuss the story of our journey of adopting cluster API I call it the ghost",
    "start": "308240",
    "end": "314360"
  },
  {
    "text": "in the machine so what was happening with us like after running cluster API in production nodes starting",
    "start": "314360",
    "end": "320199"
  },
  {
    "text": "disappearing and I'm not talking about a graceful cordon and drain kind of operation I'm talking about direct",
    "start": "320199",
    "end": "326960"
  },
  {
    "text": "deletes I think anyone who is running kubernetes in production know like when the node is deleted this is not really",
    "start": "326960",
    "end": "332919"
  },
  {
    "text": "like anything that we want to sympathize or we want to be in that and those abrupt dations would cause like",
    "start": "332919",
    "end": "339400"
  },
  {
    "text": "significant concern in our Productions and just to finish the",
    "start": "339400",
    "end": "344840"
  },
  {
    "text": "impact of that bug like one day 60% of our notes in Productions were deleted at",
    "start": "344840",
    "end": "350600"
  },
  {
    "text": "the same time so let's let's take a look we will explore the Journey of like the beauty",
    "start": "350600",
    "end": "355880"
  },
  {
    "text": "of distributed systems and how we discover issues so the issue was basically root cause to",
    "start": "355880",
    "end": "362440"
  },
  {
    "text": "the kubernetes uh node provider id so all kubernetes nodes by default they",
    "start": "362440",
    "end": "368160"
  },
  {
    "text": "have in their spec a provider id field the provider id field is used to uniquely identify the node globally so",
    "start": "368160",
    "end": "376479"
  },
  {
    "text": "basically I'm using example of aure VM instance so it will have its subscription Resource Group virtual",
    "start": "376479",
    "end": "383080"
  },
  {
    "text": "machine scill set and the instance ID also but for some reason cluster API was",
    "start": "383080",
    "end": "390800"
  },
  {
    "text": "not uniquely identifying those things so something was happening going wrong so let's take a look in the code Snippets",
    "start": "390800",
    "end": "397280"
  },
  {
    "text": "that we discovered so what we found like how",
    "start": "397280",
    "end": "402440"
  },
  {
    "text": "capsi was providing the ID of the cluster was taking the last slash of the",
    "start": "402440",
    "end": "409080"
  },
  {
    "text": "string and just taking it as an ID so that means like in this string zero is the ID across all machine pools so all",
    "start": "409080",
    "end": "416800"
  },
  {
    "text": "we need to do is like just have another virtual machine skill set with the ID",
    "start": "416800",
    "end": "422280"
  },
  {
    "text": "zero and that will be misidentified with the same node that was like one of the",
    "start": "422280",
    "end": "427360"
  },
  {
    "text": "key factor in our issues that means like uh when the nodes are misidentified they",
    "start": "427360",
    "end": "433879"
  },
  {
    "text": "can be deleted abruptly but to add to the injury this risk conditions was only",
    "start": "433879",
    "end": "440680"
  },
  {
    "text": "triggered when we were scaling down so when we were migrating to our Aur all we were doing were scaling up scaling up",
    "start": "440680",
    "end": "447360"
  },
  {
    "text": "till we reach our maximum capacity and we were stable and the day then automatic scale down happened like 60%",
    "start": "447360",
    "end": "454319"
  },
  {
    "text": "of our nodes were gone so just to summarize the problem",
    "start": "454319",
    "end": "459639"
  },
  {
    "text": "was the the capsi using the instance ID the and it was which was not unique",
    "start": "459639",
    "end": "464840"
  },
  {
    "text": "across uh machine pools and that was leading to like a significant cluster",
    "start": "464840",
    "end": "470560"
  },
  {
    "text": "instability and uh causing significant pain for us in the production to solve",
    "start": "470560",
    "end": "477000"
  },
  {
    "text": "these issues uh I will say like we need to give kudos to the maintainers of the Capi like uh all of that I explained was",
    "start": "477000",
    "end": "484560"
  },
  {
    "text": "discovered in a 30- minute Zoom call a PR was landed and hot fix was released so we came out of that like very quickly",
    "start": "484560",
    "end": "492039"
  },
  {
    "text": "this was not an issue that was open for weeks or months to say this was just",
    "start": "492039",
    "end": "497240"
  },
  {
    "text": "solved in minutes so that was that was great now like now we can say like this",
    "start": "497240",
    "end": "503280"
  },
  {
    "text": "was the only issue we will say we encounter with cluster apine Productions other than that in our last three years",
    "start": "503280",
    "end": "509520"
  },
  {
    "text": "we have not encountered any big issue that would cause um outages in",
    "start": "509520",
    "end": "516518"
  },
  {
    "text": "production but now with all this bug fixed and uh we are running smoothly",
    "start": "516519",
    "end": "521839"
  },
  {
    "text": "again uh we were not finished because we were just still doing a lot of manual operations with the cluster API present",
    "start": "521839",
    "end": "528320"
  },
  {
    "text": "there and our job was not done till we quit babysitting like this manual",
    "start": "528320",
    "end": "534560"
  },
  {
    "text": "operations now I will give few example of the manual operation that we're doing and what was causing that and also how",
    "start": "534560",
    "end": "541959"
  },
  {
    "text": "that cluster API is defined generically for most of the customers we need to",
    "start": "541959",
    "end": "547320"
  },
  {
    "text": "adopt it to specific business needs so the first problem like to",
    "start": "547320",
    "end": "555519"
  },
  {
    "text": "understand that let's take a look how the AKs does an upgrade of a note pool when AKs is doing a note pool upgrade it",
    "start": "555519",
    "end": "561680"
  },
  {
    "text": "will add a buffer note that buffer Noe is empty it will start draining the",
    "start": "561680",
    "end": "567360"
  },
  {
    "text": "note all the workloads will get evicted till the note is empty and that",
    "start": "567360",
    "end": "572920"
  },
  {
    "text": "new note is then reimaged the old note is reimaged and now after reimaged and",
    "start": "572920",
    "end": "578399"
  },
  {
    "text": "being upgraded becomes a new note new buffer note and this process continues till the whole note pool has been",
    "start": "578399",
    "end": "585320"
  },
  {
    "text": "upgraded but the issue comes when we have certain workloads that are running in a node that won't allow draining so",
    "start": "585320",
    "end": "593519"
  },
  {
    "text": "the whole process will fail it will we will get stuck in the Azure portal or other places you will see the in the",
    "start": "593519",
    "end": "599760"
  },
  {
    "text": "failed state it will tell us about the errors that encountering why in that node some workload is having some issues",
    "start": "599760",
    "end": "606839"
  },
  {
    "text": "and this is not about like misbehaving workloads totally because one of good example is like cnpg post gra operator",
    "start": "606839",
    "end": "615760"
  },
  {
    "text": "which set the post disruption budget to Max available to zero which means like",
    "start": "615760",
    "end": "621399"
  },
  {
    "text": "we cannot drain that the operator itself detects a node is being cordoned where the parts of the post are",
    "start": "621399",
    "end": "629000"
  },
  {
    "text": "running it will start a failover of the replicas active replicas and then later change",
    "start": "629000",
    "end": "635680"
  },
  {
    "text": "the post disruption budget and expect that the node draining continues automatically but that was not the case",
    "start": "635680",
    "end": "641360"
  },
  {
    "text": "for us so we needed a we can find a work around for that so so we need like a",
    "start": "641360",
    "end": "647120"
  },
  {
    "text": "human in the loop who will just continue with that solve all this problem with",
    "start": "647120",
    "end": "652920"
  },
  {
    "text": "the notes that are being stucked one by one looking at it what is causing it and then continue",
    "start": "652920",
    "end": "660319"
  },
  {
    "text": "the second problem this is like another specific problem that we encountered",
    "start": "660440",
    "end": "665680"
  },
  {
    "text": "because of our setup so how I was explaining the not pool upgrades was happening is like it's",
    "start": "665680",
    "end": "672160"
  },
  {
    "text": "designed to think that uh we are using the least allocated schedule or strategy",
    "start": "672160",
    "end": "679200"
  },
  {
    "text": "which means like the new node is empty the buffer node is empty so whenever we are evicting workloads they will all end",
    "start": "679200",
    "end": "686720"
  },
  {
    "text": "up in the empty Noe because that is the least used this is the default kubernets strategy so if I have 10 nodes I'm",
    "start": "686720",
    "end": "693200"
  },
  {
    "text": "scheduling 10 parts all 10 parts will end up in all Distributing in 10 nodes",
    "start": "693200",
    "end": "698800"
  },
  {
    "text": "but we run pretty tight bin packed cluster so we want all our nodes to be",
    "start": "698800",
    "end": "704399"
  },
  {
    "text": "tightly bin packed to do that we use a custom uh schedule of strategy that is",
    "start": "704399",
    "end": "710760"
  },
  {
    "text": "of most allocated which means like it will try to find the nodes which still have some space to try to fill in all",
    "start": "710760",
    "end": "716480"
  },
  {
    "text": "the capacity so when the AKs upgrade is starting we will find those nodes start",
    "start": "716480",
    "end": "722079"
  },
  {
    "text": "filling in and almost always nothing was getting schedule at the buffer note we",
    "start": "722079",
    "end": "728639"
  },
  {
    "text": "were just beenin pagging better our clusters and while we were doing that we were just setting our worklow ready to",
    "start": "728639",
    "end": "735480"
  },
  {
    "text": "be drained again so if we are running a workload and it's going through a node pool upgrade",
    "start": "735480",
    "end": "741639"
  },
  {
    "text": "process it means it will be disrupted multiple times when we are doing this not pool",
    "start": "741639",
    "end": "747480"
  },
  {
    "text": "upgrades now this is a problem which is not very critical but like it does makes",
    "start": "747480",
    "end": "753240"
  },
  {
    "text": "the experience like not really great for the upgrades of course we can add a",
    "start": "753240",
    "end": "758360"
  },
  {
    "text": "human in the loop that human can go and cod on all the rest of the nodes so just",
    "start": "758360",
    "end": "763760"
  },
  {
    "text": "when we are doing these upgrades always the new nodes or buffer nodes that will get the pods and once those pods are",
    "start": "763760",
    "end": "771839"
  },
  {
    "text": "like scheduled on the buffer node we can uncode on the ones this is still a lot of manual operations but just to S say",
    "start": "771839",
    "end": "779320"
  },
  {
    "text": "like we can do like something smoothly let's jump into the next",
    "start": "779320",
    "end": "785199"
  },
  {
    "text": "problem um this is the immutable Fields like so for the context like uh all",
    "start": "785199",
    "end": "791800"
  },
  {
    "text": "these cloud provider when they're offering this managed kubernetes like under the hood they're like offering a",
    "start": "791800",
    "end": "799320"
  },
  {
    "text": "underlying implementation for example in the case of azure it's a node pool is a virtual machine skill set so what we can",
    "start": "799320",
    "end": "806120"
  },
  {
    "text": "do with a node pool in cluster API is basically lied by the limitations of",
    "start": "806120",
    "end": "811519"
  },
  {
    "text": "virtual machine skill set in a virtual machine skill set we cannot change instance type I cannot change from a",
    "start": "811519",
    "end": "817560"
  },
  {
    "text": "regular to spot we have to create a new virtual machine skill set the same applies for if I want to move to a",
    "start": "817560",
    "end": "824000"
  },
  {
    "text": "bigger virtual machine scale sets just because the requirements changed or some",
    "start": "824000",
    "end": "829800"
  },
  {
    "text": "other like U configuration like Max Sport that which are directly related to",
    "start": "829800",
    "end": "834920"
  },
  {
    "text": "the network configuration of the virtual machine scill sets so how many Nicks we are attaching to that VM depends on the",
    "start": "834920",
    "end": "841320"
  },
  {
    "text": "Max Sports configuration that we are doing on the cluster API for that this",
    "start": "841320",
    "end": "846720"
  },
  {
    "text": "again caus like certain kind of like uh uh impediments for us to continue",
    "start": "846720",
    "end": "852880"
  },
  {
    "text": "operating at scale because every time we are doing some kind of changes in the",
    "start": "852880",
    "end": "858040"
  },
  {
    "text": "node pool we will have to do uh encounter like these kind of like uh",
    "start": "858040",
    "end": "863199"
  },
  {
    "text": "immutable Fields issues again we can introduce another human in the loop that human what can do is like create a new",
    "start": "863199",
    "end": "869639"
  },
  {
    "text": "not pool and gratefully delete the old not pool so basic we can continue with this process new note pool is with the",
    "start": "869639",
    "end": "876199"
  },
  {
    "text": "new settings it's a new virtual machine skill set and uh it will just work out",
    "start": "876199",
    "end": "881480"
  },
  {
    "text": "of the box so this problem that I just commented uh are all about like",
    "start": "881480",
    "end": "886959"
  },
  {
    "text": "different problems and they still require human in the loop to continue with the",
    "start": "886959",
    "end": "893000"
  },
  {
    "text": "operations Okay so so I think we all know that any kind of manual operation",
    "start": "897680",
    "end": "903120"
  },
  {
    "text": "or if you have a human Loop process it doesn't scale right so how do we automated um well the good thing is that",
    "start": "903120",
    "end": "910199"
  },
  {
    "text": "we are using cluster API and cluster API is extensible so I think the first idea",
    "start": "910199",
    "end": "916120"
  },
  {
    "text": "we considered was if we use cluster API uh build our own custom provider that",
    "start": "916120",
    "end": "921600"
  },
  {
    "text": "encapsulates all of the B all of the cloud provider logic and our business specific needs uh that could solve our",
    "start": "921600",
    "end": "927720"
  },
  {
    "text": "problem but later we figured out that uh implementing the cloud provider logic is",
    "start": "927720",
    "end": "934560"
  },
  {
    "text": "unnecessary so we decided to start with the foundation of cluster API along with",
    "start": "934560",
    "end": "940040"
  },
  {
    "text": "the cluster API provider for aure capz um and then only Implement a custom",
    "start": "940040",
    "end": "946480"
  },
  {
    "text": "extensions on top of it all of these custom extensions are just like custom resources and controllers that",
    "start": "946480",
    "end": "951759"
  },
  {
    "text": "encapsulate our business specific needs and they extend the existing custom resources that come out of the box from",
    "start": "951759",
    "end": "957800"
  },
  {
    "text": "cluster API and cap C uh so what does that look like so",
    "start": "957800",
    "end": "963600"
  },
  {
    "text": "these are some of the uh custom resources that we use today so at the bottom we have the cluster API ones uh",
    "start": "963600",
    "end": "971160"
  },
  {
    "text": "there's a cluster CR and a machine pool CR the cluster a CR like creates a cluster or represents a cluster and the",
    "start": "971160",
    "end": "978000"
  },
  {
    "text": "Machine pool CR uh is for any node pools that you want to have uh then we layer",
    "start": "978000",
    "end": "983440"
  },
  {
    "text": "it with the cluster API provider operator uh the controllers and that introduces is azure manage cluster Azure",
    "start": "983440",
    "end": "990839"
  },
  {
    "text": "manage control plane CR uh this along with the cluster CR represents the control plane of each kubernetes cluster",
    "start": "990839",
    "end": "996519"
  },
  {
    "text": "in case and then the for node pools we have Azure manage machine pool CR so",
    "start": "996519",
    "end": "1002240"
  },
  {
    "text": "that represents each node pool um and then like what Zan pointed out earlier",
    "start": "1002240",
    "end": "1008120"
  },
  {
    "text": "um the machine pools every time we have to make any change to any of the mutable fields or we're doing like an upgrade or",
    "start": "1008120",
    "end": "1014480"
  },
  {
    "text": "like a uh some kind of like rotation uh to encapsulate the whole process of like recreating we introduce",
    "start": "1014480",
    "end": "1021880"
  },
  {
    "text": "a no node pool CR node pool CR is our one of our custom extensions um and that sits on top of the machine pool uh Azure",
    "start": "1021880",
    "end": "1029319"
  },
  {
    "text": "manage machine pool and the Machine pool CRS so with this new controller and the new custom resource what does what does",
    "start": "1029319",
    "end": "1036240"
  },
  {
    "text": "our operation look like so uh for example we're taking like a life cycle",
    "start": "1036240",
    "end": "1041400"
  },
  {
    "text": "uh not pool change life cycle so be changing the version upgrading a version or just simply changing instance family",
    "start": "1041400",
    "end": "1048919"
  },
  {
    "text": "so we start with a not pool CR um The Box on the left uh so under the hood",
    "start": "1048919",
    "end": "1054919"
  },
  {
    "text": "that represents a machine pool and a machine pool can have multiple nodes running workloads if we change a field if we",
    "start": "1054919",
    "end": "1062280"
  },
  {
    "text": "need to change a field in the node pool what we do is like we modify the not poool CR uh and then the corresponding uh",
    "start": "1062280",
    "end": "1069160"
  },
  {
    "text": "controller then picks up this change what it does is like it creates a new machine pool B with the new settings new",
    "start": "1069160",
    "end": "1076760"
  },
  {
    "text": "configurations or new versions uh it then taints all the nodes in the original machine pool a uh and then",
    "start": "1076760",
    "end": "1084840"
  },
  {
    "text": "drains all the workloads from this machine pool a once that happens it's drained onto the machine pool B uh it",
    "start": "1084840",
    "end": "1091200"
  },
  {
    "text": "deletes the old machine pool a uh so I think the beauty of this process is that",
    "start": "1091200",
    "end": "1097880"
  },
  {
    "text": "from the platform Engineers point of view from our point of view from the operations point of view we're only",
    "start": "1097880",
    "end": "1103559"
  },
  {
    "text": "interacting with the nopool CR so we're making any changes in the nopool CR and under the hood the controller takes care",
    "start": "1103559",
    "end": "1109000"
  },
  {
    "text": "of all the changes be it creating a new note pool be it replacing a note pool or even like in placeplace modifications",
    "start": "1109000",
    "end": "1115200"
  },
  {
    "text": "and also from the workloads point of view the developers that we serve their point of view uh this is a very opaque",
    "start": "1115200",
    "end": "1121880"
  },
  {
    "text": "uh opaque like operation so if you're running with some kind of taint or some kind of Toleration um on on a certain",
    "start": "1121880",
    "end": "1129520"
  },
  {
    "text": "node pool and we need to swap out uh from like spot nodes to regular nodes for example uh we don't have to like go",
    "start": "1129520",
    "end": "1135679"
  },
  {
    "text": "coordinate with the workload owners or we don't have to like disrupt all the workloads at once y y so it's like a",
    "start": "1135679",
    "end": "1143360"
  },
  {
    "text": "essentially this whole process is encapsulated in a very declared of API not CR and the whole process is like",
    "start": "1143360",
    "end": "1150120"
  },
  {
    "text": "programmatically handled so uh here are a few other like",
    "start": "1150120",
    "end": "1155679"
  },
  {
    "text": "extensions we implemented uh so not pool was the one I explained uh we also had",
    "start": "1155679",
    "end": "1161000"
  },
  {
    "text": "additional configurations that we want to tweak on the control plane of AK clusters uh for example we use a very",
    "start": "1161000",
    "end": "1167480"
  },
  {
    "text": "custom um cluster autoscaler profile that also gets configured in a in a",
    "start": "1167480",
    "end": "1173799"
  },
  {
    "text": "separate conf separate custom resource and there's a controller for it that takes care of like applying it to the",
    "start": "1173799",
    "end": "1179440"
  },
  {
    "text": "control plane um and again this this is not exhaustive we keep adding new",
    "start": "1179440",
    "end": "1184880"
  },
  {
    "text": "configurations we keep adding new control uh new controllers and custom resources all the times all the time as",
    "start": "1184880",
    "end": "1190280"
  },
  {
    "text": "our business requirements change um",
    "start": "1190280",
    "end": "1196039"
  },
  {
    "text": "so as the be was explaining we have solved all the problems that I was explaining earlier uh this led to",
    "start": "1200919",
    "end": "1207280"
  },
  {
    "text": "somehow leading to the establishment of a foundational principle that we apply in our own platform engineering and we",
    "start": "1207280",
    "end": "1214159"
  },
  {
    "text": "call it objects democracy what does it means it means like all kubernetes life",
    "start": "1214159",
    "end": "1220280"
  },
  {
    "text": "cycle related operational blocks need to be present as kubernetes objects inside",
    "start": "1220280",
    "end": "1226200"
  },
  {
    "text": "the uh kubernetes itself what as it gives us like it's giving us",
    "start": "1226200",
    "end": "1231520"
  },
  {
    "text": "like the freedom to solve all the problems on our own paas to build a platform that is",
    "start": "1231520",
    "end": "1238039"
  },
  {
    "text": "sustainable it gives also like from the broader point of view a unified",
    "start": "1238039",
    "end": "1243760"
  },
  {
    "text": "management which means like we have a centralized control plane running in a management cluster and which allow us to",
    "start": "1243760",
    "end": "1251400"
  },
  {
    "text": "enable a centralized management of resources configurations and and policies across all clusters",
    "start": "1251400",
    "end": "1259280"
  },
  {
    "text": "the other thing that it gives us like the seamless abstractions like n just explained we have a note pool that we",
    "start": "1259280",
    "end": "1264360"
  },
  {
    "text": "just created which encapsulates machine pools multiple machine pools at the same",
    "start": "1264360",
    "end": "1269720"
  },
  {
    "text": "times but that can get extended to any other abstraction you want which will hide the complexity away from our",
    "start": "1269720",
    "end": "1276400"
  },
  {
    "text": "platform Engineers we who do not need to know the underlying complexities that comes with the uh other resources in",
    "start": "1276400",
    "end": "1284919"
  },
  {
    "text": "this case when we are upgrading not poool they do not need to understand like like what are the limitations of a",
    "start": "1284919",
    "end": "1290240"
  },
  {
    "text": "virtual machine skill set but it also gives us like infinite",
    "start": "1290240",
    "end": "1296159"
  },
  {
    "text": "extensibility which means like we can continue extending for the rapid adoption of the ever evolving changes in",
    "start": "1296159",
    "end": "1302760"
  },
  {
    "text": "the business needs we need to move from a regular to spot nodes we can figure",
    "start": "1302760",
    "end": "1308559"
  },
  {
    "text": "out how to do that and add plugins and other operators and CRS to continue",
    "start": "1308559",
    "end": "1314720"
  },
  {
    "text": "expanding whatever it needs to keep the human out of the loop which take us to like our ultimate goal which is",
    "start": "1314720",
    "end": "1321120"
  },
  {
    "text": "automation Revolution it means like we really do not want any human in the loop",
    "start": "1321120",
    "end": "1327159"
  },
  {
    "text": "we want to automate everything and have autonomous workflows in place which will",
    "start": "1327159",
    "end": "1333880"
  },
  {
    "text": "also Drive the efficiency and reliability of our clusters and above all it what reduced",
    "start": "1333880",
    "end": "1340799"
  },
  {
    "text": "was the errors human introduced errors the as the error minimized by routine",
    "start": "1340799",
    "end": "1346960"
  },
  {
    "text": "talks automatic task of upgrades and other routine things that we were doing so by embracing embracing these like",
    "start": "1346960",
    "end": "1354559"
  },
  {
    "text": "principles of the object democracy we significantly reduced like",
    "start": "1354559",
    "end": "1360120"
  },
  {
    "text": "the reliability issues we were facing and also improved like our",
    "start": "1360120",
    "end": "1366120"
  },
  {
    "text": "infrastructure uh robustness and",
    "start": "1366120",
    "end": "1370400"
  },
  {
    "text": "efficiency okay so I think in summary so what does this all mean uh so over the",
    "start": "1377240",
    "end": "1383279"
  },
  {
    "text": "last few years we've achieved our goal of uh eliminating human Loop processes and kind of achieving this like ultimate",
    "start": "1383279",
    "end": "1389520"
  },
  {
    "text": "Automation in our infrastructure management so this whole principle of object democracy is so beautiful that we",
    "start": "1389520",
    "end": "1395480"
  },
  {
    "text": "actually applied it to all of our infrastructure control plane um so like I said earlier we actually heavily use",
    "start": "1395480",
    "end": "1401440"
  },
  {
    "text": "cncf projects a lot of Open Source stuff to uh that we manage ourselves um so we",
    "start": "1401440",
    "end": "1407600"
  },
  {
    "text": "applied this principle to all of them we represent all of our infrastructure components all of our abstractions and",
    "start": "1407600",
    "end": "1412880"
  },
  {
    "text": "all of the associated operations um using custom resources and controller so",
    "start": "1412880",
    "end": "1418120"
  },
  {
    "text": "right now on our on our platform we have about 130 custom resources uh in the",
    "start": "1418120",
    "end": "1423400"
  },
  {
    "text": "control plane um and like they work pretty seamlessly we can we make",
    "start": "1423400",
    "end": "1428440"
  },
  {
    "text": "modifications pretty frequently as well ultimately like the the The Leverage we",
    "start": "1428440",
    "end": "1434080"
  },
  {
    "text": "gain from applying this principle across our infrastructure Sac is is that we",
    "start": "1434080",
    "end": "1440039"
  },
  {
    "text": "have complete control of end to-end life cycle and this gives us like a lot of power to platform engineers and then uh",
    "start": "1440039",
    "end": "1446799"
  },
  {
    "text": "in the end like it gives us like operational efficiency that we need to scale um so a couple of learnings from",
    "start": "1446799",
    "end": "1454720"
  },
  {
    "text": "our journey adopting cluster API um so one of the few messages that I want to",
    "start": "1454720",
    "end": "1459799"
  },
  {
    "text": "leave you guys with uh the first one is we always prioritize business specific needs so I think us as users of",
    "start": "1459799",
    "end": "1466039"
  },
  {
    "text": "kubernetes us as platform engineers it's very easy to say that uh this is how",
    "start": "1466039",
    "end": "1471399"
  },
  {
    "text": "kubernetes is or this is how it should be used because kubernetes is so easy to use out of the box but I think we should",
    "start": "1471399",
    "end": "1478399"
  },
  {
    "text": "always remember that like our ultimate goal is to serve the business that we have and also to serve the developers",
    "start": "1478399",
    "end": "1484919"
  },
  {
    "text": "that rely upon us so we should always be prioritizing what the business need what are the unique constraints that our",
    "start": "1484919",
    "end": "1491320"
  },
  {
    "text": "developers have uh first adopter risk it's very obvious we were one of the early",
    "start": "1491320",
    "end": "1496720"
  },
  {
    "text": "adopters of cluster API as mentioned one of the ghost in our system bugs um so",
    "start": "1496720",
    "end": "1501799"
  },
  {
    "text": "anytime you adop something new I think it's a good mindset to have to embrace",
    "start": "1501799",
    "end": "1507039"
  },
  {
    "text": "these kinds of hiccups and be ready for those right I mean these happen we we we've been in industry for long enough",
    "start": "1507039",
    "end": "1512760"
  },
  {
    "text": "where we know that uh these kinds of mishaps will happen and just be ready to handle those um and one of the",
    "start": "1512760",
    "end": "1519880"
  },
  {
    "text": "nonexpected results we got by focusing so heavily on automation is automation",
    "start": "1519880",
    "end": "1526039"
  },
  {
    "text": "actually increase our reliability so before we actually moved to Cluster API we had a semi-manual process U of like",
    "start": "1526039",
    "end": "1534120"
  },
  {
    "text": "provisioning and life cycle management for clusters um we saw that like every time we would do like an upgrade kubernetes version upgrade we would have",
    "start": "1534120",
    "end": "1541360"
  },
  {
    "text": "at least one internal incident uh since we switched to Cluster API we've done about four or five version upgrades and",
    "start": "1541360",
    "end": "1547559"
  },
  {
    "text": "we've had absolutely zero uh incidents uh rising from it uh and the last idea I want to leave",
    "start": "1547559",
    "end": "1554880"
  },
  {
    "text": "you guys with is kubernetes is not an end product kubernetes is actually a",
    "start": "1554880",
    "end": "1560000"
  },
  {
    "text": "framework for building platforms and us as platform Engineers it's our job to",
    "start": "1560000",
    "end": "1565279"
  },
  {
    "text": "actually tailor these platforms to what the business needs and kubernetes is so extensible so versatile and all these",
    "start": "1565279",
    "end": "1573039"
  },
  {
    "text": "all these software like cluster API uh so extensible we should definitely be leveraging these principles um to do",
    "start": "1573039",
    "end": "1580640"
  },
  {
    "text": "so uh with that uh I'm going to leave a few links here so uh have QR code to",
    "start": "1580640",
    "end": "1587760"
  },
  {
    "text": "both Z and my LinkedIn profiles if you guys want to reach out to us have any questions have a discussion we're always",
    "start": "1587760",
    "end": "1593520"
  },
  {
    "text": "happy to chat um you can download the slides if you want and we wrote a blog",
    "start": "1593520",
    "end": "1599039"
  },
  {
    "text": "post about this topic where we go into a little more detail if you want to check it out I'll leave it up here for for you",
    "start": "1599039",
    "end": "1605880"
  },
  {
    "text": "guys um and I think we have a few more minutes so if you guys have any questions we'll take a few",
    "start": "1605880",
    "end": "1613760"
  },
  {
    "text": "I don't think uh convenient and one con is that du",
    "start": "1647080",
    "end": "1652760"
  },
  {
    "text": "unit upgrade we will face the uh P node will be upgraded we may have uh new uh",
    "start": "1652760",
    "end": "1660559"
  },
  {
    "text": "Ami like for for AWS we have a new Ami for the uh noes and it will be uh",
    "start": "1660559",
    "end": "1668399"
  },
  {
    "text": "upgraded for the machine pole and may cause P to be uh deleted and uh",
    "start": "1668399",
    "end": "1675600"
  },
  {
    "text": "restarted so so how you handle this situations do I really upgrade I can explain too if you want",
    "start": "1675600",
    "end": "1683440"
  },
  {
    "text": "yeah so I think um there are few details we I think the question was like uh during during a version upgrade for",
    "start": "1683440",
    "end": "1690039"
  },
  {
    "text": "kubernetes using cluster API there could be unexpected disruptions to pod how do you handle those uh so we left out some",
    "start": "1690039",
    "end": "1697640"
  },
  {
    "text": "details from the slides but um so often",
    "start": "1697640",
    "end": "1703919"
  },
  {
    "text": "there are two two principles one is like practicing good hygiene with application configurations so like not allowing po",
    "start": "1703919",
    "end": "1710799"
  },
  {
    "text": "disruption budget Max unavailable zero for example or uh things like safe to",
    "start": "1710799",
    "end": "1716919"
  },
  {
    "text": "evict false yatas so and that's sometimes hard to achieve as well so we actually have controllers in place where",
    "start": "1716919",
    "end": "1723919"
  },
  {
    "text": "um we allow workloads to plug into like a graceful shutdown uh pre-web hook and",
    "start": "1723919",
    "end": "1730760"
  },
  {
    "text": "what it does is like it calls some kind of application state allows the application shut down before there's like a eviction call uh",
    "start": "1730760",
    "end": "1740039"
  },
  {
    "text": "so we we allow our applications to like configure this like however they want to it's like very um it's it's extremely",
    "start": "1742760",
    "end": "1749720"
  },
  {
    "text": "configurable like it's like extremely flexible and it plugs into like the eviction object that kubernetes",
    "start": "1749720",
    "end": "1757080"
  },
  {
    "text": "creates thank you uh I have a question can you please tell some how you deploy",
    "start": "1761840",
    "end": "1768200"
  },
  {
    "text": "is manifests or custom resources to uh production you use Helm charts maybe uh",
    "start": "1768200",
    "end": "1775039"
  },
  {
    "text": "how you store it maybe use terraform above it to store State and so on thank",
    "start": "1775039",
    "end": "1781200"
  },
  {
    "text": "you yeah so I think um for for applications we use Helm charts extensively um so we have a",
    "start": "1781200",
    "end": "1787880"
  },
  {
    "text": "microservices architecture uh over a th microservices at this point uh so they're all Helm charts uh Sor in git we",
    "start": "1787880",
    "end": "1796039"
  },
  {
    "text": "our application delivery pipeline uses get Ops uh so it's delivered from uh from repositories so all changes are",
    "start": "1796039",
    "end": "1802720"
  },
  {
    "text": "initiated uh in git and then are deployed using RCI systems um and then",
    "start": "1802720",
    "end": "1808440"
  },
  {
    "text": "we apply the same principles for all the custom resources that we have to manage infrastructure as well so applications",
    "start": "1808440",
    "end": "1815279"
  },
  {
    "text": "infrastructure everything goes through the same C pipelines uh everything is configured and help",
    "start": "1815279",
    "end": "1822880"
  },
  {
    "text": "okay uh if you guys have any other questions reach out to us we're always happy to chat and thanks for listening to us",
    "start": "1831720",
    "end": "1837670"
  },
  {
    "text": "[Applause]",
    "start": "1837670",
    "end": "1841579"
  }
]
[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "hello everybody good morning my name is Tom I'm just hosting such doing a quick introduction for Rob hopefully",
    "start": "0",
    "end": "6120"
  },
  {
    "text": "everyone's in the right room there's been a few room swaps so if you're not here to talk about m3 I'm from atheists you're probably looking for app dev",
    "start": "6120",
    "end": "12420"
  },
  {
    "text": "which I have no idea where it is nobody's leaving so we'll get on with it so today we're going to hear from Rob",
    "start": "12420",
    "end": "18570"
  },
  {
    "text": "about m3 and Prometheus I was on the program committee and was super keen on this talk mainly mean I'm one of the",
    "start": "18570",
    "end": "24750"
  },
  {
    "text": "Prometheus developers but I also develop a competing system - m3 and I really want to hear about how they've solved",
    "start": "24750",
    "end": "30179"
  },
  {
    "text": "some of the same problems we've had to solve so you're a round of applause for Rob thanks Tom so yes this talk is",
    "start": "30179",
    "end": "44010"
  },
  {
    "start": "40000",
    "end": "293000"
  },
  {
    "text": "called interim prometheus monitoring at planet scale for everyone and other than",
    "start": "44010",
    "end": "49559"
  },
  {
    "text": "that clickbait title that I'm gonna talk a little bit about being wondering and increasing number of",
    "start": "49559",
    "end": "56129"
  },
  {
    "text": "things so yeah there's a few people in this space and technology products now",
    "start": "56129",
    "end": "61440"
  },
  {
    "text": "as Tom kind of mentioned metrics is being used as a platform more than ever it's becoming really a foundational",
    "start": "61440",
    "end": "68760"
  },
  {
    "text": "building block similar to how databases of applications for products metrics are",
    "start": "68760",
    "end": "75900"
  },
  {
    "text": "being essentially a building block for building reliable systems of scale and",
    "start": "75900",
    "end": "80909"
  },
  {
    "text": "delivering high level levels of service quality and it's also you know being",
    "start": "80909",
    "end": "86580"
  },
  {
    "text": "used for order remediation or to rollback it's being used for what are balancing",
    "start": "86580",
    "end": "92610"
  },
  {
    "text": "stateful systems it's it's becoming pretty prevalent and like if you look",
    "start": "92610",
    "end": "99119"
  },
  {
    "text": "back you know five to ten years I think logging was which I'm a far more popular than the metrics and that probably still",
    "start": "99119",
    "end": "105570"
  },
  {
    "text": "is the case but metrics now has a pretty strong foothold in the in observability",
    "start": "105570",
    "end": "110750"
  },
  {
    "text": "so you know I also want to talk a little bit about operating in in many different regions many different environments that",
    "start": "110750",
    "end": "120210"
  },
  {
    "text": "that's becoming increasingly more common these days especially a because it's easier to do with the cloud and B",
    "start": "120210",
    "end": "126930"
  },
  {
    "text": "because a lot of it makes a lot of sense for a loved businesses and of course you know that",
    "start": "126930",
    "end": "133650"
  },
  {
    "text": "the forth talk itself is going to focus on n3 and Prometheus so Who am I",
    "start": "133650",
    "end": "139200"
  },
  {
    "text": "an Australian monitoring node so self-proclaimed of course and I've",
    "start": "139200",
    "end": "144590"
  },
  {
    "text": "commonly found that I'm drowning my friends with pictures of my kid so I thought I'd do the same here also the",
    "start": "144590",
    "end": "152760"
  },
  {
    "text": "yet creator of n3 B which is an open source time series database and that is",
    "start": "152760",
    "end": "158670"
  },
  {
    "text": "essentially the footlight the underpinnings of m3 which is an open source monitoring system built in uber",
    "start": "158670",
    "end": "165960"
  },
  {
    "text": "which I've been working on for about 3 plus years now and I'm a member of open metrics where a CNC F committee that's",
    "start": "165960",
    "end": "173040"
  },
  {
    "text": "trying to standardize and metrics exposition format so that a lot more of",
    "start": "173040",
    "end": "178260"
  },
  {
    "text": "these systems that are being built in the community can talk to each other basically natively using a shared kind",
    "start": "178260",
    "end": "184110"
  },
  {
    "text": "of standard so Prometheus just as a reminder this is the first talk of the",
    "start": "184110",
    "end": "189480"
  },
  {
    "text": "day and I've ever told about m3 which is a much solving different things",
    "start": "189480",
    "end": "195570"
  },
  {
    "text": "Prometheus is is what most organizations will reach for and should reach for when",
    "start": "195570",
    "end": "201209"
  },
  {
    "text": "they begin wanting to monitor their their stack and then starting to build",
    "start": "201209",
    "end": "207690"
  },
  {
    "text": "alerting and other kind of order monitoring systems that they're at their",
    "start": "207690",
    "end": "214980"
  },
  {
    "text": "companies and organisations it's an all-in-one industry standard solution essentially will both discover and",
    "start": "214980",
    "end": "222060"
  },
  {
    "text": "ingest and allow you to store and query metrics and you can think of it similar",
    "start": "222060",
    "end": "227700"
  },
  {
    "text": "to to kind of like my C colon that it's very much built to be rock-solid and run",
    "start": "227700",
    "end": "233700"
  },
  {
    "text": "on a single node and you can set up different types of deployments of it but that's primarily the space that it's",
    "start": "233700",
    "end": "240750"
  },
  {
    "text": "trying to solve so you know as a reminder kubernetes looks a little bit",
    "start": "240750",
    "end": "246390"
  },
  {
    "text": "like this in most people's lives so essentially you know you have a previous instance maybe it's in a single",
    "start": "246390",
    "end": "252810"
  },
  {
    "text": "region it's usually of course the single promethease instance can only be in a single availability zone because it's a",
    "start": "252810",
    "end": "259470"
  },
  {
    "text": "single since itself and it basically monitors your application as it runs on say",
    "start": "259470",
    "end": "265640"
  },
  {
    "text": "kubernetes or an AC to the ec2 Amazon platform or GCE so basically the richer",
    "start": "265640",
    "end": "273620"
  },
  {
    "text": "service discovery layer allows it to kind of understand how and where your",
    "start": "273620",
    "end": "279110"
  },
  {
    "text": "application is running very easily and basically discover and collect those those metrics make them accessible to",
    "start": "279110",
    "end": "285770"
  },
  {
    "text": "you for visualization using profiler and also you know using alert manager or",
    "start": "285770",
    "end": "291680"
  },
  {
    "text": "some other alerting engine so m3 what is that that is it's a project from uber it",
    "start": "291680",
    "end": "298550"
  },
  {
    "start": "293000",
    "end": "498000"
  },
  {
    "text": "was began in early 2015 so kind of six nine months or so officer Prometheus",
    "start": "298550",
    "end": "304880"
  },
  {
    "text": "itself and it was built primarily to scale monitoring horizontally so it was",
    "start": "304880",
    "end": "310370"
  },
  {
    "text": "kind of orthogonal at least in the early days of what I was trying to do and and pretty much still is again about",
    "start": "310370",
    "end": "316550"
  },
  {
    "text": "prometheus is what every organization should reach for first before any of these other systems because it sells so",
    "start": "316550",
    "end": "323360"
  },
  {
    "text": "many of your your problems issues and is interoperable with everything out there",
    "start": "323360",
    "end": "328490"
  },
  {
    "text": "from day one and most people don't have that many metrics so even running to Prometheus instances will serve a whole",
    "start": "328490",
    "end": "334430"
  },
  {
    "text": "bunch of organizations just fine but m3 for those that it doesn't solve you know",
    "start": "334430",
    "end": "340130"
  },
  {
    "text": "that that setup doesn't solve so well is essentially yes built to scale your",
    "start": "340130",
    "end": "345170"
  },
  {
    "text": "monitoring horizontally and in a very cost-effective nature so that's one thing that from day one has been very",
    "start": "345170",
    "end": "351230"
  },
  {
    "text": "very important for uber some organizations it's very easy for it to happen it happened to us it happened to",
    "start": "351230",
    "end": "357920"
  },
  {
    "text": "Netflix they haven't tons of other companies you're monitoring and observability platform especially when",
    "start": "357920",
    "end": "365030"
  },
  {
    "text": "engineers start to instrument absolutely everything they possibly can begins to be a large part of your cloud",
    "start": "365030",
    "end": "371890"
  },
  {
    "text": "footprint essentially it ends up costing you a lot so rubriz being able to push",
    "start": "371890",
    "end": "377240"
  },
  {
    "text": "you know that percent of spend of your entire stack for monitoring down to",
    "start": "377240",
    "end": "382820"
  },
  {
    "text": "roughly two percent up from you know larger organizers sometimes you see a 10",
    "start": "382820",
    "end": "390100"
  },
  {
    "text": "fifteen 20 percent being spent on monitoring their ability and reliability at companies and organizations so you",
    "start": "390100",
    "end": "397480"
  },
  {
    "text": "know I that's always been a staple of the project and will continue to be one of the goals going forward and was",
    "start": "397480",
    "end": "404110"
  },
  {
    "text": "essentially first released in the open source in August 2018 so about eight",
    "start": "404110",
    "end": "409210"
  },
  {
    "text": "months ago my Master's probably wrong in that one long flight was my excuse anyway is",
    "start": "409210",
    "end": "416730"
  },
  {
    "text": "basically being written in open source from 2016 but we only really put",
    "start": "416730",
    "end": "421990"
  },
  {
    "text": "together the documentation and other stuff to actually run it with integrations with things like prometheus",
    "start": "421990",
    "end": "428350"
  },
  {
    "text": "and that since August last year so we have a monthly community meetings with",
    "start": "428350",
    "end": "434860"
  },
  {
    "text": "attendees from small to large organizations it's released every few weeks and also last night as I was",
    "start": "434860",
    "end": "443670"
  },
  {
    "text": "basically trying some things out that I realized in quite work right so you know",
    "start": "443670",
    "end": "449620"
  },
  {
    "text": "this is kind of what it looks like it's basically multi-region aware so it",
    "start": "449620",
    "end": "455500"
  },
  {
    "text": "can basically store metrics local to eight each region that you run in and then essentially fans out queries when",
    "start": "455500",
    "end": "462940"
  },
  {
    "text": "you need to join data across those two whole of the regions that you run in and",
    "start": "462940",
    "end": "468370"
  },
  {
    "text": "so you know it understands Prometheus and understands graphite and it's kind of compatible with multiple metrics",
    "start": "468370",
    "end": "474880"
  },
  {
    "text": "formats which rubra was really important when we got started because we basically had a whole bunch of legacy applications",
    "start": "474880",
    "end": "480460"
  },
  {
    "text": "that emitted graphite metrics still to this day do they're becoming a smaller percentage of the overall footprint of",
    "start": "480460",
    "end": "487740"
  },
  {
    "text": "applications adiru but they're still there and we didn't want to turn them off or run multiple disparate systems",
    "start": "487740",
    "end": "494050"
  },
  {
    "text": "just for the different types of metrics formats that we supported so three main",
    "start": "494050",
    "end": "501400"
  },
  {
    "text": "points I want to talk about in three I just want to basically talk to how you know it runs pretty much anywhere these",
    "start": "501400",
    "end": "507880"
  },
  {
    "text": "days which is you know great for I think the open source community whether you're",
    "start": "507880",
    "end": "513909"
  },
  {
    "text": "running on premise whether you're running in the cloud whether you're running on kubernetes it there and it also supports monitoring a",
    "start": "513910",
    "end": "521630"
  },
  {
    "text": "whole bunch of different applications it's scalable to billions of metrics this is a workload that's been run in",
    "start": "521630",
    "end": "527420"
  },
  {
    "text": "production uber for quite some time now and it has a focus on simple operability",
    "start": "527420",
    "end": "532820"
  },
  {
    "text": "we to this day only have two dedicated s eries on the m3 team at uber which is",
    "start": "532820",
    "end": "540139"
  },
  {
    "text": "pretty incredible considering it went from you know tens of storage nodes to thousands of storage nodes today so",
    "start": "540139",
    "end": "548959"
  },
  {
    "start": "547000",
    "end": "572000"
  },
  {
    "text": "touching on runs anywhere so as I mentioned you know similar to Prometheus because it's basically compatible with",
    "start": "548959",
    "end": "554930"
  },
  {
    "text": "Prometheus as sort of a long-term storage you can monitor a ton of any application that's cloud native or has a",
    "start": "554930",
    "end": "562970"
  },
  {
    "text": "service discovery layer in prometheus it's runs on kuben AZ or on-premise as I",
    "start": "562970",
    "end": "568579"
  },
  {
    "text": "mentioned it's multi-region aware so that's that's pretty important I think",
    "start": "568579",
    "end": "574820"
  },
  {
    "start": "572000",
    "end": "786000"
  },
  {
    "text": "as as again as we're kind of running these more complicated applications everywhere to be able to be native",
    "start": "574820",
    "end": "581860"
  },
  {
    "text": "natively multi region is important so why would you want to use m3 with",
    "start": "581860",
    "end": "587510"
  },
  {
    "text": "previous so a lot of a lot of people are wanting to kind of establish a Saleh's",
    "start": "587510",
    "end": "593029"
  },
  {
    "text": "of their companies and organizations in a way that lets them you know really be",
    "start": "593029",
    "end": "598670"
  },
  {
    "text": "data-driven about what they're monitoring how they're monitoring how they're performing and a lot of the time",
    "start": "598670",
    "end": "605630"
  },
  {
    "text": "that means storing things for longer so you can basically do month or month comparisons or even you know just",
    "start": "605630",
    "end": "612290"
  },
  {
    "text": "getting started week in week so you can store metrics at very specific retention periods and you don't have to worry",
    "start": "612290",
    "end": "619910"
  },
  {
    "text": "about losing one or two nodes or backing up or restoring data or anything like that",
    "start": "619910",
    "end": "625010"
  },
  {
    "text": "as long as you always have at least a certain number of replicas available",
    "start": "625010",
    "end": "632380"
  },
  {
    "text": "you'll be able to access and read and write your data just fine so and you might also want to store",
    "start": "632380",
    "end": "639410"
  },
  {
    "text": "different types of metrics at different retentions which is becoming increasingly important and you can scale",
    "start": "639410",
    "end": "645589"
  },
  {
    "text": "up your storage by just adding nodes so this is again what Prometheus may look like with your Apple",
    "start": "645589",
    "end": "652109"
  },
  {
    "text": "this is what using it within three months like in a very basic manner so we're still looking at a single region",
    "start": "652109",
    "end": "658259"
  },
  {
    "text": "in this example essentially entry coordinator is a proxy tier that'll and",
    "start": "658259",
    "end": "665339"
  },
  {
    "text": "Jess Prometheus remote right requests which is HTTP one snappy encoded per",
    "start": "665339",
    "end": "672689"
  },
  {
    "text": "debuff and so you can actually put an HTTP load balancer in front of entry",
    "start": "672689",
    "end": "678179"
  },
  {
    "text": "coordinator and send a whole bunch of different Prometheus metrics just so that just at that layer of entry",
    "start": "678179",
    "end": "684239"
  },
  {
    "text": "coordinators so it's kind of stateless unless you're aggregating metrics and",
    "start": "684239",
    "end": "689999"
  },
  {
    "text": "what's nice about that is that that's really the only two roles you need to to run to get started the m30 big cluster",
    "start": "689999",
    "end": "695609"
  },
  {
    "text": "itself which you can manage with kubernetes is the second role here and that's spread across availability zones",
    "start": "695609",
    "end": "701369"
  },
  {
    "text": "so as soon as a metric crosses a threshold from Prometheus into the entry system its replicated across multiple",
    "start": "701369",
    "end": "708209"
  },
  {
    "text": "availability zones and so what a lot of people of course are interested in doing",
    "start": "708209",
    "end": "713669"
  },
  {
    "text": "is viewing kind of all the metrics from multiple Prometheus instances across",
    "start": "713669",
    "end": "718849"
  },
  {
    "text": "either in a single region or across multiple regions and if you want to do that essentially you can point for finer",
    "start": "718849",
    "end": "725189"
  },
  {
    "text": "or your learning engine directly to the entry coordinator it does speak Prohm ql natively and essentially can join all",
    "start": "725189",
    "end": "733619"
  },
  {
    "text": "that data that you sending from the difference between with use instances because it's stored in one place so you can do a sum across regions or sum",
    "start": "733619",
    "end": "740039"
  },
  {
    "text": "across wherever your application is running and you don't have to worry about Oh",
    "start": "740039",
    "end": "745919"
  },
  {
    "text": "does my Prometheus live here for this application in this zone or region and",
    "start": "745919",
    "end": "751189"
  },
  {
    "text": "then you know you can also deploy a dedicated entry query instance why you",
    "start": "751189",
    "end": "756329"
  },
  {
    "text": "might want to do this is so that you basically don't interrupt your rights when heavy read queries come in so you",
    "start": "756329",
    "end": "763529"
  },
  {
    "text": "know sometimes people like to look at thousands or hundreds of thousands of",
    "start": "763529",
    "end": "768539"
  },
  {
    "text": "metrics and perform the crazy aggregations which might cause a problem for query services of any kind so these",
    "start": "768539",
    "end": "777689"
  },
  {
    "text": "poison queries are able at least to be isolated to the rate path and don't disrupt your collection of metrics if you deploy in a",
    "start": "777689",
    "end": "784600"
  },
  {
    "text": "dedicated entry query instance so talking a little bit about graphite we",
    "start": "784600",
    "end": "790389"
  },
  {
    "start": "786000",
    "end": "856000"
  },
  {
    "text": "support basically carbon TCP on ingestion and graphite functions we're",
    "start": "790389",
    "end": "795430"
  },
  {
    "text": "trying to work with some of the booking comm engineers to see if we can basically use their graphite query layer",
    "start": "795430",
    "end": "803230"
  },
  {
    "text": "right now it's essentially something that is home-baked based on the 0.10",
    "start": "803230",
    "end": "808930"
  },
  {
    "text": "release for graphite so it's not as up-to-date is the most most recent",
    "start": "808930",
    "end": "814410"
  },
  {
    "text": "graphite the full set of functions are just not quite there but it says it's",
    "start": "814410",
    "end": "822459"
  },
  {
    "text": "great for getting started and hopefully we can work with work with booking comm to get that into a much more complete",
    "start": "822459",
    "end": "828399"
  },
  {
    "text": "set of graphite query support so this is",
    "start": "828399",
    "end": "833560"
  },
  {
    "text": "kind of what it looks like with graphite carbon TCP line protocol eyes can be adjusted by the coordinator and then",
    "start": "833560",
    "end": "839800"
  },
  {
    "text": "essentially you can store graphite and Prometheus metrics in a single cluster side-by-side so this is quite nice",
    "start": "839800",
    "end": "846459"
  },
  {
    "text": "because again if you're coming from like a legacy system you've got your latest and greatest but you also want to",
    "start": "846459",
    "end": "851470"
  },
  {
    "text": "support graphite you only need one single system at least a store and query that data so M 3 runs in multi region I",
    "start": "851470",
    "end": "860440"
  },
  {
    "start": "856000",
    "end": "970000"
  },
  {
    "text": "went in a multi regional wear fashion as I kind of mentioned essentially the the",
    "start": "860440",
    "end": "867550"
  },
  {
    "text": "there's zero cross region traffic running where you store all this all your data basically region local this is",
    "start": "867550",
    "end": "874569"
  },
  {
    "text": "pretty important because as a lot of you know like cloud bandwidth costs are very very real it's one of the more expensive",
    "start": "874569",
    "end": "880269"
  },
  {
    "text": "parts of actually running in the cloud and shipping traffic cross region all the time it can be very expensive so",
    "start": "880269",
    "end": "887949"
  },
  {
    "text": "the other thing that's nice as well is that you know people basically would",
    "start": "887949",
    "end": "893980"
  },
  {
    "text": "like to have high reliability so and that's one out one way of getting around that is essentially like spreading data",
    "start": "893980",
    "end": "900609"
  },
  {
    "text": "across regions or at least like a single place that that's something that n3 supports at least locally in a region is",
    "start": "900609",
    "end": "906970"
  },
  {
    "text": "just assisting data across availability zones so if you have a single availability zone that goes down you're",
    "start": "906970",
    "end": "913600"
  },
  {
    "text": "still reading a riding metrics just fine of that local region you can lose an entire region as well you'll still be",
    "start": "913600",
    "end": "918939"
  },
  {
    "text": "able to access data from all other regions you know both read and write and this is",
    "start": "918939",
    "end": "925209"
  },
  {
    "text": "what basically a region local deployment of m3 looks like this is essentially a Prometheus a sentence remote right data",
    "start": "925209",
    "end": "932769"
  },
  {
    "text": "two in three coordinators which are stateless in your availability zones and",
    "start": "932769",
    "end": "938470"
  },
  {
    "text": "then the entry to be cluster as I said is again is spread over availability zones managed by kubernetes and then the",
    "start": "938470",
    "end": "944290"
  },
  {
    "text": "global query tier looks something like this where you can essentially put a HTTP load balancer in front of all of",
    "start": "944290",
    "end": "949299"
  },
  {
    "text": "your regions and then essentially queries can hit either any region so if one goes down it'll fold out a load",
    "start": "949299",
    "end": "955419"
  },
  {
    "text": "balancer and because the coordinators or dedicated m3 query instances if you're",
    "start": "955419",
    "end": "960759"
  },
  {
    "text": "deployed using that because I know about each other they basically will sum an aggregate data from all the other",
    "start": "960759",
    "end": "966339"
  },
  {
    "text": "regions and return you as a single sum in one query so talking a little bit",
    "start": "966339",
    "end": "972579"
  },
  {
    "text": "more about the kind of core pillars of the system which is score scaling to a",
    "start": "972579",
    "end": "978970"
  },
  {
    "text": "very very large number of metrics for uber has 4,000 plus micro sources which",
    "start": "978970",
    "end": "984910"
  },
  {
    "text": "is both the tyranny and not not also not",
    "start": "984910",
    "end": "990040"
  },
  {
    "text": "a tyranny it's a let builders build mentality essentially is what we call it",
    "start": "990040",
    "end": "995529"
  },
  {
    "text": "so there there's some nice things that comes from just having a whole bunch of network service and making it easy to",
    "start": "995529",
    "end": "1001470"
  },
  {
    "text": "deploy but it is definitely not Maritimes so you know because of this",
    "start": "1001470",
    "end": "1007259"
  },
  {
    "text": "you know it forced us into basically make systems that made everything look the same and scale out basically",
    "start": "1007259",
    "end": "1015279"
  },
  {
    "text": "Methos market services in a very horizontal fashion so so one of the",
    "start": "1015279",
    "end": "1020680"
  },
  {
    "text": "benefits of this charity is essentially there's no one boarding to whole month to monitoring there's no provisioning a",
    "start": "1020680",
    "end": "1027668"
  },
  {
    "text": "service for a team you just add storage nodes as required and it's used for a",
    "start": "1027669",
    "end": "1034089"
  },
  {
    "text": "whole bunch of different things so at first you know it's just a standard kind of application metrics latency request",
    "start": "1034089",
    "end": "1041589"
  },
  {
    "text": "counts etc finding is like but then we started realizing that developers were",
    "start": "1041589",
    "end": "1049929"
  },
  {
    "text": "using it for business metrics as well so you know as anyone that's used a Prometheus client library knows very",
    "start": "1049929",
    "end": "1057039"
  },
  {
    "text": "easy to begin to just drop in instrumentation and in tons of your code pause and so it's not meant to be relied",
    "start": "1057039",
    "end": "1065710"
  },
  {
    "text": "upon for business making decisions but it's very easy to get an idea of how your application is basically performing",
    "start": "1065710",
    "end": "1073419"
  },
  {
    "text": "at a different market segment if you can support high cardinality metrics at the storage layer and then you know we have",
    "start": "1073419",
    "end": "1080169"
  },
  {
    "text": "also we also collect basically Network fabric metrics a bandwidth and latency for different network devices and",
    "start": "1080169",
    "end": "1088179"
  },
  {
    "text": "routing systems data center device temperatures we do capacity planning off these metrics for basically buying",
    "start": "1088179",
    "end": "1096039"
  },
  {
    "text": "hardware for some of our own premises data centers working out how much load there and load averages how that's",
    "start": "1096039",
    "end": "1101260"
  },
  {
    "text": "increasing and we can look at that month every month in that whole system we can also do it like macro analytical style",
    "start": "1101260",
    "end": "1106720"
  },
  {
    "text": "queries to see like disk failure rates and different types of discs and",
    "start": "1106720",
    "end": "1112149"
  },
  {
    "text": "different SKUs so actually being able to store and query these in a really large",
    "start": "1112149",
    "end": "1117659"
  },
  {
    "text": "fashion is is really it becomes extremely beneficial especially as you",
    "start": "1117659",
    "end": "1123360"
  },
  {
    "text": "do especially as things are getting more complicated and yeah we also do a whole",
    "start": "1123360",
    "end": "1130240"
  },
  {
    "text": "bunch of stuff that I'd never even knew about that there's a whole bunch of people using us as a platform basically - for syncing data into it and then",
    "start": "1130240",
    "end": "1137710"
  },
  {
    "text": "reading that data out - load balancer applications and so you know some of these stateful things are built on",
    "start": "1137710",
    "end": "1143500"
  },
  {
    "text": "Apache helix or other kind of infrastructure which basically means they move data around as workloads move",
    "start": "1143500",
    "end": "1151230"
  },
  {
    "text": "so the n3 platform itself you know it's obviously has to support a large large",
    "start": "1151230",
    "end": "1156240"
  },
  {
    "text": "amount of users we basically see around 700 million metrics being aggregated by",
    "start": "1156240",
    "end": "1162600"
  },
  {
    "text": "the system at peak capacity and then that translates to roughly like 35 million metrics stored at any given time",
    "start": "1162600",
    "end": "1170640"
  },
  {
    "text": "to storage and this is across thousands of in 30 V nodes and there's about nine",
    "start": "1170640",
    "end": "1175650"
  },
  {
    "text": "billion metrics in you Sidhu room so it's architected you know for a",
    "start": "1175650",
    "end": "1181890"
  },
  {
    "text": "liability scale that's that's really where we started and why we started there that was the the fundamental underpinnings of this project each",
    "start": "1181890",
    "end": "1189210"
  },
  {
    "text": "component is designed to run across availability zones in region and this lower inter region network bandwidth",
    "start": "1189210",
    "end": "1194960"
  },
  {
    "text": "queries are executed and distributed in parallel so one of the biggest thing when you start to get to the billions of",
    "start": "1194960",
    "end": "1200190"
  },
  {
    "text": "metrics is being able to find these metrics and find them quickly so because",
    "start": "1200190",
    "end": "1205470"
  },
  {
    "text": "of the flat collection that basically any metrics platform does you don't",
    "start": "1205470",
    "end": "1210960"
  },
  {
    "text": "write a schema you don't tell your metric system how to basically store and",
    "start": "1210960",
    "end": "1216150"
  },
  {
    "text": "index different types of metrics so essentially you need to build a very generous indexing system and when you",
    "start": "1216150",
    "end": "1223140"
  },
  {
    "text": "have flat structure like that being able to find metrics at at very large high cardinalities is becomes difficult so",
    "start": "1223140",
    "end": "1231450"
  },
  {
    "text": "basically here you can see that we distribute the work of at least finding those metrics and extracting that data",
    "start": "1231450",
    "end": "1237690"
  },
  {
    "text": "to too many multiple storage nodes and this essentially happens in parallel as",
    "start": "1237690",
    "end": "1243510"
  },
  {
    "text": "you execute a query so and you know as you kind of like continue to to get a larger amount of this flat structured",
    "start": "1243510",
    "end": "1250710"
  },
  {
    "text": "data spread across everywhere being able to distribute that metric lookup starts",
    "start": "1250710",
    "end": "1256740"
  },
  {
    "text": "to matter a lot so this is a post you know other types of systems that basically archive data to long-term",
    "start": "1256740",
    "end": "1263370"
  },
  {
    "text": "storage you know they might off load it to s3 or other like slower-moving dater",
    "start": "1263370",
    "end": "1270490"
  },
  {
    "text": "we're houses and this is actually you know a great pattern I think that for some people works really well but",
    "start": "1270490",
    "end": "1277990"
  },
  {
    "text": "because it's you know a little bit perhaps easier to manage but having said that you know kubernetes and communities",
    "start": "1277990",
    "end": "1284680"
  },
  {
    "text": "operators are making things a lot easier these days but one basically downside of this is that when you grow to really",
    "start": "1284680",
    "end": "1290800"
  },
  {
    "text": "large sizes of datasets essentially you know you have to rely on a single process to be able to pull all that data",
    "start": "1290800",
    "end": "1297160"
  },
  {
    "text": "and find all those metrics in the index lookup for a given query so you can",
    "start": "1297160",
    "end": "1302650"
  },
  {
    "text": "imagine that you know once you get to a certain size for a time window a time slice in retention that you're looking",
    "start": "1302650",
    "end": "1309850"
  },
  {
    "text": "at that's a lot of data to pull back and for a single query note to basically",
    "start": "1309850",
    "end": "1314950"
  },
  {
    "text": "perform that lookup and and find the data you're looking for and so the index",
    "start": "1314950",
    "end": "1320170"
  },
  {
    "text": "you know talking a little bit more about that is basically backed by FST segments this is similar to what Apache Lucine",
    "start": "1320170",
    "end": "1326740"
  },
  {
    "text": "uses to index documents and which of course elasticsearch is built upon it",
    "start": "1326740",
    "end": "1332500"
  },
  {
    "text": "essentially allows us to filter and regex queries over billions of metrics we are using and we've made some",
    "start": "1332500",
    "end": "1339970"
  },
  {
    "text": "upstream changes to let go the go Couchbase of elam library which provides us so we didn't build this from scratch",
    "start": "1339970",
    "end": "1346420"
  },
  {
    "text": "this is is a very powerful library and definitely very interesting so basically",
    "start": "1346420",
    "end": "1352030"
  },
  {
    "text": "an FST segment that kind of looks like a try you can imagine if all the words that you're all the text that you're",
    "start": "1352030",
    "end": "1359080"
  },
  {
    "text": "basically indexing he's put into a try and then it basically compresses that try and collapses that and then you can",
    "start": "1359080",
    "end": "1365710"
  },
  {
    "text": "basically very very efficiently walk that try and work out essentially which",
    "start": "1365710",
    "end": "1372130"
  },
  {
    "text": "parts of the try match that query and then return basically the union of all",
    "start": "1372130",
    "end": "1378850"
  },
  {
    "text": "of the matching try nodes that that you match for a query and then we have a you",
    "start": "1378850",
    "end": "1384790"
  },
  {
    "start": "1383000",
    "end": "1510000"
  },
  {
    "text": "know focus on again as super low probability again there's only two essays on the entry team that is",
    "start": "1384790",
    "end": "1392260"
  },
  {
    "text": "managing all of this basically you know can run premise but also an MDB and and",
    "start": "1392260",
    "end": "1399240"
  },
  {
    "text": "what makes them a lot of this able to be run easily is that basically we have",
    "start": "1399240",
    "end": "1405960"
  },
  {
    "text": "automation that that can replace notes for you add or scale up or scale down",
    "start": "1405960",
    "end": "1411570"
  },
  {
    "text": "depending on what you need and so you know we've kind of pushed for these fewer roles and pushing complexity into",
    "start": "1411570",
    "end": "1419010"
  },
  {
    "text": "these roles themselves so again you only really need two roles to get started within three we don't have any",
    "start": "1419010",
    "end": "1424740"
  },
  {
    "text": "background tasks or require monitoring we used to have a large batch down sampling that we would do where you",
    "start": "1424740",
    "end": "1431039"
  },
  {
    "text": "basically write you know raw metrics into our system then has some batch process come collect some of those raw metrics can pack them into one minute or",
    "start": "1431039",
    "end": "1438419"
  },
  {
    "text": "ten minute I'll store them back now so when you're storing metrics for months or years just collecting about ten",
    "start": "1438419",
    "end": "1444210"
  },
  {
    "text": "seconds and then trying to like read all that ten-second data in one query it's not really very efficient you're just",
    "start": "1444210",
    "end": "1450360"
  },
  {
    "text": "operating on gigabytes and gigabytes of data so down sampling that into one that are ten minute tiles is very important",
    "start": "1450360",
    "end": "1456779"
  },
  {
    "text": "one thing we found they were doing it in a batch fashion reading aggregated data that we stored and then writing it back",
    "start": "1456779",
    "end": "1463110"
  },
  {
    "text": "is that you basically have to babysit this process that goes and does this kind of like large batch processing job",
    "start": "1463110",
    "end": "1470370"
  },
  {
    "text": "now so we basically in the entry coordinator and if you're running in a more scaled up fashion you can use entry",
    "start": "1470370",
    "end": "1476279"
  },
  {
    "text": "aggregator which is a distributed aggregation server but basically we do",
    "start": "1476279",
    "end": "1481409"
  },
  {
    "text": "all that a down sampling on the ingestion path so essentially this happens in real time as you're collecting your metrics so as long as",
    "start": "1481409",
    "end": "1487890"
  },
  {
    "text": "you're you know instances are healthy you're fine and you don't kind of have",
    "start": "1487890",
    "end": "1493470"
  },
  {
    "text": "to babysit these background tasks so that's one differentiating factor I guess with with m3 which is interesting",
    "start": "1493470",
    "end": "1500149"
  },
  {
    "text": "the you know and again the koobideh is operator can handle a lot of the",
    "start": "1500149",
    "end": "1505909"
  },
  {
    "text": "replacing and scaling up is scaling down of resources for m3 so I thought that we",
    "start": "1505909",
    "end": "1513120"
  },
  {
    "start": "1510000",
    "end": "1990000"
  },
  {
    "text": "might have a quick demo of at least some of what it can do so this is essentially",
    "start": "1513120",
    "end": "1520130"
  },
  {
    "text": "what I'm going to run through now there's essentially we're gonna basically look at a multi region set up",
    "start": "1520130",
    "end": "1526320"
  },
  {
    "text": "in three and you can try and leave it should be fairly reproducible",
    "start": "1526320",
    "end": "1531410"
  },
  {
    "text": "and this repository that I've linked here basically shows a readme on how to",
    "start": "1531410",
    "end": "1536690"
  },
  {
    "text": "how to reproduce this benchmark but essentially we basically got this I set",
    "start": "1536690",
    "end": "1543080"
  },
  {
    "text": "up that looks very similar to this so node exporter and problem we've kind of compressed into a single benchmark or",
    "start": "1543080",
    "end": "1549110"
  },
  {
    "text": "utility called prom room by bench and essentially it generates node exported data using the influx DB metrics metric",
    "start": "1549110",
    "end": "1558590"
  },
  {
    "text": "benchmark or generator so basically all this data looks like no T supporter coming in and it just remote right for",
    "start": "1558590",
    "end": "1564680"
  },
  {
    "text": "that using the Prometheus remote right format so that's protobuf encoded",
    "start": "1564680",
    "end": "1571550"
  },
  {
    "text": "snapping snapping compressed Oratia p12 the entry coordinator and then this they",
    "start": "1571550",
    "end": "1577430"
  },
  {
    "text": "will all write it to basically local regional and 3 DB clusters so demos",
    "start": "1577430",
    "end": "1583400"
  },
  {
    "text": "always fail so I'm prepared for that mmm and we'll just see what we'll just see",
    "start": "1583400",
    "end": "1590210"
  },
  {
    "text": "how we do so first this first is Wi-Fi and I",
    "start": "1590210",
    "end": "1596390"
  },
  {
    "text": "really should have joined this before stepping up here okay okay",
    "start": "1596390",
    "end": "1604940"
  },
  {
    "text": "I just tried hotspot them so basically I'm going to with Luth first look at the",
    "start": "1604940",
    "end": "1611180"
  },
  {
    "text": "EU West design so here I'm just gonna",
    "start": "1611180",
    "end": "1618110"
  },
  {
    "text": "check in and see basically okay so I've basically got ten of these chrome bench",
    "start": "1618110",
    "end": "1623200"
  },
  {
    "text": "remote remote Prometheus bench markers running so each one of these does",
    "start": "1623200",
    "end": "1629570"
  },
  {
    "text": "roughly about a thousand metrics per second coming from node exporter so I'm just gonna pull it forward to microphone",
    "start": "1629570",
    "end": "1636050"
  },
  {
    "text": "or instance running here okay great and",
    "start": "1636050",
    "end": "1642010"
  },
  {
    "text": "it is here great so basically because I'm running",
    "start": "1642670",
    "end": "1648890"
  },
  {
    "text": "ten of these you can see here that sorry",
    "start": "1648890",
    "end": "1654310"
  },
  {
    "text": "translates to about ten thousand metrics per second per note that I'm running so essentially I'm",
    "start": "1654310",
    "end": "1661250"
  },
  {
    "text": "running 30 storage notes over those 30 storage nodes I'm popping about a hundred thousand logical rights because",
    "start": "1661250",
    "end": "1668240"
  },
  {
    "text": "entropy replicates that at a factor of three that essentially means we're doing",
    "start": "1668240",
    "end": "1674149"
  },
  {
    "text": "about 300,000 actual writes because after replication that's that's how many is being consistent to disk and so we're",
    "start": "1674149",
    "end": "1681620"
  },
  {
    "text": "about we're ingesting a hundred thousand logical rights and three hundred thousand actual rights to this thirty-nine cluster right now so",
    "start": "1681620",
    "end": "1688850"
  },
  {
    "text": "basically I'm gonna go and scale this up so if we edit the deployment for premier",
    "start": "1688850",
    "end": "1696830"
  },
  {
    "text": "bench we can find that yes it's",
    "start": "1696830",
    "end": "1702110"
  },
  {
    "text": "basically ten replicas here I'm gonna scale this up to a hundred so wishes",
    "start": "1702110",
    "end": "1709879"
  },
  {
    "text": "yep see all these containers being created essentially you know okay so",
    "start": "1709879",
    "end": "1717529"
  },
  {
    "text": "basically now we see extra lloyd from these nerdy exporter metrics starting to",
    "start": "1717529",
    "end": "1724639"
  },
  {
    "text": "hit these instances and so we're going to about a hundred k per second up from",
    "start": "1724639",
    "end": "1732230"
  },
  {
    "text": "10k per storage node this should be about 1 million rights per second logical and 3 million actual rights and",
    "start": "1732230",
    "end": "1740570"
  },
  {
    "text": "basically including replication",
    "start": "1740570",
    "end": "1744220"
  },
  {
    "text": "let's just look at lost five minutes and",
    "start": "1746650",
    "end": "1753410"
  },
  {
    "text": "unfortunately I'm not using preemptable instances so this is inexpensive detonator run so basically now we're",
    "start": "1753410",
    "end": "1761360"
  },
  {
    "text": "yeah at 100k per node doing about three million actual riots 1 million logical",
    "start": "1761360",
    "end": "1766790"
  },
  {
    "text": "rights I'm going to basically scale this up again let's check it to two hundred",
    "start": "1766790",
    "end": "1779950"
  },
  {
    "text": "okay so now we're going to create a bunch of are these benchmarking containers and then let's see this fluid",
    "start": "1784150",
    "end": "1792220"
  },
  {
    "text": "added so you know I'm kind of expecting to get to about if we can get to 400k that'll be nice a lot a hundred percent",
    "start": "1792220",
    "end": "1801010"
  },
  {
    "text": "expecting to get there considering I was playing around with this last night so",
    "start": "1801010",
    "end": "1806860"
  },
  {
    "text": "this is basically a view of the gke google kubernetes engine cluster view",
    "start": "1806860",
    "end": "1815050"
  },
  {
    "text": "and so this is the utilization across all these 13 nodes so this is the CPU utilization of the cluster now I'm using",
    "start": "1815050",
    "end": "1821380"
  },
  {
    "text": "30 nodes here but there's essentially you know the coordinate is running on",
    "start": "1821380",
    "end": "1826510"
  },
  {
    "text": "top of those DV nodes as well as the problem remote venture and and some other things in the cluster like etc D",
    "start": "1826510",
    "end": "1833290"
  },
  {
    "text": "and stuff like that so it's not just in 3b using these resources either so here",
    "start": "1833290",
    "end": "1839290"
  },
  {
    "text": "yeah we can see basically CPU is definitely starting to spike up none not",
    "start": "1839290",
    "end": "1846100"
  },
  {
    "text": "insignificant amount okay so that seems pretty stable now and we've hit about",
    "start": "1846100",
    "end": "1852100"
  },
  {
    "text": "yes six million actual writes with two million logical writes so now we're going to scale up again",
    "start": "1852100",
    "end": "1859770"
  },
  {
    "text": "and if we get here I might stop because I prefer to do Q&A than just make you",
    "start": "1866700",
    "end": "1873419"
  },
  {
    "text": "watch grass all day but yeah but basically we've benchmark that's",
    "start": "1873419",
    "end": "1878489"
  },
  {
    "text": "definitely doing four million large actual rats so that's about 2 2 X from",
    "start": "1878489",
    "end": "1884789"
  },
  {
    "text": "kind of what we're seeing now see ya",
    "start": "1884789",
    "end": "1890009"
  },
  {
    "text": "this dashboard as well by the ways can be found on prefer Norcom so if you find yourself playing around with them 3 B",
    "start": "1890009",
    "end": "1895980"
  },
  {
    "text": "and you want to want to actually see some of the stats coming out of it you can find it there and so yes now we're",
    "start": "1895980",
    "end": "1903090"
  },
  {
    "text": "at 300k doing yeah basically nine million actual rights 3 million logical",
    "start": "1903090",
    "end": "1909779"
  },
  {
    "text": "rights you can see the you know the service side latency creeping up here this is basically a p99",
    "start": "1909779",
    "end": "1916379"
  },
  {
    "text": "so you know most of the most of the rights are completing much much faster than this but it's definitely it takes a",
    "start": "1916379",
    "end": "1923279"
  },
  {
    "text": "little while to kind of warm up so maybe probably about a great idea to ramp this",
    "start": "1923279",
    "end": "1930629"
  },
  {
    "text": "up so quickly anyway I'll take this to 350 but then",
    "start": "1930629",
    "end": "1936570"
  },
  {
    "text": "I'll just I'll take questions so yeah so",
    "start": "1936570",
    "end": "1942899"
  },
  {
    "text": "that's that I do want to jump back has that's going to there and basically talked a little bit about the road map",
    "start": "1942899",
    "end": "1949049"
  },
  {
    "text": "you know basically we want to hide the lifecycle management to the kubernetes cluster so we basically wanted to make",
    "start": "1949049",
    "end": "1955440"
  },
  {
    "text": "it support a lot more of the day-to-day management activities want to add am 3ql",
    "start": "1955440",
    "end": "1962399"
  },
  {
    "text": "query language support which is an internal query this language at uber",
    "start": "1962399",
    "end": "1968730"
  },
  {
    "text": "that was pipe base which we think the community might be interested in and then you know we're also going to be",
    "start": "1968730",
    "end": "1973859"
  },
  {
    "text": "looking into making it a more generic time series database but I'm going to basically take questions now and thank",
    "start": "1973859",
    "end": "1979919"
  },
  {
    "text": "you all for for listening",
    "start": "1979919",
    "end": "1983148"
  },
  {
    "text": "[Applause] hello I had a question about the",
    "start": "1987840",
    "end": "1995910"
  },
  {
    "start": "1990000",
    "end": "2227000"
  },
  {
    "text": "ingestion path you mentioned something about being able to down sample I was curious what sort of control do",
    "start": "1995910",
    "end": "2001610"
  },
  {
    "text": "you have on exactly what you decide to store in terms of what's coming in yeah",
    "start": "2001610",
    "end": "2007539"
  },
  {
    "text": "great great question so essentially we have some standard retention policies so",
    "start": "2007539",
    "end": "2013850"
  },
  {
    "text": "basically like two days at ten second resolution thirty days in one minute",
    "start": "2013850",
    "end": "2018860"
  },
  {
    "text": "and that basically applies to everything that we're collecting and then essentially we have the ability to just",
    "start": "2018860",
    "end": "2024830"
  },
  {
    "text": "make API requests or use the UI's like not quite there at open source but essentially to create filters and then",
    "start": "2024830",
    "end": "2032240"
  },
  {
    "text": "developers just go in and creative filters themselves and essentially that that means you can kind of store things",
    "start": "2032240",
    "end": "2038210"
  },
  {
    "text": "that arbitrary resolutions we have resolutions up retention up to five years at one hour of resolution o",
    "start": "2038210",
    "end": "2044539"
  },
  {
    "text": "scaling all the way down to one second resolution at like 24 hours or something like that folks please stay seated until",
    "start": "2044539",
    "end": "2052158"
  },
  {
    "text": "the end of the talk respect the speaker anyone else going on the question go moe",
    "start": "2052159",
    "end": "2057858"
  },
  {
    "text": "moe thank you",
    "start": "2057859",
    "end": "2060700"
  },
  {
    "text": "thank you for a joke I have a question about one of the scheme you mentioned when we use M tree cure and we point the",
    "start": "2063780",
    "end": "2073290"
  },
  {
    "text": "graph on a trait which protocol does support M tree iesson is a understand",
    "start": "2073290",
    "end": "2080520"
  },
  {
    "text": "right that it is a prompt kill micrometers format yeah so the reason we",
    "start": "2080520",
    "end": "2087840"
  },
  {
    "text": "have already begun talking about that right now is because yes it does understand native prong qo however it's",
    "start": "2087840",
    "end": "2093600"
  },
  {
    "text": "never going to be one-to-one as accurate as default Prometheus so it's because",
    "start": "2093600",
    "end": "2100530"
  },
  {
    "text": "it's you know being developed recently it's still basically being worked on but",
    "start": "2100530",
    "end": "2106050"
  },
  {
    "text": "it supports pretty much all to make like all of the functions information today there is I think some issues with binary",
    "start": "2106050",
    "end": "2114950"
  },
  {
    "text": "some of the operators aren't working out 100% as expected right now and we",
    "start": "2114950",
    "end": "2122040"
  },
  {
    "text": "actually need to build basically comprehensive test suite that ensures that it acts exactly as Prometheus does so that's still coming but yes it",
    "start": "2122040",
    "end": "2128810"
  },
  {
    "text": "basically speaks from QL as well as graphite as well yeah so one of the",
    "start": "2128810",
    "end": "2138240"
  },
  {
    "text": "challenges of scaling promises or is of course at storage level that's a great",
    "start": "2138240",
    "end": "2143730"
  },
  {
    "text": "solution I encountered issues on the memory level meaning that we they're not",
    "start": "2143730",
    "end": "2150390"
  },
  {
    "text": "a huge parameters that are managing like two terabyte of data I'm exploding the",
    "start": "2150390",
    "end": "2155790"
  },
  {
    "text": "in memory so I'm wondering how which solutions you see do implement or would",
    "start": "2155790",
    "end": "2162150"
  },
  {
    "text": "you recommend for this kind of yeah great question so I like one thing is",
    "start": "2162150",
    "end": "2167400"
  },
  {
    "text": "essentially memory is always gonna be an issue and all of these systems some of the reason why we get such high",
    "start": "2167400",
    "end": "2173730"
  },
  {
    "text": "compression on this data and allows you to really reduce the cost is that you're basically doing very very high levels of",
    "start": "2173730",
    "end": "2180780"
  },
  {
    "text": "runtime length compression on this data which is a lot easier to do when it stored in memory so you'll see systems",
    "start": "2180780",
    "end": "2187890"
  },
  {
    "text": "like basically m3 has similar issue and uses a fair amount of memory depending on the block size that you choose you can make that block size",
    "start": "2187890",
    "end": "2194070"
  },
  {
    "text": "smaller but it makes your queries like take more time this is basically searching more blocks on disk but",
    "start": "2194070",
    "end": "2199910"
  },
  {
    "text": "essentially we would like to get to a point where we're kind of like not really doing regular compactions because",
    "start": "2199910",
    "end": "2206310"
  },
  {
    "text": "that's why what we're trying to avoid with the system and reduce the cost overall but kind of this kind of",
    "start": "2206310",
    "end": "2212430"
  },
  {
    "text": "concatenation like compaction process with m3 so hopefully at some point we'll",
    "start": "2212430",
    "end": "2219000"
  },
  {
    "text": "be able to actually unload some of that that's not being touched very frequently but we're not there yet thanks very much Rob thanks Tom",
    "start": "2219000",
    "end": "2226770"
  },
  {
    "text": "[Applause]",
    "start": "2226770",
    "end": "2229489"
  }
]
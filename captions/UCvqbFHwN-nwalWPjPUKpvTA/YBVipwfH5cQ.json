[
  {
    "text": "oh very good morning and thanks a lot for joining me in the session on unified monitoring of containers and",
    "start": "0",
    "end": "6359"
  },
  {
    "text": "microservices I'm Michonne Sahai were",
    "start": "6359",
    "end": "11790"
  },
  {
    "text": "affiliated with the Pro limited and working in the open source Co a lab and",
    "start": "11790",
    "end": "17250"
  },
  {
    "text": "Wipro I have been working on in fine monitoring and computer vision since",
    "start": "17250",
    "end": "23430"
  },
  {
    "text": "last couple of years and basically involved with the data analysis team I",
    "start": "23430",
    "end": "28439"
  },
  {
    "text": "would also like to take the opportunity to thank my colleague pavani Anand she",
    "start": "28439",
    "end": "34380"
  },
  {
    "text": "is an architect and Wipro limited she was a co speaker for this particular",
    "start": "34380",
    "end": "39480"
  },
  {
    "text": "talk but due to some personal emergencies she had to take leave she had been instrumental in conceptualizing",
    "start": "39480",
    "end": "45750"
  },
  {
    "text": "this entire unified monitoring framework and has deep expertise and log analytics",
    "start": "45750",
    "end": "52410"
  },
  {
    "text": "so coming back to today's talk the goal of the presentation is I would like to",
    "start": "52410",
    "end": "57660"
  },
  {
    "text": "explain how we have utilized the power of Zipkin along with the intelligence of apache spark ecosystem and the",
    "start": "57660",
    "end": "65070"
  },
  {
    "text": "flexibility of elastic locks - gabbana plus bead stack to create the signified",
    "start": "65070",
    "end": "70439"
  },
  {
    "text": "monitoring framework so I have divided this particular talk in three different",
    "start": "70439",
    "end": "76080"
  },
  {
    "text": "parts in the first section I will be setting up the context as to why unified monitoring is required with respect to",
    "start": "76080",
    "end": "82049"
  },
  {
    "text": "micro services containers in the second section we'll go through the solution overview and in the final section I have",
    "start": "82049",
    "end": "89600"
  },
  {
    "text": "solution demonstration in which will be catering to few use cases with respect",
    "start": "89600",
    "end": "94770"
  },
  {
    "text": "to the unified monitoring including anomaly detection so here we are this is",
    "start": "94770",
    "end": "103530"
  },
  {
    "text": "a typical micro services use case which you can actually map it to any of the",
    "start": "103530",
    "end": "109409"
  },
  {
    "text": "micro services use case which might you be implementing so for me this this can",
    "start": "109409",
    "end": "115950"
  },
  {
    "text": "map to a online e-commerce application and historically which was a monolithic",
    "start": "115950",
    "end": "123270"
  },
  {
    "text": "app and then it was not able to scale up had issues with respect to speed of go to market and then we adopted the micro",
    "start": "123270",
    "end": "131039"
  },
  {
    "text": "services architecture that's the micro-services accurate",
    "start": "131039",
    "end": "137200"
  },
  {
    "text": "picture since it is build on modulite dilation so it helps us in reducing the",
    "start": "137200",
    "end": "143680"
  },
  {
    "text": "complexity so each of this high-level module can be considered as a service",
    "start": "143680",
    "end": "149830"
  },
  {
    "text": "now and each of the service functionality can map to a business",
    "start": "149830",
    "end": "155380"
  },
  {
    "text": "capability so so with micro services we achieved service isolation or to",
    "start": "155380",
    "end": "161560"
  },
  {
    "text": "services are not tightly coupled with each other they have their own release cycle they they don't have a very tight",
    "start": "161560",
    "end": "169600"
  },
  {
    "text": "integration between each other they can not provide high scalability no we are",
    "start": "169600",
    "end": "175660"
  },
  {
    "text": "not actually scaling up the entire monolithic app if needed need to scale",
    "start": "175660",
    "end": "181300"
  },
  {
    "text": "up rather than we can pick and choose the services which are of most and utmost importance and not having a high",
    "start": "181300",
    "end": "187410"
  },
  {
    "text": "resource requirement that can be scaled up it is giving us the flexibility in in the sense that no services can be",
    "start": "187410",
    "end": "194620"
  },
  {
    "text": "written in their own programming languages so you can actually write",
    "start": "194620",
    "end": "200670"
  },
  {
    "text": "account service or that in a Python and whereas your customer service can be",
    "start": "200670",
    "end": "206470"
  },
  {
    "text": "written in a Java programming language and finally it gives us a better resource utilization since it you can",
    "start": "206470",
    "end": "213670"
  },
  {
    "text": "actually scale up and scale down services as per the tech requirement",
    "start": "213670",
    "end": "219190"
  },
  {
    "text": "that you have in hand but again like everything micro services comes with a",
    "start": "219190",
    "end": "225850"
  },
  {
    "text": "cost and the cost is more related to Network overheads now we have n number",
    "start": "225850",
    "end": "232720"
  },
  {
    "text": "of services which are interacting with each other over HTTP so we have a high number of network overhead then again we",
    "start": "232720",
    "end": "240790"
  },
  {
    "text": "have services which can be written in their own programming languages so they",
    "start": "240790",
    "end": "245799"
  },
  {
    "text": "have their own deployment approach they can have their own release cycles so again it becomes an ops nightmare so",
    "start": "245799",
    "end": "252880"
  },
  {
    "text": "finally this awesome trio comes in where we have the micro services which can be",
    "start": "252880",
    "end": "258060"
  },
  {
    "text": "deployed in containers and run in kubernetes cluster so finally",
    "start": "258060",
    "end": "263980"
  },
  {
    "text": "what we have achieved is service isolation as we have already seen with respect to micro services the stag or",
    "start": "263980",
    "end": "271030"
  },
  {
    "text": "mystic hosting again with the combination of containers and micro",
    "start": "271030",
    "end": "276790"
  },
  {
    "text": "services and the container orchestration and the cluster cluster and the workload management which is taken whereby",
    "start": "276790",
    "end": "282670"
  },
  {
    "text": "kubernetes now we have a lot of moving pieces we have a huge number of micro",
    "start": "282670",
    "end": "289690"
  },
  {
    "text": "services a same number of containers pods nodes data centers and there are",
    "start": "289690",
    "end": "297790"
  },
  {
    "text": "applications which are not yet moved into kubernetes cluster they are still running on bare metal in their own",
    "start": "297790",
    "end": "302890"
  },
  {
    "text": "private data centers so the amount of data that is getting generated with",
    "start": "302890",
    "end": "309250"
  },
  {
    "text": "respect to the logs and metrics is overwhelming and these data that is",
    "start": "309250",
    "end": "314620"
  },
  {
    "text": "getting generated the the sheer volume the velocity velocity and the variety is",
    "start": "314620",
    "end": "321850"
  },
  {
    "text": "simply mind-boggling so but again we cannot ignore the data that is generated",
    "start": "321850",
    "end": "326979"
  },
  {
    "text": "out of logs or metrics because they have of deep importance to both the ops and",
    "start": "326979",
    "end": "333700"
  },
  {
    "text": "the business teams and in the current business landscape the the data driven",
    "start": "333700",
    "end": "342330"
  },
  {
    "text": "the data different approach actually affects both the top line and bottom line of the enterprise's and as per the",
    "start": "342330",
    "end": "350320"
  },
  {
    "text": "study in 2015-16 by Enterprise Management Associates almost 65% of",
    "start": "350320",
    "end": "357330"
  },
  {
    "text": "enterprises use more than 10 monitoring apps to keep tab of their applications",
    "start": "357330",
    "end": "363430"
  },
  {
    "text": "and their infrastructure and the same studies also states that almost 71",
    "start": "363430",
    "end": "370570"
  },
  {
    "text": "percent of the enterprise's actually spend around 5% hours to fix an average",
    "start": "370570",
    "end": "377620"
  },
  {
    "text": "performance issue now that is quite obvious you have an application that was running quite fine since last couple of",
    "start": "377620",
    "end": "383500"
  },
  {
    "text": "months or years and slowly it this performance start degrading it maybe",
    "start": "383500",
    "end": "388690"
  },
  {
    "text": "because of some least recent releases or patch it may be because of the data base it disconnect",
    "start": "388690",
    "end": "394240"
  },
  {
    "text": "with is having some kind of a slow query issue or it may be because the external",
    "start": "394240",
    "end": "399310"
  },
  {
    "text": "services are interacting with having some performance issues with it but with",
    "start": "399310",
    "end": "405069"
  },
  {
    "text": "ten monitoring frameworks or in apps in your hand how can you go about and try",
    "start": "405069",
    "end": "411280"
  },
  {
    "text": "to figure out where that particular problem is and this is that it becomes",
    "start": "411280",
    "end": "417039"
  },
  {
    "text": "very imperative for enterprises to have a very strategic and a robust unified",
    "start": "417039",
    "end": "422470"
  },
  {
    "text": "monitoring framework in place so this is where our need for monitoring solutions",
    "start": "422470",
    "end": "430960"
  },
  {
    "text": "came in like as I have mentioned we there is a hybrid deployments there is a",
    "start": "430960",
    "end": "436060"
  },
  {
    "text": "high data volume there is a multiple monitoring frameworks their need for integrated insights and the one more",
    "start": "436060",
    "end": "442720"
  },
  {
    "text": "important thing that enterprises are looking for is they need to get the",
    "start": "442720",
    "end": "448780"
  },
  {
    "text": "issues to be figured out more in a proactive manner rather than rectified in a reactive approach and this is where",
    "start": "448780",
    "end": "457919"
  },
  {
    "text": "in analytically intelligent platform comes in pictures so are unifying",
    "start": "457919",
    "end": "465190"
  },
  {
    "text": "monitoring framework have the set of wish list it has a customizable report",
    "start": "465190",
    "end": "471520"
  },
  {
    "text": "and dashboard so we want to have at least a single window through which a",
    "start": "471520",
    "end": "478539"
  },
  {
    "text": "business or an ops can actually go into the monitoring solution and figure out",
    "start": "478539",
    "end": "484719"
  },
  {
    "text": "where the problem is we need to have a support for programmable interfaces",
    "start": "484719",
    "end": "489990"
  },
  {
    "text": "again with respect to flexibility of enterprise integration we need to have",
    "start": "489990",
    "end": "495509"
  },
  {
    "text": "interfaces which can be extended so it more about having open source frameworks",
    "start": "495509",
    "end": "502180"
  },
  {
    "text": "and which is adhering to open standards so that we can actually customize it as",
    "start": "502180",
    "end": "507250"
  },
  {
    "text": "per our application and the enterprise need as I've said like operational intelligence platform because we need a",
    "start": "507250",
    "end": "514599"
  },
  {
    "text": "more of a proactive approach for issue identification rather than a reactive approach of issue rectification and",
    "start": "514599",
    "end": "522760"
  },
  {
    "text": "finally DevOps friendly so this was one of our main wish list which",
    "start": "522760",
    "end": "528089"
  },
  {
    "text": "we actually achieved having a one-click",
    "start": "528089",
    "end": "533339"
  },
  {
    "text": "kind of a deployment through ansible so our entire unified monitoring framework can be deployed using one click with the",
    "start": "533339",
    "end": "540870"
  },
  {
    "text": "ansible script that is running behind the screen so the list of assets that we",
    "start": "540870",
    "end": "552660"
  },
  {
    "text": "are monitoring as of now we have lists in the infrastructure containers",
    "start": "552660",
    "end": "558630"
  },
  {
    "text": "platforms and applications from infrastructure perspective we are monitoring most of the bare-metal",
    "start": "558630",
    "end": "563730"
  },
  {
    "text": "virtual machines IOT devices network services like HTTP d then from container",
    "start": "563730",
    "end": "570510"
  },
  {
    "text": "platform perspective it is the kubernetes docker containers the messaging platforms web servers and from",
    "start": "570510",
    "end": "578730"
  },
  {
    "text": "application perspective is the application logs application monitoring frame monitoring logs and even the",
    "start": "578730",
    "end": "585000"
  },
  {
    "text": "events and traces so now that we are done with the with setting up the",
    "start": "585000",
    "end": "592170"
  },
  {
    "text": "context as to why unified monitoring is required so we'll come into the second",
    "start": "592170",
    "end": "597180"
  },
  {
    "text": "section this is about the solution conceptual view so again we are taking",
    "start": "597180",
    "end": "604920"
  },
  {
    "text": "into consideration the same micro services use case typical use case that we had shown in the previous one of the",
    "start": "604920",
    "end": "612329"
  },
  {
    "text": "slide and we were targeting an online e-commerce application and specifically for from the demo perspective there is",
    "start": "612329",
    "end": "620370"
  },
  {
    "text": "one this particular API the pradhan for API which will show in the latest stage",
    "start": "620370",
    "end": "625680"
  },
  {
    "text": "which that API is actually orchestrated through multiple services that is a",
    "start": "625680",
    "end": "632550"
  },
  {
    "text": "broad detail pradhan mantri and the broad review so from the conceptual",
    "start": "632550",
    "end": "638850"
  },
  {
    "text": "point of view like all the monitor monitored assets the data in the form of",
    "start": "638850",
    "end": "644100"
  },
  {
    "text": "logs and metrics are pushed through the exporters into the data acquisition layer the exporters being the Zipkin",
    "start": "644100",
    "end": "651750"
  },
  {
    "text": "emitters the elastic beats the locks - strippers and in through the data acquisition layer",
    "start": "651750",
    "end": "659100"
  },
  {
    "text": "consisting of the Zipkin collector and the Kafka lock stash the data is pushed into elastic DB where finally it is",
    "start": "659100",
    "end": "666120"
  },
  {
    "text": "being utilized by Apache spark for predictive analysis for Zipkin and",
    "start": "666120",
    "end": "672000"
  },
  {
    "text": "Cabana for visualization and by Sentinel for alerting and reporting so the main",
    "start": "672000",
    "end": "679950"
  },
  {
    "text": "the first main important layer of our solution is the ingestion layer which",
    "start": "679950",
    "end": "685760"
  },
  {
    "text": "consists of mainly the Zipkin emitters and the elastic beats so the micro",
    "start": "685760",
    "end": "693870"
  },
  {
    "text": "services are both fast and flexible but in case of a performance issue which",
    "start": "693870",
    "end": "700440"
  },
  {
    "text": "comes and it is very tough to debug and do any kind of a profiling this is the",
    "start": "700440",
    "end": "706500"
  },
  {
    "text": "reason being like the micro services or a single service I will never give you",
    "start": "706500",
    "end": "711630"
  },
  {
    "text": "the complete picture of your entire application and in a normal production",
    "start": "711630",
    "end": "716790"
  },
  {
    "text": "deployment of where these services are having a very complex kind of an integration so it is very tough to find",
    "start": "716790",
    "end": "724200"
  },
  {
    "text": "out where a particular service is deployed in which particular container in which particular pod or a host",
    "start": "724200",
    "end": "732000"
  },
  {
    "text": "so this is where distributed tracing helps us so whenever a request passes on",
    "start": "732000",
    "end": "739260"
  },
  {
    "text": "from each of the services metadata is actually intake injected into that",
    "start": "739260",
    "end": "744630"
  },
  {
    "text": "particular request and finally those information are aggregated and you get a",
    "start": "744630",
    "end": "751640"
  },
  {
    "text": "services transaction graph in almost a near real-time so our emitters like in",
    "start": "751640",
    "end": "758970"
  },
  {
    "text": "our application the demo application which consists of node.js and spring boot apps we are we are using the spring",
    "start": "758970",
    "end": "766680"
  },
  {
    "text": "sleuth and the Zipkin J's components for emitters you have the Ruby emitters and there's a",
    "start": "766680",
    "end": "774420"
  },
  {
    "text": "lot many emitters provided in the github open communities which can be utilized",
    "start": "774420",
    "end": "780870"
  },
  {
    "text": "as per your application needs which are now pushed into the Apache Kafka and from there the Zipkin collector picks it",
    "start": "780870",
    "end": "787920"
  },
  {
    "text": "up and pushes into elasticsearch so Zipkin provides the capability both of Kalat collating the",
    "start": "787920",
    "end": "795180"
  },
  {
    "text": "trace information as well as for visualizing them the second mode most",
    "start": "795180",
    "end": "803040"
  },
  {
    "text": "important component in our ingestion layer is the elastic beats the elastic beats are open source edge based",
    "start": "803040",
    "end": "812639"
  },
  {
    "text": "shippers which are written in golang so they're by default well quite a few",
    "start": "812639",
    "end": "819110"
  },
  {
    "text": "beats are available made available by elastic like the metric beat file beat",
    "start": "819110",
    "end": "824910"
  },
  {
    "text": "packet beat heartbeat or beat these are the few default beats which are available by elastic and you can also",
    "start": "824910",
    "end": "832319"
  },
  {
    "text": "look into the community driven beats where like few of the most famous which we have utilized are the the coffe cup",
    "start": "832319",
    "end": "840449"
  },
  {
    "text": "the spar with the spring beats and the Kafka beat so now all the as beats we",
    "start": "840449",
    "end": "846870"
  },
  {
    "text": "can understand from the names of this beat metric bit is more for capturing the infrastructure metric information",
    "start": "846870",
    "end": "853410"
  },
  {
    "text": "file bit captures all the log related information packet bit is more about its nips the network traffic and gathers the",
    "start": "853410",
    "end": "861149"
  },
  {
    "text": "network metrics information and those are finally pushed into the elastic dB and so elastic DB is again an open",
    "start": "861149",
    "end": "869069"
  },
  {
    "text": "source text search analytics engine and it it actually can store a huge volume",
    "start": "869069",
    "end": "880050"
  },
  {
    "text": "of data and you can do fast searches and also you can do fast analytical",
    "start": "880050",
    "end": "886709"
  },
  {
    "text": "operations on the data that is getting stored in it and so it internally uses",
    "start": "886709",
    "end": "892529"
  },
  {
    "text": "bkd tree algorithm for multi node multi data dimensional so it actually helps in",
    "start": "892529",
    "end": "900750"
  },
  {
    "text": "optimizing the disk space as well as also optimizes the indexing and the",
    "start": "900750",
    "end": "906470"
  },
  {
    "text": "search that can be made so we have also",
    "start": "906470",
    "end": "911810"
  },
  {
    "text": "used a lot of aggregation features which helps in your analytical and statistical",
    "start": "911810",
    "end": "918740"
  },
  {
    "text": "dashboard generations and is also concept of ingest note which",
    "start": "918740",
    "end": "924819"
  },
  {
    "text": "whose aim is actually to enrich the data and also whose aim is to process the",
    "start": "924819",
    "end": "932629"
  },
  {
    "text": "data before actually that particular document is getting indexed into elastic DB and there are support with respect to",
    "start": "932629",
    "end": "941779"
  },
  {
    "text": "cross cross cluster search which helps us to actually scale up the elastic DB",
    "start": "941779",
    "end": "948319"
  },
  {
    "text": "and also rollover and string API switch so historical data which are not being",
    "start": "948319",
    "end": "954709"
  },
  {
    "text": "accessed can be actually shrink and this you can optimize the disk space",
    "start": "954709",
    "end": "960230"
  },
  {
    "text": "utilization so now that we have all the data of ship from our api's and from our",
    "start": "960230",
    "end": "968389"
  },
  {
    "text": "micro services and our kubernetes cluster containers into the elastic DB",
    "start": "968389",
    "end": "975800"
  },
  {
    "text": "so the next part for our unified monitoring solution is to actually do",
    "start": "975800",
    "end": "982610"
  },
  {
    "text": "some kind of predictive analysis not that API the protein for API we want to make sure that in case there is an issue",
    "start": "982610",
    "end": "988939"
  },
  {
    "text": "with respect to the the latency there's a high latency or there's a huge number",
    "start": "988939",
    "end": "995179"
  },
  {
    "text": "of requests that is giving a for not for kind of a status so we want to make sure",
    "start": "995179",
    "end": "1002679"
  },
  {
    "text": "that it is more of a proactive nature in which the ops team are notified not when",
    "start": "1002679",
    "end": "1009399"
  },
  {
    "text": "the actual SLA has gone beyond the required limit so this is where we are",
    "start": "1009399",
    "end": "1015790"
  },
  {
    "text": "doing the predictive analysis approach in which we are using apache spark ecosystem which has the streaming ml",
    "start": "1015790",
    "end": "1023889"
  },
  {
    "text": "live and spark SQL component we are utilizing the pi spark in the spark or",
    "start": "1023889",
    "end": "1029288"
  },
  {
    "text": "api for model generation and so the data collection is already done by the",
    "start": "1029289",
    "end": "1035380"
  },
  {
    "text": "elastic search and the pre-processing is done by the spring art the spark RDD and",
    "start": "1035380",
    "end": "1041380"
  },
  {
    "text": "this park SQL and finally the model ml model generation we are utilizing the",
    "start": "1041380",
    "end": "1046569"
  },
  {
    "text": "k-means for anomaly detection so and then the data that is being",
    "start": "1046569",
    "end": "1054360"
  },
  {
    "text": "- so we have a time window once the model is generated for within that particular time window a scheduler runs",
    "start": "1054360",
    "end": "1061410"
  },
  {
    "text": "and fetches the data from elastic DB and send it across to the model to infer if",
    "start": "1061410",
    "end": "1067620"
  },
  {
    "text": "there is any kind of an outlier that need that is present in the data in that",
    "start": "1067620",
    "end": "1073650"
  },
  {
    "text": "particular time window and then it pushes it on again back to the DB for",
    "start": "1073650",
    "end": "1079920"
  },
  {
    "text": "the next component that is the Sentinel the alerting and reporting component so",
    "start": "1079920",
    "end": "1085290"
  },
  {
    "text": "Sentinel is again it is a plug in",
    "start": "1085290",
    "end": "1090330"
  },
  {
    "text": "node.js plugin for Cabana which again",
    "start": "1090330",
    "end": "1095910"
  },
  {
    "text": "falls into the category of extreme extensible programmable interface that we are actually adhering to in our",
    "start": "1095910",
    "end": "1103070"
  },
  {
    "text": "framework and it actually works in three main steps so we have a watcher",
    "start": "1103070",
    "end": "1109830"
  },
  {
    "text": "configured in our Sentinel which in the scheduled interval of time sends out a",
    "start": "1109830",
    "end": "1116669"
  },
  {
    "text": "request to the elastic DB with a script and events this script is executed and",
    "start": "1116669",
    "end": "1123720"
  },
  {
    "text": "then we can actually it will it will either give a positive or a negative response and if in case the response is",
    "start": "1123720",
    "end": "1131280"
  },
  {
    "text": "positive or if there's an alert that need to be triggered so the action is taken and alert is triggered you can",
    "start": "1131280",
    "end": "1137429"
  },
  {
    "text": "also configure reports in Sentinel and schedule the interval when the report need to be generated and send out to the",
    "start": "1137429",
    "end": "1144419"
  },
  {
    "text": "ops or the business teams not with you",
    "start": "1144419",
    "end": "1155010"
  },
  {
    "text": "know you have the author lab with you know it may be in your email and so using that particular outlier detail the",
    "start": "1155010",
    "end": "1162390"
  },
  {
    "text": "Sentinel pushes the the the information through the email which can now be",
    "start": "1162390",
    "end": "1168660"
  },
  {
    "text": "accessed through the URL to the Zipkin visualization so it this is what the",
    "start": "1168660",
    "end": "1176640"
  },
  {
    "text": "main screen in the Zipkin UI which actually gives us the service dependency",
    "start": "1176640",
    "end": "1182850"
  },
  {
    "text": "as well as you can capture the latency with respect to each of the services that I",
    "start": "1182850",
    "end": "1188210"
  },
  {
    "text": "being invoked in that particular request and Zipkin has a direct integration with",
    "start": "1188210",
    "end": "1195130"
  },
  {
    "text": "Cabana UI so you can actually then with",
    "start": "1195130",
    "end": "1200990"
  },
  {
    "text": "a click of button you can go to Cabana UI asper the URL that you have configured it you can go to a business",
    "start": "1200990",
    "end": "1206960"
  },
  {
    "text": "view as per the URL that you have configured or to an ops view",
    "start": "1206960",
    "end": "1213040"
  },
  {
    "text": "so so now so this this is how we actually have configured all the",
    "start": "1213040",
    "end": "1220010"
  },
  {
    "text": "components in our stack for the unified monitoring so I know jump onto the",
    "start": "1220010",
    "end": "1229850"
  },
  {
    "text": "solution demonstration",
    "start": "1229850",
    "end": "1233380"
  },
  {
    "text": "so now as we have seen that the main API",
    "start": "1248340",
    "end": "1253420"
  },
  {
    "text": "that we wanted to monitor was the the the pradhan for api of the micro",
    "start": "1253420",
    "end": "1260530"
  },
  {
    "text": "services use case that we had picked up for the online e-commerce application so",
    "start": "1260530",
    "end": "1266200"
  },
  {
    "text": "we will cater to three different features in our solution demonstration",
    "start": "1266200",
    "end": "1271780"
  },
  {
    "text": "this is more of a require this is a recorded demonstration because there's a lot of moving part and there are some",
    "start": "1271780",
    "end": "1278250"
  },
  {
    "text": "emails that need to be accessed and thus",
    "start": "1278250",
    "end": "1283390"
  },
  {
    "text": "we have recorded this demo so the first one would be more about the the unified",
    "start": "1283390",
    "end": "1289120"
  },
  {
    "text": "monitoring of containers and micro services in a kubernetes cluster the second one would be about the",
    "start": "1289120",
    "end": "1296010"
  },
  {
    "text": "distributed tracing and third is we will identify we will introduce an anomaly in",
    "start": "1296010",
    "end": "1301380"
  },
  {
    "text": "one of the services and try to figure out through our unified monitoring",
    "start": "1301380",
    "end": "1306990"
  },
  {
    "text": "framework in a more proactive manner",
    "start": "1306990",
    "end": "1311429"
  },
  {
    "text": "so this is the microservices at rest so we have this is a Cabana UI at as of now",
    "start": "1318210",
    "end": "1325990"
  },
  {
    "text": "the cluster is the kubernetes cluster is done so we have all the metrics shown as",
    "start": "1325990",
    "end": "1331720"
  },
  {
    "text": "zero like the nodes that the deployment containers and the libel pods then we",
    "start": "1331720",
    "end": "1338649"
  },
  {
    "text": "will start up our the kubernetes cluster and we have provided the size s3 and we",
    "start": "1338649",
    "end": "1353769"
  },
  {
    "text": "can see all the pods and all the different deployments that are present",
    "start": "1353769",
    "end": "1362440"
  },
  {
    "text": "in that particular trust cluster with the few of the pods in the cube system and most of the application-specific",
    "start": "1362440",
    "end": "1369190"
  },
  {
    "text": "pods are in the default namespace and we",
    "start": "1369190",
    "end": "1375100"
  },
  {
    "text": "can see there are three nodes up and running and now if we go to our the kubernetes overview dashboard we can see",
    "start": "1375100",
    "end": "1382600"
  },
  {
    "text": "that there are three nodes running with the 20 pods and 14 deployments and there",
    "start": "1382600",
    "end": "1388659"
  },
  {
    "text": "are 25 containers and so again this",
    "start": "1388659",
    "end": "1394720"
  },
  {
    "text": "kevanna dashboard is highly customizable so we have picked and choose those particular metrics which we wanted to",
    "start": "1394720",
    "end": "1401830"
  },
  {
    "text": "showcase for this particular solution demonstration but you can actually get",
    "start": "1401830",
    "end": "1408190"
  },
  {
    "text": "other charts and graphs in here as per your needs so this is for the that it",
    "start": "1408190",
    "end": "1414820"
  },
  {
    "text": "gives us the top nodes by memory usage so we have three node lustre in which it",
    "start": "1414820",
    "end": "1420429"
  },
  {
    "text": "is we are having the three nodes with the memory usage Pro displayed with them",
    "start": "1420429",
    "end": "1425880"
  },
  {
    "text": "and it gives us the information regarding the net by node and",
    "start": "1425880",
    "end": "1431320"
  },
  {
    "text": "network out for each of the three nodes and then we go to the parts like the",
    "start": "1431320",
    "end": "1437740"
  },
  {
    "text": "second tab is for the pods overview so it will give all the parts that are running in your cluster and",
    "start": "1437740",
    "end": "1443910"
  },
  {
    "text": "on the right hand side it lists outs all the pods that are running the prod review service the detailed service and",
    "start": "1443910",
    "end": "1453200"
  },
  {
    "text": "then we since we are looking more from the perspective of memory and the CPI",
    "start": "1453290",
    "end": "1458370"
  },
  {
    "text": "utilization in our use case so we have listed on the top memory intensive parts",
    "start": "1458370",
    "end": "1464460"
  },
  {
    "text": "and the top CPU intensive parts and this",
    "start": "1464460",
    "end": "1471600"
  },
  {
    "text": "is the cloud tagging of all the contain all the containers that are running in",
    "start": "1471600",
    "end": "1476760"
  },
  {
    "text": "our cluster and finally we can also see what are the top and CPU intensive",
    "start": "1476760",
    "end": "1483600"
  },
  {
    "text": "containers and the top memory usage for by the containers so again as I said",
    "start": "1483600",
    "end": "1489060"
  },
  {
    "text": "like all the graphs are customizable so this is again more with respect to the use case that we have picked up for",
    "start": "1489060",
    "end": "1496050"
  },
  {
    "text": "demonstration so now we can go to a port",
    "start": "1496050",
    "end": "1507270"
  },
  {
    "text": "for a specific node so we will we can actually drill down from a node level go",
    "start": "1507270",
    "end": "1513570"
  },
  {
    "text": "to a pot level and in that particular part we can actually figure out what are what which container is running so we",
    "start": "1513570",
    "end": "1521370"
  },
  {
    "text": "can in that particular node we see that the the list of memory intensive ports",
    "start": "1521370",
    "end": "1528000"
  },
  {
    "text": "the Zeppelin deployment the prod detail service similarly we we can see this top",
    "start": "1528000",
    "end": "1534060"
  },
  {
    "text": "CPU intensive ports and in that particular part the the one which we",
    "start": "1534060",
    "end": "1539820"
  },
  {
    "text": "have selected the prod detail service is the container that is running and it",
    "start": "1539820",
    "end": "1547440"
  },
  {
    "text": "gives us the the CPU information as well as the memory usage information for that",
    "start": "1547440",
    "end": "1554940"
  },
  {
    "text": "particular container and port so now we'll go into the distributed tracing",
    "start": "1554940",
    "end": "1562110"
  },
  {
    "text": "part wherein so this is the URL which which is accessible for the pradhan for",
    "start": "1562110",
    "end": "1569100"
  },
  {
    "text": "API and now once we have make up quite a few",
    "start": "1569100",
    "end": "1574340"
  },
  {
    "text": "number of requests on that particular API we can go to the Zipkin and a zip in zip again we can actually see the the",
    "start": "1574340",
    "end": "1581690"
  },
  {
    "text": "traceability with respect to the protein for API lock what all services are being called internally for that particular",
    "start": "1581690",
    "end": "1589010"
  },
  {
    "text": "service and we can see that as of now",
    "start": "1589010",
    "end": "1595010"
  },
  {
    "text": "the the total time for the response was around seven twenty 21 milliseconds and",
    "start": "1595010",
    "end": "1602350"
  },
  {
    "text": "then we can go into the detail of this particular service and we can capture",
    "start": "1602350",
    "end": "1609260"
  },
  {
    "text": "the trace ID so these are all the information captured by these pin",
    "start": "1609260",
    "end": "1614540"
  },
  {
    "text": "emitters and pushed it into the the elastic DV through the Zipkin collector",
    "start": "1614540",
    "end": "1620000"
  },
  {
    "text": "and know if we utilize this particular trace ID and go into our the container",
    "start": "1620000",
    "end": "1628490"
  },
  {
    "text": "tab in our Cabana dashboard we can actually see that the entire information",
    "start": "1628490",
    "end": "1635720"
  },
  {
    "text": "is also captured in Cabana with respect to all these services and we can see on",
    "start": "1635720",
    "end": "1642440"
  },
  {
    "text": "the right-hand side what is the kind of the services whether it is a server or client because internally those services",
    "start": "1642440",
    "end": "1648380"
  },
  {
    "text": "are calling a MongoDB which is the storage for them so whenever it calls a",
    "start": "1648380",
    "end": "1655850"
  },
  {
    "text": "MongoDB tax as a flying for as for those services and so so this is the pradhan",
    "start": "1655850",
    "end": "1666620"
  },
  {
    "text": "for service which i was talking about and this is the normal trend which we",
    "start": "1666620",
    "end": "1672770"
  },
  {
    "text": "have captured for the last twenty to fifty days this is the trend which we have simulated through jmeter as to",
    "start": "1672770",
    "end": "1679250"
  },
  {
    "text": "initially in the in the any initial part of the day the the we have a quite less",
    "start": "1679250",
    "end": "1686750"
  },
  {
    "text": "number of requests that are coming in and slowly those requests are going up and it is more about the HTTP code 200",
    "start": "1686750",
    "end": "1693440"
  },
  {
    "text": "and it Peaks up at around 4 to 5 p.m. and then slowly tapers down during the",
    "start": "1693440",
    "end": "1699500"
  },
  {
    "text": "phagon of the day and then we pass it on that",
    "start": "1699500",
    "end": "1704720"
  },
  {
    "text": "particular information to our to our apache spark outlier detection of the",
    "start": "1704720",
    "end": "1711830"
  },
  {
    "text": "predictive analysis framework and this is where we utilize the came in cluster",
    "start": "1711830",
    "end": "1716870"
  },
  {
    "text": "and those red spots are the centroid for our for our cluster so we have",
    "start": "1716870",
    "end": "1722539"
  },
  {
    "text": "configured for as the cluster again this is more about the intuition or the",
    "start": "1722539",
    "end": "1727720"
  },
  {
    "text": "business and the technical team who can come up as to decide how many clusters need to be configured for your",
    "start": "1727720",
    "end": "1734000"
  },
  {
    "text": "particular model and now we have the clusters configured we have four",
    "start": "1734000",
    "end": "1739070"
  },
  {
    "text": "different clusters with the centroid available in them and then we will",
    "start": "1739070",
    "end": "1744220"
  },
  {
    "text": "configure the alert in a sentinel so as I have said the Sentinel has Watchers",
    "start": "1744220",
    "end": "1751549"
  },
  {
    "text": "alarms and reports so we are configuring up pradhan for service anomaly which",
    "start": "1751549",
    "end": "1756620"
  },
  {
    "text": "will run in every five minute and there's a script which it needs to",
    "start": "1756620",
    "end": "1762470"
  },
  {
    "text": "invoke in every five minute and if there is a positive response then it will send",
    "start": "1762470",
    "end": "1767840"
  },
  {
    "text": "out a report and an alert as configured in the system and finally we will",
    "start": "1767840",
    "end": "1774380"
  },
  {
    "text": "introduce some anomaly so this is my prod review service and I am introducing an anomaly with respect to the memory",
    "start": "1774380",
    "end": "1781789"
  },
  {
    "text": "conception I have written a small piece of code which actually runs which",
    "start": "1781789",
    "end": "1787130"
  },
  {
    "text": "actually eats up one zero four bytes till the entire memory for that",
    "start": "1787130",
    "end": "1792559"
  },
  {
    "text": "particular node is not exhausted and then I'll deploy that particular I'll",
    "start": "1792559",
    "end": "1799669"
  },
  {
    "text": "build it up and push it into a docker hub and this is my deployment script in",
    "start": "1799669",
    "end": "1805130"
  },
  {
    "text": "kubernetes for prod review service alright as of now we have the version",
    "start": "1805130",
    "end": "1810980"
  },
  {
    "text": "9.0 running and then I I I'll change the",
    "start": "1810980",
    "end": "1816049"
  },
  {
    "text": "image for that particular deployment from 9.0 to 10.0 the one which we have",
    "start": "1816049",
    "end": "1822140"
  },
  {
    "text": "pushed into the talker and make some it requests through our browser and even",
    "start": "1822140",
    "end": "1828409"
  },
  {
    "text": "through jmeter scripts so that we are creating a right",
    "start": "1828409",
    "end": "1834140"
  },
  {
    "text": "kind of anomaly and at that particular time through the Sentinel and alert is sent",
    "start": "1834140",
    "end": "1840190"
  },
  {
    "text": "across as an email to our to our inbox and here we have to do two emails one is",
    "start": "1840190",
    "end": "1847300"
  },
  {
    "text": "the report and other is the alert so in the report it gives out the current",
    "start": "1847300",
    "end": "1852990"
  },
  {
    "text": "status of your system and again you can sell since the it is running on phantom",
    "start": "1852990",
    "end": "1860470"
  },
  {
    "text": "JSU you can configure which part of your Cabana dashboard that you want to push",
    "start": "1860470",
    "end": "1866020"
  },
  {
    "text": "it on to your email inbox as a as a as a snapshot and the second is the alert",
    "start": "1866020",
    "end": "1874240"
  },
  {
    "text": "this is the actual alert for that particular time window in which there was an anomaly detected and if you click",
    "start": "1874240",
    "end": "1881860"
  },
  {
    "text": "on this particular alert it takes you directly to the second UI and here we can actually see that the pradhan for",
    "start": "1881860",
    "end": "1888430"
  },
  {
    "text": "service the latency has increased from 0.78 millisecond which was earlier to",
    "start": "1888430",
    "end": "1895330"
  },
  {
    "text": "around 13 second as of law and and if we",
    "start": "1895330",
    "end": "1902590"
  },
  {
    "text": "drill down further we can actually see that the prod product reveiw service the",
    "start": "1902590",
    "end": "1909340"
  },
  {
    "text": "gate rating count is actually taking up the most amount of time and then we we",
    "start": "1909340",
    "end": "1916480"
  },
  {
    "text": "can actually see the trace ID capture the trace ID and then this we have a",
    "start": "1916480",
    "end": "1921700"
  },
  {
    "text": "link of this logs length which if I click on it it will directly take you to",
    "start": "1921700",
    "end": "1927280"
  },
  {
    "text": "the Cabana UI and there we can actually see which particular service is taking",
    "start": "1927280",
    "end": "1935140"
  },
  {
    "text": "most of the time and it also lists out the other services which are part of that particular API invocation and we",
    "start": "1935140",
    "end": "1943720"
  },
  {
    "text": "can we have listed down we have figured out that this is the particular part and",
    "start": "1943720",
    "end": "1949080"
  },
  {
    "text": "this is the particular container which is which is creating that but that",
    "start": "1949080",
    "end": "1955420"
  },
  {
    "text": "outlier now if we go to the pods overview and try to see what is the",
    "start": "1955420",
    "end": "1960850"
  },
  {
    "text": "status so we can see that the prod review service is actually consuming around 2.2 GB of RAM earlier it was",
    "start": "1960850",
    "end": "1968380"
  },
  {
    "text": "around 800 MB and then if we drill down further we can",
    "start": "1968380",
    "end": "1974580"
  },
  {
    "text": "within the container also we can see that the CPU is picking up and also the",
    "start": "1974580",
    "end": "1979980"
  },
  {
    "text": "memory is pretty high compared to the normal scenario when the prodigy service was working in a correct manner and then",
    "start": "1979980",
    "end": "1989010"
  },
  {
    "text": "we can actually roll out that particular image which we had deployed from 10.0 to",
    "start": "1989010",
    "end": "1996930"
  },
  {
    "text": "9.0 and if we go back to the current status after the the the deployment has",
    "start": "1996930",
    "end": "2005780"
  },
  {
    "text": "been backed out from 10.0 to 9.0 we can see that law the proud of your service",
    "start": "2005780",
    "end": "2011030"
  },
  {
    "text": "memory consumption is within the limit of 846 MB and the other CPU and the",
    "start": "2011030",
    "end": "2018680"
  },
  {
    "text": "memory metrics are also well within the range so yeah so this is what we wanted",
    "start": "2018680",
    "end": "2028310"
  },
  {
    "text": "to showcase as to how the the unified",
    "start": "2028310",
    "end": "2033770"
  },
  {
    "text": "monitoring framework we are utilizing all the the the component with respect",
    "start": "2033770",
    "end": "2040250"
  },
  {
    "text": "to the elastic amana Zipkin distributed logging apache spark and",
    "start": "2040250",
    "end": "2047220"
  },
  {
    "text": "helping us in our proactive issue detection and also for monitoring of our",
    "start": "2047220",
    "end": "2052720"
  },
  {
    "text": "clusters so that's it so then with the",
    "start": "2052720",
    "end": "2062610"
  },
  {
    "text": "session so if we have any questions",
    "start": "2062610",
    "end": "2067590"
  },
  {
    "text": "[Applause]",
    "start": "2069090",
    "end": "2077590"
  },
  {
    "text": "again like with respect to the we wanted to monitor the entire ecosystem of an",
    "start": "2089610",
    "end": "2095740"
  },
  {
    "text": "enterprise and we wanted to make sure that even the visa we didn't want it",
    "start": "2095740",
    "end": "2103120"
  },
  {
    "text": "only to limit ourselves within the you can say the kubernetes or that",
    "start": "2103120",
    "end": "2108250"
  },
  {
    "text": "particular ecosystem so in order to monitor the entire enterprise which can",
    "start": "2108250",
    "end": "2113950"
  },
  {
    "text": "have private data centers applications which are running on bare metal and we",
    "start": "2113950",
    "end": "2119170"
  },
  {
    "text": "also had a very very kind of very very",
    "start": "2119170",
    "end": "2124630"
  },
  {
    "text": "good you can say the performance with related to elastic DB so we took up this",
    "start": "2124630",
    "end": "2130600"
  },
  {
    "text": "particular approach",
    "start": "2130600",
    "end": "2133380"
  },
  {
    "text": "hello over here over here sorry yeah",
    "start": "2138910",
    "end": "2145030"
  },
  {
    "text": "can you give us some more specific examples of like how you have used spark machine learning predictive modeling to",
    "start": "2145030",
    "end": "2151930"
  },
  {
    "text": "solve the problem I hear you mentioned like you have used like a k-means exact",
    "start": "2151930",
    "end": "2157500"
  },
  {
    "text": "connects in a business terms like for example I have an application which are",
    "start": "2157500",
    "end": "2162880"
  },
  {
    "text": "micro-services can you speak about what's the problem is and how it is",
    "start": "2162880",
    "end": "2168340"
  },
  {
    "text": "solved yeah so so so what we targeted this was you can say that this is not a",
    "start": "2168340",
    "end": "2173620"
  },
  {
    "text": "multivariate model that we had created this was a single variant just for the demonstration purpose but again you can",
    "start": "2173620",
    "end": "2180370"
  },
  {
    "text": "have mobility you can have a combination of latency you can have a condemnation of HTTP status code and also the time",
    "start": "2180370",
    "end": "2186880"
  },
  {
    "text": "window in which that particular data data you are actually capturing and then you can have a normal trend and then use",
    "start": "2186880",
    "end": "2194620"
  },
  {
    "text": "a came in cluster again again this when we have used the caming clustering in Apache it is more of a Spock it is more",
    "start": "2194620",
    "end": "2201550"
  },
  {
    "text": "about the intuition with which we we capture that K value so so for us it was",
    "start": "2201550",
    "end": "2207820"
  },
  {
    "text": "more about capturing the latency the HTTP status code and the time window in",
    "start": "2207820",
    "end": "2213730"
  },
  {
    "text": "which those particular parameters are captured and then we passed it on to create of specific clusters and this is",
    "start": "2213730",
    "end": "2221230"
  },
  {
    "text": "more about the application status at a particular time with respect to latency",
    "start": "2221230",
    "end": "2227800"
  },
  {
    "text": "and the HTTP code so that is what we were targeting thank you and my second",
    "start": "2227800",
    "end": "2234220"
  },
  {
    "text": "question is on Cabana - boats I mean do you have any standard configurations or",
    "start": "2234220",
    "end": "2239620"
  },
  {
    "text": "like do you have to create those - boats explicitly see them for most of the",
    "start": "2239620",
    "end": "2245310"
  },
  {
    "text": "metrics and in logs there are default dashboard available provided by Cabana",
    "start": "2245310",
    "end": "2252430"
  },
  {
    "text": "and if you want to be more intuitive and you want to get more insights into the",
    "start": "2252430",
    "end": "2257590"
  },
  {
    "text": "data then you can easily create those dashboards with all the metrics and the logs information that are captured so it",
    "start": "2257590",
    "end": "2263890"
  },
  {
    "text": "is very easy like I am NOT having a background of Cabana but again when I",
    "start": "2263890",
    "end": "2270760"
  },
  {
    "text": "started working on unified monitoring it was pretty intuitive more of a dragon dog kind of stuff so my name is Andy",
    "start": "2270760",
    "end": "2280060"
  },
  {
    "text": "Santos I work for eBay right I'm actually one of my team actually focuses on exactly the same thing which is the",
    "start": "2280060",
    "end": "2285790"
  },
  {
    "text": "observability right so coming back to Cabana we actually keep Ana has this limitation because they have to license called ex",
    "start": "2285790",
    "end": "2292000"
  },
  {
    "text": "back so they're trying to get from the open source into the into more commercial right so there are certain",
    "start": "2292000",
    "end": "2297790"
  },
  {
    "text": "plugins they are not keeping as an open source but we internally we actually contribute it back we have an open",
    "start": "2297790",
    "end": "2304900"
  },
  {
    "text": "source tab but we actually created a lot of plugins for example if you wanted to create like a tail command prompt with a",
    "start": "2304900",
    "end": "2310630"
  },
  {
    "text": "little banner you don't have a way to do that but we created a plug-in to do that it's actually pretty simple to do you can use JavaScript to do a lot of this",
    "start": "2310630",
    "end": "2317410"
  },
  {
    "text": "one for someone other one is that we find it interesting is that you'd want it to do a heat map right within the",
    "start": "2317410",
    "end": "2323320"
  },
  {
    "text": "bigger clusters right how do you see like the density of the deployment stuff like that you can do a heat map and we",
    "start": "2323320",
    "end": "2328870"
  },
  {
    "text": "have the code that does that will be more happy to share it but the other thing that I have a question is there",
    "start": "2328870",
    "end": "2335260"
  },
  {
    "text": "what is the skill that we deal with and I'm actually interested to see how we can potentially collaborate and open",
    "start": "2335260",
    "end": "2340300"
  },
  {
    "text": "source that because we actually dealing with a much larger scale there we've done this architecture peep or a so our",
    "start": "2340300",
    "end": "2347830"
  },
  {
    "text": "scale is about 10 million matrix per second okay from the locks eyes with dealing with about 10 petabytes a day and this is not",
    "start": "2347830",
    "end": "2356170"
  },
  {
    "text": "just the infrastructure but the entire application that runs with an ebay train so what we were forced to do is that if",
    "start": "2356170",
    "end": "2363070"
  },
  {
    "text": "you rely on the elastic search databases by itself it's not gonna scale you found that out the hard way so one way is push",
    "start": "2363070",
    "end": "2371200"
  },
  {
    "text": "it onto influx DV so well we didn't like influx TV because they also went from",
    "start": "2371200",
    "end": "2376420"
  },
  {
    "text": "the open source so we decided so on the high level up emoting happy to go in",
    "start": "2376420",
    "end": "2381550"
  },
  {
    "text": "details so we actually split this into two different stories one is a hot air and the other one is called here dry the",
    "start": "2381550",
    "end": "2388240"
  },
  {
    "text": "hot air is anything within let's say two weeks you can define that depending on how much one are you willing to do that",
    "start": "2388240",
    "end": "2393520"
  },
  {
    "text": "right yeah and then the coastal rates are something that for metrics we store it in the open tsdp",
    "start": "2393520",
    "end": "2399220"
  },
  {
    "text": "all right open source and then for los we store it into the Hadoop right on the",
    "start": "2399220",
    "end": "2404260"
  },
  {
    "text": "hot storage for matrix we sleep are we added a few things so one",
    "start": "2404260",
    "end": "2409310"
  },
  {
    "text": "of them is there is an Apache foundation called ignite basically in a store a lot of this metrics that in memory so super",
    "start": "2409310",
    "end": "2415970"
  },
  {
    "text": "pass if you wanted to do something within the sub seconds right there is not a one call from Facebook or parent J",
    "start": "2415970",
    "end": "2422420"
  },
  {
    "text": "they also kind of you know does the Delta compressions also that we can evaluating okay on the log size we do to",
    "start": "2422420",
    "end": "2429980"
  },
  {
    "text": "use elastic search for short you know duration of the data but for the longer",
    "start": "2429980",
    "end": "2435800"
  },
  {
    "text": "duration of data as I said we used a tube right there is also another startup company that I know we actually working",
    "start": "2435800",
    "end": "2442910"
  },
  {
    "text": "with them called a space they're basically claiming that they can actually take the elastic into ten times",
    "start": "2442910",
    "end": "2447920"
  },
  {
    "text": "of the performance yeah so I'm writing my own is that there is a lot of like",
    "start": "2447920",
    "end": "2454430"
  },
  {
    "text": "company that interested so we do with this you can actually collaborate together because EPA doesn't plan to make it into any kind of product which",
    "start": "2454430",
    "end": "2461240"
  },
  {
    "text": "me more than happy to do some sort of open source collaboration gorilla or",
    "start": "2461240",
    "end": "2468920"
  },
  {
    "text": "Perrin J does the saute to a time series the custom-designed this one so they can",
    "start": "2468920",
    "end": "2475340"
  },
  {
    "text": "still load everything in the memory into a delta delta compression so the amount memory that you can use is actually can",
    "start": "2475340",
    "end": "2481160"
  },
  {
    "text": "be maximized to actual store their error yeah",
    "start": "2481160",
    "end": "2485770"
  },
  {
    "text": "no no we are not using any any closed product so that is the reason we went",
    "start": "2491359",
    "end": "2498329"
  },
  {
    "text": "about using sentinel so sentinel again is an open source Apache 2 license we",
    "start": "2498329",
    "end": "2504119"
  },
  {
    "text": "didn't use expects that's why we introduced Apache spark so our entire fire monitoring framework is an open",
    "start": "2504119",
    "end": "2511349"
  },
  {
    "text": "source ok so again we have a get separate plugin for that we are not at",
    "start": "2511349",
    "end": "2518159"
  },
  {
    "text": "all using x-pac because that is the the boundary in which we need to work of open standard and open source so we have",
    "start": "2518159",
    "end": "2524429"
  },
  {
    "text": "our own plugin for which we do the access when they are back specifically",
    "start": "2524429",
    "end": "2530599"
  },
  {
    "text": "yeah I hate to end this session but the next speaker is here for the next",
    "start": "2530599",
    "end": "2536279"
  },
  {
    "text": "station they didn't give y'all enough time there to transition you I'm sorry",
    "start": "2536279",
    "end": "2542740"
  },
  {
    "text": "[Applause]",
    "start": "2542740",
    "end": "2545960"
  }
]
[
  {
    "start": "0",
    "end": "52000"
  },
  {
    "text": "okay it's free minutes after the scheduled time so let's start hello everyone my name is Marty Vegas and I am",
    "start": "0",
    "end": "6750"
  },
  {
    "text": "very happy to welcome you on the introduction to auto-scale I'm not sure",
    "start": "6750",
    "end": "12360"
  },
  {
    "text": "about you but I love late-november everything is starting to slow down and people begin to switch their focus from",
    "start": "12360",
    "end": "19619"
  },
  {
    "text": "Jodhpur related topics to something a little bit more pleasant like best",
    "start": "19619",
    "end": "25199"
  },
  {
    "text": "recipes for Thanksgiving dinner choosing Christmas present for the loved ones planning New Year's party hunting",
    "start": "25199",
    "end": "32250"
  },
  {
    "text": "for the best black friday cyber monday deals are simply thinking how to use the",
    "start": "32250",
    "end": "37500"
  },
  {
    "text": "remaining of their paid time off and the last thing you would like to get during Thanksgiving Christmas Black Friday or",
    "start": "37500",
    "end": "44399"
  },
  {
    "text": "vacation or actually at any time is an other court that you'll cluster has",
    "start": "44399",
    "end": "50309"
  },
  {
    "text": "problems so you prepare you are logging monitoring alerting you check whether",
    "start": "50309",
    "end": "57329"
  },
  {
    "text": "your applications are well configured you do load test and analyze traffic first to validate the apps themselves",
    "start": "57329",
    "end": "64518"
  },
  {
    "text": "but also to answer questions like how many pots should I have in my deployment",
    "start": "64519",
    "end": "71479"
  },
  {
    "text": "how big the pots should be how much resources do I need in my cluster and",
    "start": "71479",
    "end": "79070"
  },
  {
    "text": "these are not easy questions of course lots of measurements tests checks and",
    "start": "79070",
    "end": "85670"
  },
  {
    "text": "what difference can be performed however most of technical people don't have",
    "start": "85670",
    "end": "90720"
  },
  {
    "text": "strong clairvoyant skills and life will always find a way to surprise you proper",
    "start": "90720",
    "end": "97350"
  },
  {
    "text": "pot count for today may be too little for tomorrow when the traffic increases and absent-minded developer may forget",
    "start": "97350",
    "end": "104130"
  },
  {
    "text": "to mention that they increase the cash in the application ten times just to be on the safe side on Black Friday and now",
    "start": "104130",
    "end": "111270"
  },
  {
    "text": "the app is starting to throwing out a few more exception someone may start another workload in the cluster",
    "start": "111270",
    "end": "117540"
  },
  {
    "text": "depleting its capacity and you will be called to fix it according to Murphy's laws more likely",
    "start": "117540",
    "end": "124469"
  },
  {
    "text": "at the worst possible time and obviously you don't want to be woken up in the",
    "start": "124469",
    "end": "130470"
  },
  {
    "text": "middle of the night or interrupted during vacation you would like to have an automation a",
    "start": "130470",
    "end": "135650"
  },
  {
    "text": "robot would observe your cluster and add or remove a computational capacity when",
    "start": "135650",
    "end": "140930"
  },
  {
    "text": "needed to keep your workloads healthy and at the same time to keep your",
    "start": "140930",
    "end": "146060"
  },
  {
    "text": "monthly bills low lucky for you we have a couple of such robots in kubernetes",
    "start": "146060",
    "end": "151640"
  },
  {
    "text": "and now I'm going to describe them to you the first robot is called horizontal",
    "start": "151640",
    "end": "157489"
  },
  {
    "start": "155000",
    "end": "522000"
  },
  {
    "text": "pot autoscaler horizontal pot autoscaler is based on metrics that express the",
    "start": "157489",
    "end": "163400"
  },
  {
    "text": "load that the application gets it can be either CPU usage or something a little",
    "start": "163400",
    "end": "168470"
  },
  {
    "text": "bit more custom like the number of queries per second or some other gods like value provided by the user HPA",
    "start": "168470",
    "end": "177620"
  },
  {
    "text": "takes the value of the metrics compares it with the user-defined target and",
    "start": "177620",
    "end": "182890"
  },
  {
    "text": "depending on this comparison adds or removes replicas hoping to move the",
    "start": "182890",
    "end": "188510"
  },
  {
    "text": "matrix towards the desired value let's take a look on how does it work in",
    "start": "188510",
    "end": "194390"
  },
  {
    "text": "practice but before that let me clarify something while talking about HPA I will",
    "start": "194390",
    "end": "201650"
  },
  {
    "text": "use a word utilization I understand it as a ratio between the current load",
    "start": "201650",
    "end": "206950"
  },
  {
    "text": "expressed by some metrics and the maximum amount of load that the application can handle for example if a",
    "start": "206950",
    "end": "214340"
  },
  {
    "text": "pot requested one CPU and is using only 0.5 then the CPU utilization is 50% if",
    "start": "214340",
    "end": "221269"
  },
  {
    "text": "the pot can handle let's say 1000 Q PSS but is processing only 200 at this given",
    "start": "221269",
    "end": "226790"
  },
  {
    "text": "moment then the utilization is obviously 20% okay now the mentioned example on",
    "start": "226790",
    "end": "232790"
  },
  {
    "text": "this example we have four pots that are burning hot they are reporting very high",
    "start": "232790",
    "end": "238160"
  },
  {
    "text": "utilization their load is above the target they use almost all of their",
    "start": "238160",
    "end": "243590"
  },
  {
    "text": "capacity should the traffic increase there might not be enough computing power to handle it if we add another pot",
    "start": "243590",
    "end": "253040"
  },
  {
    "text": "then the same traffic will be spread across five pots then the average per",
    "start": "253040",
    "end": "258889"
  },
  {
    "text": "pot load will obviously decrease leaving more space for the spikes and coming closer to the desired target",
    "start": "258889",
    "end": "266389"
  },
  {
    "text": "if the situation is slightly different and for each of the pots the load is",
    "start": "266389",
    "end": "272520"
  },
  {
    "text": "below the target then it might be actually beneficial to delete one of the",
    "start": "272520",
    "end": "277680"
  },
  {
    "text": "pots then the traffic on the remaining pots will increase the pots will be better utilized and you will have more",
    "start": "277680",
    "end": "283889"
  },
  {
    "text": "free resources in your cluster and this is what horizontal pot autoscaler does it adds and deletes",
    "start": "283889",
    "end": "290729"
  },
  {
    "text": "what replicas when needed when to use horizontal pot autoscaler",
    "start": "290729",
    "end": "295910"
  },
  {
    "text": "horizontal path autoscaler weren't the best we've stated serving workers that can spin up in replicas reasonably fast",
    "start": "295910",
    "end": "301789"
  },
  {
    "text": "you can also use for example autoscaler with other workers like something related to Cubase processing and so on",
    "start": "301789",
    "end": "309110"
  },
  {
    "text": "how to enable it horizontal photo scanner is a part of core kubernetes api",
    "start": "309110",
    "end": "314310"
  },
  {
    "text": "s-- HPS is controlled by an HP object you created this object either we",
    "start": "314310",
    "end": "320630"
  },
  {
    "text": "manually with providing here mode definition or by cube outer scale command cpu utilization auto scaling is",
    "start": "320630",
    "end": "329190"
  },
  {
    "text": "available out of the box custom metrics require a little bit more work please check the documentation for",
    "start": "329190",
    "end": "334830"
  },
  {
    "text": "details while setting up HPA it is crucial to set the target value or a",
    "start": "334830",
    "end": "341330"
  },
  {
    "text": "more general target utilization right one - utilization is your spike capacity",
    "start": "341330",
    "end": "348389"
  },
  {
    "text": "and the driver for scallops - small buffer made prevent scallops and may",
    "start": "348389",
    "end": "355259"
  },
  {
    "text": "overload your application too big obviously causes a waste the value of",
    "start": "355259",
    "end": "361080"
  },
  {
    "text": "the target utilization should allow you to run with the increased traffic but with the old",
    "start": "361080",
    "end": "367680"
  },
  {
    "text": "number of replicas for let's say two three minutes and still have a bit of buffer so if you expect that within any",
    "start": "367680",
    "end": "375539"
  },
  {
    "text": "two minutes your traffic may rise by let's say 50% then you should set target",
    "start": "375539",
    "end": "380550"
  },
  {
    "text": "utilization to less than 65% if it can double to less than 50% and so on what",
    "start": "380550",
    "end": "389159"
  },
  {
    "text": "are the other best practices for horizontal pot autoscaler applications under HPA should correctly",
    "start": "389159",
    "end": "398130"
  },
  {
    "text": "handle seek terms this means that after receiving this signal the application",
    "start": "398130",
    "end": "404730"
  },
  {
    "text": "should not stop immediately but finish all of the requests that are in flight and still listen for incoming connection",
    "start": "404730",
    "end": "412590"
  },
  {
    "text": "that may arrive after the pod termination begins why it takes a while",
    "start": "412590",
    "end": "418230"
  },
  {
    "text": "to update all cubed proxies and all load balancers sometimes even one minute if",
    "start": "418230",
    "end": "425460"
  },
  {
    "text": "your application dies before all queue proxies until all balancers are updated",
    "start": "425460",
    "end": "430980"
  },
  {
    "text": "I mean your replica dies before all queue proxies and twelve others are updated some requests may up end up in",
    "start": "430980",
    "end": "438750"
  },
  {
    "text": "the void causing errors on the client side also neroli cos should not receive requests",
    "start": "438750",
    "end": "446550"
  },
  {
    "text": "before they are ready for that to ensure that please PLEASE setup readiness group",
    "start": "446550",
    "end": "451920"
  },
  {
    "text": "and like this prop by the way it's a good practice even without result about autoscaler but is particularly important",
    "start": "451920",
    "end": "459060"
  },
  {
    "text": "when your pots are constantly starting and stopping also please keep your",
    "start": "459060",
    "end": "465150"
  },
  {
    "text": "metrics server healthy it's the source of CPU utilization metrics and without",
    "start": "465150",
    "end": "470250"
  },
  {
    "text": "it HP a on CPU will not work last but not least please enable cluster",
    "start": "470250",
    "end": "476310"
  },
  {
    "text": "autoscaler while adding new replicas you may end up without any free capacity in",
    "start": "476310",
    "end": "481470"
  },
  {
    "text": "the cluster and you will need something to fix it up for you all talk about cost at a scalar in the moment what types of",
    "start": "481470",
    "end": "490080"
  },
  {
    "text": "savings you can expect from using horizontal portal to scalar simplifying a bit what's under HP L will request one",
    "start": "490080",
    "end": "498360"
  },
  {
    "text": "divided by the utilization target more resources that is absolutely needed to handle traffic so if you set your target",
    "start": "498360",
    "end": "505110"
  },
  {
    "text": "utilization to 65% earpods will be over provisioned by 50%",
    "start": "505110",
    "end": "510560"
  },
  {
    "text": "without HP a you will always use the same maximum amount of resources most",
    "start": "510560",
    "end": "516719"
  },
  {
    "text": "likely over-provisioned way more than 50% the second robot from our happy",
    "start": "516720",
    "end": "524910"
  },
  {
    "start": "522000",
    "end": "940000"
  },
  {
    "text": "auto-scaling family is vertical without the scalar vertical quad autoscaler",
    "start": "524910",
    "end": "531380"
  },
  {
    "text": "monitors the real CPU and memory usage as well as out of my more events to",
    "start": "531380",
    "end": "537180"
  },
  {
    "text": "estimate what should be the pod size in terms of requested CPU and memory what",
    "start": "537180",
    "end": "542700"
  },
  {
    "text": "request is used by the scheduler to decide where to put the body only machine that has enough free resources",
    "start": "542700",
    "end": "549930"
  },
  {
    "text": "can has de port what request also defines how much resources will be guaranteed to the application if it's",
    "start": "549930",
    "end": "556800"
  },
  {
    "text": "too small then the application may be trotted down or throw some out of memory",
    "start": "556800",
    "end": "562260"
  },
  {
    "text": "exceptions if it's too big then resources are obviously wasted so it's",
    "start": "562260",
    "end": "567540"
  },
  {
    "text": "important to set all requests right so what a vpat does let's take a look at",
    "start": "567540",
    "end": "575100"
  },
  {
    "text": "the example here we have a palette that uses 95% of the requested capacity for a",
    "start": "575100",
    "end": "581610"
  },
  {
    "text": "significant period of time it is definitely not a healthy situation and in this case vertical pot autoscaler",
    "start": "581610",
    "end": "588750"
  },
  {
    "text": "will recommend increasing the pot size so that the same load consume and consumes only let's say 75% of the",
    "start": "588750",
    "end": "595620"
  },
  {
    "text": "capacity not 95 in the similar fashion",
    "start": "595620",
    "end": "600930"
  },
  {
    "text": "if the load on the pot is low for an extended period of time BPA will recommend to decrease pot size",
    "start": "600930",
    "end": "607140"
  },
  {
    "text": "to free some space and allow better utilization of your machines vertical",
    "start": "607140",
    "end": "613829"
  },
  {
    "text": "path autoscaler can work in three modes in first it only provides recommendations but doesn't",
    "start": "613829",
    "end": "619740"
  },
  {
    "text": "change anything the user is responsible for setting this pot request manually in",
    "start": "619740",
    "end": "625050"
  },
  {
    "text": "the second it only said for the request on new pots it doesn't change the",
    "start": "625050",
    "end": "630260"
  },
  {
    "text": "existing pots even if they have suboptimal a request and in the last",
    "start": "630260",
    "end": "635910"
  },
  {
    "text": "mode auto VPI kills existing parts and recreate them with updated requests if",
    "start": "635910",
    "end": "643230"
  },
  {
    "text": "they have this suboptimal requests present you can use VPA",
    "start": "643230",
    "end": "650520"
  },
  {
    "text": "for both stateless and stifled workloads especially if they cannot be handled by",
    "start": "650520",
    "end": "656339"
  },
  {
    "text": "HP obviously VP is particularly useful when you have no idea how to set what",
    "start": "656339",
    "end": "662100"
  },
  {
    "text": "request right and outer mode is very handy when your application can be restarted and you",
    "start": "662100",
    "end": "668190"
  },
  {
    "text": "gained enough confidence with VP recommendations when running it in recommendations on remote vertical path",
    "start": "668190",
    "end": "675600"
  },
  {
    "text": "autoscaler is not a part of core kubernetes you either need to install it as an additional component or enable it",
    "start": "675600",
    "end": "682080"
  },
  {
    "text": "on your kubernetes managed solutions like GK with the appropriate cloud provider specific commands then you",
    "start": "682080",
    "end": "690839"
  },
  {
    "text": "create a VPN objecting to your application in a similar fashion as in HP a however there is no dedicated keep",
    "start": "690839",
    "end": "698490"
  },
  {
    "text": "CTL command yet ok now the list of best practices for",
    "start": "698490",
    "end": "704040"
  },
  {
    "text": "VPA as mentioned earlier start your adventure with VP a in recommendation",
    "start": "704040",
    "end": "709950"
  },
  {
    "text": "and in mode give it away like a day or more convince yourself that the recommendations are good and then",
    "start": "709950",
    "end": "716190"
  },
  {
    "text": "consider switching it to auto when running in auto mode set your pot",
    "start": "716190",
    "end": "721440"
  },
  {
    "text": "disruptions but budgets it will allow BPA to know how much pods can be updated",
    "start": "721440",
    "end": "728339"
  },
  {
    "text": "and killed at the same time actually you should set for disruption budgets in",
    "start": "728339",
    "end": "735480"
  },
  {
    "text": "many other situations of leaf wisdom when configuring VP a set minimum and",
    "start": "735480",
    "end": "742800"
  },
  {
    "text": "maximum container size in VP object just to be on the safe side in outage life",
    "start": "742800",
    "end": "748350"
  },
  {
    "text": "situation for example when the traffic is not coming for you to your",
    "start": "748350",
    "end": "753420"
  },
  {
    "text": "application for hours maybe even this severe outage we might reduce pot size",
    "start": "753420",
    "end": "760470"
  },
  {
    "text": "significantly and then you will have a very unpleasant surprise when the traffic suddenly is back vpf looks for a",
    "start": "760470",
    "end": "767940"
  },
  {
    "text": "longer time horizon and doesn't immediately have adjust the recommendations so after this situation",
    "start": "767940",
    "end": "773279"
  },
  {
    "text": "if you don't set minimum your hosts will be small for for first and for sometime",
    "start": "773279",
    "end": "778980"
  },
  {
    "text": "too small VP doesn't update deployment specification",
    "start": "778980",
    "end": "784140"
  },
  {
    "text": "it only update spot requests on the newly created pots in admission control change so a good practice is to put",
    "start": "784140",
    "end": "791339"
  },
  {
    "text": "reasonable pot requests taken from our example from VP recommendations in the deployment itself just in case for",
    "start": "791339",
    "end": "798460"
  },
  {
    "text": "example someone turned off VP acted accidentally VP a doesn't like huge",
    "start": "798460",
    "end": "805690"
  },
  {
    "text": "abrupt changes for example if you have 30 pots put replicas right now please",
    "start": "805690",
    "end": "811270"
  },
  {
    "text": "don't change it to five in a one step but do it gradually so that VP a can",
    "start": "811270",
    "end": "816280"
  },
  {
    "text": "adjust VP restores history a very significant change in your application",
    "start": "816280",
    "end": "822280"
  },
  {
    "text": "like completely new version completely new behavior may require a new VP a and to do it properly you should create a",
    "start": "822280",
    "end": "829330"
  },
  {
    "text": "new deployment with a slightly different label set because VP a touching spot",
    "start": "829330",
    "end": "834600"
  },
  {
    "text": "usage based on labels that they have and the period takes metrics from Martin",
    "start": "834600",
    "end": "841270"
  },
  {
    "text": "metric server so in a similar fashion as in HP a it is important to keep it healthy and in the same ways in HP a you",
    "start": "841270",
    "end": "850210"
  },
  {
    "text": "should enable cluster autoscaler in your cluster can you mix horizontal and",
    "start": "850210",
    "end": "857320"
  },
  {
    "text": "vertical but also scalar on the same workload well the short answer is no the",
    "start": "857320",
    "end": "862660"
  },
  {
    "text": "more detailed answer starts with execute cautions and it depends technically you",
    "start": "862660",
    "end": "868570"
  },
  {
    "text": "can always use VP a in recommendation mode it is saved nothing has changed and nothing bad should happen to you however",
    "start": "868570",
    "end": "875350"
  },
  {
    "text": "in order to get stable results you should either use custom metrics in HP",
    "start": "875350",
    "end": "881050"
  },
  {
    "text": "or absolute values for HP target when scaling on CPU because VP or college is",
    "start": "881050",
    "end": "887590"
  },
  {
    "text": "changing both sizes and relative values will be affected by this change when and",
    "start": "887590",
    "end": "895240"
  },
  {
    "text": "you should make sure that your application gets enough traffic a pH pH not be at its minimum number of replicas",
    "start": "895240",
    "end": "903040"
  },
  {
    "text": "all the time and then when you combine HP and VPI switching to auto is risky",
    "start": "903040",
    "end": "910600"
  },
  {
    "text": "and should be only done when you deeply understand HP i dpnt and your workload",
    "start": "910600",
    "end": "916510"
  },
  {
    "text": "cost characteristic ok few words about potential savings with vp l you only",
    "start": "916510",
    "end": "924100"
  },
  {
    "text": "request the resources that are actually needed with out of EPA you use your best gas or",
    "start": "924100",
    "end": "929790"
  },
  {
    "text": "maybe some wintering for providing pot sizes usually people significantly over",
    "start": "929790",
    "end": "936240"
  },
  {
    "text": "provisions sometimes couple times now",
    "start": "936240",
    "end": "941910"
  },
  {
    "start": "940000",
    "end": "1274000"
  },
  {
    "text": "the third and last robot cluster out a scalar horizontal and vertical pot auto",
    "start": "941910",
    "end": "948959"
  },
  {
    "text": "scalars are targeted at scaling user workloads cluster autoscaler scale is",
    "start": "948959",
    "end": "954540"
  },
  {
    "text": "the underlying computing infrastructure it provides nodes for pods that don't",
    "start": "954540",
    "end": "960300"
  },
  {
    "text": "have a place to run in the cluster it also compacts the underutilized nodes",
    "start": "960300",
    "end": "965940"
  },
  {
    "text": "it is based on scheduling simulation and declared pot requests it doesn't use any",
    "start": "965940",
    "end": "970950"
  },
  {
    "text": "matrix like actuals if you use it or I know observed QP SS so let's take a look",
    "start": "970950",
    "end": "977279"
  },
  {
    "text": "on how does it work in practice here we have four pots three pots are big one is",
    "start": "977279",
    "end": "984360"
  },
  {
    "text": "small and leave some free capacity on its node if a new pot comes then it may",
    "start": "984360",
    "end": "990779"
  },
  {
    "text": "actually fit on this Ferno and scheduler will place it there however if all nodes",
    "start": "990779",
    "end": "997290"
  },
  {
    "text": "are kind of full and the scheduler has no way of placing the pot and you notice",
    "start": "997290",
    "end": "1002870"
  },
  {
    "text": "needed and then cluster autoscaler comes into action it talks to your cloud provider and spin-ups and you note the",
    "start": "1002870",
    "end": "1011630"
  },
  {
    "text": "new node arrives and scheduler puts the appending pot on the new empty node on",
    "start": "1011630",
    "end": "1019970"
  },
  {
    "text": "some other occasion some nodes might not be utilized to their full potential like",
    "start": "1019970",
    "end": "1025130"
  },
  {
    "text": "on this picture small year ol and green pods have notes for themselves however",
    "start": "1025130",
    "end": "1030650"
  },
  {
    "text": "if we move the green pot to the third node will get a free note that can be",
    "start": "1030650",
    "end": "1036140"
  },
  {
    "text": "safely deleted like this reducing your monthly cloud provider bill and this is",
    "start": "1036140",
    "end": "1042438"
  },
  {
    "text": "exactly what cluster autoscaler does it removes and as new nodes to your cluster",
    "start": "1042439",
    "end": "1047928"
  },
  {
    "text": "as needed when to use cluster autoscaler and the short answer is always",
    "start": "1047929",
    "end": "1054080"
  },
  {
    "text": "especially when you have more than two free nodes and your cluster were close",
    "start": "1054080",
    "end": "1059120"
  },
  {
    "text": "change in time the cluster of the scaler works with multiple cloud providers we have support",
    "start": "1059120",
    "end": "1065590"
  },
  {
    "text": "for Alibaba AWS either by digital ocean Google cloud OpenStack and market plus",
    "start": "1065590",
    "end": "1072100"
  },
  {
    "text": "there are some cloud providers supported out of the core kubernetes / autoscaler repository which we seek out the scaling",
    "start": "1072100",
    "end": "1079330"
  },
  {
    "text": "don't closely follow to enable a cluster autoscaler please follow provided",
    "start": "1079330",
    "end": "1085690"
  },
  {
    "text": "specific guys some environments like GK have built in easy to switch the turnout cluster autoscaler but many require",
    "start": "1085690",
    "end": "1092560"
  },
  {
    "text": "additional manual stuff so please check the appropriate documentation for details best practice use the hosted",
    "start": "1092560",
    "end": "1100150"
  },
  {
    "text": "version of cluster autoscaler when possible pick the version of class autoscaler",
    "start": "1100150",
    "end": "1105160"
  },
  {
    "text": "that matches your cluster version they might be some subtle differences between",
    "start": "1105160",
    "end": "1110290"
  },
  {
    "text": "version of scheduler which might result in inconsistent cluster or the scaler",
    "start": "1110290",
    "end": "1115990"
  },
  {
    "text": "behavior if you take old class router scaler and put it on new cluster and",
    "start": "1115990",
    "end": "1123610"
  },
  {
    "text": "vice versa and define pod disruption budget for applications it is",
    "start": "1123610",
    "end": "1129970"
  },
  {
    "text": "particularly important for the compacting phase of cluster auto-scaling",
    "start": "1129970",
    "end": "1135250"
  },
  {
    "text": "and it controls the number of replicas that can be taken down at a given moment I mentioned Italy it with VP air but it",
    "start": "1135250",
    "end": "1143110"
  },
  {
    "text": "is also very useful here savings cluster autoscaler will drive",
    "start": "1143110",
    "end": "1150610"
  },
  {
    "text": "your cluster utilization about 10% above scale don't result which is by default",
    "start": "1150610",
    "end": "1156270"
  },
  {
    "text": "50% so utilization will get somewhere around 60 percent in terms of requested",
    "start": "1156270",
    "end": "1162580"
  },
  {
    "text": "capacity but rated as a sum of all pot requests on your node if you want to learn more how to squeeze more",
    "start": "1162580",
    "end": "1170880"
  },
  {
    "text": "performance from clusters color please come and join us on seek auto-scaling deep dive tomorrow without",
    "start": "1170880",
    "end": "1178360"
  },
  {
    "text": "clusters carry your utilization depends on your own bin packing skills and a bit",
    "start": "1178360",
    "end": "1183730"
  },
  {
    "text": "of luck unlocked cluster on average the utilization is significantly lower than it could have been with if you had",
    "start": "1183730",
    "end": "1191230"
  },
  {
    "text": "cluster autoscaler enabled as the stock is slowly getting to the end I would",
    "start": "1191230",
    "end": "1198260"
  },
  {
    "text": "like to give you a little bit more information about the seek auto-scaling itself we have meetings every Monday as",
    "start": "1198260",
    "end": "1206500"
  },
  {
    "text": "most of our contributors are in Europe the meetings are held at 4 p.m. European",
    "start": "1206500",
    "end": "1212390"
  },
  {
    "text": "time which is unfortunately 7 p.m. on the west coast and we have the meeting",
    "start": "1212390",
    "end": "1217460"
  },
  {
    "text": "so zoom the link is is here but you can also find it on our little documentation we have quite active slack channel so if",
    "start": "1217460",
    "end": "1225950"
  },
  {
    "text": "the meeting time doesn't suit you feel free to ask your questions concerns or new ideas when your your new ideas there",
    "start": "1225950",
    "end": "1233740"
  },
  {
    "text": "and most of our staff cluster autoscaler and vpa assists in kubernetes /",
    "start": "1233740",
    "end": "1240320"
  },
  {
    "text": "autoscaler repository on github HP itself is in the core kubernetes /",
    "start": "1240320",
    "end": "1245870"
  },
  {
    "text": "kubernetes repo and as I said we have sequel to scaling deep dive on Wednesday",
    "start": "1245870",
    "end": "1252950"
  },
  {
    "text": "at the 1150 my colleague vivek will tell you more about cluster autoscaler options to debug it and options to find",
    "start": "1252950",
    "end": "1259790"
  },
  {
    "text": "unity thank you this is the end of my talk and now we have couple minutes for",
    "start": "1259790",
    "end": "1265730"
  },
  {
    "text": "questions",
    "start": "1265730",
    "end": "1268240"
  },
  {
    "text": "okay do we have a mic render perfect hi",
    "start": "1273810",
    "end": "1287130"
  },
  {
    "start": "1274000",
    "end": "1397000"
  },
  {
    "text": "I'm good okay so I'm you enter from JD comm you not recommend the mixing of the",
    "start": "1287190",
    "end": "1294460"
  },
  {
    "text": "V PHP a what in your case we do see indeed in particular when we run a state for application there right we want to",
    "start": "1294460",
    "end": "1301870"
  },
  {
    "text": "do VP a first but if it exceeds the capacity of the nodes and we have to do",
    "start": "1301870",
    "end": "1307150"
  },
  {
    "text": "the HP a so I just wandering in a community and any player or you do not see a leader the Fortius a big thing of",
    "start": "1307150",
    "end": "1313930"
  },
  {
    "text": "the HTP of api even the CA and i find that the integration yes that's a no",
    "start": "1313930",
    "end": "1324160"
  },
  {
    "text": "problem so so far we have been working on graduating vp itself it has been mark",
    "start": "1324160",
    "end": "1331300"
  },
  {
    "text": "GI this summer / autumn so the next step will be to making sure that all the",
    "start": "1331300",
    "end": "1336700"
  },
  {
    "text": "environment works together right now we so far we have been focusing more on making sure that individual building",
    "start": "1336700",
    "end": "1344020"
  },
  {
    "text": "blocks are perfect so we are aware of the problems working on it hopefully we'll have some good solution nice talk",
    "start": "1344020",
    "end": "1355050"
  },
  {
    "text": "question about could you elaborate a little bit about the how does the autoscaler work in term of deaf",
    "start": "1355050",
    "end": "1361330"
  },
  {
    "text": "fragmentation assuming for example in my cluster i have large pod that consumed a",
    "start": "1361330",
    "end": "1367330"
  },
  {
    "text": "large portion of the node mix with really really small pods how because do",
    "start": "1367330",
    "end": "1373090"
  },
  {
    "text": "you understand a little bit my question [Music]",
    "start": "1373090",
    "end": "1377769"
  },
  {
    "text": "removes notes yes when it does the defragmentation or do they actually",
    "start": "1378420",
    "end": "1383620"
  },
  {
    "text": "force to evict notes from other pods or what's the life cycle when i'm trying to",
    "start": "1383620",
    "end": "1389560"
  },
  {
    "text": "compress do you have do you have free",
    "start": "1389560",
    "end": "1398590"
  },
  {
    "start": "1397000",
    "end": "1493000"
  },
  {
    "text": "time tomorrow at 11:50 yes please don't",
    "start": "1398590",
    "end": "1403750"
  },
  {
    "text": "hi question cluster out is healer you mentioned that it's providers so it's",
    "start": "1403750",
    "end": "1409480"
  },
  {
    "text": "only hosted clusters or on-prem clusters can for on-prem the situation is",
    "start": "1409480",
    "end": "1415900"
  },
  {
    "text": "different not sure how your our premise organized if you are using vmware or whatever i've",
    "start": "1415900",
    "end": "1422590"
  },
  {
    "text": "heard the dreamer of mine I mean so we're using our cluster is on AWS but it's all ec2 base so we build it our on",
    "start": "1422590",
    "end": "1429550"
  },
  {
    "text": "our own way terraforming ansible so is there any way to integrate cluster autoscaler with our automation and",
    "start": "1429550",
    "end": "1436690"
  },
  {
    "text": "utilize that or it works only with providers so we support AWS so if you're",
    "start": "1436690",
    "end": "1442480"
  },
  {
    "text": "only WS you can enable class autoscaler day and there is quite extensive",
    "start": "1442480",
    "end": "1448690"
  },
  {
    "text": "documentation how to do it on our github in our github repository and you you",
    "start": "1448690",
    "end": "1455500"
  },
  {
    "text": "were mentioning something about on print right it's not what I'm trying to say",
    "start": "1455500",
    "end": "1462640"
  },
  {
    "text": "that our cluster is not host like we use ec2 but we build it from scratch ourselves so we're not using the it oh",
    "start": "1462640",
    "end": "1469930"
  },
  {
    "text": "there's a hosted cluster okay so this okay so you can use it with purely",
    "start": "1469930",
    "end": "1475360"
  },
  {
    "text": "vanilla kubernetes you start on your own and manage on your own the sources of cluster autoscaler are freely available",
    "start": "1475360",
    "end": "1481960"
  },
  {
    "text": "so you can go there get all the either ready release or compile it by yourself",
    "start": "1481960",
    "end": "1488860"
  },
  {
    "text": "put it in your cluster and it will work thank you hi I'm getting from IBM I have",
    "start": "1488860",
    "end": "1495820"
  },
  {
    "start": "1493000",
    "end": "1617000"
  },
  {
    "text": "two questions for you one for the cluster autoscaler you mentioned it doesn't monitor foreign metrics on the",
    "start": "1495820",
    "end": "1501820"
  },
  {
    "text": "CPU or memory it notices say pending pods and you know does the scale of operation what are some of the ways or",
    "start": "1501820",
    "end": "1508570"
  },
  {
    "text": "approaches you can suggest for having the autoscaler trigger a scale-up",
    "start": "1508570",
    "end": "1513910"
  },
  {
    "text": "operation based on some sort of threshold on the CPU memory when on the cluster utilization rather than",
    "start": "1513910",
    "end": "1520210"
  },
  {
    "text": "noticing the pending parts and the the second question around the VP a memory B",
    "start": "1520210",
    "end": "1525280"
  },
  {
    "text": "let's do it one by one because I will forget what the first question was about okay sorry",
    "start": "1525280",
    "end": "1531790"
  },
  {
    "text": "yeah I have limitations so y+ autoscaler is networking on",
    "start": "1531790",
    "end": "1539649"
  },
  {
    "text": "metrics so cluster autoscaler is already complicated this and we decided that we will separate Auto scalars work out out",
    "start": "1539649",
    "end": "1547269"
  },
  {
    "text": "of scalars work on matrix because we can actually observe the matrix there and if",
    "start": "1547269",
    "end": "1555129"
  },
  {
    "text": "you want to optimize your pod shape or the number of power pods you should use",
    "start": "1555129",
    "end": "1562659"
  },
  {
    "text": "HP on or VP respectively hey Dell class autoscaler assumes that the workloads",
    "start": "1562659",
    "end": "1569230"
  },
  {
    "text": "are kind of already optimized so they are not overrunning their pottery class",
    "start": "1569230",
    "end": "1574990"
  },
  {
    "text": "and you have the correct number of them so each of the node is kind of healthy so it's not that you requested just a",
    "start": "1574990",
    "end": "1583149"
  },
  {
    "text": "half a node and here we are trying to use twice of the capacity so this is the",
    "start": "1583149",
    "end": "1589299"
  },
  {
    "text": "assumption that is in base of Castille to scalar and then we use",
    "start": "1589299",
    "end": "1595269"
  },
  {
    "text": "scheduling simulation to decide whether you will need a one extra node to handle",
    "start": "1595269",
    "end": "1601690"
  },
  {
    "text": "the pending post that you have or maybe five extra notes and decide based on",
    "start": "1601690",
    "end": "1606720"
  },
  {
    "text": "various heuristics what shape of the nodes should be if you have multiple",
    "start": "1606720",
    "end": "1612480"
  },
  {
    "text": "auto-scaling groups notice or whatever your provider has yeah thanks for the",
    "start": "1612480",
    "end": "1618309"
  },
  {
    "text": "insights on that ok second question second question on the VP a you mentioned VP it doesn't necessarily act",
    "start": "1618309",
    "end": "1624549"
  },
  {
    "text": "on the you know changing the matrix but it provides the suggestions and actually any newer started parts and in that can",
    "start": "1624549",
    "end": "1632470"
  },
  {
    "text": "be limitations if we have resource quotas based on name species and deployment level and doesn't make any",
    "start": "1632470",
    "end": "1638830"
  },
  {
    "text": "changes to the deployment itself would you suggest it is we should you know leverage VP a to make changes to the",
    "start": "1638830",
    "end": "1646059"
  },
  {
    "text": "names namespace level quota or deployment to automatically end-to-end you know leverage VP a or would it be",
    "start": "1646059",
    "end": "1653320"
  },
  {
    "text": "not a good idea so VP a does for changes before the",
    "start": "1653320",
    "end": "1658360"
  },
  {
    "text": "quota is checked so if you have quota the updated part will pass if you don't",
    "start": "1658360",
    "end": "1665019"
  },
  {
    "text": "have quota then obviously the pot will be rejected so quota is",
    "start": "1665019",
    "end": "1672320"
  },
  {
    "text": "fully for the respected and most people set up quota for in company building",
    "start": "1672320",
    "end": "1681350"
  },
  {
    "text": "reasons or to reducing the cost of final development or whatever and right now we",
    "start": "1681350",
    "end": "1688540"
  },
  {
    "text": "haven't seen much need for updating water itself in VP a what was the second",
    "start": "1688540",
    "end": "1698360"
  },
  {
    "text": "part of your question would it suggest it might be a good idea to leverage VP a to make changes to the deployment",
    "start": "1698360",
    "end": "1703430"
  },
  {
    "text": "template quotas are name so we thought about doing changes to to the deployment",
    "start": "1703430",
    "end": "1710420"
  },
  {
    "text": "however any change the deployment trigger spot recreation and it doesn't",
    "start": "1710420",
    "end": "1717110"
  },
  {
    "text": "necessary adhere to poke disruption budget so it could have more severe",
    "start": "1717110",
    "end": "1724250"
  },
  {
    "text": "effect on your deployment that you would wish so at this moment we have no plans",
    "start": "1724250",
    "end": "1730070"
  },
  {
    "text": "to update the deployments because of body disruption budget issues and",
    "start": "1730070",
    "end": "1736490"
  },
  {
    "text": "secondly deployment Stork history so every single change made to deployment",
    "start": "1736490",
    "end": "1743480"
  },
  {
    "text": "is stored there so if vertical cut out to scale are doing is doing let's say 10 updates per",
    "start": "1743480",
    "end": "1751580"
  },
  {
    "text": "day based on the changing patterns also on your valuable history would be",
    "start": "1751580",
    "end": "1758300"
  },
  {
    "text": "completely overwritten by not so wild valuable VP activity so at this moment",
    "start": "1758300",
    "end": "1767930"
  },
  {
    "text": "there is no way to change things in",
    "start": "1767930",
    "end": "1773330"
  },
  {
    "text": "deployment without writing it to the deployment history and for this and",
    "start": "1773330",
    "end": "1779900"
  },
  {
    "text": "couple of many of other reasons we decided that we will rather stick to what our base and ask users to update",
    "start": "1779900",
    "end": "1787370"
  },
  {
    "text": "the deployment by themselves but if you have strong case please come to seek out",
    "start": "1787370",
    "end": "1792410"
  },
  {
    "text": "the scaling meeting on Monday and we can discuss it further sure yeah thank you for answering thank you",
    "start": "1792410",
    "end": "1798190"
  },
  {
    "text": "hi smartass this the cluster autoscaler kill unhealthy nodes or that a different",
    "start": "1798190",
    "end": "1804799"
  },
  {
    "text": "problem cluster autoscaler will kill and healthy nodes so we monitor the",
    "start": "1804799",
    "end": "1812149"
  },
  {
    "text": "situation of the nodes and if node is unhealthy and your cluster can be scaled",
    "start": "1812149",
    "end": "1818419"
  },
  {
    "text": "also you set the min and Max cluster size accordingly we will delete the node",
    "start": "1818419",
    "end": "1825200"
  },
  {
    "text": "however if you are already at the boundary of your cluster size we will",
    "start": "1825200",
    "end": "1831679"
  },
  {
    "text": "not delete the unhealthy node and the node and I hope you know deletion will",
    "start": "1831679",
    "end": "1837169"
  },
  {
    "text": "happen I believe like 20 minutes after we spot this is not ready or something",
    "start": "1837169",
    "end": "1842659"
  },
  {
    "text": "like that okay how does the vertical pod",
    "start": "1842659",
    "end": "1849769"
  },
  {
    "text": "autoscaler and the cluster autoscaler handle different CPUs between on-prem",
    "start": "1849769",
    "end": "1854960"
  },
  {
    "text": "cloud and ec2 instances because not all CPUs are created equal",
    "start": "1854960",
    "end": "1860769"
  },
  {
    "text": "so we kind of assumed that CPUs are",
    "start": "1860769",
    "end": "1867049"
  },
  {
    "text": "equivalent in the same fashion as kubernetes system so when you request",
    "start": "1867049",
    "end": "1873909"
  },
  {
    "text": "some capacity input request you just specify one CPU you don't specify it I",
    "start": "1873909",
    "end": "1880340"
  },
  {
    "text": "don't know in meets teraflops or whatever you just say one one CPU and",
    "start": "1880340",
    "end": "1885830"
  },
  {
    "text": "you hope for the best so unfortunately we don't have any extra tolling except like what request or",
    "start": "1885830",
    "end": "1892820"
  },
  {
    "text": "maybe label SEC selector in your pots to ask for particular performance of of the",
    "start": "1892820",
    "end": "1900440"
  },
  {
    "text": "machine is there any plan on adding networkers that work it I'm not aware of",
    "start": "1900440",
    "end": "1908889"
  },
  {
    "text": "this white effort to request I don't know meets truffles with whatever inputs",
    "start": "1908889",
    "end": "1915639"
  },
  {
    "text": "but you can try to bypass it by resetting the level selector on your pot",
    "start": "1915639",
    "end": "1921860"
  },
  {
    "text": "so that this pot runs on the on the newest intel architecture and some other pots can be run",
    "start": "1921860",
    "end": "1927450"
  },
  {
    "text": "some older stuff in case of H behave and",
    "start": "1927450",
    "end": "1936000"
  },
  {
    "text": "the hardbound scales which parts will go down first oldest are the new HP I use",
    "start": "1936000",
    "end": "1941970"
  },
  {
    "text": "this deployment logic to scale down deployment and a random pod will be",
    "start": "1941970",
    "end": "1947460"
  },
  {
    "text": "killed there is no strategy on which one unfortunately that's how deployment",
    "start": "1947460",
    "end": "1953640"
  },
  {
    "text": "works and if deployment changes the strategy for scale down we would get it",
    "start": "1953640",
    "end": "1960150"
  },
  {
    "text": "automatically a plus so we work with any open an object that has scale sub",
    "start": "1960150",
    "end": "1967920"
  },
  {
    "text": "resource so the strategy is not only limited to two deployment deployment",
    "start": "1967920",
    "end": "1974400"
  },
  {
    "text": "itself does it allow you to kill a particular pod so we cannot do it from the HP itself so our hands are a little",
    "start": "1974400",
    "end": "1982260"
  },
  {
    "text": "bit tight and random port is killed sorry for that in order to scale say if",
    "start": "1982260",
    "end": "1989370"
  },
  {
    "text": "multiple parts are pending sorry could",
    "start": "1989370",
    "end": "1994380"
  },
  {
    "text": "you please if multiple parts are in pending state and then we have the nodes that will auto scale right",
    "start": "1994380",
    "end": "1999870"
  },
  {
    "text": "once parts down scale which node will",
    "start": "1999870",
    "end": "2004970"
  },
  {
    "text": "will be killed first so we have various strategies there deciding which node to",
    "start": "2004970",
    "end": "2011420"
  },
  {
    "text": "pick the first thing is that we will pick nodes that are less utilized so we",
    "start": "2011420",
    "end": "2017630"
  },
  {
    "text": "have the threshold and nodes above a particular address what will not be cut so for example by default because it",
    "start": "2017630",
    "end": "2023750"
  },
  {
    "text": "knows that have at least 50% of their capacity used as well utilized and we",
    "start": "2023750",
    "end": "2029570"
  },
  {
    "text": "don't compact them you can change it if you want to learn how to change it please come on Wednesday to the talk",
    "start": "2029570",
    "end": "2035800"
  },
  {
    "text": "otherwise we just some notes that provides that allows us to D delete the",
    "start": "2035800",
    "end": "2042110"
  },
  {
    "text": "pods samples may have pod disruption budget some postman some nodes may be",
    "start": "2042110",
    "end": "2047410"
  },
  {
    "text": "holding like important system components and even if they were like the best candidates there cannot be killed",
    "start": "2047410",
    "end": "2055190"
  },
  {
    "text": "because there is a metric server running there and killing metric server could could cause an outage or there is a DNS",
    "start": "2055190",
    "end": "2061980"
  },
  {
    "text": "server or something like that so mmm the actual strategy there is a little bit",
    "start": "2061980",
    "end": "2067260"
  },
  {
    "text": "more complex thank you I'm afraid I have run out of time so if you have any more questions please join",
    "start": "2067260",
    "end": "2075600"
  },
  {
    "text": "me outside of this room thank you [Applause]",
    "start": "2075600",
    "end": "2080949"
  }
]
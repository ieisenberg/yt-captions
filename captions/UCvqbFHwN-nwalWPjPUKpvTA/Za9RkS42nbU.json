[
  {
    "text": "hi my name is tara lisowski and i am",
    "start": "240",
    "end": "2720"
  },
  {
    "text": "presenting with cody glosser",
    "start": "2720",
    "end": "5120"
  },
  {
    "text": "today we will illustrate how entity",
    "start": "5120",
    "end": "7359"
  },
  {
    "text": "operator automates ncd database",
    "start": "7359",
    "end": "9599"
  },
  {
    "text": "management",
    "start": "9599",
    "end": "10639"
  },
  {
    "text": "and eliminates database downtime etcd is",
    "start": "10639",
    "end": "14160"
  },
  {
    "text": "the primary data store of kubernetes",
    "start": "14160",
    "end": "16320"
  },
  {
    "text": "and holds all the kubernetes cluster",
    "start": "16320",
    "end": "18640"
  },
  {
    "text": "state",
    "start": "18640",
    "end": "20320"
  },
  {
    "text": "internally at ibm our first entity",
    "start": "20320",
    "end": "23199"
  },
  {
    "text": "deployment model for coop clusters",
    "start": "23199",
    "end": "25599"
  },
  {
    "text": "consisted of deploying and managing etcd",
    "start": "25599",
    "end": "28240"
  },
  {
    "text": "instances",
    "start": "28240",
    "end": "29359"
  },
  {
    "text": "on vms using ansible",
    "start": "29359",
    "end": "32558"
  },
  {
    "text": "as we scaled the number of kubernetes",
    "start": "32559",
    "end": "34480"
  },
  {
    "text": "clusters we managed",
    "start": "34480",
    "end": "36079"
  },
  {
    "text": "this deployment model became a",
    "start": "36079",
    "end": "37600"
  },
  {
    "text": "bottleneck to the scale we could operate",
    "start": "37600",
    "end": "39680"
  },
  {
    "text": "at",
    "start": "39680",
    "end": "40480"
  },
  {
    "text": "due to the amount of engineering hours",
    "start": "40480",
    "end": "42480"
  },
  {
    "text": "it took to maintain this",
    "start": "42480",
    "end": "44079"
  },
  {
    "text": "automation suite at scale have any of",
    "start": "44079",
    "end": "46960"
  },
  {
    "text": "you all had the experience of going away",
    "start": "46960",
    "end": "48640"
  },
  {
    "text": "for vacation for a week",
    "start": "48640",
    "end": "50320"
  },
  {
    "text": "and coming back to an inbox of a",
    "start": "50320",
    "end": "52160"
  },
  {
    "text": "thousand plus emails",
    "start": "52160",
    "end": "53440"
  },
  {
    "text": "that you have to process and respond to",
    "start": "53440",
    "end": "56640"
  },
  {
    "text": "that's the same feeling our engineers",
    "start": "56640",
    "end": "58640"
  },
  {
    "text": "were experiencing",
    "start": "58640",
    "end": "60000"
  },
  {
    "text": "as the various database creation and",
    "start": "60000",
    "end": "62160"
  },
  {
    "text": "administration tasks",
    "start": "62160",
    "end": "64000"
  },
  {
    "text": "queued up on a weekly basis in addition",
    "start": "64000",
    "end": "68080"
  },
  {
    "text": "deployment and upgrade times of ncd",
    "start": "68080",
    "end": "70840"
  },
  {
    "text": "clusters took",
    "start": "70840",
    "end": "72240"
  },
  {
    "text": "on average one to two hours to complete",
    "start": "72240",
    "end": "75840"
  },
  {
    "text": "which increased the total time it took",
    "start": "75840",
    "end": "78400"
  },
  {
    "text": "to get a kubernetes environment",
    "start": "78400",
    "end": "80400"
  },
  {
    "text": "functional we needed to re-architect the",
    "start": "80400",
    "end": "83439"
  },
  {
    "text": "way we",
    "start": "83439",
    "end": "85840"
  },
  {
    "text": "cluster deployments in order to scale",
    "start": "85840",
    "end": "88799"
  },
  {
    "text": "the amount of kubernetes clusters",
    "start": "88799",
    "end": "91200"
  },
  {
    "text": "we could manage moving to an entity",
    "start": "91200",
    "end": "94880"
  },
  {
    "text": "deployment model",
    "start": "94880",
    "end": "96159"
  },
  {
    "text": "centered around a cd operator allowed us",
    "start": "96159",
    "end": "98799"
  },
  {
    "text": "to eliminate these bottlenecks",
    "start": "98799",
    "end": "101439"
  },
  {
    "text": "to put it in perspective we manage a",
    "start": "101439",
    "end": "103840"
  },
  {
    "text": "thousand times more",
    "start": "103840",
    "end": "105280"
  },
  {
    "text": "etcd clusters with our entity operator",
    "start": "105280",
    "end": "108159"
  },
  {
    "text": "based solution",
    "start": "108159",
    "end": "109600"
  },
  {
    "text": "than our ansible base solution in",
    "start": "109600",
    "end": "112560"
  },
  {
    "text": "addition",
    "start": "112560",
    "end": "113520"
  },
  {
    "text": "over the past year we have spent",
    "start": "113520",
    "end": "115520"
  },
  {
    "text": "significantly less",
    "start": "115520",
    "end": "116799"
  },
  {
    "text": "engineering hours maintaining all lcd",
    "start": "116799",
    "end": "120000"
  },
  {
    "text": "clusters managed by a city operator",
    "start": "120000",
    "end": "122479"
  },
  {
    "text": "compared to those managed by our ansible",
    "start": "122479",
    "end": "124960"
  },
  {
    "text": "base solution",
    "start": "124960",
    "end": "126799"
  },
  {
    "text": "now let's illustrate the power of entity",
    "start": "126799",
    "end": "129360"
  },
  {
    "text": "operator",
    "start": "129360",
    "end": "130160"
  },
  {
    "text": "by walking through a live demo of the",
    "start": "130160",
    "end": "132560"
  },
  {
    "text": "entity cluster deployment process",
    "start": "132560",
    "end": "136560"
  },
  {
    "text": "a quick note for those that have",
    "start": "138640",
    "end": "140000"
  },
  {
    "text": "downloaded this slide deck",
    "start": "140000",
    "end": "142239"
  },
  {
    "text": "the number in the top left hand corner",
    "start": "142239",
    "end": "144080"
  },
  {
    "text": "of my screen corresponds to the slide",
    "start": "144080",
    "end": "146160"
  },
  {
    "text": "number that has the content we are",
    "start": "146160",
    "end": "148000"
  },
  {
    "text": "currently covering",
    "start": "148000",
    "end": "149360"
  },
  {
    "text": "and will be updated throughout the demo",
    "start": "149360",
    "end": "153360"
  },
  {
    "text": "we are going to create a three node",
    "start": "153599",
    "end": "155840"
  },
  {
    "text": "highly available",
    "start": "155840",
    "end": "157000"
  },
  {
    "text": "multi-az ltd cluster managed by etcd",
    "start": "157000",
    "end": "160480"
  },
  {
    "text": "operator",
    "start": "160480",
    "end": "162000"
  },
  {
    "text": "we first need to define the database",
    "start": "162000",
    "end": "164319"
  },
  {
    "text": "that entity operator is going to create",
    "start": "164319",
    "end": "166879"
  },
  {
    "text": "for us",
    "start": "166879",
    "end": "167519"
  },
  {
    "text": "in a language it understands that",
    "start": "167519",
    "end": "170800"
  },
  {
    "text": "language is the etsy cluster custom",
    "start": "170800",
    "end": "173840"
  },
  {
    "text": "resource",
    "start": "173840",
    "end": "174640"
  },
  {
    "text": "definition the crd",
    "start": "174640",
    "end": "177920"
  },
  {
    "text": "provides entity operator with structured",
    "start": "177920",
    "end": "180879"
  },
  {
    "text": "data",
    "start": "180879",
    "end": "181680"
  },
  {
    "text": "that outlines all the requirements for",
    "start": "181680",
    "end": "184159"
  },
  {
    "text": "the ncd cluster",
    "start": "184159",
    "end": "185680"
  },
  {
    "text": "which allows ncd operator to take action",
    "start": "185680",
    "end": "188959"
  },
  {
    "text": "toward creating a cluster that meets all",
    "start": "188959",
    "end": "191920"
  },
  {
    "text": "those requirements",
    "start": "191920",
    "end": "193599"
  },
  {
    "text": "the process is conceptually similar to",
    "start": "193599",
    "end": "196319"
  },
  {
    "text": "that of an",
    "start": "196319",
    "end": "196879"
  },
  {
    "text": "engineer working a github issue that",
    "start": "196879",
    "end": "199440"
  },
  {
    "text": "outlines the requirements for creating a",
    "start": "199440",
    "end": "201360"
  },
  {
    "text": "three-node",
    "start": "201360",
    "end": "202080"
  },
  {
    "text": "ncd cluster i have an example of that",
    "start": "202080",
    "end": "205519"
  },
  {
    "text": "here",
    "start": "205519",
    "end": "207840"
  },
  {
    "text": "once the engineer has read the",
    "start": "209840",
    "end": "211200"
  },
  {
    "text": "requirements he or she will begin",
    "start": "211200",
    "end": "213440"
  },
  {
    "text": "executing actions toward achieving the",
    "start": "213440",
    "end": "216000"
  },
  {
    "text": "desired result",
    "start": "216000",
    "end": "217440"
  },
  {
    "text": "like provisioning three vms and then",
    "start": "217440",
    "end": "220400"
  },
  {
    "text": "installing and configuring",
    "start": "220400",
    "end": "221840"
  },
  {
    "text": "entity on each individual vm to create a",
    "start": "221840",
    "end": "225280"
  },
  {
    "text": "functioning cluster the engineer will",
    "start": "225280",
    "end": "228640"
  },
  {
    "text": "provide status updates in the issue",
    "start": "228640",
    "end": "231360"
  },
  {
    "text": "that will track their progress on the",
    "start": "231360",
    "end": "233439"
  },
  {
    "text": "task and ultimately close the issue",
    "start": "233439",
    "end": "236480"
  },
  {
    "text": "when the task is completed",
    "start": "236480",
    "end": "239599"
  },
  {
    "text": "the github issue is the same idea as the",
    "start": "239599",
    "end": "242159"
  },
  {
    "text": "entity cluster crd",
    "start": "242159",
    "end": "244000"
  },
  {
    "text": "and the engineer is the lcd operator",
    "start": "244000",
    "end": "247519"
  },
  {
    "text": "for all the non-engineers in the room",
    "start": "247519",
    "end": "249760"
  },
  {
    "text": "think of a person gathering three items",
    "start": "249760",
    "end": "251760"
  },
  {
    "text": "in a grocery list",
    "start": "251760",
    "end": "253200"
  },
  {
    "text": "at the grocery store the person is going",
    "start": "253200",
    "end": "255920"
  },
  {
    "text": "to read the piece of paper",
    "start": "255920",
    "end": "257519"
  },
  {
    "text": "outlining the items and take three",
    "start": "257519",
    "end": "259440"
  },
  {
    "text": "discrete actions",
    "start": "259440",
    "end": "261040"
  },
  {
    "text": "that consist of finding each item and",
    "start": "261040",
    "end": "263199"
  },
  {
    "text": "placing it in the cart",
    "start": "263199",
    "end": "265120"
  },
  {
    "text": "the grocery list is the structured data",
    "start": "265120",
    "end": "267040"
  },
  {
    "text": "in this situation",
    "start": "267040",
    "end": "268639"
  },
  {
    "text": "and the person gathering the items is",
    "start": "268639",
    "end": "270960"
  },
  {
    "text": "the operator",
    "start": "270960",
    "end": "272960"
  },
  {
    "text": "the key point in these analogies is",
    "start": "272960",
    "end": "275120"
  },
  {
    "text": "enough information",
    "start": "275120",
    "end": "276960"
  },
  {
    "text": "needs to be communicated to the operator",
    "start": "276960",
    "end": "280080"
  },
  {
    "text": "in order for he or she to properly",
    "start": "280080",
    "end": "282240"
  },
  {
    "text": "deliver the result",
    "start": "282240",
    "end": "284400"
  },
  {
    "text": "a lot of the same data you saw in the",
    "start": "284400",
    "end": "286479"
  },
  {
    "text": "github issue that the engineer worked",
    "start": "286479",
    "end": "289280"
  },
  {
    "text": "is going to appear in the edcd cluster",
    "start": "289280",
    "end": "291520"
  },
  {
    "text": "crd resource",
    "start": "291520",
    "end": "296960"
  },
  {
    "text": "there's a few major sections of the ncd",
    "start": "296960",
    "end": "299440"
  },
  {
    "text": "crd",
    "start": "299440",
    "end": "300160"
  },
  {
    "text": "to highlight first is the size and",
    "start": "300160",
    "end": "302960"
  },
  {
    "text": "version fields",
    "start": "302960",
    "end": "304320"
  },
  {
    "text": "which are going to control the size and",
    "start": "304320",
    "end": "306320"
  },
  {
    "text": "version that the lcd cluster is deployed",
    "start": "306320",
    "end": "308840"
  },
  {
    "text": "with",
    "start": "308840",
    "end": "311840"
  },
  {
    "text": "the next section are the scheduling",
    "start": "313199",
    "end": "316000"
  },
  {
    "text": "rules",
    "start": "316000",
    "end": "316639"
  },
  {
    "text": "which are going to build upon kube's",
    "start": "316639",
    "end": "318560"
  },
  {
    "text": "scheduling logic to ensure the pods",
    "start": "318560",
    "end": "321199"
  },
  {
    "text": "that run individual entity instances",
    "start": "321199",
    "end": "324240"
  },
  {
    "text": "end up on three different nodes and",
    "start": "324240",
    "end": "326560"
  },
  {
    "text": "three different availability zones",
    "start": "326560",
    "end": "329840"
  },
  {
    "text": "lastly there are customizations to the",
    "start": "329840",
    "end": "332400"
  },
  {
    "text": "configuration of",
    "start": "332400",
    "end": "333600"
  },
  {
    "text": "individual ncd instances including the",
    "start": "333600",
    "end": "336840"
  },
  {
    "text": "supported cipher suites",
    "start": "336840",
    "end": "340720"
  },
  {
    "text": "we are going to apply this entity",
    "start": "340800",
    "end": "342800"
  },
  {
    "text": "cluster custom resource definition",
    "start": "342800",
    "end": "345840"
  },
  {
    "text": "into the cluster",
    "start": "345840",
    "end": "348880"
  },
  {
    "text": "which entity operator will then read to",
    "start": "349440",
    "end": "352720"
  },
  {
    "text": "to execute and create the database",
    "start": "352720",
    "end": "356080"
  },
  {
    "text": "entity operator will execute the",
    "start": "356080",
    "end": "357840"
  },
  {
    "text": "following series of logic loops",
    "start": "357840",
    "end": "359520"
  },
  {
    "text": "after it detects the creation of the crd",
    "start": "359520",
    "end": "366639"
  },
  {
    "text": "in the first logic loop entity operator",
    "start": "366639",
    "end": "369199"
  },
  {
    "text": "has been told to create a cluster of",
    "start": "369199",
    "end": "370639"
  },
  {
    "text": "three fcd instances",
    "start": "370639",
    "end": "372400"
  },
  {
    "text": "at version 342 and currently has no",
    "start": "372400",
    "end": "374880"
  },
  {
    "text": "existing instances",
    "start": "374880",
    "end": "376960"
  },
  {
    "text": "etsy operator will create one lcd",
    "start": "376960",
    "end": "379199"
  },
  {
    "text": "instance",
    "start": "379199",
    "end": "380960"
  },
  {
    "text": "to initialize the cluster and give it",
    "start": "380960",
    "end": "382720"
  },
  {
    "text": "time to get healthy",
    "start": "382720",
    "end": "384319"
  },
  {
    "text": "sd operator will also update the crd to",
    "start": "384319",
    "end": "386880"
  },
  {
    "text": "reflect what it has accomplished so far",
    "start": "386880",
    "end": "390800"
  },
  {
    "text": "now the next logic loop starts etsy",
    "start": "392560",
    "end": "395919"
  },
  {
    "text": "operator has been told to create a",
    "start": "395919",
    "end": "397360"
  },
  {
    "text": "cluster of three fcd instances",
    "start": "397360",
    "end": "399360"
  },
  {
    "text": "at version 342 and has one healthy",
    "start": "399360",
    "end": "402720"
  },
  {
    "text": "instance",
    "start": "402720",
    "end": "405199"
  },
  {
    "text": "entity operator will call into the fcd",
    "start": "406400",
    "end": "408639"
  },
  {
    "text": "cluster",
    "start": "408639",
    "end": "410080"
  },
  {
    "text": "and configure it to add a new member",
    "start": "410080",
    "end": "412720"
  },
  {
    "text": "then it will spin up an ncd instance",
    "start": "412720",
    "end": "414800"
  },
  {
    "text": "that will function as that member and",
    "start": "414800",
    "end": "416960"
  },
  {
    "text": "give the cluster time to stabilize",
    "start": "416960",
    "end": "423840"
  },
  {
    "text": "now the final logic loop starts that",
    "start": "426080",
    "end": "428560"
  },
  {
    "text": "will execute an action",
    "start": "428560",
    "end": "430560"
  },
  {
    "text": "entity operator has been told to create",
    "start": "430560",
    "end": "432560"
  },
  {
    "text": "a ncd cluster",
    "start": "432560",
    "end": "434160"
  },
  {
    "text": "of three entity instances at version 342",
    "start": "434160",
    "end": "437759"
  },
  {
    "text": "and has two healthy instances",
    "start": "437759",
    "end": "441680"
  },
  {
    "text": "etsy operator will call into the ncd",
    "start": "442479",
    "end": "444880"
  },
  {
    "text": "cluster and configure it to add a new",
    "start": "444880",
    "end": "447120"
  },
  {
    "text": "member",
    "start": "447120",
    "end": "448160"
  },
  {
    "text": "then it will spin up an ncd instance",
    "start": "448160",
    "end": "450000"
  },
  {
    "text": "that will function as that member",
    "start": "450000",
    "end": "451599"
  },
  {
    "text": "and give the cluster time to stabilize",
    "start": "451599",
    "end": "455919"
  },
  {
    "text": "finally xd operator has been told to",
    "start": "458639",
    "end": "461199"
  },
  {
    "text": "create a cluster of three entity",
    "start": "461199",
    "end": "463039"
  },
  {
    "text": "instances",
    "start": "463039",
    "end": "463759"
  },
  {
    "text": "at version 342 and has three etsy three",
    "start": "463759",
    "end": "466960"
  },
  {
    "text": "healthy instances",
    "start": "466960",
    "end": "468879"
  },
  {
    "text": "its work is finished and now it takes",
    "start": "468879",
    "end": "470879"
  },
  {
    "text": "some much-needed time off",
    "start": "470879",
    "end": "472639"
  },
  {
    "text": "puts on a vr headset and watches the",
    "start": "472639",
    "end": "475199"
  },
  {
    "text": "tulips in amsterdam",
    "start": "475199",
    "end": "476560"
  },
  {
    "text": "safely from its home at this point",
    "start": "476560",
    "end": "480479"
  },
  {
    "text": "we have accomplished our goal of",
    "start": "480479",
    "end": "482240"
  },
  {
    "text": "creating a functioning multi-z",
    "start": "482240",
    "end": "484560"
  },
  {
    "text": "ltd cluster that is ready to serve",
    "start": "484560",
    "end": "487120"
  },
  {
    "text": "requests",
    "start": "487120",
    "end": "489599"
  },
  {
    "text": "in this theoretical situation the",
    "start": "490960",
    "end": "493360"
  },
  {
    "text": "cluster is put into production",
    "start": "493360",
    "end": "495280"
  },
  {
    "text": "use and results in downtime if it goes",
    "start": "495280",
    "end": "498000"
  },
  {
    "text": "down",
    "start": "498000",
    "end": "499840"
  },
  {
    "text": "the cluster is also under strict",
    "start": "499840",
    "end": "501919"
  },
  {
    "text": "compliance guidelines",
    "start": "501919",
    "end": "504000"
  },
  {
    "text": "that the organization managing it has to",
    "start": "504000",
    "end": "506720"
  },
  {
    "text": "me",
    "start": "506720",
    "end": "507599"
  },
  {
    "text": "security vulnerabilities can be",
    "start": "507599",
    "end": "509039"
  },
  {
    "text": "disclosed at any time that",
    "start": "509039",
    "end": "510639"
  },
  {
    "text": "impact the entity version we are",
    "start": "510639",
    "end": "512959"
  },
  {
    "text": "currently running",
    "start": "512959",
    "end": "514399"
  },
  {
    "text": "this is just one of the many reasons why",
    "start": "514399",
    "end": "516560"
  },
  {
    "text": "we need to have a system that automates",
    "start": "516560",
    "end": "518640"
  },
  {
    "text": "the entire",
    "start": "518640",
    "end": "519440"
  },
  {
    "text": "ncd cluster upgrade process without",
    "start": "519440",
    "end": "522479"
  },
  {
    "text": "any downtime etsy operator",
    "start": "522479",
    "end": "526000"
  },
  {
    "text": "makes this process as simple as one",
    "start": "526000",
    "end": "528000"
  },
  {
    "text": "command",
    "start": "528000",
    "end": "529040"
  },
  {
    "text": "an update to the version field in the",
    "start": "529040",
    "end": "530720"
  },
  {
    "text": "ncd cluster crd resource",
    "start": "530720",
    "end": "535839"
  },
  {
    "text": "after we apply this change into our",
    "start": "536800",
    "end": "538640"
  },
  {
    "text": "environment",
    "start": "538640",
    "end": "541279"
  },
  {
    "text": "entity operator will detect that on the",
    "start": "542720",
    "end": "544880"
  },
  {
    "text": "next reconciliation loop",
    "start": "544880",
    "end": "546640"
  },
  {
    "text": "to begin the upgrade process the upgrade",
    "start": "546640",
    "end": "549600"
  },
  {
    "text": "process will consist of the following",
    "start": "549600",
    "end": "551200"
  },
  {
    "text": "logic loops",
    "start": "551200",
    "end": "554000"
  },
  {
    "text": "in the first logic loop etcd operator",
    "start": "558480",
    "end": "561120"
  },
  {
    "text": "has been told to create a cluster of",
    "start": "561120",
    "end": "562640"
  },
  {
    "text": "three fcd instances",
    "start": "562640",
    "end": "564000"
  },
  {
    "text": "at version 343 and has three healthy",
    "start": "564000",
    "end": "566959"
  },
  {
    "text": "instances running three four",
    "start": "566959",
    "end": "568320"
  },
  {
    "text": "two etsy operator will patch the image",
    "start": "568320",
    "end": "571440"
  },
  {
    "text": "of one",
    "start": "571440",
    "end": "572000"
  },
  {
    "text": "etcd instance to be 343 and then give",
    "start": "572000",
    "end": "575200"
  },
  {
    "text": "the cluster time to stabilize",
    "start": "575200",
    "end": "577279"
  },
  {
    "text": "the execution of this logic loop can be",
    "start": "577279",
    "end": "579920"
  },
  {
    "text": "identified when a pod",
    "start": "579920",
    "end": "581360"
  },
  {
    "text": "in the entity cluster registers a",
    "start": "581360",
    "end": "583279"
  },
  {
    "text": "restart",
    "start": "583279",
    "end": "585839"
  },
  {
    "text": "the execution of the next logic loop can",
    "start": "586959",
    "end": "589200"
  },
  {
    "text": "be identified",
    "start": "589200",
    "end": "590640"
  },
  {
    "text": "by the restarts of two ncd pods",
    "start": "590640",
    "end": "594480"
  },
  {
    "text": "in this loop entity operator has been",
    "start": "594480",
    "end": "596800"
  },
  {
    "text": "told to create a",
    "start": "596800",
    "end": "597839"
  },
  {
    "text": "cluster of three std instances at",
    "start": "597839",
    "end": "600320"
  },
  {
    "text": "version 343",
    "start": "600320",
    "end": "602079"
  },
  {
    "text": "and has three healthy instances two",
    "start": "602079",
    "end": "604720"
  },
  {
    "text": "running three four two",
    "start": "604720",
    "end": "606399"
  },
  {
    "text": "and one running three four three etsy",
    "start": "606399",
    "end": "609279"
  },
  {
    "text": "operator will patch",
    "start": "609279",
    "end": "610399"
  },
  {
    "text": "the image of one lcd",
    "start": "610399",
    "end": "613519"
  },
  {
    "text": "instance to be 343 and then give the",
    "start": "613519",
    "end": "616000"
  },
  {
    "text": "cluster time to stabilize",
    "start": "616000",
    "end": "619839"
  },
  {
    "text": "the execution of the final logic loop",
    "start": "621360",
    "end": "624399"
  },
  {
    "text": "that executes an action can be",
    "start": "624399",
    "end": "626240"
  },
  {
    "text": "identified by the restarts of three",
    "start": "626240",
    "end": "628399"
  },
  {
    "text": "entity pods",
    "start": "628399",
    "end": "633040"
  },
  {
    "text": "entity operator has been told to create",
    "start": "633040",
    "end": "634880"
  },
  {
    "text": "a cluster of three entity instances at",
    "start": "634880",
    "end": "637120"
  },
  {
    "text": "version 343",
    "start": "637120",
    "end": "638880"
  },
  {
    "text": "it has three healthy instances one",
    "start": "638880",
    "end": "641200"
  },
  {
    "text": "running three four two",
    "start": "641200",
    "end": "642560"
  },
  {
    "text": "and two running three four three etsy",
    "start": "642560",
    "end": "645360"
  },
  {
    "text": "operator will",
    "start": "645360",
    "end": "646079"
  },
  {
    "text": "patch the image of one of the xd",
    "start": "646079",
    "end": "648160"
  },
  {
    "text": "instances to be 343",
    "start": "648160",
    "end": "650160"
  },
  {
    "text": "and then give the cluster time to get",
    "start": "650160",
    "end": "652959"
  },
  {
    "text": "fully healthy",
    "start": "652959",
    "end": "655839"
  },
  {
    "text": "at this point the cluster is fully",
    "start": "656320",
    "end": "658720"
  },
  {
    "text": "healthy",
    "start": "658720",
    "end": "659360"
  },
  {
    "text": "since all the pods are in two of two",
    "start": "659360",
    "end": "661600"
  },
  {
    "text": "ready state",
    "start": "661600",
    "end": "662640"
  },
  {
    "text": "and we have completed the upgrade",
    "start": "662640",
    "end": "664000"
  },
  {
    "text": "process",
    "start": "664000",
    "end": "665839"
  },
  {
    "text": "you'll note throughout the entire",
    "start": "665839",
    "end": "667600"
  },
  {
    "text": "upgrade process",
    "start": "667600",
    "end": "668959"
  },
  {
    "text": "we had two pods ready to serve traffic",
    "start": "668959",
    "end": "671200"
  },
  {
    "text": "at any given time",
    "start": "671200",
    "end": "672800"
  },
  {
    "text": "which ensures writes and reads can be",
    "start": "672800",
    "end": "675600"
  },
  {
    "text": "processed throughout the entire upgrade",
    "start": "675600",
    "end": "678320"
  },
  {
    "text": "to recap we were able to set up a ha",
    "start": "678320",
    "end": "681720"
  },
  {
    "text": "multi-azee cluster",
    "start": "681720",
    "end": "683680"
  },
  {
    "text": "in under four minutes and execute an",
    "start": "683680",
    "end": "686079"
  },
  {
    "text": "entire database",
    "start": "686079",
    "end": "687279"
  },
  {
    "text": "upgrade with zero downtime in under four",
    "start": "687279",
    "end": "689760"
  },
  {
    "text": "minutes as well",
    "start": "689760",
    "end": "691279"
  },
  {
    "text": "now i'll turn it over to cody to take us",
    "start": "691279",
    "end": "694160"
  },
  {
    "text": "through the power etcd operator can",
    "start": "694160",
    "end": "695839"
  },
  {
    "text": "provide",
    "start": "695839",
    "end": "696720"
  },
  {
    "text": "in disaster scenarios thank you tyler",
    "start": "696720",
    "end": "700560"
  },
  {
    "text": "my name is cody glosser the next thing",
    "start": "700560",
    "end": "702480"
  },
  {
    "text": "i'm going to talk about is what makes",
    "start": "702480",
    "end": "703839"
  },
  {
    "text": "sed",
    "start": "703839",
    "end": "704399"
  },
  {
    "text": "highly available and go through a few",
    "start": "704399",
    "end": "706079"
  },
  {
    "text": "different disaster recovery scenarios",
    "start": "706079",
    "end": "708480"
  },
  {
    "text": "as tyler pointed out before the fcd",
    "start": "708480",
    "end": "710800"
  },
  {
    "text": "cluster custom resource definition has",
    "start": "710800",
    "end": "713040"
  },
  {
    "text": "pod affinity rules that prevent paws",
    "start": "713040",
    "end": "714880"
  },
  {
    "text": "from being scheduled into the same zone",
    "start": "714880",
    "end": "717120"
  },
  {
    "text": "and host based off the node labels",
    "start": "717120",
    "end": "720399"
  },
  {
    "text": "as you can see in the image here the pod",
    "start": "720399",
    "end": "722079"
  },
  {
    "text": "affinity rules look at a topology key",
    "start": "722079",
    "end": "724240"
  },
  {
    "text": "that specifies the zone",
    "start": "724240",
    "end": "726959"
  },
  {
    "text": "let's go through a few different",
    "start": "726959",
    "end": "728639"
  },
  {
    "text": "scenarios to help visualize",
    "start": "728639",
    "end": "730160"
  },
  {
    "text": "high availability in this scenario our",
    "start": "730160",
    "end": "732880"
  },
  {
    "text": "lcd cluster pods are scheduled across",
    "start": "732880",
    "end": "734560"
  },
  {
    "text": "three zones",
    "start": "734560",
    "end": "735279"
  },
  {
    "text": "del 10 del 12 and dial 13. each zone has",
    "start": "735279",
    "end": "738639"
  },
  {
    "text": "four worker nodes",
    "start": "738639",
    "end": "740160"
  },
  {
    "text": "now let's say we have a power outage and",
    "start": "740160",
    "end": "741839"
  },
  {
    "text": "we lose nodes in dial 10",
    "start": "741839",
    "end": "743200"
  },
  {
    "text": "including the node that the sd cluster",
    "start": "743200",
    "end": "744720"
  },
  {
    "text": "pod is running on",
    "start": "744720",
    "end": "747360"
  },
  {
    "text": "the scd operator will detect that the",
    "start": "747360",
    "end": "749279"
  },
  {
    "text": "pod is dead and the actual peers does",
    "start": "749279",
    "end": "751120"
  },
  {
    "text": "not equal the desired peers",
    "start": "751120",
    "end": "752720"
  },
  {
    "text": "so we'll attempt to schedule a pod we'll",
    "start": "752720",
    "end": "754959"
  },
  {
    "text": "look for a running and ready node in",
    "start": "754959",
    "end": "756639"
  },
  {
    "text": "dial 10 to be able to schedule to",
    "start": "756639",
    "end": "759760"
  },
  {
    "text": "as you can see in this example the new",
    "start": "759760",
    "end": "761279"
  },
  {
    "text": "pod came up on worker 1",
    "start": "761279",
    "end": "762959"
  },
  {
    "text": "in dell 10. now let's do the same",
    "start": "762959",
    "end": "765360"
  },
  {
    "text": "scenario",
    "start": "765360",
    "end": "766000"
  },
  {
    "text": "interacting directly with the kubernetes",
    "start": "766000",
    "end": "767760"
  },
  {
    "text": "cluster",
    "start": "767760",
    "end": "769600"
  },
  {
    "text": "as you can see here i have the same",
    "start": "769600",
    "end": "772560"
  },
  {
    "text": "setup with four nodes in dial 12",
    "start": "772560",
    "end": "774720"
  },
  {
    "text": "4 and dial 13 and 4 and dial 10.",
    "start": "774720",
    "end": "777279"
  },
  {
    "text": "additionally",
    "start": "777279",
    "end": "778000"
  },
  {
    "text": "you can see the lcd pods are scheduled",
    "start": "778000",
    "end": "780160"
  },
  {
    "text": "to a node in each zone",
    "start": "780160",
    "end": "782160"
  },
  {
    "text": "now we're going to simulate a zone",
    "start": "782160",
    "end": "783519"
  },
  {
    "text": "failure in dell 10 on",
    "start": "783519",
    "end": "786800"
  },
  {
    "text": "these two nodes",
    "start": "786800",
    "end": "789680"
  },
  {
    "text": "with the watch on the lcd pods you will",
    "start": "789920",
    "end": "792079"
  },
  {
    "text": "see that the lcd pod",
    "start": "792079",
    "end": "793360"
  },
  {
    "text": "starts to go into a terminating state",
    "start": "793360",
    "end": "796560"
  },
  {
    "text": "and then eventually the fcd operator",
    "start": "796560",
    "end": "799760"
  },
  {
    "text": "spin back up a new healthy",
    "start": "799760",
    "end": "801839"
  },
  {
    "text": "pod in dell 10.",
    "start": "801839",
    "end": "805120"
  },
  {
    "text": "for scenario 2 let's see what happens if",
    "start": "812720",
    "end": "814800"
  },
  {
    "text": "all nodes go down in dell 10.",
    "start": "814800",
    "end": "816880"
  },
  {
    "text": "we either have the option to open up a",
    "start": "816880",
    "end": "818560"
  },
  {
    "text": "new zone or wait until we get a healthy",
    "start": "818560",
    "end": "820480"
  },
  {
    "text": "node in dial 10",
    "start": "820480",
    "end": "821760"
  },
  {
    "text": "up while we are at two or three pods the",
    "start": "821760",
    "end": "824079"
  },
  {
    "text": "fcd cluster is still healthy and",
    "start": "824079",
    "end": "825600"
  },
  {
    "text": "achieves quorum so there's no",
    "start": "825600",
    "end": "827279"
  },
  {
    "text": "outage to the instance if we were to",
    "start": "827279",
    "end": "829680"
  },
  {
    "text": "lose another zone or lcd pod",
    "start": "829680",
    "end": "831279"
  },
  {
    "text": "then quorum would be broken back to our",
    "start": "831279",
    "end": "834160"
  },
  {
    "text": "kubernetes cluster we will demonstrate",
    "start": "834160",
    "end": "835839"
  },
  {
    "text": "this scenario",
    "start": "835839",
    "end": "836800"
  },
  {
    "text": "as you can see we have all the fcd pods",
    "start": "836800",
    "end": "838800"
  },
  {
    "text": "back up and running",
    "start": "838800",
    "end": "840160"
  },
  {
    "text": "next we will simulate killing all nodes",
    "start": "840160",
    "end": "842079"
  },
  {
    "text": "in the zone",
    "start": "842079",
    "end": "844639"
  },
  {
    "text": "with this watch up you will see that the",
    "start": "848320",
    "end": "850079"
  },
  {
    "text": "scd pod in dial 10",
    "start": "850079",
    "end": "851519"
  },
  {
    "text": "goes into a terminating state as you can",
    "start": "851519",
    "end": "854399"
  },
  {
    "text": "see all the nodes below in dalton have",
    "start": "854399",
    "end": "856320"
  },
  {
    "text": "entered a scheduling disabled state and",
    "start": "856320",
    "end": "858160"
  },
  {
    "text": "will eventually hit a not ready state",
    "start": "858160",
    "end": "860639"
  },
  {
    "text": "a new lcd pod could spun up but will be",
    "start": "860639",
    "end": "862959"
  },
  {
    "text": "an impending state until a new",
    "start": "862959",
    "end": "864560"
  },
  {
    "text": "node becomes healthy in dell 10.",
    "start": "864560",
    "end": "871839"
  },
  {
    "text": "describing the pending pod you'll see",
    "start": "874959",
    "end": "877440"
  },
  {
    "text": "zero of twelve nodes are available",
    "start": "877440",
    "end": "879839"
  },
  {
    "text": "with four nodes unscheduleable and eight",
    "start": "879839",
    "end": "882079"
  },
  {
    "text": "nodes do not meet",
    "start": "882079",
    "end": "883360"
  },
  {
    "text": "are pod affinity slash anti-evidently",
    "start": "883360",
    "end": "886160"
  },
  {
    "text": "rules",
    "start": "886160",
    "end": "887360"
  },
  {
    "text": "for our next scenario what happens if we",
    "start": "887360",
    "end": "889279"
  },
  {
    "text": "break quorum",
    "start": "889279",
    "end": "890480"
  },
  {
    "text": "quorum is the minimum number of members",
    "start": "890480",
    "end": "892240"
  },
  {
    "text": "of an etcd cluster necessary to have it",
    "start": "892240",
    "end": "894399"
  },
  {
    "text": "in a functioning state",
    "start": "894399",
    "end": "895920"
  },
  {
    "text": "quorum is achieved from having majority",
    "start": "895920",
    "end": "897920"
  },
  {
    "text": "of pods in a running and healthy state",
    "start": "897920",
    "end": "899760"
  },
  {
    "text": "in our case is two of three running pods",
    "start": "899760",
    "end": "902639"
  },
  {
    "text": "as you can see in this scenario we lose",
    "start": "902639",
    "end": "904399"
  },
  {
    "text": "all of our nodes in dell 10",
    "start": "904399",
    "end": "905760"
  },
  {
    "text": "and a node in dell 12 that has our other",
    "start": "905760",
    "end": "908000"
  },
  {
    "text": "lcd pod running on it",
    "start": "908000",
    "end": "909760"
  },
  {
    "text": "with only one etsy pod running the data",
    "start": "909760",
    "end": "912000"
  },
  {
    "text": "is still being persisted in the pod",
    "start": "912000",
    "end": "913839"
  },
  {
    "text": "and is in a read-only state to the lcd",
    "start": "913839",
    "end": "916079"
  },
  {
    "text": "operator instances",
    "start": "916079",
    "end": "917680"
  },
  {
    "text": "if we were to lose the final pod in dell",
    "start": "917680",
    "end": "919360"
  },
  {
    "text": "12 we will not be able to recover the",
    "start": "919360",
    "end": "921199"
  },
  {
    "text": "data",
    "start": "921199",
    "end": "921839"
  },
  {
    "text": "and manual recovery is needed to recover",
    "start": "921839",
    "end": "923839"
  },
  {
    "text": "from the most recent backup now let's go",
    "start": "923839",
    "end": "926399"
  },
  {
    "text": "back to our kubernetes cluster and",
    "start": "926399",
    "end": "927920"
  },
  {
    "text": "demonstrate both of these cases when",
    "start": "927920",
    "end": "929600"
  },
  {
    "text": "losing quorum",
    "start": "929600",
    "end": "932160"
  },
  {
    "text": "as you can see the fcd cluster has three",
    "start": "932160",
    "end": "934800"
  },
  {
    "text": "or three running pods",
    "start": "934800",
    "end": "936880"
  },
  {
    "text": "now let me write some data to the ncd",
    "start": "936880",
    "end": "938800"
  },
  {
    "text": "database let's put in kubecon 2020",
    "start": "938800",
    "end": "941519"
  },
  {
    "text": "as the value in demo as the key now let",
    "start": "941519",
    "end": "944480"
  },
  {
    "text": "me simulate",
    "start": "944480",
    "end": "945199"
  },
  {
    "text": "failure in dell 10 by killing all the",
    "start": "945199",
    "end": "947920"
  },
  {
    "text": "nodes in that zone",
    "start": "947920",
    "end": "948959"
  },
  {
    "text": "and one node in dial 12.",
    "start": "948959",
    "end": "952480"
  },
  {
    "text": "as you can see two of the three pods",
    "start": "953360",
    "end": "955440"
  },
  {
    "text": "have gone into a terminating state",
    "start": "955440",
    "end": "957440"
  },
  {
    "text": "the third running pod will stay in this",
    "start": "957440",
    "end": "959199"
  },
  {
    "text": "running state to allow us to take a",
    "start": "959199",
    "end": "960560"
  },
  {
    "text": "backup of the most recent ncd data",
    "start": "960560",
    "end": "963519"
  },
  {
    "text": "let's try to read and write to the scd",
    "start": "963519",
    "end": "965120"
  },
  {
    "text": "database again",
    "start": "965120",
    "end": "969040"
  },
  {
    "text": "let me write the value lost data to the",
    "start": "969040",
    "end": "970880"
  },
  {
    "text": "key demo",
    "start": "970880",
    "end": "973600"
  },
  {
    "text": "and as you can see i'm getting a context",
    "start": "979040",
    "end": "981360"
  },
  {
    "text": "deadline exceeded error",
    "start": "981360",
    "end": "983040"
  },
  {
    "text": "let me try to just read the key demo",
    "start": "983040",
    "end": "987519"
  },
  {
    "text": "and as you can see i'm getting the same",
    "start": "993120",
    "end": "994959"
  },
  {
    "text": "context deadline exceeded error",
    "start": "994959",
    "end": "998480"
  },
  {
    "text": "with this one at cd pod up let's attempt",
    "start": "998480",
    "end": "1000720"
  },
  {
    "text": "a backup and restore",
    "start": "1000720",
    "end": "1002320"
  },
  {
    "text": "so now we need to construct an cd backup",
    "start": "1002320",
    "end": "1004399"
  },
  {
    "text": "custom resource definition",
    "start": "1004399",
    "end": "1006000"
  },
  {
    "text": "you can see an example of that here the",
    "start": "1006000",
    "end": "1008160"
  },
  {
    "text": "sections highlighted in blue",
    "start": "1008160",
    "end": "1009680"
  },
  {
    "text": "is information on where this backup will",
    "start": "1009680",
    "end": "1011600"
  },
  {
    "text": "be stored it contains the backup",
    "start": "1011600",
    "end": "1013279"
  },
  {
    "text": "location",
    "start": "1013279",
    "end": "1014079"
  },
  {
    "text": "the path and the credentials to get to",
    "start": "1014079",
    "end": "1015839"
  },
  {
    "text": "that location the section highlighted in",
    "start": "1015839",
    "end": "1018240"
  },
  {
    "text": "red",
    "start": "1018240",
    "end": "1018720"
  },
  {
    "text": "is information on how the etc backup",
    "start": "1018720",
    "end": "1020720"
  },
  {
    "text": "operator can contact",
    "start": "1020720",
    "end": "1022320"
  },
  {
    "text": "the fcd instance this end point is etcd",
    "start": "1022320",
    "end": "1025280"
  },
  {
    "text": "headless kubernetes service endpoint",
    "start": "1025280",
    "end": "1027678"
  },
  {
    "text": "for this fcd cluster back to the",
    "start": "1027679",
    "end": "1030160"
  },
  {
    "text": "kubernetes cluster",
    "start": "1030160",
    "end": "1031678"
  },
  {
    "text": "let's apply the fcd backup resource and",
    "start": "1031679",
    "end": "1033839"
  },
  {
    "text": "wait for it to succeed",
    "start": "1033839",
    "end": "1038000"
  },
  {
    "text": "you can see that it succeeded by looking",
    "start": "1038000",
    "end": "1040000"
  },
  {
    "text": "at the status field",
    "start": "1040000",
    "end": "1041038"
  },
  {
    "text": "of the fcd backup resource now that the",
    "start": "1041039",
    "end": "1044640"
  },
  {
    "text": "lcd data is backed up we can restore the",
    "start": "1044640",
    "end": "1046720"
  },
  {
    "text": "sd cluster without losing any of our",
    "start": "1046720",
    "end": "1048480"
  },
  {
    "text": "data",
    "start": "1048480",
    "end": "1049280"
  },
  {
    "text": "before we do a restore let's recover our",
    "start": "1049280",
    "end": "1051360"
  },
  {
    "text": "nodes",
    "start": "1051360",
    "end": "1053840"
  },
  {
    "text": "now we need to construct an sd restore",
    "start": "1056160",
    "end": "1058400"
  },
  {
    "text": "custom resource definition",
    "start": "1058400",
    "end": "1060080"
  },
  {
    "text": "an example of that can be found here",
    "start": "1060080",
    "end": "1062559"
  },
  {
    "text": "section highlighted in blue",
    "start": "1062559",
    "end": "1064000"
  },
  {
    "text": "is information on where the backup is",
    "start": "1064000",
    "end": "1065679"
  },
  {
    "text": "stored notice how this is the same path",
    "start": "1065679",
    "end": "1067919"
  },
  {
    "text": "we used for the fcd backup resource",
    "start": "1067919",
    "end": "1070720"
  },
  {
    "text": "the section highlighted in red is the",
    "start": "1070720",
    "end": "1072320"
  },
  {
    "text": "name of the fcd backup resource",
    "start": "1072320",
    "end": "1074080"
  },
  {
    "text": "that the data will be copied to",
    "start": "1074080",
    "end": "1077120"
  },
  {
    "text": "back to the kubernetes cluster now let's",
    "start": "1077120",
    "end": "1079440"
  },
  {
    "text": "apply the fcd restore resource",
    "start": "1079440",
    "end": "1081440"
  },
  {
    "text": "and wait for all the lcd pods to come",
    "start": "1081440",
    "end": "1083520"
  },
  {
    "text": "back up",
    "start": "1083520",
    "end": "1095840"
  },
  {
    "text": "now that the pods are back up and",
    "start": "1098960",
    "end": "1100320"
  },
  {
    "text": "running let's try and read that key from",
    "start": "1100320",
    "end": "1102080"
  },
  {
    "text": "sce to confirm we did not lose any data",
    "start": "1102080",
    "end": "1106240"
  },
  {
    "text": "so again i'm going to read from the key",
    "start": "1106400",
    "end": "1108720"
  },
  {
    "text": "demo",
    "start": "1108720",
    "end": "1111120"
  },
  {
    "text": "and we can see that kubecon 2020 is",
    "start": "1111600",
    "end": "1114080"
  },
  {
    "text": "still written in that field",
    "start": "1114080",
    "end": "1115760"
  },
  {
    "text": "titan's still intact and everything is",
    "start": "1115760",
    "end": "1117679"
  },
  {
    "text": "back to functioning normally",
    "start": "1117679",
    "end": "1119840"
  },
  {
    "text": "for our last scenario scenario 4 we lose",
    "start": "1119840",
    "end": "1122559"
  },
  {
    "text": "all our etcd pods and break quorum",
    "start": "1122559",
    "end": "1125120"
  },
  {
    "text": "as you can see here we lost all our",
    "start": "1125120",
    "end": "1126720"
  },
  {
    "text": "nodes in dell 10 one node in dial 12",
    "start": "1126720",
    "end": "1129520"
  },
  {
    "text": "and another node in dell 13. back to the",
    "start": "1129520",
    "end": "1132720"
  },
  {
    "text": "kubernetes cluster",
    "start": "1132720",
    "end": "1134240"
  },
  {
    "text": "as you can see the fcd cluster is back",
    "start": "1134240",
    "end": "1136160"
  },
  {
    "text": "to three to three pods running",
    "start": "1136160",
    "end": "1138160"
  },
  {
    "text": "now let's write data to the scdub",
    "start": "1138160",
    "end": "1139919"
  },
  {
    "text": "database again",
    "start": "1139919",
    "end": "1141360"
  },
  {
    "text": "let's put in lost data and write it to",
    "start": "1141360",
    "end": "1144400"
  },
  {
    "text": "the key",
    "start": "1144400",
    "end": "1145039"
  },
  {
    "text": "demo let me simulate a complete failure",
    "start": "1145039",
    "end": "1148320"
  },
  {
    "text": "in dell 10 by killing all the nodes",
    "start": "1148320",
    "end": "1150480"
  },
  {
    "text": "one node in dial 12 and one node in dial",
    "start": "1150480",
    "end": "1152880"
  },
  {
    "text": "13.",
    "start": "1152880",
    "end": "1155440"
  },
  {
    "text": "now that you can see all the pods have",
    "start": "1157760",
    "end": "1159200"
  },
  {
    "text": "died let's attempt",
    "start": "1159200",
    "end": "1161039"
  },
  {
    "text": "to do a backup with the same ammo we",
    "start": "1161039",
    "end": "1163120"
  },
  {
    "text": "used before",
    "start": "1163120",
    "end": "1165840"
  },
  {
    "text": "as you can see in the status of the",
    "start": "1166080",
    "end": "1167520"
  },
  {
    "text": "backup we were unable to complete it",
    "start": "1167520",
    "end": "1169360"
  },
  {
    "text": "because the scd backup operator is not",
    "start": "1169360",
    "end": "1171360"
  },
  {
    "text": "able to contact the lcd cluster",
    "start": "1171360",
    "end": "1174720"
  },
  {
    "text": "the next step to do is to restore from",
    "start": "1174720",
    "end": "1176799"
  },
  {
    "text": "the most recent backup",
    "start": "1176799",
    "end": "1178400"
  },
  {
    "text": "the one we saved in the previous",
    "start": "1178400",
    "end": "1179919"
  },
  {
    "text": "scenario but first let's recover our",
    "start": "1179919",
    "end": "1182320"
  },
  {
    "text": "nodes again",
    "start": "1182320",
    "end": "1184880"
  },
  {
    "text": "now that the nodes are recovered let's",
    "start": "1185200",
    "end": "1187360"
  },
  {
    "text": "apply the same",
    "start": "1187360",
    "end": "1188320"
  },
  {
    "text": "lcd restore resource again and wait for",
    "start": "1188320",
    "end": "1190559"
  },
  {
    "text": "all the lcd pods to come back",
    "start": "1190559",
    "end": "1192080"
  },
  {
    "text": "up",
    "start": "1192080",
    "end": "1194240"
  },
  {
    "text": "now that all the pods are up and running",
    "start": "1204000",
    "end": "1205840"
  },
  {
    "text": "let's try and read from our ncd database",
    "start": "1205840",
    "end": "1208559"
  },
  {
    "text": "let's read the key demo again",
    "start": "1208559",
    "end": "1211679"
  },
  {
    "text": "and as you can see the most recent data",
    "start": "1211679",
    "end": "1213520"
  },
  {
    "text": "we wrote lost data is no longer there",
    "start": "1213520",
    "end": "1215600"
  },
  {
    "text": "and it was reverted back to kubecon",
    "start": "1215600",
    "end": "1217440"
  },
  {
    "text": "2020.",
    "start": "1217440",
    "end": "1219039"
  },
  {
    "text": "that completes my demo on ncd high",
    "start": "1219039",
    "end": "1220720"
  },
  {
    "text": "availability and disaster recovery",
    "start": "1220720",
    "end": "1226080"
  }
]
[
  {
    "text": "it's so nice to see everyone here at Chicago I'm Sunil Goan from cloud I lead",
    "start": "80",
    "end": "5400"
  },
  {
    "text": "the compute platform team and Unicon scheduling team at clra I'm in this big",
    "start": "5400",
    "end": "10800"
  },
  {
    "text": "data space for over a decade and I contribute majorly to the Unicorn schuer",
    "start": "10800",
    "end": "16440"
  },
  {
    "text": "which is a native batch scheduler for kubernetes in various rols so in today's",
    "start": "16440",
    "end": "22080"
  },
  {
    "text": "session I will I'll be covering the Big Data migration Journey um TOS kubernetes",
    "start": "22080",
    "end": "27279"
  },
  {
    "text": "from cloud so let us take an example of an",
    "start": "27279",
    "end": "32439"
  },
  {
    "text": "Enterprise um company focusing on adopting AI so they'll be looking at",
    "start": "32440",
    "end": "38399"
  },
  {
    "text": "various categories and trying to assess the impact of the AA adoption and as you",
    "start": "38399",
    "end": "43719"
  },
  {
    "text": "can see adopting a could increase the productivity of the R&D or generating",
    "start": "43719",
    "end": "50800"
  },
  {
    "text": "faster content for the marketing team or even saving CS for their uh HR team as",
    "start": "50800",
    "end": "55879"
  },
  {
    "text": "well the common underlying factor to derive such a big Improvement",
    "start": "55879",
    "end": "61239"
  },
  {
    "text": "is nothing but data yes the data itself is the differentiating factor here and",
    "start": "61239",
    "end": "68360"
  },
  {
    "text": "that will be helping to power the a adoption so I want to take a a peak look",
    "start": "68360",
    "end": "74759"
  },
  {
    "text": "at the data itself and its relevance the first one is data",
    "start": "74759",
    "end": "80960"
  },
  {
    "text": "explosion around 75% of the data is not structured and Cloud ra is managing 25",
    "start": "80960",
    "end": "87960"
  },
  {
    "text": "exabytes of data that is roughly around 25 20% of the overall data right and 200",
    "start": "87960",
    "end": "93600"
  },
  {
    "text": "trillion objects are there in uh S3 as of 2023 yes uh everyone needs access to",
    "start": "93600",
    "end": "100399"
  },
  {
    "text": "this data as well right and all the type of application be it AI or non AI the",
    "start": "100399",
    "end": "106000"
  },
  {
    "text": "access is um expected and we are seeing around 50x uh increase in the consumer",
    "start": "106000",
    "end": "112360"
  },
  {
    "text": "side of um access however the question is is storing and managing the data is it",
    "start": "112360",
    "end": "119479"
  },
  {
    "text": "enough I'll say no because you need to get the best value proposition out of the data",
    "start": "119479",
    "end": "125320"
  },
  {
    "text": "otherwise it doesn't matter so in order to do that you need some powerful engines that can help to uh get that",
    "start": "125320",
    "end": "134400"
  },
  {
    "text": "insights so here's a quick overview uh about the the data life cycle and the",
    "start": "134480",
    "end": "140440"
  },
  {
    "text": "use cases that cloud usually solves uh using the Big Data engines so the first",
    "start": "140440",
    "end": "146640"
  },
  {
    "text": "use case as you see it's a collect that nothing but the data injection so this enables the customers to streams uh the",
    "start": "146640",
    "end": "153760"
  },
  {
    "text": "data into their data product by uh providing capabilities such as like analyzing the streaming data with",
    "start": "153760",
    "end": "160319"
  },
  {
    "text": "complex patterns or similar um actions and gain some uh in out of that and one",
    "start": "160319",
    "end": "167599"
  },
  {
    "text": "of the examples could be risk analysis or fraud detection so in the data engineering that a second use case uh it",
    "start": "167599",
    "end": "174159"
  },
  {
    "text": "provides a tool set uh for ETL uh um processes and it helps to to uh cover a",
    "start": "174159",
    "end": "180879"
  },
  {
    "text": "large set of users the third one is Warehouse it enables actually um",
    "start": "180879",
    "end": "187720"
  },
  {
    "text": "business intelligence use cases and it helps to make sure that you get do the right reporting and analytics on the",
    "start": "187720",
    "end": "194040"
  },
  {
    "text": "data the third one is operational database it delivers a scalable real time um and make sure that you your",
    "start": "194040",
    "end": "202000"
  },
  {
    "text": "structur data is collocated with the unstructured data and still make some um analysis on top of that and finally uh",
    "start": "202000",
    "end": "208640"
  },
  {
    "text": "the machine learning itself so it basically empowers the organization to build and deploy your",
    "start": "208640",
    "end": "213799"
  },
  {
    "text": "machine learning models and add the AA capabilities for the businesses that they are looking at so let us look at",
    "start": "213799",
    "end": "220799"
  },
  {
    "text": "these engines that I just mentioned here right um but before that I want to cover one more extra use case so from the data",
    "start": "220799",
    "end": "228439"
  },
  {
    "text": "engineer or data scientist perspective um they'll be trying to build some pipelines usually and take the data from",
    "start": "228439",
    "end": "236120"
  },
  {
    "text": "the source and make sure that do some analysis and then put it to the final um",
    "start": "236120",
    "end": "241480"
  },
  {
    "text": "store and make and one more one more challenge will be that uh whatever",
    "start": "241480",
    "end": "246640"
  },
  {
    "text": "changes that they make at the source it has to reflect in the Target systems as well so it should be real time so I'm",
    "start": "246640",
    "end": "251920"
  },
  {
    "text": "just taking a small example um from a one of our customers basically take the data from multiple sources of course the",
    "start": "251920",
    "end": "258199"
  },
  {
    "text": "scale will be huge here and then apply updates or apply the Delta and then um",
    "start": "258199",
    "end": "264360"
  },
  {
    "text": "apply the final updates to to the data processing and usually you'll be doing",
    "start": "264360",
    "end": "269639"
  },
  {
    "text": "with asset transactions or multiple operations on top of that and then you need to take periodic",
    "start": "269639",
    "end": "276000"
  },
  {
    "text": "backups right uh for the auditing and compliance uh purposes and then run some historic",
    "start": "276000",
    "end": "282320"
  },
  {
    "text": "queries time travel will be very helpful here and finally the Predictive Services",
    "start": "282320",
    "end": "287360"
  },
  {
    "text": "Itself by and with that we'll be able to make make some good ml model out of it",
    "start": "287360",
    "end": "292479"
  },
  {
    "text": "and take some Data Insights so if this is a use case that we see usually let's",
    "start": "292479",
    "end": "298199"
  },
  {
    "text": "see what all engines are helping to achieve this so we have Iceberg apash",
    "start": "298199",
    "end": "303680"
  },
  {
    "text": "Iceberg as the top layer and then we have the engines like knif I spark fling",
    "start": "303680",
    "end": "308800"
  },
  {
    "text": "Impala all those all of them are helping to make sure that the use cases that I mentioned here is is can be scaled and",
    "start": "308800",
    "end": "315960"
  },
  {
    "text": "you can get what you really want looking for so I think I mentioned about few of",
    "start": "315960",
    "end": "322199"
  },
  {
    "text": "the engines so in our data platform we have more than 30 plus open source",
    "start": "322199",
    "end": "327880"
  },
  {
    "text": "projects and many of core data engines and because of that itself the compute",
    "start": "327880",
    "end": "333400"
  },
  {
    "text": "itself is going to be very complex and if you look at through the lens of deployment architecture some of",
    "start": "333400",
    "end": "340240"
  },
  {
    "text": "these deployments could be long running stateful services and some of them could be batch work CLS something which be",
    "start": "340240",
    "end": "346600"
  },
  {
    "text": "bustable like go up to 20,000 30,000 containers and shrink back so and one of the classical example is Apaches spark",
    "start": "346600",
    "end": "353520"
  },
  {
    "text": "itself right and these engines with the use cases that I mentioned is pivotal",
    "start": "353520",
    "end": "358840"
  },
  {
    "text": "for the Gen use case as well so and these were the these were this is how",
    "start": "358840",
    "end": "364000"
  },
  {
    "text": "our platform was designed with all these engines and the use cases that I just mentioned it just make sure that I think",
    "start": "364000",
    "end": "370360"
  },
  {
    "text": "um in the new era also we are um able to achieve the same thing by addressing",
    "start": "370360",
    "end": "376400"
  },
  {
    "text": "some of the gaps so I want to take one more linear look here like the data processing",
    "start": "376400",
    "end": "383479"
  },
  {
    "text": "methods and changes it evolve right and look at the last decade itself the number of engines that came name is too",
    "start": "383479",
    "end": "391440"
  },
  {
    "text": "many like recently the llm is a new addition here and the pace of this change is also increasing day by day and",
    "start": "391440",
    "end": "398840"
  },
  {
    "text": "thanks to the open source Innovation um it's just it'll continue to grow the way it is and the change is also applicable",
    "start": "398840",
    "end": "406000"
  },
  {
    "text": "for the platform as well we had something called yarn in the past kuber is actually there it helps us to scale",
    "start": "406000",
    "end": "412319"
  },
  {
    "text": "even much better in the cloud n way and if you look at the key take takeaways here data is a constant part",
    "start": "412319",
    "end": "419720"
  },
  {
    "text": "so engines change the platform change but data is at the end of the day same and with the new engines platform need",
    "start": "419720",
    "end": "426240"
  },
  {
    "text": "to be adaptable it need to be flexible to ensure that they will be able to process the same thing and the actions that we are",
    "start": "426240",
    "end": "434039"
  },
  {
    "text": "looking here is nothing but Embrace this change because engines are going to come the existing engines need to evolve and",
    "start": "434039",
    "end": "440520"
  },
  {
    "text": "the platform need to be flexible as well so it's all about adapting to this new change and one of the key things what we",
    "start": "440520",
    "end": "448280"
  },
  {
    "text": "um look at is the open Source element because most of the engines as you see is all open source and um it's essential",
    "start": "448280",
    "end": "454680"
  },
  {
    "text": "that we are not getting into the vendor login aspects now the same use case I just I",
    "start": "454680",
    "end": "461599"
  },
  {
    "text": "mentioned earlier if you look at through the platform administrator view from the company it will be looking like",
    "start": "461599",
    "end": "467440"
  },
  {
    "text": "something like this you have your compute at the bottom you have the storage layer then you have the resource management layer that was y the past and",
    "start": "467440",
    "end": "474440"
  },
  {
    "text": "then your metadata catalog security elements and then your applications or engines are sitting right on top of that",
    "start": "474440",
    "end": "480639"
  },
  {
    "text": "finally the the business data or the business code will be sitting on top of this because it makes use of all these",
    "start": "480639",
    "end": "486680"
  },
  {
    "text": "engines and derive some meaningful insights I want to give one more view of",
    "start": "486680",
    "end": "491960"
  },
  {
    "text": "the same stack but through a resource point of view um the same use cases that",
    "start": "491960",
    "end": "497199"
  },
  {
    "text": "we saw earlier like streaming use cases or batch use cases I can structure the",
    "start": "497199",
    "end": "502840"
  },
  {
    "text": "overall Custer capacity in this hierarchical manner and assign certain resource quota to it so then those",
    "start": "502840",
    "end": "509599"
  },
  {
    "text": "engines will be executing within that realm of that Cota what is assigned to it so this was very common in the past",
    "start": "509599",
    "end": "516839"
  },
  {
    "text": "decade and for many of the big data use cases now coming to the challenges for",
    "start": "516839",
    "end": "523959"
  },
  {
    "text": "managing such a big data platform so I want to uh show four different pillars",
    "start": "523959",
    "end": "529880"
  },
  {
    "text": "and through that pillars I would like to explain what are the challenges that we saw and how we we actually we are going",
    "start": "529880",
    "end": "536720"
  },
  {
    "text": "to solve with adopting kubernetes and be beyond that what other extra challenges that we saw and how we solve some of",
    "start": "536720",
    "end": "543600"
  },
  {
    "text": "them so that is how I wanted to uh take this further session so the first pillar is Resource",
    "start": "543600",
    "end": "549399"
  },
  {
    "text": "Management so deploying uh different versions of the applications and with",
    "start": "549399",
    "end": "554640"
  },
  {
    "text": "different types of dependencies were one of the biggest challenge for us and it's not that easy at all when you run",
    "start": "554640",
    "end": "560760"
  },
  {
    "text": "different versions of the same application there will be conflicts and we run into many issues and of course no",
    "start": "560760",
    "end": "566399"
  },
  {
    "text": "easy ior issue is a big challenge um the containers who are running on the same",
    "start": "566399",
    "end": "571959"
  },
  {
    "text": "machine could impact the performance slas and Etc and it was very difficult",
    "start": "571959",
    "end": "577200"
  },
  {
    "text": "to Auto scale um in such uh such workloads um based on the workload",
    "start": "577200",
    "end": "582720"
  },
  {
    "text": "demand the Second Use case or the pillar that I'm looking for is scalable",
    "start": "582720",
    "end": "588040"
  },
  {
    "text": "clusters so from the cluster point of view most of our clusters or all the Clusters that we have is collocated with",
    "start": "588040",
    "end": "595240"
  },
  {
    "text": "the storage and compute together so this is nothing but the data locality that many of you might have heard about in",
    "start": "595240",
    "end": "600839"
  },
  {
    "text": "the past so you want to make sure that you send your Compu to the machine where you have your",
    "start": "600839",
    "end": "607040"
  },
  {
    "text": "data so we will look at how we we solve this issue in the upcoming slides now",
    "start": "607040",
    "end": "612680"
  },
  {
    "text": "the third pillar is about operational efficiency so it is important that like we adapt to the latest of the the best",
    "start": "612680",
    "end": "619600"
  },
  {
    "text": "of the platform without any doubt and for that we need to make sure that our applications or our engines are simplif",
    "start": "619600",
    "end": "627040"
  },
  {
    "text": "easy to maintain easy to deploy easy to provision but those were not the case in the",
    "start": "627040",
    "end": "632399"
  },
  {
    "text": "past finally from the hybrid Cloud point of view we need to make most of our",
    "start": "632399",
    "end": "638720"
  },
  {
    "text": "obligation have to be ported to public cloud and then private Cloud we need to make sure that the same need to be available it is not that easy at all so",
    "start": "638720",
    "end": "645240"
  },
  {
    "text": "that was one of the other challenge that we saw so this these challenges that I",
    "start": "645240",
    "end": "651720"
  },
  {
    "text": "mentioned that exactly LED our journey towards kubernetes so we felt that kubernetes is the right ecosystem the",
    "start": "651720",
    "end": "658480"
  },
  {
    "text": "right platform for us to make sure that the Next Generation data platform can be",
    "start": "658480",
    "end": "664000"
  },
  {
    "text": "um relay on so the data services that we call it",
    "start": "664000",
    "end": "671120"
  },
  {
    "text": "as the new data platform from our um stack we call it as data services they are completely on kubernetes and we see",
    "start": "671120",
    "end": "678519"
  },
  {
    "text": "that that is a future towards the hybrid so the cluster form factor that we had",
    "start": "678519",
    "end": "683600"
  },
  {
    "text": "it was very complex it is very labor intensive as well and it was not easy to be easy to maintain so it had to be",
    "start": "683600",
    "end": "691000"
  },
  {
    "text": "replaced with some with the new stack that is nothing but kubernetes and we found it's very simpler more capable and",
    "start": "691000",
    "end": "698519"
  },
  {
    "text": "makees and it it easy for it's easy for both data practitioners and the platform admins as well so we re architectured",
    "start": "698519",
    "end": "706720"
  },
  {
    "text": "our traditional Big Data cluster from a monolith uh to a microservice based",
    "start": "706720",
    "end": "712480"
  },
  {
    "text": "architecture and we also made sure that we um make our overall servers into",
    "start": "712480",
    "end": "720639"
  },
  {
    "text": "minor services like it's very easy for put all these service together and then make some relations out of",
    "start": "720639",
    "end": "727560"
  },
  {
    "text": "that and we also leveraged the container cloud and it helped us to disaggregate",
    "start": "727560",
    "end": "733199"
  },
  {
    "text": "the storage from the computer that also was a major key point for us now the applications that we have it has to be",
    "start": "733199",
    "end": "740320"
  },
  {
    "text": "optimized to adapt the create the new application so one of the challenge that we saw was it was not easy to create a",
    "start": "740320",
    "end": "746199"
  },
  {
    "text": "new application and then um make some more make the make the new application",
    "start": "746199",
    "end": "752079"
  },
  {
    "text": "faster right and for many of our customers it was not easy at all so the new platform we wanted to ensure that",
    "start": "752079",
    "end": "758519"
  },
  {
    "text": "they can develop the application on top of the data platform in an easy",
    "start": "758519",
    "end": "763560"
  },
  {
    "text": "manner finally the maintenance itself so upgrades were always a big problem so we",
    "start": "763560",
    "end": "769160"
  },
  {
    "text": "wanted to ensure that the platform itself can upgrade zero downtime or with high",
    "start": "769160",
    "end": "775959"
  },
  {
    "text": "available Okay so so the next step in this journey for us was we adapted",
    "start": "777040",
    "end": "784440"
  },
  {
    "text": "kubernetes but the question was did we miss something that we had it in the",
    "start": "784440",
    "end": "789560"
  },
  {
    "text": "past or did we add some new complexities or challenges into our stack so I would",
    "start": "789560",
    "end": "795160"
  },
  {
    "text": "like to look at few of them the first one is about the hierarchical cues itself so do we have the same",
    "start": "795160",
    "end": "801320"
  },
  {
    "text": "flexibility available from the platform uh to manage the resources uh so I will",
    "start": "801320",
    "end": "806519"
  },
  {
    "text": "say we don't have yet and the next point was about is our um",
    "start": "806519",
    "end": "812440"
  },
  {
    "text": "Services multi-tenant is it easy to um adopt maybe 200 2,000 or 3,000 plus",
    "start": "812440",
    "end": "817959"
  },
  {
    "text": "users to our system and then run queries or workloads Etc can I also achieve the same SLA that",
    "start": "817959",
    "end": "825959"
  },
  {
    "text": "I had uh in the previous tag so that was also a major question so can this service scale the way it used to scale",
    "start": "825959",
    "end": "833800"
  },
  {
    "text": "like 20,000 30,000 containers for running one spark batch workload",
    "start": "833800",
    "end": "839680"
  },
  {
    "text": "and finally is this cost effective compared to the previous stack so if some of these are not met that's a huge",
    "start": "839680",
    "end": "846399"
  },
  {
    "text": "problem because then the new platform will not be helpful for us at",
    "start": "846399",
    "end": "851759"
  },
  {
    "text": "all and the major question for us was the data engines itself that helped to",
    "start": "852440",
    "end": "857959"
  },
  {
    "text": "solve a ton of use cases just like the way I mentioned earlier is it ready to adapt the new",
    "start": "857959",
    "end": "864160"
  },
  {
    "text": "platform and yes it was not quiet so cloud sold some of them and let's see",
    "start": "864160",
    "end": "871720"
  },
  {
    "text": "how we reached um took the new platform",
    "start": "871720",
    "end": "877120"
  },
  {
    "text": "itself okay so the resource management is the first vertical so kubernetes uh",
    "start": "877880",
    "end": "883240"
  },
  {
    "text": "empowered our data platform to support faster Auto scaling without any doubt and it was cost effective and now we are",
    "start": "883240",
    "end": "889519"
  },
  {
    "text": "able to run containerized workloads so that means we don't need to worry about any noise in iers and we can actually",
    "start": "889519",
    "end": "895519"
  },
  {
    "text": "run any type of versions of application with its own dependencies so it became very easy for to manage the dependencies",
    "start": "895519",
    "end": "902240"
  },
  {
    "text": "with the cized form factor and we were able to solve the resource isolation in a much simpler",
    "start": "902240",
    "end": "908360"
  },
  {
    "text": "manner than we thought it in the",
    "start": "908360",
    "end": "911880"
  },
  {
    "text": "past now the challenges that we saw with kubernetes so the question was like how",
    "start": "917800",
    "end": "923240"
  },
  {
    "text": "do we assign cotas to the teams or users based on the use case or how to submit a",
    "start": "923240",
    "end": "930120"
  },
  {
    "text": "bigger batch workload and consider it as one unit or how do I maximize the",
    "start": "930120",
    "end": "936480"
  },
  {
    "text": "resource utilization in a fixed size cluster so in a cloud it's much easier you can Auto scale and come down but",
    "start": "936480",
    "end": "942800"
  },
  {
    "text": "when you're are in on Prem your cluster is limited so you need to make the best out of the hardware so how do we do that",
    "start": "942800",
    "end": "949399"
  },
  {
    "text": "some of the limitation that we saw with kuber scheduler was it the the cotas that we set on the kubernetes is is just",
    "start": "949399",
    "end": "957079"
  },
  {
    "text": "an add-on and and the enforcements were only available at the resource creation",
    "start": "957079",
    "end": "962240"
  },
  {
    "text": "time and the quotas and limits were set at the name Space level and the lack of",
    "start": "962240",
    "end": "967839"
  },
  {
    "text": "um application aware preemption were a big challenge so the elasticity was not quite fully",
    "start": "967839",
    "end": "974560"
  },
  {
    "text": "achieved so as a solution uh when we thought about this resource related",
    "start": "974560",
    "end": "980720"
  },
  {
    "text": "problems we found that there is a gap and we open sourced a project called apachi unicorn so this is a batch",
    "start": "980720",
    "end": "987839"
  },
  {
    "text": "scheduler for kubernetes and we open source it in 2019 so over the last few",
    "start": "987839",
    "end": "993079"
  },
  {
    "text": "years it became uh one of the powerful batch schuer in kubernetes and uh we",
    "start": "993079",
    "end": "999040"
  },
  {
    "text": "have very various Deep dive um sessions on this Schuler itself in the previous",
    "start": "999040",
    "end": "1004600"
  },
  {
    "text": "Cube Conns as well but I want to touch briefly about what it is so unicorn can",
    "start": "1004600",
    "end": "1009759"
  },
  {
    "text": "schedule any type of jobs be batch Service Long running it does not matter it can support a huge scale of demand",
    "start": "1009759",
    "end": "1018199"
  },
  {
    "text": "from application like spark or hi it is very easy to integrate to any new engine",
    "start": "1018199",
    "end": "1023920"
  },
  {
    "text": "because we are using symbol annotations and label so it is not that you need to make a huge change in the Big Data",
    "start": "1023920",
    "end": "1029918"
  },
  {
    "text": "engines or your own application to use a scheduler and it does support hierarchical cues so that means you can",
    "start": "1029919",
    "end": "1036558"
  },
  {
    "text": "set the quotas at each level it also supports various types of scheduling like Fair ordering policy or fifo or um",
    "start": "1036559",
    "end": "1045079"
  },
  {
    "text": "gang scheduling itself so I'm taking the same Q hierarchy that I showed earlier in the",
    "start": "1045079",
    "end": "1051679"
  },
  {
    "text": "use case as the root level then you have the streaming and you have the badge then you have the wehouse queue",
    "start": "1051679",
    "end": "1057360"
  },
  {
    "text": "underneath and inest queue um and finally the data engineering so I'm submitting some jobs so usually it will",
    "start": "1057360",
    "end": "1063400"
  },
  {
    "text": "be coming as a p um the left the warehouse will be maybe a hive job or an imala job on the data engineering que it",
    "start": "1063400",
    "end": "1070440"
  },
  {
    "text": "could be a fling or a spark job but overall it's around I think 20 GB uh in the streaming",
    "start": "1070440",
    "end": "1078600"
  },
  {
    "text": "q and 30 GB in the usage at the badge job and overall it is around 50 GB but",
    "start": "1078600",
    "end": "1084480"
  },
  {
    "text": "if I set my Kota at the top level to 50 so let's see if I submit a job like say",
    "start": "1084480",
    "end": "1090720"
  },
  {
    "text": "an injection job a CF car it could be possible that we will not be able to run it but rather than rejecting or failing",
    "start": "1090720",
    "end": "1097200"
  },
  {
    "text": "this job we will queue it up so that whenever there is a capacity available at later stage we will be able to",
    "start": "1097200",
    "end": "1102960"
  },
  {
    "text": "schedule it so that is one of the powerful aspect of um unicorn",
    "start": "1102960",
    "end": "1108960"
  },
  {
    "text": "so you can set the resource limits at each level so this hierarchy is very similar to the old form factor uh in Yar",
    "start": "1108960",
    "end": "1117679"
  },
  {
    "text": "um if folks are familiar with it you'll be able to easily relate this now let us look at the Second",
    "start": "1117679",
    "end": "1124159"
  },
  {
    "text": "Challenge this is related to the preemption so in kubernetes um the endre cluster is sorted based on priority so",
    "start": "1124159",
    "end": "1132159"
  },
  {
    "text": "it's a big que and ports are considered for eviction based on the priority",
    "start": "1132159",
    "end": "1137320"
  },
  {
    "text": "itself so an opt out is not quite possible that means any of your ports",
    "start": "1137320",
    "end": "1142559"
  },
  {
    "text": "could be eligible for preemption at any point of time and it'll be a problem for jobs like spark because if you kill the",
    "start": "1142559",
    "end": "1149880"
  },
  {
    "text": "driver or the originator Port your entire application will fail so that was one of our critical concern and one of",
    "start": "1149880",
    "end": "1156520"
  },
  {
    "text": "other concern was like the priority class it is a cluster object so that means anyone can actually change the",
    "start": "1156520",
    "end": "1163280"
  },
  {
    "text": "priority to a higher value so that means we can have some Rogue users",
    "start": "1163280",
    "end": "1169159"
  },
  {
    "text": "so unicorn was able to solve some of these problem that I mentioned earlier but to talk about the preemption in",
    "start": "1169159",
    "end": "1174919"
  },
  {
    "text": "unicor I just need to take take a bit of a time to explain how unicorn works so",
    "start": "1174919",
    "end": "1180120"
  },
  {
    "text": "unlike unlike the default scheduler um which is using a fif Q unicorn works in",
    "start": "1180120",
    "end": "1185520"
  },
  {
    "text": "the hierarchical level so it's a parent child relationship model so the resource",
    "start": "1185520",
    "end": "1190559"
  },
  {
    "text": "limits configurations and access control almost all of them can be defined at any level",
    "start": "1190559",
    "end": "1196120"
  },
  {
    "text": "in the hierarchy and it will be in inited by the child cues and preemption",
    "start": "1196120",
    "end": "1201520"
  },
  {
    "text": "makes use of the fact that unicorn allows specifying both guaranteed and a",
    "start": "1201520",
    "end": "1206559"
  },
  {
    "text": "Max limit for each Q so when a resource um utilization for a que exceeds the",
    "start": "1206559",
    "end": "1214679"
  },
  {
    "text": "guaranteed it actually can get take some more extra capacity available from the max limit maybe because the sibling cues",
    "start": "1214679",
    "end": "1221080"
  },
  {
    "text": "are not using it so it grabs some resources now when the actual demand comes from the underutilized Queue at a",
    "start": "1221080",
    "end": "1227600"
  },
  {
    "text": "later state P the overcommitted queue those application we will preempt it but",
    "start": "1227600",
    "end": "1234039"
  },
  {
    "text": "the way we will be preempting is such a way that we will kill only the executors that means the originator ports will be",
    "start": "1234039",
    "end": "1240760"
  },
  {
    "text": "kept alive so that at later point of time when the disable capacity is",
    "start": "1240760",
    "end": "1245880"
  },
  {
    "text": "available we will be able to resume the work and continue the job so that is the idea and also it is possible that you",
    "start": "1245880",
    "end": "1253240"
  },
  {
    "text": "can spare certain ports by marking that these are non- touchable ports or something like that it will be very easy",
    "start": "1253240",
    "end": "1259840"
  },
  {
    "text": "for the admins to uh take control of the preemption in a much granular",
    "start": "1259840",
    "end": "1265080"
  },
  {
    "text": "way so here is a cube demo that I wanted to",
    "start": "1265080",
    "end": "1270320"
  },
  {
    "text": "show so this is one of our new platform from clra CDE is a data engineering",
    "start": "1270320",
    "end": "1275880"
  },
  {
    "text": "spark and we are creating multiple virtual clusters for running different types of spark versions so each virtual",
    "start": "1275880",
    "end": "1283760"
  },
  {
    "text": "cluster that is nothing but a spark two or a spark three you can specify the guarant capacity that you want and you",
    "start": "1283760",
    "end": "1289840"
  },
  {
    "text": "can also specify the Max Capacity so you have vc1 and vc2 that is",
    "start": "1289840",
    "end": "1295520"
  },
  {
    "text": "the two virtual cluster that I created and both virtual clusters I set 10 cores as a guaranteed and it can grow up to 20",
    "start": "1295520",
    "end": "1302520"
  },
  {
    "text": "cores if unused so this is how the resource utilization dashboard will look like the",
    "start": "1302520",
    "end": "1308000"
  },
  {
    "text": "exact hierarchical so you can specify the hierarchy based on your um organization demand I'm running some",
    "start": "1308000",
    "end": "1314760"
  },
  {
    "text": "jobs first and the utilization I'm taking to 10 p cods sorry 10 cores in the Bo and it",
    "start": "1314760",
    "end": "1322360"
  },
  {
    "text": "actually uh meets the guaranteed capacity so once the guaranteed capacity",
    "start": "1322360",
    "end": "1327400"
  },
  {
    "text": "is met so I'm running some more job maybe a job number two I think it'll take another four more course goes up to",
    "start": "1327400",
    "end": "1333679"
  },
  {
    "text": "14 so that means I'm now above my guaranteed so at this point of time if",
    "start": "1333679",
    "end": "1340159"
  },
  {
    "text": "there is a demand com from the second virtual cluster that is maybe a spar three cluster that's what I think I'm",
    "start": "1340159",
    "end": "1345960"
  },
  {
    "text": "trying to do um we need to grab the resources back so there are two ways we can do if we enable preemption it goes",
    "start": "1345960",
    "end": "1353200"
  },
  {
    "text": "and kills the job and then gets the capacity and if it is not it'll wait for",
    "start": "1353200",
    "end": "1358720"
  },
  {
    "text": "the job to complete and get the um capacity to the second job so here you",
    "start": "1358720",
    "end": "1364000"
  },
  {
    "text": "can see that the second job is now running from the second rest cluster and runs are",
    "start": "1364000",
    "end": "1370440"
  },
  {
    "text": "ongoing so I'm trying to show the logs to see that we have seen some progress in the spark job so that is good",
    "start": "1370440",
    "end": "1379159"
  },
  {
    "text": "now second scenario is basically I want to say that okay I'm changing the max limit of the cluster to 12 course so",
    "start": "1379159",
    "end": "1385679"
  },
  {
    "text": "that means I cannot grow Beyond to so I'm starting um a job in the vc2 and the",
    "start": "1385679",
    "end": "1392679"
  },
  {
    "text": "usages goes up to around n and I want to run more jobs with run",
    "start": "1392679",
    "end": "1398480"
  },
  {
    "text": "93 run 94 that means I want to see that when you meet the Cota upper quota what",
    "start": "1398480",
    "end": "1405480"
  },
  {
    "text": "happens to these jobs it has to Simply wait so that is something like I'm trying to you hit the max here with the",
    "start": "1405480",
    "end": "1411679"
  },
  {
    "text": "to course so that no more Executives can run and we have some notices this is nothing but from kubernetes we get the",
    "start": "1411679",
    "end": "1417480"
  },
  {
    "text": "feedback that oh yeah that it is in pending",
    "start": "1417480",
    "end": "1421480"
  },
  {
    "text": "state right so let me move",
    "start": "1426240",
    "end": "1432559"
  },
  {
    "text": "on so this is related to the performance and scale part right so you are running Spark jobs or fling almost all the",
    "start": "1432600",
    "end": "1439600"
  },
  {
    "text": "different types of data workloads in the previous all Legacy form factor and it",
    "start": "1439600",
    "end": "1445000"
  },
  {
    "text": "can scale up to say 10,000 notes if you want right so that is how the scale um possibility of the previous platform and",
    "start": "1445000",
    "end": "1452080"
  },
  {
    "text": "you are you can run different type of workloads like spark or fling but in the new platform of course it comes with its",
    "start": "1452080",
    "end": "1458320"
  },
  {
    "text": "own challenges that we mentioned but how are we fairing in terms of performance numbers so some of the numbers that we",
    "start": "1458320",
    "end": "1463960"
  },
  {
    "text": "ran was uh running some TP CDs queries on spark on the left most one we can see",
    "start": "1463960",
    "end": "1469720"
  },
  {
    "text": "it is a spark on Yann we get around 48 or something like that I",
    "start": "1469720",
    "end": "1475159"
  },
  {
    "text": "think um the execution time and similar um job the same job with the same spec",
    "start": "1475159",
    "end": "1481559"
  },
  {
    "text": "when we ran on the spark on kubernetes form factor we were able to get almost",
    "start": "1481559",
    "end": "1487399"
  },
  {
    "text": "on par performance or slightly better and we ran a spark 3 job and mostly the",
    "start": "1487399",
    "end": "1492799"
  },
  {
    "text": "same thing so same job same data set same cluster size so we made sure that all those those things are same but",
    "start": "1492799",
    "end": "1499559"
  },
  {
    "text": "compared the results so this gave some confidence that we are not losing any performance though the many of the",
    "start": "1499559",
    "end": "1506480"
  },
  {
    "text": "aspects in terms of provisioning of ports are slower and Etc in the kubernetes form factor so this proves that unicorn and",
    "start": "1506480",
    "end": "1514919"
  },
  {
    "text": "kubernetes together actually Moniz modernized our data platform and made sure that I think our new platform is in",
    "start": "1514919",
    "end": "1522200"
  },
  {
    "text": "the right direction and we are able to solve majority of the use case that we are looking for",
    "start": "1522200",
    "end": "1529039"
  },
  {
    "text": "now let's look at the second pillar that is the scaling cluster so here one of",
    "start": "1529039",
    "end": "1534840"
  },
  {
    "text": "the major challenge that we were seeing that the storage and compute they were collocated so if the storage and compute",
    "start": "1534840",
    "end": "1541000"
  },
  {
    "text": "are collocated what will happen is that you need you'll have more challenges in scaling this cluster because you may",
    "start": "1541000",
    "end": "1546799"
  },
  {
    "text": "have you may need more compute but you don't need to buy extra Hardware like for ssds or something like for your",
    "start": "1546799",
    "end": "1553399"
  },
  {
    "text": "storage it is not required at all but because it is collocated you are for to buy the additional storage as well thus",
    "start": "1553399",
    "end": "1560120"
  },
  {
    "text": "your TCO won't be great so one of the fundamental thing what we have done is um we disaggregated the storage and",
    "start": "1560120",
    "end": "1566120"
  },
  {
    "text": "compute and made sure that our engines are capable of accessing data from any",
    "start": "1566120",
    "end": "1572279"
  },
  {
    "text": "location so one of the question that we usually get it what about the data locality in the previous decade it was all about data locality so what will",
    "start": "1572279",
    "end": "1578760"
  },
  {
    "text": "happen to that but I think that's a new architecture right because you have the better Network now better IO that kind",
    "start": "1578760",
    "end": "1583880"
  },
  {
    "text": "of compensates the data locality that means the performance won't be impacted as",
    "start": "1583880",
    "end": "1589399"
  },
  {
    "text": "much now the speciality Hardware itself you have gpus and ssds that are very",
    "start": "1589399",
    "end": "1594880"
  },
  {
    "text": "scarce resources how to make sure that the right application gets those um",
    "start": "1594880",
    "end": "1600000"
  },
  {
    "text": "dedicated Hardware so if someone else uses that you will lose it so when you're a larger organization and you",
    "start": "1600000",
    "end": "1605520"
  },
  {
    "text": "have a massive cluster there are chances that you will be losing majority of those scarce resource to someone else of",
    "start": "1605520",
    "end": "1612799"
  },
  {
    "text": "a lower priority nature so we need to make sure that we handle that so that that is one of the crucial um problem",
    "start": "1612799",
    "end": "1619640"
  },
  {
    "text": "for us and finally autoscaling itself like are we are we scaling in a way that",
    "start": "1619640",
    "end": "1625080"
  },
  {
    "text": "like we have to scale for example if there is enough compute demand then we",
    "start": "1625080",
    "end": "1630320"
  },
  {
    "text": "can scale but if we do not have we should not be wasting a lot of resources that means we need to shut down those",
    "start": "1630320",
    "end": "1635640"
  },
  {
    "text": "clusters as well so with",
    "start": "1635640",
    "end": "1642360"
  },
  {
    "text": "cuties what we go TOS basically um a set of features right so so the first one",
    "start": "1642360",
    "end": "1648320"
  },
  {
    "text": "was the CSI plugin itself it helped to ensure that we could now connect to any",
    "start": "1648320",
    "end": "1653799"
  },
  {
    "text": "storage be it in public cloud or private Cloud it doesn't matter we use a CSA storage plugin so we can easily connect",
    "start": "1653799",
    "end": "1660559"
  },
  {
    "text": "and our story of our hybrid story becomes much more simpler and it helped to make sure that",
    "start": "1660559",
    "end": "1667159"
  },
  {
    "text": "we get the best um candidates for those speciality Hardware like gpus for",
    "start": "1667159",
    "end": "1673720"
  },
  {
    "text": "example if I have an ml job I need to make sure that only those ml job or use users of the ml will be getting those",
    "start": "1673720",
    "end": "1679320"
  },
  {
    "text": "Hardwares and it's also less administrative overhead for spinning up the Clusters and we can do this",
    "start": "1679320",
    "end": "1685840"
  },
  {
    "text": "deployment very fast in kubernetes so that means our spin up time improved a",
    "start": "1685840",
    "end": "1691200"
  },
  {
    "text": "lot and determining the right cluster size usually it is very difficult but",
    "start": "1691200",
    "end": "1696399"
  },
  {
    "text": "with auto scaling we were able to toggle that and figure out the right cluster size and what is the optimal um usage",
    "start": "1696399",
    "end": "1703919"
  },
  {
    "text": "pattern so this is what we got from kubernetes and we had still some more",
    "start": "1703919",
    "end": "1709519"
  },
  {
    "text": "problems the and how did we solve from cloud side I think for the disaggregated",
    "start": "1709519",
    "end": "1714880"
  },
  {
    "text": "storage and compute ozone played a crucial part so Apache ozone is a",
    "start": "1714880",
    "end": "1720640"
  },
  {
    "text": "scalable redundant distributed Object Store and it can store up to billions of",
    "start": "1720640",
    "end": "1727559"
  },
  {
    "text": "objects on Prem right so that means we can p pack more data per node that means",
    "start": "1727559",
    "end": "1733799"
  },
  {
    "text": "we can go way more dense in with storage on each node so that means you don't need a larger pool of storage clusters",
    "start": "1733799",
    "end": "1741840"
  },
  {
    "text": "you can actually condense them to few number of storage nodes and you can have your compute nodes run on the side as",
    "start": "1741840",
    "end": "1749200"
  },
  {
    "text": "many you like so this will help the TCO play better because the cost of",
    "start": "1749200",
    "end": "1754399"
  },
  {
    "text": "maintaining multiple clusters is now much low so ozone was a crucial player",
    "start": "1754399",
    "end": "1761120"
  },
  {
    "text": "in this part and we also had U more uh development efforts went from our um",
    "start": "1761120",
    "end": "1767799"
  },
  {
    "text": "many of our developers to improve the cloud connectors so many of the Big Data engines if you use as it is in the cloud",
    "start": "1767799",
    "end": "1775200"
  },
  {
    "text": "you will not be getting the performance that we are looking for so the cloud connectors team worked a lot and s3a",
    "start": "1775200",
    "end": "1780799"
  },
  {
    "text": "connector is one of the example where we had a lot of uh development and research went in and that enabled to get a a very",
    "start": "1780799",
    "end": "1789679"
  },
  {
    "text": "powerful um data access model for our big data engines in",
    "start": "1789679",
    "end": "1795360"
  },
  {
    "text": "cloud and finally this is how the stack may look like overall you have the",
    "start": "1795360",
    "end": "1801240"
  },
  {
    "text": "commodity infra then you have the storage and containers but disaggregated storage powered by ozone and the",
    "start": "1801240",
    "end": "1807399"
  },
  {
    "text": "containers are coming from the Cuban SL now let's look at the operational",
    "start": "1807399",
    "end": "1812760"
  },
  {
    "text": "efficiency aspects so some of the challenges that we saw in the Big Data platform they were mostly about how to",
    "start": "1812760",
    "end": "1818840"
  },
  {
    "text": "upgrade your um Services right without keeping any downtime how to keep the",
    "start": "1818840",
    "end": "1824360"
  },
  {
    "text": "service highly available is it easy for us to get the new applications and we also saw some",
    "start": "1824360",
    "end": "1830640"
  },
  {
    "text": "additional challenges from kubernetes itself the CER quicker kubernetes releases literally hurt us a lot because",
    "start": "1830640",
    "end": "1836799"
  },
  {
    "text": "now that means we need to upgrade faster and it is not that easy to upgrade a big data platform it is not easy at all and",
    "start": "1836799",
    "end": "1844200"
  },
  {
    "text": "evolution of these apis that means it can break a lot of apis and that means",
    "start": "1844200",
    "end": "1849240"
  },
  {
    "text": "more engineering has to go to make sure that various places in our code base is it using the right apas or not so",
    "start": "1849240",
    "end": "1856000"
  },
  {
    "text": "upgrade was always a pain for us so the way we solved it or the way we",
    "start": "1856000",
    "end": "1861799"
  },
  {
    "text": "are solving it is basically with a bunch of principles we made sure that we have a clean separ separation of Kus apis",
    "start": "1861799",
    "end": "1868600"
  },
  {
    "text": "usage from our core services and apps and we we tried AO um mixing the apis",
    "start": "1868600",
    "end": "1875279"
  },
  {
    "text": "the client libraries or the binary packages itself from the source code and",
    "start": "1875279",
    "end": "1880480"
  },
  {
    "text": "that abstraction literally helping us to make sure that our upgrades are not that",
    "start": "1880480",
    "end": "1885559"
  },
  {
    "text": "painful and also CSA storage we made sure that and we'll be using only for epimeral purpose but if we want any",
    "start": "1885559",
    "end": "1892279"
  },
  {
    "text": "persistent storage we use we use some cleaner data abstractions and finally the monolith",
    "start": "1892279",
    "end": "1897880"
  },
  {
    "text": "and microservice architecture itself the dependencies between the services are crucial so when we we we we may had a a",
    "start": "1897880",
    "end": "1906279"
  },
  {
    "text": "big data um platform with maybe 14 or 15 of services running so if you split them",
    "start": "1906279",
    "end": "1912440"
  },
  {
    "text": "to say 90 or 100 microservices it is not that easy at all so it was very critical",
    "start": "1912440",
    "end": "1917919"
  },
  {
    "text": "for us to make sure that the dependencies are called out correctly and designed correctly and a feature",
    "start": "1917919",
    "end": "1923559"
  },
  {
    "text": "like this helped us a lot like for example designing a CH mode option to make sure that a service can be brought",
    "start": "1923559",
    "end": "1930399"
  },
  {
    "text": "down to zero maybe to do that we may need to touch maybe five or eight services so that principle definitely is",
    "start": "1930399",
    "end": "1936639"
  },
  {
    "text": "helping us but there's a lot of work need to do even from our end so it will",
    "start": "1936639",
    "end": "1943039"
  },
  {
    "text": "continue finally towards the hybrid Cloud segment I just want to explain the the previous",
    "start": "1943039",
    "end": "1950799"
  },
  {
    "text": "gen architecture where the data and compute were together and we touch based on that and the second layer is again we",
    "start": "1950799",
    "end": "1957360"
  },
  {
    "text": "try to disate them to storage and compute in VMS in the public cloud and towards the New Gen era we are trying to",
    "start": "1957360",
    "end": "1964639"
  },
  {
    "text": "make sure that we use a proper containerized form factor in kubernetes to make sure that our Gen 3 is what we",
    "start": "1964639",
    "end": "1971399"
  },
  {
    "text": "are looking for and to that um the cloud agility and flexib ibility on Prem",
    "start": "1971399",
    "end": "1978360"
  },
  {
    "text": "really helped a lot and to run the workloads on the right infra that was",
    "start": "1978360",
    "end": "1984240"
  },
  {
    "text": "crucial for us so we want to make sure that we have the unified deployment architecture and lake house that is",
    "start": "1984240",
    "end": "1990039"
  },
  {
    "text": "powered by apach Iceberg made sure that the data life cycle is very easy to",
    "start": "1990039",
    "end": "1996000"
  },
  {
    "text": "maintain and finally the onboarding of the new application is much more simpler now because it is containerized we made",
    "start": "1996000",
    "end": "2003399"
  },
  {
    "text": "sure that new application can just come on and users can come in and then make the best out of our",
    "start": "2003399",
    "end": "2009360"
  },
  {
    "text": "platform so how do we see the new architecture so I want to start with platform admin so they were one of the",
    "start": "2009360",
    "end": "2016559"
  },
  {
    "text": "pillars uh we were using our platform so we wanted to make sure that their life is easy and the the citizen developers",
    "start": "2016559",
    "end": "2024799"
  },
  {
    "text": "within that our customer orc so they make sure that they use the uh platform",
    "start": "2024799",
    "end": "2030320"
  },
  {
    "text": "provided by the admins and develop their applications on top of that and finally the business users within their or get",
    "start": "2030320",
    "end": "2037600"
  },
  {
    "text": "that application and they make some more inferences be a quarterly Business Report or any of those things so",
    "start": "2037600",
    "end": "2044919"
  },
  {
    "text": "addressing all three use user segments were very crucial for us and that made sure and with that we were able to",
    "start": "2044919",
    "end": "2051720"
  },
  {
    "text": "design something like a a advanced hybrid platform which can scale to any",
    "start": "2051720",
    "end": "2059158"
  },
  {
    "text": "type of public cloud or private cloud with a proper governance layer and run",
    "start": "2059159",
    "end": "2064599"
  },
  {
    "text": "different Services instead of servers or application these are nothing but the experience or services and then give",
    "start": "2064599",
    "end": "2072320"
  },
  {
    "text": "that as a platform for running your AI workloads so this is the final um",
    "start": "2072320",
    "end": "2078280"
  },
  {
    "text": "platform that we ended up with so with that I will close my talk if you have",
    "start": "2078280",
    "end": "2085398"
  },
  {
    "text": "any questions",
    "start": "2085399",
    "end": "2088200"
  },
  {
    "text": "please thank you",
    "start": "2095280",
    "end": "2098879"
  },
  {
    "text": "hi I was interested to say about the Pache unicorn um did you ever compare the performance of that to spark",
    "start": "2101760",
    "end": "2107480"
  },
  {
    "text": "operator for for running spark batch jobs on kubernetes yeah so the the virtual cluster of the spark experience",
    "start": "2107480",
    "end": "2114280"
  },
  {
    "text": "that I show we were using Apachi Livy so Livy as an endpoint um was used to",
    "start": "2114280",
    "end": "2120119"
  },
  {
    "text": "submit the spark jobs and then unicorn was helping to schedule them but we do have integration the unicorn schedu has",
    "start": "2120119",
    "end": "2126920"
  },
  {
    "text": "integration with the spark operator so you can use the spark operator itself and with that it will be scheduled by",
    "start": "2126920",
    "end": "2133040"
  },
  {
    "text": "unicorn so we have few blocks out how to use that but internally within Cloud we were using Ley insur House Park operator",
    "start": "2133040",
    "end": "2140800"
  },
  {
    "text": "sounds good thank you hi uh so one of the challenges uh we",
    "start": "2140800",
    "end": "2149359"
  },
  {
    "text": "see around U adopting spark on top of kubernetes is around uh uh Shuffle space",
    "start": "2149359",
    "end": "2155440"
  },
  {
    "text": "right so in in in uh in a hardware based model right so we had like local discs which which allowed us to handle Shuffle",
    "start": "2155440",
    "end": "2161839"
  },
  {
    "text": "space effectively so how do you guys solve it in in the decoupled architecture where like uh the",
    "start": "2161839",
    "end": "2167880"
  },
  {
    "text": "containers does might not have the same amount of yeah that's an excellent question so this is one of our concern",
    "start": "2167880",
    "end": "2173400"
  },
  {
    "text": "as well when we migrated to the new spark on kubernetes I did not touch in detail about the storage layer so we we",
    "start": "2173400",
    "end": "2180560"
  },
  {
    "text": "had if you have enough space in your root dis it's much more easier because then you can utilize that space but",
    "start": "2180560",
    "end": "2187880"
  },
  {
    "text": "majority of the deployment you may not be able to get that much of root dis space so what we did was we enabled the",
    "start": "2187880",
    "end": "2194440"
  },
  {
    "text": "spark three feature so spark 3 has a feature with Dynamic partitioning so you can say that in which partition that you",
    "start": "2194440",
    "end": "2201560"
  },
  {
    "text": "can actually run um like use your Shuffle so we Mount some maybe an EFS",
    "start": "2201560",
    "end": "2208200"
  },
  {
    "text": "volume some high performance data volumes and then use that for the Shuffle by making use of that Spar",
    "start": "2208200",
    "end": "2213960"
  },
  {
    "text": "functionality but it is available only in Spar three okay so that is one of the biggest challenge thank you so much yeah",
    "start": "2213960",
    "end": "2219920"
  },
  {
    "text": "that's helpful",
    "start": "2219920",
    "end": "2223200"
  }
]
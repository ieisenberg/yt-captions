[
  {
    "start": "0",
    "end": "70000"
  },
  {
    "text": "okay hi everybody my name is Luka Sarah",
    "start": "30",
    "end": "3030"
  },
  {
    "text": "Marian I am a senior software engineer",
    "start": "3030",
    "end": "4790"
  },
  {
    "text": "at Red Hat and we're gonna be talking",
    "start": "4790",
    "end": "7350"
  },
  {
    "text": "about automating GPU infrastructure for",
    "start": "7350",
    "end": "9389"
  },
  {
    "text": "kubernetes for container linux this",
    "start": "9389",
    "end": "12960"
  },
  {
    "text": "sounds like really specific to container",
    "start": "12960",
    "end": "15719"
  },
  {
    "text": "linux but I think that you'll find that",
    "start": "15719",
    "end": "19020"
  },
  {
    "text": "it actually generalizes well to Linux in",
    "start": "19020",
    "end": "22140"
  },
  {
    "text": "general and we're going to be doing a",
    "start": "22140",
    "end": "24300"
  },
  {
    "text": "little bit deeper dive into somewhat",
    "start": "24300",
    "end": "26099"
  },
  {
    "text": "like the nitty gritty of getting kernel",
    "start": "26099",
    "end": "29279"
  },
  {
    "text": "modules and stuff set up for your nodes",
    "start": "29279",
    "end": "30720"
  },
  {
    "text": "and I think that this will complement",
    "start": "30720",
    "end": "32398"
  },
  {
    "text": "well some of the other talks we had in",
    "start": "32399",
    "end": "34050"
  },
  {
    "text": "koukin so far related the GPU is like I",
    "start": "34050",
    "end": "36480"
  },
  {
    "text": "know it's talked yesterday and we're",
    "start": "36480",
    "end": "37770"
  },
  {
    "text": "here to talk just a half an hour ago",
    "start": "37770",
    "end": "41450"
  },
  {
    "text": "the goal really is to take you from",
    "start": "41809",
    "end": "44969"
  },
  {
    "text": "thinking that you know everything about",
    "start": "44969",
    "end": "46550"
  },
  {
    "text": "compiling GPUs GPU drivers to doubting",
    "start": "46550",
    "end": "51329"
  },
  {
    "text": "everything you know and then to once",
    "start": "51329",
    "end": "52620"
  },
  {
    "text": "again believing that you kind of know",
    "start": "52620",
    "end": "54210"
  },
  {
    "text": "things as well and if the demo gods like",
    "start": "54210",
    "end": "57449"
  },
  {
    "text": "it we'll have a demo as well where will",
    "start": "57449",
    "end": "61739"
  },
  {
    "text": "bring up a kubernetes cluster accelerate",
    "start": "61739",
    "end": "64378"
  },
  {
    "text": "with get people with GPUs and and all",
    "start": "64379",
    "end": "67590"
  },
  {
    "text": "that to take under ten minutes so let's",
    "start": "67590",
    "end": "69659"
  },
  {
    "text": "see what happens first and foremost the",
    "start": "69659",
    "end": "73409"
  },
  {
    "start": "70000",
    "end": "94000"
  },
  {
    "text": "astute observer will see that all of the",
    "start": "73409",
    "end": "75270"
  },
  {
    "text": "slides are branded with a red hat but",
    "start": "75270",
    "end": "76799"
  },
  {
    "text": "the shed said that I work at core OS",
    "start": "76799",
    "end": "78150"
  },
  {
    "text": "this is not a mistake Korra was recently",
    "start": "78150",
    "end": "80610"
  },
  {
    "text": "acquired and we very happily join",
    "start": "80610",
    "end": "83220"
  },
  {
    "text": "everyone at Red Hat if you have any",
    "start": "83220",
    "end": "85590"
  },
  {
    "text": "questions for Cora West's related things",
    "start": "85590",
    "end": "88020"
  },
  {
    "text": "or red hat related things please grab me",
    "start": "88020",
    "end": "90180"
  },
  {
    "text": "or any other Red Hat person and I'd be",
    "start": "90180",
    "end": "92400"
  },
  {
    "text": "very happy to talk to you so a little",
    "start": "92400",
    "end": "95400"
  },
  {
    "start": "94000",
    "end": "135000"
  },
  {
    "text": "bit about me like I said my name is",
    "start": "95400",
    "end": "97829"
  },
  {
    "text": "Lucas I live in Berlin I am an",
    "start": "97829",
    "end": "101250"
  },
  {
    "text": "electrical engineer",
    "start": "101250",
    "end": "102299"
  },
  {
    "text": "I studied robotics and controls and I",
    "start": "102299",
    "end": "105119"
  },
  {
    "text": "work for the last year and a half on the",
    "start": "105119",
    "end": "108540"
  },
  {
    "text": "tectonic installer at core OS and now",
    "start": "108540",
    "end": "111600"
  },
  {
    "text": "I'm working on bringing everything that",
    "start": "111600",
    "end": "113009"
  },
  {
    "text": "we learned from tectonic onto openshift",
    "start": "113009",
    "end": "115590"
  },
  {
    "text": "in my spare time though outside of Red",
    "start": "115590",
    "end": "118799"
  },
  {
    "text": "Hat and outside of kubernetes I like to",
    "start": "118799",
    "end": "120630"
  },
  {
    "text": "work on machine learning projects and",
    "start": "120630",
    "end": "122759"
  },
  {
    "text": "controls related things I work a lot",
    "start": "122759",
    "end": "125280"
  },
  {
    "text": "with this other guy his name is Daniel",
    "start": "125280",
    "end": "126869"
  },
  {
    "text": "he's my twin brother he also has a funny",
    "start": "126869",
    "end": "130229"
  },
  {
    "text": "looking github avatar and we're always",
    "start": "130229",
    "end": "131910"
  },
  {
    "text": "working on machine learning projects",
    "start": "131910",
    "end": "133260"
  },
  {
    "text": "they got",
    "start": "133260",
    "end": "133550"
  },
  {
    "text": "so one of the issues that we see when",
    "start": "133550",
    "end": "137610"
  },
  {
    "start": "135000",
    "end": "170000"
  },
  {
    "text": "we're working on projects for the first",
    "start": "137610",
    "end": "140130"
  },
  {
    "text": "time is that since we live so far apart",
    "start": "140130",
    "end": "142500"
  },
  {
    "text": "sometimes collaborating can be difficult",
    "start": "142500",
    "end": "144860"
  },
  {
    "text": "for example we're sharing our code maybe",
    "start": "144860",
    "end": "148890"
  },
  {
    "text": "on a jupiter notebook or something but",
    "start": "148890",
    "end": "150540"
  },
  {
    "text": "we also want to share our hardware so",
    "start": "150540",
    "end": "151920"
  },
  {
    "text": "that we can both train our models in an",
    "start": "151920",
    "end": "153810"
  },
  {
    "text": "accelerated way it makes no sense if I",
    "start": "153810",
    "end": "155850"
  },
  {
    "text": "have the hardware and Danny has to wait",
    "start": "155850",
    "end": "157680"
  },
  {
    "text": "for me to be up so you can send me code",
    "start": "157680",
    "end": "159720"
  },
  {
    "text": "and I can train something that just",
    "start": "159720",
    "end": "161340"
  },
  {
    "text": "doesn't work but luckily for us we are",
    "start": "161340",
    "end": "164190"
  },
  {
    "text": "at coop Connie you and if we just put",
    "start": "164190",
    "end": "167250"
  },
  {
    "text": "our work load onto kubernetes it solves",
    "start": "167250",
    "end": "168870"
  },
  {
    "text": "everything and we can go home early",
    "start": "168870",
    "end": "169920"
  },
  {
    "text": "right what we will see is that maybe",
    "start": "169920",
    "end": "172950"
  },
  {
    "text": "it's a little bit trickier than this",
    "start": "172950",
    "end": "174470"
  },
  {
    "text": "right here we have the IKEA instructions",
    "start": "174470",
    "end": "177720"
  },
  {
    "text": "for how to build a kubernetes cluster",
    "start": "177720",
    "end": "180420"
  },
  {
    "text": "powered by GPUs I wish it was this",
    "start": "180420",
    "end": "184709"
  },
  {
    "text": "simple you just plug these things in",
    "start": "184709",
    "end": "186090"
  },
  {
    "text": "together but maybe it's actually not so",
    "start": "186090",
    "end": "187730"
  },
  {
    "text": "say that you have you know your CUDA",
    "start": "187730",
    "end": "190590"
  },
  {
    "text": "powered work load be at tensorflow or",
    "start": "190590",
    "end": "192989"
  },
  {
    "text": "Jupiter notebook or something and you",
    "start": "192989",
    "end": "195720"
  },
  {
    "text": "package it up in a container with all of",
    "start": "195720",
    "end": "197010"
  },
  {
    "text": "its dependencies you use kubernetes to",
    "start": "197010",
    "end": "200010"
  },
  {
    "text": "manage container its life cycle expose",
    "start": "200010",
    "end": "201959"
  },
  {
    "text": "the service to the internet so that I",
    "start": "201959",
    "end": "203640"
  },
  {
    "text": "can log in on a website and be like",
    "start": "203640",
    "end": "205290"
  },
  {
    "text": "Jupiter notebook around these commands I",
    "start": "205290",
    "end": "207269"
  },
  {
    "text": "accelerate everything using Nvidia and",
    "start": "207269",
    "end": "209489"
  },
  {
    "text": "then personally I run all of my",
    "start": "209489",
    "end": "211170"
  },
  {
    "text": "kubernetes clusters on top of core OS",
    "start": "211170",
    "end": "212640"
  },
  {
    "text": "just because I like container Linux",
    "start": "212640",
    "end": "216200"
  },
  {
    "text": "because it gives me like low maintenance",
    "start": "216200",
    "end": "218130"
  },
  {
    "text": "overhead everything updates",
    "start": "218130",
    "end": "219690"
  },
  {
    "text": "automatically and this is all great but",
    "start": "219690",
    "end": "222840"
  },
  {
    "text": "as we're going to see some of these",
    "start": "222840",
    "end": "224970"
  },
  {
    "text": "components are not very obvious we know",
    "start": "224970",
    "end": "226860"
  },
  {
    "text": "how to plug in a workload into",
    "start": "226860",
    "end": "228150"
  },
  {
    "text": "kubernetes we're all at coop con we've",
    "start": "228150",
    "end": "229829"
  },
  {
    "text": "done this before just last talk half an",
    "start": "229829",
    "end": "233340"
  },
  {
    "text": "hour ago ro he'd explained in very great",
    "start": "233340",
    "end": "235290"
  },
  {
    "text": "detail how you can plug kubernetes into",
    "start": "235290",
    "end": "239239"
  },
  {
    "text": "into NVIDIA GPUs and how to use a device",
    "start": "239239",
    "end": "242400"
  },
  {
    "text": "plug-in to accomplish this but the one",
    "start": "242400",
    "end": "243930"
  },
  {
    "text": "thing that's still a little bit",
    "start": "243930",
    "end": "245040"
  },
  {
    "text": "questionable for a lot of people out",
    "start": "245040",
    "end": "246959"
  },
  {
    "text": "there and is a little bit fragment in",
    "start": "246959",
    "end": "248220"
  },
  {
    "text": "the community is how do you get your GPU",
    "start": "248220",
    "end": "250110"
  },
  {
    "text": "drivers and how do you get NVIDIA GPUs",
    "start": "250110",
    "end": "252959"
  },
  {
    "text": "working on Linux in the first place",
    "start": "252959",
    "end": "254340"
  },
  {
    "text": "so really quickly we have a pop quiz I",
    "start": "254340",
    "end": "257489"
  },
  {
    "start": "255000",
    "end": "294000"
  },
  {
    "text": "guess you guys were not expecting this",
    "start": "257489",
    "end": "259040"
  },
  {
    "text": "it should be very easy if you guys were",
    "start": "259040",
    "end": "261989"
  },
  {
    "text": "just in the last talk row he actually",
    "start": "261989",
    "end": "264210"
  },
  {
    "text": "covered each of the four points that I'm",
    "start": "264210",
    "end": "266010"
  },
  {
    "text": "looking for does that",
    "start": "266010",
    "end": "267030"
  },
  {
    "text": "anybody know what are the four things",
    "start": "267030",
    "end": "268740"
  },
  {
    "text": "that I need to get my GPU working on",
    "start": "268740",
    "end": "270770"
  },
  {
    "text": "Linux machine can you just call them out",
    "start": "270770",
    "end": "273210"
  },
  {
    "text": "I need drivers this is actually two of",
    "start": "273210",
    "end": "277110"
  },
  {
    "text": "the things so this could be the kernel",
    "start": "277110",
    "end": "278580"
  },
  {
    "text": "modules and the libraries what else I",
    "start": "278580",
    "end": "280080"
  },
  {
    "text": "need I need GPUs this is the obvious one",
    "start": "280080",
    "end": "283440"
  },
  {
    "text": "a lot of people miss and what's the last",
    "start": "283440",
    "end": "284610"
  },
  {
    "text": "thing I need well I need my CUDA",
    "start": "284610",
    "end": "288300"
  },
  {
    "text": "libraries on my workload right if I want",
    "start": "288300",
    "end": "290100"
  },
  {
    "text": "to use a CUDA accelerated workload I",
    "start": "290100",
    "end": "291450"
  },
  {
    "text": "need to have CUDA libraries as well okay",
    "start": "291450",
    "end": "294180"
  },
  {
    "start": "294000",
    "end": "325000"
  },
  {
    "text": "so here we have an example of what our",
    "start": "294180",
    "end": "297150"
  },
  {
    "text": "anatomy of a CUDA workload might look",
    "start": "297150",
    "end": "299190"
  },
  {
    "text": "like so I have my application at the",
    "start": "299190",
    "end": "300900"
  },
  {
    "text": "very top this container comes packaged",
    "start": "300900",
    "end": "303240"
  },
  {
    "text": "in with my cuda live libraries as well",
    "start": "303240",
    "end": "308220"
  },
  {
    "text": "my you know user plays my user level",
    "start": "308220",
    "end": "310140"
  },
  {
    "text": "libraries",
    "start": "310140",
    "end": "310620"
  },
  {
    "text": "I need my Nvidia device files that get",
    "start": "310620",
    "end": "313410"
  },
  {
    "text": "created um and you know these are",
    "start": "313410",
    "end": "316620"
  },
  {
    "text": "created once I've loaded my kernel",
    "start": "316620",
    "end": "318330"
  },
  {
    "text": "modules I create the device nodes and",
    "start": "318330",
    "end": "320700"
  },
  {
    "text": "obviously at the very bottom I need",
    "start": "320700",
    "end": "322500"
  },
  {
    "text": "might be GPUs as well so using the",
    "start": "322500",
    "end": "326160"
  },
  {
    "start": "325000",
    "end": "363000"
  },
  {
    "text": "knowledge that we just had in the quiz",
    "start": "326160",
    "end": "327360"
  },
  {
    "text": "we can fill in our IKEA diagram a little",
    "start": "327360",
    "end": "329370"
  },
  {
    "text": "bit more and we can see that the GPU",
    "start": "329370",
    "end": "332340"
  },
  {
    "text": "drivers sorry the the CUDA libraries",
    "start": "332340",
    "end": "334590"
  },
  {
    "text": "come for free thankfully that all the",
    "start": "334590",
    "end": "336540"
  },
  {
    "text": "folks at Nvidia are providing docker",
    "start": "336540",
    "end": "338610"
  },
  {
    "text": "base images for CUDA that packaged the",
    "start": "338610",
    "end": "340919"
  },
  {
    "text": "CUDA libraries for us so we can build",
    "start": "340919",
    "end": "342539"
  },
  {
    "text": "our containers on top of that that's",
    "start": "342539",
    "end": "343620"
  },
  {
    "text": "very great that comes for free assuming",
    "start": "343620",
    "end": "346229"
  },
  {
    "text": "somebody in the audience buys me a GPU",
    "start": "346229",
    "end": "347970"
  },
  {
    "text": "we have a GPU so we can check that off",
    "start": "347970",
    "end": "349729"
  },
  {
    "text": "the two things that we don't really know",
    "start": "349729",
    "end": "351930"
  },
  {
    "text": "that are kind of still question marks",
    "start": "351930",
    "end": "353789"
  },
  {
    "text": "are where do the Nvidia libraries come",
    "start": "353789",
    "end": "355919"
  },
  {
    "text": "from and then also where do the kernel",
    "start": "355919",
    "end": "358530"
  },
  {
    "text": "modules come from and this is actually",
    "start": "358530",
    "end": "361830"
  },
  {
    "text": "kind of a trickier question",
    "start": "361830",
    "end": "363830"
  },
  {
    "start": "363000",
    "end": "399000"
  },
  {
    "text": "it turns out that the Linux community is",
    "start": "363830",
    "end": "366330"
  },
  {
    "text": "a little bit fragmented here right like",
    "start": "366330",
    "end": "368010"
  },
  {
    "text": "for example if I am on Ubuntu I can sudo",
    "start": "368010",
    "end": "370830"
  },
  {
    "text": "apt-get install my Nvidia drivers or",
    "start": "370830",
    "end": "372900"
  },
  {
    "text": "something if I'm on fedora I can do the",
    "start": "372900",
    "end": "374220"
  },
  {
    "text": "same thing but what happens if I'm on",
    "start": "374220",
    "end": "375960"
  },
  {
    "text": "container Linux where I don't have a",
    "start": "375960",
    "end": "377130"
  },
  {
    "text": "package manager right and then even if I",
    "start": "377130",
    "end": "380729"
  },
  {
    "text": "did have a package manager what happens",
    "start": "380729",
    "end": "382110"
  },
  {
    "text": "with my OS upgrades and my kernel",
    "start": "382110",
    "end": "384210"
  },
  {
    "text": "version changes and now my kernel",
    "start": "384210",
    "end": "385650"
  },
  {
    "text": "modules don't work what happens then",
    "start": "385650",
    "end": "386789"
  },
  {
    "text": "right do I just have downtime on my",
    "start": "386789",
    "end": "389940"
  },
  {
    "text": "server do I have to go in and manually",
    "start": "389940",
    "end": "391380"
  },
  {
    "text": "fix this again what do I do",
    "start": "391380",
    "end": "392910"
  },
  {
    "text": "so even though we don't have a package",
    "start": "392910",
    "end": "396570"
  },
  {
    "text": "manager let's not be deterred let's get",
    "start": "396570",
    "end": "399180"
  },
  {
    "text": "our kernel modules built for container",
    "start": "399180",
    "end": "400500"
  },
  {
    "text": "Linux",
    "start": "400500",
    "end": "400860"
  },
  {
    "text": "so the first thing we do all do when we",
    "start": "400860",
    "end": "402449"
  },
  {
    "text": "want to do this as we go to the docks",
    "start": "402449",
    "end": "403650"
  },
  {
    "text": "right and we go to the dogs to go to the",
    "start": "403650",
    "end": "406169"
  },
  {
    "text": "documentation website and we say all",
    "start": "406169",
    "end": "407909"
  },
  {
    "text": "right which packages already exist scent",
    "start": "407909",
    "end": "411539"
  },
  {
    "text": "OS fedora I don't see container Linux on",
    "start": "411539",
    "end": "415229"
  },
  {
    "text": "here so I'm sorry I wasted everybody's",
    "start": "415229",
    "end": "417810"
  },
  {
    "text": "time there will be no GPUs on container",
    "start": "417810",
    "end": "419939"
  },
  {
    "text": "Linux you can all go home this is it",
    "start": "419939",
    "end": "422240"
  },
  {
    "text": "but somebody says Lucas don't give up",
    "start": "422240",
    "end": "425639"
  },
  {
    "text": "after all why don't you just download",
    "start": "425639",
    "end": "429210"
  },
  {
    "text": "the nvidia installer and compile the",
    "start": "429210",
    "end": "431099"
  },
  {
    "text": "kernel modules yourself you guys are",
    "start": "431099",
    "end": "434219"
  },
  {
    "text": "very smart",
    "start": "434219",
    "end": "434819"
  },
  {
    "text": "I'm not surprised we are at coop Connie",
    "start": "434819",
    "end": "437909"
  },
  {
    "text": "you one of the greatest gatherings of",
    "start": "437909",
    "end": "440009"
  },
  {
    "text": "minds in all of southern Copenhagen so",
    "start": "440009",
    "end": "443460"
  },
  {
    "text": "yeah let's do exactly that I'll take",
    "start": "443460",
    "end": "444719"
  },
  {
    "text": "your advice let's download the kernel",
    "start": "444719",
    "end": "447270"
  },
  {
    "text": "the nvidia installer sources and compile",
    "start": "447270",
    "end": "450419"
  },
  {
    "text": "it ourselves right what could go wrong",
    "start": "450419",
    "end": "454129"
  },
  {
    "text": "let's see all right so I download I curl",
    "start": "455599",
    "end": "459750"
  },
  {
    "text": "it down all I need now is to run GCC on",
    "start": "459750",
    "end": "463080"
  },
  {
    "text": "my container links machine except it",
    "start": "463080",
    "end": "465389"
  },
  {
    "text": "turns out the GCC is not installed on",
    "start": "465389",
    "end": "466830"
  },
  {
    "text": "this minimal OS who would have thunk it",
    "start": "466830",
    "end": "469520"
  },
  {
    "text": "okay what do I do now",
    "start": "469520",
    "end": "471960"
  },
  {
    "text": "this is obviously not gonna work right",
    "start": "471960",
    "end": "473969"
  },
  {
    "text": "this is just a no-go from the beginning",
    "start": "473969",
    "end": "475589"
  },
  {
    "text": "okay",
    "start": "475589",
    "end": "476719"
  },
  {
    "text": "your guys's next intuition obviously is",
    "start": "476719",
    "end": "479279"
  },
  {
    "text": "this is a container os why don't we just",
    "start": "479279",
    "end": "480900"
  },
  {
    "text": "run the build in a container if I",
    "start": "480900",
    "end": "482969"
  },
  {
    "text": "googled docker",
    "start": "482969",
    "end": "484039"
  },
  {
    "text": "GCC on Google I get like 50 hits right",
    "start": "484039",
    "end": "487409"
  },
  {
    "text": "okay so great I'll docker run GCC",
    "start": "487409",
    "end": "489810"
  },
  {
    "text": "download the Nvidia installer and then I",
    "start": "489810",
    "end": "492569"
  },
  {
    "text": "follow the doc some more and it says",
    "start": "492569",
    "end": "493889"
  },
  {
    "text": "okay now you just have to provide the",
    "start": "493889",
    "end": "495509"
  },
  {
    "text": "path to the kernel sources all right but",
    "start": "495509",
    "end": "497669"
  },
  {
    "text": "where the kernel sources on container",
    "start": "497669",
    "end": "498839"
  },
  {
    "text": "Linux right like this is a minimal OS",
    "start": "498839",
    "end": "500669"
  },
  {
    "text": "again this doesn't come packaged in the",
    "start": "500669",
    "end": "502620"
  },
  {
    "text": "US where does it come from we shouldn't",
    "start": "502620",
    "end": "504900"
  },
  {
    "text": "have been surprised of course we were",
    "start": "504900",
    "end": "506159"
  },
  {
    "text": "gonna need the kernel sources we're at",
    "start": "506159",
    "end": "507689"
  },
  {
    "text": "the end of the day we're compiling",
    "start": "507689",
    "end": "508680"
  },
  {
    "text": "kernel modules it makes sense that we",
    "start": "508680",
    "end": "510150"
  },
  {
    "text": "have to link against the kernel sources",
    "start": "510150",
    "end": "511740"
  },
  {
    "text": "now the problem is actually even a",
    "start": "511740",
    "end": "514349"
  },
  {
    "text": "little bit trickier than this if you",
    "start": "514349",
    "end": "516930"
  },
  {
    "text": "notice we're running a completely",
    "start": "516930",
    "end": "518518"
  },
  {
    "text": "arbitrary version of GCC right ideally",
    "start": "518519",
    "end": "520740"
  },
  {
    "text": "we should be running the same tool chain",
    "start": "520740",
    "end": "522180"
  },
  {
    "text": "that was used to compile the kernel to",
    "start": "522180",
    "end": "523890"
  },
  {
    "text": "build the kernel modules as well and",
    "start": "523890",
    "end": "525060"
  },
  {
    "text": "this could provide I mean this could",
    "start": "525060",
    "end": "526740"
  },
  {
    "text": "produce completely unexpected results we",
    "start": "526740",
    "end": "528180"
  },
  {
    "text": "don't know this is gonna work or not",
    "start": "528180",
    "end": "529140"
  },
  {
    "text": "even if we had the kernel sources so I",
    "start": "529140",
    "end": "531500"
  },
  {
    "text": "mean this is also just no-go",
    "start": "531500",
    "end": "534270"
  },
  {
    "start": "534000",
    "end": "588000"
  },
  {
    "text": "you guys had very good intuition but we",
    "start": "534270",
    "end": "537330"
  },
  {
    "text": "got nowhere your advice it was very very",
    "start": "537330",
    "end": "540240"
  },
  {
    "text": "well-intentioned but we're no closer to",
    "start": "540240",
    "end": "541950"
  },
  {
    "text": "getting GPUs on container Linux so far",
    "start": "541950",
    "end": "543810"
  },
  {
    "text": "the avatars my github avatar is getting",
    "start": "543810",
    "end": "547110"
  },
  {
    "text": "very impatient and I still don't have my",
    "start": "547110",
    "end": "549300"
  },
  {
    "text": "GPUs right so now what do I do",
    "start": "549300",
    "end": "552290"
  },
  {
    "text": "okay well I Google core OS container",
    "start": "552290",
    "end": "556110"
  },
  {
    "text": "Linux kernel modules the first result is",
    "start": "556110",
    "end": "558600"
  },
  {
    "text": "some docs explaining how to do this on",
    "start": "558600",
    "end": "560399"
  },
  {
    "text": "container like so why didn't we do this",
    "start": "560399",
    "end": "561600"
  },
  {
    "text": "in the beginning it turns out that",
    "start": "561600",
    "end": "563490"
  },
  {
    "text": "there's docs that document exactly how",
    "start": "563490",
    "end": "565980"
  },
  {
    "text": "to compile these kernel modules so",
    "start": "565980",
    "end": "567440"
  },
  {
    "text": "really getting kernel modules working on",
    "start": "567440",
    "end": "569940"
  },
  {
    "text": "container Linux should be as easy and",
    "start": "569940",
    "end": "571680"
  },
  {
    "text": "it's just running these steps in fact if",
    "start": "571680",
    "end": "575640"
  },
  {
    "text": "the steps are very well-documented",
    "start": "575640",
    "end": "577830"
  },
  {
    "text": "automating the compilation of these",
    "start": "577830",
    "end": "579270"
  },
  {
    "text": "kernel modules should be as easy as just",
    "start": "579270",
    "end": "580529"
  },
  {
    "text": "scripting these steps right so now I can",
    "start": "580529",
    "end": "582570"
  },
  {
    "text": "automatically compile my kernel modules",
    "start": "582570",
    "end": "584070"
  },
  {
    "text": "and my Nvidia libraries for containing",
    "start": "584070",
    "end": "586050"
  },
  {
    "text": "Linux just with one script if I look out",
    "start": "586050",
    "end": "589350"
  },
  {
    "start": "588000",
    "end": "936000"
  },
  {
    "text": "in the wild there's actually a few",
    "start": "589350",
    "end": "591420"
  },
  {
    "text": "projects that already do this I went to",
    "start": "591420",
    "end": "594110"
  },
  {
    "text": "koukin North America 2016 and one of the",
    "start": "594110",
    "end": "597870"
  },
  {
    "text": "speakers Rudy Kyoto I think I said his",
    "start": "597870",
    "end": "600810"
  },
  {
    "text": "name right uh from clarify he gave a",
    "start": "600810",
    "end": "603930"
  },
  {
    "text": "speech titled state of the GP Union and",
    "start": "603930",
    "end": "606329"
  },
  {
    "text": "the very last slide made a very brief",
    "start": "606329",
    "end": "608040"
  },
  {
    "text": "mention to this one project called aptly",
    "start": "608040",
    "end": "611040"
  },
  {
    "text": "named core OS Nvidia and it does exactly",
    "start": "611040",
    "end": "613290"
  },
  {
    "text": "that it just automated the instructions",
    "start": "613290",
    "end": "614940"
  },
  {
    "text": "that we saw in the core OS documentation",
    "start": "614940",
    "end": "617790"
  },
  {
    "text": "and it um if I say chorus Nvidia build",
    "start": "617790",
    "end": "622440"
  },
  {
    "text": "you know my version of the of Nvidia",
    "start": "622440",
    "end": "624720"
  },
  {
    "text": "it'll produce the kernel modules and",
    "start": "624720",
    "end": "627300"
  },
  {
    "text": "also libraries so great is that great",
    "start": "627300",
    "end": "630390"
  },
  {
    "text": "does that solve all of our problems it",
    "start": "630390",
    "end": "631890"
  },
  {
    "text": "turns out not really ok so now I have a",
    "start": "631890",
    "end": "634200"
  },
  {
    "text": "way to automatically produce my kernel",
    "start": "634200",
    "end": "636300"
  },
  {
    "text": "modules but how do i Adam ate this",
    "start": "636300",
    "end": "638880"
  },
  {
    "text": "script right next week when container",
    "start": "638880",
    "end": "642029"
  },
  {
    "text": "Linux releases a new version and I'm on",
    "start": "642029",
    "end": "645600"
  },
  {
    "text": "vacation",
    "start": "645600",
    "end": "646170"
  },
  {
    "text": "who's gonna login to my machine and",
    "start": "646170",
    "end": "647850"
  },
  {
    "text": "rerun this script and say hey build a",
    "start": "647850",
    "end": "651000"
  },
  {
    "text": "new version for the new kernel or you",
    "start": "651000",
    "end": "654060"
  },
  {
    "text": "know what happens if I want to change to",
    "start": "654060",
    "end": "656910"
  },
  {
    "text": "a new Nvidia version then what happens",
    "start": "656910",
    "end": "659190"
  },
  {
    "text": "how do i tomatoes secondly how can I",
    "start": "659190",
    "end": "662370"
  },
  {
    "text": "make this work in a way that's native to",
    "start": "662370",
    "end": "664890"
  },
  {
    "text": "kubernetes right like",
    "start": "664890",
    "end": "667660"
  },
  {
    "text": "ideally I don't want to have to like SSH",
    "start": "667660",
    "end": "670930"
  },
  {
    "text": "into my machines or I don't want to have",
    "start": "670930",
    "end": "672430"
  },
  {
    "text": "to create a cron job to do this or",
    "start": "672430",
    "end": "675069"
  },
  {
    "text": "anything like that right I would want to",
    "start": "675069",
    "end": "676209"
  },
  {
    "text": "just have a pod something native in",
    "start": "676209",
    "end": "678610"
  },
  {
    "text": "kubernetes that does this automatically",
    "start": "678610",
    "end": "680680"
  },
  {
    "text": "for me so the obvious answer is Lucas",
    "start": "680680",
    "end": "682720"
  },
  {
    "text": "why don't you just shove it all in a",
    "start": "682720",
    "end": "684339"
  },
  {
    "text": "container and this is the right",
    "start": "684339",
    "end": "685389"
  },
  {
    "text": "intuition putting this build script into",
    "start": "685389",
    "end": "687519"
  },
  {
    "text": "a container it's definitely the right",
    "start": "687519",
    "end": "688870"
  },
  {
    "text": "idea the nuances are a little bit",
    "start": "688870",
    "end": "690670"
  },
  {
    "text": "trickier because container Linux the the",
    "start": "690670",
    "end": "693819"
  },
  {
    "text": "instructions provided for building",
    "start": "693819",
    "end": "696009"
  },
  {
    "text": "kernel modules they tell you to download",
    "start": "696009",
    "end": "698290"
  },
  {
    "text": "a developer container that contains",
    "start": "698290",
    "end": "701279"
  },
  {
    "text": "these include the kernel sources as well",
    "start": "701279",
    "end": "704410"
  },
  {
    "text": "as the tool chain used to build the OS",
    "start": "704410",
    "end": "705810"
  },
  {
    "text": "so the nuances of running this container",
    "start": "705810",
    "end": "708610"
  },
  {
    "text": "inside of another container is a little",
    "start": "708610",
    "end": "709810"
  },
  {
    "text": "bit tricky but this is definitely the",
    "start": "709810",
    "end": "711040"
  },
  {
    "text": "right intuition in fact if I run this",
    "start": "711040",
    "end": "714100"
  },
  {
    "text": "inside of a container I can run my",
    "start": "714100",
    "end": "715980"
  },
  {
    "text": "kernel compiler sorry my kernel module",
    "start": "715980",
    "end": "718720"
  },
  {
    "text": "compiler in a daemon set that's",
    "start": "718720",
    "end": "720490"
  },
  {
    "text": "scheduled onto all of my GPU nodes if I",
    "start": "720490",
    "end": "722589"
  },
  {
    "text": "schedule it until every single GPU node",
    "start": "722589",
    "end": "724329"
  },
  {
    "text": "I no longer have to manually SSH onto my",
    "start": "724329",
    "end": "726430"
  },
  {
    "text": "machines and do anything right every",
    "start": "726430",
    "end": "729190"
  },
  {
    "text": "single time that my machine updates and",
    "start": "729190",
    "end": "730990"
  },
  {
    "text": "reboots my kernel modules will get",
    "start": "730990",
    "end": "732610"
  },
  {
    "text": "automatically recompiled for me so this",
    "start": "732610",
    "end": "734589"
  },
  {
    "text": "saves me a lot of headache in fact this",
    "start": "734589",
    "end": "737410"
  },
  {
    "text": "is exactly what is done in the wild by",
    "start": "737410",
    "end": "740139"
  },
  {
    "text": "the Google platform Google cloud",
    "start": "740139",
    "end": "741850"
  },
  {
    "text": "platform folks so wrote he was just",
    "start": "741850",
    "end": "743410"
  },
  {
    "text": "speaking about this they created a",
    "start": "743410",
    "end": "746339"
  },
  {
    "text": "container that is exactly that for cost",
    "start": "746339",
    "end": "749079"
  },
  {
    "text": "the container optimized OS like other",
    "start": "749079",
    "end": "751360"
  },
  {
    "text": "like container Linux it is very minimal",
    "start": "751360",
    "end": "753699"
  },
  {
    "text": "but this container is a script the",
    "start": "753699",
    "end": "755920"
  },
  {
    "text": "Downloads the cost kernel sources",
    "start": "755920",
    "end": "757899"
  },
  {
    "text": "compiled the kernel modules and just",
    "start": "757899",
    "end": "759939"
  },
  {
    "text": "dump them in a host volume that later",
    "start": "759939",
    "end": "762699"
  },
  {
    "text": "pods that need to use CUDA or whatever",
    "start": "762699",
    "end": "765130"
  },
  {
    "text": "else can just consume those volumes we",
    "start": "765130",
    "end": "770439"
  },
  {
    "text": "can skip this and come back if we have",
    "start": "770439",
    "end": "771670"
  },
  {
    "text": "time so at the end of the day if I have",
    "start": "771670",
    "end": "776410"
  },
  {
    "text": "a daemon set this runs this container",
    "start": "776410",
    "end": "778589"
  },
  {
    "text": "compiling kernel modules for kubernetes",
    "start": "778589",
    "end": "781029"
  },
  {
    "text": "for any of my nodes it's really as",
    "start": "781029",
    "end": "783639"
  },
  {
    "text": "simple as just saying coop CL coop CTL",
    "start": "783639",
    "end": "785740"
  },
  {
    "text": "apply this daemon set and that is like",
    "start": "785740",
    "end": "789670"
  },
  {
    "text": "the most kubernetes native way I could",
    "start": "789670",
    "end": "790899"
  },
  {
    "text": "think of doing this really quickly I'm",
    "start": "790899",
    "end": "793389"
  },
  {
    "text": "going to terraform apply something so",
    "start": "793389",
    "end": "795459"
  },
  {
    "text": "that by the end of this thing we have a",
    "start": "795459",
    "end": "797589"
  },
  {
    "text": "cluster we can play with",
    "start": "797589",
    "end": "800610"
  },
  {
    "text": "okay very cool",
    "start": "803849",
    "end": "806639"
  },
  {
    "text": "okay so this is it um next what let's",
    "start": "806639",
    "end": "810639"
  },
  {
    "text": "see okay great so now we know how to",
    "start": "810639",
    "end": "816459"
  },
  {
    "text": "compile our kernel module automatically",
    "start": "816459",
    "end": "817779"
  },
  {
    "text": "right this is great this gets the long",
    "start": "817779",
    "end": "818979"
  },
  {
    "text": "way of the way there",
    "start": "818979",
    "end": "819899"
  },
  {
    "text": "but how do I consume these kernel",
    "start": "819899",
    "end": "822159"
  },
  {
    "text": "modules and the libraries once they're",
    "start": "822159",
    "end": "823839"
  },
  {
    "text": "on my machine it turns out that getting",
    "start": "823839",
    "end": "827109"
  },
  {
    "text": "these getting these kernel modules and",
    "start": "827109",
    "end": "829089"
  },
  {
    "text": "getting the libraries working with any",
    "start": "829089",
    "end": "830919"
  },
  {
    "text": "sample workload is actually very",
    "start": "830919",
    "end": "832059"
  },
  {
    "text": "straightforward here I have a toy",
    "start": "832059",
    "end": "835149"
  },
  {
    "text": "workload that is an nvidia cuda",
    "start": "835149",
    "end": "837519"
  },
  {
    "text": "container and i'm just going to run the",
    "start": "837519",
    "end": "839769"
  },
  {
    "text": "nvidia SMI utility which is the system",
    "start": "839769",
    "end": "843519"
  },
  {
    "text": "management interface it just prints out",
    "start": "843519",
    "end": "845019"
  },
  {
    "text": "statistics about like you know memory",
    "start": "845019",
    "end": "846909"
  },
  {
    "text": "consumption temperature whatever about",
    "start": "846909",
    "end": "848589"
  },
  {
    "text": "the attached GPUs on your machine and",
    "start": "848589",
    "end": "850029"
  },
  {
    "text": "the only thing I really need to do is",
    "start": "850029",
    "end": "852189"
  },
  {
    "text": "say tell my container runtime to mount",
    "start": "852189",
    "end": "854979"
  },
  {
    "text": "in my device nodes and bind mount my",
    "start": "854979",
    "end": "858759"
  },
  {
    "text": "libraries and then that's all I really",
    "start": "858759",
    "end": "861909"
  },
  {
    "text": "need one of the issues that we see with",
    "start": "861909",
    "end": "864999"
  },
  {
    "text": "this though is that I'm leaning very",
    "start": "864999",
    "end": "867399"
  },
  {
    "text": "heavily on my container runtime to do",
    "start": "867399",
    "end": "869019"
  },
  {
    "text": "this for me",
    "start": "869019",
    "end": "870249"
  },
  {
    "text": "in fact I'm leaning so heavily on it",
    "start": "870249",
    "end": "872979"
  },
  {
    "text": "that I need to tell it exactly where my",
    "start": "872979",
    "end": "875229"
  },
  {
    "text": "libraries are on my hosts and which",
    "start": "875229",
    "end": "877599"
  },
  {
    "text": "devices I want to use and if we try to",
    "start": "877599",
    "end": "881349"
  },
  {
    "text": "extrapolate this to kubernetes and we",
    "start": "881349",
    "end": "883119"
  },
  {
    "text": "ask how can we automate this exact same",
    "start": "883119",
    "end": "885099"
  },
  {
    "text": "task for kubernetes it means that we",
    "start": "885099",
    "end": "887079"
  },
  {
    "text": "would have to enter pots back specify I",
    "start": "887079",
    "end": "889289"
  },
  {
    "text": "want to use a volume mount with these",
    "start": "889289",
    "end": "891939"
  },
  {
    "text": "exact host paths for my my shared",
    "start": "891939",
    "end": "896139"
  },
  {
    "text": "libraries I need to and then my my",
    "start": "896139",
    "end": "898779"
  },
  {
    "text": "application needs to know which device",
    "start": "898779",
    "end": "900429"
  },
  {
    "text": "nodes to use and this obviously is not",
    "start": "900429",
    "end": "902139"
  },
  {
    "text": "gonna scale well right it means that I",
    "start": "902139",
    "end": "905079"
  },
  {
    "text": "have the very tightly couple the",
    "start": "905079",
    "end": "907409"
  },
  {
    "text": "representation of my hosts to my pod",
    "start": "907409",
    "end": "910599"
  },
  {
    "text": "spec and now suddenly if I want to share",
    "start": "910599",
    "end": "912339"
  },
  {
    "text": "my pods back across nodes that I have my",
    "start": "912339",
    "end": "914409"
  },
  {
    "text": "libraries installed differently or",
    "start": "914409",
    "end": "915669"
  },
  {
    "text": "across different clusters that it's not",
    "start": "915669",
    "end": "917469"
  },
  {
    "text": "gonna work anymore I'm gonna have to",
    "start": "917469",
    "end": "918669"
  },
  {
    "text": "modify my pod specs oh very good",
    "start": "918669",
    "end": "920939"
  },
  {
    "text": "let's see",
    "start": "920939",
    "end": "924179"
  },
  {
    "text": "so this is just doing some GPG stuff for",
    "start": "929200",
    "end": "934130"
  },
  {
    "text": "our cluster very good you guys should",
    "start": "934130",
    "end": "937370"
  },
  {
    "start": "936000",
    "end": "992000"
  },
  {
    "text": "have told me okay",
    "start": "937370",
    "end": "940580"
  },
  {
    "text": "it turns out that things - all the",
    "start": "940580",
    "end": "943760"
  },
  {
    "text": "efforts that came into the device",
    "start": "943760",
    "end": "945170"
  },
  {
    "text": "plug-in system in kubernetes 110 the man",
    "start": "945170",
    "end": "951530"
  },
  {
    "text": "again let's see okay thanks to all the",
    "start": "951530",
    "end": "959780"
  },
  {
    "text": "work that went to the device plugin",
    "start": "959780",
    "end": "961250"
  },
  {
    "text": "system all of the work of having to buy",
    "start": "961250",
    "end": "965570"
  },
  {
    "text": "mount in the libraries and stuff comes",
    "start": "965570",
    "end": "967040"
  },
  {
    "text": "for free now the the device plugins",
    "start": "967040",
    "end": "971560"
  },
  {
    "text": "developed for by both Google and also by",
    "start": "971560",
    "end": "975350"
  },
  {
    "text": "Nvidia take care of mounting in the",
    "start": "975350",
    "end": "977540"
  },
  {
    "text": "libraries for us and it means that we no",
    "start": "977540",
    "end": "980120"
  },
  {
    "text": "longer have to specify in our paw spec",
    "start": "980120",
    "end": "981680"
  },
  {
    "text": "explicitly hey I want to use these in",
    "start": "981680",
    "end": "983900"
  },
  {
    "text": "video libraries located here on the host",
    "start": "983900",
    "end": "985400"
  },
  {
    "text": "and my application doesn't have to know",
    "start": "985400",
    "end": "987230"
  },
  {
    "text": "which doesn't have to know which device",
    "start": "987230",
    "end": "990560"
  },
  {
    "text": "nodes to use either in fact the device",
    "start": "990560",
    "end": "995720"
  },
  {
    "start": "992000",
    "end": "1017000"
  },
  {
    "text": "plugin for Google for example is",
    "start": "995720",
    "end": "997430"
  },
  {
    "text": "extremely simple it's only a couple",
    "start": "997430",
    "end": "998870"
  },
  {
    "text": "hundred lines of go and the code that",
    "start": "998870",
    "end": "1000760"
  },
  {
    "text": "does the mounting of the libraries is",
    "start": "1000760",
    "end": "1001990"
  },
  {
    "text": "also similarly very simple so like it's",
    "start": "1001990",
    "end": "1003880"
  },
  {
    "text": "only a couple lines but it means this is",
    "start": "1003880",
    "end": "1006850"
  },
  {
    "text": "the difference between having very",
    "start": "1006850",
    "end": "1008200"
  },
  {
    "text": "tightly coupled pod specs to our",
    "start": "1008200",
    "end": "1009850"
  },
  {
    "text": "infrastructure and having very loosely",
    "start": "1009850",
    "end": "1011380"
  },
  {
    "text": "coupled things where we can just say in",
    "start": "1011380",
    "end": "1012730"
  },
  {
    "text": "a pod spec hey require one GPU and",
    "start": "1012730",
    "end": "1015100"
  },
  {
    "text": "that's it okay",
    "start": "1015100",
    "end": "1017530"
  },
  {
    "text": "so where are we now after all of this we",
    "start": "1017530",
    "end": "1021730"
  },
  {
    "text": "know that we can use a GPU installer to",
    "start": "1021730",
    "end": "1025209"
  },
  {
    "text": "generate our Nvidia libraries get our",
    "start": "1025209",
    "end": "1028089"
  },
  {
    "text": "kernel modules install the kernel",
    "start": "1028090",
    "end": "1029709"
  },
  {
    "text": "modules create device nodes so that",
    "start": "1029709",
    "end": "1032829"
  },
  {
    "text": "would be what everything here right this",
    "start": "1032830",
    "end": "1036490"
  },
  {
    "text": "is everything that's done by the GPU",
    "start": "1036490",
    "end": "1037600"
  },
  {
    "text": "installer this is great so it'll create",
    "start": "1037600",
    "end": "1039760"
  },
  {
    "text": "device nodes that are that have that are",
    "start": "1039760",
    "end": "1042689"
  },
  {
    "text": "have to do with the GPUs that are",
    "start": "1042690",
    "end": "1044740"
  },
  {
    "text": "attached to the host and then the device",
    "start": "1044740",
    "end": "1046300"
  },
  {
    "text": "plug-in takes care of these other areas",
    "start": "1046300",
    "end": "1048189"
  },
  {
    "text": "it's actually what's specifying which",
    "start": "1048190",
    "end": "1050020"
  },
  {
    "text": "volumes I want to mount in to my",
    "start": "1050020",
    "end": "1052330"
  },
  {
    "text": "containers so that my applications at",
    "start": "1052330",
    "end": "1054670"
  },
  {
    "text": "the very top via tensor flow or Jupiter",
    "start": "1054670",
    "end": "1056170"
  },
  {
    "text": "or whatever else don't have to know",
    "start": "1056170",
    "end": "1058030"
  },
  {
    "text": "anything about the",
    "start": "1058030",
    "end": "1059230"
  },
  {
    "text": "on the host that's awesome right okay so",
    "start": "1059230",
    "end": "1064240"
  },
  {
    "text": "now what if we go back to our Kia our",
    "start": "1064240",
    "end": "1067780"
  },
  {
    "text": "IKEA instructions one last time we see",
    "start": "1067780",
    "end": "1070809"
  },
  {
    "text": "that we now have checkboxes on",
    "start": "1070809",
    "end": "1072040"
  },
  {
    "text": "everything we know where our kudo",
    "start": "1072040",
    "end": "1073660"
  },
  {
    "text": "libraries are we have a GPU that you",
    "start": "1073660",
    "end": "1075880"
  },
  {
    "text": "guys got me we have our Nvidia libraries",
    "start": "1075880",
    "end": "1078400"
  },
  {
    "text": "compiled automatically and our kernel",
    "start": "1078400",
    "end": "1080200"
  },
  {
    "text": "modules as well so this is going very",
    "start": "1080200",
    "end": "1082510"
  },
  {
    "text": "good what else do we need",
    "start": "1082510",
    "end": "1084640"
  },
  {
    "text": "I guess this is essentially all of the",
    "start": "1084640",
    "end": "1086020"
  },
  {
    "text": "theory around um automating the GPU",
    "start": "1086020",
    "end": "1088150"
  },
  {
    "text": "infrastructure now we kind of want to",
    "start": "1088150",
    "end": "1090040"
  },
  {
    "text": "take a look at a real-life situation so",
    "start": "1090040",
    "end": "1093240"
  },
  {
    "text": "without further ado let's do a demo I",
    "start": "1093240",
    "end": "1097720"
  },
  {
    "text": "guess what's gonna happen in this demo",
    "start": "1097720",
    "end": "1101440"
  },
  {
    "start": "1101000",
    "end": "1466000"
  },
  {
    "text": "okay so in this demo if you want you can",
    "start": "1101440",
    "end": "1103570"
  },
  {
    "text": "follow along it's on github.com slash",
    "start": "1103570",
    "end": "1106360"
  },
  {
    "text": "squat this is my username kook on you",
    "start": "1106360",
    "end": "1108910"
  },
  {
    "text": "2018 we're gonna be building a cluster",
    "start": "1108910",
    "end": "1112030"
  },
  {
    "text": "using typhoon so this is a very minimal",
    "start": "1112030",
    "end": "1114700"
  },
  {
    "text": "self hosted kubernetes cluster we're",
    "start": "1114700",
    "end": "1117130"
  },
  {
    "text": "going to be using gke it can honestly",
    "start": "1117130",
    "end": "1118480"
  },
  {
    "text": "work on anything",
    "start": "1118480",
    "end": "1120460"
  },
  {
    "text": "I have a GPU installer Damon said that I",
    "start": "1120460",
    "end": "1125679"
  },
  {
    "text": "wrote for container Linux we can use",
    "start": "1125679",
    "end": "1127540"
  },
  {
    "text": "this just last week I found another one",
    "start": "1127540",
    "end": "1129850"
  },
  {
    "text": "so there's actually several",
    "start": "1129850",
    "end": "1130900"
  },
  {
    "text": "implementations of these things like you",
    "start": "1130900",
    "end": "1132400"
  },
  {
    "text": "know this is one of the things where the",
    "start": "1132400",
    "end": "1133809"
  },
  {
    "text": "community is getting very fragmented but",
    "start": "1133809",
    "end": "1135179"
  },
  {
    "text": "we have a GPU installer they were going",
    "start": "1135179",
    "end": "1137260"
  },
  {
    "text": "to use to compile the kernel modules we",
    "start": "1137260",
    "end": "1139600"
  },
  {
    "text": "have the device plugin that is in",
    "start": "1139600",
    "end": "1143020"
  },
  {
    "text": "upstream kubernetes so as of one month",
    "start": "1143020",
    "end": "1145900"
  },
  {
    "text": "ago there is a device plug-in in the",
    "start": "1145900",
    "end": "1148690"
  },
  {
    "text": "kubernetes repository and the cluster",
    "start": "1148690",
    "end": "1150190"
  },
  {
    "text": "add-ons and then we're gonna run a",
    "start": "1150190",
    "end": "1153160"
  },
  {
    "text": "neural network as our sample workload",
    "start": "1153160",
    "end": "1155559"
  },
  {
    "text": "and it's going to do some object",
    "start": "1155559",
    "end": "1156910"
  },
  {
    "text": "detection for us so let's see didn't",
    "start": "1156910",
    "end": "1162960"
  },
  {
    "text": "[Music]",
    "start": "1162960",
    "end": "1166309"
  },
  {
    "text": "very cool very cool okay so what do we",
    "start": "1171700",
    "end": "1178570"
  },
  {
    "text": "have here the if you guys see the",
    "start": "1178570",
    "end": "1181150"
  },
  {
    "text": "terraform here didn't finish running so",
    "start": "1181150",
    "end": "1182440"
  },
  {
    "text": "I'm gonna use my other cluster that I",
    "start": "1182440",
    "end": "1184420"
  },
  {
    "text": "just made this morning that is already",
    "start": "1184420",
    "end": "1186460"
  },
  {
    "text": "built and then we'll apply all the",
    "start": "1186460",
    "end": "1188380"
  },
  {
    "text": "kubernetes manifests and everything that",
    "start": "1188380",
    "end": "1190030"
  },
  {
    "text": "we need to it okay so let's see if the",
    "start": "1190030",
    "end": "1193360"
  },
  {
    "text": "demo gods are kind to us okay very cool",
    "start": "1193360",
    "end": "1198700"
  },
  {
    "text": "so we already created our cluster now",
    "start": "1198700",
    "end": "1201730"
  },
  {
    "text": "we'll all these think we want to do is",
    "start": "1201730",
    "end": "1203200"
  },
  {
    "text": "let's get the nodes let's see how we're",
    "start": "1203200",
    "end": "1206290"
  },
  {
    "text": "doing here okay great so I have a two",
    "start": "1206290",
    "end": "1211120"
  },
  {
    "text": "node cluster I have one controller and",
    "start": "1211120",
    "end": "1213340"
  },
  {
    "text": "then one worker this worker is has a GPU",
    "start": "1213340",
    "end": "1217810"
  },
  {
    "text": "attached to it so let's take a look at",
    "start": "1217810",
    "end": "1224250"
  },
  {
    "text": "what manifests we have here we have our",
    "start": "1224250",
    "end": "1229560"
  },
  {
    "text": "darknet",
    "start": "1229560",
    "end": "1230980"
  },
  {
    "text": "you know our genetic detection",
    "start": "1230980",
    "end": "1233670"
  },
  {
    "text": "deployment we have our device plug-in",
    "start": "1233670",
    "end": "1235780"
  },
  {
    "text": "daemon set and then we have our GPU ins",
    "start": "1235780",
    "end": "1239080"
  },
  {
    "text": "driver installer Damon set as well so",
    "start": "1239080",
    "end": "1242970"
  },
  {
    "text": "let's coop CTL apply let's see what",
    "start": "1242970",
    "end": "1251110"
  },
  {
    "text": "happens yeah very cool that was",
    "start": "1251110",
    "end": "1255130"
  },
  {
    "text": "extremely fast then okay now what we",
    "start": "1255130",
    "end": "1259300"
  },
  {
    "text": "want to do so we did the manifest let's",
    "start": "1259300",
    "end": "1261670"
  },
  {
    "text": "look at the driver installer let's see",
    "start": "1261670",
    "end": "1263710"
  },
  {
    "text": "how this thing is progressing so again",
    "start": "1263710",
    "end": "1267430"
  },
  {
    "text": "this driver installer is running as a",
    "start": "1267430",
    "end": "1269710"
  },
  {
    "text": "daemon set on all the GPU nodes in this",
    "start": "1269710",
    "end": "1271600"
  },
  {
    "text": "case just one it's gonna compile the",
    "start": "1271600",
    "end": "1274090"
  },
  {
    "text": "kernel modules put them on the host disk",
    "start": "1274090",
    "end": "1276310"
  },
  {
    "text": "it's going to modprobe",
    "start": "1276310",
    "end": "1279280"
  },
  {
    "text": "so it's gonna insert the kernel modules",
    "start": "1279280",
    "end": "1280990"
  },
  {
    "text": "it's gonna create device nodes that",
    "start": "1280990",
    "end": "1283240"
  },
  {
    "text": "later we can use using a device plugin",
    "start": "1283240",
    "end": "1285520"
  },
  {
    "text": "okay so let's take a look yeah okay so",
    "start": "1285520",
    "end": "1289120"
  },
  {
    "text": "it actually finished compiling already",
    "start": "1289120",
    "end": "1290410"
  },
  {
    "text": "these errors at the bottom are noise but",
    "start": "1290410",
    "end": "1293740"
  },
  {
    "text": "it this should have worked just fine so",
    "start": "1293740",
    "end": "1295330"
  },
  {
    "text": "let's see we can check the logs of the",
    "start": "1295330",
    "end": "1298360"
  },
  {
    "text": "device plugin to see if indeed the",
    "start": "1298360",
    "end": "1301960"
  },
  {
    "text": "device plugins saw",
    "start": "1301960",
    "end": "1304860"
  },
  {
    "text": "that this is all registered okay this is",
    "start": "1304860",
    "end": "1307880"
  },
  {
    "text": "apparently device plug-in on a different",
    "start": "1307880",
    "end": "1309929"
  },
  {
    "text": "node let's see on the other night what",
    "start": "1309929",
    "end": "1313530"
  },
  {
    "text": "happened okay very cool so the device",
    "start": "1313530",
    "end": "1319230"
  },
  {
    "text": "plugin here is registering a device and",
    "start": "1319230",
    "end": "1323880"
  },
  {
    "text": "video 0 it's in healthy state healthy",
    "start": "1323880",
    "end": "1326040"
  },
  {
    "text": "state so this is exactly what we were",
    "start": "1326040",
    "end": "1329040"
  },
  {
    "text": "hoping for let's take a look at that",
    "start": "1329040",
    "end": "1334380"
  },
  {
    "text": "node let's if we describe the node we",
    "start": "1334380",
    "end": "1335820"
  },
  {
    "text": "should see that it actually has GPUs on",
    "start": "1335820",
    "end": "1338760"
  },
  {
    "text": "it okay let's see we have one NVIDIA GPU",
    "start": "1338760",
    "end": "1346820"
  },
  {
    "text": "and the capacity here yeah perfect so we",
    "start": "1346820",
    "end": "1350760"
  },
  {
    "text": "have the GPUs ideal what else do we see",
    "start": "1350760",
    "end": "1353850"
  },
  {
    "text": "ok let's take a really quick look at",
    "start": "1353850",
    "end": "1357230"
  },
  {
    "text": "what the manifest for the workload looks",
    "start": "1357230",
    "end": "1360570"
  },
  {
    "text": "like so we have some standard deployed",
    "start": "1360570",
    "end": "1364590"
  },
  {
    "text": "on boiler plate we have the command",
    "start": "1364590",
    "end": "1366870"
  },
  {
    "text": "that's just running the the neural",
    "start": "1366870",
    "end": "1370200"
  },
  {
    "text": "network and the interesting stuff is",
    "start": "1370200",
    "end": "1372600"
  },
  {
    "text": "here we have we're specifying one GPU",
    "start": "1372600",
    "end": "1375210"
  },
  {
    "text": "and we're also tolerating the GPU taint",
    "start": "1375210",
    "end": "1380030"
  },
  {
    "text": "very cool ok so the last thing we want",
    "start": "1380030",
    "end": "1388260"
  },
  {
    "text": "to see is let's take a look see if this",
    "start": "1388260",
    "end": "1392360"
  },
  {
    "text": "container is already ready sometimes",
    "start": "1392360",
    "end": "1394650"
  },
  {
    "text": "these things take a long time to",
    "start": "1394650",
    "end": "1395549"
  },
  {
    "text": "download because the the CUDA base",
    "start": "1395549",
    "end": "1398070"
  },
  {
    "text": "images are pretty big sometimes in",
    "start": "1398070",
    "end": "1399419"
  },
  {
    "text": "depending on the network connection ok",
    "start": "1399419",
    "end": "1400980"
  },
  {
    "text": "this already created the container",
    "start": "1400980",
    "end": "1402290"
  },
  {
    "text": "perfect and let's see the last thing so",
    "start": "1402290",
    "end": "1409740"
  },
  {
    "text": "let's check the logs of this ok great so",
    "start": "1409740",
    "end": "1413280"
  },
  {
    "text": "this neural network is running and we're",
    "start": "1413280",
    "end": "1419910"
  },
  {
    "text": "gonna run this is just a sample client",
    "start": "1419910",
    "end": "1423270"
  },
  {
    "text": "app that what this is going to be doing",
    "start": "1423270",
    "end": "1425070"
  },
  {
    "text": "is it's gonna run some OpenCV is just",
    "start": "1425070",
    "end": "1427200"
  },
  {
    "text": "going to be taking photos of me and",
    "start": "1427200",
    "end": "1428280"
  },
  {
    "text": "submitting it to the to the cluster for",
    "start": "1428280",
    "end": "1433309"
  },
  {
    "text": "some object detection so this is me it's",
    "start": "1433309",
    "end": "1436230"
  },
  {
    "text": "just labeling me and seeing that I'm",
    "start": "1436230",
    "end": "1437250"
  },
  {
    "text": "here and this is",
    "start": "1437250",
    "end": "1438240"
  },
  {
    "text": "accelerated by CUDA if I didn't have my",
    "start": "1438240",
    "end": "1440130"
  },
  {
    "text": "kernel modules here and I didn't have a",
    "start": "1440130",
    "end": "1442080"
  },
  {
    "text": "GPU this would be taking like 10 seconds",
    "start": "1442080",
    "end": "1443940"
  },
  {
    "text": "per image but there's actually taking",
    "start": "1443940",
    "end": "1445530"
  },
  {
    "text": "very little time and most of the lag is",
    "start": "1445530",
    "end": "1448020"
  },
  {
    "text": "actually just latency and uploading the",
    "start": "1448020",
    "end": "1449660"
  },
  {
    "text": "and uploading the images to the server",
    "start": "1449660",
    "end": "1452340"
  },
  {
    "text": "so this is all working and what's the",
    "start": "1452340",
    "end": "1456630"
  },
  {
    "text": "result in here so this is our demo this",
    "start": "1456630",
    "end": "1458940"
  },
  {
    "text": "concludes the interactive portion how",
    "start": "1458940",
    "end": "1463350"
  },
  {
    "text": "did I make this fullscreen again well",
    "start": "1463350",
    "end": "1466050"
  },
  {
    "start": "1466000",
    "end": "1577000"
  },
  {
    "text": "okay so what happened here we saw that",
    "start": "1466050",
    "end": "1470480"
  },
  {
    "text": "very quickly if we bring up a kubernetes",
    "start": "1470480",
    "end": "1472740"
  },
  {
    "text": "cluster we can apply to manifest have",
    "start": "1472740",
    "end": "1475470"
  },
  {
    "text": "our GPUs and our GPU drivers installed",
    "start": "1475470",
    "end": "1477300"
  },
  {
    "text": "and we can get running with a workload",
    "start": "1477300",
    "end": "1478830"
  },
  {
    "text": "super super fast what is missing here",
    "start": "1478830",
    "end": "1481740"
  },
  {
    "text": "one of the things that we alluded to",
    "start": "1481740",
    "end": "1483300"
  },
  {
    "text": "earlier that are missing is that the GPU",
    "start": "1483300",
    "end": "1487429"
  },
  {
    "text": "ecosystem is still very fragmented so",
    "start": "1487429",
    "end": "1491809"
  },
  {
    "text": "there is a different can there's a",
    "start": "1491809",
    "end": "1493770"
  },
  {
    "text": "different GPU installer for every",
    "start": "1493770",
    "end": "1495240"
  },
  {
    "text": "operating system or really that's like",
    "start": "1495240",
    "end": "1496770"
  },
  {
    "text": "the way things are going in the world",
    "start": "1496770",
    "end": "1498059"
  },
  {
    "text": "right now and in fact there may be",
    "start": "1498059",
    "end": "1500309"
  },
  {
    "text": "multiple implementations for every",
    "start": "1500309",
    "end": "1502170"
  },
  {
    "text": "operating system and this is also not",
    "start": "1502170",
    "end": "1503940"
  },
  {
    "text": "ideal instead of us pooling our efforts",
    "start": "1503940",
    "end": "1505080"
  },
  {
    "text": "it would be great if we had some generic",
    "start": "1505080",
    "end": "1507260"
  },
  {
    "text": "utilities that we could use for more of",
    "start": "1507260",
    "end": "1510270"
  },
  {
    "text": "our more of our infrastructure what",
    "start": "1510270",
    "end": "1512700"
  },
  {
    "text": "other problems do we have there's also",
    "start": "1512700",
    "end": "1514920"
  },
  {
    "text": "the issue that whenever I whenever I",
    "start": "1514920",
    "end": "1519750"
  },
  {
    "text": "update my operating system I still don't",
    "start": "1519750",
    "end": "1521670"
  },
  {
    "text": "have zero downtime deployments so if I",
    "start": "1521670",
    "end": "1523590"
  },
  {
    "text": "do an operating system update my my pod",
    "start": "1523590",
    "end": "1528000"
  },
  {
    "text": "will get my GPU installer part will get",
    "start": "1528000",
    "end": "1529830"
  },
  {
    "text": "rescheduled on to my node it has to",
    "start": "1529830",
    "end": "1531510"
  },
  {
    "text": "recompile the kernel modules while this",
    "start": "1531510",
    "end": "1532980"
  },
  {
    "text": "is compiling so maybe five or ten",
    "start": "1532980",
    "end": "1534960"
  },
  {
    "text": "minutes my workloads will be",
    "start": "1534960",
    "end": "1539340"
  },
  {
    "text": "unschedulable they'll just be pending so",
    "start": "1539340",
    "end": "1541470"
  },
  {
    "text": "I still have downtime and then the last",
    "start": "1541470",
    "end": "1545130"
  },
  {
    "text": "issue is that what about sharing my",
    "start": "1545130",
    "end": "1547890"
  },
  {
    "text": "kernel modules if I have ten GPUs sorry",
    "start": "1547890",
    "end": "1550679"
  },
  {
    "text": "if I have ten nodes that have GPUs every",
    "start": "1550679",
    "end": "1552270"
  },
  {
    "text": "single one is going to compile my kernel",
    "start": "1552270",
    "end": "1553800"
  },
  {
    "text": "modules it would be great if I could",
    "start": "1553800",
    "end": "1555600"
  },
  {
    "text": "just compile them once and distribute",
    "start": "1555600",
    "end": "1557610"
  },
  {
    "text": "them everywhere these are all things",
    "start": "1557610",
    "end": "1560610"
  },
  {
    "text": "that we still have to do and these are",
    "start": "1560610",
    "end": "1563340"
  },
  {
    "text": "some open questions but with that I",
    "start": "1563340",
    "end": "1565140"
  },
  {
    "text": "leave you guys thank you very much if",
    "start": "1565140",
    "end": "1567059"
  },
  {
    "text": "you have any questions please ask me",
    "start": "1567059",
    "end": "1570830"
  },
  {
    "text": "and otherwise we can just chat",
    "start": "1570830",
    "end": "1571910"
  },
  {
    "text": "afterwards yeah",
    "start": "1571910",
    "end": "1574450"
  },
  {
    "text": "[Applause]",
    "start": "1575310",
    "end": "1578980"
  }
]
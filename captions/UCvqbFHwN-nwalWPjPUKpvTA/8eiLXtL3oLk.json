[
  {
    "text": "welcome um to uh to our talk where's your money going The Beginner's got to",
    "start": "320",
    "end": "5359"
  },
  {
    "text": "monitoring uh measuring kubernetes costs my name is Mark Poco I'm a senior software engineer at graan labs and with",
    "start": "5359",
    "end": "11440"
  },
  {
    "text": "me is I'm I'm quano also gra Labs working both we both work at the platform team yes um so before we start",
    "start": "11440",
    "end": "19600"
  },
  {
    "text": "let's do a little bit of a story right imagine a scenario you get your Cloud Bill uh your kubernetes cost doubles",
    "start": "19600",
    "end": "25480"
  },
  {
    "text": "month over month and uh you're trying to figure out where did your where where did it come from so you start with your",
    "start": "25480",
    "end": "32119"
  },
  {
    "text": "bill and you look at it and no matter what you do it doesn't really help you figure out where that cost is coming",
    "start": "32119",
    "end": "37239"
  },
  {
    "text": "from so the next thing you do you go to your cost Explorer and see what other dimensions are available for you and",
    "start": "37239",
    "end": "44920"
  },
  {
    "text": "really don't come up with much and in this case we're showing um uh what's it called the incidence types you might be",
    "start": "44920",
    "end": "51039"
  },
  {
    "text": "able to see where that cost is coming from but nothing about the cluster or the workload so you turn to your",
    "start": "51039",
    "end": "56199"
  },
  {
    "text": "favorite uh data visualization tool and you look at things like like CPU usage and memory utilization look at this over",
    "start": "56199",
    "end": "63359"
  },
  {
    "text": "time and still nothing's really standing out to you on what is driving our costs",
    "start": "63359",
    "end": "69600"
  },
  {
    "text": "and this leaves you sad so show of hands how many people have",
    "start": "69600",
    "end": "75439"
  },
  {
    "text": "had this happen before all right that's yeah everybody um how many people are",
    "start": "75439",
    "end": "81320"
  },
  {
    "text": "running Cube State metrics in your kubernetes cluster all right so the good news is",
    "start": "81320",
    "end": "87000"
  },
  {
    "text": "for those that are doing this you're going to be able to walk away today with some promptu all queries that you could run and be able to visualize this and",
    "start": "87000",
    "end": "93799"
  },
  {
    "text": "those that don't hopefully this is a good incentive to maybe look into Cube State Matrix so what can you expect",
    "start": "93799",
    "end": "101360"
  },
  {
    "text": "today first thing we're going to do is that there's a we're going to try to show a couple approaches that we use at",
    "start": "101360",
    "end": "106880"
  },
  {
    "text": "gra labs to help um Bridge the disconnect between your billing statement and the metrics that you're",
    "start": "106880",
    "end": "112840"
  },
  {
    "text": "already collecting in your kubernetes cluster after that we're going to step through a couple of promu examples to",
    "start": "112840",
    "end": "118360"
  },
  {
    "text": "help measure um in this particular case we're going to show CPU because that's usually the most costly um and then",
    "start": "118360",
    "end": "125360"
  },
  {
    "text": "finally we're going to share a couple of Lessons Learned both in terms of setting this up and measuring it and also uh how",
    "start": "125360",
    "end": "131760"
  },
  {
    "text": "we helped improve that cost and with that we turn over to wano so um yeah to",
    "start": "131760",
    "end": "138400"
  },
  {
    "text": "to start digging in into this uh we need to understand uh the nature of our our spendings this is a really very simple",
    "start": "138400",
    "end": "145879"
  },
  {
    "text": "formula as you can see spend being the amount of money that you pay for your resources on a particular period of time",
    "start": "145879",
    "end": "152959"
  },
  {
    "text": "usage being the amount of unit the number of units of such resources and",
    "start": "152959",
    "end": "158200"
  },
  {
    "text": "the rate is how much you are being charged for for each of these units this is important to to to group to get to",
    "start": "158200",
    "end": "164879"
  },
  {
    "text": "group separate actually to be able to focus on the force that you put on each part of these factors like in usage we",
    "start": "164879",
    "end": "172319"
  },
  {
    "text": "can see the things like for example amount of CPU course amount of memory traffic and such and it rate are dollars",
    "start": "172319",
    "end": "179920"
  },
  {
    "text": "per each unit of these uh of these resources from the cloud providers and",
    "start": "179920",
    "end": "185840"
  },
  {
    "text": "this uh then drives different really separates how we need to focus or what",
    "start": "185840",
    "end": "192120"
  },
  {
    "text": "are what are the work streams that you need to develop to be able to tackle this in the case of usage we need to be",
    "start": "192120",
    "end": "199040"
  },
  {
    "text": "aware of our work L sizing this is the most common intuitive one when you think about improving your cost stand you",
    "start": "199040",
    "end": "205920"
  },
  {
    "text": "usually think oh I need to properly do a right right size of of my resources that",
    "start": "205920",
    "end": "211080"
  },
  {
    "text": "is how much I ask and how much I use but there are also several other factors that are pretty important in driving",
    "start": "211080",
    "end": "217439"
  },
  {
    "text": "your cost other one is autoscaling having proper autoscaling story both on",
    "start": "217439",
    "end": "223400"
  },
  {
    "text": "kubernetes like things like HPA and vpa but also underline how how much your",
    "start": "223400",
    "end": "229640"
  },
  {
    "text": "cluster can be elastic to actually create new noes or destroy noes that you don't need",
    "start": "229640",
    "end": "234680"
  },
  {
    "text": "anymore and then another aspect that is highlighted there because it's the aspect that we will be actually touching",
    "start": "234680",
    "end": "240879"
  },
  {
    "text": "during the rest of the talk is cluster be packing cluster be packing mean mean that you have a no how well you're able",
    "start": "240879",
    "end": "247640"
  },
  {
    "text": "to actually pack all the PO in this node to have the the Le the least uh slack",
    "start": "247640",
    "end": "253280"
  },
  {
    "text": "resources in that node and and as you can see uh then there is a different aspect like R alog together that is",
    "start": "253280",
    "end": "260840"
  },
  {
    "text": "essentially uh you need to understand what is the kind of discounts that you can get from your cloud provider on",
    "start": "260840",
    "end": "267919"
  },
  {
    "text": "aspects like committing for certain amount of resources that you will be using over time but also things like for",
    "start": "267919",
    "end": "273759"
  },
  {
    "text": "example the CPU architecture that you're using is it Intel AMD arm are your work",
    "start": "273759",
    "end": "279560"
  },
  {
    "text": "gloss ready to actually run on this on these architectures and then things like for example spot BMS what in Richie he",
    "start": "279560",
    "end": "286919"
  },
  {
    "text": "did really good approach to the to this spot VMS are kind of free k chaos",
    "start": "286919",
    "end": "292400"
  },
  {
    "text": "engineering because these are kind of uh VMS that can disappear anytime you have",
    "start": "292400",
    "end": "297440"
  },
  {
    "text": "it there they have a steep discount but they can go without the notice maybe just a minute noce so important then to",
    "start": "297440",
    "end": "304919"
  },
  {
    "text": "to focus here is how we separate this because also it impacts which teams will",
    "start": "304919",
    "end": "311000"
  },
  {
    "text": "be in charge of each of these items that I'm highlighting there so let's let's try then to to focus the rest of the",
    "start": "311000",
    "end": "317520"
  },
  {
    "text": "talk the talk on cluster be packing what we see there essentially is trying to by the way this is a graphing",
    "start": "317520",
    "end": "325360"
  },
  {
    "text": "grafana as you can see this is a result of of some query there well we see that over time is spending like for example",
    "start": "325360",
    "end": "332680"
  },
  {
    "text": "if we focus at 5:00 p.m. during that hour from 5:00 p.m. to 6 p.m. we will",
    "start": "332680",
    "end": "338560"
  },
  {
    "text": "spending something like $1.4 in total the top box is CPU the",
    "start": "338560",
    "end": "344400"
  },
  {
    "text": "bottom box is memory and this also is hinting us that we will narrow the rest of the talk to compute resources only",
    "start": "344400",
    "end": "351479"
  },
  {
    "text": "because in 25 minutes is is what what what we can get so um again this is a",
    "start": "351479",
    "end": "357440"
  },
  {
    "text": "spense so this is dollar time dollar over time if we apply the formula here we see",
    "start": "357440",
    "end": "365520"
  },
  {
    "text": "that actually this span is composed of discrete unit of resources in this case",
    "start": "365520",
    "end": "370840"
  },
  {
    "text": "we are trying for example again at 5:00 p.m we're trying to graph something like four nodes for example you have there",
    "start": "370840",
    "end": "377599"
  },
  {
    "text": "the four noes each node may have eight or 18 vcpu um and then on the top you have CPU",
    "start": "377599",
    "end": "384680"
  },
  {
    "text": "and on the bottom memory and you can see that the number is the same but again it's important to understand that it's",
    "start": "384680",
    "end": "391199"
  },
  {
    "text": "not continuous what you request especially when when you are running a kubernetes cluster on top of Cloud this",
    "start": "391199",
    "end": "397599"
  },
  {
    "text": "will be discrete indeed the noes are being created or destroyed as as for example to to to the right of that graph",
    "start": "397599",
    "end": "405000"
  },
  {
    "text": "this will be discrete amounts and then a different dimension is how much are you paying for this as we just saw at the",
    "start": "405000",
    "end": "411880"
  },
  {
    "text": "end of the day what you will be paying for will be the volume that you're seeing there essentially the integral",
    "start": "411880",
    "end": "417479"
  },
  {
    "text": "let's say the sum of each of of These Bars over time over a period of",
    "start": "417479",
    "end": "423039"
  },
  {
    "text": "time let's see then uh let's try to focus then because this is kind of a",
    "start": "423039",
    "end": "428720"
  },
  {
    "text": "pretty lowlevel view right we are seeing there the nose we're trying to graph there the nose that we are driving from",
    "start": "428720",
    "end": "434479"
  },
  {
    "text": "our cloud provider Let's see we need to understand then how kubernetes workloads",
    "start": "434479",
    "end": "439800"
  },
  {
    "text": "Drive the creation of these units and this is key to understand how we're going to cope on on with the cost on",
    "start": "439800",
    "end": "448199"
  },
  {
    "text": "each of these aspects then let's see what drives qu is cost",
    "start": "448199",
    "end": "453680"
  },
  {
    "text": "here we try to graph a you know a a p there is just simple web service that is",
    "start": "453680",
    "end": "460440"
  },
  {
    "text": "asking for one CPU and 2 G Ram it's not your running uh it's kind of pending",
    "start": "460440",
    "end": "466319"
  },
  {
    "text": "until it can land into a no that you have it's asking one CPU 2 gam and it",
    "start": "466319",
    "end": "473560"
  },
  {
    "text": "happened to land it in a note that is 8 CPU on 16 gig of RAM you can start to sense that this something not so good",
    "start": "473560",
    "end": "480680"
  },
  {
    "text": "regarding this picture until you actually put eight replicas and you have this kind of",
    "start": "480680",
    "end": "486039"
  },
  {
    "text": "unicor awesome theoretical scenario where where you are right we are exactly fulfilling the",
    "start": "486039",
    "end": "493520"
  },
  {
    "text": "capacity of the no obviously this is pretty theoretical and indeed Mark we will address this uh when we show the",
    "start": "493520",
    "end": "501120"
  },
  {
    "text": "how we tackle this we have uh another pole there and we have essentially the",
    "start": "501120",
    "end": "506680"
  },
  {
    "text": "same scenario before let's that's sinking we have essentially if you if",
    "start": "506680",
    "end": "512240"
  },
  {
    "text": "you read through the through this graph you will see that you have CPU at the no",
    "start": "512240",
    "end": "517399"
  },
  {
    "text": "level but CPU at the PO level also usually when we use cetes we actually",
    "start": "517399",
    "end": "524560"
  },
  {
    "text": "only see the up part like if you sum all the resources that you are your BS are",
    "start": "524560",
    "end": "531080"
  },
  {
    "text": "using you will be seeing the the aggregation of all these small boxes inside but we need to be able to",
    "start": "531080",
    "end": "537320"
  },
  {
    "text": "actually separate both to measure both to be able to to to see the driver and",
    "start": "537320",
    "end": "543720"
  },
  {
    "text": "the effect of that driver being what is inside and the effect is the actual noes that's being",
    "start": "543720",
    "end": "549399"
  },
  {
    "text": "allocated so then we need to indeed again we are in this talk we are just",
    "start": "549399",
    "end": "554519"
  },
  {
    "text": "focusing on compute so CPU memory of nose and likewise for",
    "start": "554519",
    "end": "561399"
  },
  {
    "text": "workload uh as Mark mention uh if you have Cube State metrics you will have",
    "start": "561399",
    "end": "567760"
  },
  {
    "text": "these metrics provided by you by the way this is not meant to be a promql class of course but just a quick introduction",
    "start": "567760",
    "end": "575120"
  },
  {
    "text": "what you have there like Cube no status capacity is indeed the name of the metric and this metric can have as you",
    "start": "575120",
    "end": "582440"
  },
  {
    "text": "can see have several labels these labels can have several values the cardinality",
    "start": "582440",
    "end": "587680"
  },
  {
    "text": "of this and then the the combination of the metric name and the label value will",
    "start": "587680",
    "end": "593680"
  },
  {
    "text": "give you a single will give you a single point in time of data and this is called Time series so just to put an example",
    "start": "593680",
    "end": "601320"
  },
  {
    "text": "you fix the cluster because you taking care of you are actually watching this particular cluster you fix resource to",
    "start": "601320",
    "end": "607320"
  },
  {
    "text": "be equal CPU for example you fix a note because you are watching this note and then you will get a number like eight",
    "start": "607320",
    "end": "613640"
  },
  {
    "text": "for example for that metric about for that time series about eight because it",
    "start": "613640",
    "end": "619000"
  },
  {
    "text": "has 8 V CPU now we again this we are watching at",
    "start": "619000",
    "end": "624240"
  },
  {
    "text": "the box that is hosting these Pots if we go at pot level you will see that we have a metric that is Q container",
    "start": "624240",
    "end": "632399"
  },
  {
    "text": "resource request so it will have we are we are not actually putting there the",
    "start": "632399",
    "end": "637560"
  },
  {
    "text": "label like pod and and container just for the sake of of space in the screen",
    "start": "637560",
    "end": "643959"
  },
  {
    "text": "but essentially we essentially the same idea you see that we have cluster resource node and Nam space and then",
    "start": "643959",
    "end": "651200"
  },
  {
    "text": "Mark will help us uh understand how we can bring some queries to aggregate this",
    "start": "651200",
    "end": "658480"
  },
  {
    "text": "thank you w so all right again bringing this all back is we're going to focus on the",
    "start": "658480",
    "end": "663519"
  },
  {
    "text": "usage side because that's what drives your cost in your clusters we have two metrics now that we could do some work",
    "start": "663519",
    "end": "670519"
  },
  {
    "text": "with and so let's step through we're going to three examples of how to measure compute in a cluster the first",
    "start": "670519",
    "end": "676880"
  },
  {
    "text": "one is how do we measure the cost of our nodes so in pseudo code and promql um we",
    "start": "676880",
    "end": "682880"
  },
  {
    "text": "have this again we're expressing that formula sum is equal to usage time rate and to measure your nodes you need need",
    "start": "682880",
    "end": "689160"
  },
  {
    "text": "to update your usage to get how much resources You' requested so in this example we have Cube uh node status",
    "start": "689160",
    "end": "696680"
  },
  {
    "text": "capacity and we're saying we want the resource uh of CPU and what's charted on the right is going to be how many CPUs",
    "start": "696680",
    "end": "704079"
  },
  {
    "text": "for an entire cluster you have um what's called how many CPUs are being requested",
    "start": "704079",
    "end": "710720"
  },
  {
    "text": "summed up um as the graph goes down that's kind of shown that there's fewer nodes as that graph goes up it means",
    "start": "710720",
    "end": "716920"
  },
  {
    "text": "that there's more nodes um and now that we know the number of cores of a cluster",
    "start": "716920",
    "end": "722839"
  },
  {
    "text": "we could then figure out what do it cost to run that cluster we're going to cheat a little bit today for rate um what",
    "start": "722839",
    "end": "729560"
  },
  {
    "text": "we're going to do is we're going to go to a cloud provider right and there's three things that you really care about",
    "start": "729560",
    "end": "735040"
  },
  {
    "text": "for cost of a CPU it's the region that you're in the instance type and whether",
    "start": "735040",
    "end": "740240"
  },
  {
    "text": "or not it's on demand machine or if it's a spot machine so in this example what we're going to do is we're going to find",
    "start": "740240",
    "end": "747320"
  },
  {
    "text": "out we're going to use the onoma price cuz that's most likely you're running an on theand machine um so we're going to",
    "start": "747320",
    "end": "753600"
  },
  {
    "text": "take the three cents per uh per hour for vcpu and we're going to plug that into rate and charted what that looks like is",
    "start": "753600",
    "end": "761839"
  },
  {
    "text": "over time how much we're spending per per minute and we're going to come back to a minute and the your",
    "start": "761839",
    "end": "769160"
  },
  {
    "text": "cloud provider charges you per hour but we're going to um cast it to a minute",
    "start": "769160",
    "end": "774399"
  },
  {
    "text": "because in this this query you could explore your data right this is something you get whatever tool you're",
    "start": "774399",
    "end": "779519"
  },
  {
    "text": "using you could explore it um and you could chart it over time but most likely if you have a lot of nodes a lot of",
    "start": "779519",
    "end": "785240"
  },
  {
    "text": "clusters this query you're probably not going to go further than a week maybe a month if you're in a smaller cluster so",
    "start": "785240",
    "end": "792760"
  },
  {
    "text": "we cast it to a minute and what we're going to do is we're going to create something called a recording rule in",
    "start": "792760",
    "end": "798120"
  },
  {
    "text": "Prometheus and if you haven't used uh recording rules before it's pretty much it's a job that runs periodically it's",
    "start": "798120",
    "end": "805000"
  },
  {
    "text": "defined in yel and what you do is you specify the the uh metric name that you want to store this data into you give it",
    "start": "805000",
    "end": "812240"
  },
  {
    "text": "the expression in this case it's that the the example who add sum by cluster um and you attach to it a label in this",
    "start": "812240",
    "end": "821079"
  },
  {
    "text": "case we're saying resources CPU and so when this runs in uh Prometheus what's",
    "start": "821079",
    "end": "826959"
  },
  {
    "text": "going to happen every minute this runs it's going to tick it's going to calculate the cost per minute and it's",
    "start": "826959",
    "end": "833160"
  },
  {
    "text": "going to store it in uh the record cluster cost per minute sum and with a a",
    "start": "833160",
    "end": "839199"
  },
  {
    "text": "resource label of CPU and this allows you eventually you could do memory you could do persistent volumes you could do",
    "start": "839199",
    "end": "845720"
  },
  {
    "text": "object storage realistically resource could be a many different factors so",
    "start": "845720",
    "end": "853120"
  },
  {
    "text": "once you have this running you it stores it over time so that's how you measure",
    "start": "853120",
    "end": "859480"
  },
  {
    "text": "nodes most likely your nodes isn't really you know you probably could get a sense of what you're spending you",
    "start": "859480",
    "end": "865160"
  },
  {
    "text": "probably really care about what is actually costing what and in this case we're showing a little bit",
    "start": "865160",
    "end": "871160"
  },
  {
    "text": "more of a realistic example where we're running pretty much the Prometheus community and um one of the things that",
    "start": "871160",
    "end": "878120"
  },
  {
    "text": "we do at least in internally with the grafana is we use name spaces to isolate our workloads so in this case we have a",
    "start": "878120",
    "end": "884480"
  },
  {
    "text": "perthus instance that running in likely High availability mode it's bigger because it's most likely consuming a lot",
    "start": "884480",
    "end": "890639"
  },
  {
    "text": "of memory and then we have a bunch of other little workloads so the question is how do you measure this like how do",
    "start": "890639",
    "end": "896399"
  },
  {
    "text": "you measure that name space because this is probably the most important aspect for your engineering teams so coming",
    "start": "896399",
    "end": "903920"
  },
  {
    "text": "back we're going to alter that um equation just a little bit in this case we're going to do some by namespace and",
    "start": "903920",
    "end": "910920"
  },
  {
    "text": "instead of the usage we're going to look at requests right what is the workloads running in that Nam space requesting",
    "start": "910920",
    "end": "919720"
  },
  {
    "text": "so from CP State metrics you have this metric Cube pod container resource requests and again we're doing CPU",
    "start": "919720",
    "end": "926360"
  },
  {
    "text": "because that's most likely the most expensive and if you look at the graph one of the things you might notice again is that",
    "start": "926360",
    "end": "932480"
  },
  {
    "text": "it's going up and down over time so nodes when you're measuring nodes that's",
    "start": "932480",
    "end": "937680"
  },
  {
    "text": "just going to be new nodes added new nodes delet or uh new nodes deleted in",
    "start": "937680",
    "end": "942880"
  },
  {
    "text": "this case it's most likely replicas you likely are using some type of horizontal po Auto scaling policy and so as the um",
    "start": "942880",
    "end": "951519"
  },
  {
    "text": "number of cores goes down you likely have less replicas as it goes up you likely have more once the newer version",
    "start": "951519",
    "end": "958160"
  },
  {
    "text": "of kuber comes out and you could have Dynamic resource requests this is probably going to change a little bit um",
    "start": "958160",
    "end": "964399"
  },
  {
    "text": "so again we're going to cheat here and for rate we're going to use that same three about three cents um per per hour",
    "start": "964399",
    "end": "971880"
  },
  {
    "text": "we're going to convert it to a minute and this is the cost per namespace charted over time and and this",
    "start": "971880",
    "end": "978040"
  },
  {
    "text": "is a madeup example where we generated some fake data we have namespace a and namespace b and you know we could look",
    "start": "978040",
    "end": "985440"
  },
  {
    "text": "to see how much does it cost per minute over time so similarly this is useful",
    "start": "985440",
    "end": "990680"
  },
  {
    "text": "you could run this today and you could get some actual data um on the cost of",
    "start": "990680",
    "end": "995880"
  },
  {
    "text": "your namespace but if you want to go over time it's most likely not going to work so going to fall back on a",
    "start": "995880",
    "end": "1002600"
  },
  {
    "text": "recording rule in this case we're going to call it cluster namespace cost per minute sum and for the expression we're",
    "start": "1002600",
    "end": "1009199"
  },
  {
    "text": "going to use uh what we had before in our Explorer and we're going to again add the resource uh label of CPU so",
    "start": "1009199",
    "end": "1016360"
  },
  {
    "text": "again if you want to do memory instead of it being the resource CPU you change that to memory find the hourly price of",
    "start": "1016360",
    "end": "1022000"
  },
  {
    "text": "memory do a little bit of conversion because uh bytes and gigabytes they they",
    "start": "1022000",
    "end": "1027199"
  },
  {
    "text": "don't always match up so this is two examples we have one more",
    "start": "1027199",
    "end": "1033319"
  },
  {
    "text": "that I think is really important that lines up with almost every keynote speak about Energy Efficiency and so both",
    "start": "1033319",
    "end": "1041520"
  },
  {
    "text": "those exam almost all three examples are extremely unlikely to happen in in in um",
    "start": "1041520",
    "end": "1047160"
  },
  {
    "text": "in a production cluster most likely what you're going to have is you're going to have a lot of nodes over",
    "start": "1047160",
    "end": "1052559"
  },
  {
    "text": "time and each of those nodes is going to have a different level of uh um what's",
    "start": "1052559",
    "end": "1059120"
  },
  {
    "text": "it called um workloads running on it and what we really care about from a",
    "start": "1059120",
    "end": "1064640"
  },
  {
    "text": "platform perspective is figuring out how much of that extra space on that node",
    "start": "1064640",
    "end": "1070320"
  },
  {
    "text": "are we not using and the reason for that is that's I mean that that you're paying for that entire node and if it's not",
    "start": "1070320",
    "end": "1078000"
  },
  {
    "text": "being used used you're wasting money right and you're wasting energy and it's",
    "start": "1078000",
    "end": "1083799"
  },
  {
    "text": "yeah it's something important for us to track so how do you measure that this one's probably the most complex but you",
    "start": "1083799",
    "end": "1090080"
  },
  {
    "text": "have to kind of follow me um instead of caring about the usage or the number of",
    "start": "1090080",
    "end": "1096039"
  },
  {
    "text": "requests for a node or workload you care about you want to know how much capacity",
    "start": "1096039",
    "end": "1102280"
  },
  {
    "text": "is on that node minus how much your workloads are requesting right that's",
    "start": "1102280",
    "end": "1107360"
  },
  {
    "text": "going to be what drives your idle usage um that's what's left over and then Times by the rate and that gives you how",
    "start": "1107360",
    "end": "1113960"
  },
  {
    "text": "much you're spending on just idle resources so it's it's a lot if you're not",
    "start": "1113960",
    "end": "1120480"
  },
  {
    "text": "familiar with promql um but let's step through it right you have on the inside you have a sum by node of the capacity",
    "start": "1120480",
    "end": "1128320"
  },
  {
    "text": "of of the node minus sum by node of the requests on that node and again we're",
    "start": "1128320",
    "end": "1134679"
  },
  {
    "text": "looking at CPU and what's charted here on the right is how much we're spending",
    "start": "1134679",
    "end": "1139720"
  },
  {
    "text": "per minute on resources that are not being used by anything so and we're",
    "start": "1139720",
    "end": "1146039"
  },
  {
    "text": "convert it to 60 seconds because again you could do maybe a week of this 30 days 6 months is not going to not going",
    "start": "1146039",
    "end": "1153240"
  },
  {
    "text": "to cut it so take a pause it's three prom qall",
    "start": "1153240",
    "end": "1158640"
  },
  {
    "text": "queries that we've looked at if you're not familiar it could be quite a bit um I would love to be able to spend more time and St through memory persistent",
    "start": "1158640",
    "end": "1165559"
  },
  {
    "text": "volumes you're going to just have to bear with me oh got ahead of myself um let's look at",
    "start": "1165559",
    "end": "1172280"
  },
  {
    "text": "that in recording rule because th this is pretty interesting with what we do um we have cluster name space cost per",
    "start": "1172280",
    "end": "1177880"
  },
  {
    "text": "minute sum and we have this query here right the same one we had before notice",
    "start": "1177880",
    "end": "1183360"
  },
  {
    "text": "though in a query we don't sum up by namespace anywhere and there's a reason for that",
    "start": "1183360",
    "end": "1188720"
  },
  {
    "text": "is Idle resource isn't Associated to a namespace It's associated to a note we add an extra label called namespace",
    "start": "1188720",
    "end": "1196039"
  },
  {
    "text": "under double Idol and we call that at a virtual names space pretty much what we do is we associate all of the DAT all of",
    "start": "1196039",
    "end": "1202640"
  },
  {
    "text": "the spend that we're not using anything on into a single Nam space and we could",
    "start": "1202640",
    "end": "1208400"
  },
  {
    "text": "do some pretty cool stuff with that so here's where we're at we showed a",
    "start": "1208400",
    "end": "1214320"
  },
  {
    "text": "couple of things here unfortunately can't step through the entire process but I do want to show you what we do",
    "start": "1214320",
    "end": "1219440"
  },
  {
    "text": "internally in grafana and the the way that we measure this so if you put this all together right",
    "start": "1219440",
    "end": "1226919"
  },
  {
    "text": "you draw the rest of that owl you have this pretty complex looking query where what we're what what we're graphing here",
    "start": "1226919",
    "end": "1233679"
  },
  {
    "text": "is how much what's the percentage of all of our spend that's",
    "start": "1233679",
    "end": "1238960"
  },
  {
    "text": "being associated with idle resources and this is important for many reasons right",
    "start": "1238960",
    "end": "1244640"
  },
  {
    "text": "this is money that we're spending to our cloud provider that isn't being used at",
    "start": "1244640",
    "end": "1250240"
  },
  {
    "text": "all so we have targets and goals within our organization of what we want to do with that and what's really cool about",
    "start": "1250240",
    "end": "1259000"
  },
  {
    "text": "this is that every month or every week we get a report on how much we spend within our organization by team and also",
    "start": "1259000",
    "end": "1266080"
  },
  {
    "text": "as a platform we care about the idle resources so you might notice that there is a point where it kind of shoots up",
    "start": "1266080",
    "end": "1272520"
  },
  {
    "text": "right about mid July July 14th we noticed that and we were able to",
    "start": "1272520",
    "end": "1279000"
  },
  {
    "text": "react and we were able to get that cost under control so that we didn't have a surprise Bill and so this is six months",
    "start": "1279000",
    "end": "1286640"
  },
  {
    "text": "we track this we could uh do it over a year 18 months",
    "start": "1286640",
    "end": "1292559"
  },
  {
    "text": "um and yeah so with everything right",
    "start": "1292600",
    "end": "1298120"
  },
  {
    "text": "this has been an iterative process it's taken a while um I've been doing this you know we've been doing this for about",
    "start": "1298120",
    "end": "1304120"
  },
  {
    "text": "a year just trying to get to the point where we're at um the first main like",
    "start": "1304120",
    "end": "1310760"
  },
  {
    "text": "shortcoming of this Approach at least with what we shared with you is that it only it it only works for homogeneous",
    "start": "1310760",
    "end": "1316600"
  },
  {
    "text": "clusters most likely you're going to have clusters with many different node types and in our case we run across many",
    "start": "1316600",
    "end": "1322880"
  },
  {
    "text": "Cloud providers so that's that's a hard problem to solve so what we first did",
    "start": "1322880",
    "end": "1328320"
  },
  {
    "text": "that worked very well was we averaged how much our CPU cost across all of our",
    "start": "1328320",
    "end": "1333360"
  },
  {
    "text": "Cloud providers and instead of using that like three cents an hour we use that that the average for a month and",
    "start": "1333360",
    "end": "1342640"
  },
  {
    "text": "use that in all of our recording rules we did that for about six months um and then from there we used open cost we",
    "start": "1342640",
    "end": "1350200"
  },
  {
    "text": "deployed that to all of our clusters and instead of using that estimated number we're able to join a query and we're",
    "start": "1350200",
    "end": "1356840"
  },
  {
    "text": "able to uh get the actual cost of the node and it takes into account the region it takes into account if it's",
    "start": "1356840",
    "end": "1362960"
  },
  {
    "text": "spot the type of instance um and the interesting thing for us is that when we",
    "start": "1362960",
    "end": "1369799"
  },
  {
    "text": "converted from the estimated to the actual numbers our estimated was about 90% correct right and again that's",
    "start": "1369799",
    "end": "1376840"
  },
  {
    "text": "across three cloud providers if I heard that I wouldn't believe it that's it was really I couldn't believe when I saw the",
    "start": "1376840",
    "end": "1383840"
  },
  {
    "text": "numbers but we wrote about this in our blog post and we adopted open cost so go check that out if you don't believe that",
    "start": "1383840",
    "end": "1390120"
  },
  {
    "text": "um the other thing right now is this only takes into account compute resources so we could do CPU we could do",
    "start": "1390120",
    "end": "1396400"
  },
  {
    "text": "memory we could do persistent volume most likely at least within grafana we use a lot of object storage which has a",
    "start": "1396400",
    "end": "1403840"
  },
  {
    "text": "very different type of compute and we want to be able to associate to our teams and let them understand how much",
    "start": "1403840",
    "end": "1409240"
  },
  {
    "text": "they spending on that Resource as well so it's something that we' built internally and we're not quite sure what",
    "start": "1409240",
    "end": "1415600"
  },
  {
    "text": "we're going to do but there will be something from that um now you might",
    "start": "1415600",
    "end": "1420799"
  },
  {
    "text": "have noticed all my examples I used AWS for billing you know if you've used that before but I pulled the numbers from gcp",
    "start": "1420799",
    "end": "1428200"
  },
  {
    "text": "not all of your Cloud providers are going to give you an actual breakdown of CPU and memory so if you're in if your",
    "start": "1428200",
    "end": "1434279"
  },
  {
    "text": "cloud provider doesn't give that to you it's about 80% uh if if they just give you the total",
    "start": "1434279",
    "end": "1440440"
  },
  {
    "text": "cost of an instance it's about 80% for CPU 20% memory so you could do some math",
    "start": "1440440",
    "end": "1445720"
  },
  {
    "text": "on that to figure that one out um and then finally name spaces doesn't match up the teams so from a platform",
    "start": "1445720",
    "end": "1452600"
  },
  {
    "text": "perspective this is really powerful for us to figure out Ido resource but our Engineers they they need to know like",
    "start": "1452600",
    "end": "1459600"
  },
  {
    "text": "not just the name space but how much are they spending so we have this kind of",
    "start": "1459600",
    "end": "1464679"
  },
  {
    "text": "like magical uh little metric that is part of our CI process um that",
    "start": "1464679",
    "end": "1469880"
  },
  {
    "text": "Associates the Nam space the teams so that when we build these queries after the recording rules we're able to join",
    "start": "1469880",
    "end": "1476279"
  },
  {
    "text": "up namespace the team and we could then provide all of our teams a breakdown of their",
    "start": "1476279",
    "end": "1481559"
  },
  {
    "text": "costs uh yeah just to to to add a bit on top of what Mark said attribution here",
    "start": "1481559",
    "end": "1487799"
  },
  {
    "text": "right being able to attribute so that teams actual engineering teams can take care of the costs that they own uh and",
    "start": "1487799",
    "end": "1495399"
  },
  {
    "text": "imagine that underscore idel to to which team it goes It goes to platform team so",
    "start": "1495399",
    "end": "1501559"
  },
  {
    "text": "interesting here also the defining the ownership doing this this being able for teams to actually own their own cost so",
    "start": "1501559",
    "end": "1509360"
  },
  {
    "text": "they can actually do their what is called TCO for CA of ownership for by the teams and with this lesson learn let",
    "start": "1509360",
    "end": "1517080"
  },
  {
    "text": "let's see what lessons we learn on the our Bing Journey uh oh maybe n or maybe",
    "start": "1517080",
    "end": "1524159"
  },
  {
    "text": "we need to ask ourselves first a question do we have uh resource request",
    "start": "1524159",
    "end": "1529960"
  },
  {
    "text": "for our workloads uh resource CPU memory yes uh is at least the more",
    "start": "1529960",
    "end": "1537559"
  },
  {
    "text": "relevant ones few hands up okay you cannot Embark in this journey if you",
    "start": "1537559",
    "end": "1544360"
  },
  {
    "text": "don't tackle this properly because the resource that you request for your PS is what drives the scheduler to actually",
    "start": "1544360",
    "end": "1551279"
  },
  {
    "text": "landar those PS in in a particular node that has that capacity available and",
    "start": "1551279",
    "end": "1557039"
  },
  {
    "text": "then the view view that the schedular has regarding the proper be packing the scaler together with the cluster out the",
    "start": "1557039",
    "end": "1563039"
  },
  {
    "text": "scaler needs to know how much you are requesting for that PO again we're talking about B packing not resizing",
    "start": "1563039",
    "end": "1570480"
  },
  {
    "text": "that is we're not talking here in this talk about how well you are using the resources that you request we are",
    "start": "1570480",
    "end": "1576279"
  },
  {
    "text": "talking about how well we have been packing what you request for on the noes that you have available so here",
    "start": "1576279",
    "end": "1584000"
  },
  {
    "text": "essentially the idea of this is to share the to share you some tools some approaches that has helped us in G by",
    "start": "1584000",
    "end": "1591919"
  },
  {
    "text": "default the cluster run with something that is called balance mode balance mode let's say is try to be gentle with the",
    "start": "1591919",
    "end": "1598960"
  },
  {
    "text": "pods trying to do a fair distribution of the PS over the nose that you have available if you switch that and this is",
    "start": "1598960",
    "end": "1605919"
  },
  {
    "text": "a clusterwise setting to optimize utilization this is the opposite it will try to actually do this being packing",
    "start": "1605919",
    "end": "1612720"
  },
  {
    "text": "but again if you don't have those requests finding instead of be packing you will have both maing right you need",
    "start": "1612720",
    "end": "1619600"
  },
  {
    "text": "to be able to to to tell the Schuler how much you're requesting for very useful",
    "start": "1619600",
    "end": "1624919"
  },
  {
    "text": "for that for for for us I I will give you some some numbers in a bit for the kind of patterns that that",
    "start": "1624919",
    "end": "1633200"
  },
  {
    "text": "uh that we have in grafana we have essentially continuous deployment so we don't have a day where we deploy we have",
    "start": "1633200",
    "end": "1638880"
  },
  {
    "text": "so many teams working where so essentially we're con constantly deploying rolling out new versions or or",
    "start": "1638880",
    "end": "1645760"
  },
  {
    "text": "or new settings for for the service that we run and this creates a lot of Def",
    "start": "1645760",
    "end": "1651399"
  },
  {
    "text": "fragmentation at the nose so let's say you have a point in time where you have an awesome Bean packing uh picture like",
    "start": "1651399",
    "end": "1658240"
  },
  {
    "text": "20 something per as H as Mark was showing but then you do a roll up and",
    "start": "1658240",
    "end": "1663320"
  },
  {
    "text": "then essentially you fragment all this no with all these gaps of resources so by allocating new noes where the new",
    "start": "1663320",
    "end": "1669399"
  },
  {
    "text": "post are landing and what we found in know because of the way that we use platform is that in G this is what this",
    "start": "1669399",
    "end": "1676960"
  },
  {
    "text": "was taking too long after a roll out it may take two days to actually settle",
    "start": "1676960",
    "end": "1682440"
  },
  {
    "text": "back to the idle percentage call out and G again to be able to measure that",
    "start": "1682440",
    "end": "1687799"
  },
  {
    "text": "because else you're running blind all all what what just Mark show and this is a per minute measure so we actually",
    "start": "1687799",
    "end": "1694640"
  },
  {
    "text": "tracking that Idol so we were able to react on that and say okay this is taking too long a tool that helped us",
    "start": "1694640",
    "end": "1701000"
  },
  {
    "text": "that is certainly not a silver ballet and you need to understand how it works has many knobs is that a shedler this",
    "start": "1701000",
    "end": "1707480"
  },
  {
    "text": "schedular will try indeed to observe how well you are using those nodes has",
    "start": "1707480",
    "end": "1713120"
  },
  {
    "text": "several strategies one of them is high node utilization and then it if it observes that the node is being",
    "start": "1713120",
    "end": "1718600"
  },
  {
    "text": "underutilized it will evict the PS to be able to kill the node but of course you",
    "start": "1718600",
    "end": "1724039"
  },
  {
    "text": "need to understand the sched again it's not a silver ballet you",
    "start": "1724039",
    "end": "1729679"
  },
  {
    "text": "we have some in this some incidents because of this we have to really tweak this properly this this is on G we are",
    "start": "1729679",
    "end": "1737159"
  },
  {
    "text": "running on three main Cloud providers in AWS uh we replac the",
    "start": "1737159",
    "end": "1743240"
  },
  {
    "text": "cluster the AOS scaler a call out an important call out here in Google the",
    "start": "1743240",
    "end": "1748440"
  },
  {
    "text": "SCH and the cluster of the scaler are in the corner plane so you in G you don't",
    "start": "1748440",
    "end": "1753519"
  },
  {
    "text": "control it in there's this difference the SCH is in the contol play but you",
    "start": "1753519",
    "end": "1759120"
  },
  {
    "text": "need to run your own cluster of the scaler so this is replaceable Carpenter is an open source project um that",
    "start": "1759120",
    "end": "1767000"
  },
  {
    "text": "actually tends to replace the stock cluster of the scaler and it has so many knobs",
    "start": "1767000",
    "end": "1772039"
  },
  {
    "text": "things like you can configure for example the especially diversity of the underlying nose to to better match the",
    "start": "1772039",
    "end": "1778760"
  },
  {
    "text": "shape of the POS by shape I mean the radio memory divided by CPU match the",
    "start": "1778760",
    "end": "1784200"
  },
  {
    "text": "shape of the pose with the shape of the nose and have a better be packing story",
    "start": "1784200",
    "end": "1789600"
  },
  {
    "text": "and we are really lucky uh today like yes today we published uh a blog post by",
    "start": "1789600",
    "end": "1797399"
  },
  {
    "text": "couple teammates that were actually working in Carpenter Logan and Paula which has which has a pretty well",
    "start": "1797399",
    "end": "1804080"
  },
  {
    "text": "detailed and some really interesting views on again on this on how car have helped us especially on the on ouring",
    "start": "1804080",
    "end": "1811080"
  },
  {
    "text": "parking story and then finally a call out for this uh white paper by Google",
    "start": "1811080",
    "end": "1816640"
  },
  {
    "text": "stat of kubernetes cost optimization and uh and with that I think that we're done",
    "start": "1816640",
    "end": "1823360"
  },
  {
    "text": "yeah thank you thank you for being here and and thanks",
    "start": "1823360",
    "end": "1828760"
  },
  {
    "text": "[Applause]",
    "start": "1828760",
    "end": "1835680"
  },
  {
    "text": "sorry f i I forgot something numbers I I had promised some numbers we went for something like without touching anything",
    "start": "1835919",
    "end": "1842760"
  },
  {
    "text": "on our cluster we were hovering 40 45% of FAL",
    "start": "1842760",
    "end": "1848120"
  },
  {
    "text": "resources consider that you you have 50% of f resources you're essentially paying for the double that you are actually",
    "start": "1848120",
    "end": "1854640"
  },
  {
    "text": "using right your your noes are using half so we went from something like",
    "start": "1854640",
    "end": "1860360"
  },
  {
    "text": "45ish to 22 25% of idle",
    "start": "1860360",
    "end": "1865760"
  },
  {
    "text": "usage questions yeah",
    "start": "1867120",
    "end": "1872840"
  },
  {
    "text": "questions question too late please use a",
    "start": "1875720",
    "end": "1883279"
  },
  {
    "text": "microphone uh I noticed you were using requests for everything is that not uh considered",
    "start": "1883279",
    "end": "1891399"
  },
  {
    "text": "limits uh by itself or is that the container request and then the limits are on top of that so the main thing",
    "start": "1891399",
    "end": "1898399"
  },
  {
    "text": "that the scheduler cares about is what you request right so if you have upper limits like it could go up to that and",
    "start": "1898399",
    "end": "1905399"
  },
  {
    "text": "that's fine but the main thing that we care about is tracking what our resources are requesting um we've we've",
    "start": "1905399",
    "end": "1911320"
  },
  {
    "text": "done some analysis comparing the two right looking at the the maximum value between other the the limit the usage",
    "start": "1911320",
    "end": "1918120"
  },
  {
    "text": "that they've had versus the request and at least in our organization it's really",
    "start": "1918120",
    "end": "1923799"
  },
  {
    "text": "has been negligible so we focus on requests at least yeah to keep it",
    "start": "1923799",
    "end": "1929880"
  },
  {
    "text": "simple kind of follow up to that like shouldn't it be the max of usage or",
    "start": "1929880",
    "end": "1935159"
  },
  {
    "text": "requests in order to get the correct number for the work uh so uh as as we",
    "start": "1935159",
    "end": "1941159"
  },
  {
    "text": "mentioned in this particular talk we're actually focusing on B packing so understanding how the schul is able to",
    "start": "1941159",
    "end": "1946760"
  },
  {
    "text": "be the PS we are not focusing on right sizing that will be a a completely different approach you have different",
    "start": "1946760",
    "end": "1952799"
  },
  {
    "text": "metrics to try to see how well you are using the amount of request the the the",
    "start": "1952799",
    "end": "1958279"
  },
  {
    "text": "request that you are requesting so but that's why we wanted to highlight the start of the talk when we talk about",
    "start": "1958279",
    "end": "1965320"
  },
  {
    "text": "about um usage that is a different aspect of usage this is how how much of",
    "start": "1965320",
    "end": "1970639"
  },
  {
    "text": "your if I understand correctly your question will be how well you're using how the resources that you're requested",
    "start": "1970639",
    "end": "1976320"
  },
  {
    "text": "at the P level uh the other question is about CPU like you broke down a note into CPU cost",
    "start": "1976320",
    "end": "1982840"
  },
  {
    "text": "versus memory cost I'm not sure if that's accurate because like let's say you reserve a note on AWS right it comes",
    "start": "1982840",
    "end": "1988760"
  },
  {
    "text": "with 4 CPU and let's say 16 gig memory you can't really break down that into",
    "start": "1988760",
    "end": "1994200"
  },
  {
    "text": "like separate costs CU like you can reserve 16 gigs of memory but you only use two CPU but you're still taking up",
    "start": "1994200",
    "end": "1999840"
  },
  {
    "text": "the whole node right so yeah and that's a great question so I I the way that we",
    "start": "1999840",
    "end": "2006480"
  },
  {
    "text": "we approach us internally is we're not trying to get to accounting level accuracy to have it line up exactly with",
    "start": "2006480",
    "end": "2011919"
  },
  {
    "text": "our bill we're just trying to have a rough approximation of each workload",
    "start": "2011919",
    "end": "2017399"
  },
  {
    "text": "what it's requesting what those units of cost are and we sum that up over time and for us we're really looking for",
    "start": "2017399",
    "end": "2023919"
  },
  {
    "text": "Trends right we want to see over time for our workloads what have they requested and um calculate the cost of",
    "start": "2023919",
    "end": "2031840"
  },
  {
    "text": "those requests gotcha thanks thank you",
    "start": "2031840",
    "end": "2037559"
  },
  {
    "text": "great talk um question is there a place that you publish any dashboard that has",
    "start": "2037559",
    "end": "2044240"
  },
  {
    "text": "this like different the queries like so like open source or like",
    "start": "2044240",
    "end": "2050000"
  },
  {
    "text": "internally yeah open source not yet that's something we're trying to figure out so we we use um like JSA internally",
    "start": "2050000",
    "end": "2057358"
  },
  {
    "text": "to publish a lot of our dashboards a lot of our queries and whatnot so it's one of those things we're trying to figure",
    "start": "2057359",
    "end": "2063000"
  },
  {
    "text": "out the right balance because most people probably aren't using Json on it um but if it's something you're interested in um you can join our slack",
    "start": "2063000",
    "end": "2069679"
  },
  {
    "text": "Channel and we're we will more than happy to share that Yeah we actually run",
    "start": "2069679",
    "end": "2074919"
  },
  {
    "text": "short of time we we wanted to create a repo with the let's say already manifested uh because as Mark mentioned",
    "start": "2074919",
    "end": "2081000"
  },
  {
    "text": "we're using Jon sometimes that the J is is kind of hard to to get started with",
    "start": "2081000",
    "end": "2087118"
  },
  {
    "text": "so yeah just a little so we want to let's say to to to share the already manifested uh recording rules but we run",
    "start": "2087119",
    "end": "2095200"
  },
  {
    "text": "out of time and that's why we created this resource essentially a channel there in our slack and and we may actually publish in",
    "start": "2095200",
    "end": "2102880"
  },
  {
    "text": "uh some of these as asert but yeah it's our PL to actually publish the the full",
    "start": "2102880",
    "end": "2108440"
  },
  {
    "text": "I will reach out to a slack yeah sure thank you thank",
    "start": "2108440",
    "end": "2113599"
  },
  {
    "text": "you probably have time for one more question",
    "start": "2114520",
    "end": "2119359"
  },
  {
    "text": "anybody with that thank you time thank thank",
    "start": "2119640",
    "end": "2126760"
  }
]
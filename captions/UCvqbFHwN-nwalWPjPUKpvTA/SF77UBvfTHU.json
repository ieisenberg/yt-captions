[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "thank you all for coming today to hear us talk about natural language search with Kukla so my name is jeremy levy i",
    "start": "30",
    "end": "7259"
  },
  {
    "text": "am the tech lead for the Google cube flow engineering team and I'll let my co-speaker introduce himself",
    "start": "7259",
    "end": "12269"
  },
  {
    "text": "I'm Hamill Husein I work at github that's a machine learning engineer I focus on representation learning of code",
    "start": "12269",
    "end": "20180"
  },
  {
    "start": "20000",
    "end": "90000"
  },
  {
    "text": "so here's the agenda for for today so the key point that we want to try to get across today is that going from an idea",
    "start": "20180",
    "end": "27840"
  },
  {
    "text": "for an ml product into into production takes way too much time and so with coop flow we're trying to build a platform",
    "start": "27840",
    "end": "34380"
  },
  {
    "text": "that's really going to help you accelerate getting your ideas into production and so to tell that story",
    "start": "34380",
    "end": "40460"
  },
  {
    "text": "Hamill's going to talk about his experience at github working on a natural language code search engine and",
    "start": "40460",
    "end": "46739"
  },
  {
    "text": "some of the challenges that he faced getting that idea into production and we're going to use that as motivation to",
    "start": "46739",
    "end": "53059"
  },
  {
    "text": "sort of highlight the types of problems that we were creating cube flow to solve and so we'll explain what we mean by",
    "start": "53059",
    "end": "59070"
  },
  {
    "text": "cube flow in terms of you know a kubernetes need a platform for machine learning and then we're gonna do",
    "start": "59070",
    "end": "64619"
  },
  {
    "text": "basically a walkthrough we're gonna we're gonna go through step by steps the process that Hamill went through to",
    "start": "64619",
    "end": "70890"
  },
  {
    "text": "build this natural language code search but we're gonna do it using coop flow and sort of show how we can take advantage of coop flow to accelerate",
    "start": "70890",
    "end": "78210"
  },
  {
    "text": "that process and then we'll come back to Hamill who will have some some concluding remarks and so with that I'm",
    "start": "78210",
    "end": "85259"
  },
  {
    "text": "going to hand it over to Hamill to talk about what he was doing at github thanks",
    "start": "85259",
    "end": "91170"
  },
  {
    "text": "Jeremy so like Jeremy said we want to ground this talk in coop flow with a sort of",
    "start": "91170",
    "end": "97829"
  },
  {
    "text": "real life example and so one of the things I'm working on at github is",
    "start": "97829",
    "end": "103399"
  },
  {
    "text": "trying to create new ways to search code that are not available today so one",
    "start": "103399",
    "end": "109380"
  },
  {
    "text": "example of that is being able to search code with natural language queries so",
    "start": "109380",
    "end": "115920"
  },
  {
    "text": "today when you try to search for code its keyword search so you got you have to know what the syntax is that you're",
    "start": "115920",
    "end": "121320"
  },
  {
    "text": "looking for or you have to try to figure out what keyword might be in the code",
    "start": "121320",
    "end": "127439"
  },
  {
    "text": "but what if you could just search for code using natural language",
    "start": "127439",
    "end": "132490"
  },
  {
    "text": "in a very human way and not really worry about what the syntax is and retrieve",
    "start": "132490",
    "end": "138940"
  },
  {
    "text": "the code that you're looking for that sounds like science fiction but actually the reality is probably a lot closer",
    "start": "138940",
    "end": "146530"
  },
  {
    "text": "than you think and so what we have is we this is still under experimentation but",
    "start": "146530",
    "end": "154270"
  },
  {
    "text": "we've open sourced an end end example with data and code it's a really",
    "start": "154270",
    "end": "159520"
  },
  {
    "text": "exciting open source example because it's not an academic data set this is a real messy data set from a real data",
    "start": "159520",
    "end": "166300"
  },
  {
    "text": "product and we show that there are some exciting results that you can replicate",
    "start": "166300",
    "end": "171970"
  },
  {
    "text": "yourself and then also this is actually inside the coop flow repository and one",
    "start": "171970",
    "end": "179290"
  },
  {
    "text": "of the canonical examples that they have of how to wrestle a somewhat complex",
    "start": "179290",
    "end": "186610"
  },
  {
    "text": "machine learning problem with coop flow I'm not going to go in depth about the",
    "start": "186610",
    "end": "192730"
  },
  {
    "text": "model and the data science behind it but there's a blog post that you can find and you can reference on the slides when",
    "start": "192730",
    "end": "201610"
  },
  {
    "text": "you get a chance later so one of the",
    "start": "201610",
    "end": "208240"
  },
  {
    "text": "main I just want to talk about sort of some misperceptions about machine learning about launching machine",
    "start": "208240",
    "end": "213970"
  },
  {
    "text": "learning products scaling machine learning products and how that's relevant goop flow so so you might think",
    "start": "213970",
    "end": "222880"
  },
  {
    "text": "so it might strike you that this natural language semantic code search is very complex and it might take a long time to",
    "start": "222880",
    "end": "229540"
  },
  {
    "text": "build which is is true but I want to break that down a little bit so our",
    "start": "229540",
    "end": "236620"
  },
  {
    "text": "first prototype of natural language code search we did in about two weeks so we",
    "start": "236620",
    "end": "244090"
  },
  {
    "text": "built it end and we prototype that we demonstrated in some jupiter notebooks and we open sourced it and only took two",
    "start": "244090",
    "end": "251200"
  },
  {
    "text": "people two weeks to do a couple of days later we put a UI in front of it and we",
    "start": "251200",
    "end": "260070"
  },
  {
    "text": "launched a blog post about it and open sourced it completely to the whole",
    "start": "260070",
    "end": "265090"
  },
  {
    "text": "world three months later we stood up a",
    "start": "265090",
    "end": "270910"
  },
  {
    "text": "site called experiments github.com where we kind of serve this at a larger scale",
    "start": "270910",
    "end": "279010"
  },
  {
    "text": "to the public and sort of productionize this model on a micro site so this is",
    "start": "279010",
    "end": "286630"
  },
  {
    "text": "really profound it took two weeks to build a model and then three months",
    "start": "286630",
    "end": "292780"
  },
  {
    "text": "later after working really hard every day we launched it into production on a",
    "start": "292780",
    "end": "298330"
  },
  {
    "text": "microsite not even on github.com if it were lodged on github.com and i might take two years with the current workflow",
    "start": "298330",
    "end": "304330"
  },
  {
    "text": "that we had so this is really interesting why does it take two weeks",
    "start": "304330",
    "end": "310419"
  },
  {
    "text": "to make the thing and may you know three months to to launch the thing that might",
    "start": "310419",
    "end": "316300"
  },
  {
    "text": "be surprising so I want to talk about that so there's a perception in the industry today that data products these",
    "start": "316300",
    "end": "325630"
  },
  {
    "start": "318000",
    "end": "395000"
  },
  {
    "text": "machine learning products are mostly about machine learning that's where there's a perception that you need to",
    "start": "325630",
    "end": "333490"
  },
  {
    "text": "pour all your resources into machine learning that you need tons of data scientists and if you throw lots of data",
    "start": "333490",
    "end": "340389"
  },
  {
    "text": "scientists out the problem then you can launch these these amazing products",
    "start": "340389",
    "end": "347010"
  },
  {
    "text": "however this is a misperception and you see that teams are often resourced in",
    "start": "347010",
    "end": "353289"
  },
  {
    "text": "this way so I've worked at github and Airbnb and several other tech companies and I will",
    "start": "353289",
    "end": "360250"
  },
  {
    "text": "say that a lot of times it's a very it's a very tends to be lopsided so you'll have ten machine learning engineers and",
    "start": "360250",
    "end": "368200"
  },
  {
    "text": "maybe one data engineer or one software engineer paired with those ten data",
    "start": "368200",
    "end": "374500"
  },
  {
    "text": "scientists and that's really interesting because the the perception in people's",
    "start": "374500",
    "end": "380889"
  },
  {
    "text": "minds is the product is mostly about machine learning and really all this",
    "start": "380889",
    "end": "387789"
  },
  {
    "text": "other stuff that DevOps and the engineering is kind of you know an afterthought",
    "start": "387789",
    "end": "394650"
  },
  {
    "start": "395000",
    "end": "568000"
  },
  {
    "text": "however reality looks like this where machine learning is a very small",
    "start": "395210",
    "end": "401070"
  },
  {
    "text": "component that yellow dot and everything else is you know the data product is",
    "start": "401070",
    "end": "408720"
  },
  {
    "text": "really taken up by all of these other components so configuration scaling you",
    "start": "408720",
    "end": "417810"
  },
  {
    "text": "know the DevOps of software engineering it really you know that is kind of what",
    "start": "417810",
    "end": "423210"
  },
  {
    "text": "a real machine learning product is about and actually this this graphic is from a",
    "start": "423210",
    "end": "428400"
  },
  {
    "text": "paper that they may have seen from Google that hidden technical debt and",
    "start": "428400",
    "end": "434190"
  },
  {
    "text": "machine learning systems which I encourage you to read and this actually reflects reality very well and what",
    "start": "434190",
    "end": "441210"
  },
  {
    "text": "happens is there's often a chicken-and-egg problem where organizations hire a bunch of machine",
    "start": "441210",
    "end": "446490"
  },
  {
    "text": "learning experts or data scientists and when they land they say hey we actually",
    "start": "446490",
    "end": "452700"
  },
  {
    "text": "need support from engineering or DevOps and the answer is that you know you can",
    "start": "452700",
    "end": "460740"
  },
  {
    "text": "you show some value first often the data scientists they're able to show the",
    "start": "460740",
    "end": "465840"
  },
  {
    "text": "value without launching something so it's kind of chicken and egg problem it's a frustration in the industry and one one really interesting point here is",
    "start": "465840",
    "end": "474450"
  },
  {
    "text": "there's a perception in the industry that there's a shortage of data scientists there's a lot of buzz about",
    "start": "474450",
    "end": "481340"
  },
  {
    "text": "the shortage of machine learning engineers a shortage of of this skill",
    "start": "481340",
    "end": "487790"
  },
  {
    "text": "but I would actually like to challenge you to say if you know what data scientists or if you know machine learning engineer ask them what their",
    "start": "487790",
    "end": "495240"
  },
  {
    "text": "biggest bottleneck is and I will guess that very few people will say we need",
    "start": "495240",
    "end": "501090"
  },
  {
    "text": "more data scientists what you often hear is any better tools better infrastructure more cross-functional",
    "start": "501090",
    "end": "509220"
  },
  {
    "text": "support and so I would say the shortage",
    "start": "509220",
    "end": "514530"
  },
  {
    "text": "the real demand for unlocking machine learning is all of this tooling is often",
    "start": "514530",
    "end": "520260"
  },
  {
    "text": "all this tooling and that's something that's not talked about and if you're sitting in this room and you're building these skills I think",
    "start": "520260",
    "end": "527260"
  },
  {
    "text": "that is really exciting and you'll see some companies recently that have become",
    "start": "527260",
    "end": "534070"
  },
  {
    "text": "savvy to this so uber with Michelangelo Airbnb with bighead Facebook with",
    "start": "534070",
    "end": "540610"
  },
  {
    "text": "Facebook learn lyft learn creating this in-house machine learning infrastructure",
    "start": "540610",
    "end": "547590"
  },
  {
    "text": "however you know those are homegrown tools they're very complex they address",
    "start": "547590",
    "end": "554200"
  },
  {
    "text": "this need but what is is there an open source solution to this problem and",
    "start": "554200",
    "end": "560670"
  },
  {
    "text": "that's why I'm excited about what Jeremy is about to talk about next which so",
    "start": "560670",
    "end": "567850"
  },
  {
    "text": "thank you very much I think that is a great motivator so like I said before you know we're trying with kupo to build",
    "start": "567850",
    "end": "575110"
  },
  {
    "text": "a kubernetes native platform for building ml products and the idea here is to leverage containers in kubernetes",
    "start": "575110",
    "end": "581590"
  },
  {
    "text": "to solve the same sorts of DevOps challenges that we see in non ml products and bring those those those",
    "start": "581590",
    "end": "588580"
  },
  {
    "text": "same solutions to data scientists and the ML community so to give you a concrete example when I talk to Hamel",
    "start": "588580",
    "end": "595390"
  },
  {
    "text": "and we started this discussion about this collaboration I asked him you know how how are you doing your training",
    "start": "595390",
    "end": "600610"
  },
  {
    "text": "where are you running your models and he told me what he was doing was he was spitting up VMs on the cloud and so in",
    "start": "600610",
    "end": "607570"
  },
  {
    "text": "this regard he was actually you know ahead of where we see most data scientists because most data scientists tell us that they're just running either",
    "start": "607570",
    "end": "614410"
  },
  {
    "text": "on their little laptop or maybe like a heavy ba you know a very complicated box that has lots of GPUs under their desk",
    "start": "614410",
    "end": "622170"
  },
  {
    "text": "so Hamel was well ahead of the game when when when the when he told me he was",
    "start": "622170",
    "end": "627400"
  },
  {
    "text": "running on cloud it was only six months later when I sort of delved a little bit deeper I sort of assumed he was just",
    "start": "627400",
    "end": "633970"
  },
  {
    "text": "using the natural cloud epi is to spin up the VMS but then when he told me was you know of course not he wasn't doing",
    "start": "633970",
    "end": "640360"
  },
  {
    "text": "that because like any enterprise you know github is very concerned about the",
    "start": "640360",
    "end": "647950"
  },
  {
    "text": "the safety of the enterprise and they don't want to they're worried about locking down the surface area of cloud",
    "start": "647950",
    "end": "653860"
  },
  {
    "text": "to make sure that people can't shoot themselves in the foot so he was actually consuming through higher level infrastructure",
    "start": "653860",
    "end": "661839"
  },
  {
    "text": "abstractions that github built and this actually restricted him to only sort of spitting up and managing VMs through a",
    "start": "661839",
    "end": "667870"
  },
  {
    "text": "chat bot that's yes right and so this",
    "start": "667870",
    "end": "673089"
  },
  {
    "text": "created a lot of toil for him in terms of you know managing these different VMs",
    "start": "673089",
    "end": "678250"
  },
  {
    "text": "and so it's in particular you know I'm training models can be a very long running process so you know he would",
    "start": "678250",
    "end": "683860"
  },
  {
    "text": "spin up one VM let one model train and then spin up another VM SSA chain and",
    "start": "683860",
    "end": "688959"
  },
  {
    "text": "spin up you know it's launched something else let that train and then manually tear these things up and down right so",
    "start": "688959",
    "end": "694480"
  },
  {
    "text": "that's a lot of toil and that's precisely the kinds of problems that we're solving with kubernetes right we're taking advantage of things like",
    "start": "694480",
    "end": "700779"
  },
  {
    "text": "our back in namespaces to isolate people eight resources and create secure environments you know where we were",
    "start": "700779",
    "end": "708370"
  },
  {
    "text": "there's work from like IBM and others to create batch schedulers to make it easy to provision resources so we really",
    "start": "708370",
    "end": "713769"
  },
  {
    "text": "wanted to take advantage of kubernetes to build this machine learning platform and there's a couple of reasons we",
    "start": "713769",
    "end": "718870"
  },
  {
    "text": "picked kubernetes the first hopefully this is not a controversial statement in this conference but you know we think",
    "start": "718870",
    "end": "724899"
  },
  {
    "text": "kubernetes has won so increasingly we either see customers have either adopted",
    "start": "724899",
    "end": "730269"
  },
  {
    "text": "kubernetes or they're just strongly thinking about moving to kubernetes and it's mostly a question of how to migrate",
    "start": "730269",
    "end": "735699"
  },
  {
    "text": "their infrastructure the second thing is we we increasingly see our customers asking for hybrid solutions they want to",
    "start": "735699",
    "end": "742480"
  },
  {
    "text": "be able to run both on Prem and in the cloud and so we can take advantage of kubernetes to deliver that because",
    "start": "742480",
    "end": "747939"
  },
  {
    "text": "kubernetes already runs everywhere it runs on prem and in the cloud so if we if we build the platform on top of",
    "start": "747939",
    "end": "754389"
  },
  {
    "text": "kubernetes then we automatically create a platform which is which is you know hybrid and runs everywhere the second",
    "start": "754389",
    "end": "760959"
  },
  {
    "text": "thing is you know as Hamill mentioned a lot of times at organizations we see this split between the data scientists",
    "start": "760959",
    "end": "766089"
  },
  {
    "text": "teams and the infrastructure teams and they have sort of different nomenclature and different stats so we think that if",
    "start": "766089",
    "end": "771639"
  },
  {
    "text": "we can get everybody sort of using kubernetes and sort of get that in kubernetes to be a natural choice for",
    "start": "771639",
    "end": "777240"
  },
  {
    "text": "data scientists and ml engineers we think we can make it a lot easier to move infrastructure from the idea or",
    "start": "777240",
    "end": "784240"
  },
  {
    "text": "experimentation phase into production because you won't have to rewrite or we do a lot of your infrastructure all be already be there and then finally the",
    "start": "784240",
    "end": "792279"
  },
  {
    "text": "last piece I just want to mention you know coop flow is entirely open so there's a couple reasons for doing that",
    "start": "792279",
    "end": "798249"
  },
  {
    "text": "first we increasingly seeing customers asking for solutions that don't provide",
    "start": "798249",
    "end": "803259"
  },
  {
    "text": "lock-in they care a lot about that the second thing is we've seen from the kubernetes community that building an",
    "start": "803259",
    "end": "809290"
  },
  {
    "text": "open-source ecosystem is really a great way to build a complex platform and so",
    "start": "809290",
    "end": "814809"
  },
  {
    "text": "we really wanted to try to build a community and you leverage that to build the platform rather than trying to build",
    "start": "814809",
    "end": "820420"
  },
  {
    "text": "it all ourselves so the first thing that we're really trying to do with coop flow",
    "start": "820420",
    "end": "825699"
  },
  {
    "start": "822000",
    "end": "1000000"
  },
  {
    "text": "is we want to provide components for every stage of ml life's ml development",
    "start": "825699",
    "end": "830920"
  },
  {
    "text": "we are a long way from there but we already have a lot of components that solve different problems in the ml",
    "start": "830920",
    "end": "836680"
  },
  {
    "text": "lifecycle in fact we have so many that I can't talk about all of them today but I",
    "start": "836680",
    "end": "842079"
  },
  {
    "text": "did want to give you examples for every for various stages of what what exists today",
    "start": "842079",
    "end": "847379"
  },
  {
    "text": "so the first first step in sort of the ml lifecycle development development",
    "start": "847379",
    "end": "853120"
  },
  {
    "text": "lifecycle is you have to do experimentation and data exploration right and so for that you know our data",
    "start": "853120",
    "end": "858370"
  },
  {
    "text": "scientists want Jupiter they want notebooks for interactive data scientist",
    "start": "858370",
    "end": "863529"
  },
  {
    "text": "environments so we've taken advantage of Jupiter and Jupiter hub to run and provision notebooks on kubernetes and so",
    "start": "863529",
    "end": "871059"
  },
  {
    "text": "they've done a lot of great work in the Jupiter community to run on kubernetes and we're just taking advantage of that the next step in development is you",
    "start": "871059",
    "end": "878620"
  },
  {
    "text": "actually have to train your models so for this what we've done is we've started developing custom resources in",
    "start": "878620",
    "end": "884709"
  },
  {
    "text": "kubernetes so we have custom resources for you know tensorflow and pi torch and some of the other frameworks as well and",
    "start": "884709",
    "end": "890920"
  },
  {
    "text": "these custom resources make it really easy to run distributed training on kubernetes so this allows you to train",
    "start": "890920",
    "end": "896860"
  },
  {
    "text": "large models on kubernetes and scale out horizontally we also provide catted",
    "start": "896860",
    "end": "902410"
  },
  {
    "text": "which is a hyper parameter tuning system which makes it easy to optimize the",
    "start": "902410",
    "end": "907569"
  },
  {
    "text": "parameters of your model and you can take advantage of the algorithms built in cat into cat Abe and define hyper",
    "start": "907569",
    "end": "913629"
  },
  {
    "text": "parameter tuning jobs declaratively without writing them in code the next step is of course inference and so for",
    "start": "913629",
    "end": "920470"
  },
  {
    "text": "inference we providing beam transforms for doing batch inference so beam is an",
    "start": "920470",
    "end": "925610"
  },
  {
    "text": "etl framework similar to spark that's going to make it easy to scale out and run batch inference on very large data",
    "start": "925610",
    "end": "931010"
  },
  {
    "text": "sets and we're going to take advantage of that in the natural language code search example we're also working on",
    "start": "931010",
    "end": "937220"
  },
  {
    "text": "providing cloud native integrations for various model servers so 10 0 serving is",
    "start": "937220",
    "end": "943730"
  },
  {
    "text": "a very popular model server for the tensorflow community we went ahead and added to that Prometheus integrations so",
    "start": "943730",
    "end": "950450"
  },
  {
    "text": "you can begin to export your metrics like application metrics such as model load times to Prometheus another big",
    "start": "950450",
    "end": "957019"
  },
  {
    "text": "problem in ml is that you often have complex workflows for training your models so maybe you have to pre-process",
    "start": "957019",
    "end": "962899"
  },
  {
    "text": "some data and then train your model or for deploying your model maybe you have to again pre-process the data and then",
    "start": "962899",
    "end": "968510"
  },
  {
    "text": "do batch inference and so we we wanted to provide a solution for expressing",
    "start": "968510",
    "end": "974930"
  },
  {
    "text": "these complex workflows and so that's why we've recently introduced coop flow pipelines and then finally what we've",
    "start": "974930",
    "end": "982160"
  },
  {
    "text": "seen is a big problem is getting the data to feed your models so a feature store is very important so gojek has",
    "start": "982160",
    "end": "989209"
  },
  {
    "text": "been working on a feature store for their own internal use they've I think just recently open sourced it and I",
    "start": "989209",
    "end": "995180"
  },
  {
    "text": "think they're going to submit a proposal pretty soon to add that to coop flow so we're very excited about that as well so",
    "start": "995180",
    "end": "1001600"
  },
  {
    "start": "1000000",
    "end": "1068000"
  },
  {
    "text": "so one of the problems is it's not just enough to have all these different components we really want to organize",
    "start": "1001600",
    "end": "1007240"
  },
  {
    "text": "these components into a cohesive platform and so that's why in the coop flow community we've been spending a lot",
    "start": "1007240",
    "end": "1012250"
  },
  {
    "text": "of time on providing simple solutions a one click or one command solution for",
    "start": "1012250",
    "end": "1017320"
  },
  {
    "text": "deploying coop flow right and so this diagram on the right gives you a little bit of the product example of the problem right so this is for two paterno",
    "start": "1017320",
    "end": "1024459"
  },
  {
    "text": "books so when we deploy Jupiter we don't just want to run the jupiter pods and spin up the jupiter notebooks we want to",
    "start": "1024459",
    "end": "1030850"
  },
  {
    "text": "provision the appropriate credentials in terms of our back for isolating accessing kubernetes resources and also",
    "start": "1030850",
    "end": "1037540"
  },
  {
    "text": "service accounts for accessing cloud resources like object store so you can access your data stores from your",
    "start": "1037540",
    "end": "1042850"
  },
  {
    "text": "notebooks and then since it's a web service we have to provide a good ingress story and so that people can",
    "start": "1042850",
    "end": "1049840"
  },
  {
    "text": "access their notebooks from outside the cluster so when they're running on their local laptop so that means we have to",
    "start": "1049840",
    "end": "1055090"
  },
  {
    "text": "set up ingress and think about things like certificates and types of security measures right so",
    "start": "1055090",
    "end": "1060270"
  },
  {
    "text": "those are the types of things we take care of them we deploy coop flow and so we have a command line tool as well as a",
    "start": "1060270",
    "end": "1065880"
  },
  {
    "text": "web app and then as I mentioned pipelines is one of the newest additions",
    "start": "1065880",
    "end": "1072060"
  },
  {
    "start": "1068000",
    "end": "1152000"
  },
  {
    "text": "to coop flow and so basically what pipelines does is it allows you to",
    "start": "1072060",
    "end": "1077130"
  },
  {
    "text": "define complex ml workflows in Python so it's very natural for data scientists and ml engineers they don't have to",
    "start": "1077130",
    "end": "1082860"
  },
  {
    "text": "switch their mindset from Python to ya mole or some other framework to define their Python to there to find their",
    "start": "1082860",
    "end": "1088770"
  },
  {
    "text": "pipeline and so I have a simple simple example down here and so what we can see here is you know they're defining what",
    "start": "1088770",
    "end": "1096420"
  },
  {
    "text": "they want to run for every step so every step runs it in its own container so we're just specifying the doctor image",
    "start": "1096420",
    "end": "1102060"
  },
  {
    "text": "room on a run and the command we want to run and then we have some simple Python syntax that specifies the order in which",
    "start": "1102060",
    "end": "1107640"
  },
  {
    "text": "the steps should be executed and the only reason we have to explicitly specify the order is if the order can't",
    "start": "1107640",
    "end": "1114000"
  },
  {
    "text": "be implicitly determined from the data dependencies so a lot of times in ml workflows there's data dependencies so",
    "start": "1114000",
    "end": "1120480"
  },
  {
    "text": "the output of one step is the input to the next step and if you have such a pipeline then pipelines will",
    "start": "1120480",
    "end": "1125760"
  },
  {
    "text": "automatically infer the graph for you and you don't have to explicitly construct the graph and then we have a",
    "start": "1125760",
    "end": "1132270"
  },
  {
    "text": "UI that makes it very easy to visualize all in all your runs and track all your runs and you can take advantage of",
    "start": "1132270",
    "end": "1139320"
  },
  {
    "text": "pipelines to run your pipeline schedule your pipelines to run regularly so you can take advantage of that to update",
    "start": "1139320",
    "end": "1144720"
  },
  {
    "text": "your models and then under the hood this is being powered by Argo so we're very grateful to the Argo community for all",
    "start": "1144720",
    "end": "1151140"
  },
  {
    "text": "the work they've done there and then the next piece that's going to be critical to our to our story for natural language",
    "start": "1151140",
    "end": "1156540"
  },
  {
    "start": "1152000",
    "end": "1213000"
  },
  {
    "text": "code surgeons we're going to take advantage of Argo CD so Argo CD is a continuous delivery system for",
    "start": "1156540",
    "end": "1162210"
  },
  {
    "text": "kubernetes and we're going to take advantage of this stuff to continuously push our latest model into production so",
    "start": "1162210",
    "end": "1168120"
  },
  {
    "text": "the what Argo CD does is it's basically an agent that you run on your kubernetes cluster and you point it at a git repo",
    "start": "1168120",
    "end": "1174720"
  },
  {
    "text": "and this is the git repo where you store the manifests for all of your kubernetes resources that comprise your application",
    "start": "1174720",
    "end": "1180480"
  },
  {
    "text": "and what Argos CD will do is it will continually monitor what's actually deployed in your coop Flo cluster I'm",
    "start": "1180480",
    "end": "1187200"
  },
  {
    "text": "sorry in your kubernetes cluster and if it detects that what you have deployed is out of",
    "start": "1187200",
    "end": "1192290"
  },
  {
    "text": "with what your what's in your manifests it will update what you have running in production to match what's in the end",
    "start": "1192290",
    "end": "1198260"
  },
  {
    "text": "the manifests so this creates a very simple way to begin automating your your",
    "start": "1198260",
    "end": "1203840"
  },
  {
    "text": "delivery because now all you have to do is push a commit that changes the parameters or of your server or whatever",
    "start": "1203840",
    "end": "1209990"
  },
  {
    "text": "and then our go CD will take care of rolling that out so now I wanted to come back to the process of how we actually",
    "start": "1209990",
    "end": "1217460"
  },
  {
    "start": "1213000",
    "end": "1265000"
  },
  {
    "text": "use coop flow taking advantage of the example of natural language code search",
    "start": "1217460",
    "end": "1222680"
  },
  {
    "text": "so here's the schematic of the high-level process that that Hamel went through so he started off by identifying",
    "start": "1222680",
    "end": "1230030"
  },
  {
    "text": "a problem he then did some experimentation to see if it was solvable for with machine learning he",
    "start": "1230030",
    "end": "1236060"
  },
  {
    "text": "then trained some models and then he deployed those models and ran them in in",
    "start": "1236060",
    "end": "1241430"
  },
  {
    "text": "production so we're going to go through that process now with coop flow and a couple of things to sort of look out for",
    "start": "1241430",
    "end": "1247640"
  },
  {
    "text": "it is the fact that we have a multiple steps involved in building the model and",
    "start": "1247640",
    "end": "1252680"
  },
  {
    "text": "then a lot of these steps have different resources that have different resource requirements right so it's a perfect",
    "start": "1252680",
    "end": "1258290"
  },
  {
    "text": "problem for taking advantage of kubernetes and letting kubernetes take advantage of take care of resource",
    "start": "1258290",
    "end": "1263660"
  },
  {
    "text": "management so switching over so this is our click to deploy app and so this is",
    "start": "1263660",
    "end": "1270140"
  },
  {
    "start": "1265000",
    "end": "1305000"
  },
  {
    "text": "what we're building so we can really make it super easy for data scientists like Hamel who don't know anything about",
    "start": "1270140",
    "end": "1275900"
  },
  {
    "text": "kubernetes to get started and so the idea here is that with one simple click they can deploy their entire kubernetes",
    "start": "1275900",
    "end": "1281540"
  },
  {
    "text": "cluster with all of the coop flow services deployed and wired up for their particular you know cloud so in this",
    "start": "1281540",
    "end": "1290300"
  },
  {
    "text": "case all you would have to do is specify the the project where he wants to deploy his infrastructure as well as the name",
    "start": "1290300",
    "end": "1296900"
  },
  {
    "text": "of the deployment that he wants to assign his deployment and then you can click deploy and all those resources",
    "start": "1296900",
    "end": "1302750"
  },
  {
    "text": "would go and get deployed after he spins",
    "start": "1302750",
    "end": "1308870"
  },
  {
    "start": "1305000",
    "end": "1343000"
  },
  {
    "text": "up coop flow he can come to what we call our central navigation dashboard and from here we can see all the different",
    "start": "1308870",
    "end": "1314900"
  },
  {
    "text": "services we have running in our coop flow cluster so we have the handy link to our Doc's because those are always",
    "start": "1314900",
    "end": "1320090"
  },
  {
    "text": "helpful but you can also from here navigate to Jupiter hubs so we can begin spinning up",
    "start": "1320090",
    "end": "1325230"
  },
  {
    "text": "books to do is model development we provide a convenient dashboard for monitoring your tensorflow jobs cat tip",
    "start": "1325230",
    "end": "1333059"
  },
  {
    "text": "is again our hyper parameter tuning system it's grayed out here because I haven't deployed it in this particular",
    "start": "1333059",
    "end": "1338160"
  },
  {
    "text": "instance and then finally we have a link to our pipeline's product so if we went",
    "start": "1338160",
    "end": "1344070"
  },
  {
    "start": "1343000",
    "end": "1428000"
  },
  {
    "text": "to Jupiter hub this is the spawner UI and this is our latest spawner UI which",
    "start": "1344070",
    "end": "1350190"
  },
  {
    "text": "will be available in our next release at the end of this month and a huge thanks to a ripto for investing and cleaning up",
    "start": "1350190",
    "end": "1355950"
  },
  {
    "text": "the UI and making it much prettier and so from here what what they can do is we provide a bunch of canned Jupiter images",
    "start": "1355950",
    "end": "1364169"
  },
  {
    "text": "docker images that have different libraries installed for different versions of tensorflow for CPU as well as GPUs so these this",
    "start": "1364169",
    "end": "1371970"
  },
  {
    "text": "makes it easy to get a notebook environment suitable out of the box but",
    "start": "1371970",
    "end": "1378330"
  },
  {
    "text": "you can also build your own custom environments just by building your own docker image and installing whatever libraries you want and then you can just",
    "start": "1378330",
    "end": "1384240"
  },
  {
    "text": "enter the URL of your document here and if you click on advanced we can scroll down and we can see a bunch of different",
    "start": "1384240",
    "end": "1390929"
  },
  {
    "text": "options to specify the resources we want to give to our notebook and so from here",
    "start": "1390929",
    "end": "1396000"
  },
  {
    "text": "we can specify CPU RAM or GPUs and also again thanks to ripto and our next",
    "start": "1396000",
    "end": "1401400"
  },
  {
    "text": "release will actually be able to attach persistent volume claims so you can add volumes for either reading with data or",
    "start": "1401400",
    "end": "1407340"
  },
  {
    "text": "writing data and from there you can actually go ahead and click spawn so the idea here is we're trying to make it",
    "start": "1407340",
    "end": "1413190"
  },
  {
    "text": "super easy for data scientists to get real get started running on kubernetes at the beginning of their workflow and",
    "start": "1413190",
    "end": "1418799"
  },
  {
    "text": "start taking advantage of it without having to climb that mountain of learning kubernetes and installing the",
    "start": "1418799",
    "end": "1424410"
  },
  {
    "text": "tool train like Cupido or case Anette or anything else so after that we can dump",
    "start": "1424410",
    "end": "1430650"
  },
  {
    "text": "them into a notebook and from here they can begin developing their notebook at their model and doing their data analysis just like they would normally",
    "start": "1430650",
    "end": "1436850"
  },
  {
    "text": "but one of the things we want to do is we want to give them the abandoned the ability to take advantage of kubernetes",
    "start": "1436850",
    "end": "1441860"
  },
  {
    "text": "so as we mentioned you know Hamill was MANET managing a lot of VMs to run the",
    "start": "1441860",
    "end": "1446970"
  },
  {
    "text": "different parts of his his workflow so after he prototyped his initial model he",
    "start": "1446970",
    "end": "1452730"
  },
  {
    "text": "would then want to run some long-running job to actually train that model overnight so this is a great way",
    "start": "1452730",
    "end": "1458710"
  },
  {
    "text": "opportunity to take advantage of kubernetes but one of the barriers is to go from a notebook to actually a job",
    "start": "1458710",
    "end": "1464740"
  },
  {
    "text": "runner in kubernetes it's a multi-step process so you have to convert that notebook to Python code",
    "start": "1464740",
    "end": "1470529"
  },
  {
    "text": "you then have to build the docker image you then have to build the yamo file to actually launch that resource on",
    "start": "1470529",
    "end": "1476380"
  },
  {
    "text": "kubernetes so if you're a kubernetes if you're familiar with kubernetes that may not seem like a whole lot but if you're",
    "start": "1476380",
    "end": "1482710"
  },
  {
    "text": "a data scientist you it's in you're new to kubernetes that's going to trip you up and that's going to become a barrier",
    "start": "1482710",
    "end": "1488320"
  },
  {
    "text": "so to solve that we were with our next release we're going to begin to have our initial release of fairing and fairing",
    "start": "1488320",
    "end": "1495070"
  },
  {
    "text": "is a Python library that's going to make it easy to go directly from your to paterno book to a resource running on",
    "start": "1495070",
    "end": "1500590"
  },
  {
    "text": "kubernetes right so here's how this works in our notebook we're just gonna",
    "start": "1500590",
    "end": "1505659"
  },
  {
    "text": "import the faring library it's a normal Python library and then in our next cell",
    "start": "1505659",
    "end": "1511120"
  },
  {
    "text": "we're basically going to define a couple of variables to configure the faring library and the most important one is",
    "start": "1511120",
    "end": "1517720"
  },
  {
    "text": "all we're just going to specify the registry where we want our docker images to be published down here we can",
    "start": "1517720",
    "end": "1525070"
  },
  {
    "text": "basically define our normal Python code for training our model so this is the tensorflow code for training amnesty so",
    "start": "1525070",
    "end": "1532899"
  },
  {
    "text": "this is what this example was a little bit new so we didn't have time to update it to use code search so it's using M",
    "start": "1532899",
    "end": "1538750"
  },
  {
    "text": "mist but the only changes we've made to this this this code is we've organized",
    "start": "1538750",
    "end": "1544419"
  },
  {
    "text": "it into a class and put it into a method name to training and the only way we reason we did that is so we have a way",
    "start": "1544419",
    "end": "1550750"
  },
  {
    "text": "of identifying which code to actually invoke in the notebook and then we added an annotation to this class that",
    "start": "1550750",
    "end": "1557320"
  },
  {
    "text": "specifies how we want to run it so here we just added this annotation that specifies the number of workers and the",
    "start": "1557320",
    "end": "1563860"
  },
  {
    "text": "number of parameter servers we want to run and then down here we instantiate",
    "start": "1563860",
    "end": "1569470"
  },
  {
    "text": "the class just like we would normally and then we invoke the Train method just like we would normally if we were",
    "start": "1569470",
    "end": "1574600"
  },
  {
    "text": "running the code inside our notebook but because of the fairing and the annotation we added what's actually",
    "start": "1574600",
    "end": "1580330"
  },
  {
    "text": "happening is under the hood we're going to convert this notebook to a Python file build the docker image and then",
    "start": "1580330",
    "end": "1587080"
  },
  {
    "text": "launch a kubernetes resource a tensorflow distributed training job which is our custom resource on kubernetes and then",
    "start": "1587080",
    "end": "1595080"
  },
  {
    "text": "down here we're just printing out the logs for convenience so here we're enabling our data scientists to get on",
    "start": "1595080",
    "end": "1601470"
  },
  {
    "text": "board with kubernetes without having to you know learn climb the mountain of learning kubernetes so the next step for",
    "start": "1601470",
    "end": "1610320"
  },
  {
    "start": "1608000",
    "end": "1768000"
  },
  {
    "text": "this particular example is we actually",
    "start": "1610320",
    "end": "1617870"
  },
  {
    "text": "pulled up so the way this solution is architected we actually have to build an",
    "start": "1617870",
    "end": "1623730"
  },
  {
    "text": "index that has the predictions for all of the code in github and the reason we have to build an index is because if we",
    "start": "1623730",
    "end": "1629910"
  },
  {
    "text": "tried to compute this online at serving time it would take way too long so we have to periodically build this index",
    "start": "1629910",
    "end": "1636840"
  },
  {
    "text": "and then push this into production so the way we do this is we're going to build a coop flow pipeline and this coop",
    "start": "1636840",
    "end": "1643080"
  },
  {
    "text": "flow pipeline is going to consist of three steps the first step is going to basically be running a data Philip job",
    "start": "1643080",
    "end": "1650130"
  },
  {
    "text": "or beam job that's going to compute the predictions for all of the code in github so there's about two hundred",
    "start": "1650130",
    "end": "1656910"
  },
  {
    "text": "several hundred million files in github which is about two several terabytes worth of data so if we didn't use an ETL",
    "start": "1656910",
    "end": "1663720"
  },
  {
    "text": "framework to like be more SPARC to scale",
    "start": "1663720",
    "end": "1669420"
  },
  {
    "text": "out the inference it would take a really long time so in this case it would take about three hundred and fifty CPU hours",
    "start": "1669420",
    "end": "1674670"
  },
  {
    "text": "but by taking advantage of an ETL framework we can scale out horizontally and we can run that in about an hour by",
    "start": "1674670",
    "end": "1681420"
  },
  {
    "text": "by take advantage of more machines the next step in the pipeline is we have to build an index which we can actually",
    "start": "1681420",
    "end": "1687600"
  },
  {
    "text": "serve in production and then once we've built that index we actually want to",
    "start": "1687600",
    "end": "1693390"
  },
  {
    "text": "push that index into production so that we get the latest model running in production and so what we do is we have",
    "start": "1693390",
    "end": "1700260"
  },
  {
    "text": "a a simple script that we're gonna run which is basically going to create a commit to our repository and it's going",
    "start": "1700260",
    "end": "1706170"
  },
  {
    "text": "to update the command line arguments of our server to point to the latest index",
    "start": "1706170",
    "end": "1711680"
  },
  {
    "text": "and one of the problems our DevOps challenges is you know code is constantly being uploaded to github so",
    "start": "1711680",
    "end": "1718860"
  },
  {
    "text": "if we don't compare eaat eclis recompute these this index and deploy it into production",
    "start": "1718860",
    "end": "1724950"
  },
  {
    "text": "predictions are going to get stale and the quality is going to go down so here we can take advantage of coop flow",
    "start": "1724950",
    "end": "1731010"
  },
  {
    "text": "pipelines to easily schedule a periodic run so if we click through if we click",
    "start": "1731010",
    "end": "1740639"
  },
  {
    "text": "through to our experiment from here we can through the UI we can click start",
    "start": "1740639",
    "end": "1745830"
  },
  {
    "text": "our recurring run so from here we basically just select the pipeline we",
    "start": "1745830",
    "end": "1751169"
  },
  {
    "text": "specify a name and down here we can specify the trigger schedule so we can either specify it you can run",
    "start": "1751169",
    "end": "1756630"
  },
  {
    "text": "periodically or we can run on like a cron schedule and then if we go back to the UI we can see all the different runs",
    "start": "1756630",
    "end": "1764100"
  },
  {
    "text": "that we have so it's running every six hours and pushing out that commit then to actually roll out that commit we rely",
    "start": "1764100",
    "end": "1770789"
  },
  {
    "start": "1768000",
    "end": "1848000"
  },
  {
    "text": "on our go CD so this is this is the UI for our go CD so you can basically see",
    "start": "1770789",
    "end": "1777299"
  },
  {
    "text": "from here that it's showing all the infrastructure we have deployed so we have basically two different servers and",
    "start": "1777299",
    "end": "1783960"
  },
  {
    "text": "it's showing that it's actually been synchronized with what's in the git repository so down here what we're",
    "start": "1783960",
    "end": "1790260"
  },
  {
    "text": "showing through the UI is we're seeing a diff between what's actually deployed in for in production and the manifest",
    "start": "1790260",
    "end": "1796409"
  },
  {
    "text": "that's this checked in to get the git repository so in this case everything is",
    "start": "1796409",
    "end": "1801470"
  },
  {
    "text": "synchronized and up-to-date so there's",
    "start": "1801470",
    "end": "1806700"
  },
  {
    "text": "no diff and so that's how we can continually push out our our model into",
    "start": "1806700",
    "end": "1811919"
  },
  {
    "text": "production right so we've spent a lot of time walking through a bunch of different steps you know and going",
    "start": "1811919",
    "end": "1820230"
  },
  {
    "text": "through a bunch of different infrastructure but what we didn't talk about was you know the model or show any complicated math or algorithms right and",
    "start": "1820230",
    "end": "1828539"
  },
  {
    "text": "that's because most of the time and energy ends up getting spent on all the infrastructure that you have to build to",
    "start": "1828539",
    "end": "1834779"
  },
  {
    "text": "keep your models up-to-date and so with that I'm going to hand it back to Hamill for some some concluding remarks",
    "start": "1834779",
    "end": "1842659"
  },
  {
    "text": "thanks Jeremy I just want to kind of conclude really fast to leave enough",
    "start": "1848790",
    "end": "1854070"
  },
  {
    "text": "time for questions but just want to again repeat the point that and this is",
    "start": "1854070",
    "end": "1859710"
  },
  {
    "text": "for especially any folks from the data science industry or data side specialty watching or machine learning managers",
    "start": "1859710",
    "end": "1866730"
  },
  {
    "text": "but you know if if you're struggling to get value out of machine learning and you already have a data scientist then I",
    "start": "1866730",
    "end": "1875570"
  },
  {
    "text": "would challenge you know I would argue that you probably don't need another data scientists what you probably need",
    "start": "1875570",
    "end": "1881490"
  },
  {
    "text": "is infrastructure help invest in tooling and things like that because of the gap",
    "start": "1881490",
    "end": "1889980"
  },
  {
    "text": "between the perception and reality that I discussed earlier this pyramid right here is Monica or goddess higher data",
    "start": "1889980",
    "end": "1896700"
  },
  {
    "text": "science hierarchy of needs widely used in data science circles as a talking",
    "start": "1896700",
    "end": "1904590"
  },
  {
    "text": "point of how there's a hierarchy of needs and you know at the bottom layer",
    "start": "1904590",
    "end": "1912060"
  },
  {
    "text": "you have instrumentation logging collecting data then you have you know pipelines ETL cleaning your data and",
    "start": "1912060",
    "end": "1919080"
  },
  {
    "text": "it's only when you get to the top of the pyramid you know so I would say the firt",
    "start": "1919080",
    "end": "1924600"
  },
  {
    "text": "the last three layers of what you would typically maybe consider data science and at the very top is AI deep learning",
    "start": "1924600",
    "end": "1933000"
  },
  {
    "text": "machine learning and it's it for some reason this the way that people invest",
    "start": "1933000",
    "end": "1940140"
  },
  {
    "text": "in machine learning they invert this pyramid which is amazing and that's why",
    "start": "1940140",
    "end": "1948120"
  },
  {
    "text": "I think goo flow is a really good tool that would help Assad some of these",
    "start": "1948120",
    "end": "1954990"
  },
  {
    "text": "problems in the industry and I think the folks that learn this infrastructure are",
    "start": "1954990",
    "end": "1960360"
  },
  {
    "text": "actually going to be some of the most valuable people and you know the machine",
    "start": "1960360",
    "end": "1965700"
  },
  {
    "text": "learning workflow so I'll leave it open to questions yeah and just briefly there was a bunch",
    "start": "1965700",
    "end": "1972960"
  },
  {
    "start": "1968000",
    "end": "2139000"
  },
  {
    "text": "of different people that helped out with this demo and putting everything together we just wanted to give them a huge thank you then there's a bunch of",
    "start": "1972960",
    "end": "1979260"
  },
  {
    "text": "different talks and booths for related to cube though so if curiouser have time definitely check",
    "start": "1979260",
    "end": "1984410"
  },
  {
    "text": "them out thank you very much do we have",
    "start": "1984410",
    "end": "1996530"
  },
  {
    "text": "time for questions two minutes go ahead",
    "start": "1996530",
    "end": "2003120"
  },
  {
    "text": "yes it's called fairing so if you can find under coupe flow slash bearing yeah",
    "start": "2008240",
    "end": "2016420"
  },
  {
    "text": "and and the two authors are right there you guys and you can bother them it's me",
    "start": "2016420",
    "end": "2022450"
  },
  {
    "text": "Matt on my team and then William at Microsoft",
    "start": "2022450",
    "end": "2027160"
  },
  {
    "text": "so the question was how does fairing compared to tender for serving and",
    "start": "2035549",
    "end": "2041200"
  },
  {
    "text": "deployment so they're complementary so the point of fairing is to make it",
    "start": "2041200",
    "end": "2046660"
  },
  {
    "text": "possible to go from your code being in a docker image to you know sorry from",
    "start": "2046660",
    "end": "2051790"
  },
  {
    "text": "being in a notebook to a docker image then once you have that docker image you can deploy that let's say with Selden if",
    "start": "2051790",
    "end": "2057970"
  },
  {
    "text": "you wanted to have like a graph of micro-services so that would be so Sheldon would be the type of kubernetes resource you might create with fairing",
    "start": "2057970",
    "end": "2064570"
  },
  {
    "text": "as opposed for if you were doing the model deployment as opposed to training",
    "start": "2064570",
    "end": "2069540"
  },
  {
    "text": "do you want to explain how the model works I didn't hear the question so",
    "start": "2092100",
    "end": "2097260"
  },
  {
    "text": "sorry",
    "start": "2097260",
    "end": "2099560"
  },
  {
    "text": "okay so the question is about what kind of inference we're using batch versus real-time difference for code search so",
    "start": "2108390",
    "end": "2114690"
  },
  {
    "text": "on the demo website because it's only a demo website right now it's not on github.com we pre compute the",
    "start": "2114690",
    "end": "2121079"
  },
  {
    "text": "representations of code and then in real-time we compute the representation",
    "start": "2121079",
    "end": "2126839"
  },
  {
    "text": "of your query so you can argue do it we're doing a batch and real-time",
    "start": "2126839",
    "end": "2132180"
  },
  {
    "text": "inference and in some degree yeah all right I think that's it so thank you",
    "start": "2132180",
    "end": "2137489"
  },
  {
    "text": "very much",
    "start": "2137489",
    "end": "2139730"
  }
]
[
  {
    "text": "right uh should we get started sound good uh all right i just want to",
    "start": "10480",
    "end": "16240"
  },
  {
    "text": "start by saying how tremendously excited i am to be back speaking at in person conferences again it's great to see all",
    "start": "16240",
    "end": "22240"
  },
  {
    "text": "of your smiling faces hopefully under masks please but today we're gonna have a bit of fun",
    "start": "22240",
    "end": "28160"
  },
  {
    "text": "talking about the strange scary world of monitoring serverless applications",
    "start": "28160",
    "end": "34559"
  },
  {
    "text": "is that going to let me change slide oh no technology yeah",
    "start": "34800",
    "end": "40559"
  },
  {
    "text": "yeah it works uh for a bit of a quick introduction uh for those of you who haven't",
    "start": "40559",
    "end": "46079"
  },
  {
    "text": "met me yet my name is khan douche i have been doing this observability thing for arguably far too long uh i started out",
    "start": "46079",
    "end": "53520"
  },
  {
    "text": "in like physical control systems before realizing that spoiler physics kind of sucks and the",
    "start": "53520",
    "end": "59760"
  },
  {
    "text": "less you have to deal with that the better but i now tech lead our amazing observability platform team at",
    "start": "59760",
    "end": "65840"
  },
  {
    "text": "cloudflare we build the tools that cloudflare engineers use to",
    "start": "65840",
    "end": "71600"
  },
  {
    "text": "monitor and debug cloudflare and today i'm going to take you on a bit of",
    "start": "71600",
    "end": "76640"
  },
  {
    "text": "a journey through cloudflare's evolution into the serverless space because it's kind of interesting right over the",
    "start": "76640",
    "end": "82720"
  },
  {
    "text": "last 10 years or so we've seen this like slow transition into serverless applications and",
    "start": "82720",
    "end": "89680"
  },
  {
    "text": "at least from an open source observability standpoint it really feels like we haven't been able to keep up",
    "start": "89680",
    "end": "96159"
  },
  {
    "text": "i don't know whether that's the vendor lock-in that's inherent with serverless platforms or what but",
    "start": "96159",
    "end": "102159"
  },
  {
    "text": "i'll be honest i'm getting old part of me just wants to you know shake my fist in the sky and say",
    "start": "102159",
    "end": "108880"
  },
  {
    "text": "hey let the young folk deal with it but i mean the more i'm forced to deal with",
    "start": "108880",
    "end": "115280"
  },
  {
    "text": "serverless functions the more i've learned to love them because you know i have been forced to use them",
    "start": "115280",
    "end": "120880"
  },
  {
    "text": "as i'd imagine at least some of you have and they're great they solve quite a few",
    "start": "120880",
    "end": "127200"
  },
  {
    "text": "issues that our standard servered applications have they get",
    "start": "127200",
    "end": "132239"
  },
  {
    "text": "things like scaling for free they get things like uh sort of microservice architectures",
    "start": "132239",
    "end": "138239"
  },
  {
    "text": "really really easily so what we really need to do is update our operational models",
    "start": "138239",
    "end": "144239"
  },
  {
    "text": "to deal with them right",
    "start": "144239",
    "end": "147120"
  },
  {
    "text": "and that brings me to cloudflare workers uh this isn't a sales pitch i just want to give a bit of flavor to our experience",
    "start": "149280",
    "end": "155040"
  },
  {
    "text": "but back in 2017 or so cloudflare invented its own serverless platform you",
    "start": "155040",
    "end": "160640"
  },
  {
    "text": "know as you do and the annoying thing happened because",
    "start": "160640",
    "end": "165920"
  },
  {
    "text": "when you invent something the absolute worst thing that can possibly happen to you is that people start using it and",
    "start": "165920",
    "end": "173120"
  },
  {
    "text": "as an observability team we blinked and you know in that blink",
    "start": "173120",
    "end": "179599"
  },
  {
    "text": "we had a bit of a problem because we had this weird cambrian explosion of serverless",
    "start": "179599",
    "end": "184800"
  },
  {
    "text": "applications at cloudflare in that blink 10 20 30 different serverless applications we're suddenly built on top",
    "start": "184800",
    "end": "191840"
  },
  {
    "text": "of cloudflare workers and despite the circular dependency this was a bit of a",
    "start": "191840",
    "end": "196879"
  },
  {
    "text": "problem and i'll be the first to admit we fumbled the ball on that one we hadn't",
    "start": "196879",
    "end": "203599"
  },
  {
    "text": "really sort of offered any sort of solution to these teams and this led to a whole bunch of",
    "start": "203599",
    "end": "210959"
  },
  {
    "text": "interesting solutions that we'll get into later really it became clear very very quickly",
    "start": "210959",
    "end": "217440"
  },
  {
    "text": "that we needed to offer some sort of solution to this some sort of actual offering to bring",
    "start": "217440",
    "end": "224239"
  },
  {
    "text": "serverless functions sort of back into the fold of well-supported architectures",
    "start": "224239",
    "end": "230159"
  },
  {
    "text": "it just wasn't very clear how to do that and",
    "start": "230159",
    "end": "235920"
  },
  {
    "text": "there's a lot to talk about there from metrics to logs to traces and everything in between but",
    "start": "235920",
    "end": "243760"
  },
  {
    "text": "let's talk about time series today because we don't have that much time and i think we'll all agree that",
    "start": "243760",
    "end": "250000"
  },
  {
    "text": "the sort of de facto standard for collecting and storing time series these days is prometheus right it's sort of a",
    "start": "250000",
    "end": "256959"
  },
  {
    "text": "lingua franca everything uses remote right everything uses text exposition and",
    "start": "256959",
    "end": "262160"
  },
  {
    "text": "i know we have a few prometheus maintainers in the audience today so at least from me thank you because you make",
    "start": "262160",
    "end": "269120"
  },
  {
    "text": "my life a hell of a lot easier but if we're being honest prometheus makes a",
    "start": "269120",
    "end": "274400"
  },
  {
    "text": "few assumptions it has a bit of a downside right and apologies for the image it's really hard",
    "start": "274400",
    "end": "280080"
  },
  {
    "text": "to find like safe for work old greek art i don't know why but um prometheus has a",
    "start": "280080",
    "end": "287759"
  },
  {
    "text": "bit of a downside right it has a dark side it makes a few assumptions that are very innovative",
    "start": "287759",
    "end": "293840"
  },
  {
    "text": "at least for the time and if we're being honest they sort of force you into a particular architecture",
    "start": "293840",
    "end": "300320"
  },
  {
    "text": "prometheus at a high level assumes a few things it assumes that your system lives long enough to be",
    "start": "300320",
    "end": "307280"
  },
  {
    "text": "discovered and scraped it assumes that your service is sort of network enabled and it can expose things over the",
    "start": "307280",
    "end": "313360"
  },
  {
    "text": "network and it assumes that you can do your own aggregation and",
    "start": "313360",
    "end": "318800"
  },
  {
    "text": "let's break those down a bit because they're perhaps not obvious prometheus firstly",
    "start": "318800",
    "end": "324560"
  },
  {
    "text": "requires that your system lives long enough right uh excuse me",
    "start": "324560",
    "end": "331918"
  },
  {
    "text": "prometheus rather inevitably i think uses a pull-based model for metrics collection",
    "start": "334880",
    "end": "339919"
  },
  {
    "text": "right for those who haven't seen that in action the general idea is that instead of",
    "start": "339919",
    "end": "346400"
  },
  {
    "text": "instead of your service sort of actively pushing metrics out to some sort of collector",
    "start": "346400",
    "end": "351440"
  },
  {
    "text": "prometheus will discover where your service is reach out to it and pull metrics back and this is kind of cool",
    "start": "351440",
    "end": "358479"
  },
  {
    "text": "right because it gives us a bunch of things for free we get things like health monitoring because if we can't",
    "start": "358479",
    "end": "364000"
  },
  {
    "text": "pull your metrics well maybe your service is down we get things like capacity control because we can decide",
    "start": "364000",
    "end": "370400"
  },
  {
    "text": "how often to pull metrics and how many of them to pull we get things like easy testing because",
    "start": "370400",
    "end": "376880"
  },
  {
    "text": "we don't have to mock out collection endpoints but prometheus isn't always scraping",
    "start": "376880",
    "end": "383120"
  },
  {
    "text": "right it's scraping every five ten fifteen seconds whatever which means that in reality your service",
    "start": "383120",
    "end": "390240"
  },
  {
    "text": "has to live for at least five 15 seconds which",
    "start": "390240",
    "end": "396160"
  },
  {
    "text": "may or may not be the case at the same time and this sort of goes hand in hand with the last one",
    "start": "396160",
    "end": "401840"
  },
  {
    "text": "prometheus assumes that you can expose things over the network and again maybe the case maybe not because",
    "start": "401840",
    "end": "408880"
  },
  {
    "text": "in practice this requires you to be able to listen on a port it requires you to be able to spin up a server",
    "start": "408880",
    "end": "415599"
  },
  {
    "text": "if you want to secure the communication you need to have firewall rules you need to have tls certificates maybe client",
    "start": "415599",
    "end": "421440"
  },
  {
    "text": "certificates so again it sort of gets a bit messy in the weeds",
    "start": "421440",
    "end": "426800"
  },
  {
    "text": "and finally prometheus assumes that you can do your own aggregation and",
    "start": "426800",
    "end": "432560"
  },
  {
    "text": "this is a bit opaque so it's easier to sort of represent it with a bit of a counter example",
    "start": "432560",
    "end": "437840"
  },
  {
    "text": "if we imagine say a service that only ever processes one request",
    "start": "437840",
    "end": "443280"
  },
  {
    "text": "and some hypothetical service we can ignore the previous two requirements for now we say somehow prometheus gets our",
    "start": "443280",
    "end": "450400"
  },
  {
    "text": "metrics but our service processes run requests so what would a request count metric",
    "start": "450400",
    "end": "456160"
  },
  {
    "text": "look like in that case well um our service process is one request right",
    "start": "456160",
    "end": "462160"
  },
  {
    "text": "the request count is a one so we push a one to prometheus and if we get a second request while we start another service",
    "start": "462160",
    "end": "469199"
  },
  {
    "text": "and it pushes a one to prometheus and well this is a bit of a problem right because from prometheus's point of view",
    "start": "469199",
    "end": "475840"
  },
  {
    "text": "well that metric jumps to a one and then never never goes anywhere so we can't",
    "start": "475840",
    "end": "482160"
  },
  {
    "text": "accurately represent things like request counts in this standard setup",
    "start": "482160",
    "end": "487440"
  },
  {
    "text": "we could maybe do some magic if we explode our cardinalities and do recording rules or something like that",
    "start": "487440",
    "end": "494240"
  },
  {
    "text": "but in practice we probably want to do that we need our service to be able to do",
    "start": "494240",
    "end": "499840"
  },
  {
    "text": "some level of aggregation so let's summarize those a bit",
    "start": "499840",
    "end": "505120"
  },
  {
    "text": "with those requirements prometheus is very well suited to a particular model of architecture right a service that is",
    "start": "505120",
    "end": "511919"
  },
  {
    "text": "long running a service that is network enabled a service that is able to do multiple things in every sense of the",
    "start": "511919",
    "end": "518159"
  },
  {
    "text": "word a traditional servered application so let's consider our serverless example",
    "start": "518159",
    "end": "525200"
  },
  {
    "text": "well our serverless functions live for hundreds of milliseconds maybe seconds",
    "start": "525200",
    "end": "530720"
  },
  {
    "text": "at worst our serverless functions aren't really network enabled in the traditional sense",
    "start": "530720",
    "end": "536080"
  },
  {
    "text": "they can't listen on a port they can't spin up a server and even if they could that would sort of be antithetical to",
    "start": "536080",
    "end": "542480"
  },
  {
    "text": "the whole idea of serverless in the first place and they only have a process one request",
    "start": "542480",
    "end": "548320"
  },
  {
    "text": "so in all three ways our serverless functions don't hold up",
    "start": "548320",
    "end": "554160"
  },
  {
    "text": "these assumptions and when we were first sort of investigating",
    "start": "554160",
    "end": "559600"
  },
  {
    "text": "these problems these were the issues we we encountered",
    "start": "559600",
    "end": "565440"
  },
  {
    "text": "so what can we do right we're engineers we look for solutions and so we can look",
    "start": "565440",
    "end": "570560"
  },
  {
    "text": "at prior art serverless functions have been around for what 10 years nearly at this point so",
    "start": "570560",
    "end": "577440"
  },
  {
    "text": "this problem must be solved already for us and first week first thing we can look at is",
    "start": "577440",
    "end": "582560"
  },
  {
    "text": "the push gateway don't roll your eyes over there the push gateway for those of you who",
    "start": "582560",
    "end": "587920"
  },
  {
    "text": "haven't seen it effectively functions as a long-lived proxy for metrics the idea is that you can http post",
    "start": "587920",
    "end": "596560"
  },
  {
    "text": "a text exposition and the push gateway will handle all of the difficult parts of those",
    "start": "596560",
    "end": "603360"
  },
  {
    "text": "first two requirements listening on the network living long enough to be discovered and scraped so we only need",
    "start": "603360",
    "end": "609920"
  },
  {
    "text": "to be able to push something and it works and how the push gateway sort of functions",
    "start": "609920",
    "end": "615680"
  },
  {
    "text": "and what makes it interesting is how it handles sort of repeated pushes that is",
    "start": "615680",
    "end": "621600"
  },
  {
    "text": "pushing the same metric twice for example and this goes back to our request count example if we push that",
    "start": "621600",
    "end": "628720"
  },
  {
    "text": "request count with a one and then we push it with another one well the push gateway replaces those those old values",
    "start": "628720",
    "end": "635120"
  },
  {
    "text": "so we still get this repeating one problem at the same time in the same upstream",
    "start": "635120",
    "end": "641360"
  },
  {
    "text": "documentation well we can find the aggregation gateway by our friends at weaveworks and",
    "start": "641360",
    "end": "647200"
  },
  {
    "text": "the aggregation gateway is very very similar it functions as a push gateway except",
    "start": "647200",
    "end": "653120"
  },
  {
    "text": "in the case of this repeated metrics issue right if we push a one and then",
    "start": "653120",
    "end": "658160"
  },
  {
    "text": "another one well the aggregation gateway perhaps obviously aggregates them right",
    "start": "658160",
    "end": "663279"
  },
  {
    "text": "and secret by aggregate we mean some we're just being fancy",
    "start": "663279",
    "end": "668640"
  },
  {
    "text": "but ostensibly this solves all our problems right we can listen on a port we can just sort of use",
    "start": "668640",
    "end": "675519"
  },
  {
    "text": "these push gateway semantics but we can aggregate our values we can do request counts ostensibly we're done",
    "start": "675519",
    "end": "682240"
  },
  {
    "text": "right well maybe maybe not because at this point we decided to go on a bit",
    "start": "682240",
    "end": "689839"
  },
  {
    "text": "of a survey through our engineering teams because engineering teams at cloudflare they're",
    "start": "689839",
    "end": "695600"
  },
  {
    "text": "not dumb right they're not pushing things to production without monitoring so they must be doing it somehow and we",
    "start": "695600",
    "end": "702640"
  },
  {
    "text": "wanted to work out how they were doing it whether or not there was a consensus in",
    "start": "702640",
    "end": "708000"
  },
  {
    "text": "sort of what was the best solution out there at the same time we wanted to know what they were doing like what sort of",
    "start": "708000",
    "end": "714560"
  },
  {
    "text": "metrics because each of these solutions has a different set of trade-offs",
    "start": "714560",
    "end": "721040"
  },
  {
    "text": "and i'll be honest what we found was a bit of a mess this is not trying to disparage any cloud flow engineers they",
    "start": "721040",
    "end": "727519"
  },
  {
    "text": "were doing what was necessary but there was really no consensus around",
    "start": "727519",
    "end": "734240"
  },
  {
    "text": "what was the solution to this problem we had push gateway setups",
    "start": "734240",
    "end": "739920"
  },
  {
    "text": "and teams weren't using counters we had aggregation gateway setups where teams were weren't using gauges",
    "start": "739920",
    "end": "746959"
  },
  {
    "text": "we had one team that had built this weird frankensteinian monster of a binary that sort of combined the two",
    "start": "746959",
    "end": "754320"
  },
  {
    "text": "into one and sort of had weird routing logic to route different metrics to different",
    "start": "754320",
    "end": "760720"
  },
  {
    "text": "gateways that was actually very interesting we had metrics that were being like tromboned",
    "start": "760720",
    "end": "767360"
  },
  {
    "text": "back through internal ui pipelines we had teams that built sort of custom",
    "start": "767360",
    "end": "772399"
  },
  {
    "text": "logic on top of sentry to pull time series metrics there was really no consensus about",
    "start": "772399",
    "end": "779600"
  },
  {
    "text": "where we could go at the same time we wanted to know what sort of metrics",
    "start": "779600",
    "end": "785040"
  },
  {
    "text": "people were pushing right how were they dealing with these trade-offs and perhaps most obviously teams needed",
    "start": "785040",
    "end": "791360"
  },
  {
    "text": "counters counters are very boring the general idea is right we have a bunch of metrics",
    "start": "791360",
    "end": "797600"
  },
  {
    "text": "that we can sum up together to produce a final value nothing",
    "start": "797600",
    "end": "802880"
  },
  {
    "text": "too interesting their counters are counters",
    "start": "802880",
    "end": "807760"
  },
  {
    "text": "at the same time teams need gauges and gauges are more interesting because",
    "start": "809120",
    "end": "815600"
  },
  {
    "text": "gauges well if we're say processing a thousand requests and we're just replacing gauge",
    "start": "815600",
    "end": "821279"
  },
  {
    "text": "values we're dropping 999 of those so is that useful maybe not and this is",
    "start": "821279",
    "end": "828240"
  },
  {
    "text": "where i want to revisit that frankensteinian binary from before because that team was actually doing",
    "start": "828240",
    "end": "833760"
  },
  {
    "text": "some really interesting stuff like taking aggregates over different gauge values as they came in to sort of capture these",
    "start": "833760",
    "end": "840839"
  },
  {
    "text": "changes we'll get back to that in a second but that was actually quite interesting",
    "start": "840839",
    "end": "846160"
  },
  {
    "text": "at the same time teams needed histograms again perhaps unsurprisingly and",
    "start": "846160",
    "end": "851680"
  },
  {
    "text": "as much as we didn't want to have to deal with the cardinality of histograms they were there and i suppose they're",
    "start": "851680",
    "end": "858000"
  },
  {
    "text": "useful but histograms ostensibly are just counters",
    "start": "858000",
    "end": "863920"
  },
  {
    "text": "on steroids right we're summing up all the individual buckets into a final value but",
    "start": "863920",
    "end": "870959"
  },
  {
    "text": "beneath the surface there is some level of complication there what happens if we",
    "start": "870959",
    "end": "876720"
  },
  {
    "text": "get a push with different sets of buckets how do we sort of merge those together how do we even",
    "start": "876720",
    "end": "882720"
  },
  {
    "text": "merge a summary right does that even make sense to do i don't know you tell me but",
    "start": "882720",
    "end": "889920"
  },
  {
    "text": "we had histograms and finally and perhaps most interestingly we had infometrics and",
    "start": "889920",
    "end": "896560"
  },
  {
    "text": "if you've ever orchestrated anything with say client golang you've probably seen an infometric",
    "start": "896560",
    "end": "902079"
  },
  {
    "text": "what makes them very interesting is the fact that their behavior is",
    "start": "902079",
    "end": "908079"
  },
  {
    "text": "not not obvious infometrics for those who haven't seen them generally the idea is you have some",
    "start": "908079",
    "end": "914959"
  },
  {
    "text": "sort of static label set baked into your binary and",
    "start": "914959",
    "end": "920560"
  },
  {
    "text": "your binary will expose that as a gauge with a value of one",
    "start": "920560",
    "end": "925680"
  },
  {
    "text": "that's not too interesting but what into what is interesting is how those behave over time because",
    "start": "925680",
    "end": "932560"
  },
  {
    "text": "when we deploy a new version with a new static label set well the old version shuts down that label set finishes and",
    "start": "932560",
    "end": "940240"
  },
  {
    "text": "the new one comes up and it's interesting because that is not implicit in the fact that it's a gauge",
    "start": "940240",
    "end": "946480"
  },
  {
    "text": "that is purely sort of borne out of how the application handles these metrics",
    "start": "946480",
    "end": "953199"
  },
  {
    "text": "over time so where does that leave us let's take these new requirements and",
    "start": "953199",
    "end": "959360"
  },
  {
    "text": "revisit our upstream solutions well the push gateway",
    "start": "959360",
    "end": "964800"
  },
  {
    "text": "maybe that works maybe it doesn't in fact if you read the documentation",
    "start": "964800",
    "end": "970160"
  },
  {
    "text": "who does that not me who has time if you read the documentation well",
    "start": "970160",
    "end": "976240"
  },
  {
    "text": "the push gateway is sort of out anyway it very clearly states that hey probably",
    "start": "976240",
    "end": "981839"
  },
  {
    "text": "don't use this for serverless things yeah oh well we can sort of abandon that one that's",
    "start": "981839",
    "end": "988320"
  },
  {
    "text": "sad promises so many things at the same time we have the aggravation",
    "start": "988320",
    "end": "994000"
  },
  {
    "text": "gateway and the aggregation gateway gets us sort of closer maybe",
    "start": "994000",
    "end": "1000160"
  },
  {
    "text": "it gives us different trade-offs for you we can represent counters but the way the aggregation gateway handles gauges",
    "start": "1000160",
    "end": "1006639"
  },
  {
    "text": "is slightly weird and we we still can't get our info metrics out of it which is",
    "start": "1006639",
    "end": "1012880"
  },
  {
    "text": "what we really wanted to do because the aggregation gateway works only on types right so",
    "start": "1012880",
    "end": "1019120"
  },
  {
    "text": "a metric type has a behavior maybe that works maybe it doesn't",
    "start": "1019120",
    "end": "1025600"
  },
  {
    "text": "at the same time we were investigating event-based solutions right as an industry we're",
    "start": "1025600",
    "end": "1031839"
  },
  {
    "text": "moving more towards these sort of high dimensionality high cardinality events",
    "start": "1031839",
    "end": "1037280"
  },
  {
    "text": "maybe we could do something there and we decided against these things for",
    "start": "1037280",
    "end": "1043520"
  },
  {
    "text": "two reasons mostly a at least at the time",
    "start": "1043520",
    "end": "1048720"
  },
  {
    "text": "they were rather immature and we didn't really want to put something that experimental into production and b",
    "start": "1048720",
    "end": "1056480"
  },
  {
    "text": "we didn't really want to fracture our environment too much because",
    "start": "1056480",
    "end": "1062160"
  },
  {
    "text": "as an internal platform team you really have to focus on your developer experience and",
    "start": "1062160",
    "end": "1068400"
  },
  {
    "text": "having two separate systems one for serverless architectures and one for",
    "start": "1068400",
    "end": "1073440"
  },
  {
    "text": "more standard architectures didn't really sit well with us we wanted to sort of have a consistent experience",
    "start": "1073440",
    "end": "1081840"
  },
  {
    "text": "throughout the whole stack so where does that leave us right because",
    "start": "1081840",
    "end": "1088480"
  },
  {
    "text": "all of these upstream solutions sort of seem out of the window so it became pretty clear pretty quickly",
    "start": "1088480",
    "end": "1095200"
  },
  {
    "text": "that we were gonna need to build something ourselves as annoying as that is because",
    "start": "1095200",
    "end": "1101919"
  },
  {
    "text": "we had a couple of requirements we wanted to maintain compatibility with",
    "start": "1101919",
    "end": "1107520"
  },
  {
    "text": "all of the existing sort of client libraries and client orchestration and at the same time we wanted to",
    "start": "1107520",
    "end": "1114000"
  },
  {
    "text": "represent all of these different semantics that we had summing counters replacing gauges but",
    "start": "1114000",
    "end": "1119760"
  },
  {
    "text": "also infometrics and again these these statistical functions over incoming",
    "start": "1119760",
    "end": "1125039"
  },
  {
    "text": "gauge values so it was pretty clear we were going to have to do something ourselves and",
    "start": "1125039",
    "end": "1131120"
  },
  {
    "text": "that's what we did we called it the gravel gateway the code is there it's in rust so buyer beware on that point",
    "start": "1131120",
    "end": "1138000"
  },
  {
    "text": "uh the main thing i want to mention because it'll make my family proud is that",
    "start": "1138000",
    "end": "1144799"
  },
  {
    "text": "this is a mining pun i come from a mining family i think this is funny in mining we have things called aggregates",
    "start": "1144799",
    "end": "1151760"
  },
  {
    "text": "like sand gravel and things i think this is funny literally no one else does so",
    "start": "1151760",
    "end": "1157120"
  },
  {
    "text": "if i could have a pity laugh so i don't cry myself to sleep tonight that would be appreciated",
    "start": "1157120",
    "end": "1163640"
  },
  {
    "text": "thank you i appreciate it as i say code is there go have a look",
    "start": "1164480",
    "end": "1170640"
  },
  {
    "text": "buy everywhere with the rust stuff some functional requirements we had when",
    "start": "1170640",
    "end": "1175679"
  },
  {
    "text": "we were building this we wanted to maintain compatibility with the existing client libraries right if",
    "start": "1175679",
    "end": "1182320"
  },
  {
    "text": "we're already building something bespoke internally we want to do that as little as possible",
    "start": "1182320",
    "end": "1187360"
  },
  {
    "text": "because training new engineers to use new internal things",
    "start": "1187360",
    "end": "1192640"
  },
  {
    "text": "it's just an extra burden that teams don't want at the same time we needed to aggregate",
    "start": "1192640",
    "end": "1198160"
  },
  {
    "text": "like the aggregation gateway but we needed to support way more different types of aggregations",
    "start": "1198160",
    "end": "1204960"
  },
  {
    "text": "all of these things we'd identified and therein lies a bit of a problem right because",
    "start": "1204960",
    "end": "1210559"
  },
  {
    "text": "here's two metrics ah fancy two gauges ostensibly right we have",
    "start": "1210559",
    "end": "1217679"
  },
  {
    "text": "a build info gauge and we have a go threads gauge i remember this slide",
    "start": "1217679",
    "end": "1225840"
  },
  {
    "text": "and ostensibly these are very boring metrics they're two gauges but",
    "start": "1225840",
    "end": "1231039"
  },
  {
    "text": "there is some sort of implied behavior in how our applications handle them over time the second one there standard gauge",
    "start": "1231039",
    "end": "1238559"
  },
  {
    "text": "goes up and down the first one is an infometric and there's nothing inherent in that text exposition that",
    "start": "1238559",
    "end": "1246320"
  },
  {
    "text": "says it's an infometric outside of the metric name but we'll ignore that um",
    "start": "1246320",
    "end": "1252000"
  },
  {
    "text": "this is the problem right because how the application handles these over",
    "start": "1252000",
    "end": "1258080"
  },
  {
    "text": "time is sort of the defining factor in these metrics and in our serverless example well",
    "start": "1258080",
    "end": "1265760"
  },
  {
    "text": "we don't have an overtime we get one shot so we need some way to communicate to",
    "start": "1265760",
    "end": "1273280"
  },
  {
    "text": "something external like our gateway how these metrics are supposed to behave over time",
    "start": "1273280",
    "end": "1280400"
  },
  {
    "text": "and there's really only a few controllable fields we have if we want",
    "start": "1280400",
    "end": "1286080"
  },
  {
    "text": "to sort of maintain all of the text exposition things we",
    "start": "1286080",
    "end": "1291760"
  },
  {
    "text": "have the type but that's a very fixed sort of set of things we have the",
    "start": "1291760",
    "end": "1298240"
  },
  {
    "text": "help text sort of maybe we have the metric name and we have the",
    "start": "1298240",
    "end": "1304240"
  },
  {
    "text": "label set and any one of those last three would have kind of worked but",
    "start": "1304240",
    "end": "1310880"
  },
  {
    "text": "ultimately we decided on smuggling some semantic information into the labels and",
    "start": "1310880",
    "end": "1316960"
  },
  {
    "text": "you know that's what we did we have the clear mode label in our gateway clear mode label allows",
    "start": "1316960",
    "end": "1324240"
  },
  {
    "text": "communication with the gateway as to those overtime semantics",
    "start": "1324240",
    "end": "1329440"
  },
  {
    "text": "for example we have a clear mode info that represents these sort of info semantics",
    "start": "1329440",
    "end": "1334880"
  },
  {
    "text": "every type has a default clear mode so we sum counters we replace gauges that",
    "start": "1334880",
    "end": "1340559"
  },
  {
    "text": "sort of thing but being able to specify it more directly allows that sort of direct control it",
    "start": "1340559",
    "end": "1346960"
  },
  {
    "text": "allows us to bring serverless functions up to the almost level the same level of",
    "start": "1346960",
    "end": "1353200"
  },
  {
    "text": "monitoring as as our more traditional servered applications for example if we want to sum counters",
    "start": "1353200",
    "end": "1360960"
  },
  {
    "text": "again that's the default behavior but if we want to be a bit explicit for the sake of demonstration well",
    "start": "1360960",
    "end": "1367200"
  },
  {
    "text": "we can use the clear mode sum and if we push a one and a one we get a two basic math",
    "start": "1367200",
    "end": "1372559"
  },
  {
    "text": "hopefully everyone can follow along with that the main interesting idea is that we do",
    "start": "1372559",
    "end": "1377760"
  },
  {
    "text": "strip out the clear mode when we re-expose these metrics to prometheus",
    "start": "1377760",
    "end": "1382799"
  },
  {
    "text": "that allows us to be that allows us to make this whole process entirely transparent from the",
    "start": "1382799",
    "end": "1388320"
  },
  {
    "text": "prometheus end right there's no way of telling if you're looking at the metrics in prometheus whether a serverless",
    "start": "1388320",
    "end": "1394880"
  },
  {
    "text": "function is running or whether it's a more traditional application architecture and",
    "start": "1394880",
    "end": "1399919"
  },
  {
    "text": "i think that's sort of nice because being able to tell the difference sort of spoils the abstraction a bit",
    "start": "1399919",
    "end": "1406720"
  },
  {
    "text": "at the same time we have the family clear mode which gives us these sort of info semantics",
    "start": "1406720",
    "end": "1412640"
  },
  {
    "text": "if we push a 1.17 and then we push a 1.18 well we get a 1.18 out the other",
    "start": "1412640",
    "end": "1418400"
  },
  {
    "text": "end because we've gotten rid of that whole metric family when that new one",
    "start": "1418400",
    "end": "1423600"
  },
  {
    "text": "comes in we've gotten rid of that 1.17 we replaced it with a 1.18 again perhaps",
    "start": "1423600",
    "end": "1430640"
  },
  {
    "text": "simple the more interesting one is",
    "start": "1430640",
    "end": "1435760"
  },
  {
    "text": "statistical functions right and this is where i wanted to revisit that because metrics are a",
    "start": "1435760",
    "end": "1442080"
  },
  {
    "text": "simple number they're a single number that changes over time and",
    "start": "1442080",
    "end": "1447360"
  },
  {
    "text": "means medians percentiles they're a bit different",
    "start": "1447360",
    "end": "1452480"
  },
  {
    "text": "so we can sort of track a mean as a single number over time but",
    "start": "1452480",
    "end": "1458720"
  },
  {
    "text": "is that useful because if we deploy a new version of our service that doubles",
    "start": "1458720",
    "end": "1464320"
  },
  {
    "text": "the memory usage well we probably want to know about that",
    "start": "1464320",
    "end": "1469760"
  },
  {
    "text": "without that doubling being dragged down by two weeks of a previous function",
    "start": "1469760",
    "end": "1476000"
  },
  {
    "text": "so in reality what we want to be able to do is expire values over time and",
    "start": "1476000",
    "end": "1483279"
  },
  {
    "text": "to do that we actually stole a concept from another internal project we have",
    "start": "1483279",
    "end": "1488480"
  },
  {
    "text": "called cleodora go listen to my ollyfest talk if you want to talk about that",
    "start": "1488480",
    "end": "1493919"
  },
  {
    "text": "but the general idea is that in cleodora we have a concept of pebbles which",
    "start": "1493919",
    "end": "1499120"
  },
  {
    "text": "works well with the gravel gateway idea pebbles are effectively",
    "start": "1499120",
    "end": "1504400"
  },
  {
    "text": "a sort of time-based bucket and we keep a circular buffer of those",
    "start": "1504400",
    "end": "1509679"
  },
  {
    "text": "over time and each bucket contains a sort of pre-aggregated value",
    "start": "1509679",
    "end": "1516640"
  },
  {
    "text": "of all of the incoming values in that time slot so",
    "start": "1516640",
    "end": "1522320"
  },
  {
    "text": "in reality we get this aggregate of aggregates out the other end which does lose us some level of precision but",
    "start": "1522320",
    "end": "1530799"
  },
  {
    "text": "in practice we found it doesn't really matter too much there are some edge cases there it's not perfect",
    "start": "1530799",
    "end": "1537679"
  },
  {
    "text": "but we get this sort of idea right we have this rotating buffer and we can get rid of things over time and this is",
    "start": "1537679",
    "end": "1544320"
  },
  {
    "text": "where we get more complicated clear modes things like mean five minutes we're taking a mean over the last five",
    "start": "1544320",
    "end": "1550000"
  },
  {
    "text": "minutes of data and that allows us to get better insights i think",
    "start": "1550000",
    "end": "1555440"
  },
  {
    "text": "at the same time because we're not augmenting the text exposition format in any way",
    "start": "1555440",
    "end": "1560880"
  },
  {
    "text": "we get compatibility with existing client libraries for free right",
    "start": "1560880",
    "end": "1566480"
  },
  {
    "text": "which is a good thing it means we don't have to train engineers to do anything differently we can just use standard client",
    "start": "1566480",
    "end": "1572320"
  },
  {
    "text": "libraries to add another label set or another label to the label set",
    "start": "1572320",
    "end": "1577360"
  },
  {
    "text": "and because most of us i'd imagine are engineers and we like some code",
    "start": "1577360",
    "end": "1582799"
  },
  {
    "text": "here you go i don't know why we like code why do we like code here's some code excuse the javascript",
    "start": "1582799",
    "end": "1588559"
  },
  {
    "text": "you can see that it's basically exactly the same as a standard",
    "start": "1588559",
    "end": "1594559"
  },
  {
    "text": "as a standard orchestration right we have a request count we don't even need to change that one because",
    "start": "1594559",
    "end": "1599919"
  },
  {
    "text": "the default for request or the default for counters is we sum them and easy",
    "start": "1599919",
    "end": "1605840"
  },
  {
    "text": "and we have a version we have an info metric that's pretty cool",
    "start": "1605840",
    "end": "1612400"
  },
  {
    "text": "if we deployed a 1.1 we would clear out that 1.0 in the gateway because of its",
    "start": "1612400",
    "end": "1618080"
  },
  {
    "text": "clear mode fun code ignore the javascript please that's actually taken from an internal",
    "start": "1618080",
    "end": "1624320"
  },
  {
    "text": "cloudflare worker we have strips down of course but that's the general idea also that's the",
    "start": "1624320",
    "end": "1630559"
  },
  {
    "text": "actual url please don't hack me so that's about it we have the gravel",
    "start": "1630559",
    "end": "1637279"
  },
  {
    "text": "gateway let's look towards the future shall we where do we go from here well",
    "start": "1637279",
    "end": "1643919"
  },
  {
    "text": "in the gateway itself we have a few things coming up we're always trying to evolve it because",
    "start": "1643919",
    "end": "1650480"
  },
  {
    "text": "we're always trying to improve on things we're adding some interesting aggregations things like deltas of",
    "start": "1650480",
    "end": "1657120"
  },
  {
    "text": "counters over time things yeah that sort of stuff more",
    "start": "1657120",
    "end": "1662720"
  },
  {
    "text": "uh statistical functions we want to rewrite pebbles a bit to get rid of some of those edge cases we're also doing",
    "start": "1662720",
    "end": "1669600"
  },
  {
    "text": "some interesting things with scaling it up because it turns out at least at cloudflare we get some rather large",
    "start": "1669600",
    "end": "1676480"
  },
  {
    "text": "services which you know kind of sucks when you're doing sort of six seven figure requests per",
    "start": "1676480",
    "end": "1682960"
  },
  {
    "text": "second turns out a little go binary on a little rust binary on a server i can't",
    "start": "1682960",
    "end": "1688399"
  },
  {
    "text": "really keep up but hey we're looking at sort of clustering it scaling it out again look at the code",
    "start": "1688399",
    "end": "1694240"
  },
  {
    "text": "for the early sort of mentionings of that at the same time",
    "start": "1694240",
    "end": "1700240"
  },
  {
    "text": "we're looking at things like openmetrics for those of you who haven't seen that it's a sort of attempt to codify",
    "start": "1700240",
    "end": "1706559"
  },
  {
    "text": "something very similar to the prometheus text exposition format",
    "start": "1706559",
    "end": "1711600"
  },
  {
    "text": "the main interesting thing is that it defines a whole bunch more types and",
    "start": "1711600",
    "end": "1717760"
  },
  {
    "text": "i know at least some of you out there have just been smugly going ha ha colin we've already solved this problem and",
    "start": "1717760",
    "end": "1724080"
  },
  {
    "text": "you are right because in openmetrics we get things like infometrics we get things like state set",
    "start": "1724080",
    "end": "1729600"
  },
  {
    "text": "metrics all of these different fancy types and that is great because maybe we can get rid of this hacky clear",
    "start": "1729600",
    "end": "1735600"
  },
  {
    "text": "mode someday maybe at the same time",
    "start": "1735600",
    "end": "1741279"
  },
  {
    "text": "we're moving as an industry towards more event-based things because ostensibly that's what we have right we",
    "start": "1741279",
    "end": "1747039"
  },
  {
    "text": "have an event push out of our serverless function we're just doing some level of aggregation on it",
    "start": "1747039",
    "end": "1752799"
  },
  {
    "text": "so again it's a really interesting area of research to sort of look at these more event-based solutions and",
    "start": "1752799",
    "end": "1759919"
  },
  {
    "text": "aggregating time series out of them as i mentioned we have an internal thing cleodora and go see my ollyfest talk if",
    "start": "1759919",
    "end": "1767360"
  },
  {
    "text": "you want to know more about that but it's definitely an interesting area of research and i'm excited to see where",
    "start": "1767360",
    "end": "1773200"
  },
  {
    "text": "we go from there but that's about all i have again code is there if you want to read more on the",
    "start": "1773200",
    "end": "1779760"
  },
  {
    "text": "sort of motivations for this then there's another qr code with a link but that's about all i have the final",
    "start": "1779760",
    "end": "1786640"
  },
  {
    "text": "takeaway i'd like people to encourage is even though things have been around for",
    "start": "1786640",
    "end": "1792559"
  },
  {
    "text": "a long time like serverless functions have been around for what 10 years now there are still open problems in them so",
    "start": "1792559",
    "end": "1800559"
  },
  {
    "text": "even in a world where you might think that there are no problems left to solve",
    "start": "1800559",
    "end": "1806080"
  },
  {
    "text": "there are plenty of problems for you to solve and please go out and solve them because it makes my life a hell of a lot easier",
    "start": "1806080",
    "end": "1812559"
  },
  {
    "text": "thank you",
    "start": "1812559",
    "end": "1815799"
  }
]
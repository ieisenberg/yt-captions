[
  {
    "start": "0",
    "end": "64000"
  },
  {
    "text": "all right good afternoon everybody welcome to today's session networking optimizations for multi node deep",
    "start": "240",
    "end": "6480"
  },
  {
    "text": "learning on kubernetes before we get going I'd like to remind everybody to please rate the session",
    "start": "6480",
    "end": "11820"
  },
  {
    "text": "afterwards on the schedule app also if you have any translation needs we got translation going on over here",
    "start": "11820",
    "end": "18090"
  },
  {
    "text": "just punch in that URL type in the code and then you have the app on your phone please use headphones though versus the",
    "start": "18090",
    "end": "24449"
  },
  {
    "text": "audio speaker um I'd like to introduce these speakers for today arez cohen",
    "start": "24449",
    "end": "29699"
  },
  {
    "text": "vice-president for cloud x nei program at monix and Rashad Chopra principal",
    "start": "29699",
    "end": "35250"
  },
  {
    "text": "software engineer within video working on AI deep learning infrastructure it was like with that I'd like to hand it back over to you guys thank you thank",
    "start": "35250",
    "end": "41790"
  },
  {
    "text": "you very much so good afternoon everybody we thought to start with why",
    "start": "41790",
    "end": "49020"
  },
  {
    "text": "machine learning but to be honest this days it's quite obvious machine learning",
    "start": "49020",
    "end": "54600"
  },
  {
    "text": "is everywhere even we have this little thing here that translate it is all machine learning based so really machine",
    "start": "54600",
    "end": "61260"
  },
  {
    "text": "learning is everywhere and we definitely want to run machine learning in kubernetes as well this is just a basic",
    "start": "61260",
    "end": "68070"
  },
  {
    "start": "64000",
    "end": "64000"
  },
  {
    "text": "definition of what machine learning is from Wikipedia in essence is just the",
    "start": "68070",
    "end": "73439"
  },
  {
    "text": "ability to allow machines to learn from data and program themselves but the real",
    "start": "73439",
    "end": "79380"
  },
  {
    "start": "79000",
    "end": "79000"
  },
  {
    "text": "development over the past few years is around subfield of machine learning",
    "start": "79380",
    "end": "84869"
  },
  {
    "text": "called deep learning or deep neural network which is basically an",
    "start": "84869",
    "end": "91020"
  },
  {
    "text": "implementation of machine learning which is inspired by the brain in other words",
    "start": "91020",
    "end": "96210"
  },
  {
    "text": "taking a biological implementation if you like and translate that into",
    "start": "96210",
    "end": "102710"
  },
  {
    "text": "software implementation this is the very",
    "start": "102710",
    "end": "108299"
  },
  {
    "start": "107000",
    "end": "107000"
  },
  {
    "text": "basic of neural networks who not do a neural networks course here but I do want you to understand the basics so it",
    "start": "108299",
    "end": "115320"
  },
  {
    "text": "will help us understand the challenges in running in in large scale what you see here is a single neuron which has",
    "start": "115320",
    "end": "122369"
  },
  {
    "text": "three inputs on the left hand side X 0 X 1 and X",
    "start": "122369",
    "end": "128030"
  },
  {
    "text": "and with each input we associate a weight W 0 W 1 and W 2 and those weights",
    "start": "128030",
    "end": "137150"
  },
  {
    "text": "are very important those weights will define if this neural network will work properly or not so we need to tune them",
    "start": "137150",
    "end": "143630"
  },
  {
    "text": "and we'll talk about how we do that in a minute those inputs and the weights are going into the cell body there's a simple",
    "start": "143630",
    "end": "150830"
  },
  {
    "text": "function there that decide if this neuron should fire or not so as a single neuron that's pretty simple and a single",
    "start": "150830",
    "end": "159110"
  },
  {
    "text": "neuron doesn't really help us a lot but when we couldn't combine them together interesting things start to happen this",
    "start": "159110",
    "end": "166190"
  },
  {
    "start": "161000",
    "end": "161000"
  },
  {
    "text": "is a neural network that the image processing and predictive and images",
    "start": "166190",
    "end": "173180"
  },
  {
    "text": "digits 0 1 2 all the way to 9 you can see the output on the right hand side",
    "start": "173180",
    "end": "178400"
  },
  {
    "text": "and the input on the left hand side this is an image this is a 3 layer Network",
    "start": "178400",
    "end": "183470"
  },
  {
    "text": "and as you considers many connection between the neurons the neurons are all connected interconnected to each other",
    "start": "183470",
    "end": "189560"
  },
  {
    "text": "now on every connection there are weights as we said earlier so you can",
    "start": "189560",
    "end": "194750"
  },
  {
    "text": "assume that there's quite a lot of weight on this neural network but neural",
    "start": "194750",
    "end": "200959"
  },
  {
    "text": "network can be much bigger this is a 12 layer neural network and as",
    "start": "200959",
    "end": "206390"
  },
  {
    "text": "you can imagine there are much more parameters much more weights that needs to be tuned for this neural network to",
    "start": "206390",
    "end": "213410"
  },
  {
    "text": "work efficiently and this is definitely not the biggest neural network actually today we're saying neural networks that",
    "start": "213410",
    "end": "220489"
  },
  {
    "text": "are multiple hundreds of layers and they",
    "start": "220489",
    "end": "225950"
  },
  {
    "text": "can be very very very large and very complex now when we build a neural",
    "start": "225950",
    "end": "231290"
  },
  {
    "start": "230000",
    "end": "230000"
  },
  {
    "text": "network in the beginning it doesn't act as we want it to be we need to train it",
    "start": "231290",
    "end": "236600"
  },
  {
    "text": "we need to teach it and the way we're teaching neural network is through a process where we feed information that",
    "start": "236600",
    "end": "243920"
  },
  {
    "text": "is pre classified or pre tagged a good example a very classical example is an",
    "start": "243920",
    "end": "249380"
  },
  {
    "text": "image processing when we are trying to teach a system to the distinguish between dogs and cats so we will feed",
    "start": "249380",
    "end": "255260"
  },
  {
    "text": "images of dogs and cats but we know that there are dog and cats and on the output we will check what was",
    "start": "255260",
    "end": "262760"
  },
  {
    "text": "the result and we will try to feedback and fix those weights that I said earlier through some kind of algorithm",
    "start": "262760",
    "end": "268940"
  },
  {
    "text": "until the point where we feed dog image and it will say it's a dog and good probability and a can't imagine it will",
    "start": "268940",
    "end": "275300"
  },
  {
    "text": "say it's a cat and then at that point we say that the neural network is trained and then we can move to the inference",
    "start": "275300",
    "end": "282380"
  },
  {
    "text": "phase the inference phase is basically the execution part this is where we actually push an untagged ma data it can",
    "start": "282380",
    "end": "289850"
  },
  {
    "text": "be an image that we don't know exactly what it has and it will tell us if it is a dog or a cat of course this is a",
    "start": "289850",
    "end": "296180"
  },
  {
    "text": "simplified example the training phase is very challenging it is very very much",
    "start": "296180",
    "end": "302720"
  },
  {
    "start": "299000",
    "end": "299000"
  },
  {
    "text": "compute intensive process this is why NVIDIA GPU is such a wonderful solution",
    "start": "302720",
    "end": "308060"
  },
  {
    "text": "because it allows us to drive computational very fast but what we see",
    "start": "308060",
    "end": "314540"
  },
  {
    "text": "is that those neural networks are growing in complexity and the input data",
    "start": "314540",
    "end": "319820"
  },
  {
    "text": "is growing as well and actually today if we are looking at modern models and",
    "start": "319820",
    "end": "326450"
  },
  {
    "text": "problems it takes us weeks to train a model obviously that is very challenging",
    "start": "326450",
    "end": "331940"
  },
  {
    "text": "challenging because a week is a long time but also we need to train quite",
    "start": "331940",
    "end": "336980"
  },
  {
    "text": "often there's still reason what we'll learn to train often one is because development model is not a linear",
    "start": "336980",
    "end": "344030"
  },
  {
    "text": "process like writing a C code or any other language you are used to you write the model you train it you see how it",
    "start": "344030",
    "end": "350570"
  },
  {
    "text": "behaves you change it and then you train it again and you go on and on now if you do that and it takes you a week between",
    "start": "350570",
    "end": "356750"
  },
  {
    "text": "training that's very inefficient another reason is that just like in life you",
    "start": "356750",
    "end": "362720"
  },
  {
    "text": "have to keep on learning you build the model you train it great you put it in production but things change the world",
    "start": "362720",
    "end": "370070"
  },
  {
    "text": "is dynamic and we need to be able to keep on teaching the model too and and",
    "start": "370070",
    "end": "375770"
  },
  {
    "text": "bring it to be more accurate so what we really need is we need to to accelerate",
    "start": "375770",
    "end": "382190"
  },
  {
    "text": "our training time and the only way to do that is to do scale-out computing",
    "start": "382190",
    "end": "387250"
  },
  {
    "text": "basically add more computers so how do we how do we do trainer scale out in",
    "start": "387250",
    "end": "393289"
  },
  {
    "start": "390000",
    "end": "390000"
  },
  {
    "text": "machine learning this paradigm called data parallelism and basically what it",
    "start": "393289",
    "end": "398630"
  },
  {
    "text": "does is basically instead of having a single computer that has all the input data we just add more computer we scale",
    "start": "398630",
    "end": "404900"
  },
  {
    "text": "out and we take the input data we split it in between the different computers so",
    "start": "404900",
    "end": "411050"
  },
  {
    "text": "in this example each computer will get sixth 1/6 of the data and then it do a",
    "start": "411050",
    "end": "418010"
  },
  {
    "text": "local training now if each of the computer will do local training you will end up with 6 different models because",
    "start": "418010",
    "end": "425330"
  },
  {
    "text": "each of them was working on different data elements so that will not work what we really need to do is we need to",
    "start": "425330",
    "end": "431510"
  },
  {
    "text": "combine those machines power together and the way to do that is basically split the data into mini batches let's",
    "start": "431510",
    "end": "438590"
  },
  {
    "text": "say 32 images do local training on each node and then communicate the results",
    "start": "438590",
    "end": "445070"
  },
  {
    "text": "and combine them together through the network it can be to a single computer it can be between the computers there's",
    "start": "445070",
    "end": "451310"
  },
  {
    "text": "different ways to do that and eventually this process when we are iterating this",
    "start": "451310",
    "end": "458560"
  },
  {
    "text": "multiple times it can be hundreds of thousands or millions of iteration we",
    "start": "458560",
    "end": "463850"
  },
  {
    "text": "will get a single end model that is trained now when we look at those network element in the training phase we",
    "start": "463850",
    "end": "472729"
  },
  {
    "start": "468000",
    "end": "468000"
  },
  {
    "text": "see that the communication pattern is very very challenging it which it will be usually a very high performance high",
    "start": "472729",
    "end": "479960"
  },
  {
    "text": "throughput the those models can be transferring tens and hundreds of",
    "start": "479960",
    "end": "487010"
  },
  {
    "text": "gigabits per second so it's a lot of data from every computer and you have a lot of computers usually doing that it",
    "start": "487010",
    "end": "493669"
  },
  {
    "text": "will be very high message rate and low latency requirements and it has collective operation in nature what I",
    "start": "493669",
    "end": "501740"
  },
  {
    "text": "mean by collective operation is that all those nodes are working together they work on a mini batch to communicate and",
    "start": "501740",
    "end": "508400"
  },
  {
    "text": "they're waiting for each other so they work as a collective and as a collective you need to wait for everybody and synchronize",
    "start": "508400",
    "end": "515300"
  },
  {
    "text": "everybody together and this type of communication pattern very much remind us of high-performance computing Network",
    "start": "515300",
    "end": "523250"
  },
  {
    "text": "which are all the supercomputers and we know from a lot of years of experience",
    "start": "523250",
    "end": "528950"
  },
  {
    "text": "that advanced network techniques such as are the main GPU direct are critical for",
    "start": "528950",
    "end": "535070"
  },
  {
    "text": "having an efficient training I mentioned early may let me just give you a quick",
    "start": "535070",
    "end": "541340"
  },
  {
    "text": "explanation about what is already made our day way is a remote direct memory access it is a transport service you",
    "start": "541340",
    "end": "548360"
  },
  {
    "text": "guys probably know TCP and UDP so it's in the same layer of Mallis and but it",
    "start": "548360",
    "end": "554090"
  },
  {
    "text": "was designed much later and it is much more advanced in terms of feature set it",
    "start": "554090",
    "end": "560120"
  },
  {
    "text": "provides ability to do read and write over the network not only send receive and it provides us ability to the kernel",
    "start": "560120",
    "end": "567470"
  },
  {
    "text": "bypass kernel bypasses when the application talks directly to the odd were bypassing the kernel and by that we",
    "start": "567470",
    "end": "573350"
  },
  {
    "text": "get very low latency and it provides full hardware offload at least with the Mellanox necks which means that we can",
    "start": "573350",
    "end": "579710"
  },
  {
    "text": "transfer hundreds of gigabytes without any CPU intervention so the CPU load is zero and the efficiency is very very",
    "start": "579710",
    "end": "586490"
  },
  {
    "text": "high our device started from a technology called InfiniBand but today it's part of Ethernet it is called Rocky",
    "start": "586490",
    "end": "593000"
  },
  {
    "text": "and the interface the software interface is not sockets it is an interface called verbs which is very important because",
    "start": "593000",
    "end": "600140"
  },
  {
    "text": "the normal net devices that we transfer to the container doesn't provide Rocky are the main interface we need a",
    "start": "600140",
    "end": "607040"
  },
  {
    "text": "different interface GPU direct is a technology that allow us a better",
    "start": "607040",
    "end": "612770"
  },
  {
    "start": "609000",
    "end": "609000"
  },
  {
    "text": "efficiency of sending and receiving data from the GPU to the network what you see on the top right hand side is how do you",
    "start": "612770",
    "end": "619220"
  },
  {
    "text": "get data in and out of the GPU memory without GPU director what you do is",
    "start": "619220",
    "end": "624530"
  },
  {
    "text": "typically copy data from the GPU memory to the host memory copy the host memory",
    "start": "624530",
    "end": "629600"
  },
  {
    "text": "to a buffer in the host number again for the network and send it out that's not very efficient of this GPU direct is a",
    "start": "629600",
    "end": "636980"
  },
  {
    "text": "technology that developed by Nvidia and Mellanox together about 10 years ago which allowed the",
    "start": "636980",
    "end": "644100"
  },
  {
    "text": "neck and the gpo to communicate directly to each other so the neck can access the GPU memory and send and receive data",
    "start": "644100",
    "end": "649920"
  },
  {
    "text": "directly from there obviously it provides a much more or much better",
    "start": "649920",
    "end": "655520"
  },
  {
    "text": "efficiency so how do we enable our team a NGP direct in kubernetes",
    "start": "655520",
    "end": "661910"
  },
  {
    "text": "so today we are using SRA of V as a mechanism to expose our DMA in GPU",
    "start": "661910",
    "end": "668190"
  },
  {
    "text": "direct SRV is a PCI specification stands for single route our virtualization and",
    "start": "668190",
    "end": "674730"
  },
  {
    "text": "basically what does what does it mean it means that you can take a PCI device slice it and provide slices to an",
    "start": "674730",
    "end": "682590"
  },
  {
    "text": "application called virtual function what you see on the images and on the bottom",
    "start": "682590",
    "end": "688140"
  },
  {
    "text": "here on the left hand side you'd see the standard configuration on the right hand side you see this Ravn you can see that",
    "start": "688140",
    "end": "694050"
  },
  {
    "text": "every virtual function coming from the device has a net device but also the our DMA device those devices that are needed",
    "start": "694050",
    "end": "701100"
  },
  {
    "text": "for our DMA that can be mapped into the container there are seen eyes and device plugins",
    "start": "701100",
    "end": "706980"
  },
  {
    "text": "to provision SRA of a it is completely standout and upstream and you can find the links in this page so from a",
    "start": "706980",
    "end": "714960"
  },
  {
    "text": "container perspective the container will see when when when the SRA of a device",
    "start": "714960",
    "end": "720720"
  },
  {
    "text": "and CNI plugin are activated the container will see both an our DMA",
    "start": "720720",
    "end": "726270"
  },
  {
    "text": "device this is the IB dev that you see here as well as a net device under the namespace of that container and we'll",
    "start": "726270",
    "end": "732630"
  },
  {
    "text": "get a slice of the neck as part of the server interface so how does it look",
    "start": "732630",
    "end": "738780"
  },
  {
    "text": "from an orchestration perspective on the kubernetes level so first the SR every Network device",
    "start": "738780",
    "end": "745710"
  },
  {
    "text": "plug-in will advertise the service capabilities basically how many virtual",
    "start": "745710",
    "end": "751650"
  },
  {
    "text": "functions each device has and then when you launch a pod it will define that it",
    "start": "751650",
    "end": "757410"
  },
  {
    "text": "needs a survivor V in case that it needs a service or it will say need a virtual function the kubernetes scheduler then",
    "start": "757410",
    "end": "764040"
  },
  {
    "text": "we'll run the pod in the right host with with those resources the device plug-in",
    "start": "764040",
    "end": "769670"
  },
  {
    "text": "will allocate the virtual function that will be connected to the",
    "start": "769670",
    "end": "775170"
  },
  {
    "text": "but the allocated device is communicated with SRA OVC ni because we need the net",
    "start": "775170",
    "end": "780779"
  },
  {
    "text": "device to run on that interface and then the service and I will move the virtual function that device to they put the",
    "start": "780779",
    "end": "787980"
  },
  {
    "text": "name space in kubernetes today you are",
    "start": "787980",
    "end": "793980"
  },
  {
    "text": "not allowed to run more than one interface I want one CNI into a pod and",
    "start": "793980",
    "end": "799170"
  },
  {
    "text": "for that multo soar similar and plugins were developed monitors as a meta plugin",
    "start": "799170",
    "end": "806670"
  },
  {
    "text": "which allows to provide multiple interfaces to to a pod there will be",
    "start": "806670",
    "end": "813360"
  },
  {
    "text": "always one interface which will be the prime the master interface this is the standard kind of eth0 that that you are",
    "start": "813360",
    "end": "820470"
  },
  {
    "text": "using and this is where all the security groups and policies and so on will be applied but then Moltres provides you",
    "start": "820470",
    "end": "827820"
  },
  {
    "text": "the ability to connect additional so nice one omo it can be more than one and in our",
    "start": "827820",
    "end": "834660"
  },
  {
    "text": "case it is obviously a survey of a and those interfaces although they are",
    "start": "834660",
    "end": "840839"
  },
  {
    "text": "providing connectivity they don't have any security policies around them and",
    "start": "840839",
    "end": "846480"
  },
  {
    "text": "they are not able to be present in under the kubernetes interface and with that I",
    "start": "846480",
    "end": "853529"
  },
  {
    "text": "will hand to result",
    "start": "853529",
    "end": "857329"
  },
  {
    "text": "No welcome to part 2 of the post learn",
    "start": "860360",
    "end": "866790"
  },
  {
    "text": "session of the last day of the conference I'm sure you guys excited try to make it interesting funny thing I",
    "start": "866790",
    "end": "873120"
  },
  {
    "text": "noticed that when rez said our DMA the a",
    "start": "873120",
    "end": "878940"
  },
  {
    "text": "I think running over there was saying our DNA it's that was noticing and it's",
    "start": "878940",
    "end": "887490"
  },
  {
    "text": "more clever than I was afraid of anyway yeah we get to probably my accent or I'm",
    "start": "887490",
    "end": "898380"
  },
  {
    "text": "smarter than it alright alright so uh",
    "start": "898380",
    "end": "903780"
  },
  {
    "start": "902000",
    "end": "902000"
  },
  {
    "text": "arrests talked about all the ingredients that you would need to get deep learning",
    "start": "903780",
    "end": "910130"
  },
  {
    "text": "going on Cuban Aires for multiple nodes you need our DMA and everything he put",
    "start": "910130",
    "end": "915570"
  },
  {
    "text": "it on the list of all the ingredients and I put all these ingredients together you will have a large data center hopefully if you want to scale out and",
    "start": "915570",
    "end": "921780"
  },
  {
    "text": "push further and further you have a large data center and you could be able to put these pieces together and things",
    "start": "921780",
    "end": "927270"
  },
  {
    "text": "would start to work I'm afraid not you will run into issues and those are",
    "start": "927270",
    "end": "932550"
  },
  {
    "text": "the issues which I'm gonna list down if you ever going to try this in your data center you know bring this",
    "start": "932550",
    "end": "937620"
  },
  {
    "text": "infrastructure up you're gonna have to take care of these issues in mind some of them are functional issues you will",
    "start": "937620",
    "end": "943050"
  },
  {
    "text": "see that stuff is not working and some of them are performance issues you will see the other stuff is working at as low",
    "start": "943050",
    "end": "949560"
  },
  {
    "text": "as 1% of the performance that you thought or as I would have shown in the slides so I will go through some of this",
    "start": "949560",
    "end": "955320"
  },
  {
    "text": "list and we start probably start making some counts of things that I am going to list and in the end I'm going to show",
    "start": "955320",
    "end": "960660"
  },
  {
    "text": "some performance graphs on how when we put in these optimizations what do we see do we see the expected results or",
    "start": "960660",
    "end": "966270"
  },
  {
    "start": "966000",
    "end": "966000"
  },
  {
    "text": "not alright so we'll start with priori flow control explicit congestion notification stuff you can read up on Google what it",
    "start": "966270",
    "end": "973170"
  },
  {
    "text": "is it's broadly about saying when the network is going to be shared it's an either RDMA over converged Ethernet",
    "start": "973170",
    "end": "979610"
  },
  {
    "text": "you're gonna have trouble with other things so well let's separate our priority flow control things and then",
    "start": "979610",
    "end": "984810"
  },
  {
    "text": "let's make a separate channel you need to configure there on the host the ecn bits which is ingest",
    "start": "984810",
    "end": "990460"
  },
  {
    "text": "notifications which is just saying a ferris congestion please back off dumps in traffic let's don't make it worse kind of things these are things which",
    "start": "990460",
    "end": "996520"
  },
  {
    "text": "you have to can fix on your switch or the router and then other things you",
    "start": "996520",
    "end": "1001980"
  },
  {
    "text": "need to get this ACS thing set up on BIOS if you don't do that you will see some performance suffering and then",
    "start": "1001980",
    "end": "1008610"
  },
  {
    "text": "there's a GPO direct which it has introduced if you don't put this kernel module in imagine now you have 20 boxes",
    "start": "1008610",
    "end": "1018270"
  },
  {
    "text": "in your data center or 200 boxes and you didn't put one of the kernel modules thing going on in one of the boxes",
    "start": "1018270",
    "end": "1023730"
  },
  {
    "text": "dismissed one what is the BB or the single most important principle of high",
    "start": "1023730",
    "end": "1029400"
  },
  {
    "text": "performance computing the slowest guy is gonna guide the performance of the",
    "start": "1029400",
    "end": "1035400"
  },
  {
    "text": "entire flock when you say the whole thing is not even 20% performance what's going wrong well please go through the",
    "start": "1035400",
    "end": "1041339"
  },
  {
    "text": "checklist this suffered this so believe us the final part is blue flame registers the TVs in Mellanox cause if",
    "start": "1041339",
    "end": "1048060"
  },
  {
    "text": "you have smaller packets 64 bytes less or something and then you probably want to tune this further you don't want to",
    "start": "1048060",
    "end": "1054630"
  },
  {
    "text": "see if I pursue drop it's not that 5% broken performance is important I translate that to 5% of your money going",
    "start": "1054630",
    "end": "1062010"
  },
  {
    "text": "waste when you have invested millions of dollars on that infrastructure going how many of these are there four of these",
    "start": "1062010",
    "end": "1067200"
  },
  {
    "text": "all right we keep going you don't believe me probably and these are the graphs that we measured we didn't do PFC",
    "start": "1067200",
    "end": "1072840"
  },
  {
    "text": "NECN the one on the left is showing four interface cards the red orange green and",
    "start": "1072840",
    "end": "1079200"
  },
  {
    "text": "blue trying to operate over some period of time which is the x axis and the y",
    "start": "1079200",
    "end": "1084300"
  },
  {
    "text": "axis is the gigabits per second and the max you could have gotten a hundred gigs per seconds that's the card",
    "start": "1084300",
    "end": "1090540"
  },
  {
    "text": "throughput and you would see that you don't get the things right one of the cards is just working at 20% twenty you",
    "start": "1090540",
    "end": "1098820"
  },
  {
    "text": "get bits per second will just enable that and you see the graph on the right and you say nearly everyone is working",
    "start": "1098820",
    "end": "1104520"
  },
  {
    "text": "together like brothers should be and you get above 90% but you can see as anyone",
    "start": "1104520",
    "end": "1112500"
  },
  {
    "text": "can that there's some small spikes that come down we were at the four counts of things",
    "start": "1112500",
    "end": "1118800"
  },
  {
    "text": "that we had optimized I'm gonna go next on how to remove these spikes also if",
    "start": "1118800",
    "end": "1125190"
  },
  {
    "start": "1124000",
    "end": "1124000"
  },
  {
    "text": "there's one single important thing that you're here for and you want to learn on",
    "start": "1125190",
    "end": "1130440"
  },
  {
    "text": "how to get deep learning infrastructure on scale with kubernetes and everything this is the one thing which will improve",
    "start": "1130440",
    "end": "1138180"
  },
  {
    "text": "your performance multifold make it scalable make it reliable the problem",
    "start": "1138180",
    "end": "1143430"
  },
  {
    "text": "statement is that I got these boxes you know the GP boxes each box has eight GPUs or sixteen GPS or four GPS of",
    "start": "1143430",
    "end": "1149490"
  },
  {
    "text": "whatever your favorite configuration work and let's connect them to the network and the network has these",
    "start": "1149490",
    "end": "1154860"
  },
  {
    "text": "top-of-rack switches or something how do you connect them if you're anyone like me or something stupid or learning this",
    "start": "1154860",
    "end": "1161880"
  },
  {
    "text": "is what I did I put these boxes and then the rod got over I put this into the switch and then get to the other rack put these boxes put it within the top of",
    "start": "1161880",
    "end": "1168630"
  },
  {
    "text": "the rack and the connect the power of the rack to the fabs and spines or whatever it is does not work and it will",
    "start": "1168630",
    "end": "1177840"
  },
  {
    "text": "work for any other thing that you would try to do it would not work for deep learning why because deep learning has a peculiar",
    "start": "1177840",
    "end": "1184470"
  },
  {
    "text": "thing when you try to share those mini-batches with your parameter servers and everything what's going on is that",
    "start": "1184470",
    "end": "1192050"
  },
  {
    "text": "the if you see this diagram on the right",
    "start": "1192050",
    "end": "1199140"
  },
  {
    "text": "top right the information sharing happens in and through a ring or a",
    "start": "1199140",
    "end": "1204450"
  },
  {
    "text": "parameter server or a tree or something whatever information goes through Nick one comes out of Nick one covering all",
    "start": "1204450",
    "end": "1210540"
  },
  {
    "text": "the GPUs conducting all the parameters that each of those GP is communicated goes to the other GPU node and",
    "start": "1210540",
    "end": "1215820"
  },
  {
    "text": "communicates with Nick one also and goes to the third node and can me guess with Nick one again all the Nick ones want to",
    "start": "1215820",
    "end": "1221940"
  },
  {
    "text": "talk to each other all the Nick tools want to talk to each other all the Nick trees want to talk to each other never",
    "start": "1221940",
    "end": "1228240"
  },
  {
    "text": "would you have a situation in deep learning in the frameworks that Nick one is trying to talk to Nick - no Nick one",
    "start": "1228240",
    "end": "1234240"
  },
  {
    "text": "talks to Nick one Nick two - Nick - three - three four - four so a minor point but a very clever point I'm saying",
    "start": "1234240",
    "end": "1242130"
  },
  {
    "text": "the single most important thing if you have to learn so wake up listen to this when you fire up your servers get your",
    "start": "1242130",
    "end": "1248899"
  },
  {
    "text": "NIC 1 2 switch 1 all the NIC tools to switch to all the NIC trees to switch 3",
    "start": "1248899",
    "end": "1254779"
  },
  {
    "text": "even if they're from the same box just a simple measure and the result is that",
    "start": "1254779",
    "end": "1260570"
  },
  {
    "text": "when all NIC ones perform their communication pattern they will have no extra hop one hop right they all go to",
    "start": "1260570",
    "end": "1267440"
  },
  {
    "text": "the same switch they get back to the thing there is no extra hop required now extra hop is bad when you're talking",
    "start": "1267440",
    "end": "1273109"
  },
  {
    "text": "about RDMA over Ethernet a simple principle very easy to understand just that I struggle so much with putting all",
    "start": "1273109",
    "end": "1280070"
  },
  {
    "text": "of these Tunes the same single switch and everything and the one important thing that you can learn from here is that if you get the number of ports on",
    "start": "1280070",
    "end": "1286399"
  },
  {
    "text": "your switch is more than the more you can scale any cluster if you have a 128-bit of 128 port switch you will be",
    "start": "1286399",
    "end": "1293960"
  },
  {
    "text": "able to connect 128 machines on one switch that would nearly mean 1,000 GPUs",
    "start": "1293960",
    "end": "1302619"
  },
  {
    "text": "5 points did I make this is the single most important one sixth point if you",
    "start": "1302619",
    "end": "1308869"
  },
  {
    "start": "1307000",
    "end": "1307000"
  },
  {
    "text": "don't enable this this is going to be dysfunctional this is a source based routing now it has introduced that using",
    "start": "1308869",
    "end": "1314599"
  },
  {
    "text": "multiple you will have multiple interfaces into the pod when you have multiple interfaces all of them are on a",
    "start": "1314599",
    "end": "1321889"
  },
  {
    "text": "different network and possibly would be do you know how routing works then if I",
    "start": "1321889",
    "end": "1328249"
  },
  {
    "text": "want to go from a box to some IP address my destination routing table says oh you",
    "start": "1328249",
    "end": "1335929"
  },
  {
    "text": "want to get to that subnet use this NIC I say hold on I'm deep learning ok I know which NIC to use don't tell me to",
    "start": "1335929",
    "end": "1342739"
  },
  {
    "text": "use that Nick I know which need to use I want to connect NIC one to Nick one don't tell me that your routing table is",
    "start": "1342739",
    "end": "1348349"
  },
  {
    "text": "saying to use NIC for for that subnet well you need so space jargon here so that when you're deep learning framework",
    "start": "1348349",
    "end": "1355549"
  },
  {
    "text": "is trying to share parameters it consults the source based routing and says NIC one will always go from NIC one",
    "start": "1355549",
    "end": "1361009"
  },
  {
    "text": "you choose the source interface and you choose the destination interface and you",
    "start": "1361009",
    "end": "1366470"
  },
  {
    "text": "need this plug-in to make this working so we always put this together if you have a quick question I can answer now we can take this bit",
    "start": "1366470",
    "end": "1373570"
  },
  {
    "text": "yeah layer 2 network clearly and you will not have VLANs then and you will",
    "start": "1374129",
    "end": "1379599"
  },
  {
    "text": "not have ever the possibility of going and expanding your network when you have a 648 port switch and a second we have",
    "start": "1379599",
    "end": "1385839"
  },
  {
    "text": "layer 3 if you don't want layer 3 yes if you stick in layer 2 you don't need this but you want to scale out and we wanted",
    "start": "1385839",
    "end": "1392769"
  },
  {
    "text": "to scale out so we said well let's make it generic good question thank you this",
    "start": "1392769",
    "end": "1399070"
  },
  {
    "start": "1398000",
    "end": "1398000"
  },
  {
    "text": "is the roughly the final thing that I'm going to talk about we can spend a lot of time on this and if you want we can",
    "start": "1399070",
    "end": "1404139"
  },
  {
    "text": "close the sooner but these are real performance measurements now I could have gone on to hundreds of GPUs but I",
    "start": "1404139",
    "end": "1414279"
  },
  {
    "text": "wanted to restrict and see that just 5 boxes put together just 42:48 GPUs put",
    "start": "1414279",
    "end": "1419889"
  },
  {
    "text": "together on different scale what are the numbers that I got on resonate 50 which",
    "start": "1419889",
    "end": "1425109"
  },
  {
    "text": "has 23 million parameters to be shared on every one of the 50 layers when you do deep learning training on 14 million",
    "start": "1425109",
    "end": "1432940"
  },
  {
    "text": "images the y-axis is number of images per second the x-axis is number of GPS",
    "start": "1432940",
    "end": "1440919"
  },
  {
    "text": "that are used and the three graphs are on batch sizes",
    "start": "1440919",
    "end": "1446369"
  },
  {
    "text": "see clearly in SGD we trust' SGD is the",
    "start": "1446369",
    "end": "1452109"
  },
  {
    "text": "algorithm that we use stochastic gradient descent to share those parameters and that's why you would see",
    "start": "1452109",
    "end": "1458169"
  },
  {
    "text": "why the batch sizes are important why your accuracy is important why the training image the these speed of",
    "start": "1458169",
    "end": "1464469"
  },
  {
    "text": "training is important and how these things play but with the network guys we want to make sure that what did I do all",
    "start": "1464469",
    "end": "1471459"
  },
  {
    "text": "this for and you can see in the third graph just in five boxes put together",
    "start": "1471459",
    "end": "1476649"
  },
  {
    "text": "you can see if you did not put your network right the red line is the RDMA",
    "start": "1476649",
    "end": "1482229"
  },
  {
    "text": "highly optimized stuff and the blue line is also hundred gigs I'm not comparing wrong mixed with stuff the blue line was",
    "start": "1482229",
    "end": "1489309"
  },
  {
    "text": "also the hundred gig mix and you see two extra in performance that's half your",
    "start": "1489309",
    "end": "1495309"
  },
  {
    "text": "money wasted in just five boxes put together five as in or six boxes put together yeah so 48",
    "start": "1495309",
    "end": "1502240"
  },
  {
    "text": "GPUs you would see 2 X performers last now as you start to scale into hundreds and thousands GPUs you can calculate",
    "start": "1502240",
    "end": "1509049"
  },
  {
    "text": "what's going to go happen the top left graph is the bigger batch size and there",
    "start": "1509049",
    "end": "1517179"
  },
  {
    "text": "are three lines there one is the orange line which is the ideal theoretical maximum that you could ever get which is",
    "start": "1517179",
    "end": "1523390"
  },
  {
    "text": "what I did with one GPU I took and I said what if I put 48 jeebies I just",
    "start": "1523390",
    "end": "1529870"
  },
  {
    "text": "took that number and multiplied by 48 that's the idea you could get and if you see in most of these graphs until 8 GPUs",
    "start": "1529870",
    "end": "1537039"
  },
  {
    "text": "you definitely get similar scale and after 8 you start to Peter off a little",
    "start": "1537039",
    "end": "1542110"
  },
  {
    "text": "bit in at the scale this slope is not one anymore or something it's because one box had hit GPUs it's only when the",
    "start": "1542110",
    "end": "1549070"
  },
  {
    "text": "second box comes in you use the actual network you use the PFC if the EZ ends you will use the optimizations that I've",
    "start": "1549070",
    "end": "1555789"
  },
  {
    "text": "been talking about who likes to see half of their data or half of their money",
    "start": "1555789",
    "end": "1560799"
  },
  {
    "text": "going based nobody we're talking millions of dollars here I'll prove my point in the end with a joke",
    "start": "1560799",
    "end": "1568980"
  },
  {
    "start": "1569000",
    "end": "1569000"
  },
  {
    "text": "at somebody in conclusion or stretch it we can talk about this later and these graphs are important these are real measurements and they're not done yet we",
    "start": "1570960",
    "end": "1579240"
  },
  {
    "text": "can improve this further we're gonna pull these red guys a little of them and try to see how the scale and everything so I'm putting together laughs with 800",
    "start": "1579240",
    "end": "1586290"
  },
  {
    "text": "GPS and then thousand GPS and see how far it goes and then you've seen the ml per members and everything we want to train the",
    "start": "1586290",
    "end": "1594210"
  },
  {
    "text": "resident 50 or the more complex models even 150 and 150 and what not not in",
    "start": "1594210",
    "end": "1600030"
  },
  {
    "text": "weeks as it used to take not in days nor in hours these results are the old model",
    "start": "1600030",
    "end": "1606990"
  },
  {
    "text": "trained in five minutes so you can train retrain things like those well this is",
    "start": "1606990",
    "end": "1613830"
  },
  {
    "text": "the summary and it's coming to a close finally the upshot of the matter is a",
    "start": "1613830",
    "end": "1619200"
  },
  {
    "text": "multi rail Adam and Cuban it is is possible and it scales very well as we have shown we've shown the performance",
    "start": "1619200",
    "end": "1624360"
  },
  {
    "text": "numbers there are a lot of things to take care of and you can go over the slides we'll publish it of course",
    "start": "1624360",
    "end": "1629810"
  },
  {
    "text": "further work would be storage you got a plan for it or we'll talk about it",
    "start": "1629810",
    "end": "1635400"
  },
  {
    "text": "ambient temperature is an important thing if you have 100 degree going on outside you will see that performance of",
    "start": "1635400",
    "end": "1642240"
  },
  {
    "text": "your data center is suffering and you would say for I did everything right what's wrong well it's just hot outside plays around in pressure there are other",
    "start": "1642240",
    "end": "1649620"
  },
  {
    "text": "things what are the clearest biggest principal slower sling will guide the performance of the entire job it's an HPC thing and to close does anyone know",
    "start": "1649620",
    "end": "1658200"
  },
  {
    "text": "what principle does a plane fly this was asked to me when I was doing my pilot",
    "start": "1658200",
    "end": "1663480"
  },
  {
    "text": "training several years ago and I took the first ground instruction and the instructor said so you've learned a",
    "start": "1663480",
    "end": "1669780"
  },
  {
    "text": "little bit about how planes fly how do they how do they fly and I was naive I said you know like how networks works on",
    "start": "1669780",
    "end": "1676560"
  },
  {
    "text": "bits and switching everything so the Bernoulli's principle or things know the",
    "start": "1676560",
    "end": "1682140"
  },
  {
    "text": "only principle is you put money it flies this is networking put money in course just take a few things thank you",
    "start": "1682140",
    "end": "1690530"
  },
  {
    "text": "so if any of you have questions that we have few more minutes and you're more",
    "start": "1694519",
    "end": "1699840"
  },
  {
    "text": "than welcome to contact rich out of myself yes do you have performance",
    "start": "1699840",
    "end": "1708419"
  },
  {
    "text": "numbers visibly the bare metal versus kubernetes that you could illustrate on this screen is on bare metal okay so if",
    "start": "1708419",
    "end": "1716940"
  },
  {
    "text": "you remove the infrastructure and just run it purely on bare metal how would this look like that's what I was trying",
    "start": "1716940",
    "end": "1722249"
  },
  {
    "text": "to figure out exactly the same it's if it's an argument that your name spaces introduce anything they're not in the",
    "start": "1722249",
    "end": "1729210"
  },
  {
    "text": "data path okay the SRO V the whole idea is that there is no bridge there is nothing the SR IV idea is that you take",
    "start": "1729210",
    "end": "1735389"
  },
  {
    "text": "the physical interface nearly the physical interface take make the virtual function out of it and pull it right into it and as a rest set it doesn't",
    "start": "1735389",
    "end": "1741509"
  },
  {
    "text": "work on those sockets it works on the verbs so the data plane is not even there it doesn't even know what namespace and everything is it does but",
    "start": "1741509",
    "end": "1748979"
  },
  {
    "text": "it's not in the path yes maybe just add one thing that we didn't talk about here",
    "start": "1748979",
    "end": "1754259"
  },
  {
    "text": "but the next phase that we will do is actually enable all the Sdn controllers with the bypass so we you know in the",
    "start": "1754259",
    "end": "1763409"
  },
  {
    "text": "very near future will be able to run all those goodies where the full Sdn and",
    "start": "1763409",
    "end": "1768659"
  },
  {
    "text": "without any performance impact that's the next phase any additional questions",
    "start": "1768659",
    "end": "1774440"
  },
  {
    "text": "yeah over here",
    "start": "1774440",
    "end": "1777768"
  },
  {
    "text": "if we are slicing the GPU to V GPUs right will we see any issues here like",
    "start": "1787030",
    "end": "1793750"
  },
  {
    "text": "our multiple jobs we'll run the universe of the problem you're trying to solve",
    "start": "1793750",
    "end": "1799000"
  },
  {
    "text": "we're taking one job and we're gonna take thousands of GPUs and use saying",
    "start": "1799000",
    "end": "1804460"
  },
  {
    "text": "that we take one GP and split it into multiple jobs so we can't compare this I",
    "start": "1804460",
    "end": "1809890"
  },
  {
    "text": "mean I I know that this is the thing that we need to work I mean this is the problem case if it's is not that problem statement it's this problem statement is",
    "start": "1809890",
    "end": "1816280"
  },
  {
    "text": "I got a model it takes hours to run and optimize how can I bring it down to minutes so this is not GPU sharing this",
    "start": "1816280",
    "end": "1824860"
  },
  {
    "text": "is taking everything in your data center or on one job finishing minutes come back with the new parameters yes so if",
    "start": "1824860",
    "end": "1836440"
  },
  {
    "text": "you have a large GPU cluster in which you run in different trainings in parallel like different different sets",
    "start": "1836440",
    "end": "1842500"
  },
  {
    "text": "of you know TC video trainings you know when you keep running were low your",
    "start": "1842500",
    "end": "1847660"
  },
  {
    "text": "cluster it gets somehow fragmented like you cannot do perfectly say that you cannot put the jobs next to each other",
    "start": "1847660",
    "end": "1853210"
  },
  {
    "text": "that's right so when you're you seen rocky instead of InfiniBand how much",
    "start": "1853210",
    "end": "1858940"
  },
  {
    "text": "noise can you know how much noise can it survive or you know to make hotspots in",
    "start": "1858940",
    "end": "1864430"
  },
  {
    "text": "the network because with InfiniBand G so Hollis has always like a double path to you can ante somehow the nodes will",
    "start": "1864430",
    "end": "1871870"
  },
  {
    "text": "reach each other within a certain Latin C with a certain path weight without noise but with rocky is not the case if",
    "start": "1871870",
    "end": "1878260"
  },
  {
    "text": "your question is if I could tell right is that with rocky you're selling the",
    "start": "1878260",
    "end": "1884440"
  },
  {
    "text": "network in some way and within few when you get the Clear Channel and everything and stuff so this work is showing rocky",
    "start": "1884440",
    "end": "1891490"
  },
  {
    "text": "but it's not occluding rocky first including InfiniBand first of all so it's a principle should apply and then",
    "start": "1891490",
    "end": "1897040"
  },
  {
    "text": "we should work on IB as well but come back to your question yes if you clog a network you will get clogged results if",
    "start": "1897040",
    "end": "1902590"
  },
  {
    "text": "you clear in it what you will get clear results is this there's nothing else but but you don't forget the PFC ECN",
    "start": "1902590",
    "end": "1909490"
  },
  {
    "text": "bits right if you have you have ecn on you would have a normally functioning cluster but if you still are overloaded",
    "start": "1909490",
    "end": "1915730"
  },
  {
    "text": "at least you would not die with thrashing I will just maybe quickly add",
    "start": "1915730",
    "end": "1922010"
  },
  {
    "text": "on that in general when you're running multi applications and a cloud which is",
    "start": "1922010",
    "end": "1927020"
  },
  {
    "text": "our performance you need to do placement in a network aware manner if you'll",
    "start": "1927020",
    "end": "1932510"
  },
  {
    "text": "place your workloads and without any network awareness you may have challenges and it is not available yet",
    "start": "1932510",
    "end": "1940280"
  },
  {
    "text": "to this part of kubernetes but this is something that HPC guys are definitely but you can do never placement but it",
    "start": "1940280",
    "end": "1947330"
  },
  {
    "text": "will get fragmented eventually because you place three you take four nodes and use for a job that's a dangerous throw",
    "start": "1947330",
    "end": "1952820"
  },
  {
    "text": "scale-free and then you only need two and then two are isolated I made you may not have four next to each other right",
    "start": "1952820",
    "end": "1958880"
  },
  {
    "text": "you're right I mean this is a problem that we faced in our data center and we are doing a new scheduler we have built",
    "start": "1958880",
    "end": "1965060"
  },
  {
    "text": "a new scheduler for the deep learning jobs for communities and to begin with for these large jobs we do gang",
    "start": "1965060",
    "end": "1970370"
  },
  {
    "text": "scheduling so that we know that the gang scheduler will put all these jobs on the nodes that are allocated so we demarcate",
    "start": "1970370",
    "end": "1977690"
  },
  {
    "text": "these nodes saying this is a node which will run jobs which want eight GPUs this is a node which will run which will four",
    "start": "1977690",
    "end": "1984860"
  },
  {
    "text": "jobs which want four GPS which means two jobs can fit if you had a GPS if your four jobs get creative here sixteen GPS on that box in this is a box a separate",
    "start": "1984860",
    "end": "1992120"
  },
  {
    "text": "box labeled separately the scheduler knows the notes Electra knows and everything which is going to run only",
    "start": "1992120",
    "end": "1997790"
  },
  {
    "text": "jobs which one one GPU which means we can fit sixteen jobs if there are sixteen GPUs eight jobs without using",
    "start": "1997790",
    "end": "2002890"
  },
  {
    "text": "but that's how we try to avoid that fragmentation it is an integer programming problem if you say I want to",
    "start": "2002890",
    "end": "2009430"
  },
  {
    "text": "solve everything and not have fragmentation yes it's a real problem you will have lot of what's called",
    "start": "2009430",
    "end": "2015870"
  },
  {
    "text": "efficiency issues utilization so I think we're at the top the hour at this point",
    "start": "2015870",
    "end": "2022900"
  },
  {
    "text": "so all right okay if you have any other questions I catch up with the guys afterwards outside and thank you for",
    "start": "2022900",
    "end": "2030070"
  },
  {
    "text": "coming to the session thank you thank you thank you [Music]",
    "start": "2030070",
    "end": "2035290"
  }
]
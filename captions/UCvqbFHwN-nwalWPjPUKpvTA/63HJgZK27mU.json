[
  {
    "start": "0",
    "end": "58000"
  },
  {
    "text": "Nihao and welcome to our talk building an open-source data science platform based around cute flow so just a quick",
    "start": "0",
    "end": "8670"
  },
  {
    "text": "raise of hands who has to use tensor flow before tensor flow all right I",
    "start": "8670",
    "end": "14370"
  },
  {
    "text": "guess half the room so this talk is basically about how can we move from",
    "start": "14370",
    "end": "20730"
  },
  {
    "text": "using tensor flow to words using Q flow to what's actually building a complete",
    "start": "20730",
    "end": "27330"
  },
  {
    "text": "data science pipeline with all the features from data over to models",
    "start": "27330",
    "end": "33809"
  },
  {
    "text": "serving over a notebook sharing and everything else it is based on the experience we have with a number of",
    "start": "33809",
    "end": "40800"
  },
  {
    "text": "customers mostly in us some using Q flow others just using other open source",
    "start": "40800",
    "end": "47190"
  },
  {
    "text": "technologies I'm York I'm the technical lead for data science over at mesosphere I used to be",
    "start": "47190",
    "end": "54660"
  },
  {
    "text": "a core Miso's developer actually the same as Gilbert here",
    "start": "54660",
    "end": "60140"
  },
  {
    "text": "your slide I thought you're gonna introduce me no okay - Gilbert I'm relating the",
    "start": "60140",
    "end": "67530"
  },
  {
    "text": "containerization teen atmosphere and Apache Masons PNC and committee",
    "start": "67530",
    "end": "72799"
  },
  {
    "text": "basically today's talks about as well",
    "start": "72799",
    "end": "77880"
  },
  {
    "text": "how to even run Q everyone how do we run keep pro on kubernetes on mates and",
    "start": "77880",
    "end": "82890"
  },
  {
    "text": "majors so yeah first couples like an",
    "start": "82890",
    "end": "88110"
  },
  {
    "text": "interest like why we do we want to do machine running and what's the problem",
    "start": "88110",
    "end": "93600"
  },
  {
    "text": "we are facing and what's the potential solution and potential future roommate we can have so yeah it's already like",
    "start": "93600",
    "end": "103259"
  },
  {
    "text": "the second decade of the 21st century so we have got more data and data is stored",
    "start": "103259",
    "end": "110700"
  },
  {
    "text": "in the data center and to process this data it's way too hard so people have to",
    "start": "110700",
    "end": "119159"
  },
  {
    "text": "do like the convolutions have to do like the mapping then and then they have to",
    "start": "119159",
    "end": "125490"
  },
  {
    "text": "do it again and again so it's too painful for data scientists because they might probably focus on",
    "start": "125490",
    "end": "133190"
  },
  {
    "text": "algorithm to focus on like machine learning Co and then given the data set",
    "start": "133190",
    "end": "138330"
  },
  {
    "text": "they should be supposed to train the model and then come up with a solution and but the problem here is like if they",
    "start": "138330",
    "end": "148020"
  },
  {
    "text": "want to scale up there are a lot more problem than interest off they have to manage the cluster they have to schedule",
    "start": "148020",
    "end": "155250"
  },
  {
    "text": "the resources from the cluster GPU CPU and memory and they have to do the",
    "start": "155250",
    "end": "160860"
  },
  {
    "text": "monitoring on their tasks so yeah this",
    "start": "160860",
    "end": "166140"
  },
  {
    "text": "is just another slide so as an example like we cut data everywhere from our",
    "start": "166140",
    "end": "172170"
  },
  {
    "text": "life for example like auto driving we get GPU data we got sensors we got",
    "start": "172170",
    "end": "178860"
  },
  {
    "text": "photos from the other car so and then I come from each of the vehicle and we",
    "start": "178860",
    "end": "184740"
  },
  {
    "text": "need the data sender to do with with all those data and then then assigns",
    "start": "184740",
    "end": "190740"
  },
  {
    "text": "could come up with resolution like oh this is the user behavior we should",
    "start": "190740",
    "end": "195840"
  },
  {
    "text": "improve the way we ought to peel out the card and we need to improve the way like",
    "start": "195840",
    "end": "202230"
  },
  {
    "text": "make the life easier for the drivers so it's like a batch so right now is very",
    "start": "202230",
    "end": "209750"
  },
  {
    "text": "close to us like we could have the machine learning to develop deep batch",
    "start": "209750",
    "end": "216390"
  },
  {
    "text": "for us which means like the music my potentially come from computer and",
    "start": "216390",
    "end": "221760"
  },
  {
    "text": "they're all a I've developed has has anyone actually seen that project when I",
    "start": "221760",
    "end": "227190"
  },
  {
    "text": "first saw that for the first time I was really impressed because it really sounds like for rock music so that was",
    "start": "227190",
    "end": "234510"
  },
  {
    "text": "kind of like one of my moments whoa we have really come very far with deep neural networks yeah it's not like it's",
    "start": "234510",
    "end": "241770"
  },
  {
    "text": "way too early but surprisingly like recently at least files a couple like the training project they make music",
    "start": "241770",
    "end": "248430"
  },
  {
    "text": "they have they have the machine they have the computer AI to learn like thousands of machine and then they have",
    "start": "248430",
    "end": "254940"
  },
  {
    "text": "the AI to generate their own music this Suns now too bad so okay so that's what",
    "start": "254940",
    "end": "263970"
  },
  {
    "text": "were data scientists supposed to do they supposed to focus on like imperative machine learning Co and given the data",
    "start": "263970",
    "end": "271320"
  },
  {
    "text": "sent no matter it's like large set or not they should be able to change the data for the model and then they should",
    "start": "271320",
    "end": "277650"
  },
  {
    "text": "be able to run the model and then they might want to improve the code and then do it again and again and then finally",
    "start": "277650",
    "end": "284700"
  },
  {
    "text": "they have a precise enough model for for their data training so this is I do but",
    "start": "284700",
    "end": "293160"
  },
  {
    "text": "not realistic at this moment because we've got a lot of challenge for cluster",
    "start": "293160",
    "end": "300270"
  },
  {
    "text": "management so yeah this is a is a hidden technical challenge from machine",
    "start": "300270",
    "end": "307140"
  },
  {
    "text": "learning system so as you guys can see like only the central Bret part it is",
    "start": "307140",
    "end": "314670"
  },
  {
    "text": "the machine learning and for data scientists yeah they have to do with a",
    "start": "314670",
    "end": "320430"
  },
  {
    "text": "lot of like operator responsibility development responsibility and classroom",
    "start": "320430",
    "end": "326250"
  },
  {
    "text": "management so which is not supposed to be done by them and we should have some like existing",
    "start": "326250",
    "end": "334230"
  },
  {
    "text": "project to help that have scientists and make their life easier so that's what we are doing with cube",
    "start": "334230",
    "end": "341340"
  },
  {
    "text": "Pro and this light you guys might already see this slide earlier this morning in the keynote from chakra and I",
    "start": "341340",
    "end": "349470"
  },
  {
    "text": "was surprisingly realized that oh they have the same slices and for this one",
    "start": "349470",
    "end": "354600"
  },
  {
    "text": "and basically it is a good thing to me at least it is a good thing it means",
    "start": "354600",
    "end": "360330"
  },
  {
    "text": "like in the industry in machine learning in AI different company different organization and open",
    "start": "360330",
    "end": "366479"
  },
  {
    "text": "source project we realized that similar problem we want to resolve this problem and that's it and we get started from",
    "start": "366479",
    "end": "373620"
  },
  {
    "text": "here and then coincidentally we fry the same solution cue Pro here yeah I think",
    "start": "373620",
    "end": "380250"
  },
  {
    "text": "as you guys can see like each of this prompt it might not be easy resource",
    "start": "380250",
    "end": "385860"
  },
  {
    "text": "management no matter kinetics or measures we have different with resource scaling strategy",
    "start": "385860",
    "end": "391169"
  },
  {
    "text": "and people might need to deal with some low-level things like GPU topology to improve the performance then",
    "start": "391169",
    "end": "397770"
  },
  {
    "text": "might need to deal with like the continued runtime potentially the prevalence Muslim or isolation for data",
    "start": "397770",
    "end": "403139"
  },
  {
    "text": "science data scientist and those may not be the things necessary for data",
    "start": "403139",
    "end": "409050"
  },
  {
    "text": "scientists to understand we want we expect like data scientists just focus",
    "start": "409050",
    "end": "414509"
  },
  {
    "text": "on what they should focus on on just focus on like developing the best",
    "start": "414509",
    "end": "421879"
  },
  {
    "text": "algorithm for machine learning and then change the model that's it okay so we",
    "start": "421879",
    "end": "429539"
  },
  {
    "text": "come up with a solution q pro so Q pro unified different",
    "start": "429539",
    "end": "435090"
  },
  {
    "text": "training model and then it come up with the pipeline with different parts of",
    "start": "435090",
    "end": "440280"
  },
  {
    "text": "this training distributed system so it included included like data preparation",
    "start": "440280",
    "end": "447440"
  },
  {
    "text": "press the model engineering from the jupiter notebook and it also integrated",
    "start": "447440",
    "end": "453349"
  },
  {
    "text": "that's the major part from the tensor fro but for model training for like",
    "start": "453349",
    "end": "458759"
  },
  {
    "text": "monitoring and then it come up with some sets the right ruling for the back purpose and as well as like the model",
    "start": "458759",
    "end": "465990"
  },
  {
    "text": "serving from the pensive row this is a quick definition about q pro for any for",
    "start": "465990",
    "end": "473699"
  },
  {
    "text": "folks who never touch q felt before so basically a q proof project is dedicated to make deployment of machine",
    "start": "473699",
    "end": "481770"
  },
  {
    "text": "learning workflow on kubernetes simple portable and scalable so yeah scallop",
    "start": "481770",
    "end": "489569"
  },
  {
    "text": "scalability is always the biggest problem for assistant engineer for this",
    "start": "489569",
    "end": "494969"
  },
  {
    "text": "building season is never easy so you might hurt a lot of story from those becoming like Alibaba like 10 like",
    "start": "494969",
    "end": "503190"
  },
  {
    "text": "Tenzin and many other companies like Google Twitter so they scale up to like",
    "start": "503190",
    "end": "508969"
  },
  {
    "text": "hundred of thousands of machine and even 1 million machine but a lot of work they",
    "start": "508969",
    "end": "515430"
  },
  {
    "text": "might have like 1,000 engineer team to scout that up to improve the kernel to improve the core component of their",
    "start": "515430",
    "end": "522450"
  },
  {
    "text": "scarran's scheduling system and then they might also do a lot of",
    "start": "522450",
    "end": "527720"
  },
  {
    "text": "limitation on the schedule to improve the performance so we more a lot more",
    "start": "527720",
    "end": "533640"
  },
  {
    "text": "discussion about scalability but yeah today's part we're gonna focus on cue",
    "start": "533640",
    "end": "539460"
  },
  {
    "text": "Pro so yep so the next I gonna have my colleague yoke so introduce the detail",
    "start": "539460",
    "end": "546690"
  },
  {
    "text": "on cue Pro and our adventury so first of",
    "start": "546690",
    "end": "551970"
  },
  {
    "text": "all couplet was started actually last year and just yesterday they announced",
    "start": "551970",
    "end": "557339"
  },
  {
    "text": "the ODA 3 release so congratulations to the entire queue flow community it's",
    "start": "557339",
    "end": "562950"
  },
  {
    "text": "really great to see and it was really cool to see the progress I've been making towards that this is also another",
    "start": "562950",
    "end": "569790"
  },
  {
    "text": "talk from yesterday from Aaron and Fay about this last year of cube flow",
    "start": "569790",
    "end": "576899"
  },
  {
    "text": "basically and anyone who's interested in cube flow I would really recommend watching the recording later on because",
    "start": "576899",
    "end": "583560"
  },
  {
    "text": "real focus in this talk will focus a bit like on what's happening around will not",
    "start": "583560",
    "end": "588690"
  },
  {
    "text": "cover so much of see details of cue flow itself more like what are best practices around what do I need to build like a",
    "start": "588690",
    "end": "595080"
  },
  {
    "text": "scalable data science platform and operates that in general so just a quick",
    "start": "595080",
    "end": "601230"
  },
  {
    "text": "question how many of you have seen this image or actually read that paper so",
    "start": "601230",
    "end": "606260"
  },
  {
    "text": "this is tensor flow extended and this was kind of see it's kind of the",
    "start": "606260",
    "end": "612350"
  },
  {
    "text": "motivation or kind of used to be the guiding principle for a cue flow so this",
    "start": "612350",
    "end": "619500"
  },
  {
    "text": "is about like how Google this machine learning and it's about the entire pipeline and a lot of different pieces",
    "start": "619500",
    "end": "626610"
  },
  {
    "text": "in the tensor flow ecosystem have been actually developed from this and just",
    "start": "626610",
    "end": "632310"
  },
  {
    "text": "cue flow actually has evolved further from this goal or original motivation so",
    "start": "632310",
    "end": "638610"
  },
  {
    "text": "if we look at it today and this is what I found really amazing over just one year we actually we are not just focused",
    "start": "638610",
    "end": "645029"
  },
  {
    "text": "on tensor flow itself anymore we also have pi torch in there there's also some MX net support we have hyper parameter",
    "start": "645029",
    "end": "652800"
  },
  {
    "text": "optimization we have a lot of other ecosystem projects stepping in here like",
    "start": "652800",
    "end": "657990"
  },
  {
    "text": "Seldon AI for serving model DB being used to store metadata for models so it's actually not just",
    "start": "657990",
    "end": "665750"
  },
  {
    "text": "tensorflow anymore it's going back to this original goal we saw earlier about becoming the",
    "start": "665750",
    "end": "673380"
  },
  {
    "text": "default kind of pipeline to orchestrate and deploy machine learning pipelines everywhere still even if we have this",
    "start": "673380",
    "end": "682709"
  },
  {
    "text": "pipeline in my opinion cube flow works really well if I am I'm in a cloud",
    "start": "682709",
    "end": "688680"
  },
  {
    "text": "environment if I'm on Google cloud if I'm on Amazon if I'm on Alibaba cloud",
    "start": "688680",
    "end": "694140"
  },
  {
    "text": "this works really well because they are still some hidden pieces missing so if",
    "start": "694140",
    "end": "700410"
  },
  {
    "text": "I'm in a cloud I actually have access to cloud storage so I can store my data sets I can store my model somewhere in a",
    "start": "700410",
    "end": "708420"
  },
  {
    "text": "persistent fashion I typically have access to some kind of way to do a batch",
    "start": "708420",
    "end": "714000"
  },
  {
    "text": "data pre-processing I have some kind of stream systems where I can actually",
    "start": "714000",
    "end": "719790"
  },
  {
    "text": "stream my requests and while I'm in a cloud environment I can simply use all",
    "start": "719790",
    "end": "725490"
  },
  {
    "text": "of that not necessarily for free but I as a developer I don't necessarily have",
    "start": "725490",
    "end": "731220"
  },
  {
    "text": "to care about that now many of our customers many of our users especially",
    "start": "731220",
    "end": "738300"
  },
  {
    "text": "in Europe or environments which are like constraint which data can be uploaded to",
    "start": "738300",
    "end": "743610"
  },
  {
    "text": "the cloud they actually try to build something similar in their own data center so there are a lot of open source",
    "start": "743610",
    "end": "750660"
  },
  {
    "text": "tools available so for example SPARC is a really great tool to do data",
    "start": "750660",
    "end": "755940"
  },
  {
    "text": "pre-processing or in general like the entire beam integration if I want that",
    "start": "755940",
    "end": "762480"
  },
  {
    "text": "more abstracted HDFS is a great data store for unstructured data I can use",
    "start": "762480",
    "end": "769079"
  },
  {
    "text": "Kafka to pipe my requests - what's my serving layer so it's just I all the",
    "start": "769079",
    "end": "776670"
  },
  {
    "text": "sudden once I try to build that in my own environment so in an on-prem cluster I start to have",
    "start": "776670",
    "end": "783720"
  },
  {
    "text": "to consider all those different components missing which I just get for free in a cloud environment here so in",
    "start": "783720",
    "end": "791819"
  },
  {
    "start": "790000",
    "end": "1261000"
  },
  {
    "text": "the end so the typically like the advanced picture so this is what we see people building over",
    "start": "791819",
    "end": "797640"
  },
  {
    "text": "years and most likely not having all of that but let's just simply go through",
    "start": "797640",
    "end": "803160"
  },
  {
    "text": "what different steps are actually needed in such kind of pipeline what I really liked in the keynote this morning it",
    "start": "803160",
    "end": "809760"
  },
  {
    "text": "touched up on some points which are very dear to me especially its the challenges so you might actually recognize some of",
    "start": "809760",
    "end": "817350"
  },
  {
    "text": "those points from this morning's keynote so it all starts with like data and streaming I need to have access to data",
    "start": "817350",
    "end": "823890"
  },
  {
    "text": "sets at best I have like versioned access to data sets there are a number of companies actually trying to get",
    "start": "823890",
    "end": "830970"
  },
  {
    "text": "better support sir we kursk it doesn't really work for large files there's for example dot science I've seen some of",
    "start": "830970",
    "end": "837750"
  },
  {
    "text": "their people here as well which give me a virgin' access to data sets I can also",
    "start": "837750",
    "end": "843390"
  },
  {
    "text": "just have a data stream so it doesn't have to be fixed data set many systems just have streaming data and so I could",
    "start": "843390",
    "end": "850590"
  },
  {
    "text": "have like a Kafka stream of data which I might actually also use snapshots for for training and so this is kind of the",
    "start": "850590",
    "end": "857700"
  },
  {
    "text": "first a basis layer but it's really important and we'll come back to some more details here in a second the second",
    "start": "857700",
    "end": "864960"
  },
  {
    "text": "part and this is where my data scientist really wants to focus on this is the model engineering this is the data",
    "start": "864960",
    "end": "870720"
  },
  {
    "text": "preparation and model building so this is really typically Jupiter how many of",
    "start": "870720",
    "end": "876480"
  },
  {
    "text": "you know Jupiter as a project or have used it some for those of you who",
    "start": "876480",
    "end": "882120"
  },
  {
    "text": "haven't I would really recommend it it's a really nice way to get started with data science without having to worry",
    "start": "882120",
    "end": "888420"
  },
  {
    "text": "about too many of the details and so as mentioned this is like where my data",
    "start": "888420",
    "end": "893550"
  },
  {
    "text": "scientist he can go in he can prepare that data set he can extract features and then the next layer is actually",
    "start": "893550",
    "end": "901440"
  },
  {
    "text": "modeled training model trainings this is really where most of the resources GPUs",
    "start": "901440",
    "end": "906450"
  },
  {
    "text": "TPU CPUs are flowing in where I have different hyper parameter runs and this",
    "start": "906450",
    "end": "914640"
  },
  {
    "text": "is something where typically more like dev ops people should come in because they actually understand distributed",
    "start": "914640",
    "end": "921180"
  },
  {
    "text": "training and distributed computation once I'm done with training I have a",
    "start": "921180",
    "end": "926880"
  },
  {
    "text": "of models which I need to store and I not only need to store the models but",
    "start": "926880",
    "end": "932670"
  },
  {
    "text": "even or equally important I also have to store the metadata of those models how",
    "start": "932670",
    "end": "938760"
  },
  {
    "text": "what was the Train accuracy what was the validation accuracy to all those",
    "start": "938760",
    "end": "944820"
  },
  {
    "text": "different statistics because here I later on from the model management layer",
    "start": "944820",
    "end": "950640"
  },
  {
    "text": "I actually have to select the models I want to serve for production workloads and that might depend on questions like",
    "start": "950640",
    "end": "957420"
  },
  {
    "text": "give me the best performing model for a GPU environment which takes less than of",
    "start": "957420",
    "end": "964880"
  },
  {
    "text": "0.5 seconds to do inference so I need a lot of this metadata to actually choose",
    "start": "964880",
    "end": "971610"
  },
  {
    "text": "the different models I want to serve later on in production so this is the simple pipeline walkthrough but around",
    "start": "971610",
    "end": "978990"
  },
  {
    "text": "that we have a lot of other pieces already this morning we it was mentioned that we need 2 different kinds of",
    "start": "978990",
    "end": "985350"
  },
  {
    "text": "monitoring systems the first one is kind of fuzzy models for the data science or",
    "start": "985350",
    "end": "990540"
  },
  {
    "text": "data scientists themselves and this is focus yeah on the model it's on the model accuracy and this is typically",
    "start": "990540",
    "end": "996990"
  },
  {
    "text": "something like cancer board secondly as this is becoming a fairly complex",
    "start": "996990",
    "end": "1002350"
  },
  {
    "text": "architecture we also need some systems to actually monitor this architecture itself all right then if we continue",
    "start": "1002350",
    "end": "1010580"
  },
  {
    "text": "down here we mentioned like C data is very very important and data scientists",
    "start": "1010580",
    "end": "1017480"
  },
  {
    "text": "they typically spend 60 to 70% of their time preparing their data sets so for",
    "start": "1017480",
    "end": "1024199"
  },
  {
    "text": "example cleaning up the data set converting or everything to like a",
    "start": "1024199",
    "end": "1029569"
  },
  {
    "text": "common hopefully metric system based from it maybe extracting specific",
    "start": "1029569",
    "end": "1036800"
  },
  {
    "text": "features so if I'm building a fraud model for example I only care about that",
    "start": "1036800",
    "end": "1042260"
  },
  {
    "text": "I have some representation of a user and this can actually be shared amongst different data scientist and this is why",
    "start": "1042260",
    "end": "1050060"
  },
  {
    "text": "a component such as a feature feature catalog or other systems they also call",
    "start": "1050060",
    "end": "1056120"
  },
  {
    "text": "it features stores become really important because as mentioned if I invest sixty to",
    "start": "1056120",
    "end": "1061750"
  },
  {
    "text": "seventy percent of my data scientists time in developing those features and",
    "start": "1061750",
    "end": "1066940"
  },
  {
    "text": "cleaning the data sets this is something which should be shared between different data scientists the second part is",
    "start": "1066940",
    "end": "1073419"
  },
  {
    "text": "actually all this work here this kid is fairly automatic so a data scientist",
    "start": "1073419",
    "end": "1078909"
  },
  {
    "text": "shouldn't have to worry to start his training runs or anything else and from traditional software engineering we",
    "start": "1078909",
    "end": "1085510"
  },
  {
    "text": "actually have techniques to deal with that continuous integration maybe even continuous delivery if we want to deploy",
    "start": "1085510",
    "end": "1092320"
  },
  {
    "text": "the models later on into production so having some kind of CI CI c deep",
    "start": "1092320",
    "end": "1098080"
  },
  {
    "text": "pipeline here really is taking off a lot of load from the data scientist to have to train that manually and it also which",
    "start": "1098080",
    "end": "1105970"
  },
  {
    "text": "we'll see in a second helps us with reproducibility the other piece which is we already mentioned like so stupid in",
    "start": "1105970",
    "end": "1113080"
  },
  {
    "text": "notebooks they are very very helpful and very very important so I also want to share those notebooks between different",
    "start": "1113080",
    "end": "1119590"
  },
  {
    "text": "people and so something like binder those of you who haven't seen binder",
    "start": "1119590",
    "end": "1124809"
  },
  {
    "text": "it's a really cool open source project which basically allows me to store and I",
    "start": "1124809",
    "end": "1129970"
  },
  {
    "text": "PI some notebooks or a jupiter notebook to github and then simply say gives that",
    "start": "1129970",
    "end": "1135399"
  },
  {
    "text": "link to anyone else and they can simply run it without having to spin up any infrastructure binder or they are also",
    "start": "1135399",
    "end": "1142149"
  },
  {
    "text": "like open source projects running that like called my binder for example or",
    "start": "1142149",
    "end": "1148120"
  },
  {
    "text": "google also has something very similar they give you an executable form of your",
    "start": "1148120",
    "end": "1153309"
  },
  {
    "text": "jupiter notebook I can just sent it to Gilbert here and he doesn't have to set up Jupiter itself he can just run that",
    "start": "1153309",
    "end": "1159429"
  },
  {
    "text": "from this web link which is really cool the other thing I actually really want to share are my trained models so having",
    "start": "1159429",
    "end": "1166840"
  },
  {
    "text": "something like tensorflow hop or a model library is really useful first of all",
    "start": "1166840",
    "end": "1172179"
  },
  {
    "text": "for sharing sea trained models but also later on for transfer learning so",
    "start": "1172179",
    "end": "1177580"
  },
  {
    "text": "transfer learning I would go in I take a fully trained model like imagenet or something like that",
    "start": "1177580",
    "end": "1183340"
  },
  {
    "text": "I go in I take away the last few layers and then I specialized that to my",
    "start": "1183340",
    "end": "1188620"
  },
  {
    "text": "specific data set but using this using this preacher a model it really reduces the amount of",
    "start": "1188620",
    "end": "1195750"
  },
  {
    "text": "time I and resources I have to invest into training and it also reduces the",
    "start": "1195750",
    "end": "1201120"
  },
  {
    "text": "data set size I actually need to train that because most of the base features",
    "start": "1201120",
    "end": "1207330"
  },
  {
    "text": "already been covered by this pre trained model here so having a platform where I",
    "start": "1207330",
    "end": "1212669"
  },
  {
    "text": "can actually share and reuse models retrain models it's also quite important",
    "start": "1212669",
    "end": "1218630"
  },
  {
    "text": "last underneath we actually need something to manage all those resources",
    "start": "1218630",
    "end": "1223679"
  },
  {
    "text": "to manage all those different distributed systems so if we just count we got like Kafka Cassandra HDFS Jupiter",
    "start": "1223679",
    "end": "1231870"
  },
  {
    "text": "is more like a container service but here we got 10 to flow SPARC PI torch so",
    "start": "1231870",
    "end": "1237179"
  },
  {
    "text": "we actually end up with a large number of different distributed systems which we all have to manage and this is really",
    "start": "1237179",
    "end": "1245130"
  },
  {
    "text": "hard for like a DevOps person to set all this up in just a manual fashion so",
    "start": "1245130",
    "end": "1250140"
  },
  {
    "text": "having like a layer 4 first of all the resource management and then also for service management is really really",
    "start": "1250140",
    "end": "1257370"
  },
  {
    "text": "important and really helps us to set up such kind of pipeline all right yes just",
    "start": "1257370",
    "end": "1264870"
  },
  {
    "start": "1261000",
    "end": "1366000"
  },
  {
    "text": "one quick one let me talk about like the challenge of like having different like",
    "start": "1264870",
    "end": "1270510"
  },
  {
    "text": "machine learning framework did learning framework running on the same cluster we do have a customer like surfer from like",
    "start": "1270510",
    "end": "1278970"
  },
  {
    "text": "oh when they realize they want to run spark which is like best John and Grady framework and then they're on to 110",
    "start": "1278970",
    "end": "1286110"
  },
  {
    "text": "serpro while they also want to run the Cassandra and Kappa on the same cluster and head and then have one single",
    "start": "1286110",
    "end": "1292380"
  },
  {
    "text": "cluster to manage all those distributed system and machine learning workflow and that's really painful for at least for",
    "start": "1292380",
    "end": "1301110"
  },
  {
    "text": "data scientist to manage the whole cluster because like some some of the tasks they are quitting and then they",
    "start": "1301110",
    "end": "1307649"
  },
  {
    "text": "will occupy other resources and for data scientist it's hard really hard for them",
    "start": "1307649",
    "end": "1313649"
  },
  {
    "text": "to realize oh we need to introduce more like scheduling strategy to make it more",
    "start": "1313649",
    "end": "1320010"
  },
  {
    "text": "scalable actually this is what the next slide is about see data scientist himself he wants to be the superhero",
    "start": "1320010",
    "end": "1326130"
  },
  {
    "text": "writing really cool code and he shouldn't have to worry about distribution or distribution strategies",
    "start": "1326130",
    "end": "1331920"
  },
  {
    "text": "he should really be able to focus on his models and this is why we typically see",
    "start": "1331920",
    "end": "1337350"
  },
  {
    "text": "different personas being introduced and so he actually he needs a sidekick helping him to be still be this really",
    "start": "1337350",
    "end": "1344910"
  },
  {
    "text": "cool superhero and this is typically like today it's either referred to as",
    "start": "1344910",
    "end": "1350070"
  },
  {
    "text": "data engineer it's more like a DevOps person which is really helping this guy",
    "start": "1350070",
    "end": "1358410"
  },
  {
    "text": "in controlling the entire infrastructure with helping the data scientists to be",
    "start": "1358410",
    "end": "1364500"
  },
  {
    "text": "able to focus on his models the next challenge is actually then a data",
    "start": "1364500",
    "end": "1370470"
  },
  {
    "start": "1366000",
    "end": "1484000"
  },
  {
    "text": "quality as mentioned earlier typically this is what most people underestimate",
    "start": "1370470",
    "end": "1376770"
  },
  {
    "text": "if they start with that first amnesty I suppose everyone who is started with tensorflow has probably",
    "start": "1376770",
    "end": "1384060"
  },
  {
    "text": "done like this amnesty example right I download the pre clean data set I go in",
    "start": "1384060",
    "end": "1389400"
  },
  {
    "text": "there and I can directly train my model but in reality unfortunately this is not",
    "start": "1389400",
    "end": "1395280"
  },
  {
    "text": "the case so demo data sets are a fortunate exception here but typically I",
    "start": "1395280",
    "end": "1400410"
  },
  {
    "text": "really spend a large amount of my time as a data scientist and preparing my",
    "start": "1400410",
    "end": "1406050"
  },
  {
    "text": "entire data quality and the kind of promise of deep learning especially is",
    "start": "1406050",
    "end": "1412410"
  },
  {
    "text": "that everything is being derived from the data itself so just keep in mind if",
    "start": "1412410",
    "end": "1418200"
  },
  {
    "text": "your data is of bad quality your model will be of bad quality as well the other",
    "start": "1418200",
    "end": "1423780"
  },
  {
    "text": "important lesson is and I actually seen that at a user site is if you update",
    "start": "1423780",
    "end": "1429900"
  },
  {
    "text": "your procedures your pipeline to do the data preparation you also need to update",
    "start": "1429900",
    "end": "1436530"
  },
  {
    "text": "the same procedure to your real-life data coming into the serving layer here so actually what those people did they",
    "start": "1436530",
    "end": "1444150"
  },
  {
    "text": "came up with a really cool way a new way so they had an existing pipeline running in production and then they stepped in",
    "start": "1444150",
    "end": "1451940"
  },
  {
    "text": "and improved the way they were cleaning and preparing their data sets their",
    "start": "1451940",
    "end": "1458160"
  },
  {
    "text": "models had much quality much better accuracy but once",
    "start": "1458160",
    "end": "1463420"
  },
  {
    "text": "they deployed him to production it had really bad quality what happened",
    "start": "1463420",
    "end": "1468640"
  },
  {
    "text": "they didn't update the data cleaning procedures in the serving environment",
    "start": "1468640",
    "end": "1473920"
  },
  {
    "text": "for the live production data so that was still kind of the old data format which",
    "start": "1473920",
    "end": "1480670"
  },
  {
    "text": "obviously didn't match those two those new models here and so this is actually",
    "start": "1480670",
    "end": "1489940"
  },
  {
    "start": "1484000",
    "end": "1546000"
  },
  {
    "text": "this was a sly I was looking for earlier here this is actually this division of labor so if we jump back here to our",
    "start": "1489940",
    "end": "1496690"
  },
  {
    "text": "like superhero data scientist plus his sidekick this is the earlier image we",
    "start": "1496690",
    "end": "1502960"
  },
  {
    "text": "saw with all the different challenges and now we actually can divide this between different personas so the data",
    "start": "1502960",
    "end": "1510070"
  },
  {
    "text": "scientists he can actually focus on riding his machine learning code on preparing data on exploring data on",
    "start": "1510070",
    "end": "1517930"
  },
  {
    "text": "extracting features maybe he needs to do like some model monitoring but overall",
    "start": "1517930",
    "end": "1523300"
  },
  {
    "text": "he can really focus on being a data scientist and most data scientists I",
    "start": "1523300",
    "end": "1528880"
  },
  {
    "text": "know they also they have more like a mathematical background so this is what they like do it and now we have those",
    "start": "1528880",
    "end": "1534820"
  },
  {
    "text": "other people like the data engineer data ops engineer and they can actually help with all the stuff around which often",
    "start": "1534820",
    "end": "1542410"
  },
  {
    "text": "also requires more knowledge about distributed computation and yeah this is",
    "start": "1542410",
    "end": "1548710"
  },
  {
    "text": "so this is kind of this rise of sis data off Stata engineers the people I seen",
    "start": "1548710",
    "end": "1554440"
  },
  {
    "text": "it's really really hard to find them but they are combining two key skills first of all date of science and secondly they",
    "start": "1554440",
    "end": "1561400"
  },
  {
    "text": "actually understand distributed systems fairly well because this is the",
    "start": "1561400",
    "end": "1567040"
  },
  {
    "text": "challenge they have to match this world of data science with the distributed",
    "start": "1567040",
    "end": "1572290"
  },
  {
    "text": "systems engineering quiz actually controlling all those different systems we've seen earlier if you want it's kind",
    "start": "1572290",
    "end": "1578500"
  },
  {
    "text": "of like this DevOps person but for like data science in particular",
    "start": "1578500",
    "end": "1584549"
  },
  {
    "start": "1584000",
    "end": "1617000"
  },
  {
    "text": "this is actually Z of the original paper it's the first publication on software",
    "start": "1584780",
    "end": "1592670"
  },
  {
    "text": "engineering there was a mentioning before but it actually software",
    "start": "1592670",
    "end": "1597830"
  },
  {
    "text": "engineering is something where I feel we can learn a lot for data science I feel data science right now is in a state",
    "start": "1597830",
    "end": "1603860"
  },
  {
    "text": "software engineering was like around nineteen forty sixty eight where",
    "start": "1603860",
    "end": "1609470"
  },
  {
    "text": "everyone was doing stuff very ad hoc everyone was trying to figure out his or",
    "start": "1609470",
    "end": "1614990"
  },
  {
    "text": "her own ways of doing things and so I would actually post that question do we",
    "start": "1614990",
    "end": "1620480"
  },
  {
    "start": "1617000",
    "end": "1639000"
  },
  {
    "text": "need something similar for data science do we need something like data science engineering principles so a systematic",
    "start": "1620480",
    "end": "1627910"
  },
  {
    "text": "quantifiable approach to the development of models and also then the testing of",
    "start": "1627910",
    "end": "1634310"
  },
  {
    "text": "models and everything around which we actually have learned in software engineering and people like Ian good",
    "start": "1634310",
    "end": "1641870"
  },
  {
    "start": "1639000",
    "end": "1658000"
  },
  {
    "text": "fella for example they also have similar opinions so this is what we are currently working on in the Bay Area",
    "start": "1641870",
    "end": "1648050"
  },
  {
    "text": "with other big ml users such as uber and",
    "start": "1648050",
    "end": "1653270"
  },
  {
    "text": "other big companies doing ml which names we are not allowed to mention on stage I",
    "start": "1653270",
    "end": "1660100"
  },
  {
    "start": "1658000",
    "end": "1764000"
  },
  {
    "text": "always feel this first challenge if we look at software engineering is like requirements engineering how do I come",
    "start": "1660100",
    "end": "1666950"
  },
  {
    "text": "up with the requirements I need before I start developing my model and there",
    "start": "1666950",
    "end": "1672500"
  },
  {
    "text": "having talked to a lot of people the most important question someone should ask if he's told to develop like a deep",
    "start": "1672500",
    "end": "1680420"
  },
  {
    "text": "neural network is is that does it actually make sense I currently feel that especially neural",
    "start": "1680420",
    "end": "1686330"
  },
  {
    "text": "networks they are very very powerful but they often we apply them to problems",
    "start": "1686330",
    "end": "1691850"
  },
  {
    "text": "where they don't really match so especially if for example if I have a small data set which might not be",
    "start": "1691850",
    "end": "1698810"
  },
  {
    "text": "sufficient to train an entire neural network if it's a bad data quality or",
    "start": "1698810",
    "end": "1703820"
  },
  {
    "text": "actually my function is also pretty similar something like support vector",
    "start": "1703820",
    "end": "1708920"
  },
  {
    "text": "machine so even like logistic regressions can be very very powerful so we shouldn't just blindly use deep",
    "start": "1708920",
    "end": "1715640"
  },
  {
    "text": "neural networks because this is what our CTO has just read about other requirements I",
    "start": "1715640",
    "end": "1721790"
  },
  {
    "text": "should gather is like what is actually my target and serving environment will I",
    "start": "1721790",
    "end": "1726860"
  },
  {
    "text": "serve sat in a car where you need likes ups second response times will I serve",
    "start": "1726860",
    "end": "1732110"
  },
  {
    "text": "that in a large cluster way I have a lot of GPUs available so what is kind of the resources I have in my serving",
    "start": "1732110",
    "end": "1739340"
  },
  {
    "text": "requirement where later on I will use that model and also what are the guarantees so what timing guarantees do",
    "start": "1739340",
    "end": "1746600"
  },
  {
    "text": "I have to have other questions are there pre-trained models available I believe",
    "start": "1746600",
    "end": "1751970"
  },
  {
    "text": "most of us shouldn't they actually develop new models people like Google or research have actually come up with a",
    "start": "1751970",
    "end": "1758660"
  },
  {
    "text": "lot of really cool model architectures and there's a lot we can actually reuse here the next biggest challenge and this",
    "start": "1758660",
    "end": "1767720"
  },
  {
    "start": "1764000",
    "end": "1864000"
  },
  {
    "text": "is where I see most companies actually fail is reproducible builds still data",
    "start": "1767720",
    "end": "1773870"
  },
  {
    "text": "science right now it's a very ad hoc process data scientist goes in he's playing with the data he's playing with",
    "start": "1773870",
    "end": "1780530"
  },
  {
    "text": "this model once the accuracy looks good he goes over to the dev ops engineer or",
    "start": "1780530",
    "end": "1786350"
  },
  {
    "text": "some kind of ops person and tells them here's my model please deploy that to production and so",
    "start": "1786350",
    "end": "1793760"
  },
  {
    "text": "what we seen is that even just going back and say can we retrain this model",
    "start": "1793760",
    "end": "1799640"
  },
  {
    "text": "with the same data set or with an updated data set often becomes a challenge in different environments so",
    "start": "1799640",
    "end": "1806510"
  },
  {
    "text": "especially if you have to deal with regulatory requirements for example in finance or healthcare this is like a big",
    "start": "1806510",
    "end": "1813800"
  },
  {
    "text": "challenge and so two projects which I really find helpful there when I first",
    "start": "1813800",
    "end": "1820490"
  },
  {
    "text": "prepared that cube flow pipelines weren't out there yet but they just",
    "start": "1820490",
    "end": "1825500"
  },
  {
    "text": "announced also cube flow pipelines and m/l flow both of them they give me a way",
    "start": "1825500",
    "end": "1831680"
  },
  {
    "text": "to get an artifact of my data of my entire pipeline flow so I can actually",
    "start": "1831680",
    "end": "1837440"
  },
  {
    "text": "go in and reproducibly train that the other aspect which I find really important here is again the continuous",
    "start": "1837440",
    "end": "1845030"
  },
  {
    "text": "integration part because it actually forces me to create a reproducible artifact so",
    "start": "1845030",
    "end": "1852110"
  },
  {
    "text": "my if the entire training process is being taken care of by my CI CD pipeline",
    "start": "1852110",
    "end": "1857899"
  },
  {
    "text": "I actually have to create a reproducible artifact because otherwise it cannot be",
    "start": "1857899",
    "end": "1863419"
  },
  {
    "text": "trained just real brief as probably more people are familiar with cube flow",
    "start": "1863419",
    "end": "1869120"
  },
  {
    "start": "1864000",
    "end": "1904000"
  },
  {
    "text": "pipelines ml flow m/l flow is a project by data breaks the guys behind spark and",
    "start": "1869120",
    "end": "1875980"
  },
  {
    "text": "the sub project here I like most is actually the project's part because it",
    "start": "1875980",
    "end": "1882620"
  },
  {
    "text": "gives me a packaging format it's very very simple but it gives me a packaging",
    "start": "1882620",
    "end": "1888289"
  },
  {
    "text": "format for reproducible runs on any platform so I can go in and just retrain",
    "start": "1888289",
    "end": "1893299"
  },
  {
    "text": "my model q flow pipelines to something similar but I said you can use both it",
    "start": "1893299",
    "end": "1899690"
  },
  {
    "text": "probably depends a little on also the surrounding parts and so then and this",
    "start": "1899690",
    "end": "1907730"
  },
  {
    "start": "1904000",
    "end": "1958000"
  },
  {
    "text": "is again coming back to this division between different personas as well it's",
    "start": "1907730",
    "end": "1913519"
  },
  {
    "text": "again so here we have the data scientist up here so he can deal with this dataset",
    "start": "1913519",
    "end": "1918919"
  },
  {
    "text": "he can use his Jupiter notebook to explore his data to come up with a model",
    "start": "1918919",
    "end": "1925130"
  },
  {
    "text": "and once he's done he's actually currently this is typically a gift",
    "start": "1925130",
    "end": "1930919"
  },
  {
    "text": "commit but once he's done he doesn't get commits from his Jupiter notebook and this is actually triggering the C ICD",
    "start": "1930919",
    "end": "1939350"
  },
  {
    "text": "pipeline so we have taken care of all the distributed training model testing",
    "start": "1939350",
    "end": "1944600"
  },
  {
    "text": "model optimizations model storage and if I actually want to do also continues CD",
    "start": "1944600",
    "end": "1952190"
  },
  {
    "text": "I can even then put it into serving into production with that so this is for",
    "start": "1952190",
    "end": "1961789"
  },
  {
    "start": "1958000",
    "end": "2000000"
  },
  {
    "text": "those of you who haven't seen Jupiter this is kind of what Jupiter looks like so this is the first view if I go in and",
    "start": "1961789",
    "end": "1970149"
  },
  {
    "text": "actually I can simply in the web browser I can write on my Python code I can write my Scala code for SPARC I can",
    "start": "1970149",
    "end": "1978980"
  },
  {
    "text": "write Java code so I don't have to set up my own environment and I can then also execute it from there I",
    "start": "1978980",
    "end": "1987620"
  },
  {
    "text": "can export those notebooks I can share them so they're just a very nice way for",
    "start": "1987620",
    "end": "1992720"
  },
  {
    "text": "data scientist of not having to deal with setting up infrastructure and actually being able to focus on their",
    "start": "1992720",
    "end": "1999080"
  },
  {
    "text": "real work [Music] the other challenge about this data",
    "start": "1999080",
    "end": "2006700"
  },
  {
    "start": "2000000",
    "end": "2081000"
  },
  {
    "text": "quality or data pre-processing and this is the feature catalog we saw earlier",
    "start": "2006700",
    "end": "2011710"
  },
  {
    "text": "and this is basically about this work we want to share in cleaning and preparing",
    "start": "2011710",
    "end": "2017230"
  },
  {
    "text": "the data set which we can for example if we are in Q flow we often or intensive",
    "start": "2017230",
    "end": "2023860"
  },
  {
    "text": "flow like we do TF transform but once we have done that and it ends up in this",
    "start": "2023860",
    "end": "2030880"
  },
  {
    "text": "like one big pipeline I cannot simply share that with other people so everyone",
    "start": "2030880",
    "end": "2036010"
  },
  {
    "text": "who is coming up with like a fraud detection model or who wants to use user",
    "start": "2036010",
    "end": "2041710"
  },
  {
    "text": "data has to come up with his or her own way to actually prepare all this user",
    "start": "2041710",
    "end": "2046870"
  },
  {
    "text": "data and come up with a user data representation with a user data feature",
    "start": "2046870",
    "end": "2051879"
  },
  {
    "text": "and so therefore a feature catalog is really useful to share that so it's kind",
    "start": "2051880",
    "end": "2058270"
  },
  {
    "text": "of like a pre-processing cache I can even cache the prepared data sets and then also discovery components that",
    "start": "2058270",
    "end": "2065590"
  },
  {
    "text": "other people can find and reuse that and a a really highly recommended resource",
    "start": "2065590",
    "end": "2071500"
  },
  {
    "text": "is it's called Michelangelo by uber so they actually in their blog post they",
    "start": "2071500",
    "end": "2078520"
  },
  {
    "text": "talked a lot about this feature catalog other thing again our model libraries so",
    "start": "2078520",
    "end": "2085750"
  },
  {
    "start": "2081000",
    "end": "2122000"
  },
  {
    "text": "in normal software engineering we deal a lot with libraries we should do something similar in data science so we",
    "start": "2085750",
    "end": "2092740"
  },
  {
    "text": "can reuse pre-trained data sets we can use pre trained and embeddings we don't",
    "start": "2092740",
    "end": "2099520"
  },
  {
    "text": "have to come up with everything from scratch we don't have to train everything from scratch so also this is",
    "start": "2099520",
    "end": "2105400"
  },
  {
    "text": "something I seen organizations set it up in their organization and simply share",
    "start": "2105400",
    "end": "2110620"
  },
  {
    "text": "all this and it really boosted the productivity and it also reduced the",
    "start": "2110620",
    "end": "2116380"
  },
  {
    "text": "amount of resources they had to spend on compute GPUs CPUs I",
    "start": "2116380",
    "end": "2122220"
  },
  {
    "start": "2122000",
    "end": "2186000"
  },
  {
    "text": "got one minute all right then let me jump through here let me see all right",
    "start": "2122220",
    "end": "2129820"
  },
  {
    "text": "hyper parameter optimization also very important but there was actually this is",
    "start": "2129820",
    "end": "2136089"
  },
  {
    "text": "being covered all of the previous slides up covered in the Q flow talk itself one other thing I would really highly",
    "start": "2136089",
    "end": "2143770"
  },
  {
    "text": "highlight and everyone should think about is model optimization so once I've",
    "start": "2143770",
    "end": "2148810"
  },
  {
    "text": "trained my model I actually need to go in and optimize it for example for",
    "start": "2148810",
    "end": "2154119"
  },
  {
    "text": "different serving environments if I want to have a neural network running on a mobile phone it's the normal output of",
    "start": "2154119",
    "end": "2162570"
  },
  {
    "text": "tensorflow probably it's going to be way too large and way too slow so I can go in there's",
    "start": "2162570",
    "end": "2169480"
  },
  {
    "text": "like there are different transform steps but this is something you should really consider and you can also optimize that",
    "start": "2169480",
    "end": "2176260"
  },
  {
    "text": "for different serving environments you might produce one model which is running on CPUs one which is running on GPUs and",
    "start": "2176260",
    "end": "2183430"
  },
  {
    "text": "maybe one which is running on your mobile phone challenge challenge this is",
    "start": "2183430",
    "end": "2189339"
  },
  {
    "start": "2186000",
    "end": "2228000"
  },
  {
    "text": "actually what Gilbert mentioned earlier it likes this resource and service management this is also very very",
    "start": "2189339",
    "end": "2195220"
  },
  {
    "text": "challenging as I have to deal with all those different distributed systems what",
    "start": "2195220",
    "end": "2200829"
  },
  {
    "text": "I would typically do in a cloud environment I spin up different virtual machines for each well this is actually",
    "start": "2200829",
    "end": "2206530"
  },
  {
    "text": "wasting a lot of resources so if I'm having like one VM for each of those this is gonna not lead to very resource",
    "start": "2206530",
    "end": "2214180"
  },
  {
    "text": "efficient cluster so I should actually come up with a way and queue flow also has some really cool tools and like auto",
    "start": "2214180",
    "end": "2221050"
  },
  {
    "text": "scaling for example the tensorflow cluster which can really help me for like a performant resource management",
    "start": "2221050",
    "end": "2228869"
  },
  {
    "start": "2228000",
    "end": "2320000"
  },
  {
    "text": "alright and this is basically leading to this entire pipeline if you have any",
    "start": "2228869",
    "end": "2234430"
  },
  {
    "text": "more questions feel free to either talk to us or we also have like a white paper",
    "start": "2234430",
    "end": "2241150"
  },
  {
    "text": "you can download from the slides which is going in some more details I would actually love to close with like my wish",
    "start": "2241150",
    "end": "2248079"
  },
  {
    "text": "list of for the next queue flow iterations as yesterday we announced like the odor",
    "start": "2248079",
    "end": "2253360"
  },
  {
    "text": "3 release and the roadmap also looks pretty cool first of all it's really",
    "start": "2253360",
    "end": "2258610"
  },
  {
    "text": "better see ICD integration seeing what's happening with Argos CD is cool but it",
    "start": "2258610",
    "end": "2264520"
  },
  {
    "text": "should really be easier to integrate with different CD environments I should be able to share my notebooks with other",
    "start": "2264520",
    "end": "2271150"
  },
  {
    "text": "people and what I also believe in we actually need a common metadata layer",
    "start": "2271150",
    "end": "2277480"
  },
  {
    "text": "having different components storing the metadata for example for the like model",
    "start": "2277480",
    "end": "2282970"
  },
  {
    "text": "dB we also have metadata which we gather from experiments so I feel having a",
    "start": "2282970",
    "end": "2288460"
  },
  {
    "text": "common metadata layer across this entire infrastructure is going to be so helpful",
    "start": "2288460",
    "end": "2293700"
  },
  {
    "text": "in sharing that data and being reproducible lasting but that was also",
    "start": "2293700",
    "end": "2299140"
  },
  {
    "text": "announced yesterday is actually like a government ends model which they are currently considering so really to have",
    "start": "2299140",
    "end": "2305080"
  },
  {
    "text": "a bigger community around that because I feel cube flows really helping us and having a reproducible standard way to",
    "start": "2305080",
    "end": "2312340"
  },
  {
    "text": "set up machine learning pipelines thank you so much",
    "start": "2312340",
    "end": "2317730"
  },
  {
    "text": "[Applause]",
    "start": "2320000",
    "end": "2322590"
  }
]
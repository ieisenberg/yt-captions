[
  {
    "text": "uh hi everyone Welcome to our talk today",
    "start": "399",
    "end": "3560"
  },
  {
    "text": "so uh today our topic is to use web",
    "start": "3560",
    "end": "8000"
  },
  {
    "text": "assembly to run AI",
    "start": "8000",
    "end": "10480"
  },
  {
    "text": "influence um so um I am the founding",
    "start": "10480",
    "end": "14480"
  },
  {
    "text": "member of wasm Ed project as you can see",
    "start": "14480",
    "end": "17439"
  },
  {
    "text": "um on the slides that that's our GitHub",
    "start": "17439",
    "end": "19960"
  },
  {
    "text": "repo it's a cncf project and Mel is a",
    "start": "19960",
    "end": "24000"
  },
  {
    "text": "Founder uh of this project was",
    "start": "24000",
    "end": "28080"
  },
  {
    "text": "match uh so so I think we will start",
    "start": "28560",
    "end": "31800"
  },
  {
    "text": "with two",
    "start": "31800",
    "end": "33559"
  },
  {
    "text": "demos um we are going to run open source",
    "start": "33559",
    "end": "37800"
  },
  {
    "text": "gen models on your infra and or boundled",
    "start": "37800",
    "end": "41680"
  },
  {
    "text": "with your own",
    "start": "41680",
    "end": "44160"
  },
  {
    "text": "apps thank you Mary yeah so yeah I think",
    "start": "44160",
    "end": "48600"
  },
  {
    "text": "the best way to get started instead of",
    "start": "48600",
    "end": "50320"
  },
  {
    "text": "explaining what is wasam and why we use",
    "start": "50320",
    "end": "52440"
  },
  {
    "text": "it for AI and all kind of stuff you know",
    "start": "52440",
    "end": "54600"
  },
  {
    "text": "I think it's probably easier if we just",
    "start": "54600",
    "end": "56480"
  },
  {
    "text": "have a demo to see what we can do and",
    "start": "56480",
    "end": "58559"
  },
  {
    "text": "what are the benefit why why why don't",
    "start": "58559",
    "end": "60120"
  },
  {
    "text": "you use Python why don't you use AMA why",
    "start": "60120",
    "end": "61920"
  },
  {
    "text": "don't you use any of the other large",
    "start": "61920",
    "end": "63600"
  },
  {
    "text": "language model model toolkit out there",
    "start": "63600",
    "end": "65799"
  },
  {
    "text": "so um here is a GitHub report that we",
    "start": "65799",
    "end": "68200"
  },
  {
    "text": "prepared it's called Talk talk you know",
    "start": "68200",
    "end": "70000"
  },
  {
    "text": "so let me actually um exit from here and",
    "start": "70000",
    "end": "73439"
  },
  {
    "text": "uh uh please excuse my Messi La desktop",
    "start": "73439",
    "end": "78720"
  },
  {
    "text": "it's",
    "start": "78720",
    "end": "79520"
  },
  {
    "text": "here so I going to run this demo twice",
    "start": "79520",
    "end": "82720"
  },
  {
    "text": "you know um if you look at this UI this",
    "start": "82720",
    "end": "85720"
  },
  {
    "text": "is um you know uh a lot of you may be",
    "start": "85720",
    "end": "87560"
  },
  {
    "text": "familiar with this with this UI it's a",
    "start": "87560",
    "end": "89600"
  },
  {
    "text": "it's a web UI and it allow me to talk to",
    "start": "89600",
    "end": "92280"
  },
  {
    "text": "my computer and uh then it would",
    "start": "92280",
    "end": "94479"
  },
  {
    "text": "generate some answer so let me talk to",
    "start": "94479",
    "end": "95920"
  },
  {
    "text": "my computer now I had",
    "start": "95920",
    "end": "99079"
  },
  {
    "text": "record I mean Sol City right now can you",
    "start": "99079",
    "end": "101840"
  },
  {
    "text": "recommend some places to Wi",
    "start": "101840",
    "end": "104200"
  },
  {
    "text": "it so hopefully that you heard my",
    "start": "104200",
    "end": "106680"
  },
  {
    "text": "question right I said I'm in Salt Lake",
    "start": "106680",
    "end": "108320"
  },
  {
    "text": "City right now can you recommend some",
    "start": "108320",
    "end": "109759"
  },
  {
    "text": "places to visit and I going to submit it",
    "start": "109759",
    "end": "112119"
  },
  {
    "text": "you know so basically it send this voice",
    "start": "112119",
    "end": "115000"
  },
  {
    "text": "to a server it's come back right back",
    "start": "115000",
    "end": "118640"
  },
  {
    "text": "okay so you know so here say I'm",
    "start": "118640",
    "end": "121159"
  },
  {
    "text": "transcribed to I'm inan Sal Lake City",
    "start": "121159",
    "end": "123079"
  },
  {
    "text": "can you recommend some place to wear",
    "start": "123079",
    "end": "125079"
  },
  {
    "text": "that and here is the answer in text and",
    "start": "125079",
    "end": "127360"
  },
  {
    "text": "also in voice so I play the voice and",
    "start": "127360",
    "end": "129239"
  },
  {
    "text": "let you",
    "start": "129239",
    "end": "131520"
  },
  {
    "text": "hear Utah state capital Natural History",
    "start": "133239",
    "end": "136959"
  },
  {
    "text": "Museum of Utah and Great Salt Lake also",
    "start": "136959",
    "end": "140680"
  },
  {
    "text": "check out the Gateway Mall redb Garden",
    "start": "140680",
    "end": "144000"
  },
  {
    "text": "and nen Peak all right so you know um so",
    "start": "144000",
    "end": "148280"
  },
  {
    "text": "this is um you know it's seem like a",
    "start": "148280",
    "end": "150760"
  },
  {
    "text": "basic application right you know just uh",
    "start": "150760",
    "end": "152920"
  },
  {
    "text": "transcribe voice text use a large",
    "start": "152920",
    "end": "155040"
  },
  {
    "text": "language model to answer the text and",
    "start": "155040",
    "end": "156920"
  },
  {
    "text": "then sensitize the text back to W okay",
    "start": "156920",
    "end": "159560"
  },
  {
    "text": "so um but uh what I want to focus on is",
    "start": "159560",
    "end": "162400"
  },
  {
    "text": "that this the whole setup requires very",
    "start": "162400",
    "end": "164840"
  },
  {
    "text": "little resources this whole setup runs",
    "start": "164840",
    "end": "167360"
  },
  {
    "text": "on the lowest GPU machine you can buy",
    "start": "167360",
    "end": "170120"
  },
  {
    "text": "you can possibly buy on Azure so it's on",
    "start": "170120",
    "end": "172239"
  },
  {
    "text": "media T4 it runs three J models with",
    "start": "172239",
    "end": "176720"
  },
  {
    "text": "their own wrong time with their own PRS",
    "start": "176720",
    "end": "178480"
  },
  {
    "text": "and with the entire application is just",
    "start": "178480",
    "end": "181000"
  },
  {
    "text": "running on a single GPU machine right so",
    "start": "181000",
    "end": "183680"
  },
  {
    "text": "this is the first demo and I want to do",
    "start": "183680",
    "end": "185840"
  },
  {
    "text": "the demo again this time perhaps go even",
    "start": "185840",
    "end": "187840"
  },
  {
    "text": "more extreme to have everything on my",
    "start": "187840",
    "end": "190000"
  },
  {
    "text": "laptop as you can see I have a gazillion",
    "start": "190000",
    "end": "191560"
  },
  {
    "text": "things running on my laptop I have the",
    "start": "191560",
    "end": "193959"
  },
  {
    "text": "Google Slides I have everything but I",
    "start": "193959",
    "end": "196120"
  },
  {
    "text": "also have a large language model in the",
    "start": "196120",
    "end": "198239"
  },
  {
    "text": "the three large in the J model that I",
    "start": "198239",
    "end": "200200"
  },
  {
    "text": "talk about right so what I going to do",
    "start": "200200",
    "end": "202120"
  },
  {
    "text": "is I going to ask a different question",
    "start": "202120",
    "end": "203720"
  },
  {
    "text": "you know so what should I ask should I",
    "start": "203720",
    "end": "205680"
  },
  {
    "text": "ask Okay so",
    "start": "205680",
    "end": "209879"
  },
  {
    "text": "what are the most important conferences",
    "start": "209879",
    "end": "212000"
  },
  {
    "text": "of the Linux",
    "start": "212000",
    "end": "214239"
  },
  {
    "text": "Foundation My Hope Is that he going to",
    "start": "214239",
    "end": "216239"
  },
  {
    "text": "say cuom but I don't know you know so so",
    "start": "216239",
    "end": "219360"
  },
  {
    "text": "I going to submit it and uh so basically",
    "start": "219360",
    "end": "221120"
  },
  {
    "text": "submit locally if you look at the uh all",
    "start": "221120",
    "end": "223640"
  },
  {
    "text": "the model now runs locally I can even",
    "start": "223640",
    "end": "225760"
  },
  {
    "text": "turn you know because I'm presenting",
    "start": "225760",
    "end": "227239"
  },
  {
    "text": "from Google slide so I can't really turn",
    "start": "227239",
    "end": "228840"
  },
  {
    "text": "on my Wi-Fi but you know I could so here",
    "start": "228840",
    "end": "231840"
  },
  {
    "text": "it says what are the most important",
    "start": "231840",
    "end": "233840"
  },
  {
    "text": "conferences in the Linux Foundation here",
    "start": "233840",
    "end": "236680"
  },
  {
    "text": "the talk AI I'll let it speak for it",
    "start": "236680",
    "end": "240400"
  },
  {
    "text": "the Linux Foundation hosts several key",
    "start": "240400",
    "end": "243400"
  },
  {
    "text": "conferences these include Linux Summit",
    "start": "243400",
    "end": "246879"
  },
  {
    "text": "embedded Linux conference ELC open",
    "start": "246879",
    "end": "250640"
  },
  {
    "text": "source Summit Cloud native con plus",
    "start": "250640",
    "end": "253319"
  },
  {
    "text": "cubec con yay did say copon",
    "start": "253319",
    "end": "257280"
  },
  {
    "text": "right so yeah that's a um so what I want",
    "start": "257280",
    "end": "261799"
  },
  {
    "text": "to um convey here is really that's um",
    "start": "261799",
    "end": "265160"
  },
  {
    "text": "you know I have a fairly low-end MacBook",
    "start": "265160",
    "end": "267240"
  },
  {
    "text": "you know the MacBook is like three years",
    "start": "267240",
    "end": "268840"
  },
  {
    "text": "old I bought it in during the pandemic",
    "start": "268840",
    "end": "271039"
  },
  {
    "text": "and uh it's only have 16 gig of memory",
    "start": "271039",
    "end": "273360"
  },
  {
    "text": "and I'm running a llama 3.2 large",
    "start": "273360",
    "end": "275960"
  },
  {
    "text": "language model uh a whisper V2 large",
    "start": "275960",
    "end": "278800"
  },
  {
    "text": "model and uh another uh GPT sway TTS",
    "start": "278800",
    "end": "282479"
  },
  {
    "text": "model so all of them because um because",
    "start": "282479",
    "end": "286400"
  },
  {
    "text": "we have a lightweight wrun time and we",
    "start": "286400",
    "end": "288000"
  },
  {
    "text": "have a wrun time that can handle",
    "start": "288000",
    "end": "290000"
  },
  {
    "text": "multiple models so we were able to run",
    "start": "290000",
    "end": "292080"
  },
  {
    "text": "all of them on a single piece of",
    "start": "292080",
    "end": "293520"
  },
  {
    "text": "hardware on or or on very low end um um",
    "start": "293520",
    "end": "299199"
  },
  {
    "text": "cloud",
    "start": "299199",
    "end": "300160"
  },
  {
    "text": "so let me go back to the presentation",
    "start": "300160",
    "end": "302520"
  },
  {
    "text": "and uh to go to the next two so if you",
    "start": "302520",
    "end": "305039"
  },
  {
    "text": "want to try this on your own machine you",
    "start": "305039",
    "end": "306280"
  },
  {
    "text": "can actually try this on on your machine",
    "start": "306280",
    "end": "308199"
  },
  {
    "text": "today you know if you have a Macbook or",
    "start": "308199",
    "end": "310240"
  },
  {
    "text": "if you have a say you know a aure",
    "start": "310240",
    "end": "313240"
  },
  {
    "text": "machine you know running Nvidia that you",
    "start": "313240",
    "end": "314880"
  },
  {
    "text": "can try try today just go to that GitHub",
    "start": "314880",
    "end": "316880"
  },
  {
    "text": "repository it has all the instructions",
    "start": "316880",
    "end": "318240"
  },
  {
    "text": "you can do just what it can even switch",
    "start": "318240",
    "end": "320440"
  },
  {
    "text": "languages you know um you know when we",
    "start": "320440",
    "end": "322240"
  },
  {
    "text": "demate from our boost you know we have a",
    "start": "322240",
    "end": "324479"
  },
  {
    "text": "a a conent of Japanese people come by",
    "start": "324479",
    "end": "326400"
  },
  {
    "text": "and they all ask questions in Japanese",
    "start": "326400",
    "end": "328199"
  },
  {
    "text": "and they answer in Japanese which I have",
    "start": "328199",
    "end": "330560"
  },
  {
    "text": "no idea what they talk about but I'm",
    "start": "330560",
    "end": "332319"
  },
  {
    "text": "told you know it was pretty good so you",
    "start": "332319",
    "end": "334600"
  },
  {
    "text": "know that's uh so it was great fun if",
    "start": "334600",
    "end": "336479"
  },
  {
    "text": "you uh if you have time you should uh",
    "start": "336479",
    "end": "338319"
  },
  {
    "text": "you do that and then you know this is",
    "start": "338319",
    "end": "340639"
  },
  {
    "text": "just to repeat what I've said know",
    "start": "340639",
    "end": "342600"
  },
  {
    "text": "there's three U very popular jni models",
    "start": "342600",
    "end": "345680"
  },
  {
    "text": "running on the same Hardware you know",
    "start": "345680",
    "end": "347199"
  },
  {
    "text": "using a unified um run time that we call",
    "start": "347199",
    "end": "350120"
  },
  {
    "text": "wasm Ed Lama Ed which we're going to get",
    "start": "350120",
    "end": "351720"
  },
  {
    "text": "into um you know details in a minute and",
    "start": "351720",
    "end": "354680"
  },
  {
    "text": "uh the key takeaways here really is that",
    "start": "354680",
    "end": "357000"
  },
  {
    "text": "um there is a WR time that is uh that is",
    "start": "357000",
    "end": "360039"
  },
  {
    "text": "that support multiple G models not only",
    "start": "360039",
    "end": "362160"
  },
  {
    "text": "just support large language model but",
    "start": "362160",
    "end": "363560"
  },
  {
    "text": "also support waste to text text to waste",
    "start": "363560",
    "end": "365919"
  },
  {
    "text": "and I what I haven't show uh text to",
    "start": "365919",
    "end": "368199"
  },
  {
    "text": "image stable diffusion type of models",
    "start": "368199",
    "end": "370080"
  },
  {
    "text": "and text to video and you know things",
    "start": "370080",
    "end": "371759"
  },
  {
    "text": "like that it extremely lightweight so",
    "start": "371759",
    "end": "374479"
  },
  {
    "text": "the entire application you know",
    "start": "374479",
    "end": "376039"
  },
  {
    "text": "excluding the large language model",
    "start": "376039",
    "end": "377599"
  },
  {
    "text": "themselves the entire application",
    "start": "377599",
    "end": "379080"
  },
  {
    "text": "combined is 20 megabytes okay so you",
    "start": "379080",
    "end": "381280"
  },
  {
    "text": "know that's uh to give you idea of how",
    "start": "381280",
    "end": "383639"
  },
  {
    "text": "that compares which um we're also going",
    "start": "383639",
    "end": "385160"
  },
  {
    "text": "to talk about in a minute the python py",
    "start": "385160",
    "end": "387680"
  },
  {
    "text": "to doer image adver minimum is 3 GB it",
    "start": "387680",
    "end": "391160"
  },
  {
    "text": "goes all the way up to 9 GB okay that's",
    "start": "391160",
    "end": "393680"
  },
  {
    "text": "compressed the doer image okay so you",
    "start": "393680",
    "end": "396120"
  },
  {
    "text": "know um we are talking about things that",
    "start": "396120",
    "end": "398599"
  },
  {
    "text": "two or three orders magnitude smaller",
    "start": "398599",
    "end": "400880"
  },
  {
    "text": "that's uh and runs super fast and runs",
    "start": "400880",
    "end": "403759"
  },
  {
    "text": "you know um uh uh you know very",
    "start": "403759",
    "end": "406000"
  },
  {
    "text": "lightweight and very fast and another",
    "start": "406000",
    "end": "407840"
  },
  {
    "text": "thing I want to also I want to highlight",
    "start": "407840",
    "end": "409720"
  },
  {
    "text": "is the application that runs on the",
    "start": "409720",
    "end": "411919"
  },
  {
    "text": "cloud of media machine that I showed in",
    "start": "411919",
    "end": "414280"
  },
  {
    "text": "the first demo and the local MacBook on",
    "start": "414280",
    "end": "416879"
  },
  {
    "text": "the second demo are actually the exact",
    "start": "416879",
    "end": "418639"
  },
  {
    "text": "same application it's not the",
    "start": "418639",
    "end": "420400"
  },
  {
    "text": "application that has be Rewritten for",
    "start": "420400",
    "end": "422440"
  },
  {
    "text": "the the Cuda framework or the metal",
    "start": "422440",
    "end": "424800"
  },
  {
    "text": "framework on the Mac being recompiled I",
    "start": "424800",
    "end": "427759"
  },
  {
    "text": "did nothing I just copied the binary",
    "start": "427759",
    "end": "429879"
  },
  {
    "text": "application using FTP using SCP directly",
    "start": "429879",
    "end": "432919"
  },
  {
    "text": "from my development machine to the",
    "start": "432919",
    "end": "434440"
  },
  {
    "text": "Nvidia machine and it runs out off the",
    "start": "434440",
    "end": "436520"
  },
  {
    "text": "Box on the GPU right there right so you",
    "start": "436520",
    "end": "438759"
  },
  {
    "text": "know so three main takeaways is that you",
    "start": "438759",
    "end": "441240"
  },
  {
    "text": "know what I have demonstrated is support",
    "start": "441240",
    "end": "442639"
  },
  {
    "text": "multiple gni models using a single",
    "start": "442639",
    "end": "444599"
  },
  {
    "text": "runtime framework very lightweight and",
    "start": "444599",
    "end": "447000"
  },
  {
    "text": "pability across GPU platforms so uh I",
    "start": "447000",
    "end": "449960"
  },
  {
    "text": "going to turn over to Marie to do the",
    "start": "449960",
    "end": "451759"
  },
  {
    "text": "second demo yeah thank you uh so the",
    "start": "451759",
    "end": "456240"
  },
  {
    "text": "second demo is a video translation tool",
    "start": "456240",
    "end": "459879"
  },
  {
    "text": "powered by large Lang model and was a",
    "start": "459879",
    "end": "462080"
  },
  {
    "text": "match so um yeah I will",
    "start": "462080",
    "end": "465879"
  },
  {
    "text": "show um how uh a video that I have",
    "start": "465879",
    "end": "470199"
  },
  {
    "text": "already translated from Chinese into",
    "start": "470199",
    "end": "473280"
  },
  {
    "text": "English um but it's uh only subtitling",
    "start": "473280",
    "end": "476159"
  },
  {
    "text": "but you can also do dubbing in English",
    "start": "476159",
    "end": "479039"
  },
  {
    "text": "or",
    "start": "479039",
    "end": "480360"
  },
  {
    "text": "languages um so yeah I'll play this",
    "start": "480360",
    "end": "485280"
  },
  {
    "text": "first yeah so yeah that's a very short",
    "start": "496720",
    "end": "499639"
  },
  {
    "text": "demo so that's a very uh big influencer",
    "start": "499639",
    "end": "504639"
  },
  {
    "text": "on YouTube is a Chinese influencer uh he",
    "start": "504639",
    "end": "507479"
  },
  {
    "text": "has she has been like silent for 3 years",
    "start": "507479",
    "end": "510360"
  },
  {
    "text": "and that's um recently she started to",
    "start": "510360",
    "end": "513080"
  },
  {
    "text": "post video So like um that's only in",
    "start": "513080",
    "end": "515880"
  },
  {
    "text": "Chinese but we uploaded this uh to this",
    "start": "515880",
    "end": "519680"
  },
  {
    "text": "Tool uh video translation tool and it",
    "start": "519680",
    "end": "522719"
  },
  {
    "text": "get dubbed or um captioned in English so",
    "start": "522719",
    "end": "527320"
  },
  {
    "text": "I will do a demo to uh the other way",
    "start": "527320",
    "end": "532200"
  },
  {
    "text": "around to uh upload a English video and",
    "start": "532200",
    "end": "535839"
  },
  {
    "text": "get a a Chinese translation",
    "start": "535839",
    "end": "540519"
  },
  {
    "text": "uh so yeah I'll open the video lang.com",
    "start": "540519",
    "end": "545200"
  },
  {
    "text": "uh let me open",
    "start": "545200",
    "end": "549360"
  },
  {
    "text": "it",
    "start": "549360",
    "end": "551720"
  },
  {
    "text": "yeah so yeah uh I'm going to do English",
    "start": "551720",
    "end": "556120"
  },
  {
    "text": "to",
    "start": "556120",
    "end": "557240"
  },
  {
    "text": "Chinese and uh this is a video recording",
    "start": "557240",
    "end": "562640"
  },
  {
    "text": "we did this August test test uh of lonus",
    "start": "562640",
    "end": "567880"
  },
  {
    "text": "TS uh he did a keynote",
    "start": "567880",
    "end": "571240"
  },
  {
    "text": "interview uh to talk about the scaling",
    "start": "571240",
    "end": "573959"
  },
  {
    "text": "law of",
    "start": "573959",
    "end": "575279"
  },
  {
    "text": "AI so here I can choose whether to dub",
    "start": "575279",
    "end": "579360"
  },
  {
    "text": "it or to caption it so I'm going to",
    "start": "579360",
    "end": "582160"
  },
  {
    "text": "choose D dub it in",
    "start": "582160",
    "end": "584399"
  },
  {
    "text": "Chinese from English so here I um I'm",
    "start": "584399",
    "end": "589480"
  },
  {
    "text": "going to enter my email address after",
    "start": "589480",
    "end": "592200"
  },
  {
    "text": "it's down it would be uh it s would send",
    "start": "592200",
    "end": "595800"
  },
  {
    "text": "an email to me of the translated video",
    "start": "595800",
    "end": "600760"
  },
  {
    "text": "yeah yeah while we are waiting for",
    "start": "600760",
    "end": "603480"
  },
  {
    "text": "that uh because it's also powered by uh",
    "start": "603480",
    "end": "607480"
  },
  {
    "text": "lar model so it's can take a little bit",
    "start": "607480",
    "end": "610920"
  },
  {
    "text": "so we will um come back to",
    "start": "610920",
    "end": "613519"
  },
  {
    "text": "this I guess after we have finished the",
    "start": "613519",
    "end": "617920"
  },
  {
    "text": "presentation",
    "start": "617920",
    "end": "620399"
  },
  {
    "text": "um",
    "start": "620399",
    "end": "622800"
  },
  {
    "text": "yeah we all go on with our",
    "start": "622800",
    "end": "626720"
  },
  {
    "text": "presentation so yeah while we wait for",
    "start": "626720",
    "end": "629440"
  },
  {
    "text": "that I think one of the most interesting",
    "start": "629440",
    "end": "631800"
  },
  {
    "text": "aspect of this is that you know uh I'm",
    "start": "631800",
    "end": "634120"
  },
  {
    "text": "sure you have heard of this this term a",
    "start": "634120",
    "end": "635959"
  },
  {
    "text": "lot is scaling law apply to inference",
    "start": "635959",
    "end": "638480"
  },
  {
    "text": "right you know so for for the longest",
    "start": "638480",
    "end": "640240"
  },
  {
    "text": "time you know we saw the scaling law is",
    "start": "640240",
    "end": "641959"
  },
  {
    "text": "on the training or pre-training side",
    "start": "641959",
    "end": "643440"
  },
  {
    "text": "when you train a b longer when you train",
    "start": "643440",
    "end": "644959"
  },
  {
    "text": "it with more data the AI going to be",
    "start": "644959",
    "end": "646839"
  },
  {
    "text": "smarter however you know one of the",
    "start": "646839",
    "end": "649480"
  },
  {
    "text": "strongest uh rational the use case of",
    "start": "649480",
    "end": "652160"
  },
  {
    "text": "use open source AI is really because we",
    "start": "652160",
    "end": "654240"
  },
  {
    "text": "have now scaling law at inference you",
    "start": "654240",
    "end": "656399"
  },
  {
    "text": "know it's a this is a very sharp",
    "start": "656399",
    "end": "658440"
  },
  {
    "text": "contrast with demo that I just did I the",
    "start": "658440",
    "end": "660720"
  },
  {
    "text": "demo I just did I wouldn't say it's",
    "start": "660720",
    "end": "662720"
  },
  {
    "text": "realtime audio but it's semi real time",
    "start": "662720",
    "end": "664680"
  },
  {
    "text": "right you know if I say say something I",
    "start": "664680",
    "end": "666440"
  },
  {
    "text": "submit and it come backs in like 2 three",
    "start": "666440",
    "end": "669040"
  },
  {
    "text": "seconds right you know that's 10 seconds",
    "start": "669040",
    "end": "670839"
  },
  {
    "text": "tops you know but for this video even",
    "start": "670839",
    "end": "673279"
  },
  {
    "text": "the video that might have shown is only",
    "start": "673279",
    "end": "674880"
  },
  {
    "text": "40 minut 40 seconds it takes a couple",
    "start": "674880",
    "end": "677560"
  },
  {
    "text": "minutes to translate that why because",
    "start": "677560",
    "end": "680399"
  },
  {
    "text": "the whole in the whole process we have",
    "start": "680399",
    "end": "682120"
  },
  {
    "text": "multiple large language models to",
    "start": "682120",
    "end": "683639"
  },
  {
    "text": "translate the same video and they check",
    "start": "683639",
    "end": "685880"
  },
  {
    "text": "against each other and they give",
    "start": "685880",
    "end": "687639"
  },
  {
    "text": "suggestions to each other which one is",
    "start": "687639",
    "end": "689519"
  },
  {
    "text": "the best translation so after a couple",
    "start": "689519",
    "end": "692680"
  },
  {
    "text": "minutes if you if you let the the AI",
    "start": "692680",
    "end": "695360"
  },
  {
    "text": "think longer you would get a much better",
    "start": "695360",
    "end": "697680"
  },
  {
    "text": "results so you know that's where you",
    "start": "697680",
    "end": "699760"
  },
  {
    "text": "know um we have this system actually set",
    "start": "699760",
    "end": "701880"
  },
  {
    "text": "up you know when we had a um um you know",
    "start": "701880",
    "end": "705000"
  },
  {
    "text": "um a cube con went in China you know we",
    "start": "705000",
    "end": "707880"
  },
  {
    "text": "have this system set up to do realtime",
    "start": "707880",
    "end": "710160"
  },
  {
    "text": "translation and you would say you would",
    "start": "710160",
    "end": "712399"
  },
  {
    "text": "see the the the translation result is",
    "start": "712399",
    "end": "714399"
  },
  {
    "text": "not that good but if you give it",
    "start": "714399",
    "end": "716560"
  },
  {
    "text": "sufficient time to think you know if you",
    "start": "716560",
    "end": "718240"
  },
  {
    "text": "give it couple minutes to think about",
    "start": "718240",
    "end": "720360"
  },
  {
    "text": "the 40 seconds video it going to give",
    "start": "720360",
    "end": "722399"
  },
  {
    "text": "you much better translation because it's",
    "start": "722399",
    "end": "724240"
  },
  {
    "text": "going to have multiple different um uh",
    "start": "724240",
    "end": "727040"
  },
  {
    "text": "uh large language models and each of",
    "start": "727040",
    "end": "729120"
  },
  {
    "text": "them going to have different prompts",
    "start": "729120",
    "end": "730600"
  },
  {
    "text": "some of the prompts would be um to be",
    "start": "730600",
    "end": "732920"
  },
  {
    "text": "context aware that this is the talk that",
    "start": "732920",
    "end": "734959"
  },
  {
    "text": "given in cucon China in Hong Kong so it",
    "start": "734959",
    "end": "737959"
  },
  {
    "text": "would know that the um you know the",
    "start": "737959",
    "end": "740720"
  },
  {
    "text": "words in there are going to be",
    "start": "740720",
    "end": "742000"
  },
  {
    "text": "pronounced in certain ways so for",
    "start": "742000",
    "end": "743240"
  },
  {
    "text": "instance you know people talk about you",
    "start": "743240",
    "end": "745000"
  },
  {
    "text": "know here people talk about kubernetes",
    "start": "745000",
    "end": "746959"
  },
  {
    "text": "or GitHub you know those are fairly un",
    "start": "746959",
    "end": "749199"
  },
  {
    "text": "common words in the you know in the in",
    "start": "749199",
    "end": "751320"
  },
  {
    "text": "the regular English speaking world right",
    "start": "751320",
    "end": "752959"
  },
  {
    "text": "you know so for the for the U for The",
    "start": "752959",
    "end": "755920"
  },
  {
    "text": "Voice model and for the larg language to",
    "start": "755920",
    "end": "757399"
  },
  {
    "text": "pick up those words and understand what",
    "start": "757399",
    "end": "758959"
  },
  {
    "text": "they are often times you would need um",
    "start": "758959",
    "end": "761320"
  },
  {
    "text": "you know special prompts and in order to",
    "start": "761320",
    "end": "763240"
  },
  {
    "text": "do all this I think you know um to have",
    "start": "763240",
    "end": "765600"
  },
  {
    "text": "highly efficient around time to run",
    "start": "765600",
    "end": "767440"
  },
  {
    "text": "large language model on your own",
    "start": "767440",
    "end": "768760"
  },
  {
    "text": "infrastructure is very important it's",
    "start": "768760",
    "end": "770839"
  },
  {
    "text": "not just a you know a agentic system",
    "start": "770839",
    "end": "773639"
  },
  {
    "text": "that I use all the same model that come",
    "start": "773639",
    "end": "775279"
  },
  {
    "text": "from open that they are all the same",
    "start": "775279",
    "end": "777079"
  },
  {
    "text": "model and just promptly differently you",
    "start": "777079",
    "end": "778600"
  },
  {
    "text": "know that's a",
    "start": "778600",
    "end": "779680"
  },
  {
    "text": "that just would not give you um I think",
    "start": "779680",
    "end": "782199"
  },
  {
    "text": "the optimal results what you want is the",
    "start": "782199",
    "end": "784240"
  },
  {
    "text": "model that is fine-tuned and trained in",
    "start": "784240",
    "end": "786199"
  },
  {
    "text": "slightly different ways so that they",
    "start": "786199",
    "end": "788079"
  },
  {
    "text": "would give different answers you know",
    "start": "788079",
    "end": "789600"
  },
  {
    "text": "that's um when you see the same content",
    "start": "789600",
    "end": "791720"
  },
  {
    "text": "right you know so and then you have",
    "start": "791720",
    "end": "793600"
  },
  {
    "text": "those models to cross check each other",
    "start": "793600",
    "end": "795639"
  },
  {
    "text": "to say you know um you know um um then",
    "start": "795639",
    "end": "798000"
  },
  {
    "text": "they would vote to say you know which",
    "start": "798000",
    "end": "799680"
  },
  {
    "text": "translation that they would want to use",
    "start": "799680",
    "end": "801240"
  },
  {
    "text": "on each individual sentence right so",
    "start": "801240",
    "end": "803199"
  },
  {
    "text": "this is the whole point you know that's",
    "start": "803199",
    "end": "804720"
  },
  {
    "text": "uh um you know um the once we have done",
    "start": "804720",
    "end": "808639"
  },
  {
    "text": "this uh this demo the the the takeaway",
    "start": "808639",
    "end": "811040"
  },
  {
    "text": "point for this demo really is that you",
    "start": "811040",
    "end": "812880"
  },
  {
    "text": "know for a gentic system you really need",
    "start": "812880",
    "end": "816120"
  },
  {
    "text": "multiple specialized models you need",
    "start": "816120",
    "end": "818000"
  },
  {
    "text": "applications to be tightly coupled with",
    "start": "818000",
    "end": "819639"
  },
  {
    "text": "the models not just I write any",
    "start": "819639",
    "end": "821440"
  },
  {
    "text": "application that going to work for the",
    "start": "821440",
    "end": "822600"
  },
  {
    "text": "open you know it's that I going to write",
    "start": "822600",
    "end": "825079"
  },
  {
    "text": "application that specifically for this",
    "start": "825079",
    "end": "826600"
  },
  {
    "text": "model for the Llama 3.2 but not",
    "start": "826600",
    "end": "829040"
  },
  {
    "text": "necessarily work for llama 3.1 because",
    "start": "829040",
    "end": "831680"
  },
  {
    "text": "the promp structure is different right",
    "start": "831680",
    "end": "833279"
  },
  {
    "text": "the models are different or the model",
    "start": "833279",
    "end": "835920"
  },
  {
    "text": "going to work for um Chan 2.5 which is a",
    "start": "835920",
    "end": "839240"
  },
  {
    "text": "train model that understand that",
    "start": "839240",
    "end": "840560"
  },
  {
    "text": "language much better right so you know",
    "start": "840560",
    "end": "842320"
  },
  {
    "text": "so there's lots of um things that you",
    "start": "842320",
    "end": "844199"
  },
  {
    "text": "can twe yourself you know if you have a",
    "start": "844199",
    "end": "846120"
  },
  {
    "text": "open source based uh solution stack of",
    "start": "846120",
    "end": "848839"
  },
  {
    "text": "solutions and of course it also requires",
    "start": "848839",
    "end": "851079"
  },
  {
    "text": "very efficient use of GPU compute",
    "start": "851079",
    "end": "853199"
  },
  {
    "text": "because you know when you have all those",
    "start": "853199",
    "end": "854519"
  },
  {
    "text": "models running they sometimes they are",
    "start": "854519",
    "end": "856279"
  },
  {
    "text": "all need GPU resources sometimes they",
    "start": "856279",
    "end": "858839"
  },
  {
    "text": "you know they are all idle right you",
    "start": "858839",
    "end": "860279"
  },
  {
    "text": "know so you need a a highly efficient",
    "start": "860279",
    "end": "863079"
  },
  {
    "text": "framework that can orchestrate you know",
    "start": "863079",
    "end": "865000"
  },
  {
    "text": "those workload across gpus so let's go",
    "start": "865000",
    "end": "867480"
  },
  {
    "text": "back and see if this um this translation",
    "start": "867480",
    "end": "870440"
  },
  {
    "text": "is done where is it yeah so it's done",
    "start": "870440",
    "end": "874360"
  },
  {
    "text": "you can play it okay I thought it would",
    "start": "874360",
    "end": "876480"
  },
  {
    "text": "take",
    "start": "876480",
    "end": "878639"
  },
  {
    "text": "longer so that's uh",
    "start": "878639",
    "end": "882759"
  },
  {
    "text": "less should we like play the original I",
    "start": "890040",
    "end": "892800"
  },
  {
    "text": "think I think you get an idea right you",
    "start": "892800",
    "end": "894440"
  },
  {
    "text": "know it's mixed English and Chinese you",
    "start": "894440",
    "end": "896160"
  },
  {
    "text": "know if you speak Chinese here you'll be",
    "start": "896160",
    "end": "898120"
  },
  {
    "text": "able to know because I speak Chinese so",
    "start": "898120",
    "end": "899880"
  },
  {
    "text": "I guarantee you it's a good",
    "start": "899880",
    "end": "903040"
  },
  {
    "text": "translation so but you know but you can",
    "start": "904079",
    "end": "906519"
  },
  {
    "text": "see that U you know um he makes you know",
    "start": "906519",
    "end": "908680"
  },
  {
    "text": "the translation makes English word with",
    "start": "908680",
    "end": "910240"
  },
  {
    "text": "Chinese words and it handles it very",
    "start": "910240",
    "end": "911920"
  },
  {
    "text": "well so yeah yeah so um go back to the",
    "start": "911920",
    "end": "919240"
  },
  {
    "text": "presentation",
    "start": "919240",
    "end": "922240"
  },
  {
    "text": "um um now why wasn't uh I guess for C",
    "start": "922920",
    "end": "929720"
  },
  {
    "text": "attendees wasn't might not sound that",
    "start": "929720",
    "end": "933279"
  },
  {
    "text": "familiar especially if you uh consider",
    "start": "933279",
    "end": "936319"
  },
  {
    "text": "using it as a",
    "start": "936319",
    "end": "937959"
  },
  {
    "text": "container uh so it's not a very so it's",
    "start": "937959",
    "end": "941199"
  },
  {
    "text": "like comparatively young so uh but it's",
    "start": "941199",
    "end": "943959"
  },
  {
    "text": "uh already being used in um the browser",
    "start": "943959",
    "end": "946839"
  },
  {
    "text": "for a long time so",
    "start": "946839",
    "end": "949480"
  },
  {
    "text": "um uh it became the w3c standard the",
    "start": "949480",
    "end": "954240"
  },
  {
    "text": "fourth one uh in",
    "start": "954240",
    "end": "957120"
  },
  {
    "text": "2015 and um",
    "start": "957120",
    "end": "960079"
  },
  {
    "text": "uh all the browsers supports web",
    "start": "960079",
    "end": "963040"
  },
  {
    "text": "assembly and in",
    "start": "963040",
    "end": "965519"
  },
  {
    "text": "2019 whaty got released so that would",
    "start": "965519",
    "end": "969680"
  },
  {
    "text": "allow wasam to access system what is",
    "start": "969680",
    "end": "972240"
  },
  {
    "text": "stand for web assembly system interface",
    "start": "972240",
    "end": "975759"
  },
  {
    "text": "so um that's when serde WM is ready to",
    "start": "975759",
    "end": "979440"
  },
  {
    "text": "go",
    "start": "979440",
    "end": "980399"
  },
  {
    "text": "mainstream and uh um yeah uh yeah I I I",
    "start": "980399",
    "end": "986040"
  },
  {
    "text": "was wrong so uh WC uh 3 group uh was",
    "start": "986040",
    "end": "989920"
  },
  {
    "text": "founded in 2015 and it became the first",
    "start": "989920",
    "end": "993000"
  },
  {
    "text": "uh language for the web in",
    "start": "993000",
    "end": "995319"
  },
  {
    "text": "2019 um and um in",
    "start": "995319",
    "end": "998600"
  },
  {
    "text": "2022 the cncf uh survey have founded",
    "start": "998600",
    "end": "1002839"
  },
  {
    "text": "that containers uh that's the only key",
    "start": "1002839",
    "end": "1006240"
  },
  {
    "text": "finding they have of that survey that is",
    "start": "1006240",
    "end": "1009560"
  },
  {
    "text": "containers are the new normal and web",
    "start": "1009560",
    "end": "1011639"
  },
  {
    "text": "assembly is the",
    "start": "1011639",
    "end": "1013639"
  },
  {
    "text": "future so um this is a kind of recent",
    "start": "1013639",
    "end": "1018920"
  },
  {
    "text": "news so Wikipedia posted on their blog",
    "start": "1018920",
    "end": "1023399"
  },
  {
    "text": "saying that uh it slashed a lot of uh",
    "start": "1023399",
    "end": "1027360"
  },
  {
    "text": "millisecond of is is WM execution with W",
    "start": "1027360",
    "end": "1031438"
  },
  {
    "text": "match so uh that's used on Wiki",
    "start": "1031439",
    "end": "1035240"
  },
  {
    "text": "functions is a serverless function",
    "start": "1035240",
    "end": "1037280"
  },
  {
    "text": "platform uh integrated into uh Wikipedia",
    "start": "1037280",
    "end": "1041199"
  },
  {
    "text": "and it's one of the most uh popular",
    "start": "1041199",
    "end": "1043199"
  },
  {
    "text": "website worldwide and um it's so these",
    "start": "1043199",
    "end": "1046880"
  },
  {
    "text": "post have got uh over 120 views and 400",
    "start": "1046880",
    "end": "1052919"
  },
  {
    "text": "plus up upbs in just half a day so uh",
    "start": "1052919",
    "end": "1058679"
  },
  {
    "text": "why not",
    "start": "1058679",
    "end": "1060720"
  },
  {
    "text": "Pyon all right so um thank you mighty so",
    "start": "1060720",
    "end": "1063640"
  },
  {
    "text": "we had a you know uh a good introduction",
    "start": "1063640",
    "end": "1066039"
  },
  {
    "text": "what wasm but then why do we use wasm to",
    "start": "1066039",
    "end": "1068640"
  },
  {
    "text": "drive GPU you know so this is a question",
    "start": "1068640",
    "end": "1070600"
  },
  {
    "text": "I always you know um when I talk to",
    "start": "1070600",
    "end": "1072799"
  },
  {
    "text": "people who run you know large language",
    "start": "1072799",
    "end": "1074360"
  },
  {
    "text": "model locally I I asked them you know",
    "start": "1074360",
    "end": "1076159"
  },
  {
    "text": "raise your hand what what stack do you",
    "start": "1076159",
    "end": "1077720"
  },
  {
    "text": "use and I say 90% of them use Python",
    "start": "1077720",
    "end": "1080280"
  },
  {
    "text": "okay but you know because you know we",
    "start": "1080280",
    "end": "1082799"
  },
  {
    "text": "automatically associate machine learning",
    "start": "1082799",
    "end": "1084440"
  },
  {
    "text": "and all that stuff with python but",
    "start": "1084440",
    "end": "1086159"
  },
  {
    "text": "python is great for training models is",
    "start": "1086159",
    "end": "1088440"
  },
  {
    "text": "actually terrible for inference because",
    "start": "1088440",
    "end": "1091440"
  },
  {
    "text": "it's extremely bloated I you know I dare",
    "start": "1091440",
    "end": "1094039"
  },
  {
    "text": "not wrong python without virtual",
    "start": "1094039",
    "end": "1095760"
  },
  {
    "text": "environments or without um you know",
    "start": "1095760",
    "end": "1098120"
  },
  {
    "text": "Docker right you know because you know",
    "start": "1098120",
    "end": "1101880"
  },
  {
    "text": "um in a few days your computer will be",
    "start": "1101880",
    "end": "1104320"
  },
  {
    "text": "completely unusable because you know",
    "start": "1104320",
    "end": "1105720"
  },
  {
    "text": "there will be version conflict",
    "start": "1105720",
    "end": "1106799"
  },
  {
    "text": "everywhere you know that's a so this is",
    "start": "1106799",
    "end": "1108360"
  },
  {
    "text": "one of the big issue with python and",
    "start": "1108360",
    "end": "1110320"
  },
  {
    "text": "python is also um it's very bloated but",
    "start": "1110320",
    "end": "1113039"
  },
  {
    "text": "very complex and also that makes it very",
    "start": "1113039",
    "end": "1115559"
  },
  {
    "text": "vulnerable to supply chain attacks and",
    "start": "1115559",
    "end": "1117919"
  },
  {
    "text": "you know things like that so to run on",
    "start": "1117919",
    "end": "1119919"
  },
  {
    "text": "production and public facing inference",
    "start": "1119919",
    "end": "1122080"
  },
  {
    "text": "Frameworks and inference applications I",
    "start": "1122080",
    "end": "1123799"
  },
  {
    "text": "think it's a um you know my in my",
    "start": "1123799",
    "end": "1125480"
  },
  {
    "text": "opinion it would be a mistake and uh",
    "start": "1125480",
    "end": "1127840"
  },
  {
    "text": "that is not just my opinion you know",
    "start": "1127840",
    "end": "1129760"
  },
  {
    "text": "that's uh so Greg Brockman here is open",
    "start": "1129760",
    "end": "1132280"
  },
  {
    "text": "AI CTO and uh you know that's I quote",
    "start": "1132280",
    "end": "1135400"
  },
  {
    "text": "him you know that's model of machine",
    "start": "1135400",
    "end": "1137320"
  },
  {
    "text": "model machine learning engine making",
    "start": "1137320",
    "end": "1139360"
  },
  {
    "text": "python not be a Bott neck right you know",
    "start": "1139360",
    "end": "1141240"
  },
  {
    "text": "because you spend so much time",
    "start": "1141240",
    "end": "1142559"
  },
  {
    "text": "installing Python and trying to figure",
    "start": "1142559",
    "end": "1144360"
  },
  {
    "text": "out the conflict and you know stuff like",
    "start": "1144360",
    "end": "1146280"
  },
  {
    "text": "that and uh if you look at what XI did",
    "start": "1146280",
    "end": "1148960"
  },
  {
    "text": "you know they um they recently released",
    "start": "1148960",
    "end": "1150760"
  },
  {
    "text": "their API they have been um promoting",
    "start": "1150760",
    "end": "1153159"
  },
  {
    "text": "the idea of all their stuff is read rust",
    "start": "1153159",
    "end": "1155600"
  },
  {
    "text": "you know there's no python that goes",
    "start": "1155600",
    "end": "1157440"
  },
  {
    "text": "into their uh you know model serving and",
    "start": "1157440",
    "end": "1159440"
  },
  {
    "text": "you know things like that and also to",
    "start": "1159440",
    "end": "1161280"
  },
  {
    "text": "Echo the point I I I I said earlier just",
    "start": "1161280",
    "end": "1164039"
  },
  {
    "text": "to prove it you know is that U you know",
    "start": "1164039",
    "end": "1166080"
  },
  {
    "text": "if you do the py torch doer image is",
    "start": "1166080",
    "end": "1168360"
  },
  {
    "text": "which in it that's um you know 8 GB",
    "start": "1168360",
    "end": "1171440"
  },
  {
    "text": "right there you know almost the 9 GB",
    "start": "1171440",
    "end": "1173360"
  },
  {
    "text": "right you know so that's compressed",
    "start": "1173360",
    "end": "1174960"
  },
  {
    "text": "stalker image you know that's when you",
    "start": "1174960",
    "end": "1176520"
  },
  {
    "text": "explode it on your device it's going to",
    "start": "1176520",
    "end": "1177880"
  },
  {
    "text": "be a lot bigger right you know just",
    "start": "1177880",
    "end": "1179520"
  },
  {
    "text": "recall the entire application that I",
    "start": "1179520",
    "end": "1181360"
  },
  {
    "text": "have just shown you you know the three",
    "start": "1181360",
    "end": "1183000"
  },
  {
    "text": "agent um you know translation and a",
    "start": "1183000",
    "end": "1185200"
  },
  {
    "text": "question answer application is only 20",
    "start": "1185200",
    "end": "1186880"
  },
  {
    "text": "megabytes",
    "start": "1186880",
    "end": "1188280"
  },
  {
    "text": "okay so then okay no P okay then what",
    "start": "1188280",
    "end": "1193360"
  },
  {
    "text": "about other um very popular tools like",
    "start": "1193360",
    "end": "1195480"
  },
  {
    "text": "AMA you know that's I personally use AMA",
    "start": "1195480",
    "end": "1197919"
  },
  {
    "text": "I like it a lot you know that's I",
    "start": "1197919",
    "end": "1199480"
  },
  {
    "text": "believe they're on stage at uh you know",
    "start": "1199480",
    "end": "1202000"
  },
  {
    "text": "um at cucon EU a couple months ago you",
    "start": "1202000",
    "end": "1204320"
  },
  {
    "text": "know so um but there are some uh issues",
    "start": "1204320",
    "end": "1207799"
  },
  {
    "text": "when you try to use it not just on your",
    "start": "1207799",
    "end": "1211400"
  },
  {
    "text": "laptop but on uh say a cloud machine or",
    "start": "1211400",
    "end": "1214720"
  },
  {
    "text": "H device right so the biggest problem",
    "start": "1214720",
    "end": "1217000"
  },
  {
    "text": "that we have encountered is that it only",
    "start": "1217000",
    "end": "1219039"
  },
  {
    "text": "support large language models you know",
    "start": "1219039",
    "end": "1220679"
  },
  {
    "text": "it's recently support Vision based large",
    "start": "1220679",
    "end": "1222320"
  },
  {
    "text": "language models but it doesn't support",
    "start": "1222320",
    "end": "1223840"
  },
  {
    "text": "things like whisper or stable diffusion",
    "start": "1223840",
    "end": "1225840"
  },
  {
    "text": "or things like that but as you have seen",
    "start": "1225840",
    "end": "1227919"
  },
  {
    "text": "those are integral part of your entire",
    "start": "1227919",
    "end": "1230080"
  },
  {
    "text": "application so if that's the case then",
    "start": "1230080",
    "end": "1232880"
  },
  {
    "text": "you still need to introduce python you",
    "start": "1232880",
    "end": "1234679"
  },
  {
    "text": "just use llama to run llama you know",
    "start": "1234679",
    "end": "1236200"
  },
  {
    "text": "that's a but the rest of the stuff you",
    "start": "1236200",
    "end": "1237640"
  },
  {
    "text": "still need to find solutions for that",
    "start": "1237640",
    "end": "1239000"
  },
  {
    "text": "right the other thing is about oper",
    "start": "1239000",
    "end": "1241000"
  },
  {
    "text": "operational weight because designed to",
    "start": "1241000",
    "end": "1242600"
  },
  {
    "text": "be a desktop tool so it's sort of",
    "start": "1242600",
    "end": "1244400"
  },
  {
    "text": "function like Docker you know so it has",
    "start": "1244400",
    "end": "1246080"
  },
  {
    "text": "its own Dem that monitor is the process",
    "start": "1246080",
    "end": "1248679"
  },
  {
    "text": "which requires pseudo um privilege and",
    "start": "1248679",
    "end": "1251440"
  },
  {
    "text": "it has its own repositories that you",
    "start": "1251440",
    "end": "1253480"
  },
  {
    "text": "have to make sure you have connection to",
    "start": "1253480",
    "end": "1255240"
  },
  {
    "text": "and you know things like that so you",
    "start": "1255240",
    "end": "1257000"
  },
  {
    "text": "know why I like it a lot I use use it on",
    "start": "1257000",
    "end": "1258919"
  },
  {
    "text": "my own computer but I don't use it on",
    "start": "1258919",
    "end": "1261000"
  },
  {
    "text": "the server for this for those reasons",
    "start": "1261000",
    "end": "1264320"
  },
  {
    "text": "so now we say python is too heavy orama",
    "start": "1264320",
    "end": "1267559"
  },
  {
    "text": "maybe too heavy so why why we just go",
    "start": "1267559",
    "end": "1269960"
  },
  {
    "text": "straight to the to the most lightweight",
    "start": "1269960",
    "end": "1271840"
  },
  {
    "text": "Solutions why don't we just go to C++",
    "start": "1271840",
    "end": "1274880"
  },
  {
    "text": "like we have seen there's llama CPP",
    "start": "1274880",
    "end": "1276919"
  },
  {
    "text": "there's whisper. CPP there torch. CPP",
    "start": "1276919",
    "end": "1279480"
  },
  {
    "text": "there's vrm and you know there's a",
    "start": "1279480",
    "end": "1281159"
  },
  {
    "text": "variety of different C++ Bas solution",
    "start": "1281159",
    "end": "1283320"
  },
  {
    "text": "where you can run your large language",
    "start": "1283320",
    "end": "1284640"
  },
  {
    "text": "model right but as I mentioned earlier",
    "start": "1284640",
    "end": "1287640"
  },
  {
    "text": "you know that's why we had this or we",
    "start": "1287640",
    "end": "1289279"
  },
  {
    "text": "did the first demo twice is that",
    "start": "1289279",
    "end": "1291279"
  },
  {
    "text": "portability is a really huge problem for",
    "start": "1291279",
    "end": "1293080"
  },
  {
    "text": "C++ right you know so especially when",
    "start": "1293080",
    "end": "1295279"
  },
  {
    "text": "GPU was involved okay so you know that's",
    "start": "1295279",
    "end": "1297919"
  },
  {
    "text": "uh um if you develop a C+ 5 application",
    "start": "1297919",
    "end": "1300919"
  },
  {
    "text": "on your Mac you need to use the Mac GPU",
    "start": "1300919",
    "end": "1303720"
  },
  {
    "text": "SDK and they compile to that Target and",
    "start": "1303720",
    "end": "1306200"
  },
  {
    "text": "then run it uh none of this stuff going",
    "start": "1306200",
    "end": "1308360"
  },
  {
    "text": "to work on the Nvidia stuff and none of",
    "start": "1308360",
    "end": "1310240"
  },
  {
    "text": "this stuff going to work on AMD and with",
    "start": "1310240",
    "end": "1312480"
  },
  {
    "text": "all those GPU frame and mpu you know uh",
    "start": "1312480",
    "end": "1316000"
  },
  {
    "text": "architecture that coming along you know",
    "start": "1316000",
    "end": "1317760"
  },
  {
    "text": "it become become",
    "start": "1317760",
    "end": "1319440"
  },
  {
    "text": "I think a huge problem for portability",
    "start": "1319440",
    "end": "1321120"
  },
  {
    "text": "right you know that then of course you",
    "start": "1321120",
    "end": "1322679"
  },
  {
    "text": "know people um are not really interested",
    "start": "1322679",
    "end": "1325840"
  },
  {
    "text": "in working with C++ anymore especially",
    "start": "1325840",
    "end": "1327840"
  },
  {
    "text": "application developers you know I think",
    "start": "1327840",
    "end": "1329320"
  },
  {
    "text": "rust and go would be the languages would",
    "start": "1329320",
    "end": "1331440"
  },
  {
    "text": "much more prefer you know so I think to",
    "start": "1331440",
    "end": "1333640"
  },
  {
    "text": "provide a more than language framework",
    "start": "1333640",
    "end": "1335760"
  },
  {
    "text": "that's uh that on top of those but do",
    "start": "1335760",
    "end": "1337559"
  },
  {
    "text": "not add much weight to that C++ um",
    "start": "1337559",
    "end": "1339960"
  },
  {
    "text": "framework would be the ideal case you",
    "start": "1339960",
    "end": "1342640"
  },
  {
    "text": "know that's uh that's why we have um we",
    "start": "1342640",
    "end": "1346000"
  },
  {
    "text": "created um you know um uh uh a wasm ede",
    "start": "1346000",
    "end": "1349320"
  },
  {
    "text": "and the application on top of it called",
    "start": "1349320",
    "end": "1350679"
  },
  {
    "text": "llama ede right you know so that's where",
    "start": "1350679",
    "end": "1352440"
  },
  {
    "text": "you see par all those demos and U so um",
    "start": "1352440",
    "end": "1356799"
  },
  {
    "text": "before I hand over to Miley I I would",
    "start": "1356799",
    "end": "1359039"
  },
  {
    "text": "also like to add you know um there's",
    "start": "1359039",
    "end": "1361279"
  },
  {
    "text": "currently um couple hundred thousand",
    "start": "1361279",
    "end": "1363559"
  },
  {
    "text": "machines running L to run large language",
    "start": "1363559",
    "end": "1366279"
  },
  {
    "text": "model inference so it's um you know so",
    "start": "1366279",
    "end": "1368799"
  },
  {
    "text": "if you ask me it's production ready",
    "start": "1368799",
    "end": "1370440"
  },
  {
    "text": "right you know it's uh so mostly our",
    "start": "1370440",
    "end": "1372640"
  },
  {
    "text": "personal laptops or you know um um Edge",
    "start": "1372640",
    "end": "1376159"
  },
  {
    "text": "devices like Raspberry Pi type of",
    "start": "1376159",
    "end": "1377720"
  },
  {
    "text": "devices or orange Pi all those all those",
    "start": "1377720",
    "end": "1380120"
  },
  {
    "text": "Pi devices that has mpu on it right uh",
    "start": "1380120",
    "end": "1382559"
  },
  {
    "text": "robotic devices and also um um H Cloud",
    "start": "1382559",
    "end": "1386360"
  },
  {
    "text": "servers like the servers you GPU servers",
    "start": "1386360",
    "end": "1388760"
  },
  {
    "text": "you get from um you know traditional CDM",
    "start": "1388760",
    "end": "1391200"
  },
  {
    "text": "providers like Cloud FL or fast you you",
    "start": "1391200",
    "end": "1393440"
  },
  {
    "text": "know places like those right so yeah",
    "start": "1393440",
    "end": "1395679"
  },
  {
    "text": "that's a so Lama Edge is a uh is a rust",
    "start": "1395679",
    "end": "1398600"
  },
  {
    "text": "application that we build the large",
    "start": "1398600",
    "end": "1399919"
  },
  {
    "text": "language model around time on top of",
    "start": "1399919",
    "end": "1401279"
  },
  {
    "text": "wasm edge",
    "start": "1401279",
    "end": "1402520"
  },
  {
    "text": "so yeah so uh yeah L is just like",
    "start": "1402520",
    "end": "1407520"
  },
  {
    "text": "Michael mentioned it's a a a set of",
    "start": "1407520",
    "end": "1410279"
  },
  {
    "text": "tools uh AI related to uh web on top of",
    "start": "1410279",
    "end": "1414159"
  },
  {
    "text": "w match and it's a that platform you can",
    "start": "1414159",
    "end": "1417240"
  },
  {
    "text": "see it that way and it's um allows you",
    "start": "1417240",
    "end": "1420640"
  },
  {
    "text": "to build open a compatible API servers",
    "start": "1420640",
    "end": "1424240"
  },
  {
    "text": "uh it would support multimodel apis and",
    "start": "1424240",
    "end": "1427360"
  },
  {
    "text": "Tool calls and building search and also",
    "start": "1427360",
    "end": "1430799"
  },
  {
    "text": "rack so you can write in your uh in",
    "start": "1430799",
    "end": "1434440"
  },
  {
    "text": "different languages like uh rust and",
    "start": "1434440",
    "end": "1436600"
  },
  {
    "text": "JavaScript and compile it in into uh web",
    "start": "1436600",
    "end": "1439799"
  },
  {
    "text": "assembly and then it would be fully",
    "start": "1439799",
    "end": "1441960"
  },
  {
    "text": "light uh portable and lightweight and uh",
    "start": "1441960",
    "end": "1445200"
  },
  {
    "text": "yeah uh so that's",
    "start": "1445200",
    "end": "1446799"
  },
  {
    "text": "a uh GitHub repo for the uh Lage project",
    "start": "1446799",
    "end": "1452360"
  },
  {
    "text": "and um uh I think we have just already",
    "start": "1452360",
    "end": "1455840"
  },
  {
    "text": "covered those so it's um High weigh and",
    "start": "1455840",
    "end": "1459360"
  },
  {
    "text": "portable and uh you can uh use any open",
    "start": "1459360",
    "end": "1462960"
  },
  {
    "text": "source lend language models uh on",
    "start": "1462960",
    "end": "1466200"
  },
  {
    "text": "hugging phase and it's embeded and uh",
    "start": "1466200",
    "end": "1469640"
  },
  {
    "text": "it's uh uh because it's already uh uh",
    "start": "1469640",
    "end": "1474000"
  },
  {
    "text": "Sim seemlessly integrated into the kues",
    "start": "1474000",
    "end": "1479399"
  },
  {
    "text": "ecosystem and it's uh officially",
    "start": "1479679",
    "end": "1482159"
  },
  {
    "text": "supported by this uh different occation",
    "start": "1482159",
    "end": "1487480"
  },
  {
    "text": "uh tools and uh",
    "start": "1487480",
    "end": "1490799"
  },
  {
    "text": "uh Contin and fed and hat so yeah I",
    "start": "1490799",
    "end": "1495720"
  },
  {
    "text": "guess uh that's would bring us to the uh",
    "start": "1495720",
    "end": "1502120"
  },
  {
    "text": "calling for contributor parts so uh as",
    "start": "1502120",
    "end": "1505520"
  },
  {
    "text": "an open source project we always need",
    "start": "1505520",
    "end": "1507520"
  },
  {
    "text": "more contributors so you can go check",
    "start": "1507520",
    "end": "1510120"
  },
  {
    "text": "out our GitHub repo and uh check out",
    "start": "1510120",
    "end": "1513640"
  },
  {
    "text": "these different taxs like good first",
    "start": "1513640",
    "end": "1516000"
  },
  {
    "text": "issue or hober Fest which allows you to",
    "start": "1516000",
    "end": "1519440"
  },
  {
    "text": "win small gifts by um finishing uh",
    "start": "1519440",
    "end": "1523760"
  },
  {
    "text": "different tasks and also UHF mentorship",
    "start": "1523760",
    "end": "1528000"
  },
  {
    "text": "I think we are one of the um project",
    "start": "1528000",
    "end": "1531320"
  },
  {
    "text": "that provide the most uh the most",
    "start": "1531320",
    "end": "1533399"
  },
  {
    "text": "mentors in the mentorship program with",
    "start": "1533399",
    "end": "1536279"
  },
  {
    "text": "Lin foundation so every year we would",
    "start": "1536279",
    "end": "1539080"
  },
  {
    "text": "have uh 12 mentees so uh four mentees",
    "start": "1539080",
    "end": "1543799"
  },
  {
    "text": "each uh each term so three terms a year",
    "start": "1543799",
    "end": "1548120"
  },
  {
    "text": "and also Google Su",
    "start": "1548120",
    "end": "1551039"
  },
  {
    "text": "codes and uh yeah and if you guys have",
    "start": "1551039",
    "end": "1555440"
  },
  {
    "text": "uh successfully run um",
    "start": "1555440",
    "end": "1558760"
  },
  {
    "text": "what we have demoed or like have wrote a",
    "start": "1558760",
    "end": "1561919"
  },
  {
    "text": "article about it you can participate in",
    "start": "1561919",
    "end": "1565120"
  },
  {
    "text": "this um incentive",
    "start": "1565120",
    "end": "1568120"
  },
  {
    "text": "program and every month we would have a",
    "start": "1568120",
    "end": "1571760"
  },
  {
    "text": "monthly community meeting at the first",
    "start": "1571760",
    "end": "1574960"
  },
  {
    "text": "uh Tuesday of each month um and it's all",
    "start": "1574960",
    "end": "1578960"
  },
  {
    "text": "public and everyone can sign up and join",
    "start": "1578960",
    "end": "1583640"
  },
  {
    "text": "us uh so we are going to uh host was",
    "start": "1583640",
    "end": "1588039"
  },
  {
    "text": "there",
    "start": "1588039",
    "end": "1588799"
  },
  {
    "text": "de room in uh Brussels in foston and",
    "start": "1588799",
    "end": "1593039"
  },
  {
    "text": "right now the cfp has opened and also uh",
    "start": "1593039",
    "end": "1597320"
  },
  {
    "text": "this gim is some some new conference we",
    "start": "1597320",
    "end": "1601080"
  },
  {
    "text": "just started from last year so it's uh",
    "start": "1601080",
    "end": "1604559"
  },
  {
    "text": "very similar to foston uh it's hosted",
    "start": "1604559",
    "end": "1608880"
  },
  {
    "text": "this year in Del delord uh uh Del and",
    "start": "1608880",
    "end": "1614120"
  },
  {
    "text": "Del sorry Del and uh Beijing this year",
    "start": "1614120",
    "end": "1618080"
  },
  {
    "text": "uh and oh last year it was in Shanghai",
    "start": "1618080",
    "end": "1621520"
  },
  {
    "text": "and it was a collocated event with Cube",
    "start": "1621520",
    "end": "1624120"
  },
  {
    "text": "Kong",
    "start": "1624120",
    "end": "1625159"
  },
  {
    "text": "China so um and also kcd",
    "start": "1625159",
    "end": "1629679"
  },
  {
    "text": "2025 um I'm hosting kcd Beijing in March",
    "start": "1629679",
    "end": "1633720"
  },
  {
    "text": "15 which would be the first kubernetes",
    "start": "1633720",
    "end": "1637039"
  },
  {
    "text": "community kubernetes community days uh",
    "start": "1637039",
    "end": "1640399"
  },
  {
    "text": "of the world so uh the CP will be open",
    "start": "1640399",
    "end": "1643840"
  },
  {
    "text": "soon and also uh we are one of the",
    "start": "1643840",
    "end": "1646559"
  },
  {
    "text": "co-organizers for Russ",
    "start": "1646559",
    "end": "1648679"
  },
  {
    "text": "R China comp uh if you guys are",
    "start": "1648679",
    "end": "1651600"
  },
  {
    "text": "interested in in speaking you can submit",
    "start": "1651600",
    "end": "1654159"
  },
  {
    "text": "a talk and that would be our um QR code",
    "start": "1654159",
    "end": "1658039"
  },
  {
    "text": "for our Discord community and uh YouTube",
    "start": "1658039",
    "end": "1662120"
  },
  {
    "text": "and also that's our uh GitHub and",
    "start": "1662120",
    "end": "1664720"
  },
  {
    "text": "Twitter handles and Linkedin names so if",
    "start": "1664720",
    "end": "1668120"
  },
  {
    "text": "you're interested uh please reach out to",
    "start": "1668120",
    "end": "1670279"
  },
  {
    "text": "us and I guess that's uh that will be",
    "start": "1670279",
    "end": "1674200"
  },
  {
    "text": "the end of do you have anything to add",
    "start": "1674200",
    "end": "1676600"
  },
  {
    "text": "Michael no I think we have couple",
    "start": "1676600",
    "end": "1678440"
  },
  {
    "text": "minutes so you know so if there's uh",
    "start": "1678440",
    "end": "1680159"
  },
  {
    "text": "questions you know that's uh we are",
    "start": "1680159",
    "end": "1682039"
  },
  {
    "text": "happy to answer them you know I know",
    "start": "1682039",
    "end": "1683760"
  },
  {
    "text": "this talk didn't get into a lot of",
    "start": "1683760",
    "end": "1685519"
  },
  {
    "text": "technical details we didn't really show",
    "start": "1685519",
    "end": "1687480"
  },
  {
    "text": "you the rust code that kind of you know",
    "start": "1687480",
    "end": "1689440"
  },
  {
    "text": "that perform all those they're not super",
    "start": "1689440",
    "end": "1691240"
  },
  {
    "text": "complicated just go to our GitHub",
    "start": "1691240",
    "end": "1693039"
  },
  {
    "text": "repositories you know those are I think",
    "start": "1693039",
    "end": "1695360"
  },
  {
    "text": "you know like I said compiling to like",
    "start": "1695360",
    "end": "1697559"
  },
  {
    "text": "20 megabytes it can't be that difficult",
    "start": "1697559",
    "end": "1699720"
  },
  {
    "text": "so you know so if there's any questions",
    "start": "1699720",
    "end": "1701600"
  },
  {
    "text": "please",
    "start": "1701600",
    "end": "1704600"
  },
  {
    "text": "oh okay then you know so um we're going",
    "start": "1714039",
    "end": "1717000"
  },
  {
    "text": "to stay here um for the next couple",
    "start": "1717000",
    "end": "1719760"
  },
  {
    "text": "minutes before the next speaker shows up",
    "start": "1719760",
    "end": "1721279"
  },
  {
    "text": "so you know so if you have anything you",
    "start": "1721279",
    "end": "1722880"
  },
  {
    "text": "want to talk to us privately you know",
    "start": "1722880",
    "end": "1724480"
  },
  {
    "text": "you can uh come up and otherwise thank",
    "start": "1724480",
    "end": "1727039"
  },
  {
    "text": "you very so much for coming to our talk",
    "start": "1727039",
    "end": "1728760"
  },
  {
    "text": "and uh wish you a good day",
    "start": "1728760",
    "end": "1732799"
  }
]
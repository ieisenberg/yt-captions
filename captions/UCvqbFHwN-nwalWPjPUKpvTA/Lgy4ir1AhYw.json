[
  {
    "text": "thank you for attending this session um I'm Uki working for cyber agent in Japan",
    "start": "40",
    "end": "8639"
  },
  {
    "text": "and so I'm technical read Q Pro utl and training working group and so I'm",
    "start": "8639",
    "end": "17199"
  },
  {
    "text": "technically read um Cube kubernetes q",
    "start": "17199",
    "end": "22359"
  },
  {
    "text": "and Ria for cube Contra manager jav API",
    "start": "22359",
    "end": "28000"
  },
  {
    "text": "so today um my co-speaker Andre is unfortunately unable to",
    "start": "28000",
    "end": "35160"
  },
  {
    "text": "attending this session in person so but so I got um videos from him so I will",
    "start": "35160",
    "end": "45680"
  },
  {
    "text": "pra a video from him so let's start so today's session is so democratizing AI",
    "start": "45680",
    "end": "56079"
  },
  {
    "text": "model training on cuberes with c job and job",
    "start": "56079",
    "end": "61960"
  },
  {
    "text": "set so the first part is um Android part",
    "start": "61960",
    "end": "68320"
  },
  {
    "text": "so let me phase",
    "start": "68320",
    "end": "73880"
  },
  {
    "text": "videos hey kcon I'm Andre I work at Apple I'm also member of the K steering committee I've been this committee for",
    "start": "79720",
    "end": "85759"
  },
  {
    "text": "last six and a half years I've been involved in development of projects such as training operator and ctib and today",
    "start": "85759",
    "end": "91159"
  },
  {
    "text": "before we actually going to share you how we going to democratize modal training on top of compus I want to speak a little bit about the background",
    "start": "91159",
    "end": "96840"
  },
  {
    "text": "and history so let me first all talk about the data scientists so in Ideal World data scientists what they want",
    "start": "96840",
    "end": "102280"
  },
  {
    "text": "they want to write their fighter code and want to have have a way to actually quickly scale it and the tricky part",
    "start": "102280",
    "end": "107360"
  },
  {
    "text": "because it's actually interactive process they want to have a way to actually repeat this multiple times before to find like the best",
    "start": "107360",
    "end": "113159"
  },
  {
    "text": "configuration for their model so they can push it to production but in reality there are many things which associated",
    "start": "113159",
    "end": "118960"
  },
  {
    "text": "with this process for example you need to make sure you can appr properly configure your Docker images your data access maybe you want to like enable",
    "start": "118960",
    "end": "125560"
  },
  {
    "text": "different policies like fail or success policies for full tolerance maybe you want to enable the gang scheduling or",
    "start": "125560",
    "end": "131599"
  },
  {
    "text": "maybe you want to configure your uh resource cues for efficient uh Resource Management so we call all of this as",
    "start": "131599",
    "end": "137879"
  },
  {
    "text": "kind of infrastructure pain which uh data scientists need to deal with before they can write the code and scale it and",
    "start": "137879",
    "end": "143560"
  },
  {
    "text": "we need to find a way how we can abstract it and simplify it also there are many many challenges which which is",
    "start": "143560",
    "end": "150200"
  },
  {
    "text": "associated with model training for example right now we live in the world of generative a models become very complex it has billions of parameters",
    "start": "150200",
    "end": "156760"
  },
  {
    "text": "that is set also very huge so we need to find a way how we can distribute them across multiple GPU devices also we need",
    "start": "156760",
    "end": "162920"
  },
  {
    "text": "to make sure like we efficiently manage the computer sources uh like gpus and tpus uh also like we need to find uh",
    "start": "162920",
    "end": "169360"
  },
  {
    "text": "provide an API for all this diverse ml infrastructure and all this new distributor strategies like fsdp data",
    "start": "169360",
    "end": "176040"
  },
  {
    "text": "and model parallelism so if we summarize all of this like what users actually want they want to write their code and",
    "start": "176040",
    "end": "182040"
  },
  {
    "text": "they want to scale it so they want to make sure like the environment actually simple flexible and scalable and they",
    "start": "182040",
    "end": "187799"
  },
  {
    "text": "want to make sure like they can uh just be focusing on the model development instead of like infrastructure so by that I just want to",
    "start": "187799",
    "end": "194680"
  },
  {
    "text": "quickly also talk about the qflow so I hope many of you familiar with this ecosystem but just to summarize qflow is",
    "start": "194680",
    "end": "200920"
  },
  {
    "text": "the ecosystem of the different open source project they can be used as a standalone applications so I have a different projects for data processing",
    "start": "200920",
    "end": "207480"
  },
  {
    "text": "training tuning serving pip lines so you FL like bridge between like ml ecosystem",
    "start": "207480",
    "end": "213200"
  },
  {
    "text": "and the cloud ecosystem all these projects run natively on top of kuus and in this session we only be focusing on",
    "start": "213200",
    "end": "218760"
  },
  {
    "text": "training operator so training operator is actually the stalon open source project which can uh run distributed",
    "start": "218760",
    "end": "225400"
  },
  {
    "text": "training on top of kubernetes for most popular Frameworks like pytorch Jacks denlow it also offered the python SDK",
    "start": "225400",
    "end": "232760"
  },
  {
    "text": "and API to play with it's also like capable to do llm fine tuning elastic training we also have integration with q",
    "start": "232760",
    "end": "240040"
  },
  {
    "text": "volcano for advanced resource management and job scheduling we also have an MPI",
    "start": "240040",
    "end": "245159"
  },
  {
    "text": "support for different distributed techniques uh and we we have also like",
    "start": "245159",
    "end": "251239"
  },
  {
    "text": "the features around all redu type of training so I just want to also spend a little bit of time about the history of",
    "start": "251239",
    "end": "256639"
  },
  {
    "text": "qlow and training operator so back in 2017 when Google actually introduced qlow project it was a uh they kind of",
    "start": "256639",
    "end": "263440"
  },
  {
    "text": "like created the component called tensorflow operator which kind of orchestrate the TF jobs the TF jobs is",
    "start": "263440",
    "end": "268720"
  },
  {
    "text": "actually allows you to to run pza flow task on top of kubernets natively uh so back then uh kubernetes was lacking with",
    "start": "268720",
    "end": "275400"
  },
  {
    "text": "some uh Advanced badge uh features so that is why we have to implement all the features by ourselves so in 2018 and",
    "start": "275400",
    "end": "282120"
  },
  {
    "text": "2019 we expanded support with more Frameworks back the time actually joined the community so we started support",
    "start": "282120",
    "end": "288000"
  },
  {
    "text": "pytorch MX chop uh MPI XG boost and we have a lot of customer sources which",
    "start": "288000",
    "end": "293720"
  },
  {
    "text": "allows you to do distributive training just with the specific framework also like we have a lot of these different",
    "start": "293720",
    "end": "299039"
  },
  {
    "text": "operators we decided to consolidate them in the single operator so we call the training operator wei1 in",
    "start": "299039",
    "end": "304919"
  },
  {
    "text": "2021 which actually like a single kubernetes uh operator which managing all those crds and back then likeus was",
    "start": "304919",
    "end": "312759"
  },
  {
    "text": "commus introduced the B working group which just designed to actually simplify and improve the way to run HPC and AI",
    "start": "312759",
    "end": "319160"
  },
  {
    "text": "workloads so there are was there were a lot of great initiatives like Q uh job set leader work set projects which also",
    "start": "319160",
    "end": "326280"
  },
  {
    "text": "like improve the the running those workloads also like many features was contributed directly to the jobs like",
    "start": "326280",
    "end": "331520"
  },
  {
    "text": "index jobs Port file policies which also improved the uh the AI model training uh",
    "start": "331520",
    "end": "337199"
  },
  {
    "text": "workloads and back then so right now in 2024 we actually uh try to find uh we",
    "start": "337199",
    "end": "344120"
  },
  {
    "text": "actually try to see how we can consolidate our effort being kues and qflow community so we can provide UniFi",
    "start": "344120",
    "end": "350600"
  },
  {
    "text": "infrastructure for all the users who want to use kues as the primary tool for model training and we want to see how we",
    "start": "350600",
    "end": "357240"
  },
  {
    "text": "can consolidate our efforts so by that I'm super exciting to announce you the new project which we",
    "start": "357240",
    "end": "362360"
  },
  {
    "text": "call Q flow training V2 and uh we have several goals uh for this project that",
    "start": "362360",
    "end": "368160"
  },
  {
    "text": "we um identify so the first goal it should be very simple to use and simple",
    "start": "368160",
    "end": "373440"
  },
  {
    "text": "to scale so since we work with data scientists we want to make sure it's the python is our kind of main interface uh",
    "start": "373440",
    "end": "380400"
  },
  {
    "text": "to interact with the apis so data scientists they don't need to work with the docker don't need to work with a yaml just python also like because right",
    "start": "380400",
    "end": "387800"
  },
  {
    "text": "now many people just do the post training we want to make sure uh this project is capable to quickly fine-tune",
    "start": "387800",
    "end": "393280"
  },
  {
    "text": "all the favorite llms um also we want to provide the robust support for all this um um diverse ml",
    "start": "393280",
    "end": "400720"
  },
  {
    "text": "ecosystem we want to streamline the model and data set pre utilization so we",
    "start": "400720",
    "end": "406240"
  },
  {
    "text": "can make sure like this task can be delegated on on the CPU workloads and reduce the the cost uh and optimize cost",
    "start": "406240",
    "end": "412800"
  },
  {
    "text": "for for for gpus and the most important thing we want to consolidate effort between kuas and the Q communities so we",
    "start": "412800",
    "end": "419280"
  },
  {
    "text": "can work together to actually make cators uh to actually democratize cators for model shining workloads and Not",
    "start": "419280",
    "end": "426840"
  },
  {
    "text": "Duplicate our efforts so I think like the the best thing to actually see it live with show like the demo and let me",
    "start": "426840",
    "end": "434479"
  },
  {
    "text": "show you few examples of this new API so right now in this demo I'm going",
    "start": "434479",
    "end": "441560"
  },
  {
    "text": "to play the role of data scientist and the first example actually what I'm going to do I'm going to develop the PTO model which will do the image",
    "start": "441560",
    "end": "447479"
  },
  {
    "text": "classification and this is very simp simple example but just to show like the power of the scale and this model",
    "start": "447479",
    "end": "453440"
  },
  {
    "text": "actually will uh do the the fashionist uh uh question data set image",
    "start": "453440",
    "end": "459360"
  },
  {
    "text": "classification so as we can see on the left side I have my workspace I have multiple python files so I have the first file called Data set. py this file",
    "start": "459360",
    "end": "466840"
  },
  {
    "text": "actually contains the configuration for my data set so here I'm just using the open source fion is data set i'm",
    "start": "466840",
    "end": "472400"
  },
  {
    "text": "converting my images to the tensors before I can uh use it in my training code so then I have the file called",
    "start": "472400",
    "end": "479159"
  },
  {
    "text": "model py so this model contains the my actually convolution neural network",
    "start": "479159",
    "end": "484319"
  },
  {
    "text": "model which has like two convolution layers and two linear layers and as output we have like 10 different images",
    "start": "484319",
    "end": "489840"
  },
  {
    "text": "because we have 10 samples of our data set and we have like the forward Loop for my model and the third file called",
    "start": "489840",
    "end": "494879"
  },
  {
    "text": "train. pii and this file actually contains the training Loop for my uh actual pytorch training so here it's",
    "start": "494879",
    "end": "501280"
  },
  {
    "text": "very simple just native pytorch API uh I want to make sure like my if my my code can be distributed across across",
    "start": "501280",
    "end": "508800"
  },
  {
    "text": "multiple part noes so for that I'm using the distributed uh torch distributed API",
    "start": "508800",
    "end": "514760"
  },
  {
    "text": "uh also like I'm reusing the assets from different files so here I'm importing the am data set from my data set model",
    "start": "514760",
    "end": "521000"
  },
  {
    "text": "from this file I'm attaching this data set to data loader um then I'm attaching",
    "start": "521000",
    "end": "526480"
  },
  {
    "text": "my data set to the distributor so the data can be distributed uh so the next step for me is actually getting the",
    "start": "526480",
    "end": "531720"
  },
  {
    "text": "model from the model uh from the model file and attaching this model to the to the device and the next like the final",
    "start": "531720",
    "end": "538519"
  },
  {
    "text": "step is is defining like the the pyto training clop so here is again it's just native pyto code when I have my uh",
    "start": "538519",
    "end": "544560"
  },
  {
    "text": "Optimizer when I running my Feit foring clop and at the very end when my training is complete I'm just exporting",
    "start": "544560",
    "end": "551200"
  },
  {
    "text": "model all the way to the S3 so I can do my model evaluation so I'm defining my training Loop here like the whole of the",
    "start": "551200",
    "end": "557959"
  },
  {
    "text": "Native py API again what is my next step uh so my next step is actually running this code make sure it's actually",
    "start": "557959",
    "end": "563959"
  },
  {
    "text": "working so I am importing from train.py uh my train py Model A my train P model",
    "start": "563959",
    "end": "570040"
  },
  {
    "text": "function I just want to make sure it's actually runnable so we can see it is running on CPU it's actually just run on",
    "start": "570040",
    "end": "577040"
  },
  {
    "text": "few batches and training is actually running so I'm happy with it I want to scale it right so back to my",
    "start": "577040",
    "end": "582680"
  },
  {
    "text": "presentation I write my P code I want to scale it so what is my next step uh it's",
    "start": "582680",
    "end": "588320"
  },
  {
    "text": "actually using the qflow API so for this we have this new API called list run times so this is the python API which",
    "start": "588320",
    "end": "595360"
  },
  {
    "text": "actually leads you sever run times you as a data science can play with so you can think as the runtime like a",
    "start": "595360",
    "end": "601040"
  },
  {
    "text": "blueprint or configuration U which contains the optimal configuration that",
    "start": "601040",
    "end": "606880"
  },
  {
    "text": "I can use to perform different tasks so run times can be used for pre-training or it can be used for post trining for",
    "start": "606880",
    "end": "613800"
  },
  {
    "text": "pre-training runtime it means like I can use them for if I want to train my model on a large data set from scratch uh and",
    "start": "613800",
    "end": "620680"
  },
  {
    "text": "I have like runtime for Jacks for torch here also run time shows that how many devices by default is going to use and",
    "start": "620680",
    "end": "627800"
  },
  {
    "text": "also what is the type of the device and we have run time for post training the post training run time can be use for fine tuning like for example supervised",
    "start": "627800",
    "end": "634600"
  },
  {
    "text": "fine tuning or reinforcement learning with human fback algorithms so which actually allows me to do the quickly llm",
    "start": "634600",
    "end": "641560"
  },
  {
    "text": "evaluation and llm fine tuning so for here we also like showing the default devices this run time is going to use uh",
    "start": "641560",
    "end": "649800"
  },
  {
    "text": "for me uh if I want to play with it so for this example I'm going to use the torch distributed runtime so I'm going",
    "start": "649800",
    "end": "655600"
  },
  {
    "text": "to assign this runtime to my variable and the next step is actually uh running",
    "start": "655600",
    "end": "660839"
  },
  {
    "text": "using the train API so again it's simple python API which uh which can actually",
    "start": "660839",
    "end": "666480"
  },
  {
    "text": "accept my sharing function as the input and accepting the scaling cont like for example how many pytorch nodes I want to",
    "start": "666480",
    "end": "673279"
  },
  {
    "text": "use and how like how much resources I'm going to use for every node so for this particular example I'm going to use the",
    "start": "673279",
    "end": "678839"
  },
  {
    "text": "two GPU and three nodes so in total we're going to distribute my data across six gpus so this actually generate the",
    "start": "678839",
    "end": "686519"
  },
  {
    "text": "random job ID so this is my job I can use the python API to list the",
    "start": "686519",
    "end": "693639"
  },
  {
    "text": "job and this is actually creating the job uh on the CES cluster and the the",
    "start": "693639",
    "end": "699120"
  },
  {
    "text": "thing is we also creating the snapshot of my file system of my workspace which we have on the left side with all those",
    "start": "699120",
    "end": "704560"
  },
  {
    "text": "files and putting those files on my distribut training job so the files is are distributed across all of the",
    "start": "704560",
    "end": "711000"
  },
  {
    "text": "devices and all of the P nodes so next step for me I can also run the get job API and list all the components",
    "start": "711000",
    "end": "719560"
  },
  {
    "text": "so all of the jobs they uh they contains multiple components so because I'm running this job on the three nodes it",
    "start": "719560",
    "end": "725800"
  },
  {
    "text": "has three components so every component represent a separate pych node and it also has the devices so since we're",
    "start": "725800",
    "end": "731720"
  },
  {
    "text": "running the two GPU per node every component has the uh two GPU has been attached to this uh to this component so",
    "start": "731720",
    "end": "739800"
  },
  {
    "text": "then when I checking my components and checking my jobs I can get the locks from my training uh from my uh using",
    "start": "739800",
    "end": "746040"
  },
  {
    "text": "using the get jop blocks API and as we can see here we here we're",
    "start": "746040",
    "end": "751120"
  },
  {
    "text": "using GPU the world size equal to six because we distribute our code AC our",
    "start": "751120",
    "end": "756600"
  },
  {
    "text": "code across um six devices and uh the data since like here we uh distribute",
    "start": "756600",
    "end": "763399"
  },
  {
    "text": "across six devices the 6,000 samples distributed and every GPU is only",
    "start": "763399",
    "end": "768839"
  },
  {
    "text": "processing the 10,000 samples so at the very end when the tring is complete we exporting model to the S3 so the power",
    "start": "768839",
    "end": "775639"
  },
  {
    "text": "of this again I am as a data scientist I'm just working with the python I just work with python I quickly run my code",
    "start": "775639",
    "end": "782279"
  },
  {
    "text": "evaluate it and I'm scale it and I think it's like if I'm happy with it my code is ready to go to production because",
    "start": "782279",
    "end": "788079"
  },
  {
    "text": "everything is being packaged as the python files and I can create the unit test I can package them I can uh share",
    "start": "788079",
    "end": "794959"
  },
  {
    "text": "it and again I can also download my model from S3 here and as we can see the model should",
    "start": "794959",
    "end": "802440"
  },
  {
    "text": "appear on the left side yeah model PT and I can try test my model with sample images so we're going to pass some of",
    "start": "802440",
    "end": "808959"
  },
  {
    "text": "the testing images so this is all the samples from data set and let's see what kind of output our model will be",
    "start": "808959",
    "end": "814440"
  },
  {
    "text": "generated so yeah we can see that the green actually indicated the model correctly predict the image righted",
    "start": "814440",
    "end": "819600"
  },
  {
    "text": "indicate the model incorrectly predict an image and so we can run it several times and several batches just to see",
    "start": "819600",
    "end": "825160"
  },
  {
    "text": "what is results of my model so it's very simple but it's very powerful because I can control scale I can control my code",
    "start": "825160",
    "end": "832480"
  },
  {
    "text": "I I just I don't really worry about anything else like images yamos just python just pytorch and it's very",
    "start": "832480",
    "end": "839399"
  },
  {
    "text": "scalable so the next example that I want to show actually the the how we can use this post training run time so for this",
    "start": "839399",
    "end": "845320"
  },
  {
    "text": "we're going to f tune Lama 3.2 with one bilon parameters so the first step for me as a data scientist similar to the",
    "start": "845320",
    "end": "851440"
  },
  {
    "text": "previous example I'm just listing all those run times so and I'm going to use this torch",
    "start": "851440",
    "end": "857600"
  },
  {
    "text": "tune L 3.2 runtime so this runtime by default using four GPU devices and uh",
    "start": "857600",
    "end": "864480"
  },
  {
    "text": "how I can kick off uh the job for me instead of passing the function I can use the Str to just passing the data set",
    "start": "864480",
    "end": "870600"
  },
  {
    "text": "configuration and the trainer configuration so we as the qlow community are planning to support a lot",
    "start": "870600",
    "end": "876000"
  },
  {
    "text": "of uh llm run times for data scientist to play with but basically we pre-create the uh the initialization and we",
    "start": "876000",
    "end": "882880"
  },
  {
    "text": "precreate the trader and data scientist just need to adjust the parameters they want to tweak for example this uh in",
    "start": "882880",
    "end": "888800"
  },
  {
    "text": "this particular sample I adjusting the lower config so we're going to do the parameter ficient fine tuning I'm going",
    "start": "888800",
    "end": "894160"
  },
  {
    "text": "to just pass the rank equals to four for my lower config and I'm going to use the alpaka that data set which contains uh",
    "start": "894160",
    "end": "900920"
  },
  {
    "text": "several instructions which I want to use to fine-tune my my Lama 3.2 so again",
    "start": "900920",
    "end": "906120"
  },
  {
    "text": "same API same function if I don't want to pass this configuration I can even you know hide it and use a default",
    "start": "906120",
    "end": "911639"
  },
  {
    "text": "runtime configuration uh but I want to adjust it to make sure I can also address the lur config so it should",
    "start": "911639",
    "end": "917320"
  },
  {
    "text": "generate the random job ID the same API I can list all of my jobs uh I can see that one jobs have",
    "start": "917320",
    "end": "923880"
  },
  {
    "text": "been created and the one job already succeeded the previous one I can also list all of my components from my jobs",
    "start": "923880",
    "end": "929399"
  },
  {
    "text": "so compared to the previous example since this components is actually using the post training runtime or blueprint",
    "start": "929399",
    "end": "934959"
  },
  {
    "text": "we can call it it also has the initializer job which actually do the",
    "start": "934959",
    "end": "940000"
  },
  {
    "text": "model and data set initialization on CPU to reduce the GPU uh time when actually",
    "start": "940000",
    "end": "946319"
  },
  {
    "text": "we don't need it right and then it actually distribute this data across all this nodes so in this example we're just using the one node with four GPU uh in",
    "start": "946319",
    "end": "954120"
  },
  {
    "text": "in this node so then we can also use the python API to get the locks from datas",
    "start": "954120",
    "end": "959199"
  },
  {
    "text": "at initializer we can see that datas has been downloaded also we can check like the model initializer locks that the",
    "start": "959199",
    "end": "964959"
  },
  {
    "text": "model also have been downloaded uh from the from the from the hugging phase and we can get the locks from uh",
    "start": "964959",
    "end": "973000"
  },
  {
    "text": "from our using the get job blocks API so this actually trainer behind the scenes that using fsdp to distribute our model",
    "start": "973000",
    "end": "980519"
  },
  {
    "text": "across uh multiple shards so we can reduce the memory footprint and make sure we can actually train this model on",
    "start": "980519",
    "end": "986279"
  },
  {
    "text": "v00 gpus also like since we're passing the four we using the one note with four",
    "start": "986279",
    "end": "992199"
  },
  {
    "text": "gpus the world size equals to four and as we can see here the lurer config like the config that we pass is actually",
    "start": "992199",
    "end": "997600"
  },
  {
    "text": "being propagated here so we only train 400,000 uh model parameter instead of 1 billion parameters so it's much faster",
    "start": "997600",
    "end": "1004440"
  },
  {
    "text": "and we can actually see the results so here we actually run the training um this is running right now inside the",
    "start": "1004440",
    "end": "1010639"
  },
  {
    "text": "training nodes and at the very end when the training will be complete we also do",
    "start": "1010639",
    "end": "1016319"
  },
  {
    "text": "the model evaluation and we export the P adapters to the S3 when the model is",
    "start": "1016319",
    "end": "1022120"
  },
  {
    "text": "complete so here you can see the memory footprint which is like around 12gb and what is GPU type so model P adapters",
    "start": "1022120",
    "end": "1028880"
  },
  {
    "text": "have been has been exported to S3 so what is my next step I want to test my model right so I want to import this",
    "start": "1028880",
    "end": "1034600"
  },
  {
    "text": "model all the way from My3 to my notebook uh this is downloading the",
    "start": "1034600",
    "end": "1040280"
  },
  {
    "text": "adapters and this is like loading the adapters to the hugging pH API so we can",
    "start": "1040280",
    "end": "1045480"
  },
  {
    "text": "make sure just to see how our model will perform and let's let's just pass some random prompts so let's ask the most",
    "start": "1045480",
    "end": "1051360"
  },
  {
    "text": "complicated question to the llm how many RS in Strawberry um I hope our model okay our",
    "start": "1051360",
    "end": "1058559"
  },
  {
    "text": "model is pretty as I can see it's uh pretty clever it's actually can um you know uh answer such complicated question",
    "start": "1058559",
    "end": "1065919"
  },
  {
    "text": "let's try to see if I run it again what okay okay for not every time not every time but at least you know we can see",
    "start": "1065919",
    "end": "1071440"
  },
  {
    "text": "some results so yeah so we can see the results from llm let's try to pass some other prompt like for example what is",
    "start": "1071440",
    "end": "1077440"
  },
  {
    "text": "Cube con and what is cu flow so we're passing the instructions we're passing the input to our model and we waiting",
    "start": "1077440",
    "end": "1082640"
  },
  {
    "text": "for response uh so right now like as we can",
    "start": "1082640",
    "end": "1088159"
  },
  {
    "text": "see the model producing results CCO flow to tools Brad governance ecosystem CCO",
    "start": "1088159",
    "end": "1093919"
  },
  {
    "text": "conference but qf flow it's a seit of tools to enable build train and deploy machine learning models using kuus great",
    "start": "1093919",
    "end": "1100679"
  },
  {
    "text": "so I'm actually getting my model I was evaluating this model and I getting my results it's very quick it's very",
    "start": "1100679",
    "end": "1106640"
  },
  {
    "text": "powerful and me as a data scientist I don't really worry about any of those infrastructure apis I'm just working",
    "start": "1106640",
    "end": "1112960"
  },
  {
    "text": "with python so what we actually saw um let me go back to my slide",
    "start": "1112960",
    "end": "1120000"
  },
  {
    "text": "so what we saw it's extremely simple but it's very powerful behind the scenes",
    "start": "1120000",
    "end": "1125880"
  },
  {
    "text": "because it's flexible enough and it's scalable enough so first of all I want to speak more about like Simplicity and",
    "start": "1125880",
    "end": "1131240"
  },
  {
    "text": "flexibility so we've been working with uh running model training for like almost like seven years so right now we",
    "start": "1131240",
    "end": "1137840"
  },
  {
    "text": "see the differ type of persona which we interact with so the first of all we can identify the devops engineer and melops",
    "start": "1137840",
    "end": "1144400"
  },
  {
    "text": "engineer Persona so for those folks like devops engineer usually they know the kubernetes API they know how to",
    "start": "1144400",
    "end": "1149640"
  },
  {
    "text": "configure the resource cues uh the volumes and other kubernetes API parameters and we have the amops",
    "start": "1149640",
    "end": "1155760"
  },
  {
    "text": "engineer who actually probably not like kuus API but they know how to deal with thepi with torch so they know some ml",
    "start": "1155760",
    "end": "1163320"
  },
  {
    "text": "configurations so for those folks we created the new API new C called training runtime which they can",
    "start": "1163320",
    "end": "1169600"
  },
  {
    "text": "pre-create and this runtime can be a blueprint or configuration for data scientists they can play with and",
    "start": "1169600",
    "end": "1176000"
  },
  {
    "text": "evaluate because data scientist they only know the py they they only need to know the py API so they can quickly",
    "start": "1176000",
    "end": "1182039"
  },
  {
    "text": "evaluate like they can quickly run their experiments reusing those blueprints that that was pre-created by their",
    "start": "1182039",
    "end": "1187559"
  },
  {
    "text": "platform engineers and then behind the scenes we're going to create the job set which actually will create the jobs to",
    "start": "1187559",
    "end": "1192880"
  },
  {
    "text": "perform the the fine-tuning or distribut training so what we saw in the demo behind the scenes something like this",
    "start": "1192880",
    "end": "1198200"
  },
  {
    "text": "happening this is the life cycle llm runtime the amops engineer and the vops engineer together they build those",
    "start": "1198200",
    "end": "1204200"
  },
  {
    "text": "runtimes we again as a community also playing to provide the state-ofthe-art run times to run those finding on top of",
    "start": "1204200",
    "end": "1210600"
  },
  {
    "text": "kuus these run times can be reused by data scientist so they can use the python SDK to kick off the job so job",
    "start": "1210600",
    "end": "1217320"
  },
  {
    "text": "will actually create the job set and the job set actually will create the multiple tasks like initializer job and the trainer job and initializer on CPU",
    "start": "1217320",
    "end": "1224799"
  },
  {
    "text": "will do the the asset initialization like data set and model and then the trainer actually create the pyter",
    "start": "1224799",
    "end": "1230720"
  },
  {
    "text": "cluster to distribute those workloads across multiple devices and multiple nodes and workers and then we we also",
    "start": "1230720",
    "end": "1237640"
  },
  {
    "text": "like exporting model all the way to the cloud storage also I have a custom like you know initializers that trying like",
    "start": "1237640",
    "end": "1243240"
  },
  {
    "text": "we as the the open source team is working on in in training operator we also have the custom LM trainer that you",
    "start": "1243240",
    "end": "1249360"
  },
  {
    "text": "can tweak to work with different models so data scien don't even need to worry about how to configure those complex",
    "start": "1249360",
    "end": "1255120"
  },
  {
    "text": "distributed environment and also also like I want to speak a little bit about simplicity so",
    "start": "1255120",
    "end": "1260880"
  },
  {
    "text": "as we saw in the demo data scientist they only work with python they can use Python to list the those run times they",
    "start": "1260880",
    "end": "1266600"
  },
  {
    "text": "can use the python to cck off the jobs they can use the train API to just you know uh pass the configurations they can",
    "start": "1266600",
    "end": "1272679"
  },
  {
    "text": "adjust they can pass the whole training function uh to the train API so this training function can be evaluated on",
    "start": "1272679",
    "end": "1278200"
  },
  {
    "text": "every pych node and it can be distributed so no Docker images just Python and just by",
    "start": "1278200",
    "end": "1284640"
  },
  {
    "text": "torch uh similar to this uh we converting this uh we're using this new customer defic",
    "start": "1284640",
    "end": "1291120"
  },
  {
    "text": "called train job and this train job has a minimal amount of parameters that scientist can TW for example it has the",
    "start": "1291120",
    "end": "1296720"
  },
  {
    "text": "configuration for trainer configuration for data set and configuration for model so trainer means like what kind of",
    "start": "1296720",
    "end": "1302440"
  },
  {
    "text": "parameters you want to pass directly to the your trainer like lower config for example data set means like what data",
    "start": "1302440",
    "end": "1309000"
  },
  {
    "text": "set you want to use what parameters you want to adjust model config also allows you to specify the output of your model",
    "start": "1309000",
    "end": "1314520"
  },
  {
    "text": "for example if you want to export your adapters to to like to some Custom Image or to different like you know uh blob",
    "start": "1314520",
    "end": "1320840"
  },
  {
    "text": "like cloud storage and also like they had this runtime reference where actually uh have the reference of the",
    "start": "1320840",
    "end": "1327559"
  },
  {
    "text": "runtime that platform Engineers actually prepare for data scientist so for that let me pass it to Yuki so he will tell",
    "start": "1327559",
    "end": "1333000"
  },
  {
    "text": "you more about what is this run time and how it can be useful to create those blueprints for data scientists um so",
    "start": "1333000",
    "end": "1340000"
  },
  {
    "text": "they can work with okay so let me switch to my slide",
    "start": "1340000",
    "end": "1348640"
  },
  {
    "text": "just a [Music]",
    "start": "1348640",
    "end": "1353869"
  },
  {
    "text": "second all right okay so from this slide so I'm going to introduce runtime CDs",
    "start": "1360360",
    "end": "1368600"
  },
  {
    "text": "and such mechanisms as Andre mentioned uh we",
    "start": "1368600",
    "end": "1374679"
  },
  {
    "text": "introduced two type of crds um based on the Persona so the run times are aimed",
    "start": "1374679",
    "end": "1383880"
  },
  {
    "text": "to be used by Ops related to developers like devops and ml Ops",
    "start": "1383880",
    "end": "1391720"
  },
  {
    "text": "engineer additionally so we have one type of runtime but we have two Rebel",
    "start": "1391720",
    "end": "1399240"
  },
  {
    "text": "run times the first Rebel is crossa training R time um which can be created",
    "start": "1399240",
    "end": "1407080"
  },
  {
    "text": "at the cross scope training runtime this is so useful when the Ops engineer want",
    "start": "1407080",
    "end": "1415360"
  },
  {
    "text": "to distribute the reusable run times to all ml engineer to all kubernetes",
    "start": "1415360",
    "end": "1425159"
  },
  {
    "text": "tenants the second Rebel is training run time which can be created at the name",
    "start": "1425159",
    "end": "1431720"
  },
  {
    "text": "space called training run time we are assuming the stuation where the ml or ml",
    "start": "1431720",
    "end": "1438960"
  },
  {
    "text": "Ops engineer want to create the Project Specific run",
    "start": "1438960",
    "end": "1444480"
  },
  {
    "text": "times next um let me introduce the each block of",
    "start": "1444480",
    "end": "1451279"
  },
  {
    "text": "runtime the first block is for machine learning specific parameter",
    "start": "1451279",
    "end": "1457960"
  },
  {
    "text": "specifications this allows us to specify the number of nodes number of processes",
    "start": "1457960",
    "end": "1464159"
  },
  {
    "text": "in the Single part and so on that is machine learning framework specific",
    "start": "1464159",
    "end": "1471440"
  },
  {
    "text": "parameters this will this will be set up by mlops Engineers since devops",
    "start": "1471440",
    "end": "1478760"
  },
  {
    "text": "Engineers sometimes do not have ml framework specific",
    "start": "1478760",
    "end": "1484760"
  },
  {
    "text": "knowledges the second block is Gang scheduling parameters as you know so machine",
    "start": "1484760",
    "end": "1492720"
  },
  {
    "text": "learning workloads and gang scheduling is so important",
    "start": "1492720",
    "end": "1499360"
  },
  {
    "text": "so the training operator supports the kubernetes schedule PR called scheduling",
    "start": "1499360",
    "end": "1506120"
  },
  {
    "text": "pring so when we install the C schedu pluging into your cluster this field can",
    "start": "1506120",
    "end": "1514720"
  },
  {
    "text": "be used final block is jobet",
    "start": "1514720",
    "end": "1520760"
  },
  {
    "text": "template and so jobet template details",
    "start": "1520760",
    "end": "1526039"
  },
  {
    "text": "so let me introduce next",
    "start": "1526039",
    "end": "1530320"
  },
  {
    "text": "slide this is the jobet template parts so the jobet template block has all of",
    "start": "1531159",
    "end": "1539480"
  },
  {
    "text": "jobet spec Fields but we have some Cube for dedicated reserved replicated jobs and",
    "start": "1539480",
    "end": "1547480"
  },
  {
    "text": "container name the one important resoled name is",
    "start": "1547480",
    "end": "1552760"
  },
  {
    "text": "train anode which is used by main training processes",
    "start": "1552760",
    "end": "1560039"
  },
  {
    "text": "additionally we will separately start the model and storage initialization",
    "start": "1560039",
    "end": "1565600"
  },
  {
    "text": "jobs and insert some parameters to train node as Andre described in",
    "start": "1565600",
    "end": "1575278"
  },
  {
    "text": "demo and so this is a corresponding table uh what run times and machine",
    "start": "1579120",
    "end": "1586520"
  },
  {
    "text": "learning Frameworks are support it so current CPR B1 API is supporting the",
    "start": "1586520",
    "end": "1593919"
  },
  {
    "text": "pyto T Pro Hing phas MPI Jacks pzle pzle",
    "start": "1593919",
    "end": "1601960"
  },
  {
    "text": "X boost by dedicated custom resources like pyal job and D",
    "start": "1601960",
    "end": "1609679"
  },
  {
    "text": "job but since bats API we are planning",
    "start": "1609679",
    "end": "1614960"
  },
  {
    "text": "to support all of B1 API supporting machine learning Frameworks",
    "start": "1614960",
    "end": "1620840"
  },
  {
    "text": "and more by runtime CD it's not dedicated to custom job",
    "start": "1620840",
    "end": "1628559"
  },
  {
    "text": "API because as you know the ml ecosystem is growing much faster and the State",
    "start": "1628559",
    "end": "1636200"
  },
  {
    "text": "ofthe art of Frameworks are replaced rapidly in this",
    "start": "1636200",
    "end": "1642520"
  },
  {
    "text": "sitation it's changing to follow the ml ecosystem and realize all of user",
    "start": "1642520",
    "end": "1648799"
  },
  {
    "text": "request by dedicated custom job API for example so sometimes users",
    "start": "1648799",
    "end": "1657240"
  },
  {
    "text": "request um can we support um this new parameters for XXX um machine learning",
    "start": "1657240",
    "end": "1665399"
  },
  {
    "text": "Frameworks and can we support the uh not open source U machine learning framework",
    "start": "1665399",
    "end": "1673840"
  },
  {
    "text": "um um in the training operator so we decided to provide the extensible",
    "start": "1673840",
    "end": "1682159"
  },
  {
    "text": "runtime and pring mechanism so that we can easily support",
    "start": "1682159",
    "end": "1687760"
  },
  {
    "text": "new Frameworks and allow external communities and users setting up arbit",
    "start": "1687760",
    "end": "1695559"
  },
  {
    "text": "parameters and machine learning framework separate from Upstream Cube for",
    "start": "1695559",
    "end": "1702000"
  },
  {
    "text": "committee actually um we are planning to support the LM run times like ramama",
    "start": "1702000",
    "end": "1710559"
  },
  {
    "text": "Jammer M by this extensible mechanism in the next slide let me",
    "start": "1710559",
    "end": "1717399"
  },
  {
    "text": "introduce what is extensive run times the training operator beats",
    "start": "1717399",
    "end": "1725279"
  },
  {
    "text": "API has two level extension mechanism the first is this pring",
    "start": "1725279",
    "end": "1731720"
  },
  {
    "text": "mechanism which can be extended part of Upstream training and crossa training",
    "start": "1731720",
    "end": "1738159"
  },
  {
    "text": "run time this extensive mechanism which is significantly",
    "start": "1738159",
    "end": "1744840"
  },
  {
    "text": "inspired by Cube schedu scheduling framework but the mechanism is a",
    "start": "1744840",
    "end": "1752039"
  },
  {
    "text": "slightly different from the scheduling framework this can be",
    "start": "1752039",
    "end": "1758440"
  },
  {
    "text": "executed when the training operator build the actual jobs based on the train",
    "start": "1758440",
    "end": "1765279"
  },
  {
    "text": "job and training run times the left side",
    "start": "1765279",
    "end": "1771519"
  },
  {
    "text": "block pre-execution phase will be executed before the training operator",
    "start": "1771519",
    "end": "1776760"
  },
  {
    "text": "build actual jobs as an example the custom variation extension",
    "start": "1776760",
    "end": "1783559"
  },
  {
    "text": "points are executed as a variating admission web hick the right side Block",
    "start": "1783559",
    "end": "1790640"
  },
  {
    "text": "Main phase will be executed um executed um to build",
    "start": "1790640",
    "end": "1798880"
  },
  {
    "text": "jobs and each extension points are executed step by step by left side to",
    "start": "1798880",
    "end": "1806120"
  },
  {
    "text": "right side and this can be extensible which means anyone can extend this",
    "start": "1806120",
    "end": "1813559"
  },
  {
    "text": "framework and add arbitrary arbitrary pruin to each extension point for",
    "start": "1813559",
    "end": "1821080"
  },
  {
    "text": "example you can implement the company specific parameter injection logic as a",
    "start": "1821080",
    "end": "1827679"
  },
  {
    "text": "PR next this is another",
    "start": "1827679",
    "end": "1832960"
  },
  {
    "text": "mechanism as we mentioned in the train job slides we can specify the arbit",
    "start": "1832960",
    "end": "1839799"
  },
  {
    "text": "runtime name in the train job CD so if you want to use the inhouse or",
    "start": "1839799",
    "end": "1848039"
  },
  {
    "text": "third party CDs to deploy Couer with train job you can Implement hor runtime",
    "start": "1848039",
    "end": "1856679"
  },
  {
    "text": "mechanism then you can use it as training operated",
    "start": "1856679",
    "end": "1863039"
  },
  {
    "text": "jobs next um I'm going to talk about scalability and cost",
    "start": "1863039",
    "end": "1869919"
  },
  {
    "text": "saving typically um train jobs are needed to prepare the best model and",
    "start": "1869919",
    "end": "1876799"
  },
  {
    "text": "data set but we often execute such initializations in in container or a",
    "start": "1876799",
    "end": "1884799"
  },
  {
    "text": "main container part of main trainer jobs or parts that will rot the cost effectives",
    "start": "1884799",
    "end": "1893880"
  },
  {
    "text": "because even though the downloading model and data set are not used",
    "start": "1893880",
    "end": "1900039"
  },
  {
    "text": "dpus those parts keep holding the dpus so the training operator will",
    "start": "1900039",
    "end": "1907919"
  },
  {
    "text": "prepare the data set and model separated from Main trainer",
    "start": "1907919",
    "end": "1916480"
  },
  {
    "text": "jobs the second um is",
    "start": "1916480",
    "end": "1922240"
  },
  {
    "text": "um removing um duplication of between Q Pro and",
    "start": "1922240",
    "end": "1929279"
  },
  {
    "text": "kubernetes community in the B1 a q Pro API",
    "start": "1929279",
    "end": "1936080"
  },
  {
    "text": "so we Implement um similar job mechanism",
    "start": "1936080",
    "end": "1941960"
  },
  {
    "text": "by ourselves but since bat API we rely",
    "start": "1941960",
    "end": "1947279"
  },
  {
    "text": "on the job set and job",
    "start": "1947279",
    "end": "1952600"
  },
  {
    "text": "API the SEC the third part is so performance so B1 API so the training",
    "start": "1952720",
    "end": "1962519"
  },
  {
    "text": "operator will create Parts",
    "start": "1962519",
    "end": "1968080"
  },
  {
    "text": "sequen but so in large training environment that is pain",
    "start": "1968080",
    "end": "1973919"
  },
  {
    "text": "points so but so keep Contra manager Java API can",
    "start": "1973919",
    "end": "1980720"
  },
  {
    "text": "create Parts um concurrently so B API can improve um",
    "start": "1980720",
    "end": "1990000"
  },
  {
    "text": "performance and scalability uh in the large machine learning training",
    "start": "1990000",
    "end": "1997159"
  },
  {
    "text": "environment so let me for the this session so first um we are talking on",
    "start": "1998080",
    "end": "2007279"
  },
  {
    "text": "simple to use and scale second and person is main user interface third",
    "start": "2007279",
    "end": "2014799"
  },
  {
    "text": "enabling quick furing of LMS only by",
    "start": "2014799",
    "end": "2020600"
  },
  {
    "text": "python provide the force is provides robust support for ML",
    "start": "2020600",
    "end": "2027120"
  },
  {
    "text": "ecosystem fifs streamline data set and pre-trained model",
    "start": "2027120",
    "end": "2033080"
  },
  {
    "text": "initialization finally we talked consolidates eort between cuberes and C",
    "start": "2033080",
    "end": "2042000"
  },
  {
    "text": "communities but we have some future work so first is so we are planning to",
    "start": "2043000",
    "end": "2051079"
  },
  {
    "text": "support um some of um funing around times second is so supporting and MPI",
    "start": "2051079",
    "end": "2061240"
  },
  {
    "text": "training B2 in the training operator B2 the third is so it's not only for CU",
    "start": "2061240",
    "end": "2070960"
  },
  {
    "text": "Pro um but so we are working on B kubernetes bchw working group for",
    "start": "2070960",
    "end": "2078118"
  },
  {
    "text": "example job set serial job execution policy um state for index job policy Mar",
    "start": "2078119",
    "end": "2088200"
  },
  {
    "text": "cluster job dispatching with q and so qu management with",
    "start": "2088200",
    "end": "2095480"
  },
  {
    "text": "SK all right so this is so Community QR",
    "start": "2096040",
    "end": "2101200"
  },
  {
    "text": "code so if you have um if you have interesting for this um API",
    "start": "2101200",
    "end": "2109400"
  },
  {
    "text": "so please join our community meeting and GitHub",
    "start": "2109400",
    "end": "2115599"
  },
  {
    "text": "issue here is a contributor for the CU training B API it's not only for",
    "start": "2115599",
    "end": "2121800"
  },
  {
    "text": "production cods including documentation and discussion and testing cuse thank",
    "start": "2121800",
    "end": "2128920"
  },
  {
    "text": "you for all contributors finally um please send your",
    "start": "2128920",
    "end": "2134359"
  },
  {
    "text": "feedback via this QR code thank you for listening our presentation",
    "start": "2134359",
    "end": "2141240"
  },
  {
    "text": "[Applause]",
    "start": "2141240",
    "end": "2148080"
  }
]
[
  {
    "text": "Welcome to our talk while we try to answer this very popular question that",
    "start": "240",
    "end": "5560"
  },
  {
    "text": "many of you probably have heard how many Network policies can I create my name is",
    "start": "5560",
    "end": "10800"
  },
  {
    "text": "n Piva I'm a senior software engineer at radad hi and I'm Sean krton a",
    "start": "10800",
    "end": "17199"
  },
  {
    "text": "distinguished engineer at igera the company behind Calico in case you you haven't heard of",
    "start": "17199",
    "end": "23519"
  },
  {
    "text": "us okay um so today we're going to try and answer this question how many Network",
    "start": "24279",
    "end": "30439"
  },
  {
    "text": "policies can I create um and Nadia has the first half of this talk so she's going to take you through why that's a",
    "start": "30439",
    "end": "37600"
  },
  {
    "text": "difficult question um she's going to introduce you to her new model and framework for scale",
    "start": "37600",
    "end": "43079"
  },
  {
    "text": "testing Network policies and why it was needed it comes down to some kind of problem with measuring",
    "start": "43079",
    "end": "51039"
  },
  {
    "text": "confusing uh multi-dimensional objects these Network policies we're dealing with um she's going to introduce you to",
    "start": "51039",
    "end": "57680"
  },
  {
    "text": "CU burner oh sorry uh curn um and uh the convergence tracking",
    "start": "57680",
    "end": "64239"
  },
  {
    "text": "approach that she's using um and then show you some sample",
    "start": "64239",
    "end": "69320"
  },
  {
    "text": "results from open shift uh then it'll be my part of the talk um I'll introduce",
    "start": "69320",
    "end": "75200"
  },
  {
    "text": "tiga's part and all this um and give a a demo of of testing like how you run one",
    "start": "75200",
    "end": "80960"
  },
  {
    "text": "of these tests uh then we'll Circle back to wrap up and try to answer the",
    "start": "80960",
    "end": "86200"
  },
  {
    "text": "question okay Nadia over to you thank you all right let's start from the beginning",
    "start": "86200",
    "end": "93040"
  },
  {
    "text": "what is Network policy for those of you who may not know Network policy is a kubernetes API that ensures network",
    "start": "93040",
    "end": "100759"
  },
  {
    "text": "security what it does it allows you to specify connections that should be allowed for a specific set of PODS and",
    "start": "100759",
    "end": "107560"
  },
  {
    "text": "then everything else will be denied so here is a simple example that you can see that's a network policy that is",
    "start": "107560",
    "end": "114200"
  },
  {
    "text": "created in the default namespace and it isolates all the pods in that namespace",
    "start": "114200",
    "end": "120119"
  },
  {
    "text": "it is very simple and it has just one Ingress rule that allows connections",
    "start": "120119",
    "end": "125439"
  },
  {
    "text": "from a specific Nam space with a project name my project so if you look to the right side you'll see an example",
    "start": "125439",
    "end": "132200"
  },
  {
    "text": "configuration where we have two name spaces the default name space has just one pod that is the Pod that is isolated",
    "start": "132200",
    "end": "139319"
  },
  {
    "text": "and there is the my project namespace that also has just one pod so in this case given Network policy allows just",
    "start": "139319",
    "end": "146680"
  },
  {
    "text": "one connection now we create one extra pod B",
    "start": "146680",
    "end": "152160"
  },
  {
    "text": "in the default namespace the network policy is still exactly the same but what it does now it allows two",
    "start": "152160",
    "end": "159519"
  },
  {
    "text": "connections you can imagine we can create a couple more pods and the number of connections that the exact same",
    "start": "159519",
    "end": "165800"
  },
  {
    "text": "network policy allows will grow so what it means for us is even Network policy",
    "start": "165800",
    "end": "171840"
  },
  {
    "text": "with the exact same spec may have very different scale impact on the cluster so",
    "start": "171840",
    "end": "179200"
  },
  {
    "text": "what it means is that Network policy scale impact depends not just on the spec of the object itself but also on",
    "start": "179200",
    "end": "187159"
  },
  {
    "text": "the other objects that exist in the cluster especially Nam space and pods and their labels which as you can",
    "start": "187159",
    "end": "193080"
  },
  {
    "text": "imagine makes the scale testing quite tricky now there is more than that the",
    "start": "193080",
    "end": "199319"
  },
  {
    "text": "spec of a network policy itself is also pretty tricky it has lots of lists of",
    "start": "199319",
    "end": "204599"
  },
  {
    "text": "different rules as you can see here and this list may have any number of elements like for example you can see a",
    "start": "204599",
    "end": "211519"
  },
  {
    "text": "list of Ingress or egress rules every rule may have a list of peers that it specifies uh a list of IP blocks",
    "start": "211519",
    "end": "218879"
  },
  {
    "text": "exceptions for some CER rules lists of different ports and many more so now you",
    "start": "218879",
    "end": "224760"
  },
  {
    "text": "can imagine that the network policy we've seen on the previous slide will have also a different scale impact it",
    "start": "224760",
    "end": "230640"
  },
  {
    "text": "had just one rule and this network policy is a bit more complicated and the number of rules also can grow like to",
    "start": "230640",
    "end": "237159"
  },
  {
    "text": "hundreds and thousands potentially so both these objects are just one network",
    "start": "237159",
    "end": "242560"
  },
  {
    "text": "policy but they are very different so saying I can create one network policy without adding more details to that",
    "start": "242560",
    "end": "249920"
  },
  {
    "text": "doesn't really clarify what is the scale impact of that so we try to solve this problem",
    "start": "249920",
    "end": "256519"
  },
  {
    "text": "with defining a network policy scale profile which is a set of parameters",
    "start": "256519",
    "end": "261799"
  },
  {
    "text": "that you set up and that allows you to simplify all the possible Network policy",
    "start": "261799",
    "end": "267120"
  },
  {
    "text": "configurations but it should be expressive and enough to allow for different configurations of different",
    "start": "267120",
    "end": "273120"
  },
  {
    "text": "network policies so these are I'll try to explain a couple of parameters that we have here the first one is the number",
    "start": "273120",
    "end": "280440"
  },
  {
    "text": "of local pods that's the number of PODS that are isolated which as we figured is important then we also simplify all the",
    "start": "280440",
    "end": "287919"
  },
  {
    "text": "generated Network policy canix to have just one peer in every rule as you can",
    "start": "287919",
    "end": "293199"
  },
  {
    "text": "see here and there are two main types of peers in network policy they are either",
    "start": "293199",
    "end": "300039"
  },
  {
    "text": "cider based or pod selector based so ciders is the parameter that specifies",
    "start": "300039",
    "end": "305360"
  },
  {
    "text": "the number of Ip block peers you can see there are three on that slide and the",
    "start": "305360",
    "end": "311520"
  },
  {
    "text": "other one is po selector so in this example there are two po selector rules",
    "start": "311520",
    "end": "317080"
  },
  {
    "text": "and pod selector is a bit more complicated than ciders because you also need to say how many pods are selected",
    "start": "317080",
    "end": "323680"
  },
  {
    "text": "by each peer and we do that with two extra parameters that are called peer name spaces and peer pods they are again",
    "start": "323680",
    "end": "331600"
  },
  {
    "text": "for simplification all namespace peers will select the exact same amount of PODS but the pods will be different but",
    "start": "331600",
    "end": "338520"
  },
  {
    "text": "the amount will be the same and it is controlled by these two parameters if that wasn't enough we have",
    "start": "338520",
    "end": "344960"
  },
  {
    "text": "a couple more so as we've mentioned there are also Port specifications that",
    "start": "344960",
    "end": "350360"
  },
  {
    "text": "may be attached to every Rule and network policy there are two main types which is a single port which just a",
    "start": "350360",
    "end": "356199"
  },
  {
    "text": "number and the port range which specifies the beginning and the end of the the range uh so here when you",
    "start": "356199",
    "end": "363240"
  },
  {
    "text": "specify this parameter in our scale profile it will generate a port config",
    "start": "363240",
    "end": "368479"
  },
  {
    "text": "as you can see here both for ciders and pod selector",
    "start": "368479",
    "end": "373599"
  },
  {
    "text": "rules okay let's take a look at a simple",
    "start": "373599",
    "end": "379080"
  },
  {
    "text": "example oh ah right so all right uh just to sum this up the network policy scale",
    "start": "379080",
    "end": "386240"
  },
  {
    "text": "profile in the end has seven parameters that you can see on the slide uh that is",
    "start": "386240",
    "end": "391639"
  },
  {
    "text": "the thing that defines how Network policy yaml will look like and that is good enough to understand what is the",
    "start": "391639",
    "end": "398199"
  },
  {
    "text": "scale impact of a given Network policy now I hope at this point it is obvious",
    "start": "398199",
    "end": "403280"
  },
  {
    "text": "that there is no single or simple answer to how many Network policies can I create but we can still add some",
    "start": "403280",
    "end": "410479"
  },
  {
    "text": "certainty here by using this network policy scale profile which hopefully",
    "start": "410479",
    "end": "415840"
  },
  {
    "text": "should allow us to answer this question with some more details all right let's take a quick look at the example Network",
    "start": "415840",
    "end": "421960"
  },
  {
    "text": "policy that will be generated for a very simple profile it has just one local pod",
    "start": "421960",
    "end": "427000"
  },
  {
    "text": "and one cider so you can see it here there is one Ingress rule with a cider based pier and there is a pod selector",
    "start": "427000",
    "end": "434560"
  },
  {
    "text": "that selects one pod believe me that selects one pod or a tricky labeling system to do that um all right so we've",
    "start": "434560",
    "end": "442720"
  },
  {
    "text": "figured out the network policy specification more or less there are a couple more things that we need to set",
    "start": "442720",
    "end": "448160"
  },
  {
    "text": "for every name space which which is the number of PODS per Nam space number of network policies per Nam space and",
    "start": "448160",
    "end": "454560"
  },
  {
    "text": "Ingress and egress policies can be also created separately in case that matters and that set of parameters",
    "start": "454560",
    "end": "461800"
  },
  {
    "text": "specifies just one Nam space so what we're going to do to scale test the cluster will create a number of copies",
    "start": "461800",
    "end": "468520"
  },
  {
    "text": "of these namespaces and that goes to the namespaces variable",
    "start": "468520",
    "end": "474000"
  },
  {
    "text": "here all right so that defines the workload I hope more or less in the cluster from the net Network policy",
    "start": "474000",
    "end": "480159"
  },
  {
    "text": "point of view there are though many more parameters potentially that may affect",
    "start": "480159",
    "end": "485199"
  },
  {
    "text": "the test results like the number of nodes the number of resources on the Pod or resources allocated to the node Cube",
    "start": "485199",
    "end": "491680"
  },
  {
    "text": "API server performance and so on and so forth but fortunately that applies more or less to every scale test so that is a",
    "start": "491680",
    "end": "499840"
  },
  {
    "text": "problem that exists not just for Network policies but for all the other scale testing so we won't pay too much attention to that but it is important to",
    "start": "499840",
    "end": "507440"
  },
  {
    "text": "remember that there are lots of different things that can affect the scale results for a specific",
    "start": "507440",
    "end": "514159"
  },
  {
    "text": "run okay so we have defined what kind of a workload we want to create how do we",
    "start": "514159",
    "end": "519919"
  },
  {
    "text": "do that there is a really nice cncf sandbox project that is called CU burner",
    "start": "519919",
    "end": "526160"
  },
  {
    "text": "that is able to generate the workload based on given yaml files for you so it can create delete patch kubernetes",
    "start": "526160",
    "end": "533040"
  },
  {
    "text": "objects it has also some nice features to report test results and collect metrics during the scale run so that you",
    "start": "533040",
    "end": "538839"
  },
  {
    "text": "can see how your system is doing in the middle of this scale test and there is",
    "start": "538839",
    "end": "543920"
  },
  {
    "text": "an extra repository here called kubernetes net Poole scale it contains all the yls for the network policy scale",
    "start": "543920",
    "end": "551480"
  },
  {
    "text": "testing with the mentioned parameters so what it does is it generates the workload with a given scale profile",
    "start": "551480",
    "end": "558240"
  },
  {
    "text": "using CU burner it also May visualize scale testing results with Prometheus",
    "start": "558240",
    "end": "563920"
  },
  {
    "text": "open search graan stch for you and it also can do some static Network policy analysis which will get back to the end",
    "start": "563920",
    "end": "571079"
  },
  {
    "text": "of this talk and I want to say special thanks to the open shift uh scale test",
    "start": "571079",
    "end": "578040"
  },
  {
    "text": "uh team that really helped me with that and the CU burner is a really nice project that will help you introduce new",
    "start": "578040",
    "end": "583720"
  },
  {
    "text": "parameters in case you need to do so okay looks like we are almost ready",
    "start": "583720",
    "end": "589320"
  },
  {
    "text": "to run our scale test but not just yet there is one extra nice feature of a",
    "start": "589320",
    "end": "594839"
  },
  {
    "text": "network policy that we need to figure out so the point is Network policy",
    "start": "594839",
    "end": "600200"
  },
  {
    "text": "doesn't have a status that means that we have no way to know when all the network",
    "start": "600200",
    "end": "605560"
  },
  {
    "text": "policies are applied so all the objects will be created but it doesn't mean that",
    "start": "605560",
    "end": "611360"
  },
  {
    "text": "it is applied to all selected ports at the same time so what do we do there are",
    "start": "611360",
    "end": "617160"
  },
  {
    "text": "potentially many ways to do so but that's what we went with considering we",
    "start": "617160",
    "end": "622880"
  },
  {
    "text": "apply the whole workload at once and there are no new changes in the cluster",
    "start": "622880",
    "end": "628640"
  },
  {
    "text": "your cluster should come to a stable or converg state at some point hopefully",
    "start": "628640",
    "end": "633959"
  },
  {
    "text": "now we can try to track networking State on every node and that's what we called",
    "start": "633959",
    "end": "639040"
  },
  {
    "text": "a convergence tracker job that is a customizable job that can be uh in our",
    "start": "639040",
    "end": "644760"
  },
  {
    "text": "cases a simple python script and it tracks the networking setup progress on every node different networking plugins",
    "start": "644760",
    "end": "651800"
  },
  {
    "text": "have different definitions of what a networking State on a node is but that is also what's good about that because",
    "start": "651800",
    "end": "657279"
  },
  {
    "text": "they can just Implement their own conversion trer to just see how it looks like so I am a contributor to the oven",
    "start": "657279",
    "end": "664040"
  },
  {
    "text": "kubernetes project that is a plugin that implements Network policies using ovs flows and here you can see the example",
    "start": "664040",
    "end": "671560"
  },
  {
    "text": "of metrics that shows the number of ovs flows after you apply a set of network policies so you can see it's growing",
    "start": "671560",
    "end": "677760"
  },
  {
    "text": "growing growing and at some point it stops that point is where all the network policies are applied and where",
    "start": "677760",
    "end": "684120"
  },
  {
    "text": "we can say now we're done the scale test is finished so that's how it's going to look like",
    "start": "684120",
    "end": "691240"
  },
  {
    "text": "all right so far so good now we're ready to run the test and get some nice pictures so CU burner as I said allows",
    "start": "691360",
    "end": "697800"
  },
  {
    "text": "you to collect some metrics and see some nice dashboards so here are a couple of Snippets of what you'll get from every",
    "start": "697800",
    "end": "704200"
  },
  {
    "text": "scale test run and these dashboards can also be stored so you can get back to",
    "start": "704200",
    "end": "709360"
  },
  {
    "text": "your scale test results and see how it looked like some time ago so you'll find",
    "start": "709360",
    "end": "714440"
  },
  {
    "text": "here all the different parameters of a scale test run the number of created objects",
    "start": "714440",
    "end": "720040"
  },
  {
    "text": "uh the scale per name space you'll find the seven parameters that I've tried to explain before which specify the scale",
    "start": "720040",
    "end": "727240"
  },
  {
    "text": "profile itself and there are also some details from every convergence tracker from every node that shows at what time",
    "start": "727240",
    "end": "735279"
  },
  {
    "text": "every node was converged in addition to that there are many more things that you can report an",
    "start": "735279",
    "end": "742440"
  },
  {
    "text": "important example is the resources usage that's probably what you also want to track which is the CPU and memory usage",
    "start": "742440",
    "end": "748399"
  },
  {
    "text": "for example so here you can see uh it's ovn Cube node pod CPU usage which is the",
    "start": "748399",
    "end": "753839"
  },
  {
    "text": "thing that actually implements the network policies and you can see that when the network policies are applied the CPU usage bumps up and then it goes",
    "start": "753839",
    "end": "761360"
  },
  {
    "text": "down when everything is done okay so let's say I've run this",
    "start": "761360",
    "end": "768839"
  },
  {
    "text": "test for a thousand Network policies my dashboards look look good CPU usage is",
    "start": "768839",
    "end": "773959"
  },
  {
    "text": "fine what do I do next I need to find the scale limit this is what I care",
    "start": "773959",
    "end": "779480"
  },
  {
    "text": "about so to find the scale limit we need to define the conditions for a test",
    "start": "779480",
    "end": "784639"
  },
  {
    "text": "failure so when the test is failed there are multiple ways to do so cluster death is an obvious one that will happen",
    "start": "784639",
    "end": "791360"
  },
  {
    "text": "sometimes if you apply too much too many Network policies then the other one is cluster health so you can get different",
    "start": "791360",
    "end": "797839"
  },
  {
    "text": "metrics from your cluster and track how well it's doing maybe in resource usage",
    "start": "797839",
    "end": "803880"
  },
  {
    "text": "point of view or from whatever you care about actually and the main thing we use here here is the conversion time so we",
    "start": "803880",
    "end": "812000"
  },
  {
    "text": "say that if applying a given Network policy configuration takes longer than n minutes and you can set it but 10",
    "start": "812000",
    "end": "818920"
  },
  {
    "text": "minutes is yourself then the test is failed it was too long and it's unacceptable we say this test doesn't",
    "start": "818920",
    "end": "825920"
  },
  {
    "text": "pass so to find the scale limit you can do what you can do is you can save all",
    "start": "825920",
    "end": "832160"
  },
  {
    "text": "the parameters as you can see here at the little spreadsheet example and just",
    "start": "832160",
    "end": "837600"
  },
  {
    "text": "increase the number of Network policy per namespace for every run at some",
    "start": "837600",
    "end": "843079"
  },
  {
    "text": "point your test will fail and say I cannot handle that many that's what you can see there in red and then basically",
    "start": "843079",
    "end": "851160"
  },
  {
    "text": "the answer to the question how many Network policies with a given scale profile can I create will be the last",
    "start": "851160",
    "end": "857560"
  },
  {
    "text": "successful run yay okay so how else we can use that we",
    "start": "857560",
    "end": "866079"
  },
  {
    "text": "call this whole system scale testing framework and I am a part of the open shift",
    "start": "866079",
    "end": "871480"
  },
  {
    "text": "networking team and what we did is we released some performance improvements for Network policy handling in open",
    "start": "871480",
    "end": "877839"
  },
  {
    "text": "shift 414 and we use this framework to just see and measure how much better",
    "start": "877839",
    "end": "883440"
  },
  {
    "text": "Network policies are handled now and I will not overload you with lots of details you can imagine there are lots",
    "start": "883440",
    "end": "889079"
  },
  {
    "text": "of different dashboards and parameters to that I'll show you two simple examples here so first of all this is",
    "start": "889079",
    "end": "895040"
  },
  {
    "text": "the graph you've already seen which is the number of obvious flows and convergence time so on top here you can",
    "start": "895040",
    "end": "901440"
  },
  {
    "text": "see how this graph looks for 20,000 Network policies with a very simple",
    "start": "901440",
    "end": "907320"
  },
  {
    "text": "profile one local pod one pod selector and one cider so in open ship 42 before",
    "start": "907320",
    "end": "912720"
  },
  {
    "text": "the improvements it took 24 minutes to converge here at the bottom you can see that after the performance improvements",
    "start": "912720",
    "end": "919480"
  },
  {
    "text": "in 414 the exact same configuration was applied in 5 minutes and that is how you",
    "start": "919480",
    "end": "925680"
  },
  {
    "text": "can use this test the performance scale framework right right you can measure and see how much better your system is",
    "start": "925680",
    "end": "932240"
  },
  {
    "text": "doing now since this system convergence converges faster now it means we can",
    "start": "932240",
    "end": "938880"
  },
  {
    "text": "also create more Network policies within a given time so that's what we have here",
    "start": "938880",
    "end": "944319"
  },
  {
    "text": "on the right side you can see the scale limit for open shift 412 was just 15,000",
    "start": "944319",
    "end": "949959"
  },
  {
    "text": "Network policies with a given profile and in opens shift 44 it was already",
    "start": "949959",
    "end": "955560"
  },
  {
    "text": "60,000 as which is this summer the sum of of Ingress and degress Network policies if the numbers don't make sense",
    "start": "955560",
    "end": "963160"
  },
  {
    "text": "immediately okay so really good we used that for open shift we tracked how well",
    "start": "963160",
    "end": "968680"
  },
  {
    "text": "our Network policy implementations work for now but then we thought oh maybe it can be useful for someone else too and",
    "start": "968680",
    "end": "975600"
  },
  {
    "text": "the rest of this story Sean will tell you thank you",
    "start": "975600",
    "end": "981319"
  },
  {
    "text": "Nadia so I work for igera the company behind Calico",
    "start": "981319",
    "end": "987680"
  },
  {
    "text": "um sorry just getting a bit of feedback uh and where did we come into",
    "start": "987680",
    "end": "993000"
  },
  {
    "text": "the story so NAD invited us as as she said um and the problem really resonated",
    "start": "993000",
    "end": "1000000"
  },
  {
    "text": "with us as well it's it's a question that we get asked a lot um we we get it",
    "start": "1000000",
    "end": "1005480"
  },
  {
    "text": "from customers you know how big does this scale and it always depends on so",
    "start": "1005480",
    "end": "1010519"
  },
  {
    "text": "many different factors so um it tends to be costly for us to answer um and we",
    "start": "1010519",
    "end": "1017639"
  },
  {
    "text": "don't have a good way of doing self-service tests for our Solutions team and our uh our customers themselves",
    "start": "1017639",
    "end": "1025120"
  },
  {
    "text": "if they wanted to run it um we do have some scale testing infrastructure but it's a little bit long in the tooth it",
    "start": "1025120",
    "end": "1033120"
  },
  {
    "text": "gets um necessary maintenance um because it's not our main it's not our main",
    "start": "1033120",
    "end": "1038280"
  },
  {
    "text": "focus but it is very capable when we need to use it but we're talking you know grafana 4.x I checked the version",
    "start": "1038280",
    "end": "1045199"
  },
  {
    "text": "of the of the dashboards that we had there um and it's not really suitable for",
    "start": "1045199",
    "end": "1050559"
  },
  {
    "text": "self-service because the inputs are not as kind of uh neatly specified as the",
    "start": "1050559",
    "end": "1056880"
  },
  {
    "text": "ones that Nadia took you through like they they're not very intuitive um it would need a lot of",
    "start": "1056880",
    "end": "1061960"
  },
  {
    "text": "Polish to open source it so perhaps CU burner is the answer we were just about",
    "start": "1061960",
    "end": "1067559"
  },
  {
    "text": "invest we were just investing in uh scale and scale testing infrastructure",
    "start": "1067559",
    "end": "1072720"
  },
  {
    "text": "again so we wanted we we were also kind of looking around and seeing if the landscape had changed and Nadia came",
    "start": "1072720",
    "end": "1079280"
  },
  {
    "text": "along and asked if we wanted to contribute to the new tool so it sort of dovetailed really nicely for us so what",
    "start": "1079280",
    "end": "1084960"
  },
  {
    "text": "did we do um my colleague Mazda mainly um who couldn't be here due to some fun",
    "start": "1084960",
    "end": "1092039"
  },
  {
    "text": "with his passport um built a conversion tracker for Calico um we tackled our",
    "start": "1092039",
    "end": "1097640"
  },
  {
    "text": "sort of mainstream IP tables and IP sets data plane so we're",
    "start": "1097640",
    "end": "1102720"
  },
  {
    "text": "monitoring um the Calico equivalent to the to obs's flows we're monitoring IP I",
    "start": "1102720",
    "end": "1108919"
  },
  {
    "text": "tables and IP sets convergence but we'll we'll likely extend it to do BPF and and",
    "start": "1108919",
    "end": "1114360"
  },
  {
    "text": "other things later um and it all kind of weighs in at about",
    "start": "1114360",
    "end": "1121240"
  },
  {
    "text": "200 lines of python so it's it's it's an approach that's really easy to get started with and and and get something",
    "start": "1121240",
    "end": "1127720"
  },
  {
    "text": "that works and you can start testing and then you can add more things into it later to to monitor the health of your",
    "start": "1127720",
    "end": "1134159"
  },
  {
    "text": "components and things like that make sure that things are staying up but you can do that manually initially so it's",
    "start": "1134159",
    "end": "1140039"
  },
  {
    "text": "it's quite a nice nice framework to get started with um we added a cube burner",
    "start": "1140039",
    "end": "1145120"
  },
  {
    "text": "yaml to scrape our Calico specific metrics from our Prometheus instance and",
    "start": "1145120",
    "end": "1151200"
  },
  {
    "text": "then those show up in the dashboard so that that was straightforward again um",
    "start": "1151200",
    "end": "1156320"
  },
  {
    "text": "and we made a new grafana dashboard this time for grafana 10x so things have moved on a little bit um it all went",
    "start": "1156320",
    "end": "1163520"
  },
  {
    "text": "really smoothly with a lot of help from Nadia so she helped land some patches to cube burner um with her contacts there",
    "start": "1163520",
    "end": "1170000"
  },
  {
    "text": "and and that sort of made our convergence track it easier to write um and we ran some tests too so we",
    "start": "1170000",
    "end": "1177240"
  },
  {
    "text": "also had some performance improvements and that seemed like an obvious thing to to show but I kind of wanted to show two",
    "start": "1177240",
    "end": "1184280"
  },
  {
    "text": "sides of the of the coin so um our performance improvements in our 327",
    "start": "1184280",
    "end": "1190880"
  },
  {
    "text": "release they apply mostly to selectors and not to like cider based rules so I",
    "start": "1190880",
    "end": "1196880"
  },
  {
    "text": "I've got two profiles to show you later in the talk where we can compare the two and you see a very different change in",
    "start": "1196880",
    "end": "1203400"
  },
  {
    "text": "in the 327 results but before we do that let's do a",
    "start": "1203400",
    "end": "1208600"
  },
  {
    "text": "little demo and show uh how how you run this tool so be before the talk um I've",
    "start": "1208600",
    "end": "1215039"
  },
  {
    "text": "set up a a cluster in gcp so Cube burner now supports arbitary kubernetes",
    "start": "1215039",
    "end": "1220720"
  },
  {
    "text": "clusters it's not in any way tied to open shift um I've got Prometheus metrics",
    "start": "1220720",
    "end": "1226840"
  },
  {
    "text": "enabled in Calico actually I'm going to do that as the demo um and I've got a persistent results server with grafana",
    "start": "1226840",
    "end": "1234320"
  },
  {
    "text": "and open search I think we used for this I've set up Q burner the ca tool which is a download um on a a jump box in gcp",
    "start": "1234320",
    "end": "1242760"
  },
  {
    "text": "and I've checked out Nadia's repo with the the yaml that we we put into that and that has calico's um contribution in",
    "start": "1242760",
    "end": "1249760"
  },
  {
    "text": "there so I'm going to switch",
    "start": "1249760",
    "end": "1253000"
  },
  {
    "text": "over [Music]",
    "start": "1257600",
    "end": "1263559"
  },
  {
    "text": "can we switch to this",
    "start": "1272559",
    "end": "1275760"
  },
  {
    "text": "mic is it",
    "start": "1280159",
    "end": "1283480"
  },
  {
    "text": "working I yeah I'll",
    "start": "1285400",
    "end": "1292240"
  },
  {
    "text": "okay so I'm on my jump box um and I'm going",
    "start": "1292240",
    "end": "1297440"
  },
  {
    "text": "to set up my Cube",
    "start": "1297440",
    "end": "1302039"
  },
  {
    "text": "config and then I have a",
    "start": "1302919",
    "end": "1306559"
  },
  {
    "text": "script I have a script to configure the cluster so I'll run the script uh this",
    "start": "1310400",
    "end": "1315720"
  },
  {
    "text": "this uses Cube Cal to um patch calico's configuration to enable Prometheus and",
    "start": "1315720",
    "end": "1321480"
  },
  {
    "text": "it also installs a manifest from Nadia's repo which um is what's needed to",
    "start": "1321480",
    "end": "1327039"
  },
  {
    "text": "monitor Calico so it's just a kind of basic promethus setup that that will work for this um so if I run",
    "start": "1327039",
    "end": "1336159"
  },
  {
    "text": "that um everything got patched and created and then I've got a little",
    "start": "1336159",
    "end": "1342440"
  },
  {
    "text": "function I can run which again came from Nadia uh that will'll just check that",
    "start": "1342440",
    "end": "1347640"
  },
  {
    "text": "Prometheus is service has come up um so then what do I have so what",
    "start": "1347640",
    "end": "1354880"
  },
  {
    "text": "while that comes up I've got the Kate's net pole scale repo checked out and most",
    "start": "1354880",
    "end": "1361279"
  },
  {
    "text": "of the um the meat of it is inside this subfolder um and the the most important",
    "start": "1361279",
    "end": "1368360"
  },
  {
    "text": "thing to look at is the n file so that's set of environment variables that",
    "start": "1368360",
    "end": "1374679"
  },
  {
    "text": "control the framework and you will recognize these from Nadia's part of the",
    "start": "1374679",
    "end": "1381960"
  },
  {
    "text": "talk um I've also got cube config in there um you need to set the platform",
    "start": "1381960",
    "end": "1387559"
  },
  {
    "text": "appropriately so there's a subdirectory for each platform that's supported so this is the I've set Calico obviously um",
    "start": "1387559",
    "end": "1394039"
  },
  {
    "text": "and I've enabled the convergence tracker um and that's that's most of what's in",
    "start": "1394039",
    "end": "1399799"
  },
  {
    "text": "there I think the only other thing is I've reduced the end of job pause",
    "start": "1399799",
    "end": "1405400"
  },
  {
    "text": "normally it waits at the end of the job to collect CP metrics and so on for a little while after and I've I've",
    "start": "1405400",
    "end": "1411200"
  },
  {
    "text": "shortened that for the demo um and if I show",
    "start": "1411200",
    "end": "1417640"
  },
  {
    "text": "the metric. yaml um I think this is a",
    "start": "1417640",
    "end": "1422960"
  },
  {
    "text": "good one to look at so these are calico's metrics that I've added at the end so basically you just you just give",
    "start": "1422960",
    "end": "1428520"
  },
  {
    "text": "a Prometheus query to um Cube burner and it will scrape all of these at the end",
    "start": "1428520",
    "end": "1433880"
  },
  {
    "text": "of the test and put them into elastic search for the uh dashboard to show at the end so they go in the persistent",
    "start": "1433880",
    "end": "1440960"
  },
  {
    "text": "store and your Prometheus can be um discarded at the end of the test um and then the actual test itself",
    "start": "1440960",
    "end": "1448559"
  },
  {
    "text": "is in that network policy. yaml but I I won't dig into that it's a lot of templating so I think we're ready to run",
    "start": "1448559",
    "end": "1454919"
  },
  {
    "text": "the test oh did I Source my n Source the N",
    "start": "1454919",
    "end": "1463240"
  },
  {
    "text": "file and that's the sort of command that you would run to you you need to run to execute Cube Cube burner so- M for the",
    "start": "1465440",
    "end": "1473840"
  },
  {
    "text": "metric - c I'm not sure what that stands for but you pass the network policy which is like the test you want to run -",
    "start": "1473840",
    "end": "1480039"
  },
  {
    "text": "U uh to configure the Prometheus instance it's going to scrape and I've set log level debug just so we get more",
    "start": "1480039",
    "end": "1486880"
  },
  {
    "text": "more output so if I run that it kicks off and it's cre it goes through",
    "start": "1486880",
    "end": "1492720"
  },
  {
    "text": "multiple phases so the way you configure Cube burner is with a like folders of yaml and of yaml so the first phase is",
    "start": "1492720",
    "end": "1500720"
  },
  {
    "text": "creating the convergence trackers and then it's going through and creating some Network policies um and while",
    "start": "1500720",
    "end": "1506880"
  },
  {
    "text": "that's running um it takes about five minutes to run this demo so I'll switch",
    "start": "1506880",
    "end": "1512000"
  },
  {
    "text": "to something else normally takes about 10 minutes to run a proper a proper run",
    "start": "1512000",
    "end": "1517679"
  },
  {
    "text": "um while that's running we can go back and have a look at the uh the",
    "start": "1517679",
    "end": "1523520"
  },
  {
    "text": "metrics so I think I'll Swit switch back to that mic I think um so",
    "start": "1525440",
    "end": "1533240"
  },
  {
    "text": "here's our results with a cider heavy profile and in these results this is the results from 326 I wasn't really",
    "start": "1533240",
    "end": "1540559"
  },
  {
    "text": "expecting any big change in 327 on this um so it converges fairly quickly it",
    "start": "1540559",
    "end": "1546720"
  },
  {
    "text": "doesn't use a lot of CPU which is the graph on the kind of the the left there",
    "start": "1546720",
    "end": "1553840"
  },
  {
    "text": "and the two graphs at the top those are from the convergence track so we get metrics from the convergence tracker",
    "start": "1553840",
    "end": "1560279"
  },
  {
    "text": "showing the IP tables rules climbing and the IP sets steady in this test um there's also more results that would be",
    "start": "1560279",
    "end": "1567399"
  },
  {
    "text": "off screen here showing kubernetes kubernetes things moving to",
    "start": "1567399",
    "end": "1572799"
  },
  {
    "text": "327 um it did improve which was a bit of a surprise um but it didn't improve by a",
    "start": "1572799",
    "end": "1579919"
  },
  {
    "text": "whole lot on this test and the you know the number of um IP tables rules and so on CPU usage or kind of Fairly",
    "start": "1579919",
    "end": "1586960"
  },
  {
    "text": "consistent it just converged a little bit quicker um but if we flip over to the",
    "start": "1586960",
    "end": "1592000"
  },
  {
    "text": "selector heavy profile so here we have a lot of peer selectors in the",
    "start": "1592000",
    "end": "1597159"
  },
  {
    "text": "rules um as instead of just kind of simple ciders we actually used the",
    "start": "1597159",
    "end": "1603880"
  },
  {
    "text": "script that Nadia talked about to ramp up the number of network policies until it failed and then we got this graph",
    "start": "1603880",
    "end": "1610320"
  },
  {
    "text": "with like very spiky CPU probably a lot of garbage collection and nasty things happening loads of Ip tables rules loads",
    "start": "1610320",
    "end": "1617279"
  },
  {
    "text": "of Ip sets um but if we switched to 327 we were able to confirm that it",
    "start": "1617279",
    "end": "1623840"
  },
  {
    "text": "converged at that rate and the CPU was a lot lower and everything was like as we're expecting um we also kind of",
    "start": "1623840",
    "end": "1630520"
  },
  {
    "text": "doubly confirmed that things were working as expected by adding some extra metrics in 327 so we were able to put",
    "start": "1630520",
    "end": "1638559"
  },
  {
    "text": "those into our dashboard so we can show this graph at the bottom left optimized selectors that counts up when when we",
    "start": "1638559",
    "end": "1646080"
  },
  {
    "text": "know we've optimized something as we were intending to optimize it so it's really useful to to be able to add those",
    "start": "1646080",
    "end": "1652000"
  },
  {
    "text": "Calico specific things in for for our testing um and",
    "start": "1652000",
    "end": "1658399"
  },
  {
    "text": "yes yeah so thereo results probably still",
    "start": "1660279",
    "end": "1668000"
  },
  {
    "text": "running let's get back to the yeah let's see how did we do yeah pausing for one",
    "start": "1668000",
    "end": "1674399"
  },
  {
    "text": "minute before finishing y um yeah let's just carry on so tigera",
    "start": "1674399",
    "end": "1682440"
  },
  {
    "text": "perspective think I'm on these mics now TIG tigera perspective um really glad",
    "start": "1682440",
    "end": "1688039"
  },
  {
    "text": "Nadia reached out it was at a really good time for us um it is a shared pain point for us and hopefully we all",
    "start": "1688039",
    "end": "1693720"
  },
  {
    "text": "benefit from the shared project I know we'll be using CU burner in future because it's a lot um a lot nicer than",
    "start": "1693720",
    "end": "1699799"
  },
  {
    "text": "what we have um we were able to kind of map some real policy questions that we",
    "start": "1699799",
    "end": "1705679"
  },
  {
    "text": "had and some real per questions into the available parameters and kind of showed",
    "start": "1705679",
    "end": "1710880"
  },
  {
    "text": "roughly what we expected but some surprises which is is nice in a way because it it shows you that you really",
    "start": "1710880",
    "end": "1716519"
  },
  {
    "text": "are testing something um and I'm interested to see where it goes next so",
    "start": "1716519",
    "end": "1722200"
  },
  {
    "text": "maybe a little bit out of scope for this but we'd quite like to figure out a way to do like higher scale testing with",
    "start": "1722200",
    "end": "1729320"
  },
  {
    "text": "mock nodes and things like that we've been experimenting with that in internally um and it'd be quite nice to",
    "start": "1729320",
    "end": "1736000"
  },
  {
    "text": "have some real connectivity checking like on top of the the convergence stuff",
    "start": "1736000",
    "end": "1742000"
  },
  {
    "text": "just like Stoke my paranoia make sure it's really really doing what I want it to do um but yeah um we' we've enjoyed",
    "start": "1742000",
    "end": "1750880"
  },
  {
    "text": "contributing so Nadia how many Network policies can I create right getting back to the",
    "start": "1750880",
    "end": "1757679"
  },
  {
    "text": "original question and telling what's next so we have an answer for this question with a predefined scale profile",
    "start": "1757679",
    "end": "1765200"
  },
  {
    "text": "which bows down to seven parameters I've been talking about now you could say",
    "start": "1765200",
    "end": "1770240"
  },
  {
    "text": "that people don't usually run thousands of network policies with the exact same skill profile in their cluster they",
    "start": "1770240",
    "end": "1776080"
  },
  {
    "text": "probably have a couple of policies with very different profiles at the same time so what can we do with that and that's",
    "start": "1776080",
    "end": "1782159"
  },
  {
    "text": "something that's still in progress but we are working on that first of all we can try to Define some meaningful scale",
    "start": "1782159",
    "end": "1788080"
  },
  {
    "text": "profiles to be used as an upper bound saying if I know that a 100p selector",
    "start": "1788080",
    "end": "1793640"
  },
  {
    "text": "profile allows 10,000 Network policies and I know my network polic policies just use 10 pod selectors and they need",
    "start": "1793640",
    "end": "1800279"
  },
  {
    "text": "just 2,000 then it probably will work right because it's much less than what is already supported so I can use this",
    "start": "1800279",
    "end": "1806679"
  },
  {
    "text": "information already now I may have lots of network policies in my cluster but I don't really know what's the scale",
    "start": "1806679",
    "end": "1812960"
  },
  {
    "text": "profile for them I don't know how many pod selectors and ciders they using so there is a tool now that given the",
    "start": "1812960",
    "end": "1819960"
  },
  {
    "text": "output of all the yaml that it needs which is pods Nam spaces and network policies can give you some analysis or a",
    "start": "1819960",
    "end": "1827440"
  },
  {
    "text": "scale report for the existing workload that you have and it will show you all the scale parameters of different",
    "start": "1827440",
    "end": "1833880"
  },
  {
    "text": "network policies that already exist in your cluster based on the yaml so we just provide some statistics and data",
    "start": "1833880",
    "end": "1840120"
  },
  {
    "text": "for you and the most ambitious one is the approximation for any type of",
    "start": "1840120",
    "end": "1846399"
  },
  {
    "text": "profile using existing scale test results the simple option is I know one",
    "start": "1846399",
    "end": "1852559"
  },
  {
    "text": "cider profile allows 10,000 Network policies and 10 Siders allows 5,000",
    "start": "1852559",
    "end": "1857600"
  },
  {
    "text": "Network policies can I approximately say how many Network policies for a five- cider profile can be created without",
    "start": "1857600",
    "end": "1864440"
  },
  {
    "text": "actually running the whole test so that's the simple idea it goes further to all the different parameters of",
    "start": "1864440",
    "end": "1869799"
  },
  {
    "text": "course that's a pretty complicated thing but we are also working on that and hope to get some nice results there and the",
    "start": "1869799",
    "end": "1876320"
  },
  {
    "text": "last thing is adding more coverage as you've noticed we don't have IP block except for existing Network policies or",
    "start": "1876320",
    "end": "1882279"
  },
  {
    "text": "named ports they are not a part of the profile just yet but it can be added any time and we also hope to use the same",
    "start": "1882279",
    "end": "1889360"
  },
  {
    "text": "scale test profile for other apis like admin Network policy in the",
    "start": "1889360",
    "end": "1894799"
  },
  {
    "text": "future now let see if the demo finished now let's see if the demo finished uh so it did and it spack out a",
    "start": "1894799",
    "end": "1903120"
  },
  {
    "text": "uu ID so this is how Cube burner uh Records the tests in elastic search and",
    "start": "1903120",
    "end": "1909039"
  },
  {
    "text": "if we switch over to this tab over here we should be able to show the last 30",
    "start": "1909039",
    "end": "1915080"
  },
  {
    "text": "minutes um and if there was more than one test in the last 30 minutes it would appear in this uh this drop down here",
    "start": "1915080",
    "end": "1922000"
  },
  {
    "text": "but I think we got the right U ID 8652 yeah so we'll sh we'll share that",
    "start": "1922000",
    "end": "1928240"
  },
  {
    "text": "one which was already visible and if you H in on the time this was just a rerun of one of the tests I already showed but",
    "start": "1928240",
    "end": "1934960"
  },
  {
    "text": "you can see you get a live dashboard and you can um poke around and scrolling",
    "start": "1934960",
    "end": "1940480"
  },
  {
    "text": "down we have a few more Calico metrics and some metrics from the the kubernetes API server you can add whatever you want",
    "start": "1940480",
    "end": "1947440"
  },
  {
    "text": "when you build these these dashboards um and yeah the profile at the top oh the",
    "start": "1947440",
    "end": "1953320"
  },
  {
    "text": "no should say five that's a mistake so it works it",
    "start": "1953320",
    "end": "1960039"
  },
  {
    "text": "[Applause] worked I think we have a couple of minutes for",
    "start": "1963980",
    "end": "1971320"
  },
  {
    "text": "questions yep I don't know if we have microphones or something you can",
    "start": "1972240",
    "end": "1979840"
  },
  {
    "text": "okay people so maybe we can just have a discussion to ask the question as",
    "start": "1983120",
    "end": "1991000"
  },
  {
    "text": "you all right we'll be here for any questions and discussions considering a lot of people are leaving and moving",
    "start": "1992360",
    "end": "1998399"
  },
  {
    "text": "probably so uh great thanks everyone",
    "start": "1998399",
    "end": "2003960"
  }
]
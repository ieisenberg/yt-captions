[
  {
    "text": "hello everyone um super excited to see all of you interested in scalability so",
    "start": "280",
    "end": "5680"
  },
  {
    "text": "we will be talking about scaling kubernetes networking 2,000 5,000 and 100,000 nodes I'm marel Jumba I'm I work",
    "start": "5680",
    "end": "14280"
  },
  {
    "text": "at isovalent and together with me we have d leich uh from",
    "start": "14280",
    "end": "19680"
  },
  {
    "text": "Google so let's start with celum what is celum probably most of you heard about",
    "start": "19680",
    "end": "25640"
  },
  {
    "text": "celium and most popular is cium cni which is secure scalable cni plugin that",
    "start": "25640",
    "end": "32200"
  },
  {
    "text": "you can use for kubernetes um but then except for cni we also do have hble in case you are",
    "start": "32200",
    "end": "39760"
  },
  {
    "text": "interested in uh Network observability and last but not least tetragon so",
    "start": "39760",
    "end": "46239"
  },
  {
    "text": "tetragon allows you to um to to basically secure your container runtime",
    "start": "46239",
    "end": "52520"
  },
  {
    "text": "with policies similar to network policies and what all these projects",
    "start": "52520",
    "end": "57719"
  },
  {
    "text": "have in common is that they use utilize ebpf so short introduction into",
    "start": "57719",
    "end": "64439"
  },
  {
    "text": "ebpf um you can think of it as you can write small program that can be attached",
    "start": "64439",
    "end": "70200"
  },
  {
    "text": "to different events within uh Linux kernel and what you can do with it is for example if you are interested in",
    "start": "70200",
    "end": "76880"
  },
  {
    "text": "observability you can export some of the information from the kernel to ebpf map",
    "start": "76880",
    "end": "82400"
  },
  {
    "text": "and then from user space you can access that data but it also works the other way around let's say that you want to",
    "start": "82400",
    "end": "88840"
  },
  {
    "text": "implement um Service uh load balancing in kubernetes what you can do is",
    "start": "88840",
    "end": "94360"
  },
  {
    "text": "actually take service take all the backends that are behind the service write those IPS into ebpf map and then",
    "start": "94360",
    "end": "101640"
  },
  {
    "text": "have the ebpf program translate cluster IP into one of the backends and it's one",
    "start": "101640",
    "end": "107759"
  },
  {
    "text": "of the most important parts of ebpf it's that it's way more efficient than other",
    "start": "107759",
    "end": "115000"
  },
  {
    "text": "Alternatives so we'll be focusing today mostly on cium cni",
    "start": "115000",
    "end": "120520"
  },
  {
    "text": "short summary what celum cni is um first of all efficient scalable kubernetes cni",
    "start": "120520",
    "end": "127119"
  },
  {
    "text": "that also provides security kubernetes network policies but also more advanced cium Network policies um as mentioned",
    "start": "127119",
    "end": "134720"
  },
  {
    "text": "before service load balancing so if you are um interested in Cube proxy",
    "start": "134720",
    "end": "140480"
  },
  {
    "text": "replacement you can use cium to do the service load balancing instead of Cu",
    "start": "140480",
    "end": "145840"
  },
  {
    "text": "proxy and last but not least which we'll be covering later on as well well is multicluster if you are interested in",
    "start": "145840",
    "end": "152480"
  },
  {
    "text": "running multiple clusters and connectivity between different clusters then you can utilize as",
    "start": "152480",
    "end": "159680"
  },
  {
    "text": "well um but let's start with even understanding what does the scalability even mean so our title",
    "start": "159680",
    "end": "168120"
  },
  {
    "text": "mentions 100,000 nodes right but the scalability is not just the number of",
    "start": "168120",
    "end": "173519"
  },
  {
    "text": "nodes it's way more than that so when we are thinking about scalability of kubernetes there are so many more",
    "start": "173519",
    "end": "179239"
  },
  {
    "text": "dimensions that we care about noes is just one dimension that we care about but also like how many pods do you have",
    "start": "179239",
    "end": "186040"
  },
  {
    "text": "how many Network policies how many services or how many beckons those Services have and with that in mind uh",
    "start": "186040",
    "end": "194159"
  },
  {
    "text": "we really need to think about all those Dimensions when testing uh networking",
    "start": "194159",
    "end": "199519"
  },
  {
    "text": "and scalability of kuber netics but then again okay we let's say",
    "start": "199519",
    "end": "205560"
  },
  {
    "text": "we have some rough numbers what we want to test in terms of scalability",
    "start": "205560",
    "end": "210760"
  },
  {
    "text": "um what we need to do is understand when our cluster is happy but what does it",
    "start": "210760",
    "end": "216040"
  },
  {
    "text": "mean well we need to have some sis slos so I mentioned here like few sis and",
    "start": "216040",
    "end": "222000"
  },
  {
    "text": "slos that we care about when scale testing um networking and kubernetes and",
    "start": "222000",
    "end": "228239"
  },
  {
    "text": "one example is po startup latency well we we care how much time it takes for your PO connectivity to be up H",
    "start": "228239",
    "end": "236239"
  },
  {
    "text": "similarly for the node we also care about Network programming latency so you can think of it as how much time it",
    "start": "236239",
    "end": "243439"
  },
  {
    "text": "takes for the backand behind services to be propagated across across cluster if",
    "start": "243439",
    "end": "248680"
  },
  {
    "text": "you apply Network policies how much time it takes for those Network policies to be applied and last but not least in",
    "start": "248680",
    "end": "255640"
  },
  {
    "text": "cluster Network latency and throughput these are just few examples there is way more than that but",
    "start": "255640",
    "end": "262880"
  },
  {
    "text": "those are kind of most mostly related to the networking and some of them we will",
    "start": "262880",
    "end": "268000"
  },
  {
    "text": "be covering later on as well and with that in mind um stage is yours D yeah so",
    "start": "268000",
    "end": "275280"
  },
  {
    "text": "I'm going to talk about network security on a large scale uh particularly how uh",
    "start": "275280",
    "end": "280600"
  },
  {
    "text": "workload security with kubernetes network policies can scale up to 5,000 nodes and 200,000 BS on a single cluster",
    "start": "280600",
    "end": "288160"
  },
  {
    "text": "what I'm going to cover is uh the target scale that we want to achieve uh how Network policies are implemented what",
    "start": "288160",
    "end": "294919"
  },
  {
    "text": "challenges we overcame and how the performance and metrics and improvements in progress so first uh as marel",
    "start": "294919",
    "end": "303120"
  },
  {
    "text": "mentioned there are uh a number of scalability Dimensions that we care",
    "start": "303120",
    "end": "308240"
  },
  {
    "text": "about and in this case we want to be able to support up to 5,000 nodes 200,000 pods uh one 100 pod changes per",
    "start": "308240",
    "end": "317759"
  },
  {
    "text": "second up to 10,000 Network policies and 20 changes to network policies per",
    "start": "317759",
    "end": "323840"
  },
  {
    "text": "second uh first we'll start a little bit about Network policies uh what they are how they're used and and for them an",
    "start": "323840",
    "end": "330479"
  },
  {
    "text": "important detail is security identity so security identity is generated from pod",
    "start": "330479",
    "end": "336039"
  },
  {
    "text": "labels and namespace labels and network policy select the these pod labels and",
    "start": "336039",
    "end": "341759"
  },
  {
    "text": "namespace labels the same ones and then later po toot communication is allowed only between pods that have selected",
    "start": "341759",
    "end": "349800"
  },
  {
    "text": "identities uh to illustrate how Network policies are implemented we can look",
    "start": "349800",
    "end": "354919"
  },
  {
    "text": "first at the control plane which is uh done by celum agent that that is a demon",
    "start": "354919",
    "end": "360319"
  },
  {
    "text": "set that runs on every node it watches some kubernetes API",
    "start": "360319",
    "end": "366560"
  },
  {
    "text": "resources like the standard ones pods namespaces Network policies and celium",
    "start": "366560",
    "end": "372000"
  },
  {
    "text": "custom resources that are derived from pods and namespaces celium end points and celium identities and with all of",
    "start": "372000",
    "end": "378479"
  },
  {
    "text": "these data it can populate ebpf maps that are the the first first BPF map",
    "start": "378479",
    "end": "385520"
  },
  {
    "text": "that is per node it is IP cache and it Maps uh pod IPS to uh identities to the",
    "start": "385520",
    "end": "393080"
  },
  {
    "text": "security identities that I've mentioned and then we have ebpf policy maps that",
    "start": "393080",
    "end": "398319"
  },
  {
    "text": "are per end point so every po has one and it consists of which identities are",
    "start": "398319",
    "end": "405599"
  },
  {
    "text": "allowed to communicate with this pod and then there is the enforcement of policies on the right side we see the",
    "start": "405599",
    "end": "411720"
  },
  {
    "text": "data plane when pod a is trying to communicate with b b uh and there is a",
    "start": "411720",
    "end": "417000"
  },
  {
    "text": "network policy on the side of Ingress of b b uh when the packet is coming in and",
    "start": "417000",
    "end": "423759"
  },
  {
    "text": "the network policy enforcement system is triggered it will try first to map the",
    "start": "423759",
    "end": "429879"
  },
  {
    "text": "IP of the incoming pod uh to an identity",
    "start": "429879",
    "end": "435199"
  },
  {
    "text": "and it will manage to find it here in this case and then after that it will",
    "start": "435199",
    "end": "440560"
  },
  {
    "text": "try to find uh if this identity exists in the Pod B policy map and if it does",
    "start": "440560",
    "end": "448639"
  },
  {
    "text": "it will allow traffic and in this case it does uh if it didn't it would just drop the traffic so it will be dropped",
    "start": "448639",
    "end": "455520"
  },
  {
    "text": "so what was the bottleneck when we are trying to uh scale Network policies to",
    "start": "455520",
    "end": "461120"
  },
  {
    "text": "5,000 nodes and 100 200,000 pods with 100 B changes per second so the thing is",
    "start": "461120",
    "end": "468599"
  },
  {
    "text": "that in order to program ebpf maps on every node uh every node needs to know",
    "start": "468599",
    "end": "475759"
  },
  {
    "text": "about IP to pod security identity mapping for every pod this means that if",
    "start": "475759",
    "end": "482680"
  },
  {
    "text": "we are changing 100 pods per second we'll have to send 500,000 events per",
    "start": "482680",
    "end": "488800"
  },
  {
    "text": "second to all of the pods one event and uh C Cube API server on the most",
    "start": "488800",
    "end": "496039"
  },
  {
    "text": "powerful machines uh cannot handle that much uh over 100,000 events per second",
    "start": "496039",
    "end": "501879"
  },
  {
    "text": "are already a Troublesome so the safe limit in this case would be about 100",
    "start": "501879",
    "end": "507039"
  },
  {
    "text": "1,000 nodes for 100 pot changes per second and uh what did we do to overcome",
    "start": "507039",
    "end": "512919"
  },
  {
    "text": "it is uh Implement batching celium end points and this was inspired by",
    "start": "512919",
    "end": "518719"
  },
  {
    "text": "kubernetes end point slice uh this is done in a way that we are trying to slice the ire entire pool",
    "start": "518719",
    "end": "525600"
  },
  {
    "text": "of end points in case of endpoint slices we are reducing the size of the endpoints object the kubernetes one and",
    "start": "525600",
    "end": "532120"
  },
  {
    "text": "here we are just uh reducing the number of events by uh batching the end points",
    "start": "532120",
    "end": "538680"
  },
  {
    "text": "into a group of 50 for the slice and uh there is a graph on the",
    "start": "538680",
    "end": "545360"
  },
  {
    "text": "right which illustrates how uh the diagram that illustrates how it's done uh so when pod is created uh we see on",
    "start": "545360",
    "end": "554560"
  },
  {
    "text": "the point one there is celium cni AD and at that point celium endpoint is created",
    "start": "554560",
    "end": "561200"
  },
  {
    "text": "uh in the cube API server by the celium agent and the celium operator has the",
    "start": "561200",
    "end": "566240"
  },
  {
    "text": "job to batch celium end points into slices uh celium operator is a deployment that",
    "start": "566240",
    "end": "572560"
  },
  {
    "text": "can run in the cluster and it will see this celium endpoint creation and it will batch it inside of a slice and also",
    "start": "572560",
    "end": "580079"
  },
  {
    "text": "create uh post that update and then uh the point five is when all of the celium",
    "start": "580079",
    "end": "585959"
  },
  {
    "text": "agents in the cluster receive the celium end point slice and all of them will be",
    "start": "585959",
    "end": "591839"
  },
  {
    "text": "able to update the IP cache map that I mentioned in the previous slide so they will all know about uh this new pods IP",
    "start": "591839",
    "end": "601160"
  },
  {
    "text": "to Identity mapping so why does this work why does it work that we are batching end points into slices uh the",
    "start": "601160",
    "end": "609440"
  },
  {
    "text": "main uh issue is that uh kubernetes control plane uh is heavily impacted by",
    "start": "609440",
    "end": "616839"
  },
  {
    "text": "having too many uh events uh yeah when we have what 500,000",
    "start": "616839",
    "end": "623440"
  },
  {
    "text": "events per second that uh Cube AP server needs to handle uh the performance is",
    "start": "623440",
    "end": "629360"
  },
  {
    "text": "dropping and in some cases the watches are being terminated and their troubles intercluster",
    "start": "629360",
    "end": "634959"
  },
  {
    "text": "entirely sending fewer large request enables Q qapa server to handle the 100",
    "start": "634959",
    "end": "640560"
  },
  {
    "text": "uh po changes per second and cend point slice contains the minimum amount of",
    "start": "640560",
    "end": "645959"
  },
  {
    "text": "data for selum end points having security identity only to be a size of 64bit integer instead of a list of",
    "start": "645959",
    "end": "652320"
  },
  {
    "text": "strings which can be a lot uh significantly reduces the size of each end point one slice contains 50 end",
    "start": "652320",
    "end": "660279"
  },
  {
    "text": "points and a full slice is on average five times smaller than 50 celium end",
    "start": "660279",
    "end": "665600"
  },
  {
    "text": "points what about performance so as I said already we've uh demonstrated that",
    "start": "665600",
    "end": "672519"
  },
  {
    "text": "uh the scale will grow from one th000 nodes to 5,000 nodes with the same turn",
    "start": "672519",
    "end": "678000"
  },
  {
    "text": "rate on the pods and also the number of PODS can increase because we have some limits on how many um pods per node can",
    "start": "678000",
    "end": "685480"
  },
  {
    "text": "be and in this case we are in general uh supporting 200,000 pods because we are",
    "start": "685480",
    "end": "692040"
  },
  {
    "text": "recommending about 40 pods per node on this large scale and another thing we",
    "start": "692040",
    "end": "697120"
  },
  {
    "text": "can see that M Points slices updates are rate limited to 10 per second",
    "start": "697120",
    "end": "702560"
  },
  {
    "text": "because still we can uh overload the apaa server and we need to rate limit it in this case we are sending 10 times a",
    "start": "702560",
    "end": "710880"
  },
  {
    "text": "lower number of uh events we used to send with sment points up to 500,000 but",
    "start": "710880",
    "end": "717519"
  },
  {
    "text": "now we sending 50,000 and also we can support up to 500 pod updates per second",
    "start": "717519",
    "end": "724519"
  },
  {
    "text": "in a worst case scenario when you would suddenly want to update uh the security identities of all of the pods in your",
    "start": "724519",
    "end": "731040"
  },
  {
    "text": "cluster it would take up to 400 seconds in this case so it's uh a little bit",
    "start": "731040",
    "end": "736399"
  },
  {
    "text": "less than 7 Minutes uh okay so now we're going to",
    "start": "736399",
    "end": "742440"
  },
  {
    "text": "look at which metrics we are using which SLI we are having to uh look at the",
    "start": "742440",
    "end": "747720"
  },
  {
    "text": "improvements that we made on the bottleneck which is uh to propagate cium end points to all of the pods all of the",
    "start": "747720",
    "end": "755440"
  },
  {
    "text": "nodes and for them to see the ip2 identity mapping so celium and point propagation delay metric exists in the",
    "start": "755440",
    "end": "762000"
  },
  {
    "text": "cium agent and represents in this case networ policy enforcement latency because policy programming latency on",
    "start": "762000",
    "end": "768639"
  },
  {
    "text": "each note takes very low time which is less than 5 seconds after propagation of endpoints regardless of scale and the",
    "start": "768639",
    "end": "777320"
  },
  {
    "text": "diagram we see here is a four-step process where the start time is and point creation and end time is and",
    "start": "777320",
    "end": "783959"
  },
  {
    "text": "point received through and point slice uh and that is the entire delay",
    "start": "783959",
    "end": "789320"
  },
  {
    "text": "that selement point propagation delay metric is showing what are the other challenges",
    "start": "789320",
    "end": "795839"
  },
  {
    "text": "that we are currently facing so for n network policies to work at a very large",
    "start": "795839",
    "end": "801040"
  },
  {
    "text": "scale it's possible that there will be too many celium identities and there are some limits there uh so celum identity",
    "start": "801040",
    "end": "808079"
  },
  {
    "text": "equals the identity of One Security identity for pods and in this case uh",
    "start": "808079",
    "end": "813600"
  },
  {
    "text": "there is a hard limit of 65,000 security identities per cluster this is just by Design but the bigger restriction is",
    "start": "813600",
    "end": "819639"
  },
  {
    "text": "that we have a per pod BPF policy map which is 16,000 security identities for",
    "start": "819639",
    "end": "826360"
  },
  {
    "text": "each uh map and there are ways to trigger that ways that can trigger this",
    "start": "826360",
    "end": "833040"
  },
  {
    "text": "that can make you uh scale up to over 16,000 pods uh 16 ,000 security",
    "start": "833040",
    "end": "839519"
  },
  {
    "text": "identities and that is for example if you have uh unique label sets for most of the pods or all of the pods so even",
    "start": "839519",
    "end": "846000"
  },
  {
    "text": "just having 16,000 pods can uh in some senses break the cluster",
    "start": "846000",
    "end": "851839"
  },
  {
    "text": "where there will be the new pods will not be able to start because the ebpf policy Maps will not be able to uh be",
    "start": "851839",
    "end": "859440"
  },
  {
    "text": "populated and also there is another problem identity duplication which comes from uh distributed management of s",
    "start": "859440",
    "end": "867160"
  },
  {
    "text": "celum identities where celium agents are trying to create identities for the same",
    "start": "867160",
    "end": "873120"
  },
  {
    "text": "uh unique label set at the same time and uh they will create different ones and",
    "start": "873120",
    "end": "878399"
  },
  {
    "text": "there will be duplication which will which is causing that there is even more security identities in the cluster and",
    "start": "878399",
    "end": "884800"
  },
  {
    "text": "one ongoing issue is the namespace label change because uh security identities",
    "start": "884800",
    "end": "890120"
  },
  {
    "text": "depend on namespace labels it happens so that if namespace labels are changed all",
    "start": "890120",
    "end": "897800"
  },
  {
    "text": "security identities for the pods in this uh in the names space that was changing",
    "start": "897800",
    "end": "903759"
  },
  {
    "text": "labels we'll have to also change so what are the improvements we're currently working on the first one",
    "start": "903759",
    "end": "910399"
  },
  {
    "text": "is centralized identity management we are moving identity management to celium operator from celium agents this",
    "start": "910399",
    "end": "918160"
  },
  {
    "text": "resolves identity duplication reduces po startup latency because celium",
    "start": "918160",
    "end": "923440"
  },
  {
    "text": "identities are created on pod creation now instead of celium and point creation security Improvement celium agent loses",
    "start": "923440",
    "end": "930120"
  },
  {
    "text": "permission to write the celium identities no longer has a vulnerability there and enables forther further",
    "start": "930120",
    "end": "936880"
  },
  {
    "text": "improvements and optimizations uh this will enable us to",
    "start": "936880",
    "end": "942279"
  },
  {
    "text": "start uh using security relevant labeles uh filter even without",
    "start": "942279",
    "end": "947759"
  },
  {
    "text": "restarting selum agents so it means that we'll greatly reduce the number of security identities in uh some cases we",
    "start": "947759",
    "end": "955519"
  },
  {
    "text": "are able to reduce them by one by aund by a factor of 100 and another thing is",
    "start": "955519",
    "end": "963240"
  },
  {
    "text": "improving performance and reli reliability depending on scale by adding",
    "start": "963240",
    "end": "968279"
  },
  {
    "text": "Dynamic celum endpoint slice update rate limiting we want to try to also",
    "start": "968279",
    "end": "975000"
  },
  {
    "text": "uh rely on priority and fairness of kubernetes but for now we still need to",
    "start": "975000",
    "end": "982199"
  },
  {
    "text": "have this rate limiting and dynamically scaling up and down and Down based on the number of uh",
    "start": "982199",
    "end": "989160"
  },
  {
    "text": "based on the size of the cluster and the size of the master VMS the kubernetes",
    "start": "989160",
    "end": "995360"
  },
  {
    "text": "control play VMS is going to work uh another thing is faster policy enforcement for uh system critical",
    "start": "995360",
    "end": "1002880"
  },
  {
    "text": "pods uh this is achieved by priority propagation of celum end point",
    "start": "1002880",
    "end": "1008279"
  },
  {
    "text": "slices uh then we have uh a reduction in policy enforcement latency on a large",
    "start": "1008279",
    "end": "1014839"
  },
  {
    "text": "scale which is not something that we've been working on but in qap server there is an optimization coming soon for",
    "start": "1014839",
    "end": "1020839"
  },
  {
    "text": "processing events for many Watchers in kubernetes 129 and now I'll be bring it back to",
    "start": "1020839",
    "end": "1027558"
  },
  {
    "text": "marel okay thank you so we heard quite a lot of a lot of different problems that",
    "start": "1027559",
    "end": "1033199"
  },
  {
    "text": "we have when having single cluster and now the question becomes like what's else what what else can you do if you",
    "start": "1033199",
    "end": "1039839"
  },
  {
    "text": "are facing some of those issues so uh I would like to talk about cluster mesh so",
    "start": "1039839",
    "end": "1045520"
  },
  {
    "text": "if you are interested into higher scale what you might consider is actually a cluster mesh to connect multiple",
    "start": "1045520",
    "end": "1051760"
  },
  {
    "text": "clusters so what is the cluster mesh cluster mesh in a nutshell provides you",
    "start": "1051760",
    "end": "1056880"
  },
  {
    "text": "with connectivity pot topot connectivity between the Clusters and then on top of",
    "start": "1056880",
    "end": "1062080"
  },
  {
    "text": "that what you are getting is all the benefits of so starting with network policy enforcement that works across",
    "start": "1062080",
    "end": "1068840"
  },
  {
    "text": "clusters but also a transparent service Discovery so you can easily share Services between clusters um and of for",
    "start": "1068840",
    "end": "1077080"
  },
  {
    "text": "of course for example transport arent encryption if you are interested in this",
    "start": "1077080",
    "end": "1082280"
  },
  {
    "text": "topic um so let's go through two different use cases to kind of show you",
    "start": "1082280",
    "end": "1088200"
  },
  {
    "text": "what's possible with cluster mesh um so one example is let's say you have two clusters and you have backhands deployed",
    "start": "1088200",
    "end": "1095919"
  },
  {
    "text": "to both of them and let's say that you misconfigured your your backhands in one",
    "start": "1095919",
    "end": "1101440"
  },
  {
    "text": "of the Clusters so what cium can do and cluster mesh it can actually redirect",
    "start": "1101440",
    "end": "1107080"
  },
  {
    "text": "automatically um those connections to other cluster in case of misconfiguration so if you are",
    "start": "1107080",
    "end": "1113480"
  },
  {
    "text": "interested in high availability that might be option for you um another case",
    "start": "1113480",
    "end": "1118679"
  },
  {
    "text": "uh let's say that you are managing um Vault service like in this case um instead of the point it to all of the",
    "start": "1118679",
    "end": "1125600"
  },
  {
    "text": "Clusters that that you manage what you can do is have single cluster where you can manage this service and then just",
    "start": "1125600",
    "end": "1132360"
  },
  {
    "text": "simply expose it to to other clusters that can then later utilize this service",
    "start": "1132360",
    "end": "1139679"
  },
  {
    "text": "um so we were thinking about scalability of cluster mesh and uh our first initial",
    "start": "1139679",
    "end": "1147360"
  },
  {
    "text": "architecture was quite simple that we developed for it um the idea was that agent and operator they are just writing",
    "start": "1147360",
    "end": "1154360"
  },
  {
    "text": "the data to kubernetes control plane including nodes identities and",
    "start": "1154360",
    "end": "1159960"
  },
  {
    "text": "endpoints and then later on what was happening is that the cluster mesh",
    "start": "1159960",
    "end": "1165200"
  },
  {
    "text": "control plane was taking all of that data and right it down to to the Ed CD",
    "start": "1165200",
    "end": "1170919"
  },
  {
    "text": "and as you can see here the Ed CD then later is exposed to other clusters so",
    "start": "1170919",
    "end": "1177080"
  },
  {
    "text": "agents in remote clusters are watching for all those changes in nodes identities endpoints in order to provide",
    "start": "1177080",
    "end": "1183840"
  },
  {
    "text": "the connectivity between clusters and with that initial architecture uh what we did we did scale",
    "start": "1183840",
    "end": "1191320"
  },
  {
    "text": "testing so uh similarly what we were interested in was scale of 250 five",
    "start": "1191320",
    "end": "1198960"
  },
  {
    "text": "clusters 50,000 notes uh around like 50 notes per second of turn um end point",
    "start": "1198960",
    "end": "1206480"
  },
  {
    "text": "propagation up to 100 end points per second and half million pods in",
    "start": "1206480",
    "end": "1211840"
  },
  {
    "text": "total so with that in mind we prepared our test beted for for testing and we",
    "start": "1211840",
    "end": "1217600"
  },
  {
    "text": "were interested how much time it takes for the data to be propagated across across clusters and what we saw with",
    "start": "1217600",
    "end": "1224360"
  },
  {
    "text": "this initial architecture was that um",
    "start": "1224360",
    "end": "1230000"
  },
  {
    "text": "in the above uh graph you can see like what's the number of nodes and as it is increasing you can see more and more",
    "start": "1230000",
    "end": "1236559"
  },
  {
    "text": "spikes uh which basically mean that the data propagation between clusters was getting a little bit worse but what's",
    "start": "1236559",
    "end": "1243080"
  },
  {
    "text": "even more concerning is that at some point around like 35,000 notes 40,000 notes in the whole cluster mesh we",
    "start": "1243080",
    "end": "1249760"
  },
  {
    "text": "actually started to see that the data was not propagated at all so we were wondering like okay what what was going",
    "start": "1249760",
    "end": "1256440"
  },
  {
    "text": "on right so we took a look at the etcd metrix and what happened was that",
    "start": "1256440",
    "end": "1262640"
  },
  {
    "text": "whenever we were scaling the number of notes we can see that the CPU usage was increasing and at some point it just",
    "start": "1262640",
    "end": "1268799"
  },
  {
    "text": "skyrocketed to like 50 CPU cores uh similarly memory usage was increasing",
    "start": "1268799",
    "end": "1274320"
  },
  {
    "text": "and uh what we found out was that um when we took a look at the number of",
    "start": "1274320",
    "end": "1280559"
  },
  {
    "text": "watches that were opened to at CD uh there is this sudden drop so and it",
    "start": "1280559",
    "end": "1287520"
  },
  {
    "text": "correlates strongly with with the issue that we saw with data propagation between clusters and so what it means is",
    "start": "1287520",
    "end": "1294720"
  },
  {
    "text": "that at CD at this scale was really struggling and was unable to actually handle the data propagation so we were",
    "start": "1294720",
    "end": "1302240"
  },
  {
    "text": "thinking like okay so with that in mind like what we can do what we can do to actually improve the architecture of",
    "start": "1302240",
    "end": "1307880"
  },
  {
    "text": "cluster mesh and make it reliable at high scale um so one more thing the",
    "start": "1307880",
    "end": "1315440"
  },
  {
    "text": "bottleneck was as I mentioned um those all the that all the remote nodes were",
    "start": "1315440",
    "end": "1321559"
  },
  {
    "text": "watching single single poor at CD that was basically struggling with 50,000",
    "start": "1321559",
    "end": "1327080"
  },
  {
    "text": "noes so we introduced one more component into the cluster mesh we call it K store",
    "start": "1327080",
    "end": "1332640"
  },
  {
    "text": "mesh and the idea is that instead of having all of the nodes in the cluster match MH watch the at CD we have another",
    "start": "1332640",
    "end": "1340400"
  },
  {
    "text": "one in in in each cluster that replicates the data for from other",
    "start": "1340400",
    "end": "1345919"
  },
  {
    "text": "clusters so what it means is that nodes within single cluster they",
    "start": "1345919",
    "end": "1352720"
  },
  {
    "text": "are only watching the at CD in the same cluster um so going from 50,000 clients",
    "start": "1352720",
    "end": "1360279"
  },
  {
    "text": "that we had previously in our architecture we were able to reduce the number of clients to couple of hundreds",
    "start": "1360279",
    "end": "1367480"
  },
  {
    "text": "and this is way more manageable and much easier for at CD to handle that was our assumption but we of course wanted to",
    "start": "1367480",
    "end": "1374240"
  },
  {
    "text": "make scale tests and ensure that uh our assumption are correct so we did exactly",
    "start": "1374240",
    "end": "1380440"
  },
  {
    "text": "the same test and what we saw was that when we have like super high turn of",
    "start": "1380440",
    "end": "1386799"
  },
  {
    "text": "nodes as you can see here at the beginning um then the amount of data is quite high so we were throttling",
    "start": "1386799",
    "end": "1392559"
  },
  {
    "text": "actually the amount of data that was propagated across clusters so you can see that at the beginning during the",
    "start": "1392559",
    "end": "1398080"
  },
  {
    "text": "high note turn um there was delay around 1 second but it was pretty stable but",
    "start": "1398080",
    "end": "1403440"
  },
  {
    "text": "then once the note turn decreased and we were adding nodes slower and slower the data propagation delay was much",
    "start": "1403440",
    "end": "1411080"
  },
  {
    "text": "lower in terms of like maybe it was like tens of milliseconds and then of course like you",
    "start": "1411080",
    "end": "1417720"
  },
  {
    "text": "know taking um look at our experience with previous architecture we were wondering like Okay so let's take a look",
    "start": "1417720",
    "end": "1424679"
  },
  {
    "text": "at at CD again and um as we can see like CP usage of at CD was totally flat all",
    "start": "1424679",
    "end": "1430840"
  },
  {
    "text": "the time similarly memory usage was not couple of gigabytes but but couple",
    "start": "1430840",
    "end": "1436600"
  },
  {
    "text": "hundreds of megabytes um so our title actually mentioned",
    "start": "1436600",
    "end": "1443000"
  },
  {
    "text": "100,000 notes and you might ask okay so why I was showing only 50,000 notes so",
    "start": "1443000",
    "end": "1448799"
  },
  {
    "text": "first Improvement that we are um looking for in the cluster mes is that sometimes",
    "start": "1448799",
    "end": "1455200"
  },
  {
    "text": "we see that our customers want to scale even Beyond 250 uh 55 clusters so we are actually",
    "start": "1455200",
    "end": "1462159"
  },
  {
    "text": "adding support for 511 clusters in cluster mesh um and then on top of that",
    "start": "1462159",
    "end": "1468520"
  },
  {
    "text": "there are some other improvements that I would like to talk about so we are targeting around 100 um endpoint",
    "start": "1468520",
    "end": "1474880"
  },
  {
    "text": "propagation between clusters we are also looking into increasing that so the latency of data propagation gets slower",
    "start": "1474880",
    "end": "1482679"
  },
  {
    "text": "and last but not least we were also uh looking into uh reducing the",
    "start": "1482679",
    "end": "1487960"
  },
  {
    "text": "initialization time of control plane for cluster mesh you can think of it as like",
    "start": "1487960",
    "end": "1493159"
  },
  {
    "text": "if you are doing the upgrade and you need to upgrade the cluster mesh uh control plane then basically it needs to",
    "start": "1493159",
    "end": "1501159"
  },
  {
    "text": "synchronize quite a lot of data so we are also taking a look into that to minimize the amount of time uh that that",
    "start": "1501159",
    "end": "1507760"
  },
  {
    "text": "is required for uh for initialization of the cluster mesh um",
    "start": "1507760",
    "end": "1514640"
  },
  {
    "text": "so yeah thank you that's that's all and please provide feedback uh we will",
    "start": "1514640",
    "end": "1520480"
  },
  {
    "text": "really appreciate it and now we have time for",
    "start": "1520480",
    "end": "1529679"
  },
  {
    "text": "questions hi uh I have a question about the class mesh uh I believe CL I have a",
    "start": "1532600",
    "end": "1540720"
  },
  {
    "text": "question about class mesh so I believe it's using annotation",
    "start": "1540720",
    "end": "1546120"
  },
  {
    "text": "to set the global Service and the  agent s the service from the uh",
    "start": "1546120",
    "end": "1554559"
  },
  {
    "text": "other clusters MH and then the check the service by one just tell if it has an",
    "start": "1554559",
    "end": "1560000"
  },
  {
    "text": "anti or not uh so my question is why not just use label I mean you can use sorry",
    "start": "1560000",
    "end": "1566360"
  },
  {
    "text": "could could you speak a bit louder oh sorry yeah uh my question is why not to",
    "start": "1566360",
    "end": "1571480"
  },
  {
    "text": "use label inside because if you use the label you can just get the uh CMA service by",
    "start": "1571480",
    "end": "1579200"
  },
  {
    "text": "filter right you don't need to check one by one sorry sorry I didn't get it sorry",
    "start": "1579200",
    "end": "1589600"
  },
  {
    "text": "um wait okay maybe I will just jump here sorry it seems like the microphone here",
    "start": "1589960",
    "end": "1595840"
  },
  {
    "text": "is yeah yeah my question is the I believe the the class match yes annotation right annotation yeah Global",
    "start": "1595840",
    "end": "1603080"
  },
  {
    "text": "annotation yes uh but with that is like the agent need to check one by one to",
    "start": "1603080",
    "end": "1610640"
  },
  {
    "text": "tell if it has and not yeah so why not use the Lao why not use uh use Lao if",
    "start": "1610640",
    "end": "1617399"
  },
  {
    "text": "use label you can just the label okay so um yeah so I think the question was um",
    "start": "1617399",
    "end": "1626799"
  },
  {
    "text": "So currently how the Global Services work in cluster mesh is that you need to annotate the service and then the",
    "start": "1626799",
    "end": "1633080"
  },
  {
    "text": "service is um propagated across cluster meshes and the question was If instead",
    "start": "1633080",
    "end": "1640080"
  },
  {
    "text": "of that we could do the filtering on the agent side right kind of I mean you use",
    "start": "1640080",
    "end": "1646480"
  },
  {
    "text": "the label tell you can",
    "start": "1646480",
    "end": "1651880"
  },
  {
    "text": "just you could query okay so the question is like instead of like propagating all of the data Maybe the",
    "start": "1651880",
    "end": "1657880"
  },
  {
    "text": "agents in the remote cluster could actually query the API server in the other cluster so this kind of raises you",
    "start": "1657880",
    "end": "1665000"
  },
  {
    "text": "know reliability issues I think and uh one of the things like imagine then like",
    "start": "1665000",
    "end": "1671200"
  },
  {
    "text": "having 50,000 nodes talking to single kubernetes API server that would be even",
    "start": "1671200",
    "end": "1676720"
  },
  {
    "text": "worse as we saw with the single cluster issues like it could work potentially up",
    "start": "1676720",
    "end": "1682120"
  },
  {
    "text": "to 5,000 nodes but once you go beyond beyond that that scale you cannot really rely on the kubernetes control plane to",
    "start": "1682120",
    "end": "1688840"
  },
  {
    "text": "propagate that data for you yeah uh the question also was if could be like kind of like lazy loading thing where like",
    "start": "1688840",
    "end": "1695919"
  },
  {
    "text": "once you use the service it could query the kubernetes API the CL M ER",
    "start": "1695919",
    "end": "1704120"
  },
  {
    "text": "is the right uh the class APS server it get",
    "start": "1704120",
    "end": "1712919"
  },
  {
    "text": "service from APS server and put it the right",
    "start": "1712919",
    "end": "1718760"
  },
  {
    "text": "mhm so get Services I",
    "start": "1718760",
    "end": "1724840"
  },
  {
    "text": "mean could it be all services instead of just the ones that are",
    "start": "1724840",
    "end": "1730240"
  },
  {
    "text": "labeled yeah I mean like we could theoretically so how it works right now is you need to actually annotate the",
    "start": "1730240",
    "end": "1736799"
  },
  {
    "text": "service that you want want to expose and theoretically we could we could we could",
    "start": "1736799",
    "end": "1742080"
  },
  {
    "text": "um transfer all of the services but that's not really efficient and also from security perspective like you want",
    "start": "1742080",
    "end": "1747480"
  },
  {
    "text": "to limit amount of services that are exposed between clusters so yeah okay",
    "start": "1747480",
    "end": "1753480"
  },
  {
    "text": "okay um do we have other questions yeah I have one um when he talked about uh",
    "start": "1753480",
    "end": "1759760"
  },
  {
    "text": " operator that he will uh like do the identity allocation is that already",
    "start": "1759760",
    "end": "1766519"
  },
  {
    "text": "available in the 1.5 or no not yet but it should be available in 115 yes okay",
    "start": "1766519",
    "end": "1773080"
  },
  {
    "text": "cool thanks hi uh first of all thank you for",
    "start": "1773080",
    "end": "1778720"
  },
  {
    "text": "the great presentation and I have a question to d uh because we are using",
    "start": "1778720",
    "end": "1784799"
  },
  {
    "text": "gke and they are using like a data plan person two it's not as same as the",
    "start": "1784799",
    "end": "1790279"
  },
  {
    "text": "celium so have you test that kind of scalability I mean I I'm just curious",
    "start": "1790279",
    "end": "1795559"
  },
  {
    "text": "how many node we can scale of with the data plane person to instead of the",
    "start": "1795559",
    "end": "1801399"
  },
  {
    "text": "steum yeah so the data plane v21 GK supports up to 5,000 nodes as long as",
    "start": "1801399",
    "end": "1806679"
  },
  {
    "text": "you have a regional cluster because there are issues if you're a zonal cluster you have only one uh kubernetes",
    "start": "1806679",
    "end": "1813880"
  },
  {
    "text": "uh control plane VM so uh again it's related to scalability is not just the",
    "start": "1813880",
    "end": "1820600"
  },
  {
    "text": "number of nodes we are supporting uh we are supporting 5,000 nodes and 200,000",
    "start": "1820600",
    "end": "1826039"
  },
  {
    "text": "pods with exactly those limitations that I presented here and those tests were done on GK so if you want to run network",
    "start": "1826039",
    "end": "1832240"
  },
  {
    "text": "policies on GK powered by celium because data plan we do use a okay thanks so from my",
    "start": "1832240",
    "end": "1839519"
  },
  {
    "text": "understanding it's same like a limit and same like a mechanism is like a native",
    "start": "1839519",
    "end": "1845120"
  },
  {
    "text": "celum yes yes exactly that I presented those are the limits for GK right now uh",
    "start": "1845120",
    "end": "1851720"
  },
  {
    "text": "it's a kind of related question but like data plan persons to they are not supporting like celium pal",
    "start": "1851720",
    "end": "1857760"
  },
  {
    "text": "we need to use the network policy is that affect any issues yes uh that's a good question I",
    "start": "1857760",
    "end": "1864799"
  },
  {
    "text": "didn't mentioned that uh the tests here were done for uh kubernetes Network policies so the standard objects and not",
    "start": "1864799",
    "end": "1871679"
  },
  {
    "text": "the custom resources uh some celium Network policies are not affected and",
    "start": "1871679",
    "end": "1878840"
  },
  {
    "text": "would work but there are some cases where it doesn't work and there are some of them that are already fixed and uh",
    "start": "1878840",
    "end": "1884519"
  },
  {
    "text": "data plane V2 is looking to support also some other network policies but it's",
    "start": "1884519",
    "end": "1890480"
  },
  {
    "text": "still in progress so it's mainly about using them on scale in general it's not supporting because uh on gke we are",
    "start": "1890480",
    "end": "1899000"
  },
  {
    "text": "resolving some of the network policy related uh use cases with in in another",
    "start": "1899000",
    "end": "1905279"
  },
  {
    "text": "ways so in some other ways so that's that's it yeah good great thank you sorry I just remembered uh I",
    "start": "1905279",
    "end": "1912760"
  },
  {
    "text": "followup question uh for the operator um is that going to work with",
    "start": "1912760",
    "end": "1918279"
  },
  {
    "text": "like KV store identity allocation mode because as far as I know slum operator is not connected to at CD it's only like",
    "start": "1918279",
    "end": "1926799"
  },
  {
    "text": "it's not using KV store it's using crd yeah I know but so it's not going to work with uh KV store mode uh it can it",
    "start": "1926799",
    "end": "1934440"
  },
  {
    "text": "will it will we we will probably like right now right now we don't have a clear path of it it it is going to be",
    "start": "1934440",
    "end": "1940519"
  },
  {
    "text": "first with crd uh if there is there is a need for it we will we'll have it as well cool okay thanks a lot",
    "start": "1940519",
    "end": "1949080"
  },
  {
    "text": "um my question is around um identity you had um something in your SL about 65,000",
    "start": "1949519",
    "end": "1954760"
  },
  {
    "text": "identity what you can scale to how does that correlate to cers right if you're talking outside the cluster to a legacy",
    "start": "1954760",
    "end": "1959960"
  },
  {
    "text": "environment like VMS or something where you can't rely on identity okay so uh you mean like in terms of like cluster",
    "start": "1959960",
    "end": "1966240"
  },
  {
    "text": "mesh for example right or cluster mesh or just a single um yeah so so this is",
    "start": "1966240",
    "end": "1971399"
  },
  {
    "text": "basically kind of like per cluster limitation uh so if you are using like cluster M for example then the limit",
    "start": "1971399",
    "end": "1977279"
  },
  {
    "text": "applies to each single cluster separately so you have like you can have more identities than than that in",
    "start": "1977279",
    "end": "1982639"
  },
  {
    "text": "cluster mesh and um does does 65,000 equal a cider limit like how many ciders",
    "start": "1982639",
    "end": "1989600"
  },
  {
    "text": "could I put into it like a BPF map or total identity yes so I I can answer so",
    "start": "1989600",
    "end": "1994840"
  },
  {
    "text": "uh one ebpf policy map can have only 16,000 entries so you cannot specify",
    "start": "1994840",
    "end": "2001080"
  },
  {
    "text": "more than different 16,000 cider ranges so one cider range really equal to one",
    "start": "2001080",
    "end": "2007679"
  },
  {
    "text": "local identity but not the same asium identity which is global because every node is programming cider ranges as",
    "start": "2007679",
    "end": "2017480"
  },
  {
    "text": "identities locally and doesn't share with other everyone can do it on their own they don't need to share this data",
    "start": "2017480",
    "end": "2022679"
  },
  {
    "text": "so you can still the limit is 16,000 different CER ranges and what if I had to go over that",
    "start": "2022679",
    "end": "2030320"
  },
  {
    "text": "would that be something that it's possible with it's it's possible to",
    "start": "2030320",
    "end": "2035440"
  },
  {
    "text": "increase the M size uh right now why we are not looking into that direction is because there is a significant memory",
    "start": "2035440",
    "end": "2043840"
  },
  {
    "text": "increase because it's a fixed size so every time you create a new pod there is going to be a new policy map for it and",
    "start": "2043840",
    "end": "2051040"
  },
  {
    "text": "then it's a fixed size right now 16,000 entries there is some amount of uh",
    "start": "2051040",
    "end": "2056480"
  },
  {
    "text": "memory that needs to be allocated so it's possible it's a trade-off you you can do it we are looking to a Direction",
    "start": "2056480",
    "end": "2062720"
  },
  {
    "text": "Where We Are reducing the number of identities where it will just work and it will be as up optimiz the possible meaning that you will not have to use",
    "start": "2062720",
    "end": "2069839"
  },
  {
    "text": "per pod additional uh memory on the note that will be just fixed and even if you",
    "start": "2069839",
    "end": "2075320"
  },
  {
    "text": "because even if you're then not populating these Maps this memory is still allocated and the not released",
    "start": "2075320",
    "end": "2082280"
  },
  {
    "text": "yeah gotcha great talk thanks thank",
    "start": "2082280",
    "end": "2086879"
  },
  {
    "text": "you than",
    "start": "2095879",
    "end": "2102079"
  }
]
[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "welcome everyone to my talk mate",
    "start": "160",
    "end": "2000"
  },
  {
    "text": "prometheus use less memory and restart",
    "start": "2000",
    "end": "4080"
  },
  {
    "text": "faster",
    "start": "4080",
    "end": "5200"
  },
  {
    "text": "a little bit about myself i am ganesh",
    "start": "5200",
    "end": "7200"
  },
  {
    "text": "vernecker i am a software engineer at",
    "start": "7200",
    "end": "9440"
  },
  {
    "text": "grafana labs",
    "start": "9440",
    "end": "10800"
  },
  {
    "text": "and i am also a prometheus member and i",
    "start": "10800",
    "end": "12960"
  },
  {
    "text": "maintain the tsb engine of the",
    "start": "12960",
    "end": "14920"
  },
  {
    "text": "prometheus",
    "start": "14920",
    "end": "17119"
  },
  {
    "text": "so before we understand how we achieved",
    "start": "17119",
    "end": "19520"
  },
  {
    "text": "a reduction in memory and faster restart",
    "start": "19520",
    "end": "22240"
  },
  {
    "text": "you need to know how a sample goes",
    "start": "22240",
    "end": "24160"
  },
  {
    "text": "through in the tsdb",
    "start": "24160",
    "end": "26400"
  },
  {
    "text": "here i am assuming that you already know",
    "start": "26400",
    "end": "28320"
  },
  {
    "text": "a little bit about prometheus",
    "start": "28320",
    "end": "30240"
  },
  {
    "text": "and what does a memory series mean or a",
    "start": "30240",
    "end": "33280"
  },
  {
    "text": "series mean",
    "start": "33280",
    "end": "35200"
  },
  {
    "text": "so let's dive into a life cycle of a",
    "start": "35200",
    "end": "38000"
  },
  {
    "text": "sample",
    "start": "38000",
    "end": "39200"
  },
  {
    "text": "so this is how tsdb looks at a higher",
    "start": "39200",
    "end": "41680"
  },
  {
    "text": "level",
    "start": "41680",
    "end": "42320"
  },
  {
    "text": "there is something called the head block",
    "start": "42320",
    "end": "44399"
  },
  {
    "text": "which is the in memory part",
    "start": "44399",
    "end": "46000"
  },
  {
    "text": "of the database and there is a right",
    "start": "46000",
    "end": "48480"
  },
  {
    "text": "ahead log",
    "start": "48480",
    "end": "49840"
  },
  {
    "text": "which keeps it's on the disk which keeps",
    "start": "49840",
    "end": "52960"
  },
  {
    "text": "the record of all the samples and series",
    "start": "52960",
    "end": "54800"
  },
  {
    "text": "that are incoming",
    "start": "54800",
    "end": "56000"
  },
  {
    "text": "in the head so that in whenever there is",
    "start": "56000",
    "end": "58719"
  },
  {
    "text": "a crash we can recover the data from the",
    "start": "58719",
    "end": "60480"
  },
  {
    "text": "right ahead log",
    "start": "60480",
    "end": "61840"
  },
  {
    "text": "and there are blocks which are",
    "start": "61840",
    "end": "63440"
  },
  {
    "text": "persistent blocks on the disk",
    "start": "63440",
    "end": "65600"
  },
  {
    "text": "these are just data flushed from the",
    "start": "65600",
    "end": "67360"
  },
  {
    "text": "head block onto the disk",
    "start": "67360",
    "end": "69439"
  },
  {
    "text": "and uh with the in this",
    "start": "69439",
    "end": "72640"
  },
  {
    "text": "diagram the time grows from left to",
    "start": "72640",
    "end": "74560"
  },
  {
    "text": "right so the block on the left side is",
    "start": "74560",
    "end": "76320"
  },
  {
    "text": "the oldest block",
    "start": "76320",
    "end": "77360"
  },
  {
    "text": "this one looks bigger because it's",
    "start": "77360",
    "end": "80000"
  },
  {
    "text": "formed by merging two",
    "start": "80000",
    "end": "81439"
  },
  {
    "text": "blocks or more so the main focus",
    "start": "81439",
    "end": "84880"
  },
  {
    "text": "of this work is going to be the head",
    "start": "84880",
    "end": "88320"
  },
  {
    "text": "block and the right ahead log",
    "start": "88320",
    "end": "90159"
  },
  {
    "text": "because the memory optimizations and the",
    "start": "90159",
    "end": "92479"
  },
  {
    "text": "restart all are linked",
    "start": "92479",
    "end": "94720"
  },
  {
    "text": "to this particular section so let's zoom",
    "start": "94720",
    "end": "97680"
  },
  {
    "text": "a little bit into this",
    "start": "97680",
    "end": "99520"
  },
  {
    "text": "and understand in depth about the life",
    "start": "99520",
    "end": "102720"
  },
  {
    "text": "cycle of a sample",
    "start": "102720",
    "end": "105680"
  },
  {
    "start": "104000",
    "end": "104000"
  },
  {
    "text": "so in in all the discussions going",
    "start": "105840",
    "end": "108399"
  },
  {
    "text": "forward",
    "start": "108399",
    "end": "108960"
  },
  {
    "text": "i'll be talking with respect to a single",
    "start": "108960",
    "end": "111280"
  },
  {
    "text": "series",
    "start": "111280",
    "end": "112159"
  },
  {
    "text": "and yeah all the discussions are just",
    "start": "112159",
    "end": "114640"
  },
  {
    "text": "about a single series",
    "start": "114640",
    "end": "116079"
  },
  {
    "text": "i have a horizontal line here anything",
    "start": "116079",
    "end": "118560"
  },
  {
    "text": "that's represented",
    "start": "118560",
    "end": "119759"
  },
  {
    "text": "above this is in the memory anything",
    "start": "119759",
    "end": "122240"
  },
  {
    "text": "that's below this",
    "start": "122240",
    "end": "123439"
  },
  {
    "text": "is on the disk so here we have a sample",
    "start": "123439",
    "end": "127040"
  },
  {
    "text": "incoming",
    "start": "127040",
    "end": "127840"
  },
  {
    "text": "inside the head block and we store the",
    "start": "127840",
    "end": "130000"
  },
  {
    "text": "samples",
    "start": "130000",
    "end": "130879"
  },
  {
    "text": "in something called chunk a chunk",
    "start": "130879",
    "end": "134080"
  },
  {
    "text": "is a compressed unit of up to 120",
    "start": "134080",
    "end": "136640"
  },
  {
    "text": "samples",
    "start": "136640",
    "end": "138080"
  },
  {
    "text": "so let's say your scrape interval is 15",
    "start": "138080",
    "end": "140800"
  },
  {
    "text": "seconds",
    "start": "140800",
    "end": "141680"
  },
  {
    "text": "that means 120 samples would span",
    "start": "141680",
    "end": "144720"
  },
  {
    "text": "up to like 30 minutes so here i have",
    "start": "144720",
    "end": "147280"
  },
  {
    "text": "represented the chunk which is actively",
    "start": "147280",
    "end": "149760"
  },
  {
    "text": "being",
    "start": "149760",
    "end": "150080"
  },
  {
    "text": "appended to in the color red and",
    "start": "150080",
    "end": "153840"
  },
  {
    "text": "whenever we write a sample to the chunk",
    "start": "153840",
    "end": "155920"
  },
  {
    "text": "we also write it to the right ahead log",
    "start": "155920",
    "end": "158319"
  },
  {
    "text": "so that whenever there is a crash we can",
    "start": "158319",
    "end": "160000"
  },
  {
    "text": "recreate the same sample",
    "start": "160000",
    "end": "162160"
  },
  {
    "text": "and as i said it's a compressed unit of",
    "start": "162160",
    "end": "164640"
  },
  {
    "text": "120 samples so what happens",
    "start": "164640",
    "end": "166400"
  },
  {
    "text": "after you cross 120 samples we just cut",
    "start": "166400",
    "end": "169920"
  },
  {
    "text": "another chunk",
    "start": "169920",
    "end": "170959"
  },
  {
    "text": "so we end the life cycle of a single",
    "start": "170959",
    "end": "173760"
  },
  {
    "text": "chunk so this one was",
    "start": "173760",
    "end": "175440"
  },
  {
    "text": "red before now it has been cut up to 120",
    "start": "175440",
    "end": "178800"
  },
  {
    "text": "samples and there is a new",
    "start": "178800",
    "end": "180239"
  },
  {
    "text": "chunk which will be actively appended",
    "start": "180239",
    "end": "182400"
  },
  {
    "text": "too",
    "start": "182400",
    "end": "183360"
  },
  {
    "text": "so once you cut a chunk the chunky",
    "start": "183360",
    "end": "186560"
  },
  {
    "text": "seen the yellow shade is read only",
    "start": "186560",
    "end": "190319"
  },
  {
    "text": "that it's never appended to or no sample",
    "start": "190319",
    "end": "192720"
  },
  {
    "text": "is deleted",
    "start": "192720",
    "end": "194239"
  },
  {
    "text": "before we flush it into a block",
    "start": "194239",
    "end": "196840"
  },
  {
    "text": "similarly",
    "start": "196840",
    "end": "199840"
  },
  {
    "text": "the chunk just keeps getting the data",
    "start": "199840",
    "end": "202800"
  },
  {
    "text": "and the",
    "start": "202800",
    "end": "203680"
  },
  {
    "text": "new chunk is cut after every 30 minutes",
    "start": "203680",
    "end": "206080"
  },
  {
    "text": "if you assume 15 minute",
    "start": "206080",
    "end": "207519"
  },
  {
    "text": "15 second scrape interval and yep every",
    "start": "207519",
    "end": "210799"
  },
  {
    "text": "chunk has 120 samples",
    "start": "210799",
    "end": "212799"
  },
  {
    "text": "and considering the head",
    "start": "212799",
    "end": "216159"
  },
  {
    "text": "block range is like two hours like the",
    "start": "216159",
    "end": "218879"
  },
  {
    "text": "first block that you cut is two hours",
    "start": "218879",
    "end": "220879"
  },
  {
    "text": "in size the head block will store up to",
    "start": "220879",
    "end": "223120"
  },
  {
    "text": "three hours of data",
    "start": "223120",
    "end": "224239"
  },
  {
    "text": "so if you count the chunks here 30",
    "start": "224239",
    "end": "226000"
  },
  {
    "text": "minutes 30 minutes 30 minutes this spans",
    "start": "226000",
    "end": "228239"
  },
  {
    "text": "up to three hours of data and only the",
    "start": "228239",
    "end": "231440"
  },
  {
    "text": "red color chunk",
    "start": "231440",
    "end": "233599"
  },
  {
    "text": "is mutable like the samples will be",
    "start": "233599",
    "end": "235680"
  },
  {
    "text": "added but it won't be deleted",
    "start": "235680",
    "end": "237439"
  },
  {
    "text": "and the rest of the chunks are read only",
    "start": "237439",
    "end": "240000"
  },
  {
    "text": "once we come to this stage where the",
    "start": "240000",
    "end": "242000"
  },
  {
    "text": "head block spans three hours",
    "start": "242000",
    "end": "245120"
  },
  {
    "text": "we cut a block we take the first two",
    "start": "245120",
    "end": "247200"
  },
  {
    "text": "hours of data",
    "start": "247200",
    "end": "248239"
  },
  {
    "text": "which is the first four chunks here",
    "start": "248239",
    "end": "250159"
  },
  {
    "text": "leaving aside the fifth and the sixth",
    "start": "250159",
    "end": "251760"
  },
  {
    "text": "chunk",
    "start": "251760",
    "end": "252720"
  },
  {
    "text": "and this is flushed into the disk as a",
    "start": "252720",
    "end": "255760"
  },
  {
    "text": "part",
    "start": "255760",
    "end": "256400"
  },
  {
    "text": "as a block if you observed from the",
    "start": "256400",
    "end": "259759"
  },
  {
    "text": "beginning",
    "start": "259759",
    "end": "260799"
  },
  {
    "text": "the right ahead log it's growing as and",
    "start": "260799",
    "end": "263600"
  },
  {
    "text": "when",
    "start": "263600",
    "end": "264080"
  },
  {
    "text": "the data is incoming and once we cut the",
    "start": "264080",
    "end": "266840"
  },
  {
    "text": "block",
    "start": "266840",
    "end": "268240"
  },
  {
    "start": "267000",
    "end": "267000"
  },
  {
    "text": "the right-hand log is truncated",
    "start": "268240",
    "end": "271759"
  },
  {
    "text": "and the block consists of its own index",
    "start": "271759",
    "end": "274960"
  },
  {
    "text": "and such chunks stored separately the",
    "start": "274960",
    "end": "277440"
  },
  {
    "text": "index is required to",
    "start": "277440",
    "end": "280080"
  },
  {
    "text": "search into the chunks and here in the",
    "start": "280080",
    "end": "282880"
  },
  {
    "text": "head block i'm not showing you",
    "start": "282880",
    "end": "284960"
  },
  {
    "text": "other parts like the in-memory index i'm",
    "start": "284960",
    "end": "287120"
  },
  {
    "text": "just showing the chunks because",
    "start": "287120",
    "end": "288720"
  },
  {
    "text": "that's more relevant for this stock but",
    "start": "288720",
    "end": "291360"
  },
  {
    "text": "there is",
    "start": "291360",
    "end": "292000"
  },
  {
    "text": "a index here too for the head block",
    "start": "292000",
    "end": "296720"
  },
  {
    "text": "so this cycle repeats now you see the",
    "start": "296720",
    "end": "299520"
  },
  {
    "text": "chunk is 5",
    "start": "299520",
    "end": "300560"
  },
  {
    "text": "again it gets more samples there are",
    "start": "300560",
    "end": "302320"
  },
  {
    "text": "more chunks and the block is cut again",
    "start": "302320",
    "end": "305199"
  },
  {
    "text": "sweet so the block the diagram is",
    "start": "305199",
    "end": "309280"
  },
  {
    "text": "changed little bit to represent the",
    "start": "309280",
    "end": "311199"
  },
  {
    "text": "active chunk which is in red color here",
    "start": "311199",
    "end": "313280"
  },
  {
    "text": "and the index",
    "start": "313280",
    "end": "314400"
  },
  {
    "text": "for the blocks",
    "start": "314400",
    "end": "317120"
  },
  {
    "text": "and we created smaller blocks once it",
    "start": "317520",
    "end": "321199"
  },
  {
    "text": "grows back in time if the blocks are",
    "start": "321199",
    "end": "324160"
  },
  {
    "text": "merged to form bigger blocks",
    "start": "324160",
    "end": "326560"
  },
  {
    "text": "so now let's save some memory and the",
    "start": "326560",
    "end": "329840"
  },
  {
    "text": "as you see as you can already see here",
    "start": "329840",
    "end": "332320"
  },
  {
    "text": "it's done through memory mapping from",
    "start": "332320",
    "end": "334240"
  },
  {
    "text": "disk",
    "start": "334240",
    "end": "334960"
  },
  {
    "text": "so let's see how that's done so that's",
    "start": "334960",
    "end": "336880"
  },
  {
    "start": "336000",
    "end": "336000"
  },
  {
    "text": "done by these two pairs that have worked",
    "start": "336880",
    "end": "338880"
  },
  {
    "text": "on",
    "start": "338880",
    "end": "339440"
  },
  {
    "text": "and this work is in the prometheus",
    "start": "339440",
    "end": "342240"
  },
  {
    "text": "release 2.19",
    "start": "342240",
    "end": "343919"
  },
  {
    "text": "so you can appeal to that if you wish to",
    "start": "343919",
    "end": "346639"
  },
  {
    "text": "have this optimization in",
    "start": "346639",
    "end": "348720"
  },
  {
    "text": "so let's go back to the initial state",
    "start": "348720",
    "end": "351120"
  },
  {
    "text": "where there was one active chunk",
    "start": "351120",
    "end": "353280"
  },
  {
    "text": "and the sample was being appended to",
    "start": "353280",
    "end": "354880"
  },
  {
    "text": "that and obviously there is a right",
    "start": "354880",
    "end": "356240"
  },
  {
    "text": "ahead lock",
    "start": "356240",
    "end": "358240"
  },
  {
    "text": "as i said when there is a chunk the",
    "start": "358240",
    "end": "360800"
  },
  {
    "text": "yellow chunk which is already cut",
    "start": "360800",
    "end": "362560"
  },
  {
    "text": "it's just read only and it cannot be",
    "start": "362560",
    "end": "365680"
  },
  {
    "text": "returned to or it cannot be deleted it's",
    "start": "365680",
    "end": "368560"
  },
  {
    "text": "similar to a block",
    "start": "368560",
    "end": "370080"
  },
  {
    "text": "where the chunks in the block are",
    "start": "370080",
    "end": "372240"
  },
  {
    "text": "immutable",
    "start": "372240",
    "end": "373360"
  },
  {
    "text": "hence your memory map from the disk",
    "start": "373360",
    "end": "375199"
  },
  {
    "text": "memory mapping is",
    "start": "375199",
    "end": "376880"
  },
  {
    "text": "a feature given by the os where",
    "start": "376880",
    "end": "380240"
  },
  {
    "text": "you need not load the entire file into",
    "start": "380240",
    "end": "382400"
  },
  {
    "text": "the memory if you want to access",
    "start": "382400",
    "end": "384800"
  },
  {
    "text": "and you can just say i want to access",
    "start": "384800",
    "end": "386479"
  },
  {
    "text": "this part of the file and the os will",
    "start": "386479",
    "end": "388479"
  },
  {
    "text": "take care of loading",
    "start": "388479",
    "end": "389680"
  },
  {
    "text": "just that part of the file into the",
    "start": "389680",
    "end": "391120"
  },
  {
    "text": "memory which is great",
    "start": "391120",
    "end": "393280"
  },
  {
    "text": "it removes a lot of complexity from the",
    "start": "393280",
    "end": "395280"
  },
  {
    "text": "code",
    "start": "395280",
    "end": "396639"
  },
  {
    "text": "so similarly because we memory mac jumps",
    "start": "396639",
    "end": "399520"
  },
  {
    "text": "chunks from the disk for the blocks",
    "start": "399520",
    "end": "401840"
  },
  {
    "text": "why can't we do it for even the head",
    "start": "401840",
    "end": "404000"
  },
  {
    "text": "block",
    "start": "404000",
    "end": "404960"
  },
  {
    "text": "so that's what we exactly do once we cut",
    "start": "404960",
    "end": "408319"
  },
  {
    "text": "a new chunk for the head we flush that",
    "start": "408319",
    "end": "412560"
  },
  {
    "text": "to the disc as you can see i already",
    "start": "412560",
    "end": "414479"
  },
  {
    "text": "mentioned this line is",
    "start": "414479",
    "end": "415919"
  },
  {
    "text": "separates the memory from the disc so",
    "start": "415919",
    "end": "417759"
  },
  {
    "text": "now the chunk is",
    "start": "417759",
    "end": "419360"
  },
  {
    "text": "on the disc and while the chunk is on",
    "start": "419360",
    "end": "422720"
  },
  {
    "text": "the disc we just store",
    "start": "422720",
    "end": "424080"
  },
  {
    "text": "a reference for this chunk into the",
    "start": "424080",
    "end": "426240"
  },
  {
    "text": "memory so the chunk can grow up to like",
    "start": "426240",
    "end": "428880"
  },
  {
    "text": "120 bytes or 150 bytes or maybe even 200",
    "start": "428880",
    "end": "432000"
  },
  {
    "text": "bytes",
    "start": "432000",
    "end": "432800"
  },
  {
    "text": "that's replaced by just 8 bytes of",
    "start": "432800",
    "end": "435680"
  },
  {
    "text": "reference into the memory",
    "start": "435680",
    "end": "438160"
  },
  {
    "text": "similarly as and when we are cutting the",
    "start": "438160",
    "end": "441120"
  },
  {
    "text": "chunk",
    "start": "441120",
    "end": "441840"
  },
  {
    "text": "here the new chunk there is a second",
    "start": "441840",
    "end": "444000"
  },
  {
    "text": "chunk incoming",
    "start": "444000",
    "end": "445440"
  },
  {
    "text": "immediately we flush it to the disk if",
    "start": "445440",
    "end": "448240"
  },
  {
    "text": "you observe carefully",
    "start": "448240",
    "end": "449520"
  },
  {
    "text": "the right ahead log",
    "start": "449520",
    "end": "452560"
  },
  {
    "text": "it grows like once it's flush to the",
    "start": "452560",
    "end": "454960"
  },
  {
    "text": "disc the right headlock is",
    "start": "454960",
    "end": "456720"
  },
  {
    "text": "not truncated it grows i will explain",
    "start": "456720",
    "end": "459280"
  },
  {
    "text": "why this happens in",
    "start": "459280",
    "end": "461039"
  },
  {
    "text": "a moment so similarly we have one chunk",
    "start": "461039",
    "end": "464160"
  },
  {
    "text": "two chunk and all the five chunks",
    "start": "464160",
    "end": "467759"
  },
  {
    "start": "466000",
    "end": "466000"
  },
  {
    "text": "memory mapped to the disk so",
    "start": "467759",
    "end": "470879"
  },
  {
    "text": "when the compaction happens the chunks",
    "start": "470879",
    "end": "473280"
  },
  {
    "text": "are taken from here",
    "start": "473280",
    "end": "474879"
  },
  {
    "text": "and the truncation doesn't happen",
    "start": "474879",
    "end": "476400"
  },
  {
    "text": "immediately here i am not going in deep",
    "start": "476400",
    "end": "478240"
  },
  {
    "text": "about how",
    "start": "478240",
    "end": "479120"
  },
  {
    "text": "the my chunks are truncated because it's",
    "start": "479120",
    "end": "481840"
  },
  {
    "text": "not much relearned for this talk",
    "start": "481840",
    "end": "483840"
  },
  {
    "text": "but yep that's how we are saving memory",
    "start": "483840",
    "end": "486560"
  },
  {
    "text": "though it feels like you are",
    "start": "486560",
    "end": "488479"
  },
  {
    "text": "saving like 5 6 of the memory but",
    "start": "488479",
    "end": "492000"
  },
  {
    "text": "it's really not 5 6 because the other",
    "start": "492000",
    "end": "494960"
  },
  {
    "text": "factors are considered like",
    "start": "494960",
    "end": "496240"
  },
  {
    "text": "the in memory index the symbols that is",
    "start": "496240",
    "end": "498479"
  },
  {
    "text": "stored",
    "start": "498479",
    "end": "499360"
  },
  {
    "text": "and the memory required to load a block",
    "start": "499360",
    "end": "502160"
  },
  {
    "text": "and lots of other things",
    "start": "502160",
    "end": "504000"
  },
  {
    "text": "so realistically speaking the memory",
    "start": "504000",
    "end": "506240"
  },
  {
    "text": "savings is like",
    "start": "506240",
    "end": "508080"
  },
  {
    "text": "30 to 40 percent in best case or up to",
    "start": "508080",
    "end": "511520"
  },
  {
    "text": "50",
    "start": "511520",
    "end": "512240"
  },
  {
    "text": "and when there is a high chunk when i",
    "start": "512240",
    "end": "514159"
  },
  {
    "text": "say churn it means the rate at which new",
    "start": "514159",
    "end": "516000"
  },
  {
    "text": "series are being created or new series",
    "start": "516000",
    "end": "518320"
  },
  {
    "text": "are being deleted when that is high the",
    "start": "518320",
    "end": "521360"
  },
  {
    "text": "savings are less",
    "start": "521360",
    "end": "523039"
  },
  {
    "text": "but if we go back to the discussion of",
    "start": "523039",
    "end": "525600"
  },
  {
    "text": "15 second scrape interval",
    "start": "525600",
    "end": "527200"
  },
  {
    "text": "we used to store six chunks into the",
    "start": "527200",
    "end": "529120"
  },
  {
    "text": "memory in the worst",
    "start": "529120",
    "end": "530720"
  },
  {
    "text": "case but now it's in for all the scrape",
    "start": "530720",
    "end": "534080"
  },
  {
    "text": "intervals",
    "start": "534080",
    "end": "534720"
  },
  {
    "text": "it's up to one chunk that we store into",
    "start": "534720",
    "end": "537279"
  },
  {
    "text": "the memory which is sweet",
    "start": "537279",
    "end": "538800"
  },
  {
    "text": "so we run something called prom bench",
    "start": "538800",
    "end": "541680"
  },
  {
    "text": "which is a heavy benchmark for every",
    "start": "541680",
    "end": "543600"
  },
  {
    "text": "release that we",
    "start": "543600",
    "end": "544880"
  },
  {
    "text": "cut out so this uh is comparing",
    "start": "544880",
    "end": "548880"
  },
  {
    "text": "the release 2.19 with the release 2.18",
    "start": "548880",
    "end": "553279"
  },
  {
    "text": "and you can see there is 30 to 40",
    "start": "553279",
    "end": "555600"
  },
  {
    "text": "reduction",
    "start": "555600",
    "end": "556320"
  },
  {
    "text": "in the memory usage there are lots of",
    "start": "556320",
    "end": "559440"
  },
  {
    "text": "lines here",
    "start": "559440",
    "end": "560000"
  },
  {
    "text": "not to confuse with many other lines",
    "start": "560000",
    "end": "561519"
  },
  {
    "text": "that we have it's the yellow line here",
    "start": "561519",
    "end": "563279"
  },
  {
    "text": "and the green line that is being",
    "start": "563279",
    "end": "564560"
  },
  {
    "text": "compared to",
    "start": "564560",
    "end": "565760"
  },
  {
    "text": "and this is when the churn is low which",
    "start": "565760",
    "end": "568240"
  },
  {
    "text": "means the rate at which new series being",
    "start": "568240",
    "end": "570080"
  },
  {
    "text": "is being created is very less",
    "start": "570080",
    "end": "572240"
  },
  {
    "text": "and when there is a high churn there is",
    "start": "572240",
    "end": "574959"
  },
  {
    "text": "still some reduction which",
    "start": "574959",
    "end": "576000"
  },
  {
    "text": "is like 10 to 20 percent and this is",
    "start": "576000",
    "end": "578959"
  },
  {
    "text": "from git lab",
    "start": "578959",
    "end": "580080"
  },
  {
    "text": "from one of the github gitlab issues so",
    "start": "580080",
    "end": "583200"
  },
  {
    "text": "when they upgraded to prometheus 2.19",
    "start": "583200",
    "end": "586560"
  },
  {
    "text": "they saw a reduction up to 50",
    "start": "586560",
    "end": "590240"
  },
  {
    "text": "if you see on the left side uh before",
    "start": "590240",
    "end": "592640"
  },
  {
    "text": "memory mapping",
    "start": "592640",
    "end": "593519"
  },
  {
    "text": "there are spikes every two hours because",
    "start": "593519",
    "end": "596240"
  },
  {
    "text": "as you saw",
    "start": "596240",
    "end": "597839"
  },
  {
    "text": "initially in the life cycle of a sample",
    "start": "597839",
    "end": "600880"
  },
  {
    "text": "the head stores up to six chunks if we",
    "start": "600880",
    "end": "603680"
  },
  {
    "text": "take",
    "start": "603680",
    "end": "604560"
  },
  {
    "text": "the scrap interval of 15 seconds so with",
    "start": "604560",
    "end": "606560"
  },
  {
    "text": "time the memory grows",
    "start": "606560",
    "end": "608000"
  },
  {
    "text": "for head block and after compaction it",
    "start": "608000",
    "end": "610079"
  },
  {
    "text": "comes down it grows for two hours",
    "start": "610079",
    "end": "612320"
  },
  {
    "text": "after compaction it comes down but you",
    "start": "612320",
    "end": "614320"
  },
  {
    "text": "see after memory mapping because",
    "start": "614320",
    "end": "616320"
  },
  {
    "text": "we store up to one chunk in the memory",
    "start": "616320",
    "end": "619920"
  },
  {
    "text": "in the worst case the memory is little",
    "start": "619920",
    "end": "623120"
  },
  {
    "text": "stable there is no",
    "start": "623120",
    "end": "624240"
  },
  {
    "text": "ups and down like this",
    "start": "624240",
    "end": "627440"
  },
  {
    "text": "so that's sweet now talking about little",
    "start": "627440",
    "end": "630800"
  },
  {
    "start": "629000",
    "end": "629000"
  },
  {
    "text": "fast replay this is not the ultimate",
    "start": "630800",
    "end": "632880"
  },
  {
    "text": "fast replay that i'm going to speak",
    "start": "632880",
    "end": "634480"
  },
  {
    "text": "about this was a good side effect",
    "start": "634480",
    "end": "636800"
  },
  {
    "text": "of the memory mapping work so explaining",
    "start": "636800",
    "end": "639839"
  },
  {
    "text": "a little bit about",
    "start": "639839",
    "end": "641600"
  },
  {
    "text": "replays the replay consists of going",
    "start": "641600",
    "end": "644240"
  },
  {
    "text": "through the right headlock records",
    "start": "644240",
    "end": "646160"
  },
  {
    "text": "and replaying each and every sample that",
    "start": "646160",
    "end": "648320"
  },
  {
    "text": "we ingested before",
    "start": "648320",
    "end": "649680"
  },
  {
    "text": "so the replay consists of recreating the",
    "start": "649680",
    "end": "653279"
  },
  {
    "text": "compressed chunks",
    "start": "653279",
    "end": "654560"
  },
  {
    "text": "that we have in the memory or you can",
    "start": "654560",
    "end": "656720"
  },
  {
    "text": "see the memory map chunks",
    "start": "656720",
    "end": "658839"
  },
  {
    "text": "so recreating those compress",
    "start": "658839",
    "end": "662000"
  },
  {
    "text": "compressed chunks is an additional cpu",
    "start": "662000",
    "end": "665279"
  },
  {
    "text": "task and takes a bit of",
    "start": "665279",
    "end": "667040"
  },
  {
    "text": "time so because we already have the",
    "start": "667040",
    "end": "669680"
  },
  {
    "text": "entire chunk",
    "start": "669680",
    "end": "670800"
  },
  {
    "text": "flushed on the disc whenever we are",
    "start": "670800",
    "end": "672640"
  },
  {
    "text": "iterating through the samples",
    "start": "672640",
    "end": "674880"
  },
  {
    "text": "we look back and see if there is a chunk",
    "start": "674880",
    "end": "677760"
  },
  {
    "text": "a memory map chunk which is already",
    "start": "677760",
    "end": "679680"
  },
  {
    "text": "present for this time range",
    "start": "679680",
    "end": "681200"
  },
  {
    "text": "and hence we skip the sample so we don't",
    "start": "681200",
    "end": "683600"
  },
  {
    "text": "need to",
    "start": "683600",
    "end": "684399"
  },
  {
    "text": "recreate all the chunks",
    "start": "684399",
    "end": "687519"
  },
  {
    "text": "that are already there on the disk and",
    "start": "687519",
    "end": "689760"
  },
  {
    "text": "because we don't have to recreate the",
    "start": "689760",
    "end": "692640"
  },
  {
    "text": "compressed chunks this uh causes",
    "start": "692640",
    "end": "696079"
  },
  {
    "text": "a reduction of restart time by up to 20",
    "start": "696079",
    "end": "698640"
  },
  {
    "text": "to 30 percent that we saw in the from",
    "start": "698640",
    "end": "700480"
  },
  {
    "text": "bench",
    "start": "700480",
    "end": "701120"
  },
  {
    "text": "which is a nice side effect of this",
    "start": "701120",
    "end": "706000"
  },
  {
    "text": "now so i mentioned i will talk why",
    "start": "706640",
    "end": "710160"
  },
  {
    "text": "we should not we don't truncate the",
    "start": "710160",
    "end": "712160"
  },
  {
    "text": "right headlock",
    "start": "712160",
    "end": "713200"
  },
  {
    "text": "because the right hired log is required",
    "start": "713200",
    "end": "716560"
  },
  {
    "text": "during replay to recreate this",
    "start": "716560",
    "end": "718480"
  },
  {
    "text": "chunk in the memory but because there",
    "start": "718480",
    "end": "721200"
  },
  {
    "text": "are",
    "start": "721200",
    "end": "721760"
  },
  {
    "text": "millions of series we don't know where",
    "start": "721760",
    "end": "724959"
  },
  {
    "text": "exactly is the sample for this right",
    "start": "724959",
    "end": "726880"
  },
  {
    "text": "ahead for this chunk",
    "start": "726880",
    "end": "728240"
  },
  {
    "text": "in the right ahead log so if we had to",
    "start": "728240",
    "end": "730880"
  },
  {
    "text": "truncate the right headlock for these",
    "start": "730880",
    "end": "732639"
  },
  {
    "text": "chunks",
    "start": "732639",
    "end": "733440"
  },
  {
    "text": "we have to go through the entire right",
    "start": "733440",
    "end": "735360"
  },
  {
    "text": "ahead log and remove the irrelevant",
    "start": "735360",
    "end": "737680"
  },
  {
    "text": "samples",
    "start": "737680",
    "end": "738480"
  },
  {
    "text": "and rewrite the right dialog which is",
    "start": "738480",
    "end": "740639"
  },
  {
    "text": "very inefficient and very expensive in",
    "start": "740639",
    "end": "742639"
  },
  {
    "text": "terms of disk",
    "start": "742639",
    "end": "744000"
  },
  {
    "text": "and yep it will just stall a lot of",
    "start": "744000",
    "end": "747440"
  },
  {
    "text": "other process of prometheus",
    "start": "747440",
    "end": "748959"
  },
  {
    "text": "so we don't truncate that ahead log",
    "start": "748959",
    "end": "751519"
  },
  {
    "text": "immediately",
    "start": "751519",
    "end": "752399"
  },
  {
    "text": "we truncate it like before whenever a",
    "start": "752399",
    "end": "755120"
  },
  {
    "text": "compaction of head happens",
    "start": "755120",
    "end": "757680"
  },
  {
    "text": "and also remote light depends on right",
    "start": "757680",
    "end": "759839"
  },
  {
    "text": "ahead log",
    "start": "759839",
    "end": "760800"
  },
  {
    "text": "to send it to remote storage for long",
    "start": "760800",
    "end": "763120"
  },
  {
    "text": "term retention",
    "start": "763120",
    "end": "764639"
  },
  {
    "text": "so unless the remote write starts using",
    "start": "764639",
    "end": "768079"
  },
  {
    "text": "the memory map",
    "start": "768079",
    "end": "768880"
  },
  {
    "text": "chunks for remote writing we cannot",
    "start": "768880",
    "end": "772560"
  },
  {
    "text": "truncate the right headlock very soon so",
    "start": "772560",
    "end": "774800"
  },
  {
    "text": "that's one of the reason",
    "start": "774800",
    "end": "777440"
  },
  {
    "text": "and there are some things to keep in",
    "start": "777440",
    "end": "779279"
  },
  {
    "text": "mind this memory saving is not like",
    "start": "779279",
    "end": "781680"
  },
  {
    "text": "the final thing that you see the memory",
    "start": "781680",
    "end": "784399"
  },
  {
    "text": "can grow",
    "start": "784399",
    "end": "785519"
  },
  {
    "text": "because as i said memory mapping is an",
    "start": "785519",
    "end": "787600"
  },
  {
    "text": "os feature",
    "start": "787600",
    "end": "788720"
  },
  {
    "text": "and if you want to access it it's",
    "start": "788720",
    "end": "790880"
  },
  {
    "text": "brought back into the memory again",
    "start": "790880",
    "end": "793839"
  },
  {
    "text": "so that happens when you have a query",
    "start": "793839",
    "end": "796079"
  },
  {
    "text": "hitting the memory map chunks",
    "start": "796079",
    "end": "797920"
  },
  {
    "text": "so for example if you have a query",
    "start": "797920",
    "end": "801120"
  },
  {
    "text": "which touches like all the series for",
    "start": "801120",
    "end": "803920"
  },
  {
    "text": "the past three hours of data",
    "start": "803920",
    "end": "806000"
  },
  {
    "text": "then it's going to load back all the",
    "start": "806000",
    "end": "808399"
  },
  {
    "text": "chunks into the memory",
    "start": "808399",
    "end": "809680"
  },
  {
    "text": "but realistically speaking that doesn't",
    "start": "809680",
    "end": "811680"
  },
  {
    "text": "happen often",
    "start": "811680",
    "end": "813519"
  },
  {
    "text": "so if you don't run a very heavy queries",
    "start": "813519",
    "end": "816560"
  },
  {
    "text": "for a very well like past two or three",
    "start": "816560",
    "end": "819519"
  },
  {
    "text": "hours of data",
    "start": "819519",
    "end": "820639"
  },
  {
    "text": "then you should be good in this regard",
    "start": "820639",
    "end": "822800"
  },
  {
    "text": "also because we are flushing",
    "start": "822800",
    "end": "824959"
  },
  {
    "text": "the chunks immediately to the disk there",
    "start": "824959",
    "end": "828079"
  },
  {
    "text": "is",
    "start": "828079",
    "end": "829040"
  },
  {
    "text": "an additional disk space requirement",
    "start": "829040",
    "end": "830880"
  },
  {
    "text": "because even when the compaction of head",
    "start": "830880",
    "end": "833600"
  },
  {
    "text": "happens",
    "start": "833600",
    "end": "834480"
  },
  {
    "text": "there is still some chunks like the",
    "start": "834480",
    "end": "836639"
  },
  {
    "text": "memory map chunks on the desk",
    "start": "836639",
    "end": "839440"
  },
  {
    "text": "so that takes some extra space so if you",
    "start": "839440",
    "end": "841040"
  },
  {
    "text": "are tight on disk space",
    "start": "841040",
    "end": "843040"
  },
  {
    "text": "this is something to keep in mind to",
    "start": "843040",
    "end": "845040"
  },
  {
    "text": "adjust your retention or the",
    "start": "845040",
    "end": "847199"
  },
  {
    "text": "this size base retention or just give",
    "start": "847199",
    "end": "849839"
  },
  {
    "text": "more",
    "start": "849839",
    "end": "850399"
  },
  {
    "text": "space to it now that we have seen how",
    "start": "850399",
    "end": "853519"
  },
  {
    "text": "are we saving the memory",
    "start": "853519",
    "end": "855360"
  },
  {
    "text": "let's talk about fast restarts because",
    "start": "855360",
    "end": "857920"
  },
  {
    "text": "when you have like millions of series",
    "start": "857920",
    "end": "860320"
  },
  {
    "text": "the restart can span up to 10 minutes or",
    "start": "860320",
    "end": "863440"
  },
  {
    "text": "more",
    "start": "863440",
    "end": "863839"
  },
  {
    "text": "which is not so ideal in",
    "start": "863839",
    "end": "866880"
  },
  {
    "text": "terms of monitoring because yeah you are",
    "start": "866880",
    "end": "869519"
  },
  {
    "text": "using this for writing and you want it",
    "start": "869519",
    "end": "871199"
  },
  {
    "text": "to be up",
    "start": "871199",
    "end": "872000"
  },
  {
    "text": "for most of the time i'm saying it's",
    "start": "872000",
    "end": "875199"
  },
  {
    "text": "coming soon because it's a work in",
    "start": "875199",
    "end": "876720"
  },
  {
    "text": "progress",
    "start": "876720",
    "end": "877680"
  },
  {
    "text": "and it should be in sometime soon in the",
    "start": "877680",
    "end": "880399"
  },
  {
    "text": "future",
    "start": "880399",
    "end": "882800"
  },
  {
    "start": "881000",
    "end": "881000"
  },
  {
    "text": "so this is how the tsdb uh specifically",
    "start": "883120",
    "end": "886639"
  },
  {
    "text": "the head block and the right headlock",
    "start": "886639",
    "end": "888160"
  },
  {
    "text": "looks",
    "start": "888160",
    "end": "889519"
  },
  {
    "text": "after the memory mapping and",
    "start": "889519",
    "end": "893040"
  },
  {
    "text": "as i briefly talked before we",
    "start": "893040",
    "end": "896160"
  },
  {
    "text": "are iterating through the entire right",
    "start": "896160",
    "end": "898320"
  },
  {
    "text": "ahead log",
    "start": "898320",
    "end": "899760"
  },
  {
    "text": "just to create this last chunk because",
    "start": "899760",
    "end": "901680"
  },
  {
    "text": "we don't know where are the samples for",
    "start": "901680",
    "end": "903440"
  },
  {
    "text": "this last chunk",
    "start": "903440",
    "end": "905360"
  },
  {
    "text": "and even though we have the chunks",
    "start": "905360",
    "end": "908320"
  },
  {
    "text": "already flushed entered a disk like the",
    "start": "908320",
    "end": "910240"
  },
  {
    "text": "old chunks",
    "start": "910240",
    "end": "912000"
  },
  {
    "text": "we are still going through the samples",
    "start": "912000",
    "end": "913760"
  },
  {
    "text": "for these chunks just to discard it",
    "start": "913760",
    "end": "916079"
  },
  {
    "text": "later",
    "start": "916079",
    "end": "917839"
  },
  {
    "text": "what if we knew what are the exact",
    "start": "917839",
    "end": "920880"
  },
  {
    "text": "samples for this chunk so that we don't",
    "start": "920880",
    "end": "922959"
  },
  {
    "text": "need to go through the entire right",
    "start": "922959",
    "end": "924839"
  },
  {
    "text": "headlock yep you guessed it right",
    "start": "924839",
    "end": "927680"
  },
  {
    "text": "we just flush this last chunk on the",
    "start": "927680",
    "end": "930240"
  },
  {
    "start": "928000",
    "end": "928000"
  },
  {
    "text": "disc",
    "start": "930240",
    "end": "930880"
  },
  {
    "text": "and we call it a snapshot so this",
    "start": "930880",
    "end": "933680"
  },
  {
    "text": "happens during shutdown",
    "start": "933680",
    "end": "935199"
  },
  {
    "text": "initially we thought we could take a",
    "start": "935199",
    "end": "937519"
  },
  {
    "text": "regular snapshot",
    "start": "937519",
    "end": "938959"
  },
  {
    "text": "but with some calculations we came to a",
    "start": "938959",
    "end": "941680"
  },
  {
    "text": "conclusion this can cause up to 50",
    "start": "941680",
    "end": "943600"
  },
  {
    "text": "percent or more",
    "start": "943600",
    "end": "944880"
  },
  {
    "text": "right amplification which is not really",
    "start": "944880",
    "end": "946800"
  },
  {
    "text": "desired so",
    "start": "946800",
    "end": "948320"
  },
  {
    "text": "in this what we do is whenever we are",
    "start": "948320",
    "end": "951040"
  },
  {
    "text": "shutting down the prometheus",
    "start": "951040",
    "end": "952720"
  },
  {
    "text": "we just flush this chunk which is being",
    "start": "952720",
    "end": "955519"
  },
  {
    "text": "appended to",
    "start": "955519",
    "end": "956720"
  },
  {
    "text": "to the disk along with its labels and",
    "start": "956720",
    "end": "959759"
  },
  {
    "text": "values which",
    "start": "959759",
    "end": "960560"
  },
  {
    "text": "are part of the series uh yep i'm not",
    "start": "960560",
    "end": "963120"
  },
  {
    "text": "going in detail about the",
    "start": "963120",
    "end": "964800"
  },
  {
    "text": "prometheus but if label values are part",
    "start": "964800",
    "end": "967120"
  },
  {
    "text": "of memory series",
    "start": "967120",
    "end": "969519"
  },
  {
    "text": "so at this point you know what are the",
    "start": "969519",
    "end": "972320"
  },
  {
    "text": "old chunks",
    "start": "972320",
    "end": "973759"
  },
  {
    "text": "and you don't need to go through the",
    "start": "973759",
    "end": "975440"
  },
  {
    "text": "right ahead log",
    "start": "975440",
    "end": "977519"
  },
  {
    "text": "because you already know what are the",
    "start": "977519",
    "end": "979600"
  },
  {
    "text": "samples in the active chunk because we",
    "start": "979600",
    "end": "981759"
  },
  {
    "text": "just flushed it during shutdown",
    "start": "981759",
    "end": "985279"
  },
  {
    "start": "984000",
    "end": "984000"
  },
  {
    "text": "so the replay with this snapshot in just",
    "start": "985600",
    "end": "988800"
  },
  {
    "text": "consists of",
    "start": "988800",
    "end": "989920"
  },
  {
    "text": "going through this memory map chunks and",
    "start": "989920",
    "end": "992160"
  },
  {
    "text": "the snapshot",
    "start": "992160",
    "end": "993360"
  },
  {
    "text": "and you don't need to go to the right",
    "start": "993360",
    "end": "994880"
  },
  {
    "text": "ahead log so i mentioned",
    "start": "994880",
    "end": "997279"
  },
  {
    "text": "recreating the compressed chunk is one",
    "start": "997279",
    "end": "999440"
  },
  {
    "text": "of the cpu intensive task",
    "start": "999440",
    "end": "1002000"
  },
  {
    "text": "the another thing which is cpu intensive",
    "start": "1002000",
    "end": "1004560"
  },
  {
    "text": "is decoding the",
    "start": "1004560",
    "end": "1006079"
  },
  {
    "text": "right headlock records from the disk",
    "start": "1006079",
    "end": "1008480"
  },
  {
    "text": "which forms the majority of the right",
    "start": "1008480",
    "end": "1010320"
  },
  {
    "text": "ahead log",
    "start": "1010320",
    "end": "1011279"
  },
  {
    "text": "replay time so with this snapshot",
    "start": "1011279",
    "end": "1014639"
  },
  {
    "text": "in there is no need to go through the",
    "start": "1014639",
    "end": "1018000"
  },
  {
    "text": "right ahead log",
    "start": "1018000",
    "end": "1020880"
  },
  {
    "text": "but when we talk about restart time it's",
    "start": "1021040",
    "end": "1023600"
  },
  {
    "text": "not just about when prometheus is coming",
    "start": "1023600",
    "end": "1025839"
  },
  {
    "text": "up",
    "start": "1025839",
    "end": "1026400"
  },
  {
    "text": "now that we have snapshotting into the",
    "start": "1026400",
    "end": "1028798"
  },
  {
    "text": "picture when shutting down",
    "start": "1028799",
    "end": "1030480"
  },
  {
    "text": "we also need to consider the time that",
    "start": "1030480",
    "end": "1032640"
  },
  {
    "text": "it takes",
    "start": "1032640",
    "end": "1033520"
  },
  {
    "text": "to create this snapshot but surprisingly",
    "start": "1033520",
    "end": "1036480"
  },
  {
    "text": "snapshotting like",
    "start": "1036480",
    "end": "1037600"
  },
  {
    "text": "a million series takes two to three",
    "start": "1037600",
    "end": "1041038"
  },
  {
    "text": "seconds or maybe max five seconds so",
    "start": "1041039",
    "end": "1042959"
  },
  {
    "text": "which is great",
    "start": "1042959",
    "end": "1045120"
  },
  {
    "text": "and the entire turnaround time which is",
    "start": "1045120",
    "end": "1048160"
  },
  {
    "text": "shutting down and start replaying the",
    "start": "1048160",
    "end": "1050880"
  },
  {
    "text": "right headlock and getting the promises",
    "start": "1050880",
    "end": "1052559"
  },
  {
    "text": "back up again",
    "start": "1052559",
    "end": "1053679"
  },
  {
    "text": "is like 5x faster which is like 80",
    "start": "1053679",
    "end": "1055840"
  },
  {
    "text": "reduction in time",
    "start": "1055840",
    "end": "1056960"
  },
  {
    "text": "to give you some realistic numbers when",
    "start": "1056960",
    "end": "1058880"
  },
  {
    "text": "we ran this using from bench and",
    "start": "1058880",
    "end": "1060640"
  },
  {
    "text": "restarted",
    "start": "1060640",
    "end": "1061679"
  },
  {
    "text": "the prometheus server without this",
    "start": "1061679",
    "end": "1064400"
  },
  {
    "text": "snapshotting",
    "start": "1064400",
    "end": "1065520"
  },
  {
    "text": "but with the memory mapping the replay",
    "start": "1065520",
    "end": "1067440"
  },
  {
    "text": "was like two and a half minutes",
    "start": "1067440",
    "end": "1069600"
  },
  {
    "text": "and with the snapshotting in place the",
    "start": "1069600",
    "end": "1073200"
  },
  {
    "text": "the entire turnaround time was uh like",
    "start": "1073200",
    "end": "1076559"
  },
  {
    "text": "less than 30 seconds so it can be little",
    "start": "1076559",
    "end": "1079600"
  },
  {
    "text": "more than",
    "start": "1079600",
    "end": "1080080"
  },
  {
    "text": "5x faster because the test was done",
    "start": "1080080",
    "end": "1083440"
  },
  {
    "text": "before this right ahead lock could grow",
    "start": "1083440",
    "end": "1085760"
  },
  {
    "text": "for entire three hours",
    "start": "1085760",
    "end": "1087600"
  },
  {
    "text": "it was more like for like one hour of",
    "start": "1087600",
    "end": "1090720"
  },
  {
    "text": "one to two hours of right ahead log but",
    "start": "1090720",
    "end": "1093039"
  },
  {
    "text": "if the prometheus was kept",
    "start": "1093039",
    "end": "1094640"
  },
  {
    "text": "learning for longer and then restarted",
    "start": "1094640",
    "end": "1097600"
  },
  {
    "text": "the gains",
    "start": "1097600",
    "end": "1098400"
  },
  {
    "text": "could be more than 5x faster so that is",
    "start": "1098400",
    "end": "1101520"
  },
  {
    "text": "sweet",
    "start": "1101520",
    "end": "1103919"
  },
  {
    "text": "so more about snapshotting yep this is",
    "start": "1107039",
    "end": "1109280"
  },
  {
    "text": "best effort as i already said this is",
    "start": "1109280",
    "end": "1111280"
  },
  {
    "text": "during graceful shutdown",
    "start": "1111280",
    "end": "1113120"
  },
  {
    "text": "and it's not done in regular intervals",
    "start": "1113120",
    "end": "1118080"
  },
  {
    "text": "so if your prometheus happens to crash",
    "start": "1118080",
    "end": "1120160"
  },
  {
    "text": "in between for whatever reason",
    "start": "1120160",
    "end": "1122559"
  },
  {
    "text": "then the restarts will be slow as before",
    "start": "1122559",
    "end": "1125120"
  },
  {
    "text": "and it won't be fast",
    "start": "1125120",
    "end": "1126720"
  },
  {
    "text": "and because we are taking snapshot it's",
    "start": "1126720",
    "end": "1129440"
  },
  {
    "text": "going",
    "start": "1129440",
    "end": "1129919"
  },
  {
    "text": "on the disk it's going to require a",
    "start": "1129919",
    "end": "1132240"
  },
  {
    "text": "little more disk",
    "start": "1132240",
    "end": "1133280"
  },
  {
    "text": "space which you need to take into",
    "start": "1133280",
    "end": "1136080"
  },
  {
    "text": "account when you",
    "start": "1136080",
    "end": "1137039"
  },
  {
    "text": "plan your resource requirements or the",
    "start": "1137039",
    "end": "1140320"
  },
  {
    "text": "retention period",
    "start": "1140320",
    "end": "1143279"
  },
  {
    "text": "so this is a work in progress majority",
    "start": "1145039",
    "end": "1147440"
  },
  {
    "text": "of work is done like the designing and",
    "start": "1147440",
    "end": "1149280"
  },
  {
    "text": "lots of iterations and how it should be",
    "start": "1149280",
    "end": "1151120"
  },
  {
    "text": "done and the format etc",
    "start": "1151120",
    "end": "1153440"
  },
  {
    "text": "so i expect to be done in august",
    "start": "1153440",
    "end": "1156720"
  },
  {
    "text": "or latest by september because i'm going",
    "start": "1156720",
    "end": "1159280"
  },
  {
    "text": "to work on this so i'm giving",
    "start": "1159280",
    "end": "1161200"
  },
  {
    "text": "an idea based on what i think will be",
    "start": "1161200",
    "end": "1163840"
  },
  {
    "text": "done",
    "start": "1163840",
    "end": "1164799"
  },
  {
    "text": "but yep with snapshotting in place",
    "start": "1164799",
    "end": "1168080"
  },
  {
    "text": "the restarts are like 80 fast and there",
    "start": "1168080",
    "end": "1171280"
  },
  {
    "text": "are more exciting things coming in the",
    "start": "1171280",
    "end": "1173280"
  },
  {
    "text": "tsdb",
    "start": "1173280",
    "end": "1174960"
  },
  {
    "text": "these two just scratch the surface of",
    "start": "1174960",
    "end": "1177200"
  },
  {
    "text": "what has done",
    "start": "1177200",
    "end": "1178559"
  },
  {
    "text": "has been done in the tstp and what's",
    "start": "1178559",
    "end": "1180960"
  },
  {
    "text": "coming up",
    "start": "1180960",
    "end": "1182000"
  },
  {
    "text": "but a blog post will be soon out",
    "start": "1182000",
    "end": "1185280"
  },
  {
    "text": "or it will be already out by the time",
    "start": "1185280",
    "end": "1187679"
  },
  {
    "text": "this talk",
    "start": "1187679",
    "end": "1188799"
  },
  {
    "text": "is up in the grafana blog where i talk",
    "start": "1188799",
    "end": "1192000"
  },
  {
    "text": "more about what's more uh coming up",
    "start": "1192000",
    "end": "1195039"
  },
  {
    "text": "in the tsdb space and what you should be",
    "start": "1195039",
    "end": "1197679"
  },
  {
    "text": "looking forward to",
    "start": "1197679",
    "end": "1200000"
  },
  {
    "text": "yep to summarize what we have uh",
    "start": "1200000",
    "end": "1202960"
  },
  {
    "text": "discussed till now",
    "start": "1202960",
    "end": "1204559"
  },
  {
    "text": "in the memory mapping we flush the",
    "start": "1204559",
    "end": "1206799"
  },
  {
    "text": "chunks on the disk",
    "start": "1206799",
    "end": "1208320"
  },
  {
    "text": "and hence we save the memory and in",
    "start": "1208320",
    "end": "1211520"
  },
  {
    "text": "snapshotting because we have just the",
    "start": "1211520",
    "end": "1213679"
  },
  {
    "text": "last chunk that is on the memory which",
    "start": "1213679",
    "end": "1215679"
  },
  {
    "text": "needs to be recreated",
    "start": "1215679",
    "end": "1217280"
  },
  {
    "text": "we just flush it to the disk during",
    "start": "1217280",
    "end": "1218880"
  },
  {
    "text": "shutdown taking a snapshot",
    "start": "1218880",
    "end": "1221039"
  },
  {
    "text": "and we don't need to go through the",
    "start": "1221039",
    "end": "1222799"
  },
  {
    "text": "right head log again and the replay just",
    "start": "1222799",
    "end": "1224799"
  },
  {
    "text": "consists of going through the memory map",
    "start": "1224799",
    "end": "1226880"
  },
  {
    "text": "chunks",
    "start": "1226880",
    "end": "1227600"
  },
  {
    "text": "and the snapshot and that's how we are",
    "start": "1227600",
    "end": "1230320"
  },
  {
    "text": "making the restart faster",
    "start": "1230320",
    "end": "1233760"
  },
  {
    "text": "thank you that's all and by the way this",
    "start": "1233760",
    "end": "1236240"
  },
  {
    "text": "is my twitter handle",
    "start": "1236240",
    "end": "1237600"
  },
  {
    "text": "if you have any questions or if you have",
    "start": "1237600",
    "end": "1240240"
  },
  {
    "text": "if you are watching this",
    "start": "1240240",
    "end": "1241679"
  },
  {
    "text": "talk after it's aired you can",
    "start": "1241679",
    "end": "1245520"
  },
  {
    "text": "feel free to reach out to me for any",
    "start": "1245520",
    "end": "1247280"
  },
  {
    "text": "questions that you have",
    "start": "1247280",
    "end": "1249200"
  },
  {
    "text": "thank you",
    "start": "1249200",
    "end": "1253200"
  }
]
[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "hello everyone so as Kelsey already",
    "start": "0",
    "end": "2510"
  },
  {
    "text": "introduced me my name is Sahil dua and",
    "start": "2510",
    "end": "5359"
  },
  {
    "text": "today I'm going to talk about how we",
    "start": "5359",
    "end": "9120"
  },
  {
    "text": "build a production pipeline to deploy",
    "start": "9120",
    "end": "12480"
  },
  {
    "text": "our deep learning models in production",
    "start": "12480",
    "end": "15509"
  },
  {
    "text": "of course using humanities I hope I",
    "start": "15509",
    "end": "18630"
  },
  {
    "text": "covered all the buzzwords ok so I hope",
    "start": "18630",
    "end": "23220"
  },
  {
    "text": "at the end of this talk you will feel",
    "start": "23220",
    "end": "25800"
  },
  {
    "text": "more confident in putting your models to",
    "start": "25800",
    "end": "29429"
  },
  {
    "text": "production serving traffic serving",
    "start": "29429",
    "end": "31619"
  },
  {
    "text": "predictions at whatever scale you work",
    "start": "31619",
    "end": "34050"
  },
  {
    "text": "on so let's start before I start let me",
    "start": "34050",
    "end": "40710"
  },
  {
    "start": "38000",
    "end": "87000"
  },
  {
    "text": "give a bit of intro about myself I work",
    "start": "40710",
    "end": "44940"
  },
  {
    "text": "at booking as a software developer",
    "start": "44940",
    "end": "47960"
  },
  {
    "text": "previously I've been involved in",
    "start": "47960",
    "end": "50160"
  },
  {
    "text": "building the deep learning",
    "start": "50160",
    "end": "51120"
  },
  {
    "text": "infrastructure there to support our deep",
    "start": "51120",
    "end": "54480"
  },
  {
    "text": "learning models and that's what I'm",
    "start": "54480",
    "end": "56399"
  },
  {
    "text": "going to be talking about today besides",
    "start": "56399",
    "end": "60390"
  },
  {
    "text": "that I am a big open source fan I",
    "start": "60390",
    "end": "62820"
  },
  {
    "text": "contribute to a bunch of different",
    "start": "62820",
    "end": "65158"
  },
  {
    "text": "projects and my most recent biggest",
    "start": "65159",
    "end": "67799"
  },
  {
    "text": "contribution has been to the git project",
    "start": "67799",
    "end": "69689"
  },
  {
    "text": "itself which I'm really excited about",
    "start": "69689",
    "end": "71310"
  },
  {
    "text": "and besides that I have a frequent tech",
    "start": "71310",
    "end": "75420"
  },
  {
    "text": "speaker I normally talk about topics",
    "start": "75420",
    "end": "77250"
  },
  {
    "text": "like a be testing data analysis deep",
    "start": "77250",
    "end": "80520"
  },
  {
    "text": "learning containers and a bunch of stuff",
    "start": "80520",
    "end": "82799"
  },
  {
    "text": "around that so let's see what I'm going",
    "start": "82799",
    "end": "87990"
  },
  {
    "start": "87000",
    "end": "112000"
  },
  {
    "text": "to cover today I will start with",
    "start": "87990",
    "end": "90470"
  },
  {
    "text": "mentioning some of the applications of",
    "start": "90470",
    "end": "92640"
  },
  {
    "text": "deep learning some of the things why we",
    "start": "92640",
    "end": "95670"
  },
  {
    "text": "felt that this is an important problem",
    "start": "95670",
    "end": "97590"
  },
  {
    "text": "to solve then we'll see how we train our",
    "start": "97590",
    "end": "101850"
  },
  {
    "text": "models and then we'll see how we use",
    "start": "101850",
    "end": "105299"
  },
  {
    "text": "those training models to serve",
    "start": "105299",
    "end": "107520"
  },
  {
    "text": "predictions how we deploy them so let's",
    "start": "107520",
    "end": "112320"
  },
  {
    "start": "112000",
    "end": "156000"
  },
  {
    "text": "start let's start with the deep learning",
    "start": "112320",
    "end": "114299"
  },
  {
    "text": "applications and before I go there it's",
    "start": "114299",
    "end": "116939"
  },
  {
    "text": "really important to understand what",
    "start": "116939",
    "end": "118530"
  },
  {
    "text": "scale I'm talking about here so at",
    "start": "118530",
    "end": "122909"
  },
  {
    "text": "booking.com we have more than 1.5",
    "start": "122909",
    "end": "125460"
  },
  {
    "text": "million room nights booked every 24",
    "start": "125460",
    "end": "127710"
  },
  {
    "text": "hours and these bookings come from more",
    "start": "127710",
    "end": "131310"
  },
  {
    "text": "than 1.4 million properties that we have",
    "start": "131310",
    "end": "133920"
  },
  {
    "text": "220 countries so let me make one thing",
    "start": "133920",
    "end": "137760"
  },
  {
    "text": "clear I'm not here to brag about these",
    "start": "137760",
    "end": "139800"
  },
  {
    "text": "numbers here the point I'm making here",
    "start": "139800",
    "end": "141930"
  },
  {
    "text": "is that at this huge scale we have",
    "start": "141930",
    "end": "146040"
  },
  {
    "text": "access to a large amount of data about",
    "start": "146040",
    "end": "148230"
  },
  {
    "text": "our users and we can use that to improve",
    "start": "148230",
    "end": "151410"
  },
  {
    "text": "their experience on our product so let's",
    "start": "151410",
    "end": "155610"
  },
  {
    "text": "see how we do that the first application",
    "start": "155610",
    "end": "158190"
  },
  {
    "text": "of deep learning that we saw at booking",
    "start": "158190",
    "end": "160050"
  },
  {
    "text": "was image tagging trying to look at a",
    "start": "160050",
    "end": "164400"
  },
  {
    "text": "image",
    "start": "164400",
    "end": "165090"
  },
  {
    "text": "and identifying what objects are there",
    "start": "165090",
    "end": "168510"
  },
  {
    "text": "is a really important problem for us",
    "start": "168510",
    "end": "170610"
  },
  {
    "text": "because then we can use that information",
    "start": "170610",
    "end": "172230"
  },
  {
    "text": "to have extra meta information about",
    "start": "172230",
    "end": "175500"
  },
  {
    "text": "properties that we have on booking.com",
    "start": "175500",
    "end": "179420"
  },
  {
    "text": "another problem that we are solving is",
    "start": "179630",
    "end": "182070"
  },
  {
    "text": "translations we are trying to build",
    "start": "182070",
    "end": "185070"
  },
  {
    "text": "models to translate the text that we",
    "start": "185070",
    "end": "187500"
  },
  {
    "text": "have from one language to another",
    "start": "187500",
    "end": "189500"
  },
  {
    "text": "without any human intervention and this",
    "start": "189500",
    "end": "192959"
  },
  {
    "text": "is a data that's really specific to our",
    "start": "192959",
    "end": "194970"
  },
  {
    "text": "travel domain and it's not like publicly",
    "start": "194970",
    "end": "197760"
  },
  {
    "text": "available translations can't do that but",
    "start": "197760",
    "end": "199950"
  },
  {
    "text": "we're trying to be really",
    "start": "199950",
    "end": "200820"
  },
  {
    "text": "domain-specific here and trying to",
    "start": "200820",
    "end": "202530"
  },
  {
    "text": "translate our own stuff which is later",
    "start": "202530",
    "end": "205019"
  },
  {
    "text": "to travel and we bid quite a lot on",
    "start": "205019",
    "end": "210269"
  },
  {
    "text": "advertisements on various search engines",
    "start": "210269",
    "end": "212430"
  },
  {
    "text": "and we want to be making sure that we",
    "start": "212430",
    "end": "216959"
  },
  {
    "text": "spend the right amount of money we built",
    "start": "216959",
    "end": "219360"
  },
  {
    "text": "the right amount of money on the right",
    "start": "219360",
    "end": "220769"
  },
  {
    "text": "kind of keywords so that we have maximum",
    "start": "220769",
    "end": "223530"
  },
  {
    "text": "return on investment so we have our",
    "start": "223530",
    "end": "226230"
  },
  {
    "text": "models in place which using which we",
    "start": "226230",
    "end": "228660"
  },
  {
    "text": "predict how much we should be bidding on",
    "start": "228660",
    "end": "231390"
  },
  {
    "text": "what kind of keywords and when we should",
    "start": "231390",
    "end": "235019"
  },
  {
    "text": "be doing that and we have a bunch of",
    "start": "235019",
    "end": "238019"
  },
  {
    "text": "other applications of deep learning",
    "start": "238019",
    "end": "240090"
  },
  {
    "text": "where we deploy our models deploy our",
    "start": "240090",
    "end": "242280"
  },
  {
    "text": "resources to solve some complicated",
    "start": "242280",
    "end": "244560"
  },
  {
    "text": "problems now let me talk about one",
    "start": "244560",
    "end": "250620"
  },
  {
    "start": "249000",
    "end": "387000"
  },
  {
    "text": "application in detail so the image",
    "start": "250620",
    "end": "252420"
  },
  {
    "text": "tagging what is the problem here so this",
    "start": "252420",
    "end": "255690"
  },
  {
    "text": "is just one question that we want to",
    "start": "255690",
    "end": "257010"
  },
  {
    "text": "answer the question is what do you see",
    "start": "257010",
    "end": "259979"
  },
  {
    "text": "in this image now this is a really",
    "start": "259979",
    "end": "263760"
  },
  {
    "text": "simple problem if we ask any one of you",
    "start": "263760",
    "end": "266640"
  },
  {
    "text": "you can easily see you",
    "start": "266640",
    "end": "267780"
  },
  {
    "text": "they're in this image you can identify",
    "start": "267780",
    "end": "268980"
  },
  {
    "text": "the objects but it's not really easy for",
    "start": "268980",
    "end": "272490"
  },
  {
    "text": "a machine to be able to tell what's",
    "start": "272490",
    "end": "274380"
  },
  {
    "text": "there in this image and what makes this",
    "start": "274380",
    "end": "278280"
  },
  {
    "text": "problem even harder is that the context",
    "start": "278280",
    "end": "280950"
  },
  {
    "text": "matters a lot let's take an example so",
    "start": "280950",
    "end": "285450"
  },
  {
    "text": "if we pass this image through some",
    "start": "285450",
    "end": "287280"
  },
  {
    "text": "publicly available networks which detect",
    "start": "287280",
    "end": "290190"
  },
  {
    "text": "the objects in the images these are the",
    "start": "290190",
    "end": "293550"
  },
  {
    "text": "results that we get it tells us that we",
    "start": "293550",
    "end": "297270"
  },
  {
    "text": "have oceanfront nature beach house it's",
    "start": "297270",
    "end": "302220"
  },
  {
    "text": "a building okay but do we really care",
    "start": "302220",
    "end": "303900"
  },
  {
    "text": "about that these are not the things that",
    "start": "303900",
    "end": "306270"
  },
  {
    "text": "we are concerned about at booking.com",
    "start": "306270",
    "end": "309350"
  },
  {
    "text": "however these are the things that we",
    "start": "309350",
    "end": "311520"
  },
  {
    "text": "care about we care about if there is a",
    "start": "311520",
    "end": "314669"
  },
  {
    "text": "sea view from this room from this",
    "start": "314669",
    "end": "317040"
  },
  {
    "text": "property we care about if there is a",
    "start": "317040",
    "end": "319560"
  },
  {
    "text": "balcony Terrace associated with this",
    "start": "319560",
    "end": "322140"
  },
  {
    "text": "property if this photo has a bed object",
    "start": "322140",
    "end": "327750"
  },
  {
    "text": "any object like so far chair or if this",
    "start": "327750",
    "end": "330570"
  },
  {
    "text": "is a picture of inside view of a room",
    "start": "330570",
    "end": "333680"
  },
  {
    "text": "and here's one more interesting thing",
    "start": "333680",
    "end": "338550"
  },
  {
    "text": "about this problem there's going to be",
    "start": "338550",
    "end": "340560"
  },
  {
    "text": "hierarchy of the tags that we are",
    "start": "340560",
    "end": "342840"
  },
  {
    "text": "talking about these labels there is",
    "start": "342840",
    "end": "344460"
  },
  {
    "text": "going to be hierarchy of these labels",
    "start": "344460",
    "end": "345900"
  },
  {
    "text": "here for example if you see that there",
    "start": "345900",
    "end": "349260"
  },
  {
    "text": "isn't there is a bed in this image you",
    "start": "349260",
    "end": "352830"
  },
  {
    "text": "can be sure that this is going to be an",
    "start": "352830",
    "end": "354630"
  },
  {
    "text": "inside view of the room unless you are",
    "start": "354630",
    "end": "359580"
  },
  {
    "text": "in such a room where there is no room",
    "start": "359580",
    "end": "361050"
  },
  {
    "text": "just a bed so yeah once we can identify",
    "start": "361050",
    "end": "368130"
  },
  {
    "text": "the objects once we know what's there in",
    "start": "368130",
    "end": "370320"
  },
  {
    "text": "an image we can map this information",
    "start": "370320",
    "end": "372510"
  },
  {
    "text": "back to the properties that we have and",
    "start": "372510",
    "end": "375020"
  },
  {
    "text": "use this information to help our",
    "start": "375020",
    "end": "378330"
  },
  {
    "text": "customers in finding the relevant",
    "start": "378330",
    "end": "380430"
  },
  {
    "text": "properties that they are looking for",
    "start": "380430",
    "end": "381979"
  },
  {
    "text": "easily and quickly so now that we have",
    "start": "381979",
    "end": "387780"
  },
  {
    "text": "seen one application of deep learning",
    "start": "387780",
    "end": "389370"
  },
  {
    "text": "what's so special or this what's so",
    "start": "389370",
    "end": "391590"
  },
  {
    "text": "special about the workload that we have",
    "start": "391590",
    "end": "393450"
  },
  {
    "text": "to run to train these models or to",
    "start": "393450",
    "end": "396450"
  },
  {
    "text": "deploy these models let's talk about",
    "start": "396450",
    "end": "398550"
  },
  {
    "text": "that like why do we really need",
    "start": "398550",
    "end": "400200"
  },
  {
    "text": "something special some",
    "start": "400200",
    "end": "401620"
  },
  {
    "text": "different platform or a pipeline to work",
    "start": "401620",
    "end": "405790"
  },
  {
    "text": "on these kind of problems so the first",
    "start": "405790",
    "end": "409300"
  },
  {
    "text": "thing that's different is the deep",
    "start": "409300",
    "end": "412240"
  },
  {
    "text": "learning workload is highly",
    "start": "412240",
    "end": "413979"
  },
  {
    "text": "computationally intensive which means",
    "start": "413979",
    "end": "417430"
  },
  {
    "text": "it's possible that to run the model to",
    "start": "417430",
    "end": "420520"
  },
  {
    "text": "get one prediction out of it you might",
    "start": "420520",
    "end": "422560"
  },
  {
    "text": "have to do thousands or even sometimes",
    "start": "422560",
    "end": "425050"
  },
  {
    "text": "millions of mathematical calculations",
    "start": "425050",
    "end": "429150"
  },
  {
    "text": "another thing is most of the times the",
    "start": "430260",
    "end": "434139"
  },
  {
    "text": "algorithms that we use to train these",
    "start": "434139",
    "end": "436300"
  },
  {
    "text": "models are not easy to paralyze and the",
    "start": "436300",
    "end": "441370"
  },
  {
    "text": "third thing is this huge amount of data",
    "start": "441370",
    "end": "443919"
  },
  {
    "text": "involved the data goes from tens to",
    "start": "443919",
    "end": "446979"
  },
  {
    "text": "hundreds of gigs and sometimes the data",
    "start": "446979",
    "end": "448600"
  },
  {
    "text": "is in terabytes as well so we have to",
    "start": "448600",
    "end": "451630"
  },
  {
    "text": "have some different kind of platform to",
    "start": "451630",
    "end": "454360"
  },
  {
    "text": "run these kind of workloads to run the",
    "start": "454360",
    "end": "456610"
  },
  {
    "text": "training to run the deployment so now",
    "start": "456610",
    "end": "460389"
  },
  {
    "text": "why do we choose q1 it is for that there",
    "start": "460389",
    "end": "464260"
  },
  {
    "text": "are a few reasons for that the few",
    "start": "464260",
    "end": "465880"
  },
  {
    "text": "things cracked six that we identified",
    "start": "465880",
    "end": "467849"
  },
  {
    "text": "which make your when it is a viable",
    "start": "467849",
    "end": "470050"
  },
  {
    "text": "solution for this problem so first of",
    "start": "470050",
    "end": "474220"
  },
  {
    "text": "all isolation there is a namespace",
    "start": "474220",
    "end": "477039"
  },
  {
    "text": "isolation which human it is provides",
    "start": "477039",
    "end": "479020"
  },
  {
    "text": "which makes sure that the resources are",
    "start": "479020",
    "end": "482080"
  },
  {
    "text": "not shared between the processes and",
    "start": "482080",
    "end": "484050"
  },
  {
    "text": "those processes are not fighting not",
    "start": "484050",
    "end": "487180"
  },
  {
    "text": "competing against each other for those",
    "start": "487180",
    "end": "489220"
  },
  {
    "text": "resources and second is elasticity",
    "start": "489220",
    "end": "493590"
  },
  {
    "text": "curators provides the ability to easily",
    "start": "493590",
    "end": "496960"
  },
  {
    "text": "scale up scale down our applications and",
    "start": "496960",
    "end": "499599"
  },
  {
    "text": "also lets us run as many containers as",
    "start": "499599",
    "end": "502210"
  },
  {
    "text": "we want as as far as we have the",
    "start": "502210",
    "end": "504729"
  },
  {
    "text": "hardware and this leads to a better",
    "start": "504729",
    "end": "507310"
  },
  {
    "text": "utilization of",
    "start": "507310",
    "end": "508510"
  },
  {
    "text": "the existing resources that we have and",
    "start": "508510",
    "end": "512219"
  },
  {
    "text": "the third thing is the flexibility that",
    "start": "512219",
    "end": "514900"
  },
  {
    "text": "we get it provides us a easy quick way",
    "start": "514900",
    "end": "519279"
  },
  {
    "text": "to try out new things try out a library",
    "start": "519279",
    "end": "521950"
  },
  {
    "text": "try out a new framework in our",
    "start": "521950",
    "end": "524020"
  },
  {
    "text": "production environment and that leads to",
    "start": "524020",
    "end": "526360"
  },
  {
    "text": "a faster velocity of innovation for us",
    "start": "526360",
    "end": "530430"
  },
  {
    "text": "now let's see how we do our training",
    "start": "532800",
    "end": "536080"
  },
  {
    "start": "533000",
    "end": "642000"
  },
  {
    "text": "with kubernetes so the first thing to",
    "start": "536080",
    "end": "539260"
  },
  {
    "text": "note here is we have our base images",
    "start": "539260",
    "end": "541750"
  },
  {
    "text": "with all the machine learning frameworks",
    "start": "541750",
    "end": "543790"
  },
  {
    "text": "that we think are going to be used and",
    "start": "543790",
    "end": "545890"
  },
  {
    "text": "these are normally tensorflow",
    "start": "545890",
    "end": "548560"
  },
  {
    "text": "torch waffle rabbit and a bunch of other",
    "start": "548560",
    "end": "550900"
  },
  {
    "text": "frameworks that people are using that",
    "start": "550900",
    "end": "553180"
  },
  {
    "text": "data scientists are using to write their",
    "start": "553180",
    "end": "554710"
  },
  {
    "text": "models now interesting thing here is",
    "start": "554710",
    "end": "558460"
  },
  {
    "text": "that we don't put any training code in",
    "start": "558460",
    "end": "562090"
  },
  {
    "text": "the image so this makes it easy for us",
    "start": "562090",
    "end": "567430"
  },
  {
    "text": "to easily eye trait or while we are",
    "start": "567430",
    "end": "570040"
  },
  {
    "text": "developing what the means is we don't",
    "start": "570040",
    "end": "572410"
  },
  {
    "text": "have to go through a workflow of making",
    "start": "572410",
    "end": "574780"
  },
  {
    "text": "a change to their training code building",
    "start": "574780",
    "end": "577030"
  },
  {
    "text": "an image putting it into the registry",
    "start": "577030",
    "end": "579450"
  },
  {
    "text": "downloading it and running a container",
    "start": "579450",
    "end": "581610"
  },
  {
    "text": "all we have to do at every training step",
    "start": "581610",
    "end": "584980"
  },
  {
    "text": "is just run that container and tell it",
    "start": "584980",
    "end": "588880"
  },
  {
    "text": "where the code should be fetched from so",
    "start": "588880",
    "end": "592750"
  },
  {
    "text": "the helps us in iterating really quickly",
    "start": "592750",
    "end": "595150"
  },
  {
    "text": "and to run the training we need a lot of",
    "start": "595150",
    "end": "599380"
  },
  {
    "text": "data we need to have access to the data",
    "start": "599380",
    "end": "601480"
  },
  {
    "text": "so how do we get data to these",
    "start": "601480",
    "end": "603040"
  },
  {
    "text": "containers that we are running what we",
    "start": "603040",
    "end": "605440"
  },
  {
    "text": "do is there it really depends on what",
    "start": "605440",
    "end": "608140"
  },
  {
    "text": "framework the model is using for example",
    "start": "608140",
    "end": "609790"
  },
  {
    "text": "some of the frameworks know how to talk",
    "start": "609790",
    "end": "612010"
  },
  {
    "text": "to her dupe in those cases for example",
    "start": "612010",
    "end": "614410"
  },
  {
    "text": "tensorflow in case of transfer flow we",
    "start": "614410",
    "end": "616780"
  },
  {
    "text": "can steam the data directly from Hadoop",
    "start": "616780",
    "end": "619060"
  },
  {
    "text": "and in the case of a framework when it",
    "start": "619060",
    "end": "622990"
  },
  {
    "text": "doesn't know how to talk to Hadoop we",
    "start": "622990",
    "end": "626410"
  },
  {
    "text": "can get a persistent volume associated",
    "start": "626410",
    "end": "629470"
  },
  {
    "text": "with the pod and get the data downloaded",
    "start": "629470",
    "end": "633190"
  },
  {
    "text": "over there and then run the training as",
    "start": "633190",
    "end": "634870"
  },
  {
    "text": "if the data is available with the",
    "start": "634870",
    "end": "636310"
  },
  {
    "text": "container locally so let's look at this",
    "start": "636310",
    "end": "643270"
  },
  {
    "start": "642000",
    "end": "723000"
  },
  {
    "text": "process of training now from a visual",
    "start": "643270",
    "end": "645790"
  },
  {
    "text": "point of view so we have a training pod",
    "start": "645790",
    "end": "648780"
  },
  {
    "text": "which knows where the code is to be",
    "start": "648780",
    "end": "652510"
  },
  {
    "text": "fetched from where the code is to be",
    "start": "652510",
    "end": "654280"
  },
  {
    "text": "fetched and it takes the code the code",
    "start": "654280",
    "end": "658030"
  },
  {
    "text": "has some training script evaluation",
    "start": "658030",
    "end": "660070"
  },
  {
    "text": "script and the next step now is to get",
    "start": "660070",
    "end": "664060"
  },
  {
    "text": "the data and as I already mentioned",
    "start": "664060",
    "end": "666010"
  },
  {
    "text": "can be either using directly streaming",
    "start": "666010",
    "end": "668110"
  },
  {
    "text": "from Hadoop storage or it can be",
    "start": "668110",
    "end": "670500"
  },
  {
    "text": "downloaded into persistent volume and",
    "start": "670500",
    "end": "672730"
  },
  {
    "text": "then trying to use it as locally",
    "start": "672730",
    "end": "674980"
  },
  {
    "text": "available data so once we get the data",
    "start": "674980",
    "end": "679090"
  },
  {
    "text": "now we'll start running the training and",
    "start": "679090",
    "end": "681730"
  },
  {
    "text": "while the training is running we want to",
    "start": "681730",
    "end": "683710"
  },
  {
    "text": "be able to look at the progress of it",
    "start": "683710",
    "end": "686440"
  },
  {
    "text": "like look at what's going on inside that",
    "start": "686440",
    "end": "688330"
  },
  {
    "text": "data scientists should be able to look",
    "start": "688330",
    "end": "690610"
  },
  {
    "text": "at the progress should be able to map",
    "start": "690610",
    "end": "692380"
  },
  {
    "text": "back use tensor board to monitor the",
    "start": "692380",
    "end": "694960"
  },
  {
    "text": "performance monitor the training process",
    "start": "694960",
    "end": "697300"
  },
  {
    "text": "so we stream the logs back to Hadoop",
    "start": "697300",
    "end": "699940"
  },
  {
    "text": "storage and once the training is done we",
    "start": "699940",
    "end": "705400"
  },
  {
    "text": "want to be able to store this model",
    "start": "705400",
    "end": "706780"
  },
  {
    "text": "somewhere so that we can use that later",
    "start": "706780",
    "end": "708400"
  },
  {
    "text": "to deploy it to get predictions out of",
    "start": "708400",
    "end": "711130"
  },
  {
    "text": "it so we take the model put it back to",
    "start": "711130",
    "end": "715810"
  },
  {
    "text": "the Hadoop storage and we are done with",
    "start": "715810",
    "end": "718180"
  },
  {
    "text": "the training so once we have trained our",
    "start": "718180",
    "end": "724480"
  },
  {
    "start": "723000",
    "end": "735000"
  },
  {
    "text": "model the next step is to take this",
    "start": "724480",
    "end": "726580"
  },
  {
    "text": "model and deploy it so that we can serve",
    "start": "726580",
    "end": "730060"
  },
  {
    "text": "predictions to the actual clients now",
    "start": "730060",
    "end": "733780"
  },
  {
    "text": "let's see what we want here we want to",
    "start": "733780",
    "end": "736780"
  },
  {
    "start": "735000",
    "end": "770000"
  },
  {
    "text": "have a model we just train running",
    "start": "736780",
    "end": "739990"
  },
  {
    "text": "somewhere in isolation and being able to",
    "start": "739990",
    "end": "742900"
  },
  {
    "text": "serve traffic using REST API and",
    "start": "742900",
    "end": "749160"
  },
  {
    "text": "similarly we want to have multiple",
    "start": "749160",
    "end": "751210"
  },
  {
    "text": "models being able to serve traffic in a",
    "start": "751210",
    "end": "754900"
  },
  {
    "text": "similar way in their isolation isolation",
    "start": "754900",
    "end": "757210"
  },
  {
    "text": "environments at the same time we want to",
    "start": "757210",
    "end": "761740"
  },
  {
    "text": "scale these models scale the",
    "start": "761740",
    "end": "764290"
  },
  {
    "text": "applications that are running these",
    "start": "764290",
    "end": "765430"
  },
  {
    "text": "models independently so let's see how we",
    "start": "765430",
    "end": "769990"
  },
  {
    "text": "do that so the first thing we have here",
    "start": "769990",
    "end": "774280"
  },
  {
    "start": "770000",
    "end": "835000"
  },
  {
    "text": "is we have the stateless application",
    "start": "774280",
    "end": "776530"
  },
  {
    "text": "code with some common code which is",
    "start": "776530",
    "end": "778450"
  },
  {
    "text": "required to kick the server running we",
    "start": "778450",
    "end": "783520"
  },
  {
    "text": "containerize it and this is really",
    "start": "783520",
    "end": "786220"
  },
  {
    "text": "important we don't have any model",
    "start": "786220",
    "end": "788140"
  },
  {
    "text": "embedded in the image so now this again",
    "start": "788140",
    "end": "790750"
  },
  {
    "text": "helps us in two things one is making",
    "start": "790750",
    "end": "793480"
  },
  {
    "text": "sure that the size of the image is",
    "start": "793480",
    "end": "795130"
  },
  {
    "text": "really small because the models can go",
    "start": "795130",
    "end": "796930"
  },
  {
    "text": "up to a few gigabytes sometimes",
    "start": "796930",
    "end": "799050"
  },
  {
    "text": "so this helps us in making sure the",
    "start": "799050",
    "end": "800640"
  },
  {
    "text": "images are always small and the time to",
    "start": "800640",
    "end": "803460"
  },
  {
    "text": "run the container is really small and",
    "start": "803460",
    "end": "805520"
  },
  {
    "text": "the second thing is it makes the images",
    "start": "805520",
    "end": "808470"
  },
  {
    "text": "that we have reusable we don't have to",
    "start": "808470",
    "end": "812280"
  },
  {
    "text": "build a new image every time we train a",
    "start": "812280",
    "end": "813930"
  },
  {
    "text": "model we just have to kick the container",
    "start": "813930",
    "end": "816420"
  },
  {
    "text": "with the image that we have and make it",
    "start": "816420",
    "end": "819060"
  },
  {
    "text": "point to a particular model that we just",
    "start": "819060",
    "end": "821400"
  },
  {
    "text": "trained and then we expose the rest API",
    "start": "821400",
    "end": "829320"
  },
  {
    "text": "to get predictions out of it now again",
    "start": "829320",
    "end": "833880"
  },
  {
    "text": "let's look at this from a visual point",
    "start": "833880",
    "end": "835650"
  },
  {
    "start": "835000",
    "end": "882000"
  },
  {
    "text": "of view we have our serving pod which we",
    "start": "835650",
    "end": "838950"
  },
  {
    "text": "are running in our curators cluster it",
    "start": "838950",
    "end": "841710"
  },
  {
    "text": "has some basic code to just get this",
    "start": "841710",
    "end": "844380"
  },
  {
    "text": "thing started to be able to get the",
    "start": "844380",
    "end": "847350"
  },
  {
    "text": "model and do all the stuff and now we",
    "start": "847350",
    "end": "849810"
  },
  {
    "text": "know that we exported the model to",
    "start": "849810",
    "end": "851370"
  },
  {
    "text": "Hadoop storage we want to carry it back",
    "start": "851370",
    "end": "853200"
  },
  {
    "text": "now so that we can run the training we",
    "start": "853200",
    "end": "858000"
  },
  {
    "text": "get the model back and we load it into",
    "start": "858000",
    "end": "861240"
  },
  {
    "text": "the memory once we have the model loaded",
    "start": "861240",
    "end": "865410"
  },
  {
    "text": "into the memory we want to expose that",
    "start": "865410",
    "end": "867690"
  },
  {
    "text": "as a REST API to the client so that",
    "start": "867690",
    "end": "870540"
  },
  {
    "text": "clients can send a get request with all",
    "start": "870540",
    "end": "872370"
  },
  {
    "text": "the input features that they have that",
    "start": "872370",
    "end": "874020"
  },
  {
    "text": "the model requires and send the",
    "start": "874020",
    "end": "876780"
  },
  {
    "text": "predictions back in the response now",
    "start": "876780",
    "end": "881640"
  },
  {
    "text": "overall this is how it looks like get",
    "start": "881640",
    "end": "885060"
  },
  {
    "start": "882000",
    "end": "934000"
  },
  {
    "text": "the model from Hadoop storage loaded",
    "start": "885060",
    "end": "888000"
  },
  {
    "text": "into memory serve predictions using a",
    "start": "888000",
    "end": "891120"
  },
  {
    "text": "REST API to the clients and in reality",
    "start": "891120",
    "end": "896910"
  },
  {
    "text": "this is all looks like it's not always",
    "start": "896910",
    "end": "899370"
  },
  {
    "text": "just one part there are multiple pods",
    "start": "899370",
    "end": "901500"
  },
  {
    "text": "running for one application running the",
    "start": "901500",
    "end": "903270"
  },
  {
    "text": "same model doing the same process that I",
    "start": "903270",
    "end": "904980"
  },
  {
    "text": "just mentioned and serving traffic to a",
    "start": "904980",
    "end": "908100"
  },
  {
    "text": "large number of clients using the same",
    "start": "908100",
    "end": "910560"
  },
  {
    "text": "mechanism that I just mentioned and",
    "start": "910560",
    "end": "913790"
  },
  {
    "text": "using this kind of setup we are able to",
    "start": "913790",
    "end": "917130"
  },
  {
    "text": "scale up or scale down different models",
    "start": "917130",
    "end": "921020"
  },
  {
    "text": "according to their requirement cording",
    "start": "921020",
    "end": "923070"
  },
  {
    "text": "to the demand according to how many",
    "start": "923070",
    "end": "924540"
  },
  {
    "text": "clients who want to connect how many",
    "start": "924540",
    "end": "926340"
  },
  {
    "text": "clients want those kind of",
    "start": "926340",
    "end": "928530"
  },
  {
    "text": "recommendations those kind of",
    "start": "928530",
    "end": "929940"
  },
  {
    "text": "predictions",
    "start": "929940",
    "end": "932360"
  },
  {
    "start": "934000",
    "end": "977000"
  },
  {
    "text": "now what do we need to do to create a",
    "start": "934190",
    "end": "938010"
  },
  {
    "text": "deployment create a new model deployment",
    "start": "938010",
    "end": "940910"
  },
  {
    "text": "we create a deployment deployment object",
    "start": "940910",
    "end": "944670"
  },
  {
    "text": "here which is going to specify the pods",
    "start": "944670",
    "end": "948120"
  },
  {
    "text": "configuration based on where it needs to",
    "start": "948120",
    "end": "950640"
  },
  {
    "text": "get the data from where it needs to get",
    "start": "950640",
    "end": "952260"
  },
  {
    "text": "the model from and how it needs to get",
    "start": "952260",
    "end": "955230"
  },
  {
    "text": "started once we have the deployment",
    "start": "955230",
    "end": "957660"
  },
  {
    "text": "running we want to create a new service",
    "start": "957660",
    "end": "959670"
  },
  {
    "text": "so that we can expose this these pods",
    "start": "959670",
    "end": "962580"
  },
  {
    "text": "and wait for these parts to to pass the",
    "start": "962580",
    "end": "969000"
  },
  {
    "text": "lightness and airiness props before they",
    "start": "969000",
    "end": "971220"
  },
  {
    "text": "can start serving traffic so let me",
    "start": "971220",
    "end": "976230"
  },
  {
    "text": "quickly try to summarize what we just",
    "start": "976230",
    "end": "978360"
  },
  {
    "start": "977000",
    "end": "1045000"
  },
  {
    "text": "talked about so I started with",
    "start": "978360",
    "end": "980640"
  },
  {
    "text": "applications of deep learning the",
    "start": "980640",
    "end": "983279"
  },
  {
    "text": "applications like image tagging",
    "start": "983279",
    "end": "984930"
  },
  {
    "text": "translations and ads bidding how we",
    "start": "984930",
    "end": "987450"
  },
  {
    "text": "solve these problems or why these",
    "start": "987450",
    "end": "989130"
  },
  {
    "text": "problems are really important for us",
    "start": "989130",
    "end": "990800"
  },
  {
    "text": "then we saw how it rained on models",
    "start": "990800",
    "end": "994670"
  },
  {
    "text": "spawn a new training pod get the code",
    "start": "994670",
    "end": "997589"
  },
  {
    "text": "from the git repo and to run the",
    "start": "997589",
    "end": "1000950"
  },
  {
    "text": "training stream back the logs and export",
    "start": "1000950",
    "end": "1002960"
  },
  {
    "text": "the model at the end of the training",
    "start": "1002960",
    "end": "1004160"
  },
  {
    "text": "back to Hadoop storage once we have the",
    "start": "1004160",
    "end": "1008780"
  },
  {
    "text": "training done once we have a trained",
    "start": "1008780",
    "end": "1010700"
  },
  {
    "text": "model that we now can deploy we spawn up",
    "start": "1010700",
    "end": "1013940"
  },
  {
    "text": "a new serving pod that will take the",
    "start": "1013940",
    "end": "1017240"
  },
  {
    "text": "model from Hadoop storage loaded into",
    "start": "1017240",
    "end": "1020720"
  },
  {
    "text": "the memory and expose REST API that's",
    "start": "1020720",
    "end": "1029420"
  },
  {
    "text": "what I that's all I had to cover today",
    "start": "1029420",
    "end": "1031760"
  },
  {
    "text": "and if you want to get in touch please",
    "start": "1031760",
    "end": "1033250"
  },
  {
    "text": "get in touch with me on LinkedIn or",
    "start": "1033250",
    "end": "1035420"
  },
  {
    "text": "Twitter or whatever you prefer and I",
    "start": "1035420",
    "end": "1036860"
  },
  {
    "text": "will be around today if you have any",
    "start": "1036860",
    "end": "1038300"
  },
  {
    "text": "questions thank you",
    "start": "1038300",
    "end": "1040930"
  },
  {
    "text": "[Applause]",
    "start": "1040930",
    "end": "1047579"
  }
]
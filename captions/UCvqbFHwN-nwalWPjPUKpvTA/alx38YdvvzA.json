[
  {
    "text": "hey everyone welcome to my talk about securing kubernetes applications by crafting custom second profiles i'm",
    "start": "80",
    "end": "6000"
  },
  {
    "text": "sasha and it's a pleasure to be here today",
    "start": "6000",
    "end": "9759"
  },
  {
    "text": "what do we want to see in this talk so the first thing i would like to tell you about is a brief history about setcoming",
    "start": "11120",
    "end": "17440"
  },
  {
    "text": "kubernetes so we reflect the development progress of second in kubernetes and we",
    "start": "17440",
    "end": "22880"
  },
  {
    "text": "will see what the current state of second kubernetes is after that we will craft a customs",
    "start": "22880",
    "end": "28480"
  },
  {
    "text": "account profile by hand for this we will use a real world example and we will use",
    "start": "28480",
    "end": "34000"
  },
  {
    "text": "two methods like tracing the logs and running recording second profiles by using ebpf",
    "start": "34000",
    "end": "42160"
  },
  {
    "text": "after that we will speak about how we can automate away those manual efforts so how we how could it be possible to",
    "start": "42160",
    "end": "48320"
  },
  {
    "text": "integrate our recording into a ci cd system for example and how we can get",
    "start": "48320",
    "end": "53600"
  },
  {
    "text": "rid of all those manual steps in between and after that we will speak about the bright future of a per default more",
    "start": "53600",
    "end": "60640"
  },
  {
    "text": "secure kubernetes so how can we make the kubernetes more secure by default by",
    "start": "60640",
    "end": "65680"
  },
  {
    "text": "using second profiles for example second is a cisco interceptor feature",
    "start": "65680",
    "end": "72000"
  },
  {
    "text": "for the linux kernel so it really works like this so you want to do a this call on your application and then you can",
    "start": "72000",
    "end": "78320"
  },
  {
    "text": "decide which which action do you want to take with this syscall so for example",
    "start": "78320",
    "end": "83920"
  },
  {
    "text": "you have a different list of actions available you can for example say that you will only want to lock this action",
    "start": "83920",
    "end": "90799"
  },
  {
    "text": "you want to arrow out or you want to allow this cisco for example",
    "start": "90799",
    "end": "96560"
  },
  {
    "text": "and this can boost the application security by limiting the list of allowed syscalls so you can maintain a list of",
    "start": "96560",
    "end": "102240"
  },
  {
    "text": "allowed cisco's you can also maintain a list of blocked syscalls and you can also",
    "start": "102240",
    "end": "107439"
  },
  {
    "text": "find greatly define what the error code for example should be in case your disallows this call and this has been",
    "start": "107439",
    "end": "114799"
  },
  {
    "text": "added to kubernetes a long time ago so we also have a default security profile",
    "start": "114799",
    "end": "120640"
  },
  {
    "text": "this has been defined by the container runtimes but kubernetes requires that such a profile exist in every container",
    "start": "120640",
    "end": "127119"
  },
  {
    "text": "on time like container d cryo and docker second was going to ga which means",
    "start": "127119",
    "end": "134000"
  },
  {
    "text": "generally available since kubernetes 1.90 so we now can consider this feature as stable since quite some releases and",
    "start": "134000",
    "end": "141760"
  },
  {
    "text": "it also supports most linux kernel versions there are some constraints or there are",
    "start": "141760",
    "end": "147599"
  },
  {
    "text": "some environments where second may be not supported so we also have to take this into consideration that we have for",
    "start": "147599",
    "end": "153519"
  },
  {
    "text": "example a decent architecture or linux distribution it does not support secop at all",
    "start": "153519",
    "end": "159840"
  },
  {
    "text": "but in general this second fields are usable by a dative field in the security context or",
    "start": "159840",
    "end": "166879"
  },
  {
    "text": "a deprecated annotation this can be done by the container or by the pot so we can apply profiles to",
    "start": "166879",
    "end": "173360"
  },
  {
    "text": "parts which then inherit to containers or we can specify those profiles on a container level",
    "start": "173360",
    "end": "179360"
  },
  {
    "text": "and overall goal is to remove the annotation support in 1.25",
    "start": "179360",
    "end": "184720"
  },
  {
    "text": "i also have to mention that all workloads run unconfined by default which means that saccomp is disabled for",
    "start": "184720",
    "end": "190080"
  },
  {
    "text": "them we have a special feature introduced in one of the recent kubernetes versions which is called staccom default and this allows us to",
    "start": "190080",
    "end": "197200"
  },
  {
    "text": "change that behavior for example by using the default profile for all workloads on the specified node",
    "start": "197200",
    "end": "204080"
  },
  {
    "text": "i have to mention that this feature is alpha for now so it's not enabled on every node per default",
    "start": "204080",
    "end": "209840"
  },
  {
    "text": "and one drawback is that default profiles may differ between container and time so it may be possible that if",
    "start": "209840",
    "end": "216560"
  },
  {
    "text": "we have clusters with mixed container runtimes then it maybe may be overall",
    "start": "216560",
    "end": "222159"
  },
  {
    "text": "behavior may be different between one node and the other those custom profiles",
    "start": "222159",
    "end": "228000"
  },
  {
    "text": "can be defined as json files so there is two main issues with that so first of",
    "start": "228000",
    "end": "234480"
  },
  {
    "text": "all they have to be distributed to all nodes to be available for the whole cluster and the container runtimes have",
    "start": "234480",
    "end": "241120"
  },
  {
    "text": "to apply them from disk so we don't have an automated way in kubernetes to distribute those profiles",
    "start": "241120",
    "end": "247439"
  },
  {
    "text": "to each node and then load them from disk how can we craft custom second profiles",
    "start": "247439",
    "end": "254000"
  },
  {
    "text": "by hand our overall goal is now to understand how can second profiles work and which",
    "start": "254000",
    "end": "260160"
  },
  {
    "text": "possibilities do they allow and then how my application behaves and which this calls it executes during that",
    "start": "260160",
    "end": "267120"
  },
  {
    "text": "time and we have to collect a list of this calls which are required to pay it allowed additionally so",
    "start": "267120",
    "end": "274320"
  },
  {
    "text": "we have to take the whole cluster separate setup into account and to not create two restrict drift profiles which",
    "start": "274320",
    "end": "280800"
  },
  {
    "text": "means that different architectures may require differences scores and also different architectures",
    "start": "280800",
    "end": "288160"
  },
  {
    "text": "allow a different differences calls and the workload configuration has an influence on the executed syscalls as",
    "start": "288160",
    "end": "294560"
  },
  {
    "text": "well which means that having a workload configured differently for example by setting some options to",
    "start": "294560",
    "end": "301919"
  },
  {
    "text": "some configuration files or something like this may also lead to executing different code paths and this will",
    "start": "301919",
    "end": "308320"
  },
  {
    "text": "automatically lead in different syscalls which has a direct influence on the zaccom profile",
    "start": "308320",
    "end": "314320"
  },
  {
    "text": "the example project we would like to choose today is cube object proxy which is basically just an",
    "start": "314320",
    "end": "320880"
  },
  {
    "text": "http proxy but it can perform our back authorization against the kubernetes api",
    "start": "320880",
    "end": "326880"
  },
  {
    "text": "and this allows us to restrict requests to the api at all in network uh isolated",
    "start": "326880",
    "end": "332160"
  },
  {
    "text": "environments and it has been developed initially to protect prometheus metrics",
    "start": "332160",
    "end": "337600"
  },
  {
    "text": "and points so it's possible to add an additional additional layer of security to usually",
    "start": "337600",
    "end": "344479"
  },
  {
    "text": "plainly exposed prometheus metrics and this is a single container deployment which simplifies this is",
    "start": "344479",
    "end": "350800"
  },
  {
    "text": "called tracing at all having an application which consists of multiple containers or even multiple",
    "start": "350800",
    "end": "357520"
  },
  {
    "text": "deployments like a microservice architecture would require us to create second profiles for all single",
    "start": "357520",
    "end": "364000"
  },
  {
    "text": "deployment and all single containers and this would be probably too much for this demo here i'll link the project",
    "start": "364000",
    "end": "370400"
  },
  {
    "text": "here so you can check this out if you want to learn more about cubarbic proxy",
    "start": "370400",
    "end": "375680"
  },
  {
    "text": "so how to actually record those scores the first method we can use is tracing",
    "start": "375680",
    "end": "380880"
  },
  {
    "text": "the con locks so this requires audit d or this look to be installed and configured on the system which is",
    "start": "380880",
    "end": "387280"
  },
  {
    "text": "something which may be possible across all distributions i mean",
    "start": "387280",
    "end": "392560"
  },
  {
    "text": "there are many distributions like plain ubuntu which only have syslog and there are also other distributions",
    "start": "392560",
    "end": "398560"
  },
  {
    "text": "which ship order d in a good configured way by default nevertheless we have to consider that",
    "start": "398560",
    "end": "405120"
  },
  {
    "text": "there is a rate limit not only for other d but also for this lock and we can set the two sis colors here to",
    "start": "405120",
    "end": "412080"
  },
  {
    "text": "disable the print k rate limit and the rate limit burst otherwise we will probably miss some scores during the",
    "start": "412080",
    "end": "418080"
  },
  {
    "text": "logging of extensive applications we mainly rely on one single linux",
    "start": "418080",
    "end": "424160"
  },
  {
    "text": "kernel function to record all this calls and this is audit second you can see this function here directly from the",
    "start": "424160",
    "end": "430479"
  },
  {
    "text": "latest version of the linux kernel and the only thing it does is creating the log string",
    "start": "430479",
    "end": "436560"
  },
  {
    "text": "containing a bunch of information like the cisco itself and the architecture and then printing that",
    "start": "436560",
    "end": "442639"
  },
  {
    "text": "to the kendall buffer but this comes with a bunch of limitations so for example this course",
    "start": "442639",
    "end": "448240"
  },
  {
    "text": "will only get locked if they got requested for logging which means per default allowed and",
    "start": "448240",
    "end": "454160"
  },
  {
    "text": "also blocked those calls won't be locked at all so generally logging has a high",
    "start": "454160",
    "end": "460160"
  },
  {
    "text": "performance impact i tested it with a bunch of applications and it really slows down the overall application",
    "start": "460160",
    "end": "466160"
  },
  {
    "text": "because it blocks every time we have to lock a line and there is a special setcomp action",
    "start": "466160",
    "end": "473199"
  },
  {
    "text": "available for logging so i already mentioned that there are multiple actions available and creating a second profile",
    "start": "473199",
    "end": "479759"
  },
  {
    "text": "on disk which is a bunch of json for our profiling applications is as simple as",
    "start": "479759",
    "end": "485039"
  },
  {
    "text": "this line so we just have to specify a default action and this action is second back to log so",
    "start": "485039",
    "end": "491360"
  },
  {
    "text": "which is the actual value here we also have to double check if logging or lock the keyboard lock is part of",
    "start": "491360",
    "end": "498400"
  },
  {
    "text": "proxy's kernel set comp actions lock otherwise we would not lock anything at all",
    "start": "498400",
    "end": "504479"
  },
  {
    "text": "now we have to put this profile into the default location for the cubelet to look for second profiles which is smartlab",
    "start": "504479",
    "end": "510639"
  },
  {
    "text": "cubelet second we name our file log.json and for the example of cube orbic proxy",
    "start": "510639",
    "end": "518000"
  },
  {
    "text": "we'll change the security context of the second secretary context of the deployment",
    "start": "518000",
    "end": "523440"
  },
  {
    "text": "to specify the second profile localhost and then point to the relative path",
    "start": "523440",
    "end": "529120"
  },
  {
    "text": "which is log.json now we can finally run our demo",
    "start": "529120",
    "end": "534399"
  },
  {
    "text": "application and trace the bar log audit audit log in my system so",
    "start": "534399",
    "end": "540080"
  },
  {
    "text": "we have to be aware that those files also rotate at a common size it also depends on the configuration of audit d",
    "start": "540080",
    "end": "546959"
  },
  {
    "text": "and and order d itself can also be configured to have a rate limit",
    "start": "546959",
    "end": "553040"
  },
  {
    "text": "we can double check that by running suited order ctl minus s which prints out the configuration for that",
    "start": "553040",
    "end": "559040"
  },
  {
    "text": "and then the the question would be how can we link the workload which is currently",
    "start": "559040",
    "end": "565519"
  },
  {
    "text": "running to the actual output of the audit logs so the only thing we can do is we can",
    "start": "565519",
    "end": "572000"
  },
  {
    "text": "just yeah we could also we have a process name for example but process names are not unique on the",
    "start": "572000",
    "end": "577760"
  },
  {
    "text": "system we have to choose the unique process identifiers of the pid and with chris ctl we could look for our",
    "start": "577760",
    "end": "585920"
  },
  {
    "text": "container on the local machine like crystalps and then look for cube object proxy then we get a container id",
    "start": "585920",
    "end": "592640"
  },
  {
    "text": "and by using the container id we can use cryctl inspect and then grab for the",
    "start": "592640",
    "end": "599680"
  },
  {
    "text": "info pit and this gives us the process id of the workload of the container",
    "start": "599680",
    "end": "607600"
  },
  {
    "text": "and when we have that then we can obtain a list of syscalls so for example if we",
    "start": "607600",
    "end": "612959"
  },
  {
    "text": "run pseudocad wirelog audit or the d-log and then look for the type setcom because we have",
    "start": "612959",
    "end": "619120"
  },
  {
    "text": "noted the multiple types available but we only are interested in the typeset comp",
    "start": "619120",
    "end": "624240"
  },
  {
    "text": "then we additionally prep for the pid and then we have an automatically",
    "start": "624240",
    "end": "630640"
  },
  {
    "text": "resolution of the syscall name which is written in uppercase here and if we sort those uniquely and also",
    "start": "630640",
    "end": "638720"
  },
  {
    "text": "now remove the new lines here that i can print it out then we will see all this calls available or required for running",
    "start": "638720",
    "end": "646560"
  },
  {
    "text": "the cube our back proxy binary so for example we can see we need bind",
    "start": "646560",
    "end": "651600"
  },
  {
    "text": "we need clone and yeah we also need socket for example because it will",
    "start": "651600",
    "end": "657120"
  },
  {
    "text": "actually create a socket and a bunch of other ciscos like listen and that's interesting",
    "start": "657120",
    "end": "663760"
  },
  {
    "text": "but we only have started the application for now means that this list of ciscos reflects",
    "start": "663760",
    "end": "670000"
  },
  {
    "text": "only the solder of the application not its actual usage so it's really important to gather this course for all available",
    "start": "670000",
    "end": "677519"
  },
  {
    "text": "code paths so what we now do is we create the client we created example client",
    "start": "677519",
    "end": "683760"
  },
  {
    "text": "um and this will then connect to the cube orbit proxy we'll try to gather the",
    "start": "683760",
    "end": "689920"
  },
  {
    "text": "metrics and then we can see if we do it do it again collecting this is called that a bunch of ciscos have been added",
    "start": "689920",
    "end": "696320"
  },
  {
    "text": "to our list for example connect and get peer name so means that",
    "start": "696320",
    "end": "702880"
  },
  {
    "text": "actually using the application will trigger the code paths and this is crucial for this overall approach",
    "start": "702880",
    "end": "710240"
  },
  {
    "text": "so what we can do now with this list of syscalls is that we create an allow list of possible syscalls for this deployment",
    "start": "710240",
    "end": "717200"
  },
  {
    "text": "so we use a default action of arrowing out we can also specify the arrow return code if we want to and the arrow no",
    "start": "717200",
    "end": "725040"
  },
  {
    "text": "error code like which is e-perm in this case but we could also choose enosis for",
    "start": "725040",
    "end": "730480"
  },
  {
    "text": "example and then we specified a list of ciscos which are allowed so disallowing",
    "start": "730480",
    "end": "735760"
  },
  {
    "text": "everything and then having something like an allowed list is always the most secure approach rather than going the",
    "start": "735760",
    "end": "741360"
  },
  {
    "text": "other way around and then we add those syscall names to our list",
    "start": "741360",
    "end": "746639"
  },
  {
    "text": "and after that we can use this profile as a new second",
    "start": "746639",
    "end": "752000"
  },
  {
    "text": "profile on disk and this is something i would like to demonstrate you know so first of all let's double check that",
    "start": "752000",
    "end": "758880"
  },
  {
    "text": "my system actually is able to lock anything by using order d and yes so the second",
    "start": "758880",
    "end": "765920"
  },
  {
    "text": "actions locked uh skill process kill threat um trap aeronaut things like that and also the most important part is the",
    "start": "765920",
    "end": "772880"
  },
  {
    "text": "lock here now what we can do now is we can create our profile which is",
    "start": "772880",
    "end": "779839"
  },
  {
    "text": "called log json and this profile has to be copied into",
    "start": "779839",
    "end": "785760"
  },
  {
    "text": "the wallet dublin second directory otherwise",
    "start": "785760",
    "end": "790880"
  },
  {
    "text": "it wouldn't work at all so if we now double check our deployment then we have to ensure that the security",
    "start": "790880",
    "end": "797839"
  },
  {
    "text": "context of the container for the cube outback proxy specifies a localhost profile which is",
    "start": "797839",
    "end": "804560"
  },
  {
    "text": "called log.json and this is already the case we can apply it",
    "start": "804560",
    "end": "810000"
  },
  {
    "text": "and then we can wait for it up and running which is already the case now and now it already should lock some this",
    "start": "810000",
    "end": "816959"
  },
  {
    "text": "calls into our log audit audit.log so if we now",
    "start": "816959",
    "end": "822160"
  },
  {
    "text": "retrieve the container id by using create ctlps and export it as",
    "start": "822160",
    "end": "830720"
  },
  {
    "text": "like this then we can also export the process id by using crash ctr inspect like this",
    "start": "830720",
    "end": "836720"
  },
  {
    "text": "and the process id should be now available like this",
    "start": "836720",
    "end": "842399"
  },
  {
    "text": "but what we now have to do is we can just",
    "start": "842399",
    "end": "847839"
  },
  {
    "text": "grab our audit locks we can do it like this because we have multiple order",
    "start": "847839",
    "end": "853040"
  },
  {
    "text": "blocks and then we have to grab for the type second additionally",
    "start": "853040",
    "end": "861199"
  },
  {
    "text": "grab for the process id and we can also double check",
    "start": "861199",
    "end": "867519"
  },
  {
    "text": "like this that there are those entries are unique and here we are",
    "start": "867519",
    "end": "873600"
  },
  {
    "text": "this is a list of this course we have right now and",
    "start": "873600",
    "end": "878639"
  },
  {
    "text": "we can also we also have to actually use the client so we as a client example",
    "start": "878639",
    "end": "884480"
  },
  {
    "text": "available for kubernetes proxy which creates a job and this job will run to completion",
    "start": "884480",
    "end": "892480"
  },
  {
    "text": "like this so we can just see that it actually works",
    "start": "892480",
    "end": "900160"
  },
  {
    "text": "so the authorization itself against cubic proxy has been worked and if we now run it again",
    "start": "900160",
    "end": "907040"
  },
  {
    "text": "then we see that we have a bunch of moses calls and those two scores can be the base for our actual second profile",
    "start": "907040",
    "end": "914880"
  },
  {
    "text": "so let's modify this log json profile",
    "start": "914880",
    "end": "920639"
  },
  {
    "text": "and use pc5 for example the example we have in our demonstration",
    "start": "920639",
    "end": "927199"
  },
  {
    "text": "so this profile now contains 25 syscalls and",
    "start": "927199",
    "end": "932320"
  },
  {
    "text": "if we copy it and if we copy it into",
    "start": "932320",
    "end": "938480"
  },
  {
    "text": "our profile.json for example and then modify the deployment to point to",
    "start": "938480",
    "end": "946880"
  },
  {
    "text": "this profile dot json then we can verify that it actually",
    "start": "946880",
    "end": "953600"
  },
  {
    "text": "works then reapply the deployment again and we can see that it is now",
    "start": "953600",
    "end": "961279"
  },
  {
    "text": "up and running by using our recorded profile",
    "start": "961279",
    "end": "966079"
  },
  {
    "text": "so let's add some thoughts on this overall approach so creating profiles via deluxe can be slow especially when",
    "start": "967120",
    "end": "973360"
  },
  {
    "text": "we consider using it in the cicd based automation so if we consider having a huge test suite of end to end tests",
    "start": "973360",
    "end": "979759"
  },
  {
    "text": "which already takes a bunch of hours to run then we probably will further slow it down by using the audit logging",
    "start": "979759",
    "end": "987519"
  },
  {
    "text": "and all nodes have to be pre-configured to not rate limit those logs and",
    "start": "987519",
    "end": "993199"
  },
  {
    "text": "especially gathering all application code paths is really the hardest part here so we have to ensure that we test",
    "start": "993199",
    "end": "999839"
  },
  {
    "text": "that that we test all use cases accordingly and there is another way of doing this",
    "start": "999839",
    "end": "1007279"
  },
  {
    "text": "by utilizing eppf so ebpf is a technology which allows us",
    "start": "1007279",
    "end": "1014000"
  },
  {
    "text": "to run code inside of the kernel by loading it dynamically and this supports",
    "start": "1014000",
    "end": "1019680"
  },
  {
    "text": "a bunch of trace points for example we have this rows this calls enter trace point",
    "start": "1019680",
    "end": "1024880"
  },
  {
    "text": "which gets executed for every syscall on the whole system so",
    "start": "1024880",
    "end": "1031360"
  },
  {
    "text": "and even before we want to do that syscall so this provides us some basic mitigation point for the syscall",
    "start": "1031360",
    "end": "1039120"
  },
  {
    "text": "and but we have to be aware that is always runs in global scope of the whole",
    "start": "1039120",
    "end": "1044640"
  },
  {
    "text": "system so we have to correlate the information of the process to the container in the",
    "start": "1044640",
    "end": "1050559"
  },
  {
    "text": "same way as we have to do it with the audit logging we can use tools like ppf trays which",
    "start": "1050559",
    "end": "1058400"
  },
  {
    "text": "already allow us to collect the required data so bpf trace provides its own",
    "start": "1058400",
    "end": "1063440"
  },
  {
    "text": "abstraction language on top of ebpf and for example we can run bpf trace and",
    "start": "1063440",
    "end": "1068960"
  },
  {
    "text": "then select the trace point rows this calls this enter and then we already pre-filter for",
    "start": "1068960",
    "end": "1074960"
  },
  {
    "text": "the application name cube object proxy and what we then print is we print a pid",
    "start": "1074960",
    "end": "1081280"
  },
  {
    "text": "and this is called id and if we run an application like this in parallel or even before the cube opec",
    "start": "1081280",
    "end": "1088559"
  },
  {
    "text": "proxy has been started then we can start the cube object proxy later on and",
    "start": "1088559",
    "end": "1095039"
  },
  {
    "text": "if this has been done if the global proxy is teared down and we have run all our",
    "start": "1095039",
    "end": "1100320"
  },
  {
    "text": "tests then we can grab like the pid into",
    "start": "1100320",
    "end": "1106480"
  },
  {
    "text": "the output which provides us then a list of this call numbers",
    "start": "1106480",
    "end": "1112480"
  },
  {
    "text": "like here so there is no automatic resolution of the syscall name we only get the number on the local system",
    "start": "1112480",
    "end": "1119200"
  },
  {
    "text": "this is reason because those syscall numbers can change from system configuration to system configuration",
    "start": "1119200",
    "end": "1125600"
  },
  {
    "text": "namely the architecture of the system now we have to convert those syscall numbers back into the actual name which",
    "start": "1125600",
    "end": "1131600"
  },
  {
    "text": "can be done by the au syscall binary which is part of audit d so if we dump all ciscos then we see",
    "start": "1131600",
    "end": "1139039"
  },
  {
    "text": "that we have the number correlated to the actual name of the syscall so",
    "start": "1139039",
    "end": "1145440"
  },
  {
    "text": "that gives us standard profile and then we can apply this profile to the workbook itself",
    "start": "1146000",
    "end": "1151360"
  },
  {
    "text": "it is possible to create setcom profiles manually without having to write an ebbf application from scratch by using this",
    "start": "1151360",
    "end": "1158160"
  },
  {
    "text": "approach um but it would be also possible to create an own eppf application for example there",
    "start": "1158160",
    "end": "1165039"
  },
  {
    "text": "is the golang binding lib ppf.go then we could",
    "start": "1165039",
    "end": "1170240"
  },
  {
    "text": "correlate the information of the process id to the container we are using by using the c group path on the local",
    "start": "1170240",
    "end": "1176640"
  },
  {
    "text": "machine and then collect the data directly at hog but this sounds complicated doesn't it",
    "start": "1176640",
    "end": "1183919"
  },
  {
    "text": "so my thoughts on this overall approach are creating profiles",
    "start": "1183919",
    "end": "1189200"
  },
  {
    "text": "would not affect the system performance in the same way is logging because ebpf is really fast we would still have to overcome so we",
    "start": "1189200",
    "end": "1196480"
  },
  {
    "text": "are in the kernel space and we would still have to overcome the performance drawback when",
    "start": "1196480",
    "end": "1201520"
  },
  {
    "text": "moving the data like the syscalls and the process ids back into the user space so this has a performance",
    "start": "1201520",
    "end": "1208559"
  },
  {
    "text": "impact but not in the same way as the logging yes and all nodes have to be reconfig",
    "start": "1208559",
    "end": "1214320"
  },
  {
    "text": "configured to contain either the custom uppf application or the dependent tools so we",
    "start": "1214320",
    "end": "1221200"
  },
  {
    "text": "can't just use plain kubernetes we have to use ppf trays or compile the ebbf applications and ensure that the eppf",
    "start": "1221200",
    "end": "1228640"
  },
  {
    "text": "application runs on the node and things like that um and gathering all application code",
    "start": "1228640",
    "end": "1234400"
  },
  {
    "text": "path is still extremely hard but there must be a better way in doing this right",
    "start": "1234400",
    "end": "1241039"
  },
  {
    "text": "and this is actually the case for example the security profiles operator is an operator which focuses only on",
    "start": "1241120",
    "end": "1247280"
  },
  {
    "text": "security profiles for second c linux and app armor and this provides an automation around lock and ebpf based",
    "start": "1247280",
    "end": "1254080"
  },
  {
    "text": "profile recording it automatically traces the logs at the right time and that extracts the data",
    "start": "1254080",
    "end": "1261679"
  },
  {
    "text": "means if i run a workload then i can pre-define that i want to record this workload and then the security profiles",
    "start": "1261679",
    "end": "1269039"
  },
  {
    "text": "operator will take care of tracing the logs and gathering the data for example",
    "start": "1269039",
    "end": "1274559"
  },
  {
    "text": "correlating the process id to the workload and it can also leverage ebpf to recode",
    "start": "1274559",
    "end": "1280000"
  },
  {
    "text": "those profiles for example for performance reasons for example and this also automatically correlates",
    "start": "1280000",
    "end": "1286559"
  },
  {
    "text": "the workload to the underlying process and it creates second profile so if a",
    "start": "1286559",
    "end": "1292400"
  },
  {
    "text": "recording has been done namely a workload has been removed then it will automatically record a second",
    "start": "1292400",
    "end": "1298400"
  },
  {
    "text": "profile based on that workload this second profile will be represented",
    "start": "1298400",
    "end": "1303919"
  },
  {
    "text": "as a second crd so it's even easier to handle it and if we have a second crd",
    "start": "1303919",
    "end": "1309840"
  },
  {
    "text": "then it automatically reconciles all those profiles to all nodes so we can have a workflow where we have a",
    "start": "1309840",
    "end": "1316559"
  },
  {
    "text": "professory a profile and then automatically reuses it within a cluster without relying on a single node cluster",
    "start": "1316559",
    "end": "1323200"
  },
  {
    "text": "so the distribution of the profiles will be taken automatically which is really great",
    "start": "1323200",
    "end": "1328720"
  },
  {
    "text": "how does the eppf recording and the security profiles operator work in detail so first of all we have to specify a",
    "start": "1328720",
    "end": "1335600"
  },
  {
    "text": "custom resource definition which defines that we want to record a workload this will happen by using a standard selector",
    "start": "1335600",
    "end": "1344400"
  },
  {
    "text": "and if the profile recording crd access and we create our workload matching that",
    "start": "1344400",
    "end": "1350159"
  },
  {
    "text": "selector then the security profiles operator will use a web hook to add a recording annotation",
    "start": "1350159",
    "end": "1357120"
  },
  {
    "text": "and this is the only job of the profile recorder so adding this annotation will",
    "start": "1357120",
    "end": "1362640"
  },
  {
    "text": "indicate to the bpf recorder vr grpc that we now want to start a recording",
    "start": "1362640",
    "end": "1368640"
  },
  {
    "text": "and this loads automatically loads in libpf application into the kernel which doesn't require recompiling the",
    "start": "1368640",
    "end": "1375760"
  },
  {
    "text": "application itself because it uses ebpf query which means compile ones run everywhere",
    "start": "1375760",
    "end": "1382240"
  },
  {
    "text": "to start the application locally so it loads the eppf program which also",
    "start": "1382240",
    "end": "1387600"
  },
  {
    "text": "uses this is entertracepoint and this program records this is calls for every pit",
    "start": "1387600",
    "end": "1393760"
  },
  {
    "text": "on the local machine and it throws an event on the pid which which will be used by tracking the",
    "start": "1393760",
    "end": "1400880"
  },
  {
    "text": "mount namespace because the mount namespace is usually something which is really stable across a container",
    "start": "1400880",
    "end": "1406320"
  },
  {
    "text": "and these events will be used by the event processor in the ebpf recorder it",
    "start": "1406320",
    "end": "1411840"
  },
  {
    "text": "tries to get the container id for the process id by using the local c group",
    "start": "1411840",
    "end": "1417200"
  },
  {
    "text": "and then it tries to find the container id in the cluster and if this has been found and it looks for the profile",
    "start": "1417200",
    "end": "1422480"
  },
  {
    "text": "recording annotation and then it starts tracking the profile for the pid and the amount namespace",
    "start": "1422480",
    "end": "1428799"
  },
  {
    "text": "or this is the overall loop and then if we stop the workload then the profile recorder will actually collect the",
    "start": "1428799",
    "end": "1434480"
  },
  {
    "text": "syscalls from the bpf recorder and the ppf recorder will take care of automatically unloading itself so the",
    "start": "1434480",
    "end": "1441520"
  },
  {
    "text": "bbf program itself runs only during the life cycle of a single recording or",
    "start": "1441520",
    "end": "1447760"
  },
  {
    "text": "yeah multiple recordings are probably all possible as well i would like to demonstrate that to you",
    "start": "1447760",
    "end": "1455120"
  },
  {
    "text": "so if you look into my current kubernetes cluster then we can see that the security provides operators up and",
    "start": "1455120",
    "end": "1461120"
  },
  {
    "text": "running and that we also have salt manager deployed which is a direct dependency if we don't have any other",
    "start": "1461120",
    "end": "1467679"
  },
  {
    "text": "static effect provider available within the cluster the first thing we have to do because",
    "start": "1467679",
    "end": "1473840"
  },
  {
    "text": "it's disabled by default is to enable the ppf recorder and to do this",
    "start": "1473840",
    "end": "1480159"
  },
  {
    "text": "we just have to patch the security profiles operator daemon configuration",
    "start": "1480159",
    "end": "1485200"
  },
  {
    "text": "which is called spod and over the spec that we enable the ppf recorder and set this to true",
    "start": "1485200",
    "end": "1493120"
  },
  {
    "text": "so if we did this then we can see that the security profiles operator will take care of",
    "start": "1493120",
    "end": "1498400"
  },
  {
    "text": "rolling out itself again with the new configuration and after a couple of seconds the spod",
    "start": "1498400",
    "end": "1504799"
  },
  {
    "text": "instance should be up and running again if we now look into the into the logs of",
    "start": "1504799",
    "end": "1511919"
  },
  {
    "text": "the ppf record or container then we can see that it does some sort of self check",
    "start": "1511919",
    "end": "1518960"
  },
  {
    "text": "before it actually starts so it gets the ppf it does a ppf load unload",
    "start": "1518960",
    "end": "1525360"
  },
  {
    "text": "self-test it loads the ppf module and it tries to attach the trace point and then",
    "start": "1525360",
    "end": "1531440"
  },
  {
    "text": "it if this are all is successfully then it unloads the module afterwards itself",
    "start": "1531440",
    "end": "1538320"
  },
  {
    "text": "and this is great because this already provides us a feedback if the ppf module",
    "start": "1538320",
    "end": "1545760"
  },
  {
    "text": "is working as intended so the security profiles operator ships",
    "start": "1545760",
    "end": "1550960"
  },
  {
    "text": "a default example for recording statcom profiles by using bpf",
    "start": "1550960",
    "end": "1557600"
  },
  {
    "text": "and if we look into this example then we can see that we have a special kind profile recording available for the",
    "start": "1557600",
    "end": "1563600"
  },
  {
    "text": "security profiles operator and we can give this a name which is",
    "start": "1563600",
    "end": "1568799"
  },
  {
    "text": "test recording in our case so this will be later on the name of the recording itself or be part of the name",
    "start": "1568799",
    "end": "1575039"
  },
  {
    "text": "of the recording itself and what we want to record are second profiles so for the recorder bpf right",
    "start": "1575039",
    "end": "1582080"
  },
  {
    "text": "now we only can record second profiles the lux recorder would also support recording the linux profiles by the way",
    "start": "1582080",
    "end": "1589520"
  },
  {
    "text": "we use a pod selector which matches our labels app equals alpine and this is",
    "start": "1589520",
    "end": "1596000"
  },
  {
    "text": "the overall indicator for the recorder to match any part which contains that",
    "start": "1596000",
    "end": "1601120"
  },
  {
    "text": "label will be recorded so let's apply it",
    "start": "1601120",
    "end": "1607600"
  },
  {
    "text": "and then we can also double check if it's available",
    "start": "1608880",
    "end": "1613799"
  },
  {
    "text": "yeah our test recording is available here and what we can do now is we can run a",
    "start": "1615279",
    "end": "1620480"
  },
  {
    "text": "workload which is using an alpine image and contains the label app equals alpine",
    "start": "1620480",
    "end": "1628400"
  },
  {
    "text": "and if the container is up and running then we could usually do some tests or execute some ciscos for example",
    "start": "1630480",
    "end": "1637520"
  },
  {
    "text": "we can create a test directory test1 and also test2",
    "start": "1637520",
    "end": "1643520"
  },
  {
    "text": "and if we exit this container again then it will be automatically removed and after a couple of seconds",
    "start": "1643520",
    "end": "1650240"
  },
  {
    "text": "the security profiles operator ppf recorder should also return the",
    "start": "1650240",
    "end": "1656559"
  },
  {
    "text": "the profile for the track pids you can see",
    "start": "1656559",
    "end": "1662080"
  },
  {
    "text": "the compass h command and the mount name space related to it and also see that all sub commands for",
    "start": "1662080",
    "end": "1669760"
  },
  {
    "text": "example mkd as a sub command of the s8 shell if i run it within it and it also",
    "start": "1669760",
    "end": "1675360"
  },
  {
    "text": "tracks the amount in space of it and that's equal and if the result has been returned then the",
    "start": "1675360",
    "end": "1681840"
  },
  {
    "text": "ppf recorder cleans up itself and stops the module itself for security purposes",
    "start": "1681840",
    "end": "1688320"
  },
  {
    "text": "so now the second profile should be available right so if we",
    "start": "1688320",
    "end": "1693679"
  },
  {
    "text": "look for our second profiles then we can see that the test recording alpha profile has been installed and is",
    "start": "1693679",
    "end": "1699200"
  },
  {
    "text": "available on all nodes within this cluster and we can also look",
    "start": "1699200",
    "end": "1705279"
  },
  {
    "text": "what the actual install path is so the operator itself creates a namespace",
    "start": "1705279",
    "end": "1710399"
  },
  {
    "text": "operator and then it uses the namespace which is default in this case and then it creates the json file for the second",
    "start": "1710399",
    "end": "1716880"
  },
  {
    "text": "profile and if we look at the profile itself",
    "start": "1716880",
    "end": "1722399"
  },
  {
    "text": "then we can see that it is an allow list as i as we already did for the log recording",
    "start": "1722399",
    "end": "1728000"
  },
  {
    "text": "for example we have a default action which is arrowing we also have the local",
    "start": "1728000",
    "end": "1733120"
  },
  {
    "text": "architecture available here and the list of allowed this course which is only the list of really",
    "start": "1733120",
    "end": "1738880"
  },
  {
    "text": "necessarily allowed ciscos and you can also can see that we have mkd and mkdir ad here",
    "start": "1738880",
    "end": "1745200"
  },
  {
    "text": "available within this profile",
    "start": "1745200",
    "end": "1749158"
  },
  {
    "text": "so general thoughts on this approach so we get mostly get rid of all manual collection",
    "start": "1752000",
    "end": "1757440"
  },
  {
    "text": "obstacles so we don't have to pre-configure the local node we just have to deploy the security profiles",
    "start": "1757440",
    "end": "1762799"
  },
  {
    "text": "operator and that's it but gathering all application code is still the hardest part here the integration into a cicd",
    "start": "1762799",
    "end": "1770320"
  },
  {
    "text": "workflow would allow us updating statcom profiles with the application lifecycle so we have to consider that second",
    "start": "1770320",
    "end": "1776799"
  },
  {
    "text": "profiles change when application code changes and this could be integrated into a",
    "start": "1776799",
    "end": "1782320"
  },
  {
    "text": "whole cicd workflow for collecting the profiles and then distributing them as well by upgrading",
    "start": "1782320",
    "end": "1788240"
  },
  {
    "text": "because the security profiles operator can also reconcile those profiles on each node you can also take care of",
    "start": "1788240",
    "end": "1793279"
  },
  {
    "text": "updating them on the other side the security profiles operator could also be used in production to distribute the profiles",
    "start": "1793279",
    "end": "1800240"
  },
  {
    "text": "using the crt let's speak about the bright future of a",
    "start": "1800240",
    "end": "1806640"
  },
  {
    "text": "per default more secure kubernetes so the second default feature should be graduated to beta and",
    "start": "1806640",
    "end": "1812640"
  },
  {
    "text": "kubernetes 1-25 but this means that also it won't be enabled",
    "start": "1812640",
    "end": "1819360"
  },
  {
    "text": "by default because since kubernetes 1.24 those beta features are not enabled per",
    "start": "1819360",
    "end": "1824399"
  },
  {
    "text": "default anymore so creator aging the feature to stable would gain us a security boost in kubernetes um the plan is also to make",
    "start": "1824399",
    "end": "1831760"
  },
  {
    "text": "it api aware so that we have actually representation of the sake of",
    "start": "1831760",
    "end": "1836799"
  },
  {
    "text": "the use decom profile not only for the cubelet but also for the end user",
    "start": "1836799",
    "end": "1842240"
  },
  {
    "text": "and then handling those upgrade paths is probably the most complex part so we were thinking about",
    "start": "1842240",
    "end": "1848000"
  },
  {
    "text": "upgrading only or enabling the feature only for new workloads and existing workloads won't be touched at all but",
    "start": "1848000",
    "end": "1854720"
  },
  {
    "text": "for example downgrading again would be then even harder than upgrading",
    "start": "1854720",
    "end": "1860240"
  },
  {
    "text": "you could help us um by making kubernetes music by default for example by using the custom second profiles or",
    "start": "1860240",
    "end": "1867039"
  },
  {
    "text": "by using the security profiles operator or just sticking to runtime default for all your applications",
    "start": "1867039",
    "end": "1873519"
  },
  {
    "text": "and other other than that it would be really great if you would try out the second default feature in kubernetes and",
    "start": "1873519",
    "end": "1879919"
  },
  {
    "text": "provide some additional feedback about how it behaves if you enable second default and everything",
    "start": "1879919",
    "end": "1885039"
  },
  {
    "text": "works out of the box then you can also choose runtime default for your application as well",
    "start": "1885039",
    "end": "1890720"
  },
  {
    "text": "and that's it thank you for listening to this talk um i really appreciate your feedback and let's have a chat about",
    "start": "1890720",
    "end": "1897600"
  },
  {
    "text": "this",
    "start": "1897600",
    "end": "1900559"
  }
]
[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "hi everyone welcome to petabyte scale",
    "start": "1439",
    "end": "3439"
  },
  {
    "text": "logging with fluency influent bit",
    "start": "3439",
    "end": "5120"
  },
  {
    "text": "a use case from intuit my name is",
    "start": "5120",
    "end": "7359"
  },
  {
    "text": "onorock i'm",
    "start": "7359",
    "end": "8240"
  },
  {
    "text": "part of the company calyptia and i help",
    "start": "8240",
    "end": "10240"
  },
  {
    "text": "run product there",
    "start": "10240",
    "end": "12160"
  },
  {
    "text": "so who are we so today it's going to be",
    "start": "12160",
    "end": "13920"
  },
  {
    "text": "myself and hansel who's joining me from",
    "start": "13920",
    "end": "15759"
  },
  {
    "text": "intuit who's on the cloud observability",
    "start": "15759",
    "end": "17600"
  },
  {
    "text": "team there",
    "start": "17600",
    "end": "18400"
  },
  {
    "text": "as a senior software engineer and for",
    "start": "18400",
    "end": "20640"
  },
  {
    "text": "myself i'm part of the",
    "start": "20640",
    "end": "22160"
  },
  {
    "text": "oss group that is a maintainer for the",
    "start": "22160",
    "end": "24880"
  },
  {
    "text": "fluent bit project",
    "start": "24880",
    "end": "26240"
  },
  {
    "text": "and i help drive product for both",
    "start": "26240",
    "end": "27599"
  },
  {
    "text": "flipped and flinty",
    "start": "27599",
    "end": "30400"
  },
  {
    "start": "30000",
    "end": "106000"
  },
  {
    "text": "so for those who are unfamiliar with",
    "start": "30400",
    "end": "32800"
  },
  {
    "text": "what is fluenty and what",
    "start": "32800",
    "end": "34239"
  },
  {
    "text": "what is fluent bit they are cloud native",
    "start": "34239",
    "end": "37120"
  },
  {
    "text": "computing foundation projects",
    "start": "37120",
    "end": "39040"
  },
  {
    "text": "they are part of the graduated projects",
    "start": "39040",
    "end": "40719"
  },
  {
    "text": "alongside kubernetes prometheus and",
    "start": "40719",
    "end": "42879"
  },
  {
    "text": "others",
    "start": "42879",
    "end": "43520"
  },
  {
    "text": "they started 10 years ago and the",
    "start": "43520",
    "end": "45440"
  },
  {
    "text": "primary problem they solve",
    "start": "45440",
    "end": "47680"
  },
  {
    "text": "is how do you take data from point a",
    "start": "47680",
    "end": "50960"
  },
  {
    "text": "and send it to point b and if we look at",
    "start": "50960",
    "end": "53760"
  },
  {
    "text": "this problem",
    "start": "53760",
    "end": "54640"
  },
  {
    "text": "over the last 10 years where you see",
    "start": "54640",
    "end": "57360"
  },
  {
    "text": "that",
    "start": "57360",
    "end": "57760"
  },
  {
    "text": "data sources continually evolve we have",
    "start": "57760",
    "end": "60000"
  },
  {
    "text": "more things like",
    "start": "60000",
    "end": "61039"
  },
  {
    "text": "mobile applications system logs",
    "start": "61039",
    "end": "63359"
  },
  {
    "text": "kubernetes",
    "start": "63359",
    "end": "65080"
  },
  {
    "text": "microservices containers app metrics",
    "start": "65080",
    "end": "69040"
  },
  {
    "text": "and we have additional destinations that",
    "start": "69040",
    "end": "71280"
  },
  {
    "text": "just keep compounding you might have",
    "start": "71280",
    "end": "73040"
  },
  {
    "text": "things like",
    "start": "73040",
    "end": "74240"
  },
  {
    "text": "uh amazon s3 you might have splunk",
    "start": "74240",
    "end": "76960"
  },
  {
    "text": "elasticsearch loki",
    "start": "76960",
    "end": "79040"
  },
  {
    "text": "azure gcp kafka",
    "start": "79040",
    "end": "82640"
  },
  {
    "text": "and those destinations just continue to",
    "start": "82640",
    "end": "84799"
  },
  {
    "text": "evolve and expand",
    "start": "84799",
    "end": "86000"
  },
  {
    "text": "you might need to send data to multiple",
    "start": "86000",
    "end": "88000"
  },
  {
    "text": "you might need to send data",
    "start": "88000",
    "end": "89360"
  },
  {
    "text": "to all of them you might need to send",
    "start": "89360",
    "end": "90799"
  },
  {
    "text": "data to a single one",
    "start": "90799",
    "end": "92479"
  },
  {
    "text": "but in any case fluent d and fluent bid",
    "start": "92479",
    "end": "94799"
  },
  {
    "text": "are really vendor neutral solutions to",
    "start": "94799",
    "end": "97360"
  },
  {
    "text": "saying",
    "start": "97360",
    "end": "98000"
  },
  {
    "text": "let's collect data once and send it to",
    "start": "98000",
    "end": "100880"
  },
  {
    "text": "as",
    "start": "100880",
    "end": "101200"
  },
  {
    "text": "many destinations as you require",
    "start": "101200",
    "end": "105200"
  },
  {
    "text": "now when we look at challenges for",
    "start": "105200",
    "end": "107680"
  },
  {
    "start": "106000",
    "end": "190000"
  },
  {
    "text": "logging at scale",
    "start": "107680",
    "end": "109280"
  },
  {
    "text": "we have to look at this and perspective",
    "start": "109280",
    "end": "111840"
  },
  {
    "text": "of a broad overview one is",
    "start": "111840",
    "end": "114079"
  },
  {
    "text": "high scale can really equal very high",
    "start": "114079",
    "end": "117119"
  },
  {
    "text": "costs",
    "start": "117119",
    "end": "118320"
  },
  {
    "text": "you can have things like reliability and",
    "start": "118320",
    "end": "120479"
  },
  {
    "text": "buffering uh how do you make sure that",
    "start": "120479",
    "end": "122479"
  },
  {
    "text": "logs get sent where they're supposed to",
    "start": "122479",
    "end": "124880"
  },
  {
    "text": "and you don't want to open up a request",
    "start": "124880",
    "end": "127360"
  },
  {
    "text": "every single",
    "start": "127360",
    "end": "128080"
  },
  {
    "text": "time that you have a new message think",
    "start": "128080",
    "end": "130560"
  },
  {
    "text": "about that when you're sending",
    "start": "130560",
    "end": "132080"
  },
  {
    "text": "10 000 to 100 000 messages per second",
    "start": "132080",
    "end": "135280"
  },
  {
    "text": "networking always an issue here with",
    "start": "135280",
    "end": "138160"
  },
  {
    "text": "things like",
    "start": "138160",
    "end": "139040"
  },
  {
    "text": "ephemeral workloads and kubernetes or",
    "start": "139040",
    "end": "141520"
  },
  {
    "text": "you're in the cloud",
    "start": "141520",
    "end": "143120"
  },
  {
    "text": "you might have air gapped environments",
    "start": "143120",
    "end": "144800"
  },
  {
    "text": "how do you make sure networking",
    "start": "144800",
    "end": "146239"
  },
  {
    "text": "doesn't hurt you when you're doing",
    "start": "146239",
    "end": "148319"
  },
  {
    "text": "logging at scale",
    "start": "148319",
    "end": "150080"
  },
  {
    "text": "event throughput you might need to",
    "start": "150080",
    "end": "151840"
  },
  {
    "text": "maximize how many messages per second",
    "start": "151840",
    "end": "154160"
  },
  {
    "text": "you're sending",
    "start": "154160",
    "end": "155200"
  },
  {
    "text": "you might have latency requirements you",
    "start": "155200",
    "end": "157280"
  },
  {
    "text": "might have to",
    "start": "157280",
    "end": "158400"
  },
  {
    "text": "get messages so that they your",
    "start": "158400",
    "end": "160560"
  },
  {
    "text": "developers your operations folks can go",
    "start": "160560",
    "end": "162879"
  },
  {
    "text": "and",
    "start": "162879",
    "end": "163360"
  },
  {
    "text": "start to debug and diagnose all that",
    "start": "163360",
    "end": "165440"
  },
  {
    "text": "information",
    "start": "165440",
    "end": "167200"
  },
  {
    "text": "security so again in a large scale",
    "start": "167200",
    "end": "170080"
  },
  {
    "text": "environment",
    "start": "170080",
    "end": "170959"
  },
  {
    "text": "we might have sensitive information that",
    "start": "170959",
    "end": "172720"
  },
  {
    "text": "might make its way through",
    "start": "172720",
    "end": "174319"
  },
  {
    "text": "how do you look at securing the data",
    "start": "174319",
    "end": "176239"
  },
  {
    "text": "transition",
    "start": "176239",
    "end": "177599"
  },
  {
    "text": "and then last but not least when you're",
    "start": "177599",
    "end": "179599"
  },
  {
    "text": "running this in production",
    "start": "179599",
    "end": "181200"
  },
  {
    "text": "how do you look at operationality or",
    "start": "181200",
    "end": "183519"
  },
  {
    "text": "ways to minimize",
    "start": "183519",
    "end": "185440"
  },
  {
    "text": "the performance impacts uh at a larger",
    "start": "185440",
    "end": "188480"
  },
  {
    "text": "scale",
    "start": "188480",
    "end": "189760"
  },
  {
    "text": "so what we're we'll talk about in in",
    "start": "189760",
    "end": "192080"
  },
  {
    "start": "190000",
    "end": "385000"
  },
  {
    "text": "this session is how into it solved many",
    "start": "192080",
    "end": "193840"
  },
  {
    "text": "of these challenges",
    "start": "193840",
    "end": "195200"
  },
  {
    "text": "uh but also how fluent d influent bit",
    "start": "195200",
    "end": "198159"
  },
  {
    "text": "have solved these challenges",
    "start": "198159",
    "end": "199920"
  },
  {
    "text": "over the course of the 10 years that",
    "start": "199920",
    "end": "201519"
  },
  {
    "text": "that project's been running",
    "start": "201519",
    "end": "203200"
  },
  {
    "text": "one is filtering parsing and compression",
    "start": "203200",
    "end": "205440"
  },
  {
    "text": "so support for",
    "start": "205440",
    "end": "206879"
  },
  {
    "text": "compressing workloads being able to take",
    "start": "206879",
    "end": "209440"
  },
  {
    "text": "data and throw away stuff that isn't",
    "start": "209440",
    "end": "211440"
  },
  {
    "text": "used",
    "start": "211440",
    "end": "212319"
  },
  {
    "text": "parsing data so you can take log",
    "start": "212319",
    "end": "214400"
  },
  {
    "text": "messages and",
    "start": "214400",
    "end": "215599"
  },
  {
    "text": "make really good sense out of them so",
    "start": "215599",
    "end": "217440"
  },
  {
    "text": "taking like for example an apache http",
    "start": "217440",
    "end": "219760"
  },
  {
    "text": "server log",
    "start": "219760",
    "end": "220959"
  },
  {
    "text": "and giving you the additional",
    "start": "220959",
    "end": "223360"
  },
  {
    "text": "information like ips which you can then",
    "start": "223360",
    "end": "225440"
  },
  {
    "text": "go enrich with geo",
    "start": "225440",
    "end": "226879"
  },
  {
    "text": "information things like",
    "start": "226879",
    "end": "230319"
  },
  {
    "text": "source ip the request type reliability",
    "start": "230319",
    "end": "234000"
  },
  {
    "text": "and buffering",
    "start": "234000",
    "end": "234720"
  },
  {
    "text": "so within fluency influence bit there",
    "start": "234720",
    "end": "236799"
  },
  {
    "text": "are file system and memory buffers",
    "start": "236799",
    "end": "239040"
  },
  {
    "text": "so if you need really fast performance",
    "start": "239040",
    "end": "241599"
  },
  {
    "text": "and you want to send bulk messages you",
    "start": "241599",
    "end": "243200"
  },
  {
    "text": "can use the memory buffer by default",
    "start": "243200",
    "end": "245680"
  },
  {
    "text": "but both of these projects also support",
    "start": "245680",
    "end": "247360"
  },
  {
    "text": "file system buffering",
    "start": "247360",
    "end": "248720"
  },
  {
    "text": "which is great in case of things",
    "start": "248720",
    "end": "250799"
  },
  {
    "text": "crashing",
    "start": "250799",
    "end": "252319"
  },
  {
    "text": "for example you might have a server that",
    "start": "252319",
    "end": "254879"
  },
  {
    "text": "goes down",
    "start": "254879",
    "end": "255840"
  },
  {
    "text": "but because you're storing everything on",
    "start": "255840",
    "end": "257519"
  },
  {
    "text": "the file system",
    "start": "257519",
    "end": "258880"
  },
  {
    "text": "you're able to recover all of that",
    "start": "258880",
    "end": "260320"
  },
  {
    "text": "information none of that data is lost",
    "start": "260320",
    "end": "262160"
  },
  {
    "text": "they all follow in at least once",
    "start": "262160",
    "end": "263919"
  },
  {
    "text": "mechanism",
    "start": "263919",
    "end": "265440"
  },
  {
    "text": "which leads into networking so when",
    "start": "265440",
    "end": "267520"
  },
  {
    "text": "networking goes down",
    "start": "267520",
    "end": "269040"
  },
  {
    "text": "we don't lose data we have a",
    "start": "269040",
    "end": "270800"
  },
  {
    "text": "configurable retry mechanism",
    "start": "270800",
    "end": "273280"
  },
  {
    "text": "as well as back pressure handling so as",
    "start": "273280",
    "end": "275759"
  },
  {
    "text": "the load increases",
    "start": "275759",
    "end": "277440"
  },
  {
    "text": "from say a file or an application",
    "start": "277440",
    "end": "281520"
  },
  {
    "text": "fluentbit is able to understand that",
    "start": "281520",
    "end": "284880"
  },
  {
    "text": "maybe the application can't receive too",
    "start": "284880",
    "end": "286639"
  },
  {
    "text": "many messages at the second",
    "start": "286639",
    "end": "288479"
  },
  {
    "text": "and we'll recover try at a at a",
    "start": "288479",
    "end": "290880"
  },
  {
    "text": "desirable time",
    "start": "290880",
    "end": "292080"
  },
  {
    "text": "in the future and especially when you're",
    "start": "292080",
    "end": "294560"
  },
  {
    "text": "logging at scale you might have",
    "start": "294560",
    "end": "296560"
  },
  {
    "text": "thousands and thousands of endpoints or",
    "start": "296560",
    "end": "298479"
  },
  {
    "text": "thousands and thousands of applications",
    "start": "298479",
    "end": "300160"
  },
  {
    "text": "logging data",
    "start": "300160",
    "end": "301919"
  },
  {
    "text": "how do you make sure that all these",
    "start": "301919",
    "end": "303120"
  },
  {
    "text": "retries don't try exactly at the same",
    "start": "303120",
    "end": "305680"
  },
  {
    "text": "time and unfortunately",
    "start": "305680",
    "end": "307039"
  },
  {
    "text": "cause the denial of service these are",
    "start": "307039",
    "end": "309360"
  },
  {
    "text": "places where we've built a lot of that",
    "start": "309360",
    "end": "311520"
  },
  {
    "text": "functionality within the open source",
    "start": "311520",
    "end": "313520"
  },
  {
    "text": "fluentine fluid bit",
    "start": "313520",
    "end": "315600"
  },
  {
    "text": "event throughput another place where",
    "start": "315600",
    "end": "318720"
  },
  {
    "text": "if you need additional performance and",
    "start": "318720",
    "end": "321680"
  },
  {
    "text": "you have the resources to dedicate you",
    "start": "321680",
    "end": "324080"
  },
  {
    "text": "can use aspects like multi-worker",
    "start": "324080",
    "end": "326000"
  },
  {
    "text": "configuration in both 4d",
    "start": "326000",
    "end": "327680"
  },
  {
    "text": "and fluent bit and and give you the",
    "start": "327680",
    "end": "330160"
  },
  {
    "text": "ability to utilize",
    "start": "330160",
    "end": "332240"
  },
  {
    "text": "a lot of the server resources that you",
    "start": "332240",
    "end": "334560"
  },
  {
    "text": "have at your disposal",
    "start": "334560",
    "end": "336479"
  },
  {
    "text": "with security there's two places to this",
    "start": "336479",
    "end": "339120"
  },
  {
    "text": "if you're securing sensitive information",
    "start": "339120",
    "end": "341360"
  },
  {
    "text": "you can use anonymization filters you",
    "start": "341360",
    "end": "343759"
  },
  {
    "text": "can use parsing to remove those",
    "start": "343759",
    "end": "346479"
  },
  {
    "text": "secure fields and then of course with",
    "start": "346479",
    "end": "348960"
  },
  {
    "text": "tls",
    "start": "348960",
    "end": "349759"
  },
  {
    "text": "both fluently influent bit support the",
    "start": "349759",
    "end": "352000"
  },
  {
    "text": "ability for",
    "start": "352000",
    "end": "353199"
  },
  {
    "text": "encryption and transit operationally",
    "start": "353199",
    "end": "356639"
  },
  {
    "text": "we we can use things like different",
    "start": "356639",
    "end": "358880"
  },
  {
    "text": "architectures",
    "start": "358880",
    "end": "359840"
  },
  {
    "text": "so both products both projects have been",
    "start": "359840",
    "end": "362880"
  },
  {
    "text": "designed with this ease of use and",
    "start": "362880",
    "end": "365840"
  },
  {
    "text": "flexibility in mind",
    "start": "365840",
    "end": "367280"
  },
  {
    "text": "you might want to minimize the resources",
    "start": "367280",
    "end": "370080"
  },
  {
    "text": "spent",
    "start": "370080",
    "end": "370639"
  },
  {
    "text": "say at your source within containers",
    "start": "370639",
    "end": "373280"
  },
  {
    "text": "within your kubernetes nodes",
    "start": "373280",
    "end": "375520"
  },
  {
    "text": "within your servers and do more of that",
    "start": "375520",
    "end": "378160"
  },
  {
    "text": "processing at a centralized layer",
    "start": "378160",
    "end": "380960"
  },
  {
    "text": "and we call that the forwarder aggregate",
    "start": "380960",
    "end": "383199"
  },
  {
    "text": "aggregator called",
    "start": "383199",
    "end": "384160"
  },
  {
    "text": "architecture so just some common",
    "start": "384160",
    "end": "386400"
  },
  {
    "start": "385000",
    "end": "487000"
  },
  {
    "text": "architecture",
    "start": "386400",
    "end": "387280"
  },
  {
    "text": "patterns right we have the forwarder",
    "start": "387280",
    "end": "389199"
  },
  {
    "text": "only which",
    "start": "389199",
    "end": "390560"
  },
  {
    "text": "allows you to take all of these sources",
    "start": "390560",
    "end": "393039"
  },
  {
    "text": "and independent pieces",
    "start": "393039",
    "end": "394960"
  },
  {
    "text": "and send data they each individually",
    "start": "394960",
    "end": "397280"
  },
  {
    "text": "handle",
    "start": "397280",
    "end": "398160"
  },
  {
    "text": "back pressure so you're not necessarily",
    "start": "398160",
    "end": "400639"
  },
  {
    "text": "relying on a single point",
    "start": "400639",
    "end": "402400"
  },
  {
    "text": "to grapple the data enrich it and then",
    "start": "402400",
    "end": "405120"
  },
  {
    "text": "send it out",
    "start": "405120",
    "end": "406720"
  },
  {
    "text": "the disadvantages is you have to do a",
    "start": "406720",
    "end": "408560"
  },
  {
    "text": "little bit more configuration management",
    "start": "408560",
    "end": "410880"
  },
  {
    "text": "um and it is sometimes hard to end more",
    "start": "410880",
    "end": "412960"
  },
  {
    "text": "destinations which falls a little bit",
    "start": "412960",
    "end": "414960"
  },
  {
    "text": "with",
    "start": "414960",
    "end": "415520"
  },
  {
    "text": "the configuration right if i'm sending",
    "start": "415520",
    "end": "417520"
  },
  {
    "text": "data to",
    "start": "417520",
    "end": "418639"
  },
  {
    "text": "uh splunk elasticsearch and kafka at the",
    "start": "418639",
    "end": "421199"
  },
  {
    "text": "same time",
    "start": "421199",
    "end": "422800"
  },
  {
    "text": "i might have to go and configure that",
    "start": "422800",
    "end": "424960"
  },
  {
    "text": "individually on a",
    "start": "424960",
    "end": "426319"
  },
  {
    "text": "on a forwarder basis now a common",
    "start": "426319",
    "end": "430000"
  },
  {
    "text": "architecture pattern we see with large",
    "start": "430000",
    "end": "431840"
  },
  {
    "text": "scale is forwarders with aggregators",
    "start": "431840",
    "end": "435120"
  },
  {
    "text": "so that is going to be less resource",
    "start": "435120",
    "end": "437120"
  },
  {
    "text": "utilization on the edge devices",
    "start": "437120",
    "end": "439199"
  },
  {
    "text": "all they're doing is collecting that",
    "start": "439199",
    "end": "440720"
  },
  {
    "text": "data and forwarding it onto an",
    "start": "440720",
    "end": "442240"
  },
  {
    "text": "aggregator",
    "start": "442240",
    "end": "443199"
  },
  {
    "text": "it allows you to process and and scale",
    "start": "443199",
    "end": "445520"
  },
  {
    "text": "the aggregator to your independently",
    "start": "445520",
    "end": "447840"
  },
  {
    "text": "you can add more back ends with this",
    "start": "447840",
    "end": "449680"
  },
  {
    "text": "with in a single tier",
    "start": "449680",
    "end": "451599"
  },
  {
    "text": "and then of course the disadvantagers",
    "start": "451599",
    "end": "453280"
  },
  {
    "text": "you do have to dedicate some of",
    "start": "453280",
    "end": "455360"
  },
  {
    "text": "the aggregator instance now that's all",
    "start": "455360",
    "end": "458160"
  },
  {
    "text": "for",
    "start": "458160",
    "end": "458560"
  },
  {
    "text": "just a general overview of how fluenty",
    "start": "458560",
    "end": "461360"
  },
  {
    "text": "and fluent bit uh",
    "start": "461360",
    "end": "462479"
  },
  {
    "text": "our projects other employees within the",
    "start": "462479",
    "end": "464879"
  },
  {
    "text": "cloud native computing foundation",
    "start": "464879",
    "end": "467120"
  },
  {
    "text": "and now how you can look at some of the",
    "start": "467120",
    "end": "469120"
  },
  {
    "text": "challenges that they solve for",
    "start": "469120",
    "end": "470720"
  },
  {
    "text": "for at scale i'm really happy to pass it",
    "start": "470720",
    "end": "473599"
  },
  {
    "text": "over to hansel who's going to be able to",
    "start": "473599",
    "end": "475919"
  },
  {
    "text": "talk a bit about",
    "start": "475919",
    "end": "477039"
  },
  {
    "text": "the use case specifics add intuit and",
    "start": "477039",
    "end": "479440"
  },
  {
    "text": "give us",
    "start": "479440",
    "end": "480879"
  },
  {
    "text": "an idea how petabyte scale can can be",
    "start": "480879",
    "end": "483039"
  },
  {
    "text": "achieved in reality",
    "start": "483039",
    "end": "484319"
  },
  {
    "text": "so with that let me hand it over to",
    "start": "484319",
    "end": "485919"
  },
  {
    "text": "hazel",
    "start": "485919",
    "end": "488000"
  },
  {
    "start": "487000",
    "end": "517000"
  },
  {
    "text": "thank you interact now we'll get into",
    "start": "488000",
    "end": "490080"
  },
  {
    "text": "the use case i can into it into it",
    "start": "490080",
    "end": "491680"
  },
  {
    "text": "provides financial solution for",
    "start": "491680",
    "end": "493120"
  },
  {
    "text": "consumers",
    "start": "493120",
    "end": "493919"
  },
  {
    "text": "small businesses and self-employed",
    "start": "493919",
    "end": "495759"
  },
  {
    "text": "individuals",
    "start": "495759",
    "end": "497120"
  },
  {
    "text": "major products from intuit include turbo",
    "start": "497120",
    "end": "498960"
  },
  {
    "text": "tax quickbooks and mint",
    "start": "498960",
    "end": "501680"
  },
  {
    "text": "at into it kubernetes is adopted widely",
    "start": "501680",
    "end": "504240"
  },
  {
    "text": "across four business units",
    "start": "504240",
    "end": "506319"
  },
  {
    "text": "it's used extensively at over 30",
    "start": "506319",
    "end": "508319"
  },
  {
    "text": "segments with more than 5000 engineers",
    "start": "508319",
    "end": "510800"
  },
  {
    "text": "onboarded to it",
    "start": "510800",
    "end": "512320"
  },
  {
    "text": "we also have over 80 engineers",
    "start": "512320",
    "end": "514080"
  },
  {
    "text": "developing our kubernetes platform",
    "start": "514080",
    "end": "517440"
  },
  {
    "start": "517000",
    "end": "689000"
  },
  {
    "text": "we'll see how fluent d and fluent bet",
    "start": "517440",
    "end": "519518"
  },
  {
    "text": "are used to handle logging",
    "start": "519519",
    "end": "521120"
  },
  {
    "text": "from kubernetes cluster set into it the",
    "start": "521120",
    "end": "523839"
  },
  {
    "text": "use case",
    "start": "523839",
    "end": "524560"
  },
  {
    "text": "is to transport logs generated within",
    "start": "524560",
    "end": "526720"
  },
  {
    "text": "the container",
    "start": "526720",
    "end": "527839"
  },
  {
    "text": "which is returned to std out or std",
    "start": "527839",
    "end": "530000"
  },
  {
    "text": "error stream to our persistent lock",
    "start": "530000",
    "end": "532839"
  },
  {
    "text": "store",
    "start": "532839",
    "end": "534399"
  },
  {
    "text": "to enable this we have a daemon set",
    "start": "534399",
    "end": "536000"
  },
  {
    "text": "deployed in the cluster",
    "start": "536000",
    "end": "537440"
  },
  {
    "text": "this ensures that a logging part is",
    "start": "537440",
    "end": "539279"
  },
  {
    "text": "present in each and every node",
    "start": "539279",
    "end": "541120"
  },
  {
    "text": "this part contains fluency of one bit",
    "start": "541120",
    "end": "543440"
  },
  {
    "text": "which is then responsible for collecting",
    "start": "543440",
    "end": "545120"
  },
  {
    "text": "the",
    "start": "545120",
    "end": "545519"
  },
  {
    "text": "and forwarding the logs from that entire",
    "start": "545519",
    "end": "547360"
  },
  {
    "text": "node",
    "start": "547360",
    "end": "548720"
  },
  {
    "text": "the docker logging plugin fights logs",
    "start": "548720",
    "end": "550720"
  },
  {
    "text": "into the files which are tailed and",
    "start": "550720",
    "end": "552320"
  },
  {
    "text": "processed",
    "start": "552320",
    "end": "553600"
  },
  {
    "text": "the log events must also be enriched",
    "start": "553600",
    "end": "555279"
  },
  {
    "text": "with some metadata",
    "start": "555279",
    "end": "556959"
  },
  {
    "text": "this would enable us to identify the",
    "start": "556959",
    "end": "558560"
  },
  {
    "text": "cluster namespace",
    "start": "558560",
    "end": "560000"
  },
  {
    "text": "power and container where each event",
    "start": "560000",
    "end": "562000"
  },
  {
    "text": "originates from",
    "start": "562000",
    "end": "563120"
  },
  {
    "text": "when running search queries at the log",
    "start": "563120",
    "end": "564560"
  },
  {
    "text": "store and all this must be fast",
    "start": "564560",
    "end": "567440"
  },
  {
    "text": "and efficient we want to be able to",
    "start": "567440",
    "end": "569440"
  },
  {
    "text": "transport huge volumes of data",
    "start": "569440",
    "end": "571360"
  },
  {
    "text": "with as low end-to-end latency as",
    "start": "571360",
    "end": "573279"
  },
  {
    "text": "possible",
    "start": "573279",
    "end": "575200"
  },
  {
    "text": "we have a centralized persistent log",
    "start": "575200",
    "end": "576880"
  },
  {
    "text": "store where all",
    "start": "576880",
    "end": "578320"
  },
  {
    "text": "customers can see and query log events",
    "start": "578320",
    "end": "581040"
  },
  {
    "text": "we wanted a common path to transport all",
    "start": "581040",
    "end": "583440"
  },
  {
    "text": "the logs",
    "start": "583440",
    "end": "584320"
  },
  {
    "text": "and it's a pipeline this would simplify",
    "start": "584320",
    "end": "586720"
  },
  {
    "text": "the connectivity between the vpcs",
    "start": "586720",
    "end": "588560"
  },
  {
    "text": "containing the kubernetes clusters",
    "start": "588560",
    "end": "590560"
  },
  {
    "text": "and the vpc containing the log store",
    "start": "590560",
    "end": "593760"
  },
  {
    "text": "you only have to expose the log store to",
    "start": "593760",
    "end": "595680"
  },
  {
    "text": "the pipeline instead of all the clusters",
    "start": "595680",
    "end": "598160"
  },
  {
    "text": "this helps us avoid sending the log",
    "start": "598160",
    "end": "600160"
  },
  {
    "text": "events over the internet",
    "start": "600160",
    "end": "602000"
  },
  {
    "text": "sending data over the internet is very",
    "start": "602000",
    "end": "604000"
  },
  {
    "text": "expensive and we can cut down the cost",
    "start": "604000",
    "end": "605760"
  },
  {
    "text": "drastically by sending data through aws",
    "start": "605760",
    "end": "608000"
  },
  {
    "text": "network only",
    "start": "608000",
    "end": "610480"
  },
  {
    "text": "during any connectivity issues with the",
    "start": "610480",
    "end": "611920"
  },
  {
    "text": "lock store once the buffers get filled",
    "start": "611920",
    "end": "614240"
  },
  {
    "text": "up",
    "start": "614240",
    "end": "614880"
  },
  {
    "text": "the logs are gone for good if you have",
    "start": "614880",
    "end": "617360"
  },
  {
    "text": "an intermediate",
    "start": "617360",
    "end": "618079"
  },
  {
    "text": "store for these logs this can be",
    "start": "618079",
    "end": "620079"
  },
  {
    "text": "prevented",
    "start": "620079",
    "end": "621200"
  },
  {
    "text": "this also provides an opportunity for",
    "start": "621200",
    "end": "622959"
  },
  {
    "text": "other applications to read",
    "start": "622959",
    "end": "624560"
  },
  {
    "text": "the raw log data this is especially",
    "start": "624560",
    "end": "627040"
  },
  {
    "text": "useful for security compliance and",
    "start": "627040",
    "end": "628800"
  },
  {
    "text": "analytics applications",
    "start": "628800",
    "end": "631440"
  },
  {
    "text": "this is our name approach which is a",
    "start": "631440",
    "end": "633120"
  },
  {
    "text": "string pipeline there is a demonstrator",
    "start": "633120",
    "end": "636000"
  },
  {
    "text": "so each kubernetes node",
    "start": "636000",
    "end": "637760"
  },
  {
    "text": "will have a logging port running in it",
    "start": "637760",
    "end": "640160"
  },
  {
    "text": "this part will tell the log file from",
    "start": "640160",
    "end": "642079"
  },
  {
    "text": "the host mounted as volume",
    "start": "642079",
    "end": "644720"
  },
  {
    "text": "there is a fluent bit plugin that gets",
    "start": "644720",
    "end": "646640"
  },
  {
    "text": "the community's metadata from its api",
    "start": "646640",
    "end": "648800"
  },
  {
    "text": "and enriches the log events with that",
    "start": "648800",
    "end": "651279"
  },
  {
    "text": "these enriched log events are then sent",
    "start": "651279",
    "end": "653440"
  },
  {
    "text": "to a kinesis data stream",
    "start": "653440",
    "end": "655680"
  },
  {
    "text": "the events are then routed to kinesis",
    "start": "655680",
    "end": "657680"
  },
  {
    "text": "firehose",
    "start": "657680",
    "end": "658800"
  },
  {
    "text": "now the kinesis fire hose has a native",
    "start": "658800",
    "end": "661040"
  },
  {
    "text": "capability to write to the log store and",
    "start": "661040",
    "end": "662959"
  },
  {
    "text": "that's how the english log data",
    "start": "662959",
    "end": "664880"
  },
  {
    "text": "gets to the persistent store this",
    "start": "664880",
    "end": "667680"
  },
  {
    "text": "provides a reliable",
    "start": "667680",
    "end": "668959"
  },
  {
    "text": "scalable mechanism to transport the logs",
    "start": "668959",
    "end": "671760"
  },
  {
    "text": "from hundreds of kubernetes cluster",
    "start": "671760",
    "end": "674000"
  },
  {
    "text": "onto a centralized position log store",
    "start": "674000",
    "end": "677120"
  },
  {
    "text": "we only need access to the lobster from",
    "start": "677120",
    "end": "679040"
  },
  {
    "text": "fire hose and this data transfer",
    "start": "679040",
    "end": "680959"
  },
  {
    "text": "happened within a releases network",
    "start": "680959",
    "end": "683120"
  },
  {
    "text": "also the logs can be read from kinesis",
    "start": "683120",
    "end": "685279"
  },
  {
    "text": "data stream",
    "start": "685279",
    "end": "686320"
  },
  {
    "text": "while just using a consumer this",
    "start": "686320",
    "end": "689519"
  },
  {
    "start": "689000",
    "end": "800000"
  },
  {
    "text": "pipeline was working well for us",
    "start": "689519",
    "end": "691120"
  },
  {
    "text": "initially",
    "start": "691120",
    "end": "692079"
  },
  {
    "text": "but as we started supporting more and",
    "start": "692079",
    "end": "694399"
  },
  {
    "text": "larger cluster",
    "start": "694399",
    "end": "695600"
  },
  {
    "text": "we started facing some challenges",
    "start": "695600",
    "end": "698640"
  },
  {
    "text": "with this pipeline we had a hard limit",
    "start": "698640",
    "end": "700480"
  },
  {
    "text": "on the number of events that can be",
    "start": "700480",
    "end": "702160"
  },
  {
    "text": "transported every second",
    "start": "702160",
    "end": "703680"
  },
  {
    "text": "in each pod with the solution that used",
    "start": "703680",
    "end": "706720"
  },
  {
    "text": "fluency",
    "start": "706720",
    "end": "707440"
  },
  {
    "text": "as a logging container we were capped at",
    "start": "707440",
    "end": "709760"
  },
  {
    "text": "2500 events per second per node",
    "start": "709760",
    "end": "713200"
  },
  {
    "text": "once we should serve it to fluent bit",
    "start": "713200",
    "end": "714800"
  },
  {
    "text": "base logging container we were able to",
    "start": "714800",
    "end": "717120"
  },
  {
    "text": "double that limit to 5000 events per",
    "start": "717120",
    "end": "719440"
  },
  {
    "text": "second per node",
    "start": "719440",
    "end": "721200"
  },
  {
    "text": "however this was still not enough",
    "start": "721200",
    "end": "723200"
  },
  {
    "text": "especially for larger nodes which",
    "start": "723200",
    "end": "724800"
  },
  {
    "text": "contain a lot of containers packed",
    "start": "724800",
    "end": "726399"
  },
  {
    "text": "inside",
    "start": "726399",
    "end": "728160"
  },
  {
    "text": "also as you saw there are two hops",
    "start": "728160",
    "end": "730000"
  },
  {
    "text": "between the cluster and the log store",
    "start": "730000",
    "end": "732079"
  },
  {
    "text": "each of these hops were introducing some",
    "start": "732079",
    "end": "733839"
  },
  {
    "text": "latency",
    "start": "733839",
    "end": "735120"
  },
  {
    "text": "which was quickly adding up we started",
    "start": "735120",
    "end": "738000"
  },
  {
    "text": "seeing the median n2 and latency getting",
    "start": "738000",
    "end": "740000"
  },
  {
    "text": "as high as 30 seconds",
    "start": "740000",
    "end": "742000"
  },
  {
    "text": "this was not acceptable for our most",
    "start": "742000",
    "end": "744240"
  },
  {
    "text": "time critical applications",
    "start": "744240",
    "end": "745680"
  },
  {
    "text": "so we decided to reduce the number of",
    "start": "745680",
    "end": "747200"
  },
  {
    "text": "hops and hence the time it takes for the",
    "start": "747200",
    "end": "749360"
  },
  {
    "text": "transport",
    "start": "749360",
    "end": "751440"
  },
  {
    "text": "to maintain this streaming pipeline we",
    "start": "751440",
    "end": "753440"
  },
  {
    "text": "had to have",
    "start": "753440",
    "end": "754560"
  },
  {
    "text": "some persistent resources running the",
    "start": "754560",
    "end": "756880"
  },
  {
    "text": "lock load",
    "start": "756880",
    "end": "757680"
  },
  {
    "text": "that needed to be transported was",
    "start": "757680",
    "end": "759760"
  },
  {
    "text": "extremely elastic",
    "start": "759760",
    "end": "760880"
  },
  {
    "text": "especially based on different times of",
    "start": "760880",
    "end": "762480"
  },
  {
    "text": "the day",
    "start": "762480",
    "end": "764000"
  },
  {
    "text": "however these resources even with the",
    "start": "764000",
    "end": "765920"
  },
  {
    "text": "auto scaling enable",
    "start": "765920",
    "end": "767279"
  },
  {
    "text": "were not able to scale efficiently to",
    "start": "767279",
    "end": "769120"
  },
  {
    "text": "match that log load",
    "start": "769120",
    "end": "771120"
  },
  {
    "text": "this was making the pipeline inefficient",
    "start": "771120",
    "end": "773200"
  },
  {
    "text": "in terms of the cost",
    "start": "773200",
    "end": "774399"
  },
  {
    "text": "and ended up being too expensive we",
    "start": "774399",
    "end": "776639"
  },
  {
    "text": "wanted to cut down some costs as well",
    "start": "776639",
    "end": "778720"
  },
  {
    "text": "so in simpler terms the target for the",
    "start": "778720",
    "end": "781200"
  },
  {
    "text": "new pipeline",
    "start": "781200",
    "end": "782079"
  },
  {
    "text": "were to increase the throughput",
    "start": "782079",
    "end": "783519"
  },
  {
    "text": "dramatically without increasing the",
    "start": "783519",
    "end": "785360"
  },
  {
    "text": "resource consumption by that",
    "start": "785360",
    "end": "786880"
  },
  {
    "text": "port reduce the end-to-end latency of",
    "start": "786880",
    "end": "789760"
  },
  {
    "text": "the log transport pipeline as much as",
    "start": "789760",
    "end": "791600"
  },
  {
    "text": "possible",
    "start": "791600",
    "end": "792560"
  },
  {
    "text": "and to minimize the cost needed to",
    "start": "792560",
    "end": "794160"
  },
  {
    "text": "maintain it",
    "start": "794160",
    "end": "795600"
  },
  {
    "text": "and this is where the s3 pipeline comes",
    "start": "795600",
    "end": "797920"
  },
  {
    "text": "into play",
    "start": "797920",
    "end": "800959"
  },
  {
    "start": "800000",
    "end": "941000"
  },
  {
    "text": "this is how the architecture of s3",
    "start": "800959",
    "end": "802800"
  },
  {
    "text": "pipeline looks like",
    "start": "802800",
    "end": "804880"
  },
  {
    "text": "the space enclosed by the blue dashed",
    "start": "804880",
    "end": "806880"
  },
  {
    "text": "line represent",
    "start": "806880",
    "end": "808320"
  },
  {
    "text": "a node running in the kubernetes cluster",
    "start": "808320",
    "end": "811200"
  },
  {
    "text": "each node contains a daemon set power",
    "start": "811200",
    "end": "813440"
  },
  {
    "text": "containing fluently the locks written by",
    "start": "813440",
    "end": "816639"
  },
  {
    "text": "the container on its std out and std",
    "start": "816639",
    "end": "818959"
  },
  {
    "text": "error streams",
    "start": "818959",
    "end": "819839"
  },
  {
    "text": "will be written as files that are",
    "start": "819839",
    "end": "821680"
  },
  {
    "text": "rotated in the node",
    "start": "821680",
    "end": "823360"
  },
  {
    "text": "and it's all done by the docker daemon",
    "start": "823360",
    "end": "826240"
  },
  {
    "text": "these files are exposed to the container",
    "start": "826240",
    "end": "828160"
  },
  {
    "text": "by using a volume mounted directly onto",
    "start": "828160",
    "end": "830399"
  },
  {
    "text": "the host",
    "start": "830399",
    "end": "831519"
  },
  {
    "text": "the fluency container then tails these",
    "start": "831519",
    "end": "833600"
  },
  {
    "text": "files and listens for any new log events",
    "start": "833600",
    "end": "836480"
  },
  {
    "text": "and for any new log events fluently",
    "start": "836480",
    "end": "838240"
  },
  {
    "text": "pushes it onto a buffer which is",
    "start": "838240",
    "end": "839760"
  },
  {
    "text": "specific for each container",
    "start": "839760",
    "end": "841440"
  },
  {
    "text": "at a certain fixed interval 10 seconds",
    "start": "841440",
    "end": "843600"
  },
  {
    "text": "in this case",
    "start": "843600",
    "end": "844800"
  },
  {
    "text": "the buffers are flush onto an s3 bucket",
    "start": "844800",
    "end": "847839"
  },
  {
    "text": "object after compressing it with g6 so",
    "start": "847839",
    "end": "850480"
  },
  {
    "text": "each s3 object would contain logs",
    "start": "850480",
    "end": "852320"
  },
  {
    "text": "generated by the container for 10",
    "start": "852320",
    "end": "853920"
  },
  {
    "text": "seconds compressed as a jzip file",
    "start": "853920",
    "end": "856720"
  },
  {
    "text": "in the pipeline fluently is not",
    "start": "856720",
    "end": "858160"
  },
  {
    "text": "responsible for enriching the log data",
    "start": "858160",
    "end": "860000"
  },
  {
    "text": "with metadata",
    "start": "860000",
    "end": "861040"
  },
  {
    "text": "but rather provides the logs as is onto",
    "start": "861040",
    "end": "863199"
  },
  {
    "text": "the object",
    "start": "863199",
    "end": "865040"
  },
  {
    "text": "now we have a separate deployment in the",
    "start": "865040",
    "end": "866560"
  },
  {
    "text": "cluster which ensures that a single",
    "start": "866560",
    "end": "868399"
  },
  {
    "text": "power will be running across this",
    "start": "868399",
    "end": "869839"
  },
  {
    "text": "cluster",
    "start": "869839",
    "end": "870880"
  },
  {
    "text": "this deployment communicates with",
    "start": "870880",
    "end": "872399"
  },
  {
    "text": "kubernetes api and gets information",
    "start": "872399",
    "end": "874639"
  },
  {
    "text": "about any new containers for any new",
    "start": "874639",
    "end": "877360"
  },
  {
    "text": "containers created in the cluster",
    "start": "877360",
    "end": "878880"
  },
  {
    "text": "it will fetch its placement and other",
    "start": "878880",
    "end": "880880"
  },
  {
    "text": "metadata including its labels and",
    "start": "880880",
    "end": "882720"
  },
  {
    "text": "annotations",
    "start": "882720",
    "end": "883760"
  },
  {
    "text": "and pushes it on to a separate extra",
    "start": "883760",
    "end": "885600"
  },
  {
    "text": "bucket",
    "start": "885600",
    "end": "887519"
  },
  {
    "text": "within the log pipeline vpc we have a",
    "start": "887519",
    "end": "890079"
  },
  {
    "text": "deployment running in",
    "start": "890079",
    "end": "891120"
  },
  {
    "text": "aws far gate this deployment listens to",
    "start": "891120",
    "end": "893839"
  },
  {
    "text": "any new objects in the log s3 packet",
    "start": "893839",
    "end": "896079"
  },
  {
    "text": "for any new object in this bucket the",
    "start": "896079",
    "end": "897839"
  },
  {
    "text": "path would indicate the container for",
    "start": "897839",
    "end": "899440"
  },
  {
    "text": "which the logs are for",
    "start": "899440",
    "end": "900959"
  },
  {
    "text": "the log pipeline deployment then fetch",
    "start": "900959",
    "end": "902639"
  },
  {
    "text": "the corresponding metadata",
    "start": "902639",
    "end": "904240"
  },
  {
    "text": "from the metadata bucket both these are",
    "start": "904240",
    "end": "907040"
  },
  {
    "text": "then sent over together",
    "start": "907040",
    "end": "908639"
  },
  {
    "text": "onto the log store present in a separate",
    "start": "908639",
    "end": "910800"
  },
  {
    "text": "icon and bpc",
    "start": "910800",
    "end": "912560"
  },
  {
    "text": "this communication happens over aws's",
    "start": "912560",
    "end": "914959"
  },
  {
    "text": "transit gateway",
    "start": "914959",
    "end": "916320"
  },
  {
    "text": "the log store is then able to apply the",
    "start": "916320",
    "end": "918320"
  },
  {
    "text": "metadata to each and every event in the",
    "start": "918320",
    "end": "920399"
  },
  {
    "text": "log",
    "start": "920399",
    "end": "920800"
  },
  {
    "text": "s3 object the key takeaways in the",
    "start": "920800",
    "end": "923519"
  },
  {
    "text": "architecture are that the log data is",
    "start": "923519",
    "end": "925440"
  },
  {
    "text": "compressed from the cluster",
    "start": "925440",
    "end": "926880"
  },
  {
    "text": "and only deflated at the log store and",
    "start": "926880",
    "end": "929440"
  },
  {
    "text": "all the data transfer happens within the",
    "start": "929440",
    "end": "931120"
  },
  {
    "text": "aws network",
    "start": "931120",
    "end": "932399"
  },
  {
    "text": "and moreover crossover transfer have",
    "start": "932399",
    "end": "934880"
  },
  {
    "text": "been",
    "start": "934880",
    "end": "935440"
  },
  {
    "text": "via a transfer gateway created",
    "start": "935440",
    "end": "937360"
  },
  {
    "text": "specifically for that purpose",
    "start": "937360",
    "end": "941839"
  },
  {
    "start": "941000",
    "end": "1080000"
  },
  {
    "text": "as you can see fluently is deployed in",
    "start": "941920",
    "end": "944639"
  },
  {
    "text": "the cluster as a daemon set",
    "start": "944639",
    "end": "945839"
  },
  {
    "text": "this ensures that there is a single",
    "start": "945839",
    "end": "947440"
  },
  {
    "text": "power in every node",
    "start": "947440",
    "end": "949040"
  },
  {
    "text": "and each pod is then responsible for",
    "start": "949040",
    "end": "950959"
  },
  {
    "text": "transporting logs",
    "start": "950959",
    "end": "952480"
  },
  {
    "text": "from all the containers in that node",
    "start": "952480",
    "end": "954880"
  },
  {
    "text": "regardless of how big that node is",
    "start": "954880",
    "end": "957279"
  },
  {
    "text": "from this we can realize that this part",
    "start": "957279",
    "end": "958880"
  },
  {
    "text": "will become the bottleneck and the",
    "start": "958880",
    "end": "960399"
  },
  {
    "text": "weakest link in the chain",
    "start": "960399",
    "end": "962560"
  },
  {
    "text": "so the throughput will be set by the",
    "start": "962560",
    "end": "964639"
  },
  {
    "text": "moon that can be transported by a single",
    "start": "964639",
    "end": "966839"
  },
  {
    "text": "part",
    "start": "966839",
    "end": "968160"
  },
  {
    "text": "the biggest gain in the throughput can",
    "start": "968160",
    "end": "969839"
  },
  {
    "text": "be achieved by making demonstrate",
    "start": "969839",
    "end": "971519"
  },
  {
    "text": "process transport more and more events",
    "start": "971519",
    "end": "974399"
  },
  {
    "text": "one mechanism to achieve this is to do",
    "start": "974399",
    "end": "976720"
  },
  {
    "text": "as little",
    "start": "976720",
    "end": "977519"
  },
  {
    "text": "processing as possible at the daemon set",
    "start": "977519",
    "end": "979360"
  },
  {
    "text": "part",
    "start": "979360",
    "end": "981040"
  },
  {
    "text": "that is the key to note in the new",
    "start": "981040",
    "end": "983360"
  },
  {
    "text": "pipeline design",
    "start": "983360",
    "end": "984959"
  },
  {
    "text": "next we wanted to identify all the",
    "start": "984959",
    "end": "986639"
  },
  {
    "text": "things that can be offloaded from the",
    "start": "986639",
    "end": "988240"
  },
  {
    "text": "fluency",
    "start": "988240",
    "end": "988959"
  },
  {
    "text": "and how we facilitate that function",
    "start": "988959",
    "end": "991040"
  },
  {
    "text": "elsewhere",
    "start": "991040",
    "end": "992639"
  },
  {
    "text": "after multiplication we were able to",
    "start": "992639",
    "end": "994399"
  },
  {
    "text": "pick two cpu intensive",
    "start": "994399",
    "end": "996000"
  },
  {
    "text": "processors that can be offloaded without",
    "start": "996000",
    "end": "998240"
  },
  {
    "text": "any change in the events at the log",
    "start": "998240",
    "end": "999759"
  },
  {
    "text": "store",
    "start": "999759",
    "end": "1000800"
  },
  {
    "text": "these were providing us with this",
    "start": "1000800",
    "end": "1002160"
  },
  {
    "text": "massive genuine support",
    "start": "1002160",
    "end": "1004480"
  },
  {
    "text": "so the first thing that we were able to",
    "start": "1004480",
    "end": "1006000"
  },
  {
    "text": "offload was timestamp parsing",
    "start": "1006000",
    "end": "1008160"
  },
  {
    "text": "timestamp has to be passed from each",
    "start": "1008160",
    "end": "1009920"
  },
  {
    "text": "event for a couple of things",
    "start": "1009920",
    "end": "1011440"
  },
  {
    "text": "to attribute a timestamp for each event",
    "start": "1011440",
    "end": "1013680"
  },
  {
    "text": "and to identify the starting line",
    "start": "1013680",
    "end": "1015759"
  },
  {
    "text": "of new event in case of multi-line",
    "start": "1015759",
    "end": "1017440"
  },
  {
    "text": "events",
    "start": "1017440",
    "end": "1018959"
  },
  {
    "text": "this was very cpu intensive but we were",
    "start": "1018959",
    "end": "1021519"
  },
  {
    "text": "able to offload this onto our log store",
    "start": "1021519",
    "end": "1023680"
  },
  {
    "text": "without any change in the end user",
    "start": "1023680",
    "end": "1025280"
  },
  {
    "text": "experience",
    "start": "1025280",
    "end": "1026720"
  },
  {
    "text": "the second thing we offloaded is the",
    "start": "1026720",
    "end": "1028798"
  },
  {
    "text": "metadata enrichment",
    "start": "1028799",
    "end": "1030640"
  },
  {
    "text": "in the previous pipeline each event was",
    "start": "1030640",
    "end": "1032319"
  },
  {
    "text": "enriched with the required metadata by",
    "start": "1032319",
    "end": "1034160"
  },
  {
    "text": "fluency itself",
    "start": "1034160",
    "end": "1035760"
  },
  {
    "text": "this has now been offloaded and done by",
    "start": "1035760",
    "end": "1037918"
  },
  {
    "text": "the metadata deployment",
    "start": "1037919",
    "end": "1040558"
  },
  {
    "text": "external log pipeline deployment and the",
    "start": "1040559",
    "end": "1043280"
  },
  {
    "text": "log store",
    "start": "1043280",
    "end": "1044319"
  },
  {
    "text": "the metadata deployment communicates",
    "start": "1044319",
    "end": "1045918"
  },
  {
    "text": "with the kubernetes api",
    "start": "1045919",
    "end": "1047438"
  },
  {
    "text": "to get the required container metadata",
    "start": "1047439",
    "end": "1049440"
  },
  {
    "text": "in an s3 object",
    "start": "1049440",
    "end": "1050960"
  },
  {
    "text": "the external log pipeline deployment",
    "start": "1050960",
    "end": "1052400"
  },
  {
    "text": "then collates this container specific",
    "start": "1052400",
    "end": "1054240"
  },
  {
    "text": "metadata",
    "start": "1054240",
    "end": "1055120"
  },
  {
    "text": "with each s3 log object which is also",
    "start": "1055120",
    "end": "1057520"
  },
  {
    "text": "container specific",
    "start": "1057520",
    "end": "1059600"
  },
  {
    "text": "both these are then sent together to the",
    "start": "1059600",
    "end": "1061520"
  },
  {
    "text": "log store which is up which can then",
    "start": "1061520",
    "end": "1063120"
  },
  {
    "text": "apply the metadata to all the live",
    "start": "1063120",
    "end": "1065120"
  },
  {
    "text": "events in the file the additional",
    "start": "1065120",
    "end": "1067360"
  },
  {
    "text": "advantage with this is that the metadata",
    "start": "1067360",
    "end": "1069280"
  },
  {
    "text": "enrichment happens in batch",
    "start": "1069280",
    "end": "1070799"
  },
  {
    "text": "across all the events in ns3 object at",
    "start": "1070799",
    "end": "1072799"
  },
  {
    "text": "once this reduces the processing",
    "start": "1072799",
    "end": "1075440"
  },
  {
    "text": "needed and the amount of data transfer",
    "start": "1075440",
    "end": "1080799"
  },
  {
    "start": "1080000",
    "end": "1169000"
  },
  {
    "text": "when looking at the cost breakdown for",
    "start": "1080799",
    "end": "1082640"
  },
  {
    "text": "the pipeline we found that the data",
    "start": "1082640",
    "end": "1084400"
  },
  {
    "text": "transfer cost was the highest component",
    "start": "1084400",
    "end": "1087039"
  },
  {
    "text": "higher than even compute and storage",
    "start": "1087039",
    "end": "1090160"
  },
  {
    "text": "so if we can reduce the amount of data",
    "start": "1090160",
    "end": "1091840"
  },
  {
    "text": "sent over and use a more cost effective",
    "start": "1091840",
    "end": "1094640"
  },
  {
    "text": "way to transport it",
    "start": "1094640",
    "end": "1095840"
  },
  {
    "text": "they can make huge savings in the cost",
    "start": "1095840",
    "end": "1098320"
  },
  {
    "text": "one added benefit is that",
    "start": "1098320",
    "end": "1100160"
  },
  {
    "text": "as we reduce the amount of data transfer",
    "start": "1100160",
    "end": "1102559"
  },
  {
    "text": "the latency also goes down",
    "start": "1102559",
    "end": "1105600"
  },
  {
    "text": "as mentioned before fluently compresses",
    "start": "1105600",
    "end": "1107440"
  },
  {
    "text": "the data via gzip",
    "start": "1107440",
    "end": "1108880"
  },
  {
    "text": "and the buffer when it's flushed to an",
    "start": "1108880",
    "end": "1110559"
  },
  {
    "text": "s3 object",
    "start": "1110559",
    "end": "1111919"
  },
  {
    "text": "in our normal load load we were getting",
    "start": "1111919",
    "end": "1114480"
  },
  {
    "text": "around 10 times compression",
    "start": "1114480",
    "end": "1116240"
  },
  {
    "text": "this gc file then be returned to log",
    "start": "1116240",
    "end": "1119520"
  },
  {
    "text": "store asses",
    "start": "1119520",
    "end": "1120880"
  },
  {
    "text": "what that means is that the log data",
    "start": "1120880",
    "end": "1122640"
  },
  {
    "text": "stays compressed as soon as it leaves",
    "start": "1122640",
    "end": "1124400"
  },
  {
    "text": "the clusters",
    "start": "1124400",
    "end": "1125360"
  },
  {
    "text": "and until it reaches the long story or",
    "start": "1125360",
    "end": "1127520"
  },
  {
    "text": "the log data is always compressed in",
    "start": "1127520",
    "end": "1129280"
  },
  {
    "text": "transit",
    "start": "1129280",
    "end": "1130240"
  },
  {
    "text": "just this one change cut down the data",
    "start": "1130240",
    "end": "1131919"
  },
  {
    "text": "transferred to one tenth the volume to",
    "start": "1131919",
    "end": "1134400"
  },
  {
    "text": "that of before",
    "start": "1134400",
    "end": "1136000"
  },
  {
    "text": "also as we are applying the metadata in",
    "start": "1136000",
    "end": "1138240"
  },
  {
    "text": "batch for an entire",
    "start": "1138240",
    "end": "1139280"
  },
  {
    "text": "three object each object even need not",
    "start": "1139280",
    "end": "1141280"
  },
  {
    "text": "have the metadata along with it",
    "start": "1141280",
    "end": "1142960"
  },
  {
    "text": "this was also giving us large strings in",
    "start": "1142960",
    "end": "1144960"
  },
  {
    "text": "terms of the amount of data transferred",
    "start": "1144960",
    "end": "1146880"
  },
  {
    "text": "by cutting down the size of each row log",
    "start": "1146880",
    "end": "1148840"
  },
  {
    "text": "event",
    "start": "1148840",
    "end": "1150080"
  },
  {
    "text": "this is when we compare it to the",
    "start": "1150080",
    "end": "1151600"
  },
  {
    "text": "previous string pipeline",
    "start": "1151600",
    "end": "1153280"
  },
  {
    "text": "we also have set up an aws transit",
    "start": "1153280",
    "end": "1155360"
  },
  {
    "text": "gateway between our log pipeline vpc",
    "start": "1155360",
    "end": "1157760"
  },
  {
    "text": "and the log story pc and all the data",
    "start": "1157760",
    "end": "1160080"
  },
  {
    "text": "transfer happens through this",
    "start": "1160080",
    "end": "1162000"
  },
  {
    "text": "this was giving us around 60 in cost",
    "start": "1162000",
    "end": "1164240"
  },
  {
    "text": "saving as opposed to sending the data",
    "start": "1164240",
    "end": "1165840"
  },
  {
    "text": "over the internet",
    "start": "1165840",
    "end": "1166720"
  },
  {
    "text": "using an app gateway",
    "start": "1166720",
    "end": "1169760"
  },
  {
    "start": "1169000",
    "end": "1206000"
  },
  {
    "text": "to demonstrate how this new pipeline",
    "start": "1169760",
    "end": "1172080"
  },
  {
    "text": "performs i have set up a test united",
    "start": "1172080",
    "end": "1174240"
  },
  {
    "text": "cluster",
    "start": "1174240",
    "end": "1174799"
  },
  {
    "text": "with three worker nodes each node",
    "start": "1174799",
    "end": "1177280"
  },
  {
    "text": "contains the daemon set bar",
    "start": "1177280",
    "end": "1179039"
  },
  {
    "text": "and a few other parts to generate some",
    "start": "1179039",
    "end": "1180960"
  },
  {
    "text": "sample log events",
    "start": "1180960",
    "end": "1182640"
  },
  {
    "text": "this cluster also contains the metadata",
    "start": "1182640",
    "end": "1184480"
  },
  {
    "text": "deployment",
    "start": "1184480",
    "end": "1185919"
  },
  {
    "text": "as you can see from our metrics",
    "start": "1185919",
    "end": "1187520"
  },
  {
    "text": "dashboard that with",
    "start": "1187520",
    "end": "1188960"
  },
  {
    "text": "three nodes it's able to transport 90",
    "start": "1188960",
    "end": "1191120"
  },
  {
    "text": "000 events per",
    "start": "1191120",
    "end": "1192000"
  },
  {
    "text": "second without any errors so that means",
    "start": "1192000",
    "end": "1195360"
  },
  {
    "text": "that each node can support up to 30 000",
    "start": "1195360",
    "end": "1197440"
  },
  {
    "text": "events per second",
    "start": "1197440",
    "end": "1198960"
  },
  {
    "text": "we also see that the cpu of the parts",
    "start": "1198960",
    "end": "1200799"
  },
  {
    "text": "stays stable and that it can constantly",
    "start": "1200799",
    "end": "1203120"
  },
  {
    "text": "support the log",
    "start": "1203120",
    "end": "1204000"
  },
  {
    "text": "over a period of time",
    "start": "1204000",
    "end": "1207360"
  },
  {
    "start": "1206000",
    "end": "1246000"
  },
  {
    "text": "the lock generator in this each node",
    "start": "1207360",
    "end": "1209440"
  },
  {
    "text": "collectively was generating 30 000",
    "start": "1209440",
    "end": "1211120"
  },
  {
    "text": "events per second",
    "start": "1211120",
    "end": "1212159"
  },
  {
    "text": "and we have three such nodes so the",
    "start": "1212159",
    "end": "1215120"
  },
  {
    "text": "total log load was around 90 000 events",
    "start": "1215120",
    "end": "1217760"
  },
  {
    "text": "per second",
    "start": "1217760",
    "end": "1218880"
  },
  {
    "text": "and i ran this log test for an hour so",
    "start": "1218880",
    "end": "1221200"
  },
  {
    "text": "that should give us 324 million events",
    "start": "1221200",
    "end": "1223600"
  },
  {
    "text": "at our lock store that's exactly what we",
    "start": "1223600",
    "end": "1225600"
  },
  {
    "text": "see in our log dashboard",
    "start": "1225600",
    "end": "1227840"
  },
  {
    "text": "we can now see that the end to end",
    "start": "1227840",
    "end": "1229200"
  },
  {
    "text": "latency which is a time difference",
    "start": "1229200",
    "end": "1231039"
  },
  {
    "text": "between the container logging and event",
    "start": "1231039",
    "end": "1233120"
  },
  {
    "text": "and the logs are indexing it we see that",
    "start": "1233120",
    "end": "1236080"
  },
  {
    "text": "the median end-to-end latency is just",
    "start": "1236080",
    "end": "1238000"
  },
  {
    "text": "around 9",
    "start": "1238000",
    "end": "1238960"
  },
  {
    "text": "8 seconds and the 99th personnel is less",
    "start": "1238960",
    "end": "1241679"
  },
  {
    "text": "than 14 seconds",
    "start": "1241679",
    "end": "1242960"
  },
  {
    "text": "that's a massive drop from our streaming",
    "start": "1242960",
    "end": "1244880"
  },
  {
    "text": "pipeline",
    "start": "1244880",
    "end": "1247120"
  },
  {
    "start": "1246000",
    "end": "1324000"
  },
  {
    "text": "let me give a summary on the",
    "start": "1247120",
    "end": "1248480"
  },
  {
    "text": "improvements of this s3 based pipeline",
    "start": "1248480",
    "end": "1251120"
  },
  {
    "text": "over a streaming pipeline that we saw",
    "start": "1251120",
    "end": "1253039"
  },
  {
    "text": "from the demo",
    "start": "1253039",
    "end": "1254799"
  },
  {
    "text": "in the case of throughput we saw a",
    "start": "1254799",
    "end": "1256640"
  },
  {
    "text": "massive six times",
    "start": "1256640",
    "end": "1258000"
  },
  {
    "text": "jump in the number of events that can be",
    "start": "1258000",
    "end": "1259440"
  },
  {
    "text": "transported from 5000 events per second",
    "start": "1259440",
    "end": "1262000"
  },
  {
    "text": "per node to 30 000 events per second per",
    "start": "1262000",
    "end": "1265039"
  },
  {
    "text": "node",
    "start": "1265039",
    "end": "1266000"
  },
  {
    "text": "moreover we have tested transporting",
    "start": "1266000",
    "end": "1268320"
  },
  {
    "text": "over one gigabyte",
    "start": "1268320",
    "end": "1269679"
  },
  {
    "text": "per second from a single kubernetes",
    "start": "1269679",
    "end": "1271280"
  },
  {
    "text": "cluster",
    "start": "1271280",
    "end": "1273200"
  },
  {
    "text": "next up we see that the median engine",
    "start": "1273200",
    "end": "1275039"
  },
  {
    "text": "latency drops to less than one-third",
    "start": "1275039",
    "end": "1277520"
  },
  {
    "text": "from around 30 seconds in the streaming",
    "start": "1277520",
    "end": "1279039"
  },
  {
    "text": "pipeline to just over eight seconds in",
    "start": "1279039",
    "end": "1281120"
  },
  {
    "text": "the s3 based pipeline",
    "start": "1281120",
    "end": "1282720"
  },
  {
    "text": "the difference grows considerably when",
    "start": "1282720",
    "end": "1284960"
  },
  {
    "text": "considering the 99 first l which",
    "start": "1284960",
    "end": "1288000"
  },
  {
    "text": "has a latency cut down by more than 75",
    "start": "1288000",
    "end": "1291200"
  },
  {
    "text": "finally looking at the cost we see the",
    "start": "1291200",
    "end": "1292799"
  },
  {
    "text": "cost saving of more than 92",
    "start": "1292799",
    "end": "1294640"
  },
  {
    "text": "when compared to the streaming pipeline",
    "start": "1294640",
    "end": "1296720"
  },
  {
    "text": "this is due to not having",
    "start": "1296720",
    "end": "1298640"
  },
  {
    "text": "to keep persistent resources running",
    "start": "1298640",
    "end": "1300480"
  },
  {
    "text": "compression of the log data",
    "start": "1300480",
    "end": "1301840"
  },
  {
    "text": "and using transit gateway this was",
    "start": "1301840",
    "end": "1303919"
  },
  {
    "text": "coming around to more than 50",
    "start": "1303919",
    "end": "1305440"
  },
  {
    "text": "000 us dollars saved over every petabyte",
    "start": "1305440",
    "end": "1308240"
  },
  {
    "text": "transfer",
    "start": "1308240",
    "end": "1309679"
  },
  {
    "text": "this is a story of how we were able to",
    "start": "1309679",
    "end": "1311440"
  },
  {
    "text": "create a petabyte scale logging pipeline",
    "start": "1311440",
    "end": "1313760"
  },
  {
    "text": "at intuit",
    "start": "1313760",
    "end": "1314400"
  },
  {
    "text": "using fluency and fluent bit thank you",
    "start": "1314400",
    "end": "1316480"
  },
  {
    "text": "all so much for participating in this",
    "start": "1316480",
    "end": "1318480"
  },
  {
    "text": "session",
    "start": "1318480",
    "end": "1318960"
  },
  {
    "text": "and i would like to open up the forum",
    "start": "1318960",
    "end": "1320559"
  },
  {
    "text": "for questions at this point",
    "start": "1320559",
    "end": "1322720"
  },
  {
    "text": "thank you",
    "start": "1322720",
    "end": "1326559"
  }
]
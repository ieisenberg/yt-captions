[
  {
    "text": "hello everyone uh thanks for joining us so today uh we'll be talking about crd",
    "start": "640",
    "end": "7600"
  },
  {
    "text": "versus dedicated at CD lessons from taming High churn clusters my name is",
    "start": "7600",
    "end": "12840"
  },
  {
    "text": "hant I'm an engineer at dayto dog and I'm also a celum cncf maintainer and this is Marcel he works on celium at",
    "start": "12840",
    "end": "20279"
  },
  {
    "text": "isovalent and he's also active in kubernetes six scaleability",
    "start": "20279",
    "end": "25960"
  },
  {
    "text": "so crd versus KV star so if you're building an application that is kubernetes native or",
    "start": "26400",
    "end": "34800"
  },
  {
    "text": "like a controller you have a decision to make if you have some state that you want to store you have a decision to",
    "start": "34800",
    "end": "40760"
  },
  {
    "text": "make so do you use crds to store that data or do you use a dedicated KV store to store that data so in addition to the",
    "start": "40760",
    "end": "47640"
  },
  {
    "text": "total volume that you want to store your data access patterns should also influence that decision right so in this",
    "start": "47640",
    "end": "54280"
  },
  {
    "text": "talk we'll get into some details on some of the decisions celium had to make right",
    "start": "54280",
    "end": "60960"
  },
  {
    "text": "so we'll discuss quickly some some aspects of kubernetes scalability and how kubernetes",
    "start": "60960",
    "end": "68000"
  },
  {
    "text": "scalability impacts different features in celium and some of the current state and some of the options that exist in",
    "start": "68000",
    "end": "73680"
  },
  {
    "text": "celium today to help you and how the road ahead looks like and some of the lessons we learned uh along the way so",
    "start": "73680",
    "end": "80200"
  },
  {
    "text": "with that I'll let Marcel talk about kubernetes scalability okay so let's start talking",
    "start": "80200",
    "end": "86560"
  },
  {
    "text": "about kubernetes scalability so usually when you think about kubernetes scalability what you have in mind is",
    "start": "86560",
    "end": "92280"
  },
  {
    "text": "like what's the number of nodes right well wrong like scalability is not just",
    "start": "92280",
    "end": "97360"
  },
  {
    "text": "the number of nodes when I think about scalability of kubernetes um it's important to think about multiple",
    "start": "97360",
    "end": "104560"
  },
  {
    "text": "Dimensions um so number of nodes is just one dimension that you should care about",
    "start": "104560",
    "end": "109840"
  },
  {
    "text": "when thinking about scalability and like the next thing that usually comes up to mind is the number of PODS right but",
    "start": "109840",
    "end": "117240"
  },
  {
    "text": "this is not all so the question becomes like what are those other dimensions that we should care about when we are",
    "start": "117240",
    "end": "123360"
  },
  {
    "text": "operating kubernetes cluster at scale so now we will talk about two different kubernetes features that probably all of",
    "start": "123360",
    "end": "130239"
  },
  {
    "text": "you are familiar with and try to think about like how they affect scalability",
    "start": "130239",
    "end": "135800"
  },
  {
    "text": "of kubernetes so let's start with kubernetes Services um so the idea is quite simple",
    "start": "135800",
    "end": "142879"
  },
  {
    "text": "you define service the service gets virtual IP or cluster IP assigned and then you have bunch of backend pods",
    "start": "142879",
    "end": "149560"
  },
  {
    "text": "right so um from client perspective when you want to connect to to the service H",
    "start": "149560",
    "end": "155280"
  },
  {
    "text": "what happens is that you know you initiate the connection to to this virtual IP um but you need to have some",
    "start": "155280",
    "end": "161840"
  },
  {
    "text": "kind of proxy and usually it's just Cube proxy that understands the concept of",
    "start": "161840",
    "end": "166879"
  },
  {
    "text": "services so um the proxy is responsible for Translating that virtual IP to one",
    "start": "166879",
    "end": "172680"
  },
  {
    "text": "of your backend pods and initiate the connection for you so now let's make",
    "start": "172680",
    "end": "178560"
  },
  {
    "text": "this thought experiment if you were going to implement Q proxy how would you do",
    "start": "178560",
    "end": "183920"
  },
  {
    "text": "it um so first of all um obviously you have service object and endpoint object",
    "start": "183920",
    "end": "190280"
  },
  {
    "text": "so endpoint object is essentially list of ips of all the backend pods U that",
    "start": "190280",
    "end": "195879"
  },
  {
    "text": "are behind the service and of course we have bunch of services bunch of end points and corresponding backend pods",
    "start": "195879",
    "end": "203319"
  },
  {
    "text": "behind the service and all these objects live in Cube API servers so they are",
    "start": "203319",
    "end": "208439"
  },
  {
    "text": "actually served to cube proxy um for read requests from Cube API server and",
    "start": "208439",
    "end": "215519"
  },
  {
    "text": "um except for like and of course the proxy is running on on one note and it",
    "start": "215519",
    "end": "221560"
  },
  {
    "text": "needs to understand um all the services and all the endpoints so it initiates",
    "start": "221560",
    "end": "226920"
  },
  {
    "text": "the watch request to to cube API server to get all the updates of services and endpoints but of course in the",
    "start": "226920",
    "end": "233159"
  },
  {
    "text": "kubernetes cluster you have bunch of nodes and each node needs to run this proxy so what happens in this case is is",
    "start": "233159",
    "end": "240200"
  },
  {
    "text": "whenever service or endpoint is being updated a cube API server actually needs",
    "start": "240200",
    "end": "245640"
  },
  {
    "text": "to broadcast this information to to all of the proxies that are running on your noes um and there's one more component",
    "start": "245640",
    "end": "252319"
  },
  {
    "text": "so uh even though when you are thinking about services and there are some back and PS behind those Services um the",
    "start": "252319",
    "end": "259320"
  },
  {
    "text": "information that is exposed is basically only the IPS be behind the service so there is endpoints reconciler that",
    "start": "259320",
    "end": "266320"
  },
  {
    "text": "actually understands what are the backend points behind the service and it's publishing this information about",
    "start": "266320",
    "end": "272720"
  },
  {
    "text": "IPS to um object called endpoints uh so what's the issue with this design well",
    "start": "272720",
    "end": "278759"
  },
  {
    "text": "basically whenever you create new pod and this pod is behind the service what",
    "start": "278759",
    "end": "284360"
  },
  {
    "text": "happens is the endpoints reconciler needs to update the endpoint right and you can think of it as you can have one",
    "start": "284360",
    "end": "290560"
  },
  {
    "text": "service that has thousand of PODS behind it and single creation of the Pod makes",
    "start": "290560",
    "end": "298479"
  },
  {
    "text": "you know update to the endpoint and this endpoint has thousands of ips so this huge object needs to be broadcasted to",
    "start": "298479",
    "end": "305919"
  },
  {
    "text": "to all of the nodes so this is definitely inefficient so that's why in kubernetes um kubernetes introduced",
    "start": "305919",
    "end": "312560"
  },
  {
    "text": "endpoint slices so instead of having like one to one mapping between service and endpoints what you have is one to",
    "start": "312560",
    "end": "319080"
  },
  {
    "text": "many mappings where endpoint slices um have fixed amount of ips behind um like",
    "start": "319080",
    "end": "326800"
  },
  {
    "text": "within the single object there is a fixed amount of ipce so it's up to 100 and um what happens then is like if you",
    "start": "326800",
    "end": "334600"
  },
  {
    "text": "create the Pod then you don't need to send out all the IPS behind the service",
    "start": "334600",
    "end": "339720"
  },
  {
    "text": "what you only need to do is send the update of the endpoint slice single endpoint slice that is you know with",
    "start": "339720",
    "end": "346720"
  },
  {
    "text": "fixed um amount of ips um so now let's take a look at",
    "start": "346720",
    "end": "353240"
  },
  {
    "text": "Network policy so in a sense Network policies idea is quite simple you have",
    "start": "353240",
    "end": "360240"
  },
  {
    "text": "some front end pods you have backend pods and you have database pods and what you want is well you want front end pods",
    "start": "360240",
    "end": "367199"
  },
  {
    "text": "to be able to connect to the backend pods and backend pods to connect to the database pod but by default in",
    "start": "367199",
    "end": "373880"
  },
  {
    "text": "kubernetes like each pod can talk to any other pod so you know it's possible that the front end pod can connect to the",
    "start": "373880",
    "end": "380880"
  },
  {
    "text": "other front end pod or even talk directly to the database so what you want to do is actually you want to",
    "start": "380880",
    "end": "387680"
  },
  {
    "text": "restrict those type of connections and that's the purpose of network policies",
    "start": "387680",
    "end": "393400"
  },
  {
    "text": "so let's take a look at example Network policy how it describes such you know",
    "start": "393400",
    "end": "400160"
  },
  {
    "text": "connections that are allowed so first of all um you are starting with saying okay",
    "start": "400160",
    "end": "405880"
  },
  {
    "text": "this network policy applies to those specific pods but even though we were thinking about deployments how",
    "start": "405880",
    "end": "412080"
  },
  {
    "text": "deployments talk to each other here we are specifying labels that we care about so it says that the network policy",
    "start": "412080",
    "end": "419160"
  },
  {
    "text": "applies to all of the parts that have this specific label then we specify whether it's",
    "start": "419160",
    "end": "425560"
  },
  {
    "text": "Ingress or egress traffic and which pods our front end can connect to and here is",
    "start": "425560",
    "end": "432080"
  },
  {
    "text": "example where you can specify both namespace selector and pod selector so what it means is well my frontend pod is",
    "start": "432080",
    "end": "439759"
  },
  {
    "text": "able to connect to all the pods that live within the name space with the label like specified label and then also",
    "start": "439759",
    "end": "447759"
  },
  {
    "text": "those SPS need to actually have specific label which means like it's it's quite",
    "start": "447759",
    "end": "453520"
  },
  {
    "text": "more powerful than just saying which deployments that you have in a cluster can talk to each other so now let's",
    "start": "453520",
    "end": "460160"
  },
  {
    "text": "think like from kind of like the proxy perspective how would you go about implementing such feature to actually",
    "start": "460160",
    "end": "467280"
  },
  {
    "text": "restrict those connections that you are interested in um so again like let's say we have",
    "start": "467280",
    "end": "472520"
  },
  {
    "text": "some kind of proxy running on the Node and um well we said that we need to be",
    "start": "472520",
    "end": "477800"
  },
  {
    "text": "aware of labels of the pod so like obvious thing would be to just watch for",
    "start": "477800",
    "end": "483560"
  },
  {
    "text": "all the pods right um and get all the updates of PODS so we are aware of the labels of these pods but the issue with",
    "start": "483560",
    "end": "490759"
  },
  {
    "text": "that is that you know the pods are being updated quite often and there is no easy way to actually filter out um what",
    "start": "490759",
    "end": "497319"
  },
  {
    "text": "updates we are receiving so think about like cuet updating status of of the Pod",
    "start": "497319",
    "end": "502759"
  },
  {
    "text": "what happens is like as a proxy we would be receiving all of these updates even though we don't really care we only care",
    "start": "502759",
    "end": "508360"
  },
  {
    "text": "about the changes to the lab in order to enforce Network policies then of course like the network policies",
    "start": "508360",
    "end": "515599"
  },
  {
    "text": "reference as well um labels from namespaces so we need to be aware of the",
    "start": "515599",
    "end": "521479"
  },
  {
    "text": "labels of the namespaces so we need to watch for for those as well and last but not least Network policies if we are",
    "start": "521479",
    "end": "527920"
  },
  {
    "text": "going to enforce them and again like if the proxy or whatever it is is running all of the nodes that each update would",
    "start": "527920",
    "end": "534920"
  },
  {
    "text": "be propagated so this is kind of like the naive implementation that you can think of and we can see that you know if",
    "start": "534920",
    "end": "540680"
  },
  {
    "text": "you have high turn of the pods then in this case the information will be propagated to all of the",
    "start": "540680",
    "end": "545760"
  },
  {
    "text": "nodes so we went through those two examples to kind of like think what are",
    "start": "545760",
    "end": "551440"
  },
  {
    "text": "other dimensions that we should care about so first of all like there is obviously number of nodes and number of",
    "start": "551440",
    "end": "558040"
  },
  {
    "text": "PODS is it's important but then we should also think about pod turn we saw that in both cases po turn actually",
    "start": "558040",
    "end": "565040"
  },
  {
    "text": "matters um to take a look like how many different uh are being broadcasted",
    "start": "565040",
    "end": "570760"
  },
  {
    "text": "within your cluster um another thing number of services then like what's the churn of the beckons behind the services",
    "start": "570760",
    "end": "578200"
  },
  {
    "text": "what's the number of Nam spaces what's the names space turn right we we still need to understand like the those labels",
    "start": "578200",
    "end": "584600"
  },
  {
    "text": "for enforcing Network policies and you know Network policies and the CH of",
    "start": "584600",
    "end": "590160"
  },
  {
    "text": "network policies so just to recap like if we are thinking about scalability of",
    "start": "590160",
    "end": "595640"
  },
  {
    "text": "kubernetes not just the number of nodes but it's actually way more dimensions and just based on those two features",
    "start": "595640",
    "end": "602519"
  },
  {
    "text": "that we were talking about in kubernetes we can see that it's quite multi-dimensional",
    "start": "602519",
    "end": "607800"
  },
  {
    "text": "problem so with that in mind let's think about what's the target scale that we would like to support you know if we are",
    "start": "607800",
    "end": "614760"
  },
  {
    "text": "implemented implementing this kind of like proxy so the target scale is based",
    "start": "614760",
    "end": "619920"
  },
  {
    "text": "on official recommendations from from kubernetes so you know you probably know that kubernetes supports up to 5,000",
    "start": "619920",
    "end": "626920"
  },
  {
    "text": "nodes then like less known um limitation is a recommendation actually is 10,000",
    "start": "626920",
    "end": "633040"
  },
  {
    "text": "Services then 150,000 pots which means like on average you should have 30 pots per per node um then pots turn around",
    "start": "633040",
    "end": "641279"
  },
  {
    "text": "100 po changes per second it can be either Creations deletions or just you",
    "start": "641279",
    "end": "647519"
  },
  {
    "text": "know changes of the pods um Network policies this is something that actually we came up with uh for for you know",
    "start": "647519",
    "end": "655000"
  },
  {
    "text": "thinking about um from Sing perspective this is not the official recommendation",
    "start": "655000",
    "end": "660680"
  },
  {
    "text": "but we need to establish some Target scale that we are interested in and also the network policies churn around 20 20",
    "start": "660680",
    "end": "667800"
  },
  {
    "text": "per second um so going back um hmon was",
    "start": "667800",
    "end": "672839"
  },
  {
    "text": "mentioning before that we are working both on celium so celum is evf based",
    "start": "672839",
    "end": "677959"
  },
  {
    "text": "networking observability and security and one of the open source projects that we have is cni um and you know as a",
    "start": "677959",
    "end": "687079"
  },
  {
    "text": "part of cni we need to implement those two features that we were mentioning before croxy replacement so instead of",
    "start": "687079",
    "end": "693240"
  },
  {
    "text": "like using croxy um you can use cni to to implement those things and then",
    "start": "693240",
    "end": "698560"
  },
  {
    "text": "also Network policies so I was mentioning before that",
    "start": "698560",
    "end": "707000"
  },
  {
    "text": "you know the naive implementation would be to just watch for all the Pod changes and all the namespace changes but that's",
    "start": "707000",
    "end": "713560"
  },
  {
    "text": "not how we implement it in um and the reason is that we are not interested in those updates that you know cuet",
    "start": "713560",
    "end": "719600"
  },
  {
    "text": "could be doing to the statuses of the pods so how we went about it is you know we created two crds first one is celium",
    "start": "719600",
    "end": "727560"
  },
  {
    "text": "identity so instead of watching for the changes of the pods and namespaces what we do is we create cium identity and",
    "start": "727560",
    "end": "733959"
  },
  {
    "text": "this is kind of like the summary of all the labels which means like whenever the Pod status changes for example by cubet",
    "start": "733959",
    "end": "740720"
  },
  {
    "text": "we don't actually need to know about it because we care only about the labels of PODS and",
    "start": "740720",
    "end": "746880"
  },
  {
    "text": "namespaces um and then we also have SE endpoint and that's those two things are",
    "start": "746880",
    "end": "752040"
  },
  {
    "text": "enough to actually enforce Network policies so the idea is that you have single um endpoint per pod running",
    "start": "752040",
    "end": "759760"
  },
  {
    "text": "in your cluster and it's mapping between um between the Pod and the identity so",
    "start": "759760",
    "end": "765360"
  },
  {
    "text": "we know that okay this PO has this particular identity and we know all the labels um so with that design um we only",
    "start": "765360",
    "end": "773760"
  },
  {
    "text": "need Network policies in order to enforce them um and agent watches for the changes of network policies",
    "start": "773760",
    "end": "780360"
  },
  {
    "text": "endpoints and identities so this is much better design as compared to like",
    "start": "780360",
    "end": "786279"
  },
  {
    "text": "knif solution where we would be receiving all the P updates within the",
    "start": "786279",
    "end": "791440"
  },
  {
    "text": "cluster so now um let's make step back and um I was mentioning kind of like the",
    "start": "791800",
    "end": "798760"
  },
  {
    "text": "default mode in which selum runs which is the crd mode but that was not always the case so kubernetes was released in",
    "start": "798760",
    "end": "806880"
  },
  {
    "text": "2015 um for initial release was also 2015 uh but well crds were introduced in",
    "start": "806880",
    "end": "815320"
  },
  {
    "text": "2017 so I was mentioning about those two crds but the question is like so how did",
    "start": "815320",
    "end": "821279"
  },
  {
    "text": " work actually if the crds did not exist at that time and the qu and the",
    "start": "821279",
    "end": "826959"
  },
  {
    "text": "answer is well at CD was used as the control plane for State Management um",
    "start": "826959",
    "end": "833079"
  },
  {
    "text": "between slume agents and please don't quote me on these dates these were taken from uh Wikipedia so they might be wrong",
    "start": "833079",
    "end": "840399"
  },
  {
    "text": "for example like if you if you take a look at the releases of kubernetes you might see that 1.0 might still be kind",
    "start": "840399",
    "end": "846480"
  },
  {
    "text": "of supported like end of life date is empty so I don't know and um to sum up",
    "start": "846480",
    "end": "853279"
  },
  {
    "text": "basically we have two different ways of running one with etcd one with crd",
    "start": "853279",
    "end": "858720"
  },
  {
    "text": "and now hamand will talk a little bit more about what are the differences what are the pros and cons of both of",
    "start": "858720",
    "end": "866839"
  },
  {
    "text": "them cool thanks marel I'm sure someone's going to make a Wikipedia edit now",
    "start": "867839",
    "end": "874480"
  },
  {
    "text": "but all right so we know that celium has two identity allocation modes right so",
    "start": "874480",
    "end": "881360"
  },
  {
    "text": "there's the crd identity allocation mode and the KV store identity allocation mode so if you take a closer look at the",
    "start": "881360",
    "end": "888120"
  },
  {
    "text": "celum documentation you'll realize that currently crd mode is recommended only",
    "start": "888120",
    "end": "893600"
  },
  {
    "text": "up to 1,000 nodes and if you want to go beyond that up to 5,000 nodes it's recommended that you use use the KV",
    "start": "893600",
    "end": "899759"
  },
  {
    "text": "store identity allocation mode with hcd right so let's zoom out a little bit and",
    "start": "899759",
    "end": "906639"
  },
  {
    "text": "uh understand how the architecture looks like right now right so you have your kubernetes control plan and celium",
    "start": "906639",
    "end": "913120"
  },
  {
    "text": "primarily has two components right so there's a celum operator which runs as a deployment in your cluster and there's",
    "start": "913120",
    "end": "918480"
  },
  {
    "text": "celum agent which runs as a demon set on every single node in your cluster and there are other components like cluster",
    "start": "918480",
    "end": "924399"
  },
  {
    "text": "mesh API server depending on if you're Mees using cluster mesh or not but we not talk about that in this uh in this",
    "start": "924399",
    "end": "931519"
  },
  {
    "text": "session so depending on how you're managing your kubernetes clusters you might be running on cloud providers with",
    "start": "931519",
    "end": "937560"
  },
  {
    "text": "using managed kubernetes services so if you're using managed kubernetes Services you generally don't have to worry about",
    "start": "937560",
    "end": "943519"
  },
  {
    "text": "uh your kubernetes control plane but your kubernetes control plane is also backed by its own SD cluster right so if",
    "start": "943519",
    "end": "950399"
  },
  {
    "text": "you using CD mode celum creates CID objects so that the operator and agent can talk to each other and maintain",
    "start": "950399",
    "end": "957920"
  },
  {
    "text": "state but if you want to use the KV store mode you will have to manage your own H CD",
    "start": "957920",
    "end": "964079"
  },
  {
    "text": "cluster right so there is no way around that you'll have to manage the entire life cycle provisioning maintenance and",
    "start": "964079",
    "end": "970240"
  },
  {
    "text": "all of that and when you use the KV store mode with hcd Salem endpoints and identities are now written to your uh",
    "start": "970240",
    "end": "976800"
  },
  {
    "text": "ETD cluster so what are the challenges with running your own ETD cluster right so",
    "start": "976800",
    "end": "983839"
  },
  {
    "text": "how does our day two look like with h CD so for starters you'll have to worry",
    "start": "983839",
    "end": "989040"
  },
  {
    "text": "about taking periodic backups of course you also need to know how to restore from those backups right and you'll have",
    "start": "989040",
    "end": "995480"
  },
  {
    "text": "to run something called compaction right so hcd keeps track of the history for",
    "start": "995480",
    "end": "1002440"
  },
  {
    "text": "all the keys that are stored in hcd so every once in a while you'll have to run compaction so that you can save on your",
    "start": "1002440",
    "end": "1008319"
  },
  {
    "text": "disk space luckily there are a few options that are already built in in ETD so you can set auto compaction and ETD",
    "start": "1008319",
    "end": "1015079"
  },
  {
    "text": "will take care of it but the problem is every time you run these compa action operations it might leave your disk",
    "start": "1015079",
    "end": "1021079"
  },
  {
    "text": "space fragmented and if that happens you'll have to run defragmentation operations and this does not happen",
    "start": "1021079",
    "end": "1027438"
  },
  {
    "text": "automatically right and you need to do defragmentation on a per node basis",
    "start": "1027439",
    "end": "1032880"
  },
  {
    "text": "right so and another thing to note about defragmentation is that this is kind of",
    "start": "1032880",
    "end": "1038160"
  },
  {
    "text": "like a stop theor uh model so every time you run your defragmentation operation",
    "start": "1038160",
    "end": "1043319"
  },
  {
    "text": "your ETD stops responding or uh does not accept any read or write requests right",
    "start": "1043319",
    "end": "1048360"
  },
  {
    "text": "and you you'll have to run these on every single node in your H cluster so you'll have to have something that",
    "start": "1048360",
    "end": "1053440"
  },
  {
    "text": "coordinates those um defragmentation operations and SD clusters also have",
    "start": "1053440",
    "end": "1059679"
  },
  {
    "text": "default space codas so if you fail to do these defragmentation operations or something else happens and you end up",
    "start": "1059679",
    "end": "1065559"
  },
  {
    "text": "filling your uh Coda ETD goes into an alarm state right and when it enters",
    "start": "1065559",
    "end": "1070799"
  },
  {
    "text": "this alarm state it again stops responding to read or write requests and that's bad as well and on top of that",
    "start": "1070799",
    "end": "1077039"
  },
  {
    "text": "you'll also have to worry about periodic update security patches and things like that and the Crux of this problem is",
    "start": "1077039",
    "end": "1083760"
  },
  {
    "text": "there is no official tooling to take care of all of this so you either have to write your own tooling or use some",
    "start": "1083760",
    "end": "1090080"
  },
  {
    "text": "unsupported or unofficial things that exist on GitHub and let's say you put some",
    "start": "1090080",
    "end": "1096480"
  },
  {
    "text": "scripts together and manage the life cycle of your ET CD clusters that's not enough either right",
    "start": "1096480",
    "end": "1103360"
  },
  {
    "text": "so HD clusters are also very sensitive to uh dis and network latency so depending on on how active your clusters",
    "start": "1103360",
    "end": "1110159"
  },
  {
    "text": "are and how big your kubernetes clusters are sometimes your the your diss might",
    "start": "1110159",
    "end": "1115400"
  },
  {
    "text": "not be fast enough or your network might not be fast enough luckily ETD already has some Telemetry for this so if you",
    "start": "1115400",
    "end": "1122200"
  },
  {
    "text": "see logs like this your ETD instances might need an",
    "start": "1122200",
    "end": "1127720"
  },
  {
    "text": "upgrade and it doesn't stop with that either right so you'll have to make sure that all the clients that are connecting",
    "start": "1128559",
    "end": "1134000"
  },
  {
    "text": "to your hcd clusters are well behaved right so let's say you do an hcd roll out and um so every time you do an ETD",
    "start": "1134000",
    "end": "1142120"
  },
  {
    "text": "roll out there is a chance that your clients might be skewed onto one of the ETD nodes and this is not great for your",
    "start": "1142120",
    "end": "1149400"
  },
  {
    "text": "clusters health either it makes the node with the most connections more prone to getting home",
    "start": "1149400",
    "end": "1155200"
  },
  {
    "text": "killed um so actually API server already has a solution for this U there's a go",
    "start": "1155200",
    "end": "1160760"
  },
  {
    "text": "away chance that you can set on the API server and if you do that API server will make sure that clients rebalance",
    "start": "1160760",
    "end": "1166240"
  },
  {
    "text": "automatically and if you find yourself in the situ situation with uh celium agent you'll have to do a celium agent",
    "start": "1166240",
    "end": "1172320"
  },
  {
    "text": "uh restart roll out to make sure you balance them",
    "start": "1172320",
    "end": "1177559"
  },
  {
    "text": "again and let's say if your clusters are getting bigger and you want to have more",
    "start": "1178080",
    "end": "1183360"
  },
  {
    "text": "read throughput in your clusters right so generally three node configuration is the most common configuration folks run",
    "start": "1183360",
    "end": "1188600"
  },
  {
    "text": "on and this allows you to tolerate like one node loss but if you want to tolerate like more than one node loss",
    "start": "1188600",
    "end": "1194480"
  },
  {
    "text": "you might have five node clusters right but the problem here here is while",
    "start": "1194480",
    "end": "1199799"
  },
  {
    "text": "trying to scale the reads and ETD is a Corum based system so every time you",
    "start": "1199799",
    "end": "1204960"
  },
  {
    "text": "post a right to HD cluster your majority of the nodes have to acknowledge that right right so in an attempt to scale",
    "start": "1204960",
    "end": "1212480"
  },
  {
    "text": "your read performance you'll actually negatively impact your right performance so just horizontally scaling is also not",
    "start": "1212480",
    "end": "1218360"
  },
  {
    "text": "the solution and on top of that at CD also does not have native rate limiting",
    "start": "1218360",
    "end": "1223720"
  },
  {
    "text": "systems in place so if your clients are misbehaved for some reason or you're running into into a bug you could",
    "start": "1223720",
    "end": "1230559"
  },
  {
    "text": "overwhelm your hcd nodes and which can eventually lead to being home killed uh you can also enforce client at rate",
    "start": "1230559",
    "end": "1237039"
  },
  {
    "text": "limiting Salem already does that but that's not a perfect solution either because you cannot really coordinate all",
    "start": "1237039",
    "end": "1242960"
  },
  {
    "text": "the clients at one place right so what I'm getting at with all",
    "start": "1242960",
    "end": "1248120"
  },
  {
    "text": "this is that uh running your own H3 clusters involves a non-trivial amount of Maintenance and if you want to learn",
    "start": "1248120",
    "end": "1253919"
  },
  {
    "text": "more quirks about H CD maintenance there are already some great talk great cubec con talks out there do check it out you",
    "start": "1253919",
    "end": "1260520"
  },
  {
    "text": "know why these folks are talking about it because they're running manag services and luckily we actually have a",
    "start": "1260520",
    "end": "1267240"
  },
  {
    "text": "great team at data dog that takes care of running HDs for us so and Maxim's here he has built a great tool for us to",
    "start": "1267240",
    "end": "1273919"
  },
  {
    "text": "automatically take care of uh a bunch of this maintenance so as a thought exercise",
    "start": "1273919",
    "end": "1280320"
  },
  {
    "text": "let's say if you want to improve this situation right so what can we do maybe we can introduce a caching layer in",
    "start": "1280320",
    "end": "1286919"
  },
  {
    "text": "front of your hcd cluster so that we can scale our read performance without having to take a hit on your right",
    "start": "1286919",
    "end": "1292919"
  },
  {
    "text": "performance or maybe we can introduce a proxy that does some rate limiting before you send requests to your KV",
    "start": "1292919",
    "end": "1299120"
  },
  {
    "text": "store so does anyone know of a component that kind of already does this a",
    "start": "1299120",
    "end": "1304919"
  },
  {
    "text": "component that we are already like quite familiar with and use every day any",
    "start": "1304919",
    "end": "1311880"
  },
  {
    "text": "guesses yeah so a quick clue is it also has a very well- defined",
    "start": "1311880",
    "end": "1317520"
  },
  {
    "text": "API so if you guess kubernetes API server you're absolutely right right so",
    "start": "1317520",
    "end": "1323279"
  },
  {
    "text": "kubernetes API server already implements all of these Primitives is essentially a cache that's sitting in front of an ETD",
    "start": "1323279",
    "end": "1329799"
  },
  {
    "text": "cluster every time you make request ETD is going to cach that response so your read performance will obviously be",
    "start": "1329799",
    "end": "1336559"
  },
  {
    "text": "better because it's coming from a cache and it already has a battle tested priority and flow control system so you",
    "start": "1336559",
    "end": "1343200"
  },
  {
    "text": "can make sure you can protect your uh kubernetes control plane and it also has options for batching as Marcel spoke",
    "start": "1343200",
    "end": "1350960"
  },
  {
    "text": "about before so in theory CD mode should be",
    "start": "1350960",
    "end": "1356760"
  },
  {
    "text": "better than KV store mode right so why is it that c mode is recommended only for up to thousand nodes so are we",
    "start": "1356760",
    "end": "1363080"
  },
  {
    "text": "simply solving this problem by creating some dedicated infrastructure and just throwing some money at it to solve the",
    "start": "1363080",
    "end": "1369200"
  },
  {
    "text": "problem so let's that's unwrap and take a look right so the core of this problem",
    "start": "1369200",
    "end": "1376000"
  },
  {
    "text": "comes from this concept of celium endpoint right so I'd like to reemphasize here that celium end points",
    "start": "1376000",
    "end": "1382760"
  },
  {
    "text": "are different from kubernetes endpoints there's one part there's one end point for every single part that's",
    "start": "1382760",
    "end": "1388480"
  },
  {
    "text": "running in your cluster because celium end points are the abstraction that celium uses to manage the network life",
    "start": "1388480",
    "end": "1394080"
  },
  {
    "text": "cycle of the of the pod on the node right and in order to enforce Network",
    "start": "1394080",
    "end": "1399159"
  },
  {
    "text": "policy celium needs to maintain a mapping of the IP address to Identity and it does that by watching celum end",
    "start": "1399159",
    "end": "1405840"
  },
  {
    "text": "points so every single celum agent uh in your cluster has a watcher against the kubernetes API server to get notified on",
    "start": "1405840",
    "end": "1413559"
  },
  {
    "text": "um celm endpoint updates so let's take a look at a scenario let's say we have a 5,000 node",
    "start": "1413559",
    "end": "1421080"
  },
  {
    "text": "cluster and we have a new pod that's scheduled onto one of these nodes and soon after um your container runtime",
    "start": "1421080",
    "end": "1428799"
  },
  {
    "text": "creates a cni add call to the celum agent celum agent will create a endpoint",
    "start": "1428799",
    "end": "1434559"
  },
  {
    "text": "object for you so and that endpoint needs to live in your uh API server because you're using the crd mode so an",
    "start": "1434559",
    "end": "1440960"
  },
  {
    "text": "update gets posted to the API server and soon after that happens let's say you",
    "start": "1440960",
    "end": "1446039"
  },
  {
    "text": "have a 5,000 node cluster and kubernetes needs to support around 100 changes 100",
    "start": "1446039",
    "end": "1452559"
  },
  {
    "text": "part changes per second and that's the churn we are trying to Target and with the churn of 100 and point updates per",
    "start": "1452559",
    "end": "1459200"
  },
  {
    "text": "second and a 5,000 node cluster your control plane needs to process 500,000",
    "start": "1459200",
    "end": "1464400"
  },
  {
    "text": "watch update events right this is a lot of update events depending on how you've",
    "start": "1464400",
    "end": "1469480"
  },
  {
    "text": "configured your kubernetes clusters if you have proper flow control and proper things configured then it will either",
    "start": "1469480",
    "end": "1476640"
  },
  {
    "text": "completely kill your kubernetes control plane or it will take forever to propagate those updates to your entire",
    "start": "1476640",
    "end": "1482399"
  },
  {
    "text": "cluster right which is also not great so what's the solution here luckily as uh",
    "start": "1482399",
    "end": "1489320"
  },
  {
    "text": "Marcel mentioned kubernetes also had the same problem with Q proxy and the",
    "start": "1489320",
    "end": "1494679"
  },
  {
    "text": "solution for this was kubernetes endpoint slices so uh which allows you to slice your total endpoint objects",
    "start": "1494679",
    "end": "1501279"
  },
  {
    "text": "into fewer uh batched endpoint slice objects right so a similar solution was also",
    "start": "1501279",
    "end": "1508640"
  },
  {
    "text": "implemented for celium and it's called celium endpoint slices and with endpoint slices it",
    "start": "1508640",
    "end": "1514679"
  },
  {
    "text": "allows you to like you can configure your endpoint slice bat size up to 100 so that allows you to bring down your",
    "start": "1514679",
    "end": "1521200"
  },
  {
    "text": "500,000 updates to around 5,000 updates those are a lot more manageable so",
    "start": "1521200",
    "end": "1526320"
  },
  {
    "text": "you're basically trading off some latency for scalability right uh the slide looks a little complex but we'll",
    "start": "1526320",
    "end": "1533480"
  },
  {
    "text": "walk through it um so the part where uh CM agent uh so let's imagine a node has",
    "start": "1533480",
    "end": "1541559"
  },
  {
    "text": "a pod scheduled on it and that part really does not change so the container on time makes a cni add call celum agent",
    "start": "1541559",
    "end": "1548559"
  },
  {
    "text": "creates a endpoint object that gets posted to the kubernetes API server and",
    "start": "1548559",
    "end": "1553600"
  },
  {
    "text": "then the new thing here is that the celm operator is now watching for celm endpoints instead of every agent",
    "start": "1553600",
    "end": "1559559"
  },
  {
    "text": "watching for them and operator is responsible for batching all of those  endpoints into a endpoint slice",
    "start": "1559559",
    "end": "1566600"
  },
  {
    "text": "right and we only need to send out that batched celm endpoint slice object now",
    "start": "1566600",
    "end": "1572279"
  },
  {
    "text": "right so that's basically 5,000 right it's a lot more manageable and over the course of years",
    "start": "1572279",
    "end": "1580000"
  },
  {
    "text": "uh the celum endpoint slice object has been uh folks have been start started to run it on production and we started",
    "start": "1580000",
    "end": "1586279"
  },
  {
    "text": "seeing a lot more options to fine tune  endpoint slices so you can precisely control how much your bat size is going",
    "start": "1586279",
    "end": "1592880"
  },
  {
    "text": "to be how you're going to group those uh cend points into C and point slices and",
    "start": "1592880",
    "end": "1599159"
  },
  {
    "text": "the QPS at which the operator can write to the kubernetes control plane and uh",
    "start": "1599159",
    "end": "1604360"
  },
  {
    "text": "there's also a way to now automatically configure them so that depending on how big your clusters are you can",
    "start": "1604360",
    "end": "1609640"
  },
  {
    "text": "automatically decide those rate limits so it's getting a lot better now but CM endpoint slices if you take a closer",
    "start": "1609640",
    "end": "1616520"
  },
  {
    "text": "look at the documentation there's still marked as beta so in order to understand why that's the",
    "start": "1616520",
    "end": "1623000"
  },
  {
    "text": "case and talk a little bit about where we are headed uh I let Marcel uh continue okay so let's first uh recap",
    "start": "1623000",
    "end": "1631480"
  },
  {
    "text": "what was the story so you know starting with celum celum supported only the atcd",
    "start": "1631480",
    "end": "1636960"
  },
  {
    "text": "mode then crds were introduced celium started working with crds in kubernetes",
    "start": "1636960",
    "end": "1643120"
  },
  {
    "text": "endpoint slices were introduced and now like we have beta celum endpoint slices",
    "start": "1643120",
    "end": "1648240"
  },
  {
    "text": "in cium so um what's the future so if you are interested in keeping track of",
    "start": "1648240",
    "end": "1653480"
  },
  {
    "text": "all those scalability related improvements in the context of celium this is the issue that you can follow",
    "start": "1653480",
    "end": "1659000"
  },
  {
    "text": "and um long story short there are actually three most important things to mention so first of all we want to make",
    "start": "1659000",
    "end": "1666039"
  },
  {
    "text": " Point slies slices stable and as hon showed before there is quite a lot of",
    "start": "1666039",
    "end": "1673039"
  },
  {
    "text": "tuning that you can do right now but if we want to support end users we want to make it really easy to use so you just",
    "start": "1673039",
    "end": "1681000"
  },
  {
    "text": "enable it and it works works at scale um but then like once we allow and say like",
    "start": "1681000",
    "end": "1686679"
  },
  {
    "text": "it's stable right like we need to have still CI testing so we want to actually cover scalability uh of and crds uh",
    "start": "1686679",
    "end": "1695799"
  },
  {
    "text": "in our CI testing so once we say it's stable and people start using it we want to make sure that there are no any",
    "start": "1695799",
    "end": "1702080"
  },
  {
    "text": "regressions so um and I'm saying 5,000 nodes again but you know the thing is",
    "start": "1702080",
    "end": "1707799"
  },
  {
    "text": "that it's it's way more than that like all the poch turn Network policies all this kind of stuff that I mentioned",
    "start": "1707799",
    "end": "1713480"
  },
  {
    "text": "before um and last but not least for for users who are running right now in KB",
    "start": "1713480",
    "end": "1718919"
  },
  {
    "text": "store mode we are working together with data do on making it possible to migrate from KB store to to crd um so I think",
    "start": "1718919",
    "end": "1726919"
  },
  {
    "text": "the biggest lesson learned with all of that is that you need to consider access",
    "start": "1726919",
    "end": "1733279"
  },
  {
    "text": "patterns in in your clusters because as the scale grows or the ch increases um",
    "start": "1733279",
    "end": "1739519"
  },
  {
    "text": "you need to be aware of amount of events that your control plane whatever it is either crd or LCD needs to handle and",
    "start": "1739519",
    "end": "1748200"
  },
  {
    "text": "that's the most important thing I think to to consider when scaling up the kubernetes um one more honorable mention",
    "start": "1748200",
    "end": "1755559"
  },
  {
    "text": "so even though we're kind of comparing endpoint slices and endpoint slices there is still some difference because",
    "start": "1755559",
    "end": "1762240"
  },
  {
    "text": "one is native kubernetes resource the other is crd and crds are basically",
    "start": "1762240",
    "end": "1769279"
  },
  {
    "text": "um Jon encoded sorry um so you know",
    "start": "1769279",
    "end": "1775399"
  },
  {
    "text": "native resources are are protuff crds are Json and this is some like this is",
    "start": "1775399",
    "end": "1781559"
  },
  {
    "text": "really important cap to keep track of I think even though you don't see",
    "start": "1781559",
    "end": "1787080"
  },
  {
    "text": "it um so um I would say um you know basically it's Cabo serializer and the",
    "start": "1787080",
    "end": "1793399"
  },
  {
    "text": "idea is that it will bring down the gap between you know native resource and",
    "start": "1793399",
    "end": "1798519"
  },
  {
    "text": "crds so super exciting stuff to look for but we still think like this is not",
    "start": "1798519",
    "end": "1804559"
  },
  {
    "text": "required for you know scaling in the context of for for crd mode uh so",
    "start": "1804559",
    "end": "1810880"
  },
  {
    "text": "thank you all uh if you are interested in scalability topics please chat with us um you can visit our Boo and also",
    "start": "1810880",
    "end": "1818679"
  },
  {
    "text": "please join six scalability channels it can be either or kubernetes we are on both of them and uh please share the",
    "start": "1818679",
    "end": "1826240"
  },
  {
    "text": "feedback thank you",
    "start": "1826240",
    "end": "1829960"
  },
  {
    "text": "and now I think we have five minutes for questions if there are no",
    "start": "1835399",
    "end": "1841740"
  },
  {
    "text": "[Laughter] Mar uh there is microphone somewhere I",
    "start": "1841740",
    "end": "1848880"
  },
  {
    "text": "okay yes I have a question why do you create separate celum identity if you",
    "start": "1848880",
    "end": "1855159"
  },
  {
    "text": "just to listen for label updates if you could just use a metadata M",
    "start": "1855159",
    "end": "1861600"
  },
  {
    "text": "meta watch for only metadata changes which is supported by kuber as a",
    "start": "1861600",
    "end": "1867919"
  },
  {
    "text": "feature so actually like S sim identities are not um not the",
    "start": "1867919",
    "end": "1875799"
  },
  {
    "text": "main source of term the end points are right so like it doesn't matter I think",
    "start": "1875799",
    "end": "1883679"
  },
  {
    "text": "and uh celum identities allow you to like group different work CLS together so you can configure how you want your",
    "start": "1883679",
    "end": "1890360"
  },
  {
    "text": "identities to be allocated so if you just focus on a certain set of labels you can aggregate different workloads",
    "start": "1890360",
    "end": "1897039"
  },
  {
    "text": "into just one identity so they all share one identity so we need that abstraction",
    "start": "1897039",
    "end": "1902320"
  },
  {
    "text": "to handle",
    "start": "1902320",
    "end": "1904919"
  },
  {
    "text": "that uh do you thanks uh really great talk and",
    "start": "1910840",
    "end": "1917480"
  },
  {
    "text": "interesting um I'm curious about the definition of churn rate so I I would have guessed that would have meant how",
    "start": "1917480",
    "end": "1923039"
  },
  {
    "text": "often pods are being created and deleted but is it actually how fast cubet is updating the status and is that another",
    "start": "1923039",
    "end": "1929360"
  },
  {
    "text": "screw you can turn this is very interesting question so it it depends",
    "start": "1929360",
    "end": "1934720"
  },
  {
    "text": "right like it depends on the component what it means right like um some components care only about po Creations",
    "start": "1934720",
    "end": "1942200"
  },
  {
    "text": "right but but still like even if you just watch for the pods you are receiving all of the updates right so",
    "start": "1942200",
    "end": "1948399"
  },
  {
    "text": "maybe you are interested in new pods being created like in Cube scheduler let's say right um so the Pod turn",
    "start": "1948399",
    "end": "1956799"
  },
  {
    "text": "usually means like all the creations deletions and updates to the pods uh but",
    "start": "1956799",
    "end": "1962840"
  },
  {
    "text": "depending on the context you know sometimes you care only on on about like some part of it I think uh but you are",
    "start": "1962840",
    "end": "1969960"
  },
  {
    "text": "basically receiving all of the updates always if you're interested in watching the B updates and is there anything you",
    "start": "1969960",
    "end": "1975440"
  },
  {
    "text": "can change that to say I only want to be updated on Chang just to certain fields or to tell cuet please update at a lower",
    "start": "1975440",
    "end": "1981440"
  },
  {
    "text": "frequency probably not so that's so about updating I think",
    "start": "1981440",
    "end": "1987760"
  },
  {
    "text": "so this is the purpose of priority and furnace and um that's one of the",
    "start": "1987760",
    "end": "1992799"
  },
  {
    "text": "advantages of crds and API server over over etcd that it take Can it can take",
    "start": "1992799",
    "end": "1998240"
  },
  {
    "text": "into account amount of churn and throttle different right requests thank",
    "start": "1998240",
    "end": "2003679"
  },
  {
    "text": "you and uh one of the reasons why CM endpoint was created itself is because",
    "start": "2003679",
    "end": "2008760"
  },
  {
    "text": "we don't care about all the Pod status updates so every time a somebody posts a pod status update we don't have to be",
    "start": "2008760",
    "end": "2014559"
  },
  {
    "text": "notified about it so the creating a separate object allows us to like decouple both of those things and make",
    "start": "2014559",
    "end": "2019880"
  },
  {
    "text": "sure we only keep the relevant information so yeah",
    "start": "2019880",
    "end": "2025840"
  },
  {
    "text": "thanks okay thank you thank",
    "start": "2028600",
    "end": "2033638"
  },
  {
    "text": "you",
    "start": "2036720",
    "end": "2039720"
  }
]
[
  {
    "text": "yeah all right cool what's going on everyone my name is Ryan I am going to be talking today about A Tale of Two",
    "start": "440",
    "end": "6600"
  },
  {
    "text": "flame graphs at least that's what the uh talk is titled um but really uh what I",
    "start": "6600",
    "end": "12440"
  },
  {
    "text": "hope for this to be is kind of a more practical guide to how you can get value from flame graphs from continuous",
    "start": "12440",
    "end": "19960"
  },
  {
    "text": "profiling uh those two are somewhat synonymous uh I'm going to get more into the nuances of what that all means",
    "start": "19960",
    "end": "26960"
  },
  {
    "text": "throughout this talk but uh yeah I hope by the end of this that you'll have an idea of how you can use flame graphs and",
    "start": "26960",
    "end": "32920"
  },
  {
    "text": "profiling to better understand your applications and understand things about it that you wouldn't be able to",
    "start": "32920",
    "end": "38760"
  },
  {
    "text": "otherwise understand with uh you know the other signals that are out there um so before I start as I said I'm Ryan um",
    "start": "38760",
    "end": "46680"
  },
  {
    "text": "I'm from Indianapolis originally uh moved out to Oakland to work on pyroscope with uh my co-founder Dimitri",
    "start": "46680",
    "end": "54840"
  },
  {
    "text": "over here um we were acquired by graffo later that's where I now work",
    "start": "54840",
    "end": "60800"
  },
  {
    "text": "um the uh as I guess as a side note one of the reasons why was that we we really felt like profiling had a lot of use",
    "start": "60800",
    "end": "68720"
  },
  {
    "text": "inside of the context of other logs metrics and traces and uh that seemed",
    "start": "68720",
    "end": "74320"
  },
  {
    "text": "easiest to do there um but that's a conversation for another time um yeah I",
    "start": "74320",
    "end": "80119"
  },
  {
    "text": "focus mostly on the product and ux side of profiling obviously there's a lot that goes into collecting profiling data",
    "start": "80119",
    "end": "87119"
  },
  {
    "text": "efficiently storing all these flame graphs um being able to query them from the technical side but all of that",
    "start": "87119",
    "end": "94479"
  },
  {
    "text": "doesn't necessarily mean anything or have any value if you aren't able to then analyze that data in a way that's",
    "start": "94479",
    "end": "100280"
  },
  {
    "text": "meaningful and valuable and so I spent a lot of time focusing on that and how we",
    "start": "100280",
    "end": "105360"
  },
  {
    "text": "can improve that within the uh within the project um as far as fun stuff I'm an",
    "start": "105360",
    "end": "111719"
  },
  {
    "text": "avid Super Smash Bros player I like disc golf trashy reality TV um yeah with that",
    "start": "111719",
    "end": "118000"
  },
  {
    "text": "let's go ahead and get into it what I'm I'm going to talk to talk about today uh what are flame graphs um different types",
    "start": "118000",
    "end": "125159"
  },
  {
    "text": "of profilers how profiling kind of fits into the overall observability space how",
    "start": "125159",
    "end": "131160"
  },
  {
    "text": "to efficiently you know manage the storage of profiles over time and uh the",
    "start": "131160",
    "end": "136720"
  },
  {
    "text": "main use cases for profiling and then finally uh I'm going to give some examples both uh real world of um some",
    "start": "136720",
    "end": "144080"
  },
  {
    "text": "internal things that we've done with profiling and also how it can be used to",
    "start": "144080",
    "end": "149360"
  },
  {
    "text": "uh help tell a story so starting with what are flame",
    "start": "149360",
    "end": "154440"
  },
  {
    "text": "graphs um this is a image by Julia Evans who's one of the uh creators of RB spy a",
    "start": "154440",
    "end": "161920"
  },
  {
    "text": "ruby profiler um and this is a abstract example but basically what a flame graph",
    "start": "161920",
    "end": "167599"
  },
  {
    "text": "is is it shows which parts of your code are consuming the most resources so that",
    "start": "167599",
    "end": "173120"
  },
  {
    "text": "can be CPU it can be Memory um it can be a number of other metrics that are",
    "start": "173120",
    "end": "178720"
  },
  {
    "text": "similarly formatted um but the way that you read these flame graphs and sometimes they're I guess",
    "start": "178720",
    "end": "185840"
  },
  {
    "text": "flipped um inverted vertically but uh the way you read them is that horizontally from left to right is 100%",
    "start": "185840",
    "end": "193560"
  },
  {
    "text": "of the time and then as you go up uh in this case this would be uh referencing",
    "start": "193560",
    "end": "199000"
  },
  {
    "text": "that main calls the function either alligator or Panda um 60% and 40% of the",
    "start": "199000",
    "end": "205440"
  },
  {
    "text": "time respectively then those functions would call you know these other fun functions and so um you basically read",
    "start": "205440",
    "end": "212000"
  },
  {
    "text": "it as a stack Trace vertically and then the width represents the almost like a pie chart the amount of time that was",
    "start": "212000",
    "end": "218720"
  },
  {
    "text": "spent uh by your application on that particular um you know function and uh",
    "start": "218720",
    "end": "225720"
  },
  {
    "text": "I'm going to get back to this piece here but um you know a common way that this has been used traditionally is is a",
    "start": "225720",
    "end": "231599"
  },
  {
    "text": "bunch of these kind of pipes to get the uh actual flame graph stuff and that's something that now as profiling has kind",
    "start": "231599",
    "end": "238799"
  },
  {
    "text": "of evolved has uh is slowly getting phased out in favor of more uh robust",
    "start": "238799",
    "end": "244640"
  },
  {
    "text": "kind of query languages and ability to query profiling data so um a slightly less abstract",
    "start": "244640",
    "end": "252799"
  },
  {
    "text": "version uh a version with actual code this is showing how um code that you",
    "start": "252799",
    "end": "257919"
  },
  {
    "text": "would actually write gets transformed into a flame graph and so in this case um this is just a obviously a very",
    "start": "257919",
    "end": "264479"
  },
  {
    "text": "simple Python program to show conceptually how this works and so um",
    "start": "264479",
    "end": "269759"
  },
  {
    "text": "you know if this were happening in server.py obviously server.py is happening 100% of the time and then you",
    "start": "269759",
    "end": "276000"
  },
  {
    "text": "see it either calls fast function or slow function which then call work uh",
    "start": "276000",
    "end": "281320"
  },
  {
    "text": "they each call work for a different amount of time and so you see that reflected here and that the slow",
    "start": "281320",
    "end": "287680"
  },
  {
    "text": "function is consuming you know 80% the fast function is consuming 20% and uh",
    "start": "287680",
    "end": "293600"
  },
  {
    "text": "the the work beneath it is reflected as well so yeah so there's two main types",
    "start": "293600",
    "end": "301320"
  },
  {
    "text": "of profilers I would say a lot of people um profiling Is Not A New Concept it's",
    "start": "301320",
    "end": "306440"
  },
  {
    "text": "something that's been around for a long time but traditionally uh I would say the you know kind of standard",
    "start": "306440",
    "end": "311880"
  },
  {
    "text": "traditional profilers the way you can get this information of how long is spent on a function or how many",
    "start": "311880",
    "end": "318240"
  },
  {
    "text": "resources are spent there um would require sort of inserting you know a a",
    "start": "318240",
    "end": "324000"
  },
  {
    "text": "function at the be or almost like a breakpoint at the beginning of a function at the end of a function then",
    "start": "324000",
    "end": "329600"
  },
  {
    "text": "recording you know some Metric in between sending that somewhere and being able to then you know catalog that over",
    "start": "329600",
    "end": "336360"
  },
  {
    "text": "time and while that is slightly more accurate uh or very accurate in in most",
    "start": "336360",
    "end": "343199"
  },
  {
    "text": "cases the um the overhead of that is so high that it doesn't make it something",
    "start": "343199",
    "end": "348400"
  },
  {
    "text": "that you could do in a practical sense in production for example you're just",
    "start": "348400",
    "end": "353520"
  },
  {
    "text": "adding a whole bunch of extra overhead to your application for um relatively uh",
    "start": "353520",
    "end": "359600"
  },
  {
    "text": "you know relative to that little benefit uh more as time has gone on a lot of",
    "start": "359600",
    "end": "365880"
  },
  {
    "text": "people have shifted to sampling profilers which rather than record every single little thing they uh sample the",
    "start": "365880",
    "end": "373039"
  },
  {
    "text": "stack Trace at some sort of frequency often times you'll hear maybe a 100 times per second um and then uh by by",
    "start": "373039",
    "end": "381160"
  },
  {
    "text": "that method you're able to get this profiling data from basically an outside process and not slow down your",
    "start": "381160",
    "end": "387599"
  },
  {
    "text": "application and also add a whole bunch of extra overhead and then you know you",
    "start": "387599",
    "end": "393479"
  },
  {
    "text": "collect that profiling data you send it off somewhere where it can be uh stored and queried efficiently um depending on",
    "start": "393479",
    "end": "401599"
  },
  {
    "text": "how you're doing the profiling you're able it may not even require runtime changes um you know some are in the form",
    "start": "401599",
    "end": "408919"
  },
  {
    "text": "of like a ruby gem or a pit package or something like that but other things like ebpf allow you to get profiling",
    "start": "408919",
    "end": "414680"
  },
  {
    "text": "data without um necessarily having to even change code within your application",
    "start": "414680",
    "end": "419919"
  },
  {
    "text": "and uh although it is technically slightly less accurate you do find that there's um you know directionally it's",
    "start": "419919",
    "end": "427120"
  },
  {
    "text": "close enough that uh you know again relative to the amount of overhead that you're saving by collecting the",
    "start": "427120",
    "end": "433400"
  },
  {
    "text": "profiling data this way you're able to um to get a lot of value from",
    "start": "433400",
    "end": "439800"
  },
  {
    "text": "it so here's a um so so how does profiling kind of fit in with the other",
    "start": "440199",
    "end": "445520"
  },
  {
    "text": "signals I mean I'm sure uh a lot of you have heard about metrics logs and traces",
    "start": "445520",
    "end": "450960"
  },
  {
    "text": "a lot of people often refer to profiling as kind of the next pillar of observability um it's uh yeah and so",
    "start": "450960",
    "end": "459080"
  },
  {
    "text": "profiling is really useful and I would say it's it's kind of on that um",
    "start": "459080",
    "end": "464800"
  },
  {
    "text": "Spectrum a little bit earlier stage than some of the other signals but I would say uh especially due to like otel and",
    "start": "464800",
    "end": "472840"
  },
  {
    "text": "um people's familiarity with the value they get from these other signals I would say that it's definitely moving uh",
    "start": "472840",
    "end": "478440"
  },
  {
    "text": "more quickly into um into people's workflows and so you know typically with",
    "start": "478440",
    "end": "484080"
  },
  {
    "text": "other signals like if you take logs for example the way uh you know it typically starts you probably console log a bunch",
    "start": "484080",
    "end": "491159"
  },
  {
    "text": "of things locally get a bunch of do put a bunch of debug statements somewhere you get some information you need to",
    "start": "491159",
    "end": "497720"
  },
  {
    "text": "debug something then as time goes on you might formalize that a little bit more you have it on some uh you know your",
    "start": "497720",
    "end": "504759"
  },
  {
    "text": "production machines maybe in your staging environment you have some sort of logs that you're able to you know",
    "start": "504759",
    "end": "510319"
  },
  {
    "text": "tail or ssh in and go look at when something's wrong and then you know",
    "start": "510319",
    "end": "515360"
  },
  {
    "text": "again as you start to mature even more depending on where your company lands on the sort of buy versus build you know",
    "start": "515360",
    "end": "521360"
  },
  {
    "text": "maybe you build some sort of storage to be able to collect this data um and query it back when you need it or um you",
    "start": "521360",
    "end": "529040"
  },
  {
    "text": "know potentially use some sort of database for uh whatever it is maybe using Prometheus or um or Loki or",
    "start": "529040",
    "end": "536839"
  },
  {
    "text": "something to store that or using a vendor to actually store all this data where you can then focus on actually",
    "start": "536839",
    "end": "543040"
  },
  {
    "text": "optimizing your application and so you know that's an example with logs I would say with profiles it's it's a little bit",
    "start": "543040",
    "end": "549560"
  },
  {
    "text": "more in that area um if you're using go profiling comes uh standard with the",
    "start": "549560",
    "end": "555959"
  },
  {
    "text": "runtime there and so um a lot of people are familiar in the go ecosystem with it",
    "start": "555959",
    "end": "561399"
  },
  {
    "text": "uh Ruby has some uh pretty strong profilers so does Java with the um with",
    "start": "561399",
    "end": "567279"
  },
  {
    "text": "JFR and uh and yeah and so a lot of people are familiar with it in the sense where they'll you know do a benchmark or",
    "start": "567279",
    "end": "573760"
  },
  {
    "text": "profile something have it stored uh you know maybe it's just a file on their desktop or um maybe there is something a",
    "start": "573760",
    "end": "580480"
  },
  {
    "text": "little bit more formal where you know you'll save something in and put it in an S3 bucket or something but the uh",
    "start": "580480",
    "end": "587480"
  },
  {
    "text": "what I would say there is that the a lot of the um profiling backends whether",
    "start": "587480",
    "end": "593279"
  },
  {
    "text": "that's open source or vendors are able to make profiling data much more um kind",
    "start": "593279",
    "end": "601200"
  },
  {
    "text": "of compact and efficient to both store it and query it just by the nature of how profiling data is set up relative to",
    "start": "601200",
    "end": "609560"
  },
  {
    "text": "metrics logs and traces and um and I'm going to show some examples of that in a second but it also sort of lends itself",
    "start": "609560",
    "end": "616680"
  },
  {
    "text": "really nicely to people kind of moving directly towards this uh sort of centralized optimized phase rather than",
    "start": "616680",
    "end": "624079"
  },
  {
    "text": "um having to spend too long on the sort of uh earlier stages of the maturity curve",
    "start": "624079",
    "end": "631040"
  },
  {
    "text": "um here's just some examples of what the uh UI for a continuous profile looks",
    "start": "631880",
    "end": "637720"
  },
  {
    "text": "like I'm going to um you know talk a lot about pyroscope today just because that's the one I'm most familiar with",
    "start": "637720",
    "end": "643600"
  },
  {
    "text": "but um there's uh Pixie uh which also is an open- Source profiler there's",
    "start": "643600",
    "end": "650079"
  },
  {
    "text": "parka um elastic they have there's is",
    "start": "650079",
    "end": "655360"
  },
  {
    "text": "not open source but uh whole system profiling um data dog so um a lot of",
    "start": "655360",
    "end": "661399"
  },
  {
    "text": "these companies are um you know again doing profiling but able to get this profiling data really inexpensively and",
    "start": "661399",
    "end": "668399"
  },
  {
    "text": "then add a lot of value by um you know kind of storing it efficiently and uh rendering it back to you and so I'm",
    "start": "668399",
    "end": "675680"
  },
  {
    "text": "going to talk a little bit about how that is um about how we were able to",
    "start": "675680",
    "end": "682160"
  },
  {
    "text": "achieve that conceptually inside of pyroscope again um these concepts are",
    "start": "682160",
    "end": "688279"
  },
  {
    "text": "you know might take different shapes and forms depending on who's doing them but at the end of the day um a lot of it",
    "start": "688279",
    "end": "694040"
  },
  {
    "text": "ends up being being very similar and so I already talked about how profiling data gets turned into a flame graph and",
    "start": "694040",
    "end": "701040"
  },
  {
    "text": "so now I'm going to talk about yeah like I said that that storage piece and the querying piece so the problem with you",
    "start": "701040",
    "end": "707800"
  },
  {
    "text": "know just taking this profiling data and storing it in you know in an S3 bucket or on a file system somewhere is that",
    "start": "707800",
    "end": "716040"
  },
  {
    "text": "the it's going to take up a lot of space particular ularly if you're doing continuous profiling where you're",
    "start": "716040",
    "end": "721800"
  },
  {
    "text": "getting you know a profile every you know maybe second or 10 seconds or over some period of time um and per host it's",
    "start": "721800",
    "end": "730399"
  },
  {
    "text": "it's going to add up really quickly and get to the point where you have so much data that you're paying for to store",
    "start": "730399",
    "end": "737000"
  },
  {
    "text": "that you're not getting more value than the cost it takes to just get this data to begin with and the way that we",
    "start": "737000",
    "end": "743360"
  },
  {
    "text": "address this is you know a profiling a profile you can think of as just a giant tree and so everything in a profile um",
    "start": "743360",
    "end": "751320"
  },
  {
    "text": "you know it starts at the main function which then calls some functions which then calls some functions and as you can",
    "start": "751320",
    "end": "757360"
  },
  {
    "text": "imagine especially um if you just think about what a stack Trace looks like there's a lot of repetition in it where",
    "start": "757360",
    "end": "764360"
  },
  {
    "text": "really the only main difference in a lot of cases is going to be the you know the bottom Leaf nodes and so by turning",
    "start": "764360",
    "end": "772199"
  },
  {
    "text": "these stack traces into a tree we're able to duplicate a bunch of the",
    "start": "772199",
    "end": "777560"
  },
  {
    "text": "information that we would than store and be able to like I said store that much more",
    "start": "777560",
    "end": "783959"
  },
  {
    "text": "efficiently and then on top of that not only the the stack traces but the symbols themselves within the stack",
    "start": "783959",
    "end": "790560"
  },
  {
    "text": "traces also have a lot of repetition so in this case you know the symbols being you know net HTTP requests net IO read",
    "start": "790560",
    "end": "798000"
  },
  {
    "text": "net IO write um here's kind of an example of how you would take those three um those three symbols and be able",
    "start": "798000",
    "end": "805279"
  },
  {
    "text": "to turn those into a uh try in order to compress the symbol names themselves in",
    "start": "805279",
    "end": "811639"
  },
  {
    "text": "addition to compressing the uh the stack traces and so then when you combine this",
    "start": "811639",
    "end": "818120"
  },
  {
    "text": "you know idea of compressing the stack Trace with compressing the symbol names you end up with a very uh efficient",
    "start": "818120",
    "end": "825480"
  },
  {
    "text": "representation of profiling data that you can then you know now when you're putting that into wherever the storage",
    "start": "825480",
    "end": "831920"
  },
  {
    "text": "system is you can um you know do so without it being too expensive and uh",
    "start": "831920",
    "end": "838399"
  },
  {
    "text": "help the the economics of kind of the the uh return on investment",
    "start": "838399",
    "end": "844320"
  },
  {
    "text": "there and so yeah so after you've stored all this data efficiently the the next",
    "start": "844720",
    "end": "850079"
  },
  {
    "text": "problem becomes then how do you query it efficiently you know now you have all this you know highly compact data that's",
    "start": "850079",
    "end": "856639"
  },
  {
    "text": "been stored in um you know some database or some storage somewhere and you want",
    "start": "856639",
    "end": "861680"
  },
  {
    "text": "to recall it back maybe you want to see you know how much resources were we spending on you know this part of our",
    "start": "861680",
    "end": "868000"
  },
  {
    "text": "architecture something along those lines and you're going to need to query that data back again if you're storing this",
    "start": "868000",
    "end": "874240"
  },
  {
    "text": "data along with these timestamps every you know 10 seconds and let's say you want to see a full days worth of data or",
    "start": "874240",
    "end": "880759"
  },
  {
    "text": "a week or a month whatever it might be if you aren't doing anything special on",
    "start": "880759",
    "end": "885880"
  },
  {
    "text": "the query side it's going to be a very expensive query because you're going to need to take a whole bunch of profiles",
    "start": "885880",
    "end": "893680"
  },
  {
    "text": "and merge them at query time and so the way that we address this was being able able to um basically do um use segment",
    "start": "893680",
    "end": "902480"
  },
  {
    "text": "trees to store the data at different granularities so that you're able to",
    "start": "902480",
    "end": "908040"
  },
  {
    "text": "decrease the amount of uh actual work that's needed in order to build these",
    "start": "908040",
    "end": "913279"
  },
  {
    "text": "profiles for whatever time range you're looking for um and so in this case like",
    "start": "913279",
    "end": "918639"
  },
  {
    "text": "I said by default it's going to you know store these profiles every 10 seconds and then um but then it's going to store",
    "start": "918639",
    "end": "925880"
  },
  {
    "text": "a you know 20 second time segment profile and a 40c Time segment profile",
    "start": "925880",
    "end": "931920"
  },
  {
    "text": "and that's going to you know continue on 80 uh you know so on and so forth and",
    "start": "931920",
    "end": "936959"
  },
  {
    "text": "what that allows is then let's say we want a query 50 seconds worth of data the the benefit of using these segment",
    "start": "936959",
    "end": "944000"
  },
  {
    "text": "trees is again now instead of having to merge four of those",
    "start": "944000",
    "end": "949399"
  },
  {
    "text": "10c um Time 10sec Flame graphs you're able to then you know uh basically merge",
    "start": "949399",
    "end": "956880"
  },
  {
    "text": "instead of doing four merge operations you you can just do one and you can take this 40-second flame graph a 10-second",
    "start": "956880",
    "end": "963759"
  },
  {
    "text": "flame graph merge the two of those rather than merge all four of these um",
    "start": "963759",
    "end": "970560"
  },
  {
    "text": "individually cool um okay so so once you have all of this data so you know that's",
    "start": "971680",
    "end": "976920"
  },
  {
    "text": "just kind of a highlevel conceptual idea of of how you can get all this data and",
    "start": "976920",
    "end": "982000"
  },
  {
    "text": "you know uh retrieve it efficiently store it efficiently quer it efficiently",
    "start": "982000",
    "end": "987199"
  },
  {
    "text": "um again the all of that's great from a technical perspective but then it comes down to after you've done all that what",
    "start": "987199",
    "end": "993399"
  },
  {
    "text": "is the actual value that you get from profiling what is the business case and",
    "start": "993399",
    "end": "998920"
  },
  {
    "text": "what I would say there is that there's there sort of um and we kind of learned this from both you know customers open",
    "start": "998920",
    "end": "1004560"
  },
  {
    "text": "source users people who we've talked to at Community calls stuff like that the issues people write there's kind of",
    "start": "1004560",
    "end": "1009600"
  },
  {
    "text": "three main use cases that we see um one is for cost cutting uh you know obviously if you understand where these",
    "start": "1009600",
    "end": "1016279"
  },
  {
    "text": "resources are being allocated you can then um know that you know let's say you're spending 100,000 on compute",
    "start": "1016279",
    "end": "1023040"
  },
  {
    "text": "resources if you then have a flame graph that represents your compute resources your CPU then now you can um use that to",
    "start": "1023040",
    "end": "1031438"
  },
  {
    "text": "say oh if we want to knock 10% off of that we should check out this flame graph figure out exactly where we can go",
    "start": "1031439",
    "end": "1037520"
  },
  {
    "text": "in order to make the find the uh you know the hot spots the low hanging fruit that are um kind of the biggest I guess",
    "start": "1037520",
    "end": "1044760"
  },
  {
    "text": "cost centers are the biggest things causing us cost um you also have Revenue generation this one's a little bit",
    "start": "1044760",
    "end": "1051480"
  },
  {
    "text": "harder to explain but uh I'll show an example in a second um but this one",
    "start": "1051480",
    "end": "1056720"
  },
  {
    "text": "often times latency for for many applications correlates to some loss or",
    "start": "1056720",
    "end": "1062919"
  },
  {
    "text": "gain in Revenue depending on which way the latency is moving and basically you",
    "start": "1062919",
    "end": "1068000"
  },
  {
    "text": "can then um you know if you're using profiling to understand that latency then you can often optimize that and be",
    "start": "1068000",
    "end": "1075000"
  },
  {
    "text": "able to uh have some kind of impact on your end users that might result in um",
    "start": "1075000",
    "end": "1080559"
  },
  {
    "text": "you know more revenue or uh not losing revenue and then finally the the one",
    "start": "1080559",
    "end": "1086080"
  },
  {
    "text": "that uh you know probably makes the is the easiest to understand is just debugging an incident resolution I would",
    "start": "1086080",
    "end": "1092120"
  },
  {
    "text": "say that um or I often say that that profiling is kind of the most fundamental uh uh you know when it comes",
    "start": "1092120",
    "end": "1100120"
  },
  {
    "text": "to understanding your performance data the most fundamental unit flame graphs they tell you a breakdown by line um",
    "start": "1100120",
    "end": "1107840"
  },
  {
    "text": "Often by line number by function all of that and being able to have that information whether you're looking using",
    "start": "1107840",
    "end": "1114400"
  },
  {
    "text": "logs metrics traces you know one of them all of them none of them having that granularity is always going to give get",
    "start": "1114400",
    "end": "1120960"
  },
  {
    "text": "you a little bit closer to finding the root cause of whatever issue you're looking at than without it and I'm going",
    "start": "1120960",
    "end": "1127840"
  },
  {
    "text": "to show an example of that in a second as well so um the so yeah so this is like a",
    "start": "1127840",
    "end": "1134360"
  },
  {
    "text": "a visualization that's kind of showing that the cost cutting uh you know idea in more detail uh we I say 3% here uh of",
    "start": "1134360",
    "end": "1142240"
  },
  {
    "text": "the overhead of profiling it often is much less you know occasionally it can be a little bit more but uh conceptually",
    "start": "1142240",
    "end": "1149480"
  },
  {
    "text": "the actual percentage you know to some extent with it being reasonably low",
    "start": "1149480",
    "end": "1154559"
  },
  {
    "text": "doesn't really matter whether it's you know 1 three five because the at the end of the day you know you likely aren't",
    "start": "1154559",
    "end": "1160720"
  },
  {
    "text": "running all of your uh you know applications at like 97% capacity where three is going to be",
    "start": "1160720",
    "end": "1166919"
  },
  {
    "text": "the difference between anything major but then you know again having this data",
    "start": "1166919",
    "end": "1172880"
  },
  {
    "text": "is so valuable that now you're able to understand so many other parts of your",
    "start": "1172880",
    "end": "1178159"
  },
  {
    "text": "infrastructure that you can then um you know optimize those in a way that you you know the profiling sort of pays for",
    "start": "1178159",
    "end": "1184520"
  },
  {
    "text": "itself very quickly um once you start to look into the flame graphs and understand your architecture better and",
    "start": "1184520",
    "end": "1190919"
  },
  {
    "text": "so you know I would say you know there's a lot of people who traditionally maybe",
    "start": "1190919",
    "end": "1196000"
  },
  {
    "text": "didn't Focus as much on costs and then you know in today's market environment",
    "start": "1196000",
    "end": "1201080"
  },
  {
    "text": "there's a lot more focus on efficiency and making sure that people are um you",
    "start": "1201080",
    "end": "1207159"
  },
  {
    "text": "know being efficient and not just you know scaling things up and instead understanding if uh yeah if if the the",
    "start": "1207159",
    "end": "1215159"
  },
  {
    "text": "return on investment for the various parts of the infrastructure actually match what you would expect or what you",
    "start": "1215159",
    "end": "1220679"
  },
  {
    "text": "would want or have budgeted and so uh for this 3% You Now understand",
    "start": "1220679",
    "end": "1226760"
  },
  {
    "text": "your usage of logs met and traces something that we often see is that a lot of people will worry about like oh",
    "start": "1226760",
    "end": "1233120"
  },
  {
    "text": "well 3% that sounds like a lot of overhead or or whatever it might be and then they start profiling and realize",
    "start": "1233120",
    "end": "1239080"
  },
  {
    "text": "that you know someone left a log line in production that's uh causing them to",
    "start": "1239080",
    "end": "1245240"
  },
  {
    "text": "spend maybe 10% just logging things mindlessly instead of um being more uh",
    "start": "1245240",
    "end": "1251760"
  },
  {
    "text": "strategic about what they're logging or maybe the trace sample rate is much higher than is actually needed and is",
    "start": "1251760",
    "end": "1257559"
  },
  {
    "text": "actually causing more overhead than they expected whatever it might be um messaging and queuing systems are also",
    "start": "1257559",
    "end": "1264880"
  },
  {
    "text": "very uh commonly offenders here you know it's something that's happening asynchronously so a lot of times people",
    "start": "1264880",
    "end": "1270799"
  },
  {
    "text": "will uh tend to write not as good of code there and uh and then it just",
    "start": "1270799",
    "end": "1276600"
  },
  {
    "text": "Stacks up over time to the point where then you know maybe the queue is overflowing and you want to understand",
    "start": "1276600",
    "end": "1281960"
  },
  {
    "text": "why if you don't have profiling that's a really tricky thing to debug but if you do have profiling you just go back in",
    "start": "1281960",
    "end": "1288640"
  },
  {
    "text": "time understand where the resources were going and break it",
    "start": "1288640",
    "end": "1293799"
  },
  {
    "text": "down um yeah here's here's an example as well uh and some of these statistics are",
    "start": "1294159",
    "end": "1299799"
  },
  {
    "text": "even a little bit old so uh this one's from a long time ago but uh again conceptually for every amount of uh for",
    "start": "1299799",
    "end": "1309240"
  },
  {
    "text": "every amount of latency it's more likely someone's going to leave their shopping cart or they're going to leave the app",
    "start": "1309240",
    "end": "1315640"
  },
  {
    "text": "uh for Google they said they generate 20% less traffic for every additional 500 milliseconds in latency and so again",
    "start": "1315640",
    "end": "1323120"
  },
  {
    "text": "having these profiles is really good at debugging that Uber had a really good blog post where they were talking about",
    "start": "1323120",
    "end": "1328320"
  },
  {
    "text": "their metrics ingestion and they didn't even realize that they were spending a",
    "start": "1328320",
    "end": "1333440"
  },
  {
    "text": "ton of time almost half the time doing a operation that was almost completely",
    "start": "1333440",
    "end": "1338960"
  },
  {
    "text": "unnecessary and so by cutting that out they were able to cut their ingestion latency in half and now again you're",
    "start": "1338960",
    "end": "1344799"
  },
  {
    "text": "able to uh much be much more efficient with the way that you're doing",
    "start": "1344799",
    "end": "1350440"
  },
  {
    "text": "things there um yeah this is just talking about other uh other Industries",
    "start": "1350440",
    "end": "1356760"
  },
  {
    "text": "where the same concept uh occurs uh you know fintech banking e-commerce",
    "start": "1356760",
    "end": "1362840"
  },
  {
    "text": "streaming everybody's uh who has dealt with that you know buffering lag and",
    "start": "1362840",
    "end": "1368919"
  },
  {
    "text": "online gaming advertising latency is extremely important there um this is just a number of other areas where you",
    "start": "1368919",
    "end": "1375559"
  },
  {
    "text": "can kind of see that and then visualizing again just conceptually that curve of how latency affects bounce",
    "start": "1375559",
    "end": "1381480"
  },
  {
    "text": "rates and revenue and that kind of stuff um and then on the incident side",
    "start": "1381480",
    "end": "1387360"
  },
  {
    "text": "uh here's an example that I don't know how easy it is to see up there but um",
    "start": "1387360",
    "end": "1392440"
  },
  {
    "text": "this was something from us internally where we had an outage and this is kind",
    "start": "1392440",
    "end": "1397480"
  },
  {
    "text": "of what it looks what uh you know before uh this was like right after we we joined the grafana team and uh after we",
    "start": "1397480",
    "end": "1404760"
  },
  {
    "text": "had started profiling everything in production and um you know so we have this outage people are used to looking",
    "start": "1404760",
    "end": "1411080"
  },
  {
    "text": "at uh you know at these Prometheus mamir charts and in this case um you know all",
    "start": "1411080",
    "end": "1418600"
  },
  {
    "text": "of the things that are happening here are not uh incredibly important to the point that I'm making but if you look at",
    "start": "1418600",
    "end": "1424240"
  },
  {
    "text": "this blue line here which I believe is um is just uh errors I think and so this",
    "start": "1424240",
    "end": "1432480"
  },
  {
    "text": "blue line here is erors you know you see one Spike here of this blue line you see another Spike here where it spikes up",
    "start": "1432480",
    "end": "1438120"
  },
  {
    "text": "very high and there's another issue here and then you know we thought we solved the problem and so this is Prof or this",
    "start": "1438120",
    "end": "1445559"
  },
  {
    "text": "is how you would you know maybe go through an incident if you didn't have profiling and you did have some sort of metrics that are at least letting you",
    "start": "1445559",
    "end": "1452039"
  },
  {
    "text": "know that something's wrong but then with profiling you know again so you can see here it's like 2120 to",
    "start": "1452039",
    "end": "1458600"
  },
  {
    "text": "2135 then 2140 to a little bit after uh you can see the same thing reflected",
    "start": "1458600",
    "end": "1465480"
  },
  {
    "text": "with continuous profiling the difference is that now these spikes are attached to",
    "start": "1465480",
    "end": "1471039"
  },
  {
    "text": "some sort of code that is attributed to them and so in this case you're able to",
    "start": "1471039",
    "end": "1476799"
  },
  {
    "text": "um use profiling use these and you're only seeing one flame graph here but there's actually two flame graphs that",
    "start": "1476799",
    "end": "1482679"
  },
  {
    "text": "are diffed in this uh result right here but you have one flame graph from where",
    "start": "1482679",
    "end": "1488279"
  },
  {
    "text": "things were healthy and then you have one flame graph from where things were unhealthy you're able to Overlay those",
    "start": "1488279",
    "end": "1493600"
  },
  {
    "text": "on top of each other and now you go from just knowing that there's these spikes with with these issues to knowing",
    "start": "1493600",
    "end": "1499640"
  },
  {
    "text": "exactly what caused them which lines of code are the ones that you should look at in order to debug those issues and I",
    "start": "1499640",
    "end": "1508679"
  },
  {
    "text": "just realized I forgot to run something so we'll see if that works um cool so uh so yeah so now I'm going",
    "start": "1508679",
    "end": "1517720"
  },
  {
    "text": "to go through an example showing some other cases where you can kind of use um",
    "start": "1517720",
    "end": "1524159"
  },
  {
    "text": "two flame graphs either uh of the of the the same application with different",
    "start": "1524159",
    "end": "1529679"
  },
  {
    "text": "labels or different time periods whatever it might be and uh basically you can use those flame graphs in order",
    "start": "1529679",
    "end": "1536440"
  },
  {
    "text": "to understand some resource similar to the example that I just showed where you can um yeah you can just more clearly",
    "start": "1536440",
    "end": "1543480"
  },
  {
    "text": "see what's what's going wrong so um this is a visualization kind of showing this",
    "start": "1543480",
    "end": "1549120"
  },
  {
    "text": "is like the uh joerger hot rod app basically just a a sample ride share application so if you can imagine that",
    "start": "1549120",
    "end": "1556799"
  },
  {
    "text": "you could apply this to really any any company that has um you know multiple servers whatever it might be uh we have",
    "start": "1556799",
    "end": "1563799"
  },
  {
    "text": "one in the east region one in the North Region one in the South Region and we've labeled those with the region tag and",
    "start": "1563799",
    "end": "1570600"
  },
  {
    "text": "then we have uh three different routes that we've labeled with the vehicle tag and every 10 seconds those servers are",
    "start": "1570600",
    "end": "1577520"
  },
  {
    "text": "collecting profiling data of what's happening on those servers and then sending those to the pyroscope server",
    "start": "1577520",
    "end": "1584039"
  },
  {
    "text": "where all of that fancy compression trees and tries stuff happen um and then that's where we'll be able",
    "start": "1584039",
    "end": "1590880"
  },
  {
    "text": "to then query this data from um when we want to see what's going on and so let",
    "start": "1590880",
    "end": "1596880"
  },
  {
    "text": "me show what it actually looks like in practice so so yeah so here make some",
    "start": "1596880",
    "end": "1603880"
  },
  {
    "text": "more space here um so yeah so here's what it looks like once you get into a",
    "start": "1603880",
    "end": "1609559"
  },
  {
    "text": "UI again each one is going to do this slightly differently but um effectively",
    "start": "1609559",
    "end": "1614640"
  },
  {
    "text": "do the same thing and so in this case we're able to see uh we're looking at the CPU from that image that I was just",
    "start": "1614640",
    "end": "1621919"
  },
  {
    "text": "showing you and we can look at the and we're looking specifically at the region tag to figure out um you know is there",
    "start": "1621919",
    "end": "1629000"
  },
  {
    "text": "something wrong with the region tag and in this case you can see there's a pie",
    "start": "1629000",
    "end": "1634320"
  },
  {
    "text": "chart that represents the CPU utilization for this application and for",
    "start": "1634320",
    "end": "1639440"
  },
  {
    "text": "some reason the north region is consuming 67% of CPU while the East and",
    "start": "1639440",
    "end": "1645399"
  },
  {
    "text": "the South regions are consuming significantly less now if this is your application maybe you just have more",
    "start": "1645399",
    "end": "1652720"
  },
  {
    "text": "people excuse me you have more people in this North Region and maybe that makes sense or maybe this is something that",
    "start": "1652720",
    "end": "1659120"
  },
  {
    "text": "seems a little suspicious to you either way being able to uh go in here and",
    "start": "1659120",
    "end": "1664480"
  },
  {
    "text": "click on these different regions see the flame graphs associated with each of them is uh you know a good start in",
    "start": "1664480",
    "end": "1671559"
  },
  {
    "text": "being able to debug why there's these differences between them and uh so if",
    "start": "1671559",
    "end": "1677200"
  },
  {
    "text": "here if I wanted to say compare uh we'll pick one of these regions where there's",
    "start": "1677200",
    "end": "1682240"
  },
  {
    "text": "not a lot of CPU being spent to this North Region so let's say we'll pick the East one in blue and the north one in",
    "start": "1682240",
    "end": "1689559"
  },
  {
    "text": "green and hit this compare tags button and so now we're able to let me select",
    "start": "1689559",
    "end": "1696360"
  },
  {
    "text": "the same time period here so now we're able to compare these",
    "start": "1696360",
    "end": "1701840"
  },
  {
    "text": "two side by side so you can see here we've selected the east region for this flame graph the North Region for this",
    "start": "1701840",
    "end": "1707679"
  },
  {
    "text": "flame graph and you know if you're looking at this and this is your application uh already you might start",
    "start": "1707679",
    "end": "1713919"
  },
  {
    "text": "to see that there's um some differences between them this this node here is only",
    "start": "1713919",
    "end": "1719600"
  },
  {
    "text": "taking uh is taking much less width of the entire application compared to this one and uh but again being able to see",
    "start": "1719600",
    "end": "1727120"
  },
  {
    "text": "these two flame graphs starts to be like okay uh we're starting to see something different between the East and the North",
    "start": "1727120",
    "end": "1733279"
  },
  {
    "text": "Region and then the the sort of next step to this is to then overlay these two flame graphs on top of each other",
    "start": "1733279",
    "end": "1740399"
  },
  {
    "text": "and be able to calculate the diff between them and so in this case now that we've overlaid them we can see that",
    "start": "1740399",
    "end": "1747279"
  },
  {
    "text": "the difference between this region and this region is that there's um you know",
    "start": "1747279",
    "end": "1752679"
  },
  {
    "text": "one is consuming 31% of CPU on uh this specific function and the other is",
    "start": "1752679",
    "end": "1758679"
  },
  {
    "text": "consuming 80 and so you can imagine that's uh super helpful and telling you",
    "start": "1758679",
    "end": "1763720"
  },
  {
    "text": "that um you know maybe there's something that you should look into with this driver availability function um and then",
    "start": "1763720",
    "end": "1770080"
  },
  {
    "text": "you can kind of follow it down to figure out what it calls um apparently in this case uh it may be a mutex lock uh like I",
    "start": "1770080",
    "end": "1777440"
  },
  {
    "text": "said this is just a conceptual example um that is causing that and and then you",
    "start": "1777440",
    "end": "1782880"
  },
  {
    "text": "would be able to go into the code fix that and potentially save a lot of CPU",
    "start": "1782880",
    "end": "1787960"
  },
  {
    "text": "um save a lot of money maybe fix an incident um the next one that I just",
    "start": "1787960",
    "end": "1795960"
  },
  {
    "text": "started running um",
    "start": "1795960",
    "end": "1803200"
  },
  {
    "text": "cool so then another example we talked a lot about",
    "start": "1803200",
    "end": "1809519"
  },
  {
    "text": "CPU um this one uh I'm going to show a memory example so uh you know the same",
    "start": "1809519",
    "end": "1817120"
  },
  {
    "text": "way CPU is useful you can do the same type of analysis with memory profiling as well um this is one that I I just",
    "start": "1817120",
    "end": "1824440"
  },
  {
    "text": "started uh running but you can see here here that there's clearly we're looking at uh Inus space for the same",
    "start": "1824440",
    "end": "1831480"
  },
  {
    "text": "application again broken down by region and in this case we're seeing that there's um that the the green and the",
    "start": "1831480",
    "end": "1838799"
  },
  {
    "text": "yellow ones are are fairly consistent but this blue one there's it's starting",
    "start": "1838799",
    "end": "1844120"
  },
  {
    "text": "to grow um if I had started this at the beginning of my talk like I meant to it would show a uh a clear memory leak you",
    "start": "1844120",
    "end": "1852399"
  },
  {
    "text": "can already see it starting to happen and uh again you you're able to kind of jump in here and compare these different",
    "start": "1852399",
    "end": "1858720"
  },
  {
    "text": "flame graphs to each other and uh you know if you're looking at them here it",
    "start": "1858720",
    "end": "1863960"
  },
  {
    "text": "might not be as clear but once you you click on that region where you do see things starting to spike um you can then",
    "start": "1863960",
    "end": "1870960"
  },
  {
    "text": "go in and see specifically what the issue is there and there's a uh cach",
    "start": "1870960",
    "end": "1876360"
  },
  {
    "text": "vehicle locations function that's consuming a bunch of the resources um the last one I will talk",
    "start": "1876360",
    "end": "1884519"
  },
  {
    "text": "about is one um that actually was uh part of the reason that we started pyroscope there was uh me and Dimitri",
    "start": "1884519",
    "end": "1893200"
  },
  {
    "text": "the other uh co-founder of it we were working at it at a previous company and",
    "start": "1893200",
    "end": "1898840"
  },
  {
    "text": "we were we started using profiling we were using RB spy um not in a continuous since but uh or I guess yeah we we kind",
    "start": "1898840",
    "end": "1905760"
  },
  {
    "text": "of built a hacky version of what now exists as pyroscope um and basically",
    "start": "1905760",
    "end": "1912039"
  },
  {
    "text": "what we realized once we started doing that was that we were we were doing a whole bunch of compression on some some",
    "start": "1912039",
    "end": "1917360"
  },
  {
    "text": "stuff that we were storing in um yeah storing for our company and basically we",
    "start": "1917360",
    "end": "1922639"
  },
  {
    "text": "didn't realize until we started doing profiling how much of that um how much",
    "start": "1922639",
    "end": "1928120"
  },
  {
    "text": "of our CPU resources were actually being spent on this compression and as it turned out by default the uh the library",
    "start": "1928120",
    "end": "1935639"
  },
  {
    "text": "that we were using defaults to like the maximum level of compression where it's consuming a ton of CPU to do that",
    "start": "1935639",
    "end": "1942159"
  },
  {
    "text": "compression and it was just not something that we needed it wasn't a conscious choice that we made to do that",
    "start": "1942159",
    "end": "1947799"
  },
  {
    "text": "much compression as soon as we uh changed it from the default to a much",
    "start": "1947799",
    "end": "1952880"
  },
  {
    "text": "lower level of compression we were able to save um I think it was like 20% on our compute Bill and uh our bosses were",
    "start": "1952880",
    "end": "1961519"
  },
  {
    "text": "were very happy and so um that was where we kind of started to realize that there's there there's probably so many",
    "start": "1961519",
    "end": "1967440"
  },
  {
    "text": "of these issues not just for us but for others where it's kind of you know lurking somewhere in the code you know",
    "start": "1967440",
    "end": "1973480"
  },
  {
    "text": "something that was not necessarily a conscious decision but has a major effect effect and again we would have never known that that's what all the CPU",
    "start": "1973480",
    "end": "1980279"
  },
  {
    "text": "was getting spent on until we see this breakdown um by function and by",
    "start": "1980279",
    "end": "1986519"
  },
  {
    "text": "line um yeah so that's all I have I guess the last thing I'll mention um obviously uh logs mates and traces uh",
    "start": "1986519",
    "end": "1994080"
  },
  {
    "text": "already have a little bit of a home inside of open Telemetry uh right now we are working hard uh and have been",
    "start": "1994080",
    "end": "2001760"
  },
  {
    "text": "working on for the past year and a halfish on um on getting Prof iling into",
    "start": "2001760",
    "end": "2007639"
  },
  {
    "text": "otel as well and so uh we will be at the otel booth uh talking about profiling so",
    "start": "2007639",
    "end": "2014480"
  },
  {
    "text": "we would love to hear anyone who has used this in any capacity or is interested in learning more feel free to",
    "start": "2014480",
    "end": "2020720"
  },
  {
    "text": "come by and chat with us about it um we have uh just proposed the new profiling",
    "start": "2020720",
    "end": "2027080"
  },
  {
    "text": "uh Otep uh the model for what profiling would look like in an otel context and",
    "start": "2027080",
    "end": "2033279"
  },
  {
    "text": "uh yeah are are looking for people's feedback on it so that's all I have I talked longer than I thought I would",
    "start": "2033279",
    "end": "2039760"
  },
  {
    "text": "so we only have 55 seconds for [Applause]",
    "start": "2039760",
    "end": "2048740"
  },
  {
    "text": "questions or just feel free to come up after because they're going to shut off the thing in a",
    "start": "2050760",
    "end": "2056760"
  },
  {
    "text": "second",
    "start": "2056760",
    "end": "2059760"
  }
]
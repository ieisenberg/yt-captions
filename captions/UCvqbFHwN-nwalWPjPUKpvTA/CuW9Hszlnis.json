[
  {
    "text": "hello everyone thanks for being there today um this session is part of the K MERS track",
    "start": "520",
    "end": "9280"
  },
  {
    "text": "we will explore some real world Integrations and recent cutting Cutting",
    "start": "9280",
    "end": "15559"
  },
  {
    "text": "Edge updates so first up let's do a quick round of introductions I'm Char",
    "start": "15559",
    "end": "22240"
  },
  {
    "text": "BR ker working at near mat and working exclusively on KERO and open source",
    "start": "22240",
    "end": "29679"
  },
  {
    "text": "project project um with me are my fantastic co-p speakers so Karen and",
    "start": "29679",
    "end": "35960"
  },
  {
    "text": "lanting can you tell us a word about you uh hi everyone I'm lanting I work on the",
    "start": "35960",
    "end": "41200"
  },
  {
    "text": "container orchestration team of Robin Hood and hello I'm Karen um lanting and",
    "start": "41200",
    "end": "46320"
  },
  {
    "text": "I work together to integrate cero into Robin Hood stack awesome today lenting",
    "start": "46320",
    "end": "52680"
  },
  {
    "text": "and Karen will kick things off by sharing their experience integrating",
    "start": "52680",
    "end": "57719"
  },
  {
    "text": "KERO into their platform uh after that I lead us to a deep dive",
    "start": "57719",
    "end": "64040"
  },
  {
    "text": "into kerno reporting system and highlight the latest improvements so",
    "start": "64040",
    "end": "69600"
  },
  {
    "text": "let's get started Karen can you start and present the",
    "start": "69600",
    "end": "76520"
  },
  {
    "text": "agenda okay so just a quick overview of what we're actually going to talk about",
    "start": "76840",
    "end": "82320"
  },
  {
    "text": "so lanting and I will start off with discussing why we actually decided to choose cerno out of all the options that",
    "start": "82320",
    "end": "89159"
  },
  {
    "text": "we had and then the process that we follow to actually install cerno and do some of um the migrations and also talk",
    "start": "89159",
    "end": "97119"
  },
  {
    "text": "about the strategy for storing policies as code and then we will pass it off to Charles to talk about one of the new",
    "start": "97119",
    "end": "104240"
  },
  {
    "text": "features in Cabo okay so I'm going to start off with",
    "start": "104240",
    "end": "110399"
  },
  {
    "text": "a little bit of context so um for those of you that don't know Robin Hood is a",
    "start": "110399",
    "end": "115560"
  },
  {
    "text": "brokerage firm so there are quite strict security and comp requirements which",
    "start": "115560",
    "end": "121520"
  },
  {
    "text": "makes um strong policy enforcement capabilities essential in our kubernetes clusters and this is kind of a slide",
    "start": "121520",
    "end": "128599"
  },
  {
    "text": "that represents the state of the world before we installed cerno so we had um",
    "start": "128599",
    "end": "135760"
  },
  {
    "text": "pod security policies that we used which um was a part of um kubernetes I say was",
    "start": "135760",
    "end": "142519"
  },
  {
    "text": "um because it is actually um removed in the most recent versions um but we were using pod security policies to enforce",
    "start": "142519",
    "end": "149519"
  },
  {
    "text": "things like whether a pod could use um the host Network for example and then the next um part of kubernetes um Native",
    "start": "149519",
    "end": "157280"
  },
  {
    "text": "that we used is um arbac just for managing um permissions to different",
    "start": "157280",
    "end": "162400"
  },
  {
    "text": "resources so this is just through things like cluster roles and cluster rle bindings and finally for the things that",
    "start": "162400",
    "end": "169200"
  },
  {
    "text": "native um PSPs and arbac couldn't cover we used our in-house admission server so",
    "start": "169200",
    "end": "175159"
  },
  {
    "text": "this is just um a deployment of um a admission server running as go code with",
    "start": "175159",
    "end": "181200"
  },
  {
    "text": "go code and um in combination with a web hook configuration and we can write like",
    "start": "181200",
    "end": "186760"
  },
  {
    "text": "arbitrary policies using that so I'm going to talk about a few",
    "start": "186760",
    "end": "192280"
  },
  {
    "text": "problems with the setup so I talked about how in the most recent versions of kubernetes pod security policies are",
    "start": "192280",
    "end": "198560"
  },
  {
    "text": "actually defecated um they were replaced with pod security admission and we had some problems with",
    "start": "198560",
    "end": "206040"
  },
  {
    "text": "arbec as well there are some things that we wanted to do um such as having fine",
    "start": "206040",
    "end": "211400"
  },
  {
    "text": "grain enforcement like having wild card matching for a resource name which is not actually supported um in C's native",
    "start": "211400",
    "end": "218480"
  },
  {
    "text": "arbac so um actually to get around that we could use our in-house admission server but with our in-house admission",
    "start": "218480",
    "end": "226319"
  },
  {
    "text": "server we also faced a whole Suite of issues so our team um was the and still",
    "start": "226319",
    "end": "232319"
  },
  {
    "text": "is the owner of the admission server code itself but there are other infrastructure teams that want to also",
    "start": "232319",
    "end": "239079"
  },
  {
    "text": "contribute different admission policies um and for other teams it was actually",
    "start": "239079",
    "end": "244720"
  },
  {
    "text": "kind of difficult to do this because they didn't fully understand that deploy strategy they didn't understand the",
    "start": "244720",
    "end": "250280"
  },
  {
    "text": "whole structure of the code so it was quite a toily process um for them to actually write this code and um beyond",
    "start": "250280",
    "end": "258000"
  },
  {
    "text": "that there um were some things that weren't abstracted away in the admission server such as um having a understanding",
    "start": "258000",
    "end": "265320"
  },
  {
    "text": "of how um informers work which not all infrastructure teams fully understood",
    "start": "265320",
    "end": "271400"
  },
  {
    "text": "so because of all of these issues we decided that we needed to kind of U make",
    "start": "271400",
    "end": "276960"
  },
  {
    "text": "an improvement and we had a few different options so um yeah so this is a slide",
    "start": "276960",
    "end": "284440"
  },
  {
    "text": "that summarizes all the options we had I didn't include um kerno on here because I'll actually go more in depth about",
    "start": "284440",
    "end": "291039"
  },
  {
    "text": "that later but um first talking about um the Pod security policy replacement",
    "start": "291039",
    "end": "297639"
  },
  {
    "text": "which is POD security admission pretty early on we decided that that wasn't a good fit for us because pod security",
    "start": "297639",
    "end": "304320"
  },
  {
    "text": "admission requires that you kind of categorize everything into three categories and we wanted something more",
    "start": "304320",
    "end": "309840"
  },
  {
    "text": "fine green than that so we need we needed something else other than po security admission the other option that we had",
    "start": "309840",
    "end": "317560"
  },
  {
    "text": "was to just improve our in-house admission server we could um choose to have our engineering time spent on",
    "start": "317560",
    "end": "324199"
  },
  {
    "text": "actually um having a much better framework that's easier for people to contribute to have better protection",
    "start": "324199",
    "end": "330280"
  },
  {
    "text": "um to prevent people from Landing bugs just because they don't understand um how informers work and um yeah so this",
    "start": "330280",
    "end": "337960"
  },
  {
    "text": "was something that was on the table but we also felt that um because our team",
    "start": "337960",
    "end": "343479"
  },
  {
    "text": "actually owns quite a few components um if there is a solution that exists out there that already has this it's not",
    "start": "343479",
    "end": "349960"
  },
  {
    "text": "really worth our effort to basically um reinvent something so um this is kind of",
    "start": "349960",
    "end": "355680"
  },
  {
    "text": "the short list that we had of the different um open source or or thirdparty admission servers that",
    "start": "355680",
    "end": "361520"
  },
  {
    "text": "existed so um one of them was day tree which we didn't we kind of eliminated",
    "start": "361520",
    "end": "368199"
  },
  {
    "text": "early on as well because it required having Central policy management and not",
    "start": "368199",
    "end": "373280"
  },
  {
    "text": "um having policy management internally so we didn't like that and then the next",
    "start": "373280",
    "end": "378400"
  },
  {
    "text": "one we actually looked at JS policy which was pretty attractive at first for a few reasons um it's very flexible and",
    "start": "378400",
    "end": "386319"
  },
  {
    "text": "the team behind it also made a lot of pretty popular um kubernetes projects but once we took a closer look we",
    "start": "386319",
    "end": "393039"
  },
  {
    "text": "realized it really was not production ready it was missing um a lot of basic",
    "start": "393039",
    "end": "398400"
  },
  {
    "text": "capabilities um related to tracing and metrics and it also wasn't used um at",
    "start": "398400",
    "end": "403880"
  },
  {
    "text": "least we didn't find any use cases at scale and we didn't want to be the guinea pigs for that so we decided not",
    "start": "403880",
    "end": "410080"
  },
  {
    "text": "to go with JS policy either so um in the end we had two serious condensers which",
    "start": "410080",
    "end": "415919"
  },
  {
    "text": "were um open um sorry Opa open policy agent and cerno so both Opa and cerno um",
    "start": "415919",
    "end": "423960"
  },
  {
    "text": "hit all of our hard requirements um except that Opa had one big drawback",
    "start": "423960",
    "end": "430120"
  },
  {
    "text": "which is that the policy language used for Opa is Rego and um unfortunately at",
    "start": "430120",
    "end": "436000"
  },
  {
    "text": "Robin Hood well maybe fortunately depending on your perspective um we don't have a history of using Rego and",
    "start": "436000",
    "end": "443400"
  },
  {
    "text": "that was not good because um arguably it would be harder to write a policy in Rego using opa than to just use our",
    "start": "443400",
    "end": "451360"
  },
  {
    "text": "existing in-house admission server and write go code so yeah like what would be the point of installing something new if",
    "start": "451360",
    "end": "456479"
  },
  {
    "text": "it's um just as or more difficult to use so for those reasons in the end cerno",
    "start": "456479",
    "end": "462919"
  },
  {
    "text": "ended up being um the winner out of all of the choices and I mentioned that it hit all of our hard requirements so um",
    "start": "462919",
    "end": "469840"
  },
  {
    "text": "that's kind of listed out on the slide here the first is that we wanted to um yeah constrain um any arbitrary um",
    "start": "469840",
    "end": "477680"
  },
  {
    "text": "requests to the kubernetes API because cerno is an admission controller it satisfies that and one important thing",
    "start": "477680",
    "end": "486360"
  },
  {
    "text": "that comes with cerno is some more mature tooling than what we had in our in-house admission server so um it's it",
    "start": "486360",
    "end": "494720"
  },
  {
    "text": "has a tool to actually um audit the existing resources in the cluster so if",
    "start": "494720",
    "end": "500520"
  },
  {
    "text": "you write a policy you can actually check to see how many of the existing resources it would reject and with our",
    "start": "500520",
    "end": "507960"
  },
  {
    "text": "in-house admission server we had to write custom scripts for um each policy that we wrote which is not very",
    "start": "507960",
    "end": "515080"
  },
  {
    "text": "sustainable and finally Cal policies are pretty easy to write so they are um",
    "start": "515080",
    "end": "521640"
  },
  {
    "text": "written in yaml and um any kuet engineer is pretty familiar with using yaml so we",
    "start": "521640",
    "end": "526920"
  },
  {
    "text": "were confident that other infrastructure teams would be able to learn this pretty quickly and I have a diagram here just",
    "start": "526920",
    "end": "533920"
  },
  {
    "text": "to show um the setup that we have with caverno currently so we don't actually",
    "start": "533920",
    "end": "539720"
  },
  {
    "text": "use all of the features we mainly just um rely on the policies and then some of like the more basic parts of the",
    "start": "539720",
    "end": "546440"
  },
  {
    "text": "admission controller so we don't use the reporting feature or the background scans and that's because in our initial",
    "start": "546440",
    "end": "553760"
  },
  {
    "text": "testing um we actually had some problems with um ET CD storage getting filled up",
    "start": "553760",
    "end": "558920"
  },
  {
    "text": "by reports but Charles will actually talk about how um cerno has worked on improving that so it might be a feature",
    "start": "558920",
    "end": "565800"
  },
  {
    "text": "that we will use in the future and these are some of the bonuses that",
    "start": "565800",
    "end": "571839"
  },
  {
    "text": "we get with cerno so not um in any of our hard requirements but definitely nice to have so caverno has a pretty",
    "start": "571839",
    "end": "578839"
  },
  {
    "text": "extensive um repository of policies that you can pull from so when we were switching over from our pod security",
    "start": "578839",
    "end": "586040"
  },
  {
    "text": "policies to KERO policies it was really nice to be able to um model off of",
    "start": "586040",
    "end": "591800"
  },
  {
    "text": "existing ones that were very similar to what we wanted to do and those even come with um integration tests and unit tests",
    "start": "591800",
    "end": "598440"
  },
  {
    "text": "as well and another great thing about kerno is that it is actively maintained",
    "start": "598440",
    "end": "603839"
  },
  {
    "text": "um the supporters are very responsive and um yeah we definitely didn't want to",
    "start": "603839",
    "end": "609079"
  },
  {
    "text": "be using a deprecated tool and have to end up maintaining that on our own so this is pretty important for us and",
    "start": "609079",
    "end": "615800"
  },
  {
    "text": "finally cerno has a pretty mature testing framework there is a CI CLI tool",
    "start": "615800",
    "end": "622000"
  },
  {
    "text": "that you can use which does kind of the equivalent of unit testing and there are also integration test tooling provided",
    "start": "622000",
    "end": "630040"
  },
  {
    "text": "and that was really great compared to our in-house admission server which didn't really have much enforcement of",
    "start": "630040",
    "end": "636680"
  },
  {
    "text": "testing it's kind of like you write a test if someone like does the proper code review if you remember which you",
    "start": "636680",
    "end": "642639"
  },
  {
    "text": "know of course is not a great strategy for having good test coverage so um just to give you a bit of",
    "start": "642639",
    "end": "650560"
  },
  {
    "text": "an overview for um how this process actually looked like we did the evaluation early last year so kind of a",
    "start": "650560",
    "end": "657920"
  },
  {
    "text": "while ago that's when we were facing problems with um infr teams not having a good time writing um the custom",
    "start": "657920",
    "end": "665399"
  },
  {
    "text": "admission plugins and also hitting some issues with our back not being customizable and then po security",
    "start": "665399",
    "end": "672240"
  },
  {
    "text": "policies getting deprecated so that's when we knew we had to look for other options um and because of",
    "start": "672240",
    "end": "678240"
  },
  {
    "text": "prioritization and different um yeah company objectives we ended up starting",
    "start": "678240",
    "end": "683279"
  },
  {
    "text": "to work on it at the beginning of this year so we did some initial testing and once that was complete then we worked on",
    "start": "683279",
    "end": "690120"
  },
  {
    "text": "actually integrating CNO um into our platform so that meant actually setting",
    "start": "690120",
    "end": "695560"
  },
  {
    "text": "up like all the testing framework to like automatically run at build time and just to make it easy for people to",
    "start": "695560",
    "end": "702079"
  },
  {
    "text": "contribute policies and once that was done then we started actually migrating all of our pod security policies into",
    "start": "702079",
    "end": "708519"
  },
  {
    "text": "CNO policies which lanting will talk um more in depth about and once that was",
    "start": "708519",
    "end": "714040"
  },
  {
    "text": "complete then we made the stance no more validating um custom plugins in our in",
    "start": "714040",
    "end": "719320"
  },
  {
    "text": "house admission server um unless there's a very good reason that it can't be done with caverno um and that's so that we",
    "start": "719320",
    "end": "726639"
  },
  {
    "text": "can kind of stop the bleeding um for people contributing and adding more to something that we want to get rid of and",
    "start": "726639",
    "end": "733040"
  },
  {
    "text": "we're currently in the process of upgrading cerno to a newer version to get some performance improvements um in",
    "start": "733040",
    "end": "740279"
  },
  {
    "text": "order to unblock us to do the work of moving more admission server um plugins",
    "start": "740279",
    "end": "746120"
  },
  {
    "text": "into cerno policies and then having the same stance that we did for validating",
    "start": "746120",
    "end": "751519"
  },
  {
    "text": "policies um for mutating policies so that we can remove our custom admission server as much as",
    "start": "751519",
    "end": "757560"
  },
  {
    "text": "possible and now I will pass it off to lanting yeah so I will talk a bit more",
    "start": "757560",
    "end": "764920"
  },
  {
    "text": "about how we did the P PSP migration in detail um so from this graph um you can",
    "start": "764920",
    "end": "770800"
  },
  {
    "text": "see that we first write a kebero cluster policy um in audit mode it's a yaml file",
    "start": "770800",
    "end": "778199"
  },
  {
    "text": "um and we deploy it the cluster what audit mode means is that for example if",
    "start": "778199",
    "end": "783279"
  },
  {
    "text": "we have a validating policy um if there is a resource that violates what the",
    "start": "783279",
    "end": "788360"
  },
  {
    "text": "policy validates against um it will still be able to get created but the violation will be logged and we can go",
    "start": "788360",
    "end": "795880"
  },
  {
    "text": "in and look at those logs and address the violation um either we uh codify",
    "start": "795880",
    "end": "801959"
  },
  {
    "text": "this violating workload as an exception or um we try to help them use something",
    "start": "801959",
    "end": "807120"
  },
  {
    "text": "else that does not violate the policy so um after a period of fake time we're",
    "start": "807120",
    "end": "813199"
  },
  {
    "text": "sure that okay this policy won't break anything then we change it to enforce mode um at this point if anything",
    "start": "813199",
    "end": "821399"
  },
  {
    "text": "violates the policy it will not be successfully created or updated um and we continue baking for a",
    "start": "821399",
    "end": "829760"
  },
  {
    "text": "while and once we are certain that ke no cluster policies fully replace the",
    "start": "829760",
    "end": "834839"
  },
  {
    "text": "functionality of Po security policies and they don't break anything we delete the Pod security",
    "start": "834839",
    "end": "841440"
  },
  {
    "text": "policies um and we turn off the Pod security policy admission controller",
    "start": "841440",
    "end": "847199"
  },
  {
    "text": "from the API server um and the specific validation that PSPs fully replace um",
    "start": "847199",
    "end": "855320"
  },
  {
    "text": "sorry uh cluster policies fully replace PSPs is done by testing um so we deploy",
    "start": "855320",
    "end": "861920"
  },
  {
    "text": "integration tests written with the keyber no chainsaw framework in the cluster um it's in the form of like try",
    "start": "861920",
    "end": "868160"
  },
  {
    "text": "creating a pod validate that this pod successfully gets created or it doesn't successfully get created because it's",
    "start": "868160",
    "end": "874639"
  },
  {
    "text": "blocked by this policy um so that way um we don't really need to do any manual",
    "start": "874639",
    "end": "880199"
  },
  {
    "text": "action here to validate the behavior um one thing to note is that the audit mode",
    "start": "880199",
    "end": "886199"
  },
  {
    "text": "only exists for validating policies so if you have mutating policies they go straight to mutating your resources so a",
    "start": "886199",
    "end": "893480"
  },
  {
    "text": "bit more caution needs to be done with testing there um and next up I will talk",
    "start": "893480",
    "end": "899440"
  },
  {
    "text": "about our break class scenarios so if we have a policy that's blocking something",
    "start": "899440",
    "end": "904720"
  },
  {
    "text": "really critical from coming up or it's breaking something um easiest way is to",
    "start": "904720",
    "end": "910240"
  },
  {
    "text": "delete that policy um and then figure out things from there um if uh somehow",
    "start": "910240",
    "end": "917440"
  },
  {
    "text": "we want to exempt an entire Nam space from keyber noose enforcement we can use",
    "start": "917440",
    "end": "922480"
  },
  {
    "text": "keyber no namespace filters so typically we exempt Cube system and the cubero",
    "start": "922480",
    "end": "927680"
  },
  {
    "text": "namespace itself from keber no's admission control to prevent any Deadlocks um and if somehow we just see",
    "start": "927680",
    "end": "936480"
  },
  {
    "text": "like very high latencies in the cluster due to admission control like something's broken we don't know what",
    "start": "936480",
    "end": "941800"
  },
  {
    "text": "yet um well we can still scale down the deploy uh the kerno deployment to zero",
    "start": "941800",
    "end": "947880"
  },
  {
    "text": "replicas or just delete the deployment um what this does is it also deletes the",
    "start": "947880",
    "end": "953639"
  },
  {
    "text": "validating web Hut configurations and mutating web Hut configurations that are managed by kerno so the API server stops",
    "start": "953639",
    "end": "961319"
  },
  {
    "text": "sending requests over to kerno um and we will figure out from there um and if all",
    "start": "961319",
    "end": "968399"
  },
  {
    "text": "that fails for some reason we can disable the validating admission web hook and mutating admission web hook",
    "start": "968399",
    "end": "975079"
  },
  {
    "text": "plugins from the API server um there are flags on the API server where you can list what admission web hooks you enable",
    "start": "975079",
    "end": "982279"
  },
  {
    "text": "um so these are our break glass scenarios um and I'll talk a bit about our policy structure",
    "start": "982279",
    "end": "989680"
  },
  {
    "text": "um so for each feature that we want to govern so for example if we only want our pods to use the following list of",
    "start": "989680",
    "end": "997240"
  },
  {
    "text": "volumes um we have one policy that selects all resources in the cluster by",
    "start": "997240",
    "end": "1002560"
  },
  {
    "text": "default um and we can exclude certain pods based on namespace and labels so um",
    "start": "1002560",
    "end": "1010240"
  },
  {
    "text": "these would be our exception use cases for example if a pod really wants to use host path okay we can exclude it from",
    "start": "1010240",
    "end": "1016319"
  },
  {
    "text": "this policy so it doesn't get blocked now now the problem then becomes there's nothing governing this pod so it can not",
    "start": "1016319",
    "end": "1022959"
  },
  {
    "text": "only use host path it can use like Star it can use whatever it wants um so we",
    "start": "1022959",
    "end": "1028199"
  },
  {
    "text": "create the second policy that selects the excluded resources and validates what they use so um with a combination",
    "start": "1028199",
    "end": "1035600"
  },
  {
    "text": "of these two types of policies we select all resources in the cluster um validate",
    "start": "1035600",
    "end": "1040918"
  },
  {
    "text": "some default thing while allowing for exceptions and finally I will talk about",
    "start": "1040919",
    "end": "1047760"
  },
  {
    "text": "how we do test um so Karen mentioned previously that kerno offer some really nice testing",
    "start": "1047760",
    "end": "1054280"
  },
  {
    "text": "Frameworks um so typically we start with a keber no CLI test that we run as a",
    "start": "1054280",
    "end": "1060400"
  },
  {
    "text": "unit test um at um I guess build time um",
    "start": "1060400",
    "end": "1066120"
  },
  {
    "text": "so the test structure is as follows um you select you import um some",
    "start": "1066120",
    "end": "1073080"
  },
  {
    "text": "test resources you import the policy that you want to test against and then",
    "start": "1073080",
    "end": "1078280"
  },
  {
    "text": "you deare something like this pod evaluated against this rule from this",
    "start": "1078280",
    "end": "1083799"
  },
  {
    "text": "policy should result in a pass or it should result in a skip because it's excluded or it should result in a",
    "start": "1083799",
    "end": "1090360"
  },
  {
    "text": "failure because it violates the policy Rule and it failed um so very easy declarative testing um and this can just",
    "start": "1090360",
    "end": "1098039"
  },
  {
    "text": "be run locally from your command line um and another test that we write is using",
    "start": "1098039",
    "end": "1105440"
  },
  {
    "text": "the keyer no chainsaw framework so these are end to tests that we deploy in our",
    "start": "1105440",
    "end": "1110799"
  },
  {
    "text": "CD pipeline um and the structure is like the following you try creating a pod and",
    "start": "1110799",
    "end": "1118960"
  },
  {
    "text": "you assert the behavior of um this pod creation so same thing um it would",
    "start": "1118960",
    "end": "1125159"
  },
  {
    "text": "successfully be created and maybe these fields would be added to the podspec because there's a mutating policy Etc um",
    "start": "1125159",
    "end": "1132400"
  },
  {
    "text": "so this seal this chainsaw test actually creates resources in the cluster and cleans it up and it runs every time our",
    "start": "1132400",
    "end": "1138880"
  },
  {
    "text": "CD pipeline runs um and with a combination of these two types of tests",
    "start": "1138880",
    "end": "1144280"
  },
  {
    "text": "we're pretty confident that our policies won't break anything um and this will conclude the",
    "start": "1144280",
    "end": "1151120"
  },
  {
    "text": "Robin Hood Journey section and we're giving thanks to Bashon suji Madu and",
    "start": "1151120",
    "end": "1156320"
  },
  {
    "text": "Nick people who helped us on this project next I will pass it on to Charles to talk about kerno",
    "start": "1156320",
    "end": "1164400"
  },
  {
    "text": "improvements thank you uh that's great feedback that's really interesting to",
    "start": "1164400",
    "end": "1169520"
  },
  {
    "text": "have this kind of feedback and how keano can help uh when integrated in um",
    "start": "1169520",
    "end": "1176720"
  },
  {
    "text": "existing platforms even with existing Solutions um on my side I will continue",
    "start": "1176720",
    "end": "1183000"
  },
  {
    "text": "this presentation focusing on cno's reporting system and deep dive into an",
    "start": "1183000",
    "end": "1189559"
  },
  {
    "text": "exciting new component the CNO report server uh the problem is that when",
    "start": "1189559",
    "end": "1196360"
  },
  {
    "text": "kivano operates at large scale the amount of reports generated and",
    "start": "1196360",
    "end": "1202559"
  },
  {
    "text": "managed by KERO can be huge and consume a lot of storage Um this can lead to",
    "start": "1202559",
    "end": "1209799"
  },
  {
    "text": "problematic situations where the storage system capacity becomes a a",
    "start": "1209799",
    "end": "1215440"
  },
  {
    "text": "bottleneck uh and eventually impacts the worldall cluster operation um so to",
    "start": "1215440",
    "end": "1222600"
  },
  {
    "text": "understand the challenges um better let's start with exploring our Kos",
    "start": "1222600",
    "end": "1228960"
  },
  {
    "text": "reporting system works and the type of reports it generates and uses so the",
    "start": "1228960",
    "end": "1236360"
  },
  {
    "text": "first uh type of report needed is uh when a request is submitted to the API",
    "start": "1236360",
    "end": "1245200"
  },
  {
    "text": "server um the IPI server will call into kerno to validate or mutate the resource",
    "start": "1245200",
    "end": "1253039"
  },
  {
    "text": "being processed and based on the policies installed in the cluster it produces results",
    "start": "1253039",
    "end": "1259240"
  },
  {
    "text": "and this results is what we call an admission time report",
    "start": "1259240",
    "end": "1264960"
  },
  {
    "text": "um so yes uh keep in mind that there's",
    "start": "1264960",
    "end": "1270000"
  },
  {
    "text": "no guarantee that the webbook will be called only once uh when there are",
    "start": "1270000",
    "end": "1275320"
  },
  {
    "text": "multiple web books sometimes a webbook can be called uh until the the the",
    "start": "1275320",
    "end": "1281679"
  },
  {
    "text": "mutated resource stabilizes um or that the submitted",
    "start": "1281679",
    "end": "1287120"
  },
  {
    "text": "resource will uh ultimately reach the cluster so maybe another webbook is",
    "start": "1287120",
    "end": "1292760"
  },
  {
    "text": "going to reject the resource so we potentially generate results for a",
    "start": "1292760",
    "end": "1297840"
  },
  {
    "text": "resource that will never exist um so therefore reports generated that this",
    "start": "1297840",
    "end": "1305039"
  },
  {
    "text": "stage um are intermediary and may be processed at the later stage or even in",
    "start": "1305039",
    "end": "1311360"
  },
  {
    "text": "some cases it may be just discarded um and of course uh there's uh",
    "start": "1311360",
    "end": "1317799"
  },
  {
    "text": "every admission time report is unique and it can it can grow to an",
    "start": "1317799",
    "end": "1325240"
  },
  {
    "text": "infinite number uh every admission request will generate a different",
    "start": "1325240",
    "end": "1330440"
  },
  {
    "text": "admission time report so that's the first case where KERO needs to generate a",
    "start": "1330440",
    "end": "1335679"
  },
  {
    "text": "report uh the second one is uh when a",
    "start": "1335679",
    "end": "1340720"
  },
  {
    "text": "policy or resource changes in the cluster or eventually on a predefined",
    "start": "1340720",
    "end": "1345760"
  },
  {
    "text": "schedule to make sure reports are up to date even when something changes externally uh in these cases Keno",
    "start": "1345760",
    "end": "1354960"
  },
  {
    "text": "fetches all manage resources all matching resources for a given policy it",
    "start": "1354960",
    "end": "1361080"
  },
  {
    "text": "evaluates the policies against the resources and produ produces new fmr",
    "start": "1361080",
    "end": "1367200"
  },
  {
    "text": "reports This Time background scan reports um they are limited to at most",
    "start": "1367200",
    "end": "1373840"
  },
  {
    "text": "one per resource uh we don't need to generate more than one uh so the number",
    "start": "1373840",
    "end": "1380919"
  },
  {
    "text": "of them is completely under control but they are still",
    "start": "1380919",
    "end": "1386080"
  },
  {
    "text": "intermediary reports and kept for later processing so they will have to be",
    "start": "1386080",
    "end": "1391760"
  },
  {
    "text": "somehow combined with admission time reports to produce the final report uh",
    "start": "1391760",
    "end": "1398120"
  },
  {
    "text": "and of course even if they are fmal reports that are not supposed to persist",
    "start": "1398120",
    "end": "1403960"
  },
  {
    "text": "for a long time in the cluster they can create a lot of storage ity and still",
    "start": "1403960",
    "end": "1409720"
  },
  {
    "text": "consume storage space finally uh we have a third type of",
    "start": "1409720",
    "end": "1416559"
  },
  {
    "text": "report which is called the policy report this time it is a long live report",
    "start": "1416559",
    "end": "1421760"
  },
  {
    "text": "report um every policy report belongs to a specific resource and it shares the",
    "start": "1421760",
    "end": "1428520"
  },
  {
    "text": "same life cycle when the resource is deleted from the cluster the report is deleted from the cluster when the",
    "start": "1428520",
    "end": "1434720"
  },
  {
    "text": "resource changes the report is updated and so on and um those policy reports",
    "start": "1434720",
    "end": "1440200"
  },
  {
    "text": "are built by um aggregating together the fmal reports created earlier so at",
    "start": "1440200",
    "end": "1447679"
  },
  {
    "text": "admissions time and eventually background scan time so to do that CNO",
    "start": "1447679",
    "end": "1453799"
  },
  {
    "text": "FES all FAL reports from the API server and therefore the underlying storage it",
    "start": "1453799",
    "end": "1461880"
  },
  {
    "text": "Aggregates them together with the current policy report if if any uh it up",
    "start": "1461880",
    "end": "1468399"
  },
  {
    "text": "updates the policy report um so in the storage again and ultimately it deletes",
    "start": "1468399",
    "end": "1475880"
  },
  {
    "text": "all the F reports that have been processed at this stage",
    "start": "1475880",
    "end": "1481679"
  },
  {
    "text": "so yes it does this update the policy report and delete reports that have been",
    "start": "1481679",
    "end": "1488640"
  },
  {
    "text": "processed so um that's it this is the only way we can get a",
    "start": "1488640",
    "end": "1495720"
  },
  {
    "text": "consistent report in a distributed system we can generate partial reports",
    "start": "1495720",
    "end": "1502840"
  },
  {
    "text": "and eventually update the final report because uh one request can go through",
    "start": "1502840",
    "end": "1508520"
  },
  {
    "text": "one API server another request can go through another API server uh in a",
    "start": "1508520",
    "end": "1514679"
  },
  {
    "text": "highly available mode you don't have a single API API",
    "start": "1514679",
    "end": "1520200"
  },
  {
    "text": "server uh and now we know everything about our reports are created and the",
    "start": "1520200",
    "end": "1526000"
  },
  {
    "text": "interactions with the API server storage it's obvious that it takes a lot",
    "start": "1526000",
    "end": "1531760"
  },
  {
    "text": "of read write and delet operations to get the final reports of course this can",
    "start": "1531760",
    "end": "1538200"
  },
  {
    "text": "impact the iepi server in one way or another so it can increase the API",
    "start": "1538200",
    "end": "1545360"
  },
  {
    "text": "server lad degrade performance and it also poses a significant operational",
    "start": "1545360",
    "end": "1551679"
  },
  {
    "text": "risk because if etcd uh is in trouble API server is in",
    "start": "1551679",
    "end": "1557039"
  },
  {
    "text": "trouble the Schuler is in in trouble the worldall cluster is in trouble um and",
    "start": "1557039",
    "end": "1562120"
  },
  {
    "text": "etcd has capacity limits so it's clear that we need to move the report",
    "start": "1562120",
    "end": "1569279"
  },
  {
    "text": "system out of etcd if we want to support large scale",
    "start": "1569279",
    "end": "1575279"
  },
  {
    "text": "clusters and here we are um fortunately the API",
    "start": "1575279",
    "end": "1581080"
  },
  {
    "text": "server I API aggregation layer enables just that by allowing different apis to",
    "start": "1581080",
    "end": "1589279"
  },
  {
    "text": "be handled by separate Services each service having its own storage so a",
    "start": "1589279",
    "end": "1595960"
  },
  {
    "text": "typical example is the metric server most of us have installed in their",
    "start": "1595960",
    "end": "1602159"
  },
  {
    "text": "clusters it's available in the API server but it is implemented in an",
    "start": "1602159",
    "end": "1607720"
  },
  {
    "text": "independent service and with its sound storage usually it's in memory and it",
    "start": "1607720",
    "end": "1614279"
  },
  {
    "text": "keeps in memory the different metrics so you ask the API server but the API",
    "start": "1614279",
    "end": "1619760"
  },
  {
    "text": "server doesn't itself serves the metrics it delegates this to another service in",
    "start": "1619760",
    "end": "1626480"
  },
  {
    "text": "the cluster and the report server follows the exact same principle uh as",
    "start": "1626480",
    "end": "1632919"
  },
  {
    "text": "you can see in this gam at the top kerno and triy are communicating with the API",
    "start": "1632919",
    "end": "1639960"
  },
  {
    "text": "server uh depending on the request the API server will either handle it",
    "start": "1639960",
    "end": "1646720"
  },
  {
    "text": "directly and uh interact with the cluster itcd storage so it's on the left",
    "start": "1646720",
    "end": "1652840"
  },
  {
    "text": "on the diagram if you request a config map pod anything it will be directly",
    "start": "1652840",
    "end": "1659240"
  },
  {
    "text": "handled by the API server and etcd uh if the request is about an foll",
    "start": "1659240",
    "end": "1666919"
  },
  {
    "text": "report or a policy report the API server will delegate handling to the report",
    "start": "1666919",
    "end": "1672799"
  },
  {
    "text": "server on the right and the report server can then use the storage of",
    "start": "1672799",
    "end": "1678600"
  },
  {
    "text": "choice uh it can be a postgress database it can be a separate tcd if you want it",
    "start": "1678600",
    "end": "1684919"
  },
  {
    "text": "can store reports in memory if you have a lot of memory why not um but in the end the report system",
    "start": "1684919",
    "end": "1695080"
  },
  {
    "text": "has its own storage and logic uh and uh and yeah that was the goal so finally",
    "start": "1695080",
    "end": "1704320"
  },
  {
    "text": "um with the report server all the report management and stuff is now offloaded",
    "start": "1704320",
    "end": "1710960"
  },
  {
    "text": "from the API server to the report server and the performance should now be",
    "start": "1710960",
    "end": "1716600"
  },
  {
    "text": "exactly the same with or without reporting enabled and the cluster",
    "start": "1716600",
    "end": "1722240"
  },
  {
    "text": "operations should not be put at risk anymore eventually the report system",
    "start": "1722240",
    "end": "1728279"
  },
  {
    "text": "will be down but it doesn't matter for the API server is going to continue",
    "start": "1728279",
    "end": "1735279"
  },
  {
    "text": "working well and it won't impact the cluster just because uh the report",
    "start": "1735279",
    "end": "1742200"
  },
  {
    "text": "system is down so we're probably going to lose a few reports but it's better to",
    "start": "1742200",
    "end": "1748799"
  },
  {
    "text": "lose reports than to break the cluster um so yes and as a bonus having the",
    "start": "1748799",
    "end": "1757480"
  },
  {
    "text": "reports in a relational database is a good thing because you can potentially",
    "start": "1757480",
    "end": "1763159"
  },
  {
    "text": "query those reports with um standard SQL statements SQL statements in English so",
    "start": "1763159",
    "end": "1770799"
  },
  {
    "text": "yeah that that can make sense uh even from a business point of view uh on top",
    "start": "1770799",
    "end": "1777279"
  },
  {
    "text": "of that uh some clusters were simply too large to enable report it would have uh",
    "start": "1777279",
    "end": "1784120"
  },
  {
    "text": "immediately um blocked etcd entirely so",
    "start": "1784120",
    "end": "1789440"
  },
  {
    "text": "this enables those new uh those extremely large clusters to use",
    "start": "1789440",
    "end": "1794960"
  },
  {
    "text": "reporting finally uh it doesn't benefit only Toano it can be uh useful for",
    "start": "1794960",
    "end": "1802720"
  },
  {
    "text": "others projects too as long as they use the policy reports here is uh like TRV",
    "start": "1802720",
    "end": "1808840"
  },
  {
    "text": "for example because it doesn't require any cut change everything happens in the API server so now we have a quick case",
    "start": "1808840",
    "end": "1816559"
  },
  {
    "text": "study before concluding the session uh on the left uh we have a",
    "start": "1816559",
    "end": "1822519"
  },
  {
    "text": "cluster without report server on the right a cluster with report server and then we meure",
    "start": "1822519",
    "end": "1829159"
  },
  {
    "text": "the etcd storage consumed uh at different level of PODS and reports so",
    "start": "1829159",
    "end": "1837080"
  },
  {
    "text": "there's 17 policies installed in those clusters from the pot security standards",
    "start": "1837080",
    "end": "1843000"
  },
  {
    "text": "and you can see that on the left um the etcd storage space grows rapidly and on",
    "start": "1843000",
    "end": "1849559"
  },
  {
    "text": "the right it stays relatively flat where the report server is installed the final",
    "start": "1849559",
    "end": "1856080"
  },
  {
    "text": "conclusion is that uh at 10,000 spots the ITC CD storage size is reduced by",
    "start": "1856080",
    "end": "1863880"
  },
  {
    "text": "More than 70% with the report server saving a",
    "start": "1863880",
    "end": "1870080"
  },
  {
    "text": "significant amount of storage space for regular API server",
    "start": "1870080",
    "end": "1876799"
  },
  {
    "text": "operations and yeah that's it uh it's almost the end of this session",
    "start": "1876799",
    "end": "1882200"
  },
  {
    "text": "so if there's a single thing to remember it's that Keno report system represents",
    "start": "1882200",
    "end": "1888919"
  },
  {
    "text": "a non negligable uh risk at high scales and",
    "start": "1888919",
    "end": "1894279"
  },
  {
    "text": "it's absolutely not safe to store reports in etcd above a certain size uh",
    "start": "1894279",
    "end": "1900880"
  },
  {
    "text": "for those big clusters the report server makes a huge difference highly reducing",
    "start": "1900880",
    "end": "1906399"
  },
  {
    "text": "the operational risks and preserving the performance of the cluster it's very",
    "start": "1906399",
    "end": "1911880"
  },
  {
    "text": "easy to install just an M chart so you deploy the M chart and you're done",
    "start": "1911880",
    "end": "1918559"
  },
  {
    "text": "you can bring your own database if needed you can bring your own cloud managed instance for example for reduced",
    "start": "1918559",
    "end": "1925639"
  },
  {
    "text": "maintenance if it's perfectly fine and yeah don't take an",
    "start": "1925639",
    "end": "1932000"
  },
  {
    "text": "unnecessary risk if you operate a big cluster give it a try and give us feedback and help us improve things so",
    "start": "1932000",
    "end": "1940039"
  },
  {
    "text": "yeah you have the link to the GitHub repository everything is available there",
    "start": "1940039",
    "end": "1945200"
  },
  {
    "text": "I think we're almost at the end maybe we can have one or two questions if any so",
    "start": "1945200",
    "end": "1952279"
  },
  {
    "text": "I don't",
    "start": "1952279",
    "end": "1954600"
  },
  {
    "text": "know you have questions oh Sor I'm wondering what what",
    "start": "1960919",
    "end": "1966440"
  },
  {
    "text": "does a large cluster look like like let's say you have 200 nodes and a few hundred new pods an hour is that",
    "start": "1966440",
    "end": "1972200"
  },
  {
    "text": "something where you'd think you'd have an issue or are we talking like much bigger clusters than that I think we're talking about much much bigger",
    "start": "1972200",
    "end": "1979000"
  },
  {
    "text": "clusters but it also depends on the number of policies so it's probably a",
    "start": "1979000",
    "end": "1986120"
  },
  {
    "text": "combination of number of resources and number of policies and also the activity",
    "start": "1986120",
    "end": "1994320"
  },
  {
    "text": "matters because the more admission requests the more processing you will",
    "start": "1994320",
    "end": "1999600"
  },
  {
    "text": "have to do uh I think it's hard to give um okay but I",
    "start": "1999600",
    "end": "2008440"
  },
  {
    "text": "guess it would it basically be like number of uh like number of nodes or pods times number of policies would be",
    "start": "2008440",
    "end": "2015279"
  },
  {
    "text": "like a general risk factor yeah okay",
    "start": "2015279",
    "end": "2020760"
  },
  {
    "text": "definitely uh I I don't know much about Cavo I haven't looked into it too much so I this might be a na naive question",
    "start": "2022440",
    "end": "2029399"
  },
  {
    "text": "can you load policies from file instead of from crd objects like from an empty d That's",
    "start": "2029399",
    "end": "2036519"
  },
  {
    "text": "managed by a side car you can do that the CLI does just that",
    "start": "2036519",
    "end": "2042159"
  },
  {
    "text": "um but of course if you're in a kubernetes cluster it's um easier to",
    "start": "2042159",
    "end": "2047639"
  },
  {
    "text": "load them from the uh from the control plane uh you can watch them if something",
    "start": "2047639",
    "end": "2053800"
  },
  {
    "text": "changes you get notified and things like this uh but yes I guess you could have a",
    "start": "2053800",
    "end": "2059398"
  },
  {
    "text": "complete provider I think we have to stop but we can continue with the cashs",
    "start": "2059399",
    "end": "2064440"
  },
  {
    "text": "in the corridor Okay so",
    "start": "2064440",
    "end": "2069520"
  }
]
[
  {
    "text": "thank you again we're gonna dive into the state of production machine learning in 2019 my name is Alejandro Salcedo",
    "start": "30",
    "end": "7830"
  },
  {
    "text": "you can find my Twitter down there I am the chief scientist at the Institute for ethically ion machine learning and I'm",
    "start": "7830",
    "end": "14549"
  },
  {
    "text": "also the engineering director at this open source company called Selden technologies the Institute is a research",
    "start": "14549",
    "end": "22140"
  },
  {
    "text": "center that focuses on building standards for the use of machine learning in production and Selden is an",
    "start": "22140",
    "end": "30539"
  },
  {
    "text": "open source machine learning deployment and orchestration platform that allows you to deploy your models from research",
    "start": "30539",
    "end": "37770"
  },
  {
    "text": "to production and you can check out and try out the platform with Selden on",
    "start": "37770",
    "end": "42870"
  },
  {
    "text": "Selden delaio so let's talk about data science projects so small data science projects in essence they are not not a",
    "start": "42870",
    "end": "50370"
  },
  {
    "text": "big problem so you tend to have two workflows the first one is model development and the second one is",
    "start": "50370",
    "end": "57320"
  },
  {
    "text": "serving your developed model you know it consists of the usual steps of you know",
    "start": "57320",
    "end": "62370"
  },
  {
    "text": "getting some data and cleaning it defining some features to transform the data selecting a model defined in",
    "start": "62370",
    "end": "68670"
  },
  {
    "text": "scoring metrics and then iterating once you're happy you persist that model and then it goes to production to be able to",
    "start": "68670",
    "end": "75030"
  },
  {
    "text": "serve any inference data that you see are coming through right so in small",
    "start": "75030",
    "end": "80939"
  },
  {
    "text": "projects it works relatively well however as our data science requirements grow we face new issues increasing",
    "start": "80939",
    "end": "89280"
  },
  {
    "text": "complexities of flow of data so who here has used crontab let's see a show of",
    "start": "89280",
    "end": "95549"
  },
  {
    "text": "hands yes so people may know what crontab nightmare looks like when you",
    "start": "95549",
    "end": "100619"
  },
  {
    "text": "scale to much without the process around it each data scientist has their own set",
    "start": "100619",
    "end": "106380"
  },
  {
    "text": "of tools so I'm like tensorflow our spark you know and good luck taking that you know away when when it's",
    "start": "106380",
    "end": "112770"
  },
  {
    "text": "actually a very productive to serving models becomes increasingly harder as",
    "start": "112770",
    "end": "118740"
  },
  {
    "text": "there's a larger number of them in production there's there's more high parameters and in place there's",
    "start": "118740",
    "end": "124710"
  },
  {
    "text": "different versions of each model running with different train data etc etc and",
    "start": "124710",
    "end": "130709"
  },
  {
    "text": "when stuff goes wrong it's hard to trace back not only in terms of the people that are involved but also the responsibility",
    "start": "130709",
    "end": "137160"
  },
  {
    "text": "that is laid so how do you manage who's whose person needs to be in charge of",
    "start": "137160",
    "end": "142530"
  },
  {
    "text": "what and then as your technical function grows also should your infrastructure",
    "start": "142530",
    "end": "149310"
  },
  {
    "text": "and that is where the concept of machine learning operations comes in so it is",
    "start": "149310",
    "end": "154620"
  },
  {
    "text": "this layer of complexity that is not just product or features it's also processes and best practices and it is",
    "start": "154620",
    "end": "163050"
  },
  {
    "text": "challenging the role of machine learning engineering is still being defined it is the intersection of software engineering",
    "start": "163050",
    "end": "169769"
  },
  {
    "text": "data science DevOps etc and not only that but when you see a job description",
    "start": "169769",
    "end": "176370"
  },
  {
    "text": "for machine learning engineer it tends to be something like we need a professional with a PhD you know five",
    "start": "176370",
    "end": "184470"
  },
  {
    "text": "years experience software development experience with DevOps tools like Jenkins you know data science experience",
    "start": "184470",
    "end": "191489"
  },
  {
    "text": "to build models consultant experience to figure out where to apply them so a",
    "start": "191489",
    "end": "196620"
  },
  {
    "text": "McKinsey consultant for a salary of an intern right that's what you tend to see in this sort of stuff so it is it is it",
    "start": "196620",
    "end": "203670"
  },
  {
    "text": "is currently being defined because it's a spectrum and we're gonna cover some of that and we've also mapped the ecosystem",
    "start": "203670",
    "end": "210329"
  },
  {
    "text": "we have another link that cannot be reached but it's still in the same repo",
    "start": "210329",
    "end": "215360"
  },
  {
    "text": "github.com slash ethical ml this has one",
    "start": "215360",
    "end": "220620"
  },
  {
    "text": "of the largest and longest toolset to be able to find frameworks to manage your",
    "start": "220620",
    "end": "228420"
  },
  {
    "text": "production machine learning if you see a tool that you can't see there please feel free to contribute the principles",
    "start": "228420",
    "end": "235890"
  },
  {
    "text": "that we're going to cover today however are the principles of reproducibility orchestration and explain ability so",
    "start": "235890",
    "end": "243239"
  },
  {
    "text": "let's get started with reproducibility reproducibility encompasses the concepts of model and data versioning so being",
    "start": "243239",
    "end": "251519"
  },
  {
    "text": "able to keep track of your models as they're in production but also in development as you train them this",
    "start": "251519",
    "end": "257700"
  },
  {
    "text": "requires an abstraction of the individual steps into atomic self-sustaining and versioned models and",
    "start": "257700",
    "end": "265409"
  },
  {
    "text": "it includes the data that comes the code slash configuration and the data that comes out and this is complex",
    "start": "265409",
    "end": "272490"
  },
  {
    "text": "not only because you already have the complete the challenge of keeping track of these three three different concepts",
    "start": "272490",
    "end": "280469"
  },
  {
    "text": "but also that it goes one level higher into the definition of your",
    "start": "280469",
    "end": "285479"
  },
  {
    "text": "computational pipeline and you may have some feature generators you may have some some models some some data cleaners",
    "start": "285479",
    "end": "292259"
  },
  {
    "text": "that you may want to use and reuse right so you need to keep track of what what is inside but how it how it all stitches",
    "start": "292259",
    "end": "299819"
  },
  {
    "text": "together and version that in in some cases as well so what we're going to",
    "start": "299819",
    "end": "305129"
  },
  {
    "text": "dive now into is a a case study an example of reusable pipelines in an NLP",
    "start": "305129",
    "end": "311099"
  },
  {
    "text": "use case so we're going to be using this technology that were contributing to you",
    "start": "311099",
    "end": "317520"
  },
  {
    "text": "can also you know access it through this link or it's on the gate repo which we're going to link but this is",
    "start": "317520",
    "end": "324900"
  },
  {
    "text": "basically what cube flow is it allows you to define computational pipelines of your machine learning and the",
    "start": "324900",
    "end": "331919"
  },
  {
    "text": "interesting thing about this is that we have reusable steps of an NLP pipeline what you see here is an NLP classifier",
    "start": "331919",
    "end": "339509"
  },
  {
    "text": "it basically takes an SL a sentence and it states whether it is it should be",
    "start": "339509",
    "end": "346560"
  },
  {
    "text": "moderated or not it's hateful speech or not and this is basically something that is done in forums we took the reddit",
    "start": "346560",
    "end": "353639"
  },
  {
    "text": "hate speech dataset which is basically the data set that moderators was",
    "start": "353639",
    "end": "359279"
  },
  {
    "text": "collected from moderators that removed comments and what we show here is we have a continuous stream of tweets and",
    "start": "359279",
    "end": "367159"
  },
  {
    "text": "these tweets are the brexit tweets I don't know if you're familiar with breaks it in the UK but it's basically",
    "start": "367159",
    "end": "373560"
  },
  {
    "text": "processing all of brexit and what we're gonna do here is we're gonna train another pipeline where the last step is",
    "start": "373560",
    "end": "380339"
  },
  {
    "text": "a deployment you know using Seldon so we're using cube flow to run that our loading of the data the cleaning of the",
    "start": "380339",
    "end": "386789"
  },
  {
    "text": "text the tokenization the vectorization the prediction etc so here you can see also in the logs the input and output I",
    "start": "386789",
    "end": "394110"
  },
  {
    "text": "think the tokenizer shows it a bit better so here you can see this the string and the tokens coming out right",
    "start": "394110",
    "end": "400649"
  },
  {
    "text": "so you can see through the UI and ability to train pipelines so we're gonna go here we're gonna select the pipeline that we define",
    "start": "400649",
    "end": "406620"
  },
  {
    "text": "programmatically and you know we're gonna create a trigger so there's gonna be row number four here we can define",
    "start": "406620",
    "end": "414660"
  },
  {
    "text": "some high parameters in this case we're giving our data set for the github comments but we can also have a Twitter",
    "start": "414660",
    "end": "422789"
  },
  {
    "text": "data set of like Arno sentiment analysis so as long as you pass a CSV file together with you know the name of the",
    "start": "422789",
    "end": "430710"
  },
  {
    "text": "column where you have the features the text and the name of the labels that you're gonna use to train your model",
    "start": "430710",
    "end": "436320"
  },
  {
    "text": "right you can also pass things like the number of tf-idf vectors so the the",
    "start": "436320",
    "end": "441710"
  },
  {
    "text": "Engram range and some hyper parameters for the different steps and then we can",
    "start": "441710",
    "end": "447030"
  },
  {
    "text": "actually just trigger it from the front-end we can just basically see the running pipeline in real time so this is",
    "start": "447030",
    "end": "453780"
  },
  {
    "text": "actually running in my local machine and as you know you know we don't have the best internet in this place at this",
    "start": "453780",
    "end": "460229"
  },
  {
    "text": "point so it's gonna probably take a while the first step what it did is it created a persistent value a persistent",
    "start": "460229",
    "end": "468300"
  },
  {
    "text": "volume claim and it's going to attach it to every single container so the",
    "start": "468300",
    "end": "474210"
  },
  {
    "text": "containers can use that volume to pass the data from one to the other step to the other step and this is interesting",
    "start": "474210",
    "end": "480419"
  },
  {
    "text": "because there's full provenance of the data that is currently available and what that means is that every single R",
    "start": "480419",
    "end": "488340"
  },
  {
    "text": "on the inputs and outputs of every single one of those steps is actually",
    "start": "488340",
    "end": "495419"
  },
  {
    "text": "stored in a persistent volume that then can be backed up right and then the",
    "start": "495419",
    "end": "500760"
  },
  {
    "text": "internet right now it's yeah it's like connection refused so I probably need you know that the VPN but I actually",
    "start": "500760",
    "end": "507900"
  },
  {
    "text": "have it like running on an online cluster that I'm going to show you because I was preparing for for this",
    "start": "507900",
    "end": "513810"
  },
  {
    "text": "just in case and I'm actually going to also connect to my server just in case",
    "start": "513810",
    "end": "518820"
  },
  {
    "text": "as well but yeah so basically what you're doing here is you're training a pipeline and the end end result will be",
    "start": "518820",
    "end": "526410"
  },
  {
    "text": "a basically a run that you're storing with with a",
    "start": "526410",
    "end": "531720"
  },
  {
    "text": "respective persistent volume so in this case you know it downloads it cleans it etcetera etc and everything",
    "start": "531720",
    "end": "538290"
  },
  {
    "text": "is stored in this persistent volume with the ultimate goal of deploying it into your kubernetes cluster so that is that",
    "start": "538290",
    "end": "544650"
  },
  {
    "text": "is the whole essence of this of this multiple steps that are involved there and you know there are also several",
    "start": "544650",
    "end": "551100"
  },
  {
    "text": "other tools that you can use for the reproducibility of your machine learning",
    "start": "551100",
    "end": "556640"
  },
  {
    "text": "such as you know this tool called beta version control this is I get hub get",
    "start": "556640",
    "end": "564000"
  },
  {
    "text": "like fork that also allows you to take to save state of all of the different",
    "start": "564000",
    "end": "571650"
  },
  {
    "text": "components they emit the data the code and the inputs and outputs etc so the",
    "start": "571650",
    "end": "579060"
  },
  {
    "text": "way that you interact with it is very similar to the way that you interact with kit and they have a very very",
    "start": "579060",
    "end": "584220"
  },
  {
    "text": "interesting approach ml flow is another tool from data bricks they have an",
    "start": "584220",
    "end": "590370"
  },
  {
    "text": "approach to manage your experiments and track your experiments and then finally we have another tool called pachyderm",
    "start": "590370",
    "end": "598520"
  },
  {
    "text": "pachyderm focuses on fully reproducible pipelines so there is actually a very",
    "start": "598520",
    "end": "604830"
  },
  {
    "text": "interesting integration that we that we do with with with pachyderm as well and",
    "start": "604830",
    "end": "610190"
  },
  {
    "text": "that is for this for the piece of reproducibility this is an interesting concept because all the all the",
    "start": "610190",
    "end": "616560"
  },
  {
    "text": "different parts of the grid that you saw you know I could dive for two hours and talk about them right so they are quite",
    "start": "616560",
    "end": "623850"
  },
  {
    "text": "complex but they're in the important thing from this talk is to get a feel of",
    "start": "623850",
    "end": "629190"
  },
  {
    "text": "the ecosystem and to more than anything just get involved and help the conversation help us push the",
    "start": "629190",
    "end": "636750"
  },
  {
    "text": "conversation forward now the second part is on model orchestration this involves",
    "start": "636750",
    "end": "642720"
  },
  {
    "text": "training and serving models at scale and this is basically what we do primarily at Seldon we we have an open source",
    "start": "642720",
    "end": "650340"
  },
  {
    "text": "framework that allows you to containerize language agnostic models this is this can be Python of course but",
    "start": "650340",
    "end": "657810"
  },
  {
    "text": "also can be Java are you know if you're feeling you know like a cowboy you can",
    "start": "657810",
    "end": "663660"
  },
  {
    "text": "also the Fortran I mean if you build a wrapper for it I don't know why you would but you also can and cap",
    "start": "663660",
    "end": "669030"
  },
  {
    "text": "so late legacy models and this involves also about serving at scale so it's not",
    "start": "669030",
    "end": "675390"
  },
  {
    "text": "just about the complexity of putting the models in production but it's about also orchestrating them",
    "start": "675390",
    "end": "680850"
  },
  {
    "text": "standardizing the metrics and we're gonna talk about that stuff so and this is a hard problem because it becomes a",
    "start": "680850",
    "end": "687840"
  },
  {
    "text": "computational resource allocation right its services with different computational requirements you know with",
    "start": "687840",
    "end": "693780"
  },
  {
    "text": "often complex computational graphs and you know we need to allocate the right",
    "start": "693780",
    "end": "698820"
  },
  {
    "text": "resources at the right time to also not overshoot right and this is a hard problem fortunately you know we have managed to",
    "start": "698820",
    "end": "706470"
  },
  {
    "text": "leverage a lot of the kubernetes infrastructure and with the you know",
    "start": "706470",
    "end": "712920"
  },
  {
    "text": "recent relatively recent debut of CR DS for you know the last two years we're",
    "start": "712920",
    "end": "719310"
  },
  {
    "text": "also able to abstract some of these complex concepts of infrastructure and",
    "start": "719310",
    "end": "724350"
  },
  {
    "text": "being able to define them define them in encapsulated components so then we can",
    "start": "724350",
    "end": "731150"
  },
  {
    "text": "suggest design patterns in the same way that you would in object-oriented",
    "start": "731150",
    "end": "737610"
  },
  {
    "text": "programming right and we're gonna actually cover some object-oriented",
    "start": "737610",
    "end": "743720"
  },
  {
    "text": "design patterns for your infrastructure as we discuss this and the reason why",
    "start": "743720",
    "end": "749970"
  },
  {
    "text": "also serving an unemployment of models is hard is because it introduces a layer",
    "start": "749970",
    "end": "755460"
  },
  {
    "text": "of governance and compliance so that already ambiguous field of machine",
    "start": "755460",
    "end": "761610"
  },
  {
    "text": "learning engineering that we touched upon is in the intersection with other",
    "start": "761610",
    "end": "767510"
  },
  {
    "text": "industry specific fields like policy expertise industry domain experts and",
    "start": "767510",
    "end": "773640"
  },
  {
    "text": "then that forms the centerpiece which is the the question of what are the standards you know what",
    "start": "773640",
    "end": "778680"
  },
  {
    "text": "what are they the key processes metrics you know a framework risk assessment",
    "start": "778680",
    "end": "785900"
  },
  {
    "text": "processes that we can have in place to make sure that we have our production machine learning following the right",
    "start": "785900",
    "end": "792330"
  },
  {
    "text": "policies etc etc and we're actually contributing to several algorithms with",
    "start": "792330",
    "end": "798480"
  },
  {
    "text": "I Triple E and several of the other bodies like ISO to define standards like the algorithmic bias",
    "start": "798480",
    "end": "804750"
  },
  {
    "text": "standard and in order for us to be able to go one level higher we need to define",
    "start": "804750",
    "end": "812070"
  },
  {
    "text": "the standardization of metrics right we've done this for microservices we know that latency is something that you",
    "start": "812070",
    "end": "818400"
  },
  {
    "text": "would track we know that requests per second errors but when it comes to when it comes to models you have other",
    "start": "818400",
    "end": "824580"
  },
  {
    "text": "metrics that you may have to standardize like accuracy precision recall model",
    "start": "824580",
    "end": "830310"
  },
  {
    "text": "divergence etc etc and what is interesting from from there is that then",
    "start": "830310",
    "end": "835950"
  },
  {
    "text": "is mapping those metrics with your internal policies to create this concept",
    "start": "835950",
    "end": "841230"
  },
  {
    "text": "we call programmatic governance right not only you define your policies you know with with actual writing but you're",
    "start": "841230",
    "end": "848460"
  },
  {
    "text": "able to also encode them in your impact and code them through your infrastructure right and in this case",
    "start": "848460",
    "end": "854820"
  },
  {
    "text": "what we provide is some you know standardized metrics with any model that you deploy in production but we are",
    "start": "854820",
    "end": "861600"
  },
  {
    "text": "currently working with the cube flow team and this is a very interesting initiative to create some standard for",
    "start": "861600",
    "end": "867720"
  },
  {
    "text": "for those metrics that are going to be exposed so that any met any any model",
    "start": "867720",
    "end": "873090"
  },
  {
    "text": "that is deployed in production it's not always going to have them but we can all",
    "start": "873090",
    "end": "878250"
  },
  {
    "text": "have at least an agreement that at least it should and that is that is an",
    "start": "878250",
    "end": "883950"
  },
  {
    "text": "important thing the second piece is also standardization of errors and logging right right now a lot of the times it is",
    "start": "883950",
    "end": "890850"
  },
  {
    "text": "data scientists having to maintain their models in production but with the introduction of these tools you're able",
    "start": "890850",
    "end": "896970"
  },
  {
    "text": "to create a division so that there is a distribution of responsibilities there",
    "start": "896970",
    "end": "902340"
  },
  {
    "text": "the scientists the data science sis admins do sysadmin right and you can",
    "start": "902340",
    "end": "909270"
  },
  {
    "text": "also then go into higher-level tasks like complex deployment strategies so with Selden you can do things like",
    "start": "909270",
    "end": "916100"
  },
  {
    "text": "explanations lie detection feature transformations etc but this is about defining your computational graph",
    "start": "916100",
    "end": "922700"
  },
  {
    "text": "specific to machine learning right so so this is not new and and super",
    "start": "922700",
    "end": "929630"
  },
  {
    "text": "cutting-edge in terms of the higher level but it's what is new is being able",
    "start": "929630",
    "end": "935430"
  },
  {
    "text": "to abstract it into machine you know abstracting infrastructure into machine learning and and then is",
    "start": "935430",
    "end": "942240"
  },
  {
    "text": "introducing get-ups so we're going to dive into this example has anyone here",
    "start": "942240",
    "end": "947850"
  },
  {
    "text": "heard of this new platform called PI",
    "start": "947850",
    "end": "952860"
  },
  {
    "text": "torch hub or tensorflow hub let's see a show of hands peiter job tensorflow hub",
    "start": "952860",
    "end": "958350"
  },
  {
    "text": "okay cool so basically what that is is a repository where researchers and",
    "start": "958350",
    "end": "964339"
  },
  {
    "text": "engineers they can actually submit their trained models things like Bert G GP to",
    "start": "964339",
    "end": "972470"
  },
  {
    "text": "things like vgg all of those neural networks and models that were trained on",
    "start": "972470",
    "end": "979079"
  },
  {
    "text": "massive scale data or just models that you've trained can be actually just put in github and made available so you have",
    "start": "979079",
    "end": "986610"
  },
  {
    "text": "that way of versioning that we discussed previously with your code and model and",
    "start": "986610",
    "end": "992910"
  },
  {
    "text": "configuration right so what we do is we're able to provide an integration and",
    "start": "992910",
    "end": "999179"
  },
  {
    "text": "this is all open source by the way this whole open source we're gonna show all of the examples are available online",
    "start": "999179",
    "end": "1005350"
  },
  {
    "text": "we're able to have a direct integration get-ups integration with the PI torch",
    "start": "1005350",
    "end": "1011300"
  },
  {
    "text": "our github and what get-ups is it basically means you keep in sync your",
    "start": "1011300",
    "end": "1017569"
  },
  {
    "text": "your github definition and your production environment so some if",
    "start": "1017569",
    "end": "1022730"
  },
  {
    "text": "something changes and github something changes in your production right and that is sort of your layer of sort of",
    "start": "1022730",
    "end": "1030730"
  },
  {
    "text": "quality that you make sure that there's an approval process around that and in this case we provide that get-ups layer",
    "start": "1030730",
    "end": "1038089"
  },
  {
    "text": "between pi towards whenever a new change comes in then the the seldom gets",
    "start": "1038089",
    "end": "1044240"
  },
  {
    "text": "triggered it wraps and container ices the model and then the model is put into production it could be like you know a",
    "start": "1044240",
    "end": "1050480"
  },
  {
    "text": "simple model it could be you know an a/b test it could be a a stacked set of",
    "start": "1050480",
    "end": "1057770"
  },
  {
    "text": "models etc etc and then we're gonna dive into that example so so basically you",
    "start": "1057770",
    "end": "1064370"
  },
  {
    "text": "know the first example was here you can actually build your NLP pipeline you can try it out yourself",
    "start": "1064370",
    "end": "1070679"
  },
  {
    "text": "but now we're gonna dive into into the next example which is you know building production level piped or chopped models",
    "start": "1070679",
    "end": "1077129"
  },
  {
    "text": "in kubernetes with ten lines of code for it to look like that the ultimate",
    "start": "1077129",
    "end": "1082620"
  },
  {
    "text": "objective is to separate concerns right your data scientist is able to use the",
    "start": "1082620",
    "end": "1088139"
  },
  {
    "text": "models your Sree develops person is able to manage them and monitor them right",
    "start": "1088139",
    "end": "1094049"
  },
  {
    "text": "that does the main thing is how to abstract and distribute concerns and separate concern",
    "start": "1094049",
    "end": "1100049"
  },
  {
    "text": "so let's actually zoom in so the process that the steps that you would do is you would basically first just create a",
    "start": "1100049",
    "end": "1106710"
  },
  {
    "text": "wrapper in this case for Python of your model create a wrapper of your model",
    "start": "1106710",
    "end": "1111750"
  },
  {
    "text": "that has a predict function so anything that has that you know takes an input",
    "start": "1111750",
    "end": "1117659"
  },
  {
    "text": "and returns an output can be wrapped in this case we can take nan PI race but we",
    "start": "1117659",
    "end": "1123509"
  },
  {
    "text": "choose to take the highly optimized tensor through through the byte",
    "start": "1123509",
    "end": "1129889"
  },
  {
    "text": "serialization right so what this does is a wrapper that takes some tensor runs it",
    "start": "1129889",
    "end": "1136289"
  },
  {
    "text": "through the loaded model and returns the inference result right it just so",
    "start": "1136289",
    "end": "1142590"
  },
  {
    "text": "happens that when it's initialized it calls torch hub load and it loads the",
    "start": "1142590",
    "end": "1148980"
  },
  {
    "text": "specific model right so what this basically does is it's a wrapper for tent for tighter job that is able to",
    "start": "1148980",
    "end": "1156990"
  },
  {
    "text": "load models dynamically from PI to chop and once it's in production you know",
    "start": "1156990",
    "end": "1162779"
  },
  {
    "text": "when you send any requests it's going to basically be able to you know run run",
    "start": "1162779",
    "end": "1168269"
  },
  {
    "text": "everything through that model so what we will do is we will just save this in a file so we're doing right file in",
    "start": "1168269",
    "end": "1173730"
  },
  {
    "text": "deployment image PI torch cell and deployment of Pi then we specify the",
    "start": "1173730",
    "end": "1179490"
  },
  {
    "text": "requirements of that you know code of that Python code this requires PI torch",
    "start": "1179490",
    "end": "1186509"
  },
  {
    "text": "numpy the image pill library and then we create a configuration library that says",
    "start": "1186509",
    "end": "1193320"
  },
  {
    "text": "what's the name of the model that we're sorry' the name of our wrapping class wrapper class and then we just use the",
    "start": "1193320",
    "end": "1200309"
  },
  {
    "text": "s2i tool to be able to build it these basically contain arises it and",
    "start": "1200309",
    "end": "1207270"
  },
  {
    "text": "builds a docker container that has a REST API and a G RPC API together with",
    "start": "1207270",
    "end": "1214350"
  },
  {
    "text": "Prometheus metrics containerized with with that wrapper so now if we spin up",
    "start": "1214350",
    "end": "1221070"
  },
  {
    "text": "that that that container if we pass the model that we want it would basically",
    "start": "1221070",
    "end": "1226880"
  },
  {
    "text": "dynamically pull that model from tighter job right so we basically created our Selden",
    "start": "1226880",
    "end": "1233760"
  },
  {
    "text": "configuration and every time that we trigger it we just say I want imagenet",
    "start": "1233760",
    "end": "1239970"
  },
  {
    "text": "or Inception b3 and it just basically pulls it and deploys it into kubernetes",
    "start": "1239970",
    "end": "1245520"
  },
  {
    "text": "right so in this case we define our like a Yama file that specifies that image",
    "start": "1245520",
    "end": "1252690"
  },
  {
    "text": "that we just built so is that containerized pi-thirds wrapper and the only difference is that",
    "start": "1252690",
    "end": "1259200"
  },
  {
    "text": "here we have a replacer for the parameters that we pass so this is our",
    "start": "1259200",
    "end": "1264390"
  },
  {
    "text": "own Selden definition right so you define the containers and then you",
    "start": "1264390",
    "end": "1269580"
  },
  {
    "text": "define the computational graph right in this case it's just a computational graph of one node and we're passing the",
    "start": "1269580",
    "end": "1276240"
  },
  {
    "text": "parameter model name which in this case would be you know vgg 11 or BG 19 or it",
    "start": "1276240",
    "end": "1284790"
  },
  {
    "text": "can be Bert right whatever it is and what then it does it basically deploys",
    "start": "1284790",
    "end": "1291150"
  },
  {
    "text": "it so here we're just actually doing a set replace so we're deploying the mobile net and then when you actually",
    "start": "1291150",
    "end": "1297510"
  },
  {
    "text": "run it you can see that it's actually running because we pass those parameters",
    "start": "1297510",
    "end": "1302730"
  },
  {
    "text": "it's called PI to shop and mobile net right m-net and we can actually you know get",
    "start": "1302730",
    "end": "1308940"
  },
  {
    "text": "the logs to see that it actually downloads it and then runs runs the application and then we can just send",
    "start": "1308940",
    "end": "1314880"
  },
  {
    "text": "rest requests right so we create a seldom rest client but you can also do",
    "start": "1314880",
    "end": "1320370"
  },
  {
    "text": "curl or postman or whatever and we load an image so this is the image of this",
    "start": "1320370",
    "end": "1327480"
  },
  {
    "text": "dog we convert that image into tensors and we send the bytes of those tensors",
    "start": "1327480",
    "end": "1333260"
  },
  {
    "text": "for getting like that request and response right so we Pikul and then we just send the predict",
    "start": "1333260",
    "end": "1339960"
  },
  {
    "text": "and then similarly here we're doing so here yeah we're on pickling the response right so is it sending the request and",
    "start": "1339960",
    "end": "1346799"
  },
  {
    "text": "then we get the response so it's basically a REST API a G RPC and rest API that you deployed and now you can",
    "start": "1346799",
    "end": "1353100"
  },
  {
    "text": "interact with write so ultimately you build your model in Python you build a",
    "start": "1353100",
    "end": "1358860"
  },
  {
    "text": "wrapper and then you're able to just deploy it as many times as you want you",
    "start": "1358860",
    "end": "1364049"
  },
  {
    "text": "can have your replicas scales etc etc you get all the benefits that kubernetes",
    "start": "1364049",
    "end": "1369629"
  },
  {
    "text": "gives you and again you know this example is online so you can actually jump in and try it out so that is for",
    "start": "1369629",
    "end": "1377309"
  },
  {
    "text": "that so again you know check it out that's gonna be on this and again for the people that I just arrived is",
    "start": "1377309",
    "end": "1382860"
  },
  {
    "text": "github.com slash ethical ml and then you'll see state of machine learning",
    "start": "1382860",
    "end": "1388919"
  },
  {
    "text": "2019 that you'll find that link and then other libraries to watch because you",
    "start": "1388919",
    "end": "1395220"
  },
  {
    "text": "know this is a whole ecosystem you'll find this in the in the list M leap serving focuses on optimized serving of",
    "start": "1395220",
    "end": "1405269"
  },
  {
    "text": "models this allows you to use a serialized definitions like PI and py",
    "start": "1405269",
    "end": "1412320"
  },
  {
    "text": "FML as well as several other standards Oh in an X that you can actually use for",
    "start": "1412320",
    "end": "1418080"
  },
  {
    "text": "for the deployment of your models deep detect is a unified API that abstracts",
    "start": "1418080",
    "end": "1423720"
  },
  {
    "text": "you know some of the most common libraries and these are different sort of levels of abstraction right like this",
    "start": "1423720",
    "end": "1430139"
  },
  {
    "text": "one's focused primarily on unified libraries so they don't really container eyes so it really depends on the use",
    "start": "1430139",
    "end": "1437820"
  },
  {
    "text": "case you know we try to focus on a more higher level generic use case and now we're gonna jump on the third part on",
    "start": "1437820",
    "end": "1444500"
  },
  {
    "text": "explain ability so this is basically tackling the issue of black box model",
    "start": "1444500",
    "end": "1450029"
  },
  {
    "text": "situations and the reason why this is important is because in highly related sectors if you are able to are",
    "start": "1450029",
    "end": "1457169"
  },
  {
    "text": "predicting someone's approval of a loan whether someone's loans should be",
    "start": "1457169",
    "end": "1463409"
  },
  {
    "text": "approved or rejected you know if if there's a regulation in place like you need to be able to explain",
    "start": "1463409",
    "end": "1470130"
  },
  {
    "text": "a prediction ended up being in a certain way you know for various reasons perhaps where there is discrimination of a",
    "start": "1470130",
    "end": "1476100"
  },
  {
    "text": "specific group whether it is a bias inherent or you know unconscious",
    "start": "1476100",
    "end": "1481410"
  },
  {
    "text": "conscious or unconscious you know whatever is that is the underlying reason explain ability is a very",
    "start": "1481410",
    "end": "1486960"
  },
  {
    "text": "important piece in to machine learning and you know explain ability needs to go beyond the algorithms you know it is",
    "start": "1486960",
    "end": "1493500"
  },
  {
    "text": "important to find the tools but it's also more important to identify the process and you know the process that",
    "start": "1493500",
    "end": "1499470"
  },
  {
    "text": "you know we currently follow it extends the traditional data science workflow by",
    "start": "1499470",
    "end": "1505440"
  },
  {
    "text": "introducing three steps so data analysis model evaluation and production monitoring and you know for the for the",
    "start": "1505440",
    "end": "1513210"
  },
  {
    "text": "data assessment the first part you know it's identifying things like class imbalances protected features things",
    "start": "1513210",
    "end": "1519270"
  },
  {
    "text": "like correlations data represent ability you know all those things are very important to I be able to identify but",
    "start": "1519270",
    "end": "1525690"
  },
  {
    "text": "also to match with the specific domain for the model assessment and we're gonna",
    "start": "1525690",
    "end": "1530940"
  },
  {
    "text": "dive into that is feature importance you know local versus global methods black",
    "start": "1530940",
    "end": "1538440"
  },
  {
    "text": "box versus white box model explanation methods model matrix analysis you know",
    "start": "1538440",
    "end": "1544830"
  },
  {
    "text": "in this case that is a feature importance permutation feature importance approach and then the last",
    "start": "1544830",
    "end": "1551880"
  },
  {
    "text": "one is production monitoring is the question of what are the metrics that you need to put in place in order for",
    "start": "1551880",
    "end": "1557310"
  },
  {
    "text": "your production environment to have a reasonable level of monitoring and",
    "start": "1557310",
    "end": "1563160"
  },
  {
    "text": "alerts even perhaps right if there's a mole divergence what does that even mean because of course accuracy it is context",
    "start": "1563160",
    "end": "1572730"
  },
  {
    "text": "specific right like you can't just arrive and you know ninety percent accuracy in one use case is different to",
    "start": "1572730",
    "end": "1577860"
  },
  {
    "text": "another and the reason why this is important is because when now going into production deployment of machine",
    "start": "1577860",
    "end": "1585060"
  },
  {
    "text": "learning you now encounter things like essays that you need to abide by right with microservices it's easy right",
    "start": "1585060",
    "end": "1591690"
  },
  {
    "text": "uptime you know you may have sometimes support etc etc but with machine learning systems there may be some",
    "start": "1591690",
    "end": "1598320"
  },
  {
    "text": "metrics that you know need to be defined in place for the for that to reflect what",
    "start": "1598320",
    "end": "1603810"
  },
  {
    "text": "value is being brought this could be things like accuracy this could be",
    "start": "1603810",
    "end": "1609210"
  },
  {
    "text": "things like precision recall etc etc a level of explain ability you know what",
    "start": "1609210",
    "end": "1616020"
  },
  {
    "text": "what would that even mean etc etc and what we're gonna be diving into is something a very interesting piece is",
    "start": "1616020",
    "end": "1622470"
  },
  {
    "text": "going on the only higher level part of this leveraging kubernetes and and more",
    "start": "1622470",
    "end": "1627960"
  },
  {
    "text": "specifically as I mentioned previously the CR DS within kubernetes you know leveraging this has allowed us to",
    "start": "1627960",
    "end": "1633720"
  },
  {
    "text": "provide a higher level of abstraction for design patterns in machine learning in this example specifically we have a",
    "start": "1633720",
    "end": "1641430"
  },
  {
    "text": "design pattern which we which I call the explainer pattern in this case you're able to deploy a machine learning model",
    "start": "1641430",
    "end": "1646980"
  },
  {
    "text": "which could be a black box model you know a containerized model as we just showed that this could be like a PI",
    "start": "1646980",
    "end": "1652590"
  },
  {
    "text": "touch more like like birds or vgg or whatever it is and then you would deploy a sort of like a respective expects",
    "start": "1652590",
    "end": "1663800"
  },
  {
    "text": "explainer right and this explainer would be able to explain why the model is",
    "start": "1663800",
    "end": "1669510"
  },
  {
    "text": "doing the predictions it's doing right so once you would have a model doing predictions you would have another model",
    "start": "1669510",
    "end": "1675810"
  },
  {
    "text": "explaining that models predictions and that sounds really meta right that",
    "start": "1675810",
    "end": "1681060"
  },
  {
    "text": "sounds like inception but but it actually is it's more practical than you think and we're going to be diving into",
    "start": "1681060",
    "end": "1687030"
  },
  {
    "text": "an example for this last part we're going to be using this library that we",
    "start": "1687030",
    "end": "1692580"
  },
  {
    "text": "open source code alibi so this is basically a model blackbox model",
    "start": "1692580",
    "end": "1699030"
  },
  {
    "text": "explanation library and we're going to be using specifically this concept of",
    "start": "1699030",
    "end": "1704400"
  },
  {
    "text": "anchor model explanations so this basically ask the question if the model made a prediction what what pieces of",
    "start": "1704400",
    "end": "1711750"
  },
  {
    "text": "that input what were the features that made that prediction that label in this",
    "start": "1711750",
    "end": "1718710"
  },
  {
    "text": "case you know is the question of what made this picture a cat and it identifies what are the pixels that are",
    "start": "1718710",
    "end": "1726110"
  },
  {
    "text": "how most predictive power for that specific prediction right so this this",
    "start": "1726110",
    "end": "1731190"
  },
  {
    "text": "allows for explanations of the model itself and we're going to be using that in our in our",
    "start": "1731190",
    "end": "1737040"
  },
  {
    "text": "right so in this example we're going to be basically first building a income",
    "start": "1737040",
    "end": "1743760"
  },
  {
    "text": "prediction classifier right so we're going to run first are all of our",
    "start": "1743760",
    "end": "1749030"
  },
  {
    "text": "components with helm then we're going to train a model using the income",
    "start": "1749030",
    "end": "1756210"
  },
  {
    "text": "classifier data set so this is a tabular data set to be able to predict whether somebody earns more or less than 50k we",
    "start": "1756210",
    "end": "1763980"
  },
  {
    "text": "will have then a model that is basically trained on that so we're using just basically a uh you know a label encoder",
    "start": "1763980",
    "end": "1773580"
  },
  {
    "text": "to be able to like process the data we're gonna create our preprocessor and then we're gonna create with a random",
    "start": "1773580",
    "end": "1780090"
  },
  {
    "text": "forest classifier the predictor right so we basically just have a model right we have a model we're gonna treat that as a",
    "start": "1780090",
    "end": "1786600"
  },
  {
    "text": "black box model it doesn't matter if it's a neural network or random forests we don't care right it's a black box",
    "start": "1786600",
    "end": "1792600"
  },
  {
    "text": "model when we run a friction so we can see that you know the performance is gonna predict either either you know a",
    "start": "1792600",
    "end": "1799020"
  },
  {
    "text": "binary was a positive or negative class and now we're gonna continue eyes and deploy the model so again we create a",
    "start": "1799020",
    "end": "1806310"
  },
  {
    "text": "wrapper so this wrapper basically just you know loads that pickup model that we",
    "start": "1806310",
    "end": "1812760"
  },
  {
    "text": "just created and whenever you call this function you know it takes whatever the input is runs it through the model and",
    "start": "1812760",
    "end": "1820170"
  },
  {
    "text": "then returns it so this is gonna be our API right so once you create the wrapper we basically define the dependencies",
    "start": "1820170",
    "end": "1827850"
  },
  {
    "text": "again and build a container by just pointing to that wrapper and now we have",
    "start": "1827850",
    "end": "1834000"
  },
  {
    "text": "a containerized model we deploy it to cover Nettie's with the same definition you know with with cube codes will apply",
    "start": "1834000",
    "end": "1840960"
  },
  {
    "text": "so we're just saying like that container we just built you know we want to rest API FOA and then once it's in production",
    "start": "1840960",
    "end": "1848370"
  },
  {
    "text": "we can actually just send curl requests so here we're sending the data for that",
    "start": "1848370",
    "end": "1853470"
  },
  {
    "text": "income classifier so these are the features and then you know we get the prediction here whether it's positive or",
    "start": "1853470",
    "end": "1859470"
  },
  {
    "text": "negative so here it was you know a negative prediction right so with what we now do is we actually take one of the",
    "start": "1859470",
    "end": "1866520"
  },
  {
    "text": "explainers the anchor explainers and we basically take that explainer and use",
    "start": "1866520",
    "end": "1872650"
  },
  {
    "text": "that function of the model so we basically give the model to be able to say well what of those what from that",
    "start": "1872650",
    "end": "1879400"
  },
  {
    "text": "model gave that prediction and in this case it says well it was marital status being separated sans sex female what",
    "start": "1879400",
    "end": "1886780"
  },
  {
    "text": "made that prediction being rejected right so that's what it basically does but the cool thing is that we can now",
    "start": "1886780",
    "end": "1892750"
  },
  {
    "text": "connect through you know that same you know we create a function that reaches",
    "start": "1892750",
    "end": "1898600"
  },
  {
    "text": "to that model we deployed right and we now can actually make that explainer",
    "start": "1898600",
    "end": "1904930"
  },
  {
    "text": "point to the production model right so we're we're basically now instead of explaining our local model we're",
    "start": "1904930",
    "end": "1911800"
  },
  {
    "text": "explaining that model in kubernetes right so we're basically just saying",
    "start": "1911800",
    "end": "1917470"
  },
  {
    "text": "well use this predict this remote function predict remote function which is just sending the request there and we",
    "start": "1917470",
    "end": "1923830"
  },
  {
    "text": "can actually explain that that that remote predictor so now that we can actually explain the remote predictor we",
    "start": "1923830",
    "end": "1929650"
  },
  {
    "text": "can deploy our explainer right and we follow the same steps we are going to containerize it by creating a wrapper",
    "start": "1929650",
    "end": "1935560"
  },
  {
    "text": "right so we just create a wrapper we containerize it with our script and then we push it to production so we",
    "start": "1935560",
    "end": "1941620"
  },
  {
    "text": "container I sit and we push it to production and now we basically have as",
    "start": "1941620",
    "end": "1946870"
  },
  {
    "text": "I explained a model to be able to run predictions and then a model to be able",
    "start": "1946870",
    "end": "1952780"
  },
  {
    "text": "to explain the predictions that it ran and we actually have a front-end that we",
    "start": "1952780",
    "end": "1959110"
  },
  {
    "text": "can use to actually show you how those predictions would look like so here we have a the income classifier we can see",
    "start": "1959110",
    "end": "1966970"
  },
  {
    "text": "all the all the logs so all of the predictions that have gone through that model and we can actually request well I",
    "start": "1966970",
    "end": "1974230"
  },
  {
    "text": "mean if internets on our side we can actually request the explanation for that specific prediction right so here",
    "start": "1974230",
    "end": "1981790"
  },
  {
    "text": "we can see why it predicted what it predicted so it's the same thing we saw what shiny right so right now it allows",
    "start": "1981790",
    "end": "1991360"
  },
  {
    "text": "you to just see what what we saw so now it's cool if I wasn't cool but you know now you can see what what what power it",
    "start": "1991360",
    "end": "1997090"
  },
  {
    "text": "has so just to wrap up you know because this is the last few slides they're all",
    "start": "1997090",
    "end": "2002690"
  },
  {
    "text": "very cool for air frameworks like le5 explained like I'm five shop which I would recommend check out and xai which",
    "start": "2002690",
    "end": "2009620"
  },
  {
    "text": "focuses more on that data so with that said you know we covered a high level",
    "start": "2009620",
    "end": "2014720"
  },
  {
    "text": "overview of the ecosystem there's still so much more to cover please go check out the ecosystem list this is one of",
    "start": "2014720",
    "end": "2020570"
  },
  {
    "text": "the most extensive lists of open source tools on production machine learning please contribute because we want to",
    "start": "2020570",
    "end": "2027230"
  },
  {
    "text": "have you know a more and better understanding we've just added this week",
    "start": "2027230",
    "end": "2032440"
  },
  {
    "text": "a new section on adversarial robustness which is really cool and we're gonna",
    "start": "2032440",
    "end": "2039380"
  },
  {
    "text": "actually add that to the production set of tool set so with that said thank you very much you know you can find the",
    "start": "2039380",
    "end": "2046550"
  },
  {
    "text": "slides online if you have any questions I'm gonna stick around so thank you very much for your time",
    "start": "2046550",
    "end": "2053169"
  },
  {
    "text": "[Applause]",
    "start": "2053170",
    "end": "2057689"
  }
]
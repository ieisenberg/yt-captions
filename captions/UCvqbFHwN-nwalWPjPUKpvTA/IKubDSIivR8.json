[
  {
    "start": "0",
    "end": "197000"
  },
  {
    "text": "hello everyone last official session of the day yeah",
    "start": "30",
    "end": "6150"
  },
  {
    "text": "all right make some noise let's be let's be awake good job thank you appreciate",
    "start": "6150",
    "end": "12570"
  },
  {
    "text": "that hi I'm Priyanka and I'm your track host I am director of evangelism at",
    "start": "12570",
    "end": "18150"
  },
  {
    "text": "gitlab and also member of the governing board of the cloud native computing",
    "start": "18150",
    "end": "23310"
  },
  {
    "text": "foundation or the CNC F the org that brings you coop con so well thank you so",
    "start": "23310",
    "end": "29849"
  },
  {
    "text": "much for coming and being troopers throughout the day I hope you've learned a lot of awesome stuff I definitely did",
    "start": "29849",
    "end": "36739"
  },
  {
    "text": "this track is the machine learning and data track which for me is super interesting because I'm from the",
    "start": "36739",
    "end": "43079"
  },
  {
    "text": "observability world and so this is new new stuff I get to learn so that's pretty cool",
    "start": "43079",
    "end": "48480"
  },
  {
    "text": "as with all sessions it's really important for us to learn what you thought of the null the knowledge that",
    "start": "48480",
    "end": "55800"
  },
  {
    "text": "you gained so please do go to scat calm after and rate the session I'm on the",
    "start": "55800",
    "end": "61559"
  },
  {
    "text": "program committee and I can't tell you how helpful it is because every year we get hundreds and thousands of",
    "start": "61559",
    "end": "66869"
  },
  {
    "text": "submissions at this point and having some direction from your ratings is really helpful so with that housekeeping",
    "start": "66869",
    "end": "74460"
  },
  {
    "text": "out of the way I'd like to introduce the last speakers of this in this room so",
    "start": "74460",
    "end": "80700"
  },
  {
    "text": "Derek from Google and Konstantin from lyft are going to talk about Richard oh",
    "start": "80700",
    "end": "90229"
  },
  {
    "text": "I don't know yeah the last speaker was Derek not that that helps in any way",
    "start": "91250",
    "end": "96710"
  },
  {
    "text": "Richard from Google and Konstantin from lyft are going to speak about how when",
    "start": "96710",
    "end": "102240"
  },
  {
    "text": "you have ml workloads they often require a lot of compute resources when that's",
    "start": "102240",
    "end": "107640"
  },
  {
    "text": "the case and you're using all kinds of abstraction layers there's kubernetes there's control planes this that it's",
    "start": "107640",
    "end": "113970"
  },
  {
    "text": "hard to know exactly where your resources are being allocated where the spend is going and that is very",
    "start": "113970",
    "end": "120390"
  },
  {
    "text": "important to the longevity of any project that you're working on so they're gonna talk about something they",
    "start": "120390",
    "end": "126810"
  },
  {
    "text": "built called infraspinatus set and dashboards to analyze where your spends",
    "start": "126810",
    "end": "132660"
  },
  {
    "text": "going and talk about how to think through these things for resources intensive ml workloads so with that",
    "start": "132660",
    "end": "139340"
  },
  {
    "text": "Richard and Konstantin please take it away thank you",
    "start": "139340",
    "end": "144390"
  },
  {
    "text": "cool so our topic is called measuring and optimizing kubernetes usage at lift",
    "start": "144390",
    "end": "151010"
  },
  {
    "text": "I'm Richard I work at Google and not a picture person so there's a picture of",
    "start": "153050",
    "end": "158489"
  },
  {
    "text": "my cat instead you can see that she's learning machine learning so so I am",
    "start": "158489",
    "end": "166019"
  },
  {
    "text": "Constantine I sort of put a few logos to make myself seem more legit so I",
    "start": "166019",
    "end": "172920"
  },
  {
    "text": "recently graduated from Northeastern kind of last year and before that I",
    "start": "172920",
    "end": "178079"
  },
  {
    "text": "interned at Instagram and stripe working on product and machine learning and then",
    "start": "178079",
    "end": "183600"
  },
  {
    "text": "at lyft I joined a team called capacity and basically the point of the capacity",
    "start": "183600",
    "end": "188880"
  },
  {
    "text": "team was that our infrastructure costs were increasing a lot and we needed to build visibility and tooling to control",
    "start": "188880",
    "end": "195209"
  },
  {
    "text": "that so I want to give you guys a brief overview but you're going to learn basically we're gonna try to cover a lot",
    "start": "195209",
    "end": "202950"
  },
  {
    "start": "197000",
    "end": "197000"
  },
  {
    "text": "of ground and I want you to understand sort of like our journey with cloud infrastructure spending at lift a little",
    "start": "202950",
    "end": "209430"
  },
  {
    "text": "bit about sort of the way that we use cube flow some of the machine learning workloads how those complicate our cloud",
    "start": "209430",
    "end": "215670"
  },
  {
    "text": "and for spending story and then finally how we built a product called infra spend and how we extended it to track",
    "start": "215670",
    "end": "222620"
  },
  {
    "text": "platforms like kubernetes and also other multi-tenant platforms and I kind of want you guys to keep in mind why this",
    "start": "222620",
    "end": "229620"
  },
  {
    "text": "is important what matters and then hopefully maybe if you don't have",
    "start": "229620",
    "end": "234900"
  },
  {
    "text": "something similar at your organization can inspire you to try to take on this journey cool so like I said around the",
    "start": "234900",
    "end": "244290"
  },
  {
    "start": "241000",
    "end": "241000"
  },
  {
    "text": "time that I joined our infrastructure bill was increasing quite a bit so at lift our philosophy with infra is",
    "start": "244290",
    "end": "250620"
  },
  {
    "text": "that we want to give teams autonomy to spend up whatever resources they need but this was a problem because it also",
    "start": "250620",
    "end": "256650"
  },
  {
    "text": "meant that we pretty much had no idea where like our spend was going until we",
    "start": "256650",
    "end": "262950"
  },
  {
    "start": "261000",
    "end": "261000"
  },
  {
    "text": "built a spreadsheet so my manager who I guess what by the time was not a manager",
    "start": "262950",
    "end": "268139"
  },
  {
    "text": "sort of this initiative at lift and he was just scraping AWS api's and uploading that data into Google sheets",
    "start": "268139",
    "end": "275419"
  },
  {
    "text": "and then around the times I joined we started working on something called inter spun 2.0 which is much more",
    "start": "275419",
    "end": "281700"
  },
  {
    "start": "276000",
    "end": "276000"
  },
  {
    "text": "sophisticated technologies to pull this thing called the cost and usage report from AWS and process it using sort of",
    "start": "281700",
    "end": "289770"
  },
  {
    "text": "like standard infrastructure like lifts data platform and create this like nice",
    "start": "289770",
    "end": "295740"
  },
  {
    "text": "data set that we can build on top of so don't want to dive into it too much right now but there are two features",
    "start": "295740",
    "end": "303690"
  },
  {
    "text": "that we should keep in mind one of them is that we wanted to derive something called a lift label which lets us track",
    "start": "303690",
    "end": "311419"
  },
  {
    "text": "spending and resources in a way that's like unique and identifiable across lift and searched from platforms and the",
    "start": "311419",
    "end": "318210"
  },
  {
    "text": "other important feature is that we introduced this notion of true cost and so basically unlike the old old sort of",
    "start": "318210",
    "end": "324330"
  },
  {
    "text": "like world and and even in the costing you should report an AWS you have different identical usage within the",
    "start": "324330",
    "end": "331950"
  },
  {
    "text": "same time frame that has different values so you can have two identical nodes that you're getting billed for and",
    "start": "331950",
    "end": "338789"
  },
  {
    "text": "you can be paying two dollars for one and one dollar for another even though they're being used at the same time so",
    "start": "338789",
    "end": "344970"
  },
  {
    "text": "this is kind of important later on as we talk about multi-tenant platform attribution and sort of like fairly billing different teams we'll go through",
    "start": "344970",
    "end": "353760"
  },
  {
    "text": "these real quick so this is kind of like one of the entry points to in for spend it lets you choose or for dashboards so",
    "start": "353760",
    "end": "360240"
  },
  {
    "text": "there's like the deep dive dashboard executive dashboard stuff like that and this is a view that",
    "start": "360240",
    "end": "367080"
  },
  {
    "text": "people tend to like a lot so you can see that the time series with like the stacked bar chart so that kind of shows",
    "start": "367080",
    "end": "374480"
  },
  {
    "text": "like each of those is like oh like a cluster or like a data store and then if",
    "start": "374480",
    "end": "379530"
  },
  {
    "text": "you can read up there this is just like the series that we see for the mapping organization have left over the course",
    "start": "379530",
    "end": "385680"
  },
  {
    "text": "of a week and so providing us kind of like rich data it really helps get",
    "start": "385680",
    "end": "390930"
  },
  {
    "text": "people to like look into it and like dig into it because it's so easy to digest",
    "start": "390930",
    "end": "396260"
  },
  {
    "text": "another interest one demo trends executive dashboards so I guess the the",
    "start": "396260",
    "end": "403640"
  },
  {
    "text": "complication here is that in the olden days when you had a single resource like",
    "start": "403640",
    "end": "409710"
  },
  {
    "text": "an auto scaling group or like a cluster you would have like one service running on it so you might have like the pricing",
    "start": "409710",
    "end": "415080"
  },
  {
    "text": "service which runs on the pricing cluster but obviously with multi hit on platforms that's no longer the case so",
    "start": "415080",
    "end": "421170"
  },
  {
    "text": "you're kind of you have like one kubernetes cluster and you're running hundreds of services and so being able",
    "start": "421170",
    "end": "426210"
  },
  {
    "text": "to see the cost of the kubernetes cluster is not that useful so for",
    "start": "426210",
    "end": "432660"
  },
  {
    "text": "example this is like the this is like the number of easy to see 518 X large",
    "start": "432660",
    "end": "440820"
  },
  {
    "text": "instances that we were running in our core kubernetes clusters at one point",
    "start": "440820",
    "end": "448460"
  },
  {
    "start": "448000",
    "end": "448000"
  },
  {
    "text": "and then this is further complicated by the fact that we've had dozens of different clusters that lift that we",
    "start": "448460",
    "end": "454440"
  },
  {
    "text": "needed to attribute so there's the core kubernetes cluster is in flight and",
    "start": "454440",
    "end": "461300"
  },
  {
    "text": "machine learning clusters so Richard is going to speak a bit about cube flow and",
    "start": "461300",
    "end": "468480"
  },
  {
    "text": "some of the features that we've used okay thank you so as a constantine",
    "start": "468480",
    "end": "476130"
  },
  {
    "text": "mentioned at left we I mean they so they",
    "start": "476130",
    "end": "481740"
  },
  {
    "text": "have this platform called lips learned for a machine learning platform and it",
    "start": "481740",
    "end": "486930"
  },
  {
    "text": "uses components from coop flow so that's that's what I work on at",
    "start": "486930",
    "end": "492310"
  },
  {
    "text": "Google so one of the problems that consoles invention is like criminalities",
    "start": "492310",
    "end": "497620"
  },
  {
    "text": "reduces visibility into your usage right and this is like is a sir baited by the",
    "start": "497620",
    "end": "503020"
  },
  {
    "text": "fact that machine learning workloads are quite complex so we're going to take a tour of Google and we're going to look",
    "start": "503020",
    "end": "509140"
  },
  {
    "text": "at how different machine learning were closed that's going to affect spending and usage okay so no book instances",
    "start": "509140",
    "end": "518469"
  },
  {
    "start": "516000",
    "end": "516000"
  },
  {
    "text": "right so this is pretty straightforward so you as a user you can build all your",
    "start": "518470",
    "end": "525850"
  },
  {
    "text": "notebook dependencies like your your Python libraries your tensor flow",
    "start": "525850",
    "end": "530920"
  },
  {
    "text": "libraries and into this one container you start a container instance and you",
    "start": "530920",
    "end": "536800"
  },
  {
    "text": "can open up the web portal and you use your you can type your your training code here and write everything in",
    "start": "536800",
    "end": "542920"
  },
  {
    "text": "notebook all right so what's the use this pattern like you're most likely",
    "start": "542920",
    "end": "548020"
  },
  {
    "text": "using it as individual users all right so anybody any data scientists or any",
    "start": "548020",
    "end": "553210"
  },
  {
    "text": "machine learning engineering can just spin up a notebook okay and you won't happy to be a",
    "start": "553210",
    "end": "558850"
  },
  {
    "text": "high-availability right if you want to start a notebook session you wanted to start out right",
    "start": "558850",
    "end": "564160"
  },
  {
    "text": "away you don't want to wait 30 minutes or so for it to start up so most likely",
    "start": "564160",
    "end": "569440"
  },
  {
    "text": "you have multiple users using multiple notebook instances and the users pattern",
    "start": "569440",
    "end": "577540"
  },
  {
    "text": "kind of grows like a linear fashion and but you could have problems like",
    "start": "577540",
    "end": "582820"
  },
  {
    "text": "potentially I don't notebooks right someone starts a notebook session used it for cover hours and just I forget",
    "start": "582820",
    "end": "588910"
  },
  {
    "text": "about it and you know you have these idle resources sitting around right so",
    "start": "588910",
    "end": "595840"
  },
  {
    "text": "that's for notebook instances another possibility is like k of serving",
    "start": "595840",
    "end": "603610"
  },
  {
    "text": "which is there were there was a talk earlier on this but basically this is the scalable kubernetes native enforcing",
    "start": "603610",
    "end": "610510"
  },
  {
    "text": "service for this you want the usage to",
    "start": "610510",
    "end": "615970"
  },
  {
    "text": "be most likely it's also high availability but you also want the",
    "start": "615970",
    "end": "621730"
  },
  {
    "text": "ability to quickly at capacity right let's say you're you're calling for for the enforcing",
    "start": "621730",
    "end": "629519"
  },
  {
    "text": "calls right you have a certain spike this requires you to quickly adjust to",
    "start": "629519",
    "end": "634649"
  },
  {
    "text": "the additional level of demand right and potentially you need a lot more GPUs so",
    "start": "634649",
    "end": "642899"
  },
  {
    "text": "you can see that this is quite different from the notebook instance where it grows fairly linearly and for notebooks",
    "start": "642899",
    "end": "651649"
  },
  {
    "text": "your usage is most likely a tribute to individual users but in this case is",
    "start": "651649",
    "end": "657570"
  },
  {
    "text": "more likely to be attributed to a service or a team okay we also have a",
    "start": "657570",
    "end": "666450"
  },
  {
    "start": "666000",
    "end": "666000"
  },
  {
    "text": "code for pipelines so this is a component component that allows you to",
    "start": "666450",
    "end": "671519"
  },
  {
    "text": "build into in machine learning workflows so we can see an example on the right",
    "start": "671519",
    "end": "676769"
  },
  {
    "text": "hand side the writing is little small but you can see it's just like creating a class or there's a transform training",
    "start": "676769",
    "end": "683490"
  },
  {
    "text": "predict so it takes these machine learning steps and build the",
    "start": "683490",
    "end": "689430"
  },
  {
    "text": "dependencies into this dependency graph and you can run these workflows regularly on a schedule right so what's",
    "start": "689430",
    "end": "698190"
  },
  {
    "text": "that like in the real production environment well you could have suppose you have some resource constraints on on",
    "start": "698190",
    "end": "706170"
  },
  {
    "text": "some of these steps and you have a multiple of these pipelines running in parallel or running in together right so",
    "start": "706170",
    "end": "714060"
  },
  {
    "text": "you could have these bottlenecks because some steps like the training sets may be",
    "start": "714060",
    "end": "719970"
  },
  {
    "text": "very resource intensive and so you could have several of these pipelines competing for the same resources and",
    "start": "719970",
    "end": "728720"
  },
  {
    "text": "this is my favorite hyper parameter optimization because this is a component",
    "start": "728720",
    "end": "734190"
  },
  {
    "start": "730000",
    "end": "730000"
  },
  {
    "text": "that I work on the most so a little bit about hyper parameter optimization right",
    "start": "734190",
    "end": "740850"
  },
  {
    "text": "so hyper parameters are parameters that are external to the model unlike the",
    "start": "740850",
    "end": "746699"
  },
  {
    "text": "model parameters which is in a training process you learn the values of the model parameters right for hybrid",
    "start": "746699",
    "end": "754079"
  },
  {
    "text": "parameter you set the values of these before you started training process so",
    "start": "754079",
    "end": "759090"
  },
  {
    "text": "examples are like the learning rate number of layers a batch size kernel",
    "start": "759090",
    "end": "764250"
  },
  {
    "text": "type and so on so the process of hyper parameter optimization is finding the",
    "start": "764250",
    "end": "770670"
  },
  {
    "text": "best values such that the amount of performance is maximized so in qu flow",
    "start": "770670",
    "end": "779220"
  },
  {
    "start": "777000",
    "end": "777000"
  },
  {
    "text": "there is a component called ketchup that's basically the open source implementation of hyper around or tuning",
    "start": "779220",
    "end": "785670"
  },
  {
    "text": "on Chrome or Nettie's and what it does is you just initialize your search space",
    "start": "785670",
    "end": "791430"
  },
  {
    "text": "and your model and there are two main constraints for a tuning experiment",
    "start": "791430",
    "end": "798900"
  },
  {
    "text": "there is a objective value which is let's say you're trying to optimize your",
    "start": "798900",
    "end": "804920"
  },
  {
    "text": "prediction accuracy right so you can set a goal like I want my prediction accuracy be 90 percent or something",
    "start": "804920",
    "end": "813620"
  },
  {
    "text": "there is also a budget so this is like how many trials I want to run right so",
    "start": "813710",
    "end": "819780"
  },
  {
    "text": "these are the constraints for my experiment and each initial iteration only does a guess the next set of",
    "start": "819780",
    "end": "827670"
  },
  {
    "text": "parameter suggestions from saturation service through this call called guess suggestions and that gives you the",
    "start": "827670",
    "end": "835170"
  },
  {
    "text": "next set of your hyper parameters use and then this gets plugged into a trial",
    "start": "835170",
    "end": "841890"
  },
  {
    "text": "I try our just a running instance of the of your water raters are trying to",
    "start": "841890",
    "end": "846900"
  },
  {
    "text": "optimize your experiment so it runs that while using the parameter values and it",
    "start": "846900",
    "end": "852210"
  },
  {
    "text": "produces some metrics values and these metrics could report it back to the reporting service and it continues right",
    "start": "852210",
    "end": "862519"
  },
  {
    "text": "so how does this affect our our spanning story well so a tuning job is can be",
    "start": "863270",
    "end": "872160"
  },
  {
    "text": "very CPU intensive right because you could have potentially many of these",
    "start": "872160",
    "end": "880070"
  },
  {
    "text": "actually explained each trial is actually a training job right because you're launching a job and you're",
    "start": "880070",
    "end": "885600"
  },
  {
    "text": "training for like some number of epochs and it produces some set of metrics and",
    "start": "885600",
    "end": "891030"
  },
  {
    "text": "give me this metrics we determine if this is a a good set of hyper parameters",
    "start": "891030",
    "end": "896400"
  },
  {
    "text": "or not right so if you're using really bad values okay we can weekend terminate",
    "start": "896400",
    "end": "901920"
  },
  {
    "text": "the experiment early but sometimes if you're either trying to optimize for",
    "start": "901920",
    "end": "907350"
  },
  {
    "text": "like the additional 1% or 2% if you're using like for example busy and",
    "start": "907350",
    "end": "913470"
  },
  {
    "text": "optimization right that means we're going to explore a certain range of values more",
    "start": "913470",
    "end": "919730"
  },
  {
    "text": "so we basically running iterative training training trials on the same",
    "start": "919730",
    "end": "926670"
  },
  {
    "text": "range of set of parameters so that could be very resource-intensive",
    "start": "926670",
    "end": "932550"
  },
  {
    "text": "right and that can have a lot of a high capacity demand and depending on how",
    "start": "932550",
    "end": "938070"
  },
  {
    "text": "much resource that you have available you can also configure how many trials you want to run in parallel right so",
    "start": "938070",
    "end": "947040"
  },
  {
    "text": "what does it all mean so we've seen a few examples like we didn't see distributive training high preparator",
    "start": "947040",
    "end": "952050"
  },
  {
    "text": "tuning serving and your notebook instances right so all these have very",
    "start": "952050",
    "end": "961110"
  },
  {
    "text": "different usage patterns right some of them are very high volume high demand",
    "start": "961110",
    "end": "967820"
  },
  {
    "text": "someone require very high availability and some are very resource intensive right so and this is a further",
    "start": "967820",
    "end": "977010"
  },
  {
    "text": "complicated by the fact that your concert could be multi-tenant you could have several different teams and each",
    "start": "977010",
    "end": "983640"
  },
  {
    "text": "team could be doing different things some might be more doing more training some might be more experimenting with",
    "start": "983640",
    "end": "989550"
  },
  {
    "text": "notebooks right so because we are nation earlier the kubernetes high as a way",
    "start": "989550",
    "end": "996000"
  },
  {
    "text": "that are these details so if everything is just aggregated at cluster level it is very difficult to attribute what your",
    "start": "996000",
    "end": "1003770"
  },
  {
    "text": "your actual spending is right so multi-tenancy is some a problem that",
    "start": "1003770",
    "end": "1009650"
  },
  {
    "text": "could flow itself is trying to address and in our upcoming 1.0 release we want",
    "start": "1009650",
    "end": "1015440"
  },
  {
    "text": "you to have a complete story for what desi but we are more working tourists",
    "start": "1015440",
    "end": "1022210"
  },
  {
    "text": "like the user isolation right to being able to create a a profile where each",
    "start": "1022210",
    "end": "1027370"
  },
  {
    "text": "user can have a isolate a set of resources to use so another part of the",
    "start": "1027370",
    "end": "1034060"
  },
  {
    "text": "story is how do we attribute usage in the multi-tenancy world so and that's",
    "start": "1034060",
    "end": "1040420"
  },
  {
    "text": "what constant thing is going to do tell us about cool thanks so in the first part of the",
    "start": "1040420",
    "end": "1048069"
  },
  {
    "text": "presentation I talked about in for spend without Moses hidden platform attribution where you kind of see",
    "start": "1048070",
    "end": "1053110"
  },
  {
    "text": "resources in aggregate and so now I'm going to talk about some of the",
    "start": "1053110",
    "end": "1058540"
  },
  {
    "text": "infrastructure that we built to allow subdivision of those shared resources",
    "start": "1058540",
    "end": "1064000"
  },
  {
    "text": "such as our ml platform and our cocktail workloads and the way that we thought about it at lift so essentially we",
    "start": "1064000",
    "end": "1073000"
  },
  {
    "text": "wanted to build a system that is modular and extensible so we wanted to start",
    "start": "1073000",
    "end": "1078220"
  },
  {
    "text": "with kubernetes but we wanted the concepts that we use for multi-tenancy to extend to other platforms like ETL",
    "start": "1078220",
    "end": "1085000"
  },
  {
    "text": "experimentation and so on and so forth and finally or and we wanted to make this a platform for platforms so we",
    "start": "1085000",
    "end": "1093030"
  },
  {
    "text": "basically wanted to provide a clear way that platform owners can provide their",
    "start": "1093030",
    "end": "1098440"
  },
  {
    "text": "attribution data to us and subdivide their resources because partially our",
    "start": "1098440",
    "end": "1104680"
  },
  {
    "text": "philosophy is that platform owners understand how they should attribute their resources best so there are",
    "start": "1104680",
    "end": "1111340"
  },
  {
    "start": "1109000",
    "end": "1109000"
  },
  {
    "text": "basically two important concepts to talk about the first is like the definitional",
    "start": "1111340",
    "end": "1116920"
  },
  {
    "text": "platform and so the way we think of it is a platform ties together a bunch of",
    "start": "1116920",
    "end": "1124030"
  },
  {
    "text": "resources so in the AWS world you might have databases and s3 buckets and ec2",
    "start": "1124030",
    "end": "1134230"
  },
  {
    "text": "clusters as different resources and we want to unify those under a single",
    "start": "1134230",
    "end": "1139690"
  },
  {
    "text": "platform tag and then provide an attribution schedule which tells us how",
    "start": "1139690",
    "end": "1144820"
  },
  {
    "text": "we should break down the cost of each of those resources to different attribution",
    "start": "1144820",
    "end": "1151030"
  },
  {
    "text": "label and so that ties into the label concept that I brought up in our investment 2.0",
    "start": "1151030",
    "end": "1157660"
  },
  {
    "text": "data set so quick a slide on the properties of an attribution schedule",
    "start": "1157660",
    "end": "1163950"
  },
  {
    "start": "1159000",
    "end": "1159000"
  },
  {
    "text": "basically for a certain attribution schedule all the platforms that we specify it should be in there have to be",
    "start": "1163950",
    "end": "1170080"
  },
  {
    "text": "defined and then within each of those platforms there must be data for every single hour",
    "start": "1170080",
    "end": "1176400"
  },
  {
    "text": "and then the usage has to add up to exactly one so this is essentially it's",
    "start": "1176400",
    "end": "1181690"
  },
  {
    "text": "a hive table that breaks down the hourly cost of a certain platform according to",
    "start": "1181690",
    "end": "1187390"
  },
  {
    "text": "different attribution labels as a percent and in terms of how a tribution",
    "start": "1187390",
    "end": "1194080"
  },
  {
    "start": "1190000",
    "end": "1190000"
  },
  {
    "text": "schedules can be generated we essentially support three different methods for attribution schedule",
    "start": "1194080",
    "end": "1200380"
  },
  {
    "text": "generation the first that I'm going to talk more in depth about in this presentation is like a custom pipeline",
    "start": "1200380",
    "end": "1207370"
  },
  {
    "text": "that we built using Prometheus to pull kubernetes metrics and currently we",
    "start": "1207370",
    "end": "1213580"
  },
  {
    "text": "support CPU and memory in that and so kubernetes cluster owners can choose whether to have their platforms",
    "start": "1213580",
    "end": "1220840"
  },
  {
    "text": "attributed based on CPU or memory if that doesn't work for platform owners",
    "start": "1220840",
    "end": "1226120"
  },
  {
    "text": "there are sort of two other options that I'm just going to touch on right here but not necessarily go into like the",
    "start": "1226120",
    "end": "1231640"
  },
  {
    "text": "details of so basically either platform owners can stream their usage to us",
    "start": "1231640",
    "end": "1237010"
  },
  {
    "text": "they're like lift standard analytics infrastructure or they can support their",
    "start": "1237010",
    "end": "1242650"
  },
  {
    "text": "own attribution schedule that has the properties that I brought up earlier and we can consume that as well so they sort",
    "start": "1242650",
    "end": "1250750"
  },
  {
    "text": "of go from least involvement for the platform writer and to most involvement the platform owner may be a quick aside",
    "start": "1250750",
    "end": "1260140"
  },
  {
    "start": "1257000",
    "end": "1257000"
  },
  {
    "text": "set in terms of how this works on the back end is we keep a bunch of different",
    "start": "1260140",
    "end": "1267430"
  },
  {
    "text": "contribution schedules someone that might be reported by platforms summer",
    "start": "1267430",
    "end": "1272740"
  },
  {
    "text": "the kubernetes pipelines on top and we unify those into a single step that we",
    "start": "1272740",
    "end": "1278200"
  },
  {
    "text": "staged to join into our and respond data so",
    "start": "1278200",
    "end": "1284190"
  },
  {
    "text": "I guess without further ado I'll talk a little bit about how we provide a namespace level attribution to our",
    "start": "1284190",
    "end": "1290100"
  },
  {
    "text": "kubernetes workloads first so here's a practical example of how this works up",
    "start": "1290100",
    "end": "1298050"
  },
  {
    "text": "top you see the cost of different resources in our raw enforcement data so",
    "start": "1298050",
    "end": "1304740"
  },
  {
    "text": "you have for example at 1:00 p.m. cluster 0 cost $1 and on the attribution",
    "start": "1304740",
    "end": "1310620"
  },
  {
    "text": "schedule down below on the left side you can see that the usage of the cluster 0",
    "start": "1310620",
    "end": "1318120"
  },
  {
    "text": "platform should be subdivided like 50% of it should go to the free namespace",
    "start": "1318120",
    "end": "1323660"
  },
  {
    "text": "30% goes to our first service and 20% goes to our second service and then",
    "start": "1323660",
    "end": "1330360"
  },
  {
    "text": "after the join step you can see that usage is subdivided in the enriched enforcement data another thing that we",
    "start": "1330360",
    "end": "1340530"
  },
  {
    "start": "1337000",
    "end": "1337000"
  },
  {
    "text": "had a lot of discussion around and are actively working to build more support on our different cost models for",
    "start": "1340530",
    "end": "1348230"
  },
  {
    "text": "platforms so in the case of kubernetes we have like entertained a bunch of",
    "start": "1348230",
    "end": "1353790"
  },
  {
    "text": "options so we started a half by building the CPU allocation cost model and I",
    "start": "1353790",
    "end": "1361290"
  },
  {
    "text": "guess some of the other ones are fairly intuitive in terms of what they might look like under the hood but essentially",
    "start": "1361290",
    "end": "1368040"
  },
  {
    "text": "what this means is like we look at the total number of CPU cores that are available on a cluster within a certain",
    "start": "1368040",
    "end": "1373950"
  },
  {
    "text": "instance type in aggregate and then we divide the number of cores requested by",
    "start": "1373950",
    "end": "1380220"
  },
  {
    "text": "any given namespace by the total number of cores and the cluster within that instance type another aside here is that",
    "start": "1380220",
    "end": "1391730"
  },
  {
    "start": "1388000",
    "end": "1388000"
  },
  {
    "text": "we think of enforcement as being about allocation rather than utilization or",
    "start": "1391730",
    "end": "1398370"
  },
  {
    "text": "efficiency so I guess like in the non",
    "start": "1398370",
    "end": "1403920"
  },
  {
    "text": "kubernetes world this means that like if your team spends up a node even if they don't use it at all it goes to your team",
    "start": "1403920",
    "end": "1410910"
  },
  {
    "text": "and similarly with kubernetes if you request some resources even if you're",
    "start": "1410910",
    "end": "1416460"
  },
  {
    "text": "not using them effect they should be attributed to your team however we are actively working on like",
    "start": "1416460",
    "end": "1424350"
  },
  {
    "text": "developing different features and when different products or potentially even integrating the two to support more",
    "start": "1424350",
    "end": "1430590"
  },
  {
    "text": "visibility into the efficiency of different allocations I guess one other bit is although we",
    "start": "1430590",
    "end": "1441149"
  },
  {
    "start": "1434000",
    "end": "1434000"
  },
  {
    "text": "don't really think of enforcement as being about efficiency we kind of have a",
    "start": "1441149",
    "end": "1447600"
  },
  {
    "text": "feature that allows us to monitor the efficiency of our kubernetes platforms which is our unallocated capacity so",
    "start": "1447600",
    "end": "1454289"
  },
  {
    "text": "according to our cost model with like the CPU allocation things that I",
    "start": "1454289",
    "end": "1459929"
  },
  {
    "text": "discussed we have a balance which is the",
    "start": "1459929",
    "end": "1466789"
  },
  {
    "text": "the leftover cores after you have accounted for the namespaces that have requested CPU cores in the cluster and",
    "start": "1466789",
    "end": "1472350"
  },
  {
    "text": "so we surface our unallocated CPU",
    "start": "1472350",
    "end": "1477720"
  },
  {
    "text": "capacity in our data in terms of how we",
    "start": "1477720",
    "end": "1483090"
  },
  {
    "start": "1480000",
    "end": "1480000"
  },
  {
    "text": "collected our kubernetes metrics we spun up a very lightweight micro service",
    "start": "1483090",
    "end": "1488809"
  },
  {
    "text": "which scrapes metrics for each of our crew bodies clusters so two bodies",
    "start": "1488809",
    "end": "1494249"
  },
  {
    "text": "cluster owners can register their cluster which essentially means that our",
    "start": "1494249",
    "end": "1500039"
  },
  {
    "text": "service will scrape that clusters Prometheus and at issue is a couple of different requests so one is that we we",
    "start": "1500039",
    "end": "1509700"
  },
  {
    "text": "take cube state metrics from Prometheus for CPU core requests for running pods",
    "start": "1509700",
    "end": "1518539"
  },
  {
    "text": "as well as the CPU capacity memory capacity and more recently pod labels so",
    "start": "1518539",
    "end": "1526409"
  },
  {
    "text": "of going to a little bit of detail about how we use pod labels but essentially it's to do custom tag attribution on",
    "start": "1526409",
    "end": "1534869"
  },
  {
    "text": "things other than namespaces for annotations that users might add to their pods so downstream our service",
    "start": "1534869",
    "end": "1545100"
  },
  {
    "start": "1541000",
    "end": "1541000"
  },
  {
    "text": "omits our kubernetes usage data so like the requests and capacity and so",
    "start": "1545100",
    "end": "1550409"
  },
  {
    "text": "on and to our hive infrastructure and there are two steps essentially and I kind of",
    "start": "1550409",
    "end": "1560480"
  },
  {
    "text": "illustrate the purposes put screenshots of what that code looks like but compressed it so you can't read it",
    "start": "1560480",
    "end": "1567480"
  },
  {
    "text": "hopefully that's kind of entertaining so",
    "start": "1567480",
    "end": "1572730"
  },
  {
    "text": "on the left side we take the we essentially do this computation that I",
    "start": "1572730",
    "end": "1578850"
  },
  {
    "text": "discussed where we group all our requests by namespace and then we divide those by the total cluster capacity and",
    "start": "1578850",
    "end": "1586470"
  },
  {
    "text": "by instance type as well so did that in kind of hide QL I definitely would not",
    "start": "1586470",
    "end": "1593549"
  },
  {
    "text": "recommend that and then the the step afterwards is we run interpolation so",
    "start": "1593549",
    "end": "1600919"
  },
  {
    "text": "because we have a bunch of different instance types and a bunch of different kubernetes clusters we want to make sure",
    "start": "1600919",
    "end": "1608789"
  },
  {
    "text": "that even if one of our dependencies like cubes 8 metrics or Prometheus's off line that doesn't serve get serviced in",
    "start": "1608789",
    "end": "1616559"
  },
  {
    "text": "our data so the guy just want to be notified of it but not necessarily have it break or create gaps in our data and",
    "start": "1616559",
    "end": "1622740"
  },
  {
    "text": "so we run interpolation where if we're missing data for a certain hour then we'll fill it in with the previous hour",
    "start": "1622740",
    "end": "1630559"
  },
  {
    "start": "1631000",
    "end": "1631000"
  },
  {
    "text": "so it's sort of sort of the point I just brought up because there are lots of",
    "start": "1631730",
    "end": "1637409"
  },
  {
    "text": "different kubernetes clusters and within those clusters there's lots of different dimensions that we want to support the",
    "start": "1637409",
    "end": "1644340"
  },
  {
    "text": "operational load has actually been or at the beginning of the project was actually a fairly high and so some of",
    "start": "1644340",
    "end": "1652110"
  },
  {
    "text": "the more challenging things were just getting the right visibility in our service to scrape those metrics so that",
    "start": "1652110",
    "end": "1659580"
  },
  {
    "text": "we're notified essentially as soon as possible if one of the dependencies like cube state metrics or Prometheus is",
    "start": "1659580",
    "end": "1665100"
  },
  {
    "text": "offline and also to notify the teams that actually own those clusters that",
    "start": "1665100",
    "end": "1672090"
  },
  {
    "text": "they should make sure that their systems are functioning properly and then the",
    "start": "1672090",
    "end": "1677460"
  },
  {
    "text": "other is actually that similarly with like roll-ups and different dimensions",
    "start": "1677460",
    "end": "1682770"
  },
  {
    "text": "being present on the data like the distinction between Odin's instance type in our denote an instance and like",
    "start": "1682770",
    "end": "1689580"
  },
  {
    "text": "keeps a metrics basically it was really important to test assumptions about our data at every single step so kind of",
    "start": "1689580",
    "end": "1696690"
  },
  {
    "text": "seems like a fairly simple pipeline but in reality there's probably like seven or eight sequential components and we've",
    "start": "1696690",
    "end": "1704910"
  },
  {
    "text": "kind of experienced like different unexpected behaviors at most of them so it's really important to do sanity",
    "start": "1704910",
    "end": "1710070"
  },
  {
    "text": "checks at every step cool so that's a little bit of details",
    "start": "1710070",
    "end": "1715200"
  },
  {
    "text": "on how we implemented this under the hood I guess up next I wanted to just go",
    "start": "1715200",
    "end": "1722160"
  },
  {
    "text": "through a few screenshots and might talk through what the product experience was",
    "start": "1722160",
    "end": "1727860"
  },
  {
    "text": "with then respond 2.0 with kubernetes so this is another screenshot from our",
    "start": "1727860",
    "end": "1734760"
  },
  {
    "start": "1730000",
    "end": "1730000"
  },
  {
    "text": "product so one of the things you can see on the left side and like the green is",
    "start": "1734760",
    "end": "1740820"
  },
  {
    "text": "our either daily or hourly usage on just",
    "start": "1740820",
    "end": "1746940"
  },
  {
    "text": "like bear instances and on the right side you can see our hourly usage on",
    "start": "1746940",
    "end": "1753660"
  },
  {
    "text": "kubernetes so the thing that I want to highlight is that like almost",
    "start": "1753660",
    "end": "1759320"
  },
  {
    "text": "categorically all of our kubernetes deployments were over provisioned when we first went on the platform but over",
    "start": "1759320",
    "end": "1767820"
  },
  {
    "text": "time partially because we've had this data and it's like in in like everyone's face we've been able to like tune the",
    "start": "1767820",
    "end": "1775830"
  },
  {
    "text": "sizes of different workloads and for almost all of them make them or for all",
    "start": "1775830",
    "end": "1782070"
  },
  {
    "text": "of them really make them more efficient on kubernetes what cost perspective so",
    "start": "1782070",
    "end": "1787770"
  },
  {
    "start": "1786000",
    "end": "1786000"
  },
  {
    "text": "this is another sort of a couple screenshots from a presentation about how kubera saves money and same story",
    "start": "1787770",
    "end": "1796020"
  },
  {
    "text": "like on the left side you have the like the raw ecqs usage and then on the right",
    "start": "1796020",
    "end": "1802080"
  },
  {
    "text": "side you have the kubernetes usage after it's been tuned so",
    "start": "1802080",
    "end": "1809750"
  },
  {
    "text": "so the big impact there was that it lets",
    "start": "1811820",
    "end": "1817380"
  },
  {
    "text": "us track our raw infra and Kubrat his usage side by side and also kind of to",
    "start": "1817380",
    "end": "1825240"
  },
  {
    "text": "that point it lets in for teens throughout the company see all of their",
    "start": "1825240",
    "end": "1830580"
  },
  {
    "text": "cloud products in one place the other thing that I brought up is this like",
    "start": "1830580",
    "end": "1837060"
  },
  {
    "start": "1833000",
    "end": "1833000"
  },
  {
    "text": "unallocated cluster capacity that we tracked and so you can see that as we started migrating to kubernetes our",
    "start": "1837060",
    "end": "1844430"
  },
  {
    "text": "unallocated space on our clusters was continuously increasing and so it became",
    "start": "1844430",
    "end": "1850230"
  },
  {
    "text": "kind of a significant cost that infor spend was able to surface and because we",
    "start": "1850230",
    "end": "1855510"
  },
  {
    "text": "had this it got a lot of people to look into it and try different things around",
    "start": "1855510",
    "end": "1862430"
  },
  {
    "text": "tuning autoscaler policies and also",
    "start": "1862430",
    "end": "1867500"
  },
  {
    "text": "deploying new services so raise",
    "start": "1867500",
    "end": "1873630"
  },
  {
    "text": "awareness of inefficiencies from an allocation standpoint and so there there",
    "start": "1873630",
    "end": "1880410"
  },
  {
    "text": "have been a few things that we've done to make our crew buddies deployments more efficient I think the biggest",
    "start": "1880410",
    "end": "1886530"
  },
  {
    "text": "impact was tuning cluster scaling policies so like removing nodes when",
    "start": "1886530",
    "end": "1892920"
  },
  {
    "text": "they're CP utilization is higher than previously and also for tuning plots",
    "start": "1892920",
    "end": "1900570"
  },
  {
    "text": "getting policies so ok so quick aside",
    "start": "1900570",
    "end": "1906930"
  },
  {
    "text": "yeah so a lot of the stuff going forward is kind of like additional features that",
    "start": "1906930",
    "end": "1913440"
  },
  {
    "text": "we've been adding to our Kubrat ease for enforcement infrastructure so we're",
    "start": "1913440",
    "end": "1919230"
  },
  {
    "text": "working on supporting more allocation schedules and adding different dimensions so we've had a few teams",
    "start": "1919230",
    "end": "1925860"
  },
  {
    "text": "experiment with like looking at their attribution data based on a container or based on custom pod labels that they",
    "start": "1925860",
    "end": "1932580"
  },
  {
    "text": "emit through our usage tracking service and also working with teams to build",
    "start": "1932580",
    "end": "1939180"
  },
  {
    "text": "custom views into the data so as an example one of these custom views that says an enforcement dashboard that",
    "start": "1939180",
    "end": "1945510"
  },
  {
    "text": "our machine learning platform team built and it basically just breaks down the",
    "start": "1945510",
    "end": "1951120"
  },
  {
    "text": "costs of just their crew brownies clusters and lets them look at like namespace level attribution and have",
    "start": "1951120",
    "end": "1956700"
  },
  {
    "text": "different sort of like visualizations and charts and trends and then with",
    "start": "1956700",
    "end": "1962370"
  },
  {
    "text": "regard to different dimensions this is another chart that we have that further",
    "start": "1962370",
    "end": "1968520"
  },
  {
    "text": "subdivides the namespace level attribution to containers and then filters out just the containers that",
    "start": "1968520",
    "end": "1974730"
  },
  {
    "text": "correspond to spork jobs and so this has been kind of useful as well because now",
    "start": "1974730",
    "end": "1981330"
  },
  {
    "text": "you can see who's using sparks specifically on live learning",
    "start": "1981330",
    "end": "1986909"
  },
  {
    "text": "do the same data set and that sort of goes with the point about being able to",
    "start": "1986909",
    "end": "1992580"
  },
  {
    "text": "build custom dashboards on top of the data set that we built so I guess almost",
    "start": "1992580",
    "end": "2000559"
  },
  {
    "start": "1996000",
    "end": "1996000"
  },
  {
    "text": "everything that we use is open source and it should generalize to like different vendors I think we have some",
    "start": "2000559",
    "end": "2009110"
  },
  {
    "text": "stuff and it's like essentially to integrate things like wavefront and so",
    "start": "2009110",
    "end": "2016820"
  },
  {
    "text": "on but the technologies that we use are essentially Prometheus and kubernetes and CubeSat metrics and just that data",
    "start": "2016820",
    "end": "2024080"
  },
  {
    "text": "into hive we make it usable through druid so Joe it allows us to like query",
    "start": "2024080",
    "end": "2030500"
  },
  {
    "text": "the data much more quickly and we display it through another lift open source project called super Sun which is",
    "start": "2030500",
    "end": "2036710"
  },
  {
    "text": "essentially how we built all the dashboards that I shouldn't screenshots of throughout the presentation cool so",
    "start": "2036710",
    "end": "2044809"
  },
  {
    "text": "yeah I mean going forward we want to on board more platforms to enforce pend",
    "start": "2044809",
    "end": "2053320"
  },
  {
    "text": "provide finer granularity talk about efficiency more somebody that cool",
    "start": "2053320",
    "end": "2063000"
  },
  {
    "text": "Thanks all right questions",
    "start": "2063000",
    "end": "2073040"
  },
  {
    "text": "so prior to using enforcement you mentioned that kubernetes kind of",
    "start": "2079470",
    "end": "2085290"
  },
  {
    "text": "clouded your visibility into cost compared to the you know cost and usage data that AWS provides but now that you",
    "start": "2085290",
    "end": "2093030"
  },
  {
    "text": "have infrared would you say that you have more visibility into your costs than you did with AWS costs and usage",
    "start": "2093030",
    "end": "2102720"
  },
  {
    "text": "reports that's a good question I think",
    "start": "2102720",
    "end": "2113220"
  },
  {
    "text": "so in general we we kind of have more granular visibility with enforcement in",
    "start": "2113220",
    "end": "2120510"
  },
  {
    "text": "some sense because we see our usage disaggregated across different clusters",
    "start": "2120510",
    "end": "2125700"
  },
  {
    "text": "so if we have one service that's running across like four or five clusters we see our usage across those five there are",
    "start": "2125700",
    "end": "2136710"
  },
  {
    "text": "some I guess like challenges around the unallocated portion of our crew",
    "start": "2136710",
    "end": "2143010"
  },
  {
    "text": "brightest clusters so that that might make it a little bit harder but it's a",
    "start": "2143010",
    "end": "2153270"
  },
  {
    "text": "question you mentioned that you have different type of allocation based on",
    "start": "2153270",
    "end": "2158280"
  },
  {
    "text": "the different team so one question I was wondering is if you have different team that are like let's say I've got a",
    "start": "2158280",
    "end": "2165329"
  },
  {
    "text": "workload that is CPU driven while another one that is memory driven and they both share within the same cluster",
    "start": "2165329",
    "end": "2171900"
  },
  {
    "text": "how do you split them apart so when we",
    "start": "2171900",
    "end": "2178770"
  },
  {
    "text": "were first building the multi-platform attribution with kubernetes GPU wasn't",
    "start": "2178770",
    "end": "2186329"
  },
  {
    "text": "really supported through CubeSat metrics not sure if that's still the case but we",
    "start": "2186329",
    "end": "2191609"
  },
  {
    "text": "basically could collect attribution schedules for either CPU data or for memory data and so we did some like",
    "start": "2191609",
    "end": "2199200"
  },
  {
    "text": "ad-hoc analysis for our platforms to find whether CPU or memory made more",
    "start": "2199200",
    "end": "2204359"
  },
  {
    "text": "sense in terms of like how that allocation would come out and so for our",
    "start": "2204359",
    "end": "2210359"
  },
  {
    "text": "core platforms we found that it was CPU for other platforms like for some of our",
    "start": "2210359",
    "end": "2216450"
  },
  {
    "text": "ml workloads we found it was a memory and so we're basically allowing",
    "start": "2216450",
    "end": "2221970"
  },
  {
    "text": "platforms to choose which of those standard kubernetes models they can",
    "start": "2221970",
    "end": "2226980"
  },
  {
    "text": "actually be their platform based on and if neither of those really works for them then they can either report their",
    "start": "2226980",
    "end": "2233310"
  },
  {
    "text": "own usage or support their own allocation schedule so you said so if",
    "start": "2233310",
    "end": "2249120"
  },
  {
    "text": "there's two types of workloads then you have to instantiate two times so platforms um",
    "start": "2249120",
    "end": "2255060"
  },
  {
    "text": "that's so not necessarily but like",
    "start": "2255060",
    "end": "2262200"
  },
  {
    "text": "practically speaking for example in our core clusters we find that like 95% of",
    "start": "2262200",
    "end": "2269340"
  },
  {
    "text": "those workloads are CPU bound and so we feel somewhat comfortable allocate or",
    "start": "2269340",
    "end": "2276030"
  },
  {
    "text": "attributing those based on CPU so we",
    "start": "2276030",
    "end": "2283050"
  },
  {
    "text": "like to know that it leaves that you have a version of cout flowcode leaves",
    "start": "2283050",
    "end": "2288270"
  },
  {
    "text": "phone and is modified from the cooler open source project right and I would",
    "start": "2288270",
    "end": "2293700"
  },
  {
    "text": "like to know the difference between the leaf flow and of a source version could",
    "start": "2293700",
    "end": "2300050"
  },
  {
    "text": "you talk about the lift learner right yeah okay so live learn far as I know is",
    "start": "2301070",
    "end": "2308880"
  },
  {
    "text": "a collection of a cycle internal machine learning platform at lift and my",
    "start": "2308880",
    "end": "2315090"
  },
  {
    "text": "understanding is they use components from a release version of code flow so they may have like for an example of the",
    "start": "2315090",
    "end": "2323070"
  },
  {
    "text": "hybrid parameter tuning I think that they built around a UI to simplify some of the like getting started experience",
    "start": "2323070",
    "end": "2330210"
  },
  {
    "text": "because if you use the Cadi of just out of the box you have to configure to see",
    "start": "2330210",
    "end": "2335580"
  },
  {
    "text": "RDS and all that stuff right so that they have a pretty nice user interface sense and it's more specific towards it",
    "start": "2335580",
    "end": "2342750"
  },
  {
    "text": "but it's not like it's not a different version of go floor okay so and in the future is it possible",
    "start": "2342750",
    "end": "2350430"
  },
  {
    "text": "to open-source those different feature maybe maybe because in the leaves they have a good feature and that is that cou",
    "start": "2350430",
    "end": "2359339"
  },
  {
    "text": "flow doesn't have and maybe believe to can contribute to cou flow maybe I mean I think they should agreed oh cool thank",
    "start": "2359339",
    "end": "2371549"
  },
  {
    "text": "you everybody feel free to continue the conversation in the hallway yes",
    "start": "2371549",
    "end": "2376849"
  }
]
[
  {
    "start": "0",
    "end": "10000"
  },
  {
    "text": "my name is Ned beverage and album sharing with you how we run and manage",
    "start": "60",
    "end": "5390"
  },
  {
    "text": "kafka clusters in kubernetes a tomatillos and amylose is provider of IT",
    "start": "5390",
    "end": "12240"
  },
  {
    "start": "10000",
    "end": "58000"
  },
  {
    "text": "services for travel industry so for those of you who came by plane and sting",
    "start": "12240",
    "end": "17430"
  },
  {
    "text": "or hotel you might have used be using our services without knowing we're",
    "start": "17430",
    "end": "22830"
  },
  {
    "text": "celebrating 30 years this year which makes us much younger than our biggest competitor which is a texan company we",
    "start": "22830",
    "end": "30150"
  },
  {
    "text": "have been running kubernetes since its inception so since three years which is",
    "start": "30150",
    "end": "35460"
  },
  {
    "text": "basically 30 years equivalent in kubernetes years on our own premises and",
    "start": "35460",
    "end": "41430"
  },
  {
    "text": "in public clouds i'm solution architecture Madhu's i'm helping our",
    "start": "41430",
    "end": "46440"
  },
  {
    "text": "business units i'll developed new platforms or migrate and 30 years we have but the number of applications and",
    "start": "46440",
    "end": "52890"
  },
  {
    "text": "today's migrations are over almost always towards kubernetes so we use",
    "start": "52890",
    "end": "59430"
  },
  {
    "text": "Kafka we use Kafka outside kubernetes we use Kafka next to kubernetes we actually",
    "start": "59430",
    "end": "65460"
  },
  {
    "text": "did it since we started using it for logs and for events collection we have been installing it using puppet which is",
    "start": "65460",
    "end": "72450"
  },
  {
    "text": "an experience we don't like to repeat and recently we had this idea to start",
    "start": "72450",
    "end": "78930"
  },
  {
    "text": "using actually Kafka for more functional stuff and we are building this streaming platform where we have a number of",
    "start": "78930",
    "end": "85670"
  },
  {
    "text": "events operational events from the airlines or things like bookings or",
    "start": "85670",
    "end": "91009"
  },
  {
    "text": "boardings which go into the platform there's a whole number of micro services",
    "start": "91009",
    "end": "97079"
  },
  {
    "text": "which process this in the pipeline and then certainly some actions executed at the end and use Kafka is underlying",
    "start": "97079",
    "end": "103110"
  },
  {
    "text": "messaging infrastructure so it's supposed to be advanced session so I guess you all know Kafka to be on the",
    "start": "103110",
    "end": "110399"
  },
  {
    "start": "105000",
    "end": "149000"
  },
  {
    "text": "same page choice Kafka it's a streaming platform you have a",
    "start": "110399",
    "end": "115890"
  },
  {
    "text": "cluster of servers and servers are called brokers storing streams of",
    "start": "115890",
    "end": "121320"
  },
  {
    "text": "Records in topics topics are split into partitions which are spread over all",
    "start": "121320",
    "end": "128220"
  },
  {
    "text": "brokers which allows for horizontal scalability you can add new brokers a new partition",
    "start": "128220",
    "end": "133490"
  },
  {
    "text": "and accept more traffic you can replicate those partitions to have a",
    "start": "133490",
    "end": "138770"
  },
  {
    "text": "higher ability if I'm broker dies you have a backup on another and you have",
    "start": "138770",
    "end": "144730"
  },
  {
    "text": "producers and consumers as clients of this platform can so can we run it in",
    "start": "144730",
    "end": "151130"
  },
  {
    "start": "149000",
    "end": "220000"
  },
  {
    "text": "kubernetes well when you run a normal replica set or you do deployment in",
    "start": "151130",
    "end": "157280"
  },
  {
    "text": "kubernetes you get something like a pod which is called with a random ish",
    "start": "157280",
    "end": "163390"
  },
  {
    "text": "extension at the end which is not fits well with Kafka basic in Kafka in a calc",
    "start": "163390",
    "end": "171710"
  },
  {
    "text": "a cluster each broker has its own unique identity which is both an ID but it also",
    "start": "171710",
    "end": "177350"
  },
  {
    "text": "has to have your own unique network address so that brokers can talk between themselves and also that they can",
    "start": "177350",
    "end": "182930"
  },
  {
    "text": "clients can talk with brokers they also need persistence to store this partitioned log files in addition you",
    "start": "182930",
    "end": "191120"
  },
  {
    "text": "don't you need another thing next a Kafka cluster is a zookeeper cluster because Kafka stores a lot of metadata",
    "start": "191120",
    "end": "198080"
  },
  {
    "text": "inside zookeeper which is basically exactly the same thing you need another cluster with each other identity and",
    "start": "198080",
    "end": "205970"
  },
  {
    "text": "persistence and luckily we have now stateful sets in kubernetes actually",
    "start": "205970",
    "end": "212450"
  },
  {
    "text": "when we started those were called pet sets they evolved and they will soon be",
    "start": "212450",
    "end": "217880"
  },
  {
    "text": "exiting better so what is a stateful set unlike traditional pods if we can save",
    "start": "217880",
    "end": "226610"
  },
  {
    "text": "something three years old traditional is stateful set pods have stable Poland",
    "start": "226610",
    "end": "234050"
  },
  {
    "text": "entities so they will called pod zero pod one was two they you also need to",
    "start": "234050",
    "end": "239660"
  },
  {
    "text": "create headless service which is a kind of sub domain within your namespace so",
    "start": "239660",
    "end": "245600"
  },
  {
    "text": "your pod address would be pods erode some domain if it's the name of the service dot name space whether they",
    "start": "245600",
    "end": "253310"
  },
  {
    "text": "provide stable storage they provide orders start up and start down or shut down so they will start press 0 then 1",
    "start": "253310",
    "end": "259910"
  },
  {
    "text": "then 2 and shut down in reverse and since recently there is a rolling gap",
    "start": "259910",
    "end": "266570"
  },
  {
    "text": "it's so to run Kafka and zookeeper we need to state process and actually know",
    "start": "266570",
    "end": "272660"
  },
  {
    "start": "267000",
    "end": "313000"
  },
  {
    "text": "medias when we rank Afghan zookeeper deployments we always run one Kafka and one associated zookeeper for those who",
    "start": "272660",
    "end": "279890"
  },
  {
    "text": "operate Kafka you know you can share zookeepers across many several clusters it's not what we're doing",
    "start": "279890",
    "end": "285230"
  },
  {
    "text": "two bridges we're deploying one one-to-one and in addition there is a",
    "start": "285230",
    "end": "291680"
  },
  {
    "text": "discovery service so unlike headless service which doesn't have any cluster IP the discovery service has the cluster",
    "start": "291680",
    "end": "299000"
  },
  {
    "text": "IP and it's actually allows clients to just say okay I want to connect to Kafka you would strap them you don't have to",
    "start": "299000",
    "end": "305360"
  },
  {
    "text": "tell them go to Kafka zero we tell them go to Kafka and it will fall on one of the brokers and then learn about for",
    "start": "305360",
    "end": "311870"
  },
  {
    "text": "cluster and of course if you want to deploy things in kubernetes first thing",
    "start": "311870",
    "end": "317720"
  },
  {
    "start": "313000",
    "end": "349000"
  },
  {
    "text": "that you need is containers and you need your descriptors and then you need probably things like I want to",
    "start": "317720",
    "end": "324500"
  },
  {
    "text": "facilitate this and to replicate and to do several times deployment so you things like charts so there is a number",
    "start": "324500",
    "end": "331040"
  },
  {
    "text": "of projects out there on github I think most are inspired by Owens kubernetes",
    "start": "331040",
    "end": "336680"
  },
  {
    "text": "Kafka those involved are the ones which are inspired by what how we operate",
    "start": "336680",
    "end": "342170"
  },
  {
    "text": "inside the Madhu's you have a chart and you have the operator so I'll be trying",
    "start": "342170",
    "end": "350780"
  },
  {
    "start": "349000",
    "end": "458000"
  },
  {
    "text": "do small demo so I hope the demo gods are on my side today it worked on plane coming over here so",
    "start": "350780",
    "end": "359090"
  },
  {
    "text": "the first thing I will do I will deploy to a producer in the consumer",
    "start": "359090",
    "end": "364810"
  },
  {
    "text": "and of course we'll see because I haven't deployed Kafka cluster they will",
    "start": "368840",
    "end": "376230"
  },
  {
    "text": "probably fail probably so they'll failing as there's no Caprica their nose knows nothing in the cluster",
    "start": "376230",
    "end": "382050"
  },
  {
    "text": "so let's delete those two and I would",
    "start": "382050",
    "end": "387419"
  },
  {
    "text": "now deploy class who you a time ideas we are actually running or open shift as October neatest distribution so we're",
    "start": "387419",
    "end": "393000"
  },
  {
    "text": "using openshift templates to deploy here I'll be using home charts how is package manager for Benitez and",
    "start": "393000",
    "end": "400710"
  },
  {
    "text": "it's a great way to reproduce your deployments or to have multiple deployments if you want in an",
    "start": "400710",
    "end": "406620"
  },
  {
    "text": "environment so I will here deploy my cluster",
    "start": "406620",
    "end": "413870"
  },
  {
    "text": "and she takes just a few seconds and we'll see what hang will deploy all the",
    "start": "419470",
    "end": "426040"
  },
  {
    "text": "elements necessary so several stateful sets and services that are needed so let's have a look first we have our",
    "start": "426040",
    "end": "431320"
  },
  {
    "text": "staple sets up there two of them Kafka and zookeeper I requested three of each",
    "start": "431320",
    "end": "439630"
  },
  {
    "text": "and we have our services that were so mentioning just before we have a headless services with no IP no cluster",
    "start": "439630",
    "end": "446440"
  },
  {
    "text": "IP and we have a cluster IP services for the discovery there are few other things",
    "start": "446440",
    "end": "451660"
  },
  {
    "text": "that are deployed here by talking about those later so while it spins them up",
    "start": "451660",
    "end": "460720"
  },
  {
    "start": "458000",
    "end": "538000"
  },
  {
    "text": "and just share a few of the practices we use actually in on ideas when deploying",
    "start": "460720",
    "end": "466960"
  },
  {
    "text": "Kafka Kafka is pretty much disk i/o and network performance per capita disk i/o",
    "start": "466960",
    "end": "474040"
  },
  {
    "text": "network base so we will actually want to land Kafka Brokers on the instances which",
    "start": "474040",
    "end": "480430"
  },
  {
    "text": "have good performance disguise so basically it means SSD and we use note selectors for this for all the brokers",
    "start": "480430",
    "end": "487300"
  },
  {
    "text": "have known selectors that have want to deploy them on the nodes which has have a label disk fast or something similar",
    "start": "487300",
    "end": "493930"
  },
  {
    "text": "but we also want to do something is that we don't want it all our capture brokers",
    "start": "493930",
    "end": "499090"
  },
  {
    "text": "land on the same node with this label because if we lose that node then we lose all of the cluster so we are using",
    "start": "499090",
    "end": "506440"
  },
  {
    "text": "an T affinity just featuring kubernetes which allows us to tell you take this a",
    "start": "506440",
    "end": "513419"
  },
  {
    "text": "pod which have this specific label and spread them across some topology key and",
    "start": "513419",
    "end": "520560"
  },
  {
    "text": "here we are using a host name G so we are saying basically two kubernetes when",
    "start": "520560",
    "end": "525820"
  },
  {
    "text": "you deploy these Kafka brokers please make them across different machines we",
    "start": "525820",
    "end": "531550"
  },
  {
    "text": "are using preferred you can also enforce it you can say it has to be on different machines the other thing which is",
    "start": "531550",
    "end": "541120"
  },
  {
    "start": "538000",
    "end": "571000"
  },
  {
    "text": "necessary for Kafka is persistent storage when you're using stateful set",
    "start": "541120",
    "end": "547089"
  },
  {
    "text": "you can use a volume volume claim templates were actually",
    "start": "547089",
    "end": "552440"
  },
  {
    "text": "specified a kind of volume claim you want and each part would get exactly the",
    "start": "552440",
    "end": "558020"
  },
  {
    "text": "same volume claimed type so you have a six part you will have six different",
    "start": "558020",
    "end": "563680"
  },
  {
    "text": "claims and for those of you who were reading this license and of listening of me it's written things they are",
    "start": "563680",
    "end": "569780"
  },
  {
    "text": "completely different because that's a common wisdom when you're running Kafka you want to keep your logs you want to",
    "start": "569780",
    "end": "576890"
  },
  {
    "start": "571000",
    "end": "695000"
  },
  {
    "text": "get persistent volumes you get its provisioned its attached to your pod it's stored your pod dies you will get",
    "start": "576890",
    "end": "582530"
  },
  {
    "text": "it back again our particular case we are building a streaming platform which has",
    "start": "582530",
    "end": "588320"
  },
  {
    "text": "pretty strict isolates from the moment that an event comes inside it should be",
    "start": "588320",
    "end": "594050"
  },
  {
    "text": "all the action should be taken within a few seconds at most a few minutes so we",
    "start": "594050",
    "end": "599450"
  },
  {
    "text": "can keep the amount of data fairly limited on the brokers and we want this",
    "start": "599450",
    "end": "605690"
  },
  {
    "text": "high performance so we could use host host path but that's not good security",
    "start": "605690",
    "end": "612260"
  },
  {
    "text": "wise so what we actually do is we for each of the pod in a poll set with two PC okay use empty volume it would be",
    "start": "612260",
    "end": "619040"
  },
  {
    "text": "local disk it will be an SSD it will be very fast if the container crashes we",
    "start": "619040",
    "end": "625190"
  },
  {
    "text": "get actually the same empty there and all fine if the node crash is what we",
    "start": "625190",
    "end": "630530"
  },
  {
    "text": "live with it but we are running Kafka and one of the selling points of cafes this replication you have a copy of your",
    "start": "630530",
    "end": "638890"
  },
  {
    "text": "partitions replicated so when a pod is spun up on a different note eventually",
    "start": "638890",
    "end": "644540"
  },
  {
    "text": "to get up-to-date in sync with the current leaders and it will be able to",
    "start": "644540",
    "end": "650540"
  },
  {
    "text": "serve it of course to be able to do it you have to have enough brokers and you have enough replicas so yeah five book",
    "start": "650540",
    "end": "657340"
  },
  {
    "text": "brokered cluster and two replicas well you can afford to lose one of the",
    "start": "657340",
    "end": "663320"
  },
  {
    "text": "brokers have to wrap because you can only afford to lose one brokers if you lose to you",
    "start": "663320",
    "end": "668930"
  },
  {
    "text": "you might be in trouble what's coming soon in a queue Benitez is",
    "start": "668930",
    "end": "674090"
  },
  {
    "text": "actually in alpha already is local persistent volumes which would be volumes which are on a local machine and",
    "start": "674090",
    "end": "680510"
  },
  {
    "text": "the pod would then be always scheduled on this particular machine it's something that we'll be looking into future in future",
    "start": "680510",
    "end": "688540"
  },
  {
    "text": "only currently behavior with the empty gear was sufficient for our you use",
    "start": "688540",
    "end": "694069"
  },
  {
    "text": "cases you have to monitor what's going on you won't have there several",
    "start": "694069",
    "end": "700009"
  },
  {
    "start": "695000",
    "end": "719000"
  },
  {
    "text": "approaches called to monitor Kafka consider also in github you may use",
    "start": "700009",
    "end": "706040"
  },
  {
    "text": "Kafka scripts what we actually do in a me do is we use TCP socket who actually",
    "start": "706040",
    "end": "711110"
  },
  {
    "text": "will open the sockets on the character brokers because that's what's telling us it's running it's accepting connections",
    "start": "711110",
    "end": "717259"
  },
  {
    "text": "and we use Prometheus NJ mix we are",
    "start": "717259",
    "end": "723579"
  },
  {
    "start": "719000",
    "end": "747000"
  },
  {
    "text": "we're repackaging ourselves containers so basically we are deriving from what",
    "start": "723579",
    "end": "730129"
  },
  {
    "text": "has been done in fabricate projects which for everything which is JVM automatically exposes primitives and J",
    "start": "730129",
    "end": "737360"
  },
  {
    "text": "mix entry points so you have the nice dashboards and if when the operators needs to do something they can go",
    "start": "737360",
    "end": "742399"
  },
  {
    "text": "directly and connect to the pod and look into the gem X that's all diving into",
    "start": "742399",
    "end": "750589"
  },
  {
    "start": "747000",
    "end": "886000"
  },
  {
    "text": "operators let's have continued with our demo power so",
    "start": "750589",
    "end": "756610"
  },
  {
    "text": "deploy again our consumer and producer and see what happens there oh it's not",
    "start": "764020",
    "end": "772670"
  },
  {
    "text": "working so well actually it's connected it's no longer a big section you should",
    "start": "772670",
    "end": "778310"
  },
  {
    "text": "Java exception we'll see there it's connected but we are running in a",
    "start": "778310",
    "end": "783770"
  },
  {
    "text": "multi-tenant environment so we have micro services which are published there so we have dozen of the themes worth",
    "start": "783770",
    "end": "789410"
  },
  {
    "text": "publishing those independently and we want actually to control who connects to",
    "start": "789410",
    "end": "794720"
  },
  {
    "text": "do which cluster we don't want that okay you go there just that Kafka 1992 and",
    "start": "794720",
    "end": "800510"
  },
  {
    "text": "you're connected to a cluster and you start publishing we want to use to identify clients and we are actually",
    "start": "800510",
    "end": "808130"
  },
  {
    "text": "before I have installed as it's a process we create separate secrets and there are secrets published for each of",
    "start": "808130",
    "end": "814970"
  },
  {
    "text": "the cup clusters which allow clients to connect so there's a jazz file inside it",
    "start": "814970",
    "end": "820959"
  },
  {
    "text": "so let's do it let's deploy the secured version",
    "start": "820959",
    "end": "827800"
  },
  {
    "text": "as we spin up eventually it will hopefully",
    "start": "835750",
    "end": "844200"
  },
  {
    "text": "yes it's there and it's not running it's still failing but it's a different error",
    "start": "846830",
    "end": "852970"
  },
  {
    "text": "it's failing with unknown topic because if you want to run things with Kafka you",
    "start": "852970",
    "end": "859250"
  },
  {
    "text": "need to create topics and there are two ways basically how you do it you can do it by saying okay",
    "start": "859250",
    "end": "864980"
  },
  {
    "text": "anyone can create the topics which basically reads to Caltech thing in there you have a hundreds of topics or",
    "start": "864980",
    "end": "870500"
  },
  {
    "text": "you may use Kafka scripting Capcom scripts to do it so either there is a",
    "start": "870500",
    "end": "876380"
  },
  {
    "text": "person who is typing or you have ansible or whatever tween you use to create",
    "start": "876380",
    "end": "881420"
  },
  {
    "text": "those topics which brings us to the subject of the operators so what are the",
    "start": "881420",
    "end": "888380"
  },
  {
    "start": "886000",
    "end": "926000"
  },
  {
    "text": "operators it's a pattern of transposing the domain knowledge of essary",
    "start": "888380",
    "end": "893720"
  },
  {
    "text": "operations or releasing teams into executive opcode to automate behavior",
    "start": "893720",
    "end": "900940"
  },
  {
    "text": "space on some kind of descriptors you describe what you want to have and the",
    "start": "900940",
    "end": "906500"
  },
  {
    "text": "tooling will do it for you anima dos we actually love all operators we use couple dos there's open source",
    "start": "906500",
    "end": "912320"
  },
  {
    "text": "primitives the views the blue ones are actually doing is that we have written and some are open sourced already",
    "start": "912320",
    "end": "919370"
  },
  {
    "text": "workflow and some will be are like Redis cluster and I'm twisting the doctors do",
    "start": "919370",
    "end": "929750"
  },
  {
    "start": "926000",
    "end": "975000"
  },
  {
    "text": "is they provision clusters that's what primitives are for example does or that but that's where our radius cluster",
    "start": "929750",
    "end": "935839"
  },
  {
    "text": "operator does among other things as you see I can actually fairly easy provision",
    "start": "935839",
    "end": "942740"
  },
  {
    "text": "clusters using a hand charts or open ship templates or apps with sort today",
    "start": "942740",
    "end": "948589"
  },
  {
    "text": "at keynotes and once the platform is up and once Kafka is running for us it",
    "start": "948589",
    "end": "954770"
  },
  {
    "text": "stays in place it will be there for a fairly long amount of time we can scale it up if there's a problem and that's",
    "start": "954770",
    "end": "960620"
  },
  {
    "text": "usually what we need scale up scaling down and evacuation if you have to do",
    "start": "960620",
    "end": "966709"
  },
  {
    "text": "upgrades of the nodes and upgrades are tricky some of these things work because of the category applications talked",
    "start": "966709",
    "end": "973430"
  },
  {
    "text": "about a little bit at the end you have this question of topics is we're deploying dozens of micro",
    "start": "973430",
    "end": "980280"
  },
  {
    "start": "975000",
    "end": "1050000"
  },
  {
    "text": "believe doesn't even more of topics being created and for us we want to have",
    "start": "980280",
    "end": "986430"
  },
  {
    "text": "the topics present in target environments when we deploy micro services so we can start to mediate",
    "start": "986430",
    "end": "991950"
  },
  {
    "text": "we're running we want to delete them if a micro service is not there because particularly they can be rearranged and",
    "start": "991950",
    "end": "999080"
  },
  {
    "text": "for different customers want to have the same behavior in environments in",
    "start": "999080",
    "end": "1004790"
  },
  {
    "text": "development in QA in production but also across different production clusters as we may have clusters running on our",
    "start": "1004790",
    "end": "1011510"
  },
  {
    "text": "premises or in the public cloud we want to be able to react on things like ok",
    "start": "1011510",
    "end": "1017030"
  },
  {
    "text": "this now is no longer having disk space let's reduce retention time for Kafka",
    "start": "1017030",
    "end": "1022760"
  },
  {
    "text": "and we'll actually want to deliver all this as a code so when developers",
    "start": "1022760",
    "end": "1028130"
  },
  {
    "text": "actually finish their coding they do the pull request there's a container bill we",
    "start": "1028130",
    "end": "1033199"
  },
  {
    "text": "actually from their description of their project generally deployment Yama file",
    "start": "1033199",
    "end": "1039050"
  },
  {
    "text": "and generate this descriptor of the topic which then goes even kubernetes and then there is a process in",
    "start": "1039050",
    "end": "1044810"
  },
  {
    "text": "kubernetes a cooperator which looks into it and applies it so how does it look",
    "start": "1044810",
    "end": "1052040"
  },
  {
    "start": "1050000",
    "end": "1098000"
  },
  {
    "text": "topic as a goer it's a config map for us it might be soon customer resource it's",
    "start": "1052040",
    "end": "1059120"
  },
  {
    "text": "a config map which basically says I want a topic like this name which is the name of the config map where the partition",
    "start": "1059120",
    "end": "1065240"
  },
  {
    "text": "count with the replication factor letters and maybe someone knew what how to configure more into details the",
    "start": "1065240",
    "end": "1072500"
  },
  {
    "text": "properties and whenever this config map is created then in queue burn it is the operator that's managing the cluster",
    "start": "1072500",
    "end": "1079040"
  },
  {
    "text": "will create a topic for it and whenever a config map is deleted it will delete it and it's actually exactly the same",
    "start": "1079040",
    "end": "1085250"
  },
  {
    "text": "behavior as Service Catalog provision and provision behavior well intentionally map it because we are",
    "start": "1085250",
    "end": "1092450"
  },
  {
    "text": "going towards offering internally IT services as a Service Catalog so let's do it let's create this",
    "start": "1092450",
    "end": "1102550"
  },
  {
    "start": "1098000",
    "end": "1146000"
  },
  {
    "text": "config map so there and let's have a look at what's going on here so have",
    "start": "1106230",
    "end": "1113590"
  },
  {
    "text": "long a little list here oh and it's working so as soon as the config map was",
    "start": "1113590",
    "end": "1120640"
  },
  {
    "text": "there topic was created and the publisher started working and the consumer started consuming can just show",
    "start": "1120640",
    "end": "1127030"
  },
  {
    "text": "you what happened inside the operator so",
    "start": "1127030",
    "end": "1134140"
  },
  {
    "text": "inside the operator there there's a lot which basically says ok I've seen that",
    "start": "1134140",
    "end": "1140140"
  },
  {
    "text": "you have did the config map and I created a topic for this config map so",
    "start": "1140140",
    "end": "1146590"
  },
  {
    "start": "1146000",
    "end": "1205000"
  },
  {
    "text": "let's find it allows us to manage all the topics but one actually to go a step further there conscious about security",
    "start": "1146590",
    "end": "1154630"
  },
  {
    "text": "we want to control the access to the topics we don't want that a developer",
    "start": "1154630",
    "end": "1161770"
  },
  {
    "text": "hard-coded a topic name in the code that suddenly the micro service which is deployed starts publishing to a topic",
    "start": "1161770",
    "end": "1168580"
  },
  {
    "text": "which shouldn't be there so we are actually using access control where we have each deployment comes with a",
    "start": "1168580",
    "end": "1175660"
  },
  {
    "text": "notation saying OK it's an I'm consuming this topic and I'm publishing to this topic a bit i'm not multiple actually",
    "start": "1175660",
    "end": "1182080"
  },
  {
    "text": "and about what the operator does it monitors this behavior this deployment",
    "start": "1182080",
    "end": "1192130"
  },
  {
    "text": "and will actually apply actually choose first one random user assign it to this",
    "start": "1192130",
    "end": "1198580"
  },
  {
    "text": "deployment create a secret and assign the rights into Kafka to use it so this",
    "start": "1198580",
    "end": "1205840"
  },
  {
    "start": "1205000",
    "end": "1281000"
  },
  {
    "text": "part of the demo",
    "start": "1205840",
    "end": "1208529"
  },
  {
    "text": "the plank here yes y'all and if we look",
    "start": "1214700",
    "end": "1220430"
  },
  {
    "text": "at the operator logs we would immediately see that operator has seen",
    "start": "1220430",
    "end": "1226790"
  },
  {
    "text": "that there is a new deployment they're called Kafka producer and has assigned a user for it and then the same",
    "start": "1226790",
    "end": "1234410"
  },
  {
    "text": "thing for the consumer lower and assign the user great and if you look at the",
    "start": "1234410",
    "end": "1239570"
  },
  {
    "text": "secrets actually see that we can now",
    "start": "1239570",
    "end": "1247940"
  },
  {
    "text": "have credentials created for our producer and somewhere there should be",
    "start": "1247940",
    "end": "1253250"
  },
  {
    "text": "like here should be credentials created for all for the consumers and those credentials contains users which in this",
    "start": "1253250",
    "end": "1260210"
  },
  {
    "text": "particular case for consumer you can only read from one topic and producer can only publish to one topic previous",
    "start": "1260210",
    "end": "1267470"
  },
  {
    "text": "use previous case where with the credentials it's it was it could publish to anything okay a little bit ahead of",
    "start": "1267470",
    "end": "1279260"
  },
  {
    "text": "at the time so which calf cop grades it's the thing that we wanted to build",
    "start": "1279260",
    "end": "1285440"
  },
  {
    "start": "1281000",
    "end": "1376000"
  },
  {
    "text": "since the inception inside calf",
    "start": "1285440",
    "end": "1291170"
  },
  {
    "text": "cooperator during our work on this I think there were like three or four",
    "start": "1291170",
    "end": "1298300"
  },
  {
    "text": "changes in Kafka that had to do upgrades and basically each of them had a little",
    "start": "1298300",
    "end": "1304520"
  },
  {
    "text": "bit different scenario which is like not really looking like something that's easily can be easily automatized so for",
    "start": "1304520",
    "end": "1313370"
  },
  {
    "text": "example if they change into broker protocol you might need first when you upgrade to use the old protocol so you",
    "start": "1313370",
    "end": "1319820"
  },
  {
    "text": "roll out one upgrade then you change do the configuration change then roll the second upgrade but maybe the the Kafka",
    "start": "1319820",
    "end": "1327500"
  },
  {
    "text": "change storage format hopefully now they are one zero so those things will happen will less you change storage format so",
    "start": "1327500",
    "end": "1334760"
  },
  {
    "text": "you might have to first to update consumers then go on on the servers I had this idea like don't upgrade but",
    "start": "1334760",
    "end": "1342920"
  },
  {
    "text": "instead to recreate cluster so basically it means we have one cluster running the old version we",
    "start": "1342920",
    "end": "1348050"
  },
  {
    "text": "create a new cluster with the new version they're running next to each other we can publish actually to book",
    "start": "1348050",
    "end": "1355850"
  },
  {
    "text": "though to both clusters and then we switch it's kinda Bluegreen deployment it comes with its own set of problems",
    "start": "1355850",
    "end": "1364100"
  },
  {
    "text": "which is actually wouldn't suggest that any more well more looking into",
    "start": "1364100",
    "end": "1369410"
  },
  {
    "text": "automated izing that in the future finding a way how we can do this the first step simply and performance as I",
    "start": "1369410",
    "end": "1381770"
  },
  {
    "start": "1376000",
    "end": "1469000"
  },
  {
    "text": "said Kafka performances dominated by disk i/o that's what we have experienced",
    "start": "1381770",
    "end": "1387920"
  },
  {
    "text": "and having a good desk we're hoping for SSD but having a good disk even if you",
    "start": "1387920",
    "end": "1393800"
  },
  {
    "text": "have network storage maybe it will work if a good network storage then the second is by network and it's almost",
    "start": "1393800",
    "end": "1401330"
  },
  {
    "text": "never by CPU or by memory fairly low",
    "start": "1401330",
    "end": "1408380"
  },
  {
    "text": "even for throughput like hundred K messages per second have issues there's",
    "start": "1408380",
    "end": "1414170"
  },
  {
    "text": "a couple of things which pure strange when doing tests thinks of some like",
    "start": "1414170",
    "end": "1420820"
  },
  {
    "text": "sometimes Kafka brokers and Duke a broker and the zookeeper land on the",
    "start": "1420820",
    "end": "1426650"
  },
  {
    "text": "same node so it actually reduced quite a lot network throughput there because",
    "start": "1426650",
    "end": "1432020"
  },
  {
    "text": "they're talking to themselves on the same node sometimes that actually even",
    "start": "1432020",
    "end": "1437060"
  },
  {
    "text": "clients will land on the same node so you might see that you have like twenty",
    "start": "1437060",
    "end": "1443180"
  },
  {
    "text": "instances of a micro service pod and then two of them are having this super",
    "start": "1443180",
    "end": "1449990"
  },
  {
    "text": "high performance and all the others are behind the same so they landed actually same node as ask Africa brokers and",
    "start": "1449990",
    "end": "1457640"
  },
  {
    "text": "they're talking between their self things to be ready in a cloud",
    "start": "1457640",
    "end": "1462650"
  },
  {
    "text": "environment that's not everything behaves always the same and I think that would be it for representation if you",
    "start": "1462650",
    "end": "1471680"
  },
  {
    "start": "1469000",
    "end": "1982000"
  },
  {
    "text": "have any questions feel free to ask [Applause]",
    "start": "1471680",
    "end": "1476820"
  },
  {
    "text": "[Music]",
    "start": "1476820",
    "end": "1480259"
  },
  {
    "text": "can you repeat order this is your Kafka",
    "start": "1487730",
    "end": "1492960"
  },
  {
    "text": "cluster zone away or how are you handling gauging okay so we are come our",
    "start": "1492960",
    "end": "1498090"
  },
  {
    "text": "clusters are a spread so kubernetes clusters are spread across our are close",
    "start": "1498090",
    "end": "1505320"
  },
  {
    "text": "out our infrastructure and we basically rely on the fact that they are they're",
    "start": "1505320",
    "end": "1512010"
  },
  {
    "text": "not there no we're realizing - in fact that there will be split across different zones in our data center but",
    "start": "1512010",
    "end": "1518490"
  },
  {
    "text": "not we don't make them aware of the zone they're not - right there's nothing like haricot vert or things like that",
    "start": "1518490",
    "end": "1526430"
  },
  {
    "text": "we have our we operate our own that data a data center and we will deploy to",
    "start": "1532560",
    "end": "1538120"
  },
  {
    "text": "water clouds but prepared on datacenter yeah mm-hmm okay you can say it I repeat",
    "start": "1538120",
    "end": "1551160"
  },
  {
    "text": "the question was do we have any constraints a number persistent volume we create per node as I said when we run",
    "start": "1558400",
    "end": "1565960"
  },
  {
    "text": "Kafka we are running them with empty there so we don't create persistent volumes we are not using much persistent",
    "start": "1565960",
    "end": "1573290"
  },
  {
    "text": "volumes at the moment we use for some of the monitoring tool we used it for the",
    "start": "1573290",
    "end": "1578540"
  },
  {
    "text": "Kafka but and but hadn't put in place any specific constraints there okay the",
    "start": "1578540",
    "end": "1595640"
  },
  {
    "text": "question was called to a handle of cooperator upgrades but it's tough",
    "start": "1595640",
    "end": "1601280"
  },
  {
    "text": "cooperate is completely stateless so it's actually upgraded out of the band it can be updated in any moment in the",
    "start": "1601280",
    "end": "1606830"
  },
  {
    "text": "time and actually all the updates it does it does by Delta it's like kubernetes it's checks what is Kafka",
    "start": "1606830",
    "end": "1613040"
  },
  {
    "text": "cluster what we're having kubernetes and applies the Delta yes yes it's watching",
    "start": "1613040",
    "end": "1624050"
  },
  {
    "text": "changes undercover the question was it that's tough culprit or listen to the changes on accompaniment to access the",
    "start": "1624050",
    "end": "1636380"
  },
  {
    "text": "questions do provide a way to get to Kafka from outside class sir meaning clients are outside of the class know if",
    "start": "1636380",
    "end": "1646400"
  },
  {
    "text": "someone has the solution for that we were very interested in ok",
    "start": "1646400",
    "end": "1654340"
  },
  {
    "text": "the question was did we write the operator the Java client for the kubernetes with the Java client for the",
    "start": "1660590",
    "end": "1667050"
  },
  {
    "text": "kubernetes and Java client for the new Java client for the Kafka admin client",
    "start": "1667050",
    "end": "1673970"
  },
  {
    "text": "here",
    "start": "1673970",
    "end": "1676970"
  },
  {
    "text": "it's didn't repeat or so confluent",
    "start": "1680830",
    "end": "1690230"
  },
  {
    "text": "suggested two wrong Kafka cluster on bear motto for performance reason what do you think about that okay",
    "start": "1690230",
    "end": "1698770"
  },
  {
    "text": "our approach is that we tend to run as much as possible things in VMs and then",
    "start": "1698770",
    "end": "1705740"
  },
  {
    "text": "let's run into kubernetes maybe we will be running to bring to some bare metal but currently we are running on the new",
    "start": "1705740",
    "end": "1712730"
  },
  {
    "text": "VMs we had the same exactly the same suggestion from confluence to run at on bare metal but we went for a VM I think",
    "start": "1712730",
    "end": "1721490"
  },
  {
    "text": "there was a sinner yeah",
    "start": "1721490",
    "end": "1724600"
  },
  {
    "text": "it's needed for a date the question was why is this headless service is needed",
    "start": "1726509",
    "end": "1731789"
  },
  {
    "text": "its need for stateful set it by design that's how staple said behaves you need to provide an applet service and then",
    "start": "1731789",
    "end": "1738299"
  },
  {
    "text": "the pods will be in with the DNS name which is pod name state Harless service",
    "start": "1738299",
    "end": "1744149"
  },
  {
    "text": "tandem I think our in this platform are",
    "start": "1744149",
    "end": "1754980"
  },
  {
    "text": "typical cluster would be five brokers we",
    "start": "1754980",
    "end": "1760559"
  },
  {
    "text": "have bigger ones but I'm not sure I can't share formation",
    "start": "1760559",
    "end": "1768830"
  },
  {
    "text": "you can either come or because I really",
    "start": "1777680",
    "end": "1783590"
  },
  {
    "text": "the order of deployment is that a true keeper has to come up and running before",
    "start": "1785360",
    "end": "1790440"
  },
  {
    "text": "you deploy oh yeah thanks we don't have force order of deployment we actually I",
    "start": "1790440",
    "end": "1796710"
  },
  {
    "text": "don't think I put get port Alex let's do just that you sit here yet actually",
    "start": "1796710",
    "end": "1806460"
  },
  {
    "text": "seeing that the kafka zero restarted once I was in starting because it's",
    "start": "1806460",
    "end": "1811860"
  },
  {
    "text": "waiting was it said there's no zookeeper Andrew twist it crashed and we started",
    "start": "1811860",
    "end": "1817950"
  },
  {
    "text": "again you are asking the Kafka to try and recover until the zookeeper is up",
    "start": "1817950",
    "end": "1823620"
  },
  {
    "text": "and running I mean just speaking to the mic you put",
    "start": "1823620",
    "end": "1830340"
  },
  {
    "text": "the link up of your github operator yeah do you have any other custom code that you used to run it or is that kind of",
    "start": "1830340",
    "end": "1835770"
  },
  {
    "text": "the everything that is needed now it's not what we run inside house and that's",
    "start": "1835770",
    "end": "1841830"
  },
  {
    "text": "your question what do you be able to describe any of the the customizations",
    "start": "1841830",
    "end": "1847170"
  },
  {
    "text": "that you had to do we have few customizations around security of mostly",
    "start": "1847170",
    "end": "1852990"
  },
  {
    "text": "which are inside it's pretty much a similar thing also we are less up to",
    "start": "1852990",
    "end": "1861600"
  },
  {
    "text": "date with the recent version of kubernetes and openshift inside house compared to this one so you",
    "start": "1861600",
    "end": "1867450"
  },
  {
    "text": "don't see any restrictions on running the published version and so does",
    "start": "1867450",
    "end": "1874520"
  },
  {
    "text": "actually we are in talks with some open-source players that to make this",
    "start": "1874520",
    "end": "1881850"
  },
  {
    "text": "really open source web eff doesn't get anything we will be open sourcing it from am at your side but and if there is",
    "start": "1881850",
    "end": "1890070"
  },
  {
    "text": "to be a community we think there should be someone who is more into this panel wonderful let's talk",
    "start": "1890070",
    "end": "1897350"
  },
  {
    "text": "sorry can you just repeat Oh what kind of stories do you use when we run it on public cloud so we don't run I say that",
    "start": "1900560",
    "end": "1910590"
  },
  {
    "text": "we don't run this with persistence volumed at the public cloud we use",
    "start": "1910590",
    "end": "1916020"
  },
  {
    "text": "instances we have which have asses these even on public cloud can you describe",
    "start": "1916020",
    "end": "1925860"
  },
  {
    "text": "your general strategy for scaling down",
    "start": "1925860",
    "end": "1930049"
  },
  {
    "text": "no scaling down general strategy to",
    "start": "1932840",
    "end": "1941970"
  },
  {
    "text": "scaling down would be a lot of manual work by moving partitions and replicas",
    "start": "1941970",
    "end": "1949320"
  },
  {
    "text": "and then scaling down and one of the things is that usually system may be",
    "start": "1949320",
    "end": "1954840"
  },
  {
    "text": "like - usually most of the problems that we experienced were due to the humans so when the humans scaled it down without",
    "start": "1954840",
    "end": "1962240"
  },
  {
    "text": "taking steps but they have to do before so it would be really great if that can",
    "start": "1962240",
    "end": "1968880"
  },
  {
    "text": "be automatized questions oh thank you",
    "start": "1968880",
    "end": "1975210"
  },
  {
    "text": "very much I hope you have there are nice [Applause] [Music]",
    "start": "1975210",
    "end": "1981950"
  }
]
[
  {
    "start": "0",
    "end": "77000"
  },
  {
    "text": "okay cool uh it's 11: a.m. let's get started so thank you everyone for attending my talk today my name is",
    "start": "680",
    "end": "6879"
  },
  {
    "text": "Shirley yam and I'm an engineering manager in LinkedIn today we're going to talk about how LinkedIn stabilized and",
    "start": "6879",
    "end": "13639"
  },
  {
    "text": "ji First Data lak house by provision 20,000 ephemeral clusters every year so",
    "start": "13639",
    "end": "20039"
  },
  {
    "text": "a little bit about myself uh I've been LinkedIn for seven years currently I'm working in linkedin's Big Data platform",
    "start": "20039",
    "end": "26599"
  },
  {
    "text": "team so there are two areas I'm responsible for one is the foundations team uh which is handles all horizontal",
    "start": "26599",
    "end": "34079"
  },
  {
    "text": "stuff within the offline stat including developer productivity that is how we build this product uh security um cost",
    "start": "34079",
    "end": "42160"
  },
  {
    "text": "efficiency as well as some of resilience stuff the other area is the um LinkedIn",
    "start": "42160",
    "end": "47440"
  },
  {
    "text": "airflow team where we are working on all the data processing jobs and also some",
    "start": "47440",
    "end": "53359"
  },
  {
    "text": "of the workflow orchestration within LinkedIn okay so agendas today we we",
    "start": "53359",
    "end": "60199"
  },
  {
    "text": "started by talking about our Pro U problem statements and we will share our approach on solving this problem as well",
    "start": "60199",
    "end": "67040"
  },
  {
    "text": "as the results we'll also share some of the learnings and continuous development we'll summarize our talk lastly and also",
    "start": "67040",
    "end": "74080"
  },
  {
    "text": "we'll touch a little bit on our next steps when I talked about uh 20K Emeral",
    "start": "74080",
    "end": "80640"
  },
  {
    "start": "77000",
    "end": "134000"
  },
  {
    "text": "clusters I want to First share about the LinkedIn offline stack and our uh what",
    "start": "80640",
    "end": "86240"
  },
  {
    "text": "the Clusters our ephemeral clusters are simulating so currently LinkedIn has about 10 plus Hado clusters which can be",
    "start": "86240",
    "end": "93520"
  },
  {
    "text": "transfered to more than 35k total notes and 400 four plus extra bu storage so we",
    "start": "93520",
    "end": "100240"
  },
  {
    "text": "run 500k jobs per day and this can be transferred to around 100 million containers allocations every day now the",
    "start": "100240",
    "end": "107640"
  },
  {
    "text": "whole offline stack we have a 100 Engineers working on that which includes both STS and sres and and we are",
    "start": "107640",
    "end": "114719"
  },
  {
    "text": "maintaining uh 30 plus core Services we'll keep growing on that our users are",
    "start": "114719",
    "end": "119920"
  },
  {
    "text": "definitely the whole LinkedIn uh including AI Engineers data scientists analysts and everyone who actually",
    "start": "119920",
    "end": "126719"
  },
  {
    "text": "request access for the offline stack so what are the challenges if we're running",
    "start": "126719",
    "end": "131840"
  },
  {
    "text": "at such a large scale so I want to share two examples here these are two slack",
    "start": "131840",
    "end": "137800"
  },
  {
    "start": "134000",
    "end": "195000"
  },
  {
    "text": "messages I um took a screenshot so the first one is actually a machine learning",
    "start": "137800",
    "end": "143360"
  },
  {
    "text": "Arrow from emoji you can see our AI Engineers are pretty frustrated because the 11 hours drob failed again",
    "start": "143360",
    "end": "150720"
  },
  {
    "text": "and the reason was because the um they trying to release the checkpoint and",
    "start": "150720",
    "end": "155920"
  },
  {
    "text": "fail due to an hdfs connection arrow and uh the second one is actually um kind of",
    "start": "155920",
    "end": "162120"
  },
  {
    "text": "a common issues within uh LinkedIn because we our services are interdependent among each other and in",
    "start": "162120",
    "end": "168640"
  },
  {
    "text": "this specific case uh it's trino so trino was trying to release a backward incompatible change uh which broke the",
    "start": "168640",
    "end": "176360"
  },
  {
    "text": "Jupiter notebook that data scientist and and AI engineer used a lot and",
    "start": "176360",
    "end": "181920"
  },
  {
    "text": "completely block them for a couple hours until they fully rote it back so when",
    "start": "181920",
    "end": "187080"
  },
  {
    "text": "you have such a large scale and you have all these Services interdependent with each other your infrastructure just",
    "start": "187080",
    "end": "193120"
  },
  {
    "text": "become very unpredictable on the other hand and our",
    "start": "193120",
    "end": "198360"
  },
  {
    "start": "195000",
    "end": "337000"
  },
  {
    "text": "business as every other company are continue growing so LinkedIn has transitioned its business to an AI and",
    "start": "198360",
    "end": "204760"
  },
  {
    "text": "machine learning Centric so here we constantly have multiple big initiative",
    "start": "204760",
    "end": "209799"
  },
  {
    "text": "is all going on at the same time so here is a screenshot well sorry see here is basically a snapshot of the current",
    "start": "209799",
    "end": "215480"
  },
  {
    "text": "ongoing uh in at the top level we so the uh the orange one here are actually the",
    "start": "215480",
    "end": "221840"
  },
  {
    "text": "ones it's a new initiatives so at the top level we are heavily investing on the data pre-processing and training we",
    "start": "221840",
    "end": "228519"
  },
  {
    "text": "introduced The mtron Deep speed and large language models to our stock and",
    "start": "228519",
    "end": "234000"
  },
  {
    "text": "to support those at the pipeline level we introduced the flight which is actually famous for its fast iteration",
    "start": "234000",
    "end": "240519"
  },
  {
    "text": "on um the machine learning workflow orchestration as well as airflow uh",
    "start": "240519",
    "end": "245799"
  },
  {
    "text": "which is in replacement of the previous asand to orchestrate the data processing jobs in Compu layer we are shifting",
    "start": "245799",
    "end": "252480"
  },
  {
    "text": "entirely from uh y to kubernetes and we are introducing spark on K8 to our stack",
    "start": "252480",
    "end": "259160"
  },
  {
    "text": "as well as also experimenting on using volcano for the offline uh workload on",
    "start": "259160",
    "end": "264960"
  },
  {
    "text": "scheduling metadata layer so we we are adopting unified SE",
    "start": "264960",
    "end": "270280"
  },
  {
    "text": "uh on top of AAR Iceberg so LinkedIn just open source its um product open",
    "start": "270280",
    "end": "275680"
  },
  {
    "text": "house I think a couple weeks ago so if you're interested feel free to uh to check that on the GitHub lastly we're",
    "start": "275680",
    "end": "282199"
  },
  {
    "text": "actually adopting object storage so LinkedIn is currently building its own object storage and um which is a best",
    "start": "282199",
    "end": "289960"
  },
  {
    "text": "for um better for the io and read uh read R reput for machine learning uh one",
    "start": "289960",
    "end": "296080"
  },
  {
    "text": "reasons is as I showed before uh sometimes the hdfs is not not that stable so we want to eliminate that",
    "start": "296080",
    "end": "301360"
  },
  {
    "text": "issues another is and you we want a faster say throughput in term of say data set and storing the experiments and",
    "start": "301360",
    "end": "309759"
  },
  {
    "text": "uh even the code across the stat we're actually doing a security revamp so um",
    "start": "309759",
    "end": "316120"
  },
  {
    "text": "currently LinkedIn is still using the um had delegation token so with all of",
    "start": "316120",
    "end": "321759"
  },
  {
    "text": "these change within our stat it's no longer can satisfy our needs so we are leveraging uh Speedy token as well as",
    "start": "321759",
    "end": "328600"
  },
  {
    "text": "the spile and we wanted to say adopt the rback and pack based C security mechanism how does our engineer feel",
    "start": "328600",
    "end": "335759"
  },
  {
    "text": "about all of this and of course our Engineers are very excited to work on our new",
    "start": "335759",
    "end": "341400"
  },
  {
    "start": "337000",
    "end": "431000"
  },
  {
    "text": "initiatives like every other engineer right so on the other hand um they",
    "start": "341400",
    "end": "346560"
  },
  {
    "text": "actually afraid of making new change two examples here the first one is the last Fu had update was September",
    "start": "346560",
    "end": "353360"
  },
  {
    "text": "2021 even though this message was return s months ago it's still around two years",
    "start": "353360",
    "end": "359240"
  },
  {
    "text": "without any of the F Hado update so a lot of new Chang we're not able to say uh capturing our stack and the second",
    "start": "359240",
    "end": "366960"
  },
  {
    "text": "one is a coordination among our Engineers when they try to release change to our client libraries in",
    "start": "366960",
    "end": "373240"
  },
  {
    "text": "LinkedIn all the client of the offline stack are in a uh single monor report",
    "start": "373240",
    "end": "378360"
  },
  {
    "text": "the reason we did this before is because we want to make sure that say we always keep backward in uh compatibility when",
    "start": "378360",
    "end": "385360"
  },
  {
    "text": "we release these change among the stack now uh for after couple years our stat",
    "start": "385360",
    "end": "390680"
  },
  {
    "text": "grows our say number of say Engineers grows so this is actually become a botet so consider you have a 100 Engineers or",
    "start": "390680",
    "end": "397800"
  },
  {
    "text": "say contribute to the the same code base you actually are very scared of say releasing product say issues or causing",
    "start": "397800",
    "end": "405000"
  },
  {
    "text": "product issues when you are releasing change so our engineer actually needs to constantly think about backward",
    "start": "405000",
    "end": "410120"
  },
  {
    "text": "compatibility forward compatibility and all of these things so and basically you",
    "start": "410120",
    "end": "415319"
  },
  {
    "text": "can see there they even a little bit Fair of say um releasing the change and the result is we actually last year",
    "start": "415319",
    "end": "422160"
  },
  {
    "text": "we actually seen on that there are 15 versions without getting released in our client say libraries which actually caus",
    "start": "422160",
    "end": "428800"
  },
  {
    "text": "a big production issues so we start to debug this issue right and we need to solve it uh like every other company our",
    "start": "428800",
    "end": "436160"
  },
  {
    "start": "431000",
    "end": "523000"
  },
  {
    "text": "development cycle is we develop we build and we deploy to production now because",
    "start": "436160",
    "end": "441360"
  },
  {
    "text": "linking is having such a large scale and we have so many clusters the bottom is",
    "start": "441360",
    "end": "446680"
  },
  {
    "text": "when you deploy to all of these clusters so consider you deploy to one of the static clusters and it takes a couple",
    "start": "446680",
    "end": "453800"
  },
  {
    "text": "days and now if you find a bug and now you have to say all go back you you need",
    "start": "453800",
    "end": "459000"
  },
  {
    "text": "to roll back and go back to fix it the process all the process again so it may take couple weeks and eventually when",
    "start": "459000",
    "end": "465800"
  },
  {
    "text": "you release your all the production clusters it may take a couple of months so it's pretty bad so we started to",
    "start": "465800",
    "end": "471919"
  },
  {
    "text": "think about this what if we can just say taking something ephemeral",
    "start": "471919",
    "end": "477479"
  },
  {
    "text": "and we can run all of this spin it up within 10 to 20 minutes so our uh Engineers can basically just uh test on",
    "start": "477479",
    "end": "485280"
  },
  {
    "text": "top of this Emeral cluster and if we can simulate the production clusters then",
    "start": "485280",
    "end": "490440"
  },
  {
    "text": "they basically can just test eally so the whole process will be you deploy a cluster for a couple minutes right say",
    "start": "490440",
    "end": "498400"
  },
  {
    "text": "and you run your test assuming everything okay you say having in a couple hours everything should be good",
    "start": "498400",
    "end": "504080"
  },
  {
    "text": "and even the worst case it may take one or two days for you to fix everything now the overall process of releasing to",
    "start": "504080",
    "end": "511520"
  },
  {
    "text": "the whole production can be reduced from weeks to months to just say days right so at most a couple weeks so it's",
    "start": "511520",
    "end": "519000"
  },
  {
    "text": "basically will be a large produ productivity increase that's why how we",
    "start": "519000",
    "end": "524720"
  },
  {
    "start": "523000",
    "end": "553000"
  },
  {
    "text": "introduce a Ground Hog Day the idea is we take a a snapshot of all the offline",
    "start": "524720",
    "end": "529800"
  },
  {
    "text": "St stack and then we bundle it and we allow our user to be specify their um",
    "start": "529800",
    "end": "535800"
  },
  {
    "text": "production um the production confli they want so that we can say take a snapshot",
    "start": "535800",
    "end": "540920"
  },
  {
    "text": "of all these clusters uh and run it on kuet so that they can run Tas so as you can see the name name come from the",
    "start": "540920",
    "end": "548040"
  },
  {
    "text": "movie gr hog day and what it means is we can run it over and over again so um as our uh user are mainly",
    "start": "548040",
    "end": "557880"
  },
  {
    "text": "the platform Engineers so the goal we wanted to make sure is we have SIMPLE ux",
    "start": "557880",
    "end": "563120"
  },
  {
    "text": "and we want the learning curve for our Engineers as low as possible and we want allow them to be able to integrate this",
    "start": "563120",
    "end": "569399"
  },
  {
    "text": "product everywhere they want so I want to show a demo on how the ground hook day works and I hope it",
    "start": "569399",
    "end": "578040"
  },
  {
    "start": "578000",
    "end": "654000"
  },
  {
    "text": "works and I hope the phone is not too small but if it's small I can show it",
    "start": "578839",
    "end": "584920"
  },
  {
    "text": "the one in the local it's good enough okay so basically it's taking ajacent",
    "start": "584920",
    "end": "590160"
  },
  {
    "text": "config as you can see and you can put some cluster level configs as well as some of the flow level conf as I",
    "start": "590160",
    "end": "596920"
  },
  {
    "text": "mentioned that LinkedIn supports three orchestrators ask and the Legacy ones L flow and flight so basically in the type",
    "start": "596920",
    "end": "603880"
  },
  {
    "text": "here you are able to put all of these things based on your need every um because every orchestrator the way it",
    "start": "603880",
    "end": "610440"
  },
  {
    "text": "defines a flow is different so you will need to put some of the flow level say config and metadata there so our system",
    "start": "610440",
    "end": "616480"
  },
  {
    "text": "can automatically create um the flows for you so in this example it's showing askam so you will need to Define what",
    "start": "616480",
    "end": "623399"
  },
  {
    "text": "they have a concept is a project and then flow if it's an air flow you will just have a Dack so um and then",
    "start": "623399",
    "end": "632519"
  },
  {
    "text": "say the demo just shows some and the zip file is actually where your test the",
    "start": "632519",
    "end": "638639"
  },
  {
    "text": "code for your test uh which we download directly from um the artifactory and um basically then it",
    "start": "638639",
    "end": "646160"
  },
  {
    "text": "will be used automatically to execute the the flows I'm going to fast forward a little bit so that we don't spend too",
    "start": "646160",
    "end": "652839"
  },
  {
    "text": "much time um so as I mentioned we want a simple ux so basically this thing is uh",
    "start": "652839",
    "end": "659000"
  },
  {
    "start": "654000",
    "end": "718000"
  },
  {
    "text": "we have a c uh C sorry CI uh to say execute our flow and in this example we",
    "start": "659000",
    "end": "665760"
  },
  {
    "text": "actually integrate um with our um pre-commit so the CI process and once I",
    "start": "665760",
    "end": "672200"
  },
  {
    "text": "want to mention one thing is this cluster ID here it's a uu ID um the",
    "start": "672200",
    "end": "677959"
  },
  {
    "text": "reason is at any time we have um many say Emeral clusters running our C",
    "start": "677959",
    "end": "683720"
  },
  {
    "text": "namespace and I we wanted to allow our users to be able to access their Epal cluster so we need a unique identifier",
    "start": "683720",
    "end": "691279"
  },
  {
    "text": "and in this one it shows that starts with h5u I'm going to show that in the ephemeral U orchestrator UI you will",
    "start": "691279",
    "end": "697639"
  },
  {
    "text": "also find this and then so this is basically saying that",
    "start": "697639",
    "end": "704519"
  },
  {
    "text": "all the flow has executed successfully so it's not showing clear",
    "start": "704519",
    "end": "711000"
  },
  {
    "text": "here but I'm going to show it later so the remaining say it will be say the same experience as you just run a flow",
    "start": "711000",
    "end": "719240"
  },
  {
    "start": "718000",
    "end": "768000"
  },
  {
    "text": "in a normal static cluster so in this one it's because it's using askaban so",
    "start": "719240",
    "end": "724959"
  },
  {
    "text": "you will see an askaban uh UI and as I mentioned that in the URL you will have",
    "start": "724959",
    "end": "730360"
  },
  {
    "text": "this uu ID identified and basically say um also so to allow our users to easily",
    "start": "730360",
    "end": "738160"
  },
  {
    "text": "use use this find this URL we basically already construct this in our log it's in the CI output so the user can",
    "start": "738160",
    "end": "744480"
  },
  {
    "text": "directly just click on it and it's also showing here this uu ID and so that you",
    "start": "744480",
    "end": "749760"
  },
  {
    "text": "when you actually logging on so consider your user and you have multiple um say",
    "start": "749760",
    "end": "755279"
  },
  {
    "text": "ephemeral cluster you know which one you want to find remaining things are just say uh",
    "start": "755279",
    "end": "761800"
  },
  {
    "text": "you need to log in as a normal user and the this is the same integration as for",
    "start": "761800",
    "end": "767199"
  },
  {
    "text": "a production cluster because we want to make sure that even when you're testing you actually ensure your the whole uh",
    "start": "767199",
    "end": "773199"
  },
  {
    "text": "security flow the authentication is working and all of these projects you define it in the fix and it's",
    "start": "773199",
    "end": "780079"
  },
  {
    "text": "automatically created and remaining thing is you have your flows in the project and",
    "start": "780079",
    "end": "789279"
  },
  {
    "text": "executions and then your dck and your flow logs which you can use for debug as",
    "start": "789279",
    "end": "796920"
  },
  {
    "text": "well as your job blocks so in addition to that sometimes uh not all the logs",
    "start": "796920",
    "end": "804000"
  },
  {
    "start": "799000",
    "end": "854000"
  },
  {
    "text": "you can find in orchestrator right so for example if you have a spark application uh it depends on where your",
    "start": "804000",
    "end": "810320"
  },
  {
    "text": "what your schedule is when we develop this we were still using Y so and I have",
    "start": "810320",
    "end": "815360"
  },
  {
    "text": "this say demo using Y so basically if user wants to um debug using um for it a",
    "start": "815360",
    "end": "821800"
  },
  {
    "text": "specific spark application you actually need to go to the Y resource manager in the UI and we also output this URL in",
    "start": "821800",
    "end": "829079"
  },
  {
    "text": "our log so user can just directly click and as you can see that say uh it's",
    "start": "829079",
    "end": "836720"
  },
  {
    "text": "basically the same experience as a static cluster so basically you click on that and you",
    "start": "836720",
    "end": "843199"
  },
  {
    "text": "can find your logs Okay cool so the next thing",
    "start": "843199",
    "end": "852399"
  },
  {
    "text": "is the result here so as I mentioned uh Groundhog Day we enable developer to be",
    "start": "853800",
    "end": "859600"
  },
  {
    "start": "854000",
    "end": "921000"
  },
  {
    "text": "able to provision um our dat data L house clusters on the Fly using Kates",
    "start": "859600",
    "end": "866199"
  },
  {
    "text": "and user can integrate anywhere uh spin up on a box or integrated with their CI command and we also allow user to be",
    "start": "866199",
    "end": "873759"
  },
  {
    "text": "able to customize the production uh environment in in their configs and now",
    "start": "873759",
    "end": "879040"
  },
  {
    "text": "and after we launch this product say we see our Compu team the CI success rate has increased from 68.1 to",
    "start": "879040",
    "end": "886199"
  },
  {
    "text": "81.7% and the storage team the CI success rate has increased from 76% to",
    "start": "886199",
    "end": "893079"
  },
  {
    "text": "87.5% uh scale here I mentioned we run 20K so the real data is we run 23.5k",
    "start": "893079",
    "end": "899040"
  },
  {
    "text": "feral clusters every year and 500 K flows and now since we launched it last",
    "start": "899040",
    "end": "904560"
  },
  {
    "text": "year we have captured 2.1k to more than 2,000 flow failures in",
    "start": "904560",
    "end": "910839"
  },
  {
    "text": "pre-commit what it means is um 2,000 um bugs and production issues have been",
    "start": "910839",
    "end": "916519"
  },
  {
    "text": "captured before the code is even released into any of the cluster architecture here we are in a",
    "start": "916519",
    "end": "923320"
  },
  {
    "text": "cpcom so you can assume that everything is deployed using cnes so both the uh",
    "start": "923320",
    "end": "929000"
  },
  {
    "text": "control plan and the data plan in our cluster in our kuet sorry in our groundhog dat clusters are deployed",
    "start": "929000",
    "end": "934959"
  },
  {
    "text": "using um kubernetes and internally the control plan contains two service",
    "start": "934959",
    "end": "940680"
  },
  {
    "text": "orchestration service and the history service so the name the responsibility is as the name suggest is orchestration",
    "start": "940680",
    "end": "947399"
  },
  {
    "text": "service is talk to the kuet uh API to spin up this eal clusters history",
    "start": "947399",
    "end": "952440"
  },
  {
    "text": "service and it includes all the metadata for every of the executions so user can just debug inspect all replay their",
    "start": "952440",
    "end": "959880"
  },
  {
    "text": "executions now I want to talk a little bit about how we are able to say mimic the production environment so uh the way",
    "start": "959880",
    "end": "966759"
  },
  {
    "text": "we do it is we actually integrate with our Central release system it's a source of a truth for all the versions deployed",
    "start": "966759",
    "end": "973000"
  },
  {
    "text": "in all the environment so basically is whenever user uh specify the environment they want to put it's a Edom we will",
    "start": "973000",
    "end": "979240"
  },
  {
    "text": "just talk to our Central release system and they'll give us a list of say the services and the versions they deploy in",
    "start": "979240",
    "end": "984759"
  },
  {
    "text": "their environment so what we do is we're going to um override uh in our user specified hem chart so that they know",
    "start": "984759",
    "end": "992079"
  },
  {
    "text": "when Kuman is spin up the cluster and know said okay this is the right image I need to download and spin spin up um the",
    "start": "992079",
    "end": "999399"
  },
  {
    "text": "data plan contains a group of say kuber resources which are used to say create this flows I showed it before as well as",
    "start": "999399",
    "end": "1006199"
  },
  {
    "text": "to um execute the executions and user are are able to access their ephemeral",
    "start": "1006199",
    "end": "1012440"
  },
  {
    "text": "clusters through an edge proxy which I actually showed a URI before and uh if users want to log on to a specific",
    "start": "1012440",
    "end": "1019639"
  },
  {
    "text": "container uh they can just use the normal say way like port",
    "start": "1019639",
    "end": "1024959"
  },
  {
    "start": "1025000",
    "end": "1090000"
  },
  {
    "text": "forward um after we launch this first thing we wanted to ensure is we wanted to keep this platform as stable as",
    "start": "1025319",
    "end": "1032240"
  },
  {
    "text": "possible so the first thing you do is metrix now uh as we inspect our Matrix",
    "start": "1032240",
    "end": "1037798"
  },
  {
    "text": "in our Emeral clusters we notice our Matrix are either sparse or has no data it's basically show as this it doesn't",
    "start": "1037799",
    "end": "1044240"
  },
  {
    "text": "work right so we started to debug a little bit and we notice that the reason",
    "start": "1044240",
    "end": "1049480"
  },
  {
    "text": "was because uh in LinkedIn the matrics were actually not multi-dimensional what it means is consider you have a simple",
    "start": "1049480",
    "end": "1056120"
  },
  {
    "text": "rest service and you emit say status code right so the number of status you emit for example you have four and it",
    "start": "1056120",
    "end": "1062200"
  },
  {
    "text": "will become say four single graphs so it's not ideal but it's still workable for um the rest of services because in",
    "start": "1062200",
    "end": "1069400"
  },
  {
    "text": "the end you have finite number of say status codes but it doesn't work for all a FAL case um because they all a FAL",
    "start": "1069400",
    "end": "1075840"
  },
  {
    "text": "classes come and go and everything's been up is different so we definitely need to solve this problem and as every",
    "start": "1075840",
    "end": "1081880"
  },
  {
    "text": "our every KU service the first thing we need to we think about is we want to integrate with the premisus SDK and how",
    "start": "1081880",
    "end": "1088640"
  },
  {
    "text": "do we do it is like everyone else we're thinking about using open tary and we do",
    "start": "1088640",
    "end": "1094640"
  },
  {
    "start": "1090000",
    "end": "1165000"
  },
  {
    "text": "this by uh expose different um client to our users uh if they want to use this",
    "start": "1094640",
    "end": "1100880"
  },
  {
    "text": "tool and basically is for us we are using the premesis SDK and we also have",
    "start": "1100880",
    "end": "1106440"
  },
  {
    "text": "the status D client open because we want to keep back work compatible in case they wanted to say continue using our um",
    "start": "1106440",
    "end": "1113280"
  },
  {
    "text": "LinkedIn provided internal matric service so every host there will be an Hotel agent and we expose the uh one",
    "start": "1113280",
    "end": "1120080"
  },
  {
    "text": "single protocol the olp protocol uh on the Matrix collector side so uh for",
    "start": "1120080",
    "end": "1125600"
  },
  {
    "text": "ourselves we use the otel Gateway it's also open source so that we can have a nice UI the grafana UI and we can also",
    "start": "1125600",
    "end": "1131320"
  },
  {
    "text": "integrate with M MDM which is a Microsoft developed the uh Matrix Service and um as you can and ALS",
    "start": "1131320",
    "end": "1138919"
  },
  {
    "text": "cooster event as you can imagine LinkedIn is also a Microsoft company so we try to say adopt our own things as",
    "start": "1138919",
    "end": "1144919"
  },
  {
    "text": "much as possible and on the other hand we also actually get a for of the open",
    "start": "1144919",
    "end": "1150400"
  },
  {
    "text": "Terry so that we can uh do some improvement and we can say inest the",
    "start": "1150400",
    "end": "1155799"
  },
  {
    "text": "data inest The Matrix to our um conventional Matrix Matrix system which is called in graph as show in the first",
    "start": "1155799",
    "end": "1162240"
  },
  {
    "text": "say on screenshot before now after we release this and for ourself we",
    "start": "1162240",
    "end": "1168840"
  },
  {
    "start": "1165000",
    "end": "1221000"
  },
  {
    "text": "definitely see a very nice graph and not only for the operational Matrix we also enable business Matrix in our the same",
    "start": "1168840",
    "end": "1176000"
  },
  {
    "text": "grafana dashboard and business metrics are actually very important for myself",
    "start": "1176000",
    "end": "1181520"
  },
  {
    "text": "because as a manager you want to showcase the impact uh operational matric are good for our on course we",
    "start": "1181520",
    "end": "1186880"
  },
  {
    "text": "have we can have alert and metric to inspect uh not only that uh these two",
    "start": "1186880",
    "end": "1192200"
  },
  {
    "text": "actually have been uh adopted by every service who either in LinkedIn who either wanted to say put from an open",
    "start": "1192200",
    "end": "1199400"
  },
  {
    "text": "source or try to say on open source themselves for example the open source uh soorry open housee service I",
    "start": "1199400",
    "end": "1205360"
  },
  {
    "text": "mentioned before uh build on top of the uh apach Iceberg So eventually uh we",
    "start": "1205360",
    "end": "1210960"
  },
  {
    "text": "work with the monitoring infer team on in LinkedIn and we hand off this tool so and they are developing on top of it now",
    "start": "1210960",
    "end": "1216880"
  },
  {
    "text": "it's become a general to in LinkedIn for all the K use cases is Matrix enough right so um",
    "start": "1216880",
    "end": "1224840"
  },
  {
    "start": "1221000",
    "end": "1290000"
  },
  {
    "text": "Matrix help you to dedu but does it help you to actually debug your issues and this is this say screenshot or the",
    "start": "1224840",
    "end": "1232280"
  },
  {
    "text": "slack message is our user who reach out to us they like say hey our integration task has failed how do I debug right so",
    "start": "1232280",
    "end": "1239120"
  },
  {
    "text": "if you run task you know integration task it's good because it help you to test all the compatibility among your",
    "start": "1239120",
    "end": "1245480"
  },
  {
    "text": "dependencies but it doesn't help you sometimes it's hard for you to debu you don't know whether it's your code issue",
    "start": "1245480",
    "end": "1250799"
  },
  {
    "text": "or your dependency issue or it's an infrastructure issu so you want to find a way to quickly debug another thing is",
    "start": "1250799",
    "end": "1257080"
  },
  {
    "text": "from our engineer our call perspective is if say you have uh Whenever there is",
    "start": "1257080",
    "end": "1262679"
  },
  {
    "text": "an issue you're are blocking uh every say user CI so we need to quickly detect",
    "start": "1262679",
    "end": "1267840"
  },
  {
    "text": "actually not just detect debug this issue if it's our problem we need to fix that ourself it's it's if it's our um",
    "start": "1267840",
    "end": "1274320"
  },
  {
    "text": "component problem like for example if it's spark or hdfs because they release something bad we need to work with them",
    "start": "1274320",
    "end": "1280320"
  },
  {
    "text": "to say solve this problem ASAP now so we definitely need to improve our debug",
    "start": "1280320",
    "end": "1286039"
  },
  {
    "text": "experience so that we can quickly um debug the issue and we are and to we",
    "start": "1286039",
    "end": "1292200"
  },
  {
    "start": "1290000",
    "end": "1361000"
  },
  {
    "text": "took some um kind of inspiration from an open source tool called assas so",
    "start": "1292200",
    "end": "1297279"
  },
  {
    "text": "basically this tool allows you to use a yo config and on top of it so you can",
    "start": "1297279",
    "end": "1303520"
  },
  {
    "text": "just change the jvm say you can change the um the debug the log level and also",
    "start": "1303520",
    "end": "1311039"
  },
  {
    "text": "expose the stack Trace at the jvm level uh this to actually works with us quite well because uh most of our services",
    "start": "1311039",
    "end": "1317720"
  },
  {
    "text": "deploy as you can system they are actually using on the uh",
    "start": "1317720",
    "end": "1323120"
  },
  {
    "text": "jvm services so we did we did it by say first say we just use the plan to",
    "start": "1323120",
    "end": "1329520"
  },
  {
    "text": "ourselves and we using our uncle and we actually find it's pretty useful because our debug experience is much faster uh",
    "start": "1329520",
    "end": "1336440"
  },
  {
    "text": "after we did it for ourself we um basically want to expose to our users so what we do is we integrate with our",
    "start": "1336440",
    "end": "1342960"
  },
  {
    "text": "ground hook day CLI and then say we expose this thing so that user can debug",
    "start": "1342960",
    "end": "1348000"
  },
  {
    "text": "now after we uh launch this thing we actually say get a pretty good feedback from our users and also our our own on",
    "start": "1348000",
    "end": "1355679"
  },
  {
    "text": "call ex experience has been say improved a",
    "start": "1355679",
    "end": "1361120"
  },
  {
    "start": "1361000",
    "end": "1557000"
  },
  {
    "text": "lot um so takeaways right so what is Groundhog Day Groundhog Day it's an",
    "start": "1361120",
    "end": "1366600"
  },
  {
    "text": "infal dat lak house hosted entirely on kubernetes and we this product actually",
    "start": "1366600",
    "end": "1372039"
  },
  {
    "text": "helped our platform Engineers improved our um de productivity um by increasing",
    "start": "1372039",
    "end": "1378240"
  },
  {
    "text": "in enable them to say having a f faster iteration so along the way uh we also say made some foundational uh efforts",
    "start": "1378240",
    "end": "1386039"
  },
  {
    "text": "across the LinkedIn on observability so we also improve the debuggability by introduce the um the",
    "start": "1386039",
    "end": "1392120"
  },
  {
    "text": "OAS to into LinkedIn and with that we believe that we can keep up with the pace of our ml Innovations is driving",
    "start": "1392120",
    "end": "1399400"
  },
  {
    "text": "now this thing actually is not uh all shiny and bright so it Tes actually takes us two years to made uh",
    "start": "1399400",
    "end": "1406520"
  },
  {
    "text": "fundamentally uh the reason was because um it's a horizontal problem it's an intersection among everything um in in",
    "start": "1406520",
    "end": "1415200"
  },
  {
    "text": "the offline stack right so and sometimes it's really hard to actually set the ownership right that's one thing um",
    "start": "1415200",
    "end": "1422159"
  },
  {
    "text": "because it's a big company and you need to actually negotiate around with different teams to make sure they agree on to um say taking the enle on board to",
    "start": "1422159",
    "end": "1430200"
  },
  {
    "text": "your product and maintain this this platform now two lessons we learned",
    "start": "1430200",
    "end": "1435240"
  },
  {
    "text": "first thing is devops is increasingly important so in LinkedIn because it's a",
    "start": "1435240",
    "end": "1440559"
  },
  {
    "text": "such large company initially we actually have a clean separation among say devs",
    "start": "1440559",
    "end": "1446080"
  },
  {
    "text": "and srees and since last year we are starting to transition uh from this",
    "start": "1446080",
    "end": "1451200"
  },
  {
    "text": "model to everyone needs to be devops what it means is regardless your title you will need to write your code and you",
    "start": "1451200",
    "end": "1456559"
  },
  {
    "text": "need to deploy your code and uh monitoring your deployment and also your",
    "start": "1456559",
    "end": "1461960"
  },
  {
    "text": "product so um it actually takes our developers um previously they only",
    "start": "1461960",
    "end": "1467559"
  },
  {
    "text": "responsible for for uh writing a code and test um they need to change their experience and they need to learn all of",
    "start": "1467559",
    "end": "1473520"
  },
  {
    "text": "these tool that they were not used to ham chart terraform and c and the coup",
    "start": "1473520",
    "end": "1479159"
  },
  {
    "text": "cuddle command all of these things they need to learn so it's taking them some of the ramp say time um to say get used",
    "start": "1479159",
    "end": "1485919"
  },
  {
    "text": "to it another thing is the most important part for the whole tool is it needs to be able to uh reproduce the",
    "start": "1485919",
    "end": "1493480"
  },
  {
    "text": "production environment so basically you need to version everything it sounds very easy especially for everyone here",
    "start": "1493480",
    "end": "1498880"
  },
  {
    "text": "your Cloud native it's very easy to you but I mean as LinkedIn is just doing this transition it's a little bit it's",
    "start": "1498880",
    "end": "1505240"
  },
  {
    "text": "also taking some time for folks to ramp up so initially for our sres when they",
    "start": "1505240",
    "end": "1510760"
  },
  {
    "text": "deploy so even now if you look at some of the documentation on Hado system you",
    "start": "1510760",
    "end": "1516840"
  },
  {
    "text": "will see that deployment dog it will say that hey you build your RPM you download on your host and you restart your",
    "start": "1516840",
    "end": "1522880"
  },
  {
    "text": "service it's not a model anymore In This Cloud native world so you need to say um",
    "start": "1522880",
    "end": "1527960"
  },
  {
    "text": "building image for your code you need to say uh Mount Your conf you need to say",
    "start": "1527960",
    "end": "1533360"
  },
  {
    "text": "uh use ham chart for your deployments and you need to checking everything right so and this actually took our sres",
    "start": "1533360",
    "end": "1540840"
  },
  {
    "text": "a while to say get used to all of this model and in the beginning because they don't remember to say checking",
    "start": "1540840",
    "end": "1546320"
  },
  {
    "text": "everything we actually not able to say fully U getting this say production environment mimic so that's why the",
    "start": "1546320",
    "end": "1552960"
  },
  {
    "text": "hosting actually takes a little bit than we expected um so last L uh what do we want",
    "start": "1552960",
    "end": "1559720"
  },
  {
    "start": "1557000",
    "end": "1770000"
  },
  {
    "text": "to do next we definitely want to improve the efficiency and what I mean by that is we should be able to uh spinning up",
    "start": "1559720",
    "end": "1566799"
  },
  {
    "text": "the whole cluster within five minutes and that's why so there are two parts uh",
    "start": "1566799",
    "end": "1572080"
  },
  {
    "text": "one thing is we wanted to say why do we say that data is important right so we",
    "start": "1572080",
    "end": "1577360"
  },
  {
    "text": "believe that data should be continue to be a central in this AI Centric world uh",
    "start": "1577360",
    "end": "1584440"
  },
  {
    "text": "I'm actually coding a um blog from uh James he's a research engineer in open",
    "start": "1584440",
    "end": "1590360"
  },
  {
    "text": "Ai and he actually have a very interesting blog so I find myself very intuitive so if you're interested you",
    "start": "1590360",
    "end": "1595799"
  },
  {
    "text": "can just check out my understanding on that is basically um data the key part",
    "start": "1595799",
    "end": "1602799"
  },
  {
    "text": "of all this AI Innovation is that data so think about this even now um a lot of",
    "start": "1602799",
    "end": "1608600"
  },
  {
    "text": "say big init uh institutions and even so for ourselves we are say just use some a",
    "start": "1608600",
    "end": "1614360"
  },
  {
    "text": "pre-trained model big models and then we apply our data and then get the result we want right some of the data set which",
    "start": "1614360",
    "end": "1620919"
  },
  {
    "text": "I actually was watching a show this morning is you can just train on your local laptop right this is this will be",
    "start": "1620919",
    "end": "1626600"
  },
  {
    "text": "trained but the data pre-processing the computer this is the part you continuously needs to be investing and",
    "start": "1626600",
    "end": "1632440"
  },
  {
    "text": "we need to ensure that our platform engineer can actually uh have a fast iteration on all of this next thing is",
    "start": "1632440",
    "end": "1639320"
  },
  {
    "text": "why do we say five minutes this is actually from our customer feedback so 30 minutes is basically not usable it's",
    "start": "1639320",
    "end": "1645720"
  },
  {
    "text": "too long right 10 to 20 minutes most of the are willing to use it in their pre-commit um they're willing to wait",
    "start": "1645720",
    "end": "1651480"
  },
  {
    "text": "this amount of time and to say hey um before my co- checking just do a sanity check right only if say we can make it",
    "start": "1651480",
    "end": "1658520"
  },
  {
    "text": "in five minutes they willing to use it more often in their development basically as you spin up something you do some experiment in your code you tear",
    "start": "1658520",
    "end": "1665519"
  },
  {
    "text": "it on you do more development and then you spin it again how do we do this so two ways one thing is uh you wanted to",
    "start": "1665519",
    "end": "1672720"
  },
  {
    "text": "cash as much as possible everything should be in local as much as possible except for the necessary",
    "start": "1672720",
    "end": "1678960"
  },
  {
    "text": "uh you want to patch the necessary diff and also say upload the necessary jars",
    "start": "1678960",
    "end": "1684720"
  },
  {
    "text": "right but remaining things your images needs to be local and everything SLE dependency needs local it just needs to",
    "start": "1684720",
    "end": "1689960"
  },
  {
    "text": "be spin up instead of you download from a remote say image uh registry another",
    "start": "1689960",
    "end": "1695080"
  },
  {
    "text": "thing is we want to expose a way for our user to be able to uh basically just",
    "start": "1695080",
    "end": "1700760"
  },
  {
    "text": "selectively spinning up certain component so think about it if you're a spark engineer you probably don't care",
    "start": "1700760",
    "end": "1706880"
  },
  {
    "text": "if you're uh in your eeral cluster you have a trino or or Flank In Your stack right you just",
    "start": "1706880",
    "end": "1714600"
  },
  {
    "text": "need your orchestrator uh in our case we also need some reshuffle service but",
    "start": "1714600",
    "end": "1719760"
  },
  {
    "text": "mainly is you don't need all of this other computer engine in your cluster you need some of the storage so that you",
    "start": "1719760",
    "end": "1725000"
  },
  {
    "text": "can import the data in uh that's it right so if by allowing our user to be able to uh construct uh to selectively",
    "start": "1725000",
    "end": "1733320"
  },
  {
    "text": "say uh choose a component they want to spin up we can just reduce this overhead of spinning up different um parts and",
    "start": "1733320",
    "end": "1739919"
  },
  {
    "text": "different say spin up the services so um with that uh I actually",
    "start": "1739919",
    "end": "1745320"
  },
  {
    "text": "say concluded my talk and I think we have enough time for",
    "start": "1745320",
    "end": "1751720"
  },
  {
    "text": "[Applause]",
    "start": "1752460",
    "end": "1758519"
  },
  {
    "text": "Q&A um need a map just one",
    "start": "1758519",
    "end": "1764480"
  },
  {
    "text": "working you hear me well yeah um but one quick",
    "start": "1767039",
    "end": "1773559"
  },
  {
    "start": "1770000",
    "end": "1905000"
  },
  {
    "text": "question when you say you um you duplicate anything everything with snapshots to uh to get your stack up and",
    "start": "1773559",
    "end": "1781039"
  },
  {
    "text": "running in 25 minutes uh I understood that it is about all the versions of",
    "start": "1781039",
    "end": "1786360"
  },
  {
    "text": "your containers that are snapchot and and redeployed automatically what about the data because uh most of the time the",
    "start": "1786360",
    "end": "1793279"
  },
  {
    "text": "problem is to initiate with the the accurate data similar to what is in",
    "start": "1793279",
    "end": "1798720"
  },
  {
    "text": "production yes so uh to repeat the question is um how do we say get the",
    "start": "1798720",
    "end": "1803799"
  },
  {
    "text": "data in for on our users to run the end to end test and sometimes the um act",
    "start": "1803799",
    "end": "1809480"
  },
  {
    "text": "accuracy is depending on data so there are two ways for users to be able to do so if say mostly the user will just",
    "start": "1809480",
    "end": "1815840"
  },
  {
    "text": "choose to say we and import some data from our staging cluster and the reason",
    "start": "1815840",
    "end": "1822039"
  },
  {
    "text": "is say in the production cluster there are some Pi data basically people related data we cannot say from security",
    "start": "1822039",
    "end": "1827640"
  },
  {
    "text": "perspective I we cannot just import so we do have some uh obsc data that from",
    "start": "1827640",
    "end": "1834480"
  },
  {
    "text": "our staging cluster for the production from the production so we can import of course because it's a FAL cluster you",
    "start": "1834480",
    "end": "1840720"
  },
  {
    "text": "cannot say and have say um basically infinite amount of storage so we don't",
    "start": "1840720",
    "end": "1846880"
  },
  {
    "text": "expect the users to say import a lot of data it will just couple at most I think 100 megabytes data and because it's",
    "start": "1846880",
    "end": "1854080"
  },
  {
    "text": "running the CI so mostly is it will still for a fun functional testing and",
    "start": "1854080",
    "end": "1860039"
  },
  {
    "text": "we do have another say pre-o cluster which is running some of the flows for um preo they have some production data",
    "start": "1860039",
    "end": "1867000"
  },
  {
    "text": "and they they pass the security say uh requirement to be able to run this as a as the end sanity check before they we",
    "start": "1867000",
    "end": "1873480"
  },
  {
    "text": "fully Rel release their to production um does that answer your question sure thank",
    "start": "1873480",
    "end": "1881000"
  },
  {
    "text": "you",
    "start": "1886919",
    "end": "1889919"
  },
  {
    "text": "cool if no question thank you for having me today enjoy the rest of your um",
    "start": "1896279",
    "end": "1903840"
  },
  {
    "text": "conference",
    "start": "1904440",
    "end": "1907440"
  }
]
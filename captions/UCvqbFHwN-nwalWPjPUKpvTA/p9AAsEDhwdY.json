[
  {
    "text": "you you",
    "start": "155200",
    "end": "162020"
  },
  {
    "text": "you",
    "start": "163390",
    "end": "165450"
  },
  {
    "text": "you",
    "start": "178860",
    "end": "180920"
  },
  {
    "text": "you you",
    "start": "197220",
    "end": "201540"
  },
  {
    "text": "you",
    "start": "203180",
    "end": "205239"
  },
  {
    "text": "you",
    "start": "216180",
    "end": "218239"
  },
  {
    "text": "hello hello hello",
    "start": "342460",
    "end": "348340"
  },
  {
    "text": "we have only six people so let's do it like this we give people a few more",
    "start": "359500",
    "end": "366169"
  },
  {
    "text": "minutes to join but when we start we tell them next time we will start at one time and then we actually start our",
    "start": "366169",
    "end": "372289"
  },
  {
    "text": "course I'm honestly somewhat tired of always waiting we only have 50 minutes",
    "start": "372289",
    "end": "379669"
  },
  {
    "text": "anyway if we always wait five minutes we're basically at 45 minutes and all of",
    "start": "379669",
    "end": "386509"
  },
  {
    "text": "this way too interesting so your hair started yes actually I kept I kept the",
    "start": "386509",
    "end": "400250"
  },
  {
    "text": "Mohawk at the connors longer and buying it the second time in two different colors was also not planned coinciding",
    "start": "400250",
    "end": "408889"
  },
  {
    "text": "with the lockdown ending in in Germany or being lessened too and it's super",
    "start": "408889",
    "end": "427969"
  },
  {
    "text": "interesting for anyone who like all of the people almost called have hair so you all don't know this and I didn't",
    "start": "427969",
    "end": "433129"
  },
  {
    "text": "know either your ears get so cold",
    "start": "433129",
    "end": "439310"
  },
  {
    "text": "because all of the wind which is all of a sudden not catching in your hair it's absolutely fascinating and your head",
    "start": "439310",
    "end": "445879"
  },
  {
    "text": "gets hot in random bits and pieces and spots course your head is trying to to",
    "start": "445879",
    "end": "452419"
  },
  {
    "text": "heat the brain and what have you die of cold which is all irrelevant but I'm",
    "start": "452419",
    "end": "457789"
  },
  {
    "text": "trying to fill those two minutes until the five after and then we start and then going forward and I'll also send",
    "start": "457789",
    "end": "463400"
  },
  {
    "text": "email actually it may take an actual item on this one we will simply start",
    "start": "463400",
    "end": "468529"
  },
  {
    "text": "and not wait on people",
    "start": "468529",
    "end": "471520"
  },
  {
    "text": "and looking through been looking through mail and things of I'm back from vacation now for two whole weeks so i",
    "start": "483570",
    "end": "489670"
  },
  {
    "text": "i've excavated my inbox down took before before i left it it seems we still",
    "start": "489670",
    "end": "495220"
  },
  {
    "text": "haven't heard back from the toc we did order on the agenda did you hear",
    "start": "495220",
    "end": "500230"
  },
  {
    "text": "anything well the thing which i heard so okay it's far after so let's start so",
    "start": "500230",
    "end": "507730"
  },
  {
    "text": "first things first next time we will start precisely on time and i have sent this out for for future meetings too so",
    "start": "507730",
    "end": "516690"
  },
  {
    "text": "update on on the toc there was this toc",
    "start": "516690",
    "end": "522520"
  },
  {
    "text": "sick call last week and we have a sponsor for for both panels and cortex",
    "start": "522520",
    "end": "530950"
  },
  {
    "text": "incubation she is called katie c'mon gee",
    "start": "530950",
    "end": "536770"
  },
  {
    "text": "I hope I pronounced it correctly and she took both of those two judgement items",
    "start": "536770",
    "end": "542670"
  },
  {
    "text": "for TOC I poked her today and didn't get",
    "start": "542670",
    "end": "548230"
  },
  {
    "text": "any update yet on what she thinks about you diligence documents but I don't also",
    "start": "548230",
    "end": "555790"
  },
  {
    "text": "don't have any kind of an or anything so for now we just wait and see what happens yeah but we have a QC person who is",
    "start": "555790",
    "end": "565540"
  },
  {
    "text": "looking at both cortex and which is already a lot more than we had a week",
    "start": "565540",
    "end": "570730"
  },
  {
    "text": "ago so that's nice",
    "start": "570730",
    "end": "573779"
  },
  {
    "text": "so this was this and the other thing is the open source analytic platform thing",
    "start": "576020",
    "end": "585140"
  },
  {
    "text": "partic do you want to start yes really I can essentially give some quick he'll",
    "start": "585140",
    "end": "592080"
  },
  {
    "text": "hear me yes I can give some quick update",
    "start": "592080",
    "end": "597300"
  },
  {
    "text": "update what was done from the last meeting because and the very end of the",
    "start": "597300",
    "end": "603540"
  },
  {
    "text": "last meeting two weeks ago we started this topic and I actually kind of announced that we are definitely looking",
    "start": "603540",
    "end": "610380"
  },
  {
    "text": "at as as kind of prom to use community and kind of announced what are the",
    "start": "610380",
    "end": "617570"
  },
  {
    "text": "communication channels and what we want to achieve let me write write essentially if you click on this link",
    "start": "617570",
    "end": "623310"
  },
  {
    "text": "there is an email thread and also kind of github issue where everyone is",
    "start": "623310",
    "end": "628380"
  },
  {
    "text": "welcome to give feedback on what analytic system you are using and kind",
    "start": "628380",
    "end": "633750"
  },
  {
    "text": "of to be honest analytic space using different signals to be honest not only",
    "start": "633750",
    "end": "641960"
  },
  {
    "text": "observability but attack signals from from any data data source and what we",
    "start": "641960",
    "end": "647190"
  },
  {
    "text": "want to achieve here is to kind of integrate better than the monitoring",
    "start": "647190",
    "end": "652350"
  },
  {
    "text": "world where especially as part of the kind of Proteus project we want to give",
    "start": "652350",
    "end": "658920"
  },
  {
    "text": "more ways of using those monitoring data for example metrics in analytic use",
    "start": "658920",
    "end": "665130"
  },
  {
    "text": "cases right and so we are looking for four kind of voice of the community on",
    "start": "665130",
    "end": "671340"
  },
  {
    "text": "what systems and one ap what ap is are the most needed and what would kind of",
    "start": "671340",
    "end": "677490"
  },
  {
    "text": "solve the most use cases and so we are super happy to kind of create those",
    "start": "677490",
    "end": "683190"
  },
  {
    "text": "api's as maintainers but we need to have some kind of feedback who were to go",
    "start": "683190",
    "end": "688440"
  },
  {
    "text": "because you know we are not experts on this field so this is the topic that we",
    "start": "688440",
    "end": "693540"
  },
  {
    "text": "want to kind of move forward a move on so that two weeks ago we agreed that sick observability is definitely a good",
    "start": "693540",
    "end": "701790"
  },
  {
    "text": "spot for discussing those things because well there was no better sake related to this topic",
    "start": "701790",
    "end": "707910"
  },
  {
    "text": "furthermore we are touching observability data which in those days we are you know kind of retrieving and",
    "start": "707910",
    "end": "714930"
  },
  {
    "text": "gathering for long-term times like you know years and and amounts of the data so we want to make use of it so I guess",
    "start": "714930",
    "end": "723660"
  },
  {
    "text": "we'll be having some conversation in those in those meetings and on our",
    "start": "723660",
    "end": "728670"
  },
  {
    "text": "communication channels so I would I would love you to speak up even now if",
    "start": "728670",
    "end": "734250"
  },
  {
    "text": "you have any feedback so there will be time for that I would also maybe give",
    "start": "734250",
    "end": "741930"
  },
  {
    "text": "some status what happened outside of the our meetings very quickly first of all we have prompted from a huge community",
    "start": "741930",
    "end": "748529"
  },
  {
    "text": "meeting where we touch this very topic I will kind of copy that link in where you",
    "start": "748529",
    "end": "756720"
  },
  {
    "text": "can find the video and so you can watch it fully but essentially as part of this",
    "start": "756720",
    "end": "761940"
  },
  {
    "text": "meeting we talked about this very topic",
    "start": "761940",
    "end": "768199"
  },
  {
    "text": "it's kind of in a tweet but it's available and we spent some time and",
    "start": "768680",
    "end": "775500"
  },
  {
    "text": "what we had here in this in this meeting we had like Rob from n 3 dB so kind of",
    "start": "775500",
    "end": "782250"
  },
  {
    "text": "long-term storage matrix system they shared what they are looking for in",
    "start": "782250",
    "end": "789420"
  },
  {
    "text": "terms of kind of spiking this topic how to integrate data metrics with analytic system and he mentioned that they are",
    "start": "789420",
    "end": "797519"
  },
  {
    "text": "planning to address some kind of spark integration and presto so this is very",
    "start": "797519",
    "end": "803370"
  },
  {
    "text": "kind of specific things that we can already try to integrate with so you're welcome to check this video and to kind",
    "start": "803370",
    "end": "810449"
  },
  {
    "text": "of know the details and and we also have lots of feedback on the kind of github",
    "start": "810449",
    "end": "817709"
  },
  {
    "text": "issue I try to summarize this topic here briefly so you can kind of check this",
    "start": "817709",
    "end": "824430"
  },
  {
    "text": "out it's like a summary of what we know so far what projects were mentioned and you know how they how we can kind of",
    "start": "824430",
    "end": "833880"
  },
  {
    "text": "solve it solve integration from metrics to those to those",
    "start": "833880",
    "end": "839149"
  },
  {
    "text": "projects there you know apart from spark and presto quick house once mentioned",
    "start": "839149",
    "end": "845329"
  },
  {
    "text": "druid all sorts of timescale db2 also sort of systems and and we were looking for them",
    "start": "845329",
    "end": "851870"
  },
  {
    "text": "for the direction that will be you know the most useful for for the community on top of that one more thing awesome who I",
    "start": "851870",
    "end": "859790"
  },
  {
    "text": "think is this on the skull was super active and and and we found you know a",
    "start": "859790",
    "end": "865339"
  },
  {
    "text": "couple of cool maybe not very popular project that are already integrating prometheus and storage format and and",
    "start": "865339",
    "end": "874759"
  },
  {
    "text": "and kind of couple it with I think some kind of analytic API that you can",
    "start": "874759",
    "end": "880999"
  },
  {
    "text": "connect with spark and Osun do you want to maybe give some quick deal dr summary",
    "start": "880999",
    "end": "886370"
  },
  {
    "text": "of what's the lightest of of your findings hello do you hear me",
    "start": "886370",
    "end": "896149"
  },
  {
    "text": "yes perfectly yes I am recently a little",
    "start": "896149",
    "end": "904850"
  },
  {
    "text": "bit in a research mode about the topic and focused of matrix maybe doing the",
    "start": "904850",
    "end": "920540"
  },
  {
    "text": "learning in that matrix data but meet",
    "start": "920540",
    "end": "926600"
  },
  {
    "text": "every common using ml algorithms are in general in Python there's lots of",
    "start": "926600",
    "end": "934220"
  },
  {
    "text": "frameworks and we planning to use spark jobs on our site because of the ABA",
    "start": "934220",
    "end": "943730"
  },
  {
    "text": "analytic team has a beauty and they are currently using them if we can reuse",
    "start": "943730",
    "end": "951499"
  },
  {
    "text": "that this platform it will be very good so I focus to them spark integrations",
    "start": "951499",
    "end": "962679"
  },
  {
    "text": "uses some kind of internal Java and also",
    "start": "962679",
    "end": "969290"
  },
  {
    "text": "scholar internals of the library still connected and there",
    "start": "969290",
    "end": "978860"
  },
  {
    "text": "should be a extra effort to maintain every each scholar and spark release",
    "start": "978860",
    "end": "985839"
  },
  {
    "text": "some elasticsearch cassandra coach place drivers are common in this sense i can",
    "start": "985839",
    "end": "994580"
  },
  {
    "text": "say but a little dream or a very crazy",
    "start": "994580",
    "end": "1002920"
  },
  {
    "text": "idea but I see lots of every fight on a",
    "start": "1002920",
    "end": "1009339"
  },
  {
    "text": "Manticore you you",
    "start": "1009339",
    "end": "1015779"
  },
  {
    "text": "I think we lost along yeah seems like",
    "start": "1021720",
    "end": "1030050"
  },
  {
    "text": "that's but you know in the meantime once",
    "start": "1030050",
    "end": "1039660"
  },
  {
    "text": "his back like like that yeah yeah we",
    "start": "1039660",
    "end": "1047339"
  },
  {
    "text": "lost your last minute oh oh",
    "start": "1047340",
    "end": "1050929"
  },
  {
    "text": "yeah we can't hear him so while we wait",
    "start": "1068049",
    "end": "1076789"
  },
  {
    "text": "for him to return would it be useful for us to sort of brainstorm a list of",
    "start": "1076789",
    "end": "1082340"
  },
  {
    "text": "scenarios that would be enabled by having these systems I don't want to",
    "start": "1082340",
    "end": "1089059"
  },
  {
    "text": "lead any witnesses so well oh I'll speak last or later but this is an active",
    "start": "1089059",
    "end": "1094279"
  },
  {
    "text": "topic for at least my day job and we have we have exactly this squarely in",
    "start": "1094279",
    "end": "1100039"
  },
  {
    "text": "our sights for a variety of scenarios but we don't already have that curated",
    "start": "1100039",
    "end": "1107299"
  },
  {
    "text": "yet no wrong answer is just brainstorming starting place that might be worth a couple minutes what do you",
    "start": "1107299",
    "end": "1114649"
  },
  {
    "text": "offer",
    "start": "1114649",
    "end": "1116799"
  },
  {
    "text": "definitely so in this kind of issue I kind of we can gather the use cases",
    "start": "1125049",
    "end": "1131330"
  },
  {
    "text": "maybe from from our point of view like from newbies who are not maybe using this amazing analyze analysis system so",
    "start": "1131330",
    "end": "1139730"
  },
  {
    "text": "analytic system so obviously we can be wrong so definitely it's worth to have maybe short document Google look that we",
    "start": "1139730",
    "end": "1145880"
  },
  {
    "text": "can offline collaborate with so maybe let's have that an action item right so",
    "start": "1145880",
    "end": "1151580"
  },
  {
    "text": "I will share some of the common work and focus on requirements not necessarily",
    "start": "1151580",
    "end": "1157750"
  },
  {
    "text": "about exact solution already right that makes sense to me I think you need to",
    "start": "1157750",
    "end": "1165080"
  },
  {
    "text": "understand the use cases of where you want to end up to go beyond the",
    "start": "1165080",
    "end": "1171519"
  },
  {
    "text": "immediately obvious approaches like on a very high level you can obviously say we",
    "start": "1171519",
    "end": "1177049"
  },
  {
    "text": "want to enable deeper analysis but to answer what do we mean what are the boundaries",
    "start": "1177049",
    "end": "1182950"
  },
  {
    "text": "we probably need to agree on well not even agree but at least stake out a few",
    "start": "1182950",
    "end": "1190029"
  },
  {
    "text": "common users and what actually needs to resolve I can see the pot if we want to",
    "start": "1190029",
    "end": "1198380"
  },
  {
    "text": "talk about now is that we can start it yeah sure so one of the one of the more high-value",
    "start": "1198380",
    "end": "1204980"
  },
  {
    "text": "scenarios for my team would be to be able to you know build datasets and",
    "start": "1204980",
    "end": "1214460"
  },
  {
    "text": "curate them and and expose them such that they are suitable for model training for anomaly detection",
    "start": "1214460",
    "end": "1220120"
  },
  {
    "text": "particularly in our case with periodicity on the you know month or a",
    "start": "1220120",
    "end": "1225890"
  },
  {
    "text": "multi month or even quarterly or yearly scale many of the commercial offerings today like data dog for example do",
    "start": "1225890",
    "end": "1232780"
  },
  {
    "text": "analysis of periodicity for anomaly detection on the one to two week maximum time horizon we we run a lot of machine",
    "start": "1232780",
    "end": "1241010"
  },
  {
    "text": "learning and and we serve a lot of models for real-time auctions another",
    "start": "1241010",
    "end": "1246740"
  },
  {
    "text": "other fairly fairly real-time things being an EdTech so we'd like to apply",
    "start": "1246740",
    "end": "1253100"
  },
  {
    "text": "some of that same methodology to you know the vast firehoses data we have coming from not just",
    "start": "1253100",
    "end": "1259840"
  },
  {
    "text": "infrastructure and various layers like communities and the various cloud posted services we use but also leveraging",
    "start": "1259840",
    "end": "1266270"
  },
  {
    "text": "custom metrics that are exposed as Prometheus or open metrics formatted data today you know we're dumping that",
    "start": "1266270",
    "end": "1274040"
  },
  {
    "text": "the cortex but we've explored you know everything from time scale to influx to lock basically anything that can take a",
    "start": "1274040",
    "end": "1280940"
  },
  {
    "text": "remote write input stream and so we haven't we haven't solved this challenge",
    "start": "1280940",
    "end": "1288320"
  },
  {
    "text": "yet but that is one of our question areas so that we can you know like for example in the insurance market you know",
    "start": "1288320",
    "end": "1294860"
  },
  {
    "text": "help them health insurance in the u.s. is an open enrollment thing right and it's usually in the fourth quarter of",
    "start": "1294860",
    "end": "1300020"
  },
  {
    "text": "the year so we will see huge spikes then but in other domains like financial services or other places you have fairly",
    "start": "1300020",
    "end": "1307490"
  },
  {
    "text": "predictable absent flows of traffic that dramatically change particularly cloud",
    "start": "1307490",
    "end": "1313370"
  },
  {
    "text": "native systems so being able to have alerting that's not threshold based and",
    "start": "1313370",
    "end": "1318830"
  },
  {
    "text": "is not anomaly detection based on what happened like last Wednesday but is is more about what happened last year at",
    "start": "1318830",
    "end": "1325610"
  },
  {
    "text": "this time or last quarter at this time those are the there's some cross reference amazing",
    "start": "1325610",
    "end": "1332190"
  },
  {
    "text": "that doesn't make sense so let me put here also the thing that I we gather so far in our kind of let's say in our",
    "start": "1332190",
    "end": "1345980"
  },
  {
    "text": "let's say organization so first of all and also from the perspective of kind of",
    "start": "1345980",
    "end": "1351120"
  },
  {
    "text": "room keys what is missing or in what's what is actually difficult to obtain",
    "start": "1351120",
    "end": "1356310"
  },
  {
    "text": "right from from it so we were talking about kind of producing",
    "start": "1356310",
    "end": "1361680"
  },
  {
    "text": "multi-dimensional reports from years of data right so very often you are you",
    "start": "1361680",
    "end": "1368910"
  },
  {
    "text": "want to have a nice visualization that is not real time and not full all right",
    "start": "1368910",
    "end": "1374700"
  },
  {
    "text": "alerting but actually to analyze that you know by humans for example right or",
    "start": "1374700",
    "end": "1380130"
  },
  {
    "text": "or or to show some characteristic and",
    "start": "1380130",
    "end": "1385800"
  },
  {
    "text": "just print it right and for for your managers for your I know senior management and this is something that",
    "start": "1385800",
    "end": "1392850"
  },
  {
    "text": "it's very painful in in current kind of state of confuse because if all the queries are very heavy in terms of",
    "start": "1392850",
    "end": "1401840"
  },
  {
    "text": "cardinality and currently prompt use is focused on real-time kind of response",
    "start": "1401840",
    "end": "1408480"
  },
  {
    "text": "with low latency this mean that it's not easy there was no kind of API that allows it maybe for like streamed slower",
    "start": "1408480",
    "end": "1420800"
  },
  {
    "text": "API that will allow producing those reports right so this is kind of use",
    "start": "1420800",
    "end": "1426360"
  },
  {
    "text": "case that we found problematic and that we want to solve with this analytic analytic forum the second thing is good",
    "start": "1426360",
    "end": "1435060"
  },
  {
    "text": "discoverability of what dimensions we have available right so one thing is that we want to be able to fetch this",
    "start": "1435060",
    "end": "1441510"
  },
  {
    "text": "data for machine learning for other use cases but first we need to know what",
    "start": "1441510",
    "end": "1446970"
  },
  {
    "text": "data we have and in perfuse is not that easy because the best knowledge you have",
    "start": "1446970",
    "end": "1452340"
  },
  {
    "text": "if you are producing this data right if you are if you know what your application actually",
    "start": "1452340",
    "end": "1458570"
  },
  {
    "text": "Chris allows you exposes what metrics are exposed right if you want to kind of",
    "start": "1458570",
    "end": "1464480"
  },
  {
    "text": "discover those then you are putting a heavy load and there's no very good API on that so you know something that that",
    "start": "1464480",
    "end": "1473300"
  },
  {
    "text": "this is trying to solve is discoverability of of your data and",
    "start": "1473300",
    "end": "1480910"
  },
  {
    "text": "allow joining data from multiple sources yes there is definitely you know a use",
    "start": "1480910",
    "end": "1486230"
  },
  {
    "text": "case for having those reports or anomaly detection as you as you said that will",
    "start": "1486230",
    "end": "1491330"
  },
  {
    "text": "combine not only metrics but also logs and maybe also you know the data that you got from segments that you know from",
    "start": "1491330",
    "end": "1498110"
  },
  {
    "text": "website and and what users are accessing actually so those are further use cases",
    "start": "1498110",
    "end": "1505130"
  },
  {
    "text": "that we could see but definitely yeah let's let's let's gather most of them I",
    "start": "1505130",
    "end": "1511360"
  },
  {
    "text": "could speak to two other scenarios but again there's a lot of people on the call and I don't I don't want to hog the",
    "start": "1511360",
    "end": "1517340"
  },
  {
    "text": "airtime so to make one note so everyone",
    "start": "1517340",
    "end": "1524360"
  },
  {
    "text": "is explicitly aware of this that we already have different use cases and as much as MIT was talking about shipping",
    "start": "1524360",
    "end": "1529790"
  },
  {
    "text": "data often doing analysis somewhere else where as particles talking about doing it within the observability stack which",
    "start": "1529790",
    "end": "1536900"
  },
  {
    "text": "is already a huge difference and with that I'm going to show up and require",
    "start": "1536900",
    "end": "1542060"
  },
  {
    "text": "someone who's not partic met or me to to pipe up and voice an opinion please we",
    "start": "1542060",
    "end": "1553460"
  },
  {
    "text": "only buy it if you don't talk if you talk we don't bite",
    "start": "1553460",
    "end": "1558670"
  },
  {
    "text": "you your cup goes away in the magic backroom",
    "start": "1559840",
    "end": "1566050"
  },
  {
    "text": "fee no one no one has any opinion on this I mean on some level I like to keep",
    "start": "1566050",
    "end": "1574960"
  },
  {
    "text": "things small and composable so shoving a whole bunch of data analytic stuff into an observability stack kind of feels",
    "start": "1574960",
    "end": "1581440"
  },
  {
    "text": "like creating a massive monolith instead of a bunch of little tools that compose to do something nice but that doesn't",
    "start": "1581440",
    "end": "1588340"
  },
  {
    "text": "mean you can't have a marketing umbrella that's got a bunch of smaller projects underneath it to go and fit together",
    "start": "1588340",
    "end": "1593950"
  },
  {
    "text": "nicely just as a thought you can also",
    "start": "1593950",
    "end": "1600340"
  },
  {
    "text": "have something in the middle value basically enabled composability for",
    "start": "1600340",
    "end": "1605470"
  },
  {
    "text": "example something but we again very deep in permit Iceland if Prometheus had a batch API versus an",
    "start": "1605470",
    "end": "1611740"
  },
  {
    "text": "interactive API where you can put requests which basically they can return",
    "start": "1611740",
    "end": "1617320"
  },
  {
    "text": "in an hour or in a day I don't care I just care about this happening at some point and that's basically what all what",
    "start": "1617320",
    "end": "1625720"
  },
  {
    "text": "on mainframes grew large with this distinction between interactive database access and batch database access and",
    "start": "1625720",
    "end": "1633160"
  },
  {
    "text": "this simple split enabled insanely powerful use cases so for example this",
    "start": "1633160",
    "end": "1639550"
  },
  {
    "text": "is something which you know observability engine could offer and then try and just interface with other",
    "start": "1639550",
    "end": "1645670"
  },
  {
    "text": "things nicely and I think that's I'm a",
    "start": "1645670",
    "end": "1651340"
  },
  {
    "text": "hundred percent behind that I think that the really interesting story is the API is that enabled the external use cases",
    "start": "1651340",
    "end": "1658360"
  },
  {
    "text": "so instead of going and shoving a you know Jupiter notebook into Prometheus",
    "start": "1658360",
    "end": "1663970"
  },
  {
    "text": "lord help us building an awesome API that goes in the enables those new types",
    "start": "1663970",
    "end": "1669640"
  },
  {
    "text": "of workloads is definitely a hundred percent the UNIX philosophy composability",
    "start": "1669640",
    "end": "1674920"
  },
  {
    "text": "community play yeah I think at least for",
    "start": "1674920",
    "end": "1681000"
  },
  {
    "text": "time-series metrics I think remote read and remote write are fairly brilliant I think there's a need",
    "start": "1681000",
    "end": "1687580"
  },
  {
    "text": "for some backfilling and I've talked with some of the folks here already",
    "start": "1687580",
    "end": "1692980"
  },
  {
    "text": "about this in the past but we're looking acutely and maybe even writing in ourselves or doing it in the",
    "start": "1692980",
    "end": "1699190"
  },
  {
    "text": "context of prometheus community but a mirroring proxy for remote write would",
    "start": "1699190",
    "end": "1706480"
  },
  {
    "text": "allow us to have our existing observability stack in place where you know from all sorts of places both",
    "start": "1706480",
    "end": "1711960"
  },
  {
    "text": "kubernetes and not we have metrics you",
    "start": "1711960",
    "end": "1717040"
  },
  {
    "text": "know heading to a centralized back-end and if we can tee those off very easily",
    "start": "1717040",
    "end": "1723220"
  },
  {
    "text": "and just replicate all of that to go to other systems like perhaps time scale or",
    "start": "1723220",
    "end": "1729550"
  },
  {
    "text": "click house or whatever that would let us kind of not muddy the observability",
    "start": "1729550",
    "end": "1736240"
  },
  {
    "text": "stack with this analytic stuff but would still make it very simple to move and in",
    "start": "1736240",
    "end": "1741880"
  },
  {
    "text": "the same spirit you know one of the things that I have the least amount of like concrete plans about how we're",
    "start": "1741880",
    "end": "1747760"
  },
  {
    "text": "going to achieve it is the same with trace data in particular we have a lot of our services or you know that we're",
    "start": "1747760",
    "end": "1755010"
  },
  {
    "text": "universally instrumenting with open telemetry the link Rd mesh we're using",
    "start": "1755010",
    "end": "1760420"
  },
  {
    "text": "also can export headers as well and and in those spans many of our development",
    "start": "1760420",
    "end": "1766900"
  },
  {
    "text": "teams are finding it useful to put additional metadata like you know logged messages or stacktrace",
    "start": "1766900",
    "end": "1773170"
  },
  {
    "text": "you know failure things unique identifier so we have this whole bunch of data that's not Prometheus or which I",
    "start": "1773170",
    "end": "1779050"
  },
  {
    "text": "don't have the same set of API today to handle a cross different trace back-end",
    "start": "1779050",
    "end": "1784540"
  },
  {
    "text": "so we're sending everything to Yaeger right but how do I get it all that in a good way and how do I use other backends",
    "start": "1784540",
    "end": "1791320"
  },
  {
    "text": "or whatever to bring that trace data into scope for analysis I really love",
    "start": "1791320",
    "end": "1798280"
  },
  {
    "text": "the mirroring idea because going back to the segment comments from earlier like that's what I use segment for is",
    "start": "1798280",
    "end": "1804640"
  },
  {
    "text": "literally just mirroring and splitting out all my analytics data into a bunch of different backends whether it's Google Analytics or bigquery or whatever",
    "start": "1804640",
    "end": "1813070"
  },
  {
    "text": "and like it's my favorite tool on earth specifically for that reason because",
    "start": "1813070",
    "end": "1819010"
  },
  {
    "text": "there's a whole bunch of different tools that do a bunch of different things I want a single stream that comes in and then splits it out into other backends",
    "start": "1819010",
    "end": "1825970"
  },
  {
    "text": "that I can slice and dice different ways is this a SAS hosted thing yeah I think",
    "start": "1825970",
    "end": "1833500"
  },
  {
    "text": "there's a a like segment knockoff that's open source there's a lot of competitors",
    "start": "1833500",
    "end": "1841330"
  },
  {
    "text": "to segments I've definitely used it it's pretty cool product yeah I think but",
    "start": "1841330",
    "end": "1850600"
  },
  {
    "text": "somebody touched on it before and again it should be less afraid about talking I supposed to set an example you know one",
    "start": "1850600",
    "end": "1859419"
  },
  {
    "text": "of the reasons why we want to find a way to do this with open source tooling is primarily so you can run ourselves we",
    "start": "1859419",
    "end": "1865360"
  },
  {
    "text": "handle a lot of PII 2 nd pH high and so many SAS tools we can use but it",
    "start": "1865360",
    "end": "1871149"
  },
  {
    "text": "requires a fairly you know FedRAMP certifications of just a lot of you know",
    "start": "1871149",
    "end": "1876399"
  },
  {
    "text": "talk to compliance auditing it's a long it's a heavy-lift operationally to use",
    "start": "1876399",
    "end": "1883600"
  },
  {
    "text": "some of these tools because the data needs to stay within our own pcs of",
    "start": "1883600",
    "end": "1888789"
  },
  {
    "text": "networks so from a requirements perspective I think at least for our",
    "start": "1888789",
    "end": "1894899"
  },
  {
    "text": "business soft hosted as if there's a pretty important news and when we get",
    "start": "1894899",
    "end": "1902049"
  },
  {
    "text": "into the volume you know we did some tests with you know a link or D they service match give me everything you can",
    "start": "1902049",
    "end": "1908549"
  },
  {
    "text": "it's you know we actually have a whole data platform team and they all have xt",
    "start": "1908549",
    "end": "1914080"
  },
  {
    "text": "man just they're very quickly dwarfed sitting on that",
    "start": "1914080",
    "end": "1919919"
  },
  {
    "text": "is there anything in the CN CF umbrella around reasoning on trace data that",
    "start": "1927299",
    "end": "1934950"
  },
  {
    "text": "folks have found useful or are you know do I have a knowledge gap about what I",
    "start": "1934950",
    "end": "1942029"
  },
  {
    "text": "could just be using or is there an actual gap in projects web traces you",
    "start": "1942029",
    "end": "1949320"
  },
  {
    "text": "then you can actually send it to Gnostic search for instance and Julia had six there but it's very it's not obvious out",
    "start": "1949320",
    "end": "1958320"
  },
  {
    "text": "of the box that you actually you need to take care of that in the back end we had",
    "start": "1958320",
    "end": "1964350"
  },
  {
    "text": "exactly the same question internally generated a lot of trial he traces a lot of metrics and how do we do an analysis",
    "start": "1964350",
    "end": "1970679"
  },
  {
    "text": "on that right now it's a bit it is not easily discoverable basically yeah I I",
    "start": "1970679",
    "end": "1977909"
  },
  {
    "text": "think we've identified at least for our roadmap kind of two buckets in this general topic one correlation of trace",
    "start": "1977909",
    "end": "1986010"
  },
  {
    "text": "logs is traces logs and metrics for operational key use cases you know like",
    "start": "1986010",
    "end": "1991950"
  },
  {
    "text": "what's going wrong one went splat or iterative development of these cases and for that we've been using core fauna you",
    "start": "1991950",
    "end": "1998730"
  },
  {
    "text": "know to stitch together the logs traces and metrics and we expect that to be a nice fit but on the analytics side you",
    "start": "1998730",
    "end": "2007640"
  },
  {
    "text": "know to dive deeper in I think there's a lot of opportunity does anyone know of projects work that might help fill this",
    "start": "2007640",
    "end": "2014330"
  },
  {
    "text": "gap or should we at least take an action to report up to the TOC that this is one domain that is ripe for new projects to",
    "start": "2014330",
    "end": "2022700"
  },
  {
    "text": "join the ciencia I think yeah here is probably the",
    "start": "2022700",
    "end": "2032779"
  },
  {
    "text": "project that does most from on the opposite side I think the rest is all in the commercial part budget space but",
    "start": "2032779",
    "end": "2040039"
  },
  {
    "text": "people are going to India endo dicks on top and project open telemetry also try",
    "start": "2040039",
    "end": "2046549"
  },
  {
    "text": "to focus really on the data connection but not the processing and not the analytics part I think that the biggest",
    "start": "2046549",
    "end": "2057669"
  },
  {
    "text": "the biggest part of analytics to is definitely a or a special thing a project has done done recently I mean",
    "start": "2057669",
    "end": "2065658"
  },
  {
    "text": "there's other questions I've ever seen you come up there do you have even like a uniform a great",
    "start": "2065659",
    "end": "2071868"
  },
  {
    "text": "data model how you store things like you mentioned like today people use log messages part of traces this is once we",
    "start": "2071869",
    "end": "2078440"
  },
  {
    "text": "start telling people like 10 10 years ago not to do because it's highly",
    "start": "2078440",
    "end": "2083780"
  },
  {
    "text": "inefficient from a processing part later on or the back end and you want to split up these two data sources and just link",
    "start": "2083780",
    "end": "2090648"
  },
  {
    "text": "them together by IDs because easily a trace processing needs to be even higher",
    "start": "2090649",
    "end": "2095868"
  },
  {
    "text": "performant and they are taking a lot of processing so I'm not sure what I'm",
    "start": "2095869",
    "end": "2101540"
  },
  {
    "text": "helping here and I'm following a discussion that's where was like listening in here for most of the time",
    "start": "2101540",
    "end": "2106760"
  },
  {
    "text": "but if you want to combine these different data sources I think that's that's really what you need to need to agree on how they coalesce labels that",
    "start": "2106760",
    "end": "2113150"
  },
  {
    "text": "you can create the cross of table data sources and on the other topic I",
    "start": "2113150",
    "end": "2120680"
  },
  {
    "text": "mentioned before about processing an input output I personally like them like one source of data or like one stream of",
    "start": "2120680",
    "end": "2128599"
  },
  {
    "text": "data processing into different tools I just see this getting harder and harder",
    "start": "2128599",
    "end": "2134150"
  },
  {
    "text": "the more data you're consuming and if you're like massively large systems just",
    "start": "2134150",
    "end": "2139339"
  },
  {
    "text": "reading the data again after your store it becomes more more than issue this is",
    "start": "2139339",
    "end": "2146300"
  },
  {
    "text": "also like a lot of the work that I'm focusing on right now how do I not have to eat or how can we use the amount of",
    "start": "2146300",
    "end": "2153650"
  },
  {
    "text": "data after wheat it's magic again it's possible so if you see it and one day",
    "start": "2153650",
    "end": "2158839"
  },
  {
    "text": "produce 200 or less 20 terabytes of data and the streaming it to five tools and storing",
    "start": "2158839",
    "end": "2164959"
  },
  {
    "text": "it in five schools is 20 terabytes became 100 terabytes and if we even add",
    "start": "2164959",
    "end": "2171650"
  },
  {
    "text": "more tools over the Xhosa store data again and not just the results after",
    "start": "2171650",
    "end": "2177829"
  },
  {
    "text": "processing it just becomes more and more so that's why if you wanted to look into",
    "start": "2177829",
    "end": "2184039"
  },
  {
    "text": "something but look more into a three data processing model Internet data can easily be processed in a stream data",
    "start": "2184039",
    "end": "2190609"
  },
  {
    "text": "processing type of approach probably a lot of people using Kafka for these kind",
    "start": "2190609",
    "end": "2199069"
  },
  {
    "text": "of scenarios but this is I'm just not",
    "start": "2199069",
    "end": "2205400"
  },
  {
    "text": "sure but I'm off topic right now where I'm part of this I just wanted it I personally think it's on topic if we're",
    "start": "2205400",
    "end": "2212329"
  },
  {
    "text": "talking about you know traces being part of this observability data that's coaching directly well but we've been",
    "start": "2212329",
    "end": "2220160"
  },
  {
    "text": "looking at in our group is yes we will be using likely khakha to actually",
    "start": "2220160",
    "end": "2226999"
  },
  {
    "text": "shovel things around but in particular tale based sampling with the open telemetry collector and seeing what we",
    "start": "2226999",
    "end": "2233269"
  },
  {
    "text": "can do to much like fluent bit moves processing of logs and tokenization and",
    "start": "2233269",
    "end": "2239359"
  },
  {
    "text": "some of the compute cost out to the edge near where the logs are being transmitted so that you know you don't",
    "start": "2239359",
    "end": "2245029"
  },
  {
    "text": "you don't have all that stuff on the wire necessarily or you can reduce the overall volume we're looking at how can",
    "start": "2245029",
    "end": "2252559"
  },
  {
    "text": "we be considering rather how can we you know do as much as possible where we're",
    "start": "2252559",
    "end": "2258979"
  },
  {
    "text": "collecting all traces but you know at the point where we're collecting and what we're calling the things we don't",
    "start": "2258979",
    "end": "2265429"
  },
  {
    "text": "care about so programming models to do stream processing that that edge",
    "start": "2265429",
    "end": "2270739"
  },
  {
    "text": "locations where the services are you know in cluster or on a virtual machine whatever before we store all that is we",
    "start": "2270739",
    "end": "2281269"
  },
  {
    "text": "think might be the best approach yeah I think we are touching exactly",
    "start": "2281269",
    "end": "2287469"
  },
  {
    "text": "this topic on there two ways either you move everything in convert everything to the tools that a target format or we",
    "start": "2287469",
    "end": "2294579"
  },
  {
    "text": "have some way of aggregating and stream those data and just fetch what you need",
    "start": "2294579",
    "end": "2300190"
  },
  {
    "text": "from the various data sources and this is yeah just just nicer because you",
    "start": "2300190",
    "end": "2306069"
  },
  {
    "text": "don't reproduce data but yeah I think one actionable thing that we could like anyone on this call could start working",
    "start": "2306069",
    "end": "2312190"
  },
  {
    "text": "on maybe we just make a ticket for a test for it and see who's interested is but you know on this very topic like I",
    "start": "2312190",
    "end": "2319329"
  },
  {
    "text": "have active questions now that I don't see easy answers to without just trying it around the jaegers scalability like",
    "start": "2319329",
    "end": "2325479"
  },
  {
    "text": "what happens if i take blank amount of data and throw it into a Jaeger back-end and I just keep putting the at what",
    "start": "2325479",
    "end": "2333099"
  },
  {
    "text": "point does it fall over and not become usable or should I run lots of little ones you know so much like we're psyched",
    "start": "2333099",
    "end": "2340539"
  },
  {
    "text": "about cortex because it provides this centralized fairly cheap way to store a lot so time series data you know and",
    "start": "2340539",
    "end": "2348459"
  },
  {
    "text": "make it query about all the things the cortex does we kind of want something similar for Jaeger I referred for trace",
    "start": "2348459",
    "end": "2354400"
  },
  {
    "text": "data and I don't I don't worry now know what that is so in scope for this to be",
    "start": "2354400",
    "end": "2360130"
  },
  {
    "text": "like making some case studies and just taking some base measurements so that let's say like in the year 2020 you know",
    "start": "2360130",
    "end": "2366009"
  },
  {
    "text": "in July where I to put this much data in this is what the performance would be yes but now definitely good discussions",
    "start": "2366009",
    "end": "2375549"
  },
  {
    "text": "in a younger team how to scale it more and there was a recent spike on butter butter making database and there are",
    "start": "2375549",
    "end": "2383890"
  },
  {
    "text": "much much more what's going on but I think this doesn't so like analytics a kind of problem right now is just",
    "start": "2383890",
    "end": "2390699"
  },
  {
    "text": "another maybe more high cardinality kind of database and and the question can we",
    "start": "2390699",
    "end": "2397869"
  },
  {
    "text": "scale it but but still we just another data right and and I think we should",
    "start": "2397869",
    "end": "2403809"
  },
  {
    "text": "have this topic how to scale yaker and and and and but I think that might be something we can pull you know yeah",
    "start": "2403809",
    "end": "2410769"
  },
  {
    "text": "Gertie might well here and definitely talk about that and help them scale because they did they need some help but",
    "start": "2410769",
    "end": "2418890"
  },
  {
    "text": "I don't even know how to make bigger scale I mean what is a suitable durable store for trace data that could be used",
    "start": "2419030",
    "end": "2427190"
  },
  {
    "text": "for analytics purposes yeah so it's more closely Jaeger thing and more of a like",
    "start": "2427190",
    "end": "2434960"
  },
  {
    "text": "we have remote read remote right right and I can have different backends but that to me seems like that sounds like a",
    "start": "2434960",
    "end": "2441920"
  },
  {
    "text": "valid use case right we would like to have a tool that may be composed the data from both from gears and Jager and",
    "start": "2441920",
    "end": "2448880"
  },
  {
    "text": "something that will are some system that we allow to do that it's actually a good verification for for this topic right",
    "start": "2448880",
    "end": "2455750"
  },
  {
    "text": "for this spike we're doing a good point",
    "start": "2455750",
    "end": "2460750"
  },
  {
    "text": "on the previous topic of figure so here I on the stream processing",
    "start": "2467650",
    "end": "2474290"
  },
  {
    "text": "um are you we saying this is something that you're considering or my audio got",
    "start": "2474290",
    "end": "2480830"
  },
  {
    "text": "garbled when I when you were talking is their projects or are their API is already they could be suitable here or",
    "start": "2480830",
    "end": "2489020"
  },
  {
    "text": "they could be applied to dien stream processing on okay technically",
    "start": "2489020",
    "end": "2495590"
  },
  {
    "text": "everything you do was touristy there will be processing because he'd get in midstream he just has to merge a lot of",
    "start": "2495590",
    "end": "2501020"
  },
  {
    "text": "data together that's how the idea we do it at scale and also one year I mean we",
    "start": "2501020",
    "end": "2507140"
  },
  {
    "text": "did it before when we exported data it was also street based because you need high performance out forever washes the",
    "start": "2507140",
    "end": "2512660"
  },
  {
    "text": "amount of stable pricey crazy but it is raised a the process into being",
    "start": "2512660",
    "end": "2519830"
  },
  {
    "text": "sensitive is a mixture if you did and maybe that makes it so hard - what was it - tango because the mixture of sleep",
    "start": "2519830",
    "end": "2525980"
  },
  {
    "text": "data processing if you for example need to calculate metrics from that stream of phrases that you get in there like",
    "start": "2525980",
    "end": "2532610"
  },
  {
    "text": "service response time if you want to collect them on an on a per trace level which you already don't have",
    "start": "2532610",
    "end": "2539300"
  },
  {
    "text": "to do if you have metrics for for for",
    "start": "2539300",
    "end": "2544520"
  },
  {
    "text": "response times but if you want to slice and dice them and then it's like really this high cardinality database type of",
    "start": "2544520",
    "end": "2551130"
  },
  {
    "text": "is that you run against these daggers but even there we found that stream data processing solves a lot of issues that",
    "start": "2551130",
    "end": "2557370"
  },
  {
    "text": "we are analyzed there for example for problem patterns as we are collecting the data and off later on I mean my",
    "start": "2557370",
    "end": "2565050"
  },
  {
    "text": "personal opinion is if you do good data analysis on trace data you will use the amount of use cases where you have to do",
    "start": "2565050",
    "end": "2570780"
  },
  {
    "text": "a lot of real-time queries on that data because that the bigger world right now",
    "start": "2570780",
    "end": "2576450"
  },
  {
    "text": "goes into aggregation of of traces it's",
    "start": "2576450",
    "end": "2582150"
  },
  {
    "text": "kind of interesting to watch and because as Jonah here who's working a space for yeah I was well yeah we started always",
    "start": "2582150",
    "end": "2588930"
  },
  {
    "text": "Cindy traces until to the point where we realized that looking at Cindy traces is nice for a developer to understand what",
    "start": "2588930",
    "end": "2596130"
  },
  {
    "text": "they called us or for debugging intermittent errors but reasonable in",
    "start": "2596130",
    "end": "2602340"
  },
  {
    "text": "large systems just have too many traces and similarity and outlier analysis of",
    "start": "2602340",
    "end": "2608870"
  },
  {
    "text": "traces which eventually graph based data structures is something that you're usually looking for the individual parts",
    "start": "2608870",
    "end": "2615480"
  },
  {
    "text": "you rarely look at because it's just too many so one of one of the things the",
    "start": "2615480",
    "end": "2621120"
  },
  {
    "text": "Geiger is missing is like the ability to create metrics from traces in that in",
    "start": "2621120",
    "end": "2627090"
  },
  {
    "text": "that real-time way which is definitely something we're looking to contribute back into the project and then the idea",
    "start": "2627090",
    "end": "2635130"
  },
  {
    "text": "would be to expose those to be scraped by something like Prometheus where you could then start to do trending and",
    "start": "2635130",
    "end": "2641370"
  },
  {
    "text": "other types of analysis of the trace data that's being collected and ultimately you could actually detect a",
    "start": "2641370",
    "end": "2649260"
  },
  {
    "text": "lot of problems just based on metrics versus having to actually analyze all",
    "start": "2649260",
    "end": "2655050"
  },
  {
    "text": "the traces because what jäger it just hammers the back end and it becomes really difficult with elasticsearch to",
    "start": "2655050",
    "end": "2661860"
  },
  {
    "text": "do these types of things at scale this is exactly what we're dealing with in our system as our customers continue to",
    "start": "2661860",
    "end": "2669570"
  },
  {
    "text": "send more trace data you know to our back-end and it's definitely kind of a",
    "start": "2669570",
    "end": "2676920"
  },
  {
    "text": "disconnect between traces and metrics that I'm seeing in the community so the",
    "start": "2676920",
    "end": "2682560"
  },
  {
    "text": "same approaches but what one other is why we've chosen Loki for some of our",
    "start": "2682560",
    "end": "2688100"
  },
  {
    "text": "log aggregation scenarios in particular prom tale which is a demon set that runs",
    "start": "2688100",
    "end": "2693350"
  },
  {
    "text": "in a kubernetes context anyway entails all the logs it it can look for things",
    "start": "2693350",
    "end": "2700280"
  },
  {
    "text": "and have log derived metrics that are exposed as a prometheus endpoint that",
    "start": "2700280",
    "end": "2705470"
  },
  {
    "text": "can then be scraped by the same in cluster Prometheus to get exactly the same thing to get like frequencies in",
    "start": "2705470",
    "end": "2711500"
  },
  {
    "text": "various custom processing it it also",
    "start": "2711500",
    "end": "2716720"
  },
  {
    "text": "does it on the server side in this ladder like which is which is a differentiator actually because you can",
    "start": "2716720",
    "end": "2722480"
  },
  {
    "text": "do bog derive metrics for things that we didn't set up ahead of time to make metrics for but different different",
    "start": "2722480",
    "end": "2728870"
  },
  {
    "text": "topic for a different day I mean I think it's different argument I mean I believe that logs still have a lot of value if",
    "start": "2728870",
    "end": "2736430"
  },
  {
    "text": "they're indexed and Loki doesn't do indexing so yeah unless you leave all",
    "start": "2736430",
    "end": "2742280"
  },
  {
    "text": "this yeah sorry no I I'm sorry you're absolutely right I didn't mean to say it",
    "start": "2742280",
    "end": "2749030"
  },
  {
    "text": "was holistically everything it's one prong of an approach but we're also doing some indexing on targeted",
    "start": "2749030",
    "end": "2755690"
  },
  {
    "text": "workloads as well but my point was that",
    "start": "2755690",
    "end": "2760880"
  },
  {
    "text": "did the notion of at the point of collection deriving time-series metrics because it's simpler sometimes in more",
    "start": "2760880",
    "end": "2767780"
  },
  {
    "text": "expedient to reason on the time series than it is to plow through the full trace data or through the full log data",
    "start": "2767780",
    "end": "2774820"
  },
  {
    "text": "it's a common approach to calculate",
    "start": "2774820",
    "end": "2781040"
  },
  {
    "text": "metrics across different instances you have to echo gate and somewhere again because are you also doing it based on",
    "start": "2781040",
    "end": "2789580"
  },
  {
    "text": "that fixed data I think this discussion we're having right now per se what to use for what s is one that has been",
    "start": "2789640",
    "end": "2797360"
  },
  {
    "text": "going on for over ten years in the modern community yep just telling people what to do is it",
    "start": "2797360",
    "end": "2803140"
  },
  {
    "text": "it is it good to be like what to use metrics for what to do is trace is what to not do these traces if the only thing",
    "start": "2803140",
    "end": "2810290"
  },
  {
    "text": "I want is a response time for service sending trace data that I then you",
    "start": "2810290",
    "end": "2816640"
  },
  {
    "text": "to calculate the metric to then do a little thing might not be the best move",
    "start": "2816640",
    "end": "2821769"
  },
  {
    "text": "at all might not be reliable essentially you know yeah I guess that's why I wanted to focus on scenarios I've been",
    "start": "2821769",
    "end": "2828039"
  },
  {
    "text": "holding off but I could just really quickly just bounce through two additional scenarios that we might want to add to the list I'm curious if other",
    "start": "2828039",
    "end": "2833829"
  },
  {
    "text": "people have these same ones one is correlation of infrastructure metrics with ask so you know most product riders",
    "start": "2833829",
    "end": "2842109"
  },
  {
    "text": "that we use you don't give you costing information and being able to correlate those two things there's two others that",
    "start": "2842109",
    "end": "2848200"
  },
  {
    "text": "we had when looking at horizontal versus vertical pod auto scaling you know that",
    "start": "2848200",
    "end": "2856029"
  },
  {
    "text": "that's a place where we would like to run experiments capture the impact",
    "start": "2856029",
    "end": "2862119"
  },
  {
    "text": "particularly from legacy workloads that were inherited shall we say that aren't completely understood but have you know",
    "start": "2862119",
    "end": "2869230"
  },
  {
    "text": "good test collateral where we can filter some traffic to to run experiments you know when when does it make more sense",
    "start": "2869230",
    "end": "2875680"
  },
  {
    "text": "to scale vertically worse as far as on tallien and just capturing the metrics for all of that and then correlating it with",
    "start": "2875680",
    "end": "2881940"
  },
  {
    "text": "what the autoscaler did can provide you know the ability to create models to",
    "start": "2881940",
    "end": "2888549"
  },
  {
    "text": "came out how we should better utilize hardware and then Carling all that back to different the cost those are those",
    "start": "2888549",
    "end": "2896289"
  },
  {
    "text": "are two scenarios at least that our ways we internet ever quote might want to use",
    "start": "2896289",
    "end": "2903750"
  },
  {
    "text": "analytics on and then the third all",
    "start": "2903750",
    "end": "2909430"
  },
  {
    "text": "mention is that we we've launched internally to brag a little it's actually quite simple just a deployed",
    "start": "2909430",
    "end": "2914799"
  },
  {
    "text": "tracker service so so some of our CI NCD when it makes deploys or when a lot of hand deploys that aren't automated yet",
    "start": "2914799",
    "end": "2921279"
  },
  {
    "text": "are made we've got that going to a back-end service which is then making in",
    "start": "2921279",
    "end": "2928720"
  },
  {
    "text": "our case graph on on annotations and also surfacing that via a Prometheus aggregation push gave a time-series",
    "start": "2928720",
    "end": "2936069"
  },
  {
    "text": "metrics out of our deploys so we can correlate like deploys to anomalies or",
    "start": "2936069",
    "end": "2942099"
  },
  {
    "text": "errors or whatever happening good or bad in our infrastructure and that's another thing where there's so much data and so",
    "start": "2942099",
    "end": "2949000"
  },
  {
    "text": "many different points of measurements different services that applying a more systemic analytical approach that there",
    "start": "2949000",
    "end": "2957160"
  },
  {
    "text": "can make it less you know needle in haystack kind of traditional debugging",
    "start": "2957160",
    "end": "2962970"
  },
  {
    "text": "this would like this is exactly it's exactly something that's considered",
    "start": "2962970",
    "end": "2968970"
  },
  {
    "text": "basically when we doing the deploy you want to look at the trace data to see",
    "start": "2968970",
    "end": "2974110"
  },
  {
    "text": "exactly what changed if we can generate metrics out of there then we have immediately insights into you know maybe",
    "start": "2974110",
    "end": "2979900"
  },
  {
    "text": "this band took 10 percent longer suddenly because we did this deployments I mean correlate that also to response",
    "start": "2979900",
    "end": "2986620"
  },
  {
    "text": "time on a metric and it'll get a lot some walking at the same times I creating all that it's kind of really",
    "start": "2986620",
    "end": "2993520"
  },
  {
    "text": "hard right now cuz you have to integrate with lots of different systems and and yeah with traces need you don't have really good tools right now to do that",
    "start": "2993520",
    "end": "3000630"
  },
  {
    "text": "that can handle the load and scale well but yeah one of the things you said was",
    "start": "3000630",
    "end": "3006330"
  },
  {
    "text": "you wondered if others were kind of heading in the same direction definitely I mean with exactly the use",
    "start": "3006330",
    "end": "3011730"
  },
  {
    "text": "case right now yeah I think I want to kind of bomb this threat because we are",
    "start": "3011730",
    "end": "3017940"
  },
  {
    "text": "actually thinking about that in kind of from Q's community because with the low",
    "start": "3017940",
    "end": "3023730"
  },
  {
    "text": "key and and hacker we are kind of collaborating together and we are already having some POC of solutions",
    "start": "3023730",
    "end": "3030810"
  },
  {
    "text": "that for example are having strong links between his data so you are still pushing you know",
    "start": "3030810",
    "end": "3037110"
  },
  {
    "text": "gathering metrics you are still pushing blocks like he used to you still pushing traces however you the recessive kind of",
    "start": "3037110",
    "end": "3044610"
  },
  {
    "text": "way worried only index once because they say kind of you have actually the same",
    "start": "3044610",
    "end": "3051380"
  },
  {
    "text": "resources in both of those signals right and so you can totally have the same index that will give you you know that",
    "start": "3051380",
    "end": "3058680"
  },
  {
    "text": "certain application for example so that's already reducing a lot of space",
    "start": "3058680",
    "end": "3065700"
  },
  {
    "text": "and and complexity and and and resources that you have to use for for those",
    "start": "3065700",
    "end": "3071580"
  },
  {
    "text": "signals right so for example you have Pro materials are giving exemplars that",
    "start": "3071580",
    "end": "3077720"
  },
  {
    "text": "can hold trace IDs for the for example slower",
    "start": "3077720",
    "end": "3083440"
  },
  {
    "text": "some interesting thing that happened during observation of latency of this request for example so then you can",
    "start": "3083440",
    "end": "3089810"
  },
  {
    "text": "navigate to trace and and have traces and the same you can share the trace ID",
    "start": "3089810",
    "end": "3095990"
  },
  {
    "text": "and the request ID for the logins so we can jump from that between logging and tracing and if you would and kind of",
    "start": "3095990",
    "end": "3103250"
  },
  {
    "text": "work together in a way that those databases will share some kind of information for example indexes which",
    "start": "3103250",
    "end": "3110210"
  },
  {
    "text": "are very heavy there is a huge wing here so we're trying to go for this because you really",
    "start": "3110210",
    "end": "3116870"
  },
  {
    "text": "need to gather metrics and push metrics right as we agreed for the four",
    "start": "3116870",
    "end": "3122690"
  },
  {
    "text": "different purposes like for alerting you have to have reliable real-time metrics for traces you are fine with those and a",
    "start": "3122690",
    "end": "3130100"
  },
  {
    "text": "slower latency for kind of trace availability so there yeah it's hard to",
    "start": "3130100",
    "end": "3137450"
  },
  {
    "text": "have just one solution and just use traces and forget about anything however we want to make sure with this",
    "start": "3137450",
    "end": "3143630"
  },
  {
    "text": "observability group as well that we can collaborate together and have uniform",
    "start": "3143630",
    "end": "3149660"
  },
  {
    "text": "solution yet and then that's what we care for you it's also interesting it's",
    "start": "3149660",
    "end": "3155030"
  },
  {
    "text": "you mentioned correlate everything and if you use the elastic search completely and I'm in no way like trying to sell it",
    "start": "3155030",
    "end": "3160700"
  },
  {
    "text": "or anything but you can actually already do that but you have to be completely locked in in that system it would be",
    "start": "3160700",
    "end": "3166220"
  },
  {
    "text": "nice to be able to use now the CNCs projects in the same way that you can correlate all those things all together",
    "start": "3166220",
    "end": "3171520"
  },
  {
    "text": "and still keep you to the cloud native kind of way of working exactly this has",
    "start": "3171520",
    "end": "3179990"
  },
  {
    "text": "been awesome I'm just looking at the clock at we have I think they have two minutes left Richard what do you think",
    "start": "3179990",
    "end": "3187520"
  },
  {
    "text": "next steps are I mean I don't want to just move forward and become actionable",
    "start": "3187520",
    "end": "3194360"
  },
  {
    "text": "things that we can fan out to so I think one thing which we should be doing is",
    "start": "3194360",
    "end": "3200330"
  },
  {
    "text": "start collating use cases start",
    "start": "3200330",
    "end": "3205430"
  },
  {
    "text": "collating use cases in a shared document are using if you want I can send them on",
    "start": "3205430",
    "end": "3211280"
  },
  {
    "text": "around without any restriction so everyone can just toss stuff in maybe let this sit for a week or so - to",
    "start": "3211280",
    "end": "3219010"
  },
  {
    "text": "have a brainstorming session and then from there try and there's still more [Music]",
    "start": "3219010",
    "end": "3225120"
  },
  {
    "text": "generalized use cases all of this the other thing",
    "start": "3225120",
    "end": "3231420"
  },
  {
    "text": "Cynthia POC asked us to select a third chair with a little bit more view on",
    "start": "3232050",
    "end": "3238840"
  },
  {
    "text": "diversity so if anyone of you have suggestions highly appreciated because",
    "start": "3238840",
    "end": "3245080"
  },
  {
    "text": "initially we did look around it didn't really find a lot but we are restarts",
    "start": "3245080",
    "end": "3251440"
  },
  {
    "text": "that effort is anyone interested in",
    "start": "3251440",
    "end": "3262720"
  },
  {
    "text": "working on sort of a case a set of case studies maybe not on what tools to use but just like either working with either",
    "start": "3262720",
    "end": "3271450"
  },
  {
    "text": "reaching out to projects like Jaeger and open telemetry and seeing what they have in terms of again like I'm tactically",
    "start": "3271450",
    "end": "3277390"
  },
  {
    "text": "looking I'm wanted to play Jaeger for example or I'm gonna deploy whatever just raw sizing it seems like a you know",
    "start": "3277390",
    "end": "3284710"
  },
  {
    "text": "figure it out as you go and I'd like to just create provision what's needed so",
    "start": "3284710",
    "end": "3289930"
  },
  {
    "text": "there might be some low-hanging fruit there for new country new contributors or new members of the cig I would I",
    "start": "3289930",
    "end": "3296530"
  },
  {
    "text": "would encourage us all to make suggestions like cooking slag or in github but I would like to period a",
    "start": "3296530",
    "end": "3302650"
  },
  {
    "text": "backlog much larger than the folks on this call could deal with so that we can say to potential cig members hey come",
    "start": "3302650",
    "end": "3309640"
  },
  {
    "text": "join us this is all some already we just if you're interested in this stuff you can contribute and here's how so perhaps",
    "start": "3309640",
    "end": "3317230"
  },
  {
    "text": "that's a separate brainstorm and I'll follow up with something on the list",
    "start": "3317230",
    "end": "3322470"
  },
  {
    "text": "I think we can you can do that collaborate you kind of in together right so I'm happy to set up this",
    "start": "3324619",
    "end": "3331160"
  },
  {
    "text": "document because kind of started this this topic and kind of announced it so",
    "start": "3331160",
    "end": "3336349"
  },
  {
    "text": "everyone can reach that the closest project they are working on and and and",
    "start": "3336349",
    "end": "3343039"
  },
  {
    "text": "give an input on the case studies and requirements right this is our goal for now and use cases or did not catch you",
    "start": "3343039",
    "end": "3357079"
  },
  {
    "text": "seen use cases because I think for Alan for this sake like I think case studies",
    "start": "3357079",
    "end": "3363049"
  },
  {
    "text": "are valuable but somewhat orthogonal in as much as even someone has something working which they're able and willing",
    "start": "3363049",
    "end": "3368930"
  },
  {
    "text": "to talk about but this is largely disconnected from us coming to an",
    "start": "3368930",
    "end": "3374150"
  },
  {
    "text": "agreement of what use cases to cover oh yes they're totally orthogonal I just we",
    "start": "3374150",
    "end": "3382009"
  },
  {
    "text": "had mentioned them in line and I just wanted to call them out as potential next time welcome to Arctic who who seem",
    "start": "3382009",
    "end": "3390079"
  },
  {
    "text": "to mix the two okay yeah he should",
    "start": "3390079",
    "end": "3408619"
  },
  {
    "text": "really and I know I keep saying this but we should try and move more work into into but I like discussion today cool",
    "start": "3408619",
    "end": "3423140"
  },
  {
    "text": "thank you I've got to try to think of a joke involving observability for next time yes peace I'll put the challenge",
    "start": "3423140",
    "end": "3430130"
  },
  {
    "text": "out because I'm not a very funny person let's not actually I do wondering",
    "start": "3430130",
    "end": "3434979"
  },
  {
    "text": "you you",
    "start": "3441950",
    "end": "3448520"
  }
]
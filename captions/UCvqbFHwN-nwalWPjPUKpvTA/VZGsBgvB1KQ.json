[
  {
    "text": "okay hello everyone good afternoon uh I'm jih Che from Korea and I'd like",
    "start": "1620",
    "end": "10200"
  },
  {
    "text": "to thank everyone for participating in today's presentation despite your busy",
    "start": "10200",
    "end": "15480"
  },
  {
    "text": "schedules uh I am working at Samsung S6 as an",
    "start": "15480",
    "end": "22140"
  },
  {
    "text": "infra item I'm sorry I am uh I have been working at Samsung SDS as an infra",
    "start": "22140",
    "end": "28680"
  },
  {
    "text": "architect for about seven years and as a cloud architect for the recent three",
    "start": "28680",
    "end": "34800"
  },
  {
    "text": "years having particular uh interested in open source including kubernetes and",
    "start": "34800",
    "end": "42120"
  },
  {
    "text": "Cuba flow and I'm also proceeding with a various POC to develop the best machine",
    "start": "42120",
    "end": "49020"
  },
  {
    "text": "learning platform focusing on the components like Network server and GPU",
    "start": "49020",
    "end": "55620"
  },
  {
    "text": "and applied it to service based on my experiences as an infra architect",
    "start": "55620",
    "end": "62579"
  },
  {
    "text": "my team is currently developing a machine learning platform which is based",
    "start": "62579",
    "end": "68880"
  },
  {
    "text": "on Kiva flow and at the beginning of this year we add on the functions uh",
    "start": "68880",
    "end": "74939"
  },
  {
    "text": "that for enhancing the usability to qf flow which is on Samsung SDS Cloud",
    "start": "74939",
    "end": "81780"
  },
  {
    "text": "platform and release a keyword flow service which is consistently being",
    "start": "81780",
    "end": "87720"
  },
  {
    "text": "updated uh for those of you who are not familiar",
    "start": "87720",
    "end": "93600"
  },
  {
    "text": "with SSP Samsung Cloud platform is a cloud environment launched by Samsung",
    "start": "93600",
    "end": "100159"
  },
  {
    "text": "SDS in July last year which what virtualizes and provide buys various",
    "start": "100159",
    "end": "107460"
  },
  {
    "text": "components like Computing stories and database that are necessary for",
    "start": "107460",
    "end": "113340"
  },
  {
    "text": "corporations corporate Cloud can be used conveniently as a self-service and it",
    "start": "113340",
    "end": "121500"
  },
  {
    "text": "provides a very high quality availability and stability as I",
    "start": "121500",
    "end": "128039"
  },
  {
    "text": "mentioned earlier my team developed a keyword flow service on this sap",
    "start": "128039",
    "end": "134239"
  },
  {
    "text": "through our experience of developing a machine learning platform we've learned",
    "start": "134239",
    "end": "139920"
  },
  {
    "text": "a lot I assume that those from the field of machine learning Ai and Mr office",
    "start": "139920",
    "end": "146160"
  },
  {
    "text": "would agree with me on this the biggest lesson that we learned the on The",
    "start": "146160",
    "end": "151739"
  },
  {
    "text": "Limited cost and how important it was to utilize the GPU within that cost",
    "start": "151739",
    "end": "158819"
  },
  {
    "text": "so I'd like to introduce two cases stories on how we improve to improve",
    "start": "158819",
    "end": "166140"
  },
  {
    "text": "that part and applied it to our platform service",
    "start": "166140",
    "end": "171620"
  },
  {
    "text": "yes first of all for those who are not familiar with the Cuba flow it is a",
    "start": "171660",
    "end": "178140"
  },
  {
    "text": "machine learning are toolkit based on kubernetes and its open source projects",
    "start": "178140",
    "end": "183959"
  },
  {
    "text": "and that enables the simple scaling of motion machine learning model and",
    "start": "183959",
    "end": "189000"
  },
  {
    "text": "deployment to production qf Pro provides various components like Jupiter notebook",
    "start": "189000",
    "end": "195180"
  },
  {
    "text": "captive or pipelines and training operators that allowing data scientists",
    "start": "195180",
    "end": "201300"
  },
  {
    "text": "and machine learning Engineers to work on machine learning training high",
    "start": "201300",
    "end": "206879"
  },
  {
    "text": "performance parameter tuning and serving workflow however the components that uh",
    "start": "206879",
    "end": "213060"
  },
  {
    "text": "process process effective distributed training by combining with GPU ecosystem",
    "start": "213060",
    "end": "220200"
  },
  {
    "text": "or maximize the GPU utilization rates are really provided",
    "start": "220200",
    "end": "225900"
  },
  {
    "text": "so we proceeded with POC based on two GPU Technologies one is multi-instance",
    "start": "225900",
    "end": "234000"
  },
  {
    "text": "GPU provided by a Nvidia ampere architecture and the other one is GPU",
    "start": "234000",
    "end": "240120"
  },
  {
    "text": "director RDMA I'm gonna share the POC result for each of them today",
    "start": "240120",
    "end": "247159"
  },
  {
    "text": "uh let's first take a look at a POC on Mig with these two tables we can compare the",
    "start": "248040",
    "end": "255480"
  },
  {
    "text": "specification of GPU for data centers and for desktops used for uh experts as",
    "start": "255480",
    "end": "263400"
  },
  {
    "text": "you can see from the table on the left the GPU for data centers and servers for",
    "start": "263400",
    "end": "269520"
  },
  {
    "text": "use for AI and HPC has large resource and processing capacity it is worth two",
    "start": "269520",
    "end": "278280"
  },
  {
    "text": "teeth for huge volume training then let's look at the specification of",
    "start": "278280",
    "end": "283500"
  },
  {
    "text": "desktop GPU for export it's memory size as a four to eight",
    "start": "283500",
    "end": "289860"
  },
  {
    "text": "gigabytes at the minimum and its specification is about a half or",
    "start": "289860",
    "end": "295220"
  },
  {
    "text": "120th of a GPU for data centers this means that it is relatively less GPA",
    "start": "295220",
    "end": "303240"
  },
  {
    "text": "resource is needed for a light model development or inference task in other",
    "start": "303240",
    "end": "309300"
  },
  {
    "text": "words using one unit of GPU for data centers in AI development or inference",
    "start": "309300",
    "end": "315660"
  },
  {
    "text": "task list is a waste of resources",
    "start": "315660",
    "end": "320479"
  },
  {
    "text": "is a technology that came out to tackle this issue Mi can split one unit of GPU",
    "start": "322039",
    "end": "330900"
  },
  {
    "text": "up to seven instances and each instance can be used for one complete GPU Mrs can",
    "start": "330900",
    "end": "339240"
  },
  {
    "text": "partition GPU into a instances that each has a high bandwidth",
    "start": "339240",
    "end": "346919"
  },
  {
    "text": "memory cache and comparing core uh when various tasks like different AI",
    "start": "346919",
    "end": "355919"
  },
  {
    "text": "inference or Jupiter jobs Jupiter jobs or training jobs is uh executed in the",
    "start": "355919",
    "end": "363479"
  },
  {
    "text": "same GPU without Mig then each task completes each other each other for the",
    "start": "363479",
    "end": "371940"
  },
  {
    "text": "same resource on the other hand with Mig or the tasks are executed simultaneously",
    "start": "371940",
    "end": "378660"
  },
  {
    "text": "in different instances securing for service quality",
    "start": "378660",
    "end": "384479"
  },
  {
    "text": "and in extending the scope of a computer accelerated Computing resource to all",
    "start": "384479",
    "end": "392759"
  },
  {
    "text": "the users Mis was particularly fascinating for us to handle the large",
    "start": "392759",
    "end": "399120"
  },
  {
    "text": "scale of GPU for data centers and we thought that we can enhance the machine",
    "start": "399120",
    "end": "406860"
  },
  {
    "text": "learning efficiency by combining it with curved flow so we proceeded we proceeded",
    "start": "406860",
    "end": "414600"
  },
  {
    "text": "with a technology verification since QV is not a platform that is simply loaded",
    "start": "414600",
    "end": "422100"
  },
  {
    "text": "on operating system layer so we have to verify it in barometer",
    "start": "422100",
    "end": "427819"
  },
  {
    "text": "hypervisor virtual machine operating system kubernetes and Cube Pro consecutively",
    "start": "427819",
    "end": "435199"
  },
  {
    "text": "through numerous phases and our biggest interest was in the procedure of each",
    "start": "435199",
    "end": "442800"
  },
  {
    "text": "phase and the most efficient way in terms of",
    "start": "442800",
    "end": "450000"
  },
  {
    "text": "performance so oh I'm sorry",
    "start": "450000",
    "end": "455780"
  },
  {
    "text": "I'm sorry so",
    "start": "458400",
    "end": "463500"
  },
  {
    "text": "I oh I onto this to reached every step how to set the Miz on today's",
    "start": "465020",
    "end": "472080"
  },
  {
    "text": "presentation but however let's rather focus on the lessons that we learned",
    "start": "472080",
    "end": "480860"
  },
  {
    "text": "first we didn't work well on Cuba flow the official document to thoroughly",
    "start": "480860",
    "end": "486979"
  },
  {
    "text": "explains up to kubernetes layer and the test on the operating system layer and",
    "start": "486979",
    "end": "493979"
  },
  {
    "text": "kubernetes layer were done without any issue however we had to uh we had to",
    "start": "493979",
    "end": "500759"
  },
  {
    "text": "take up step further step further to check up the cube flow layer",
    "start": "500759",
    "end": "505800"
  },
  {
    "text": "and to sum up it works very well as you might have expected",
    "start": "505800",
    "end": "511339"
  },
  {
    "text": "this screen shows Jupiter need to build test screen that is created on Cuba flow",
    "start": "511339",
    "end": "519320"
  },
  {
    "text": "the screen on the left shows the GPU confirmation comment executed with",
    "start": "519320",
    "end": "525600"
  },
  {
    "text": "injector notebook and we can see the information of the four gigabyte site a",
    "start": "525600",
    "end": "533100"
  },
  {
    "text": "100 GPU and one Mi device of GI id9 that",
    "start": "533100",
    "end": "539220"
  },
  {
    "text": "has been located on the right is the screen that shows",
    "start": "539220",
    "end": "544320"
  },
  {
    "text": "GPU information of the node where notebook is loaded one unit of a 100 GPU",
    "start": "544320",
    "end": "551820"
  },
  {
    "text": "is divided into seven MOS devices devices and the process is located",
    "start": "551820",
    "end": "558620"
  },
  {
    "text": "to the device GI I did not in as we track the process we can see that is the",
    "start": "558620",
    "end": "566459"
  },
  {
    "text": "Jupiter Notebook on the meter so we executed simple Eminence training",
    "start": "566459",
    "end": "573600"
  },
  {
    "text": "on Jupiter notebook and as you can see it works very well with mis device",
    "start": "573600",
    "end": "580200"
  },
  {
    "text": "yeah however we faced a minor issue during this testing when Jupiter",
    "start": "580200",
    "end": "587820"
  },
  {
    "text": "notebook is created the Mis device is not detected on open source qfro",
    "start": "587820",
    "end": "594360"
  },
  {
    "text": "dashboard so let's take a closure look at this",
    "start": "594360",
    "end": "599399"
  },
  {
    "text": "the left is the screen for open source qf flow when Jupiter Note 2 is creative",
    "start": "599399",
    "end": "606240"
  },
  {
    "text": "then a CPU memory and the GPU resource can be selected but in GPU only the",
    "start": "606240",
    "end": "614580"
  },
  {
    "text": "quantity can be selected the Mis device cannot be detected so we have to update",
    "start": "614580",
    "end": "622080"
  },
  {
    "text": "the Nutri yaml 5 manually for testing and thinking that it will be very",
    "start": "622080",
    "end": "627959"
  },
  {
    "text": "inconvenient for developers who are on familiar with kubernetes so that was the",
    "start": "627959",
    "end": "634500"
  },
  {
    "text": "reason why we enhanced this part on our platform on the right is the screen for",
    "start": "634500",
    "end": "640440"
  },
  {
    "text": "creating network of a speculable service as you can see",
    "start": "640440",
    "end": "645839"
  },
  {
    "text": "we can select the tribute type type as of now we can see 10 gigabyte size",
    "start": "645839",
    "end": "652440"
  },
  {
    "text": "Mis device and GPU type support it is a set for users to select",
    "start": "652440",
    "end": "658800"
  },
  {
    "text": "instantly on the dashboard without updating your file and it will be",
    "start": "658800",
    "end": "664380"
  },
  {
    "text": "appreciated if such Mis device function is applied to open source Community",
    "start": "664380",
    "end": "670380"
  },
  {
    "text": "later then that's a more work on asset speaker",
    "start": "670380",
    "end": "677220"
  },
  {
    "text": "flow service for utilizing resource including Mi device it can be checked on",
    "start": "677220",
    "end": "683519"
  },
  {
    "text": "the dashboard image device information of the node configured in the cluster",
    "start": "683519",
    "end": "689279"
  },
  {
    "text": "can can be checked and the resource used amount can be reported and the allocate",
    "start": "689279",
    "end": "696240"
  },
  {
    "text": "allocation of resource code can be restricted and I think it's going to be",
    "start": "696240",
    "end": "701700"
  },
  {
    "text": "very useful then let's move on to the next lesson that we",
    "start": "701700",
    "end": "708480"
  },
  {
    "text": "learned we wanted to check whether the distributed training was visible on mi's",
    "start": "708480",
    "end": "715019"
  },
  {
    "text": "device although mice technology is not suitable for large volume of tasks like",
    "start": "715019",
    "end": "721760"
  },
  {
    "text": "distributed training but we just wanted to check its possibility",
    "start": "721760",
    "end": "727220"
  },
  {
    "text": "for those of you who are not familiar with the concept of distributed training",
    "start": "727220",
    "end": "733640"
  },
  {
    "text": "it involves one training job that uses numerous gpus",
    "start": "733640",
    "end": "740779"
  },
  {
    "text": "that to execute Trading it can be executed in one node or",
    "start": "740779",
    "end": "748740"
  },
  {
    "text": "martinus like the one in a picture we are going to test this DDP drop in pi",
    "start": "748740",
    "end": "756420"
  },
  {
    "text": "torch using an outstanding technology called cuda specialized for NVIDIA GPU",
    "start": "756420",
    "end": "764579"
  },
  {
    "text": "for task execution device is located using Cuda command in device in the",
    "start": "764579",
    "end": "770880"
  },
  {
    "text": "device let's look at those specific example on the left is a distributed training",
    "start": "770880",
    "end": "777600"
  },
  {
    "text": "Yammer allocating four gpus to one part and running total of two parts as you",
    "start": "777600",
    "end": "785880"
  },
  {
    "text": "can see on the right by executing it then the pro or the process are located",
    "start": "785880",
    "end": "791779"
  },
  {
    "text": "in the one node and if we look at the executed low then",
    "start": "791779",
    "end": "799019"
  },
  {
    "text": "we can see that Quran device has been allocated properly and the task has been",
    "start": "799019",
    "end": "805440"
  },
  {
    "text": "completed this is the DDP that generally takes place in GPU then let's allocate",
    "start": "805440",
    "end": "813360"
  },
  {
    "text": "the same task with mis device only it is the distributed trading Yammer that runs",
    "start": "813360",
    "end": "820260"
  },
  {
    "text": "total of two parts by allocating a two Mi devices for each part as you can see",
    "start": "820260",
    "end": "827700"
  },
  {
    "text": "on the right an error occurs in runtime of qur device detection",
    "start": "827700",
    "end": "833220"
  },
  {
    "text": "then does this mean that distributed training is not visible on Mig",
    "start": "833220",
    "end": "840560"
  },
  {
    "text": "for accurate accuracy verification we allocated one Mis device for each part",
    "start": "840560",
    "end": "848519"
  },
  {
    "text": "for the same task as you can see on the right now moist device was located",
    "start": "848519",
    "end": "855060"
  },
  {
    "text": "properly and distributed training was executed without any issue we found out",
    "start": "855060",
    "end": "863459"
  },
  {
    "text": "that distributed training is visible with mis device but the task is",
    "start": "863459",
    "end": "870660"
  },
  {
    "text": "executable when only one device is located for each part",
    "start": "870660",
    "end": "877860"
  },
  {
    "text": "then lastly let's take a look at the performance to sum up for lighter Motors",
    "start": "877860",
    "end": "884820"
  },
  {
    "text": "it was three to seven times more efficient on Mrs device we executed",
    "start": "884820",
    "end": "891180"
  },
  {
    "text": "model training in both barometer and virtual machine environment we compared",
    "start": "891180",
    "end": "896880"
  },
  {
    "text": "the execution time for the method that executes the execute the same model",
    "start": "896880",
    "end": "902779"
  },
  {
    "text": "consecutively seven times in the in one GPU and the method that executes",
    "start": "902779",
    "end": "909139"
  },
  {
    "text": "simultaneously on 7mis devices we saw three times better performance for",
    "start": "909139",
    "end": "915540"
  },
  {
    "text": "heavier models like RNN and five to seven times better performance on a",
    "start": "915540",
    "end": "922260"
  },
  {
    "text": "light lighter models like CNN and resonant 18. we found this variable",
    "start": "922260",
    "end": "928620"
  },
  {
    "text": "enough to apply to our SSP service",
    "start": "928620",
    "end": "933980"
  },
  {
    "text": "furthermore we found some points to consider for kubernetes were testing and",
    "start": "934040",
    "end": "940800"
  },
  {
    "text": "if you're interested in it then you can take a look at the document which we",
    "start": "940800",
    "end": "946260"
  },
  {
    "text": "have written in a specific technology guide so",
    "start": "946260",
    "end": "952019"
  },
  {
    "text": "so far we went over the POC related to",
    "start": "952019",
    "end": "957120"
  },
  {
    "text": "Mi technology with which GPU is divided into seven instances at Max and",
    "start": "957120",
    "end": "964740"
  },
  {
    "text": "efficient use of the peel is possible even for only one unit of zipu for",
    "start": "964740",
    "end": "971399"
  },
  {
    "text": "numerous users were on accurate applications by using Mig however it is",
    "start": "971399",
    "end": "978240"
  },
  {
    "text": "suitable for data Sciences model development developing tasks or inference task and not for large skills",
    "start": "978240",
    "end": "986639"
  },
  {
    "text": "test like distributed training and it allows more efficient use of GPU",
    "start": "986639",
    "end": "993540"
  },
  {
    "text": "resources if it tries to wear then",
    "start": "993540",
    "end": "999680"
  },
  {
    "text": "let's move on to the record case study I'd like to introduce POC with related",
    "start": "999680",
    "end": "1007399"
  },
  {
    "text": "to review director RDMA technology as the size of the model gets bigger and",
    "start": "1007399",
    "end": "1013759"
  },
  {
    "text": "the amount of the data is increases to enhance the accuracy of deep learning we",
    "start": "1013759",
    "end": "1020600"
  },
  {
    "text": "need countries the computers and efficient distributed processing I'm",
    "start": "1020600",
    "end": "1026360"
  },
  {
    "text": "going to explain GPU direct RDMA technology for working out of GPU",
    "start": "1026360",
    "end": "1031900"
  },
  {
    "text": "distributed training and system architecture as well as some examples",
    "start": "1031900",
    "end": "1038058"
  },
  {
    "text": "and share the performance the verification result first of all GPU art direct RDMA is a",
    "start": "1038059",
    "end": "1046520"
  },
  {
    "text": "function that allows direct access to uh to the peel memory between GPU GPU for",
    "start": "1046520",
    "end": "1055340"
  },
  {
    "text": "GPU communication between remote nodes and uh",
    "start": "1055340",
    "end": "1060500"
  },
  {
    "text": "through the network interface data i o between GPU GPU memories is processed",
    "start": "1060500",
    "end": "1068480"
  },
  {
    "text": "without involving CPU to understand it better let's take a",
    "start": "1068480",
    "end": "1075080"
  },
  {
    "text": "look at four cases the two diagrams at the top I'll show",
    "start": "1075080",
    "end": "1080660"
  },
  {
    "text": "the different attributes communicating within in a single node and the the",
    "start": "1080660",
    "end": "1086299"
  },
  {
    "text": "other two at the bottom choose the communication between the periods of the remote node first let's take a look at",
    "start": "1086299",
    "end": "1095000"
  },
  {
    "text": "the communication of GPU within in a single load we without GPU director peer-to-peer",
    "start": "1095000",
    "end": "1103460"
  },
  {
    "text": "though who's the CPU must transfer the data from the GPU memory to the host",
    "start": "1103460",
    "end": "1110000"
  },
  {
    "text": "memory and then from the host memory to the the other second gpus memory",
    "start": "1110000",
    "end": "1116720"
  },
  {
    "text": "but with the GPU directed peer-to-peer the data can be transferred very",
    "start": "1116720",
    "end": "1123260"
  },
  {
    "text": "directly from a GPU memory to other the other GPS memory",
    "start": "1123260",
    "end": "1130580"
  },
  {
    "text": "it works similarly to for internet communication as well we distribute",
    "start": "1130580",
    "end": "1137780"
  },
  {
    "text": "without Triple direct RDMA then there are what what what we copied from the",
    "start": "1137780",
    "end": "1145520"
  },
  {
    "text": "GPU memory to the host memory a host memory and then from the host memory to",
    "start": "1145520",
    "end": "1151280"
  },
  {
    "text": "a remote host but with GPU director RDMA there is a transferred directly from the",
    "start": "1151280",
    "end": "1160220"
  },
  {
    "text": "pure memory of it is sent via RDMA network adapter like infiniband to the",
    "start": "1160220",
    "end": "1167660"
  },
  {
    "text": "remote host with no CPU environment it seems that the communication will be",
    "start": "1167660",
    "end": "1174080"
  },
  {
    "text": "done more quickly without the pure environment so",
    "start": "1174080",
    "end": "1180740"
  },
  {
    "text": "then what do we need to use GPU direct RDMA various environmental settings is",
    "start": "1180740",
    "end": "1188179"
  },
  {
    "text": "necessary for GPU director RDMA applying GPU director resume to Cuba flow for",
    "start": "1188179",
    "end": "1195380"
  },
  {
    "text": "Hardware we need Network equipment that supports academic communication and for",
    "start": "1195380",
    "end": "1202100"
  },
  {
    "text": "our POC we've set bare metal environment and with infinite event network adapter",
    "start": "1202100",
    "end": "1208160"
  },
  {
    "text": "and Nvidia a100 GPU in order to detect the GPU and network adapter driver and",
    "start": "1208160",
    "end": "1216740"
  },
  {
    "text": "turkey setting is necessary for operating operating system layer and kubernetes system layer the parts in",
    "start": "1216740",
    "end": "1224539"
  },
  {
    "text": "light green are the modules for using GPU and those in dark blue blue are the",
    "start": "1224539",
    "end": "1232700"
  },
  {
    "text": "modules for using a network adapter let's first look at OS layer we have to",
    "start": "1232700",
    "end": "1239960"
  },
  {
    "text": "set forward things displayed in the in diagram when Nvidia developer is is stored to",
    "start": "1239960",
    "end": "1248140"
  },
  {
    "text": "have GP recognized and or as an OS and",
    "start": "1248140",
    "end": "1253820"
  },
  {
    "text": "the Nvidia container toolkit is set to be run on kubernetes then it is possible",
    "start": "1253820",
    "end": "1260600"
  },
  {
    "text": "to use GPU after installing all faded driver to have infinite event network",
    "start": "1260600",
    "end": "1267080"
  },
  {
    "text": "adapter recognized and installing a web pyramid driver that supports RDMA",
    "start": "1267080",
    "end": "1273919"
  },
  {
    "text": "communication then setting of os layer is completed when the settings layer is",
    "start": "1273919",
    "end": "1281660"
  },
  {
    "text": "done then let's take a look at kubernetes layer as you can see we have",
    "start": "1281660",
    "end": "1287480"
  },
  {
    "text": "to set Nvidia device plugin and our daily measure the device",
    "start": "1287480",
    "end": "1293299"
  },
  {
    "text": "to current layer a video device plugin is a demo set that automatically",
    "start": "1293299",
    "end": "1299240"
  },
  {
    "text": "recognizes and runs GPU in kubernetes layer it is mandatory for using GPU in",
    "start": "1299240",
    "end": "1306799"
  },
  {
    "text": "kubernetes if RDMA shares a device that allows access between Parts by sharing",
    "start": "1306799",
    "end": "1314120"
  },
  {
    "text": "the RDA divide RDMA device between the remote kubernetes nodes then",
    "start": "1314120",
    "end": "1321559"
  },
  {
    "text": "we are ready to use GPU direct RDMA in kubernetes layer the part in yellow is",
    "start": "1321559",
    "end": "1329419"
  },
  {
    "text": "the container in this layer and we used Cuda cdnn and nicker for our POC then",
    "start": "1329419",
    "end": "1338299"
  },
  {
    "text": "early preparation is completed to use GPU director rdb",
    "start": "1338299",
    "end": "1344539"
  },
  {
    "text": "let's take a look at the sample that we tested it is a Yammer that executes a",
    "start": "1344539",
    "end": "1351679"
  },
  {
    "text": "distributed training on image segmentation model using training",
    "start": "1351679",
    "end": "1356780"
  },
  {
    "text": "Operator by touch drop embedded in Cuba flow we set the party in red rectangle to use",
    "start": "1356780",
    "end": "1365780"
  },
  {
    "text": "GPU direct RDMA first setting over two Osos environment variables in container",
    "start": "1365780",
    "end": "1373940"
  },
  {
    "text": "image is necessary one variable is for knicker communication using infiniband and the",
    "start": "1373940",
    "end": "1381980"
  },
  {
    "text": "other is for GPU direct RDMA level then after we designate our damaturated",
    "start": "1381980",
    "end": "1389780"
  },
  {
    "text": "device with its the custom resource set in kubernetes layer in previous in in",
    "start": "1389780",
    "end": "1396740"
  },
  {
    "text": "advance then set the security contact for IPs",
    "start": "1396740",
    "end": "1402260"
  },
  {
    "text": "lock then we can proceed with the test we want",
    "start": "1402260",
    "end": "1408159"
  },
  {
    "text": "let's look at the log that has actually been executed the Osos environment",
    "start": "1408460",
    "end": "1416000"
  },
  {
    "text": "variable is set X has been extra uh sorry is that properly",
    "start": "1416000",
    "end": "1425000"
  },
  {
    "text": "and we can see the a100 GPU",
    "start": "1425000",
    "end": "1430159"
  },
  {
    "text": "and the infinite event is set to the root this means that Infinity is not",
    "start": "1430159",
    "end": "1436360"
  },
  {
    "text": "disabled in other words we use in free event using GPU direct RDMA we can see a",
    "start": "1436360",
    "end": "1444500"
  },
  {
    "text": "nickel log the clock where training takes place",
    "start": "1444500",
    "end": "1449600"
  },
  {
    "text": "how effective ODB then let's see",
    "start": "1449600",
    "end": "1454659"
  },
  {
    "text": "this is on throughput measured by increasing the number of gpus for image",
    "start": "1454659",
    "end": "1462500"
  },
  {
    "text": "classification detection and segmentation model and natural language",
    "start": "1462500",
    "end": "1467840"
  },
  {
    "text": "understanding model in our POC environment we increased the number of GPU from one",
    "start": "1467840",
    "end": "1475340"
  },
  {
    "text": "to two four eight six and sixteen and used for use a total of 16 gpus for the",
    "start": "1475340",
    "end": "1483559"
  },
  {
    "text": "red rectangle and it is the comparison of performance results between the green",
    "start": "1483559",
    "end": "1490280"
  },
  {
    "text": "bar that you use the triple direct RDMA and the blue bird that does not",
    "start": "1490280",
    "end": "1496940"
  },
  {
    "text": "it differs but generally we can expect the effect",
    "start": "1496940",
    "end": "1503179"
  },
  {
    "text": "to be around 114 to 612 percentage",
    "start": "1503179",
    "end": "1510020"
  },
  {
    "text": "uh basically as the number of GPU increases the performance improves but",
    "start": "1510020",
    "end": "1517760"
  },
  {
    "text": "in some model the performance of Martino's may be undermined if a huge",
    "start": "1517760",
    "end": "1523580"
  },
  {
    "text": "value of parameter communication uh consist continuously takes place in the",
    "start": "1523580",
    "end": "1529820"
  },
  {
    "text": "model but by using GPU direct RDMA it can communicate more effectively",
    "start": "1529820",
    "end": "1537799"
  },
  {
    "text": "as we saw the the performance verification result we achieved an",
    "start": "1537799",
    "end": "1544100"
  },
  {
    "text": "extremely satisfying the result and by applying this with release infiniband",
    "start": "1544100",
    "end": "1550700"
  },
  {
    "text": "based multi-nodes GPU service on SSP last month",
    "start": "1550700",
    "end": "1557120"
  },
  {
    "text": "mm-hmm and yes oh yes that's it I think this is",
    "start": "1557120",
    "end": "1563600"
  },
  {
    "text": "your eyes or I wanted to share today uh the presentation was based on the cases",
    "start": "1563600",
    "end": "1571100"
  },
  {
    "text": "from our experience and although it was a brief explanation completed in about",
    "start": "1571100",
    "end": "1578059"
  },
  {
    "text": "30 minutes due to the time limit but I want to mention I want to mention that",
    "start": "1578059",
    "end": "1584059"
  },
  {
    "text": "we have gone through a countless dryer and error many of you working in this",
    "start": "1584059",
    "end": "1590539"
  },
  {
    "text": "field maybe or will be going through the same difficulties so I hope you find my",
    "start": "1590539",
    "end": "1597980"
  },
  {
    "text": "presentation a little bit helpful and I'd like to finish today's",
    "start": "1597980",
    "end": "1604000"
  },
  {
    "text": "presentation so thank you for your time and attention and stay uh and have a",
    "start": "1604000",
    "end": "1612620"
  },
  {
    "text": "safe trip and thank you thank you [Applause]",
    "start": "1612620",
    "end": "1622780"
  },
  {
    "text": "and also you can uh and also you can download this presentation at the schedule.com",
    "start": "1623299",
    "end": "1629720"
  },
  {
    "text": "and any question",
    "start": "1629720",
    "end": "1633278"
  },
  {
    "text": "uh Yes actually we uh we proceeded with the POC based on Docker but basically",
    "start": "1640240",
    "end": "1647299"
  },
  {
    "text": "our asset specific kubernetes service is based on container D so we basically",
    "start": "1647299",
    "end": "1654700"
  },
  {
    "text": "processed with the container the base too",
    "start": "1654700",
    "end": "1659320"
  },
  {
    "text": "yes it is based on decorative",
    "start": "1660620",
    "end": "1665860"
  },
  {
    "text": "oh yes okay and thank you",
    "start": "1666760",
    "end": "1673240"
  },
  {
    "text": "in one of your first slides it looked like you were having trouble on kubeflow",
    "start": "1674840",
    "end": "1681100"
  },
  {
    "text": "recognizing the migs and then you mentioned that you had to apply changes",
    "start": "1681100",
    "end": "1687500"
  },
  {
    "text": "but I wasn't clear if the changes in the yaml file were only applied to the",
    "start": "1687500",
    "end": "1693100"
  },
  {
    "text": "Samsung SCP service or if it was something that",
    "start": "1693100",
    "end": "1698779"
  },
  {
    "text": "got committed back to cube flow I'm sorry could you take up your mask and then",
    "start": "1698779",
    "end": "1705559"
  },
  {
    "text": "please I will speak okay earlier you had trouble",
    "start": "1705559",
    "end": "1712820"
  },
  {
    "text": "having kubeflow recognize your migs your GPU migs you mentioned that you had to",
    "start": "1712820",
    "end": "1720740"
  },
  {
    "text": "apply changes to some yaml files so that Cube flow could see your migs but I",
    "start": "1720740",
    "end": "1728240"
  },
  {
    "text": "wasn't sure it it wasn't clear if those changes were applied to the Samsung",
    "start": "1728240",
    "end": "1735820"
  },
  {
    "text": "SCP platform or if they were committed back to cube flow after really we",
    "start": "1735820",
    "end": "1741940"
  },
  {
    "text": "operated to our sscp flow service okay",
    "start": "1741940",
    "end": "1747020"
  },
  {
    "text": "so does that mean then that Cube flow may still have trouble oh yes identifying images thank you",
    "start": "1747020",
    "end": "1755380"
  },
  {
    "text": "any other questions oh okay",
    "start": "1758000",
    "end": "1762700"
  },
  {
    "text": "when you're doing your distributed testing with Mig right you're using big instances to run",
    "start": "1763820",
    "end": "1770600"
  },
  {
    "text": "distributed with a single Mig instance in each container",
    "start": "1770600",
    "end": "1775779"
  },
  {
    "text": "uh what was the interconnect was it just using ethernet as the interconnect because",
    "start": "1775779",
    "end": "1781940"
  },
  {
    "text": "of the lack of GPU Direct when you're using Mig",
    "start": "1781940",
    "end": "1787760"
  },
  {
    "text": "I'm sorry I'm sorry could you take over your mask please yeah I'm sorry",
    "start": "1787760",
    "end": "1794419"
  },
  {
    "text": "uh one of the first tests you were running was uh distributed training in Mig right you",
    "start": "1794419",
    "end": "1803000"
  },
  {
    "text": "did it with uh two Mig instances per container and it failed but with a single Mig instance per container it",
    "start": "1803000",
    "end": "1811159"
  },
  {
    "text": "worked what was the interconnect actually uh it is the",
    "start": "1811159",
    "end": "1818240"
  },
  {
    "text": "NBA it is based on a medium pair architecture so they they designed uh",
    "start": "1818240",
    "end": "1825500"
  },
  {
    "text": "with uh so I'm guessing it wasn't using infiniband it was falling back to",
    "start": "1825500",
    "end": "1831380"
  },
  {
    "text": "ethernet in those cases interconnect like the for the",
    "start": "1831380",
    "end": "1838580"
  },
  {
    "text": "distributed Communications uh it is with infinite event nothing it",
    "start": "1838580",
    "end": "1845000"
  },
  {
    "text": "was using infiniband with a single Mig instance no actually infinite event is for the",
    "start": "1845000",
    "end": "1851720"
  },
  {
    "text": "remote nodes in Internet so internet is doesn't need any infinite event network",
    "start": "1851720",
    "end": "1857240"
  },
  {
    "text": "adapter it is a communicate within the MP3 in the single node",
    "start": "1857240",
    "end": "1865700"
  },
  {
    "text": "so that does not need any infinite band in a single note in us when you're doing the distributed",
    "start": "1865700",
    "end": "1873860"
  },
  {
    "text": "test with single Mig instances right yeah it is uh so so you were not",
    "start": "1873860",
    "end": "1879679"
  },
  {
    "text": "requesting uh RDMA HCA for those pods",
    "start": "1879679",
    "end": "1885279"
  },
  {
    "text": "or appropriate",
    "start": "1885279",
    "end": "1889279"
  },
  {
    "text": "I'm sorry if you have any question then you can also email me then",
    "start": "1891679",
    "end": "1898220"
  },
  {
    "text": "I will answer that I'm very sorry any other characters",
    "start": "1898220",
    "end": "1905440"
  },
  {
    "text": "okay then I think that that's it thank you",
    "start": "1905480",
    "end": "1911539"
  },
  {
    "text": "for your time again [Applause]",
    "start": "1911539",
    "end": "1916950"
  }
]
[
  {
    "start": "0",
    "end": "32000"
  },
  {
    "text": "hello everyone",
    "start": "1120",
    "end": "2399"
  },
  {
    "text": "i am ganesh vaneker i am one of the",
    "start": "2399",
    "end": "5040"
  },
  {
    "text": "prometheus team member and i am also a",
    "start": "5040",
    "end": "8160"
  },
  {
    "text": "maintainer of prometheus dsdb",
    "start": "8160",
    "end": "12240"
  },
  {
    "text": "and i am dieter plating",
    "start": "12240",
    "end": "14320"
  },
  {
    "text": "i've been working on monitoring systems",
    "start": "14320",
    "end": "15920"
  },
  {
    "text": "for about 10 years but i've never",
    "start": "15920",
    "end": "18400"
  },
  {
    "text": "actually contributed to prometheus",
    "start": "18400",
    "end": "20000"
  },
  {
    "text": "before so this is kind of my first time",
    "start": "20000",
    "end": "22400"
  },
  {
    "text": "working with tsdb and i'm really",
    "start": "22400",
    "end": "24000"
  },
  {
    "text": "enjoying it so far",
    "start": "24000",
    "end": "25519"
  },
  {
    "text": "and i really enjoy histograms so when i",
    "start": "25519",
    "end": "27680"
  },
  {
    "text": "had the chance to work on this project i",
    "start": "27680",
    "end": "29439"
  },
  {
    "text": "i was very excited",
    "start": "29439",
    "end": "32800"
  },
  {
    "text": "so our colleague jordan robinstein",
    "start": "33520",
    "end": "36079"
  },
  {
    "text": "already gave many presentations about",
    "start": "36079",
    "end": "39920"
  },
  {
    "text": "histograms and how they're currently",
    "start": "39920",
    "end": "41440"
  },
  {
    "text": "implemented in prometheus",
    "start": "41440",
    "end": "43600"
  },
  {
    "text": "what some of the shortcomings are and",
    "start": "43600",
    "end": "45280"
  },
  {
    "text": "his ideas for better histograms",
    "start": "45280",
    "end": "49280"
  },
  {
    "start": "49000",
    "end": "120000"
  },
  {
    "text": "um but",
    "start": "49680",
    "end": "50800"
  },
  {
    "text": "first we should probably just do a quick",
    "start": "50800",
    "end": "52399"
  },
  {
    "text": "recap what is a histogram anyway so",
    "start": "52399",
    "end": "54879"
  },
  {
    "text": "basically a histogram is a way to",
    "start": "54879",
    "end": "58000"
  },
  {
    "text": "categorize your numeric observations",
    "start": "58000",
    "end": "60960"
  },
  {
    "text": "into ranges",
    "start": "60960",
    "end": "62399"
  },
  {
    "text": "and this is very useful for looking at",
    "start": "62399",
    "end": "64478"
  },
  {
    "text": "distributions of data for example for",
    "start": "64479",
    "end": "66400"
  },
  {
    "text": "latency metrics",
    "start": "66400",
    "end": "67840"
  },
  {
    "text": "so in this example here on the left you",
    "start": "67840",
    "end": "70320"
  },
  {
    "text": "can see",
    "start": "70320",
    "end": "71439"
  },
  {
    "text": "that",
    "start": "71439",
    "end": "72560"
  },
  {
    "text": "there were three observations that were",
    "start": "72560",
    "end": "74960"
  },
  {
    "text": "smaller or equal to 0.25 then there were",
    "start": "74960",
    "end": "78400"
  },
  {
    "text": "six observations between 0.25 and and a",
    "start": "78400",
    "end": "81520"
  },
  {
    "text": "half",
    "start": "81520",
    "end": "82400"
  },
  {
    "text": "and so forth",
    "start": "82400",
    "end": "83680"
  },
  {
    "text": "so this is a really useful way to get a",
    "start": "83680",
    "end": "86159"
  },
  {
    "text": "good understanding of your distribution",
    "start": "86159",
    "end": "87759"
  },
  {
    "text": "of data it lets you calculate",
    "start": "87759",
    "end": "89920"
  },
  {
    "text": "percentiles and so forth",
    "start": "89920",
    "end": "93438"
  },
  {
    "text": "the way this is currently implemented in",
    "start": "94000",
    "end": "96079"
  },
  {
    "text": "prometheus is you have a separate series",
    "start": "96079",
    "end": "99040"
  },
  {
    "text": "for every single bucket so you can see",
    "start": "99040",
    "end": "101200"
  },
  {
    "text": "here you have your different buckets",
    "start": "101200",
    "end": "103119"
  },
  {
    "text": "they all have a label declaring",
    "start": "103119",
    "end": "105920"
  },
  {
    "text": "one of the bounds and of course they",
    "start": "105920",
    "end": "107840"
  },
  {
    "text": "have the number of metrics in each",
    "start": "107840",
    "end": "110720"
  },
  {
    "text": "and then you also have some additional",
    "start": "110720",
    "end": "112399"
  },
  {
    "text": "series for example a sum series with the",
    "start": "112399",
    "end": "115040"
  },
  {
    "text": "sum of all the samples and the count",
    "start": "115040",
    "end": "117119"
  },
  {
    "text": "which counts all the samples",
    "start": "117119",
    "end": "120640"
  },
  {
    "start": "120000",
    "end": "233000"
  },
  {
    "text": "so there are some shortcomings here that",
    "start": "121360",
    "end": "124000"
  },
  {
    "text": "we intend to improve on",
    "start": "124000",
    "end": "126320"
  },
  {
    "text": "but first of all of course whatever",
    "start": "126320",
    "end": "128399"
  },
  {
    "text": "currently works should keep working",
    "start": "128399",
    "end": "130080"
  },
  {
    "text": "that's kind of obvious",
    "start": "130080",
    "end": "132160"
  },
  {
    "text": "um the second one",
    "start": "132160",
    "end": "134640"
  },
  {
    "text": "this is kind of a",
    "start": "134640",
    "end": "136720"
  },
  {
    "text": "one of the bigger problems i would say",
    "start": "136720",
    "end": "138080"
  },
  {
    "text": "with the current implementation of",
    "start": "138080",
    "end": "139200"
  },
  {
    "text": "histograms is that you have to",
    "start": "139200",
    "end": "142239"
  },
  {
    "text": "manually define your buckets and you",
    "start": "142239",
    "end": "144319"
  },
  {
    "text": "basically have to make a guess around",
    "start": "144319",
    "end": "147200"
  },
  {
    "text": "what the values will look like",
    "start": "147200",
    "end": "149120"
  },
  {
    "text": "and then hopefully",
    "start": "149120",
    "end": "150640"
  },
  {
    "text": "you know your data won't go out of",
    "start": "150640",
    "end": "152000"
  },
  {
    "text": "bounds or you'll lose precision and it's",
    "start": "152000",
    "end": "154239"
  },
  {
    "text": "kind of a clunky method",
    "start": "154239",
    "end": "157840"
  },
  {
    "text": "so in the new version we would rather",
    "start": "158160",
    "end": "160000"
  },
  {
    "text": "just do away with that completely and",
    "start": "160000",
    "end": "161760"
  },
  {
    "text": "just automatically",
    "start": "161760",
    "end": "164080"
  },
  {
    "text": "come up with all the right bucket sizes",
    "start": "164080",
    "end": "166640"
  },
  {
    "text": "third we want to have",
    "start": "166640",
    "end": "168400"
  },
  {
    "text": "correct aggregation both across time and",
    "start": "168400",
    "end": "170959"
  },
  {
    "text": "also across labels and especially when",
    "start": "170959",
    "end": "173920"
  },
  {
    "text": "you have histograms with different",
    "start": "173920",
    "end": "175360"
  },
  {
    "text": "bucket layouts those different layouts",
    "start": "175360",
    "end": "177680"
  },
  {
    "text": "should be chosen so that they are",
    "start": "177680",
    "end": "179760"
  },
  {
    "text": "compatible and mergable basically",
    "start": "179760",
    "end": "182800"
  },
  {
    "text": "so that you don't lose uh",
    "start": "182800",
    "end": "185040"
  },
  {
    "text": "that you can correctly aggregate them",
    "start": "185040",
    "end": "186560"
  },
  {
    "text": "and don't lose any uh data quality",
    "start": "186560",
    "end": "190239"
  },
  {
    "text": "and then",
    "start": "190239",
    "end": "191280"
  },
  {
    "text": "of course you need to be able to",
    "start": "191280",
    "end": "193840"
  },
  {
    "text": "have very accurate estimations you need",
    "start": "193840",
    "end": "196000"
  },
  {
    "text": "to have a low error rate and you so that",
    "start": "196000",
    "end": "198000"
  },
  {
    "text": "you can compute correct quantiles and",
    "start": "198000",
    "end": "200480"
  },
  {
    "text": "percentage estimations",
    "start": "200480",
    "end": "202800"
  },
  {
    "text": "and finally we believe that if we can",
    "start": "202800",
    "end": "205200"
  },
  {
    "text": "lower the cost of the histograms",
    "start": "205200",
    "end": "209519"
  },
  {
    "text": "then we can make partitioning much more",
    "start": "209519",
    "end": "211280"
  },
  {
    "text": "feasible because i suspect that right",
    "start": "211280",
    "end": "213920"
  },
  {
    "text": "now many",
    "start": "213920",
    "end": "214879"
  },
  {
    "text": "instagram users",
    "start": "214879",
    "end": "216720"
  },
  {
    "text": "don't partition as much as they can like",
    "start": "216720",
    "end": "219440"
  },
  {
    "text": "for example partitioning by an http",
    "start": "219440",
    "end": "222480"
  },
  {
    "text": "status code label or by a route or a",
    "start": "222480",
    "end": "224879"
  },
  {
    "text": "path label is currently not not so",
    "start": "224879",
    "end": "227280"
  },
  {
    "text": "common but if we if we make histograms",
    "start": "227280",
    "end": "229440"
  },
  {
    "text": "much cheaper then you can partition as",
    "start": "229440",
    "end": "231840"
  },
  {
    "text": "much as you want",
    "start": "231840",
    "end": "234480"
  },
  {
    "start": "233000",
    "end": "252000"
  },
  {
    "text": "there is a big design dock that bjorn",
    "start": "234480",
    "end": "236720"
  },
  {
    "text": "wrote",
    "start": "236720",
    "end": "237920"
  },
  {
    "text": "it goes in the design",
    "start": "237920",
    "end": "240959"
  },
  {
    "text": "very in depth and it's a very",
    "start": "240959",
    "end": "242080"
  },
  {
    "text": "interesting read",
    "start": "242080",
    "end": "243599"
  },
  {
    "text": "so if you want to understand it more you",
    "start": "243599",
    "end": "245519"
  },
  {
    "text": "should look at the dark because",
    "start": "245519",
    "end": "246640"
  },
  {
    "text": "currently",
    "start": "246640",
    "end": "247599"
  },
  {
    "text": "in this presentation we can only really",
    "start": "247599",
    "end": "249439"
  },
  {
    "text": "cover a small bit of the design",
    "start": "249439",
    "end": "253439"
  },
  {
    "start": "252000",
    "end": "265000"
  },
  {
    "text": "so we recently had a hackathon at",
    "start": "253680",
    "end": "256000"
  },
  {
    "text": "grafana labs so beyond detail and i",
    "start": "256000",
    "end": "258880"
  },
  {
    "text": "thought it would be cool to get this",
    "start": "258880",
    "end": "261040"
  },
  {
    "text": "design dock into a working prototype",
    "start": "261040",
    "end": "265199"
  },
  {
    "start": "265000",
    "end": "363000"
  },
  {
    "text": "and before we jump into the prototype",
    "start": "266000",
    "end": "268400"
  },
  {
    "text": "let's see why high resolution histograms",
    "start": "268400",
    "end": "270800"
  },
  {
    "text": "are so useful by the way the heat map",
    "start": "270800",
    "end": "272960"
  },
  {
    "text": "that you are seeing right now is reading",
    "start": "272960",
    "end": "275120"
  },
  {
    "text": "the data from our prototype itself so",
    "start": "275120",
    "end": "277919"
  },
  {
    "text": "let's see what we can",
    "start": "277919",
    "end": "279759"
  },
  {
    "text": "figure out from this heat map initially",
    "start": "279759",
    "end": "282160"
  },
  {
    "text": "the request i have some kind of short",
    "start": "282160",
    "end": "284880"
  },
  {
    "text": "band of latencies and then after some",
    "start": "284880",
    "end": "288000"
  },
  {
    "text": "time the latency stabilizes and you can",
    "start": "288000",
    "end": "290960"
  },
  {
    "text": "see there are way a lot of request for",
    "start": "290960",
    "end": "294080"
  },
  {
    "text": "some buckets which show up as red",
    "start": "294080",
    "end": "296400"
  },
  {
    "text": "and after some time a new canary was",
    "start": "296400",
    "end": "299120"
  },
  {
    "text": "tested and you can see the latency",
    "start": "299120",
    "end": "301440"
  },
  {
    "text": "dropped and but it became less practical",
    "start": "301440",
    "end": "304320"
  },
  {
    "text": "predictable because it was spread around",
    "start": "304320",
    "end": "306479"
  },
  {
    "text": "the big time and you can clearly see",
    "start": "306479",
    "end": "309199"
  },
  {
    "text": "when this new canary was deployed into",
    "start": "309199",
    "end": "311600"
  },
  {
    "text": "the prod",
    "start": "311600",
    "end": "312880"
  },
  {
    "text": "and all the latencies just dropped and",
    "start": "312880",
    "end": "316800"
  },
  {
    "text": "spread across a big range and after some",
    "start": "316800",
    "end": "319280"
  },
  {
    "text": "time",
    "start": "319280",
    "end": "320720"
  },
  {
    "text": "a part of the system started behaving",
    "start": "320720",
    "end": "323280"
  },
  {
    "text": "weirdly and the latency shot up you can",
    "start": "323280",
    "end": "326639"
  },
  {
    "text": "see two bands of slowness there it could",
    "start": "326639",
    "end": "329840"
  },
  {
    "text": "be",
    "start": "329840",
    "end": "330560"
  },
  {
    "text": "some heavy operation or some cold cash",
    "start": "330560",
    "end": "333600"
  },
  {
    "text": "and you can see exactly the time when",
    "start": "333600",
    "end": "335919"
  },
  {
    "text": "the issue started and the issues when",
    "start": "335919",
    "end": "338400"
  },
  {
    "text": "the issue stopped and after the issue",
    "start": "338400",
    "end": "340639"
  },
  {
    "text": "had stopped",
    "start": "340639",
    "end": "342160"
  },
  {
    "text": "the latency just kept on increasing and",
    "start": "342160",
    "end": "344720"
  },
  {
    "text": "increasing until it became stable and",
    "start": "344720",
    "end": "347520"
  },
  {
    "text": "within a band",
    "start": "347520",
    "end": "349759"
  },
  {
    "text": "so this is the kind of",
    "start": "349759",
    "end": "353199"
  },
  {
    "text": "visualization that we would like to get",
    "start": "353199",
    "end": "355039"
  },
  {
    "text": "from high resolution histograms which",
    "start": "355039",
    "end": "357520"
  },
  {
    "text": "not",
    "start": "357520",
    "end": "358800"
  },
  {
    "text": "feasible right now because of expensive",
    "start": "358800",
    "end": "361120"
  },
  {
    "text": "buckets",
    "start": "361120",
    "end": "363600"
  },
  {
    "start": "363000",
    "end": "390000"
  },
  {
    "text": "but in this prototype like in this stock",
    "start": "363919",
    "end": "367120"
  },
  {
    "text": "we are going to talk about three things",
    "start": "367120",
    "end": "369199"
  },
  {
    "text": "one is how do we expose this uh higher",
    "start": "369199",
    "end": "371840"
  },
  {
    "text": "resolution histograms",
    "start": "371840",
    "end": "373680"
  },
  {
    "text": "and how do we scrape it and then how can",
    "start": "373680",
    "end": "376560"
  },
  {
    "text": "we encode these histograms efficiently",
    "start": "376560",
    "end": "379520"
  },
  {
    "text": "into a tsdb",
    "start": "379520",
    "end": "381039"
  },
  {
    "text": "and we benchmark the space",
    "start": "381039",
    "end": "384560"
  },
  {
    "text": "taken by these new histograms in the tsd",
    "start": "384560",
    "end": "389600"
  },
  {
    "start": "390000",
    "end": "502000"
  },
  {
    "text": "so as far as the instrumentation goes um",
    "start": "391199",
    "end": "395680"
  },
  {
    "text": "this is based on you know the the",
    "start": "395680",
    "end": "398080"
  },
  {
    "text": "current implementation and in fact if",
    "start": "398080",
    "end": "400080"
  },
  {
    "text": "you look at the orange line here what",
    "start": "400080",
    "end": "402160"
  },
  {
    "text": "this does is so this exposes the",
    "start": "402160",
    "end": "404479"
  },
  {
    "text": "conventional histograms using using the",
    "start": "404479",
    "end": "406400"
  },
  {
    "text": "current method but it gets a little bit",
    "start": "406400",
    "end": "408960"
  },
  {
    "text": "more interesting when we look at these",
    "start": "408960",
    "end": "411039"
  },
  {
    "text": "three items here",
    "start": "411039",
    "end": "412479"
  },
  {
    "text": "so the sparse buckets factor",
    "start": "412479",
    "end": "414639"
  },
  {
    "text": "that basically defines the precision of",
    "start": "414639",
    "end": "416880"
  },
  {
    "text": "your histogram and this is a growth",
    "start": "416880",
    "end": "418800"
  },
  {
    "text": "factor",
    "start": "418800",
    "end": "419759"
  },
  {
    "text": "and it describes whenever you go from",
    "start": "419759",
    "end": "422000"
  },
  {
    "text": "one bucket to the next bucket it",
    "start": "422000",
    "end": "423759"
  },
  {
    "text": "describes how much growth you see so",
    "start": "423759",
    "end": "426080"
  },
  {
    "text": "that as you keep adding adding more",
    "start": "426080",
    "end": "428080"
  },
  {
    "text": "buckets they also keep growing and",
    "start": "428080",
    "end": "430160"
  },
  {
    "text": "growing",
    "start": "430160",
    "end": "431520"
  },
  {
    "text": "um",
    "start": "431520",
    "end": "433120"
  },
  {
    "text": "and because we automatically allocate",
    "start": "433120",
    "end": "435039"
  },
  {
    "text": "buckets however many are needed to",
    "start": "435039",
    "end": "437599"
  },
  {
    "text": "accommodate your data you probably want",
    "start": "437599",
    "end": "439759"
  },
  {
    "text": "to set some kind of limit because",
    "start": "439759",
    "end": "441039"
  },
  {
    "text": "otherwise in theory it can just grow",
    "start": "441039",
    "end": "443120"
  },
  {
    "text": "infinitely",
    "start": "443120",
    "end": "444720"
  },
  {
    "text": "in this case we set a maximum number of",
    "start": "444720",
    "end": "447599"
  },
  {
    "text": "150",
    "start": "447599",
    "end": "449599"
  },
  {
    "text": "and",
    "start": "449599",
    "end": "450639"
  },
  {
    "text": "the way we",
    "start": "450639",
    "end": "451919"
  },
  {
    "text": "implement that limit it's it's in two",
    "start": "451919",
    "end": "453840"
  },
  {
    "text": "ways so the first way is we can reset",
    "start": "453840",
    "end": "457199"
  },
  {
    "text": "a bucket",
    "start": "457199",
    "end": "458800"
  },
  {
    "text": "and this declares that we could reset up",
    "start": "458800",
    "end": "461120"
  },
  {
    "text": "to once per hour",
    "start": "461120",
    "end": "463360"
  },
  {
    "text": "and basically what a reset means is you",
    "start": "463360",
    "end": "464960"
  },
  {
    "text": "start a new chunk",
    "start": "464960",
    "end": "466479"
  },
  {
    "text": "and",
    "start": "466479",
    "end": "467520"
  },
  {
    "text": "you get rid of all the buckets that were",
    "start": "467520",
    "end": "469120"
  },
  {
    "text": "at some point used by some data and you",
    "start": "469120",
    "end": "471120"
  },
  {
    "text": "only start using the buckets that are",
    "start": "471120",
    "end": "473039"
  },
  {
    "text": "needed for the current data and",
    "start": "473039",
    "end": "474879"
  },
  {
    "text": "hopefully and commonly that will be",
    "start": "474879",
    "end": "476639"
  },
  {
    "text": "enough to get you under that limit",
    "start": "476639",
    "end": "479919"
  },
  {
    "text": "if that's not sufficient to reach your",
    "start": "479919",
    "end": "482400"
  },
  {
    "text": "defined limit then we have an",
    "start": "482400",
    "end": "484960"
  },
  {
    "text": "a second solution which is",
    "start": "484960",
    "end": "487039"
  },
  {
    "text": "it start decreasing the precision",
    "start": "487039",
    "end": "489360"
  },
  {
    "text": "so that's something to keep in mind that",
    "start": "489360",
    "end": "491039"
  },
  {
    "text": "in certain cases when you hit your limit",
    "start": "491039",
    "end": "493599"
  },
  {
    "text": "you might need to or it will",
    "start": "493599",
    "end": "495199"
  },
  {
    "text": "automatically start growing your buckets",
    "start": "495199",
    "end": "497840"
  },
  {
    "text": "and your precision will go down a little",
    "start": "497840",
    "end": "499440"
  },
  {
    "text": "bit",
    "start": "499440",
    "end": "501599"
  },
  {
    "start": "502000",
    "end": "665000"
  },
  {
    "text": "so the encoding of how all the data",
    "start": "503919",
    "end": "507680"
  },
  {
    "text": "after it gets scraped actually gets",
    "start": "507680",
    "end": "509440"
  },
  {
    "text": "saved into histogram chunks",
    "start": "509440",
    "end": "512240"
  },
  {
    "text": "there's so by the way this is a little",
    "start": "512240",
    "end": "513680"
  },
  {
    "text": "bit simplified i left out a bunch of",
    "start": "513680",
    "end": "516320"
  },
  {
    "text": "other details",
    "start": "516320",
    "end": "517599"
  },
  {
    "text": "but basically there's two main things in",
    "start": "517599",
    "end": "519680"
  },
  {
    "text": "the beginning of the chunk you have your",
    "start": "519680",
    "end": "521039"
  },
  {
    "text": "metadata and it describes the exact",
    "start": "521039",
    "end": "523599"
  },
  {
    "text": "shape of your histogram",
    "start": "523599",
    "end": "525279"
  },
  {
    "text": "and then after that are the individual",
    "start": "525279",
    "end": "526560"
  },
  {
    "text": "histogram samples",
    "start": "526560",
    "end": "528320"
  },
  {
    "text": "so the metadata there's two key",
    "start": "528320",
    "end": "531519"
  },
  {
    "text": "entries here",
    "start": "531519",
    "end": "532800"
  },
  {
    "text": "one is the schema and this is simply a",
    "start": "532800",
    "end": "534800"
  },
  {
    "text": "number that describes the growth factor",
    "start": "534800",
    "end": "536880"
  },
  {
    "text": "so we saw a growth factor of 1.1 earlier",
    "start": "536880",
    "end": "539519"
  },
  {
    "text": "that basically gets encoded as a simple",
    "start": "539519",
    "end": "541279"
  },
  {
    "text": "integer",
    "start": "541279",
    "end": "543040"
  },
  {
    "text": "and then we declare which buckets are",
    "start": "543040",
    "end": "545440"
  },
  {
    "text": "actually being used",
    "start": "545440",
    "end": "546880"
  },
  {
    "text": "because in theory you could have an",
    "start": "546880",
    "end": "548160"
  },
  {
    "text": "infinite number of buckets",
    "start": "548160",
    "end": "549920"
  },
  {
    "text": "the way it works is and by the way some",
    "start": "549920",
    "end": "552000"
  },
  {
    "text": "of these buckets might be used for data",
    "start": "552000",
    "end": "553760"
  },
  {
    "text": "some of those buckets might need to be",
    "start": "553760",
    "end": "555120"
  },
  {
    "text": "skipped because they don't have any data",
    "start": "555120",
    "end": "556880"
  },
  {
    "text": "and the way we implement this is quite",
    "start": "556880",
    "end": "558640"
  },
  {
    "text": "simply as a list that says you know",
    "start": "558640",
    "end": "560959"
  },
  {
    "text": "basically for example skip 10 buckets",
    "start": "560959",
    "end": "563839"
  },
  {
    "text": "that are not used then you have 20",
    "start": "563839",
    "end": "565600"
  },
  {
    "text": "buckets that are used then you have this",
    "start": "565600",
    "end": "567519"
  },
  {
    "text": "many that are not used then you have",
    "start": "567519",
    "end": "569040"
  },
  {
    "text": "that many that are used again and so",
    "start": "569040",
    "end": "571120"
  },
  {
    "text": "forth so this basically describes the",
    "start": "571120",
    "end": "572800"
  },
  {
    "text": "entire range of buckets that are used",
    "start": "572800",
    "end": "575839"
  },
  {
    "text": "and this is also why we call them sparse",
    "start": "575839",
    "end": "577440"
  },
  {
    "text": "histograms",
    "start": "577440",
    "end": "578959"
  },
  {
    "text": "because in this infinite space of",
    "start": "578959",
    "end": "580800"
  },
  {
    "text": "buckets if you only use a subset of them",
    "start": "580800",
    "end": "582800"
  },
  {
    "text": "this is a very efficient way",
    "start": "582800",
    "end": "585040"
  },
  {
    "text": "to not have the overhead of all the",
    "start": "585040",
    "end": "586640"
  },
  {
    "text": "buckets that are not used",
    "start": "586640",
    "end": "588480"
  },
  {
    "text": "and i also just want to point out that",
    "start": "588480",
    "end": "589920"
  },
  {
    "text": "using just these two items in the",
    "start": "589920",
    "end": "592080"
  },
  {
    "text": "metadata you can get the exact",
    "start": "592080",
    "end": "593680"
  },
  {
    "text": "description of how the histogram looks",
    "start": "593680",
    "end": "595760"
  },
  {
    "text": "like",
    "start": "595760",
    "end": "597200"
  },
  {
    "text": "as far as the actual data goes",
    "start": "597200",
    "end": "600240"
  },
  {
    "text": "um this is inspired by",
    "start": "600240",
    "end": "603279"
  },
  {
    "text": "by the current xor encoding of simple",
    "start": "603279",
    "end": "605760"
  },
  {
    "text": "time series there's just uh there's some",
    "start": "605760",
    "end": "608320"
  },
  {
    "text": "more fields and then of course the",
    "start": "608320",
    "end": "609920"
  },
  {
    "text": "buckets this is a",
    "start": "609920",
    "end": "611440"
  },
  {
    "text": "variable length",
    "start": "611440",
    "end": "612880"
  },
  {
    "text": "field",
    "start": "612880",
    "end": "614640"
  },
  {
    "text": "but basically",
    "start": "614640",
    "end": "615920"
  },
  {
    "text": "the first histogram sample that comes in",
    "start": "615920",
    "end": "618720"
  },
  {
    "text": "um",
    "start": "618720",
    "end": "619760"
  },
  {
    "text": "we're just going to store all the fields",
    "start": "619760",
    "end": "620880"
  },
  {
    "text": "raw as integers and as floats and as a",
    "start": "620880",
    "end": "623519"
  },
  {
    "text": "sequence of integers then the second",
    "start": "623519",
    "end": "625519"
  },
  {
    "text": "histogram will show we're storing deltas",
    "start": "625519",
    "end": "628880"
  },
  {
    "text": "and the third and the fourth and so",
    "start": "628880",
    "end": "630399"
  },
  {
    "text": "forth histograms we just store delta of",
    "start": "630399",
    "end": "633760"
  },
  {
    "text": "delta everywhere",
    "start": "633760",
    "end": "635519"
  },
  {
    "text": "the one exception here is the sum field",
    "start": "635519",
    "end": "638160"
  },
  {
    "text": "so the sum of all the observations",
    "start": "638160",
    "end": "640880"
  },
  {
    "text": "because that's a floating point number",
    "start": "640880",
    "end": "642480"
  },
  {
    "text": "we use the xor encoding from the gorilla",
    "start": "642480",
    "end": "644399"
  },
  {
    "text": "paper",
    "start": "644399",
    "end": "645279"
  },
  {
    "text": "just like the",
    "start": "645279",
    "end": "646880"
  },
  {
    "text": "standard xor encoding",
    "start": "646880",
    "end": "648720"
  },
  {
    "text": "of time series",
    "start": "648720",
    "end": "650320"
  },
  {
    "text": "and all of this data gets written into a",
    "start": "650320",
    "end": "653120"
  },
  {
    "text": "bit stream which of course gets",
    "start": "653120",
    "end": "654880"
  },
  {
    "text": "serialized as a chunk of bytes",
    "start": "654880",
    "end": "657839"
  },
  {
    "text": "and so yeah this contains the full",
    "start": "657839",
    "end": "659360"
  },
  {
    "text": "metadata describing",
    "start": "659360",
    "end": "661120"
  },
  {
    "text": "the histogram format and then all the",
    "start": "661120",
    "end": "662959"
  },
  {
    "text": "histogram samples",
    "start": "662959",
    "end": "666000"
  },
  {
    "start": "665000",
    "end": "707000"
  },
  {
    "text": "and talking about our test setup we",
    "start": "666240",
    "end": "669040"
  },
  {
    "text": "instrumented the cortex gateway on our",
    "start": "669040",
    "end": "672160"
  },
  {
    "text": "graphene cloud dev clusters with both",
    "start": "672160",
    "end": "674240"
  },
  {
    "text": "conventional and high resolution",
    "start": "674240",
    "end": "676480"
  },
  {
    "text": "histograms cortex gateway is the",
    "start": "676480",
    "end": "678880"
  },
  {
    "text": "component which sits in front of our",
    "start": "678880",
    "end": "681040"
  },
  {
    "text": "cortex clusters and all the read and",
    "start": "681040",
    "end": "683040"
  },
  {
    "text": "write traffic goes through it",
    "start": "683040",
    "end": "685279"
  },
  {
    "text": "and",
    "start": "685279",
    "end": "686160"
  },
  {
    "text": "we set up two prometheus one of them",
    "start": "686160",
    "end": "688399"
  },
  {
    "text": "scraping the conventional histograms and",
    "start": "688399",
    "end": "690160"
  },
  {
    "text": "one of them only skipping the high",
    "start": "690160",
    "end": "691519"
  },
  {
    "text": "resolution histograms",
    "start": "691519",
    "end": "693279"
  },
  {
    "text": "and we",
    "start": "693279",
    "end": "694720"
  },
  {
    "text": "compared the storage at",
    "start": "694720",
    "end": "697279"
  },
  {
    "text": "saturation which means",
    "start": "697279",
    "end": "699040"
  },
  {
    "text": "all the buckets that had to be filled",
    "start": "699040",
    "end": "701040"
  },
  {
    "text": "were filled and there was less fastness",
    "start": "701040",
    "end": "705360"
  },
  {
    "start": "707000",
    "end": "797000"
  },
  {
    "text": "and this is how the data looked like in",
    "start": "707839",
    "end": "711040"
  },
  {
    "text": "the conventional histograms we had 14",
    "start": "711040",
    "end": "713600"
  },
  {
    "text": "fixed buckets",
    "start": "713600",
    "end": "715200"
  },
  {
    "text": "which means",
    "start": "715200",
    "end": "716880"
  },
  {
    "text": "you have 14",
    "start": "716880",
    "end": "718320"
  },
  {
    "text": "time series data a time series in the",
    "start": "718320",
    "end": "720480"
  },
  {
    "text": "dsp for each bucket and you just saw",
    "start": "720480",
    "end": "723519"
  },
  {
    "text": "that we have some additional series for",
    "start": "723519",
    "end": "725360"
  },
  {
    "text": "each histogram one of them being the",
    "start": "725360",
    "end": "727680"
  },
  {
    "text": "infinite bucket one of them is some",
    "start": "727680",
    "end": "730399"
  },
  {
    "text": "uh series one of them is count series so",
    "start": "730399",
    "end": "733360"
  },
  {
    "text": "add those three up then you have 17 tsb",
    "start": "733360",
    "end": "736639"
  },
  {
    "text": "series per histogram and for sparse high",
    "start": "736639",
    "end": "739839"
  },
  {
    "text": "resolution histograms",
    "start": "739839",
    "end": "741920"
  },
  {
    "text": "the number of buckets varies in our",
    "start": "741920",
    "end": "745440"
  },
  {
    "text": "data we saw that it varied between one",
    "start": "745440",
    "end": "747440"
  },
  {
    "text": "bucket to 128 buckets and it's dynamic",
    "start": "747440",
    "end": "751360"
  },
  {
    "text": "and",
    "start": "751360",
    "end": "752480"
  },
  {
    "text": "because all of these buckets are stored",
    "start": "752480",
    "end": "754720"
  },
  {
    "text": "in the same chunk we only need one time",
    "start": "754720",
    "end": "757600"
  },
  {
    "text": "series",
    "start": "757600",
    "end": "758560"
  },
  {
    "text": "in the dsdb to represent a histogram in",
    "start": "758560",
    "end": "761360"
  },
  {
    "text": "all its buckets",
    "start": "761360",
    "end": "762959"
  },
  {
    "text": "so we have two blocks two data blocks",
    "start": "762959",
    "end": "765360"
  },
  {
    "text": "under observation here one of them",
    "start": "765360",
    "end": "767680"
  },
  {
    "text": "escaped data for 18 hours which had 249",
    "start": "767680",
    "end": "771279"
  },
  {
    "text": "histograms",
    "start": "771279",
    "end": "772800"
  },
  {
    "text": "and you can see the number of series",
    "start": "772800",
    "end": "774639"
  },
  {
    "text": "it's multi there's a multiple of 17 for",
    "start": "774639",
    "end": "776800"
  },
  {
    "text": "the conventional multiple of one for",
    "start": "776800",
    "end": "778720"
  },
  {
    "text": "this pass similarly block b is spanning",
    "start": "778720",
    "end": "781680"
  },
  {
    "text": "two hours and 144 histograms",
    "start": "781680",
    "end": "784000"
  },
  {
    "text": "though both of them skate the same thing",
    "start": "784000",
    "end": "786079"
  },
  {
    "text": "the block a has",
    "start": "786079",
    "end": "787680"
  },
  {
    "text": "nearly the double number of histograms",
    "start": "787680",
    "end": "789680"
  },
  {
    "text": "because there was a rollout",
    "start": "789680",
    "end": "791279"
  },
  {
    "text": "so few labels changed so you get more",
    "start": "791279",
    "end": "793519"
  },
  {
    "text": "histograms",
    "start": "793519",
    "end": "795040"
  },
  {
    "text": "in the next slide",
    "start": "795040",
    "end": "797519"
  },
  {
    "start": "797000",
    "end": "855000"
  },
  {
    "text": "we will",
    "start": "797519",
    "end": "798639"
  },
  {
    "text": "see how this dynamic buckets look like",
    "start": "798639",
    "end": "801519"
  },
  {
    "text": "so all of these uh this is a snapshot of",
    "start": "801519",
    "end": "804240"
  },
  {
    "text": "few of the series from the blocks for",
    "start": "804240",
    "end": "807120"
  },
  {
    "text": "the sparse histogram you can see that",
    "start": "807120",
    "end": "809360"
  },
  {
    "text": "the number of buckets vary in huge",
    "start": "809360",
    "end": "812320"
  },
  {
    "text": "numbers for example if uh for querying",
    "start": "812320",
    "end": "816079"
  },
  {
    "text": "the query can be expensive or cheap so",
    "start": "816079",
    "end": "819440"
  },
  {
    "text": "the latency of query can span a huge",
    "start": "819440",
    "end": "822079"
  },
  {
    "text": "range so you have you have to cover too",
    "start": "822079",
    "end": "823680"
  },
  {
    "text": "many buckets and if you take example",
    "start": "823680",
    "end": "826079"
  },
  {
    "text": "like",
    "start": "826079",
    "end": "827519"
  },
  {
    "text": "a gateway timeout it's mostly set at a",
    "start": "827519",
    "end": "830720"
  },
  {
    "text": "fixed time so you are always going to",
    "start": "830720",
    "end": "833279"
  },
  {
    "text": "observe a fixed",
    "start": "833279",
    "end": "835040"
  },
  {
    "text": "uh time for that",
    "start": "835040",
    "end": "837279"
  },
  {
    "text": "particular histogram so it's always",
    "start": "837279",
    "end": "838720"
  },
  {
    "text": "going to fall in a single bucket so you",
    "start": "838720",
    "end": "840880"
  },
  {
    "text": "won't really need more than one bucket",
    "start": "840880",
    "end": "843600"
  },
  {
    "text": "for that histogram so this shows that uh",
    "start": "843600",
    "end": "846880"
  },
  {
    "text": "partitioning histograms into multiple",
    "start": "846880",
    "end": "849360"
  },
  {
    "text": "histograms with different labels is not",
    "start": "849360",
    "end": "851360"
  },
  {
    "text": "going to be expensive because the",
    "start": "851360",
    "end": "852639"
  },
  {
    "text": "buckets are dynamic here",
    "start": "852639",
    "end": "854800"
  },
  {
    "text": "now let's look at our benchmark results",
    "start": "854800",
    "end": "858560"
  },
  {
    "start": "855000",
    "end": "953000"
  },
  {
    "text": "yep this this is pretty interesting it",
    "start": "858560",
    "end": "861279"
  },
  {
    "text": "also give our mind",
    "start": "861279",
    "end": "863040"
  },
  {
    "text": "so",
    "start": "863040",
    "end": "863839"
  },
  {
    "text": "the first column you see the reduction",
    "start": "863839",
    "end": "866320"
  },
  {
    "text": "in index size the reduction is like 94",
    "start": "866320",
    "end": "869120"
  },
  {
    "text": "and 93 percent for the block and if you",
    "start": "869120",
    "end": "872560"
  },
  {
    "text": "look at it carefully it is",
    "start": "872560",
    "end": "874800"
  },
  {
    "text": "a",
    "start": "874800",
    "end": "876000"
  },
  {
    "text": "17 x reduction or little more than 17 x",
    "start": "876000",
    "end": "878959"
  },
  {
    "text": "reduction which was the ratio between",
    "start": "878959",
    "end": "881040"
  },
  {
    "text": "number of series required for",
    "start": "881040",
    "end": "882560"
  },
  {
    "text": "conventional passes to come and it's",
    "start": "882560",
    "end": "884480"
  },
  {
    "text": "little more than 17x because in the",
    "start": "884480",
    "end": "886959"
  },
  {
    "text": "index store the series information but",
    "start": "886959",
    "end": "889600"
  },
  {
    "text": "in the sparse histogram you don't have",
    "start": "889600",
    "end": "891199"
  },
  {
    "text": "to store the le label",
    "start": "891199",
    "end": "893199"
  },
  {
    "text": "so there comes the additional little",
    "start": "893199",
    "end": "895360"
  },
  {
    "text": "more than 17x reduction in the index and",
    "start": "895360",
    "end": "898320"
  },
  {
    "text": "if you look at the chunks though",
    "start": "898320",
    "end": "900240"
  },
  {
    "text": "we have",
    "start": "900240",
    "end": "901440"
  },
  {
    "text": "more buckets",
    "start": "901440",
    "end": "902800"
  },
  {
    "text": "in this past histogram you still get an",
    "start": "902800",
    "end": "906079"
  },
  {
    "text": "efficient coding so there is like 43 and",
    "start": "906079",
    "end": "908880"
  },
  {
    "text": "48 reduction in the size taken by the",
    "start": "908880",
    "end": "911760"
  },
  {
    "text": "chunks themselves and if you combine",
    "start": "911760",
    "end": "913920"
  },
  {
    "text": "both the sizes like the both index and",
    "start": "913920",
    "end": "916480"
  },
  {
    "text": "chunks overall reduction is like 48 to",
    "start": "916480",
    "end": "919519"
  },
  {
    "text": "60 percent it it can vary based on how",
    "start": "919519",
    "end": "922639"
  },
  {
    "text": "long your data is",
    "start": "922639",
    "end": "924240"
  },
  {
    "text": "and",
    "start": "924240",
    "end": "925279"
  },
  {
    "text": "this also means the memory that the head",
    "start": "925279",
    "end": "928560"
  },
  {
    "text": "block would take will be little less",
    "start": "928560",
    "end": "931120"
  },
  {
    "text": "because",
    "start": "931120",
    "end": "932240"
  },
  {
    "text": "it will be you it's using the same",
    "start": "932240",
    "end": "934480"
  },
  {
    "text": "encoding as used in the block and the",
    "start": "934480",
    "end": "936800"
  },
  {
    "text": "number of series is it takes a lot of",
    "start": "936800",
    "end": "939519"
  },
  {
    "text": "space in the memory usually and that's",
    "start": "939519",
    "end": "942079"
  },
  {
    "text": "going to reduce with a single series per",
    "start": "942079",
    "end": "944639"
  },
  {
    "text": "histogram",
    "start": "944639",
    "end": "946000"
  },
  {
    "text": "so there comes the overall savings in",
    "start": "946000",
    "end": "948720"
  },
  {
    "text": "memory and",
    "start": "948720",
    "end": "950399"
  },
  {
    "text": "a space",
    "start": "950399",
    "end": "953639"
  },
  {
    "start": "953000",
    "end": "1054000"
  },
  {
    "text": "so um let's start to recap",
    "start": "954480",
    "end": "957759"
  },
  {
    "text": "our conclusion so far",
    "start": "957759",
    "end": "959600"
  },
  {
    "text": "so",
    "start": "959600",
    "end": "960560"
  },
  {
    "text": "there's very little configuration as we",
    "start": "960560",
    "end": "962399"
  },
  {
    "text": "saw in the instrumentation section you",
    "start": "962399",
    "end": "964079"
  },
  {
    "text": "basically",
    "start": "964079",
    "end": "965279"
  },
  {
    "text": "have to define a precision but even that",
    "start": "965279",
    "end": "967440"
  },
  {
    "text": "we can just default to something seen",
    "start": "967440",
    "end": "969040"
  },
  {
    "text": "like 1.1",
    "start": "969040",
    "end": "970480"
  },
  {
    "text": "and you probably want to specify a limit",
    "start": "970480",
    "end": "972399"
  },
  {
    "text": "but hopefully you will never reach it",
    "start": "972399",
    "end": "973759"
  },
  {
    "text": "just like in our experiments",
    "start": "973759",
    "end": "976000"
  },
  {
    "text": "as you saw we reached up 228 buckets we",
    "start": "976000",
    "end": "978959"
  },
  {
    "text": "never reached our 150 limit",
    "start": "978959",
    "end": "982320"
  },
  {
    "text": "but if you don't specify those then",
    "start": "982320",
    "end": "984639"
  },
  {
    "text": "basically have zero config and it should",
    "start": "984639",
    "end": "986399"
  },
  {
    "text": "just work out of the box",
    "start": "986399",
    "end": "989440"
  },
  {
    "text": "and with that growth factor of 1.1 we",
    "start": "990000",
    "end": "992800"
  },
  {
    "text": "also observe a significantly more uh",
    "start": "992800",
    "end": "996959"
  },
  {
    "text": "basically precise bucket boundaries so",
    "start": "996959",
    "end": "998800"
  },
  {
    "text": "we see a",
    "start": "998800",
    "end": "1000320"
  },
  {
    "text": "difference in precision of about an",
    "start": "1000320",
    "end": "1002079"
  },
  {
    "text": "order of magnitude compared to the the",
    "start": "1002079",
    "end": "1004240"
  },
  {
    "text": "manual bucket assignment",
    "start": "1004240",
    "end": "1006800"
  },
  {
    "text": "and then i also want to point out that",
    "start": "1006800",
    "end": "1009279"
  },
  {
    "text": "as your observations you know if they go",
    "start": "1009279",
    "end": "1011600"
  },
  {
    "text": "well beyond the range that you",
    "start": "1011600",
    "end": "1013519"
  },
  {
    "text": "originally thought your data might lie",
    "start": "1013519",
    "end": "1015279"
  },
  {
    "text": "in you still get to maintain that same",
    "start": "1015279",
    "end": "1017440"
  },
  {
    "text": "precision",
    "start": "1017440",
    "end": "1018560"
  },
  {
    "text": "so in the conventional current",
    "start": "1018560",
    "end": "1020800"
  },
  {
    "text": "implementation of histograms",
    "start": "1020800",
    "end": "1022720"
  },
  {
    "text": "i i hope you would have accounted for",
    "start": "1022720",
    "end": "1024558"
  },
  {
    "text": "some of your data and configured your",
    "start": "1024559",
    "end": "1026240"
  },
  {
    "text": "buckets properly because if your data",
    "start": "1026240",
    "end": "1028319"
  },
  {
    "text": "goes beyond that range",
    "start": "1028319",
    "end": "1030160"
  },
  {
    "text": "suddenly your your relative error starts",
    "start": "1030160",
    "end": "1032079"
  },
  {
    "text": "going up significantly but but not with",
    "start": "1032079",
    "end": "1034079"
  },
  {
    "text": "the new histograms",
    "start": "1034079",
    "end": "1036640"
  },
  {
    "text": "and",
    "start": "1036640",
    "end": "1037520"
  },
  {
    "text": "they're fully mergeable and aggregatable",
    "start": "1037520",
    "end": "1039520"
  },
  {
    "text": "we didn't really go too much in detail",
    "start": "1039520",
    "end": "1041678"
  },
  {
    "text": "for that but uh you'll you'll just have",
    "start": "1041679",
    "end": "1043760"
  },
  {
    "text": "to check the design talk if you want to",
    "start": "1043760",
    "end": "1045360"
  },
  {
    "text": "understand more about how how that works",
    "start": "1045360",
    "end": "1047280"
  },
  {
    "text": "but basically it's about",
    "start": "1047280",
    "end": "1049120"
  },
  {
    "text": "when you have different bucket layouts",
    "start": "1049120",
    "end": "1050480"
  },
  {
    "text": "how they are compatible and you can",
    "start": "1050480",
    "end": "1052000"
  },
  {
    "text": "merge them",
    "start": "1052000",
    "end": "1054480"
  },
  {
    "start": "1054000",
    "end": "1101000"
  },
  {
    "text": "and we saw that there was nearly half",
    "start": "1054720",
    "end": "1057120"
  },
  {
    "text": "of a half of reduction of storage",
    "start": "1057120",
    "end": "1059600"
  },
  {
    "text": "requirement and there was more than 90",
    "start": "1059600",
    "end": "1061760"
  },
  {
    "text": "percent of index reduction so far in",
    "start": "1061760",
    "end": "1064559"
  },
  {
    "text": "node test and depending on how many",
    "start": "1064559",
    "end": "1067280"
  },
  {
    "text": "buckets you have chosen for your",
    "start": "1067280",
    "end": "1069600"
  },
  {
    "text": "existing conventional histogram you will",
    "start": "1069600",
    "end": "1071760"
  },
  {
    "text": "see similar reduction in the index and",
    "start": "1071760",
    "end": "1075360"
  },
  {
    "text": "the sparseness makes it very efficient",
    "start": "1075360",
    "end": "1078320"
  },
  {
    "text": "to have partitioning in the histogram we",
    "start": "1078320",
    "end": "1080799"
  },
  {
    "text": "saw the buckets varied from 1 to 128 so",
    "start": "1080799",
    "end": "1085600"
  },
  {
    "text": "when you have more partitioning it",
    "start": "1085600",
    "end": "1088000"
  },
  {
    "text": "doesn't mean there is a linear cost as",
    "start": "1088000",
    "end": "1090240"
  },
  {
    "text": "we have for conventional histograms",
    "start": "1090240",
    "end": "1092160"
  },
  {
    "text": "where the buckets are fixed and and",
    "start": "1092160",
    "end": "1094720"
  },
  {
    "text": "basically we have a sublinear growth",
    "start": "1094720",
    "end": "1096799"
  },
  {
    "text": "because the buckets are dynamic",
    "start": "1096799",
    "end": "1100720"
  },
  {
    "start": "1101000",
    "end": "1172000"
  },
  {
    "text": "there are two limitations that i think",
    "start": "1103039",
    "end": "1105600"
  },
  {
    "text": "are worth pointing out",
    "start": "1105600",
    "end": "1107280"
  },
  {
    "text": "the first one is obviously the limit",
    "start": "1107280",
    "end": "1110000"
  },
  {
    "text": "that we already pointed out earlier",
    "start": "1110000",
    "end": "1113679"
  },
  {
    "text": "you probably want to set some kind of",
    "start": "1113840",
    "end": "1115120"
  },
  {
    "text": "limit to make sure",
    "start": "1115120",
    "end": "1116720"
  },
  {
    "text": "you know if your data is really",
    "start": "1116720",
    "end": "1120000"
  },
  {
    "text": "very",
    "start": "1120000",
    "end": "1122000"
  },
  {
    "text": "if you have a lot of",
    "start": "1122000",
    "end": "1123440"
  },
  {
    "text": "variability in your data that you",
    "start": "1123440",
    "end": "1125360"
  },
  {
    "text": "control the amount of buckets that you",
    "start": "1125360",
    "end": "1126640"
  },
  {
    "text": "use and as i pointed out earlier we can",
    "start": "1126640",
    "end": "1129440"
  },
  {
    "text": "just try to cut a new chunk and usually",
    "start": "1129440",
    "end": "1131600"
  },
  {
    "text": "that works but in certain cases that",
    "start": "1131600",
    "end": "1133280"
  },
  {
    "text": "might not be sufficient and then the",
    "start": "1133280",
    "end": "1135520"
  },
  {
    "text": "precision will automatically get lowered",
    "start": "1135520",
    "end": "1137919"
  },
  {
    "text": "we currently don't have a way to really",
    "start": "1137919",
    "end": "1139440"
  },
  {
    "text": "expose that",
    "start": "1139440",
    "end": "1141520"
  },
  {
    "text": "but this is something to think about in",
    "start": "1141520",
    "end": "1142880"
  },
  {
    "text": "the future to maybe make that a little",
    "start": "1142880",
    "end": "1144320"
  },
  {
    "text": "bit more clear in the ui",
    "start": "1144320",
    "end": "1147280"
  },
  {
    "text": "and then finally",
    "start": "1147280",
    "end": "1149039"
  },
  {
    "text": "we currently don't have custom bucket",
    "start": "1149039",
    "end": "1150480"
  },
  {
    "text": "boundaries so if you want to answer",
    "start": "1150480",
    "end": "1152400"
  },
  {
    "text": "questions such as",
    "start": "1152400",
    "end": "1153919"
  },
  {
    "text": "what's the percentage of uh requests",
    "start": "1153919",
    "end": "1157120"
  },
  {
    "text": "that were exactly 250 milliseconds or up",
    "start": "1157120",
    "end": "1160080"
  },
  {
    "text": "to 250 milliseconds and you want to set",
    "start": "1160080",
    "end": "1162480"
  },
  {
    "text": "very specific human-friendly boundaries",
    "start": "1162480",
    "end": "1164640"
  },
  {
    "text": "like that that's currently not supported",
    "start": "1164640",
    "end": "1167120"
  },
  {
    "text": "but i think bjorn has some ideas on how",
    "start": "1167120",
    "end": "1169039"
  },
  {
    "text": "to make that work",
    "start": "1169039",
    "end": "1171679"
  },
  {
    "start": "1172000",
    "end": "1246000"
  },
  {
    "text": "and the work that we have done till now",
    "start": "1172960",
    "end": "1175280"
  },
  {
    "text": "only contains scraping and ingesting",
    "start": "1175280",
    "end": "1177919"
  },
  {
    "text": "into the tstp and retrieving histograms",
    "start": "1177919",
    "end": "1180960"
  },
  {
    "text": "at a tstp layer that raw histograms and",
    "start": "1180960",
    "end": "1183520"
  },
  {
    "text": "we have a lot of future work to be done",
    "start": "1183520",
    "end": "1185840"
  },
  {
    "text": "uh the main one being the promptil",
    "start": "1185840",
    "end": "1187840"
  },
  {
    "text": "support so that promgial can natively",
    "start": "1187840",
    "end": "1190880"
  },
  {
    "text": "work with these past histograms and also",
    "start": "1190880",
    "end": "1194240"
  },
  {
    "text": "we could create sparse histograms",
    "start": "1194240",
    "end": "1196720"
  },
  {
    "text": "in recording rules using this promptu",
    "start": "1196720",
    "end": "1199200"
  },
  {
    "text": "the heat map that you saw we needed to",
    "start": "1199200",
    "end": "1201760"
  },
  {
    "text": "do some hacksaw to get it working but it",
    "start": "1201760",
    "end": "1204080"
  },
  {
    "text": "did not use any native pronounced",
    "start": "1204080",
    "end": "1205840"
  },
  {
    "text": "support and the next one because we want",
    "start": "1205840",
    "end": "1208080"
  },
  {
    "text": "to",
    "start": "1208080",
    "end": "1208880"
  },
  {
    "text": "uh",
    "start": "1208880",
    "end": "1209760"
  },
  {
    "text": "uh one of our goal was what is working",
    "start": "1209760",
    "end": "1212559"
  },
  {
    "text": "right now should keep working so we need",
    "start": "1212559",
    "end": "1214640"
  },
  {
    "text": "a compatibility layer to bridge the",
    "start": "1214640",
    "end": "1217440"
  },
  {
    "text": "conventional and sparse histogram so",
    "start": "1217440",
    "end": "1219280"
  },
  {
    "text": "that they can work together",
    "start": "1219280",
    "end": "1221600"
  },
  {
    "text": "and we want to",
    "start": "1221600",
    "end": "1224080"
  },
  {
    "text": "play with more data and determine the",
    "start": "1224080",
    "end": "1226320"
  },
  {
    "text": "query cost and because there is a big",
    "start": "1226320",
    "end": "1229200"
  },
  {
    "text": "reduction in index",
    "start": "1229200",
    "end": "1230880"
  },
  {
    "text": "we uh we think that it will be a",
    "start": "1230880",
    "end": "1234000"
  },
  {
    "text": "reduction in lookup cost for these",
    "start": "1234000",
    "end": "1236480"
  },
  {
    "text": "histograms so that is just a hypothesis",
    "start": "1236480",
    "end": "1239520"
  },
  {
    "text": "but we need to play with a lot more data",
    "start": "1239520",
    "end": "1241679"
  },
  {
    "text": "and return the query cost",
    "start": "1241679",
    "end": "1246000"
  },
  {
    "start": "1246000",
    "end": "1279000"
  },
  {
    "text": "so that's it um",
    "start": "1247520",
    "end": "1249360"
  },
  {
    "text": "if you're interested in the code you can",
    "start": "1249360",
    "end": "1251440"
  },
  {
    "text": "check the sparse histogram branches of",
    "start": "1251440",
    "end": "1253840"
  },
  {
    "text": "the prometheus project and the client",
    "start": "1253840",
    "end": "1255840"
  },
  {
    "text": "goaling repositories so that's just all",
    "start": "1255840",
    "end": "1258400"
  },
  {
    "text": "of our experimental codes so far",
    "start": "1258400",
    "end": "1261360"
  },
  {
    "text": "i emphasize experimental",
    "start": "1261360",
    "end": "1263840"
  },
  {
    "text": "um",
    "start": "1263840",
    "end": "1264799"
  },
  {
    "text": "and yeah we would love to hear what you",
    "start": "1264799",
    "end": "1266799"
  },
  {
    "text": "think so both ganesha's and my twitter",
    "start": "1266799",
    "end": "1270000"
  },
  {
    "text": "handles are listed here so please please",
    "start": "1270000",
    "end": "1271919"
  },
  {
    "text": "let us know what you think and i hope",
    "start": "1271919",
    "end": "1273760"
  },
  {
    "text": "that everyone has a great rest of the",
    "start": "1273760",
    "end": "1275520"
  },
  {
    "text": "conference thank you very much",
    "start": "1275520",
    "end": "1278000"
  },
  {
    "text": "thank you",
    "start": "1278000",
    "end": "1281159"
  }
]
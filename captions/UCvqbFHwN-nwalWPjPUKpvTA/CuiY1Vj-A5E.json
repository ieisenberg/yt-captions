[
  {
    "start": "0",
    "end": "104000"
  },
  {
    "text": "okay I think we can start um hi everyone uh my name is s and today I'll will be talking about websockets and scalability",
    "start": "799",
    "end": "8599"
  },
  {
    "text": "challenges related to them um let me start with an image from an incident we",
    "start": "8599",
    "end": "14280"
  },
  {
    "text": "had some time ago yeah um it was a long Friday we we had to stay until 2: a.m.",
    "start": "14280",
    "end": "21640"
  },
  {
    "text": "uh but we eventually fixed the issue uh the alternative would have been to quit our jobs and move to another city we we",
    "start": "21640",
    "end": "28560"
  },
  {
    "text": "didn't do that fortunately and we had a lot of learnings in this incident but most importantly it was a",
    "start": "28560",
    "end": "35239"
  },
  {
    "text": "wakeup call for us that we need to improve the scalability of our system and the",
    "start": "35239",
    "end": "40719"
  },
  {
    "text": "reliability um you might be wondering what's what's happening here but before I go into more details um let me say a",
    "start": "40719",
    "end": "48559"
  },
  {
    "text": "couple words about myself uh so I'm s I'm a software engineer and consultant at",
    "start": "48559",
    "end": "54120"
  },
  {
    "text": "netlight netlight is a tech consulting company based in Europe um I focused",
    "start": "54120",
    "end": "60039"
  },
  {
    "text": "mostly on cloud engineering uh Cloud architecture site reliability engineering and more recently I've also",
    "start": "60039",
    "end": "67240"
  },
  {
    "text": "gotten interested in developer experience topics u in my free time I enjoy uh basketball photography and",
    "start": "67240",
    "end": "75080"
  },
  {
    "text": "usually Fridays without pag duty calls um in this talk uh I'll be talking about",
    "start": "75080",
    "end": "84200"
  },
  {
    "text": "uh electric vehicle charging just to set some context some Basics then then I",
    "start": "84200",
    "end": "90320"
  },
  {
    "text": "will jump into websockets and scalability challenges and actual concrete problems that we we faced in",
    "start": "90320",
    "end": "96680"
  },
  {
    "text": "our platform and finally our approach uh and how we addressed these uh challenges",
    "start": "96680",
    "end": "103520"
  },
  {
    "text": "so let's start with the first one some context about uh EV charging um let's do",
    "start": "103520",
    "end": "109079"
  },
  {
    "start": "104000",
    "end": "378000"
  },
  {
    "text": "a quick show of hand so how many of you have driven an electric car already what",
    "start": "109079",
    "end": "114520"
  },
  {
    "text": "that's quite a lot more than half that's nice then maybe you are already familiar",
    "start": "114520",
    "end": "119719"
  },
  {
    "text": "with with some of the frustrations with with charging electric cars let's take a",
    "start": "119719",
    "end": "124960"
  },
  {
    "text": "look what that uh looks like so the EV driver would plug in their car into a",
    "start": "124960",
    "end": "131800"
  },
  {
    "text": "charging station and the charging station is of course connected to the electrical grid but also it has an",
    "start": "131800",
    "end": "139160"
  },
  {
    "text": "internet connection Via mobile carrier and it uses this internet connection to communicate to a system which is called",
    "start": "139160",
    "end": "145800"
  },
  {
    "text": "a charging Point operator it communicates uh via OC PP messages it's",
    "start": "145800",
    "end": "151519"
  },
  {
    "text": "just a a protocol that standardizes uh the how the messages should look like and the flow should",
    "start": "151519",
    "end": "157720"
  },
  {
    "text": "look like it's an open standard and it makes it possible to operate uh stations from different",
    "start": "157720",
    "end": "163840"
  },
  {
    "text": "vendors the charging Point operator is a system that companies that are",
    "start": "163840",
    "end": "169760"
  },
  {
    "text": "interested in offering EV charging solutions would build and in the couple",
    "start": "169760",
    "end": "175319"
  },
  {
    "text": "in the last couple of years I've been leading a platform team in one of our uh largest EV clients charging EV charging",
    "start": "175319",
    "end": "182200"
  },
  {
    "text": "clients and in this theme the goal is basically to provide an easy to use uh reliable interface to the charging",
    "start": "182200",
    "end": "188959"
  },
  {
    "text": "stations we don't have any user-facing products ourself but we rather offer this platform and the other teams uh",
    "start": "188959",
    "end": "196120"
  },
  {
    "text": "built uh actual business products we offer features like station management",
    "start": "196120",
    "end": "201480"
  },
  {
    "text": "session handling uh authorization remote start and stop for uh controlling your",
    "start": "201480",
    "end": "207000"
  },
  {
    "text": "charging experience via a mobile phone for example uh firmware updates and management uh",
    "start": "207000",
    "end": "213799"
  },
  {
    "text": "and so on and this is what the Baseline architecture uh looks like so um on the",
    "start": "213799",
    "end": "221720"
  },
  {
    "text": "left hand side we have the platform services and uh here we have a component",
    "start": "221720",
    "end": "228080"
  },
  {
    "text": "which is called the websocket gateway it's the entry point for stations to connect to our system it's limited in uh",
    "start": "228080",
    "end": "235680"
  },
  {
    "text": "in in scope it just basically maintains this websocket connection does some parsing some rate",
    "start": "235680",
    "end": "241120"
  },
  {
    "text": "limiting but that's about it and then we have the station Management Service",
    "start": "241120",
    "end": "246239"
  },
  {
    "text": "where most of the business logic is implemented the the ocpp stuff uh",
    "start": "246239",
    "end": "251280"
  },
  {
    "text": "session handling uh and and most of the business logic of our platform and then",
    "start": "251280",
    "end": "256680"
  },
  {
    "text": "on the right we have uh a few more services which are isolated in scope like the firmware service history for",
    "start": "256680",
    "end": "263840"
  },
  {
    "text": "for times years data and analytics Diagnostics and so on and um all of this",
    "start": "263840",
    "end": "269800"
  },
  {
    "text": "this is exposed via an API to uh to the product teams either b2c or B2B uh and",
    "start": "269800",
    "end": "277440"
  },
  {
    "text": "they they can use that to build uh stuff like home charging for people who buy a charging station and install it in their",
    "start": "277440",
    "end": "283400"
  },
  {
    "text": "homes dealer charging for companies that provide uh charging at their facilities",
    "start": "283400",
    "end": "289680"
  },
  {
    "text": "and a lot of other products as well um now let me do a quick primer",
    "start": "289680",
    "end": "295479"
  },
  {
    "text": "about websockets so even if you haven't used them before you can will follow the rest of the talk uh so websockets is",
    "start": "295479",
    "end": "303479"
  },
  {
    "text": "basically a protocol that uh enables low latency by directional communication",
    "start": "303479",
    "end": "308680"
  },
  {
    "text": "between a client and a server in our case the clients are the charging stations and the server is the websocket",
    "start": "308680",
    "end": "314840"
  },
  {
    "text": "component uh that we saw earlier uh basically it provides a persistent",
    "start": "314840",
    "end": "319960"
  },
  {
    "text": "connection uh over uh over a single TCP uh uh a",
    "start": "319960",
    "end": "325560"
  },
  {
    "text": "persistent Channel over a single TCP connection and comparing it to H gpp the",
    "start": "325560",
    "end": "331080"
  },
  {
    "text": "benefit here is that the client doesn't have to reestablish uh a new TCP connection every time that they want to",
    "start": "331080",
    "end": "337240"
  },
  {
    "text": "send a message right this uh connection can be reused uh and uh you can get uh rid of a",
    "start": "337240",
    "end": "345160"
  },
  {
    "text": "lot of the overheads of course it has a price and this price is that the server now has to",
    "start": "345160",
    "end": "350440"
  },
  {
    "text": "maintain this state of the connection the connection is long lift and it's stateful uh in nature and you can read",
    "start": "350440",
    "end": "358039"
  },
  {
    "text": "more about it I left the link there but basically that's that's more or less it has use cases in a lot of",
    "start": "358039",
    "end": "364680"
  },
  {
    "text": "applications that need some realtime communication like for example um multiplayer games uh collaborative",
    "start": "364680",
    "end": "372240"
  },
  {
    "text": "editing um chats stock tickers and so on and that brings us to the trouble",
    "start": "372240",
    "end": "379360"
  },
  {
    "start": "378000",
    "end": "790000"
  },
  {
    "text": "with scaling out websockets so we'll explore a little bit why is it different for example comparing it to an HTTP web",
    "start": "379360",
    "end": "386280"
  },
  {
    "text": "server what's what's exactly the challenge first off let's start with load balancing and horizontal",
    "start": "386280",
    "end": "393680"
  },
  {
    "text": "autoscaling so consider here the the the situation on the left it's um we have a",
    "start": "393680",
    "end": "401160"
  },
  {
    "text": "a network load balancer with a standard brown Robin strategy and let's say that",
    "start": "401160",
    "end": "407440"
  },
  {
    "text": "uh websocket Gateway has uh four parts it's a horizontally scaled application",
    "start": "407440",
    "end": "412639"
  },
  {
    "text": "and this would be an equilibrium state so each of the pots is maintaining 8,000 connections 8,000 stations basically",
    "start": "412639",
    "end": "420120"
  },
  {
    "text": "and everything is in equilibrium but if there is a restart in one of the pods for whatever reason or",
    "start": "420120",
    "end": "427120"
  },
  {
    "text": "even if uh the HPA decides to scale up or down this can change that situation",
    "start": "427120",
    "end": "432720"
  },
  {
    "text": "uh pretty easily so here for example pod number four was restarted those stations disconnect and",
    "start": "432720",
    "end": "440440"
  },
  {
    "text": "then they reconnect again but uh the load balancer will simply redistribute",
    "start": "440440",
    "end": "445840"
  },
  {
    "text": "those and we'll end up with a situation like the one in the right where where now we have some pots with more",
    "start": "445840",
    "end": "451919"
  },
  {
    "text": "connections some with fewer connections and of course with time you know",
    "start": "451919",
    "end": "457240"
  },
  {
    "text": "stations reconnect uh and this will go to an equilibrium but an indefinite amount of time is needed for this to",
    "start": "457240",
    "end": "464120"
  },
  {
    "text": "happen and during this time there can be instabilities right so some pods are serving more connections maybe they can",
    "start": "464120",
    "end": "469720"
  },
  {
    "text": "run out of memory crash uh and um maybe the clients will experience high high",
    "start": "469720",
    "end": "476599"
  },
  {
    "text": "tail latencies at those at those spots uh so the system can end up in this uh",
    "start": "476599",
    "end": "483599"
  },
  {
    "text": "State out of equilibrium which can be problematic the second problem has to do",
    "start": "483599",
    "end": "489400"
  },
  {
    "text": "with something that call a reconnection storm uh so I mentioned earlier",
    "start": "489400",
    "end": "495639"
  },
  {
    "text": "that stations are connected to the internet via mobile carriers so let's",
    "start": "495639",
    "end": "501120"
  },
  {
    "text": "consider a situation where some stations on on the left here are connected via",
    "start": "501120",
    "end": "507120"
  },
  {
    "text": "carrier number one some stations or 10,000 stations are connected via carrier number",
    "start": "507120",
    "end": "512320"
  },
  {
    "text": "two and if this carrier number one has an issue an outage uh maybe a regional",
    "start": "512320",
    "end": "519320"
  },
  {
    "text": "uh outage all of those stations will will lose the connection all at once and",
    "start": "519320",
    "end": "525160"
  },
  {
    "text": "then they will try to connect all at once as well as as soon as this issue",
    "start": "525160",
    "end": "530440"
  },
  {
    "text": "with the U with the network carrier is resolved and basically what this causes",
    "start": "530440",
    "end": "536680"
  },
  {
    "text": "is large unpredictable loads spikes and it's a little bit like an accidental",
    "start": "536680",
    "end": "542320"
  },
  {
    "text": "denial of service ad act what would usually help here is uh",
    "start": "542320",
    "end": "547519"
  },
  {
    "text": "retry with an exponential back off however we don't really have control over this because it's the vendors that",
    "start": "547519",
    "end": "553640"
  },
  {
    "text": "implement the the station firmware and ideally they should do that they should",
    "start": "553640",
    "end": "560079"
  },
  {
    "text": "Implement that retry with exponential back off but in practice uh we rarely see uh them doing it and usually just",
    "start": "560079",
    "end": "567040"
  },
  {
    "text": "the stations reconnect immedi after they are disconnected and this is problematic",
    "start": "567040",
    "end": "573480"
  },
  {
    "text": "uh triggers can be uh Network carrier outages as we saw as I described",
    "start": "573480",
    "end": "579680"
  },
  {
    "text": "earlier uh it can be even much more benign things like a release in the",
    "start": "579680",
    "end": "585440"
  },
  {
    "text": "websocket Gateway or a pot being rescheduled right this can start up uh",
    "start": "585440",
    "end": "591600"
  },
  {
    "text": "can create a load Spike which might later lead to to positive feedback loops",
    "start": "591600",
    "end": "596880"
  },
  {
    "text": "so let's look at the implications a little bit the the system is always at a risk of entering an unstable State there",
    "start": "596880",
    "end": "604720"
  },
  {
    "text": "is always a risk of these uh positive feedback loops so let's say let's say a",
    "start": "604720",
    "end": "612399"
  },
  {
    "text": "large number of stations try to reconnect at at once maybe some pods will crash causing more stations to lose",
    "start": "612399",
    "end": "619640"
  },
  {
    "text": "their connections and then those stations will immediately try to connect again and this can lead to the cycle a",
    "start": "619640",
    "end": "626240"
  },
  {
    "text": "positive feedback loop which then the system cannot recover from uh by itself um another one is load Spike",
    "start": "626240",
    "end": "635040"
  },
  {
    "text": "propagation so even in the case that the platform can handle the load U",
    "start": "635040",
    "end": "640959"
  },
  {
    "text": "itself uh the downstream Services might not be able to handle that kind of load",
    "start": "640959",
    "end": "646600"
  },
  {
    "text": "these spikes so this is also an issue that uh that plagued our system a little",
    "start": "646600",
    "end": "654000"
  },
  {
    "text": "bit um and also um another smaller thing less serious it's that",
    "start": "654000",
    "end": "660120"
  },
  {
    "text": "during releases of the websocket Gateway component um we know that there is user",
    "start": "660120",
    "end": "665320"
  },
  {
    "text": "impact so there is connection disruption it doesn't make the station completely unusable but still it it uh makes the",
    "start": "665320",
    "end": "672519"
  },
  {
    "text": "user experience worse so since we know this we introduced the maintenance window Rule and every time we need to",
    "start": "672519",
    "end": "679079"
  },
  {
    "text": "make a release there we had to announce this it's it's quite quite an annoying thing to do and also it goes against our",
    "start": "679079",
    "end": "686560"
  },
  {
    "text": "continuous delivery practices and back to our incident that we saw",
    "start": "686560",
    "end": "692200"
  },
  {
    "text": "earlier so this was also caused by one of these spikes in in",
    "start": "692200",
    "end": "697519"
  },
  {
    "text": "reconnections and um it was a combination of factors really that ended up in in this uh in this incident it was",
    "start": "697519",
    "end": "706200"
  },
  {
    "text": "the size of the database the target utilization of memory uh and and CPU in",
    "start": "706200",
    "end": "712120"
  },
  {
    "text": "the pods um the load at that time uh but the root cause was something",
    "start": "712120",
    "end": "719040"
  },
  {
    "text": "else else it was in the logger some misconfiguration we were logging to the logging API and it wasn't",
    "start": "719040",
    "end": "726399"
  },
  {
    "text": "able to accept all all requests caused some back back pressure which eventually",
    "start": "726399",
    "end": "731800"
  },
  {
    "text": "led to pods being killed because there were running out of memory so it was batching all of these log items for",
    "start": "731800",
    "end": "738240"
  },
  {
    "text": "longer than it should and uh it was causing this however this wasn't",
    "start": "738240",
    "end": "743480"
  },
  {
    "text": "introduced in a release or something the logger had been like that for a long period of time what really triggered this is this combination of factors and",
    "start": "743480",
    "end": "751240"
  },
  {
    "text": "the nature of the station reconnections and and this reconnection storm uh",
    "start": "751240",
    "end": "757000"
  },
  {
    "text": "Behavior Uh so we knew that uh something had to be done and we needed to improve",
    "start": "757000",
    "end": "763240"
  },
  {
    "text": "um the reliability and scalability of our system I really like this quote from",
    "start": "763240",
    "end": "769199"
  },
  {
    "text": "Google's SRE book reliability is the most important feature of any system and",
    "start": "769199",
    "end": "774320"
  },
  {
    "text": "it's certainly true in our case so reliability is really the core value propos that we offer to the platform",
    "start": "774320",
    "end": "781800"
  },
  {
    "text": "teams um so we set out to to tackle these challenges and um let's see how we",
    "start": "781800",
    "end": "789959"
  },
  {
    "text": "did that so how did we address these challenges um let's start by looking at",
    "start": "789959",
    "end": "797480"
  },
  {
    "text": "the connection flow again I listed the steps here but I won't go through them it's more for completeness really uh but",
    "start": "797480",
    "end": "805040"
  },
  {
    "text": "what's um what's the takeaway here is that in the website Gateway component uh",
    "start": "805040",
    "end": "810680"
  },
  {
    "text": "which is horizontal scaled as is the station Management Service there we we do the termination of uh TLS we do some",
    "start": "810680",
    "end": "819199"
  },
  {
    "text": "parsing we do some rate limiting and then uh the authentication process for",
    "start": "819199",
    "end": "825519"
  },
  {
    "text": "for the station uh happens in the station Management Service and during this process we save a couple of things",
    "start": "825519",
    "end": "831839"
  },
  {
    "text": "regarding that connection in the postgress database and during times of high load uh what happens is that that",
    "start": "831839",
    "end": "839120"
  },
  {
    "text": "this database can become a ball neck uh so this is the main takeaway from uh from this uh connection flow uh that I",
    "start": "839120",
    "end": "846480"
  },
  {
    "text": "wanted to show so there are a couple wres a couple reads that happen to the database and during peak times of load",
    "start": "846480",
    "end": "853920"
  },
  {
    "text": "uh this can be uh a bottleneck some quick remedies that we",
    "start": "853920",
    "end": "859880"
  },
  {
    "text": "could apply right away are basically over provision the database yeah just throw some money at the problem hope",
    "start": "859880",
    "end": "866959"
  },
  {
    "text": "that it goes away it's wasteful and costly of course but still as a temporary solution it's it's pretty",
    "start": "866959",
    "end": "873440"
  },
  {
    "text": "helpful um another thing which is a little bit more subtle is to adjust the",
    "start": "873440",
    "end": "880759"
  },
  {
    "text": "horizontal pod autoscaler uh stabilization window so we have a couple",
    "start": "880759",
    "end": "886000"
  },
  {
    "text": "of metric C that we use for scaling up and down and we don't want to react to every single fluctuation there so",
    "start": "886000",
    "end": "892839"
  },
  {
    "text": "because of this reconnection Behavior we want to avoid that as much as possible uh so basically making this this larger",
    "start": "892839",
    "end": "899839"
  },
  {
    "text": "helps you smoothen out uh the reactions of the HPA and helps uh avoid these",
    "start": "899839",
    "end": "906240"
  },
  {
    "text": "fluctuations in the replica count yeah that's good enough for some",
    "start": "906240",
    "end": "911600"
  },
  {
    "text": "quick remedies uh but we also set some goals that we wanted for our long-term",
    "start": "911600",
    "end": "918199"
  },
  {
    "text": "Solutions and primarily we wanted a more lightweight connection flow that we",
    "start": "918199",
    "end": "924000"
  },
  {
    "text": "could scale uh easier and that would also help us alleviate database related",
    "start": "924000",
    "end": "930600"
  },
  {
    "text": "ball necks right so as we saw earlier we had to over provision the database by",
    "start": "930600",
    "end": "935800"
  },
  {
    "text": "quite a lot we also wanted to decouple the downstream services to stop this",
    "start": "935800",
    "end": "942079"
  },
  {
    "text": "propagation of load spikes that I described earlier and also we wanted to dis reduce",
    "start": "942079",
    "end": "948160"
  },
  {
    "text": "the disruption during releases so find a way that hopefully we can remove this uh",
    "start": "948160",
    "end": "954839"
  },
  {
    "text": "maintenance window Rule and also have as little as impact in the in the user",
    "start": "954839",
    "end": "959959"
  },
  {
    "text": "experience when we are doing a release in the websocket Gateway component so these are some goals that",
    "start": "959959",
    "end": "965880"
  },
  {
    "text": "we set out for ourselves uh and now we go into a little bit more uh concrete um approaches how",
    "start": "965880",
    "end": "973240"
  },
  {
    "start": "972000",
    "end": "1170000"
  },
  {
    "text": "we how we try to achieve this first I'll discuss about optimizing the websocket",
    "start": "973240",
    "end": "979600"
  },
  {
    "text": "connection flow so some observations um we saw this",
    "start": "979600",
    "end": "986800"
  },
  {
    "text": "earlier this is not new the key observation is that the connectivity",
    "start": "986800",
    "end": "993079"
  },
  {
    "text": "data that we stored in the postgress database was aeral in nature that means",
    "start": "993079",
    "end": "998279"
  },
  {
    "text": "that um we don't really need the durability guarantees of postgress to",
    "start": "998279",
    "end": "1004240"
  },
  {
    "text": "store that and um if we could avoid storing in",
    "start": "1004240",
    "end": "1009360"
  },
  {
    "text": "the postgress database that would be great because then in times of high load we don't really need to reach out to the",
    "start": "1009360",
    "end": "1016000"
  },
  {
    "text": "database and we can avoid that uh model neck so uh what we did here is basically",
    "start": "1016000",
    "end": "1022759"
  },
  {
    "text": "introduced this service that we call the connectivity service this encapsulates",
    "start": "1022759",
    "end": "1028640"
  },
  {
    "text": "the the connection logic and the the connection connectivity domain uh and um",
    "start": "1028640",
    "end": "1035480"
  },
  {
    "text": "it it modifies the connection in such a the the flow a little bit so that we no",
    "start": "1035480",
    "end": "1040760"
  },
  {
    "text": "longer need to store that data in the postgress database but we can do it in a in memory database yeah it boils down to",
    "start": "1040760",
    "end": "1049320"
  },
  {
    "text": "memory being faster than than dis and for our case this is great fit because",
    "start": "1049320",
    "end": "1055280"
  },
  {
    "text": "even if let's say something goes wrong with the inmemory database the server crashes we can easily recreate that data",
    "start": "1055280",
    "end": "1061320"
  },
  {
    "text": "by having the stations reconnect right that's sorry without going into",
    "start": "1061320",
    "end": "1068039"
  },
  {
    "text": "the the uh backup mechanisms for reddis and so on right so even if it crashes we",
    "start": "1068039",
    "end": "1075559"
  },
  {
    "text": "can easily recreate it uh and and have the data back in in the Rus database so",
    "start": "1075559",
    "end": "1082280"
  },
  {
    "text": "fmal data is a great fit for uh uh for the inmemory database",
    "start": "1082280",
    "end": "1089200"
  },
  {
    "text": "um and what we saw is that we were able to reduce the connection establishing",
    "start": "1089200",
    "end": "1094600"
  },
  {
    "text": "Time by one order of magnitude and um we reduce the load on",
    "start": "1094600",
    "end": "1099760"
  },
  {
    "text": "the postgress database which means we can also now scale down to a much more reasonable size we no longer need the",
    "start": "1099760",
    "end": "1106280"
  },
  {
    "text": "database to be able to take in the the peak of the of the of these traffic spikes",
    "start": "1106280",
    "end": "1112000"
  },
  {
    "text": "right which is orders of magnitude or at least one order of magnitude uh larger",
    "start": "1112000",
    "end": "1118320"
  },
  {
    "text": "compared to normal traffic or normal load in the database and we also were able to",
    "start": "1118320",
    "end": "1124400"
  },
  {
    "text": "decouple the the connection flow from other functionalities uh for it was we used",
    "start": "1124400",
    "end": "1130200"
  },
  {
    "text": "this chance since we were revising the flow a little bit we used this chance to also uh refactor quite a few things it",
    "start": "1130200",
    "end": "1137400"
  },
  {
    "text": "was intertwined with some other flows like the certificate renewal flow and um",
    "start": "1137400",
    "end": "1143919"
  },
  {
    "text": "we used this chance to also uh do some decoupling there so all in all we were we were pretty happy with this was a",
    "start": "1143919",
    "end": "1150600"
  },
  {
    "text": "long migration process and it took some effort had a lot of subties uh but it",
    "start": "1150600",
    "end": "1156799"
  },
  {
    "text": "was really worth it uh in the end um yes uh but still uh another problem",
    "start": "1156799",
    "end": "1164120"
  },
  {
    "text": "the problem that we had remaining is that uh during a release",
    "start": "1164120",
    "end": "1169520"
  },
  {
    "text": "we still had a lot of disruptions and",
    "start": "1169520",
    "end": "1174639"
  },
  {
    "start": "1170000",
    "end": "1464000"
  },
  {
    "text": "um a lot of user impact when we were doing a release so let's see how we",
    "start": "1175200",
    "end": "1181200"
  },
  {
    "text": "tackle that uh so one",
    "start": "1181200",
    "end": "1189320"
  },
  {
    "text": "second the root of the problem was in rolling updates in kubernetes so the",
    "start": "1195559",
    "end": "1201600"
  },
  {
    "text": "idea with rolling updates is to incrementally replace current pods with",
    "start": "1201600",
    "end": "1206720"
  },
  {
    "text": "newer pods right and Max search and Max and available let you control this how fast this happens uh and there are some",
    "start": "1206720",
    "end": "1214320"
  },
  {
    "text": "other configurations as well but these are the the the main ones um rolling up",
    "start": "1214320",
    "end": "1220360"
  },
  {
    "text": "dates are great are great in most cases right they give you zero downtime",
    "start": "1220360",
    "end": "1226159"
  },
  {
    "text": "deployments without basically having to change anything and they are perfect fit for most applications however they are a",
    "start": "1226159",
    "end": "1234159"
  },
  {
    "text": "bad fit for applications sensitive to disruptions like like websocket Gateway",
    "start": "1234159",
    "end": "1240799"
  },
  {
    "text": "where we have these long uh lift connections that we don't want to disrupt let's see why so take a look",
    "start": "1240799",
    "end": "1247799"
  },
  {
    "text": "at uh at this scenario so we have the station connected let's say we have three",
    "start": "1247799",
    "end": "1253360"
  },
  {
    "text": "replicas uh three replicas yeah of version one and we want to do an update",
    "start": "1253360",
    "end": "1259200"
  },
  {
    "text": "and we'll start by basically uh killing uh one uh pod from version one scaling",
    "start": "1259200",
    "end": "1267159"
  },
  {
    "text": "up a version two pod and at that point the station would lose connection but it will then try to connect to another pod",
    "start": "1267159",
    "end": "1275520"
  },
  {
    "text": "and establish it again right and then we repeat this process a couple of times until we have all of the pods in version",
    "start": "1275520",
    "end": "1284360"
  },
  {
    "text": "two you see even in this trival example with just three pods and one station the",
    "start": "1284360",
    "end": "1290640"
  },
  {
    "text": "station lost its connection three times it had to reconnect and this causes a u a bad",
    "start": "1290640",
    "end": "1300400"
  },
  {
    "text": "experience basically on the user side it causes quite some considerable impact um",
    "start": "1300400",
    "end": "1306760"
  },
  {
    "text": "so ideally we we would need to to avoid this and you can imagine what happens uh",
    "start": "1306760",
    "end": "1313080"
  },
  {
    "text": "when there are multiple stations and and many more pods right these traffic spikes this is also reason why the",
    "start": "1313080",
    "end": "1319640"
  },
  {
    "text": "traffic spikes are Amplified a bit because uh stations are connected or are",
    "start": "1319640",
    "end": "1325200"
  },
  {
    "text": "trying to reconnect multiple times uh during uh release with rolling",
    "start": "1325200",
    "end": "1330240"
  },
  {
    "text": "updates and um a way to tackle this is basically to switch to blue green",
    "start": "1330240",
    "end": "1335559"
  },
  {
    "text": "deployments let's do a quick overview of how that works so we would have a",
    "start": "1335559",
    "end": "1341279"
  },
  {
    "text": "replica set of three and version one and then the idea is um to switch the",
    "start": "1341279",
    "end": "1348559"
  },
  {
    "text": "traffic all at once so first we would bring up version two uh the same replica",
    "start": "1348559",
    "end": "1354279"
  },
  {
    "text": "set we can run some checks right before promoting it uh look at some metrics and",
    "start": "1354279",
    "end": "1361200"
  },
  {
    "text": "then we would switch the traffic of the stations all at once and ideally here the stations would disconnect only once",
    "start": "1361200",
    "end": "1368559"
  },
  {
    "text": "so there is only one reconnection in total uh when this update happens eventually we can remove the version one",
    "start": "1368559",
    "end": "1374960"
  },
  {
    "text": "pods and then the release is finished uh we arol rollouts I left the link there",
    "start": "1374960",
    "end": "1380440"
  },
  {
    "text": "to do this to to do blue green deployments it has a lot more features than we use and I definitely recommend",
    "start": "1380440",
    "end": "1386080"
  },
  {
    "text": "it if you are uh looking to use blue green",
    "start": "1386080",
    "end": "1391559"
  },
  {
    "text": "deployments um the plot here uh on the left hand side also shows uh a little",
    "start": "1391559",
    "end": "1398279"
  },
  {
    "text": "bit what I was describing so on the y-axis we have the number of total connections and on the x-axis we have",
    "start": "1398279",
    "end": "1405080"
  },
  {
    "text": "time and you can see that it really takes a while to recover to that normal",
    "start": "1405080",
    "end": "1411080"
  },
  {
    "text": "um load or to the to the point where all stations are uh",
    "start": "1411080",
    "end": "1416799"
  },
  {
    "text": "reconnected and uh comparing that to the blue green uh approach this window this",
    "start": "1416799",
    "end": "1424080"
  },
  {
    "text": "time window of disruptions is really reduced by a lot and by some measurements that we did was around 80%",
    "start": "1424080",
    "end": "1430840"
  },
  {
    "text": "uh on on average reduction by simply switching to blue green deoy uh deployment so this is really an example",
    "start": "1430840",
    "end": "1437679"
  },
  {
    "text": "where it's quite a low effort investment but it really pays off the return of",
    "start": "1437679",
    "end": "1443520"
  },
  {
    "text": "investment for this was uh quite large for us um and it really helped us improve",
    "start": "1443520",
    "end": "1451559"
  },
  {
    "text": "the reliability of of the system also uh the reduce the disruptions during a",
    "start": "1451559",
    "end": "1459600"
  },
  {
    "text": "release uh so that's the second thing that we did but now uh let's take a look",
    "start": "1459600",
    "end": "1466360"
  },
  {
    "start": "1464000",
    "end": "1860000"
  },
  {
    "text": "at the load Spike propagation topic that I discussed earlier um if you remember I",
    "start": "1466360",
    "end": "1472640"
  },
  {
    "text": "I was talking about these load spikes that propagate to the downstream services and that's",
    "start": "1472640",
    "end": "1479000"
  },
  {
    "text": "problematic even if the platform can uh can handle the traffic that's still problematic for the downstream Services",
    "start": "1479000",
    "end": "1486080"
  },
  {
    "text": "if they have to handle this traffic as well",
    "start": "1486080",
    "end": "1491120"
  },
  {
    "text": "so um what we did is consider switching or or switch to an event driven",
    "start": "1491120",
    "end": "1497320"
  },
  {
    "text": "architecture uh how many of you are familiar with eventon architecture have you used before that's nice quite a lot I I think",
    "start": "1497320",
    "end": "1505000"
  },
  {
    "text": "everybody has a little bit different everybody means something different with event driven",
    "start": "1505000",
    "end": "1510120"
  },
  {
    "text": "architecture um but um a definition that uh I think a",
    "start": "1510120",
    "end": "1516559"
  },
  {
    "text": "lot of people would agree is that it's basically an architectural pattern uh to build Services which communicate with",
    "start": "1516559",
    "end": "1522679"
  },
  {
    "text": "each other uh asynchronously it uses events an event is both a fact and a a trigger and it's",
    "start": "1522679",
    "end": "1531080"
  },
  {
    "text": "expressed as a notification and usually by the name you can already tell it's always in past tense like station",
    "start": "1531080",
    "end": "1537399"
  },
  {
    "text": "connected or station disconnected or charging session started whatever and uh",
    "start": "1537399",
    "end": "1543080"
  },
  {
    "text": "and then you'd have producers which are publishing these events when something happens in that part of the domain and",
    "start": "1543080",
    "end": "1549640"
  },
  {
    "text": "they would put it in a queue where then consumers can um uh can consume it and",
    "start": "1549640",
    "end": "1555520"
  },
  {
    "text": "Trigger some Logic on their own or simply uh simply ignore it it would need",
    "start": "1555520",
    "end": "1561640"
  },
  {
    "text": "a talk of its own to do it justice to this topic so there is a nice article from AWS and from Martin Fowler that",
    "start": "1561640",
    "end": "1567240"
  },
  {
    "text": "I've linked uh there the URL is not visible but the slides are in sced so you can uh look it",
    "start": "1567240",
    "end": "1575559"
  },
  {
    "text": "up from there and in our case um the reasoning",
    "start": "1575559",
    "end": "1580720"
  },
  {
    "text": "goes a bit like this so um it it really helps eventory",
    "start": "1580720",
    "end": "1585840"
  },
  {
    "text": "architecture and and aing and an asynchronous communication way really helps with uh circuit breaking uh",
    "start": "1585840",
    "end": "1593760"
  },
  {
    "text": "between the platform and the downstream services and we could put a stop basically to to the propagation of load",
    "start": "1593760",
    "end": "1601600"
  },
  {
    "text": "spikes uh in our case we use gcp pup sub and for example the push subscriptions U",
    "start": "1601600",
    "end": "1608159"
  },
  {
    "text": "have a mechanism similar to the TCP uh congestion control mechanism so so that",
    "start": "1608159",
    "end": "1613760"
  },
  {
    "text": "it avoids overwhelming the subscriber if the subscriber has a tough time",
    "start": "1613760",
    "end": "1620159"
  },
  {
    "text": "processing the request right so it doesn't overwhelm or it doesn't run into these bottlenecks uh that a subscribe",
    "start": "1620159",
    "end": "1627760"
  },
  {
    "text": "might have typically the database right so or if you're using poll subscriptions",
    "start": "1627760",
    "end": "1633600"
  },
  {
    "text": "there is a a flow control U rate that pops up gives you uh so basically this",
    "start": "1633600",
    "end": "1639960"
  },
  {
    "text": "is the circuit breaking aspect that the event cues provide us",
    "start": "1639960",
    "end": "1645240"
  },
  {
    "text": "um another thing another benefit of event driven architecture is that it helps decoupling services and teams and",
    "start": "1645240",
    "end": "1653760"
  },
  {
    "text": "uh the the goal is to have more independent teams and and better split",
    "start": "1653760",
    "end": "1659520"
  },
  {
    "text": "uh or or clearer better boundaries between the services and even it",
    "start": "1659520",
    "end": "1665320"
  },
  {
    "text": "architecture isn't necessarily the only way to achieve it but it it helps and it usually makes it easier to achieve this",
    "start": "1665320",
    "end": "1672880"
  },
  {
    "text": "decoupling and also um the asynchronous communication way uh fits well to the",
    "start": "1672880",
    "end": "1679519"
  },
  {
    "text": "underlying business processes that we have so it really uh we can model the business processes well and therefore it",
    "start": "1679519",
    "end": "1686360"
  },
  {
    "text": "was a good fit for us and it helps us uh address a lot of the problems however",
    "start": "1686360",
    "end": "1692159"
  },
  {
    "text": "there there are a bunch of um use cases where event driven architecture is a pretty bad fit so even",
    "start": "1692159",
    "end": "1700159"
  },
  {
    "text": "though you know event driven architecture is is pretty cool you know it gets you a lot of street cred it's",
    "start": "1700159",
    "end": "1705399"
  },
  {
    "text": "right up there with rewriting your system in Rust uh it doesn't uh we doesn't mean that we apply",
    "start": "1705399",
    "end": "1712919"
  },
  {
    "text": "it mindlessly uh everywhere right so we really have to pick and and make a a",
    "start": "1712919",
    "end": "1718399"
  },
  {
    "text": "good choice and a deliberate choice about the trade-offs that we are making for example one of the uh one of the",
    "start": "1718399",
    "end": "1725679"
  },
  {
    "text": "trade-offs is eventual consistency not all system can systems can tolerate eventual",
    "start": "1725679",
    "end": "1731039"
  },
  {
    "text": "consistency um in their in their business flow um yes and",
    "start": "1731039",
    "end": "1738840"
  },
  {
    "text": "um I've listed a little bit of our approach here but I won't go uh through",
    "start": "1738840",
    "end": "1744519"
  },
  {
    "text": "all of it the main takeaway is basically that to be successful with a transition to to event driven it's very critical to",
    "start": "1744519",
    "end": "1752519"
  },
  {
    "text": "to lower the barrier of entry for the teams especially for teams that are coming from a from a synchronous approach of building things and not only",
    "start": "1752519",
    "end": "1761200"
  },
  {
    "text": "uh help in the conceptual level but also on the technical level by providing good abstractions and uh good tooling around",
    "start": "1761200",
    "end": "1767640"
  },
  {
    "text": "them to to to lower this barrier of Entry as much as possible and and make the transition smooth and we we had a",
    "start": "1767640",
    "end": "1774880"
  },
  {
    "text": "lot of uh a lot of effort that we invested into that to to make this uh",
    "start": "1774880",
    "end": "1781159"
  },
  {
    "text": "transition successful uh so that would be the the takeaway there and um with",
    "start": "1781159",
    "end": "1788960"
  },
  {
    "text": "that we we come to the summary so there is no penia in addressing these uh",
    "start": "1788960",
    "end": "1794480"
  },
  {
    "text": "challenges an analysis of the load patterns and analysis of the bottle is",
    "start": "1794480",
    "end": "1799880"
  },
  {
    "text": "crucial to inform your your system design decisions in our case we went a",
    "start": "1799880",
    "end": "1806159"
  },
  {
    "text": "little bit uh through the challenges and now I'll I'll mention again the the the",
    "start": "1806159",
    "end": "1812440"
  },
  {
    "text": "core ideas here so we made the the websocket connection flow more",
    "start": "1812440",
    "end": "1817519"
  },
  {
    "text": "lightweight via introducing an inmemory database um which we can scale",
    "start": "1817519",
    "end": "1823760"
  },
  {
    "text": "independently and scale more easily and avoid the the bottl legs that we have with the postest",
    "start": "1823760",
    "end": "1830679"
  },
  {
    "text": "database um we reduced the disruptions during deployments by introducing blue",
    "start": "1830679",
    "end": "1835840"
  },
  {
    "text": "green deployments we discussed a little bit how the strategy the deployment strategy might affect the reliability of",
    "start": "1835840",
    "end": "1843159"
  },
  {
    "text": "your webset applications um and also we talked a",
    "start": "1843159",
    "end": "1848720"
  },
  {
    "text": "little bit about circuit breaking and uh what you can do to stop these uh propagation of load spikes and even",
    "start": "1848720",
    "end": "1856919"
  },
  {
    "text": "cues and uh that's about it uh I've listed some links you can find me online",
    "start": "1856919",
    "end": "1863960"
  },
  {
    "start": "1860000",
    "end": "2231000"
  },
  {
    "text": "or best of all simply grab me for a chat after the talk and let's now go into a",
    "start": "1863960",
    "end": "1869760"
  },
  {
    "text": "questions and answers [Applause]",
    "start": "1869760",
    "end": "1880529"
  },
  {
    "text": "session hi hello um you were talking about uh pubsub as a way to decouple the",
    "start": "1881600",
    "end": "1888000"
  },
  {
    "text": "Downstream server but you're using the Google so you basically have infinite",
    "start": "1888000",
    "end": "1893799"
  },
  {
    "text": "scaling on your pobub if you're on an own Prem for example wouldn't you just move the blow up or the over scaling",
    "start": "1893799",
    "end": "1900799"
  },
  {
    "text": "from the downstream server to your Pub subsystem that's a good point it's",
    "start": "1900799",
    "end": "1906000"
  },
  {
    "text": "always uh so often with Cloud this is a little bit of a misconception that oh I",
    "start": "1906000",
    "end": "1911960"
  },
  {
    "text": "shifted to the cloud and now it's their problem right so one needs to be aware of um the limits and the quas and and uh",
    "start": "1911960",
    "end": "1920320"
  },
  {
    "text": "what happens when you you get close to those limits it's a good question I think um uh there is no straightforward",
    "start": "1920320",
    "end": "1927720"
  },
  {
    "text": "answer to this but I can say that in our case we did some back of the envelope calculations and we are very much inside",
    "start": "1927720",
    "end": "1935240"
  },
  {
    "text": "the uh the limits uh that pops up has and when we get closer to them we can",
    "start": "1935240",
    "end": "1942799"
  },
  {
    "text": "revisit some decisions and and uh think about it again but uh it's a very good",
    "start": "1942799",
    "end": "1948679"
  },
  {
    "text": "point it's a it's a very good thing to consider when using this and it would be",
    "start": "1948679",
    "end": "1954720"
  },
  {
    "text": "um a misconception to approach it hey it can scale infinitely elastically and I",
    "start": "1954720",
    "end": "1960360"
  },
  {
    "text": "don't have to care about it yeah and it's probably even more concrete when",
    "start": "1960360",
    "end": "1966080"
  },
  {
    "text": "you have you are operating this event broker right and you're not relying on some some Cloud",
    "start": "1966080",
    "end": "1973080"
  },
  {
    "text": "yeah hi uh thank you for the talk when you talked about",
    "start": "1973240",
    "end": "1978360"
  },
  {
    "text": "uh switching to Red Green deployment did you think about somehow making it gradual like creating",
    "start": "1978360",
    "end": "1986440"
  },
  {
    "text": "V2 all at once but then connecting uh killing the V1 ports one by one",
    "start": "1986440",
    "end": "1993320"
  },
  {
    "text": "so uh not all stations reconnect all at the same time because you also get this",
    "start": "1993320",
    "end": "1998639"
  },
  {
    "text": "problem that all all stations will try to reconnect at the same time mhm so did",
    "start": "1998639",
    "end": "2004279"
  },
  {
    "text": "you think maybe about something like gradual red green deployment so you will kill off old connections more",
    "start": "2004279",
    "end": "2011600"
  },
  {
    "text": "gradually um that would be something to consider we didn't do it so uh when we",
    "start": "2011600",
    "end": "2016799"
  },
  {
    "text": "were considering using Argo roll outs or some other solutions that were available we also considered implementing it in",
    "start": "2016799",
    "end": "2023919"
  },
  {
    "text": "our own so that we don't add a dependency basically to the cluster um",
    "start": "2023919",
    "end": "2030279"
  },
  {
    "text": "we did some evaluation of the options and basically the total cost cost of",
    "start": "2030279",
    "end": "2036159"
  },
  {
    "text": "ownership leaned to towards just using Argo I'm not aware that Argo has",
    "start": "2036159",
    "end": "2041440"
  },
  {
    "text": "something like that Argo rollot has something like that that you can gradually uh kill off the the V2 um uh",
    "start": "2041440",
    "end": "2050520"
  },
  {
    "text": "usually it just starts uh killing them as soon as uh the timeout Runs Out Just",
    "start": "2050520",
    "end": "2057520"
  },
  {
    "text": "you have you have uh websocket long lift uh connections so it's a bit unusual use",
    "start": "2057520",
    "end": "2064280"
  },
  {
    "text": "case so when red green uh deployment happen happens if you have standard",
    "start": "2064280",
    "end": "2070440"
  },
  {
    "text": "request response up it doesn't matter but as you describe you have problem of",
    "start": "2070440",
    "end": "2075760"
  },
  {
    "text": "all stations reconnecting at the same time and you kind of get it with red green deployment um okay so you've",
    "start": "2075760",
    "end": "2083398"
  },
  {
    "text": "mentioned eventual consistency and you achieved it through using an inmemory database in between uh",
    "start": "2083399",
    "end": "2091480"
  },
  {
    "text": "the postgress to reduce the um latency",
    "start": "2091480",
    "end": "2096599"
  },
  {
    "text": "that's been caused through the database connectivity",
    "start": "2096599",
    "end": "2102560"
  },
  {
    "text": "um yes what do you think about I mean could you like have used a database that",
    "start": "2103520",
    "end": "2109760"
  },
  {
    "text": "provides eventual consistency instead um I'm not sure if I understand",
    "start": "2109760",
    "end": "2115599"
  },
  {
    "text": "the question correctly so maybe could could you repeat it or rephrase it a bit",
    "start": "2115599",
    "end": "2120680"
  },
  {
    "text": "uh yes instead of um using the inmemory database in",
    "start": "2120680",
    "end": "2126160"
  },
  {
    "text": "between for eventure consistency um wouldn't it have been better to use a",
    "start": "2126160",
    "end": "2133079"
  },
  {
    "text": "database that provides eventure consistency instead um so I would say the goal of",
    "start": "2133079",
    "end": "2140320"
  },
  {
    "text": "switching or using introducing an inmemory Database The Connection flow was not achieving eventual consistency",
    "start": "2140320",
    "end": "2148400"
  },
  {
    "text": "um it was rather making the flow um more manageable to scale and make it",
    "start": "2148400",
    "end": "2155280"
  },
  {
    "text": "independent of the other flows so so if if there is a high load we don't put uh",
    "start": "2155280",
    "end": "2161200"
  },
  {
    "text": "uh high pressure into the postgress database which a lot of the other uh",
    "start": "2161200",
    "end": "2166319"
  },
  {
    "text": "business flows are dependent on uh so we would um we would decouple",
    "start": "2166319",
    "end": "2173400"
  },
  {
    "text": "it from the rest of the flows and make it more lightweight uh and we could scale it independently by just dealing",
    "start": "2173400",
    "end": "2180359"
  },
  {
    "text": "with the Reddit or in our case redis but it can be any in memory database we",
    "start": "2180359",
    "end": "2185680"
  },
  {
    "text": "could scale it independently by just deal with that um yeah so eventual inconsistency I",
    "start": "2185680",
    "end": "2193280"
  },
  {
    "text": "think it came up later right when we introduced event cues mentioned it as a trade-off that comes with asynchronous",
    "start": "2193280",
    "end": "2200720"
  },
  {
    "text": "communication but it wasn't a goal uh in itself to achieve by introducing redus",
    "start": "2200720",
    "end": "2207359"
  },
  {
    "text": "right so um yeah that's I hope that answers the",
    "start": "2207359",
    "end": "2212480"
  },
  {
    "text": "questions or if you have a followup let me know",
    "start": "2212480",
    "end": "2219520"
  },
  {
    "text": "all right it looks like no more questions thank you for joining",
    "start": "2221440",
    "end": "2227760"
  },
  {
    "text": "and",
    "start": "2230079",
    "end": "2233079"
  }
]
[
  {
    "text": "all right we're going to get started um",
    "start": "80",
    "end": "2800"
  },
  {
    "text": "we have a a lot of good stuff for you",
    "start": "2800",
    "end": "4839"
  },
  {
    "text": "hope hopefully everybody's feeling good",
    "start": "4839",
    "end": "6319"
  },
  {
    "text": "after this very nice lunch and uh we had",
    "start": "6319",
    "end": "10200"
  },
  {
    "text": "some technical problems so the topic of",
    "start": "10200",
    "end": "12360"
  },
  {
    "text": "our talk is not visible on the first",
    "start": "12360",
    "end": "14040"
  },
  {
    "text": "slide so we're just going to move to the",
    "start": "14040",
    "end": "15759"
  },
  {
    "text": "next one but you you guys hopefully know",
    "start": "15759",
    "end": "18119"
  },
  {
    "text": "why you're here",
    "start": "18119",
    "end": "20240"
  },
  {
    "text": "so my name is Ashish kamra I'm a senior",
    "start": "20240",
    "end": "23160"
  },
  {
    "text": "manager at uh red hat I lead the AI",
    "start": "23160",
    "end": "26039"
  },
  {
    "text": "performance team at red hat and with me",
    "start": "26039",
    "end": "27840"
  },
  {
    "text": "I have Boaz uh who uh is part of the red",
    "start": "27840",
    "end": "31320"
  },
  {
    "text": "hat performance and scale team and uh he",
    "start": "31320",
    "end": "33320"
  },
  {
    "text": "works on distributed workload training",
    "start": "33320",
    "end": "35120"
  },
  {
    "text": "on",
    "start": "35120",
    "end": "37360"
  },
  {
    "text": "kubernetes so the talk is multinode fine",
    "start": "37559",
    "end": "40480"
  },
  {
    "text": "tuning on llm so let's really look at",
    "start": "40480",
    "end": "42879"
  },
  {
    "text": "why we fine-tune llms in the first",
    "start": "42879",
    "end": "45399"
  },
  {
    "text": "place I again apologize for my bad",
    "start": "45399",
    "end": "47920"
  },
  {
    "text": "throat uh hope it's not too bad for you",
    "start": "47920",
    "end": "50680"
  },
  {
    "text": "guys to make out what I'm saying so",
    "start": "50680",
    "end": "53760"
  },
  {
    "text": "basically when you are fine tuning a",
    "start": "53760",
    "end": "55440"
  },
  {
    "text": "large language model you basically start",
    "start": "55440",
    "end": "57199"
  },
  {
    "text": "with a base llm and you feel the domain",
    "start": "57199",
    "end": "60480"
  },
  {
    "text": "specific data in order to improve its",
    "start": "60480",
    "end": "62920"
  },
  {
    "text": "accuracy specifically on the data that",
    "start": "62920",
    "end": "65119"
  },
  {
    "text": "you're feeding to the llm and the result",
    "start": "65119",
    "end": "67200"
  },
  {
    "text": "is a new fine tune model which is now",
    "start": "67200",
    "end": "68880"
  },
  {
    "text": "more aligned with the data that you fed",
    "start": "68880",
    "end": "70880"
  },
  {
    "text": "it and now it can adhere to your",
    "start": "70880",
    "end": "72880"
  },
  {
    "text": "language style and the data patterns now",
    "start": "72880",
    "end": "75400"
  },
  {
    "text": "the main challenges this process is like",
    "start": "75400",
    "end": "77880"
  },
  {
    "text": "training you're feeding more data to the",
    "start": "77880",
    "end": "79960"
  },
  {
    "text": "model so it's very very",
    "start": "79960",
    "end": "82280"
  },
  {
    "text": "resource uh",
    "start": "82280",
    "end": "84240"
  },
  {
    "text": "intensive and specifically you know in",
    "start": "84240",
    "end": "87920"
  },
  {
    "text": "kubernetes uh this kind of fine tuning",
    "start": "87920",
    "end": "90920"
  },
  {
    "text": "would require you to support high-end",
    "start": "90920",
    "end": "92640"
  },
  {
    "text": "gpus or accelerators um there will be",
    "start": "92640",
    "end": "95439"
  },
  {
    "text": "scheduling complexities because you are",
    "start": "95439",
    "end": "97439"
  },
  {
    "text": "doing it across uh multiple nodes which",
    "start": "97439",
    "end": "100439"
  },
  {
    "text": "is the topic of our talk and U you know",
    "start": "100439",
    "end": "103320"
  },
  {
    "text": "that's where projects like Q can help uh",
    "start": "103320",
    "end": "105560"
  },
  {
    "text": "with with all the scheduling problems",
    "start": "105560",
    "end": "107200"
  },
  {
    "text": "but the main topic of concern is the",
    "start": "107200",
    "end": "109320"
  },
  {
    "text": "networking uh latency concerns when you",
    "start": "109320",
    "end": "111680"
  },
  {
    "text": "are trying to do training across",
    "start": "111680",
    "end": "113920"
  },
  {
    "text": "multiple nodes um which will be the",
    "start": "113920",
    "end": "116360"
  },
  {
    "text": "focus of our",
    "start": "116360",
    "end": "118159"
  },
  {
    "text": "talk so I just wanted to give a kind of",
    "start": "118159",
    "end": "121399"
  },
  {
    "text": "a bird's eye view of what multi-node",
    "start": "121399",
    "end": "123680"
  },
  {
    "text": "fine tuning infrastructure can look like",
    "start": "123680",
    "end": "125360"
  },
  {
    "text": "in general this is not kubernets so you",
    "start": "125360",
    "end": "128039"
  },
  {
    "text": "have multiple compute nodes which have",
    "start": "128039",
    "end": "129840"
  },
  {
    "text": "the gpus or the accelerators which are",
    "start": "129840",
    "end": "132440"
  },
  {
    "text": "actually doing the compute heavy task",
    "start": "132440",
    "end": "135040"
  },
  {
    "text": "then you have a backend Network which is",
    "start": "135040",
    "end": "137440"
  },
  {
    "text": "responsible for all the training traffic",
    "start": "137440",
    "end": "139760"
  },
  {
    "text": "you know all the um the weights and the",
    "start": "139760",
    "end": "142720"
  },
  {
    "text": "gradients and the optimizers that you",
    "start": "142720",
    "end": "144480"
  },
  {
    "text": "want to pass across the various gpus",
    "start": "144480",
    "end": "147080"
  },
  {
    "text": "then you have another Network so it's",
    "start": "147080",
    "end": "149040"
  },
  {
    "text": "better to isolate Network so that you",
    "start": "149040",
    "end": "150560"
  },
  {
    "text": "have better Network performance for",
    "start": "150560",
    "end": "152319"
  },
  {
    "text": "front end and storage traffic storage is",
    "start": "152319",
    "end": "155280"
  },
  {
    "text": "very important because you want to feed",
    "start": "155280",
    "end": "157319"
  },
  {
    "text": "all the compute nodes with the the",
    "start": "157319",
    "end": "160200"
  },
  {
    "text": "training data set and also for taking",
    "start": "160200",
    "end": "162159"
  },
  {
    "text": "checkpoints so I just wanted to give a",
    "start": "162159",
    "end": "164800"
  },
  {
    "text": "bird eye view of this and the focus of",
    "start": "164800",
    "end": "166519"
  },
  {
    "text": "this talk is uh the backend networking",
    "start": "166519",
    "end": "168519"
  },
  {
    "text": "part of it and Boaz has a lot of good",
    "start": "168519",
    "end": "170480"
  },
  {
    "text": "results to show you in that",
    "start": "170480",
    "end": "173560"
  },
  {
    "text": "case um so we'll go through which",
    "start": "173560",
    "end": "176879"
  },
  {
    "text": "operators were used in this particular",
    "start": "176879",
    "end": "178840"
  },
  {
    "text": "experiment um",
    "start": "178840",
    "end": "180519"
  },
  {
    "text": "specifically we're going to focus on",
    "start": "180519",
    "end": "182720"
  },
  {
    "text": "results of TCP versus rocce this is RDMA",
    "start": "182720",
    "end": "186640"
  },
  {
    "text": "over converge ethernet will have a slide",
    "start": "186640",
    "end": "188879"
  },
  {
    "text": "for a sorry quick overview of what Roc",
    "start": "188879",
    "end": "193200"
  },
  {
    "text": "is we'll talk about Laura fine tuning a",
    "start": "193200",
    "end": "195799"
  },
  {
    "text": "little bit um and then nickel is",
    "start": "195799",
    "end": "198720"
  },
  {
    "text": "nvidia's communication libraries and",
    "start": "198720",
    "end": "201080"
  },
  {
    "text": "some of the tuning that we did for to",
    "start": "201080",
    "end": "203159"
  },
  {
    "text": "get better performance and U we'll go",
    "start": "203159",
    "end": "206080"
  },
  {
    "text": "through a lot of results so don't have a",
    "start": "206080",
    "end": "208599"
  },
  {
    "text": "lot of time so I'm just going to quickly",
    "start": "208599",
    "end": "210519"
  },
  {
    "text": "uh walk through some of the operators",
    "start": "210519",
    "end": "213280"
  },
  {
    "text": "first so um first of all we got to",
    "start": "213280",
    "end": "217000"
  },
  {
    "text": "detect um you know what Hardware we are",
    "start": "217000",
    "end": "219720"
  },
  {
    "text": "using on the Node so that's where the",
    "start": "219720",
    "end": "221519"
  },
  {
    "text": "node feature Discovery operator helps us",
    "start": "221519",
    "end": "224560"
  },
  {
    "text": "then we did all these experiments using",
    "start": "224560",
    "end": "226680"
  },
  {
    "text": "Nvidia gpus so for that you know to put",
    "start": "226680",
    "end": "229159"
  },
  {
    "text": "the driver on the compute node and also",
    "start": "229159",
    "end": "232200"
  },
  {
    "text": "all the other um software components",
    "start": "232200",
    "end": "234319"
  },
  {
    "text": "that Nvidia wants on kubernetes you need",
    "start": "234319",
    "end": "236599"
  },
  {
    "text": "the Nvidia GPU operator um we use uh GPU",
    "start": "236599",
    "end": "241560"
  },
  {
    "text": "direct another technology from uh Nvidia",
    "start": "241560",
    "end": "244680"
  },
  {
    "text": "so we need the Nvidia Network operator",
    "start": "244680",
    "end": "246280"
  },
  {
    "text": "for that um we used uh multiple we we're",
    "start": "246280",
    "end": "251439"
  },
  {
    "text": "passing multiple neck ports to our",
    "start": "251439",
    "end": "254159"
  },
  {
    "text": "training pods so we use for that we use",
    "start": "254159",
    "end": "256479"
  },
  {
    "text": "the multin cni boas will go in a little",
    "start": "256479",
    "end": "258720"
  },
  {
    "text": "bit more detail on what that uh multin",
    "start": "258720",
    "end": "260799"
  },
  {
    "text": "cni is later and then the training",
    "start": "260799",
    "end": "262960"
  },
  {
    "text": "operator to actually orchestrate the",
    "start": "262960",
    "end": "264639"
  },
  {
    "text": "training job um and then bunch of",
    "start": "264639",
    "end": "268639"
  },
  {
    "text": "storage related options lvm operator The",
    "start": "268639",
    "end": "271199"
  },
  {
    "text": "Rook operator for consuming St storage",
    "start": "271199",
    "end": "274560"
  },
  {
    "text": "and NFS we actually only use NFS in this",
    "start": "274560",
    "end": "277039"
  },
  {
    "text": "experiment and uh the others are mostly",
    "start": "277039",
    "end": "279800"
  },
  {
    "text": "for reference if you want to use other",
    "start": "279800",
    "end": "282280"
  },
  {
    "text": "storage",
    "start": "282280",
    "end": "283759"
  },
  {
    "text": "options um so this is kind of what the",
    "start": "283759",
    "end": "286240"
  },
  {
    "text": "setup looked like for our experiments so",
    "start": "286240",
    "end": "288840"
  },
  {
    "text": "we only did this on like two nodes uh",
    "start": "288840",
    "end": "291240"
  },
  {
    "text": "one master and one worker each node was",
    "start": "291240",
    "end": "294080"
  },
  {
    "text": "uh fitted with eight Nvidia a100 gpus 80",
    "start": "294080",
    "end": "297600"
  },
  {
    "text": "gig cards each and",
    "start": "297600",
    "end": "300600"
  },
  {
    "text": "two melanox uh connectx 6 cards to each",
    "start": "300600",
    "end": "304240"
  },
  {
    "text": "with two ports um each Port uh 200 gbits",
    "start": "304240",
    "end": "308479"
  },
  {
    "text": "per second and then everything to",
    "start": "308479",
    "end": "311000"
  },
  {
    "text": "connected through",
    "start": "311000",
    "end": "312960"
  },
  {
    "text": "switch um and yeah so we have a pie",
    "start": "312960",
    "end": "315960"
  },
  {
    "text": "torch based uh uh distributed training",
    "start": "315960",
    "end": "318360"
  },
  {
    "text": "job and Boaz will go into more details",
    "start": "318360",
    "end": "320520"
  },
  {
    "text": "later in the slide what that job exactly",
    "start": "320520",
    "end": "322280"
  },
  {
    "text": "is what it does and so we have basically",
    "start": "322280",
    "end": "324960"
  },
  {
    "text": "two pods one on the master worker node",
    "start": "324960",
    "end": "327080"
  },
  {
    "text": "and other one on the work uh uh the",
    "start": "327080",
    "end": "329840"
  },
  {
    "text": "actual just the work",
    "start": "329840",
    "end": "332280"
  },
  {
    "text": "modde okay so I'm just going to skip",
    "start": "332280",
    "end": "334560"
  },
  {
    "text": "over some of these slides because um",
    "start": "334560",
    "end": "337400"
  },
  {
    "text": "don't have a lot of time to go into the",
    "start": "337400",
    "end": "338919"
  },
  {
    "text": "details of each of the operators that we",
    "start": "338919",
    "end": "340600"
  },
  {
    "text": "use but again as I said so we use the",
    "start": "340600",
    "end": "342639"
  },
  {
    "text": "NFD operator to discover all the",
    "start": "342639",
    "end": "344160"
  },
  {
    "text": "features of the node uh the GPU operator",
    "start": "344160",
    "end": "346720"
  },
  {
    "text": "to lay down all the artifacts that",
    "start": "346720",
    "end": "349120"
  },
  {
    "text": "Nvidia uh to make Nvidia gpus work for",
    "start": "349120",
    "end": "352039"
  },
  {
    "text": "AI",
    "start": "352039",
    "end": "352880"
  },
  {
    "text": "training um the network operator for",
    "start": "352880",
    "end": "356400"
  },
  {
    "text": "some of the RDMA features from Nvidia",
    "start": "356400",
    "end": "358880"
  },
  {
    "text": "and multin because we need more",
    "start": "358880",
    "end": "361199"
  },
  {
    "text": "aggregate bandwidth to drive the",
    "start": "361199",
    "end": "363160"
  },
  {
    "text": "training traffic so we need to pass",
    "start": "363160",
    "end": "365520"
  },
  {
    "text": "multiple uh Nick ports to our",
    "start": "365520",
    "end": "367880"
  },
  {
    "text": "ports and finally the cube flow training",
    "start": "367880",
    "end": "370240"
  },
  {
    "text": "operator which is the uh the",
    "start": "370240",
    "end": "372599"
  },
  {
    "text": "orchestrator for um uh running the",
    "start": "372599",
    "end": "376080"
  },
  {
    "text": "training",
    "start": "376080",
    "end": "378240"
  },
  {
    "text": "job so as I said like the main thing",
    "start": "378240",
    "end": "380680"
  },
  {
    "text": "that we want to highlight",
    "start": "380680",
    "end": "382599"
  },
  {
    "text": "is the backend network uh that is very",
    "start": "382599",
    "end": "386560"
  },
  {
    "text": "important for driving Optimal",
    "start": "386560",
    "end": "389080"
  },
  {
    "text": "Performance",
    "start": "389080",
    "end": "390400"
  },
  {
    "text": "so and for that um we want to make a",
    "start": "390400",
    "end": "393680"
  },
  {
    "text": "differentiation between using TCP as",
    "start": "393680",
    "end": "395840"
  },
  {
    "text": "your um layer3 Network versus using",
    "start": "395840",
    "end": "399120"
  },
  {
    "text": "Rocky which is RDMA over converge",
    "start": "399120",
    "end": "400919"
  },
  {
    "text": "ethernet know this is kind of a dense",
    "start": "400919",
    "end": "402759"
  },
  {
    "text": "slide don't have time to go through all",
    "start": "402759",
    "end": "404599"
  },
  {
    "text": "of it but just one the important thing",
    "start": "404599",
    "end": "406840"
  },
  {
    "text": "to note here is that with the RDMA over",
    "start": "406840",
    "end": "409199"
  },
  {
    "text": "converge ethernet we bypass the kernel",
    "start": "409199",
    "end": "411800"
  },
  {
    "text": "when we are doing the data transfer over",
    "start": "411800",
    "end": "413280"
  },
  {
    "text": "the network so so instead of copying",
    "start": "413280",
    "end": "415840"
  },
  {
    "text": "memory",
    "start": "415840",
    "end": "417000"
  },
  {
    "text": "from uh the CPU memory to the Network",
    "start": "417000",
    "end": "419800"
  },
  {
    "text": "buffers you can you directly copy memory",
    "start": "419800",
    "end": "422039"
  },
  {
    "text": "from your application byp passing the",
    "start": "422039",
    "end": "424199"
  },
  {
    "text": "CPU and just directly over the network",
    "start": "424199",
    "end": "427280"
  },
  {
    "text": "and that really helps with in case of",
    "start": "427280",
    "end": "429639"
  },
  {
    "text": "gpus because there is uh while doing AI",
    "start": "429639",
    "end": "432440"
  },
  {
    "text": "training or fine-tuning there's lot of",
    "start": "432440",
    "end": "434720"
  },
  {
    "text": "inter GPU memory data transfer and",
    "start": "434720",
    "end": "437560"
  },
  {
    "text": "memory copy that needs to happen so",
    "start": "437560",
    "end": "439919"
  },
  {
    "text": "using RDMA and also GPU direct you could",
    "start": "439919",
    "end": "443560"
  },
  {
    "text": "actually copy data from one GPU to",
    "start": "443560",
    "end": "445199"
  },
  {
    "text": "another just bypassing the CPU",
    "start": "445199",
    "end": "446840"
  },
  {
    "text": "completely in the loop that really helps",
    "start": "446840",
    "end": "448879"
  },
  {
    "text": "with the",
    "start": "448879",
    "end": "450039"
  },
  {
    "text": "the networking and and you will see that",
    "start": "450039",
    "end": "452680"
  },
  {
    "text": "in some of the results that boas will go",
    "start": "452680",
    "end": "455280"
  },
  {
    "text": "through the subsequent slides all right",
    "start": "455280",
    "end": "458840"
  },
  {
    "text": "we good okay did pretty well on",
    "start": "458840",
    "end": "463120"
  },
  {
    "text": "time okay so uh let's talk a little bit",
    "start": "463120",
    "end": "466199"
  },
  {
    "text": "about the result before I go into it uh",
    "start": "466199",
    "end": "468599"
  },
  {
    "text": "the thing I want you to come out with",
    "start": "468599",
    "end": "470599"
  },
  {
    "text": "with this uh presentation is basically",
    "start": "470599",
    "end": "473800"
  },
  {
    "text": "you will know how to get more out of",
    "start": "473800",
    "end": "476280"
  },
  {
    "text": "your own system if you are running any",
    "start": "476280",
    "end": "478479"
  },
  {
    "text": "Nvidia training or or you know any type",
    "start": "478479",
    "end": "480840"
  },
  {
    "text": "of training at all uh you can maximize",
    "start": "480840",
    "end": "484000"
  },
  {
    "text": "it in a couple of ways uh we'll go",
    "start": "484000",
    "end": "487280"
  },
  {
    "text": "through that when we look at the results",
    "start": "487280",
    "end": "489759"
  },
  {
    "text": "some of them will have to go through",
    "start": "489759",
    "end": "491759"
  },
  {
    "text": "pretty fast because uh yeah down",
    "start": "491759",
    "end": "495039"
  },
  {
    "text": "limitation uh okay so the training info",
    "start": "495039",
    "end": "498440"
  },
  {
    "text": "uh you can see that I'm using the metal",
    "start": "498440",
    "end": "501520"
  },
  {
    "text": "L 3B instruct uh for our module and as",
    "start": "501520",
    "end": "506560"
  },
  {
    "text": "the data set I took 500 samp",
    "start": "506560",
    "end": "510199"
  },
  {
    "text": "from the open web text just rly Shuffle",
    "start": "510199",
    "end": "513760"
  },
  {
    "text": "some of the examples uh the training",
    "start": "513760",
    "end": "516159"
  },
  {
    "text": "script I'm using is the FMS HF tuning",
    "start": "516159",
    "end": "520680"
  },
  {
    "text": "which you can create your own but uh I",
    "start": "520680",
    "end": "523640"
  },
  {
    "text": "took something that I know that is",
    "start": "523640",
    "end": "525080"
  },
  {
    "text": "already been you know working and uh uh",
    "start": "525080",
    "end": "529519"
  },
  {
    "text": "fit what I was trying to do um and uh",
    "start": "529519",
    "end": "534320"
  },
  {
    "text": "the metrics so the metrics I'm going to",
    "start": "534320",
    "end": "536360"
  },
  {
    "text": "present basically the results are going",
    "start": "536360",
    "end": "538600"
  },
  {
    "text": "to be the SM utilization uh which I what",
    "start": "538600",
    "end": "541880"
  },
  {
    "text": "it is we basically measure the",
    "start": "541880",
    "end": "544040"
  },
  {
    "text": "percentage of streaming",
    "start": "544040",
    "end": "545680"
  },
  {
    "text": "microprocessors on a GPU well the active",
    "start": "545680",
    "end": "548480"
  },
  {
    "text": "ones this is how we trying to determine",
    "start": "548480",
    "end": "550680"
  },
  {
    "text": "how much of the GPU are we actually",
    "start": "550680",
    "end": "552480"
  },
  {
    "text": "using uh another way to do that is to",
    "start": "552480",
    "end": "555839"
  },
  {
    "text": "measure the actual GPU",
    "start": "555839",
    "end": "557880"
  },
  {
    "text": "utilization uh you will see why I take",
    "start": "557880",
    "end": "560240"
  },
  {
    "text": "both and the power consumption how much",
    "start": "560240",
    "end": "563480"
  },
  {
    "text": "envir we actually consuming and the",
    "start": "563480",
    "end": "566560"
  },
  {
    "text": "bottom line is how long it actually",
    "start": "566560",
    "end": "568240"
  },
  {
    "text": "takes for us to complete the training",
    "start": "568240",
    "end": "570079"
  },
  {
    "text": "that's the most important part normally",
    "start": "570079",
    "end": "572160"
  },
  {
    "text": "you know people don't actually care what",
    "start": "572160",
    "end": "573920"
  },
  {
    "text": "you're doing or how long it takes you to",
    "start": "573920",
    "end": "575800"
  },
  {
    "text": "do it um this is the most important part",
    "start": "575800",
    "end": "578800"
  },
  {
    "text": "I",
    "start": "578800",
    "end": "579959"
  },
  {
    "text": "guess uh the training parameters uh",
    "start": "579959",
    "end": "583440"
  },
  {
    "text": "we'll go through this really briefly uh",
    "start": "583440",
    "end": "585600"
  },
  {
    "text": "I'm assuming the presentation will be",
    "start": "585600",
    "end": "587399"
  },
  {
    "text": "available later on but um I will go",
    "start": "587399",
    "end": "591320"
  },
  {
    "text": "through what's important basically we",
    "start": "591320",
    "end": "593160"
  },
  {
    "text": "starting with a single appac the BET",
    "start": "593160",
    "end": "595880"
  },
  {
    "text": "size is the length sequence L is 4,000",
    "start": "595880",
    "end": "599720"
  },
  {
    "text": "96 which basically means we are",
    "start": "599720",
    "end": "602000"
  },
  {
    "text": "processing 4,096 tokens for every patch",
    "start": "602000",
    "end": "606880"
  },
  {
    "text": "and going skip this one oh yeah another",
    "start": "606880",
    "end": "610160"
  },
  {
    "text": "thing is we're doing a distributed",
    "start": "610160",
    "end": "611920"
  },
  {
    "text": "training technique which means we're",
    "start": "611920",
    "end": "614240"
  },
  {
    "text": "basically Shing the information across",
    "start": "614240",
    "end": "616600"
  },
  {
    "text": "multiple gpus and nodes this is how we",
    "start": "616600",
    "end": "619880"
  },
  {
    "text": "can fit really large llms into",
    "start": "619880",
    "end": "622839"
  },
  {
    "text": "relatively smaller",
    "start": "622839",
    "end": "626959"
  },
  {
    "text": "environments uh okay so so this is a",
    "start": "627279",
    "end": "630040"
  },
  {
    "text": "basic comparison of RDMA full training",
    "start": "630040",
    "end": "633959"
  },
  {
    "text": "without any tuning without anything else",
    "start": "633959",
    "end": "636600"
  },
  {
    "text": "and we can see we're getting 37% faster",
    "start": "636600",
    "end": "640519"
  },
  {
    "text": "uh compares to",
    "start": "640519",
    "end": "643480"
  },
  {
    "text": "TCP now",
    "start": "644440",
    "end": "647480"
  },
  {
    "text": "um the gpus in both cases and basically",
    "start": "647480",
    "end": "651680"
  },
  {
    "text": "using the same amount on",
    "start": "651680",
    "end": "653760"
  },
  {
    "text": "verum um uh consumption so you can see",
    "start": "653760",
    "end": "657600"
  },
  {
    "text": "we basically fill it up the Intel",
    "start": "657600",
    "end": "659959"
  },
  {
    "text": "allowance that we have or relative",
    "start": "659959",
    "end": "662560"
  },
  {
    "text": "closer like",
    "start": "662560",
    "end": "664800"
  },
  {
    "text": "98% uh this is the network forut uh this",
    "start": "664800",
    "end": "667519"
  },
  {
    "text": "is a network for TPC TCP versus",
    "start": "667519",
    "end": "671320"
  },
  {
    "text": "um rookie I'm going to call it rookie",
    "start": "671320",
    "end": "673639"
  },
  {
    "text": "for now on uh so we can see the Rie has",
    "start": "673639",
    "end": "677519"
  },
  {
    "text": "traffic fluctuations that shows off that",
    "start": "677519",
    "end": "680680"
  },
  {
    "text": "uh the gpus either don't have enough",
    "start": "680680",
    "end": "683079"
  },
  {
    "text": "holow to saturate the network or they",
    "start": "683079",
    "end": "685519"
  },
  {
    "text": "just uh not using not being used",
    "start": "685519",
    "end": "688519"
  },
  {
    "text": "efficiently",
    "start": "688519",
    "end": "690920"
  },
  {
    "text": "uh I was trying to use both gpus and SM",
    "start": "690920",
    "end": "693600"
  },
  {
    "text": "utilization like I mentioned earlier uh",
    "start": "693600",
    "end": "696079"
  },
  {
    "text": "we wanted to assertain the actual GPU",
    "start": "696079",
    "end": "697880"
  },
  {
    "text": "utilization however I found them that",
    "start": "697880",
    "end": "700440"
  },
  {
    "text": "the most reliable metrics uh you can",
    "start": "700440",
    "end": "702720"
  },
  {
    "text": "judge for yourself which is why I also",
    "start": "702720",
    "end": "705800"
  },
  {
    "text": "measuring power",
    "start": "705800",
    "end": "708720"
  },
  {
    "text": "consumption and",
    "start": "708760",
    "end": "711440"
  },
  {
    "text": "uh well it's it's an additional metric",
    "start": "711440",
    "end": "714000"
  },
  {
    "text": "to have better understanding of the",
    "start": "714000",
    "end": "715480"
  },
  {
    "text": "actual GPU utilization and we can see",
    "start": "715480",
    "end": "718200"
  },
  {
    "text": "that with the Rook the gpus are using",
    "start": "718200",
    "end": "721399"
  },
  {
    "text": "54% of the voltage allowance while TCP",
    "start": "721399",
    "end": "725639"
  },
  {
    "text": "is using only",
    "start": "725639",
    "end": "727160"
  },
  {
    "text": "45% so if you look at power consumption",
    "start": "727160",
    "end": "730720"
  },
  {
    "text": "with rookie the gpus are working a bit",
    "start": "730720",
    "end": "734120"
  },
  {
    "text": "harder uh yeah so um let's talk about",
    "start": "734120",
    "end": "738720"
  },
  {
    "text": "fine tuning so fine tuning is our way to",
    "start": "738720",
    "end": "741639"
  },
  {
    "text": "be more efficient with training uh we",
    "start": "741639",
    "end": "743680"
  },
  {
    "text": "simply updating a small portion of the",
    "start": "743680",
    "end": "746079"
  },
  {
    "text": "model",
    "start": "746079",
    "end": "747279"
  },
  {
    "text": "parameters um in this example we use",
    "start": "747279",
    "end": "750760"
  },
  {
    "text": "this four attentions head I can't really",
    "start": "750760",
    "end": "753399"
  },
  {
    "text": "get too deep into this uh again time",
    "start": "753399",
    "end": "756839"
  },
  {
    "text": "limitations um will have all of this",
    "start": "756839",
    "end": "759399"
  },
  {
    "text": "later on but I wante a little bit about",
    "start": "759399",
    "end": "761959"
  },
  {
    "text": "each of these uh attention heads and",
    "start": "761959",
    "end": "764959"
  },
  {
    "text": "what the purpose",
    "start": "764959",
    "end": "767760"
  },
  {
    "text": "is uh this is the um parameters we're",
    "start": "767760",
    "end": "771480"
  },
  {
    "text": "using",
    "start": "771480",
    "end": "773519"
  },
  {
    "text": "um I I get through them right now but I",
    "start": "773519",
    "end": "778199"
  },
  {
    "text": "feel like",
    "start": "778199",
    "end": "779680"
  },
  {
    "text": "uh we will go through them later right",
    "start": "779680",
    "end": "781560"
  },
  {
    "text": "if we have the",
    "start": "781560",
    "end": "783279"
  },
  {
    "text": "time uh now with L fine tuning we can",
    "start": "783279",
    "end": "785880"
  },
  {
    "text": "see that the training is 56% faster than",
    "start": "785880",
    "end": "789639"
  },
  {
    "text": "with dring on gcp so um we can see we",
    "start": "789639",
    "end": "795519"
  },
  {
    "text": "doing a lot better now we have shortened",
    "start": "795519",
    "end": "797880"
  },
  {
    "text": "our training",
    "start": "797880",
    "end": "799480"
  },
  {
    "text": "duration and uh that's because we're",
    "start": "799480",
    "end": "802880"
  },
  {
    "text": "using lower now and we are only focusing",
    "start": "802880",
    "end": "805320"
  },
  {
    "text": "on the specific layers that we are",
    "start": "805320",
    "end": "807680"
  },
  {
    "text": "interested in",
    "start": "807680",
    "end": "811120"
  },
  {
    "text": "again in both cases uh the gpus vum",
    "start": "811360",
    "end": "815680"
  },
  {
    "text": "consumption is almost identical or",
    "start": "815680",
    "end": "819040"
  },
  {
    "text": "identical um depending how you look at",
    "start": "819040",
    "end": "821240"
  },
  {
    "text": "the statistics but uh we see that you",
    "start": "821240",
    "end": "824440"
  },
  {
    "text": "are consuming a lot less VM now because",
    "start": "824440",
    "end": "828360"
  },
  {
    "text": "we basically focusing on really specific",
    "start": "828360",
    "end": "831279"
  },
  {
    "text": "parameters so we don't need that much VM",
    "start": "831279",
    "end": "834240"
  },
  {
    "text": "anymore which give us the space to do",
    "start": "834240",
    "end": "837959"
  },
  {
    "text": "more things with that",
    "start": "837959",
    "end": "841360"
  },
  {
    "text": "V uh yeah so in terms of networking you",
    "start": "842120",
    "end": "846560"
  },
  {
    "text": "can see with the lower flut has much",
    "start": "846560",
    "end": "848720"
  },
  {
    "text": "less fluctuation that he had before and",
    "start": "848720",
    "end": "851839"
  },
  {
    "text": "the average flut below you can see that",
    "start": "851839",
    "end": "855079"
  },
  {
    "text": "rookie is working a lot",
    "start": "855079",
    "end": "857920"
  },
  {
    "text": "faster I kept adding those uh SM and GPU",
    "start": "857920",
    "end": "861959"
  },
  {
    "text": "utilization but uh this is that you know",
    "start": "861959",
    "end": "865759"
  },
  {
    "text": "so to have all the information presented",
    "start": "865759",
    "end": "869240"
  },
  {
    "text": "but uh like I said again uh it's not the",
    "start": "869240",
    "end": "871839"
  },
  {
    "text": "most reliable thing to it this is kind",
    "start": "871839",
    "end": "873720"
  },
  {
    "text": "of a known thing between uh us AI",
    "start": "873720",
    "end": "877839"
  },
  {
    "text": "Engineers that are looking into all this",
    "start": "877839",
    "end": "880279"
  },
  {
    "text": "training",
    "start": "880279",
    "end": "882120"
  },
  {
    "text": "stuff um yeah",
    "start": "882120",
    "end": "885440"
  },
  {
    "text": "so TCP versus low power consumption so",
    "start": "885440",
    "end": "889600"
  },
  {
    "text": "earlier we used about I don't remember",
    "start": "889600",
    "end": "892680"
  },
  {
    "text": "how much is was",
    "start": "892680",
    "end": "893839"
  },
  {
    "text": "46% yep and now we",
    "start": "893839",
    "end": "896639"
  },
  {
    "text": "increased our consumption you can see in",
    "start": "896639",
    "end": "899120"
  },
  {
    "text": "the chart by how much and now we're",
    "start": "899120",
    "end": "901279"
  },
  {
    "text": "going into the important",
    "start": "901279",
    "end": "903079"
  },
  {
    "text": "stuff um which is fine tuning even",
    "start": "903079",
    "end": "908240"
  },
  {
    "text": "better so you have best performance you",
    "start": "908240",
    "end": "911079"
  },
  {
    "text": "can get out of our setup so I don't know",
    "start": "911079",
    "end": "914160"
  },
  {
    "text": "if this is the EnV Nvidia SMI topology",
    "start": "914160",
    "end": "918600"
  },
  {
    "text": "up there is the command line you can run",
    "start": "918600",
    "end": "920560"
  },
  {
    "text": "it and you get this table and it's",
    "start": "920560",
    "end": "922600"
  },
  {
    "text": "basically shows you the",
    "start": "922600",
    "end": "925000"
  },
  {
    "text": "topology in your uh setup and you can",
    "start": "925000",
    "end": "928399"
  },
  {
    "text": "see in the square gpu0 is connected to",
    "start": "928399",
    "end": "931240"
  },
  {
    "text": "all the other gpus uh via 12 lens EnV",
    "start": "931240",
    "end": "934880"
  },
  {
    "text": "link which is our high speeed interface",
    "start": "934880",
    "end": "937000"
  },
  {
    "text": "for rookie however routing the data",
    "start": "937000",
    "end": "940319"
  },
  {
    "text": "through Nick zero which is marked in a",
    "start": "940319",
    "end": "943680"
  },
  {
    "text": "pink Square will degr the rookie",
    "start": "943680",
    "end": "946160"
  },
  {
    "text": "performance um if you can",
    "start": "946160",
    "end": "950319"
  },
  {
    "text": "see over there in the X well if you go",
    "start": "950319",
    "end": "953160"
  },
  {
    "text": "through Nick zero and Nick one you will",
    "start": "953160",
    "end": "954839"
  },
  {
    "text": "go through sis and if you look at system",
    "start": "954839",
    "end": "957319"
  },
  {
    "text": "here you will see that ction interesting",
    "start": "957319",
    "end": "959920"
  },
  {
    "text": "through PCI as well at thep internet we",
    "start": "959920",
    "end": "962920"
  },
  {
    "text": "kind of counter the efficiency that Rie",
    "start": "962920",
    "end": "965839"
  },
  {
    "text": "has to offer we don't want to do that",
    "start": "965839",
    "end": "968279"
  },
  {
    "text": "what we want to do is go through",
    "start": "968279",
    "end": "972720"
  },
  {
    "text": "as little oh to work as the minimum",
    "start": "972720",
    "end": "976959"
  },
  {
    "text": "component as we can in order to reduce",
    "start": "976959",
    "end": "979839"
  },
  {
    "text": "our latency and maximize our fut",
    "start": "979839",
    "end": "983480"
  },
  {
    "text": "so what we can do we can force the",
    "start": "983480",
    "end": "987920"
  },
  {
    "text": "system for example if you look at gpu0",
    "start": "987920",
    "end": "991120"
  },
  {
    "text": "up to GPU 3 we can if we can force them",
    "start": "991120",
    "end": "994759"
  },
  {
    "text": "to go through Nick two and nick3 and ni4",
    "start": "994759",
    "end": "998199"
  },
  {
    "text": "instead of going through Nick zero and",
    "start": "998199",
    "end": "1000000"
  },
  {
    "text": "Nick one you have better performance",
    "start": "1000000",
    "end": "1002160"
  },
  {
    "text": "because you are moving through less",
    "start": "1002160",
    "end": "1006720"
  },
  {
    "text": "components and this is how we do",
    "start": "1008319",
    "end": "1011120"
  },
  {
    "text": "it uh you can create a topology XML file",
    "start": "1011120",
    "end": "1015000"
  },
  {
    "text": "and with this topology XML file you can",
    "start": "1015000",
    "end": "1017880"
  },
  {
    "text": "Define",
    "start": "1017880",
    "end": "1020040"
  },
  {
    "text": "which uh which ni use with specific",
    "start": "1020040",
    "end": "1024918"
  },
  {
    "text": "interface and you can set that with the",
    "start": "1024919",
    "end": "1028120"
  },
  {
    "text": "Nvidia",
    "start": "1028120",
    "end": "1029400"
  },
  {
    "text": "nickel uh environment variable and uh",
    "start": "1029400",
    "end": "1033120"
  },
  {
    "text": "with that you can force the data",
    "start": "1033120",
    "end": "1036120"
  },
  {
    "text": "PA and that will increase your",
    "start": "1036120",
    "end": "1038319"
  },
  {
    "text": "performance significantly along with",
    "start": "1038319",
    "end": "1040640"
  },
  {
    "text": "other parameters we're going to look",
    "start": "1040640",
    "end": "1043918"
  },
  {
    "text": "into so these are a few other",
    "start": "1043919",
    "end": "1047360"
  },
  {
    "text": "parameters that we are",
    "start": "1047360",
    "end": "1049360"
  },
  {
    "text": "uh going to apply well already applied",
    "start": "1049360",
    "end": "1053400"
  },
  {
    "text": "and um you can kind of go through them",
    "start": "1053400",
    "end": "1056799"
  },
  {
    "text": "but you can see it's really important to",
    "start": "1056799",
    "end": "1058320"
  },
  {
    "text": "set them up for example the algorithm um",
    "start": "1058320",
    "end": "1062039"
  },
  {
    "text": "nickel is using nickel by the way is the",
    "start": "1062039",
    "end": "1064799"
  },
  {
    "text": "Nidia communication Library which pyo",
    "start": "1064799",
    "end": "1068200"
  },
  {
    "text": "using as a backand to move data I don't",
    "start": "1068200",
    "end": "1070559"
  },
  {
    "text": "know if I said that or not um so you can",
    "start": "1070559",
    "end": "1073480"
  },
  {
    "text": "see the default is actually three which",
    "start": "1073480",
    "end": "1075120"
  },
  {
    "text": "is not really optimal for um nvms links",
    "start": "1075120",
    "end": "1079360"
  },
  {
    "text": "that I'm using so um all these buffos",
    "start": "1079360",
    "end": "1083480"
  },
  {
    "text": "will uh I mean all the all the settings",
    "start": "1083480",
    "end": "1086600"
  },
  {
    "text": "will affect all your training and how",
    "start": "1086600",
    "end": "1089559"
  },
  {
    "text": "fast it goes and how much Network you",
    "start": "1089559",
    "end": "1091400"
  },
  {
    "text": "are using during the training so you can",
    "start": "1091400",
    "end": "1094200"
  },
  {
    "text": "uh do other things with the",
    "start": "1094200",
    "end": "1096960"
  },
  {
    "text": "network okay so now that we",
    "start": "1096960",
    "end": "1103240"
  },
  {
    "text": "um switch to laa now we have um and",
    "start": "1103240",
    "end": "1108200"
  },
  {
    "text": "increase the size so now we're using",
    "start": "1108200",
    "end": "1110799"
  },
  {
    "text": "more V right so now we increase the V",
    "start": "1110799",
    "end": "1114159"
  },
  {
    "text": "the the the sequence length to basically",
    "start": "1114159",
    "end": "1117760"
  },
  {
    "text": "8,000 up to up from",
    "start": "1117760",
    "end": "1120760"
  },
  {
    "text": "4,096 because we are doing two batches",
    "start": "1120760",
    "end": "1123360"
  },
  {
    "text": "so we're doing more training but we are",
    "start": "1123360",
    "end": "1125720"
  },
  {
    "text": "still not fully allocated all our vam um",
    "start": "1125720",
    "end": "1129360"
  },
  {
    "text": "because we still have more space but if",
    "start": "1129360",
    "end": "1130960"
  },
  {
    "text": "we increase that to three batches we",
    "start": "1130960",
    "end": "1134159"
  },
  {
    "text": "will EIT OEM and we'll be out of memory",
    "start": "1134159",
    "end": "1136200"
  },
  {
    "text": "and we'll just rush so",
    "start": "1136200",
    "end": "1139799"
  },
  {
    "text": "let me try and show that in a better way",
    "start": "1139799",
    "end": "1143240"
  },
  {
    "text": "maybe it will be easier to explain that",
    "start": "1143240",
    "end": "1145960"
  },
  {
    "text": "so you can see that we started training",
    "start": "1145960",
    "end": "1148320"
  },
  {
    "text": "with bet size one and sequ left of",
    "start": "1148320",
    "end": "1151480"
  },
  {
    "text": "496 we fill up 98% of the V this is what",
    "start": "1151480",
    "end": "1154679"
  },
  {
    "text": "I've showed you at the beginning now we",
    "start": "1154679",
    "end": "1157080"
  },
  {
    "text": "switch to Lowa training and we focus on",
    "start": "1157080",
    "end": "1159240"
  },
  {
    "text": "the specific parameters that we care",
    "start": "1159240",
    "end": "1161400"
  },
  {
    "text": "about and we still kept the B size at",
    "start": "1161400",
    "end": "1164320"
  },
  {
    "text": "one the sequence have remain the same",
    "start": "1164320",
    "end": "1167200"
  },
  {
    "text": "but we are feeling only 40% of the v um",
    "start": "1167200",
    "end": "1171080"
  },
  {
    "text": "with 4,096 tokens now at the next step",
    "start": "1171080",
    "end": "1175679"
  },
  {
    "text": "we increase the B si2 because we now",
    "start": "1175679",
    "end": "1178000"
  },
  {
    "text": "have the VM capacity to do that and",
    "start": "1178000",
    "end": "1181240"
  },
  {
    "text": "basically we are trading a total of 8",
    "start": "1181240",
    "end": "1183880"
  },
  {
    "text": "8,000 192 tokens but we're filling up",
    "start": "1183880",
    "end": "1187480"
  },
  {
    "text": "75% of the vam we can't increase this to",
    "start": "1187480",
    "end": "1190840"
  },
  {
    "text": "three because we will hit OEM what we",
    "start": "1190840",
    "end": "1194200"
  },
  {
    "text": "can do we're not going to we're not",
    "start": "1194200",
    "end": "1196760"
  },
  {
    "text": "going to go through that in this present",
    "start": "1196760",
    "end": "1198919"
  },
  {
    "text": "is going to out of scope but ideally",
    "start": "1198919",
    "end": "1201760"
  },
  {
    "text": "what you want to do is increase the bed",
    "start": "1201760",
    "end": "1203640"
  },
  {
    "text": "size to free and then reduce the",
    "start": "1203640",
    "end": "1206720"
  },
  {
    "text": "sequence",
    "start": "1206720",
    "end": "1208000"
  },
  {
    "text": "length which will fill up your entire",
    "start": "1208000",
    "end": "1210520"
  },
  {
    "text": "GPU vam so you will allocate your",
    "start": "1210520",
    "end": "1213440"
  },
  {
    "text": "resources in a better way and you will",
    "start": "1213440",
    "end": "1217039"
  },
  {
    "text": "have more tokens being",
    "start": "1217039",
    "end": "1220639"
  },
  {
    "text": "processed let me go back the",
    "start": "1220799",
    "end": "1225519"
  },
  {
    "text": "okay uh again TCP GPU SM",
    "start": "1229000",
    "end": "1233720"
  },
  {
    "text": "utilization um power consumption okay so",
    "start": "1233720",
    "end": "1237280"
  },
  {
    "text": "power consumption is like I said the",
    "start": "1237280",
    "end": "1239360"
  },
  {
    "text": "metric I've seen taking the most hit uh",
    "start": "1239360",
    "end": "1242760"
  },
  {
    "text": "when you know we utilizing the gpus",
    "start": "1242760",
    "end": "1245159"
  },
  {
    "text": "better so we can see that our TCP",
    "start": "1245159",
    "end": "1250320"
  },
  {
    "text": "utilization is now 63% and rookie went",
    "start": "1250320",
    "end": "1253919"
  },
  {
    "text": "to",
    "start": "1253919",
    "end": "1256120"
  },
  {
    "text": "85% which basically means we're using a",
    "start": "1257240",
    "end": "1259880"
  },
  {
    "text": "lot of electricity which means the GPS",
    "start": "1259880",
    "end": "1262000"
  },
  {
    "text": "are working",
    "start": "1262000",
    "end": "1264400"
  },
  {
    "text": "harder uh so using less left throughput",
    "start": "1264400",
    "end": "1267840"
  },
  {
    "text": "uh why is that important because we can",
    "start": "1267840",
    "end": "1270279"
  },
  {
    "text": "use something like SRV which is um an",
    "start": "1270279",
    "end": "1274880"
  },
  {
    "text": "operator a different oper we we we're",
    "start": "1274880",
    "end": "1277480"
  },
  {
    "text": "not using it right now but we have the",
    "start": "1277480",
    "end": "1279840"
  },
  {
    "text": "option to use the SV and withv we can",
    "start": "1279840",
    "end": "1283480"
  },
  {
    "text": "create multiple virtual interfaces on",
    "start": "1283480",
    "end": "1287159"
  },
  {
    "text": "top of our rooki Nick",
    "start": "1287159",
    "end": "1289120"
  },
  {
    "text": "uh those interfaces basically give you",
    "start": "1289120",
    "end": "1291279"
  },
  {
    "text": "the option to attach additional pods",
    "start": "1291279",
    "end": "1294960"
  },
  {
    "text": "that will have that highspeed access to",
    "start": "1294960",
    "end": "1298679"
  },
  {
    "text": "that Network and so you can even if",
    "start": "1298679",
    "end": "1300880"
  },
  {
    "text": "you're not using the full band on you",
    "start": "1300880",
    "end": "1303000"
  },
  {
    "text": "can have other pods that can use that",
    "start": "1303000",
    "end": "1306080"
  },
  {
    "text": "and the Nvidia operator has something",
    "start": "1306080",
    "end": "1308559"
  },
  {
    "text": "that is called Mig uh which allows you",
    "start": "1308559",
    "end": "1311760"
  },
  {
    "text": "to uh share gpus across multiple parts",
    "start": "1311760",
    "end": "1315400"
  },
  {
    "text": "so you can have a few teams working and",
    "start": "1315400",
    "end": "1318120"
  },
  {
    "text": "then you can really fully utilize your",
    "start": "1318120",
    "end": "1320760"
  },
  {
    "text": "gpus which are the most expensive things",
    "start": "1320760",
    "end": "1323880"
  },
  {
    "text": "out there right now in terms of Hardware",
    "start": "1323880",
    "end": "1328039"
  },
  {
    "text": "components uh yeah so this is our final",
    "start": "1328159",
    "end": "1332760"
  },
  {
    "text": "result and you can see we further",
    "start": "1332760",
    "end": "1335919"
  },
  {
    "text": "improve our training Time by",
    "start": "1335919",
    "end": "1338760"
  },
  {
    "text": "40% and this is our bottom",
    "start": "1338760",
    "end": "1343200"
  },
  {
    "text": "line",
    "start": "1345640",
    "end": "1347360"
  },
  {
    "text": "so that's that's for",
    "start": "1347360",
    "end": "1349360"
  },
  {
    "text": "TCP we started it took us like 2,000",
    "start": "1349360",
    "end": "1354640"
  },
  {
    "text": "seconds to train things and then we went",
    "start": "1354640",
    "end": "1357840"
  },
  {
    "text": "down to 95",
    "start": "1357840",
    "end": "1361600"
  },
  {
    "text": "953 with u Laura and this is with the",
    "start": "1361600",
    "end": "1366120"
  },
  {
    "text": "rookie now if you look at those numbers",
    "start": "1366120",
    "end": "1369360"
  },
  {
    "text": "it doesn't look like a lot of savings",
    "start": "1369360",
    "end": "1371240"
  },
  {
    "text": "but you have to remember that's only",
    "start": "1371240",
    "end": "1373320"
  },
  {
    "text": "500,000 samples and normally when you do",
    "start": "1373320",
    "end": "1377440"
  },
  {
    "text": "some real training it will be hundreds",
    "start": "1377440",
    "end": "1379320"
  },
  {
    "text": "of millions so that here might translate",
    "start": "1379320",
    "end": "1383000"
  },
  {
    "text": "to a few minutes but in reality that can",
    "start": "1383000",
    "end": "1385120"
  },
  {
    "text": "be translated to a few",
    "start": "1385120",
    "end": "1387520"
  },
  {
    "text": "months oh yeah I have a remote",
    "start": "1387520",
    "end": "1391600"
  },
  {
    "text": "now",
    "start": "1391600",
    "end": "1393559"
  },
  {
    "text": "um",
    "start": "1393559",
    "end": "1396159"
  },
  {
    "text": "cool um yeah so um all the files that I",
    "start": "1396159",
    "end": "1399559"
  },
  {
    "text": "use to generate all this data uh it's",
    "start": "1399559",
    "end": "1402520"
  },
  {
    "text": "open for everyone uh at this GitHub so",
    "start": "1402520",
    "end": "1405559"
  },
  {
    "text": "if you want to try yourself all the the",
    "start": "1405559",
    "end": "1408720"
  },
  {
    "text": "policies all the scripts all in the you",
    "start": "1408720",
    "end": "1411320"
  },
  {
    "text": "can just take it and use it and do",
    "start": "1411320",
    "end": "1413080"
  },
  {
    "text": "whatever you want with",
    "start": "1413080",
    "end": "1415600"
  },
  {
    "text": "it that's it our times 10 minutes very",
    "start": "1415600",
    "end": "1420320"
  },
  {
    "text": "good 10 minutes is what we need for",
    "start": "1420320",
    "end": "1423679"
  },
  {
    "text": "questions any questions go",
    "start": "1423679",
    "end": "1428519"
  },
  {
    "text": "ahead providing Rd",
    "start": "1431520",
    "end": "1434840"
  },
  {
    "text": "overnet has infs",
    "start": "1434840",
    "end": "1438640"
  },
  {
    "text": "F adap so how isck",
    "start": "1438640",
    "end": "1442320"
  },
  {
    "text": "comp well it's not about how it Compares",
    "start": "1442320",
    "end": "1445799"
  },
  {
    "text": "it's about how much food they actually",
    "start": "1445799",
    "end": "1447440"
  },
  {
    "text": "offer on that line right so that's is",
    "start": "1447440",
    "end": "1450440"
  },
  {
    "text": "infinity band specifically the cx6 each",
    "start": "1450440",
    "end": "1453520"
  },
  {
    "text": "of them offer 200 gigs and in this",
    "start": "1453520",
    "end": "1456559"
  },
  {
    "text": "specific case I had two right I was not",
    "start": "1456559",
    "end": "1459840"
  },
  {
    "text": "able to fully utilize that amount of",
    "start": "1459840",
    "end": "1463159"
  },
  {
    "text": "throughput because I did some small",
    "start": "1463159",
    "end": "1465360"
  },
  {
    "text": "things in order to not fully utilize",
    "start": "1465360",
    "end": "1466960"
  },
  {
    "text": "that Network and in",
    "start": "1466960",
    "end": "1468880"
  },
  {
    "text": "the training well in Ru the training",
    "start": "1468880",
    "end": "1471240"
  },
  {
    "text": "duration that I had uh but it's all a",
    "start": "1471240",
    "end": "1474919"
  },
  {
    "text": "question of",
    "start": "1474919",
    "end": "1476520"
  },
  {
    "text": "FO and the latency well it depends on",
    "start": "1476520",
    "end": "1479679"
  },
  {
    "text": "the model size but Po and latency so it",
    "start": "1479679",
    "end": "1482399"
  },
  {
    "text": "depends on what they're offering and if",
    "start": "1482399",
    "end": "1484919"
  },
  {
    "text": "it supports rce or remote direct RDMA",
    "start": "1484919",
    "end": "1490799"
  },
  {
    "text": "which is a bit different",
    "start": "1490799",
    "end": "1494360"
  },
  {
    "text": "can on a cluster of 500 your nickel",
    "start": "1505399",
    "end": "1510080"
  },
  {
    "text": "bandwidth if you run a nickel test your",
    "start": "1510080",
    "end": "1511919"
  },
  {
    "text": "nickel bandwidth would be about 275",
    "start": "1511919",
    "end": "1516240"
  },
  {
    "text": "G",
    "start": "1519399",
    "end": "1520960"
  },
  {
    "text": "275 GES",
    "start": "1520960",
    "end": "1523320"
  },
  {
    "text": "notes yeah cha bite per second 275 oh in",
    "start": "1523320",
    "end": "1527080"
  },
  {
    "text": "this if I could just add like in in this",
    "start": "1527080",
    "end": "1528640"
  },
  {
    "text": "experiment we you know we showed what we",
    "start": "1528640",
    "end": "1530600"
  },
  {
    "text": "did just two nodes and we had RDMA over",
    "start": "1530600",
    "end": "1533679"
  },
  {
    "text": "ethernet I think the problem was we",
    "start": "1533679",
    "end": "1535520"
  },
  {
    "text": "didn't really have a Infinity band based",
    "start": "1535520",
    "end": "1538360"
  },
  {
    "text": "setup right so as you know like for",
    "start": "1538360",
    "end": "1540200"
  },
  {
    "text": "Infinity band you need an Infinity band",
    "start": "1540200",
    "end": "1541679"
  },
  {
    "text": "capable switch the good thing with uh",
    "start": "1541679",
    "end": "1544279"
  },
  {
    "text": "ethernet is that you can use a standard",
    "start": "1544279",
    "end": "1545960"
  },
  {
    "text": "standard switch and just still get the",
    "start": "1545960",
    "end": "1547880"
  },
  {
    "text": "benefits of",
    "start": "1547880",
    "end": "1548960"
  },
  {
    "text": "RDMA with the 60 gpus that I had uh",
    "start": "1548960",
    "end": "1552600"
  },
  {
    "text": "which might not Sun a lot but they cost",
    "start": "1552600",
    "end": "1554640"
  },
  {
    "text": "as much as my apartment to buy um with",
    "start": "1554640",
    "end": "1557720"
  },
  {
    "text": "this uh 16 gpus that I had I could max",
    "start": "1557720",
    "end": "1560399"
  },
  {
    "text": "out at 40 gig per",
    "start": "1560399",
    "end": "1562559"
  },
  {
    "text": "second 40 gigabyte per second if",
    "start": "1562559",
    "end": "1566960"
  },
  {
    "text": "yeah any other",
    "start": "1566960",
    "end": "1570440"
  },
  {
    "text": "questions no I I use full fsdp which",
    "start": "1578600",
    "end": "1581559"
  },
  {
    "text": "means I show them all",
    "start": "1581559",
    "end": "1584279"
  },
  {
    "text": "across I couldn't do it otherwise",
    "start": "1584279",
    "end": "1586480"
  },
  {
    "text": "because um you know uh realatively well",
    "start": "1586480",
    "end": "1591120"
  },
  {
    "text": "not anymore now we have models like with",
    "start": "1591120",
    "end": "1593640"
  },
  {
    "text": "hundreds of millions of parameters this",
    "start": "1593640",
    "end": "1596799"
  },
  {
    "text": "has three billion and uh I still needed",
    "start": "1596799",
    "end": "1599480"
  },
  {
    "text": "to show them across all of them in order",
    "start": "1599480",
    "end": "1601279"
  },
  {
    "text": "to get it to fit uh specifically with",
    "start": "1601279",
    "end": "1604720"
  },
  {
    "text": "that signal",
    "start": "1604720",
    "end": "1606279"
  },
  {
    "text": "left any other",
    "start": "1606279",
    "end": "1609720"
  },
  {
    "text": "questions great looks like we're done",
    "start": "1612279",
    "end": "1617080"
  },
  {
    "text": "early okay okay thank you okay thank you",
    "start": "1617080",
    "end": "1622919"
  }
]
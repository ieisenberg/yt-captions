[
  {
    "text": "good afternoon welcome to the session on sustainable scaling of kubernetes workloads with inpl po resize using",
    "start": "560",
    "end": "7520"
  },
  {
    "text": "predictive AI uh I am Vin I work for eBay Cloud where I'm helping build ebpf",
    "start": "7520",
    "end": "12960"
  },
  {
    "text": "powered communities networking at global scale for large clusters with a lot of PODS Haren please introduce yourself hi",
    "start": "12960",
    "end": "20560"
  },
  {
    "text": "everyone I'm horen I'm currently a PhD student at uiu and I'm working on microservices and Cloud Resource",
    "start": "20560",
    "end": "27199"
  },
  {
    "text": "Management with machine learning thank you horen so the agenda for today uh we'll",
    "start": "27199",
    "end": "35719"
  },
  {
    "text": "start by describing the over provisioning problem and look at the environmental impact and the dollar cost of over provisioning uh we touch we",
    "start": "35719",
    "end": "42360"
  },
  {
    "text": "touch upon our road map and outline why this is important for eBay and quickly recap the inpl SP res size feature we",
    "start": "42360",
    "end": "48640"
  },
  {
    "text": "also look at the cluster oscular use case and see how inpl po res size can help improve it and we then switch gears",
    "start": "48640",
    "end": "55559"
  },
  {
    "text": "and oron will walk us through the current state of AI in the cloud uh",
    "start": "55559",
    "end": "60760"
  },
  {
    "text": "we'll take a look at the role that reinforcement learning can play in autoscaling and see how AI can help us",
    "start": "60760",
    "end": "67520"
  },
  {
    "text": "go from being reactive to being proactive with Autos scaling and to conclude we'll look at how RL training",
    "start": "67520",
    "end": "73280"
  },
  {
    "text": "is done and review evaluation results so accurately estimating what",
    "start": "73280",
    "end": "81079"
  },
  {
    "text": "resources your pod needs is a very hard problem um those of you who contain containerized your apps in communities",
    "start": "81079",
    "end": "88119"
  },
  {
    "text": "may have come to the resources section of the yaml and wondered gee how much CPU do I need uh how much memory do I",
    "start": "88119",
    "end": "94640"
  },
  {
    "text": "need for my pod or how much storage and um these are this makes it hard and it's",
    "start": "94640",
    "end": "100960"
  },
  {
    "text": "a challenging problem and um for various reasons the Java apps that use uh CPU",
    "start": "100960",
    "end": "108680"
  },
  {
    "text": "there's excuse me for example Java apps use more CPU at startup time and consume a fraction of the initial CPU during",
    "start": "108680",
    "end": "115320"
  },
  {
    "text": "normal run times uh so if you use fixed limit for a guaranteed C class spot it",
    "start": "115320",
    "end": "121159"
  },
  {
    "text": "means choosing between a slow startup or over provisioning you could get the over",
    "start": "121159",
    "end": "126439"
  },
  {
    "text": "provisioning you could get the provisioning right but still be subject to load shocks uh due to external factors such as other pods going down or",
    "start": "126439",
    "end": "133319"
  },
  {
    "text": "the load balance load load balancer misbehaving your code may take slower",
    "start": "133319",
    "end": "138680"
  },
  {
    "text": "paths more often due to varying nature of the requests and uh the services that you depend on May experience outages",
    "start": "138680",
    "end": "145800"
  },
  {
    "text": "causing causing uh your service to get backed up with request and if you do everything right if you",
    "start": "145800",
    "end": "152840"
  },
  {
    "text": "get the provisioning right you profile your uh code with real traffic and use vpa recommender perfectly tune the load",
    "start": "152840",
    "end": "159879"
  },
  {
    "text": "balancer and HPA well as of today K8 does not allow you to mutate your pod",
    "start": "159879",
    "end": "165400"
  },
  {
    "text": "resources out of the box so in order to deal with changes so",
    "start": "165400",
    "end": "171519"
  },
  {
    "text": "there's not a lot that you can control and over provisioning comes with",
    "start": "171519",
    "end": "177440"
  },
  {
    "text": "a cost First uh there is the environment Al impact Steven ma did a case study 2",
    "start": "177440",
    "end": "182680"
  },
  {
    "text": "years ago when cryptocurrency minia was in full swing he estimated that a single",
    "start": "182680",
    "end": "188000"
  },
  {
    "text": "data center consumed the power equivalent of 50,000 homes that crypto",
    "start": "188000",
    "end": "193159"
  },
  {
    "text": "energy hunger is now being replaced by AI energy needs and AI workloads tend to be computer intensive and network",
    "start": "193159",
    "end": "200840"
  },
  {
    "text": "intensive data centers also have significant cooling needs they require a",
    "start": "200840",
    "end": "206400"
  },
  {
    "text": "lot of water and then there is the CO2 emissions impact and there is the noise",
    "start": "206400",
    "end": "213439"
  },
  {
    "text": "and electronic waste that comes with it so why should we care it's simple",
    "start": "213439",
    "end": "219200"
  },
  {
    "text": "because there is no Planet B and then of course there is a dollar",
    "start": "219200",
    "end": "225120"
  },
  {
    "text": "cost to over-provisioning uh J Chapel in a blog estimated that 26.6 billion were",
    "start": "225120",
    "end": "231120"
  },
  {
    "text": "wasted Cloud spending in 2021 and he found that 40% of is instances were",
    "start": "231120",
    "end": "236799"
  },
  {
    "text": "overallocated which talled to $8.7 billion in overspend in another report a",
    "start": "236799",
    "end": "242480"
  },
  {
    "text": "vendor named cast AI estimated that 37% of Computer Resources allocated were never",
    "start": "242480",
    "end": "248400"
  },
  {
    "text": "used and last year a company named strong force did a survey where people",
    "start": "248400",
    "end": "253760"
  },
  {
    "text": "responded that 47% of the Cloud waste was from over provisioning they also felt that majority of the respondents",
    "start": "253760",
    "end": "260479"
  },
  {
    "text": "also felt that kuet complexity was a contributing factor the theme is that",
    "start": "260479",
    "end": "266240"
  },
  {
    "text": "about half the resources are wasted and in a nutshell this is an expensive problem and this affects the bottom line",
    "start": "266240",
    "end": "272880"
  },
  {
    "text": "for companies and in the end it impacts consumer wallets but it also means that",
    "start": "272880",
    "end": "279400"
  },
  {
    "text": "we have an opportunity here to do better sustainability has been an",
    "start": "279400",
    "end": "286479"
  },
  {
    "text": "important business goal at eBay when the when your business is about finding new purpose for once loved but abandoned",
    "start": "286479",
    "end": "293039"
  },
  {
    "text": "items reuse and sustainability comes naturally uh specifically at the data",
    "start": "293039",
    "end": "300120"
  },
  {
    "text": "center level that uh do 550 shipping seals the deal for me uh specifically at",
    "start": "300120",
    "end": "306160"
  },
  {
    "text": "the data center level the goal is exclusive renewable energy use HPA with predictive AI to better estimate the",
    "start": "306160",
    "end": "313720"
  },
  {
    "text": "replication needs is an ongoing effort at this time and next year there are plans to take up vpa to right siiz pods",
    "start": "313720",
    "end": "320440"
  },
  {
    "text": "and containers and this is where in place pod res size is an important piece of the puzzle as it avoids workload",
    "start": "320440",
    "end": "326759"
  },
  {
    "text": "disruption due to Vertical scaling and the over head of scheduling new parts and starting them up eventually we want",
    "start": "326759",
    "end": "334840"
  },
  {
    "text": "to get to sorry we eventually we want to get",
    "start": "334840",
    "end": "340280"
  },
  {
    "text": "to back here we want to get to the um",
    "start": "340280",
    "end": "345880"
  },
  {
    "text": "multi-dimensional Port Auto scaling now in Place Port resize up until earlier this year you could not",
    "start": "345880",
    "end": "352319"
  },
  {
    "text": "edit the resources given to your pod you had to restart your workload if you wanted to change its resources and then",
    "start": "352319",
    "end": "359120"
  },
  {
    "text": "finally finally we merged finally we merged the pull",
    "start": "359120",
    "end": "365280"
  },
  {
    "text": "request in kuus 127 that enables us to use uh enables us to resize Pod without",
    "start": "365280",
    "end": "371240"
  },
  {
    "text": "disruption I have a Blog that you can visit to learn more about this feature and how to use it I presented a detailed",
    "start": "371240",
    "end": "377880"
  },
  {
    "text": "design about this in a talk last year the field names in the API have changed slightly since but the core design that",
    "start": "377880",
    "end": "385280"
  },
  {
    "text": "was presented Remains the Same and if you're interested in the details there",
    "start": "385280",
    "end": "390560"
  },
  {
    "text": "is a link to the cap U cap stands for communities enhancement proposal that's our design",
    "start": "390560",
    "end": "397638"
  },
  {
    "text": "document one application of inpl SP resize with sustainability benefits came",
    "start": "397720",
    "end": "403520"
  },
  {
    "text": "from a recent blog post by Peter meowski he noticed that Java apps needed a lot more CPU during startup time than when",
    "start": "403520",
    "end": "410759"
  },
  {
    "text": "doing regular work as I mentioned earlier so if you have a guaranteed qos class pod with hard CPU limits optimized",
    "start": "410759",
    "end": "418919"
  },
  {
    "text": "for the Run time need it would result in Long startup times and the alternative",
    "start": "418919",
    "end": "424319"
  },
  {
    "text": "is over provisioning in this use case he resizes the CPU limits lower after the app",
    "start": "424319",
    "end": "431319"
  },
  {
    "text": "startup phase was complete and this means a job can start and finish faster",
    "start": "431319",
    "end": "436759"
  },
  {
    "text": "and we can power down unneeded ndes sooner and AKA it helps you become",
    "start": "436759",
    "end": "441960"
  },
  {
    "text": "energy conscious and costc conscious so cluster R scaler mainly",
    "start": "441960",
    "end": "448960"
  },
  {
    "text": "does two two things for us number one it scales up clusters when pods are pending due to insufficient resources and it",
    "start": "448960",
    "end": "456120"
  },
  {
    "text": "scales down clusters by removing underutilized nodes consider this scenario uh you have kubernetes cluster",
    "start": "456120",
    "end": "462680"
  },
  {
    "text": "and a couple of nodes in there and they are at capacity running pods a couple of",
    "start": "462680",
    "end": "468639"
  },
  {
    "text": "new pods show up they are pending due to lack of resources and they will remain pending until some pots finish and free",
    "start": "468639",
    "end": "475720"
  },
  {
    "text": "up some room cluster autoscaler SE sees this and calls into the cloud provider API to",
    "start": "475720",
    "end": "482120"
  },
  {
    "text": "allocate a new node then the scheduler can then assign these pending ports to that new node the issue with this is",
    "start": "482120",
    "end": "489159"
  },
  {
    "text": "that cluster autoscaler only considers the Pod resource requests it does not",
    "start": "489159",
    "end": "494360"
  },
  {
    "text": "take into account the resource utilization of running pods before allocating new nodes this also means",
    "start": "494360",
    "end": "500680"
  },
  {
    "text": "that your cluster could be very underutilized yet you end up bringing new nodes online in other words your",
    "start": "500680",
    "end": "507560"
  },
  {
    "text": "carbon footprint goes up and and you waste money let's have a quick look at how",
    "start": "507560",
    "end": "514919"
  },
  {
    "text": "cluster autoscaler works today I'm going to use uh this is using qbdm cloud provider and uh I'm going to play a",
    "start": "514919",
    "end": "521800"
  },
  {
    "text": "pre-recorded demo for this part I apologize if people in the back find it hard to see but there is an uploaded",
    "start": "521800",
    "end": "527600"
  },
  {
    "text": "video for this as well this is a demo of cluster autoscaling with QBE adms cloud provider in this demo we have a simple",
    "start": "527600",
    "end": "534279"
  },
  {
    "text": "cluster with two nodes a master and a node called node one and we have two parts that are running on node one",
    "start": "534279",
    "end": "540120"
  },
  {
    "text": "taking a closer look at node one we see that pod one has requested one CPU and pod two has requested 500 M",
    "start": "540120",
    "end": "547880"
  },
  {
    "text": "CPUs we also note that this node has two CPUs allocatable and a capacity of 2",
    "start": "547880",
    "end": "554839"
  },
  {
    "text": "CPUs these parts are idle though and if we want to schedule one",
    "start": "554839",
    "end": "562120"
  },
  {
    "text": "more pod that requests one more CPU it's not",
    "start": "562120",
    "end": "567920"
  },
  {
    "text": "going to be able to schedule because there's not no room in the cluster even though the cluster is underutilized let's start the",
    "start": "567920",
    "end": "576560"
  },
  {
    "text": "part when we create the Pod we see that one more pod is up in the API and it's pending and it will remain pending until",
    "start": "577720",
    "end": "586519"
  },
  {
    "text": "there is more room in the cluster let's take a look at the",
    "start": "586519",
    "end": "591560"
  },
  {
    "text": "reason we do a k described pod on this PO and in the events we see it's failed",
    "start": "591560",
    "end": "597160"
  },
  {
    "text": "scheduling and the reason is insufficiency CPU in order to connect more CPU we will",
    "start": "597160",
    "end": "603959"
  },
  {
    "text": "add a new node to the cluster using Cub ADM cloud",
    "start": "603959",
    "end": "608839"
  },
  {
    "text": "provider with this yl file we can deploy the cloud provider and this cloud provider is going to listen for requests",
    "start": "609560",
    "end": "617079"
  },
  {
    "text": "to scale up the cluster on the local host address at Port",
    "start": "617079",
    "end": "622399"
  },
  {
    "text": "8086 so now that we have deployed the Pod the cluster the qbdm cloud provider",
    "start": "625120",
    "end": "630720"
  },
  {
    "text": "is up and running and if we look at the",
    "start": "630720",
    "end": "634560"
  },
  {
    "text": "logs we see that it's listening at the local host address Port",
    "start": "636279",
    "end": "642320"
  },
  {
    "text": "8086 next we start the cluster Auto scaler we tell the cluster aut scaler",
    "start": "642320",
    "end": "649639"
  },
  {
    "text": "how to reach the cloud provider by providing this config file which just points to the address to the cloud",
    "start": "649639",
    "end": "656160"
  },
  {
    "text": "provider that we just started",
    "start": "656160",
    "end": "661040"
  },
  {
    "text": "so now we start the cluster Auto scaler it's going to connect to the API and see that there is a partt pending",
    "start": "661760",
    "end": "668800"
  },
  {
    "text": "and it's going to request a scale up of the cluster with the qadium clock Rider",
    "start": "668800",
    "end": "673920"
  },
  {
    "text": "there is the request for scale up and the qbm cloud provider has added a new",
    "start": "673920",
    "end": "679639"
  },
  {
    "text": "node this node is up and running and that will be reflected in the API and",
    "start": "679639",
    "end": "686160"
  },
  {
    "text": "the Schuler will see that a new node is up and running shortly and when it does that it will look to schedule this",
    "start": "686160",
    "end": "693519"
  },
  {
    "text": "pending pod and there we go the pending p is now",
    "start": "693519",
    "end": "699839"
  },
  {
    "text": "up and running this concludes the demo of QB ADM as cloud provider for cluster",
    "start": "699839",
    "end": "706360"
  },
  {
    "text": "Auto scaling okay I'm glad that didn't",
    "start": "706360",
    "end": "712360"
  },
  {
    "text": "crash so uh what you saw is just a vanilla cluster autoscaler uh we allocated new node and then we SK schedu",
    "start": "712360",
    "end": "719240"
  },
  {
    "text": "this spot on that new node node 2 even though node one is underutilized and uh",
    "start": "719240",
    "end": "725120"
  },
  {
    "text": "that's what motivated the stock today and uh sets the basis for the next demo we're going to show in a little",
    "start": "725120",
    "end": "731759"
  },
  {
    "text": "bit now let's look at what we can do differently with in place pod resize what we have now is the ability to",
    "start": "734079",
    "end": "740519"
  },
  {
    "text": "quickly resize the Pod without disruption so that means spot disruption budgets are not an issue we can make a",
    "start": "740519",
    "end": "747079"
  },
  {
    "text": "small tweak to the cluster autoscaler project where uh we instead of immediately requesting a new note from",
    "start": "747079",
    "end": "753199"
  },
  {
    "text": "the cloud provider we check to see if current Parts can be resized down and if",
    "start": "753199",
    "end": "759000"
  },
  {
    "text": "we can do that we and we can create some more room then we end up we end up um",
    "start": "759000",
    "end": "767440"
  },
  {
    "text": "scheduling the port without firing up new nodes and we save some money and we we become more",
    "start": "767440",
    "end": "773279"
  },
  {
    "text": "sustainable what does this look like in terms of the code change well it's still a very simple tweak what we do is we arm",
    "start": "773279",
    "end": "780160"
  },
  {
    "text": "the CL arm the cluster autoscaler with what I call as a p smer now the",
    "start": "780160",
    "end": "785399"
  },
  {
    "text": "difference is that we check that in this case the pet are underutilized we scale them shrink them before we scale up the",
    "start": "785399",
    "end": "793279"
  },
  {
    "text": "cluster now what does this look like for this we'll switch to a live demo because",
    "start": "793279",
    "end": "799399"
  },
  {
    "text": "I'm feeling adventurous let's see how that",
    "start": "799399",
    "end": "804120"
  },
  {
    "text": "goes so you have the same setup as before you have uh two nodes two nodes here the master and node one we have a",
    "start": "805399",
    "end": "812480"
  },
  {
    "text": "few pods running there is the QB ADM cloud provider pod that's standing by to receive request to scale up the cluster",
    "start": "812480",
    "end": "818959"
  },
  {
    "text": "if need be and there are those are Parts part one and part two which are uh",
    "start": "818959",
    "end": "824440"
  },
  {
    "text": "underutilized they uh they're tailing the null device so they're really doing nothing uh if you look at the",
    "start": "824440",
    "end": "832959"
  },
  {
    "text": "node we see that pod one is has requested one CPU and part two has",
    "start": "834959",
    "end": "840040"
  },
  {
    "text": "requested 500 M CPUs in a node that has allocate table of 2 CPUs and a capacity",
    "start": "840040",
    "end": "846399"
  },
  {
    "text": "of 2 CPUs these pods are great candidates to be resized down and that's what we will do in this case you can see",
    "start": "846399",
    "end": "853360"
  },
  {
    "text": "here that pod one is also requesting one C has a request of one CPU and allocation of one CPU by the kuet when",
    "start": "853360",
    "end": "860199"
  },
  {
    "text": "we do uh the describe the port and get its container status allocated resources a new feature that was added in in place",
    "start": "860199",
    "end": "866480"
  },
  {
    "text": "po size um",
    "start": "866480",
    "end": "871560"
  },
  {
    "text": "next if you want to schedule one more Port as",
    "start": "871560",
    "end": "876199"
  },
  {
    "text": "before which requests one more CPU it won't be able to schedule just as before so let's do",
    "start": "881360",
    "end": "888320"
  },
  {
    "text": "that I'm going to create this port in the API and it's showing up in the API",
    "start": "888320",
    "end": "894079"
  },
  {
    "text": "it's spending as before and the reason it's spending is",
    "start": "894079",
    "end": "899959"
  },
  {
    "text": "I'm going to do a k describe pod and in the events we see that it has",
    "start": "899959",
    "end": "905120"
  },
  {
    "text": "failed scheduling and the reason is insufficient CPU now this time around though we're",
    "start": "905120",
    "end": "911399"
  },
  {
    "text": "going to do something slightly different instead of running our vanilla cluster Auto scaler we're going to run this pod",
    "start": "911399",
    "end": "917199"
  },
  {
    "text": "smusher cluster Auto scaler which is hardcoded to resize down pod one to 200",
    "start": "917199",
    "end": "922480"
  },
  {
    "text": "M CPUs so let's hit",
    "start": "922480",
    "end": "926480"
  },
  {
    "text": "it so now it's going to connect to the API and there we go it has detected that a",
    "start": "927600",
    "end": "934360"
  },
  {
    "text": "pod is spending but before resizing the cluster it checked it can smoos pod one",
    "start": "934360",
    "end": "939480"
  },
  {
    "text": "to 200 B CPUs and we'll look at this again now we are",
    "start": "939480",
    "end": "947199"
  },
  {
    "text": "at 2 CPUs for pod one and we see that",
    "start": "947199",
    "end": "952240"
  },
  {
    "text": "one more pod has now been scheduled but this time it's scheduled on node one because we created room by shrinking",
    "start": "952240",
    "end": "957639"
  },
  {
    "text": "that pod and we did not need to allocate node two so thus we saved some",
    "start": "957639",
    "end": "964199"
  },
  {
    "text": "money so that uh that's a demo for uh the second case",
    "start": "970000",
    "end": "977959"
  },
  {
    "text": "with in place poy size now does this mean we're done well not quite there are",
    "start": "977959",
    "end": "984120"
  },
  {
    "text": "many ways this could go wrong uh let's look at a couple of ways things can play out in ways you do not expect you just",
    "start": "984120",
    "end": "990480"
  },
  {
    "text": "took away memory from a part that's known to get o killed during spikes and a spike is about to occur or that idle",
    "start": "990480",
    "end": "997279"
  },
  {
    "text": "CPU you repurposed for degrades a shopping experience for your site users later when a bad job starts we can",
    "start": "997279",
    "end": "1004959"
  },
  {
    "text": "speculate all day about the different ways in which things could go wrong but the real question to ask is can we as",
    "start": "1004959",
    "end": "1011199"
  },
  {
    "text": "humans come up with a smarter set of heris stics sure we can but if we had",
    "start": "1011199",
    "end": "1016639"
  },
  {
    "text": "infinite time but then then is there a better way than that well it turns out there is making recommendations based on",
    "start": "1016639",
    "end": "1024000"
  },
  {
    "text": "a large set of parameters in a reasonable amount of time in a reasonable amount of time is a",
    "start": "1024000",
    "end": "1030000"
  },
  {
    "text": "job best suited for keep my things up uh making recommendations based on a large",
    "start": "1030000",
    "end": "1035120"
  },
  {
    "text": "set of parameters in reasonable amount of time is a task best suited for AI uh so let's hear from Ron how AI can help",
    "start": "1035120",
    "end": "1042839"
  },
  {
    "text": "take it away or thank you there oops so let's step back a little bit",
    "start": "1042839",
    "end": "1051240"
  },
  {
    "text": "looking at the call platforms and you may find that General resource management is actually everywhere in",
    "start": "1051240",
    "end": "1057240"
  },
  {
    "text": "Cloud platforms workload a scaling is one example and others include job",
    "start": "1057240",
    "end": "1063080"
  },
  {
    "text": "scheduling VMO container placement conest control Etc and such problems",
    "start": "1063080",
    "end": "1069880"
  },
  {
    "text": "have been around for a long time both in theory and in practice but yet remain",
    "start": "1069880",
    "end": "1075120"
  },
  {
    "text": "significantly challenging currently most are relying on human engineered",
    "start": "1075120",
    "end": "1081559"
  },
  {
    "text": "tics on the other hand we have learning based approaches such as reinforcement learning which allows us to use deepure",
    "start": "1081559",
    "end": "1089200"
  },
  {
    "text": "networks to express the complex Dynamics with raw and noisy signals and to express the decision-making policies",
    "start": "1089200",
    "end": "1096640"
  },
  {
    "text": "learning based approaches are available because we have abundant data generated",
    "start": "1096640",
    "end": "1101760"
  },
  {
    "text": "in more than Cloud platforms examples include monitoring data system metrics application",
    "start": "1101760",
    "end": "1107960"
  },
  {
    "text": "performance Matrix and those are there due to the Improvement of absorbability",
    "start": "1107960",
    "end": "1115280"
  },
  {
    "text": "tools so let's look at what people do today for those system management tasks there are two main",
    "start": "1116039",
    "end": "1122440"
  },
  {
    "text": "categories human engineering and reinforcement learning based approaches representing the learning based",
    "start": "1122440",
    "end": "1128760"
  },
  {
    "text": "Solutions but actually at a higher level they share similarities so here I make a",
    "start": "1128760",
    "end": "1133919"
  },
  {
    "text": "side by side comparison on the left hand side we have human d engineering people usually start",
    "start": "1133919",
    "end": "1140679"
  },
  {
    "text": "with a simple system model based on for example C Theory and they need to manually produce",
    "start": "1140679",
    "end": "1146640"
  },
  {
    "text": "some heuristics or parameters to make it work and of course we need to test and toe those parameters with extensive",
    "start": "1146640",
    "end": "1153880"
  },
  {
    "text": "profiling based on for uh like until relatively good huris heuristics are found and durly for the average case and",
    "start": "1153880",
    "end": "1161840"
  },
  {
    "text": "whenever there's any changes to the applications or the call platforms we need to redo these steps again and again",
    "start": "1161840",
    "end": "1169440"
  },
  {
    "text": "on the other hand there is an opportunity for using learning based Solutions such as reinforcement learning",
    "start": "1169440",
    "end": "1175360"
  },
  {
    "text": "where an artificial agent is created to interact with the environment and the system management task is usually",
    "start": "1175360",
    "end": "1181720"
  },
  {
    "text": "formulated as a mark of decision process essentially a sequential decision-",
    "start": "1181720",
    "end": "1186760"
  },
  {
    "text": "making process and the agent starts from a random policy this policy maps from",
    "start": "1186760",
    "end": "1192480"
  },
  {
    "text": "the states to the actions and is usually parameterized by newer Networks each",
    "start": "1192480",
    "end": "1198640"
  },
  {
    "text": "time step it obtains states make an action and then gets the reward indicating how good the action is given",
    "start": "1198640",
    "end": "1205760"
  },
  {
    "text": "the current context and this policy will be optimized based on the reward as you can",
    "start": "1205760",
    "end": "1211799"
  },
  {
    "text": "see this is also like a loop and it will continue until convergence or there's no improvement when updating the model",
    "start": "1211799",
    "end": "1219400"
  },
  {
    "text": "parameters there are two main reasons why learning based approaches such as iio is suitable for cloud system",
    "start": "1219400",
    "end": "1226559"
  },
  {
    "text": "management the first reason is that it provides a systematic framework for automatic retraining to reduce repeated",
    "start": "1226559",
    "end": "1233640"
  },
  {
    "text": "human driven profiling and tuning and secondly it reduces costly",
    "start": "1233640",
    "end": "1239720"
  },
  {
    "text": "optimization or search to constant time which makes it scalable to the large",
    "start": "1239720",
    "end": "1244919"
  },
  {
    "text": "State action space in Dynamic Cloud environment for heterogeneous",
    "start": "1244919",
    "end": "1251080"
  },
  {
    "text": "applications as a primary I is an approach that falling between suis learning and Unice learning it doesn't",
    "start": "1251280",
    "end": "1259039"
  },
  {
    "text": "require any labeled data but needs a reward an agent interacts with the",
    "start": "1259039",
    "end": "1264240"
  },
  {
    "text": "environment in a step-by-step manner at each time step T is going to get a state",
    "start": "1264240",
    "end": "1269400"
  },
  {
    "text": "St make an action a and then receive the reward RT as I mentioned the reward here",
    "start": "1269400",
    "end": "1276039"
  },
  {
    "text": "serves as the feedback like the loss function which directs I policy or model",
    "start": "1276039",
    "end": "1281279"
  },
  {
    "text": "training and the goal of our engine training is to maximize the expected cumulative reward in any t step",
    "start": "1281279",
    "end": "1290720"
  },
  {
    "text": "trajectory so let's look at how we formulate the workload Auto skating task as an IR problem in the kubernetes",
    "start": "1290720",
    "end": "1298200"
  },
  {
    "text": "cluster application workflows are usually deployed as poal containers to",
    "start": "1298200",
    "end": "1303360"
  },
  {
    "text": "continuously meet application slos and Achieve High resource utilization the IR",
    "start": "1303360",
    "end": "1308799"
  },
  {
    "text": "based Auto skater is responsible for Autos skating uh like in a vertical",
    "start": "1308799",
    "end": "1313840"
  },
  {
    "text": "Dimension such as resizing the container regarding the CPU and memory limit limit and horizontal scating to adjust the",
    "start": "1313840",
    "end": "1320960"
  },
  {
    "text": "number of containers with I we get rid of human driven application profiling and",
    "start": "1320960",
    "end": "1327240"
  },
  {
    "text": "parameter tuning in heris based approaches for example in threshold",
    "start": "1327240",
    "end": "1332400"
  },
  {
    "text": "based autoc skating the op the optimal threshold for CP utilization without",
    "start": "1332400",
    "end": "1337960"
  },
  {
    "text": "violating the application performance as a lows actually varies across different applications or",
    "start": "1337960",
    "end": "1343799"
  },
  {
    "text": "platforms and I automates policy learning with the systematic and dynamic",
    "start": "1343799",
    "end": "1348880"
  },
  {
    "text": "feedback control Loop to support our training and inference in Kutis we have",
    "start": "1348880",
    "end": "1355760"
  },
  {
    "text": "multi-dimensional pod Auto scaler or MPA the design of MPA actually follows the",
    "start": "1355760",
    "end": "1361799"
  },
  {
    "text": "similar style of vpa that separates scaling recommendation from actuation by",
    "start": "1361799",
    "end": "1367600"
  },
  {
    "text": "doing so it supports customized plug andplay multi-dimensional Auto scalers such as",
    "start": "1367600",
    "end": "1373880"
  },
  {
    "text": "a first we have application deployments and Metric servers in the kubernetes",
    "start": "1373880",
    "end": "1379360"
  },
  {
    "text": "cluster and then MP recommenders gets the measurements from the metrix servers",
    "start": "1379360",
    "end": "1384640"
  },
  {
    "text": "and gets the scaling recommendations from either the I agent from aiss or the",
    "start": "1384640",
    "end": "1389679"
  },
  {
    "text": "traditional vpa or HPA controllers the recommender then sets the scaling configurations in the mpa",
    "start": "1389679",
    "end": "1397240"
  },
  {
    "text": "API and then the updator operator executes the horizontal or vertical",
    "start": "1397240",
    "end": "1402919"
  },
  {
    "text": "scanning recommendation configuration updates",
    "start": "1402919",
    "end": "1408480"
  },
  {
    "text": "here we took the open source implementation from firm which has been published in usdi 2020 as the I based",
    "start": "1408480",
    "end": "1414799"
  },
  {
    "text": "Auto scaler which is a proactive approach meaning that the IR agent",
    "start": "1414799",
    "end": "1420320"
  },
  {
    "text": "decides how to autoscale to react to the perceived states such as the current",
    "start": "1420320",
    "end": "1425360"
  },
  {
    "text": "utilization or the current application performance metrix but we can make it a proactive a",
    "start": "1425360",
    "end": "1431720"
  },
  {
    "text": "scaling approach by prepending a predictor following the way that deep scaling is doing which has been",
    "start": "1431720",
    "end": "1437919"
  },
  {
    "text": "published Inc last year instead of taking the current uh measurement like",
    "start": "1437919",
    "end": "1443600"
  },
  {
    "text": "the timer series data the predictor forecast the next time Windows time series data on utilization and Lads and",
    "start": "1443600",
    "end": "1451200"
  },
  {
    "text": "then pass it to the our agent to make the decision for the our agent it's really",
    "start": "1451200",
    "end": "1458559"
  },
  {
    "text": "just trained to make resource reprobation decisions directly from experience and it is optimized for the",
    "start": "1458559",
    "end": "1465799"
  },
  {
    "text": "end to end objectives what does that me as I mentioned the reward function in I",
    "start": "1465799",
    "end": "1471840"
  },
  {
    "text": "acts as the loss function to point the I agent to the right direction and the reward function in our case is defined",
    "start": "1471840",
    "end": "1479000"
  },
  {
    "text": "as this function it's basically consists of two parts the first parts means to",
    "start": "1479000",
    "end": "1484720"
  },
  {
    "text": "mitigate ASO variations fast in this case smt is the SLO maintenance at time",
    "start": "1484720",
    "end": "1490520"
  },
  {
    "text": "T and is defined as the SLO latency divided by the current latency a lower",
    "start": "1490520",
    "end": "1496120"
  },
  {
    "text": "value means worse performance degrad ation and we give it like a penalty by having lower",
    "start": "1496120",
    "end": "1501760"
  },
  {
    "text": "reward the second part is to avoid over prasing it's defined as the resource",
    "start": "1501760",
    "end": "1507039"
  },
  {
    "text": "usage at time T divided by the assigned resource limit or allocation a high",
    "start": "1507039",
    "end": "1512399"
  },
  {
    "text": "value means High resource utilization efficiency and less operation and this",
    "start": "1512399",
    "end": "1517919"
  },
  {
    "text": "align with our objectives in an ENT",
    "start": "1517919",
    "end": "1522559"
  },
  {
    "text": "Manner and we did evaluations on microservices deployed on kubernetes",
    "start": "1523080",
    "end": "1528440"
  },
  {
    "text": "overall we found that I based autoscaler reduces the SLO violation mitigation Time by up to nine times compared with",
    "start": "1528440",
    "end": "1535520"
  },
  {
    "text": "Baseline kubernetes Auto skers breaking up it reduces the average tail latency",
    "start": "1535520",
    "end": "1541279"
  },
  {
    "text": "by up to 11 times while reducing the overall requested CPU limit by up to",
    "start": "1541279",
    "end": "1546919"
  },
  {
    "text": "62% in the meantime it reduces the number of dropped request or timeout request in the microservice applications",
    "start": "1546919",
    "end": "1553679"
  },
  {
    "text": "by up to eight times so to to summarize our talk today",
    "start": "1553679",
    "end": "1559520"
  },
  {
    "text": "we saw that cloud computing comes with a significant amount of environmental impact and dollar cost thankfully in",
    "start": "1559520",
    "end": "1567080"
  },
  {
    "text": "place P resize feature helps us drive towards the goal of multi-dimensional Part auto scaling we also look at how",
    "start": "1567080",
    "end": "1574240"
  },
  {
    "text": "reinforcement learning helps us further improve the efficiency which has played a very promising role in kubernets Auto",
    "start": "1574240",
    "end": "1581039"
  },
  {
    "text": "scaling it saves us from the laborers work and it also helps us from being",
    "start": "1581039",
    "end": "1586240"
  },
  {
    "text": "reactive to proactive our next steps would to drive the in",
    "start": "1586240",
    "end": "1591320"
  },
  {
    "text": "place pod resize feature to ja and realiz cost saving and reduce the common footprint via holistic aut skem and we",
    "start": "1591320",
    "end": "1599200"
  },
  {
    "text": "could use Community to help with this here is a list of references whose",
    "start": "1599200",
    "end": "1605200"
  },
  {
    "text": "work helped us put together this talk including several papers I mentioned in the",
    "start": "1605200",
    "end": "1610799"
  },
  {
    "text": "talk and we would like to hear back from you so that we can learn what we could do better please scan this QR code it",
    "start": "1610799",
    "end": "1617919"
  },
  {
    "text": "will take you to uh to the place where you can leave us feedback and with that we will conclude this talk and open this",
    "start": "1617919",
    "end": "1624399"
  },
  {
    "text": "session for",
    "start": "1624399",
    "end": "1627120"
  },
  {
    "text": "Q&A thank you so if you have any questions please",
    "start": "1635080",
    "end": "1640720"
  },
  {
    "text": "come up to the mic over there and U we can answer them to you really neat stuff appreciate it",
    "start": "1640720",
    "end": "1648360"
  },
  {
    "text": "could you back up one slide so we can get the references",
    "start": "1648360",
    "end": "1654640"
  },
  {
    "text": "oh I have uploaded the slides to SK so you can get it from there",
    "start": "1654720",
    "end": "1660640"
  },
  {
    "text": "too hi this is abishek from IPM research hi uh so I have two questions um we",
    "start": "1661320",
    "end": "1668000"
  },
  {
    "text": "covered a little bit about U AI workload use case so the first question is gpus",
    "start": "1668000",
    "end": "1674080"
  },
  {
    "text": "currently are expressed in kubernetes as fixed integer quantities how would scale",
    "start": "1674080",
    "end": "1679919"
  },
  {
    "text": "down work in that aspect and the second question is again regarding uh the AI",
    "start": "1679919",
    "end": "1685679"
  },
  {
    "text": "workload use case most of these workloads have gang scheduling semantics so will this uh technology help in uh",
    "start": "1685679",
    "end": "1693080"
  },
  {
    "text": "resizing gangs of PODS that are related to a single application currently um let me take the",
    "start": "1693080",
    "end": "1700720"
  },
  {
    "text": "first question uh there the GPU workloads yes they are they're currently",
    "start": "1700720",
    "end": "1706279"
  },
  {
    "text": "uh they're show up they're showing up as extended resources and the spec that we have today for in place SP resize only",
    "start": "1706279",
    "end": "1713320"
  },
  {
    "text": "covers CPU and memory it does not cover extended resources today and that was",
    "start": "1713320",
    "end": "1718760"
  },
  {
    "text": "mainly a decision to keep the scope in check and uh it's a large project as it",
    "start": "1718760",
    "end": "1724200"
  },
  {
    "text": "is uh a future kep is welcome uh that can you know scale up and scale down",
    "start": "1724200",
    "end": "1729840"
  },
  {
    "text": "gpus um I don't know if that could benefit from uh in place poy size kind",
    "start": "1729840",
    "end": "1735240"
  },
  {
    "text": "of whether it depends on whether you want it in units of one or you want smaller than that uh but I can see that",
    "start": "1735240",
    "end": "1743080"
  },
  {
    "text": "potentially being one of the things that come in extended resources you want to scale the number of GPS that you have",
    "start": "1743080",
    "end": "1748159"
  },
  {
    "text": "for your pod up and down yeah that could be there uh and uh regarding regarding",
    "start": "1748159",
    "end": "1754559"
  },
  {
    "text": "the second question let me think the scheduling approach that we have today um with inl",
    "start": "1754559",
    "end": "1762919"
  },
  {
    "text": "poy Size Doesn't really it's it's not even assisting it",
    "start": "1762919",
    "end": "1768000"
  },
  {
    "text": "just observes and this has come up uh Schuler could potentially come up as uh",
    "start": "1768000",
    "end": "1773600"
  },
  {
    "text": "something that can assist what it does r for is that it steers new parts that are",
    "start": "1773600",
    "end": "1779399"
  },
  {
    "text": "coming away from notes that are requesting resize so that way resize gets a little bit of priority as far as",
    "start": "1779399",
    "end": "1785960"
  },
  {
    "text": "gang scheduling whether we're going to take that into the scope of inl in place pod",
    "start": "1785960",
    "end": "1791480"
  },
  {
    "text": "resize um I don't see that happening anytime soon but uh if you have a strong",
    "start": "1791480",
    "end": "1797399"
  },
  {
    "text": "strong proposal of requirements and a kept in mind that's totally welcome uh the community would love to see that and",
    "start": "1797399",
    "end": "1804799"
  },
  {
    "text": "uh we want to get uh it's we we want to get community review these are fairly",
    "start": "1804799",
    "end": "1810960"
  },
  {
    "text": "big uh asks because it scales across multiple components you scaling across you need to change the API you need to",
    "start": "1810960",
    "end": "1817480"
  },
  {
    "text": "change the Schuler CET all critical components of kuun so they will go through thorough",
    "start": "1817480",
    "end": "1823840"
  },
  {
    "text": "reviews thanks V sure",
    "start": "1823840",
    "end": "1829240"
  },
  {
    "text": "um thanks for the talk really interesting I was curious when you're doing your reinforcement learning um are",
    "start": "1829360",
    "end": "1835519"
  },
  {
    "text": "you training that against a live cluster or do you have some sort of like simulation environment that you're doing the training in or what does that look",
    "start": "1835519",
    "end": "1842600"
  },
  {
    "text": "like yeah thanks for the question so so the question is during the reinforced",
    "start": "1842600",
    "end": "1847640"
  },
  {
    "text": "learning agent training are we using the live cluster or simulator so actually in this experiments we are using a live",
    "start": "1847640",
    "end": "1854039"
  },
  {
    "text": "cluster creating the uh first deploy the microservice benchmarks on the cluster",
    "start": "1854039",
    "end": "1859639"
  },
  {
    "text": "and then deploy the workload generator to drive the microservices running to serve the request and then the reinforc",
    "start": "1859639",
    "end": "1866440"
  },
  {
    "text": "learning agent training is actually happening by interacting with the mpa like setting scaling recommendations and",
    "start": "1866440",
    "end": "1873039"
  },
  {
    "text": "then receive the feedback yes cool thanks thank",
    "start": "1873039",
    "end": "1878279"
  },
  {
    "text": "you hello thank you for the session uh I'm fean and I'm from a healthcare",
    "start": "1878279",
    "end": "1883799"
  },
  {
    "text": "domain so uh with not Auto scaling will",
    "start": "1883799",
    "end": "1888960"
  },
  {
    "text": "not selector tains and tolerations uh will be considered while this uh Auto",
    "start": "1888960",
    "end": "1894960"
  },
  {
    "text": "scaling is performed so",
    "start": "1894960",
    "end": "1900200"
  },
  {
    "text": "um let me take the first part of the question that there two I think there are two part answers to this uh the",
    "start": "1900240",
    "end": "1905440"
  },
  {
    "text": "first one is uh vertical scaling in place vertical scaling that is after",
    "start": "1905440",
    "end": "1910799"
  },
  {
    "text": "scheduling so tat set tolerations don't really come into play here uh with regards to multi-dimensional Part auto",
    "start": "1910799",
    "end": "1917200"
  },
  {
    "text": "scaling the author of that uh cap is standing right next to me and I'll let",
    "start": "1917200",
    "end": "1923000"
  },
  {
    "text": "him answer that question so could you repeat the",
    "start": "1923000",
    "end": "1929320"
  },
  {
    "text": "question is it okay so uh while you do the no Autos scaling yes will the no",
    "start": "1929320",
    "end": "1937679"
  },
  {
    "text": "selector P Affinity rules and um tense and tolerations will that be taken into",
    "start": "1937679",
    "end": "1945039"
  },
  {
    "text": "consideration mainly when you scale it down [Music] uh skating down so so you're asking when",
    "start": "1945039",
    "end": "1951799"
  },
  {
    "text": "you remove a pod sorry when you remove a no from the",
    "start": "1951799",
    "end": "1957200"
  },
  {
    "text": "cluster uh yeah I'm trying to understand so you're asking uh when we are scaling",
    "start": "1957200",
    "end": "1962559"
  },
  {
    "text": "down the resource limit yeah so let me tell you this um two or more than one",
    "start": "1962559",
    "end": "1971240"
  },
  {
    "text": "pod an application has like only two parts and um you are scaling the KN down",
    "start": "1971240",
    "end": "1979279"
  },
  {
    "text": "yes and uh these uh you only have like two kns with a certain not uh not",
    "start": "1979279",
    "end": "1985080"
  },
  {
    "text": "selector and the ports can run only on those two nodes oh okay okay yeah I see",
    "start": "1985080",
    "end": "1991159"
  },
  {
    "text": "so so you're asking like uh when There's a constraint that the PS can only run it",
    "start": "1991159",
    "end": "1996440"
  },
  {
    "text": "on those two noes but there's no like capacity on those two noes like what you do with so uh no the capacity is there",
    "start": "1996440",
    "end": "2003240"
  },
  {
    "text": "on the two nodes actually the one of the node is underutilized so you don't have",
    "start": "2003240",
    "end": "2008320"
  },
  {
    "text": "that node to be on the cluster and you decides to scale it down remove the node from the",
    "start": "2008320",
    "end": "2013760"
  },
  {
    "text": "cluster oh let me let me take that question so the current cluster autoscaler the way it works I think it",
    "start": "2013760",
    "end": "2019760"
  },
  {
    "text": "takes into consideration if a part can be evicted if a part cannot be evicted we won't get a scale down uh but frankly",
    "start": "2019760",
    "end": "2027639"
  },
  {
    "text": "I think the current cluster Auto scaler will uh the auto scaling Community is looking to replace it with the Carpenter",
    "start": "2027639",
    "end": "2035000"
  },
  {
    "text": "and let's see if that gives us more features thank",
    "start": "2035000",
    "end": "2039600"
  },
  {
    "text": "you correct yeah no it's a",
    "start": "2041399",
    "end": "2047760"
  },
  {
    "text": "nod but they said the nod also right you had the I think disruption budget will",
    "start": "2047760",
    "end": "2053320"
  },
  {
    "text": "stop I wanted to know what all things are taken into",
    "start": "2053320",
    "end": "2059000"
  },
  {
    "text": "consideration yeah but that's",
    "start": "2064119",
    "end": "2068878"
  },
  {
    "text": "no no yeah it just changes the sizing thank uh thank you for your tremendous",
    "start": "2072760",
    "end": "2078358"
  },
  {
    "text": "work uh as someone operating solely on on Prime I've been like uh looking at",
    "start": "2078359",
    "end": "2083839"
  },
  {
    "text": "this proposal for three years and every time it hasn't met the release uh",
    "start": "2083839",
    "end": "2089158"
  },
  {
    "text": "Milestone it was like Christmas taken back from me so uh my question is you",
    "start": "2089159",
    "end": "2095200"
  },
  {
    "text": "are um uh performing reinforced learning on actual good data but in practice we",
    "start": "2095200",
    "end": "2101160"
  },
  {
    "text": "are then operating in environments with microservices where the reward function",
    "start": "2101160",
    "end": "2107200"
  },
  {
    "text": "and the metrics of reward function could be heavily impacted not only by the performance of the service itself but",
    "start": "2107200",
    "end": "2114040"
  },
  {
    "text": "rather by the performance of dependencies like databases or performance of other services that are",
    "start": "2114040",
    "end": "2120000"
  },
  {
    "text": "dependencies for this one upstream and downstream performances so what are your",
    "start": "2120000",
    "end": "2125400"
  },
  {
    "text": "uh ideas on how can incorporate the filtering of the latency or other reward",
    "start": "2125400",
    "end": "2132680"
  },
  {
    "text": "uh uh targets that could smooth out the impact of not the decisions made by the",
    "start": "2132680",
    "end": "2139240"
  },
  {
    "text": "uh reinforced learner out of scaler itself but about around the environment is it",
    "start": "2139240",
    "end": "2145720"
  },
  {
    "text": "clear so let let me repeat the question so you're saying in microservices there could be always third party services",
    "start": "2147079",
    "end": "2153520"
  },
  {
    "text": "like databases and how can we isolate the root cost for Asolo viations yeah so",
    "start": "2153520",
    "end": "2159319"
  },
  {
    "text": "how can we in the end of the day stop the uh autoscale to trigger any kind of",
    "start": "2159319",
    "end": "2165440"
  },
  {
    "text": "uh excessive upscaling or down scaling which is not actually correlated with",
    "start": "2165440",
    "end": "2171160"
  },
  {
    "text": "the decisions made previously because there are there is noise in in this kind of environment yeah yeah that's a good",
    "start": "2171160",
    "end": "2178040"
  },
  {
    "text": "question so actually we uh like if you if you check out our our paper there",
    "start": "2178040",
    "end": "2183359"
  },
  {
    "text": "like the number number eight here so actually we we treat the mic services like a graph so we first use tracing",
    "start": "2183359",
    "end": "2190040"
  },
  {
    "text": "tools like yagger to first nail down what's the root cost candidate for those SLO violations so if it's not the uh",
    "start": "2190040",
    "end": "2198000"
  },
  {
    "text": "microservice a then we are going to only focus on the root cost uh for the SLO",
    "start": "2198000",
    "end": "2203319"
  },
  {
    "text": "violations and then the and then the our agent only focus on that particular microservice component but not on all",
    "start": "2203319",
    "end": "2210160"
  },
  {
    "text": "the micros services at the same time so by doing that we are not like excessively scaling up some you know uh",
    "start": "2210160",
    "end": "2216760"
  },
  {
    "text": "peripheral some uh microservices but only targeting the rot cost candidates",
    "start": "2216760",
    "end": "2221960"
  },
  {
    "text": "uh I have extra questions but I think I first need to check the the yeah feel free to shoot me questions thank",
    "start": "2221960",
    "end": "2228480"
  },
  {
    "text": "you okay we are out of time uh so I think we need to stop now uh we can certainly hang around outside and then",
    "start": "2228480",
    "end": "2235200"
  },
  {
    "text": "take more questions if that's okay right thank you guys thank you very much for",
    "start": "2235200",
    "end": "2241480"
  },
  {
    "text": "coming",
    "start": "2241760",
    "end": "2244760"
  }
]
[
  {
    "start": "0",
    "end": "19000"
  },
  {
    "text": "everyone it's great to see everybody interested about auto-scaling on the wake from Google to take a deep",
    "start": "870",
    "end": "9630"
  },
  {
    "text": "dive with everybody in the order scaling right so there was this great",
    "start": "9630",
    "end": "16529"
  },
  {
    "text": "presentation yesterday by my colleague Marcin about an introduction to order scaling and heaters upon the best",
    "start": "16529",
    "end": "23730"
  },
  {
    "start": "19000",
    "end": "98000"
  },
  {
    "text": "practices the types of auto scale is what they do and everything so when the",
    "start": "23730",
    "end": "29490"
  },
  {
    "text": "slides and the recaps do come out of all the presentations do have a look at that",
    "start": "29490",
    "end": "36440"
  },
  {
    "text": "but for the uninitiated I will touch upon some of those or introduction topics so taking resources for your",
    "start": "36440",
    "end": "45690"
  },
  {
    "text": "applications is hard or they're never standing still there's always more traffic less traffic Black Friday's are",
    "start": "45690",
    "end": "52920"
  },
  {
    "text": "the boundary Monday coming up so it's difficult for you to set a decent or",
    "start": "52920",
    "end": "58890"
  },
  {
    "text": "even you know working limit for your for the scaling personally as a developer it was really hard for me to be nice auto",
    "start": "58890",
    "end": "66659"
  },
  {
    "text": "scaling does help you with this it gives you or three types of water skill is with three different purposes",
    "start": "66659",
    "end": "73830"
  },
  {
    "text": "or so we touch upon that a little bit here or to get the right amount of",
    "start": "73830",
    "end": "79140"
  },
  {
    "text": "resource limits and request for your pods you should probably go with the vertical orders order to scale it and to",
    "start": "79140",
    "end": "87659"
  },
  {
    "text": "set the right amount of replicas that your application needs you should go with HPA and to set the right amount of",
    "start": "87659",
    "end": "93509"
  },
  {
    "text": "notes in your cluster you should probably use less you're a scalar so Oh",
    "start": "93509",
    "end": "100040"
  },
  {
    "start": "98000",
    "end": "137000"
  },
  {
    "text": "VP a what does it do so how do you know the right amount of CPU or memory that",
    "start": "100040",
    "end": "105630"
  },
  {
    "text": "your workloads need it can be really difficult to figure that out especially if you are starting out so VP a actually",
    "start": "105630",
    "end": "113399"
  },
  {
    "text": "transfer or historical performance of your application and the utilization or the utilization of resources your",
    "start": "113399",
    "end": "120719"
  },
  {
    "text": "application has across time and I do recommend to write resource limits or",
    "start": "120719",
    "end": "127670"
  },
  {
    "text": "actually sells them for you or this can actually alter your workloads to",
    "start": "127670",
    "end": "133780"
  },
  {
    "text": "said our optimal resource limits for you horizontal quadrotor scaling or so again",
    "start": "133780",
    "end": "141250"
  },
  {
    "start": "137000",
    "end": "181000"
  },
  {
    "text": "figuring out the right amount of replicas that your part that your deployment needs is hard especially you",
    "start": "141250",
    "end": "147400"
  },
  {
    "text": "know our production situation so or HP helps you with that it targets a certain",
    "start": "147400",
    "end": "154350"
  },
  {
    "text": "target utilization that you that the user sets and if the utilization exceeds",
    "start": "154350",
    "end": "160030"
  },
  {
    "text": "that if your current utilization exceeds that or be scaled out by adding more replicas and effect or if your target if",
    "start": "160030",
    "end": "168220"
  },
  {
    "text": "your current or utilization is less than the specified target it reduces the amount of replicas so basically it",
    "start": "168220",
    "end": "175570"
  },
  {
    "text": "pushes your current utilization towards the Stargate utilization oh let's get",
    "start": "175570",
    "end": "183130"
  },
  {
    "start": "181000",
    "end": "262000"
  },
  {
    "text": "out the scalars so how do you know how many nodes your lessor needs at this",
    "start": "183130",
    "end": "188170"
  },
  {
    "text": "point of time at any point of time it can be extremely difficult because you might have something like HP a turned on",
    "start": "188170",
    "end": "194290"
  },
  {
    "text": "which increases them or reports and do you really have room for your extra part",
    "start": "194290",
    "end": "200140"
  },
  {
    "text": "now onto your of onto one of your notes maybe yes but if you do or aren't you",
    "start": "200140",
    "end": "206670"
  },
  {
    "text": "or provisioning somewhat you can sort of save caused by only using nodes when you",
    "start": "206670",
    "end": "213100"
  },
  {
    "text": "really need them so CA turning on CA can actually increase your cluster orders sorry plus your",
    "start": "213100",
    "end": "219489"
  },
  {
    "text": "utilization by quite some or level so we call so scale down so if your or if we",
    "start": "219489",
    "end": "227410"
  },
  {
    "text": "scaled up and then it turned out that your workload is done and now you might not need the new it anymore",
    "start": "227410",
    "end": "233859"
  },
  {
    "text": "we actually scale down scale it down for you so in this talk we'll take a deep dive into how you can use the cluster or",
    "start": "233859",
    "end": "241989"
  },
  {
    "text": "a scalar to reduced your infra costs so because we add and remove nodes this",
    "start": "241989",
    "end": "250030"
  },
  {
    "text": "affects your monthly in trouble so if you do have a lot of nodes you might",
    "start": "250030",
    "end": "255400"
  },
  {
    "text": "have a bigger available",
    "start": "255400",
    "end": "258298"
  },
  {
    "start": "262000",
    "end": "383000"
  },
  {
    "text": "yeah all right so let's take to actually",
    "start": "262030",
    "end": "268310"
  },
  {
    "text": "understand an optimized cluster or a scaler we need to know what it does and how it does it so let's take the",
    "start": "268310",
    "end": "274550"
  },
  {
    "text": "scenario where you have two node pools a node pool is basically similar-looking",
    "start": "274550",
    "end": "279860"
  },
  {
    "text": "nodes a few similar degree nodes so there are two node pools in this case there's an NL standard food and I know",
    "start": "279860",
    "end": "286040"
  },
  {
    "text": "standard eight and one standard for has capacity for full CPUs while TN one",
    "start": "286040",
    "end": "292400"
  },
  {
    "text": "standard eight has capacity for 80 so given the scenario we also see that",
    "start": "292400",
    "end": "298340"
  },
  {
    "text": "these nodes are filled with blocks and these blocks represents you till it will",
    "start": "298340",
    "end": "305120"
  },
  {
    "text": "be or the node being utilized by your boards so if you take the first genuine standard food node you can't see that it",
    "start": "305120",
    "end": "312020"
  },
  {
    "text": "is sort of half filled and that basically signifies that half of it is being utilized by some of your ports",
    "start": "312020",
    "end": "318889"
  },
  {
    "text": "already on it but above the yellow line you see there are two boards that are of that request",
    "start": "318889",
    "end": "327770"
  },
  {
    "text": "for CPUs and three CPUs each and they are not on any node the signifies that",
    "start": "327770",
    "end": "334250"
  },
  {
    "text": "they are pending boards they could have appeared from a new workload order HP a",
    "start": "334250",
    "end": "339380"
  },
  {
    "text": "or the scale workload could be or any of those or you know sources so what",
    "start": "339380",
    "end": "347240"
  },
  {
    "text": "cluster or descaler actually does is yeah so what plus you know to scale it actually does is it adds nodes for you",
    "start": "347240",
    "end": "354520"
  },
  {
    "text": "so quickly it doesn't seem to be working very well yes I'll stay closer to the",
    "start": "354520",
    "end": "364460"
  },
  {
    "text": "laptop I guess right so we actually add nodes for you so in this case there are",
    "start": "364460",
    "end": "371450"
  },
  {
    "text": "two new nodes that are added or the two NL standard for nodes that just appeared",
    "start": "371450",
    "end": "377240"
  },
  {
    "text": "and these should be able to house your pending boards so why did we scale out",
    "start": "377240",
    "end": "385970"
  },
  {
    "start": "383000",
    "end": "401000"
  },
  {
    "text": "the n1 standard for why did we add two nodes to n1 standard for nodes while we",
    "start": "385970",
    "end": "391669"
  },
  {
    "text": "could have added only one n1 standard eight or can we also customize this behavior",
    "start": "391669",
    "end": "399289"
  },
  {
    "text": "somehow the answer is yes we can so cluster autoscaler has this concept",
    "start": "399289",
    "end": "406069"
  },
  {
    "start": "401000",
    "end": "451000"
  },
  {
    "text": "of expanders or an expander is basically a a veil or an option to expand your",
    "start": "406069",
    "end": "413419"
  },
  {
    "text": "clusters in this particular mechanism and each expanded has this function",
    "start": "413419",
    "end": "418970"
  },
  {
    "text": "called best option which is which evaluates a bunch of options to ield the best option and each option in turn has",
    "start": "418970",
    "end": "427669"
  },
  {
    "text": "a new group to scale out it has the extra amount of nodes that particular",
    "start": "427669",
    "end": "433130"
  },
  {
    "text": "node group has to be scaled by and the pending pods that will be housed by this",
    "start": "433130",
    "end": "438979"
  },
  {
    "text": "scalar so let's turn order scalar has a few expanders already implemented each",
    "start": "438979",
    "end": "445820"
  },
  {
    "text": "with different parameters that are optimized we'll go over them so the",
    "start": "445820",
    "end": "452570"
  },
  {
    "start": "451000",
    "end": "501000"
  },
  {
    "text": "first expander that we have is least wastage expanded so um when you add new",
    "start": "452570",
    "end": "458990"
  },
  {
    "text": "nodes there is certain wastage in world if you add them and underutilized them so V basically the sorry the least least",
    "start": "458990",
    "end": "467690"
  },
  {
    "text": "is expanded actually pegs to nodes that are that have least wastage so we do",
    "start": "467690",
    "end": "475669"
  },
  {
    "text": "have a formula here that basically helps with that there's also the fact that it",
    "start": "475669",
    "end": "481159"
  },
  {
    "text": "optimizes for options where you pay less no tax or because the mode notes you",
    "start": "481159",
    "end": "487099"
  },
  {
    "text": "have the more tax you have to pay in terms of cubelet running on those extra nodes and also you know your demon sides",
    "start": "487099",
    "end": "496909"
  },
  {
    "text": "and other ports running on those nodes so we try to optimize for that and this expired nice ways to expand the next",
    "start": "496909",
    "end": "504620"
  },
  {
    "start": "501000",
    "end": "559000"
  },
  {
    "text": "expire that I want to talk about is price expanded so price expanded is",
    "start": "504620",
    "end": "509810"
  },
  {
    "text": "slightly more complicated it optimizes food the cost incurred per resource",
    "start": "509810",
    "end": "515810"
  },
  {
    "text": "requested by our pending ports so if in the earlier case we had 7 or CPUs",
    "start": "515810",
    "end": "521440"
  },
  {
    "text": "requested by our pending ports and we want to optimize for the dollar cost of",
    "start": "521440",
    "end": "527740"
  },
  {
    "text": "satisfying these sports and we also want to optimize for the current cluster shape",
    "start": "527740",
    "end": "533390"
  },
  {
    "text": "so in general it's better or to prefer larger cluster larger nodes for larger",
    "start": "533390",
    "end": "541040"
  },
  {
    "text": "clusters or for reasons of management cheerin and you also pay less tax if you",
    "start": "541040",
    "end": "549320"
  },
  {
    "text": "have larger nodes there are some formulas that I'll that you can do can",
    "start": "549320",
    "end": "555649"
  },
  {
    "text": "do to understand exactly how it works but I'll skip that for now so the other",
    "start": "555649",
    "end": "561769"
  },
  {
    "start": "559000",
    "end": "592000"
  },
  {
    "text": "expander that we have and I want to talk about is more sports expanded so keep in",
    "start": "561769",
    "end": "567019"
  },
  {
    "text": "mind that every option does not satisfy all your pending boards especially if your pending pods ports are of different",
    "start": "567019",
    "end": "573350"
  },
  {
    "text": "sizes so most post expander takes the option that satisfies the most amount of",
    "start": "573350",
    "end": "580310"
  },
  {
    "text": "ports most amount of pending words or you can use this option when you need to",
    "start": "580310",
    "end": "585529"
  },
  {
    "text": "scale out and schedule as soon as possible and satisfy as many nodes as possible or the last expander that I",
    "start": "585529",
    "end": "593660"
  },
  {
    "start": "592000",
    "end": "627000"
  },
  {
    "text": "want to talk about is priority expander so when we have options we basically",
    "start": "593660",
    "end": "601190"
  },
  {
    "text": "look at these options and a which will pick the option that has the highest",
    "start": "601190",
    "end": "607010"
  },
  {
    "text": "priority specified in this particular expanded and the priority here is",
    "start": "607010",
    "end": "612110"
  },
  {
    "text": "specified by the user in a config map that would look like this so in this",
    "start": "612110",
    "end": "618110"
  },
  {
    "text": "case or the nvm for large machines have the higher priority so we will try to",
    "start": "618110",
    "end": "624920"
  },
  {
    "text": "scale that if that is possible so how do you pick the right call flow for your",
    "start": "624920",
    "end": "630610"
  },
  {
    "start": "627000",
    "end": "658000"
  },
  {
    "text": "situation how do you pick the right expander in most cases just start out with your project price expander it will",
    "start": "630610",
    "end": "636769"
  },
  {
    "text": "work for the majority of the use cases and optimize what actually matters for you it in which might be priced right",
    "start": "636769",
    "end": "644180"
  },
  {
    "text": "which might bid price it good so again if for some reason you feel the price",
    "start": "644180",
    "end": "651260"
  },
  {
    "text": "expander is not optimal in your condition then you can try changing it based on what you feel can be optimized",
    "start": "651260",
    "end": "658839"
  },
  {
    "start": "658000",
    "end": "865000"
  },
  {
    "text": "all right so moving on the scanner also that scaled down for",
    "start": "658839",
    "end": "664220"
  },
  {
    "text": "you so take a look at this situation this sort of looks like it like the earlier situation but the cluster is",
    "start": "664220",
    "end": "670899"
  },
  {
    "text": "pretty sparse now it has a lot of emptiness on it and if you look closely",
    "start": "670899",
    "end": "677089"
  },
  {
    "text": "you can see - and then standard four nodes which are completely empty and there are three and when standard eight",
    "start": "677089",
    "end": "685820"
  },
  {
    "text": "nodes which could be you know optimized further they're mostly empty if you",
    "start": "685820",
    "end": "691130"
  },
  {
    "text": "click take a closer look you can in fact see that all these port the three ports",
    "start": "691130",
    "end": "698060"
  },
  {
    "text": "that are on the n1 standard nodes can actually be fit into one and one started node so that is what see it does for you",
    "start": "698060",
    "end": "705070"
  },
  {
    "text": "so at equal to zero we analyzed your cluster and figure out which nodes might",
    "start": "705070",
    "end": "710990"
  },
  {
    "text": "be unneeded so in this case your of two",
    "start": "710990",
    "end": "716750"
  },
  {
    "text": "and one standard four nodes and the three and one standard eight nodes are marked as I needed these are your",
    "start": "716750",
    "end": "723019"
  },
  {
    "text": "potential candidates were scaled down and if you look closely there's also a simulation result the CS c assimilate if",
    "start": "723019",
    "end": "731149"
  },
  {
    "text": "a particular you know all the put all these pods in these unneeded nodes can",
    "start": "731149",
    "end": "737390"
  },
  {
    "text": "be fit into our different destinations so we move on from here of two so once a",
    "start": "737390",
    "end": "747350"
  },
  {
    "text": "node is marked are needed it has to stay are needed for ten minutes or a",
    "start": "747350",
    "end": "752839"
  },
  {
    "text": "particular window that can be configured before we actually attempt to scale it down or the stability purposes we don't",
    "start": "752839",
    "end": "760190"
  },
  {
    "text": "want to scale down too quickly because if you do that you take a hit on availability so and we don't scale down",
    "start": "760190",
    "end": "768050"
  },
  {
    "text": "all the nodes at once all the unneeded nodes as once because that creates too much flux in the cluster so what we do",
    "start": "768050",
    "end": "775190"
  },
  {
    "text": "instead is we try to scale down the empty nodes in bulk so here the two and",
    "start": "775190",
    "end": "781010"
  },
  {
    "text": "one standard four nodes which are sort of empty we try to scale down and at a",
    "start": "781010",
    "end": "786170"
  },
  {
    "text": "equal to 10 we achieve that right so after that happens we again don't remove",
    "start": "786170",
    "end": "794449"
  },
  {
    "text": "all the in one standard eight at once we instead try to remove non empty nodes one by one so we also wait",
    "start": "794449",
    "end": "803960"
  },
  {
    "text": "so since a scale down happened at t equal to ten minutes we wait a while before ria tempting another scale down",
    "start": "803960",
    "end": "810650"
  },
  {
    "text": "and this is for stability purposes again we don't want to scale down all nodes one all at once or in short delays that",
    "start": "810650",
    "end": "818330"
  },
  {
    "text": "can severely affect your clusters availability and you will see this or and this is the theme of the",
    "start": "818330",
    "end": "824780"
  },
  {
    "text": "presentation as basically cost versus availability so at after the period of",
    "start": "824780",
    "end": "831410"
  },
  {
    "text": "time in this case that he folders ten minutes v re attempt to scale down and the second node the second in the",
    "start": "831410",
    "end": "838550"
  },
  {
    "text": "standard node is scaled up and hence support on and go spending but it can be scheduled on your n1 standard eight so",
    "start": "838550",
    "end": "847610"
  },
  {
    "text": "everything's fine or we had a scale down again so we wait for a period of time before he",
    "start": "847610",
    "end": "852620"
  },
  {
    "text": "attempting a scale down and we do that at t equal to thirty minutes the pod cuts spending on that node and",
    "start": "852620",
    "end": "859090"
  },
  {
    "text": "then we have it oh we have a very compact looking Lester at T equal to thirty minutes right so again the theme",
    "start": "859090",
    "end": "869450"
  },
  {
    "start": "865000",
    "end": "946000"
  },
  {
    "text": "of the presentation is cost versus availability you can queue in your cluster of and cluster order scalar to",
    "start": "869450",
    "end": "876710"
  },
  {
    "text": "sort of lean in one direction and that is what we'll be talking about but",
    "start": "876710",
    "end": "881720"
  },
  {
    "text": "before that I wanted to point out the CA is tuned for most of most of the serving",
    "start": "881720",
    "end": "888110"
  },
  {
    "text": "workloads so majority of the workloads in general are serving workloads like a web server or some kind and for that or",
    "start": "888110",
    "end": "895660"
  },
  {
    "text": "the default behavior works fine more than fine in fact but if you feel",
    "start": "895660",
    "end": "901490"
  },
  {
    "text": "like your workload is different somehow and you have you think you could you know tuned it better and make push it",
    "start": "901490",
    "end": "907610"
  },
  {
    "text": "towards a certain direction or then you can tune it so you can tune it in the",
    "start": "907610",
    "end": "914990"
  },
  {
    "text": "direction of availability or the direction of cost saving so if you have a workload like for example a batch",
    "start": "914990",
    "end": "921110"
  },
  {
    "text": "workload or so how are battling for different batch workloads show up all at",
    "start": "921110",
    "end": "926210"
  },
  {
    "text": "once the workload shows all up at once or so you have to immediately and the just as fast as they",
    "start": "926210",
    "end": "933680"
  },
  {
    "text": "came and they will get the workload completes and you would have to scale down quicker so in those cases you might",
    "start": "933680",
    "end": "940339"
  },
  {
    "text": "want to optimize see a further and we'll talk about how yes",
    "start": "940339",
    "end": "947660"
  },
  {
    "text": "so there are certain flags for optimizing utilization nca and we'll go",
    "start": "947660",
    "end": "953779"
  },
  {
    "text": "over them one by one so the first one is scaled out unneeded time so this is the",
    "start": "953779",
    "end": "959600"
  },
  {
    "text": "time that a node has to be unneeded for before we attempt scaled on so having",
    "start": "959600",
    "end": "966980"
  },
  {
    "text": "the higher value would basically protect you against flapping so if you remove a",
    "start": "966980",
    "end": "974690"
  },
  {
    "text": "node quickly it might so happen that a workload shows up and then you have to scale up again so there will be a lot of",
    "start": "974690",
    "end": "980060"
  },
  {
    "text": "flapping in that case so you would want to protect a keen side and the way to do it would be increasing this on the other",
    "start": "980060",
    "end": "986209"
  },
  {
    "text": "hand if you reduce it you will have faso scaled on potentially and you would also have because of you know or higher see a",
    "start": "986209",
    "end": "994040"
  },
  {
    "text": "reaction time the second thing I wanted to talk about is scaled oddly after",
    "start": "994040",
    "end": "999770"
  },
  {
    "text": "delete so after a particular scale down we wait for a certain period of time for",
    "start": "999770",
    "end": "1005170"
  },
  {
    "text": "the situation to stabilize before we reattempt it via time scale down so this flag affects this time similarly if you",
    "start": "1005170",
    "end": "1014740"
  },
  {
    "text": "want to increase this amount or he will threaten to yourself against flapping and you would have higher availability",
    "start": "1014740",
    "end": "1020320"
  },
  {
    "text": "in general if you'd reduce this time you would gain how fast is scale down you",
    "start": "1020320",
    "end": "1026110"
  },
  {
    "text": "would have fast you see a reaction speed the third fact that I wanted to talk to",
    "start": "1026110",
    "end": "1032020"
  },
  {
    "text": "you bird is the scale down utilization threshold so um first know to be",
    "start": "1032020",
    "end": "1038079"
  },
  {
    "text": "unneeded how how do we mark our node to be unneeded so the utilization on that",
    "start": "1038079",
    "end": "1043480"
  },
  {
    "text": "particular node has to be below a certain threshold for it to be deemed as unneeded and this flag directly affects",
    "start": "1043480",
    "end": "1050890"
  },
  {
    "text": "that value the default is around 50% so if you're a V market we mark nodes as",
    "start": "1050890",
    "end": "1056740"
  },
  {
    "text": "unneeded once they fall below the utilization threshold or 50%",
    "start": "1056740",
    "end": "1063429"
  },
  {
    "text": "so if you have a higher threshold that allows for lucid packing of your notes",
    "start": "1063429",
    "end": "1070090"
  },
  {
    "text": "because of scale Don's won't happen asked frequently it also allows for the level of over-provisioning so you can or",
    "start": "1070090",
    "end": "1078670"
  },
  {
    "text": "privation the cluster will not look as compact so you would have some level of",
    "start": "1078670",
    "end": "1084250"
  },
  {
    "text": "over-provisioning which might be needed for availability reasons on the other",
    "start": "1084250",
    "end": "1089650"
  },
  {
    "text": "hand if you decrease this value you would potentially have tighter nodes",
    "start": "1089650",
    "end": "1094830"
  },
  {
    "text": "I have potentially also have higher utilization the fourth plans that I",
    "start": "1094830",
    "end": "1102610"
  },
  {
    "text": "wanted to talk to you about is max empty bulky lead so as you've seen earlier see",
    "start": "1102610",
    "end": "1108070"
  },
  {
    "text": "it does delete empty nodes all at once right but there's a limit to that so the",
    "start": "1108070",
    "end": "1114490"
  },
  {
    "text": "limit by default is 10 so we do scale down 10 empty nodes at once but this can",
    "start": "1114490",
    "end": "1121300"
  },
  {
    "text": "be increased or you would want to increase that if you want faster clean up after let's say a batch job or if you",
    "start": "1121300",
    "end": "1127809"
  },
  {
    "text": "have larger clusters where are 10 nodes might not be enough to scale down at",
    "start": "1127809",
    "end": "1132940"
  },
  {
    "text": "once or so in which case you would want to increase the sample or decreasing this number protects you against making",
    "start": "1132940",
    "end": "1140020"
  },
  {
    "text": "big changes in your cluster so again for availability reasons you would want that",
    "start": "1140020",
    "end": "1147090"
  },
  {
    "start": "1147000",
    "end": "1217000"
  },
  {
    "text": "there are also other things that matter as a flagship matter or I'll go over them briefly the first for example is",
    "start": "1147090",
    "end": "1156360"
  },
  {
    "text": "unready scalar under any time so if a node is unready we wait for a certain amount of time before attempting scale",
    "start": "1156360",
    "end": "1162730"
  },
  {
    "text": "down or the flag directly effect side scan interval is a time that CA is",
    "start": "1162730",
    "end": "1169440"
  },
  {
    "text": "basically how often see area reevaluate your cluster or scale down delay after",
    "start": "1169440",
    "end": "1175390"
  },
  {
    "text": "failure is so after if after failure and",
    "start": "1175390",
    "end": "1180730"
  },
  {
    "text": "scale down we wait for a certain time before he attempting it or reactant a scale down and this flag effects that um",
    "start": "1180730",
    "end": "1187470"
  },
  {
    "text": "scale down delay after ID so if we scale up we wait for a certain amount of time",
    "start": "1187470",
    "end": "1194140"
  },
  {
    "text": "for stabilization reasons before we attempt another scale done and this flag",
    "start": "1194140",
    "end": "1199330"
  },
  {
    "text": "effects AK value unremovable note recheck time out so if we're nude is deemed as unremovable for whatever",
    "start": "1199330",
    "end": "1206080"
  },
  {
    "text": "reasons we have a timeout for which we recheck if the if we can still delete",
    "start": "1206080",
    "end": "1211749"
  },
  {
    "text": "this an immovable node and this flux value would affect the timeout so if you",
    "start": "1211749",
    "end": "1218889"
  },
  {
    "text": "look at it broadly the values on the left the flag values on the left make",
    "start": "1218889",
    "end": "1224830"
  },
  {
    "text": "your be scale downs quicker and if you have multiple scale downs lined up and",
    "start": "1224830",
    "end": "1230109"
  },
  {
    "text": "multiple clean so if you what a clean your clustered or the values under setting the values on the right would",
    "start": "1230109",
    "end": "1236940"
  },
  {
    "text": "help you have the serial scale dance faster",
    "start": "1236940",
    "end": "1243899"
  },
  {
    "text": "so there are game there are some non cluster or the scale of flags that also",
    "start": "1244659",
    "end": "1250299"
  },
  {
    "text": "mattered so for your controller manager and should you live queue API QP s and Q",
    "start": "1250299",
    "end": "1257409"
  },
  {
    "text": "PPI first matter so for example cube API a QP s is the QP s that your controller",
    "start": "1257409",
    "end": "1264009"
  },
  {
    "text": "manager or scheduler or uses to talk to the API server so if it's not set to a",
    "start": "1264009",
    "end": "1269259"
  },
  {
    "text": "high enough value or you will have put for a poor performance that effects that can affect your or scale down since",
    "start": "1269259",
    "end": "1276190"
  },
  {
    "text": "Caleb's API server flags so there are there is the math mutating requests in",
    "start": "1276190",
    "end": "1284349"
  },
  {
    "text": "flight and max requests in flight that signify how many requests can your API",
    "start": "1284349",
    "end": "1292059"
  },
  {
    "text": "server handle in flight so how many concurrent requests can it handle at once and that number if not set to high",
    "start": "1292059",
    "end": "1299799"
  },
  {
    "text": "enough or to a high enough value would affect the performance right so how do",
    "start": "1299799",
    "end": "1306519"
  },
  {
    "start": "1305000",
    "end": "1373000"
  },
  {
    "text": "you use these or flags in real life if you're using or self hosted kubernetes",
    "start": "1306519",
    "end": "1312460"
  },
  {
    "text": "or it's simple and I'll just change or the value in your C it should work we do",
    "start": "1312460",
    "end": "1319149"
  },
  {
    "text": "recommend that you gradually change them and maybe even one flag at a time so that you don't affect it a lot and",
    "start": "1319149",
    "end": "1326889"
  },
  {
    "text": "you understand what are the consequence of changing a particularly value decreasing or increasing it and",
    "start": "1326889",
    "end": "1333300"
  },
  {
    "text": "over time you will reach what you feel is your optimal situation for hosted",
    "start": "1333300",
    "end": "1341080"
  },
  {
    "text": "solutions full solutions like gke we have auto scaling profiles the charge or",
    "start": "1341080",
    "end": "1348820"
  },
  {
    "text": "beta soon where you have a curated profile that you can just pick from and say hey I want to optimize my",
    "start": "1348820",
    "end": "1354970"
  },
  {
    "text": "utilization and that would basically mean a certain list of flags are set to",
    "start": "1354970",
    "end": "1360310"
  },
  {
    "text": "certain values to help you do that for other cloud providers or you would have",
    "start": "1360310",
    "end": "1365320"
  },
  {
    "text": "to figure out or exactly how to change the flags and how to set it to optimal",
    "start": "1365320",
    "end": "1371260"
  },
  {
    "text": "numbers all right um I guess that's it for the presentation but we can move on",
    "start": "1371260",
    "end": "1377920"
  },
  {
    "start": "1373000",
    "end": "1448000"
  },
  {
    "text": "to the questions [Applause]",
    "start": "1377920",
    "end": "1388720"
  },
  {
    "text": "all right they did not seem to be any unless I'm missing oh this one here this",
    "start": "1391310",
    "end": "1398420"
  },
  {
    "text": "one here do we have a mic no mics",
    "start": "1398420",
    "end": "1414790"
  },
  {
    "text": "ah",
    "start": "1421050",
    "end": "1423080"
  },
  {
    "start": "1448000",
    "end": "1524000"
  },
  {
    "text": "so I'm going to repeat the question of for the benefit of everyone who couldn't hear that so the question was how can we",
    "start": "1448130",
    "end": "1456480"
  },
  {
    "text": "actually use these methods to handle cases where we have workloads that burst",
    "start": "1456480",
    "end": "1462179"
  },
  {
    "text": "with more CPU usage and then don't need that CPU with that amount of resources",
    "start": "1462179",
    "end": "1467970"
  },
  {
    "text": "anymore could we you you start these techniques set so if they are the same workload so",
    "start": "1467970",
    "end": "1475590"
  },
  {
    "text": "for example if the work load already exists in a cluster but the limits are being changed by something like VP a and",
    "start": "1475590",
    "end": "1481620"
  },
  {
    "text": "and thirds you would need more resources in a short burst in that in those cases",
    "start": "1481620",
    "end": "1487350"
  },
  {
    "text": "yes you could use some of these flags but then these floods that is",
    "start": "1487350",
    "end": "1493350"
  },
  {
    "text": "particularly discussed some of them are useful for scale-up most of them are used for scale down so if you want to scale down quickly and",
    "start": "1493350",
    "end": "1499169"
  },
  {
    "text": "use less resources that is how you could use these methods to do that or another",
    "start": "1499169",
    "end": "1505169"
  },
  {
    "text": "question",
    "start": "1505169",
    "end": "1507590"
  },
  {
    "start": "1524000",
    "end": "1613000"
  },
  {
    "text": "right so the gentleman here was interested in figuring out if we could",
    "start": "1524040",
    "end": "1530220"
  },
  {
    "text": "use less euro descaler in an on-prem setup so for this or I do also recommend",
    "start": "1530220",
    "end": "1537210"
  },
  {
    "text": "margins or talk yesterday but or you can sort of do it there are methods to do it",
    "start": "1537210",
    "end": "1543450"
  },
  {
    "text": "so cluster order scale it supports a few cloud providers at this point if we have a exhaustive list of floods providers",
    "start": "1543450",
    "end": "1550230"
  },
  {
    "text": "that we support on Prem is not really a cloud cloud provider at this point",
    "start": "1550230",
    "end": "1555570"
  },
  {
    "text": "particular point of time because that is not implemented in the one Prem setup could become widely different but if you",
    "start": "1555570",
    "end": "1563190"
  },
  {
    "text": "if you could in fact implement an interface called cloud provider which",
    "start": "1563190",
    "end": "1568890"
  },
  {
    "text": "exists in cluster order scale it in your own Prem set up that means that you can use order scalar so any any environment",
    "start": "1568890",
    "end": "1577530"
  },
  {
    "text": "that can potentially implement this cloud provider interface can use cluster or a scalar",
    "start": "1577530",
    "end": "1584810"
  },
  {
    "text": "um any other questions sure gentlemen a friend so Mike so I want to be able to",
    "start": "1598770",
    "end": "1619620"
  },
  {
    "start": "1613000",
    "end": "1679000"
  },
  {
    "text": "use the autoscaler while balancing the high availability that I might ask my scheduler for so I might tell my",
    "start": "1619620",
    "end": "1625380"
  },
  {
    "text": "scheduler I want you to balance my pause across availability zones but this kind of the autoscaler kind of fights a",
    "start": "1625380",
    "end": "1631740"
  },
  {
    "text": "little bit with this preference because the scheduler doesn't know about the autoscaler the autoscaler might only",
    "start": "1631740",
    "end": "1636840"
  },
  {
    "text": "leave room on one node so all the pods get scheduled there and it's kind of like happens over and over we notice in",
    "start": "1636840",
    "end": "1644280"
  },
  {
    "text": "production is there is should I just tune it to have more room like you suggested should is there a better story",
    "start": "1644280",
    "end": "1651090"
  },
  {
    "text": "for happen so with that yes that's a good question there yes at this point we",
    "start": "1651090",
    "end": "1656850"
  },
  {
    "text": "are scheduled a team and the cluster or the scaler team are working on something like a balancing out a balanced way of",
    "start": "1656850",
    "end": "1664860"
  },
  {
    "text": "doing this like if you want to spread out your nodes across multiple new ones and have more balanced set up you should",
    "start": "1664860",
    "end": "1671370"
  },
  {
    "text": "be able to do this with solution that we are working on and this is definitely on the radar okay thank you so all of the",
    "start": "1671370",
    "end": "1680429"
  },
  {
    "start": "1679000",
    "end": "1770000"
  },
  {
    "text": "utilization that you had in your talk is all about requests right is there any",
    "start": "1680429",
    "end": "1686100"
  },
  {
    "text": "work being done to use actual utilization at the machine to work on",
    "start": "1686100",
    "end": "1692870"
  },
  {
    "text": "vertical pod auto auto scaling and/or cluster auto scaling great so this is a",
    "start": "1692870",
    "end": "1700110"
  },
  {
    "text": "good question why don't we you know you just use utilization to figure out and you know trigger scale of when required",
    "start": "1700110",
    "end": "1707160"
  },
  {
    "text": "etcetera and scale and well required so there is a strict boundary between the",
    "start": "1707160",
    "end": "1713250"
  },
  {
    "text": "auto scalars and we want it to be that way so there is a separation of concerns with what we want the autoscaler to do",
    "start": "1713250",
    "end": "1718940"
  },
  {
    "text": "when it comes to the autoscaler level we make certain assumptions we make the",
    "start": "1718940",
    "end": "1724530"
  },
  {
    "text": "assumption that everything in terms of resource requests is already perfect because something like BPA would have",
    "start": "1724530",
    "end": "1730800"
  },
  {
    "text": "done it so in this case we basically try to do",
    "start": "1730800",
    "end": "1736010"
  },
  {
    "text": "the best we can based on this assumption so he would probably want a junior VP a",
    "start": "1736010",
    "end": "1742370"
  },
  {
    "text": "or to get the right amount of resource request and resource limit set and based",
    "start": "1742370",
    "end": "1747920"
  },
  {
    "text": "on that the cluster orders key load will try to do the best it can and that provides us a good layer of separation",
    "start": "1747920",
    "end": "1753590"
  },
  {
    "text": "of concerns - the following question is are you aware of the kernel bursting",
    "start": "1753590",
    "end": "1758840"
  },
  {
    "text": "patches currently in flight on l kml I don't think I'm aware of that so we can",
    "start": "1758840",
    "end": "1763850"
  },
  {
    "text": "talk more about that after day yeah we could talk about that afterwards but I'd love to talk to you about that so we run",
    "start": "1763850",
    "end": "1773470"
  },
  {
    "start": "1770000",
    "end": "1800000"
  },
  {
    "text": "pools of specialized worker worker nodes does the is the cluster autoscaler able",
    "start": "1773470",
    "end": "1779420"
  },
  {
    "text": "to take into account things like taints that would be applied to a worker pool yes so the plus you notice Kelly also",
    "start": "1779420",
    "end": "1786170"
  },
  {
    "text": "works with chains and labels if they are appeared and the food scale if your pod",
    "start": "1786170",
    "end": "1792890"
  },
  {
    "text": "would only fit in those particular node pools will scale those dedicated node poles oh yeah I did not notice this",
    "start": "1792890",
    "end": "1802280"
  },
  {
    "start": "1800000",
    "end": "1833000"
  },
  {
    "text": "lines let me skip erosion okay I was wondering does the autoscaler take into",
    "start": "1802280",
    "end": "1807800"
  },
  {
    "text": "account like draining nodes before scheduling to make sure that your workloads stay available yes so we do",
    "start": "1807800",
    "end": "1813230"
  },
  {
    "text": "drain a node before our video move it and that and we also look at before even",
    "start": "1813230",
    "end": "1819770"
  },
  {
    "text": "tree we look at things like for disruption budgets to make sure that the board on that can actually be recreated",
    "start": "1819770",
    "end": "1825950"
  },
  {
    "text": "and can be fit and anywhere else so or we do do that I wanted to ask if you had",
    "start": "1825950",
    "end": "1835070"
  },
  {
    "start": "1833000",
    "end": "1886000"
  },
  {
    "text": "any opinions on observability best practices particularly about like why didn't this scale down when I thought it",
    "start": "1835070",
    "end": "1841610"
  },
  {
    "text": "should is always the classic one that's a great question so one thing that we are working towards is visibility so why",
    "start": "1841610",
    "end": "1849440"
  },
  {
    "text": "did the cluster or the scaler scale up or scale down at this point of time cm it's kubernetes events and these events",
    "start": "1849440",
    "end": "1859010"
  },
  {
    "text": "have the reason why it scaled up or scaled down oh now actually we civilized",
    "start": "1859010",
    "end": "1864290"
  },
  {
    "text": "thing the event into an timeline or something like that is left out to the consumer of",
    "start": "1864290",
    "end": "1870179"
  },
  {
    "text": "these events or something like gke has a product in beta value we try to",
    "start": "1870179",
    "end": "1876240"
  },
  {
    "text": "visualize this over that time like over Peter timeline so we do or from the cluster on what our scalar point of view",
    "start": "1876240",
    "end": "1882210"
  },
  {
    "text": "we do Emmit these events are there any",
    "start": "1882210",
    "end": "1887690"
  },
  {
    "start": "1886000",
    "end": "1918000"
  },
  {
    "text": "considerations that you should keep in mind if you're gonna be using the cluster autoscaler along with like preemptable x' or spot instances um so",
    "start": "1887690",
    "end": "1894960"
  },
  {
    "text": "it does work with p.m. tables um 100% sure about its part instance isn't because not a weight of how exactly it",
    "start": "1894960",
    "end": "1903720"
  },
  {
    "text": "works at a to base but um in terms of preemptable it doesn't work with it in",
    "start": "1903720",
    "end": "1908880"
  },
  {
    "text": "in case it also is a weight of the fact that the M tables are cheaper so you",
    "start": "1908880",
    "end": "1914760"
  },
  {
    "text": "should be able to work with it perfectly question about the cluster autoscaler",
    "start": "1914760",
    "end": "1920790"
  },
  {
    "start": "1918000",
    "end": "1987000"
  },
  {
    "text": "well because the looking at the pod resources versus cluster resources",
    "start": "1920790",
    "end": "1925860"
  },
  {
    "text": "sometimes when the noes are actually scheduling up they are scheduling up by one by one so like weights word is there",
    "start": "1925860",
    "end": "1932429"
  },
  {
    "text": "a possibility for to have like a more fastest gala that goes more looking at the metrics of the cluster versus the",
    "start": "1932429",
    "end": "1938970"
  },
  {
    "text": "metrics of the pods right so at this point of time we only look at we only",
    "start": "1938970",
    "end": "1946830"
  },
  {
    "text": "scale up once we notice an unshakable point on there are so there are",
    "start": "1946830",
    "end": "1952500"
  },
  {
    "text": "proposals about sort of doing this predictively making predictions about you know can we",
    "start": "1952500",
    "end": "1958710"
  },
  {
    "text": "already scale up without having a pending pod but those are what they are which are just proposals at this point",
    "start": "1958710",
    "end": "1965100"
  },
  {
    "text": "or but we will be looking at that more in the future and any proposals at that all also",
    "start": "1965100",
    "end": "1970440"
  },
  {
    "text": "welcome or one thing I forgot to put it on the side is a fact that we have or",
    "start": "1970440",
    "end": "1975750"
  },
  {
    "text": "the scale C go to scaling meetings Monday 7:00 p.m. est DT so any proposals",
    "start": "1975750",
    "end": "1982380"
  },
  {
    "text": "are welcome any requests are also welcome awesome thank you thanks I think",
    "start": "1982380",
    "end": "1987960"
  },
  {
    "text": "you were saying earlier that a lot of the flags that you had up could be used for scale down especially when",
    "start": "1987960",
    "end": "1994380"
  },
  {
    "text": "you're talking about for example batch jobs specifically to batch jobs do you have any guidance or on the like either",
    "start": "1994380",
    "end": "2001100"
  },
  {
    "text": "scale up or just in general great um scale up it's for a lot of",
    "start": "2001100",
    "end": "2006500"
  },
  {
    "text": "providers Caleb is already pretty fast should be fine for the lot of cases or scale down is where we get the most",
    "start": "2006500",
    "end": "2012860"
  },
  {
    "text": "amount of requests and this should help with that so it depends on you if you're",
    "start": "2012860",
    "end": "2019279"
  },
  {
    "text": "using a hosted solution or a self hosted solution we're using a self hosted solution you can use eggs all the",
    "start": "2019279",
    "end": "2027409"
  },
  {
    "text": "contents in this presentation to figure out the right values for your batch workload and a few optimizes gradually",
    "start": "2027409",
    "end": "2035120"
  },
  {
    "text": "you should be able to find a sweet spot for you pretty soon two questions",
    "start": "2035120",
    "end": "2043220"
  },
  {
    "text": "one if are there any claw cloud provider specifics that we have to keep in mind and the second is if you use custom",
    "start": "2043220",
    "end": "2050450"
  },
  {
    "text": "metrics for horizontal part of scaling outside of CPU and memory is there any bearing on cluster or scaling I'll",
    "start": "2050450",
    "end": "2057908"
  },
  {
    "text": "answer the first question or first so are there any cloud provider or things",
    "start": "2057909",
    "end": "2063888"
  },
  {
    "text": "that you have to keep in mind I think one of the biggest thing that you have to keep in mind is that the scale up or",
    "start": "2063889",
    "end": "2069408"
  },
  {
    "text": "scale down time once cluster or the scaler decides hey let's remove this node the response time and the time",
    "start": "2069409",
    "end": "2075980"
  },
  {
    "text": "after which it actually happens if we're completely on the cloud provider so for example cloud provider a might be able",
    "start": "2075980",
    "end": "2081858"
  },
  {
    "text": "to scale down quickly but remove the node much quicker than cloud provider P or and that is something that you'll",
    "start": "2081859",
    "end": "2087260"
  },
  {
    "text": "have to experiment and figure out okay and the second question could you please repeat that yeah if we have any non star",
    "start": "2087260",
    "end": "2094579"
  },
  {
    "text": "I mean not not CP or a custom metrics right not CP your memory but custom metrics for horizontal pod auto scaling is there anything that we have to bear",
    "start": "2094579",
    "end": "2101450"
  },
  {
    "text": "in mind when we do cluster auto scaling right um so nothing of that sort Annette when it comes to cluster to",
    "start": "2101450",
    "end": "2107119"
  },
  {
    "text": "scale it because we do again have that separation of concerns there but there are some best practices to set your you",
    "start": "2107119",
    "end": "2115730"
  },
  {
    "text": "know choose the right metric of so for example if we generally don't use advise you to use metrics such as memory",
    "start": "2115730",
    "end": "2122510"
  },
  {
    "text": "and latency so we can talk more about that okay this is this I guess so",
    "start": "2122510",
    "end": "2128000"
  },
  {
    "text": "there are some gotchas which we can do yes thank you hi um so I think you",
    "start": "2128000",
    "end": "2133430"
  },
  {
    "start": "2132000",
    "end": "2214000"
  },
  {
    "text": "mentioned that autoscaler works with no tent so I'm asking the question under the amount of tenancy contacts so let's",
    "start": "2133430",
    "end": "2140390"
  },
  {
    "text": "say I have some workload only can be rung in a specific node groups so can autoscaler kind of like create a new",
    "start": "2140390",
    "end": "2147740"
  },
  {
    "text": "node for me that I have bigger machines if I have to create a new notebook and autoscaler can like scale one the bigger",
    "start": "2147740",
    "end": "2155720"
  },
  {
    "text": "load groups down to zero and move out the power to some smaller node groups that can only run it so if the question",
    "start": "2155720",
    "end": "2161119"
  },
  {
    "text": "is can the autoscaler create a new load pool for you you're like with big machines automatically currently no no",
    "start": "2161119",
    "end": "2168020"
  },
  {
    "text": "but we have sort of a feature that disease in gke or because we understand",
    "start": "2168020",
    "end": "2173720"
  },
  {
    "text": "how a Blood Factory because we just work on gogledd so we do have that feature",
    "start": "2173720",
    "end": "2178910"
  },
  {
    "text": "for Google Cloud or we can talk more about that after the presentation answering the questions the second thing",
    "start": "2178910",
    "end": "2185660"
  },
  {
    "text": "is that does it can you selectively scale a particular node group yes you can if you have the right teens and",
    "start": "2185660",
    "end": "2192830"
  },
  {
    "text": "Toleration zon that know the right teens on the node group and the right holiday shins for your parts I see so can",
    "start": "2192830",
    "end": "2199190"
  },
  {
    "text": "autoscaler scale the node pou to zero so we are out",
    "start": "2199190",
    "end": "2204349"
  },
  {
    "text": "of time it's just been notified it should sorry for the questions that I couldn't handle or we can't do that",
    "start": "2204349",
    "end": "2209630"
  },
  {
    "text": "right outside thank you [Applause]",
    "start": "2209630",
    "end": "2216190"
  }
]
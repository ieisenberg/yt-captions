[
  {
    "start": "0",
    "end": "34000"
  },
  {
    "text": "yeah so welcome how many of you have been to Kiev gone before so three people",
    "start": "30",
    "end": "7170"
  },
  {
    "text": "I mean how many of you have seen cube flow before let seen fear how many of",
    "start": "7170",
    "end": "14519"
  },
  {
    "text": "you have actually used it just getting a sense of the audience like four so yeah this is a good place to be if you",
    "start": "14519",
    "end": "20460"
  },
  {
    "text": "haven't used cube pillow before how many of you have used tensorflow before most",
    "start": "20460",
    "end": "26279"
  },
  {
    "text": "the audience okay great so today we're going to talk about bringing your data",
    "start": "26279",
    "end": "31650"
  },
  {
    "text": "pipeline into the age of machine learning my name is Chris gone I am a product marketing manager at mesosphere",
    "start": "31650",
    "end": "39379"
  },
  {
    "start": "34000",
    "end": "90000"
  },
  {
    "text": "I've been in the kubernetes community a very long time on the CN CN CN CF",
    "start": "39379",
    "end": "44789"
  },
  {
    "text": "ambassador if you're interested in what that program is if you've seen that machine walking around with that face on",
    "start": "44789",
    "end": "51030"
  },
  {
    "text": "it you could ask that device and they could tell you what a CNC F ambassador is but basically we advocate for CN CF",
    "start": "51030",
    "end": "58980"
  },
  {
    "text": "technologies like kubernetes and core DNS and the rest of them that we've learned about in this conference",
    "start": "58980",
    "end": "65150"
  },
  {
    "text": "previous to that I was an analyst at Gartner I covered public cloud particularly public infrastructure as a",
    "start": "65150",
    "end": "71670"
  },
  {
    "text": "service to follow me on Twitter this is not my first keep Khan speech yeah so",
    "start": "71670",
    "end": "77970"
  },
  {
    "text": "I've been I've didn't been here before I've done keynote speaker speeches at Q Khan I've also traveled throughout the",
    "start": "77970",
    "end": "84600"
  },
  {
    "text": "United States and Europe teaching people about kubernetes for the past three years",
    "start": "84600",
    "end": "89810"
  },
  {
    "text": "I'm yuk so I'm a technical community lead what does that mean that I'm",
    "start": "89810",
    "end": "95189"
  },
  {
    "text": "basically picking up community projects and make sure that they work well with Apache missiles and then DCOs so when we",
    "start": "95189",
    "end": "103439"
  },
  {
    "text": "start up new projects like tends to flow like you flowin end up with me and then I work with a community of getting that",
    "start": "103439",
    "end": "109920"
  },
  {
    "text": "going originally when the cur developer of Apache missiles but yeah more recently I really enjoys this machine",
    "start": "109920",
    "end": "117149"
  },
  {
    "text": "learning area data science in general so I believe this is why it's a good food",
    "start": "117149",
    "end": "122310"
  },
  {
    "text": "to preside co-presenter is Chris here and yeah so most hands actually went up",
    "start": "122310",
    "end": "130979"
  },
  {
    "text": "when we said when we asked like who knows tense flow but maybe just to recap kind of CI dear",
    "start": "130979",
    "end": "136140"
  },
  {
    "text": "why deep learning right now is becoming so popular first of all we got more compute power and we got more data and",
    "start": "136140",
    "end": "141990"
  },
  {
    "text": "that actually means that this traditional machine learning pipeline imagine we want to have this classifier",
    "start": "141990",
    "end": "148320"
  },
  {
    "text": "darker CAD or hot dark non hot dog what happened in traditional machine learning",
    "start": "148320",
    "end": "154770"
  },
  {
    "text": "we actually we had a very smart highly paid person sitting there and he would",
    "start": "154770",
    "end": "159810"
  },
  {
    "text": "extract features and with his features and could build like an SVM or some kind of classification mechanism to actually",
    "start": "159810",
    "end": "167490"
  },
  {
    "text": "classify those images and then we had our output hot dog non hot dog dog cat",
    "start": "167490",
    "end": "173870"
  },
  {
    "text": "with machine learning this actually requires this extra effort and with",
    "start": "173870",
    "end": "179100"
  },
  {
    "text": "steep learning we're replacing this human basically with stator and more machinery so instead of having someone",
    "start": "179100",
    "end": "185730"
  },
  {
    "text": "who also had might have a bias and deciding what kind of features you might want to extract we actually just leave",
    "start": "185730",
    "end": "192630"
  },
  {
    "text": "that up to the machine because from if we have enough data we are much better in figuring it out from the data what",
    "start": "192630",
    "end": "198270"
  },
  {
    "text": "are the best features to actually decide this dark non doc question here so how",
    "start": "198270",
    "end": "204330"
  },
  {
    "text": "does it typically look like we gets like some label picket pictures where a pure human draw like some boxes around the",
    "start": "204330",
    "end": "211470"
  },
  {
    "text": "stalk here so label input data and the more of this input data we have the",
    "start": "211470",
    "end": "216600"
  },
  {
    "text": "better and then we come up with like a basic network structure and we start",
    "start": "216600",
    "end": "222239"
  },
  {
    "text": "training Z weights and then the have a trained model and then the second step",
    "start": "222239",
    "end": "229050"
  },
  {
    "text": "comes and this is actually the inference step or the serving stuff and then we have our model and we deploy to",
    "start": "229050",
    "end": "236040"
  },
  {
    "text": "production so we're actually getting new previously unseen images and then we search them and already in this slide",
    "start": "236040",
    "end": "242640"
  },
  {
    "text": "this is something when I look at conferences or when I look at blog posts a lot of people focus on like the first",
    "start": "242640",
    "end": "249450"
  },
  {
    "text": "site training what are the best images what is like the best models to use how",
    "start": "249450",
    "end": "255360"
  },
  {
    "text": "do I train best and how to optimize my hyperparameters and that's all very important but like in production use",
    "start": "255360",
    "end": "261930"
  },
  {
    "text": "cases the second step of how do I serve this model how do I actually builds us into complete",
    "start": "261930",
    "end": "267250"
  },
  {
    "text": "line is at least equally important tensorflow of almost all hands to end off so I",
    "start": "267250",
    "end": "274120"
  },
  {
    "start": "270000",
    "end": "320000"
  },
  {
    "text": "don't want to say too much but it's basically a library often used to build",
    "start": "274120",
    "end": "279490"
  },
  {
    "text": "deep learning models it's not only deep learning models actually it can also do more traditional machine learning and",
    "start": "279490",
    "end": "286500"
  },
  {
    "text": "the nice part about it that we kind of have an abstraction we have multiple high level interfaces on top but in the",
    "start": "286500",
    "end": "294250"
  },
  {
    "text": "end we are coming up with a was like our model and then tensorflow can actually",
    "start": "294250",
    "end": "300640"
  },
  {
    "text": "distribute that across different infrastructures so it can optimize my",
    "start": "300640",
    "end": "305650"
  },
  {
    "text": "learning process for a set up where I have GPUs where I've CPUs when I'm",
    "start": "305650",
    "end": "310870"
  },
  {
    "text": "distributed when I'm non distributed so either as a data scientist writing my model I don't have to worry about it if",
    "start": "310870",
    "end": "316780"
  },
  {
    "text": "I use to write api's if I use the right api's and just if we look back how",
    "start": "316780",
    "end": "324100"
  },
  {
    "start": "320000",
    "end": "376000"
  },
  {
    "text": "tensor flow has been trending on github stars so here's is first when it jumps",
    "start": "324100",
    "end": "329800"
  },
  {
    "text": "up this was actually when Google put tensorflow on github and you can see it steadily",
    "start": "329800",
    "end": "335260"
  },
  {
    "text": "increasing and it's really an impressive growth I was just at developers",
    "start": "335260",
    "end": "340660"
  },
  {
    "text": "tensorflow developer summit last month in Mountain View and it's really impressive so this was like the largest",
    "start": "340660",
    "end": "346630"
  },
  {
    "text": "conference I've always felt q Khan is large or skating much larger but that was really impressive for such a young",
    "start": "346630",
    "end": "352660"
  },
  {
    "text": "project to see such a big conference coming up there and you can also see",
    "start": "352660",
    "end": "359140"
  },
  {
    "text": "like if we take get up stars as kind of a metric how it compares to other",
    "start": "359140",
    "end": "364150"
  },
  {
    "text": "projects for me honestly they're really good other projects as well but it simply shows that there's a lot of",
    "start": "364150",
    "end": "370120"
  },
  {
    "text": "developer power and also for a lot of users in in the tensorflow realm",
    "start": "370120",
    "end": "376290"
  },
  {
    "start": "376000",
    "end": "403000"
  },
  {
    "text": "tensorflow how does that look like if I do that as a single developer being a",
    "start": "376290",
    "end": "382090"
  },
  {
    "text": "single developer and this is what I actually really like about it I simply downloads the libraries and I can run",
    "start": "382090",
    "end": "387640"
  },
  {
    "text": "that on my own machine and listen if I download the pre-trained model I can actually get that working with like an",
    "start": "387640",
    "end": "394060"
  },
  {
    "text": "hour time and I've trained my first model so it actually makes it very simple being a single single node eval",
    "start": "394060",
    "end": "401200"
  },
  {
    "text": "for just testing things out but if we",
    "start": "401200",
    "end": "406660"
  },
  {
    "start": "403000",
    "end": "549000"
  },
  {
    "text": "actually turn over and we leave our own desk where it's simple but then we",
    "start": "406660",
    "end": "413500"
  },
  {
    "text": "actually want to put that in production it becomes a bit harder because we all",
    "start": "413500",
    "end": "419050"
  },
  {
    "text": "these problems which would like non-existent on my laptop we have when we want to do that in production so we",
    "start": "419050",
    "end": "424330"
  },
  {
    "text": "have to consider where do I store my data tip if we want to do a machine",
    "start": "424330",
    "end": "429340"
  },
  {
    "text": "learning deep learning right we need datasets which don't fit on a single machine so I need some kind of distributed data storage I need to",
    "start": "429340",
    "end": "435970"
  },
  {
    "text": "prepare data typically datasets I get from anywhere in my production cluster",
    "start": "435970",
    "end": "441760"
  },
  {
    "text": "in very rare cases I might use them directly but often I actually I have to",
    "start": "441760",
    "end": "447220"
  },
  {
    "text": "prepare cleanse them which we'll see in a second then of the data scientists work starts actually have to explore the",
    "start": "447220",
    "end": "453460"
  },
  {
    "text": "data and once I have an kind of idea what I want to train I actually I need",
    "start": "453460",
    "end": "459070"
  },
  {
    "text": "to kick off like a large job utilizing a large class my data set is large and even in the distributed set up this can",
    "start": "459070",
    "end": "465910"
  },
  {
    "text": "take days and while this is running it's really important to keep monitoring in",
    "start": "465910",
    "end": "471340"
  },
  {
    "text": "mind tensor board it's really nice to monitor kind of C training progress but",
    "start": "471340",
    "end": "476500"
  },
  {
    "text": "a distributed infrastructure it already kind of points it out I also want some monitoring for this overall",
    "start": "476500",
    "end": "482170"
  },
  {
    "text": "infrastructure then also debugging tfd Bach it's nice",
    "start": "482170",
    "end": "487720"
  },
  {
    "text": "I really how many of you have seen that it's actually there it's an alpha or better version included intensive board",
    "start": "487720",
    "end": "494380"
  },
  {
    "text": "in the latest version so previously like TF debug used to be this command line",
    "start": "494380",
    "end": "501850"
  },
  {
    "text": "saying which for us it was helpful but it was kind of annoying to use and in the latest versions they actually puts",
    "start": "501850",
    "end": "507310"
  },
  {
    "text": "that into a tensor board as well so that's a great step for debugging forward and then the last part and as",
    "start": "507310",
    "end": "516130"
  },
  {
    "text": "mentioned earlier also one of the important parts actually model serving is when I puts this model into production and they're a bunch of",
    "start": "516130",
    "end": "523360"
  },
  {
    "text": "challenges they're like how do I get my data in there like how do i trigger requests how do I choose which model I",
    "start": "523360",
    "end": "530920"
  },
  {
    "text": "want to serve I kind of need zero downtime deployments for my model serving after all as this training process is",
    "start": "530920",
    "end": "538209"
  },
  {
    "text": "not a one-time thing it's actually an iterative thing when I get more data when I refine my models so also as a",
    "start": "538209",
    "end": "543879"
  },
  {
    "text": "model serving side kind of has to reflect that all right so with that the typical workflow if I'm",
    "start": "543879",
    "end": "553029"
  },
  {
    "start": "549000",
    "end": "625000"
  },
  {
    "text": "want to run tensorflow on a distributed set up or just the training part it",
    "start": "553029",
    "end": "558879"
  },
  {
    "text": "becomes more complex so I have to pick a number of machines I have to install",
    "start": "558879",
    "end": "564339"
  },
  {
    "text": "tensor flow on them and if I'm not using the right api's I actually have to adapt",
    "start": "564339",
    "end": "570339"
  },
  {
    "text": "my coaches that I would actually just encourage everyone stick to there's no new a high-level api's because they'll",
    "start": "570339",
    "end": "577360"
  },
  {
    "text": "automatically be able to distribute your code they'll be automatically they can utilize also TP use if you're running on",
    "start": "577360",
    "end": "584680"
  },
  {
    "text": "Google infrastructure so it kind of abstracts away from where I have to write my own entire cluster set up but",
    "start": "584680",
    "end": "592329"
  },
  {
    "text": "even in that scenario I still have to specify the class respect with those IP addresses for my distributed setup and",
    "start": "592329",
    "end": "600249"
  },
  {
    "text": "then I have to deploy my Python code or however I wrote it onto all files and then I can finally kick off the training",
    "start": "600249",
    "end": "607569"
  },
  {
    "text": "and also like down here in this node setup there are different types of nodes",
    "start": "607569",
    "end": "614679"
  },
  {
    "text": "I might have worker nodes I might have parameter servers so it's a",
    "start": "614679",
    "end": "619809"
  },
  {
    "text": "kind of art of how to set it up efficiently is that I get the best output out of my cluster so and",
    "start": "619809",
    "end": "627870"
  },
  {
    "start": "625000",
    "end": "663000"
  },
  {
    "text": "distribute a job running for days what do we expect they're going to be failures and that can be depending on",
    "start": "627870",
    "end": "635110"
  },
  {
    "text": "the failure type this can be rather annoying as if I have my hard-coded cluster spec with all those IP addresses",
    "start": "635110",
    "end": "640509"
  },
  {
    "text": "I might actually have to restart the job simply because nodes have gone down and",
    "start": "640509",
    "end": "647199"
  },
  {
    "text": "if half the notes are down my performance is gonna be pretty bad this is actually these failures this is",
    "start": "647199",
    "end": "654490"
  },
  {
    "text": "actually true for any distributed system and you should keep that in mind with also the other big data tools we'll be",
    "start": "654490",
    "end": "660790"
  },
  {
    "text": "talking about here was that I would actually hand over to or hand back to",
    "start": "660790",
    "end": "666129"
  },
  {
    "start": "663000",
    "end": "786000"
  },
  {
    "text": "Chris actually who is going to talk about the entire pipeline from start to end yeah so if",
    "start": "666129",
    "end": "673269"
  },
  {
    "text": "you haven't seen or guessed by now we really want to not only get you running",
    "start": "673269",
    "end": "679269"
  },
  {
    "text": "up and running on kubernetes but get you workloads running on kubernetes and a great workload to run on kubernetes is",
    "start": "679269",
    "end": "685630"
  },
  {
    "text": "is tensorflow and there's great tools out there including something that will investigate called cube flow but we want",
    "start": "685630",
    "end": "693160"
  },
  {
    "text": "to all the other sessions i've seen on key flow or tend to flow on kubernetes they often had some magic behind it and",
    "start": "693160",
    "end": "700829"
  },
  {
    "text": "it's some of these external parts that you would have that may be part of a",
    "start": "700829",
    "end": "705940"
  },
  {
    "text": "public cloud or something so I just wanted to go through the entire pipeline so that you could be successful in",
    "start": "705940",
    "end": "711820"
  },
  {
    "text": "setting up from your database all the way to your model serving so in a",
    "start": "711820",
    "end": "717430"
  },
  {
    "text": "typical deep learning pipeline you have your data and streaming this is where your housing your data it could be in",
    "start": "717430",
    "end": "723970"
  },
  {
    "text": "the public cloud or it could be in an open source tool there's several ones that we'll cover today that are extremely popular and",
    "start": "723970",
    "end": "730240"
  },
  {
    "text": "then you have your users so in one of the tools that we'll investigate some of",
    "start": "730240",
    "end": "735760"
  },
  {
    "text": "this is given for you but there's other users preparation type software that you",
    "start": "735760",
    "end": "742209"
  },
  {
    "text": "can use there's also spark which we saw today during the keynote and that's a good way to do data preparation and",
    "start": "742209",
    "end": "749829"
  },
  {
    "text": "we'll have a live demo of that as well some data preparation that we're doing before we ingest it into into the tensor",
    "start": "749829",
    "end": "758139"
  },
  {
    "text": "flow and then we have the frameworks and the clusters so the cluster is obviously",
    "start": "758139",
    "end": "763290"
  },
  {
    "text": "kubernetes that it's landing on and there's many different deep learning frameworks out there and then the models",
    "start": "763290",
    "end": "769149"
  },
  {
    "text": "and the model serving so in kubernetes world there is a tool called cube flow a",
    "start": "769149",
    "end": "775600"
  },
  {
    "text": "few of your hands went up you've used this before this allows you to get kubernetes up and running very easily",
    "start": "775600",
    "end": "782170"
  },
  {
    "text": "I'm sorry tend to flow up and running very easily on kubernetes so what does",
    "start": "782170",
    "end": "787420"
  },
  {
    "start": "786000",
    "end": "827000"
  },
  {
    "text": "it include it automates the distribution of deep learning and so it installs",
    "start": "787420",
    "end": "793440"
  },
  {
    "text": "tensorflow on kubernetes with that it also includes jupiter notebooks it",
    "start": "793440",
    "end": "799990"
  },
  {
    "text": "currently works only on kubernetes if you have other distributed systems it won't work on that but it's open for commits and",
    "start": "799990",
    "end": "807760"
  },
  {
    "text": "then it requires to get it set up requires some knowledge of case on it it",
    "start": "807760",
    "end": "814180"
  },
  {
    "text": "is a tool for packaging and deploying to kubernetes so I you know I'm a marketing",
    "start": "814180",
    "end": "820150"
  },
  {
    "text": "guy and I was able to use it in a day and figure it out so I'm sure the technical audience will have no problem",
    "start": "820150",
    "end": "827550"
  },
  {
    "start": "827000",
    "end": "868000"
  },
  {
    "text": "so that will get you tensorflow on kubernetes so what is the stuff that",
    "start": "827550",
    "end": "832960"
  },
  {
    "text": "I've seen when that I said has been magic when I've seen this demoed before it's often that the data part of this so",
    "start": "832960",
    "end": "841450"
  },
  {
    "text": "connecting your data is obviously one of the most crucial pieces for analyzing any data that you're gonna do there's",
    "start": "841450",
    "end": "848200"
  },
  {
    "text": "open source tools that are available that you could store and stream your data SPARC Kafka MongoDB will do a flink",
    "start": "848200",
    "end": "855220"
  },
  {
    "text": "demo today and then a lot of the demos I've seen use magic manage options in",
    "start": "855220",
    "end": "860860"
  },
  {
    "text": "public cloud as well Google Cloud Storage or something of the like from",
    "start": "860860",
    "end": "866380"
  },
  {
    "text": "the other vendors so in the data",
    "start": "866380",
    "end": "871630"
  },
  {
    "start": "868000",
    "end": "901000"
  },
  {
    "text": "pipeline you saw a few steps when the first step is input data management so",
    "start": "871630",
    "end": "878560"
  },
  {
    "text": "what are the problems there is your was saying you have a large amount of data the availability of the clusters",
    "start": "878560",
    "end": "884500"
  },
  {
    "text": "oftentimes you have a firehose of data coming in more data is coming in all the time the solution are these open source",
    "start": "884500",
    "end": "891970"
  },
  {
    "text": "tools or some public cloud options that are available like HDFS Kafka for stream",
    "start": "891970",
    "end": "897010"
  },
  {
    "text": "and Cassandra for distributed databases",
    "start": "897010",
    "end": "902370"
  },
  {
    "start": "901000",
    "end": "966000"
  },
  {
    "text": "so these are all I would say in the big data market which has been growing since",
    "start": "902370",
    "end": "907810"
  },
  {
    "text": "the first inception and I would say mid 2008 2007 type timeframe and why have",
    "start": "907810",
    "end": "917410"
  },
  {
    "text": "them been growing because we're creating more and more data every day there's also large and existing data streams",
    "start": "917410",
    "end": "924370"
  },
  {
    "text": "that we need to connect to so this is a lot of times you want to use something that you're familiar with when you're",
    "start": "924370",
    "end": "931200"
  },
  {
    "text": "working with 10 to flow you've already used HDFS or you've already use",
    "start": "931200",
    "end": "937060"
  },
  {
    "text": "Kafka and you might not necessarily want to go to one of the public cloud AP is",
    "start": "937060",
    "end": "942490"
  },
  {
    "text": "and their proprietary tools also there's often strict data governance around",
    "start": "942490",
    "end": "948220"
  },
  {
    "text": "especially in European companies I was actually talking to a European company the other day at cube con and as soon as",
    "start": "948220",
    "end": "955389"
  },
  {
    "text": "they analyzed the data with their deep learning tool they actually had to erase it and that's because the the government",
    "start": "955389",
    "end": "961329"
  },
  {
    "text": "actually doesn't allow them to keep around the results because it is customer data so data preparation so if",
    "start": "961329",
    "end": "970750"
  },
  {
    "start": "966000",
    "end": "1007000"
  },
  {
    "text": "you're doing a demo data set it's almost like a hello world it's very easy to do but that's the exception to the rule",
    "start": "970750",
    "end": "976480"
  },
  {
    "text": "oftentimes you have to do a lot of data cleanup the time stamps might be off or",
    "start": "976480",
    "end": "981639"
  },
  {
    "text": "you might be collecting it at different frequencies so you have to match it up there's obviously oftentimes a lot of",
    "start": "981639",
    "end": "988360"
  },
  {
    "text": "junk in data we've all seen it all of us have that that have worked with data before so you need to have tools in",
    "start": "988360",
    "end": "995500"
  },
  {
    "text": "order to clean that up so do some analysis will cover spark and flink today I believe our demo specifically is",
    "start": "995500",
    "end": "1002490"
  },
  {
    "text": "on flink so we'll see doing some of that in in our demo and then model management",
    "start": "1002490",
    "end": "1010309"
  },
  {
    "start": "1007000",
    "end": "1032000"
  },
  {
    "text": "so the ability not just to create the models but actually whole distribute",
    "start": "1010309",
    "end": "1016350"
  },
  {
    "text": "them and actually get them out to your clients and so there's several open",
    "start": "1016350",
    "end": "1021899"
  },
  {
    "text": "source tools for that as well we already covered HDFS MongoDB is another one and this is a it's something that we will",
    "start": "1021899",
    "end": "1030449"
  },
  {
    "text": "demo as well so that's your deep learning pipeline again you have your",
    "start": "1030449",
    "end": "1035668"
  },
  {
    "start": "1032000",
    "end": "1050000"
  },
  {
    "text": "data and streaming your users your frameworks and your models and model",
    "start": "1035669",
    "end": "1040740"
  },
  {
    "text": "serving and what cube flow is doing is helping you with your users your models your models serving and obviously",
    "start": "1040740",
    "end": "1046949"
  },
  {
    "text": "getting tensorflow working on kubernetes so today we'll actually be using and you",
    "start": "1046949",
    "end": "1053130"
  },
  {
    "start": "1050000",
    "end": "1156000"
  },
  {
    "text": "can use public cloud to get the data obviously as well we'll be using mesos to get some of these open source",
    "start": "1053130",
    "end": "1059159"
  },
  {
    "text": "frameworks that we talked about like flink and HDFS meses has a long history of working with these big data",
    "start": "1059159",
    "end": "1066000"
  },
  {
    "text": "frameworks in very large environments thousands of No and mission-critical type organizations",
    "start": "1066000",
    "end": "1072770"
  },
  {
    "text": "and so what missus does is though almost treats your infrastructure like",
    "start": "1072770",
    "end": "1079670"
  },
  {
    "text": "kubernetes treats pods so you could say I want this amount of infrastructure and it gets it up and running and then if",
    "start": "1079670",
    "end": "1085910"
  },
  {
    "text": "some of the infrastructure goes down it actually in a declarative model checks oh the desired state does not match the",
    "start": "1085910",
    "end": "1091610"
  },
  {
    "text": "reality of the state of what I want I don't have enough kubernetes worker nodes for instance and it could easily",
    "start": "1091610",
    "end": "1097360"
  },
  {
    "text": "replicate and spin up another Cooper Nettie's worker node and so there's a lot of cumin container management",
    "start": "1097360",
    "end": "1103430"
  },
  {
    "text": "solutions that work on on mesos kubernetes is one of them marathons another is one that has been released",
    "start": "1103430",
    "end": "1108920"
  },
  {
    "text": "two weeks ago by titus I'm sorry by Netflix called Titus and I actually use mesos to spin up 200,000 clusters of",
    "start": "1108920",
    "end": "1116000"
  },
  {
    "text": "titus per day I have no idea why they need 200,000 orchestration clusters per",
    "start": "1116000",
    "end": "1121790"
  },
  {
    "text": "day but that's what they said that they do so with the Misses architecture the",
    "start": "1121790",
    "end": "1127130"
  },
  {
    "text": "way that it works is that we have an agent on each one of these nodes and they're offering resources to all these",
    "start": "1127130",
    "end": "1133700"
  },
  {
    "text": "different schedules who have their own way of doing things so kubernetes scheduler is you know scheduling pods in",
    "start": "1133700",
    "end": "1140240"
  },
  {
    "text": "one way then SPARC schedulers doing it in another and in Kochba is doing in another so they're asking for resources",
    "start": "1140240",
    "end": "1145790"
  },
  {
    "text": "and the massive scheduler says oh okay this is kubernetes needs six worker nodes so it gives it the amount of CPU",
    "start": "1145790",
    "end": "1153290"
  },
  {
    "text": "and memory that it needs and with that devil",
    "start": "1153290",
    "end": "1159140"
  },
  {
    "start": "1156000",
    "end": "1220000"
  },
  {
    "text": "can I just maybe at like one more sentence here so as you mentioned like missus is treating all those systems",
    "start": "1159140",
    "end": "1165020"
  },
  {
    "text": "like kubernetes is treating your pods so this is why it's just like two-level",
    "start": "1165020",
    "end": "1170390"
  },
  {
    "text": "scheduling so Maysles is kind of easier scheduling missus only cares about resources but then the way in which",
    "start": "1170390",
    "end": "1176210"
  },
  {
    "text": "different systems like human at ease like HDFS need to treat tasks there's",
    "start": "1176210",
    "end": "1182930"
  },
  {
    "text": "actually a second level and this is very application specific so as you mentioned HDFS needs a totally different treatment",
    "start": "1182930",
    "end": "1189680"
  },
  {
    "text": "and this is first of all when deploying it but more importantly when they're actually failure scenarios if a pot and",
    "start": "1189680",
    "end": "1196760"
  },
  {
    "text": "your next pot fails I'll simply reschedule that and I don't necessarily care where but if my HDFS data no",
    "start": "1196760",
    "end": "1203549"
  },
  {
    "text": "failing or if both my HDFS name notes are gone I actually needed more complex",
    "start": "1203549",
    "end": "1208559"
  },
  {
    "text": "a recovery step and so this is kind of what's those schedulers if you want to",
    "start": "1208559",
    "end": "1214409"
  },
  {
    "text": "compare them to operators like operators for distributed systems are pretty good at all right we see demo so when being",
    "start": "1214409",
    "end": "1224389"
  },
  {
    "text": "on the cloud and this is actually where cube flow I really like it is when I'm running for example on Google",
    "start": "1224389",
    "end": "1230850"
  },
  {
    "text": "infrastructure so when running on Google infrastructure I have actually managed spark I can use for data cleansing data",
    "start": "1230850",
    "end": "1238440"
  },
  {
    "text": "preparation and so that might read from cloud storage it will read my date her",
    "start": "1238440",
    "end": "1243929"
  },
  {
    "text": "and it will just might write it back into the cloud storage here then I can",
    "start": "1243929",
    "end": "1249119"
  },
  {
    "text": "use my typical cue flow workflow so I'll spin up a Jupiter notebook I then",
    "start": "1249119",
    "end": "1255379"
  },
  {
    "text": "explore my data I will train my model using tenza flow I can use tensor boards",
    "start": "1255379",
    "end": "1261330"
  },
  {
    "text": "to actually monitor the progress I can use TFT Bach 2d debugging and then",
    "start": "1261330",
    "end": "1267799"
  },
  {
    "text": "there's actually there you've got like two options in queue flow itself for serving so I then can surf my models and",
    "start": "1267799",
    "end": "1276529"
  },
  {
    "text": "so once I have my model serving up they're actually in the way of hitting a tryst request so there are also",
    "start": "1276529",
    "end": "1282869"
  },
  {
    "text": "different streaming solutions in those cloud settings now the question is just what happens if I'm not in one of those",
    "start": "1282869",
    "end": "1289799"
  },
  {
    "text": "cloud settings what can I do so if we",
    "start": "1289799",
    "end": "1295289"
  },
  {
    "start": "1293000",
    "end": "1379000"
  },
  {
    "text": "are open source and also if we want to be independent of those cloud tools the",
    "start": "1295289",
    "end": "1301830"
  },
  {
    "text": "typical solutions I see out there are spark for a data cleansing so spark I typically see that if have like batch",
    "start": "1301830",
    "end": "1309600"
  },
  {
    "text": "workloads so if I already have my data stored in HDFS and then I just flows",
    "start": "1309600",
    "end": "1314820"
  },
  {
    "text": "through it and HDFS it's a very scalable storage and then for streaming Kafka a",
    "start": "1314820",
    "end": "1324869"
  },
  {
    "text": "very good solution for is actually streaming the request and then hitting my attend surf low serving there's",
    "start": "1324869",
    "end": "1330690"
  },
  {
    "text": "actually something has anyone heard of C rendezvous architecture",
    "start": "1330690",
    "end": "1336770"
  },
  {
    "text": "yeah so this is actually by Ted Dunning",
    "start": "1336770",
    "end": "1342150"
  },
  {
    "text": "from a mapper and this is actually heavily relying on kafka boughs for",
    "start": "1342150",
    "end": "1348049"
  },
  {
    "text": "hitting different serving end points so the question is what do I do if I have different models and I don't actually",
    "start": "1348049",
    "end": "1354240"
  },
  {
    "text": "know which one gives me the best result because this training process is mentioned it's iteratively so I end up",
    "start": "1354240",
    "end": "1360450"
  },
  {
    "text": "with like many hundreds of models and as I need to pick which ones are best so",
    "start": "1360450",
    "end": "1366750"
  },
  {
    "text": "the idea is kind of to take multiple models at the same time here for kafka stream serving the request and another",
    "start": "1366750",
    "end": "1373470"
  },
  {
    "text": "kafka stream actually collecting the results and then I decide which of those results I want to use so this down here",
    "start": "1373470",
    "end": "1381870"
  },
  {
    "start": "1379000",
    "end": "1416000"
  },
  {
    "text": "this is basically cue flow and it's very powerful and very helpful and everything",
    "start": "1381870",
    "end": "1388919"
  },
  {
    "text": "on top this is then up to you what you want to use depending on your infrastructure if you are an AWS you can",
    "start": "1388919",
    "end": "1396210"
  },
  {
    "text": "use the AWS tools if you're in Google you can use the Google tools if you're on Prem you actually you need to come up",
    "start": "1396210",
    "end": "1402630"
  },
  {
    "text": "with alternative solutions so this is kind of the open source version of this which might even if you consider even",
    "start": "1402630",
    "end": "1410429"
  },
  {
    "text": "though you're running in the cloud it might be a good choice simply because you're not tied to particular cloud",
    "start": "1410429",
    "end": "1415980"
  },
  {
    "text": "vendor and yeah this brings us to the demo and for this demo I said there are",
    "start": "1415980",
    "end": "1422760"
  },
  {
    "start": "1416000",
    "end": "1500000"
  },
  {
    "text": "many many options but as we are working on Miso's and TCS we kind of choose that",
    "start": "1422760",
    "end": "1428400"
  },
  {
    "text": "for that so how much time do I have left five minutes with questions okay so here",
    "start": "1428400",
    "end": "1436740"
  },
  {
    "text": "we actually we have a cluster where like all those tools running in on AWS in",
    "start": "1436740",
    "end": "1442169"
  },
  {
    "text": "this case but this can also be an on-prem so I actually have a system where I have kubernetes running this is",
    "start": "1442169",
    "end": "1448919"
  },
  {
    "text": "pure kubernetes and if we look at that I already deployed a cute flow on it as",
    "start": "1448919",
    "end": "1454799"
  },
  {
    "text": "it takes a while it's in another namespace but this is just the open-source kubernetes queue flow so",
    "start": "1454799",
    "end": "1465090"
  },
  {
    "text": "here I can see this is my default very simple it's a getting started",
    "start": "1465090",
    "end": "1470279"
  },
  {
    "text": "acute flu example which I deployed here and it's not so bad which case on it and",
    "start": "1470279",
    "end": "1477359"
  },
  {
    "text": "then we have HDFS which is holding a some of our input data we have captive",
    "start": "1477359",
    "end": "1483029"
  },
  {
    "text": "streaming flink for also data cleansing so so actually there let me just switch",
    "start": "1483029",
    "end": "1490859"
  },
  {
    "text": "back to the slides from one second so if",
    "start": "1490859",
    "end": "1496289"
  },
  {
    "text": "you recall this picture here SPARC is really great if I have like a batch",
    "start": "1496289",
    "end": "1502379"
  },
  {
    "start": "1500000",
    "end": "1698000"
  },
  {
    "text": "processing so if I have my data on HDFS and then I run a batch job I cleanse it",
    "start": "1502379",
    "end": "1509099"
  },
  {
    "text": "and prepare it for my workflow but often I even have like a stream of data coming",
    "start": "1509099",
    "end": "1514739"
  },
  {
    "text": "in so if I have this event stream coming in and then I want to store this data what I also seen people do is they",
    "start": "1514739",
    "end": "1521729"
  },
  {
    "text": "really use like a streaming system spark could do that as well but flink is my",
    "start": "1521729",
    "end": "1527070"
  },
  {
    "text": "personal favorite there but personal choice so they actually use flink and",
    "start": "1527070",
    "end": "1532289"
  },
  {
    "text": "they pre-process the data and then they actually write it into HDFS here okay so",
    "start": "1532289",
    "end": "1540229"
  },
  {
    "text": "having that set what what I would do now I would actually just deploy a spark job",
    "start": "1540229",
    "end": "1546749"
  },
  {
    "text": "to cleanse my data so it would will read from HDFS and right back to HDFS and I",
    "start": "1546749",
    "end": "1554039"
  },
  {
    "text": "have my cheat sheet here so I'll explain",
    "start": "1554039",
    "end": "1559979"
  },
  {
    "text": "that in a second",
    "start": "1559979",
    "end": "1563269"
  },
  {
    "text": "didn't you install the spark CLI no I did not",
    "start": "1568959",
    "end": "1574399"
  },
  {
    "text": "all right then I just need to just need to do that on the fly and sorry it just takes one second I asked him before",
    "start": "1574399",
    "end": "1582049"
  },
  {
    "text": "oh I installed the kubernetes CLI de so it's just a CLI extension for kind of C",
    "start": "1582049",
    "end": "1589190"
  },
  {
    "text": "cube cuttle for 4d cos for missiles and",
    "start": "1589190",
    "end": "1594259"
  },
  {
    "text": "this is installing right now and here we can now submit a spark job it's only as long as I as I used a gist to store it",
    "start": "1594259",
    "end": "1604940"
  },
  {
    "text": "I said worse didn't want to create a full domain for that so okay we",
    "start": "1604940",
    "end": "1610359"
  },
  {
    "text": "submitted our job so if we now have a look at the spark UI we should be able",
    "start": "1610359",
    "end": "1615679"
  },
  {
    "text": "to see that hopefully our data cleansing job has been running successfully so",
    "start": "1615679",
    "end": "1621559"
  },
  {
    "text": "it's still launching so those of you who know how spark works it's launching our",
    "start": "1621559",
    "end": "1626719"
  },
  {
    "text": "driver here and still processing our data but we'll just leave that open and",
    "start": "1626719",
    "end": "1634039"
  },
  {
    "text": "continue with our demo so far next step",
    "start": "1634039",
    "end": "1639950"
  },
  {
    "text": "is we actually we want to access as the default cube flow and for that it's our",
    "start": "1639950",
    "end": "1645679"
  },
  {
    "text": "nice port forwarding done I think I only",
    "start": "1645679",
    "end": "1653629"
  },
  {
    "text": "need this",
    "start": "1653629",
    "end": "1656229"
  },
  {
    "text": "good",
    "start": "1663800",
    "end": "1666430"
  },
  {
    "text": "and here we come up with like our Jupiter hop how many of you know Jupiter",
    "start": "1676140",
    "end": "1683640"
  },
  {
    "text": "hop so so Jupiter notebooks as Chris mentioned earlier they are like a great",
    "start": "1683640",
    "end": "1689250"
  },
  {
    "text": "way for data scientists to kind of explore their data sets I mean if I'm a",
    "start": "1689250",
    "end": "1695970"
  },
  {
    "text": "data scientist I want like an easy-to-use interface and Jupiter hop is",
    "start": "1695970",
    "end": "1701280"
  },
  {
    "start": "1698000",
    "end": "1792000"
  },
  {
    "text": "a way of easily spawning so Jupiter notebooks and here we go",
    "start": "1701280",
    "end": "1706790"
  },
  {
    "text": "and so I already spawned one like spawning a Jupiter notebook it's a huge docker image I think it's",
    "start": "1706790",
    "end": "1713580"
  },
  {
    "text": "like a 10 gigabyte darker image so it takes a while so this is why I actually launched one upfront but we can easily",
    "start": "1713580",
    "end": "1720120"
  },
  {
    "text": "launch if I log in with another user from Jupiter hop you can launch as many as you would like so in here I want a",
    "start": "1720120",
    "end": "1729390"
  },
  {
    "text": "new PI sensory context great so this is",
    "start": "1729390",
    "end": "1736530"
  },
  {
    "text": "what Jupiter is about I simply get this easy shell and there I can now execute",
    "start": "1736530",
    "end": "1742850"
  },
  {
    "text": "attempts a flow program basically and",
    "start": "1742850",
    "end": "1748910"
  },
  {
    "text": "I've one here",
    "start": "1748910",
    "end": "1752930"
  },
  {
    "text": "so this is the default amnesty example and what it does it actually downloads",
    "start": "1762230",
    "end": "1767780"
  },
  {
    "text": "the dataset from from the internet it's like the default tensorflow one but",
    "start": "1767780",
    "end": "1773450"
  },
  {
    "text": "we'll change that in a second or depending on how much time there is left five minutes with questions we can",
    "start": "1773450",
    "end": "1780470"
  },
  {
    "text": "easily change that to also move it somewhere else and so executing this now",
    "start": "1780470",
    "end": "1789490"
  },
  {
    "text": "so this takes a while to run and yeah those warnings are accuracy example but",
    "start": "1789520",
    "end": "1795470"
  },
  {
    "start": "1792000",
    "end": "2108000"
  },
  {
    "text": "it's the official example I wanted to stick to the official queue for example it's using a deprecated you eyes but",
    "start": "1795470",
    "end": "1802520"
  },
  {
    "text": "don't be alarmed by this it's just at a precaution warnings and one thing why I",
    "start": "1802520",
    "end": "1809390"
  },
  {
    "text": "personally we've been talking about tensorflow quite a lot but actually there are other tools which makes this",
    "start": "1809390",
    "end": "1817130"
  },
  {
    "text": "easier so one thing which is a little annoying for me with tensorflow up until very recently is like the",
    "start": "1817130",
    "end": "1824090"
  },
  {
    "text": "sessions run so what tensorflow does I actually I built a very static compute graph and",
    "start": "1824090",
    "end": "1829100"
  },
  {
    "text": "then I run this compute graph over and over again in the 1.7 versions they",
    "start": "1829100",
    "end": "1834740"
  },
  {
    "text": "introduced eager execution and other tools for example pi torch I really like",
    "start": "1834740",
    "end": "1839870"
  },
  {
    "text": "that as a feature of Pi Church they actually allow me to do that on the fly so I can actually computer get my my",
    "start": "1839870",
    "end": "1847730"
  },
  {
    "text": "entire define my entire graph on the fly which means I can also output after each",
    "start": "1847730",
    "end": "1854840"
  },
  {
    "text": "step and I can debug after each step and yeah it ran we have an okayish for this",
    "start": "1854840",
    "end": "1862190"
  },
  {
    "text": "number of iterations output accuracy and",
    "start": "1862190",
    "end": "1869540"
  },
  {
    "text": "now this takes a bit longer so I now I",
    "start": "1869540",
    "end": "1875060"
  },
  {
    "text": "can basically switch in switch in my HDFS back-end and this is very important",
    "start": "1875060",
    "end": "1881870"
  },
  {
    "text": "for it tend to flow for multiple reasons so there are actually three spots in this program why I might want to have",
    "start": "1881870",
    "end": "1889160"
  },
  {
    "text": "set and first of all it's for import so what we do here this is a very small",
    "start": "1889160",
    "end": "1894320"
  },
  {
    "text": "data set which has been downloaded in choose the darker image running Jupiter here but if I'm going at more scale I",
    "start": "1894320",
    "end": "1901310"
  },
  {
    "text": "actually I'd probably want to resit from HDFS in my cluster the second thing is",
    "start": "1901310",
    "end": "1906800"
  },
  {
    "text": "sends the model which are output and I write somewhere and these searching and",
    "start": "1906800",
    "end": "1912350"
  },
  {
    "text": "most important probably or others are also important but also very important",
    "start": "1912350",
    "end": "1918320"
  },
  {
    "text": "thing is the metadata so how many of you have used tensor board so tensor board",
    "start": "1918320",
    "end": "1925670"
  },
  {
    "text": "it needs somewhere from where to read those checkpoint files and they're HDFS",
    "start": "1925670",
    "end": "1932150"
  },
  {
    "text": "is a great option so just when I need some kind of distributed file system",
    "start": "1932150",
    "end": "1937310"
  },
  {
    "text": "where while this job is running it can actually write those metadata checkpoints and then from where tensor",
    "start": "1937310",
    "end": "1942890"
  },
  {
    "text": "board can read them and later on also other tools can read this metadata to visualize that as we only have two",
    "start": "1942890",
    "end": "1952790"
  },
  {
    "text": "minutes left I would actually go over to questions I'll be around and I'm happy so the next step is basically we exports",
    "start": "1952790",
    "end": "1959930"
  },
  {
    "text": "it to HTS we look at HDFS where it's stored and we you see data we previously",
    "start": "1959930",
    "end": "1966070"
  },
  {
    "text": "cleansed with a spark job yeah and the slides will be online if you look under",
    "start": "1966070",
    "end": "1971090"
  },
  {
    "text": "the talk I believe they're there and all the steps are in there everything that you saw is all open source so if you",
    "start": "1971090",
    "end": "1978050"
  },
  {
    "text": "want to go and do it yourself we could probably put these commands in there we don't have them right now but that",
    "start": "1978050",
    "end": "1983660"
  },
  {
    "text": "should be simple to do I'll put them in the deck after I'm done so are there any questions on getting tend to flow up and",
    "start": "1983660",
    "end": "1991040"
  },
  {
    "text": "running and kubernetes any of the open source tools that we saw yes",
    "start": "1991040",
    "end": "1996820"
  },
  {
    "text": "[Music]",
    "start": "1999760",
    "end": "2002809"
  },
  {
    "text": "ya know so yeah yeah so we stick with",
    "start": "2008309",
    "end": "2016809"
  },
  {
    "text": "Jupiter for today because that's what you get from yeah okay",
    "start": "2016809",
    "end": "2022600"
  },
  {
    "text": "so for production or the workflow I typically see is is you go in your data",
    "start": "2022600",
    "end": "2029769"
  },
  {
    "text": "scientists actually train that they explore so Jupiter for me it's more of",
    "start": "2029769",
    "end": "2035289"
  },
  {
    "text": "like for exploring data and getting a feel for the model but once you have sent a production scenario you should",
    "start": "2035289",
    "end": "2041470"
  },
  {
    "text": "also have this definition this pison file this should be somewhere versioned in github or whatever artifactory",
    "start": "2041470",
    "end": "2049388"
  },
  {
    "text": "version storage you have and then you're then you're actually a firing off that",
    "start": "2049389",
    "end": "2054878"
  },
  {
    "text": "job against the cluster so also this example you can get their tricks in",
    "start": "2054879",
    "end": "2062079"
  },
  {
    "text": "which you can get Jupiter against a distributed cluster in this scenario is actually just using the resources inside",
    "start": "2062079",
    "end": "2068079"
  },
  {
    "text": "the container you can't connect it against an external cluster but like for the large-scale learning you actually",
    "start": "2068079",
    "end": "2073690"
  },
  {
    "text": "you want more so if you go back to this pipeline like this user is just like the initial and analytics but then once we",
    "start": "2073690",
    "end": "2081579"
  },
  {
    "text": "had to framework in cluster level you actually you wouldn't typically you wouldn't launch that from Jupiter",
    "start": "2081579",
    "end": "2087339"
  },
  {
    "text": "directly yes so that's the last question I think I'll taken and sorry we were",
    "start": "2087339",
    "end": "2093849"
  },
  {
    "text": "just at a time I think will be up here and then we could take questions up here and we'll be around for the next ten",
    "start": "2093849",
    "end": "2099460"
  },
  {
    "text": "minutes and then if we go over go into the hallway and take questions out there right I think we're out of time right",
    "start": "2099460",
    "end": "2105339"
  },
  {
    "text": "yeah thank you",
    "start": "2105339",
    "end": "2108630"
  }
]
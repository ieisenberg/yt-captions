[
  {
    "text": "hello hi guys how are you good happy to come back at cubecon",
    "start": "719",
    "end": "8400"
  },
  {
    "text": "who's your first time here maybe you can raise your hand oh really",
    "start": "8400",
    "end": "14000"
  },
  {
    "text": "oh man that's great that's great in the meanwhile they bring all the audio stuff so we're going to do some",
    "start": "14000",
    "end": "21119"
  },
  {
    "text": "quick in conversation so well first of all welcome i think that kubecon is one of",
    "start": "21119",
    "end": "27039"
  },
  {
    "text": "the best conference around not because of just kubernetes because of technology and and community",
    "start": "27039",
    "end": "33440"
  },
  {
    "text": "so yeah really happy to hear that this is the first time that everybody raised the hand yeah that's awesome",
    "start": "33440",
    "end": "39920"
  },
  {
    "text": "okay okay maybe some question who's a fluency",
    "start": "40559",
    "end": "45840"
  },
  {
    "text": "or fluent bet user already okay",
    "start": "45840",
    "end": "51039"
  },
  {
    "text": "now who's interested in metrics okay there you have",
    "start": "51039",
    "end": "58198"
  },
  {
    "text": "yeah let's get started is this working too yeah oh awesome okay",
    "start": "70799",
    "end": "77040"
  },
  {
    "text": "so yeah hey everyone my name is honorag i'm one of the co-founders maintainers fluent d flint bit project and of course",
    "start": "77040",
    "end": "83040"
  },
  {
    "text": "we have eduardo creator of the flintfit project as well so yeah really when we start looking at",
    "start": "83040",
    "end": "90640"
  },
  {
    "text": "fluent bit and fluentd the way we've begun to think about these projects is really a swiss army knife",
    "start": "90640",
    "end": "97920"
  },
  {
    "text": "for observability how do we look at all this data start slicing and dicing it making it very accessible",
    "start": "97920",
    "end": "105119"
  },
  {
    "text": "as part of the ecosystem and how these projects start to fit together kind of",
    "start": "105119",
    "end": "110240"
  },
  {
    "text": "in the in the broader set of the ecosystem right many folks first time at cubecon so many projects going around",
    "start": "110240",
    "end": "116079"
  },
  {
    "text": "how do we look at this ecosystem at a little bit of a broader level",
    "start": "116079",
    "end": "121920"
  },
  {
    "text": "so one of the important things is like a when you are thinking about",
    "start": "122399",
    "end": "127439"
  },
  {
    "text": "observability in general it's because you want to analyze",
    "start": "127439",
    "end": "132640"
  },
  {
    "text": "you know your application how this stuff is working right at the end of the day managing",
    "start": "132640",
    "end": "138239"
  },
  {
    "text": "infrastructure or managing the services that run behind the scenes you don't want to be worried about that",
    "start": "138239",
    "end": "144400"
  },
  {
    "text": "right it's like if you're using a linux system you don't want to know how glfc is working right you just want to make sure",
    "start": "144400",
    "end": "151120"
  },
  {
    "text": "that the application is running it's getting the right resources memory allocation everything",
    "start": "151120",
    "end": "156879"
  },
  {
    "text": "and if we go to a higher level from observability your final goal always will be how do i analyze my data right",
    "start": "156879",
    "end": "164480"
  },
  {
    "text": "but in order to analyze your data you need to get the data first right in a central",
    "start": "164480",
    "end": "169840"
  },
  {
    "text": "place most of the time and this data that you get come from different sources and from different",
    "start": "169840",
    "end": "175280"
  },
  {
    "text": "kind of natures right you can think about logs you can think about metrics and you can think",
    "start": "175280",
    "end": "180800"
  },
  {
    "text": "about traces i i i guess that most of you already",
    "start": "180800",
    "end": "186239"
  },
  {
    "text": "working in in some companies and i'm pretty sure that 99 of you will",
    "start": "186239",
    "end": "191440"
  },
  {
    "text": "say we don't have just one solution for everything right you just don't have a",
    "start": "191440",
    "end": "197280"
  },
  {
    "text": "mysql maybe you also have positive sql you have readies and your architectures always grows they always evolve and all",
    "start": "197280",
    "end": "204959"
  },
  {
    "text": "this transition there are always more components being added and at some point it's and from a",
    "start": "204959",
    "end": "210640"
  },
  {
    "text": "development perspective the same thing happens you will get some applications written in java some others in node.js",
    "start": "210640",
    "end": "216159"
  },
  {
    "text": "with javascript so you face this problem that we have different natures or different origins",
    "start": "216159",
    "end": "222480"
  },
  {
    "text": "and in our case observability different source of information and a at some point you will you will",
    "start": "222480",
    "end": "229360"
  },
  {
    "text": "find that you are instrumental with primitives maybe you're using fluency you're using fluent bit but the goal is always the",
    "start": "229360",
    "end": "236640"
  },
  {
    "text": "same how do i analyze my data but you have to fix the first problem",
    "start": "236640",
    "end": "241680"
  },
  {
    "text": "so we try to see that a and communicate that the fluent ecosystem as the name",
    "start": "241680",
    "end": "246879"
  },
  {
    "text": "say is fluent it aims not to compete with other projects even from an agent",
    "start": "246879",
    "end": "252959"
  },
  {
    "text": "perspective or company perspective we don't try to compete to be a drop",
    "start": "252959",
    "end": "258239"
  },
  {
    "text": "in replacement we try just to be a solution that can be integrated in your architecture in your",
    "start": "258239",
    "end": "265280"
  },
  {
    "text": "own environment so no matter what you're running your applications no matter what",
    "start": "265280",
    "end": "270560"
  },
  {
    "text": "you're using for instrumentation and the instrumentation at the end you can use fluent to connect different ecosystems",
    "start": "270560",
    "end": "277360"
  },
  {
    "text": "so and and our ecosystem has a really interesting thing the first one well",
    "start": "277360",
    "end": "282960"
  },
  {
    "text": "everybody knows that it's all fully open source but one of the things that you might not realize and you might are",
    "start": "282960",
    "end": "289759"
  },
  {
    "text": "facing this in the enterprise is that sometimes exist with the concept of vendor lock-in because since your goal",
    "start": "289759",
    "end": "295919"
  },
  {
    "text": "is to do analysis makes sense you're going to say oh i'm going to invest in splunk elastic open search",
    "start": "295919",
    "end": "302080"
  },
  {
    "text": "and then they will tell you these are the tools that you need to do all this data collection",
    "start": "302080",
    "end": "307680"
  },
  {
    "text": "right but some of them are not real are open source",
    "start": "307680",
    "end": "313199"
  },
  {
    "text": "but they will tell you okay if you use this you get married to this technology to this stack that is a vendor looking",
    "start": "313199",
    "end": "321120"
  },
  {
    "text": "because after one year when you went to switch it will be a huge pain what about if now you think oh there's a",
    "start": "321120",
    "end": "327280"
  },
  {
    "text": "new fancy database that i want to use right what would be the solution oh you",
    "start": "327280",
    "end": "332560"
  },
  {
    "text": "just no need to replace the database you also have to replace all your agents and that becomes a problem",
    "start": "332560",
    "end": "339600"
  },
  {
    "text": "the fluent ecosystem tried to be to avoid this vendor looking for you and",
    "start": "339600",
    "end": "344880"
  },
  {
    "text": "as i said a couple of times we are agnostic no matter what is the product",
    "start": "344880",
    "end": "350160"
  },
  {
    "text": "no matter what is the project or the ecosystem or the tool inside the same cncf stack we try to be compatible with",
    "start": "350160",
    "end": "357600"
  },
  {
    "text": "all the standards and in the fluent ecosystem well if you are",
    "start": "357600",
    "end": "362800"
  },
  {
    "text": "using it i think that is extra information who use fluent bet nowadays its standards influence amazon",
    "start": "362800",
    "end": "369919"
  },
  {
    "text": "google microsoft azure when cloud providers choose something is because it's",
    "start": "369919",
    "end": "376240"
  },
  {
    "text": "production great and now a quick recap of the past present and future of the fluent deep",
    "start": "376240",
    "end": "382400"
  },
  {
    "text": "project and ecosystem that we have you know everything started with fluentd almost 11 years ago a solution to",
    "start": "382400",
    "end": "388639"
  },
  {
    "text": "collect logs for our x company to send all the data to the cloud we made it open source and this break succeeded the",
    "start": "388639",
    "end": "395680"
  },
  {
    "text": "people built around a thousand plugins it's a huge ecosystem right but it was not just ready uh for",
    "start": "395680",
    "end": "402960"
  },
  {
    "text": "the cloud environments right because fluent is really in ruby is more heavy so when you go to deploy this and 100 or",
    "start": "402960",
    "end": "409759"
  },
  {
    "text": "thousands of machines right you know using 200 megabytes of memory or 400 it's really expensive and cpu",
    "start": "409759",
    "end": "417599"
  },
  {
    "text": "intensive in general at the same time we started doing some innovation we come up with the next",
    "start": "417599",
    "end": "422800"
  },
  {
    "text": "generation of tool which was fluent part of the same family but reading in c",
    "start": "422800",
    "end": "428160"
  },
  {
    "text": "optimizer for performance and making sure that it was a really good solution for",
    "start": "428160",
    "end": "433280"
  },
  {
    "text": "everybody but our same philosophy philosophy we didn't want to have a drop-in replacement right we said that",
    "start": "433280",
    "end": "439199"
  },
  {
    "text": "fluent bed is going to integrate with fluency or you can use them separately or just independently",
    "start": "439199",
    "end": "446000"
  },
  {
    "text": "and now one of the trends that we have is that well since the cloud providers migrated",
    "start": "446000",
    "end": "451520"
  },
  {
    "text": "from fluency to fluent bits like the default de facto standard most of users are following the same pattern and i",
    "start": "451520",
    "end": "458880"
  },
  {
    "text": "would say that nowadays user does not need a thousand plugins most of you might creating your own",
    "start": "458880",
    "end": "465360"
  },
  {
    "text": "microservices your own application and you are just instrumenting by using or sending the data to a custom",
    "start": "465360",
    "end": "471520"
  },
  {
    "text": "http endpoint for example fluentd supports like a thousand plugins connecting between connectors source",
    "start": "471520",
    "end": "477680"
  },
  {
    "text": "destinations in a fluent bed we support a hundred but as of now i think we",
    "start": "477680",
    "end": "482800"
  },
  {
    "text": "cannot get any more requirements right we support splunk elastic open search http and many others",
    "start": "482800",
    "end": "490560"
  },
  {
    "text": "and the highlights of production rate high performance when you run an agent and you see that this agent",
    "start": "490560",
    "end": "496400"
  },
  {
    "text": "doing nothing is using 600 kilobytes of memory means something right",
    "start": "496400",
    "end": "502879"
  },
  {
    "text": "of course when you get more data you start processing data you need more memory to handle all that load",
    "start": "502879",
    "end": "508479"
  },
  {
    "text": "and we always try to have to be very low resource consumption you can write a tool that can process",
    "start": "508479",
    "end": "515200"
  },
  {
    "text": "millions of messages per second right but maybe you need a cluster of",
    "start": "515200",
    "end": "520640"
  },
  {
    "text": "five machines to process that right so we always try to optimize for performance and see how much how far we",
    "start": "520640",
    "end": "526480"
  },
  {
    "text": "can go with fluent bet and we have demonstrated that in the last year we pretty much",
    "start": "526480",
    "end": "531680"
  },
  {
    "text": "started doing 4x or 5x times in performance improvements by doing threading optimizing the core memory",
    "start": "531680",
    "end": "538080"
  },
  {
    "text": "allocations and so on and how you can use fluid there's a couple of distributions",
    "start": "538080",
    "end": "544560"
  },
  {
    "text": "of course the the upstream version is that what most people use you can get it from docker hub you can",
    "start": "544560",
    "end": "550160"
  },
  {
    "text": "get your packages for ubuntu sent to us we have aws that they have their own",
    "start": "550160",
    "end": "555200"
  },
  {
    "text": "distribution of fluent bed which is similar upstream but the difference that they they optimize for their own",
    "start": "555200",
    "end": "561760"
  },
  {
    "text": "amazon services connectors so they provide different connectors it's more friendly so if you're running",
    "start": "561760",
    "end": "567440"
  },
  {
    "text": "on aws and you're a customer yeah you can use that one caliptia the company that we",
    "start": "567440",
    "end": "574880"
  },
  {
    "text": "funded with anurag which is on top of the fluent ecosystem we have our own fluent bit distribution too",
    "start": "574880",
    "end": "581279"
  },
  {
    "text": "but this is mostly tied for as an lts version right enterprise ready so if",
    "start": "581279",
    "end": "586399"
  },
  {
    "text": "you're going to run a fluent bed and you want to make sure that there's no breaking change for the next 18 months",
    "start": "586399",
    "end": "592480"
  },
  {
    "text": "you can use a kalitia for fluent bet and google ops agent google created this",
    "start": "592480",
    "end": "598800"
  },
  {
    "text": "own agent for their own customers that has two components has fluent bet for all the lock management and they have a",
    "start": "598800",
    "end": "605920"
  },
  {
    "text": "small open telemetry agent for metrics and traces so they ship this for their own customers so if you're a google customer",
    "start": "605920",
    "end": "612880"
  },
  {
    "text": "you can use google ops agent but at the end of the day you can do the same with the upstream version",
    "start": "612880",
    "end": "618959"
  },
  {
    "text": "right so we're not trying to post what to use just go with upstream and then if you need something more specific yeah",
    "start": "618959",
    "end": "625279"
  },
  {
    "text": "it's like i do use vanilla kubernetes do i use openshift you know it's a matter",
    "start": "625279",
    "end": "631440"
  },
  {
    "text": "of personal decision and yeah this is fluent uh we aim to",
    "start": "631440",
    "end": "637279"
  },
  {
    "text": "collect data from different sources and send that data to multiple destinations we do buffering retry logic",
    "start": "637279",
    "end": "643839"
  },
  {
    "text": "we back up in the file system in a very optimized set a way now as a community based fluent bit has",
    "start": "643839",
    "end": "651279"
  },
  {
    "text": "been deployed and cncf and all this like one more more than one billion times in total",
    "start": "651279",
    "end": "658320"
  },
  {
    "text": "right and we didn't put the fraction here but this is about order of millions right so last year we pretty much 600",
    "start": "658320",
    "end": "665920"
  },
  {
    "text": "millions and you can see how the number of deployments today this year is going so this is just insane and this is",
    "start": "665920",
    "end": "672720"
  },
  {
    "text": "thanks to the community and people who's here and actually most of the features that you see in fluent bed in fluentd is",
    "start": "672720",
    "end": "678320"
  },
  {
    "text": "because of the feedback that you provide after these sessions in the conference everything kubernetes filter lua",
    "start": "678320",
    "end": "685680"
  },
  {
    "text": "scripting and i don't know elasticsearch open search all of that so don't think that you're",
    "start": "685680",
    "end": "692240"
  },
  {
    "text": "going to just consume information here you can also help us to build the roadmap of what will be the future of",
    "start": "692240",
    "end": "698720"
  },
  {
    "text": "the project and that's really important so um",
    "start": "698720",
    "end": "704160"
  },
  {
    "text": "investments everybody cares about oh this is a program reading in c right memory safety is an issue what about",
    "start": "704160",
    "end": "710320"
  },
  {
    "text": "languages it's a common topic so the only thing that we can do is to making sure that every version",
    "start": "710320",
    "end": "717360"
  },
  {
    "text": "gets a most tested every time more improvement and so on so we invested a",
    "start": "717360",
    "end": "723200"
  },
  {
    "text": "lot on ci cd regression checks sanitization making sure that it's running five",
    "start": "723200",
    "end": "728800"
  },
  {
    "text": "fine on all architectures a we have a security team working with a google oss",
    "start": "728800",
    "end": "734639"
  },
  {
    "text": "fashion technologies we gotta talk about that in fluentcon which was our conference this monday",
    "start": "734639",
    "end": "740560"
  },
  {
    "text": "pretty much fluentbit is being tested with random input on different interfaces different functions and",
    "start": "740560",
    "end": "747279"
  },
  {
    "text": "trying to make it crash yeah the first year it crashes like crazy right but this has been running 24x7 for more than",
    "start": "747279",
    "end": "754000"
  },
  {
    "text": "one year and most of these corner cases this box has been fixed already",
    "start": "754000",
    "end": "759680"
  },
  {
    "text": "and we started solving the logs problem but we said we just saw blocks right and i think",
    "start": "759680",
    "end": "766240"
  },
  {
    "text": "that we think that matrix is interesting and there's more problems so we started extending our scope to metrics and also",
    "start": "766240",
    "end": "772160"
  },
  {
    "text": "traces and this is a question oh metrics and traces but there's other projects right",
    "start": "772160",
    "end": "777519"
  },
  {
    "text": "and that's this is a primary topic of these presentations so i will let anarch",
    "start": "777519",
    "end": "782720"
  },
  {
    "text": "elaborate more about that yeah awesome thanks edward and yeah if i if i talk about logs",
    "start": "782720",
    "end": "787920"
  },
  {
    "text": "metrics and traces you know when when we talked to the community what we were finding is folks had a bunch of common",
    "start": "787920",
    "end": "794560"
  },
  {
    "text": "use cases so as folks were gathering logs many times there were metrics in those logs things they wanted to extract",
    "start": "794560",
    "end": "802000"
  },
  {
    "text": "and what we found was folks were writing gigantic lua scripts extracting all these small decimal points from logs",
    "start": "802000",
    "end": "808800"
  },
  {
    "text": "doing all sorts of additions and then trying to hack it together with node exporter or something else and and get",
    "start": "808800",
    "end": "816000"
  },
  {
    "text": "into a prometheus format and so we took our philosophy of how do we integrate with these ecosystems makes things",
    "start": "816000",
    "end": "821600"
  },
  {
    "text": "easier for for all our users and that's really what said us last year on how do we integrate",
    "start": "821600",
    "end": "826959"
  },
  {
    "text": "much much deeper into to a metric sense and we'll talk about traces as well so first logs right this is what we've been",
    "start": "826959",
    "end": "833839"
  },
  {
    "text": "doing for for 11 plus years with fluentd when we look at it from a project side you know logs are unstructured data you",
    "start": "833839",
    "end": "840480"
  },
  {
    "text": "can have some unstructured logs where someone might write in logger hi my name is john or hello my name is jill we have",
    "start": "840480",
    "end": "848560"
  },
  {
    "text": "structured logs things well known like nginx access logs or structured schema",
    "start": "848560",
    "end": "853839"
  },
  {
    "text": "like syslog you could have schema list logs and as you are gathering these logs you",
    "start": "853839",
    "end": "860000"
  },
  {
    "text": "might want to do some processing right the most common use case of this is if you are gathering these logs in",
    "start": "860000",
    "end": "865519"
  },
  {
    "text": "kubernetes you want to enrich them with container pod namespace all of these contextual clues to help you debug and",
    "start": "865519",
    "end": "872800"
  },
  {
    "text": "troubleshoot much much faster the same can be said where you might want to reduce that data right one of",
    "start": "872800",
    "end": "878639"
  },
  {
    "text": "the big use cases that we see from a community perspective is folks who are",
    "start": "878639",
    "end": "883680"
  },
  {
    "text": "gathering petabytes and petabytes of data might not want to pay for those petabytes and petabytes of data or send",
    "start": "883680",
    "end": "889600"
  },
  {
    "text": "it to perhaps a less expensive less used data store so that things can be",
    "start": "889600",
    "end": "895519"
  },
  {
    "text": "a little bit cheaper and that's one of the other big use cases that we see with logs is how do we filter those out how",
    "start": "895519",
    "end": "901680"
  },
  {
    "text": "do we reduce them or how do we send it to to multiple locations and i think metrics are also really fun",
    "start": "901680",
    "end": "908800"
  },
  {
    "text": "because when we started fluent bit back in in 2015 its initial use case was for",
    "start": "908800",
    "end": "914720"
  },
  {
    "text": "embedded linux and when you're running on embedded linux those things are like iot devices",
    "start": "914720",
    "end": "920800"
  },
  {
    "text": "wind turbines robots within warehouses the main information that",
    "start": "920800",
    "end": "927360"
  },
  {
    "text": "folks wanted to capture at the time was cpu memory thermal kernel uh all sorts of metrics",
    "start": "927360",
    "end": "934720"
  },
  {
    "text": "uh from those and that's those are actually the first plug-ins that flip it had it didn't have a tail plug-in it couldn't read",
    "start": "934720",
    "end": "940480"
  },
  {
    "text": "log files and so that was something we had way way back then and we kept on",
    "start": "940480",
    "end": "945680"
  },
  {
    "text": "seeing folks use it but when we saw those log base metrics being used last year",
    "start": "945680",
    "end": "951360"
  },
  {
    "text": "we realized hey those are not what folks need in this new day and age what the kind of the standard we see is is",
    "start": "951360",
    "end": "957680"
  },
  {
    "text": "prometheus being used almost everywhere and open metrics being being that that compatibility layer",
    "start": "957680",
    "end": "964240"
  },
  {
    "text": "so we went in and made sure that fluentpit can speak the language of those metrics added counters gauges",
    "start": "964240",
    "end": "969839"
  },
  {
    "text": "histogram summaries we created libraries of uh called c metrics it's in the project you can you can go and look at",
    "start": "969839",
    "end": "975759"
  },
  {
    "text": "it and then make these things all exportable so within all these metrics that we go collect we're able to export",
    "start": "975759",
    "end": "982480"
  },
  {
    "text": "them into into various formats and now what we've gone and done this year is said you know open telemetry is",
    "start": "982480",
    "end": "989199"
  },
  {
    "text": "coming with with a giant wave let's go make sure that fluentpic can also speak that and and be compatible",
    "start": "989199",
    "end": "995440"
  },
  {
    "text": "so the the first step we took there was with open telemetry metrics and making sure if you're using the open telemetry",
    "start": "995440",
    "end": "1002720"
  },
  {
    "text": "metrics sdk you're collecting those things uh we'll be able to collect that and send it out and we have a",
    "start": "1002720",
    "end": "1009040"
  },
  {
    "text": "small demo that we can show here as well so what does this look like in actuality when you look at the fluent",
    "start": "1009040",
    "end": "1015199"
  },
  {
    "text": "ecosystem it's really made of all these different plugins inputs outputs and in the input side we've added a",
    "start": "1015199",
    "end": "1021279"
  },
  {
    "text": "prometheus scraper so you can scrape your custom metrics if you're running as a side car so right",
    "start": "1021279",
    "end": "1026558"
  },
  {
    "text": "next to your kubernetes applications you can go ahead and grab those metrics",
    "start": "1026559",
    "end": "1031600"
  },
  {
    "text": "also mimic node exporter metrics so you know we're not doing the full breadth uh that the prometheus node exporter team",
    "start": "1031600",
    "end": "1037600"
  },
  {
    "text": "is doing that's an awesome piece of software does fantastic things but there was a lot of commonality with what we",
    "start": "1037600",
    "end": "1043520"
  },
  {
    "text": "had done with our plugins and we wanted to make sure that we collect you know 80 percent of those give you a good",
    "start": "1043520",
    "end": "1048880"
  },
  {
    "text": "dashboard if you're using things like grafana or other things to visualize on top",
    "start": "1048880",
    "end": "1053919"
  },
  {
    "text": "and then from an output side what are the two main ways to to get these metrics the prometheus exporter so if",
    "start": "1053919",
    "end": "1059280"
  },
  {
    "text": "you're scraping those metrics how can i just plug into what already exists and also prometheus remote right so a",
    "start": "1059280",
    "end": "1065679"
  },
  {
    "text": "lot of services these days whether they're third-party services or uh projects like m3 thanos cortex",
    "start": "1065679",
    "end": "1074799"
  },
  {
    "text": "i'm sure there's some others uh having the ability to just remote right into in directly into those services and not",
    "start": "1074799",
    "end": "1081200"
  },
  {
    "text": "being exclusive so another big thing is like we didn't want to say you must only do remote write with scrape or only do",
    "start": "1081200",
    "end": "1088320"
  },
  {
    "text": "node exporter metrics with exporter you can kind of choose combine send it in three four different locations use",
    "start": "1088320",
    "end": "1095440"
  },
  {
    "text": "five exporters if you want send it to seven places with prometheus remote right be very flexible in the same way",
    "start": "1095440",
    "end": "1101760"
  },
  {
    "text": "that we are with logs and other data sources what does this look like from a configuration standpoint so the metrics",
    "start": "1101760",
    "end": "1108960"
  },
  {
    "text": "also are our unique influent bit in that our metrics are don't go through the same pipelines that logs go through so",
    "start": "1108960",
    "end": "1115919"
  },
  {
    "text": "metrics are almost treated as an independent type you can in this configuration example see hey we're",
    "start": "1115919",
    "end": "1122160"
  },
  {
    "text": "collecting node exporter metrics and then we're outputting them to the port 2021. we could easily add a prometheus",
    "start": "1122160",
    "end": "1128880"
  },
  {
    "text": "remote write as another output if we'd like as well add our tls settings our service",
    "start": "1128880",
    "end": "1135600"
  },
  {
    "text": "and whatever ad label tags that we might want as part of that for our dashboard",
    "start": "1135600",
    "end": "1142000"
  },
  {
    "text": "yep prometheus scraper this one is actually brand new to flintbit 1.9 which was released march of",
    "start": "1142000",
    "end": "1147840"
  },
  {
    "text": "this year and this one allows you just as you would with any scraping go ahead grab",
    "start": "1147840",
    "end": "1153760"
  },
  {
    "text": "something get in the format in this case we're using uh hashicorp vault and then we're",
    "start": "1153760",
    "end": "1159280"
  },
  {
    "text": "using an output to prometheus remote right with additional labels",
    "start": "1159280",
    "end": "1165520"
  },
  {
    "text": "and with open telemetry yeah so similarly we started off with http so input and",
    "start": "1165520",
    "end": "1171200"
  },
  {
    "text": "output so you're able to ingest with http and output with http we're looking",
    "start": "1171200",
    "end": "1176559"
  },
  {
    "text": "at additional protocols there as open telemetry supports more than just hdp",
    "start": "1176559",
    "end": "1182640"
  },
  {
    "text": "and then on of course on top of that all of the tracing side as part of part of the roadmap which we'll cover here in a",
    "start": "1182640",
    "end": "1189280"
  },
  {
    "text": "bit so what does this look like in actuality uh when we put it all together so we have a quick demo",
    "start": "1189280",
    "end": "1195440"
  },
  {
    "text": "and this is very very simple i have a javascript application i'm instrumenting it with the standard of the day which is",
    "start": "1195440",
    "end": "1200880"
  },
  {
    "text": "open telemetry all the great work that that team's done for building those libraries we send those via the metric",
    "start": "1200880",
    "end": "1206720"
  },
  {
    "text": "sdk to flip it and then we have prometheus already in place so it scrapes that via prometheus scraper and",
    "start": "1206720",
    "end": "1213200"
  },
  {
    "text": "then we just visualize it with with grafana so let me go ahead and close this out",
    "start": "1213200",
    "end": "1221000"
  },
  {
    "text": "and let's go ahead and switch into let's do a couple things i'm going to go",
    "start": "1221200",
    "end": "1226640"
  },
  {
    "text": "tab by tab here so first let's start with the application so this is my javascript application",
    "start": "1226640",
    "end": "1232799"
  },
  {
    "text": "you can see i'm using let me go ahead and increase the size here i'm using the otlp open telemetry",
    "start": "1232799",
    "end": "1239679"
  },
  {
    "text": "protocol metric exporter and i'm sending it to fluid bit on its 8080 port so",
    "start": "1239679",
    "end": "1244799"
  },
  {
    "text": "within fluid bit i have a read from the http open telemetry and then i have an",
    "start": "1244799",
    "end": "1250320"
  },
  {
    "text": "exporter which is that prometheus exporter that i mentioned earlier and if i go to the 2021 port what does",
    "start": "1250320",
    "end": "1257760"
  },
  {
    "text": "it look like if we just viewed it raw this is really all it is just a simple counter from open telemetry test up down",
    "start": "1257760",
    "end": "1265600"
  },
  {
    "text": "then prometheus we look at prometheus and it's scrape config it's grabbing from fluent bit on the 2021 port that we",
    "start": "1265600",
    "end": "1273200"
  },
  {
    "text": "were exposing and finally come back to grafana and how do we visualize all that so it's a very",
    "start": "1273200",
    "end": "1280240"
  },
  {
    "text": "simple pipeline uh something that is you know very easily replicable something that",
    "start": "1280240",
    "end": "1286159"
  },
  {
    "text": "we're going to continue to add more and more features to but of course that's what we are here for this conference and and interested",
    "start": "1286159",
    "end": "1292720"
  },
  {
    "text": "in your feedback on what is needed what can we add what can we",
    "start": "1292720",
    "end": "1297840"
  },
  {
    "text": "make sure works really really well and especially when we look at some of some of the use cases that has made",
    "start": "1297840",
    "end": "1304000"
  },
  {
    "text": "fluent successful in the log space with filtering reducing data enriching data how can we bring some of",
    "start": "1304000",
    "end": "1310720"
  },
  {
    "text": "those same ideas to how we're scraping and modifying uh some of these metrics",
    "start": "1310720",
    "end": "1317200"
  },
  {
    "text": "from open telemetry and open metrics so with that let me switch back to the slides here",
    "start": "1317200",
    "end": "1324159"
  },
  {
    "text": "and let's talk a little bit about roadmap and the first first big one is traces",
    "start": "1325520",
    "end": "1331520"
  },
  {
    "text": "right so when we look at logs and traces and metrics because we treat them as independent data sources one of the the",
    "start": "1331520",
    "end": "1338640"
  },
  {
    "text": "ideals is how can we start to make some really meaningful correlations or interactions between those pieces of",
    "start": "1338640",
    "end": "1345280"
  },
  {
    "text": "data and especially when we look at fluent bit and what we've done with logs we've had",
    "start": "1345280",
    "end": "1350320"
  },
  {
    "text": "some of these notions of stream processing so you can write sql today on top of your logs",
    "start": "1350320",
    "end": "1355600"
  },
  {
    "text": "common use cases might be i'm using nginx access logs i want to group by error codes with the sql query select",
    "start": "1355600",
    "end": "1362799"
  },
  {
    "text": "star from group by error code or response code and then pump out a smaller",
    "start": "1362799",
    "end": "1369679"
  },
  {
    "text": "amount of logs similarly trying to bring some of that logic over to traces",
    "start": "1369679",
    "end": "1374880"
  },
  {
    "text": "bringing some of that logic over to metrics and in order to do that we need to introduce the the same style of hey",
    "start": "1374880",
    "end": "1380480"
  },
  {
    "text": "here's a brand new format of traces so our idea is to bring that into q4 of this year and also extend the the",
    "start": "1380480",
    "end": "1387600"
  },
  {
    "text": "current open telemetry input output so instead of you having to say open telemetry metrics or open telemetry uh",
    "start": "1387600",
    "end": "1393840"
  },
  {
    "text": "traces have it all live within kind of that same uh configuration set that you",
    "start": "1393840",
    "end": "1399039"
  },
  {
    "text": "saw before uh then the other biggest one something that is",
    "start": "1399039",
    "end": "1404480"
  },
  {
    "text": "always continuous is performance improvements when we look at flippin and again it's it's success that",
    "start": "1404480",
    "end": "1411039"
  },
  {
    "text": "we've seen within containerized kubernetes environments it's really that high performance low footprint",
    "start": "1411039",
    "end": "1417440"
  },
  {
    "text": "and being able to scale that to you know we have banks that run on 100 000 servers we have super small startups",
    "start": "1417440",
    "end": "1424000"
  },
  {
    "text": "that will run this on you know the k3s super small micro kubernetes clusters so",
    "start": "1424000",
    "end": "1429840"
  },
  {
    "text": "want to make sure that that performance maintains and to do that we want to have a better handling of how we treat all",
    "start": "1429840",
    "end": "1436320"
  },
  {
    "text": "these events because we're not just going to be collecting logs anymore we'll collect metrics we'll collect traces",
    "start": "1436320",
    "end": "1441919"
  },
  {
    "text": "and make sure that all of that is async has a good um good higher performance",
    "start": "1441919",
    "end": "1447120"
  },
  {
    "text": "we're also going to be introducing threading support so we added that on the output side with fluent bit so you",
    "start": "1447120",
    "end": "1453039"
  },
  {
    "text": "can add more threads so if you're for example sending terabytes of data",
    "start": "1453039",
    "end": "1458559"
  },
  {
    "text": "you can add this worker setting which is now the default in 1.9 and and really pump that data through",
    "start": "1458559",
    "end": "1464720"
  },
  {
    "text": "and now we're finding the bottleneck coming on the tail side when i'm reading that data if i'm reading a petabyte per day",
    "start": "1464720",
    "end": "1471120"
  },
  {
    "text": "how do i make sure that i'm reading maybe from 10 000 files or as container density increases i increase the amount",
    "start": "1471120",
    "end": "1477600"
  },
  {
    "text": "of files that i have on that node so we're going to be introducing input plugins in a separate thread and of",
    "start": "1477600",
    "end": "1483279"
  },
  {
    "text": "course optimized core operations so if you're really interested in some of these performance improvements we had a",
    "start": "1483279",
    "end": "1489039"
  },
  {
    "text": "couple talks from flumecon which are recorded and already on youtube things from aws about improving the event loop",
    "start": "1489039",
    "end": "1495440"
  },
  {
    "text": "um also things from again the folks in the security side who are doing some of the fuzzing and",
    "start": "1495440",
    "end": "1501520"
  },
  {
    "text": "ensuring things are are compatible and well a developer experience so again we know",
    "start": "1501520",
    "end": "1507919"
  },
  {
    "text": "flip it is written in c and it might not be the most appetizing thing to go and try to conquer",
    "start": "1507919",
    "end": "1513279"
  },
  {
    "text": "but we do have golang interfaces for the output side and we're going to bring that to the input side as well",
    "start": "1513279",
    "end": "1519039"
  },
  {
    "text": "when when we think of some of those use cases especially in context of metrics traces",
    "start": "1519039",
    "end": "1524880"
  },
  {
    "text": "these can be things like sas data sources things that have apis that have really great go sdks for and you might",
    "start": "1524880",
    "end": "1532000"
  },
  {
    "text": "want to go scrape that data collect that data bring that data in do some correlations generate some prometheus metrics",
    "start": "1532000",
    "end": "1538799"
  },
  {
    "text": "generate some some hotel metrics or whatnot from so yeah that",
    "start": "1538799",
    "end": "1544159"
  },
  {
    "text": "experience is coming in q3 would love to talk to folks who are interested in writing more of those plugins always",
    "start": "1544159",
    "end": "1550480"
  },
  {
    "text": "interested in getting the the community feedback there so yeah you know in this last one you",
    "start": "1550480",
    "end": "1556799"
  },
  {
    "text": "know when we think of our our ideals and how we keep building the project and alongside the community uh you know with",
    "start": "1556799",
    "end": "1563760"
  },
  {
    "text": "with uh bruce lee we think of you know be like water uh be be fluent my friend be fluid so",
    "start": "1563760",
    "end": "1571679"
  },
  {
    "text": "yeah with that i think we we have quite a bit of time for for questions and with this super packed room we'd love to",
    "start": "1571679",
    "end": "1578400"
  },
  {
    "text": "to answer as many as we can okay thank you",
    "start": "1578400",
    "end": "1584400"
  },
  {
    "text": "yeah hey thanks thanks uh yeah do we have mike okay first of all like applause for",
    "start": "1584400",
    "end": "1591360"
  },
  {
    "text": "speakers",
    "start": "1591360",
    "end": "1594360"
  },
  {
    "text": "amazing amazing and uh yeah let's we have a couple of questions actually virtually so we try to kind of make it a",
    "start": "1599440",
    "end": "1605200"
  },
  {
    "text": "hybrid uh and yeah um who has maybe maybe you can start with in-person questions",
    "start": "1605200",
    "end": "1610559"
  },
  {
    "text": "anyone has any questions already have fun okay i will try to bring you the mic",
    "start": "1610559",
    "end": "1617039"
  },
  {
    "text": "uh so thank you first uh you mentioned about traces which sounds",
    "start": "1618159",
    "end": "1623440"
  },
  {
    "text": "great i guess my question is have you thought about uh doing it the other way",
    "start": "1623440",
    "end": "1629760"
  },
  {
    "text": "around which is having fluent bits emits is or its own traces so that we can",
    "start": "1629760",
    "end": "1635039"
  },
  {
    "text": "follow the path of our logs and kind of like know that when a log is emitted it",
    "start": "1635039",
    "end": "1640080"
  },
  {
    "text": "is sent somewhere and then we would be with these two traces uh be able to know",
    "start": "1640080",
    "end": "1645440"
  },
  {
    "text": "the full path until when the log is uh sent to the database and how long that takes basically",
    "start": "1645440",
    "end": "1651679"
  },
  {
    "text": "yeah can you hear me right yeah okay so uh should we handle fluent bit traces",
    "start": "1651679",
    "end": "1657679"
  },
  {
    "text": "internal information that's primarily the question the question when we talk about traces uh traces are hard in",
    "start": "1657679",
    "end": "1663840"
  },
  {
    "text": "general right so the way that we are going we we're starting approach right now because this is in development right",
    "start": "1663840",
    "end": "1670880"
  },
  {
    "text": "it's not to do traces processing not do the traces correlation in the agent",
    "start": "1670880",
    "end": "1676480"
  },
  {
    "text": "because we might need to do buffering some kind of indexing but more complex so in traces just to clarify",
    "start": "1676480",
    "end": "1683039"
  },
  {
    "text": "traces where we're going to do is initially as of now take the traces it's in a row format and allow send that road",
    "start": "1683039",
    "end": "1690240"
  },
  {
    "text": "traces to destinations and back-ends that they have all the the intel to",
    "start": "1690240",
    "end": "1695600"
  },
  {
    "text": "process those traces and correlate them kind of grafana or there's some cloud services that accomplish that from",
    "start": "1695600",
    "end": "1702559"
  },
  {
    "text": "internal fluid traces we have not make any decision but this is really interesting we might think on how to",
    "start": "1702559",
    "end": "1708559"
  },
  {
    "text": "cheap the internal events of fluent bed in the yeah we are shipping the outside information but we are not yeah",
    "start": "1708559",
    "end": "1714799"
  },
  {
    "text": "receiving the internal information so this i'm smiling because you know a few weeks ago in one of our community",
    "start": "1714799",
    "end": "1720559"
  },
  {
    "text": "meetings we talked about this idea of being able to peer into what is a plug and doing what what information is",
    "start": "1720559",
    "end": "1727600"
  },
  {
    "text": "flowing through so we started a discussion on it in in github so love participation in there try to",
    "start": "1727600",
    "end": "1734559"
  },
  {
    "text": "spec out like what those requirements look like we have some ideas uh but of course",
    "start": "1734559",
    "end": "1739760"
  },
  {
    "text": "there's there's a lot to to go back and forth with security you don't want people just peering in over a hdp port",
    "start": "1739760",
    "end": "1746640"
  },
  {
    "text": "of all your logs right if they're sensitive so a lot a lot of stuff there but would love for for more",
    "start": "1746640",
    "end": "1753360"
  },
  {
    "text": "community feedback and what we can do there nice nice so observability for observability right here",
    "start": "1753360",
    "end": "1760480"
  },
  {
    "text": "any other questions in this room",
    "start": "1760480",
    "end": "1764679"
  },
  {
    "text": "hi first of all thank you uh you said in q4 uh you flap it will get racist",
    "start": "1769440",
    "end": "1776480"
  },
  {
    "text": "support but i think we can right now we can use forwarder plug-in forward output for uh",
    "start": "1776480",
    "end": "1783840"
  },
  {
    "text": "sounding traces from the kubernetes to maybe open telemetry or uh other places uh",
    "start": "1783840",
    "end": "1790559"
  },
  {
    "text": "will you suggest that yeah we will it will be okay or uh you will suggest that we should wait",
    "start": "1790559",
    "end": "1796720"
  },
  {
    "text": "for uh q4 or legit trace support yeah g good question maybe i'll answer a",
    "start": "1796720",
    "end": "1803120"
  },
  {
    "text": "little and then i'll hand it to eduardo um so so the question is hey should we wait till q4 or should we use some of",
    "start": "1803120",
    "end": "1809200"
  },
  {
    "text": "the existing integrations that that already are there so to clarify some of those",
    "start": "1809200",
    "end": "1814240"
  },
  {
    "text": "existing integrations are from fluent fluentd fluent bit using the forward protocol",
    "start": "1814240",
    "end": "1820320"
  },
  {
    "text": "which is protocol over message pack over tcp to the hotel collector and that's a great way there's there's some good",
    "start": "1820320",
    "end": "1826640"
  },
  {
    "text": "sessions uh on that or or recorded content on that there's a guide on the hotel documentation on how to do it",
    "start": "1826640",
    "end": "1833520"
  },
  {
    "text": "but this is actually different so this would be receiving the traces to fluid bit",
    "start": "1833520",
    "end": "1838880"
  },
  {
    "text": "so so this so in q4 you'll be able to receive those traces if you're using the",
    "start": "1838880",
    "end": "1844080"
  },
  {
    "text": "fluent forward protocol via app or via fluenty or flintbed you can already",
    "start": "1844080",
    "end": "1849120"
  },
  {
    "text": "integrate with hotel collector great great thank you okay any other maybe last person from",
    "start": "1849120",
    "end": "1855679"
  },
  {
    "text": "the room we have others as well great let's go",
    "start": "1855679",
    "end": "1863080"
  },
  {
    "text": "uh hi um the last time i checked the project i remember there was no uh yokto",
    "start": "1864000",
    "end": "1869600"
  },
  {
    "text": "layer for your project like for fluid bit i think there was only a recipe hanging around in the documentation",
    "start": "1869600",
    "end": "1875760"
  },
  {
    "text": "somewhere so is there a reason why you don't provide your own layer or have you been thinking about it",
    "start": "1875760",
    "end": "1882640"
  },
  {
    "text": "yeah as i mentioned briefly fluent beta started as a project for embedded linux",
    "start": "1882640",
    "end": "1888399"
  },
  {
    "text": "originally right and then we switched the focus to to the cloud because",
    "start": "1888399",
    "end": "1894080"
  },
  {
    "text": "at that time embedded false there are no standards right there was no community around it but in the in the",
    "start": "1894080",
    "end": "1901039"
  },
  {
    "text": "container space evolved quickly now those beatback files from yokto are",
    "start": "1901039",
    "end": "1906399"
  },
  {
    "text": "there for historical reasons and we aim to support them but we as maintainers a actually we are so busy",
    "start": "1906399",
    "end": "1913679"
  },
  {
    "text": "with so many requirements that we can no longer maintain that recipe it might be broken we just try to update the version",
    "start": "1913679",
    "end": "1920799"
  },
  {
    "text": "but if you're using jokto you know beatback files and you can fix it at least on meta pr and happy to get that",
    "start": "1920799",
    "end": "1928159"
  },
  {
    "text": "you know process through there's no more reason that that it's maintained yeah okay let's take maybe a",
    "start": "1928159",
    "end": "1935679"
  },
  {
    "text": "few virtual questions so we have first about um otlp how about adding otp support",
    "start": "1935679",
    "end": "1942320"
  },
  {
    "text": "into fluent beat in and out yeah that's what we are doing actually what is my camera",
    "start": "1942320",
    "end": "1948960"
  },
  {
    "text": "so that's very generic as well because means also metrics logs yeah traces so",
    "start": "1948960",
    "end": "1954640"
  },
  {
    "text": "there's another question about logging okay so otlp for us is more another",
    "start": "1954640",
    "end": "1960559"
  },
  {
    "text": "protocol that we integrate with we integrate with c slope forward and",
    "start": "1960559",
    "end": "1966080"
  },
  {
    "text": "well i don't know we have nqtt we have a bunch of protocols that we support so for us all otlp is another",
    "start": "1966080",
    "end": "1972799"
  },
  {
    "text": "protocol that we're going to we started supporting right now initially with matrix because we were experimenting",
    "start": "1972799",
    "end": "1978240"
  },
  {
    "text": "with metrics now the default case is traces but we're going to do just route traces",
    "start": "1978240",
    "end": "1984559"
  },
  {
    "text": "and yeah so we support that already in the input and in the output side yeah we did",
    "start": "1984559",
    "end": "1989840"
  },
  {
    "text": "all the protocol buff conversion to ceiling layer and that is functional already what about otp otlp logging yeah",
    "start": "1989840",
    "end": "1997600"
  },
  {
    "text": "we just heard that otlp the log spec was just released but",
    "start": "1997600",
    "end": "2002960"
  },
  {
    "text": "there's not much content that we can add at the moment because of the following the way that we handle the project and",
    "start": "2002960",
    "end": "2009360"
  },
  {
    "text": "we manage as a community is like we try to optimize for what is the standard in",
    "start": "2009360",
    "end": "2014559"
  },
  {
    "text": "the industry for example when we get started with a metrics the first question was okay what",
    "start": "2014559",
    "end": "2020559"
  },
  {
    "text": "is the standard for metrics in the industry and what it is prometheus",
    "start": "2020559",
    "end": "2026159"
  },
  {
    "text": "so we start to support them prometheus then ot for example if i say what is the standard for traces",
    "start": "2026159",
    "end": "2032399"
  },
  {
    "text": "open telemetry right now if i ask today what is the standard",
    "start": "2032399",
    "end": "2037600"
  },
  {
    "text": "for example for um what was metrics for logging i think that is not standard right oclp",
    "start": "2037600",
    "end": "2044559"
  },
  {
    "text": "is heading into into that direction so as soon as this get more traction in the community we get more use cases",
    "start": "2044559",
    "end": "2051599"
  },
  {
    "text": "right we're going to start supporting all these layers great great answer essentially it has to",
    "start": "2051599",
    "end": "2056960"
  },
  {
    "text": "organically grow right yeah yeah thank you okay last question maybe from the room",
    "start": "2056960",
    "end": "2064720"
  },
  {
    "text": "hi thanks for the talk did you think about having a fluent bit as our own input source for metrics for example for",
    "start": "2065359",
    "end": "2072800"
  },
  {
    "text": "for counting logs and putting that into a metric yeah so fluent bit has",
    "start": "2072800",
    "end": "2079280"
  },
  {
    "text": "it has its own way of monitoring today so you can expose expose over prometheus that's been there for 2-3 years",
    "start": "2079280",
    "end": "2086878"
  },
  {
    "text": "over a port and it gives you input logs input bytes output bytes great ways",
    "start": "2086879",
    "end": "2092560"
  },
  {
    "text": "to now like analyze if you're sending data if you're removing data how much data you're sending to",
    "start": "2092560",
    "end": "2098640"
  },
  {
    "text": "particular endpoints or you might have a no easy log file that exists today we did introduce a few",
    "start": "2098640",
    "end": "2105680"
  },
  {
    "text": "months back fluent bit metrics it's a it's its own plugin that will take those",
    "start": "2105680",
    "end": "2111280"
  },
  {
    "text": "usually exposed over http metrics and ingest them as part of the pipeline",
    "start": "2111280",
    "end": "2116800"
  },
  {
    "text": "so that that does exist today so you could remote write those metrics um or or export them to a",
    "start": "2116800",
    "end": "2122320"
  },
  {
    "text": "custom port if you need to okay that's it for for today um and thank you we have 20 minutes break",
    "start": "2122320",
    "end": "2128800"
  },
  {
    "text": "applause for speakers again",
    "start": "2128800",
    "end": "2133160"
  }
]
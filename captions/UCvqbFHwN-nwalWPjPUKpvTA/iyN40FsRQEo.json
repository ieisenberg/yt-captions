[
  {
    "start": "0",
    "end": "73000"
  },
  {
    "text": "yeah thanks very much for coming my name is Brian Boram I'm an engineer at weave",
    "start": "30",
    "end": "7049"
  },
  {
    "text": "works and that's my twitter handle which",
    "start": "7049",
    "end": "13740"
  },
  {
    "text": "is the main reason I'm here no I'm here to talk about cortex and I gave this the",
    "start": "13740",
    "end": "24449"
  },
  {
    "text": "clickbait title of infinitely scalable so who came because they were kind of",
    "start": "24449",
    "end": "30449"
  },
  {
    "text": "riled up like there's no way it can be",
    "start": "30449",
    "end": "36210"
  },
  {
    "text": "infinitely scalable so welcome and then",
    "start": "36210",
    "end": "42540"
  },
  {
    "text": "when I was thinking about when I was thinking about the name and and kind of",
    "start": "42540",
    "end": "49260"
  },
  {
    "text": "running it around in my head and and somehow it turned into infinity war you",
    "start": "49260",
    "end": "56340"
  },
  {
    "text": "know which is was a was a film that was out recently and it's kind of a dumb",
    "start": "56340",
    "end": "64830"
  },
  {
    "text": "film they go they go chasing around after these stones Infinity stones so I'm not gonna mention any of that again",
    "start": "64830",
    "end": "73880"
  },
  {
    "start": "73000",
    "end": "73000"
  },
  {
    "text": "so cortex is a time-series store built",
    "start": "74840",
    "end": "79920"
  },
  {
    "text": "on promises who uses Prometheus and I put my own hand up because we also do",
    "start": "79920",
    "end": "86009"
  },
  {
    "text": "use Prometheus it is it is built on prometheus we we have we huge we use the",
    "start": "86009",
    "end": "93000"
  },
  {
    "text": "code very much built on it great benefit of the old source community and the key",
    "start": "93000",
    "end": "103590"
  },
  {
    "text": "attributes of cortex are that it is horizontally scalable highly available",
    "start": "103590",
    "end": "110479"
  },
  {
    "text": "provides long-term storage and is a multi-tenant system so I'm gonna say a",
    "start": "110479",
    "end": "118049"
  },
  {
    "text": "lot more about all of those things over the course of this talk cortex is a CN",
    "start": "118049",
    "end": "124079"
  },
  {
    "text": "CF project we we started at we've works we turned over the IP to the CN CF it's",
    "start": "124079",
    "end": "130229"
  },
  {
    "text": "Apache licensed you can the source code from that URL at the",
    "start": "130229",
    "end": "135719"
  },
  {
    "text": "bottom of the page court reject slash cortex okay why did we build cortex well",
    "start": "135719",
    "end": "143670"
  },
  {
    "start": "142000",
    "end": "142000"
  },
  {
    "text": "we run we've works we run this software as a service monitoring as reserve ability",
    "start": "143670",
    "end": "150060"
  },
  {
    "text": "and continuous deployment platform we've cloud and we wanted to do things like",
    "start": "150060",
    "end": "156299"
  },
  {
    "text": "like dashboards we draw these automatic magic dashboards and we wanted to do",
    "start": "156299",
    "end": "161939"
  },
  {
    "text": "that as a as a sign up you know you can just show up with your credit card and",
    "start": "161939",
    "end": "168829"
  },
  {
    "text": "sign up we didn't want to have to provision Promethean dividual user so we",
    "start": "168829",
    "end": "174450"
  },
  {
    "text": "wanted a multi-tenant system so that's the that's the genesis of the thing this",
    "start": "174450",
    "end": "180299"
  },
  {
    "start": "179000",
    "end": "179000"
  },
  {
    "text": "is the weather the minds behind cortex this is a screen dump from github so it",
    "start": "180299",
    "end": "190919"
  },
  {
    "text": "started June 2016 two and a half years ish we've been running it in production",
    "start": "190919",
    "end": "198810"
  },
  {
    "text": "about two years probably the number one",
    "start": "198810",
    "end": "204859"
  },
  {
    "text": "committer Tom Wilkie in the audience we got a few of the maintainer of cortex here we got Ken here myself and there",
    "start": "204859",
    "end": "216060"
  },
  {
    "text": "there are people on this list who are also maintainer of Prometheus so again I want to stress a lot of lot of sharing",
    "start": "216060",
    "end": "222780"
  },
  {
    "text": "and collaboration there you probably can't see on the screen but I do find it",
    "start": "222780",
    "end": "228930"
  },
  {
    "text": "amusing that the Tom's the number of lines deleted is higher than the number of lines added so I guess he's number",
    "start": "228930",
    "end": "238169"
  },
  {
    "text": "one in a way anyway so yeah the the",
    "start": "238169",
    "end": "246989"
  },
  {
    "text": "community the minds behind cortex the other side of the community who uses",
    "start": "246989",
    "end": "253169"
  },
  {
    "start": "249000",
    "end": "249000"
  },
  {
    "text": "cortex it is it has been adopted by a number of people running platforms we've",
    "start": "253169",
    "end": "258959"
  },
  {
    "text": "worked obviously profound labs Aspen mash and platform 9 are here at",
    "start": "258959",
    "end": "266590"
  },
  {
    "text": "cube Cohen and as our Maya data neaby s they're part of the people on the right",
    "start": "266590",
    "end": "273550"
  },
  {
    "text": "are some of the users of some of the",
    "start": "273550",
    "end": "278920"
  },
  {
    "text": "platforms on the left and and I put this so this is the sole of the pro is it is they were liking the the dominant vanity",
    "start": "278920",
    "end": "285100"
  },
  {
    "text": "storm metaphorical is yes okay one good I pleased one thank you anyway",
    "start": "285100",
    "end": "294070"
  },
  {
    "start": "294000",
    "end": "294000"
  },
  {
    "text": "yeah so that's this ticular gummy know most of you put your hand up that you use Prometheus so you probably have a",
    "start": "294070",
    "end": "299620"
  },
  {
    "text": "pretty good idea how it works but but",
    "start": "299620",
    "end": "305380"
  },
  {
    "text": "just to to cover the basics Prometheus runs as one process that",
    "start": "305380",
    "end": "312370"
  },
  {
    "text": "that's one of the key things very simple just run it and and you pointed at",
    "start": "312370",
    "end": "318100"
  },
  {
    "text": "things that have metrics which might be your own apps or it might be some kind",
    "start": "318100",
    "end": "323230"
  },
  {
    "text": "of exporter that gets data from somewhere else we call this great thing it pulls the metrics in it compresses",
    "start": "323230",
    "end": "330670"
  },
  {
    "text": "them stores them on disk and it also serves up queries which which come from",
    "start": "330670",
    "end": "336970"
  },
  {
    "text": "some kind of dashboard viewer something like that so that's the the basic",
    "start": "336970",
    "end": "344770"
  },
  {
    "text": "operation of Prometheus so problem comes",
    "start": "344770",
    "end": "351460"
  },
  {
    "text": "when you have more things more apps more",
    "start": "351460",
    "end": "356760"
  },
  {
    "start": "353000",
    "end": "353000"
  },
  {
    "text": "nodes more everything what are you going",
    "start": "356760",
    "end": "363070"
  },
  {
    "text": "to do well you can just get a bigger box Prometheus scales really well you can",
    "start": "363070",
    "end": "371580"
  },
  {
    "text": "you can certainly serve millions of time series from one large Prometheus box",
    "start": "371580",
    "end": "378130"
  },
  {
    "text": "very effective very good very well engineered but but some people then find",
    "start": "378130",
    "end": "385120"
  },
  {
    "text": "that that tops out it still not an you",
    "start": "385120",
    "end": "391600"
  },
  {
    "text": "know can't get a box big enough or don't don't maybe you want that much risk in one place so the next place that people",
    "start": "391600",
    "end": "397870"
  },
  {
    "text": "go is to split up the problem so this point you",
    "start": "397870",
    "end": "403300"
  },
  {
    "text": "have to kind of pick you know your manually sharding the data you whether",
    "start": "403300",
    "end": "409210"
  },
  {
    "text": "you slice it by apps versus infrastructure or you slice it by team a versus team B or you slice it by data",
    "start": "409210",
    "end": "416050"
  },
  {
    "text": "center or are you slice it you you you are gonna have to pick and then that",
    "start": "416050",
    "end": "423819"
  },
  {
    "text": "leads to a problem on in terms of viewing the data that how do you build",
    "start": "423819",
    "end": "431520"
  },
  {
    "text": "one chart that brings together data how do you get a global view of of the the",
    "start": "431520",
    "end": "438819"
  },
  {
    "text": "data that you've split up so that becomes a problem and there are ways to",
    "start": "438819",
    "end": "444250"
  },
  {
    "text": "solve it in Prometheus but it gets pretty complicated so we wanted to do",
    "start": "444250",
    "end": "449469"
  },
  {
    "text": "that differently in in cortex instead of one process we run many processes it is",
    "start": "449469",
    "end": "456550"
  },
  {
    "text": "it's what Tom calls on micro services oriented architecture flame me about",
    "start": "456550",
    "end": "463990"
  },
  {
    "text": "that one so this this is the this is the cortex architecture we we actually use",
    "start": "463990",
    "end": "472650"
  },
  {
    "text": "standard Prometheus to do the scraping the the operation of pulling in the",
    "start": "472650",
    "end": "477699"
  },
  {
    "text": "individual metrics from the endpoints they are sent to a distributor process",
    "start": "477699",
    "end": "485560"
  },
  {
    "text": "they're compressed they're stored and we have a query process and it's it split",
    "start": "485560",
    "end": "493000"
  },
  {
    "text": "up into multiple pieces so let's let's walk through each of those in turn and talk a bit more detail about how they",
    "start": "493000",
    "end": "498969"
  },
  {
    "text": "work so the the thing that processes",
    "start": "498969",
    "end": "506520"
  },
  {
    "start": "500000",
    "end": "500000"
  },
  {
    "text": "time series samples coming in on ingest we call an in gesture so yeah at the",
    "start": "506520",
    "end": "515948"
  },
  {
    "text": "point of my infinitely scalable headline is it sits horizontally scalable if you if you need more power you add more in",
    "start": "515949",
    "end": "522880"
  },
  {
    "text": "gestures we route through a process called the distributor we route every",
    "start": "522880",
    "end": "528640"
  },
  {
    "text": "time series 2-1 in gesture we do that using technique called a",
    "start": "528640",
    "end": "535750"
  },
  {
    "text": "distributed hash table DHT you can google that you know I've got a link",
    "start": "535750",
    "end": "541330"
  },
  {
    "text": "there if you want to read one of the seminal papers about that idea actually",
    "start": "541330",
    "end": "546490"
  },
  {
    "text": "I want to stress core Texas is built on unlike decades of work and research that",
    "start": "546490",
    "end": "553630"
  },
  {
    "text": "other people did very very well born techniques for distributed databases",
    "start": "553630",
    "end": "560680"
  },
  {
    "text": "basically so III don't wanna I don't want to claim any of the insight or",
    "start": "560680",
    "end": "568330"
  },
  {
    "text": "ingenuity in in in taking those ideas these are these are pretty standard ideas but they they're also pretty good",
    "start": "568330",
    "end": "574420"
  },
  {
    "text": "ideas so the the great thing about a DHT is there's no bottleneck in terms of",
    "start": "574420",
    "end": "581170"
  },
  {
    "text": "coordinating you can you can keep on adding in jesters and they will be",
    "start": "581170",
    "end": "586240"
  },
  {
    "text": "inserted into the DHT and we will route time series 2-1 in jester and they they",
    "start": "586240",
    "end": "595510"
  },
  {
    "text": "don't have to you know communicate every single time to one central point which is is going to limit scalability so",
    "start": "595510",
    "end": "602850"
  },
  {
    "text": "distributor working through the DHT gives us for this piece gives us an",
    "start": "602850",
    "end": "609640"
  },
  {
    "text": "infinite scalability let's look inside",
    "start": "609640",
    "end": "615240"
  },
  {
    "start": "615000",
    "end": "615000"
  },
  {
    "text": "one of those in jesters so the the",
    "start": "615240",
    "end": "620650"
  },
  {
    "text": "samples come in each wiggly line here is is a time series actually in reality",
    "start": "620650",
    "end": "629290"
  },
  {
    "text": "most time series are zero continuously it's it's kind of dull when you look at it but I've imagined that all of my time",
    "start": "629290",
    "end": "637000"
  },
  {
    "text": "series are much more exciting here so so",
    "start": "637000",
    "end": "642790"
  },
  {
    "text": "the the the wiggly lines come in they build up at different rates and that they're compressed in memory the the",
    "start": "642790",
    "end": "651100"
  },
  {
    "text": "compression technique that cortex uses and basically every time series database",
    "start": "651100",
    "end": "657550"
  },
  {
    "text": "I know about uses is called gorilla compression came from Facebook link to",
    "start": "657550",
    "end": "663640"
  },
  {
    "text": "the paper there so we compress it we get this massive compression of the data and when",
    "start": "663640",
    "end": "670899"
  },
  {
    "text": "we reach a certain level which is well originally it was 1k recently we've",
    "start": "670899",
    "end": "677769"
  },
  {
    "text": "brought that up to sort of four or five K typically a few hours of data in one",
    "start": "677769",
    "end": "682930"
  },
  {
    "text": "chunk we we stick the chunks in a store so this is the power of the Infinity",
    "start": "682930",
    "end": "691570"
  },
  {
    "text": "stone the space stone is compressing our data we do store it in memory for a few",
    "start": "691570",
    "end": "698290"
  },
  {
    "text": "hours compressing it and then we send it to the store oh yeah I wanted to mention",
    "start": "698290",
    "end": "708070"
  },
  {
    "text": "the store has the basic data it also has an index I'll talk about the index in a",
    "start": "708070",
    "end": "713709"
  },
  {
    "text": "minute so we're going to store the data for a long time what do we want from",
    "start": "713709",
    "end": "722500"
  },
  {
    "start": "715000",
    "end": "715000"
  },
  {
    "text": "that we want scalability because we were infinitely scalable that's why you came",
    "start": "722500",
    "end": "727769"
  },
  {
    "text": "we want speed because we don't want to wait any time at all for our dashboards",
    "start": "727769",
    "end": "733029"
  },
  {
    "text": "to draw the third thing you might not be",
    "start": "733029",
    "end": "738790"
  },
  {
    "text": "so immediately aware of durability what do I mean by this so so you can put",
    "start": "738790",
    "end": "745990"
  },
  {
    "text": "something on a disk and if you're going to store it for years or months or whatever you gonna store a lot of it we",
    "start": "745990",
    "end": "752890"
  },
  {
    "text": "have hundreds of terabytes of this stuff then your disk is going to fail so you",
    "start": "752890",
    "end": "762040"
  },
  {
    "text": "need to store multiple copies on disk to save yourself when one of those copies",
    "start": "762040",
    "end": "768250"
  },
  {
    "text": "fails and then when one of them inevitably does fail you need to make a",
    "start": "768250",
    "end": "773920"
  },
  {
    "text": "new copy from one of the other copies that you were hanging on to right so",
    "start": "773920",
    "end": "779380"
  },
  {
    "text": "that's that's a kind of anti entropy function they call it in order to have",
    "start": "779380",
    "end": "785320"
  },
  {
    "text": "durability for the long term at enormous scale so that's a lot of work and if",
    "start": "785320",
    "end": "793240"
  },
  {
    "text": "there's one thing I can tell you about me and Tom we don't like doing any work so",
    "start": "793240",
    "end": "799790"
  },
  {
    "text": "so we get someone else to do that work so cortex can speak to a variety of",
    "start": "799790",
    "end": "807500"
  },
  {
    "text": "back-end stores Cassandra very well known one dynamodb",
    "start": "807500",
    "end": "813770"
  },
  {
    "text": "or s3 from Amazon BigTable Google cloud store so there's two kinds of store on",
    "start": "813770",
    "end": "821090"
  },
  {
    "text": "there the the table oriented ones like DynamoDB are used for the index and the",
    "start": "821090",
    "end": "829130"
  },
  {
    "text": "the sort of bucket oriented ones generally used for the the chunks the",
    "start": "829130",
    "end": "834200"
  },
  {
    "text": "the the actual time series chunks that we've stored from the in gesture",
    "start": "834200",
    "end": "840040"
  },
  {
    "text": "although that that isn't an an iron rule we we do also have the capability to",
    "start": "840040",
    "end": "845600"
  },
  {
    "text": "store chunks in DynamoDB and in BigTable and in Cassandra so anyway there's",
    "start": "845600",
    "end": "852800"
  },
  {
    "text": "there's actually more backends coming it's quite a nice kind of adapter pattern but yeah we do we do rely on",
    "start": "852800",
    "end": "861890"
  },
  {
    "text": "someone else to do this work of making the data durable and also also running",
    "start": "861890",
    "end": "867580"
  },
  {
    "text": "index lookups at enormous speed at enormous scale so look a little bit more",
    "start": "867580",
    "end": "876770"
  },
  {
    "start": "875000",
    "end": "875000"
  },
  {
    "text": "into the detail of the index it's called an inverted index",
    "start": "876770",
    "end": "884200"
  },
  {
    "text": "what are we mean by this we so I've got an example there of a Prometheus metric",
    "start": "884200",
    "end": "891520"
  },
  {
    "text": "so every metric has a name HTTP duration seconds in this case and it has a set of",
    "start": "891520",
    "end": "897590"
  },
  {
    "text": "labels and each label has a value so job equals shipping instance equals a path",
    "start": "897590",
    "end": "902900"
  },
  {
    "text": "equals foo result equals 200 the average tends to be about 10-12 labels",
    "start": "902900",
    "end": "908120"
  },
  {
    "text": "parametric and the the concept of in inverted index is we we break all of",
    "start": "908120",
    "end": "913400"
  },
  {
    "text": "those values out of that role and we we store them separately we store a list",
    "start": "913400",
    "end": "919130"
  },
  {
    "text": "against those so so we kind of have an",
    "start": "919130",
    "end": "925700"
  },
  {
    "text": "index for each label against each metric and we have all the possible values",
    "start": "925700",
    "end": "931940"
  },
  {
    "text": "pulled out there and against those we have all the time series this is basically the way that",
    "start": "931940",
    "end": "938540"
  },
  {
    "text": "Google indexes the web right the the you know that the for a word that you're searching for cortex they have a list of",
    "start": "938540",
    "end": "947240"
  },
  {
    "text": "all the web pages that mention that word let's look at the the read side of that",
    "start": "947240",
    "end": "954290"
  },
  {
    "start": "951000",
    "end": "951000"
  },
  {
    "text": "if we want to if we have a query a prompt to our query I want to summarize all the or view all",
    "start": "954290",
    "end": "962810"
  },
  {
    "text": "the time series that have job equals shipping what I do is I go to that row",
    "start": "962810",
    "end": "968900"
  },
  {
    "text": "in the index first of all for the the job label look up shipping that gets me",
    "start": "968900",
    "end": "975740"
  },
  {
    "text": "a set of time series for each time",
    "start": "975740",
    "end": "981260"
  },
  {
    "text": "series I look it up for the right time boundary and I'm the last hour or the last week or whatever that gets me a set",
    "start": "981260",
    "end": "988970"
  },
  {
    "text": "of those chunks I bring the chunks in and unpack those into the individual",
    "start": "988970",
    "end": "994580"
  },
  {
    "text": "samples so that's the inverted index again not a novel technique I'm I'm just",
    "start": "994580",
    "end": "1002709"
  },
  {
    "text": "kind of going through how it works but pretty pretty common technique for this",
    "start": "1002709",
    "end": "1009190"
  },
  {
    "text": "kind of large-scale database okay so",
    "start": "1009190",
    "end": "1016440"
  },
  {
    "start": "1016000",
    "end": "1016000"
  },
  {
    "text": "back to my picture at the beginning this is the query err piece and again this is horizontally scalable I can add queriers",
    "start": "1016440",
    "end": "1022930"
  },
  {
    "text": "if I have more people looking up you know more people viewing dashboards I",
    "start": "1022930",
    "end": "1029199"
  },
  {
    "text": "can add queriers they're all independent they just talked to the store the store is massively scalable because I'm paying",
    "start": "1029199",
    "end": "1035438"
  },
  {
    "text": "Amazon vast amounts of money for it or whoever Google other other cloud stores",
    "start": "1035439",
    "end": "1041290"
  },
  {
    "text": "are available one little wrinkle the you",
    "start": "1041290",
    "end": "1048130"
  },
  {
    "text": "know I mentioned that the the samples are compressed in memory they're kind of chunked up to a few hours in memory so",
    "start": "1048130",
    "end": "1056110"
  },
  {
    "text": "we also need to go to the in jesters to get the that last you know last couple",
    "start": "1056110",
    "end": "1062320"
  },
  {
    "text": "of hours of data is going to be in memory we need to check there as well as in the store and then we do like everything to go",
    "start": "1062320",
    "end": "1070090"
  },
  {
    "text": "fast so we put a cache on there we do a lot of caching we cache index lookups we",
    "start": "1070090",
    "end": "1077080"
  },
  {
    "text": "cache chunk lookups we cache partial results with cache lot of things and and",
    "start": "1077080",
    "end": "1083800"
  },
  {
    "text": "to stress the the the micro service nature of this the the fact that we've",
    "start": "1083800",
    "end": "1089410"
  },
  {
    "text": "broken it up into pieces lets us maybe maybe this is a place where we kind of innovate a bit we get",
    "start": "1089410",
    "end": "1096220"
  },
  {
    "text": "creative and add more kinds of queriers and more kinds of caches and we can do",
    "start": "1096220",
    "end": "1101230"
  },
  {
    "text": "that fairly freely because we it's AA split into bits ok so put it all",
    "start": "1101230",
    "end": "1109660"
  },
  {
    "text": "together oh no one more thing one more thing sorry yeah reality so so maybe",
    "start": "1109660",
    "end": "1116140"
  },
  {
    "start": "1110000",
    "end": "1110000"
  },
  {
    "text": "some of you are thinking hang on you're holding my data in memory for hours what happens if it crashes obviously my",
    "start": "1116140",
    "end": "1124000"
  },
  {
    "text": "software doesn't crash but you might have patched it or something I might",
    "start": "1124000",
    "end": "1129220"
  },
  {
    "text": "crash anyway the the the the answer is we we actually send each sample two",
    "start": "1129220",
    "end": "1136720"
  },
  {
    "text": "three and jester's and we hope that all three of them don't crash that wasn't a",
    "start": "1136720",
    "end": "1143620"
  },
  {
    "text": "joke yeah so we so that the the DHT is",
    "start": "1143620",
    "end": "1156760"
  },
  {
    "text": "actually used to pick consistent set of three in jester's for each time series",
    "start": "1156760",
    "end": "1162780"
  },
  {
    "text": "we build up the samples in memory three times over and we send them to the store",
    "start": "1162780",
    "end": "1168880"
  },
  {
    "text": "and we duplicate later on query okay so now we can put it all together right",
    "start": "1168880",
    "end": "1175480"
  },
  {
    "start": "1175000",
    "end": "1175000"
  },
  {
    "text": "yes spent minutes on these slides yeah",
    "start": "1175480",
    "end": "1181960"
  },
  {
    "text": "put it all together this is our infinitely scalable Prometheus each each",
    "start": "1181960",
    "end": "1189910"
  },
  {
    "text": "section here we can just add processes they do not interlock they do not inter",
    "start": "1189910",
    "end": "1196540"
  },
  {
    "text": "communicate across the the vertical segments here the many many",
    "start": "1196540",
    "end": "1206640"
  },
  {
    "text": "Prometheus's can be sending data in they go into many distributors it probably",
    "start": "1206640",
    "end": "1212070"
  },
  {
    "text": "goes through some kind of load balancer you know like an e lb or something like that they distributors use the DHT to",
    "start": "1212070",
    "end": "1220799"
  },
  {
    "text": "pick in jesters many in jesters the in jesters write to a no sequel store which",
    "start": "1220799",
    "end": "1227460"
  },
  {
    "text": "is massively scalable has however many hundreds of discs we can have as many",
    "start": "1227460",
    "end": "1233490"
  },
  {
    "text": "query or processes as we like and we serve it all out to as many users or as",
    "start": "1233490",
    "end": "1239399"
  },
  {
    "text": "are visiting our site the whole thing is",
    "start": "1239399",
    "end": "1244470"
  },
  {
    "text": "multi tenant front to back so we we give",
    "start": "1244470",
    "end": "1249539"
  },
  {
    "text": "each we call it an instance we you know think in terms of you as a user of the",
    "start": "1249539",
    "end": "1256260"
  },
  {
    "text": "system might have your dev instance your staging instance your production",
    "start": "1256260",
    "end": "1261299"
  },
  {
    "text": "instance or you know whatever however you want to think of these things separately so an instance is not",
    "start": "1261299",
    "end": "1268200"
  },
  {
    "text": "necessarily one customer could have multiple instances but each one has a",
    "start": "1268200",
    "end": "1273270"
  },
  {
    "text": "key as an ID that ID is is carried through the system the ID forms part of",
    "start": "1273270",
    "end": "1281909"
  },
  {
    "text": "the index so we can look up queries for one instance at a time and the whatever",
    "start": "1281909",
    "end": "1288990"
  },
  {
    "text": "is is on the query side you know that we build dashboards you can use something",
    "start": "1288990",
    "end": "1295140"
  },
  {
    "text": "like graph Anna because cortex speaks the exact Prometheus API that that",
    "start": "1295140",
    "end": "1303240"
  },
  {
    "text": "Prometheus does so anything that will talk to Prometheus can be used on the on",
    "start": "1303240",
    "end": "1310260"
  },
  {
    "text": "the query side anything that can provide metrics to Prometheus can be used on the scraping side and we maintain that that",
    "start": "1310260",
    "end": "1316950"
  },
  {
    "text": "multi-tenant ID all the way through so that's some that is the big picture of",
    "start": "1316950",
    "end": "1323070"
  },
  {
    "text": "our infinitely scalable Prometheus now I",
    "start": "1323070",
    "end": "1328500"
  },
  {
    "text": "wanted to mention there's one character who I haven't mentioned",
    "start": "1328500",
    "end": "1334520"
  },
  {
    "text": "in the film well a little bit later",
    "start": "1334520",
    "end": "1345799"
  },
  {
    "text": "Santos is the name of a another project which which is also on github and also",
    "start": "1345799",
    "end": "1355880"
  },
  {
    "text": "seeks to provide highly available Prometheus and long-term storage it's",
    "start": "1355880",
    "end": "1363100"
  },
  {
    "text": "it's quite a bit newer than cortex about a year or so old right now and they they",
    "start": "1363100",
    "end": "1374330"
  },
  {
    "text": "set out with a with a rather different aim which was was to try and keep things",
    "start": "1374330",
    "end": "1379549"
  },
  {
    "text": "simpler trying to keep things closer to the the native Prometheus what is",
    "start": "1379549",
    "end": "1386750"
  },
  {
    "text": "interesting is it's kind of edging I mean you can tell from the from the picture here they it's edging up in",
    "start": "1386750",
    "end": "1394940"
  },
  {
    "text": "complexity they certainly have a more components than they started with but I",
    "start": "1394940",
    "end": "1402980"
  },
  {
    "text": "think what is good is to look at the similarities you know its they're both",
    "start": "1402980",
    "end": "1408140"
  },
  {
    "text": "both projects have a huge reuse of prometheus code both have have this aim",
    "start": "1408140",
    "end": "1415460"
  },
  {
    "text": "when you've split up your metrics to begin with because they're in different",
    "start": "1415460",
    "end": "1420530"
  },
  {
    "text": "data centers or something like that you want to bring them together into a global view they both have that feature",
    "start": "1420530",
    "end": "1427659"
  },
  {
    "text": "they both have this split between recent data in in the Thanos case the recent",
    "start": "1427659",
    "end": "1434870"
  },
  {
    "text": "data is just in the Prometheus and and Prometheus writes it to disk they take those disk blocks and ship them off to",
    "start": "1434870",
    "end": "1442070"
  },
  {
    "text": "long-term storage like like an s3 same kind of thing but there is this split same-same in court excellent arrows",
    "start": "1442070",
    "end": "1448900"
  },
  {
    "text": "there's there's cloud buckets like s3 and as I said they do have multiple",
    "start": "1448900",
    "end": "1455480"
  },
  {
    "text": "components in their architecture so yeah a lot of lot of similarities between the",
    "start": "1455480",
    "end": "1461179"
  },
  {
    "text": "two projects I'll just point out the big difference is multi-tenant right",
    "start": "1461179",
    "end": "1467500"
  },
  {
    "start": "1462000",
    "end": "1462000"
  },
  {
    "text": "sex is a multi-tenant system we needed that we were building a cloud prometheus",
    "start": "1467500",
    "end": "1475120"
  },
  {
    "text": "as a service and we didn't want to we didn't want to kind of install a new Prometheus every time a customer turned",
    "start": "1475120",
    "end": "1482290"
  },
  {
    "text": "up so cortex is is multi-tenant front to back cortex does this automatic sharding",
    "start": "1482290",
    "end": "1491170"
  },
  {
    "text": "based on the the distributed hash table thanassis is kind of starting from the",
    "start": "1491170",
    "end": "1497170"
  },
  {
    "text": "standpoint you you've mark manually divided up your you you have these Prometheus running separately to begin",
    "start": "1497170",
    "end": "1502960"
  },
  {
    "text": "with differences in the storage format so cortex does what I call query",
    "start": "1502960",
    "end": "1511390"
  },
  {
    "text": "sharding so if you do a 30-day query will actually run 31-day queries in",
    "start": "1511390",
    "end": "1516760"
  },
  {
    "text": "parallel to speed that up that's that's a feature that US doesn't have Fallas",
    "start": "1516760",
    "end": "1522250"
  },
  {
    "text": "does down sampling so they can take your old or data maybe you've sampled it at a",
    "start": "1522250",
    "end": "1527550"
  },
  {
    "text": "five-second interval and they can down sample it to a one-minute interval we don't have that feature so healthy",
    "start": "1527550",
    "end": "1534430"
  },
  {
    "text": "competition different projects different aims and I got to make a joke about a",
    "start": "1534430",
    "end": "1540970"
  },
  {
    "text": "film I said on the description of of the",
    "start": "1540970",
    "end": "1550900"
  },
  {
    "start": "1544000",
    "end": "1544000"
  },
  {
    "text": "talk that I talk about our experiences in production we have been running it nearly two years so one of the things is",
    "start": "1550900",
    "end": "1558790"
  },
  {
    "text": "that that anyone can sign up you know if you show up you get a free trial so I",
    "start": "1558790",
    "end": "1564790"
  },
  {
    "text": "knew anyone can kind of I imagine some of you are in this room pointing your notebooks at my service and and trying",
    "start": "1564790",
    "end": "1572320"
  },
  {
    "text": "to break it so yeah this should be fun",
    "start": "1572320",
    "end": "1577570"
  },
  {
    "text": "well anyway then on any random day someone can show up with data that we've never seen before or data in quantities",
    "start": "1577570",
    "end": "1583540"
  },
  {
    "text": "that we've never seen before and we need to deal with that so we learned a lot about about scaling a big back-end",
    "start": "1583540",
    "end": "1591430"
  },
  {
    "text": "system one aspect of that these no",
    "start": "1591430",
    "end": "1598480"
  },
  {
    "text": "sequel the index basically is hard getting that to scale getting it",
    "start": "1598480",
    "end": "1606040"
  },
  {
    "text": "to run efficiently there's there's these two things that are kind of pulling in opposite directions you you you want to",
    "start": "1606040",
    "end": "1613090"
  },
  {
    "text": "parallel ice what you're doing because you have a big back-end this is where",
    "start": "1613090",
    "end": "1620290"
  },
  {
    "text": "I'm talking about something like big table or or DynamoDB Amazon and Google and so on they run that at a huge scale",
    "start": "1620290",
    "end": "1627370"
  },
  {
    "text": "so so on on our side on the code we want to talk to it as many times in parallel",
    "start": "1627370",
    "end": "1633250"
  },
  {
    "text": "as possible however on the flip side you need to batch up your your requests otherwise",
    "start": "1633250",
    "end": "1639190"
  },
  {
    "text": "you the power call overhead is very highs and those things are pulling in opposite directions so kind of kind of",
    "start": "1639190",
    "end": "1644380"
  },
  {
    "text": "tuning and tweaking that is a lot of the work that's gone into cortex also tuning",
    "start": "1644380",
    "end": "1650530"
  },
  {
    "text": "the schema hot spots of you if you write to the same place in the in while in",
    "start": "1650530",
    "end": "1657160"
  },
  {
    "text": "terms of the underlying data store if you write to the same place too often at",
    "start": "1657160",
    "end": "1662200"
  },
  {
    "text": "the same time it'll choke we're sharin Version nine of the schema of exactly",
    "start": "1662200",
    "end": "1668590"
  },
  {
    "text": "how we do that and and hilariously we have to maintain all the code for all",
    "start": "1668590",
    "end": "1674200"
  },
  {
    "text": "the previous eight schemas is all still",
    "start": "1674200",
    "end": "1679570"
  },
  {
    "text": "in there because we you know we actually used this thing in production we still still reading some of that data other",
    "start": "1679570",
    "end": "1688270"
  },
  {
    "text": "experiences out of memory errors I don't know yeah that that's I guess I'm just",
    "start": "1688270",
    "end": "1695980"
  },
  {
    "text": "looking for sympathy here high cardinality queries it's been a little",
    "start": "1695980",
    "end": "1703059"
  },
  {
    "text": "bit of a theme in some of the observability talks around here high",
    "start": "1703059",
    "end": "1709300"
  },
  {
    "text": "cardinality basically the meaning and a",
    "start": "1709300",
    "end": "1714640"
  },
  {
    "text": "lot of time time series behind one metric and by a lot I mean 10 million so",
    "start": "1714640",
    "end": "1723429"
  },
  {
    "text": "it says in the Prometheus documentation that 100,000 should be no problem and",
    "start": "1723429",
    "end": "1729370"
  },
  {
    "text": "that's true enough how do you get to those numbers that basically by putting something like your",
    "start": "1729370",
    "end": "1736230"
  },
  {
    "text": "client IP in as a label you go you know if you have a million customers actually",
    "start": "1736230",
    "end": "1743940"
  },
  {
    "text": "even if you only have a thousand customers but you're running your service on a thousand machines and that",
    "start": "1743940",
    "end": "1749640"
  },
  {
    "text": "multiplies up so you have a million time series now so this is that kind of effect the the labels multiply and and",
    "start": "1749640",
    "end": "1760140"
  },
  {
    "text": "we basically that's still a challenge at",
    "start": "1760140",
    "end": "1765240"
  },
  {
    "text": "some point we bring all the data into memory in order to summarize it and and the thing will blow up if you've got too",
    "start": "1765240",
    "end": "1772680"
  },
  {
    "text": "much of it what else",
    "start": "1772680",
    "end": "1778100"
  },
  {
    "text": "short-lived time series yeah that's another thing though the metadata basically Dwarfs the actual real data",
    "start": "1778100",
    "end": "1785600"
  },
  {
    "text": "anyway looking forward we are trying to",
    "start": "1785600",
    "end": "1794750"
  },
  {
    "text": "have a writer head log meaning we stick stuff on disk early so that if we have a",
    "start": "1794750",
    "end": "1800820"
  },
  {
    "text": "crash and we lose everything in memory then we don't lose hours of data so",
    "start": "1800820",
    "end": "1808470"
  },
  {
    "text": "that's that's the the flipside of when I said earlier I just hope that all three of them don't crash at once if if we",
    "start": "1808470",
    "end": "1814770"
  },
  {
    "text": "have a right head log then that's less of a danger it is a very complicated",
    "start": "1814770",
    "end": "1820080"
  },
  {
    "text": "beast cortex because of all these multi processes microservices pretty complex",
    "start": "1820080",
    "end": "1825750"
  },
  {
    "text": "to run so Tom's been working on a simpler config for that oh yeah we run",
    "start": "1825750",
    "end": "1833160"
  },
  {
    "text": "rules like alerts and things that that is not currently sharded that needs to",
    "start": "1833160",
    "end": "1838230"
  },
  {
    "text": "be charted for scalability we might add downsampling but anyway I hope we get more users i i'd love any of you to join",
    "start": "1838230",
    "end": "1847140"
  },
  {
    "text": "up as a as a user and a doctor as a contributor if you like it's an open",
    "start": "1847140",
    "end": "1852930"
  },
  {
    "text": "source project and it grows with the community so yeah please please visit",
    "start": "1852930",
    "end": "1859830"
  },
  {
    "text": "the project take out your phone or your laptop now and star on Hubb because my pay is directly tied to",
    "start": "1859830",
    "end": "1867760"
  },
  {
    "text": "the number of stars no it isn't and yeah",
    "start": "1867760",
    "end": "1874420"
  },
  {
    "text": "thank you I guess we have time for a",
    "start": "1874420",
    "end": "1885070"
  },
  {
    "text": "couple of questions if anyone wants to go there I have a question back there as a microphone and you want to try",
    "start": "1885070",
    "end": "1891010"
  },
  {
    "text": "shouting or I got if I have a chair",
    "start": "1891010",
    "end": "1898120"
  },
  {
    "text": "mirrored Prometheus pair I believe Thanos does dee doop do you guys handle",
    "start": "1898120",
    "end": "1904390"
  },
  {
    "text": "that as well yeah so that so the I guess",
    "start": "1904390",
    "end": "1910000"
  },
  {
    "text": "the point you're making is is that on the scraping side there's a single point",
    "start": "1910000",
    "end": "1915820"
  },
  {
    "text": "of failure and yeah in the Thanos project the way you deal with that is by",
    "start": "1915820",
    "end": "1920950"
  },
  {
    "text": "running two of them scrape everything twice and then deegeu and we do not have",
    "start": "1920950",
    "end": "1926230"
  },
  {
    "text": "that feature in cortex I mean basically basically we're not",
    "start": "1926230",
    "end": "1931510"
  },
  {
    "text": "putting any we're not we're not getting that process to do any work in the in",
    "start": "1931510",
    "end": "1936550"
  },
  {
    "text": "the cortex model it's just scraping and immediately sending the samples so if something goes wrong with it you know if",
    "start": "1936550",
    "end": "1942550"
  },
  {
    "text": "it crashes it'll just restart it's it's really in the furnace model it's holding",
    "start": "1942550",
    "end": "1948280"
  },
  {
    "text": "a lot of data and it's used for queries so so it's more important that it's a",
    "start": "1948280",
    "end": "1953740"
  },
  {
    "text": "che in in the cortex model the the originating Prometheus is it's kind of",
    "start": "1953740",
    "end": "1959110"
  },
  {
    "text": "ephemeral you know if if it's sending us samples we've got them mm-hmm if it's",
    "start": "1959110",
    "end": "1964270"
  },
  {
    "text": "got a problem it's not sending us samples so yeah that is a feature we",
    "start": "1964270",
    "end": "1969820"
  },
  {
    "text": "could add but it's less of a sort of critical point in cortex one more quick",
    "start": "1969820",
    "end": "1975550"
  },
  {
    "text": "question the alert rules and recording rules so I understand at a high level I",
    "start": "1975550",
    "end": "1982150"
  },
  {
    "text": "can look at your system as a long-term retention and global query can I also define alert rules and recording rules",
    "start": "1982150",
    "end": "1988990"
  },
  {
    "text": "at a at a global level on the adjuster nodes are somewhere yeah so we have a",
    "start": "1988990",
    "end": "1994540"
  },
  {
    "text": "component called the ruler which runs according rules and alerts just you know",
    "start": "1994540",
    "end": "1999940"
  },
  {
    "text": "exactly the same way as Prometheus runs them and I didn't include it in the talk",
    "start": "1999940",
    "end": "2005690"
  },
  {
    "text": "for reasons of time but yes it exists hello hi hi so you were talking about",
    "start": "2005690",
    "end": "2013620"
  },
  {
    "text": "the flesh failures in the in jesters okay so what is it common approaches you",
    "start": "2013620",
    "end": "2020130"
  },
  {
    "text": "take those all those two have problems is it is it like what I am thinking is it's like the the ingestion is happening",
    "start": "2020130",
    "end": "2026010"
  },
  {
    "text": "very fast versus the the system the storage is not able to handle the the load right yeah so your question is you",
    "start": "2026010",
    "end": "2033870"
  },
  {
    "text": "know I talked about in jesters getting choked up and being unable to flush yeah what causes that so in in DynamoDB well",
    "start": "2033870",
    "end": "2047520"
  },
  {
    "text": "up until about two weeks ago you had you got to pick a capacity level you paid",
    "start": "2047520",
    "end": "2052580"
  },
  {
    "text": "pre-selected the capacity level so if you select that to load then it'll just back up in memory and I I'm I'm sure I",
    "start": "2052580",
    "end": "2061919"
  },
  {
    "text": "am one of the hundred experts in the world on scaling DynamoDB because I've done it a thousand times I are also one",
    "start": "2061920",
    "end": "2071909"
  },
  {
    "text": "of the top 100 people in the world for modesty yes so that's one reason yes so",
    "start": "2071910",
    "end": "2079590"
  },
  {
    "text": "if you for whatever reason if you're running Cassandra yourself you'd have the same problem you've picked a fixed level of capacity and if you're if",
    "start": "2079590",
    "end": "2087389"
  },
  {
    "text": "you're trying to flush chunks faster than that so that what is nice is the in jesters can kind of grow and shrink they",
    "start": "2087390",
    "end": "2093899"
  },
  {
    "text": "don't they don't need to flush immediately you can have a one hour backlog as long as it's not going up",
    "start": "2093900",
    "end": "2099360"
  },
  {
    "text": "forever as long as as long as it comes down at some point you find some more capacity find a new credit card to put",
    "start": "2099360",
    "end": "2106170"
  },
  {
    "text": "on the Amazon bill then it so that's one reason just not enough capacity in the",
    "start": "2106170",
    "end": "2111750"
  },
  {
    "text": "backend some of that stuff like short live time series is is a surprising",
    "start": "2111750",
    "end": "2119250"
  },
  {
    "text": "problem you know like I mentioned on the slide apache spark will like run pods for for 10 seconds run like a thousand",
    "start": "2119250",
    "end": "2127710"
  },
  {
    "text": "pods for 10 seconds and so we we barely get one Sam actually what we should probably do is",
    "start": "2127710",
    "end": "2133030"
  },
  {
    "text": "throw it away because it's very little you can do with the query but but that has been a case you know how I said any",
    "start": "2133030",
    "end": "2140050"
  },
  {
    "text": "random person can sign up on the web we we have limits in there now we have we",
    "start": "2140050",
    "end": "2146710"
  },
  {
    "text": "have a bunch of kind of soft limits in the software to kind of avoid just",
    "start": "2146710",
    "end": "2153310"
  },
  {
    "text": "getting taken down by someone who has an exciting kind of data but that's that's",
    "start": "2153310",
    "end": "2159430"
  },
  {
    "text": "another another kind of reason if it's just a lot of tiny tiny chunks then then",
    "start": "2159430",
    "end": "2165490"
  },
  {
    "text": "it's going to need a lot more resource than you were thinking of we're at time",
    "start": "2165490",
    "end": "2171790"
  },
  {
    "text": "okay well thank you very much I'm here all week come to the weave Works booth [Applause]",
    "start": "2171790",
    "end": "2180449"
  }
]
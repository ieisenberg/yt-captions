[
  {
    "start": "0",
    "end": "415000"
  },
  {
    "text": "so for both of us it's our first keep",
    "start": "30",
    "end": "1979"
  },
  {
    "text": "God and naturally first keep contact so",
    "start": "1979",
    "end": "4020"
  },
  {
    "text": "we're we're excited big room lots of",
    "start": "4020",
    "end": "6629"
  },
  {
    "text": "people hopefully you'll take back all of",
    "start": "6629",
    "end": "10170"
  },
  {
    "text": "the things we tell you and actually",
    "start": "10170",
    "end": "11700"
  },
  {
    "text": "implement them in your organization so I",
    "start": "11700",
    "end": "15480"
  },
  {
    "text": "want to start off with kind of a not",
    "start": "15480",
    "end": "18960"
  },
  {
    "text": "quite relevant to keep kubernetes or",
    "start": "18960",
    "end": "21180"
  },
  {
    "text": "cube con project this was a github repo",
    "start": "21180",
    "end": "24480"
  },
  {
    "text": "of Brad Fitzpatrick another Googler and",
    "start": "24480",
    "end": "27570"
  },
  {
    "text": "he was writing about his home lab setup",
    "start": "27570",
    "end": "30390"
  },
  {
    "text": "and his home internet setup some of you",
    "start": "30390",
    "end": "32550"
  },
  {
    "text": "might have seen this unhappy news and",
    "start": "32550",
    "end": "35910"
  },
  {
    "text": "his goal was hey I want hive highly",
    "start": "35910",
    "end": "38670"
  },
  {
    "text": "available internet access for my home",
    "start": "38670",
    "end": "41190"
  },
  {
    "text": "lab and I don't want any single points",
    "start": "41190",
    "end": "43440"
  },
  {
    "text": "of failure and so you know if you've",
    "start": "43440",
    "end": "46379"
  },
  {
    "text": "built any labs or any systems at home or",
    "start": "46379",
    "end": "50250"
  },
  {
    "text": "in your organization you might know that",
    "start": "50250",
    "end": "52320"
  },
  {
    "text": "there's redundant power supplies",
    "start": "52320",
    "end": "54690"
  },
  {
    "text": "redundant Wi-Fi switches network access",
    "start": "54690",
    "end": "57809"
  },
  {
    "text": "points and so on but I also saw he had",
    "start": "57809",
    "end": "60059"
  },
  {
    "text": "two ISPs a lot of us don't even have two",
    "start": "60059",
    "end": "62250"
  },
  {
    "text": "eyes piece to choose from and I thought",
    "start": "62250",
    "end": "65430"
  },
  {
    "text": "about it and it makes sense if there is",
    "start": "65430",
    "end": "67860"
  },
  {
    "text": "no single point of failure it makes",
    "start": "67860",
    "end": "70680"
  },
  {
    "text": "sense to prevent yourself head yourself",
    "start": "70680",
    "end": "72570"
  },
  {
    "text": "from a rat chewing through your fiber",
    "start": "72570",
    "end": "74310"
  },
  {
    "text": "and going with a broadband as a",
    "start": "74310",
    "end": "76350"
  },
  {
    "text": "secondary and so what does this have to",
    "start": "76350",
    "end": "78930"
  },
  {
    "text": "do with kubernetes we're at coop con not",
    "start": "78930",
    "end": "80909"
  },
  {
    "text": "lab con after all",
    "start": "80909",
    "end": "82939"
  },
  {
    "text": "so kubernetes is some of you might know",
    "start": "82939",
    "end": "86610"
  },
  {
    "text": "it's a distributed container",
    "start": "86610",
    "end": "88200"
  },
  {
    "text": "orchestration system it is great it's",
    "start": "88200",
    "end": "91409"
  },
  {
    "text": "based on Google's knowledge of after",
    "start": "91409",
    "end": "93960"
  },
  {
    "text": "running billions of containers every",
    "start": "93960",
    "end": "95939"
  },
  {
    "text": "single week on a distributed planet",
    "start": "95939",
    "end": "98159"
  },
  {
    "text": "scale but really planet skill doesn't",
    "start": "98159",
    "end": "101040"
  },
  {
    "text": "really mean anything if you don't have",
    "start": "101040",
    "end": "102990"
  },
  {
    "text": "redundancy and high availability if one",
    "start": "102990",
    "end": "105570"
  },
  {
    "text": "of the components of your system goes",
    "start": "105570",
    "end": "107549"
  },
  {
    "text": "down and that causes all of the other",
    "start": "107549",
    "end": "109560"
  },
  {
    "text": "systems to not be available doesn't",
    "start": "109560",
    "end": "112740"
  },
  {
    "text": "matter how much you scale it's not good",
    "start": "112740",
    "end": "115020"
  },
  {
    "text": "for you so and I get a feel for the room",
    "start": "115020",
    "end": "117570"
  },
  {
    "text": "of feel for the room here how many",
    "start": "117570",
    "end": "119880"
  },
  {
    "text": "people use kubernetes right now one or",
    "start": "119880",
    "end": "123960"
  },
  {
    "text": "two people okay and how many people have",
    "start": "123960",
    "end": "127170"
  },
  {
    "text": "actually deployed a kubernetes cluster",
    "start": "127170",
    "end": "128610"
  },
  {
    "text": "not using a management service quite a",
    "start": "128610",
    "end": "132270"
  },
  {
    "text": "few ops people and how many",
    "start": "132270",
    "end": "133890"
  },
  {
    "text": "have done h a cluster setups Wow a lot",
    "start": "133890",
    "end": "137460"
  },
  {
    "text": "of people great and how many of you have",
    "start": "137460",
    "end": "140340"
  },
  {
    "text": "been asked to raise your hand at a",
    "start": "140340",
    "end": "141569"
  },
  {
    "text": "conference before cool so hi my name is",
    "start": "141569",
    "end": "147360"
  },
  {
    "text": "Karan Goyal I'm a software engineer at",
    "start": "147360",
    "end": "149370"
  },
  {
    "text": "Google and here in Seattle and I work on",
    "start": "149370",
    "end": "152190"
  },
  {
    "text": "gke on Prem some of you might know about",
    "start": "152190",
    "end": "154920"
  },
  {
    "text": "that and I'm making challenge I'm also a",
    "start": "154920",
    "end": "157680"
  },
  {
    "text": "software engineer on the GK on Prem team",
    "start": "157680",
    "end": "160140"
  },
  {
    "text": "at Google and before I joined this team",
    "start": "160140",
    "end": "162090"
  },
  {
    "text": "I was on a different team at Google that",
    "start": "162090",
    "end": "163590"
  },
  {
    "text": "worked on the Cloud Foundry container",
    "start": "163590",
    "end": "165569"
  },
  {
    "text": "runtime so that's another kubernetes",
    "start": "165569",
    "end": "168000"
  },
  {
    "text": "project so I've been working in the",
    "start": "168000",
    "end": "169410"
  },
  {
    "text": "kubernetes space for about two years",
    "start": "169410",
    "end": "172790"
  },
  {
    "text": "okay so let's come back to this question",
    "start": "172790",
    "end": "175050"
  },
  {
    "text": "because I don't think we've quite",
    "start": "175050",
    "end": "176190"
  },
  {
    "text": "answered this yet what is high",
    "start": "176190",
    "end": "178050"
  },
  {
    "text": "availability anyways basically what it",
    "start": "178050",
    "end": "180900"
  },
  {
    "text": "means is that you want to have a high",
    "start": "180900",
    "end": "182400"
  },
  {
    "text": "SLO or a service level objective so you",
    "start": "182400",
    "end": "186360"
  },
  {
    "text": "have a certain amount of availability",
    "start": "186360",
    "end": "187860"
  },
  {
    "text": "that you promise so for example GK has",
    "start": "187860",
    "end": "192000"
  },
  {
    "text": "an H a product called GK a regional",
    "start": "192000",
    "end": "194610"
  },
  {
    "text": "clusters and the control plane of those",
    "start": "194610",
    "end": "196650"
  },
  {
    "text": "clusters is available in ninety nine",
    "start": "196650",
    "end": "198810"
  },
  {
    "text": "point nine five percent of the time so",
    "start": "198810",
    "end": "200640"
  },
  {
    "text": "great now we know high availability",
    "start": "200640",
    "end": "202950"
  },
  {
    "text": "means you want to be available a lot",
    "start": "202950",
    "end": "205200"
  },
  {
    "text": "that's not super helpful but basically",
    "start": "205200",
    "end": "209220"
  },
  {
    "text": "what we want to talk about today is how",
    "start": "209220",
    "end": "210660"
  },
  {
    "text": "we're going to achieve that how do we",
    "start": "210660",
    "end": "213180"
  },
  {
    "text": "make sure that our system has no failure",
    "start": "213180",
    "end": "215970"
  },
  {
    "text": "points that could take down our whole",
    "start": "215970",
    "end": "217709"
  },
  {
    "text": "system that weren't redundant so if we",
    "start": "217709",
    "end": "220709"
  },
  {
    "text": "bring it back to the home internet set",
    "start": "220709",
    "end": "222090"
  },
  {
    "text": "up that's exactly what Brad Fitzpatrick",
    "start": "222090",
    "end": "224040"
  },
  {
    "text": "did for his own internet set up we're",
    "start": "224040",
    "end": "226530"
  },
  {
    "text": "gonna do that for our clusters before we",
    "start": "226530",
    "end": "231510"
  },
  {
    "text": "get too far into that I want to talk",
    "start": "231510",
    "end": "233400"
  },
  {
    "text": "about multi master or multi controller",
    "start": "233400",
    "end": "235470"
  },
  {
    "text": "nodes this means that you're running",
    "start": "235470",
    "end": "237329"
  },
  {
    "text": "multiple copies of your control plans so",
    "start": "237329",
    "end": "239430"
  },
  {
    "text": "that if any of the copies fail you have",
    "start": "239430",
    "end": "241530"
  },
  {
    "text": "other ones to come take up the work and",
    "start": "241530",
    "end": "244890"
  },
  {
    "text": "that's great that's a really important",
    "start": "244890",
    "end": "246390"
  },
  {
    "text": "part of high availability but in a lot",
    "start": "246390",
    "end": "248700"
  },
  {
    "text": "of cases it's not enough we want to look",
    "start": "248700",
    "end": "250890"
  },
  {
    "text": "at every layer of our stack including",
    "start": "250890",
    "end": "252660"
  },
  {
    "text": "the control plane networking",
    "start": "252660",
    "end": "255109"
  },
  {
    "text": "applications and persistence and make",
    "start": "255109",
    "end": "257640"
  },
  {
    "text": "sure that we don't have single points of",
    "start": "257640",
    "end": "259229"
  },
  {
    "text": "failure within any point in the system",
    "start": "259229",
    "end": "262490"
  },
  {
    "text": "what kind of failures are we talking",
    "start": "262490",
    "end": "264599"
  },
  {
    "text": "about there are so many things that can",
    "start": "264599",
    "end": "266039"
  },
  {
    "text": "fail in our",
    "start": "266039",
    "end": "266639"
  },
  {
    "text": "system and we want to make sure that we",
    "start": "266639",
    "end": "268560"
  },
  {
    "text": "talk about a lot of them and plan for",
    "start": "268560",
    "end": "271499"
  },
  {
    "text": "all of those failures so we could have",
    "start": "271499",
    "end": "273990"
  },
  {
    "text": "failures in our application so if we're",
    "start": "273990",
    "end": "276150"
  },
  {
    "text": "running an application we want to make",
    "start": "276150",
    "end": "277590"
  },
  {
    "text": "sure we're running multiple copies of it",
    "start": "277590",
    "end": "279150"
  },
  {
    "text": "so that if one of them fails we don't",
    "start": "279150",
    "end": "281159"
  },
  {
    "text": "necessarily care why as long as there",
    "start": "281159",
    "end": "283319"
  },
  {
    "text": "are other ones available to take up the",
    "start": "283319",
    "end": "285029"
  },
  {
    "text": "work but if we were running all of those",
    "start": "285029",
    "end": "288120"
  },
  {
    "text": "copies on the same VM then we would care",
    "start": "288120",
    "end": "290610"
  },
  {
    "text": "if that failed so we need to make sure",
    "start": "290610",
    "end": "292499"
  },
  {
    "text": "that we're spreading our workloads",
    "start": "292499",
    "end": "293729"
  },
  {
    "text": "across VMs as well and similarly if all",
    "start": "293729",
    "end": "296969"
  },
  {
    "text": "of those VMs were running on the same",
    "start": "296969",
    "end": "298319"
  },
  {
    "text": "physical machine then we can't handle a",
    "start": "298319",
    "end": "300509"
  },
  {
    "text": "failure of that physical machine either",
    "start": "300509",
    "end": "302069"
  },
  {
    "text": "so we want to run ideally across",
    "start": "302069",
    "end": "304020"
  },
  {
    "text": "physical machines and then you can",
    "start": "304020",
    "end": "306000"
  },
  {
    "text": "imagine there are other things that",
    "start": "306000",
    "end": "307259"
  },
  {
    "text": "could fail also so if we're running",
    "start": "307259",
    "end": "309870"
  },
  {
    "text": "three physical machines but they're all",
    "start": "309870",
    "end": "312389"
  },
  {
    "text": "connected to the same power source or",
    "start": "312389",
    "end": "314009"
  },
  {
    "text": "they're all using the same cooling",
    "start": "314009",
    "end": "315539"
  },
  {
    "text": "system we can't handle failures and",
    "start": "315539",
    "end": "317460"
  },
  {
    "text": "those them either we also want to make",
    "start": "317460",
    "end": "320310"
  },
  {
    "text": "sure we handle network partitions so if",
    "start": "320310",
    "end": "322650"
  },
  {
    "text": "a network switch fails in our lab the",
    "start": "322650",
    "end": "325409"
  },
  {
    "text": "nodes can't communicate with each other",
    "start": "325409",
    "end": "327120"
  },
  {
    "text": "we want to make sure we know what's",
    "start": "327120",
    "end": "328830"
  },
  {
    "text": "going to happen in the system if that",
    "start": "328830",
    "end": "330150"
  },
  {
    "text": "happens and storage is a really critical",
    "start": "330150",
    "end": "332819"
  },
  {
    "text": "one",
    "start": "332819",
    "end": "333240"
  },
  {
    "text": "if we lose storage we need to make sure",
    "start": "333240",
    "end": "335610"
  },
  {
    "text": "we don't lose the data because that can",
    "start": "335610",
    "end": "337529"
  },
  {
    "text": "be irreversible on GK or a little bit",
    "start": "337529",
    "end": "342659"
  },
  {
    "text": "lucky because we have this concept of",
    "start": "342659",
    "end": "344580"
  },
  {
    "text": "regions and zones and this encapsulate",
    "start": "344580",
    "end": "346800"
  },
  {
    "text": "Sal OTT of the things that I just talked",
    "start": "346800",
    "end": "348149"
  },
  {
    "text": "about regions are geographical areas so",
    "start": "348149",
    "end": "352409"
  },
  {
    "text": "those are very isolated from each other",
    "start": "352409",
    "end": "354029"
  },
  {
    "text": "if you're running across regions you can",
    "start": "354029",
    "end": "356039"
  },
  {
    "text": "even handle like natural disasters in",
    "start": "356039",
    "end": "357839"
  },
  {
    "text": "one area and then zones are a deployment",
    "start": "357839",
    "end": "361169"
  },
  {
    "text": "area within a region that is independent",
    "start": "361169",
    "end": "363870"
  },
  {
    "text": "they're independent from each other in a",
    "start": "363870",
    "end": "365189"
  },
  {
    "text": "lot of ways like if you're running",
    "start": "365189",
    "end": "366810"
  },
  {
    "text": "across zones then you know you have",
    "start": "366810",
    "end": "368610"
  },
  {
    "text": "different power sources you know you",
    "start": "368610",
    "end": "369960"
  },
  {
    "text": "have different cooling systems and",
    "start": "369960",
    "end": "371370"
  },
  {
    "text": "usually they're running in different",
    "start": "371370",
    "end": "372629"
  },
  {
    "text": "areas of the datacenter as well and the",
    "start": "372629",
    "end": "375509"
  },
  {
    "text": "reason I'm telling you this is because",
    "start": "375509",
    "end": "376770"
  },
  {
    "text": "through most of this talk we're going to",
    "start": "376770",
    "end": "378210"
  },
  {
    "text": "use zones as our failure domain and I",
    "start": "378210",
    "end": "380430"
  },
  {
    "text": "just want you to remember that that",
    "start": "380430",
    "end": "381539"
  },
  {
    "text": "already encapsulate Sal OTT of these",
    "start": "381539",
    "end": "383159"
  },
  {
    "text": "failures that I talked about but you can",
    "start": "383159",
    "end": "386250"
  },
  {
    "text": "also replicate this in your own setup if",
    "start": "386250",
    "end": "388439"
  },
  {
    "text": "you're running on Prem okay so we've",
    "start": "388439",
    "end": "391560"
  },
  {
    "text": "divided our talk into three sections",
    "start": "391560",
    "end": "393120"
  },
  {
    "text": "first we have applications how do we run",
    "start": "393120",
    "end": "395610"
  },
  {
    "text": "applications on kubernetes",
    "start": "395610",
    "end": "397590"
  },
  {
    "text": "in highly available way then we'll talk",
    "start": "397590",
    "end": "399960"
  },
  {
    "text": "about kubernetes itself the control",
    "start": "399960",
    "end": "402090"
  },
  {
    "text": "plane how do we run the controller",
    "start": "402090",
    "end": "403710"
  },
  {
    "text": "manager the API server and the scheduler",
    "start": "403710",
    "end": "405960"
  },
  {
    "text": "for kubernetes in a highly available way",
    "start": "405960",
    "end": "407970"
  },
  {
    "text": "and we split out at CD as a special part",
    "start": "407970",
    "end": "410820"
  },
  {
    "text": "because it's our data layer we want we",
    "start": "410820",
    "end": "412830"
  },
  {
    "text": "have a couple of extra considerations",
    "start": "412830",
    "end": "414330"
  },
  {
    "text": "there there we go",
    "start": "414330",
    "end": "426000"
  },
  {
    "start": "415000",
    "end": "704000"
  },
  {
    "text": "so we want to talk about application",
    "start": "426000",
    "end": "427470"
  },
  {
    "text": "high availability first because it makes",
    "start": "427470",
    "end": "430110"
  },
  {
    "text": "intuitively a little bit more sense a",
    "start": "430110",
    "end": "432360"
  },
  {
    "text": "lot of the features and functionality",
    "start": "432360",
    "end": "434550"
  },
  {
    "text": "we'll talk about is packaged and in",
    "start": "434550",
    "end": "436650"
  },
  {
    "text": "kubernetes and comes out of the box so",
    "start": "436650",
    "end": "439320"
  },
  {
    "text": "it'll be a little bit easier to",
    "start": "439320",
    "end": "440580"
  },
  {
    "text": "understand here so we're gonna assume",
    "start": "440580",
    "end": "442410"
  },
  {
    "text": "that we're running this cluster with",
    "start": "442410",
    "end": "444810"
  },
  {
    "text": "three replicas of our workload the green",
    "start": "444810",
    "end": "448050"
  },
  {
    "text": "boxes are VMs and the orange yellow",
    "start": "448050",
    "end": "450960"
  },
  {
    "text": "boxes are workloads containers pods and",
    "start": "450960",
    "end": "454860"
  },
  {
    "text": "you can see that we're running our VMs",
    "start": "454860",
    "end": "457200"
  },
  {
    "text": "across three different zones of a region",
    "start": "457200",
    "end": "459600"
  },
  {
    "text": "and like Megan said these happen to be",
    "start": "459600",
    "end": "461520"
  },
  {
    "text": "in different data centers across",
    "start": "461520",
    "end": "463600"
  },
  {
    "text": "[Music]",
    "start": "463600",
    "end": "464780"
  },
  {
    "text": "different physical locations but in the",
    "start": "464780",
    "end": "467010"
  },
  {
    "text": "same region so let's assume that we are",
    "start": "467010",
    "end": "471660"
  },
  {
    "text": "running these workloads they are",
    "start": "471660",
    "end": "472950"
  },
  {
    "text": "scheduled over three different PN's over",
    "start": "472950",
    "end": "474930"
  },
  {
    "text": "three different zones this concept of",
    "start": "474930",
    "end": "477810"
  },
  {
    "text": "scheduling across different zones is not",
    "start": "477810",
    "end": "479820"
  },
  {
    "text": "native and primitive in kubernetes I'll",
    "start": "479820",
    "end": "482730"
  },
  {
    "text": "talk in a little bit about how to go",
    "start": "482730",
    "end": "484140"
  },
  {
    "text": "about achieving that and let's say one",
    "start": "484140",
    "end": "487020"
  },
  {
    "text": "of our zones the one on the further",
    "start": "487020",
    "end": "488550"
  },
  {
    "text": "right goes down we're lucky because our",
    "start": "488550",
    "end": "491340"
  },
  {
    "text": "control plane is not running there in",
    "start": "491340",
    "end": "493980"
  },
  {
    "text": "this case the scheduler will see that",
    "start": "493980",
    "end": "495900"
  },
  {
    "text": "hey I was supposed to run through your",
    "start": "495900",
    "end": "498030"
  },
  {
    "text": "replicas but there's only two running so",
    "start": "498030",
    "end": "500070"
  },
  {
    "text": "let me just get you'll schedule one more",
    "start": "500070",
    "end": "502440"
  },
  {
    "text": "and bring up the running count to three",
    "start": "502440",
    "end": "504420"
  },
  {
    "text": "and it happens to land in zone D so this",
    "start": "504420",
    "end": "511350"
  },
  {
    "text": "is this is probably what you're most",
    "start": "511350",
    "end": "513150"
  },
  {
    "text": "familiar with as a developer as someone",
    "start": "513150",
    "end": "515130"
  },
  {
    "text": "who is deploying the workload on",
    "start": "515130",
    "end": "516360"
  },
  {
    "text": "kubernetes is a concept of a deployment",
    "start": "516360",
    "end": "518940"
  },
  {
    "text": "or a replica set or a replica you would",
    "start": "518940",
    "end": "523260"
  },
  {
    "text": "run your pod as a deployment and you",
    "start": "523260",
    "end": "525870"
  },
  {
    "text": "would set the replicas in our case to be",
    "start": "525870",
    "end": "527940"
  },
  {
    "text": "three the second more important thing",
    "start": "527940",
    "end": "530370"
  },
  {
    "text": "here is",
    "start": "530370",
    "end": "531100"
  },
  {
    "text": "rolling updates or just update type in",
    "start": "531100",
    "end": "533079"
  },
  {
    "text": "general if you try to update all of your",
    "start": "533079",
    "end": "536310"
  },
  {
    "text": "pods and container if you try to update",
    "start": "536310",
    "end": "539319"
  },
  {
    "text": "your deployment and you don't set a",
    "start": "539319",
    "end": "542199"
  },
  {
    "text": "rolling strategies to rolling update",
    "start": "542199",
    "end": "543759"
  },
  {
    "text": "strategy the scheduler will just take",
    "start": "543759",
    "end": "545980"
  },
  {
    "text": "down all of the replicas of your",
    "start": "545980",
    "end": "547540"
  },
  {
    "text": "deployment and so you might see a",
    "start": "547540",
    "end": "549579"
  },
  {
    "text": "disruption there in our rule that we",
    "start": "549579",
    "end": "552399"
  },
  {
    "text": "have on screen here we're setting max",
    "start": "552399",
    "end": "554350"
  },
  {
    "text": "unavailable to one and so this will be a",
    "start": "554350",
    "end": "556060"
  },
  {
    "text": "rolling upgrade where one replica is",
    "start": "556060",
    "end": "558100"
  },
  {
    "text": "taken down at a time and the new one is",
    "start": "558100",
    "end": "559720"
  },
  {
    "text": "brought up this is this is a great use",
    "start": "559720",
    "end": "565000"
  },
  {
    "text": "of out of out of the box functionality",
    "start": "565000",
    "end": "567250"
  },
  {
    "text": "because you don't need to write your own",
    "start": "567250",
    "end": "569019"
  },
  {
    "text": "machinery there is a replication",
    "start": "569019",
    "end": "570880"
  },
  {
    "text": "controller that's watching for changes",
    "start": "570880",
    "end": "573160"
  },
  {
    "text": "to your either deployment manifest or",
    "start": "573160",
    "end": "575529"
  },
  {
    "text": "updates to your pots themselves and",
    "start": "575529",
    "end": "577810"
  },
  {
    "text": "reconciling any errors that happen",
    "start": "577810",
    "end": "580259"
  },
  {
    "text": "similar concepts translate to stateful",
    "start": "580259",
    "end": "583449"
  },
  {
    "text": "sets for stateful applications you get",
    "start": "583449",
    "end": "586149"
  },
  {
    "text": "stable storage stable persistent storage",
    "start": "586149",
    "end": "588009"
  },
  {
    "text": "and stable Network identities and we'll",
    "start": "588009",
    "end": "591279"
  },
  {
    "text": "talk about staple sets in a little bit",
    "start": "591279",
    "end": "593529"
  },
  {
    "text": "more detail later the next thing is the",
    "start": "593529",
    "end": "596920"
  },
  {
    "text": "concept of setting zones and you might",
    "start": "596920",
    "end": "599860"
  },
  {
    "text": "remember I said it is not intrinsic to",
    "start": "599860",
    "end": "601959"
  },
  {
    "text": "kubernetes but if you do use a",
    "start": "601959",
    "end": "604600"
  },
  {
    "text": "kubernetes cloud provider you get that",
    "start": "604600",
    "end": "607300"
  },
  {
    "text": "feature again out of the box there but",
    "start": "607300",
    "end": "611110"
  },
  {
    "text": "if you don't use a cloud provider and",
    "start": "611110",
    "end": "612670"
  },
  {
    "text": "you want to do it by hand you need to do",
    "start": "612670",
    "end": "614949"
  },
  {
    "text": "two things the first is setting pod and",
    "start": "614949",
    "end": "617230"
  },
  {
    "text": "I affinity rules to your pods like the",
    "start": "617230",
    "end": "619300"
  },
  {
    "text": "one on screen where we set the specific",
    "start": "619300",
    "end": "621519"
  },
  {
    "text": "failure domain key and the second is you",
    "start": "621519",
    "end": "624850"
  },
  {
    "text": "would add labels to each of your nodes",
    "start": "624850",
    "end": "627009"
  },
  {
    "text": "where the key happens to be that failure",
    "start": "627009",
    "end": "628930"
  },
  {
    "text": "domain key and the value can be anything",
    "start": "628930",
    "end": "631810"
  },
  {
    "text": "so in our case it would be us central",
    "start": "631810",
    "end": "633579"
  },
  {
    "text": "one a B C D and so on once you do that",
    "start": "633579",
    "end": "637509"
  },
  {
    "text": "the scheduler will schedule all of your",
    "start": "637509",
    "end": "639880"
  },
  {
    "text": "workloads across those zones but again",
    "start": "639880",
    "end": "642550"
  },
  {
    "text": "if you deploy a cloud provider that will",
    "start": "642550",
    "end": "644470"
  },
  {
    "text": "just happen for you so next thing I want",
    "start": "644470",
    "end": "648399"
  },
  {
    "text": "to talk about in touch here is node",
    "start": "648399",
    "end": "650439"
  },
  {
    "text": "upgrades and specifically other types of",
    "start": "650439",
    "end": "652839"
  },
  {
    "text": "voluntary disruptions that you might",
    "start": "652839",
    "end": "654459"
  },
  {
    "text": "want to do so if you want to do kernel",
    "start": "654459",
    "end": "656230"
  },
  {
    "text": "upgrades on your machine you will need",
    "start": "656230",
    "end": "658269"
  },
  {
    "text": "to drain all of the pods there and",
    "start": "658269",
    "end": "660190"
  },
  {
    "text": "maintenance and then join it back into",
    "start": "660190",
    "end": "661600"
  },
  {
    "text": "the cluster but if you decide to drain",
    "start": "661600",
    "end": "663910"
  },
  {
    "text": "it drain the machine all of the replicas",
    "start": "663910",
    "end": "666879"
  },
  {
    "text": "and all of the pods running there will",
    "start": "666879",
    "end": "668079"
  },
  {
    "text": "be drained at the same time and it's",
    "start": "668079",
    "end": "669579"
  },
  {
    "text": "possible that all of your pods were",
    "start": "669579",
    "end": "672279"
  },
  {
    "text": "running there and all of those are gone",
    "start": "672279",
    "end": "674199"
  },
  {
    "text": "and so your services unavailable to get",
    "start": "674199",
    "end": "676899"
  },
  {
    "text": "over that you can use pod disruption",
    "start": "676899",
    "end": "678370"
  },
  {
    "text": "budgets where you can set again your",
    "start": "678370",
    "end": "681339"
  },
  {
    "text": "tolerance for downtime and if the",
    "start": "681339",
    "end": "684939"
  },
  {
    "text": "tolerance here is not met by any trained",
    "start": "684939",
    "end": "687459"
  },
  {
    "text": "commands the pod eviction API will just",
    "start": "687459",
    "end": "689470"
  },
  {
    "text": "reject the call so this was useful when",
    "start": "689470",
    "end": "691750"
  },
  {
    "text": "you have three pods running across three",
    "start": "691750",
    "end": "694060"
  },
  {
    "text": "different machines you start draining",
    "start": "694060",
    "end": "696220"
  },
  {
    "text": "one of them at a time and you can set",
    "start": "696220",
    "end": "698709"
  },
  {
    "text": "the disruption budget to be targeting",
    "start": "698709",
    "end": "700689"
  },
  {
    "text": "just one and have at least two available",
    "start": "700689",
    "end": "702250"
  },
  {
    "text": "at a time okay let's talk about the",
    "start": "702250",
    "end": "706029"
  },
  {
    "start": "704000",
    "end": "1029000"
  },
  {
    "text": "control plant itself we're not okay",
    "start": "706029",
    "end": "714430"
  },
  {
    "text": "so earlier on this slide carne showed",
    "start": "714430",
    "end": "716589"
  },
  {
    "text": "you what would happen if we had a",
    "start": "716589",
    "end": "717910"
  },
  {
    "text": "failure in US central 1b but what if our",
    "start": "717910",
    "end": "720759"
  },
  {
    "text": "failure had been in u.s. central and F",
    "start": "720759",
    "end": "722709"
  },
  {
    "text": "which is where our control plane is",
    "start": "722709",
    "end": "723970"
  },
  {
    "text": "running in that case we don't have a",
    "start": "723970",
    "end": "726490"
  },
  {
    "text": "control plane running anymore so you can",
    "start": "726490",
    "end": "728139"
  },
  {
    "text": "see that the containers that we're",
    "start": "728139",
    "end": "729430"
  },
  {
    "text": "running in that region or that zone are",
    "start": "729430",
    "end": "731649"
  },
  {
    "text": "no longer rescheduled because nothing's",
    "start": "731649",
    "end": "733839"
  },
  {
    "text": "there to reschedule it anything that's",
    "start": "733839",
    "end": "736149"
  },
  {
    "text": "running in the healthy zones is going to",
    "start": "736149",
    "end": "738160"
  },
  {
    "text": "continue running and if you had a load",
    "start": "738160",
    "end": "740079"
  },
  {
    "text": "balancer in front of those services then",
    "start": "740079",
    "end": "742630"
  },
  {
    "text": "the load balancer will notice that one",
    "start": "742630",
    "end": "744850"
  },
  {
    "text": "of the notes is not there anymore and",
    "start": "744850",
    "end": "746110"
  },
  {
    "text": "stop sending traffic to it so that",
    "start": "746110",
    "end": "747819"
  },
  {
    "text": "should be okay but there are some we",
    "start": "747819",
    "end": "750370"
  },
  {
    "text": "might see some intermittent issues in",
    "start": "750370",
    "end": "751720"
  },
  {
    "text": "the cluster while this is happening the",
    "start": "751720",
    "end": "755050"
  },
  {
    "text": "solution of course is to also run our",
    "start": "755050",
    "end": "757319"
  },
  {
    "text": "control plane nodes across them so we're",
    "start": "757319",
    "end": "759790"
  },
  {
    "text": "going to run three VMs one in each zone",
    "start": "759790",
    "end": "761680"
  },
  {
    "text": "and then we're going to run a replica of",
    "start": "761680",
    "end": "763600"
  },
  {
    "text": "all the control plan components on each",
    "start": "763600",
    "end": "765459"
  },
  {
    "text": "of these VMs let's look at what's",
    "start": "765459",
    "end": "769120"
  },
  {
    "text": "actually happening on those VMs we have",
    "start": "769120",
    "end": "771279"
  },
  {
    "text": "the API server which talks to @cd again",
    "start": "771279",
    "end": "774040"
  },
  {
    "text": "that's going to be in the next section",
    "start": "774040",
    "end": "775329"
  },
  {
    "text": "and then we have the scheduler and the",
    "start": "775329",
    "end": "777100"
  },
  {
    "text": "controller manager the API server is",
    "start": "777100",
    "end": "779949"
  },
  {
    "text": "really easy to run multiple replicas of",
    "start": "779949",
    "end": "781600"
  },
  {
    "text": "because it is completely stateless we",
    "start": "781600",
    "end": "784990"
  },
  {
    "text": "can just run it as active active so all",
    "start": "784990",
    "end": "786790"
  },
  {
    "text": "of them can take the same request and",
    "start": "786790",
    "end": "788380"
  },
  {
    "text": "all we have to do is put a load balancer",
    "start": "788380",
    "end": "790889"
  },
  {
    "text": "in front of API servers and we should be",
    "start": "790889",
    "end": "793350"
  },
  {
    "text": "fine the scheduler and controller",
    "start": "793350",
    "end": "796019"
  },
  {
    "text": "manager are a little bit more",
    "start": "796019",
    "end": "797339"
  },
  {
    "text": "complicated because they have to read",
    "start": "797339",
    "end": "799410"
  },
  {
    "text": "data and then act on the data and write",
    "start": "799410",
    "end": "801269"
  },
  {
    "text": "data also we want to make sure we're",
    "start": "801269",
    "end": "803220"
  },
  {
    "text": "only running one of them actively at a",
    "start": "803220",
    "end": "804959"
  },
  {
    "text": "time so what we do is we have a locking",
    "start": "804959",
    "end": "808139"
  },
  {
    "text": "system they'll all attempt to apply on",
    "start": "808139",
    "end": "810239"
  },
  {
    "text": "the lock one of them will get the lock",
    "start": "810239",
    "end": "811949"
  },
  {
    "text": "and that one will become the active",
    "start": "811949",
    "end": "813419"
  },
  {
    "text": "component and then the other two will",
    "start": "813419",
    "end": "815399"
  },
  {
    "text": "just wait for that one to fail so if it",
    "start": "815399",
    "end": "817619"
  },
  {
    "text": "fails they can they can take over by",
    "start": "817619",
    "end": "819359"
  },
  {
    "text": "acquiring the lock in order to configure",
    "start": "819359",
    "end": "822779"
  },
  {
    "text": "that we have there are five slides on",
    "start": "822779",
    "end": "825239"
  },
  {
    "text": "these components leader elect all you",
    "start": "825239",
    "end": "827579"
  },
  {
    "text": "have to do is set it to true and then",
    "start": "827579",
    "end": "828839"
  },
  {
    "text": "all of this will work but the other ones",
    "start": "828839",
    "end": "830790"
  },
  {
    "text": "are around they let you configure how",
    "start": "830790",
    "end": "833399"
  },
  {
    "text": "long it'll take for one of the passive",
    "start": "833399",
    "end": "836369"
  },
  {
    "text": "components to take over if the leader",
    "start": "836369",
    "end": "838319"
  },
  {
    "text": "fails ok so we've talked about kind of",
    "start": "838319",
    "end": "842459"
  },
  {
    "text": "like the multi master setup now but we",
    "start": "842459",
    "end": "845549"
  },
  {
    "text": "haven't really talked about a lot of",
    "start": "845549",
    "end": "846600"
  },
  {
    "text": "other things that are important in H a",
    "start": "846600",
    "end": "848540"
  },
  {
    "text": "if one of our party M fails like if we",
    "start": "848540",
    "end": "852660"
  },
  {
    "text": "had a zone outage nothing's really like",
    "start": "852660",
    "end": "854910"
  },
  {
    "text": "health checking to make sure that we",
    "start": "854910",
    "end": "855989"
  },
  {
    "text": "always have three available and we don't",
    "start": "855989",
    "end": "858179"
  },
  {
    "text": "have anything that's gonna handle",
    "start": "858179",
    "end": "859619"
  },
  {
    "text": "failure recovery in that case we also",
    "start": "859619",
    "end": "862110"
  },
  {
    "text": "haven't talked about how to upgrade",
    "start": "862110",
    "end": "863129"
  },
  {
    "text": "without downtime there are actually a",
    "start": "863129",
    "end": "865649"
  },
  {
    "text": "lot of solutions to this and a lot of",
    "start": "865649",
    "end": "868410"
  },
  {
    "text": "options you can explore depending on",
    "start": "868410",
    "end": "870059"
  },
  {
    "text": "what you need of course there are hosted",
    "start": "870059",
    "end": "872279"
  },
  {
    "text": "solutions like gk e gk regional clusters",
    "start": "872279",
    "end": "875549"
  },
  {
    "text": "will do this for you already",
    "start": "875549",
    "end": "877189"
  },
  {
    "text": "or gk on prem which is what we work on",
    "start": "877189",
    "end": "880399"
  },
  {
    "text": "you can use managed instance groups to",
    "start": "880399",
    "end": "882959"
  },
  {
    "text": "make sure you have the correct number of",
    "start": "882959",
    "end": "884610"
  },
  {
    "text": "machines available at all times that's a",
    "start": "884610",
    "end": "886860"
  },
  {
    "text": "GCE feature also you can build your own",
    "start": "886860",
    "end": "889980"
  },
  {
    "text": "monitoring server but that would be",
    "start": "889980",
    "end": "891600"
  },
  {
    "text": "really hard we would know and then",
    "start": "891600",
    "end": "894809"
  },
  {
    "text": "there's also kuru knows itself so there",
    "start": "894809",
    "end": "896759"
  },
  {
    "text": "are kind of two different ways you can",
    "start": "896759",
    "end": "898169"
  },
  {
    "text": "use kubernetes to do this for you or two",
    "start": "898169",
    "end": "901110"
  },
  {
    "text": "schools of thought I guess and like we",
    "start": "901110",
    "end": "903419"
  },
  {
    "text": "just saw in the application section of",
    "start": "903419",
    "end": "905459"
  },
  {
    "text": "the talk kubernetes helped us in a lot",
    "start": "905459",
    "end": "907289"
  },
  {
    "text": "of ways to manage these things for us",
    "start": "907289",
    "end": "909389"
  },
  {
    "text": "the first way of doing this is called",
    "start": "909389",
    "end": "911609"
  },
  {
    "text": "self hosting this is when you run",
    "start": "911609",
    "end": "913679"
  },
  {
    "text": "kubernetes and it manages itself as pods",
    "start": "913679",
    "end": "916619"
  },
  {
    "text": "in the same cluster this is gonna have",
    "start": "916619",
    "end": "919350"
  },
  {
    "text": "some interesting bootstrapping issues or",
    "start": "919350",
    "end": "921470"
  },
  {
    "text": "certain failures can be hard to recover",
    "start": "921470",
    "end": "923699"
  },
  {
    "text": "from",
    "start": "923699",
    "end": "924190"
  },
  {
    "text": "does anyone has anyone tried using self",
    "start": "924190",
    "end": "926800"
  },
  {
    "text": "hosted clusters before okay really two",
    "start": "926800",
    "end": "930400"
  },
  {
    "text": "people this time did anyone like it did",
    "start": "930400",
    "end": "932470"
  },
  {
    "text": "any hands were raised okay well yeah so",
    "start": "932470",
    "end": "937990"
  },
  {
    "text": "if you want to try this out though cube",
    "start": "937990",
    "end": "939400"
  },
  {
    "text": "admin has it as an experimental feature",
    "start": "939400",
    "end": "941350"
  },
  {
    "text": "so you can try to plug a cluster this",
    "start": "941350",
    "end": "942850"
  },
  {
    "text": "way I think the way that has gained a",
    "start": "942850",
    "end": "945190"
  },
  {
    "text": "little bit more traction though recently",
    "start": "945190",
    "end": "946570"
  },
  {
    "text": "is the management cluster idea so you",
    "start": "946570",
    "end": "949000"
  },
  {
    "text": "have two clusters now cluster a is",
    "start": "949000",
    "end": "951100"
  },
  {
    "text": "unmanaged and it manages a bunch of",
    "start": "951100",
    "end": "953800"
  },
  {
    "text": "clusters in this case just one cluster B",
    "start": "953800",
    "end": "956680"
  },
  {
    "text": "so cluster a is control plane is",
    "start": "956680",
    "end": "958570"
  },
  {
    "text": "managing cluster B's worklet cluster B",
    "start": "958570",
    "end": "961510"
  },
  {
    "text": "is control plane as pods so you can see",
    "start": "961510",
    "end": "964840"
  },
  {
    "text": "cluster a's node is the same as cluster",
    "start": "964840",
    "end": "967210"
  },
  {
    "text": "b's controller node and then cluster B",
    "start": "967210",
    "end": "969430"
  },
  {
    "text": "can just manage its own workloads but",
    "start": "969430",
    "end": "971650"
  },
  {
    "text": "like I said cluster a is unmanaged",
    "start": "971650",
    "end": "973510"
  },
  {
    "text": "itself if that fails though the control",
    "start": "973510",
    "end": "977440"
  },
  {
    "text": "plane of cluster B will continue running",
    "start": "977440",
    "end": "978970"
  },
  {
    "text": "but you'll need to be able to have a",
    "start": "978970",
    "end": "980530"
  },
  {
    "text": "good recovery story for that gke",
    "start": "980530",
    "end": "984490"
  },
  {
    "text": "solution is regional clusters like I've",
    "start": "984490",
    "end": "986500"
  },
  {
    "text": "said before regional clusters will",
    "start": "986500",
    "end": "988720"
  },
  {
    "text": "automatically run the master nodes",
    "start": "988720",
    "end": "990580"
  },
  {
    "text": "across three zones it'll run three",
    "start": "990580",
    "end": "992350"
  },
  {
    "text": "replicas of the control plane and it'll",
    "start": "992350",
    "end": "995140"
  },
  {
    "text": "put a global load balancer in front of",
    "start": "995140",
    "end": "997720"
  },
  {
    "text": "the API servers for your cluster also",
    "start": "997720",
    "end": "1001140"
  },
  {
    "text": "one of the benefits of GK regional",
    "start": "1001140",
    "end": "1003120"
  },
  {
    "text": "clusters is that Google's sres are now",
    "start": "1003120",
    "end": "1005460"
  },
  {
    "text": "managing your compute networking and",
    "start": "1005460",
    "end": "1007320"
  },
  {
    "text": "storage resources for you there's also",
    "start": "1007320",
    "end": "1011550"
  },
  {
    "text": "the cluster API this does machine and",
    "start": "1011550",
    "end": "1013530"
  },
  {
    "text": "cluster management in kubernetes style",
    "start": "1013530",
    "end": "1015930"
  },
  {
    "text": "API objects we worked up we work on this",
    "start": "1015930",
    "end": "1018690"
  },
  {
    "text": "and some of our team works on this at",
    "start": "1018690",
    "end": "1020460"
  },
  {
    "text": "Google as well if you're interested in",
    "start": "1020460",
    "end": "1022050"
  },
  {
    "text": "learning more about that there's a",
    "start": "1022050",
    "end": "1023550"
  },
  {
    "text": "cluster API work group in cig cluster",
    "start": "1023550",
    "end": "1026640"
  },
  {
    "text": "lifecycle thank you so next we want to",
    "start": "1026640",
    "end": "1033540"
  },
  {
    "start": "1029000",
    "end": "1510000"
  },
  {
    "text": "talk about our data plane which in this",
    "start": "1033540",
    "end": "1036540"
  },
  {
    "text": "case kubernetes case is at CD and at CD",
    "start": "1036540",
    "end": "1040110"
  },
  {
    "text": "is a little bit of a snowflake here",
    "start": "1040110",
    "end": "1041819"
  },
  {
    "text": "because it is backed by a database and",
    "start": "1041819",
    "end": "1044640"
  },
  {
    "text": "for writes to a database to succeed in a",
    "start": "1044640",
    "end": "1047370"
  },
  {
    "text": "distributed environment there needs to",
    "start": "1047370",
    "end": "1049590"
  },
  {
    "text": "be a strict majority to elect a leader",
    "start": "1049590",
    "end": "1051360"
  },
  {
    "text": "that can for writes to succeed so what I",
    "start": "1051360",
    "end": "1056100"
  },
  {
    "text": "want to talk about here is why",
    "start": "1056100",
    "end": "1057970"
  },
  {
    "text": "city's the reason reason that at least",
    "start": "1057970",
    "end": "1060370"
  },
  {
    "text": "in gke we decided to go with three",
    "start": "1060370",
    "end": "1062890"
  },
  {
    "text": "masters instead of say two or four or",
    "start": "1062890",
    "end": "1064990"
  },
  {
    "text": "even higher than that",
    "start": "1064990",
    "end": "1068520"
  },
  {
    "text": "so at CDs basis is distributed consensus",
    "start": "1069010",
    "end": "1073570"
  },
  {
    "text": "algorithm called raft I won't go into",
    "start": "1073570",
    "end": "1075429"
  },
  {
    "text": "details there's papers about that the",
    "start": "1075429",
    "end": "1078190"
  },
  {
    "text": "equation that governs that series",
    "start": "1078190",
    "end": "1079750"
  },
  {
    "text": "operate or raft in general is this",
    "start": "1079750",
    "end": "1082150"
  },
  {
    "text": "simple n over 2 plus 1 equation what",
    "start": "1082150",
    "end": "1085240"
  },
  {
    "text": "this tells us is that for any action to",
    "start": "1085240",
    "end": "1087580"
  },
  {
    "text": "take place there needs to be a very",
    "start": "1087580",
    "end": "1089409"
  },
  {
    "text": "strict majority of at least 51% of the",
    "start": "1089409",
    "end": "1092919"
  },
  {
    "text": "members very democratic so in F Series",
    "start": "1092919",
    "end": "1097690"
  },
  {
    "text": "case what that means is at least 51% of",
    "start": "1097690",
    "end": "1100179"
  },
  {
    "text": "the members of an FC D cluster need to",
    "start": "1100179",
    "end": "1103120"
  },
  {
    "text": "reach a quorum on the leader and so",
    "start": "1103120",
    "end": "1107650"
  },
  {
    "text": "let's see what happens with if our EDD",
    "start": "1107650",
    "end": "1111010"
  },
  {
    "text": "cluster was only 2 replicas instead of 3",
    "start": "1111010",
    "end": "1113520"
  },
  {
    "text": "and we can assume that we're doing an",
    "start": "1113520",
    "end": "1116140"
  },
  {
    "text": "upgrade of our cluster and the rightmost",
    "start": "1116140",
    "end": "1118230"
  },
  {
    "text": "master is down for that maintenance or",
    "start": "1118230",
    "end": "1121539"
  },
  {
    "text": "upgrade well in that case we have one of",
    "start": "1121539",
    "end": "1124240"
  },
  {
    "text": "our master of one of them is down which",
    "start": "1124240",
    "end": "1127000"
  },
  {
    "text": "means only one out of the table 50% are",
    "start": "1127000",
    "end": "1130090"
  },
  {
    "text": "able to reach a quorum but we need a",
    "start": "1130090",
    "end": "1132429"
  },
  {
    "text": "strict 51% majority here and so rights",
    "start": "1132429",
    "end": "1136120"
  },
  {
    "text": "to our database will not succeed so we",
    "start": "1136120",
    "end": "1138909"
  },
  {
    "text": "can understand why one is not good",
    "start": "1138909",
    "end": "1141010"
  },
  {
    "text": "because one goes down you have nothing",
    "start": "1141010",
    "end": "1142720"
  },
  {
    "text": "we can see why 2 is not good one of them",
    "start": "1142720",
    "end": "1146230"
  },
  {
    "text": "goes down we have no tolerance after",
    "start": "1146230",
    "end": "1148510"
  },
  {
    "text": "that but why three why not 4 because you",
    "start": "1148510",
    "end": "1153070"
  },
  {
    "text": "know for if 4 people were attending this",
    "start": "1153070",
    "end": "1155440"
  },
  {
    "text": "talk that's better than having three",
    "start": "1155440",
    "end": "1156580"
  },
  {
    "text": "people so I want to go back to those",
    "start": "1156580",
    "end": "1159400"
  },
  {
    "text": "that equation again and here's a table",
    "start": "1159400",
    "end": "1161620"
  },
  {
    "text": "of potential cluster sizes the member of",
    "start": "1161620",
    "end": "1166360"
  },
  {
    "text": "members that we need for a majority to",
    "start": "1166360",
    "end": "1169480"
  },
  {
    "text": "reach and then the failure tolerance or",
    "start": "1169480",
    "end": "1172419"
  },
  {
    "text": "the fault tolerance that that provides",
    "start": "1172419",
    "end": "1174400"
  },
  {
    "text": "us so as you can see in the row 1 2 we",
    "start": "1174400",
    "end": "1179110"
  },
  {
    "text": "talked about that so it's very intuitive",
    "start": "1179110",
    "end": "1180460"
  },
  {
    "text": "there and I've highlighted rows 3 & 4",
    "start": "1180460",
    "end": "1183700"
  },
  {
    "text": "what you can see is for a cluster size",
    "start": "1183700",
    "end": "1185919"
  },
  {
    "text": "of three two out of the three members",
    "start": "1185919",
    "end": "1187590"
  },
  {
    "text": "need to be in consensus that's 60",
    "start": "1187590",
    "end": "1190960"
  },
  {
    "text": "6% of the members but when we jump to",
    "start": "1190960",
    "end": "1193240"
  },
  {
    "text": "four three out of those four are needed",
    "start": "1193240",
    "end": "1195460"
  },
  {
    "text": "to reach a quorum that's 75 percent so",
    "start": "1195460",
    "end": "1198520"
  },
  {
    "text": "we by increasing our cluster size from",
    "start": "1198520",
    "end": "1201100"
  },
  {
    "text": "three to four we've actually decreased",
    "start": "1201100",
    "end": "1203080"
  },
  {
    "text": "our probability of reaching a consensus",
    "start": "1203080",
    "end": "1206070"
  },
  {
    "text": "but in the last column you can see that",
    "start": "1206070",
    "end": "1208690"
  },
  {
    "text": "our fault tolerance is exactly the same",
    "start": "1208690",
    "end": "1211120"
  },
  {
    "text": "we can still only tolerate one machine",
    "start": "1211120",
    "end": "1213340"
  },
  {
    "text": "failure from the same table you can also",
    "start": "1213340",
    "end": "1216669"
  },
  {
    "text": "notice that odd numbered cluster sizes",
    "start": "1216669",
    "end": "1219700"
  },
  {
    "text": "beyond cluster size of two is strictly",
    "start": "1219700",
    "end": "1222610"
  },
  {
    "text": "better in terms of a of reaching quorum",
    "start": "1222610",
    "end": "1225309"
  },
  {
    "text": "and be providing failure tolerance than",
    "start": "1225309",
    "end": "1228130"
  },
  {
    "text": "even-numbered so you can say",
    "start": "1228130",
    "end": "1229990"
  },
  {
    "text": "odd-numbered provides us with better",
    "start": "1229990",
    "end": "1231370"
  },
  {
    "text": "odds of having a highly available",
    "start": "1231370",
    "end": "1233799"
  },
  {
    "text": "cluster thank you so why not why didn't",
    "start": "1233799",
    "end": "1238120"
  },
  {
    "text": "we choose five then because five is",
    "start": "1238120",
    "end": "1240100"
  },
  {
    "text": "better than three well then it comes",
    "start": "1240100",
    "end": "1241750"
  },
  {
    "text": "down to decisions like is it how",
    "start": "1241750",
    "end": "1244299"
  },
  {
    "text": "expensive is it going to be to run five",
    "start": "1244299",
    "end": "1246250"
  },
  {
    "text": "machines versus through versus three and",
    "start": "1246250",
    "end": "1248679"
  },
  {
    "text": "is that cost justified in my say the",
    "start": "1248679",
    "end": "1251830"
  },
  {
    "text": "revenue or the business value and the",
    "start": "1251830",
    "end": "1253750"
  },
  {
    "text": "second is even if you scale up to five",
    "start": "1253750",
    "end": "1257020"
  },
  {
    "text": "masters and theoretically at City can",
    "start": "1257020",
    "end": "1259360"
  },
  {
    "text": "provide you say five nines of",
    "start": "1259360",
    "end": "1261610"
  },
  {
    "text": "availability your downstream systems",
    "start": "1261610",
    "end": "1263950"
  },
  {
    "text": "still might not be able to provide you",
    "start": "1263950",
    "end": "1265840"
  },
  {
    "text": "with that much availability so your",
    "start": "1265840",
    "end": "1267820"
  },
  {
    "text": "upper limit is still the lowest common",
    "start": "1267820",
    "end": "1270549"
  },
  {
    "text": "denominator of downstream systems and so",
    "start": "1270549",
    "end": "1273340"
  },
  {
    "text": "three to us seemed like the best",
    "start": "1273340",
    "end": "1275409"
  },
  {
    "text": "trade-off between all of these decisions",
    "start": "1275409",
    "end": "1277059"
  },
  {
    "text": "but it's really an activity for for you",
    "start": "1277059",
    "end": "1280570"
  },
  {
    "text": "to evaluate what your business needs are",
    "start": "1280570",
    "end": "1282549"
  },
  {
    "text": "what your business goals are and how",
    "start": "1282549",
    "end": "1284260"
  },
  {
    "text": "much availability you need so let's see",
    "start": "1284260",
    "end": "1287590"
  },
  {
    "text": "what happens in case of three replicas",
    "start": "1287590",
    "end": "1289690"
  },
  {
    "text": "now that we've established that it's a",
    "start": "1289690",
    "end": "1291429"
  },
  {
    "text": "good good first step",
    "start": "1291429",
    "end": "1293710"
  },
  {
    "text": "say one of our nodes goes down again one",
    "start": "1293710",
    "end": "1295899"
  },
  {
    "text": "of our masters is down for upgrades in",
    "start": "1295899",
    "end": "1298840"
  },
  {
    "text": "that case we still have two available",
    "start": "1298840",
    "end": "1300220"
  },
  {
    "text": "replicas and those two can still now",
    "start": "1300220",
    "end": "1302710"
  },
  {
    "text": "reach to reach a quorum because we have",
    "start": "1302710",
    "end": "1304750"
  },
  {
    "text": "a strict majority so rights to our",
    "start": "1304750",
    "end": "1307059"
  },
  {
    "text": "database will succeed do note that if",
    "start": "1307059",
    "end": "1309820"
  },
  {
    "text": "during this upgrade one more of the",
    "start": "1309820",
    "end": "1313179"
  },
  {
    "text": "replicas goes down only one one of our",
    "start": "1313179",
    "end": "1316210"
  },
  {
    "text": "masters is up we our rights will not",
    "start": "1316210",
    "end": "1318399"
  },
  {
    "text": "succeed since we do not have a strict",
    "start": "1318399",
    "end": "1320080"
  },
  {
    "text": "majority so if you are upgrading a three",
    "start": "1320080",
    "end": "1323170"
  },
  {
    "text": "master three cluster size cluster you do",
    "start": "1323170",
    "end": "1328090"
  },
  {
    "text": "not get a high availability cluster",
    "start": "1328090",
    "end": "1330700"
  },
  {
    "text": "during an upgrade itself if you want",
    "start": "1330700",
    "end": "1332920"
  },
  {
    "text": "that well go to the next odd number",
    "start": "1332920",
    "end": "1334690"
  },
  {
    "text": "replica size like five now you can",
    "start": "1334690",
    "end": "1336880"
  },
  {
    "text": "tolerate two machine failures and still",
    "start": "1336880",
    "end": "1339520"
  },
  {
    "text": "be high availability so this is what EDD",
    "start": "1339520",
    "end": "1342550"
  },
  {
    "text": "recommends for a lot of its really",
    "start": "1342550",
    "end": "1344950"
  },
  {
    "text": "cluster sizes but again it depends on",
    "start": "1344950",
    "end": "1347170"
  },
  {
    "text": "your business needs so how would we go",
    "start": "1347170",
    "end": "1350650"
  },
  {
    "text": "about configuring it",
    "start": "1350650",
    "end": "1352300"
  },
  {
    "text": "there are documentation that there is",
    "start": "1352300",
    "end": "1354280"
  },
  {
    "text": "documentation for out there so I won't",
    "start": "1354280",
    "end": "1355780"
  },
  {
    "text": "spend too much time but there are two",
    "start": "1355780",
    "end": "1357610"
  },
  {
    "text": "steps one is you tell @zd where all the",
    "start": "1357610",
    "end": "1359710"
  },
  {
    "text": "peers are this can be IP addresses or",
    "start": "1359710",
    "end": "1362710"
  },
  {
    "text": "dns service names and the second is you",
    "start": "1362710",
    "end": "1365170"
  },
  {
    "text": "start the cube API server with those @cd",
    "start": "1365170",
    "end": "1368170"
  },
  {
    "text": "instances there is a linked example",
    "start": "1368170",
    "end": "1371130"
  },
  {
    "text": "manifest on screen so you can go back",
    "start": "1371130",
    "end": "1374410"
  },
  {
    "text": "and look at that and because that CD is",
    "start": "1374410",
    "end": "1377650"
  },
  {
    "text": "backed by a data store we do recommend",
    "start": "1377650",
    "end": "1380140"
  },
  {
    "text": "having preparing preparing for any",
    "start": "1380140",
    "end": "1383620"
  },
  {
    "text": "downtime that you might have because of",
    "start": "1383620",
    "end": "1385570"
  },
  {
    "text": "disk failures data corruption and the",
    "start": "1385570",
    "end": "1388240"
  },
  {
    "text": "biggest one is backup in backup and",
    "start": "1388240",
    "end": "1390070"
  },
  {
    "text": "restore we recommend having periodic",
    "start": "1390070",
    "end": "1393430"
  },
  {
    "text": "backups monitoring that those backups",
    "start": "1393430",
    "end": "1395590"
  },
  {
    "text": "are having an alerting when those",
    "start": "1395590",
    "end": "1397090"
  },
  {
    "text": "backups are not happening especially for",
    "start": "1397090",
    "end": "1398980"
  },
  {
    "text": "production systems and if you've run if",
    "start": "1398980",
    "end": "1402970"
  },
  {
    "text": "you run production systems where you are",
    "start": "1402970",
    "end": "1405190"
  },
  {
    "text": "taking backups you definitely have to",
    "start": "1405190",
    "end": "1407640"
  },
  {
    "text": "test to restore randomly in your backups",
    "start": "1407640",
    "end": "1411600"
  },
  {
    "text": "if you do lose your data due to some",
    "start": "1411600",
    "end": "1414700"
  },
  {
    "text": "mishap and you are not able to restore",
    "start": "1414700",
    "end": "1416470"
  },
  {
    "text": "or people have not been trained on how",
    "start": "1416470",
    "end": "1418420"
  },
  {
    "text": "to restore it your backup is useless so",
    "start": "1418420",
    "end": "1421720"
  },
  {
    "text": "there is that linked document",
    "start": "1421720",
    "end": "1423850"
  },
  {
    "text": "documentation page on how to do this",
    "start": "1423850",
    "end": "1425500"
  },
  {
    "text": "backup and restore and how to also",
    "start": "1425500",
    "end": "1427480"
  },
  {
    "text": "recover from when your cluster cannot",
    "start": "1427480",
    "end": "1430330"
  },
  {
    "text": "reach quorum so dump some tool",
    "start": "1430330",
    "end": "1433540"
  },
  {
    "text": "recommendations hefty Oh has Ark some",
    "start": "1433540",
    "end": "1436030"
  },
  {
    "text": "people might have used that before it's",
    "start": "1436030",
    "end": "1438520"
  },
  {
    "text": "great it's a server client where the",
    "start": "1438520",
    "end": "1440800"
  },
  {
    "text": "server lives on your cluster the client",
    "start": "1440800",
    "end": "1442540"
  },
  {
    "text": "makes HCD calls to basically iterate",
    "start": "1442540",
    "end": "1445960"
  },
  {
    "text": "through all of the objects save them in",
    "start": "1445960",
    "end": "1447790"
  },
  {
    "text": "a data store and you can recover them by",
    "start": "1447790",
    "end": "1450640"
  },
  {
    "text": "just posting them back to the API server",
    "start": "1450640",
    "end": "1452550"
  },
  {
    "text": "do you note that this requires the API",
    "start": "1452550",
    "end": "1454960"
  },
  {
    "text": "server so if your API server itself is",
    "start": "1454960",
    "end": "1456940"
  },
  {
    "text": "down because something happened during",
    "start": "1456940",
    "end": "1458770"
  },
  {
    "text": "an upgrade restoring might not be that",
    "start": "1458770",
    "end": "1460990"
  },
  {
    "text": "easy there is also at city operator",
    "start": "1460990",
    "end": "1464470"
  },
  {
    "text": "which again look into and Etsy d-zone",
    "start": "1464470",
    "end": "1466810"
  },
  {
    "text": "CLI has a snapshot function which you",
    "start": "1466810",
    "end": "1470380"
  },
  {
    "text": "can run periodically in something like a",
    "start": "1470380",
    "end": "1472060"
  },
  {
    "text": "cron job so what we're gonna do is",
    "start": "1472060",
    "end": "1477670"
  },
  {
    "text": "deploy an application across zones on a",
    "start": "1477670",
    "end": "1480250"
  },
  {
    "text": "cross zone multi master cluster and then",
    "start": "1480250",
    "end": "1483130"
  },
  {
    "text": "we're gonna simulate a zone failure so",
    "start": "1483130",
    "end": "1486010"
  },
  {
    "text": "our cluster will look like this we have",
    "start": "1486010",
    "end": "1487540"
  },
  {
    "text": "three VMs at our controller nodes three",
    "start": "1487540",
    "end": "1490090"
  },
  {
    "text": "VMs at our worker nodes we deployed this",
    "start": "1490090",
    "end": "1492730"
  },
  {
    "text": "cluster using kubernetes the hard way",
    "start": "1492730",
    "end": "1494320"
  },
  {
    "text": "but we made it cross zone which is one",
    "start": "1494320",
    "end": "1497770"
  },
  {
    "text": "of the only differences and then we're",
    "start": "1497770",
    "end": "1499660"
  },
  {
    "text": "gonna deploy our application across them",
    "start": "1499660",
    "end": "1501100"
  },
  {
    "text": "and see what happens when we delete the",
    "start": "1501100",
    "end": "1503290"
  },
  {
    "text": "VMs in one of the zones which is",
    "start": "1503290",
    "end": "1504610"
  },
  {
    "text": "simulating our zone failure okay",
    "start": "1504610",
    "end": "1512190"
  },
  {
    "start": "1510000",
    "end": "1747000"
  },
  {
    "text": "so first on the Left we're going to show",
    "start": "1513240",
    "end": "1515530"
  },
  {
    "text": "what nodes we have running in our",
    "start": "1515530",
    "end": "1516730"
  },
  {
    "text": "cluster the left is cute cuddle get",
    "start": "1516730",
    "end": "1519070"
  },
  {
    "text": "nodes and then the right is the Google",
    "start": "1519070",
    "end": "1521230"
  },
  {
    "text": "Cloud console and we can see that the",
    "start": "1521230",
    "end": "1523990"
  },
  {
    "text": "zone labels have been applied to all of",
    "start": "1523990",
    "end": "1526630"
  },
  {
    "text": "these nodes we had to apply them",
    "start": "1526630",
    "end": "1528070"
  },
  {
    "text": "ourselves because the way we deployed it",
    "start": "1528070",
    "end": "1530470"
  },
  {
    "text": "didn't use a cloud provider but like we",
    "start": "1530470",
    "end": "1533020"
  },
  {
    "text": "said earlier if you used a cloud",
    "start": "1533020",
    "end": "1534160"
  },
  {
    "text": "provider this would be applied",
    "start": "1534160",
    "end": "1535120"
  },
  {
    "text": "automatically so you can see where zero",
    "start": "1535120",
    "end": "1537700"
  },
  {
    "text": "is in u.s. west 1a that matches over",
    "start": "1537700",
    "end": "1540190"
  },
  {
    "text": "here then in the cloud console we'll",
    "start": "1540190",
    "end": "1543220"
  },
  {
    "text": "look at the load balancer that's sitting",
    "start": "1543220",
    "end": "1545020"
  },
  {
    "text": "in front of our controller nodes and",
    "start": "1545020",
    "end": "1548290"
  },
  {
    "text": "what we should see is three healthy",
    "start": "1548290",
    "end": "1551950"
  },
  {
    "text": "controller nodes so yes we have three",
    "start": "1551950",
    "end": "1554610"
  },
  {
    "text": "now we're gonna deploy our application",
    "start": "1554610",
    "end": "1556810"
  },
  {
    "text": "so we're gonna watch what pods we have",
    "start": "1556810",
    "end": "1559150"
  },
  {
    "text": "running in our cluster currently we",
    "start": "1559150",
    "end": "1560620"
  },
  {
    "text": "don't have any then we'll create this",
    "start": "1560620",
    "end": "1562570"
  },
  {
    "text": "simple nginx deployment and we'll look",
    "start": "1562570",
    "end": "1565750"
  },
  {
    "text": "at what's in that deployment so first we",
    "start": "1565750",
    "end": "1567820"
  },
  {
    "text": "can see that the notes or the pods are",
    "start": "1567820",
    "end": "1570280"
  },
  {
    "text": "all scheduled across the three different",
    "start": "1570280",
    "end": "1572560"
  },
  {
    "text": "worker nodes because they're in three",
    "start": "1572560",
    "end": "1573790"
  },
  {
    "text": "different zones and down here you can",
    "start": "1573790",
    "end": "1575800"
  },
  {
    "text": "see that we have this preferred during",
    "start": "1575800",
    "end": "1577420"
  },
  {
    "text": "scheduling pod anti affinity rule which",
    "start": "1577420",
    "end": "1580210"
  },
  {
    "text": "uses this failure domain zone top alot",
    "start": "1580210",
    "end": "1582970"
  },
  {
    "text": "topology key and since it's preferred it",
    "start": "1582970",
    "end": "1587020"
  },
  {
    "text": "will reschedule two pods into the same",
    "start": "1587020",
    "end": "1589960"
  },
  {
    "text": "if it has to if we make it if we made it",
    "start": "1589960",
    "end": "1592840"
  },
  {
    "text": "required then it wouldn't do that okay",
    "start": "1592840",
    "end": "1595980"
  },
  {
    "text": "now we can delete our zone we can't",
    "start": "1595980",
    "end": "1600279"
  },
  {
    "text": "actually delete a zone because we would",
    "start": "1600279",
    "end": "1601480"
  },
  {
    "text": "probably get fired but so okay on the",
    "start": "1601480",
    "end": "1604570"
  },
  {
    "text": "bottom we're looking at the pods that",
    "start": "1604570",
    "end": "1605860"
  },
  {
    "text": "are running in the cluster and you can",
    "start": "1605860",
    "end": "1607390"
  },
  {
    "text": "see which worker node they're running on",
    "start": "1607390",
    "end": "1609539"
  },
  {
    "text": "on the top we're gonna look at our nodes",
    "start": "1609539",
    "end": "1611860"
  },
  {
    "text": "and we're gonna make sure that they're",
    "start": "1611860",
    "end": "1613630"
  },
  {
    "text": "all in a good ready state and we'll see",
    "start": "1613630",
    "end": "1616809"
  },
  {
    "text": "what zone they're running in again so",
    "start": "1616809",
    "end": "1619570"
  },
  {
    "text": "you can see right here they're all ready",
    "start": "1619570",
    "end": "1621490"
  },
  {
    "text": "right now",
    "start": "1621490",
    "end": "1622620"
  },
  {
    "text": "okay now the scary part although this is",
    "start": "1622620",
    "end": "1625179"
  },
  {
    "text": "a video so it's a little bit less scary",
    "start": "1625179",
    "end": "1627539"
  },
  {
    "text": "we're gonna delete controllers 0 and",
    "start": "1627539",
    "end": "1631059"
  },
  {
    "text": "can't work or 0 which are both running",
    "start": "1631059",
    "end": "1632529"
  },
  {
    "text": "in uswest 1a once we delete them",
    "start": "1632529",
    "end": "1638140"
  },
  {
    "text": "the first thing we'll see is over here",
    "start": "1638140",
    "end": "1640720"
  },
  {
    "text": "we'll have a slight and then a down time",
    "start": "1640720",
    "end": "1642940"
  },
  {
    "text": "but we should see it automatically",
    "start": "1642940",
    "end": "1644860"
  },
  {
    "text": "recover itself the reason well let's see",
    "start": "1644860",
    "end": "1648700"
  },
  {
    "text": "it should happen pretty fast yeah so we",
    "start": "1648700",
    "end": "1650980"
  },
  {
    "text": "can see our calls to q4q pedal are",
    "start": "1650980",
    "end": "1653140"
  },
  {
    "text": "failing but then they come back pretty",
    "start": "1653140",
    "end": "1654700"
  },
  {
    "text": "quickly the reason for that is that the",
    "start": "1654700",
    "end": "1657309"
  },
  {
    "text": "load balancer that's sitting in front of",
    "start": "1657309",
    "end": "1658720"
  },
  {
    "text": "the 3 API servers has a health check on",
    "start": "1658720",
    "end": "1661630"
  },
  {
    "text": "it and it takes about two seconds to",
    "start": "1661630",
    "end": "1663309"
  },
  {
    "text": "recognize if one of them's failing which",
    "start": "1663309",
    "end": "1665260"
  },
  {
    "text": "I configured myself so you can configure",
    "start": "1665260",
    "end": "1666820"
  },
  {
    "text": "the time amount that it takes to recover",
    "start": "1666820",
    "end": "1670110"
  },
  {
    "text": "okay so while they're deleting what",
    "start": "1670110",
    "end": "1672940"
  },
  {
    "text": "we'll see first I believe is that worker",
    "start": "1672940",
    "end": "1675909"
  },
  {
    "text": "0 will become not ready we also changed",
    "start": "1675909",
    "end": "1679510"
  },
  {
    "text": "the pot eviction timeout when we",
    "start": "1679510",
    "end": "1681730"
  },
  {
    "text": "deployed the cluster to make it a victim",
    "start": "1681730",
    "end": "1683440"
  },
  {
    "text": "pods quicker when it realized one of",
    "start": "1683440",
    "end": "1684850"
  },
  {
    "text": "them is not ready so now our nodes are",
    "start": "1684850",
    "end": "1686890"
  },
  {
    "text": "deleted and we can see this one's not",
    "start": "1686890",
    "end": "1688270"
  },
  {
    "text": "ready and now down here we'll see a new",
    "start": "1688270",
    "end": "1692320"
  },
  {
    "text": "pod is scheduled on work or two really",
    "start": "1692320",
    "end": "1695320"
  },
  {
    "text": "quickly because we're core zero is now",
    "start": "1695320",
    "end": "1697539"
  },
  {
    "text": "no longer ready and now we can look at",
    "start": "1697539",
    "end": "1701559"
  },
  {
    "text": "the load balancer again to make sure",
    "start": "1701559",
    "end": "1703330"
  },
  {
    "text": "that we're not actually sending traffic",
    "start": "1703330",
    "end": "1704919"
  },
  {
    "text": "to controllers 0 anymore we can see what",
    "start": "1704919",
    "end": "1707230"
  },
  {
    "text": "that looks like so yeah we can see",
    "start": "1707230",
    "end": "1711100"
  },
  {
    "text": "controllers 0 is now a yellow",
    "start": "1711100",
    "end": "1713679"
  },
  {
    "text": "exclamation point because it's not",
    "start": "1713679",
    "end": "1717070"
  },
  {
    "text": "healthy cool that's all we have we've",
    "start": "1717070",
    "end": "1720429"
  },
  {
    "text": "linked some additional resources here",
    "start": "1720429",
    "end": "1722200"
  },
  {
    "text": "one is for",
    "start": "1722200",
    "end": "1723549"
  },
  {
    "text": "general clusters what you talked about",
    "start": "1723549",
    "end": "1724779"
  },
  {
    "text": "already we also linked the kubernetes",
    "start": "1724779",
    "end": "1727389"
  },
  {
    "text": "high availability Doc's here Cabrini's",
    "start": "1727389",
    "end": "1730210"
  },
  {
    "text": "the hard way if you want to try the demo",
    "start": "1730210",
    "end": "1731409"
  },
  {
    "text": "yourself and then also the cluster API",
    "start": "1731409",
    "end": "1734230"
  },
  {
    "text": "cig and we'll be in the at the Google",
    "start": "1734230",
    "end": "1737080"
  },
  {
    "text": "cloud booth downstairs in the exhibition",
    "start": "1737080",
    "end": "1739119"
  },
  {
    "text": "hall so if you have any questions I hope",
    "start": "1739119",
    "end": "1741100"
  },
  {
    "text": "all of you come find us there thank you",
    "start": "1741100",
    "end": "1742840"
  },
  {
    "text": "thank you",
    "start": "1742840",
    "end": "1743580"
  },
  {
    "text": "[Applause]",
    "start": "1743580",
    "end": "1749349"
  }
]
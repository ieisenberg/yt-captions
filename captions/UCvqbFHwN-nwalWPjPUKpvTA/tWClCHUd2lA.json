[
  {
    "text": "hi everyone yeah thank you for coming this session okay yeah my name is B so I'm",
    "start": "120",
    "end": "6440"
  },
  {
    "text": "coming from Apple and uh I have been working in the Big Data area for about",
    "start": "6440",
    "end": "13360"
  },
  {
    "text": "about more than 10 years so it's a long time and now I'm in apple building data",
    "start": "13360",
    "end": "19080"
  },
  {
    "text": "platform and the Machine learning platform yeah very nice to see you here so my colleague uh hi Buu my name is hi I also",
    "start": "19080",
    "end": "27840"
  },
  {
    "text": "from Apple and I work in the data infer team uh so I'm glad to be here talking",
    "start": "27840",
    "end": "34440"
  },
  {
    "text": "about uh uh reliability and cost efficiency uh for running",
    "start": "34440",
    "end": "40680"
  },
  {
    "text": "spark uh using Co in the cloud thank",
    "start": "40680",
    "end": "46719"
  },
  {
    "text": "you great let's get started so this is talk about CL native",
    "start": "46719",
    "end": "52960"
  },
  {
    "text": "data processing and also about aachi spark so I want to do a very quick survey so here how many people use Spark",
    "start": "52960",
    "end": "60719"
  },
  {
    "text": "before Oh great okay you are in the right place and I'm in the right place",
    "start": "60719",
    "end": "66560"
  },
  {
    "text": "okay nice here is a quick agenda we will maybe very quickly",
    "start": "66560",
    "end": "73840"
  },
  {
    "text": "introduce spark and how F tolerance Works in spark then we will present what kind of",
    "start": "73840",
    "end": "79960"
  },
  {
    "text": "problem we try to solve let's tell some problem with spark and uh there are",
    "start": "79960",
    "end": "85000"
  },
  {
    "text": "already many solutions they are built for different reasons so you will see a lot of and we build another solution uh",
    "start": "85000",
    "end": "92399"
  },
  {
    "text": "now we call Cloud Shuffle manager CSM and we will explain how it works",
    "start": "92399",
    "end": "98119"
  },
  {
    "text": "what benefit it has then hopefully you we can have more discussion so please uh",
    "start": "98119",
    "end": "104799"
  },
  {
    "text": "if you have any questions so we can discuss more",
    "start": "104799",
    "end": "109280"
  },
  {
    "text": "yeah yeah very quick about Spar spark was created about uh 15 years ago it's a",
    "start": "111040",
    "end": "117920"
  },
  {
    "text": "long time and it is unified framework to do dat processing a very large scale",
    "start": "117920",
    "end": "124759"
  },
  {
    "text": "it's very fast how it works it it is underline it's map reduce very simple concept",
    "start": "124759",
    "end": "132480"
  },
  {
    "text": "brought by Google if you have very large amount of data it splits data in small",
    "start": "132480",
    "end": "138800"
  },
  {
    "text": "chunks and process those chunks in parallel so you can use your computer power to Pro that them in massively",
    "start": "138800",
    "end": "145879"
  },
  {
    "text": "scale and run it very quickly and original was",
    "start": "145879",
    "end": "150920"
  },
  {
    "text": "running in your own data center like a yarn and these days people bring spark",
    "start": "150920",
    "end": "157040"
  },
  {
    "text": "to Cloud error it can run on",
    "start": "157040",
    "end": "161879"
  },
  {
    "text": "community cool yeah very small kind of explaining about how",
    "start": "162239",
    "end": "170200"
  },
  {
    "text": "map reduce Works uh map reduce proves a data in two stage the first stage is map it split",
    "start": "170200",
    "end": "178120"
  },
  {
    "text": "data and put Rel dated data together on each machine here we call executor here",
    "start": "178120",
    "end": "184720"
  },
  {
    "text": "is a SQL statement select word and count to do a word counting very simple uh SQL",
    "start": "184720",
    "end": "192040"
  },
  {
    "text": "execution so the map side get a data split then it will Shuffle the data and",
    "start": "192040",
    "end": "198080"
  },
  {
    "text": "get the same word to the same place then in the reducer side it just",
    "start": "198080",
    "end": "203440"
  },
  {
    "text": "count each word and generate the output file which count how many words appeared",
    "start": "203440",
    "end": "211080"
  },
  {
    "text": "underline spark is just very simple like this even though it's a",
    "start": "211080",
    "end": "218280"
  },
  {
    "text": "simple spark bring multiple stage Maru into the",
    "start": "218280",
    "end": "224040"
  },
  {
    "text": "framework and between different stage it can Shuffle data when it shuffle data it will",
    "start": "224040",
    "end": "233920"
  },
  {
    "text": "exchange the data files among different executor so we will see some problem",
    "start": "233920",
    "end": "239040"
  },
  {
    "text": "might happen here here and before I will work how spark",
    "start": "239040",
    "end": "244159"
  },
  {
    "text": "solve the for tolerance problem so because this different stage so if one",
    "start": "244159",
    "end": "249280"
  },
  {
    "text": "stage goes wrong then spark will try to recompute the data from previous stage",
    "start": "249280",
    "end": "256759"
  },
  {
    "text": "and then continue running that is how sparks of for tolerance in current state",
    "start": "256759",
    "end": "263520"
  },
  {
    "text": "current status so for example here",
    "start": "263520",
    "end": "270520"
  },
  {
    "text": "there's a execut three when it dies and ex five which depends on execut",
    "start": "270520",
    "end": "276479"
  },
  {
    "text": "three so what will happen spark will launch a new executor",
    "start": "276479",
    "end": "283240"
  },
  {
    "text": "like executor six here this executor will reprocess data and now the next stage execut five",
    "start": "283240",
    "end": "291720"
  },
  {
    "text": "is happy it can get data from there and continue",
    "start": "291720",
    "end": "296080"
  },
  {
    "text": "running so now what problem we have so let's think in this scenario so normally",
    "start": "296919",
    "end": "303000"
  },
  {
    "text": "you have a lot of data and executor may maybe there cross multiple",
    "start": "303000",
    "end": "311240"
  },
  {
    "text": "stage in this case the ex one cross stage 10 and 11 so it has Shuffle file",
    "start": "311240",
    "end": "319639"
  },
  {
    "text": "Shuffle data on these two",
    "start": "319639",
    "end": "323720"
  },
  {
    "text": "stages now let's see if executed one dies uh the next",
    "start": "325000",
    "end": "330240"
  },
  {
    "text": "stage executor five got fet failure so what will happen so spark will launch",
    "start": "330240",
    "end": "336360"
  },
  {
    "text": "another executor on the middle stage then that middle stage we read data from",
    "start": "336360",
    "end": "341759"
  },
  {
    "text": "previous stage but in the previous stage because that executor still is dead so",
    "start": "341759",
    "end": "347919"
  },
  {
    "text": "the middle stage will fail again and The Spar will launch a new executor in previous stage so it will",
    "start": "347919",
    "end": "355080"
  },
  {
    "text": "kind of pro propagate back and to the previous St stage and just a chain",
    "start": "355080",
    "end": "362560"
  },
  {
    "text": "reaction uh the result is it may run slow because a lot of retry or in the",
    "start": "362560",
    "end": "367599"
  },
  {
    "text": "end there's a limit of the retry so the application May Fail if the retry has happened too many",
    "start": "367599",
    "end": "375400"
  },
  {
    "text": "times this is really a trouble in the cloud so people like to use sport VM",
    "start": "376479",
    "end": "382960"
  },
  {
    "text": "because sport VM is kind of cheap and can save you cost but the downside is it",
    "start": "382960",
    "end": "389000"
  },
  {
    "text": "can be termin ated by Cloud vendor at any time so if it determinated your",
    "start": "389000",
    "end": "394199"
  },
  {
    "text": "spark job will high likely fail because all the shuffle data lost and Spar has a dynamic allocation",
    "start": "394199",
    "end": "402000"
  },
  {
    "text": "feature uh it will also kill your executor so it make call the application fail as",
    "start": "402000",
    "end": "409120"
  },
  {
    "text": "well so how we solve this problem in the Cloud area the idea is",
    "start": "411039",
    "end": "417919"
  },
  {
    "text": "very simple we can decouple compute and the storage here the storage is Shuffle storage so we don't store the shuffle",
    "start": "417919",
    "end": "425039"
  },
  {
    "text": "data on the local disk we can start the shle data on remote storage so in this",
    "start": "425039",
    "end": "431000"
  },
  {
    "text": "case when your executor is gone the data is still in the remote storage so your",
    "start": "431000",
    "end": "436919"
  },
  {
    "text": "execution can resume at any time and this is very powerful that means when you run Spar application you can just",
    "start": "436919",
    "end": "444160"
  },
  {
    "text": "kill your executor at any time without impact the success of the application",
    "start": "444160",
    "end": "450360"
  },
  {
    "text": "the downside is right now the remote storage like cloud storage is maybe slow",
    "start": "450360",
    "end": "458120"
  },
  {
    "text": "when you read a lot of files so it is good at throughput but it's not good at latency so if you have many small files",
    "start": "458120",
    "end": "465199"
  },
  {
    "text": "it will be pretty slow you will have some way to solve this problem as",
    "start": "465199",
    "end": "471240"
  },
  {
    "text": "well yeah before our solution the industry already work on",
    "start": "471639",
    "end": "477400"
  },
  {
    "text": "this for a few years they come out all these Solutions so you can just uh",
    "start": "477400",
    "end": "483840"
  },
  {
    "text": "search it you can find a lot of information from that and uh before I work in apple I was in Uber there I",
    "start": "483840",
    "end": "491319"
  },
  {
    "text": "built my previous Shuffle service the remote Shuffle service there uh",
    "start": "491319",
    "end": "497080"
  },
  {
    "text": "we launch another dedicated server to store the shle data there but now here",
    "start": "497080",
    "end": "503080"
  },
  {
    "text": "in apple I kind of build another version so because we want to make the server",
    "start": "503080",
    "end": "508319"
  },
  {
    "text": "list we do not want to to another server so we will see how we do it later",
    "start": "508319",
    "end": "515599"
  },
  {
    "text": "yeah yeah here's a quick o overview and uh explain what's the difference of",
    "start": "516399",
    "end": "521959"
  },
  {
    "text": "different solutions so we look at at three angle so whether it support remote",
    "start": "521959",
    "end": "528560"
  },
  {
    "text": "storage uh how is the operation cost and uh whether it supports the support of",
    "start": "528560",
    "end": "534640"
  },
  {
    "text": "VM so right now our solution Cloud Shuffle manager is is the only solution",
    "start": "534640",
    "end": "540519"
  },
  {
    "text": "which satisfy the three dimensions all other Solutions never work in some part",
    "start": "540519",
    "end": "546720"
  },
  {
    "text": "and fit some scenario yeah every solution is good uh",
    "start": "546720",
    "end": "552040"
  },
  {
    "text": "in their certain scenario",
    "start": "552040",
    "end": "556120"
  },
  {
    "text": "yeah here is the overall architecture of our solution so in our side",
    "start": "558320",
    "end": "567079"
  },
  {
    "text": "we we build the whole platform uh with a spark Gateway so that",
    "start": "567279",
    "end": "574320"
  },
  {
    "text": "spark Gateway is also open source project you can check the link and go there it can help you to run Spar job",
    "start": "574320",
    "end": "580920"
  },
  {
    "text": "very easily on the kuet and we can enhance that to add The",
    "start": "580920",
    "end": "587720"
  },
  {
    "text": "Spar job Spar config manager so it can inject Cloud shffle manager related",
    "start": "587720",
    "end": "594160"
  },
  {
    "text": "configuration there and the user don't need to do too much work then in the right side it is how",
    "start": "594160",
    "end": "600959"
  },
  {
    "text": "the class manager is implemented so the green blocks are the",
    "start": "600959",
    "end": "607680"
  },
  {
    "text": "new components we add into spark the first one is we add a dual",
    "start": "607680",
    "end": "614240"
  },
  {
    "text": "Shuffle manager when executor is running we copy the shuffle file from",
    "start": "614240",
    "end": "621000"
  },
  {
    "text": "local disk to cloud storage yeah it's just very simple copy but it's very it's",
    "start": "621000",
    "end": "628160"
  },
  {
    "text": "very fast and uh we can also optimize the copy and has we'll explain that",
    "start": "628160",
    "end": "636720"
  },
  {
    "text": "later so when the data is generated and another executor will read it with uh",
    "start": "636720",
    "end": "643920"
  },
  {
    "text": "continued execution so what happen if the previous executor is",
    "start": "643920",
    "end": "650519"
  },
  {
    "text": "dead we add a fullback shule reader here so if the previous executor is dead the",
    "start": "650519",
    "end": "657240"
  },
  {
    "text": "fullback Shuffle reader will read from cloud storage and continue running so",
    "start": "657240",
    "end": "663320"
  },
  {
    "text": "this will make your application very reliable and it will never fail and sometime when execut is dead it",
    "start": "663320",
    "end": "671880"
  },
  {
    "text": "may take a while for us to detect that so it slow down the whole process so we",
    "start": "671880",
    "end": "677040"
  },
  {
    "text": "proactively add a dead executed detector so if we detect a executor is dead we will read",
    "start": "677040",
    "end": "683920"
  },
  {
    "text": "from cloud story directly without do the fallback so it can minimize the theault",
    "start": "683920",
    "end": "690480"
  },
  {
    "text": "recovery time cool yeah so my colleague will dive",
    "start": "690480",
    "end": "696440"
  },
  {
    "text": "into some detail and explain how we test",
    "start": "696440",
    "end": "700320"
  },
  {
    "text": "it okay so I would like to uh talk about uh some of the details about our design",
    "start": "701720",
    "end": "709320"
  },
  {
    "text": "so firstly uh why we chose uh cloud storage as the place to uh store the",
    "start": "709320",
    "end": "716760"
  },
  {
    "text": "Soft Data so because because that bring us many benefits we really like for",
    "start": "716760",
    "end": "723519"
  },
  {
    "text": "example High availability High scalability uh building life cycle",
    "start": "723519",
    "end": "730079"
  },
  {
    "text": "manager so we can do data clean up automatically very easily and the",
    "start": "730079",
    "end": "735600"
  },
  {
    "text": "security features such as fun Gren Access Control uh encryptions so a lot of uh",
    "start": "735600",
    "end": "744800"
  },
  {
    "text": "Building Services uh features available for us and this this is really a very",
    "start": "744800",
    "end": "750839"
  },
  {
    "text": "easy and a lazy uh approach for us so we trying to uh take advantage all the",
    "start": "750839",
    "end": "758760"
  },
  {
    "text": "existing services from the cloud so we don't have to reinvent the views so we",
    "start": "758760",
    "end": "764760"
  },
  {
    "text": "can save our effort and that's the main uh reason we chose cloud",
    "start": "764760",
    "end": "772440"
  },
  {
    "text": "storage however on the other side the main challenge is that uh cloud storage",
    "start": "772440",
    "end": "778680"
  },
  {
    "text": "is relatively slow if we compare to local",
    "start": "778680",
    "end": "783720"
  },
  {
    "text": "ssds uh and it is really a challenge because uh that uh many of our effort",
    "start": "783720",
    "end": "791279"
  },
  {
    "text": "has to address the that",
    "start": "791279",
    "end": "794959"
  },
  {
    "text": "problems so uh as mentioned that's the challenge and uh so we had to make uh a",
    "start": "796480",
    "end": "804279"
  },
  {
    "text": "number of optimizations in order to achieve cost efficiency",
    "start": "804279",
    "end": "810079"
  },
  {
    "text": "and uh here we list a few of them so firstly uh we only uh we only read from",
    "start": "810079",
    "end": "818880"
  },
  {
    "text": "cloud storage only if we have to and meaning that the majority of the read",
    "start": "818880",
    "end": "825959"
  },
  {
    "text": "still uh going to the local disk so the majority still going to the fast uh",
    "start": "825959",
    "end": "832880"
  },
  {
    "text": "local dist only uh fall back uh if we have",
    "start": "832880",
    "end": "837920"
  },
  {
    "text": "to uh uh also we added a feature called aryn right so AR sync right basically",
    "start": "837920",
    "end": "844920"
  },
  {
    "text": "saying that we don't have to stop and wait until the copy finish we can just",
    "start": "844920",
    "end": "853079"
  },
  {
    "text": "uh have the reducer set continue to uh move on and then uh let the copy happen",
    "start": "853079",
    "end": "860920"
  },
  {
    "text": "on the background asynchronously so this can Ser as some run",
    "start": "860920",
    "end": "866639"
  },
  {
    "text": "times and another feature that we uh is trying to leverage some catching",
    "start": "866639",
    "end": "873399"
  },
  {
    "text": "mechanisms so to uh catch small files for example the uh inex files they are",
    "start": "873399",
    "end": "881600"
  },
  {
    "text": "pretty small so we trying to uh make some catching uh on both executor side",
    "start": "881600",
    "end": "888240"
  },
  {
    "text": "and the driver side so it can uh boost the",
    "start": "888240",
    "end": "893480"
  },
  {
    "text": "performance and uh so with all this work uh we a able to do some evaluations for",
    "start": "895079",
    "end": "901079"
  },
  {
    "text": "the performance that we really concerned about and in order to make a fair uh",
    "start": "901079",
    "end": "907120"
  },
  {
    "text": "meaningful uh evaluation so uh firstly we do the M uh benchmarking evaluation",
    "start": "907120",
    "end": "913880"
  },
  {
    "text": "using tcps so tcps is industry uh commonly",
    "start": "913880",
    "end": "919759"
  },
  {
    "text": "used benchmarking tool utility for uh typical spark workload uh performance",
    "start": "919759",
    "end": "927399"
  },
  {
    "text": "test and this allow us to run a number of uh uh skills against the CSM to",
    "start": "927399",
    "end": "935639"
  },
  {
    "text": "evaluate how it works and secondly uh we developed a utility called the",
    "start": "935639",
    "end": "943839"
  },
  {
    "text": "terminis simulator so basically we like to simulate the what happens in a real",
    "start": "943839",
    "end": "951120"
  },
  {
    "text": "world and then we run the benchmarking job uh one uh after another one uh so",
    "start": "951120",
    "end": "957519"
  },
  {
    "text": "basically firstly We Run The and then we run uh the job with CSM",
    "start": "957519",
    "end": "963720"
  },
  {
    "text": "enabled uh we trigger the termination at the same time uh in the same stage so we're",
    "start": "963720",
    "end": "971639"
  },
  {
    "text": "trying to apply the same condition to both so we can uh compare the result",
    "start": "971639",
    "end": "979279"
  },
  {
    "text": "after the key metrics we care about is basically two fold so one is the",
    "start": "979279",
    "end": "985279"
  },
  {
    "text": "overhead so we want to make sure the overhead we introduced is insignificant",
    "start": "985279",
    "end": "991079"
  },
  {
    "text": "is reasonable and on the other side we want to measure the runtime reduction we",
    "start": "991079",
    "end": "996560"
  },
  {
    "text": "like to see the runtime is reduced significantly so we can claim a profit",
    "start": "996560",
    "end": "1002639"
  },
  {
    "text": "from that so uh this UI you may be familiar",
    "start": "1002639",
    "end": "1009240"
  },
  {
    "text": "since many people are familiar with spark so this the spark Hui it shows",
    "start": "1009240",
    "end": "1015720"
  },
  {
    "text": "what happens when uh the termination happened so we in this example we uh kill the F",
    "start": "1015720",
    "end": "1024520"
  },
  {
    "text": "executors uh two at a time and you know that the s data also",
    "start": "1024520",
    "end": "1030640"
  },
  {
    "text": "last uh when the termination happens because every iut they have some some uh",
    "start": "1030640",
    "end": "1037360"
  },
  {
    "text": "Soft Data inside it and this shows what happens uh",
    "start": "1037360",
    "end": "1044880"
  },
  {
    "text": "without CSM so that's basically the Baseline uh uh native spark how Native",
    "start": "1044880",
    "end": "1050160"
  },
  {
    "text": "spark behave when uh termination happens so on the bottom you can see there is f",
    "start": "1050160",
    "end": "1057400"
  },
  {
    "text": "failed exception so that means the reducer s encountered this exception",
    "start": "1057400",
    "end": "1063400"
  },
  {
    "text": "they failed to fast s data from the merer side because the marer had been",
    "start": "1063400",
    "end": "1069559"
  },
  {
    "text": "killed they were gone so the uh s data was lost as a result on the left hand",
    "start": "1069559",
    "end": "1075840"
  },
  {
    "text": "side you can see there were multiple St tce because spark has to regenerate the",
    "start": "1075840",
    "end": "1082799"
  },
  {
    "text": "s data and on the right hand side you can see there are multiple entries in the",
    "start": "1082799",
    "end": "1088960"
  },
  {
    "text": "input column that's because the job when they do retrice they had to reread the",
    "start": "1088960",
    "end": "1094919"
  },
  {
    "text": "data from the shes so those when those retra happened it take a lot of times",
    "start": "1094919",
    "end": "1100600"
  },
  {
    "text": "and that's all dollars and here is what happened when",
    "start": "1100600",
    "end": "1106440"
  },
  {
    "text": "we enable CSM so there was no stage reice and uh there only the data only",
    "start": "1106440",
    "end": "1115159"
  },
  {
    "text": "read once so what happened behind the scene is that uh uh when we enable CSM",
    "start": "1115159",
    "end": "1121559"
  },
  {
    "text": "we got a copy we got another copy of the sof data uh on the cloud storage so when",
    "start": "1121559",
    "end": "1128760"
  },
  {
    "text": "the executor got killed the reducer was able to fetch the other copy from the",
    "start": "1128760",
    "end": "1135320"
  },
  {
    "text": "cloud storage so it can continue to move on so it doesn't it didn't need to uh",
    "start": "1135320",
    "end": "1140640"
  },
  {
    "text": "redo the re and uh the result is uh sewing uh on",
    "start": "1140640",
    "end": "1146559"
  },
  {
    "text": "the bottom so we can see the run time when we enable the CSM is about 50%",
    "start": "1146559",
    "end": "1153039"
  },
  {
    "text": "reduction compared to the",
    "start": "1153039",
    "end": "1156639"
  },
  {
    "text": "Baseline and we run this uh benchmarking mul multiple times we use a scheduler to",
    "start": "1159240",
    "end": "1165520"
  },
  {
    "text": "schedule the job regularly and uh on average we observed uh about 5 to 10%",
    "start": "1165520",
    "end": "1175400"
  },
  {
    "text": "overhead that's due to the actual right so that's the one we",
    "start": "1175400",
    "end": "1181760"
  },
  {
    "text": "concerned and uh with that we were able to achieve reliability so there are no",
    "start": "1181760",
    "end": "1189480"
  },
  {
    "text": "uh job failures uh because we had another copy",
    "start": "1189480",
    "end": "1195960"
  },
  {
    "text": "of the s data on the cloud storage and that improve the",
    "start": "1195960",
    "end": "1201120"
  },
  {
    "text": "reliability and there are no much uh stage retrace also because uh the job",
    "start": "1201120",
    "end": "1208200"
  },
  {
    "text": "was able to continue without having to regenerate s data and we also run this uh on the",
    "start": "1208200",
    "end": "1216200"
  },
  {
    "text": "standard jobs so which are basically large scale applications in",
    "start": "1216200",
    "end": "1222799"
  },
  {
    "text": "production and we observed a similar result and we actually uh quite a few of",
    "start": "1222799",
    "end": "1232039"
  },
  {
    "text": "our uh standard jobs we enabled our snle rate uh and uh we observed a similar uh",
    "start": "1232039",
    "end": "1240039"
  },
  {
    "text": "same run time as the Baseline so meaning that the overhead is very minimum when",
    "start": "1240039",
    "end": "1246840"
  },
  {
    "text": "we enable a single R so basically we take a little risk uh but we gain some",
    "start": "1246840",
    "end": "1253520"
  },
  {
    "text": "performance boost uh and we do uh notice there were",
    "start": "1253520",
    "end": "1259120"
  },
  {
    "text": "about a 5% CPU usage uh increase and mostly uh that's",
    "start": "1259120",
    "end": "1265360"
  },
  {
    "text": "because uh Soft Data we read from local dis we need to do we need to do uncompression and decretion and also",
    "start": "1265360",
    "end": "1272960"
  },
  {
    "text": "copy itself it taks and uh uh also nwork IO there so",
    "start": "1272960",
    "end": "1279080"
  },
  {
    "text": "there is slightly overhead about",
    "start": "1279080",
    "end": "1283519"
  },
  {
    "text": "5% and just a recap for the C M so CSM",
    "start": "1284159",
    "end": "1291200"
  },
  {
    "text": "it is a solution to uh increase the reliability for spark especially when",
    "start": "1291200",
    "end": "1297880"
  },
  {
    "text": "spark running on top of kubernetes in a cloud environment it is a so less approach it",
    "start": "1297880",
    "end": "1306080"
  },
  {
    "text": "mean that we don't need to it doesn't require to set up a separate shaffle service and",
    "start": "1306080",
    "end": "1314080"
  },
  {
    "text": "that save a lot of effort uh so we say cost both from the",
    "start": "1314080",
    "end": "1319960"
  },
  {
    "text": "compute and from the SRE side and we try to take advantage cloud",
    "start": "1319960",
    "end": "1327520"
  },
  {
    "text": "storage as a mature Service uh it is reliable scalable",
    "start": "1327520",
    "end": "1333039"
  },
  {
    "text": "secure secure and there are BNS of uh features we just want to take and",
    "start": "1333039",
    "end": "1340080"
  },
  {
    "text": "use and uh so this solution can be applied to multiple",
    "start": "1340080",
    "end": "1345799"
  },
  {
    "text": "scenarios so uh firstly it allow us to run spark on top of Spar",
    "start": "1345799",
    "end": "1353320"
  },
  {
    "text": "VMS so Spar VMS basically coming with a a significant cost uh",
    "start": "1353320",
    "end": "1359679"
  },
  {
    "text": "discount so that enable uh cost efficiency be available utilizing spot",
    "start": "1359679",
    "end": "1367320"
  },
  {
    "text": "VMS and another uh use case is dynamic allocation so I want to uh talk a little",
    "start": "1367320",
    "end": "1373039"
  },
  {
    "text": "bit about Dynamic allocation uh So currently uh Spark",
    "start": "1373039",
    "end": "1380000"
  },
  {
    "text": "uh if we run spark on kubernetes it requir to if we want to enable Dynamic",
    "start": "1380000",
    "end": "1387320"
  },
  {
    "text": "allocation it required to enable sof tracking and the S tracking time out by",
    "start": "1387320",
    "end": "1395120"
  },
  {
    "text": "default is infinity so basically it say it means that uh uh if there is any self",
    "start": "1395120",
    "end": "1402520"
  },
  {
    "text": "data on executors Dynam Dynamic allocation will not work very effectively",
    "start": "1402520",
    "end": "1409159"
  },
  {
    "text": "uh but if we enable CSM since we have another copy of soft data on the cloud",
    "start": "1409159",
    "end": "1414799"
  },
  {
    "text": "storage we achieved somehow uh",
    "start": "1414799",
    "end": "1419880"
  },
  {
    "text": "decoupling for computer and storage so when we enable it in our standard jobs",
    "start": "1419880",
    "end": "1427480"
  },
  {
    "text": "we observed uh uh the dynamic the dynamic dynamic allocation uh happen",
    "start": "1427480",
    "end": "1434679"
  },
  {
    "text": "more effectively more efficiently and that basically it is horizontal a scale for spark on the Java",
    "start": "1434679",
    "end": "1445120"
  },
  {
    "text": "level yeah and that's pretty much for today's talk and uh we like to take",
    "start": "1446120",
    "end": "1452200"
  },
  {
    "text": "questions or feedbacks if there is thank you yeah thank",
    "start": "1452200",
    "end": "1458860"
  },
  {
    "text": "[Applause]",
    "start": "1458860",
    "end": "1463840"
  },
  {
    "text": "you yeah if you have any question relate to this or you have any question about sparkk Dynamic allocation yeah we can",
    "start": "1464720",
    "end": "1471720"
  },
  {
    "text": "feel free to ask yeah oh the question is is it open",
    "start": "1471720",
    "end": "1479440"
  },
  {
    "text": "sourced uh it is not open sourced yet so we are working on",
    "start": "1479440",
    "end": "1484640"
  },
  {
    "text": "it but the idea is general and uh",
    "start": "1485240",
    "end": "1490640"
  },
  {
    "text": "overall it doesn't take too much effort to implement yourself yeah by the",
    "start": "1490640",
    "end": "1496880"
  },
  {
    "text": "way okay go",
    "start": "1497320",
    "end": "1502120"
  },
  {
    "text": "ahead sorry I cannot hear so there's a microphone there",
    "start": "1503799",
    "end": "1509159"
  },
  {
    "text": "yeah can you elaborate a little bit on the data format that you are using when",
    "start": "1509159",
    "end": "1514679"
  },
  {
    "text": "you're writing to the cloud storage okay this is something Prof",
    "start": "1514679",
    "end": "1522360"
  },
  {
    "text": "yeah okay yeah okay I can I answer this so the question is the data format",
    "start": "1523600",
    "end": "1528840"
  },
  {
    "text": "and we the short answer is we didn't change the DAT format because we want the solution to be simple and uh the",
    "start": "1528840",
    "end": "1536679"
  },
  {
    "text": "answer is Spar shle file it kind of a file we segmented uh it has several",
    "start": "1536679",
    "end": "1542600"
  },
  {
    "text": "segment each segment is a split it's corresponding to the process split in the spark we just copy the whole file to",
    "start": "1542600",
    "end": "1549919"
  },
  {
    "text": "the cloud story so we're now trying to do any uh shorting merging those stuff",
    "start": "1549919",
    "end": "1555520"
  },
  {
    "text": "things yet uh but uh is a good uh question that may potentially improve",
    "start": "1555520",
    "end": "1563120"
  },
  {
    "text": "the performance further",
    "start": "1563120",
    "end": "1566880"
  },
  {
    "text": "yeah it I may have one um you mentioned that",
    "start": "1571600",
    "end": "1577720"
  },
  {
    "text": "storing this uh Shuffle data on uh the cloud blob store is secure um how do you",
    "start": "1577720",
    "end": "1584720"
  },
  {
    "text": "achieve that oh you mean security yes like authentication and none other",
    "start": "1584720",
    "end": "1592840"
  },
  {
    "text": "user can read the very same bucket or the same data yeah good question so as I mentioned that we uh we trying to fully",
    "start": "1592840",
    "end": "1601360"
  },
  {
    "text": "leverage features from the cloud storage and the cloud storage it come with fun",
    "start": "1601360",
    "end": "1607480"
  },
  {
    "text": "access control and we uh so uh so we",
    "start": "1607480",
    "end": "1613679"
  },
  {
    "text": "basically use the uh uh the security",
    "start": "1613679",
    "end": "1619039"
  },
  {
    "text": "uh Access Control to control the access for example we use the uh IM roles so",
    "start": "1619039",
    "end": "1626960"
  },
  {
    "text": "that uh enable uh to uh have authentication and aeration happened on",
    "start": "1626960",
    "end": "1634399"
  },
  {
    "text": "the SLE data and uh uh we uh we do have like Q based authorization and so we can",
    "start": "1634399",
    "end": "1643799"
  },
  {
    "text": "uh uh keep uh the self data uh in a secure way on the cloud",
    "start": "1643799",
    "end": "1649640"
  },
  {
    "text": "storage yeah so yeah that explain the from the cloud storage part from spark",
    "start": "1649640",
    "end": "1655799"
  },
  {
    "text": "side NE setting you can enable data encryption in spark so it's a spark",
    "start": "1655799",
    "end": "1661880"
  },
  {
    "text": "config supported by native spark and we also leverage that after you enable the encryption spark will generate a unique",
    "start": "1661880",
    "end": "1669760"
  },
  {
    "text": "key for each application and it will use that key to encrypt your data before it",
    "start": "1669760",
    "end": "1676200"
  },
  {
    "text": "rides to the local dis and the right to the cloud storage and because other application and other people do not know",
    "start": "1676200",
    "end": "1682840"
  },
  {
    "text": "that key so the data is is very secure only for your own",
    "start": "1682840",
    "end": "1688640"
  },
  {
    "text": "application all right so another question so from what I'm understanding the lack of an external Shuffle service",
    "start": "1689880",
    "end": "1697559"
  },
  {
    "text": "makes so that if you're trying to use the dynamic executor allocation uh",
    "start": "1697559",
    "end": "1702679"
  },
  {
    "text": "basically it's going to how to say have an harder time in downscaling these executors",
    "start": "1702679",
    "end": "1708880"
  },
  {
    "text": "because I mean those partition are going to maybe still needed in the future in the future stages uh is your solution uh",
    "start": "1708880",
    "end": "1717440"
  },
  {
    "text": "as how to say uh allowing spark to downscale those Dynamic allocated",
    "start": "1717440",
    "end": "1724880"
  },
  {
    "text": "executors uh yeah exactly uh as you mentioned without uh uh another copy of",
    "start": "1724880",
    "end": "1732240"
  },
  {
    "text": "the Soft Data all the Soft Data will be stored on the local disk and that's",
    "start": "1732240",
    "end": "1737320"
  },
  {
    "text": "associated with the executors so even though you enable Dynamic allocation but the sof tracking",
    "start": "1737320",
    "end": "1745279"
  },
  {
    "text": "will disallow the scaling down happen effectively yeah exactly yeah yeah thank",
    "start": "1745279",
    "end": "1752840"
  },
  {
    "text": "you so I so with I just want to explain with Shuffle I was Cloud Shuffle manager",
    "start": "1752840",
    "end": "1759960"
  },
  {
    "text": "you can enable that at the down scale very easily without cloud manager",
    "start": "1759960",
    "end": "1766679"
  },
  {
    "text": "normally it does doesn't work well with Native spark there's a risk involved",
    "start": "1766679",
    "end": "1772039"
  },
  {
    "text": "because you don't set Infinity as the tracking and so if if they get uh",
    "start": "1772039",
    "end": "1778760"
  },
  {
    "text": "um deleted the executor then you lost the data and you start again yeah",
    "start": "1778760",
    "end": "1783919"
  },
  {
    "text": "exactly we when use cloud Shuffle manager we set that time out to zero so",
    "start": "1783919",
    "end": "1789200"
  },
  {
    "text": "it just expire immedately just be uh shut down at any time because you can",
    "start": "1789200",
    "end": "1794279"
  },
  {
    "text": "get from the cloud storage yes exactly cloud storage we uh talking about S3 GCS",
    "start": "1794279",
    "end": "1800559"
  },
  {
    "text": "and that kind of yes yeah we're trying to uh make the solution uh cloud",
    "start": "1800559",
    "end": "1805640"
  },
  {
    "text": "provider agnostic so it means that it can be used uh across different Service",
    "start": "1805640",
    "end": "1812159"
  },
  {
    "text": "Pro providers yeah and one curiosity is how long did uh it take for you to build",
    "start": "1812159",
    "end": "1818720"
  },
  {
    "text": "that uh because you said it's not open source yet you can build it yourself the idea is quite easy but I'm I'm curious",
    "start": "1818720",
    "end": "1826360"
  },
  {
    "text": "how long it take good good good yeah good question thanks for asking that to",
    "start": "1826360",
    "end": "1832279"
  },
  {
    "text": "get is not that easy because you see there are so many solutions previously",
    "start": "1832279",
    "end": "1838360"
  },
  {
    "text": "we tried different ideas and we do multiple iteration to get there so now the idea is very simple but it is after",
    "start": "1838360",
    "end": "1845960"
  },
  {
    "text": "several round of iteration if you just focus current idea the change is only on",
    "start": "1845960",
    "end": "1852320"
  },
  {
    "text": "the shule writer and the reader it's a small change and you at retry in in",
    "start": "1852320",
    "end": "1859120"
  },
  {
    "text": "spark internal code I will say if you are very familiar with spark you can do",
    "start": "1859120",
    "end": "1865000"
  },
  {
    "text": "the change adding some testing time maybe in one or two months if you are familiar",
    "start": "1865000",
    "end": "1871559"
  },
  {
    "text": "with spark yeah okay and uh did you need also to patch uh spark core or was it",
    "start": "1871559",
    "end": "1878960"
  },
  {
    "text": "possible to do it just using uh plugins let's say yeah both are possible if you",
    "start": "1878960",
    "end": "1885080"
  },
  {
    "text": "want to do it quick and dirty you can just make change in inside spark kernel",
    "start": "1885080",
    "end": "1890559"
  },
  {
    "text": "call code but spark Shuffle manager has abstraction like Shuffle manager",
    "start": "1890559",
    "end": "1895760"
  },
  {
    "text": "interface so previously I built my previous version of sh service I use that without need to change it the SP",
    "start": "1895760",
    "end": "1902399"
  },
  {
    "text": "call code but that will take kind of more time but both are possible yeah okay but in your case so you because I'm",
    "start": "1902399",
    "end": "1910960"
  },
  {
    "text": "cous about the let's say the fullback logic is that built into your Shuffle",
    "start": "1910960",
    "end": "1916840"
  },
  {
    "text": "manager uh so uh you don't need to touch anything of spark core to make that work",
    "start": "1916840",
    "end": "1924880"
  },
  {
    "text": "because your Shuffle manager is like uh probably borrowing some code from the",
    "start": "1924880",
    "end": "1931000"
  },
  {
    "text": "standard one plus adding your logic is that the the case uh right right now we",
    "start": "1931000",
    "end": "1937440"
  },
  {
    "text": "embed that code in Spar core part because we want to iterate fast okay so we are working on to extract that and",
    "start": "1937440",
    "end": "1944360"
  },
  {
    "text": "put it in the shle manager abstraction so it won't kind of change the internal code got it so right now you have like",
    "start": "1944360",
    "end": "1951200"
  },
  {
    "text": "your spark drro yes okay thank you cool no problem",
    "start": "1951200",
    "end": "1957200"
  },
  {
    "text": "yeah okay thank you everyone uh bo and me will be around if you have questions feedback is welcome to this us thank you",
    "start": "1959240",
    "end": "1966880"
  },
  {
    "text": "okay thank you",
    "start": "1966880",
    "end": "1971080"
  }
]
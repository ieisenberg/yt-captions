[
  {
    "text": "hey everyone welcome to ccon my name is",
    "start": "120",
    "end": "2879"
  },
  {
    "text": "Kevin Clues and this is my colleague",
    "start": "2879",
    "end": "4440"
  },
  {
    "text": "sanj chaty and today we're going to be",
    "start": "4440",
    "end": "6640"
  },
  {
    "text": "talking about accelerating AI workloads",
    "start": "6640",
    "end": "8760"
  },
  {
    "text": "with gpus in kubernetes so let's Dive",
    "start": "8760",
    "end": "11679"
  },
  {
    "text": "Right",
    "start": "11679",
    "end": "13000"
  },
  {
    "text": "In we are in the midst of the next",
    "start": "13000",
    "end": "15240"
  },
  {
    "text": "Industrial Revolution from self-driving",
    "start": "15240",
    "end": "17760"
  },
  {
    "text": "cars to real-time Health monitoring and",
    "start": "17760",
    "end": "20400"
  },
  {
    "text": "smart cities AI is powering it",
    "start": "20400",
    "end": "23599"
  },
  {
    "text": "all and at the heart of this revolution",
    "start": "23599",
    "end": "26240"
  },
  {
    "text": "are gpus and the platform that provides",
    "start": "26240",
    "end": "28760"
  },
  {
    "text": "applications access to them",
    "start": "28760",
    "end": "30960"
  },
  {
    "text": "for many kubernetes has already become",
    "start": "30960",
    "end": "33440"
  },
  {
    "text": "this platform but we still have a lot of",
    "start": "33440",
    "end": "35960"
  },
  {
    "text": "work to do before we can unlock the full",
    "start": "35960",
    "end": "37680"
  },
  {
    "text": "potential of gpus to accelerate AI",
    "start": "37680",
    "end": "40079"
  },
  {
    "text": "workloads on",
    "start": "40079",
    "end": "42000"
  },
  {
    "text": "kubernetes this includes changes to both",
    "start": "42000",
    "end": "44079"
  },
  {
    "text": "the low-level mechanisms used to request",
    "start": "44079",
    "end": "46199"
  },
  {
    "text": "access to",
    "start": "46199",
    "end": "47120"
  },
  {
    "text": "gpus as well as the higher level",
    "start": "47120",
    "end": "49160"
  },
  {
    "text": "processes needed to map a set of gpus to",
    "start": "49160",
    "end": "51879"
  },
  {
    "text": "a workload based on its",
    "start": "51879",
    "end": "54760"
  },
  {
    "text": "requests where the biggest change in",
    "start": "54760",
    "end": "56760"
  },
  {
    "text": "terms of resource management will be",
    "start": "56760",
    "end": "59000"
  },
  {
    "text": "direct support for nonf funable and",
    "start": "59000",
    "end": "61440"
  },
  {
    "text": "non-exclusive resources at the node",
    "start": "61440",
    "end": "64960"
  },
  {
    "text": "level and the changes at the higher",
    "start": "64960",
    "end": "66960"
  },
  {
    "text": "layers will take the form of things like",
    "start": "66960",
    "end": "68840"
  },
  {
    "text": "topology aware placement strategies and",
    "start": "68840",
    "end": "71759"
  },
  {
    "text": "advanced multi-dimensional",
    "start": "71759",
    "end": "74799"
  },
  {
    "text": "scheduling so to kick things off I'm",
    "start": "75200",
    "end": "77640"
  },
  {
    "text": "going to start with a brief overview of",
    "start": "77640",
    "end": "79159"
  },
  {
    "text": "what it takes to enable GPU support in",
    "start": "79159",
    "end": "80920"
  },
  {
    "text": "kubernetes",
    "start": "80920",
    "end": "83400"
  },
  {
    "text": "today I'll then jump into the details of",
    "start": "83400",
    "end": "85640"
  },
  {
    "text": "one very specific use case that could",
    "start": "85640",
    "end": "87640"
  },
  {
    "text": "benefit from non-fungible and",
    "start": "87640",
    "end": "89280"
  },
  {
    "text": "non-exclusive of resources namely GPU",
    "start": "89280",
    "end": "94240"
  },
  {
    "text": "sharing I'll then introduce a new",
    "start": "94280",
    "end": "96200"
  },
  {
    "text": "feature called Dynamic resource",
    "start": "96200",
    "end": "97680"
  },
  {
    "text": "allocation or Dr for short which we see",
    "start": "97680",
    "end": "100880"
  },
  {
    "text": "as the enabler for taking GPU support",
    "start": "100880",
    "end": "102640"
  },
  {
    "text": "and kubernetes to the next",
    "start": "102640",
    "end": "105439"
  },
  {
    "text": "level finally I'll hand things over to",
    "start": "105439",
    "end": "107960"
  },
  {
    "text": "Sanjay who will walk us through some of",
    "start": "107960",
    "end": "109640"
  },
  {
    "text": "the challenges with scaling out gpus on",
    "start": "109640",
    "end": "114119"
  },
  {
    "text": "kubernetes so what does it take to",
    "start": "115360",
    "end": "117159"
  },
  {
    "text": "actually enable GPU support in",
    "start": "117159",
    "end": "118520"
  },
  {
    "text": "kubernetes today",
    "start": "118520",
    "end": "120880"
  },
  {
    "text": "well it takes a mix of host level",
    "start": "120880",
    "end": "122360"
  },
  {
    "text": "components such as the Nvidia container",
    "start": "122360",
    "end": "124240"
  },
  {
    "text": "toolkit and the underlying Nvidia GPU",
    "start": "124240",
    "end": "127759"
  },
  {
    "text": "driver as well as a set of kubernetes",
    "start": "127759",
    "end": "130000"
  },
  {
    "text": "specific components such as the cad",
    "start": "130000",
    "end": "132040"
  },
  {
    "text": "device plugin GPU feature Discovery and",
    "start": "132040",
    "end": "134920"
  },
  {
    "text": "the Nvidia Mig",
    "start": "134920",
    "end": "137599"
  },
  {
    "text": "manager with these in place one can make",
    "start": "137959",
    "end": "140840"
  },
  {
    "text": "requests like the one seen on the right",
    "start": "140840",
    "end": "142720"
  },
  {
    "text": "to inject GPU support into their",
    "start": "142720",
    "end": "146800"
  },
  {
    "text": "workloads as well as direct those",
    "start": "147599",
    "end": "149440"
  },
  {
    "text": "workloads to a particular type of GPU",
    "start": "149440",
    "end": "152000"
  },
  {
    "text": "using a node selector if",
    "start": "152000",
    "end": "155360"
  },
  {
    "text": "desired to ease the deployment of all",
    "start": "156959",
    "end": "159239"
  },
  {
    "text": "these components Nvidia provides a GPU",
    "start": "159239",
    "end": "161720"
  },
  {
    "text": "operator which I'm not going to go into",
    "start": "161720",
    "end": "163560"
  },
  {
    "text": "the details of today but I encourage you",
    "start": "163560",
    "end": "166319"
  },
  {
    "text": "to uh to watch the following talks later",
    "start": "166319",
    "end": "168840"
  },
  {
    "text": "this week um to learn more one tomorrow",
    "start": "168840",
    "end": "172280"
  },
  {
    "text": "at 3:25 p.m. and one on Friday at 11:00",
    "start": "172280",
    "end": "178000"
  },
  {
    "text": "a.m. for history lesson on the evolution",
    "start": "178480",
    "end": "180959"
  },
  {
    "text": "of GPU support in kubernetes I encourage",
    "start": "180959",
    "end": "183480"
  },
  {
    "text": "you to also check out the following",
    "start": "183480",
    "end": "184920"
  },
  {
    "text": "talks from various organizations at past",
    "start": "184920",
    "end": "189440"
  },
  {
    "text": "cucon okay so now that we know how to",
    "start": "192280",
    "end": "194760"
  },
  {
    "text": "bring kubernetes cluster up with GPU",
    "start": "194760",
    "end": "196400"
  },
  {
    "text": "support how do we actually make the most",
    "start": "196400",
    "end": "198440"
  },
  {
    "text": "of the gpus we have available to",
    "start": "198440",
    "end": "201319"
  },
  {
    "text": "us well there's five primary techniques",
    "start": "201319",
    "end": "203840"
  },
  {
    "text": "that can be used to share gpus amongst",
    "start": "203840",
    "end": "205799"
  },
  {
    "text": "multiple workloads time slicing MPS Mig",
    "start": "205799",
    "end": "211480"
  },
  {
    "text": "vgpus and Cuda",
    "start": "211480",
    "end": "214959"
  },
  {
    "text": "streams most of these techniques have",
    "start": "214959",
    "end": "216920"
  },
  {
    "text": "been available to kubernetes users in",
    "start": "216920",
    "end": "218439"
  },
  {
    "text": "one form or another for quite some",
    "start": "218439",
    "end": "221879"
  },
  {
    "text": "time the one exception being MPS which",
    "start": "221879",
    "end": "225360"
  },
  {
    "text": "we plan to release official support for",
    "start": "225360",
    "end": "227000"
  },
  {
    "text": "in the next couple of",
    "start": "227000",
    "end": "229760"
  },
  {
    "text": "weeks so what's the difference between",
    "start": "232000",
    "end": "234079"
  },
  {
    "text": "all of these uh different sharing",
    "start": "234079",
    "end": "236319"
  },
  {
    "text": "techniques well as you can imagine time",
    "start": "236319",
    "end": "238799"
  },
  {
    "text": "slicing provides the ability to run",
    "start": "238799",
    "end": "240480"
  },
  {
    "text": "several workloads concurrently on the",
    "start": "240480",
    "end": "242079"
  },
  {
    "text": "same GPU rather than spreading them",
    "start": "242079",
    "end": "244319"
  },
  {
    "text": "across multiple",
    "start": "244319",
    "end": "246159"
  },
  {
    "text": "gpus each workload has access to the",
    "start": "246159",
    "end": "248480"
  },
  {
    "text": "full capabilities of the GPU but they",
    "start": "248480",
    "end": "250879"
  },
  {
    "text": "alternate in",
    "start": "250879",
    "end": "253599"
  },
  {
    "text": "time MPS in contrast provides a method",
    "start": "254640",
    "end": "257680"
  },
  {
    "text": "of space partitioning where instead of",
    "start": "257680",
    "end": "259840"
  },
  {
    "text": "alternating workloads on a Shar GPU in",
    "start": "259840",
    "end": "261919"
  },
  {
    "text": "Time Each workload remains resident on",
    "start": "261919",
    "end": "264400"
  },
  {
    "text": "the GPU without being swapped off but",
    "start": "264400",
    "end": "267120"
  },
  {
    "text": "with only a fraction of its total memory",
    "start": "267120",
    "end": "268800"
  },
  {
    "text": "and compute capability",
    "start": "268800",
    "end": "271720"
  },
  {
    "text": "Mig is similar to MPS in that the",
    "start": "273680",
    "end": "275639"
  },
  {
    "text": "resources of the GPU are space",
    "start": "275639",
    "end": "277160"
  },
  {
    "text": "partitioned but they are done so at the",
    "start": "277160",
    "end": "279039"
  },
  {
    "text": "hardware level rather than in software",
    "start": "279039",
    "end": "281560"
  },
  {
    "text": "meaning that Mig devices are suitable",
    "start": "281560",
    "end": "283039"
  },
  {
    "text": "for multi-tenant environments where MPS",
    "start": "283039",
    "end": "285680"
  },
  {
    "text": "is",
    "start": "285680",
    "end": "287840"
  },
  {
    "text": "not now vgpus are interesting in that",
    "start": "289240",
    "end": "292199"
  },
  {
    "text": "they can be configured for either time",
    "start": "292199",
    "end": "293800"
  },
  {
    "text": "slicing or space partitioning using Mig",
    "start": "293800",
    "end": "297400"
  },
  {
    "text": "with the added property that each vgpu",
    "start": "297400",
    "end": "299560"
  },
  {
    "text": "is is wrapped in a virtual machine",
    "start": "299560",
    "end": "301600"
  },
  {
    "text": "making them suitable for multi-tenanted",
    "start": "301600",
    "end": "303520"
  },
  {
    "text": "environments under both",
    "start": "303520",
    "end": "306960"
  },
  {
    "text": "configurations unlike the previous",
    "start": "317400",
    "end": "319080"
  },
  {
    "text": "sharing techniques which provide shared",
    "start": "319080",
    "end": "321160"
  },
  {
    "text": "access to a GPU at the system level the",
    "start": "321160",
    "end": "323800"
  },
  {
    "text": "final one Cuda streams is a programming",
    "start": "323800",
    "end": "327120"
  },
  {
    "text": "abstraction that allows you to run",
    "start": "327120",
    "end": "328520"
  },
  {
    "text": "multiple kernels in par",
    "start": "328520",
    "end": "330280"
  },
  {
    "text": "from within a single",
    "start": "330280",
    "end": "333120"
  },
  {
    "text": "application and with all of these",
    "start": "333639",
    "end": "335319"
  },
  {
    "text": "sharing strategies in place you can",
    "start": "335319",
    "end": "337319"
  },
  {
    "text": "actually layer them on top of one",
    "start": "337319",
    "end": "338800"
  },
  {
    "text": "another in order to maximize GPU",
    "start": "338800",
    "end": "340919"
  },
  {
    "text": "utilization across all of your",
    "start": "340919",
    "end": "344680"
  },
  {
    "text": "workloads now different setups call for",
    "start": "347880",
    "end": "350600"
  },
  {
    "text": "different strategies in terms of how or",
    "start": "350600",
    "end": "353080"
  },
  {
    "text": "if GPU sharing should be used at",
    "start": "353080",
    "end": "355520"
  },
  {
    "text": "all and I'm not going to go through this",
    "start": "355520",
    "end": "357440"
  },
  {
    "text": "table right now but I encourage you to",
    "start": "357440",
    "end": "359400"
  },
  {
    "text": "read read the blog post linked at the",
    "start": "359400",
    "end": "360800"
  },
  {
    "text": "bottom of this slide to learn more about",
    "start": "360800",
    "end": "362759"
  },
  {
    "text": "the advantages and disadvantages of each",
    "start": "362759",
    "end": "364560"
  },
  {
    "text": "strategy in different",
    "start": "364560",
    "end": "367680"
  },
  {
    "text": "scenarios I also recommend checking out",
    "start": "369479",
    "end": "371680"
  },
  {
    "text": "these talks to learn",
    "start": "371680",
    "end": "374599"
  },
  {
    "text": "more okay so the last thing I'm going to",
    "start": "379240",
    "end": "381520"
  },
  {
    "text": "talk uh talk about before handing things",
    "start": "381520",
    "end": "383039"
  },
  {
    "text": "over to Sanjay is uh is",
    "start": "383039",
    "end": "386160"
  },
  {
    "text": "Dr so Dr is a new way of requesting",
    "start": "386160",
    "end": "389039"
  },
  {
    "text": "resources kubernetes available as an",
    "start": "389039",
    "end": "391160"
  },
  {
    "text": "alpha feature since",
    "start": "391160",
    "end": "393280"
  },
  {
    "text": "126 it provides an alternative to the",
    "start": "393280",
    "end": "395759"
  },
  {
    "text": "count-based API for requesting",
    "start": "395759",
    "end": "398120"
  },
  {
    "text": "nvidia.com",
    "start": "398120",
    "end": "399639"
  },
  {
    "text": "gpu2 for",
    "start": "399639",
    "end": "402319"
  },
  {
    "text": "example and what makes it so powerful is",
    "start": "402319",
    "end": "404840"
  },
  {
    "text": "that it puts full control of the API to",
    "start": "404840",
    "end": "406720"
  },
  {
    "text": "select and configure resources directly",
    "start": "406720",
    "end": "409000"
  },
  {
    "text": "in the hands of third party",
    "start": "409000",
    "end": "412080"
  },
  {
    "text": "developers it also gives one the ability",
    "start": "412479",
    "end": "414599"
  },
  {
    "text": "to precisely control how resources are",
    "start": "414599",
    "end": "416280"
  },
  {
    "text": "shared between containers and pods which",
    "start": "416280",
    "end": "418599"
  },
  {
    "text": "is one of the main limitations of the",
    "start": "418599",
    "end": "420080"
  },
  {
    "text": "existing device plugin API as it stands",
    "start": "420080",
    "end": "424000"
  },
  {
    "text": "today in the interest of time I'm not",
    "start": "425639",
    "end": "428199"
  },
  {
    "text": "going to dive too deep into the details",
    "start": "428199",
    "end": "429680"
  },
  {
    "text": "of Dr right now but I encourage you to",
    "start": "429680",
    "end": "432280"
  },
  {
    "text": "stick around for these two talks later",
    "start": "432280",
    "end": "433919"
  },
  {
    "text": "today to learn",
    "start": "433919",
    "end": "436639"
  },
  {
    "text": "more I also encourage you to check out",
    "start": "439639",
    "end": "441960"
  },
  {
    "text": "these talks from previous",
    "start": "441960",
    "end": "444919"
  },
  {
    "text": "cubon in particular my one from last",
    "start": "444919",
    "end": "447680"
  },
  {
    "text": "November which focuses specifically on",
    "start": "447680",
    "end": "449599"
  },
  {
    "text": "Dr with",
    "start": "449599",
    "end": "452520"
  },
  {
    "text": "gpus and with that I'll hand things over",
    "start": "454680",
    "end": "457120"
  },
  {
    "text": "to sandre who will take it from",
    "start": "457120",
    "end": "460280"
  },
  {
    "text": "here thank you",
    "start": "463479",
    "end": "466800"
  },
  {
    "text": "Kevin hello cucon it is such an honor to",
    "start": "466960",
    "end": "469919"
  },
  {
    "text": "be here today as we living in the most",
    "start": "469919",
    "end": "472120"
  },
  {
    "text": "incredible moment of Our Lives the world",
    "start": "472120",
    "end": "475360"
  },
  {
    "text": "is discovering and falling in love with",
    "start": "475360",
    "end": "477120"
  },
  {
    "text": "generative AI today I want to highlight",
    "start": "477120",
    "end": "480319"
  },
  {
    "text": "Nvidia Picasso a gen Foundry to build",
    "start": "480319",
    "end": "484319"
  },
  {
    "text": "and deploy foundational models for",
    "start": "484319",
    "end": "486120"
  },
  {
    "text": "computer",
    "start": "486120",
    "end": "487520"
  },
  {
    "text": "vision I feel so proud to share that",
    "start": "487520",
    "end": "490360"
  },
  {
    "text": "cuetes is driving Picasso's life cycle",
    "start": "490360",
    "end": "493599"
  },
  {
    "text": "from training to",
    "start": "493599",
    "end": "495879"
  },
  {
    "text": "inference and today I will focus on",
    "start": "495879",
    "end": "498720"
  },
  {
    "text": "training and the challenges we have",
    "start": "498720",
    "end": "500800"
  },
  {
    "text": "faced when scaling out with",
    "start": "500800",
    "end": "503000"
  },
  {
    "text": "gpus for the inference part I hope you",
    "start": "503000",
    "end": "506080"
  },
  {
    "text": "got to attend my colleague Yan Chen's",
    "start": "506080",
    "end": "509000"
  },
  {
    "text": "talk yest today on talking about the",
    "start": "509000",
    "end": "511400"
  },
  {
    "text": "costs of",
    "start": "511400",
    "end": "513839"
  },
  {
    "text": "inference now Pico's Journey on",
    "start": "513919",
    "end": "516000"
  },
  {
    "text": "kubernetes started back in",
    "start": "516000",
    "end": "517880"
  },
  {
    "text": "20120 you can check out our coupon talks",
    "start": "517880",
    "end": "520959"
  },
  {
    "text": "from that year for more",
    "start": "520959",
    "end": "522599"
  },
  {
    "text": "details now the training workloads are",
    "start": "522599",
    "end": "524880"
  },
  {
    "text": "essentially bad jobs that require",
    "start": "524880",
    "end": "527680"
  },
  {
    "text": "anywhere from 8 to 52 gpus and they all",
    "start": "527680",
    "end": "531800"
  },
  {
    "text": "depend on all reduced Collective",
    "start": "531800",
    "end": "533959"
  },
  {
    "text": "communication between all the gpus As",
    "start": "533959",
    "end": "536519"
  },
  {
    "text": "for the synchronous stochastic radient",
    "start": "536519",
    "end": "538440"
  },
  {
    "text": "descent",
    "start": "538440",
    "end": "540279"
  },
  {
    "text": "however to reliably run multinode jobs",
    "start": "540279",
    "end": "544279"
  },
  {
    "text": "of various skilles and priorities from",
    "start": "544279",
    "end": "546399"
  },
  {
    "text": "multiple users on a shared GPU cluster",
    "start": "546399",
    "end": "550279"
  },
  {
    "text": "we realize the need to augment",
    "start": "550279",
    "end": "551920"
  },
  {
    "text": "kubernetes with Advanced scheduling",
    "start": "551920",
    "end": "554720"
  },
  {
    "text": "capabilities for example gang scheduling",
    "start": "554720",
    "end": "557440"
  },
  {
    "text": "starvation handling topology aware",
    "start": "557440",
    "end": "560560"
  },
  {
    "text": "placement fairness algorithms and much",
    "start": "560560",
    "end": "564240"
  },
  {
    "text": "more currently many of these features",
    "start": "564240",
    "end": "566959"
  },
  {
    "text": "exist in open source projects today but",
    "start": "566959",
    "end": "570440"
  },
  {
    "text": "we still need comprehensive Solutions in",
    "start": "570440",
    "end": "573600"
  },
  {
    "text": "kubernetes when scaling out with",
    "start": "573600",
    "end": "576360"
  },
  {
    "text": "gpus today I will touch upon the top",
    "start": "576360",
    "end": "579120"
  },
  {
    "text": "three challenges namely topology of",
    "start": "579120",
    "end": "581480"
  },
  {
    "text": "repare placement fall tolerance and",
    "start": "581480",
    "end": "584120"
  },
  {
    "text": "multi-dimensional",
    "start": "584120",
    "end": "586440"
  },
  {
    "text": "optimization first let's look into the",
    "start": "586440",
    "end": "588440"
  },
  {
    "text": "challenges with topology of we",
    "start": "588440",
    "end": "591000"
  },
  {
    "text": "placement to satisfy the massive compute",
    "start": "591000",
    "end": "594320"
  },
  {
    "text": "demands of generative AI scaleout",
    "start": "594320",
    "end": "596920"
  },
  {
    "text": "clusters need to interconnect thousands",
    "start": "596920",
    "end": "598839"
  },
  {
    "text": "of gpus",
    "start": "598839",
    "end": "600720"
  },
  {
    "text": "now inside a djx node for example the",
    "start": "600720",
    "end": "603279"
  },
  {
    "text": "djx a100 node there are eight gpus and",
    "start": "603279",
    "end": "606480"
  },
  {
    "text": "they can all directly communicate with",
    "start": "606480",
    "end": "608399"
  },
  {
    "text": "each other using envil",
    "start": "608399",
    "end": "610040"
  },
  {
    "text": "link however beyond the envil link",
    "start": "610040",
    "end": "612440"
  },
  {
    "text": "domain multi-level rack and spine",
    "start": "612440",
    "end": "615000"
  },
  {
    "text": "switching units with GPU direct RDMA",
    "start": "615000",
    "end": "618079"
  },
  {
    "text": "support can scale out these clusters",
    "start": "618079",
    "end": "620560"
  },
  {
    "text": "with hundreds and thousands of djx",
    "start": "620560",
    "end": "622839"
  },
  {
    "text": "nodes so to schedule multinode jobs you",
    "start": "622839",
    "end": "626279"
  },
  {
    "text": "have to be aware of two net topology",
    "start": "626279",
    "end": "628519"
  },
  {
    "text": "aware constraints first an optimal",
    "start": "628519",
    "end": "633320"
  },
  {
    "text": "placement that minimizes the Hop",
    "start": "633320",
    "end": "635600"
  },
  {
    "text": "distance between the",
    "start": "635600",
    "end": "637000"
  },
  {
    "text": "nodes and second B packing these",
    "start": "637000",
    "end": "640240"
  },
  {
    "text": "multi-node jobs within switching",
    "start": "640240",
    "end": "642360"
  },
  {
    "text": "hierarchies to improve cluster",
    "start": "642360",
    "end": "645920"
  },
  {
    "text": "occupancy and within a node the",
    "start": "645920",
    "end": "648839"
  },
  {
    "text": "application launcher also needs to be",
    "start": "648839",
    "end": "650560"
  },
  {
    "text": "Numa aware so that it can bind the",
    "start": "650560",
    "end": "653279"
  },
  {
    "text": "training processes to the appropriate",
    "start": "653279",
    "end": "655160"
  },
  {
    "text": "CPU core complex for example in a dgx",
    "start": "655160",
    "end": "657959"
  },
  {
    "text": "a100 node there are Numa nodes but the",
    "start": "657959",
    "end": "660920"
  },
  {
    "text": "eight gpus are connected to only four of",
    "start": "660920",
    "end": "663079"
  },
  {
    "text": "them hence topology we placement of a",
    "start": "663079",
    "end": "665800"
  },
  {
    "text": "training application is key both within",
    "start": "665800",
    "end": "668639"
  },
  {
    "text": "and across",
    "start": "668639",
    "end": "670160"
  },
  {
    "text": "nodes next let's look at fall tolerance",
    "start": "670160",
    "end": "673079"
  },
  {
    "text": "and",
    "start": "673079",
    "end": "674399"
  },
  {
    "text": "resiliency since GPU clusters constantly",
    "start": "674399",
    "end": "677120"
  },
  {
    "text": "operate at Peak Performance it is not",
    "start": "677120",
    "end": "679760"
  },
  {
    "text": "uncommon that electrical and mechanical",
    "start": "679760",
    "end": "682399"
  },
  {
    "text": "components can degrade or fail over time",
    "start": "682399",
    "end": "685639"
  },
  {
    "text": "and these component failures can lead to",
    "start": "685639",
    "end": "688680"
  },
  {
    "text": "issues like GPU throttling and even job",
    "start": "688680",
    "end": "691800"
  },
  {
    "text": "failures so we need to detect these",
    "start": "691800",
    "end": "694440"
  },
  {
    "text": "signals and isolate the faulty nodes and",
    "start": "694440",
    "end": "697480"
  },
  {
    "text": "D so that we can diagnose and repair",
    "start": "697480",
    "end": "699200"
  },
  {
    "text": "these faulty",
    "start": "699200",
    "end": "700959"
  },
  {
    "text": "components however to operate this at",
    "start": "700959",
    "end": "703240"
  },
  {
    "text": "scale it is imperative that we have to",
    "start": "703240",
    "end": "705600"
  },
  {
    "text": "automate this fault handling life",
    "start": "705600",
    "end": "708600"
  },
  {
    "text": "cycle the first step is to build",
    "start": "708600",
    "end": "712160"
  },
  {
    "text": "observability into the GPU",
    "start": "712160",
    "end": "714279"
  },
  {
    "text": "infrastructure with inband and outof",
    "start": "714279",
    "end": "716480"
  },
  {
    "text": "band GPU monitoring invidious in from",
    "start": "716480",
    "end": "719279"
  },
  {
    "text": "monitoring components like dcgm and",
    "start": "719279",
    "end": "721160"
  },
  {
    "text": "infin band Diagnostics combined with",
    "start": "721160",
    "end": "723800"
  },
  {
    "text": "kubernetes no problem detector and other",
    "start": "723800",
    "end": "725920"
  },
  {
    "text": "Linux utilities can help to surface",
    "start": "725920",
    "end": "728920"
  },
  {
    "text": "these system falls to the control",
    "start": "728920",
    "end": "731120"
  },
  {
    "text": "plane typically as note",
    "start": "731120",
    "end": "734600"
  },
  {
    "text": "conditions now based on these detected",
    "start": "734600",
    "end": "737199"
  },
  {
    "text": "node conditions a scheduling control",
    "start": "737199",
    "end": "739760"
  },
  {
    "text": "flow with fault handling capability and",
    "start": "739760",
    "end": "742519"
  },
  {
    "text": "combined with application Level",
    "start": "742519",
    "end": "744160"
  },
  {
    "text": "checkpointing can ensure that the",
    "start": "744160",
    "end": "746240"
  },
  {
    "text": "training jobs run to completion for",
    "start": "746240",
    "end": "748920"
  },
  {
    "text": "example example if pods are augmented",
    "start": "748920",
    "end": "751600"
  },
  {
    "text": "with an init container that runs",
    "start": "751600",
    "end": "753839"
  },
  {
    "text": "pre-flight it host and network level",
    "start": "753839",
    "end": "756480"
  },
  {
    "text": "test then faulty noes can be detected",
    "start": "756480",
    "end": "759120"
  },
  {
    "text": "even before the application starts",
    "start": "759120",
    "end": "762680"
  },
  {
    "text": "running and if also are detected after",
    "start": "762680",
    "end": "765160"
  },
  {
    "text": "the in phas then the application may",
    "start": "765160",
    "end": "767240"
  },
  {
    "text": "need to be checkpointed and the pods",
    "start": "767240",
    "end": "769199"
  },
  {
    "text": "rescheduled to healthy set of nodes and",
    "start": "769199",
    "end": "772760"
  },
  {
    "text": "automated fall tolerant",
    "start": "772760",
    "end": "775079"
  },
  {
    "text": "scheduling which is both proactive and",
    "start": "775079",
    "end": "777639"
  },
  {
    "text": "reactive is an essential requirement",
    "start": "777639",
    "end": "779839"
  },
  {
    "text": "with scaling out on GPU",
    "start": "779839",
    "end": "781880"
  },
  {
    "text": "clusters and finally putting it all",
    "start": "781880",
    "end": "784160"
  },
  {
    "text": "together I want to highlight the",
    "start": "784160",
    "end": "785720"
  },
  {
    "text": "multi-dimensional optimization",
    "start": "785720",
    "end": "788839"
  },
  {
    "text": "problem imagine we have a 40 node",
    "start": "788839",
    "end": "791760"
  },
  {
    "text": "cluster with two switching",
    "start": "791760",
    "end": "793839"
  },
  {
    "text": "units now there are 16 nodes that are",
    "start": "793839",
    "end": "797720"
  },
  {
    "text": "currently occupied running a job from",
    "start": "797720",
    "end": "799639"
  },
  {
    "text": "user",
    "start": "799639",
    "end": "800680"
  },
  {
    "text": "one and 24 nodes just became",
    "start": "800680",
    "end": "804639"
  },
  {
    "text": "available and there are four multi-node",
    "start": "804639",
    "end": "807160"
  },
  {
    "text": "jobs of various sizes and requirements",
    "start": "807160",
    "end": "808920"
  },
  {
    "text": "that are waiting to be scheduled three",
    "start": "808920",
    "end": "810560"
  },
  {
    "text": "of them from user one one from user two",
    "start": "810560",
    "end": "814839"
  },
  {
    "text": "now",
    "start": "814839",
    "end": "816160"
  },
  {
    "text": "interestingly depending on the kpi to",
    "start": "816160",
    "end": "818800"
  },
  {
    "text": "optimize the scheduler can end up",
    "start": "818800",
    "end": "820959"
  },
  {
    "text": "choosing a different job to optimize for",
    "start": "820959",
    "end": "823959"
  },
  {
    "text": "starvation and topology it'll choose J1",
    "start": "823959",
    "end": "827079"
  },
  {
    "text": "for occupancy it'll choose J uh j3 for",
    "start": "827079",
    "end": "831000"
  },
  {
    "text": "priority it'll choose J2 and for",
    "start": "831000",
    "end": "834120"
  },
  {
    "text": "fairness it'll choose",
    "start": "834120",
    "end": "836320"
  },
  {
    "text": "j4 so which one should the scheduler",
    "start": "836320",
    "end": "838759"
  },
  {
    "text": "choose",
    "start": "838759",
    "end": "840600"
  },
  {
    "text": "for most users the most important kpi is",
    "start": "840600",
    "end": "844000"
  },
  {
    "text": "priority and starvation of their",
    "start": "844000",
    "end": "846120"
  },
  {
    "text": "jobs and for the business objectives it",
    "start": "846120",
    "end": "849399"
  },
  {
    "text": "is occupancy of the cluster and cluster",
    "start": "849399",
    "end": "852279"
  },
  {
    "text": "admins always try to allocate resources",
    "start": "852279",
    "end": "854759"
  },
  {
    "text": "fairly amongst",
    "start": "854759",
    "end": "856040"
  },
  {
    "text": "users this is a classic",
    "start": "856040",
    "end": "858079"
  },
  {
    "text": "multi-dimensional optimization",
    "start": "858079",
    "end": "860240"
  },
  {
    "text": "problem so we need to think about a",
    "start": "860240",
    "end": "863320"
  },
  {
    "text": "configurable",
    "start": "863320",
    "end": "865000"
  },
  {
    "text": "multi-objective optimization framework",
    "start": "865000",
    "end": "867079"
  },
  {
    "text": "that will make deterministic decisions",
    "start": "867079",
    "end": "868839"
  },
  {
    "text": "by considering all the global",
    "start": "868839",
    "end": "870839"
  },
  {
    "text": "constraints in a GPU cluster and not",
    "start": "870839",
    "end": "873399"
  },
  {
    "text": "just when scheduling but also when uh",
    "start": "873399",
    "end": "876279"
  },
  {
    "text": "finding the optimal victim set for",
    "start": "876279",
    "end": "878079"
  },
  {
    "text": "preemption or the optimal node group",
    "start": "878079",
    "end": "880880"
  },
  {
    "text": "when doing node",
    "start": "880880",
    "end": "883399"
  },
  {
    "text": "reservations today I want to conclude",
    "start": "883399",
    "end": "885519"
  },
  {
    "text": "with a call to action this is a great",
    "start": "885519",
    "end": "888399"
  },
  {
    "text": "time to solve challenging problems with",
    "start": "888399",
    "end": "890720"
  },
  {
    "text": "Gen and gpus in kubernetes Nvidia just",
    "start": "890720",
    "end": "894079"
  },
  {
    "text": "announced Nvidia",
    "start": "894079",
    "end": "896000"
  },
  {
    "text": "Blackwell amongst many other features",
    "start": "896000",
    "end": "898120"
  },
  {
    "text": "there's inbuilt hard Hardware support",
    "start": "898120",
    "end": "899560"
  },
  {
    "text": "for",
    "start": "899560",
    "end": "900480"
  },
  {
    "text": "resiliency we want kubernetes to take",
    "start": "900480",
    "end": "902920"
  },
  {
    "text": "advantage of that Kevin has been",
    "start": "902920",
    "end": "905199"
  },
  {
    "text": "engaging with the community on the",
    "start": "905199",
    "end": "907079"
  },
  {
    "text": "low-level mechanisms to enable GPU",
    "start": "907079",
    "end": "909199"
  },
  {
    "text": "resource management and we will keep",
    "start": "909199",
    "end": "911560"
  },
  {
    "text": "engaging to solve the GP scale",
    "start": "911560",
    "end": "913000"
  },
  {
    "text": "challenges as well for many this is the",
    "start": "913000",
    "end": "916600"
  },
  {
    "text": "Linux moment for cubanes let's make it",
    "start": "916600",
    "end": "919199"
  },
  {
    "text": "happen thank you",
    "start": "919199",
    "end": "922079"
  },
  {
    "text": "[Music]",
    "start": "924920",
    "end": "926680"
  },
  {
    "text": "all",
    "start": "926680",
    "end": "929680"
  }
]
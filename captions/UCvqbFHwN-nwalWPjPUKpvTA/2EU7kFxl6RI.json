[
  {
    "start": "0",
    "end": "71000"
  },
  {
    "text": "hi my name is axel",
    "start": "960",
    "end": "3600"
  },
  {
    "text": "and my name is mike and we are here",
    "start": "3600",
    "end": "7120"
  },
  {
    "text": "to tell you how to successfully fail at",
    "start": "7120",
    "end": "10320"
  },
  {
    "text": "life the",
    "start": "10320",
    "end": "13920"
  },
  {
    "text": "baseless claim that a company",
    "start": "13920",
    "end": "17119"
  },
  {
    "text": "celebrates failure is becoming as common",
    "start": "17119",
    "end": "20480"
  },
  {
    "text": "for trope in modern tech",
    "start": "20480",
    "end": "22240"
  },
  {
    "text": "as have you tried turning it off and on",
    "start": "22240",
    "end": "25119"
  },
  {
    "text": "again",
    "start": "25119",
    "end": "26560"
  },
  {
    "text": "it turns out that repeated failure",
    "start": "26560",
    "end": "31199"
  },
  {
    "text": "is not enough to ensure future success",
    "start": "31199",
    "end": "35120"
  },
  {
    "text": "and in practice celebrating failure",
    "start": "35120",
    "end": "39360"
  },
  {
    "text": "often amounts to not firing people who",
    "start": "39360",
    "end": "42879"
  },
  {
    "text": "are bad at their job",
    "start": "42879",
    "end": "45120"
  },
  {
    "text": "as such thinking about how to fail",
    "start": "45120",
    "end": "48480"
  },
  {
    "text": "forward that is fail in a way",
    "start": "48480",
    "end": "52079"
  },
  {
    "text": "that moves you meaningfully towards your",
    "start": "52079",
    "end": "55360"
  },
  {
    "text": "goal",
    "start": "55360",
    "end": "56399"
  },
  {
    "text": "is relevant this talk",
    "start": "56399",
    "end": "59760"
  },
  {
    "text": "is about how we failed five consecutive",
    "start": "59760",
    "end": "63280"
  },
  {
    "text": "deploys",
    "start": "63280",
    "end": "64158"
  },
  {
    "text": "at spotify and why we're",
    "start": "64159",
    "end": "68159"
  },
  {
    "text": "reasonably proud about it",
    "start": "68159",
    "end": "72080"
  },
  {
    "start": "71000",
    "end": "101000"
  },
  {
    "text": "first a little background at spotify",
    "start": "72080",
    "end": "75600"
  },
  {
    "text": "we have a google load balancer in front",
    "start": "75600",
    "end": "78000"
  },
  {
    "text": "of our microservices",
    "start": "78000",
    "end": "80000"
  },
  {
    "text": "and for a long time we've been wanting",
    "start": "80000",
    "end": "82080"
  },
  {
    "text": "to run envoy as an http proxy at the",
    "start": "82080",
    "end": "84479"
  },
  {
    "text": "perimeter of our back ends",
    "start": "84479",
    "end": "86640"
  },
  {
    "text": "in addition to having a unified",
    "start": "86640",
    "end": "88479"
  },
  {
    "text": "perimeter there is a long laundry list",
    "start": "88479",
    "end": "90640"
  },
  {
    "text": "of futures we want to get out of this",
    "start": "90640",
    "end": "92479"
  },
  {
    "text": "setup",
    "start": "92479",
    "end": "93520"
  },
  {
    "text": "common metrics authentication rate",
    "start": "93520",
    "end": "95920"
  },
  {
    "text": "limiting",
    "start": "95920",
    "end": "96720"
  },
  {
    "text": "client ip lookups access logs",
    "start": "96720",
    "end": "99759"
  },
  {
    "text": "and so on and as you might know",
    "start": "99759",
    "end": "103920"
  },
  {
    "start": "101000",
    "end": "142000"
  },
  {
    "text": "envoy doesn't actually do all of those",
    "start": "103920",
    "end": "105520"
  },
  {
    "text": "things our desired android setup",
    "start": "105520",
    "end": "108159"
  },
  {
    "text": "contains a docker",
    "start": "108159",
    "end": "109360"
  },
  {
    "text": "sidecar that runs a second service",
    "start": "109360",
    "end": "111920"
  },
  {
    "text": "implementing",
    "start": "111920",
    "end": "112720"
  },
  {
    "text": "authentication guip lookups and smarter",
    "start": "112720",
    "end": "115520"
  },
  {
    "text": "things",
    "start": "115520",
    "end": "116880"
  },
  {
    "text": "envoy will call this service for most",
    "start": "116880",
    "end": "119040"
  },
  {
    "text": "incoming requests",
    "start": "119040",
    "end": "120719"
  },
  {
    "text": "using the rtc extension",
    "start": "120719",
    "end": "124560"
  },
  {
    "text": "we started this journey over a year ago",
    "start": "125280",
    "end": "128479"
  },
  {
    "text": "by adding our first services behind",
    "start": "128479",
    "end": "130399"
  },
  {
    "text": "envoy we have then",
    "start": "130399",
    "end": "132239"
  },
  {
    "text": "gradually added more and more traffic",
    "start": "132239",
    "end": "134800"
  },
  {
    "text": "and now",
    "start": "134800",
    "end": "135599"
  },
  {
    "text": "it's time for the biggest deployment the",
    "start": "135599",
    "end": "138160"
  },
  {
    "text": "http traffic from the actual spotify",
    "start": "138160",
    "end": "140879"
  },
  {
    "text": "clients",
    "start": "140879",
    "end": "143440"
  },
  {
    "start": "142000",
    "end": "215000"
  },
  {
    "text": "but before such an important move",
    "start": "143440",
    "end": "146959"
  },
  {
    "text": "we wanted to do a fair bit of testing",
    "start": "146959",
    "end": "150239"
  },
  {
    "text": "to build confidence that this would",
    "start": "150239",
    "end": "153680"
  },
  {
    "text": "actually work we created a test setup",
    "start": "153680",
    "end": "158080"
  },
  {
    "text": "that resembled the production setup as",
    "start": "158080",
    "end": "160720"
  },
  {
    "text": "much",
    "start": "160720",
    "end": "161440"
  },
  {
    "text": "as possible instead of a real client",
    "start": "161440",
    "end": "164879"
  },
  {
    "text": "we use the wrk2 tool which does",
    "start": "164879",
    "end": "168319"
  },
  {
    "text": "open loop testing that is it allows us",
    "start": "168319",
    "end": "171440"
  },
  {
    "text": "to",
    "start": "171440",
    "end": "171760"
  },
  {
    "text": "set the desired request rate instead of",
    "start": "171760",
    "end": "174959"
  },
  {
    "text": "just trying to fully saturate the system",
    "start": "174959",
    "end": "177519"
  },
  {
    "text": "this is almost always the correct way to",
    "start": "177519",
    "end": "181120"
  },
  {
    "text": "load test the system",
    "start": "181120",
    "end": "183519"
  },
  {
    "text": "our test setup uses the same load",
    "start": "183519",
    "end": "186319"
  },
  {
    "text": "balancer",
    "start": "186319",
    "end": "187120"
  },
  {
    "text": "as production an identically configured",
    "start": "187120",
    "end": "190159"
  },
  {
    "text": "cluster",
    "start": "190159",
    "end": "190959"
  },
  {
    "text": "but with only one host and various",
    "start": "190959",
    "end": "194560"
  },
  {
    "text": "different core counts on that host",
    "start": "194560",
    "end": "197760"
  },
  {
    "text": "finally our test used a single upstream",
    "start": "197760",
    "end": "201360"
  },
  {
    "text": "service",
    "start": "201360",
    "end": "202080"
  },
  {
    "text": "named no op no up is a service",
    "start": "202080",
    "end": "205599"
  },
  {
    "text": "whose reply time status code and payload",
    "start": "205599",
    "end": "208959"
  },
  {
    "text": "size",
    "start": "208959",
    "end": "209760"
  },
  {
    "text": "can all be configured on each incoming",
    "start": "209760",
    "end": "212959"
  },
  {
    "text": "request",
    "start": "212959",
    "end": "215360"
  },
  {
    "start": "215000",
    "end": "268000"
  },
  {
    "text": "so what did we find",
    "start": "215360",
    "end": "218879"
  },
  {
    "text": "first of all regardless of number of",
    "start": "218879",
    "end": "221519"
  },
  {
    "text": "cores",
    "start": "221519",
    "end": "222000"
  },
  {
    "text": "on the host metrics propagation always",
    "start": "222000",
    "end": "225120"
  },
  {
    "text": "uses one",
    "start": "225120",
    "end": "226000"
  },
  {
    "text": "full core secondly a few configuration",
    "start": "226000",
    "end": "230239"
  },
  {
    "text": "bottlenecks were found",
    "start": "230239",
    "end": "231840"
  },
  {
    "text": "the biggest one was the http thread pool",
    "start": "231840",
    "end": "234560"
  },
  {
    "text": "in our off-c",
    "start": "234560",
    "end": "235680"
  },
  {
    "text": "sidecar we tried eight",
    "start": "235680",
    "end": "239519"
  },
  {
    "text": "32 and 64 core hosts and 32 cores",
    "start": "239519",
    "end": "244080"
  },
  {
    "text": "offered the best throughput per core",
    "start": "244080",
    "end": "247599"
  },
  {
    "text": "we saw some failure rate elevation on",
    "start": "247599",
    "end": "250239"
  },
  {
    "text": "slow requests",
    "start": "250239",
    "end": "251599"
  },
  {
    "text": "but we didn't investigate this further",
    "start": "251599",
    "end": "255840"
  },
  {
    "text": "and finally we could see that tls",
    "start": "255840",
    "end": "259199"
  },
  {
    "text": "used a bit more cpu than we expected",
    "start": "259199",
    "end": "262560"
  },
  {
    "text": "in the flame graphs good enough",
    "start": "262560",
    "end": "266080"
  },
  {
    "text": "let's go and we did and thanks to that",
    "start": "266080",
    "end": "270080"
  },
  {
    "start": "268000",
    "end": "278000"
  },
  {
    "text": "we have this amazing news article",
    "start": "270080",
    "end": "273120"
  },
  {
    "text": "and needless to say we had to roll back",
    "start": "273120",
    "end": "276479"
  },
  {
    "text": "fairly quickly",
    "start": "276479",
    "end": "279280"
  },
  {
    "start": "278000",
    "end": "337000"
  },
  {
    "text": "what was going on well it turns out",
    "start": "279919",
    "end": "283440"
  },
  {
    "text": "that envoy's circuit breaker which",
    "start": "283440",
    "end": "286479"
  },
  {
    "text": "is really just an outstanding request",
    "start": "286479",
    "end": "288960"
  },
  {
    "text": "limit",
    "start": "288960",
    "end": "289680"
  },
  {
    "text": "had triggered it has a default limit of",
    "start": "289680",
    "end": "293040"
  },
  {
    "text": "1000 requests",
    "start": "293040",
    "end": "294800"
  },
  {
    "text": "which we had not changed",
    "start": "294800",
    "end": "298400"
  },
  {
    "text": "handling 30 to 30 000 rps",
    "start": "298400",
    "end": "301919"
  },
  {
    "text": "per host means that average latency on",
    "start": "301919",
    "end": "304639"
  },
  {
    "text": "your request",
    "start": "304639",
    "end": "305600"
  },
  {
    "text": "must be lower than 30 milliseconds",
    "start": "305600",
    "end": "309199"
  },
  {
    "text": "we had in fact checked that the median",
    "start": "309199",
    "end": "311919"
  },
  {
    "text": "latency",
    "start": "311919",
    "end": "313039"
  },
  {
    "text": "was much lower than that but as usual",
    "start": "313039",
    "end": "317280"
  },
  {
    "text": "the long tail ruins everything",
    "start": "317280",
    "end": "321759"
  },
  {
    "text": "so we had failed to check the right",
    "start": "321759",
    "end": "325120"
  },
  {
    "text": "metric for this situation which is",
    "start": "325120",
    "end": "328400"
  },
  {
    "text": "the average because",
    "start": "328400",
    "end": "332880"
  },
  {
    "text": "onward doesn't report the average",
    "start": "332880",
    "end": "338639"
  },
  {
    "text": "but the good news is we could",
    "start": "338639",
    "end": "340720"
  },
  {
    "text": "successfully reproduce the problem in",
    "start": "340720",
    "end": "342960"
  },
  {
    "text": "our test environment",
    "start": "342960",
    "end": "344720"
  },
  {
    "text": "and we could validate that it went away",
    "start": "344720",
    "end": "347680"
  },
  {
    "text": "when we adjusted the limit",
    "start": "347680",
    "end": "350479"
  },
  {
    "text": "so we adjusted the production circuit",
    "start": "350479",
    "end": "353199"
  },
  {
    "text": "breaker settings",
    "start": "353199",
    "end": "354400"
  },
  {
    "text": "and we tried again and this time it",
    "start": "354400",
    "end": "357360"
  },
  {
    "text": "worked",
    "start": "357360",
    "end": "359120"
  },
  {
    "text": "for a few minutes",
    "start": "359120",
    "end": "361840"
  },
  {
    "start": "362000",
    "end": "390000"
  },
  {
    "text": "it started out fine but as time went on",
    "start": "362560",
    "end": "365919"
  },
  {
    "text": "we got more and more errors",
    "start": "365919",
    "end": "368240"
  },
  {
    "text": "we noted this amazing graph showing the",
    "start": "368240",
    "end": "371120"
  },
  {
    "text": "number of requests for each host",
    "start": "371120",
    "end": "373840"
  },
  {
    "text": "basically the load balancer seems to",
    "start": "373840",
    "end": "376400"
  },
  {
    "text": "throw all it can at a random host",
    "start": "376400",
    "end": "378720"
  },
  {
    "text": "until it gets overloaded then it throw",
    "start": "378720",
    "end": "382000"
  },
  {
    "text": "the load away at the other hosts instead",
    "start": "382000",
    "end": "384800"
  },
  {
    "text": "spiraling into more and more 500 hours",
    "start": "384800",
    "end": "388000"
  },
  {
    "text": "from overloaded hosts",
    "start": "388000",
    "end": "391199"
  },
  {
    "text": "we adjusted our environment to be",
    "start": "391440",
    "end": "393440"
  },
  {
    "text": "protected production",
    "start": "393440",
    "end": "395039"
  },
  {
    "text": "by increasing its size from one to ten",
    "start": "395039",
    "end": "398080"
  },
  {
    "text": "we could then see the same problem in",
    "start": "398080",
    "end": "400240"
  },
  {
    "text": "our test environment",
    "start": "400240",
    "end": "401759"
  },
  {
    "text": "and after some testing we figured that",
    "start": "401759",
    "end": "404560"
  },
  {
    "text": "if we tell the load balancer to target",
    "start": "404560",
    "end": "406720"
  },
  {
    "text": "15 000 requests per second for each host",
    "start": "406720",
    "end": "409599"
  },
  {
    "text": "everything looks fine",
    "start": "409599",
    "end": "412560"
  },
  {
    "text": "we had assumed that a single node test",
    "start": "412880",
    "end": "415440"
  },
  {
    "text": "cluster would be fine",
    "start": "415440",
    "end": "417440"
  },
  {
    "text": "looking back it feels pretty naive to",
    "start": "417440",
    "end": "420080"
  },
  {
    "text": "use a single node",
    "start": "420080",
    "end": "422000"
  },
  {
    "text": "but it's always easier when you have all",
    "start": "422000",
    "end": "424560"
  },
  {
    "text": "the answers",
    "start": "424560",
    "end": "425840"
  },
  {
    "text": "we didn't know that the load balancer",
    "start": "425840",
    "end": "427599"
  },
  {
    "text": "considered a single node cluster special",
    "start": "427599",
    "end": "430400"
  },
  {
    "text": "so we did fail to make most to make our",
    "start": "430400",
    "end": "433039"
  },
  {
    "text": "test setup",
    "start": "433039",
    "end": "433840"
  },
  {
    "text": "similar enough to production to save",
    "start": "433840",
    "end": "436800"
  },
  {
    "text": "some money",
    "start": "436800",
    "end": "439360"
  },
  {
    "text": "and slot link to 15 000 requests stop",
    "start": "439599",
    "end": "442720"
  },
  {
    "text": "the flapping",
    "start": "442720",
    "end": "444160"
  },
  {
    "text": "but we have poor research usage and",
    "start": "444160",
    "end": "447360"
  },
  {
    "text": "an elevated failure rate clearly",
    "start": "447360",
    "end": "450319"
  },
  {
    "text": "something still wasn't right",
    "start": "450319",
    "end": "453840"
  },
  {
    "text": "but we didn't know where so",
    "start": "454080",
    "end": "458080"
  },
  {
    "text": "we tried to isolate the different parts",
    "start": "458080",
    "end": "460240"
  },
  {
    "text": "of the system",
    "start": "460240",
    "end": "461199"
  },
  {
    "text": "to locate the bottleneck we started with",
    "start": "461199",
    "end": "464800"
  },
  {
    "text": "the previously mentioned off z",
    "start": "464800",
    "end": "466960"
  },
  {
    "text": "sidecar we disable it and",
    "start": "466960",
    "end": "470319"
  },
  {
    "text": "rps went from fifteen thousand to twenty",
    "start": "470319",
    "end": "472639"
  },
  {
    "text": "thousand",
    "start": "472639",
    "end": "474000"
  },
  {
    "text": "this is expected since the number of",
    "start": "474000",
    "end": "476160"
  },
  {
    "text": "messages that are processed by the host",
    "start": "476160",
    "end": "478479"
  },
  {
    "text": "goes down significantly and",
    "start": "478479",
    "end": "481599"
  },
  {
    "text": "also cpu usage during these load tests",
    "start": "481599",
    "end": "484479"
  },
  {
    "text": "still stayed",
    "start": "484479",
    "end": "485360"
  },
  {
    "text": "well below 50 percent so",
    "start": "485360",
    "end": "489199"
  },
  {
    "text": "that was not the limiting factor",
    "start": "489199",
    "end": "492960"
  },
  {
    "text": "next we turned our eyes to the no op",
    "start": "492960",
    "end": "496000"
  },
  {
    "text": "service",
    "start": "496000",
    "end": "497120"
  },
  {
    "text": "this fake service runs in kubernetes",
    "start": "497120",
    "end": "500960"
  },
  {
    "text": "we did some quick profiling and found",
    "start": "500960",
    "end": "503199"
  },
  {
    "text": "that each replica",
    "start": "503199",
    "end": "504879"
  },
  {
    "text": "can handle 23 000 rps",
    "start": "504879",
    "end": "508639"
  },
  {
    "text": "it is auto scaled with a maximum of 100",
    "start": "508639",
    "end": "511599"
  },
  {
    "text": "replicas",
    "start": "511599",
    "end": "512640"
  },
  {
    "text": "that means it can handle roughly 2.3",
    "start": "512640",
    "end": "515279"
  },
  {
    "text": "million",
    "start": "515279",
    "end": "515839"
  },
  {
    "text": "rps once again not the limiting factor",
    "start": "515839",
    "end": "521839"
  },
  {
    "start": "521000",
    "end": "556000"
  },
  {
    "text": "most envoy users use the http 2 stack",
    "start": "521839",
    "end": "525440"
  },
  {
    "text": "but envoy and our upstream uses",
    "start": "525440",
    "end": "529519"
  },
  {
    "text": "http 1.1 perhaps the http 1.1 stack",
    "start": "529519",
    "end": "534080"
  },
  {
    "text": "is somehow less scalable we ran a test",
    "start": "534080",
    "end": "538000"
  },
  {
    "text": "where envoy directly responds to all",
    "start": "538000",
    "end": "540320"
  },
  {
    "text": "requests",
    "start": "540320",
    "end": "542240"
  },
  {
    "text": "thereby bypassing any http 1.1 stack",
    "start": "542240",
    "end": "546080"
  },
  {
    "text": "and we found that we could handle only",
    "start": "546080",
    "end": "548160"
  },
  {
    "text": "30 000 rps",
    "start": "548160",
    "end": "549920"
  },
  {
    "text": "with a 10 cpu usage",
    "start": "549920",
    "end": "553920"
  },
  {
    "text": "why",
    "start": "554320",
    "end": "556720"
  },
  {
    "start": "556000",
    "end": "577000"
  },
  {
    "text": "this is the low point it is the part of",
    "start": "557600",
    "end": "560480"
  },
  {
    "text": "the hero's journey",
    "start": "560480",
    "end": "562000"
  },
  {
    "text": "known as the abyss it is",
    "start": "562000",
    "end": "565519"
  },
  {
    "text": "where we considered giving up on",
    "start": "565519",
    "end": "567120"
  },
  {
    "text": "software development and finding a brand",
    "start": "567120",
    "end": "569680"
  },
  {
    "text": "new career",
    "start": "569680",
    "end": "571040"
  },
  {
    "text": "one that makes sense like",
    "start": "571040",
    "end": "574839"
  },
  {
    "text": "carpentry",
    "start": "574839",
    "end": "577839"
  },
  {
    "start": "577000",
    "end": "706000"
  },
  {
    "text": "but instead we started looking at the",
    "start": "578240",
    "end": "581360"
  },
  {
    "text": "number of connections",
    "start": "581360",
    "end": "582560"
  },
  {
    "text": "between our load balancer and nyhosts",
    "start": "582560",
    "end": "585839"
  },
  {
    "text": "and found that we have about 13 thousand",
    "start": "585839",
    "end": "588000"
  },
  {
    "text": "connection to east host",
    "start": "588000",
    "end": "590320"
  },
  {
    "text": "that's a pretty high number and someone",
    "start": "590320",
    "end": "593519"
  },
  {
    "text": "pointed out",
    "start": "593519",
    "end": "594399"
  },
  {
    "text": "that the buffer size is one megabyte",
    "start": "594399",
    "end": "598080"
  },
  {
    "text": "and with some math you get a total",
    "start": "598080",
    "end": "600399"
  },
  {
    "text": "buffer size of",
    "start": "600399",
    "end": "601760"
  },
  {
    "text": "13 gigabytes that's quite a lot of",
    "start": "601760",
    "end": "604320"
  },
  {
    "text": "buffering for ny to do",
    "start": "604320",
    "end": "607040"
  },
  {
    "text": "so we tried to decrease it to 32",
    "start": "607040",
    "end": "609440"
  },
  {
    "text": "kilobytes for each connection",
    "start": "609440",
    "end": "612079"
  },
  {
    "text": "and our request per second increased",
    "start": "612079",
    "end": "615120"
  },
  {
    "text": "from 30 to 60 000",
    "start": "615120",
    "end": "616800"
  },
  {
    "text": "on direct responses we did try",
    "start": "616800",
    "end": "620640"
  },
  {
    "text": "to tweak similar settings like the",
    "start": "620640",
    "end": "622399"
  },
  {
    "text": "number of concurrent streams",
    "start": "622399",
    "end": "624000"
  },
  {
    "text": "and window sizes but we didn't find",
    "start": "624000",
    "end": "627279"
  },
  {
    "text": "anything",
    "start": "627279",
    "end": "627920"
  },
  {
    "text": "we thought were worth changing",
    "start": "627920",
    "end": "632720"
  },
  {
    "text": "as soon as we hit 15 000 requests per",
    "start": "632720",
    "end": "635120"
  },
  {
    "text": "second",
    "start": "635120",
    "end": "636079"
  },
  {
    "text": "latency started to increase",
    "start": "636079",
    "end": "639920"
  },
  {
    "text": "this did not happen if we removed the",
    "start": "640000",
    "end": "642079"
  },
  {
    "text": "rtc decorator",
    "start": "642079",
    "end": "643440"
  },
  {
    "text": "from the from the request path",
    "start": "643440",
    "end": "646880"
  },
  {
    "text": "to check if it was the service that was",
    "start": "646880",
    "end": "648800"
  },
  {
    "text": "slow replaced it",
    "start": "648800",
    "end": "650560"
  },
  {
    "text": "with a service that immediately returned",
    "start": "650560",
    "end": "652640"
  },
  {
    "text": "to 100 okay",
    "start": "652640",
    "end": "655040"
  },
  {
    "text": "performance was still bad and we only",
    "start": "655040",
    "end": "657760"
  },
  {
    "text": "got 15 000 requests per second",
    "start": "657760",
    "end": "661839"
  },
  {
    "text": "clearly we have isolated an issue in the",
    "start": "662720",
    "end": "665760"
  },
  {
    "text": "communication between",
    "start": "665760",
    "end": "666880"
  },
  {
    "text": "envoy and the otc sidecar",
    "start": "666880",
    "end": "670240"
  },
  {
    "text": "this was narrow enough",
    "start": "670240",
    "end": "673600"
  },
  {
    "text": "for a teammate to realize",
    "start": "673600",
    "end": "676880"
  },
  {
    "text": "that we have previously touched the",
    "start": "676880",
    "end": "678320"
  },
  {
    "text": "network configuration on this cluster",
    "start": "678320",
    "end": "680560"
  },
  {
    "text": "and sure enough we were using docker",
    "start": "680560",
    "end": "683760"
  },
  {
    "text": "network bridge",
    "start": "683760",
    "end": "684640"
  },
  {
    "text": "instead of the much faster loopback",
    "start": "684640",
    "end": "686839"
  },
  {
    "text": "device",
    "start": "686839",
    "end": "688399"
  },
  {
    "text": "throughput increased to 30 000 requests",
    "start": "688399",
    "end": "691120"
  },
  {
    "text": "per second",
    "start": "691120",
    "end": "692480"
  },
  {
    "text": "but why didn't we see this earlier",
    "start": "692480",
    "end": "696160"
  },
  {
    "text": "it does only increase latency so badly",
    "start": "696160",
    "end": "699680"
  },
  {
    "text": "that the load balancer started",
    "start": "699680",
    "end": "701200"
  },
  {
    "text": "considering the hose dead",
    "start": "701200",
    "end": "702720"
  },
  {
    "text": "it didn't actually limit the throughput",
    "start": "702720",
    "end": "706879"
  },
  {
    "text": "finally we have reached the end of our",
    "start": "707440",
    "end": "710399"
  },
  {
    "text": "journey",
    "start": "710399",
    "end": "711440"
  },
  {
    "text": "everything worked we hid in production",
    "start": "711440",
    "end": "715200"
  },
  {
    "text": "and everything is fine",
    "start": "715200",
    "end": "718240"
  },
  {
    "text": "for a few minutes then once again the",
    "start": "718240",
    "end": "722160"
  },
  {
    "text": "error rate started to creep up",
    "start": "722160",
    "end": "724560"
  },
  {
    "text": "and rps went down to the same old 15 000",
    "start": "724560",
    "end": "728839"
  },
  {
    "text": "rps",
    "start": "728839",
    "end": "730880"
  },
  {
    "start": "729000",
    "end": "766000"
  },
  {
    "text": "we decided at this point to drill down",
    "start": "730880",
    "end": "733279"
  },
  {
    "text": "to the various thread pools on the",
    "start": "733279",
    "end": "734880"
  },
  {
    "text": "system",
    "start": "734880",
    "end": "735600"
  },
  {
    "text": "to see if any of them were overloaded",
    "start": "735600",
    "end": "738639"
  },
  {
    "text": "what we found instead was that the main",
    "start": "738639",
    "end": "741440"
  },
  {
    "text": "envoy worker pool",
    "start": "741440",
    "end": "742880"
  },
  {
    "text": "was extremely unevenly loaded some",
    "start": "742880",
    "end": "745760"
  },
  {
    "text": "threads were pegged at 100 percent",
    "start": "745760",
    "end": "748720"
  },
  {
    "text": "others were doing nothing we assumed",
    "start": "748720",
    "end": "752079"
  },
  {
    "text": "that this was a locking problem and we",
    "start": "752079",
    "end": "754079"
  },
  {
    "text": "started to work on profiling envoy",
    "start": "754079",
    "end": "757279"
  },
  {
    "text": "that is until someone noticed that the",
    "start": "757279",
    "end": "760320"
  },
  {
    "text": "number of open connections to each",
    "start": "760320",
    "end": "762560"
  },
  {
    "text": "worker thread",
    "start": "762560",
    "end": "763519"
  },
  {
    "text": "was actually similarly lopsided",
    "start": "763519",
    "end": "767600"
  },
  {
    "start": "766000",
    "end": "818000"
  },
  {
    "text": "so why were some worker threads",
    "start": "767600",
    "end": "771120"
  },
  {
    "text": "receiving",
    "start": "771120",
    "end": "771680"
  },
  {
    "text": "all of the traffic and others none we",
    "start": "771680",
    "end": "774560"
  },
  {
    "text": "could not reproduce this problem in our",
    "start": "774560",
    "end": "776320"
  },
  {
    "text": "test environment",
    "start": "776320",
    "end": "777600"
  },
  {
    "text": "which meant that we were flying blind we",
    "start": "777600",
    "end": "780399"
  },
  {
    "text": "decided",
    "start": "780399",
    "end": "781200"
  },
  {
    "text": "to reach out to the envoy community as",
    "start": "781200",
    "end": "783839"
  },
  {
    "text": "well",
    "start": "783839",
    "end": "784399"
  },
  {
    "text": "as our cloud provider google we got a",
    "start": "784399",
    "end": "788000"
  },
  {
    "text": "suggestion",
    "start": "788000",
    "end": "788959"
  },
  {
    "text": "from both in the form of harvey touch",
    "start": "788959",
    "end": "792639"
  },
  {
    "text": "so reuse port this configuration option",
    "start": "792639",
    "end": "796160"
  },
  {
    "text": "in envoy is",
    "start": "796160",
    "end": "797120"
  },
  {
    "text": "described as such this makes",
    "start": "797120",
    "end": "800240"
  },
  {
    "text": "inbound connections distribute among",
    "start": "800240",
    "end": "802800"
  },
  {
    "text": "worker threads",
    "start": "802800",
    "end": "803839"
  },
  {
    "text": "roughly evenly in cases where there",
    "start": "803839",
    "end": "807040"
  },
  {
    "text": "are a high number of connections",
    "start": "807040",
    "end": "810079"
  },
  {
    "text": "which begs the question when would you",
    "start": "810079",
    "end": "813519"
  },
  {
    "text": "not want connections evenly distributed",
    "start": "813519",
    "end": "816320"
  },
  {
    "text": "among workers",
    "start": "816320",
    "end": "819120"
  },
  {
    "start": "818000",
    "end": "855000"
  },
  {
    "text": "anyway it worked",
    "start": "819440",
    "end": "824079"
  },
  {
    "text": "but why couldn't we reproduce this",
    "start": "824320",
    "end": "827600"
  },
  {
    "text": "problem in testing",
    "start": "827600",
    "end": "830399"
  },
  {
    "text": "it turns out that load started out",
    "start": "830399",
    "end": "833680"
  },
  {
    "text": "pretty evenly distributed and then",
    "start": "833680",
    "end": "836399"
  },
  {
    "text": "slowly diverges",
    "start": "836399",
    "end": "838639"
  },
  {
    "text": "our test cluster was either reconfigured",
    "start": "838639",
    "end": "842480"
  },
  {
    "text": "often enough",
    "start": "842480",
    "end": "843760"
  },
  {
    "text": "or saw long enough breaks with no",
    "start": "843760",
    "end": "846480"
  },
  {
    "text": "traffic",
    "start": "846480",
    "end": "847519"
  },
  {
    "text": "that things reset themselves whereas our",
    "start": "847519",
    "end": "850639"
  },
  {
    "text": "production traffic",
    "start": "850639",
    "end": "851920"
  },
  {
    "text": "cluster was always loaded",
    "start": "851920",
    "end": "856079"
  },
  {
    "start": "855000",
    "end": "885000"
  },
  {
    "text": "so this is the end of our journey",
    "start": "856079",
    "end": "859279"
  },
  {
    "text": "we have now had four months without any",
    "start": "859279",
    "end": "861680"
  },
  {
    "text": "major problems",
    "start": "861680",
    "end": "863360"
  },
  {
    "text": "and to get more certainty we did a",
    "start": "863360",
    "end": "866320"
  },
  {
    "text": "successful regional failover test where",
    "start": "866320",
    "end": "868160"
  },
  {
    "text": "we killed one region",
    "start": "868160",
    "end": "869440"
  },
  {
    "text": "and let all that traffic go to our other",
    "start": "869440",
    "end": "871279"
  },
  {
    "text": "regions and it just worked",
    "start": "871279",
    "end": "874480"
  },
  {
    "text": "so we have started doing fun things like",
    "start": "874480",
    "end": "876720"
  },
  {
    "text": "upgrading to the version 3 of the xts",
    "start": "876720",
    "end": "878880"
  },
  {
    "text": "api",
    "start": "878880",
    "end": "880160"
  },
  {
    "text": "adding rate limiting and looking at",
    "start": "880160",
    "end": "882480"
  },
  {
    "text": "course configuration for our clients",
    "start": "882480",
    "end": "886079"
  },
  {
    "text": "and we did take it slow by rolling out",
    "start": "886639",
    "end": "889519"
  },
  {
    "text": "gradual",
    "start": "889519",
    "end": "890160"
  },
  {
    "text": "over an entire year and we did spend a",
    "start": "890160",
    "end": "893440"
  },
  {
    "text": "full week of performance testing before",
    "start": "893440",
    "end": "895839"
  },
  {
    "text": "our last and final deployment and still",
    "start": "895839",
    "end": "898959"
  },
  {
    "text": "we failed to identify five major",
    "start": "898959",
    "end": "901360"
  },
  {
    "text": "scalability bottlenecks",
    "start": "901360",
    "end": "904079"
  },
  {
    "text": "maybe spending an hour looking at all",
    "start": "904079",
    "end": "906800"
  },
  {
    "text": "the available metrics",
    "start": "906800",
    "end": "908000"
  },
  {
    "text": "while testing our setup might have",
    "start": "908000",
    "end": "910800"
  },
  {
    "text": "actually identified",
    "start": "910800",
    "end": "911920"
  },
  {
    "text": "a few of these problems but probably not",
    "start": "911920",
    "end": "915279"
  },
  {
    "text": "all of them looking back this journey",
    "start": "915279",
    "end": "918720"
  },
  {
    "text": "was a lot of fun",
    "start": "918720",
    "end": "920399"
  },
  {
    "text": "even though it didn't always feel like",
    "start": "920399",
    "end": "922480"
  },
  {
    "text": "that while it was ongoing",
    "start": "922480",
    "end": "925040"
  },
  {
    "text": "and we for sure did learn a lot",
    "start": "925040",
    "end": "929199"
  },
  {
    "start": "928000",
    "end": "981000"
  },
  {
    "text": "so some suggestions we thought we would",
    "start": "929199",
    "end": "932240"
  },
  {
    "text": "share",
    "start": "932240",
    "end": "933360"
  },
  {
    "text": "they would most likely have helped us so",
    "start": "933360",
    "end": "935279"
  },
  {
    "text": "maybe they can help",
    "start": "935279",
    "end": "936639"
  },
  {
    "text": "someone else make the default cue size",
    "start": "936639",
    "end": "940320"
  },
  {
    "text": "per core so you don't have to remember",
    "start": "940320",
    "end": "942720"
  },
  {
    "text": "to change it when you change your",
    "start": "942720",
    "end": "944160"
  },
  {
    "text": "machine type",
    "start": "944160",
    "end": "945199"
  },
  {
    "text": "to have a different number of cores",
    "start": "945199",
    "end": "948399"
  },
  {
    "text": "make so reuse port default",
    "start": "948399",
    "end": "951680"
  },
  {
    "text": "we know this has some performance costs",
    "start": "951680",
    "end": "953920"
  },
  {
    "text": "to low traffic servers",
    "start": "953920",
    "end": "955759"
  },
  {
    "text": "but we figure efficiency is more",
    "start": "955759",
    "end": "958079"
  },
  {
    "text": "important on high traffic servers",
    "start": "958079",
    "end": "960800"
  },
  {
    "text": "another alternative would be to",
    "start": "960800",
    "end": "962560"
  },
  {
    "text": "highlight it in the",
    "start": "962560",
    "end": "964240"
  },
  {
    "text": "best practices guide for android as an",
    "start": "964240",
    "end": "966480"
  },
  {
    "text": "edge proxy",
    "start": "966480",
    "end": "968320"
  },
  {
    "text": "and last add average latency to the",
    "start": "968320",
    "end": "971040"
  },
  {
    "text": "histograms",
    "start": "971040",
    "end": "972399"
  },
  {
    "text": "we know averages can be overused and",
    "start": "972399",
    "end": "974800"
  },
  {
    "text": "misguiding",
    "start": "974800",
    "end": "976000"
  },
  {
    "text": "but when doing math on connection",
    "start": "976000",
    "end": "978000"
  },
  {
    "text": "settings it can be",
    "start": "978000",
    "end": "979120"
  },
  {
    "text": "very helpful",
    "start": "979120",
    "end": "982160"
  },
  {
    "text": "okay so how do you fail at life",
    "start": "982160",
    "end": "987360"
  },
  {
    "text": "by planning for it assume",
    "start": "987360",
    "end": "991120"
  },
  {
    "text": "that you will fail because you will",
    "start": "991120",
    "end": "994880"
  },
  {
    "text": "try to think ahead to when you will fail",
    "start": "994880",
    "end": "998079"
  },
  {
    "text": "and try to think of what you need to do",
    "start": "998079",
    "end": "1001759"
  },
  {
    "text": "next and make sure that you have the",
    "start": "1001759",
    "end": "1005199"
  },
  {
    "text": "tools at your disposal",
    "start": "1005199",
    "end": "1007040"
  },
  {
    "text": "to do just that this",
    "start": "1007040",
    "end": "1010720"
  },
  {
    "text": "often means having the right metrics",
    "start": "1010720",
    "end": "1014079"
  },
  {
    "text": "next do your best to reproduce",
    "start": "1014079",
    "end": "1017279"
  },
  {
    "text": "all problems outside of the production",
    "start": "1017279",
    "end": "1020720"
  },
  {
    "text": "environment",
    "start": "1020720",
    "end": "1022079"
  },
  {
    "text": "not only does doing so give you much",
    "start": "1022079",
    "end": "1024880"
  },
  {
    "text": "more opportunity",
    "start": "1024880",
    "end": "1026000"
  },
  {
    "text": "to see what happens in various related",
    "start": "1026000",
    "end": "1028319"
  },
  {
    "text": "failure scenarios",
    "start": "1028319",
    "end": "1029839"
  },
  {
    "text": "the act of crafting",
    "start": "1029839",
    "end": "1033120"
  },
  {
    "text": "a test environment often shows you blind",
    "start": "1033280",
    "end": "1036240"
  },
  {
    "text": "spots",
    "start": "1036240",
    "end": "1036880"
  },
  {
    "text": "you didn't know you had and finally",
    "start": "1036880",
    "end": "1040720"
  },
  {
    "text": "communicate ask for help",
    "start": "1040720",
    "end": "1044880"
  },
  {
    "text": "broadcast your shortcomings to anyone",
    "start": "1044880",
    "end": "1047438"
  },
  {
    "text": "who can be made to listen",
    "start": "1047439",
    "end": "1050559"
  },
  {
    "text": "like you even if",
    "start": "1050559",
    "end": "1053600"
  },
  {
    "text": "your mistakes are embarrassingly dumb",
    "start": "1053600",
    "end": "1057280"
  },
  {
    "text": "like ours keep talking",
    "start": "1057280",
    "end": "1060880"
  },
  {
    "text": "maybe some of those mistakes can be",
    "start": "1060880",
    "end": "1064160"
  },
  {
    "text": "prevented",
    "start": "1064160",
    "end": "1065039"
  },
  {
    "text": "through code changes and if not",
    "start": "1065039",
    "end": "1068160"
  },
  {
    "text": "at least more people will know",
    "start": "1068160",
    "end": "1071360"
  },
  {
    "text": "about the common pitfalls",
    "start": "1071360",
    "end": "1074799"
  },
  {
    "start": "1074000",
    "end": "1470000"
  },
  {
    "text": "hello everyone are there any questions",
    "start": "1074960",
    "end": "1078799"
  },
  {
    "text": "in here",
    "start": "1078799",
    "end": "1081840"
  },
  {
    "text": "thank you for all of the feedback and",
    "start": "1087360",
    "end": "1090160"
  },
  {
    "text": "the thumbs up and whatnot",
    "start": "1090160",
    "end": "1092720"
  },
  {
    "text": "let's see uh have you guys looked at",
    "start": "1092720",
    "end": "1095840"
  },
  {
    "text": "enabling",
    "start": "1095840",
    "end": "1097039"
  },
  {
    "text": "exact balancer on the listener",
    "start": "1097039",
    "end": "1100799"
  },
  {
    "text": "i'm gonna let you handle that one",
    "start": "1100799",
    "end": "1102080"
  },
  {
    "text": "because i don't know i i",
    "start": "1102080",
    "end": "1104080"
  },
  {
    "text": "don't actually know what that is that",
    "start": "1104080",
    "end": "1107120"
  },
  {
    "text": "was what i was too ashamed to admit",
    "start": "1107120",
    "end": "1109280"
  },
  {
    "text": "so i'm not ashamed of things like that",
    "start": "1109280",
    "end": "1112559"
  },
  {
    "text": "uh i have no idea i will look it up",
    "start": "1112559",
    "end": "1114160"
  },
  {
    "text": "thanks for a tip",
    "start": "1114160",
    "end": "1116799"
  },
  {
    "text": "uh question about if http 1.1 issue was",
    "start": "1119440",
    "end": "1122880"
  },
  {
    "text": "identified",
    "start": "1122880",
    "end": "1124240"
  },
  {
    "text": "so there was no http 1.1",
    "start": "1124240",
    "end": "1128320"
  },
  {
    "text": "issue that was a suspicion that we had",
    "start": "1128320",
    "end": "1130880"
  },
  {
    "text": "that maybe",
    "start": "1130880",
    "end": "1132160"
  },
  {
    "text": "the http 1.1 stack was slower or less",
    "start": "1132160",
    "end": "1135520"
  },
  {
    "text": "battle tested or less scalable or",
    "start": "1135520",
    "end": "1137280"
  },
  {
    "text": "something like that and that turned out",
    "start": "1137280",
    "end": "1139520"
  },
  {
    "text": "to be",
    "start": "1139520",
    "end": "1140320"
  },
  {
    "text": "wrong uh we are still using http",
    "start": "1140320",
    "end": "1144000"
  },
  {
    "text": "2 from envoy to the load balancer",
    "start": "1144000",
    "end": "1147840"
  },
  {
    "text": "from from the load balancer to envoy",
    "start": "1147840",
    "end": "1149520"
  },
  {
    "text": "obviously and then from envoy",
    "start": "1149520",
    "end": "1151520"
  },
  {
    "text": "to our microservices we're talking http",
    "start": "1151520",
    "end": "1154160"
  },
  {
    "text": "1.1",
    "start": "1154160",
    "end": "1155360"
  },
  {
    "text": "and they both seem to perform just fine",
    "start": "1155360",
    "end": "1164000"
  },
  {
    "text": "uh running into very similar problems at",
    "start": "1164000",
    "end": "1166640"
  },
  {
    "text": "twitter",
    "start": "1166640",
    "end": "1167520"
  },
  {
    "text": "i think overall",
    "start": "1167520",
    "end": "1171120"
  },
  {
    "text": "i would expect people that have very",
    "start": "1171120",
    "end": "1173919"
  },
  {
    "text": "large",
    "start": "1173919",
    "end": "1174880"
  },
  {
    "text": "request volumes to have similar issues",
    "start": "1174880",
    "end": "1178240"
  },
  {
    "text": "and i think uh",
    "start": "1178240",
    "end": "1181679"
  },
  {
    "text": "like there is a very good start of",
    "start": "1181679",
    "end": "1184799"
  },
  {
    "text": "how to put how to make uh online http",
    "start": "1184799",
    "end": "1188559"
  },
  {
    "text": "proxy for a large",
    "start": "1188559",
    "end": "1189840"
  },
  {
    "text": "organization in the docs for envoy but i",
    "start": "1189840",
    "end": "1193120"
  },
  {
    "text": "think there are",
    "start": "1193120",
    "end": "1194080"
  },
  {
    "text": "there are opportunities to improve",
    "start": "1194080",
    "end": "1197280"
  },
  {
    "text": "the configuration as well as improve",
    "start": "1197280",
    "end": "1199679"
  },
  {
    "text": "that documentation to make",
    "start": "1199679",
    "end": "1202000"
  },
  {
    "text": "life even easier for a",
    "start": "1202000",
    "end": "1205200"
  },
  {
    "text": "large uh installations",
    "start": "1205200",
    "end": "1208960"
  },
  {
    "text": "yeah definitely",
    "start": "1208960",
    "end": "1211919"
  },
  {
    "text": "ah it's another way of forcing",
    "start": "1216000",
    "end": "1217600"
  },
  {
    "text": "connection balancing well",
    "start": "1217600",
    "end": "1220240"
  },
  {
    "text": "then we should look into and see if it",
    "start": "1220240",
    "end": "1222480"
  },
  {
    "text": "works",
    "start": "1222480",
    "end": "1223520"
  },
  {
    "text": "better or worse thanks for the tip yeah",
    "start": "1223520",
    "end": "1226799"
  },
  {
    "text": "and yes maxim in our load testing we got",
    "start": "1226799",
    "end": "1230320"
  },
  {
    "text": "about 1000 requests per second per core",
    "start": "1230320",
    "end": "1234000"
  },
  {
    "text": "i think in production we get a little",
    "start": "1234000",
    "end": "1235520"
  },
  {
    "text": "bit less",
    "start": "1235520",
    "end": "1238000"
  },
  {
    "text": "and matt klein asks why are you using",
    "start": "1243039",
    "end": "1246320"
  },
  {
    "text": "http 1.1 to the back ends versus 2",
    "start": "1246320",
    "end": "1250880"
  },
  {
    "text": "and the answer to that is",
    "start": "1250880",
    "end": "1254159"
  },
  {
    "text": "mostly legacy so spotify",
    "start": "1254159",
    "end": "1258159"
  },
  {
    "text": "has a very old network stack it's almost",
    "start": "1258159",
    "end": "1262080"
  },
  {
    "text": "it's about a decade old we implemented",
    "start": "1262080",
    "end": "1264960"
  },
  {
    "text": "our own",
    "start": "1264960",
    "end": "1266240"
  },
  {
    "text": "uh transport layer instead of uh http",
    "start": "1266240",
    "end": "1270400"
  },
  {
    "text": "because we had a lot of scalability",
    "start": "1270400",
    "end": "1272720"
  },
  {
    "text": "problems with http",
    "start": "1272720",
    "end": "1275039"
  },
  {
    "text": "this uh transport layer called hermes",
    "start": "1275039",
    "end": "1278880"
  },
  {
    "text": "is basically very similar in most ways",
    "start": "1278880",
    "end": "1281520"
  },
  {
    "text": "to http",
    "start": "1281520",
    "end": "1282559"
  },
  {
    "text": "2. it solves the same problems in mostly",
    "start": "1282559",
    "end": "1285679"
  },
  {
    "text": "the same way",
    "start": "1285679",
    "end": "1286799"
  },
  {
    "text": "and it tries to be very http like",
    "start": "1286799",
    "end": "1290080"
  },
  {
    "text": "in its api but it is",
    "start": "1290080",
    "end": "1293360"
  },
  {
    "text": "uh older than http 2. we started work",
    "start": "1293360",
    "end": "1297919"
  },
  {
    "text": "slightly after well like slightly before",
    "start": "1297919",
    "end": "1301200"
  },
  {
    "text": "google started talking about speedy",
    "start": "1301200",
    "end": "1303360"
  },
  {
    "text": "publicly",
    "start": "1303360",
    "end": "1305440"
  },
  {
    "text": "and we are still transitioning away from",
    "start": "1305440",
    "end": "1307840"
  },
  {
    "text": "this internal hermes protocol",
    "start": "1307840",
    "end": "1309919"
  },
  {
    "text": "and what we have today for our hermes",
    "start": "1309919",
    "end": "1312400"
  },
  {
    "text": "based services",
    "start": "1312400",
    "end": "1313840"
  },
  {
    "text": "is a uh",
    "start": "1313840",
    "end": "1317039"
  },
  {
    "text": "like library that you can use to accept",
    "start": "1317039",
    "end": "1320320"
  },
  {
    "text": "http traffic as if it was hermes traffic",
    "start": "1320320",
    "end": "1323600"
  },
  {
    "text": "and we are instead moving to internally",
    "start": "1323600",
    "end": "1326080"
  },
  {
    "text": "use",
    "start": "1326080",
    "end": "1326960"
  },
  {
    "text": "uh http 2 and grpc and then",
    "start": "1326960",
    "end": "1330480"
  },
  {
    "text": "in the future hopefully http 3 and so on",
    "start": "1330480",
    "end": "1333919"
  },
  {
    "text": "like modernizing our stack but we're not",
    "start": "1333919",
    "end": "1336799"
  },
  {
    "text": "there yet",
    "start": "1336799",
    "end": "1339279"
  },
  {
    "text": "and christopher we're six people",
    "start": "1341919",
    "end": "1345440"
  },
  {
    "text": "i believe",
    "start": "1345440",
    "end": "1347840"
  },
  {
    "text": "yeah something like that yes",
    "start": "1348880",
    "end": "1353039"
  },
  {
    "text": "and the other people are more competent",
    "start": "1353039",
    "end": "1355120"
  },
  {
    "text": "than me and ex",
    "start": "1355120",
    "end": "1357840"
  },
  {
    "text": "that's why they kicked me out yes",
    "start": "1357840",
    "end": "1361840"
  },
  {
    "text": "and louise i'm not sure how many",
    "start": "1365280",
    "end": "1367520"
  },
  {
    "text": "requests per connection we had",
    "start": "1367520",
    "end": "1370559"
  },
  {
    "text": "if you ask me on slack i can i can check",
    "start": "1370559",
    "end": "1373919"
  },
  {
    "text": "it",
    "start": "1373919",
    "end": "1376080"
  },
  {
    "text": "so with regards to much in the way of",
    "start": "1382480",
    "end": "1385200"
  },
  {
    "text": "filters",
    "start": "1385200",
    "end": "1386480"
  },
  {
    "text": "we are using a few filters to filter out",
    "start": "1386480",
    "end": "1389760"
  },
  {
    "text": "uh users who are not allowed on some",
    "start": "1389760",
    "end": "1392799"
  },
  {
    "text": "resources and so on",
    "start": "1392799",
    "end": "1394400"
  },
  {
    "text": "but the big thing that reduces our",
    "start": "1394400",
    "end": "1397600"
  },
  {
    "text": "efficiency",
    "start": "1397600",
    "end": "1398400"
  },
  {
    "text": "i would say is that we are running",
    "start": "1398400",
    "end": "1402159"
  },
  {
    "text": "both the uh both envoy itself",
    "start": "1402159",
    "end": "1406000"
  },
  {
    "text": "and this decorator side car which is",
    "start": "1406000",
    "end": "1408720"
  },
  {
    "text": "implemented as",
    "start": "1408720",
    "end": "1409840"
  },
  {
    "text": "an ext off c filter on",
    "start": "1409840",
    "end": "1413120"
  },
  {
    "text": "those on the same 32 core machine so the",
    "start": "1413120",
    "end": "1416320"
  },
  {
    "text": "three resource hogs on the machine",
    "start": "1416320",
    "end": "1418640"
  },
  {
    "text": "is envoy itself which uses like half the",
    "start": "1418640",
    "end": "1422080"
  },
  {
    "text": "cpu",
    "start": "1422080",
    "end": "1423120"
  },
  {
    "text": "and then the sidecar which uses slightly",
    "start": "1423120",
    "end": "1425760"
  },
  {
    "text": "less but still a significant amount",
    "start": "1425760",
    "end": "1428159"
  },
  {
    "text": "and lastly also the metrics propagation",
    "start": "1428159",
    "end": "1431120"
  },
  {
    "text": "which uses about 1 out of 32 cores",
    "start": "1431120",
    "end": "1434240"
  },
  {
    "text": "so all three of those are running on",
    "start": "1434240",
    "end": "1437039"
  },
  {
    "text": "every single envoy host",
    "start": "1437039",
    "end": "1439120"
  },
  {
    "text": "so and also that means that you're",
    "start": "1439120",
    "end": "1442159"
  },
  {
    "text": "getting",
    "start": "1442159",
    "end": "1443200"
  },
  {
    "text": "you get a message in to envoy and then",
    "start": "1443200",
    "end": "1446559"
  },
  {
    "text": "it's passed out from envoy to the other",
    "start": "1446559",
    "end": "1448400"
  },
  {
    "text": "service and then back",
    "start": "1448400",
    "end": "1449679"
  },
  {
    "text": "and then to the next and then you get",
    "start": "1449679",
    "end": "1451360"
  },
  {
    "text": "the replying so like",
    "start": "1451360",
    "end": "1453120"
  },
  {
    "text": "there are six message passing steps or",
    "start": "1453120",
    "end": "1455360"
  },
  {
    "text": "something like that",
    "start": "1455360",
    "end": "1456720"
  },
  {
    "text": "uh not just the four that you would",
    "start": "1456720",
    "end": "1459120"
  },
  {
    "text": "expect",
    "start": "1459120",
    "end": "1460480"
  },
  {
    "text": "my math is probably wrong but something",
    "start": "1460480",
    "end": "1462400"
  },
  {
    "text": "along those lines",
    "start": "1462400",
    "end": "1463679"
  },
  {
    "text": "yeah and also the our decorator is in",
    "start": "1463679",
    "end": "1466159"
  },
  {
    "text": "java so we have some garbage collection",
    "start": "1466159",
    "end": "1468559"
  },
  {
    "text": "fun things",
    "start": "1468559",
    "end": "1472320"
  },
  {
    "start": "1470000",
    "end": "1616000"
  },
  {
    "text": "and replacing it with filters i don't",
    "start": "1472320",
    "end": "1475360"
  },
  {
    "text": "think we have talked about that",
    "start": "1475360",
    "end": "1478559"
  },
  {
    "text": "and i'm not sure why we decided to go",
    "start": "1478960",
    "end": "1481679"
  },
  {
    "text": "with a",
    "start": "1481679",
    "end": "1483200"
  },
  {
    "text": "side car that was before i joined the",
    "start": "1483200",
    "end": "1485360"
  },
  {
    "text": "team actually",
    "start": "1485360",
    "end": "1487120"
  },
  {
    "text": "that decision is over a year old",
    "start": "1487120",
    "end": "1490480"
  },
  {
    "text": "i i was very interested to hear",
    "start": "1490480",
    "end": "1495120"
  },
  {
    "text": "the uh talk like one of the starting",
    "start": "1495120",
    "end": "1498960"
  },
  {
    "text": "talks about using webassembly to make",
    "start": "1498960",
    "end": "1501440"
  },
  {
    "text": "your own custom filters in envoy",
    "start": "1501440",
    "end": "1505360"
  },
  {
    "text": "that could definitely be useful for us",
    "start": "1505360",
    "end": "1510000"
  },
  {
    "text": "we did not want to write our own c",
    "start": "1510240",
    "end": "1512799"
  },
  {
    "text": "c-plus plus filters because",
    "start": "1512799",
    "end": "1514799"
  },
  {
    "text": "we as a company have too few developers",
    "start": "1514799",
    "end": "1518559"
  },
  {
    "text": "who are super comfortable with",
    "start": "1518559",
    "end": "1520640"
  },
  {
    "text": "c plus plus and then it becomes a",
    "start": "1520640",
    "end": "1524320"
  },
  {
    "text": "like who owns its uh problem problem",
    "start": "1524320",
    "end": "1528000"
  },
  {
    "text": "whereas we have lots of java devs but",
    "start": "1528000",
    "end": "1531039"
  },
  {
    "text": "webassembly might help out with that we",
    "start": "1531039",
    "end": "1533600"
  },
  {
    "text": "don't know",
    "start": "1533600",
    "end": "1534159"
  },
  {
    "text": "we'll see",
    "start": "1534159",
    "end": "1536559"
  },
  {
    "text": "but overall i agree that the sidecar",
    "start": "1539919",
    "end": "1542400"
  },
  {
    "text": "solution",
    "start": "1542400",
    "end": "1543039"
  },
  {
    "text": "feels like probably not what we want to",
    "start": "1543039",
    "end": "1546080"
  },
  {
    "text": "do long term",
    "start": "1546080",
    "end": "1548080"
  },
  {
    "text": "yeah and maxine we're running on",
    "start": "1548080",
    "end": "1550880"
  },
  {
    "text": "managing infrastructure",
    "start": "1550880",
    "end": "1557840"
  },
  {
    "text": "i think we answered all of the questions",
    "start": "1561039",
    "end": "1564640"
  },
  {
    "text": "if someone has a question that they um",
    "start": "1564640",
    "end": "1568400"
  },
  {
    "text": "posted that we didn't answer it's not",
    "start": "1568400",
    "end": "1571039"
  },
  {
    "text": "because we hate you",
    "start": "1571039",
    "end": "1572000"
  },
  {
    "text": "it's because we missed it so please feel",
    "start": "1572000",
    "end": "1574000"
  },
  {
    "text": "free to repost it in that case",
    "start": "1574000",
    "end": "1576080"
  },
  {
    "text": "yeah or ask on the elmo slack at least",
    "start": "1576080",
    "end": "1579200"
  },
  {
    "text": "i'm there i'm not sure if you are",
    "start": "1579200",
    "end": "1580400"
  },
  {
    "text": "excellent",
    "start": "1580400",
    "end": "1581200"
  },
  {
    "text": "i actually am fantastic i know",
    "start": "1581200",
    "end": "1586639"
  },
  {
    "text": "well that seems to be it",
    "start": "1589440",
    "end": "1594799"
  },
  {
    "text": "sure does thanks a lot everyone for",
    "start": "1594799",
    "end": "1597440"
  },
  {
    "text": "listening",
    "start": "1597440",
    "end": "1599600"
  },
  {
    "text": "this was uh this was great i will now",
    "start": "1599600",
    "end": "1603919"
  },
  {
    "text": "disconnect and uh go say hi",
    "start": "1603919",
    "end": "1607039"
  },
  {
    "text": "to the third uh talker from this",
    "start": "1607039",
    "end": "1610320"
  },
  {
    "text": "conference",
    "start": "1610320",
    "end": "1611520"
  },
  {
    "text": "titus so bye",
    "start": "1611520",
    "end": "1614799"
  },
  {
    "text": "bye everyone",
    "start": "1614799",
    "end": "1618559"
  }
]
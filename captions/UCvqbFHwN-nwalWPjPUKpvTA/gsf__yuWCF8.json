[
  {
    "start": "0",
    "end": "97000"
  },
  {
    "text": "okay well hey thanks for being here",
    "start": "260",
    "end": "3240"
  },
  {
    "text": "I know it's near the end of the day at",
    "start": "3240",
    "end": "6390"
  },
  {
    "text": "the two-day conference here it was",
    "start": "6390",
    "end": "8099"
  },
  {
    "text": "probably kind of tired and some of you",
    "start": "8099",
    "end": "10620"
  },
  {
    "text": "are probably jet-lagged like I am and",
    "start": "10620",
    "end": "12530"
  },
  {
    "text": "looking forward to hanging out and",
    "start": "12530",
    "end": "14849"
  },
  {
    "text": "relaxing a little bit this evening so",
    "start": "14849",
    "end": "17779"
  },
  {
    "text": "appreciate you showing up and being here",
    "start": "17779",
    "end": "20550"
  },
  {
    "text": "I hope I can make it worth your while my",
    "start": "20550",
    "end": "23910"
  },
  {
    "text": "name is Sam Wilson I'm here from concur",
    "start": "23910",
    "end": "26580"
  },
  {
    "text": "principal architects there and we're",
    "start": "26580",
    "end": "29609"
  },
  {
    "text": "going to talk about switching from",
    "start": "29609",
    "end": "31080"
  },
  {
    "text": "external load balancing to console and",
    "start": "31080",
    "end": "33690"
  },
  {
    "text": "ingress with kubernetes maybe not quite",
    "start": "33690",
    "end": "39260"
  },
  {
    "text": "because instead we're going to talk",
    "start": "39260",
    "end": "42059"
  },
  {
    "text": "about how we tried to switch from",
    "start": "42059",
    "end": "46200"
  },
  {
    "text": "external load balancing to console and",
    "start": "46200",
    "end": "48780"
  },
  {
    "text": "ingress and some of the challenges who",
    "start": "48780",
    "end": "50670"
  },
  {
    "text": "ran into and where we're going to go to",
    "start": "50670",
    "end": "52559"
  },
  {
    "text": "from from there so a little bit about",
    "start": "52559",
    "end": "58140"
  },
  {
    "text": "concur we are in the business of",
    "start": "58140",
    "end": "61410"
  },
  {
    "text": "controlling spend for companies and at",
    "start": "61410",
    "end": "66659"
  },
  {
    "text": "the same time we make it easier as an",
    "start": "66659",
    "end": "70320"
  },
  {
    "text": "employee to get reimbursed quickly for",
    "start": "70320",
    "end": "73229"
  },
  {
    "text": "that spend when you're on the road and",
    "start": "73229",
    "end": "76590"
  },
  {
    "text": "our users expect our services to be",
    "start": "76590",
    "end": "79200"
  },
  {
    "text": "available so availability is super",
    "start": "79200",
    "end": "81119"
  },
  {
    "text": "important to us",
    "start": "81119",
    "end": "82950"
  },
  {
    "text": "and speaking of users we've been growing",
    "start": "82950",
    "end": "86549"
  },
  {
    "text": "like mad and it hasn't slowed down fact",
    "start": "86549",
    "end": "89670"
  },
  {
    "text": "it's accelerated since s ap acquired our",
    "start": "89670",
    "end": "92729"
  },
  {
    "text": "business a few years ago little about me",
    "start": "92729",
    "end": "98820"
  },
  {
    "start": "97000",
    "end": "127000"
  },
  {
    "text": "oh yeah sorry",
    "start": "98820",
    "end": "100619"
  },
  {
    "text": "I been at concur forever and worn a lot",
    "start": "100619",
    "end": "105060"
  },
  {
    "text": "of different hats throughout the years",
    "start": "105060",
    "end": "106590"
  },
  {
    "text": "thankfully otherwise I'd be really bored",
    "start": "106590",
    "end": "108479"
  },
  {
    "text": "and I've been working on kubernetes for",
    "start": "108479",
    "end": "111180"
  },
  {
    "text": "about a year and a half now and I",
    "start": "111180",
    "end": "113670"
  },
  {
    "text": "currently participate in the Federation",
    "start": "113670",
    "end": "115770"
  },
  {
    "text": "sig and have been a contributor to that",
    "start": "115770",
    "end": "122700"
  },
  {
    "text": "regard so I love working with the",
    "start": "122700",
    "end": "125280"
  },
  {
    "text": "product a little bit about kubernetes",
    "start": "125280",
    "end": "130080"
  },
  {
    "start": "127000",
    "end": "203000"
  },
  {
    "text": "second curve this is a very high level",
    "start": "130080",
    "end": "132300"
  },
  {
    "text": "view we have a lot of clusters and a lot",
    "start": "132300",
    "end": "136050"
  },
  {
    "text": "of different locations and in order to",
    "start": "136050",
    "end": "139050"
  },
  {
    "text": "make it easy to deploy from a CI system",
    "start": "139050",
    "end": "143270"
  },
  {
    "text": "onto those kubernetes clusters we wrote",
    "start": "143270",
    "end": "145800"
  },
  {
    "text": "our own internal tool tool called",
    "start": "145800",
    "end": "147870"
  },
  {
    "text": "skipper that's what the penguin is there",
    "start": "147870",
    "end": "150300"
  },
  {
    "text": "and what this does is it takes the the",
    "start": "150300",
    "end": "153209"
  },
  {
    "text": "deployment primitives as a result of our",
    "start": "153209",
    "end": "155640"
  },
  {
    "text": "CI the container version of the",
    "start": "155640",
    "end": "159510"
  },
  {
    "text": "container how many copies you want to",
    "start": "159510",
    "end": "161250"
  },
  {
    "text": "run environment variables and where you",
    "start": "161250",
    "end": "163950"
  },
  {
    "text": "want to run it whether you're running it",
    "start": "163950",
    "end": "165599"
  },
  {
    "text": "in the US or Mia or everywhere and then",
    "start": "165599",
    "end": "168840"
  },
  {
    "text": "it translates that into the different",
    "start": "168840",
    "end": "171030"
  },
  {
    "text": "kubernetes api calls so that the",
    "start": "171030",
    "end": "174470"
  },
  {
    "text": "services and deployment objects and",
    "start": "174470",
    "end": "177390"
  },
  {
    "text": "whatever else are created on those",
    "start": "177390",
    "end": "178769"
  },
  {
    "text": "clusters and rollouts blue/green",
    "start": "178769",
    "end": "182190"
  },
  {
    "text": "deployments happen thanks to deployments",
    "start": "182190",
    "end": "185840"
  },
  {
    "text": "ci to us is a composable tier so that",
    "start": "185840",
    "end": "189180"
  },
  {
    "text": "could be jenkins it could be drone it",
    "start": "189180",
    "end": "191250"
  },
  {
    "text": "could be circle CI it doesn't matter to",
    "start": "191250",
    "end": "193890"
  },
  {
    "text": "us the important thing is that it's",
    "start": "193890",
    "end": "195480"
  },
  {
    "text": "really simple to do that deployment",
    "start": "195480",
    "end": "197610"
  },
  {
    "text": "through a curl command at the end of the",
    "start": "197610",
    "end": "199500"
  },
  {
    "text": "CI process so zooming in a little bit on",
    "start": "199500",
    "end": "205739"
  },
  {
    "start": "203000",
    "end": "272000"
  },
  {
    "text": "a single cluster we've gone with a core",
    "start": "205739",
    "end": "209700"
  },
  {
    "text": "OS deployment we love the the core OS",
    "start": "209700",
    "end": "212819"
  },
  {
    "text": "system super simple to get started a lot",
    "start": "212819",
    "end": "215730"
  },
  {
    "text": "of the things have been figured out for",
    "start": "215730",
    "end": "217830"
  },
  {
    "text": "us already like what version of X CD and",
    "start": "217830",
    "end": "221099"
  },
  {
    "text": "flannel and and dr. all worked together",
    "start": "221099",
    "end": "226370"
  },
  {
    "text": "we we still make every cluster highly",
    "start": "226370",
    "end": "230310"
  },
  {
    "text": "available with multiple sed nodes and",
    "start": "230310",
    "end": "233189"
  },
  {
    "text": "master nodes we plug the pool of master",
    "start": "233189",
    "end": "236640"
  },
  {
    "text": "nodes into external load balancers",
    "start": "236640",
    "end": "238920"
  },
  {
    "text": "inside our data center so that API calls",
    "start": "238920",
    "end": "243060"
  },
  {
    "text": "can be distributed to those masters and",
    "start": "243060",
    "end": "246379"
  },
  {
    "text": "if a service is deployed on our clusters",
    "start": "246379",
    "end": "249900"
  },
  {
    "text": "that service is also tied into external",
    "start": "249900",
    "end": "252750"
  },
  {
    "text": "load balancing I'll talk a little bit",
    "start": "252750",
    "end": "254250"
  },
  {
    "text": "more about how we do that in a minute",
    "start": "254250",
    "end": "256459"
  },
  {
    "text": "we've pulled monitoring and elq outside",
    "start": "256459",
    "end": "259949"
  },
  {
    "text": "of the cluster for obvious reasons",
    "start": "259949",
    "end": "262070"
  },
  {
    "text": "we have multiple clusters and also if",
    "start": "262070",
    "end": "264290"
  },
  {
    "text": "you know if you had an issue with the",
    "start": "264290",
    "end": "265610"
  },
  {
    "text": "cluster it'd be nice to be able to",
    "start": "265610",
    "end": "266900"
  },
  {
    "text": "actually use those services so zooming",
    "start": "266900",
    "end": "273440"
  },
  {
    "start": "272000",
    "end": "357000"
  },
  {
    "text": "out just a little bit to where we're",
    "start": "273440",
    "end": "276110"
  },
  {
    "text": "looking at multiple clusters now in a",
    "start": "276110",
    "end": "277790"
  },
  {
    "text": "single location we we tie those clusters",
    "start": "277790",
    "end": "283190"
  },
  {
    "text": "into load balancing with a single",
    "start": "283190",
    "end": "285830"
  },
  {
    "text": "endpoint so a service that is being",
    "start": "285830",
    "end": "290060"
  },
  {
    "text": "accessed would have a single DNS name a",
    "start": "290060",
    "end": "292610"
  },
  {
    "text": "single VIP and a single pool but inside",
    "start": "292610",
    "end": "297320"
  },
  {
    "text": "of that pool are kubernetes nodes from",
    "start": "297320",
    "end": "302150"
  },
  {
    "text": "each of those clusters so if a single",
    "start": "302150",
    "end": "305270"
  },
  {
    "text": "cluster is having an issue then requests",
    "start": "305270",
    "end": "308660"
  },
  {
    "text": "can still get routed to the other",
    "start": "308660",
    "end": "310340"
  },
  {
    "text": "kubernetes clusters and we we made a",
    "start": "310340",
    "end": "313460"
  },
  {
    "text": "conscious decision early on to go with",
    "start": "313460",
    "end": "315950"
  },
  {
    "text": "this approach because the technology was",
    "start": "315950",
    "end": "318500"
  },
  {
    "text": "still very new any time you're dealing",
    "start": "318500",
    "end": "322550"
  },
  {
    "text": "with new technology there's some",
    "start": "322550",
    "end": "324080"
  },
  {
    "text": "unknowns you could hit we didn't want to",
    "start": "324080",
    "end": "326540"
  },
  {
    "text": "risk those unknowns impacting our",
    "start": "326540",
    "end": "328940"
  },
  {
    "text": "end-users and we wanted to go into a",
    "start": "328940",
    "end": "331430"
  },
  {
    "text": "production state with kubernetes as fast",
    "start": "331430",
    "end": "334220"
  },
  {
    "text": "as possible so that's why we we want",
    "start": "334220",
    "end": "335990"
  },
  {
    "text": "with this architecture okay so but how",
    "start": "335990",
    "end": "338810"
  },
  {
    "text": "do you do that right how do you get",
    "start": "338810",
    "end": "340940"
  },
  {
    "text": "those kubernetes nodes plugged into a",
    "start": "340940",
    "end": "344840"
  },
  {
    "text": "load balancer if you're in a private",
    "start": "344840",
    "end": "346340"
  },
  {
    "text": "data center we're in private cloud or",
    "start": "346340",
    "end": "349910"
  },
  {
    "text": "you know our own data centers and a lot",
    "start": "349910",
    "end": "352010"
  },
  {
    "text": "of locations we're also in public cloud",
    "start": "352010",
    "end": "353660"
  },
  {
    "text": "so we wanted it to work the same as much",
    "start": "353660",
    "end": "357680"
  },
  {
    "start": "357000",
    "end": "409000"
  },
  {
    "text": "as possible so we wrote our own little",
    "start": "357680",
    "end": "360820"
  },
  {
    "text": "kubernetes plugin it's just a simple",
    "start": "360820",
    "end": "363380"
  },
  {
    "text": "golang container that runs on kubernetes",
    "start": "363380",
    "end": "366260"
  },
  {
    "text": "it watches the API some of you may have",
    "start": "366260",
    "end": "368420"
  },
  {
    "text": "attended some talks today talking about",
    "start": "368420",
    "end": "370520"
  },
  {
    "text": "how to leverage the kubernetes api and",
    "start": "370520",
    "end": "373640"
  },
  {
    "text": "that's exactly what we did",
    "start": "373640",
    "end": "375440"
  },
  {
    "text": "super 90s api is awesome you can get a",
    "start": "375440",
    "end": "377960"
  },
  {
    "text": "watch endpoint you can get updates and",
    "start": "377960",
    "end": "381290"
  },
  {
    "text": "to fire off whatever events or changes",
    "start": "381290",
    "end": "384470"
  },
  {
    "text": "that you need to make externally or",
    "start": "384470",
    "end": "386480"
  },
  {
    "text": "inside the cluster but how does this",
    "start": "386480",
    "end": "389900"
  },
  {
    "text": "help you guys right because you don't",
    "start": "389900",
    "end": "391790"
  },
  {
    "text": "have our load balancing technology",
    "start": "391790",
    "end": "393740"
  },
  {
    "text": "inside your data center",
    "start": "393740",
    "end": "395330"
  },
  {
    "text": "chances are you don't have our",
    "start": "395330",
    "end": "397690"
  },
  {
    "text": "abstracted API either we wrote we have",
    "start": "397690",
    "end": "400160"
  },
  {
    "text": "our own load-balancing as a service",
    "start": "400160",
    "end": "402020"
  },
  {
    "text": "inside our data centers that were we're",
    "start": "402020",
    "end": "403850"
  },
  {
    "text": "leveraging here instead of reaching out",
    "start": "403850",
    "end": "405770"
  },
  {
    "text": "to the vendors API directly well you",
    "start": "405770",
    "end": "410900"
  },
  {
    "start": "409000",
    "end": "453000"
  },
  {
    "text": "could do this yourself too if if you",
    "start": "410900",
    "end": "413180"
  },
  {
    "text": "have private data center needs whether",
    "start": "413180",
    "end": "415730"
  },
  {
    "text": "it's load balancing or logging changes",
    "start": "415730",
    "end": "419510"
  },
  {
    "text": "to the cluster or whatever else we you",
    "start": "419510",
    "end": "422990"
  },
  {
    "text": "know created a little sample project on",
    "start": "422990",
    "end": "426230"
  },
  {
    "text": "how to do this it builds a docker",
    "start": "426230",
    "end": "428150"
  },
  {
    "text": "container you can also use a sample",
    "start": "428150",
    "end": "431540"
  },
  {
    "text": "project to test locally against mini",
    "start": "431540",
    "end": "435620"
  },
  {
    "text": "cube it's all the test scripts are set",
    "start": "435620",
    "end": "438770"
  },
  {
    "text": "up for you you could just add your",
    "start": "438770",
    "end": "440900"
  },
  {
    "text": "business logic there or you could just",
    "start": "440900",
    "end": "443180"
  },
  {
    "text": "write your own - and use this as an",
    "start": "443180",
    "end": "445310"
  },
  {
    "text": "example just wanted to share as much as",
    "start": "445310",
    "end": "448460"
  },
  {
    "text": "we could about how we did this inside",
    "start": "448460",
    "end": "450410"
  },
  {
    "text": "our data center ok but what are some of",
    "start": "450410",
    "end": "455540"
  },
  {
    "start": "453000",
    "end": "503000"
  },
  {
    "text": "the challenges we ran into with this",
    "start": "455540",
    "end": "457910"
  },
  {
    "text": "design because clearly it wasn't our",
    "start": "457910",
    "end": "460250"
  },
  {
    "text": "design of choice if we wanted to move",
    "start": "460250",
    "end": "462020"
  },
  {
    "text": "away from external load balancing",
    "start": "462020",
    "end": "464500"
  },
  {
    "text": "well one challenge is that the plugin",
    "start": "464500",
    "end": "467990"
  },
  {
    "text": "has to be pretty smart because it's",
    "start": "467990",
    "end": "470480"
  },
  {
    "text": "manipulating a single pool that has",
    "start": "470480",
    "end": "473500"
  },
  {
    "text": "nodes in it from many clusters so you",
    "start": "473500",
    "end": "477200"
  },
  {
    "text": "know first of all you need to make sure",
    "start": "477200",
    "end": "478250"
  },
  {
    "text": "that you're not messing with nodes from",
    "start": "478250",
    "end": "481550"
  },
  {
    "text": "another cluster and you can't use your",
    "start": "481550",
    "end": "484340"
  },
  {
    "text": "node port that you get as a way of",
    "start": "484340",
    "end": "488690"
  },
  {
    "text": "filtering that you have to actually look",
    "start": "488690",
    "end": "490340"
  },
  {
    "text": "at the IP ranges because those node",
    "start": "490340",
    "end": "492230"
  },
  {
    "text": "ports are dynamic but there is a chance",
    "start": "492230",
    "end": "494840"
  },
  {
    "text": "of a collision that you could end up",
    "start": "494840",
    "end": "497120"
  },
  {
    "text": "having the same nodes port from multiple",
    "start": "497120",
    "end": "500210"
  },
  {
    "text": "clusters the other thing is when we try",
    "start": "500210",
    "end": "506090"
  },
  {
    "start": "503000",
    "end": "611000"
  },
  {
    "text": "to bridge this technology into the cloud",
    "start": "506090",
    "end": "508840"
  },
  {
    "text": "we decided to go with the software load",
    "start": "508840",
    "end": "513050"
  },
  {
    "text": "balancer version of our vendors hardware",
    "start": "513050",
    "end": "515810"
  },
  {
    "text": "load balancer and again this is a",
    "start": "515810",
    "end": "518270"
  },
  {
    "text": "conscious decision we made mainly",
    "start": "518270",
    "end": "520909"
  },
  {
    "text": "because our monolithic apps that we're",
    "start": "520910",
    "end": "523700"
  },
  {
    "text": "all supporting to the cloud relied on",
    "start": "523700",
    "end": "526840"
  },
  {
    "text": "specific features for that",
    "start": "526840",
    "end": "529050"
  },
  {
    "text": "load balancer so we were going to be",
    "start": "529050",
    "end": "531839"
  },
  {
    "text": "moving it into the cloud anyways as a",
    "start": "531839",
    "end": "533940"
  },
  {
    "text": "software-defined appliance and we wanted",
    "start": "533940",
    "end": "538980"
  },
  {
    "text": "things to still be able to talk to each",
    "start": "538980",
    "end": "541380"
  },
  {
    "text": "other from the legacy system to the new",
    "start": "541380",
    "end": "544890"
  },
  {
    "text": "micro services systems as much as",
    "start": "544890",
    "end": "548430"
  },
  {
    "text": "possible the same way inside our data",
    "start": "548430",
    "end": "550290"
  },
  {
    "text": "center as it works in the cloud",
    "start": "550290",
    "end": "553310"
  },
  {
    "text": "well the software-defined load balancing",
    "start": "553310",
    "end": "559649"
  },
  {
    "text": "doesn't look the same in the cloud as it",
    "start": "559649",
    "end": "563459"
  },
  {
    "text": "does inside the data center for one",
    "start": "563459",
    "end": "565500"
  },
  {
    "text": "there's a different load balancer for",
    "start": "565500",
    "end": "567180"
  },
  {
    "text": "each availability zone and then also",
    "start": "567180",
    "end": "569670"
  },
  {
    "text": "there's a global traffic manager that",
    "start": "569670",
    "end": "572339"
  },
  {
    "text": "routes traffic to each of those load",
    "start": "572339",
    "end": "574380"
  },
  {
    "text": "balancers and in order to make this all",
    "start": "574380",
    "end": "577470"
  },
  {
    "text": "work we had to update our load balancing",
    "start": "577470",
    "end": "580140"
  },
  {
    "text": "as a service API to be able to speak a",
    "start": "580140",
    "end": "582839"
  },
  {
    "text": "totally different API to the global",
    "start": "582839",
    "end": "586350"
  },
  {
    "text": "Traffic Manager and we had to handle the",
    "start": "586350",
    "end": "591630"
  },
  {
    "text": "fact that there was three load balancers",
    "start": "591630",
    "end": "594060"
  },
  {
    "text": "that each service would would end up",
    "start": "594060",
    "end": "596190"
  },
  {
    "text": "getting plugged into so just to show",
    "start": "596190",
    "end": "599339"
  },
  {
    "text": "what this would look like with three",
    "start": "599339",
    "end": "602100"
  },
  {
    "text": "services running on the three kubernetes",
    "start": "602100",
    "end": "604200"
  },
  {
    "text": "clusters you're adding each one of those",
    "start": "604200",
    "end": "606899"
  },
  {
    "text": "to every single load balancer and then",
    "start": "606899",
    "end": "612529"
  },
  {
    "start": "611000",
    "end": "651000"
  },
  {
    "text": "the vendor recommends for high",
    "start": "612529",
    "end": "615360"
  },
  {
    "text": "availability reasons that you also add",
    "start": "615360",
    "end": "619970"
  },
  {
    "text": "nodes from clusters in different regions",
    "start": "619970",
    "end": "623820"
  },
  {
    "text": "or different availability zones so we",
    "start": "623820",
    "end": "627959"
  },
  {
    "text": "ended up having to run three copies of",
    "start": "627959",
    "end": "630149"
  },
  {
    "text": "our integration on each cluster in order",
    "start": "630149",
    "end": "633360"
  },
  {
    "text": "to plug the nodes into the three load",
    "start": "633360",
    "end": "635579"
  },
  {
    "text": "balancers and it just gets really messy",
    "start": "635579",
    "end": "638760"
  },
  {
    "text": "right at the it creates a lot of",
    "start": "638760",
    "end": "641430"
  },
  {
    "text": "spaghetti in our cloud environment that",
    "start": "641430",
    "end": "644100"
  },
  {
    "text": "really shouldn't be there",
    "start": "644100",
    "end": "647029"
  },
  {
    "start": "651000",
    "end": "698000"
  },
  {
    "text": "okay so we wanted a better approach we",
    "start": "651200",
    "end": "654210"
  },
  {
    "text": "started to write down our requirements",
    "start": "654210",
    "end": "656370"
  },
  {
    "text": "we wanted the environments to still look",
    "start": "656370",
    "end": "659700"
  },
  {
    "text": "as much the same as possible in every",
    "start": "659700",
    "end": "662910"
  },
  {
    "text": "location we wanted to use the same",
    "start": "662910",
    "end": "666390"
  },
  {
    "text": "technology at every location as well if",
    "start": "666390",
    "end": "668220"
  },
  {
    "text": "we could SSL needs to be as close to our",
    "start": "668220",
    "end": "672300"
  },
  {
    "text": "actual pods as possible and make sense",
    "start": "672300",
    "end": "677040"
  },
  {
    "text": "for the workload and it still needs to",
    "start": "677040",
    "end": "680190"
  },
  {
    "text": "work with our own micro services client",
    "start": "680190",
    "end": "683190"
  },
  {
    "text": "certificate validation and job",
    "start": "683190",
    "end": "685230"
  },
  {
    "text": "validation I'm not going to get into the",
    "start": "685230",
    "end": "687840"
  },
  {
    "text": "details of how that works just because I",
    "start": "687840",
    "end": "689610"
  },
  {
    "text": "can't share it publicly but just wanted",
    "start": "689610",
    "end": "692880"
  },
  {
    "text": "to mention the third there are those",
    "start": "692880",
    "end": "694080"
  },
  {
    "text": "requirements that set in to this okay so",
    "start": "694080",
    "end": "700070"
  },
  {
    "start": "698000",
    "end": "735000"
  },
  {
    "text": "physical load balancers don't work",
    "start": "700070",
    "end": "702980"
  },
  {
    "text": "because there's no real equivalent in",
    "start": "702980",
    "end": "707070"
  },
  {
    "text": "the cloud this is like a nice classic",
    "start": "707070",
    "end": "711060"
  },
  {
    "text": "car that's fast but doesn't have all the",
    "start": "711060",
    "end": "714570"
  },
  {
    "text": "bells and whistles that we need in a",
    "start": "714570",
    "end": "716640"
  },
  {
    "text": "cloud or like a really nice steamer and",
    "start": "716640",
    "end": "721310"
  },
  {
    "text": "the cloud load balancing technology",
    "start": "721310",
    "end": "724440"
  },
  {
    "text": "doesn't work for us because we can't run",
    "start": "724440",
    "end": "728040"
  },
  {
    "text": "cloud load balancing and our data",
    "start": "728040",
    "end": "730080"
  },
  {
    "text": "centers it's not currently so we started",
    "start": "730080",
    "end": "737670"
  },
  {
    "start": "735000",
    "end": "874000"
  },
  {
    "text": "to look at console and ingress and",
    "start": "737670",
    "end": "739350"
  },
  {
    "text": "pairing them together so a little bit",
    "start": "739350",
    "end": "742860"
  },
  {
    "text": "about console and when I'm talking about",
    "start": "742860",
    "end": "745560"
  },
  {
    "text": "console here I'm talking about console",
    "start": "745560",
    "end": "747960"
  },
  {
    "text": "services and not console key value store",
    "start": "747960",
    "end": "751340"
  },
  {
    "text": "very different the services allow you to",
    "start": "751340",
    "end": "756140"
  },
  {
    "text": "take a set of systems and tie them into",
    "start": "756140",
    "end": "761940"
  },
  {
    "text": "a single service that then when you when",
    "start": "761940",
    "end": "768480"
  },
  {
    "text": "you do that you get a DNS name and",
    "start": "768480",
    "end": "770040"
  },
  {
    "text": "console for that service that resolves",
    "start": "770040",
    "end": "772710"
  },
  {
    "text": "if you use the console as your DNS",
    "start": "772710",
    "end": "776820"
  },
  {
    "text": "server itself or you forward to it from",
    "start": "776820",
    "end": "779610"
  },
  {
    "text": "your your existing DNS servers every",
    "start": "779610",
    "end": "782790"
  },
  {
    "text": "time you ask",
    "start": "782790",
    "end": "783780"
  },
  {
    "text": "for what the the a record is of that DNS",
    "start": "783780",
    "end": "787860"
  },
  {
    "text": "you'll get one of the servers that are",
    "start": "787860",
    "end": "791250"
  },
  {
    "text": "behind the name and there's a bunch of",
    "start": "791250",
    "end": "796230"
  },
  {
    "text": "logic that you can have console do there",
    "start": "796230",
    "end": "799380"
  },
  {
    "text": "so that it decides which note is",
    "start": "799380",
    "end": "803190"
  },
  {
    "text": "responding the fastest and gives you",
    "start": "803190",
    "end": "805230"
  },
  {
    "text": "that IP or gives you the IP address of",
    "start": "805230",
    "end": "809070"
  },
  {
    "text": "the the node that's closest to you so",
    "start": "809070",
    "end": "812640"
  },
  {
    "text": "it's very valuable it it doesn't do",
    "start": "812640",
    "end": "815850"
  },
  {
    "text": "anything at the the higher networking",
    "start": "815850",
    "end": "817830"
  },
  {
    "text": "layers right it's just giving you an IP",
    "start": "817830",
    "end": "820020"
  },
  {
    "text": "address and that's why it pairs really",
    "start": "820020",
    "end": "823140"
  },
  {
    "text": "well with ingress because ingress can do",
    "start": "823140",
    "end": "826080"
  },
  {
    "text": "that layer seven stuff so if you wanted",
    "start": "826080",
    "end": "828150"
  },
  {
    "text": "to route to service based on the host",
    "start": "828150",
    "end": "831390"
  },
  {
    "text": "header or based on the URI path then",
    "start": "831390",
    "end": "835280"
  },
  {
    "text": "ingress handles that well with each",
    "start": "835280",
    "end": "838350"
  },
  {
    "text": "console service you'd have a unique DNS",
    "start": "838350",
    "end": "840780"
  },
  {
    "text": "name and with ingress you could look at",
    "start": "840780",
    "end": "844680"
  },
  {
    "text": "that name and route it to the to the",
    "start": "844680",
    "end": "846660"
  },
  {
    "text": "correct server in our testing within",
    "start": "846660",
    "end": "849450"
  },
  {
    "text": "graphs we saw two or three millisecond",
    "start": "849450",
    "end": "851670"
  },
  {
    "text": "overhead we use the nginx",
    "start": "851670",
    "end": "854540"
  },
  {
    "text": "load balancing your mileage may vary but",
    "start": "854540",
    "end": "859110"
  },
  {
    "text": "I just want to mention that that we saw",
    "start": "859110",
    "end": "860820"
  },
  {
    "text": "that that seemed like a reasonable",
    "start": "860820",
    "end": "862550"
  },
  {
    "text": "overhead for our micro services calls as",
    "start": "862550",
    "end": "865500"
  },
  {
    "text": "long as they weren't you know linear a",
    "start": "865500",
    "end": "868770"
  },
  {
    "text": "thousand calls it would create two to",
    "start": "868770",
    "end": "870780"
  },
  {
    "text": "three seconds of latency so the the",
    "start": "870780",
    "end": "875940"
  },
  {
    "start": "874000",
    "end": "939000"
  },
  {
    "text": "question came to be is this the perfect",
    "start": "875940",
    "end": "877410"
  },
  {
    "text": "match so we put together a experiment",
    "start": "877410",
    "end": "880200"
  },
  {
    "text": "using the technologies and we leveraged",
    "start": "880200",
    "end": "885600"
  },
  {
    "text": "a similar plugin to what you see in the",
    "start": "885600",
    "end": "887910"
  },
  {
    "text": "community coop the console plug-in that",
    "start": "887910",
    "end": "891540"
  },
  {
    "text": "would take changes to services and nodes",
    "start": "891540",
    "end": "894780"
  },
  {
    "text": "and kubernetes from the watch endpoints",
    "start": "894780",
    "end": "897980"
  },
  {
    "text": "excuse me and translate that late that",
    "start": "897980",
    "end": "902190"
  },
  {
    "text": "into the API calls that you need to add",
    "start": "902190",
    "end": "904620"
  },
  {
    "text": "and remove the the correct nodes and",
    "start": "904620",
    "end": "907740"
  },
  {
    "text": "node ports and console well we ran into",
    "start": "907740",
    "end": "914220"
  },
  {
    "text": "some issues also you have to create the",
    "start": "914220",
    "end": "916589"
  },
  {
    "text": "ingress control",
    "start": "916589",
    "end": "917550"
  },
  {
    "text": "on kubernetes and the ingress resources",
    "start": "917550",
    "end": "920089"
  },
  {
    "text": "themselves in order to make this work",
    "start": "920089",
    "end": "924089"
  },
  {
    "text": "and ingress works the same way actually",
    "start": "924089",
    "end": "925800"
  },
  {
    "text": "right the ingress controller is watching",
    "start": "925800",
    "end": "928290"
  },
  {
    "text": "for the ingress objects in kubernetes",
    "start": "928290",
    "end": "930930"
  },
  {
    "text": "and manipulating the load balancing",
    "start": "930930",
    "end": "935610"
  },
  {
    "text": "rules dynamically okay so we ran some",
    "start": "935610",
    "end": "941610"
  },
  {
    "start": "939000",
    "end": "1106000"
  },
  {
    "text": "problems accessing services across",
    "start": "941610",
    "end": "944850"
  },
  {
    "text": "datacenters was an issue for us because",
    "start": "944850",
    "end": "948019"
  },
  {
    "text": "let's say my services my site console",
    "start": "948019",
    "end": "951540"
  },
  {
    "text": "dot IO well if I'm in a Mia and I'm",
    "start": "951540",
    "end": "955500"
  },
  {
    "text": "looking for my site at console dot IO",
    "start": "955500",
    "end": "957360"
  },
  {
    "text": "it'll give me the local location for",
    "start": "957360",
    "end": "961079"
  },
  {
    "text": "that site if I need to reach out to the",
    "start": "961079",
    "end": "964800"
  },
  {
    "text": "u.s. though there wasn't a way for us to",
    "start": "964800",
    "end": "969029"
  },
  {
    "text": "do that because we hadn't set up",
    "start": "969029",
    "end": "971220"
  },
  {
    "text": "clustering of console between all of our",
    "start": "971220",
    "end": "973680"
  },
  {
    "text": "data centers console supports this where",
    "start": "973680",
    "end": "977220"
  },
  {
    "text": "you could say my site us console dot IO",
    "start": "977220",
    "end": "980790"
  },
  {
    "text": "but we're just not set up for that yet",
    "start": "980790",
    "end": "982380"
  },
  {
    "text": "it wasn't a part of our rollout also",
    "start": "982380",
    "end": "986870"
  },
  {
    "text": "console DNS by default is set up with a",
    "start": "986870",
    "end": "991890"
  },
  {
    "text": "TTL of zero so what that means is every",
    "start": "991890",
    "end": "995790"
  },
  {
    "text": "single DNS query is going to reach out",
    "start": "995790",
    "end": "998430"
  },
  {
    "text": "to the console DNS server also it's",
    "start": "998430",
    "end": "1001910"
  },
  {
    "text": "paxos under the covers and it's going to",
    "start": "1001910",
    "end": "1005990"
  },
  {
    "text": "make sure that it is responding with a",
    "start": "1005990",
    "end": "1009380"
  },
  {
    "text": "valid result by checking with the other",
    "start": "1009380",
    "end": "1012170"
  },
  {
    "text": "nodes in the cluster this takes time so",
    "start": "1012170",
    "end": "1015620"
  },
  {
    "text": "what we saw is on our untuned system was",
    "start": "1015620",
    "end": "1020209"
  },
  {
    "text": "between 150 and 300 milliseconds of",
    "start": "1020209",
    "end": "1022940"
  },
  {
    "text": "latency to do each console query which",
    "start": "1022940",
    "end": "1026928"
  },
  {
    "text": "that would definitely not fly we've got",
    "start": "1026929",
    "end": "1028579"
  },
  {
    "text": "some tuning to do there so that's why we",
    "start": "1028579",
    "end": "1030918"
  },
  {
    "text": "backed off a little bit we haven't quite",
    "start": "1030919",
    "end": "1033110"
  },
  {
    "text": "resolved those issues yet but they are",
    "start": "1033110",
    "end": "1034910"
  },
  {
    "text": "definitely solvable",
    "start": "1034910",
    "end": "1037720"
  },
  {
    "text": "lastly the the coop de console plug-in",
    "start": "1037720",
    "end": "1041390"
  },
  {
    "text": "you can find online in fact I found a",
    "start": "1041390",
    "end": "1044418"
  },
  {
    "text": "bunch of different Forks of it I don't",
    "start": "1044419",
    "end": "1045800"
  },
  {
    "text": "know why there's so many of them there's",
    "start": "1045800",
    "end": "1047120"
  },
  {
    "text": "there's like 10 or 20 of them out there",
    "start": "1047120",
    "end": "1050680"
  },
  {
    "text": "none of them supported console ACLs so",
    "start": "1050680",
    "end": "1054070"
  },
  {
    "text": "we had again needed to make some code",
    "start": "1054070",
    "end": "1057550"
  },
  {
    "text": "changes there in order to support that",
    "start": "1057550",
    "end": "1059140"
  },
  {
    "text": "I'm happy to contribute those back if",
    "start": "1059140",
    "end": "1061480"
  },
  {
    "text": "somebody can tell me what the route",
    "start": "1061480",
    "end": "1063040"
  },
  {
    "text": "Coupe de console project is to",
    "start": "1063040",
    "end": "1065770"
  },
  {
    "text": "contribute them to be happy to do it a",
    "start": "1065770",
    "end": "1070630"
  },
  {
    "text": "side benefit of using console is it",
    "start": "1070630",
    "end": "1074320"
  },
  {
    "text": "stores the SRV record data so not only",
    "start": "1074320",
    "end": "1077560"
  },
  {
    "text": "do you get the dns name but you also get",
    "start": "1077560",
    "end": "1079600"
  },
  {
    "text": "the port the kubernetes node for that",
    "start": "1079600",
    "end": "1083500"
  },
  {
    "text": "the service is running on for each node",
    "start": "1083500",
    "end": "1085800"
  },
  {
    "text": "so if you're using a client library that",
    "start": "1085800",
    "end": "1089200"
  },
  {
    "text": "knows how to read SRV records and get",
    "start": "1089200",
    "end": "1092020"
  },
  {
    "text": "the port you could skip the ingress",
    "start": "1092020",
    "end": "1095080"
  },
  {
    "text": "controller layer completely and hit your",
    "start": "1095080",
    "end": "1098200"
  },
  {
    "text": "service directly which would save you",
    "start": "1098200",
    "end": "1100720"
  },
  {
    "text": "that 2 to 3 milliseconds which might",
    "start": "1100720",
    "end": "1102460"
  },
  {
    "text": "really matter for some workloads ok so",
    "start": "1102460",
    "end": "1107730"
  },
  {
    "start": "1106000",
    "end": "1212000"
  },
  {
    "text": "having hit some stumbling blocks there",
    "start": "1107730",
    "end": "1110560"
  },
  {
    "text": "we decided to go and look at other",
    "start": "1110560",
    "end": "1112810"
  },
  {
    "text": "alternatives like is there some other",
    "start": "1112810",
    "end": "1114880"
  },
  {
    "text": "way to solve this problem",
    "start": "1114880",
    "end": "1116080"
  },
  {
    "text": "and we went back to our load balancing",
    "start": "1116080",
    "end": "1119590"
  },
  {
    "text": "keyer and we said okay why don't we",
    "start": "1119590",
    "end": "1121720"
  },
  {
    "text": "couple what we're doing today with load",
    "start": "1121720",
    "end": "1123820"
  },
  {
    "text": "balancing inside our data center with",
    "start": "1123820",
    "end": "1125830"
  },
  {
    "text": "ingress so what this involves is having",
    "start": "1125830",
    "end": "1130570"
  },
  {
    "text": "a lighter weight version of our plugin",
    "start": "1130570",
    "end": "1132430"
  },
  {
    "text": "so instead of tying services into the",
    "start": "1132430",
    "end": "1136270"
  },
  {
    "text": "load balancer for every service running",
    "start": "1136270",
    "end": "1139510"
  },
  {
    "text": "or third entries into the load balancer",
    "start": "1139510",
    "end": "1141820"
  },
  {
    "text": "for every service running on kubernetes",
    "start": "1141820",
    "end": "1143320"
  },
  {
    "text": "it would just tie in the ingress",
    "start": "1143320",
    "end": "1146260"
  },
  {
    "text": "controller service itself into load",
    "start": "1146260",
    "end": "1148540"
  },
  {
    "text": "balancing so that there's a small number",
    "start": "1148540",
    "end": "1152920"
  },
  {
    "text": "of VIPs on the load balancer that then",
    "start": "1152920",
    "end": "1157930"
  },
  {
    "text": "route directly to ingress and then",
    "start": "1157930",
    "end": "1160540"
  },
  {
    "text": "ingress from there would forward the",
    "start": "1160540",
    "end": "1164010"
  },
  {
    "text": "request to the correct service based on",
    "start": "1164010",
    "end": "1167410"
  },
  {
    "text": "DNS names and we have the capability",
    "start": "1167410",
    "end": "1171520"
  },
  {
    "text": "inside of our data center we have a DNS",
    "start": "1171520",
    "end": "1173770"
  },
  {
    "text": "API so it would just be a matter of",
    "start": "1173770",
    "end": "1177280"
  },
  {
    "text": "creating a cname for each service that",
    "start": "1177280",
    "end": "1180910"
  },
  {
    "text": "would then point to either the",
    "start": "1180910",
    "end": "1183820"
  },
  {
    "text": "main regional load balancer pool or VIP",
    "start": "1183820",
    "end": "1189640"
  },
  {
    "text": "or the individual pool that the service",
    "start": "1189640",
    "end": "1193510"
  },
  {
    "text": "is running on if it's not running across",
    "start": "1193510",
    "end": "1195070"
  },
  {
    "text": "tall clusters and by doing that we would",
    "start": "1195070",
    "end": "1199540"
  },
  {
    "text": "get essentially the same thing we're",
    "start": "1199540",
    "end": "1201310"
  },
  {
    "text": "getting out of console Plus in graphs",
    "start": "1201310",
    "end": "1203860"
  },
  {
    "text": "but just using native DNS and using the",
    "start": "1203860",
    "end": "1209050"
  },
  {
    "text": "native load balancing that we have in",
    "start": "1209050",
    "end": "1210580"
  },
  {
    "text": "our data center another thought that we",
    "start": "1210580",
    "end": "1217720"
  },
  {
    "start": "1212000",
    "end": "1307000"
  },
  {
    "text": "have here and what we're experimenting",
    "start": "1217720",
    "end": "1219760"
  },
  {
    "text": "with is in the cloud environments just",
    "start": "1219760",
    "end": "1222460"
  },
  {
    "text": "leveraging auto scaling auto scaling can",
    "start": "1222460",
    "end": "1224800"
  },
  {
    "text": "already add and remove nodes into load",
    "start": "1224800",
    "end": "1228910"
  },
  {
    "text": "balancers and it can do it so that your",
    "start": "1228910",
    "end": "1232750"
  },
  {
    "text": "nodes can get tied into multiple load",
    "start": "1232750",
    "end": "1235420"
  },
  {
    "text": "balancers as well so why not just",
    "start": "1235420",
    "end": "1238270"
  },
  {
    "text": "leverage what's available already there",
    "start": "1238270",
    "end": "1240340"
  },
  {
    "text": "instead of having any plug-in running on",
    "start": "1240340",
    "end": "1242530"
  },
  {
    "text": "the kubernetes clusters and it's less",
    "start": "1242530",
    "end": "1246340"
  },
  {
    "text": "rust to maintain overall so this would",
    "start": "1246340",
    "end": "1249670"
  },
  {
    "text": "end up making it so from a end end",
    "start": "1249670",
    "end": "1253810"
  },
  {
    "text": "developer team perspective kubernetes is",
    "start": "1253810",
    "end": "1257500"
  },
  {
    "text": "acting the same way inside the cloud as",
    "start": "1257500",
    "end": "1260080"
  },
  {
    "text": "it is inside our data center they just",
    "start": "1260080",
    "end": "1262480"
  },
  {
    "text": "have ingress objects and services and",
    "start": "1262480",
    "end": "1266230"
  },
  {
    "text": "deployments on kubernetes and the cname",
    "start": "1266230",
    "end": "1270910"
  },
  {
    "text": "would then get tied into either the the",
    "start": "1270910",
    "end": "1274300"
  },
  {
    "text": "main load balancer or each individual",
    "start": "1274300",
    "end": "1276610"
  },
  {
    "text": "load balancer depending on what the",
    "start": "1276610",
    "end": "1278230"
  },
  {
    "text": "needs are okay so to make that work",
    "start": "1278230",
    "end": "1283900"
  },
  {
    "text": "though you'd have to have the multiple",
    "start": "1283900",
    "end": "1287560"
  },
  {
    "text": "endpoints one for each cluster and then",
    "start": "1287560",
    "end": "1291100"
  },
  {
    "text": "one for all of the clusters and you'd",
    "start": "1291100",
    "end": "1294850"
  },
  {
    "text": "have to have a way of creating that",
    "start": "1294850",
    "end": "1296080"
  },
  {
    "text": "cname for each service so that ingress",
    "start": "1296080",
    "end": "1300550"
  },
  {
    "text": "can route the traffic and then you'd",
    "start": "1300550",
    "end": "1302620"
  },
  {
    "text": "have to create the ingress objects for",
    "start": "1302620",
    "end": "1304480"
  },
  {
    "text": "every service as well well fortunately",
    "start": "1304480",
    "end": "1308590"
  },
  {
    "start": "1307000",
    "end": "1327000"
  },
  {
    "text": "for us that's pretty easy to do that",
    "start": "1308590",
    "end": "1310450"
  },
  {
    "text": "because we already have an abstraction",
    "start": "1310450",
    "end": "1312190"
  },
  {
    "text": "here so adding in ingress is",
    "start": "1312190",
    "end": "1315460"
  },
  {
    "text": "and a DNS API call to each deployment is",
    "start": "1315460",
    "end": "1319120"
  },
  {
    "text": "just a matter of updating our our",
    "start": "1319120",
    "end": "1320799"
  },
  {
    "text": "skipper tool so it would be clean and",
    "start": "1320799",
    "end": "1324520"
  },
  {
    "text": "straightforward so a little bit more",
    "start": "1324520",
    "end": "1329559"
  },
  {
    "start": "1327000",
    "end": "1520000"
  },
  {
    "text": "about skipper because I not yet",
    "start": "1329559",
    "end": "1333520"
  },
  {
    "text": "open-source skipper itself I'm",
    "start": "1333520",
    "end": "1335500"
  },
  {
    "text": "definitely open to doing so but I would",
    "start": "1335500",
    "end": "1339820"
  },
  {
    "text": "much rather work together with people to",
    "start": "1339820",
    "end": "1343299"
  },
  {
    "text": "rewrite something that makes sense for",
    "start": "1343299",
    "end": "1345370"
  },
  {
    "text": "the whole community if it turns out to",
    "start": "1345370",
    "end": "1348490"
  },
  {
    "text": "be something that would be useful I've",
    "start": "1348490",
    "end": "1350200"
  },
  {
    "text": "heard a few other talks today and",
    "start": "1350200",
    "end": "1352779"
  },
  {
    "text": "yesterday with similar needs that we",
    "start": "1352779",
    "end": "1355840"
  },
  {
    "text": "have so it might make sense for us to do",
    "start": "1355840",
    "end": "1358480"
  },
  {
    "text": "that also I've been making skipper",
    "start": "1358480",
    "end": "1361840"
  },
  {
    "text": "thinner as much as I can so it's a it's",
    "start": "1361840",
    "end": "1364899"
  },
  {
    "text": "less code for us to maintain and it",
    "start": "1364899",
    "end": "1366520"
  },
  {
    "text": "gives value back to the community by",
    "start": "1366520",
    "end": "1368590"
  },
  {
    "text": "contributing the features that we've",
    "start": "1368590",
    "end": "1371440"
  },
  {
    "text": "rolled into this product internally into",
    "start": "1371440",
    "end": "1374250"
  },
  {
    "text": "kubernetes Federation and that's really",
    "start": "1374250",
    "end": "1376990"
  },
  {
    "text": "the direction we want to go a long term",
    "start": "1376990",
    "end": "1378789"
  },
  {
    "text": "is to just leverage Federation",
    "start": "1378789",
    "end": "1382020"
  },
  {
    "text": "everybody knows though that Federation",
    "start": "1382020",
    "end": "1384159"
  },
  {
    "text": "works great on cloud providers right now",
    "start": "1384159",
    "end": "1387880"
  },
  {
    "text": "but but not so much inside your data",
    "start": "1387880",
    "end": "1389470"
  },
  {
    "text": "center so that's what I have I'd be",
    "start": "1389470",
    "end": "1394809"
  },
  {
    "text": "happy to take any questions I'm sorry",
    "start": "1394809",
    "end": "1404700"
  },
  {
    "text": "yeah so the ingress is terminate a cell",
    "start": "1405549",
    "end": "1409460"
  },
  {
    "text": "using certificate and we're needed they",
    "start": "1409460",
    "end": "1413179"
  },
  {
    "text": "can reestablish SSL to the individual",
    "start": "1413179",
    "end": "1415969"
  },
  {
    "text": "pods as well so for us we have",
    "start": "1415969",
    "end": "1424779"
  },
  {
    "text": "individual you know DNS spaces that we",
    "start": "1424779",
    "end": "1428419"
  },
  {
    "text": "own and we're able to wild-card the",
    "start": "1428419",
    "end": "1431090"
  },
  {
    "text": "certificate internally with an internal",
    "start": "1431090",
    "end": "1433519"
  },
  {
    "text": "DNS name at the ingress layer and then",
    "start": "1433519",
    "end": "1436539"
  },
  {
    "text": "use individual certificates from there",
    "start": "1436539",
    "end": "1440019"
  },
  {
    "text": "for our client certificate operation",
    "start": "1440019",
    "end": "1444879"
  },
  {
    "text": "okay yeah I'd be happy to talk after yes",
    "start": "1453940",
    "end": "1463748"
  },
  {
    "text": "okay so the question is who is the",
    "start": "1469779",
    "end": "1472489"
  },
  {
    "text": "consumer for the console DNS in this",
    "start": "1472489",
    "end": "1475119"
  },
  {
    "text": "situation it is not external consumers",
    "start": "1475119",
    "end": "1479749"
  },
  {
    "text": "its internal consumers of the console",
    "start": "1479749",
    "end": "1483200"
  },
  {
    "text": "DNS all of our external calls go through",
    "start": "1483200",
    "end": "1486799"
  },
  {
    "text": "a separate tier of API gateways in our",
    "start": "1486799",
    "end": "1491149"
  },
  {
    "text": "our data centers and then from there it",
    "start": "1491149",
    "end": "1494269"
  },
  {
    "text": "would end up hitting the console DMS",
    "start": "1494269",
    "end": "1497419"
  },
  {
    "text": "yeah great",
    "start": "1497419",
    "end": "1503349"
  },
  {
    "text": "happy to take more questions if they're",
    "start": "1503349",
    "end": "1507469"
  },
  {
    "text": "more",
    "start": "1507469",
    "end": "1509710"
  },
  {
    "text": "all right everybody looking forward",
    "start": "1511910",
    "end": "1516740"
  }
]
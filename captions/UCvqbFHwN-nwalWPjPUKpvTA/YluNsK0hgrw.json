[
  {
    "text": "so let's get started uh it's we're at at time now and hi everyone uh thank you",
    "start": "240",
    "end": "6399"
  },
  {
    "text": "for joining in this afternoon it really is great to see all of you here um again",
    "start": "6399",
    "end": "14320"
  },
  {
    "text": "uh I'll I'll start off with doing some brief introductions uh and uh then we'll",
    "start": "14320",
    "end": "19880"
  },
  {
    "text": "get started we'd really like this session to be interactive and and you know have qu have more of a Time",
    "start": "19880",
    "end": "26960"
  },
  {
    "text": "allocated for questions at the end so so with further Ado uh I'm Alita Sharma I'm",
    "start": "26960",
    "end": "34000"
  },
  {
    "text": "the uh co-chair on the observability tag",
    "start": "34000",
    "end": "39040"
  },
  {
    "text": "and I've been working in the observability space for many years now I contribute to open Telemetry as well as",
    "start": "39040",
    "end": "45520"
  },
  {
    "text": "I'm on the uh governance committee for the project I also uh have been you know",
    "start": "45520",
    "end": "52719"
  },
  {
    "text": "involved working across uh the Prometheus and the open Telemetry project on making sure that that the uh",
    "start": "52719",
    "end": "61160"
  },
  {
    "text": "metric protocol has been fully interoperable and again super happy to",
    "start": "61160",
    "end": "66720"
  },
  {
    "text": "see you know the collaboration we had there uh and I also work in the uh",
    "start": "66720",
    "end": "73040"
  },
  {
    "text": "Thanos cortex um as well as um other Stacks across the uh observability space",
    "start": "73040",
    "end": "82119"
  },
  {
    "text": "so with much further Ado again hand it over to BK and then to VJ to introduce",
    "start": "82119",
    "end": "88200"
  },
  {
    "text": "themselves and then we'll get started thank you amazing so my name is bar poka",
    "start": "88200",
    "end": "93600"
  },
  {
    "text": "um and I'm uh working at Google as a senior software engineer I'm active in cncf as a t Tech lead for this group and",
    "start": "93600",
    "end": "101759"
  },
  {
    "text": "uh um yeah I'm maintaining PR Thanos um many other open source projects and yeah",
    "start": "101759",
    "end": "107960"
  },
  {
    "text": "I think inuse what's relevant we recently are active to make sure it works with open Telemetry very very well",
    "start": "107960",
    "end": "114439"
  },
  {
    "text": "um yeah I also wrote a book efficient go uh it's about golang and optimizations um yeah",
    "start": "114439",
    "end": "121840"
  },
  {
    "text": "uh hello everyone my name is uh Vijay Samuel uh and uh I help lead the query",
    "start": "122000",
    "end": "127119"
  },
  {
    "text": "language standardization uh work group as part of the observ tag um I've I've",
    "start": "127119",
    "end": "132760"
  },
  {
    "text": "been an active participant in the Prometheus and the open Elementary communities as well uh outside of that I",
    "start": "132760",
    "end": "139680"
  },
  {
    "text": "uh help run architecture for the observ platform at",
    "start": "139680",
    "end": "144519"
  },
  {
    "text": "eBay let's go all right so um for today we have again like a few slides few",
    "start": "147080",
    "end": "154080"
  },
  {
    "text": "content Parts prepared but we want to make sure it's interactive at the end so let's go go through them very quickly we",
    "start": "154080",
    "end": "159760"
  },
  {
    "text": "want to talk about definition of this group what we do uh we want to actually show what we do by showing our progress",
    "start": "159760",
    "end": "166200"
  },
  {
    "text": "we want to talk about active work groups um so kind of like dedicated group of people and focus you know meetings and",
    "start": "166200",
    "end": "173280"
  },
  {
    "text": "and work stream uh about certain project to get it done uh we talk about trends that we see uh when we are talking with",
    "start": "173280",
    "end": "179400"
  },
  {
    "text": "end users users and you know vendors and how to get involved so essentially call for action for you to help us uh in this",
    "start": "179400",
    "end": "186519"
  },
  {
    "text": "journey so very quickly what we do that's our Charter um but essentially in a simple world we try to um yeah grow",
    "start": "186519",
    "end": "194760"
  },
  {
    "text": "the ecosystem of uh open source observability we want to identify gaps so think maybe projects that are missing",
    "start": "194760",
    "end": "201200"
  },
  {
    "text": "in this ecosystem maybe uh you know like kind of things we can improve in those projects especially around",
    "start": "201200",
    "end": "206680"
  },
  {
    "text": "interoperability compatibility between each other we want to share good patterns share knowledge about you know",
    "start": "206680",
    "end": "212519"
  },
  {
    "text": "observability in general for both you know new to observability and those who are more advanced um we want to be",
    "start": "212519",
    "end": "219360"
  },
  {
    "text": "ventor neutral so um you know we want to make sure we're you know unbiased here",
    "start": "219360",
    "end": "224640"
  },
  {
    "text": "and we are kind of like making sure you can kind of like no vendor kind of like",
    "start": "224640",
    "end": "230040"
  },
  {
    "text": "steal the whole um the whole ecosystem here in terms of observability so everyone has a first chance uh to move",
    "start": "230040",
    "end": "235879"
  },
  {
    "text": "around with their observability data and finally yeah support projects right we as you know we have multiple",
    "start": "235879",
    "end": "242079"
  },
  {
    "text": "observability projects in the cncf some of them are in sandbox incubated and graduated stage and they uh they just",
    "start": "242079",
    "end": "248640"
  },
  {
    "text": "sometimes ask us for help or especially if they have to move to a different graduation um stage we help them uh to",
    "start": "248640",
    "end": "255840"
  },
  {
    "text": "get there so let's talk about some accomplishments so this year we released",
    "start": "255840",
    "end": "261759"
  },
  {
    "text": "uh observability paper um it's essentially an introduction to observability as we know it in the cncf",
    "start": "261759",
    "end": "268160"
  },
  {
    "text": "uh that's the first one version uh it you know 30 over 30 people help writing",
    "start": "268160",
    "end": "274240"
  },
  {
    "text": "content or reviewing uh so it's it's pretty kind of like elaborative um so",
    "start": "274240",
    "end": "279880"
  },
  {
    "text": "make sure you you go you go there um get this you know read me page and and and work with it there is a lot of actions",
    "start": "279880",
    "end": "287120"
  },
  {
    "text": "there right it's of course not um it has gaps right it has some things we would like to expand more so this is call for",
    "start": "287120",
    "end": "294080"
  },
  {
    "text": "action for you right like essentially we have our GitHub repo just go there check the open issues um and assign yourself",
    "start": "294080",
    "end": "300800"
  },
  {
    "text": "and try to provide a content for us we can review we can expand this and release version two Z this is in",
    "start": "300800",
    "end": "306320"
  },
  {
    "text": "progress uh if you have ideas for uh more content that you you read through the paper and you are missing let us",
    "start": "306320",
    "end": "312840"
  },
  {
    "text": "know we'll just add it there um and and you know maybe we can collaborate together on this so you know everyone",
    "start": "312840",
    "end": "319400"
  },
  {
    "text": "knows more about observability essentially as it evolves second thing we we love",
    "start": "319400",
    "end": "325720"
  },
  {
    "text": "knowledge sharing especially in the video format so in our tag community meeting we sometimes host uh presentations so",
    "start": "325720",
    "end": "333080"
  },
  {
    "text": "feel free to check our YouTube channel where we essentially uh talked about those projects for example in the last",
    "start": "333080",
    "end": "338600"
  },
  {
    "text": "quarter we talked about accessibility optimizing promes open cost open elry uh",
    "start": "338600",
    "end": "344680"
  },
  {
    "text": "GPD and where is the graph of understanding artifact composition so um",
    "start": "344680",
    "end": "350160"
  },
  {
    "text": "lots of nice stuff new to me sometimes as well and um so feel free to join and learn especially feel free to share your",
    "start": "350160",
    "end": "357120"
  },
  {
    "text": "knowledge about you know very wide spectrum of of observability we already have scheduled three more talks uh very",
    "start": "357120",
    "end": "363319"
  },
  {
    "text": "very soon um Native histograms by born and continuous profiling from Fred Eric polar signals and proxy wome by uh",
    "start": "363319",
    "end": "371080"
  },
  {
    "text": "Wesley so really let us know if you want to speak about that we want to host you we want to share your knowledge and you",
    "start": "371080",
    "end": "377280"
  },
  {
    "text": "know our community to ask your ask questions to you as well um later on we",
    "start": "377280",
    "end": "382840"
  },
  {
    "text": "also collaborate with other tags and and and work groups uh recently we kind of",
    "start": "382840",
    "end": "388160"
  },
  {
    "text": "sponsored uh very important Cloud native AI work group of course and um they",
    "start": "388160",
    "end": "393599"
  },
  {
    "text": "actually were super fast to deliver a really really comprehend white paper as well um and this available on the cncf",
    "start": "393599",
    "end": "401000"
  },
  {
    "text": "page um side note we should probably make our white paper available there as well obser B21 um so that's some action",
    "start": "401000",
    "end": "408440"
  },
  {
    "text": "item for me uh from this week uh we should uh also mention that we are kind",
    "start": "408440",
    "end": "413840"
  },
  {
    "text": "of trying to review the projects when that comes to a cncf for example we took",
    "start": "413840",
    "end": "419080"
  },
  {
    "text": "a look on Petry kuber GPD loging operator and um yeah it's amazing to to",
    "start": "419080",
    "end": "424680"
  },
  {
    "text": "see this space grow um and yeah finally work groups I mentioned two work work groups first is observe kues it's",
    "start": "424680",
    "end": "431759"
  },
  {
    "text": "essentially um our um um idea to kind of like make sure make make sure to share",
    "start": "431759",
    "end": "437759"
  },
  {
    "text": "the knowledge in interactive way so we have a paper we have documentation but we would like to also show you uh maybe",
    "start": "437759",
    "end": "444000"
  },
  {
    "text": "a demo maybe a tutorial that spins up multiple let's say the biggest projects observability project projects on the",
    "start": "444000",
    "end": "450120"
  },
  {
    "text": "communities and see how you can um essentially observe some application",
    "start": "450120",
    "end": "455720"
  },
  {
    "text": "which is like online boutique um so thank you uh for you know like so many people were there but definitely shout",
    "start": "455720",
    "end": "462199"
  },
  {
    "text": "out to Ken and uh Henrik right probably more sorry but like so so many people",
    "start": "462199",
    "end": "467479"
  },
  {
    "text": "were um kind of like already doing this and so right now we have a demo um that",
    "start": "467479",
    "end": "472639"
  },
  {
    "text": "you know uses essentially contains you know metric logging traces uh but we want to convert that to tutorial so if",
    "start": "472639",
    "end": "478560"
  },
  {
    "text": "you want to help join this work group and we can kind of build nice tutorial that can be you can reduse as well in",
    "start": "478560",
    "end": "484240"
  },
  {
    "text": "your presentations in you know in in in your internal training so so I think it's a nice uh nice project and VI will",
    "start": "484240",
    "end": "493000"
  },
  {
    "text": "tell you more about exciting stuff on querying thank you Berk uh query",
    "start": "493000",
    "end": "501080"
  },
  {
    "text": "language uh standardization um as everyone is aware with the open Telemetry few years ago when things on",
    "start": "501080",
    "end": "508720"
  },
  {
    "text": "the inj side were extremely fragmented like-minded people came together they",
    "start": "508720",
    "end": "514080"
  },
  {
    "text": "put out a specification and a means for everything to converge to the point where we now have one SDK per language",
    "start": "514080",
    "end": "521880"
  },
  {
    "text": "for all signals and it is basically the defacto standard uh a few months ago",
    "start": "521880",
    "end": "527360"
  },
  {
    "text": "Chris Larson uh from Netflix and uh myself uh we had the conversation with",
    "start": "527360",
    "end": "533040"
  },
  {
    "text": "the tag uh to see how we can do something similar for the query side",
    "start": "533040",
    "end": "538240"
  },
  {
    "text": "because uh the same that was for in just several years ago is still the case on the query side there are so many",
    "start": "538240",
    "end": "544760"
  },
  {
    "text": "languages that are there um different kind of preferences were baked into each of the languages um so we are setting",
    "start": "544760",
    "end": "553120"
  },
  {
    "text": "ourself uh on the journey to figure out what these languages are what was the reason they were built in or designed in",
    "start": "553120",
    "end": "560240"
  },
  {
    "text": "the way that they they were uh what are the commonalities that are there how can we uh suggest something that could be a",
    "start": "560240",
    "end": "567880"
  },
  {
    "text": "standard on the query side as well uh so that uh observability as a practice has",
    "start": "567880",
    "end": "573000"
  },
  {
    "text": "a single way to instrument and a single way to query so that being said uh uh",
    "start": "573000",
    "end": "578480"
  },
  {
    "text": "this past year uh we have actively been um surveying uh several uh open source",
    "start": "578480",
    "end": "585519"
  },
  {
    "text": "projects and uh vendor products on how the languages have been U uh built out",
    "start": "585519",
    "end": "591880"
  },
  {
    "text": "and uh shout out to everyone uh who helped out uh or spent time in coming up",
    "start": "591880",
    "end": "597839"
  },
  {
    "text": "with slides and uh Mee with the working group and explaining um everything about the language and answer all the",
    "start": "597839",
    "end": "603640"
  },
  {
    "text": "questions that we had uh some of them are on the screen we still have uh few",
    "start": "603640",
    "end": "608880"
  },
  {
    "text": "more to go uh if you are a creator of uh an open source project that has its own",
    "start": "608880",
    "end": "614160"
  },
  {
    "text": "query language for observ or if you uh are a vendor uh that has done the same",
    "start": "614160",
    "end": "619560"
  },
  {
    "text": "uh for the products that you own uh please do reach out to us uh we'd be happy to interview and collect uh",
    "start": "619560",
    "end": "626200"
  },
  {
    "text": "valuable feedback that you might have on how your language is came about um The",
    "start": "626200",
    "end": "631440"
  },
  {
    "text": "Next Step that we also want to do is to uh empower the end users uh to tell us",
    "start": "631440",
    "end": "636720"
  },
  {
    "text": "about their observability Journey uh what are the ways in which they query the observability platforms uh that they",
    "start": "636720",
    "end": "642639"
  },
  {
    "text": "are consuming uh right now um what are the pillars that they use how they consume them for the various use cases",
    "start": "642639",
    "end": "649560"
  },
  {
    "text": "so that we can identify uh patterns on okay these are things that are very important to end users these are things",
    "start": "649560",
    "end": "655600"
  },
  {
    "text": "that are not available but they really care about uh things like that uh so that we can finally go about describing",
    "start": "655600",
    "end": "662680"
  },
  {
    "text": "um that ideal language that uh U that we could potentially propose um we welcome",
    "start": "662680",
    "end": "668000"
  },
  {
    "text": "contributions um both on the uh on the Creator side and on the end user side",
    "start": "668000",
    "end": "673519"
  },
  {
    "text": "you can find us at the slack channel uh that's mentioned on the slides and we meet the second and fourth Tuesdays uh",
    "start": "673519",
    "end": "680519"
  },
  {
    "text": "9:00 a.m. PST thank you um yeah off",
    "start": "680519",
    "end": "687480"
  },
  {
    "text": "to Okay so so um today another topic that we want to cover you know know all",
    "start": "687720",
    "end": "694600"
  },
  {
    "text": "about our work groups uh but you know this has been an area which has uh kind",
    "start": "694600",
    "end": "699839"
  },
  {
    "text": "of picked up steam amazingly fast in the few last few last year I would say and",
    "start": "699839",
    "end": "707079"
  },
  {
    "text": "and uh it really is you know how leveraging understanding observability",
    "start": "707079",
    "end": "712160"
  },
  {
    "text": "for llms uh as well as uh understanding how to use llms for observability",
    "start": "712160",
    "end": "719880"
  },
  {
    "text": "so in in this diagram as you see uh in the case of",
    "start": "719880",
    "end": "725160"
  },
  {
    "text": "llms which are again uh you can use for",
    "start": "725160",
    "end": "730560"
  },
  {
    "text": "observability to act predict suggest assist you know with the help of an llm",
    "start": "730560",
    "end": "736199"
  },
  {
    "text": "in observability similarly uh llms can be observed monitored and analyzed uh",
    "start": "736199",
    "end": "744519"
  },
  {
    "text": "with the observability Frameworks you know that that they look at right so uh",
    "start": "744519",
    "end": "750160"
  },
  {
    "text": "that they used with so again it means different things to different people you",
    "start": "750160",
    "end": "755760"
  },
  {
    "text": "know from an observability perspective llms um can help a lot with uh root",
    "start": "755760",
    "end": "762680"
  },
  {
    "text": "cause analysis and I think we have the next slide here um where we can we can",
    "start": "762680",
    "end": "770120"
  },
  {
    "text": "actually talk a little bit about the layers but uh oops J forward oops oop",
    "start": "770120",
    "end": "777279"
  },
  {
    "text": "oops okay click",
    "start": "777279",
    "end": "781800"
  },
  {
    "text": "it try it nice okay thank you try it once",
    "start": "782519",
    "end": "789800"
  },
  {
    "text": "more just click it fast enough okay so going back to the first slide again I",
    "start": "790000",
    "end": "795519"
  },
  {
    "text": "just wanted to complete my thought there that llms in observability are typically",
    "start": "795519",
    "end": "800920"
  },
  {
    "text": "used for root cause triaging today in in systems produ you know where where you",
    "start": "800920",
    "end": "806279"
  },
  {
    "text": "have deployed applications in production and you also use it for analysis because",
    "start": "806279",
    "end": "812360"
  },
  {
    "text": "it has already come into the you know uh mlops pipelines where operations does",
    "start": "812360",
    "end": "818959"
  },
  {
    "text": "look at you know use llms now for being able to real time you know coals all the",
    "start": "818959",
    "end": "826560"
  },
  {
    "text": "uh alerts and the data that you know Telemetry data that is being generated",
    "start": "826560",
    "end": "832480"
  },
  {
    "text": "by and uh similarly uh llm assistants",
    "start": "832480",
    "end": "837839"
  },
  {
    "text": "based assistance like like you know chat Bots are being used for uh querying this",
    "start": "837839",
    "end": "845279"
  },
  {
    "text": "data right so if you are getting if you're running an um uh you know",
    "start": "845279",
    "end": "850839"
  },
  {
    "text": "application globally where you're running it in six regions and you're getting data Telemetry data from all",
    "start": "850839",
    "end": "857800"
  },
  {
    "text": "those six regions typically an llm is used nowadays to be able to consume that",
    "start": "857800",
    "end": "864240"
  },
  {
    "text": "data you know in terms of the Telemetry coming in and being able to query that",
    "start": "864240",
    "end": "869480"
  },
  {
    "text": "for triaging and Analysis so you know that's a very basic case of how llms are",
    "start": "869480",
    "end": "875440"
  },
  {
    "text": "used but it it still is something that has rolled in into Ops today right and",
    "start": "875440",
    "end": "881600"
  },
  {
    "text": "this is not even without adding observability Frameworks to use llms",
    "start": "881600",
    "end": "889360"
  },
  {
    "text": "actively and directly so um uh that's something that again uh also leads to",
    "start": "889360",
    "end": "896480"
  },
  {
    "text": "the you know opportunity here to be able to actually adapt existing open-source",
    "start": "896480",
    "end": "904040"
  },
  {
    "text": "collection Frameworks such as open Telemetry or any other Prometheus agent",
    "start": "904040",
    "end": "909839"
  },
  {
    "text": "and other uh you know agent components in open source that exist in the cncf",
    "start": "909839",
    "end": "916079"
  },
  {
    "text": "environment or otherwise to be able to leverage llms for exactly you know",
    "start": "916079",
    "end": "922120"
  },
  {
    "text": "consuming Telemetry data understanding it pre- agrega and being able to",
    "start": "922120",
    "end": "927199"
  },
  {
    "text": "actually provide uh standardized signal anal analysis as a result so moving on",
    "start": "927199",
    "end": "934319"
  },
  {
    "text": "again um llms are also a new type of asset or workload if you will that we we",
    "start": "934319",
    "end": "942480"
  },
  {
    "text": "need to observe and I had you know we were talking about uh AI uh enabled",
    "start": "942480",
    "end": "948120"
  },
  {
    "text": "applications in a previous talk I had where you have different models that are",
    "start": "948120",
    "end": "954000"
  },
  {
    "text": "being introduced weekly some of them and most of them are black box today right",
    "start": "954000",
    "end": "959120"
  },
  {
    "text": "the blackbox observability the blackbox even to the application sometimes but no",
    "start": "959120",
    "end": "964360"
  },
  {
    "text": "there are also models where the entire you know weights as well as other",
    "start": "964360",
    "end": "971519"
  },
  {
    "text": "parameters for the model are all defined they are actually published and you do",
    "start": "971519",
    "end": "976839"
  },
  {
    "text": "have some metrics that are you know being um uh released or available from",
    "start": "976839",
    "end": "983519"
  },
  {
    "text": "each layer so in these layers again as applications we come are built with llms",
    "start": "983519",
    "end": "989680"
  },
  {
    "text": "the need for observing these llms also becomes part of understanding their",
    "start": "989680",
    "end": "995440"
  },
  {
    "text": "behavior and applications you know which included code and models traditionally",
    "start": "995440",
    "end": "1002480"
  },
  {
    "text": "now also includes small models or large llms right and and and also that again",
    "start": "1002480",
    "end": "1012600"
  },
  {
    "text": "leads back to the idea that for observability you are also looking at",
    "start": "1012600",
    "end": "1018519"
  },
  {
    "text": "new types of Hardware which is used for AI applications such as gpus accelerat",
    "start": "1018519",
    "end": "1024880"
  },
  {
    "text": "CPUs and other kinds of specialized uh you know uh chipsets and also model",
    "start": "1024880",
    "end": "1032480"
  },
  {
    "text": "inferencing and training pipelines so these are new assets that are coming into place but also observ on the",
    "start": "1032480",
    "end": "1040160"
  },
  {
    "text": "observability side that framework of instrumentation as well as analysis",
    "start": "1040160",
    "end": "1046038"
  },
  {
    "text": "needs to be built out in the existing applicate you know observability",
    "start": "1046039",
    "end": "1051200"
  },
  {
    "text": "projects that exist today which are very widely used across the industry so",
    "start": "1051200",
    "end": "1056640"
  },
  {
    "text": "moving on again um some of the areas that are already being used are using",
    "start": "1056640",
    "end": "1064080"
  },
  {
    "text": "llm based data are anomaly detection um ped analysis uh distributed tracing",
    "start": "1064080",
    "end": "1072520"
  },
  {
    "text": "comprehension where you need to understand you know the the uh if you",
    "start": "1072520",
    "end": "1077600"
  },
  {
    "text": "have uh hundreds of spans in a particular transaction for example you",
    "start": "1077600",
    "end": "1083360"
  },
  {
    "text": "know what is the general Behavior going to look like as well as data quality",
    "start": "1083360",
    "end": "1088559"
  },
  {
    "text": "root cause analysis and you know also suggestions for other steps so B do you",
    "start": "1088559",
    "end": "1094120"
  },
  {
    "text": "want to talk a little bit here about you know rags and why Rags are not uh enough",
    "start": "1094120",
    "end": "1099440"
  },
  {
    "text": "don't quote me there but essentially I saw um well like um I guess uh yeah like",
    "start": "1099440",
    "end": "1106120"
  },
  {
    "text": "generally like the community around M especially around observability or making decisions on top of like some",
    "start": "1106120",
    "end": "1112799"
  },
  {
    "text": "data that you have available are complaining on raack which is essentially using Vector databases right",
    "start": "1112799",
    "end": "1118799"
  },
  {
    "text": "and essentially my point is that if you want to innovate if you want to uh kind of like um know what's next is that we",
    "start": "1118799",
    "end": "1126240"
  },
  {
    "text": "need better kind of ways of uh making sure that our LM has context of your life deployments because right now the",
    "start": "1126240",
    "end": "1133080"
  },
  {
    "text": "current Solutions are essentially asking chpt or jini right to um to just um make",
    "start": "1133080",
    "end": "1139120"
  },
  {
    "text": "some decision or kind of suggest somec decision based on like limited context of like you know maybe thousand tokens",
    "start": "1139120",
    "end": "1145840"
  },
  {
    "text": "or 10,000 tokens which you can paste maybe you know I don't know hundred of yamal of your deployments right but you",
    "start": "1145840",
    "end": "1152640"
  },
  {
    "text": "Lally cannot model your whole architecture um yet right so and and you",
    "start": "1152640",
    "end": "1158200"
  },
  {
    "text": "know rack is essentially a way to kind of like maybe get this um data up front uh to the llm but it's still not enough",
    "start": "1158200",
    "end": "1165039"
  },
  {
    "text": "so my point is like we are still looking for ways to kind of like make it better so please innovate please like it's not",
    "start": "1165039",
    "end": "1171440"
  },
  {
    "text": "like somebody do it for you there is lots of room we can improve but yeah essentially uh this is what we are",
    "start": "1171440",
    "end": "1176799"
  },
  {
    "text": "looking for uh in the future of yeah embedding llm with observability data",
    "start": "1176799",
    "end": "1182080"
  },
  {
    "text": "good so uh I think you know again needless to say the reason why we highlighted this space is because it's",
    "start": "1182080",
    "end": "1189200"
  },
  {
    "text": "evolving very fast and whether that's on the tool chains that exist today or",
    "start": "1189200",
    "end": "1196120"
  },
  {
    "text": "whether there'll be new tool chains that are coming in you know which are added for specifically you know understanding",
    "start": "1196120",
    "end": "1203960"
  },
  {
    "text": "llms and being able to actually monitor analyze and visualize and correlate all",
    "start": "1203960",
    "end": "1211120"
  },
  {
    "text": "across the board with other uh you know layers of the system to be able to get a",
    "start": "1211120",
    "end": "1217039"
  },
  {
    "text": "more holistic understanding that you usually you know want to have from",
    "start": "1217039",
    "end": "1223039"
  },
  {
    "text": "observability there is a fair bit of work to be done there right and that's the opportunity where if you're an",
    "start": "1223039",
    "end": "1229240"
  },
  {
    "text": "observability engineer or an ml engineer you really can get involved in actually",
    "start": "1229240",
    "end": "1234600"
  },
  {
    "text": "building out some of these features on existing projects or maybe even you know",
    "start": "1234600",
    "end": "1239960"
  },
  {
    "text": "starting a new project where you actually specialize on a certain set of",
    "start": "1239960",
    "end": "1245080"
  },
  {
    "text": "models that you know you're looking at or you understand well and to be able to build the",
    "start": "1245080",
    "end": "1250919"
  },
  {
    "text": "observability instrumentation for it so moving on again um there's an uh",
    "start": "1250919",
    "end": "1259000"
  },
  {
    "text": "we usually do this every year and these are some of the trends that you know we see across the observability space um at",
    "start": "1259000",
    "end": "1268280"
  },
  {
    "text": "this given point in time and uh again across the industry whether we are using",
    "start": "1268280",
    "end": "1274919"
  },
  {
    "text": "llms or not in our applications cost continues to be a very very pervasive",
    "start": "1274919",
    "end": "1282320"
  },
  {
    "text": "theme where uh understanding cost and performance re uh and of resources is",
    "start": "1282320",
    "end": "1290880"
  },
  {
    "text": "super important because when you know organizations are running large scale",
    "start": "1290880",
    "end": "1296760"
  },
  {
    "text": "systems large scale applications on cloud infrastructure that the cost",
    "start": "1296760",
    "end": "1304840"
  },
  {
    "text": "optimization is is essential as an essential part of observability and observability platform",
    "start": "1304840",
    "end": "1313320"
  },
  {
    "text": "costs from pre-aggregation and sampling that is data costs in itself itself is",
    "start": "1313320",
    "end": "1319320"
  },
  {
    "text": "an area where there are continuous improvements in terms of what does pre- agregation do for you right can you",
    "start": "1319320",
    "end": "1326320"
  },
  {
    "text": "reduce the cardinality of the data you're setting over the wire because it",
    "start": "1326320",
    "end": "1331679"
  },
  {
    "text": "costs money right at the end of the day and and do you turn on tracing you know",
    "start": "1331679",
    "end": "1338159"
  },
  {
    "text": "for uh 30 seconds uh in order to get 100% traces or you know do you do it for",
    "start": "1338159",
    "end": "1345279"
  },
  {
    "text": "a minute it costs money and and so this is a very pervasive theme in the",
    "start": "1345279",
    "end": "1351760"
  },
  {
    "text": "industry in terms of continuing to optimize and there's a couple of open-",
    "start": "1351760",
    "end": "1357080"
  },
  {
    "text": "source projects within the observability domain in uh the cncf itself Cube cost",
    "start": "1357080",
    "end": "1362960"
  },
  {
    "text": "and open cost open cost Cube cost is based on open cost uh and and these have",
    "start": "1362960",
    "end": "1368880"
  },
  {
    "text": "been you know used as just a foundational um projects if you will or",
    "start": "1368880",
    "end": "1374919"
  },
  {
    "text": "foundational components to be able to track cost right but as you now enter also uh the world",
    "start": "1374919",
    "end": "1382360"
  },
  {
    "text": "of smart applications you know that Dimension changes because how do you",
    "start": "1382360",
    "end": "1387400"
  },
  {
    "text": "measure costs for models right and is that something that",
    "start": "1387400",
    "end": "1393000"
  },
  {
    "text": "has already been defined so these are areas which are evolving which you know you uh uh there's a fair bit of work",
    "start": "1393000",
    "end": "1399679"
  },
  {
    "text": "that is being done by Hardware vendors to be able to you know provide some data",
    "start": "1399679",
    "end": "1405559"
  },
  {
    "text": "for the resource utilization you're doing but it's not adequate because you",
    "start": "1405559",
    "end": "1410919"
  },
  {
    "text": "know there are lots of other moving Parts in the data that is being generated you know for your Telemetry of",
    "start": "1410919",
    "end": "1418200"
  },
  {
    "text": "your applications which also costs money when you're shipping it over the wire or",
    "start": "1418200",
    "end": "1423240"
  },
  {
    "text": "whether you're storing it how long you're storing it for and you know do you actually look at it uh you know",
    "start": "1423240",
    "end": "1430559"
  },
  {
    "text": "seven days after you don't need it anymore right so these are many considerations that you need to keep in",
    "start": "1430559",
    "end": "1437440"
  },
  {
    "text": "mind and there's a fair bit of work happening in the industry both from end users as well as from open-source uh",
    "start": "1437440",
    "end": "1445320"
  },
  {
    "text": "Engineers on the projects where some of this is being thought about the other",
    "start": "1445320",
    "end": "1450760"
  },
  {
    "text": "part is uh very you know there's a fair bit of work happening is end observability where you have um you know",
    "start": "1450760",
    "end": "1459120"
  },
  {
    "text": "this is not a solved problem yet although you know many many uh uh",
    "start": "1459120",
    "end": "1464720"
  },
  {
    "text": "pipelines have been proposed and uh many reference architectures exist but you",
    "start": "1464720",
    "end": "1471720"
  },
  {
    "text": "still cannot say Hey you know I'm going to just turn this this this on and everything will work end to endend in",
    "start": "1471720",
    "end": "1478320"
  },
  {
    "text": "terms of being able to see my Edge networks my Edge devices app client",
    "start": "1478320",
    "end": "1484760"
  },
  {
    "text": "applications service side applications infrastructure models as well as any any",
    "start": "1484760",
    "end": "1491600"
  },
  {
    "text": "other data that you want to see it's not it's not there still even after you know",
    "start": "1491600",
    "end": "1497120"
  },
  {
    "text": "all the work that we've all done whether that's in open Telemetry or whether that's in Prometheus or whether that is",
    "start": "1497120",
    "end": "1503640"
  },
  {
    "text": "in uh tracing or logging right so this is also another",
    "start": "1503640",
    "end": "1510799"
  },
  {
    "text": "opportunity there there's a lot of work that is you know ongoing but again our world also becomes more complex as we",
    "start": "1510799",
    "end": "1518679"
  },
  {
    "text": "introduce a new generation of applications coming in smart",
    "start": "1518679",
    "end": "1524520"
  },
  {
    "text": "applications uh open Telemetry is moving Us in the right right direction because",
    "start": "1524520",
    "end": "1529559"
  },
  {
    "text": "as you can see uh uh initially the project started with you know uh",
    "start": "1529559",
    "end": "1536360"
  },
  {
    "text": "converging inje in under you know of the different Telemetry s data under one",
    "start": "1536360",
    "end": "1543640"
  },
  {
    "text": "umbrella and uh initially it came and started with tracing uh then metric",
    "start": "1543640",
    "end": "1550200"
  },
  {
    "text": "logging and today profiling has also become the fourth signal on the project",
    "start": "1550200",
    "end": "1556360"
  },
  {
    "text": "for ingestion right so you continue to see that convergence happening in the",
    "start": "1556360",
    "end": "1561880"
  },
  {
    "text": "ingestion space now why is profiling important because believe it or not in",
    "start": "1561880",
    "end": "1567360"
  },
  {
    "text": "the world of understanding performance and resource utilization for",
    "start": "1567360",
    "end": "1572679"
  },
  {
    "text": "models again profiling is used fabit for being able to understand those layers",
    "start": "1572679",
    "end": "1579480"
  },
  {
    "text": "and what you know the uh latency is and performance is for each of those layers",
    "start": "1579480",
    "end": "1586880"
  },
  {
    "text": "when they are in a mod when they're being used for uh training or for inference pipelines right so again uh",
    "start": "1586880",
    "end": "1595360"
  },
  {
    "text": "it's an interesting time in history where you're also seeing that convergence happening but existing",
    "start": "1595360",
    "end": "1601240"
  },
  {
    "text": "Telemetry type signals being used for you know that um for for these uh",
    "start": "1601240",
    "end": "1608080"
  },
  {
    "text": "observing these new assets if you will and last but not least uh just wanted to",
    "start": "1608080",
    "end": "1613799"
  },
  {
    "text": "call out that multi- tency is also another area where there's a significant",
    "start": "1613799",
    "end": "1620039"
  },
  {
    "text": "amount of work that's you know ongoing uh and what that what does that mean is",
    "start": "1620039",
    "end": "1625880"
  },
  {
    "text": "that you know for large scale systems which You're Building you would like to",
    "start": "1625880",
    "end": "1630960"
  },
  {
    "text": "have multiple customers leveraging the same common",
    "start": "1630960",
    "end": "1636399"
  },
  {
    "text": "infrastructure from a cost perspective and hence multi- tendency even on in the",
    "start": "1636399",
    "end": "1643279"
  },
  {
    "text": "observability data space becomes a thing because you do want to be able to access",
    "start": "1643279",
    "end": "1650640"
  },
  {
    "text": "you know data and correlate across multiple tenants which may be different",
    "start": "1650640",
    "end": "1655919"
  },
  {
    "text": "name spaces that are belonging to a single customer right and a single",
    "start": "1655919",
    "end": "1661880"
  },
  {
    "text": "customer could be uh for example your Finance you know organization running 20",
    "start": "1661880",
    "end": "1669440"
  },
  {
    "text": "applications where they're sending Telemetry for 20 applications into 20 TS",
    "start": "1669440",
    "end": "1675640"
  },
  {
    "text": "right and they want to be able to correlate their observability data and be able to see hey you know this is the",
    "start": "1675640",
    "end": "1683039"
  },
  {
    "text": "behavior of our systems at any given point in time so multi-tenancy is",
    "start": "1683039",
    "end": "1688640"
  },
  {
    "text": "actually becoming very important in the uh in the scale of you know the type of",
    "start": "1688640",
    "end": "1696440"
  },
  {
    "text": "applications as well as the cardinality of data that is being generated by",
    "start": "1696440",
    "end": "1703480"
  },
  {
    "text": "systems so with that said again I think um I'll over to B do you want to kind of",
    "start": "1703480",
    "end": "1711480"
  },
  {
    "text": "not why not I would love to all right so last slide um how you can get involved right make sure to participate in our",
    "start": "1711480",
    "end": "1718279"
  },
  {
    "text": "discussions um you can do that by um yeah joining our calls uh which we have",
    "start": "1718279",
    "end": "1723679"
  },
  {
    "text": "two per month um make sure to just add a topic to the agenda maybe go to our",
    "start": "1723679",
    "end": "1729159"
  },
  {
    "text": "slack Channel and let us know what you would like to chat and maybe how to form this but feel free to ask about anything",
    "start": "1729159",
    "end": "1735519"
  },
  {
    "text": "we have people essentially new to the community ask asking maybe questions that are kind of related to maybe promus",
    "start": "1735519",
    "end": "1741360"
  },
  {
    "text": "project and op Telemetry and and tanos and any other project and they kind of don't know where to start feel free to",
    "start": "1741360",
    "end": "1746679"
  },
  {
    "text": "ask them there like it's fine we direct you to the correct people and this is super important don't be shy uh we are",
    "start": "1746679",
    "end": "1752320"
  },
  {
    "text": "we are here for you uh you can use our mailing list but but I think slack is really good enough um and yeah really",
    "start": "1752320",
    "end": "1758159"
  },
  {
    "text": "share your insights and present the topic about May the project you know about maybe problems you have about you",
    "start": "1758159",
    "end": "1763919"
  },
  {
    "text": "know how you even if you didn't solve it yet you know what incidents you have you would like to have you in so please join",
    "start": "1763919",
    "end": "1769559"
  },
  {
    "text": "us and thank you for coming [Laughter]",
    "start": "1769559",
    "end": "1777519"
  },
  {
    "text": "today if no one stops us maybe you can ask some questions let me grab",
    "start": "1777519",
    "end": "1783440"
  },
  {
    "text": "microphone anyone any questions yes hi thank you for the talk um I'm not",
    "start": "1795919",
    "end": "1805519"
  },
  {
    "text": "familiar with the lrm uh things so we talk we you talk about the model LM for",
    "start": "1805519",
    "end": "1812600"
  },
  {
    "text": "the observability so where we can find S type thing where you can find the the",
    "start": "1812600",
    "end": "1818960"
  },
  {
    "text": "the model something available for I don't know to test on our data or you",
    "start": "1818960",
    "end": "1824919"
  },
  {
    "text": "have to buy a vendor so I think I think um uh it's a good question because you know where do",
    "start": "1824919",
    "end": "1831440"
  },
  {
    "text": "I find an model that I could use for observability data right even if it were",
    "start": "1831440",
    "end": "1837200"
  },
  {
    "text": "out of the box there are several uh simple models that are available which",
    "start": "1837200",
    "end": "1842480"
  },
  {
    "text": "are open source uh and they can be used um you can even use the existing chat",
    "start": "1842480",
    "end": "1849240"
  },
  {
    "text": "GPT or gemini or other uh you know uh",
    "start": "1849240",
    "end": "1854399"
  },
  {
    "text": "Services out of the box but uh typically you know you can just actually conf",
    "start": "1854399",
    "end": "1860240"
  },
  {
    "text": "configure that um in terms of being able to download models I think uh the",
    "start": "1860240",
    "end": "1867320"
  },
  {
    "text": "references we could give are probably your hugging face models the tensorflow models your pyos models which are",
    "start": "1867320",
    "end": "1875360"
  },
  {
    "text": "actually available uh it depends on the number of parameters that you are you",
    "start": "1875360",
    "end": "1880480"
  },
  {
    "text": "know interested in and where you're running these models because again size",
    "start": "1880480",
    "end": "1886799"
  },
  {
    "text": "uh is uh you know proportionally larger if you have large models right large",
    "start": "1886799",
    "end": "1893039"
  },
  {
    "text": "llms so um definitely you know these are some the uh projects where you can",
    "start": "1893039",
    "end": "1899799"
  },
  {
    "text": "actually download the models and run them amazing any other",
    "start": "1899799",
    "end": "1906840"
  },
  {
    "text": "question hi yeah thank you for the talk it was very very good um I like the llm",
    "start": "1907440",
    "end": "1912639"
  },
  {
    "text": "part as well even though that's not something that's being utilized that by us at this point I think we are still",
    "start": "1912639",
    "end": "1919600"
  },
  {
    "text": "kind of at the point where um I think we have a challenge of balancing resource",
    "start": "1919600",
    "end": "1925000"
  },
  {
    "text": "consumption and allocation versus granularity of the data that you get out of it right like you know it um you",
    "start": "1925000",
    "end": "1932480"
  },
  {
    "text": "increase your cardinality you increase the amount of series and the resource usage particularly memory explodes in uh",
    "start": "1932480",
    "end": "1939679"
  },
  {
    "text": "Prometheus and in Thanos do you have any guidelines on how to deal with that problem how to find the right",
    "start": "1939679",
    "end": "1946120"
  },
  {
    "text": "balance Mar did you want to answer that for I think it's a it's a good question",
    "start": "1946120",
    "end": "1951600"
  },
  {
    "text": "I think you should be able we should have a solution where you specify I want to use only you know let's say two",
    "start": "1951600",
    "end": "1956840"
  },
  {
    "text": "terabytes of memory on my cluster and nothing more and essentially uh you know let's do as maximum as as as possible",
    "start": "1956840",
    "end": "1963600"
  },
  {
    "text": "within now it's bit more manual um so but I really encourage you to kind of",
    "start": "1963600",
    "end": "1968679"
  },
  {
    "text": "like make it data driven so essentially um essentially you know kind of measure",
    "start": "1968679",
    "end": "1973799"
  },
  {
    "text": "Benchmark and when put on production some portion of observability slowly increasing right um agree on certain",
    "start": "1973799",
    "end": "1980120"
  },
  {
    "text": "cardinality of the metrics agree on certain volume of logs and traces um see",
    "start": "1980120",
    "end": "1985840"
  },
  {
    "text": "you know to the point where it's kind of minimally minimally useful uh measure the cost of it and let's see and start",
    "start": "1985840",
    "end": "1991960"
  },
  {
    "text": "from there and you know if it's too expensive for you you have to essentially uh reduce some of it uh",
    "start": "1991960",
    "end": "1998880"
  },
  {
    "text": "maybe focus on metrics more and less on logs maybe opposite maybe actually reduce cality of metrics and use logs",
    "start": "1998880",
    "end": "2005559"
  },
  {
    "text": "more um but um yeah this is what I would what I would kind of like um recommend I",
    "start": "2005559",
    "end": "2011600"
  },
  {
    "text": "wish there was more automatic solution that will help you analyze all of this it's a good idea um you need this you",
    "start": "2011600",
    "end": "2020399"
  },
  {
    "text": "need that one one other thing that you can probably do is like analyze your uh query logs to see if the labels that",
    "start": "2020399",
    "end": "2029000"
  },
  {
    "text": "have high cardinality or things that you're actually querying if not um some of the projects have ways to do",
    "start": "2029000",
    "end": "2036440"
  },
  {
    "text": "pre-aggregation or you can use the open tary collector to do aggregations as",
    "start": "2036440",
    "end": "2041480"
  },
  {
    "text": "well so that before it hits the tsdb you can um pre-aggregate and store which is",
    "start": "2041480",
    "end": "2046799"
  },
  {
    "text": "a lot cheaper yeah I mean we defin again in in several of the solutions you know",
    "start": "2046799",
    "end": "2053398"
  },
  {
    "text": "we definitely uh preaggregate a lot and and we are very conscious of uh again",
    "start": "2053399",
    "end": "2061919"
  },
  {
    "text": "capacity sizing ahead of time uh where you are actually very much much uh",
    "start": "2061919",
    "end": "2068720"
  },
  {
    "text": "sizing storage um as well as data traffic right",
    "start": "2068720",
    "end": "2074720"
  },
  {
    "text": "so uh kind of going in with some uh initial parameters you know for these",
    "start": "2074720",
    "end": "2081079"
  },
  {
    "text": "numbers is always good but uh also the percentage of you know uh traffic that",
    "start": "2081079",
    "end": "2088440"
  },
  {
    "text": "you're are sending or data you're sending uh is always proportional to the kind amount of aggregation you're doing",
    "start": "2088440",
    "end": "2095919"
  },
  {
    "text": "so you can do multi-level aggregation depending on the type of metric or depending on of on the time",
    "start": "2095919",
    "end": "2104880"
  },
  {
    "text": "period right uh thanks for the talk and it's",
    "start": "2104880",
    "end": "2111400"
  },
  {
    "text": "nice to see the tag is progressing uh in in a year a lot of things uh has",
    "start": "2111400",
    "end": "2119320"
  },
  {
    "text": "progressed I uh about the first question part actually uh we already have an open",
    "start": "2119320",
    "end": "2126280"
  },
  {
    "text": "Telemetry demo in open tet repository and another one",
    "start": "2126280",
    "end": "2131680"
  },
  {
    "text": "here but a start point for llms a demo",
    "start": "2131680",
    "end": "2136880"
  },
  {
    "text": "application would be great actually uh where we can uh each of us yeah yeah",
    "start": "2136880",
    "end": "2144400"
  },
  {
    "text": "actually uh we were discussing this on the open Telemetry demo and and we do plan to use you know kind of introduce a",
    "start": "2144400",
    "end": "2152400"
  },
  {
    "text": "workflow for being able to actually do a simple model and uh being able to trace",
    "start": "2152400",
    "end": "2159000"
  },
  {
    "text": "it or uh being able to you know instrument it and then publish some",
    "start": "2159000",
    "end": "2165720"
  },
  {
    "text": "metrics right it would be still a playground app but still nonetheless you",
    "start": "2165720",
    "end": "2171319"
  },
  {
    "text": "know H does provide you insight into how you would do the instrumentation what",
    "start": "2171319",
    "end": "2176800"
  },
  {
    "text": "kind of metrics are you you know looking at for the models and also uh what",
    "start": "2176800",
    "end": "2183520"
  },
  {
    "text": "translates into slas and slos for for applic for uh model",
    "start": "2183520",
    "end": "2190800"
  },
  {
    "text": "performance because that's another new area that's emerging out of that that's great news and the second part uh I have",
    "start": "2190800",
    "end": "2198480"
  },
  {
    "text": "heard a lot of cost uh word uh throughout the conference but uh maybe",
    "start": "2198480",
    "end": "2205440"
  },
  {
    "text": "an energy consumption uh can be also as",
    "start": "2205440",
    "end": "2211200"
  },
  {
    "text": "fres or uh kitchen equipment we have those labels that might be nice looking",
    "start": "2211200",
    "end": "2218560"
  },
  {
    "text": "at from energy perspective yeah in fact uh in fact there's been a conversation",
    "start": "2218560",
    "end": "2224000"
  },
  {
    "text": "about the tag sustainability um uh working with the tag observability tag to be able to",
    "start": "2224000",
    "end": "2231560"
  },
  {
    "text": "define a new sustainability taxonomy of labels so that that actually could be",
    "start": "2231560",
    "end": "2237720"
  },
  {
    "text": "used as a standardized set to begin with for you know energy uh uh and",
    "start": "2237720",
    "end": "2244480"
  },
  {
    "text": "performance uh obs observability yeah great presentations I love the end",
    "start": "2244480",
    "end": "2251200"
  },
  {
    "text": "user surveys so keep up with those I would really like to see more of those um coming from the public sector uh we",
    "start": "2251200",
    "end": "2259000"
  },
  {
    "text": "would really like to sort of participate more with our experience and um",
    "start": "2259000",
    "end": "2264119"
  },
  {
    "text": "documentation is really uh top concern missing documentation and Scattered on",
    "start": "2264119",
    "end": "2270720"
  },
  {
    "text": "on specific projects or um open Telemetry in general uh it's uh sort of",
    "start": "2270720",
    "end": "2277040"
  },
  {
    "text": "very is it on the website or do you do I need to dig through all of the repos yes I",
    "start": "2277040",
    "end": "2283280"
  },
  {
    "text": "mean so open Telemetry for example which is a very large project right it has 80 plus Reapers um uh is in the process of",
    "start": "2283280",
    "end": "2291800"
  },
  {
    "text": "consolidating all the documentation onto the doc site right so you have to not go",
    "start": "2291800",
    "end": "2297200"
  },
  {
    "text": "to Every repo but rather than you can find it on Open Telemetry do/ dos and",
    "start": "2297200",
    "end": "2303319"
  },
  {
    "text": "Prometheus is the same way I me again the documentation is s ized and and most",
    "start": "2303319",
    "end": "2309520"
  },
  {
    "text": "large projects tend to do that uh but if you see any areas you know where you see",
    "start": "2309520",
    "end": "2315280"
  },
  {
    "text": "that you know it could do better definitely please let us know we talk with the projects all the time that's",
    "start": "2315280",
    "end": "2321160"
  },
  {
    "text": "great so definitely we can you know work together and and the second thing would be more uh use Cas or case studies uh",
    "start": "2321160",
    "end": "2329680"
  },
  {
    "text": "how certain companies in different sectors implemented sort of all the signals and make use across of that in",
    "start": "2329680",
    "end": "2337680"
  },
  {
    "text": "in their organizations especially when they have multiple teams I have 200 teams and thousand developers so making",
    "start": "2337680",
    "end": "2343760"
  },
  {
    "text": "sense of all the Telemetry is quite the challenge yes yes absolutely and I think",
    "start": "2343760",
    "end": "2349000"
  },
  {
    "text": "to that point I would say that the new end user tag uh you know tab that is",
    "start": "2349000",
    "end": "2355200"
  },
  {
    "text": "coming in now is actually uh tasked with that initiative of uh continuing to get",
    "start": "2355200",
    "end": "2363640"
  },
  {
    "text": "in technical case studies of observability implement orations which",
    "start": "2363640",
    "end": "2368680"
  },
  {
    "text": "will be you know again published by the cncf but that's a new initiative that's actually just starting off well honestly",
    "start": "2368680",
    "end": "2376280"
  },
  {
    "text": "we could kind of have some section about observability use cases and we can essentially dig through the existing Cube con talks and just make it in a",
    "start": "2376280",
    "end": "2382920"
  },
  {
    "text": "centralized place that's a good idea so I will not this down last two questions",
    "start": "2382920",
    "end": "2389280"
  },
  {
    "text": "maybe thanks again for the talk um so my question is what are some of the best",
    "start": "2389280",
    "end": "2394520"
  },
  {
    "text": "practices to use llms for at scale of",
    "start": "2394520",
    "end": "2399319"
  },
  {
    "text": "what you want to take that I can I can take the second uh iteration of it at",
    "start": "2401599",
    "end": "2407000"
  },
  {
    "text": "scale I mean that's the problem that's we are missing here for example like there was a good question before um",
    "start": "2407000",
    "end": "2412319"
  },
  {
    "text": "there is no observability specific models right so you have to kind of use the general model to ask uh you know",
    "start": "2412319",
    "end": "2417880"
  },
  {
    "text": "generic questions and provide as much context as possible so the best advice I",
    "start": "2417880",
    "end": "2423760"
  },
  {
    "text": "have now is that choose the model that kind of yeah it's the the biggest with",
    "start": "2423760",
    "end": "2428800"
  },
  {
    "text": "whatever compute power you have uh available and um and really try to",
    "start": "2428800",
    "end": "2434240"
  },
  {
    "text": "narrow the context um so essentially what exactly is happening in your",
    "start": "2434240",
    "end": "2439640"
  },
  {
    "text": "cluster what exactly scale problems you have and um yeah and go from there but we are missing uh yeah we don't have a",
    "start": "2439640",
    "end": "2445839"
  },
  {
    "text": "good answer to this question sorry so yeah I mean it's a good question because at this point in time there is not a",
    "start": "2445839",
    "end": "2453359"
  },
  {
    "text": "standardized suggestion that you know we can give out of the box but however um",
    "start": "2453359",
    "end": "2459599"
  },
  {
    "text": "we do plan to actually collate that together over this year because you know",
    "start": "2459599",
    "end": "2465800"
  },
  {
    "text": "again uh there are several models at this point that are used for observability it depends on like if",
    "start": "2465800",
    "end": "2473119"
  },
  {
    "text": "you're doing anomaly detection there are specific models that are used uh you",
    "start": "2473119",
    "end": "2478640"
  },
  {
    "text": "know both uh statist statistical as well as ml models which are very common uh",
    "start": "2478640",
    "end": "2485920"
  },
  {
    "text": "commonly used and and we can certainly you know kind of catalog that out on the",
    "start": "2485920",
    "end": "2491359"
  },
  {
    "text": "tag observability uh you know documentation but um right now there is",
    "start": "2491359",
    "end": "2498480"
  },
  {
    "text": "not any Consolidated doc documentation that is available another to do thank",
    "start": "2498480",
    "end": "2504280"
  },
  {
    "text": "you last question uh I was following your work on",
    "start": "2504280",
    "end": "2509359"
  },
  {
    "text": "uh standardizing query languages and I also heard opinion that uh since llm",
    "start": "2509359",
    "end": "2515960"
  },
  {
    "text": "becomes so powerful it doesn't make much sense to standardize it because uh",
    "start": "2515960",
    "end": "2521280"
  },
  {
    "text": "learning current is no longer a problem so we can like generate everything and no need to learn each individual",
    "start": "2521280",
    "end": "2527560"
  },
  {
    "text": "language but on the other hand each language is tailored to actual database uh so it will be more efficient and any",
    "start": "2527560",
    "end": "2536480"
  },
  {
    "text": "average standardized query language will be not that good as existing one can you",
    "start": "2536480",
    "end": "2542760"
  },
  {
    "text": "give any arguments why it's wrong and like why we still need this and so so I",
    "start": "2542760",
    "end": "2548559"
  },
  {
    "text": "think it's a very good point in time I mean you know because we started the query language group just you know a few",
    "start": "2548559",
    "end": "2556119"
  },
  {
    "text": "months ago and and it's really really awesome to see llms you know pick up",
    "start": "2556119",
    "end": "2562000"
  },
  {
    "text": "steam and actually get used for um uh mlops right so ml observability is also",
    "start": "2562000",
    "end": "2570800"
  },
  {
    "text": "actually being used so if I gave you an answer that yes it's already being done",
    "start": "2570800",
    "end": "2576400"
  },
  {
    "text": "where you know multiple query languages are in the observability query language space are",
    "start": "2576400",
    "end": "2583599"
  },
  {
    "text": "actually being fed to llms and there's one human query that is being done to",
    "start": "2583599",
    "end": "2590559"
  },
  {
    "text": "you know get whatever data you want from whichever Telemetry type that is already",
    "start": "2590559",
    "end": "2596079"
  },
  {
    "text": "being done now what is uh uh The Next Step here is that if we could provide a",
    "start": "2596079",
    "end": "2603400"
  },
  {
    "text": "reference implementation from the qu language group or a reference you know",
    "start": "2603400",
    "end": "2610280"
  },
  {
    "text": "architecture that hey you know you can take this kind of a model with you know these specifications and be able to uh",
    "start": "2610280",
    "end": "2619480"
  },
  {
    "text": "have a demo application available for multiple query languages uh that you can",
    "start": "2619480",
    "end": "2625400"
  },
  {
    "text": "download and use that's the next step uh I can I can add one one point to that um",
    "start": "2625400",
    "end": "2632359"
  },
  {
    "text": "so yes it is possible for each uh project SL provid to have a model that",
    "start": "2632359",
    "end": "2639079"
  },
  {
    "text": "can understand their backend but uh from an end user perspective uh it's not just",
    "start": "2639079",
    "end": "2644800"
  },
  {
    "text": "dashboards or ad hoc queries that you typically care about a big portion of your observability is with recording",
    "start": "2644800",
    "end": "2650839"
  },
  {
    "text": "rules and alerting rules and whatnot so there would you put an llm in front of",
    "start": "2650839",
    "end": "2656480"
  },
  {
    "text": "that it would probably be something that's not very coste efficient uh but rather if you have uh",
    "start": "2656480",
    "end": "2663839"
  },
  {
    "text": "standardization you promote uh uh neutrality in terms of projects and uh",
    "start": "2663839",
    "end": "2670119"
  },
  {
    "text": "vendors implementing their own thing and you're able to Define your rules and alerts uh in one way and use it across",
    "start": "2670119",
    "end": "2678119"
  },
  {
    "text": "uh any of these uh projects yeah and like Alita mentioned like it also provides us the ability to say that okay",
    "start": "2678119",
    "end": "2684960"
  },
  {
    "text": "you can have one base model for this uh standardized query language that you fine tune and uh you offer that as a",
    "start": "2684960",
    "end": "2692119"
  },
  {
    "text": "mechanism for others to add weights and things like that so there are there are definitely a lot of advantages to having",
    "start": "2692119",
    "end": "2699960"
  },
  {
    "text": "a standardized language similar to what we have for the database world and I would like to add two things one thing",
    "start": "2699960",
    "end": "2706960"
  },
  {
    "text": "is that uh when I was walking through the boo today or yesterday there were two vendors who don't who offer",
    "start": "2706960",
    "end": "2712920"
  },
  {
    "text": "essentially logging and tracing metrix back end they use promql for metrix but they don't have any language for logging and traces and I ask why not just using",
    "start": "2712920",
    "end": "2720240"
  },
  {
    "text": "something that that is now or um or something that or create your own I was like I'm not doing this like there is qu",
    "start": "2720240",
    "end": "2726200"
  },
  {
    "text": "standardization how we know kind of collaborated with open Telemetry they will come with something amazing I just",
    "start": "2726200",
    "end": "2732240"
  },
  {
    "text": "people will definitely adopt it so I'm just waiting I'm not going to implement twice so that's the first kind of thing that people are waiting for kind of",
    "start": "2732240",
    "end": "2738400"
  },
  {
    "text": "somebody who helped Define some standard language uh they don't want to do that right um the second thing is that um",
    "start": "2738400",
    "end": "2744680"
  },
  {
    "text": "many of those small uh let's say languages that are per project like they are not in the general model like and",
    "start": "2744680",
    "end": "2750520"
  },
  {
    "text": "there's liter statement from from some people it's like if CH GPT doesn't know about this certain language it doesn't",
    "start": "2750520",
    "end": "2756599"
  },
  {
    "text": "exist for me right that this is where we are here um at this point which is could could be changed many of those maybe",
    "start": "2756599",
    "end": "2762839"
  },
  {
    "text": "small project or like uh vendors would have their own models that would help the with this problem but right now a",
    "start": "2762839",
    "end": "2768960"
  },
  {
    "text": "single language can help um yeah to like have a one model that understand this language for example and with that",
    "start": "2768960",
    "end": "2775200"
  },
  {
    "text": "really we thank you for yeah so many questions and yeah thank you",
    "start": "2775200",
    "end": "2781200"
  },
  {
    "text": "again",
    "start": "2781200",
    "end": "2784200"
  }
]
[
  {
    "text": "um just wanted to start out with a quick show of hands how many people here run",
    "start": "2639",
    "end": "7839"
  },
  {
    "text": "postgress in production on kubernetes awesome how many people run very large",
    "start": "7839",
    "end": "13559"
  },
  {
    "text": "postgress clusters in production very cool and and another show of hands how",
    "start": "13559",
    "end": "19359"
  },
  {
    "text": "many people think uh kubernetes is possible to run very large uh great cool well hopefully uh by",
    "start": "19359",
    "end": "29359"
  },
  {
    "text": "the end of this we can get more of those hands raised and a quick spoiler alert",
    "start": "29359",
    "end": "35800"
  },
  {
    "text": "um we're going to show some ways to make it possible to actually restore very large kubernetes uh postgress clusters",
    "start": "35800",
    "end": "44160"
  },
  {
    "text": "300 times faster than you can today all right so welcome everybody uh",
    "start": "44160",
    "end": "51000"
  },
  {
    "text": "my name is Michelle I am a software engineer at Google um I have been a",
    "start": "51000",
    "end": "56199"
  },
  {
    "text": "kubernetes maintainer since 2017 and I a six storage",
    "start": "56199",
    "end": "61239"
  },
  {
    "text": "I'm joined here and yeah thanks Michelle I'm Gabrielle Gabriel bolini I'm VP of cloud native ATB ITB is a company that",
    "start": "61239",
    "end": "69960"
  },
  {
    "text": "um contributes to the pgus open source project I've been using pogus for more",
    "start": "69960",
    "end": "75400"
  },
  {
    "text": "than 20 years and uh now I'm also do da on kubernetes",
    "start": "75400",
    "end": "80880"
  },
  {
    "text": "Ambassador and uh uh an open source contributor in the past I I created um I",
    "start": "80880",
    "end": "87439"
  },
  {
    "text": "don't know if you're are familiar with Barman anyone does anyone know Barman for posg here okay so I created Barman",
    "start": "87439",
    "end": "95920"
  },
  {
    "text": "in 2011 it's a backup and restore manager for pgus and now I'm also",
    "start": "95920",
    "end": "102600"
  },
  {
    "text": "maintainer of cloud npg which is an operator for uh to run Posas incub NES",
    "start": "102600",
    "end": "109399"
  },
  {
    "text": "thank you cool yeah so first start off with a background in postgress",
    "start": "109399",
    "end": "115159"
  },
  {
    "text": "Technologies on on how postgress does backup and Recovery um we're going to",
    "start": "115159",
    "end": "120399"
  },
  {
    "text": "talk about the new volume snapshot backup and Recovery feature with the cloud native PG operator um we're going",
    "start": "120399",
    "end": "128200"
  },
  {
    "text": "to dive a little bit into details on the actual apis and how you use it um we're",
    "start": "128200",
    "end": "134640"
  },
  {
    "text": "going to show a demo and then we will wrap that up",
    "start": "134640",
    "end": "139720"
  },
  {
    "text": "afterwards yeah so in this first section I will go through um some important",
    "start": "142080",
    "end": "148080"
  },
  {
    "text": "Concepts behind this recovery with pogus",
    "start": "148080",
    "end": "153160"
  },
  {
    "text": "databases so Disaster Recovery is together with high availability one of",
    "start": "153160",
    "end": "158720"
  },
  {
    "text": "the core components in it to achieve business continuity planning a business",
    "start": "158720",
    "end": "164280"
  },
  {
    "text": "continuity solution always starts with defining the goal to achieve as an",
    "start": "164280",
    "end": "171319"
  },
  {
    "text": "organization so once these goals are defined we can shape our infrastructure",
    "start": "171319",
    "end": "176720"
  },
  {
    "text": "and our system accordingly but how do we Define these",
    "start": "176720",
    "end": "181879"
  },
  {
    "text": "business continuity goals so over the past years two primary metrics have",
    "start": "181879",
    "end": "187400"
  },
  {
    "text": "emerged the first one is RPO or recovery Point objective which is the amount of",
    "start": "187400",
    "end": "193560"
  },
  {
    "text": "time that we uh amount of uh data that we can afford to lose uh after a failure",
    "start": "193560",
    "end": "200159"
  },
  {
    "text": "and RPO is primarily a disaster recovery metric the second one is RTO or recovery",
    "start": "200159",
    "end": "207239"
  },
  {
    "text": "time objective which is the time need did to restore uh a service after a failure and",
    "start": "207239",
    "end": "215920"
  },
  {
    "text": "RTO is primarily a high availability metric so it's only through uh an",
    "start": "215920",
    "end": "221799"
  },
  {
    "text": "exercise of risk management and cost efficiency that organizations find the",
    "start": "221799",
    "end": "227400"
  },
  {
    "text": "right balance between these two opposing metrics so one of the coolest aspects of",
    "start": "227400",
    "end": "234159"
  },
  {
    "text": "pogress is it's an innate flexibility and impeccable robustness that that come",
    "start": "234159",
    "end": "240040"
  },
  {
    "text": "straight out of the box so it's no wonder that pgus has earned its reputation as the ultimate Rock Solid",
    "start": "240040",
    "end": "247319"
  },
  {
    "text": "database so as this t-shirt shows you know so so let's see why so going back",
    "start": "247319",
    "end": "256320"
  },
  {
    "text": "in 2001 pgus introduced crash recovery",
    "start": "256320",
    "end": "261560"
  },
  {
    "text": "using right ahead logging uh that marked a significant",
    "start": "261560",
    "end": "266639"
  },
  {
    "text": "step in data durability you probably remember you know the lamp stack at the",
    "start": "266639",
    "end": "272759"
  },
  {
    "text": "time pus and MySQL were emerging and at the time pgus was worrying about this",
    "start": "272759",
    "end": "279520"
  },
  {
    "text": "stuff not losing data more than performance and that's what made MySQL",
    "start": "279520",
    "end": "284800"
  },
  {
    "text": "more popular at the time okay but again don't know if you know a recent stack",
    "start": "284800",
    "end": "289840"
  },
  {
    "text": "Overflow survey revealed that actually now pus is the most popular database in",
    "start": "289840",
    "end": "295600"
  },
  {
    "text": "the world okay so in 2005 the introduction of continuous backup and",
    "start": "295600",
    "end": "301880"
  },
  {
    "text": "point in time recovery fortified pogress through online physical based backups",
    "start": "301880",
    "end": "307600"
  },
  {
    "text": "and wall archiving enabling effective uh Disaster Recovery these pioneering features are",
    "start": "307600",
    "end": "314680"
  },
  {
    "text": "the focal point of today's presentation over the next decade pgus",
    "start": "314680",
    "end": "320800"
  },
  {
    "text": "expanded its continuous backup infrastructure to include advanc the advanced replication system that we",
    "start": "320800",
    "end": "327759"
  },
  {
    "text": "witness today and primarily serving the high availability needs uh of an",
    "start": "327759",
    "end": "333440"
  },
  {
    "text": "organization so it's important to note that this uh presentation doesn't cover PG dump as PG dump only generates SQL",
    "start": "333440",
    "end": "342440"
  },
  {
    "text": "level snapshots of the database and these are not suitable for business",
    "start": "342440",
    "end": "347600"
  },
  {
    "text": "continuity so instead we focus on continuous backup so before looking into Posas",
    "start": "347600",
    "end": "354800"
  },
  {
    "text": "backup and Recovery infrastructure let's grasp uh some fundamental",
    "start": "354800",
    "end": "360039"
  },
  {
    "text": "Concepts pgus writes data in 8 kilobyte Pages inside the directory called PG",
    "start": "360039",
    "end": "367080"
  },
  {
    "text": "data while transactions are stored in right ahead log files that are also",
    "start": "367080",
    "end": "372680"
  },
  {
    "text": "known as PG wall shared buffers uh serve as a cache",
    "start": "372680",
    "end": "378280"
  },
  {
    "text": "for better performance and each connection with a client is managed by",
    "start": "378280",
    "end": "383680"
  },
  {
    "text": "dedicated process known as posers backend when a get backend uh request a",
    "start": "383680",
    "end": "391360"
  },
  {
    "text": "page from dis the page is first loaded in the shed",
    "start": "391360",
    "end": "396880"
  },
  {
    "text": "buffers and then returned to the uh back end and when a back end changes the",
    "start": "396880",
    "end": "403680"
  },
  {
    "text": "content of a page in memory that change is first saved in the right ahead",
    "start": "403680",
    "end": "411039"
  },
  {
    "text": "log not the data files so as you can see the shed buffers you know have the",
    "start": "411039",
    "end": "417759"
  },
  {
    "text": "content there okay the information is written the wall segment this is the reason why this is",
    "start": "417759",
    "end": "424960"
  },
  {
    "text": "called right ahead log or simply wall so for better data durability pgus",
    "start": "424960",
    "end": "432800"
  },
  {
    "text": "allows you to Archive each wall file in another location and this is normally",
    "start": "432800",
    "end": "437919"
  },
  {
    "text": "referred to as the wall archive pgus works on the assumption",
    "start": "437919",
    "end": "444000"
  },
  {
    "text": "that Shar buffers and data files might differ any",
    "start": "444000",
    "end": "450520"
  },
  {
    "text": "time it's the checkpoint process that ensures that dirty pages are regularly",
    "start": "450520",
    "end": "456360"
  },
  {
    "text": "flushed to dis so in brief to ensure smooth",
    "start": "456360",
    "end": "463720"
  },
  {
    "text": "Disaster Recovery we need to focus on safeguarding PG database",
    "start": "463720",
    "end": "470199"
  },
  {
    "text": "backups and the wall archive these resources are essential",
    "start": "470199",
    "end": "475400"
  },
  {
    "text": "for point in time recovery and at the same time serve as the Bedrock for postgress",
    "start": "475400",
    "end": "482840"
  },
  {
    "text": "replication so let's examine now the mechanics of continuous",
    "start": "483520",
    "end": "488759"
  },
  {
    "text": "backup with an active pogress server and its PG data the current wall file is",
    "start": "488759",
    "end": "496000"
  },
  {
    "text": "consistently archived in a separate storage location such as for example uh",
    "start": "496000",
    "end": "502080"
  },
  {
    "text": "an object store files inside the PG data need to be physically copied these cies are",
    "start": "502080",
    "end": "509800"
  },
  {
    "text": "called base backups and pogus provides an API for taking them online without",
    "start": "509800",
    "end": "516159"
  },
  {
    "text": "stopping the database these are called hot physical",
    "start": "516159",
    "end": "521279"
  },
  {
    "text": "backups the procedure is quite simple you invoke the pogus uh API to start a",
    "start": "521279",
    "end": "527080"
  },
  {
    "text": "backup it's called PG start backup or PG backup start start now and begin copying",
    "start": "527080",
    "end": "533279"
  },
  {
    "text": "all the files inside uh the PG data this process could take a few minutes",
    "start": "533279",
    "end": "539920"
  },
  {
    "text": "few hours few days it depends on the size of your database and in the meantime those files",
    "start": "539920",
    "end": "547240"
  },
  {
    "text": "might change and uh but this is not a problem because as I said before pgus",
    "start": "547240",
    "end": "554040"
  },
  {
    "text": "expects that all changes are stored in the right Ahad log first and they are",
    "start": "554040",
    "end": "559200"
  },
  {
    "text": "saved in the wall archive so by saving the wall archive and the base backups we're fine so",
    "start": "559200",
    "end": "567399"
  },
  {
    "text": "concluding the backup involves signaling the end of the copy process",
    "start": "567399",
    "end": "573839"
  },
  {
    "text": "through the pus API and awaiting for the final wall file to be",
    "start": "573839",
    "end": "579640"
  },
  {
    "text": "archived U safely for a backup to be uh",
    "start": "579640",
    "end": "586040"
  },
  {
    "text": "consistently restored you need all the wall files from the start uh of the",
    "start": "586040",
    "end": "592160"
  },
  {
    "text": "backup till the end of the backup um pictures this now you know",
    "start": "592160",
    "end": "599399"
  },
  {
    "text": "you've got your database in in production As Time Marches on your",
    "start": "599399",
    "end": "604839"
  },
  {
    "text": "database chains Out World files recycles them and dutifully archives them so your",
    "start": "604839",
    "end": "612959"
  },
  {
    "text": "task is as simple as scheduling backups whether daily or or weekly it's really",
    "start": "612959",
    "end": "619680"
  },
  {
    "text": "up to you and if you do this you basically have continuous backup in",
    "start": "619680",
    "end": "625560"
  },
  {
    "text": "pogress so notably pogress does does not require a specific implementation for",
    "start": "625560",
    "end": "632120"
  },
  {
    "text": "copying these files and this is very important for us you know because with",
    "start": "632120",
    "end": "638360"
  },
  {
    "text": "our operator we're now using volume snapshots okay this is a generic",
    "start": "638360",
    "end": "643399"
  },
  {
    "text": "implementation so please follow me now as this this is very important okay provided you have a catalog of Base",
    "start": "643399",
    "end": "650639"
  },
  {
    "text": "backups and the continuous sequence of all files in the archive pogress allows",
    "start": "650639",
    "end": "656760"
  },
  {
    "text": "you to recover to any point in time from the end of the first base backup that",
    "start": "656760",
    "end": "663079"
  },
  {
    "text": "you have to the latest committed transaction that is contained in the",
    "start": "663079",
    "end": "669200"
  },
  {
    "text": "last archived wall file in the okay so this is",
    "start": "669200",
    "end": "674680"
  },
  {
    "text": "simple okay simple and clear so you suppose you have a disaster now and you",
    "start": "674680",
    "end": "679800"
  },
  {
    "text": "need to recover to the point before the disaster you basically copy the the",
    "start": "679800",
    "end": "686480"
  },
  {
    "text": "latest available base backup in the server where you want to restore pogress and then for example you configure",
    "start": "686480",
    "end": "693240"
  },
  {
    "text": "pogress to recover up to the latest available transaction in the wall",
    "start": "693240",
    "end": "698680"
  },
  {
    "text": "archive posg uh starts fetching all the wall files from from the First wall",
    "start": "698680",
    "end": "705040"
  },
  {
    "text": "required by the uh base backup and applies the commit committed",
    "start": "705040",
    "end": "710320"
  },
  {
    "text": "transactions until it reaches the recovery Target which is in our in our case the end of the wall okay",
    "start": "710320",
    "end": "720839"
  },
  {
    "text": "then it promotes itself becoming ready to serve your",
    "start": "720839",
    "end": "726320"
  },
  {
    "text": "applications and this feature is important to note I just provide an example to restore Until the End okay",
    "start": "726320",
    "end": "733360"
  },
  {
    "text": "this is the case of full disaster but suppose you you delete uh a table or you",
    "start": "733360",
    "end": "740360"
  },
  {
    "text": "put a wrong wear query in your SQL statement uh you can go back to any",
    "start": "740360",
    "end": "746480"
  },
  {
    "text": "point in time okay so as demonstrated earlier Posas is",
    "start": "746480",
    "end": "752040"
  },
  {
    "text": "fully equipped to meet your business continuity needs all you require is to",
    "start": "752040",
    "end": "757120"
  },
  {
    "text": "set up um uh three things regular base",
    "start": "757120",
    "end": "763320"
  },
  {
    "text": "backups configuration of uh continuous wall archiving distribution of backups",
    "start": "763320",
    "end": "769399"
  },
  {
    "text": "and Wall Files across multiple locations for enhance Global RPO and RTO goals if",
    "start": "769399",
    "end": "776760"
  },
  {
    "text": "you adopt these practices you gain the ability to recover your system at any given uh moment and this is a proven uh",
    "start": "776760",
    "end": "785519"
  },
  {
    "text": "strategy that already many organizations have embraced in the last decade and and",
    "start": "785519",
    "end": "791600"
  },
  {
    "text": "and more outside kubernetes but this is Cube con this is 2023 so let's delve into how the cloud",
    "start": "791600",
    "end": "799279"
  },
  {
    "text": "native PG operator with no with no effort integrates all of these and",
    "start": "799279",
    "end": "805880"
  },
  {
    "text": "conceals uh the underlying complexity uh for you so cloud npg is actually more than a",
    "start": "805880",
    "end": "814880"
  },
  {
    "text": "more than an operator so it aligns perfectly with the principles outlined",
    "start": "814880",
    "end": "820320"
  },
  {
    "text": "by Jeff Carpenter and Patrick mcfadin in the in this book it harnesses the",
    "start": "820320",
    "end": "826600"
  },
  {
    "text": "kubernetes API operates declaratively prioritizes observability and comes with",
    "start": "826600",
    "end": "833399"
  },
  {
    "text": "buil-in security this robust solution includes a production radio operator for all",
    "start": "833399",
    "end": "840440"
  },
  {
    "text": "supported kubernetes versions and the suite of operant images for",
    "start": "840440",
    "end": "845920"
  },
  {
    "text": "pogress clpg sets apart from other pogus operators as it directly um extends",
    "start": "845920",
    "end": "854160"
  },
  {
    "text": "kubernetes to manage the entire life cycle of a pogus database encompassing Essential Day two",
    "start": "854160",
    "end": "862199"
  },
  {
    "text": "operations such as automated failover or backup and Recovery in cont to other approaches it",
    "start": "862199",
    "end": "870240"
  },
  {
    "text": "for go the use of stateful sets opting to manage uh persistent volume claims",
    "start": "870240",
    "end": "878120"
  },
  {
    "text": "directly CL PG was initiated by my company EDB and now is an open source",
    "start": "878399",
    "end": "885279"
  },
  {
    "text": "project that is managed uh by an openly governed and vendor neutral",
    "start": "885279",
    "end": "890880"
  },
  {
    "text": "Community as maintainers we committed to uh seeking inclusion in the cncf uh",
    "start": "890880",
    "end": "897680"
  },
  {
    "text": "sandbox and uh if you want to know more you can SC this scan this QR code and",
    "start": "897680",
    "end": "904320"
  },
  {
    "text": "get to the project download it test it and read the documentation but let's now examine what",
    "start": "904320",
    "end": "910839"
  },
  {
    "text": "cloud native PG provides in terms of Disaster Recovery Cloud native PG stores wall archive in an object store and out",
    "start": "910839",
    "end": "918480"
  },
  {
    "text": "of the box Wall Files are archived maximum every five minutes this is your",
    "start": "918480",
    "end": "923560"
  },
  {
    "text": "worst case scenario for RPO physical based backups can be taken",
    "start": "923560",
    "end": "929040"
  },
  {
    "text": "instead in two ways using object stores or on volume snapshots using the new uh",
    "start": "929040",
    "end": "936160"
  },
  {
    "text": "support for the standard kubernetes API and when dealing with large databases",
    "start": "936160",
    "end": "941279"
  },
  {
    "text": "volume snapshots emerge as the preferred choice for streamlined backup and",
    "start": "941279",
    "end": "948000"
  },
  {
    "text": "Recovery here's a quick comparison table outlining the backup and Recovery methods between the object store and",
    "start": "948000",
    "end": "955199"
  },
  {
    "text": "volume snapshot approaches a crucial point to consider is the copy and right",
    "start": "955199",
    "end": "960839"
  },
  {
    "text": "optimization offered by the storage enabling you to leverage incremental and",
    "start": "960839",
    "end": "966759"
  },
  {
    "text": "differential backup and recovery at at block uh Block",
    "start": "966759",
    "end": "971800"
  },
  {
    "text": "Level these F functionalities prove to be essential again especially when",
    "start": "971800",
    "end": "977279"
  },
  {
    "text": "dealing with large scale databases and this is probably one of",
    "start": "977279",
    "end": "982759"
  },
  {
    "text": "the most important slides today's presentation is a summary of The Benchmark results I ran",
    "start": "982759",
    "end": "989040"
  },
  {
    "text": "on EK on an eks cluster so to ensure consistency the test excl was focused on",
    "start": "989040",
    "end": "995360"
  },
  {
    "text": "base backup recovery without wall recovery I conducted uh some tests",
    "start": "995360",
    "end": "1001600"
  },
  {
    "text": "across various database sizes ranging from four gigabyt to over 4 terabyte",
    "start": "1001600",
    "end": "1007079"
  },
  {
    "text": "databases with consistent outcomes notably volume snapshots systematically",
    "start": "1007079",
    "end": "1012920"
  },
  {
    "text": "outperformed object stores in both backup and Recovery operations so",
    "start": "1012920",
    "end": "1018480"
  },
  {
    "text": "consider the 4.4 tbte uh scenario backup speed showcased a 25 fold Improvement",
    "start": "1018480",
    "end": "1026600"
  },
  {
    "text": "compared to object stores more importantly recovery time demonstrated a",
    "start": "1026600",
    "end": "1034000"
  },
  {
    "text": "300 fold improvement over object stores",
    "start": "1034000",
    "end": "1039240"
  },
  {
    "text": "again underscoring uh the remarkable Advantage is that the standard API that",
    "start": "1039240",
    "end": "1045798"
  },
  {
    "text": "kubernetes provides for volume snapshot um brings to to the game so now back to",
    "start": "1045799",
    "end": "1055000"
  },
  {
    "text": "Michelle all right thank you so let's explore what's happening uh under the",
    "start": "1055000",
    "end": "1060160"
  },
  {
    "text": "hood um oh sorry with Cloud native PG backups um so Cloud native PG is",
    "start": "1060160",
    "end": "1067960"
  },
  {
    "text": "leveraging the kubernetes volume snapshots feature um this feature went GA in kubernetes 120 and it provides a",
    "start": "1067960",
    "end": "1077760"
  },
  {
    "text": "standard and portable API across um storage providers through CSI drivers",
    "start": "1077760",
    "end": "1083640"
  },
  {
    "text": "and today we have over a 100 different CSI drivers available um supported by",
    "start": "1083640",
    "end": "1089400"
  },
  {
    "text": "all the major Cloud providers and on Prem storage vendors and so the",
    "start": "1089400",
    "end": "1094760"
  },
  {
    "text": "kubernetes uh volume snapshots API lets you do three basic operations first",
    "start": "1094760",
    "end": "1101600"
  },
  {
    "text": "create a snapshot of a persistent volume claim delete that snapshot and then also",
    "start": "1101600",
    "end": "1107760"
  },
  {
    "text": "create a new persistent volume claim from the snapshot and just taking a look at the",
    "start": "1107760",
    "end": "1114679"
  },
  {
    "text": "kubernetes API in a little more detail we can see that the API here follows a",
    "start": "1114679",
    "end": "1120200"
  },
  {
    "text": "similar pattern to persistent volume claims in kubernetes so as a user you",
    "start": "1120200",
    "end": "1126080"
  },
  {
    "text": "will create a volume snapshot object and you specify the persistent volume claim you want to um take that snapshot of um",
    "start": "1126080",
    "end": "1134520"
  },
  {
    "text": "you can also specify custom parameters and config configuration for those snapshots with a uh snapshot volume",
    "start": "1134520",
    "end": "1143080"
  },
  {
    "text": "snapshot class and then from there kubernetes will then invoke the CSI",
    "start": "1143080",
    "end": "1148880"
  },
  {
    "text": "drivers to actually go take the snapshots in the in the underlying storage",
    "start": "1148880",
    "end": "1153960"
  },
  {
    "text": "system and then when you actually want to restore your workload um with a new",
    "start": "1153960",
    "end": "1160880"
  },
  {
    "text": "dis what you would do is create a new persistent volume claim object where you",
    "start": "1160880",
    "end": "1167080"
  },
  {
    "text": "specify um as a data source that volume snapshot and now kubernetes will go and",
    "start": "1167080",
    "end": "1173080"
  },
  {
    "text": "reh will create a new volume and rehydrate that data from that snapshot so that's that's kind of what's",
    "start": "1173080",
    "end": "1180320"
  },
  {
    "text": "Happening um you know at the kubernetes level of things but we can um see here",
    "start": "1180320",
    "end": "1186200"
  },
  {
    "text": "how the cloud native PG API can simplify that",
    "start": "1186200",
    "end": "1191440"
  },
  {
    "text": "experience so um here's the cloud native PG uh cluster specification",
    "start": "1191440",
    "end": "1198840"
  },
  {
    "text": "and we can see here um in order to configure volume snapshots backup all",
    "start": "1198840",
    "end": "1205880"
  },
  {
    "text": "you have to do is go to the backup SE session and then um just specify the",
    "start": "1205880",
    "end": "1211080"
  },
  {
    "text": "volume snapshot class that you want to use for taking them and then also if you want to also um do the wall archive",
    "start": "1211080",
    "end": "1219200"
  },
  {
    "text": "backups then you also configure an object store uh for the Barm man Object Store backup policy so once you",
    "start": "1219200",
    "end": "1227360"
  },
  {
    "text": "configure that then the next step is you can take snap or you can take backups in one of two",
    "start": "1227360",
    "end": "1233360"
  },
  {
    "text": "ways um one way is you can create the schedule backup object um where you can",
    "start": "1233360",
    "end": "1238960"
  },
  {
    "text": "specify a schedule um this example here is showing taking a backup once a day um",
    "start": "1238960",
    "end": "1244240"
  },
  {
    "text": "you specify your Cloud native PG cluster you want to take that back up above and",
    "start": "1244240",
    "end": "1249640"
  },
  {
    "text": "the method you choose will be volume snapshots um you can also take a snap uh",
    "start": "1249640",
    "end": "1255559"
  },
  {
    "text": "backup on Demand by using the cloud needed PG Cube cuddle uh command um and",
    "start": "1255559",
    "end": "1261960"
  },
  {
    "text": "where you just give the um you just you just give the cluster that you want to",
    "start": "1261960",
    "end": "1267400"
  },
  {
    "text": "take a backup up and the method which is also volume",
    "start": "1267400",
    "end": "1271960"
  },
  {
    "text": "snapshots and now in a disaster recovery scenario if you need to restore that",
    "start": "1273400",
    "end": "1279400"
  },
  {
    "text": "postgress cluster what you'll do here is create a new Cloud native PG cluster",
    "start": "1279400",
    "end": "1284640"
  },
  {
    "text": "object and under the bootstrap and Recovery SE uh section that is where you",
    "start": "1284640",
    "end": "1291039"
  },
  {
    "text": "specify the volume snapshots that you want to restore this cluster from and",
    "start": "1291039",
    "end": "1296919"
  },
  {
    "text": "here you P directly pass in the names of the kubernetes volume snapshot objects you want to",
    "start": "1296919",
    "end": "1303520"
  },
  {
    "text": "use all right so let's go ahead and uh see this in action with a",
    "start": "1303799",
    "end": "1312120"
  },
  {
    "text": "demo how do cool so our demo cluster we're going",
    "start": "1312520",
    "end": "1318960"
  },
  {
    "text": "to demonstrate this on um a gke cluster and I'll probably have to look",
    "start": "1318960",
    "end": "1324559"
  },
  {
    "text": "here to see what's going on okay we're going to start with a three node uh",
    "start": "1324559",
    "end": "1330919"
  },
  {
    "text": "postgress cluster and we can see here um you'll in the cluster spec we'll specify",
    "start": "1330919",
    "end": "1337360"
  },
  {
    "text": "the storage classes we want to use for the volumes and then under the backup section we're specifying the volume",
    "start": "1337360",
    "end": "1344159"
  },
  {
    "text": "snapshot class um that we want to use for our backup method and we can also then um just",
    "start": "1344159",
    "end": "1352240"
  },
  {
    "text": "check which volume snapshot classes we have in our cluster um here we're just using a default volume snapshot class",
    "start": "1352240",
    "end": "1360320"
  },
  {
    "text": "using persistent Diss and then um you can see on the top",
    "start": "1360320",
    "end": "1365559"
  },
  {
    "text": "we have the scheduled backup objects where we're saying take a backup once a",
    "start": "1365559",
    "end": "1372000"
  },
  {
    "text": "day all right and so now we can actually um let's also Al look at the the",
    "start": "1374039",
    "end": "1379279"
  },
  {
    "text": "postgress cluster that's currently running um we'll see the name here we can see the number of",
    "start": "1379279",
    "end": "1386279"
  },
  {
    "text": "instances um and then when we uh go down we can see a couple of conditions about",
    "start": "1386279",
    "end": "1392960"
  },
  {
    "text": "the cluster we can see that the cluster is healthy um continuous archiving is",
    "start": "1392960",
    "end": "1398159"
  },
  {
    "text": "working and we can see when the last backup was successful or failed um going",
    "start": "1398159",
    "end": "1404279"
  },
  {
    "text": "down a little bit more we can see some more details like we can see which pod is currently the primary we can see all",
    "start": "1404279",
    "end": "1411360"
  },
  {
    "text": "the persistent volume claims that um this cluster is using and we can also see all the other pods that are part of",
    "start": "1411360",
    "end": "1417600"
  },
  {
    "text": "this cluster and then we'll also see what backups we have currently taken and so",
    "start": "1417600",
    "end": "1424360"
  },
  {
    "text": "we can see we took our last backup was taken about six minutes ago and we can",
    "start": "1424360",
    "end": "1429640"
  },
  {
    "text": "also find the corresponding kubernetes volume snapshots that were taken as part of",
    "start": "1429640",
    "end": "1435400"
  },
  {
    "text": "that and you can see here there's two two snapshots one for the main um data",
    "start": "1435400",
    "end": "1441240"
  },
  {
    "text": "volumes and another for the wall and then um now we're going to log",
    "start": "1441240",
    "end": "1447919"
  },
  {
    "text": "in to the database to just inspect some of the tables that are available um this",
    "start": "1447919",
    "end": "1453240"
  },
  {
    "text": "database was populated with data using pgbench um we'll see here that this is a 22",
    "start": "1453240",
    "end": "1460440"
  },
  {
    "text": "gbyte database and um we can see this has about 150 million rows of",
    "start": "1460440",
    "end": "1470559"
  },
  {
    "text": "data okay so now we're going to simulate a disaster we're just going to go and",
    "start": "1473720",
    "end": "1479840"
  },
  {
    "text": "delete the cluster whoops my",
    "start": "1479840",
    "end": "1485679"
  },
  {
    "text": "bad okay and so now um we'll see the pods there's no more pods left besides",
    "start": "1496760",
    "end": "1503399"
  },
  {
    "text": "our our client pod and then um we can see all the discs are gone but we can",
    "start": "1503399",
    "end": "1509559"
  },
  {
    "text": "see we still have our snapshots um and so now we want to",
    "start": "1509559",
    "end": "1515600"
  },
  {
    "text": "restore this cluster so let's take note of those two snapshots the last two snapshots that we want to",
    "start": "1515600",
    "end": "1522919"
  },
  {
    "text": "use um we're going to start a watch on the uh Cloud native PG cluster object",
    "start": "1522919",
    "end": "1529159"
  },
  {
    "text": "and then we're going to kick off this script um which will basically start",
    "start": "1529159",
    "end": "1534440"
  },
  {
    "text": "creating the new restored cluster um we can see that now um we're",
    "start": "1534440",
    "end": "1540799"
  },
  {
    "text": "starting to bring up the primary and let's go ahead and inspect the new",
    "start": "1540799",
    "end": "1545840"
  },
  {
    "text": "cluster spec here um here we're going to first restore the primary and so here you can",
    "start": "1545840",
    "end": "1553080"
  },
  {
    "text": "see the instance is is one but after this is done we can end up scaling it out to the remaining replicas and the",
    "start": "1553080",
    "end": "1559880"
  },
  {
    "text": "most important part here is in this bootstrap section here we are specifying",
    "start": "1559880",
    "end": "1565399"
  },
  {
    "text": "the the two um latest volume snapshots in the cluster we one for the uh",
    "start": "1565399",
    "end": "1571720"
  },
  {
    "text": "volume uh sorry for the data volume and one for the uh Wall Storage and so it",
    "start": "1571720",
    "end": "1577760"
  },
  {
    "text": "takes about a minute and after a minute um the Pod is able to come up and um now we're able to uh we're",
    "start": "1577760",
    "end": "1586640"
  },
  {
    "text": "just waiting for it to kind of become leader and there we go now the cluster",
    "start": "1586640",
    "end": "1592559"
  },
  {
    "text": "is healthy yep and then we're going to just inspect",
    "start": "1592559",
    "end": "1599600"
  },
  {
    "text": "a couple of the objects we see now some new persistent volume claims have been created and if we take a look at those",
    "start": "1599600",
    "end": "1607600"
  },
  {
    "text": "in a little more",
    "start": "1607600",
    "end": "1610600"
  },
  {
    "text": "detail we can see when we this persistent volume claim we can see the",
    "start": "1614600",
    "end": "1619960"
  },
  {
    "text": "data source um is specified as D volume",
    "start": "1619960",
    "end": "1625320"
  },
  {
    "text": "snapshot and so this volume was created with data populated from that",
    "start": "1625320",
    "end": "1631919"
  },
  {
    "text": "snapshot all right and then now we're going to go back um log back into the",
    "start": "1632240",
    "end": "1638760"
  },
  {
    "text": "cluster and inspect the database",
    "start": "1638760",
    "end": "1643360"
  },
  {
    "text": "contents we'll check the size again it's still 22 gigs and then we'll check the",
    "start": "1646520",
    "end": "1652240"
  },
  {
    "text": "number of rows in the table and should be 150",
    "start": "1652240",
    "end": "1657960"
  },
  {
    "text": "million all",
    "start": "1657960",
    "end": "1661158"
  },
  {
    "text": "right sorry we need to restore our slides",
    "start": "1673279",
    "end": "1679519"
  },
  {
    "text": "I don't know",
    "start": "1679679",
    "end": "1682360"
  },
  {
    "text": "Happ yeah I'm good with databases but not with this stuff",
    "start": "1706440",
    "end": "1713880"
  },
  {
    "text": "so okay yeah so um now that we've seen",
    "start": "1713960",
    "end": "1719000"
  },
  {
    "text": "no I'm good now that we've seen um sort of a example of how it works today um",
    "start": "1719000",
    "end": "1724679"
  },
  {
    "text": "like to just talk about some of the future enhancements that uh we're continuing to look into in both the",
    "start": "1724679",
    "end": "1730000"
  },
  {
    "text": "kubernetes space and the cloud PG space so first in kubernetes um we are",
    "start": "1730000",
    "end": "1735960"
  },
  {
    "text": "developing this new volume group snapshots feature which will um",
    "start": "1735960",
    "end": "1741000"
  },
  {
    "text": "definitely help Cloud native PG um be able to take uh volume snapshot backups",
    "start": "1741000",
    "end": "1746640"
  },
  {
    "text": "more efficiently because you can do things like partitioning your data and optimizing for different storage uh",
    "start": "1746640",
    "end": "1754320"
  },
  {
    "text": "efficiencies and then also allow taking those volume snapshots in parallel um",
    "start": "1754320",
    "end": "1760080"
  },
  {
    "text": "another enhancement we're working on in in six storage is the container object storage interface um this is very",
    "start": "1760080",
    "end": "1767440"
  },
  {
    "text": "similar to the concept of CSI but it's tailored for object storage and it's",
    "start": "1767440",
    "end": "1773640"
  },
  {
    "text": "trying to standardize the control plane operations for managing object storage buckets um this is also this would be",
    "start": "1773640",
    "end": "1781039"
  },
  {
    "text": "very useful for cloud native PG as well um as you can see um it it uses object",
    "start": "1781039",
    "end": "1786840"
  },
  {
    "text": "storage it manages object storage to do the uh wall archiving and then um I don't know if do",
    "start": "1786840",
    "end": "1793159"
  },
  {
    "text": "you want to talk about kontic PG we actually working on version 122 which will be released by the end of the year",
    "start": "1793159",
    "end": "1800080"
  },
  {
    "text": "which will support table spaces so table spaces are a vertical scalability feature that will enable to improve this",
    "start": "1800080",
    "end": "1808360"
  },
  {
    "text": "you know management of very large databases even further and we just",
    "start": "1808360",
    "end": "1813640"
  },
  {
    "text": "started basically we just scraping the surface at the moment of what the volume",
    "start": "1813640",
    "end": "1818760"
  },
  {
    "text": "snapch that CSI drivers are actually able to offer to us the next step will be PVC cloning so basically imagine this",
    "start": "1818760",
    "end": "1826279"
  },
  {
    "text": "you can scale up just by cloning volumes uh instead of running PG based backups",
    "start": "1826279",
    "end": "1832600"
  },
  {
    "text": "and these will also be used for in place",
    "start": "1832600",
    "end": "1836398"
  },
  {
    "text": "upgrades okay so uh key takeaways you know we've got a full open source stack",
    "start": "1839240",
    "end": "1845000"
  },
  {
    "text": "now to run pgus in kubernetes okay uh you've got clpg pql and kubernetes so",
    "start": "1845000",
    "end": "1852240"
  },
  {
    "text": "you can really mitigate the risk of vendor loin and uh the main benefit of",
    "start": "1852240",
    "end": "1858600"
  },
  {
    "text": "using volum snapshots is to have in general better RPO and RTO goals which",
    "start": "1858600",
    "end": "1865000"
  },
  {
    "text": "again are the business continuity uh goals that we need to achieve okay and",
    "start": "1865000",
    "end": "1870880"
  },
  {
    "text": "uh they are suitable for all major cloud service providers but they're also",
    "start": "1870880",
    "end": "1876120"
  },
  {
    "text": "available on on premise okay on premise so our advice is",
    "start": "1876120",
    "end": "1881679"
  },
  {
    "text": "to check what your storage classes provide and uh do your benchmarks you",
    "start": "1881679",
    "end": "1887399"
  },
  {
    "text": "know do your test and if you can use volume snapshots the other good thing is that you can actually also mix backup",
    "start": "1887399",
    "end": "1894000"
  },
  {
    "text": "strategies you can have have a hybrid strategies with object stores and volume snapshot in your in your in your",
    "start": "1894000",
    "end": "1901880"
  },
  {
    "text": "system so volume snapshot basically open a new er era for for pogas in kubernetes",
    "start": "1901880",
    "end": "1909559"
  },
  {
    "text": "because thank thanks to incremental and differential backup and Recovery you know we can manage very large databases",
    "start": "1909559",
    "end": "1916519"
  },
  {
    "text": "as you saw in the previous slide and this is just a",
    "start": "1916519",
    "end": "1921559"
  },
  {
    "text": "recommended uh reading for you I wrote this blog article a month ago uh that",
    "start": "1921559",
    "end": "1927760"
  },
  {
    "text": "gives you an idea about our view um in terms of architecture for",
    "start": "1927760",
    "end": "1933519"
  },
  {
    "text": "pgus in kubernetes and uh there's also these other blog article that pretty much",
    "start": "1933519",
    "end": "1941399"
  },
  {
    "text": "Recaps the things we have the benchmarks that I ran as part of this presentation",
    "start": "1941399",
    "end": "1949080"
  },
  {
    "text": "so you'll find these in the slides for laser usage so any",
    "start": "1949159",
    "end": "1957399"
  },
  {
    "text": "questions so do you want to go okay um my question is how would you or can you",
    "start": "1960880",
    "end": "1966480"
  },
  {
    "text": "make this multi- region hot hot or is this limited to like I know I know yeah",
    "start": "1966480",
    "end": "1973600"
  },
  {
    "text": "yeah so basically this is uh the good thing about this Sy and if you if you",
    "start": "1973600",
    "end": "1979000"
  },
  {
    "text": "read the blog article about the architecture you'll find uh a lot of information on the multi- region stuff",
    "start": "1979000",
    "end": "1985559"
  },
  {
    "text": "but essentially by using volume snapshots we delegate data Mobility to the storage class so as long as the",
    "start": "1985559",
    "end": "1992320"
  },
  {
    "text": "volume snapshot is available in the other region that's fine okay we can",
    "start": "1992320",
    "end": "1997679"
  },
  {
    "text": "recover thank you I guess there's lunch that's why",
    "start": "1997679",
    "end": "2002960"
  },
  {
    "text": "everyone's leaving uh hello uh we currently do you use the operator from zando and maybe I",
    "start": "2002960",
    "end": "2010720"
  },
  {
    "text": "just wanted to ask you what uh what does differentiate you from them what's what's better because I think that you",
    "start": "2010720",
    "end": "2016519"
  },
  {
    "text": "have started quite recently okay that's not really okay so the question is what primarily what's",
    "start": "2016519",
    "end": "2022639"
  },
  {
    "text": "the main difference between the zaland operator and our operator so the zaland operator is actually the",
    "start": "2022639",
    "end": "2028919"
  },
  {
    "text": "second uh Posas operator every written and uh uh we are from Italy we know",
    "start": "2028919",
    "end": "2035960"
  },
  {
    "text": "zando people a lot we and we that's actually the first time I saw pgus in",
    "start": "2035960",
    "end": "2042120"
  },
  {
    "text": "kubernetes we took a completely different approach with the operator uh",
    "start": "2042120",
    "end": "2047440"
  },
  {
    "text": "we actually tried tried to BR to bring pgus in kubernetes and for example we",
    "start": "2047440",
    "end": "2052760"
  },
  {
    "text": "didn't use patroni we didn't use Barman or pest so we didn't use the tools",
    "start": "2052760",
    "end": "2059440"
  },
  {
    "text": "available in pgus but we actually decided to leverage what's in kubernetes so um that's why I it's more",
    "start": "2059440",
    "end": "2067480"
  },
  {
    "text": "than an operator because it's actually also a failover management system it it",
    "start": "2067480",
    "end": "2073200"
  },
  {
    "text": "it provides um Taps for observability backup and Recovery as you see now and I",
    "start": "2073200",
    "end": "2079878"
  },
  {
    "text": "said this is just a start so it's fundamentally a completely different",
    "start": "2079879",
    "end": "2085679"
  },
  {
    "text": "approach that we took we waited we started four years ago actually we",
    "start": "2085679",
    "end": "2090919"
  },
  {
    "text": "released it open source a year and a half ago and uh we waited for local",
    "start": "2090919",
    "end": "2096280"
  },
  {
    "text": "persistent volumes to to be basically ready that's if you read again the story",
    "start": "2096280",
    "end": "2102920"
  },
  {
    "text": "you see that we actually before starting this project we benchmarked running",
    "start": "2102920",
    "end": "2109200"
  },
  {
    "text": "Posas on bare metal we didn't find any difference because that's the way we used to do it okay we were we've been",
    "start": "2109200",
    "end": "2116400"
  },
  {
    "text": "managing some of the largest pgus databases for years in the world um and",
    "start": "2116400",
    "end": "2122240"
  },
  {
    "text": "so we wanted to make sure that it could work on Mel as well and it does okay and",
    "start": "2122240",
    "end": "2130119"
  },
  {
    "text": "volume snapshots are also available on bare mesal installations so it's essentially a completely different",
    "start": "2130119",
    "end": "2136040"
  },
  {
    "text": "approach we don't use State full sets we use persistent volume claims that's why",
    "start": "2136040",
    "end": "2141599"
  },
  {
    "text": "I think we are able to do this stuff as well it helps us for rolling up",
    "start": "2141599",
    "end": "2146880"
  },
  {
    "text": "upgrades po disruption budget control all this kind of stuff you know so have",
    "start": "2146880",
    "end": "2152400"
  },
  {
    "text": "a look and and you know join the community and if you've got this is very",
    "start": "2152400",
    "end": "2157480"
  },
  {
    "text": "impressive thank you I would I would like to thank Leonardo Leonardo please stand up today",
    "start": "2157480",
    "end": "2165599"
  },
  {
    "text": "it's his birthday Leonardo",
    "start": "2165599",
    "end": "2169880"
  },
  {
    "text": "is a maintainer of cloud NTI PG and any other questions yeah so uh thanks this",
    "start": "2171720",
    "end": "2179240"
  },
  {
    "text": "is amazing work uh just had two questions one uh can volume snapshots be taken uh off cluster and restored to a",
    "start": "2179240",
    "end": "2186400"
  },
  {
    "text": "different cluster as well and the second one was regarding the cloud native PG operator like it's sometimes useful to",
    "start": "2186400",
    "end": "2193160"
  },
  {
    "text": "see a list of backups right like uh if you if you've taken hundreds of backups in a long running cluster uh is there a",
    "start": "2193160",
    "end": "2199319"
  },
  {
    "text": "way to do that with the operator I I'll reply to the second maybe if you want to reply to the first yeah sorry what was",
    "start": "2199319",
    "end": "2206079"
  },
  {
    "text": "the first question if you can move it oh sorry so the first question is uh is it",
    "start": "2206079",
    "end": "2211720"
  },
  {
    "text": "possible to move the volume snapshots to a different cluster and restore it on a different like like let's say take it on",
    "start": "2211720",
    "end": "2217400"
  },
  {
    "text": "uh one cluster and move it on two a different clusters yes um uh you'll need to double check the uh actual storage",
    "start": "2217400",
    "end": "2223880"
  },
  {
    "text": "capabilities but for the most part when um the objects and kubernetes are just references to the snapshots in the",
    "start": "2223880",
    "end": "2230880"
  },
  {
    "text": "underlying storage system so you should just be able to take those snapshot objects and just import them into",
    "start": "2230880",
    "end": "2237319"
  },
  {
    "text": "another cluster okay yeah and for the backups you can actually get the list of",
    "start": "2237319",
    "end": "2242920"
  },
  {
    "text": "backups and uh uh we put a lot of labels in the backup objects by default",
    "start": "2242920",
    "end": "2250480"
  },
  {
    "text": "so you are able to for example see what backups belong to a cluster the date",
    "start": "2250480",
    "end": "2256760"
  },
  {
    "text": "they were taken uh all these we've got several labels and annotations okay in",
    "start": "2256760",
    "end": "2263560"
  },
  {
    "text": "both the volume snapshots and the backups for example it's important for the volume snapshots that we also store",
    "start": "2263560",
    "end": "2271040"
  },
  {
    "text": "as as an annotation the conf the the spec of the cluster so so uh the spec of",
    "start": "2271040",
    "end": "2278280"
  },
  {
    "text": "the cluster is stored in the in the volume snapshot so you only need that to restore everything okay that's why this",
    "start": "2278280",
    "end": "2285839"
  },
  {
    "text": "also integrates with kubernetes level backup tools okay very well makes sense",
    "start": "2285839",
    "end": "2291160"
  },
  {
    "text": "okay thanks another question",
    "start": "2291160",
    "end": "2299599"
  },
  {
    "text": "y Cloud native PG Advantage is",
    "start": "2305520",
    "end": "2312838"
  },
  {
    "text": "over",
    "start": "2314000",
    "end": "2317000"
  },
  {
    "text": "but okay so essentially clown PG it's pogus okay then all the benchmarks",
    "start": "2321680",
    "end": "2328160"
  },
  {
    "text": "basically our exercise has been to bring pogus in kubernetes okay so and now we",
    "start": "2328160",
    "end": "2337200"
  },
  {
    "text": "can say in my opinion I will never go back to VMS or their method to to to to",
    "start": "2337200",
    "end": "2342880"
  },
  {
    "text": "run Posas okay to me this is the best way to run pgus that we have okay and",
    "start": "2342880",
    "end": "2349040"
  },
  {
    "text": "essentially the same things that we were applying on bare metal and VMS now you",
    "start": "2349040",
    "end": "2354160"
  },
  {
    "text": "apply them on kubernetes you need kubernetes skills and you know it to",
    "start": "2354160",
    "end": "2359319"
  },
  {
    "text": "reach the TPS you know transaction per seconds it's really an exercise of",
    "start": "2359319",
    "end": "2364800"
  },
  {
    "text": "customizing POS to your organization which is different from any other",
    "start": "2364800",
    "end": "2369920"
  },
  {
    "text": "organization in the world and run benchmarks okay but this is pus I mean",
    "start": "2369920",
    "end": "2375839"
  },
  {
    "text": "the test that I showed before I was able to run to achieve 1100 transaction per",
    "start": "2375839",
    "end": "2381520"
  },
  {
    "text": "seconds on the 4.5 terabyte database using synchronous comit and remote apply",
    "start": "2381520",
    "end": "2388800"
  },
  {
    "text": "so if you know pogus you know what it means it means that I write a transaction and not only I wait that the",
    "start": "2388800",
    "end": "2395040"
  },
  {
    "text": "stand for the standby to store it locally I also wait for the standby to",
    "start": "2395040",
    "end": "2400960"
  },
  {
    "text": "apply and see it so essentially you have Rec consistency between this the primary",
    "start": "2400960",
    "end": "2407040"
  },
  {
    "text": "and the standby okay these are amazing results I mean you know the vertical scalability",
    "start": "2407040",
    "end": "2414720"
  },
  {
    "text": "in pogus is something that we should not uh under underplay okay when we are",
    "start": "2414720",
    "end": "2420839"
  },
  {
    "text": "table spaces and partitioning I think this is another interesting",
    "start": "2420839",
    "end": "2427040"
  },
  {
    "text": "talk maybe for next year or for uh Paris you know I look forward to it yeah there",
    "start": "2427040",
    "end": "2434560"
  },
  {
    "text": "are no stateful setes how do you scale up and down if there are no stateful setes here",
    "start": "2434560",
    "end": "2441440"
  },
  {
    "text": "so how do you scale up and down we cannot remove random part right I mean",
    "start": "2441440",
    "end": "2446680"
  },
  {
    "text": "it's all done by the operator the operator treats every instance like any other so there's no primary or you know",
    "start": "2446680",
    "end": "2453800"
  },
  {
    "text": "one that is better than the others okay so it's again like treating like cattle",
    "start": "2453800",
    "end": "2459800"
  },
  {
    "text": "instead of pets okay we bypass the state full set concept and we control directly",
    "start": "2459800",
    "end": "2466040"
  },
  {
    "text": "the persistent volumes okay because I mean we've we've written this stuff for",
    "start": "2466040",
    "end": "2472240"
  },
  {
    "text": "pogus as you saw 15 years ago okay so we have put all the logic inside kubernetes",
    "start": "2472240",
    "end": "2480040"
  },
  {
    "text": "where we have more control than before than ever actually because applications",
    "start": "2480040",
    "end": "2485520"
  },
  {
    "text": "that reside where the database is benefit from having a single Authority",
    "start": "2485520",
    "end": "2491040"
  },
  {
    "text": "that controls the network and primarily rooting as well okay so that's why I",
    "start": "2491040",
    "end": "2497960"
  },
  {
    "text": "mean we've never experienced this bit brain with clown PG and when you talk",
    "start": "2497960",
    "end": "2503440"
  },
  {
    "text": "about fail over management that's quite impressive but one thing I suggest that",
    "start": "2503440",
    "end": "2508920"
  },
  {
    "text": "you look at is the amount of end to end tests that we continuously run in our",
    "start": "2508920",
    "end": "2515240"
  },
  {
    "text": "Pipelines and uh and uh yeah and how we build the operator in general you know",
    "start": "2515240",
    "end": "2523240"
  },
  {
    "text": "but yeah so basically we just control everything we hibernate the the cluster we we can",
    "start": "2523240",
    "end": "2529560"
  },
  {
    "text": "fence the instances so even the rolling upgrade upgrade procedure we first",
    "start": "2529560",
    "end": "2535319"
  },
  {
    "text": "upgrade the standby and then we give you the possibility to choose to do the",
    "start": "2535319",
    "end": "2541359"
  },
  {
    "text": "switch switch over or simple restart of the of the instance and and do it",
    "start": "2541359",
    "end": "2547559"
  },
  {
    "text": "automatically or you know manually okay so this is thanks to",
    "start": "2547559",
    "end": "2553440"
  },
  {
    "text": "directly working with with persistent",
    "start": "2553440",
    "end": "2557720"
  },
  {
    "text": "volumes all right any other questions cool thank you everyone thank",
    "start": "2563200",
    "end": "2570960"
  },
  {
    "text": "you",
    "start": "2571119",
    "end": "2574119"
  }
]
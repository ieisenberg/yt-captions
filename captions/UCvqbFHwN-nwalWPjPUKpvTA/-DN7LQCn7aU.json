[
  {
    "text": "greetings everyone welcome to the project K native maintainers session where you are not going to hear from",
    "start": "80",
    "end": "6240"
  },
  {
    "text": "maintainers this time around how great K native is but hear about the stories how",
    "start": "6240",
    "end": "12480"
  },
  {
    "text": "K native fars in the real world I am NAA Singh I am K native steering committee member and today I have with me four",
    "start": "12480",
    "end": "19640"
  },
  {
    "text": "guest speakers who are going to talk about what how they are using K native in the",
    "start": "19640",
    "end": "25720"
  },
  {
    "text": "world so if you attended one of my previous sessions you will think that I'm",
    "start": "25720",
    "end": "31720"
  },
  {
    "text": "repeating myself but I think it is worth repeating that K native is more than sever less now what do I mean by that uh",
    "start": "31720",
    "end": "39960"
  },
  {
    "text": "in kubernetes to create and deploy a service you have a lot of constructs",
    "start": "39960",
    "end": "45200"
  },
  {
    "text": "that you need to keep take care of to create to configure to deploy what K",
    "start": "45200",
    "end": "50360"
  },
  {
    "text": "native does it takes away the cognitive toil that you need to have because you run a command on a container it gives",
    "start": "50360",
    "end": "57719"
  },
  {
    "text": "you a ready to use URL with autot TLS and also provide you Auto scaling",
    "start": "57719",
    "end": "64559"
  },
  {
    "text": "Based On Demand with Infamous scale back to zero and that makes it a serverless",
    "start": "64559",
    "end": "70840"
  },
  {
    "text": "platform for kubernetes as well as a simplified kubernetes for application developers but that's not all it is also",
    "start": "70840",
    "end": "79240"
  },
  {
    "text": "event driven platform for kubernetes because it provides you the Eventing infrastructure for your all your event",
    "start": "79240",
    "end": "85119"
  },
  {
    "text": "driven needs and with one more what I want to say is if I can reduce it to",
    "start": "85119",
    "end": "90520"
  },
  {
    "text": "tagline it is K native by default and kubernetes when you",
    "start": "90520",
    "end": "95960"
  },
  {
    "text": "must so today we will learn from our guest speakers their use cases what scenarios they are using K native for",
    "start": "95960",
    "end": "103040"
  },
  {
    "text": "and why K native and with that I am going to give it to my first guest speaker to kick it",
    "start": "103040",
    "end": "110119"
  },
  {
    "text": "off so I'm Andrew senar and um I work for cor weave who's a GPU Focus cloud",
    "start": "110119",
    "end": "116360"
  },
  {
    "text": "provider so HPC rendering sort of things like that and we use K native for a managed service",
    "start": "116360",
    "end": "124759"
  },
  {
    "text": "that allows our customers to run serverless style workloads most of our customers are using K native to serve",
    "start": "124759",
    "end": "132360"
  },
  {
    "text": "large language models and like image generation and one of the reasons they",
    "start": "132360",
    "end": "137879"
  },
  {
    "text": "like to use these is because of the ability to scale up and down scale to zero these are very big features that",
    "start": "137879",
    "end": "143080"
  },
  {
    "text": "they want some of them deploy a lot of fine tunes that don't get a lot of usage so scale Zer is pretty important so con",
    "start": "143080",
    "end": "149959"
  },
  {
    "text": "of serving provides a very simplified deployment for them and it handles the scaling the Ingress everything all inone",
    "start": "149959",
    "end": "155840"
  },
  {
    "text": "you can set this up and we have seen some customers do this manually with like kada autoscaler and whatnot but",
    "start": "155840",
    "end": "161040"
  },
  {
    "text": "this is so much easier for them to manage and use you get the one crd so that's the really big driver for uh the",
    "start": "161040",
    "end": "167800"
  },
  {
    "text": "K of usage there and we have a lot of clients using it we have thousands of K",
    "start": "167800",
    "end": "172879"
  },
  {
    "text": "Services over with lots of PODS so I'm going to talk about a few",
    "start": "172879",
    "end": "178879"
  },
  {
    "text": "challenges we've had through our usage we've actually had a really overall good experience but there's a few things that",
    "start": "178879",
    "end": "184640"
  },
  {
    "text": "we've kind of learned from it and I just kind want to highlight some of those so the activators for C of serving we've",
    "start": "184640",
    "end": "191519"
  },
  {
    "text": "chosen to manually scal them versus using the HPA we found in our large cluster with our thousands of services",
    "start": "191519",
    "end": "197000"
  },
  {
    "text": "that that extra kind of churn of the end points can cause some less than optimal Behavior we've",
    "start": "197000",
    "end": "203200"
  },
  {
    "text": "seen this in the past from other speakers as well uh We've increased our activator capacity again per activator",
    "start": "203200",
    "end": "209319"
  },
  {
    "text": "because we found a lot of our services have very cyclical views and that helps it churn Less on the end points we have",
    "start": "209319",
    "end": "216120"
  },
  {
    "text": "a lot of dashboards to monitor the the health of our cluster there to make sure it's performing well we run a dual",
    "start": "216120",
    "end": "222400"
  },
  {
    "text": "Ingress with K native so we run both Courier and ISO uh career is great for what we need ISO was kind of used at the",
    "start": "222400",
    "end": "229640"
  },
  {
    "text": "time before career existed it's a little heavy weight for our usage and we've seen better scaling of Courier um that",
    "start": "229640",
    "end": "237120"
  },
  {
    "text": "was something that kind of came through you know we've had some bugs in the past with the activators not detecting pod",
    "start": "237120",
    "end": "242519"
  },
  {
    "text": "Readiness and whatnot we've worked through those are patched now and you know occasionally very large clusters",
    "start": "242519",
    "end": "247720"
  },
  {
    "text": "you can run into some slowness here and there uh that you just kind of have to manage uh there's some things we've done",
    "start": "247720",
    "end": "252879"
  },
  {
    "text": "to improve that areas where there's a slowness but overall it's been very robust on the control plan side on",
    "start": "252879",
    "end": "261040"
  },
  {
    "text": "people using K Services um we've have a really good experience with K native but",
    "start": "261040",
    "end": "267759"
  },
  {
    "text": "not all our customers are experts in deployment cand services so some frequent things we see is a lot of our",
    "start": "267759",
    "end": "274120"
  },
  {
    "text": "customers especially with large language models you know they tend to have very large containers they tend to put their",
    "start": "274120",
    "end": "279560"
  },
  {
    "text": "models in their containers they pull their models from hugging face and they expect all this to scale up and down quickly it doesn't",
    "start": "279560",
    "end": "287199"
  },
  {
    "text": "so we've done a lot of training and whatnot with our customers helping them you know go from long container start",
    "start": "287199",
    "end": "293400"
  },
  {
    "text": "times well over five minutes you know down to 30 second start times or less uh",
    "start": "293400",
    "end": "299120"
  },
  {
    "text": "our INF structure set up to kind of optimize some things so we kind of steer them towards how we have things in place",
    "start": "299120",
    "end": "304360"
  },
  {
    "text": "there uh other things some again not every customer is an expert at K native or how to configure the service so we've",
    "start": "304360",
    "end": "310199"
  },
  {
    "text": "seen like incorrect container concurrency llms a lot of times you have one GPU assigned to your container you",
    "start": "310199",
    "end": "316039"
  },
  {
    "text": "can handle one request at a time if you set your container concurrency to zero or 40 in K native you will have problems",
    "start": "316039",
    "end": "323960"
  },
  {
    "text": "because you'll cue in the Q proxy and a lot of your requests will time out and then you'll come us complaining why do",
    "start": "323960",
    "end": "330720"
  },
  {
    "text": "we have all these failures and I'll say well you kind of misconfigured things uh so we've seen a lot of things there so",
    "start": "330720",
    "end": "337039"
  },
  {
    "text": "sometimes a lot of the like challenges we face with K native aren't really challenges with K native the thing it's",
    "start": "337039",
    "end": "342919"
  },
  {
    "text": "a lot of the understanding of our customers and whatnot so we've got a lot of docs for our internal support people to help our customers through things as",
    "start": "342919",
    "end": "349720"
  },
  {
    "text": "well as we have public docs on our doc site for best practices for inference and serving so that's kind of how that's",
    "start": "349720",
    "end": "356039"
  },
  {
    "text": "where a lot of the focus has been with like I'd call issues and problems they're not really issues and problems they're just getting the right",
    "start": "356039",
    "end": "362360"
  },
  {
    "text": "understanding on how to use the tool to do the right job so I'm gonna hand it over to the",
    "start": "362360",
    "end": "368520"
  },
  {
    "text": "next guy yeah thank you so my name is nor sareno I work for SBA um a german-based",
    "start": "368520",
    "end": "376280"
  },
  {
    "text": "um it infrastructure and consultancy Company and um yeah I'm an architect",
    "start": "376280",
    "end": "381919"
  },
  {
    "text": "mainly dabling at currently in open Shi of kubernetes and distributed systems in the public sector and we are using",
    "start": "381919",
    "end": "388840"
  },
  {
    "text": "cative mainly for the Eventing component um because we have clients who have like",
    "start": "388840",
    "end": "394199"
  },
  {
    "text": "multiple departments and they have many monoliths which they are now transforming into Cloud native",
    "start": "394199",
    "end": "400520"
  },
  {
    "text": "applications and this provides a big um overhead and communication problem",
    "start": "400520",
    "end": "406880"
  },
  {
    "text": "inside the organization so we have chosen to use conative Eventing to like decouple the applications and provide",
    "start": "406880",
    "end": "414039"
  },
  {
    "text": "like a platform software as a service experience to the different departments that are residing in the client side um",
    "start": "414039",
    "end": "422840"
  },
  {
    "text": "one problem that we of course face is that we cannot use something that is SAS and cloudbased because we have high",
    "start": "422840",
    "end": "428520"
  },
  {
    "text": "compliance um standards so we have to choose something that is very um",
    "start": "428520",
    "end": "434520"
  },
  {
    "text": "standardized has Open Standards and can last maybe decades or we can think it",
    "start": "434520",
    "end": "440080"
  },
  {
    "text": "can last decades at least that's what we hope for and we came to the conclusion that conative is here the best fit it",
    "start": "440080",
    "end": "446840"
  },
  {
    "text": "uses like Open Standards um like cloud events um and the interfaces and the",
    "start": "446840",
    "end": "452879"
  },
  {
    "text": "architecture is very stable and good design so the end users that we will deploy conative 2 they just have to",
    "start": "452879",
    "end": "459199"
  },
  {
    "text": "interact with very simple and straightforward interfaces and can rely that they always work IR regardless if",
    "start": "459199",
    "end": "465840"
  },
  {
    "text": "they having a development experience inside the cloud for just development and then going into highight where it's",
    "start": "465840",
    "end": "471840"
  },
  {
    "text": "aired and secured um so the goal in essence is creating a big magic event mesh as a",
    "start": "471840",
    "end": "478240"
  },
  {
    "text": "software as a service that we can deploy on Prem and the users can interact with through the broken trigger model um on",
    "start": "478240",
    "end": "486159"
  },
  {
    "text": "the right side on the on the picture you can see here it's like an high level overview of what we are doing so we have",
    "start": "486159",
    "end": "491800"
  },
  {
    "text": "multiple kubernetes clusters and um we are uh we're putting a load balancer in",
    "start": "491800",
    "end": "497039"
  },
  {
    "text": "front of these clusters and through the load balancer we address one of our um",
    "start": "497039",
    "end": "502360"
  },
  {
    "text": "conative Brokers to then ingest the events that are coming to the system and",
    "start": "502360",
    "end": "507400"
  },
  {
    "text": "through that conative broker we call them the clust the C native broker we then low balance these um or forward",
    "start": "507400",
    "end": "513360"
  },
  {
    "text": "these events to the other clusters which we then call the followup clusters and from there the projects then get their",
    "start": "513360",
    "end": "520279"
  },
  {
    "text": "name spaces they can apply for a name space or departments and they can just publish their workload applications into",
    "start": "520279",
    "end": "527200"
  },
  {
    "text": "their namespaces and then also consume the conative services so for example the broker trigger model which is backed by",
    "start": "527200",
    "end": "533680"
  },
  {
    "text": "aacha Kafka in our case um we have some requirements in regards to that which",
    "start": "533680",
    "end": "539560"
  },
  {
    "text": "are specific to the public sector which is like we have to we have some environments which are low side we have",
    "start": "539560",
    "end": "544959"
  },
  {
    "text": "some environments which are high side so air environments and specific compliance",
    "start": "544959",
    "end": "550079"
  },
  {
    "text": "standards we have to agree to firewalls are a huge issue custom certificate authorities and multiple clusters many",
    "start": "550079",
    "end": "558079"
  },
  {
    "text": "stages different data centers which are also secured in a weird way which are",
    "start": "558079",
    "end": "563360"
  },
  {
    "text": "not usual in the um open market so um this is all things we had to consider",
    "start": "563360",
    "end": "568800"
  },
  {
    "text": "when the stative at the customer side challenges we saw during the",
    "start": "568800",
    "end": "574680"
  },
  {
    "text": "buildup and the implementation were mainly with the persistence so at least",
    "start": "574680",
    "end": "580480"
  },
  {
    "text": "back then in the documentation uh the documentation and the details about how the persistence and EG for example kafco",
    "start": "580480",
    "end": "587440"
  },
  {
    "text": "rabbit mq is implemented into K native wasn't as straightforward as it is now",
    "start": "587440",
    "end": "592480"
  },
  {
    "text": "so the documentation is much more better now in that regard but we had to figure out a lot of things on the go um um and",
    "start": "592480",
    "end": "599839"
  },
  {
    "text": "that's the second point about the SP docs there were there were some issues we had to find out through looking to",
    "start": "599839",
    "end": "604880"
  },
  {
    "text": "the GitHub code but which is our now covered as well in the documentation and for our case for",
    "start": "604880",
    "end": "611240"
  },
  {
    "text": "example is the custom certificate Authority which we had to inject into all the pots that call like consumers",
    "start": "611240",
    "end": "618360"
  },
  {
    "text": "because our services that we call our deployments they all have custom certificates included into their",
    "start": "618360",
    "end": "624480"
  },
  {
    "text": "image um on the user side and user side one challenge is we are working in the",
    "start": "624480",
    "end": "630240"
  },
  {
    "text": "public sector you can imagine pay is not that good so the engineers that are there are not really the engineers that",
    "start": "630240",
    "end": "637440"
  },
  {
    "text": "would be confronted with Cloud native Computing to solutions they usually have",
    "start": "637440",
    "end": "643240"
  },
  {
    "text": "like multiple years of experience at that client and they're used in their stack so it's maybe net Java and not",
    "start": "643240",
    "end": "650360"
  },
  {
    "text": "much out of that because getting new tools into that environment is kind of tricky so we the onboarding part was a",
    "start": "650360",
    "end": "658040"
  },
  {
    "text": "big big um yeah effort on our side we had to redent everything we had to go",
    "start": "658040",
    "end": "663600"
  },
  {
    "text": "through a lot of work workshops with the users and as well the architectural",
    "start": "663600",
    "end": "668760"
  },
  {
    "text": "Parts like um item potency at least once delivery we had to explain those",
    "start": "668760",
    "end": "674200"
  },
  {
    "text": "Concepts very much very often um in detail so that the users understand what",
    "start": "674200",
    "end": "679519"
  },
  {
    "text": "they're really doing um we had to create a default grafana dashboard which is currently not",
    "start": "679519",
    "end": "685000"
  },
  {
    "text": "included in the Upstream project because this then allows the um consumer to really see on one page what is happening",
    "start": "685000",
    "end": "691000"
  },
  {
    "text": "in their system end to end and identify for example issues in their system and then go to jiga to trace them down and",
    "start": "691000",
    "end": "698959"
  },
  {
    "text": "on the G up side we had some issues especially in the administration part where we deploy a lot of like broker and",
    "start": "698959",
    "end": "705000"
  },
  {
    "text": "triggers and when we update the cluster and all the Departments are already",
    "start": "705000",
    "end": "710800"
  },
  {
    "text": "deploying their stuff while that is happening the reconciler sometimes gets some HIC herbs and uh yeah it leads to",
    "start": "710800",
    "end": "718120"
  },
  {
    "text": "weird issues let's say like that so we are still working to finding out what exactly kind of issues we are getting",
    "start": "718120",
    "end": "724560"
  },
  {
    "text": "but um um yeah that's something that we are still not sure what is the reason on that end um error messages as well are",
    "start": "724560",
    "end": "732959"
  },
  {
    "text": "sometimes not that descriptive so especially in the controller level controll plane um there might be some",
    "start": "732959",
    "end": "738760"
  },
  {
    "text": "error messages you might see if you use it in production where you really have to drill down and sometimes also go to",
    "start": "738760",
    "end": "743959"
  },
  {
    "text": "the GitHub go code to figure out what is happening here because you get the go code line that exception but the error",
    "start": "743959",
    "end": "750560"
  },
  {
    "text": "itself is non descriptive something like context Deadlight exceeded doesn't tell you much um yeah and that's kind of the",
    "start": "750560",
    "end": "757800"
  },
  {
    "text": "challenges we had we all um face those challenges and also found a fix to this",
    "start": "757800",
    "end": "763480"
  },
  {
    "text": "but that's just something to keep in mind on the usage size conative is very easy to use and it has simple interfaces",
    "start": "763480",
    "end": "769560"
  },
  {
    "text": "on the administrator side um you have to be very knowledgeable in all the systems you're using be it Kafka rabit mq",
    "start": "769560",
    "end": "775959"
  },
  {
    "text": "conative itself kubernetes how kubernetes works the programming Lang languages that are being used into",
    "start": "775959",
    "end": "781760"
  },
  {
    "text": "context of the customer so it's very I guess you have",
    "start": "781760",
    "end": "787279"
  },
  {
    "text": "to have a broad skill set if you want to deploy it as an admin a recommendation from my side is",
    "start": "787279",
    "end": "794320"
  },
  {
    "text": "load and Chaos tests um your conative deployment very uh from the start so use",
    "start": "794320",
    "end": "799519"
  },
  {
    "text": "something like chaos smesh um use something like k6 or what we used was a",
    "start": "799519",
    "end": "804880"
  },
  {
    "text": "hyper foil I think we use it to test it and get some histograms to see how works in your system do some back of back of",
    "start": "804880",
    "end": "811480"
  },
  {
    "text": "the envelope math to figure out what is your throughput with your Kafka so that you get a realistic estimate of the",
    "start": "811480",
    "end": "817560"
  },
  {
    "text": "boundaries you were going to push um if you are in a regulated environment like public sector compliance think about",
    "start": "817560",
    "end": "824320"
  },
  {
    "text": "that in the beginning not at the end or you will face problems um and um yeah consider self",
    "start": "824320",
    "end": "830320"
  },
  {
    "text": "service so enable the users that they can do it themselves and just help them on the knowledge part develop experience",
    "start": "830320",
    "end": "837880"
  },
  {
    "text": "is key um that is what we found out so make it even easier than the normal docs",
    "start": "837880",
    "end": "843440"
  },
  {
    "text": "and tools are doing it create something that is uh unique to the customer experience or the environment that",
    "start": "843440",
    "end": "849040"
  },
  {
    "text": "you're working in um keep an issue lock about all the infrastructure things you're finding we have a structure for",
    "start": "849040",
    "end": "854959"
  },
  {
    "text": "that we always document root cause assumption solution and ticket link um optimize the workflows if you have",
    "start": "854959",
    "end": "861000"
  },
  {
    "text": "shared responsibilities and create a unified observability plane above all your",
    "start": "861000",
    "end": "866920"
  },
  {
    "text": "services especially in the event part because you're then working with distributed systems so that is the",
    "start": "866920",
    "end": "872480"
  },
  {
    "text": "recommendations I can give and uh yeah give it a guy try try out K native um so",
    "start": "872480",
    "end": "878320"
  },
  {
    "text": "far for our use case we are very happy with it and um we are surprised that we could set up something like this in a",
    "start": "878320",
    "end": "884399"
  },
  {
    "text": "very highly regulated environment so yeah that's for my part thank",
    "start": "884399",
    "end": "890199"
  },
  {
    "text": "you um there is a use case study on this K native Eventing on cncf website this",
    "start": "894839",
    "end": "900240"
  },
  {
    "text": "is the QR code for that and I'll upload the slide deck later so do check it",
    "start": "900240",
    "end": "905279"
  },
  {
    "text": "out all right so I guess I'm next so my name is Ricardo I'm a company engineer at CERN I'm also in the to and the newly",
    "start": "905279",
    "end": "913560"
  },
  {
    "text": "formed technical advisor Board of the cncf I'll give like I I guess everyone",
    "start": "913560",
    "end": "919600"
  },
  {
    "text": "knows more or less what CERN is about but basically we are a large Physics laboratory and we have large",
    "start": "919600",
    "end": "925800"
  },
  {
    "text": "requirements in terms of data storage uh and also analyzing processing the",
    "start": "925800",
    "end": "931880"
  },
  {
    "text": "data so we we keep looking at all sorts of technologies that can help us uh today and in what's coming in a few",
    "start": "931880",
    "end": "939240"
  },
  {
    "text": "years as well uh so we've been using K native for inference for quite a while",
    "start": "939240",
    "end": "945959"
  },
  {
    "text": "um also via copf flow um we have uh strong requirements in in in terms of U",
    "start": "945959",
    "end": "953199"
  },
  {
    "text": "machine learning that are uh speeding up pretty quickly I'm sure everyone has been here hearing about gen llms but",
    "start": "953199",
    "end": "960880"
  },
  {
    "text": "actually there's a lot more around machine learning that was there uh more than a year ago uh even more than 10",
    "start": "960880",
    "end": "967759"
  },
  {
    "text": "years ago so these things um are just becoming more relevant but uh but",
    "start": "967759",
    "end": "974000"
  },
  {
    "text": "they've been there for a while so um the requirements we have for this sort of services that we we run are integration",
    "start": "974000",
    "end": "981560"
  },
  {
    "text": "with gpus this has been a big thing since uh since a while uh and also the",
    "start": "981560",
    "end": "986959"
  },
  {
    "text": "integration with uh better ways to improve GPU utilization and efficiency concurrency uh things",
    "start": "986959",
    "end": "994600"
  },
  {
    "text": "like Nvidia time slicing and PS make all these sort of things and for us it's",
    "start": "994600",
    "end": "999720"
  },
  {
    "text": "very important to have a platform that uh gives us uh easy access to to the sort of things like the Nvidia GPU",
    "start": "999720",
    "end": "1006759"
  },
  {
    "text": "operator which we already use elsewhere as well so in the in the right side you see a a picture of uh multiple models",
    "start": "1006759",
    "end": "1013560"
  },
  {
    "text": "being served uh the fact that we can actually use uh even different back ends for for the serving is quite quite",
    "start": "1013560",
    "end": "1020120"
  },
  {
    "text": "relevant uh K native also gives us an easy way to to manage those Services",
    "start": "1020120",
    "end": "1025640"
  },
  {
    "text": "versioning roll outs rolling back as well giving different endpoints to to people as well autoscaling and I'll talk",
    "start": "1025640",
    "end": "1032199"
  },
  {
    "text": "a bit about that and this is what we've been using basically in production for for a while uh there are other use cases",
    "start": "1032199",
    "end": "1039160"
  },
  {
    "text": "that pop up uh that are quite interesting so I'll talk about two of them the bottom left one uh is about the",
    "start": "1039160",
    "end": "1046280"
  },
  {
    "text": "basically the key uh use casee have a turn which is when the data comes in we",
    "start": "1046280",
    "end": "1051400"
  },
  {
    "text": "get what we call Raw data and we store it in a back end in this case I put cfs3 but it can actually be uh the actual",
    "start": "1051400",
    "end": "1058400"
  },
  {
    "text": "storage system is not today uh s in S3 but for this data but I give an example",
    "start": "1058400",
    "end": "1063720"
  },
  {
    "text": "because this is the use case we have so we would push the raw data and we' rely on events on the S3 side to trigger um",
    "start": "1063720",
    "end": "1070640"
  },
  {
    "text": "um the analysis the first step analysis that would generate something we call estd which is event summary data and",
    "start": "1070640",
    "end": "1077200"
  },
  {
    "text": "this would generate output that gets pushed again into our back end storage this triggers another event that gives",
    "start": "1077200",
    "end": "1083600"
  },
  {
    "text": "the next step which is the aod which is the analysis object data and this is what then gets pushed to the uh physics",
    "start": "1083600",
    "end": "1090640"
  },
  {
    "text": "groups so this this sort of U uh way to do workflows uh is actually quite",
    "start": "1090640",
    "end": "1096400"
  },
  {
    "text": "interesting because we can manage the the processing part uh on the server side instead of having to like republish",
    "start": "1096400",
    "end": "1103280"
  },
  {
    "text": "the software to run the workflows on large scale batch systems and give users the responsibility of maintaining those",
    "start": "1103280",
    "end": "1109080"
  },
  {
    "text": "so there's there's a nice use case there to follow it is not in production it's something we keep uh trying and we still",
    "start": "1109080",
    "end": "1114360"
  },
  {
    "text": "don't have it figured out then the other one is gitlab C uh there's a lot of",
    "start": "1114360",
    "end": "1119760"
  },
  {
    "text": "requests for to do more than what you can do uh with continuous integration uh when it's integrated the repost uh and",
    "start": "1119760",
    "end": "1126679"
  },
  {
    "text": "to use those web Hooks and triggers to to uh use manage services that can be",
    "start": "1126679",
    "end": "1132159"
  },
  {
    "text": "again versioned and managed elsewhere so those are the two we're looking at uh",
    "start": "1132159",
    "end": "1137360"
  },
  {
    "text": "regarding challenges so again we do machine learning one of the big issues if you've I've given a couple of talks",
    "start": "1137360",
    "end": "1143480"
  },
  {
    "text": "about this as well elsewhere but we have very large images um these are not necessarily U machine learning models",
    "start": "1143480",
    "end": "1150159"
  },
  {
    "text": "but just the software we manage uh image distribution is a big thing for this",
    "start": "1150159",
    "end": "1155280"
  },
  {
    "text": "sort of uh serving um um use cases it's even more important because you want the",
    "start": "1155280",
    "end": "1161480"
  },
  {
    "text": "the starts to be pretty fast so the images have to be either pre-distributed but if you have several versions of",
    "start": "1161480",
    "end": "1167159"
  },
  {
    "text": "software like this you're talking about about potentially terabytes of data that have to be on the nodes so we've been",
    "start": "1167159",
    "end": "1172720"
  },
  {
    "text": "looking for a few years into this sort of lazy pulling uh where you just instead of pulling the full image and",
    "start": "1172720",
    "end": "1178280"
  },
  {
    "text": "starting the service you actually start immediately and you pull the files you actually need at runtime and there's",
    "start": "1178280",
    "end": "1184320"
  },
  {
    "text": "some nice integration in continuity I put here an example the benefits are dramatic you can see the Improvement on",
    "start": "1184320",
    "end": "1190360"
  },
  {
    "text": "pulling times from minutes to just a few seconds and then the execu the the",
    "start": "1190360",
    "end": "1196039"
  },
  {
    "text": "Ingress is also very important we we move a lot less data around so so this this makes a big difference um The",
    "start": "1196039",
    "end": "1203320"
  },
  {
    "text": "Challenge another challenge we have is that we actually don't have a big use case for service mesh elsewhere um so we",
    "start": "1203320",
    "end": "1209360"
  },
  {
    "text": "had to learnto when we started looking at it um just for the specific use case",
    "start": "1209360",
    "end": "1214520"
  },
  {
    "text": "so the knowledge about uh this tool is not necessarily spread across the teams",
    "start": "1214520",
    "end": "1220559"
  },
  {
    "text": "uh which makes it a bit harder to to manage uh when when we have incidents uh the other challenge we have",
    "start": "1220559",
    "end": "1227320"
  },
  {
    "text": "is that the remote serving is often done in aircap environments close to the machines uh so this is not a use case",
    "start": "1227320",
    "end": "1234039"
  },
  {
    "text": "we've explored completely but it means that we have to have some sort of offline replication of of the things",
    "start": "1234039",
    "end": "1239880"
  },
  {
    "text": "that need to be served now I'll finish with the the needs that we see for for our use cases",
    "start": "1239880",
    "end": "1246559"
  },
  {
    "text": "in the future so we do have a lot of uh ml coming uh bigger bigger models until",
    "start": "1246559",
    "end": "1253080"
  },
  {
    "text": "now we actually didn't have that big models uh we start having a lot of bigger models but also so uh the some of",
    "start": "1253080",
    "end": "1259600"
  },
  {
    "text": "the ml use cases they actually rely on the container to have the model but they rely on a lot of external data that is",
    "start": "1259600",
    "end": "1265799"
  },
  {
    "text": "not inside the container image which means that all these benefits that I mentioned before of optimizing cold",
    "start": "1265799",
    "end": "1271880"
  },
  {
    "text": "start um they become an issue when actually you're pulling uh gigabytes of",
    "start": "1271880",
    "end": "1277120"
  },
  {
    "text": "additional data at at at start so this becomes a quite a big issue it's not",
    "start": "1277120",
    "end": "1282720"
  },
  {
    "text": "something that the traditional container or oci registry really handles so it's something that the community not only K",
    "start": "1282720",
    "end": "1289279"
  },
  {
    "text": "native will have to figure out uh the other one is very large models uh we",
    "start": "1289279",
    "end": "1294799"
  },
  {
    "text": "traditionally had pretty small models I would say some of them start being big enough to not fit in memory on a single",
    "start": "1294799",
    "end": "1301679"
  },
  {
    "text": "GPU so something that also again this has to be figured out how how we'll",
    "start": "1301679",
    "end": "1306760"
  },
  {
    "text": "handle this kind of use case properly uh the other one is we want to make the best use of GPU so um making sure that",
    "start": "1306760",
    "end": "1314440"
  },
  {
    "text": "they are not idle uh that when they are claimed by a uh serving component that",
    "start": "1314440",
    "end": "1319679"
  },
  {
    "text": "actually we can run more than one workload maybe on the same GPU so that we don't have them idle when when things",
    "start": "1319679",
    "end": "1325480"
  },
  {
    "text": "are just hanging hang hanging there waiting for new requests even before they are cleaned up for being idle uh so",
    "start": "1325480",
    "end": "1333240"
  },
  {
    "text": "for gpus we've been doing things like M with partitioning slicing slicing but there are challenges because um um",
    "start": "1333240",
    "end": "1340840"
  },
  {
    "text": "unless you do physical partition we make memory sharing is not obvious so uh we",
    "start": "1340840",
    "end": "1346799"
  },
  {
    "text": "are looking into things like the uh Dr in kubernetes that is kind of promising for this uh the other one is",
    "start": "1346799",
    "end": "1353039"
  },
  {
    "text": "multicluster so we are by Design multicluster on premises because we have",
    "start": "1353039",
    "end": "1359080"
  },
  {
    "text": "this requirement of different types of resources that are located in different areas uh but also we want to burst and",
    "start": "1359080",
    "end": "1365640"
  },
  {
    "text": "scale out to public clouds and to give a good experience to our users uh while",
    "start": "1365640",
    "end": "1370679"
  },
  {
    "text": "trying to do deployments that cross administrative boundaries is not obvious uh especially because kubernetes was not",
    "start": "1370679",
    "end": "1377279"
  },
  {
    "text": "designed from the start to be multicluster so scheduling is kind of still a big issue that we have to figure",
    "start": "1377279",
    "end": "1383000"
  },
  {
    "text": "out so it's not again a particular issue for K native but I think it's something that K will have to integrate properly",
    "start": "1383000",
    "end": "1389159"
  },
  {
    "text": "to to serve this use cases and with this I pass",
    "start": "1389159",
    "end": "1395360"
  },
  {
    "text": "to thanks for um hi everyone um my name is Ado",
    "start": "1396200",
    "end": "1402440"
  },
  {
    "text": "garciaa I am an open source engineer with chenard uh uh we are a supply chain",
    "start": "1402440",
    "end": "1408559"
  },
  {
    "text": "security company for those are familiar with the supply chain security space what we do is we protect you from uh to",
    "start": "1408559",
    "end": "1416840"
  },
  {
    "text": "make sure that software that you inest uh is safe to run and it's it can",
    "start": "1416840",
    "end": "1422039"
  },
  {
    "text": "be safely used to build your applications on top of it um so obviously that involves lots of Open",
    "start": "1422039",
    "end": "1428279"
  },
  {
    "text": "Source um and as part of that uh we use",
    "start": "1428279",
    "end": "1433520"
  },
  {
    "text": "K native to power all of our sources all of our services so and so I'm going to give you a brief",
    "start": "1433520",
    "end": "1441600"
  },
  {
    "text": "overview of one of our services which is uh charden force uh chard enforces is",
    "start": "1441600",
    "end": "1447480"
  },
  {
    "text": "our um supply chain security uh uh control plane if you want to uh see it",
    "start": "1447480",
    "end": "1454360"
  },
  {
    "text": "like that uh chard enforce performs many functions um it uh the way it operates",
    "start": "1454360",
    "end": "1460200"
  },
  {
    "text": "is that it uh observes or workloads in your cluster and uh it reports back what",
    "start": "1460200",
    "end": "1465320"
  },
  {
    "text": "you're running and based on that information we perform a lot of uh uh it has a lot of features to act on that uh",
    "start": "1465320",
    "end": "1472000"
  },
  {
    "text": "so it can do uh from security scans in just t boms uh it it will tell you",
    "start": "1472000",
    "end": "1478600"
  },
  {
    "text": "what's running where it can it also does a multicluster um multi it has multicluster",
    "start": "1478600",
    "end": "1485120"
  },
  {
    "text": "capabilities and uh and you're going to see how we do it in a little bit so those",
    "start": "1485120",
    "end": "1491159"
  },
  {
    "text": "Services all of them are powered by K native servers uh serving um the most uh",
    "start": "1491159",
    "end": "1498480"
  },
  {
    "text": "we uh our changer enforce practically has no um Ro deployments uh or all of",
    "start": "1498480",
    "end": "1505919"
  },
  {
    "text": "our services are uh deployed as uh using uh gr native uh serving um and this",
    "start": "1505919",
    "end": "1513200"
  },
  {
    "text": "includes around 30 35 features that uh include all of those uh things like uh",
    "start": "1513200",
    "end": "1520120"
  },
  {
    "text": "like like the uh like those me I I mentioned before um now uh we also use",
    "start": "1520120",
    "end": "1527520"
  },
  {
    "text": "um uh Eventing uh and Eventing is where to",
    "start": "1527520",
    "end": "1533520"
  },
  {
    "text": "report back to the users uh all of the all of the events that we uh detect in",
    "start": "1533520",
    "end": "1539120"
  },
  {
    "text": "your clusters so for example when we uh perform a vulnerability scan on your workloads uh we use Eventing to send the",
    "start": "1539120",
    "end": "1547799"
  },
  {
    "text": "notifications uh back to the user and to the console uh we also um we also uh use",
    "start": "1547799",
    "end": "1556360"
  },
  {
    "text": "Eventing for the life cycle notifications of our admission controller so we have enforce scan um",
    "start": "1556360",
    "end": "1563720"
  },
  {
    "text": "has an admission controller that lets you uh admit or deny workloads based on",
    "start": "1563720",
    "end": "1569320"
  },
  {
    "text": "uh policies that you define in your uh that you define uh for each of your",
    "start": "1569320",
    "end": "1575039"
  },
  {
    "text": "workloads uh and you will use Eventing to communicate all of those um now",
    "start": "1575039",
    "end": "1581760"
  },
  {
    "text": "inside of your closer we this is optional but we can run um an agent and",
    "start": "1581760",
    "end": "1587760"
  },
  {
    "text": "that agent is uh built it's the one that observes the running workloads on your closers and reports them back to uh to",
    "start": "1587760",
    "end": "1594240"
  },
  {
    "text": "our SAS and that one is built using the K native controller",
    "start": "1594240",
    "end": "1600520"
  },
  {
    "text": "framework um and so we discussed talking about uh",
    "start": "1600520",
    "end": "1607000"
  },
  {
    "text": "some of the challenges um inside of chenard we have uh lots of conative",
    "start": "1607000",
    "end": "1612559"
  },
  {
    "text": "expertise um this uh and uh I'm I try",
    "start": "1612559",
    "end": "1617760"
  },
  {
    "text": "I'm trying to collect what I heard from our Engineers um in one single slide um",
    "start": "1617760",
    "end": "1624120"
  },
  {
    "text": "and this boils down to one thing um so in in the main problem that we have with",
    "start": "1624120",
    "end": "1632120"
  },
  {
    "text": "gative when running it was uh making sure that the rabit mq broker was doing",
    "start": "1632120",
    "end": "1638799"
  },
  {
    "text": "what we wanted it to do um so uh the main the main problem that we",
    "start": "1638799",
    "end": "1645200"
  },
  {
    "text": "faced was that uh interacting with uh the project can be a",
    "start": "1645200",
    "end": "1652200"
  },
  {
    "text": "little bit slow uh we we are proud to be serving back uh submitting back",
    "start": "1652200",
    "end": "1658880"
  },
  {
    "text": "contributions to the project uh but uh the the broker is in a I don't know in",
    "start": "1658880",
    "end": "1665640"
  },
  {
    "text": "in need of help uh so when trying to find more documentation when trying to",
    "start": "1665640",
    "end": "1671440"
  },
  {
    "text": "uh get advice from the maintainers it has been some a little bit of a problem",
    "start": "1671440",
    "end": "1676960"
  },
  {
    "text": "um so some of it has to do with the fact that uh G native abstracts a lot of",
    "start": "1676960",
    "end": "1682519"
  },
  {
    "text": "things for you but it also has to make sure that the rabit mq backend is running properly so it has to take care",
    "start": "1682519",
    "end": "1688760"
  },
  {
    "text": "of a lot of things but when you have to find- tun the the features in the in the",
    "start": "1688760",
    "end": "1693799"
  },
  {
    "text": "in the rabbit mq back end sometimes it's difficult you have to deal with annotations and uh it can be difficult",
    "start": "1693799",
    "end": "1700480"
  },
  {
    "text": "to pass them to the back end so um at this point I would like to so one thing",
    "start": "1700480",
    "end": "1706640"
  },
  {
    "text": "I forgot to mention is I have uh this year I had the privilege to serve on the K native steam committee representing my",
    "start": "1706640",
    "end": "1713440"
  },
  {
    "text": "company uh in the end user seat um together with Nina and um",
    "start": "1713440",
    "end": "1720679"
  },
  {
    "text": "so I wanted to finish on this land because I would like to like open uh the call for participation in",
    "start": "1720679",
    "end": "1728320"
  },
  {
    "text": "the project uh so if you are a k native user um you can do lots of things to",
    "start": "1728320",
    "end": "1734399"
  },
  {
    "text": "help the project starting with uh helping struck you uh we're interested in",
    "start": "1734399",
    "end": "1739880"
  },
  {
    "text": "hearing from you uh who's using it and how but more importantly try to approach",
    "start": "1739880",
    "end": "1745559"
  },
  {
    "text": "and see some of the uh help some of the issues that are outstanding so while",
    "start": "1745559",
    "end": "1750600"
  },
  {
    "text": "things can work very well uh we need your help to make them easier to run um",
    "start": "1750600",
    "end": "1756200"
  },
  {
    "text": "so with that I present it tonight thank you for me learning about that K native",
    "start": "1756200",
    "end": "1762919"
  },
  {
    "text": "was serving AIML long before they were mainstream was was the key with certain use case um but I found those end users",
    "start": "1762919",
    "end": "1772039"
  },
  {
    "text": "from every part of the world like Eventing use case serving use case and everything we do have some time if you",
    "start": "1772039",
    "end": "1779399"
  },
  {
    "text": "have couple of questions to our end users if you have conative related questions please find us on cncf slack",
    "start": "1779399",
    "end": "1785919"
  },
  {
    "text": "but you might not have access to the end user so if you have questions for them we can take them right now but I would",
    "start": "1785919",
    "end": "1791720"
  },
  {
    "text": "ask you to come to that mic over there so that we can actually hear the questions and record them so",
    "start": "1791720",
    "end": "1799159"
  },
  {
    "text": "so [Laughter]",
    "start": "1799159",
    "end": "1805150"
  },
  {
    "text": "[Applause] yes all right is this thing on yes uh my",
    "start": "1805150",
    "end": "1812600"
  },
  {
    "text": "question is for Norris you mentioned that the reconciler has issues with uh changes to K native resources what were",
    "start": "1812600",
    "end": "1820039"
  },
  {
    "text": "those and are those things that anybody that uses K native needs to worry about um depends on your deployment I guess uh",
    "start": "1820039",
    "end": "1826600"
  },
  {
    "text": "so how many so I think we have a unique com combination we deploy and all the",
    "start": "1826600",
    "end": "1831720"
  },
  {
    "text": "projects deploy all their stuff with ag CD so you can imagine we are talking about maybe hundreds maybe thousands of",
    "start": "1831720",
    "end": "1839559"
  },
  {
    "text": "custom resources um that might be changed during the reconciliation Loop and we",
    "start": "1839559",
    "end": "1846720"
  },
  {
    "text": "specifically have that problem usually with the Kafka controller somewhere so we think it's pinpointed somewhere in",
    "start": "1846720",
    "end": "1853039"
  },
  {
    "text": "the CF reconciliation when we change stuffff um but it's very hard to debug as I said the error message are not very",
    "start": "1853039",
    "end": "1859440"
  },
  {
    "text": "descriptive and you have all this um layering so you have conative the Eventing core mechanism then you have",
    "start": "1859440",
    "end": "1866200"
  },
  {
    "text": "the Kafka controller then you have Kafka itself so to pinpoint very clearly what",
    "start": "1866200",
    "end": "1871240"
  },
  {
    "text": "happened where is kind of tricky um so we are still figuring out",
    "start": "1871240",
    "end": "1876679"
  },
  {
    "text": "what really is the reason could also be our deployment or kubernetes configuration in the end but currently",
    "start": "1876679",
    "end": "1882480"
  },
  {
    "text": "we are sure it's more conative issue yeah and since there's no other",
    "start": "1882480",
    "end": "1887519"
  },
  {
    "text": "questions I'll ask another one this is to anybody um what's often touted as a as a huge advantage of K native is the",
    "start": "1887519",
    "end": "1894240"
  },
  {
    "text": "ability to scale to zero um but what I'm wondering is when you get into a production environment I understand that",
    "start": "1894240",
    "end": "1900360"
  },
  {
    "text": "maybe in development and in early stages this is great because I can scale completely to zero but in a production",
    "start": "1900360",
    "end": "1905639"
  },
  {
    "text": "environment I can see if I have like core weaves use case this might be super useful because a customer only wants to",
    "start": "1905639",
    "end": "1912080"
  },
  {
    "text": "run an ml pipeline once a day or something um but uh in larger production",
    "start": "1912080",
    "end": "1918320"
  },
  {
    "text": "environments where I'm constantly running uh or doing work um is scale to zero really that valuable yeah so like",
    "start": "1918320",
    "end": "1925440"
  },
  {
    "text": "some of our customers scale to zero doesn't do them anything they're they're setting their Min scale to you know five",
    "start": "1925440",
    "end": "1931240"
  },
  {
    "text": "50 nodes five nodes 100 nodes however many pods you know they need to run their back end other customers like I",
    "start": "1931240",
    "end": "1936840"
  },
  {
    "text": "said they do fine tunes and fine tunes are very specific and so they have a tendency to allow scale to zero because",
    "start": "1936840",
    "end": "1943440"
  },
  {
    "text": "they're okay with that startup time uh given that they have you know hundreds of these fine tunes sitting around they",
    "start": "1943440",
    "end": "1950080"
  },
  {
    "text": "don't want to be paying for all those resources when no one's using them and",
    "start": "1950080",
    "end": "1955279"
  },
  {
    "text": "so they've made the trade-off decision that like they're okay with the startup time these customers have generally done",
    "start": "1955279",
    "end": "1960480"
  },
  {
    "text": "good with optimizing their startup time so we're not talking about five 10 minute startup times we're talking about sub 30 second startup times uh they're",
    "start": "1960480",
    "end": "1967720"
  },
  {
    "text": "okay with that tradeoff and so there are use cases that we see some customers in production utilize it a decent bit and",
    "start": "1967720",
    "end": "1974919"
  },
  {
    "text": "other customers not at all so it's it's very use case uh centered I will say the",
    "start": "1974919",
    "end": "1980960"
  },
  {
    "text": "functionality in K native that allows scale to zero and allows the queuing in the activator is also very useful for",
    "start": "1980960",
    "end": "1987880"
  },
  {
    "text": "burst so while your containers are spinning up especially with long container start times if you get hit by",
    "start": "1987880",
    "end": "1993440"
  },
  {
    "text": "a lot of requests the same thing that allows scale to zero handles burst and queuing so like that being built in like",
    "start": "1993440",
    "end": "2000320"
  },
  {
    "text": "that functionality and that c functionality helps you out even if you're not using scale the zero uh I guess is what I'm saying so it does a",
    "start": "2000320",
    "end": "2007600"
  },
  {
    "text": "really good job of handling long container start times where you need to buffer thousands of requests before you",
    "start": "2007600",
    "end": "2012919"
  },
  {
    "text": "have containers ready as well thank you I'll just add if you don't want in production cases you can",
    "start": "2012919",
    "end": "2020200"
  },
  {
    "text": "always keep scale to one but that was a good do we have one",
    "start": "2020200",
    "end": "2025679"
  },
  {
    "text": "more question yeah hi uh my question is for Ricardo um",
    "start": "2025679",
    "end": "2031440"
  },
  {
    "text": "you had shown that you have a um multi-step physics models that you run",
    "start": "2031440",
    "end": "2037679"
  },
  {
    "text": "um there are a number of different ways you can um do that um y k native and is",
    "start": "2037679",
    "end": "2044960"
  },
  {
    "text": "are there just specific use cases you use it k for and um right so maybe I go",
    "start": "2044960",
    "end": "2051720"
  },
  {
    "text": "back to that slide quickly uh so you're talking about the bottom left is that it",
    "start": "2051720",
    "end": "2058158"
  },
  {
    "text": "yeah so that's kind of a still experimentation we are evaluating for for this sort of use case uh this is not",
    "start": "2058159",
    "end": "2064320"
  },
  {
    "text": "for physics models this for workflows to to do what we call event reconstruction which is when the data comes from the",
    "start": "2064320",
    "end": "2070398"
  },
  {
    "text": "detectors it needs like we have the raw data and we need to do the Reconstruction to see what actually",
    "start": "2070399",
    "end": "2075760"
  },
  {
    "text": "happens happened in the collisions so this is uh some workflows that we have",
    "start": "2075760",
    "end": "2081320"
  },
  {
    "text": "for 20 years in place and the way we usually do this we is we deploy some",
    "start": "2081320",
    "end": "2086760"
  },
  {
    "text": "sort of batch workflows on a dag but the software that is being run uh has to be",
    "start": "2086760",
    "end": "2092158"
  },
  {
    "text": "managed by the physics groups uh by the people submitting the jobs they need to describe the jobs which versions of the",
    "start": "2092159",
    "end": "2098480"
  },
  {
    "text": "the software should be running for those workflows all the steps have to be defined so but the main motivation for",
    "start": "2098480",
    "end": "2104240"
  },
  {
    "text": "this is that the components doing the data collection they will just store it and this will trigger events that",
    "start": "2104240",
    "end": "2110200"
  },
  {
    "text": "trigger the Reconstruction steps the the proper ones and also the actual reconstruction software is now an",
    "start": "2110200",
    "end": "2117680"
  },
  {
    "text": "endpoint an HTTP endpoint where the what is running there is managed by a system",
    "start": "2117680",
    "end": "2123560"
  },
  {
    "text": "administrator and can be described in in G and we can do get ups for that we",
    "start": "2123560",
    "end": "2128839"
  },
  {
    "text": "don't have to teach the users how to build their workflows and which versions",
    "start": "2128839",
    "end": "2133920"
  },
  {
    "text": "to use and all these things we can do as we do for services we can actually offer",
    "start": "2133920",
    "end": "2139280"
  },
  {
    "text": "them a workflow an easy way to implement workflows now if this will actually be used at scale we don't know because",
    "start": "2139280",
    "end": "2145920"
  },
  {
    "text": "people are already used to to to using large P systems but it's a very interesting use case and building",
    "start": "2145920",
    "end": "2152800"
  },
  {
    "text": "complex workflows with this sort of Eventing model event and ser serving is actually quite easy and you can you can",
    "start": "2152800",
    "end": "2160200"
  },
  {
    "text": "describe it in a declarative way so there there's some value there I think thank you and I love the energy",
    "start": "2160200",
    "end": "2168079"
  },
  {
    "text": "though uh and we are out of time I'm just going to this is our QR code you know where to",
    "start": "2168079",
    "end": "2176640"
  },
  {
    "text": "find us the cncf SL Google Groups and um we have lot of tutorials there and if",
    "start": "2176640",
    "end": "2182720"
  },
  {
    "text": "you're still with us if you could leave uh feedback on our session that would be great thank you so much enjoy the rest",
    "start": "2182720",
    "end": "2188319"
  },
  {
    "text": "of the keepon and safe trip back home",
    "start": "2188319",
    "end": "2194240"
  }
]
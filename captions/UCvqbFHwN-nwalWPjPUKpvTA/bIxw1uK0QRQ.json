[
  {
    "text": "good morning everyone uh today we are",
    "start": "80",
    "end": "3919"
  },
  {
    "text": "going to talk about something very",
    "start": "3919",
    "end": "6080"
  },
  {
    "text": "peculiar uh how we managed to develop",
    "start": "6080",
    "end": "10000"
  },
  {
    "text": "and to create a platform to develop",
    "start": "10000",
    "end": "12000"
  },
  {
    "text": "digital twins in a hybrid cloud plus HPC",
    "start": "12000",
    "end": "16800"
  },
  {
    "text": "scenario right",
    "start": "16800",
    "end": "19320"
  },
  {
    "text": "so first of all presentations i'm Diego",
    "start": "19320",
    "end": "22800"
  },
  {
    "text": "Changotini from INF that is the National",
    "start": "22800",
    "end": "25439"
  },
  {
    "text": "Institute for Nuclear Physics in Italy",
    "start": "25439",
    "end": "28240"
  },
  {
    "text": "and here with me on the stage there is",
    "start": "28240",
    "end": "30160"
  },
  {
    "text": "Matabunino that is from the CERN open",
    "start": "30160",
    "end": "32640"
  },
  {
    "text": "lab so you might have heard CERN inafan",
    "start": "32640",
    "end": "37360"
  },
  {
    "text": "it's on the same kind of of track we are",
    "start": "37360",
    "end": "40320"
  },
  {
    "text": "doing physics with particles and so why",
    "start": "40320",
    "end": "44000"
  },
  {
    "text": "we are here talking about um digital",
    "start": "44000",
    "end": "47480"
  },
  {
    "text": "twins well there are several reasons uh",
    "start": "47480",
    "end": "50800"
  },
  {
    "text": "and several institute and projects that",
    "start": "50800",
    "end": "53520"
  },
  {
    "text": "are working into whatever we are",
    "start": "53520",
    "end": "55920"
  },
  {
    "text": "presenting today i give you here just",
    "start": "55920",
    "end": "59280"
  },
  {
    "text": "the links so you can check later if",
    "start": "59280",
    "end": "60960"
  },
  {
    "text": "you're",
    "start": "60960",
    "end": "61960"
  },
  {
    "text": "interested what are digital twins then i",
    "start": "61960",
    "end": "66000"
  },
  {
    "text": "love this uh sentence that summarize",
    "start": "66000",
    "end": "69439"
  },
  {
    "text": "very well uh what should be uh a digital",
    "start": "69439",
    "end": "73119"
  },
  {
    "text": "twin so it's a digital representation of",
    "start": "73119",
    "end": "75920"
  },
  {
    "text": "a real world system and yeah it it's not",
    "start": "75920",
    "end": "80200"
  },
  {
    "text": "working like that but kind of you know",
    "start": "80200",
    "end": "84040"
  },
  {
    "text": "so you have projecting wildfire and you",
    "start": "84040",
    "end": "87600"
  },
  {
    "text": "want to uh forecast whatever will happen",
    "start": "87600",
    "end": "90640"
  },
  {
    "text": "in in case of this disaster or in this",
    "start": "90640",
    "end": "95360"
  },
  {
    "text": "kind of other disaster you want to",
    "start": "95360",
    "end": "98079"
  },
  {
    "text": "understand the impact of floating on",
    "start": "98079",
    "end": "100720"
  },
  {
    "text": "your um landscape",
    "start": "100720",
    "end": "104159"
  },
  {
    "text": "and then there are other digital twins",
    "start": "104159",
    "end": "106640"
  },
  {
    "text": "that can be very useful and for instance",
    "start": "106640",
    "end": "110000"
  },
  {
    "text": "one that was just uh mentioned before uh",
    "start": "110000",
    "end": "113439"
  },
  {
    "text": "in the nice panel that was mentioned",
    "start": "113439",
    "end": "117040"
  },
  {
    "text": "before uh is particle detection so we",
    "start": "117040",
    "end": "120079"
  },
  {
    "text": "have this big camera that are uh trained",
    "start": "120079",
    "end": "124000"
  },
  {
    "text": "and projected to create photos detailed",
    "start": "124000",
    "end": "128160"
  },
  {
    "text": "pictures of what happens between",
    "start": "128160",
    "end": "129840"
  },
  {
    "text": "particles why not creating a digital",
    "start": "129840",
    "end": "132400"
  },
  {
    "text": "team of these big cameras and facilitate",
    "start": "132400",
    "end": "134959"
  },
  {
    "text": "our life and same for noise we have to",
    "start": "134959",
    "end": "138160"
  },
  {
    "text": "do precise measurement we can simulate",
    "start": "138160",
    "end": "140959"
  },
  {
    "text": "noise or teach a machine to simulate the",
    "start": "140959",
    "end": "143920"
  },
  {
    "text": "real world noise we have in our",
    "start": "143920",
    "end": "148239"
  },
  {
    "text": "environments from all these use cases",
    "start": "148360",
    "end": "150959"
  },
  {
    "text": "that share very similar uh needs we",
    "start": "150959",
    "end": "155840"
  },
  {
    "text": "started investigating possibility to",
    "start": "155840",
    "end": "157680"
  },
  {
    "text": "create an engine for digital twins to",
    "start": "157680",
    "end": "160319"
  },
  {
    "text": "something that will serve multiple",
    "start": "160319",
    "end": "162920"
  },
  {
    "text": "communities and make them adopt and use",
    "start": "162920",
    "end": "167440"
  },
  {
    "text": "resources that are shared across",
    "start": "167440",
    "end": "169280"
  },
  {
    "text": "different providers so you see intertwin",
    "start": "169280",
    "end": "171760"
  },
  {
    "text": "is the project European project uh where",
    "start": "171760",
    "end": "174000"
  },
  {
    "text": "we are working this out and on one end",
    "start": "174000",
    "end": "177200"
  },
  {
    "text": "we have the providers so that can span",
    "start": "177200",
    "end": "180560"
  },
  {
    "text": "from cloud providers to supercomputers",
    "start": "180560",
    "end": "184080"
  },
  {
    "text": "euro HPC",
    "start": "184080",
    "end": "186599"
  },
  {
    "text": "supercomputers and on the other side you",
    "start": "186599",
    "end": "188800"
  },
  {
    "text": "have frameworks that users use to uh do",
    "start": "188800",
    "end": "192560"
  },
  {
    "text": "their digital twins what are the",
    "start": "192560",
    "end": "195120"
  },
  {
    "text": "challenges there so you have to provide",
    "start": "195120",
    "end": "198959"
  },
  {
    "text": "a platform that is capable to support",
    "start": "198959",
    "end": "202400"
  },
  {
    "text": "all different use cases all different",
    "start": "202400",
    "end": "204760"
  },
  {
    "text": "frameworks but also you have to merge",
    "start": "204760",
    "end": "207120"
  },
  {
    "text": "that with the offloading capability of",
    "start": "207120",
    "end": "209760"
  },
  {
    "text": "every task on different kind of backends",
    "start": "209760",
    "end": "212799"
  },
  {
    "text": "that not necessarily are able to run uh",
    "start": "212799",
    "end": "215920"
  },
  {
    "text": "cloud payloads",
    "start": "215920",
    "end": "219000"
  },
  {
    "text": "finally since you have this multiplicity",
    "start": "219000",
    "end": "221599"
  },
  {
    "text": "of back ends you want to uh maintain all",
    "start": "221599",
    "end": "225280"
  },
  {
    "text": "your software as interoperable as",
    "start": "225280",
    "end": "227760"
  },
  {
    "text": "possible so you want to reproduce the",
    "start": "227760",
    "end": "229920"
  },
  {
    "text": "very same resource on any kind of back",
    "start": "229920",
    "end": "232840"
  },
  {
    "text": "ends so the challenge in a nutshell we",
    "start": "232840",
    "end": "236000"
  },
  {
    "text": "have a distributed hogenous",
    "start": "236000",
    "end": "239000"
  },
  {
    "text": "resources good and then we need to put",
    "start": "239000",
    "end": "242159"
  },
  {
    "text": "on top a common",
    "start": "242159",
    "end": "244439"
  },
  {
    "text": "interface two problems comes from here",
    "start": "244439",
    "end": "246959"
  },
  {
    "text": "so how we give access to the users to",
    "start": "246959",
    "end": "249760"
  },
  {
    "text": "this platform and how we maintain all",
    "start": "249760",
    "end": "252000"
  },
  {
    "text": "our workflows consistent to each other",
    "start": "252000",
    "end": "256079"
  },
  {
    "text": "so for instance starting from the",
    "start": "256079",
    "end": "258639"
  },
  {
    "text": "software and the containerology that can",
    "start": "258639",
    "end": "260880"
  },
  {
    "text": "come from different container runtime",
    "start": "260880",
    "end": "264040"
  },
  {
    "text": "interface plus we know that we have a",
    "start": "264040",
    "end": "267919"
  },
  {
    "text": "lots of users that actually don't care",
    "start": "267919",
    "end": "270960"
  },
  {
    "text": "where they are going to run they just",
    "start": "270960",
    "end": "272880"
  },
  {
    "text": "want their jobs to be done",
    "start": "272880",
    "end": "275600"
  },
  {
    "text": "fortunately enough in this case but also",
    "start": "275600",
    "end": "278400"
  },
  {
    "text": "in particle physics we start to",
    "start": "278400",
    "end": "280479"
  },
  {
    "text": "converging to a set of tools that are",
    "start": "280479",
    "end": "283840"
  },
  {
    "text": "cloud native so the main interface that",
    "start": "283840",
    "end": "286720"
  },
  {
    "text": "we face in most cases is Kubernetes so",
    "start": "286720",
    "end": "291120"
  },
  {
    "text": "we left out just with a uh a question",
    "start": "291120",
    "end": "294479"
  },
  {
    "text": "how we can merge a Kubernetes API access",
    "start": "294479",
    "end": "297600"
  },
  {
    "text": "to different kind of resources and we",
    "start": "297600",
    "end": "300479"
  },
  {
    "text": "listen before for quantum computing is",
    "start": "300479",
    "end": "303600"
  },
  {
    "text": "kind of the same challenge",
    "start": "303600",
    "end": "305680"
  },
  {
    "text": "so uh someone told me that on Tuesday",
    "start": "305680",
    "end": "308639"
  },
  {
    "text": "there were there was a nice talk about",
    "start": "308639",
    "end": "311440"
  },
  {
    "text": "uh this technology that is interlink",
    "start": "311440",
    "end": "313199"
  },
  {
    "text": "totally not uh not presented by me so",
    "start": "313199",
    "end": "317360"
  },
  {
    "text": "there is a demo for the solution that",
    "start": "317360",
    "end": "319280"
  },
  {
    "text": "I'm going to briefly introd introduce",
    "start": "319280",
    "end": "321360"
  },
  {
    "text": "here so if you're curious just check it",
    "start": "321360",
    "end": "323360"
  },
  {
    "text": "out and the idea is to create a plugable",
    "start": "323360",
    "end": "327199"
  },
  {
    "text": "system where we put adapters on top of",
    "start": "327199",
    "end": "330560"
  },
  {
    "text": "the remote resources that we want to",
    "start": "330560",
    "end": "332880"
  },
  {
    "text": "control through the Kubernetes",
    "start": "332880",
    "end": "335000"
  },
  {
    "text": "cluster and we try very hard to keep the",
    "start": "335000",
    "end": "337840"
  },
  {
    "text": "requirements for the providers the uh",
    "start": "337840",
    "end": "340479"
  },
  {
    "text": "less inbases possible so you plug",
    "start": "340479",
    "end": "343520"
  },
  {
    "text": "interlink on top your edge node here and",
    "start": "343520",
    "end": "348160"
  },
  {
    "text": "you're good to go basically you create a",
    "start": "348160",
    "end": "350000"
  },
  {
    "text": "virtual node based on virtual cublet",
    "start": "350000",
    "end": "351759"
  },
  {
    "text": "technology that is capable to schedule",
    "start": "351759",
    "end": "354080"
  },
  {
    "text": "pod on your zoom supercomput for",
    "start": "354080",
    "end": "357880"
  },
  {
    "text": "instance and yeah so why we choose this",
    "start": "357880",
    "end": "361919"
  },
  {
    "text": "way well in this way we are capable to",
    "start": "361919",
    "end": "365680"
  },
  {
    "text": "grant our users access to kubernetes in",
    "start": "365680",
    "end": "368400"
  },
  {
    "text": "interface with no compromise with no cds",
    "start": "368400",
    "end": "372000"
  },
  {
    "text": "everything just run like playing",
    "start": "372000",
    "end": "373840"
  },
  {
    "text": "kubernetes so you have pause with",
    "start": "373840",
    "end": "375919"
  },
  {
    "text": "annotation you select a virtual note and",
    "start": "375919",
    "end": "377919"
  },
  {
    "text": "voila you go end up into supercomputers",
    "start": "377919",
    "end": "380960"
  },
  {
    "text": "that do your machine learning pipeline",
    "start": "380960",
    "end": "382639"
  },
  {
    "text": "or your digital twin and everything is",
    "start": "382639",
    "end": "384880"
  },
  {
    "text": "reported back once learn it's a",
    "start": "384880",
    "end": "387680"
  },
  {
    "text": "community effort of course and the",
    "start": "387680",
    "end": "389440"
  },
  {
    "text": "community is very uh interested in",
    "start": "389440",
    "end": "392560"
  },
  {
    "text": "understanding how they pl can plug their",
    "start": "392560",
    "end": "394880"
  },
  {
    "text": "own providers and in fact we have not",
    "start": "394880",
    "end": "397360"
  },
  {
    "text": "only scientific use case but you can",
    "start": "397360",
    "end": "399199"
  },
  {
    "text": "find here in the list also enterprise",
    "start": "399199",
    "end": "401039"
  },
  {
    "text": "that try to uh plug their container as a",
    "start": "401039",
    "end": "403919"
  },
  {
    "text": "service solution in this way and the",
    "start": "403919",
    "end": "407360"
  },
  {
    "text": "latest news uh is that uh now this",
    "start": "407360",
    "end": "410639"
  },
  {
    "text": "project is part of the cloud native",
    "start": "410639",
    "end": "412400"
  },
  {
    "text": "sandbox we just uh passed the vote uh a",
    "start": "412400",
    "end": "415360"
  },
  {
    "text": "couple of months ago and so uh I take",
    "start": "415360",
    "end": "419199"
  },
  {
    "text": "this occasion to say that it's a really",
    "start": "419199",
    "end": "421440"
  },
  {
    "text": "thin and simple interface that is",
    "start": "421440",
    "end": "425039"
  },
  {
    "text": "perfect for uh introduction of new",
    "start": "425039",
    "end": "427759"
  },
  {
    "text": "commitment or wider communities so we",
    "start": "427759",
    "end": "430400"
  },
  {
    "text": "are really looking into get more people",
    "start": "430400",
    "end": "432720"
  },
  {
    "text": "on board on",
    "start": "432720",
    "end": "435000"
  },
  {
    "text": "this so we have an interpace if you wish",
    "start": "435000",
    "end": "438800"
  },
  {
    "text": "so a set of frameworks that can run on",
    "start": "438800",
    "end": "440960"
  },
  {
    "text": "different Kubernetes cluster that thanks",
    "start": "440960",
    "end": "443120"
  },
  {
    "text": "to this adapter can run on on VMs with",
    "start": "443120",
    "end": "446720"
  },
  {
    "text": "GPUs on HTC system like HD condo on",
    "start": "446720",
    "end": "450639"
  },
  {
    "text": "quantum we are trying uh to see how we",
    "start": "450639",
    "end": "453680"
  },
  {
    "text": "can what we can do with this in with a",
    "start": "453680",
    "end": "456080"
  },
  {
    "text": "Galatia supercomputer uh quantum",
    "start": "456080",
    "end": "458880"
  },
  {
    "text": "computing and then we have HPC centers",
    "start": "458880",
    "end": "462080"
  },
  {
    "text": "that were where we started we need these",
    "start": "462080",
    "end": "464639"
  },
  {
    "text": "kind of centers to create digital twins",
    "start": "464639",
    "end": "469039"
  },
  {
    "text": "so we create a cube ray for instance",
    "start": "469039",
    "end": "472400"
  },
  {
    "text": "from plain kubernetes and",
    "start": "472400",
    "end": "474840"
  },
  {
    "text": "chart",
    "start": "474840",
    "end": "476840"
  },
  {
    "text": "this spoon up different working nodes",
    "start": "476840",
    "end": "480319"
  },
  {
    "text": "but pay attention these working nodes",
    "start": "480319",
    "end": "483520"
  },
  {
    "text": "are living inside a supercomputer",
    "start": "483520",
    "end": "486080"
  },
  {
    "text": "everything seamless and completely uh",
    "start": "486080",
    "end": "488639"
  },
  {
    "text": "the user are completely unaware",
    "start": "488639",
    "end": "490240"
  },
  {
    "text": "everything is happen below cool now we",
    "start": "490240",
    "end": "494000"
  },
  {
    "text": "have big powers we have also big",
    "start": "494000",
    "end": "495919"
  },
  {
    "text": "responsibilities because",
    "start": "495919",
    "end": "498720"
  },
  {
    "text": "uh we need to provide a consistent",
    "start": "498720",
    "end": "501840"
  },
  {
    "text": "environment for our users we need in",
    "start": "501840",
    "end": "504160"
  },
  {
    "text": "other words a spaceship and a spaceship",
    "start": "504160",
    "end": "508879"
  },
  {
    "text": "needs to provide us with a consistency",
    "start": "508879",
    "end": "511520"
  },
  {
    "text": "uh of workflows we need to check our",
    "start": "511520",
    "end": "513279"
  },
  {
    "text": "workflows we need reproducible results",
    "start": "513279",
    "end": "515839"
  },
  {
    "text": "and yes we can do with the CI system",
    "start": "515839",
    "end": "518560"
  },
  {
    "text": "that we have nowadays but not without",
    "start": "518560",
    "end": "522159"
  },
  {
    "text": "locking uh our yourself into a custom",
    "start": "522159",
    "end": "525040"
  },
  {
    "text": "solution or reusing and copy pasting uh",
    "start": "525040",
    "end": "529519"
  },
  {
    "text": "nightmare that you might know very well",
    "start": "529519",
    "end": "533040"
  },
  {
    "text": "what Dagger provides the solution we",
    "start": "533040",
    "end": "535200"
  },
  {
    "text": "choose for for this uh is a runtime",
    "start": "535200",
    "end": "539959"
  },
  {
    "text": "basically that it's meant to create",
    "start": "539959",
    "end": "542640"
  },
  {
    "text": "composible software and go we scientists",
    "start": "542640",
    "end": "546240"
  },
  {
    "text": "love composible things so we took a look",
    "start": "546240",
    "end": "549760"
  },
  {
    "text": "at that and yeah we got pretty pretty",
    "start": "549760",
    "end": "552399"
  },
  {
    "text": "far because we have now repeatability of",
    "start": "552399",
    "end": "554880"
  },
  {
    "text": "our results we can compose all our uh",
    "start": "554880",
    "end": "558000"
  },
  {
    "text": "software in an efficient way and we can",
    "start": "558000",
    "end": "561120"
  },
  {
    "text": "also observe what happens when we build",
    "start": "561120",
    "end": "563120"
  },
  {
    "text": "and win test stuff so this is uh all",
    "start": "563120",
    "end": "567519"
  },
  {
    "text": "good but even more we have a universal",
    "start": "567519",
    "end": "570480"
  },
  {
    "text": "type system so we can code our pipeline",
    "start": "570480",
    "end": "572959"
  },
  {
    "text": "in a very efficient way we have a net",
    "start": "572959",
    "end": "575600"
  },
  {
    "text": "platform where we have uh caching for",
    "start": "575600",
    "end": "578240"
  },
  {
    "text": "our artifacts and we have built-in",
    "start": "578240",
    "end": "581080"
  },
  {
    "text": "observability and finally yeah the new",
    "start": "581080",
    "end": "585200"
  },
  {
    "text": "uh the new thing is that we also have",
    "start": "585200",
    "end": "587600"
  },
  {
    "text": "native integration with LLM that is",
    "start": "587600",
    "end": "590240"
  },
  {
    "text": "might be uh of use in the next years",
    "start": "590240",
    "end": "594240"
  },
  {
    "text": "this is the situation different modules",
    "start": "594240",
    "end": "596800"
  },
  {
    "text": "that does different things all together",
    "start": "596800",
    "end": "599360"
  },
  {
    "text": "can be composed to create different",
    "start": "599360",
    "end": "601279"
  },
  {
    "text": "pipelines that we can run on uh our",
    "start": "601279",
    "end": "605440"
  },
  {
    "text": "machine first of all so on your laptop",
    "start": "605440",
    "end": "607440"
  },
  {
    "text": "you can run those pipelines but the very",
    "start": "607440",
    "end": "610080"
  },
  {
    "text": "same pipeline we run all right uh we run",
    "start": "610080",
    "end": "613600"
  },
  {
    "text": "in the docker engine in your CI",
    "start": "613600",
    "end": "617160"
  },
  {
    "text": "system and all right so just one last",
    "start": "617160",
    "end": "623240"
  },
  {
    "text": "news this sandbox that you send around",
    "start": "623240",
    "end": "626320"
  },
  {
    "text": "with between your local machine and your",
    "start": "626320",
    "end": "628480"
  },
  {
    "text": "remote machine can also host LLM aent so",
    "start": "628480",
    "end": "631920"
  },
  {
    "text": "we can have some improvements of our",
    "start": "631920",
    "end": "634000"
  },
  {
    "text": "workflows based on our uh set of pieces",
    "start": "634000",
    "end": "637680"
  },
  {
    "text": "that we put into the puzzle and we ship",
    "start": "637680",
    "end": "641519"
  },
  {
    "text": "also all our software in a resilient and",
    "start": "641519",
    "end": "644560"
  },
  {
    "text": "efficient way for more details I leave",
    "start": "644560",
    "end": "647839"
  },
  {
    "text": "all the links during the presentation so",
    "start": "647839",
    "end": "651040"
  },
  {
    "text": "now we have a an interpace and a dagger",
    "start": "651040",
    "end": "654720"
  },
  {
    "text": "that can match provide us the capability",
    "start": "654720",
    "end": "656959"
  },
  {
    "text": "to run on external resources through a",
    "start": "656959",
    "end": "659600"
  },
  {
    "text": "Kubernetes cluster but those Kubernetes",
    "start": "659600",
    "end": "661760"
  },
  {
    "text": "cluster can run also in a sandbox on our",
    "start": "661760",
    "end": "665120"
  },
  {
    "text": "CI pipeline granting us all the",
    "start": "665120",
    "end": "668000"
  },
  {
    "text": "capability to be double checked before",
    "start": "668000",
    "end": "670800"
  },
  {
    "text": "we push changes to to production and",
    "start": "670800",
    "end": "674240"
  },
  {
    "text": "reusing also other modules that we use",
    "start": "674240",
    "end": "677279"
  },
  {
    "text": "in other use cases so pretty good so far",
    "start": "677279",
    "end": "680320"
  },
  {
    "text": "i would say we are pretty satisfied and",
    "start": "680320",
    "end": "683120"
  },
  {
    "text": "we are all set for the launch now please",
    "start": "683120",
    "end": "685279"
  },
  {
    "text": "mate introduced to what we did with all",
    "start": "685279",
    "end": "688160"
  },
  {
    "text": "this stuff thanks a lot Diego for the",
    "start": "688160",
    "end": "690000"
  },
  {
    "text": "introduction very nice yeah so let's see",
    "start": "690000",
    "end": "692399"
  },
  {
    "text": "in practice uh what we are been doing",
    "start": "692399",
    "end": "694560"
  },
  {
    "text": "with inner link and dagger so first of",
    "start": "694560",
    "end": "696720"
  },
  {
    "text": "all as introduction I'm from CERN open",
    "start": "696720",
    "end": "698880"
  },
  {
    "text": "lab which is this um entity in the CERN",
    "start": "698880",
    "end": "701760"
  },
  {
    "text": "IT department which is responsible for",
    "start": "701760",
    "end": "704200"
  },
  {
    "text": "establishing collaborations with",
    "start": "704200",
    "end": "706640"
  },
  {
    "text": "industry and academia so here you can",
    "start": "706640",
    "end": "709519"
  },
  {
    "text": "see our partners and I mean of course",
    "start": "709519",
    "end": "712160"
  },
  {
    "text": "feel free to reach out if you have ideas",
    "start": "712160",
    "end": "713920"
  },
  {
    "text": "would like to collaborate we're always",
    "start": "713920",
    "end": "715519"
  },
  {
    "text": "open to you know new collaborations and",
    "start": "715519",
    "end": "718720"
  },
  {
    "text": "um as was saying we are interested in",
    "start": "718720",
    "end": "721600"
  },
  {
    "text": "digital twins for instance so we're",
    "start": "721600",
    "end": "723120"
  },
  {
    "text": "taking we are participating into the",
    "start": "723120",
    "end": "724880"
  },
  {
    "text": "inner twin project and um in this",
    "start": "724880",
    "end": "727800"
  },
  {
    "text": "project we are responsible for",
    "start": "727800",
    "end": "730079"
  },
  {
    "text": "developing a component for scalable AI",
    "start": "730079",
    "end": "733120"
  },
  {
    "text": "workflows for scientific digital twin",
    "start": "733120",
    "end": "736200"
  },
  {
    "text": "applications this component is",
    "start": "736200",
    "end": "738399"
  },
  {
    "text": "implemented as a Python library which is",
    "start": "738399",
    "end": "740639"
  },
  {
    "text": "called it twin AI and um it's uh it can",
    "start": "740639",
    "end": "744560"
  },
  {
    "text": "you can imagine that as a toolkit that",
    "start": "744560",
    "end": "747440"
  },
  {
    "text": "provides scientists with different uh",
    "start": "747440",
    "end": "749920"
  },
  {
    "text": "functionalities to support distributed",
    "start": "749920",
    "end": "752399"
  },
  {
    "text": "machine learning um training distributed",
    "start": "752399",
    "end": "755440"
  },
  {
    "text": "hyperparameter optimization can support",
    "start": "755440",
    "end": "757680"
  },
  {
    "text": "PyTorch and TensorFlow and also has a",
    "start": "757680",
    "end": "760800"
  },
  {
    "text": "spec strong focus on the machine",
    "start": "760800",
    "end": "763279"
  },
  {
    "text": "learning tracking so the uh machine",
    "start": "763279",
    "end": "765920"
  },
  {
    "text": "learning metadata data that is generated",
    "start": "765920",
    "end": "767600"
  },
  {
    "text": "during training for instance also",
    "start": "767600",
    "end": "770480"
  },
  {
    "text": "allowing you to store the models I mean",
    "start": "770480",
    "end": "772959"
  },
  {
    "text": "to connect to a models registry where",
    "start": "772959",
    "end": "774720"
  },
  {
    "text": "you can store uh the models and version",
    "start": "774720",
    "end": "777200"
  },
  {
    "text": "them and so on and so forth and for this",
    "start": "777200",
    "end": "779440"
  },
  {
    "text": "we're using for instance MLflow",
    "start": "779440",
    "end": "782000"
  },
  {
    "text": "um when I talk about distributed machine",
    "start": "782000",
    "end": "784160"
  },
  {
    "text": "learning training I'm actually thinking",
    "start": "784160",
    "end": "786000"
  },
  {
    "text": "of two different models one is the pure",
    "start": "786000",
    "end": "788959"
  },
  {
    "text": "data parallel distributed training in",
    "start": "788959",
    "end": "790720"
  },
  {
    "text": "which we have a model which which is you",
    "start": "790720",
    "end": "793760"
  },
  {
    "text": "know replicated on different GPUs on",
    "start": "793760",
    "end": "796079"
  },
  {
    "text": "different nodes potentially multiple",
    "start": "796079",
    "end": "798079"
  },
  {
    "text": "nodes and the data set is partitioned so",
    "start": "798079",
    "end": "800959"
  },
  {
    "text": "each uh local replica of the model will",
    "start": "800959",
    "end": "803839"
  },
  {
    "text": "actually access a subset a specific",
    "start": "803839",
    "end": "806639"
  },
  {
    "text": "partition of the data set uh on the",
    "start": "806639",
    "end": "809440"
  },
  {
    "text": "other hand we can also support model",
    "start": "809440",
    "end": "812000"
  },
  {
    "text": "parallel and hybrid model parallel and",
    "start": "812000",
    "end": "814480"
  },
  {
    "text": "data parallel training so in uh which is",
    "start": "814480",
    "end": "816800"
  },
  {
    "text": "the the image on the right in this case",
    "start": "816800",
    "end": "818800"
  },
  {
    "text": "the model is too large to fit on a",
    "start": "818800",
    "end": "821120"
  },
  {
    "text": "single GPU which is pretty common",
    "start": "821120",
    "end": "822720"
  },
  {
    "text": "nowadays for very large language models",
    "start": "822720",
    "end": "825279"
  },
  {
    "text": "or like transformer based models so in",
    "start": "825279",
    "end": "827440"
  },
  {
    "text": "this case the model is distributed over",
    "start": "827440",
    "end": "829040"
  },
  {
    "text": "multiple GPUs and um to do this we rely",
    "start": "829040",
    "end": "832720"
  },
  {
    "text": "on uh popular frameworks such as",
    "start": "832720",
    "end": "835720"
  },
  {
    "text": "pytorch ray and the speed another key",
    "start": "835720",
    "end": "839120"
  },
  {
    "text": "feature as I was saying is",
    "start": "839120",
    "end": "840560"
  },
  {
    "text": "hyperparameter optimization so in this",
    "start": "840560",
    "end": "843040"
  },
  {
    "text": "case you can imagine you have a training",
    "start": "843040",
    "end": "844720"
  },
  {
    "text": "uh tuning configuration in which you",
    "start": "844720",
    "end": "846959"
  },
  {
    "text": "define the ranges for your",
    "start": "846959",
    "end": "848920"
  },
  {
    "text": "hyperparameters and then the ituna",
    "start": "848920",
    "end": "851120"
  },
  {
    "text": "trainer will make sure that uh in",
    "start": "851120",
    "end": "854160"
  },
  {
    "text": "individual uh training trials are run in",
    "start": "854160",
    "end": "857519"
  },
  {
    "text": "parallel so distributed over HPC",
    "start": "857519",
    "end": "859680"
  },
  {
    "text": "infrastructure over multiple nodes um",
    "start": "859680",
    "end": "862720"
  },
  {
    "text": "and uh in in an optimized way um and to",
    "start": "862720",
    "end": "866560"
  },
  {
    "text": "do this we rely on ray tune so let's see",
    "start": "866560",
    "end": "869279"
  },
  {
    "text": "some examples uh of digital twin use",
    "start": "869279",
    "end": "872000"
  },
  {
    "text": "cases that we have in interwin that have",
    "start": "872000",
    "end": "874320"
  },
  {
    "text": "been currently integrated in it these",
    "start": "874320",
    "end": "876800"
  },
  {
    "text": "are not the only ones but let's see uh",
    "start": "876800",
    "end": "878959"
  },
  {
    "text": "two of them so the first one uh it's as",
    "start": "878959",
    "end": "883040"
  },
  {
    "text": "it's tackling I mean it's as I it's",
    "start": "883040",
    "end": "886160"
  },
  {
    "text": "focusing on the on the domain of",
    "start": "886160",
    "end": "888040"
  },
  {
    "text": "environmental sciences so on",
    "start": "888040",
    "end": "890160"
  },
  {
    "text": "hydraological modeling and developing AI",
    "start": "890160",
    "end": "892639"
  },
  {
    "text": "model to improve early warnings for",
    "start": "892639",
    "end": "895800"
  },
  {
    "text": "droughts the other is from physics um so",
    "start": "895800",
    "end": "900480"
  },
  {
    "text": "we're collaborating with people working",
    "start": "900480",
    "end": "902000"
  },
  {
    "text": "on the data collected at the Virgo in",
    "start": "902000",
    "end": "904839"
  },
  {
    "text": "interpherometer um which is meant to you",
    "start": "904839",
    "end": "908480"
  },
  {
    "text": "know measure gravitational wave signals",
    "start": "908480",
    "end": "911279"
  },
  {
    "text": "and uh what they would like to do is to",
    "start": "911279",
    "end": "913199"
  },
  {
    "text": "use AI based model to den noiseise the",
    "start": "913199",
    "end": "915760"
  },
  {
    "text": "signals captured by the detector so here",
    "start": "915760",
    "end": "918639"
  },
  {
    "text": "we can see an example of um um let's say",
    "start": "918639",
    "end": "922959"
  },
  {
    "text": "scalability analysis that we did with it",
    "start": "922959",
    "end": "926079"
  },
  {
    "text": "so on the on the left we can see a plot",
    "start": "926079",
    "end": "928800"
  },
  {
    "text": "in which we compare different",
    "start": "928800",
    "end": "930560"
  },
  {
    "text": "distributed frameworks how they scale",
    "start": "930560",
    "end": "932560"
  },
  {
    "text": "for the same model on the same data set",
    "start": "932560",
    "end": "934320"
  },
  {
    "text": "of course and uh on the right we can see",
    "start": "934320",
    "end": "936959"
  },
  {
    "text": "an example of energy benchmarking so",
    "start": "936959",
    "end": "938959"
  },
  {
    "text": "we're also interested in studying how",
    "start": "938959",
    "end": "941279"
  },
  {
    "text": "the how you know different distributed",
    "start": "941279",
    "end": "943199"
  },
  {
    "text": "frameworks for a specific model for a",
    "start": "943199",
    "end": "946079"
  },
  {
    "text": "specific use case and a specific data",
    "start": "946079",
    "end": "947680"
  },
  {
    "text": "set you know how much is the energy",
    "start": "947680",
    "end": "949680"
  },
  {
    "text": "consumption and you know in other words",
    "start": "949680",
    "end": "952720"
  },
  {
    "text": "to highlight the different trade-offs uh",
    "start": "952720",
    "end": "955279"
  },
  {
    "text": "another example as I was saying in this",
    "start": "955279",
    "end": "957199"
  },
  {
    "text": "case we used i20ai to perform",
    "start": "957199",
    "end": "958959"
  },
  {
    "text": "hyperparameter optimization of a of a",
    "start": "958959",
    "end": "961360"
  },
  {
    "text": "model for hydraological modeling and",
    "start": "961360",
    "end": "963759"
  },
  {
    "text": "with i20i we were able to reduce uh the",
    "start": "963759",
    "end": "966399"
  },
  {
    "text": "validation loss of almost",
    "start": "966399",
    "end": "969880"
  },
  {
    "text": "75% but so how do we make sure that the",
    "start": "969880",
    "end": "973519"
  },
  {
    "text": "code that we're developing in aai is",
    "start": "973519",
    "end": "975839"
  },
  {
    "text": "always",
    "start": "975839",
    "end": "976759"
  },
  {
    "text": "consistent um so as I was saying it is",
    "start": "976759",
    "end": "979759"
  },
  {
    "text": "this abstraction layer on top of popular",
    "start": "979759",
    "end": "983040"
  },
  {
    "text": "distributed machine learning frameworks",
    "start": "983040",
    "end": "985040"
  },
  {
    "text": "so uh the users will provide a training",
    "start": "985040",
    "end": "987360"
  },
  {
    "text": "configuration and a tuning configuration",
    "start": "987360",
    "end": "989040"
  },
  {
    "text": "and then the trainer will abstract out",
    "start": "989040",
    "end": "991360"
  },
  {
    "text": "from the complexity uh below which are",
    "start": "991360",
    "end": "994399"
  },
  {
    "text": "basically different you know distributed",
    "start": "994399",
    "end": "995839"
  },
  {
    "text": "machine learning uh uh frameworks and",
    "start": "995839",
    "end": "997920"
  },
  {
    "text": "also from the HPC",
    "start": "997920",
    "end": "1000199"
  },
  {
    "text": "infrastructure uh of course we can write",
    "start": "1000199",
    "end": "1002880"
  },
  {
    "text": "some tests uh and and we do that uh and",
    "start": "1002880",
    "end": "1006079"
  },
  {
    "text": "we we have of course some unit and",
    "start": "1006079",
    "end": "1007839"
  },
  {
    "text": "integration tests uh that we use for",
    "start": "1007839",
    "end": "1010000"
  },
  {
    "text": "instance to test the abstraction layer",
    "start": "1010000",
    "end": "1012160"
  },
  {
    "text": "that we developed for the loggers or for",
    "start": "1012160",
    "end": "1014079"
  },
  {
    "text": "some utility functions or some you know",
    "start": "1014079",
    "end": "1017199"
  },
  {
    "text": "general purpose unit integration testing",
    "start": "1017199",
    "end": "1019440"
  },
  {
    "text": "for whatever any kind of feature uh",
    "start": "1019440",
    "end": "1022240"
  },
  {
    "text": "these are classical let's say these are",
    "start": "1022240",
    "end": "1024160"
  },
  {
    "text": "traditional unit and integration tests",
    "start": "1024160",
    "end": "1026240"
  },
  {
    "text": "and can be run anywhere and these are",
    "start": "1026240",
    "end": "1028240"
  },
  {
    "text": "not the topic of this talk you already",
    "start": "1028240",
    "end": "1030240"
  },
  {
    "text": "know them uh the problem is that some",
    "start": "1030240",
    "end": "1032798"
  },
  {
    "text": "features of it AAI are inherently",
    "start": "1032799",
    "end": "1036319"
  },
  {
    "text": "distributed so how can we test these",
    "start": "1036319",
    "end": "1038959"
  },
  {
    "text": "features uh you know everywhere like how",
    "start": "1038959",
    "end": "1043120"
  },
  {
    "text": "can how can we test these features",
    "start": "1043120",
    "end": "1044959"
  },
  {
    "text": "without having access to GPUs to",
    "start": "1044959",
    "end": "1046959"
  },
  {
    "text": "multiple nodes an example is the worker",
    "start": "1046959",
    "end": "1050640"
  },
  {
    "text": "uh rank accation so what does it mean",
    "start": "1050640",
    "end": "1053679"
  },
  {
    "text": "when we have for instance data parallel",
    "start": "1053679",
    "end": "1055760"
  },
  {
    "text": "training each uh process assigned to a",
    "start": "1055760",
    "end": "1059200"
  },
  {
    "text": "specific GPU is also assigned different",
    "start": "1059200",
    "end": "1061679"
  },
  {
    "text": "ranks and the ranks are needed in the",
    "start": "1061679",
    "end": "1064320"
  },
  {
    "text": "collective communication in in the",
    "start": "1064320",
    "end": "1066559"
  },
  {
    "text": "communication between the workers so how",
    "start": "1066559",
    "end": "1069120"
  },
  {
    "text": "how can we test this uh on a laptop of",
    "start": "1069120",
    "end": "1072000"
  },
  {
    "text": "course we cannot I mean we we need",
    "start": "1072000",
    "end": "1073520"
  },
  {
    "text": "specific infrastructure same is for the",
    "start": "1073520",
    "end": "1076160"
  },
  {
    "text": "collective operations such as all gather",
    "start": "1076160",
    "end": "1079120"
  },
  {
    "text": "gather barrier and so on and so forth so",
    "start": "1079120",
    "end": "1081200"
  },
  {
    "text": "how can we make sure that our software",
    "start": "1081200",
    "end": "1083280"
  },
  {
    "text": "is actually implementing this these",
    "start": "1083280",
    "end": "1085360"
  },
  {
    "text": "operations in the right way other",
    "start": "1085360",
    "end": "1087760"
  },
  {
    "text": "examples are for instance saving and",
    "start": "1087760",
    "end": "1090080"
  },
  {
    "text": "loading checkpoints in a distributed",
    "start": "1090080",
    "end": "1092080"
  },
  {
    "text": "machine learning uh setting uh end to",
    "start": "1092080",
    "end": "1094640"
  },
  {
    "text": "end integration testing for distributed",
    "start": "1094640",
    "end": "1096320"
  },
  {
    "text": "machine learning training and also the",
    "start": "1096320",
    "end": "1099280"
  },
  {
    "text": "possib also testing that we can run",
    "start": "1099280",
    "end": "1102480"
  },
  {
    "text": "distributed machine learning training",
    "start": "1102480",
    "end": "1104720"
  },
  {
    "text": "under hyperparameter optimization so",
    "start": "1104720",
    "end": "1106960"
  },
  {
    "text": "there's like a an hierarchy so we have a",
    "start": "1106960",
    "end": "1109600"
  },
  {
    "text": "high level uh distribution which is the",
    "start": "1109600",
    "end": "1111840"
  },
  {
    "text": "hyperparameter optimization and then",
    "start": "1111840",
    "end": "1113600"
  },
  {
    "text": "each trial is also distributed so how",
    "start": "1113600",
    "end": "1115600"
  },
  {
    "text": "can we test this um well that's the",
    "start": "1115600",
    "end": "1119600"
  },
  {
    "text": "topic of the talk of course and um uh",
    "start": "1119600",
    "end": "1122720"
  },
  {
    "text": "we're also interested in you know",
    "start": "1122720",
    "end": "1125360"
  },
  {
    "text": "repeating these tests for all the",
    "start": "1125360",
    "end": "1127679"
  },
  {
    "text": "frameworks that we're we're actually",
    "start": "1127679",
    "end": "1129520"
  },
  {
    "text": "using so you can see that there's a kind",
    "start": "1129520",
    "end": "1131679"
  },
  {
    "text": "of you know matrix that is building up",
    "start": "1131679",
    "end": "1134600"
  },
  {
    "text": "here oops yeah so how do we how do we",
    "start": "1134600",
    "end": "1138559"
  },
  {
    "text": "actually run the tests in practice so we",
    "start": "1138559",
    "end": "1141600"
  },
  {
    "text": "have distributed launchers which are",
    "start": "1141600",
    "end": "1143840"
  },
  {
    "text": "compatible with the uh distributed uh",
    "start": "1143840",
    "end": "1146880"
  },
  {
    "text": "machine learning frameworks for instance",
    "start": "1146880",
    "end": "1148720"
  },
  {
    "text": "for PyTorch so for torch DDP there's",
    "start": "1148720",
    "end": "1151120"
  },
  {
    "text": "torch run if you if you know it uh if",
    "start": "1151120",
    "end": "1153600"
  },
  {
    "text": "you ever heard of it and this will allow",
    "start": "1153600",
    "end": "1155520"
  },
  {
    "text": "to spawn multiple processes and each",
    "start": "1155520",
    "end": "1157440"
  },
  {
    "text": "process is basically just a pi test",
    "start": "1157440",
    "end": "1159840"
  },
  {
    "text": "command so I I I guess you're familiar",
    "start": "1159840",
    "end": "1161919"
  },
  {
    "text": "with pi test and uh and then each test",
    "start": "1161919",
    "end": "1164720"
  },
  {
    "text": "case will actually communicate with the",
    "start": "1164720",
    "end": "1167039"
  },
  {
    "text": "other test cases using a collective u",
    "start": "1167039",
    "end": "1169840"
  },
  {
    "text": "communication back end which is provided",
    "start": "1169840",
    "end": "1171440"
  },
  {
    "text": "by the distributed machine learning",
    "start": "1171440",
    "end": "1173120"
  },
  {
    "text": "framework uh and the whole thing will",
    "start": "1173120",
    "end": "1175760"
  },
  {
    "text": "then be possible to be uh tested on HPC",
    "start": "1175760",
    "end": "1179360"
  },
  {
    "text": "so this is an high level representation",
    "start": "1179360",
    "end": "1182400"
  },
  {
    "text": "of our tests now let's put everything",
    "start": "1182400",
    "end": "1185039"
  },
  {
    "text": "together we saw digital twins HPC AI uh",
    "start": "1185039",
    "end": "1189440"
  },
  {
    "text": "I know hydraological modeling uh",
    "start": "1189440",
    "end": "1191360"
  },
  {
    "text": "gravitational waves so great but then",
    "start": "1191360",
    "end": "1193840"
  },
  {
    "text": "how do we actually automate our tests on",
    "start": "1193840",
    "end": "1196559"
  },
  {
    "text": "HPC in practice uh we have our code on",
    "start": "1196559",
    "end": "1200080"
  },
  {
    "text": "GitHub on GitHub we also keep our CI",
    "start": "1200080",
    "end": "1202720"
  },
  {
    "text": "workflows such as software quality",
    "start": "1202720",
    "end": "1204400"
  },
  {
    "text": "assessment uh unit tests we build a",
    "start": "1204400",
    "end": "1207280"
  },
  {
    "text": "contain the Docker containers on HPC",
    "start": "1207280",
    "end": "1209679"
  },
  {
    "text": "great but how do we integrate then the",
    "start": "1209679",
    "end": "1212240"
  },
  {
    "text": "HPC resources into into into GitHub",
    "start": "1212240",
    "end": "1216600"
  },
  {
    "text": "um so first ingredient is dugger",
    "start": "1216600",
    "end": "1219360"
  },
  {
    "text": "pipelines so D already made a very nice",
    "start": "1219360",
    "end": "1221799"
  },
  {
    "text": "introduction the the the great benefit",
    "start": "1221799",
    "end": "1224720"
  },
  {
    "text": "in my opinion uh what I noticed at least",
    "start": "1224720",
    "end": "1226799"
  },
  {
    "text": "is that you know you can avoid to push",
    "start": "1226799",
    "end": "1228559"
  },
  {
    "text": "and prey okay you have a reproducible CI",
    "start": "1228559",
    "end": "1230799"
  },
  {
    "text": "that you can run on your laptop you can",
    "start": "1230799",
    "end": "1232080"
  },
  {
    "text": "run it on GitHub on GitLab whatever you",
    "start": "1232080",
    "end": "1233919"
  },
  {
    "text": "want it will always be the same and is",
    "start": "1233919",
    "end": "1236159"
  },
  {
    "text": "based on containers which is pretty",
    "start": "1236159",
    "end": "1238240"
  },
  {
    "text": "pretty useful for us uh and second uh",
    "start": "1238240",
    "end": "1241039"
  },
  {
    "text": "dagger pipelines allow to span on thely",
    "start": "1241039",
    "end": "1244320"
  },
  {
    "text": "services in the pipeline and this will",
    "start": "1244320",
    "end": "1246960"
  },
  {
    "text": "be pretty useful for the next step which",
    "start": "1246960",
    "end": "1249760"
  },
  {
    "text": "is putting everything together with",
    "start": "1249760",
    "end": "1251440"
  },
  {
    "text": "interlink so on the left we have the",
    "start": "1251440",
    "end": "1253919"
  },
  {
    "text": "cloud side so GitHub code CI pipeline",
    "start": "1253919",
    "end": "1258159"
  },
  {
    "text": "Dagger pipeline basically and on the",
    "start": "1258159",
    "end": "1260240"
  },
  {
    "text": "right we have the HPC so the remote HPC",
    "start": "1260240",
    "end": "1262799"
  },
  {
    "text": "supercomputer um they use different",
    "start": "1262799",
    "end": "1265840"
  },
  {
    "text": "technologies so on cloud we can uh on",
    "start": "1265840",
    "end": "1268720"
  },
  {
    "text": "GitHub we can build docker containers",
    "start": "1268720",
    "end": "1271039"
  },
  {
    "text": "but then we need when we want to run on",
    "start": "1271039",
    "end": "1272799"
  },
  {
    "text": "HPC we actually need singularity",
    "start": "1272799",
    "end": "1274480"
  },
  {
    "text": "containers so part of the CI uh let's",
    "start": "1274480",
    "end": "1277840"
  },
  {
    "text": "say pipeline also consists in converting",
    "start": "1277840",
    "end": "1280320"
  },
  {
    "text": "the Docker containers into singularity",
    "start": "1280320",
    "end": "1282480"
  },
  {
    "text": "containers before they're actually",
    "start": "1282480",
    "end": "1283840"
  },
  {
    "text": "tested on HPC so it's um but let's see",
    "start": "1283840",
    "end": "1287520"
  },
  {
    "text": "more details what the pipeline looks",
    "start": "1287520",
    "end": "1289480"
  },
  {
    "text": "like so uh first of all of course we",
    "start": "1289480",
    "end": "1292720"
  },
  {
    "text": "build a Docker container and we run some",
    "start": "1292720",
    "end": "1295280"
  },
  {
    "text": "uh unit tests like simple CPU only tests",
    "start": "1295280",
    "end": "1298080"
  },
  {
    "text": "that can be run on GitHub um next we",
    "start": "1298080",
    "end": "1301919"
  },
  {
    "text": "convert the docker uh image to a",
    "start": "1301919",
    "end": "1305280"
  },
  {
    "text": "singularity image file and we push it to",
    "start": "1305280",
    "end": "1308080"
  },
  {
    "text": "some let's say singularity registry it's",
    "start": "1308080",
    "end": "1311280"
  },
  {
    "text": "not it's not shown here but and then we",
    "start": "1311280",
    "end": "1313840"
  },
  {
    "text": "actually deploy inner link on well",
    "start": "1313840",
    "end": "1316320"
  },
  {
    "text": "actually we deploy k3s",
    "start": "1316320",
    "end": "1318720"
  },
  {
    "text": "uh inside the dagger pipeline on the fly",
    "start": "1318720",
    "end": "1321200"
  },
  {
    "text": "and uh on top of k3s we deploy inner",
    "start": "1321200",
    "end": "1323679"
  },
  {
    "text": "link so now uh by magic we are able to",
    "start": "1323679",
    "end": "1327039"
  },
  {
    "text": "use interlink and submit jobs to HPC",
    "start": "1327039",
    "end": "1329440"
  },
  {
    "text": "within this pipeline and so the last the",
    "start": "1329440",
    "end": "1331760"
  },
  {
    "text": "last step let's let's say the central",
    "start": "1331760",
    "end": "1333840"
  },
  {
    "text": "step in this picture is let's actually",
    "start": "1333840",
    "end": "1335840"
  },
  {
    "text": "run the tests on HPC so we using a link",
    "start": "1335840",
    "end": "1339360"
  },
  {
    "text": "we submit the jobs uh if the tests are",
    "start": "1339360",
    "end": "1341760"
  },
  {
    "text": "passing great we can publish the new",
    "start": "1341760",
    "end": "1344240"
  },
  {
    "text": "version of the container image both to a",
    "start": "1344240",
    "end": "1346799"
  },
  {
    "text": "singularity image um registry and to a",
    "start": "1346799",
    "end": "1350080"
  },
  {
    "text": "do to a docker container registry",
    "start": "1350080",
    "end": "1353360"
  },
  {
    "text": "um yeah so this is actually implemented",
    "start": "1353360",
    "end": "1355919"
  },
  {
    "text": "as a dagger module so you have also a",
    "start": "1355919",
    "end": "1357520"
  },
  {
    "text": "link um yeah you can find it on the",
    "start": "1357520",
    "end": "1360799"
  },
  {
    "text": "dagger verse uh I'm sure everyone can",
    "start": "1360799",
    "end": "1363120"
  },
  {
    "text": "read here but um this is of course just",
    "start": "1363120",
    "end": "1366159"
  },
  {
    "text": "to you know give an overview of the code",
    "start": "1366159",
    "end": "1368720"
  },
  {
    "text": "so in practice how does it look like um",
    "start": "1368720",
    "end": "1372720"
  },
  {
    "text": "uh we've been defining three dagger",
    "start": "1372720",
    "end": "1374480"
  },
  {
    "text": "types are called so first one iti so",
    "start": "1374480",
    "end": "1377440"
  },
  {
    "text": "that's that's you know where we have the",
    "start": "1377440",
    "end": "1379200"
  },
  {
    "text": "logic to build a container to connect to",
    "start": "1379200",
    "end": "1382240"
  },
  {
    "text": "inner link uh to run the tests on HPC I",
    "start": "1382240",
    "end": "1385440"
  },
  {
    "text": "mean to um to convert to singularity",
    "start": "1385440",
    "end": "1389120"
  },
  {
    "text": "everything all of this is on GitHub so",
    "start": "1389120",
    "end": "1390720"
  },
  {
    "text": "of course you can always have a look at",
    "start": "1390720",
    "end": "1392000"
  },
  {
    "text": "that then we have the inner link cont uh",
    "start": "1392000",
    "end": "1394480"
  },
  {
    "text": "the inner link uh type which you know",
    "start": "1394480",
    "end": "1397120"
  },
  {
    "text": "allows to bootstrap the inner link",
    "start": "1397120",
    "end": "1399200"
  },
  {
    "text": "service and the last one is the",
    "start": "1399200",
    "end": "1401000"
  },
  {
    "text": "singularity step which actually uh I",
    "start": "1401000",
    "end": "1404080"
  },
  {
    "text": "mean the singularity type which actually",
    "start": "1404080",
    "end": "1405360"
  },
  {
    "text": "allows to convert the docker container",
    "start": "1405360",
    "end": "1406799"
  },
  {
    "text": "to singularity image so here we have",
    "start": "1406799",
    "end": "1410080"
  },
  {
    "text": "some examples on how to use this",
    "start": "1410080",
    "end": "1411840"
  },
  {
    "text": "pipeline on the left uh if you could see",
    "start": "1411840",
    "end": "1414799"
  },
  {
    "text": "uh you can actually see some examples of",
    "start": "1414799",
    "end": "1417919"
  },
  {
    "text": "um how a container I mean how a CI/CD",
    "start": "1417919",
    "end": "1421600"
  },
  {
    "text": "pip I mean CI pipeline can be built in a",
    "start": "1421600",
    "end": "1424320"
  },
  {
    "text": "modular way so if we want we can just",
    "start": "1424320",
    "end": "1425840"
  },
  {
    "text": "build a container and publish it or",
    "start": "1425840",
    "end": "1427600"
  },
  {
    "text": "build a container and open a terminal in",
    "start": "1427600",
    "end": "1429200"
  },
  {
    "text": "it immediately or I don't know build a",
    "start": "1429200",
    "end": "1432720"
  },
  {
    "text": "container test it on CPU only let's say",
    "start": "1432720",
    "end": "1435840"
  },
  {
    "text": "environment and publish if you want so",
    "start": "1435840",
    "end": "1437679"
  },
  {
    "text": "it's it's really modular whereas on the",
    "start": "1437679",
    "end": "1439760"
  },
  {
    "text": "right we have some examples on how to",
    "start": "1439760",
    "end": "1442960"
  },
  {
    "text": "actually spawn inner link and uh submit",
    "start": "1442960",
    "end": "1445840"
  },
  {
    "text": "jobs from the same dagger pipeline so we",
    "start": "1445840",
    "end": "1448559"
  },
  {
    "text": "could you could even just use inner link",
    "start": "1448559",
    "end": "1450320"
  },
  {
    "text": "without caring about all the rest on the",
    "start": "1450320",
    "end": "1452559"
  },
  {
    "text": "right you have some examples on how to",
    "start": "1452559",
    "end": "1454240"
  },
  {
    "text": "do that um so let's see an example so",
    "start": "1454240",
    "end": "1458000"
  },
  {
    "text": "these are the this is this is the the",
    "start": "1458000",
    "end": "1459760"
  },
  {
    "text": "the end to end workflow so we launch we",
    "start": "1459760",
    "end": "1463440"
  },
  {
    "text": "push let's say to GitHub this will",
    "start": "1463440",
    "end": "1465679"
  },
  {
    "text": "trigger some um let's say GitHub actions",
    "start": "1465679",
    "end": "1469039"
  },
  {
    "text": "or some some some workflows uh which",
    "start": "1469039",
    "end": "1472000"
  },
  {
    "text": "under the hood will run a Dagger",
    "start": "1472000",
    "end": "1474279"
  },
  {
    "text": "pipeline here you can see the the the",
    "start": "1474279",
    "end": "1476880"
  },
  {
    "text": "trace of the Dagger pipeline on the",
    "start": "1476880",
    "end": "1478799"
  },
  {
    "text": "Dagger cloud so uh I mean of course I I",
    "start": "1478799",
    "end": "1481440"
  },
  {
    "text": "cannot you know open the tabs but it's",
    "start": "1481440",
    "end": "1483840"
  },
  {
    "text": "very it's very uh very nice because you",
    "start": "1483840",
    "end": "1485840"
  },
  {
    "text": "can navigate inside the whole tray so",
    "start": "1485840",
    "end": "1488400"
  },
  {
    "text": "here we can see that at the beginning we",
    "start": "1488400",
    "end": "1490080"
  },
  {
    "text": "were passing some variables as secrets",
    "start": "1490080",
    "end": "1492640"
  },
  {
    "text": "then uh the the container was built and",
    "start": "1492640",
    "end": "1496480"
  },
  {
    "text": "the last step is actually the uh release",
    "start": "1496480",
    "end": "1499200"
  },
  {
    "text": "pipeline so uh you know push I mean the",
    "start": "1499200",
    "end": "1502000"
  },
  {
    "text": "deploy inner link run the test on HPC",
    "start": "1502000",
    "end": "1504240"
  },
  {
    "text": "and and and push the final images and",
    "start": "1504240",
    "end": "1506720"
  },
  {
    "text": "here we got the final images so the",
    "start": "1506720",
    "end": "1508559"
  },
  {
    "text": "docker images will be pushed to the",
    "start": "1508559",
    "end": "1510880"
  },
  {
    "text": "github containers registry whereas the",
    "start": "1510880",
    "end": "1513039"
  },
  {
    "text": "singularity images will be pushed to a",
    "start": "1513039",
    "end": "1515200"
  },
  {
    "text": "harbor registry which is currently",
    "start": "1515200",
    "end": "1517279"
  },
  {
    "text": "hosted on cern resources and here you",
    "start": "1517279",
    "end": "1519919"
  },
  {
    "text": "have the the you know uh complete user",
    "start": "1519919",
    "end": "1523320"
  },
  {
    "text": "story now let's let's wrap up um what",
    "start": "1523320",
    "end": "1527360"
  },
  {
    "text": "can we currently do uh well of course",
    "start": "1527360",
    "end": "1530240"
  },
  {
    "text": "build containers in a reproducible uh CI",
    "start": "1530240",
    "end": "1532880"
  },
  {
    "text": "pipeline thanks to Dagger uh we can",
    "start": "1532880",
    "end": "1535440"
  },
  {
    "text": "integrate the factor HPC into GitHub and",
    "start": "1535440",
    "end": "1539520"
  },
  {
    "text": "we can automate the whole thing um so",
    "start": "1539520",
    "end": "1543360"
  },
  {
    "text": "integrate the CI tests on HPC through",
    "start": "1543360",
    "end": "1546000"
  },
  {
    "text": "GitHub using GitHub actions Dagger and",
    "start": "1546000",
    "end": "1548520"
  },
  {
    "text": "Interlink next steps um next steps are",
    "start": "1548520",
    "end": "1552000"
  },
  {
    "text": "to scale up so we can create more tests",
    "start": "1552000",
    "end": "1555039"
  },
  {
    "text": "for instance as I was sharing before we",
    "start": "1555039",
    "end": "1556960"
  },
  {
    "text": "are really interested in studying the",
    "start": "1556960",
    "end": "1558679"
  },
  {
    "text": "scalability of um of our code so we",
    "start": "1558679",
    "end": "1562159"
  },
  {
    "text": "we're not all we're only not only",
    "start": "1562159",
    "end": "1564080"
  },
  {
    "text": "interested in checking that the code is",
    "start": "1564080",
    "end": "1566159"
  },
  {
    "text": "running but we also want to make sure",
    "start": "1566159",
    "end": "1567440"
  },
  {
    "text": "that our trainer I mean when we you know",
    "start": "1567440",
    "end": "1569840"
  },
  {
    "text": "make changes to our trainer we're not",
    "start": "1569840",
    "end": "1571440"
  },
  {
    "text": "actually introducing some um",
    "start": "1571440",
    "end": "1573120"
  },
  {
    "text": "inefficiencies so one one set of tests",
    "start": "1573120",
    "end": "1575760"
  },
  {
    "text": "could be you know having some baseline",
    "start": "1575760",
    "end": "1578320"
  },
  {
    "text": "code some some baseline reference",
    "start": "1578320",
    "end": "1580320"
  },
  {
    "text": "actually making sure that the code is",
    "start": "1580320",
    "end": "1582000"
  },
  {
    "text": "actually you know scaling is always",
    "start": "1582000",
    "end": "1584000"
  },
  {
    "text": "scaling the same way or even better uh",
    "start": "1584000",
    "end": "1586080"
  },
  {
    "text": "or on the other hand also studying the",
    "start": "1586080",
    "end": "1587919"
  },
  {
    "text": "the the energy consumption for for",
    "start": "1587919",
    "end": "1590000"
  },
  {
    "text": "similar reasons second could be",
    "start": "1590000",
    "end": "1592080"
  },
  {
    "text": "integrating new uh HPC centers so at the",
    "start": "1592080",
    "end": "1595279"
  },
  {
    "text": "moment we have just been working with",
    "start": "1595279",
    "end": "1596799"
  },
  {
    "text": "Vega in Slovenia and the third one it's",
    "start": "1596799",
    "end": "1599360"
  },
  {
    "text": "pretty uh interesting because we could",
    "start": "1599360",
    "end": "1602320"
  },
  {
    "text": "so the whole CI that we've been writing",
    "start": "1602320",
    "end": "1604720"
  },
  {
    "text": "so far is for our code so for right to",
    "start": "1604720",
    "end": "1606799"
  },
  {
    "text": "AI for the abstraction layer but we",
    "start": "1606799",
    "end": "1608480"
  },
  {
    "text": "could extend this to any use case that",
    "start": "1608480",
    "end": "1610880"
  },
  {
    "text": "would like to you know write dry runs",
    "start": "1610880",
    "end": "1613919"
  },
  {
    "text": "tests for their um let's say machine",
    "start": "1613919",
    "end": "1616640"
  },
  {
    "text": "learning training for instance before uh",
    "start": "1616640",
    "end": "1619440"
  },
  {
    "text": "committing to very large jobs on HPC",
    "start": "1619440",
    "end": "1622400"
  },
  {
    "text": "which you know take time and maybe you",
    "start": "1622400",
    "end": "1625120"
  },
  {
    "text": "need to wait a lot in in the queue and",
    "start": "1625120",
    "end": "1627360"
  },
  {
    "text": "it's not very uncommon to you know",
    "start": "1627360",
    "end": "1629600"
  },
  {
    "text": "allocate resources on HPC for I know",
    "start": "1629600",
    "end": "1631840"
  },
  {
    "text": "many hours on know many many many GPUs",
    "start": "1631840",
    "end": "1634640"
  },
  {
    "text": "and then for some mistake you know it",
    "start": "1634640",
    "end": "1638480"
  },
  {
    "text": "just crashes right so but sometimes the",
    "start": "1638480",
    "end": "1640400"
  },
  {
    "text": "allocation is not always released",
    "start": "1640400",
    "end": "1641840"
  },
  {
    "text": "immediately so you may you may be paying",
    "start": "1641840",
    "end": "1644400"
  },
  {
    "text": "you know you may be charged let's say",
    "start": "1644400",
    "end": "1646080"
  },
  {
    "text": "for comput time anyway so it's it's it",
    "start": "1646080",
    "end": "1648400"
  },
  {
    "text": "could potentially be uh pretty useful",
    "start": "1648400",
    "end": "1651760"
  },
  {
    "text": "for for our users also to extend what",
    "start": "1651760",
    "end": "1654320"
  },
  {
    "text": "we've been developing to their uh let's",
    "start": "1654320",
    "end": "1656960"
  },
  {
    "text": "say day-to-day development for HPC code",
    "start": "1656960",
    "end": "1660400"
  },
  {
    "text": "for AI on",
    "start": "1660400",
    "end": "1661799"
  },
  {
    "text": "HPC and uh with this thanks a lot for",
    "start": "1661799",
    "end": "1665039"
  },
  {
    "text": "attending you can you know of course",
    "start": "1665039",
    "end": "1666720"
  },
  {
    "text": "leave a feedback and uh I left some",
    "start": "1666720",
    "end": "1669440"
  },
  {
    "text": "references if you want to know more from",
    "start": "1669440",
    "end": "1670799"
  },
  {
    "text": "the slides um but yeah thanks a lot yeah",
    "start": "1670799",
    "end": "1674159"
  },
  {
    "text": "thank",
    "start": "1674159",
    "end": "1676320"
  },
  {
    "text": "you and if you are interested in in any",
    "start": "1677159",
    "end": "1679919"
  },
  {
    "text": "of this of course we are here until the",
    "start": "1679919",
    "end": "1682720"
  },
  {
    "text": "end of the day so you can reach out and",
    "start": "1682720",
    "end": "1684799"
  },
  {
    "text": "we can talk about Yeah yeah",
    "start": "1684799",
    "end": "1688158"
  }
]
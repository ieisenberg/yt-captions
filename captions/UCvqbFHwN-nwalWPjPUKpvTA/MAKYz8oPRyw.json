[
  {
    "text": "okay so I'll just in truth once again is calling it's a product manager from Nance and Wally",
    "start": "30",
    "end": "7140"
  },
  {
    "text": "also one of the core contributors to the project and I have been using nax based",
    "start": "7140",
    "end": "12599"
  },
  {
    "text": "systems for for a while it seems like around six years already so it's really",
    "start": "12599",
    "end": "19770"
  },
  {
    "text": "cool how Nance is really taking off now joining the CNC AFM the growing",
    "start": "19770",
    "end": "25529"
  },
  {
    "text": "ecosystem so really thank you for attending and this is going to be an",
    "start": "25529",
    "end": "31170"
  },
  {
    "text": "extension from the previous talk if you have any questions during the talk at",
    "start": "31170",
    "end": "37680"
  },
  {
    "text": "the freeze your hand and it can be interactive and solve as many questions we have has this the last talk and so",
    "start": "37680",
    "end": "45690"
  },
  {
    "text": "this is a deep dive into the Nats project okay so for these I have some",
    "start": "45690",
    "end": "54480"
  },
  {
    "text": "slides and agenda for this session and we I want to show you some of the salty",
    "start": "54480",
    "end": "61109"
  },
  {
    "text": "design for both and Nats and not streaming and so the how they work and",
    "start": "61109",
    "end": "66510"
  },
  {
    "text": "how those not streaming fits into the picture and give some highlights from",
    "start": "66510",
    "end": "72330"
  },
  {
    "text": "the Nats ecosystems from Mexico system and also I give you some demos of of",
    "start": "72330",
    "end": "78119"
  },
  {
    "text": "usage examples of how to use snaps so let's start with NAT and I mentioned by",
    "start": "78119",
    "end": "86250"
  },
  {
    "text": "Colleen earlier but it's a high performance machine server with Mingo it was originally written in Ruby within",
    "start": "86250",
    "end": "92009"
  },
  {
    "text": "the main machine this was in 2011 or for Cloud Foundry so in there I mean Nance",
    "start": "92009",
    "end": "102420"
  },
  {
    "text": "was like well the message board used for",
    "start": "102420",
    "end": "107640"
  },
  {
    "text": "the command control doing the command control between the components in Cloud Foundry and in terms of performance it",
    "start": "107640",
    "end": "113340"
  },
  {
    "text": "was still pretty fast had around 150,000 messages per second so it worked very",
    "start": "113340",
    "end": "118649"
  },
  {
    "text": "well like for even those in spite of those limitations and",
    "start": "118649",
    "end": "125280"
  },
  {
    "text": "the foundations are still very solid since then I mean like the protocol is",
    "start": "125280",
    "end": "132120"
  },
  {
    "text": "is pretty much the same still it is the implementation is an again it's a pure",
    "start": "132120",
    "end": "138510"
  },
  {
    "text": "poly subscribe system on top of tcp/ip and you can use secure connections with TLS and from the rewrite the binary name",
    "start": "138510",
    "end": "147959"
  },
  {
    "text": "is Jeanette steam you have thought about changing in today not server but and this point unity have stock and this is",
    "start": "147959",
    "end": "157349"
  },
  {
    "text": "a simple example of the protocol we have an example demo endpoint you can just",
    "start": "157349",
    "end": "162629"
  },
  {
    "text": "turn it into it Stanley demo dotnet say you're in the port for two to two and as you start",
    "start": "162629",
    "end": "170269"
  },
  {
    "text": "establish a connection to to the server the first thing you will get is this",
    "start": "170269",
    "end": "176930"
  },
  {
    "text": "infrastructure and a lot of important fields use the maximum payload size so all the messages that you send to nets",
    "start": "177319",
    "end": "184980"
  },
  {
    "text": "are constrained to one megabyte by default or you can tune this in the server if you want same like larger",
    "start": "184980",
    "end": "193680"
  },
  {
    "text": "messages and this some basic publish/subscribe features from from the server right here",
    "start": "193680",
    "end": "201030"
  },
  {
    "text": "here we are making a sub subscription into the hell of dot Copenhagen subject and publishing on the subject and five",
    "start": "201030",
    "end": "210120"
  },
  {
    "text": "bytes this is going to be a just a world message and since this client has",
    "start": "210120",
    "end": "215430"
  },
  {
    "text": "registered interest into this hello dot Copenhagen subject then the server is going to announce it that you have a one",
    "start": "215430",
    "end": "222629"
  },
  {
    "text": "message on this hello dot Copenhagen that's matching the first subscription that you made and it's five bytes in",
    "start": "222629",
    "end": "229109"
  },
  {
    "text": "total right so the server is 10 you have many bytes you are should be reading",
    "start": "229109",
    "end": "235470"
  },
  {
    "text": "from the server right so this is what allows you to the server to be payload",
    "start": "235470",
    "end": "241139"
  },
  {
    "text": "agnostic right so and you know Nance doesn't constrain you to any type of an",
    "start": "241139",
    "end": "247739"
  },
  {
    "text": "encoding serialization formats right you can use protocol buffers JSON message pack whatever fits your needs and the",
    "start": "247739",
    "end": "256919"
  },
  {
    "text": "complete protocol is it's just these ten commands you can probably subscribe messages there is an unsubscribe and a",
    "start": "256919",
    "end": "264870"
  },
  {
    "text": "comment where you can define a priori how many messages you want to receive for example you can",
    "start": "264870",
    "end": "271319"
  },
  {
    "text": "say I only want to receive five messages on on this subscription after that just",
    "start": "271319",
    "end": "277440"
  },
  {
    "text": "fade away and stop receiving them and you can't customize your connection",
    "start": "277440",
    "end": "283440"
  },
  {
    "text": "against the server with using connect I mean this is important when handling credentials for example there's the info",
    "start": "283440",
    "end": "291569"
  },
  {
    "text": "protocol which is used both by sharing metadata to the clients and also for",
    "start": "291569",
    "end": "297569"
  },
  {
    "text": "gossiping the network topology from the cluster right so this is the way and the auto discovery mechanism it works right",
    "start": "297569",
    "end": "304440"
  },
  {
    "text": "so as soon as a cluster a new server joins the cluster the these network",
    "start": "304440",
    "end": "309750"
  },
  {
    "text": "locations are gossip to the clients and also well yeah message messages the",
    "start": "309750",
    "end": "317780"
  },
  {
    "text": "protocol which is for processing messages and there's a errors that",
    "start": "317780",
    "end": "323780"
  },
  {
    "text": "notification that can necessary consent this plus okay is for when you have the",
    "start": "323780",
    "end": "329610"
  },
  {
    "text": "verbose smoother on the server which is activated by disabled by default for the",
    "start": "329610",
    "end": "334650"
  },
  {
    "text": "clients right and there's a ping and pong always happening between the client and the server so periodically every two",
    "start": "334650",
    "end": "341460"
  },
  {
    "text": "minutes there's going to be a keepalive happening so that the connection is always healthy this is a simple example",
    "start": "341460",
    "end": "350250"
  },
  {
    "text": "of using they go client the go client is the one that is a get the most well is a",
    "start": "350250",
    "end": "357330"
  },
  {
    "text": "canonical implementation for for what",
    "start": "357330",
    "end": "362340"
  },
  {
    "text": "Nats client well with the behaviors from Nats client and here we have an example",
    "start": "362340",
    "end": "369000"
  },
  {
    "text": "of an asynchronous subscriber subscribing to this hello subject in takes a callback it has a very similar",
    "start": "369000",
    "end": "376229"
  },
  {
    "text": "API for all the other client implementations that we have and as soon",
    "start": "376229",
    "end": "382110"
  },
  {
    "text": "as we publish a message and on the hello subject then this well it would print",
    "start": "382110",
    "end": "389009"
  },
  {
    "text": "that you receive this message right and the server and it's again seven",
    "start": "389009",
    "end": "397349"
  },
  {
    "text": "megabytes binary no dependencies you have you can grab one of the latest release in github and slash releases",
    "start": "397349",
    "end": "406340"
  },
  {
    "text": "this is the latest version right now personal 1.1.1 and i can start sharing",
    "start": "406340",
    "end": "415110"
  },
  {
    "text": "some of them examples of how things works with nets some basic usage of them",
    "start": "415110",
    "end": "423590"
  },
  {
    "text": "on the net server so everyone seems to smoke yeah okay so this is the starting",
    "start": "423590",
    "end": "454800"
  },
  {
    "text": "engine and see it's fairly straightforward and it has by default is",
    "start": "454800",
    "end": "459840"
  },
  {
    "text": "going to be listening on the port and a 42 to there is an extra port you can open for receive gathering a matrix from",
    "start": "459840",
    "end": "467970"
  },
  {
    "text": "server this is important for a two to two in a just mock test the connection",
    "start": "467970",
    "end": "478250"
  },
  {
    "text": "yeah simpler subscriptions world okay so",
    "start": "478520",
    "end": "496470"
  },
  {
    "text": "we can do the same with the clients have some examples here so you have a",
    "start": "496470",
    "end": "506250"
  },
  {
    "text": "multiple and what messaging patterns right so you can broadcast and 1 to n",
    "start": "506250",
    "end": "514039"
  },
  {
    "text": "communication by using an but pure poly subscribe there's also a request",
    "start": "514039",
    "end": "519810"
  },
  {
    "text": "response and that will guarantee like doing the one-to-one communication and",
    "start": "519810",
    "end": "526320"
  },
  {
    "text": "also there's the cue subscription that you can use to for doing the load balancing right so simply simplest",
    "start": "526320",
    "end": "532589"
  },
  {
    "text": "simple example is your side doing a request reply well just a periodic timer app",
    "start": "532589",
    "end": "542339"
  },
  {
    "text": "this is so yeah it's a simple client",
    "start": "542339",
    "end": "548589"
  },
  {
    "text": "just connects to net and it's going to periodically sending a message every",
    "start": "548589",
    "end": "553630"
  },
  {
    "text": "second right so let's start it it's not here",
    "start": "553630",
    "end": "560399"
  },
  {
    "text": "okay so now we have a protocol sending em messages and let's another let's add",
    "start": "594620",
    "end": "601580"
  },
  {
    "text": "another subscriber let me see where am I here now I'm going to add a client that",
    "start": "601580",
    "end": "617510"
  },
  {
    "text": "is not going to subscribe me to the hello subject and I start receiving these messages so yeah it started",
    "start": "617510",
    "end": "634970"
  },
  {
    "text": "receiving all of these messages and something that is a so next I'll support",
    "start": "634970",
    "end": "643880"
  },
  {
    "text": "for wild cards in that's right so if you are interested into auditing all the",
    "start": "643880",
    "end": "650210"
  },
  {
    "text": "traffic that is happening right now you can use for example the full wild card",
    "start": "650210",
    "end": "657770"
  },
  {
    "text": "that will will make this a new client receive basically tap into all of the",
    "start": "657770",
    "end": "663950"
  },
  {
    "text": "traffic that is happening right now so and this original subscriber will still be able to consume all of those",
    "start": "663950",
    "end": "670220"
  },
  {
    "text": "messages then let's see what happens if",
    "start": "670220",
    "end": "676460"
  },
  {
    "text": "I kill the server you will see that the",
    "start": "676460",
    "end": "681680"
  },
  {
    "text": "client in the middle continues to publish messages even though it is still not connected right and the reason for",
    "start": "681680",
    "end": "687890"
  },
  {
    "text": "this is that the client is has an internal reconnection logic happening so every two seconds is going to try to",
    "start": "687890",
    "end": "694660"
  },
  {
    "text": "reconnect to the server and it has like 80 megabytes buffer where it will",
    "start": "694660",
    "end": "700130"
  },
  {
    "text": "continue to accumulate a pending data until it's able to reconnect so once we",
    "start": "700130",
    "end": "707150"
  },
  {
    "text": "reconnect the it basically make a burst",
    "start": "707150",
    "end": "713150"
  },
  {
    "text": "of all of the messages that were accumulated during the downtime from the server",
    "start": "713150",
    "end": "720010"
  },
  {
    "text": "and this is for them I want to win two",
    "start": "722000",
    "end": "728120"
  },
  {
    "text": "went to in communication and because I exposed the monitoring endpoint so I can",
    "start": "728120",
    "end": "735420"
  },
  {
    "text": "use a net stop to monitor all the connected clients so let's increase the",
    "start": "735420",
    "end": "741210"
  },
  {
    "text": "number of clients okay so now we have",
    "start": "741210",
    "end": "762300"
  },
  {
    "text": "twenty clients that are consuming all these messages and this will get very",
    "start": "762300",
    "end": "768330"
  },
  {
    "text": "chatty very very fast so there is a another API",
    "start": "768330",
    "end": "774150"
  },
  {
    "text": "that you can use which is that you subscribe in this case we can modify this subscriber to use a cue",
    "start": "774150",
    "end": "782370"
  },
  {
    "text": "subscription and they name a group for this set of workers so then instead of",
    "start": "782370",
    "end": "790800"
  },
  {
    "text": "everything everyone receiving the message what happens is that the server",
    "start": "790800",
    "end": "795900"
  },
  {
    "text": "will randomly balance these two just only one of them so if we run once again",
    "start": "795900",
    "end": "803150"
  },
  {
    "text": "and you can see that randomly the server",
    "start": "803150",
    "end": "808200"
  },
  {
    "text": "will be sending the message to only one of them and the third important feature",
    "start": "808200",
    "end": "816780"
  },
  {
    "text": "from the server is the request response so you can do",
    "start": "816780",
    "end": "823610"
  },
  {
    "text": "so in this case I'm going to be sending a as missing as many messages as I can",
    "start": "831509",
    "end": "837250"
  },
  {
    "text": "every on the hello subject and giving up",
    "start": "837250",
    "end": "842889"
  },
  {
    "text": "after 200 milliseconds so yeah it was a",
    "start": "842889",
    "end": "868720"
  },
  {
    "text": "timeout so I'm going to use a cue group",
    "start": "868720",
    "end": "878790"
  },
  {
    "text": "subscriber okay there is what's",
    "start": "879540",
    "end": "896639"
  },
  {
    "text": "connected so by passing the - D - be flax into the",
    "start": "908939",
    "end": "916410"
  },
  {
    "text": "server you can enable they're both login to the for the server but these are hits",
    "start": "916410",
    "end": "922920"
  },
  {
    "text": "a performance a little bit so it's very useful for production buddy setup guys",
    "start": "922920",
    "end": "930950"
  },
  {
    "text": "can increase the latency from the request so its case I'm oh yeah there's",
    "start": "930950",
    "end": "937620"
  },
  {
    "text": "no errors and it's able to communicate I just getting a 100 milliseconds response",
    "start": "937620",
    "end": "943290"
  },
  {
    "text": "times but it would be faster if I remove the bear boss yeah yeah so this is like",
    "start": "943290",
    "end": "954900"
  },
  {
    "text": "the three main features that you can get from from that one - and communication and probably subscribe using the load",
    "start": "954900",
    "end": "961980"
  },
  {
    "text": "balancing groups and week use subscriptions and request response for one to one and the rest of the features",
    "start": "961980",
    "end": "967380"
  },
  {
    "text": "from the from that Sand Gnats project just build on top of these main three",
    "start": "967380",
    "end": "973010"
  },
  {
    "text": "well building blocks so back to the presentation",
    "start": "973010",
    "end": "979490"
  },
  {
    "text": "well wall is going back to the presentation one of the things you can do is combine the load balancing with",
    "start": "980990",
    "end": "988290"
  },
  {
    "text": "request reply so you might have several requires out there ready to reply but",
    "start": "988290",
    "end": "995880"
  },
  {
    "text": "then send a request and I'll go to any one of the seven it's a great way to load balance and scale so if you find",
    "start": "995880",
    "end": "1001490"
  },
  {
    "text": "you're taking too much time processing your requests you simply scale-up more they're in the same queue group only",
    "start": "1001490",
    "end": "1007910"
  },
  {
    "text": "ones gonna respond so you can scale up thirty or forty if you have to as load increases and then scale back down again",
    "start": "1007910",
    "end": "1016660"
  },
  {
    "text": "so moving on to some of the operational aspects from net this is what a usual",
    "start": "1016720",
    "end": "1024260"
  },
  {
    "text": "production setup for Nets would look like you don't have a set of Nats clusters so that you have high",
    "start": "1024260",
    "end": "1031188"
  },
  {
    "text": "availability there are three main ports they would be opening this 42 for the",
    "start": "1031189",
    "end": "1036650"
  },
  {
    "text": "clients to connect there is a 6 to 2 to 4 the clustering peers to connect to each other and then for monitoring",
    "start": "1036650",
    "end": "1042800"
  },
  {
    "text": "purposes in case you want to just either just pull yourself be some like to me like to me like not",
    "start": "1042800",
    "end": "1050630"
  },
  {
    "text": "stopped or permitted exporter for the high availability it is you need to set",
    "start": "1050630",
    "end": "1058970"
  },
  {
    "text": "up the nuts clusters to be in a full mesh and one hop setup and as for as a",
    "start": "1058970",
    "end": "1065539"
  },
  {
    "text": "client and that client doesn't really need to own in requires to be connected",
    "start": "1065539",
    "end": "1070730"
  },
  {
    "text": "to one of the to any node as part of the cluster right so it doesn't then the",
    "start": "1070730",
    "end": "1077690"
  },
  {
    "text": "next cluster will be responsible of routing the messages rest then according",
    "start": "1077690",
    "end": "1083330"
  },
  {
    "text": "to the interest graph right so in the in case in this case if this client publishes a messaged to to this server I",
    "start": "1083330",
    "end": "1091639"
  },
  {
    "text": "mean all of the clients that are connected to this same and server I'm going to receive the message and also",
    "start": "1091639",
    "end": "1097760"
  },
  {
    "text": "the ones that are remotely interested into this message is going to be are going to be receiving them setting up",
    "start": "1097760",
    "end": "1106159"
  },
  {
    "text": "the Linux cluster and it can be done by just using the auto discovery mechanisms",
    "start": "1106159",
    "end": "1112639"
  },
  {
    "text": "so in this case the first one note that it doesn't have these - - routes and",
    "start": "1112639",
    "end": "1118929"
  },
  {
    "text": "parameter so that one is going to become the seed server then the second one will",
    "start": "1118929",
    "end": "1127159"
  },
  {
    "text": "join and it knows that there is at least one seed server at this at this 6 - 2 -",
    "start": "1127159",
    "end": "1133940"
  },
  {
    "text": "location and then the third note and it's going to be joining and then the",
    "start": "1133940",
    "end": "1139789"
  },
  {
    "text": "full mesh nuts cluster will be assembled so in terms of the protocol how it works",
    "start": "1139789",
    "end": "1145940"
  },
  {
    "text": "internally is that it is leveraging the info comment to gossip around where the",
    "start": "1145940",
    "end": "1152289"
  },
  {
    "text": "the URLs that are available inside of the cluster so once these joints then",
    "start": "1152289",
    "end": "1159019"
  },
  {
    "text": "the other node is going to connect to this other one and that's how the full mesh set up is well it's assembled and",
    "start": "1159019",
    "end": "1170510"
  },
  {
    "text": "then all of the clients that were connected to these other servers are going to receive all so they're not the",
    "start": "1170510",
    "end": "1175760"
  },
  {
    "text": "network location so now they will be they will add this end into the their",
    "start": "1175760",
    "end": "1181860"
  },
  {
    "text": "own into the server into the pool of service that they can't reconnect so in case the server and now fails it will",
    "start": "1181860",
    "end": "1189420"
  },
  {
    "text": "the client will fall back into the reconnection logic and then transparently reconnect into this other",
    "start": "1189420",
    "end": "1196140"
  },
  {
    "text": "server that just joined so it automatically fails over there is a",
    "start": "1196140",
    "end": "1204380"
  },
  {
    "text": "capability to set to set up and secure by default secure by default the",
    "start": "1204380",
    "end": "1209730"
  },
  {
    "text": "connections so you set up the server to use a certificates and then any client",
    "start": "1209730",
    "end": "1215610"
  },
  {
    "text": "that wants to connect to the server it has to establish TLS right then be here once again the e phone info command is",
    "start": "1215610",
    "end": "1221940"
  },
  {
    "text": "used when you set up TLS in the server then it's going to announce you that you",
    "start": "1221940",
    "end": "1227220"
  },
  {
    "text": "should start the TLS handshake otherwise you will not be able to continue communication then it happens and then",
    "start": "1227220",
    "end": "1235110"
  },
  {
    "text": "you can continue communicate sit where",
    "start": "1235110",
    "end": "1240380"
  },
  {
    "text": "as usual complete secure net setup would",
    "start": "1240380",
    "end": "1246480"
  },
  {
    "text": "involve both securing the port for the TLS for the clients and also you can use",
    "start": "1246480",
    "end": "1253770"
  },
  {
    "text": "a different set of certificates for the clustering peers so and also you can",
    "start": "1253770",
    "end": "1259530"
  },
  {
    "text": "expose the HTTP endpoint to well to use HTTPS to be able to secure circularly",
    "start": "1259530",
    "end": "1265230"
  },
  {
    "text": "scrape the matrix and this one of the",
    "start": "1265230",
    "end": "1271130"
  },
  {
    "text": "important well most important and features from nets which is how resilient it is and I Colin mentioned",
    "start": "1271130",
    "end": "1278040"
  },
  {
    "text": "earlier in the in the interim and there is a concept that slow consumers the",
    "start": "1278040",
    "end": "1283680"
  },
  {
    "text": "nuts are really optimized for this use case where and let's say the for example",
    "start": "1283680",
    "end": "1289590"
  },
  {
    "text": "there is a client that is subscribing to us and hello subject but it is not been",
    "start": "1289590",
    "end": "1294810"
  },
  {
    "text": "able to process all of these messages that it is receiving right so if the",
    "start": "1294810",
    "end": "1300660"
  },
  {
    "text": "server starts accumulating too many of these messages it is going to give it two seconds a deadline to drain",
    "start": "1300660",
    "end": "1307560"
  },
  {
    "text": "everything that is been sent to the client and if it doesn't read all",
    "start": "1307560",
    "end": "1314130"
  },
  {
    "text": "of those bytes then it will disconnect the client and tell it that it's a slow",
    "start": "1314130",
    "end": "1319470"
  },
  {
    "text": "consumer when you get to this point it is already kind of too late so as part",
    "start": "1319470",
    "end": "1325710"
  },
  {
    "text": "of the application well you should ought to do is for example in case of their",
    "start": "1325710",
    "end": "1331710"
  },
  {
    "text": "synchronous subscribers you could cap the the length of how many messages",
    "start": "1331710",
    "end": "1338639"
  },
  {
    "text": "should be pending for example by the fawley 65 65 thousand messages but you",
    "start": "1338639",
    "end": "1345809"
  },
  {
    "text": "can lower those so that you can detect earlier that there is an applic and slow",
    "start": "1345809",
    "end": "1351509"
  },
  {
    "text": "consumer error and the application layer at the application level so and nuts and",
    "start": "1351509",
    "end": "1359490"
  },
  {
    "text": "then next I want to cover at NAT streaming and not streaming builds on",
    "start": "1359490",
    "end": "1364769"
  },
  {
    "text": "top of all the previous business it is request response protocol using the",
    "start": "1364769",
    "end": "1371940"
  },
  {
    "text": "request response an API from Nats and because Nats is a protocol and pedal and",
    "start": "1371940",
    "end": "1377220"
  },
  {
    "text": "Gnostic we need to decide to use some serialization format we decided to use a protocol buffers in this case and the",
    "start": "1377220",
    "end": "1384480"
  },
  {
    "text": "code name is Stan because we call we we say that is the complete opposite from",
    "start": "1384480",
    "end": "1389820"
  },
  {
    "text": "net so while net gives you the admins to live and most wants the liberal guarantees and it really optimized for",
    "start": "1389820",
    "end": "1398090"
  },
  {
    "text": "well keeping things simple and there is a little bit more estate as part of a standard not streaming server so you",
    "start": "1398090",
    "end": "1404730"
  },
  {
    "text": "have a persistent of messages you have the storage then all this hacking",
    "start": "1404730",
    "end": "1410720"
  },
  {
    "text": "happening between the clients and so to ensure that they're consuming the",
    "start": "1410720",
    "end": "1416070"
  },
  {
    "text": "message so yeah just in the in the client libraries you would see this name",
    "start": "1416070",
    "end": "1422399"
  },
  {
    "text": "stand like import the stand which is much much shorter than and at streaming",
    "start": "1422399",
    "end": "1428120"
  },
  {
    "text": "it is essentially an application ads application so what if you reuse this",
    "start": "1428120",
    "end": "1435210"
  },
  {
    "text": "for an already available next cluster for example and it connects to two nuts",
    "start": "1435210",
    "end": "1440639"
  },
  {
    "text": "and use it as a transport to enhance the every mode for fournette so in case we",
    "start": "1440639",
    "end": "1448690"
  },
  {
    "text": "have a knack streaming client libraries for for many different application run",
    "start": "1448690",
    "end": "1454180"
  },
  {
    "text": "times so they implement the request response protocol from net streaming and it allows you to make a publish and then",
    "start": "1454180",
    "end": "1462220"
  },
  {
    "text": "ensure that it is persistent and then it is act and the ones that are subscribed",
    "start": "1462220",
    "end": "1468070"
  },
  {
    "text": "will be able to replay for from the beginning all the messages or just for a certain point and you can reuse this",
    "start": "1468070",
    "end": "1476470"
  },
  {
    "text": "same cluster both for using not streaming or just regular Net",
    "start": "1476470",
    "end": "1482559"
  },
  {
    "text": "Applications and because it is built on top of next you get all the the same set",
    "start": "1482559",
    "end": "1489550"
  },
  {
    "text": "of features in Kate for the reconnection logic and high availability and clustering so in case one of the Nets",
    "start": "1489550",
    "end": "1495940"
  },
  {
    "text": "servers and goes away then we reconnect to another one of the available NAT",
    "start": "1495940",
    "end": "1500980"
  },
  {
    "text": "servers for now that you have a state then the high availability for not",
    "start": "1500980",
    "end": "1508510"
  },
  {
    "text": "streaming itself comes also into the picture so one of the ways to solve this is by the fault tolerance move from not",
    "start": "1508510",
    "end": "1515860"
  },
  {
    "text": "streaming so in this mode you can have a single net streaming server become the",
    "start": "1515860",
    "end": "1521500"
  },
  {
    "text": "active server that is going to be persisting the messages on well the active server and you can have a set of",
    "start": "1521500",
    "end": "1529240"
  },
  {
    "text": "standby in a streaming servers that will well become active in case the the other",
    "start": "1529240",
    "end": "1536620"
  },
  {
    "text": "one fails and there's also not streaming clustering support by using raft so the",
    "start": "1536620",
    "end": "1543400"
  },
  {
    "text": "way this works is by well well with following the raft consensus algorithm",
    "start": "1543400",
    "end": "1549040"
  },
  {
    "text": "one of them becomes the leader and you can have a set of followers that are",
    "start": "1549040",
    "end": "1555340"
  },
  {
    "text": "going to be replicated all of the locks of the messages that are published to",
    "start": "1555340",
    "end": "1562179"
  },
  {
    "text": "Jeanette and since you are reducing you can have",
    "start": "1562179",
    "end": "1567690"
  },
  {
    "text": "a multiple set of a nut streaming service and using with different names right so you can have let's say a",
    "start": "1567690",
    "end": "1575479"
  },
  {
    "text": "cluster a not streaming server and alongside a cluster B and they're all",
    "start": "1575479",
    "end": "1582989"
  },
  {
    "text": "reducing the same and that's closer and",
    "start": "1582989",
    "end": "1589190"
  },
  {
    "text": "what by default if you try an app streaming and actually what happens is",
    "start": "1589190",
    "end": "1594719"
  },
  {
    "text": "that not Suman is embedding in the NAP server so you you will run that",
    "start": "1594719",
    "end": "1600989"
  },
  {
    "text": "streaming with an embedded and that's server where that is connecting to and",
    "start": "1600989",
    "end": "1607200"
  },
  {
    "text": "then you can also deploy it in this way where we don't having to in case you",
    "start": "1607200",
    "end": "1615179"
  },
  {
    "text": "don't have another available and that's closer so moving forward solid pieces",
    "start": "1615179",
    "end": "1623039"
  },
  {
    "text": "from Nats ecosystem we have available docker images for both and Nats and not",
    "start": "1623039",
    "end": "1628440"
  },
  {
    "text": "streaming there are very lightweight that we're using the form from scratch approach so that there are they have",
    "start": "1628440",
    "end": "1634559"
  },
  {
    "text": "very few layers the not streaming the next one is like 700 bytes one of the first official images that was well",
    "start": "1634559",
    "end": "1643139"
  },
  {
    "text": "using this approach from scratch we have a permitted exporter and we showed in",
    "start": "1643139",
    "end": "1649649"
  },
  {
    "text": "the keynote where you can configure it to scrape and matrix from a Sara Lee",
    "start": "1649649",
    "end": "1657629"
  },
  {
    "text": "exposing the monitoring endpoint and now very cool project is glue I this is very",
    "start": "1657629",
    "end": "1667349"
  },
  {
    "text": "sophisticated way it does is they actually implemented around a c++ clients for nets and not streaming as",
    "start": "1667349",
    "end": "1672959"
  },
  {
    "text": "part of my and here's a link for the demo is a it's a basically it's like",
    "start": "1672959",
    "end": "1680039"
  },
  {
    "text": "this invented gateway where you can make HTTP request and then publishes messages",
    "start": "1680039",
    "end": "1685379"
  },
  {
    "text": "that Trinette and so you're gonna do",
    "start": "1685379",
    "end": "1693409"
  },
  {
    "text": "some people familiar with the flow and you get from G RPC and there's an interesting project in the community",
    "start": "1693769",
    "end": "1699749"
  },
  {
    "text": "named Danny and RPC which is a gap you get you to some middle ground here where you can use",
    "start": "1699749",
    "end": "1705809"
  },
  {
    "text": "protocol buffers to on top of net so then you can I will take advantage of",
    "start": "1705809",
    "end": "1713999"
  },
  {
    "text": "total load balancing features that you get from Nets and using doing them pop sobbing and also there's the operator",
    "start": "1713999",
    "end": "1723509"
  },
  {
    "text": "that was originally developed by Paul appearance and that so I said well",
    "start": "1723509",
    "end": "1730849"
  },
  {
    "text": "you're using a kubernetes that simpler way to deploy nuts clusters where we're",
    "start": "1730849",
    "end": "1737749"
  },
  {
    "text": "configuring the for configuring the full mesh in a very simple way and this is an",
    "start": "1737749",
    "end": "1746700"
  },
  {
    "text": "example manifest from that separator so so far any any questions I mean yes",
    "start": "1746700",
    "end": "1758658"
  },
  {
    "text": "yeah",
    "start": "1759289",
    "end": "1762289"
  },
  {
    "text": "so the question was about offender offender who often pluggable",
    "start": "1777779",
    "end": "1785399"
  },
  {
    "text": "authentication and authorization it's been a long a few days right now",
    "start": "1785399",
    "end": "1791899"
  },
  {
    "text": "today we don't have anything pluggable but what we allow you to do is to",
    "start": "1791899",
    "end": "1797129"
  },
  {
    "text": "rewrite the configuration file and then send a signal to the NAT server that will then reread and apply all the",
    "start": "1797129",
    "end": "1803369"
  },
  {
    "text": "differences so if you want to let's say remover user or revoke their creds then",
    "start": "1803369",
    "end": "1809149"
  },
  {
    "text": "you can just simply remove them from the configuration file send a signal it'll reload and actually kill all the",
    "start": "1809149",
    "end": "1815639"
  },
  {
    "text": "connections that that user is associated with sometime in the future we aren't exactly sure when we have plans for a",
    "start": "1815639",
    "end": "1822419"
  },
  {
    "text": "pluggable interface that may happen sooner rather than later but are later rather than sooner I mean what we'll see",
    "start": "1822419",
    "end": "1828899"
  },
  {
    "text": "but some sort of pluggable interface that will let you call out to whatever you need 200 or you know LDAP whatever",
    "start": "1828899",
    "end": "1837950"
  },
  {
    "text": "the question was what authorization to changes kick everyone off no it only kick off the people that were there the",
    "start": "1849919",
    "end": "1856529"
  },
  {
    "text": "user that connection ID that was affected and the same with permissions",
    "start": "1856529",
    "end": "1861989"
  },
  {
    "text": "so let's say you had somebody you know yet Colin publishing to foo and then you",
    "start": "1861989",
    "end": "1868049"
  },
  {
    "text": "change the permissions where Colin could no longer published a foo that would just stop",
    "start": "1868049",
    "end": "1874220"
  },
  {
    "text": "so the question is how big of clusters have we tested with I believe there's",
    "start": "1888659",
    "end": "1895989"
  },
  {
    "text": "been some users that have had clusters in their range of 50 to a hundred servers and it's kind of a tricky",
    "start": "1895989",
    "end": "1903639"
  },
  {
    "text": "question to answer as far as the penalty it depends on how many subscriptions you're making what rate you're making a",
    "start": "1903639",
    "end": "1910989"
  },
  {
    "text": "subscription so if you're making hundreds of new subscriptions a second that interest is propagated throughout",
    "start": "1910989",
    "end": "1917559"
  },
  {
    "text": "the cluster you'll have a penalty if you have a fairly stable number of static",
    "start": "1917559",
    "end": "1924009"
  },
  {
    "text": "number of subscriptions where you know maybe just a couple a minute then you can scale actually quite a bit further",
    "start": "1924009",
    "end": "1930700"
  },
  {
    "text": "because you don't have that interest propagated you don't have that chatter between the servers yes the question was",
    "start": "1930700",
    "end": "1946479"
  },
  {
    "text": "do we support exactly once the answer's no I don't really think we'll ever",
    "start": "1946479",
    "end": "1952179"
  },
  {
    "text": "support exactly once there's a few reasons for that with with newer",
    "start": "1952179",
    "end": "1957399"
  },
  {
    "text": "applications they tend to be designed to be idempotent and when you implement",
    "start": "1957399",
    "end": "1962470"
  },
  {
    "text": "exactly once there's a lot of mechanics behind the scenes that that really incur",
    "start": "1962470",
    "end": "1969009"
  },
  {
    "text": "some big penalties the other thing is that exactly once doesn't actually",
    "start": "1969009",
    "end": "1974799"
  },
  {
    "text": "protect your applications processing so let's say you've received your message you should start to process it you crash",
    "start": "1974799",
    "end": "1981099"
  },
  {
    "text": "halfway through well you're either gonna have to roll or crash halfway through right if you did any any sort of storage",
    "start": "1981099",
    "end": "1988779"
  },
  {
    "text": "into a database or anything like that you're gonna have to do some cleanup or fixing later on in which case most",
    "start": "1988779",
    "end": "1994840"
  },
  {
    "text": "people just use the item potent approach let's say you detect an error then",
    "start": "1994840",
    "end": "2000359"
  },
  {
    "text": "you're gonna have to roll back and then not act that message and rereceive it",
    "start": "2000359",
    "end": "2005879"
  },
  {
    "text": "anyhow so exactly once there's there's just very few situations where people really",
    "start": "2005879",
    "end": "2010889"
  },
  {
    "text": "need it I get the sense a lot of users think they think they need it when they don't and in fact end up having to make",
    "start": "2010889",
    "end": "2017840"
  },
  {
    "text": "things idempotent anyhow to make their system stable that's my opinion you know I could be wrong but long answer to you",
    "start": "2017840",
    "end": "2025700"
  },
  {
    "text": "know no and probably not the question",
    "start": "2025700",
    "end": "2073158"
  },
  {
    "text": "was with streaming servers how do i scale horizontally or make it highly available is that yeah so what what we",
    "start": "2073159",
    "end": "2082700"
  },
  {
    "text": "can do is streaming servers is for high availability you've got two options you can use raft which is your clustering",
    "start": "2082700",
    "end": "2089990"
  },
  {
    "text": "that we also have a warm failover mode where you might have a few instances",
    "start": "2089990",
    "end": "2095060"
  },
  {
    "text": "running that aren't actually doing anything but the ready to pick up as soon as a primary instance fails and",
    "start": "2095060",
    "end": "2101030"
  },
  {
    "text": "that's your high availability option as far as scaling we allow you to partition",
    "start": "2101030",
    "end": "2106850"
  },
  {
    "text": "servers by subject so you might have a streaming server that handles subjects",
    "start": "2106850",
    "end": "2112850"
  },
  {
    "text": "foo and bar and another streaming server in the same cluster that handles bass",
    "start": "2112850",
    "end": "2117890"
  },
  {
    "text": "and that's how you scale so you scale horizontally by subject rather than like",
    "start": "2117890",
    "end": "2124190"
  },
  {
    "text": "an other messaging solutions by partitioning lots of questions",
    "start": "2124190",
    "end": "2132490"
  },
  {
    "text": "so the question was about buffering data and streaming and when do we act how do",
    "start": "2148500",
    "end": "2154420"
  },
  {
    "text": "we manage that so there's two modes in streaming so we support an F sync mode",
    "start": "2154420",
    "end": "2160269"
  },
  {
    "text": "which means you do the server's do not respond to the raft log append with an",
    "start": "2160269",
    "end": "2167410"
  },
  {
    "text": "okay until the the message in question has been f synched to disk we also offer",
    "start": "2167410",
    "end": "2175960"
  },
  {
    "text": "a mode that allows that message to be buffered on to the disk for better performance and for people that are ok",
    "start": "2175960",
    "end": "2181089"
  },
  {
    "text": "because you're gonna have a quorum so you're gonna have maybe five instances so that's one part of that and then it's",
    "start": "2181089",
    "end": "2189160"
  },
  {
    "text": "just the nature of the round protocol so before we will send a message to a net",
    "start": "2189160",
    "end": "2195609"
  },
  {
    "text": "streaming server and before the Nats streaming server acts back saying I'm okay with that message it makes sure",
    "start": "2195609",
    "end": "2202569"
  },
  {
    "text": "that at least a quorum at least three of your five servers have successfully",
    "start": "2202569",
    "end": "2207759"
  },
  {
    "text": "persisted that message",
    "start": "2207759",
    "end": "2210779"
  },
  {
    "text": "the question was if I have multiple kubernetes clusters and I've got Nats deployments in each one but I want to",
    "start": "2244339",
    "end": "2250999"
  },
  {
    "text": "connect all of them globally what pattern would I use today you would",
    "start": "2250999",
    "end": "2256970"
  },
  {
    "text": "still need to do the full mesh was what we have today we actually are working on",
    "start": "2256970",
    "end": "2263200"
  },
  {
    "text": "bridging different clusters together to solve that exact problem and we should",
    "start": "2263200",
    "end": "2268819"
  },
  {
    "text": "have that definitely by q3",
    "start": "2268819",
    "end": "2273160"
  },
  {
    "text": "there is an impact on performance I mean you have a quite a bit more memory copy from from your your socket into memory",
    "start": "2287650",
    "end": "2295819"
  },
  {
    "text": "and then back into every other socket so it depends on a couple things since it's",
    "start": "2295819",
    "end": "2301460"
  },
  {
    "text": "a memory copy it's going to depend on some of your CPU it's going to depend on how big your pipe is what sort of",
    "start": "2301460",
    "end": "2306859"
  },
  {
    "text": "network you're working on so the answer is yeah there is a performance impact",
    "start": "2306859",
    "end": "2312099"
  },
  {
    "text": "how much depends on your resources at hand we default to a Meg but you can go",
    "start": "2312099",
    "end": "2321079"
  },
  {
    "text": "unlimited",
    "start": "2321079",
    "end": "2323920"
  },
  {
    "text": "so the question was are there headers and Nats so I can pass some things like",
    "start": "2342680",
    "end": "2349020"
  },
  {
    "text": "a correlation ID for a message the answer is no we've intentionally chosen not to include headers and nets and that",
    "start": "2349020",
    "end": "2357390"
  },
  {
    "text": "is part of the payload so NASA's entirely payload agnostic and to that end even with hetero Sweden we don't",
    "start": "2357390",
    "end": "2364050"
  },
  {
    "text": "include anything but they can certainly be added on and that's exactly what we",
    "start": "2364050",
    "end": "2369569"
  },
  {
    "text": "did that Wally mentioned in NAT streaming with using protobuf because we needed headers so we just use protobuf",
    "start": "2369569",
    "end": "2375900"
  },
  {
    "text": "for that yeah so here you can see some of the examples of community running an",
    "start": "2375900",
    "end": "2382920"
  },
  {
    "text": "ad streaming and it is Justin Justin that's protocol and because it is a",
    "start": "2382920",
    "end": "2390690"
  },
  {
    "text": "pillar not not sticking and everything's publishes protocol buffers right for not",
    "start": "2390690",
    "end": "2396150"
  },
  {
    "text": "streaming mud so yeah you have to do in",
    "start": "2396150",
    "end": "2401430"
  },
  {
    "text": "choose one and then do it on your own so we have just a few minutes left so a few",
    "start": "2401430",
    "end": "2406470"
  },
  {
    "text": "more questions",
    "start": "2406470",
    "end": "2408799"
  },
  {
    "text": "the question was is there any tracing facility built in built into Nats",
    "start": "2418819",
    "end": "2424280"
  },
  {
    "text": "no we actually have to push that up to the application because we don't have",
    "start": "2424280",
    "end": "2429569"
  },
  {
    "text": "headers so the application will want to have some sort of correlation ID or a unique ID for tracing like open tracing",
    "start": "2429569",
    "end": "2437069"
  },
  {
    "text": "with Yeager's Afghan or something like that so yeah the answer is unfortunately the application has to do that",
    "start": "2437069",
    "end": "2445670"
  },
  {
    "text": "or you haven't asked a question yet right okay if all your clients have that",
    "start": "2448130",
    "end": "2469860"
  },
  {
    "text": "much latency then yes they will the server will continue to buffer up and",
    "start": "2469860",
    "end": "2476730"
  },
  {
    "text": "then your clients will be cut off but in that situation if you're dealing with an extremely high situation a latency",
    "start": "2476730",
    "end": "2483270"
  },
  {
    "text": "situation you just increase that to ten seconds even if it's minutes you can do",
    "start": "2483270",
    "end": "2492540"
  },
  {
    "text": "it it depends on your environment if you have latency of minutes you know for a",
    "start": "2492540",
    "end": "2498420"
  },
  {
    "text": "single message to get through you know I suggest you look at other areas first",
    "start": "2498420",
    "end": "2505070"
  },
  {
    "text": "okay so we've asked for numbers on the largest cluster we've ever seen and",
    "start": "2522140",
    "end": "2527600"
  },
  {
    "text": "throughput so largest cluster it was",
    "start": "2527600",
    "end": "2533220"
  },
  {
    "text": "between I think close to a hundred nodes in the cluster as far as the throughput",
    "start": "2533220",
    "end": "2538590"
  },
  {
    "text": "goes some of our recent tests with multiple streams darica what 80 million messages a second",
    "start": "2538590",
    "end": "2546560"
  },
  {
    "text": "aggregate one just single pass through",
    "start": "2546560",
    "end": "2552000"
  },
  {
    "text": "one publisher one subscriber I think we're about 21 million messages a second",
    "start": "2552000",
    "end": "2558920"
  },
  {
    "text": "so here in the back on set okay okay Oh Wally show and then yeah and I think we",
    "start": "2561930",
    "end": "2568230"
  },
  {
    "text": "have to call it is an example of an having a tight loop and processing I'm not being able to process all the",
    "start": "2568230",
    "end": "2573930"
  },
  {
    "text": "messages that have been sent and then client is trying to reconnect and then just the server continues to say that",
    "start": "2573930",
    "end": "2580710"
  },
  {
    "text": "slow consumer detected and chopped in the connection okay well I'll let Wally",
    "start": "2580710",
    "end": "2590190"
  },
  {
    "text": "close this is his demo well thank you for attending and we'll still be here",
    "start": "2590190",
    "end": "2596700"
  },
  {
    "text": "until one yep yeah yeah so at this feel",
    "start": "2596700",
    "end": "2603480"
  },
  {
    "text": "for I feel free come by talk to us we're jet lag but still yeah we have",
    "start": "2603480",
    "end": "2608610"
  },
  {
    "text": "found maintenance hours as well at tomorrow I think tomorrow morning thank",
    "start": "2608610",
    "end": "2615120"
  },
  {
    "text": "you very much [Applause]",
    "start": "2615120",
    "end": "2620760"
  }
]
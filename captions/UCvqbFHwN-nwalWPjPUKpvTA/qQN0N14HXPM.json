[
  {
    "text": "alright let's get started after some technical difficulties Thank You Lily for lending us your laptop okay",
    "start": "1610",
    "end": "9690"
  },
  {
    "text": "so welcome to the Thomas deep dive before we jump into the presentation",
    "start": "9690",
    "end": "15980"
  },
  {
    "text": "let's give it a quick show of hands who here is already using Thomas Wow very",
    "start": "15980",
    "end": "22949"
  },
  {
    "text": "cool who is planning on using tonneaus okay that's pretty much I think almost",
    "start": "22949",
    "end": "29070"
  },
  {
    "text": "everyone raised their hand now but and if anyone didn't then hopefully we can convince you today as well for everyone",
    "start": "29070",
    "end": "35280"
  },
  {
    "text": "who did raise their hand hopefully we can raise your confidence in this system or make your about running it already or",
    "start": "35280",
    "end": "42770"
  },
  {
    "text": "hopefully we can increase your confidence about what you're about to be using so I'm Frederick I work at Red Hat",
    "start": "42770",
    "end": "50850"
  },
  {
    "text": "I work on pretty much everything around observability at Red Hat I'm a",
    "start": "50850",
    "end": "55890"
  },
  {
    "text": "prometheus maintainer I'm a tano's maintainer that's kind of why I'm here and I also lead second servant Asian",
    "start": "55890",
    "end": "63120"
  },
  {
    "text": "within kubernetes and I have partek with me today yeah hello i'm bartek i'm also working for",
    "start": "63120",
    "end": "68640"
  },
  {
    "text": "the same team as Frederick for ownership monitoring and I'm primitive maintain a raincoat initial culture of the tunnels",
    "start": "68640",
    "end": "76799"
  },
  {
    "text": "project as well and really personated about building distributed systems so we",
    "start": "76799",
    "end": "85140"
  },
  {
    "text": "already had our tano's introduction but let's recap a couple of things just so",
    "start": "85140",
    "end": "91470"
  },
  {
    "text": "we make sure we are on the same page so thomas is obviously part of the CN CF",
    "start": "91470",
    "end": "98880"
  },
  {
    "text": "that's where we're here it's a CN CF sandbox project and we have all these wonderful open-source repo",
    "start": "98880",
    "end": "106350"
  },
  {
    "text": "stats that you can read here a bunch of stars and so on obviously the most important metrics out there and more",
    "start": "106350",
    "end": "114420"
  },
  {
    "text": "largely we operate within the Prometheus ecosystem and I think something that's",
    "start": "114420",
    "end": "120659"
  },
  {
    "text": "really important to internalize about tunnels is we don't we want to not reinvent the wheel so we want to make",
    "start": "120659",
    "end": "127290"
  },
  {
    "text": "use of everything that is already existing in the Prometheus ecosystem and if it's not good",
    "start": "127290",
    "end": "132960"
  },
  {
    "text": "enough we improve that as opposed to reinventing everything new yeah and",
    "start": "132960",
    "end": "138180"
  },
  {
    "text": "something that I personally think is super exciting which is completely non technological is we recently set up like",
    "start": "138180",
    "end": "145410"
  },
  {
    "text": "neutral governance for the project so that all of you can continue to enjoy",
    "start": "145410",
    "end": "151070"
  },
  {
    "text": "this project and can trust that no one company will ever take over this project",
    "start": "151070",
    "end": "156870"
  },
  {
    "text": "so I think that's really awesome but yeah not now let's jump back into",
    "start": "156870",
    "end": "162150"
  },
  {
    "text": "technical things so let's really reiterate on a couple of architectural things about tano's so that we can deep",
    "start": "162150",
    "end": "168750"
  },
  {
    "text": "dive into some of the cooler things so this is probably one of the most common",
    "start": "168750",
    "end": "174750"
  },
  {
    "text": "setups that you see running tunnels so what we see here is a set of Prometheus servers that have the cut ton of citecar",
    "start": "174750",
    "end": "181140"
  },
  {
    "text": "next to it and the tano sidecar exposes something that we call the store API and this is kind of the universal language",
    "start": "181140",
    "end": "188010"
  },
  {
    "text": "that every component within within tano speaks and so the courier calls out via",
    "start": "188010",
    "end": "195330"
  },
  {
    "text": "the store API to these site cars and that's how you can get a global view of your data and this is probably the very",
    "start": "195330",
    "end": "202200"
  },
  {
    "text": "first thing that everyone does when they start to use tano's and so the very next",
    "start": "202200",
    "end": "209310"
  },
  {
    "text": "thing that people then start doing is they don't only have the query or access",
    "start": "209310",
    "end": "215100"
  },
  {
    "text": "all of this data they also configure the sidecar to upload this data that Prometheus periodically flushes to disk",
    "start": "215100",
    "end": "221940"
  },
  {
    "text": "to object storage and then eventually you also not just have this be a backup but you actually put the ton of store",
    "start": "221940",
    "end": "228600"
  },
  {
    "text": "gateway in front and actually can query of this long-term data so whenever we do this the when we now insert a courier a",
    "start": "228600",
    "end": "236940"
  },
  {
    "text": "query into our courier our nice expression browser right that we're we know and love from Prometheus already we",
    "start": "236940",
    "end": "243720"
  },
  {
    "text": "have that in Thomas as well so when we do that the courier won't only fan out",
    "start": "243720",
    "end": "249060"
  },
  {
    "text": "to the side cars to get the live data you will also get the historic data that is loaded from object storage so I think",
    "start": "249060",
    "end": "256380"
  },
  {
    "text": "this is a probably a very typical typical use case that we see in the evolution some people don't even go to",
    "start": "256380",
    "end": "262980"
  },
  {
    "text": "this next step and what we see here is an additional component called the ruler and what this",
    "start": "262980",
    "end": "269520"
  },
  {
    "text": "allows you to do is to do alerting and rural evaluation on a global level most",
    "start": "269520",
    "end": "276270"
  },
  {
    "text": "of the time alerting on the leaf prometheus is just fine and you should always continue doing that but there are",
    "start": "276270",
    "end": "282210"
  },
  {
    "text": "things like trend analysis or like cloth cluster analysis that you want to do",
    "start": "282210",
    "end": "287820"
  },
  {
    "text": "where the ruler comes in handy so you can also make use of all the rule evaluation things that were used to",
    "start": "287820",
    "end": "294840"
  },
  {
    "text": "under leaf Prometheus's and then going even further as I said all of these",
    "start": "294840",
    "end": "300060"
  },
  {
    "text": "components all expose the story API and we don't stop at the querier the courier",
    "start": "300060",
    "end": "305820"
  },
  {
    "text": "also exposes this thing which i think is really cool because now this allows us to layer the system in a hierarchical",
    "start": "305820",
    "end": "312690"
  },
  {
    "text": "manner and build truly global systems so as I was going through all of these",
    "start": "312690",
    "end": "319650"
  },
  {
    "text": "architectures if you paid attention and I hope everyone did I know it's late but",
    "start": "319650",
    "end": "324680"
  },
  {
    "text": "what was common in all of these architectures is one really crucial component and this is the store API and",
    "start": "324680",
    "end": "331020"
  },
  {
    "text": "this is one of the things that I want to deep dive a little bit more into today so literally every component either",
    "start": "331020",
    "end": "339900"
  },
  {
    "text": "exposes or somehow interacts with this API within tonneaus so really the sidecar the store the",
    "start": "339900",
    "end": "347370"
  },
  {
    "text": "ruler the the receive component if you went to some of the other tunnels talks",
    "start": "347370",
    "end": "352680"
  },
  {
    "text": "there were a couple of mentions about this is still an experimental component and you should totally evaluate whether",
    "start": "352680",
    "end": "358230"
  },
  {
    "text": "you actually need that component but this also exposes it and the courier",
    "start": "358230",
    "end": "363990"
  },
  {
    "text": "itself exposes it so I think this is a really important thing to understand",
    "start": "363990",
    "end": "369810"
  },
  {
    "text": "when you run Atanas cluster and that's why we want to talk about it here and one thing that we didn't initially plan",
    "start": "369810",
    "end": "376470"
  },
  {
    "text": "for the store API to do but because this is such a common thing or it's such a",
    "start": "376470",
    "end": "382100"
  },
  {
    "text": "standardized way of communicating within a Thomas cluster this actually allowed for really cool integrations that we had",
    "start": "382100",
    "end": "388050"
  },
  {
    "text": "never thought about so there was a research group for example that implemented an adapter for the that kind",
    "start": "388050",
    "end": "394440"
  },
  {
    "text": "of turns the store api calls into calls against open TS dB and suddenly people could query all this data that",
    "start": "394440",
    "end": "400980"
  },
  {
    "text": "they had historically always had in their open TS DB and query it with the Prometheus query language for example",
    "start": "400980",
    "end": "406950"
  },
  {
    "text": "that's awesome we never even thought of that so I think this is one of those things where having such a common",
    "start": "406950",
    "end": "412740"
  },
  {
    "text": "language to talk our about with our data comes in really really handy so this is",
    "start": "412740",
    "end": "420270"
  },
  {
    "text": "really what the G RPC service definition looks like this is literally what I",
    "start": "420270",
    "end": "425400"
  },
  {
    "text": "copied out of our repo and removed some comments of obviously because we have",
    "start": "425400",
    "end": "430470"
  },
  {
    "text": "comments I promise so one of the things is the info method",
    "start": "430470",
    "end": "435930"
  },
  {
    "text": "and what this is essentially is that the courier when it knows about these stores it periodically goes and grabs of this",
    "start": "435930",
    "end": "442350"
  },
  {
    "text": "information and it tells that courier what data is store a particular store",
    "start": "442350",
    "end": "447570"
  },
  {
    "text": "has so that it knows whether to fan out to this store or not and the series I",
    "start": "447570",
    "end": "452970"
  },
  {
    "text": "think is kind of obvious this is the actual raw data where the courier grabs time series from a store to process in a",
    "start": "452970",
    "end": "461190"
  },
  {
    "text": "query and then the other two are not quite as obvious I think but once you know what it's for I think it is more",
    "start": "461190",
    "end": "466950"
  },
  {
    "text": "obvious switches label names and label values is whenever you type an expression into the expression browser",
    "start": "466950",
    "end": "472830"
  },
  {
    "text": "in tano's or intermediate even this originally is an API that existed or exists in Prometheus is and this is for",
    "start": "472830",
    "end": "480600"
  },
  {
    "text": "autocomplete so when you start typing you get a drop-down in the expression browser that tells you these are all the",
    "start": "480600",
    "end": "487020"
  },
  {
    "text": "metrics that are available it does autocomplete essentially and that's this is how it works internally so let's walk",
    "start": "487020",
    "end": "495570"
  },
  {
    "text": "through the entire workflow essentially from the courier to how it gets all of this data so really like primitive kind",
    "start": "495570",
    "end": "504150"
  },
  {
    "text": "of setup could be that you have your autonomous courier and you literally just say this is the address for my store that I want you to talk to and",
    "start": "504150",
    "end": "511320"
  },
  {
    "text": "this is perfectly fine a lot of people do this but in more dynamic environments",
    "start": "511320",
    "end": "516330"
  },
  {
    "text": "where you maybe have Prometheus servers appearing and disappearing sounds kind of familiar we're a coop can I get Vegas",
    "start": "516330",
    "end": "522500"
  },
  {
    "text": "you may want to use a may want to make use of one of our discovery mechanisms",
    "start": "522500",
    "end": "527880"
  },
  {
    "text": "like DNS discovery and so this could automatically",
    "start": "527880",
    "end": "532950"
  },
  {
    "text": "sure that stores that appear are automatically added to to the courier",
    "start": "532950",
    "end": "539040"
  },
  {
    "text": "and then as I said the courier periodically goes out to these stores and calls the info endpoint and this is",
    "start": "539040",
    "end": "546120"
  },
  {
    "text": "exactly the response that we previously said saw in the ERP see service definition and this is literally what it",
    "start": "546120",
    "end": "552540"
  },
  {
    "text": "returns the time range that this particular store can serve the what kind",
    "start": "552540",
    "end": "558360"
  },
  {
    "text": "of store it is as well as a particular set of labels that identify all the data",
    "start": "558360",
    "end": "563760"
  },
  {
    "text": "in that in that store and why this is important is because now we can make",
    "start": "563760",
    "end": "569280"
  },
  {
    "text": "true- matches of our queries so let's see how that works and what that means",
    "start": "569280",
    "end": "575370"
  },
  {
    "text": "so whenever we do a query this is a very typical query for example that you see",
    "start": "575370",
    "end": "580500"
  },
  {
    "text": "in Prometheus world everything in this query gives us hints as to how we can",
    "start": "580500",
    "end": "585690"
  },
  {
    "text": "optimize this query in antennas so for example we have the metric name and we",
    "start": "585690",
    "end": "593400"
  },
  {
    "text": "have some label selectors on this in this brewery and so this label selector can tell us because some of our stores",
    "start": "593400",
    "end": "601080"
  },
  {
    "text": "are exposing this labels this particular label name so we can make sure we know",
    "start": "601080",
    "end": "608910"
  },
  {
    "text": "because of our query we are selecting region us what did I do US East one we know only truly one of",
    "start": "608910",
    "end": "618510"
  },
  {
    "text": "our stores is ever going to be able to serve data like this and so we know that we don't even have to request all these",
    "start": "618510",
    "end": "625170"
  },
  {
    "text": "other ones and there are a bunch of other my optimizations that we could do that we haven't done yet there are",
    "start": "625170",
    "end": "631740"
  },
  {
    "text": "really typical Innis in a distributed system like this Cassandra for example does a really a couple of really cool",
    "start": "631740",
    "end": "638250"
  },
  {
    "text": "things with bloom filters where we can also do true negative matches so we know",
    "start": "638250",
    "end": "643770"
  },
  {
    "text": "that we never need to fan out to a particular set of notes so those are",
    "start": "643770",
    "end": "648780"
  },
  {
    "text": "things that we want to explore that we haven't really there is still a bunch of experiments that we're running in order",
    "start": "648780",
    "end": "653790"
  },
  {
    "text": "to figure out is fanning out to a store actually that expensive with a with an",
    "start": "653790",
    "end": "659100"
  },
  {
    "text": "empty result so those are some of the questions that were that we're still exploring but just",
    "start": "659100",
    "end": "665560"
  },
  {
    "text": "we thought in a deep dive it's kind of cool to share like the thoughts that we're going through as we're working and",
    "start": "665560",
    "end": "671380"
  },
  {
    "text": "optimizing the system so I talked about this all of this in the sense of the",
    "start": "671380",
    "end": "677950"
  },
  {
    "text": "querier but this is actually an abstraction that we have antennas that we call it a proxy store and why I",
    "start": "677950",
    "end": "684160"
  },
  {
    "text": "bringing this up is because this is not this is not just the querier this is the",
    "start": "684160",
    "end": "689530"
  },
  {
    "text": "concept that we can now reuse and as a matter of fact I won't dive dive into where we reuse this in tonneaus because",
    "start": "689530",
    "end": "697570"
  },
  {
    "text": "actually it hasn't been implemented but it's being discussed but I think it's just really cool that we have these",
    "start": "697570",
    "end": "703570"
  },
  {
    "text": "abstractions that we can talk about in the Tanners project now and we can think about a more abstract level so yeah",
    "start": "703570",
    "end": "711730"
  },
  {
    "text": "that's kind of what I wanted to share about the store API and now Bartek will tell us a little bit of how we actually",
    "start": "711730",
    "end": "718600"
  },
  {
    "text": "are able to serve long-term storage of data Thank You Frederick before we start",
    "start": "718600",
    "end": "725080"
  },
  {
    "text": "I would like to ask two questions can you please raise a hand if you are now",
    "start": "725080",
    "end": "730530"
  },
  {
    "text": "storing and have access to years metric years worth of metrics in your monitoring system anyone have access to",
    "start": "730530",
    "end": "737440"
  },
  {
    "text": "years the layers of the data okay okay so it's pretty rare right because it's a hard problem to solve",
    "start": "737440",
    "end": "743260"
  },
  {
    "text": "and now please raise a hand if you would like to have an access for the years of the data if you would like to have this",
    "start": "743260",
    "end": "748390"
  },
  {
    "text": "feature okay it's like half of the of the room and actually it's it makes",
    "start": "748390",
    "end": "755950"
  },
  {
    "text": "sense because it's super useful to have a very long time metric retention for",
    "start": "755950",
    "end": "761050"
  },
  {
    "text": "your metrics now this is you know crucial because you'd like to have you know data the access to the to the to",
    "start": "761050",
    "end": "769930"
  },
  {
    "text": "the data in the past and you could have you know perform long term characteristic detection or like maybe",
    "start": "769930",
    "end": "776020"
  },
  {
    "text": "you want to report your service level indicators and you want to check something in the past maybe you know you",
    "start": "776020",
    "end": "783310"
  },
  {
    "text": "missed some some detail during incident response or something like that so having this data available in your",
    "start": "783310",
    "end": "790480"
  },
  {
    "text": "storage is the key and as we learned yesterday from Lukas and Dominique on",
    "start": "790480",
    "end": "795910"
  },
  {
    "text": "the Eternals intro and from whether fredericka adjustment ago tennis is designed to have virtual",
    "start": "795910",
    "end": "801889"
  },
  {
    "text": "due to be able to store in the query virtually unlimited retention of your",
    "start": "801889",
    "end": "807110"
  },
  {
    "text": "metrics now in this part I would like to focus and spend time to dive into",
    "start": "807110",
    "end": "813439"
  },
  {
    "text": "challenges that you might have while querying here's of the data in actually",
    "start": "813439",
    "end": "818809"
  },
  {
    "text": "any Prometheus based system so the system that we'll use you know use prom QL as a query layer and all starts with",
    "start": "818809",
    "end": "827149"
  },
  {
    "text": "a dynamic where were the favorite resolution right well think about graphing the metrics on your monitor for",
    "start": "827149",
    "end": "834769"
  },
  {
    "text": "example in prefer a dashboard or prom queue sorta know see why having dynamic query resolution is very important this",
    "start": "834769",
    "end": "841759"
  },
  {
    "text": "is because you know the data and the storage there are probably scraped with high resolution like relatively high",
    "start": "841759",
    "end": "847699"
  },
  {
    "text": "resolution like 15 seconds something for example rendering all of those samples",
    "start": "847699",
    "end": "854179"
  },
  {
    "text": "during query means you no longer time ranges like one month suddenly needs to",
    "start": "854179",
    "end": "859550"
  },
  {
    "text": "display you know two hundred thousand of samples and that's way beyond you know number of pixels we have in our monitors",
    "start": "859550",
    "end": "866059"
  },
  {
    "text": "even if someone has like a you know 4k widescreen match screen so well how prom",
    "start": "866059",
    "end": "874730"
  },
  {
    "text": "we could prom QL engine solves that problem that limitation right and proper",
    "start": "874730",
    "end": "881029"
  },
  {
    "text": "engine is something that many many projects were use right now like panels from to use cortex even right so this",
    "start": "881029",
    "end": "887990"
  },
  {
    "text": "applies to all of them for each query range request from QL defined certain",
    "start": "887990",
    "end": "894079"
  },
  {
    "text": "step and from quell then evaluates the given query every defined step",
    "start": "894079",
    "end": "899660"
  },
  {
    "text": "independent the sample stored in your storage so we can efficiently present",
    "start": "899660",
    "end": "905660"
  },
  {
    "text": "you know larger time range we've read of being here accurate enough so how it",
    "start": "905660",
    "end": "911629"
  },
  {
    "text": "works in practice in this example we have one five hour time range query which we render where",
    "start": "911629",
    "end": "918199"
  },
  {
    "text": "we render like 250 samples per series on the screen but we actually work on 1000",
    "start": "918199",
    "end": "924230"
  },
  {
    "text": "series you know on the storage level and while this works and you can have dynamic query",
    "start": "924230",
    "end": "930320"
  },
  {
    "text": "the resolution there are some limit to it notably like you know maybe when we",
    "start": "930320",
    "end": "936259"
  },
  {
    "text": "extend the time range to to the mouth of the move for time range suddenly we we",
    "start": "936259",
    "end": "944089"
  },
  {
    "text": "are still displaying the same resolution thanks to the dynamic step however we are touching and working on the large",
    "start": "944089",
    "end": "951110"
  },
  {
    "text": "number of samples that in in case of like tahno system we have to somehow",
    "start": "951110",
    "end": "956690"
  },
  {
    "text": "fetch and download for the object storage now downloading is not the only",
    "start": "956690",
    "end": "962209"
  },
  {
    "text": "cost we have right now because for that as you might probably from here we are",
    "start": "962209",
    "end": "967699"
  },
  {
    "text": "storing samples in a compressed chunks which is essentially a gorilla",
    "start": "967699",
    "end": "973910"
  },
  {
    "text": "compression algorithm structures where we store all our samples in this reduces",
    "start": "973910",
    "end": "982190"
  },
  {
    "text": "by the size of the overall storage like 11 times in average and allows us to",
    "start": "982190",
    "end": "988940"
  },
  {
    "text": "save disks IO and network bandwidth in terms of tano's in case of tano's but",
    "start": "988940",
    "end": "994819"
  },
  {
    "text": "there is trade of right and one of the trade-off is that the compressing takes time and for one samples it can be no up",
    "start": "994819",
    "end": "1002110"
  },
  {
    "text": "to 40 nanoseconds so this means like that it's actually fair latency for",
    "start": "1002110",
    "end": "1007630"
  },
  {
    "text": "smaller time rich arrange requests times shorter time range queries however you",
    "start": "1007630",
    "end": "1014470"
  },
  {
    "text": "know when we increase that when you start to query like month of the data it's actually pretty significant amount",
    "start": "1014470",
    "end": "1022690"
  },
  {
    "text": "with time so you know within if we increase that even two year it gets to",
    "start": "1022690",
    "end": "1028630"
  },
  {
    "text": "extreme because we suddenly have to fetch and present like two over two million billions to billions of samples",
    "start": "1028630",
    "end": "1035860"
  },
  {
    "text": "which already takes you know over one minute of the time of the latency just",
    "start": "1035860",
    "end": "1041530"
  },
  {
    "text": "to decompress those samples not mentioning index lookup and other latencies as well so what do we know",
    "start": "1041530",
    "end": "1047319"
  },
  {
    "text": "about like what you now at this point first of all even compress data for one",
    "start": "1047319",
    "end": "1053559"
  },
  {
    "text": "year is is is quite heavy on the disk secondly it takes a long time to decode",
    "start": "1053559",
    "end": "1059409"
  },
  {
    "text": "all those samples on the fly during query and furthermore with dynamic query",
    "start": "1059409",
    "end": "1064730"
  },
  {
    "text": "solution thanks to this step we don't really fully utilize all those samples",
    "start": "1064730",
    "end": "1069860"
  },
  {
    "text": "right so how we can improve the situation now this is where tunnels down",
    "start": "1069860",
    "end": "1074960"
  },
  {
    "text": "sampling camps very handy and this is why tunnels can design down something from the very beginning of the project",
    "start": "1074960",
    "end": "1081280"
  },
  {
    "text": "and the something is this idea of reducing resolution or reducing the",
    "start": "1081280",
    "end": "1087530"
  },
  {
    "text": "resolution of the picture of make maybe metric data while preserving the majority of the accuracy of the result",
    "start": "1087530",
    "end": "1095049"
  },
  {
    "text": "now how we achieve that inside tunnels so as you may be familiar channels are",
    "start": "1095049",
    "end": "1101480"
  },
  {
    "text": "reused at the same TSD before matters perfused us so everything is stored in the t's DB blocks now tano's has this",
    "start": "1101480",
    "end": "1109460"
  },
  {
    "text": "compactor component which compact those blocks but also on top of it it runs non",
    "start": "1109460",
    "end": "1115190"
  },
  {
    "text": "sampling process which transforms those in a row blocks into blocks with five",
    "start": "1115190",
    "end": "1121190"
  },
  {
    "text": "minutes resolution and then this five minute resolution is come in stone sample into one hour this allows to",
    "start": "1121190",
    "end": "1129530"
  },
  {
    "text": "overall reduce massively the chunk size thanks to the lower resolutions but",
    "start": "1129530",
    "end": "1135740"
  },
  {
    "text": "let's look on how we do this while still presently at preserving accuracy right",
    "start": "1135740",
    "end": "1141409"
  },
  {
    "text": "because that's important we don't want to lose any information for each row chunk we have to compute the various",
    "start": "1141409",
    "end": "1147890"
  },
  {
    "text": "aggregations right so technically for each for one chunk we have five smaller aggregation chunks so we have count",
    "start": "1147890",
    "end": "1155600"
  },
  {
    "text": "which you know have number of samples for the current window we have some which which aggregates the sum of the",
    "start": "1155600",
    "end": "1162700"
  },
  {
    "text": "values in the current window we have minimum maximum we have at the end we",
    "start": "1162700",
    "end": "1169010"
  },
  {
    "text": "have also a counter which maintains the state of the counter and make sure we",
    "start": "1169010",
    "end": "1174559"
  },
  {
    "text": "are accounting for the counter resets obviously as well and this is important because this will be used against",
    "start": "1174559",
    "end": "1181580"
  },
  {
    "text": "queries that requires rate functions or rate based offenses like rate increase irate now we also can",
    "start": "1181580",
    "end": "1190790"
  },
  {
    "text": "combine two of those aggregation chunks into together to calculate for example",
    "start": "1190790",
    "end": "1196070"
  },
  {
    "text": "average so that's pretty handy as well so how it works in practice right we we",
    "start": "1196070",
    "end": "1202489"
  },
  {
    "text": "know how it looks on the storage level how essentially from ql knows what chunk",
    "start": "1202489",
    "end": "1209029"
  },
  {
    "text": "to use and if you stir something down sample to resolution at all right so",
    "start": "1209029",
    "end": "1215749"
  },
  {
    "text": "let's take this example from ql query where we have like write a rate over a",
    "start": "1215749",
    "end": "1221450"
  },
  {
    "text": "counter of the others for step 10 seconds which is very very high",
    "start": "1221450",
    "end": "1226759"
  },
  {
    "text": "resolution what is happening is that prom coil ask the storage which is",
    "start": "1226759",
    "end": "1231769"
  },
  {
    "text": "tano's in this case for example and it gives very a lot of details in the in",
    "start": "1231769",
    "end": "1237919"
  },
  {
    "text": "the request we have you know label matures you have time range requested",
    "start": "1237919",
    "end": "1243019"
  },
  {
    "text": "you have a step and hints for for the functions that will be used over this",
    "start": "1243019",
    "end": "1249349"
  },
  {
    "text": "data so because this is high resolution that the requested data is requested to",
    "start": "1249349",
    "end": "1256519"
  },
  {
    "text": "be in high resolution we as a ton of weavers or we are respond with their own",
    "start": "1256519",
    "end": "1261919"
  },
  {
    "text": "chunks now let's imagine that we are actually extending time range to in",
    "start": "1261919",
    "end": "1266929"
  },
  {
    "text": "maybe you know month of the data suddenly the step is automatically calculated to be the safe half an hour",
    "start": "1266929",
    "end": "1274309"
  },
  {
    "text": "and and then Thanos has to decide what resolution teachers on the storage level",
    "start": "1274309",
    "end": "1279769"
  },
  {
    "text": "and it does it by asking can I fit at least five samples within this within",
    "start": "1279769",
    "end": "1285169"
  },
  {
    "text": "this interval and the answer is for half an hour yes we can use five minute",
    "start": "1285169",
    "end": "1290989"
  },
  {
    "text": "resolution because there there will be potentially six samples within that window so yeah this is how this tano's",
    "start": "1290989",
    "end": "1300470"
  },
  {
    "text": "decides how to what resolution to use however as you remember we have like five those aggregation chunks so this is",
    "start": "1300470",
    "end": "1309859"
  },
  {
    "text": "where the hints comes handy from the from the from ql request where it gives",
    "start": "1309859",
    "end": "1315529"
  },
  {
    "text": "us it advices what function will be used in this case right so we know what",
    "start": "1315529",
    "end": "1320590"
  },
  {
    "text": "aggregation should be used on the storage level and present it to the to the",
    "start": "1320590",
    "end": "1325660"
  },
  {
    "text": "well for evaluation now when we change for example query to the average of certain gouge for active others for",
    "start": "1325660",
    "end": "1333580"
  },
  {
    "text": "example then you know hint changes as well average and this is how we know",
    "start": "1333580",
    "end": "1339390"
  },
  {
    "text": "what aggregation chimes to use for example salmon count in this case now",
    "start": "1339390",
    "end": "1346180"
  },
  {
    "text": "okay at this point we know how ton of them samples the data how he chooses what our chance to use over on the query",
    "start": "1346180",
    "end": "1353740"
  },
  {
    "text": "time but let's look on the reservoir we fix what we fixed what we solved so this",
    "start": "1353740",
    "end": "1358960"
  },
  {
    "text": "is a you know if instead of the high-resolution data I will use them",
    "start": "1358960",
    "end": "1364780"
  },
  {
    "text": "sample data for the month or one year queries we suddenly can achieve much much more you can be user-friendly",
    "start": "1364780",
    "end": "1371260"
  },
  {
    "text": "experience right and and and lower load on the panel system and performing those",
    "start": "1371260",
    "end": "1377770"
  },
  {
    "text": "long term that long time range queries are much much known much more cheaper",
    "start": "1377770",
    "end": "1383260"
  },
  {
    "text": "and faster which was our initial goal now there are like few things that you",
    "start": "1383260",
    "end": "1389740"
  },
  {
    "text": "need to be careful when using down sampling and this is why down something was was previously released as a",
    "start": "1389740",
    "end": "1396400"
  },
  {
    "text": "experimental feature first of all some us are choosing the step in a different",
    "start": "1396400",
    "end": "1402670"
  },
  {
    "text": "way for example for me to use you I and tunnels you I are having semantics of specifying you know interval in seconds",
    "start": "1402670",
    "end": "1409180"
  },
  {
    "text": "however when is graph Anna there is this thing called resolution which is essentially a ratio of samples per pixel",
    "start": "1409180",
    "end": "1415920"
  },
  {
    "text": "secondly using great with non sampled data might be tricky so people used to",
    "start": "1415920",
    "end": "1422320"
  },
  {
    "text": "have just raw data and and used to hard code this five-minute orange selection and there is very important thing about",
    "start": "1422320",
    "end": "1430300"
  },
  {
    "text": "it because to forget to work correctly you need to have at least two samples",
    "start": "1430300",
    "end": "1435430"
  },
  {
    "text": "within this range selector and now when you query the data that is maybe you",
    "start": "1435430",
    "end": "1441520"
  },
  {
    "text": "have lower resolution so for example for five minutes you might have been a one sample it's it's in this case you need",
    "start": "1441520",
    "end": "1449800"
  },
  {
    "text": "to kind of increase this range select range selector to the larger values for this function to",
    "start": "1449800",
    "end": "1455210"
  },
  {
    "text": "makes sense that's why you should use you know maybe one hour and maybe for five hours for the queries that we'll be",
    "start": "1455210",
    "end": "1462620"
  },
  {
    "text": "using you know one hour resolution however in graph Anna there is something",
    "start": "1462620",
    "end": "1467720"
  },
  {
    "text": "like interval variable which is very handy as well because it automatically calculates you what is a sensible range",
    "start": "1467720",
    "end": "1475220"
  },
  {
    "text": "selector that should be used for a given time range and last but not least you need to be careful if you you know set",
    "start": "1475220",
    "end": "1482240"
  },
  {
    "text": "your attention to just remove all your role or like most of your row data and",
    "start": "1482240",
    "end": "1488299"
  },
  {
    "text": "just store you know done sampled resolution down sampled blocks it's",
    "start": "1488299",
    "end": "1493880"
  },
  {
    "text": "really easy to forget that you it will work if you query in a one month one year Kappa I don't know a couple of",
    "start": "1493880",
    "end": "1499700"
  },
  {
    "text": "weeks however if you want to zoom into certain situation suddenly you won't see",
    "start": "1499700",
    "end": "1505130"
  },
  {
    "text": "any samples so this is something to have in mind I mean idea what you are you'd like",
    "start": "1505130",
    "end": "1511370"
  },
  {
    "text": "you'd have you know all those order resolutions available in your system which allows flexibility because you can",
    "start": "1511370",
    "end": "1517549"
  },
  {
    "text": "query a long time record by ranges as well as zooming into you know what happened one year ago now there is a",
    "start": "1517549",
    "end": "1524240"
  },
  {
    "text": "trader obviously and the trade of here is that that it increases the size of the store data in the object storage",
    "start": "1524240",
    "end": "1530029"
  },
  {
    "text": "however we choose and you know obvious large because it's cheap so this is might might be worth to consider it's",
    "start": "1530029",
    "end": "1538940"
  },
  {
    "text": "also morph to mention that that the prom to you second system is looking for some down sampling solution right and and oh",
    "start": "1538940",
    "end": "1546490"
  },
  {
    "text": "they try to explore if it's useful and if yes like what implementation should",
    "start": "1546490",
    "end": "1552110"
  },
  {
    "text": "be should be it should be done should be choosing and Isetta knows like we we",
    "start": "1552110",
    "end": "1560360"
  },
  {
    "text": "choosing some implementation and and we are already discussing and collaborating",
    "start": "1560360",
    "end": "1566000"
  },
  {
    "text": "with other system to make this than something a standard right maybe to have this in the prompt to use itself so we",
    "start": "1566000",
    "end": "1572899"
  },
  {
    "text": "are looking forward to you know collaborate even more with with projects like cortex or MVB where we can have a",
    "start": "1572899",
    "end": "1579440"
  },
  {
    "text": "comment on something logic that we can already an improvement now that was for",
    "start": "1579440",
    "end": "1585230"
  },
  {
    "text": "done something right but like unrelated now unlimited retention like obviously there",
    "start": "1585230",
    "end": "1594149"
  },
  {
    "text": "are some consequences on like you need to scale the long-term storage width as",
    "start": "1594149",
    "end": "1599760"
  },
  {
    "text": "well right so this is something we were improving",
    "start": "1599760",
    "end": "1605460"
  },
  {
    "text": "over the last month by an eyeblink like a couple of new mechanisms for scaling",
    "start": "1605460",
    "end": "1611610"
  },
  {
    "text": "the store gateway essentially and the store gateway is this component that is",
    "start": "1611610",
    "end": "1616850"
  },
  {
    "text": "deployed on the objects nicknamed against the object storage and allows you to browsing",
    "start": "1616850",
    "end": "1621990"
  },
  {
    "text": "Broz those altmetrics and overall tours great however with large huge number of",
    "start": "1621990",
    "end": "1628919"
  },
  {
    "text": "objects in the object search you you can expect some kind of slowdown so you need",
    "start": "1628919",
    "end": "1638250"
  },
  {
    "text": "to be able to have like a scale of platform for this case and one of the mechanism here is time partitioning so",
    "start": "1638250",
    "end": "1645809"
  },
  {
    "text": "in the current version of the of the newest version of the terrace we allowed",
    "start": "1645809",
    "end": "1651330"
  },
  {
    "text": "to you know kind of tell the store gateway to be responsible only for a subset of the blocks for a certain time",
    "start": "1651330",
    "end": "1656880"
  },
  {
    "text": "range so with this configuration if the query will I mean if the query will",
    "start": "1656880",
    "end": "1663600"
  },
  {
    "text": "touch the certain time range it will go for example one year or like half a year",
    "start": "1663600",
    "end": "1669240"
  },
  {
    "text": "ago or before it would go to the upper store gateway if if it will be a for afresh data it will go to the another",
    "start": "1669240",
    "end": "1675870"
  },
  {
    "text": "one second mechanism to to scale out store get you a two different nodes is a",
    "start": "1675870",
    "end": "1681510"
  },
  {
    "text": "block sharding block starting is is again a way to tell store get way to be",
    "start": "1681510",
    "end": "1689370"
  },
  {
    "text": "responsible only for a certain blocks for example for blocks from a certain region like in this example",
    "start": "1689370",
    "end": "1695270"
  },
  {
    "text": "thanks to that and actually you do that by a kind of relabel in configuration",
    "start": "1695270",
    "end": "1701010"
  },
  {
    "text": "that is exactly the same as rebuilding doing scrape scraping the data on from",
    "start": "1701010",
    "end": "1708059"
  },
  {
    "text": "queue size or service discovery and and you essentially tell what blocks to",
    "start": "1708059",
    "end": "1713940"
  },
  {
    "text": "choose based on external label as well so thanks of that when you have a query against you know maybe certain of",
    "start": "1713940",
    "end": "1720179"
  },
  {
    "text": "selecting that is selecting certain you you know where to like what Stargate",
    "start": "1720179",
    "end": "1726179"
  },
  {
    "text": "with the touch and you you only direct this query to the correspondent store",
    "start": "1726179",
    "end": "1731730"
  },
  {
    "text": "gateway which again allows us to scale out target weight in some way now yeah",
    "start": "1731730",
    "end": "1741480"
  },
  {
    "text": "overall let's sum up what we learned today we explained our store API and you know",
    "start": "1741480",
    "end": "1748799"
  },
  {
    "text": "what role it has in our system and why it keeps flexibility in the way we dive into down sampling and and why it's",
    "start": "1748799",
    "end": "1755580"
  },
  {
    "text": "important and what we actually are solving here and last but not least we touch them ways to further scale out the",
    "start": "1755580",
    "end": "1762809"
  },
  {
    "text": "read path on the tunnels long-term storage so with this being said we are",
    "start": "1762809",
    "end": "1767970"
  },
  {
    "text": "thank you thank you for listening to us and yeah we're happy to take some questions and we might have four minutes",
    "start": "1767970",
    "end": "1775260"
  },
  {
    "text": "for that yet",
    "start": "1775260",
    "end": "1777919"
  },
  {
    "text": "any questions okay you can ask the first question and then your mother it sounds",
    "start": "1782310",
    "end": "1788940"
  },
  {
    "text": "good so I had a question about the read hints so I assume you're picking apart the prompt QL and you see certain",
    "start": "1788940",
    "end": "1794130"
  },
  {
    "text": "functions and you like a list identify like a read hint does that mean you have to have a read hint hard-coded in Thanos",
    "start": "1794130",
    "end": "1799530"
  },
  {
    "text": "somewhere for every bronchial function in order to handle it efficiently yeah so you say so but there was only like a",
    "start": "1799530",
    "end": "1807330"
  },
  {
    "text": "six of those to be honest so you know we care about minimum maximum yes we need to much to the aggregations we care",
    "start": "1807330",
    "end": "1813300"
  },
  {
    "text": "about rate based functions and count and some so there is like not many of those",
    "start": "1813300",
    "end": "1819120"
  },
  {
    "text": "and kind of fortunately because prom coup is very stable in term of functions this works well but yes overall that's",
    "start": "1819120",
    "end": "1826950"
  },
  {
    "text": "the idea thank you",
    "start": "1826950",
    "end": "1830450"
  },
  {
    "text": "thanks for great I had a question about how to layer like would you recommend",
    "start": "1836030",
    "end": "1843660"
  },
  {
    "text": "like what's a reasonable number of meteors instances to have one tightness",
    "start": "1843660",
    "end": "1850050"
  },
  {
    "text": "behind and when do you want to uh sort of add another query on top of it like do you just do it on a DC and if you'll",
    "start": "1850050",
    "end": "1856530"
  },
  {
    "text": "have every service in there or Denis who say like oh well 500 services per query or basic visit yeah so the good and bad",
    "start": "1856530",
    "end": "1864570"
  },
  {
    "text": "answer here is Thomas is almost a toolkit right so there's no one-size-fits-all so that's part of the",
    "start": "1864570",
    "end": "1872760"
  },
  {
    "text": "sad answer because there there is no one-size-fits-all but it also means that you can optimize exactly for your use",
    "start": "1872760",
    "end": "1879480"
  },
  {
    "text": "case so yeah there's no there's no real answer to this but most people the way",
    "start": "1879480",
    "end": "1886770"
  },
  {
    "text": "that we see it is that people start layering or people start with a sidecar",
    "start": "1886770",
    "end": "1891780"
  },
  {
    "text": "they use the Site tour as the upload mechanism and it's really just a backup right they add the query err you get",
    "start": "1891780",
    "end": "1897540"
  },
  {
    "text": "horizontal like global view of your data then you do long-term storage and then",
    "start": "1897540",
    "end": "1904680"
  },
  {
    "text": "maybe you have another courier that spends across all your clusters so",
    "start": "1904680",
    "end": "1909990"
  },
  {
    "text": "that's a totally typical kind of texture and like I highly recommend",
    "start": "1909990",
    "end": "1915280"
  },
  {
    "text": "everyone doing that at first when to add",
    "start": "1915280",
    "end": "1920890"
  },
  {
    "text": "a new prometheus for example is more less of a question of a proton owes more",
    "start": "1920890",
    "end": "1928230"
  },
  {
    "text": "how large of a machine are you willing to pay for for that prometheus is more",
    "start": "1928230",
    "end": "1933570"
  },
  {
    "text": "more the question here because at the end of the day you always will need to",
    "start": "1933570",
    "end": "1939340"
  },
  {
    "text": "ingest all of that data right and if you charted across multiple Prometheus instances or have it in one doesn't",
    "start": "1939340",
    "end": "1944830"
  },
  {
    "text": "really matter unless you want to really pack it bin pack it into small machines",
    "start": "1944830",
    "end": "1950169"
  },
  {
    "text": "write that that's totally a legit thing to do but that it doesn't nominally have anything to do with tonneaus it's just",
    "start": "1950169",
    "end": "1956080"
  },
  {
    "text": "scaling your Prometheus service does that sort of answer the question the",
    "start": "1956080",
    "end": "1962230"
  },
  {
    "text": "layering of panels where we had like multiple queries like you'll have one / DC and then you'll have one global one",
    "start": "1962230",
    "end": "1967720"
  },
  {
    "text": "sort of so you have two layers of thanas but would it be sort of should you have",
    "start": "1967720",
    "end": "1972850"
  },
  {
    "text": "good in the DC maybe two query query instances sort of that takes care of",
    "start": "1972850",
    "end": "1977860"
  },
  {
    "text": "different services yeah that'll make sense so yeah you're essentially asking if like when to use for the rated",
    "start": "1977860",
    "end": "1984280"
  },
  {
    "text": "queries and stuff like that like essentially there is no recommendation",
    "start": "1984280",
    "end": "1989830"
  },
  {
    "text": "from the like panel side like all in terms of efficiency there is not much of",
    "start": "1989830",
    "end": "1994900"
  },
  {
    "text": "the difference however it's just you know the user experience difference maybe you want to expose you know be",
    "start": "1994900",
    "end": "2001799"
  },
  {
    "text": "able to just allow users to query for just one cluster site or or like",
    "start": "2001799",
    "end": "2006929"
  },
  {
    "text": "something that is a that's very popular you have like different environments right production testing and staging and",
    "start": "2006929",
    "end": "2013230"
  },
  {
    "text": "you have you know tunnels on those free environments because you want to isolate the data and I would really recommend",
    "start": "2013230",
    "end": "2018809"
  },
  {
    "text": "that and then you have a federated layer on top of this because maybe another base administrator want to or like any",
    "start": "2018809",
    "end": "2024990"
  },
  {
    "text": "other use case where you would like to have a aggregation over different environments for a cost for example",
    "start": "2024990",
    "end": "2030809"
  },
  {
    "text": "calculation or something like that so it's really yeah your requirements",
    "start": "2030809",
    "end": "2036299"
  },
  {
    "text": "should shape kind of tano's and there's no like efficiency difference here in",
    "start": "2036299",
    "end": "2041700"
  },
  {
    "text": "layering at least right yes yes we will have to upload the",
    "start": "2041700",
    "end": "2048370"
  },
  {
    "text": "slides there's a question over here uh",
    "start": "2048370",
    "end": "2057460"
  },
  {
    "text": "you showed some of the like performance benefits of down sampling does it is",
    "start": "2057460",
    "end": "2063370"
  },
  {
    "text": "there any difference in like the storage size like you know raw data over a month",
    "start": "2063370",
    "end": "2070780"
  },
  {
    "text": "versus just having like our yeah or I mean yeah so I think this is like a very",
    "start": "2070780",
    "end": "2079600"
  },
  {
    "text": "important like thing to remember like down sampling is meant to improve your query",
    "start": "2079600",
    "end": "2085270"
  },
  {
    "text": "time right so it's not compressing here your data that much like essentially yes",
    "start": "2085270",
    "end": "2092290"
  },
  {
    "text": "technically the raw blog and you know the five minute resolution will probably provide from into position will be a bit",
    "start": "2092290",
    "end": "2097960"
  },
  {
    "text": "smaller however it's not you know focused on being like compress on a disk like we",
    "start": "2097960",
    "end": "2104650"
  },
  {
    "text": "were optimizing for the query latency for a long time ranges so yeah that's",
    "start": "2104650",
    "end": "2111340"
  },
  {
    "text": "why you should not you know if you if you just want to choose one resolution",
    "start": "2111340",
    "end": "2117010"
  },
  {
    "text": "to store maybe even a roll resolution make sense more because people tend to",
    "start": "2117010",
    "end": "2122350"
  },
  {
    "text": "just use you know users tend to use you know just use down sampling and just remove everything else just okay we have",
    "start": "2122350",
    "end": "2128260"
  },
  {
    "text": "one year don't sound data for a long time yes but then you cannot zoom in",
    "start": "2128260",
    "end": "2133780"
  },
  {
    "text": "however you could just switch this and essentially have a maybe use exactly the same space but just use roadblocks and",
    "start": "2133780",
    "end": "2140350"
  },
  {
    "text": "maybe this will fit your use case smaller surgery it depends on our needs thank you",
    "start": "2140350",
    "end": "2146650"
  },
  {
    "text": "yeah I think something important to remember here is that like in abling down something actually increases the",
    "start": "2146650",
    "end": "2152860"
  },
  {
    "text": "size of the data that you store but it in like reduces the latency of your",
    "start": "2152860",
    "end": "2158020"
  },
  {
    "text": "curries and if you don't care about the high-resolution data then you can have a low resolution on that and keep the",
    "start": "2158020",
    "end": "2165450"
  },
  {
    "text": "lower resolution data for longer but that as partic said means that you can zoom in and I get the high resolution",
    "start": "2165450",
    "end": "2172030"
  },
  {
    "text": "data so again like choose what suits your needs yes",
    "start": "2172030",
    "end": "2177800"
  },
  {
    "text": "here just a question with down sampling and and querying down sampled data or",
    "start": "2177800",
    "end": "2185030"
  },
  {
    "text": "making queries that include down sample data and very recent data that might be sitting in a journal does the journal",
    "start": "2185030",
    "end": "2191120"
  },
  {
    "text": "inhibit the performance of a lot of queries or do you include the journal information in in in the downsampled",
    "start": "2191120",
    "end": "2198380"
  },
  {
    "text": "output or do you exclude it so you don't draw information yeah I don't know much about the architecture but you if you",
    "start": "2198380",
    "end": "2204290"
  },
  {
    "text": "put journaling in the top right of the time series database you're kind of talking like the right ahead log we are",
    "start": "2204290",
    "end": "2212180"
  },
  {
    "text": "talking about one year of their of their time ranges month for the time ranges where wall is like two hours so it's not",
    "start": "2212180",
    "end": "2218090"
  },
  {
    "text": "a significant you know kind of so you know when you curl one year and maybe yes two days or like you know even even",
    "start": "2218090",
    "end": "2226010"
  },
  {
    "text": "a week it's not done sampled here and that's true for the fresh data this is still okay like we are talking about you",
    "start": "2226010",
    "end": "2232820"
  },
  {
    "text": "know lower resolution for majority of your requite of your time range right they are requesting on but that's a good",
    "start": "2232820",
    "end": "2237890"
  },
  {
    "text": "point yeah right right okay so you just admitted yeah that's good answer okay I",
    "start": "2237890",
    "end": "2243830"
  },
  {
    "text": "think we are out of time unless there was like last quick question this is",
    "start": "2243830",
    "end": "2254750"
  },
  {
    "text": "regarding down sampling again so the thing is like you guys are showing the certain standard aggregations right like",
    "start": "2254750",
    "end": "2261800"
  },
  {
    "text": "count some main max how would it actually work for percentage like let's",
    "start": "2261800",
    "end": "2267200"
  },
  {
    "text": "say certain metrics I don't care about average I only care about like percentiles how would I actually down",
    "start": "2267200",
    "end": "2272960"
  },
  {
    "text": "sample a core is any plans for you an adding support for percentile aggregation for down sampling data so",
    "start": "2272960",
    "end": "2279310"
  },
  {
    "text": "percentile or I I assume you mean hit like history or title or something like that right so we would do the",
    "start": "2279310",
    "end": "2288290"
  },
  {
    "text": "calculation for that based on down sampled data as vatic showed like we retain the counter hit remember a",
    "start": "2288290",
    "end": "2295130"
  },
  {
    "text": "histogram is just in composition of multiple counters and so we down sampled",
    "start": "2295130",
    "end": "2302180"
  },
  {
    "text": "those counters and then we can still do the histogram quantile aggregation on that down sampled data it's just a lot",
    "start": "2302180",
    "end": "2308660"
  },
  {
    "text": "less data that we have to process at this point because it's downsampled okay cool okay",
    "start": "2308660",
    "end": "2315810"
  },
  {
    "text": "thank you thank you [Applause]",
    "start": "2315810",
    "end": "2321150"
  }
]
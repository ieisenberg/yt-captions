[
  {
    "text": "hello everyone um we are here on the maintainers track and learn about",
    "start": "0",
    "end": "5759"
  },
  {
    "text": "thanos and yeah some kind of introduction about tanos and we're super excited to be here",
    "start": "5759",
    "end": "11759"
  },
  {
    "text": "in person finally and you know it's our first really kubecon after after covet so it's amazing to be",
    "start": "11759",
    "end": "18560"
  },
  {
    "text": "here and hopefully there will be some interactive time where you can ask some questions because this is",
    "start": "18560",
    "end": "24080"
  },
  {
    "text": "uh yeah we can have this versus whatever we have in virtually uh that wasn't so so possible so today",
    "start": "24080",
    "end": "31039"
  },
  {
    "text": "we'll learn about uh thanos but we also learned about other projects in the ecosystem open source projects that",
    "start": "31039",
    "end": "38960"
  },
  {
    "text": "really are fulfilling the whole observability story because as we know metrics are kind of the cheapest and the",
    "start": "38960",
    "end": "46960"
  },
  {
    "text": "most reliable you know first observability signal where you have your",
    "start": "46960",
    "end": "52000"
  },
  {
    "text": "instrumentation you have your monitoring maybe you've probably used maybe with tunnels and then you end up having a",
    "start": "52000",
    "end": "57840"
  },
  {
    "text": "kind of reliable and and quick to use uh you know alerting and debugging uh platform but it's not everything right",
    "start": "57840",
    "end": "64640"
  },
  {
    "text": "there are amazing tools that you can combine with um and we'll discuss you know what are the",
    "start": "64640",
    "end": "71119"
  },
  {
    "text": "challenges there and what are the ways to mitigate those problems but before that short introduction my",
    "start": "71119",
    "end": "77200"
  },
  {
    "text": "name is bartek plotka and i'm principal software engineer at red hat i maintain many many projects in open source um and",
    "start": "77200",
    "end": "84640"
  },
  {
    "text": "the biggest one are prometheus and thanos um really mainly about goldbank and my passion towards golank and open",
    "start": "84640",
    "end": "91040"
  },
  {
    "text": "source kind of made me also create a book and this book is coming in",
    "start": "91040",
    "end": "96960"
  },
  {
    "text": "december it's called efficient go and it's really about you know performance and and efficiency of golang",
    "start": "96960",
    "end": "103600"
  },
  {
    "text": "in a very pragmatic way and there's lots of yeah i couldn't stop myself but there's lots of observability there as well and",
    "start": "103600",
    "end": "110079"
  },
  {
    "text": "i have a camel with me hello everyone uh the name is camera i'm also a maintainer",
    "start": "110079",
    "end": "115119"
  },
  {
    "text": "of couple of open source project not as many as biotech i guess and recently i joined polar signals we",
    "start": "115119",
    "end": "122560"
  },
  {
    "text": "are an observability company and we are building continuous profiling products and i i we have a open source offering",
    "start": "122560",
    "end": "130080"
  },
  {
    "text": "called parka we're gonna actually demo on it also we recently open sourced another",
    "start": "130080",
    "end": "138800"
  },
  {
    "text": "part of our company which is an arctic db it's an open source database columnar",
    "start": "138800",
    "end": "144640"
  },
  {
    "text": "storage uh specifically before the observability signals and we are looking for database engineers so if you can go",
    "start": "144640",
    "end": "151599"
  },
  {
    "text": "to our website you can find the details but today we're gonna start talking",
    "start": "151599",
    "end": "156800"
  },
  {
    "text": "about prometheus which everything actually start with prometheus is a monitoring system inspired by borgmon uh",
    "start": "156800",
    "end": "164319"
  },
  {
    "text": "which is a tool uh created in google with the prometheus we are",
    "start": "164319",
    "end": "169680"
  },
  {
    "text": "providing a highly reliable uh easy to operate monitoring system a lot of",
    "start": "169680",
    "end": "175120"
  },
  {
    "text": "components uh just included in a single binary like alerting like querying prometus also has a",
    "start": "175120",
    "end": "182000"
  },
  {
    "text": "query language which is very flexible for you to just like monitor and create alerts",
    "start": "182000",
    "end": "188480"
  },
  {
    "text": "so and that kind of brings us to thanos which we may just say distributed",
    "start": "188480",
    "end": "195360"
  },
  {
    "text": "prometus plus plus prometheus has certain problems like it's just a single binary and you can only just vertically",
    "start": "195360",
    "end": "202560"
  },
  {
    "text": "scale it and when you have when you need highly available system you need some",
    "start": "202560",
    "end": "207680"
  },
  {
    "text": "additional facilities that's where thanos comes in",
    "start": "207680",
    "end": "212720"
  },
  {
    "text": "with thanos we are providing highly available horizontal scalable data",
    "start": "212720",
    "end": "218319"
  },
  {
    "text": "storage for prometheus basically so thanos is nearly",
    "start": "218319",
    "end": "224560"
  },
  {
    "text": "five years old now and we've been an incubating project uh nearly three years",
    "start": "224560",
    "end": "229840"
  },
  {
    "text": "if i'm not mistaken we recently crossed like 400 contributors and",
    "start": "229840",
    "end": "235360"
  },
  {
    "text": "uh we have a lot of slack users so we are we have we are a really vibrant community",
    "start": "235360",
    "end": "240400"
  },
  {
    "text": "like we always active and we answer your questions uh so if you want to reach out",
    "start": "240400",
    "end": "245519"
  },
  {
    "text": "like just join our slack channel and we just recently crossed the 10k",
    "start": "245519",
    "end": "251040"
  },
  {
    "text": "stars on github which is the most important metric of all as you all know",
    "start": "251040",
    "end": "257680"
  },
  {
    "text": "we have many many adapters many enterprise adapters like the people are using this in production and like with",
    "start": "257840",
    "end": "264560"
  },
  {
    "text": "really really highly scalable environments okay",
    "start": "264560",
    "end": "269600"
  },
  {
    "text": "now let's see how we actually get from prometheus to thanos in prometus we have different components",
    "start": "269600",
    "end": "276720"
  },
  {
    "text": "and all these components kind of kind of like living in the same binary we do this because like with a",
    "start": "276720",
    "end": "282880"
  },
  {
    "text": "single binary with a single process we can actually provide more reliable solutions and it's easy to",
    "start": "282880",
    "end": "288880"
  },
  {
    "text": "operate uh like of course there are some drawbacks like you need to install prometus closer to your workload so for",
    "start": "288880",
    "end": "296080"
  },
  {
    "text": "that like for each component by with thanos we created another dedicated",
    "start": "296080",
    "end": "301280"
  },
  {
    "text": "component like for the query pieces we we have thanos querier uh for scraping",
    "start": "301280",
    "end": "307120"
  },
  {
    "text": "pieces we have a side carve where you can actually deploy near prometheus and for the rule engine we have another",
    "start": "307120",
    "end": "313919"
  },
  {
    "text": "thing called thanos ruler so thanos has different deployment models one of them",
    "start": "313919",
    "end": "318960"
  },
  {
    "text": "is as this in described here it's a side core deployment model you can just put",
    "start": "318960",
    "end": "324400"
  },
  {
    "text": "the put the sidecar module near your prometeuses and you can have a global",
    "start": "324400",
    "end": "330240"
  },
  {
    "text": "view of all the prometuses that you connect with the sidecar another",
    "start": "330240",
    "end": "336240"
  },
  {
    "text": "model is to have an object storage for like long-term retention uh then with",
    "start": "336240",
    "end": "342639"
  },
  {
    "text": "the help of the site car we can ship all the blocks to the object store which is",
    "start": "342639",
    "end": "347680"
  },
  {
    "text": "like cheap to store and then you can just query using another component called thanos store api store",
    "start": "347680",
    "end": "354800"
  },
  {
    "text": "which we come to the api part one last thing to mention we also have a",
    "start": "354800",
    "end": "360639"
  },
  {
    "text": "another component called thanos receiver which gives you the ability to actually push your metrics directly to another",
    "start": "360639",
    "end": "367840"
  },
  {
    "text": "storage it depends on depending on your like net network topologies you may find this",
    "start": "367840",
    "end": "374560"
  },
  {
    "text": "useful rather than having a pool based model so how we actually do this uh thanks to",
    "start": "374560",
    "end": "381039"
  },
  {
    "text": "the store api which is a flexible api for us each component kind of",
    "start": "381039",
    "end": "386479"
  },
  {
    "text": "like exposes this api and from the sonos query perspective uh this is seamless",
    "start": "386479",
    "end": "393039"
  },
  {
    "text": "right so when we check the store api like thomas ruler is a",
    "start": "393039",
    "end": "398639"
  },
  {
    "text": "store api receiver store itself even sidecar itself when we say the store api",
    "start": "398639",
    "end": "404880"
  },
  {
    "text": "like it's not just a metrics but we have all other meta information that are available with that we can get all the",
    "start": "404880",
    "end": "411919"
  },
  {
    "text": "examples for example we can get the alerts we can get the recording rules like everything so with the flexibility",
    "start": "411919",
    "end": "419360"
  },
  {
    "text": "of the store api we can just like interchange all these components",
    "start": "419360",
    "end": "424720"
  },
  {
    "text": "so what we've been this recently working on is couple of improvements mostly around",
    "start": "424720",
    "end": "430880"
  },
  {
    "text": "like uh performance improvements or kind of helping to community to use",
    "start": "430880",
    "end": "437680"
  },
  {
    "text": "different solutions for their uh like caching backends for instance if you prefer to use redis now you can actually",
    "start": "437680",
    "end": "444960"
  },
  {
    "text": "add redis as your store cache backend one other cashback can we add is group cache",
    "start": "444960",
    "end": "450800"
  },
  {
    "text": "which is easier to operate it's not an external dependency you can just embed this into your thanos components and you",
    "start": "450800",
    "end": "457360"
  },
  {
    "text": "don't need anything anything else uh also we recently improved our like",
    "start": "457360",
    "end": "463120"
  },
  {
    "text": "tls support to 1.2 by default more security improvements uh vivin as i told you working on a lot",
    "start": "463120",
    "end": "471440"
  },
  {
    "text": "of performance improvements one of them is grp security api it's not just for",
    "start": "471440",
    "end": "477120"
  },
  {
    "text": "the performance uh we also uh has a new model of querying which is",
    "start": "477120",
    "end": "482720"
  },
  {
    "text": "like push down querying which is like we are getting the query and pushing down to all the store apis and then",
    "start": "482720",
    "end": "489360"
  },
  {
    "text": "collecting them back kind of on my produce model and it really helps us to improve stuff",
    "start": "489360",
    "end": "495919"
  },
  {
    "text": "uh somewhat similar to that we recently introduced this is not merged yet but",
    "start": "495919",
    "end": "502479"
  },
  {
    "text": "it's about to merge this will help us to get the data from store api a little bit faster",
    "start": "502479",
    "end": "510960"
  },
  {
    "text": "and as we talked about push down queries we just added some aggregation support",
    "start": "511039",
    "end": "516320"
  },
  {
    "text": "for the query pushdown the pr is already there like we keep uh working on that but if you",
    "start": "516320",
    "end": "524080"
  },
  {
    "text": "want to know about uh more know more about queer pushdown we have another",
    "start": "524080",
    "end": "529680"
  },
  {
    "text": "talk coming i guess it's in two hours right from philip he will be going through all",
    "start": "529680",
    "end": "535680"
  },
  {
    "text": "the recent changes about the query pushdown api and the big news okay we",
    "start": "535680",
    "end": "542480"
  },
  {
    "text": "finally met in person and we had our dev summit and we decided that our apis are",
    "start": "542480",
    "end": "548480"
  },
  {
    "text": "pretty stable we haven't changed them for the couple of even years right so it's time",
    "start": "548480",
    "end": "554560"
  },
  {
    "text": "to actually bump the tunnels to version one for that we have couple of agenda items that we need to take care of but",
    "start": "554560",
    "end": "561279"
  },
  {
    "text": "we targeted the next cube cone for the thanos 1.0 basically this doesn't change",
    "start": "561279",
    "end": "568560"
  },
  {
    "text": "anything for you i guess like the apis are pretty stable we just need to clean couple of flags maybe",
    "start": "568560",
    "end": "574800"
  },
  {
    "text": "so that we won't like be supporting uh some experiments",
    "start": "574800",
    "end": "580320"
  },
  {
    "text": "anywhere anything else to add in here yeah it's great cool and it's demo time actually let's see",
    "start": "580320",
    "end": "587600"
  },
  {
    "text": "tunnels in action yeah let's do that so we're working on this very very hard and",
    "start": "587600",
    "end": "594480"
  },
  {
    "text": "like literally before the talk as well so let's see what happens i will start by just starting the demo setup and i",
    "start": "594480",
    "end": "600160"
  },
  {
    "text": "will then explain that demo setup to you so it's written in kind of golang unit",
    "start": "600160",
    "end": "605920"
  },
  {
    "text": "test and i will talk about that maybe later but i would start and meantime it starts pretty quickly",
    "start": "605920",
    "end": "612720"
  },
  {
    "text": "but then metrics have to propagate so it takes some time i will discuss the actual setup",
    "start": "612720",
    "end": "620880"
  },
  {
    "text": "so the setup is following i wanted to kind of mimic like uh",
    "start": "620880",
    "end": "626160"
  },
  {
    "text": "you know the proper production setup that you usually would have with tunnels and this is one of many options",
    "start": "626160",
    "end": "632480"
  },
  {
    "text": "and as camel mentioned there are kind of oh you see it's starting there are um kind of three major",
    "start": "632480",
    "end": "639440"
  },
  {
    "text": "deployment models of channels so this is the most complex one that you probably you should do at the at the end of your",
    "start": "639440",
    "end": "645600"
  },
  {
    "text": "journey with thanos like that the ultimate sas kind of metrics um but at the end um how it",
    "start": "645600",
    "end": "652720"
  },
  {
    "text": "works we have we i'm i kind of let's imagine we have like customer clusters so a separate cluster under you",
    "start": "652720",
    "end": "658800"
  },
  {
    "text": "know different network where we run our applications so i have demo applications it's like simple ping server it's like a",
    "start": "658800",
    "end": "664560"
  },
  {
    "text": "simple you know slash ping http and i have finger so uh kind of clients that",
    "start": "664560",
    "end": "669839"
  },
  {
    "text": "are spamming those things uh within the pink pink web server and i want to observe my pink and make sure it's",
    "start": "669839",
    "end": "676079"
  },
  {
    "text": "healthy and i can debug that and i have full observability so i kind of installed lots of goodies into that so",
    "start": "676079",
    "end": "681360"
  },
  {
    "text": "first i instrumented that with metrix and i used grafana agent but i could use promoters as well",
    "start": "681360",
    "end": "687760"
  },
  {
    "text": "and rafana agent or promote use in this case as well actually graphing is embedding prometheus uh you know we",
    "start": "687760",
    "end": "694079"
  },
  {
    "text": "scrape metrics from this pink application and then remote right so kind of export to a separate cluster and",
    "start": "694079",
    "end": "700959"
  },
  {
    "text": "we call it observatorium because why not it's kind of like you know imagine you have like observability centralized",
    "start": "700959",
    "end": "706880"
  },
  {
    "text": "cluster and it's very simple setup at the end maybe you know it's a comp the most complex",
    "start": "706880",
    "end": "712560"
  },
  {
    "text": "deployment but it's still kind of simple you only have three micro services query receiver and ruler from channels project",
    "start": "712560",
    "end": "718880"
  },
  {
    "text": "all of them are one binary with like different flags and so you run that as your back end and as your ui for",
    "start": "718880",
    "end": "725519"
  },
  {
    "text": "querying as well then alerting now you so we we have metrics propagated",
    "start": "725519",
    "end": "730800"
  },
  {
    "text": "into to our observatory that's great but we want more let's grab",
    "start": "730800",
    "end": "736160"
  },
  {
    "text": "oh i kind of missing the the line but essentially graffana agent is then tailing the logs from the file from this",
    "start": "736160",
    "end": "742720"
  },
  {
    "text": "ping server and then sending again to graph analogy which is another back end but for logs",
    "start": "742720",
    "end": "749040"
  },
  {
    "text": "they call it prometeuse but for logs essentially and we store logs there again in our centralized cluster imagine",
    "start": "749040",
    "end": "755680"
  },
  {
    "text": "and then we do similar with tracing and we use uh kind of push api from otlp so",
    "start": "755680",
    "end": "761519"
  },
  {
    "text": "open telemetry protocol and that pushes to grafana agent and then agent is able to push that using some jager format to",
    "start": "761519",
    "end": "768480"
  },
  {
    "text": "jagger which is right now the symbols jager in memory uh storage",
    "start": "768480",
    "end": "773760"
  },
  {
    "text": "and again jager allows us to store traces and query them and and and you know all of those free systems has some",
    "start": "773760",
    "end": "780480"
  },
  {
    "text": "ui to use but we we want to make it even more nicer so we",
    "start": "780480",
    "end": "786079"
  },
  {
    "text": "want to add continuous profiling right so what it does is that we install some agent on the customer side uh and this",
    "start": "786079",
    "end": "792560"
  },
  {
    "text": "is parker developed by polar signals it's open source as well all of this is open source and it scrapes a special p",
    "start": "792560",
    "end": "799279"
  },
  {
    "text": "prof endpoint so instrumentation for profile golang has it java has it but there are also the other ways how",
    "start": "799279",
    "end": "805360"
  },
  {
    "text": "you can grab those continuous profiles so with this we have really really nice",
    "start": "805360",
    "end": "812079"
  },
  {
    "text": "overview of what's happening we have all the magic observability signals metrics logs tracing and continuous profiling",
    "start": "812079",
    "end": "818639"
  },
  {
    "text": "but as you can imagine this gets a little bit complex to use not only you know operate and hopefully",
    "start": "818639",
    "end": "825360"
  },
  {
    "text": "you know i mean industry is moving to making it easy to operate and scale and use but what about usage what about user",
    "start": "825360",
    "end": "831839"
  },
  {
    "text": "imagine i have to go to thanos ui rafana ui jugger ui and then parka ui it's just",
    "start": "831839",
    "end": "838240"
  },
  {
    "text": "kind of like scary and you have to learn three different kind of search for different search engines and",
    "start": "838240",
    "end": "845199"
  },
  {
    "text": "and apis it's kind of crazy so i was thinking it's actually not that",
    "start": "845199",
    "end": "851199"
  },
  {
    "text": "hard to implement a microservice that will understand those apis for you",
    "start": "851199",
    "end": "856560"
  },
  {
    "text": "and will explode it in a very simple correlation mechanism so we wrote you",
    "start": "856560",
    "end": "861920"
  },
  {
    "text": "know a very complex collateral ai that will essentially correlate um",
    "start": "861920",
    "end": "867760"
  },
  {
    "text": "and hopefully will help us in our journey and i'm joking of course i i wrote that two days ago it's very simple",
    "start": "867760",
    "end": "874079"
  },
  {
    "text": "service and it's very yellow but the point of this demo is to make sure is to",
    "start": "874079",
    "end": "879600"
  },
  {
    "text": "show you how easy is to implement with 100 line of codes like amazingly useful",
    "start": "879600",
    "end": "885279"
  },
  {
    "text": "correlation mechanism that ideally we can bring up to all those uis someday maybe if we embed it in deep browser so",
    "start": "885279",
    "end": "892000"
  },
  {
    "text": "maybe it's easy to have maybe you know at some point we can work with those projects like thanos loki and jagger and",
    "start": "892000",
    "end": "898079"
  },
  {
    "text": "any other to really embed this this kind of service in in uh in our browser so we",
    "start": "898079",
    "end": "903519"
  },
  {
    "text": "can kind of show you way around okay but enough talking let's see if this will work",
    "start": "903519",
    "end": "910320"
  },
  {
    "text": "so the situation is following right we have some let me quickly rearrange",
    "start": "910320",
    "end": "916240"
  },
  {
    "text": "things so we start with thanos ui and thanos allergic ui so imagine we have",
    "start": "916240",
    "end": "921680"
  },
  {
    "text": "our finger ping service alert we are happy nice we can you know go to conference",
    "start": "921680",
    "end": "928880"
  },
  {
    "text": "and just enjoy our time unfortunately we are on call and you know imagine you get paged and",
    "start": "928880",
    "end": "936480"
  },
  {
    "text": "you get paid on your phone you check and there is a link to maybe thanos ui that contains an alert and we can see",
    "start": "936480",
    "end": "944079"
  },
  {
    "text": "there are too many errors well this is what i can i can read from it right and there's some complex query to make that",
    "start": "944079",
    "end": "950079"
  },
  {
    "text": "to to express that but what i do next um hopefully there is",
    "start": "950079",
    "end": "955360"
  },
  {
    "text": "some run book there is some links that maybe to dashboard or something but what if you don't have those what if",
    "start": "955360",
    "end": "961920"
  },
  {
    "text": "you are in the middle of the night suddenly and you really want to fix it very very quickly so maybe you go to",
    "start": "961920",
    "end": "968480"
  },
  {
    "text": "thanos ui and what do you do what do i query maybe i can just search something",
    "start": "968480",
    "end": "974240"
  },
  {
    "text": "okay there are some requests http sure but",
    "start": "974240",
    "end": "979839"
  },
  {
    "text": "there might be more services that i'm observing how do i get to the information i really want right i have",
    "start": "979839",
    "end": "985519"
  },
  {
    "text": "to understand prompt you well i need to really understand what is happening so maybe there are things we can improve here",
    "start": "985519",
    "end": "990959"
  },
  {
    "text": "now let's go to our logging signal and i open you know just main graffana you know kind of ui",
    "start": "990959",
    "end": "997360"
  },
  {
    "text": "and if you are familiar with this you can you know you can do a lot here but you have to think and like in the moment on",
    "start": "997360",
    "end": "1004560"
  },
  {
    "text": "the you know uncle kind of page and it's incident situation it's really hard to kind of find you know find the correct",
    "start": "1004560",
    "end": "1010959"
  },
  {
    "text": "data source and really try to you know maybe i don't know find something right it's kind of hard",
    "start": "1010959",
    "end": "1016880"
  },
  {
    "text": "and the same with tracing you go to tracing and say oh i want to what should i what should i do what pack i should",
    "start": "1016880",
    "end": "1023199"
  },
  {
    "text": "use like how do i find my not only service that is instrumented",
    "start": "1023199",
    "end": "1028400"
  },
  {
    "text": "with those traces but also you know the exact situation exact error that is happening right",
    "start": "1028400",
    "end": "1035280"
  },
  {
    "text": "and again because we have four things there is also parka and you know how to use those this you know kind of query",
    "start": "1035280",
    "end": "1042240"
  },
  {
    "text": "filtering mechanism of parka so at the end it's kind of crazy so this is where we thought it's kind of simple to write",
    "start": "1042240",
    "end": "1048799"
  },
  {
    "text": "automation that will understand those things and you know again take it as an example it's it's just you know i'm not",
    "start": "1048799",
    "end": "1055440"
  },
  {
    "text": "front-end developer so i i didn't build a nice ui for that but think about it what i have",
    "start": "1055440",
    "end": "1061600"
  },
  {
    "text": "is like a simple ui or like simple input so i copy the alert name big service too",
    "start": "1061600",
    "end": "1066799"
  },
  {
    "text": "many errors i just put into that so being serviced too many errors i want to",
    "start": "1066799",
    "end": "1073039"
  },
  {
    "text": "use exemplars and i will tell you what's that later on and i click correlate and voila it",
    "start": "1073039",
    "end": "1079919"
  },
  {
    "text": "actually gave me a lot of links useful links i can use so let's go through this page and you",
    "start": "1079919",
    "end": "1086480"
  },
  {
    "text": "know imagine it is like embedded in your browser so it's easy to use but correlation this ai",
    "start": "1086480",
    "end": "1092559"
  },
  {
    "text": "found that there is an alert it's firing for a certain service with certain instances with certain job",
    "start": "1092559",
    "end": "1099760"
  },
  {
    "text": "and what's more amazing is that it found out that this alert is actually",
    "start": "1099760",
    "end": "1106480"
  },
  {
    "text": "using http request total counter that is also instrumented with exemplars and",
    "start": "1106480",
    "end": "1112080"
  },
  {
    "text": "exemplars is essentially a way to provide an example request id",
    "start": "1112080",
    "end": "1118559"
  },
  {
    "text": "that contributed to those errors so we know that there is a certain request",
    "start": "1118559",
    "end": "1124080"
  },
  {
    "text": "that goes among many that cause this alert to fire and we put that into exam exemplar right",
    "start": "1124080",
    "end": "1130480"
  },
  {
    "text": "and might be thousands but we we won't we only want one example so you can see that this my my service",
    "start": "1130480",
    "end": "1136480"
  },
  {
    "text": "queried actually tunnels and makes like two different api calls and gathered",
    "start": "1136480",
    "end": "1141600"
  },
  {
    "text": "that there is a request id that is correlated to those errors that cause alerts to fire",
    "start": "1141600",
    "end": "1147600"
  },
  {
    "text": "so it constructed useful you know links for us so for example we can go",
    "start": "1147600",
    "end": "1153280"
  },
  {
    "text": "and check uh you know exactly the the query behind the alert here so we",
    "start": "1153280",
    "end": "1159679"
  },
  {
    "text": "can see confirm yeah error rate is you know above 65 percent right and and you",
    "start": "1159679",
    "end": "1166960"
  },
  {
    "text": "know even like what are the actual error rate uh requests per second it's slower than then it's less than one per second",
    "start": "1166960",
    "end": "1174480"
  },
  {
    "text": "uh but you know in this actual case it's not very useful so maybe let's try a different correlation maybe you know as",
    "start": "1174480",
    "end": "1181679"
  },
  {
    "text": "um i think it was amazing talk on prometheus day from bjorn around anomaly detection and he mentioned that",
    "start": "1181679",
    "end": "1188160"
  },
  {
    "text": "you know it's it's it's useful to have those theories that you want to check but only a few of",
    "start": "1188160",
    "end": "1194640"
  },
  {
    "text": "those so we look we click from theories uh that what can go wrong what could go wrong and you know where is the best",
    "start": "1194640",
    "end": "1201919"
  },
  {
    "text": "place to look for the reason why things are failing so let's go to the",
    "start": "1201919",
    "end": "1207280"
  },
  {
    "text": "uh logging maybe logging um you know it's useful you can see i",
    "start": "1207280",
    "end": "1212320"
  },
  {
    "text": "don't need i didn't need to craft this query i have and you know you don't need to learn to look ul i have",
    "start": "1212320",
    "end": "1218640"
  },
  {
    "text": "already kind of automation corrected me this query and found that for this request we have only two log lines",
    "start": "1218640",
    "end": "1224640"
  },
  {
    "text": "unfortunately for starting the ping and finishing the ping is there anything useful can get from",
    "start": "1224640",
    "end": "1231120"
  },
  {
    "text": "that unfortunately there is not even any is there error yeah i don't think it's",
    "start": "1231120",
    "end": "1236799"
  },
  {
    "text": "there well we are unlucky here at this time logging was not very helpful uh let's try tracing",
    "start": "1236799",
    "end": "1243440"
  },
  {
    "text": "so um with tracing let's go that correlation go where you know kind of directed us to",
    "start": "1243440",
    "end": "1249760"
  },
  {
    "text": "tracing you can see that immediately they gave us you know uh this correlator gave us",
    "start": "1249760",
    "end": "1255679"
  },
  {
    "text": "the trace view right which uh which exactly is a spans for this request that",
    "start": "1255679",
    "end": "1261520"
  },
  {
    "text": "failed and contributed these alerts it's very very useful information you can see it's an error",
    "start": "1261520",
    "end": "1266559"
  },
  {
    "text": "and you know the whole request took some time but there is this evaluate ping function which took one hand over 100",
    "start": "1266559",
    "end": "1273520"
  },
  {
    "text": "one second and we can see it turned error because decided to not return",
    "start": "1273520",
    "end": "1278559"
  },
  {
    "text": "success okay that was not helpful but at least we know a function so we already knew something right",
    "start": "1278559",
    "end": "1285679"
  },
  {
    "text": "so we are unlucky this time but who knows maybe on next dollar that that information would be helpful so what we",
    "start": "1285679",
    "end": "1292080"
  },
  {
    "text": "can do let's go to the last link uh which is um parker and let's check if continuous",
    "start": "1292080",
    "end": "1298880"
  },
  {
    "text": "profiling will tell us anything and you can see you know our caller rate",
    "start": "1298880",
    "end": "1304480"
  },
  {
    "text": "calculator crafted a a query that checks",
    "start": "1304480",
    "end": "1309520"
  },
  {
    "text": "the exact job and profiling you know in the exact moment when this",
    "start": "1309520",
    "end": "1315280"
  },
  {
    "text": "you know kind of example exemplar was happening and already told us a lot so we're actually",
    "start": "1315280",
    "end": "1321360"
  },
  {
    "text": "spending a lot of cpu time let's see so apparently we spent",
    "start": "1321360",
    "end": "1327679"
  },
  {
    "text": "five minutes in total across all the pings on this nasty back function right",
    "start": "1327919",
    "end": "1334080"
  },
  {
    "text": "and if you go to my code and search for this actually let me copy",
    "start": "1334080",
    "end": "1339600"
  },
  {
    "text": "what happened here so yeah this is my pin code",
    "start": "1339600",
    "end": "1345120"
  },
  {
    "text": "let's search oh yeah i have this nasty pink that just does you know nothing and burns cpu",
    "start": "1345120",
    "end": "1351280"
  },
  {
    "text": "exactly this so yeah i found error just delete it and now it should work right so this is kind",
    "start": "1351280",
    "end": "1357679"
  },
  {
    "text": "of the story we wanted to show should we show experimental feature if this is actually working so let's try so we have",
    "start": "1357679",
    "end": "1364559"
  },
  {
    "text": "another link here and this is like uh so what you have seen is totally doable right now with like master master or",
    "start": "1364559",
    "end": "1371840"
  },
  {
    "text": "main of all those projects like latest uh releases but parker is going crazy",
    "start": "1371840",
    "end": "1377440"
  },
  {
    "text": "with features and uh one thing which is amazing is that we can use exemplar so trace id",
    "start": "1377440",
    "end": "1383039"
  },
  {
    "text": "so usually we have profiling that is across all the things that were happening in the binary",
    "start": "1383039",
    "end": "1388799"
  },
  {
    "text": "but trace id or like we can label uh you can filter out things by certain labels",
    "start": "1388799",
    "end": "1394880"
  },
  {
    "text": "and we could filter out essentially only cpu time spent for this request and",
    "start": "1394880",
    "end": "1401280"
  },
  {
    "text": "it's experimental and it was not working before whoa it works all right so",
    "start": "1401280",
    "end": "1406799"
  },
  {
    "text": "yes oh my god yeah and you can see that correlator crafted a query which",
    "start": "1406799",
    "end": "1413840"
  },
  {
    "text": "directly asked for request id and you can see that just this request took exactly one second of cpu time this is",
    "start": "1413840",
    "end": "1420559"
  },
  {
    "text": "incredible because if you have a large binary that has do lots of things and maybe it does a lot of other cpu time",
    "start": "1420559",
    "end": "1427120"
  },
  {
    "text": "work you wouldn't see the exact problem performance problem in this request so",
    "start": "1427120",
    "end": "1432480"
  },
  {
    "text": "this is yes amazing congratulations to polar signal for um you know really",
    "start": "1432480",
    "end": "1437919"
  },
  {
    "text": "yeah hacking profiles it's amazing all right so um that's for the demo side i want to",
    "start": "1437919",
    "end": "1444720"
  },
  {
    "text": "show you one more important thing so how we even constructed this exemplar",
    "start": "1444720",
    "end": "1450080"
  },
  {
    "text": "and those kind of few um all those observability signals together the key of of how we were able",
    "start": "1450080",
    "end": "1456960"
  },
  {
    "text": "to correlate those stuff is in this function it's like a middleware so it's not like very visible in the code",
    "start": "1456960",
    "end": "1463360"
  },
  {
    "text": "because it's hidden in this helper that wraps your http handler for ping and in",
    "start": "1463360",
    "end": "1468799"
  },
  {
    "text": "the go but it will look very similar in other languages so as you can see we create a registry from it use registry",
    "start": "1468799",
    "end": "1475120"
  },
  {
    "text": "from our official client golang library we create a metric for http request",
    "start": "1475120",
    "end": "1480960"
  },
  {
    "text": "total does this work yeah then we uh",
    "start": "1480960",
    "end": "1486799"
  },
  {
    "text": "grab exemplar if there is any so well grab trace id really if from tracing",
    "start": "1486799",
    "end": "1492559"
  },
  {
    "text": "library that i wrote that wraps open telemetry library by the way um and i wrote myself because i wrote another one",
    "start": "1492559",
    "end": "1499039"
  },
  {
    "text": "because it's kind of like open telemetry library was too complex to kind of use for normal humans i wrote like",
    "start": "1499039",
    "end": "1505360"
  },
  {
    "text": "opinionated smaller packages but anyway so if it's sampled if it has trace id it will return trace id that is then",
    "start": "1505360",
    "end": "1511760"
  },
  {
    "text": "consumed into official instrumentation so this",
    "start": "1511760",
    "end": "1517120"
  },
  {
    "text": "trace id is connected to our http request total metric which is kind of",
    "start": "1517120",
    "end": "1522240"
  },
  {
    "text": "like logically and symmetrically making sense right and of course we have to wrap with some tracing library to have",
    "start": "1522240",
    "end": "1528320"
  },
  {
    "text": "this trace id and all of it right so i will not explain everything but you can grab my slides and you can reproduce",
    "start": "1528320",
    "end": "1534159"
  },
  {
    "text": "everything it's like in our bw correlator repository you can run a unit",
    "start": "1534159",
    "end": "1539520"
  },
  {
    "text": "test and it will spin all those things and to achieve this i use this uh one",
    "start": "1539520",
    "end": "1545679"
  },
  {
    "text": "library you can see here efficient go end-to-end and uh if you want to learn more join",
    "start": "1545679",
    "end": "1552240"
  },
  {
    "text": "our talk today on you know 4 p.m 50 50 and there are jessica mitchell here who",
    "start": "1552240",
    "end": "1557840"
  },
  {
    "text": "will be discussing you know just this end-to-end framework because it's running containers on your",
    "start": "1557840",
    "end": "1562960"
  },
  {
    "text": "local laptop so you can totally test on production many many things and we use that to test from thanos on every",
    "start": "1562960",
    "end": "1570000"
  },
  {
    "text": "every pr so we spin up the whole tunnels deployment complex systems and ultra fast so i recommend checking that",
    "start": "1570000",
    "end": "1577440"
  },
  {
    "text": "and we also want to mention that we do mentorship so if you have any new joiners into you know open source we are",
    "start": "1577440",
    "end": "1583679"
  },
  {
    "text": "um we are there to help you and you can also watch a video from lucas and to",
    "start": "1583679",
    "end": "1589120"
  },
  {
    "text": "learn more and with that i would like to thank you and yeah",
    "start": "1589120",
    "end": "1595960"
  },
  {
    "text": "[Applause]",
    "start": "1597040",
    "end": "1602480"
  },
  {
    "text": "i guess before the questions one disclaimer like you've seen that we added examples to the alerts which is a",
    "start": "1602480",
    "end": "1609760"
  },
  {
    "text": "feature that we are we're going to add in client call link pretty soon next version same goes for parker as well the",
    "start": "1609760",
    "end": "1616240"
  },
  {
    "text": "trace id queries will be included in the next release so this is very bleeding edge demo and we have we",
    "start": "1616240",
    "end": "1622640"
  },
  {
    "text": "have time for questions actually i think five minutes or more so any questions that you want to shout out i guess",
    "start": "1622640",
    "end": "1627840"
  },
  {
    "text": "because or maybe you want to help yeah thank you thank you",
    "start": "1627840",
    "end": "1634640"
  },
  {
    "text": "let's just wait here",
    "start": "1636400",
    "end": "1640039"
  },
  {
    "text": "hello okay yeah so you had to well you you built this on on what appears to be",
    "start": "1642960",
    "end": "1649120"
  },
  {
    "text": "not very deep tweaks to the entire ecosystem right changing a few things on each client and maybe",
    "start": "1649120",
    "end": "1654799"
  },
  {
    "text": "how far are we from this being the default every of every one of these products out of the box having been",
    "start": "1654799",
    "end": "1661520"
  },
  {
    "text": "configured so that you could just plug in this correlator and is this an initiative something that is that is",
    "start": "1661520",
    "end": "1666880"
  },
  {
    "text": "happening in in is it a conversation that's happening there are definitely conversations but",
    "start": "1666880",
    "end": "1672480"
  },
  {
    "text": "it's really like organically growing i think we are there because we already you know build stable uh metric packages",
    "start": "1672480",
    "end": "1679039"
  },
  {
    "text": "that are metric libraries for different languages with exemplars now we have to",
    "start": "1679039",
    "end": "1684960"
  },
  {
    "text": "find out you know how to work with other like you know tracing libraries and logging libraries to to create those",
    "start": "1684960",
    "end": "1692000"
  },
  {
    "text": "let's say auto instrumentations for maybe your framework of preference and",
    "start": "1692000",
    "end": "1698000"
  },
  {
    "text": "you know i think you can discuss about even even you know more magic how to instrumentation in the space yeah so the",
    "start": "1698000",
    "end": "1704559"
  },
  {
    "text": "most important thing i guess here is the labels right all these tools are based on the label models that's why we how we",
    "start": "1704559",
    "end": "1710799"
  },
  {
    "text": "actually correlate those there are a couple of initiatives to just like ease up the correlation like open telemetry",
    "start": "1710799",
    "end": "1716960"
  },
  {
    "text": "which but you need to do that in the instrumentation size right so it's kind of like tightly coupled we want to do",
    "start": "1716960",
    "end": "1723520"
  },
  {
    "text": "this in a more loosely coupled way which by just using labels so uh bartek and his team is like",
    "start": "1723520",
    "end": "1731200"
  },
  {
    "text": "working on a project called observatorium which is also an open source project one aspect of that we are trying to",
    "start": "1731200",
    "end": "1737679"
  },
  {
    "text": "correlate in that project as well like without any instrumentation like one package you install and you have all",
    "start": "1737679",
    "end": "1743679"
  },
  {
    "text": "this you know uh right side thing uh you know by by just one click of the button",
    "start": "1743679",
    "end": "1749120"
  },
  {
    "text": "that's the kind of idea so we have this part done and and then you know we have to correlate all those kind of um",
    "start": "1749120",
    "end": "1755760"
  },
  {
    "text": "efforts within different libraries as well to have instrumentation part but i i think what you i wanted you to say i",
    "start": "1755760",
    "end": "1760880"
  },
  {
    "text": "will i will come to that for this still with the people of labels you need a little bit instrumentation right you",
    "start": "1760880",
    "end": "1766960"
  },
  {
    "text": "need to grab that tracing idea and put that as in label what we are also working on with the parka there is an",
    "start": "1766960",
    "end": "1772799"
  },
  {
    "text": "agent which is an ebpf based agent and collect those metrics by just using ebpf",
    "start": "1772799",
    "end": "1778159"
  },
  {
    "text": "which is zero instrumentation what we plan to add on top of that some type of",
    "start": "1778159",
    "end": "1783760"
  },
  {
    "text": "like uh labeler you may said say uh which",
    "start": "1783760",
    "end": "1788799"
  },
  {
    "text": "will just discover the metadata and just attach those to those auto instrumented label labels so it will be some somewhat",
    "start": "1788799",
    "end": "1796080"
  },
  {
    "text": "auto magical at least that's what we've planned even without labels i think it can work but the idea is that there's a",
    "start": "1796080",
    "end": "1801760"
  },
  {
    "text": "bpf you know kind of um observability direction going on as well to kind of",
    "start": "1801760",
    "end": "1807120"
  },
  {
    "text": "have all logging metrics and tracing and profiling just by ebpf so hopefully we'll see more improvements on the side",
    "start": "1807120",
    "end": "1814240"
  },
  {
    "text": "but really there is nothing better than instrumenting your own application owning the code i trust you i mean trust",
    "start": "1814240",
    "end": "1820320"
  },
  {
    "text": "me because uh we we we have amazing observability because we yeah we we kind of kind of added those",
    "start": "1820320",
    "end": "1826480"
  },
  {
    "text": "statements and this is like called open box observability there's nothing better than that but of course if you don't",
    "start": "1826480",
    "end": "1832080"
  },
  {
    "text": "have this power you have to we have to work on on those auto instrumentation tools yeah",
    "start": "1832080",
    "end": "1837120"
  },
  {
    "text": "thank you okay maybe last question",
    "start": "1837120",
    "end": "1841760"
  },
  {
    "text": "oh yeah very close by so that's good hello uh",
    "start": "1842159",
    "end": "1847360"
  },
  {
    "text": "great talk thanks uh i was at the",
    "start": "1847360",
    "end": "1852960"
  },
  {
    "text": "open telemetry community uh meeting and they were talking about",
    "start": "1852960",
    "end": "1859760"
  },
  {
    "text": "adding profiling into one of the signals of open telemetry uh",
    "start": "1859760",
    "end": "1865360"
  },
  {
    "text": "has anyone get in touch with you just to discuss this because i mean that would be awesome because then we can have the",
    "start": "1865360",
    "end": "1871760"
  },
  {
    "text": "trace id and span id into everything and then we have logs metrics and profiling all together",
    "start": "1871760",
    "end": "1878960"
  },
  {
    "text": "yeah it's kind of the holy grail everyone everybody wants to go there right but those discussions are very",
    "start": "1878960",
    "end": "1885200"
  },
  {
    "text": "early stage uh obviously we probably will be part of that discussion we are building this",
    "start": "1885200",
    "end": "1891440"
  },
  {
    "text": "open source tool so uh there is tag observability there's open telemetry subgroups so yeah uh just",
    "start": "1891440",
    "end": "1898960"
  },
  {
    "text": "be part of those discussions yourself as well if you want to see any feature that you want to add be edit but yeah we are",
    "start": "1898960",
    "end": "1905360"
  },
  {
    "text": "just like scratching the surface surface of this profiling area awesome thank you",
    "start": "1905360",
    "end": "1911519"
  },
  {
    "text": "it's worth to mention that still even with open telemetry having all the signals in the world you have to run",
    "start": "1911519",
    "end": "1917600"
  },
  {
    "text": "multiple agents because a more scalable solution like if not",
    "start": "1917600",
    "end": "1922640"
  },
  {
    "text": "normal production you won't wouldn't survive one binary having all the signals you have to have different maybe",
    "start": "1922640",
    "end": "1929840"
  },
  {
    "text": "open telemetry for example uh just different instances of open telemetry but still you have to scale those across",
    "start": "1929840",
    "end": "1936240"
  },
  {
    "text": "metrics and traces and profiles and probably logging at some point but um",
    "start": "1936240",
    "end": "1941679"
  },
  {
    "text": "those are like different characteristic of performance of collecting those so you have to manage that in practice you",
    "start": "1941679",
    "end": "1947600"
  },
  {
    "text": "have to manage that in separation so maybe it's one binary is helping i am open telemetry is doing an amazing job",
    "start": "1947600",
    "end": "1953279"
  },
  {
    "text": "on on kind of getting apis to to work together so that's amazing but the agent",
    "start": "1953279",
    "end": "1958480"
  },
  {
    "text": "side you have to still probably running the separate agents so that's that's kind of the the unfortunate reality yeah",
    "start": "1958480",
    "end": "1965919"
  },
  {
    "text": "thank you okay so last question maybe",
    "start": "1965919",
    "end": "1972720"
  },
  {
    "text": "anyone i will check questions on virtual",
    "start": "1973600",
    "end": "1978720"
  },
  {
    "text": "side i have that opened oh we have question",
    "start": "1978720",
    "end": "1985679"
  },
  {
    "text": "no it was around like a kind of audio right so thank you very much for joining",
    "start": "1985679",
    "end": "1991600"
  },
  {
    "text": "thanks",
    "start": "1991600",
    "end": "1994600"
  }
]
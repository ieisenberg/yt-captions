[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "everyone we're gonna get started so my name is Greg Jarmon I lead our",
    "start": "840",
    "end": "6089"
  },
  {
    "text": "production infrastructure group at Palantir technologies and I'm with Vlad who's the technical lead on our cloud",
    "start": "6089",
    "end": "11580"
  },
  {
    "text": "infrastructure team and today we're gonna spend some time talking about what happens when you run large kubernetes",
    "start": "11580",
    "end": "17970"
  },
  {
    "text": "clusters and you destroy every node every 48 hours we'll talk about why",
    "start": "17970",
    "end": "23130"
  },
  {
    "text": "Palantir chose to take an ephemeral approach to our infrastructure and how we run kubernetes on it some of the",
    "start": "23130",
    "end": "28710"
  },
  {
    "text": "technical challenges that come come along with that some of the solutions for solving those challenges and some of",
    "start": "28710",
    "end": "35880"
  },
  {
    "text": "the benefits that we've realized in taking this approach before I do I want",
    "start": "35880",
    "end": "42629"
  },
  {
    "start": "40000",
    "end": "170000"
  },
  {
    "text": "to briefly introduce Palantir for those who aren't familiar Palantir is a software company we were founded fifteen",
    "start": "42629",
    "end": "49170"
  },
  {
    "text": "or so years ago and our mission has been to our purpose has been to improve the",
    "start": "49170",
    "end": "56730"
  },
  {
    "text": "way the world's most important institutions use data to make decisions a few examples of what I mean our",
    "start": "56730",
    "end": "63660"
  },
  {
    "text": "software is the foundation of cyber defense systems for large institutions in entire nation states around the world",
    "start": "63660",
    "end": "69240"
  },
  {
    "text": "our software is used in support of anti-terrorist missions in the West from",
    "start": "69240",
    "end": "75240"
  },
  {
    "text": "everything from intelligence operations to mission planning in the field Ferrari",
    "start": "75240",
    "end": "82380"
  },
  {
    "text": "uses our technology to make their Formula one cars faster and more efficient if you look very closely you",
    "start": "82380",
    "end": "89130"
  },
  {
    "text": "can see our logo on the bottom right fender which is pretty cool Palantir and Airbus founded Sky wise as",
    "start": "89130",
    "end": "98060"
  },
  {
    "text": "a platform to improve the way the airline industry uses data to make air",
    "start": "98060",
    "end": "105149"
  },
  {
    "text": "travel safer and more economical today sky wise collects high-resolution telemetry from millions of sensors",
    "start": "105149",
    "end": "111860"
  },
  {
    "text": "across the aircraft flying around the world and enable Airbus engineers and",
    "start": "111860",
    "end": "117360"
  },
  {
    "text": "aircraft operators to use this data to root cause faults in flight and improve",
    "start": "117360",
    "end": "123090"
  },
  {
    "text": "the way airlines operate airline or the aircraft and the way they're manufactured",
    "start": "123090",
    "end": "129530"
  },
  {
    "text": "Palantir and merck pharmaceutical join our formative joint partnership call",
    "start": "130020",
    "end": "135490"
  },
  {
    "text": "it's entropy last year which is focused on enabling collaboration amongst medical researchers around the world",
    "start": "135490",
    "end": "140710"
  },
  {
    "text": "towards improving the cancer treatments that they're working on so how do we do",
    "start": "140710",
    "end": "148270"
  },
  {
    "text": "all this so pound here software is used by our customers to integrate data and",
    "start": "148270",
    "end": "153880"
  },
  {
    "text": "analyze data sets from around across their enterprise and is used by operators and decision-makers to make",
    "start": "153880",
    "end": "160209"
  },
  {
    "text": "better decisions using the data they have and we do this by offering our customers two data platforms Palantir",
    "start": "160209",
    "end": "167110"
  },
  {
    "text": "Gotham and Palantir foundry so I want to talk a little bit about the",
    "start": "167110",
    "end": "172750"
  },
  {
    "start": "170000",
    "end": "213000"
  },
  {
    "text": "infrastructure in which we run those platforms on behalf of our customers so",
    "start": "172750",
    "end": "178840"
  },
  {
    "text": "starting in 2013 we started offering our platforms as a platform as a service model to our customers built on top of",
    "start": "178840",
    "end": "185739"
  },
  {
    "text": "our first generation cloud architecture and AWS the world has changed a lot since then so two years after that or so",
    "start": "185739",
    "end": "192610"
  },
  {
    "text": "Caretti x' 1.0 came out in 2015 and as time went on the needs of our data",
    "start": "192610",
    "end": "198970"
  },
  {
    "text": "platform and the technology landscape continued to evolve and so in late 2016",
    "start": "198970",
    "end": "203980"
  },
  {
    "text": "we started thinking about what would it mean to rebuild our cloud architecture for the future and what would we change",
    "start": "203980",
    "end": "210700"
  },
  {
    "text": "our first generation architecture as we did that and there was a number of things that were influencing our",
    "start": "210700",
    "end": "217000"
  },
  {
    "start": "213000",
    "end": "297000"
  },
  {
    "text": "decisions in how we thought about the problem at the time so the first of those was we started running into scaling limitations and hurdles in our",
    "start": "217000",
    "end": "224140"
  },
  {
    "text": "in place patching infrastructure that was largely built on top of puppet and we used puppet to both patched the",
    "start": "224140",
    "end": "230920"
  },
  {
    "text": "operating system but also to roll out configuration changes for things like firewalls and so forth and as our fleet continued to scale our",
    "start": "230920",
    "end": "238000"
  },
  {
    "text": "ability to make these changes in a timely manner became harder and harder in 2015 there was as in a hypervisor bug",
    "start": "238000",
    "end": "245530"
  },
  {
    "text": "or two that led Amazon to need to reboot almost every ec2 instance in the entire",
    "start": "245530",
    "end": "250690"
  },
  {
    "text": "world that was running hvm virtualization and when this was announced our infrastructure team panicked as at the time we had a large",
    "start": "250690",
    "end": "259539"
  },
  {
    "text": "number of instances that had been running for longer than a year we had large volumes of the ephemeral volumes and to be honest",
    "start": "259539",
    "end": "266840"
  },
  {
    "text": "we weren't sure what would happen when those instances got rebooted we weren't sure if when they came back up whether they would still be there or whether the",
    "start": "266840",
    "end": "273500"
  },
  {
    "text": "services that we were running on those hosts would be able to come back online and at the time Netflix and some others",
    "start": "273500",
    "end": "279560"
  },
  {
    "text": "had been talking about chaos engineering and the benefits that they see from that for a number of years Netflix talking",
    "start": "279560",
    "end": "286099"
  },
  {
    "text": "about how they use chaos monkey and so forth and so as we started thinking through what we wanted our",
    "start": "286099",
    "end": "291259"
  },
  {
    "text": "infrastructure looked like in the future a lot of this led us to asking what we thought at the time was a relatively",
    "start": "291259",
    "end": "297530"
  },
  {
    "start": "297000",
    "end": "361000"
  },
  {
    "text": "straightforward question well what if we just destroyed and rebuilt every host in every environment every 48 hours if we",
    "start": "297530",
    "end": "304789"
  },
  {
    "text": "did this it allow us to treat our infrastructure as immutable and ephemeral which means we wouldn't need an in-place patching story and a lot of",
    "start": "304789",
    "end": "312050"
  },
  {
    "text": "the challenges that we had in the fears we had about rebooting instances would be solved because we'd be doing this constantly so these conversations were",
    "start": "312050",
    "end": "320300"
  },
  {
    "text": "happening at the end of 2016 kubernetes had just hit version 1.5 pet",
    "start": "320300",
    "end": "326690"
  },
  {
    "text": "sets now stateful sets had just entered the platform and it began to be believable that we could run all of our",
    "start": "326690",
    "end": "333830"
  },
  {
    "text": "software at some point time on top of kubernetes so in January of 2017 we",
    "start": "333830",
    "end": "339770"
  },
  {
    "text": "started it to a team and an effort internally we called Rubik after the Rubik's cubes our CEO used to solve and",
    "start": "339770",
    "end": "347690"
  },
  {
    "text": "leave on people's desks as a nod to kubernetes and Rubik would be our effort to rebuild our infrastructure around",
    "start": "347690",
    "end": "353479"
  },
  {
    "text": "kubernetes and in doing so treat our infrastructure as ephemeral and destroy",
    "start": "353479",
    "end": "358759"
  },
  {
    "text": "the hosts every 48 hours so today Rubik is in production at the majority of our",
    "start": "358759",
    "end": "364909"
  },
  {
    "start": "361000",
    "end": "430000"
  },
  {
    "text": "customer environments around the world we're on many many kubernetes clusters as part of this we have environments on",
    "start": "364909",
    "end": "371569"
  },
  {
    "text": "a nine AWS regions I think soon to be ten and four different continents across our fleet we have more than 2,500 nodes",
    "start": "371569",
    "end": "379310"
  },
  {
    "text": "at any given point in time oftentimes it's above 3000 as the environments scale up and down throughout the day",
    "start": "379310",
    "end": "384940"
  },
  {
    "text": "the clusters vary in size we have clusters from tens of nodes to hundreds",
    "start": "384940",
    "end": "391340"
  },
  {
    "text": "of nodes our largest oftentimes reaching 12 or 1300 nodes at the peak usage and because we're destroying every host",
    "start": "391340",
    "end": "398330"
  },
  {
    "text": "every 48 hours it means that on a 24-hour period we tend to touch about",
    "start": "398330",
    "end": "403550"
  },
  {
    "text": "10,000 ec2 instances between the standard destroying and rebuilding plus the auto scaling the primary workloads",
    "start": "403550",
    "end": "410180"
  },
  {
    "text": "that we run on top of kubernetes today are our distributed computes a lot of Apache spark jobs and because these",
    "start": "410180",
    "end": "417189"
  },
  {
    "text": "these pods need to be relatively short-lived we have a very high pod churn across our cluster so it's a",
    "start": "417189",
    "end": "423439"
  },
  {
    "text": "common that we'll see more than a million pods being run in the course of a 24-hour period",
    "start": "423439",
    "end": "428979"
  },
  {
    "text": "so I mention that we destroy these hosts all the time I'll quickly touch on a framework we use for doing so so we",
    "start": "428979",
    "end": "435740"
  },
  {
    "text": "built a controller that's responsible for destroying and rebuilding hosts in every environment it follows a",
    "start": "435740",
    "end": "441680"
  },
  {
    "text": "relatively straightforward three-step process first step is to evaluate all of the ec2",
    "start": "441680",
    "end": "447649"
  },
  {
    "text": "instances that are running that are eligible for termination we then take the eligible nodes and we",
    "start": "447649",
    "end": "452869"
  },
  {
    "text": "apply a set of constraints to those to make sure that we don't do things like take all three entity hosts out at once",
    "start": "452869",
    "end": "458119"
  },
  {
    "text": "that would be very bad we down select all of the hosts that are eligible to the hosts that we can safely terminate",
    "start": "458119",
    "end": "464749"
  },
  {
    "text": "and then we send them to an actuator which will be responsible for marking the notice on scheduled draining the",
    "start": "464749",
    "end": "470360"
  },
  {
    "text": "pods and so forth so we've been doing this for a year and a half or so there",
    "start": "470360",
    "end": "475849"
  },
  {
    "start": "472000",
    "end": "637000"
  },
  {
    "text": "have been a number of really great benefits that we've been able to see in running this in production on top of the expected benefits of that you know one",
    "start": "475849",
    "end": "482509"
  },
  {
    "text": "would expect from chaos testing as engineering and so forth the first of which was our ability to upgrade the",
    "start": "482509",
    "end": "488539"
  },
  {
    "text": "cluster and mitigate critical vulnerabilities or CDEs wood has been greatly improved and so I remember being",
    "start": "488539",
    "end": "495830"
  },
  {
    "text": "at cube Con in December last year in Seattle and a number of people were talking about how they struggled to",
    "start": "495830",
    "end": "501709"
  },
  {
    "text": "handle the number of CDs or Linux you know security vulnerabilities that came out how they handled upgrading",
    "start": "501709",
    "end": "507860"
  },
  {
    "text": "kubernetes as the hot fixes came out for those vulnerabilities and two months later they would have to handle the run",
    "start": "507860",
    "end": "513888"
  },
  {
    "text": "C thing whether they had known another not time or not and these conversations were the first thing that led me to",
    "start": "513889",
    "end": "520130"
  },
  {
    "text": "realize how valuable our system is for mitigating this because for us when the",
    "start": "520130",
    "end": "525350"
  },
  {
    "text": "when you know the hot fixes came out for the vulnerabilities it was simply a matter of us updating our ami and the same process",
    "start": "525350",
    "end": "532580"
  },
  {
    "text": "that's running constantly would roll out the mitigation for us and it was the",
    "start": "532580",
    "end": "537590"
  },
  {
    "text": "thing that we didn't really think all that much about it just happened it was just any other day the second big category benefits we saw",
    "start": "537590",
    "end": "544130"
  },
  {
    "text": "was as we started trying to do auto scaling we realized that a large set of",
    "start": "544130",
    "end": "549200"
  },
  {
    "text": "problems that one would usually has to think about when you get to doing auto scaling we had already solved because",
    "start": "549200",
    "end": "555680"
  },
  {
    "text": "those problems are the same types of problems that you need to solve when you start treating your infrastructure as a",
    "start": "555680",
    "end": "561080"
  },
  {
    "text": "femoral these are things like the hosts initialization time starts to really matter your ability to do identity you",
    "start": "561080",
    "end": "567740"
  },
  {
    "text": "know like joining a domain getting a certificate those kinds of things and your ability of handling networking connections gracefully as hosts come and",
    "start": "567740",
    "end": "574370"
  },
  {
    "text": "go so a lot of these challenges why it's gonna talk about here in a few seconds but for us what it meant was by the time",
    "start": "574370",
    "end": "579890"
  },
  {
    "text": "we got to auto scaling it was relatively straightforward path for us to get it working the third big category of",
    "start": "579890",
    "end": "586910"
  },
  {
    "text": "benefits we saw was around security and so for us our ability to mitigate advanced persistent threat or you know a",
    "start": "586910",
    "end": "593990"
  },
  {
    "text": "set of attacks that's usually where a malicious actor will use either social engineering or known vulnerability tool",
    "start": "593990",
    "end": "601670"
  },
  {
    "text": "and malware on your on a host in your network and then use that as a jump-off point to move laterally through your",
    "start": "601670",
    "end": "607490"
  },
  {
    "text": "environment our ability to mitigate these risks was greatly improved because now it is not only necessary for that",
    "start": "607490",
    "end": "614000"
  },
  {
    "text": "malicious actor to compromise a host once they must do this repeatedly because every host you know it gets",
    "start": "614000",
    "end": "619940"
  },
  {
    "text": "destroyed all the time and so malicious act will need to continuously compromise an environment and that behavior is",
    "start": "619940",
    "end": "626540"
  },
  {
    "text": "hopefully easier to detect by your like information security alerting and scanning and so forth so you know there",
    "start": "626540",
    "end": "635780"
  },
  {
    "text": "was a number of benefits there was also a large number of challenges Vlad was that tech lead on Rubik for the last 15",
    "start": "635780",
    "end": "642620"
  },
  {
    "start": "637000",
    "end": "668000"
  },
  {
    "text": "or 18 months he was on the front lines of solving his problems so I'm gonna hand it over to him to talk through some of the technical challenges we ran into",
    "start": "642620",
    "end": "648650"
  },
  {
    "text": "and some messages we found folks with four challenges first one is gonna be",
    "start": "648650",
    "end": "655130"
  },
  {
    "text": "about leave their election services the second one is gonna be about cloud scaling third one host boot up time and",
    "start": "655130",
    "end": "661520"
  },
  {
    "text": "why doesn't matter when your thermal infrastructure and then fourth one it's gonna be about edge and",
    "start": "661520",
    "end": "666630"
  },
  {
    "text": "container networking so about consensus and leader election based services it's",
    "start": "666630",
    "end": "672450"
  },
  {
    "start": "668000",
    "end": "693000"
  },
  {
    "text": "really important not to kill your leader and in such a service when you're taking now hosts for example the most important",
    "start": "672450",
    "end": "678779"
  },
  {
    "text": "service that we can think of is HCB if you kill the HD leader without any",
    "start": "678779",
    "end": "684149"
  },
  {
    "text": "graceful termination the API server is just going to 504 a couple of for a small period of time in order to solve",
    "start": "684149",
    "end": "691470"
  },
  {
    "text": "this we took an approach where we introduced a framework that we call the pre termination actions framework here",
    "start": "691470",
    "end": "698750"
  },
  {
    "start": "693000",
    "end": "736000"
  },
  {
    "text": "we deploy a binary that can either be a sidecar for a container or binary and on",
    "start": "698750",
    "end": "705690"
  },
  {
    "text": "the actual hosts when a binary starts it does watch to the API server it watches",
    "start": "705690",
    "end": "711329"
  },
  {
    "text": "for its own node and then when terminator selects the node to be terminated at the label in our case",
    "start": "711329",
    "end": "717240"
  },
  {
    "text": "termination pending equals true the the binary is going to detect that that",
    "start": "717240",
    "end": "723149"
  },
  {
    "text": "label was added and execute certain action in its the case it's going to call the move leader endpoint so then we",
    "start": "723149",
    "end": "729480"
  },
  {
    "text": "can terminate the HIV leader gracefully the API servers gonna still serve request happily in that in that time",
    "start": "729480",
    "end": "735600"
  },
  {
    "text": "frame another service that we use in Rubik it's hash code fault we use it for",
    "start": "735600",
    "end": "741420"
  },
  {
    "start": "736000",
    "end": "792000"
  },
  {
    "text": "secrets management and identity management vault is deployed as a free node one node being the primary and two",
    "start": "741420",
    "end": "748949"
  },
  {
    "text": "other nodes being secondary nodes here we chose the same approach before",
    "start": "748949",
    "end": "754050"
  },
  {
    "text": "killing the vault leader we just call it step-down endpoint this is gonna move the leadership of the vault cluster to",
    "start": "754050",
    "end": "760380"
  },
  {
    "text": "another node and then we take down the vault node itself which now is it is a",
    "start": "760380",
    "end": "766500"
  },
  {
    "text": "standby one in in the cluster other services that are present in the kids ecosystem that are doing leader election",
    "start": "766500",
    "end": "772890"
  },
  {
    "text": "are the controller manager and the scheduler for these two we don't have any important to call and we found out",
    "start": "772890",
    "end": "778350"
  },
  {
    "text": "that's just fine to kill them they're basically running in in the background",
    "start": "778350",
    "end": "783750"
  },
  {
    "text": "and they don't affect the overall health of the cluster for the 15 second time frame which they do another leader",
    "start": "783750",
    "end": "790290"
  },
  {
    "text": "election so moving to cloud challenges we found",
    "start": "790290",
    "end": "795350"
  },
  {
    "start": "792000",
    "end": "866000"
  },
  {
    "text": "that the clouds not actually infinite as we believed at start we had some",
    "start": "795350",
    "end": "802010"
  },
  {
    "text": "problems when Amazon launched their fifth generation instance types we decided to use them the next week after",
    "start": "802010",
    "end": "807800"
  },
  {
    "text": "they were launched and in many scenarios Amazon wouldn't even have one or two VMs",
    "start": "807800",
    "end": "813830"
  },
  {
    "text": "to provision for us when we were doing the normal termination cycle so we're detaching one machine 48 from",
    "start": "813830",
    "end": "819920"
  },
  {
    "text": "the auto scaling group and then waiting for the auto scaling group to bring another one up Amazon with just airing",
    "start": "819920",
    "end": "825770"
  },
  {
    "text": "out that in gas that they don't have any capacity and we should just like wait it out or swap the instance type around",
    "start": "825770",
    "end": "832250"
  },
  {
    "text": "November last year Amazon launched the feature for the auto scaling group service called multi instance type of",
    "start": "832250",
    "end": "837830"
  },
  {
    "text": "skinny groups this allows an operator to add more instance types the launch",
    "start": "837830",
    "end": "844100"
  },
  {
    "text": "template they're using for their own skin groups so for example you can have free instance types over there and if",
    "start": "844100",
    "end": "851480"
  },
  {
    "text": "Amazon can't provision the first time for you it's gonna it's gonna move to the second one and so forward so this",
    "start": "851480",
    "end": "857600"
  },
  {
    "text": "helped a lot in deploying Rubik to some of our like bespoke Amazon regions where",
    "start": "857600",
    "end": "863600"
  },
  {
    "text": "a capacity wasn't always available on top of not having capacity always we",
    "start": "863600",
    "end": "870050"
  },
  {
    "start": "866000",
    "end": "939000"
  },
  {
    "text": "found out that sometimes you're running on bad Hardware usually we touch around 10,000 hosts per day we terminate them",
    "start": "870050",
    "end": "876740"
  },
  {
    "text": "bring another one up this increases the chance that you land on bad hardware or",
    "start": "876740",
    "end": "882650"
  },
  {
    "text": "hardware that Amazon wants to retire this can be faulty hypervisors or Amazon or partner that Amazon wants to",
    "start": "882650",
    "end": "889520"
  },
  {
    "text": "duplicate and exchange in the data centers when across our fleet we turned",
    "start": "889520",
    "end": "897320"
  },
  {
    "text": "around 70,000 hosts per week so we get approximately around 100 or 150 events",
    "start": "897320",
    "end": "904610"
  },
  {
    "text": "across our fleet overall in this case we just changed or tweaked the terminator",
    "start": "904610",
    "end": "911240"
  },
  {
    "text": "code to detect this instances like early on in the in the selection process and then we just kill them without going",
    "start": "911240",
    "end": "918020"
  },
  {
    "text": "through the normal pipeline as a real-world example here you can think that one of these",
    "start": "918020",
    "end": "924710"
  },
  {
    "text": "instances that's running on bad hardware can be our API server if all if",
    "start": "924710",
    "end": "930110"
  },
  {
    "text": "that API server dies all the clients are gonna swap their connection to another healthy API server and then they're just",
    "start": "930110",
    "end": "935779"
  },
  {
    "text": "gonna have a fun during hard problem moving next to host boot up time when",
    "start": "935779",
    "end": "942529"
  },
  {
    "start": "939000",
    "end": "1082000"
  },
  {
    "text": "you're running a formal infrastructure it's actually important to design for this problem in our environment our",
    "start": "942529",
    "end": "949490"
  },
  {
    "text": "hosts live up to 48 hours so spending a lot of time just setting up the hosts",
    "start": "949490",
    "end": "955279"
  },
  {
    "text": "for doing actual work seems wasteful in the previous cloud architecture would",
    "start": "955279",
    "end": "960740"
  },
  {
    "text": "take us around 40 to 40 minutes to bring a host up and that's just time left on",
    "start": "960740",
    "end": "966019"
  },
  {
    "text": "the table not running any and user workload on each host we run for static",
    "start": "966019",
    "end": "973069"
  },
  {
    "text": "pods for various admin purposes like collecting logs or monitoring the host itself when these static pods start we",
    "start": "973069",
    "end": "980629"
  },
  {
    "text": "need to pull their darker image from a central docker registry in our case we host the central one across all our",
    "start": "980629",
    "end": "987379"
  },
  {
    "text": "environments and we found out that during a day across our fleet we are",
    "start": "987379",
    "end": "993980"
  },
  {
    "text": "doing 32,000 MH pools just for starting the hosts",
    "start": "993980",
    "end": "999649"
  },
  {
    "text": "this meant that we're spending a lot of time on our gateway machines just doing network traffic pulling these images",
    "start": "999649",
    "end": "1005199"
  },
  {
    "text": "over and over again to overcome this problem we deployed then in vbc in",
    "start": "1005199",
    "end": "1010569"
  },
  {
    "text": "cluster image registry and all the other image pools are locally that we faster",
    "start": "1010569",
    "end": "1016120"
  },
  {
    "text": "and you're not over subscribing the Gateway machines for network traffic another flavor of a host boot up problem",
    "start": "1016120",
    "end": "1023800"
  },
  {
    "text": "can be establishing the identity of the host itself usually when a host comes up",
    "start": "1023800",
    "end": "1030850"
  },
  {
    "text": "you need to write talk to an external service to get either some credentials in our case we talked to volt to get the",
    "start": "1030850",
    "end": "1038110"
  },
  {
    "text": "certificate for the host that signed for the for the host name itself back in the",
    "start": "1038110",
    "end": "1043808"
  },
  {
    "text": "day all our hosts were asking vault directly to generate the certificate and",
    "start": "1043809",
    "end": "1049360"
  },
  {
    "text": "and the key that's meant that the vault cluster itself was generating that secret material and then passing it on",
    "start": "1049360",
    "end": "1055990"
  },
  {
    "text": "to the host itself this was putting a lot of load volt cluster just like the leading",
    "start": "1055990",
    "end": "1061309"
  },
  {
    "text": "entropy and doing a lot of CPU cycles just to generate secret data we swapped",
    "start": "1061309",
    "end": "1066919"
  },
  {
    "text": "our approach to issue a CSR locally on the host and then passing the CSR to",
    "start": "1066919",
    "end": "1072769"
  },
  {
    "text": "vault to sign this overall I think dropped the load on our biggest vault",
    "start": "1072769",
    "end": "1079129"
  },
  {
    "text": "cluster around 80% moving over to ingress and egress networking our our",
    "start": "1079129",
    "end": "1088940"
  },
  {
    "start": "1082000",
    "end": "1189000"
  },
  {
    "text": "VPC design is pretty standard follows follows couple of industry standard",
    "start": "1088940",
    "end": "1094279"
  },
  {
    "text": "practices we deploy across free availability zones and each is",
    "start": "1094279",
    "end": "1099289"
  },
  {
    "text": "configured the same it has one subnet which is called the DMZ subnet and the subnet we have our gateway machine that",
    "start": "1099289",
    "end": "1106129"
  },
  {
    "text": "lives over there and then all the other subnets have their default route pointing to this gateway machines would",
    "start": "1106129",
    "end": "1114320"
  },
  {
    "text": "kill the gaiter machine normally as would be another node in the cluster so every 48 hour the host dies this means",
    "start": "1114320",
    "end": "1120889"
  },
  {
    "text": "that all the egress connections from the cluster itself to the outside world are going to be terminated",
    "start": "1120889",
    "end": "1126369"
  },
  {
    "text": "we need the way to re-establish connectivity so we just reused our pre",
    "start": "1126369",
    "end": "1132950"
  },
  {
    "text": "termination access framework to reach out to Amazon when the label was added",
    "start": "1132950",
    "end": "1138440"
  },
  {
    "text": "to the Gateway machine scan the the route tables see the ones that will be",
    "start": "1138440",
    "end": "1143840"
  },
  {
    "text": "invalidated and then just move the route to another gateway machine from the other to a disease that that are still",
    "start": "1143840",
    "end": "1150980"
  },
  {
    "text": "alive and happy this solves the Ebers problem but then we had to solve the",
    "start": "1150980",
    "end": "1156110"
  },
  {
    "text": "ingress problem connections from the outside world coming inside the cluster for this one we opted again for a",
    "start": "1156110",
    "end": "1164299"
  },
  {
    "text": "predetermination action to inject a couple of IP table rules that were sending back TCP reset packets to",
    "start": "1164299",
    "end": "1171139"
  },
  {
    "text": "existing connections to signal them that hey this host is going to die I need to connect to another one that's that's",
    "start": "1171139",
    "end": "1177169"
  },
  {
    "text": "available we also have another IP tables rule that just refuses connections so it",
    "start": "1177169",
    "end": "1184039"
  },
  {
    "text": "forces the client to connect to another host that's that's available so going to",
    "start": "1184039",
    "end": "1190519"
  },
  {
    "start": "1189000",
    "end": "1438000"
  },
  {
    "text": "continue networking here the journey has been interesting so far when we started rubrics were running",
    "start": "1190519",
    "end": "1196730"
  },
  {
    "text": "calico as our CNI plugin we're running around calico 2.5 and after some time",
    "start": "1196730",
    "end": "1204020"
  },
  {
    "text": "when when we started like scaling up and down our cluster we found out that calico didn't have enough IPS to",
    "start": "1204020",
    "end": "1210710"
  },
  {
    "text": "allocate the pods it was just tearing out saying that there are no more IPS available but we",
    "start": "1210710",
    "end": "1216410"
  },
  {
    "text": "didn't have that many parts in the system to just exhaust our full cider block we did some investigation and we found",
    "start": "1216410",
    "end": "1222140"
  },
  {
    "text": "out that the HDD that calico was using was full of data that was outdated it",
    "start": "1222140",
    "end": "1228110"
  },
  {
    "text": "had leases for IP is that weren't available anymore those parts were like",
    "start": "1228110",
    "end": "1233210"
  },
  {
    "text": "long killed so to overcome this problem we just deployed the kid scrunch out that every so often would walk the HCB",
    "start": "1233210",
    "end": "1241940"
  },
  {
    "text": "key space would validate if the data from A to B reflects the real world and",
    "start": "1241940",
    "end": "1247940"
  },
  {
    "text": "just nuke all the audio at IP all all the old IPS to to give them back",
    "start": "1247940",
    "end": "1254540"
  },
  {
    "text": "together another problem that we encountered with calico was around BGP",
    "start": "1254540",
    "end": "1260270"
  },
  {
    "text": "route syncing as our clusters grew in size would take around five to six minutes to bring the hosts up and",
    "start": "1260270",
    "end": "1267740"
  },
  {
    "text": "running so the kids know to be ready in order to receive traffic for those unaware calico increment full mesh for",
    "start": "1267740",
    "end": "1276110"
  },
  {
    "text": "its BGP routing so each node needs to establish a connection to each other node in the cluster when we encountered",
    "start": "1276110",
    "end": "1283430"
  },
  {
    "text": "this issue we decided to look in the community to see like how what other",
    "start": "1283430",
    "end": "1288650"
  },
  {
    "text": "alternatives are available for another CNI plugin and we found out the lift CNI",
    "start": "1288650",
    "end": "1294170"
  },
  {
    "text": "plugin the main differences between these two is that the left one doesn't use an overlay network as Calico does",
    "start": "1294170",
    "end": "1300410"
  },
  {
    "text": "it's doing native VPC routing so every part IP is an actual IP that amazon",
    "start": "1300410",
    "end": "1306590"
  },
  {
    "text": "knows about so they're handed out from your VPC cyberspace we swapped and start",
    "start": "1306590",
    "end": "1313430"
  },
  {
    "text": "using the left one but this didn't come with free the main issues we the main",
    "start": "1313430",
    "end": "1318950"
  },
  {
    "text": "issue in content here is we're doing somewhat bigger scale of events like bringing three to four",
    "start": "1318950",
    "end": "1325090"
  },
  {
    "text": "hundred nodes in service at the same time the lift plug-in would reach out to Amazon to allocate Annie and I then",
    "start": "1325090",
    "end": "1331720"
  },
  {
    "text": "attached the United to the host and the Hannah attached I pieced that en isopods",
    "start": "1331720",
    "end": "1337420"
  },
  {
    "text": "can run on the host so when you imagine doing 300 400 create and modify requests",
    "start": "1337420",
    "end": "1343990"
  },
  {
    "text": "in parallel to Amazon you just get the API rate limited to fix this we opted in",
    "start": "1343990",
    "end": "1351130"
  },
  {
    "text": "to swapping the order of operations so now when a pod comes on the host we",
    "start": "1351130",
    "end": "1356559"
  },
  {
    "text": "allocate any ni and then we reallocate the IPS that we know we're gonna use on",
    "start": "1356559",
    "end": "1361630"
  },
  {
    "text": "that network interface we usually know where the pod st on each note that that",
    "start": "1361630",
    "end": "1367150"
  },
  {
    "text": "we run so this is pretty fine up up until now but we utilized after moving",
    "start": "1367150",
    "end": "1373030"
  },
  {
    "text": "from calico we lost the ability to do network firewalling out of the box so we decided to take it",
    "start": "1373030",
    "end": "1378490"
  },
  {
    "text": "down upon ourselves to build the solution for this we build the solution in house but deploying it to larger",
    "start": "1378490",
    "end": "1385929"
  },
  {
    "text": "clusters we encountered certain scale problems mostly around node and party",
    "start": "1385929",
    "end": "1391420"
  },
  {
    "text": "formers the solution basically deploys an agent on every host and the agent",
    "start": "1391420",
    "end": "1397540"
  },
  {
    "text": "watches pods and watches nodes from the API server but this puts a lot of pressure on the API server starts",
    "start": "1397540",
    "end": "1404080"
  },
  {
    "text": "sending back a lot of information the network traffic outbound from the API",
    "start": "1404080",
    "end": "1409690"
  },
  {
    "text": "service just it's just insane so we went back and looked around the community to see how people are solving",
    "start": "1409690",
    "end": "1416380"
  },
  {
    "text": "this this issue and we found the cilium project and currently we're partnering",
    "start": "1416380",
    "end": "1422440"
  },
  {
    "text": "with the folks from cilium to bring all the good things from the left CNI plugin basically the E&I approach that the left",
    "start": "1422440",
    "end": "1431080"
  },
  {
    "text": "folks took and we're gonna start using the left security stack as well in in the",
    "start": "1431080",
    "end": "1436990"
  },
  {
    "text": "future I'm gonna give it back to Greg for some key takeaways thanks line so",
    "start": "1436990",
    "end": "1444010"
  },
  {
    "start": "1438000",
    "end": "1517000"
  },
  {
    "text": "you know after doing this interruption for about 18 months you know we set out to solve a set of problems that we had",
    "start": "1444010",
    "end": "1450610"
  },
  {
    "text": "at the time thinking this would be a lot easier than it ended up being and for us this was a pair of time a paradigm change in how we",
    "start": "1450610",
    "end": "1457100"
  },
  {
    "text": "approach infrastructure and with any paradigm change you're going to run into a number of unexpected issues and so we",
    "start": "1457100",
    "end": "1462860"
  },
  {
    "text": "talked through some of the issues we ran in today there were many many more that would be happy to talk about if anyone",
    "start": "1462860",
    "end": "1468260"
  },
  {
    "text": "is interested for us we found that you know investing in some relatively simple",
    "start": "1468260",
    "end": "1473950"
  },
  {
    "text": "controllers or solutions like the pre termination action framework allowed us to solve many of these problems in a",
    "start": "1473950",
    "end": "1480590"
  },
  {
    "text": "repeatable way and it took us probably longer to to do that than we should have",
    "start": "1480590",
    "end": "1485660"
  },
  {
    "text": "in retrospect and so for anyone who's considering you know taking an ephemeral",
    "start": "1485660",
    "end": "1490970"
  },
  {
    "text": "or a mutable infrastructure approach and running pretend ease on it I'd encourage you to think about these things upfront",
    "start": "1490970",
    "end": "1496900"
  },
  {
    "text": "you know we realize a lot of benefits by taking this approach I think in retrospect looking back over the last",
    "start": "1496900",
    "end": "1502610"
  },
  {
    "text": "two years knowing what we know today we would definitely take a similar approach we'd probably invest in a few areas a",
    "start": "1502610",
    "end": "1508850"
  },
  {
    "text": "little bit earlier on in the process than we did but we've been able to realize a lot of great benefits in doing",
    "start": "1508850",
    "end": "1513920"
  },
  {
    "text": "this so it didn't come without cost as I've mentioned so that's what we have",
    "start": "1513920",
    "end": "1519980"
  },
  {
    "start": "1517000",
    "end": "1558000"
  },
  {
    "text": "I'll point out that we have a booth in the vendor showroom if you're interested these topics are interested learning",
    "start": "1519980",
    "end": "1525140"
  },
  {
    "text": "more we're happy to go into a lot more depth for anyone interested we also are starting a blog series on Rubik's and",
    "start": "1525140",
    "end": "1531920"
  },
  {
    "text": "our adventures in kubernetes so that others can learn from some of our failures over the last two years so we",
    "start": "1531920",
    "end": "1537260"
  },
  {
    "text": "publish the first blog post last week and there should be a number more coming up and we're happy to turn it over for",
    "start": "1537260",
    "end": "1542270"
  },
  {
    "text": "anyone who has questions thank you [Applause]",
    "start": "1542270",
    "end": "1555460"
  },
  {
    "start": "1558000",
    "end": "1667000"
  },
  {
    "text": "when you're terminating the hosts how do you handle long-running jobs that can't",
    "start": "1559580",
    "end": "1564749"
  },
  {
    "text": "be terminated let's say in the next five hours we have this problem because some",
    "start": "1564749",
    "end": "1570659"
  },
  {
    "text": "of the jobs is really expensive to rerun and can take a long time that's a good",
    "start": "1570659",
    "end": "1576299"
  },
  {
    "text": "question so this is one of the first problems we ran into so we run a lot of spark applications and so anyone who's",
    "start": "1576299",
    "end": "1582450"
  },
  {
    "text": "familiar with spark it's you have a driver and you have several executor 'he's the cost of destroying an executor",
    "start": "1582450",
    "end": "1589109"
  },
  {
    "text": "you may have to do a little bit of repeat work the cost of destroying a driver you have to start the entire job",
    "start": "1589109",
    "end": "1595320"
  },
  {
    "text": "over and so many of these spark applications can run for very very long periods of time and so we built a",
    "start": "1595320",
    "end": "1603359"
  },
  {
    "text": "framework for our stateful services as well where we add essentially a health",
    "start": "1603359",
    "end": "1608519"
  },
  {
    "text": "endpoint sub notion of health on top of readiness and liveness and for drivers",
    "start": "1608519",
    "end": "1614309"
  },
  {
    "text": "we let them say please defer draining me please deferred killing me and so our",
    "start": "1614309",
    "end": "1622049"
  },
  {
    "text": "termination framework actually takes us into account so as we're filtering out",
    "start": "1622049",
    "end": "1627090"
  },
  {
    "text": "all of the eligible nodes into only the ones that we can actually terminate we allow some pods to defer termination for",
    "start": "1627090",
    "end": "1634649"
  },
  {
    "text": "up to 24 hours and so in theory every host only lives 48 hours but we allow at",
    "start": "1634649",
    "end": "1640919"
  },
  {
    "text": "a 24-hour grace period up necessary before we before we terminate it forcefully so some hosts can live up to",
    "start": "1640919",
    "end": "1648690"
  },
  {
    "text": "72 hours but we basically take this into account to try to avoid that with some limits so make sense any other questions",
    "start": "1648690",
    "end": "1657200"
  },
  {
    "text": "front here I'll let me bring the mic",
    "start": "1657200",
    "end": "1661518"
  },
  {
    "text": "thank you they have similar tips and tricks for ephemeral storages",
    "start": "1666690",
    "end": "1673620"
  },
  {
    "start": "1667000",
    "end": "1759000"
  },
  {
    "text": "unfortunately no we we've run into a couple problems with storage over time",
    "start": "1675360",
    "end": "1682659"
  },
  {
    "text": "so most of the storage we use today is is ephemeral so like spark jobs will spell to disk",
    "start": "1682659",
    "end": "1690309"
  },
  {
    "text": "and so forth but that's it's like a ephemeral data so it's fine for running at CD when the SD hosts get",
    "start": "1690309",
    "end": "1697570"
  },
  {
    "text": "terminated we built something kind of similar to persistent volumes versus",
    "start": "1697570",
    "end": "1703990"
  },
  {
    "text": "volume claims where we will detach the EBS volume from the old host and attach",
    "start": "1703990",
    "end": "1709360"
  },
  {
    "text": "it to the new host that comes up that's going to run at CD so that the data will follow that city around we run at City",
    "start": "1709360",
    "end": "1717610"
  },
  {
    "text": "as a static pod but obviously we can't run it as a stateful set since it underpins the API server so there are",
    "start": "1717610",
    "end": "1724059"
  },
  {
    "text": "some tricks like that that we've done which we know we've had to invest in that work upfront we don't run that we",
    "start": "1724059",
    "end": "1730029"
  },
  {
    "text": "need stateful sets today we tried a year ago and ran into some issues with auto",
    "start": "1730029",
    "end": "1736029"
  },
  {
    "text": "scaling groups having capacity that comes up at the wrong availability zone those issues have since been fixed I",
    "start": "1736029",
    "end": "1742059"
  },
  {
    "text": "think in k-y-t's 111 or 112 and so we'll pick those changes up when we return to",
    "start": "1742059",
    "end": "1748539"
  },
  {
    "text": "that work but other than you know treating entity EBS volumes moving them",
    "start": "1748539",
    "end": "1754419"
  },
  {
    "text": "around we don't really have any other choice other than and what are your",
    "start": "1754419",
    "end": "1760210"
  },
  {
    "start": "1759000",
    "end": "1823000"
  },
  {
    "text": "pipelines look like for building the images yeah I can get a one so we build",
    "start": "1760210",
    "end": "1768370"
  },
  {
    "text": "a foundation ami that's just basically running Packer on top of Ubuntu Bionic",
    "start": "1768370",
    "end": "1774820"
  },
  {
    "text": "and from there we publish that ami internally and then every type of host",
    "start": "1774820",
    "end": "1780370"
  },
  {
    "text": "that we run Rubik we have I think five of them so Gateway machines are a bit special it's needs a bit special masters which",
    "start": "1780370",
    "end": "1788740"
  },
  {
    "text": "are API server controller manager scheduler and then just like the plain worker so we rebate the foundation a mine",
    "start": "1788740",
    "end": "1794980"
  },
  {
    "text": "like different packages that we need or receiving different docker images and then we just like publish that and our",
    "start": "1794980",
    "end": "1801370"
  },
  {
    "text": "terraform code when it runs finds these like the certain type of a.m. eyes and",
    "start": "1801370",
    "end": "1807580"
  },
  {
    "text": "just much lunch of them so as a bluff is just running Packard of Ubuntu and then",
    "start": "1807580",
    "end": "1815890"
  },
  {
    "text": "like we package it internally afterwards",
    "start": "1815890",
    "end": "1819929"
  },
  {
    "text": "first of all a great job second the question and your experience most of",
    "start": "1822870",
    "end": "1828220"
  },
  {
    "start": "1823000",
    "end": "1975000"
  },
  {
    "text": "their photos be spent on the ephemeral model or at the scale or both or the",
    "start": "1828220",
    "end": "1835900"
  },
  {
    "text": "ephemeral model becomes so complicated due to the scale it's - it's the",
    "start": "1835900",
    "end": "1842350"
  },
  {
    "text": "question is are the issues that we ran into mostly due to the ephemeral nature or because of the scale is that correct",
    "start": "1842350",
    "end": "1850500"
  },
  {
    "text": "it's like a mix here for example the",
    "start": "1853140",
    "end": "1858280"
  },
  {
    "text": "ephemerality problem we found it for example in Cades is when amazon reuses",
    "start": "1858280",
    "end": "1865510"
  },
  {
    "text": "IPS from the from the vp see like a new node would come up with the same IP and then the controller manager would detect",
    "start": "1865510",
    "end": "1871750"
  },
  {
    "text": "that it has the same IP and would just kill the node from from kate itself so",
    "start": "1871750",
    "end": "1876940"
  },
  {
    "text": "basically a new machine would hijack the identity of an old one and then the controller manager would indeed the nodes or you're stuck with with just an",
    "start": "1876940",
    "end": "1883419"
  },
  {
    "text": "easy to node running a cubelet but the cubelet wouldn't read register itself so that's like one form of from relative",
    "start": "1883419",
    "end": "1890260"
  },
  {
    "text": "problem scale problem I think we wanted we hit a new scale problem it's like a",
    "start": "1890260",
    "end": "1897010"
  },
  {
    "text": "in the networking stack like the networking challenges that I discussed with calico other than that just when we",
    "start": "1897010",
    "end": "1906130"
  },
  {
    "text": "launched workloads and all of them try to talk to the API server that's mostly",
    "start": "1906130",
    "end": "1912010"
  },
  {
    "text": "something that we need to take care of on our end rather than Kate's specific problem can you think of any other area",
    "start": "1912010",
    "end": "1918730"
  },
  {
    "text": "from so I think the the edge networking challenges the glad talked about like ingress and egress from the cluster",
    "start": "1918730",
    "end": "1925730"
  },
  {
    "text": "those are largely based on like the ephemeral nature of them that's you know it has little to do with scale itself so",
    "start": "1925730",
    "end": "1932690"
  },
  {
    "text": "I think those anyone who does this who also has single entry points and egress points in their environment will also",
    "start": "1932690",
    "end": "1938870"
  },
  {
    "text": "have to face other networking like the container networking challenges were",
    "start": "1938870",
    "end": "1944870"
  },
  {
    "text": "some mix and it sort of changed over time so calico it was kind of the ephemeral nature the lift stuff we run",
    "start": "1944870",
    "end": "1951380"
  },
  {
    "text": "into today's is more related to it's more related to scale though the",
    "start": "1951380",
    "end": "1956810"
  },
  {
    "text": "problems are exacerbated by the fact that there's so much change in the environment it just makes it harder and",
    "start": "1956810",
    "end": "1963280"
  },
  {
    "text": "then yeah it's sort of a mixed I would say the first year was all ephemeral stuff the last year it's been a mix of",
    "start": "1963280",
    "end": "1970760"
  },
  {
    "text": "scale and if I'm wrong challenges hello very good talk and I do",
    "start": "1970760",
    "end": "1978440"
  },
  {
    "start": "1975000",
    "end": "2113000"
  },
  {
    "text": "upload your bond approach into this I can only imagine meetings how they went so my question is related with provider",
    "start": "1978440",
    "end": "1985550"
  },
  {
    "text": "cloud provider bugs it sounds like your approach in the lifecycle of machine can actually propagate them instead of",
    "start": "1985550",
    "end": "1991610"
  },
  {
    "text": "contain them into one let's say or two instances and how does this look like in the monitoring and alerting for you so I",
    "start": "1991610",
    "end": "2001990"
  },
  {
    "text": "think the question is how do there challenges we see how do we handle them",
    "start": "2001990",
    "end": "2007570"
  },
  {
    "text": "in like network or the monitoring and learning is that right you wanna take",
    "start": "2007570",
    "end": "2013240"
  },
  {
    "text": "that one or you want me to so I think one of the big challenges for us with",
    "start": "2013240",
    "end": "2019780"
  },
  {
    "text": "our first reiation cloud was we had very rigid rules for monitoring and alerting",
    "start": "2019780",
    "end": "2025210"
  },
  {
    "text": "so when a host would disappear for instance it would like ring all the bells which is so we couldn't autoscale",
    "start": "2025210",
    "end": "2031510"
  },
  {
    "text": "are first generation first generation cloud and the second generation one we",
    "start": "2031510",
    "end": "2036580"
  },
  {
    "text": "it with Rubik we moved to our sort of a we care a lot less about every host and",
    "start": "2036580",
    "end": "2042220"
  },
  {
    "text": "we care more about an auto scaling group and so we will alert when the of instances in in an auto scaling group",
    "start": "2042220",
    "end": "2050669"
  },
  {
    "text": "drops below some threshold but we don't care about a given host so if a host",
    "start": "2050669",
    "end": "2056128"
  },
  {
    "text": "comes up and it's bad like there's Amazon hardware issues we just kill it it's just like we don't",
    "start": "2056129",
    "end": "2062070"
  },
  {
    "text": "even care just like kill it move on with their lives and it's only once the",
    "start": "2062070",
    "end": "2067590"
  },
  {
    "text": "number of those problems crosses some threshold that we start worrying about it doesn't make sense I this is true",
    "start": "2067590",
    "end": "2074520"
  },
  {
    "text": "largely for like the large pools of worker nodes we run when one of the routers is becomes unhealthy we've had",
    "start": "2074520",
    "end": "2081360"
  },
  {
    "text": "issues over time where before the pre termination action framework we would",
    "start": "2081360",
    "end": "2086460"
  },
  {
    "text": "have an issue where if the router became bad your only egress point from the",
    "start": "2086460",
    "end": "2092100"
  },
  {
    "text": "availability zone would be down so you lose the entire AZ and so there were some issues like that that we had to",
    "start": "2092100",
    "end": "2098250"
  },
  {
    "text": "work through early on in order to make the alerting work correct but today we",
    "start": "2098250",
    "end": "2103800"
  },
  {
    "text": "take much more of a like cattle verse pets approach to the problem",
    "start": "2103800",
    "end": "2110540"
  },
  {
    "start": "2113000",
    "end": "2244000"
  },
  {
    "text": "you mentioned that you run the darker image registry locally on the V PC for",
    "start": "2114150",
    "end": "2120599"
  },
  {
    "text": "to handle the the pull the image pull problem can't describe in more detail how you manage images how many",
    "start": "2120599",
    "end": "2127230"
  },
  {
    "text": "registries you use how do you push images yeah I think so",
    "start": "2127230",
    "end": "2133349"
  },
  {
    "text": "usually our developers like building images internally and we use at factory",
    "start": "2133349",
    "end": "2138630"
  },
  {
    "text": "Jeff our artifact internally so we published those in our corporate registry and then on top of that we have",
    "start": "2138630",
    "end": "2146279"
  },
  {
    "text": "a solution that allows external clusters from the internet to just authenticate",
    "start": "2146279",
    "end": "2153180"
  },
  {
    "text": "with that corporate network registry to pull the images and in our V PC on our",
    "start": "2153180",
    "end": "2159240"
  },
  {
    "text": "gateway machines we deploy we'll play catch registry basically so the way when",
    "start": "2159240",
    "end": "2166440"
  },
  {
    "text": "the when the gate of machine comes up its cache is gonna be empty for the moment all the clients are going to",
    "start": "2166440",
    "end": "2171839"
  },
  {
    "text": "reach the cache the cache is gonna reach upstream it's gonna pull the limits and then all the image is gonna be cached on",
    "start": "2171839",
    "end": "2177359"
  },
  {
    "text": "the routers and it's gonna happen across like all free AZ's when those machines cycle basically now we're looking into",
    "start": "2177359",
    "end": "2184920"
  },
  {
    "text": "storing actually the cache on ABS drives and do the same dance as we do it look at CD like it's gonna follow the it's",
    "start": "2184920",
    "end": "2191249"
  },
  {
    "text": "gonna follow the node when it comes up and down just to sustain on unavailability of the of the central",
    "start": "2191249",
    "end": "2196259"
  },
  {
    "text": "registry itself today it's also helpful that we have a relatively few number of",
    "start": "2196259",
    "end": "2201539"
  },
  {
    "text": "images that are run in our environment like the vast majority of pods run one of five sparked images for instance and",
    "start": "2201539",
    "end": "2208739"
  },
  {
    "text": "so once ok the cache warms quite quickly and it involves slowly over time and so",
    "start": "2208739",
    "end": "2214829"
  },
  {
    "text": "we get a lot of value out of that as we run more and more of our infrastructure more and more like our micro services in",
    "start": "2214829",
    "end": "2220769"
  },
  {
    "text": "the environment we expect that to you know go up some and that will have a higher rate of churn but cool I suspect",
    "start": "2220769",
    "end": "2227670"
  },
  {
    "text": "we're probably out of time so we'll do one more question and for anyone else who's interested you find us here after or come to our booth so",
    "start": "2227670",
    "end": "2234740"
  },
  {
    "text": "to the back corner [Music]",
    "start": "2234740",
    "end": "2240159"
  },
  {
    "start": "2244000",
    "end": "2313000"
  },
  {
    "text": "hi I'm Junaid so I have a question related to DNS have you had any issues with your DNS in a while at scale",
    "start": "2244790",
    "end": "2252080"
  },
  {
    "text": "because you have like eight hundred plus notes cluster so did you face any issues with be frank here I don't think we paid",
    "start": "2252080",
    "end": "2263410"
  },
  {
    "text": "close attention to DNS issues currently we're running Cordilleras and all the",
    "start": "2263410",
    "end": "2270310"
  },
  {
    "text": "practices that the community upstream like opened to the world I think we've",
    "start": "2270310",
    "end": "2278720"
  },
  {
    "text": "hit a couple of problems with the Amazon the VPC dns resolver rate limiting us",
    "start": "2278720",
    "end": "2283910"
  },
  {
    "text": "because we're doing so many queries but I suspect those are just because of the empaths problem and the rest people are",
    "start": "2283910",
    "end": "2289940"
  },
  {
    "text": "hitting so we're planning to deploy the local node cache to like not do so many",
    "start": "2289940",
    "end": "2295760"
  },
  {
    "text": "queries upstream and just like hit the hit the local cache but other than that I think that's it and in this indiana",
    "start": "2295760",
    "end": "2303619"
  },
  {
    "text": "space that we had cool thanks for coming we're after anyone has any other",
    "start": "2303619",
    "end": "2310010"
  },
  {
    "text": "questions thank you [Applause]",
    "start": "2310010",
    "end": "2314859"
  }
]
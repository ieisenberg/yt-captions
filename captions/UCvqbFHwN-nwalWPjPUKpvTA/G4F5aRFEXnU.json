[
  {
    "start": "0",
    "end": "42000"
  },
  {
    "text": "welcome to this talk about is Tio's performance and scalability we're gonna talk about that my name is Laurent I",
    "start": "120",
    "end": "6330"
  },
  {
    "text": "work at Google I'm one of the core contributors on this to you since before 0.1 a year ago I am for alcholic I'm",
    "start": "6330",
    "end": "15990"
  },
  {
    "text": "with VMware and I'm an engineer over there I'm also looking at service machine hto topics and particularly",
    "start": "15990",
    "end": "21720"
  },
  {
    "text": "around performance and scale topics hello everyone my name is Surya dagger Allah",
    "start": "21720",
    "end": "26939"
  },
  {
    "text": "I am from my IBM along with Laurent I jointly chaired this hto working group",
    "start": "26939",
    "end": "33450"
  },
  {
    "text": "on performance also I work on IBM cloud performance engineering so I'll go a bit",
    "start": "33450",
    "end": "43829"
  },
  {
    "start": "42000",
    "end": "149000"
  },
  {
    "text": "over what we're going to talk about today we're gonna tell you a bit about",
    "start": "43829",
    "end": "49469"
  },
  {
    "text": "that working group that we have honesty we study the performance and stability",
    "start": "49469",
    "end": "54690"
  },
  {
    "text": "of sto to try to make sure it helps you solve your you'll need without consuming",
    "start": "54690",
    "end": "60199"
  },
  {
    "text": "too many resources so we have a multi-level approach that we'll go over",
    "start": "60199",
    "end": "66270"
  },
  {
    "text": "and then we'll go over forward we'll go over the environments that we are using we're testing in the multiple multitude",
    "start": "66270",
    "end": "73680"
  },
  {
    "text": "of environments and there's many scenarios that we're looking at then I'll take back the mic and we'll look at",
    "start": "73680",
    "end": "81000"
  },
  {
    "text": "the characterization and probably more more interestingly to you guys the",
    "start": "81000",
    "end": "86430"
  },
  {
    "text": "issues that we found out we found them how we fix them so far and then Surya",
    "start": "86430",
    "end": "93119"
  },
  {
    "text": "will take on the mic and talk to you guys about how we study in a realistic",
    "start": "93119",
    "end": "99030"
  },
  {
    "text": "application how do we study the performance using a realistic application benchmark and the results",
    "start": "99030",
    "end": "105840"
  },
  {
    "text": "there and at the end we'll talk about what are the next steps first to you it's very new project there's a lot of",
    "start": "105840",
    "end": "112950"
  },
  {
    "text": "cool features but there's a long road ahead in terms of what we can do to make",
    "start": "112950",
    "end": "118560"
  },
  {
    "text": "it performance scale as best as we can and then we'll take some some questions",
    "start": "118560",
    "end": "123860"
  },
  {
    "text": "so I'm assuming so that so this is the",
    "start": "123860",
    "end": "129360"
  },
  {
    "text": "workgroup I'm assuming everybody by now should know what his teo is so I'm gonna",
    "start": "129360",
    "end": "134780"
  },
  {
    "text": "just skip over that she wanted to learn about history oh the previous talk was",
    "start": "134780",
    "end": "140989"
  },
  {
    "text": "about a steel so our working group is meeting regularly and since December we",
    "start": "140989",
    "end": "146420"
  },
  {
    "text": "studied the default and I want I want to say a few words about our parts so",
    "start": "146420",
    "end": "152620"
  },
  {
    "start": "149000",
    "end": "277000"
  },
  {
    "text": "there's many levels in which we can look at the performance characterization of a system and we do it at those at multiple",
    "start": "152620",
    "end": "160550"
  },
  {
    "text": "levels first a lot of ECU is written in the go language go makes it fairly easy",
    "start": "160550",
    "end": "166580"
  },
  {
    "text": "to write benchmarks so we do have a lot of benchmarks at the component level to",
    "start": "166580",
    "end": "171709"
  },
  {
    "text": "try to make sure that for instance mixers library as efficient as possible and processing the rules and we've made",
    "start": "171709",
    "end": "180140"
  },
  {
    "text": "significant improvements in the last few months in mixer for instance the second",
    "start": "180140",
    "end": "185720"
  },
  {
    "text": "level is we do synthetic benchmarks so we simulate the setup and for that we",
    "start": "185720",
    "end": "192230"
  },
  {
    "text": "wrote a tool called for tio that of Osseo that lets you basically be a next",
    "start": "192230",
    "end": "199579"
  },
  {
    "text": "generation echo server alot generation and lets you visualize the results we",
    "start": "199579",
    "end": "209060"
  },
  {
    "text": "also then at the next level use something that more realistic for applications which is the blue proof",
    "start": "209060",
    "end": "215600"
  },
  {
    "text": "it's also open source like for to you so you can reproduce the results that we produce in your in your environment and",
    "start": "215600",
    "end": "224450"
  },
  {
    "text": "this is what we are trying to do we're trying to set up some base tools some set of libraries that anyone can use in",
    "start": "224450",
    "end": "232459"
  },
  {
    "text": "order to test in their particular cloud environment or their particular setup because it still works on QA ladies but",
    "start": "232459",
    "end": "239150"
  },
  {
    "text": "not just on pure ladies and there's many dimensions whether it's the payload size or whether it's the protocol you're",
    "start": "239150",
    "end": "245930"
  },
  {
    "text": "doing HTTP you're doing Jay RPC you're doing something else so we'd like to leverage the community so everybody can",
    "start": "245930",
    "end": "253489"
  },
  {
    "text": "participate and help us find bottlenecks in different dimensions and",
    "start": "253489",
    "end": "259549"
  },
  {
    "text": "then the last point which is actually very important in what we're doing is we",
    "start": "259549",
    "end": "264590"
  },
  {
    "text": "are doing automation where make sure that every release every night is being tested such as we find regressions",
    "start": "264590",
    "end": "270990"
  },
  {
    "text": "early or we can track the improvement over time of the performance and for",
    "start": "270990",
    "end": "279000"
  },
  {
    "start": "277000",
    "end": "659000"
  },
  {
    "text": "what now we'll go over those environments oh thanks all right packed room here I'm",
    "start": "279000",
    "end": "286470"
  },
  {
    "text": "pretty sure a lot of you guys are users of different type of cloud environments",
    "start": "286470",
    "end": "291930"
  },
  {
    "text": "AWS Google IBM on-prem OpenStack maybe cloud foundry and looking at service",
    "start": "291930",
    "end": "298020"
  },
  {
    "text": "mesh and must be wondering if these guys are actually testing or looking at scenarios from your angle so I'll try to",
    "start": "298020",
    "end": "304380"
  },
  {
    "text": "cover most of these if there's something which we are not covering please come and talk to us after the presentation and we'll be happy to talk about this or",
    "start": "304380",
    "end": "309960"
  },
  {
    "text": "you know more than that just come in contribute as well to the group so the what I'm going to cover is the different",
    "start": "309960",
    "end": "316200"
  },
  {
    "text": "environments and scenarios some of those that we have done so far as part of the working group and those include GE IBM a",
    "start": "316200",
    "end": "324870"
  },
  {
    "text": "deep us as your and some on-prem data that we got from one of the customers was using these tools so let's go over",
    "start": "324870",
    "end": "332850"
  },
  {
    "text": "how it looks like in GK this is part of the East your repository where there's there's a an environment set up a",
    "start": "332850",
    "end": "342360"
  },
  {
    "text": "framework that you can use to bring up the entire end-to-end cubed as a deployment with sto 40 oh and there are",
    "start": "342360",
    "end": "349410"
  },
  {
    "text": "few test cases that you can run for example one that you see here is where you can deploy 40 you as a client server",
    "start": "349410",
    "end": "357120"
  },
  {
    "text": "both doing part about performance testing and you can just for example",
    "start": "357120",
    "end": "363810"
  },
  {
    "text": "what you see over here on top right is a pod active server 1 and X over 2 if both",
    "start": "363810",
    "end": "368850"
  },
  {
    "text": "of them have sidecar so we will check kind of data plane and also some mixer rule checks and check performance on",
    "start": "368850",
    "end": "375870"
  },
  {
    "text": "that topic the other one is where you can also include ingress to see the results for your performance and that",
    "start": "375870",
    "end": "382950"
  },
  {
    "text": "you know traffic comes from 40 to instance running on a GC EVM outside the cluster goodness cluster and the third",
    "start": "382950",
    "end": "388380"
  },
  {
    "text": "one is where you wanna run test cases without sto to see the comparison of how it looks like where they steer and",
    "start": "388380",
    "end": "395490"
  },
  {
    "text": "without sto wedding dress without Angus etcetera that's one of the things which is there Laurent is gonna go into details of some",
    "start": "395490",
    "end": "402310"
  },
  {
    "text": "of the desserts we have captured from this scenario in this environment another one is an IBM cloud what Lauren",
    "start": "402310",
    "end": "409389"
  },
  {
    "text": "mentioned was regression Patrol this is part of the automation and CIA automation which covers which provides",
    "start": "409389",
    "end": "417340"
  },
  {
    "text": "us data on you know how daily builds are looking and this is the sample app which is there it's kind of looks like a real",
    "start": "417340",
    "end": "424449"
  },
  {
    "text": "deployment app which has a flight authentication piece a customer booking has a way to publish the radiograph Anna",
    "start": "424449",
    "end": "430779"
  },
  {
    "text": "that you can go and look at lot of Surya is going to cover this and we'll give",
    "start": "430779",
    "end": "436360"
  },
  {
    "text": "you a small demo of this one as well and in this one instead of using 4000 it uses geometer",
    "start": "436360",
    "end": "442060"
  },
  {
    "text": "which runs on a on a vm outside the cluster and generates traffic and most of it goes to the ingress so it kind of",
    "start": "442060",
    "end": "448779"
  },
  {
    "text": "looks at the holistic view or real industry use case point of view then",
    "start": "448779",
    "end": "454050"
  },
  {
    "text": "vmware we've been looking at from AWS perspective and what it does is that you",
    "start": "454050",
    "end": "459999"
  },
  {
    "text": "could bring up a kubernetes cluster using key ups and there's a jupiter notebook which allows you to bring up",
    "start": "459999",
    "end": "466000"
  },
  {
    "text": "your cluster you can define what kind of test case you want to run or scenario you want to run and you know it's super",
    "start": "466000",
    "end": "471279"
  },
  {
    "text": "configurable so you can justify just defined like number of 40 instances it's 40 s being used over here for load",
    "start": "471279",
    "end": "477039"
  },
  {
    "text": "generation but on the server side were using l1 which can handle 100 100 thousand plus requests per second it's",
    "start": "477039",
    "end": "482710"
  },
  {
    "text": "supposed to be super robust since working well for us and the kind of scenarios that we started was with was",
    "start": "482710",
    "end": "488819"
  },
  {
    "text": "without hto where this teo and with auth and then also move to without mixer see",
    "start": "488819",
    "end": "495310"
  },
  {
    "text": "the comparison of how numbers look like if we go and talk to anyone if you know someone comes is like I'm gonna adopt",
    "start": "495310",
    "end": "500949"
  },
  {
    "text": "service mesh and does it like what's the cost that I'm trying to cover so there are some numbers that we captured from",
    "start": "500949",
    "end": "506620"
  },
  {
    "text": "here our latency etc and soui I will talk about some CPUs - numbers will be",
    "start": "506620",
    "end": "512260"
  },
  {
    "text": "use over there so just to give an example here this is some sample deployment that you can use the Jupiter",
    "start": "512260",
    "end": "517719"
  },
  {
    "text": "notebook and you know just enable a steal and then run the scenario game to capture the results and then you can",
    "start": "517719",
    "end": "524138"
  },
  {
    "text": "also enable authentication to capture the same scenarios for that same results for that and an example capture of the",
    "start": "524139",
    "end": "531430"
  },
  {
    "text": "plot says here these numbers are from an old early surface tio which are like 40,000",
    "start": "531430",
    "end": "537310"
  },
  {
    "text": "QPS for a different number of clients of 40 Oh which can be scaled up and down and captures different kind of",
    "start": "537310",
    "end": "543040"
  },
  {
    "text": "percentiles 50 75 9999 99.99 and as you",
    "start": "543040",
    "end": "548680"
  },
  {
    "text": "see over here there are three bars for each of those one captures without authentication the other one cap",
    "start": "548680",
    "end": "554740"
  },
  {
    "text": "captures with sto with authentication and the third one is with no sto",
    "start": "554740",
    "end": "561280"
  },
  {
    "text": "gives you a good comparison and we'll talk about some of the improvements we have done in this area",
    "start": "561280",
    "end": "566590"
  },
  {
    "text": "another topic another cloud environment where one of our colleagues from the",
    "start": "566590",
    "end": "573400"
  },
  {
    "text": "community Kari has been running these scenarios inside Azure and what he has is he's been running with geometer which",
    "start": "573400",
    "end": "580750"
  },
  {
    "text": "talks to there's your load balancer and it looks like as is to your ingress",
    "start": "580750",
    "end": "585880"
  },
  {
    "text": "configured for the you know traffic path and there's a target service which has two nested services one is an HTTP",
    "start": "585880",
    "end": "592600"
  },
  {
    "text": "back-end the other one is a RPC back-end and it's running on aqueous pressure and",
    "start": "592600",
    "end": "598270"
  },
  {
    "text": "how it looks like is some results that we've captured over here is you see on",
    "start": "598270",
    "end": "604900"
  },
  {
    "text": "the left side it's first 15 minutes captured the service target service is sending traffic to the HTTP back-end and",
    "start": "604900",
    "end": "611560"
  },
  {
    "text": "afterwards is sending the GOP sea back in and you see some difference over there there of course you may think there are many variables here it could be",
    "start": "611560",
    "end": "617350"
  },
  {
    "text": "application code as well but there is some you know numbers we have captured over therefore in terms of differences",
    "start": "617350",
    "end": "623680"
  },
  {
    "text": "between different application different out paths and the last one I want to cover is the on Prem where for tu is",
    "start": "623680",
    "end": "630460"
  },
  {
    "text": "being used to generate traffic and is a hardware load balancer this is a completely arm deployment and the summary service looks very similar we",
    "start": "630460",
    "end": "637300"
  },
  {
    "text": "had to anonymize it because of the customer and there's an entry service which has two nested G RPC backends and",
    "start": "637300",
    "end": "642640"
  },
  {
    "text": "there are some results being captured over there this is a small presentation about 30 minutes 35 minutes so we could",
    "start": "642640",
    "end": "648880"
  },
  {
    "text": "only give you an overview if you need more information you can come talk to us and with that I'm gonna head over to",
    "start": "648880",
    "end": "654510"
  },
  {
    "text": "Laurent to talk about performance characterizations Thanks thank you",
    "start": "654510",
    "end": "659870"
  },
  {
    "start": "659000",
    "end": "1048000"
  },
  {
    "text": "so as I mentioned we were you as I mentioned earlier sorry one of the one",
    "start": "659870",
    "end": "666380"
  },
  {
    "text": "of the way we we characterize the performance of sto is through 40 so the idea for to you is kind to be a modern",
    "start": "666380",
    "end": "673510"
  },
  {
    "text": "micro service area Swiss Army knife of network testing so it's doing a lot of a",
    "start": "673510",
    "end": "678920"
  },
  {
    "text": "lot of little function all that in a very small image of a few megabytes so",
    "start": "678920",
    "end": "685970"
  },
  {
    "text": "you can deploy hundreds of it if you wanted to in order to simulate a fairly deep or wide cluster and and still be",
    "start": "685970",
    "end": "694430"
  },
  {
    "text": "very very efficient so it's also a go library so we use it inside is to you to",
    "start": "694430",
    "end": "701510"
  },
  {
    "text": "do functional testing not just performance testing so for instance we send exactly 200 requests and we make",
    "start": "701510",
    "end": "707300"
  },
  {
    "text": "sure there's no you can read the map of the result codes and we make sure that there's no errors or that the metrics",
    "start": "707300",
    "end": "713500"
  },
  {
    "text": "actually add up exactly and there's no no errors so it has a component which is",
    "start": "713500",
    "end": "722060"
  },
  {
    "text": "a command line and as a client has a load generator and also a server-side",
    "start": "722060",
    "end": "729680"
  },
  {
    "text": "like an echo server bit like HTTP bin where you can customize the result code",
    "start": "729680",
    "end": "736280"
  },
  {
    "text": "that it replies the payload size many parameters so the the main the key",
    "start": "736280",
    "end": "745430"
  },
  {
    "text": "element there is to run the system at a fixed QPS so if you what you want to do",
    "start": "745430",
    "end": "751970"
  },
  {
    "text": "when you're trying to characterize performance is you want to push your system higher and higher and then you find the point where it starts to",
    "start": "751970",
    "end": "758570"
  },
  {
    "text": "saturate maybe the CPU is saturated or the iOS is saturated and then you want to walk back from that about 80% and and",
    "start": "758570",
    "end": "766130"
  },
  {
    "text": "run the test at that fixed ups in order to get the latency that you expect to get the distribution of latencies that",
    "start": "766130",
    "end": "773060"
  },
  {
    "text": "you expect to get in in your production system so this is one of the main",
    "start": "773060",
    "end": "778430"
  },
  {
    "text": "features it can run at a set capias and there is a bit of a a way to visualize",
    "start": "778430",
    "end": "785810"
  },
  {
    "text": "the data it's also fairly high performance because it it can easily do",
    "start": "785810",
    "end": "791360"
  },
  {
    "text": "400 QPS on self-testing so I'm gonna do a bit of a",
    "start": "791360",
    "end": "796460"
  },
  {
    "text": "small demo of the actual system so some",
    "start": "796460",
    "end": "805490"
  },
  {
    "text": "of its study this is the it's big enough",
    "start": "805490",
    "end": "810800"
  },
  {
    "text": "so as you can tell it's built by engineers so the UI is not it's not supposed to be pretty but it has a bunch",
    "start": "810800",
    "end": "818690"
  },
  {
    "text": "of features you can set up whether you're gonna do a gr PC or an HTTP load",
    "start": "818690",
    "end": "823880"
  },
  {
    "text": "this is the UI to actually create a lot so it's going to run against itself and",
    "start": "823880",
    "end": "829240"
  },
  {
    "text": "the eco server that's running you can tell it for instance in this case or in five percent of the requests introduced",
    "start": "829240",
    "end": "837440"
  },
  {
    "text": "a five millisecond delay and also in the oh five percent of the requests please please make a five five or three instead",
    "start": "837440",
    "end": "844760"
  },
  {
    "text": "of a two hundred so we click here it runs against itself and then you get you",
    "start": "844760",
    "end": "851000"
  },
  {
    "text": "get the result and as you can see there is indeed like a bump there that's the",
    "start": "851000",
    "end": "856010"
  },
  {
    "text": "long tail of off the data see it bigger",
    "start": "856010",
    "end": "861770"
  },
  {
    "text": "she put in log like this and you can",
    "start": "861770",
    "end": "867980"
  },
  {
    "text": "also see the result codes there that that are about what about what we asked",
    "start": "867980",
    "end": "873080"
  },
  {
    "text": "so that lets you kind of explore like you have your system and you try a few things you explore it and then once",
    "start": "873080",
    "end": "879830"
  },
  {
    "text": "you've exploited you bake that into a scenario and then you run that scenario build up your build and that's what we",
    "start": "879830",
    "end": "885770"
  },
  {
    "text": "are doing here where we we have the",
    "start": "885770",
    "end": "892760"
  },
  {
    "text": "automation that runs now for every release on both of release branch and hour and the master branch and you can",
    "start": "892760",
    "end": "901720"
  },
  {
    "text": "visualize than the results so I'm not going to show you the daily build but I'm gonna show you what happened in the",
    "start": "901720",
    "end": "909500"
  },
  {
    "text": "last three months for our actual releases so this is the scenario one the",
    "start": "909500",
    "end": "914870"
  },
  {
    "text": "service one to service to in the picture earlier there was two services and then",
    "start": "914870",
    "end": "920450"
  },
  {
    "text": "we have a what I call a cache busting rule so there's a rule that makes it that in",
    "start": "920450",
    "end": "926509"
  },
  {
    "text": "one direction you never the mixer results are never cashed and the other direction they are",
    "start": "926509",
    "end": "932929"
  },
  {
    "text": "always cashed so that gives you a zero percent which is the worst case scenario and hundred percent which is the best",
    "start": "932929",
    "end": "939049"
  },
  {
    "text": "case scenario and then you can adjust those two numbers to get an idea of what it's going to be for your actual cash it",
    "start": "939049",
    "end": "945619"
  },
  {
    "text": "may show that you expect the mixer dashboard also shows the cash ratio so",
    "start": "945619",
    "end": "950629"
  },
  {
    "text": "you can see in your production deployment what cash it may show you actually get so here you can see the",
    "start": "950629",
    "end": "957739"
  },
  {
    "text": "evolution this is the zero five released in the middle the zero six release and",
    "start": "957739",
    "end": "963429"
  },
  {
    "text": "latest release because your 8 is not out yet which is zero seven one so in that",
    "start": "963429",
    "end": "969470"
  },
  {
    "text": "setup the black line is the QPS you can see that we went from about 700 QPS from",
    "start": "969470",
    "end": "978949"
  },
  {
    "text": "2,000 to PS and now to above 1700 QPS at",
    "start": "978949",
    "end": "984049"
  },
  {
    "text": "at the max the latency obviously is not is not great the p90 line is very high",
    "start": "984049",
    "end": "991789"
  },
  {
    "text": "because we are pushing the system there it's like cpu-bound so here we can",
    "start": "991789",
    "end": "1001029"
  },
  {
    "text": "compare to $2 point where this is your six this is your seven and if you if you put",
    "start": "1001029",
    "end": "1007749"
  },
  {
    "text": "the two together you can see you can exactly compare exactly the distribution of data and the curve of the percentage",
    "start": "1007749",
    "end": "1016929"
  },
  {
    "text": "cumulative percent you I think I'm gonna",
    "start": "1016929",
    "end": "1022660"
  },
  {
    "text": "go back to the presentation but if you have any more questions you can look up the song github is tu / patio there's a",
    "start": "1022660",
    "end": "1030699"
  },
  {
    "text": "lot of dogs and examples and those data is on photo that is tutorials you can go",
    "start": "1030699",
    "end": "1035798"
  },
  {
    "text": "look up you can explore the data that we produce and the scenarios on your own",
    "start": "1035799",
    "end": "1040928"
  },
  {
    "text": "ideas okay so this is what I showed you",
    "start": "1040929",
    "end": "1048839"
  },
  {
    "start": "1048000",
    "end": "1357000"
  },
  {
    "text": "so now for the interesting things like how did we get how was it like six",
    "start": "1049080",
    "end": "1055110"
  },
  {
    "text": "hundred QPS and now it's 1700 gps in in three months so what happened well a lot",
    "start": "1055110",
    "end": "1060119"
  },
  {
    "text": "of it is what happens when you write production software is you write it and",
    "start": "1060119",
    "end": "1065610"
  },
  {
    "text": "it seems fine and then you load it and unexpected things happen one easy way to",
    "start": "1065610",
    "end": "1071610"
  },
  {
    "text": "to get into trouble is is logging part exactly so to do a good job you want to",
    "start": "1071610",
    "end": "1077279"
  },
  {
    "text": "log in pollen events so it shows you can troubleshoot what's going on but then from a production point of view",
    "start": "1077279",
    "end": "1082789"
  },
  {
    "text": "depending how you do your login you can end up having either too many O's log",
    "start": "1082789",
    "end": "1088649"
  },
  {
    "text": "processing can slow down your your system or even say ization where your",
    "start": "1088649",
    "end": "1094859"
  },
  {
    "text": "multiple threads are trying to all log something and they can't the throughput",
    "start": "1094859",
    "end": "1100019"
  },
  {
    "text": "drops so we we found that in mixer we were logging things for every single",
    "start": "1100019",
    "end": "1105929"
  },
  {
    "text": "check and that's way way too much logging for outside of troubleshooting",
    "start": "1105929",
    "end": "1111859"
  },
  {
    "text": "another good one that happens is when you when you load test or you run a long-running test you you might discover",
    "start": "1111859",
    "end": "1118259"
  },
  {
    "text": "a memory leak so in this case we had in the Zipkin library there was it was",
    "start": "1118259",
    "end": "1124139"
  },
  {
    "text": "spawning goroutines unbounded number of collisions and yet all accessing a",
    "start": "1124139",
    "end": "1129690"
  },
  {
    "text": "single lock to try to extract that out of that lock so it was was basically",
    "start": "1129690",
    "end": "1135690"
  },
  {
    "text": "consuming memory by consuming goroutines thanks to the the right patch hole that",
    "start": "1135690",
    "end": "1142379"
  },
  {
    "text": "Sarah is going to talk about we found that at one release we actually were",
    "start": "1142379",
    "end": "1148080"
  },
  {
    "text": "doing twice the number of mixer calls there was a mix up in the and void configuration of the filter and there",
    "start": "1148080",
    "end": "1154350"
  },
  {
    "text": "was two entries for for the mixer filters we were doing twice as many calls which obviously doesn't improve",
    "start": "1154350",
    "end": "1160950"
  },
  {
    "text": "the throughput we also doing work at lower levels so in our team there's",
    "start": "1160950",
    "end": "1167549"
  },
  {
    "text": "people working on and voi at the lower level like in the TLS libraries and we",
    "start": "1167549",
    "end": "1174059"
  },
  {
    "text": "made a fair bit of improvement in the end Ling of of TLS",
    "start": "1174059",
    "end": "1179440"
  },
  {
    "text": "likewise for TCP and alpha closed issues that were causing both functional and",
    "start": "1179440",
    "end": "1185290"
  },
  {
    "text": "performance problems if you recall I mentioned we do have that cache busting",
    "start": "1185290",
    "end": "1191080"
  },
  {
    "text": "rule right the way that cache busting rule is you can check it on on github is it doesn't end between something that's",
    "start": "1191080",
    "end": "1198190"
  },
  {
    "text": "either always true or always false and then evaluates something that reads from",
    "start": "1198190",
    "end": "1204400"
  },
  {
    "text": "the request ID which is always different so cannot be cached well there was a",
    "start": "1204400",
    "end": "1209470"
  },
  {
    "text": "release where the the short-circuiting wasn't actually working so the zero-percent cache and 100% cache were",
    "start": "1209470",
    "end": "1217150"
  },
  {
    "text": "actually always the zero percent caching so we found that and we fixed it there",
    "start": "1217150",
    "end": "1223090"
  },
  {
    "text": "was another issue at some point the source IP address was part of the cache key so obviously when you're on an",
    "start": "1223090",
    "end": "1229450"
  },
  {
    "text": "ingress if you put the source IP as part of the cache key you're not gonna get a",
    "start": "1229450",
    "end": "1234570"
  },
  {
    "text": "very good performance so we look we look",
    "start": "1234570",
    "end": "1239650"
  },
  {
    "text": "at performance we will also look at scalability right so when you add a hundreds of services you have to make",
    "start": "1239650",
    "end": "1245980"
  },
  {
    "text": "sure that pilot and mixer and each company is - you can handle that scam and there was a bit of a problem with",
    "start": "1245980",
    "end": "1253660"
  },
  {
    "text": "our we we're using the the API server go-go client library and we ended up",
    "start": "1253660",
    "end": "1262800"
  },
  {
    "text": "crashing pilot fairly early with excessive memory so that was also fixed",
    "start": "1262800",
    "end": "1268500"
  },
  {
    "text": "so these two items that were still working on can see my password",
    "start": "1268500",
    "end": "1279920"
  },
  {
    "text": "[Applause] okay so so these two items that we're",
    "start": "1279920",
    "end": "1286500"
  },
  {
    "text": "still working on I'll talk a bit about the last one because it's a low-hanging fruit right the cash the way the cash",
    "start": "1286500",
    "end": "1291990"
  },
  {
    "text": "works today is that it's going to cash the mixer result for up to 100 requests",
    "start": "1291990",
    "end": "1297690"
  },
  {
    "text": "or one second and this is just what happens what we have decided like a year",
    "start": "1297690",
    "end": "1303720"
  },
  {
    "text": "ago we just put that value as the default value and we haven't really looked at it until recently obviously",
    "start": "1303720",
    "end": "1309059"
  },
  {
    "text": "it's a bit excessive because if you make a policy change that it that it applies",
    "start": "1309059",
    "end": "1314820"
  },
  {
    "text": "exactly within one second of your policy change or one hundred requests this is too much so we could easily put that to",
    "start": "1314820",
    "end": "1321450"
  },
  {
    "text": "be a thousand requests or or five second and and we would get a much better cash",
    "start": "1321450",
    "end": "1326580"
  },
  {
    "text": "it cash performance so we're going to make that change and make it configurable so you can change it to whichever you want and the other item",
    "start": "1326580",
    "end": "1334649"
  },
  {
    "text": "we're still working on is which we're trying to explain why the mixer client",
    "start": "1334649",
    "end": "1341730"
  },
  {
    "text": "performance doesn't seem to be what we expect because when we test with the internal mixer client in goal we get",
    "start": "1341730",
    "end": "1349559"
  },
  {
    "text": "much better performance than what we get end to end with the invoice so we're gonna fix that too so in summary what we",
    "start": "1349559",
    "end": "1360090"
  },
  {
    "start": "1357000",
    "end": "1493000"
  },
  {
    "text": "the work we've done over like the last three months we got the the p50 latency",
    "start": "1360090",
    "end": "1366500"
  },
  {
    "text": "down from 34 millisecond all the way down to 14 millisecond and we got the",
    "start": "1366500",
    "end": "1371879"
  },
  {
    "text": "QPS up from 700 to 1,700 on on a chip hardware like a 2g cpu machine so those",
    "start": "1371879",
    "end": "1381090"
  },
  {
    "text": "numbers are not the absolute numbers that we want to have right we want to have single millisecond overhead for",
    "start": "1381090",
    "end": "1387600"
  },
  {
    "text": "foresty oh but the trend is in the right direction and by end of here we're",
    "start": "1387600",
    "end": "1392929"
  },
  {
    "text": "committed to to work toward that do those better codes that's another",
    "start": "1392929",
    "end": "1400289"
  },
  {
    "text": "view of the improvements 0.4 is even older and that's that data and now I",
    "start": "1400289",
    "end": "1408269"
  },
  {
    "text": "will hand it to Surya thank you Thank You Lauren",
    "start": "1408269",
    "end": "1415190"
  },
  {
    "text": "as you can see as Laurent and for what mentioned from a community point of view",
    "start": "1415190",
    "end": "1422120"
  },
  {
    "text": "from a steel community point of view we had three goals we want to make sure that there is a regression mechanism",
    "start": "1422120",
    "end": "1430280"
  },
  {
    "text": "built in as we develop the service mesh and the second one is actually we want",
    "start": "1430280",
    "end": "1436280"
  },
  {
    "text": "to make sure not only the specific primitives so that you can go deep and",
    "start": "1436280",
    "end": "1441620"
  },
  {
    "text": "fix any design issues but also go in a like a breadthwise you want to go to the",
    "start": "1441620",
    "end": "1448159"
  },
  {
    "text": "multiple industry use cases and actually work right at the beginning itself to",
    "start": "1448159",
    "end": "1455169"
  },
  {
    "text": "understand and fix any kind of performance and scalability issues towards that as we have introduced the",
    "start": "1455169",
    "end": "1462260"
  },
  {
    "text": "regression patrol one of the benchmarks that we have used is called the AK near blueproof",
    "start": "1462260",
    "end": "1467750"
  },
  {
    "text": "it's actually open sourced so all of you can actually take take a look at that it",
    "start": "1467750",
    "end": "1473450"
  },
  {
    "text": "is basically a flight reservation system it has five or six specific micro",
    "start": "1473450",
    "end": "1480230"
  },
  {
    "text": "services so you can actually see that you know when you deploy this it's",
    "start": "1480230",
    "end": "1485720"
  },
  {
    "text": "actually being now run on IBM cloud but it's actually a steer that IO you can",
    "start": "1485720",
    "end": "1491630"
  },
  {
    "text": "actually go and see so what will happen is if I'm the mix of developer or the",
    "start": "1491630",
    "end": "1497179"
  },
  {
    "start": "1493000",
    "end": "1746000"
  },
  {
    "text": "pilot developer I go and you know just integrate my code changes and every",
    "start": "1497179",
    "end": "1503330"
  },
  {
    "text": "night there is this is do regression bucket it runs in the midnight and you",
    "start": "1503330",
    "end": "1510020"
  },
  {
    "text": "can actually see the results and then see it's actually color coded if you see a much bigger change in performance if",
    "start": "1510020",
    "end": "1517010"
  },
  {
    "text": "it breaches the threshold you can actually see that so what will happen once you see a regression right so you",
    "start": "1517010",
    "end": "1524960"
  },
  {
    "text": "can actually see this so people will come in interest of time actually we videoed it this one so they will go and",
    "start": "1524960",
    "end": "1531470"
  },
  {
    "text": "check it out okay what is the latest bill like we have three scenarios running so use to your full that is the",
    "start": "1531470",
    "end": "1537650"
  },
  {
    "text": "default configuration he'll go on check these are all automatically generated",
    "start": "1537650",
    "end": "1542659"
  },
  {
    "text": "data so they'll go and look at it whether pilot if I'm a pilot developer I'll go",
    "start": "1542659",
    "end": "1548650"
  },
  {
    "text": "on check out is there something that I have done wrong here that created the regression here we have an integrated",
    "start": "1548650",
    "end": "1555550"
  },
  {
    "text": "dashboard you can see the East EO and our own custom dashboards put together",
    "start": "1555550",
    "end": "1560740"
  },
  {
    "text": "and you can see in this the worker node all the metrics that you have whether",
    "start": "1560740",
    "end": "1567310"
  },
  {
    "text": "you have a disk issue or a io issue or you have any other specific issues that you know crept in that caused the",
    "start": "1567310",
    "end": "1574900"
  },
  {
    "text": "regression and you can actually look at the East your dashboard and then see whether you have any specific service",
    "start": "1574900",
    "end": "1581740"
  },
  {
    "text": "level problems that you have maybe you have a sidecar issue it's taking more CPU or memory you know all those things",
    "start": "1581740",
    "end": "1588280"
  },
  {
    "text": "that actually automate it and since we rolled out we identified many many",
    "start": "1588280",
    "end": "1595080"
  },
  {
    "text": "regressions and actually this is improving the quality of the sto service mesh itself as we are developing and I",
    "start": "1595080",
    "end": "1602710"
  },
  {
    "text": "would like to go and show you how the whole network traffic flows through this",
    "start": "1602710",
    "end": "1608560"
  },
  {
    "text": "is the one that's running on a three node cluster you can see this is the service mesh deployed on a cluster and",
    "start": "1608560",
    "end": "1614440"
  },
  {
    "text": "this is like without any load so you can see the pilot and the sidecar",
    "start": "1614440",
    "end": "1619480"
  },
  {
    "text": "interaction the packet that's going there network traffic and let me now",
    "start": "1619480",
    "end": "1624700"
  },
  {
    "text": "we're actually going to drive some load here from the from J mirror now once you",
    "start": "1624700",
    "end": "1630910"
  },
  {
    "text": "send the load from there that load the traffic will go the HTTP requests will",
    "start": "1630910",
    "end": "1636160"
  },
  {
    "text": "go through the east you ingress controller and you can actually see once the load kicks in you can see the",
    "start": "1636160",
    "end": "1642400"
  },
  {
    "text": "network flow how this whole traffic is actually going through and we can",
    "start": "1642400",
    "end": "1648460"
  },
  {
    "text": "identify any kind of bottlenecks in the whole system and you can see that traffic going through from the client in",
    "start": "1648460",
    "end": "1656260"
  },
  {
    "text": "Stephen Chris controller now it will go it will get into the flight service and",
    "start": "1656260",
    "end": "1661960"
  },
  {
    "text": "then yeah the flight service is the is the main service that takes most of these transactions and then it will get",
    "start": "1661960",
    "end": "1667960"
  },
  {
    "text": "into art service booking service and others too right you can so this is one way to clearly see whether you have any",
    "start": "1667960",
    "end": "1675400"
  },
  {
    "text": "kind of an issue the in the system and if you see some kind of a red dots that shows some kind",
    "start": "1675400",
    "end": "1682049"
  },
  {
    "text": "of an errors you can see the incoming connections and outgoing connections here how many transactions each of those",
    "start": "1682049",
    "end": "1689130"
  },
  {
    "text": "services are taking what's the throughput that you're getting what is the latency all that can we clearly see",
    "start": "1689130",
    "end": "1696090"
  },
  {
    "text": "this will give a pretty good overview of you know how is tio is performing and",
    "start": "1696090",
    "end": "1701520"
  },
  {
    "text": "scaling in a realistic customer application as you can see there are",
    "start": "1701520",
    "end": "1707250"
  },
  {
    "text": "config a config GU the way we develop this is actually we have a default configuration we look at and then we",
    "start": "1707250",
    "end": "1713640"
  },
  {
    "text": "disable the mixer we disable all the other components and then look at the performance of the East you ingress",
    "start": "1713640",
    "end": "1718740"
  },
  {
    "text": "controller right just we want to make sure that which component is actually",
    "start": "1718740",
    "end": "1723900"
  },
  {
    "text": "having issues and what are the different",
    "start": "1723900",
    "end": "1730830"
  },
  {
    "text": "industry use cases that we are using right you can see this is the polyglot micro service each service is developed",
    "start": "1730830",
    "end": "1737280"
  },
  {
    "text": "in a different language one in Java spring boat go and you know you can see",
    "start": "1737280",
    "end": "1743940"
  },
  {
    "text": "that in node right so it's available it's an open source you can actually go",
    "start": "1743940",
    "end": "1749970"
  },
  {
    "start": "1746000",
    "end": "1823000"
  },
  {
    "text": "and take a look at a blooper and another thing that because this tio there's a lot of interest from the community from",
    "start": "1749970",
    "end": "1756750"
  },
  {
    "text": "the industry we want to make sure that the real customer use cases are being",
    "start": "1756750",
    "end": "1762809"
  },
  {
    "text": "looked at as we are developing this framework one of them is the online",
    "start": "1762809",
    "end": "1768620"
  },
  {
    "text": "retail online banking application we have enabled sto with that this is the",
    "start": "1768620",
    "end": "1774390"
  },
  {
    "text": "application that's actually in production in one of the North American banks we have what we have done with",
    "start": "1774390",
    "end": "1780990"
  },
  {
    "text": "this is actually we have applied sto service mesh and we drove this to almost",
    "start": "1780990",
    "end": "1786890"
  },
  {
    "text": "4.5 billion API calls per day we want to really push that to to its limits that's",
    "start": "1786890",
    "end": "1794669"
  },
  {
    "text": "without is to you we could reach 4.5 billion but we want to understand what",
    "start": "1794669",
    "end": "1800159"
  },
  {
    "text": "is the additional capacity that you need what is the additional overhead you have to pay when you enable issed you right",
    "start": "1800159",
    "end": "1806820"
  },
  {
    "text": "those are the things that we are looking at another in the Street benchmark that we are looking at",
    "start": "1806820",
    "end": "1812089"
  },
  {
    "text": "is in the healthcare industry that is the the typical back-end for front-end",
    "start": "1812089",
    "end": "1818369"
  },
  {
    "text": "micro-services pattern is another thing that we are actually looking at for is tio so this",
    "start": "1818369",
    "end": "1825479"
  },
  {
    "start": "1823000",
    "end": "1862000"
  },
  {
    "text": "is the online banking application so you can see with and without sto what is",
    "start": "1825479",
    "end": "1831329"
  },
  {
    "text": "that additional overhead right now you can see is around 56% so you need",
    "start": "1831329",
    "end": "1837149"
  },
  {
    "text": "another 50% additional capacity to get the same kind of throughput as a",
    "start": "1837149",
    "end": "1842639"
  },
  {
    "text": "community we are trying to as a working group we are working hard as Lauren",
    "start": "1842639",
    "end": "1847649"
  },
  {
    "text": "mentioned we have a pipeline of things to optimize one of the main things that",
    "start": "1847649",
    "end": "1853169"
  },
  {
    "text": "we are trying to look at is the mixer overhead but right now you can see a",
    "start": "1853169",
    "end": "1858509"
  },
  {
    "text": "typical industrial use case you need this is the distribution without this do",
    "start": "1858509",
    "end": "1865559"
  },
  {
    "start": "1862000",
    "end": "1916000"
  },
  {
    "text": "if you distribute where you're actually spending the resources to get that 158",
    "start": "1865559",
    "end": "1871889"
  },
  {
    "text": "million API calls per day at around 3:30 millisecond response time you can see",
    "start": "1871889",
    "end": "1877979"
  },
  {
    "text": "the the olb Orchestrator is taking around 150 percent and stub is doing 120",
    "start": "1877979",
    "end": "1886349"
  },
  {
    "text": "and ingress is taking 65% so what will happen if you apply is to your service mesh you can see this you are paying",
    "start": "1886349",
    "end": "1896789"
  },
  {
    "text": "almost like two hundred eighty percent with these to your mixer is teo ingress",
    "start": "1896789",
    "end": "1902219"
  },
  {
    "text": "is a one hundred and forty percent so you can see why this additional overhead",
    "start": "1902219",
    "end": "1909049"
  },
  {
    "text": "right now the main focus is on the mixer we are working on that at this point so",
    "start": "1909049",
    "end": "1917539"
  },
  {
    "start": "1916000",
    "end": "1954000"
  },
  {
    "text": "another area is because sto if you see there is a sidecar pattern so you have",
    "start": "1917539",
    "end": "1924899"
  },
  {
    "text": "for each service you have a proxy that on by proxy attached to it so our as",
    "start": "1924899",
    "end": "1932759"
  },
  {
    "text": "part of our analysis we are also looking at what is the impact of the sidecar",
    "start": "1932759",
    "end": "1938419"
  },
  {
    "text": "what is the impact when you have an egress traffic that's going out to a public",
    "start": "1938419",
    "end": "1944010"
  },
  {
    "text": "versus the same traffic going to an on-premise service there is a big difference in both of those two so all",
    "start": "1944010",
    "end": "1951750"
  },
  {
    "text": "those things actually we are working in the community and one of the other",
    "start": "1951750",
    "end": "1957990"
  },
  {
    "start": "1954000",
    "end": "2070000"
  },
  {
    "text": "things that we really want help from you is as we are continuing to optimize the",
    "start": "1957990",
    "end": "1965549"
  },
  {
    "text": "sole service mesh we really need your help because as you have seen we have lots",
    "start": "1965549",
    "end": "1972090"
  },
  {
    "text": "and lots of new optimizations and new workloads and of course we are covering",
    "start": "1972090",
    "end": "1979410"
  },
  {
    "text": "multiple clouds like AWS - IBM cloud Google cloud razor so we would like your",
    "start": "1979410",
    "end": "1986520"
  },
  {
    "text": "help to expand and broaden that as well and be a participant for this workgroup",
    "start": "1986520",
    "end": "1992820"
  },
  {
    "text": "and we also have and need some help from",
    "start": "1992820",
    "end": "1998100"
  },
  {
    "text": "the contributions from the 40s ID and our goal here the things that we are",
    "start": "1998100",
    "end": "2004520"
  },
  {
    "text": "working right now as I mentioned the regression Patrol right now daily it runs so our goal is we are trying to",
    "start": "2004520",
    "end": "2011710"
  },
  {
    "text": "build a kind of a bot as well so that automatically if you find a specific",
    "start": "2011710",
    "end": "2017960"
  },
  {
    "text": "issue it can actually log the issue and send a you know like a slack message to",
    "start": "2017960",
    "end": "2024799"
  },
  {
    "text": "a specific channel maybe for pilot or mixer so those are the things in the works right now so we need your help in",
    "start": "2024799",
    "end": "2032059"
  },
  {
    "text": "continuing to push this and optimize our final goal here is to reduce the",
    "start": "2032059",
    "end": "2038179"
  },
  {
    "text": "additional overhead less than 10% so with that any questions you have to come",
    "start": "2038179",
    "end": "2049460"
  },
  {
    "text": "to the mics in in the middle if you have a question if you can",
    "start": "2049460",
    "end": "2055480"
  },
  {
    "text": "come on the question",
    "start": "2057000",
    "end": "2059990"
  },
  {
    "text": "thank you [Applause]",
    "start": "2066099",
    "end": "2071888"
  }
]
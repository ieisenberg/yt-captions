[
  {
    "text": "all right good afternoon folks my name is Sri coochie Butler and I'm a",
    "start": "30",
    "end": "5580"
  },
  {
    "text": "developer in the gr PC team so today I'm gonna talk about the C core architecture",
    "start": "5580",
    "end": "12660"
  },
  {
    "text": "and also the life of gnar PC so I must warn you that I have a lot of slides I'll try to go through them as quickly",
    "start": "12660",
    "end": "19590"
  },
  {
    "text": "as possible and try to leave some time in the end for Q&A all right so who is",
    "start": "19590",
    "end": "25410"
  },
  {
    "text": "the target audience for this talk so this talk is primarily aimed at like",
    "start": "25410",
    "end": "31470"
  },
  {
    "text": "power users of their PC you know someone who uses their PC in their application",
    "start": "31470",
    "end": "38160"
  },
  {
    "text": "who may have had to debug any issues who may have had to look at some of the GRP",
    "start": "38160",
    "end": "43770"
  },
  {
    "text": "see traces in the process hopefully this talk will help you like understand at least the big picture right anyone is a",
    "start": "43770",
    "end": "52649"
  },
  {
    "text": "contributing or thinking of contributing they might find the talk useful or anyone just curious like about er PC",
    "start": "52649",
    "end": "59309"
  },
  {
    "text": "architecture just just understand what's going on so all right",
    "start": "59309",
    "end": "65420"
  },
  {
    "text": "so gr PC is implemented I mean gr PC has idiomatic API s-- in over nine languages",
    "start": "65420",
    "end": "73590"
  },
  {
    "text": "actually excluded a few but over nine languages and it has three it is",
    "start": "73590",
    "end": "79619"
  },
  {
    "text": "natively implemented in three languages Java go and see all the other languages",
    "start": "79619",
    "end": "85979"
  },
  {
    "text": "are wrapped around the C implementation so my talk is primarily going to focus",
    "start": "85979",
    "end": "91290"
  },
  {
    "text": "on the C core architecture I'm just going to refer it to a seek or from this",
    "start": "91290",
    "end": "97140"
  },
  {
    "text": "point forward so yeah before diving into the details",
    "start": "97140",
    "end": "103820"
  },
  {
    "text": "it helps to sort of set some context on most of you may already know this but",
    "start": "103820",
    "end": "108960"
  },
  {
    "text": "what are some of the key features and this is primarily these are some what some of these are core specific so its",
    "start": "108960",
    "end": "117180"
  },
  {
    "text": "payload diagnostic G RPC code does not know anything about the payload doesn't know about the serialization format",
    "start": "117180",
    "end": "122969"
  },
  {
    "text": "whether it's wrote above flat buff it doesn't know that that features are",
    "start": "122969",
    "end": "128039"
  },
  {
    "text": "implemented in the in the rap language layer and then",
    "start": "128039",
    "end": "134040"
  },
  {
    "text": "it has extensible architecture that the actual functionality of course stack is very lean most of the value-add",
    "start": "134040",
    "end": "140220"
  },
  {
    "text": "functionalities come from what we call filters we'll see later in the in the",
    "start": "140220",
    "end": "145650"
  },
  {
    "text": "presentation so filters provide a lot of value at constant is like authentication tracing service discovery a bunch of",
    "start": "145650",
    "end": "153750"
  },
  {
    "text": "other stuff I even deadlines is implemented as a filter G RPC works with many transports",
    "start": "153750",
    "end": "161670"
  },
  {
    "text": "the way by default it uses HTTP - it will turn HTTP - but it can use other",
    "start": "161670",
    "end": "169620"
  },
  {
    "text": "transports we have implementations running in production using other transports like CRO net or quick which",
    "start": "169620",
    "end": "175769"
  },
  {
    "text": "is udp-based and a few more it is the API of Corin most of the",
    "start": "175769",
    "end": "183030"
  },
  {
    "text": "architecture is designed by keeping performance in mind there's a lot of optimizations we do lot of design",
    "start": "183030",
    "end": "188160"
  },
  {
    "text": "choices that's probably a different talk so I won't be really getting into that aspect in this talk okay so now let's",
    "start": "188160",
    "end": "197930"
  },
  {
    "text": "with that let's sort of look at the architecture of course so core is",
    "start": "197930",
    "end": "203000"
  },
  {
    "text": "divided into three layers the topmost layer is aptly named the surface layer",
    "start": "203000",
    "end": "208579"
  },
  {
    "text": "which itself is divided into two parts one part is the API layer which you know",
    "start": "208579",
    "end": "216420"
  },
  {
    "text": "provides the C core API and below API layer sits the filter stack those are",
    "start": "216420",
    "end": "221489"
  },
  {
    "text": "the ones that provide all the extensions I talked about so again just to remind",
    "start": "221489",
    "end": "227609"
  },
  {
    "text": "you applications do not we do not encourage applications to directly call or talk the C core API they typically",
    "start": "227609",
    "end": "235200"
  },
  {
    "text": "use the wrapped language api's and the consumers of this of the wrapped language ApS so I just wanted to make it",
    "start": "235200",
    "end": "241590"
  },
  {
    "text": "clear and the second is the transport",
    "start": "241590",
    "end": "246739"
  },
  {
    "text": "transport implements the wire protocol and by default it's HTTP - but you can",
    "start": "246739",
    "end": "253709"
  },
  {
    "text": "use other transports as well and at the bottom layer you have the IO manager that provides low level networking i/o",
    "start": "253709",
    "end": "260519"
  },
  {
    "text": "functions network utilities timers and a bunch of primitives that are sort of",
    "start": "260519",
    "end": "266190"
  },
  {
    "text": "platform specific most of the company see I tend to be platform-specific we support multiple platforms",
    "start": "266190",
    "end": "271790"
  },
  {
    "text": "there's windows-based implementation there is POSIX based and like multiple versions depending on the specific",
    "start": "271790",
    "end": "279870"
  },
  {
    "text": "kernel you're using some of not all kernels have all features so there's a lot of platform-specific code in at this",
    "start": "279870",
    "end": "285270"
  },
  {
    "text": "layer okay so again before diving into the life of",
    "start": "285270",
    "end": "290760"
  },
  {
    "text": "an RPC I just wanted to take a couple of slides to talk about some of the the",
    "start": "290760",
    "end": "297780"
  },
  {
    "text": "common terminology or the class of objects that we very commonly use use in",
    "start": "297780",
    "end": "302850"
  },
  {
    "text": "core right I mean it's and also - it helps to understand the relation between this so so let's start with the channel",
    "start": "302850",
    "end": "312540"
  },
  {
    "text": "a channel is a communication pipe between a client and a target and I'm",
    "start": "312540",
    "end": "319010"
  },
  {
    "text": "deliberately not using the term connection to describe a channel and we'll get into it later so channel is a",
    "start": "319010",
    "end": "326460"
  },
  {
    "text": "communication pipe between a client and a target a call is bound to a channel the relation between a call and the",
    "start": "326460",
    "end": "333000"
  },
  {
    "text": "channel is many-to-one so that means we can have multiple calls on the same channel and then you have a",
    "start": "333000",
    "end": "340860"
  },
  {
    "text": "bunch of operations that could be performed on a call I will talk about it",
    "start": "340860",
    "end": "347550"
  },
  {
    "text": "in the next slide so really core when you are talking at the core API all",
    "start": "347550",
    "end": "353460"
  },
  {
    "text": "you're really doing is these operations on a call the so-called unary RPC and",
    "start": "353460",
    "end": "358470"
  },
  {
    "text": "the streaming RPC abstractions that the higher wrap languages provide are really composed of these low-level operations",
    "start": "358470",
    "end": "367130"
  },
  {
    "text": "we'll look at that a little and these operations are done in batches so batch",
    "start": "367130",
    "end": "372900"
  },
  {
    "text": "is an important concept a batch can contain operations yeah batch can",
    "start": "372900",
    "end": "380400"
  },
  {
    "text": "contain one or more operations and then finally the most important concept here",
    "start": "380400",
    "end": "385950"
  },
  {
    "text": "is this notion of a completion queue so when you start a batch of operations you",
    "start": "385950",
    "end": "391350"
  },
  {
    "text": "wait the completion of the batch is notified on what we call a completion queue so typically clients since I was",
    "start": "391350",
    "end": "400050"
  },
  {
    "text": "interacting with interacting with core you know the semantics are something like they start",
    "start": "400050",
    "end": "405990"
  },
  {
    "text": "a batch of operations and then they wait they pull the completion queue to see if the batch completed and the core is the",
    "start": "405990",
    "end": "412380"
  },
  {
    "text": "one that posts the completion to the completion key so that's typically the semantics like all the APS are",
    "start": "412380",
    "end": "418530"
  },
  {
    "text": "essentially if you look at it they follow that pattern so just sort of",
    "start": "418530",
    "end": "425340"
  },
  {
    "text": "trying to bring it together so those are the ops that we support I'm not going to",
    "start": "425340",
    "end": "432150"
  },
  {
    "text": "read them out loud but the interesting thing there is just wanted to highlight that you know the message the messages",
    "start": "432150",
    "end": "438419"
  },
  {
    "text": "that are exchanged between client and server pretty similar the client always",
    "start": "438419",
    "end": "443940"
  },
  {
    "text": "starts by sending the initial metadata followed by zero or more messages followed by failing metadata and server",
    "start": "443940",
    "end": "451889"
  },
  {
    "text": "does the same in case of unary or pcs there's exactly one message that's sent",
    "start": "451889",
    "end": "457610"
  },
  {
    "text": "from the client which is essentially the parameters initial metadata from client",
    "start": "457610",
    "end": "463289"
  },
  {
    "text": "to server in a unit in all our pcs essentially contains stuff like the method name encoding type or any other",
    "start": "463289",
    "end": "470639"
  },
  {
    "text": "custom metadata we expose api's for applications to send their own custom metadata tailing metadata from client to",
    "start": "470639",
    "end": "477150"
  },
  {
    "text": "server is just end of stream indicator server to client initial metadata against has the same encoding type if",
    "start": "477150",
    "end": "485310"
  },
  {
    "text": "it's a if it's a unary RPC the message contains the return value from the",
    "start": "485310",
    "end": "490409"
  },
  {
    "text": "server trailing metadata contains the status whether the RPC the error code if that PC failed all right so I think we",
    "start": "490409",
    "end": "501810"
  },
  {
    "text": "are ready to dive deep into life up an RPC so it starts with a channel creation",
    "start": "501810",
    "end": "507590"
  },
  {
    "text": "and I'm dividing this into two phases so first part I focus on the channel",
    "start": "507590",
    "end": "512789"
  },
  {
    "text": "creation workflow and the second part I'll focus on call creation and the life of a caller on over this channel so",
    "start": "512789",
    "end": "522150"
  },
  {
    "text": "again so that's the client as I mentioned before completion queue is a very important construct so the client",
    "start": "522150",
    "end": "529230"
  },
  {
    "text": "starts by creating a completion to you and then a thread",
    "start": "529230",
    "end": "535190"
  },
  {
    "text": "waits on the completion view for events as much as it can right we always that's",
    "start": "535190",
    "end": "540290"
  },
  {
    "text": "that's a contract we expect from the users of the consumers of gr PC core so",
    "start": "540290",
    "end": "547630"
  },
  {
    "text": "the client rate the completion queue client then calls an API to create a",
    "start": "547630",
    "end": "553730"
  },
  {
    "text": "channel and passes the server's URI and that creates sort of a filter stack specific to that specific to that",
    "start": "553730",
    "end": "562089"
  },
  {
    "text": "channel that is in creation so there are a bunch of filters but the interesting",
    "start": "562089",
    "end": "567110"
  },
  {
    "text": "filter there is the client channel filter that's the one that sort of orchestrates the service discovery and",
    "start": "567110",
    "end": "572149"
  },
  {
    "text": "load balancing part so the client channel then calls the resolver resolver",
    "start": "572149",
    "end": "581449"
  },
  {
    "text": "is resolver is pluggable there are multiple resolves that we support and",
    "start": "581449",
    "end": "587180"
  },
  {
    "text": "then the resolve returns your list of addresses that the URI resolves to so",
    "start": "587180",
    "end": "593269"
  },
  {
    "text": "you are a solute server you are I might actually resolve to multiple backends so",
    "start": "593269",
    "end": "598910"
  },
  {
    "text": "I might I might be referring to the term backends and addresses interchangeably but essentially when I said back-end",
    "start": "598910",
    "end": "604880"
  },
  {
    "text": "it's one of the bases that there is all were resolved so okay so the resolver is",
    "start": "604880",
    "end": "611600"
  },
  {
    "text": "returned a bunch of addresses and I listed the the resolvers that we that",
    "start": "611600",
    "end": "617689"
  },
  {
    "text": "are that the GPC open source version has all right and then the client channel",
    "start": "617689",
    "end": "625699"
  },
  {
    "text": "filter then creates an LP policy that's associated with that channel and keep in",
    "start": "625699",
    "end": "630740"
  },
  {
    "text": "mind that this is this is a client Channel load balancing",
    "start": "630740",
    "end": "637220"
  },
  {
    "text": "I think we had a talk yesterday by yarn that talked about load balancing and so",
    "start": "637220",
    "end": "642620"
  },
  {
    "text": "this is the client channel load balancing so then the client channel",
    "start": "642620",
    "end": "648290"
  },
  {
    "text": "filter then like initiates connections to all the addresses all the backends",
    "start": "648290",
    "end": "653829"
  },
  {
    "text": "returned by the resolver",
    "start": "653829",
    "end": "657519"
  },
  {
    "text": "so yeah here basically we see connect request being sent to every backin at",
    "start": "660110",
    "end": "667829"
  },
  {
    "text": "this point I should mention that this process is typically done in a lazy fashion like when you create a channel",
    "start": "667829",
    "end": "673670"
  },
  {
    "text": "it doesn't always immediately do that we wait until the very first call is",
    "start": "673670",
    "end": "679259"
  },
  {
    "text": "created on the channel but for illustration purposes I'm just showing it here so anyway so we declined issues",
    "start": "679259",
    "end": "687299"
  },
  {
    "text": "connect to all the back ends and just let's look at one of the one of the back ends what happens when one of the",
    "start": "687299",
    "end": "693660"
  },
  {
    "text": "backups so the server our manager receives",
    "start": "693660",
    "end": "699110"
  },
  {
    "text": "receives the connection accepts the connection so that acts back to the client it also notifies the surface that a",
    "start": "699110",
    "end": "705809"
  },
  {
    "text": "there is an incoming incoming channel so server creates a channel object thereby",
    "start": "705809",
    "end": "711569"
  },
  {
    "text": "initializes the filter stack on the server it's pretty similar to the client side except if you filters that our client specific like line channel and at",
    "start": "711569",
    "end": "719160"
  },
  {
    "text": "this point the server is done server has done it's part of general creation now the client gets like server has sent the",
    "start": "719160",
    "end": "726899"
  },
  {
    "text": "accept my face so line gets the act clients IO manager tells the channel filter that yeah one of your backends",
    "start": "726899",
    "end": "733470"
  },
  {
    "text": "accepted the client channel filter then creates what we call a sub channel so",
    "start": "733470",
    "end": "739769"
  },
  {
    "text": "this is something that I didn't introduce before so so creates what we call a sub channel to the particular",
    "start": "739769",
    "end": "747239"
  },
  {
    "text": "back-end and each sub channel comes with its own set of stack SEC of filters and",
    "start": "747239",
    "end": "754790"
  },
  {
    "text": "that's it once it creates a sub channel now you have a sub channel that is",
    "start": "754790",
    "end": "759839"
  },
  {
    "text": "established in the meantime the other beckons also might have responded so",
    "start": "759839",
    "end": "765660"
  },
  {
    "text": "that results in sub channels being created for the other backends and in the end you end up with what I just",
    "start": "765660",
    "end": "771329"
  },
  {
    "text": "showed here so you have a bunch of sub channels each connecting to one of the backends and so the one thing I wanted",
    "start": "771329",
    "end": "778019"
  },
  {
    "text": "to highlight is so really all these sub channels are part of a channel so channel is really a collection of sub",
    "start": "778019",
    "end": "783509"
  },
  {
    "text": "channels and the sub Channel is the one that maps to a connection",
    "start": "783509",
    "end": "789319"
  },
  {
    "text": "all right now let's move on to a life of",
    "start": "790199",
    "end": "796959"
  },
  {
    "text": "a call just to keep like just to keep things simple I will talk about unit",
    "start": "796959",
    "end": "803110"
  },
  {
    "text": "unity calls here but streaming calls should be very similar like it's really the difference is just based on the",
    "start": "803110",
    "end": "809529"
  },
  {
    "text": "number of messages being transmitted back from client back and forth between client and server so let's pick up from",
    "start": "809529",
    "end": "816850"
  },
  {
    "text": "where we left after we were at this stage we know where client create the",
    "start": "816850",
    "end": "822939"
  },
  {
    "text": "channel it ended up with a bunch of sub channels and I'm showing one of the one",
    "start": "822939",
    "end": "828399"
  },
  {
    "text": "such sub channel one such back in now",
    "start": "828399",
    "end": "836170"
  },
  {
    "text": "client applications call it API to create a call I saw that we had some in memory for a call object keep in mind",
    "start": "836170",
    "end": "844509"
  },
  {
    "text": "that at this point this call is not bound to any of the sub channels we know that the call is bound to a channel we",
    "start": "844509",
    "end": "851739"
  },
  {
    "text": "are creating a call over the channel but it's not bound to a sub channel so that happens only when some operations are",
    "start": "851739",
    "end": "859299"
  },
  {
    "text": "started on the call right so client starts a batch of operation so it's a",
    "start": "859299",
    "end": "865720"
  },
  {
    "text": "unary call so it has to start a batch of operations I'll talk about the batch of operations in the next slide but I just",
    "start": "865720",
    "end": "870970"
  },
  {
    "text": "wanted to show what happens when a batch is started so since it's a first batch",
    "start": "870970",
    "end": "877170"
  },
  {
    "text": "depending on the LP lb policy attached to the channel one of the channels is picked so when I previously mentioned",
    "start": "877170",
    "end": "885819"
  },
  {
    "text": "about lb policy I forgot to mention what kind of plain side lb policies we support so we support 3G RPC supports 3",
    "start": "885819",
    "end": "893999"
  },
  {
    "text": "lb policies well so one is pick first that's the default so we just picks the",
    "start": "893999",
    "end": "899799"
  },
  {
    "text": "first sub Channel other one is round-robin so it just keeps round-robin in over the sub channels and the third",
    "start": "899799",
    "end": "905529"
  },
  {
    "text": "one is what's called gr PCL B which is the Lucas ID load balancing so I have",
    "start": "905529",
    "end": "913989"
  },
  {
    "text": "linked in the slide that talks about a load balancing so anyway so let's assume",
    "start": "913989",
    "end": "920410"
  },
  {
    "text": "this is the sub channel that was pick whatever might be there'll be policy but this is the subchannel that respect now",
    "start": "920410",
    "end": "928330"
  },
  {
    "text": "from this point forward let's sort of simplify diagrams so I'm only including",
    "start": "928330",
    "end": "933790"
  },
  {
    "text": "the the components that are important so we have a call there's a subchannel client and server and completion queues",
    "start": "933790",
    "end": "939910"
  },
  {
    "text": "on either side so yeah where we left off as client started a batch of operations",
    "start": "939910",
    "end": "945580"
  },
  {
    "text": "and so since it's a unary call klein",
    "start": "945580",
    "end": "950590"
  },
  {
    "text": "just starts a batch with all the possible ops right why did it start a",
    "start": "950590",
    "end": "955690"
  },
  {
    "text": "batch with all the ops why not split send and receive into two different batches it could but there's",
    "start": "955690",
    "end": "962920"
  },
  {
    "text": "really no need as we will see because it's a unit unary call can just send all",
    "start": "962920",
    "end": "968260"
  },
  {
    "text": "the operations in one batch so the client starts like once the client",
    "start": "968260",
    "end": "975990"
  },
  {
    "text": "starts the batch initial metadata is sent followed by the message followed by",
    "start": "975990",
    "end": "982840"
  },
  {
    "text": "the trailing metadata and now so three",
    "start": "982840",
    "end": "988240"
  },
  {
    "text": "three of the steps in the operations in the batch are done but the batch is not complete yet because there are three more the client is just waiting for",
    "start": "988240",
    "end": "994780"
  },
  {
    "text": "those two when I said waiting it's pulling the completion queue it knows that once the batch is completed the",
    "start": "994780",
    "end": "1000840"
  },
  {
    "text": "result will be post on the completion queue so it's just wait the client is the expectation is that the client will",
    "start": "1000840",
    "end": "1007230"
  },
  {
    "text": "be polling the completion key for the result so now at the server server sees",
    "start": "1007230",
    "end": "1013260"
  },
  {
    "text": "the initial metadata so much more specific to be more specific it's the i/o manager side of the server that sees",
    "start": "1013260",
    "end": "1019650"
  },
  {
    "text": "the initial metadata reads off a few bytes passes it to transport transport",
    "start": "1019650",
    "end": "1025079"
  },
  {
    "text": "passes it realizes it it's in initial metadata and then notifies the surface that you have an incoming call so then",
    "start": "1025079",
    "end": "1031640"
  },
  {
    "text": "surface on the server realizes that okay there is an incoming call so what do I",
    "start": "1031640",
    "end": "1036720"
  },
  {
    "text": "need and it note it notes based on the method name it knows that it's a unary call and then it says okay let me start",
    "start": "1036720",
    "end": "1043980"
  },
  {
    "text": "a batch I know that the client is sending message and trailing metadata so let me start a batch to read to receive",
    "start": "1043980",
    "end": "1051300"
  },
  {
    "text": "initial metadata receive message and receive tailing metadata right so it starts a batch and that since since all the messages",
    "start": "1051300",
    "end": "1060330"
  },
  {
    "text": "are already on the way this bath completes typically very quickly so once the batch completes a notification is",
    "start": "1060330",
    "end": "1065580"
  },
  {
    "text": "sent on the completion queue the thread picks it up now calls your higher level",
    "start": "1065580",
    "end": "1072120"
  },
  {
    "text": "higher layer application handler so this is this is your RPC implementation like",
    "start": "1072120",
    "end": "1077190"
  },
  {
    "text": "this is your unity RPC implementation that is called so that one thing I didn't show here is client calls the",
    "start": "1077190",
    "end": "1084270"
  },
  {
    "text": "wrap language which deserialized it and then call your handler and then your",
    "start": "1084270",
    "end": "1090450"
  },
  {
    "text": "handler the application handler performs the operation writes the result back",
    "start": "1090450",
    "end": "1097010"
  },
  {
    "text": "that essentially results in another batch of operations right so it is sending its initial metadata it is",
    "start": "1097010",
    "end": "1105210"
  },
  {
    "text": "sending a message that contains the response of the unary code and trailing metadata that contains any error code",
    "start": "1105210",
    "end": "1110240"
  },
  {
    "text": "and once that batch is complete the",
    "start": "1110240",
    "end": "1116490"
  },
  {
    "text": "server is pretty much done with with with the call the call is complete on",
    "start": "1116490",
    "end": "1122040"
  },
  {
    "text": "the server on the client so recall that client is waiting for the for a few ups",
    "start": "1122040",
    "end": "1130200"
  },
  {
    "text": "right so client now reads them reads the initial printer data reads the message",
    "start": "1130200",
    "end": "1135980"
  },
  {
    "text": "realizes that the batch is complete also a notification on the completion queue",
    "start": "1135980",
    "end": "1142140"
  },
  {
    "text": "and matches done on the client-side application thread picks up call is",
    "start": "1142140",
    "end": "1149580"
  },
  {
    "text": "complete on the client so this is unary",
    "start": "1149580",
    "end": "1155240"
  },
  {
    "text": "streaming is pretty similar like it's just that the number of operations in",
    "start": "1155240",
    "end": "1160650"
  },
  {
    "text": "the batch are different because a client initially the only difference is that client cannot in a unary call all the",
    "start": "1160650",
    "end": "1168360"
  },
  {
    "text": "batches all the operations were sent in one batch whereas in a swimming call",
    "start": "1168360",
    "end": "1174360"
  },
  {
    "text": "typically client sends initial metadata and then sends each message as a",
    "start": "1174360",
    "end": "1181049"
  },
  {
    "text": "separate batch because it doesn't know like how many messages might be sent",
    "start": "1181049",
    "end": "1186270"
  },
  {
    "text": "that that is a variable number so that's other than that the flow is pretty similar between client and server so",
    "start": "1186270",
    "end": "1193860"
  },
  {
    "text": "that's good I did better on time than I thought so we have 15 minutes for questions and so hopefully hopefully all",
    "start": "1193860",
    "end": "1202320"
  },
  {
    "text": "of you found there is something useful from it some takeaway I certainly did when preparing this I mostly work on the",
    "start": "1202320",
    "end": "1208860"
  },
  {
    "text": "i/o manager and transport components and I know enough to debug issues at the rest of the stack but not in not in this",
    "start": "1208860",
    "end": "1216510"
  },
  {
    "text": "much detail so I certainly learned and so it definitely I encourage you to",
    "start": "1216510",
    "end": "1222320"
  },
  {
    "text": "please contribute and these are some of the additional resources so cool so you",
    "start": "1222320",
    "end": "1230549"
  },
  {
    "text": "have about 15 minutes for Q&A so that's great",
    "start": "1230549",
    "end": "1235610"
  },
  {
    "text": "hi Thanks so from what I understood when when setting up the channel connection",
    "start": "1245430",
    "end": "1252120"
  },
  {
    "text": "there the actual network connection to the server is not set up at that point",
    "start": "1252120",
    "end": "1257650"
  },
  {
    "text": "so when I start a channel I've no knowledge if the server's are reachable or is there some kind of acknowledging",
    "start": "1257650",
    "end": "1264130"
  },
  {
    "text": "traffic correct by default that is the behavior you wouldn't know whether the server is reachable so you wouldn't know",
    "start": "1264130",
    "end": "1270910"
  },
  {
    "text": "until the first call is sent but there is a way I mean there is there are api's",
    "start": "1270910",
    "end": "1276670"
  },
  {
    "text": "if you really want to know if you want to be certain that you can let the server's are reachable there is an API",
    "start": "1276670",
    "end": "1282190"
  },
  {
    "text": "to force force the connection for any call it so I can check connection yes up",
    "start": "1282190",
    "end": "1287920"
  },
  {
    "text": "and running yes okay second question when the server sends back the response to the client is there any",
    "start": "1287920",
    "end": "1294880"
  },
  {
    "text": "acknowledgement to the server to the client received the traffic where the",
    "start": "1294880",
    "end": "1300220"
  },
  {
    "text": "server sends the response back could you repeat the question the server sends the messages back to",
    "start": "1300220",
    "end": "1305290"
  },
  {
    "text": "the client uh-huh the client receives does the server get any notification like TCP acknowledgement that is that",
    "start": "1305290",
    "end": "1311680"
  },
  {
    "text": "the client actually received all the data or is it not if they're not at the GRP sea level sure you'll have TCP level",
    "start": "1311680",
    "end": "1318640"
  },
  {
    "text": "X but not at the jail please okay okay I",
    "start": "1318640",
    "end": "1325560"
  },
  {
    "text": "can repeat the question",
    "start": "1325560",
    "end": "1329220"
  },
  {
    "text": "yeah I mean the trying to maintain wire",
    "start": "1344410",
    "end": "1349820"
  },
  {
    "text": "compatibility between what is fully backward-compatible we follow semantic",
    "start": "1349820",
    "end": "1357440"
  },
  {
    "text": "versioning so 1.0 will always in",
    "start": "1357440",
    "end": "1364430"
  },
  {
    "text": "streaming scenario since you have a completion thought and a lot of messages do you guarantee the sequence of the",
    "start": "1364430",
    "end": "1370850"
  },
  {
    "text": "messages yes we do messages on a stream are guaranteed to be retrieved so you have in the order yeah in the order they",
    "start": "1370850",
    "end": "1378710"
  },
  {
    "text": "were put on this put on the channel so you have a serial number for each yes yes",
    "start": "1378710",
    "end": "1385059"
  },
  {
    "text": "since for the presentation how do you deal with application error timeouts or",
    "start": "1395090",
    "end": "1400460"
  },
  {
    "text": "anything like that so there are many",
    "start": "1400460",
    "end": "1406160"
  },
  {
    "text": "ways so every you can set that deadline",
    "start": "1406160",
    "end": "1411500"
  },
  {
    "text": "on an RPC when you create an app you can set a deadline so if for whatever reason",
    "start": "1411500",
    "end": "1419500"
  },
  {
    "text": "your your RPC handler got stuck or taking forever",
    "start": "1419500",
    "end": "1424720"
  },
  {
    "text": "every RPC can has a deadline so RPC gets cancelled similarly you can also force",
    "start": "1424720",
    "end": "1431780"
  },
  {
    "text": "cancel an RPC both on client and server does that answer your question or were you",
    "start": "1431780",
    "end": "1438790"
  },
  {
    "text": "I think when you enable tracing in G RPC",
    "start": "1446860",
    "end": "1453039"
  },
  {
    "text": "does it add a filter in that block or it's handled by the language wrapper",
    "start": "1453039",
    "end": "1461610"
  },
  {
    "text": "like on the G RPC cool you can enable tracing and add some options in the GRP",
    "start": "1461789",
    "end": "1468010"
  },
  {
    "text": "Secor yeah those are those are just actually printf statements they're",
    "start": "1468010",
    "end": "1475539"
  },
  {
    "text": "logging to your studio they take the traces that you are talking about I'm not coming from a",
    "start": "1475539",
    "end": "1481870"
  },
  {
    "text": "filter oh yeah",
    "start": "1481870",
    "end": "1485130"
  },
  {
    "text": "thank you when you're running in a multi-threaded environment how much of these channels and such owns sure when",
    "start": "1491940",
    "end": "1500650"
  },
  {
    "text": "you're running in a workingman multi-threaded environment yeah multiple threats in your client",
    "start": "1500650",
    "end": "1508720"
  },
  {
    "text": "uh-huh oh how much of this is yeah um so",
    "start": "1508720",
    "end": "1514950"
  },
  {
    "text": "like there is like multiple cults can go on a channel right and there is no",
    "start": "1515790",
    "end": "1522090"
  },
  {
    "text": "channels are completely thread safe so you can like there's actually no",
    "start": "1522090",
    "end": "1527530"
  },
  {
    "text": "correlation multiple multiple threads can call API is to start a call on a channel it doesn't answer your question",
    "start": "1527530",
    "end": "1535420"
  },
  {
    "text": "or what oh yeah lower part so we do have some optimizations in the stack so let's say you created two channels to the same",
    "start": "1535420",
    "end": "1544780"
  },
  {
    "text": "target so let's say that's our URI resolves to only to two backends but you",
    "start": "1544780",
    "end": "1552760"
  },
  {
    "text": "created like ten channels because you wanted to paralyze in your application so you created ten channels to the same",
    "start": "1552760",
    "end": "1558100"
  },
  {
    "text": "you array they'll still use the same underlying sub channels right so we do",
    "start": "1558100",
    "end": "1565240"
  },
  {
    "text": "that so we there's no explosion of connections if we try to reuse the connections the underlined connection as much as we can which is something I",
    "start": "1565240",
    "end": "1572290"
  },
  {
    "text": "didn't talk about but so if you have two channels they still essentially use the",
    "start": "1572290",
    "end": "1578140"
  },
  {
    "text": "same sub Channel so there are some optimizations there",
    "start": "1578140",
    "end": "1583740"
  },
  {
    "text": "do you keep a full backlog of the messages in and the batch processing when a connection fails so you",
    "start": "1588710",
    "end": "1595100"
  },
  {
    "text": "automatically roll over to another sub channel or do you just if channel is disconnected for whatever",
    "start": "1595100",
    "end": "1603140"
  },
  {
    "text": "reason the call is cancelled there is recently retry support that was added so it will retry depending on the error you",
    "start": "1603140",
    "end": "1609500"
  },
  {
    "text": "got back if it's a retrial error we retry but the call is effectively canceled and it's up to the application",
    "start": "1609500",
    "end": "1614870"
  },
  {
    "text": "to initiate anyone so there's also this geo PC feature that you can annotate",
    "start": "1614870",
    "end": "1620690"
  },
  {
    "text": "your HTTP a1 API with options in the service ok and there's also Google Cloud",
    "start": "1620690",
    "end": "1628280"
  },
  {
    "text": "endpoints where you can do this this way over the llamo extra firearm is there like the open is this tool open-source",
    "start": "1628280",
    "end": "1634280"
  },
  {
    "text": "as well where you can do the channel llamo specification because I only found the inline option thing actually not",
    "start": "1634280",
    "end": "1641630"
  },
  {
    "text": "familiar with that the tools are open sourced in Google Cloud API is Google",
    "start": "1641630",
    "end": "1648980"
  },
  {
    "text": "API is a repository and they've been used mostly for our internal purposes",
    "start": "1648980",
    "end": "1654530"
  },
  {
    "text": "but they are open sourced and usable just not very friendly at times so you should be able to use but at your own",
    "start": "1654530",
    "end": "1661550"
  },
  {
    "text": "risk at this point of time and endpoints",
    "start": "1661550",
    "end": "1666950"
  },
  {
    "text": "tries to make them easier to use as a product right right yeah",
    "start": "1666950",
    "end": "1681640"
  },
  {
    "text": "is there limit of the number of a thread the open in the server side Concorde is",
    "start": "1686269",
    "end": "1694860"
  },
  {
    "text": "there a limit on the number of threads there isn't there isn't that at this",
    "start": "1694860",
    "end": "1700470"
  },
  {
    "text": "point are there any specific features are improvements you'd like to see in",
    "start": "1700470",
    "end": "1706289"
  },
  {
    "text": "the coming year so I mean from the core",
    "start": "1706289",
    "end": "1712470"
  },
  {
    "text": "perspective the things that are that we are currently working on very actively",
    "start": "1712470",
    "end": "1718470"
  },
  {
    "text": "is to make the performance even better it the performance is actually quite good but we're still still a lot of room",
    "start": "1718470",
    "end": "1726659"
  },
  {
    "text": "to improve so that's that's been one of the focus the other focus is also on sort of some of the code cleanup like",
    "start": "1726659",
    "end": "1734129"
  },
  {
    "text": "making the filters it's not exactly super easy to add a new filter if you want today so we're working on that to",
    "start": "1734129",
    "end": "1740820"
  },
  {
    "text": "make it easier is that other things you want again I like so there are two big",
    "start": "1740820",
    "end": "1748019"
  },
  {
    "text": "features and we would love help on those also one is retries and retries is",
    "start": "1748019",
    "end": "1753179"
  },
  {
    "text": "fairly complex because it's doing retransfer entry tries as well as policy based sweet rice and hedging of requests",
    "start": "1753179",
    "end": "1760409"
  },
  {
    "text": "so you can hedge requests at multiple so that's one big feature and second is called service config so what service",
    "start": "1760409",
    "end": "1767070"
  },
  {
    "text": "config does is basically allows us to specify a config and client ownership so",
    "start": "1767070",
    "end": "1773519"
  },
  {
    "text": "when you deploy and you want to say change time you you want to instruct the",
    "start": "1773519",
    "end": "1778889"
  },
  {
    "text": "tines to change deadlines because you updated server then you can handle do that on the running clients and service",
    "start": "1778889",
    "end": "1785309"
  },
  {
    "text": "to service convicts so those are two big features that we are kind of have",
    "start": "1785309",
    "end": "1790470"
  },
  {
    "text": "proposed renner if working on but we'd love to get those out",
    "start": "1790470",
    "end": "1796789"
  },
  {
    "text": "the seeker sure a good question sir how do we ensure",
    "start": "1802700",
    "end": "1808130"
  },
  {
    "text": "feature parity between seeker Java core and so we I mean first the wild protocol",
    "start": "1808130",
    "end": "1814550"
  },
  {
    "text": "is pretty clear and we have we done a bunch of interrupt tests but very",
    "start": "1814550",
    "end": "1820880"
  },
  {
    "text": "regularly between with various it's a matrix of clients and servers and and I",
    "start": "1820880",
    "end": "1829850"
  },
  {
    "text": "mean that catches most of the issues so we don't add any feature without the interrupts take your own test I tend to",
    "start": "1829850",
    "end": "1845060"
  },
  {
    "text": "any yeah that's one",
    "start": "1845060",
    "end": "1851269"
  },
  {
    "text": "how much of GR pcs design was influenced by us like stubby another internal",
    "start": "1854809",
    "end": "1861059"
  },
  {
    "text": "google RPC mechanisms I can I can answer written may be the end can add more so I",
    "start": "1861059",
    "end": "1869190"
  },
  {
    "text": "mean the completion queue model and the threading model is completely different",
    "start": "1869190",
    "end": "1874679"
  },
  {
    "text": "from stubby other I mean so that being very different and and the code really",
    "start": "1874679",
    "end": "1880970"
  },
  {
    "text": "they do not share any code at all so it's completely written from scratch",
    "start": "1880970",
    "end": "1886159"
  },
  {
    "text": "however many of the components inspired by stubby design like the polling engine",
    "start": "1886159",
    "end": "1892010"
  },
  {
    "text": "like stubby stubs polling engine has been battle tested highly optimized so",
    "start": "1892010",
    "end": "1899490"
  },
  {
    "text": "many of the ideas at that level at the granularity heavily inspired from from stubby he wondered anything yep",
    "start": "1899490",
    "end": "1906390"
  },
  {
    "text": "I think it's mostly the ideas came from sabe we've shared whenever we can but we",
    "start": "1906390",
    "end": "1912450"
  },
  {
    "text": "updated the protocol so it's HTTP to best so anything HTTP to specific is new",
    "start": "1912450",
    "end": "1917850"
  },
  {
    "text": "and our async models switch to being a completion queue based this is only for",
    "start": "1917850",
    "end": "1923940"
  },
  {
    "text": "seeker instead of being a callback based which is what we used in study",
    "start": "1923940",
    "end": "1929658"
  },
  {
    "text": "are there any significant performance differences between the implementations",
    "start": "1933870",
    "end": "1939159"
  },
  {
    "text": "in Java go and see and and how is ensure that those are really equivalent and and",
    "start": "1939159",
    "end": "1945850"
  },
  {
    "text": "behave exactly the same significant performance differences I mean there are",
    "start": "1945850",
    "end": "1952179"
  },
  {
    "text": "performance differences I mean the C++ version is generally faster then then",
    "start": "1952179",
    "end": "1959259"
  },
  {
    "text": "Java and go implementations and what was the second part of your question like how do we ah",
    "start": "1959259",
    "end": "1966360"
  },
  {
    "text": "how do we get into equivalent behavior the same interrupts we do interrupt testing very very almost continuously so",
    "start": "1968769",
    "end": "1977139"
  },
  {
    "text": "so yeah all interrupt tests and we have all the performance - ports also in open",
    "start": "1977139",
    "end": "1982539"
  },
  {
    "text": "so you can see a cross languages performance yep",
    "start": "1982539",
    "end": "1987389"
  },
  {
    "text": "so instead of looking forward like looking back are there any things that if you could go back and do again that",
    "start": "1992350",
    "end": "1997570"
  },
  {
    "text": "you would change or maybe do it slightly different way I mean there's a lot",
    "start": "1997570",
    "end": "2005639"
  },
  {
    "text": "rewrite everything I'm just kidding but like probably the the layering we",
    "start": "2005639",
    "end": "2015240"
  },
  {
    "text": "would have probably implemented it a bit cleaner right now it looks a lot cleaner",
    "start": "2015240",
    "end": "2020279"
  },
  {
    "text": "on the slides but it's not really the that clean so that's definite and we are",
    "start": "2020279",
    "end": "2025620"
  },
  {
    "text": "working on it that's not one of the code clean up things so yeah I think there when we've chose c89",
    "start": "2025620",
    "end": "2033269"
  },
  {
    "text": "to start with yeah and then we realize that it does hurt our productivity quite",
    "start": "2033269",
    "end": "2039419"
  },
  {
    "text": "a bit and that has our code kind of mixed with C 89 and C++ 11 what happens",
    "start": "2039419",
    "end": "2055050"
  },
  {
    "text": "when the address of my target server changes is there any way to to",
    "start": "2055050",
    "end": "2060329"
  },
  {
    "text": "invalidate the connection because I have here I have some kind of keep alive in the protocol you can cancel the calls so",
    "start": "2060329",
    "end": "2072960"
  },
  {
    "text": "I mean you can you can yeah you can you can cancel all the in-flight calls and",
    "start": "2072960",
    "end": "2079250"
  },
  {
    "text": "destroy a channel yeah but I have to do this on myself yes yes I mean however I",
    "start": "2079250",
    "end": "2088319"
  },
  {
    "text": "mean I must add that I mean if the URI completely changed you have to do it yourself but if the resolution like if",
    "start": "2088319",
    "end": "2096540"
  },
  {
    "text": "now it's resolving to new back ends no that's a different story that depends on the elbe policy and the",
    "start": "2096540",
    "end": "2103890"
  },
  {
    "text": "resolver that you are using so and actually again stop from yesterday",
    "start": "2103890",
    "end": "2109800"
  },
  {
    "text": "covers some of that so actually if like let's say the DNS",
    "start": "2109800",
    "end": "2116550"
  },
  {
    "text": "records change oh and like one of the back end dice that's gonna lead to resolve and then new churches are going",
    "start": "2116550",
    "end": "2124020"
  },
  {
    "text": "to be created to the new back ends if the DNS resolve happens and that happens",
    "start": "2124020",
    "end": "2129480"
  },
  {
    "text": "when the when a disconnection happens",
    "start": "2129480",
    "end": "2132920"
  },
  {
    "text": "so as a follow-up to that as far as the resolver is concerned in cases of high",
    "start": "2142210",
    "end": "2147460"
  },
  {
    "text": "availability does it always essentially resolve to the current master and you",
    "start": "2147460",
    "end": "2153309"
  },
  {
    "text": "know then route calls because the right completions and read completions are associated with the master attack what",
    "start": "2153309",
    "end": "2164589"
  },
  {
    "text": "do you mean by master so on this on the server side the service itself can be achieved correct correct",
    "start": "2164589",
    "end": "2171369"
  },
  {
    "text": "and in that it is in REO the reads and writes are essentially associated with master that's right so the resolution",
    "start": "2171369",
    "end": "2178720"
  },
  {
    "text": "aspect of it is essentially always associated with the master is that something that we are PC handles or is",
    "start": "2178720",
    "end": "2184869"
  },
  {
    "text": "it the server side it should be it has",
    "start": "2184869",
    "end": "2191980"
  },
  {
    "text": "to be if I understand your question correctly so if clearly the resolver cannot like if you are doing it right",
    "start": "2191980",
    "end": "2197640"
  },
  {
    "text": "clearly the resolver has to resolve to the master right not the so that",
    "start": "2197640",
    "end": "2203680"
  },
  {
    "text": "functionality is cannot be at the GFP sea level that that's something you have",
    "start": "2203680",
    "end": "2209260"
  },
  {
    "text": "to handle probably have a different URI for the master or like I have your own custom resolver that can that can",
    "start": "2209260",
    "end": "2216309"
  },
  {
    "text": "understand it and the second question is the interrupts tests that you mentioned",
    "start": "2216309",
    "end": "2222280"
  },
  {
    "text": "are they also open source somewhere to look at yeah yeah all the interrupts s our github people and you can look at",
    "start": "2222280",
    "end": "2228910"
  },
  {
    "text": "them all interrupts are open source and they're being used by lots of people like when nginx launched they started",
    "start": "2228910",
    "end": "2235150"
  },
  {
    "text": "running those across engine and so they can use the proxy in between",
    "start": "2235150",
    "end": "2240990"
  },
  {
    "text": "from your testing did you just see any",
    "start": "2243700",
    "end": "2248810"
  },
  {
    "text": "major performance difference between different OS or different threading models oh yeah and we we experiment a",
    "start": "2248810",
    "end": "2256790"
  },
  {
    "text": "lot with threading models and it keeps",
    "start": "2256790",
    "end": "2262580"
  },
  {
    "text": "it still evolving a mess I mean we keep experimenting with it but one thing I can tell you is applications like when",
    "start": "2262580",
    "end": "2271970"
  },
  {
    "text": "you design your servers when you arrange your servers in such our clients in such a way that there are you're minimizing",
    "start": "2271970",
    "end": "2277369"
  },
  {
    "text": "threat jumps that yields the best performance so when I say thread jump",
    "start": "2277369",
    "end": "2283480"
  },
  {
    "text": "yeah and like G RPC makes it very easy for you to choose like create your own",
    "start": "2283480",
    "end": "2289340"
  },
  {
    "text": "completion queues in the in the pictures I showed only one completion queue but you can create as many as you want right like in you can create multiple",
    "start": "2289340",
    "end": "2294950"
  },
  {
    "text": "completion queues and you can associate a call with a particular completion queue so as long as even image",
    "start": "2294950",
    "end": "2301070"
  },
  {
    "text": "contention on the completion cubes and you see RPC tries to like minimize",
    "start": "2301070",
    "end": "2307310"
  },
  {
    "text": "thread jumps and and that usually heals the best performance",
    "start": "2307310",
    "end": "2313300"
  },
  {
    "text": "I mean like like Windows has a",
    "start": "2315350",
    "end": "2320750"
  },
  {
    "text": "completely different model and right now we've only been experimenting on the on the UNIX platforms or so I don't have",
    "start": "2320750",
    "end": "2327020"
  },
  {
    "text": "much to comment on the windows there are threading model yeah me again",
    "start": "2327020",
    "end": "2333400"
  },
  {
    "text": "suggest the question about the deployment of the back end so would make sense we have many endpoints for the",
    "start": "2333400",
    "end": "2340790"
  },
  {
    "text": "different backends because like now everybody's talking about sto and having like share PC load balancing so where we",
    "start": "2340790",
    "end": "2347450"
  },
  {
    "text": "have apps from the outside coming in would will be better to have like a",
    "start": "2347450",
    "end": "2352610"
  },
  {
    "text": "single NLB and then hung into ISTE oh then it's dancing or if multiple anal",
    "start": "2352610",
    "end": "2360950"
  },
  {
    "text": "bees and then public your eyes and then to the client side load balancing I",
    "start": "2360950",
    "end": "2368140"
  },
  {
    "text": "actually didn't catch the questions fully so I'm sorry so I think he covered",
    "start": "2369550",
    "end": "2377600"
  },
  {
    "text": "load balancing yesterday and there are multiple options and it really makes",
    "start": "2377600",
    "end": "2382850"
  },
  {
    "text": "sense in everybody's individual scenario but yes one of the models is either run",
    "start": "2382850",
    "end": "2389720"
  },
  {
    "text": "a sidecar on Y or SPO type of this thing and use that to do load balancing and",
    "start": "2389720",
    "end": "2395240"
  },
  {
    "text": "it's very convenient so people do use it so that's the that's the benefit of it and it can do very advanced load",
    "start": "2395240",
    "end": "2401660"
  },
  {
    "text": "balancing the cost is that you are going through a proxy so if you're super latency or throughput sensitive that may",
    "start": "2401660",
    "end": "2407450"
  },
  {
    "text": "affect you but other than that it's a good option actually speaking of load",
    "start": "2407450",
    "end": "2419330"
  },
  {
    "text": "balancing is there any way to say like off load load balancing to the kernel and use IP vs or something you guys",
    "start": "2419330",
    "end": "2424970"
  },
  {
    "text": "experimented with that and is there a",
    "start": "2424970",
    "end": "2435590"
  },
  {
    "text": "reason you went for a multi threaded approach instead of a single threaded approach with an event loop that's a",
    "start": "2435590",
    "end": "2441620"
  },
  {
    "text": "good I I'm not sure",
    "start": "2441620",
    "end": "2447490"
  },
  {
    "text": "that comes from our experience from previous generation study where we",
    "start": "2449359",
    "end": "2455150"
  },
  {
    "text": "learned that we did need we could starve applications through single-threaded in this event loop so we used a thread",
    "start": "2455150",
    "end": "2462859"
  },
  {
    "text": "pool and so that's why it's multi-threading",
    "start": "2462859",
    "end": "2467440"
  },
  {
    "text": "okay thank you",
    "start": "2470640",
    "end": "2475008"
  }
]
[
  {
    "text": "hello everyone welcome to the session my name is Amit and I have Kevin here with",
    "start": "399",
    "end": "8120"
  },
  {
    "text": "me both of us work for compute platform team at Uber compute platform team is",
    "start": "8120",
    "end": "15080"
  },
  {
    "text": "part of platform engine group so in today's session we are going",
    "start": "15080",
    "end": "21720"
  },
  {
    "text": "to talk about efficient resource utilization for batch compute on",
    "start": "21720",
    "end": "27800"
  },
  {
    "text": "cetes we will talk about multiple challenges that we face while achieving",
    "start": "27800",
    "end": "35480"
  },
  {
    "text": "efficient resource utilization and how we resolve all of",
    "start": "35480",
    "end": "40879"
  },
  {
    "text": "them so coming to the agenda first we will talk about batch",
    "start": "41920",
    "end": "47879"
  },
  {
    "text": "compute at Uber and overview then we'll talk about",
    "start": "47879",
    "end": "53719"
  },
  {
    "text": "importance of resource sharing and what types of challenges we",
    "start": "53719",
    "end": "59120"
  },
  {
    "text": "face in in efficient resource utilization then we'll jump to",
    "start": "59120",
    "end": "64680"
  },
  {
    "text": "Solutions some key of them are resource digal resource management and",
    "start": "64680",
    "end": "70960"
  },
  {
    "text": "Federation and a specialized Hardware efficiency after that we'll talk about",
    "start": "70960",
    "end": "76960"
  },
  {
    "text": "some of the future work that we are going to do in next year and then we'll happily answer some",
    "start": "76960",
    "end": "82960"
  },
  {
    "text": "of your questions coming to the quick overview",
    "start": "82960",
    "end": "88040"
  },
  {
    "text": "of compute team we have two forms of compute in compute",
    "start": "88040",
    "end": "93079"
  },
  {
    "text": "team stateless compute and batch compute adya and Aura already talked",
    "start": "93079",
    "end": "99520"
  },
  {
    "text": "about the stateless compute in the previous session in this session we are going to focus on batch",
    "start": "99520",
    "end": "107320"
  },
  {
    "text": "compute the underlying architecture remains literally same for",
    "start": "107320",
    "end": "112960"
  },
  {
    "text": "both stateless compute and batch compute earlier we were running on Pon powered by meos and now we are in the phase of",
    "start": "112960",
    "end": "120920"
  },
  {
    "text": "migration to Coes all the lower level architecture",
    "start": "120920",
    "end": "126000"
  },
  {
    "text": "like cran host treasure service and the physical hardware and the network infrastructure remain same as for the",
    "start": "126000",
    "end": "132080"
  },
  {
    "text": "stateless compute in the batch compute we largely focus on machine learning jobs which is",
    "start": "132080",
    "end": "140560"
  },
  {
    "text": "powered by our sister team Michelangelo we'll also talk about spark",
    "start": "140560",
    "end": "145879"
  },
  {
    "text": "jobs and data science workbench so let's move",
    "start": "145879",
    "end": "152640"
  },
  {
    "text": "on coming to the use cases at Uber we have both end user use",
    "start": "152640",
    "end": "159800"
  },
  {
    "text": "cases and platform use cases which are solved through batch workloads some of",
    "start": "159800",
    "end": "165319"
  },
  {
    "text": "the key end user use cases are writer pricing intelligence ETA",
    "start": "165319",
    "end": "172040"
  },
  {
    "text": "estimation destination suggestion Etc like when you see Uber app and you",
    "start": "172040",
    "end": "177599"
  },
  {
    "text": "see the ETS those are powered by B workloads from the platform team we",
    "start": "177599",
    "end": "184560"
  },
  {
    "text": "solve some of the use cases like AI model training data science notebooks also through vatch",
    "start": "184560",
    "end": "192280"
  },
  {
    "text": "workloads to solve all these use cases we largely depend on three types of",
    "start": "192280",
    "end": "198400"
  },
  {
    "text": "processing Frameworks namely spark Ray cluster and Ray jobs and coord be on",
    "start": "198400",
    "end": "206400"
  },
  {
    "text": "job sparkk jobs are solved through the spark application crd and the spark",
    "start": "206400",
    "end": "212959"
  },
  {
    "text": "operator that is open source by Google Cloud platform Ray jobs are solved through the",
    "start": "212959",
    "end": "220560"
  },
  {
    "text": "ray cluster crd and the ray operator and kubernetes V1 job is already present in",
    "start": "220560",
    "end": "225720"
  },
  {
    "text": "the Upstream version of the Coes we literally use that so before we move on I would like",
    "start": "225720",
    "end": "234680"
  },
  {
    "text": "to give you some status So currently we have already migrated Ed all the data",
    "start": "234680",
    "end": "240599"
  },
  {
    "text": "science work rench jobs and sessions to co natives most of the machine learning",
    "start": "240599",
    "end": "247120"
  },
  {
    "text": "jobs and the AI jobs are already running on Coes some of them are still with MOS",
    "start": "247120",
    "end": "254480"
  },
  {
    "text": "which will be mated soon to Coes in the coming half for the spark jobs we have already",
    "start": "254480",
    "end": "260919"
  },
  {
    "text": "done the solution and we have just initiated the migration in coming half and next year we target to finish these",
    "start": "260919",
    "end": "268600"
  },
  {
    "text": "migrations so we are targeting next year for sure to have all the batch workloads",
    "start": "268600",
    "end": "275240"
  },
  {
    "text": "running on kubernetes coming to the scale of batch",
    "start": "275240",
    "end": "281080"
  },
  {
    "text": "compute at Uber we have around 30,000 hosts dedicated for batch compute which",
    "start": "281080",
    "end": "287479"
  },
  {
    "text": "results into around 1 million course we have also got 4,000 gpus",
    "start": "287479",
    "end": "293360"
  },
  {
    "text": "solving the machine learning jobs and the AI model trainings and per day we launch around 3",
    "start": "293360",
    "end": "300880"
  },
  {
    "text": "million containers for batch workloads and at Peak we go up to 500",
    "start": "300880",
    "end": "307080"
  },
  {
    "text": "parts per second launch rate now that we understand the use",
    "start": "307080",
    "end": "312600"
  },
  {
    "text": "cases and the scale which we're trying to solve through batch",
    "start": "312600",
    "end": "318120"
  },
  {
    "text": "workloads in Uber let's also understand the",
    "start": "318120",
    "end": "323280"
  },
  {
    "text": "importance of resource sharing because there are multiple teams involved who solve their use cases through batch",
    "start": "323280",
    "end": "329120"
  },
  {
    "text": "workload it's important to learn how we solve the",
    "start": "329120",
    "end": "334680"
  },
  {
    "text": "resource sharing problem for them so this graph actually",
    "start": "334680",
    "end": "343600"
  },
  {
    "text": "shows the utilization of resources for one particular team the red line you see",
    "start": "343600",
    "end": "349639"
  },
  {
    "text": "in the graph is actually the reservation that team has done but if you see most of the times",
    "start": "349639",
    "end": "357440"
  },
  {
    "text": "they are not adhering to that either they are going high in the utilization",
    "start": "357440",
    "end": "362560"
  },
  {
    "text": "or they are underutilized from whatever they have reserved so which means they cannot",
    "start": "362560",
    "end": "370360"
  },
  {
    "text": "actually predict how much they need in general what it means is that at the",
    "start": "370360",
    "end": "377479"
  },
  {
    "text": "time when they are going higher than the reservation they will need resources from somewhere else by some other teams",
    "start": "377479",
    "end": "383599"
  },
  {
    "text": "and at the times when they are low in utilization they can share resources with someone else",
    "start": "383599",
    "end": "390160"
  },
  {
    "text": "and this pattern is largely same for most of the teams only thing that differs is the time they go up and down",
    "start": "390160",
    "end": "396560"
  },
  {
    "text": "in utilization at different times so the next graph shows the",
    "start": "396560",
    "end": "404080"
  },
  {
    "text": "utilization for aggregation of multiple teams which means that if we aggregate",
    "start": "404080",
    "end": "409759"
  },
  {
    "text": "the resource allocation for multiple teams and plot on time then we find that it is pretty",
    "start": "409759",
    "end": "417080"
  },
  {
    "text": "close to the total available resources and that helps us understand why",
    "start": "417080",
    "end": "422360"
  },
  {
    "text": "resource sharing is important if we had not shared the resources each of them will have to",
    "start": "422360",
    "end": "428520"
  },
  {
    "text": "reserve for their Peak and that will actually cause problems in terms of cost",
    "start": "428520",
    "end": "434479"
  },
  {
    "text": "and efficiency so moving on how we solve this sharing",
    "start": "434479",
    "end": "441199"
  },
  {
    "text": "problem at Uber we have a concept of resource",
    "start": "441199",
    "end": "447120"
  },
  {
    "text": "pools what is a resource pool resource pool is a logical abstraction",
    "start": "447120",
    "end": "453199"
  },
  {
    "text": "of set of resources like CPU memory and",
    "start": "453199",
    "end": "458720"
  },
  {
    "text": "GPU in this picture if you see on the left half we have shown the",
    "start": "458720",
    "end": "464120"
  },
  {
    "text": "organizational hierarchy of uber it can be for any other company also and on the right half we are",
    "start": "464120",
    "end": "471319"
  },
  {
    "text": "showing the similar hierarchical structure for the resource pools so what happens total resources which are",
    "start": "471319",
    "end": "478000"
  },
  {
    "text": "available at the root level get distributed among the children which means sum of the resources of children",
    "start": "478000",
    "end": "485360"
  },
  {
    "text": "is equal to the some of equal to the resource available at the parent level so this hierarchical structure of",
    "start": "485360",
    "end": "492520"
  },
  {
    "text": "resource pools help us actually sharing achieve the sharing between the teams",
    "start": "492520",
    "end": "498919"
  },
  {
    "text": "between the projects and the Orcs going forward we'll see how these",
    "start": "498919",
    "end": "504960"
  },
  {
    "text": "resource pools are being used for sharing Etc Kevin will explain that",
    "start": "504960",
    "end": "510520"
  },
  {
    "text": "moving on let's talk about the first version of the architecture that we implemented to solve these",
    "start": "510520",
    "end": "519000"
  },
  {
    "text": "problems so what we did we created the resource pools inside the cluster and",
    "start": "520360",
    "end": "526440"
  },
  {
    "text": "each of the cluster at Uber is zonal in nature which resulted into each of these",
    "start": "526440",
    "end": "533880"
  },
  {
    "text": "resource pools also becoming zonal resource pools what it means that the resources which are part of of these",
    "start": "533880",
    "end": "539399"
  },
  {
    "text": "resource pools could come from only one zone however we can create multiple resource pools inside the same Zone",
    "start": "539399",
    "end": "545920"
  },
  {
    "text": "that's not a problem and this was our",
    "start": "545920",
    "end": "551959"
  },
  {
    "text": "architecture the first one that we implemented we had multiple zonal clusters each of them having a CO",
    "start": "551959",
    "end": "558480"
  },
  {
    "text": "control plane set of Cu blades and operators which help execute the batch",
    "start": "558480",
    "end": "565120"
  },
  {
    "text": "workloads like a spark or Ray and customers which were internal customers",
    "start": "565120",
    "end": "572880"
  },
  {
    "text": "were hitting this clusters the QBE API servers directly which means that each of the customers had integration with",
    "start": "572880",
    "end": "579399"
  },
  {
    "text": "these clusters and they used to submit workloads",
    "start": "579399",
    "end": "585279"
  },
  {
    "text": "directly so these two architectural decisions first one the zonal resource",
    "start": "585480",
    "end": "591839"
  },
  {
    "text": "pools and second one customers interacting with the Clusters directly",
    "start": "591839",
    "end": "597839"
  },
  {
    "text": "without any uniform layer in the middle that caus us multiple",
    "start": "597839",
    "end": "604760"
  },
  {
    "text": "challenges and some of the key challenges are here first one we faced was",
    "start": "604760",
    "end": "611440"
  },
  {
    "text": "fragmentation second non-uniform cluster usage third one zonal availability of",
    "start": "611440",
    "end": "619560"
  },
  {
    "text": "resource pools and then multiple issues in cluster management and",
    "start": "619560",
    "end": "626880"
  },
  {
    "text": "operations we'll talk about each of these in the next slides first",
    "start": "627040",
    "end": "633640"
  },
  {
    "text": "one the problem of fragmentation if you see in this picture we have again three clusters we",
    "start": "633640",
    "end": "640800"
  },
  {
    "text": "have multiple resource pools which are created on these clusters and each of these clusters also have some buffer",
    "start": "640800",
    "end": "648839"
  },
  {
    "text": "capacity total buffer capacity is shown as here 8 units but if you want to create a new",
    "start": "650000",
    "end": "656760"
  },
  {
    "text": "resource pool called resource pool 9 which is incoming resource S Pool which requires same amount of capacity which",
    "start": "656760",
    "end": "662839"
  },
  {
    "text": "is available as total buer capacity we cannot create it reason being this resource pool can be created",
    "start": "662839",
    "end": "669720"
  },
  {
    "text": "on only one of the Clusters and none of these clusters have",
    "start": "669720",
    "end": "675920"
  },
  {
    "text": "total of 80 units of capacity available which means the capacity is",
    "start": "675920",
    "end": "681760"
  },
  {
    "text": "fragmented and even if you have total capacity available we cannot create new resource pool and that's a big loss",
    "start": "681760",
    "end": "690959"
  },
  {
    "text": "moving on the next challenge we faced was non-uniform cluster",
    "start": "691040",
    "end": "696680"
  },
  {
    "text": "usage in this graph you can see it shows the cluster utilization for",
    "start": "696680",
    "end": "703079"
  },
  {
    "text": "four clusters one of the Clusters in green color is way below in its utilization",
    "start": "703079",
    "end": "710519"
  },
  {
    "text": "around 20% or even below goes to 10% and the other one is picking up to",
    "start": "710519",
    "end": "717320"
  },
  {
    "text": "100% multiple times so this problem what happens is whenever",
    "start": "717320",
    "end": "725120"
  },
  {
    "text": "we try to submit workloads on the cluster 4 which is peing a lot CL",
    "start": "725120",
    "end": "731079"
  },
  {
    "text": "workload will go to pending State because resources are not available for execution at the same time the cluster",
    "start": "731079",
    "end": "738279"
  },
  {
    "text": "which is very low in utilization resources will be wasted and why it happens because the resource pools to",
    "start": "738279",
    "end": "744519"
  },
  {
    "text": "which workloads are being submitted are on clusters and teams can submit submit",
    "start": "744519",
    "end": "749720"
  },
  {
    "text": "the worklad to the resource Bulls only so this is another problem",
    "start": "749720",
    "end": "755079"
  },
  {
    "text": "sometimes we are wasting the resource and sometimes we are waiting for",
    "start": "755079",
    "end": "760800"
  },
  {
    "text": "execution next challenge we face is zonal availability of resource",
    "start": "761160",
    "end": "768440"
  },
  {
    "text": "pools again you can see here we have three zonal clusters if Zone one goes",
    "start": "768440",
    "end": "775639"
  },
  {
    "text": "down what will happen that zonal cluster one will also go down which will result",
    "start": "775639",
    "end": "781480"
  },
  {
    "text": "into the resource pools which were available on that cluster going down what it",
    "start": "781480",
    "end": "789040"
  },
  {
    "text": "means that the teams which own these resource pools resource pools 1 2 and three they cannot submit their workloads",
    "start": "789040",
    "end": "795720"
  },
  {
    "text": "to those resource pools and this is a big problem from for them from Disaster Recovery point of view and from",
    "start": "795720",
    "end": "801959"
  },
  {
    "text": "availability point of view moving on to the next challenge",
    "start": "801959",
    "end": "810639"
  },
  {
    "text": "we Face multiple problems in cluster management and operations due to the architecture that we adopted",
    "start": "810639",
    "end": "817040"
  },
  {
    "text": "first first one being coordination required to turn up and down the Clusters whenever you have to create the",
    "start": "817040",
    "end": "823720"
  },
  {
    "text": "new cluster or bring down a cluster we'll create new resource pools we'll pass the",
    "start": "823720",
    "end": "829839"
  },
  {
    "text": "information to the different teams who are going to use these and whenever we are bringing it down we will need",
    "start": "829839",
    "end": "835880"
  },
  {
    "text": "approvals from different teams that okay we are bringing down the cluster are you fine with this or not so this becomes",
    "start": "835880",
    "end": "841079"
  },
  {
    "text": "very process heavy second one is cluster selection because the teams are looking",
    "start": "841079",
    "end": "849360"
  },
  {
    "text": "at their own resource pool only and which means that only some part of the Clusters or some clusters not all the",
    "start": "849360",
    "end": "855000"
  },
  {
    "text": "cluster at the time they don't have the best view of how to choose the",
    "start": "855000",
    "end": "861759"
  },
  {
    "text": "cluster for any new workload so cluster selection is a problem because they don't have the global",
    "start": "861759",
    "end": "867680"
  },
  {
    "text": "view also whenever we have to do releases and",
    "start": "867680",
    "end": "873480"
  },
  {
    "text": "do upgrades of the cube version if you want to bring down some part of the cube Lads in the",
    "start": "873480",
    "end": "880560"
  },
  {
    "text": "cluster that will cause lower availability to the resource pools and",
    "start": "880560",
    "end": "885639"
  },
  {
    "text": "that will impact the customers so these are the key challenges that we face for the due to the V1",
    "start": "885639",
    "end": "893800"
  },
  {
    "text": "architecture next Kevin is going to talk about how we solve these challenges",
    "start": "893959",
    "end": "899560"
  },
  {
    "text": "with Federation in batch compute kin thanks M so to solve those problems we",
    "start": "899560",
    "end": "907120"
  },
  {
    "text": "implement the new service called the B Fator with the Fator service all class",
    "start": "907120",
    "end": "912800"
  },
  {
    "text": "of details are now abstracted away from the clients it provides simple apis to",
    "start": "912800",
    "end": "918000"
  },
  {
    "text": "create read update and Del the bch workload so how do this those APS work",
    "start": "918000",
    "end": "926399"
  },
  {
    "text": "to create a job the batch figher first look at the properties of the incoming",
    "start": "926399",
    "end": "931920"
  },
  {
    "text": "workload for example the amount of resources the workload is requesting the type of resources that is whether the",
    "start": "931920",
    "end": "939240"
  },
  {
    "text": "workl is requesting GP or not for example based on those properties the",
    "start": "939240",
    "end": "945160"
  },
  {
    "text": "cluster select module within the Fator decides which cluster to place the",
    "start": "945160",
    "end": "950240"
  },
  {
    "text": "workload and then the Fator equates the workload crd object on the respective Z",
    "start": "950240",
    "end": "957600"
  },
  {
    "text": "cluster once the workflow CD object has been created depending on the workflow type",
    "start": "957600",
    "end": "964880"
  },
  {
    "text": "whether it's a spark or Ray the respective operator running on the zal comp cluster will create the parts and",
    "start": "964880",
    "end": "972800"
  },
  {
    "text": "continue to manage the life cycle of the parts now for the remaining operations",
    "start": "972800",
    "end": "979560"
  },
  {
    "text": "after the part has been created that is re update delete AP call the Fator will",
    "start": "979560",
    "end": "986800"
  },
  {
    "text": "use a module called work tracker to maintain internal mapping between the workload and the the cluster and based",
    "start": "986800",
    "end": "993800"
  },
  {
    "text": "on the mapping uh the API request will be rotated to the cube APS server of the",
    "start": "993800",
    "end": "999160"
  },
  {
    "text": "cluster which contains workload so how does the cluster section",
    "start": "999160",
    "end": "1006279"
  },
  {
    "text": "work um first of all the fer has a list of clusters uh known to itself and it",
    "start": "1006279",
    "end": "1011800"
  },
  {
    "text": "first goes through the cluster filter to get the list of custers that that are eligible to place workload so let's say",
    "start": "1011800",
    "end": "1018279"
  },
  {
    "text": "the work is requesting GPU resources the cluster filter will filter out any clusters which do not have GPU",
    "start": "1018279",
    "end": "1026438"
  },
  {
    "text": "holds next the set of eligible clusters will go to the cluster ranker you will",
    "start": "1027039",
    "end": "1032839"
  },
  {
    "text": "rank the cluster based on various characteristics like available resources in the cluster aable resources in the",
    "start": "1032839",
    "end": "1039720"
  },
  {
    "text": "resource pool amount of ping resources ETA then after ranking the most suitable",
    "start": "1039720",
    "end": "1047280"
  },
  {
    "text": "cluster will be selected to place the workload so maybe let's take a more simple example let's say the uh the",
    "start": "1047280",
    "end": "1054720"
  },
  {
    "text": "workload is requesting 10 CPU course and all cluster has passed the cluster",
    "start": "1054720",
    "end": "1059840"
  },
  {
    "text": "filter meaning they all have sufficient resources but cluster one has 100 CPU",
    "start": "1059840",
    "end": "1065039"
  },
  {
    "text": "course available class two has 50 CPU course available and class three has",
    "start": "1065039",
    "end": "1070280"
  },
  {
    "text": "20 and because class one has the most CPU course available uh you will be ranked as most",
    "start": "1070280",
    "end": "1077320"
  },
  {
    "text": "favorable cluster and later selected for placing the work",
    "start": "1077320",
    "end": "1083000"
  },
  {
    "text": "Cloud but however uh having fish alone only solved the PW problem as May has",
    "start": "1084559",
    "end": "1091400"
  },
  {
    "text": "mentioned earlier in our V1 architecture the workflow from a certain team can",
    "start": "1091400",
    "end": "1096960"
  },
  {
    "text": "only run on the zal custers which has the resource pool owned by that",
    "start": "1096960",
    "end": "1102200"
  },
  {
    "text": "team this means unless we create resource pools on every single Custer",
    "start": "1102200",
    "end": "1107559"
  },
  {
    "text": "which is quite wasteful the workflow cannot be freely placed on any",
    "start": "1107559",
    "end": "1113159"
  },
  {
    "text": "cluster so how do we solve this problem uh so instead of having the resource pools pined to a spe zal KU",
    "start": "1113159",
    "end": "1120600"
  },
  {
    "text": "cluster now resource pools are managed regionally by a service which we call",
    "start": "1120600",
    "end": "1126480"
  },
  {
    "text": "the regional resource manager the regional resource manager will be responsible for tracking the",
    "start": "1126480",
    "end": "1133200"
  },
  {
    "text": "amount of resources consumed by resource pools regionally across class",
    "start": "1133200",
    "end": "1140200"
  },
  {
    "text": "and most importantly it will constraint the amount of resources a resource pool can",
    "start": "1140200",
    "end": "1146760"
  },
  {
    "text": "consume and lastly it provides the capability to share resources",
    "start": "1146760",
    "end": "1151840"
  },
  {
    "text": "elastically among resource pools and how does Regional resource",
    "start": "1151840",
    "end": "1157880"
  },
  {
    "text": "pool manager Regional resource manager work on a very very high level it",
    "start": "1157880",
    "end": "1163159"
  },
  {
    "text": "monitors the parts within the cluster in order to track the usage for every resource pool",
    "start": "1163159",
    "end": "1169520"
  },
  {
    "text": "and Aggregates available capacity from clusters within the region then distribute those capacities to each",
    "start": "1169520",
    "end": "1176280"
  },
  {
    "text": "individual workload fairly while respecting the constraint of the resource",
    "start": "1176280",
    "end": "1182799"
  },
  {
    "text": "pool as a summary with Federation and the regional Resource Management we're",
    "start": "1183360",
    "end": "1189159"
  },
  {
    "text": "able to solve the following problem which were mentioned earlier and I will go to each I will get into each of the",
    "start": "1189159",
    "end": "1195360"
  },
  {
    "text": "point in detail in later slides so the first one we are able to eliminate resource",
    "start": "1195360",
    "end": "1201760"
  },
  {
    "text": "fragmentation the second one we're able to make the Cass usage significantly more uniform ac across",
    "start": "1201760",
    "end": "1209000"
  },
  {
    "text": "clusters the third one we're able to provide Regional availability of resource pools and lastly we are able to",
    "start": "1209000",
    "end": "1215880"
  },
  {
    "text": "greatly simplify the class management meanwhile with the regional",
    "start": "1215880",
    "end": "1221760"
  },
  {
    "text": "resource manager we are able to provide El resource sharing across different resource pools within the",
    "start": "1221760",
    "end": "1229080"
  },
  {
    "text": "region and lastly m is also going to cover the additional work we have been doing to further improve the cluster",
    "start": "1229080",
    "end": "1236159"
  },
  {
    "text": "efficiency by supporting specialized Hardware as well as as well as the",
    "start": "1236159",
    "end": "1241440"
  },
  {
    "text": "future work that we are planning for",
    "start": "1241440",
    "end": "1245039"
  },
  {
    "text": "communities so as you may recall in the previous slide if we place resource Pools St statically within the zal",
    "start": "1247240",
    "end": "1254559"
  },
  {
    "text": "Communist cure there will be additional buffer Capac capacity inside each Custer",
    "start": "1254559",
    "end": "1260480"
  },
  {
    "text": "but we are able to we are not able to create a single resource pool to utilize those buffer",
    "start": "1260480",
    "end": "1266360"
  },
  {
    "text": "capacity this causes the resource fragmentation",
    "start": "1266360",
    "end": "1271679"
  },
  {
    "text": "problem this problem is now solved now that we manage the resource RS at the regional",
    "start": "1271679",
    "end": "1277840"
  },
  {
    "text": "level in the V2 architecture we only need to making sure we only need to make",
    "start": "1277840",
    "end": "1283080"
  },
  {
    "text": "sure the sum of the resource pool capacity is less than or equal to the cler capacity within the",
    "start": "1283080",
    "end": "1290120"
  },
  {
    "text": "region as mentioned earlier the Custer selector will pick the best cust to R those workload and the regional resource",
    "start": "1290120",
    "end": "1297039"
  },
  {
    "text": "manager while making sure the resource consumed by the work is within the resource P",
    "start": "1297039",
    "end": "1303480"
  },
  {
    "text": "cont as you can see in the diagram now we are able to utilize all capacity",
    "start": "1303480",
    "end": "1308559"
  },
  {
    "text": "within the region and create a resource pool for team to consume using the buffer capacity without",
    "start": "1308559",
    "end": "1316480"
  },
  {
    "text": "fragmentation the next benefit we are seeing is significantly more uniform cluster",
    "start": "1317039",
    "end": "1324240"
  },
  {
    "text": "utilization so here is a test round that we performed on the left side it's a c",
    "start": "1324240",
    "end": "1330880"
  },
  {
    "text": "Custer utilization graph for non-rated Custer and on the right it's a graph for",
    "start": "1330880",
    "end": "1336840"
  },
  {
    "text": "the frary cluster the test was performed using the same data set which means they",
    "start": "1336840",
    "end": "1342440"
  },
  {
    "text": "have the same uh precisely control of workload workload resources work",
    "start": "1342440",
    "end": "1348159"
  },
  {
    "text": "durations and same resource pool comparation the only difference is that",
    "start": "1348159",
    "end": "1353520"
  },
  {
    "text": "on the left side the resource pools are created statically whereas on the right",
    "start": "1353520",
    "end": "1358720"
  },
  {
    "text": "side resource pool are managed dynamically by the regional resource manager as you can see for the nonf",
    "start": "1358720",
    "end": "1366080"
  },
  {
    "text": "Clusters similar to our V environment due to static resource placement we are",
    "start": "1366080",
    "end": "1372240"
  },
  {
    "text": "seeing few clusters being overly utilized whereas other clusters is under",
    "start": "1372240",
    "end": "1378000"
  },
  {
    "text": "are underutilized however for the F cluster the utilization is uniform across the",
    "start": "1378000",
    "end": "1386960"
  },
  {
    "text": "cluster also because the clust utilization pequs at a different time for different clusters in our V1",
    "start": "1386960",
    "end": "1394840"
  },
  {
    "text": "architecture having a uniform cluster utilization give us the opportunity to shrink the overall CL cluster",
    "start": "1394840",
    "end": "1403600"
  },
  {
    "text": "size meanwhile as for the workload we are observing the cluster to have 3x",
    "start": "1403600",
    "end": "1409559"
  },
  {
    "text": "reductions in P9 task scheduling time this means the user will see much",
    "start": "1409559",
    "end": "1417000"
  },
  {
    "text": "shorten time to run the",
    "start": "1417000",
    "end": "1420480"
  },
  {
    "text": "workload the next is regional availability of the resource pools previously when a cluster of Zone",
    "start": "1422039",
    "end": "1429679"
  },
  {
    "text": "goes down since the resource are class local this means the workload depending",
    "start": "1429679",
    "end": "1435000"
  },
  {
    "text": "on the resource pool will fail to execute however with the regional resource pool",
    "start": "1435000",
    "end": "1441159"
  },
  {
    "text": "manager we are we can place the workload on any cluster that have capacity for most",
    "start": "1441159",
    "end": "1447240"
  },
  {
    "text": "cases as you can see in the diagram after class one goes down work CL 1 2 3",
    "start": "1447240",
    "end": "1453279"
  },
  {
    "text": "4 can run on cluster two and three uh given that those clusters have",
    "start": "1453279",
    "end": "1458679"
  },
  {
    "text": "available capacity lastly since clients use apis",
    "start": "1458679",
    "end": "1465640"
  },
  {
    "text": "provided by the fiter to interact with underlying communist Custer this makes the custom management",
    "start": "1465640",
    "end": "1472080"
  },
  {
    "text": "much more easy um since clients no longer need to maintain the list of a clusters so no",
    "start": "1472080",
    "end": "1478880"
  },
  {
    "text": "coordination is now required to turn up or turn down the",
    "start": "1478880",
    "end": "1483880"
  },
  {
    "text": "cluster also clients no longer need to worry about how to pick the best cluster",
    "start": "1484440",
    "end": "1489600"
  },
  {
    "text": "use and it makes our platform teams life much easier since the pathw Custer",
    "start": "1489600",
    "end": "1495840"
  },
  {
    "text": "cannot be easily turned down for release and upgrade",
    "start": "1495840",
    "end": "1500360"
  },
  {
    "text": "purposes and next I will talk about the electric resource showing feature inside the regional resource manager and how we",
    "start": "1501559",
    "end": "1509440"
  },
  {
    "text": "are shuring resources am the resource PS within the region so let's take a simple example we",
    "start": "1509440",
    "end": "1516279"
  },
  {
    "text": "have resource pool one two and three in region one resource pool one and two",
    "start": "1516279",
    "end": "1522360"
  },
  {
    "text": "have fre capacities whereas resource pool three is fully utilized",
    "start": "1522360",
    "end": "1529320"
  },
  {
    "text": "now let's say a worklow is created on resource Bo three without Ela resource showing the",
    "start": "1529320",
    "end": "1536279"
  },
  {
    "text": "workflow will be paning until the workflow has other workflows have finished in resource P",
    "start": "1536279",
    "end": "1544120"
  },
  {
    "text": "three but now with elect res Shing the regional resource manager SE there are paning workload within the resour pool",
    "start": "1544399",
    "end": "1551360"
  },
  {
    "text": "three but there are also unused resources in resource tool one and two as well so the regional resource manager",
    "start": "1551360",
    "end": "1559880"
  },
  {
    "text": "is able to borrow the resources from resource P one and two and use those",
    "start": "1559880",
    "end": "1565000"
  },
  {
    "text": "resources to start the workload that is created on resource post",
    "start": "1565000",
    "end": "1570640"
  },
  {
    "text": "stre now what if there's additional workload create on Resource One since Resource One already has some",
    "start": "1572720",
    "end": "1580120"
  },
  {
    "text": "free capacity available those capacities can be used to run some of the workload",
    "start": "1580120",
    "end": "1586159"
  },
  {
    "text": "that is created but still we have still some part of workload",
    "start": "1586159",
    "end": "1593320"
  },
  {
    "text": "pending because resource boost three is consuming The Borrowed resources it has",
    "start": "1595240",
    "end": "1600600"
  },
  {
    "text": "lower priority to those resources compared to Resource One and because of",
    "start": "1600600",
    "end": "1606279"
  },
  {
    "text": "this the regional resource manager will evict the parts within the workload so",
    "start": "1606279",
    "end": "1611480"
  },
  {
    "text": "that the borrow resources are given back to Resource One so that it meets the",
    "start": "1611480",
    "end": "1616840"
  },
  {
    "text": "resource requirement for the Ping workload and lastly the additional",
    "start": "1616840",
    "end": "1623039"
  },
  {
    "text": "workload cre on resource P one is able to take the resources from resource",
    "start": "1623039",
    "end": "1629440"
  },
  {
    "text": "three so next I'll pass it back to ID to talk about the special",
    "start": "1629440",
    "end": "1634919"
  },
  {
    "text": "efficiency thank you Kevin now that we have seen how resource",
    "start": "1634919",
    "end": "1641159"
  },
  {
    "text": "sharing Works how we changed our architecture from zonal resource pools",
    "start": "1641159",
    "end": "1647120"
  },
  {
    "text": "to Regional resource pools and introduced Federation layer at the",
    "start": "1647120",
    "end": "1652440"
  },
  {
    "text": "region let's talk about some more efficiency efforts and one of them being the key",
    "start": "1652440",
    "end": "1658080"
  },
  {
    "text": "one that is for specialized Hardware efficiency so our clusters are largely",
    "start": "1658080",
    "end": "1665720"
  },
  {
    "text": "heterogeneous in nature by heterogeneous I mean they have both CPUs and gpus available in the same",
    "start": "1665720",
    "end": "1672000"
  },
  {
    "text": "cluster and some of the gpus also are different from the general gpus why",
    "start": "1672000",
    "end": "1678480"
  },
  {
    "text": "because they are dedicated for training special kind of machine learning and AI",
    "start": "1678480",
    "end": "1684640"
  },
  {
    "text": "jobs and they are much more costlier in nature and we don't want to waste those",
    "start": "1684640",
    "end": "1690480"
  },
  {
    "text": "special gpus by running other GPU jobs or the jobs which don't require any",
    "start": "1690480",
    "end": "1697480"
  },
  {
    "text": "GPU so in this diagram if you can see we have three types of ports Parts which",
    "start": "1697480",
    "end": "1703519"
  },
  {
    "text": "require only CPU in green color Parts which require general gpus which means they can run on",
    "start": "1703519",
    "end": "1710120"
  },
  {
    "text": "any GPU and ports which require special gpus in pink",
    "start": "1710120",
    "end": "1717360"
  },
  {
    "text": "color so we have simulated we have shown here two scenarios which and and both of",
    "start": "1717360",
    "end": "1723880"
  },
  {
    "text": "these are not ideal for us first one all the CPU only ports or",
    "start": "1723880",
    "end": "1730399"
  },
  {
    "text": "the general GPU ports or the special GPU Parts all of them get placed on the",
    "start": "1730399",
    "end": "1736039"
  },
  {
    "text": "special GPU notes and that's a vage in the second one if you",
    "start": "1736039",
    "end": "1742159"
  },
  {
    "text": "see the CPU only part is getting placed on the GPU pod GPU node that is again",
    "start": "1742159",
    "end": "1748880"
  },
  {
    "text": "vestage of Hardware so how we solve this",
    "start": "1748880",
    "end": "1754200"
  },
  {
    "text": "problem so we have implemented pair of schedul plugins called",
    "start": "1754480",
    "end": "1761799"
  },
  {
    "text": "Global CPU GPU management filter and a special GPU management filter",
    "start": "1761799",
    "end": "1768000"
  },
  {
    "text": "Global GPU management filter actually filters out all the GPU",
    "start": "1768000",
    "end": "1773240"
  },
  {
    "text": "nodes whenever part is requiring only CPU and it doesn't let these CPU Parts",
    "start": "1773240",
    "end": "1780960"
  },
  {
    "text": "being placed on any GPU noes the special GPU management",
    "start": "1780960",
    "end": "1787080"
  },
  {
    "text": "filter filters out all the special GPU nodes from a scheduling for",
    "start": "1787080",
    "end": "1795200"
  },
  {
    "text": "any any part that requires any general GPU and at the end we have node level",
    "start": "1795200",
    "end": "1803200"
  },
  {
    "text": "selectors which actually matches the special GPU pod to the special GPU",
    "start": "1803200",
    "end": "1808919"
  },
  {
    "text": "notes and that way we are able to correctly place the CPU ports to the CPU",
    "start": "1808919",
    "end": "1815880"
  },
  {
    "text": "nodes General GPU ports to the general GPU nodes and the special G GPU parts to the",
    "start": "1815880",
    "end": "1824159"
  },
  {
    "text": "special GPU notes and we don't waste any of the costly",
    "start": "1824159",
    "end": "1829840"
  },
  {
    "text": "Hardware by executing the parts which don't require",
    "start": "1829840",
    "end": "1835679"
  },
  {
    "text": "them next coming to the Future work so far we have solved the problems",
    "start": "1836799",
    "end": "1843440"
  },
  {
    "text": "of running batch workloads on coets for machine learning jobs by Michelangelo data science work EV and the spark",
    "start": "1843440",
    "end": "1851840"
  },
  {
    "text": "jobs next year we are going to Target Presto aache Flink",
    "start": "1851840",
    "end": "1858080"
  },
  {
    "text": "and our internal pipeline execution framework Piper and all these will be run on",
    "start": "1858080",
    "end": "1865399"
  },
  {
    "text": "Coes so we are targeting all these Solutions running on kubernetes on the shared clusters Inc",
    "start": "1865399",
    "end": "1873039"
  },
  {
    "text": "coming year that's all we had for today thanks all of you for Patiently",
    "start": "1873039",
    "end": "1880679"
  },
  {
    "text": "listening to us please share your feedback on this QR code thank",
    "start": "1880679",
    "end": "1886159"
  },
  {
    "text": "you if you have any questions",
    "start": "1886159",
    "end": "1892760"
  },
  {
    "text": "please uh for placing pots on uh CPU noes and GPU noes uh kubernetes already",
    "start": "1893639",
    "end": "1900080"
  },
  {
    "text": "has stains tolerations no definity right so what made you implement schedule",
    "start": "1900080",
    "end": "1905120"
  },
  {
    "text": "plugins beyond that so 10 tolerations are certainly one alternative uh we did",
    "start": "1905120",
    "end": "1910279"
  },
  {
    "text": "consider those in our design discussions MH um we wanted to keep it controlled",
    "start": "1910279",
    "end": "1916840"
  },
  {
    "text": "mostly on the platform site so the customers of the platform group actually who are consuming the solutions they",
    "start": "1916840",
    "end": "1923200"
  },
  {
    "text": "don't have to do much changes and that was the reason we wanted to implement it on the through the schedu",
    "start": "1923200",
    "end": "1930159"
  },
  {
    "text": "plugins so the parts coming from the customer they don't have they don't have any Toler in the",
    "start": "1930159",
    "end": "1937039"
  },
  {
    "text": "they don't have to do any changes actually okay thank you um I have a question about how the",
    "start": "1937039",
    "end": "1944279"
  },
  {
    "text": "regional resource manager works so it sounds like it sort of Aggregates",
    "start": "1944279",
    "end": "1950760"
  },
  {
    "text": "within different zones but does this assume that jobs can be disrupted and moved across the",
    "start": "1950760",
    "end": "1956880"
  },
  {
    "text": "zones um if you understand what I mean yeah go ahead yeah does that make sense",
    "start": "1956880",
    "end": "1962240"
  },
  {
    "text": "does it assume jobs are preemptable when sort of aggregating across zones and you",
    "start": "1962240",
    "end": "1967440"
  },
  {
    "text": "know dynamically sizing the resource pools yeah so jobs are certainly most of",
    "start": "1967440",
    "end": "1975080"
  },
  {
    "text": "them are preemptable I agree with you but the resource pools to which they are",
    "start": "1975080",
    "end": "1980120"
  },
  {
    "text": "being submitted if they are present only certain Zone and if that drone itself is",
    "start": "1980120",
    "end": "1986720"
  },
  {
    "text": "not available that means that the hardware capacity that particular team reserved for themsel and that was",
    "start": "1986720",
    "end": "1993159"
  },
  {
    "text": "captured bya resource pool that will not be available so once we moved the resource pool itself to the regional",
    "start": "1993159",
    "end": "1998960"
  },
  {
    "text": "level that availability problem got solved if that was a question yeah I guess I'm more interested in when you're",
    "start": "1998960",
    "end": "2006000"
  },
  {
    "text": "doing defragmentation do you assume jobs are preemptable and move them between zones uh in order to",
    "start": "2006000",
    "end": "2012519"
  },
  {
    "text": "sort of you know we do assume that jobs are Preble okay thank",
    "start": "2012519",
    "end": "2018760"
  },
  {
    "text": "you thank you for the talk really interesting um I have a question about the preemption uh that you use to",
    "start": "2018760",
    "end": "2024440"
  },
  {
    "text": "reclaim resources that were Borrowed by another uh resource pool do you use the",
    "start": "2024440",
    "end": "2029919"
  },
  {
    "text": "kubernetes native priority for pods or do you have your own priority logic implemented in the resource um manager",
    "start": "2029919",
    "end": "2037679"
  },
  {
    "text": "yeah that's a good question so we do Implement our own uh resource manager logic so basically we tag the pod in",
    "start": "2037679",
    "end": "2044840"
  },
  {
    "text": "terms whether it's paramet worklow or not then based on the the actually we use The annotation So based on",
    "start": "2044840",
    "end": "2050679"
  },
  {
    "text": "annotation we the resource manager will decide whether the part is pable or not",
    "start": "2050679",
    "end": "2056200"
  },
  {
    "text": "cool thank you um hi this is on cloud right this is",
    "start": "2056200",
    "end": "2062000"
  },
  {
    "text": "not private cluster so right now we solved it on on pem but the hardware",
    "start": "2062000",
    "end": "2067358"
  },
  {
    "text": "layer as you saw in the first diagram itself was provided by unified layer called crane hostage service so it",
    "start": "2067359",
    "end": "2074520"
  },
  {
    "text": "should work equally good on frame or Cloud the reason I ask is because if it",
    "start": "2074520",
    "end": "2079560"
  },
  {
    "text": "was cloud and you could have done version one and have a cluster autoscaler to manage the size of cluster",
    "start": "2079560",
    "end": "2086158"
  },
  {
    "text": "there's no reason why a zonal cluster should be limited in size right so size was not a problem at all in zonal nature",
    "start": "2086159",
    "end": "2092638"
  },
  {
    "text": "also we were able to create clusters of 3,000 4,000 notes then why couldn't the cluster autoscaler solve the problem why",
    "start": "2092639",
    "end": "2099760"
  },
  {
    "text": "did you have to move the jobs and do all those so a of course um when someone",
    "start": "2099760",
    "end": "2105359"
  },
  {
    "text": "reserves a capacity using the resource pools and if they're reserving within a Zone only if that zone itself is not",
    "start": "2105359",
    "end": "2111920"
  },
  {
    "text": "available it's possible Right most of theity zone go down and then the probability of aity Zone going down is",
    "start": "2111920",
    "end": "2118800"
  },
  {
    "text": "much higher than the probability of whole region going down okay so it's mainly from availability perspective",
    "start": "2118800",
    "end": "2125880"
  },
  {
    "text": "resource optimiz perspective okay yeah yeah thank you",
    "start": "2125880",
    "end": "2131480"
  }
]
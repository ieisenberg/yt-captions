[
  {
    "start": "0",
    "end": "16000"
  },
  {
    "text": "hi I'm here to talk about sharing a GPU",
    "start": "0",
    "end": "2010"
  },
  {
    "text": "among multiple containers first as we",
    "start": "2010",
    "end": "5009"
  },
  {
    "text": "said I'm Patrick McCleary and I've been",
    "start": "5009",
    "end": "6390"
  },
  {
    "text": "working at algorithm yes since 2015 we",
    "start": "6390",
    "end": "9120"
  },
  {
    "text": "run a machine learning and model",
    "start": "9120",
    "end": "10650"
  },
  {
    "text": "deployment serving scaling and",
    "start": "10650",
    "end": "12269"
  },
  {
    "text": "management platform and been working",
    "start": "12269",
    "end": "13980"
  },
  {
    "text": "with GPUs and cuber Nettie since 2016",
    "start": "13980",
    "end": "16490"
  },
  {
    "start": "16000",
    "end": "39000"
  },
  {
    "text": "the stock is focused on this issue from",
    "start": "16490",
    "end": "18869"
  },
  {
    "text": "kubernetes",
    "start": "18869",
    "end": "19500"
  },
  {
    "text": "is sharing a GPU to multiple containers",
    "start": "19500",
    "end": "21210"
  },
  {
    "text": "feasible as the goal is to share a",
    "start": "21210",
    "end": "23820"
  },
  {
    "text": "single GPU device among multiple",
    "start": "23820",
    "end": "25439"
  },
  {
    "text": "containers on the same virtual machine",
    "start": "25439",
    "end": "27539"
  },
  {
    "text": "as you can see there's a lot of comments",
    "start": "27539",
    "end": "29340"
  },
  {
    "text": "and reactions however this issue has",
    "start": "29340",
    "end": "31080"
  },
  {
    "text": "been open for over two years at this",
    "start": "31080",
    "end": "32520"
  },
  {
    "text": "point so I'm going to talk about why is",
    "start": "32520",
    "end": "34230"
  },
  {
    "text": "this difficult and what can you do today",
    "start": "34230",
    "end": "38120"
  },
  {
    "start": "39000",
    "end": "57000"
  },
  {
    "text": "it's questions often asked because",
    "start": "39230",
    "end": "41280"
  },
  {
    "text": "people want to know how to do machine",
    "start": "41280",
    "end": "42540"
  },
  {
    "text": "learning on kubernetes and in particular",
    "start": "42540",
    "end": "44489"
  },
  {
    "text": "use things like neural networks so",
    "start": "44489",
    "end": "46739"
  },
  {
    "text": "neural networks can take a long time to",
    "start": "46739",
    "end": "48690"
  },
  {
    "text": "train and execute on standard CPU",
    "start": "48690",
    "end": "50579"
  },
  {
    "text": "hardware but GPUs are specialized",
    "start": "50579",
    "end": "52530"
  },
  {
    "text": "hardware that can paralyze these",
    "start": "52530",
    "end": "54180"
  },
  {
    "text": "operations and drastically speed up this",
    "start": "54180",
    "end": "55980"
  },
  {
    "text": "process however cloud instances with",
    "start": "55980",
    "end": "58920"
  },
  {
    "start": "57000",
    "end": "77000"
  },
  {
    "text": "GPUs are substantially more expensive",
    "start": "58920",
    "end": "60270"
  },
  {
    "text": "than the CPU counterparts depending on",
    "start": "60270",
    "end": "63000"
  },
  {
    "text": "the instance type you might spend 10 X",
    "start": "63000",
    "end": "64500"
  },
  {
    "text": "or more on what you're used to spending",
    "start": "64500",
    "end": "66260"
  },
  {
    "text": "additionally cloud providers often have",
    "start": "66260",
    "end": "68430"
  },
  {
    "text": "fewer machines readily available in some",
    "start": "68430",
    "end": "70229"
  },
  {
    "text": "regions don't have any availability at",
    "start": "70229",
    "end": "71790"
  },
  {
    "text": "all so you want to be able to do as much",
    "start": "71790",
    "end": "73560"
  },
  {
    "text": "as possible with a limited set of",
    "start": "73560",
    "end": "74880"
  },
  {
    "text": "resources so what's the problem so",
    "start": "74880",
    "end": "79799"
  },
  {
    "start": "77000",
    "end": "97000"
  },
  {
    "text": "unlike other hardware resources the",
    "start": "79799",
    "end": "82049"
  },
  {
    "text": "hardware and operating system do not",
    "start": "82049",
    "end": "83369"
  },
  {
    "text": "support virtualization in the same way",
    "start": "83369",
    "end": "85140"
  },
  {
    "text": "so while you might be used to things",
    "start": "85140",
    "end": "86700"
  },
  {
    "text": "like virtual memory which virtualizes",
    "start": "86700",
    "end": "88530"
  },
  {
    "text": "physical hosts ram there isn't the same",
    "start": "88530",
    "end": "90570"
  },
  {
    "text": "type of thing for a GPU memory so",
    "start": "90570",
    "end": "92759"
  },
  {
    "text": "there's not the same isolation between",
    "start": "92759",
    "end": "94079"
  },
  {
    "text": "processes and you can't do things like",
    "start": "94079",
    "end": "95790"
  },
  {
    "text": "uber provision and you swap space",
    "start": "95790",
    "end": "97790"
  },
  {
    "start": "97000",
    "end": "165000"
  },
  {
    "text": "there's also difficulty limiting access",
    "start": "97790",
    "end": "100229"
  },
  {
    "text": "to the GPU so the Linux kernel has",
    "start": "100229",
    "end": "102810"
  },
  {
    "text": "control groups are called C groups which",
    "start": "102810",
    "end": "105090"
  },
  {
    "text": "can limit processes CPU Ram name spacing",
    "start": "105090",
    "end": "109649"
  },
  {
    "text": "and a whole bunch of other things this",
    "start": "109649",
    "end": "111450"
  },
  {
    "text": "is the mechanism that's used to enforce",
    "start": "111450",
    "end": "113070"
  },
  {
    "text": "pod limits in kubernetes but there's no",
    "start": "113070",
    "end": "115140"
  },
  {
    "text": "such C group with implementation for GPU",
    "start": "115140",
    "end": "117329"
  },
  {
    "text": "memory or other resources there's been",
    "start": "117329",
    "end": "120509"
  },
  {
    "text": "some RFC's from vendors but it's still a",
    "start": "120509",
    "end": "122399"
  },
  {
    "text": "long ways off before those get folded",
    "start": "122399",
    "end": "123930"
  },
  {
    "text": "into a Linux kernel and become generally",
    "start": "123930",
    "end": "125640"
  },
  {
    "text": "available for other people in public",
    "start": "125640",
    "end": "127259"
  },
  {
    "text": "like us additionally when multiple",
    "start": "127259",
    "end": "129899"
  },
  {
    "text": "processes need to access the GPU only",
    "start": "129899",
    "end": "131940"
  },
  {
    "text": "one can run out of time and there's",
    "start": "131940",
    "end": "133440"
  },
  {
    "text": "context switching problem to load the",
    "start": "133440",
    "end": "135030"
  },
  {
    "text": "CUDA context for one process on and the",
    "start": "135030",
    "end": "136890"
  },
  {
    "text": "other went off so even if a device has",
    "start": "136890",
    "end": "139290"
  },
  {
    "text": "capacity to run it might be more",
    "start": "139290",
    "end": "140940"
  },
  {
    "text": "efficient to run things and serially",
    "start": "140940",
    "end": "142890"
  },
  {
    "text": "rather than in parallel to alleviate",
    "start": "142890",
    "end": "146040"
  },
  {
    "text": "context switching NVIDIA has MPs it's a",
    "start": "146040",
    "end": "148650"
  },
  {
    "text": "way to share a single CUDA context",
    "start": "148650",
    "end": "150570"
  },
  {
    "text": "between multiple processes which know so",
    "start": "150570",
    "end": "153180"
  },
  {
    "text": "you no longer have to actually pay that",
    "start": "153180",
    "end": "154860"
  },
  {
    "text": "context switching penalty however if one",
    "start": "154860",
    "end": "157410"
  },
  {
    "text": "process throws an exception all",
    "start": "157410",
    "end": "158880"
  },
  {
    "text": "processes will halt running at the same",
    "start": "158880",
    "end": "161010"
  },
  {
    "text": "time so it's not a great fit for all",
    "start": "161010",
    "end": "162630"
  },
  {
    "text": "workloads in particular if they're",
    "start": "162630",
    "end": "164130"
  },
  {
    "text": "really mixed so what does kubernetes",
    "start": "164130",
    "end": "166680"
  },
  {
    "start": "165000",
    "end": "198000"
  },
  {
    "text": "support kubernetes has device plugins so",
    "start": "166680",
    "end": "170970"
  },
  {
    "text": "the operator or a cluster has to make",
    "start": "170970",
    "end": "172560"
  },
  {
    "text": "sure that all nodes are the nodes in the",
    "start": "172560",
    "end": "174180"
  },
  {
    "text": "cluster have drivers runtimes or",
    "start": "174180",
    "end": "176550"
  },
  {
    "text": "whatever they may need in order to",
    "start": "176550",
    "end": "177810"
  },
  {
    "text": "actually support the device once you've",
    "start": "177810",
    "end": "179850"
  },
  {
    "text": "done that you have to configure the",
    "start": "179850",
    "end": "181230"
  },
  {
    "text": "cubelet to actually declare that I have",
    "start": "181230",
    "end": "183060"
  },
  {
    "text": "this device available to the kubernetes",
    "start": "183060",
    "end": "184620"
  },
  {
    "text": "api server at that point in time pods",
    "start": "184620",
    "end": "187500"
  },
  {
    "text": "can request to use a device in the",
    "start": "187500",
    "end": "189480"
  },
  {
    "text": "kubernetes scheduler will make sure that",
    "start": "189480",
    "end": "191370"
  },
  {
    "text": "pods will only run on nodes that have a",
    "start": "191370",
    "end": "193050"
  },
  {
    "text": "device available however it does not",
    "start": "193050",
    "end": "195030"
  },
  {
    "text": "allow it for sharing of devices at this",
    "start": "195030",
    "end": "196830"
  },
  {
    "text": "point in time",
    "start": "196830",
    "end": "197930"
  },
  {
    "text": "so if your brew Nettie's is great at",
    "start": "197930",
    "end": "199980"
  },
  {
    "start": "198000",
    "end": "226000"
  },
  {
    "text": "assigning pods to nodes based on all",
    "start": "199980",
    "end": "201720"
  },
  {
    "text": "these complex resource constraints and",
    "start": "201720",
    "end": "203400"
  },
  {
    "text": "it's also extensible so you can extend",
    "start": "203400",
    "end": "205830"
  },
  {
    "text": "what the definition of a resource might",
    "start": "205830",
    "end": "207480"
  },
  {
    "text": "be and you can also extend the scheduler",
    "start": "207480",
    "end": "209700"
  },
  {
    "text": "and you can choose the way to change the",
    "start": "209700",
    "end": "211470"
  },
  {
    "text": "way that it prioritizes or filters out",
    "start": "211470",
    "end": "213360"
  },
  {
    "text": "nodes for running a given pod if you",
    "start": "213360",
    "end": "216330"
  },
  {
    "text": "combine these components together you",
    "start": "216330",
    "end": "217980"
  },
  {
    "text": "can build your own custom resource",
    "start": "217980",
    "end": "219330"
  },
  {
    "text": "management system such as the GPU share",
    "start": "219330",
    "end": "221400"
  },
  {
    "text": "scheduler extender listed here it's also",
    "start": "221400",
    "end": "223830"
  },
  {
    "text": "on that github issue that I linked out",
    "start": "223830",
    "end": "225450"
  },
  {
    "text": "earlier however just because something",
    "start": "225450",
    "end": "228540"
  },
  {
    "start": "226000",
    "end": "257000"
  },
  {
    "text": "is possible doesn't mean that it will",
    "start": "228540",
    "end": "229620"
  },
  {
    "text": "solve all of your problems overnight so",
    "start": "229620",
    "end": "231690"
  },
  {
    "text": "running multiple jobs in parallel may",
    "start": "231690",
    "end": "233459"
  },
  {
    "text": "negatively impact throughput as I",
    "start": "233459",
    "end": "235620"
  },
  {
    "text": "mentioned so you need some performance",
    "start": "235620",
    "end": "237480"
  },
  {
    "text": "monitoring to make sure that everything",
    "start": "237480",
    "end": "238890"
  },
  {
    "text": "is still running the way you expect it",
    "start": "238890",
    "end": "240330"
  },
  {
    "text": "to",
    "start": "240330",
    "end": "240750"
  },
  {
    "text": "and without cgroups limits are not",
    "start": "240750",
    "end": "242610"
  },
  {
    "text": "guaranteed so a process can actually",
    "start": "242610",
    "end": "244680"
  },
  {
    "text": "consume more memory than you might have",
    "start": "244680",
    "end": "245940"
  },
  {
    "text": "scheduled it for and so processes might",
    "start": "245940",
    "end": "247950"
  },
  {
    "text": "interfere with each other in ways you",
    "start": "247950",
    "end": "249269"
  },
  {
    "text": "don't expect and so you also need to",
    "start": "249269",
    "end": "251850"
  },
  {
    "text": "track the actual resource consumption of",
    "start": "251850",
    "end": "254130"
  },
  {
    "text": "a pod and build additional safeguards in",
    "start": "254130",
    "end": "255959"
  },
  {
    "text": "monitoring so hopefully you understand",
    "start": "255959",
    "end": "259169"
  },
  {
    "start": "257000",
    "end": "281000"
  },
  {
    "text": "some of the challenges of sharing GPUs",
    "start": "259169",
    "end": "260880"
  },
  {
    "text": "on kubernetes now namely isolation and",
    "start": "260880",
    "end": "263220"
  },
  {
    "text": "parallelism are difficult with GPU",
    "start": "263220",
    "end": "265080"
  },
  {
    "text": "devices however queue brunet",
    "start": "265080",
    "end": "266970"
  },
  {
    "text": "is flexible and makes anything really",
    "start": "266970",
    "end": "268590"
  },
  {
    "text": "possible but you need to be able to",
    "start": "268590",
    "end": "270240"
  },
  {
    "text": "monitor your workloads before you can",
    "start": "270240",
    "end": "271770"
  },
  {
    "text": "fully benefit so thanks and for more",
    "start": "271770",
    "end": "274890"
  },
  {
    "text": "information on how we do this come stop",
    "start": "274890",
    "end": "276450"
  },
  {
    "text": "by algorithm Youth over the next couple",
    "start": "276450",
    "end": "278220"
  },
  {
    "text": "of days",
    "start": "278220",
    "end": "279760"
  },
  {
    "text": "[Applause]",
    "start": "279760",
    "end": "282910"
  }
]
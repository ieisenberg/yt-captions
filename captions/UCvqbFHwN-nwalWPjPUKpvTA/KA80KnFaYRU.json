[
  {
    "text": "hello everyone welcome to our talk",
    "start": "560",
    "end": "2480"
  },
  {
    "text": "resource orchestration of hpc on",
    "start": "2480",
    "end": "4319"
  },
  {
    "text": "kubernetes where we are now in the",
    "start": "4319",
    "end": "6399"
  },
  {
    "text": "journey ahead",
    "start": "6399",
    "end": "8080"
  },
  {
    "text": "i'm swati seigel i'm a principal",
    "start": "8080",
    "end": "10000"
  },
  {
    "text": "software engineer working for red hat",
    "start": "10000",
    "end": "12559"
  },
  {
    "text": "i am francesco romani i'm a principal",
    "start": "12559",
    "end": "14320"
  },
  {
    "text": "software engineer working with it",
    "start": "14320",
    "end": "17199"
  },
  {
    "text": "we've been contributing to kubernetes",
    "start": "17199",
    "end": "19039"
  },
  {
    "text": "and openshift for accelerating and",
    "start": "19039",
    "end": "20800"
  },
  {
    "text": "evangelizing telco features and",
    "start": "20800",
    "end": "22720"
  },
  {
    "text": "requirements in the upstream community",
    "start": "22720",
    "end": "25359"
  },
  {
    "text": "our team has been focused on resource",
    "start": "25359",
    "end": "27199"
  },
  {
    "text": "management capabilities like no more",
    "start": "27199",
    "end": "29199"
  },
  {
    "text": "awareness hyper threading and cubelet",
    "start": "29199",
    "end": "31439"
  },
  {
    "text": "resource management",
    "start": "31439",
    "end": "32960"
  },
  {
    "text": "and we we aim to enable our customers",
    "start": "32960",
    "end": "36160"
  },
  {
    "text": "and partners to run performance",
    "start": "36160",
    "end": "37920"
  },
  {
    "text": "sensitive next generation workloads",
    "start": "37920",
    "end": "41760"
  },
  {
    "text": "in terms of the current landscape even",
    "start": "41760",
    "end": "43840"
  },
  {
    "text": "though we've been focused on telco some",
    "start": "43840",
    "end": "46079"
  },
  {
    "text": "of the problems that we have encountered",
    "start": "46079",
    "end": "47920"
  },
  {
    "text": "and are trying to solve are not only",
    "start": "47920",
    "end": "49760"
  },
  {
    "text": "irrelevant to telco but also to other",
    "start": "49760",
    "end": "51600"
  },
  {
    "text": "wide range of workloads we believe that",
    "start": "51600",
    "end": "53760"
  },
  {
    "text": "hpc workloads can benefit from some of",
    "start": "53760",
    "end": "55760"
  },
  {
    "text": "the work that we've been doing",
    "start": "55760",
    "end": "57680"
  },
  {
    "text": "and",
    "start": "57680",
    "end": "58719"
  },
  {
    "text": "and that's why we're here",
    "start": "58719",
    "end": "61280"
  },
  {
    "text": "for the talk today we would primarily be",
    "start": "61280",
    "end": "63280"
  },
  {
    "text": "focusing on workloads that care about",
    "start": "63280",
    "end": "64960"
  },
  {
    "text": "normal alignment of resources we try to",
    "start": "64960",
    "end": "67439"
  },
  {
    "text": "demystify some of the resource",
    "start": "67439",
    "end": "68960"
  },
  {
    "text": "management concepts in kubernetes",
    "start": "68960",
    "end": "71439"
  },
  {
    "text": "and our aim for the talk is to point you",
    "start": "71439",
    "end": "73520"
  },
  {
    "text": "to the right direction give you the",
    "start": "73520",
    "end": "74960"
  },
  {
    "text": "right tools and essentially allow you to",
    "start": "74960",
    "end": "77840"
  },
  {
    "text": "get your hands dirty to enable room",
    "start": "77840",
    "end": "79600"
  },
  {
    "text": "aware scheduler in your cluster",
    "start": "79600",
    "end": "83040"
  },
  {
    "text": "so for performance critical workloads",
    "start": "84240",
    "end": "86479"
  },
  {
    "text": "typically um they have very strict",
    "start": "86479",
    "end": "89040"
  },
  {
    "text": "resource requirement so it is required",
    "start": "89040",
    "end": "91520"
  },
  {
    "text": "that the resources such as cpu memory",
    "start": "91520",
    "end": "93680"
  },
  {
    "text": "and devices be allocated from the same",
    "start": "93680",
    "end": "96159"
  },
  {
    "text": "luma node for optimal performance",
    "start": "96159",
    "end": "98640"
  },
  {
    "text": "from resource management perspective",
    "start": "98640",
    "end": "100240"
  },
  {
    "text": "within cubelet we have cpu manager",
    "start": "100240",
    "end": "102479"
  },
  {
    "text": "device manager and memory manager that",
    "start": "102479",
    "end": "104880"
  },
  {
    "text": "are responsible for allocating cpus",
    "start": "104880",
    "end": "106960"
  },
  {
    "text": "devices and memory or huge pages",
    "start": "106960",
    "end": "108880"
  },
  {
    "text": "respectively and topology manager",
    "start": "108880",
    "end": "111600"
  },
  {
    "text": "gathers hints from resource managers and",
    "start": "111600",
    "end": "114000"
  },
  {
    "text": "based on the configured policy aligns",
    "start": "114000",
    "end": "116399"
  },
  {
    "text": "them on the same note",
    "start": "116399",
    "end": "119840"
  },
  {
    "text": "now numa unaware scheduler even though",
    "start": "120000",
    "end": "122399"
  },
  {
    "text": "we have the ability to align",
    "start": "122399",
    "end": "124479"
  },
  {
    "text": "the resources at node level the",
    "start": "124479",
    "end": "126799"
  },
  {
    "text": "scheduler is not no aware we have a few",
    "start": "126799",
    "end": "129520"
  },
  {
    "text": "challenges and pain points that need to",
    "start": "129520",
    "end": "131200"
  },
  {
    "text": "be addressed some of those are the first",
    "start": "131200",
    "end": "133840"
  },
  {
    "text": "one is that the scheduler lacks",
    "start": "133840",
    "end": "136160"
  },
  {
    "text": "visibility into resource availability on",
    "start": "136160",
    "end": "138720"
  },
  {
    "text": "a per number basis",
    "start": "138720",
    "end": "141200"
  },
  {
    "text": "the second one is that the cube root",
    "start": "141200",
    "end": "143280"
  },
  {
    "text": "rejection loop can cause delays in pod",
    "start": "143280",
    "end": "145520"
  },
  {
    "text": "life cycle",
    "start": "145520",
    "end": "146800"
  },
  {
    "text": "especially for low latency workloads",
    "start": "146800",
    "end": "148560"
  },
  {
    "text": "this can be um detrimental in the fact",
    "start": "148560",
    "end": "151200"
  },
  {
    "text": "that you know it can impact the sla",
    "start": "151200",
    "end": "154560"
  },
  {
    "text": "and the performance of the workload",
    "start": "154560",
    "end": "156319"
  },
  {
    "text": "itself",
    "start": "156319",
    "end": "157360"
  },
  {
    "text": "the third one is the unbounded amount of",
    "start": "157360",
    "end": "159440"
  },
  {
    "text": "aeropods that need to be cleaned up",
    "start": "159440",
    "end": "161920"
  },
  {
    "text": "let's double click on each of these pain",
    "start": "161920",
    "end": "163680"
  },
  {
    "text": "points to understand them better",
    "start": "163680",
    "end": "167040"
  },
  {
    "text": "the dynamics between topology manager",
    "start": "167280",
    "end": "170000"
  },
  {
    "text": "and scheduler is very interesting here",
    "start": "170000",
    "end": "172319"
  },
  {
    "text": "because in a way we now have two",
    "start": "172319",
    "end": "173840"
  },
  {
    "text": "schedulers",
    "start": "173840",
    "end": "175040"
  },
  {
    "text": "the cube scheduler which is the main one",
    "start": "175040",
    "end": "176800"
  },
  {
    "text": "and the topology manager which operates",
    "start": "176800",
    "end": "179040"
  },
  {
    "text": "at a node level and is responsible for",
    "start": "179040",
    "end": "181519"
  },
  {
    "text": "identifying the suitable noma node and",
    "start": "181519",
    "end": "183920"
  },
  {
    "text": "allocating the resources essentially",
    "start": "183920",
    "end": "186319"
  },
  {
    "text": "acting like a mini scheduler within",
    "start": "186319",
    "end": "188239"
  },
  {
    "text": "cubelet",
    "start": "188239",
    "end": "189599"
  },
  {
    "text": "since it is the responsibility of the",
    "start": "189599",
    "end": "192000"
  },
  {
    "text": "scheduler",
    "start": "192000",
    "end": "193760"
  },
  {
    "text": "to make sure that the pods land on the",
    "start": "193760",
    "end": "195599"
  },
  {
    "text": "node and topology manager to allocate",
    "start": "195599",
    "end": "198239"
  },
  {
    "text": "the resources the scheduler has very",
    "start": "198239",
    "end": "200720"
  },
  {
    "text": "less control over workload placement",
    "start": "200720",
    "end": "202720"
  },
  {
    "text": "within the node and the subsequent",
    "start": "202720",
    "end": "204959"
  },
  {
    "text": "resource allocation",
    "start": "204959",
    "end": "206640"
  },
  {
    "text": "in addition to that it doesn't consider",
    "start": "206640",
    "end": "208879"
  },
  {
    "text": "the topology manager policy configured",
    "start": "208879",
    "end": "210879"
  },
  {
    "text": "on the node and whether or not those",
    "start": "210879",
    "end": "213040"
  },
  {
    "text": "resources can fit on the same new node",
    "start": "213040",
    "end": "215519"
  },
  {
    "text": "so essentially it can place a pod on a",
    "start": "215519",
    "end": "218000"
  },
  {
    "text": "node where topology manager can simply",
    "start": "218000",
    "end": "220159"
  },
  {
    "text": "reject it with the topology affinity",
    "start": "220159",
    "end": "221920"
  },
  {
    "text": "error",
    "start": "221920",
    "end": "224159"
  },
  {
    "text": "but unfortunately with the current",
    "start": "224159",
    "end": "225519"
  },
  {
    "text": "design we can do much better",
    "start": "225519",
    "end": "228799"
  },
  {
    "text": "the second pain point is um is related",
    "start": "228799",
    "end": "231599"
  },
  {
    "text": "to the cubelet rejection loop if a pod",
    "start": "231599",
    "end": "234239"
  },
  {
    "text": "is part of a deployment or replica set",
    "start": "234239",
    "end": "236640"
  },
  {
    "text": "we have uh and we have the topology",
    "start": "236640",
    "end": "239280"
  },
  {
    "text": "manager configured with a single moment",
    "start": "239280",
    "end": "241120"
  },
  {
    "text": "policy we can end up with a runaway part",
    "start": "241120",
    "end": "243840"
  },
  {
    "text": "creation",
    "start": "243840",
    "end": "244879"
  },
  {
    "text": "the reason behind that is since",
    "start": "244879",
    "end": "247519"
  },
  {
    "text": "nothing has changed on the node from",
    "start": "247519",
    "end": "249200"
  },
  {
    "text": "resource perspective",
    "start": "249200",
    "end": "250879"
  },
  {
    "text": "and the pod has failed at the admission",
    "start": "250879",
    "end": "253040"
  },
  {
    "text": "time the subsequent pods created by the",
    "start": "253040",
    "end": "255519"
  },
  {
    "text": "replica set controller and are being",
    "start": "255519",
    "end": "257759"
  },
  {
    "text": "placed on the same node",
    "start": "257759",
    "end": "259840"
  },
  {
    "text": "with the same fate",
    "start": "259840",
    "end": "261359"
  },
  {
    "text": "and we end up resulting in a runway part",
    "start": "261359",
    "end": "263680"
  },
  {
    "text": "creation",
    "start": "263680",
    "end": "266000"
  },
  {
    "text": "this the third pain point is very",
    "start": "266000",
    "end": "268000"
  },
  {
    "text": "closely related to the second one",
    "start": "268000",
    "end": "270320"
  },
  {
    "text": "where we have runaway part creation and",
    "start": "270320",
    "end": "272320"
  },
  {
    "text": "essentially",
    "start": "272320",
    "end": "273600"
  },
  {
    "text": "what happens is because of the runaway",
    "start": "273600",
    "end": "275199"
  },
  {
    "text": "part creation we have a series of pods",
    "start": "275199",
    "end": "277360"
  },
  {
    "text": "that need to be cleaned up",
    "start": "277360",
    "end": "279199"
  },
  {
    "text": "even if eventually there's a pod that is",
    "start": "279199",
    "end": "281120"
  },
  {
    "text": "up and running the pods that feel",
    "start": "281120",
    "end": "283199"
  },
  {
    "text": "continue to exist on the cluster itself",
    "start": "283199",
    "end": "287680"
  },
  {
    "text": "you might say that this is clearly a",
    "start": "289040",
    "end": "291280"
  },
  {
    "text": "consequence of a spread split brain",
    "start": "291280",
    "end": "293680"
  },
  {
    "text": "problem",
    "start": "293680",
    "end": "294639"
  },
  {
    "text": "we don't",
    "start": "294639",
    "end": "295840"
  },
  {
    "text": "why don't we get rid of topology manager",
    "start": "295840",
    "end": "298080"
  },
  {
    "text": "the so-called mini scheduler",
    "start": "298080",
    "end": "300639"
  },
  {
    "text": "the answer to that would be we",
    "start": "300639",
    "end": "302479"
  },
  {
    "text": "theoretically could very well do that",
    "start": "302479",
    "end": "304800"
  },
  {
    "text": "but it's not that simple",
    "start": "304800",
    "end": "307039"
  },
  {
    "text": "in the current architecture it is an",
    "start": "307039",
    "end": "309280"
  },
  {
    "text": "intentional decision to keep the",
    "start": "309280",
    "end": "310960"
  },
  {
    "text": "hardware implementation and information",
    "start": "310960",
    "end": "313520"
  },
  {
    "text": "local to the node and the resource",
    "start": "313520",
    "end": "315520"
  },
  {
    "text": "managers within the cube that take care",
    "start": "315520",
    "end": "317280"
  },
  {
    "text": "of resource allocation and therefore",
    "start": "317280",
    "end": "319360"
  },
  {
    "text": "topology manager was placed there",
    "start": "319360",
    "end": "321840"
  },
  {
    "text": "in addition to that topology manager has",
    "start": "321840",
    "end": "323919"
  },
  {
    "text": "been with us since kubernetes",
    "start": "323919",
    "end": "326120"
  },
  {
    "text": "1.16 and it graduated to a beta feature",
    "start": "326120",
    "end": "329039"
  },
  {
    "text": "in 1.18 and preserving the existing",
    "start": "329039",
    "end": "331759"
  },
  {
    "text": "behavior and maintaining backward",
    "start": "331759",
    "end": "333759"
  },
  {
    "text": "compatibility is not going to be trivial",
    "start": "333759",
    "end": "337680"
  },
  {
    "text": "with no aware scheduling design we've",
    "start": "337680",
    "end": "340479"
  },
  {
    "text": "been trying to",
    "start": "340479",
    "end": "342560"
  },
  {
    "text": "make sure that we are taking incremental",
    "start": "342560",
    "end": "344479"
  },
  {
    "text": "steps and have an evolutionary approach",
    "start": "344479",
    "end": "347039"
  },
  {
    "text": "to come up with a solution that takes",
    "start": "347039",
    "end": "349360"
  },
  {
    "text": "care of all these concerns",
    "start": "349360",
    "end": "353240"
  },
  {
    "text": "so let's dive into no aware scheduling",
    "start": "353520",
    "end": "355520"
  },
  {
    "text": "now",
    "start": "355520",
    "end": "357520"
  },
  {
    "text": "before we dive into the architecture",
    "start": "357520",
    "end": "359280"
  },
  {
    "text": "it's important to understand the use",
    "start": "359280",
    "end": "361039"
  },
  {
    "text": "cases uh to understand the why behind",
    "start": "361039",
    "end": "363520"
  },
  {
    "text": "all the work that we've been doing",
    "start": "363520",
    "end": "365680"
  },
  {
    "text": "so",
    "start": "365680",
    "end": "366639"
  },
  {
    "text": "the first use case is workloads that",
    "start": "366639",
    "end": "369120"
  },
  {
    "text": "require specialized hardwares and that's",
    "start": "369120",
    "end": "370880"
  },
  {
    "text": "where hpc comes into picture this",
    "start": "370880",
    "end": "373440"
  },
  {
    "text": "includes hpc workloads that require",
    "start": "373440",
    "end": "376560"
  },
  {
    "text": "fpga gpus and want no more alignment of",
    "start": "376560",
    "end": "379919"
  },
  {
    "text": "the resources",
    "start": "379919",
    "end": "381360"
  },
  {
    "text": "there's another interesting use case",
    "start": "381360",
    "end": "383039"
  },
  {
    "text": "where you might want alignment of",
    "start": "383039",
    "end": "385120"
  },
  {
    "text": "multiple accelerators",
    "start": "385120",
    "end": "387680"
  },
  {
    "text": "gpu direct scheduling which which came",
    "start": "387680",
    "end": "389919"
  },
  {
    "text": "into light by wire sat it basically",
    "start": "389919",
    "end": "392560"
  },
  {
    "text": "requires multiple accelerators like gpu",
    "start": "392560",
    "end": "395120"
  },
  {
    "text": "and x for direct",
    "start": "395120",
    "end": "396880"
  },
  {
    "text": "gpu to nick transfers over pci",
    "start": "396880",
    "end": "399759"
  },
  {
    "text": "instead of going through cpus and it was",
    "start": "399759",
    "end": "402400"
  },
  {
    "text": "important that gpu nick and the cpu all",
    "start": "402400",
    "end": "405520"
  },
  {
    "text": "be allocated from the same luminor the",
    "start": "405520",
    "end": "408319"
  },
  {
    "text": "second piece here is the performance",
    "start": "408319",
    "end": "410160"
  },
  {
    "text": "sensitive workloads we've all heard",
    "start": "410160",
    "end": "412400"
  },
  {
    "text": "about",
    "start": "412400",
    "end": "413520"
  },
  {
    "text": "high throughput networking applications",
    "start": "413520",
    "end": "415440"
  },
  {
    "text": "for containerized 5g deployments",
    "start": "415440",
    "end": "418080"
  },
  {
    "text": "like",
    "start": "418080",
    "end": "419360"
  },
  {
    "text": "like other",
    "start": "419360",
    "end": "420800"
  },
  {
    "text": "container networking functions",
    "start": "420800",
    "end": "422880"
  },
  {
    "text": "uh we run user plane where packets need",
    "start": "422880",
    "end": "424880"
  },
  {
    "text": "to be processed with extremely high",
    "start": "424880",
    "end": "426560"
  },
  {
    "text": "bandwidth aligned with srv virtual",
    "start": "426560",
    "end": "428960"
  },
  {
    "text": "functions huge pages and cpu resources",
    "start": "428960",
    "end": "432880"
  },
  {
    "text": "to make sure all of them kind of are",
    "start": "432880",
    "end": "434560"
  },
  {
    "text": "aligned um the third piece is",
    "start": "434560",
    "end": "437199"
  },
  {
    "text": "applications that are sensitive to",
    "start": "437199",
    "end": "439520"
  },
  {
    "text": "the tlb misses these are applications",
    "start": "439520",
    "end": "441599"
  },
  {
    "text": "that have large memory working set or",
    "start": "441599",
    "end": "444240"
  },
  {
    "text": "sensitivity to memory access latency",
    "start": "444240",
    "end": "446800"
  },
  {
    "text": "examples of this includes database",
    "start": "446800",
    "end": "448560"
  },
  {
    "text": "management systems like mysql oracle",
    "start": "448560",
    "end": "451520"
  },
  {
    "text": "and packet processing systems like dptk",
    "start": "451520",
    "end": "456240"
  },
  {
    "text": "so now we'll dive into the nomo ware",
    "start": "457840",
    "end": "460000"
  },
  {
    "text": "scheduling solution and how it can be",
    "start": "460000",
    "end": "461759"
  },
  {
    "text": "enabled into kubernetes it's very",
    "start": "461759",
    "end": "464639"
  },
  {
    "text": "important to expose the resource",
    "start": "464639",
    "end": "466639"
  },
  {
    "text": "information with nominal granularity to",
    "start": "466639",
    "end": "468800"
  },
  {
    "text": "the scheduler and imparted the",
    "start": "468800",
    "end": "470879"
  },
  {
    "text": "intelligence to make use of the",
    "start": "470879",
    "end": "472560"
  },
  {
    "text": "information",
    "start": "472560",
    "end": "473680"
  },
  {
    "text": "provided to make a no more aware",
    "start": "473680",
    "end": "475599"
  },
  {
    "text": "scheduling decision",
    "start": "475599",
    "end": "477599"
  },
  {
    "text": "we we have enabled this in an out of t",
    "start": "477599",
    "end": "480160"
  },
  {
    "text": "solution in kubernetes and there are",
    "start": "480160",
    "end": "481919"
  },
  {
    "text": "three key components of the solution the",
    "start": "481919",
    "end": "484319"
  },
  {
    "text": "first one is",
    "start": "484319",
    "end": "485919"
  },
  {
    "text": "the new object node resource topology",
    "start": "485919",
    "end": "488000"
  },
  {
    "text": "crd",
    "start": "488000",
    "end": "489440"
  },
  {
    "text": "this is the crd based api to capture the",
    "start": "489440",
    "end": "492240"
  },
  {
    "text": "resource hardware topology of a node so",
    "start": "492240",
    "end": "495039"
  },
  {
    "text": "each node resource topology cr would",
    "start": "495039",
    "end": "497680"
  },
  {
    "text": "correspond to a node in the cluster",
    "start": "497680",
    "end": "500479"
  },
  {
    "text": "the second one is the node resource",
    "start": "500479",
    "end": "502240"
  },
  {
    "text": "topology updater agent",
    "start": "502240",
    "end": "504800"
  },
  {
    "text": "we needed an exporter component that you",
    "start": "504800",
    "end": "507440"
  },
  {
    "text": "know runs as a daemon on the node and",
    "start": "507440",
    "end": "509919"
  },
  {
    "text": "exposes resource information along with",
    "start": "509919",
    "end": "512479"
  },
  {
    "text": "the pneuma node granularity we",
    "start": "512479",
    "end": "514640"
  },
  {
    "text": "introduced a component called nfd",
    "start": "514640",
    "end": "516320"
  },
  {
    "text": "topology updater in node feature",
    "start": "516320",
    "end": "518159"
  },
  {
    "text": "discovery to do that as nfd is a",
    "start": "518159",
    "end": "520560"
  },
  {
    "text": "well-known node fleecing agent",
    "start": "520560",
    "end": "523279"
  },
  {
    "text": "we have another component called",
    "start": "523279",
    "end": "524800"
  },
  {
    "text": "resource topology exporter which was",
    "start": "524800",
    "end": "526480"
  },
  {
    "text": "custom built for gnome aware scheduling",
    "start": "526480",
    "end": "529120"
  },
  {
    "text": "in addition to this you could create",
    "start": "529120",
    "end": "530959"
  },
  {
    "text": "your own custom built exporter but you",
    "start": "530959",
    "end": "533519"
  },
  {
    "text": "have to make sure that",
    "start": "533519",
    "end": "535440"
  },
  {
    "text": "it conforms to the api",
    "start": "535440",
    "end": "538640"
  },
  {
    "text": "the third piece is the scheduler plug-in",
    "start": "538640",
    "end": "541279"
  },
  {
    "text": "we leveraged the scheduler framework to",
    "start": "541279",
    "end": "543519"
  },
  {
    "text": "create a scheduler plug-in that",
    "start": "543519",
    "end": "545040"
  },
  {
    "text": "implements filter and score extension",
    "start": "545040",
    "end": "547120"
  },
  {
    "text": "points to enhance the scheduling process",
    "start": "547120",
    "end": "550560"
  },
  {
    "text": "and make the scheduler more intelligent",
    "start": "550560",
    "end": "554880"
  },
  {
    "text": "now in terms of the end to end solution",
    "start": "555839",
    "end": "558399"
  },
  {
    "text": "we have the node resource topology api",
    "start": "558399",
    "end": "561760"
  },
  {
    "text": "we have the topology of data agents",
    "start": "561760",
    "end": "564720"
  },
  {
    "text": "and they use the power resource api to",
    "start": "564720",
    "end": "566640"
  },
  {
    "text": "gather information of the allocated",
    "start": "566640",
    "end": "569040"
  },
  {
    "text": "resources and the pneuma nodes",
    "start": "569040",
    "end": "571440"
  },
  {
    "text": "those allocated resources were come from",
    "start": "571440",
    "end": "575279"
  },
  {
    "text": "and this is done to determine the pure",
    "start": "575279",
    "end": "577680"
  },
  {
    "text": "numa available resources",
    "start": "577680",
    "end": "580240"
  },
  {
    "text": "these this information is essentially",
    "start": "580240",
    "end": "582320"
  },
  {
    "text": "exposed as crs",
    "start": "582320",
    "end": "584880"
  },
  {
    "text": "and it's available via the kubernetes",
    "start": "584880",
    "end": "587040"
  },
  {
    "text": "api",
    "start": "587040",
    "end": "588240"
  },
  {
    "text": "so now when a pod comes to the",
    "start": "588240",
    "end": "590160"
  },
  {
    "text": "kubernetes api server you essentially",
    "start": "590160",
    "end": "593200"
  },
  {
    "text": "have the topology aware scheduler",
    "start": "593200",
    "end": "594959"
  },
  {
    "text": "plug-in",
    "start": "594959",
    "end": "595920"
  },
  {
    "text": "uh that comes into picture it uses the",
    "start": "595920",
    "end": "598080"
  },
  {
    "text": "crs that's available via the api",
    "start": "598080",
    "end": "600880"
  },
  {
    "text": "and it makes a topology where scheduling",
    "start": "600880",
    "end": "603200"
  },
  {
    "text": "decision by running a simplified version",
    "start": "603200",
    "end": "605680"
  },
  {
    "text": "of topology manager alignment algorithm",
    "start": "605680",
    "end": "609440"
  },
  {
    "text": "it's important here that",
    "start": "609440",
    "end": "612000"
  },
  {
    "text": "we understand that topology manager",
    "start": "612000",
    "end": "613920"
  },
  {
    "text": "still runs its alignment logic at an old",
    "start": "613920",
    "end": "616560"
  },
  {
    "text": "level and it performs the admission",
    "start": "616560",
    "end": "618720"
  },
  {
    "text": "check for the part but what we are",
    "start": "618720",
    "end": "621279"
  },
  {
    "text": "trying to do is being proactive and",
    "start": "621279",
    "end": "623200"
  },
  {
    "text": "imparting the scheduler intelligence and",
    "start": "623200",
    "end": "625760"
  },
  {
    "text": "empowering it to make the right",
    "start": "625760",
    "end": "627120"
  },
  {
    "text": "scheduling decision",
    "start": "627120",
    "end": "629680"
  },
  {
    "text": "now i'll hand over to francesco to cover",
    "start": "629680",
    "end": "631600"
  },
  {
    "text": "next part of the presentation",
    "start": "631600",
    "end": "633680"
  },
  {
    "text": "where we'll double click on each of",
    "start": "633680",
    "end": "635519"
  },
  {
    "text": "these components",
    "start": "635519",
    "end": "636959"
  },
  {
    "text": "and cover them in more detail",
    "start": "636959",
    "end": "639040"
  },
  {
    "text": "over to your francesco",
    "start": "639040",
    "end": "640959"
  },
  {
    "text": "thank you swathi",
    "start": "640959",
    "end": "642480"
  },
  {
    "text": "so",
    "start": "642480",
    "end": "643440"
  },
  {
    "text": "let's cover the uh the components we",
    "start": "643440",
    "end": "647200"
  },
  {
    "text": "just talked about in a bit more detail",
    "start": "647200",
    "end": "649040"
  },
  {
    "text": "and let's see what comes next in terms",
    "start": "649040",
    "end": "651519"
  },
  {
    "text": "of roadmap and last but not least let's",
    "start": "651519",
    "end": "653920"
  },
  {
    "text": "cover how to get involved in this",
    "start": "653920",
    "end": "656240"
  },
  {
    "text": "initiative",
    "start": "656240",
    "end": "658399"
  },
  {
    "text": "so",
    "start": "658399",
    "end": "659279"
  },
  {
    "text": "uh they know the results topology object",
    "start": "659279",
    "end": "661680"
  },
  {
    "text": "is uh an external object being a custom",
    "start": "661680",
    "end": "664160"
  },
  {
    "text": "resource definition which uh like you",
    "start": "664160",
    "end": "666560"
  },
  {
    "text": "mentioned corresponds to one node or on",
    "start": "666560",
    "end": "669519"
  },
  {
    "text": "on the cluster so you have one one",
    "start": "669519",
    "end": "671360"
  },
  {
    "text": "relationship between node objects and",
    "start": "671360",
    "end": "673200"
  },
  {
    "text": "other source topology objects",
    "start": "673200",
    "end": "676000"
  },
  {
    "text": "what we found in this field in this",
    "start": "676000",
    "end": "678399"
  },
  {
    "text": "object is the counters for uh for each",
    "start": "678399",
    "end": "681519"
  },
  {
    "text": "number zones for each results known by",
    "start": "681519",
    "end": "684079"
  },
  {
    "text": "kubernetes about the capacity deductible",
    "start": "684079",
    "end": "686480"
  },
  {
    "text": "and available units for its resources",
    "start": "686480",
    "end": "689760"
  },
  {
    "text": "and then we'll see in a little while",
    "start": "689760",
    "end": "692240"
  },
  {
    "text": "what these actually mean",
    "start": "692240",
    "end": "695440"
  },
  {
    "text": "so let's start with an example",
    "start": "695440",
    "end": "698640"
  },
  {
    "text": "of a real world example about another",
    "start": "698640",
    "end": "701040"
  },
  {
    "text": "switch topology so we'll have we want to",
    "start": "701040",
    "end": "703600"
  },
  {
    "text": "highlight first of all the node the name",
    "start": "703600",
    "end": "705760"
  },
  {
    "text": "of the object which matches the",
    "start": "705760",
    "end": "708000"
  },
  {
    "text": "name of the node which this object",
    "start": "708000",
    "end": "710320"
  },
  {
    "text": "refers to",
    "start": "710320",
    "end": "712079"
  },
  {
    "text": "and so it's very easy to cross correlate",
    "start": "712079",
    "end": "714160"
  },
  {
    "text": "between node objects or node nodes in",
    "start": "714160",
    "end": "716560"
  },
  {
    "text": "general and not resource to polish",
    "start": "716560",
    "end": "717920"
  },
  {
    "text": "objects and then we have the",
    "start": "717920",
    "end": "720160"
  },
  {
    "text": "topology manager policy because this",
    "start": "720160",
    "end": "722240"
  },
  {
    "text": "allows the plugins to make further logic",
    "start": "722240",
    "end": "724880"
  },
  {
    "text": "and",
    "start": "724880",
    "end": "725920"
  },
  {
    "text": "about the",
    "start": "725920",
    "end": "727040"
  },
  {
    "text": "what's actually running at node level",
    "start": "727040",
    "end": "729519"
  },
  {
    "text": "in this in this case it's also important",
    "start": "729519",
    "end": "731600"
  },
  {
    "text": "that the scope which is also encoded in",
    "start": "731600",
    "end": "733680"
  },
  {
    "text": "the policy the scope of topology manager",
    "start": "733680",
    "end": "735839"
  },
  {
    "text": "and then we have the zones which",
    "start": "735839",
    "end": "737600"
  },
  {
    "text": "represent uh each anumazon each amazon",
    "start": "737600",
    "end": "741519"
  },
  {
    "text": "has a name which is unique on the node",
    "start": "741519",
    "end": "744480"
  },
  {
    "text": "so",
    "start": "744480",
    "end": "745360"
  },
  {
    "text": "it's on some different node can have",
    "start": "745360",
    "end": "747440"
  },
  {
    "text": "actually the",
    "start": "747440",
    "end": "748800"
  },
  {
    "text": "same",
    "start": "748800",
    "end": "750160"
  },
  {
    "text": "name",
    "start": "750160",
    "end": "751200"
  },
  {
    "text": "and then we have the resources so for",
    "start": "751200",
    "end": "753279"
  },
  {
    "text": "each restaurants known to kubernetes we",
    "start": "753279",
    "end": "756000"
  },
  {
    "text": "have the research name and the counters",
    "start": "756000",
    "end": "758160"
  },
  {
    "text": "associated with that resource",
    "start": "758160",
    "end": "760480"
  },
  {
    "text": "and the first of them is the capacity",
    "start": "760480",
    "end": "762880"
  },
  {
    "text": "which",
    "start": "762880",
    "end": "764000"
  },
  {
    "text": "represents how many of those resources",
    "start": "764000",
    "end": "766160"
  },
  {
    "text": "are actually physically present on this",
    "start": "766160",
    "end": "767920"
  },
  {
    "text": "zone and then you have the electable",
    "start": "767920",
    "end": "770399"
  },
  {
    "text": "because you may very want to reserve",
    "start": "770399",
    "end": "772880"
  },
  {
    "text": "some of those resources for other tasks",
    "start": "772880",
    "end": "775120"
  },
  {
    "text": "or in general to not be available to",
    "start": "775120",
    "end": "777920"
  },
  {
    "text": "the cube letter",
    "start": "777920",
    "end": "779279"
  },
  {
    "text": "so examples are for example cpu and",
    "start": "779279",
    "end": "782079"
  },
  {
    "text": "memory to reserve to system demons for",
    "start": "782079",
    "end": "784240"
  },
  {
    "text": "the no twerk properly",
    "start": "784240",
    "end": "787200"
  },
  {
    "text": "so we have the lock table which is a",
    "start": "787200",
    "end": "788639"
  },
  {
    "text": "subset of capacity",
    "start": "788639",
    "end": "790720"
  },
  {
    "text": "and we have available units which is how",
    "start": "790720",
    "end": "793519"
  },
  {
    "text": "many of the unlockable units are",
    "start": "793519",
    "end": "795279"
  },
  {
    "text": "actually ready to be assigned versus",
    "start": "795279",
    "end": "797839"
  },
  {
    "text": "already taken by workload running on",
    "start": "797839",
    "end": "799920"
  },
  {
    "text": "this node on this pneumation",
    "start": "799920",
    "end": "802399"
  },
  {
    "text": "worth mentioning cpus are referred as a",
    "start": "802399",
    "end": "805120"
  },
  {
    "text": "wall because the one single core one",
    "start": "805120",
    "end": "807440"
  },
  {
    "text": "single cpu considered a synonym is the",
    "start": "807440",
    "end": "810480"
  },
  {
    "text": "minimum amount that could be exclusively",
    "start": "810480",
    "end": "812560"
  },
  {
    "text": "allocated by the cpu manager",
    "start": "812560",
    "end": "814880"
  },
  {
    "text": "last we have the costs which are the",
    "start": "814880",
    "end": "816800"
  },
  {
    "text": "number distances as",
    "start": "816800",
    "end": "818959"
  },
  {
    "text": "reported by the linux kernel",
    "start": "818959",
    "end": "822560"
  },
  {
    "text": "can we just extend the renault object",
    "start": "823600",
    "end": "826639"
  },
  {
    "text": "well it's not that straightforward for a",
    "start": "826639",
    "end": "829199"
  },
  {
    "text": "bunch of reasons the most important ones",
    "start": "829199",
    "end": "832240"
  },
  {
    "text": "is first of all uh this is a very",
    "start": "832240",
    "end": "834720"
  },
  {
    "text": "specific information we may want to have",
    "start": "834720",
    "end": "837519"
  },
  {
    "text": "separated by the basic node object which",
    "start": "837519",
    "end": "839839"
  },
  {
    "text": "is",
    "start": "839839",
    "end": "840560"
  },
  {
    "text": "widespread and part of kubernetes api so",
    "start": "840560",
    "end": "843600"
  },
  {
    "text": "we can also",
    "start": "843600",
    "end": "845040"
  },
  {
    "text": "restrict the access to this information",
    "start": "845040",
    "end": "846800"
  },
  {
    "text": "and in general only the clients that",
    "start": "846800",
    "end": "848560"
  },
  {
    "text": "want to access this information may",
    "start": "848560",
    "end": "850720"
  },
  {
    "text": "access those object versus requiring",
    "start": "850720",
    "end": "852959"
  },
  {
    "text": "them to access the bulkier node objects",
    "start": "852959",
    "end": "856720"
  },
  {
    "text": "and nodes are bulky indeed so adding",
    "start": "856720",
    "end": "859360"
  },
  {
    "text": "even more data is not straightforward",
    "start": "859360",
    "end": "861519"
  },
  {
    "text": "then arguably",
    "start": "861519",
    "end": "863040"
  },
  {
    "text": "not today obviously better approach",
    "start": "863040",
    "end": "865680"
  },
  {
    "text": "however we are exploring options and we",
    "start": "865680",
    "end": "868240"
  },
  {
    "text": "are keeping the conversation open about",
    "start": "868240",
    "end": "869920"
  },
  {
    "text": "the best way to expose this information",
    "start": "869920",
    "end": "871920"
  },
  {
    "text": "in general and to make part of the core",
    "start": "871920",
    "end": "873839"
  },
  {
    "text": "kubernetes api so this conversation is",
    "start": "873839",
    "end": "876399"
  },
  {
    "text": "still in progress",
    "start": "876399",
    "end": "879120"
  },
  {
    "text": "we mentioned previously the topology",
    "start": "879600",
    "end": "882000"
  },
  {
    "text": "updater agent which is the component",
    "start": "882000",
    "end": "883839"
  },
  {
    "text": "running on each node",
    "start": "883839",
    "end": "885600"
  },
  {
    "text": "you are interested to expose the pernuma",
    "start": "885600",
    "end": "888560"
  },
  {
    "text": "resource allocation and availability",
    "start": "888560",
    "end": "891360"
  },
  {
    "text": "so we have one topology updater agent as",
    "start": "891360",
    "end": "894480"
  },
  {
    "text": "probably running as a demonstrate on",
    "start": "894480",
    "end": "896480"
  },
  {
    "text": "each only one set on each worker node",
    "start": "896480",
    "end": "899199"
  },
  {
    "text": "and this agent",
    "start": "899199",
    "end": "901920"
  },
  {
    "text": "needs to have authoritative information",
    "start": "901920",
    "end": "904160"
  },
  {
    "text": "about the resource availability and",
    "start": "904160",
    "end": "906800"
  },
  {
    "text": "allow current allocation and the",
    "start": "906800",
    "end": "908959"
  },
  {
    "text": "authoritative source is the cubelet",
    "start": "908959",
    "end": "910720"
  },
  {
    "text": "because the cubelet is the orchestrator",
    "start": "910720",
    "end": "912639"
  },
  {
    "text": "and the cubelet is the one which uh",
    "start": "912639",
    "end": "914880"
  },
  {
    "text": "allocates resources on a node basis",
    "start": "914880",
    "end": "916959"
  },
  {
    "text": "thanks to the quality manager and the",
    "start": "916959",
    "end": "918320"
  },
  {
    "text": "results manager",
    "start": "918320",
    "end": "919760"
  },
  {
    "text": "so",
    "start": "919760",
    "end": "920560"
  },
  {
    "text": "the topology updater agent",
    "start": "920560",
    "end": "922880"
  },
  {
    "text": "talks to the cubenet queries the cubelet",
    "start": "922880",
    "end": "925519"
  },
  {
    "text": "using the powder switches api which",
    "start": "925519",
    "end": "927680"
  },
  {
    "text": "gained support over the last few",
    "start": "927680",
    "end": "929360"
  },
  {
    "text": "releases to expose pneuma locality about",
    "start": "929360",
    "end": "932000"
  },
  {
    "text": "the",
    "start": "932000",
    "end": "932720"
  },
  {
    "text": "resources",
    "start": "932720",
    "end": "934320"
  },
  {
    "text": "associated with boards",
    "start": "934320",
    "end": "936079"
  },
  {
    "text": "the project sources api is",
    "start": "936079",
    "end": "938079"
  },
  {
    "text": "node local so it's very fast",
    "start": "938079",
    "end": "940639"
  },
  {
    "text": "but and the topology of data agents",
    "start": "940639",
    "end": "942800"
  },
  {
    "text": "queries periodically and uh",
    "start": "942800",
    "end": "945440"
  },
  {
    "text": "arranges this information per suit space",
    "start": "945440",
    "end": "947600"
  },
  {
    "text": "per normal per numa basis and updates",
    "start": "947600",
    "end": "951120"
  },
  {
    "text": "the objects they know their suits to",
    "start": "951120",
    "end": "952560"
  },
  {
    "text": "publish objects but we can also",
    "start": "952560",
    "end": "955519"
  },
  {
    "text": "introduce some notification mechanism to",
    "start": "955519",
    "end": "957600"
  },
  {
    "text": "have data project detection updater",
    "start": "957600",
    "end": "959519"
  },
  {
    "text": "agent",
    "start": "959519",
    "end": "960399"
  },
  {
    "text": "reacts quicker in a quicker way",
    "start": "960399",
    "end": "963279"
  },
  {
    "text": "the one example of this notification",
    "start": "963279",
    "end": "965120"
  },
  {
    "text": "mechanism we are exploring and trying it",
    "start": "965120",
    "end": "967279"
  },
  {
    "text": "out is for example plugging into",
    "start": "967279",
    "end": "969279"
  },
  {
    "text": "kryoke's so when a workload when a",
    "start": "969279",
    "end": "971920"
  },
  {
    "text": "container requiring exclusive resources",
    "start": "971920",
    "end": "974399"
  },
  {
    "text": "starts up data project iteration can be",
    "start": "974399",
    "end": "977120"
  },
  {
    "text": "notified and in turn query again the",
    "start": "977120",
    "end": "979120"
  },
  {
    "text": "cubelet and get up-to-date state",
    "start": "979120",
    "end": "983639"
  },
  {
    "text": "why do we need a new component to do",
    "start": "983680",
    "end": "985759"
  },
  {
    "text": "this task and we need for two main",
    "start": "985759",
    "end": "988639"
  },
  {
    "text": "reasons first of all is at this point in",
    "start": "988639",
    "end": "990639"
  },
  {
    "text": "time the not just topology is a separate",
    "start": "990639",
    "end": "992880"
  },
  {
    "text": "object so it's",
    "start": "992880",
    "end": "995199"
  },
  {
    "text": "even more evident that could be a good",
    "start": "995199",
    "end": "997120"
  },
  {
    "text": "idea to have a separate component taking",
    "start": "997120",
    "end": "998959"
  },
  {
    "text": "care of this",
    "start": "998959",
    "end": "1000800"
  },
  {
    "text": "object explicitly so it's very easy to",
    "start": "1000800",
    "end": "1003519"
  },
  {
    "text": "enable or disable",
    "start": "1003519",
    "end": "1005600"
  },
  {
    "text": "but it's that it's not enough to just",
    "start": "1005600",
    "end": "1007839"
  },
  {
    "text": "expose the initial state of the node",
    "start": "1007839",
    "end": "1010399"
  },
  {
    "text": "because there is a tighter coupling and",
    "start": "1010399",
    "end": "1013680"
  },
  {
    "text": "a tighter need for for reconciliation",
    "start": "1013680",
    "end": "1016079"
  },
  {
    "text": "between the nordstrom's topology object",
    "start": "1016079",
    "end": "1018160"
  },
  {
    "text": "and the scheduler plug-in",
    "start": "1018160",
    "end": "1020000"
  },
  {
    "text": "because",
    "start": "1020000",
    "end": "1020959"
  },
  {
    "text": "there is an uncertainty factor which is",
    "start": "1020959",
    "end": "1023199"
  },
  {
    "text": "unfortunately unavoidable about where",
    "start": "1023199",
    "end": "1025360"
  },
  {
    "text": "the location is taking place because of",
    "start": "1025360",
    "end": "1027839"
  },
  {
    "text": "the split brain thing",
    "start": "1027839",
    "end": "1030160"
  },
  {
    "text": "we we just mentioned we just described",
    "start": "1030160",
    "end": "1032720"
  },
  {
    "text": "in other words",
    "start": "1032720",
    "end": "1034640"
  },
  {
    "text": "the topology manager",
    "start": "1034640",
    "end": "1036720"
  },
  {
    "text": "then the cubelet guaranteed that the",
    "start": "1036720",
    "end": "1038640"
  },
  {
    "text": "workload",
    "start": "1038640",
    "end": "1040160"
  },
  {
    "text": "is i'll get either",
    "start": "1040160",
    "end": "1042319"
  },
  {
    "text": "all the results aligned on anumazon's",
    "start": "1042319",
    "end": "1044319"
  },
  {
    "text": "but it's not known beforehand which",
    "start": "1044319",
    "end": "1046480"
  },
  {
    "text": "number zones",
    "start": "1046480",
    "end": "1047760"
  },
  {
    "text": "or this workload is rejected so you can",
    "start": "1047760",
    "end": "1050799"
  },
  {
    "text": "you cannot predict on which the amazon",
    "start": "1050799",
    "end": "1052480"
  },
  {
    "text": "the workload is going to land so you",
    "start": "1052480",
    "end": "1053840"
  },
  {
    "text": "cannot really do accurate accounting you",
    "start": "1053840",
    "end": "1056000"
  },
  {
    "text": "can only learn after the fact",
    "start": "1056000",
    "end": "1058400"
  },
  {
    "text": "and this is caused by the fact that the",
    "start": "1058400",
    "end": "1060559"
  },
  {
    "text": "topology manager does the cubelet as the",
    "start": "1060559",
    "end": "1063360"
  },
  {
    "text": "ultimate authority on the placement",
    "start": "1063360",
    "end": "1067440"
  },
  {
    "text": "this means that we need to reconcile",
    "start": "1067440",
    "end": "1070720"
  },
  {
    "text": "more frequently the scheduler",
    "start": "1070720",
    "end": "1073360"
  },
  {
    "text": "state with numa pernuma counters and the",
    "start": "1073360",
    "end": "1077280"
  },
  {
    "text": "node state represented by the nordic",
    "start": "1077280",
    "end": "1079280"
  },
  {
    "text": "swiss topology objects and of course",
    "start": "1079280",
    "end": "1081120"
  },
  {
    "text": "this is a performance and scalability",
    "start": "1081120",
    "end": "1082559"
  },
  {
    "text": "concern which we are actively exploring",
    "start": "1082559",
    "end": "1085039"
  },
  {
    "text": "and improving and we'll cover that our",
    "start": "1085039",
    "end": "1087520"
  },
  {
    "text": "plans about that in a little while",
    "start": "1087520",
    "end": "1091120"
  },
  {
    "text": "last but not least",
    "start": "1091120",
    "end": "1093360"
  },
  {
    "text": "we cannot just override the topology",
    "start": "1093360",
    "end": "1096080"
  },
  {
    "text": "manager because it has to have the",
    "start": "1096080",
    "end": "1098320"
  },
  {
    "text": "ultimate word and about the placement",
    "start": "1098320",
    "end": "1100240"
  },
  {
    "text": "because it has the most authoritative",
    "start": "1100240",
    "end": "1102880"
  },
  {
    "text": "picture about the",
    "start": "1102880",
    "end": "1104320"
  },
  {
    "text": "exact node allocation so the scheduler",
    "start": "1104320",
    "end": "1106559"
  },
  {
    "text": "cannot and probably should not even if",
    "start": "1106559",
    "end": "1109520"
  },
  {
    "text": "it could drive the topology managed",
    "start": "1109520",
    "end": "1111520"
  },
  {
    "text": "decision",
    "start": "1111520",
    "end": "1112880"
  },
  {
    "text": "so we will have this uncertainty factor",
    "start": "1112880",
    "end": "1115039"
  },
  {
    "text": "to deal about and will have the",
    "start": "1115039",
    "end": "1116799"
  },
  {
    "text": "reconciliation need",
    "start": "1116799",
    "end": "1119840"
  },
  {
    "text": "now now that we have the data about the",
    "start": "1120559",
    "end": "1123600"
  },
  {
    "text": "paranormal research availability and",
    "start": "1123600",
    "end": "1125760"
  },
  {
    "text": "capacity",
    "start": "1125760",
    "end": "1127039"
  },
  {
    "text": "and we have an agent which keeps this",
    "start": "1127039",
    "end": "1129679"
  },
  {
    "text": "information export this information and",
    "start": "1129679",
    "end": "1131440"
  },
  {
    "text": "keeps this information fresh we can",
    "start": "1131440",
    "end": "1133440"
  },
  {
    "text": "build the scheduler plugin which consume",
    "start": "1133440",
    "end": "1135280"
  },
  {
    "text": "this information",
    "start": "1135280",
    "end": "1137600"
  },
  {
    "text": "and it's the",
    "start": "1137600",
    "end": "1139520"
  },
  {
    "text": "we have right now two plugins which",
    "start": "1139520",
    "end": "1142000"
  },
  {
    "text": "already got merged in the scheduler",
    "start": "1142000",
    "end": "1143600"
  },
  {
    "text": "plugin main repository under kubernetes",
    "start": "1143600",
    "end": "1146240"
  },
  {
    "text": "six and",
    "start": "1146240",
    "end": "1148080"
  },
  {
    "text": "the two of them are the filter plugin",
    "start": "1148080",
    "end": "1150799"
  },
  {
    "text": "which",
    "start": "1150799",
    "end": "1152080"
  },
  {
    "text": "filters out",
    "start": "1152080",
    "end": "1153919"
  },
  {
    "text": "from the later processing stage filters",
    "start": "1153919",
    "end": "1156000"
  },
  {
    "text": "out nodes which we are very confident we",
    "start": "1156000",
    "end": "1158960"
  },
  {
    "text": "are sure they cannot provide a line that",
    "start": "1158960",
    "end": "1161520"
  },
  {
    "text": "align the results to the workload",
    "start": "1161520",
    "end": "1163200"
  },
  {
    "text": "requiring them",
    "start": "1163200",
    "end": "1164480"
  },
  {
    "text": "because of how the resources are already",
    "start": "1164480",
    "end": "1167440"
  },
  {
    "text": "occupied on that node on the at the numa",
    "start": "1167440",
    "end": "1169440"
  },
  {
    "text": "level so",
    "start": "1169440",
    "end": "1170799"
  },
  {
    "text": "if the filter plugin rules out a node we",
    "start": "1170799",
    "end": "1173600"
  },
  {
    "text": "are sure that node was unsuitable is not",
    "start": "1173600",
    "end": "1175679"
  },
  {
    "text": "suitable",
    "start": "1175679",
    "end": "1177200"
  },
  {
    "text": "we also have the score plugin which",
    "start": "1177200",
    "end": "1178960"
  },
  {
    "text": "provides the well-known",
    "start": "1178960",
    "end": "1181280"
  },
  {
    "text": "scoring function and scoring policy like",
    "start": "1181280",
    "end": "1183919"
  },
  {
    "text": "list unlockable lists allocated and most",
    "start": "1183919",
    "end": "1186080"
  },
  {
    "text": "allocated on with new mac guarantees",
    "start": "1186080",
    "end": "1190480"
  },
  {
    "text": "how does",
    "start": "1191039",
    "end": "1192559"
  },
  {
    "text": "improves the pain points we mentioned",
    "start": "1192559",
    "end": "1194480"
  },
  {
    "text": "previously",
    "start": "1194480",
    "end": "1195679"
  },
  {
    "text": "first of all with the filter plugin",
    "start": "1195679",
    "end": "1197760"
  },
  {
    "text": "alone ruling out the node which cannot",
    "start": "1197760",
    "end": "1200799"
  },
  {
    "text": "accommodate the workload with the",
    "start": "1200799",
    "end": "1202159"
  },
  {
    "text": "requirements the world could have and we",
    "start": "1202159",
    "end": "1204000"
  },
  {
    "text": "would align when the workload needs",
    "start": "1204000",
    "end": "1206559"
  },
  {
    "text": "we can minimize the topology affinity",
    "start": "1206559",
    "end": "1208960"
  },
  {
    "text": "error we cannot say unfortunately",
    "start": "1208960",
    "end": "1210720"
  },
  {
    "text": "removes completely because the",
    "start": "1210720",
    "end": "1212080"
  },
  {
    "text": "uncertainty factor because the fat we",
    "start": "1212080",
    "end": "1213760"
  },
  {
    "text": "need to reconcile with the ultimate the",
    "start": "1213760",
    "end": "1215679"
  },
  {
    "text": "scissor which is the cubelet however",
    "start": "1215679",
    "end": "1218720"
  },
  {
    "text": "we can greatly improve this scenario and",
    "start": "1218720",
    "end": "1221600"
  },
  {
    "text": "we can then have more predictable",
    "start": "1221600",
    "end": "1223600"
  },
  {
    "text": "behavior",
    "start": "1223600",
    "end": "1225600"
  },
  {
    "text": "marth mentioning that some",
    "start": "1225600",
    "end": "1227760"
  },
  {
    "text": "workload type like for example",
    "start": "1227760",
    "end": "1229600"
  },
  {
    "text": "containers network functions and",
    "start": "1229600",
    "end": "1232000"
  },
  {
    "text": "5g",
    "start": "1232000",
    "end": "1233200"
  },
  {
    "text": "telco workloads also kind of expects",
    "start": "1233200",
    "end": "1236080"
  },
  {
    "text": "this kind of",
    "start": "1236080",
    "end": "1238240"
  },
  {
    "text": "number shedling so this is a way for us",
    "start": "1238240",
    "end": "1241280"
  },
  {
    "text": "to cover this gap",
    "start": "1241280",
    "end": "1244240"
  },
  {
    "text": "how can we try out these all the",
    "start": "1244960",
    "end": "1247280"
  },
  {
    "text": "components we described we talked about",
    "start": "1247280",
    "end": "1250960"
  },
  {
    "text": "we have a gita organization the links",
    "start": "1250960",
    "end": "1253360"
  },
  {
    "text": "are in the slides which is um",
    "start": "1253360",
    "end": "1256159"
  },
  {
    "text": "which contains all the repositories for",
    "start": "1256159",
    "end": "1258240"
  },
  {
    "text": "the components we are developed so for",
    "start": "1258240",
    "end": "1260480"
  },
  {
    "text": "example we have the nord resource crd",
    "start": "1260480",
    "end": "1262320"
  },
  {
    "text": "definition and the auto generated go",
    "start": "1262320",
    "end": "1264159"
  },
  {
    "text": "client",
    "start": "1264159",
    "end": "1265360"
  },
  {
    "text": "we have uh we've we mentioned that the",
    "start": "1265360",
    "end": "1268000"
  },
  {
    "text": "shadow blankets have already been merged",
    "start": "1268000",
    "end": "1270240"
  },
  {
    "text": "we have the not just roots topology data",
    "start": "1270240",
    "end": "1273280"
  },
  {
    "text": "agents",
    "start": "1273280",
    "end": "1274400"
  },
  {
    "text": "not feature discovery got support for",
    "start": "1274400",
    "end": "1277039"
  },
  {
    "text": "updating in zero 10 we have the",
    "start": "1277039",
    "end": "1279280"
  },
  {
    "text": "switzerland exporter on which we",
    "start": "1279280",
    "end": "1280960"
  },
  {
    "text": "experimented stuff and when we are",
    "start": "1280960",
    "end": "1282480"
  },
  {
    "text": "confident it's good then it's ready we",
    "start": "1282480",
    "end": "1284400"
  },
  {
    "text": "send changes so we propose changes to",
    "start": "1284400",
    "end": "1286159"
  },
  {
    "text": "another feature discovery we have",
    "start": "1286159",
    "end": "1288159"
  },
  {
    "text": "pre-built container images for rt in",
    "start": "1288159",
    "end": "1290960"
  },
  {
    "text": "this uh",
    "start": "1290960",
    "end": "1292080"
  },
  {
    "text": "dot io repository linked in the slides",
    "start": "1292080",
    "end": "1295360"
  },
  {
    "text": "same in the organization we also have",
    "start": "1295360",
    "end": "1297679"
  },
  {
    "text": "repository documentation and we also",
    "start": "1297679",
    "end": "1299600"
  },
  {
    "text": "have manifest which also encodes",
    "start": "1299600",
    "end": "1302320"
  },
  {
    "text": "not just how do you actually deploy the",
    "start": "1302320",
    "end": "1304000"
  },
  {
    "text": "components but which components which",
    "start": "1304000",
    "end": "1305600"
  },
  {
    "text": "goes with other components so you have",
    "start": "1305600",
    "end": "1307760"
  },
  {
    "text": "the set we test and tried so for example",
    "start": "1307760",
    "end": "1310559"
  },
  {
    "text": "version a of the api goes with version b",
    "start": "1310559",
    "end": "1312799"
  },
  {
    "text": "of the scheduler so you know this",
    "start": "1312799",
    "end": "1314799"
  },
  {
    "text": "version goes well together and this",
    "start": "1314799",
    "end": "1316480"
  },
  {
    "text": "information is encoded in the manifest",
    "start": "1316480",
    "end": "1318400"
  },
  {
    "text": "linked in the slides",
    "start": "1318400",
    "end": "1321120"
  },
  {
    "text": "we built a set of go packages to work",
    "start": "1321120",
    "end": "1324080"
  },
  {
    "text": "nicely to work programmatically with",
    "start": "1324080",
    "end": "1325760"
  },
  {
    "text": "those of these components to install to",
    "start": "1325760",
    "end": "1327280"
  },
  {
    "text": "manage them and we built a tool",
    "start": "1327280",
    "end": "1330400"
  },
  {
    "text": "called deployer lacking a bit creativity",
    "start": "1330400",
    "end": "1332400"
  },
  {
    "text": "here",
    "start": "1332400",
    "end": "1333360"
  },
  {
    "text": "to actually exercise those packages and",
    "start": "1333360",
    "end": "1336159"
  },
  {
    "text": "actually deploy those components in any",
    "start": "1336159",
    "end": "1338000"
  },
  {
    "text": "kubernetes cluster this command line",
    "start": "1338000",
    "end": "1340000"
  },
  {
    "text": "tool is available as binary releases is",
    "start": "1340000",
    "end": "1342720"
  },
  {
    "text": "again",
    "start": "1342720",
    "end": "1343760"
  },
  {
    "text": "linked in the slides and this this tool",
    "start": "1343760",
    "end": "1347679"
  },
  {
    "text": "is not just a demon but something we",
    "start": "1347679",
    "end": "1349120"
  },
  {
    "text": "actually use and we",
    "start": "1349120",
    "end": "1351679"
  },
  {
    "text": "we generate the manifest we mentioned",
    "start": "1351679",
    "end": "1353200"
  },
  {
    "text": "previously out of it",
    "start": "1353200",
    "end": "1355120"
  },
  {
    "text": "last but but not least this tool can",
    "start": "1355120",
    "end": "1357120"
  },
  {
    "text": "also distort and",
    "start": "1357120",
    "end": "1359360"
  },
  {
    "text": "go packages toolkit can also validate",
    "start": "1359360",
    "end": "1362240"
  },
  {
    "text": "the cluster meaning checking",
    "start": "1362240",
    "end": "1363280"
  },
  {
    "text": "configuration and ensure it is",
    "start": "1363280",
    "end": "1365520"
  },
  {
    "text": "compatible with the not the",
    "start": "1365520",
    "end": "1368080"
  },
  {
    "text": "new aware shadowing settings",
    "start": "1368080",
    "end": "1370640"
  },
  {
    "text": "for example is the topology manager well",
    "start": "1370640",
    "end": "1372400"
  },
  {
    "text": "configured in super manageable",
    "start": "1372400",
    "end": "1374080"
  },
  {
    "text": "configuration and things like this",
    "start": "1374080",
    "end": "1376720"
  },
  {
    "text": "we built so actually a subset of us",
    "start": "1376720",
    "end": "1379039"
  },
  {
    "text": "built an operator and",
    "start": "1379039",
    "end": "1381360"
  },
  {
    "text": "on top of the generic and reusable",
    "start": "1381360",
    "end": "1384880"
  },
  {
    "text": "go packages toolkit dimensional",
    "start": "1384880",
    "end": "1387360"
  },
  {
    "text": "this operator is wants to be twins",
    "start": "1387360",
    "end": "1390480"
  },
  {
    "text": "compatible so nothing specific about any",
    "start": "1390480",
    "end": "1392960"
  },
  {
    "text": "distribution however we depend on the",
    "start": "1392960",
    "end": "1394880"
  },
  {
    "text": "machine config operator because it's",
    "start": "1394880",
    "end": "1396720"
  },
  {
    "text": "much more convenient to manage node with",
    "start": "1396720",
    "end": "1398880"
  },
  {
    "text": "that but that's actually the main and",
    "start": "1398880",
    "end": "1400640"
  },
  {
    "text": "only requirement",
    "start": "1400640",
    "end": "1402720"
  },
  {
    "text": "and this operator however us more",
    "start": "1402720",
    "end": "1404799"
  },
  {
    "text": "opinionated the settings about how the",
    "start": "1404799",
    "end": "1406799"
  },
  {
    "text": "animal where shielding",
    "start": "1406799",
    "end": "1408640"
  },
  {
    "text": "would look like should look like while",
    "start": "1408640",
    "end": "1410320"
  },
  {
    "text": "the",
    "start": "1410320",
    "end": "1411360"
  },
  {
    "text": "deployer toolkit we mentioned it are",
    "start": "1411360",
    "end": "1413360"
  },
  {
    "text": "more generic",
    "start": "1413360",
    "end": "1414880"
  },
  {
    "text": "this operator is also available on",
    "start": "1414880",
    "end": "1416320"
  },
  {
    "text": "openshift",
    "start": "1416320",
    "end": "1418640"
  },
  {
    "text": "now we can we head towards the",
    "start": "1418640",
    "end": "1421120"
  },
  {
    "text": "conclusion so let's wrap up",
    "start": "1421120",
    "end": "1424159"
  },
  {
    "text": "what's in our future",
    "start": "1424159",
    "end": "1426080"
  },
  {
    "text": "we want to actually investigate and",
    "start": "1426080",
    "end": "1428559"
  },
  {
    "text": "invest and explore how we can reduce the",
    "start": "1428559",
    "end": "1431039"
  },
  {
    "text": "need to reconcile",
    "start": "1431039",
    "end": "1432720"
  },
  {
    "text": "scheduler plugin and the state of nodes",
    "start": "1432720",
    "end": "1434640"
  },
  {
    "text": "and this goes in the form of the reserve",
    "start": "1434640",
    "end": "1436640"
  },
  {
    "text": "plugin we are experiment with and we aim",
    "start": "1436640",
    "end": "1438720"
  },
  {
    "text": "to bring forward in the next months",
    "start": "1438720",
    "end": "1441760"
  },
  {
    "text": "also in the next months we want to keep",
    "start": "1441760",
    "end": "1444320"
  },
  {
    "text": "enhancing the nfd component to update",
    "start": "1444320",
    "end": "1446960"
  },
  {
    "text": "the topology",
    "start": "1446960",
    "end": "1448640"
  },
  {
    "text": "information and we will be sending",
    "start": "1448640",
    "end": "1451120"
  },
  {
    "text": "changes and",
    "start": "1451120",
    "end": "1453279"
  },
  {
    "text": "updating the code base in the next",
    "start": "1453279",
    "end": "1454799"
  },
  {
    "text": "months and we will keep the conversation",
    "start": "1454799",
    "end": "1456880"
  },
  {
    "text": "open about better integrate how to",
    "start": "1456880",
    "end": "1458640"
  },
  {
    "text": "integrate all these data and the",
    "start": "1458640",
    "end": "1460320"
  },
  {
    "text": "components in the kubernetes possibly",
    "start": "1460320",
    "end": "1462480"
  },
  {
    "text": "having native objects",
    "start": "1462480",
    "end": "1465039"
  },
  {
    "text": "should you want to participate in this",
    "start": "1465039",
    "end": "1466559"
  },
  {
    "text": "conversation the best place is the batch",
    "start": "1466559",
    "end": "1468880"
  },
  {
    "text": "working group which gathers experts and",
    "start": "1468880",
    "end": "1471440"
  },
  {
    "text": "participants for",
    "start": "1471440",
    "end": "1472880"
  },
  {
    "text": "of all the related seeks like apps node",
    "start": "1472880",
    "end": "1475600"
  },
  {
    "text": "and scheduling so the batch working",
    "start": "1475600",
    "end": "1477440"
  },
  {
    "text": "group slack channels is the best way to",
    "start": "1477440",
    "end": "1479600"
  },
  {
    "text": "get in touch to and talk about this",
    "start": "1479600",
    "end": "1482320"
  },
  {
    "text": "work",
    "start": "1482320",
    "end": "1483840"
  },
  {
    "text": "most of us also hang out on six specific",
    "start": "1483840",
    "end": "1486559"
  },
  {
    "text": "slack channels and communities like node",
    "start": "1486559",
    "end": "1488400"
  },
  {
    "text": "and scheduling",
    "start": "1488400",
    "end": "1491039"
  },
  {
    "text": "there is also a dedicated slack channel",
    "start": "1491279",
    "end": "1493520"
  },
  {
    "text": "very low traffic about this",
    "start": "1493520",
    "end": "1496159"
  },
  {
    "text": "initiative so if you want to ask",
    "start": "1496159",
    "end": "1498320"
  },
  {
    "text": "questions or propose changes or discuss",
    "start": "1498320",
    "end": "1500320"
  },
  {
    "text": "very focused",
    "start": "1500320",
    "end": "1501679"
  },
  {
    "text": "topics about this initiative this is",
    "start": "1501679",
    "end": "1503840"
  },
  {
    "text": "also a good choice",
    "start": "1503840",
    "end": "1505279"
  },
  {
    "text": "again we have the link to our own github",
    "start": "1505279",
    "end": "1507520"
  },
  {
    "text": "organization which holds the code all",
    "start": "1507520",
    "end": "1509520"
  },
  {
    "text": "the code and the documentation repos for",
    "start": "1509520",
    "end": "1511919"
  },
  {
    "text": "all the things we mentioned we are very",
    "start": "1511919",
    "end": "1513840"
  },
  {
    "text": "welcome to file issues and cnpr's",
    "start": "1513840",
    "end": "1518080"
  },
  {
    "text": "with that we are done we covered",
    "start": "1518080",
    "end": "1521279"
  },
  {
    "text": "our work",
    "start": "1521279",
    "end": "1522640"
  },
  {
    "text": "and we thank you for attending to our",
    "start": "1522640",
    "end": "1524559"
  },
  {
    "text": "session and we are very happy to answer",
    "start": "1524559",
    "end": "1526880"
  },
  {
    "text": "any questions you may have thank you",
    "start": "1526880",
    "end": "1532279"
  }
]
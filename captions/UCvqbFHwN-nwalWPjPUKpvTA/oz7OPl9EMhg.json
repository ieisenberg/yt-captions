[
  {
    "text": "Welcome to our session our session is titled prompt help me debug a",
    "start": "320",
    "end": "6600"
  },
  {
    "text": "cluster my name is Anusha ragunathan and with me is Lily Van and we're both",
    "start": "6600",
    "end": "12519"
  },
  {
    "text": "software Engineers working at intert and I'm trying to figure what a",
    "start": "12519",
    "end": "18039"
  },
  {
    "text": "good position of this mic would be all right this is",
    "start": "18039",
    "end": "25800"
  },
  {
    "text": "comfortable here's the agenda for today we'll start with with a background",
    "start": "25800",
    "end": "30840"
  },
  {
    "text": "of in it and its infrastructure at a glance then we'll dive into alerts and",
    "start": "30840",
    "end": "37399"
  },
  {
    "text": "what we've called cluster golden signals and how we've used to alleviate some of the problems of a platform",
    "start": "37399",
    "end": "46719"
  },
  {
    "text": "engineer then we'll dive deep into how to use AI for platform debugging and our",
    "start": "46719",
    "end": "52760"
  },
  {
    "text": "initial experience with this we'll have a demo following that",
    "start": "52760",
    "end": "58519"
  },
  {
    "text": "and we'll finish off with takeaways into it is a global fintech",
    "start": "58519",
    "end": "66360"
  },
  {
    "text": "company that builds several Financial products and services so if you have",
    "start": "66360",
    "end": "71400"
  },
  {
    "text": "ever used Turbo Tax to file your taxes or QuickBooks for accounting and payroll",
    "start": "71400",
    "end": "77479"
  },
  {
    "text": "know that they are all running on kubernetes based platform infrastructure Lily and I are part of",
    "start": "77479",
    "end": "84320"
  },
  {
    "text": "this platform team and here are a few numbers to show the scale at which we operate",
    "start": "84320",
    "end": "90640"
  },
  {
    "text": "I'd like to highlight that we support about 7,000 application developers within",
    "start": "90640",
    "end": "95880"
  },
  {
    "text": "int and uh these uh developers are running about 2500 Production Services",
    "start": "95880",
    "end": "102920"
  },
  {
    "text": "we have a lot more prepro services but this is just production and they go up to a bigger scale during our Peak",
    "start": "102920",
    "end": "109200"
  },
  {
    "text": "seasons and these are running on about 315 kubernetes clusters that have about",
    "start": "109200",
    "end": "117079"
  },
  {
    "text": "30,000 kubernetes name spaces now this is a pretty large scale operation what",
    "start": "117079",
    "end": "123640"
  },
  {
    "text": "does it take to observe such a large Fleet of",
    "start": "123640",
    "end": "128479"
  },
  {
    "text": "clusters now even when there are no big change events that are happening in a kubernetes cluster it is challenging to",
    "start": "128679",
    "end": "136440"
  },
  {
    "text": "observe it as you might all know because there are constant moving Parts the pods",
    "start": "136440",
    "end": "141560"
  },
  {
    "text": "are getting resized nodes are getting resized constantly because of kubernetes",
    "start": "141560",
    "end": "146920"
  },
  {
    "text": "is resource optimization strategy now add to it change events that we have",
    "start": "146920",
    "end": "154480"
  },
  {
    "text": "at into it we have a few of these we have the monthly cluster",
    "start": "154480",
    "end": "160159"
  },
  {
    "text": "upgrades that keep the in kubernetes Fleet up to date with kubernetes",
    "start": "160159",
    "end": "166080"
  },
  {
    "text": "versions We have Ami rotations in order to comply with security then we have a lot of cluster",
    "start": "166080",
    "end": "173879"
  },
  {
    "text": "add-on revisions to keep up with the different features that we have as far as cluster apps and cluster add-ons",
    "start": "173879",
    "end": "180879"
  },
  {
    "text": "and then we have a core set of platform features that are built on top of it all of these require cluster",
    "start": "180879",
    "end": "187840"
  },
  {
    "text": "upgrades and then we have something called as season Readiness how do we prepare for a peak event such as a Super",
    "start": "187840",
    "end": "195000"
  },
  {
    "text": "Bowl event or let's say a tax PE event there's a whole bunch of testing that goes in behind the scenes in order to",
    "start": "195000",
    "end": "201920"
  },
  {
    "text": "prepare our platforms for such events so those are huge change events for the",
    "start": "201920",
    "end": "207400"
  },
  {
    "text": "platform and then the actual peak season in itself there is a lot of scaling",
    "start": "207400",
    "end": "213319"
  },
  {
    "text": "events that are happening across several dimensions of the platform with respect to compute network storage observability",
    "start": "213319",
    "end": "219760"
  },
  {
    "text": "and what have you and finally there is changes expected or unexpected from our",
    "start": "219760",
    "end": "226040"
  },
  {
    "text": "cloud provider AWS in this case now what does this mean for the life of a platform engineer it means that at the",
    "start": "226040",
    "end": "233480"
  },
  {
    "text": "minimum they are receiving and resolving hundreds of alerts on a very weekly",
    "start": "233480",
    "end": "238799"
  },
  {
    "text": "basis so let's dive into alerts and cluster golden signals now what are some of the",
    "start": "238799",
    "end": "245439"
  },
  {
    "text": "concerns that a platform engineer might have especially when they go on",
    "start": "245439",
    "end": "250760"
  },
  {
    "text": "call there is a bunch of components that we monitor in a kubernetes cluster",
    "start": "250760",
    "end": "256479"
  },
  {
    "text": "whether it's per node with respect to CPU memory dis Network or processes there are",
    "start": "256479",
    "end": "262639"
  },
  {
    "text": "kubernetes components that get monitored and then there is prod life cycles as we all know there are industry standards",
    "start": "262639",
    "end": "268639"
  },
  {
    "text": "for this so the the metric sources for node components we use heapster for kubernetes we use Prometheus and for pod",
    "start": "268639",
    "end": "275639"
  },
  {
    "text": "life cycle we use cstate metrics and there's a lot more but these are the main ones and all of these alert our",
    "start": "275639",
    "end": "282880"
  },
  {
    "text": "platform engineer and when they pass a particular threshold the platform engineer then has",
    "start": "282880",
    "end": "290000"
  },
  {
    "text": "to work on these alerts and look at different things such as kubernetes events for observing kubernetes logs a",
    "start": "290000",
    "end": "299280"
  },
  {
    "text": "whole buch of different dashboards and run books to actually remediate the problem at hand and",
    "start": "299280",
    "end": "305320"
  },
  {
    "text": "potentially need cluster access for such remediation now this can be overwhelming",
    "start": "305320",
    "end": "310639"
  },
  {
    "text": "if you're doing this for about 100 plus alerts for a particular cluster and",
    "start": "310639",
    "end": "317600"
  },
  {
    "text": "you're having 315 clusters to manage now you do the math that adds up and our",
    "start": "317600",
    "end": "323680"
  },
  {
    "text": "platform engineer is getting slightly overwhelmed at this point now let's make this interesting and throw in an",
    "start": "323680",
    "end": "331520"
  },
  {
    "text": "incident who here likes to be on an incident call wow that's that's interesting do",
    "start": "331520",
    "end": "338759"
  },
  {
    "text": "you all work for pag Duty or incident doio well Lily and I don't like to be on",
    "start": "338759",
    "end": "345600"
  },
  {
    "text": "incident calls um we uh when we are uh",
    "start": "345600",
    "end": "350720"
  },
  {
    "text": "there are a bunch of other uh business related questions that come in oh how many services are impacted in this",
    "start": "350720",
    "end": "357400"
  },
  {
    "text": "incident are the Clusters that are running them healthy or not is this issue a service",
    "start": "357400",
    "end": "364160"
  },
  {
    "text": "issue or a platform issue whom do we have to page additionally and what is",
    "start": "364160",
    "end": "370039"
  },
  {
    "text": "the blast radius of this issue how many more services in the upstream or Downstream dependencies are affected by",
    "start": "370039",
    "end": "376160"
  },
  {
    "text": "it at the end of that incident call we like this constantly drowning in",
    "start": "376160",
    "end": "382000"
  },
  {
    "text": "questions alerts and what have you now there are fundamentally two problems",
    "start": "382000",
    "end": "387520"
  },
  {
    "text": "here um there is a longer time to detect problems because of alert fatigue alert",
    "start": "387520",
    "end": "392960"
  },
  {
    "text": "overdose and false positives which results in increased time to detect kubernetes platform",
    "start": "392960",
    "end": "399759"
  },
  {
    "text": "issues then there is a longer time to remediate these problems because there is an abundance of data sources and at",
    "start": "399759",
    "end": "406240"
  },
  {
    "text": "point in time when you are on an incident you want to be able to quickly get to the root of the problem and the",
    "start": "406240",
    "end": "411560"
  },
  {
    "text": "Run books are not fully automated and there is not a much of a streamlined correlation between different events",
    "start": "411560",
    "end": "417440"
  },
  {
    "text": "that are happening in the cluster so this results in an increase in",
    "start": "417440",
    "end": "422720"
  },
  {
    "text": "mttr now in order to solve this the first part of the problem and to reduce",
    "start": "422720",
    "end": "427960"
  },
  {
    "text": "the alert fatigue from a sea of alerts we've defined what are called cluster golden signals now this basically is a",
    "start": "427960",
    "end": "435199"
  },
  {
    "text": "philosophy derived from service golden signals where you have four pillars across which you can measure the health",
    "start": "435199",
    "end": "441160"
  },
  {
    "text": "of a service similarly we measure it across the four different pillars for the health of a cluster and uh these",
    "start": "441160",
    "end": "447440"
  },
  {
    "text": "four pillars are basically eror saturation latency and traffic and what",
    "start": "447440",
    "end": "452960"
  },
  {
    "text": "we do is we have a collection of algorithms um uh and quality metrics and",
    "start": "452960",
    "end": "458919"
  },
  {
    "text": "dashboards to provide a single pane of glass to observe the health of a cluster and uh once the health of a cluster",
    "start": "458919",
    "end": "465479"
  },
  {
    "text": "becomes uh degraded or critical you can have an option to get alerted on it and",
    "start": "465479",
    "end": "471520"
  },
  {
    "text": "the idea is to filter out the whole noise of alerts and give a few good quality signals that can be in turn used",
    "start": "471520",
    "end": "478039"
  },
  {
    "text": "for alerting mainly because we think that these alerts will endend up causing",
    "start": "478039",
    "end": "483440"
  },
  {
    "text": "incidents now how did we do this um we identified a core the core critical",
    "start": "483440",
    "end": "489639"
  },
  {
    "text": "components of a kubernetes cluster and we bucketed them across several functionalities uh such as control plane",
    "start": "489639",
    "end": "496440"
  },
  {
    "text": "metrics authentication autoscaling Network critical add-ons and so on and for each of these",
    "start": "496440",
    "end": "503199"
  },
  {
    "text": "components we basically generate a single Prometheus Health golden signal",
    "start": "503199",
    "end": "509080"
  },
  {
    "text": "and the health is generated based on error slas that are being breached or error counts and um the health can have",
    "start": "509080",
    "end": "516560"
  },
  {
    "text": "one of three values it can either be healthy degraded or critical and the overall health of a",
    "start": "516560",
    "end": "523560"
  },
  {
    "text": "cluster is basically an aggregation of all of the critical cluster components note that a cluster can be healthy only",
    "start": "523560",
    "end": "530640"
  },
  {
    "text": "if all of the critical components are healthy even if one of the components are degraded or critical the status",
    "start": "530640",
    "end": "537040"
  },
  {
    "text": "changes to uh degraded or critical and then we've built dashboards to surface these metrics and we've set up",
    "start": "537040",
    "end": "544680"
  },
  {
    "text": "alerting based on the health of this cluster the idea is to actually automatically create incidents based on",
    "start": "544680",
    "end": "550440"
  },
  {
    "text": "cluster golden signals being degraded or critical you here is a uh quick",
    "start": "550440",
    "end": "556240"
  },
  {
    "text": "architecture uh overview here are the sort of high level grouping of the",
    "start": "556240",
    "end": "561760"
  },
  {
    "text": "metrics so we have control plane bootstrap add-on metrics cluster add-ons and then AWS related metrics all of",
    "start": "561760",
    "end": "569079"
  },
  {
    "text": "these um have we've written Prometheus rules to specify exactly what determines the",
    "start": "569079",
    "end": "574600"
  },
  {
    "text": "health what when it will breach the health SLA as Prometheus expressions and",
    "start": "574600",
    "end": "580720"
  },
  {
    "text": "then they are deployed onto the kubernetes cluster in the Prometheus name space this is where our Prometheus",
    "start": "580720",
    "end": "587160"
  },
  {
    "text": "servers are running and uh the alert rules are established for that and then",
    "start": "587160",
    "end": "592640"
  },
  {
    "text": "when they are alert conditions are met then we trigger a um uh alert and uh it",
    "start": "592640",
    "end": "599600"
  },
  {
    "text": "also gets reflected in our dashboards now here is a quick",
    "start": "599600",
    "end": "604760"
  },
  {
    "text": "screenshot of the health of uh an entire kubernetes uh Fleet uh so we have about",
    "start": "604760",
    "end": "611160"
  },
  {
    "text": "315 clusters so the honeycomb view basically gives you a snapshot of what the health is at any particular point in",
    "start": "611160",
    "end": "618200"
  },
  {
    "text": "time and then the screenshot on the right actually shows the health of a",
    "start": "618200",
    "end": "624160"
  },
  {
    "text": "specific individual cluster and all of the individual components in it so you can drill build down and get more",
    "start": "624160",
    "end": "630360"
  },
  {
    "text": "information if there is something that has degraded or critical now here is a sample Prometheus",
    "start": "630360",
    "end": "637360"
  },
  {
    "text": "rule that shows the health golden signal and how it is calculated so in this case",
    "start": "637360",
    "end": "642639"
  },
  {
    "text": "it's basically an aggregation of of those critical components that I had",
    "start": "642639",
    "end": "647880"
  },
  {
    "text": "mentioned and uh taking a closer look at a s a single cluster component let's",
    "start": "647880",
    "end": "653000"
  },
  {
    "text": "take a look at the core DNS um add-on so in this case we determin that core DNS",
    "start": "653000",
    "end": "659000"
  },
  {
    "text": "is actually failed by looking at the error SLA in this case we look at all",
    "start": "659000",
    "end": "666600"
  },
  {
    "text": "all of the uh total responses that CNS gives over a 5 minute window and look at",
    "start": "666600",
    "end": "671839"
  },
  {
    "text": "how many suril errors were returned in that particular window and that if if that percentage breaches let's say it",
    "start": "671839",
    "end": "679440"
  },
  {
    "text": "goes below 95% then we determine that it's actually um bad U situation for",
    "start": "679440",
    "end": "686320"
  },
  {
    "text": "core DNS mainly because as we all know most of these kubernetes components reconcile on a a periodic basis and they",
    "start": "686320",
    "end": "692720"
  },
  {
    "text": "sort of get out of the error inia situation if possible there are reconcilable errors and then there are ones that you cannot recover from so we",
    "start": "692720",
    "end": "699800"
  },
  {
    "text": "look for those nonre non- recoverable errors and are able to um uh determine",
    "start": "699800",
    "end": "706360"
  },
  {
    "text": "that and alert based on that now what a platform really want",
    "start": "706360",
    "end": "712760"
  },
  {
    "text": "platform engineer really wants is to lower MTD by using cluster golden signals and this part we've been able to",
    "start": "712760",
    "end": "718880"
  },
  {
    "text": "achieve but now now that we've detected the problem what can we do to actually help",
    "start": "718880",
    "end": "724920"
  },
  {
    "text": "fasten the remediation how can we actually get to the debugging and root cause of the problem hey we know that",
    "start": "724920",
    "end": "730800"
  },
  {
    "text": "CNS had the issue has an issue but what is it that is actually causing those",
    "start": "730800",
    "end": "735959"
  },
  {
    "text": "suril errors how can we get to that why is a component failing and identifying",
    "start": "735959",
    "end": "741639"
  },
  {
    "text": "the root cause and remediating the problem is the is fundamental to actually lowering the uh mttr",
    "start": "741639",
    "end": "750120"
  },
  {
    "text": "for this we started looking at AI for platform debugging um whether it I mean when I go",
    "start": "750120",
    "end": "757920"
  },
  {
    "text": "on call when I'm not able to find uh my answers in my private run books I'm actually looking to the internet for a",
    "start": "757920",
    "end": "764000"
  },
  {
    "text": "plora of uh information whether it's errors in my kubernetes logs or events",
    "start": "764000",
    "end": "769639"
  },
  {
    "text": "whether it's Prometheus metrics whether it's any knowledge based articles that maybe open source enthusiasts or Cloud",
    "start": "769639",
    "end": "776399"
  },
  {
    "text": "providers or anyone in between has written so I'm actually constantly looking for text information out there",
    "start": "776399",
    "end": "782560"
  },
  {
    "text": "in the internet and similarly I have we have run books within inid that I have a plethora of information but they're just",
    "start": "782560",
    "end": "789399"
  },
  {
    "text": "not as streamlined as I would expect so can I use the public information and the",
    "start": "789399",
    "end": "795760"
  },
  {
    "text": "private information that's in there to streamline my my on call experience can I actually use the cluster golden signal",
    "start": "795760",
    "end": "803160"
  },
  {
    "text": "to actually trigger something for deeper debugging can I use the Prometheus remote writer ability ities to actually",
    "start": "803160",
    "end": "810160"
  },
  {
    "text": "do get some AI assistance um to talk for about all of this I'd like to call Lily",
    "start": "810160",
    "end": "816320"
  },
  {
    "text": "to take over thanks",
    "start": "816320",
    "end": "821680"
  },
  {
    "text": "anusa so as anusa mentioned in the previous slides we can summary that to",
    "start": "822880",
    "end": "828240"
  },
  {
    "text": "debug a cluster issue we need three steps first we need we want to identify the aror components and second we want",
    "start": "828240",
    "end": "835560"
  },
  {
    "text": "to identify the root cause and finally we want to know the remediation steps so",
    "start": "835560",
    "end": "841320"
  },
  {
    "text": "let's first take a look at an overall solution of those three steps and we will dive into each step after",
    "start": "841320",
    "end": "848880"
  },
  {
    "text": "that let's say we have a kubernetes cluster and how do we detect the problem",
    "start": "848959",
    "end": "855120"
  },
  {
    "text": "today we aggregate with uh premises rules and the metrics to detect the",
    "start": "855120",
    "end": "860519"
  },
  {
    "text": "cluster arror so whenever there's an error happening in the cluster there will be a matrix triggered and the",
    "start": "860519",
    "end": "867399"
  },
  {
    "text": "premises server will capture the the corresponding metrix now we have detect the problem and we want to run some",
    "start": "867399",
    "end": "874040"
  },
  {
    "text": "deeper checks to figure out the root cause or more aror",
    "start": "874040",
    "end": "879279"
  },
  {
    "text": "details we have deployed a debu name space in the same cluster with a",
    "start": "879279",
    "end": "884360"
  },
  {
    "text": "lightweight go line service called second check running and we have configured the premises rules to send a",
    "start": "884360",
    "end": "891800"
  },
  {
    "text": "remote right check uh the remote right request to the second check service and",
    "start": "891800",
    "end": "898800"
  },
  {
    "text": "after after the second check service received the request it will talk to um",
    "start": "898800",
    "end": "904320"
  },
  {
    "text": "another service called kgpt which is an open- Source tool for scanning your",
    "start": "904320",
    "end": "909440"
  },
  {
    "text": "kubernetes issues and to help you to diagnosing tring issues it can scan your target name",
    "start": "909440",
    "end": "917120"
  },
  {
    "text": "spaces and Report the error messages like the port arrrow locks and then the",
    "start": "917120",
    "end": "922519"
  },
  {
    "text": "port is like the Pod is in the crashing Loop and then finally we would like to know how to fix the issue of what the",
    "start": "922519",
    "end": "929199"
  },
  {
    "text": "next steps so Cas GPT integrates with couple public LM to get the remediation steps",
    "start": "929199",
    "end": "936639"
  },
  {
    "text": "for an arrow and in addition to that we also leverage our uh internal private",
    "start": "936639",
    "end": "943480"
  },
  {
    "text": "embedding service that we can get remediation from the private content and finally the second check",
    "start": "943480",
    "end": "951279"
  },
  {
    "text": "service will agregates the results from the private content and and plus from",
    "start": "951279",
    "end": "956959"
  },
  {
    "text": "the public content and upload the result to a S3 bucket so the data can be",
    "start": "956959",
    "end": "962120"
  },
  {
    "text": "consumed by a internal user platform or it can be also used to enrich the back enrich the private",
    "start": "962120",
    "end": "969199"
  },
  {
    "text": "content here the step I just described so let's take a closer look at the first",
    "start": "969199",
    "end": "974680"
  },
  {
    "text": "step so here is the detail of how we configure the promises rules for remote",
    "start": "974680",
    "end": "981680"
  },
  {
    "text": "right so you can see that we have a Q config there with all the details and",
    "start": "981680",
    "end": "987279"
  },
  {
    "text": "the URL is point to the second check service and it's looking for the Matrix call DNS missing lock restarts what does",
    "start": "987279",
    "end": "994880"
  },
  {
    "text": "it mean it means if my call DNS Port is restarting in my cluster the permiss",
    "start": "994880",
    "end": "1000600"
  },
  {
    "text": "server will receive this signal and send a remote write request to the second",
    "start": "1000600",
    "end": "1005720"
  },
  {
    "text": "check service now how does the second check service talk to the kgpt so we run those",
    "start": "1005720",
    "end": "1013240"
  },
  {
    "text": "two parts in the same name space so they can talk through a kubernetes service and then is talking through a grpc",
    "start": "1013240",
    "end": "1020680"
  },
  {
    "text": "connect so here is a code example of how you can use the grpc client to talk to",
    "start": "1020680",
    "end": "1026160"
  },
  {
    "text": "kgpt and we're calling uh API called analyze request and it provides the",
    "start": "1026160",
    "end": "1032079"
  },
  {
    "text": "target name space and is explain meaning if you want to enable the AI or not and",
    "start": "1032079",
    "end": "1037839"
  },
  {
    "text": "the filter is an array of streams that you can give for the filters for the analyzers such as pod log notes and the",
    "start": "1037839",
    "end": "1046319"
  },
  {
    "text": "back end is referring that which AI package you want to",
    "start": "1046319",
    "end": "1051399"
  },
  {
    "text": "use now uh let's take a deeper look at what is a",
    "start": "1051440",
    "end": "1056880"
  },
  {
    "text": "kgpt it's an open source tool for scanning your cluster diagnosing and Charing issues it has a good uh array of",
    "start": "1056880",
    "end": "1065440"
  },
  {
    "text": "analyzers that itos the relevant information from your kubernetes object spec such as Parts notes kubernetes",
    "start": "1065440",
    "end": "1073520"
  },
  {
    "text": "Service kubernetes events and even the life log so it integrates with different",
    "start": "1073520",
    "end": "1079559"
  },
  {
    "text": "AI platform for um to enrich your error message or to get REM accommodation",
    "start": "1079559",
    "end": "1085320"
  },
  {
    "text": "Solutions so here you can see from the chart it can call the open AI API it can",
    "start": "1085320",
    "end": "1091480"
  },
  {
    "text": "also call the Google jmi API and then in addition you can also set up your local",
    "start": "1091480",
    "end": "1097000"
  },
  {
    "text": "l l through the local AI interface so let's take a look at the",
    "start": "1097000",
    "end": "1103360"
  },
  {
    "text": "sample output of two analyzers uh this output does not have ai in a mod so this",
    "start": "1103360",
    "end": "1109559"
  },
  {
    "text": "is simply scan the object spec and retrieve the information from the",
    "start": "1109559",
    "end": "1114640"
  },
  {
    "text": "kubernetes events or the spec status so for the crown job analyzer it checks for",
    "start": "1114640",
    "end": "1120440"
  },
  {
    "text": "if your crown job is running as expected and for the deployment it also check if the replic has matches the actual report",
    "start": "1120440",
    "end": "1127400"
  },
  {
    "text": "running and reports the error so let's also take a look up",
    "start": "1127400",
    "end": "1133320"
  },
  {
    "text": "example of the P analyzer so if you go through the code in the high level it will fch all all the ports in the Target",
    "start": "1133320",
    "end": "1140039"
  },
  {
    "text": "name spaces and for each Port it will go through each containers check for studies for pending or crush and once it",
    "start": "1140039",
    "end": "1147480"
  },
  {
    "text": "founds that this port is not in a good state it will fench the latest kubernetes invents Aggregates all the",
    "start": "1147480",
    "end": "1153440"
  },
  {
    "text": "fer fer messages into output if you have ai option enabled it will create a promp",
    "start": "1153440",
    "end": "1159760"
  },
  {
    "text": "with all error messages and ask a solution from the public",
    "start": "1159760",
    "end": "1166840"
  },
  {
    "text": "aom so after capturing the arrow details by the kgpt the next step is remediation",
    "start": "1166840",
    "end": "1173720"
  },
  {
    "text": "so kgpt provides pretty good integration with public a which has reach context of",
    "start": "1173720",
    "end": "1179840"
  },
  {
    "text": "General kubernetes AWS knowledge however it doesn't understand uh doesn't have",
    "start": "1179840",
    "end": "1186039"
  },
  {
    "text": "any context of intu kubernetes cluster specific issues because we have our own custom addons we have our own networking",
    "start": "1186039",
    "end": "1193440"
  },
  {
    "text": "configuration imro authentication so therefore in addition to the public a M",
    "start": "1193440",
    "end": "1199280"
  },
  {
    "text": "we also use AI with our private content such as our wrong books and documents which can help us to solve the",
    "start": "1199280",
    "end": "1207360"
  },
  {
    "text": "specific INE kubernetes cluster issues so let's take a look at the",
    "start": "1207360",
    "end": "1213720"
  },
  {
    "text": "output of a case GPT with open AI API so we we were using the model GPT for 32k",
    "start": "1213720",
    "end": "1221080"
  },
  {
    "text": "and on the right is the prompt we are using to tell the AI what kind of format and solution we want so if you look at",
    "start": "1221080",
    "end": "1228360"
  },
  {
    "text": "the example it's the same um analyzer I shared in the previous slides so it says",
    "start": "1228360",
    "end": "1233679"
  },
  {
    "text": "that your deployment has one replica but zero available with the help of the AI",
    "start": "1233679",
    "end": "1239080"
  },
  {
    "text": "it actually added more details in the arrow session you say it will say okay",
    "start": "1239080",
    "end": "1244320"
  },
  {
    "text": "it may due to various of reasons like part are not being scheduled the PA are question or the written is prop feeling",
    "start": "1244320",
    "end": "1251600"
  },
  {
    "text": "and the second part it provide the solution step by step with the c CTO example commands like you can check your",
    "start": "1251600",
    "end": "1259000"
  },
  {
    "text": "deployments check the logs of your p and if you you can you need to check your application health and point and then it",
    "start": "1259000",
    "end": "1266320"
  },
  {
    "text": "tells you how to fix the USU by using the C",
    "start": "1266320",
    "end": "1271440"
  },
  {
    "text": "apply and then we also try to try to deploy a local a with llama 23b model",
    "start": "1271760",
    "end": "1278480"
  },
  {
    "text": "which running the same cluster on the GPU uh we use we were using the same",
    "start": "1278480",
    "end": "1283520"
  },
  {
    "text": "promp and we run against the same problem so it generate very similar solution",
    "start": "1283520",
    "end": "1289120"
  },
  {
    "text": "like a bunch of kuo commands that you can check the logs and check the",
    "start": "1289120",
    "end": "1294320"
  },
  {
    "text": "deployment the but it actually added a little bit of extra steps at the end says you can scale down or try to scale",
    "start": "1294320",
    "end": "1301880"
  },
  {
    "text": "down and scale up your deployment again or you can try to roll back to a previous version so we can see as we",
    "start": "1301880",
    "end": "1309080"
  },
  {
    "text": "compare both results they are both reasonable and they are actually steps we we we do when we troubleshooting a",
    "start": "1309080",
    "end": "1315520"
  },
  {
    "text": "cluster issue so moving to the private embeddings in",
    "start": "1315520",
    "end": "1323400"
  },
  {
    "text": "has deploy uh deployed um private embedding platform that use embedding",
    "start": "1323400",
    "end": "1328600"
  },
  {
    "text": "based search to provide a service to get an answer from your private content with",
    "start": "1328600",
    "end": "1334279"
  },
  {
    "text": "AI so there are three steps here uh first step is data",
    "start": "1334279",
    "end": "1339640"
  },
  {
    "text": "preparation so we can upload our wrong books and documents through their a uh UI or",
    "start": "1339640",
    "end": "1345960"
  },
  {
    "text": "API and the service will break down down your documents into chunks and create",
    "start": "1345960",
    "end": "1351039"
  },
  {
    "text": "embeddings by calling the open AI embedding API and store those vectors in",
    "start": "1351039",
    "end": "1356360"
  },
  {
    "text": "a vector DB the second step is data searching so when when the second check",
    "start": "1356360",
    "end": "1362640"
  },
  {
    "text": "service ask ask this service for an answer from my private content the",
    "start": "1362640",
    "end": "1369360"
  },
  {
    "text": "service will embed the queries by using the same API and use the distance",
    "start": "1369360",
    "end": "1375240"
  },
  {
    "text": "between query embeddings and data embeddings to rank the content and then",
    "start": "1375240",
    "end": "1380840"
  },
  {
    "text": "returner the top and relevant content the last step is to ask AI so",
    "start": "1380840",
    "end": "1387039"
  },
  {
    "text": "the relevant content will be added into a prompt and then send to a public a to",
    "start": "1387039",
    "end": "1392880"
  },
  {
    "text": "generate a response so here basically we are feding the model with relevant",
    "start": "1392880",
    "end": "1398480"
  },
  {
    "text": "context through a model input The Prompt can be something like um please use the",
    "start": "1398480",
    "end": "1403600"
  },
  {
    "text": "following context to answer the question XY day",
    "start": "1403600",
    "end": "1409400"
  },
  {
    "text": "this is the steps I just described so let's look at a",
    "start": "1409400",
    "end": "1415320"
  },
  {
    "text": "demo okay so we have deployed two parts in the debac name space kgpt and the",
    "start": "1416080",
    "end": "1422679"
  },
  {
    "text": "second check and we have created two services that can access them in the",
    "start": "1422679",
    "end": "1428880"
  },
  {
    "text": "same name space now let's check the premises rules",
    "start": "1428880",
    "end": "1434120"
  },
  {
    "text": "we have configured for this demo it's in a different name space",
    "start": "1434120",
    "end": "1440000"
  },
  {
    "text": "and we can see under the remote right session we configur the URL with uh to",
    "start": "1440000",
    "end": "1445880"
  },
  {
    "text": "the second check end point and it's looking for the Matrix coding as missing log restarts now we have to create Arrow",
    "start": "1445880",
    "end": "1453919"
  },
  {
    "text": "situation now the code DS Port is restarting or",
    "start": "1453919",
    "end": "1458840"
  },
  {
    "text": "Crush so let's check the code DS Port",
    "start": "1458960",
    "end": "1464000"
  },
  {
    "text": "status now we see that the cordinates are in the crushing Loop so we can describe the port to see to get more",
    "start": "1466520",
    "end": "1473360"
  },
  {
    "text": "details of why this port in the crushing Loop let's pick up one of the",
    "start": "1473360",
    "end": "1479279"
  },
  {
    "text": "part and it's running in the coup system name space and then we can see it's in",
    "start": "1479279",
    "end": "1484840"
  },
  {
    "text": "the crushing Loop because it's R killed then at this time then they",
    "start": "1484840",
    "end": "1490440"
  },
  {
    "text": "should see send a signal to the permissive server and the permiss server should send the remote right request to",
    "start": "1490440",
    "end": "1497640"
  },
  {
    "text": "the second check service here we're looking at the logs of the second check service so we can see that it receives",
    "start": "1497640",
    "end": "1504919"
  },
  {
    "text": "the Matrix of code DNS restart bom killed after it received the Matrix it",
    "start": "1504919",
    "end": "1511440"
  },
  {
    "text": "will cause KS GPT to run a deeper check on a port then then the kgpt will scan",
    "start": "1511440",
    "end": "1518600"
  },
  {
    "text": "the target name space which is Cube system here and then check the cordian as Port spec comb by with the kubernetes",
    "start": "1518600",
    "end": "1525520"
  },
  {
    "text": "generate the error message and then ask the public a to get a response so here",
    "start": "1525520",
    "end": "1531679"
  },
  {
    "text": "we're are still using the open AI API with model GPT",
    "start": "1531679",
    "end": "1536840"
  },
  {
    "text": "432k and then we are not using the private content in this demo because the warb killed is pretty a generic issue",
    "start": "1536840",
    "end": "1543679"
  },
  {
    "text": "that kubernetes and knowledge could have it okay now we received the response",
    "start": "1543679",
    "end": "1548760"
  },
  {
    "text": "from the kgpt so the second check service will upload this results to a remote exory",
    "start": "1548760",
    "end": "1555240"
  },
  {
    "text": "bucket then we can see yeah the results is there and it's in the Json",
    "start": "1555240",
    "end": "1561080"
  },
  {
    "text": "format so it has pretty accurate results so it says that the coding Port is in",
    "start": "1561080",
    "end": "1566440"
  },
  {
    "text": "crushing Loop due to war K and you can inspect the logs uh with the commands",
    "start": "1566440",
    "end": "1572840"
  },
  {
    "text": "and they actually teach you how to increase the memory limit by changing the the resource session on the",
    "start": "1572840",
    "end": "1580399"
  },
  {
    "text": "spec so in the future we are thinking for a simple remediation step like",
    "start": "1580399",
    "end": "1585679"
  },
  {
    "text": "increasing the memory limit we hopefully can autom through the kubernetes API and of course not every war killed",
    "start": "1585679",
    "end": "1593720"
  },
  {
    "text": "issue can be fixed by simply increase your memory resource so if you have a complicated use case we would recommend",
    "start": "1593720",
    "end": "1600600"
  },
  {
    "text": "you use your private content uh plus the public content that you can get a more",
    "start": "1600600",
    "end": "1605760"
  },
  {
    "text": "accurate answer so R team is also actively",
    "start": "1605760",
    "end": "1611799"
  },
  {
    "text": "contribute back to the ks GPT Upstream there are some couple features and fixs we have worked on and we are thinking in",
    "start": "1611799",
    "end": "1619120"
  },
  {
    "text": "the road map we're thinking we can add more AWS Integrations to get details of like say ec2",
    "start": "1619120",
    "end": "1625399"
  },
  {
    "text": "instance uh status and describe the eks API server status and also even the VPC",
    "start": "1625399",
    "end": "1632399"
  },
  {
    "text": "uh configurations which can help us to troubleshooting the AWS issues in in our",
    "start": "1632399",
    "end": "1638240"
  },
  {
    "text": "cluster so with that I'm going to pass the Bard back to the anoa for take a",
    "start": "1638240",
    "end": "1644398"
  },
  {
    "text": "ways thank you Lily great demo",
    "start": "1645480",
    "end": "1650158"
  },
  {
    "text": "all right what are our three takeaways uh we were able to achieve",
    "start": "1651520",
    "end": "1657200"
  },
  {
    "text": "some streamlining using cluster golden signals where we are able to get a",
    "start": "1657200",
    "end": "1662760"
  },
  {
    "text": "bird's eyee view of the health of all of our clusters at the same time and we",
    "start": "1662760",
    "end": "1668559"
  },
  {
    "text": "were able to also alert our platforms for incident platform Engineers on",
    "start": "1668559",
    "end": "1674440"
  },
  {
    "text": "incidents using this process and by tying up cluster golden",
    "start": "1674440",
    "end": "1679679"
  },
  {
    "text": "signals with llm based debugging we are able to actually complete the loop end",
    "start": "1679679",
    "end": "1685960"
  },
  {
    "text": "to end by not only detecting early but also getting remediation",
    "start": "1685960",
    "end": "1692120"
  },
  {
    "text": "early our initial results with uh platform debugging using AI have been",
    "start": "1692120",
    "end": "1697519"
  },
  {
    "text": "pretty promising so we're going to be investing more the K GPT Community has",
    "start": "1697519",
    "end": "1703760"
  },
  {
    "text": "been pretty welcoming of our features and contributions so we're going to be continuing to do that and as Lily said a",
    "start": "1703760",
    "end": "1711880"
  },
  {
    "text": "lot of this has to be peer reviewed right now we're not applying any of the remediations that the llm is throwing at",
    "start": "1711880",
    "end": "1718519"
  },
  {
    "text": "us it's going to be peer reviewed we're also going to be looking into um uh",
    "start": "1718519",
    "end": "1724360"
  },
  {
    "text": "things like um Rags as well as enriching",
    "start": "1724360",
    "end": "1729440"
  },
  {
    "text": "our run books and using the embeddings based Q&A at this point in time",
    "start": "1729440",
    "end": "1735279"
  },
  {
    "text": "so thanks for attending our talk and uh if you guys have questions there",
    "start": "1735279",
    "end": "1741399"
  },
  {
    "text": "are two mics on the on either sides we'll be happy to",
    "start": "1741399",
    "end": "1746640"
  },
  {
    "text": "[Applause]",
    "start": "1752830",
    "end": "1756230"
  },
  {
    "text": "answer um my question is uh as you mentioned right now rag is was the thing",
    "start": "1757919",
    "end": "1764039"
  },
  {
    "text": "that I was thinking about um are you planning so that the tool can also for",
    "start": "1764039",
    "end": "1772760"
  },
  {
    "text": "example uh if while the buing there's like a tool that it can recover from or",
    "start": "1772760",
    "end": "1778519"
  },
  {
    "text": "automate something is it something that you want to try in the future or you want just to use it for",
    "start": "1778519",
    "end": "1786480"
  },
  {
    "text": "others so as far as automatically remediating we want to be careful there",
    "start": "1786480",
    "end": "1793000"
  },
  {
    "text": "uh we haven't tested it enough to actually apply the remediations and make",
    "start": "1793000",
    "end": "1798039"
  },
  {
    "text": "making sure that it works works directly the rag use case will be for making sure",
    "start": "1798039",
    "end": "1803559"
  },
  {
    "text": "that we have AC we can check the accuracy of the results that we get um",
    "start": "1803559",
    "end": "1808640"
  },
  {
    "text": "again things that we haven't explored yet but definitely rag use case would be",
    "start": "1808640",
    "end": "1813799"
  },
  {
    "text": "more for checking the accuracy of what we get back from the llm yeah okay thank",
    "start": "1813799",
    "end": "1819679"
  },
  {
    "text": "you thank",
    "start": "1819679",
    "end": "1822320"
  },
  {
    "text": "you",
    "start": "1826960",
    "end": "1829960"
  },
  {
    "text": "thank you great talk uh just one quick question are you also thinking of extending it to the logs like scanning",
    "start": "1834519",
    "end": "1841919"
  },
  {
    "text": "the logs which comes on the standard out for the pods and linking these Prometheus matrics with the logs as well",
    "start": "1841919",
    "end": "1848519"
  },
  {
    "text": "and if you are thinking on that like how much it has influence on the cost",
    "start": "1848519",
    "end": "1854320"
  },
  {
    "text": "because log ingestions and analyzing the logs has a big cost",
    "start": "1854320",
    "end": "1860159"
  },
  {
    "text": "involved So currently the kgpt already have the log analyzer so the will query",
    "start": "1860159",
    "end": "1866720"
  },
  {
    "text": "the 100 lines life log from the Pod so we are also thinking to add integration",
    "start": "1866720",
    "end": "1872639"
  },
  {
    "text": "because we are using the Splunk so we're also thinking to add integration to pull the logs from the SP Splunk but",
    "start": "1872639",
    "end": "1878960"
  },
  {
    "text": "definitely with the limitation of the length of the log and also we need to look for the keywords for example Arrow",
    "start": "1878960",
    "end": "1885799"
  },
  {
    "text": "fi faiied and Panic so that definitely comes with the cost I think we'll put",
    "start": "1885799",
    "end": "1891360"
  },
  {
    "text": "some immitation on the on the context we want to pull on the logs and also maybe",
    "start": "1891360",
    "end": "1897279"
  },
  {
    "text": "there will be some threshold on the API call if we integrate with spun we need",
    "start": "1897279",
    "end": "1902440"
  },
  {
    "text": "to be careful on the that part as well okay thank you so also just to point out",
    "start": "1902440",
    "end": "1909919"
  },
  {
    "text": "this is near real time we're not thinking about historic uh logs so there is a company",
    "start": "1909919",
    "end": "1917919"
  },
  {
    "text": "SLA of meeting which is every incident sort of gets detected within about 5",
    "start": "1917919",
    "end": "1924000"
  },
  {
    "text": "minutes remediated within lesser than an hour or some such thing so we although",
    "start": "1924000",
    "end": "1931279"
  },
  {
    "text": "the historic information and logs would be useful for training we when we are",
    "start": "1931279",
    "end": "1937440"
  },
  {
    "text": "actually querying for immediate use um we we we wouldn't be looking too far in",
    "start": "1937440",
    "end": "1944240"
  },
  {
    "text": "the in in in the history so it would be what you have local and then for",
    "start": "1944240",
    "end": "1949600"
  },
  {
    "text": "depending on the use case going out to getting slightly more than the time windower yeah makes sense thank you I",
    "start": "1949600",
    "end": "1956559"
  },
  {
    "text": "just want to add more so I feel the log is extremely helpful if you are you have your wrong books that describe how to",
    "start": "1956559",
    "end": "1963360"
  },
  {
    "text": "solve a specific problem according to that logs yeah hi thank you for your talk uh have",
    "start": "1963360",
    "end": "1970760"
  },
  {
    "text": "you experiened with adding business logic like what service was affected",
    "start": "1970760",
    "end": "1976840"
  },
  {
    "text": "what say office was affected or what component was affected and stuff like",
    "start": "1976840",
    "end": "1984360"
  },
  {
    "text": "that yeah so right now the components or the services that we're thinking about",
    "start": "1984360",
    "end": "1989679"
  },
  {
    "text": "are limited to the cluster components um",
    "start": "1989679",
    "end": "1995480"
  },
  {
    "text": "but we definitely want to extend it to business logic or business anal because",
    "start": "1995480",
    "end": "2001000"
  },
  {
    "text": "when there is an incident call like U we get asked a lot of questions that we",
    "start": "2001000",
    "end": "2006559"
  },
  {
    "text": "don't have out of the box charts for and then we have to scramble around and get",
    "start": "2006559",
    "end": "2011840"
  },
  {
    "text": "some operational data from from what we have so that's definitely something we want to uh work on which clients were",
    "start": "2011840",
    "end": "2019399"
  },
  {
    "text": "affected how many how yes which region which yeah exactly yeah definitely well",
    "start": "2019399",
    "end": "2025600"
  },
  {
    "text": "thank you again thanks uh thank you uh I have a question",
    "start": "2025600",
    "end": "2033399"
  },
  {
    "text": "like we have one problem but there might be a situation uh m multiple incidents",
    "start": "2033399",
    "end": "2038480"
  },
  {
    "text": "will be triggered for one particular problem right so when we use this kgbt uh multiple Solutions will be there",
    "start": "2038480",
    "end": "2045440"
  },
  {
    "text": "but actually the root cause is one so how do you have this incident crawls like or sprawls like many incidents with",
    "start": "2045440",
    "end": "2053280"
  },
  {
    "text": "everybody is debugging into different different but actual root cause is one so how the empty or time on all these",
    "start": "2053280",
    "end": "2059040"
  },
  {
    "text": "things you have mentioned right in this kind of situation how do you deal with it because it keeps generating a lot of",
    "start": "2059040",
    "end": "2064919"
  },
  {
    "text": "solutions you get into solution fatig or which one to pick yeah yeah that's a good question so",
    "start": "2064919",
    "end": "2071720"
  },
  {
    "text": "we try and solve that using cluster golden signals where the dashboards that we've built so let's say we have uh case",
    "start": "2071720",
    "end": "2079440"
  },
  {
    "text": "in point let's say we have an outage because of a cni issue and there are five different clusters that are",
    "start": "2079440",
    "end": "2086200"
  },
  {
    "text": "affected by it all in their own silos but when you actually look at the golden",
    "start": "2086200",
    "end": "2091320"
  },
  {
    "text": "cluster sign cluster golden signal dashboard you can actually group it by cluster component that is f and",
    "start": "2091320",
    "end": "2098760"
  },
  {
    "text": "hopefully all of these five clusters would actually show up as red because they their health was degraded or",
    "start": "2098760",
    "end": "2105160"
  },
  {
    "text": "critical and they would actually fire up so you would actually catch it a little",
    "start": "2105160",
    "end": "2110680"
  },
  {
    "text": "ahead of time rather than the K GPT the K GPT would still there is no D",
    "start": "2110680",
    "end": "2116040"
  },
  {
    "text": "duplication of solutions at the kgpt level but there is at the cluster golden",
    "start": "2116040",
    "end": "2122359"
  },
  {
    "text": "signal level where all the cni would be failing on the five clusters and you know that there is you could basically",
    "start": "2122359",
    "end": "2129160"
  },
  {
    "text": "do deeper debugging with that knowledge okay so you use uh human cognitive things on the side on the par means I",
    "start": "2129160",
    "end": "2137000"
  },
  {
    "text": "mean to say human little bit uh we manually do this things uh at the stage",
    "start": "2137000",
    "end": "2143920"
  },
  {
    "text": "or yeah so you would have to look at the five solutions that are coming out of",
    "start": "2143920",
    "end": "2149240"
  },
  {
    "text": "these clusters with the understanding that all of these five actually failed their cni checks in the cluster golden",
    "start": "2149240",
    "end": "2155200"
  },
  {
    "text": "signal so so so far yeah yeah but there's definitely room for improving that yeah thank you so much thank you",
    "start": "2155200",
    "end": "2161760"
  },
  {
    "text": "thank you yeah also thanks a lot um I have a",
    "start": "2161760",
    "end": "2167000"
  },
  {
    "text": "question um as far as I understood the reses from the AI analysation will be",
    "start": "2167000",
    "end": "2172680"
  },
  {
    "text": "stored in a S3 bucket um how are the golden signal alerts mapped to the",
    "start": "2172680",
    "end": "2179880"
  },
  {
    "text": "analyzed content and how will the system engineer then later on access the stuff",
    "start": "2179880",
    "end": "2185839"
  },
  {
    "text": "on the S3 bucket so um basically Intuit has some internal",
    "start": "2185839",
    "end": "2194800"
  },
  {
    "text": "platform internal user platforms that we can consume those data from Sr bucket and present to the user maybe on a UI or",
    "start": "2194800",
    "end": "2202319"
  },
  {
    "text": "something and also we can read the data from the S3 bucket to automatically create wrong books from the public L and",
    "start": "2202319",
    "end": "2210680"
  },
  {
    "text": "enrich the private content for our private embeddings as well so I think instead in the future when we get this",
    "start": "2210680",
    "end": "2217839"
  },
  {
    "text": "system up a running uh instead of S3 we can maybe add another DB or DB and",
    "start": "2217839",
    "end": "2223520"
  },
  {
    "text": "to save it more properly and can be rendered through the apis and can be",
    "start": "2223520",
    "end": "2228599"
  },
  {
    "text": "consumed by different services or different other platforms within the Inuit the the ideal Target State we're",
    "start": "2228599",
    "end": "2235400"
  },
  {
    "text": "thinking about is when the platform engineer got an alert uh they actually",
    "start": "2235400",
    "end": "2241960"
  },
  {
    "text": "have embedded metadata as part of their either pay Duty alert or something with",
    "start": "2241960",
    "end": "2247520"
  },
  {
    "text": "all of the enriched remediation steps in there as well so the loop goes back to",
    "start": "2247520",
    "end": "2252800"
  },
  {
    "text": "the alert and we might be able to pull that off with page Duty uh metadata yeah",
    "start": "2252800",
    "end": "2259599"
  },
  {
    "text": "okay thanks thank you any more",
    "start": "2259599",
    "end": "2266319"
  },
  {
    "text": "questions all right thank you very much thank you",
    "start": "2266880",
    "end": "2272800"
  }
]
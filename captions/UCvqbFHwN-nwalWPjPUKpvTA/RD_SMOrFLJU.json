[
  {
    "text": "so today we will be sharing our journey",
    "start": "160",
    "end": "2360"
  },
  {
    "text": "along the the way to data locality on",
    "start": "2360",
    "end": "5640"
  },
  {
    "text": "Cloud for machine learning and AI",
    "start": "5640",
    "end": "7319"
  },
  {
    "text": "workloads my name is Sean I'm a software",
    "start": "7319",
    "end": "10080"
  },
  {
    "text": "engineer at loil and my colleague Lou",
    "start": "10080",
    "end": "13639"
  },
  {
    "text": "Who will",
    "start": "13639",
    "end": "14559"
  },
  {
    "text": "be talking about the second half of the",
    "start": "14559",
    "end": "17080"
  },
  {
    "text": "deck later she's a machine learning",
    "start": "17080",
    "end": "19880"
  },
  {
    "text": "engineer at Lille and the same time",
    "start": "19880",
    "end": "21960"
  },
  {
    "text": "she's also PMT member of our Alexa open",
    "start": "21960",
    "end": "24760"
  },
  {
    "text": "source",
    "start": "24760",
    "end": "27080"
  },
  {
    "text": "project so here's agenda of today so",
    "start": "28439",
    "end": "31480"
  },
  {
    "text": "first we'll talk about the benefits of",
    "start": "31480",
    "end": "33840"
  },
  {
    "text": "data locality and what are some of the",
    "start": "33840",
    "end": "36559"
  },
  {
    "text": "existing",
    "start": "36559",
    "end": "38079"
  },
  {
    "text": "Solutions then we'll bring up a new",
    "start": "38079",
    "end": "40239"
  },
  {
    "text": "design along with this implementation",
    "start": "40239",
    "end": "42680"
  },
  {
    "text": "and finally about some production use",
    "start": "42680",
    "end": "45120"
  },
  {
    "text": "case and the integration between lox and",
    "start": "45120",
    "end": "47800"
  },
  {
    "text": "AR",
    "start": "47800",
    "end": "49878"
  },
  {
    "text": "aray so first about the advantages of",
    "start": "49960",
    "end": "53960"
  },
  {
    "text": "bring data locality to",
    "start": "53960",
    "end": "56920"
  },
  {
    "text": "Cloud there are two main reasons the",
    "start": "56920",
    "end": "59440"
  },
  {
    "text": "first is performance game compared to",
    "start": "59440",
    "end": "62519"
  },
  {
    "text": "remote storage like S3 or AER or gcp you",
    "start": "62519",
    "end": "67080"
  },
  {
    "text": "have faster access to the",
    "start": "67080",
    "end": "70200"
  },
  {
    "text": "data therefore there will be less time",
    "start": "70200",
    "end": "72840"
  },
  {
    "text": "spent on data intensive applications",
    "start": "72840",
    "end": "75439"
  },
  {
    "text": "especially machine learning and AI over",
    "start": "75439",
    "end": "79600"
  },
  {
    "text": "clads the second main reason is about",
    "start": "79600",
    "end": "82119"
  },
  {
    "text": "cost cost saving because by reading from",
    "start": "82119",
    "end": "84880"
  },
  {
    "text": "us there will be fewer API costs made to",
    "start": "84880",
    "end": "87479"
  },
  {
    "text": "the cloud storage this includes both St",
    "start": "87479",
    "end": "89920"
  },
  {
    "text": "data and metadata API",
    "start": "89920",
    "end": "92119"
  },
  {
    "text": "cost and because of the performance gain",
    "start": "92119",
    "end": "95360"
  },
  {
    "text": "we have higher utilization of your",
    "start": "95360",
    "end": "97880"
  },
  {
    "text": "GPU less tribute time Le also leads to",
    "start": "97880",
    "end": "101280"
  },
  {
    "text": "less",
    "start": "101280",
    "end": "103600"
  },
  {
    "text": "cost now we'll look at some of the",
    "start": "105560",
    "end": "108000"
  },
  {
    "text": "existing Solutions out",
    "start": "108000",
    "end": "111119"
  },
  {
    "text": "there there are the main mainstream has",
    "start": "111880",
    "end": "115520"
  },
  {
    "text": "like two or four Solutions first is to",
    "start": "115520",
    "end": "118479"
  },
  {
    "text": "read data directly from remote storage",
    "start": "118479",
    "end": "120799"
  },
  {
    "text": "on fly second is to copy data from",
    "start": "120799",
    "end": "124479"
  },
  {
    "text": "remote to local before the training the",
    "start": "124479",
    "end": "127439"
  },
  {
    "text": "third is to use a local cach layer for",
    "start": "127439",
    "end": "130840"
  },
  {
    "text": "data reuse and lastly we can use a",
    "start": "130840",
    "end": "134400"
  },
  {
    "text": "distributed cache",
    "start": "134400",
    "end": "136519"
  },
  {
    "text": "system let's go over the one by one so",
    "start": "136519",
    "end": "140200"
  },
  {
    "text": "first if we always read from read data",
    "start": "140200",
    "end": "142319"
  },
  {
    "text": "from remote storage there will be no",
    "start": "142319",
    "end": "144040"
  },
  {
    "text": "data locality this is the easiest way to",
    "start": "144040",
    "end": "146680"
  },
  {
    "text": "sell up but at the same time every app",
    "start": "146680",
    "end": "150120"
  },
  {
    "text": "training needs to reread all the data",
    "start": "150120",
    "end": "152519"
  },
  {
    "text": "from",
    "start": "152519",
    "end": "153440"
  },
  {
    "text": "remote and because multiple AO are",
    "start": "153440",
    "end": "155920"
  },
  {
    "text": "always always needed for better accuracy",
    "start": "155920",
    "end": "159319"
  },
  {
    "text": "I mean there's no way your training only",
    "start": "159319",
    "end": "161200"
  },
  {
    "text": "involved one Appo and then reading from",
    "start": "161200",
    "end": "163920"
  },
  {
    "text": "remote will",
    "start": "163920",
    "end": "165840"
  },
  {
    "text": "take can take more time than the actual",
    "start": "165840",
    "end": "168519"
  },
  {
    "text": "training so here's a screenshot that we",
    "start": "168519",
    "end": "171400"
  },
  {
    "text": "uh did a test this is a uh P torch",
    "start": "171400",
    "end": "175879"
  },
  {
    "text": "training on a subet of image net so you",
    "start": "175879",
    "end": "180519"
  },
  {
    "text": "can see",
    "start": "180519",
    "end": "182440"
  },
  {
    "text": "82% per of the time is actually spent by",
    "start": "182440",
    "end": "185480"
  },
  {
    "text": "the data loader instead of the ACT",
    "start": "185480",
    "end": "187560"
  },
  {
    "text": "actual",
    "start": "187560",
    "end": "189879"
  },
  {
    "text": "training oh by the way the uh this",
    "start": "189959",
    "end": "193040"
  },
  {
    "text": "tested data was on on",
    "start": "193040",
    "end": "197079"
  },
  {
    "text": "S3 so the second way we just mention is",
    "start": "197319",
    "end": "200640"
  },
  {
    "text": "to copy the data to local before",
    "start": "200640",
    "end": "202599"
  },
  {
    "text": "training so now the data is local so",
    "start": "202599",
    "end": "205760"
  },
  {
    "text": "that so that you can get all the",
    "start": "205760",
    "end": "207040"
  },
  {
    "text": "benefits of data locality that incl Bo",
    "start": "207040",
    "end": "210040"
  },
  {
    "text": "cost saving and performance gain but",
    "start": "210040",
    "end": "212640"
  },
  {
    "text": "then the management is hard because you",
    "start": "212640",
    "end": "215319"
  },
  {
    "text": "must manually delete delete the training",
    "start": "215319",
    "end": "217680"
  },
  {
    "text": "data after use because you have limited",
    "start": "217680",
    "end": "220120"
  },
  {
    "text": "disk space if you don't delete data then",
    "start": "220120",
    "end": "222920"
  },
  {
    "text": "the next person or even yourself there's",
    "start": "222920",
    "end": "225319"
  },
  {
    "text": "no place to store your next training",
    "start": "225319",
    "end": "228200"
  },
  {
    "text": "data on your local",
    "start": "228200",
    "end": "230640"
  },
  {
    "text": "disk and also because we are just cach",
    "start": "230640",
    "end": "234400"
  },
  {
    "text": "that they store data in the local the",
    "start": "234400",
    "end": "237319"
  },
  {
    "text": "space is limited nowadays we all know",
    "start": "237319",
    "end": "240319"
  },
  {
    "text": "the data set can be huge so only",
    "start": "240319",
    "end": "244400"
  },
  {
    "text": "partially or even a small amount of data",
    "start": "244400",
    "end": "247879"
  },
  {
    "text": "will be stored locally so you only get",
    "start": "247879",
    "end": "250640"
  },
  {
    "text": "limited benefits of data",
    "start": "250640",
    "end": "254159"
  },
  {
    "text": "locality now talking about local cach",
    "start": "255519",
    "end": "257759"
  },
  {
    "text": "layer for the data reuse some of the",
    "start": "257759",
    "end": "260880"
  },
  {
    "text": "examples including s3fs butin local",
    "start": "260880",
    "end": "263520"
  },
  {
    "text": "cache and AOG to FS",
    "start": "263520",
    "end": "265479"
  },
  {
    "text": "fdk now re reuse data is local as well",
    "start": "265479",
    "end": "268960"
  },
  {
    "text": "because after the first",
    "start": "268960",
    "end": "270919"
  },
  {
    "text": "time that part that part data is now",
    "start": "270919",
    "end": "274320"
  },
  {
    "text": "cached",
    "start": "274320",
    "end": "276280"
  },
  {
    "text": "locally",
    "start": "276280",
    "end": "278120"
  },
  {
    "text": "and this uh this local Cash System can",
    "start": "278120",
    "end": "281720"
  },
  {
    "text": "help you with sta",
    "start": "281720",
    "end": "283160"
  },
  {
    "text": "management so that you don't have to do",
    "start": "283160",
    "end": "285240"
  },
  {
    "text": "manual deletion or manual supervision to",
    "start": "285240",
    "end": "288199"
  },
  {
    "text": "make sure everything is deleted and on",
    "start": "288199",
    "end": "291720"
  },
  {
    "text": "track but the same problem is Cash space",
    "start": "291720",
    "end": "294440"
  },
  {
    "text": "is limited",
    "start": "294440",
    "end": "297600"
  },
  {
    "text": "now the fourth way that we mentioned",
    "start": "300639",
    "end": "302840"
  },
  {
    "text": "earlier is to use a distributed cach",
    "start": "302840",
    "end": "305520"
  },
  {
    "text": "system this is what Al 2.x looks like we",
    "start": "305520",
    "end": "309759"
  },
  {
    "text": "followed a traditional distributed",
    "start": "309759",
    "end": "311759"
  },
  {
    "text": "system architecture where there's a",
    "start": "311759",
    "end": "314520"
  },
  {
    "text": "centralized moners and Masters means we",
    "start": "314520",
    "end": "318520"
  },
  {
    "text": "use some of the algorithm to make sure",
    "start": "318520",
    "end": "320960"
  },
  {
    "text": "there's High",
    "start": "320960",
    "end": "323840"
  },
  {
    "text": "availability now with multiple workers",
    "start": "323960",
    "end": "326720"
  },
  {
    "text": "that can distribute among different",
    "start": "326720",
    "end": "328800"
  },
  {
    "text": "nodes we can store much more cach data",
    "start": "328800",
    "end": "331400"
  },
  {
    "text": "compared to local",
    "start": "331400",
    "end": "332960"
  },
  {
    "text": "cache and also the system provides data",
    "start": "332960",
    "end": "335759"
  },
  {
    "text": "management",
    "start": "335759",
    "end": "337520"
  },
  {
    "text": "functionalities however we all know on",
    "start": "337520",
    "end": "340520"
  },
  {
    "text": "kubernetes or on cloud the no sometimes",
    "start": "340520",
    "end": "343199"
  },
  {
    "text": "need",
    "start": "343199",
    "end": "344319"
  },
  {
    "text": "maintenance and there will be masterer",
    "start": "344319",
    "end": "346720"
  },
  {
    "text": "failovers if anything happens so during",
    "start": "346720",
    "end": "349680"
  },
  {
    "text": "that time moner is not serving it's um",
    "start": "349680",
    "end": "352440"
  },
  {
    "text": "it's not doing its job so MERS now is a",
    "start": "352440",
    "end": "355639"
  },
  {
    "text": "single point of",
    "start": "355639",
    "end": "358319"
  },
  {
    "text": "failure and with AI and machine learning",
    "start": "358319",
    "end": "361520"
  },
  {
    "text": "workflows we are seeing the data set",
    "start": "361520",
    "end": "364160"
  },
  {
    "text": "gets larger and",
    "start": "364160",
    "end": "365560"
  },
  {
    "text": "larger it's very common to see a",
    "start": "365560",
    "end": "368319"
  },
  {
    "text": "training involves billions of files and",
    "start": "368319",
    "end": "371400"
  },
  {
    "text": "all the metadata of the files are stored",
    "start": "371400",
    "end": "373479"
  },
  {
    "text": "in moners so the huge number of files is",
    "start": "373479",
    "end": "375720"
  },
  {
    "text": "making the master the bottom neck of",
    "start": "375720",
    "end": "377599"
  },
  {
    "text": "overall",
    "start": "377599",
    "end": "380080"
  },
  {
    "text": "performance now just to sum to summarize",
    "start": "384479",
    "end": "387160"
  },
  {
    "text": "all the challenges we're facing with all",
    "start": "387160",
    "end": "389280"
  },
  {
    "text": "this ex existing Solutions the first",
    "start": "389280",
    "end": "392440"
  },
  {
    "text": "local cach storage space is",
    "start": "392440",
    "end": "395199"
  },
  {
    "text": "limited and because of amount of data is",
    "start": "395199",
    "end": "397440"
  },
  {
    "text": "gr fast this is this is now becoming a",
    "start": "397440",
    "end": "401479"
  },
  {
    "text": "problem the second is",
    "start": "401479",
    "end": "404639"
  },
  {
    "text": "reliability because on cloud and kuet",
    "start": "404639",
    "end": "407720"
  },
  {
    "text": "availability is the key for every single",
    "start": "407720",
    "end": "411240"
  },
  {
    "text": "service the third point is",
    "start": "411240",
    "end": "413639"
  },
  {
    "text": "scalability number of files for training",
    "start": "413639",
    "end": "416120"
  },
  {
    "text": "is now huge in other of bilings so so if",
    "start": "416120",
    "end": "420759"
  },
  {
    "text": "you are if the metadata or some part of",
    "start": "420759",
    "end": "423840"
  },
  {
    "text": "your system is becoming the bottleneck",
    "start": "423840",
    "end": "426599"
  },
  {
    "text": "as and making the system is even slower",
    "start": "426599",
    "end": "431560"
  },
  {
    "text": "than just reading remote storage is",
    "start": "431560",
    "end": "434440"
  },
  {
    "text": "certainly not",
    "start": "434440",
    "end": "435879"
  },
  {
    "text": "acceptable and last point is data",
    "start": "435879",
    "end": "438639"
  },
  {
    "text": "management we don't want any Manu work",
    "start": "438639",
    "end": "441400"
  },
  {
    "text": "nobody",
    "start": "441400",
    "end": "443720"
  },
  {
    "text": "wants now let's talk about the new",
    "start": "445479",
    "end": "447560"
  },
  {
    "text": "design",
    "start": "447560",
    "end": "450560"
  },
  {
    "text": "the new design involves using consistent",
    "start": "452680",
    "end": "454360"
  },
  {
    "text": "hashing for cashing data we completely",
    "start": "454360",
    "end": "458199"
  },
  {
    "text": "remov the Masters which were responsible",
    "start": "458199",
    "end": "461199"
  },
  {
    "text": "for for storing all the Met of the of",
    "start": "461199",
    "end": "464120"
  },
  {
    "text": "the files so instead we're now using",
    "start": "464120",
    "end": "467800"
  },
  {
    "text": "consistent hashing to cat both data and",
    "start": "467800",
    "end": "470120"
  },
  {
    "text": "meta on worker",
    "start": "470120",
    "end": "472800"
  },
  {
    "text": "nodes now the worker nodes have plenty",
    "start": "472800",
    "end": "475639"
  },
  {
    "text": "space of for cach because we can",
    "start": "475639",
    "end": "477599"
  },
  {
    "text": "horizontally scale them now and because",
    "start": "477599",
    "end": "480560"
  },
  {
    "text": "of there's because there's no more",
    "start": "480560",
    "end": "482280"
  },
  {
    "text": "Masters there's no more single point of",
    "start": "482280",
    "end": "483879"
  },
  {
    "text": "failure there's no more performance",
    "start": "483879",
    "end": "485800"
  },
  {
    "text": "water Masters and the system has data",
    "start": "485800",
    "end": "489039"
  },
  {
    "text": "management management",
    "start": "489039",
    "end": "490800"
  },
  {
    "text": "system it looks",
    "start": "490800",
    "end": "493680"
  },
  {
    "text": "great",
    "start": "493680",
    "end": "496680"
  },
  {
    "text": "and using cons hashing may bring load",
    "start": "497120",
    "end": "503800"
  },
  {
    "text": "imbalance some worker can be very busy",
    "start": "503800",
    "end": "506319"
  },
  {
    "text": "While others being",
    "start": "506319",
    "end": "507639"
  },
  {
    "text": "idle this not only hurt overall",
    "start": "507639",
    "end": "510759"
  },
  {
    "text": "performance but also may lead to outage",
    "start": "510759",
    "end": "513880"
  },
  {
    "text": "because one worker or several workers",
    "start": "513880",
    "end": "518120"
  },
  {
    "text": "are are under such high load that can",
    "start": "518120",
    "end": "522200"
  },
  {
    "text": "bring down all the",
    "start": "522200",
    "end": "525080"
  },
  {
    "text": "system so then we made we use this new",
    "start": "528240",
    "end": "532279"
  },
  {
    "text": "soft Affinity caching",
    "start": "532279",
    "end": "534720"
  },
  {
    "text": "solution instead of only storing one",
    "start": "534720",
    "end": "538320"
  },
  {
    "text": "copy",
    "start": "538320",
    "end": "540160"
  },
  {
    "text": "um the hash",
    "start": "540160",
    "end": "541750"
  },
  {
    "text": "[Music]",
    "start": "541750",
    "end": "542920"
  },
  {
    "text": "ring after storing the first copy we use",
    "start": "542920",
    "end": "546120"
  },
  {
    "text": "this workers information to Hash again",
    "start": "546120",
    "end": "549160"
  },
  {
    "text": "to find the next and next of course is",
    "start": "549160",
    "end": "552120"
  },
  {
    "text": "configurable and the following",
    "start": "552120",
    "end": "556120"
  },
  {
    "text": "workers therefore when the client comes",
    "start": "556120",
    "end": "560800"
  },
  {
    "text": "to comes for data and if the first",
    "start": "560800",
    "end": "564360"
  },
  {
    "text": "worker is under high load or is",
    "start": "564360",
    "end": "566320"
  },
  {
    "text": "unavailable because of Any maintenance",
    "start": "566320",
    "end": "568360"
  },
  {
    "text": "work it can ask for the second worker or",
    "start": "568360",
    "end": "572160"
  },
  {
    "text": "the third",
    "start": "572160",
    "end": "574519"
  },
  {
    "text": "worker this prevents the high load or",
    "start": "574519",
    "end": "578880"
  },
  {
    "text": "the availability of a single",
    "start": "578880",
    "end": "582839"
  },
  {
    "text": "worker so now looks let's look at the",
    "start": "586120",
    "end": "589320"
  },
  {
    "text": "implementation in Lo 3xx we implement",
    "start": "589320",
    "end": "592519"
  },
  {
    "text": "this Soft Data cach data cach scheduling",
    "start": "592519",
    "end": "596600"
  },
  {
    "text": "algorithm and we achieved much higher",
    "start": "596600",
    "end": "599519"
  },
  {
    "text": "scalability now one worker can support",
    "start": "599519",
    "end": "601839"
  },
  {
    "text": "30 to 50 million files without any",
    "start": "601839",
    "end": "605279"
  },
  {
    "text": "performance",
    "start": "605279",
    "end": "606519"
  },
  {
    "text": "degrade we have also have much higher",
    "start": "606519",
    "end": "609320"
  },
  {
    "text": "availability we have",
    "start": "609320",
    "end": "612079"
  },
  {
    "text": "99.999% off off time and there's no",
    "start": "612079",
    "end": "614320"
  },
  {
    "text": "single point of failure we also have",
    "start": "614320",
    "end": "616760"
  },
  {
    "text": "Cloud native ctive operator for easier",
    "start": "616760",
    "end": "619680"
  },
  {
    "text": "deployment and",
    "start": "619680",
    "end": "622720"
  },
  {
    "text": "management we also new newly implement",
    "start": "626519",
    "end": "630000"
  },
  {
    "text": "this Society with f FS for training alot",
    "start": "630000",
    "end": "633760"
  },
  {
    "text": "of FS can turn remote data set into",
    "start": "633760",
    "end": "637279"
  },
  {
    "text": "local directory for training so that you",
    "start": "637279",
    "end": "639920"
  },
  {
    "text": "can look at a Lo to store data or remote",
    "start": "639920",
    "end": "643800"
  },
  {
    "text": "remotely store store data just as a",
    "start": "643800",
    "end": "646839"
  },
  {
    "text": "local",
    "start": "646839",
    "end": "648639"
  },
  {
    "text": "directory the SII is responsible for",
    "start": "648639",
    "end": "651920"
  },
  {
    "text": "launching fuse P only when the data that",
    "start": "651920",
    "end": "653959"
  },
  {
    "text": "is needed so that the fuse power will",
    "start": "653959",
    "end": "657920"
  },
  {
    "text": "not always be there to",
    "start": "657920",
    "end": "659760"
  },
  {
    "text": "waste your CPU and memory",
    "start": "659760",
    "end": "664399"
  },
  {
    "text": "resources so with this we have three",
    "start": "664399",
    "end": "667000"
  },
  {
    "text": "layers caching we have fuse kernel",
    "start": "667000",
    "end": "670399"
  },
  {
    "text": "cache we have fuse local cach local disc",
    "start": "670399",
    "end": "673880"
  },
  {
    "text": "cache and then lastly we have",
    "start": "673880",
    "end": "675839"
  },
  {
    "text": "distributed cache so you can we can",
    "start": "675839",
    "end": "679320"
  },
  {
    "text": "treat this as like L1 L2 and L3 cache",
    "start": "679320",
    "end": "683000"
  },
  {
    "text": "layers and each so this Cal cach is",
    "start": "683000",
    "end": "686720"
  },
  {
    "text": "faster and local cach faster than this",
    "start": "686720",
    "end": "688720"
  },
  {
    "text": "real cach faster than you know remote",
    "start": "688720",
    "end": "692000"
  },
  {
    "text": "storage but at the same time the space",
    "start": "692000",
    "end": "695120"
  },
  {
    "text": "is also all uh growing they're more",
    "start": "695120",
    "end": "699680"
  },
  {
    "text": "stored data in distributed cach than",
    "start": "699680",
    "end": "701600"
  },
  {
    "text": "local cach than kernel",
    "start": "701600",
    "end": "704720"
  },
  {
    "text": "cach looking at some of the",
    "start": "706440",
    "end": "709680"
  },
  {
    "text": "benchmarks so here we are testing one",
    "start": "709680",
    "end": "712320"
  },
  {
    "text": "single worker with 48 threats reading",
    "start": "712320",
    "end": "716040"
  },
  {
    "text": "one reading files of size of 10",
    "start": "716040",
    "end": "718519"
  },
  {
    "text": "kilobytes",
    "start": "718519",
    "end": "719800"
  },
  {
    "text": "and here are three data points the total",
    "start": "719800",
    "end": "722399"
  },
  {
    "text": "file numbers",
    "start": "722399",
    "end": "723490"
  },
  {
    "text": "[Music]",
    "start": "723490",
    "end": "725279"
  },
  {
    "text": "are I believe this is",
    "start": "725279",
    "end": "729360"
  },
  {
    "text": "um what 24 million 48 million",
    "start": "729880",
    "end": "735040"
  },
  {
    "text": "and I think it's 4 million yeah so we",
    "start": "735800",
    "end": "739120"
  },
  {
    "text": "can see that there's no apparently no",
    "start": "739120",
    "end": "743040"
  },
  {
    "text": "performance downgrade here even though",
    "start": "743040",
    "end": "746120"
  },
  {
    "text": "the file number like we have like 10x",
    "start": "746120",
    "end": "750959"
  },
  {
    "text": "we also did a data",
    "start": "751920",
    "end": "754519"
  },
  {
    "text": "loading performance test so the first",
    "start": "754519",
    "end": "757839"
  },
  {
    "text": "one is Sav training data loading we are",
    "start": "757839",
    "end": "759680"
  },
  {
    "text": "using a subset of the image",
    "start": "759680",
    "end": "761920"
  },
  {
    "text": "net compared to S3 FS F and direct",
    "start": "761920",
    "end": "765959"
  },
  {
    "text": "reading from S3 with python B 3 we can",
    "start": "765959",
    "end": "769560"
  },
  {
    "text": "see elect Fields has a much higher ey",
    "start": "769560",
    "end": "773639"
  },
  {
    "text": "Ops and for NLP training data loading",
    "start": "773639",
    "end": "776240"
  },
  {
    "text": "here we're using a y academic data set",
    "start": "776240",
    "end": "780360"
  },
  {
    "text": "we can see three apis of a luux are all",
    "start": "780360",
    "end": "785560"
  },
  {
    "text": "all have better throughput then using S3",
    "start": "785560",
    "end": "789399"
  },
  {
    "text": "FS Fu stand",
    "start": "789399",
    "end": "790839"
  },
  {
    "text": "Lo a",
    "start": "790839",
    "end": "794199"
  },
  {
    "text": "ss3 now we'll be looking at",
    "start": "795839",
    "end": "798519"
  },
  {
    "text": "some real",
    "start": "798519",
    "end": "800519"
  },
  {
    "text": "world production use case and I'll hand",
    "start": "800519",
    "end": "804760"
  },
  {
    "text": "to do from",
    "start": "804760",
    "end": "807800"
  },
  {
    "text": "here okay thank you Sean for introducing",
    "start": "807880",
    "end": "810560"
  },
  {
    "text": "the design implementation now I'm going",
    "start": "810560",
    "end": "812519"
  },
  {
    "text": "to tell us little more about like how we",
    "start": "812519",
    "end": "814760"
  },
  {
    "text": "actually do that in production use cases",
    "start": "814760",
    "end": "817560"
  },
  {
    "text": "and take the large language model",
    "start": "817560",
    "end": "819399"
  },
  {
    "text": "pipeline as an example so this is shared",
    "start": "819399",
    "end": "822160"
  },
  {
    "text": "by one of our users that they do face",
    "start": "822160",
    "end": "824639"
  },
  {
    "text": "some problems in their model training",
    "start": "824639",
    "end": "826240"
  },
  {
    "text": "and model inference they mainly face",
    "start": "826240",
    "end": "828519"
  },
  {
    "text": "three problems here so they normally",
    "start": "828519",
    "end": "831600"
  },
  {
    "text": "have multiple clouds that they are",
    "start": "831600",
    "end": "833079"
  },
  {
    "text": "actually doing the chaining with",
    "start": "833079",
    "end": "834480"
  },
  {
    "text": "different Frameworks like Pyon like",
    "start": "834480",
    "end": "836440"
  },
  {
    "text": "spark and they have that different",
    "start": "836440",
    "end": "838519"
  },
  {
    "text": "stories distance some of the data that",
    "start": "838519",
    "end": "840680"
  },
  {
    "text": "are stor in object storage some of the",
    "start": "840680",
    "end": "842800"
  },
  {
    "text": "data that are actually controlled by",
    "start": "842800",
    "end": "844440"
  },
  {
    "text": "their own per hdfs cluster and when",
    "start": "844440",
    "end": "847320"
  },
  {
    "text": "training need to load the data from",
    "start": "847320",
    "end": "849240"
  },
  {
    "text": "storage system they found like mainly",
    "start": "849240",
    "end": "851440"
  },
  {
    "text": "two problems so first is that because",
    "start": "851440",
    "end": "854519"
  },
  {
    "text": "every time the chaining need to get the",
    "start": "854519",
    "end": "856240"
  },
  {
    "text": "data from the storage system it need to",
    "start": "856240",
    "end": "858480"
  },
  {
    "text": "go through the network and so that the",
    "start": "858480",
    "end": "861120"
  },
  {
    "text": "higher the further away the data from",
    "start": "861120",
    "end": "863839"
  },
  {
    "text": "compute then the longer time it takes to",
    "start": "863839",
    "end": "866040"
  },
  {
    "text": "get the data for your training job and",
    "start": "866040",
    "end": "868440"
  },
  {
    "text": "training job need to repeatedly fing the",
    "start": "868440",
    "end": "870759"
  },
  {
    "text": "data from cloud storage it will also put",
    "start": "870759",
    "end": "873320"
  },
  {
    "text": "the storage system either under really",
    "start": "873320",
    "end": "875680"
  },
  {
    "text": "heavy load so for object storage like S3",
    "start": "875680",
    "end": "879079"
  },
  {
    "text": "they will basically like set a request",
    "start": "879079",
    "end": "881040"
  },
  {
    "text": "limit they will error you out if you",
    "start": "881040",
    "end": "883079"
  },
  {
    "text": "request too much and we can know that",
    "start": "883079",
    "end": "885480"
  },
  {
    "text": "like chaining J they can easily exed",
    "start": "885480",
    "end": "887279"
  },
  {
    "text": "like 10,000 like queries per second and",
    "start": "887279",
    "end": "889800"
  },
  {
    "text": "you will put the oner cluster like hdfs",
    "start": "889800",
    "end": "892880"
  },
  {
    "text": "under really heavy low that's the time",
    "start": "892880",
    "end": "895160"
  },
  {
    "text": "that the storage team will yell at the",
    "start": "895160",
    "end": "897519"
  },
  {
    "text": "chaining team because you guys put us",
    "start": "897519",
    "end": "899759"
  },
  {
    "text": "under risk and especially for the right",
    "start": "899759",
    "end": "902800"
  },
  {
    "text": "wow nobody wants the right wow to fail",
    "start": "902800",
    "end": "905720"
  },
  {
    "text": "and nobody want the data to be lost so",
    "start": "905720",
    "end": "908399"
  },
  {
    "text": "that's the time that they say that okay",
    "start": "908399",
    "end": "911000"
  },
  {
    "text": "whether we can have some solution to",
    "start": "911000",
    "end": "912759"
  },
  {
    "text": "improve the GPU taxation rate while keep",
    "start": "912759",
    "end": "915480"
  },
  {
    "text": "my story system stable and on the",
    "start": "915480",
    "end": "918320"
  },
  {
    "text": "inference cluster is another problem so",
    "start": "918320",
    "end": "921199"
  },
  {
    "text": "after your model is changed by the your",
    "start": "921199",
    "end": "923800"
  },
  {
    "text": "training framework and the model is",
    "start": "923800",
    "end": "925800"
  },
  {
    "text": "prist to the storage system you want the",
    "start": "925800",
    "end": "928160"
  },
  {
    "text": "model to quickly deployed to your model",
    "start": "928160",
    "end": "930360"
  },
  {
    "text": "inference cluster so the quicker that",
    "start": "930360",
    "end": "932560"
  },
  {
    "text": "you deploy the faster you may see some",
    "start": "932560",
    "end": "934920"
  },
  {
    "text": "business mat increase all if the model",
    "start": "934920",
    "end": "937880"
  },
  {
    "text": "deployment doesn't work well you want to",
    "start": "937880",
    "end": "939920"
  },
  {
    "text": "quickly roll it back to the previous",
    "start": "939920",
    "end": "941560"
  },
  {
    "text": "version so that you help make the I",
    "start": "941560",
    "end": "944440"
  },
  {
    "text": "think the everybody happy there so",
    "start": "944440",
    "end": "946680"
  },
  {
    "text": "that's the three main problem that we",
    "start": "946680",
    "end": "948240"
  },
  {
    "text": "see in the LM",
    "start": "948240",
    "end": "950440"
  },
  {
    "text": "Pipeline and one of the solution is",
    "start": "950440",
    "end": "953040"
  },
  {
    "text": "actually to have a catching solution",
    "start": "953040",
    "end": "955480"
  },
  {
    "text": "closer to your model training and model",
    "start": "955480",
    "end": "957720"
  },
  {
    "text": "inference so so by using a catching",
    "start": "957720",
    "end": "960399"
  },
  {
    "text": "layer between the training JW and the",
    "start": "960399",
    "end": "962360"
  },
  {
    "text": "star system we bring the data and model",
    "start": "962360",
    "end": "966040"
  },
  {
    "text": "close closer to the chaining job and",
    "start": "966040",
    "end": "968120"
  },
  {
    "text": "inference job so instead of like doing",
    "start": "968120",
    "end": "970759"
  },
  {
    "text": "each iteration you always go to the",
    "start": "970759",
    "end": "972959"
  },
  {
    "text": "story system to fetch the data you can",
    "start": "972959",
    "end": "975560"
  },
  {
    "text": "only fetch once and then catch it",
    "start": "975560",
    "end": "977639"
  },
  {
    "text": "locally and then providing it to your",
    "start": "977639",
    "end": "979800"
  },
  {
    "text": "training jobs so buying this way because",
    "start": "979800",
    "end": "982800"
  },
  {
    "text": "uh aaso can be located collocated with a",
    "start": "982800",
    "end": "985319"
  },
  {
    "text": "training job so the latency is much",
    "start": "985319",
    "end": "987720"
  },
  {
    "text": "lower and the through can be much higher",
    "start": "987720",
    "end": "990560"
  },
  {
    "text": "and similarly on the model inference",
    "start": "990560",
    "end": "992839"
  },
  {
    "text": "side we can use alasio to catch the",
    "start": "992839",
    "end": "995040"
  },
  {
    "text": "different version of the models so that",
    "start": "995040",
    "end": "997839"
  },
  {
    "text": "alasu help to fetch the model from the",
    "start": "997839",
    "end": "1000000"
  },
  {
    "text": "remote storage once and then provide",
    "start": "1000000",
    "end": "1002560"
  },
  {
    "text": "those models to the model to the model",
    "start": "1002560",
    "end": "1004800"
  },
  {
    "text": "inference cluster so the deployment P",
    "start": "1004800",
    "end": "1007440"
  },
  {
    "text": "can be much",
    "start": "1007440",
    "end": "1008920"
  },
  {
    "text": "quicker I think this one like Sean",
    "start": "1008920",
    "end": "1011079"
  },
  {
    "text": "already showed before uh when training",
    "start": "1011079",
    "end": "1013480"
  },
  {
    "text": "directly uh with data from the storage",
    "start": "1013480",
    "end": "1016000"
  },
  {
    "text": "system we sometimes we can see that",
    "start": "1016000",
    "end": "1018279"
  },
  {
    "text": "there's a lot time that actually spent",
    "start": "1018279",
    "end": "1020160"
  },
  {
    "text": "in the data loader and the data loader",
    "start": "1020160",
    "end": "1022600"
  },
  {
    "text": "rate and the GPU utilization rate are",
    "start": "1022600",
    "end": "1025199"
  },
  {
    "text": "actually like the higher the data loader",
    "start": "1025199",
    "end": "1027640"
  },
  {
    "text": "rate the lower the deputization",
    "start": "1027640",
    "end": "1030600"
  },
  {
    "text": "rate and one way is that we when we have",
    "start": "1030600",
    "end": "1033600"
  },
  {
    "text": "a catching solution that closer to our",
    "start": "1033600",
    "end": "1035760"
  },
  {
    "text": "training we can directly reduce the data",
    "start": "1035760",
    "end": "1038240"
  },
  {
    "text": "loader time which directly result in a",
    "start": "1038240",
    "end": "1040678"
  },
  {
    "text": "higher deputization",
    "start": "1040679",
    "end": "1043480"
  },
  {
    "text": "rate and this is also one of the graph",
    "start": "1043480",
    "end": "1045918"
  },
  {
    "text": "that shared by our users it talks about",
    "start": "1045919",
    "end": "1048400"
  },
  {
    "text": "how long it takes to deploy their model",
    "start": "1048400",
    "end": "1051360"
  },
  {
    "text": "and so basically the higher the number",
    "start": "1051360",
    "end": "1053480"
  },
  {
    "text": "the the longer time that it takes to",
    "start": "1053480",
    "end": "1055440"
  },
  {
    "text": "deploy the model so we can see that from",
    "start": "1055440",
    "end": "1057919"
  },
  {
    "text": "the left side the blue and green bars it",
    "start": "1057919",
    "end": "1060840"
  },
  {
    "text": "basically showing how long it takes to",
    "start": "1060840",
    "end": "1062640"
  },
  {
    "text": "deploy the model when there's no",
    "start": "1062640",
    "end": "1064520"
  },
  {
    "text": "catching solution in war where you",
    "start": "1064520",
    "end": "1066679"
  },
  {
    "text": "always need to go to your storage system",
    "start": "1066679",
    "end": "1068799"
  },
  {
    "text": "to fetch the the model that you need um",
    "start": "1068799",
    "end": "1072120"
  },
  {
    "text": "and the middle part is that when they",
    "start": "1072120",
    "end": "1074280"
  },
  {
    "text": "first onboarding a catching solution to",
    "start": "1074280",
    "end": "1076360"
  },
  {
    "text": "catch the models we can directly see",
    "start": "1076360",
    "end": "1078679"
  },
  {
    "text": "that that there is only Tes one Ser time",
    "start": "1078679",
    "end": "1080880"
  },
  {
    "text": "when they first on boarding a cing",
    "start": "1080880",
    "end": "1082720"
  },
  {
    "text": "solution and the right part is where we",
    "start": "1082720",
    "end": "1087000"
  },
  {
    "text": "actually do some code optimization with",
    "start": "1087000",
    "end": "1089280"
  },
  {
    "text": "their Wars to get rid of the UN needed",
    "start": "1089280",
    "end": "1092360"
  },
  {
    "text": "cost and then to improve the overall",
    "start": "1092360",
    "end": "1094640"
  },
  {
    "text": "performance and after optimization it",
    "start": "1094640",
    "end": "1097600"
  },
  {
    "text": "only takes like one tenth of the time",
    "start": "1097600",
    "end": "1100080"
  },
  {
    "text": "compared to original model deployment",
    "start": "1100080",
    "end": "1103360"
  },
  {
    "text": "time okay lastly we also want to talk",
    "start": "1103360",
    "end": "1106120"
  },
  {
    "text": "about some of our newly like integration",
    "start": "1106120",
    "end": "1108960"
  },
  {
    "text": "with Ray I think there are several talks",
    "start": "1108960",
    "end": "1111640"
  },
  {
    "text": "that already share you guys about what's",
    "start": "1111640",
    "end": "1113880"
  },
  {
    "text": "Ray and yeah there are plenty of things",
    "start": "1113880",
    "end": "1116280"
  },
  {
    "text": "online so from our perspective I want to",
    "start": "1116280",
    "end": "1119520"
  },
  {
    "text": "like talk more about the ray training",
    "start": "1119520",
    "end": "1121360"
  },
  {
    "text": "part and Ray uses a distributed",
    "start": "1121360",
    "end": "1124080"
  },
  {
    "text": "scheduler to dispatch training JW to",
    "start": "1124080",
    "end": "1126640"
  },
  {
    "text": "available workers so it allows you to",
    "start": "1126640",
    "end": "1129720"
  },
  {
    "text": "simly horizontal scaling of training JW",
    "start": "1129720",
    "end": "1133080"
  },
  {
    "text": "across different multiple nodes and it",
    "start": "1133080",
    "end": "1135799"
  },
  {
    "text": "provides streaming data extraction for",
    "start": "1135799",
    "end": "1138080"
  },
  {
    "text": "machine learning chaining for parallel",
    "start": "1138080",
    "end": "1140480"
  },
  {
    "text": "and distribute purpose sessing and I",
    "start": "1140480",
    "end": "1142840"
  },
  {
    "text": "will talk about the r streaming",
    "start": "1142840",
    "end": "1145559"
  },
  {
    "text": "later so Ray do a really good job in",
    "start": "1145559",
    "end": "1148400"
  },
  {
    "text": "their Ray streaming uh basically uh",
    "start": "1148400",
    "end": "1151480"
  },
  {
    "text": "considering that you have like CPU and",
    "start": "1151480",
    "end": "1153799"
  },
  {
    "text": "GPU resources and they didn't download",
    "start": "1153799",
    "end": "1156640"
  },
  {
    "text": "the food data set and then do the food",
    "start": "1156640",
    "end": "1159760"
  },
  {
    "text": "preprocessing and then do the Food",
    "start": "1159760",
    "end": "1161600"
  },
  {
    "text": "Training what they do is that they",
    "start": "1161600",
    "end": "1163880"
  },
  {
    "text": "actually break the task to smaller",
    "start": "1163880",
    "end": "1165600"
  },
  {
    "text": "pieces so that uh when your gpus are",
    "start": "1165600",
    "end": "1168799"
  },
  {
    "text": "busy at chaining with batch data zero",
    "start": "1168799",
    "end": "1172120"
  },
  {
    "text": "batch zero and then your CPU is Idle you",
    "start": "1172120",
    "end": "1175400"
  },
  {
    "text": "can actually use that CPU to do the",
    "start": "1175400",
    "end": "1177960"
  },
  {
    "text": "pre-processing for data batch one and",
    "start": "1177960",
    "end": "1180640"
  },
  {
    "text": "also you can use the CPU to do the data",
    "start": "1180640",
    "end": "1183280"
  },
  {
    "text": "loading for batch two so once your batch",
    "start": "1183280",
    "end": "1186520"
  },
  {
    "text": "zero training is finished you can dly",
    "start": "1186520",
    "end": "1188919"
  },
  {
    "text": "move to training on batch one so that",
    "start": "1188919",
    "end": "1192080"
  },
  {
    "text": "you can fully utilize the GPU and CPU",
    "start": "1192080",
    "end": "1194720"
  },
  {
    "text": "resources and on the other hand",
    "start": "1194720",
    "end": "1197080"
  },
  {
    "text": "especially when there's a large dat set",
    "start": "1197080",
    "end": "1199480"
  },
  {
    "text": "it may not be able to download the full",
    "start": "1199480",
    "end": "1201640"
  },
  {
    "text": "data set and pre set and then training",
    "start": "1201640",
    "end": "1204880"
  },
  {
    "text": "because you may have enough dis space on",
    "start": "1204880",
    "end": "1206919"
  },
  {
    "text": "each note to store the full data set you",
    "start": "1206919",
    "end": "1209559"
  },
  {
    "text": "may want to overlap downloading the data",
    "start": "1209559",
    "end": "1211799"
  },
  {
    "text": "with data pre-processing and chaining to",
    "start": "1211799",
    "end": "1214159"
  },
  {
    "text": "fully utilize the CPU and GPU resources",
    "start": "1214159",
    "end": "1217520"
  },
  {
    "text": "on sometimes we also see some of the",
    "start": "1217520",
    "end": "1219280"
  },
  {
    "text": "wallows they didn't do the uh they",
    "start": "1219280",
    "end": "1222039"
  },
  {
    "text": "basically didn't use the full data set",
    "start": "1222039",
    "end": "1224400"
  },
  {
    "text": "what they did is that they do they redem",
    "start": "1224400",
    "end": "1226840"
  },
  {
    "text": "the different or random data set",
    "start": "1226840",
    "end": "1229240"
  },
  {
    "text": "when the set of the data set so that the",
    "start": "1229240",
    "end": "1232679"
  },
  {
    "text": "I think the maintainer or the data",
    "start": "1232679",
    "end": "1234360"
  },
  {
    "text": "science they don't even know like which",
    "start": "1234360",
    "end": "1236039"
  },
  {
    "text": "part of the data will be used so by",
    "start": "1236039",
    "end": "1238280"
  },
  {
    "text": "using R streaming they only need to load",
    "start": "1238280",
    "end": "1240960"
  },
  {
    "text": "the data that's actually",
    "start": "1240960",
    "end": "1243159"
  },
  {
    "text": "needed the story sounds great but there",
    "start": "1243159",
    "end": "1245960"
  },
  {
    "text": "are some problems otherwise we won't",
    "start": "1245960",
    "end": "1248200"
  },
  {
    "text": "come in so uh we actually talk to many",
    "start": "1248200",
    "end": "1250799"
  },
  {
    "text": "of the ray users and see because we see",
    "start": "1250799",
    "end": "1253840"
  },
  {
    "text": "that the the idea is amazing where",
    "start": "1253840",
    "end": "1255679"
  },
  {
    "text": "something that we can help here",
    "start": "1255679",
    "end": "1257000"
  },
  {
    "text": "especially for the data part",
    "start": "1257000",
    "end": "1259159"
  },
  {
    "text": "and we actually look at talk to some of",
    "start": "1259159",
    "end": "1261679"
  },
  {
    "text": "the users on their slack Channel and",
    "start": "1261679",
    "end": "1264000"
  },
  {
    "text": "some slack post we search the history",
    "start": "1264000",
    "end": "1266240"
  },
  {
    "text": "and Al talk to the people and so some of",
    "start": "1266240",
    "end": "1268840"
  },
  {
    "text": "the things that we found here is that",
    "start": "1268840",
    "end": "1271200"
  },
  {
    "text": "the story sounds great but uh you may",
    "start": "1271200",
    "end": "1274000"
  },
  {
    "text": "load the entire data set again and again",
    "start": "1274000",
    "end": "1276760"
  },
  {
    "text": "for each apple and then one really",
    "start": "1276760",
    "end": "1279360"
  },
  {
    "text": "important part is that when your memory",
    "start": "1279360",
    "end": "1281960"
  },
  {
    "text": "size is much smaller than your the",
    "start": "1281960",
    "end": "1284679"
  },
  {
    "text": "actual data set that needed so for",
    "start": "1284679",
    "end": "1286760"
  },
  {
    "text": "example you may have like B zero dat and",
    "start": "1286760",
    "end": "1288919"
  },
  {
    "text": "batch one data and but you only have the",
    "start": "1288919",
    "end": "1291520"
  },
  {
    "text": "memory able to hold your batch zero data",
    "start": "1291520",
    "end": "1294880"
  },
  {
    "text": "then once you finish training with batch",
    "start": "1294880",
    "end": "1297080"
  },
  {
    "text": "zero in order to work on batch one the",
    "start": "1297080",
    "end": "1299919"
  },
  {
    "text": "full memory the batch zero data need to",
    "start": "1299919",
    "end": "1302279"
  },
  {
    "text": "be erased to have space for batch one",
    "start": "1302279",
    "end": "1305720"
  },
  {
    "text": "and then when you do the next apple",
    "start": "1305720",
    "end": "1307720"
  },
  {
    "text": "again you may need to reload the batch",
    "start": "1307720",
    "end": "1309919"
  },
  {
    "text": "zero data again from your storage system",
    "start": "1309919",
    "end": "1312919"
  },
  {
    "text": "so the larger the ratio the then the",
    "start": "1312919",
    "end": "1316120"
  },
  {
    "text": "more data that you actually need to R",
    "start": "1316120",
    "end": "1318200"
  },
  {
    "text": "from your storage",
    "start": "1318200",
    "end": "1319799"
  },
  {
    "text": "system and also like some of our users",
    "start": "1319799",
    "end": "1323200"
  },
  {
    "text": "they may not only have one Ray pipeline",
    "start": "1323200",
    "end": "1326159"
  },
  {
    "text": "they actually have multiple Ray",
    "start": "1326159",
    "end": "1327799"
  },
  {
    "text": "pipelines or they they have some team",
    "start": "1327799",
    "end": "1330360"
  },
  {
    "text": "that were on Pou T flow some that using",
    "start": "1330360",
    "end": "1333360"
  },
  {
    "text": "Ray but they actually share the same",
    "start": "1333360",
    "end": "1335600"
  },
  {
    "text": "data especially the hottest data inside",
    "start": "1335600",
    "end": "1338279"
  },
  {
    "text": "one company then how can we catch the",
    "start": "1338279",
    "end": "1341279"
  },
  {
    "text": "hottest data for those multiple jobs",
    "start": "1341279",
    "end": "1343640"
  },
  {
    "text": "together is becomes a problem and some",
    "start": "1343640",
    "end": "1346559"
  },
  {
    "text": "of the users they want their model B",
    "start": "1346559",
    "end": "1348520"
  },
  {
    "text": "basically to stall in a kind of of Shar",
    "start": "1348520",
    "end": "1350880"
  },
  {
    "text": "won so that can be shared by all the",
    "start": "1350880",
    "end": "1352960"
  },
  {
    "text": "rain noes so basically for our users",
    "start": "1352960",
    "end": "1356799"
  },
  {
    "text": "they don't want to suffer from a",
    "start": "1356799",
    "end": "1358240"
  },
  {
    "text": "coldstar every time they don't want to",
    "start": "1358240",
    "end": "1360240"
  },
  {
    "text": "redownload data reprocess so that they",
    "start": "1360240",
    "end": "1363039"
  },
  {
    "text": "can chain on those data",
    "start": "1363039",
    "end": "1366320"
  },
  {
    "text": "set that brings alasio into the ray",
    "start": "1367159",
    "end": "1370000"
  },
  {
    "text": "ecosystem so r ray do a really good job",
    "start": "1370000",
    "end": "1372799"
  },
  {
    "text": "in the machine learning pipeline it",
    "start": "1372799",
    "end": "1374720"
  },
  {
    "text": "abstract some of the model chaining and",
    "start": "1374720",
    "end": "1377080"
  },
  {
    "text": "inference framework so that you can do",
    "start": "1377080",
    "end": "1379919"
  },
  {
    "text": "the different stages together and use",
    "start": "1379919",
    "end": "1381960"
  },
  {
    "text": "different machine learning framework",
    "start": "1381960",
    "end": "1383480"
  },
  {
    "text": "together and alasio sits between the",
    "start": "1383480",
    "end": "1386080"
  },
  {
    "text": "model chaining and inference framework",
    "start": "1386080",
    "end": "1388640"
  },
  {
    "text": "and also the storage system it f us to",
    "start": "1388640",
    "end": "1391520"
  },
  {
    "text": "fatch the data from remote storage catch",
    "start": "1391520",
    "end": "1394039"
  },
  {
    "text": "it locally and provide high performance",
    "start": "1394039",
    "end": "1396159"
  },
  {
    "text": "data access for the model chaining and",
    "start": "1396159",
    "end": "1399880"
  },
  {
    "text": "inference uh there's a really simple",
    "start": "1399880",
    "end": "1401960"
  },
  {
    "text": "Benchmark that we did actually use like",
    "start": "1401960",
    "end": "1404240"
  },
  {
    "text": "the nly test that R provide to us so",
    "start": "1404240",
    "end": "1408000"
  },
  {
    "text": "it's is also on the ray public Gad repo",
    "start": "1408000",
    "end": "1411320"
  },
  {
    "text": "and we run the task to compare like okay",
    "start": "1411320",
    "end": "1413919"
  },
  {
    "text": "what's alasio pass Ray uh performance",
    "start": "1413919",
    "end": "1416480"
  },
  {
    "text": "compared to Ray plus S3 direct rate and",
    "start": "1416480",
    "end": "1419919"
  },
  {
    "text": "we can see that with alasio the",
    "start": "1419919",
    "end": "1422039"
  },
  {
    "text": "performance increased at least one s and",
    "start": "1422039",
    "end": "1424400"
  },
  {
    "text": "know that this is with same region S3 so",
    "start": "1424400",
    "end": "1427000"
  },
  {
    "text": "if your star system is even further away",
    "start": "1427000",
    "end": "1429600"
  },
  {
    "text": "and if you have Network congestion issue",
    "start": "1429600",
    "end": "1431840"
  },
  {
    "text": "it may bring more",
    "start": "1431840",
    "end": "1434799"
  },
  {
    "text": "benefits and one of the other parts that",
    "start": "1434799",
    "end": "1438080"
  },
  {
    "text": "uh most of user own Bon allasio not just",
    "start": "1438080",
    "end": "1440400"
  },
  {
    "text": "for performance but also to reduce their",
    "start": "1440400",
    "end": "1442760"
  },
  {
    "text": "storage cost basically like every data",
    "start": "1442760",
    "end": "1445880"
  },
  {
    "text": "that you transfer between your storage",
    "start": "1445880",
    "end": "1447480"
  },
  {
    "text": "system to your to your training job",
    "start": "1447480",
    "end": "1450520"
  },
  {
    "text": "especially the cloud storage they",
    "start": "1450520",
    "end": "1452720"
  },
  {
    "text": "actually cost you the uh erress fee or",
    "start": "1452720",
    "end": "1455360"
  },
  {
    "text": "the data transfer fee so that and",
    "start": "1455360",
    "end": "1458159"
  },
  {
    "text": "especially like when you have a large",
    "start": "1458159",
    "end": "1459840"
  },
  {
    "text": "data set to chain on the data transfer",
    "start": "1459840",
    "end": "1462080"
  },
  {
    "text": "fee may be really",
    "start": "1462080",
    "end": "1464399"
  },
  {
    "text": "huge and on the other part we found that",
    "start": "1464399",
    "end": "1467399"
  },
  {
    "text": "it's actually really a cavy for some of",
    "start": "1467399",
    "end": "1469760"
  },
  {
    "text": "the operations so for example when uh we",
    "start": "1469760",
    "end": "1472720"
  },
  {
    "text": "are training on like image net data and",
    "start": "1472720",
    "end": "1476159"
  },
  {
    "text": "each file is really small it's only like",
    "start": "1476159",
    "end": "1478960"
  },
  {
    "text": "100 KB you can get the full file through",
    "start": "1478960",
    "end": "1483000"
  },
  {
    "text": "one call to your story system however we",
    "start": "1483000",
    "end": "1486399"
  },
  {
    "text": "do see that even one image read it it",
    "start": "1486399",
    "end": "1489720"
  },
  {
    "text": "comes with like more than two usually",
    "start": "1489720",
    "end": "1492080"
  },
  {
    "text": "two two three me the cost so for example",
    "start": "1492080",
    "end": "1494960"
  },
  {
    "text": "where's my file is that a real file or",
    "start": "1494960",
    "end": "1497440"
  },
  {
    "text": "is a directory and then I I get the file",
    "start": "1497440",
    "end": "1500200"
  },
  {
    "text": "data so one image read actually cost",
    "start": "1500200",
    "end": "1503200"
  },
  {
    "text": "like two method calls and one recall",
    "start": "1503200",
    "end": "1505640"
  },
  {
    "text": "which is really heavy so uh with alaso",
    "start": "1505640",
    "end": "1508760"
  },
  {
    "text": "we do see that there is a lot of meal",
    "start": "1508760",
    "end": "1510559"
  },
  {
    "text": "cost involving here the cost if they",
    "start": "1510559",
    "end": "1513080"
  },
  {
    "text": "result in a catching system a closer",
    "start": "1513080",
    "end": "1515159"
  },
  {
    "text": "system it can reduce basically latency",
    "start": "1515159",
    "end": "1517840"
  },
  {
    "text": "and then improve the performance and we",
    "start": "1517840",
    "end": "1519919"
  },
  {
    "text": "are also working on the uh basically",
    "start": "1519919",
    "end": "1522120"
  },
  {
    "text": "rate like they delegate some of the data",
    "start": "1522120",
    "end": "1525080"
  },
  {
    "text": "loading logic and also the format",
    "start": "1525080",
    "end": "1527679"
  },
  {
    "text": "translation te ly to other like apach",
    "start": "1527679",
    "end": "1530120"
  },
  {
    "text": "project like arrow and FSB the pon file",
    "start": "1530120",
    "end": "1533919"
  },
  {
    "text": "system interface so we also working on",
    "start": "1533919",
    "end": "1536440"
  },
  {
    "text": "that part to see whether we can reduce",
    "start": "1536440",
    "end": "1538679"
  },
  {
    "text": "autom medal cost safely and ensuring the",
    "start": "1538679",
    "end": "1541880"
  },
  {
    "text": "current is well like improve the",
    "start": "1541880",
    "end": "1546000"
  },
  {
    "text": "performance I think that's it for our",
    "start": "1546440",
    "end": "1548880"
  },
  {
    "text": "talk today and feel free to leave any",
    "start": "1548880",
    "end": "1551320"
  },
  {
    "text": "feedback on the QR code I'm not sure",
    "start": "1551320",
    "end": "1553960"
  },
  {
    "text": "whether I can receive the the feedback",
    "start": "1553960",
    "end": "1556399"
  },
  {
    "text": "and if you have any question you can",
    "start": "1556399",
    "end": "1558480"
  },
  {
    "text": "feel free to go to our SL Channel that's",
    "start": "1558480",
    "end": "1560520"
  },
  {
    "text": "the easiest way to find all the",
    "start": "1560520",
    "end": "1562039"
  },
  {
    "text": "engineers in our company and if you have",
    "start": "1562039",
    "end": "1564919"
  },
  {
    "text": "issues then go to the our alaso gab like",
    "start": "1564919",
    "end": "1568240"
  },
  {
    "text": "career issue there and anybody have any",
    "start": "1568240",
    "end": "1573080"
  },
  {
    "text": "question actually it's more people than",
    "start": "1573440",
    "end": "1575840"
  },
  {
    "text": "I",
    "start": "1575840",
    "end": "1578000"
  },
  {
    "text": "imagine okay thank you",
    "start": "1578159",
    "end": "1582640"
  }
]
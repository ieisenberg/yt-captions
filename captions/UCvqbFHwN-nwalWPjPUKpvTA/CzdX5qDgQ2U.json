[
  {
    "text": "hi everyone my name is Anish Astana i'm",
    "start": "400",
    "end": "3120"
  },
  {
    "text": "an engineering manager with the open",
    "start": "3120",
    "end": "4720"
  },
  {
    "text": "shift AI group at Red Hat um I've been",
    "start": "4720",
    "end": "7520"
  },
  {
    "text": "working in the cloud native AI space for",
    "start": "7520",
    "end": "9280"
  },
  {
    "text": "the last seven years or so now hello and",
    "start": "9280",
    "end": "13200"
  },
  {
    "text": "uh I'm Royal Alex i work for IBM",
    "start": "13200",
    "end": "15920"
  },
  {
    "text": "research something like 25 years started",
    "start": "15920",
    "end": "18640"
  },
  {
    "text": "with IBM middleware after that uh cloud",
    "start": "18640",
    "end": "21920"
  },
  {
    "text": "infrastructure cloud solutions and",
    "start": "21920",
    "end": "24160"
  },
  {
    "text": "currently my focus on data processing",
    "start": "24160",
    "end": "26320"
  },
  {
    "text": "automation and um today we'll be talking",
    "start": "26320",
    "end": "29199"
  },
  {
    "text": "to you about um foundation data",
    "start": "29199",
    "end": "32078"
  },
  {
    "text": "foundation model data engineering uh",
    "start": "32079",
    "end": "34160"
  },
  {
    "text": "using",
    "start": "34160",
    "end": "36200"
  },
  {
    "text": "kubernetes so to give a brief overview",
    "start": "36200",
    "end": "38480"
  },
  {
    "text": "of the agenda uh we'll be introducing",
    "start": "38480",
    "end": "41120"
  },
  {
    "text": "what data what these data processing",
    "start": "41120",
    "end": "43040"
  },
  {
    "text": "workflows look like first then we'll",
    "start": "43040",
    "end": "45360"
  },
  {
    "text": "talk about how projects such as cube ray",
    "start": "45360",
    "end": "47280"
  },
  {
    "text": "and cubeflow pipelines can be used to",
    "start": "47280",
    "end": "49280"
  },
  {
    "text": "scale up and productionize your",
    "start": "49280",
    "end": "51760"
  },
  {
    "text": "workflows then we'll kick off the demo",
    "start": "51760",
    "end": "54399"
  },
  {
    "text": "and then introduce another project",
    "start": "54399",
    "end": "56160"
  },
  {
    "text": "called um data preparation kit which",
    "start": "56160",
    "end": "58640"
  },
  {
    "text": "makes it much easier to build these",
    "start": "58640",
    "end": "60399"
  },
  {
    "text": "systems",
    "start": "60399",
    "end": "62280"
  },
  {
    "text": "out okay so let's talk about data",
    "start": "62280",
    "end": "64960"
  },
  {
    "text": "prep-processing workflows the for work",
    "start": "64960",
    "end": "68159"
  },
  {
    "text": "workflows usually starts from data",
    "start": "68159",
    "end": "70320"
  },
  {
    "text": "corpse access and in our case we use",
    "start": "70320",
    "end": "72960"
  },
  {
    "text": "paret files with error tables",
    "start": "72960",
    "end": "76040"
  },
  {
    "text": "format and uh when we work with large",
    "start": "76040",
    "end": "80080"
  },
  {
    "text": "data sets duplication or",
    "start": "80080",
    "end": "82280"
  },
  {
    "text": "semi-duplications are often present and",
    "start": "82280",
    "end": "86240"
  },
  {
    "text": "uh therefore the first uh steps in the",
    "start": "86240",
    "end": "88880"
  },
  {
    "text": "data processing it's uh working with the",
    "start": "88880",
    "end": "91960"
  },
  {
    "text": "dduplication which can be exact",
    "start": "91960",
    "end": "94240"
  },
  {
    "text": "duplication or combination of exact ract",
    "start": "94240",
    "end": "96960"
  },
  {
    "text": "or fit",
    "start": "96960",
    "end": "98280"
  },
  {
    "text": "duplication after that usually or might",
    "start": "98280",
    "end": "101920"
  },
  {
    "text": "be language separation and filtering",
    "start": "101920",
    "end": "105280"
  },
  {
    "text": "which allows",
    "start": "105280",
    "end": "106520"
  },
  {
    "text": "to proceed with next steps based on a",
    "start": "106520",
    "end": "111200"
  },
  {
    "text": "specific",
    "start": "111200",
    "end": "112200"
  },
  {
    "text": "language depends on uh the data input",
    "start": "112200",
    "end": "118520"
  },
  {
    "text": "some annotated transformers can exist",
    "start": "118520",
    "end": "121439"
  },
  {
    "text": "for example to check that data doesn't",
    "start": "121439",
    "end": "123560"
  },
  {
    "text": "include personal identifiable",
    "start": "123560",
    "end": "125759"
  },
  {
    "text": "information PII or hate",
    "start": "125759",
    "end": "129000"
  },
  {
    "text": "abuse profanity language or just uh",
    "start": "129000",
    "end": "132000"
  },
  {
    "text": "check that quality of documents this",
    "start": "132000",
    "end": "135200"
  },
  {
    "text": "transforms at least in our case there",
    "start": "135200",
    "end": "138599"
  },
  {
    "text": "are mutual",
    "start": "138599",
    "end": "142080"
  },
  {
    "text": "uh they do do not depends one to another",
    "start": "143480",
    "end": "146480"
  },
  {
    "text": "and we can execute them uh in any order",
    "start": "146480",
    "end": "149520"
  },
  {
    "text": "or even in parallel because they write",
    "start": "149520",
    "end": "151760"
  },
  {
    "text": "data in separate uh",
    "start": "151760",
    "end": "154840"
  },
  {
    "text": "columns we will see that in the next",
    "start": "154840",
    "end": "157599"
  },
  {
    "text": "slide and usually the process ends",
    "start": "157599",
    "end": "161400"
  },
  {
    "text": "with filtering and",
    "start": "161400",
    "end": "164360"
  },
  {
    "text": "tokenization like I said before the one",
    "start": "164360",
    "end": "168319"
  },
  {
    "text": "some uh steps can can run in parallel",
    "start": "168319",
    "end": "171040"
  },
  {
    "text": "and merge at the end",
    "start": "171040",
    "end": "174640"
  },
  {
    "text": "another type of parallelism can be",
    "start": "174680",
    "end": "178080"
  },
  {
    "text": "applied based on natural language",
    "start": "178080",
    "end": "180959"
  },
  {
    "text": "because after uh and we're going to",
    "start": "180959",
    "end": "183599"
  },
  {
    "text": "demonstrate it in demo after language",
    "start": "183599",
    "end": "186239"
  },
  {
    "text": "separation uh all next steps can be run",
    "start": "186239",
    "end": "190560"
  },
  {
    "text": "independently and execute uh for each",
    "start": "190560",
    "end": "193599"
  },
  {
    "text": "language",
    "start": "193599",
    "end": "196599"
  },
  {
    "text": "so um as Alexi talked about right like",
    "start": "197680",
    "end": "200319"
  },
  {
    "text": "you have lots of pre-processing stages",
    "start": "200319",
    "end": "202800"
  },
  {
    "text": "in your pipeline these stages may or may",
    "start": "202800",
    "end": "205360"
  },
  {
    "text": "not be linked to each other and they can",
    "start": "205360",
    "end": "207040"
  },
  {
    "text": "operate on data the very wide variety of",
    "start": "207040",
    "end": "210080"
  },
  {
    "text": "scales right it could be at the megabyte",
    "start": "210080",
    "end": "212080"
  },
  {
    "text": "gigabyte level just for like local",
    "start": "212080",
    "end": "214319"
  },
  {
    "text": "development and testing or at actual",
    "start": "214319",
    "end": "216720"
  },
  {
    "text": "terabyte scale for when you have you",
    "start": "216720",
    "end": "219200"
  },
  {
    "text": "know lots of data and you're doing",
    "start": "219200",
    "end": "220480"
  },
  {
    "text": "actual data transformations",
    "start": "220480",
    "end": "222720"
  },
  {
    "text": "one of the issues that we were running",
    "start": "222720",
    "end": "224080"
  },
  {
    "text": "into was how do we make it easy for our",
    "start": "224080",
    "end": "226319"
  },
  {
    "text": "developers to like do quick local like",
    "start": "226319",
    "end": "229720"
  },
  {
    "text": "development cycles on their laptops and",
    "start": "229720",
    "end": "232400"
  },
  {
    "text": "then scale up to the cloud right um this",
    "start": "232400",
    "end": "236720"
  },
  {
    "text": "the solution we elected to use for the",
    "start": "236720",
    "end": "238720"
  },
  {
    "text": "most part was Ray and Cubray um there's",
    "start": "238720",
    "end": "241200"
  },
  {
    "text": "obviously options like Spark Daskk and",
    "start": "241200",
    "end": "242879"
  },
  {
    "text": "all of that stuff we we liked",
    "start": "242879",
    "end": "245959"
  },
  {
    "text": "Cubray so Cubray is an operator that",
    "start": "245959",
    "end": "249760"
  },
  {
    "text": "brings core Ray concepts such as Ray",
    "start": "249760",
    "end": "252319"
  },
  {
    "text": "clusters Ray jobs and Ray serve to",
    "start": "252319",
    "end": "255160"
  },
  {
    "text": "Kubernetes since it's an operator it",
    "start": "255160",
    "end": "257840"
  },
  {
    "text": "requires custom resources and YAML which",
    "start": "257840",
    "end": "260799"
  },
  {
    "text": "most of our users actually hated we got",
    "start": "260799",
    "end": "263440"
  },
  {
    "text": "around that by using something called",
    "start": "263440",
    "end": "264880"
  },
  {
    "text": "the Cubray API server and all that does",
    "start": "264880",
    "end": "267680"
  },
  {
    "text": "is it allows your users to make direct",
    "start": "267680",
    "end": "270240"
  },
  {
    "text": "API requests and then converts them into",
    "start": "270240",
    "end": "273120"
  },
  {
    "text": "the corresponding YAML objects on the",
    "start": "273120",
    "end": "275199"
  },
  {
    "text": "cluster",
    "start": "275199",
    "end": "276800"
  },
  {
    "text": "this is acted upon by the cube operator",
    "start": "276800",
    "end": "279040"
  },
  {
    "text": "to do whatever you need it to be doing",
    "start": "279040",
    "end": "283360"
  },
  {
    "text": "all our array based transforms are",
    "start": "283360",
    "end": "285919"
  },
  {
    "text": "follows the driver worker paradigm and",
    "start": "285919",
    "end": "289160"
  },
  {
    "text": "uh this uh the driver when it start",
    "start": "289160",
    "end": "293440"
  },
  {
    "text": "reads all the input files names or",
    "start": "293440",
    "end": "296160"
  },
  {
    "text": "object names in the case of S3 and uh",
    "start": "296160",
    "end": "300479"
  },
  {
    "text": "dispatch uh tasks to",
    "start": "300479",
    "end": "303000"
  },
  {
    "text": "workers which are implemented like",
    "start": "303000",
    "end": "307280"
  },
  {
    "text": "array actors sorry unlike Spark we don't",
    "start": "311000",
    "end": "315759"
  },
  {
    "text": "have a",
    "start": "315759",
    "end": "319039"
  },
  {
    "text": "partitions here because uh when a worker",
    "start": "319039",
    "end": "322639"
  },
  {
    "text": "finishes proceeding the a file it asks",
    "start": "322639",
    "end": "326160"
  },
  {
    "text": "the driver for the next one and uh this",
    "start": "326160",
    "end": "329039"
  },
  {
    "text": "approach helped us to prevent uh slow",
    "start": "329039",
    "end": "331759"
  },
  {
    "text": "down when uh file sizes uh vary",
    "start": "331759",
    "end": "335360"
  },
  {
    "text": "significantly",
    "start": "335360",
    "end": "337600"
  },
  {
    "text": "we use",
    "start": "337600",
    "end": "339960"
  },
  {
    "text": "a separate cluster for each uh different",
    "start": "339960",
    "end": "343520"
  },
  {
    "text": "for different data processing task and",
    "start": "343520",
    "end": "346560"
  },
  {
    "text": "uh which allow us to create task",
    "start": "346560",
    "end": "348720"
  },
  {
    "text": "specific images and uh avoid",
    "start": "348720",
    "end": "351360"
  },
  {
    "text": "dependencies uh conflicts and include",
    "start": "351360",
    "end": "353680"
  },
  {
    "text": "support for legacy libraries for example",
    "start": "353680",
    "end": "355759"
  },
  {
    "text": "even Java models each worker reads and",
    "start": "355759",
    "end": "359919"
  },
  {
    "text": "writes data separately and uh this",
    "start": "359919",
    "end": "364080"
  },
  {
    "text": "spread of network load between actors or",
    "start": "364080",
    "end": "367199"
  },
  {
    "text": "in the end of the day array in the end",
    "start": "367199",
    "end": "370080"
  },
  {
    "text": "of the day Kubernetes ports and",
    "start": "370080",
    "end": "374240"
  },
  {
    "text": "nodes before going to KFP automation and",
    "start": "377000",
    "end": "381120"
  },
  {
    "text": "you know to summarize very short",
    "start": "381120",
    "end": "383520"
  },
  {
    "text": "introduction to to Ray we want to share",
    "start": "383520",
    "end": "386720"
  },
  {
    "text": "with you Our most uh extended task that",
    "start": "386720",
    "end": "390319"
  },
  {
    "text": "we executed it was a dduplication task",
    "start": "390319",
    "end": "394319"
  },
  {
    "text": "fing duplication task with almost eight",
    "start": "394319",
    "end": "397199"
  },
  {
    "text": "and a half billion",
    "start": "397199",
    "end": "398919"
  },
  {
    "text": "documents",
    "start": "398919",
    "end": "400520"
  },
  {
    "text": "with compressed storage 23",
    "start": "400520",
    "end": "403800"
  },
  {
    "text": "terabytes the task reduce the documents",
    "start": "403800",
    "end": "406960"
  },
  {
    "text": "and storage something like 33 35",
    "start": "406960",
    "end": "411560"
  },
  {
    "text": "40% but the most interesting part here",
    "start": "411560",
    "end": "414319"
  },
  {
    "text": "is the right cluster configuration",
    "start": "414319",
    "end": "416960"
  },
  {
    "text": "it included",
    "start": "416960",
    "end": "418840"
  },
  {
    "text": "7500 CPU cores and 56 terabyte of RAM",
    "start": "418840",
    "end": "423680"
  },
  {
    "text": "and the task spann almost 40",
    "start": "423680",
    "end": "428280"
  },
  {
    "text": "hours um so I just noticed that the",
    "start": "428280",
    "end": "431039"
  },
  {
    "text": "slides look a little funny we'll make",
    "start": "431039",
    "end": "432880"
  },
  {
    "text": "sure to upload slides with the correct",
    "start": "432880",
    "end": "434400"
  },
  {
    "text": "template afterwards i don't know what",
    "start": "434400",
    "end": "436080"
  },
  {
    "text": "happened um anyway so we just talked",
    "start": "436080",
    "end": "440400"
  },
  {
    "text": "about how Cubray can be used to scale up",
    "start": "440400",
    "end": "442479"
  },
  {
    "text": "your workloads but how do you",
    "start": "442479",
    "end": "444160"
  },
  {
    "text": "orchestrate these longunning ETL jobs",
    "start": "444160",
    "end": "446919"
  },
  {
    "text": "right",
    "start": "446919",
    "end": "448840"
  },
  {
    "text": "um",
    "start": "448840",
    "end": "451720"
  },
  {
    "text": "so so um your first option obviously is",
    "start": "451720",
    "end": "454880"
  },
  {
    "text": "just running things locally but that's",
    "start": "454880",
    "end": "456639"
  },
  {
    "text": "not very resilient to like PTO and",
    "start": "456639",
    "end": "458880"
  },
  {
    "text": "vacations",
    "start": "458880",
    "end": "460520"
  },
  {
    "text": "um the next thing we looked at was",
    "start": "460520",
    "end": "462720"
  },
  {
    "text": "something like Kubernetes jobs which got",
    "start": "462720",
    "end": "464880"
  },
  {
    "text": "us most of the way there but the user",
    "start": "464880",
    "end": "466560"
  },
  {
    "text": "experience wasn't quite friendly enough",
    "start": "466560",
    "end": "468319"
  },
  {
    "text": "for like a data scientist to really dive",
    "start": "468319",
    "end": "470400"
  },
  {
    "text": "into right like Kubernetes like jobs",
    "start": "470400",
    "end": "472160"
  },
  {
    "text": "they didn't have a very great UI for",
    "start": "472160",
    "end": "473639"
  },
  {
    "text": "them this is why we started using cubes",
    "start": "473639",
    "end": "476400"
  },
  {
    "text": "pipelines um while this talk is focused",
    "start": "476400",
    "end": "479280"
  },
  {
    "text": "mainly on data engineering I do want to",
    "start": "479280",
    "end": "481440"
  },
  {
    "text": "like reiterate that or iterate that um",
    "start": "481440",
    "end": "484720"
  },
  {
    "text": "cubeflow pipelines can be used for",
    "start": "484720",
    "end": "487520"
  },
  {
    "text": "orchestrating your entire MLOps life",
    "start": "487520",
    "end": "489520"
  },
  {
    "text": "cycle um there's three main ways to",
    "start": "489520",
    "end": "491759"
  },
  {
    "text": "create steps or components as they call",
    "start": "491759",
    "end": "493919"
  },
  {
    "text": "them in cubeflow pipelines um you can",
    "start": "493919",
    "end": "496560"
  },
  {
    "text": "have normal like Python decorated",
    "start": "496560",
    "end": "498479"
  },
  {
    "text": "components very easy to get started with",
    "start": "498479",
    "end": "500879"
  },
  {
    "text": "and um you can have very complicated",
    "start": "500879",
    "end": "503160"
  },
  {
    "text": "like completely custom containerized",
    "start": "503160",
    "end": "505840"
  },
  {
    "text": "components as well right so if you have",
    "start": "505840",
    "end": "507440"
  },
  {
    "text": "Java code that you need to be running",
    "start": "507440",
    "end": "508800"
  },
  {
    "text": "for some you know unfortunate reason you",
    "start": "508800",
    "end": "511520"
  },
  {
    "text": "can do",
    "start": "511520",
    "end": "513320"
  },
  {
    "text": "that um well that looks good enough um",
    "start": "513320",
    "end": "516719"
  },
  {
    "text": "so here's a picture of the UI um here",
    "start": "516719",
    "end": "519120"
  },
  {
    "text": "again the specifics of this DAG doesn't",
    "start": "519120",
    "end": "521440"
  },
  {
    "text": "actually matter right it's just like a",
    "start": "521440",
    "end": "523440"
  },
  {
    "text": "bunch of steps they're all connected",
    "start": "523440",
    "end": "524800"
  },
  {
    "text": "together um we have some users of Cuba",
    "start": "524800",
    "end": "527519"
  },
  {
    "text": "pipelines who have hundreds or even",
    "start": "527519",
    "end": "529360"
  },
  {
    "text": "thousands of components in a single",
    "start": "529360",
    "end": "531560"
  },
  {
    "text": "pipeline why they do that you know it's",
    "start": "531560",
    "end": "534080"
  },
  {
    "text": "for flexibility right you can do",
    "start": "534080",
    "end": "535360"
  },
  {
    "text": "whatever you need to be doing the other",
    "start": "535360",
    "end": "537760"
  },
  {
    "text": "thing I want to call attention to is",
    "start": "537760",
    "end": "539279"
  },
  {
    "text": "within the UI again you can see you have",
    "start": "539279",
    "end": "541200"
  },
  {
    "text": "input parameters you can look at the",
    "start": "541200",
    "end": "542880"
  },
  {
    "text": "logs while it's running all this kind of",
    "start": "542880",
    "end": "545200"
  },
  {
    "text": "stuff right yes you can do this from the",
    "start": "545200",
    "end": "547200"
  },
  {
    "text": "terminal but it makes it much easier for",
    "start": "547200",
    "end": "549279"
  },
  {
    "text": "people who aren't familiar with",
    "start": "549279",
    "end": "550480"
  },
  {
    "text": "Kubernetes to kind of orchestrate and",
    "start": "550480",
    "end": "552959"
  },
  {
    "text": "build these jobs",
    "start": "552959",
    "end": "554839"
  },
  {
    "text": "out now um say I say I want to explore",
    "start": "554839",
    "end": "559279"
  },
  {
    "text": "cubo pipelines right um maybe I don't",
    "start": "559279",
    "end": "561760"
  },
  {
    "text": "want to learn a new Python SDK for it",
    "start": "561760",
    "end": "563920"
  },
  {
    "text": "well the answer for that is Elra elra",
    "start": "563920",
    "end": "567360"
  },
  {
    "text": "offers a pretty easy to use drag and",
    "start": "567360",
    "end": "569440"
  },
  {
    "text": "drop interface for creating um",
    "start": "569440",
    "end": "572080"
  },
  {
    "text": "complicated DAGs um you just put them",
    "start": "572080",
    "end": "575040"
  },
  {
    "text": "together you can specify any input",
    "start": "575040",
    "end": "576720"
  },
  {
    "text": "parameters you need outputs sequence all",
    "start": "576720",
    "end": "580000"
  },
  {
    "text": "of that fun stuff so and if you're",
    "start": "580000",
    "end": "582560"
  },
  {
    "text": "nervous about trying it out you know use",
    "start": "582560",
    "end": "584800"
  },
  {
    "text": "a",
    "start": "584800",
    "end": "585720"
  },
  {
    "text": "Lyra so I want to briefly sum up some of",
    "start": "585720",
    "end": "588720"
  },
  {
    "text": "the key benefits we had from using Cubo",
    "start": "588720",
    "end": "590720"
  },
  {
    "text": "pipelines for this group um the first up",
    "start": "590720",
    "end": "593519"
  },
  {
    "text": "first one was",
    "start": "593519",
    "end": "595080"
  },
  {
    "text": "modularity our workflows were broken up",
    "start": "595080",
    "end": "597519"
  },
  {
    "text": "into um like smaller reusable chunks",
    "start": "597519",
    "end": "601360"
  },
  {
    "text": "that we could chain together to build",
    "start": "601360",
    "end": "603360"
  },
  {
    "text": "very complicated pipelines this made",
    "start": "603360",
    "end": "605519"
  },
  {
    "text": "debugging very easy since there was",
    "start": "605519",
    "end": "608000"
  },
  {
    "text": "individual pieces of work and when",
    "start": "608000",
    "end": "609839"
  },
  {
    "text": "something was breaking you knew what was",
    "start": "609839",
    "end": "611440"
  },
  {
    "text": "going",
    "start": "611440",
    "end": "612200"
  },
  {
    "text": "on um it also introduced um a lot of",
    "start": "612200",
    "end": "616079"
  },
  {
    "text": "nicities around reproducibility",
    "start": "616079",
    "end": "618560"
  },
  {
    "text": "kfp uh runs are kept around you know for",
    "start": "618560",
    "end": "621279"
  },
  {
    "text": "days weeks months you could see what",
    "start": "621279",
    "end": "623360"
  },
  {
    "text": "input parameters went into it what the",
    "start": "623360",
    "end": "625120"
  },
  {
    "text": "output artifacts for view all of that in",
    "start": "625120",
    "end": "627600"
  },
  {
    "text": "the UI so as a data scientist again when",
    "start": "627600",
    "end": "630560"
  },
  {
    "text": "you want to see how something has",
    "start": "630560",
    "end": "632959"
  },
  {
    "text": "shifted over time it's very easy to do",
    "start": "632959",
    "end": "634959"
  },
  {
    "text": "that without having to go anywhere else",
    "start": "634959",
    "end": "637680"
  },
  {
    "text": "lastly again I keep talking about the UI",
    "start": "637680",
    "end": "640079"
  },
  {
    "text": "right visualization capabilities in KFP",
    "start": "640079",
    "end": "643279"
  },
  {
    "text": "made it very easy to build out neurons",
    "start": "643279",
    "end": "646160"
  },
  {
    "text": "to track experiments and to just",
    "start": "646160",
    "end": "648079"
  },
  {
    "text": "troubleshoot any issues we were having",
    "start": "648079",
    "end": "650640"
  },
  {
    "text": "all of these came together to allow us",
    "start": "650640",
    "end": "652399"
  },
  {
    "text": "to replace the data scientists with",
    "start": "652399",
    "end": "654519"
  },
  {
    "text": "operators this way data scientists could",
    "start": "654519",
    "end": "657120"
  },
  {
    "text": "focus on problems that they're really",
    "start": "657120",
    "end": "659040"
  },
  {
    "text": "good at solving and like that bring",
    "start": "659040",
    "end": "660959"
  },
  {
    "text": "maximum value for them and the operators",
    "start": "660959",
    "end": "663279"
  },
  {
    "text": "could do what they're good at like just",
    "start": "663279",
    "end": "664959"
  },
  {
    "text": "running stuff",
    "start": "664959",
    "end": "667360"
  },
  {
    "text": "next up Alexi is going to be talking",
    "start": "667360",
    "end": "669200"
  },
  {
    "text": "about some of the pipelines they've",
    "start": "669200",
    "end": "670399"
  },
  {
    "text": "built",
    "start": "670399",
    "end": "672320"
  },
  {
    "text": "okay so Anish talked about modularity",
    "start": "672320",
    "end": "674480"
  },
  {
    "text": "and in order to provide uh reusable",
    "start": "674480",
    "end": "677600"
  },
  {
    "text": "components and modularity we implemented",
    "start": "677600",
    "end": "679600"
  },
  {
    "text": "all by steps like a simple pipeline and",
    "start": "679600",
    "end": "683440"
  },
  {
    "text": "uh we have first uh step is argument",
    "start": "683440",
    "end": "686800"
  },
  {
    "text": "preparation because uh some uh arguments",
    "start": "686800",
    "end": "689200"
  },
  {
    "text": "we need to proceed during the runtime",
    "start": "689200",
    "end": "691600"
  },
  {
    "text": "instead of compilation time after that",
    "start": "691600",
    "end": "694640"
  },
  {
    "text": "uh we start ray cluster and it's not we",
    "start": "694640",
    "end": "698160"
  },
  {
    "text": "actually it's a KFP component and uh",
    "start": "698160",
    "end": "700720"
  },
  {
    "text": "when the the ray cluster is ready KFP",
    "start": "700720",
    "end": "703600"
  },
  {
    "text": "submits the job to it and uh when job is",
    "start": "703600",
    "end": "706480"
  },
  {
    "text": "finished uh the cluster is stopped or",
    "start": "706480",
    "end": "709360"
  },
  {
    "text": "undep",
    "start": "709360",
    "end": "710920"
  },
  {
    "text": "undeployed the undeployed component is",
    "start": "710920",
    "end": "713600"
  },
  {
    "text": "implemented like exit handler it can be",
    "start": "713600",
    "end": "716480"
  },
  {
    "text": "similar to in the in the code for like",
    "start": "716480",
    "end": "718880"
  },
  {
    "text": "like try try and uh finalize final to",
    "start": "718880",
    "end": "723920"
  },
  {
    "text": "guarantee that cluster is undeployed",
    "start": "723920",
    "end": "726639"
  },
  {
    "text": "independently on the status of execution",
    "start": "726639",
    "end": "729600"
  },
  {
    "text": "of job if error or",
    "start": "729600",
    "end": "732279"
  },
  {
    "text": "success and all these free component uh",
    "start": "732279",
    "end": "735200"
  },
  {
    "text": "like deploy array cluster execute job",
    "start": "735200",
    "end": "737279"
  },
  {
    "text": "and uh destroys the array cluster or",
    "start": "737279",
    "end": "740639"
  },
  {
    "text": "shared component are the same for all",
    "start": "740639",
    "end": "742959"
  },
  {
    "text": "data prep-processing steps the",
    "start": "742959",
    "end": "744880"
  },
  {
    "text": "difference only in arguments that we",
    "start": "744880",
    "end": "747839"
  },
  {
    "text": "provide to",
    "start": "747839",
    "end": "748839"
  },
  {
    "text": "them we can see here example of uh",
    "start": "748839",
    "end": "752880"
  },
  {
    "text": "simple run run and with all the three",
    "start": "752880",
    "end": "756160"
  },
  {
    "text": "components like we mentioned uh here and",
    "start": "756160",
    "end": "758800"
  },
  {
    "text": "uh how we create the",
    "start": "758800",
    "end": "761240"
  },
  {
    "text": "components okay we created simple",
    "start": "761240",
    "end": "763519"
  },
  {
    "text": "pipelines but uh our target is to",
    "start": "763519",
    "end": "766160"
  },
  {
    "text": "automate the entire uh process maybe",
    "start": "766160",
    "end": "769440"
  },
  {
    "text": "several uh data prep-processing steps or",
    "start": "769440",
    "end": "771600"
  },
  {
    "text": "all the the steps so we create",
    "start": "771600",
    "end": "774240"
  },
  {
    "text": "multi-step",
    "start": "774240",
    "end": "775639"
  },
  {
    "text": "pipelines or super pipelines like we",
    "start": "775639",
    "end": "778240"
  },
  {
    "text": "call them where each step is a nested",
    "start": "778240",
    "end": "781200"
  },
  {
    "text": "pipeline or nested simple pipeline for",
    "start": "781200",
    "end": "783519"
  },
  {
    "text": "specific data prep-processing step and",
    "start": "783519",
    "end": "786320"
  },
  {
    "text": "you can ask um how we implement nested",
    "start": "786320",
    "end": "788880"
  },
  {
    "text": "pipeline if we work for example with KFP",
    "start": "788880",
    "end": "791279"
  },
  {
    "text": "v1 because uh nested pipeline were",
    "start": "791279",
    "end": "794320"
  },
  {
    "text": "introduced in KFP only in version",
    "start": "794320",
    "end": "797399"
  },
  {
    "text": "two so we use a KFPS SDK to execute",
    "start": "797399",
    "end": "802800"
  },
  {
    "text": "pre-installed uh simple pipeline and as",
    "start": "802800",
    "end": "806800"
  },
  {
    "text": "a result uh on with KFP1 we have uh n",
    "start": "806800",
    "end": "810399"
  },
  {
    "text": "plus one runs where n is the number of",
    "start": "810399",
    "end": "812959"
  },
  {
    "text": "steps in in the multi-step pipeline for",
    "start": "812959",
    "end": "815040"
  },
  {
    "text": "example here we will get four runs and",
    "start": "815040",
    "end": "819040"
  },
  {
    "text": "in the demo we are going to show you how",
    "start": "819040",
    "end": "821440"
  },
  {
    "text": "we do",
    "start": "821440",
    "end": "822440"
  },
  {
    "text": "it and it's a perfect time to go to the",
    "start": "822440",
    "end": "826120"
  },
  {
    "text": "demo i think it's this one",
    "start": "826120",
    "end": "830360"
  },
  {
    "text": "okay maybe let me stop it for a",
    "start": "830360",
    "end": "835839"
  },
  {
    "text": "moment we can see here we have several",
    "start": "838040",
    "end": "842760"
  },
  {
    "text": "pipelines deployed on KFP server it's",
    "start": "842760",
    "end": "846160"
  },
  {
    "text": "KFP v1 the first one it's a multi-step",
    "start": "846160",
    "end": "849959"
  },
  {
    "text": "pipeline just in a moment I will show it",
    "start": "849959",
    "end": "852639"
  },
  {
    "text": "and all others are simple pipelines for",
    "start": "852639",
    "end": "855600"
  },
  {
    "text": "specific uh step in the data",
    "start": "855600",
    "end": "857680"
  },
  {
    "text": "prep-processing",
    "start": "857680",
    "end": "859760"
  },
  {
    "text": "so we go",
    "start": "859760",
    "end": "861720"
  },
  {
    "text": "here and",
    "start": "861720",
    "end": "864839"
  },
  {
    "text": "uh we can see here that uh first we run",
    "start": "864839",
    "end": "868720"
  },
  {
    "text": "uh document docu document identification",
    "start": "868720",
    "end": "871360"
  },
  {
    "text": "after that exact dduplication and after",
    "start": "871360",
    "end": "874959"
  },
  {
    "text": "that",
    "start": "874959",
    "end": "876519"
  },
  {
    "text": "language separation and filtering and",
    "start": "876519",
    "end": "879680"
  },
  {
    "text": "then uh we have uh annotated transforms",
    "start": "879680",
    "end": "883600"
  },
  {
    "text": "for uh document quality",
    "start": "883600",
    "end": "887480"
  },
  {
    "text": "annotations and uh we run",
    "start": "887480",
    "end": "890519"
  },
  {
    "text": "uh uh three different",
    "start": "890519",
    "end": "893320"
  },
  {
    "text": "uh sub pipelines for different languages",
    "start": "893320",
    "end": "896320"
  },
  {
    "text": "for English uh Japanese and uh",
    "start": "896320",
    "end": "901519"
  },
  {
    "text": "French okay",
    "start": "902199",
    "end": "905320"
  },
  {
    "text": "so",
    "start": "905320",
    "end": "908320"
  },
  {
    "text": "okay and uh we can see here for each uh",
    "start": "909240",
    "end": "914480"
  },
  {
    "text": "simple pipeline we have the same pattern",
    "start": "914480",
    "end": "917199"
  },
  {
    "text": "with or with",
    "start": "917199",
    "end": "918839"
  },
  {
    "text": "arba with",
    "start": "918839",
    "end": "920600"
  },
  {
    "text": "four steps like we discussed before and",
    "start": "920600",
    "end": "923680"
  },
  {
    "text": "we didn't have any any",
    "start": "923680",
    "end": "925639"
  },
  {
    "text": "runs now we execute the the super",
    "start": "925639",
    "end": "928880"
  },
  {
    "text": "pipeline we start the",
    "start": "928880",
    "end": "931639"
  },
  {
    "text": "run okay and",
    "start": "931639",
    "end": "936399"
  },
  {
    "text": "uh we can see first first run it's the",
    "start": "937639",
    "end": "941920"
  },
  {
    "text": "run of a multistep",
    "start": "941920",
    "end": "944839"
  },
  {
    "text": "pipeline in a minute uh we will have",
    "start": "944839",
    "end": "947519"
  },
  {
    "text": "another",
    "start": "947519",
    "end": "949920"
  },
  {
    "text": "one okay",
    "start": "950680",
    "end": "952680"
  },
  {
    "text": "it's meantime I will demonstrate you the",
    "start": "952680",
    "end": "955920"
  },
  {
    "text": "KFPV2",
    "start": "955920",
    "end": "957920"
  },
  {
    "text": "it's exactly the same super pipeline but",
    "start": "957920",
    "end": "960399"
  },
  {
    "text": "uh here we have uh KFPv2 supports nested",
    "start": "960399",
    "end": "964399"
  },
  {
    "text": "pipeline here the real nested pi",
    "start": "964399",
    "end": "967160"
  },
  {
    "text": "pipelines we can go into the the UI to",
    "start": "967160",
    "end": "971120"
  },
  {
    "text": "see the parameters and uh we can execute",
    "start": "971120",
    "end": "975600"
  },
  {
    "text": "start the run and uh another example",
    "start": "975600",
    "end": "978560"
  },
  {
    "text": "here that we demonstrated like Anish",
    "start": "978560",
    "end": "980399"
  },
  {
    "text": "said that we had previous run and we",
    "start": "980399",
    "end": "982720"
  },
  {
    "text": "just clone it to run it again so we have",
    "start": "982720",
    "end": "985600"
  },
  {
    "text": "a history of uh",
    "start": "985600",
    "end": "988279"
  },
  {
    "text": "execution and we can see the first step",
    "start": "988279",
    "end": "991440"
  },
  {
    "text": "is is running now",
    "start": "991440",
    "end": "995600"
  },
  {
    "text": "go back to KFP",
    "start": "995600",
    "end": "998279"
  },
  {
    "text": "v1 refresh and we see that uh in",
    "start": "998279",
    "end": "1001360"
  },
  {
    "text": "additional to super pipeline uh docu",
    "start": "1001360",
    "end": "1004399"
  },
  {
    "text": "docu document ID is running and almost",
    "start": "1004399",
    "end": "1007680"
  },
  {
    "text": "here it's done and uh we go",
    "start": "1007680",
    "end": "1012600"
  },
  {
    "text": "back to runs and we see that exact",
    "start": "1012600",
    "end": "1015920"
  },
  {
    "text": "dduplication uh is",
    "start": "1015920",
    "end": "1018360"
  },
  {
    "text": "starting and we can see go into",
    "start": "1018360",
    "end": "1022040"
  },
  {
    "text": "the super pipeline multi-step pipeline",
    "start": "1022040",
    "end": "1025038"
  },
  {
    "text": "And we can see that the first step is",
    "start": "1025039",
    "end": "1026600"
  },
  {
    "text": "done exactly duplication is done and now",
    "start": "1026600",
    "end": "1029839"
  },
  {
    "text": "the language identification is starting",
    "start": "1029839",
    "end": "1031760"
  },
  {
    "text": "and we can see for each step the",
    "start": "1031760",
    "end": "1034000"
  },
  {
    "text": "different runs on the on the",
    "start": "1034000",
    "end": "1037480"
  },
  {
    "text": "dashboard for KFP V2 it's simpler we",
    "start": "1037480",
    "end": "1041520"
  },
  {
    "text": "have only single run and we can uh see",
    "start": "1041520",
    "end": "1044720"
  },
  {
    "text": "the status of each steps on the same uh",
    "start": "1044720",
    "end": "1047839"
  },
  {
    "text": "view",
    "start": "1047839",
    "end": "1050839"
  },
  {
    "text": "so it's",
    "start": "1052960",
    "end": "1054440"
  },
  {
    "text": "um language and notification is finished",
    "start": "1054440",
    "end": "1057679"
  },
  {
    "text": "and now we have a split for each",
    "start": "1057679",
    "end": "1060360"
  },
  {
    "text": "languages for uh English Japanese and",
    "start": "1060360",
    "end": "1064520"
  },
  {
    "text": "Fr the filtering the filtering is done",
    "start": "1064520",
    "end": "1068240"
  },
  {
    "text": "and now we run",
    "start": "1068240",
    "end": "1070360"
  },
  {
    "text": "it's",
    "start": "1070360",
    "end": "1072039"
  },
  {
    "text": "document quality",
    "start": "1072039",
    "end": "1074440"
  },
  {
    "text": "annotators the same on",
    "start": "1074440",
    "end": "1077080"
  },
  {
    "text": "KFPV2 just refresh the screen",
    "start": "1077080",
    "end": "1080559"
  },
  {
    "text": "and uh we have language identification",
    "start": "1080559",
    "end": "1083039"
  },
  {
    "text": "is done the Japanese filter is starting",
    "start": "1083039",
    "end": "1086480"
  },
  {
    "text": "the first after that others and",
    "start": "1086480",
    "end": "1090120"
  },
  {
    "text": "uh meantime we return back to KFPV1 we",
    "start": "1090120",
    "end": "1094880"
  },
  {
    "text": "see that the process is done and if we",
    "start": "1094880",
    "end": "1097600"
  },
  {
    "text": "go to the",
    "start": "1097600",
    "end": "1098679"
  },
  {
    "text": "run and we can see that instead of a",
    "start": "1098679",
    "end": "1101280"
  },
  {
    "text": "single run we have a lot of different",
    "start": "1101280",
    "end": "1103280"
  },
  {
    "text": "runs for each step we have a separate",
    "start": "1103280",
    "end": "1105039"
  },
  {
    "text": "run and we can go into the if you want",
    "start": "1105039",
    "end": "1109200"
  },
  {
    "text": "to runs and check",
    "start": "1109200",
    "end": "1110760"
  },
  {
    "text": "it on KFPV2 the Japanese filter started",
    "start": "1110760",
    "end": "1114720"
  },
  {
    "text": "first so now the docu quality for",
    "start": "1114720",
    "end": "1118000"
  },
  {
    "text": "Japanese is started and uh",
    "start": "1118000",
    "end": "1121720"
  },
  {
    "text": "other quality docu document annotators",
    "start": "1121720",
    "end": "1125600"
  },
  {
    "text": "are running and it's done and if you go",
    "start": "1125600",
    "end": "1128240"
  },
  {
    "text": "to the now to",
    "start": "1128240",
    "end": "1130440"
  },
  {
    "text": "runs just to demonstrate that all the",
    "start": "1130440",
    "end": "1133480"
  },
  {
    "text": "picture and",
    "start": "1133480",
    "end": "1136799"
  },
  {
    "text": "uh just",
    "start": "1136840",
    "end": "1140240"
  },
  {
    "text": "moment we",
    "start": "1140840",
    "end": "1142679"
  },
  {
    "text": "have only two runs here because one it's",
    "start": "1142679",
    "end": "1146640"
  },
  {
    "text": "the previous run and the second one",
    "start": "1146640",
    "end": "1149000"
  },
  {
    "text": "it's that we executed i think we done",
    "start": "1149000",
    "end": "1153360"
  },
  {
    "text": "with the",
    "start": "1153360",
    "end": "1155400"
  },
  {
    "text": "demo and",
    "start": "1155400",
    "end": "1157960"
  },
  {
    "text": "um we go to discuss",
    "start": "1157960",
    "end": "1161320"
  },
  {
    "text": "um",
    "start": "1161320",
    "end": "1163559"
  },
  {
    "text": "s the history of our work when IBM",
    "start": "1163559",
    "end": "1167679"
  },
  {
    "text": "started work uh working on um data",
    "start": "1167679",
    "end": "1170240"
  },
  {
    "text": "preparation for large language models",
    "start": "1170240",
    "end": "1173280"
  },
  {
    "text": "each data scientist work independently",
    "start": "1173280",
    "end": "1175919"
  },
  {
    "text": "they created proprietary Python scripts",
    "start": "1175919",
    "end": "1179280"
  },
  {
    "text": "executed them on Ray on Spark okay with",
    "start": "1179280",
    "end": "1182160"
  },
  {
    "text": "KFP we automated the process of uh start",
    "start": "1182160",
    "end": "1186480"
  },
  {
    "text": "and run but",
    "start": "1186480",
    "end": "1190880"
  },
  {
    "text": "the data processing scripts stay",
    "start": "1191160",
    "end": "1196160"
  },
  {
    "text": "proprietary and uh it's create a lot of",
    "start": "1196160",
    "end": "1199440"
  },
  {
    "text": "problems for example for newcomers or",
    "start": "1199440",
    "end": "1201520"
  },
  {
    "text": "somebody developers wanted to create a",
    "start": "1201520",
    "end": "1203919"
  },
  {
    "text": "new transformer he has to",
    "start": "1203919",
    "end": "1207160"
  },
  {
    "text": "know he had to know how to work with the",
    "start": "1207160",
    "end": "1211120"
  },
  {
    "text": "infrastructure how to work with ray how",
    "start": "1211120",
    "end": "1213440"
  },
  {
    "text": "to work with",
    "start": "1213440",
    "end": "1215640"
  },
  {
    "text": "spark and",
    "start": "1215640",
    "end": "1217799"
  },
  {
    "text": "uh in order to resolve this uh problem",
    "start": "1217799",
    "end": "1221120"
  },
  {
    "text": "uh last year with submitted uh or",
    "start": "1221120",
    "end": "1225760"
  },
  {
    "text": "published",
    "start": "1225760",
    "end": "1227000"
  },
  {
    "text": "uh data prep kit opensource",
    "start": "1227000",
    "end": "1230760"
  },
  {
    "text": "project that designed to provide",
    "start": "1230760",
    "end": "1233960"
  },
  {
    "text": "uh to help to implement data processing",
    "start": "1233960",
    "end": "1237679"
  },
  {
    "text": "in consistent way",
    "start": "1237679",
    "end": "1240159"
  },
  {
    "text": "it rem removed uh need for mo mobile",
    "start": "1240159",
    "end": "1244080"
  },
  {
    "text": "developers for model developers to",
    "start": "1244080",
    "end": "1246480"
  },
  {
    "text": "implement common task like access to S3",
    "start": "1246480",
    "end": "1249280"
  },
  {
    "text": "storage generate metadata",
    "start": "1249280",
    "end": "1252000"
  },
  {
    "text": "uh unified uh shared parameters and the",
    "start": "1252000",
    "end": "1255360"
  },
  {
    "text": "most important uh it wraps um run",
    "start": "1255360",
    "end": "1259799"
  },
  {
    "text": "running uh frame framework so the",
    "start": "1259799",
    "end": "1263559"
  },
  {
    "text": "developers now don't have to know deep",
    "start": "1263559",
    "end": "1266559"
  },
  {
    "text": "knowledge about rail spark",
    "start": "1266559",
    "end": "1269360"
  },
  {
    "text": "at simplify add new",
    "start": "1269360",
    "end": "1271960"
  },
  {
    "text": "models and of course uh we have KFP",
    "start": "1271960",
    "end": "1277039"
  },
  {
    "text": "automation for the models on the same",
    "start": "1277039",
    "end": "1280039"
  },
  {
    "text": "um",
    "start": "1280039",
    "end": "1282360"
  },
  {
    "text": "project DPK",
    "start": "1282360",
    "end": "1284520"
  },
  {
    "text": "was checked in production it was used",
    "start": "1284520",
    "end": "1288880"
  },
  {
    "text": "for IBM granite LLM's creations and um",
    "start": "1288880",
    "end": "1294159"
  },
  {
    "text": "two weeks ago uh DPK joined",
    "start": "1294159",
    "end": "1298159"
  },
  {
    "text": "Linux Foundation data and AI",
    "start": "1298159",
    "end": "1303480"
  },
  {
    "text": "community this picture is from",
    "start": "1303480",
    "end": "1306360"
  },
  {
    "text": "um",
    "start": "1306360",
    "end": "1308679"
  },
  {
    "text": "our paper that was published last year",
    "start": "1308679",
    "end": "1311440"
  },
  {
    "text": "on data in big data confidence and uh we",
    "start": "1311440",
    "end": "1315600"
  },
  {
    "text": "can see",
    "start": "1315600",
    "end": "1316919"
  },
  {
    "text": "here list of different transformance",
    "start": "1316919",
    "end": "1319360"
  },
  {
    "text": "it's not all of them that uh we have in",
    "start": "1319360",
    "end": "1321679"
  },
  {
    "text": "DPK we have much more but most important",
    "start": "1321679",
    "end": "1325480"
  },
  {
    "text": "past part here is that we have different",
    "start": "1325480",
    "end": "1328320"
  },
  {
    "text": "runtimes we have we can run on pi python",
    "start": "1328320",
    "end": "1331840"
  },
  {
    "text": "just on the laptop we can uh run it on",
    "start": "1331840",
    "end": "1334559"
  },
  {
    "text": "spark we can run it on array and uh KFP",
    "start": "1334559",
    "end": "1338080"
  },
  {
    "text": "automation for",
    "start": "1338080",
    "end": "1339960"
  },
  {
    "text": "uh automated process and DPK is not only",
    "start": "1339960",
    "end": "1344159"
  },
  {
    "text": "for finetuning code data preparation it",
    "start": "1344159",
    "end": "1347039"
  },
  {
    "text": "can be used for ra we have some examples",
    "start": "1347039",
    "end": "1350000"
  },
  {
    "text": "on the on the p in",
    "start": "1350000",
    "end": "1352520"
  },
  {
    "text": "the",
    "start": "1352520",
    "end": "1354679"
  },
  {
    "text": "project and",
    "start": "1354679",
    "end": "1357320"
  },
  {
    "text": "um actually yeah sure um so here's some",
    "start": "1357320",
    "end": "1360640"
  },
  {
    "text": "QR codes you can scan or just Google for",
    "start": "1360640",
    "end": "1362960"
  },
  {
    "text": "these uh the first one takes you to the",
    "start": "1362960",
    "end": "1365039"
  },
  {
    "text": "data prep kit project and the second one",
    "start": "1365039",
    "end": "1367200"
  },
  {
    "text": "is a link to the cubeflow community um",
    "start": "1367200",
    "end": "1370320"
  },
  {
    "text": "again both communities we're really",
    "start": "1370320",
    "end": "1372159"
  },
  {
    "text": "trying to grow them out um so you know",
    "start": "1372159",
    "end": "1374240"
  },
  {
    "text": "we welcome contributions",
    "start": "1374240",
    "end": "1377559"
  },
  {
    "text": "um so let's get in a few seconds for",
    "start": "1377559",
    "end": "1380400"
  },
  {
    "text": "that um I'd also like to call out this",
    "start": "1380400",
    "end": "1382720"
  },
  {
    "text": "is Alexis's first time giving a",
    "start": "1382720",
    "end": "1384320"
  },
  {
    "text": "presentation so like",
    "start": "1384320",
    "end": "1387840"
  },
  {
    "text": "[Applause]",
    "start": "1389180",
    "end": "1393880"
  },
  {
    "text": "congratulations all right we have seven",
    "start": "1393880",
    "end": "1396640"
  },
  {
    "text": "minutes left so any",
    "start": "1396640",
    "end": "1399919"
  },
  {
    "text": "questions it looks like there's a mic in",
    "start": "1401240",
    "end": "1403440"
  },
  {
    "text": "the middle I think",
    "start": "1403440",
    "end": "1407039"
  },
  {
    "text": "hello all right um yes in CubeFlow",
    "start": "1413360",
    "end": "1416880"
  },
  {
    "text": "upstream we have experimental",
    "start": "1416880",
    "end": "1419200"
  },
  {
    "text": "integration for Ray as well so did you",
    "start": "1419200",
    "end": "1421840"
  },
  {
    "text": "use that or did you build your own Ray",
    "start": "1421840",
    "end": "1425039"
  },
  {
    "text": "i'm sorry could you repeat the second",
    "start": "1425039",
    "end": "1426400"
  },
  {
    "text": "bit a bit",
    "start": "1426400",
    "end": "1428640"
  },
  {
    "text": "did you use the experimental integration",
    "start": "1428640",
    "end": "1431600"
  },
  {
    "text": "in upstream cubeflow for ray or did you",
    "start": "1431600",
    "end": "1434480"
  },
  {
    "text": "build it yourself the cube ray",
    "start": "1434480",
    "end": "1437080"
  },
  {
    "text": "integration so um this was using vanilla",
    "start": "1437080",
    "end": "1440880"
  },
  {
    "text": "cubray like there's no",
    "start": "1440880",
    "end": "1443400"
  },
  {
    "text": "additional extensions really on cube um",
    "start": "1443400",
    "end": "1446640"
  },
  {
    "text": "there were some features that were added",
    "start": "1446640",
    "end": "1448480"
  },
  {
    "text": "to the cube API server and cubri as part",
    "start": "1448480",
    "end": "1451360"
  },
  {
    "text": "of some of this work but that's all",
    "start": "1451360",
    "end": "1453200"
  },
  {
    "text": "upstream",
    "start": "1453200",
    "end": "1454880"
  },
  {
    "text": "actually we have addition but not on KFP",
    "start": "1454880",
    "end": "1458400"
  },
  {
    "text": "not on Cubray but the connection between",
    "start": "1458400",
    "end": "1461039"
  },
  {
    "text": "KFP and Cubray how to execute the the",
    "start": "1461039",
    "end": "1465760"
  },
  {
    "text": "free components that I mentioned here to",
    "start": "1465760",
    "end": "1467520"
  },
  {
    "text": "start",
    "start": "1467520",
    "end": "1468440"
  },
  {
    "text": "the array to to submit the job and to",
    "start": "1468440",
    "end": "1472000"
  },
  {
    "text": "destroy the cluster yeah for example the",
    "start": "1472000",
    "end": "1474640"
  },
  {
    "text": "permissions to do that I think they're",
    "start": "1474640",
    "end": "1476480"
  },
  {
    "text": "also upstream so that you could maybe",
    "start": "1476480",
    "end": "1479880"
  },
  {
    "text": "reuse and the second question is",
    "start": "1479880",
    "end": "1482480"
  },
  {
    "text": "regarding Spark did you try something",
    "start": "1482480",
    "end": "1484960"
  },
  {
    "text": "similar with the Spark operator as well",
    "start": "1484960",
    "end": "1489840"
  },
  {
    "text": "um I'll let you answer that one yes we",
    "start": "1489840",
    "end": "1493039"
  },
  {
    "text": "we had discussions about the spark",
    "start": "1493039",
    "end": "1495360"
  },
  {
    "text": "integration with KFP and actually",
    "start": "1495360",
    "end": "1498080"
  },
  {
    "text": "checked the spark operator that",
    "start": "1498080",
    "end": "1501039"
  },
  {
    "text": "currently part of a",
    "start": "1501039",
    "end": "1503240"
  },
  {
    "text": "KFP project but meantime we use only RA",
    "start": "1503240",
    "end": "1507200"
  },
  {
    "text": "is KFP so the spark operator is a little",
    "start": "1507200",
    "end": "1510480"
  },
  {
    "text": "more recent to the cubeflow project so",
    "start": "1510480",
    "end": "1513600"
  },
  {
    "text": "when we started on it cube seemed to be",
    "start": "1513600",
    "end": "1516080"
  },
  {
    "text": "in a better spot so something we'll",
    "start": "1516080",
    "end": "1518880"
  },
  {
    "text": "probably revisit in the future",
    "start": "1518880",
    "end": "1521919"
  },
  {
    "text": "thank you thank you",
    "start": "1521919",
    "end": "1526278"
  },
  {
    "text": "hi thank you for the presentation um",
    "start": "1528880",
    "end": "1531360"
  },
  {
    "text": "being new to the um CubeFlow um I have a",
    "start": "1531360",
    "end": "1536240"
  },
  {
    "text": "question um and it makes an impression",
    "start": "1536240",
    "end": "1539279"
  },
  {
    "text": "that the maintaining this framework on",
    "start": "1539279",
    "end": "1541279"
  },
  {
    "text": "Kubernetes is pretty large effort and",
    "start": "1541279",
    "end": "1543679"
  },
  {
    "text": "requires you know significant investment",
    "start": "1543679",
    "end": "1545520"
  },
  {
    "text": "of skills so I'm wondering for the",
    "start": "1545520",
    "end": "1548320"
  },
  {
    "text": "specific um pre-training task that you",
    "start": "1548320",
    "end": "1551039"
  },
  {
    "text": "demoed today with the cubeflow pipelines",
    "start": "1551039",
    "end": "1553919"
  },
  {
    "text": "which is obviously working could it be",
    "start": "1553919",
    "end": "1556240"
  },
  {
    "text": "sort of implemented with a more",
    "start": "1556240",
    "end": "1558120"
  },
  {
    "text": "lightweight components without",
    "start": "1558120",
    "end": "1560320"
  },
  {
    "text": "deployment the whole cubeflow so make it",
    "start": "1560320",
    "end": "1562480"
  },
  {
    "text": "more sort of smaller footprint more",
    "start": "1562480",
    "end": "1565360"
  },
  {
    "text": "accessible uh or it has to be full-blown",
    "start": "1565360",
    "end": "1568799"
  },
  {
    "text": "deployment of cubeflow pipelines",
    "start": "1568799",
    "end": "1573559"
  },
  {
    "text": "you can use DPK with",
    "start": "1574080",
    "end": "1576760"
  },
  {
    "text": "without KFP you can run it on just in",
    "start": "1576760",
    "end": "1581120"
  },
  {
    "text": "Python or spark or with array but it",
    "start": "1581120",
    "end": "1585919"
  },
  {
    "text": "will be single step and in the do in the",
    "start": "1585919",
    "end": "1591520"
  },
  {
    "text": "examples we have integration",
    "start": "1591520",
    "end": "1595120"
  },
  {
    "text": "with with the Jupiter notebooks it's a",
    "start": "1595320",
    "end": "1598240"
  },
  {
    "text": "kind of pipelines to connect the steps",
    "start": "1598240",
    "end": "1601440"
  },
  {
    "text": "together and uh currently we check if it",
    "start": "1601440",
    "end": "1604240"
  },
  {
    "text": "can be maybe with langraph",
    "start": "1604240",
    "end": "1607919"
  },
  {
    "text": "lraph and the len len flow so the same",
    "start": "1607919",
    "end": "1612159"
  },
  {
    "text": "script could be run from the Jupyter",
    "start": "1612159",
    "end": "1614320"
  },
  {
    "text": "notebook essentially and that would work",
    "start": "1614320",
    "end": "1616320"
  },
  {
    "text": "as well as long as it uses your plug-in",
    "start": "1616320",
    "end": "1618320"
  },
  {
    "text": "right correct correct okay yes thank you",
    "start": "1618320",
    "end": "1625000"
  },
  {
    "text": "all right uh well we're basically at",
    "start": "1629200",
    "end": "1631520"
  },
  {
    "text": "time um if anyone wants to talk in more",
    "start": "1631520",
    "end": "1633679"
  },
  {
    "text": "detail about any other stuff you know",
    "start": "1633679",
    "end": "1635120"
  },
  {
    "text": "feel free to come by 30 minutes is not a",
    "start": "1635120",
    "end": "1637760"
  },
  {
    "text": "lot of time to go into tons of detail so",
    "start": "1637760",
    "end": "1640799"
  },
  {
    "text": "yeah thank you for attending",
    "start": "1640799",
    "end": "1643440"
  },
  {
    "text": "thank you",
    "start": "1643440",
    "end": "1646679"
  }
]
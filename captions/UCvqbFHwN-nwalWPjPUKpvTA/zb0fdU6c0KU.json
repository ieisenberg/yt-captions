[
  {
    "start": "0",
    "end": "87000"
  },
  {
    "text": "okay we were going to start everyone for coming this is a Jaeger deep dive we'll",
    "start": "210",
    "end": "7500"
  },
  {
    "text": "live demo yesterday if you want to see that go back in time and see that one here is more about architecture of",
    "start": "7500",
    "end": "16920"
  },
  {
    "text": "Jaeger and I always deployed and all found like more technical details that",
    "start": "16920",
    "end": "22020"
  },
  {
    "text": "you may wanna know so we will talk about the project briefly as open source",
    "start": "22020",
    "end": "28380"
  },
  {
    "text": "project we will talk about how tracing really works yesterday I gave a sort of a hand wavy story about how that's",
    "start": "28380",
    "end": "35790"
  },
  {
    "text": "implemented but today we want a bit like dive a bit deeper on that and we'll talk",
    "start": "35790",
    "end": "41309"
  },
  {
    "text": "about like features of Jaeger and enrolled my opinion all other things and",
    "start": "41309",
    "end": "46379"
  },
  {
    "text": "we'll try to leave a lot more time to Q&A than yesterday so again to introduce",
    "start": "46379",
    "end": "52620"
  },
  {
    "text": "ourselves I'm URIs crow I work at uber on observability systems mostly on tracing",
    "start": "52620",
    "end": "59000"
  },
  {
    "text": "and I maintain Jaeger and open tracing and open telemetry and I published a",
    "start": "59000",
    "end": "65460"
  },
  {
    "text": "book on tracing so if you want to check it out it has a lot of things that we'll talk about today but racing in and",
    "start": "65460",
    "end": "73680"
  },
  {
    "text": "powell will take from here can you enjoy yeah hi my name is Paul if I ever get a software engineer a Red Hat I also work",
    "start": "73680",
    "end": "81030"
  },
  {
    "text": "on Jaeger open tracing and open telemetry projects swagger is not only a",
    "start": "81030",
    "end": "88530"
  },
  {
    "start": "87000",
    "end": "87000"
  },
  {
    "text": "distributed tracing tool it's also like the whole platform because we provide different bits as pieces which can be",
    "start": "88530",
    "end": "94590"
  },
  {
    "text": "used separately so starting we have a lot of instrumentation libraries written in different languages this libraries",
    "start": "94590",
    "end": "101340"
  },
  {
    "text": "implement open tracing API and you can use them in your applications to report",
    "start": "101340",
    "end": "106649"
  },
  {
    "text": "data to our trace collection back-end and then the stress collection mecca and",
    "start": "106649",
    "end": "112649"
  },
  {
    "text": "writes data to the database which is later represented in the UI then there",
    "start": "112649",
    "end": "118590"
  },
  {
    "text": "is also data mining platform which can you know get the data from the database",
    "start": "118590",
    "end": "124460"
  },
  {
    "text": "analyze it do some aggregation and stores it back which is then used in the UI for different visualizations",
    "start": "124460",
    "end": "132619"
  },
  {
    "text": "so Jaeger itself the architecture is inspired by Google's diaper system and",
    "start": "133110",
    "end": "138990"
  },
  {
    "text": "open Zipkin it was initially it started at uber in 2015 open source in in 2017",
    "start": "138990",
    "end": "148080"
  },
  {
    "text": "when it also joined CN CF s incubating project and last month we graduated as a",
    "start": "148080",
    "end": "154800"
  },
  {
    "text": "top-level CN CF project I would like to thank all of the contributors who made",
    "start": "154800",
    "end": "161220"
  },
  {
    "text": "it possible on the technology stack the",
    "start": "161220",
    "end": "167820"
  },
  {
    "start": "165000",
    "end": "165000"
  },
  {
    "text": "system itself all the backend components are written in go Lang we super",
    "start": "167820",
    "end": "173010"
  },
  {
    "text": "different storage layers so you can write data to Cassandra elasticsearch better and in memory the UI is pretty",
    "start": "173010",
    "end": "181080"
  },
  {
    "text": "nice is written in react as I mentioned before a lot of we have a lot of clients",
    "start": "181080",
    "end": "188790"
  },
  {
    "text": "in different languages so pretty much we support every mainstream language like :",
    "start": "188790",
    "end": "195030"
  },
  {
    "text": "Java Python nodejs C++ C sharp and there",
    "start": "195030",
    "end": "200459"
  },
  {
    "text": "are two community based PHP LMB then there is integration with Kafka we will",
    "start": "200459",
    "end": "206610"
  },
  {
    "text": "talk about it a little bit later and of course Apache fling and Apache spark for",
    "start": "206610",
    "end": "211980"
  },
  {
    "text": "data aggregation and data analytics about the community so the main",
    "start": "211980",
    "end": "219570"
  },
  {
    "start": "217000",
    "end": "217000"
  },
  {
    "text": "repository has about nine thousand stars in the moment a lot of contributors and",
    "start": "219570",
    "end": "224670"
  },
  {
    "text": "at the moment fifteen maintainer occurs all the projects in the main organization we are very happy to accept",
    "start": "224670",
    "end": "231720"
  },
  {
    "text": "more we do release roughly every two months although we would like to shorten",
    "start": "231720",
    "end": "239340"
  },
  {
    "text": "this time to to one month to which the features quickly to the community so",
    "start": "239340",
    "end": "249720"
  },
  {
    "text": "it's your birthday so they promised let's let's talk about how tradition",
    "start": "249720",
    "end": "256739"
  },
  {
    "text": "works in practice this might look a bit look through it so what we see here in",
    "start": "256739",
    "end": "263729"
  },
  {
    "text": "green are two to services right and we want to trace request and at the top like left left to",
    "start": "263729",
    "end": "273470"
  },
  {
    "text": "right and right to left is the request response chain of like execution so what",
    "start": "273470",
    "end": "278960"
  },
  {
    "text": "we see here is that when the request comes to the first micro service it first hits some server end point and",
    "start": "278960",
    "end": "286490"
  },
  {
    "text": "there is an instrumentation in that point which sometimes is called a trace point right that trace point before",
    "start": "286490",
    "end": "294500"
  },
  {
    "text": "certain things specifically in this case it takes the trace context which is",
    "start": "294500",
    "end": "300650"
  },
  {
    "text": "typically passed on the wire between those micro services and converts the trace contact is some in memorization so",
    "start": "300650",
    "end": "308120"
  },
  {
    "text": "that when their execution follows to the next trace point and to the next trace point that trace context or you can",
    "start": "308120",
    "end": "315320"
  },
  {
    "text": "think of trace context or in the in the simplest form as just a trace I do a request ID that's the one that we need",
    "start": "315320",
    "end": "321260"
  },
  {
    "text": "to correlate all live ants happening within the application but it's typically more than that and so that",
    "start": "321260",
    "end": "327050"
  },
  {
    "text": "trace context has to be propagated through the whole call chain not only",
    "start": "327050",
    "end": "332300"
  },
  {
    "text": "between the services but within the services as well right so like if you have multiple trace points in the service they all have to have access to",
    "start": "332300",
    "end": "338540"
  },
  {
    "text": "the trace context in order to be able to identify the event correctly and so what",
    "start": "338540",
    "end": "344300"
  },
  {
    "text": "I'm showing here is like kind of rectangular traced points and circulatory points the circular ones are",
    "start": "344300",
    "end": "350210"
  },
  {
    "text": "you can think of them with something like inside the application but maybe it's making a database call right so you",
    "start": "350210",
    "end": "355880"
  },
  {
    "text": "you have a trace point so you want to again capture some information about",
    "start": "355880",
    "end": "361280"
  },
  {
    "text": "that database call maybe like SQL query and then what every trace point does is",
    "start": "361280",
    "end": "367160"
  },
  {
    "text": "essentially what is a trace point a trace point is some piece of code which is it may be in your application",
    "start": "367160",
    "end": "373070"
  },
  {
    "text": "directly or it may be maybe it's some in",
    "start": "373070",
    "end": "378230"
  },
  {
    "text": "some framework that that your your application is using and and that piece",
    "start": "378230",
    "end": "383750"
  },
  {
    "text": "of code this gathers the data about the operation that you about you to do like",
    "start": "383750",
    "end": "389600"
  },
  {
    "text": "I said that could be a scale query or maybe some name of the temperature and it's it's writes that that data into",
    "start": "389600",
    "end": "396830"
  },
  {
    "text": "what I call in this die a tracing API right it just you can think of it like similar to logon when",
    "start": "396830",
    "end": "402819"
  },
  {
    "text": "you say a log dot info you provide the string you provide some parameters right what happens at that case you you",
    "start": "402819",
    "end": "408729"
  },
  {
    "text": "actually instrument in your code with the log statement and that information gets written to some underlying login",
    "start": "408729",
    "end": "414879"
  },
  {
    "text": "implementation that runs in your application which could later on write it to disk maybe ship it somewhere else",
    "start": "414879",
    "end": "420669"
  },
  {
    "text": "your application doesn't really care at that point you all you did just like you call the cloak with infrared so it's the",
    "start": "420669",
    "end": "425830"
  },
  {
    "text": "same thing with trace you just have you call a slightly different API maybe you start a span and you finish a span you",
    "start": "425830",
    "end": "431499"
  },
  {
    "text": "attach attack to expand your given name to span but ultimately conceptually it's very similar to just doing a more",
    "start": "431499",
    "end": "438069"
  },
  {
    "text": "structured logging and then tracing API it's an abstract thing like similar to login API is just no like it doesn't",
    "start": "438069",
    "end": "445839"
  },
  {
    "text": "actually do by itself anything you just call it it's a callback and then usually that API is implemented by some tracing",
    "start": "445839",
    "end": "452860"
  },
  {
    "text": "library in this case it could be Jaeger client it could be any other tracing library actually you can have a Zipkin",
    "start": "452860",
    "end": "457929"
  },
  {
    "text": "library or liquid open telemetry if you go to those talks so they also sometimes",
    "start": "457929",
    "end": "463300"
  },
  {
    "text": "cause the SDKs the doors libraries so those Vipers they simply implement the tracing API and then then they do",
    "start": "463300",
    "end": "469300"
  },
  {
    "text": "something with that data in case of if you take Jaeger client as an SDK what it",
    "start": "469300",
    "end": "474789"
  },
  {
    "text": "will do it will kind of buffer that data for a while and then package it convert it into thrift format and send it out of",
    "start": "474789",
    "end": "481779"
  },
  {
    "text": "process to either a guru to some of the tracing back and collection mechanisms",
    "start": "481779",
    "end": "487689"
  },
  {
    "text": "which we'll talk about there several of them and Jager and then finally as the",
    "start": "487689",
    "end": "493209"
  },
  {
    "text": "request goes further and then your micro service one makes a call to micro service to the last trace point does",
    "start": "493209",
    "end": "499179"
  },
  {
    "text": "something special it takes that in memory context they request idea whatever that we kept passing around and",
    "start": "499179",
    "end": "505389"
  },
  {
    "text": "encoded on the wire so that it has a separate representation on the wire and so that the next micro service can also",
    "start": "505389",
    "end": "512018"
  },
  {
    "text": "like starts engine date because your next micro service maybe Ryan and the different processes on different data",
    "start": "512019",
    "end": "517300"
  },
  {
    "text": "center but it will be able to correlate its events or its trace trace events",
    "start": "517300",
    "end": "522339"
  },
  {
    "text": "with the micro series one and then as they all call this and do the tracing back and eventually",
    "start": "522339",
    "end": "528960"
  },
  {
    "text": "we'll be able to reconstruct that whole request execution and so what collection here is like the blue box collection and",
    "start": "528960",
    "end": "535649"
  },
  {
    "text": "normalization because you can have events captured with different instrumentation like instrumentation the",
    "start": "535649",
    "end": "541200"
  },
  {
    "text": "walls over time sometimes formats change etc you may have one application instrumented with zipped in another",
    "start": "541200",
    "end": "546959"
  },
  {
    "text": "instrumental to the aggressor instrumental open telemetry it's actually not that hard to make them all understand each other and they may all",
    "start": "546959",
    "end": "553170"
  },
  {
    "text": "sound different data models out of the box but then collection back-end will",
    "start": "553170",
    "end": "558540"
  },
  {
    "text": "sort of normalize those into one single model that j채ger back and understands and it then it will get stored to the",
    "start": "558540",
    "end": "563610"
  },
  {
    "text": "database and from the database from the storage we have two paths on the right",
    "start": "563610",
    "end": "569850"
  },
  {
    "text": "here's like one will we basically hold the trace in events I've written with a single trace ID as a key and so you can",
    "start": "569850",
    "end": "576690"
  },
  {
    "text": "retrieve them all as a single blow up and then visualize them or do whatever you want like data mind them so that",
    "start": "576690",
    "end": "582540"
  },
  {
    "text": "that's conceptually how tracing works now to sort of clarify probably some",
    "start": "582540",
    "end": "590820"
  },
  {
    "start": "587000",
    "end": "587000"
  },
  {
    "text": "confusion about Jaeger open tracing and open telemeter not only between projects but between the technologies themselves",
    "start": "590820",
    "end": "596520"
  },
  {
    "text": "so as I was talking through that previous picture I mentioned there's a trace in API and the tracing SDK tracing",
    "start": "596520",
    "end": "603330"
  },
  {
    "text": "implementation right so open tracing is that tracing API if you if you do",
    "start": "603330",
    "end": "608430"
  },
  {
    "text": "something in your application and you make calls to trade to open tracing API nothing is going to happen right it's an",
    "start": "608430",
    "end": "615180"
  },
  {
    "text": "oval basically unless you actually plug in some SDK with it and Jaeger is that",
    "start": "615180",
    "end": "620610"
  },
  {
    "text": "SDK or you can plug in any other SDK vendor SDK even custom blender and and",
    "start": "620610",
    "end": "626700"
  },
  {
    "text": "so at the top there Malik Powell told me that it's a bit confusion but what this really shows is that it's conceptually",
    "start": "626700",
    "end": "633240"
  },
  {
    "text": "your application can be instrumented in three different ways on the Left we see is what what's called manually",
    "start": "633240",
    "end": "639510"
  },
  {
    "text": "instrumented application was basically let's say you're not using any framework you probably write in and see you know",
    "start": "639510",
    "end": "644640"
  },
  {
    "text": "and and so like all the network calls all the inter process communication that",
    "start": "644640",
    "end": "649770"
  },
  {
    "text": "you do and you need to manually go and instrument and you add the open tracing code to that right send you start the",
    "start": "649770",
    "end": "655320"
  },
  {
    "text": "span manually before call finishes planned afterwards typically no one does that because it's just like everyone",
    "start": "655320",
    "end": "661380"
  },
  {
    "text": "uses some frameworks it and so with frameworks it gets a lot easier because then the instrumentation",
    "start": "661380",
    "end": "667920"
  },
  {
    "text": "really needs to exist in the frameworks rather than in the application so if you have an HTTP framework and you making a",
    "start": "667920",
    "end": "674190"
  },
  {
    "text": "call send like get something then most likely you don't need to do anything in your business code which is tracing",
    "start": "674190",
    "end": "680160"
  },
  {
    "text": "related because the framework itself will have some middleware implemented so that the get request is actually will",
    "start": "680160",
    "end": "685980"
  },
  {
    "text": "start a span finish a span collect the timing information and all of that and and finally on the on the right the",
    "start": "685980",
    "end": "692850"
  },
  {
    "text": "third option is if you can pull that off it's like the easiest way to adopt in a",
    "start": "692850",
    "end": "698370"
  },
  {
    "text": "large organization where people sometimes use auto instrumentation where with the middle box so even though the",
    "start": "698370",
    "end": "706140"
  },
  {
    "text": "framework itself is like instrumented but the way the instrumentation is typically done for those frameworks is",
    "start": "706140",
    "end": "712680"
  },
  {
    "text": "is you still need to need to do some minimal configuration right so if you read any open tracing tutorials they",
    "start": "712680",
    "end": "719280"
  },
  {
    "text": "will start to a cable first instantiate the tracer then use this HTTP framework",
    "start": "719280",
    "end": "725100"
  },
  {
    "text": "create the middleware for it pass the tracer to the middleware a middle word and will attach the HTTP framework and",
    "start": "725100",
    "end": "730830"
  },
  {
    "text": "start doing its thing right so the minimal step that your application still needs to do is create a tracer and pass",
    "start": "730830",
    "end": "736080"
  },
  {
    "text": "it to some other frameworks right would be nice if you didn't have to do that because you can just and deploy a",
    "start": "736080",
    "end": "742500"
  },
  {
    "text": "tracing without touching any of the application code and that's what what instrumentation does historically like",
    "start": "742500",
    "end": "748860"
  },
  {
    "text": "big long-standing vendors like New Relic AppDynamics they provided those what",
    "start": "748860",
    "end": "754020"
  },
  {
    "text": "instrumentation is the case where you just maybe if you enjoy world you attach a jar to your runtime and suddenly it",
    "start": "754020",
    "end": "760290"
  },
  {
    "text": "goes and rewrites byte code in your application and and provides this kind of instrumentation we have a tuple we're",
    "start": "760290",
    "end": "767250"
  },
  {
    "text": "using one library in Python that does that and kind of all my experiences of",
    "start": "767250",
    "end": "774180"
  },
  {
    "text": "actually distributing instrumentation to services that was the easiest one because we made a change",
    "start": "774180",
    "end": "779730"
  },
  {
    "text": "once in one place and every service in Python got the tracing automatically whereas with other languages especially",
    "start": "779730",
    "end": "786270"
  },
  {
    "text": "with go some someone needs to do something manual so that those are very early in my mic ultimately all",
    "start": "786270",
    "end": "796560"
  },
  {
    "text": "three types of instrumentation they just talk to trace in API and then that case it could be open tracing API right and",
    "start": "796560",
    "end": "802470"
  },
  {
    "text": "then the rest is like you have an iteration implementation which implements the tapir and then collects",
    "start": "802470",
    "end": "807720"
  },
  {
    "text": "data and sends it to the backend finally on on the right here you can see",
    "start": "807720",
    "end": "813110"
  },
  {
    "text": "like open trace an icon and then two boxes open trace in country but the api",
    "start": "813110",
    "end": "818309"
  },
  {
    "text": "so the api is the actual product of open tracing the libraries that you can use and then there is a separate",
    "start": "818309",
    "end": "823620"
  },
  {
    "text": "organization called country which was created specifically to to create those shared middleware instrumentations that",
    "start": "823620",
    "end": "829980"
  },
  {
    "text": "you can use with popular frameworks like if you use in spring or a jungle in python you don't have to keep rewriting",
    "start": "829980",
    "end": "835800"
  },
  {
    "text": "everyone the same instrumentation because it's identical everywhere we can just write it once as an open-source",
    "start": "835800",
    "end": "842069"
  },
  {
    "text": "project and then because the only thing that project is exposed is open tracing api you can unplug any vendor any",
    "start": "842069",
    "end": "848819"
  },
  {
    "text": "tracing is decay afterwards and it will work so that was the story last year and",
    "start": "848819",
    "end": "854879"
  },
  {
    "text": "now we have open telemetry that you've probably heard a lot and open till poetry you can think of it as the next",
    "start": "854879",
    "end": "860639"
  },
  {
    "text": "iteration of open tracing it also is a merger with another project open census",
    "start": "860639",
    "end": "866309"
  },
  {
    "text": "which was kind of competing with open trace in which was very unfortunate because no one actually wanted that competition we want the standard way for",
    "start": "866309",
    "end": "872730"
  },
  {
    "text": "everyone to instrument rather than everyone have to decide which way to go and so open telemetry in that sense is",
    "start": "872730",
    "end": "879000"
  },
  {
    "text": "very similar to open tracing it has a part which is an API only right and you can implement that API 1200",
    "start": "879000",
    "end": "887689"
  },
  {
    "text": "you can use an SDK which comes by default with open telemetry",
    "start": "887689",
    "end": "894920"
  },
  {
    "text": "okay thank you oh oh please go better so one difference between telemetry and",
    "start": "901329",
    "end": "909559"
  },
  {
    "text": "open traces that open slam it does count with an SDK right so you don't need the Jaeger client anymore you can just use",
    "start": "909559",
    "end": "916069"
  },
  {
    "text": "standard SDK across or board and all the others are sort of like join forces to",
    "start": "916069",
    "end": "921649"
  },
  {
    "text": "do one single thing and it will work everyone so everything else aside from that is this kind of the same you-you-you",
    "start": "921649",
    "end": "929359"
  },
  {
    "text": "instrument the code or you use auto instrumentation which will talk to that API and then it will send data through",
    "start": "929359",
    "end": "934519"
  },
  {
    "text": "the SDK now another thing that so right",
    "start": "934519",
    "end": "943160"
  },
  {
    "text": "so my mic is not hello so the sampling",
    "start": "943160",
    "end": "948169"
  },
  {
    "text": "is it's a way how you can control how much data or how much traces are stored",
    "start": "948169",
    "end": "953480"
  },
  {
    "text": "in your thoracic system because if you end up you know tracing all the request",
    "start": "953480",
    "end": "958639"
  },
  {
    "text": "is just too much data to store so we have to have a way how to control that",
    "start": "958639",
    "end": "963669"
  },
  {
    "text": "so Jager by default does head base and blink or upfront tracing which is the",
    "start": "963669",
    "end": "970160"
  },
  {
    "start": "965000",
    "end": "965000"
  },
  {
    "text": "way when we start the trace we decide whether the trace should be stored or not we there are multiple ways how you",
    "start": "970160",
    "end": "976999"
  },
  {
    "text": "can decide it if the trace should be traced or not there are like for example",
    "start": "976999",
    "end": "982790"
  },
  {
    "text": "there is a probabilistic sample which says I want to store only 1% of all",
    "start": "982790",
    "end": "988160"
  },
  {
    "text": "traces then there is rate limiting will you say I want to store only I know 10",
    "start": "988160",
    "end": "993529"
  },
  {
    "text": "traces pair 1 second this is all per",
    "start": "993529",
    "end": "999439"
  },
  {
    "text": "service so you can configure it in the service but sometimes the service has multiple endpoints and these endpoints",
    "start": "999439",
    "end": "1005470"
  },
  {
    "text": "have a different traffic patterns so endpoint a may receive I know 1,000",
    "start": "1005470",
    "end": "1011559"
  },
  {
    "text": "requests and even B receives two requests what happens if you use",
    "start": "1011559",
    "end": "1017019"
  },
  {
    "text": "probabilistic sampler is that endpoint you will get only you know very small",
    "start": "1017019",
    "end": "1022289"
  },
  {
    "text": "traces stored for the ten point so we have a way how you can overcome this",
    "start": "1022289",
    "end": "1029079"
  },
  {
    "text": "problem by using endpoint level sampling within the service so you say for exam",
    "start": "1029079",
    "end": "1034120"
  },
  {
    "text": "and pee which receive is a lot of traffic will sample a 10% and and B",
    "start": "1034120",
    "end": "1040659"
  },
  {
    "text": "which is receives only you know fraction of that will receive I don't know 50% of 50% of the traffic will be sampled this",
    "start": "1040659",
    "end": "1049539"
  },
  {
    "text": "can be also controlled on the Jaeger server so you don't have to go to the",
    "start": "1049539",
    "end": "1054970"
  },
  {
    "text": "clients and change the configuration you just change it in the in the deployment of the separate server on the road map",
    "start": "1054970",
    "end": "1062380"
  },
  {
    "text": "we have also two new samplers coming in there will be a tag matching sampler",
    "start": "1062380",
    "end": "1069370"
  },
  {
    "text": "which basically means that when you are",
    "start": "1069370",
    "end": "1075510"
  },
  {
    "text": "okay I can continue i was working before",
    "start": "1087090",
    "end": "1095799"
  },
  {
    "text": "if i speak like this might work so one one thing i want to mention about",
    "start": "1095799",
    "end": "1102039"
  },
  {
    "text": "the reason why we do sampling in the first place is it's not just because it's too much data but because it's too",
    "start": "1102039",
    "end": "1108429"
  },
  {
    "text": "much repetitive on useless data right if because really if if you think what you",
    "start": "1108429",
    "end": "1114880"
  },
  {
    "text": "use tracing for you're not using it for monitoring every single request what you typically use it is for troubleshooting",
    "start": "1114880",
    "end": "1121270"
  },
  {
    "text": "problems it's an observability tools not a monitoring tool per se and when you",
    "start": "1121270",
    "end": "1127000"
  },
  {
    "text": "troubleshoot you actually want to capture requests which have problems but hopefully in your production 99% the",
    "start": "1127000",
    "end": "1133149"
  },
  {
    "text": "requests don't have problems right and so if you use probabilistic sampling then you're gonna capture 99% of all",
    "start": "1133149",
    "end": "1139149"
  },
  {
    "text": "your requests that you capture will be okay they're they're fine they're all the same they're all successful there's no reason actually to capture them that",
    "start": "1139149",
    "end": "1145570"
  },
  {
    "text": "menu right you might capture like ten of them you know that you just establish the overall flow but and so that that's",
    "start": "1145570",
    "end": "1153220"
  },
  {
    "text": "per head by sampling really he struggles with that because it makes the decision very at the beginning of the request has",
    "start": "1153220",
    "end": "1159309"
  },
  {
    "text": "no information about how the trace will look like afterwards right and that decision is propagated through so that",
    "start": "1159309",
    "end": "1164380"
  },
  {
    "text": "it's consistent at least because we don't want to capture like once here but none of the other ones right",
    "start": "1164380",
    "end": "1169680"
  },
  {
    "text": "and that's why the the other type of something that we were working on is a",
    "start": "1169680",
    "end": "1175480"
  },
  {
    "text": "tale based sampling which rather than like a sampling at the beginning and it",
    "start": "1175480",
    "end": "1181930"
  },
  {
    "text": "kind of actually gathers the data anyway but does it store it on disk because it's expensive it just stores it in",
    "start": "1181930",
    "end": "1187750"
  },
  {
    "text": "memory temporarily like most traces you own the last couple seconds so you don't need a lot of memory to keep all of that",
    "start": "1187750",
    "end": "1193000"
  },
  {
    "text": "right you can discard all those things within a few seconds but then once you collect all the spans for a given trace",
    "start": "1193000",
    "end": "1199090"
  },
  {
    "text": "then you can actually run some basic analysis and say oh I see error codes come in and this like or I see a usual",
    "start": "1199090",
    "end": "1205300"
  },
  {
    "text": "latencies I want to capture that and you make like involve different kind of rules of how you to sample that and so",
    "start": "1205300",
    "end": "1212170"
  },
  {
    "text": "that part is kind of not not too difficult but there is lots of infrastructure work involved to make",
    "start": "1212170",
    "end": "1217870"
  },
  {
    "text": "this work so I we actually working on rolling this out at uber so I'm hoping",
    "start": "1217870",
    "end": "1223990"
  },
  {
    "text": "that it will show up next year in j채ger open source and the tag matching that Pavel was starting to say that's still",
    "start": "1223990",
    "end": "1230620"
  },
  {
    "text": "an upfront sampling approach but it's it allows us to control to allow like users",
    "start": "1230620",
    "end": "1237940"
  },
  {
    "text": "to change sampling based on specific patterns that they see so as the name",
    "start": "1237940",
    "end": "1243970"
  },
  {
    "text": "implies you you essentially you you push a configuration to the client saying if you if if the span contains the stack",
    "start": "1243970",
    "end": "1250270"
  },
  {
    "text": "with this value then sample that's right or sample that was like a different strategy very high probability and so",
    "start": "1250270",
    "end": "1256360"
  },
  {
    "text": "that's it's very experimental right now we we've implemented that over we haven't rolled it out in production but",
    "start": "1256360",
    "end": "1262990"
  },
  {
    "text": "there is one team that's really interested in using us so I'm curious how that will turn out we would this thing but yeah but it's available at",
    "start": "1262990",
    "end": "1270520"
  },
  {
    "text": "least and ojs and go clients so far okay so you want to talk about integration",
    "start": "1270520",
    "end": "1276070"
  },
  {
    "text": "right yeah so we know okay so in",
    "start": "1276070",
    "end": "1287399"
  },
  {
    "start": "1280000",
    "end": "1280000"
  },
  {
    "text": "so regarding cnc of projects we integrate with kubernetes of course we",
    "start": "1293590",
    "end": "1301210"
  },
  {
    "text": "want to make it very easy to deploy a grown kubernetes at the moment there is ZERO operator there is the traditional",
    "start": "1301210",
    "end": "1308360"
  },
  {
    "text": "manifest and there is also the helm chart you can of course choose one of",
    "start": "1308360",
    "end": "1314630"
  },
  {
    "text": "these which you know you want to use which based on your requirements",
    "start": "1314630",
    "end": "1320630"
  },
  {
    "text": "basically what does that Prater provide over manifest the operator well it's not only",
    "start": "1320630",
    "end": "1325820"
  },
  {
    "text": "about deploying the Jaeger but it's also about managing the deployment so operator will deploy the Jaeger but then",
    "start": "1325820",
    "end": "1332750"
  },
  {
    "text": "you can also handle the updates the monitoring and so on so it's more advanced you don't have to understand",
    "start": "1332750",
    "end": "1339140"
  },
  {
    "text": "how to do how to deploy a Jaeger to use the operator you just define I want to use this storage I want to use this",
    "start": "1339140",
    "end": "1345770"
  },
  {
    "text": "configuration and operator will handle all of the deployment for you but also the upgrades if there is a new version",
    "start": "1345770",
    "end": "1351740"
  },
  {
    "text": "of Jaeger so by default Jaeger exposes matrix in",
    "start": "1351740",
    "end": "1358520"
  },
  {
    "text": "primitives format so for example eager operator you know watches this matrix if there is",
    "start": "1358520",
    "end": "1364610"
  },
  {
    "text": "something wrong it can you know change the deployment accordingly the open",
    "start": "1364610",
    "end": "1370250"
  },
  {
    "text": "telemetry already ships with Jaeger exporters and Jaeger receiver in the collector so we use and linker D already",
    "start": "1370250",
    "end": "1382610"
  },
  {
    "text": "comes with Jaeger as a default Tracy boy",
    "start": "1382610",
    "end": "1389200"
  },
  {
    "text": "uses Jaeger native client native C++ client although you can still use can",
    "start": "1389200",
    "end": "1401240"
  },
  {
    "text": "receive different races",
    "start": "1401240",
    "end": "1404590"
  },
  {
    "text": "so I guess we didn't mention Kafka but",
    "start": "1409520",
    "end": "1417380"
  },
  {
    "start": "1410000",
    "end": "1410000"
  },
  {
    "text": "Jaeger is overall implemented with a push architecture unlike premises which you just pull for",
    "start": "1417380",
    "end": "1424320"
  },
  {
    "text": "for the metrics I mean there the problem comes to either one of them so like for",
    "start": "1424320",
    "end": "1429420"
  },
  {
    "text": "us push architecture was easier because especially the applications need to know",
    "start": "1429420",
    "end": "1435000"
  },
  {
    "text": "very little about how to locate the Jaeger components in order to talk to them right and the classic architecture",
    "start": "1435000",
    "end": "1441030"
  },
  {
    "text": "what what was originally rolled out at uber had eager client in every",
    "start": "1441030",
    "end": "1447630"
  },
  {
    "text": "application sending data over UDP port to to log to agent running on a local host right",
    "start": "1447630",
    "end": "1453540"
  },
  {
    "text": "you could also run agent as a sidecar it depends on your channels requirements at uber it was easy for us to just run at",
    "start": "1453540",
    "end": "1460140"
  },
  {
    "text": "one single agent per host because we don't have like channels requirements and then the agent then takes care of",
    "start": "1460140",
    "end": "1466610"
  },
  {
    "text": "location where the rest of the j채ger back and this communication to it and and you know and passing the data",
    "start": "1466610",
    "end": "1472470"
  },
  {
    "text": "through and also the control flow that we mentioned the sampling strategies you",
    "start": "1472470",
    "end": "1477780"
  },
  {
    "text": "can configure them on the Jager back-end and they make they become available to the Jager clients at runtime so that's",
    "start": "1477780",
    "end": "1484559"
  },
  {
    "text": "done with the thread feedback loop it I think that only works if you use the",
    "start": "1484559",
    "end": "1490169"
  },
  {
    "text": "agent you cannot use if you talk directly to collector and then on the right side collectors were just like",
    "start": "1490169",
    "end": "1497250"
  },
  {
    "text": "they were completely stateless ant and they were essentially passed through they would get tracing date and write it",
    "start": "1497250",
    "end": "1502799"
  },
  {
    "text": "to the database as well and I think we have a next slide for it so yeah so the challenges with that synchronous or",
    "start": "1502799",
    "end": "1511200"
  },
  {
    "start": "1507000",
    "end": "1507000"
  },
  {
    "text": "asynchronous push approach was that if you have a traffic spike in your application or maybe some application",
    "start": "1511200",
    "end": "1517740"
  },
  {
    "text": "rolled out with the configuration of j채ger client with like hundred percent sampling and suddenly starts flooding",
    "start": "1517740",
    "end": "1522900"
  },
  {
    "text": "your back-end there's very little that Jaeger back-end could actually do to protect itself with that that's kind of",
    "start": "1522900",
    "end": "1528240"
  },
  {
    "text": "the downside of the push model and the only thing it could do is just start",
    "start": "1528240",
    "end": "1533340"
  },
  {
    "text": "dropping data but because collectors are stateless there is no partitioning by trace ID you you kind of say in raga I'm",
    "start": "1533340",
    "end": "1539250"
  },
  {
    "text": "going to drop like it percent of my spans regardless of which trace they belong to which means you the",
    "start": "1539250",
    "end": "1544440"
  },
  {
    "text": "traces that actually do get through into the database the hell they have gaps in them host which isn't great and so what",
    "start": "1544440",
    "end": "1551940"
  },
  {
    "text": "we've done is should maybe do this slide instead first what we introduced as the",
    "start": "1551940",
    "end": "1559800"
  },
  {
    "start": "1556000",
    "end": "1556000"
  },
  {
    "text": "Kafka in the middle it supported an open-source version of Jaeger and so in",
    "start": "1559800",
    "end": "1565860"
  },
  {
    "text": "which case the push model still remains but once the data hits collector it just writes data to Kafka and that provided a",
    "start": "1565860",
    "end": "1573690"
  },
  {
    "text": "couple of benefits one is cough Queens usually a lot more elastic than storage like Cassandra or elasticsearch because",
    "start": "1573690",
    "end": "1579960"
  },
  {
    "text": "those actually like I mean they have a schema they do the indexing so every right to those storage backends is way",
    "start": "1579960",
    "end": "1587070"
  },
  {
    "text": "more expensive than the simple bite rights to Kafka right and so that means",
    "start": "1587070",
    "end": "1593460"
  },
  {
    "text": "that even if there is a traffic spike on from the applications then collectors I still able to keep up with that traffic",
    "start": "1593460",
    "end": "1599610"
  },
  {
    "text": "and actually successfully write it to Kafka of course you can have a spike to size degree that your Kafka blows up but",
    "start": "1599610",
    "end": "1605130"
  },
  {
    "text": "the usually wouldn't reach those points and and Kafka tuber is like super large",
    "start": "1605130",
    "end": "1610410"
  },
  {
    "text": "so we're a tiny drop in that and and then we have another component called",
    "start": "1610410",
    "end": "1616410"
  },
  {
    "text": "Jaeger in gesture that reads from Kafka and stores data database it can be deployed in two modes one is just as a",
    "start": "1616410",
    "end": "1622290"
  },
  {
    "text": "single thing or you can split it and twin gesture in indexer for example the two where we actually split those",
    "start": "1622290",
    "end": "1627720"
  },
  {
    "text": "database into two clusters so that one cluster stores just the traces that you can retrieve by trace ID and another",
    "start": "1627720",
    "end": "1633480"
  },
  {
    "text": "cluster stores indexes for those traces that and that indexing can lag behind if",
    "start": "1633480",
    "end": "1638610"
  },
  {
    "text": "we want you oh if it happens to be we don't really care that much and the second bit is that we we started",
    "start": "1638610",
    "end": "1648750"
  },
  {
    "text": "building the data pipeline on top of that specifically with streaming fleeing jobs so the previous diagram showed that",
    "start": "1648750",
    "end": "1657540"
  },
  {
    "text": "we had a spark job that that's the current that it's available on open source it's a bad job it reads",
    "start": "1657540",
    "end": "1663360"
  },
  {
    "text": "essentially all of the database for a certain time window and and aggregates",
    "start": "1663360",
    "end": "1670560"
  },
  {
    "text": "data and creates and write it back to there but that's like expensive as specially when you have a lot of data than to read the whole thing in this",
    "start": "1670560",
    "end": "1676770"
  },
  {
    "text": "park is pretty expensive so it can timeout and you have all kinds of performance issues that whereas freeing",
    "start": "1676770",
    "end": "1682380"
  },
  {
    "text": "streaming is just does it all the time and flashes data periodically and plus I mean that's more specific to do over but",
    "start": "1682380",
    "end": "1689250"
  },
  {
    "text": "we also have a standard framework for anything that's in Kafka can be saved to HDFS so that we can query it with a",
    "start": "1689250",
    "end": "1695910"
  },
  {
    "text": "MapReduce job so the second extra bonus for us at uber it's probably easy to set up everywhere else so I want to talk",
    "start": "1695910",
    "end": "1704100"
  },
  {
    "text": "about dipping if you might want to hold",
    "start": "1704100",
    "end": "1709679"
  },
  {
    "text": "it so Yaeger can can receive data in",
    "start": "1709679",
    "end": "1716340"
  },
  {
    "start": "1712000",
    "end": "1712000"
  },
  {
    "text": "format so you can just you know redirect all the data from the king clients to",
    "start": "1716340",
    "end": "1722850"
  },
  {
    "text": "Jager collector so we could you can receive the trip to brought above and the JSON in words into format but then",
    "start": "1722850",
    "end": "1731490"
  },
  {
    "text": "also you can configure eager clients to understand zipping context propagation format so once this can be instrumented",
    "start": "1731490",
    "end": "1738330"
  },
  {
    "text": "with open tracing and Jager and other with zip in and they can still continue the same trace there is also integration",
    "start": "1738330",
    "end": "1746340"
  },
  {
    "text": "with Kafka which pretty much just uses the uses it gets the Zipkin Zipkin",
    "start": "1746340",
    "end": "1753450"
  },
  {
    "text": "format from Kafka and stores it in the rest our storage right okay so new",
    "start": "1753450",
    "end": "1761250"
  },
  {
    "text": "features since basically last cube con in Seattle there is new Jager operator",
    "start": "1761250",
    "end": "1769100"
  },
  {
    "start": "1766000",
    "end": "1766000"
  },
  {
    "text": "we pretty much it it exposes all the",
    "start": "1769100",
    "end": "1774600"
  },
  {
    "text": "configuration what we have in the Jager itself so it's you can do basically everything with it there is new local",
    "start": "1774600",
    "end": "1781919"
  },
  {
    "text": "storage Basin badger so this is something like Prometheus where you have no Oriole data and Jager",
    "start": "1781919",
    "end": "1789240"
  },
  {
    "text": "in a single pot and we also publish the storage plugin",
    "start": "1789240",
    "end": "1796169"
  },
  {
    "text": "based on G RPC at the moment there are two available implementation one for",
    "start": "1796169",
    "end": "1801419"
  },
  {
    "text": "couch B Couchbase and honorable influx DB yesterday we talked about",
    "start": "1801419",
    "end": "1807680"
  },
  {
    "text": "visualisations where you can compare to traces this is delayed sampling we talk",
    "start": "1807680",
    "end": "1817400"
  },
  {
    "text": "about the same plane it is basically that tech based sampling it's not fully",
    "start": "1817400",
    "end": "1823250"
  },
  {
    "text": "open source right but it's something we are working on it will be soon we made a",
    "start": "1823250",
    "end": "1828380"
  },
  {
    "text": "lot of improvements on the security side of the things so you can use TLS with GRP see between Jaeger agent and the",
    "start": "1828380",
    "end": "1834350"
  },
  {
    "text": "collector but also even configure tails TLS between all the storages this is",
    "start": "1834350",
    "end": "1842990"
  },
  {
    "start": "1842000",
    "end": "1842000"
  },
  {
    "text": "basically the diagram for the ERP C storage plugin it's very a lot of people",
    "start": "1842990",
    "end": "1848900"
  },
  {
    "text": "aspirate because we don't want to maintain all the storage layers in the main repository and with this you can",
    "start": "1848900",
    "end": "1856910"
  },
  {
    "text": "basically have the code base somewhere else but still use it with the upstream Jaeger okay this is you want to go back",
    "start": "1856910",
    "end": "1870740"
  },
  {
    "text": "so this is something that we didn't mention yet this is still work in progress there's actually a bug in the",
    "start": "1870740",
    "end": "1877550"
  },
  {
    "text": "last release so that's why I didn't want to show it really a live version but it",
    "start": "1877550",
    "end": "1883730"
  },
  {
    "text": "will get fixed it's an easy bug so what we've been working on is service graphs",
    "start": "1883730",
    "end": "1889370"
  },
  {
    "start": "1884000",
    "end": "1884000"
  },
  {
    "text": "we talked about series graph yesterday but traditionally those service graphs are based on just a single hop",
    "start": "1889370",
    "end": "1896330"
  },
  {
    "text": "relationship between services right which means that you you can reason",
    "start": "1896330",
    "end": "1901400"
  },
  {
    "text": "about what your immediate dependences are for service but not beyond that you cannot for example see like if if your",
    "start": "1901400",
    "end": "1908210"
  },
  {
    "text": "dependencies depend on something else and then depend on something else can you tell whether you depend on something also not especially if you trying to",
    "start": "1908210",
    "end": "1914510"
  },
  {
    "text": "figure out your SLI so things like that you can't really from the single hub diagram so all you know is that you",
    "start": "1914510",
    "end": "1919610"
  },
  {
    "text": "depend on that guy maybe it just replies with the characters out all the time right so we we started working on what",
    "start": "1919610",
    "end": "1926300"
  },
  {
    "text": "we call like deep dependency diagram so transitive diagrams where the the diagram is built on the full path that",
    "start": "1926300",
    "end": "1933140"
  },
  {
    "text": "we observed in the traces and then when you look at it in the integral form you can actually",
    "start": "1933140",
    "end": "1938760"
  },
  {
    "text": "use like mouse overs and and seed all the paths going through their services and in this example like it to to build",
    "start": "1938760",
    "end": "1946530"
  },
  {
    "text": "that diagram for the full arc each actually requires some data mining jobs",
    "start": "1946530",
    "end": "1952020"
  },
  {
    "text": "which is not available open source yet but the de visualization is available and open source for the search results",
    "start": "1952020",
    "end": "1958590"
  },
  {
    "text": "because search results is like a small subset of data which we can already run through that framework and so you can",
    "start": "1958590",
    "end": "1964140"
  },
  {
    "text": "see here that you can see on screen for",
    "start": "1964140",
    "end": "1969960"
  },
  {
    "text": "some reason anyway there's supposed to be a button right here in the top right corner say and like show show is graph",
    "start": "1969960",
    "end": "1976559"
  },
  {
    "text": "and when you do that it looks like this so again it's it's it looks very much like a regular service",
    "start": "1976559",
    "end": "1982799"
  },
  {
    "text": "dependency diagram but the the connections are life and they're sort of sensitive to where the weather you are",
    "start": "1982799",
    "end": "1989549"
  },
  {
    "text": "and you can focus this diagram to on any service so it's actually oriented to",
    "start": "1989549",
    "end": "1995669"
  },
  {
    "text": "specific service right so it only shows all the path that comes with a service shown in red not the rest of the work is",
    "start": "1995669",
    "end": "2003110"
  },
  {
    "text": "actually so that that mode is like very useful when you're trying to investigate accurate dependencies or we had",
    "start": "2003110",
    "end": "2009580"
  },
  {
    "text": "sometimes scenarios at uber where people were trying to move services between data centers and where they couldn't",
    "start": "2009580",
    "end": "2015710"
  },
  {
    "text": "figure out what the real dependencies are because no one really knows in production ok so yeah also about this",
    "start": "2015710",
    "end": "2028480"
  },
  {
    "text": "this graph we we have a version when you don't require which doesn't require any",
    "start": "2028480",
    "end": "2035030"
  },
  {
    "text": "abrogation job so basically when you load the traces in this screen view is",
    "start": "2035030",
    "end": "2040760"
  },
  {
    "text": "this data and calculate the graph in the UI so you don't have to run any sparkles",
    "start": "2040760",
    "end": "2047620"
  },
  {
    "text": "on the roadmap we are trying to make it easy for data scientist or anybody who",
    "start": "2048190",
    "end": "2055460"
  },
  {
    "start": "2049000",
    "end": "2049000"
  },
  {
    "text": "wants to play with traces to to basically get them analyze them and try",
    "start": "2055460",
    "end": "2062628"
  },
  {
    "text": "to you know find interesting information about what happened so there are two",
    "start": "2062629",
    "end": "2068990"
  },
  {
    "text": "parts we want to create a DSL trace DSL which makes it very easy to extract features from trace data",
    "start": "2068990",
    "end": "2075550"
  },
  {
    "text": "and also provide Jupiter notebooks so you can very easily deploy it and go",
    "start": "2075550",
    "end": "2081350"
  },
  {
    "text": "play with it basically so at the moment we have some version for Java which uses",
    "start": "2081350",
    "end": "2087950"
  },
  {
    "text": "gremlin and you know extends gremlin and that's some very handful methods you",
    "start": "2087950",
    "end": "2096230"
  },
  {
    "text": "know to navigate within the trace and also to query data between the trace",
    "start": "2096230",
    "end": "2101740"
  },
  {
    "text": "maybe I want to add the reason for this work is it's a continuation of our data",
    "start": "2101740",
    "end": "2108380"
  },
  {
    "text": "pipeline work and the reason why we wanted to do this this way with a sort",
    "start": "2108380",
    "end": "2113990"
  },
  {
    "text": "of like a generic DSL is really because tracing data is very rich and it's hard",
    "start": "2113990",
    "end": "2121580"
  },
  {
    "text": "to build tools that automatically extract all that rich information and presented in some way especially because",
    "start": "2121580",
    "end": "2127220"
  },
  {
    "text": "the use cases for which people want to use the tracing data often very different right",
    "start": "2127220",
    "end": "2132710"
  },
  {
    "text": "and so Jaeger has some visualizations today that might be useful in some cases but they're not utilizing like the full",
    "start": "2132710",
    "end": "2140870"
  },
  {
    "text": "power of the tracing data that's it's a new database and also querying for the database from the database directly is",
    "start": "2140870",
    "end": "2147500"
  },
  {
    "text": "is actually difficult because there are some questions that you may want to ask that cannot be answered by regular",
    "start": "2147500",
    "end": "2154880"
  },
  {
    "text": "whether it's a column or regular relational database it's you can just express those those questions for",
    "start": "2154880",
    "end": "2161300"
  },
  {
    "text": "example if if your question is I know I want you to know something about like a",
    "start": "2161300",
    "end": "2167930"
  },
  {
    "text": "trace which contains series a colon series because ER and C right it's it's a graph question essentially but if",
    "start": "2167930",
    "end": "2174370"
  },
  {
    "text": "typical Trey simply trace storage is implemented either as a key value store or the relational database so with",
    "start": "2174370",
    "end": "2181010"
  },
  {
    "text": "relational when you store one span at a time that's like you asking a question about three records essentially in their",
    "start": "2181010",
    "end": "2186920"
  },
  {
    "text": "relationship so you potentially can express it with like nested joins but it gets really really ugly and that's why we wanted to",
    "start": "2186920",
    "end": "2193880"
  },
  {
    "text": "to shift towards more like a graph ways DSL I Kremlin where you get the whole",
    "start": "2193880",
    "end": "2200210"
  },
  {
    "text": "trace in memory and you can do anything you want with it you can ask any kind of questions extract any metric from it metric me and like",
    "start": "2200210",
    "end": "2206989"
  },
  {
    "text": "you calculate something some feature about this for example how much this particular service call what percentage",
    "start": "2206989",
    "end": "2212900"
  },
  {
    "text": "of the services on a critical path right and and then the reason we want to do",
    "start": "2212900",
    "end": "2218720"
  },
  {
    "text": "tribute a dog book is because developing those kind of programs that extract features that's pretty advanced use",
    "start": "2218720",
    "end": "2225410"
  },
  {
    "text": "usage of tracing but without having that framework or that capability in place it's pretty difficult to do otherwise",
    "start": "2225410",
    "end": "2232400"
  },
  {
    "text": "like I said SQL join like joins us very hard to write for this data big Map Reduce George's like difficult",
    "start": "2232400",
    "end": "2239839"
  },
  {
    "text": "so Facebook had this implementation actually in their internal system which was very successful where you can start",
    "start": "2239839",
    "end": "2246049"
  },
  {
    "text": "with a notebook you can potentially write your query or your feature extraction code over small data set",
    "start": "2246049",
    "end": "2252619"
  },
  {
    "text": "which you can iterate and run quickly and then you got a very good signal from it hopefully and then you just take that",
    "start": "2252619",
    "end": "2258019"
  },
  {
    "text": "same thing and you run it against a large volume of data or maybe you put it in production and versus streaming data",
    "start": "2258019",
    "end": "2263809"
  },
  {
    "text": "right and so this is kind of where we want to go because it's of course it's a power user tool I don't expect like",
    "start": "2263809",
    "end": "2270710"
  },
  {
    "text": "regular engineers necessarily go in there but if you have a dedicated performance engineering tool sorry",
    "start": "2270710",
    "end": "2276859"
  },
  {
    "text": "performance engineering team whose responsibilities like okay well let's optimize efficiency across the fleet or",
    "start": "2276859",
    "end": "2282319"
  },
  {
    "text": "saw some performance issues in the service then they would benefit from this great day because otherwise tracing",
    "start": "2282319",
    "end": "2287960"
  },
  {
    "text": "date it just becomes larger inaccessible we have just default utilization that Yaeger provides they're only good for",
    "start": "2287960",
    "end": "2293989"
  },
  {
    "text": "certain use cases but not to extract a lot of net rich data and we would like",
    "start": "2293989",
    "end": "2299719"
  },
  {
    "text": "to also build a community around this so people would run this aggregation jobs internally and comment whether they find",
    "start": "2299719",
    "end": "2307789"
  },
  {
    "text": "any value in it and once we won we proved that you know this specific job",
    "start": "2307789",
    "end": "2313190"
  },
  {
    "text": "is useful we can be relevant that and created very simple deployment without",
    "start": "2313190",
    "end": "2319930"
  },
  {
    "text": "using Jupiter on books and so on this is",
    "start": "2319930",
    "end": "2328369"
  },
  {
    "text": "basically the same thing as what we've said about the tag matching sampling is kind of ad hoc something where you can",
    "start": "2328369",
    "end": "2334069"
  },
  {
    "text": "allow users to express their sampling policy in more details than just probabilistic or",
    "start": "2334069",
    "end": "2339990"
  },
  {
    "text": "something very simple that we have today it's more about like oh I want to look at these parameters of the trace and and make a sampling decision so that's part",
    "start": "2339990",
    "end": "2346829"
  },
  {
    "text": "of that work I guess tell by sampling is what we've discussed before that that's",
    "start": "2346829",
    "end": "2353970"
  },
  {
    "text": "like a larger infrastructure piece that we work in a tuber so that we can make very intelligent sampling decisions once",
    "start": "2353970",
    "end": "2360539"
  },
  {
    "text": "the whole trace is collected in memory and then store only the ones that are relevant rather than everything open",
    "start": "2360539",
    "end": "2367260"
  },
  {
    "text": "telemetry we have a lot of clients in different languages which takes a lot of time to maintain them and once the open",
    "start": "2367260",
    "end": "2372990"
  },
  {
    "text": "telemetry is ready its production ready we would like to basically deprecated our clients so we can focus more on",
    "start": "2372990",
    "end": "2379529"
  },
  {
    "text": "these data analytics jobs and provide more features you know I think that the",
    "start": "2379529",
    "end": "2386160"
  },
  {
    "text": "data collection should be somehow open sourced and used by maybe different systems and then the j채ger can focus",
    "start": "2386160",
    "end": "2393539"
  },
  {
    "text": "really on the providing value from this data to the end users rather than just",
    "start": "2393539",
    "end": "2400079"
  },
  {
    "text": "collecting that well we're out of time",
    "start": "2400079",
    "end": "2407670"
  },
  {
    "text": "so we can skip that we kind of talked about it yeah yes I think that's that's",
    "start": "2407670",
    "end": "2413430"
  },
  {
    "text": "that's all we have I don't know the official time is over so we can have",
    "start": "2413430",
    "end": "2418980"
  },
  {
    "text": "questions maybe people come over here or [Applause]",
    "start": "2418980",
    "end": "2425760"
  }
]
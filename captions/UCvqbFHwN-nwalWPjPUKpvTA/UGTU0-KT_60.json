[
  {
    "text": "all right hi everyone thank you for coming to the late track the last track",
    "start": "719",
    "end": "5960"
  },
  {
    "text": "of the day session we appreciate it uh this is the OTL cookbook my name is Tyler houth I'm an engineer from",
    "start": "5960",
    "end": "11639"
  },
  {
    "text": "honeycomb I'm Evan Bradley I'm an engineer from din trce so first I need to show a hands how",
    "start": "11639",
    "end": "18640"
  },
  {
    "text": "many people in here have used OTL before okay pretty good number all right",
    "start": "18640",
    "end": "24240"
  },
  {
    "text": "well I see that there weren't some hands up and I'm going to assume that's not because your arms cramping so first uh",
    "start": "24240",
    "end": "29519"
  },
  {
    "text": "I'm going to cover what we're going to cover today here and first we're going to get into what the collector is and",
    "start": "29519",
    "end": "35000"
  },
  {
    "text": "how OT fits into that just so that everybody's up to speed after that we're going to solve a couple of scenarios with OTL um we have the recipes as part",
    "start": "35000",
    "end": "42719"
  },
  {
    "text": "of our cookbook and we're going to frame them using these scenarios um so we hope you'll enjoy those and then to show ot's",
    "start": "42719",
    "end": "49440"
  },
  {
    "text": "flexibility we're going to take your scenarios and then we're going to do them live so we hope that you've brought some or that you can think of some",
    "start": "49440",
    "end": "55760"
  },
  {
    "text": "throughout our presentation so just to get started here the open collector is an observability",
    "start": "55760",
    "end": "61600"
  },
  {
    "text": "pipeline middleware that can Import and Export data in all sorts of formats and",
    "start": "61600",
    "end": "67320"
  },
  {
    "text": "the user can control the flow of data as it goes to the collector and The Collector owes this to its pipeline",
    "start": "67320",
    "end": "72880"
  },
  {
    "text": "model which is based on a custom like internal version that it or of data",
    "start": "72880",
    "end": "79560"
  },
  {
    "text": "that's based on OTL um and this is particularly useful with processors so processors are able to work on data on",
    "start": "79560",
    "end": "86400"
  },
  {
    "text": "this internal representation without having to worry about what the data is going to look like going out or how it looked coming in and this is going to be",
    "start": "86400",
    "end": "93040"
  },
  {
    "text": "the focus of the presentation today um o usually comes in at the processing stage in particular we're going to be focusing",
    "start": "93040",
    "end": "99520"
  },
  {
    "text": "on two processors in The Collector the transform processor which can edit data in place as it travels to the collector",
    "start": "99520",
    "end": "106240"
  },
  {
    "text": "and the filter processor which drops data from a pipeline so what is ootl ootl is a DSL",
    "start": "106240",
    "end": "114680"
  },
  {
    "text": "that is custom built for The Collector really fast really flexible it's probably the most flexible way to modify",
    "start": "114680",
    "end": "120399"
  },
  {
    "text": "data inside of the collector and it owes this to a couple of properties first you can access any field on the otop payload",
    "start": "120399",
    "end": "127439"
  },
  {
    "text": "so any data coming into the collector OT is going to provide some way of providing access to this second since",
    "start": "127439",
    "end": "133440"
  },
  {
    "text": "it's a programming language you are given a degree of expressiveness that",
    "start": "133440",
    "end": "139040"
  },
  {
    "text": "might not be present in something like a yaml config um and we've made the syntax just complex enough hopefully to do all",
    "start": "139040",
    "end": "146160"
  },
  {
    "text": "the comp or do all the Transformations that you would like to do without it overly complex uh and difficult to use",
    "start": "146160",
    "end": "152280"
  },
  {
    "text": "read one other thing that I want to call out is that the otop data model is hierarchical so let's say you're",
    "start": "152280",
    "end": "158239"
  },
  {
    "text": "emitting a bunch of logs and these logs are probably coming from an application right well you can put the application's",
    "start": "158239",
    "end": "165200"
  },
  {
    "text": "name on each of the logs so you know where it comes from but that's a lot of data duplication so OTL tries to be",
    "start": "165200",
    "end": "170319"
  },
  {
    "text": "smart about this and has this information on a resource so if you have",
    "start": "170319",
    "end": "175440"
  },
  {
    "text": "these 50 logs the 50 logs would all be associated with the resource and the resource would would have that as like a",
    "start": "175440",
    "end": "180840"
  },
  {
    "text": "list of logs under it this creates a little bit of complication when you're doing processing but as we'll see later",
    "start": "180840",
    "end": "186879"
  },
  {
    "text": "HL can handle this and the uh speed gains that you get are worth",
    "start": "186879",
    "end": "193319"
  },
  {
    "text": "it all right it's time to start going through some examples uh as we're going through these uh hopefully it Sparks",
    "start": "193599",
    "end": "199959"
  },
  {
    "text": "some ideas you can come up and give them to us at the end uh some of these are pretty complex if if we end up going a",
    "start": "199959",
    "end": "206519"
  },
  {
    "text": "little fast don't worry all of these slides are up on the session page you can come ask ask us questions we'll be at the otel observatory the rest of the",
    "start": "206519",
    "end": "212720"
  },
  {
    "text": "week so we can help describe anything that gets missed so for this first example we're going to uh process some",
    "start": "212720",
    "end": "220159"
  },
  {
    "text": "unstructured MySQL logs these logs only have a body right now with the the text inside which means they're not taking",
    "start": "220159",
    "end": "226280"
  },
  {
    "text": "advantage of otel structured nature and we'd like it to uh we want to uh extract the values",
    "start": "226280",
    "end": "234000"
  },
  {
    "text": "some values out of the uh log body and to do that we're going to use the following recipes uh we're going to set",
    "start": "234000",
    "end": "239439"
  },
  {
    "text": "some TLP log Fields we're going to parse and extract values from an unstructured log body we're going to conditionally",
    "start": "239439",
    "end": "246159"
  },
  {
    "text": "set some values and we're going to update ANP resource so the first thing we want to",
    "start": "246159",
    "end": "252560"
  },
  {
    "text": "do is to set the severity number and the severity text for this log we know that the log body in its text doesn't have",
    "start": "252560",
    "end": "258280"
  },
  {
    "text": "anything that represents severity so we're going to choose to classify all of these logs as info setting a value is",
    "start": "258280",
    "end": "264120"
  },
  {
    "text": "the most basic but most common action to take with OTL we do this using the set function it takes as its first parameter",
    "start": "264120",
    "end": "271039"
  },
  {
    "text": "the field being set and the second parameter is the value OTL provides",
    "start": "271039",
    "end": "276120"
  },
  {
    "text": "paths to each field in every signal of otel so you'll always have access to the",
    "start": "276120",
    "end": "281680"
  },
  {
    "text": "field that you want to use in addition OTL also supports enums so and if you",
    "start": "281680",
    "end": "287280"
  },
  {
    "text": "want to keep the statements nice and readable you can use something like severity number info instead of the number",
    "start": "287280",
    "end": "294479"
  },
  {
    "text": "nine next up we want to extract the interesting field query time from the log body and put it into an attribute we",
    "start": "295720",
    "end": "302440"
  },
  {
    "text": "do this using a combination of functions first OTL has the function extract patterns which uses Rex capture groups",
    "start": "302440",
    "end": "309199"
  },
  {
    "text": "to extract values from a string in this particular scenario we pass it in that log body and our Rex and it returns a",
    "start": "309199",
    "end": "315919"
  },
  {
    "text": "map from the named capture group and that captured value that returned map is",
    "start": "315919",
    "end": "321120"
  },
  {
    "text": "then piped in as the second parameter to the merge map function which takes in as the first parameter the log attributes",
    "start": "321120",
    "end": "327880"
  },
  {
    "text": "that map is the second second parameter and it merges it into the logs attribute the result is that that query",
    "start": "327880",
    "end": "334600"
  },
  {
    "text": "time parameter that gets extracted out of the body ends up in our logs attributes for use later we call",
    "start": "334600",
    "end": "339960"
  },
  {
    "text": "functions like extract patterns converters and they're really helpful to keep complex Transformations into one",
    "start": "339960",
    "end": "347039"
  },
  {
    "text": "statement next up OTL supports conditions which determine whether or not a function is executed in this",
    "start": "347199",
    "end": "354759"
  },
  {
    "text": "statement we only want the new slow attribute to be added to the log's attribute map if the query time",
    "start": "354759",
    "end": "361800"
  },
  {
    "text": "attribute which we extracted in the last scenario is if it's greater than 0.7",
    "start": "361800",
    "end": "367400"
  },
  {
    "text": "with this condition only logs that have that slow query Time end up getting this new attribute it acts like a gate",
    "start": "367400",
    "end": "373840"
  },
  {
    "text": "although this is a really simple condition with just one Boolean expression OTL does support ands ores",
    "start": "373840",
    "end": "379720"
  },
  {
    "text": "not and grouping if you need them and finally we want to set a static",
    "start": "379720",
    "end": "385800"
  },
  {
    "text": "resource attribute to represent where these logs came from in this scenario we're saying all the logs came from the",
    "start": "385800",
    "end": "390960"
  },
  {
    "text": "same place so this is the perfect the resource is the perfect place to put this type of information we can put it",
    "start": "390960",
    "end": "396160"
  },
  {
    "text": "on the resource attributes instead of the log attributes and this saves us bytes on the wire as we don't have to duplicate that information across every",
    "start": "396160",
    "end": "402360"
  },
  {
    "text": "single log here's what it looks like all put together in the transform processor",
    "start": "402360",
    "end": "408639"
  },
  {
    "text": "first for each resource we set that new attribute and then for each log we run the four statements all four statements",
    "start": "408639",
    "end": "414800"
  },
  {
    "text": "are executed from top to bottom in order for each log and then we move on to the",
    "start": "414800",
    "end": "420479"
  },
  {
    "text": "next log four statements again and it Loops through each log the result of all of these Transformations is a log with",
    "start": "420479",
    "end": "427800"
  },
  {
    "text": "newly set severity some new attributes a nice resour attribute and that body text is left",
    "start": "427800",
    "end": "434319"
  },
  {
    "text": "intact all right so let's take a look at another log example this time using a Json body instead of an unstructured",
    "start": "434319",
    "end": "441039"
  },
  {
    "text": "body so let's say that we have logs that have a stringified version of the body that you see on the right here with most",
    "start": "441039",
    "end": "447639"
  },
  {
    "text": "of the fields under that object key we want to parse this log and then take these fields and put them on the",
    "start": "447639",
    "end": "453879"
  },
  {
    "text": "structured OTL log so we're going to show here is how to parse adjacent log and then how to work with Fields such as",
    "start": "453879",
    "end": "460120"
  },
  {
    "text": "time stamps Tracer span IDs or manipulation of",
    "start": "460120",
    "end": "465918"
  },
  {
    "text": "strings thanks so let's start with parsing the body so we have the body",
    "start": "467319",
    "end": "473520"
  },
  {
    "text": "it's that uh stringified Json that we talked about um and what we want to do first is we're going to parse that and",
    "start": "473520",
    "end": "479599"
  },
  {
    "text": "that's going to turn that from a string into a map and OTL can index Maps so",
    "start": "479599",
    "end": "485360"
  },
  {
    "text": "what we're going to do is we're going to get the object key out of there and that itself is a map that we're then going to",
    "start": "485360",
    "end": "491000"
  },
  {
    "text": "merge into something called the cache so the cache is a map type uh path in ootl",
    "start": "491000",
    "end": "497680"
  },
  {
    "text": "that allows you to as the name would imply cach values between statements so something like parsing Jason we don't",
    "start": "497680",
    "end": "503520"
  },
  {
    "text": "want to redo this on every statement so we put this inside of the cache and then the cache is cleared after the group of",
    "start": "503520",
    "end": "509120"
  },
  {
    "text": "statements so you don't have to worry about any kind of cross-contamination of state so again what we're going to do",
    "start": "509120",
    "end": "514399"
  },
  {
    "text": "here is we're going to get that object uh map out of the the body and then we're going to merge that into the cache",
    "start": "514399",
    "end": "520560"
  },
  {
    "text": "producing the result that you see on the screen here so now that we have all the",
    "start": "520560",
    "end": "525760"
  },
  {
    "text": "information we want to work with inside of the cache we can get to getting that information out of the log body so first",
    "start": "525760",
    "end": "531240"
  },
  {
    "text": "we had that long Json string before that's not going to look great in our back end we wanted just the log message",
    "start": "531240",
    "end": "536640"
  },
  {
    "text": "and that happens to be inside of that Json object so we set it on the",
    "start": "536640",
    "end": "541680"
  },
  {
    "text": "body next we have time stamps and these are in a string format and we know this",
    "start": "541680",
    "end": "546839"
  },
  {
    "text": "format so what we're going to do is we're going to take a format specifier string and our time function and we're",
    "start": "546839",
    "end": "552440"
  },
  {
    "text": "going to parse this into an Epoch time which we then set on the time field in the log and this can be shown however",
    "start": "552440",
    "end": "558279"
  },
  {
    "text": "you like in your back end next we're going to associate the",
    "start": "558279",
    "end": "564720"
  },
  {
    "text": "log with the span and Trace uh according to the IDS that have been set in that Json object and while the trace and span",
    "start": "564720",
    "end": "572680"
  },
  {
    "text": "IDs are normally integers kind of underneath the Hood um o provides these string sub paths which allow you to work",
    "start": "572680",
    "end": "580279"
  },
  {
    "text": "with these as heximal values so this is really handy because that way you don't have to do the conversion yourself and OT can handle it so we got these IDs as",
    "start": "580279",
    "end": "587880"
  },
  {
    "text": "hex strings inside of this Json and all we need to do is set these onto that string path and then it will do the",
    "start": "587880",
    "end": "594000"
  },
  {
    "text": "conversion into the integer for us finally we want to put an item name",
    "start": "594000",
    "end": "600920"
  },
  {
    "text": "attribute on these logs so we've got a brand in an item and we want these to be",
    "start": "600920",
    "end": "607040"
  },
  {
    "text": "a single attribute and then we want to make sure that it's case and sensitive we just chose uppercase so what we're going to do here is we're going to do a",
    "start": "607040",
    "end": "614480"
  },
  {
    "text": "uh series of function calls and we're going to Nest those OT allows you to do this so that you don't have to do these across multiple statements so first",
    "start": "614480",
    "end": "621360"
  },
  {
    "text": "we're going to concatenate the brand in the item with a hyphen and then we're just going to set it to uppercase and",
    "start": "621360",
    "end": "626399"
  },
  {
    "text": "set it onto that attribute fairly straightforward put together it looks like this uh as we",
    "start": "626399",
    "end": "633000"
  },
  {
    "text": "covered you parse the Json body you get that object key out of it put that into",
    "start": "633000",
    "end": "638120"
  },
  {
    "text": "the cache and then you set all those fields on the log and you're good to",
    "start": "638120",
    "end": "644040"
  },
  {
    "text": "go all right let's move on to a metric example in this scenario we've got some",
    "start": "644519",
    "end": "650079"
  },
  {
    "text": "applications producing metrics following different semantic conventions we want to normalize this data so that it all",
    "start": "650079",
    "end": "656360"
  },
  {
    "text": "looks like the stable semantic inventions for HD TP when we're using it",
    "start": "656360",
    "end": "661600"
  },
  {
    "text": "we're going to scope it down to just transforming the HTTP request duration histograms but you could use OTL to",
    "start": "661600",
    "end": "668360"
  },
  {
    "text": "normalize all the data if you needed to to bring these old style histograms up to the latest semantic invention we're",
    "start": "668360",
    "end": "674240"
  },
  {
    "text": "going to have to normalize the metric unit which means scaling all the data points normalizing the metric name and",
    "start": "674240",
    "end": "679680"
  },
  {
    "text": "the some data point attributes the recipes we're going to use for this are some reusable conditions uh how to",
    "start": "679680",
    "end": "686880"
  },
  {
    "text": "rename an attribute how to scale a metric and finally how to rename a",
    "start": "686880",
    "end": "691920"
  },
  {
    "text": "metric to start we want to make sure that we do these Transformations only for those two scoped down metrics uh",
    "start": "691920",
    "end": "698240"
  },
  {
    "text": "specifically the HTTP client or server duration metrics which is the old style name to avoid duplicating these two",
    "start": "698240",
    "end": "704160"
  },
  {
    "text": "conditions across every statement we can take advantage of this convenient condition Block in the transform processor config this is a uh list of",
    "start": "704160",
    "end": "711720"
  },
  {
    "text": "Boolean expressions like aware Clause that are ored together if any of these conditions are met then the statements",
    "start": "711720",
    "end": "717200"
  },
  {
    "text": "below get executed the first recipe we're going to follow is how to rename an attribute uh to to",
    "start": "717200",
    "end": "724480"
  },
  {
    "text": "do the first part of the rename we use set again it's the most common thing that we do we set a new attribute with",
    "start": "724480",
    "end": "729920"
  },
  {
    "text": "the new name and we use the uh old attributes value as the new value we",
    "start": "729920",
    "end": "735440"
  },
  {
    "text": "don't want that old attribute key or its value around in the data point attributes map anymore so we use delete",
    "start": "735440",
    "end": "740560"
  },
  {
    "text": "keys to remove the key and its value from the attributes",
    "start": "740560",
    "end": "746680"
  },
  {
    "text": "map next we want to adjust the metrics unit which also means scaling all of the data points for that metric scaling",
    "start": "746839",
    "end": "753160"
  },
  {
    "text": "histogram is trickier than scaling a sum because it's not a single digit it's got buckets but luckily we have this",
    "start": "753160",
    "end": "758920"
  },
  {
    "text": "convenient scale uh scale metric function which can take in a scale",
    "start": "758920",
    "end": "764279"
  },
  {
    "text": "factor optionally a new unit and then it takes care of setting that new unit and",
    "start": "764279",
    "end": "769560"
  },
  {
    "text": "doing all the mathematics on all of the data points to get the scaling",
    "start": "769560",
    "end": "774399"
  },
  {
    "text": "done and then finally rename a metric again we're just going to use set we take the name in as the path we set the",
    "start": "774839",
    "end": "781160"
  },
  {
    "text": "new value and then of course we want to do it conditionally based on whether it's the client or the",
    "start": "781160",
    "end": "786519"
  },
  {
    "text": "server this is what it looks like all put together like our first example with logs we're taking advantage of ot's",
    "start": "786519",
    "end": "792600"
  },
  {
    "text": "ability to work on multiple context in this in this part uh specifically the data point and the metric context in the",
    "start": "792600",
    "end": "800040"
  },
  {
    "text": "first part we're working on data points we're only working on data points that are for the metric that we care about we",
    "start": "800040",
    "end": "806360"
  },
  {
    "text": "set the new attribute and remove we remove the old one one thing I want to call out is that in that conditions even though we're",
    "start": "806360",
    "end": "812399"
  },
  {
    "text": "working on data points which don't have a name we're able to reach up into the metric associated with that data point",
    "start": "812399",
    "end": "818480"
  },
  {
    "text": "get its name and then do the check this is because OTL understands the hierarchical nature of otel data it",
    "start": "818480",
    "end": "825440"
  },
  {
    "text": "knows that a data point is associated to exactly one metric one scope one resource and you're able to access those",
    "start": "825440",
    "end": "831480"
  },
  {
    "text": "fields in the second part we're transforming the metric we handle scaling all of or setting the new unit",
    "start": "831480",
    "end": "838079"
  },
  {
    "text": "and then scaling all of the data points all within that function and then we set the new name all right so let's take a look at",
    "start": "838079",
    "end": "845120"
  },
  {
    "text": "another metrics translation example this time using Prometheus so one thing or two things that I want to call out here",
    "start": "845120",
    "end": "851519"
  },
  {
    "text": "one we're not Prometheus experts so this isn't necessarily recommendation on what",
    "start": "851519",
    "end": "857440"
  },
  {
    "text": "to do when translating Prometheus metrics to otel and two this is a fairly convoluted example that is deliberately",
    "start": "857440",
    "end": "864279"
  },
  {
    "text": "intended to show how OTL can be used to force data into the shape that you wanted in uh even if it requires some",
    "start": "864279",
    "end": "870519"
  },
  {
    "text": "clever workarounds so if you don't totally follow this it's okay uh the key takeaway here is the flexibility of OTL",
    "start": "870519",
    "end": "877040"
  },
  {
    "text": "and not necessarily that this is the absolutely correct way to do something",
    "start": "877040",
    "end": "882519"
  },
  {
    "text": "however uh we're going to show a couple of interesting things as part of this um the this is kind of a modified example",
    "start": "882519",
    "end": "887839"
  },
  {
    "text": "of a real world example of scraping a message cu's endpoint and then taking",
    "start": "887839",
    "end": "893279"
  },
  {
    "text": "those metrics and making them more otel friendly so we want to dynamically rename the metric with without having to",
    "start": "893279",
    "end": "899600"
  },
  {
    "text": "explicitly enumerate each metric that we want to cover uh we want to do an aggregation inside of the collector so",
    "start": "899600",
    "end": "905800"
  },
  {
    "text": "do that before it reaches our back end and then finally you want to restructure the metrics payload a little bit so we have a uh information metric about our",
    "start": "905800",
    "end": "913160"
  },
  {
    "text": "cluster that we want to get the metad DAT 4 onto all of the metrics in the",
    "start": "913160",
    "end": "918600"
  },
  {
    "text": "payload so let's first start with renaming so our metrics all have this mqq prefix and the words in this are",
    "start": "918600",
    "end": "926639"
  },
  {
    "text": "delimited by underscores but in otel typically periods are used um so what we want to",
    "start": "926639",
    "end": "931680"
  },
  {
    "text": "do here is we're going to use a regular expression just to dynamically rename any metric that starts with this mqq",
    "start": "931680",
    "end": "937680"
  },
  {
    "text": "prefix and turn this into periods note here that the rest of the metric name so anything that's not in the prefix keeps",
    "start": "937680",
    "end": "944120"
  },
  {
    "text": "that underscore so the publish total will maintain the underscore despite the fact that the uh prefix has been",
    "start": "944120",
    "end": "951440"
  },
  {
    "text": "changed next we're going to do an aggregation and so we have this Q published metric and this shows the",
    "start": "951440",
    "end": "958440"
  },
  {
    "text": "number of messages for each q that a particular node handles but we want to",
    "start": "958440",
    "end": "963639"
  },
  {
    "text": "aggregate these into all of the messages that have been published from this node so what we're going to do here is we're",
    "start": "963639",
    "end": "970240"
  },
  {
    "text": "going to take a copy of the Q published metric and we're going to create a new node published metric that's inside of",
    "start": "970240",
    "end": "976839"
  },
  {
    "text": "the same payload so basically you just append to the metrics list and you keep the metric all of its data and then the",
    "start": "976839",
    "end": "982240"
  },
  {
    "text": "data points and all of their metadata and we're going to aggregate these next so the aggregation is fairly simple",
    "start": "982240",
    "end": "988720"
  },
  {
    "text": "you you can call the Aggregate and attributes function we want to sum the values for all of the publish messages",
    "start": "988720",
    "end": "995000"
  },
  {
    "text": "in the queue and we want to keep that node attribute because we want the published messages per node and we're",
    "start": "995000",
    "end": "1001000"
  },
  {
    "text": "going to do this just for that node publish metric so what it's going to do is it's going to take those three data points it's going to get rid of that Q",
    "start": "1001000",
    "end": "1007880"
  },
  {
    "text": "attribute so that's no longer a dimension for the values and it's going to sum up each of the one messages per Q",
    "start": "1007880",
    "end": "1014399"
  },
  {
    "text": "into three messages for that whole node",
    "start": "1014399",
    "end": "1019519"
  },
  {
    "text": "next what we want to do is we want to take a cluster infom metric that has a single data point with all of the",
    "start": "1019519",
    "end": "1025520"
  },
  {
    "text": "cluster information and we want to get this onto the resource so that it applies to all the metrics so what we",
    "start": "1025520",
    "end": "1031438"
  },
  {
    "text": "need to do here is since in otel the metrics themselves don't have any",
    "start": "1031439",
    "end": "1037199"
  },
  {
    "text": "attributes these all are included in the data points so since um attributes are used as dimensions in data points so",
    "start": "1037199",
    "end": "1043760"
  },
  {
    "text": "what we need to do here is we need to go down into the data point uh context and",
    "start": "1043760",
    "end": "1048919"
  },
  {
    "text": "we need to Loop through all the data points until we find that data point for the cluster infom metric after that all",
    "start": "1048919",
    "end": "1054240"
  },
  {
    "text": "we need to do is copy its attributes onto the resource attributes which will make it apply for all of the metrics in",
    "start": "1054240",
    "end": "1059960"
  },
  {
    "text": "the payload since we don't need that metric anymore what we're going to do now is",
    "start": "1059960",
    "end": "1065440"
  },
  {
    "text": "we're going to use the filter processor to go find that metric by its name and then just remove it from the",
    "start": "1065440",
    "end": "1071360"
  },
  {
    "text": "payload put together it looks like this inside of the metrics context we rename all the metrics we do that aggregation",
    "start": "1071360",
    "end": "1078240"
  },
  {
    "text": "uh and then we reach down to the data point context pull up the cluster information onto the resource and then",
    "start": "1078240",
    "end": "1083960"
  },
  {
    "text": "remove that unnecessary metric all right we I made another",
    "start": "1083960",
    "end": "1091080"
  },
  {
    "text": "example but I want to do a quick time check because we're getting close to my 10 minutes and I wanted to give enough",
    "start": "1091080",
    "end": "1096720"
  },
  {
    "text": "time for everyone to give examples enough people rais their hand that kind of understood OTL can you raise your hand if you're planning to to come up",
    "start": "1096720",
    "end": "1103240"
  },
  {
    "text": "here and give us an example if you are then I will pause here okay we didn't",
    "start": "1103240",
    "end": "1110400"
  },
  {
    "text": "get too many so I'm going to just keep going all right uh last example our spans have some attributes uh that all",
    "start": "1110400",
    "end": "1117840"
  },
  {
    "text": "share a same prefix and in this scenario we want to reorganize these attributes to be nested under a new value alt",
    "start": "1117840",
    "end": "1125039"
  },
  {
    "text": "together with that prefix removed and uh the prefix used as a as a key for the new attribute this is some we call this",
    "start": "1125039",
    "end": "1131960"
  },
  {
    "text": "Dynamic attribute manipulation or bulk attribute manipulation and it's a little tricky when you only know the prefix and",
    "start": "1131960",
    "end": "1138159"
  },
  {
    "text": "you don't know know the rest of the value it's you can't use static values in order to do manipulation uh instead you have to",
    "start": "1138159",
    "end": "1144840"
  },
  {
    "text": "group related attributes that's the recipe we're going to use and it's a little complex so we're going to do four required",
    "start": "1144840",
    "end": "1150400"
  },
  {
    "text": "Steps step number one is to duplicate the attributes into the cache we need the data duplicated so that we can mess",
    "start": "1150400",
    "end": "1156760"
  },
  {
    "text": "with it uh and we're going to do that in the cache step number two is to remove what",
    "start": "1156760",
    "end": "1162400"
  },
  {
    "text": "we don't want from each map so we use delete matching keys to remove all the attributes with that prefix from the",
    "start": "1162400",
    "end": "1168159"
  },
  {
    "text": "actual attribute map this removes all those prefixed attributes and leaves the attribute map with everything that was",
    "start": "1168159",
    "end": "1173520"
  },
  {
    "text": "left over that's okay we already duplicated all the data so it's safe we're going to add it back in a future step we do the opposite function uh keep",
    "start": "1173520",
    "end": "1181559"
  },
  {
    "text": "matching keys for the cache map in this case we pass in that prefix it drops any attribute that doesn't match that Rex",
    "start": "1181559",
    "end": "1189159"
  },
  {
    "text": "which means the ATT the cache map ends up being only those attributes we wanted to do manipulation",
    "start": "1189159",
    "end": "1194919"
  },
  {
    "text": "on step number three is to move that prefix we use replace all patterns which can do bulk manipulation on keys in a",
    "start": "1194919",
    "end": "1201880"
  },
  {
    "text": "map we pass in the cache which is holding all of those prefixed attributes we tell it to work on Keys instead of",
    "start": "1201880",
    "end": "1207400"
  },
  {
    "text": "values give it that prefix and the empty string as the replacement value it matches the prefix replaces it with an",
    "start": "1207400",
    "end": "1213880"
  },
  {
    "text": "empty string same as removing and then finally we take that",
    "start": "1213880",
    "end": "1219039"
  },
  {
    "text": "cache and we use it as the value for the new attribute otel supports Maps as",
    "start": "1219039",
    "end": "1224280"
  },
  {
    "text": "attribute values so we don't have to do anything special we can pass the cache in it copies the values over and we get",
    "start": "1224280",
    "end": "1229720"
  },
  {
    "text": "our new attribute here's what it looks like all put together we set that cache which",
    "start": "1229720",
    "end": "1235400"
  },
  {
    "text": "duplicates all the attributes we remove everything that we don't want from each map we remove the prefix from all those",
    "start": "1235400",
    "end": "1241440"
  },
  {
    "text": "attributes left over in the cache and we set a new attribute all right that was all of our",
    "start": "1241440",
    "end": "1248720"
  },
  {
    "text": "curated examples uh we're going to go over we're going to transition now into doing some of your examples live here on",
    "start": "1248720",
    "end": "1255200"
  },
  {
    "text": "stage uh I really hope you bring some if you don't uh we have some that we'll just type out",
    "start": "1255200",
    "end": "1260720"
  },
  {
    "text": "on stage uh couple rules for examples if you give them uh first no stateful",
    "start": "1260720",
    "end": "1266320"
  },
  {
    "text": "Transformations OT tail doesn't have any common functions that support stateful Transformations so uh no tail sampling",
    "start": "1266320",
    "end": "1272559"
  },
  {
    "text": "no metric conversion stuff like cumulative to Delta uh we're not going to do that uh no cross signal",
    "start": "1272559",
    "end": "1278480"
  },
  {
    "text": "Transformations OT tail is really strict with how it accesses the underlying payloads so you can't turn a log into a",
    "start": "1278480",
    "end": "1284640"
  },
  {
    "text": "span if you need to do that look at connectors a special component in the OT collector that can handle that kind of",
    "start": "1284640",
    "end": "1290240"
  },
  {
    "text": "stuff and then finally no profile Transformations you may have heard some profile stuff today OTL is getting",
    "start": "1290240",
    "end": "1295760"
  },
  {
    "text": "really close to aable support for profiles uh The Collector is working on it but we just don't have support for it",
    "start": "1295760",
    "end": "1301640"
  },
  {
    "text": "yet nol uh if you bring us an example and it's really hard and we take too long to",
    "start": "1301640",
    "end": "1306840"
  },
  {
    "text": "solve it we don't want to get stuck on it so we're just going to transition to the next one uh you can come find us at",
    "start": "1306840",
    "end": "1312559"
  },
  {
    "text": "the otel observatory we'll try to solve it with you there when you're given uh examples try to keep it succinct we'd only need the",
    "start": "1312559",
    "end": "1319400"
  },
  {
    "text": "what not the why we don't really need the context behind why you needed this transformation uh we're not going to run data through any of these we're just",
    "start": "1319400",
    "end": "1325279"
  },
  {
    "text": "going to make claims that they work so just give us the what you need done uh we'll upload all of the Transformations",
    "start": "1325279",
    "end": "1330320"
  },
  {
    "text": "we write to the session page so don't worry about taking super detailed notes or anything all these statements will be",
    "start": "1330320",
    "end": "1336400"
  },
  {
    "text": "accessible at the end of the session and then finally we're still going to do a Q&A so if you have questions related to",
    "start": "1336400",
    "end": "1342080"
  },
  {
    "text": "other OTL things but not to this exercise save them for then uh and with that I'll open it to the floor to come",
    "start": "1342080",
    "end": "1349279"
  },
  {
    "text": "test OTL and see how flexible it can",
    "start": "1349279",
    "end": "1354600"
  },
  {
    "text": "be cool all right that work okay uh okay uh this was great thanks I'm definitely",
    "start": "1362520",
    "end": "1369000"
  },
  {
    "text": "going to use the slides in the future uh just yesterday I had an issue that I",
    "start": "1369000",
    "end": "1375400"
  },
  {
    "text": "again wasn't able to solve with OTL docks so maybe that some work is needed",
    "start": "1375400",
    "end": "1380640"
  },
  {
    "text": "on the documentation but I wanted a very simple thing I wanted to know if log",
    "start": "1380640",
    "end": "1387679"
  },
  {
    "text": "body has a string in it specific string in it so it's the I think the question I",
    "start": "1387679",
    "end": "1393200"
  },
  {
    "text": "heard was how do I check if log body is a string before I do a transformation okay we can do that we",
    "start": "1393200",
    "end": "1400320"
  },
  {
    "text": "do a statement like we'll just set an attribute",
    "start": "1400320",
    "end": "1407240"
  },
  {
    "text": "test app and we have a function called is string",
    "start": "1407240",
    "end": "1414279"
  },
  {
    "text": "you can pass it the body and it returns true if the body is a Str I want to see if there is a specific string in the",
    "start": "1414279",
    "end": "1421120"
  },
  {
    "text": "body if there's info in the body oh okay uh if if you want to check if there's a specific string in the body we could",
    "start": "1421120",
    "end": "1427360"
  },
  {
    "text": "also do and is match uh pass it the body and then",
    "start": "1427360",
    "end": "1434640"
  },
  {
    "text": "whatever string you were looking for like if info is in there and that's that's using redx essentially just r y",
    "start": "1434640",
    "end": "1441520"
  },
  {
    "text": "uh so it can handle complex it's it's restricted to goes redax so no negative",
    "start": "1441520",
    "end": "1447520"
  },
  {
    "text": "look ahads I think um but yeah any sort of red Jax that go supports you can do",
    "start": "1447520",
    "end": "1452880"
  },
  {
    "text": "with that yeah so yeah I don't know why I didn't find it but yeah thanks I'm definitely going to use",
    "start": "1452880",
    "end": "1460360"
  },
  {
    "text": "it I think also we don't actually need this cuz his match will handled conversion do that yeah thank hey time",
    "start": "1462679",
    "end": "1471720"
  },
  {
    "text": "for one more okay yeah awesome thanks for for the talk uh I want to to be able",
    "start": "1471720",
    "end": "1480200"
  },
  {
    "text": "to dynamically uh Define the labels that I",
    "start": "1480200",
    "end": "1485960"
  },
  {
    "text": "want to collect from uh a resarch so let's say",
    "start": "1485960",
    "end": "1491799"
  },
  {
    "text": "we have a resarch detection and that gets a lot of labels and I went to apply",
    "start": "1491799",
    "end": "1499919"
  },
  {
    "text": "some of those labels to the metrix but I want to do that",
    "start": "1499919",
    "end": "1505480"
  },
  {
    "text": "dynamically based it on each metric but I don't want to do that in the collector",
    "start": "1505480",
    "end": "1511600"
  },
  {
    "text": "I want to do that into my code so I want to send something like a metadata saying",
    "start": "1511600",
    "end": "1517720"
  },
  {
    "text": "all of the labels that I want to keep all the infrastructural labels that I want to keep and I want to The Collector",
    "start": "1517720",
    "end": "1524960"
  },
  {
    "text": "to see that and just apply and just keep",
    "start": "1524960",
    "end": "1530720"
  },
  {
    "text": "those infrastructure labels that if you found on that let's say metadata tag I",
    "start": "1530720",
    "end": "1538240"
  },
  {
    "text": "don't think it was much clear but I I don't know if I totally follow",
    "start": "1538240",
    "end": "1544360"
  },
  {
    "text": "the scenario I'm my guess is that it's doable with some combination of the cache replace patterns um but I I don't",
    "start": "1544360",
    "end": "1553640"
  },
  {
    "text": "think I quite understood what you're asking do you want to take AEP about it",
    "start": "1553640",
    "end": "1559840"
  },
  {
    "text": "I'm not can you speak a little bit closer to the microphone unfortunately the speakers are facing away from us oh yeah sure uh oh yeah that that's",
    "start": "1559840",
    "end": "1567679"
  },
  {
    "text": "youring uh yeah I I pretty much want to dynamically select the labels uh to",
    "start": "1567679",
    "end": "1573799"
  },
  {
    "text": "apply to a specific metric uh but I don't want to do that directly in the collector I want to be dynamic from the",
    "start": "1573799",
    "end": "1581200"
  },
  {
    "text": "code so the the the matric that is emitting the matric the code that is",
    "start": "1581200",
    "end": "1586960"
  },
  {
    "text": "emitting the metric finds what what are the infrastructure labels that he wants",
    "start": "1586960",
    "end": "1592399"
  },
  {
    "text": "to keep uh when it gets to The Collector I don't I I don't know enough",
    "start": "1592399",
    "end": "1598799"
  },
  {
    "text": "about the sdks to answer that unfortunately yeah this is right now OT tail is only supported in The Collector",
    "start": "1598799",
    "end": "1604440"
  },
  {
    "text": "so if you wanted to do something in your application you could pull in OTL it is a library it's it's tagged and available",
    "start": "1604440",
    "end": "1610440"
  },
  {
    "text": "for use and you could you I I see you might be able to do",
    "start": "1610440",
    "end": "1616320"
  },
  {
    "text": "something like that but it's typically Ally used for users to express Transformations when they're not in the",
    "start": "1616320",
    "end": "1622720"
  },
  {
    "text": "code when you're in the code you've got a lot of tools available to you that like regular P data or something you probably might not need OTL let's talk",
    "start": "1622720",
    "end": "1630360"
  },
  {
    "text": "about this one after yeah sure thank you thank",
    "start": "1630360",
    "end": "1634760"
  },
  {
    "text": "you I have a use case um can you extract the time stamp from the log of metrix",
    "start": "1635600",
    "end": "1641880"
  },
  {
    "text": "and then change from one time zone to another yes uh I'm going to paraphrase",
    "start": "1641880",
    "end": "1648679"
  },
  {
    "text": "some of the functions cuz I don't have them all memorized but the answer is yes we can change time zones so it would be something like do you want to do the log",
    "start": "1648679",
    "end": "1655600"
  },
  {
    "text": "time stamp or The observed time stamp uh both okay I'll start with just",
    "start": "1655600",
    "end": "1661200"
  },
  {
    "text": "the time stamp it would be something like time um and it would",
    "start": "1661200",
    "end": "1666640"
  },
  {
    "text": "be I think our time converter can handle switching the time zone I don't",
    "start": "1666640",
    "end": "1674000"
  },
  {
    "text": "really want to pull up the function uh the functions I know it the time stamp will come in as a Time object and so you",
    "start": "1674000",
    "end": "1682799"
  },
  {
    "text": "can convert that you can get the hour off of that yes you could get the hour off of",
    "start": "1682799",
    "end": "1690200"
  },
  {
    "text": "it if it's already in it's already in Epoch time we could",
    "start": "1690200",
    "end": "1696480"
  },
  {
    "text": "do you can convert it into I mean I'll say this the time function that we showed earlier this is",
    "start": "1696480",
    "end": "1703559"
  },
  {
    "text": "how my brain is thinking right now so I'm just going to write it this way um there is a function to",
    "start": "1703559",
    "end": "1712000"
  },
  {
    "text": "turn the to take the time and turn it into a UTC time I think it's like this",
    "start": "1712000",
    "end": "1718159"
  },
  {
    "text": "and then you would pass it your format and the new time zone whatever that is",
    "start": "1718159",
    "end": "1723840"
  },
  {
    "text": "uh that's a really roundabout way to do it we might have a function that's just on a time set time zone and I don't",
    "start": "1723840",
    "end": "1730679"
  },
  {
    "text": "remember if we don't that would be a really good issue uh and if anyone's coming to contrib Fest later for open",
    "start": "1730679",
    "end": "1736880"
  },
  {
    "text": "Telemetry uh a function like that would be a really easy first contribution uh so if you're",
    "start": "1736880",
    "end": "1742240"
  },
  {
    "text": "interested in contributing to otel come to the contri Fest on Friday and maybe you can contribute a a function like",
    "start": "1742240",
    "end": "1748159"
  },
  {
    "text": "that time zone if we don't have it yeah so is it possible that if we deploy the",
    "start": "1748159",
    "end": "1753200"
  },
  {
    "text": "same code to the different region and you can dynamically uh identify the time zone",
    "start": "1753200",
    "end": "1760720"
  },
  {
    "text": "and change accordingly yeah this this time this time function supports",
    "start": "1760720",
    "end": "1766600"
  },
  {
    "text": "locality and time zone that was a feature added in the last two months",
    "start": "1766600",
    "end": "1773960"
  },
  {
    "text": "um so I think the answer to what you're saying is yes thank you",
    "start": "1773960",
    "end": "1779919"
  },
  {
    "text": "yep I'll I'll make sure that this one's true before I upload the slides hey there hey hey I got one more",
    "start": "1779919",
    "end": "1788519"
  },
  {
    "text": "um so I was kind of involved in this um but I just wanted to clarify uh",
    "start": "1788519",
    "end": "1794559"
  },
  {
    "text": "replacing a substring with a hash based on on a regular expression is this",
    "start": "1794559",
    "end": "1800240"
  },
  {
    "text": "something that we can um you know that we declare support for or there's something some work to be done there um",
    "start": "1800240",
    "end": "1807760"
  },
  {
    "text": "yeah replace a substring with a hash yeah with a hash of of a replacement",
    "start": "1807760",
    "end": "1812880"
  },
  {
    "text": "string yeah yeah yes yeah uh is it in replace pattern is it replace pattern",
    "start": "1812880",
    "end": "1818799"
  },
  {
    "text": "replace patter replace pattern uh let's say we're doing the ATT some",
    "start": "1818799",
    "end": "1825279"
  },
  {
    "text": "attribute uh we'll just keep using test because that's a good one um it takes in",
    "start": "1825279",
    "end": "1831120"
  },
  {
    "text": "the you the you have to have a capture group in there yeah we got to do we'll just do everything that star there you",
    "start": "1831120",
    "end": "1838039"
  },
  {
    "text": "go well we need the capture group uh so it's in",
    "start": "1838039",
    "end": "1844000"
  },
  {
    "text": "parenthesis this is no no no this is just just a string oh oh yeah yeah",
    "start": "1844000",
    "end": "1849240"
  },
  {
    "text": "that's that's the that's the replacement value isn't it like dollar sign dollar sign one and then you pass it in to sh",
    "start": "1849240",
    "end": "1856440"
  },
  {
    "text": "26 26 but you want in the r you want the capture grou in this Rex oh oh yeah yeah",
    "start": "1856440",
    "end": "1863399"
  },
  {
    "text": "it's got to be like do there you go uh so this fun this this statement uses a",
    "start": "1863399",
    "end": "1869760"
  },
  {
    "text": "function called replace pattern it takes in a single string in this case it would be the string pass I guess uh matches a",
    "start": "1869760",
    "end": "1877440"
  },
  {
    "text": "Rex uh in this case everything uh that capture group is referenceable as the",
    "start": "1877440",
    "end": "1883600"
  },
  {
    "text": "new value uh and when you when you add this optional parameter which is a",
    "start": "1883600",
    "end": "1888960"
  },
  {
    "text": "function it will pass this value to this function executed and that's what ends",
    "start": "1888960",
    "end": "1895440"
  },
  {
    "text": "up getting set right I have a question around this",
    "start": "1895440",
    "end": "1900960"
  },
  {
    "text": "maybe in the later in the observatory yeah I didn't catch that what' you say uh in the observatory I have a question",
    "start": "1900960",
    "end": "1907240"
  },
  {
    "text": "around this about the replacement Behavior okay okay sounds good yeah looking forward to it uh let's do one",
    "start": "1907240",
    "end": "1914480"
  },
  {
    "text": "more um I don't have use case but I I want to ask you write the um the",
    "start": "1914480",
    "end": "1921320"
  },
  {
    "text": "statement how would you recommend us to troubleshooting because I write it but I",
    "start": "1921320",
    "end": "1928080"
  },
  {
    "text": "don't know how to verify yes that is a really really really good question um",
    "start": "1928080",
    "end": "1933559"
  },
  {
    "text": "there are two things to do uh the first is the transform processor the filter",
    "start": "1933559",
    "end": "1939559"
  },
  {
    "text": "processor really everything in the collector especially think OTL is utilizing P data under the hood which is",
    "start": "1939559",
    "end": "1946760"
  },
  {
    "text": "how the collector represents data uh OT tail works on how the collector sees the data not how your",
    "start": "1946760",
    "end": "1953120"
  },
  {
    "text": "backend is showing you the data so some back ends may change the value of something they might have special fields",
    "start": "1953120",
    "end": "1958279"
  },
  {
    "text": "or or uppercase things that is not what OTL is looking at OTL is looking exactly",
    "start": "1958279",
    "end": "1963880"
  },
  {
    "text": "at what's in the collector so when troubleshooting OTL you want to look at what the collector thinks of your data",
    "start": "1963880",
    "end": "1970720"
  },
  {
    "text": "so there's two ways to do that the first is to add a debug xor with a for osity",
    "start": "1970720",
    "end": "1978799"
  },
  {
    "text": "of debug this add this to your exporter's pipeline and it will spit out",
    "start": "1978799",
    "end": "1984000"
  },
  {
    "text": "exactly what the collector views as your data so if you think that a field is",
    "start": "1984000",
    "end": "1990440"
  },
  {
    "text": "sample rate with a capital S but it's actually sample rate with a lowercase s this would show it the other thing to do",
    "start": "1990440",
    "end": "1997399"
  },
  {
    "text": "and something that's probably even better is in your service",
    "start": "1997399",
    "end": "2004120"
  },
  {
    "text": "Telemetry logs level debug we recently added to",
    "start": "2004120",
    "end": "2010960"
  },
  {
    "text": "OTL the ability to print out the transform context which is essentially",
    "start": "2010960",
    "end": "2017760"
  },
  {
    "text": "the what what this group of statements is looking at uh it will print it out at",
    "start": "2017760",
    "end": "2023279"
  },
  {
    "text": "the start before any Transformations have happened and then after each transformation it will print out what the data looks like now so you can kind",
    "start": "2023279",
    "end": "2030120"
  },
  {
    "text": "of go step by step and see what did my data look like when I started I've done a transformation what does it look like",
    "start": "2030120",
    "end": "2035960"
  },
  {
    "text": "now I've done another transformation what does it look like now it's verbose uh but it is really truthful for what",
    "start": "2035960",
    "end": "2043080"
  },
  {
    "text": "the data looks like the collector also now supports exporting logs over OTP as",
    "start": "2043080",
    "end": "2049320"
  },
  {
    "text": "of the latest version uh so if you want to push those logs to your favorite logs back end or",
    "start": "2049320",
    "end": "2056079"
  },
  {
    "text": "whatever back end you want to look look at them instead of like console log or something The Collector supports that",
    "start": "2056079",
    "end": "2062040"
  },
  {
    "text": "now but when you turn on the debug more the log is going to flow in huge size",
    "start": "2062040",
    "end": "2069000"
  },
  {
    "text": "yep so you have to go one by one one line by yep okay that's uh that is true",
    "start": "2069000",
    "end": "2075878"
  },
  {
    "text": "I don't have an answer to that it it will turn on debug logs for every component so you'll have to sift through",
    "start": "2075879",
    "end": "2081040"
  },
  {
    "text": "got it uh but they should come in order uh especially if you've just got the one pipeline like",
    "start": "2081040",
    "end": "2088720"
  },
  {
    "text": "yeah uh I ran out of time for Q&A but if people have other questions that aren't",
    "start": "2089879",
    "end": "2096079"
  },
  {
    "text": "examples we can take that now and make maybe they'll let us stay up here for a",
    "start": "2096079",
    "end": "2101240"
  },
  {
    "text": "bit sorry if I could ask a question um I'm curious about what your",
    "start": "2103760",
    "end": "2108880"
  },
  {
    "text": "development uh methodology looks like for testing here are you running these tests in some sort of self-contained way",
    "start": "2108880",
    "end": "2115480"
  },
  {
    "text": "when you write OTL or are you doing it end to end uh OTL has a pretty extensive",
    "start": "2115480",
    "end": "2120720"
  },
  {
    "text": "test Suite we have both unit tests for all of the functions uh all of the",
    "start": "2120720",
    "end": "2126440"
  },
  {
    "text": "contexts the grammar the parser all that stuff the lexer all that stuff oh I'm I'm sorry uh I asked the question badly",
    "start": "2126440",
    "end": "2133280"
  },
  {
    "text": "what I actually mean is when I write OTL as a user in in my configuration how can",
    "start": "2133280",
    "end": "2138920"
  },
  {
    "text": "I validate it oh oh oh oh like when you're when you're testing if a statement works or",
    "start": "2138920",
    "end": "2144599"
  },
  {
    "text": "not correct um do you want I a couple you want yeah no I mean so I mean it's exactly what Tyler described earlier so",
    "start": "2144599",
    "end": "2151200"
  },
  {
    "text": "first of all when you send your data through um the debug exporter is a big help because you can see whether it",
    "start": "2151200",
    "end": "2157079"
  },
  {
    "text": "looks like you expected to and if you're having issues with that then the second thing you can do is this debug level in",
    "start": "2157079",
    "end": "2164599"
  },
  {
    "text": "The Collector so this will actually print out like Tyler said the whole context so you'll see exactly what the data looks like before and after and",
    "start": "2164599",
    "end": "2171680"
  },
  {
    "text": "determine whether your statement worked or not when it comes to setting up input when I do this I normally do it locally",
    "start": "2171680",
    "end": "2178000"
  },
  {
    "text": "I keep it simple I have like a file log receiver or an OTL ason receiver and just like really",
    "start": "2178000",
    "end": "2186040"
  },
  {
    "text": "set up the data only put the transform processor only put the debug exporter um",
    "start": "2186040",
    "end": "2192119"
  },
  {
    "text": "there's some other this has come up a little bit before someone has an issue open right now for something called the OTL playground um I don't know if you've",
    "start": "2192119",
    "end": "2198920"
  },
  {
    "text": "seen that issue it's the idea of hey go has a playground where you can go and write go code what if we did that with",
    "start": "2198920",
    "end": "2204359"
  },
  {
    "text": "OTL uh they made cool like they made good progress on it they had a website hosted for a second where you could go",
    "start": "2204359",
    "end": "2210440"
  },
  {
    "text": "up and like write some statements and it was pretty sweet so uh there are some more like user facing Concepts out there",
    "start": "2210440",
    "end": "2217280"
  },
  {
    "text": "right now now for how to improve the the like experience with writing it uh but",
    "start": "2217280",
    "end": "2222520"
  },
  {
    "text": "they're still underway so for now I think just running local collectors is a good solution have you done any",
    "start": "2222520",
    "end": "2228160"
  },
  {
    "text": "investigation into static analysis for this into into what uh any any investigation into static analysis for",
    "start": "2228160",
    "end": "2234960"
  },
  {
    "text": "the statements themselves so they can be validated before they're executed uh we don't have any static analysis uh I've",
    "start": "2234960",
    "end": "2241119"
  },
  {
    "text": "always thought if someone wanted to make like a okay out of time uh we've always",
    "start": "2241119",
    "end": "2246800"
  },
  {
    "text": "thought that like doing like a vs code like thing that",
    "start": "2246800",
    "end": "2251880"
  },
  {
    "text": "checked if you were writing the statement right like would be pretty cool but no we haven't looked into that yet thank you guys",
    "start": "2251880",
    "end": "2258040"
  },
  {
    "text": "yep I think we're done yeah thank you",
    "start": "2258040",
    "end": "2264079"
  }
]
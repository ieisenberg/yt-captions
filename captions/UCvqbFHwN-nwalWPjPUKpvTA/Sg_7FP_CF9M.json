[
  {
    "text": "so for next presentation we have Oliver",
    "start": "80",
    "end": "3240"
  },
  {
    "text": "from uh IBN who is the principal",
    "start": "3240",
    "end": "6080"
  },
  {
    "text": "research scientist from IBN and we have",
    "start": "6080",
    "end": "8599"
  },
  {
    "text": "abak senior software engineer from IBN",
    "start": "8599",
    "end": "11519"
  },
  {
    "text": "to give us next",
    "start": "11519",
    "end": "13320"
  },
  {
    "text": "presentation thank you uh thank you all",
    "start": "13320",
    "end": "16000"
  },
  {
    "text": "for being here you know I think I've",
    "start": "16000",
    "end": "17840"
  },
  {
    "text": "learned a lot today but I I already find",
    "start": "17840",
    "end": "20119"
  },
  {
    "text": "the DAT that has been a bit long so uh",
    "start": "20119",
    "end": "22600"
  },
  {
    "text": "thank you for sticking around as for our",
    "start": "22600",
    "end": "24279"
  },
  {
    "text": "talk and for the lightning talk",
    "start": "24279",
    "end": "25680"
  },
  {
    "text": "afterwards so my name is Olivia T today",
    "start": "25680",
    "end": "28640"
  },
  {
    "text": "I'm joined with uh by abishek malvan car",
    "start": "28640",
    "end": "31240"
  },
  {
    "text": "who is a senior software engineer and a",
    "start": "31240",
    "end": "32758"
  },
  {
    "text": "tech lead on this project and we want to",
    "start": "32759",
    "end": "35000"
  },
  {
    "text": "tell you a little bit about our the",
    "start": "35000",
    "end": "36559"
  },
  {
    "text": "platform the software platform we've",
    "start": "36559",
    "end": "38120"
  },
  {
    "text": "been developing at IBM research to train",
    "start": "38120",
    "end": "40480"
  },
  {
    "text": "large",
    "start": "40480",
    "end": "41320"
  },
  {
    "text": "models so we've heard a lot about large",
    "start": "41320",
    "end": "45039"
  },
  {
    "text": "language models already today so that's",
    "start": "45039",
    "end": "47199"
  },
  {
    "text": "good I don't have to repeat too much",
    "start": "47199",
    "end": "49000"
  },
  {
    "text": "just want maybe to point out on this",
    "start": "49000",
    "end": "50600"
  },
  {
    "text": "slide that we like to call them",
    "start": "50600",
    "end": "52239"
  },
  {
    "text": "Foundation models because it's not just",
    "start": "52239",
    "end": "54320"
  },
  {
    "text": "about language right the the the the",
    "start": "54320",
    "end": "57039"
  },
  {
    "text": "principles the techniques the tools that",
    "start": "57039",
    "end": "58800"
  },
  {
    "text": "are made these large language models",
    "start": "58800",
    "end": "61359"
  },
  {
    "text": "very very popular they can they're",
    "start": "61359",
    "end": "63680"
  },
  {
    "text": "applicable to many other modalities and",
    "start": "63680",
    "end": "65680"
  },
  {
    "text": "at IBM research we've been looking at",
    "start": "65680",
    "end": "67240"
  },
  {
    "text": "other such things so in particular we've",
    "start": "67240",
    "end": "69600"
  },
  {
    "text": "been for instance teaming with NASA to",
    "start": "69600",
    "end": "72000"
  },
  {
    "text": "build uh geospatial models models that",
    "start": "72000",
    "end": "74360"
  },
  {
    "text": "will help you know predict uh you know",
    "start": "74360",
    "end": "77960"
  },
  {
    "text": "flooding fires uh think about natural uh",
    "start": "77960",
    "end": "81200"
  },
  {
    "text": "disasters you know environment related",
    "start": "81200",
    "end": "83759"
  },
  {
    "text": "things with the same kind of tools and",
    "start": "83759",
    "end": "85680"
  },
  {
    "text": "techniques again and the one thing that",
    "start": "85680",
    "end": "87640"
  },
  {
    "text": "all of these models uh as you know have",
    "start": "87640",
    "end": "89439"
  },
  {
    "text": "in common and they are they are very",
    "start": "89439",
    "end": "90960"
  },
  {
    "text": "large right anywhere between hundreds",
    "start": "90960",
    "end": "93759"
  },
  {
    "text": "millions of parameters to maybe you know",
    "start": "93759",
    "end": "96119"
  },
  {
    "text": "10 billions or even more 10 billions or",
    "start": "96119",
    "end": "98200"
  },
  {
    "text": "even more yes so that means a lot of",
    "start": "98200",
    "end": "100920"
  },
  {
    "text": "computes uh you know need very serious",
    "start": "100920",
    "end": "103680"
  },
  {
    "text": "Hardware to train these things but also",
    "start": "103680",
    "end": "105600"
  },
  {
    "text": "very robust software stack to manage all",
    "start": "105600",
    "end": "107840"
  },
  {
    "text": "of",
    "start": "107840",
    "end": "108719"
  },
  {
    "text": "them so briefly uh just a quick picture",
    "start": "108719",
    "end": "113280"
  },
  {
    "text": "of the you know Hardware right because",
    "start": "113280",
    "end": "115479"
  },
  {
    "text": "people always have questions about this",
    "start": "115479",
    "end": "116920"
  },
  {
    "text": "so in IBM research we've been building",
    "start": "116920",
    "end": "118520"
  },
  {
    "text": "the next generation of of cloud native",
    "start": "118520",
    "end": "120920"
  },
  {
    "text": "AI supercomputers so the key word here",
    "start": "120920",
    "end": "122759"
  },
  {
    "text": "of course is cloud native which means",
    "start": "122759",
    "end": "125280"
  },
  {
    "text": "different things the the first obvious",
    "start": "125280",
    "end": "127000"
  },
  {
    "text": "one is mean running on kubernetes or in",
    "start": "127000",
    "end": "129319"
  },
  {
    "text": "our case on open shifts but it it's more",
    "start": "129319",
    "end": "131959"
  },
  {
    "text": "than that it means also being able to",
    "start": "131959",
    "end": "133599"
  },
  {
    "text": "scale from very small systems to very",
    "start": "133599",
    "end": "135599"
  },
  {
    "text": "large systems to actually dynamically",
    "start": "135599",
    "end": "137720"
  },
  {
    "text": "scale right as we're running and so on",
    "start": "137720",
    "end": "140200"
  },
  {
    "text": "right and in research we've been uh in",
    "start": "140200",
    "end": "142519"
  },
  {
    "text": "particular pushing the limits on how",
    "start": "142519",
    "end": "144800"
  },
  {
    "text": "large we can get kubernetes right how",
    "start": "144800",
    "end": "146640"
  },
  {
    "text": "many hundreds of nodes you know growing",
    "start": "146640",
    "end": "148720"
  },
  {
    "text": "clusters like that but what we really",
    "start": "148720",
    "end": "150519"
  },
  {
    "text": "want at the end of the day is the",
    "start": "150519",
    "end": "152080"
  },
  {
    "text": "ability to either pull you know large",
    "start": "152080",
    "end": "153920"
  },
  {
    "text": "number of nodes in large clusters or",
    "start": "153920",
    "end": "155720"
  },
  {
    "text": "maybe you know rapidly switch",
    "start": "155720",
    "end": "157400"
  },
  {
    "text": "configuration divide that into many",
    "start": "157400",
    "end": "159159"
  },
  {
    "text": "small clusters if that's um you know",
    "start": "159159",
    "end": "161800"
  },
  {
    "text": "more adequate for what we want to do",
    "start": "161800",
    "end": "163440"
  },
  {
    "text": "with them we've also heard for instance",
    "start": "163440",
    "end": "165959"
  },
  {
    "text": "from BR earlier today some numbers about",
    "start": "165959",
    "end": "168519"
  },
  {
    "text": "V the cost of virtualization the cost of",
    "start": "168519",
    "end": "170680"
  },
  {
    "text": "kubernetes and so on and you know we",
    "start": "170680",
    "end": "172360"
  },
  {
    "text": "concur we believe we can do that with uh",
    "start": "172360",
    "end": "175640"
  },
  {
    "text": "uh very low",
    "start": "175640",
    "end": "178040"
  },
  {
    "text": "overhead so this is for instance a",
    "start": "178040",
    "end": "181120"
  },
  {
    "text": "screen capture of a dashboard that we",
    "start": "181120",
    "end": "184400"
  },
  {
    "text": "built from this cluster you know",
    "start": "184400",
    "end": "186400"
  },
  {
    "text": "sometimes early this year where we were",
    "start": "186400",
    "end": "188480"
  },
  {
    "text": "ramping up and starting to deploy our",
    "start": "188480",
    "end": "190799"
  },
  {
    "text": "software stack on these systems and at",
    "start": "190799",
    "end": "193000"
  },
  {
    "text": "the time there were about 100 I mean",
    "start": "193000",
    "end": "195440"
  },
  {
    "text": "1,00 a100 gpus on this system and you",
    "start": "195440",
    "end": "199000"
  },
  {
    "text": "know the important point and the B thing",
    "start": "199000",
    "end": "200920"
  },
  {
    "text": "we're going to talk about today is we",
    "start": "200920",
    "end": "202640"
  },
  {
    "text": "want this system to be fully utilized",
    "start": "202640",
    "end": "205239"
  },
  {
    "text": "right the number of you know idle gpus",
    "start": "205239",
    "end": "208000"
  },
  {
    "text": "uh needs to be really really low for",
    "start": "208000",
    "end": "210159"
  },
  {
    "text": "everybody to be happy so um now when we",
    "start": "210159",
    "end": "214280"
  },
  {
    "text": "talk about these systems okay there's a",
    "start": "214280",
    "end": "215720"
  },
  {
    "text": "hardware but the next question is what's",
    "start": "215720",
    "end": "217760"
  },
  {
    "text": "the software for this and you know if we",
    "start": "217760",
    "end": "219879"
  },
  {
    "text": "want to build good software for this we",
    "start": "219879",
    "end": "221200"
  },
  {
    "text": "have to start with user requirements",
    "start": "221200",
    "end": "223439"
  },
  {
    "text": "right and obviously no matter the users",
    "start": "223439",
    "end": "225720"
  },
  {
    "text": "there are a few things that are going to",
    "start": "225720",
    "end": "226879"
  },
  {
    "text": "transcend every user category we want",
    "start": "226879",
    "end": "229200"
  },
  {
    "text": "performance performance performance of",
    "start": "229200",
    "end": "231120"
  },
  {
    "text": "course we want people want to know",
    "start": "231120",
    "end": "233079"
  },
  {
    "text": "what's going on with the system so we",
    "start": "233079",
    "end": "234439"
  },
  {
    "text": "want observability but beyond that we",
    "start": "234439",
    "end": "236680"
  },
  {
    "text": "have to look a little bit more carefully",
    "start": "236680",
    "end": "238519"
  },
  {
    "text": "so the obvious first class of users on",
    "start": "238519",
    "end": "240680"
  },
  {
    "text": "these systems are the uh data scientists",
    "start": "240680",
    "end": "243799"
  },
  {
    "text": "the AI experts that are actually using",
    "start": "243799",
    "end": "246560"
  },
  {
    "text": "the systems to do what it's supposed to",
    "start": "246560",
    "end": "248360"
  },
  {
    "text": "do which is to train or validate Etc uh",
    "start": "248360",
    "end": "251120"
  },
  {
    "text": "large models and they have requirements",
    "start": "251120",
    "end": "254159"
  },
  {
    "text": "such as using the framework of their",
    "start": "254159",
    "end": "255879"
  },
  {
    "text": "choice right maybe they do uh the actual",
    "start": "255879",
    "end": "258600"
  },
  {
    "text": "pre-training of the models using pytorch",
    "start": "258600",
    "end": "260680"
  },
  {
    "text": "but for data preparation they want to",
    "start": "260680",
    "end": "262400"
  },
  {
    "text": "use Ray right and what they really want",
    "start": "262400",
    "end": "265240"
  },
  {
    "text": "is to just be able to submit jobs to",
    "start": "265240",
    "end": "267160"
  },
  {
    "text": "these systems and and forget about them",
    "start": "267160",
    "end": "269160"
  },
  {
    "text": "right in the sense that the system will",
    "start": "269160",
    "end": "270720"
  },
  {
    "text": "take care of them will babysit the jobs",
    "start": "270720",
    "end": "272479"
  },
  {
    "text": "maybe the job will run for weeks maybe",
    "start": "272479",
    "end": "275160"
  },
  {
    "text": "the jobs will start tomorrow right the",
    "start": "275160",
    "end": "277039"
  },
  {
    "text": "jobs are just run when when the time is",
    "start": "277039",
    "end": "279360"
  },
  {
    "text": "right and the system as much as possible",
    "start": "279360",
    "end": "281440"
  },
  {
    "text": "should should take care of all the small",
    "start": "281440",
    "end": "283199"
  },
  {
    "text": "things that can happen when you run the",
    "start": "283199",
    "end": "284520"
  },
  {
    "text": "job like a note crashing or two or three",
    "start": "284520",
    "end": "286759"
  },
  {
    "text": "or GPU or a PCI link Etc we'll we'll",
    "start": "286759",
    "end": "289199"
  },
  {
    "text": "talk about this more first category and",
    "start": "289199",
    "end": "292080"
  },
  {
    "text": "really the main characteristics of the",
    "start": "292080",
    "end": "293720"
  },
  {
    "text": "users is no matter what we want they are",
    "start": "293720",
    "end": "296360"
  },
  {
    "text": "experts they are not kubernetes experts",
    "start": "296360",
    "end": "298440"
  },
  {
    "text": "and and frankly they're making a lot",
    "start": "298440",
    "end": "300039"
  },
  {
    "text": "more money being AI experts than",
    "start": "300039",
    "end": "301800"
  },
  {
    "text": "kubernetes experts so it's not going to",
    "start": "301800",
    "end": "303720"
  },
  {
    "text": "change right the second category of",
    "start": "303720",
    "end": "305800"
  },
  {
    "text": "users is AD me the people that are there",
    "start": "305800",
    "end": "308720"
  },
  {
    "text": "to keep the system running and what they",
    "start": "308720",
    "end": "310520"
  },
  {
    "text": "want is the maximum flexibility and the",
    "start": "310520",
    "end": "312680"
  },
  {
    "text": "minimum effort but what they also are is",
    "start": "312680",
    "end": "315639"
  },
  {
    "text": "you know they live and breathe",
    "start": "315639",
    "end": "316600"
  },
  {
    "text": "kubernetes so they want to see the",
    "start": "316600",
    "end": "318240"
  },
  {
    "text": "system through the kubernetes lens",
    "start": "318240",
    "end": "321039"
  },
  {
    "text": "because that's what I understand and",
    "start": "321039",
    "end": "323240"
  },
  {
    "text": "finally of course we have executive",
    "start": "323240",
    "end": "326000"
  },
  {
    "text": "accountants you know never to forget so",
    "start": "326000",
    "end": "328080"
  },
  {
    "text": "people were there to decide what's is",
    "start": "328080",
    "end": "330240"
  },
  {
    "text": "important what's going to run on what",
    "start": "330240",
    "end": "332280"
  },
  {
    "text": "day what are the quotas what are the",
    "start": "332280",
    "end": "333800"
  },
  {
    "text": "priorities and so on want to make sure",
    "start": "333800",
    "end": "336000"
  },
  {
    "text": "that we actually the money that is spent",
    "start": "336000",
    "end": "338120"
  },
  {
    "text": "on this system is actually uh you know",
    "start": "338120",
    "end": "341240"
  },
  {
    "text": "giving us a return on inst investment so",
    "start": "341240",
    "end": "343400"
  },
  {
    "text": "utilization is high we can scale on",
    "start": "343400",
    "end": "345759"
  },
  {
    "text": "demands and so on and so forth so in",
    "start": "345759",
    "end": "348880"
  },
  {
    "text": "order to serve all these uh category of",
    "start": "348880",
    "end": "352440"
  },
  {
    "text": "users we've been building a stack in",
    "start": "352440",
    "end": "354319"
  },
  {
    "text": "open source so all we're going to talk",
    "start": "354319",
    "end": "356600"
  },
  {
    "text": "about is actually part of this community",
    "start": "356600",
    "end": "358319"
  },
  {
    "text": "called open data hub",
    "start": "358319",
    "end": "360319"
  },
  {
    "text": "at the top and we'll again describe this",
    "start": "360319",
    "end": "362880"
  },
  {
    "text": "in more details in a minute we have uh",
    "start": "362880",
    "end": "365759"
  },
  {
    "text": "the ml expert facing part of the stack",
    "start": "365759",
    "end": "369000"
  },
  {
    "text": "which call it C SDK which is",
    "start": "369000",
    "end": "371680"
  },
  {
    "text": "essentially you know Jupiter notebook",
    "start": "371680",
    "end": "374000"
  },
  {
    "text": "python that lets you you know describe",
    "start": "374000",
    "end": "376680"
  },
  {
    "text": "Implement jobs run them and so on at the",
    "start": "376680",
    "end": "379479"
  },
  {
    "text": "bottom we have kubernetes or in our case",
    "start": "379479",
    "end": "381599"
  },
  {
    "text": "uh open shifts and in the middle we have",
    "start": "381599",
    "end": "384080"
  },
  {
    "text": "the the meat of the talk for today which",
    "start": "384080",
    "end": "385680"
  },
  {
    "text": "is the workload management system",
    "start": "385680",
    "end": "387319"
  },
  {
    "text": "consisting of a mechanism to batch or",
    "start": "387319",
    "end": "390440"
  },
  {
    "text": "deal with these batch jobs and cue them",
    "start": "390440",
    "end": "393160"
  },
  {
    "text": "and run them and repair them in",
    "start": "393160",
    "end": "394840"
  },
  {
    "text": "necessary and also uh the the matching",
    "start": "394840",
    "end": "397360"
  },
  {
    "text": "component for cluster OS scaling so",
    "start": "397360",
    "end": "400680"
  },
  {
    "text": "before I let uh abishek dive into the",
    "start": "400680",
    "end": "403319"
  },
  {
    "text": "stack I just want to point out that this",
    "start": "403319",
    "end": "405759"
  },
  {
    "text": "is of course only a small piece of the",
    "start": "405759",
    "end": "408440"
  },
  {
    "text": "big puzzle that is you know bringing AI",
    "start": "408440",
    "end": "411080"
  },
  {
    "text": "to the Enterprise right on you know",
    "start": "411080",
    "end": "414160"
  },
  {
    "text": "training in validation to start with you",
    "start": "414160",
    "end": "416080"
  },
  {
    "text": "just look at creating and using a model",
    "start": "416080",
    "end": "418080"
  },
  {
    "text": "is just one part of it but we need once",
    "start": "418080",
    "end": "420319"
  },
  {
    "text": "we have trained and validated models",
    "start": "420319",
    "end": "422520"
  },
  {
    "text": "then we have to fine-tune them then we",
    "start": "422520",
    "end": "424080"
  },
  {
    "text": "have to serve them we have to run them",
    "start": "424080",
    "end": "425960"
  },
  {
    "text": "so we're also working on that and again",
    "start": "425960",
    "end": "427960"
  },
  {
    "text": "the AI piece is just the one piece of",
    "start": "427960",
    "end": "430039"
  },
  {
    "text": "the puzzle data we've heard already said",
    "start": "430039",
    "end": "432840"
  },
  {
    "text": "this multiple times is really critical",
    "start": "432840",
    "end": "434479"
  },
  {
    "text": "to these process so and governance as",
    "start": "434479",
    "end": "437160"
  },
  {
    "text": "well how do we traceability and so on so",
    "start": "437160",
    "end": "439960"
  },
  {
    "text": "of course IBM RADS have uh you know",
    "start": "439960",
    "end": "442919"
  },
  {
    "text": "products services in this in this space",
    "start": "442919",
    "end": "445400"
  },
  {
    "text": "that we're building that are you know uh",
    "start": "445400",
    "end": "448440"
  },
  {
    "text": "uh building on top of the stack we're",
    "start": "448440",
    "end": "450160"
  },
  {
    "text": "going to talk about today I'm not going",
    "start": "450160",
    "end": "451599"
  },
  {
    "text": "to talk about this in this talk but",
    "start": "451599",
    "end": "454039"
  },
  {
    "text": "please uh come to see our booth the IBM",
    "start": "454039",
    "end": "456360"
  },
  {
    "text": "Booth the red ey booth and we can fill",
    "start": "456360",
    "end": "457879"
  },
  {
    "text": "you in with the",
    "start": "457879",
    "end": "459240"
  },
  {
    "text": "details thanks AB",
    "start": "459240",
    "end": "462960"
  },
  {
    "text": "sh thank thank you Oliver hopefully",
    "start": "464440",
    "end": "467240"
  },
  {
    "text": "everyone can hear me we are now going to",
    "start": "467240",
    "end": "469759"
  },
  {
    "text": "learn about the different ingredients of",
    "start": "469759",
    "end": "472240"
  },
  {
    "text": "the stack and then have a view of the",
    "start": "472240",
    "end": "474879"
  },
  {
    "text": "whole recipe let's learn about the first",
    "start": "474879",
    "end": "477639"
  },
  {
    "text": "ingredient of the stack a c flare SDK",
    "start": "477639",
    "end": "480960"
  },
  {
    "text": "it's a simple pythonic interface",
    "start": "480960",
    "end": "482960"
  },
  {
    "text": "typically catered to researchers ml",
    "start": "482960",
    "end": "485680"
  },
  {
    "text": "engineers and data scientists for",
    "start": "485680",
    "end": "487520"
  },
  {
    "text": "interfacing with the T stack using",
    "start": "487520",
    "end": "490159"
  },
  {
    "text": "jupyter notebooks or CLI these users can",
    "start": "490159",
    "end": "493599"
  },
  {
    "text": "submit and create",
    "start": "493599",
    "end": "495520"
  },
  {
    "text": "clusters and submit jobs on the created",
    "start": "495520",
    "end": "498360"
  },
  {
    "text": "clusters using Cod flare SDK few notable",
    "start": "498360",
    "end": "502159"
  },
  {
    "text": "apis of the SDK is the cluster config",
    "start": "502159",
    "end": "504919"
  },
  {
    "text": "object the cluster config object",
    "start": "504919",
    "end": "507319"
  },
  {
    "text": "provides the ability to the users to up",
    "start": "507319",
    "end": "509479"
  },
  {
    "text": "the cluster view details of the cluster",
    "start": "509479",
    "end": "511599"
  },
  {
    "text": "and finally interact with the spawn",
    "start": "511599",
    "end": "513440"
  },
  {
    "text": "clusters by submitting jobs viewing",
    "start": "513440",
    "end": "515880"
  },
  {
    "text": "their statuses and logs and finally per",
    "start": "515880",
    "end": "518919"
  },
  {
    "text": "Performing Cur",
    "start": "518919",
    "end": "521760"
  },
  {
    "text": "operations before we move onto other",
    "start": "522039",
    "end": "524600"
  },
  {
    "text": "ingredients of the stack let's try to",
    "start": "524600",
    "end": "527200"
  },
  {
    "text": "understand difference between",
    "start": "527200",
    "end": "528160"
  },
  {
    "text": "dispatching and scheduling from the",
    "start": "528160",
    "end": "530160"
  },
  {
    "text": "stack lens when a user submits a",
    "start": "530160",
    "end": "533279"
  },
  {
    "text": "workload AKA custom resource it lands",
    "start": "533279",
    "end": "536160"
  },
  {
    "text": "inside uh the mcad Q as shown in the",
    "start": "536160",
    "end": "538680"
  },
  {
    "text": "picture",
    "start": "538680",
    "end": "539920"
  },
  {
    "text": "at some point in time the workload gets",
    "start": "539920",
    "end": "542040"
  },
  {
    "text": "sent to the respective",
    "start": "542040",
    "end": "543959"
  },
  {
    "text": "controller to spawn one or more pods the",
    "start": "543959",
    "end": "547560"
  },
  {
    "text": "process of sending workload to the",
    "start": "547560",
    "end": "549760"
  },
  {
    "text": "controller is",
    "start": "549760",
    "end": "552360"
  },
  {
    "text": "dispatching once the controller creates",
    "start": "552360",
    "end": "554880"
  },
  {
    "text": "PS they rely on the scheduler to bind",
    "start": "554880",
    "end": "557480"
  },
  {
    "text": "such pods to the",
    "start": "557480",
    "end": "559240"
  },
  {
    "text": "nodes this process is called",
    "start": "559240",
    "end": "562440"
  },
  {
    "text": "scheduling since we typically deal with",
    "start": "562440",
    "end": "564839"
  },
  {
    "text": "gang there should be gang scheduled with",
    "start": "564839",
    "end": "567360"
  },
  {
    "text": "packing unable on thep Target",
    "start": "567360",
    "end": "571079"
  },
  {
    "text": "cluster now that we understand queuing",
    "start": "571079",
    "end": "573360"
  },
  {
    "text": "and dispatching let's move on to the",
    "start": "573360",
    "end": "575760"
  },
  {
    "text": "second ingredient of the",
    "start": "575760",
    "end": "577440"
  },
  {
    "text": "stack mcad or multicluster app",
    "start": "577440",
    "end": "580279"
  },
  {
    "text": "dispatcher provides batch Computing",
    "start": "580279",
    "end": "582519"
  },
  {
    "text": "capabilities on multiple kubernetes or",
    "start": "582519",
    "end": "585560"
  },
  {
    "text": "open shift clusters It dispatches app",
    "start": "585560",
    "end": "588560"
  },
  {
    "text": "wrappers when aggregated resources are",
    "start": "588560",
    "end": "591839"
  },
  {
    "text": "available thereby guaranteeing workload",
    "start": "591839",
    "end": "594800"
  },
  {
    "text": "execution and just in time P",
    "start": "594800",
    "end": "598120"
  },
  {
    "text": "creation all this is done with zero code",
    "start": "598120",
    "end": "601279"
  },
  {
    "text": "changes on the target",
    "start": "601279",
    "end": "604079"
  },
  {
    "text": "operator it provides features such as",
    "start": "604079",
    "end": "606600"
  },
  {
    "text": "bring your own scheduler it supports any",
    "start": "606600",
    "end": "609320"
  },
  {
    "text": "Upstream kubernetes scheduler it",
    "start": "609320",
    "end": "611959"
  },
  {
    "text": "supports features like bring your own",
    "start": "611959",
    "end": "614560"
  },
  {
    "text": "framework so you can bring spark Flink",
    "start": "614560",
    "end": "618320"
  },
  {
    "text": "py torch Ray tensorflow",
    "start": "618320",
    "end": "621760"
  },
  {
    "text": "workloads it also provide standard batch",
    "start": "621760",
    "end": "624399"
  },
  {
    "text": "Computing features such as priority",
    "start": "624399",
    "end": "626800"
  },
  {
    "text": "preemption and quota management which",
    "start": "626800",
    "end": "629120"
  },
  {
    "text": "will learn",
    "start": "629120",
    "end": "630279"
  },
  {
    "text": "shortly it provides fall tolerance to",
    "start": "630279",
    "end": "633320"
  },
  {
    "text": "any compute kubernetes",
    "start": "633320",
    "end": "637200"
  },
  {
    "text": "object let's learn a bit more about",
    "start": "638480",
    "end": "641399"
  },
  {
    "text": "bring your own framework capability of",
    "start": "641399",
    "end": "644079"
  },
  {
    "text": "MCAT this is possible with the help of",
    "start": "644079",
    "end": "646639"
  },
  {
    "text": "app rapper",
    "start": "646639",
    "end": "648040"
  },
  {
    "text": "crd we see a few notable sections of the",
    "start": "648040",
    "end": "650839"
  },
  {
    "text": "app rapper crd that is used in the",
    "start": "650839",
    "end": "653600"
  },
  {
    "text": "stack first we see the resource version",
    "start": "653600",
    "end": "656120"
  },
  {
    "text": "and the name in the metadata section we",
    "start": "656120",
    "end": "658680"
  },
  {
    "text": "see Kota trees that are supported bya",
    "start": "658680",
    "end": "661160"
  },
  {
    "text": "label which we'll learn",
    "start": "661160",
    "end": "664519"
  },
  {
    "text": "shortly later we also see priorities",
    "start": "664880",
    "end": "668320"
  },
  {
    "text": "supported in the spec section these are",
    "start": "668320",
    "end": "671440"
  },
  {
    "text": "integer priorities and also we support",
    "start": "671440",
    "end": "674320"
  },
  {
    "text": "fall tolerance in the scheduling spec",
    "start": "674320",
    "end": "676839"
  },
  {
    "text": "stanza the bring your own framework",
    "start": "676839",
    "end": "679079"
  },
  {
    "text": "capability is supported by generic items",
    "start": "679079",
    "end": "682519"
  },
  {
    "text": "it has the ability to wrap or simply",
    "start": "682519",
    "end": "685600"
  },
  {
    "text": "append any custom resource that you want",
    "start": "685600",
    "end": "688440"
  },
  {
    "text": "and it gets sked inside the mcad Q all",
    "start": "688440",
    "end": "691800"
  },
  {
    "text": "this happens with zero code",
    "start": "691800",
    "end": "694200"
  },
  {
    "text": "changes on the target",
    "start": "694200",
    "end": "697600"
  },
  {
    "text": "operator let's talk a bit about fall",
    "start": "697600",
    "end": "700560"
  },
  {
    "text": "tolerance um fall tolerance is needed",
    "start": "700560",
    "end": "703000"
  },
  {
    "text": "for various reasons GPS fail very often",
    "start": "703000",
    "end": "707360"
  },
  {
    "text": "at scale there are degraded PCI links",
    "start": "707360",
    "end": "710760"
  },
  {
    "text": "which slows down the entire training at",
    "start": "710760",
    "end": "713000"
  },
  {
    "text": "scale stuck pods due to VM or node",
    "start": "713000",
    "end": "717360"
  },
  {
    "text": "failures also happen",
    "start": "717360",
    "end": "720079"
  },
  {
    "text": "if nothing there are user errors that",
    "start": "720079",
    "end": "723000"
  },
  {
    "text": "definitely happens in in at scale",
    "start": "723000",
    "end": "726519"
  },
  {
    "text": "scheduling spec stanza in app rapper",
    "start": "726519",
    "end": "728959"
  },
  {
    "text": "provides the capability to Monitor and",
    "start": "728959",
    "end": "731639"
  },
  {
    "text": "maintain the state of the gang it also",
    "start": "731639",
    "end": "734800"
  },
  {
    "text": "has the ability to customize timeout for",
    "start": "734800",
    "end": "737800"
  },
  {
    "text": "the gangs that are submitted by the",
    "start": "737800",
    "end": "740279"
  },
  {
    "text": "user if the above features are enabled",
    "start": "740279",
    "end": "743600"
  },
  {
    "text": "then mcad can recue gang automatically",
    "start": "743600",
    "end": "747399"
  },
  {
    "text": "during failures with the ability to",
    "start": "747399",
    "end": "749800"
  },
  {
    "text": "force terminate stuck",
    "start": "749800",
    "end": "752160"
  },
  {
    "text": "pods to summarize mcad can detect nodes",
    "start": "752160",
    "end": "756079"
  },
  {
    "text": "that are added removed or failed by ning",
    "start": "756079",
    "end": "759360"
  },
  {
    "text": "gangs of",
    "start": "759360",
    "end": "761880"
  },
  {
    "text": "PODS now let's move on to the Kota",
    "start": "762920",
    "end": "765839"
  },
  {
    "text": "management feature or hierarchial Kota",
    "start": "765839",
    "end": "767920"
  },
  {
    "text": "management feature of",
    "start": "767920",
    "end": "769760"
  },
  {
    "text": "mcad let's try to understand this with",
    "start": "769760",
    "end": "772680"
  },
  {
    "text": "the below borrowing",
    "start": "772680",
    "end": "774440"
  },
  {
    "text": "example consider a simple Kota tree with",
    "start": "774440",
    "end": "777680"
  },
  {
    "text": "root that has has all the cluster",
    "start": "777680",
    "end": "779959"
  },
  {
    "text": "resources and leaf nodes have respective",
    "start": "779959",
    "end": "783120"
  },
  {
    "text": "quotas when a user submits app rapper",
    "start": "783120",
    "end": "786480"
  },
  {
    "text": "one with the below resource requirements",
    "start": "786480",
    "end": "789760"
  },
  {
    "text": "to Team B we can see that Team B does",
    "start": "789760",
    "end": "793000"
  },
  {
    "text": "not have enough Kota to satisfy the",
    "start": "793000",
    "end": "795800"
  },
  {
    "text": "resource requirement of Apper",
    "start": "795800",
    "end": "798199"
  },
  {
    "text": "one when this happens since there are no",
    "start": "798199",
    "end": "801079"
  },
  {
    "text": "other jobs running inside the cluster",
    "start": "801079",
    "end": "803440"
  },
  {
    "text": "mcad automatically borrows Kota from",
    "start": "803440",
    "end": "806279"
  },
  {
    "text": "Team a and allows the app rapper one to",
    "start": "806279",
    "end": "810839"
  },
  {
    "text": "run this is really important if you want",
    "start": "810839",
    "end": "813519"
  },
  {
    "text": "to increase the cluster utilization when",
    "start": "813519",
    "end": "816160"
  },
  {
    "text": "there are idle resources in the",
    "start": "816160",
    "end": "818560"
  },
  {
    "text": "cluster at some point in time a user",
    "start": "818560",
    "end": "821240"
  },
  {
    "text": "submits app rapper 2 which is now part",
    "start": "821240",
    "end": "824000"
  },
  {
    "text": "of Team a as we can see Team a the",
    "start": "824000",
    "end": "828000"
  },
  {
    "text": "resource requirements of app rapper 2",
    "start": "828000",
    "end": "830199"
  },
  {
    "text": "are well within team A's Kota but team a",
    "start": "830199",
    "end": "833800"
  },
  {
    "text": "has been sharing its quota with Team B",
    "start": "833800",
    "end": "838000"
  },
  {
    "text": "mcad real izes that and as a part of",
    "start": "838000",
    "end": "840720"
  },
  {
    "text": "fair share mechanism mcad would preempt",
    "start": "840720",
    "end": "843560"
  },
  {
    "text": "app rapper 1 and allow app rapper 2 um",
    "start": "843560",
    "end": "847320"
  },
  {
    "text": "to",
    "start": "847320",
    "end": "849519"
  },
  {
    "text": "run when um MCAT does COTA and resource",
    "start": "849639",
    "end": "854079"
  },
  {
    "text": "check both to dispatch an app rapper if",
    "start": "854079",
    "end": "857680"
  },
  {
    "text": "the resource check fails then mcad would",
    "start": "857680",
    "end": "860040"
  },
  {
    "text": "trigger insta scaling which we'll learn",
    "start": "860040",
    "end": "862360"
  },
  {
    "text": "a bit more",
    "start": "862360",
    "end": "864199"
  },
  {
    "text": "shortly but from our experience Kota may",
    "start": "864199",
    "end": "867240"
  },
  {
    "text": "not be always physical res sources for",
    "start": "867240",
    "end": "870279"
  },
  {
    "text": "instance some workload may need tokens",
    "start": "870279",
    "end": "872519"
  },
  {
    "text": "or licenses to be shared amongst users",
    "start": "872519",
    "end": "875920"
  },
  {
    "text": "to enable this use case mcad supports",
    "start": "875920",
    "end": "878959"
  },
  {
    "text": "Kota Forest evaluation meaning mcad can",
    "start": "878959",
    "end": "882199"
  },
  {
    "text": "evaluate multiple Kota trees before an",
    "start": "882199",
    "end": "885560"
  },
  {
    "text": "app rapper is",
    "start": "885560",
    "end": "888279"
  },
  {
    "text": "dispatched let's talk a bit about bring",
    "start": "888600",
    "end": "891079"
  },
  {
    "text": "your own schedular capability different",
    "start": "891079",
    "end": "894320"
  },
  {
    "text": "teams in V superc computer run different",
    "start": "894320",
    "end": "897959"
  },
  {
    "text": "types of workload",
    "start": "897959",
    "end": "899320"
  },
  {
    "text": "Lo even open shift prefers running open",
    "start": "899320",
    "end": "903079"
  },
  {
    "text": "shift default scheduler to bind system",
    "start": "903079",
    "end": "905160"
  },
  {
    "text": "ports hence in V supercomputer for",
    "start": "905160",
    "end": "907880"
  },
  {
    "text": "training workloads we use core schedular",
    "start": "907880",
    "end": "910240"
  },
  {
    "text": "with packing at GPU Dimension to avoid",
    "start": "910240",
    "end": "913000"
  },
  {
    "text": "fragmentation at dispatch time and",
    "start": "913000",
    "end": "915279"
  },
  {
    "text": "potentially increase",
    "start": "915279",
    "end": "918480"
  },
  {
    "text": "utilization we covered a lot of internal",
    "start": "919279",
    "end": "922240"
  },
  {
    "text": "features now let's visit UI aspect of",
    "start": "922240",
    "end": "925959"
  },
  {
    "text": "mcad mcad has dashboard that supports",
    "start": "925959",
    "end": "929519"
  },
  {
    "text": "different personas it shows aggregate",
    "start": "929519",
    "end": "932199"
  },
  {
    "text": "cluster utilization from admin Persona",
    "start": "932199",
    "end": "935120"
  },
  {
    "text": "and also shows app rapper statuses from",
    "start": "935120",
    "end": "937880"
  },
  {
    "text": "user",
    "start": "937880",
    "end": "940279"
  },
  {
    "text": "Persona let's move on to the next",
    "start": "941199",
    "end": "943399"
  },
  {
    "text": "ingredient in a",
    "start": "943399",
    "end": "946319"
  },
  {
    "text": "recipe which is the node autoscaler",
    "start": "946319",
    "end": "948720"
  },
  {
    "text": "called insta scale if an app rapper is",
    "start": "948720",
    "end": "951800"
  },
  {
    "text": "pending inside mcad Q due to",
    "start": "951800",
    "end": "954000"
  },
  {
    "text": "insufficient resources then instascale",
    "start": "954000",
    "end": "956399"
  },
  {
    "text": "picks up such app rappers to get gang of",
    "start": "956399",
    "end": "958600"
  },
  {
    "text": "of resources needed to run app",
    "start": "958600",
    "end": "961480"
  },
  {
    "text": "rappers acquiring gang resources could",
    "start": "961480",
    "end": "964199"
  },
  {
    "text": "be timec consuming hence we use reuse",
    "start": "964199",
    "end": "967040"
  },
  {
    "text": "policies to transfer resources acquired",
    "start": "967040",
    "end": "970120"
  },
  {
    "text": "for previous workloads to the next",
    "start": "970120",
    "end": "973480"
  },
  {
    "text": "workload it has the capability to scale",
    "start": "973480",
    "end": "976480"
  },
  {
    "text": "down to zero and works on wide variety",
    "start": "976480",
    "end": "979560"
  },
  {
    "text": "of open shift",
    "start": "979560",
    "end": "982199"
  },
  {
    "text": "flavors finally let's see the entire",
    "start": "983600",
    "end": "986319"
  },
  {
    "text": "recipe with all the ingredients added",
    "start": "986319",
    "end": "990120"
  },
  {
    "text": "users would use code flare SDK to create",
    "start": "990120",
    "end": "993800"
  },
  {
    "text": "and interact with the cluster through",
    "start": "993800",
    "end": "996040"
  },
  {
    "text": "Jupiter notebooks or",
    "start": "996040",
    "end": "998279"
  },
  {
    "text": "CLI these workloads are then cued in",
    "start": "998279",
    "end": "1001279"
  },
  {
    "text": "mcad as app",
    "start": "1001279",
    "end": "1002880"
  },
  {
    "text": "rappers if every aggregated resources",
    "start": "1002880",
    "end": "1005759"
  },
  {
    "text": "are available in the cluster then such",
    "start": "1005759",
    "end": "1008040"
  },
  {
    "text": "app rappers are",
    "start": "1008040",
    "end": "1009480"
  },
  {
    "text": "dispatched or pending app",
    "start": "1009480",
    "end": "1013959"
  },
  {
    "text": "rappers would knock the doors of insta",
    "start": "1014800",
    "end": "1017399"
  },
  {
    "text": "scale controller",
    "start": "1017399",
    "end": "1019800"
  },
  {
    "text": "inser scale controller would acquire",
    "start": "1019800",
    "end": "1022160"
  },
  {
    "text": "gang of resources and add it to the",
    "start": "1022160",
    "end": "1024480"
  },
  {
    "text": "cluster and at later point in time would",
    "start": "1024480",
    "end": "1027558"
  },
  {
    "text": "dispatch the pending app rapper to the",
    "start": "1027559",
    "end": "1031720"
  },
  {
    "text": "cluster once the app rappers are",
    "start": "1031720",
    "end": "1034000"
  },
  {
    "text": "dispatched respective controller then",
    "start": "1034000",
    "end": "1036400"
  },
  {
    "text": "spawns",
    "start": "1036400",
    "end": "1038319"
  },
  {
    "text": "boards which get binded by the scheduler",
    "start": "1038319",
    "end": "1042120"
  },
  {
    "text": "in our use case we use coer with",
    "start": "1042120",
    "end": "1046319"
  },
  {
    "text": "packing later users start interacting",
    "start": "1046319",
    "end": "1049400"
  },
  {
    "text": "with the spawn",
    "start": "1049400",
    "end": "1051039"
  },
  {
    "text": "workload and finally when done the",
    "start": "1051039",
    "end": "1053760"
  },
  {
    "text": "cluster could be destroyed with curred",
    "start": "1053760",
    "end": "1055919"
  },
  {
    "text": "operations supported by the",
    "start": "1055919",
    "end": "1058360"
  },
  {
    "text": "SDK hope you learned a little bit more",
    "start": "1058360",
    "end": "1060880"
  },
  {
    "text": "about all the ingredients of the stack",
    "start": "1060880",
    "end": "1063120"
  },
  {
    "text": "I'll now pass on to",
    "start": "1063120",
    "end": "1066440"
  },
  {
    "text": "Olivia thanks abek so to to recap what",
    "start": "1069280",
    "end": "1073679"
  },
  {
    "text": "we've seen today we've talked about MCAT",
    "start": "1073679",
    "end": "1075520"
  },
  {
    "text": "we've talked about instascale right",
    "start": "1075520",
    "end": "1077840"
  },
  {
    "text": "there are this is dispatching systems to",
    "start": "1077840",
    "end": "1080480"
  },
  {
    "text": "dealing with large distributed workloads",
    "start": "1080480",
    "end": "1082760"
  },
  {
    "text": "such as the one we find in AI training",
    "start": "1082760",
    "end": "1085120"
  },
  {
    "text": "right one of the key characteristics",
    "start": "1085120",
    "end": "1087280"
  },
  {
    "text": "there is we're looking at jobs that",
    "start": "1087280",
    "end": "1089080"
  },
  {
    "text": "consist that use a large number of gpus",
    "start": "1089080",
    "end": "1091480"
  },
  {
    "text": "therefore a very large number of nodes",
    "start": "1091480",
    "end": "1093520"
  },
  {
    "text": "hundreds of nodes typically on the",
    "start": "1093520",
    "end": "1095280"
  },
  {
    "text": "cluster and therefore a large number of",
    "start": "1095280",
    "end": "1098120"
  },
  {
    "text": "PODS because we have one POD at least",
    "start": "1098120",
    "end": "1100559"
  },
  {
    "text": "running on each note right what that led",
    "start": "1100559",
    "end": "1102760"
  },
  {
    "text": "to is the design decision in MC that we",
    "start": "1102760",
    "end": "1105440"
  },
  {
    "text": "cannot just cods or scale B based on",
    "start": "1105440",
    "end": "1109080"
  },
  {
    "text": "pods because you know if we want to quue",
    "start": "1109080",
    "end": "1111400"
  },
  {
    "text": "10 different jobs that's a th000 pods if",
    "start": "1111400",
    "end": "1113280"
  },
  {
    "text": "we want to queue 100 different jobs",
    "start": "1113280",
    "end": "1115280"
  },
  {
    "text": "that's 10,000 pods so everything in mcad",
    "start": "1115280",
    "end": "1118000"
  },
  {
    "text": "everything in instascale is designed to",
    "start": "1118000",
    "end": "1120159"
  },
  {
    "text": "work with custom resource definitions",
    "start": "1120159",
    "end": "1123200"
  },
  {
    "text": "like python jobs Ray jobs batch jobs you",
    "start": "1123200",
    "end": "1127360"
  },
  {
    "text": "name it right the second design decision",
    "start": "1127360",
    "end": "1129600"
  },
  {
    "text": "that U Abby Shake also insisted on is we",
    "start": "1129600",
    "end": "1132600"
  },
  {
    "text": "wanted this to be completely extensible",
    "start": "1132600",
    "end": "1135000"
  },
  {
    "text": "in the sense that you know kubernetes is",
    "start": "1135000",
    "end": "1138159"
  },
  {
    "text": "is is popular to a large degree because",
    "start": "1138159",
    "end": "1140240"
  },
  {
    "text": "it's extensible so everybody has its own",
    "start": "1140240",
    "end": "1143480"
  },
  {
    "text": "you know lots of companies have their",
    "start": "1143480",
    "end": "1144919"
  },
  {
    "text": "own operators their own resour and so on",
    "start": "1144919",
    "end": "1147240"
  },
  {
    "text": "right so we wanted mccat out of the box",
    "start": "1147240",
    "end": "1149600"
  },
  {
    "text": "to work with any such things without",
    "start": "1149600",
    "end": "1152000"
  },
  {
    "text": "requiring any changes of any kind right",
    "start": "1152000",
    "end": "1154000"
  },
  {
    "text": "so if you have your own operator if you",
    "start": "1154000",
    "end": "1156159"
  },
  {
    "text": "have own your own resource type your own",
    "start": "1156159",
    "end": "1159320"
  },
  {
    "text": "kind in kubernetes you know it already",
    "start": "1159320",
    "end": "1161159"
  },
  {
    "text": "works with MCAT there's nothing to do",
    "start": "1161159",
    "end": "1162799"
  },
  {
    "text": "there right and and so so and insta",
    "start": "1162799",
    "end": "1167200"
  },
  {
    "text": "scale in the same way",
    "start": "1167200",
    "end": "1168840"
  },
  {
    "text": "uh can um can make scheding can make you",
    "start": "1168840",
    "end": "1173919"
  },
  {
    "text": "know um sorry scaling decisions not just",
    "start": "1173919",
    "end": "1176679"
  },
  {
    "text": "based on the pods that are pending but",
    "start": "1176679",
    "end": "1178520"
  },
  {
    "text": "on everything that is in the queue right",
    "start": "1178520",
    "end": "1181240"
  },
  {
    "text": "so now that's that's what we talked",
    "start": "1181240",
    "end": "1183679"
  },
  {
    "text": "about today you know the elephant is the",
    "start": "1183679",
    "end": "1185600"
  },
  {
    "text": "room is what we didn't talk about today",
    "start": "1185600",
    "end": "1187440"
  },
  {
    "text": "which is mcad stands for multicluster",
    "start": "1187440",
    "end": "1189679"
  },
  {
    "text": "app dispatcher right so in fact mcad",
    "start": "1189679",
    "end": "1192440"
  },
  {
    "text": "started as a multicluster thing in",
    "start": "1192440",
    "end": "1195320"
  },
  {
    "text": "contrast with maybe some of the other",
    "start": "1195320",
    "end": "1196640"
  },
  {
    "text": "projects we've talked about today where",
    "start": "1196640",
    "end": "1198600"
  },
  {
    "text": "we're evolving from single cluster to",
    "start": "1198600",
    "end": "1200360"
  },
  {
    "text": "multicluster we kind of did the reverse",
    "start": "1200360",
    "end": "1202240"
  },
  {
    "text": "in MCAT which we started with the",
    "start": "1202240",
    "end": "1203960"
  },
  {
    "text": "multicluster use case that's where we",
    "start": "1203960",
    "end": "1205559"
  },
  {
    "text": "came from eventually for instance in",
    "start": "1205559",
    "end": "1207440"
  },
  {
    "text": "training we realized that the single",
    "start": "1207440",
    "end": "1209200"
  },
  {
    "text": "cluster case was also really important",
    "start": "1209200",
    "end": "1211120"
  },
  {
    "text": "and so in the last couple of years at",
    "start": "1211120",
    "end": "1213240"
  },
  {
    "text": "least we' we've put the focus on that",
    "start": "1213240",
    "end": "1215120"
  },
  {
    "text": "but mcad still is a multicluster app",
    "start": "1215120",
    "end": "1217720"
  },
  {
    "text": "dispatcher it can manage a pool of",
    "start": "1217720",
    "end": "1220320"
  },
  {
    "text": "cluster a dynamic pool of cluster you",
    "start": "1220320",
    "end": "1222320"
  },
  {
    "text": "can add and remove clusters it can",
    "start": "1222320",
    "end": "1224400"
  },
  {
    "text": "monitor resource and make you know uh",
    "start": "1224400",
    "end": "1226960"
  },
  {
    "text": "decisions about quotas and resource",
    "start": "1226960",
    "end": "1228600"
  },
  {
    "text": "about different clusters and it can make",
    "start": "1228600",
    "end": "1230919"
  },
  {
    "text": "scheduling decisions based on resource",
    "start": "1230919",
    "end": "1233360"
  },
  {
    "text": "availability right so now a little bit",
    "start": "1233360",
    "end": "1235679"
  },
  {
    "text": "about our road map there's a lot of",
    "start": "1235679",
    "end": "1237200"
  },
  {
    "text": "things we want to do again similar to",
    "start": "1237200",
    "end": "1239400"
  },
  {
    "text": "things you've heard today right today",
    "start": "1239400",
    "end": "1241280"
  },
  {
    "text": "mcad is only about or mcad like many",
    "start": "1241280",
    "end": "1244000"
  },
  {
    "text": "systems thinks about gpus as as as units",
    "start": "1244000",
    "end": "1246960"
  },
  {
    "text": "right a GPU goes to this job or that job",
    "start": "1246960",
    "end": "1249480"
  },
  {
    "text": "or that job but we know for instance",
    "start": "1249480",
    "end": "1251039"
  },
  {
    "text": "with mvidia with MPS with Mig with Dr",
    "start": "1251039",
    "end": "1254400"
  },
  {
    "text": "that there are lot of mechanisms coming",
    "start": "1254400",
    "end": "1256080"
  },
  {
    "text": "up about dividing gpus and being smart",
    "start": "1256080",
    "end": "1258799"
  },
  {
    "text": "about uh you know again uh sharing gpus",
    "start": "1258799",
    "end": "1262039"
  },
  {
    "text": "between different jobs in various ways",
    "start": "1262039",
    "end": "1263559"
  },
  {
    "text": "so that's obviously something we're",
    "start": "1263559",
    "end": "1265280"
  },
  {
    "text": "working on and want to support uh one",
    "start": "1265280",
    "end": "1268720"
  },
  {
    "text": "important dimension of a dispatching",
    "start": "1268720",
    "end": "1270679"
  },
  {
    "text": "system is in which order do we dispatch",
    "start": "1270679",
    "end": "1273200"
  },
  {
    "text": "job when do we dispatch job that's",
    "start": "1273200",
    "end": "1275279"
  },
  {
    "text": "that's something you know mcap provides",
    "start": "1275279",
    "end": "1277000"
  },
  {
    "text": "a foundation for this and that's",
    "start": "1277000",
    "end": "1278799"
  },
  {
    "text": "something we're building on to do new",
    "start": "1278799",
    "end": "1280200"
  },
  {
    "text": "interesting things again we've heard",
    "start": "1280200",
    "end": "1282080"
  },
  {
    "text": "already today about the cost to the",
    "start": "1282080",
    "end": "1284799"
  },
  {
    "text": "planet uh for you know training large",
    "start": "1284799",
    "end": "1287440"
  },
  {
    "text": "models and doing AI so we're working on",
    "start": "1287440",
    "end": "1290159"
  },
  {
    "text": "on various policies there and extensions",
    "start": "1290159",
    "end": "1292880"
  },
  {
    "text": "for instance to do um to do training or",
    "start": "1292880",
    "end": "1295880"
  },
  {
    "text": "to do to do badge jobs in general I",
    "start": "1295880",
    "end": "1299039"
  },
  {
    "text": "should say that are you know uh more",
    "start": "1299039",
    "end": "1302440"
  },
  {
    "text": "power efficient or you know that use",
    "start": "1302440",
    "end": "1305279"
  },
  {
    "text": "Greener energies right that chooses",
    "start": "1305279",
    "end": "1307240"
  },
  {
    "text": "clusters depending on the time of the",
    "start": "1307240",
    "end": "1308919"
  },
  {
    "text": "day and so on and so",
    "start": "1308919",
    "end": "1310440"
  },
  {
    "text": "forth finally uh when it comes to",
    "start": "1310440",
    "end": "1313360"
  },
  {
    "text": "Cluster",
    "start": "1313360",
    "end": "1314440"
  },
  {
    "text": "autoscaling uh cluster autoscaling in",
    "start": "1314440",
    "end": "1317320"
  },
  {
    "text": "general has been a challenge because",
    "start": "1317320",
    "end": "1318840"
  },
  {
    "text": "this is not quite just a problem about",
    "start": "1318840",
    "end": "1320600"
  },
  {
    "text": "the cluster this is a problem about",
    "start": "1320600",
    "end": "1322320"
  },
  {
    "text": "what's hosting the cluster what provider",
    "start": "1322320",
    "end": "1324480"
  },
  {
    "text": "what technology is being used right so",
    "start": "1324480",
    "end": "1327200"
  },
  {
    "text": "cluster Autos scaling has been kind of a",
    "start": "1327200",
    "end": "1329360"
  },
  {
    "text": "you know different from you know uh",
    "start": "1329360",
    "end": "1331520"
  },
  {
    "text": "different Cloud providers and so on so",
    "start": "1331520",
    "end": "1333760"
  },
  {
    "text": "there's and and and in stas scale as it",
    "start": "1333760",
    "end": "1336279"
  },
  {
    "text": "exists today is primarily focused on",
    "start": "1336279",
    "end": "1338039"
  },
  {
    "text": "open shift but there's an effort in the",
    "start": "1338039",
    "end": "1339720"
  },
  {
    "text": "community to kind of standardize that to",
    "start": "1339720",
    "end": "1342400"
  },
  {
    "text": "make it much more portable across",
    "start": "1342400",
    "end": "1344120"
  },
  {
    "text": "providers across kinds of manage",
    "start": "1344120",
    "end": "1346720"
  },
  {
    "text": "clusters and so on and so definitely",
    "start": "1346720",
    "end": "1348480"
  },
  {
    "text": "also very interested in that effort and",
    "start": "1348480",
    "end": "1350440"
  },
  {
    "text": "and bringing that effort to uh mcad and",
    "start": "1350440",
    "end": "1353559"
  },
  {
    "text": "insta scale so uh as I said before",
    "start": "1353559",
    "end": "1357640"
  },
  {
    "text": "everything we discussed today is open",
    "start": "1357640",
    "end": "1359799"
  },
  {
    "text": "source we have a a code flare Community",
    "start": "1359799",
    "end": "1362559"
  },
  {
    "text": "you know GitHub slack here uh please",
    "start": "1362559",
    "end": "1364919"
  },
  {
    "text": "join us uh please let us know what you",
    "start": "1364919",
    "end": "1367640"
  },
  {
    "text": "think uh I also want to point out that",
    "start": "1367640",
    "end": "1370480"
  },
  {
    "text": "later this week we're going to have",
    "start": "1370480",
    "end": "1372000"
  },
  {
    "text": "another talk uh that is going to you",
    "start": "1372000",
    "end": "1374760"
  },
  {
    "text": "know tell you more about MP this",
    "start": "1374760",
    "end": "1376279"
  },
  {
    "text": "particular talk is actually about how to",
    "start": "1376279",
    "end": "1378200"
  },
  {
    "text": "do performance scaling performance",
    "start": "1378200",
    "end": "1380400"
  },
  {
    "text": "testing at scale simulating large",
    "start": "1380400",
    "end": "1383200"
  },
  {
    "text": "clusters and but we'll use mcad as the",
    "start": "1383200",
    "end": "1385640"
  },
  {
    "text": "running example so please come join us",
    "start": "1385640",
    "end": "1388919"
  },
  {
    "text": "and and and and watch Saras and vak talk",
    "start": "1388919",
    "end": "1391520"
  },
  {
    "text": "on",
    "start": "1391520",
    "end": "1392320"
  },
  {
    "text": "Wednesday and I think that's it for",
    "start": "1392320",
    "end": "1394960"
  },
  {
    "text": "today thank you very",
    "start": "1394960",
    "end": "1397960"
  },
  {
    "text": "much thank you so much for the great",
    "start": "1400960",
    "end": "1403120"
  },
  {
    "text": "talk I think we have time for one",
    "start": "1403120",
    "end": "1406600"
  },
  {
    "text": "question I think showed up at the right",
    "start": "1406600",
    "end": "1408720"
  },
  {
    "text": "time yeah I think so I was just going to",
    "start": "1408720",
    "end": "1410919"
  },
  {
    "text": "ask like you find it easy for the ml",
    "start": "1410919",
    "end": "1412520"
  },
  {
    "text": "engineers and the data scientist to plan",
    "start": "1412520",
    "end": "1414520"
  },
  {
    "text": "resources when they're going to write",
    "start": "1414520",
    "end": "1416400"
  },
  {
    "text": "the requests so",
    "start": "1416400",
    "end": "1420240"
  },
  {
    "text": "um you have to repeat the question yeah",
    "start": "1420240",
    "end": "1422559"
  },
  {
    "text": "yeah sorry so the question is do is it",
    "start": "1422559",
    "end": "1424720"
  },
  {
    "text": "easy for engineer to plan resources so",
    "start": "1424720",
    "end": "1427840"
  },
  {
    "text": "uh the the real answer to that is",
    "start": "1427840",
    "end": "1430480"
  },
  {
    "text": "something I could have added to the road",
    "start": "1430480",
    "end": "1432000"
  },
  {
    "text": "map is we're looking at elasticity and",
    "start": "1432000",
    "end": "1434520"
  },
  {
    "text": "all all kinds you know elasticity",
    "start": "1434520",
    "end": "1436640"
  },
  {
    "text": "there's job elasticity there's cluster",
    "start": "1436640",
    "end": "1438360"
  },
  {
    "text": "elasticity qua elasticity so it's kind",
    "start": "1438360",
    "end": "1440600"
  },
  {
    "text": "of holistic question uh but uh so uh we",
    "start": "1440600",
    "end": "1445640"
  },
  {
    "text": "we we we do I mean what what uh AI",
    "start": "1445640",
    "end": "1450159"
  },
  {
    "text": "experts think in terms of is number of",
    "start": "1450159",
    "end": "1452039"
  },
  {
    "text": "gpus and maybe number of nodes right so",
    "start": "1452039",
    "end": "1454640"
  },
  {
    "text": "that's the input essentially to our",
    "start": "1454640",
    "end": "1456520"
  },
  {
    "text": "system that what we work with and that's",
    "start": "1456520",
    "end": "1458880"
  },
  {
    "text": "that's I think works well enough right",
    "start": "1458880",
    "end": "1461440"
  },
  {
    "text": "uh where where they need help is",
    "start": "1461440",
    "end": "1463039"
  },
  {
    "text": "adjusting CPU and memory and so on but",
    "start": "1463039",
    "end": "1465480"
  },
  {
    "text": "we can we can work that from the request",
    "start": "1465480",
    "end": "1468159"
  },
  {
    "text": "for the gpus essentially yeah typically",
    "start": "1468159",
    "end": "1470840"
  },
  {
    "text": "me the workloads that researcher submit",
    "start": "1470840",
    "end": "1472960"
  },
  {
    "text": "in our facility there are they are all",
    "start": "1472960",
    "end": "1475120"
  },
  {
    "text": "gangs and gangs have this notion of all",
    "start": "1475120",
    "end": "1477880"
  },
  {
    "text": "or none right they need all the",
    "start": "1477880",
    "end": "1479919"
  },
  {
    "text": "resources at once to start so they have",
    "start": "1479919",
    "end": "1482840"
  },
  {
    "text": "a good understanding of the scale of",
    "start": "1482840",
    "end": "1485159"
  },
  {
    "text": "their model and the kind of uh gang",
    "start": "1485159",
    "end": "1488039"
  },
  {
    "text": "resources they need to start their",
    "start": "1488039",
    "end": "1490440"
  },
  {
    "text": "computation so at least internally our",
    "start": "1490440",
    "end": "1493600"
  },
  {
    "text": "users and model trainers externally I",
    "start": "1493600",
    "end": "1497080"
  },
  {
    "text": "think I I believe they know what kind of",
    "start": "1497080",
    "end": "1499640"
  },
  {
    "text": "resources they need in a prior before",
    "start": "1499640",
    "end": "1502440"
  },
  {
    "text": "submitting a job and you can always",
    "start": "1502440",
    "end": "1504679"
  },
  {
    "text": "shape that right that's point you put",
    "start": "1504679",
    "end": "1506200"
  },
  {
    "text": "some heuristic to say I think it's this",
    "start": "1506200",
    "end": "1508320"
  },
  {
    "text": "type of thing more or less",
    "start": "1508320",
    "end": "1511080"
  },
  {
    "text": "yeah I had one more question but okay",
    "start": "1511080",
    "end": "1514200"
  },
  {
    "text": "yeah sure on I I saw on one slide you're",
    "start": "1514200",
    "end": "1517480"
  },
  {
    "text": "using Ray for training and then using",
    "start": "1517480",
    "end": "1519880"
  },
  {
    "text": "ker for serving do you have any thoughts",
    "start": "1519880",
    "end": "1522360"
  },
  {
    "text": "on kerve versus Ray serve or did you not",
    "start": "1522360",
    "end": "1526159"
  },
  {
    "text": "have you not explored Ray serve yet so",
    "start": "1526159",
    "end": "1527799"
  },
  {
    "text": "we we've explored race serve uh it",
    "start": "1527799",
    "end": "1531080"
  },
  {
    "text": "initially so we we worked with any scale",
    "start": "1531080",
    "end": "1534880"
  },
  {
    "text": "for a while actually on on on trying to",
    "start": "1534880",
    "end": "1537279"
  },
  {
    "text": "bridge the two together I think this is",
    "start": "1537279",
    "end": "1539000"
  },
  {
    "text": "still still an ongoing discussion uh",
    "start": "1539000",
    "end": "1543000"
  },
  {
    "text": "We've we've had requirements in terms of",
    "start": "1543000",
    "end": "1545320"
  },
  {
    "text": "you know size of collections of models",
    "start": "1545320",
    "end": "1547279"
  },
  {
    "text": "for instance in the or size of q-tune",
    "start": "1547279",
    "end": "1549360"
  },
  {
    "text": "collections of models you know we we we",
    "start": "1549360",
    "end": "1552120"
  },
  {
    "text": "have things where we have hundreds of",
    "start": "1552120",
    "end": "1553320"
  },
  {
    "text": "thousands of models in in in our",
    "start": "1553320",
    "end": "1555120"
  },
  {
    "text": "collections right so racer wasn't Des",
    "start": "1555120",
    "end": "1557720"
  },
  {
    "text": "designed to handle that in the first",
    "start": "1557720",
    "end": "1559080"
  },
  {
    "text": "place but we worked with any scale to a",
    "start": "1559080",
    "end": "1560880"
  },
  {
    "text": "degree to reduce you know um to to to",
    "start": "1560880",
    "end": "1565559"
  },
  {
    "text": "improve on different things right so um",
    "start": "1565559",
    "end": "1568640"
  },
  {
    "text": "I think that's an ongoing that's an",
    "start": "1568640",
    "end": "1570159"
  },
  {
    "text": "ongoing effort yes got it thank you",
    "start": "1570159",
    "end": "1573520"
  },
  {
    "text": "great job thank",
    "start": "1573520",
    "end": "1576720"
  },
  {
    "text": "you",
    "start": "1577679",
    "end": "1580679"
  }
]
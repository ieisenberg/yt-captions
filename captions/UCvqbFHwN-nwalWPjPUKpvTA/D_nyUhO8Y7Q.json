[
  {
    "text": "hello everyone this is feyman from",
    "start": "0",
    "end": "2320"
  },
  {
    "text": "beijing china",
    "start": "2320",
    "end": "4160"
  },
  {
    "text": "it's so glad to be here",
    "start": "4160",
    "end": "6160"
  },
  {
    "text": "it's my second time to attend kubecon eu",
    "start": "6160",
    "end": "9440"
  },
  {
    "text": "and i was looking forward to attending",
    "start": "9440",
    "end": "11200"
  },
  {
    "text": "this meeting in prison since we have a",
    "start": "11200",
    "end": "13759"
  },
  {
    "text": "couple of friends and partners in spain",
    "start": "13759",
    "end": "16480"
  },
  {
    "text": "but unfortunately due to the pandemic",
    "start": "16480",
    "end": "19840"
  },
  {
    "text": "we can only give this speech",
    "start": "19840",
    "end": "21840"
  },
  {
    "text": "at the front of screen",
    "start": "21840",
    "end": "23760"
  },
  {
    "text": "so i hope everything could be recovered",
    "start": "23760",
    "end": "25840"
  },
  {
    "text": "soon and we can meet everyone and have a",
    "start": "25840",
    "end": "28720"
  },
  {
    "text": "cup of coffee in person",
    "start": "28720",
    "end": "31840"
  },
  {
    "text": "so before we get started with this",
    "start": "31840",
    "end": "33600"
  },
  {
    "text": "presentation",
    "start": "33600",
    "end": "35040"
  },
  {
    "text": "let me briefly introduce myself",
    "start": "35040",
    "end": "38880"
  },
  {
    "text": "so my name is feyman joe",
    "start": "38960",
    "end": "41200"
  },
  {
    "text": "i'm from cube sphere team",
    "start": "41200",
    "end": "43280"
  },
  {
    "text": "i'm a senior community manager and qing",
    "start": "43280",
    "end": "45920"
  },
  {
    "text": "cloud cube sphere",
    "start": "45920",
    "end": "47920"
  },
  {
    "text": "and i'm also cncf ambassador cdf",
    "start": "47920",
    "end": "50640"
  },
  {
    "text": "ambassador and fluent member",
    "start": "50640",
    "end": "53600"
  },
  {
    "text": "my skills include but not limited to",
    "start": "53600",
    "end": "55840"
  },
  {
    "text": "kubernetes linux flambeat frontie devops",
    "start": "55840",
    "end": "59520"
  },
  {
    "text": "and servlets",
    "start": "59520",
    "end": "61920"
  },
  {
    "text": "and i'm really enjoying technical",
    "start": "61920",
    "end": "63920"
  },
  {
    "text": "writing advocacy and outreach and host",
    "start": "63920",
    "end": "67119"
  },
  {
    "text": "events",
    "start": "67119",
    "end": "68320"
  },
  {
    "text": "alright in this talk i will demonstrate",
    "start": "68320",
    "end": "71200"
  },
  {
    "text": "how to build a cloud native login",
    "start": "71200",
    "end": "72799"
  },
  {
    "text": "pipeline on the edge with fluent",
    "start": "72799",
    "end": "74880"
  },
  {
    "text": "operator",
    "start": "74880",
    "end": "76320"
  },
  {
    "text": "so in this presentation i will walk you",
    "start": "76320",
    "end": "79119"
  },
  {
    "text": "through the challenges of logging in",
    "start": "79119",
    "end": "80880"
  },
  {
    "text": "kubernetes especially in the enterprise",
    "start": "80880",
    "end": "83439"
  },
  {
    "text": "environment",
    "start": "83439",
    "end": "84880"
  },
  {
    "text": "and next i will introduce two popular",
    "start": "84880",
    "end": "87759"
  },
  {
    "text": "login solutions",
    "start": "87759",
    "end": "89280"
  },
  {
    "text": "you might have ever used or heard about",
    "start": "89280",
    "end": "91439"
  },
  {
    "text": "it",
    "start": "91439",
    "end": "92320"
  },
  {
    "text": "the fluent bait and friendly",
    "start": "92320",
    "end": "94720"
  },
  {
    "text": "and next",
    "start": "94720",
    "end": "96799"
  },
  {
    "text": "i will introduce and demonstrate how",
    "start": "96799",
    "end": "99040"
  },
  {
    "text": "fluent operator empowers fluent bit and",
    "start": "99040",
    "end": "101759"
  },
  {
    "text": "fluently",
    "start": "101759",
    "end": "103920"
  },
  {
    "text": "and then i will give a little bit deep",
    "start": "103920",
    "end": "105680"
  },
  {
    "text": "dive into fluent operator and talk about",
    "start": "105680",
    "end": "108640"
  },
  {
    "text": "this architecture and workflow",
    "start": "108640",
    "end": "112159"
  },
  {
    "text": "and finally i will give a live demo and",
    "start": "112159",
    "end": "115040"
  },
  {
    "text": "talk about this use case in cubesphere",
    "start": "115040",
    "end": "118320"
  },
  {
    "text": "all right",
    "start": "118320",
    "end": "119280"
  },
  {
    "text": "when it comes to the challenges of",
    "start": "119280",
    "end": "121040"
  },
  {
    "text": "logging kubernetes",
    "start": "121040",
    "end": "122799"
  },
  {
    "text": "we always receive some demands and",
    "start": "122799",
    "end": "124640"
  },
  {
    "text": "complaints from different teams for",
    "start": "124640",
    "end": "126560"
  },
  {
    "text": "security and compliance reasons",
    "start": "126560",
    "end": "129920"
  },
  {
    "text": "for example",
    "start": "129920",
    "end": "131280"
  },
  {
    "text": "our developers said that",
    "start": "131280",
    "end": "133280"
  },
  {
    "text": "hey we have a huge amount of logs",
    "start": "133280",
    "end": "135200"
  },
  {
    "text": "produced every day",
    "start": "135200",
    "end": "136879"
  },
  {
    "text": "they come from different data sources",
    "start": "136879",
    "end": "139120"
  },
  {
    "text": "and data formats",
    "start": "139120",
    "end": "140959"
  },
  {
    "text": "our administrators said that",
    "start": "140959",
    "end": "143200"
  },
  {
    "text": "hey you have to make sure",
    "start": "143200",
    "end": "145520"
  },
  {
    "text": "to troubleshoot your logs in a",
    "start": "145520",
    "end": "147200"
  },
  {
    "text": "lightweight and secure solution",
    "start": "147200",
    "end": "151200"
  },
  {
    "text": "you also need to keep everything",
    "start": "151200",
    "end": "152720"
  },
  {
    "text": "traceable",
    "start": "152720",
    "end": "154319"
  },
  {
    "text": "and our security teams requested that",
    "start": "154319",
    "end": "157120"
  },
  {
    "text": "hey could you ship the logs and data to",
    "start": "157120",
    "end": "159440"
  },
  {
    "text": "multiple destinations and outputs to",
    "start": "159440",
    "end": "162720"
  },
  {
    "text": "audit and visualize them",
    "start": "162720",
    "end": "165280"
  },
  {
    "text": "oh man",
    "start": "165280",
    "end": "167120"
  },
  {
    "text": "all of these things are in accounts",
    "start": "167120",
    "end": "169360"
  },
  {
    "text": "right",
    "start": "169360",
    "end": "170560"
  },
  {
    "text": "so",
    "start": "170560",
    "end": "171680"
  },
  {
    "text": "in the real enterprise environment",
    "start": "171680",
    "end": "174720"
  },
  {
    "text": "we actually have some logs come from",
    "start": "174720",
    "end": "177040"
  },
  {
    "text": "different places such as parameter",
    "start": "177040",
    "end": "179360"
  },
  {
    "text": "servers or virtual machines they can",
    "start": "179360",
    "end": "181840"
  },
  {
    "text": "also come from embedded devices edge",
    "start": "181840",
    "end": "185120"
  },
  {
    "text": "container port tcp or udp",
    "start": "185120",
    "end": "189040"
  },
  {
    "text": "and all of those data are in different",
    "start": "189040",
    "end": "191280"
  },
  {
    "text": "data formats",
    "start": "191280",
    "end": "192800"
  },
  {
    "text": "such as json logs apache logs",
    "start": "192800",
    "end": "195920"
  },
  {
    "text": "ngx logs or container locks",
    "start": "195920",
    "end": "199920"
  },
  {
    "text": "and in some typical cases you might want",
    "start": "199920",
    "end": "202480"
  },
  {
    "text": "to shift them to different destinations",
    "start": "202480",
    "end": "204799"
  },
  {
    "text": "such as",
    "start": "204799",
    "end": "205920"
  },
  {
    "text": "elasticsearch or open search",
    "start": "205920",
    "end": "208159"
  },
  {
    "text": "locky splunk mongodb or s3 well",
    "start": "208159",
    "end": "212879"
  },
  {
    "text": "considering data security and",
    "start": "212879",
    "end": "214560"
  },
  {
    "text": "reliability when processing logs in a",
    "start": "214560",
    "end": "217040"
  },
  {
    "text": "multi-tenant environment",
    "start": "217040",
    "end": "219120"
  },
  {
    "text": "you have to isolate the log data and",
    "start": "219120",
    "end": "221440"
  },
  {
    "text": "make it only visible to a specific user",
    "start": "221440",
    "end": "224080"
  },
  {
    "text": "or in a specific namespace",
    "start": "224080",
    "end": "226560"
  },
  {
    "text": "okay",
    "start": "226560",
    "end": "227519"
  },
  {
    "text": "how do you guys debug your kubernetes",
    "start": "227519",
    "end": "229440"
  },
  {
    "text": "workloads in your daily job",
    "start": "229440",
    "end": "232400"
  },
  {
    "text": "i think the native method such as cut",
    "start": "232400",
    "end": "234959"
  },
  {
    "text": "commands is the most popular way for you",
    "start": "234959",
    "end": "237599"
  },
  {
    "text": "to retrieve the logs from a specific",
    "start": "237599",
    "end": "240400"
  },
  {
    "text": "container",
    "start": "240400",
    "end": "242959"
  },
  {
    "text": "apart from that",
    "start": "242959",
    "end": "244640"
  },
  {
    "text": "if you are running your applications and",
    "start": "244640",
    "end": "247200"
  },
  {
    "text": "infrastructure on the public cloud",
    "start": "247200",
    "end": "249840"
  },
  {
    "text": "for example azure on aws",
    "start": "249840",
    "end": "252879"
  },
  {
    "text": "you might also adopt the",
    "start": "252879",
    "end": "255120"
  },
  {
    "text": "logging solutions that are powered by",
    "start": "255120",
    "end": "257040"
  },
  {
    "text": "the cloud providers such as stackdriver",
    "start": "257040",
    "end": "260160"
  },
  {
    "text": "cloudwatch and something like that",
    "start": "260160",
    "end": "263840"
  },
  {
    "text": "so you",
    "start": "263840",
    "end": "265040"
  },
  {
    "text": "you might also find that there are some",
    "start": "265040",
    "end": "267919"
  },
  {
    "text": "sv solutions such as splunk",
    "start": "267919",
    "end": "270639"
  },
  {
    "text": "sim logic data log",
    "start": "270639",
    "end": "272880"
  },
  {
    "text": "etc",
    "start": "272880",
    "end": "274080"
  },
  {
    "text": "so far we also see a lot of popular open",
    "start": "274080",
    "end": "276960"
  },
  {
    "text": "source solutions such as elk loki from",
    "start": "276960",
    "end": "280639"
  },
  {
    "text": "bit and front d",
    "start": "280639",
    "end": "283680"
  },
  {
    "text": "but in this talk",
    "start": "283919",
    "end": "285360"
  },
  {
    "text": "we will only focus on the open source",
    "start": "285360",
    "end": "287440"
  },
  {
    "text": "login solutions like from base and front",
    "start": "287440",
    "end": "290000"
  },
  {
    "text": "d",
    "start": "290000",
    "end": "291360"
  },
  {
    "text": "you know handling data collection as",
    "start": "291360",
    "end": "293680"
  },
  {
    "text": "scale is complex and collecting and",
    "start": "293680",
    "end": "296240"
  },
  {
    "text": "aggregating diverse data requires a",
    "start": "296240",
    "end": "298479"
  },
  {
    "text": "specialized tool that can deal with",
    "start": "298479",
    "end": "301280"
  },
  {
    "text": "the scenarios like",
    "start": "301280",
    "end": "303120"
  },
  {
    "text": "different sources of information",
    "start": "303120",
    "end": "305680"
  },
  {
    "text": "different data formats data reliability",
    "start": "305680",
    "end": "308840"
  },
  {
    "text": "security flexible routing and multiple",
    "start": "308840",
    "end": "311759"
  },
  {
    "text": "destinations",
    "start": "311759",
    "end": "313520"
  },
  {
    "text": "that is why from base comes in",
    "start": "313520",
    "end": "316479"
  },
  {
    "text": "when we take a look back at the history",
    "start": "316479",
    "end": "318639"
  },
  {
    "text": "of floom bait you will find from bit",
    "start": "318639",
    "end": "321440"
  },
  {
    "text": "this project was started in 2015.",
    "start": "321440",
    "end": "325280"
  },
  {
    "text": "now it has been a sincere sub-project",
    "start": "325280",
    "end": "327680"
  },
  {
    "text": "under the umbrella front d ecosystem",
    "start": "327680",
    "end": "330880"
  },
  {
    "text": "from b was written in c",
    "start": "330880",
    "end": "333360"
  },
  {
    "text": "which is a lightweight and zero",
    "start": "333360",
    "end": "335600"
  },
  {
    "text": "dependencies project",
    "start": "335600",
    "end": "337680"
  },
  {
    "text": "from bit is also plugable it has around",
    "start": "337680",
    "end": "340000"
  },
  {
    "text": "70 plugins available",
    "start": "340000",
    "end": "342400"
  },
  {
    "text": "last but not least floom bit is quite",
    "start": "342400",
    "end": "344720"
  },
  {
    "text": "lightweight since it it has low cpu and",
    "start": "344720",
    "end": "348080"
  },
  {
    "text": "memory usage",
    "start": "348080",
    "end": "349520"
  },
  {
    "text": "okay from bit also has monitoring and",
    "start": "349520",
    "end": "352000"
  },
  {
    "text": "string processing capabilities that are",
    "start": "352000",
    "end": "354639"
  },
  {
    "text": "not listed in this slide",
    "start": "354639",
    "end": "356720"
  },
  {
    "text": "so far from bit had reached 1 billion",
    "start": "356720",
    "end": "359440"
  },
  {
    "text": "downloads and has been adopted by",
    "start": "359440",
    "end": "361840"
  },
  {
    "text": "thousands of organizations such as aws",
    "start": "361840",
    "end": "365039"
  },
  {
    "text": "digitalocean",
    "start": "365039",
    "end": "366400"
  },
  {
    "text": "microsoft cube sphere and so on",
    "start": "366400",
    "end": "369680"
  },
  {
    "text": "as you can see from this graph",
    "start": "369680",
    "end": "371520"
  },
  {
    "text": "this is a data pipeline that represents",
    "start": "371520",
    "end": "374240"
  },
  {
    "text": "a flow of data that goes through the",
    "start": "374240",
    "end": "376400"
  },
  {
    "text": "inputs filters and outputs the input",
    "start": "376400",
    "end": "380080"
  },
  {
    "text": "plugin which is used to get the",
    "start": "380080",
    "end": "382319"
  },
  {
    "text": "information from different",
    "start": "382319",
    "end": "384000"
  },
  {
    "text": "data sources password which is used to",
    "start": "384000",
    "end": "386400"
  },
  {
    "text": "convert from unstructured data to",
    "start": "386400",
    "end": "388720"
  },
  {
    "text": "structured data",
    "start": "388720",
    "end": "390240"
  },
  {
    "text": "filter is used to match exclude or",
    "start": "390240",
    "end": "392960"
  },
  {
    "text": "enrich logs with some specific metadata",
    "start": "392960",
    "end": "396160"
  },
  {
    "text": "and output is used to define the",
    "start": "396160",
    "end": "398319"
  },
  {
    "text": "destinations for the data",
    "start": "398319",
    "end": "401199"
  },
  {
    "text": "for example remote services local file",
    "start": "401199",
    "end": "404160"
  },
  {
    "text": "systems",
    "start": "404160",
    "end": "405280"
  },
  {
    "text": "loki kafka or something like that okay",
    "start": "405280",
    "end": "409120"
  },
  {
    "text": "fluently is a data collector which",
    "start": "409120",
    "end": "411360"
  },
  {
    "text": "allows you to unify the data collection",
    "start": "411360",
    "end": "413919"
  },
  {
    "text": "and consumption for better use and",
    "start": "413919",
    "end": "416319"
  },
  {
    "text": "understanding of data",
    "start": "416319",
    "end": "419120"
  },
  {
    "text": "okay you will find that fluently is much",
    "start": "419120",
    "end": "421520"
  },
  {
    "text": "mature than from bait which was started",
    "start": "421520",
    "end": "424240"
  },
  {
    "text": "in 2011",
    "start": "424240",
    "end": "426240"
  },
  {
    "text": "and it has also been a sincere graduated",
    "start": "426240",
    "end": "429599"
  },
  {
    "text": "project fluently was written in c and",
    "start": "429599",
    "end": "432080"
  },
  {
    "text": "ruby it is also pluggable and has around",
    "start": "432080",
    "end": "435199"
  },
  {
    "text": "1000 plugins available so to summarize",
    "start": "435199",
    "end": "438800"
  },
  {
    "text": "flundi allows you to build your own",
    "start": "438800",
    "end": "441520"
  },
  {
    "text": "unified login layer and this layer",
    "start": "441520",
    "end": "444000"
  },
  {
    "text": "allows developers and data analysis to",
    "start": "444000",
    "end": "446160"
  },
  {
    "text": "utilize many types of logs as they are",
    "start": "446160",
    "end": "449039"
  },
  {
    "text": "generated",
    "start": "449039",
    "end": "450560"
  },
  {
    "text": "the most important thing is",
    "start": "450560",
    "end": "452639"
  },
  {
    "text": "it mitigates the risk of bad data",
    "start": "452639",
    "end": "455039"
  },
  {
    "text": "slowing down and misinforming your",
    "start": "455039",
    "end": "457360"
  },
  {
    "text": "organization",
    "start": "457360",
    "end": "458880"
  },
  {
    "text": "okay at this point",
    "start": "458880",
    "end": "460800"
  },
  {
    "text": "let's take a look at the comparison of",
    "start": "460800",
    "end": "463120"
  },
  {
    "text": "bloomberg and fluently",
    "start": "463120",
    "end": "465759"
  },
  {
    "text": "this table describes a comparison in",
    "start": "465759",
    "end": "467919"
  },
  {
    "text": "different areas of the project",
    "start": "467919",
    "end": "470479"
  },
  {
    "text": "so you could find that",
    "start": "470479",
    "end": "472879"
  },
  {
    "text": "both fluently and from bit",
    "start": "472879",
    "end": "475280"
  },
  {
    "text": "can work as",
    "start": "475280",
    "end": "476560"
  },
  {
    "text": "aggregators or forwarders",
    "start": "476560",
    "end": "479360"
  },
  {
    "text": "they both can complement each other or",
    "start": "479360",
    "end": "482080"
  },
  {
    "text": "use them as a standalone solution",
    "start": "482080",
    "end": "485360"
  },
  {
    "text": "that is why fluent operator comes in and",
    "start": "485360",
    "end": "487759"
  },
  {
    "text": "supports managing both front bit and",
    "start": "487759",
    "end": "489840"
  },
  {
    "text": "front d",
    "start": "489840",
    "end": "491360"
  },
  {
    "text": "so from base was born to",
    "start": "491360",
    "end": "494400"
  },
  {
    "text": "facilitate the management of front bait",
    "start": "494400",
    "end": "497039"
  },
  {
    "text": "and fluentd",
    "start": "497039",
    "end": "498240"
  },
  {
    "text": "it allows you to manage the lifecycle",
    "start": "498240",
    "end": "500800"
  },
  {
    "text": "from bait and fluently before we deep",
    "start": "500800",
    "end": "503360"
  },
  {
    "text": "dive into it let's look back at its",
    "start": "503360",
    "end": "505840"
  },
  {
    "text": "history of fluent operator this project",
    "start": "505840",
    "end": "508400"
  },
  {
    "text": "was open sourced as front bait operator",
    "start": "508400",
    "end": "510879"
  },
  {
    "text": "by cubes 13 in january 2019",
    "start": "510879",
    "end": "516120"
  },
  {
    "text": "after eight versions iteration",
    "start": "516560",
    "end": "519200"
  },
  {
    "text": "it has been donated to the upstream",
    "start": "519200",
    "end": "521440"
  },
  {
    "text": "fluent community in august 2021",
    "start": "521440",
    "end": "526599"
  },
  {
    "text": "so after it has integrated the fluentd",
    "start": "526959",
    "end": "530800"
  },
  {
    "text": "into its operator",
    "start": "530800",
    "end": "532480"
  },
  {
    "text": "it has been renamed to front operator in",
    "start": "532480",
    "end": "535279"
  },
  {
    "text": "march",
    "start": "535279",
    "end": "536200"
  },
  {
    "text": "2022",
    "start": "536200",
    "end": "538000"
  },
  {
    "text": "in april front operator has reached",
    "start": "538000",
    "end": "540959"
  },
  {
    "text": "the 1.0 which marks the maturity of this",
    "start": "540959",
    "end": "544399"
  },
  {
    "text": "project",
    "start": "544399",
    "end": "545600"
  },
  {
    "text": "all right this is the initial reason",
    "start": "545600",
    "end": "547600"
  },
  {
    "text": "that we finded this project from bait",
    "start": "547600",
    "end": "550399"
  },
  {
    "text": "operator as we have seen that the front",
    "start": "550399",
    "end": "553519"
  },
  {
    "text": "base cannot reload configured gracefully",
    "start": "553519",
    "end": "556959"
  },
  {
    "text": "and it does not support dynamic",
    "start": "556959",
    "end": "559120"
  },
  {
    "text": "configuration it requires users to",
    "start": "559120",
    "end": "561760"
  },
  {
    "text": "restart its film bit part",
    "start": "561760",
    "end": "564880"
  },
  {
    "text": "and reload it manually so it is not",
    "start": "564880",
    "end": "567519"
  },
  {
    "text": "intelligent",
    "start": "567519",
    "end": "568959"
  },
  {
    "text": "especially in the production environment",
    "start": "568959",
    "end": "572320"
  },
  {
    "text": "that is why front beta operator comes in",
    "start": "572320",
    "end": "575680"
  },
  {
    "text": "okay let me give a general introduction",
    "start": "575680",
    "end": "578560"
  },
  {
    "text": "to fluent operator",
    "start": "578560",
    "end": "581839"
  },
  {
    "text": "as we mentioned earlier",
    "start": "581920",
    "end": "584240"
  },
  {
    "text": "the front operator which is used to",
    "start": "584240",
    "end": "586160"
  },
  {
    "text": "deploy and destroy flambet demo set or",
    "start": "586160",
    "end": "589360"
  },
  {
    "text": "run the status set automatically",
    "start": "589360",
    "end": "592399"
  },
  {
    "text": "second it has custom configuration which",
    "start": "592399",
    "end": "595200"
  },
  {
    "text": "allows you to select",
    "start": "595200",
    "end": "597200"
  },
  {
    "text": "the plugins like input filter output",
    "start": "597200",
    "end": "600720"
  },
  {
    "text": "by labels",
    "start": "600720",
    "end": "602640"
  },
  {
    "text": "so as we mentioned earlier",
    "start": "602640",
    "end": "604800"
  },
  {
    "text": "the dynamic reloading is also the most",
    "start": "604800",
    "end": "607360"
  },
  {
    "text": "important feature that has supported in",
    "start": "607360",
    "end": "609839"
  },
  {
    "text": "the front operator it has supported",
    "start": "609839",
    "end": "613120"
  },
  {
    "text": "update configuration without rebooting",
    "start": "613120",
    "end": "615360"
  },
  {
    "text": "from base and front deposit",
    "start": "615360",
    "end": "618079"
  },
  {
    "text": "multi-tenant log isolation has also been",
    "start": "618079",
    "end": "620560"
  },
  {
    "text": "considered in front operator",
    "start": "620560",
    "end": "623200"
  },
  {
    "text": "you know fluently supports multi-tenant",
    "start": "623200",
    "end": "625519"
  },
  {
    "text": "log isolation through label router",
    "start": "625519",
    "end": "627519"
  },
  {
    "text": "plug-in",
    "start": "627519",
    "end": "628880"
  },
  {
    "text": "last but not least",
    "start": "628880",
    "end": "630560"
  },
  {
    "text": "front-operator provides packable",
    "start": "630560",
    "end": "632399"
  },
  {
    "text": "deployed components",
    "start": "632399",
    "end": "634320"
  },
  {
    "text": "either from bit or front d can be",
    "start": "634320",
    "end": "636320"
  },
  {
    "text": "deployed separately as you can see that",
    "start": "636320",
    "end": "639200"
  },
  {
    "text": "although both floam bit and fluenty are",
    "start": "639200",
    "end": "641360"
  },
  {
    "text": "able to collect process",
    "start": "641360",
    "end": "644480"
  },
  {
    "text": "and then word logs to",
    "start": "644480",
    "end": "646399"
  },
  {
    "text": "find out that destinations you know",
    "start": "646399",
    "end": "649120"
  },
  {
    "text": "although both from bit and friendly are",
    "start": "649120",
    "end": "652000"
  },
  {
    "text": "able to collect process and then forward",
    "start": "652000",
    "end": "654800"
  },
  {
    "text": "log to different destinations",
    "start": "654800",
    "end": "657839"
  },
  {
    "text": "they have their own strengths in some",
    "start": "657839",
    "end": "659760"
  },
  {
    "text": "different aspects",
    "start": "659760",
    "end": "661440"
  },
  {
    "text": "so from bit plays the draw as a logging",
    "start": "661440",
    "end": "664000"
  },
  {
    "text": "agent on each note since it is super",
    "start": "664000",
    "end": "666880"
  },
  {
    "text": "lightweight and efficient",
    "start": "666880",
    "end": "668959"
  },
  {
    "text": "wavelength is more powerful to perform",
    "start": "668959",
    "end": "671279"
  },
  {
    "text": "advanced processing logs capability",
    "start": "671279",
    "end": "674240"
  },
  {
    "text": "because of its rich plug-in system",
    "start": "674240",
    "end": "676959"
  },
  {
    "text": "as we mentioned before",
    "start": "676959",
    "end": "679120"
  },
  {
    "text": "float operator was used to manage the",
    "start": "679120",
    "end": "681760"
  },
  {
    "text": "front bed as its inception",
    "start": "681760",
    "end": "684320"
  },
  {
    "text": "so",
    "start": "684320",
    "end": "685120"
  },
  {
    "text": "if you only enable floom bait",
    "start": "685120",
    "end": "687519"
  },
  {
    "text": "then the workflow will be quite simple",
    "start": "687519",
    "end": "690720"
  },
  {
    "text": "as you can see from this diagram",
    "start": "690720",
    "end": "693279"
  },
  {
    "text": "the front bit component defines the from",
    "start": "693279",
    "end": "695519"
  },
  {
    "text": "bit diamond set and this configuration",
    "start": "695519",
    "end": "699360"
  },
  {
    "text": "meanwhile fluent operator provides a",
    "start": "699360",
    "end": "701760"
  },
  {
    "text": "customized front bit docker image",
    "start": "701760",
    "end": "704480"
  },
  {
    "text": "from base config selects the input",
    "start": "704480",
    "end": "707279"
  },
  {
    "text": "filter and output plugins and generates",
    "start": "707279",
    "end": "710079"
  },
  {
    "text": "the final configuration into a secret",
    "start": "710079",
    "end": "713279"
  },
  {
    "text": "so",
    "start": "713279",
    "end": "714399"
  },
  {
    "text": "how does front operator manage from bit",
    "start": "714399",
    "end": "716800"
  },
  {
    "text": "and this crd to make it work better with",
    "start": "716800",
    "end": "719680"
  },
  {
    "text": "kubernetes",
    "start": "719680",
    "end": "722399"
  },
  {
    "text": "as you can see from this diagram",
    "start": "722399",
    "end": "725040"
  },
  {
    "text": "each city such as class input class",
    "start": "725040",
    "end": "727760"
  },
  {
    "text": "filter and class output represents",
    "start": "727760",
    "end": "730480"
  },
  {
    "text": "a from base configuration section",
    "start": "730480",
    "end": "733440"
  },
  {
    "text": "which are selected by cluster from base",
    "start": "733440",
    "end": "736240"
  },
  {
    "text": "config while label selectors",
    "start": "736240",
    "end": "740160"
  },
  {
    "text": "front operator watches those objects",
    "start": "740320",
    "end": "743120"
  },
  {
    "text": "constructs the final configuration and",
    "start": "743120",
    "end": "745519"
  },
  {
    "text": "finally creates a secret to store the",
    "start": "745519",
    "end": "747680"
  },
  {
    "text": "configuration which will be mounted into",
    "start": "747680",
    "end": "749760"
  },
  {
    "text": "the front bit demo set",
    "start": "749760",
    "end": "752480"
  },
  {
    "text": "so",
    "start": "752480",
    "end": "753360"
  },
  {
    "text": "the entire workflow is showing as this",
    "start": "753360",
    "end": "755760"
  },
  {
    "text": "graph",
    "start": "755760",
    "end": "757519"
  },
  {
    "text": "so at this point",
    "start": "757519",
    "end": "759200"
  },
  {
    "text": "to enable flowbase to pick up and use",
    "start": "759200",
    "end": "761440"
  },
  {
    "text": "the latest configuration whenever the",
    "start": "761440",
    "end": "763440"
  },
  {
    "text": "floam based configuration changes",
    "start": "763440",
    "end": "765600"
  },
  {
    "text": "a wrapper called front-based watcher is",
    "start": "765600",
    "end": "768399"
  },
  {
    "text": "added to restart the flame bait process",
    "start": "768399",
    "end": "771040"
  },
  {
    "text": "as soon as frame bit configuration",
    "start": "771040",
    "end": "772880"
  },
  {
    "text": "chains are detected",
    "start": "772880",
    "end": "774959"
  },
  {
    "text": "in this way",
    "start": "774959",
    "end": "776320"
  },
  {
    "text": "the frame bit part is not required to",
    "start": "776320",
    "end": "778720"
  },
  {
    "text": "restart it to reload the new",
    "start": "778720",
    "end": "780560"
  },
  {
    "text": "configuration",
    "start": "780560",
    "end": "782240"
  },
  {
    "text": "the frame based configuration is",
    "start": "782240",
    "end": "783760"
  },
  {
    "text": "reloaded in this way because there is no",
    "start": "783760",
    "end": "786240"
  },
  {
    "text": "reloading interface in front bit itself",
    "start": "786240",
    "end": "790000"
  },
  {
    "text": "so you can learn more details from these",
    "start": "790000",
    "end": "792000"
  },
  {
    "text": "links as below",
    "start": "792000",
    "end": "794000"
  },
  {
    "text": "alright",
    "start": "794000",
    "end": "794959"
  },
  {
    "text": "as we introduced before fluently is much",
    "start": "794959",
    "end": "797760"
  },
  {
    "text": "powerful to perform advanced data",
    "start": "797760",
    "end": "800000"
  },
  {
    "text": "processing because of its rich plugins",
    "start": "800000",
    "end": "804480"
  },
  {
    "text": "so we added front d support in front",
    "start": "804480",
    "end": "807120"
  },
  {
    "text": "operator and renamed it",
    "start": "807120",
    "end": "809680"
  },
  {
    "text": "now you can receive logs through",
    "start": "809680",
    "end": "811440"
  },
  {
    "text": "networks like http or skslog and then",
    "start": "811440",
    "end": "814959"
  },
  {
    "text": "process them and send those logs to the",
    "start": "814959",
    "end": "817600"
  },
  {
    "text": "final destinations",
    "start": "817600",
    "end": "819440"
  },
  {
    "text": "such as elasticsearch kafka and s3",
    "start": "819440",
    "end": "824959"
  },
  {
    "text": "rent operator provides three kinds of",
    "start": "825279",
    "end": "827600"
  },
  {
    "text": "mode that you can use as you want",
    "start": "827600",
    "end": "830560"
  },
  {
    "text": "there are floom bits only from bit plus",
    "start": "830560",
    "end": "833120"
  },
  {
    "text": "front d and front d only",
    "start": "833120",
    "end": "835839"
  },
  {
    "text": "so front operator includes crds and",
    "start": "835839",
    "end": "838320"
  },
  {
    "text": "controllers for both frame based and",
    "start": "838320",
    "end": "840240"
  },
  {
    "text": "front d which allows you to configure",
    "start": "840240",
    "end": "842720"
  },
  {
    "text": "your login pipeline in these three mods",
    "start": "842720",
    "end": "845279"
  },
  {
    "text": "as you want",
    "start": "845279",
    "end": "846959"
  },
  {
    "text": "from bit only mode that means if you",
    "start": "846959",
    "end": "849440"
  },
  {
    "text": "just need to collect logs and send those",
    "start": "849440",
    "end": "851519"
  },
  {
    "text": "logs to the final destinations",
    "start": "851519",
    "end": "854079"
  },
  {
    "text": "all you need is just from bait",
    "start": "854079",
    "end": "856959"
  },
  {
    "text": "so let's take a look at the front base",
    "start": "856959",
    "end": "859199"
  },
  {
    "text": "only",
    "start": "859199",
    "end": "861199"
  },
  {
    "text": "as you can see from this graph",
    "start": "861199",
    "end": "863440"
  },
  {
    "text": "different bit crd",
    "start": "863440",
    "end": "865279"
  },
  {
    "text": "cluster fluid bit config selects class",
    "start": "865279",
    "end": "867760"
  },
  {
    "text": "network plugins and generates the final",
    "start": "867760",
    "end": "870160"
  },
  {
    "text": "configuration into a secret",
    "start": "870160",
    "end": "872800"
  },
  {
    "text": "then the other plugins like class input",
    "start": "872800",
    "end": "876000"
  },
  {
    "text": "class filter class output and class",
    "start": "876000",
    "end": "878720"
  },
  {
    "text": "parser are selected by class from bit",
    "start": "878720",
    "end": "881519"
  },
  {
    "text": "config while label selectors",
    "start": "881519",
    "end": "885120"
  },
  {
    "text": "all right let's take a look at an",
    "start": "885120",
    "end": "887120"
  },
  {
    "text": "example use case of collecting",
    "start": "887120",
    "end": "888880"
  },
  {
    "text": "kubernetes application logs and send the",
    "start": "888880",
    "end": "891519"
  },
  {
    "text": "logs output to kafka",
    "start": "891519",
    "end": "894399"
  },
  {
    "text": "so you could define the plugins you want",
    "start": "894399",
    "end": "897360"
  },
  {
    "text": "while the label and selectors",
    "start": "897360",
    "end": "900000"
  },
  {
    "text": "for example",
    "start": "900000",
    "end": "901440"
  },
  {
    "text": "it has defined the filter plugins like",
    "start": "901440",
    "end": "903680"
  },
  {
    "text": "kubernetes",
    "start": "903680",
    "end": "905120"
  },
  {
    "text": "nest and modify plugin here",
    "start": "905120",
    "end": "909199"
  },
  {
    "text": "next let's take a look at the fluent dip",
    "start": "909199",
    "end": "911440"
  },
  {
    "text": "only mode",
    "start": "911440",
    "end": "913040"
  },
  {
    "text": "if you only need to receive logs through",
    "start": "913040",
    "end": "915279"
  },
  {
    "text": "network like http or syslog and then",
    "start": "915279",
    "end": "918880"
  },
  {
    "text": "process and send those logs to the final",
    "start": "918880",
    "end": "920959"
  },
  {
    "text": "destinations",
    "start": "920959",
    "end": "922560"
  },
  {
    "text": "you just need to enable fluentd",
    "start": "922560",
    "end": "926399"
  },
  {
    "text": "let's take a look at how those fluently",
    "start": "926399",
    "end": "928480"
  },
  {
    "text": "crds work",
    "start": "928480",
    "end": "931360"
  },
  {
    "text": "fluently is used to define the fluency",
    "start": "931519",
    "end": "933839"
  },
  {
    "text": "state facade and its configuration",
    "start": "933839",
    "end": "936880"
  },
  {
    "text": "a customized fluent image is required to",
    "start": "936880",
    "end": "939920"
  },
  {
    "text": "work with fluently operator for dynamic",
    "start": "939920",
    "end": "942639"
  },
  {
    "text": "configuration reloading",
    "start": "942639",
    "end": "945199"
  },
  {
    "text": "fluently config which is used to select",
    "start": "945199",
    "end": "947519"
  },
  {
    "text": "class level or namespace level plugins",
    "start": "947519",
    "end": "949920"
  },
  {
    "text": "such as input",
    "start": "949920",
    "end": "951519"
  },
  {
    "text": "filter and output and generates the",
    "start": "951519",
    "end": "954160"
  },
  {
    "text": "final configuration into a secret",
    "start": "954160",
    "end": "957040"
  },
  {
    "text": "similarly the class fluently config",
    "start": "957040",
    "end": "959360"
  },
  {
    "text": "which is used to select class level",
    "start": "959360",
    "end": "961440"
  },
  {
    "text": "plugins and generate the final",
    "start": "961440",
    "end": "963600"
  },
  {
    "text": "configuration to secret",
    "start": "963600",
    "end": "966480"
  },
  {
    "text": "the other components such as filter and",
    "start": "966480",
    "end": "968959"
  },
  {
    "text": "output are similar",
    "start": "968959",
    "end": "970880"
  },
  {
    "text": "they are used to define the namespace",
    "start": "970880",
    "end": "972720"
  },
  {
    "text": "level and class level configuration",
    "start": "972720",
    "end": "974560"
  },
  {
    "text": "respectively",
    "start": "974560",
    "end": "976240"
  },
  {
    "text": "again let's take a look at an example",
    "start": "976240",
    "end": "978560"
  },
  {
    "text": "use case of using fluentd to receive",
    "start": "978560",
    "end": "981040"
  },
  {
    "text": "logs from http and send the output to",
    "start": "981040",
    "end": "984160"
  },
  {
    "text": "standard out",
    "start": "984160",
    "end": "986720"
  },
  {
    "text": "you could define your plugins via labels",
    "start": "986720",
    "end": "989040"
  },
  {
    "text": "and selectors",
    "start": "989040",
    "end": "990480"
  },
  {
    "text": "which is similar to the previous sample",
    "start": "990480",
    "end": "994639"
  },
  {
    "text": "apart from the flame bait or friendly",
    "start": "995519",
    "end": "997759"
  },
  {
    "text": "only mode there's also a strong",
    "start": "997759",
    "end": "1000160"
  },
  {
    "text": "combination of fluently and flambeat in",
    "start": "1000160",
    "end": "1002320"
  },
  {
    "text": "front operator",
    "start": "1002320",
    "end": "1004000"
  },
  {
    "text": "it has more flexibility since you could",
    "start": "1004000",
    "end": "1006160"
  },
  {
    "text": "leverage their different strengths",
    "start": "1006160",
    "end": "1008839"
  },
  {
    "text": "respectively if you also need to perform",
    "start": "1008839",
    "end": "1011360"
  },
  {
    "text": "some advanced data processing to the",
    "start": "1011360",
    "end": "1013440"
  },
  {
    "text": "logs or route them to more destinations",
    "start": "1013440",
    "end": "1016720"
  },
  {
    "text": "then you just need to enable flindy and",
    "start": "1016720",
    "end": "1019360"
  },
  {
    "text": "choose the front bait plus one d mode",
    "start": "1019360",
    "end": "1022480"
  },
  {
    "text": "with its rich plugins fluently plays the",
    "start": "1022480",
    "end": "1025280"
  },
  {
    "text": "role of a log aggregation layer and it",
    "start": "1025280",
    "end": "1028000"
  },
  {
    "text": "is able to perform more advanced log",
    "start": "1028000",
    "end": "1030079"
  },
  {
    "text": "processing",
    "start": "1030079",
    "end": "1031280"
  },
  {
    "text": "you can fold logs from front bait qfnd",
    "start": "1031280",
    "end": "1034480"
  },
  {
    "text": "with ease using fluent operator",
    "start": "1034480",
    "end": "1037520"
  },
  {
    "text": "next let's take a look at a real case",
    "start": "1037520",
    "end": "1039760"
  },
  {
    "text": "study from our team",
    "start": "1039760",
    "end": "1042319"
  },
  {
    "text": "you know cubesphere is an open source",
    "start": "1042319",
    "end": "1044319"
  },
  {
    "text": "container platform built on kubernetes",
    "start": "1044319",
    "end": "1047120"
  },
  {
    "text": "cubesphere has a built-in login console",
    "start": "1047120",
    "end": "1049840"
  },
  {
    "text": "it allows users to search the logs and",
    "start": "1049840",
    "end": "1052240"
  },
  {
    "text": "configure the log collectors such as",
    "start": "1052240",
    "end": "1054480"
  },
  {
    "text": "kafka fluently or elasticsearch",
    "start": "1054480",
    "end": "1058880"
  },
  {
    "text": "cubesphere adobe's elasticsearch serves",
    "start": "1058880",
    "end": "1061120"
  },
  {
    "text": "as the backend logging service with",
    "start": "1061120",
    "end": "1063600"
  },
  {
    "text": "firmbait as a log collector it runs from",
    "start": "1063600",
    "end": "1067039"
  },
  {
    "text": "bit demo set on each node to collect the",
    "start": "1067039",
    "end": "1069440"
  },
  {
    "text": "container logs and application logs",
    "start": "1069440",
    "end": "1072799"
  },
  {
    "text": "in this way",
    "start": "1072799",
    "end": "1074080"
  },
  {
    "text": "different tenants could search the logs",
    "start": "1074080",
    "end": "1076080"
  },
  {
    "text": "in a unified login console and you are",
    "start": "1076080",
    "end": "1078960"
  },
  {
    "text": "able to configure the logs only visible",
    "start": "1078960",
    "end": "1081600"
  },
  {
    "text": "to the specific tenants or in a space",
    "start": "1081600",
    "end": "1084799"
  },
  {
    "text": "in order to help you guys get started",
    "start": "1084799",
    "end": "1086960"
  },
  {
    "text": "with fluent operator we have prepared a",
    "start": "1086960",
    "end": "1090080"
  },
  {
    "text": "workshop with step by step labs",
    "start": "1090080",
    "end": "1093039"
  },
  {
    "text": "this workshop has involved a lot of",
    "start": "1093039",
    "end": "1096000"
  },
  {
    "text": "typical and interesting use cases",
    "start": "1096000",
    "end": "1099679"
  },
  {
    "text": "for example",
    "start": "1099679",
    "end": "1100960"
  },
  {
    "text": "it starts from installing front operator",
    "start": "1100960",
    "end": "1104720"
  },
  {
    "text": "and helps you to deploy from base and",
    "start": "1104720",
    "end": "1106799"
  },
  {
    "text": "front d next",
    "start": "1106799",
    "end": "1109200"
  },
  {
    "text": "it involves three kinds of modes that",
    "start": "1109200",
    "end": "1111120"
  },
  {
    "text": "you can leverage from the operator to",
    "start": "1111120",
    "end": "1114160"
  },
  {
    "text": "send the logs to different destinations",
    "start": "1114160",
    "end": "1117280"
  },
  {
    "text": "for instance we will use front bit only",
    "start": "1117280",
    "end": "1120000"
  },
  {
    "text": "mode in this demo to collect kubernetes",
    "start": "1120000",
    "end": "1122400"
  },
  {
    "text": "application logs and send them to kafka",
    "start": "1122400",
    "end": "1125039"
  },
  {
    "text": "or elixir search",
    "start": "1125039",
    "end": "1127200"
  },
  {
    "text": "typically you can also enable from bit",
    "start": "1127200",
    "end": "1129679"
  },
  {
    "text": "plus 1d mode",
    "start": "1129679",
    "end": "1131360"
  },
  {
    "text": "it has also some typical use cases in",
    "start": "1131360",
    "end": "1133840"
  },
  {
    "text": "this section",
    "start": "1133840",
    "end": "1135280"
  },
  {
    "text": "especially in the multi-tenant scenario",
    "start": "1135280",
    "end": "1138320"
  },
  {
    "text": "finally you can also leverage fluently",
    "start": "1138320",
    "end": "1140880"
  },
  {
    "text": "only mode to use front d to receive",
    "start": "1140880",
    "end": "1143280"
  },
  {
    "text": "locks from http and output to standard",
    "start": "1143280",
    "end": "1146080"
  },
  {
    "text": "out",
    "start": "1146080",
    "end": "1147440"
  },
  {
    "text": "feel free to try it in your local",
    "start": "1147440",
    "end": "1149120"
  },
  {
    "text": "machine or your edge devices",
    "start": "1149120",
    "end": "1153280"
  },
  {
    "text": "in this demo",
    "start": "1157039",
    "end": "1158320"
  },
  {
    "text": "we will collect kubernetes logs and",
    "start": "1158320",
    "end": "1160160"
  },
  {
    "text": "forward it to elasticsearch by using",
    "start": "1160160",
    "end": "1162880"
  },
  {
    "text": "fluent operator with from bit only mode",
    "start": "1162880",
    "end": "1166720"
  },
  {
    "text": "as we mentioned earlier we have prepared",
    "start": "1166720",
    "end": "1169200"
  },
  {
    "text": "a step-by-step workshop and walk you",
    "start": "1169200",
    "end": "1171600"
  },
  {
    "text": "through how to deploy front operator and",
    "start": "1171600",
    "end": "1174240"
  },
  {
    "text": "play around it",
    "start": "1174240",
    "end": "1176080"
  },
  {
    "text": "you can check out this lab from github",
    "start": "1176080",
    "end": "1178720"
  },
  {
    "text": "and try it yourself",
    "start": "1178720",
    "end": "1180720"
  },
  {
    "text": "all of the demos sample code and",
    "start": "1180720",
    "end": "1183440"
  },
  {
    "text": "documentations are available at github",
    "start": "1183440",
    "end": "1187440"
  },
  {
    "text": "alright let's get started with this lab",
    "start": "1187440",
    "end": "1190480"
  },
  {
    "text": "i have already prepared a k3s cluster",
    "start": "1190480",
    "end": "1193600"
  },
  {
    "text": "and a minicube cluster before this lab",
    "start": "1193600",
    "end": "1196880"
  },
  {
    "text": "and in order to make this lab much",
    "start": "1196880",
    "end": "1199200"
  },
  {
    "text": "efficient and convenient for you to set",
    "start": "1199200",
    "end": "1201679"
  },
  {
    "text": "up in your local machine i finally",
    "start": "1201679",
    "end": "1203919"
  },
  {
    "text": "choose to use mini cluster for this demo",
    "start": "1203919",
    "end": "1208000"
  },
  {
    "text": "any other kubernetes distributions or",
    "start": "1208000",
    "end": "1210240"
  },
  {
    "text": "native kubernetes are also supported in",
    "start": "1210240",
    "end": "1212320"
  },
  {
    "text": "this lab",
    "start": "1212320",
    "end": "1214080"
  },
  {
    "text": "you can clone the demo repository to",
    "start": "1214080",
    "end": "1216320"
  },
  {
    "text": "your local machine",
    "start": "1216320",
    "end": "1217760"
  },
  {
    "text": "and get all of those share scripts for",
    "start": "1217760",
    "end": "1220080"
  },
  {
    "text": "the first step we will deploy a kafka",
    "start": "1220080",
    "end": "1222240"
  },
  {
    "text": "cluster and an elasticsearch cluster so",
    "start": "1222240",
    "end": "1224640"
  },
  {
    "text": "you can choose to forward those logs to",
    "start": "1224640",
    "end": "1226799"
  },
  {
    "text": "kafka or elasticsearch as you want",
    "start": "1226799",
    "end": "1230159"
  },
  {
    "text": "after a couple of seconds",
    "start": "1230159",
    "end": "1232000"
  },
  {
    "text": "we could verify if all of those kafka",
    "start": "1232000",
    "end": "1234080"
  },
  {
    "text": "cluster resources are running",
    "start": "1234080",
    "end": "1237679"
  },
  {
    "text": "after all of those kafka cluster",
    "start": "1238159",
    "end": "1239919"
  },
  {
    "text": "resources are ready we could go ahead",
    "start": "1239919",
    "end": "1242320"
  },
  {
    "text": "and deploy elasticsearch cluster with",
    "start": "1242320",
    "end": "1244320"
  },
  {
    "text": "its hem chart",
    "start": "1244320",
    "end": "1246320"
  },
  {
    "text": "it might take a couple of minutes to set",
    "start": "1246320",
    "end": "1248400"
  },
  {
    "text": "up the elasticsearch cluster so we can",
    "start": "1248400",
    "end": "1250720"
  },
  {
    "text": "take a look at the manifest of fluent",
    "start": "1250720",
    "end": "1253200"
  },
  {
    "text": "operator and to see what has been",
    "start": "1253200",
    "end": "1255360"
  },
  {
    "text": "defined in each yaml file",
    "start": "1255360",
    "end": "1258799"
  },
  {
    "text": "since we choose to collect kubernetes",
    "start": "1258799",
    "end": "1260559"
  },
  {
    "text": "logs and forward to elasticsearch using",
    "start": "1260559",
    "end": "1263679"
  },
  {
    "text": "front operator with front bit only mode",
    "start": "1263679",
    "end": "1266880"
  },
  {
    "text": "so",
    "start": "1266880",
    "end": "1267600"
  },
  {
    "text": "so we dig into this folder",
    "start": "1267600",
    "end": "1270960"
  },
  {
    "text": "as we can see from the architecture",
    "start": "1270960",
    "end": "1272880"
  },
  {
    "text": "diagram of front operator all of those",
    "start": "1272880",
    "end": "1275200"
  },
  {
    "text": "front-based crds such as from bit",
    "start": "1275200",
    "end": "1278240"
  },
  {
    "text": "class front bit config",
    "start": "1278240",
    "end": "1280320"
  },
  {
    "text": "class input class filter and class",
    "start": "1280320",
    "end": "1282720"
  },
  {
    "text": "output have been defined in those yaml",
    "start": "1282720",
    "end": "1285280"
  },
  {
    "text": "files",
    "start": "1285280",
    "end": "1287679"
  },
  {
    "text": "the destinations such as elasticsearch",
    "start": "1288080",
    "end": "1290480"
  },
  {
    "text": "has been defined in the output crd",
    "start": "1290480",
    "end": "1293360"
  },
  {
    "text": "if you want to define the other",
    "start": "1293360",
    "end": "1295520"
  },
  {
    "text": "destinations such as kafka or loki or s3",
    "start": "1295520",
    "end": "1299440"
  },
  {
    "text": "you can define it here",
    "start": "1299440",
    "end": "1302080"
  },
  {
    "text": "let's go back to the command line and to",
    "start": "1302080",
    "end": "1304080"
  },
  {
    "text": "see if elasticsearch is running or not",
    "start": "1304080",
    "end": "1307280"
  },
  {
    "text": "all right everything looks okay",
    "start": "1307280",
    "end": "1311280"
  },
  {
    "text": "the livestick search cluster has been",
    "start": "1311840",
    "end": "1313919"
  },
  {
    "text": "deployed successfully and now it should",
    "start": "1313919",
    "end": "1316480"
  },
  {
    "text": "be ready to store the logs",
    "start": "1316480",
    "end": "1320000"
  },
  {
    "text": "okay at this point",
    "start": "1320000",
    "end": "1322080"
  },
  {
    "text": "we could find that the two designations",
    "start": "1322080",
    "end": "1324480"
  },
  {
    "text": "elasticsearch and kafka are ready to use",
    "start": "1324480",
    "end": "1328880"
  },
  {
    "text": "so for the next step we are going to",
    "start": "1328880",
    "end": "1331039"
  },
  {
    "text": "deploy the lock forwarder and processor",
    "start": "1331039",
    "end": "1333840"
  },
  {
    "text": "you know from bait to cloud kubernetes",
    "start": "1333840",
    "end": "1336000"
  },
  {
    "text": "locks and ship them to these two",
    "start": "1336000",
    "end": "1337760"
  },
  {
    "text": "designations",
    "start": "1337760",
    "end": "1340480"
  },
  {
    "text": "so we could use front operator",
    "start": "1340480",
    "end": "1342240"
  },
  {
    "text": "deployment script to setup it and wait",
    "start": "1342240",
    "end": "1344720"
  },
  {
    "text": "for seconds",
    "start": "1344720",
    "end": "1347280"
  },
  {
    "text": "after we see the front operator part is",
    "start": "1347280",
    "end": "1349840"
  },
  {
    "text": "running that means we are ready to use",
    "start": "1349840",
    "end": "1352159"
  },
  {
    "text": "front operator to deploy front bit or",
    "start": "1352159",
    "end": "1354880"
  },
  {
    "text": "front d to process logs",
    "start": "1354880",
    "end": "1358480"
  },
  {
    "text": "all right let's enter the manifest",
    "start": "1358960",
    "end": "1361360"
  },
  {
    "text": "folder and choose from bit mode only",
    "start": "1361360",
    "end": "1365440"
  },
  {
    "text": "as we mentioned earlier all of those crd",
    "start": "1365440",
    "end": "1368000"
  },
  {
    "text": "yammer files have been defined in this",
    "start": "1368000",
    "end": "1370240"
  },
  {
    "text": "folder",
    "start": "1370240",
    "end": "1371919"
  },
  {
    "text": "so next you can use kubcar to apply to",
    "start": "1371919",
    "end": "1374880"
  },
  {
    "text": "create all of those resources",
    "start": "1374880",
    "end": "1378480"
  },
  {
    "text": "here we can",
    "start": "1381919",
    "end": "1383440"
  },
  {
    "text": "here we can point the targeted folder to",
    "start": "1383440",
    "end": "1385760"
  },
  {
    "text": "this place",
    "start": "1385760",
    "end": "1389080"
  },
  {
    "text": "apply it and then wait for seconds you",
    "start": "1392480",
    "end": "1395440"
  },
  {
    "text": "will find all of crd files you will find",
    "start": "1395440",
    "end": "1398400"
  },
  {
    "text": "all of those crd resources have been",
    "start": "1398400",
    "end": "1400480"
  },
  {
    "text": "created",
    "start": "1400480",
    "end": "1402000"
  },
  {
    "text": "so let's verify then",
    "start": "1402000",
    "end": "1405120"
  },
  {
    "text": "first let's verify if the front-based",
    "start": "1405120",
    "end": "1407919"
  },
  {
    "text": "demo set has been set up and running",
    "start": "1407919",
    "end": "1412399"
  },
  {
    "text": "the film-based demo set looks fine",
    "start": "1414000",
    "end": "1416480"
  },
  {
    "text": "so go ahead let's check the strategy",
    "start": "1416480",
    "end": "1419120"
  },
  {
    "text": "component of flume bait",
    "start": "1419120",
    "end": "1422559"
  },
  {
    "text": "as you can see from this fluent operator",
    "start": "1423840",
    "end": "1426480"
  },
  {
    "text": "diagram",
    "start": "1426480",
    "end": "1427840"
  },
  {
    "text": "you might need to verify the status of",
    "start": "1427840",
    "end": "1430559"
  },
  {
    "text": "those crds",
    "start": "1430559",
    "end": "1433600"
  },
  {
    "text": "let's first check the status of fluent",
    "start": "1437279",
    "end": "1439679"
  },
  {
    "text": "operator itself",
    "start": "1439679",
    "end": "1442720"
  },
  {
    "text": "and then we can get the status of",
    "start": "1443279",
    "end": "1445600"
  },
  {
    "text": "cluster from base config",
    "start": "1445600",
    "end": "1449200"
  },
  {
    "text": "next go ahead we can check the status of",
    "start": "1450080",
    "end": "1452640"
  },
  {
    "text": "class input",
    "start": "1452640",
    "end": "1454880"
  },
  {
    "text": "next let's go ahead and check this class",
    "start": "1454880",
    "end": "1456960"
  },
  {
    "text": "input status",
    "start": "1456960",
    "end": "1459840"
  },
  {
    "text": "copy and paste it and change it to class",
    "start": "1461279",
    "end": "1463760"
  },
  {
    "text": "filter",
    "start": "1463760",
    "end": "1466159"
  },
  {
    "text": "and we can see that the kubernetes",
    "start": "1466240",
    "end": "1468640"
  },
  {
    "text": "plugin has been defined in the cluster",
    "start": "1468640",
    "end": "1471200"
  },
  {
    "text": "filter part",
    "start": "1471200",
    "end": "1473840"
  },
  {
    "text": "as we have defined the elasticsearch as",
    "start": "1473919",
    "end": "1476480"
  },
  {
    "text": "a destination in this login pipeline",
    "start": "1476480",
    "end": "1479039"
  },
  {
    "text": "within the output plugin so the result",
    "start": "1479039",
    "end": "1482960"
  },
  {
    "text": "is looks like",
    "start": "1482960",
    "end": "1484240"
  },
  {
    "text": "as the same as our expectation",
    "start": "1484240",
    "end": "1488880"
  },
  {
    "text": "all right at this point",
    "start": "1489200",
    "end": "1492159"
  },
  {
    "text": "we could scroll down to the guideline of",
    "start": "1492159",
    "end": "1495279"
  },
  {
    "text": "how to check the status and",
    "start": "1495279",
    "end": "1497120"
  },
  {
    "text": "configuration of the elasticsearch and",
    "start": "1497120",
    "end": "1499919"
  },
  {
    "text": "to see if the logs and index has been",
    "start": "1499919",
    "end": "1502559"
  },
  {
    "text": "created in the elasticsearch",
    "start": "1502559",
    "end": "1506240"
  },
  {
    "text": "at the same time we could also find the",
    "start": "1509200",
    "end": "1511279"
  },
  {
    "text": "front base part is running due to we are",
    "start": "1511279",
    "end": "1514000"
  },
  {
    "text": "using front base only mode here",
    "start": "1514000",
    "end": "1517440"
  },
  {
    "text": "so next",
    "start": "1517440",
    "end": "1518720"
  },
  {
    "text": "let's verify the front base",
    "start": "1518720",
    "end": "1520559"
  },
  {
    "text": "configuration that generated by the",
    "start": "1520559",
    "end": "1522720"
  },
  {
    "text": "fluent operator",
    "start": "1522720",
    "end": "1524240"
  },
  {
    "text": "so we can copy this command line",
    "start": "1524240",
    "end": "1526960"
  },
  {
    "text": "and place it in our",
    "start": "1526960",
    "end": "1528880"
  },
  {
    "text": "terminal",
    "start": "1528880",
    "end": "1531200"
  },
  {
    "text": "yeah we could find the plugins that",
    "start": "1531200",
    "end": "1533679"
  },
  {
    "text": "defined in this",
    "start": "1533679",
    "end": "1535279"
  },
  {
    "text": "frame base configuration",
    "start": "1535279",
    "end": "1537600"
  },
  {
    "text": "it includes input filter and output",
    "start": "1537600",
    "end": "1542000"
  },
  {
    "text": "as we have already defined the",
    "start": "1542000",
    "end": "1543600"
  },
  {
    "text": "elasticsearch as a designation in the",
    "start": "1543600",
    "end": "1546159"
  },
  {
    "text": "output",
    "start": "1546159",
    "end": "1547600"
  },
  {
    "text": "you can also change it to kafka or odd",
    "start": "1547600",
    "end": "1550240"
  },
  {
    "text": "designations as you want",
    "start": "1550240",
    "end": "1553600"
  },
  {
    "text": "all right",
    "start": "1553600",
    "end": "1554960"
  },
  {
    "text": "at this point we could check the logs",
    "start": "1554960",
    "end": "1557679"
  },
  {
    "text": "from the elasticsearch so we can copy",
    "start": "1557679",
    "end": "1560240"
  },
  {
    "text": "this command line and paste it in our",
    "start": "1560240",
    "end": "1563120"
  },
  {
    "text": "terminal",
    "start": "1563120",
    "end": "1565679"
  },
  {
    "text": "wait for a second",
    "start": "1566799",
    "end": "1568840"
  },
  {
    "text": "yeah after querying the kubernetes",
    "start": "1568840",
    "end": "1571279"
  },
  {
    "text": "namespace market in the elasticsearch",
    "start": "1571279",
    "end": "1574799"
  },
  {
    "text": "we could retrieve the key value types of",
    "start": "1574799",
    "end": "1577039"
  },
  {
    "text": "logs and data from the elasticsearch",
    "start": "1577039",
    "end": "1581440"
  },
  {
    "text": "that means the logs have been collected",
    "start": "1581440",
    "end": "1583840"
  },
  {
    "text": "and shipped to the final destination you",
    "start": "1583840",
    "end": "1586159"
  },
  {
    "text": "know the last search here",
    "start": "1586159",
    "end": "1589600"
  },
  {
    "text": "all right at this point we can also",
    "start": "1592880",
    "end": "1595440"
  },
  {
    "text": "double check the result from the",
    "start": "1595440",
    "end": "1597600"
  },
  {
    "text": "elasticsearch index",
    "start": "1597600",
    "end": "1600880"
  },
  {
    "text": "normally it will create a new index for",
    "start": "1601279",
    "end": "1603840"
  },
  {
    "text": "the logs that retrieved from from bait",
    "start": "1603840",
    "end": "1607919"
  },
  {
    "text": "last but not least as we have already",
    "start": "1608880",
    "end": "1611360"
  },
  {
    "text": "deployed kafka as an optional",
    "start": "1611360",
    "end": "1613360"
  },
  {
    "text": "designation at the beginning of this",
    "start": "1613360",
    "end": "1615520"
  },
  {
    "text": "demo so you can change it",
    "start": "1615520",
    "end": "1618559"
  },
  {
    "text": "to kafka in the output",
    "start": "1618559",
    "end": "1621360"
  },
  {
    "text": "crd component",
    "start": "1621360",
    "end": "1624840"
  }
]
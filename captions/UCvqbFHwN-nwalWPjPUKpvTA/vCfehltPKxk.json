[
  {
    "text": "hello everyone this is S and Aki from Bloomberg and we're here to talk about Trino and data governance on Kubernetes",
    "start": "320",
    "end": "8160"
  },
  {
    "text": "a story of how we were able to deploy Trino on as a pro service product on",
    "start": "8160",
    "end": "13360"
  },
  {
    "text": "Kubernetes to meet the evolving requirements of data analytics and data governance within our",
    "start": "13360",
    "end": "20720"
  },
  {
    "text": "company so here's a high level overview of the data environment at Bloomberg our",
    "start": "21320",
    "end": "26480"
  },
  {
    "text": "teams deal with a massive scale of data often ranging in pabyte scale of",
    "start": "26480",
    "end": "31760"
  },
  {
    "text": "financial data spanning across the global markets and we acquire data from",
    "start": "31760",
    "end": "37040"
  },
  {
    "text": "a variety of different sources like market data news from over a 125,000",
    "start": "37040",
    "end": "42640"
  },
  {
    "text": "different curated news sources as well as thirdparty alternative data to name a",
    "start": "42640",
    "end": "47879"
  },
  {
    "text": "few our teams often also ingest real-time streaming data and analytics for market insights and recently there's",
    "start": "47879",
    "end": "55039"
  },
  {
    "text": "been a growth of self-maintained data cataloges across teams utilizing on-prem",
    "start": "55039",
    "end": "60719"
  },
  {
    "text": "S3 compatible object storage solutions to facilitate their analytical workloads",
    "start": "60719",
    "end": "66479"
  },
  {
    "text": "and last but not least there's a need to secure data discovery for AI workloads",
    "start": "66479",
    "end": "72240"
  },
  {
    "text": "so that only authorized users and AI applications can get access to the data",
    "start": "72240",
    "end": "78000"
  },
  {
    "text": "for specified use cases so given these characteristics of our data environment",
    "start": "78000",
    "end": "83759"
  },
  {
    "text": "there was an opportunity to centralize our data analytics infrastructure with the goal of enabling our data owners to",
    "start": "83759",
    "end": "91040"
  },
  {
    "text": "share data catalogs securely across many other",
    "start": "91040",
    "end": "96200"
  },
  {
    "text": "teams what you see on the screen here is an example of the data analyst pipeline that a data engineering team may manage",
    "start": "96200",
    "end": "102960"
  },
  {
    "text": "at Bloomberg for instance a market data engineering team may build their data",
    "start": "102960",
    "end": "108079"
  },
  {
    "text": "catalogs by utilizing a variety of ingestion tools like Apache Spark Apachi Flink or even Pi iceberg and in turn",
    "start": "108079",
    "end": "115920"
  },
  {
    "text": "they would use a largecale distributed processing engine to extract and transform the data into a generative",
    "start": "115920",
    "end": "122840"
  },
  {
    "text": "form or simply manage a data exploration tool to enable their data quality teams",
    "start": "122840",
    "end": "129840"
  },
  {
    "text": "or their client support teams to interactively analyze",
    "start": "129840",
    "end": "135080"
  },
  {
    "text": "data so what is Trino and how does it help centralize the data analytics",
    "start": "135080",
    "end": "141920"
  },
  {
    "text": "environment we have within our firm truno is a scalable and highly distributed processing engine that",
    "start": "141920",
    "end": "148560"
  },
  {
    "text": "optimizes query performance through parallel processing as well as predicate pushdowns that is very typical of a",
    "start": "148560",
    "end": "155120"
  },
  {
    "text": "distributed processing engine and has it has a few new tricks up its sleeve as well uh it also optimizes query",
    "start": "155120",
    "end": "162720"
  },
  {
    "text": "performance by distributed caching which allows the cluster to be able to uh",
    "start": "162720",
    "end": "168800"
  },
  {
    "text": "avoid redundant S3 reads when it's repeatedly accessing the same object",
    "start": "168800",
    "end": "174560"
  },
  {
    "text": "trino is also an NISSQL compliant engine that integrates with popular open-source",
    "start": "174560",
    "end": "180800"
  },
  {
    "text": "uh business intelligence tools and a ver versatile engine that provides support",
    "start": "180800",
    "end": "186080"
  },
  {
    "text": "for ad hoc analysis at interactive speeds and multi-hour batch workloads",
    "start": "186080",
    "end": "191159"
  },
  {
    "text": "alike so these qualities all have made Trino a data analytics tool of choice",
    "start": "191159",
    "end": "196640"
  },
  {
    "text": "for a variety of workloads because let's face it the switching costs of having to",
    "start": "196640",
    "end": "202000"
  },
  {
    "text": "learn the different quirks of multiple different data analytics tools is very much",
    "start": "202000",
    "end": "207800"
  },
  {
    "text": "real and that's where we come in we're a team that provides managed Trino as a",
    "start": "207800",
    "end": "214000"
  },
  {
    "text": "service on our manage Trino platform users define Truno cluster resource",
    "start": "214000",
    "end": "219319"
  },
  {
    "text": "configurations like the amount of memory you want to allocate into your specific Trina cluster you're requesting the",
    "start": "219319",
    "end": "225680"
  },
  {
    "text": "Trino catalog definitions that encapsulate the connection properties the connection details defining where",
    "start": "225680",
    "end": "232000"
  },
  {
    "text": "and how the data is going to be fetched from the data sources you specify in your Trina catalog and then the catalog",
    "start": "232000",
    "end": "239439"
  },
  {
    "text": "access control definitions that define who can have access to what kind of data",
    "start": "239439",
    "end": "245120"
  },
  {
    "text": "in return uh our platform provides two core features firstly our platform deploys",
    "start": "245120",
    "end": "252480"
  },
  {
    "text": "Trino clusters matching the provided resource configurations and cataloges that the user has requested to map to",
    "start": "252480",
    "end": "260799"
  },
  {
    "text": "the Trina cluster is deployed with its query endpoint and monitoring UI exposed and made available to engineers data",
    "start": "260799",
    "end": "268400"
  },
  {
    "text": "analysts and AI developers alike and as the title of our",
    "start": "268400",
    "end": "274560"
  },
  {
    "text": "presentation suggests we provide runtime data governance by enforcing policies",
    "start": "274560",
    "end": "279759"
  },
  {
    "text": "that match predefined access control definitions so these personas we refer",
    "start": "279759",
    "end": "285360"
  },
  {
    "text": "to as data owners they go into our platform and they administer these",
    "start": "285360",
    "end": "290759"
  },
  {
    "text": "policies which are used by Trino as it asks policy decision questions about",
    "start": "290759",
    "end": "296320"
  },
  {
    "text": "whether access to specific resources should be granted to a specific Trino user when a user submits an NCSQL query",
    "start": "296320",
    "end": "304880"
  },
  {
    "text": "onto the Trina cluster the Trina coordinator before it executes a query sends the query context that includes",
    "start": "304880",
    "end": "312000"
  },
  {
    "text": "the user the role the SQL statement over to the policy decision point which",
    "start": "312000",
    "end": "317759"
  },
  {
    "text": "expands the SQL statement to specific policy questions mapping to a group of",
    "start": "317759",
    "end": "324039"
  },
  {
    "text": "resources as well as the action types in order to determine if this specific user",
    "start": "324039",
    "end": "330080"
  },
  {
    "text": "should be allowed to access those resources so if the policy decision",
    "start": "330080",
    "end": "335919"
  },
  {
    "text": "point approves then the query is executed by the cluster and voila you",
    "start": "335919",
    "end": "341520"
  },
  {
    "text": "get the data but if the policy decision point rejects it Trino returns an",
    "start": "341520",
    "end": "347680"
  },
  {
    "text": "authorization error so why did we want to run TRO on",
    "start": "347680",
    "end": "353960"
  },
  {
    "text": "Kubernetes our tenants were typically engineering teams that looked after data lake architectures for their respective",
    "start": "353960",
    "end": "360400"
  },
  {
    "text": "business units and you can think of these business units as different",
    "start": "360400",
    "end": "365520"
  },
  {
    "text": "organizations within the company like the organizations that sell news data or",
    "start": "365520",
    "end": "371199"
  },
  {
    "text": "market data or risk data and one of their core requirements for a managed",
    "start": "371199",
    "end": "376319"
  },
  {
    "text": "TRO platform was that their clusters should remain unaffected when a",
    "start": "376319",
    "end": "381520"
  },
  {
    "text": "different cluster running in a different organization uh is having a service",
    "start": "381520",
    "end": "387400"
  },
  {
    "text": "disruption and although there are existing concepts like resource groups",
    "start": "387400",
    "end": "393840"
  },
  {
    "text": "uh within trainer clusters that users can use to define the amount of resources that can be allocated to a",
    "start": "393840",
    "end": "400319"
  },
  {
    "text": "subset of users within a specific trainer cluster our tenants preference was for them to have isolated trin",
    "start": "400319",
    "end": "406960"
  },
  {
    "text": "deployments that they could fine-tune and managed with a high degree of resiliency within their business units",
    "start": "406960",
    "end": "414479"
  },
  {
    "text": "so the deployment management scalability the multi-tenant enabling network",
    "start": "414479",
    "end": "419599"
  },
  {
    "text": "security uh features that come out of the box out of Trino uh out of Kubernetes sorry um made it an easy",
    "start": "419599",
    "end": "426639"
  },
  {
    "text": "choice for us to build a Trino deployment go controller to manage our",
    "start": "426639",
    "end": "434000"
  },
  {
    "text": "deployments all right but our team wasn't just tasked with building a simple Trino deployment manager and this",
    "start": "434759",
    "end": "442479"
  },
  {
    "text": "is because Triny enables users to make uh requests to uh to access data a lot",
    "start": "442479",
    "end": "450000"
  },
  {
    "text": "easier which means that the risk profile of your data analytics environment",
    "start": "450000",
    "end": "455199"
  },
  {
    "text": "increases unless you have proper authorization in place and within our",
    "start": "455199",
    "end": "460720"
  },
  {
    "text": "data environment effectively centralizing the many engineering and business teams workloads meant enabling",
    "start": "460720",
    "end": "467280"
  },
  {
    "text": "our data owners to be able to share their data catalogs across Trina clusters that are running on other",
    "start": "467280",
    "end": "474599"
  },
  {
    "text": "namespaces while still empowering them to be able to administer the policies which determine who has access to those",
    "start": "474599",
    "end": "481759"
  },
  {
    "text": "data catalogs and doing this in a secured manner posed a unique challenge which was that we",
    "start": "481759",
    "end": "488400"
  },
  {
    "text": "needed to build a centralized catalog management and policy administration mechanism to go along with the truno",
    "start": "488400",
    "end": "496080"
  },
  {
    "text": "deployment mechanism we're building for a multi-tenant architecture so now I",
    "start": "496080",
    "end": "501199"
  },
  {
    "text": "will hand it over to Aki to talk about the technical design implementation that",
    "start": "501199",
    "end": "506560"
  },
  {
    "text": "solves this challenge in our new management platform",
    "start": "506560",
    "end": "512120"
  },
  {
    "text": "thank you S so for centralized data access policy management an important",
    "start": "515279",
    "end": "520320"
  },
  {
    "text": "building block is a Chino's built-in access control uh when a user tries to execute a query in Chino Chino analyzes",
    "start": "520320",
    "end": "528160"
  },
  {
    "text": "its SQL statement before executing it and asks authorization questions such as",
    "start": "528160",
    "end": "533600"
  },
  {
    "text": "can this user select these columns from this table this mechanism allows us to",
    "start": "533600",
    "end": "538959"
  },
  {
    "text": "define the access policy up to column level so we can say for example this",
    "start": "538959",
    "end": "544160"
  },
  {
    "text": "group of people should be able to access only column A and column B from this table there are several implementations",
    "start": "544160",
    "end": "550880"
  },
  {
    "text": "that come with upstream distribution such as a file based one uh where you",
    "start": "550880",
    "end": "556240"
  },
  {
    "text": "can specify who can access which data in a JSON format in a TRO configuration file we chose an overbased",
    "start": "556240",
    "end": "563120"
  },
  {
    "text": "implementation because it allows us to decouple centralized policy management and its distribution from many instances",
    "start": "563120",
    "end": "571360"
  },
  {
    "text": "of between clusters managed by our tenants so OPA is an open source",
    "start": "571360",
    "end": "577200"
  },
  {
    "text": "software that focuses on a policy enforcement in a decoupled and reusable way it accepts policy questions as JSON",
    "start": "577200",
    "end": "584560"
  },
  {
    "text": "over HTTP or gRPC and responds in the same way one important feature for us is",
    "start": "584560",
    "end": "591680"
  },
  {
    "text": "its ability to fetch policies from external services in a well- definfined way out of the box the policy data it",
    "start": "591680",
    "end": "599200"
  },
  {
    "text": "fetches this way is called bundle and the external service that provides the bundle is called bundler this bundler is",
    "start": "599200",
    "end": "606640"
  },
  {
    "text": "what we will leverage in a policy distribution so that policies can be managed in a central place without being",
    "start": "606640",
    "end": "613279"
  },
  {
    "text": "a single point of failure or a bottleneck so based on these underlying",
    "start": "613279",
    "end": "619519"
  },
  {
    "text": "technologies uh this is what we want to achieve in our platform data owners on",
    "start": "619519",
    "end": "625680"
  },
  {
    "text": "the right hand side should be able to expose their data with granular data access policies in TRO data source is",
    "start": "625680",
    "end": "633440"
  },
  {
    "text": "represented as a catalog which is a collection of configuration properties including database connection strings",
    "start": "633440",
    "end": "641279"
  },
  {
    "text": "then tuner service owners on the left hand side should be able to create their tuner clusters which can mount cataloges",
    "start": "641279",
    "end": "648880"
  },
  {
    "text": "defined by data owners however the catalog mount should come with",
    "start": "648880",
    "end": "654320"
  },
  {
    "text": "restrictions that the data owner imposes this is where we leverage opa",
    "start": "654320",
    "end": "660079"
  },
  {
    "text": "plugin with OPA that we walked through in the previous slides when users uh send over their",
    "start": "660079",
    "end": "667200"
  },
  {
    "text": "queries Chino opera plugging enforces the policy by making HTTP requests to an",
    "start": "667200",
    "end": "672959"
  },
  {
    "text": "OPA server that is collocated with the Chino clusters opa then makes policy",
    "start": "672959",
    "end": "678560"
  },
  {
    "text": "decisions based on bundled data distributed from OPA",
    "start": "678560",
    "end": "684399"
  },
  {
    "text": "bundler on top of this our system is responsible for making dashed arrows",
    "start": "684440",
    "end": "690399"
  },
  {
    "text": "happen firstly data owner needs to have a way to define catalog properties in",
    "start": "690399",
    "end": "695839"
  },
  {
    "text": "our system secondly there are also need to be a way for them to define data",
    "start": "695839",
    "end": "701040"
  },
  {
    "text": "access policies over the catalog they defined lastly uh service owners need to",
    "start": "701040",
    "end": "707360"
  },
  {
    "text": "be able to create their clusters mounting the",
    "start": "707360",
    "end": "712600"
  },
  {
    "text": "cataloges the data owners define their cataloges as Kubernetes custom resources in our system this is almost like a",
    "start": "712600",
    "end": "720000"
  },
  {
    "text": "plain text configuration file but with the ability to inject secrets the plain text properties field",
    "start": "720000",
    "end": "727519"
  },
  {
    "text": "is basically identical to the resulting catalog properties file but uh it's it's",
    "start": "727519",
    "end": "734320"
  },
  {
    "text": "without a sensitive information such as access credentials our Kubernetes controller",
    "start": "734320",
    "end": "740720"
  },
  {
    "text": "uses secured properties fields to generate additional fields in the tuner configure file without exposing the",
    "start": "740720",
    "end": "747120"
  },
  {
    "text": "values to service owners this separation is not mandatory but this allows us to",
    "start": "747120",
    "end": "752639"
  },
  {
    "text": "safely store China catalog definitions to log stretch for example without worrying about sensitive information",
    "start": "752639",
    "end": "759839"
  },
  {
    "text": "this also makes it possible for us to let service owners discover existing cataloges directly in Kubernetes simply",
    "start": "759839",
    "end": "767519"
  },
  {
    "text": "by executing cubicle get or using kubernetes rest API without showing data access",
    "start": "767519",
    "end": "774279"
  },
  {
    "text": "credentials now that tuner catalogs are registered in our system data owners can define data access policies over them to",
    "start": "774279",
    "end": "782320"
  },
  {
    "text": "do this data owners define another custom resource by referencing the tuner catalog by name in the",
    "start": "782320",
    "end": "789079"
  },
  {
    "text": "spec and these access controls are defined as a group of tables and columns for which the cat access can be granted",
    "start": "789079",
    "end": "796560"
  },
  {
    "text": "together for example uh in a data in a data catalog many maintained by a news",
    "start": "796560",
    "end": "802880"
  },
  {
    "text": "data team if a specified set of columns in the uh table um if the specific",
    "start": "802880",
    "end": "809839"
  },
  {
    "text": "columns in the table has sensitive data those columns may be excluded from an access control so that it can be shared",
    "start": "809839",
    "end": "817440"
  },
  {
    "text": "more broadly across across many teams within the company given the desired grouping of",
    "start": "817440",
    "end": "824399"
  },
  {
    "text": "resources from the data owner uh our Kubernetes controller needs to configure over bundler so that the bundle contains",
    "start": "824399",
    "end": "831680"
  },
  {
    "text": "policies that can be used together with users identification this typically involves",
    "start": "831680",
    "end": "838720"
  },
  {
    "text": "um external identity systems configuration such as LDAP and IM um so",
    "start": "838720",
    "end": "844880"
  },
  {
    "text": "we chose uh to let the Kubernetes controller to do the work in our implementation the controller also",
    "start": "844880",
    "end": "851279"
  },
  {
    "text": "generates intermediate representations to a separate policy store to optimize the computation of bundle",
    "start": "851279",
    "end": "858920"
  },
  {
    "text": "generation our open server periodically downloads the policy bundle that contain the policy that can be used with the",
    "start": "858920",
    "end": "865839"
  },
  {
    "text": "user identities then when the user send over tuner queries with the identities such as JWT token the tuner is able to",
    "start": "865839",
    "end": "874240"
  },
  {
    "text": "allow or reject the query execution based on whether or not user belongs to",
    "start": "874240",
    "end": "880480"
  },
  {
    "text": "certain user groups or roles in a status field of the custom",
    "start": "880480",
    "end": "886480"
  },
  {
    "text": "resource uh we show generated external resources such as policies in the policy store besides whether these external",
    "start": "886480",
    "end": "892959"
  },
  {
    "text": "resources are correctly configured and ready to use so far we went through how we",
    "start": "892959",
    "end": "899920"
  },
  {
    "text": "implemented centralized data access control by data owners so as a little segue uh let me briefly talk about how",
    "start": "899920",
    "end": "906959"
  },
  {
    "text": "we reuse the same infrastructure for computation access control by service",
    "start": "906959",
    "end": "912199"
  },
  {
    "text": "owners since Trino queries as well as Trina UI accesses are via",
    "start": "912199",
    "end": "917959"
  },
  {
    "text": "HTTPS we introduced another open source component operate plug-in that allows us",
    "start": "917959",
    "end": "924160"
  },
  {
    "text": "to authorize HTTP accesses via OPA then we all we needed to do is to",
    "start": "924160",
    "end": "930959"
  },
  {
    "text": "inject additional access policies into OPA for computer resources",
    "start": "930959",
    "end": "936399"
  },
  {
    "text": "now the tune service owners can manage who should be able to access their tuned clusters by configuring an external",
    "start": "936399",
    "end": "944120"
  },
  {
    "text": "system as computation access control is relatively simpler comp compared to data",
    "start": "944120",
    "end": "949440"
  },
  {
    "text": "access control we did not need an additional Kubernetes custom resource with controller in this case but if it",
    "start": "949440",
    "end": "956560"
  },
  {
    "text": "requires more complex setup with um self tracking um such as configuration",
    "start": "956560",
    "end": "962240"
  },
  {
    "text": "spanning across multiple systems or policy representation that does not fit into well in an existing policy store we",
    "start": "962240",
    "end": "969920"
  },
  {
    "text": "could do the same as data access control so lastly we need to enable our",
    "start": "969920",
    "end": "976720"
  },
  {
    "text": "service owners to uh create their tuner clusters with mounted",
    "start": "976720",
    "end": "982680"
  },
  {
    "text": "catalogs but the configuration of the tuner cluster can be very complex as you can see we need to set up a bunches of",
    "start": "982680",
    "end": "990560"
  },
  {
    "text": "resources such as trainer coordinate and worker post as well as ingresses and config maps another complication is to",
    "start": "990560",
    "end": "997920"
  },
  {
    "text": "know configuration files where certain parameters sometimes need to be derived",
    "start": "997920",
    "end": "1003199"
  },
  {
    "text": "from other parameters in a consistent way for example the maximum memory of",
    "start": "1003199",
    "end": "1008800"
  },
  {
    "text": "each query needed to be derived from container memory size um and this is",
    "start": "1008800",
    "end": "1015759"
  },
  {
    "text": "done by accounting for JVM memory consumption outside of heap and also JVM",
    "start": "1015759",
    "end": "1020880"
  },
  {
    "text": "heap consumption outside of Trino internal memory pool",
    "start": "1020880",
    "end": "1026240"
  },
  {
    "text": "so to simplify the workflow for Juno service owners uh we introduce a custom",
    "start": "1026240",
    "end": "1031600"
  },
  {
    "text": "resource with a very limited configuration in this example the Tuno service custom resource has um list of",
    "start": "1031600",
    "end": "1039199"
  },
  {
    "text": "catalogs to be mounted and the amount of memory that users want to allocate to",
    "start": "1039199",
    "end": "1044880"
  },
  {
    "text": "their tuner clusters in our platform our Kubernetes controller generates fully",
    "start": "1044880",
    "end": "1050400"
  },
  {
    "text": "detailed configuration from these limited parameters behind the scenes the obvious trade-off here is between",
    "start": "1050400",
    "end": "1057440"
  },
  {
    "text": "the flexibility for service owners to configure their tuner clusters in the exact way for their very specific need",
    "start": "1057440",
    "end": "1064720"
  },
  {
    "text": "versus their ease of use by not needing to even think about minor details but",
    "start": "1064720",
    "end": "1071200"
  },
  {
    "text": "more importantly we as a platform owner have more opportunity to optimize resource",
    "start": "1071200",
    "end": "1077840"
  },
  {
    "text": "allocation on our end this way for example if we are going to introduce",
    "start": "1077840",
    "end": "1083280"
  },
  {
    "text": "auto scaling of number of workers it would be harder if our users are",
    "start": "1083280",
    "end": "1088320"
  },
  {
    "text": "specifying every single details in their parts instead if service owner's",
    "start": "1088320",
    "end": "1093520"
  },
  {
    "text": "expectation is more centered around the functionality such as maximum query size",
    "start": "1093520",
    "end": "1098960"
  },
  {
    "text": "or latency distribution of queries we can introduce such optimization as long",
    "start": "1098960",
    "end": "1104640"
  },
  {
    "text": "as the service level is kept above the um agreed upon level",
    "start": "1104640",
    "end": "1111120"
  },
  {
    "text": "regarding the flexibility of configuration we can introduce additional spec fields as we collect",
    "start": "1111120",
    "end": "1117520"
  },
  {
    "text": "feedbacks from service owners and define new fields in terms of the effect they",
    "start": "1117520",
    "end": "1123320"
  },
  {
    "text": "produce for example uh we added a single query limit percentage field because in",
    "start": "1123320",
    "end": "1129840"
  },
  {
    "text": "some cases service owners wanted to guarantee that at least end queries can",
    "start": "1129840",
    "end": "1135200"
  },
  {
    "text": "consume a consistent amount of maximum memory they can set this to 50 two",
    "start": "1135200",
    "end": "1141120"
  },
  {
    "text": "queries need to be have consistent maximum or 20 if they want five",
    "start": "1141120",
    "end": "1148159"
  },
  {
    "text": "queries as a controller figures out uh details and prepares required resources",
    "start": "1148679",
    "end": "1154799"
  },
  {
    "text": "um it satises of these resources in the status field the underlying kubernetes",
    "start": "1154799",
    "end": "1160720"
  },
  {
    "text": "resources are structured in a very similar way to um the open source helm chart managed in upstream tuner",
    "start": "1160720",
    "end": "1169320"
  },
  {
    "text": "project it also shows certain configuration resulting from the um",
    "start": "1169320",
    "end": "1174640"
  },
  {
    "text": "internal computation for users information in this case uh the maximum amount of memory available to each query",
    "start": "1174640",
    "end": "1182799"
  },
  {
    "text": "ended up with around 32 GB when the service is ready endpoint URLs",
    "start": "1182799",
    "end": "1190160"
  },
  {
    "text": "of query and the tuner UI will be available in the status status field as",
    "start": "1190160",
    "end": "1195480"
  },
  {
    "text": "well users can use these URLs for running tuner queries over the mounted",
    "start": "1195480",
    "end": "1200880"
  },
  {
    "text": "cataloges and look up information about their queries in Tuner",
    "start": "1200880",
    "end": "1206799"
  },
  {
    "text": "UI so overall this is what we've built data owners can create tun catalog",
    "start": "1207320",
    "end": "1215360"
  },
  {
    "text": "custom resources so that they can share data access configurations without exposing access",
    "start": "1215360",
    "end": "1221880"
  },
  {
    "text": "credentials and they can create access control custom resources so that they control data accesses up to column level",
    "start": "1221880",
    "end": "1229280"
  },
  {
    "text": "granularity over their cataloges then a tuner service owners can create tun custom resources so that",
    "start": "1229280",
    "end": "1236480"
  },
  {
    "text": "they instantiate their tuner cluster which can mount jun catalogs with a simple spec and also they can control",
    "start": "1236480",
    "end": "1243679"
  },
  {
    "text": "computer access for users here we make use of the same opa",
    "start": "1243679",
    "end": "1248799"
  },
  {
    "text": "authorization backend for data access control using opa plug-in and for computation access control using opa",
    "start": "1248799",
    "end": "1255840"
  },
  {
    "text": "envoy plug-in and now uh I will turn this back to um Sue to review the",
    "start": "1255840",
    "end": "1261200"
  },
  {
    "text": "takeaways and their future works",
    "start": "1261200",
    "end": "1265399"
  },
  {
    "text": "all right thank you Aki let me just recap what we talked about within our presentation",
    "start": "1268880",
    "end": "1274960"
  },
  {
    "text": "so we talked about deploying Trino in combination with open policy agent on Kubernetes to deliver a distributed and",
    "start": "1274960",
    "end": "1283200"
  },
  {
    "text": "secure SQL solution that applies authorization checks at runtime",
    "start": "1283200",
    "end": "1288400"
  },
  {
    "text": "we also introduced CRDs to manage Truno specific abstractions like the Trino",
    "start": "1288400",
    "end": "1293880"
  },
  {
    "text": "cataloges that allow us to share catalogs and mount these properties onto",
    "start": "1293880",
    "end": "1299440"
  },
  {
    "text": "a Trino cluster as well as the Trino service that takes a very simple set of inputs that are that are exposed for our",
    "start": "1299440",
    "end": "1306640"
  },
  {
    "text": "end users to allow them to request a Trina cluster in a very simple way and",
    "start": "1306640",
    "end": "1312880"
  },
  {
    "text": "deploy that cluster on top of Kubernetesto and Envoy",
    "start": "1312880",
    "end": "1318400"
  },
  {
    "text": "we also introduced CRDs that codify data catalog access definitions named access",
    "start": "1318400",
    "end": "1325240"
  },
  {
    "text": "controls which enable granular definition of access controls in a way",
    "start": "1325240",
    "end": "1330320"
  },
  {
    "text": "that maps onto data cataloges uh and enable centralized data",
    "start": "1330320",
    "end": "1335880"
  },
  {
    "text": "governance and finally we showcased how all of these abstractions and resources",
    "start": "1335880",
    "end": "1341280"
  },
  {
    "text": "come together in a way to support a multi-tenant platform to secure",
    "start": "1341280",
    "end": "1347360"
  },
  {
    "text": "ownership of resources and enable cross tenency sharing of data",
    "start": "1347360",
    "end": "1352720"
  },
  {
    "text": "catalogs so now we have a managed truno as a service platform that applies",
    "start": "1352760",
    "end": "1358240"
  },
  {
    "text": "authorization checks at runtimes and enables data catalog sharing across namespaces what's next we still have a",
    "start": "1358240",
    "end": "1365919"
  },
  {
    "text": "lot of work cut out for us uh and we look forward to um following the",
    "start": "1365919",
    "end": "1372000"
  },
  {
    "text": "recommendations of the open source Trina community by deploying a Trino gateway alongside our Trina services to enable",
    "start": "1372000",
    "end": "1380159"
  },
  {
    "text": "our Trina cluster users to run queries onto a federated endpoint that can route",
    "start": "1380159",
    "end": "1386559"
  },
  {
    "text": "their queries intelligently across multiple Trina clusters for use cases",
    "start": "1386559",
    "end": "1392000"
  },
  {
    "text": "like supporting a query to continue running in disaster recovery or through maintenance operations",
    "start": "1392000",
    "end": "1398480"
  },
  {
    "text": "we also look forward to enhancing our resource allocation strategy by",
    "start": "1398480",
    "end": "1404320"
  },
  {
    "text": "utilizing horizontal pod autoscaling in a kubernetes fashion and lastly we're looking forward to",
    "start": "1404320",
    "end": "1411120"
  },
  {
    "text": "extending this exact solution across other comput engines like Apache Spark",
    "start": "1411120",
    "end": "1416320"
  },
  {
    "text": "and Apache Flink so that we can reuse these definitions of mounted cataloges",
    "start": "1416320",
    "end": "1422400"
  },
  {
    "text": "and apply the same level of granular runtime authorization checks across all of our compute engines that we maintain",
    "start": "1422400",
    "end": "1428720"
  },
  {
    "text": "on Kubernetes all right thank you everyone for coming to our presentation",
    "start": "1428720",
    "end": "1436360"
  },
  {
    "text": "[Applause]",
    "start": "1436360",
    "end": "1442420"
  },
  {
    "text": "time for Q&A q&a",
    "start": "1449280",
    "end": "1455480"
  },
  {
    "text": "yeah if does anyone have any questions for us in the audience",
    "start": "1455480",
    "end": "1462360"
  },
  {
    "text": "so thank you and I was wondering how are you guys handling updates and you mentioned Trino Gateway at the end for a",
    "start": "1464880",
    "end": "1471120"
  },
  {
    "text": "little bit but how are you handling updates and maintenance right now with like interrupting queries and stuff like",
    "start": "1471120",
    "end": "1477200"
  },
  {
    "text": "that that's that's exactly right so uh our expectation or our communication to our end users is that they need to have",
    "start": "1477200",
    "end": "1484480"
  },
  {
    "text": "their own retry mechanisms unfortunately and our um our first take on our managed",
    "start": "1484480",
    "end": "1490880"
  },
  {
    "text": "train platform we just launched is to support interactive use cases so uh",
    "start": "1490880",
    "end": "1496080"
  },
  {
    "text": "we're focusing on supporting that first our next item we're working on this quarter is exactly truno gateway so that",
    "start": "1496080",
    "end": "1502480"
  },
  {
    "text": "we can support maintenance operations without disrupting uh the running queries okay thanks",
    "start": "1502480",
    "end": "1510919"
  },
  {
    "text": "hi thank you for presentation uh quick simple question",
    "start": "1513679",
    "end": "1519360"
  },
  {
    "text": "uh you had the open policy agent OPA as a central",
    "start": "1519360",
    "end": "1524919"
  },
  {
    "text": "deployment and the cataloges were embedded right what are the tradeoffs of",
    "start": "1524919",
    "end": "1531679"
  },
  {
    "text": "having um like distributed cataloges versus centralized cataloges and what are your",
    "start": "1531679",
    "end": "1538240"
  },
  {
    "text": "thoughts around it",
    "start": "1538240",
    "end": "1541880"
  },
  {
    "text": "could I could I uh ask you to clarify the distinction between distributed cataloges and centralized cataloges Are",
    "start": "1543679",
    "end": "1549200"
  },
  {
    "text": "you talking about like a centralized management system versus having distributed management systems in different name spaces yeah if you could",
    "start": "1549200",
    "end": "1555760"
  },
  {
    "text": "go back to your slide where you summed it up um this one",
    "start": "1555760",
    "end": "1563600"
  },
  {
    "text": "yeah probably just focus on catalog part you had the catalogs embedded on each",
    "start": "1563600",
    "end": "1570200"
  },
  {
    "text": "Kubernetes deployments right um typically those cataloges would update",
    "start": "1570200",
    "end": "1576320"
  },
  {
    "text": "over the period of time right so the question was more kind of around there",
    "start": "1576320",
    "end": "1582080"
  },
  {
    "text": "is philosophy of centralized catalog for entire enterprise",
    "start": "1582080",
    "end": "1587279"
  },
  {
    "text": "and then the embedded cataloges which you have for each line of business right so what are the trade-offs what have you",
    "start": "1587279",
    "end": "1593760"
  },
  {
    "text": "weighed on and how are you powering it so um so that's exactly what um we were",
    "start": "1593760",
    "end": "1601440"
  },
  {
    "text": "able to design to sort of take the benefits of both right when you have a",
    "start": "1601440",
    "end": "1606640"
  },
  {
    "text": "distributed way of allowing our tenants to define their truno catalogs of course they're empowered to uh you know use the",
    "start": "1606640",
    "end": "1614720"
  },
  {
    "text": "privileges that are granted within their namespaces and uh you know update the connection properties and the catalog",
    "start": "1614720",
    "end": "1620880"
  },
  {
    "text": "properties as they see fit but at the same time in order to be able to apply",
    "start": "1620880",
    "end": "1625919"
  },
  {
    "text": "the OPA authorization checks and make sure that the rightful owners are actually the ones who are updating the",
    "start": "1625919",
    "end": "1632159"
  },
  {
    "text": "access control policies for those cataloges we still needed a way to put everything in a centralized catalog",
    "start": "1632159",
    "end": "1638480"
  },
  {
    "text": "management system that goes along with the policy admination system so our solution is a combination of the two",
    "start": "1638480",
    "end": "1645760"
  },
  {
    "text": "where your definitions of the cataloges are still defined within your name spaces but there's still a higher level",
    "start": "1645760",
    "end": "1653840"
  },
  {
    "text": "that is centralized that actually pulls all this information from the separate name spaces so that there is still let's",
    "start": "1653840",
    "end": "1660400"
  },
  {
    "text": "say a single label or a name that refers to a specific catalog that is within a",
    "start": "1660400",
    "end": "1665679"
  },
  {
    "text": "specific namespace so that the right authorization checks can happen onto that catalog when it is shared onto to a",
    "start": "1665679",
    "end": "1672320"
  },
  {
    "text": "different user i see so if the if I may um if the catalog is updating at like",
    "start": "1672320",
    "end": "1678960"
  },
  {
    "text": "pretty brisk pace um how do you foresee that being updated onto a centralized",
    "start": "1678960",
    "end": "1684480"
  },
  {
    "text": "cataloging system what kind of updates are you uh foreseeing when you mention",
    "start": "1684480",
    "end": "1690799"
  },
  {
    "text": "that the catalog is being updated could be about the metadata it could be about the people associated with the metadata",
    "start": "1690799",
    "end": "1697919"
  },
  {
    "text": "and so on you mean the connection details or the metadata within the catalog metadata",
    "start": "1697919",
    "end": "1705200"
  },
  {
    "text": "about the data itself glosseries and so on right so I'm taking a step further",
    "start": "1705200",
    "end": "1710880"
  },
  {
    "text": "here okay um not quite sure if I understand what",
    "start": "1710880",
    "end": "1718320"
  },
  {
    "text": "you're asking but um the data owners that are defining the cataloges within their respective name spaces still have",
    "start": "1718320",
    "end": "1725200"
  },
  {
    "text": "the ability to be able to update it the only thing that needs to be centralized and protected so that the access control",
    "start": "1725200",
    "end": "1731520"
  },
  {
    "text": "policies can still be applied are the sort of the non-negotiable connection details of the catalogs",
    "start": "1731520",
    "end": "1738080"
  },
  {
    "text": "so like where where the data is being pulled from whether that be a specific S3 location or a specific database",
    "start": "1738080",
    "end": "1744799"
  },
  {
    "text": "connection string those are the things that needs to remain protected so that they can still the the same name that is",
    "start": "1744799",
    "end": "1751679"
  },
  {
    "text": "being referred across all of our platform all of our train clusters can refer to the same logical entity of the catalog",
    "start": "1751679",
    "end": "1758159"
  },
  {
    "text": "got it okay thank you",
    "start": "1758159",
    "end": "1762080"
  },
  {
    "text": "hey thank you for for the talk was very good so so my team is on a on a very",
    "start": "1764880",
    "end": "1770880"
  },
  {
    "text": "similar journey and I would be interested to hear how stable uh the solution is in terms of the end user",
    "start": "1770880",
    "end": "1778159"
  },
  {
    "text": "experience so I saw you're using iceberg and trino and and kubernetes so yeah",
    "start": "1778159",
    "end": "1784880"
  },
  {
    "text": "maybe you can share a bit yeah uh nice to meet you so we are maybe in the",
    "start": "1784880",
    "end": "1791600"
  },
  {
    "text": "earlier stages of our development so we just went into G uh two months ago and",
    "start": "1791600",
    "end": "1796880"
  },
  {
    "text": "our the existing users of our platform are having a stable experience within",
    "start": "1796880",
    "end": "1802080"
  },
  {
    "text": "all of our tiers um if you're asking about the specific choices of technologies like Kubernetes",
    "start": "1802080",
    "end": "1809200"
  },
  {
    "text": "Trino and iceberg I think that that's a combination of technology that is being celebrated across uh many companies when",
    "start": "1809200",
    "end": "1817360"
  },
  {
    "text": "they're using it for analytical purposes what I would say is because it is so",
    "start": "1817360",
    "end": "1822600"
  },
  {
    "text": "popular and because people have sort of um tried to make use of the same set of",
    "start": "1822600",
    "end": "1829279"
  },
  {
    "text": "architecture for a variety of use cases for which it might not necessarily be",
    "start": "1829279",
    "end": "1834559"
  },
  {
    "text": "tuned for i think people are often uh running into issues with maybe their",
    "start": "1834559",
    "end": "1839600"
  },
  {
    "text": "query performance because they're sort of expecting subsequent latencies of queries for a architecture that is",
    "start": "1839600",
    "end": "1845840"
  },
  {
    "text": "optimized for analytical processing that's what I would say people have been",
    "start": "1845840",
    "end": "1851039"
  },
  {
    "text": "running into issues with mostly from what I can see um was there were were there a specific set of issues that you",
    "start": "1851039",
    "end": "1857520"
  },
  {
    "text": "were thinking about when you were asking that question think more about um container life cycle management when",
    "start": "1857520",
    "end": "1864159"
  },
  {
    "text": "when uh Trino goes down i mean there are so many so many things in your tax stack",
    "start": "1864159",
    "end": "1870720"
  },
  {
    "text": "that can go wrong right so how how how does that work for the user how",
    "start": "1870720",
    "end": "1876640"
  },
  {
    "text": "stable is that yeah so just like uh we were talking about in a previous question right um when when we're when",
    "start": "1876640",
    "end": "1885760"
  },
  {
    "text": "we're invoking maintenance operations or when a data center goes down our current",
    "start": "1885760",
    "end": "1891520"
  },
  {
    "text": "architecture requires that the Trina cluster user to figure out what other cluster that is up to actually reroute",
    "start": "1891520",
    "end": "1898640"
  },
  {
    "text": "their uh queries but with something like trreno gateway sitting in front and actually intelligently balancing the",
    "start": "1898640",
    "end": "1905799"
  },
  {
    "text": "workloads that that is going to be a lot easier so there are different tools we",
    "start": "1905799",
    "end": "1911279"
  },
  {
    "text": "are looking to build on top of our current solution to introduce more stability uh to address the problems",
    "start": "1911279",
    "end": "1918480"
  },
  {
    "text": "you're asking about just right now yeah super thank you",
    "start": "1918480",
    "end": "1923279"
  }
]
[
  {
    "text": "okay good morning everyone thank you for being here with us today um I hope you're all enjoying CubeCon so far yes I",
    "start": "160",
    "end": "7440"
  },
  {
    "text": "will take that as a yes all right so today we're going to talk about day one anomaly detection for",
    "start": "7440",
    "end": "13320"
  },
  {
    "text": "observability but before we get started we'll take a quick moment to introduce ourselves hi I'm Kitika i'm a machine",
    "start": "13320",
    "end": "19439"
  },
  {
    "text": "learning engineer at Apple and I work with the observability team and my background is in observability machine",
    "start": "19439",
    "end": "25199"
  },
  {
    "text": "learning and data science prashant hello everyone uh I'm Prashant i'm also a machine learning engineer at Apple i",
    "start": "25199",
    "end": "31279"
  },
  {
    "text": "also am a part of the observability team and my background is in machine learning natural language processing and",
    "start": "31279",
    "end": "37120"
  },
  {
    "text": "observability all right okay so for those of you who attended our talk last year in CubeCon",
    "start": "37120",
    "end": "44480"
  },
  {
    "text": "uh Salt Lake City we spoke about how we can leverage anomaly detection to not just improve MTD which is meantime to",
    "start": "44480",
    "end": "51120"
  },
  {
    "text": "detect but also improve meanantime to resolve by just ingesting some additional information and bootstrapping",
    "start": "51120",
    "end": "57120"
  },
  {
    "text": "the anomaly detection models but for those of you who did not attend our talk there is a QR code up there which you",
    "start": "57120",
    "end": "63039"
  },
  {
    "text": "guys can just take a picture of um it's on YouTube you can watch it so now Prashant will go into what we're going",
    "start": "63039",
    "end": "68240"
  },
  {
    "text": "to talk about today all right thank you Critica so we as",
    "start": "68240",
    "end": "74080"
  },
  {
    "text": "Kitika mentioned we previously talked about anomaly detection and how it helps to detect and resolve incidents faster",
    "start": "74080",
    "end": "80560"
  },
  {
    "text": "but we actually wanted to take it a step further and see if we can actually increase the time between failures that",
    "start": "80560",
    "end": "87759"
  },
  {
    "text": "is if you can improve the mean time between failures in today's talk we'll talk about how combining metrics models",
    "start": "87759",
    "end": "95520"
  },
  {
    "text": "and modern-day observability tools can actually shift your approach from being reactive to proactive we'll start with a",
    "start": "95520",
    "end": "101920"
  },
  {
    "text": "case study of day one anomaly detection uh we'll talk about the cold start problem and how to overcome it with like",
    "start": "101920",
    "end": "107520"
  },
  {
    "text": "a simple demo and then we can also talk about how to train and serve more complex models with",
    "start": "107520",
    "end": "113479"
  },
  {
    "text": "CubeFlow so here's what we are hoping you'll walk away with first anomaly",
    "start": "113479",
    "end": "118759"
  },
  {
    "text": "detection isn't just a post-production tool it should be a day one decision second great anomaly detection",
    "start": "118759",
    "end": "126719"
  },
  {
    "text": "starts with great observability and that's not just metrics but meaningful metrics your feature engineering should",
    "start": "126719",
    "end": "132400"
  },
  {
    "text": "be your first model next your model should align with your operational reality you need models that strike the",
    "start": "132400",
    "end": "139680"
  },
  {
    "text": "right balance between accuracy latency and interpretability to drive the",
    "start": "139680",
    "end": "145599"
  },
  {
    "text": "maximum value and finally anomaly detection isn't just for production",
    "start": "145599",
    "end": "150879"
  },
  {
    "text": "there is immense value in applying it across staging your CI/CD even a development environments if you want to",
    "start": "150879",
    "end": "157040"
  },
  {
    "text": "catch flaky behavior before it even hits production so let's in talk about a case",
    "start": "157040",
    "end": "164200"
  },
  {
    "text": "study we wanted to introduce our new startup an astronomy theme store called",
    "start": "164200",
    "end": "170000"
  },
  {
    "text": "Stella Stash in this case study we'll follow what happens when our store runs into some issues before it even achieves",
    "start": "170000",
    "end": "178120"
  },
  {
    "text": "liftoff so in seller stash we sell telescopes for stargazing binoculars if",
    "start": "178120",
    "end": "184480"
  },
  {
    "text": "you're into bird watching or spying on your neighbors and all sort of other fancy gadgets we also offer online",
    "start": "184480",
    "end": "191680"
  },
  {
    "text": "classes for new stargazers who want to get into the field now as a store owner what exactly",
    "start": "191680",
    "end": "198560"
  },
  {
    "text": "do you want you want to ensure that your product has good reliability um availability and performance for that we",
    "start": "198560",
    "end": "205120"
  },
  {
    "text": "set up some service level agreements and we instrument some service level indicators to track these agreements we",
    "start": "205120",
    "end": "210959"
  },
  {
    "text": "have uh SLI like request latency QPS failure rate we also track some low-level infrastructure metrics like",
    "start": "210959",
    "end": "217680"
  },
  {
    "text": "memory bit rate etc and then we're done and we roll it out for our users",
    "start": "217680",
    "end": "224000"
  },
  {
    "text": "so our service is growing users are happy and our tutorials especially are a big hit so to meet this high demand we",
    "start": "224000",
    "end": "232000"
  },
  {
    "text": "start adding more to keep up with the interest and expand our",
    "start": "232000",
    "end": "237200"
  },
  {
    "text": "offerings now all is good but some customers start reporting delays higher",
    "start": "237400",
    "end": "242799"
  },
  {
    "text": "latencies and even timeouts while they're loading the tutorial catalog at this point we don't really have any",
    "start": "242799",
    "end": "249599"
  },
  {
    "text": "alerts or anomaly detection set up like after all we're still expanding we're still in the initial phase but soon a",
    "start": "249599",
    "end": "257919"
  },
  {
    "text": "wave of one-star reviews just comes our way customers are complaining about slowdowns timeouts and just a general",
    "start": "257919",
    "end": "264080"
  },
  {
    "text": "poor user experience and it's starting to hurt so we start investigating and find",
    "start": "264080",
    "end": "270880"
  },
  {
    "text": "out that the request latency has actually gone up after a few frantic sleepless nights of root cause hunting",
    "start": "270880",
    "end": "277520"
  },
  {
    "text": "we find out what the actual issue is our thumbnails are too large and as we kept",
    "start": "277520",
    "end": "283360"
  },
  {
    "text": "on adding more and more courses the page load time grew significantly leading to",
    "start": "283360",
    "end": "288720"
  },
  {
    "text": "slowdowns and timeouts we are fixing it but by this time the damage has already been done customers have already had a",
    "start": "288720",
    "end": "296400"
  },
  {
    "text": "poor user experience we have lost the user loyalty there's also the case of internal burnout where our engineers",
    "start": "296400",
    "end": "303600"
  },
  {
    "text": "have spent you know the sleepless nights trying to find the root cause and finally uh they in the meantime most of",
    "start": "303600",
    "end": "309680"
  },
  {
    "text": "the users just went to a competitor leading to a loss of revenue so where did we go",
    "start": "309680",
    "end": "316520"
  },
  {
    "text": "wrong the common assumption in building services that anomaly detection is only useful for mature and production ready",
    "start": "316520",
    "end": "323240"
  },
  {
    "text": "services on the surface it kind of makes sense like why would you bother detecting anomalies when there is when",
    "start": "323240",
    "end": "330880"
  },
  {
    "text": "everything is still being duct taped together early stage services are chaotic they keep on changing and they",
    "start": "330880",
    "end": "337280"
  },
  {
    "text": "they're frankly unpredictable so adding anomaly detection sometimes can feel",
    "start": "337280",
    "end": "342479"
  },
  {
    "text": "pointless or even frustrating but ironically that's exactly when you need it the",
    "start": "342479",
    "end": "348520"
  },
  {
    "text": "most there is a second assumption as well that anomaly detection is complex",
    "start": "348520",
    "end": "353919"
  },
  {
    "text": "it's often seen as something that can take away engineering cycles and time from things that actually matter like",
    "start": "353919",
    "end": "359360"
  },
  {
    "text": "delivering features but that's also no longer true with tools like open telemetry Prometheus and Kubernetes",
    "start": "359360",
    "end": "366160"
  },
  {
    "text": "native ML frameworks you don't really have to go all in from day one you can start small and use lightweight models",
    "start": "366160",
    "end": "374240"
  },
  {
    "text": "and then grow as the system expands so if we had actually",
    "start": "374240",
    "end": "382160"
  },
  {
    "text": "implemented anomaly detection as part of our development framework in day one things would have been a little",
    "start": "382160",
    "end": "387199"
  },
  {
    "text": "different imagine if our CI environment ran a nightly job which does build",
    "start": "387199",
    "end": "392720"
  },
  {
    "text": "overbuild analysis with anomaly detection now this job flags a spike in",
    "start": "392720",
    "end": "398160"
  },
  {
    "text": "latency nothing is really broken but something is clearly off now in our",
    "start": "398160",
    "end": "403600"
  },
  {
    "text": "actual use case this build went vended to production and were related to a bad",
    "start": "403600",
    "end": "408960"
  },
  {
    "text": "user experience but with anomaly detection in CI we would have caught this which means there would have been",
    "start": "408960",
    "end": "414319"
  },
  {
    "text": "no uh incident and no onestar",
    "start": "414319",
    "end": "419039"
  },
  {
    "text": "reviews so we've talked about day one anomaly detection and how it can be",
    "start": "421479",
    "end": "426560"
  },
  {
    "text": "helpful but how exactly do you add it for your nent services so any typical",
    "start": "426560",
    "end": "432880"
  },
  {
    "text": "machine learning life cycle generally has four important steps first is data",
    "start": "432880",
    "end": "438800"
  },
  {
    "text": "instrumentation then feature engineering then actual modeling and finally deployment and",
    "start": "438800",
    "end": "445599"
  },
  {
    "text": "inference so let's dive into this and build our day one and nom",
    "start": "445599",
    "end": "451160"
  },
  {
    "text": "detection so the first is data instrumentation so in our case it's",
    "start": "451160",
    "end": "456280"
  },
  {
    "text": "metrics so we have learned our lesson let's go back and set up an detection on every metric that we can think of i mean",
    "start": "456280",
    "end": "463199"
  },
  {
    "text": "what's the harm but more metrics can often lead to more chaos it can lead to false positives alert fatigue and just",
    "start": "463199",
    "end": "470720"
  },
  {
    "text": "unnecessary operational overhead at this point you're not detecting anomalies you're just drowning in them so the key",
    "start": "470720",
    "end": "477520"
  },
  {
    "text": "is to not just use metrics but use meaningful metrics so we have selected our",
    "start": "477520",
    "end": "484879"
  },
  {
    "text": "meaningful metrics now let's look at the second point that's feature engineering so instead of relying on",
    "start": "484879",
    "end": "490800"
  },
  {
    "text": "just raw metrics alone you can also enrich your data by building and engineering your features for example",
    "start": "490800",
    "end": "498319"
  },
  {
    "text": "rolling averages change point drift indicators or domain specific thresholds",
    "start": "498319",
    "end": "503360"
  },
  {
    "text": "these features can give your model a lot of context and it can enrich your input",
    "start": "503360",
    "end": "508720"
  },
  {
    "text": "for example you can also find slowmoving trends which would have been a little difficult to identify with a simple",
    "start": "508720",
    "end": "514880"
  },
  {
    "text": "glance from your uh raw metrics so now this will help you move",
    "start": "514880",
    "end": "520240"
  },
  {
    "text": "from metric math to actual insights",
    "start": "520240",
    "end": "524519"
  },
  {
    "text": "so we've got our metrics we've got our engineered features and now it's time for the fun part that's modeling now",
    "start": "525519",
    "end": "532080"
  },
  {
    "text": "it's time to throw all of these features into the biggest newest transformer-based model that you can find until you realize that you're",
    "start": "532080",
    "end": "539040"
  },
  {
    "text": "actually just still talking about day one anomaly detection which means your model can't actually make accurate",
    "start": "539040",
    "end": "545680"
  },
  {
    "text": "predictions if you don't have if you have limited or no historical data so",
    "start": "545680",
    "end": "551120"
  },
  {
    "text": "that means you have no baseline you have no temporal patterns you lack the distributional context of what looks",
    "start": "551120",
    "end": "557440"
  },
  {
    "text": "normal in your data and you don't have any labelled anomalies because nothing is really broken yet and this is the",
    "start": "557440",
    "end": "564080"
  },
  {
    "text": "cold start problem now if you want to train our",
    "start": "564080",
    "end": "569839"
  },
  {
    "text": "models we do have to address this problem so the good news is that there",
    "start": "569839",
    "end": "575360"
  },
  {
    "text": "are simple ways and heristics to add context to your models and you can still get useful signals even before the data",
    "start": "575360",
    "end": "581839"
  },
  {
    "text": "has settled so let's solve this cold start problem and the first way to do it is to start",
    "start": "581839",
    "end": "589080"
  },
  {
    "text": "simple we can use simple statistical anomaly detection models which don't need deep learning pipelines or large",
    "start": "589080",
    "end": "596080"
  },
  {
    "text": "training jobs and they are just simple proven explainable math and they can be used at day one",
    "start": "596080",
    "end": "602160"
  },
  {
    "text": "so take zcore for example it's great at catching sudden spikes or diffs for",
    "start": "602160",
    "end": "607440"
  },
  {
    "text": "normally distributed data like request latency these models don't need labelled anomalies or months of historical data",
    "start": "607440",
    "end": "614320"
  },
  {
    "text": "you can actually start using them from day one they offer many advantages like you can get real-time detection with",
    "start": "614320",
    "end": "620160"
  },
  {
    "text": "minimal configurations changes you have low operational cost compared to deep learning models and you can interpret",
    "start": "620160",
    "end": "626880"
  },
  {
    "text": "them really easily because they are just mathematical formulas and that's why many teams use them as a first line of",
    "start": "626880",
    "end": "632959"
  },
  {
    "text": "defense even if they are planning on adding more complex machine learning models",
    "start": "632959",
    "end": "639360"
  },
  {
    "text": "later now the second point is using prior knowledge so even before you have",
    "start": "639800",
    "end": "645519"
  },
  {
    "text": "any fancy models your domain expertise is your biggest",
    "start": "645519",
    "end": "650560"
  },
  {
    "text": "superpower domain knowledges domain knowledge gives your statistical models u the context they need so with this you",
    "start": "650680",
    "end": "658640"
  },
  {
    "text": "can uh actually identify patterns even before they emerge you can encode what you already know like what does a normal",
    "start": "658640",
    "end": "664720"
  },
  {
    "text": "request latency look like or what is a critical CPU threshold you can smooth your noisy metrics you can tune your",
    "start": "664720",
    "end": "670399"
  },
  {
    "text": "models based on parameters that you already assumed and you can leverage the distribution properties of the data and",
    "start": "670399",
    "end": "676320"
  },
  {
    "text": "a lot more this is also part of feature engineering",
    "start": "676320",
    "end": "681519"
  },
  {
    "text": "and this next is using synthetic data with synthetic data you can",
    "start": "681519",
    "end": "688000"
  },
  {
    "text": "actually simulate real world behavior and stress test your service and its dependencies so you can add synthetic",
    "start": "688000",
    "end": "694480"
  },
  {
    "text": "data like adding metric spikes uh simulating resource exhaustion adding error injection and all of this can",
    "start": "694480",
    "end": "700880"
  },
  {
    "text": "really benefit you by improving your model feedback you can bootstrap your cold start problem by adding labeled",
    "start": "700880",
    "end": "707200"
  },
  {
    "text": "anomalies from your synthetic data you can validate your signals and identify whether the models and features that",
    "start": "707200",
    "end": "712640"
  },
  {
    "text": "you've chosen are actually valuable to you and you can do all of this in a safe and reliable environment without",
    "start": "712640",
    "end": "718480"
  },
  {
    "text": "actually affecting your users so we have talked a lot about day",
    "start": "718480",
    "end": "725440"
  },
  {
    "text": "one anom detection and how it's useful let's see how you can actually implement it",
    "start": "725440",
    "end": "732760"
  },
  {
    "text": "okay so let's say there's a metric that you want to track which is a good indicator for your service",
    "start": "739279",
    "end": "746160"
  },
  {
    "text": "health this is what your metric looks like now yeah this is what your metric",
    "start": "747399",
    "end": "753360"
  },
  {
    "text": "looks like and now you want to set up anomaly detection on top of it uh just because you want to be alerted when",
    "start": "753360",
    "end": "758959"
  },
  {
    "text": "something goes wrong with the service so since we are starting simple let's leverage a zcore anomaly detection model",
    "start": "758959",
    "end": "766240"
  },
  {
    "text": "zcore uses just your running mean and standard deviation to identify anomalies",
    "start": "766240",
    "end": "771440"
  },
  {
    "text": "and since we have fortunately using Prometheus PromQL gives you simple functions that you can use to calculate",
    "start": "771440",
    "end": "778079"
  },
  {
    "text": "this running mean and standard",
    "start": "778079",
    "end": "781120"
  },
  {
    "text": "deviation let's use five minutes this is your running mean for your",
    "start": "786760",
    "end": "793200"
  },
  {
    "text": "service for your metric and similarly you can also calculate your standard deviation over",
    "start": "793200",
    "end": "800200"
  },
  {
    "text": "time there you go this is your running mean and standard deviation of the metric now the zcore formula is nothing",
    "start": "800200",
    "end": "806240"
  },
  {
    "text": "but your data minus your average time minus your running mean divided by your",
    "start": "806240",
    "end": "812480"
  },
  {
    "text": "running standard deviation this is really simple and easy to use and this gives you your zcore value",
    "start": "812480",
    "end": "819360"
  },
  {
    "text": "now zcore what it actually represents is how many standard deviations your data",
    "start": "819360",
    "end": "825440"
  },
  {
    "text": "point is away from the mean so generally you can say two to three standard deviation is something you can consider",
    "start": "825440",
    "end": "832040"
  },
  {
    "text": "anomalous but this depends on your domain expertise and what type of metric you're dealing with but for our use case",
    "start": "832040",
    "end": "838480"
  },
  {
    "text": "let's say we want to be alerted on anything that's beyond two standard deviations",
    "start": "838480",
    "end": "844360"
  },
  {
    "text": "so these are the time periods where our data was actually anomalous and this is",
    "start": "847040",
    "end": "852480"
  },
  {
    "text": "something you might want to know from your metric to identify what's going on with the service now you can't keep on",
    "start": "852480",
    "end": "858880"
  },
  {
    "text": "monitoring this Prometheus UI so we can set up like a simple",
    "start": "858880",
    "end": "865480"
  },
  {
    "text": "rule which looks like this where you identify your expression your condition that you want",
    "start": "865480",
    "end": "872560"
  },
  {
    "text": "to be alerted on anything that's greater than two standard deviations and how long you want this anomaly to persist",
    "start": "872560",
    "end": "878880"
  },
  {
    "text": "before you're actually alerted once you have this you can go to your",
    "start": "878880",
    "end": "887000"
  },
  {
    "text": "alerts and see that your rule has been set up then you can sync with your alert",
    "start": "887000",
    "end": "892320"
  },
  {
    "text": "manager and be alerted on any modality you want to uh identify if your metric",
    "start": "892320",
    "end": "898800"
  },
  {
    "text": "has some deviations from the normal behavior so congratulations you've just",
    "start": "898800",
    "end": "905120"
  },
  {
    "text": "set up zcore normal detection on your metric on day one and I understand this is really a really basic demo and most",
    "start": "905120",
    "end": "910720"
  },
  {
    "text": "of the people here probably know this but the idea is that it is so basic you could set it up in a couple of minutes",
    "start": "910720",
    "end": "916800"
  },
  {
    "text": "with very minimal data and on day one in your development",
    "start": "916800",
    "end": "922560"
  },
  {
    "text": "environment so we have discussed so far how we can",
    "start": "923240",
    "end": "929120"
  },
  {
    "text": "use day one anomaly detection using simple statistical models and heristics but as your system grows and your",
    "start": "929120",
    "end": "936320"
  },
  {
    "text": "complex data patterns emerge some things can change which your uh statistical models might not scale to so this is",
    "start": "936320",
    "end": "943839"
  },
  {
    "text": "where we want to go beyond just detecting anomalies and use more complex models and model these complex data",
    "start": "943839",
    "end": "950000"
  },
  {
    "text": "patterns using deep learning so while deep learning models are very",
    "start": "950000",
    "end": "956399"
  },
  {
    "text": "powerful the complexities that come with it are something that need to be addressed and may become a blocker on",
    "start": "956399",
    "end": "961519"
  },
  {
    "text": "day one anomaly detection on the application side our biggest problem is there is lack of label data which means",
    "start": "961519",
    "end": "969040"
  },
  {
    "text": "you don't have any idea of like what anomalies are because by definition anomalies are rare second this lack of",
    "start": "969040",
    "end": "975440"
  },
  {
    "text": "data can also cause your models to overfit so it'll be hard to once your models are over it'll be hard to",
    "start": "975440",
    "end": "981120"
  },
  {
    "text": "generalize across different use cases feature engineering is still something that you need because any machine",
    "start": "981120",
    "end": "987600"
  },
  {
    "text": "learning problem uh deals with any machine learning model is only as good as your data and finally interpretation",
    "start": "987600",
    "end": "994639"
  },
  {
    "text": "of your models is still a challenge because deep learning models are generally considered to be blackbox and",
    "start": "994639",
    "end": "1001040"
  },
  {
    "text": "it's not helpful in your early stages of anomaly detection we're still trying to trust our models",
    "start": "1001040",
    "end": "1008240"
  },
  {
    "text": "on the infrastructure side deep learning models are resource intensive especially for your training jobs it's hard to",
    "start": "1008240",
    "end": "1014639"
  },
  {
    "text": "scale them across different environments managing environments across training testing production adds a whole new",
    "start": "1014639",
    "end": "1020639"
  },
  {
    "text": "level of complexity and finally you have to find a way to iterate these uh and",
    "start": "1020639",
    "end": "1026400"
  },
  {
    "text": "deploy these models reliably and continuously so while feature",
    "start": "1026400",
    "end": "1032160"
  },
  {
    "text": "engineering is complex we can't really get away from it the model as I mentioned is are only as good as the",
    "start": "1032160",
    "end": "1038240"
  },
  {
    "text": "data and so you need to ensure you have high quality features and data input data and the reason you don't start with",
    "start": "1038240",
    "end": "1044400"
  },
  {
    "text": "deep learning models is that they're hard to interpret but as you go forward and you understand your data and models",
    "start": "1044400",
    "end": "1051039"
  },
  {
    "text": "more you can improve your interpretation of your",
    "start": "1051039",
    "end": "1055759"
  },
  {
    "text": "models however we're still left with two challenges that we can actually",
    "start": "1058520",
    "end": "1063640"
  },
  {
    "text": "address one of the best ways to overcome complexity in existing model um is to",
    "start": "1063640",
    "end": "1070440"
  },
  {
    "text": "reuse pre-trained models especially those which are trained on large diverse public data sets that's where transfer",
    "start": "1070440",
    "end": "1077440"
  },
  {
    "text": "learner comes in when you're le leveraging these pre-trained models often they are trained on diverse data",
    "start": "1077440",
    "end": "1083440"
  },
  {
    "text": "sets or public data sets you can then fine-tune it on your own data and a",
    "start": "1083440",
    "end": "1088720"
  },
  {
    "text": "small amount can go a long way finally you validate and refine your model with your feedback from your real",
    "start": "1088720",
    "end": "1095520"
  },
  {
    "text": "anomalies in your data and you can input this in your real training data set to uh get better results going forward this",
    "start": "1095520",
    "end": "1102320"
  },
  {
    "text": "allows you to get up and running quickly even if you don't have tons of label data from day",
    "start": "1102320",
    "end": "1108120"
  },
  {
    "text": "one the there are several open source models that are built exactly for these kind of problems and here are a few that",
    "start": "1108120",
    "end": "1114960"
  },
  {
    "text": "I'd recommend checking out all",
    "start": "1114960",
    "end": "1120160"
  },
  {
    "text": "right now Critica will cover some intra challenges with deploying deep learning models",
    "start": "1120720",
    "end": "1126559"
  },
  {
    "text": "awesome thanks Rashan so now that we understand how to navigate the challenges of applying deep learning",
    "start": "1126559",
    "end": "1132400"
  },
  {
    "text": "models for anomaly detection on day one on the application side let us go back to our infrastructure concerns and see",
    "start": "1132400",
    "end": "1138400"
  },
  {
    "text": "how we can overcome those so we already know the answer to this kubernetes gives us the foundation",
    "start": "1138400",
    "end": "1144720"
  },
  {
    "text": "to overcome these infrastructure concerns that we already have but to truly operationalize ML on uh top of",
    "start": "1144720",
    "end": "1151360"
  },
  {
    "text": "Kubernetes we need something that is purpose-built and the answer is CubeFlow",
    "start": "1151360",
    "end": "1157520"
  },
  {
    "text": "so CubeFlow is an open- source uh platform designed for uh making ML on Kubernetes simple portable and scalable",
    "start": "1157520",
    "end": "1165440"
  },
  {
    "text": "it provides the individual components that you would need at every step of developing deploying and productionizing",
    "start": "1165440",
    "end": "1171360"
  },
  {
    "text": "ML models um it has Spark operator for data preparation and feature engineering",
    "start": "1171360",
    "end": "1176640"
  },
  {
    "text": "it has the trainer for training your large scale distributed uh training jobs um it has a model registry where you can",
    "start": "1176640",
    "end": "1182720"
  },
  {
    "text": "store your ML metadata as well as your uh model artifacts um Kserve is amazing",
    "start": "1182720",
    "end": "1189679"
  },
  {
    "text": "for inference and model serving at scale it can do autoscaling for you and cube uh it also has cubeflow pipelines which",
    "start": "1189679",
    "end": "1196480"
  },
  {
    "text": "helps you with uh containerized deployments progressive rollouts as well as automated pipelines so with Cubeflow",
    "start": "1196480",
    "end": "1204160"
  },
  {
    "text": "we can focus on the benefits of deep learning without having the overhead of setting up custom infrastructure for",
    "start": "1204160",
    "end": "1210400"
  },
  {
    "text": "developing and deploying your machine learning models in production okay so now let's talk about",
    "start": "1210400",
    "end": "1217039"
  },
  {
    "text": "how we can use CubeFlow to set up a uh scalable anomaly detection pipeline from",
    "start": "1217039",
    "end": "1222559"
  },
  {
    "text": "data prep all the way to production okay so let's say we start from a",
    "start": "1222559",
    "end": "1228320"
  },
  {
    "text": "pre-trained model and you know I picked an LSTM model from hugging face you can pull this model and store",
    "start": "1228320",
    "end": "1235440"
  },
  {
    "text": "it on the cubeflow uh model registry which is a centralized uh versioned data store for all of your",
    "start": "1235440",
    "end": "1242200"
  },
  {
    "text": "models and the first step as we already spoke about in any deep learning or ML pipeline is data prep we can use the",
    "start": "1242200",
    "end": "1248960"
  },
  {
    "text": "spark operator to run distributed data preparation jobs at scale and the same",
    "start": "1248960",
    "end": "1254159"
  },
  {
    "text": "spark operator can also help us run transformations like PCA or time windowing which is essentially to",
    "start": "1254159",
    "end": "1260559"
  },
  {
    "text": "generate features for our model training the next step is training we",
    "start": "1260559",
    "end": "1266880"
  },
  {
    "text": "can use cubeflow trainer for transfer learning our pre-trained model the LSTM1 from hugging face on the new data that",
    "start": "1266880",
    "end": "1273679"
  },
  {
    "text": "we have and we can also leverage KIB which is a tool that um is part of cubeflow which helps with hyperparameter",
    "start": "1273679",
    "end": "1280159"
  },
  {
    "text": "tuning and finally once the training is complete uh we can use the cube cubeflow",
    "start": "1280159",
    "end": "1286799"
  },
  {
    "text": "pipelines to package the model uh model uh as a container tag it and push it",
    "start": "1286799",
    "end": "1292159"
  },
  {
    "text": "back to the model registry with the model containerized",
    "start": "1292159",
    "end": "1297200"
  },
  {
    "text": "and published kserve takes over and serves the model on a live service on Kubernetes the same anomaly detection",
    "start": "1297200",
    "end": "1304159"
  },
  {
    "text": "model can be used on a wide variety of uh data sources and a wide variety of",
    "start": "1304159",
    "end": "1309360"
  },
  {
    "text": "use cases so this is just one way that we can",
    "start": "1309360",
    "end": "1314480"
  },
  {
    "text": "leverage cubeflow to help with overcoming the uh infrastructure concerns that we spoke about earlier and",
    "start": "1314480",
    "end": "1319919"
  },
  {
    "text": "deploying scalable anomaly detection models in production on day one there is very detailed documentation um on case",
    "start": "1319919",
    "end": "1326880"
  },
  {
    "text": "of they've done a great job and I have a QR code here and you can just um scan that it also has step-by-step",
    "start": "1326880",
    "end": "1333120"
  },
  {
    "text": "installation instructions as well so it's pretty good",
    "start": "1333120",
    "end": "1338120"
  },
  {
    "text": "okay so now that we've looked at how to address the uh application as well as infrastructure concerns that we may have",
    "start": "1339080",
    "end": "1345600"
  },
  {
    "text": "with anomaly detection on day one with statistical models as well as deep learning models let us just quickly walk",
    "start": "1345600",
    "end": "1351760"
  },
  {
    "text": "through how you can set up cubeflow on your local machine and deploy a simple anomaly detection model",
    "start": "1351760",
    "end": "1357520"
  },
  {
    "text": "so we'll walk through a very simple setup and we'll use a pre-trained anomaly detection uh for cubeflow and in",
    "start": "1357520",
    "end": "1363919"
  },
  {
    "text": "instead of u you know asking to install a whole uh cubeflow platform you can",
    "start": "1363919",
    "end": "1369039"
  },
  {
    "text": "just install whatever is necessary and for this you just need kserve and its dependencies so we'll install its",
    "start": "1369039",
    "end": "1375520"
  },
  {
    "text": "dependencies uh spin up the local kubernetes cluster load a simple model uh run a minimal pipeline and deploy uh",
    "start": "1375520",
    "end": "1381840"
  },
  {
    "text": "with kserve so first you'll have to set up your local environment so we start with the basics kind customize cube",
    "start": "1381840",
    "end": "1389640"
  },
  {
    "text": "cuttle the next step is for us to spin up a cluster and this is the cluster where we will run uh kserve but before",
    "start": "1389640",
    "end": "1396159"
  },
  {
    "text": "we install case we need to install some of the dependencies that it has so the first one is sto it needs it for its",
    "start": "1396159",
    "end": "1402799"
  },
  {
    "text": "ingress and um service mesh uh the other one is search manager which is for secure communication",
    "start": "1402799",
    "end": "1408640"
  },
  {
    "text": "between the services and finally uh cube uh kserve",
    "start": "1408640",
    "end": "1413919"
  },
  {
    "text": "is built on uh k native so So it needs uh the model life cycling networking and scaling models uh from K native so we",
    "start": "1413919",
    "end": "1420720"
  },
  {
    "text": "also install that these are essentially the building blocks that will power KSER",
    "start": "1420720",
    "end": "1426080"
  },
  {
    "text": "uh KS's autoscaling traffic routing and service",
    "start": "1426080",
    "end": "1430799"
  },
  {
    "text": "exposure so once we've got STTO SR manager and K native installed we have to now set up the final piece which is",
    "start": "1431799",
    "end": "1437280"
  },
  {
    "text": "Kserve queso is the component that uh knows how to take a model and expose it",
    "start": "1437280",
    "end": "1443120"
  },
  {
    "text": "on a live API so that you can perform anomaly detection on it and that's just how you do",
    "start": "1443120",
    "end": "1449080"
  },
  {
    "text": "it so now that our infra is ready we'll take a very quick uh small model that we",
    "start": "1449080",
    "end": "1454720"
  },
  {
    "text": "can u install so the walkthrough is using a uh isolation forest from scikitlearn and this is one of the",
    "start": "1454720",
    "end": "1461120"
  },
  {
    "text": "simplest uh unsupervised anomaly detection models that you can use but it's very effective",
    "start": "1461120",
    "end": "1466640"
  },
  {
    "text": "so this short Python script has um I don't think I can show it okay it has uh",
    "start": "1466640",
    "end": "1472720"
  },
  {
    "text": "it loads a simple CSV file of the time series values reshapes it and fits it into an",
    "start": "1472720",
    "end": "1479120"
  },
  {
    "text": "isolation forest once the model is trained it saves it as a pickle file the",
    "start": "1479120",
    "end": "1484400"
  },
  {
    "text": "pickle file is all case needs to run inference it gets the mo it gets the",
    "start": "1484400",
    "end": "1490159"
  },
  {
    "text": "model uh from just the pickle file and you don't need to containerize any of this training code that we have here or",
    "start": "1490159",
    "end": "1496000"
  },
  {
    "text": "build anything fancy you just need to give this model to KSER so now you have to deploy the model",
    "start": "1496000",
    "end": "1503039"
  },
  {
    "text": "first we serve the model over HTTP from our local machines uh using a very basic Python web server and this is so that",
    "start": "1503039",
    "end": "1510880"
  },
  {
    "text": "KSER can wget the model then we write the infrance service which basically tells uh ks of what is the name of your",
    "start": "1510880",
    "end": "1520200"
  },
  {
    "text": "model where can it find the model and what is the framework it's using and in this case it's using skarn we apply this",
    "start": "1520200",
    "end": "1528000"
  },
  {
    "text": "yl and queser will spin up a cluster fetch the model and expose it on an http endpoint so you can hit that for",
    "start": "1528000",
    "end": "1535320"
  },
  {
    "text": "predictions so if you hook this up to your service you can essentially perform anomaly detection on a very wide range",
    "start": "1535320",
    "end": "1540720"
  },
  {
    "text": "of use cases and you can also store these results on Prometheus and display it on a dashboard for better",
    "start": "1540720",
    "end": "1546640"
  },
  {
    "text": "visualization and also add um alerts we have as we have already looked at and this is something that we have set",
    "start": "1546640",
    "end": "1553720"
  },
  {
    "text": "up okay so a quick recap we set up case installed dependencies brought up a",
    "start": "1553720",
    "end": "1559679"
  },
  {
    "text": "minimal cub kubernetes cluster uh run ran a minimal pipeline and deployed the model to",
    "start": "1559679",
    "end": "1565080"
  },
  {
    "text": "queserve this is a very simple approach but it is perfect for day one anomaly detection because it's simple and when",
    "start": "1565080",
    "end": "1571840"
  },
  {
    "text": "you want to iterate faster with real world data this is what comes in hand uh very quickly um here are some",
    "start": "1571840",
    "end": "1579679"
  },
  {
    "text": "resources yesterday there was a cubeflow summit i hope a lot of you attended it uh but this is their page and you can",
    "start": "1579679",
    "end": "1584880"
  },
  {
    "text": "find the videos on that and um there's also a lot of documentation out there",
    "start": "1584880",
    "end": "1590559"
  },
  {
    "text": "for uh cubeflow i personally recommend the cubeflow 101 uh talk which is for",
    "start": "1590559",
    "end": "1595679"
  },
  {
    "text": "beginners and there are a bunch of short videos that you can learn from okay all right",
    "start": "1595679",
    "end": "1603000"
  },
  {
    "text": "so this is now our full end toend pipeline from data preparation feature extraction modeling deployment uh",
    "start": "1603000",
    "end": "1610480"
  },
  {
    "text": "serving and inference you have now set up your anomaly detection for running anomaly detection on any use case that",
    "start": "1610480",
    "end": "1616640"
  },
  {
    "text": "you want and this is both the training and inference pipelines but now let's talk about what",
    "start": "1616640",
    "end": "1623679"
  },
  {
    "text": "are some of some of the advantages and what should you watch out for when doing day one anomaly detection so as we've",
    "start": "1623679",
    "end": "1630320"
  },
  {
    "text": "already seen the advantages of day one anomaly detection is you catch performance regressions early you find",
    "start": "1630320",
    "end": "1635440"
  },
  {
    "text": "integration bugs early you validate assumptions that you made while developing before that hits real uh",
    "start": "1635440",
    "end": "1641679"
  },
  {
    "text": "users and impacts them you also shorten the feedback loop of uh your application",
    "start": "1641679",
    "end": "1647120"
  },
  {
    "text": "infrastructure changes that you make and finally root cause identification is also more focused because now you're",
    "start": "1647120",
    "end": "1652960"
  },
  {
    "text": "doing it at development and the changes that are within a build are much lesser than in a release so you are more",
    "start": "1652960",
    "end": "1658880"
  },
  {
    "text": "focused when you're finding the root cause however it also comes with its own limitations ci and staging environments",
    "start": "1658880",
    "end": "1665760"
  },
  {
    "text": "which are pre-pro environments typically have low data volume which means that it's hard for the model sometimes to",
    "start": "1665760",
    "end": "1672000"
  },
  {
    "text": "learn meaningful patterns you also will likely hit a higher volume of false",
    "start": "1672000",
    "end": "1677200"
  },
  {
    "text": "positives because of the inherent uh nature to be noisy for these environments if you're retraining your",
    "start": "1677200",
    "end": "1683360"
  },
  {
    "text": "model frequently your model might overfit to unstable patterns that are in",
    "start": "1683360",
    "end": "1688799"
  },
  {
    "text": "these environments and that kind of reduces the effectiveness and finally what might",
    "start": "1688799",
    "end": "1694880"
  },
  {
    "text": "look like an anomaly in staging or in CI may not be an anomaly in production and",
    "start": "1694880",
    "end": "1699919"
  },
  {
    "text": "vice versa but the advantages still outweigh the limitations and the key is",
    "start": "1699919",
    "end": "1706240"
  },
  {
    "text": "to keep it simple while you start use interpretable models and then finetune fine-tune the thresholds and as you go",
    "start": "1706240",
    "end": "1713279"
  },
  {
    "text": "into more complex scenarios you can graduate to deep learning models that are meant for more complex scenarios and",
    "start": "1713279",
    "end": "1719440"
  },
  {
    "text": "remember treat this as a way to augment but not replace your traditional",
    "start": "1719440",
    "end": "1725320"
  },
  {
    "text": "testing so let's go back to our uh MTR graph we had in the beginning of the presentation while during the last",
    "start": "1725320",
    "end": "1731279"
  },
  {
    "text": "CubeCon we spoke about how to leverage anomaly detection for u reducing meanantime to detect and meanantime to",
    "start": "1731279",
    "end": "1738120"
  },
  {
    "text": "resolve now we'll talk about how incorporating that into our development pipeline can help so with day one",
    "start": "1738120",
    "end": "1744240"
  },
  {
    "text": "anomaly detection we could reduce the number of failures that happen in production in the first place in",
    "start": "1744240",
    "end": "1750559"
  },
  {
    "text": "production anomaly detection is something that uh is done after something goes wrong and you're already",
    "start": "1750559",
    "end": "1756559"
  },
  {
    "text": "in firefighting mode but in development anomaly detection becomes a proactive",
    "start": "1756559",
    "end": "1762120"
  },
  {
    "text": "force during application development you can spot spikes and regressions much",
    "start": "1762120",
    "end": "1768840"
  },
  {
    "text": "earlier in CI testing you can flag instability introduced by code changes or environment",
    "start": "1768840",
    "end": "1775960"
  },
  {
    "text": "drift in staging you can catch integration issues like misbehaving services or skewed data",
    "start": "1775960",
    "end": "1783279"
  },
  {
    "text": "and finally in production you usually catch catch issues that are related to environment and scale and all of these",
    "start": "1783279",
    "end": "1790240"
  },
  {
    "text": "uh contribute to a powerful shift you're not just reducing MTR you're reducing the frequency of failures altogether",
    "start": "1790240",
    "end": "1796320"
  },
  {
    "text": "because you're treating different failures at different layers of your development cycle and let's bring this all together",
    "start": "1796320",
    "end": "1803840"
  },
  {
    "text": "in this final idea if your anomaly detection only kicks in in G you're treating the symptoms but by embedding",
    "start": "1803840",
    "end": "1810399"
  },
  {
    "text": "it into the full development life cycle you shorten the lifespan of an anomaly and catch it earlier during",
    "start": "1810399",
    "end": "1816600"
  },
  {
    "text": "deployment you're also catching it earlier and responding faster which means that you are stopping the failure",
    "start": "1816600",
    "end": "1823039"
  },
  {
    "text": "from ever reaching production so if you start thinking about anomaly detection not as a last mile ops but as a first",
    "start": "1823039",
    "end": "1830000"
  },
  {
    "text": "mile development companion you're not just reducing MTR but you're also increasing the meanantime between",
    "start": "1830000",
    "end": "1836720"
  },
  {
    "text": "failures and effectively making the service more resilient okay so we hope that you took",
    "start": "1836720",
    "end": "1843279"
  },
  {
    "text": "away that anomaly detection is more than just a production tool and that you're inspired to include anomaly detection as",
    "start": "1843279",
    "end": "1849440"
  },
  {
    "text": "part of your development life cycle and you know thank you for being here today and we'll be happy to take some",
    "start": "1849440",
    "end": "1855279"
  },
  {
    "text": "questions [Applause]",
    "start": "1855279",
    "end": "1865369"
  }
]
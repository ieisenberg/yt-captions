[
  {
    "text": "good morning hi cucon I'm Shirley Bales",
    "start": "1160",
    "end": "4319"
  },
  {
    "text": "and I lead software open ecosystem",
    "start": "4319",
    "end": "6040"
  },
  {
    "text": "strategy at Intel and I'm here today to",
    "start": "6040",
    "end": "8440"
  },
  {
    "text": "talk to you about an open source project",
    "start": "8440",
    "end": "10240"
  },
  {
    "text": "that Intel contributed to the Linux",
    "start": "10240",
    "end": "12160"
  },
  {
    "text": "Foundation Ai and data Community it's",
    "start": "12160",
    "end": "14839"
  },
  {
    "text": "called open platform for Enterprise AI",
    "start": "14839",
    "end": "17080"
  },
  {
    "text": "or Opa it's",
    "start": "17080",
    "end": "19560"
  },
  {
    "text": "Opia Opia is an industrywide effort and",
    "start": "19560",
    "end": "22640"
  },
  {
    "text": "you can see a number of Partners on the",
    "start": "22640",
    "end": "24359"
  },
  {
    "text": "screen here it provides microservice",
    "start": "24359",
    "end": "26679"
  },
  {
    "text": "recipes for building Cloud native",
    "start": "26679",
    "end": "28400"
  },
  {
    "text": "generative AI applications",
    "start": "28400",
    "end": "30480"
  },
  {
    "text": "helping you simplify the development",
    "start": "30480",
    "end": "32439"
  },
  {
    "text": "production and Adoption of generative AI",
    "start": "32439",
    "end": "34760"
  },
  {
    "text": "in the",
    "start": "34760",
    "end": "35640"
  },
  {
    "text": "Enterprise we're going to walk through",
    "start": "35640",
    "end": "37399"
  },
  {
    "text": "an example application with the help of",
    "start": "37399",
    "end": "39399"
  },
  {
    "text": "a couple of friends so you might",
    "start": "39399",
    "end": "41399"
  },
  {
    "text": "recognize these lovable characters fippy",
    "start": "41399",
    "end": "43559"
  },
  {
    "text": "and Goldie and they love attending cncf",
    "start": "43559",
    "end": "46840"
  },
  {
    "text": "events they want to know what's all the",
    "start": "46840",
    "end": "49199"
  },
  {
    "text": "fun things that are going on at cubon in",
    "start": "49199",
    "end": "50879"
  },
  {
    "text": "Salt Lake City this week they're pretty",
    "start": "50879",
    "end": "53120"
  },
  {
    "text": "techsavvy and they want to use AI to",
    "start": "53120",
    "end": "55680"
  },
  {
    "text": "generate an answer now as cucon is well",
    "start": "55680",
    "end": "58559"
  },
  {
    "text": "underway there's no time no time to",
    "start": "58559",
    "end": "60920"
  },
  {
    "text": "actually train a model on the event",
    "start": "60920",
    "end": "62359"
  },
  {
    "text": "schedule so and that would really just",
    "start": "62359",
    "end": "64280"
  },
  {
    "text": "be way too expensive so we're going to",
    "start": "64280",
    "end": "66400"
  },
  {
    "text": "need to use retrieval argumented",
    "start": "66400",
    "end": "68159"
  },
  {
    "text": "generation also known as rag to inject",
    "start": "68159",
    "end": "70920"
  },
  {
    "text": "some fresh knowledge into a large",
    "start": "70920",
    "end": "72439"
  },
  {
    "text": "language model called an llm let's see",
    "start": "72439",
    "end": "75320"
  },
  {
    "text": "how it works to create a chat plus Q&A",
    "start": "75320",
    "end": "78360"
  },
  {
    "text": "rag application we first need a",
    "start": "78360",
    "end": "80400"
  },
  {
    "text": "knowledge base somewhere to begin with",
    "start": "80400",
    "end": "82680"
  },
  {
    "text": "and in this case we're going to use a",
    "start": "82680",
    "end": "84240"
  },
  {
    "text": "conference schedule we're going to feed",
    "start": "84240",
    "end": "86880"
  },
  {
    "text": "the text from the conference site into",
    "start": "86880",
    "end": "89240"
  },
  {
    "text": "the app to serve as our knowledge base",
    "start": "89240",
    "end": "92200"
  },
  {
    "text": "we then extract the copy we'll break it",
    "start": "92200",
    "end": "94560"
  },
  {
    "text": "into phras into phrases and then extract",
    "start": "94560",
    "end": "97240"
  },
  {
    "text": "the phrases into vectors the vectors",
    "start": "97240",
    "end": "99759"
  },
  {
    "text": "will then populate a vector database and",
    "start": "99759",
    "end": "102320"
  },
  {
    "text": "what you see here is a knowledge base",
    "start": "102320",
    "end": "104079"
  },
  {
    "text": "for the rag when fippi actually ask",
    "start": "104079",
    "end": "106920"
  },
  {
    "text": "Goldie what are some fun things that we",
    "start": "106920",
    "end": "108799"
  },
  {
    "text": "can do at cucon this week the",
    "start": "108799",
    "end": "110759"
  },
  {
    "text": "application then transforms the question",
    "start": "110759",
    "end": "113000"
  },
  {
    "text": "into these vectors A retriever then",
    "start": "113000",
    "end": "115960"
  },
  {
    "text": "searches the database for the related",
    "start": "115960",
    "end": "117759"
  },
  {
    "text": "data and the question in context are",
    "start": "117759",
    "end": "120079"
  },
  {
    "text": "then injected into the llm IT augments",
    "start": "120079",
    "end": "122759"
  },
  {
    "text": "the answer generation the model then",
    "start": "122759",
    "end": "125479"
  },
  {
    "text": "generates an answer for fippi and Goldie",
    "start": "125479",
    "end": "127880"
  },
  {
    "text": "so've got rag again let's retrieve",
    "start": "127880",
    "end": "129959"
  },
  {
    "text": "augment and generate so here are the",
    "start": "129959",
    "end": "132440"
  },
  {
    "text": "some events that kicked off the week and",
    "start": "132440",
    "end": "134680"
  },
  {
    "text": "props to those of you who went to the",
    "start": "134680",
    "end": "136519"
  },
  {
    "text": "house of cube last night and also made",
    "start": "136519",
    "end": "138280"
  },
  {
    "text": "it to the run at 7: a.m. this",
    "start": "138280",
    "end": "141080"
  },
  {
    "text": "morning if you set out to build a chat",
    "start": "141080",
    "end": "144280"
  },
  {
    "text": "service with rag like this you're",
    "start": "144280",
    "end": "146120"
  },
  {
    "text": "probably going to be overwhelmed there's",
    "start": "146120",
    "end": "148560"
  },
  {
    "text": "dozens of vector databases out there um",
    "start": "148560",
    "end": "151120"
  },
  {
    "text": "redis milis chroma and you would need to",
    "start": "151120",
    "end": "154120"
  },
  {
    "text": "choose between a variety of embedding",
    "start": "154120",
    "end": "156000"
  },
  {
    "text": "models which are responsible for",
    "start": "156000",
    "end": "157720"
  },
  {
    "text": "converting those texts into numbers and",
    "start": "157720",
    "end": "160680"
  },
  {
    "text": "lastly you then need to choose an llm",
    "start": "160680",
    "end": "163360"
  },
  {
    "text": "and decide between a closed model such",
    "start": "163360",
    "end": "165319"
  },
  {
    "text": "as open AI or perhaps an open source",
    "start": "165319",
    "end": "167440"
  },
  {
    "text": "model that you could run locally like",
    "start": "167440",
    "end": "169239"
  },
  {
    "text": "mistol or Falcon the options are",
    "start": "169239",
    "end": "171840"
  },
  {
    "text": "overwhelming there are no standard",
    "start": "171840",
    "end": "174040"
  },
  {
    "text": "pipelines there's no standard or a",
    "start": "174040",
    "end": "176400"
  },
  {
    "text": "repeatable foundation in in helping",
    "start": "176400",
    "end": "178519"
  },
  {
    "text": "bring all this together in escap",
    "start": "178519",
    "end": "179840"
  },
  {
    "text": "scalable",
    "start": "179840",
    "end": "181000"
  },
  {
    "text": "application so how do we make it easier",
    "start": "181000",
    "end": "183280"
  },
  {
    "text": "for Enterprises to actually build",
    "start": "183280",
    "end": "185200"
  },
  {
    "text": "effective secure generative AI",
    "start": "185200",
    "end": "187560"
  },
  {
    "text": "applications rapidly and with",
    "start": "187560",
    "end": "190400"
  },
  {
    "text": "confidence this is where Opia comes in",
    "start": "190400",
    "end": "193599"
  },
  {
    "text": "the Project's goal is to standardize AI",
    "start": "193599",
    "end": "195959"
  },
  {
    "text": "development with microservices based",
    "start": "195959",
    "end": "197840"
  },
  {
    "text": "recipes that you can use with opa's chat",
    "start": "197840",
    "end": "201480"
  },
  {
    "text": "Q&A recipe fippi and Goldie could build",
    "start": "201480",
    "end": "204120"
  },
  {
    "text": "an llm with a retrieval rag application",
    "start": "204120",
    "end": "207360"
  },
  {
    "text": "by treating each part of the endtoend",
    "start": "207360",
    "end": "209280"
  },
  {
    "text": "app ation is a composable microservice",
    "start": "209280",
    "end": "212680"
  },
  {
    "text": "you have the freedom to choose any",
    "start": "212680",
    "end": "215080"
  },
  {
    "text": "microservice that you want which helps a",
    "start": "215080",
    "end": "217360"
  },
  {
    "text": "deployment and avoids vendor",
    "start": "217360",
    "end": "220400"
  },
  {
    "text": "lockin those microservices that we just",
    "start": "220400",
    "end": "222640"
  },
  {
    "text": "saw came together to form a",
    "start": "222640",
    "end": "224319"
  },
  {
    "text": "containerized um a chat Q&A",
    "start": "224319",
    "end": "226319"
  },
  {
    "text": "containerized application and fippy and",
    "start": "226319",
    "end": "228840"
  },
  {
    "text": "Goldie use that to build their",
    "start": "228840",
    "end": "230599"
  },
  {
    "text": "application today Opia has chat Q&A plus",
    "start": "230599",
    "end": "234319"
  },
  {
    "text": "20 other recipes ready for use there's",
    "start": "234319",
    "end": "237120"
  },
  {
    "text": "audio Q&A there's um visual Q&A Cod gen",
    "start": "237120",
    "end": "241280"
  },
  {
    "text": "and there's lots more on the road map",
    "start": "241280",
    "end": "243680"
  },
  {
    "text": "each of these applications can generate",
    "start": "243680",
    "end": "245280"
  },
  {
    "text": "a Helm chart that helps you orchestrate",
    "start": "245280",
    "end": "247360"
  },
  {
    "text": "in",
    "start": "247360",
    "end": "248079"
  },
  {
    "text": "kubernetes applications deploy as",
    "start": "248079",
    "end": "250200"
  },
  {
    "text": "production ready containers for",
    "start": "250200",
    "end": "251720"
  },
  {
    "text": "kubernetes and they can run on Prem in",
    "start": "251720",
    "end": "254519"
  },
  {
    "text": "the cloud or on the",
    "start": "254519",
    "end": "257680"
  },
  {
    "text": "edge as an open source project Opa",
    "start": "258359",
    "end": "261519"
  },
  {
    "text": "relies on contributions from individuals",
    "start": "261519",
    "end": "263639"
  },
  {
    "text": "like you and partners across the",
    "start": "263639",
    "end": "265800"
  },
  {
    "text": "industry to create and test each",
    "start": "265800",
    "end": "267919"
  },
  {
    "text": "component we've been working with",
    "start": "267919",
    "end": "269880"
  },
  {
    "text": "multiple Cloud providers to build the",
    "start": "269880",
    "end": "272199"
  },
  {
    "text": "best experience possible so get another",
    "start": "272199",
    "end": "275720"
  },
  {
    "text": "QR code but please check out the OPA",
    "start": "275720",
    "end": "277680"
  },
  {
    "text": "getting started guide on GitHub um it's",
    "start": "277680",
    "end": "279919"
  },
  {
    "text": "filled with loads and loads of Open",
    "start": "279919",
    "end": "281560"
  },
  {
    "text": "Source recipes that you can use to build",
    "start": "281560",
    "end": "283960"
  },
  {
    "text": "Cloud native generative AI applications",
    "start": "283960",
    "end": "286120"
  },
  {
    "text": "for chat code generation QA Q&A and so",
    "start": "286120",
    "end": "289600"
  },
  {
    "text": "much more so if you've got questions and",
    "start": "289600",
    "end": "292160"
  },
  {
    "text": "would like to learn more please come",
    "start": "292160",
    "end": "293520"
  },
  {
    "text": "find this at the Intel booth in the expo",
    "start": "293520",
    "end": "295360"
  },
  {
    "text": "hall we're in G5 thanks for your time",
    "start": "295360",
    "end": "297840"
  },
  {
    "text": "today say hi to fippi and",
    "start": "297840",
    "end": "300160"
  },
  {
    "text": "and Jo cuan",
    "start": "300160",
    "end": "303560"
  }
]
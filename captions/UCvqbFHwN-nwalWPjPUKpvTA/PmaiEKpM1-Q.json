[
  {
    "text": "hello everyone um welcome to today's",
    "start": "280",
    "end": "2800"
  },
  {
    "text": "talk so um today we'll be talking about",
    "start": "2800",
    "end": "5520"
  },
  {
    "text": "Bloomberg's journey to manage a",
    "start": "5520",
    "end": "7319"
  },
  {
    "text": "multicluster training application with",
    "start": "7319",
    "end": "9800"
  },
  {
    "text": "kada uh my name is Ean I am a software",
    "start": "9800",
    "end": "12719"
  },
  {
    "text": "engineer on the data science platform",
    "start": "12719",
    "end": "14599"
  },
  {
    "text": "team at",
    "start": "14599",
    "end": "15640"
  },
  {
    "text": "Bloomberg my name is way Li I'm in the",
    "start": "15640",
    "end": "18880"
  },
  {
    "text": "same team with Ean also in the data",
    "start": "18880",
    "end": "21359"
  },
  {
    "text": "science platform engineering at",
    "start": "21359",
    "end": "24800"
  },
  {
    "text": "Bloomberg so here is the agenda for",
    "start": "24800",
    "end": "27400"
  },
  {
    "text": "today so we'll be talking about what is",
    "start": "27400",
    "end": "30240"
  },
  {
    "text": "data science platform in short DSP at",
    "start": "30240",
    "end": "32439"
  },
  {
    "text": "Bloomberg and we'll be talking about",
    "start": "32440",
    "end": "34760"
  },
  {
    "text": "what is kada and how we use carada in",
    "start": "34760",
    "end": "37280"
  },
  {
    "text": "Bloomberg and finally we'll be closing",
    "start": "37280",
    "end": "39480"
  },
  {
    "text": "this talk with a future road map of",
    "start": "39480",
    "end": "41719"
  },
  {
    "text": "carada and also a Q&A",
    "start": "41719",
    "end": "45600"
  },
  {
    "text": "session so uh let's begin with a brief",
    "start": "45840",
    "end": "48640"
  },
  {
    "text": "introduction to the data science",
    "start": "48640",
    "end": "50000"
  },
  {
    "text": "platform so DSP at at Bloomberg provides",
    "start": "50000",
    "end": "53680"
  },
  {
    "text": "an on Prem bare metal-based kubernetes",
    "start": "53680",
    "end": "56160"
  },
  {
    "text": "infrastructure for the entire machine",
    "start": "56160",
    "end": "58879"
  },
  {
    "text": "learning life cycle from data",
    "start": "58879",
    "end": "60719"
  },
  {
    "text": "experimenting based on jbit Notebook to",
    "start": "60719",
    "end": "63440"
  },
  {
    "text": "model training which is built upon the C",
    "start": "63440",
    "end": "65600"
  },
  {
    "text": "flow project uh especially training",
    "start": "65600",
    "end": "68159"
  },
  {
    "text": "operator and also to uh model",
    "start": "68159",
    "end": "70880"
  },
  {
    "text": "inferencing using kerve so today we'll",
    "start": "70880",
    "end": "74320"
  },
  {
    "text": "be mainly focusing on the model training",
    "start": "74320",
    "end": "78520"
  },
  {
    "text": "part so uh here is a very high level",
    "start": "79200",
    "end": "82759"
  },
  {
    "text": "simplified architecture of DSP so DSP is",
    "start": "82759",
    "end": "86159"
  },
  {
    "text": "divided into multiple tiers uh according",
    "start": "86159",
    "end": "88640"
  },
  {
    "text": "to the network Z Network Zone where the",
    "start": "88640",
    "end": "90920"
  },
  {
    "text": "cluster lives so for example we have Dev",
    "start": "90920",
    "end": "93600"
  },
  {
    "text": "tier and PR tier so each tier has",
    "start": "93600",
    "end": "96560"
  },
  {
    "text": "multiple clusters in it uh the the",
    "start": "96560",
    "end": "99759"
  },
  {
    "text": "different clusters are located in",
    "start": "99759",
    "end": "101240"
  },
  {
    "text": "different data centers in different GE",
    "start": "101240",
    "end": "103520"
  },
  {
    "text": "geographical places to ensure disaster",
    "start": "103520",
    "end": "106240"
  },
  {
    "text": "recovery and DSP supports multi-tenancy",
    "start": "106240",
    "end": "109320"
  },
  {
    "text": "for different AI teams at Bloomberg by",
    "start": "109320",
    "end": "112520"
  },
  {
    "text": "using kubet native namespace and we also",
    "start": "112520",
    "end": "115960"
  },
  {
    "text": "managed a quota that uh each name each",
    "start": "115960",
    "end": "119000"
  },
  {
    "text": "team is allowed to use um using",
    "start": "119000",
    "end": "122079"
  },
  {
    "text": "kubernetes uh resource quota so the",
    "start": "122079",
    "end": "124920"
  },
  {
    "text": "quota is duplicated across different",
    "start": "124920",
    "end": "127600"
  },
  {
    "text": "clusters within the same tier so that",
    "start": "127600",
    "end": "129959"
  },
  {
    "text": "whenever one data center goes down users",
    "start": "129959",
    "end": "132640"
  },
  {
    "text": "can submit their jobs to the other dat",
    "start": "132640",
    "end": "135040"
  },
  {
    "text": "data center the other cluster uh without",
    "start": "135040",
    "end": "137680"
  },
  {
    "text": "facing any quota related issue and",
    "start": "137680",
    "end": "140800"
  },
  {
    "text": "finally configurations such as config",
    "start": "140800",
    "end": "143680"
  },
  {
    "text": "maps and secrets are managed separately",
    "start": "143680",
    "end": "146440"
  },
  {
    "text": "so basically we are allowing users to",
    "start": "146440",
    "end": "148480"
  },
  {
    "text": "have different configurations to run",
    "start": "148480",
    "end": "150160"
  },
  {
    "text": "their model job training jobs on",
    "start": "150160",
    "end": "152120"
  },
  {
    "text": "different clusters and also using",
    "start": "152120",
    "end": "154160"
  },
  {
    "text": "different credentials to connect to",
    "start": "154160",
    "end": "155640"
  },
  {
    "text": "external",
    "start": "155640",
    "end": "158080"
  },
  {
    "text": "services so the uh the uh setup we just",
    "start": "159159",
    "end": "162879"
  },
  {
    "text": "talked about has actually brought us a",
    "start": "162879",
    "end": "165200"
  },
  {
    "text": "few challenges so the first problem is",
    "start": "165200",
    "end": "168200"
  },
  {
    "text": "uh the separate configuration and",
    "start": "168200",
    "end": "170360"
  },
  {
    "text": "credential management so because uh",
    "start": "170360",
    "end": "173239"
  },
  {
    "text": "we're allowing users to have different",
    "start": "173239",
    "end": "175760"
  },
  {
    "text": "credentials configurations on different",
    "start": "175760",
    "end": "177840"
  },
  {
    "text": "clusters it is very likely that that uh",
    "start": "177840",
    "end": "180480"
  },
  {
    "text": "a certain config or secret exists on one",
    "start": "180480",
    "end": "183120"
  },
  {
    "text": "cluster but not on other clusters in the",
    "start": "183120",
    "end": "185440"
  },
  {
    "text": "same tier so when user submits a model",
    "start": "185440",
    "end": "188280"
  },
  {
    "text": "training job to our DSP uh model",
    "start": "188280",
    "end": "191519"
  },
  {
    "text": "training clusters they have to make sure",
    "start": "191519",
    "end": "193879"
  },
  {
    "text": "that the specified configuration or",
    "start": "193879",
    "end": "195879"
  },
  {
    "text": "credential exists on the target cluster",
    "start": "195879",
    "end": "199319"
  },
  {
    "text": "so if it does not exist the job will",
    "start": "199319",
    "end": "201799"
  },
  {
    "text": "simply fail to start and solution to",
    "start": "201799",
    "end": "204640"
  },
  {
    "text": "that is relatively simple uh we just",
    "start": "204640",
    "end": "207760"
  },
  {
    "text": "need to ask users to copy their",
    "start": "207760",
    "end": "209760"
  },
  {
    "text": "credentials and configurations uh and",
    "start": "209760",
    "end": "212120"
  },
  {
    "text": "submit them create them on all of our",
    "start": "212120",
    "end": "214080"
  },
  {
    "text": "clusters uh it is simple but relatively",
    "start": "214080",
    "end": "217480"
  },
  {
    "text": "manual and um you can see it's not ideal",
    "start": "217480",
    "end": "222879"
  },
  {
    "text": "right and the Second Challenge where are",
    "start": "223120",
    "end": "226080"
  },
  {
    "text": "facing is actually due to the nature of",
    "start": "226080",
    "end": "228680"
  },
  {
    "text": "how kubernetes resource quota works so",
    "start": "228680",
    "end": "231959"
  },
  {
    "text": "every team must based uh must must",
    "start": "231959",
    "end": "234159"
  },
  {
    "text": "budget based on their potential maximum",
    "start": "234159",
    "end": "236760"
  },
  {
    "text": "resource requirement so that is for",
    "start": "236760",
    "end": "239120"
  },
  {
    "text": "example an lln team wants to train large",
    "start": "239120",
    "end": "242560"
  },
  {
    "text": "language model on our cluster uh that",
    "start": "242560",
    "end": "245640"
  },
  {
    "text": "require like say 40 gpus at the same",
    "start": "245640",
    "end": "249360"
  },
  {
    "text": "time so they have to budget enough quota",
    "start": "249360",
    "end": "253120"
  },
  {
    "text": "that's equivalent to 40 gpus on our",
    "start": "253120",
    "end": "255319"
  },
  {
    "text": "internal budgeting platform so that when",
    "start": "255319",
    "end": "258160"
  },
  {
    "text": "such a large job is submitted into our",
    "start": "258160",
    "end": "260400"
  },
  {
    "text": "cluster the job the job can get started",
    "start": "260400",
    "end": "263800"
  },
  {
    "text": "successfully so this is the nature of",
    "start": "263800",
    "end": "266320"
  },
  {
    "text": "batch workload versus long running",
    "start": "266320",
    "end": "268479"
  },
  {
    "text": "Services as a shown on the chart on the",
    "start": "268479",
    "end": "270759"
  },
  {
    "text": "left hand side so for long running",
    "start": "270759",
    "end": "273120"
  },
  {
    "text": "Services uh the resource usage is",
    "start": "273120",
    "end": "275479"
  },
  {
    "text": "relatively um stable with smaller",
    "start": "275479",
    "end": "279320"
  },
  {
    "text": "fluctuations um so kubernetes resource",
    "start": "279320",
    "end": "282039"
  },
  {
    "text": "quota fits well in this use case however",
    "start": "282039",
    "end": "285000"
  },
  {
    "text": "for batch workloads even though the",
    "start": "285000",
    "end": "287240"
  },
  {
    "text": "resource utilization May remain low for",
    "start": "287240",
    "end": "290600"
  },
  {
    "text": "most of the time when a large job comes",
    "start": "290600",
    "end": "293240"
  },
  {
    "text": "in that requires a lot of Hardware",
    "start": "293240",
    "end": "295280"
  },
  {
    "text": "resources the budget unit the budget",
    "start": "295280",
    "end": "297639"
  },
  {
    "text": "quota has to be set correctly according",
    "start": "297639",
    "end": "300320"
  },
  {
    "text": "to the maximum maximum resource usage by",
    "start": "300320",
    "end": "304120"
  },
  {
    "text": "that job so that the job can get started",
    "start": "304120",
    "end": "306759"
  },
  {
    "text": "successfully so as a result over",
    "start": "306759",
    "end": "309080"
  },
  {
    "text": "budgeting is inevitable in this setup uh",
    "start": "309080",
    "end": "311759"
  },
  {
    "text": "which leads to a waste of",
    "start": "311759",
    "end": "313800"
  },
  {
    "text": "resources so this is probably not a big",
    "start": "313800",
    "end": "316639"
  },
  {
    "text": "issue for workloads that runs on CPU and",
    "start": "316639",
    "end": "319440"
  },
  {
    "text": "memory but gpus are more expensive and",
    "start": "319440",
    "end": "322880"
  },
  {
    "text": "uh gpus run into shortage more",
    "start": "322880",
    "end": "325120"
  },
  {
    "text": "frequently so um and at this point we're",
    "start": "325120",
    "end": "328919"
  },
  {
    "text": "not having a good solution to this",
    "start": "328919",
    "end": "332520"
  },
  {
    "text": "issue and finally the current setup also",
    "start": "333960",
    "end": "337520"
  },
  {
    "text": "causes unbalanced utilization so this is",
    "start": "337520",
    "end": "341039"
  },
  {
    "text": "because people usually tend to use the",
    "start": "341039",
    "end": "343280"
  },
  {
    "text": "same cluster to run the job over and",
    "start": "343280",
    "end": "345680"
  },
  {
    "text": "over again maybe they're just uh most",
    "start": "345680",
    "end": "348280"
  },
  {
    "text": "familiar with that cluster so it's quite",
    "start": "348280",
    "end": "351160"
  },
  {
    "text": "likely that one cluster is under heavy",
    "start": "351160",
    "end": "353440"
  },
  {
    "text": "workload but the other cluster is",
    "start": "353440",
    "end": "356319"
  },
  {
    "text": "relatively idle so as is shown on the",
    "start": "356319",
    "end": "358479"
  },
  {
    "text": "diagram there uh you can see that people",
    "start": "358479",
    "end": "361240"
  },
  {
    "text": "who submit job to the cluster on the",
    "start": "361240",
    "end": "364160"
  },
  {
    "text": "left the dev dc1 cluster might have to",
    "start": "364160",
    "end": "367319"
  },
  {
    "text": "wait for a long time before their job",
    "start": "367319",
    "end": "369800"
  },
  {
    "text": "gets scheduled while the other cluster",
    "start": "369800",
    "end": "372199"
  },
  {
    "text": "the dev dco2 cluster remained idle and",
    "start": "372199",
    "end": "376080"
  },
  {
    "text": "is simply wasting money so the solution",
    "start": "376080",
    "end": "378960"
  },
  {
    "text": "is also probably simple we can just ask",
    "start": "378960",
    "end": "381759"
  },
  {
    "text": "users to evenly submit their jobs to",
    "start": "381759",
    "end": "384520"
  },
  {
    "text": "different clusters but you can see that",
    "start": "384520",
    "end": "386960"
  },
  {
    "text": "this is uh actually hard to realize",
    "start": "386960",
    "end": "391560"
  },
  {
    "text": "so all these challenges makes us think",
    "start": "392800",
    "end": "395199"
  },
  {
    "text": "about um is there anything we can do to",
    "start": "395199",
    "end": "398039"
  },
  {
    "text": "help us better automate all those stuff",
    "start": "398039",
    "end": "400199"
  },
  {
    "text": "to reduce the pain on our users and also",
    "start": "400199",
    "end": "402440"
  },
  {
    "text": "reduce the pain on our un call so with",
    "start": "402440",
    "end": "405880"
  },
  {
    "text": "that let me hand it over to way to talk",
    "start": "405880",
    "end": "408039"
  },
  {
    "text": "about more about what is",
    "start": "408039",
    "end": "411599"
  },
  {
    "text": "kada so uh what is",
    "start": "413800",
    "end": "416680"
  },
  {
    "text": "kada kada is a m cluster and M Cloud",
    "start": "416680",
    "end": "420440"
  },
  {
    "text": "kubernetes manage system which is",
    "start": "420440",
    "end": "422639"
  },
  {
    "text": "designed to provide scalable container",
    "start": "422639",
    "end": "424400"
  },
  {
    "text": "resource pools enabling developers to",
    "start": "424400",
    "end": "426879"
  },
  {
    "text": "use multile clouds and mple clusters as",
    "start": "426879",
    "end": "429360"
  },
  {
    "text": "similarly as using a single kubernetes",
    "start": "429360",
    "end": "432680"
  },
  {
    "text": "cluster and this platform enables the",
    "start": "432680",
    "end": "435240"
  },
  {
    "text": "deployment of workloads from single",
    "start": "435240",
    "end": "437440"
  },
  {
    "text": "cluster to M clusters without requiring",
    "start": "437440",
    "end": "439720"
  },
  {
    "text": "any Cod refractor it also integrates the",
    "start": "439720",
    "end": "442520"
  },
  {
    "text": "kubernetes tool chain without any loss",
    "start": "442520",
    "end": "444599"
  },
  {
    "text": "of",
    "start": "444599",
    "end": "446639"
  },
  {
    "text": "functionality it also offers out of the",
    "start": "446639",
    "end": "449280"
  },
  {
    "text": "box capabilities with building policy",
    "start": "449280",
    "end": "451479"
  },
  {
    "text": "sets for various multicluster scenarios",
    "start": "451479",
    "end": "454160"
  },
  {
    "text": "such as cross region active active and",
    "start": "454160",
    "end": "456720"
  },
  {
    "text": "remote Disaster",
    "start": "456720",
    "end": "459160"
  },
  {
    "text": "Recovery kada also supports seamless",
    "start": "459160",
    "end": "462039"
  },
  {
    "text": "migration between multiple Cloud vendors",
    "start": "462039",
    "end": "464240"
  },
  {
    "text": "avoiding vendor lock in and enabling",
    "start": "464240",
    "end": "466400"
  },
  {
    "text": "centralized management through this",
    "start": "466400",
    "end": "468319"
  },
  {
    "text": "native kues API",
    "start": "468319",
    "end": "471560"
  },
  {
    "text": "orientation it also provides various M",
    "start": "471639",
    "end": "474400"
  },
  {
    "text": "cluster scheduling policies which are",
    "start": "474400",
    "end": "476680"
  },
  {
    "text": "tailored to its industry scenarios such",
    "start": "476680",
    "end": "479240"
  },
  {
    "text": "as M region M cluster groups ensuring",
    "start": "479240",
    "end": "482520"
  },
  {
    "text": "optimal resource utilization and",
    "start": "482520",
    "end": "484199"
  },
  {
    "text": "workload distribution across",
    "start": "484199",
    "end": "487639"
  },
  {
    "text": "clusters this is carada's architecture",
    "start": "488000",
    "end": "491280"
  },
  {
    "text": "it includes a control plane deployed on",
    "start": "491280",
    "end": "493680"
  },
  {
    "text": "kubernetes comprising the cada API",
    "start": "493680",
    "end": "496400"
  },
  {
    "text": "server scheduler controller manager",
    "start": "496400",
    "end": "499639"
  },
  {
    "text": "mirroring the kubernetes control plane",
    "start": "499639",
    "end": "502120"
  },
  {
    "text": "this setup allows users to create",
    "start": "502120",
    "end": "504199"
  },
  {
    "text": "resources and arrate M cluster",
    "start": "504199",
    "end": "506639"
  },
  {
    "text": "applications through the native",
    "start": "506639",
    "end": "508280"
  },
  {
    "text": "kubernetes API",
    "start": "508280",
    "end": "510919"
  },
  {
    "text": "kada supports both push and pool modes",
    "start": "510919",
    "end": "514039"
  },
  {
    "text": "to access the member clusters in the",
    "start": "514039",
    "end": "516039"
  },
  {
    "text": "push mode kada will directly access",
    "start": "516039",
    "end": "518200"
  },
  {
    "text": "member clusters to VPI server to get",
    "start": "518200",
    "end": "520320"
  },
  {
    "text": "cluster status and deploy manifests for",
    "start": "520320",
    "end": "523479"
  },
  {
    "text": "cluster with limited network access kada",
    "start": "523479",
    "end": "526320"
  },
  {
    "text": "supports a pool mode by delegating",
    "start": "526320",
    "end": "527959"
  },
  {
    "text": "responsibilities to a cada agent within",
    "start": "527959",
    "end": "530360"
  },
  {
    "text": "the corresponding",
    "start": "530360",
    "end": "531640"
  },
  {
    "text": "cluster this arcure supports features",
    "start": "531640",
    "end": "534320"
  },
  {
    "text": "such as M cluster management",
    "start": "534320",
    "end": "536480"
  },
  {
    "text": "cross-cluster application failover",
    "start": "536480",
    "end": "538760"
  },
  {
    "text": "Global resource View and M cluster",
    "start": "538760",
    "end": "540920"
  },
  {
    "text": "service Discovery and",
    "start": "540920",
    "end": "544399"
  },
  {
    "text": "more to better understand upcoming",
    "start": "544399",
    "end": "546760"
  },
  {
    "text": "feature sections as SC The Core Concepts",
    "start": "546760",
    "end": "549440"
  },
  {
    "text": "of of kada these are the primary",
    "start": "549440",
    "end": "552120"
  },
  {
    "text": "resources essential for its C",
    "start": "552120",
    "end": "554560"
  },
  {
    "text": "functionality there are three user",
    "start": "554560",
    "end": "556360"
  },
  {
    "text": "facing apis first the resource template",
    "start": "556360",
    "end": "559680"
  },
  {
    "text": "it is on modified kubernetes resource",
    "start": "559680",
    "end": "562000"
  },
  {
    "text": "that users will interact with directly",
    "start": "562000",
    "end": "564440"
  },
  {
    "text": "such as pod and",
    "start": "564440",
    "end": "566079"
  },
  {
    "text": "deployment next for every resource",
    "start": "566079",
    "end": "568880"
  },
  {
    "text": "template it will be bound to a",
    "start": "568880",
    "end": "570839"
  },
  {
    "text": "propagation policy by a resource",
    "start": "570839",
    "end": "572839"
  },
  {
    "text": "selector this policy defines how M",
    "start": "572839",
    "end": "575519"
  },
  {
    "text": "cluster applications are scheduled and",
    "start": "575519",
    "end": "577800"
  },
  {
    "text": "specifies which cluster the application",
    "start": "577800",
    "end": "579720"
  },
  {
    "text": "is distributed",
    "start": "579720",
    "end": "581160"
  },
  {
    "text": "to there are many supported scheduling",
    "start": "581160",
    "end": "583880"
  },
  {
    "text": "policies such as cluster Affinity M",
    "start": "583880",
    "end": "586880"
  },
  {
    "text": "cluster splitting and M cluster",
    "start": "586880",
    "end": "590160"
  },
  {
    "text": "rebalancing finally override policy this",
    "start": "590160",
    "end": "594000"
  },
  {
    "text": "policy allows for differentiated",
    "start": "594000",
    "end": "596000"
  },
  {
    "text": "configurations across clusters such as",
    "start": "596000",
    "end": "598560"
  },
  {
    "text": "using different image URLs or",
    "start": "598560",
    "end": "600760"
  },
  {
    "text": "repositories for different",
    "start": "600760",
    "end": "602600"
  },
  {
    "text": "clusters and there are two internal API",
    "start": "602600",
    "end": "605600"
  },
  {
    "text": "the first one is resource binding it",
    "start": "605600",
    "end": "607880"
  },
  {
    "text": "drives the scheduling process within",
    "start": "607880",
    "end": "611480"
  },
  {
    "text": "kada the second one is work object which",
    "start": "611480",
    "end": "614800"
  },
  {
    "text": "represents the resource in the member",
    "start": "614800",
    "end": "616320"
  },
  {
    "text": "cluster at carmal layer ensuring proper",
    "start": "616320",
    "end": "618760"
  },
  {
    "text": "resource management and",
    "start": "618760",
    "end": "621160"
  },
  {
    "text": "synchronization and take the deployment",
    "start": "621160",
    "end": "623880"
  },
  {
    "text": "is example for the high level scheduling",
    "start": "623880",
    "end": "625920"
  },
  {
    "text": "process after users create a deployment",
    "start": "625920",
    "end": "629120"
  },
  {
    "text": "the corresponding resource bindings will",
    "start": "629120",
    "end": "631320"
  },
  {
    "text": "be created with the propagation policy",
    "start": "631320",
    "end": "633680"
  },
  {
    "text": "match with the resource based on the",
    "start": "633680",
    "end": "635519"
  },
  {
    "text": "resource",
    "start": "635519",
    "end": "636560"
  },
  {
    "text": "selector and the scheduler will use the",
    "start": "636560",
    "end": "639160"
  },
  {
    "text": "information in the resource findinding",
    "start": "639160",
    "end": "640680"
  },
  {
    "text": "to determine the Clusters that the",
    "start": "640680",
    "end": "642800"
  },
  {
    "text": "deployment should be distributed to and",
    "start": "642800",
    "end": "645560"
  },
  {
    "text": "the kada will create specific work",
    "start": "645560",
    "end": "647839"
  },
  {
    "text": "objects based on the resource binding",
    "start": "647839",
    "end": "649519"
  },
  {
    "text": "with the override policy match with the",
    "start": "649519",
    "end": "653079"
  },
  {
    "text": "binding which represents the actual",
    "start": "653079",
    "end": "655320"
  },
  {
    "text": "resources that are created in the member",
    "start": "655320",
    "end": "657399"
  },
  {
    "text": "cluster finally the mod that will create",
    "start": "657399",
    "end": "660120"
  },
  {
    "text": "the resource based on the work objects",
    "start": "660120",
    "end": "661880"
  },
  {
    "text": "in the member",
    "start": "661880",
    "end": "663639"
  },
  {
    "text": "clusters understanding this Core",
    "start": "663639",
    "end": "665839"
  },
  {
    "text": "Concepts we can effectively utilize",
    "start": "665839",
    "end": "667760"
  },
  {
    "text": "car's capabilities to manage and O trate",
    "start": "667760",
    "end": "670560"
  },
  {
    "text": "M cluster environments",
    "start": "670560",
    "end": "673120"
  },
  {
    "text": "seamlessly at this point I will hand",
    "start": "673120",
    "end": "675040"
  },
  {
    "text": "over to Eun to talk about how we use",
    "start": "675040",
    "end": "677160"
  },
  {
    "text": "carada and what additional works we have",
    "start": "677160",
    "end": "679600"
  },
  {
    "text": "to do to integrate with the Bloomer",
    "start": "679600",
    "end": "683319"
  },
  {
    "text": "system um so now that we have known what",
    "start": "684320",
    "end": "687800"
  },
  {
    "text": "kada is and uh what kind of problem it",
    "start": "687800",
    "end": "690680"
  },
  {
    "text": "can solve uh so let's take a look at how",
    "start": "690680",
    "end": "693480"
  },
  {
    "text": "we set up carada in Bloomberg and what",
    "start": "693480",
    "end": "695880"
  },
  {
    "text": "actual benefits carada has brought to",
    "start": "695880",
    "end": "699760"
  },
  {
    "text": "us so in this chart you can see a",
    "start": "699800",
    "end": "702480"
  },
  {
    "text": "highlevel control playing setup of our",
    "start": "702480",
    "end": "704920"
  },
  {
    "text": "kada instances so uh we deploy carada",
    "start": "704920",
    "end": "708360"
  },
  {
    "text": "instances in two different data centers",
    "start": "708360",
    "end": "710360"
  },
  {
    "text": "for high availability and in each data",
    "start": "710360",
    "end": "713600"
  },
  {
    "text": "center all Cara components are deployed",
    "start": "713600",
    "end": "716320"
  },
  {
    "text": "for example the uh API server uh the uh",
    "start": "716320",
    "end": "719720"
  },
  {
    "text": "kada scheduler and carada controller",
    "start": "719720",
    "end": "722079"
  },
  {
    "text": "manager so we also set up leader",
    "start": "722079",
    "end": "725240"
  },
  {
    "text": "election to make sure that at a point of",
    "start": "725240",
    "end": "727600"
  },
  {
    "text": "time there's only one uh component that",
    "start": "727600",
    "end": "730160"
  },
  {
    "text": "is actively",
    "start": "730160",
    "end": "731480"
  },
  {
    "text": "running so on the top you can see that",
    "start": "731480",
    "end": "734839"
  },
  {
    "text": "uh we connect the two kada API servers",
    "start": "734839",
    "end": "738440"
  },
  {
    "text": "to a single console based DNS uh service",
    "start": "738440",
    "end": "742560"
  },
  {
    "text": "Discovery so that the two kada API",
    "start": "742560",
    "end": "745120"
  },
  {
    "text": "servers are essentially agnostic to the",
    "start": "745120",
    "end": "747600"
  },
  {
    "text": "carada clients",
    "start": "747600",
    "end": "750279"
  },
  {
    "text": "and uh in the middle you can see that we",
    "start": "750279",
    "end": "753160"
  },
  {
    "text": "deploying a kind instance in every data",
    "start": "753160",
    "end": "755800"
  },
  {
    "text": "center uh which provides an SD like",
    "start": "755800",
    "end": "758720"
  },
  {
    "text": "interface for the API server of the",
    "start": "758720",
    "end": "760760"
  },
  {
    "text": "carada to store data so uh the two kind",
    "start": "760760",
    "end": "765000"
  },
  {
    "text": "instances are connected to a single",
    "start": "765000",
    "end": "767440"
  },
  {
    "text": "postgress database so that uh when one",
    "start": "767440",
    "end": "770320"
  },
  {
    "text": "side goes down the other side of the",
    "start": "770320",
    "end": "772199"
  },
  {
    "text": "carada instance can immediately pick the",
    "start": "772199",
    "end": "774240"
  },
  {
    "text": "word work up and uh the high",
    "start": "774240",
    "end": "777639"
  },
  {
    "text": "availability of the uh post grass",
    "start": "777639",
    "end": "779639"
  },
  {
    "text": "instances are are guaranteed by our",
    "start": "779639",
    "end": "782600"
  },
  {
    "text": "Bloomberg database",
    "start": "782600",
    "end": "784720"
  },
  {
    "text": "team and at the bottom you can see that",
    "start": "784720",
    "end": "787839"
  },
  {
    "text": "each carada instance is connected to all",
    "start": "787839",
    "end": "790800"
  },
  {
    "text": "clusters in the dev ti so that even",
    "start": "790800",
    "end": "793800"
  },
  {
    "text": "though one side is completely uh",
    "start": "793800",
    "end": "795920"
  },
  {
    "text": "unreachable user can still access all",
    "start": "795920",
    "end": "798680"
  },
  {
    "text": "clusters um uh through the uh the other",
    "start": "798680",
    "end": "803560"
  },
  {
    "text": "uh available kada instance",
    "start": "803560",
    "end": "807760"
  },
  {
    "text": "and uh this setup has brought us a few",
    "start": "809959",
    "end": "812880"
  },
  {
    "text": "very various benefits so the first one",
    "start": "812880",
    "end": "815320"
  },
  {
    "text": "is integrating kada uh makes us uh uh",
    "start": "815320",
    "end": "819720"
  },
  {
    "text": "allows us to do automatic fill over so",
    "start": "819720",
    "end": "822639"
  },
  {
    "text": "with kada users no longer have to worry",
    "start": "822639",
    "end": "825279"
  },
  {
    "text": "about uh selecting a cluster that is",
    "start": "825279",
    "end": "829000"
  },
  {
    "text": "properly running so carada knows which",
    "start": "829000",
    "end": "831839"
  },
  {
    "text": "cluster is up and running and which is",
    "start": "831839",
    "end": "833920"
  },
  {
    "text": "unreachable so when a new job is",
    "start": "833920",
    "end": "836279"
  },
  {
    "text": "submitted into kada kada is smart enough",
    "start": "836279",
    "end": "838839"
  },
  {
    "text": "to pick a cluster that is available to",
    "start": "838839",
    "end": "841320"
  },
  {
    "text": "run that job and uh what's even better",
    "start": "841320",
    "end": "845240"
  },
  {
    "text": "about kada is that it is able to",
    "start": "845240",
    "end": "847759"
  },
  {
    "text": "schedule uh running jobs from filed",
    "start": "847759",
    "end": "850920"
  },
  {
    "text": "clusters to the uh clusters that are",
    "start": "850920",
    "end": "853880"
  },
  {
    "text": "still available although this feature M",
    "start": "853880",
    "end": "856399"
  },
  {
    "text": "probably makes more sense for long",
    "start": "856399",
    "end": "858199"
  },
  {
    "text": "running",
    "start": "858199",
    "end": "860480"
  },
  {
    "text": "services and the other benefit that kada",
    "start": "862759",
    "end": "865880"
  },
  {
    "text": "brings to us is uh automatic propagation",
    "start": "865880",
    "end": "869120"
  },
  {
    "text": "of configurations and credentials so",
    "start": "869120",
    "end": "872399"
  },
  {
    "text": "what it means is that uh with the proper",
    "start": "872399",
    "end": "874800"
  },
  {
    "text": "setup of a propagation policy user only",
    "start": "874800",
    "end": "877880"
  },
  {
    "text": "has to create the the secret or config",
    "start": "877880",
    "end": "880880"
  },
  {
    "text": "map in the kada without having to access",
    "start": "880880",
    "end": "884480"
  },
  {
    "text": "those member clusters and kada is able",
    "start": "884480",
    "end": "887040"
  },
  {
    "text": "to propagate the secret and the",
    "start": "887040",
    "end": "889040"
  },
  {
    "text": "configuration with the exact same",
    "start": "889040",
    "end": "891519"
  },
  {
    "text": "content into all those clusters that it",
    "start": "891519",
    "end": "894920"
  },
  {
    "text": "is connected to and what's even cool is",
    "start": "894920",
    "end": "898600"
  },
  {
    "text": "if a new new cluster is added to an",
    "start": "898600",
    "end": "900800"
  },
  {
    "text": "existing tier and is on boarding to kada",
    "start": "900800",
    "end": "904040"
  },
  {
    "text": "carada is also able to pick it up and",
    "start": "904040",
    "end": "906560"
  },
  {
    "text": "propagate the existing secrets and",
    "start": "906560",
    "end": "909079"
  },
  {
    "text": "conflict maps to this newly added",
    "start": "909079",
    "end": "912120"
  },
  {
    "text": "cluster so that users can use the new",
    "start": "912120",
    "end": "915000"
  },
  {
    "text": "cluster out of the",
    "start": "915000",
    "end": "917839"
  },
  {
    "text": "box uh kada also gives us a more",
    "start": "920000",
    "end": "923920"
  },
  {
    "text": "balanced scheduling mechanism so when a",
    "start": "923920",
    "end": "926720"
  },
  {
    "text": "job is submitted into kada kada",
    "start": "926720",
    "end": "929199"
  },
  {
    "text": "automatically retrieves the uh available",
    "start": "929199",
    "end": "931800"
  },
  {
    "text": "resources of all clusters and select the",
    "start": "931800",
    "end": "934480"
  },
  {
    "text": "cluster that has the most resource to",
    "start": "934480",
    "end": "936360"
  },
  {
    "text": "run that",
    "start": "936360",
    "end": "937440"
  },
  {
    "text": "job so oh you can see that it naturally",
    "start": "937440",
    "end": "941319"
  },
  {
    "text": "balances workflows across different",
    "start": "941319",
    "end": "943519"
  },
  {
    "text": "clusters and uh there's no manual",
    "start": "943519",
    "end": "946120"
  },
  {
    "text": "interference in this process so users no",
    "start": "946120",
    "end": "949279"
  },
  {
    "text": "longer have to worry about which cluster",
    "start": "949279",
    "end": "951279"
  },
  {
    "text": "have more resource to run my job and",
    "start": "951279",
    "end": "953920"
  },
  {
    "text": "their job will not stuck in pending",
    "start": "953920",
    "end": "956959"
  },
  {
    "text": "State unless there is really no resource",
    "start": "956959",
    "end": "959800"
  },
  {
    "text": "on any of our",
    "start": "959800",
    "end": "961480"
  },
  {
    "text": "clusters uh this has greatly improved",
    "start": "961480",
    "end": "964199"
  },
  {
    "text": "the uh Hardware utilization especially",
    "start": "964199",
    "end": "966600"
  },
  {
    "text": "GP utilization of our",
    "start": "966600",
    "end": "970240"
  },
  {
    "text": "clusters and the last benefit is that uh",
    "start": "971440",
    "end": "974519"
  },
  {
    "text": "kada provides a global uniform resource",
    "start": "974519",
    "end": "977319"
  },
  {
    "text": "view it means that admins and users can",
    "start": "977319",
    "end": "980319"
  },
  {
    "text": "now perform uh common operations uh on",
    "start": "980319",
    "end": "984440"
  },
  {
    "text": "the uh resources in member clusters",
    "start": "984440",
    "end": "986959"
  },
  {
    "text": "without really having to access those",
    "start": "986959",
    "end": "989639"
  },
  {
    "text": "member clusters um it also supports",
    "start": "989639",
    "end": "992519"
  },
  {
    "text": "common debugging operations such as log",
    "start": "992519",
    "end": "995319"
  },
  {
    "text": "and exec so uh this has brought has been",
    "start": "995319",
    "end": "1000440"
  },
  {
    "text": "very convenient for both users and us as",
    "start": "1000440",
    "end": "1004199"
  },
  {
    "text": "admin uh platform admins and of course",
    "start": "1004199",
    "end": "1007680"
  },
  {
    "text": "carada does not work out of the box in",
    "start": "1007680",
    "end": "1010000"
  },
  {
    "text": "the Bloomberg environment so next I will",
    "start": "1010000",
    "end": "1012600"
  },
  {
    "text": "give it back to which to talk about",
    "start": "1012600",
    "end": "1014360"
  },
  {
    "text": "Bloomberg's efforts to make carada fits",
    "start": "1014360",
    "end": "1016480"
  },
  {
    "text": "into our environment",
    "start": "1016480",
    "end": "1020079"
  },
  {
    "text": "yes I'm going to talk about the resource",
    "start": "1021360",
    "end": "1023800"
  },
  {
    "text": "interpreter the schedule estimator and",
    "start": "1023800",
    "end": "1026480"
  },
  {
    "text": "the future Ro map of our platforms and",
    "start": "1026480",
    "end": "1029558"
  },
  {
    "text": "just from what Ean said there's some",
    "start": "1029559",
    "end": "1032678"
  },
  {
    "text": "customization that we have to do and",
    "start": "1032679",
    "end": "1034558"
  },
  {
    "text": "also some contribution they have to do",
    "start": "1034559",
    "end": "1036959"
  },
  {
    "text": "uh for integrating with our",
    "start": "1036959",
    "end": "1039199"
  },
  {
    "text": "systems so for the custom resource",
    "start": "1039199",
    "end": "1042520"
  },
  {
    "text": "inator there's in the progress of",
    "start": "1042520",
    "end": "1044959"
  },
  {
    "text": "propagating a resource from kada to",
    "start": "1044959",
    "end": "1047079"
  },
  {
    "text": "member clusters kada doesn't need to",
    "start": "1047079",
    "end": "1049600"
  },
  {
    "text": "know uh sorry car needs to know the",
    "start": "1049600",
    "end": "1052280"
  },
  {
    "text": "resource definition and it internally Ed",
    "start": "1052280",
    "end": "1055400"
  },
  {
    "text": "the replica",
    "start": "1055400",
    "end": "1057240"
  },
  {
    "text": "requirements and replica be to do",
    "start": "1057240",
    "end": "1059880"
  },
  {
    "text": "casually for kubernetes Native resources",
    "start": "1059880",
    "end": "1062919"
  },
  {
    "text": "kada knows how to parse them the",
    "start": "1062919",
    "end": "1065280"
  },
  {
    "text": "translations for Native resource are",
    "start": "1065280",
    "end": "1067480"
  },
  {
    "text": "maintained by kada but for custom",
    "start": "1067480",
    "end": "1070400"
  },
  {
    "text": "resources defined by crd as Lake of the",
    "start": "1070400",
    "end": "1073480"
  },
  {
    "text": "knowledge of the resource structure they",
    "start": "1073480",
    "end": "1075559"
  },
  {
    "text": "can only be treated as normal resources",
    "start": "1075559",
    "end": "1078240"
  },
  {
    "text": "therefore the advanced scheduling",
    "start": "1078240",
    "end": "1079919"
  },
  {
    "text": "algorithms such as clust affinities and",
    "start": "1079919",
    "end": "1083320"
  },
  {
    "text": "M cluster splitting cannot be used for",
    "start": "1083320",
    "end": "1086520"
  },
  {
    "text": "them then how to let the camarada",
    "start": "1086520",
    "end": "1089400"
  },
  {
    "text": "understand your custom resource it",
    "start": "1089400",
    "end": "1091799"
  },
  {
    "text": "provides a framework called resource",
    "start": "1091799",
    "end": "1094200"
  },
  {
    "text": "interpreter framework to help achieve",
    "start": "1094200",
    "end": "1096159"
  },
  {
    "text": "the translation it is designed for",
    "start": "1096159",
    "end": "1098679"
  },
  {
    "text": "interpreting resource structure of your",
    "start": "1098679",
    "end": "1100600"
  },
  {
    "text": "crd for example suppose we have a crd",
    "start": "1100600",
    "end": "1104280"
  },
  {
    "text": "called Chrome job with the API version",
    "start": "1104280",
    "end": "1106480"
  },
  {
    "text": "through bar. iv1",
    "start": "1106480",
    "end": "1109360"
  },
  {
    "text": "and we want to Leverage The Advan",
    "start": "1109360",
    "end": "1110799"
  },
  {
    "text": "scheduling policy we can define a chrome",
    "start": "1110799",
    "end": "1113960"
  },
  {
    "text": "job interpreter web hook to translate",
    "start": "1113960",
    "end": "1115840"
  },
  {
    "text": "the Chrome job resource which Kamala",
    "start": "1115840",
    "end": "1118360"
  },
  {
    "text": "doesn't need to be understand into a",
    "start": "1118360",
    "end": "1120720"
  },
  {
    "text": "desired replica requirements and",
    "start": "1120720",
    "end": "1123400"
  },
  {
    "text": "replicas this allows kada to apply its",
    "start": "1123400",
    "end": "1126159"
  },
  {
    "text": "Advance scheduling policies",
    "start": "1126159",
    "end": "1129039"
  },
  {
    "text": "effectively in our case we rot a worklow",
    "start": "1129039",
    "end": "1132960"
  },
  {
    "text": "interpreter to help translate our",
    "start": "1132960",
    "end": "1134520"
  },
  {
    "text": "in-house training worklow it converts",
    "start": "1134520",
    "end": "1137080"
  },
  {
    "text": "the spec of our customer inhouse",
    "start": "1137080",
    "end": "1138919"
  },
  {
    "text": "resource including custom resource",
    "start": "1138919",
    "end": "1140559"
  },
  {
    "text": "information such as GPU small to the",
    "start": "1140559",
    "end": "1143400"
  },
  {
    "text": "replica requirements and replica that",
    "start": "1143400",
    "end": "1145840"
  },
  {
    "text": "kada understand so kada is able to apply",
    "start": "1145840",
    "end": "1149600"
  },
  {
    "text": "its Advanced scheduling policies to our",
    "start": "1149600",
    "end": "1153760"
  },
  {
    "text": "workload next is the schedule",
    "start": "1154000",
    "end": "1157600"
  },
  {
    "text": "estimator the Comm scheduler by default",
    "start": "1157600",
    "end": "1160600"
  },
  {
    "text": "calculates free resources based on the",
    "start": "1160600",
    "end": "1162600"
  },
  {
    "text": "resource summary of each cluster",
    "start": "1162600",
    "end": "1165240"
  },
  {
    "text": "enabling rapid scheduling across",
    "start": "1165240",
    "end": "1167200"
  },
  {
    "text": "hundreds of clusters",
    "start": "1167200",
    "end": "1169480"
  },
  {
    "text": "however this approach can Le",
    "start": "1169480",
    "end": "1172120"
  },
  {
    "text": "Precision for instance as shown in the",
    "start": "1172120",
    "end": "1175280"
  },
  {
    "text": "slide suppose we would like to create",
    "start": "1175280",
    "end": "1177440"
  },
  {
    "text": "one replica with 30 CPU cores and 30 GI",
    "start": "1177440",
    "end": "1180240"
  },
  {
    "text": "memory while the total cluster resources",
    "start": "1180240",
    "end": "1182919"
  },
  {
    "text": "might appear sufficient for a replica",
    "start": "1182919",
    "end": "1185720"
  },
  {
    "text": "the actual available resources might not",
    "start": "1185720",
    "end": "1188240"
  },
  {
    "text": "be enough and if we schedule a replica",
    "start": "1188240",
    "end": "1191360"
  },
  {
    "text": "to this death dc01 cluster there's",
    "start": "1191360",
    "end": "1194080"
  },
  {
    "text": "actually no node can run the replica",
    "start": "1194080",
    "end": "1198559"
  },
  {
    "text": "to address this issue caral offers an",
    "start": "1199080",
    "end": "1201840"
  },
  {
    "text": "option to enable scheduling based on the",
    "start": "1201840",
    "end": "1203960"
  },
  {
    "text": "schedule estimator each cluster has a",
    "start": "1203960",
    "end": "1206919"
  },
  {
    "text": "corresponding estimator that uses",
    "start": "1206919",
    "end": "1209159"
  },
  {
    "text": "informers to sync accurate resource",
    "start": "1209159",
    "end": "1211360"
  },
  {
    "text": "information from the",
    "start": "1211360",
    "end": "1212840"
  },
  {
    "text": "cluster during the scheduling process",
    "start": "1212840",
    "end": "1216280"
  },
  {
    "text": "the scheduler uses a GPC client to",
    "start": "1216280",
    "end": "1218760"
  },
  {
    "text": "communicate with this estimators instead",
    "start": "1218760",
    "end": "1221120"
  },
  {
    "text": "of relying on the resource",
    "start": "1221120",
    "end": "1223440"
  },
  {
    "text": "summary the process involves two steps",
    "start": "1223440",
    "end": "1226679"
  },
  {
    "text": "first it will calculate the number of",
    "start": "1226679",
    "end": "1228679"
  },
  {
    "text": "repaso note can accommodate in terms of",
    "start": "1228679",
    "end": "1230919"
  },
  {
    "text": "Hardware",
    "start": "1230919",
    "end": "1231880"
  },
  {
    "text": "resources next it will determine the",
    "start": "1231880",
    "end": "1235039"
  },
  {
    "text": "maximum number of the remaining parts",
    "start": "1235039",
    "end": "1236840"
  },
  {
    "text": "the node can allow and finally calculate",
    "start": "1236840",
    "end": "1239880"
  },
  {
    "text": "the number of replicas that can be",
    "start": "1239880",
    "end": "1241400"
  },
  {
    "text": "assigned by summing the minimum of these",
    "start": "1241400",
    "end": "1243360"
  },
  {
    "text": "values for each",
    "start": "1243360",
    "end": "1245039"
  },
  {
    "text": "node by using estimators the scheduler",
    "start": "1245039",
    "end": "1248720"
  },
  {
    "text": "can have more information to determine",
    "start": "1248720",
    "end": "1250960"
  },
  {
    "text": "the appropriate cluster for the workload",
    "start": "1250960",
    "end": "1253880"
  },
  {
    "text": "and therefore reduce the possibility of",
    "start": "1253880",
    "end": "1255679"
  },
  {
    "text": "a pending replica due to insufficient",
    "start": "1255679",
    "end": "1257520"
  },
  {
    "text": "resources",
    "start": "1257520",
    "end": "1259600"
  },
  {
    "text": "Al this introduced more Network latency",
    "start": "1259600",
    "end": "1262520"
  },
  {
    "text": "and scheduling overhead it is suitable",
    "start": "1262520",
    "end": "1264840"
  },
  {
    "text": "for our use case which involves managing",
    "start": "1264840",
    "end": "1266600"
  },
  {
    "text": "tens of clusters and requires efficient",
    "start": "1266600",
    "end": "1268919"
  },
  {
    "text": "resource",
    "start": "1268919",
    "end": "1271360"
  },
  {
    "text": "utilization however there was a",
    "start": "1272679",
    "end": "1274760"
  },
  {
    "text": "limitation with the estimator as well it",
    "start": "1274760",
    "end": "1277840"
  },
  {
    "text": "didn't consider resource codas during",
    "start": "1277840",
    "end": "1280400"
  },
  {
    "text": "the scheduling process for example if we",
    "start": "1280400",
    "end": "1283799"
  },
  {
    "text": "want to schedule four replicas it's",
    "start": "1283799",
    "end": "1286000"
  },
  {
    "text": "requiring one GPU in the L main space",
    "start": "1286000",
    "end": "1289320"
  },
  {
    "text": "the replica might be scheduled to the",
    "start": "1289320",
    "end": "1291520"
  },
  {
    "text": "def dc01 cluster because it has more",
    "start": "1291520",
    "end": "1295000"
  },
  {
    "text": "overall resources than these def dc02",
    "start": "1295000",
    "end": "1298919"
  },
  {
    "text": "cluster however the LM Nim space in the",
    "start": "1298919",
    "end": "1302440"
  },
  {
    "text": "def dc01 cluster may not have the",
    "start": "1302440",
    "end": "1304960"
  },
  {
    "text": "capacity to support this replicas",
    "start": "1304960",
    "end": "1307480"
  },
  {
    "text": "causing the job to remain a pending",
    "start": "1307480",
    "end": "1309159"
  },
  {
    "text": "State on member cluster oh",
    "start": "1309159",
    "end": "1312279"
  },
  {
    "text": "sorry until previous job finished and",
    "start": "1312279",
    "end": "1315279"
  },
  {
    "text": "released the gpus",
    "start": "1315279",
    "end": "1318880"
  },
  {
    "text": "in order to make Kata scheduler aware of",
    "start": "1319840",
    "end": "1322360"
  },
  {
    "text": "the resource quota of each name space",
    "start": "1322360",
    "end": "1324760"
  },
  {
    "text": "and also take resource quota into",
    "start": "1324760",
    "end": "1326600"
  },
  {
    "text": "consideration when making scheduling",
    "start": "1326600",
    "end": "1328640"
  },
  {
    "text": "decisions we contributed a resource Cod",
    "start": "1328640",
    "end": "1331240"
  },
  {
    "text": "made plugin to carada inside the plugin",
    "start": "1331240",
    "end": "1334600"
  },
  {
    "text": "there is an resource Coda Informer which",
    "start": "1334600",
    "end": "1336640"
  },
  {
    "text": "listens to Resource Coda events in the",
    "start": "1336640",
    "end": "1338720"
  },
  {
    "text": "cluster and filters out res clusters",
    "start": "1338720",
    "end": "1341760"
  },
  {
    "text": "that do not meet the specific workload",
    "start": "1341760",
    "end": "1344159"
  },
  {
    "text": "requirements by enabling the resource",
    "start": "1344159",
    "end": "1346320"
  },
  {
    "text": "Coda pling we can further reduce the",
    "start": "1346320",
    "end": "1349200"
  },
  {
    "text": "possibility of a pending worklow in the",
    "start": "1349200",
    "end": "1350720"
  },
  {
    "text": "member",
    "start": "1350720",
    "end": "1351559"
  },
  {
    "text": "clusters feel free to check the pr if",
    "start": "1351559",
    "end": "1354080"
  },
  {
    "text": "you're",
    "start": "1354080",
    "end": "1356159"
  },
  {
    "text": "interested finally in our future role of",
    "start": "1356159",
    "end": "1359640"
  },
  {
    "text": "the platform in Bloomberg we want to",
    "start": "1359640",
    "end": "1361720"
  },
  {
    "text": "contribute continue collaborating with",
    "start": "1361720",
    "end": "1363559"
  },
  {
    "text": "the community to provide more",
    "start": "1363559",
    "end": "1365080"
  },
  {
    "text": "functionalities into our",
    "start": "1365080",
    "end": "1367559"
  },
  {
    "text": "Platform One exciting feature in carala",
    "start": "1367559",
    "end": "1370039"
  },
  {
    "text": "we are working on is the priority and",
    "start": "1370039",
    "end": "1372000"
  },
  {
    "text": "preemption this feature ensures that",
    "start": "1372000",
    "end": "1374440"
  },
  {
    "text": "critical workloads have preferential",
    "start": "1374440",
    "end": "1376279"
  },
  {
    "text": "access to resources optimiz resource",
    "start": "1376279",
    "end": "1379120"
  },
  {
    "text": "utilization and availability for",
    "start": "1379120",
    "end": "1381799"
  },
  {
    "text": "exential tasks we are actively",
    "start": "1381799",
    "end": "1384320"
  },
  {
    "text": "collaborating with the community on this",
    "start": "1384320",
    "end": "1386080"
  },
  {
    "text": "feature and hope to deploy in the coming",
    "start": "1386080",
    "end": "1388080"
  },
  {
    "text": "months feel free to check out the",
    "start": "1388080",
    "end": "1392320"
  },
  {
    "text": "proposal thank",
    "start": "1392520",
    "end": "1395720"
  },
  {
    "text": "you um any questions",
    "start": "1401080",
    "end": "1405640"
  },
  {
    "text": "thank you for the talk um one of the one",
    "start": "1408919",
    "end": "1411080"
  },
  {
    "text": "of the reasons that Cube Fed was not",
    "start": "1411080",
    "end": "1413200"
  },
  {
    "text": "very successful um was the fact that we",
    "start": "1413200",
    "end": "1416480"
  },
  {
    "text": "use the same um the same resources that",
    "start": "1416480",
    "end": "1419840"
  },
  {
    "text": "we normally use in a single cluster in a",
    "start": "1419840",
    "end": "1422159"
  },
  {
    "text": "multicluster environment in in CU fed",
    "start": "1422159",
    "end": "1425200"
  },
  {
    "text": "and I think kada was built on top of Cu",
    "start": "1425200",
    "end": "1427720"
  },
  {
    "text": "fed V2 I I believe and it follows the",
    "start": "1427720",
    "end": "1430919"
  },
  {
    "text": "same model so the issue is that you",
    "start": "1430919",
    "end": "1433279"
  },
  {
    "text": "create a deployment the deployment has a",
    "start": "1433279",
    "end": "1435760"
  },
  {
    "text": "label there is this propagation policy",
    "start": "1435760",
    "end": "1438080"
  },
  {
    "text": "that chooses the chooses the deployment",
    "start": "1438080",
    "end": "1440600"
  },
  {
    "text": "so in a way in your deployment you don't",
    "start": "1440600",
    "end": "1442919"
  },
  {
    "text": "specify how you want this deployment to",
    "start": "1442919",
    "end": "1445240"
  },
  {
    "text": "be deployed in in multiple clusters um",
    "start": "1445240",
    "end": "1449000"
  },
  {
    "text": "it's like kind of the opposite way sort",
    "start": "1449000",
    "end": "1451080"
  },
  {
    "text": "of like the propagation policy",
    "start": "1451080",
    "end": "1452919"
  },
  {
    "text": "determines how your deployment will be",
    "start": "1452919",
    "end": "1454760"
  },
  {
    "text": "deployed so basically when the user",
    "start": "1454760",
    "end": "1457440"
  },
  {
    "text": "creates that deployment they need to be",
    "start": "1457440",
    "end": "1460039"
  },
  {
    "text": "aware of maybe existing other",
    "start": "1460039",
    "end": "1461960"
  },
  {
    "text": "propagation policies that could",
    "start": "1461960",
    "end": "1463440"
  },
  {
    "text": "potentially choose their deployment and",
    "start": "1463440",
    "end": "1466000"
  },
  {
    "text": "how it's going to get propagated so imag",
    "start": "1466000",
    "end": "1468360"
  },
  {
    "text": "imag that in a name space if I have like",
    "start": "1468360",
    "end": "1470399"
  },
  {
    "text": "multiple uh propagation policies and",
    "start": "1470399",
    "end": "1473080"
  },
  {
    "text": "they have multiple label selectors there",
    "start": "1473080",
    "end": "1475039"
  },
  {
    "text": "is a possibility that you know I create",
    "start": "1475039",
    "end": "1477320"
  },
  {
    "text": "a deployment and my deployment goes to",
    "start": "1477320",
    "end": "1480279"
  },
  {
    "text": "different clusters because there was",
    "start": "1480279",
    "end": "1482399"
  },
  {
    "text": "some propagation policy in the system",
    "start": "1482399",
    "end": "1484360"
  },
  {
    "text": "and it it choses CH it chose my um my",
    "start": "1484360",
    "end": "1489120"
  },
  {
    "text": "deployment you you see how how things",
    "start": "1489120",
    "end": "1491679"
  },
  {
    "text": "are kind of like backwards in a way so",
    "start": "1491679",
    "end": "1493840"
  },
  {
    "text": "instead of the deployment specifying how",
    "start": "1493840",
    "end": "1496600"
  },
  {
    "text": "how it should be deployed it's like the",
    "start": "1496600",
    "end": "1499000"
  },
  {
    "text": "opposite way you know the deployment is",
    "start": "1499000",
    "end": "1500960"
  },
  {
    "text": "there another object determines how it",
    "start": "1500960",
    "end": "1503440"
  },
  {
    "text": "should be propagated so it this was a",
    "start": "1503440",
    "end": "1505480"
  },
  {
    "text": "major friction um in Cube fed V2 so that",
    "start": "1505480",
    "end": "1510200"
  },
  {
    "text": "that kind of made this whole project",
    "start": "1510200",
    "end": "1512279"
  },
  {
    "text": "kind of fail in a way you know it's now",
    "start": "1512279",
    "end": "1515399"
  },
  {
    "text": "archived and I don't know if you face",
    "start": "1515399",
    "end": "1518120"
  },
  {
    "text": "the same problem at all in with your",
    "start": "1518120",
    "end": "1520880"
  },
  {
    "text": "users who are using carada in actual",
    "start": "1520880",
    "end": "1523760"
  },
  {
    "text": "prod environments or",
    "start": "1523760",
    "end": "1526880"
  },
  {
    "text": "not you can",
    "start": "1526880",
    "end": "1530320"
  },
  {
    "text": "uh uh yeah I can I can probably take",
    "start": "1531279",
    "end": "1533640"
  },
  {
    "text": "this question so I think in our use case",
    "start": "1533640",
    "end": "1536120"
  },
  {
    "text": "so first um we're no our clusters are",
    "start": "1536120",
    "end": "1538880"
  },
  {
    "text": "not like uh for long running services",
    "start": "1538880",
    "end": "1541520"
  },
  {
    "text": "for like deployments we're mainly for",
    "start": "1541520",
    "end": "1543840"
  },
  {
    "text": "batw clothes like model training jobs so",
    "start": "1543840",
    "end": "1547320"
  },
  {
    "text": "um and also we're try uh we tried to",
    "start": "1547320",
    "end": "1550240"
  },
  {
    "text": "make different clusters in our uh in a",
    "start": "1550240",
    "end": "1552640"
  },
  {
    "text": "single tier consistent so they have",
    "start": "1552640",
    "end": "1554279"
  },
  {
    "text": "exactly the same Hardwares and like any",
    "start": "1554279",
    "end": "1557080"
  },
  {
    "text": "other specs so that",
    "start": "1557080",
    "end": "1558880"
  },
  {
    "text": "uh the differences should be ideally um",
    "start": "1558880",
    "end": "1561799"
  },
  {
    "text": "agnostic to users and in our use case we",
    "start": "1561799",
    "end": "1565279"
  },
  {
    "text": "also built a an API on top of carada",
    "start": "1565279",
    "end": "1568520"
  },
  {
    "text": "that allows users to override to specify",
    "start": "1568520",
    "end": "1572000"
  },
  {
    "text": "which cluster they want to submit the",
    "start": "1572000",
    "end": "1574520"
  },
  {
    "text": "job to if they want to really override",
    "start": "1574520",
    "end": "1577000"
  },
  {
    "text": "that but um we haven't seen U um",
    "start": "1577000",
    "end": "1581440"
  },
  {
    "text": "frequent like requirements for that yeah",
    "start": "1581440",
    "end": "1585039"
  },
  {
    "text": "just uh want to add one point and also",
    "start": "1585039",
    "end": "1587600"
  },
  {
    "text": "our propagation",
    "start": "1587600",
    "end": "1588760"
  },
  {
    "text": "we we have predefined propagation",
    "start": "1588760",
    "end": "1590600"
  },
  {
    "text": "policies in our clusters so user just",
    "start": "1590600",
    "end": "1594080"
  },
  {
    "text": "choose like which kind of which tier",
    "start": "1594080",
    "end": "1596679"
  },
  {
    "text": "which cluster they want to deploy to",
    "start": "1596679",
    "end": "1598480"
  },
  {
    "text": "with our predefined propagation policies",
    "start": "1598480",
    "end": "1601080"
  },
  {
    "text": "I guess your is a little B more specific",
    "start": "1601080",
    "end": "1603279"
  },
  {
    "text": "to your Environ yeah",
    "start": "1603279",
    "end": "1606399"
  },
  {
    "text": "yeah uh hi thanks a great talk I have",
    "start": "1606399",
    "end": "1609360"
  },
  {
    "text": "one question how do you compare the",
    "start": "1609360",
    "end": "1611039"
  },
  {
    "text": "project commod and the",
    "start": "1611039",
    "end": "1614600"
  },
  {
    "text": "Q yeah I think this is interest can take",
    "start": "1615039",
    "end": "1618480"
  },
  {
    "text": "it no you no you can take it this is a",
    "start": "1618480",
    "end": "1621880"
  },
  {
    "text": "very interesting point cuz uh we are",
    "start": "1621880",
    "end": "1625080"
  },
  {
    "text": "also looking into the Q but currently",
    "start": "1625080",
    "end": "1627960"
  },
  {
    "text": "for Q mainly for like bad drob workloads",
    "start": "1627960",
    "end": "1631640"
  },
  {
    "text": "and for and it doesn't provide like uh a",
    "start": "1631640",
    "end": "1635399"
  },
  {
    "text": "multic cluster Resource Management kind",
    "start": "1635399",
    "end": "1638960"
  },
  {
    "text": "of features like uh most of the user use",
    "start": "1638960",
    "end": "1642760"
  },
  {
    "text": "PE will mainly for like Distributing",
    "start": "1642760",
    "end": "1644960"
  },
  {
    "text": "training job or inferencing job but for",
    "start": "1644960",
    "end": "1648919"
  },
  {
    "text": "kada you can use it for manage like",
    "start": "1648919",
    "end": "1650919"
  },
  {
    "text": "Secrets config maps and also loan",
    "start": "1650919",
    "end": "1654279"
  },
  {
    "text": "running services like deployments and I",
    "start": "1654279",
    "end": "1657960"
  },
  {
    "text": "think this is the current key",
    "start": "1657960",
    "end": "1660799"
  },
  {
    "text": "Point cool",
    "start": "1660799",
    "end": "1664120"
  },
  {
    "text": "thanks hi um I have um use case where I",
    "start": "1664840",
    "end": "1669679"
  },
  {
    "text": "have like a m closer environment with uh",
    "start": "1669679",
    "end": "1672159"
  },
  {
    "text": "long running services and I use like AR",
    "start": "1672159",
    "end": "1675640"
  },
  {
    "text": "CD to kind of deploy to multiple closers",
    "start": "1675640",
    "end": "1678200"
  },
  {
    "text": "today the problem I have is um if a a",
    "start": "1678200",
    "end": "1681559"
  },
  {
    "text": "team for service a def findes a HPA with",
    "start": "1681559",
    "end": "1685519"
  },
  {
    "text": "replicas 10 for example minimum repors",
    "start": "1685519",
    "end": "1688519"
  },
  {
    "text": "right it gets uh uh if I have three",
    "start": "1688519",
    "end": "1691279"
  },
  {
    "text": "clusters 30 pots because you know like",
    "start": "1691279",
    "end": "1694320"
  },
  {
    "text": "Argos it didn't have like that um",
    "start": "1694320",
    "end": "1697000"
  },
  {
    "text": "capability of like Distributing like",
    "start": "1697000",
    "end": "1698840"
  },
  {
    "text": "kind of Federated HPA something like",
    "start": "1698840",
    "end": "1701720"
  },
  {
    "text": "that uh does kada have something any",
    "start": "1701720",
    "end": "1703760"
  },
  {
    "text": "feature like that they can can I know",
    "start": "1703760",
    "end": "1705919"
  },
  {
    "text": "how many clusters I have and based on",
    "start": "1705919",
    "end": "1707799"
  },
  {
    "text": "what was was defined I can distribute",
    "start": "1707799",
    "end": "1709720"
  },
  {
    "text": "the load because I saw like you mention",
    "start": "1709720",
    "end": "1711720"
  },
  {
    "text": "in in the slides right some about that",
    "start": "1711720",
    "end": "1713840"
  },
  {
    "text": "yeah there's building policies in the",
    "start": "1713840",
    "end": "1716360"
  },
  {
    "text": "propagation policies that you can Define",
    "start": "1716360",
    "end": "1719480"
  },
  {
    "text": "like uh spread constraints by different",
    "start": "1719480",
    "end": "1721880"
  },
  {
    "text": "regions or uh by different uh zones so",
    "start": "1721880",
    "end": "1726600"
  },
  {
    "text": "it does have those capabilities in the",
    "start": "1726600",
    "end": "1728399"
  },
  {
    "text": "propagation policy oh perfect thank you",
    "start": "1728399",
    "end": "1730640"
  },
  {
    "text": "and it also have uh Federated HPA and",
    "start": "1730640",
    "end": "1733440"
  },
  {
    "text": "chrome drop HPA CH HPA okay I take a",
    "start": "1733440",
    "end": "1736919"
  },
  {
    "text": "look that thank you",
    "start": "1736919",
    "end": "1740039"
  },
  {
    "text": "right yeah thanks again for attending",
    "start": "1742720",
    "end": "1744919"
  },
  {
    "text": "this talk",
    "start": "1744919",
    "end": "1748120"
  }
]
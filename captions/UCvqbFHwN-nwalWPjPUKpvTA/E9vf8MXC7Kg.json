[
  {
    "start": "0",
    "end": "145000"
  },
  {
    "text": "I'd like to thank everybody who is joining us today and welcome to today's CN CF webinar challenges in deploying",
    "start": "350",
    "end": "7710"
  },
  {
    "text": "kubernetes on hyper-converged infrastructure x' so two things yeah we'll go back let me do our Q con slide",
    "start": "7710",
    "end": "15059"
  },
  {
    "text": "I do want to also remind everybody that Q con cloud native con North America our",
    "start": "15059",
    "end": "21750"
  },
  {
    "text": "flagship event and it is coming up in November in San Diego it should still be",
    "start": "21750",
    "end": "27029"
  },
  {
    "text": "very sunny lovely in November and this is as many of you who have attended",
    "start": "27029",
    "end": "32700"
  },
  {
    "text": "before this is a time for the community to come together to further their education and advance cloud native",
    "start": "32700",
    "end": "38489"
  },
  {
    "text": "computing you can go to cube condo for more information information get your",
    "start": "38489",
    "end": "44040"
  },
  {
    "text": "ticket and we're expecting about 12,000 people and to sell that out so before we",
    "start": "44040",
    "end": "51539"
  },
  {
    "text": "get started I'd like to also go through a few some housekeeping items during the webinar you are not able to Thaksin",
    "start": "51539",
    "end": "57930"
  },
  {
    "text": "attendee there is a Q&A box at the bottom of your screen please please feel",
    "start": "57930",
    "end": "63300"
  },
  {
    "text": "free to drop your questions in there and the team from diamante will go ahead and answer them throughout the presentation",
    "start": "63300",
    "end": "69780"
  },
  {
    "text": "now with that I would like to kick it over to Anna Ren who is going to introduce today's presenters and kick",
    "start": "69780",
    "end": "76439"
  },
  {
    "text": "off the webinar thank you good morning good afternoon and good evening folks",
    "start": "76439",
    "end": "81960"
  },
  {
    "text": "wherever you are greetings so I'm not in director of product marketing at",
    "start": "81960",
    "end": "87840"
  },
  {
    "text": "diamonte along with me I have Naveen set will be founding engineer at the MRT and",
    "start": "87840",
    "end": "93180"
  },
  {
    "text": "here's Patel founding engineer at giamatti all right today today we're",
    "start": "93180",
    "end": "101400"
  },
  {
    "text": "gonna take you through the background of AWS ec2 evolution as an example I know",
    "start": "101400",
    "end": "111810"
  },
  {
    "text": "in here and I'll be discussing the challenges and some of the options solution technology is available from",
    "start": "111810",
    "end": "117630"
  },
  {
    "text": "Network and storage and when this transformation to these cloud native applications is happening and this is",
    "start": "117630",
    "end": "123630"
  },
  {
    "text": "from context of HCI platform hi this is Hiro and at the last I'll do a demo for",
    "start": "123630",
    "end": "130979"
  },
  {
    "text": "deploying a container workload and also the watch life's KVM workload onto the same HCI infrastructure using",
    "start": "130979",
    "end": "138010"
  },
  {
    "text": "the same kubernetes cluster and we'll wrap up with Q&A all right Thank You",
    "start": "138010",
    "end": "146290"
  },
  {
    "start": "145000",
    "end": "322000"
  },
  {
    "text": "Hiro so let's take you through some evolution here for the next few minutes",
    "start": "146290",
    "end": "151769"
  },
  {
    "text": "the credit goes to their two stalwarts at Amazon Web Services they are also",
    "start": "151769",
    "end": "158769"
  },
  {
    "text": "known as AWS Jerry Hargrove who is very famously known as AWS geek look him up as it obvious geek and",
    "start": "158769",
    "end": "165609"
  },
  {
    "text": "you'll find lots and lots and lots of beautiful pictures about how things work how things are architected at AWS and",
    "start": "165609",
    "end": "172409"
  },
  {
    "text": "this picture a part of the this is a part of the picture from one of Gerry",
    "start": "172409",
    "end": "177669"
  },
  {
    "text": "har cross drawings credit also goes to James Hamilton with a distinguished",
    "start": "177669",
    "end": "182859"
  },
  {
    "text": "engineer at AWS being a dear oblivious forever and there's a bunch of publications that he has done through",
    "start": "182859",
    "end": "190079"
  },
  {
    "text": "embedded rona and others that we are going to use today to walk you through",
    "start": "190079",
    "end": "195159"
  },
  {
    "text": "some of the evolutionary aspects of the easy to compute instance at AWS so it",
    "start": "195159",
    "end": "203979"
  },
  {
    "text": "all began this way for all of us anybody in IT this is a standard picture right and this is the crawl phase of what",
    "start": "203979",
    "end": "212260"
  },
  {
    "text": "Gerry calls it as for an Amazon compute instance and this is specifically Amazon",
    "start": "212260",
    "end": "219069"
  },
  {
    "text": "ec2 instance and if you go back to history the first incarnation of ec2",
    "start": "219069",
    "end": "226259"
  },
  {
    "text": "came about in 2006 alright and up to",
    "start": "226259",
    "end": "231810"
  },
  {
    "text": "2013 this was the constant picture for any compute node or host at AWS and if",
    "start": "231810",
    "end": "240579"
  },
  {
    "text": "you look at this picture you know it's got hardware on top of hardware its software software that runs networking",
    "start": "240579",
    "end": "248139"
  },
  {
    "text": "that runs storage provides management security monitoring there is a layer of",
    "start": "248139",
    "end": "253299"
  },
  {
    "text": "hypervisor and on top of the hypervisor you deploy what your machines which are known also",
    "start": "253299",
    "end": "258849"
  },
  {
    "text": "known as instances but in effect from 2006 all the way to about 2013",
    "start": "258849",
    "end": "266560"
  },
  {
    "text": "you know if you look at what Jameis Hamilton has written he basically sums it up in one sentence which is",
    "start": "266560",
    "end": "272819"
  },
  {
    "text": "networking is in effect in the way and blocking the efficient optimisation of",
    "start": "272819",
    "end": "278349"
  },
  {
    "text": "valuable resources in the data center so why is this a server is the most",
    "start": "278349",
    "end": "283509"
  },
  {
    "text": "expensive component in a data center on our server and all the components that go into a server and think about it",
    "start": "283509",
    "end": "290680"
  },
  {
    "text": "every data center in for a public cloud provider like AWS there's hundreds and hundreds of server in any data center",
    "start": "290680",
    "end": "297159"
  },
  {
    "text": "and if that's the most valuable asset that you have something else coming in",
    "start": "297159",
    "end": "302409"
  },
  {
    "text": "and coming in your way of efficient you desire utilization means a lot in terms",
    "start": "302409",
    "end": "308229"
  },
  {
    "text": "of the cost means a lot in terms of the capabilities at which the they have to",
    "start": "308229",
    "end": "314740"
  },
  {
    "text": "provide to the customers so let's take a look at now and see how this ec2 instances award over time all right so",
    "start": "314740",
    "end": "323199"
  },
  {
    "text": "this is the big picture from AWS geek of which you know I took a part of it to explain and kick this conversation off",
    "start": "323199",
    "end": "330729"
  },
  {
    "text": "and you can find this again at AWS kake.com so let's work from the",
    "start": "330729",
    "end": "336400"
  },
  {
    "text": "left-hand side or crawls from the left-hand side and try to walk by the end of it all right so what we see on",
    "start": "336400",
    "end": "342129"
  },
  {
    "text": "the left-hand sides here is the picture from ec2 instance circa 2013 all right",
    "start": "342129",
    "end": "349029"
  },
  {
    "text": "in 2013 Amazon introduced the nitro car",
    "start": "349029",
    "end": "354909"
  },
  {
    "text": "or the nitro system by using the Nitro system they offloaded the networking",
    "start": "354909",
    "end": "360849"
  },
  {
    "text": "component which was running in software onto a hardware offload known as nitro",
    "start": "360849",
    "end": "367270"
  },
  {
    "text": "and this nitro system was built on quartz meaning commercial off-the-shelf",
    "start": "367270",
    "end": "373889"
  },
  {
    "text": "components and basically just by doing this they got 20% additional bandwidth",
    "start": "373889",
    "end": "383409"
  },
  {
    "text": "on the network and this is the c3 instance so this the evolution from c2 to c3 20% additional bandwidth and 50%",
    "start": "383409",
    "end": "391409"
  },
  {
    "text": "latency reduction so your latency went down by 50% reduced performance",
    "start": "391409",
    "end": "397659"
  },
  {
    "text": "variability which means you could expect much more deterministic performance when you ran something ran a",
    "start": "397659",
    "end": "404860"
  },
  {
    "text": "virtual machine on top of the system compared to an ec2 system alright so",
    "start": "404860",
    "end": "410860"
  },
  {
    "text": "that was the first technique that they used to offload the network of course you know the taste was good so next",
    "start": "410860",
    "end": "417430"
  },
  {
    "text": "comes C 3 instance and that was one year later in 2014 and with the introduction",
    "start": "417430",
    "end": "424960"
  },
  {
    "text": "of Annapurna at that time the storage subsystem of the storage system which",
    "start": "424960",
    "end": "430449"
  },
  {
    "text": "was running in software got moved to Hardware offload and that was also a",
    "start": "430449",
    "end": "436090"
  },
  {
    "text": "cart system meaning of the shelf system ASIC based and by now moving the storage",
    "start": "436090",
    "end": "442990"
  },
  {
    "text": "component to the hardware layer to offload the system they gained 12.5%",
    "start": "442990",
    "end": "450039"
  },
  {
    "text": "more compute out of the environment what that means is if we have a hundred data",
    "start": "450039",
    "end": "456250"
  },
  {
    "text": "centers previously they basically eliminated at least 12 of them that's a",
    "start": "456250",
    "end": "462669"
  },
  {
    "text": "huge huge huge cost savings first of all on top of that it's not only about cost",
    "start": "462669",
    "end": "468759"
  },
  {
    "text": "it's also about performance it's also about latency reduction it's also about QoS type of treatment to traffic across",
    "start": "468759",
    "end": "476889"
  },
  {
    "text": "the data center so that was c4 all right so now in 2015 a year later the ec5",
    "start": "476889",
    "end": "487449"
  },
  {
    "text": "instance was introduced and following the same suit the management security",
    "start": "487449",
    "end": "494229"
  },
  {
    "text": "and monitoring layers were pushed down to the hardware layer again with another",
    "start": "494229",
    "end": "499270"
  },
  {
    "text": "hardware half load mechanism and do not hear that by moving that Amazon achieved",
    "start": "499270",
    "end": "508349"
  },
  {
    "text": "separation of control and data plane which is very critical so that there is",
    "start": "508349",
    "end": "513370"
  },
  {
    "text": "granular control of the system overall and 100% computer availability so",
    "start": "513370",
    "end": "520620"
  },
  {
    "text": "essentially again more savings more performance more compute which means more margins you know more wiggle room",
    "start": "520620",
    "end": "528190"
  },
  {
    "text": "to play with and more applications to be on loaded onto the same infrastructure because of higher performance so there",
    "start": "528190",
    "end": "536690"
  },
  {
    "text": "is a few things though that we need to work you know compare and contrast here by the time we",
    "start": "536690",
    "end": "541790"
  },
  {
    "text": "got to the c5 instance the unimportance system which was used to the management",
    "start": "541790",
    "end": "546830"
  },
  {
    "text": "security and monitoring was based off a custom ASIC not cots all right that's just you know that's",
    "start": "546830",
    "end": "553520"
  },
  {
    "text": "what it is that's what the picture says as well as one other aspect here is the",
    "start": "553520",
    "end": "560510"
  },
  {
    "text": "hypervisor layer stayed on from left to right however the hypervisor on the first",
    "start": "560510",
    "end": "566480"
  },
  {
    "text": "three is different from the hypervisor on the right hand side because the right hand side I per visor you know is known",
    "start": "566480",
    "end": "572240"
  },
  {
    "text": "as the nitro hypervisor with additional capabilities to enable certain other",
    "start": "572240",
    "end": "577700"
  },
  {
    "text": "applications to be run on the system alright so by separating control and",
    "start": "577700",
    "end": "583399"
  },
  {
    "text": "data plane they also were able to easily do billing of instances and so on all",
    "start": "583399",
    "end": "590779"
  },
  {
    "text": "right so now this is the evolution that's happened over a period of time so in summary you know offloading storage",
    "start": "590779",
    "end": "598010"
  },
  {
    "text": "networking capabilities on - you know cards based systems or custom ASIC based",
    "start": "598010",
    "end": "604250"
  },
  {
    "text": "systems provides us better in our reduces performance variability provides",
    "start": "604250",
    "end": "609650"
  },
  {
    "text": "us with better performance reduces latency and so on all right so let's have that in our mind and that evolution",
    "start": "609650",
    "end": "617570"
  },
  {
    "text": "in mind and let's see how data center has award over a period of time so here",
    "start": "617570",
    "end": "623630"
  },
  {
    "text": "for your reference these are the four variations or the form factors of the",
    "start": "623630",
    "end": "629920"
  },
  {
    "text": "e.r obvious nitro cards for your reference there's the URL take a look at them at your free time so now let's go",
    "start": "629920",
    "end": "636620"
  },
  {
    "text": "ahead and take a look at how data center looks today how hyper-converged infrastructure in a",
    "start": "636620",
    "end": "642050"
  },
  {
    "start": "637000",
    "end": "945000"
  },
  {
    "text": "data center looks today and what are some of the parallels that we can draw from public cloud providers like AWS and",
    "start": "642050",
    "end": "647839"
  },
  {
    "text": "see where we can land or where we should be heading towards in the data center so",
    "start": "647839",
    "end": "653570"
  },
  {
    "text": "here is a picture and I walk you through this from left hand side to right hand side next couple of minute and there's a little bit of reality here",
    "start": "653570",
    "end": "660970"
  },
  {
    "text": "there's a little bit of a fiction here and then there's a little bit of a reality here so I will tell you why I am",
    "start": "660970",
    "end": "666480"
  },
  {
    "text": "saying that in such a funny manner all right so let's start on the left-hand side here so it's known as first of all",
    "start": "666480",
    "end": "673360"
  },
  {
    "text": "hyper control infrastructure is the de facto infrastructure that's being",
    "start": "673360",
    "end": "678459"
  },
  {
    "text": "deployed in the data center today in every enterprise in every service",
    "start": "678459",
    "end": "683529"
  },
  {
    "text": "provider environment for any IT workload deployment all right so with I",
    "start": "683529",
    "end": "688689"
  },
  {
    "text": "watched one dot o the pioneers of HCI you know visible Nutanix VMware as you",
    "start": "688689",
    "end": "696220"
  },
  {
    "text": "all know started off by packing networking storage compute onto a single",
    "start": "696220",
    "end": "703449"
  },
  {
    "text": "node a single server and basically bringing more efficiencies in terms of",
    "start": "703449",
    "end": "709209"
  },
  {
    "text": "packing things into a server at the same time the what we also observed with",
    "start": "709209",
    "end": "714999"
  },
  {
    "text": "hyper-converged 1.0 is that host is heavily taxed in terms of utilization",
    "start": "714999",
    "end": "721149"
  },
  {
    "text": "and performance there is applications application starvation due to the way",
    "start": "721149",
    "end": "727329"
  },
  {
    "text": "that virtual machines run on an AI provider environment the noisy neighbor problems persisted SaaS could be only",
    "start": "727329",
    "end": "735369"
  },
  {
    "text": "guaranteed to a certain extent or maybe not at all sometimes and it it costed a",
    "start": "735369",
    "end": "741759"
  },
  {
    "text": "whole bunch of money still to deploy these systems so alright let's keep that",
    "start": "741759",
    "end": "747610"
  },
  {
    "text": "keep that one dollar picture in mind now let's take the learnings from AWS and",
    "start": "747610",
    "end": "752799"
  },
  {
    "text": "say and say what is we offloaded the networking component in NHC I want Auto",
    "start": "752799",
    "end": "758740"
  },
  {
    "text": "environment and made that HCI 1.5 right so that is the second picture from the",
    "start": "758740",
    "end": "765040"
  },
  {
    "text": "left-hand side alright let's fast-forward what is we also learnt from the storage evolution",
    "start": "765040",
    "end": "770679"
  },
  {
    "text": "in AWS and offloaded that onto another storage system in hardware okay that's",
    "start": "770679",
    "end": "776410"
  },
  {
    "text": "HCI 2.0 that's basically following AWS as your in terms of and areas in terms",
    "start": "776410",
    "end": "782559"
  },
  {
    "text": "of outpost and nitro that you might have seen some announcements on right so if this is a what-if scenario where if we",
    "start": "782559",
    "end": "788980"
  },
  {
    "text": "are offloaded both networking storage on to HCI to dot oh we would have gotten much more",
    "start": "788980",
    "end": "795350"
  },
  {
    "text": "efficiencies in parallel with what AWS got with respect to networking storage and so on",
    "start": "795350",
    "end": "800600"
  },
  {
    "text": "however hypervisor still remained in the picture not only that let's also take a",
    "start": "800600",
    "end": "806510"
  },
  {
    "text": "look at the current HCI solutions that we have in the market today right in all",
    "start": "806510",
    "end": "812150"
  },
  {
    "text": "of the HCI solutions that are available today the instant storage which is also",
    "start": "812150",
    "end": "817160"
  },
  {
    "text": "known as ephemeral storage is always in a pooled storage environment it is never",
    "start": "817160",
    "end": "823850"
  },
  {
    "text": "in a local storage environment on the host however public cloud providers have",
    "start": "823850",
    "end": "830420"
  },
  {
    "text": "been able to solve this problem with hardware offloads and other mechanisms to actually provide an instant storage",
    "start": "830420",
    "end": "837170"
  },
  {
    "text": "on the host that brings a lot of efficiencies that provides the QoS",
    "start": "837170",
    "end": "842360"
  },
  {
    "text": "capabilities that is critically needed for a workload to run in the environment",
    "start": "842360",
    "end": "847610"
  },
  {
    "text": "so that's absolutely missing today all right so diamonte looked at these",
    "start": "847610",
    "end": "855070"
  },
  {
    "text": "progress being made in the industry as well as the learnings that we picked up along the way and we adopted these",
    "start": "855070",
    "end": "862520"
  },
  {
    "text": "things right from day one in our approach to building the hyper current infrastructure for kubernetes so at the",
    "start": "862520",
    "end": "870200"
  },
  {
    "text": "MRT we have networking and storage offloads along with open source kubernetes patch packaged together for a",
    "start": "870200",
    "end": "878660"
  },
  {
    "text": "cloud native infrastructure all right so with this we are able to achieve 95%",
    "start": "878660",
    "end": "886030"
  },
  {
    "text": "hostel is butyl ization the hypervisor is completely eliminated there is no noisy neighbor problems all",
    "start": "886030",
    "end": "893780"
  },
  {
    "text": "those are taken care of due to the way the hardware offload works for both networking and storage SLA guarantees",
    "start": "893780",
    "end": "901280"
  },
  {
    "text": "can be provided to as granular has 100 microseconds of latency and providing",
    "start": "901280",
    "end": "911540"
  },
  {
    "text": "the lowest TCO at the same time now not",
    "start": "911540",
    "end": "916700"
  },
  {
    "text": "you know if you look at every IT team out there they are not given a white",
    "start": "916700",
    "end": "923600"
  },
  {
    "text": "piece of paper everyday or a blank piece of paper every day to restart their IT environment they will always have a set",
    "start": "923600",
    "end": "930589"
  },
  {
    "text": "of legacy workloads which may not be containerized at all which are yet to be",
    "start": "930589",
    "end": "935690"
  },
  {
    "text": "containerized so they would need to run in a virtual machine-based environment so how would we solve that problem so in",
    "start": "935690",
    "end": "946639"
  },
  {
    "start": "945000",
    "end": "1112000"
  },
  {
    "text": "the CSA of community you know the community is together brought forward the notion of C&V or container native",
    "start": "946639",
    "end": "954399"
  },
  {
    "text": "virtualization and coop board is one of the projects in this under this umbrella",
    "start": "954399",
    "end": "961149"
  },
  {
    "text": "within coop word the idea is to using collaboration coop word the idea is to",
    "start": "961149",
    "end": "968149"
  },
  {
    "text": "run containers and virtual machine as equal citizens on the same infrastructure which is either",
    "start": "968149",
    "end": "974420"
  },
  {
    "text": "conversate auto plus here with kubernetes as the orchestrator and why",
    "start": "974420",
    "end": "980600"
  },
  {
    "text": "is why is this important this is important because regardless of the workload whether it's a container",
    "start": "980600",
    "end": "986420"
  },
  {
    "text": "whether it's a virtual machine they both can be orchestrated using kubernetes if",
    "start": "986420",
    "end": "993800"
  },
  {
    "text": "they are a set of port specs and you deploy a container you deploy a set of",
    "start": "993800",
    "end": "999380"
  },
  {
    "text": "containers you deploy a virtual machine or a set of virtual machines it's the same mechanism it is the same tool it's",
    "start": "999380",
    "end": "1005230"
  },
  {
    "text": "the same learning it's the same training that you need to have right and this is",
    "start": "1005230",
    "end": "1010420"
  },
  {
    "text": "very important because simplicity drives efficiency simplicity drives debug ability simplicity drives a whole lot of",
    "start": "1010420",
    "end": "1017170"
  },
  {
    "text": "things and this is where the CNC F community is heading towards and you might have seen some announcements a",
    "start": "1017170",
    "end": "1023709"
  },
  {
    "text": "couple of weeks ago from VMware in terms of taking certain kubernetes components and plugging them into the vSphere",
    "start": "1023709",
    "end": "1030970"
  },
  {
    "text": "environment the the most important aspect to observe there is that for",
    "start": "1030970",
    "end": "1037659"
  },
  {
    "text": "anybody to run a virtual machine there to go through the vSphere way of doing things whereas when somebody wants to light up",
    "start": "1037659",
    "end": "1044319"
  },
  {
    "text": "a set of containers they will have to go through a different path and that results in two sets of tools for dudas",
    "start": "1044319",
    "end": "1051309"
  },
  {
    "text": "two different workload types two different training training two different",
    "start": "1051309",
    "end": "1056659"
  },
  {
    "text": "you know multiple training sessions etc etcetera etcetera so that kind of comes",
    "start": "1056659",
    "end": "1064070"
  },
  {
    "text": "in the way of simplicity essentially now with that background let me hand you",
    "start": "1064070",
    "end": "1070309"
  },
  {
    "text": "over to Naveen to walk through some of the critical requirements to run",
    "start": "1070309",
    "end": "1076549"
  },
  {
    "text": "containers in a CI environment sure hey thanks marine thanks for",
    "start": "1076549",
    "end": "1082490"
  },
  {
    "text": "walking through the whole evaluation process that happened over these few",
    "start": "1082490",
    "end": "1087769"
  },
  {
    "text": "years let us now look at the requirements that came up during this",
    "start": "1087769",
    "end": "1093409"
  },
  {
    "text": "process right I mean if you step back five years or so container technology had just started being touted as the",
    "start": "1093409",
    "end": "1099919"
  },
  {
    "text": "next wave of disruption the way applications will be deployed and delivered and this with oncoming change",
    "start": "1099919",
    "end": "1107779"
  },
  {
    "text": "the requirements for an HCI flash comm had to be revisited so so let's look at",
    "start": "1107779",
    "end": "1113899"
  },
  {
    "start": "1112000",
    "end": "1686000"
  },
  {
    "text": "from just containerized applications perspective right you have multiple applications running what are the new",
    "start": "1113899",
    "end": "1123769"
  },
  {
    "text": "requirements from network and storage side from this perspective you want",
    "start": "1123769",
    "end": "1130429"
  },
  {
    "text": "multiple application but you want guaranteed SLS for these applications from network and storage you want",
    "start": "1130429",
    "end": "1136549"
  },
  {
    "text": "consistency in performance predictability in performance so what does it map to on network side if you",
    "start": "1136549",
    "end": "1144559"
  },
  {
    "text": "look at it the technology has already started it was already out there Azariah",
    "start": "1144559",
    "end": "1150769"
  },
  {
    "text": "V was already proven they were already",
    "start": "1150769",
    "end": "1155899"
  },
  {
    "text": "off-the-shelf chips that could guarantee performance that could give Hardware",
    "start": "1155899",
    "end": "1160970"
  },
  {
    "text": "cubes to your application right these these allowed you to program minimum",
    "start": "1160970",
    "end": "1166159"
  },
  {
    "text": "guarantees maximum limits as at each container level at each virtual function",
    "start": "1166159",
    "end": "1172279"
  },
  {
    "text": "level that virtual function could always be extended to container let's extend",
    "start": "1172279",
    "end": "1177919"
  },
  {
    "text": "this on the storage side around the same time nvme started becoming standardized",
    "start": "1177919",
    "end": "1183760"
  },
  {
    "text": "so now you could have the same way you had it on networking site you could have",
    "start": "1183760",
    "end": "1189470"
  },
  {
    "text": "chill function which could map to namespaces at the volume at the storage",
    "start": "1189470",
    "end": "1195799"
  },
  {
    "text": "layer where you could have hardware queues for each of these virtual functions and then you could basically",
    "start": "1195799",
    "end": "1202700"
  },
  {
    "text": "guarantee minimum guarantee as well as put maximum limits on each of these",
    "start": "1202700",
    "end": "1208190"
  },
  {
    "text": "virtual functions basically meaning for each application you could guarantee a certain amount of AI ops you could limit",
    "start": "1208190",
    "end": "1216200"
  },
  {
    "text": "a certain amount of firearms now going back or referring to an arrangement of",
    "start": "1216200",
    "end": "1221360"
  },
  {
    "text": "the slides this Willis this evolution that happened there was a physical",
    "start": "1221360",
    "end": "1227779"
  },
  {
    "text": "aspect also that was out there networking side the bandits were going",
    "start": "1227779",
    "end": "1233000"
  },
  {
    "text": "from 10 gauge to 25 gig or party gave 50k and even hundred gigs with",
    "start": "1233000",
    "end": "1238179"
  },
  {
    "text": "sub-millisecond latency similarly on the storage end we are talking about a",
    "start": "1238179",
    "end": "1243200"
  },
  {
    "text": "million I ops becoming very normal again at some millisecond level so with all",
    "start": "1243200",
    "end": "1248480"
  },
  {
    "text": "this in mind now you have to really review revisit how your HGH platform is",
    "start": "1248480",
    "end": "1254509"
  },
  {
    "text": "going to look at move 1-year forward and kubernetes starts getting a strong",
    "start": "1254509",
    "end": "1260960"
  },
  {
    "text": "foothold as orchestration platform of choice from multiple applications",
    "start": "1260960",
    "end": "1268669"
  },
  {
    "text": "running on a node you are transitioning to multiple instances of applications running on multiple nodes and handling",
    "start": "1268669",
    "end": "1275899"
  },
  {
    "text": "of application failover is now part of the core design of this orchestration",
    "start": "1275899",
    "end": "1281899"
  },
  {
    "text": "platform through different sync groups and see in a CS playing of course an important role here the CNI and CSI",
    "start": "1281899",
    "end": "1289340"
  },
  {
    "text": "standards evolved I mean of course flex volume being a precursor for this on the CSI side and on the scheduler side a way",
    "start": "1289340",
    "end": "1298039"
  },
  {
    "text": "to extend the scheduler which was way more aware could take decision more",
    "start": "1298039",
    "end": "1303169"
  },
  {
    "text": "intelligently based on its knowledge of the resources of the underlying hyper-converged infrastructure so let's",
    "start": "1303169",
    "end": "1310190"
  },
  {
    "text": "look at networking and storage side requirements that came up because of time on the networking side IP address",
    "start": "1310190",
    "end": "1319429"
  },
  {
    "text": "or network endpoint being another way of referring to it it should be dynamically manageable",
    "start": "1319429",
    "end": "1324650"
  },
  {
    "text": "without the user having to provision it for each and every application instance that comes up goes away but then look at",
    "start": "1324650",
    "end": "1331490"
  },
  {
    "text": "the other way there could be certain application that would require static configuration they want a nice endpoint",
    "start": "1331490",
    "end": "1336530"
  },
  {
    "text": "to be persistent with the instance of an application ability to have visibility",
    "start": "1336530",
    "end": "1341660"
  },
  {
    "text": "of these endpoints at the network layer to allow monitoring or even enforcing policies you want separation of control",
    "start": "1341660",
    "end": "1349880"
  },
  {
    "text": "and data plane you want you don't want your data plane failover to impact your",
    "start": "1349880",
    "end": "1355820"
  },
  {
    "text": "manageability of your kubernetes cluster and availability to support availability",
    "start": "1355820",
    "end": "1365270"
  },
  {
    "text": "zones itself multiple data centers campus clusters similarly on the storage",
    "start": "1365270",
    "end": "1371990"
  },
  {
    "text": "side sorry about that",
    "start": "1371990",
    "end": "1377630"
  },
  {
    "text": "similarly on the storage end you wanted static and dynamic provisioning from so",
    "start": "1377630",
    "end": "1382910"
  },
  {
    "text": "it's perspective or from volume perspective you want it's synchronous mirroring where your application would",
    "start": "1382910",
    "end": "1389150"
  },
  {
    "text": "have persistent data across different nodes and there should be synchronous",
    "start": "1389150",
    "end": "1394330"
  },
  {
    "text": "you the application failover should not have to worry about a Delta",
    "start": "1394330",
    "end": "1399560"
  },
  {
    "text": "between the state of data across these nodes you want rich feature set from",
    "start": "1399560",
    "end": "1404990"
  },
  {
    "text": "enterprise customers perspective you want snapshots you want ability to restore the snapshot you want to take",
    "start": "1404990",
    "end": "1410720"
  },
  {
    "text": "backup and you want the ability to restore these they stay to the backups",
    "start": "1410720",
    "end": "1418360"
  },
  {
    "text": "and of course availability zones should also be able to extend the storage",
    "start": "1418360",
    "end": "1423440"
  },
  {
    "text": "features to be able to extend across availability zones",
    "start": "1423440",
    "end": "1427780"
  },
  {
    "text": "now let's look at the hair requirements for kubernetes clusters from availability zones perspective now high",
    "start": "1433000",
    "end": "1442750"
  },
  {
    "text": "availability zones from enterprise customers perspective normally maps to campus clusters these are data centers",
    "start": "1442750",
    "end": "1448900"
  },
  {
    "text": "not that far apart let's take from 1550 miles or so now the",
    "start": "1448900",
    "end": "1455440"
  },
  {
    "text": "requirements are from network and storage a little bit different on the networking side you want your",
    "start": "1455440",
    "end": "1462990"
  },
  {
    "text": "administration to be able to configure different subnets across different zones so when applications are coming across",
    "start": "1462990",
    "end": "1469690"
  },
  {
    "text": "up on different zones they get IP addresses they get endpoint assigned",
    "start": "1469690",
    "end": "1475090"
  },
  {
    "text": "dynamically automatically on the subnet where that application comes up and the",
    "start": "1475090",
    "end": "1481630"
  },
  {
    "text": "network should be laid out such that these are routable across these data centers on the storage side you want",
    "start": "1481630",
    "end": "1488470"
  },
  {
    "text": "your mirrors to be created to be placed across these zones so that a failover on",
    "start": "1488470",
    "end": "1494049"
  },
  {
    "text": "one zone allows you to move the application to another zone and having the data available synchronously in that",
    "start": "1494049",
    "end": "1501909"
  },
  {
    "text": "zone as well now all this works very well for",
    "start": "1501909",
    "end": "1508799"
  },
  {
    "text": "containerized applications but what about applications that are still on this path of transformation the",
    "start": "1508799",
    "end": "1514630"
  },
  {
    "text": "yet-to-be containerized application you don't want to have a separate infrastructure dip deploy such",
    "start": "1514630",
    "end": "1520240"
  },
  {
    "text": "application and through Cubert project under ciencia there have been some great",
    "start": "1520240",
    "end": "1525309"
  },
  {
    "text": "work done here ability to run applications in a virtualized environment but inside a container",
    "start": "1525309",
    "end": "1530320"
  },
  {
    "text": "framework refer to as container native virtualization on networking and storage",
    "start": "1530320",
    "end": "1535390"
  },
  {
    "text": "perspective you don't want anything to change from the way you did your cloud native application itself you want the",
    "start": "1535390",
    "end": "1542679"
  },
  {
    "text": "same feature parity you want the same performance and you want a single pane",
    "start": "1542679",
    "end": "1548320"
  },
  {
    "text": "of managing these applications you you have learned Kuban it is all ready to",
    "start": "1548320",
    "end": "1554140"
  },
  {
    "text": "deploy your applications natively you want these application but yet to be containerized applications to be also",
    "start": "1554140",
    "end": "1560620"
  },
  {
    "text": "managed exactly in the same way you don't want to learn a different framework for the",
    "start": "1560620",
    "end": "1565850"
  },
  {
    "text": "such applications now stepping back",
    "start": "1565850",
    "end": "1573640"
  },
  {
    "text": "given all these requirements defined for an HDI the management of these components is also an integral part of",
    "start": "1573640",
    "end": "1581330"
  },
  {
    "text": "an HDI requirement again not very different from the offerings in the cloud whether it be for configuration",
    "start": "1581330",
    "end": "1587660"
  },
  {
    "text": "management user management - Active Directory or user policy informant",
    "start": "1587660",
    "end": "1592730"
  },
  {
    "text": "enforcement - Arbor should also be considered when designing or evaluating a platform for deploying cloud native",
    "start": "1592730",
    "end": "1599059"
  },
  {
    "text": "application under this new paradigm so given all these requirements are defined",
    "start": "1599059",
    "end": "1605890"
  },
  {
    "text": "let's look at one of the solutions that's out there that does take care of all these features that I am going to",
    "start": "1605890",
    "end": "1613039"
  },
  {
    "text": "give it to hero who's going to demo demo some of the features that we just now discussed thank you thank you Naveen and",
    "start": "1613039",
    "end": "1620299"
  },
  {
    "text": "Narine for the great introduction in this section I'll go ahead and give a",
    "start": "1620299",
    "end": "1626390"
  },
  {
    "text": "demo of a multiple demos so there are three demos that I've set it up first we'll go over the setup that I'll be",
    "start": "1626390",
    "end": "1633679"
  },
  {
    "text": "using it the kubernetes cluster which is deployed on to the HPI appliance and the",
    "start": "1633679",
    "end": "1639770"
  },
  {
    "text": "same cluster will use to deploy a containerized workload which is a wordpress application that's an example",
    "start": "1639770",
    "end": "1645770"
  },
  {
    "text": "I'll use it to deploy it and we'll use the same of cuban√≠a test cluster and",
    "start": "1645770",
    "end": "1651080"
  },
  {
    "text": "deploy or KVM to showcase that yet to be containerized applications can also be",
    "start": "1651080",
    "end": "1656960"
  },
  {
    "text": "deployed onto the same infrastructure using the same Kuban a test cluster and",
    "start": "1656960",
    "end": "1662210"
  },
  {
    "text": "in the fourth section which will be the last demo in that one we will showcase",
    "start": "1662210",
    "end": "1668360"
  },
  {
    "text": "the benefits of hardware offloading for the network and storage resources and",
    "start": "1668360",
    "end": "1673760"
  },
  {
    "text": "how we can use those benefits to provide the i/o isolation for application first",
    "start": "1673760",
    "end": "1679549"
  },
  {
    "text": "VM instances along with the QoS for the performance now let's go ahead and take",
    "start": "1679549",
    "end": "1687080"
  },
  {
    "start": "1686000",
    "end": "1778000"
  },
  {
    "text": "a look at the demo demo setup type I'll be using it so I'll use a three node",
    "start": "1687080",
    "end": "1692360"
  },
  {
    "text": "cluster as I mentioned this is an HCI platform of and on which we have clustered the three",
    "start": "1692360",
    "end": "1699820"
  },
  {
    "text": "node Cuban a test cluster as you can see there are blue and green components blue",
    "start": "1699820",
    "end": "1706360"
  },
  {
    "text": "are all open source cuban a test component we have a one node node one which is running all the master",
    "start": "1706360",
    "end": "1712780"
  },
  {
    "text": "components of the kubernetes and the green component are basically nothing",
    "start": "1712780",
    "end": "1718180"
  },
  {
    "text": "but the these components provide the functionality from the HCI platform",
    "start": "1718180",
    "end": "1723340"
  },
  {
    "text": "standpoint to do a resource pooling for the network and storage standpoint and also the CNI and CSI plugins to",
    "start": "1723340",
    "end": "1730960"
  },
  {
    "text": "provision the network and storage resources to provide the guaranteed QoS",
    "start": "1730960",
    "end": "1737140"
  },
  {
    "text": "guaranteed performance and making sure that you provide our io isolation for",
    "start": "1737140",
    "end": "1742420"
  },
  {
    "text": "each and every container deployed on to this infrastructure there is also a",
    "start": "1742420",
    "end": "1747610"
  },
  {
    "text": "scheduler extension component which makes sure that it is aware of what all",
    "start": "1747610",
    "end": "1753340"
  },
  {
    "text": "the resources thus given infrastructure is able to provide making sure it is",
    "start": "1753340",
    "end": "1759010"
  },
  {
    "text": "aware of whether it's a high availability cluster whether it is a single ozone cluster and making sure it",
    "start": "1759010",
    "end": "1766960"
  },
  {
    "text": "is able to schedule the resources in a such a manner that it provides the high availability for a given resource from a",
    "start": "1766960",
    "end": "1774040"
  },
  {
    "text": "application standpoint now let's go",
    "start": "1774040",
    "end": "1779980"
  },
  {
    "start": "1778000",
    "end": "2182000"
  },
  {
    "text": "ahead and kick in the first demo where I will go ahead and deploy a wordpress application before I deploy the",
    "start": "1779980",
    "end": "1786310"
  },
  {
    "text": "application I'll just give you a pictorial view of how the application deployment will look like on to the",
    "start": "1786310",
    "end": "1792790"
  },
  {
    "text": "Cuban a test cluster that we have built across the three nodes so when we deploy",
    "start": "1792790",
    "end": "1799120"
  },
  {
    "text": "in a WordPress application which is running along with the my sequel which is using a MySQL as a data store so here",
    "start": "1799120",
    "end": "1806680"
  },
  {
    "text": "I will deploy our three instances afterward place WordPress which will be running on to the three instances node 1",
    "start": "1806680",
    "end": "1813130"
  },
  {
    "text": "node 2 and node 3 and will deploy on my sequel which will be using an underneath",
    "start": "1813130",
    "end": "1818860"
  },
  {
    "text": "persistent volume on tour diamonte i/o layer as you can see here and we will go",
    "start": "1818860",
    "end": "1825640"
  },
  {
    "text": "ahead and use a queue benitez construct called storage class 2 dynamically provisioned the persistent",
    "start": "1825640",
    "end": "1832300"
  },
  {
    "text": "storage onto the diamonte IO layer as you can see there are three discs are",
    "start": "1832300",
    "end": "1838660"
  },
  {
    "text": "drawn onto the picture green disc those are nothing but the three replicas after",
    "start": "1838660",
    "end": "1844000"
  },
  {
    "text": "persistent volume that my sequels will provision these three reps replicas are",
    "start": "1844000",
    "end": "1849250"
  },
  {
    "text": "synchronously replicated what does that mean that means it gives a hype high",
    "start": "1849250",
    "end": "1855400"
  },
  {
    "text": "ability after volume or data store on to this replicas for a my sequel to",
    "start": "1855400",
    "end": "1861100"
  },
  {
    "text": "failover in the instances ask the node going down or if the application my",
    "start": "1861100",
    "end": "1867490"
  },
  {
    "text": "sequel instance itself goes down because of some reason now the mi di layer also",
    "start": "1867490",
    "end": "1875350"
  },
  {
    "text": "provides a way to take the snapshots of these replicas because these replicas",
    "start": "1875350",
    "end": "1881230"
  },
  {
    "text": "are synchro a synchronously replicated you can use either of the replicas to take a snapshot into given a time trip",
    "start": "1881230",
    "end": "1888340"
  },
  {
    "text": "and these snapshots can also be used to back up into the third-party backup",
    "start": "1888340",
    "end": "1893890"
  },
  {
    "text": "storage like NFS or AWS now these backup can also be used in future to restore",
    "start": "1893890",
    "end": "1901300"
  },
  {
    "text": "onto a given volume also to create a new volume for log Analytics or any further",
    "start": "1901300",
    "end": "1907450"
  },
  {
    "text": "held analytics that that end user wants to do it now let's go ahead and",
    "start": "1907450",
    "end": "1916390"
  },
  {
    "text": "physically I'll go ahead and deploy this instance or the WordPress instance so",
    "start": "1916390",
    "end": "1926800"
  },
  {
    "text": "first I will go ahead and login to the cluster that we'll be using it to do a to the demo so as I mentioned before it",
    "start": "1926800",
    "end": "1935110"
  },
  {
    "text": "is a three node cluster using a four note but fourth node is using as a",
    "start": "1935110",
    "end": "1940330"
  },
  {
    "text": "standby right now we'll use this fourth node into the later part of the demo so",
    "start": "1940330",
    "end": "1945550"
  },
  {
    "text": "we'll go ahead and mainly use the three nodes of the cluster using to see allies",
    "start": "1945550",
    "end": "1953380"
  },
  {
    "text": "here one is the cube city which is open source kubernetes CLI which gives you third details from the queue bonitas",
    "start": "1953380",
    "end": "1960790"
  },
  {
    "text": "clusters time point and there is another CLI here as a dcpl CLI which is a DM Aunty infrastructure level",
    "start": "1960790",
    "end": "1967480"
  },
  {
    "text": "CLI which gives you the more awareness from the infrastructure force and",
    "start": "1967480",
    "end": "1972639"
  },
  {
    "text": "resource pooling standpoint so here you will be seeing more information from the platform standpoint like Malik Malik or",
    "start": "1972639",
    "end": "1979450"
  },
  {
    "text": "memory provided on to are available on to the server storage and remix which",
    "start": "1979450",
    "end": "1985509"
  },
  {
    "text": "also underneath infrastructure level resources that can be used to schedule a specific workload on to a given node now",
    "start": "1985509",
    "end": "1994929"
  },
  {
    "text": "let's go ahead and deploy the WordPress application here we are have three ml",
    "start": "1994929",
    "end": "2000659"
  },
  {
    "text": "specs one first one is nothing but a my sequel password so we have created a",
    "start": "2000659",
    "end": "2005909"
  },
  {
    "text": "secret for it my sequel deployment and WordPress will be deployed as a stateful set let's go ahead and create a secret",
    "start": "2005909",
    "end": "2016470"
  },
  {
    "text": "and deploy or my sequel deployment instance now let's look at into the",
    "start": "2016470",
    "end": "2023309"
  },
  {
    "text": "details of what is the pod spec looks like so if you remember from the our",
    "start": "2023309",
    "end": "2029639"
  },
  {
    "text": "pictorial way how the storage is going to be provision we have mentioned that we will be using a dynamic provision and",
    "start": "2029639",
    "end": "2036269"
  },
  {
    "text": "we'll use a storage class that is Pro construct that is provided by the Kuban",
    "start": "2036269",
    "end": "2041370"
  },
  {
    "text": "a test to provision that storage or perturbation the volume onto the Diamanti here it says that storage class",
    "start": "2041370",
    "end": "2048898"
  },
  {
    "text": "we'll be using is a mirror that means we will go ahead let's look at the what is this some mirrored storage class looks",
    "start": "2048899",
    "end": "2055740"
  },
  {
    "text": "like so here as we see we will be using and underneath a DM on T of volume",
    "start": "2055740",
    "end": "2062040"
  },
  {
    "text": "probationer and this probationer is aware of these parameters these means we",
    "start": "2062040",
    "end": "2068190"
  },
  {
    "text": "need three replicas on to a given cluster wherever we whenever we provision the storage the filesystem it",
    "start": "2068190",
    "end": "2075329"
  },
  {
    "text": "will be using is the ext4 filesystem and this is the performance tier or guaranteed to us that it requires is a",
    "start": "2075329",
    "end": "2082108"
  },
  {
    "text": "best-effort based we'll go into the details after different performance tiers that you can",
    "start": "2082109",
    "end": "2088378"
  },
  {
    "text": "provision on to the infrastructure and how we are able to give the i/o isolation in guaranteed QSR into the",
    "start": "2088379",
    "end": "2094270"
  },
  {
    "text": "later section of the demo now let's go",
    "start": "2094270",
    "end": "2099340"
  },
  {
    "text": "ahead and deploy the WordPress stateful set now once the application of right",
    "start": "2099340",
    "end": "2107890"
  },
  {
    "text": "now we have my sequel instances turning so this is the WordPress my sequel instance that we deployed and we had",
    "start": "2107890",
    "end": "2114520"
  },
  {
    "text": "requested that we needed a three-way mirrored volume or mirrored replicas for a given my sequel instance to be",
    "start": "2114520",
    "end": "2121810"
  },
  {
    "text": "deployed now if we zoom in into this volume which was dynamically provisioned",
    "start": "2121810",
    "end": "2127000"
  },
  {
    "text": "we will see that it has provision or 3-way map replicas on two or three",
    "start": "2127000",
    "end": "2132490"
  },
  {
    "text": "different nodes of the cluster and these all replicas are synchronously",
    "start": "2132490",
    "end": "2137560"
  },
  {
    "text": "replicated so that means every right will happen to the my sequel instance will be replicated onto all plexus are",
    "start": "2137560",
    "end": "2146230"
  },
  {
    "text": "all replicas of this a provision or persistent volume now let's take a look",
    "start": "2146230",
    "end": "2154660"
  },
  {
    "text": "at the pod speed so sv deployed one my sequel instance it is into a running",
    "start": "2154660",
    "end": "2160570"
  },
  {
    "text": "state it is running into the node 1 and we have three instances of the WordPress",
    "start": "2160570",
    "end": "2165609"
  },
  {
    "text": "stateful site running because we have three node cluster and we had requested for the three replicas so we have all",
    "start": "2165609",
    "end": "2171580"
  },
  {
    "text": "three instances off the replicas running on to the three different nodes of the cluster now let's go ahead and in this",
    "start": "2171580",
    "end": "2183940"
  },
  {
    "text": "section we'll go ahead and deploy a KBM instance which can be used to run the",
    "start": "2183940",
    "end": "2190000"
  },
  {
    "text": "yet-to-be containerized application on to the same queue bonitas cluster this",
    "start": "2190000",
    "end": "2195310"
  },
  {
    "text": "gives us a view on how you are able to deploy the same how we are able to use",
    "start": "2195310",
    "end": "2202300"
  },
  {
    "text": "the same node and also deploy the containerized workload along with the KBM workload here I'll just give before",
    "start": "2202300",
    "end": "2210130"
  },
  {
    "text": "we go ahead and deploy it I'll just give a little little bit deeper view into how we are able to achieve that and how we",
    "start": "2210130",
    "end": "2216550"
  },
  {
    "text": "are able to use the same infrastructure to deploy both of KVM workload along",
    "start": "2216550",
    "end": "2222220"
  },
  {
    "text": "with the container workload so and high-level if you are aware of the",
    "start": "2222220",
    "end": "2228870"
  },
  {
    "text": "q''-word project the design is very much similar to the Q part where the",
    "start": "2228870",
    "end": "2234210"
  },
  {
    "text": "philosophy is we want to run a key VM inside a container so they can coexist",
    "start": "2234210",
    "end": "2239910"
  },
  {
    "text": "on to the same infrastructure along with the container workload in this we are",
    "start": "2239910",
    "end": "2246600"
  },
  {
    "text": "using a premium as an this our solution is based off the KVM hypervisor now",
    "start": "2246600",
    "end": "2251850"
  },
  {
    "text": "looks like the KVM is becoming a default runtime manager for deploying the VN",
    "start": "2251850",
    "end": "2257930"
  },
  {
    "text": "nowadays like Google is using it AWS nitro cards are also supporting the kvms",
    "start": "2257930",
    "end": "2263640"
  },
  {
    "text": "at hypervisor to apply the VM we will use the same humanities Orchestrator",
    "start": "2263640",
    "end": "2270120"
  },
  {
    "text": "to deploy the V ends the same wave it deploys the container workload and so",
    "start": "2270120",
    "end": "2276630"
  },
  {
    "text": "based on the because of the HCI and by F offloading the network and the storage",
    "start": "2276630",
    "end": "2281700"
  },
  {
    "text": "resources we are able to achieve the consistent IO isolation and quality of",
    "start": "2281700",
    "end": "2287040"
  },
  {
    "text": "service for the both containers and the VM workload using the PCI pass-through",
    "start": "2287040",
    "end": "2292830"
  },
  {
    "text": "mechanism so here in the diagram you are seeing two - Nick components or one as a",
    "start": "2292830",
    "end": "2300840"
  },
  {
    "text": "tonight VF and another one as an nvme V F so every application or every every",
    "start": "2300840",
    "end": "2307860"
  },
  {
    "text": "container or every VM which gets probation on to the HCI or dr. diamante",
    "start": "2307860",
    "end": "2313080"
  },
  {
    "text": "x-ray out adapter it gets in its own isolated or its own isolated vs / a",
    "start": "2313080",
    "end": "2319980"
  },
  {
    "text": "container or the Pearl VM so here let's say if the VM requires a network and the",
    "start": "2319980",
    "end": "2326610"
  },
  {
    "text": "storage resource both of them both of them will get its own Silv function for",
    "start": "2326610",
    "end": "2332400"
  },
  {
    "text": "be at a fork network and the storage so this gives you a way of provisioning or",
    "start": "2332400",
    "end": "2339780"
  },
  {
    "text": "make a consistent way of getting an isolation and also guaranteed QoS for a",
    "start": "2339780",
    "end": "2345990"
  },
  {
    "text": "given application or for a given VM instance now this is a little more",
    "start": "2345990",
    "end": "2353190"
  },
  {
    "start": "2351000",
    "end": "2483000"
  },
  {
    "text": "technical I won't go into each and every component detail but this is kind of a high level picture which gives you the",
    "start": "2353190",
    "end": "2360170"
  },
  {
    "text": "details on how the same code path or same Cuba Cuba needed orchestration can",
    "start": "2360170",
    "end": "2366800"
  },
  {
    "text": "be used to deploy the power pot container or a VM instance onto the same",
    "start": "2366800",
    "end": "2372950"
  },
  {
    "text": "infrastructure so here there are two workflows which are drawn one the orange",
    "start": "2372950",
    "end": "2378890"
  },
  {
    "text": "one is a part of the regular container native workload and the red one is the",
    "start": "2378890",
    "end": "2384230"
  },
  {
    "text": "KVM deployment workload so if we say VM deployment is here in this case is",
    "start": "2384230",
    "end": "2390350"
  },
  {
    "text": "actually implemented using of Cuban itis construct called CI these custom",
    "start": "2390350",
    "end": "2395540"
  },
  {
    "text": "resource definition so kvn objects are exposed as a custom resource definition",
    "start": "2395540",
    "end": "2401960"
  },
  {
    "text": "on to this Cuban it is cluster so whenever a KBM object gets created the",
    "start": "2401960",
    "end": "2408380"
  },
  {
    "text": "custom controller kvn controller which is in the green component underneath the API servers will wash onto those",
    "start": "2408380",
    "end": "2415220"
  },
  {
    "text": "instances and it will act on it here we are seeing other components like",
    "start": "2415220",
    "end": "2421520"
  },
  {
    "text": "scheduler Network Controller x2h controller so whether you probation or",
    "start": "2421520",
    "end": "2427040"
  },
  {
    "text": "better you will deploy a container all your deploy of VM underneath all the",
    "start": "2427040",
    "end": "2432680"
  },
  {
    "text": "green components will be used in a similar manner it is there they are both",
    "start": "2432680",
    "end": "2439850"
  },
  {
    "text": "same in case of provisioning the storage or network for the container or the VM the code part will remain same this",
    "start": "2439850",
    "end": "2446930"
  },
  {
    "text": "gives us the benefit of having the same features like storage classes dynamic",
    "start": "2446930",
    "end": "2452720"
  },
  {
    "text": "provisions was static provisioning for the storage and network to be exercised",
    "start": "2452720",
    "end": "2457790"
  },
  {
    "text": "for both pod and the KVM workloads so if you see at the end on the right hand",
    "start": "2457790",
    "end": "2464300"
  },
  {
    "text": "side the containers and the vient are running next to each other they can",
    "start": "2464300",
    "end": "2469580"
  },
  {
    "text": "coexist onto the same infrastructure just because we are able to extend the Kuban it is to deploy the VM and the",
    "start": "2469580",
    "end": "2477590"
  },
  {
    "text": "container workload onto the same infrastructure now this is the pictural",
    "start": "2477590",
    "end": "2485420"
  },
  {
    "start": "2483000",
    "end": "2991000"
  },
  {
    "text": "view of how we will how I will go ahead and deploy the kvn so if you remember from the first demo",
    "start": "2485420",
    "end": "2491790"
  },
  {
    "text": "we had deployed a my sequel and one of the wordpress instance was running into",
    "start": "2491790",
    "end": "2496800"
  },
  {
    "text": "the node one in this demo i will go ahead and deploy a KVM instance onto the",
    "start": "2496800",
    "end": "2502260"
  },
  {
    "text": "same node just to demonstrate that you can you are able to deploy pub KVM and",
    "start": "2502260",
    "end": "2509250"
  },
  {
    "text": "container workload onto the same node of the same kubernetes cluster underneath",
    "start": "2509250",
    "end": "2515430"
  },
  {
    "text": "io layer is exactly the same the way we will provision in this case i will take",
    "start": "2515430",
    "end": "2521490"
  },
  {
    "text": "an example of provisioning the persistent storage using us static provisioning just to showcase the static",
    "start": "2521490",
    "end": "2527880"
  },
  {
    "text": "provision onto the cabinet is cluster for the KVN and you can still use the same storage features like mirroring",
    "start": "2527880",
    "end": "2535850"
  },
  {
    "text": "synchronous replication snapshots and also taking a backup of these snapshots",
    "start": "2535850",
    "end": "2541410"
  },
  {
    "text": "and restoring this back up into the persistent volume so as I mentioned we",
    "start": "2541410",
    "end": "2552510"
  },
  {
    "text": "have extended the kids kubernetes CR DS to support octavian as a primary object",
    "start": "2552510",
    "end": "2558750"
  },
  {
    "text": "onto the cluster so this is the KPM IRC ID and this is the custom JVM controller",
    "start": "2558750",
    "end": "2566250"
  },
  {
    "text": "that we have written to watch on to the k vm c ID is being created on to the",
    "start": "2566250",
    "end": "2571980"
  },
  {
    "text": "Kuban it is cluster and then take on or take an action on it so when we talk",
    "start": "2571980",
    "end": "2580260"
  },
  {
    "text": "about VN there are two things comes into our mind the first is how we cannot do",
    "start": "2580260",
    "end": "2586350"
  },
  {
    "text": "the boot image management how how it will be able to pull the images to boot",
    "start": "2586350",
    "end": "2592350"
  },
  {
    "text": "the VM Samet so in this example we'll use a web server based management folder",
    "start": "2592350",
    "end": "2598530"
  },
  {
    "text": "boot images so I've just deployed an engine X web server onto the same cluster which is hosting or CentOS 7",
    "start": "2598530",
    "end": "2605970"
  },
  {
    "text": "dots for Q cow image for VM to boot from so this is the nginx web server which",
    "start": "2605970",
    "end": "2614160"
  },
  {
    "text": "will be hosting the Centaurs Keuka image and this is how the KVM pod spec will",
    "start": "2614160",
    "end": "2620820"
  },
  {
    "text": "look like as you can see it is same as the part but except the baby provisions the",
    "start": "2620820",
    "end": "2627750"
  },
  {
    "text": "network is using an annotation and it will use underneath our CNI plug the",
    "start": "2627750",
    "end": "2633359"
  },
  {
    "text": "same way and I plug in to provision the network onto the same infrastructure",
    "start": "2633359",
    "end": "2638420"
  },
  {
    "text": "this is a static color endpoint because for the PM's you want to make sure the",
    "start": "2638420",
    "end": "2644010"
  },
  {
    "text": "IP addresses which are allocated once they persist for reboot or redeployment",
    "start": "2644010",
    "end": "2649980"
  },
  {
    "text": "of the same instances or in case of node failures or zone failures onto the same",
    "start": "2649980",
    "end": "2655320"
  },
  {
    "text": "kubernetes cluster so end user doesn't have to worry about IP address changes and node configuration changes and",
    "start": "2655320",
    "end": "2662310"
  },
  {
    "text": "things like that as I mentioned before we are using a webserver base of pulling",
    "start": "2662310",
    "end": "2669119"
  },
  {
    "text": "the image so this is the HTTP endpoint from where the sent os7 dots forth Q",
    "start": "2669119",
    "end": "2674430"
  },
  {
    "text": "curve image will be pulled and booted it will be used for VM boot up this is the",
    "start": "2674430",
    "end": "2682140"
  },
  {
    "text": "way we are able to expose the reserve the resources for a VM instance the",
    "start": "2682140",
    "end": "2688619"
  },
  {
    "text": "number of CPU cores that we'll be using is 16 and memory will request it for 32",
    "start": "2688619",
    "end": "2695070"
  },
  {
    "text": "gig of memory today there are two ways to access the terminal our serial",
    "start": "2695070",
    "end": "2701609"
  },
  {
    "text": "console they are itself a graphical VNC a remote control way of for graphical",
    "start": "2701609",
    "end": "2707190"
  },
  {
    "text": "remote control way of accessing the VM this is just the index for it to use it for which index to use for the graphical",
    "start": "2707190",
    "end": "2714090"
  },
  {
    "text": "VNC index and here these are all the same volume constant that you would",
    "start": "2714090",
    "end": "2719700"
  },
  {
    "text": "persist and volume constant that you would see it into a container regular container or regular spots back here you",
    "start": "2719700",
    "end": "2726930"
  },
  {
    "text": "there are two persistent volumes we have specified a one as a volume images and",
    "start": "2726930",
    "end": "2732119"
  },
  {
    "text": "another one is a data volume which is a volume one so volume images is the persistent",
    "start": "2732119",
    "end": "2740190"
  },
  {
    "text": "volume that I will use to persistently save the configuration or the boot image",
    "start": "2740190",
    "end": "2745609"
  },
  {
    "text": "so the reason we want to use the persistent volume is once the VM is boot",
    "start": "2745609",
    "end": "2751470"
  },
  {
    "text": "booted if the end user is making any configuration changes like it is making any changes in two hours",
    "start": "2751470",
    "end": "2757770"
  },
  {
    "text": "without local or the way the application should start once the VMs booted you",
    "start": "2757770",
    "end": "2763440"
  },
  {
    "text": "want to keep those configuration changes persistent on to the persistent volume to make sure that they are persisted",
    "start": "2763440",
    "end": "2770100"
  },
  {
    "text": "across reboot their persisted if the KVM instance moves from one node to another",
    "start": "2770100",
    "end": "2776400"
  },
  {
    "text": "node or it moves from one zone to another zone this volume two is the",
    "start": "2776400",
    "end": "2783210"
  },
  {
    "text": "volume one is the data volume this volume is exposed as a PCI pass-through",
    "start": "2783210",
    "end": "2788850"
  },
  {
    "text": "inside the VM and we are using a block device as an SS type and this support",
    "start": "2788850",
    "end": "2795810"
  },
  {
    "text": "was added into the Flex volume to make sure that we are able to do the PCI pass-through for a storage persistent",
    "start": "2795810",
    "end": "2802470"
  },
  {
    "text": "volume storage and also able to get the guaranteed QoS and iOS relation for the VM instances same way we are able to get",
    "start": "2802470",
    "end": "2809820"
  },
  {
    "text": "it for the container workload now we'll",
    "start": "2809820",
    "end": "2814980"
  },
  {
    "text": "go ahead and deploy the k vm instance using the same pot spec let's go ahead",
    "start": "2814980",
    "end": "2820920"
  },
  {
    "text": "and provision the endpoint which is the EP one and as i mentioned will provision",
    "start": "2820920",
    "end": "2827370"
  },
  {
    "text": "the storage with the static provisioning so we'll use a back-end CLI to create a",
    "start": "2827370",
    "end": "2832560"
  },
  {
    "text": "persistent volume this is a volume image one is the persistent volume for storing",
    "start": "2832560",
    "end": "2838080"
  },
  {
    "text": "the boot image and this is our block volume which will be exposed as a PCI",
    "start": "2838080",
    "end": "2845280"
  },
  {
    "text": "pass-through device these are the two",
    "start": "2845280",
    "end": "2851790"
  },
  {
    "text": "volumes that we just statically provisioned onto the cluster and both of them be provisioned on to the node 1",
    "start": "2851790",
    "end": "2857760"
  },
  {
    "text": "where the WordPress and my sequel instances are running let's go ahead and",
    "start": "2857760",
    "end": "2865020"
  },
  {
    "text": "create the PvP VCS to bound binders volumes and now we'll go ahead and",
    "start": "2865020",
    "end": "2873300"
  },
  {
    "text": "deploy the TVM instance now as we see the KVM instance is",
    "start": "2873300",
    "end": "2880900"
  },
  {
    "text": "created under the kV MC IDs and now custom KVM controller would have created",
    "start": "2880900",
    "end": "2887860"
  },
  {
    "text": "the KVM pod for the given CI a given K VM instance that we created here as we",
    "start": "2887860",
    "end": "2893890"
  },
  {
    "text": "see that same k vm instance we deployed it on to the same node where we have one of the wordpress instances running and",
    "start": "2893890",
    "end": "2901060"
  },
  {
    "text": "also the my sequel instance is running",
    "start": "2901060",
    "end": "2905520"
  },
  {
    "text": "now this is the IP address got attached or it was reserved for a given k vm",
    "start": "2907980",
    "end": "2913690"
  },
  {
    "text": "instance as you can see it is underneath using an SRO BBF for this given instance",
    "start": "2913690",
    "end": "2921510"
  },
  {
    "text": "and these are the two storage wall these are the two persistent volumes that got",
    "start": "2921510",
    "end": "2928030"
  },
  {
    "text": "assigned for a VM instance and as you can see the first one wall one one was",
    "start": "2928030",
    "end": "2933400"
  },
  {
    "text": "the block device so there is no device path will exist onto the host because we are doing a PCI pass-through and in that",
    "start": "2933400",
    "end": "2941140"
  },
  {
    "text": "case host will not see this piece a device on the host and it will be passed directly inside the VM and second",
    "start": "2941140",
    "end": "2948490"
  },
  {
    "text": "instance we are using for persistently saving the boot image now Alexis using a",
    "start": "2948490",
    "end": "2959830"
  },
  {
    "text": "serial console to the VM and as you can see you are able to log into the KVM",
    "start": "2959830",
    "end": "2965800"
  },
  {
    "text": "instance packages deployed and we will",
    "start": "2965800",
    "end": "2971680"
  },
  {
    "text": "able to see the same IP addresses being configured inside the VM further interface that we've exposed as a PCI",
    "start": "2971680",
    "end": "2978550"
  },
  {
    "text": "pass-through device",
    "start": "2978550",
    "end": "2981420"
  },
  {
    "start": "2991000",
    "end": "3019000"
  },
  {
    "text": "okay now we will move on to the next demo which is the last demo of this",
    "start": "2991050",
    "end": "2996240"
  },
  {
    "text": "section we would like to do and I'd like to do showcase the IO isolation with us",
    "start": "2996240",
    "end": "3001520"
  },
  {
    "text": "for performance which showcases the benefits of offloading of both Network",
    "start": "3001520",
    "end": "3008600"
  },
  {
    "text": "and storage to the hardware and how you can get the guaranteed or QoS or guaranteed performance for a given",
    "start": "3008600",
    "end": "3015650"
  },
  {
    "text": "container or a VM workload so in this demo so we have four node cluster",
    "start": "3015650",
    "end": "3022520"
  },
  {
    "start": "3019000",
    "end": "3224000"
  },
  {
    "text": "I just uncoordinated to take advantage of using a four node cluster and I would",
    "start": "3022520",
    "end": "3028850"
  },
  {
    "text": "try to deploy I would try to dedicate a node one for all the KVM instances deployment so we just use the same",
    "start": "3028850",
    "end": "3036560"
  },
  {
    "text": "kubernetes construct to label the node for the KVM deployment just to make sure that you are all the KBM instances that",
    "start": "3036560",
    "end": "3044090"
  },
  {
    "text": "we deploy on to the cluster only goes on to the node one and all the container workloads we will dedicate on the node",
    "start": "3044090",
    "end": "3051200"
  },
  {
    "text": "two three and four here we will basically deploy around 27 containers",
    "start": "3051200",
    "end": "3059090"
  },
  {
    "text": "across three nodes and nine KVM instances on node one and we will see",
    "start": "3059090",
    "end": "3064460"
  },
  {
    "text": "how we are able to guarantee the i/o isolation and also the performance for a",
    "start": "3064460",
    "end": "3070310"
  },
  {
    "text": "given workload KVM or a container workload using a hardware offload for network and storage so we just unguarded",
    "start": "3070310",
    "end": "3082820"
  },
  {
    "text": "the 1/4 node into the cluster so we have a four node cluster here we want to take",
    "start": "3082820",
    "end": "3092570"
  },
  {
    "text": "we want to demonstrate to use our usage of a performance fear and guaranteed io",
    "start": "3092570",
    "end": "3098840"
  },
  {
    "text": "isolation and the performance for the container and VM workload so we have divided tub webs were deployed at three",
    "start": "3098840",
    "end": "3107150"
  },
  {
    "text": "performance tiers here one is a best-effort high-end medium as you can see there reserved or storage I ops for",
    "start": "3107150",
    "end": "3116150"
  },
  {
    "text": "bicipital zero and network bandwidth is zero that means if a system has system have any two gifts they will get",
    "start": "3116150",
    "end": "3123130"
  },
  {
    "text": "some storage I of the network bandwidth based on the best effort hi is going to",
    "start": "3123130",
    "end": "3128980"
  },
  {
    "text": "get the maximum which is 20 K and 500 Meg and medium is the next level which",
    "start": "3128980",
    "end": "3135069"
  },
  {
    "text": "is 5 K + 125 Meg you can still use the same constructs to get the maximum to",
    "start": "3135069",
    "end": "3143140"
  },
  {
    "text": "limit the maximum storage I ops and maximum network bandwidth also but in this case we'll just will demonstrate",
    "start": "3143140",
    "end": "3149589"
  },
  {
    "text": "the mint requirement so these are the way of setting the mint requirements for a given workload I'll use this tree or",
    "start": "3149589",
    "end": "3158349"
  },
  {
    "text": "performance tiers and deployed or three instances of KVM using a best-effort",
    "start": "3158349",
    "end": "3163569"
  },
  {
    "text": "three instances of KVM using a high and other three using a medium on to the",
    "start": "3163569",
    "end": "3169869"
  },
  {
    "text": "node 1 so let's go ahead and label the",
    "start": "3169869",
    "end": "3175450"
  },
  {
    "text": "first node as a type kb n and make sure that we use the same k kb m node label",
    "start": "3175450",
    "end": "3181900"
  },
  {
    "text": "to deploy all the k vm workloads here",
    "start": "3181900",
    "end": "3187869"
  },
  {
    "text": "the node is label as a kb m here in this",
    "start": "3187869",
    "end": "3198700"
  },
  {
    "text": "we are deploying on nine instances of k vm which will be getting deployed on to",
    "start": "3198700",
    "end": "3204460"
  },
  {
    "text": "the node 1 which we labeled as a KVM node as we see there are nine instances",
    "start": "3204460",
    "end": "3214000"
  },
  {
    "text": "of k vm c ids we deployed and let's take a look at the container states as we can",
    "start": "3214000",
    "end": "3219730"
  },
  {
    "text": "see the nine instances are going into the container creating state I'll just",
    "start": "3219730",
    "end": "3225790"
  },
  {
    "start": "3224000",
    "end": "3600000"
  },
  {
    "text": "show case a another I'll just show case",
    "start": "3225790",
    "end": "3232390"
  },
  {
    "text": "or you the dashboard which we can your which we can see to the applications or",
    "start": "3232390",
    "end": "3239920"
  },
  {
    "text": "KVM instances that con deployed also this is the dashboard from the infrastructure standpoint here this is",
    "start": "3239920",
    "end": "3248170"
  },
  {
    "text": "the application tab will be able to see it",
    "start": "3248170",
    "end": "3252779"
  },
  {
    "text": "I'm just logged out I'll just log into the node",
    "start": "3254910",
    "end": "3261060"
  },
  {
    "text": "okay well it is coming up let's go ahead and we'll deploy the regular FIO and",
    "start": "3265960",
    "end": "3271839"
  },
  {
    "text": "iperf benchmarking containers onto the same infrastructure so here we'll deploy",
    "start": "3271839",
    "end": "3278440"
  },
  {
    "text": "a twenty seven instances of sio benchmarking and ipok benchmarking pots",
    "start": "3278440",
    "end": "3285160"
  },
  {
    "text": "across three nodes of the cluster okay",
    "start": "3285160",
    "end": "3296740"
  },
  {
    "text": "so here is the way we are able to look at the different applications let's go",
    "start": "3296740",
    "end": "3302500"
  },
  {
    "text": "and take a look at them good while the other container workload is coming up as we see we hide deployed",
    "start": "3302500",
    "end": "3309970"
  },
  {
    "text": "ok VM instances on to the node one of the cluster here as we can see because",
    "start": "3309970",
    "end": "3315520"
  },
  {
    "text": "of the hardware offload network and storage hardware offload your we are able to get a 1 million iOS or more than",
    "start": "3315520",
    "end": "3323230"
  },
  {
    "text": "a million I have forgiven node and we are also able to get a network",
    "start": "3323230",
    "end": "3329680"
  },
  {
    "text": "throughput if you see a title in this case we are not running victim is not running any network traffic it is only",
    "start": "3329680",
    "end": "3335710"
  },
  {
    "text": "running a storage traffic so you'll be only seeing the storage iOS and which is close to a million you are able to get",
    "start": "3335710",
    "end": "3342040"
  },
  {
    "text": "it just because of the hardware offload for the storage as we see the all parts",
    "start": "3342040",
    "end": "3347560"
  },
  {
    "text": "of these containers yes here we see a 9 k vm instances that we deployed using a",
    "start": "3347560",
    "end": "3353140"
  },
  {
    "text": "different performance tiers a3 with best-effort 3 with medium and 3 with high now let's look at the other",
    "start": "3353140",
    "end": "3361330"
  },
  {
    "text": "instances that we deployed will filter onto a specific node to see a container",
    "start": "3361330",
    "end": "3368050"
  },
  {
    "text": "workload so here are this here are the",
    "start": "3368050",
    "end": "3374470"
  },
  {
    "text": "three container workload for the s io which is nothing but a storage benchmarking application i first which",
    "start": "3374470",
    "end": "3382150"
  },
  {
    "text": "is a network I personal benchmarking tool as you can it is still coming up",
    "start": "3382150",
    "end": "3388859"
  },
  {
    "text": "once the application is fully able to drive the traffic we will see a dial see",
    "start": "3388859",
    "end": "3395770"
  },
  {
    "text": "the numbers in such a manner high workload will be getting the maximum i/o salable on to the node right",
    "start": "3395770",
    "end": "3405030"
  },
  {
    "text": "of next will next year will be the medium and after that will be the best effort so here as we can see we are able",
    "start": "3405030",
    "end": "3415260"
  },
  {
    "text": "to see 240 K iOS and I'll go ahead and enable a performance tier to show that",
    "start": "3415260",
    "end": "3423839"
  },
  {
    "text": "that was the performance tier and along with the read and write latency to see",
    "start": "3423839",
    "end": "3428849"
  },
  {
    "text": "how much latencies we are able to gain for a given specific of performance fear",
    "start": "3428849",
    "end": "3434790"
  },
  {
    "text": "workload so as we can see here all the high workload are around the under 500",
    "start": "3434790",
    "end": "3441450"
  },
  {
    "text": "microseconds latency there around 480 microsecond latency for a read workload",
    "start": "3441450",
    "end": "3446580"
  },
  {
    "text": "and as we can see here they are in turn all of them are about to get 260 ki off",
    "start": "3446580",
    "end": "3454099"
  },
  {
    "text": "we have a best-effort which are running around the 16th i/o with a higher latency because a view will be make",
    "start": "3454099",
    "end": "3462510"
  },
  {
    "text": "giving the high priority to the high workload the hardware is giving the high priority for the high workload which",
    "start": "3462510",
    "end": "3468810"
  },
  {
    "text": "requires the maximum i/o and the next is a medium which is getting a 66 ki ox and",
    "start": "3468810",
    "end": "3475320"
  },
  {
    "text": "with the 1.9 millisecond latency this is",
    "start": "3475320",
    "end": "3481109"
  },
  {
    "text": "the same behavior we will see on to the other nodes where we deployed it so here as you can see all three best-effort are",
    "start": "3481109",
    "end": "3488220"
  },
  {
    "text": "into their own range with high it getting the maximum and then the medium",
    "start": "3488220",
    "end": "3493440"
  },
  {
    "text": "into the next category",
    "start": "3493440",
    "end": "3496220"
  },
  {
    "text": "so yeah this is what I had from the demo standpoint now Phil we can wrap it up",
    "start": "3502140",
    "end": "3510910"
  },
  {
    "text": "with the Q&A Thank You Vera so there was a few questions that came",
    "start": "3510910",
    "end": "3517900"
  },
  {
    "text": "through the Q&A Channel on zoom' we have entered all of those questions feel free",
    "start": "3517900",
    "end": "3523900"
  },
  {
    "text": "to if you have any more questions you know feel free to plug them in now or",
    "start": "3523900",
    "end": "3529450"
  },
  {
    "text": "let's roll to the next one on the top of the hour",
    "start": "3529450",
    "end": "3536369"
  },
  {
    "text": "all right so if you'd like to learn more about diamonte go to diamonte comm email",
    "start": "3539009",
    "end": "3545589"
  },
  {
    "text": "us at info at the MRT comm or follow us on twitter at be Amati calm or we're",
    "start": "3545589",
    "end": "3550809"
  },
  {
    "text": "also on LinkedIn so in closing thank you for your time we appreciate it a lot hope we were able to share some insights",
    "start": "3550809",
    "end": "3558009"
  },
  {
    "text": "from the industry so in closing diamonte is an enterprise kubernetes platform with hardware",
    "start": "3558009",
    "end": "3564910"
  },
  {
    "text": "offloads based on you know cim quartz-based chipsets it's a full stack",
    "start": "3564910",
    "end": "3571299"
  },
  {
    "text": "solution is hardware and software prepackaged with open source kubernetes with million i ops for one ru and sub",
    "start": "3571299",
    "end": "3579009"
  },
  {
    "text": "one at 100 millisecond latency check out our website for all the use cases solutions of course also plan to attend",
    "start": "3579009",
    "end": "3587949"
  },
  {
    "text": "coop con we'll see you there and you can expect more from us coop con",
    "start": "3587949",
    "end": "3593319"
  },
  {
    "text": "so until then have a great day back to you Kim thank you all",
    "start": "3593319",
    "end": "3603180"
  }
]
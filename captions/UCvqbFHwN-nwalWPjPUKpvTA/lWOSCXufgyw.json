[
  {
    "text": "this is probably the closest we're going to get to a signet work the movie this conference so we're gonna start off with",
    "start": "30",
    "end": "5130"
  },
  {
    "text": "a introductory session so if you want to learn more about the network stack in kubernetes and how it fits together this",
    "start": "5130",
    "end": "12599"
  },
  {
    "text": "is a good place I'm going to step through a walkthrough of kind of the base components take maybe a couple",
    "start": "12599",
    "end": "19439"
  },
  {
    "text": "quick questions around each one then move on to the next we're around halfway through the session we're going to switch to a deep dive which is more",
    "start": "19439",
    "end": "24779"
  },
  {
    "text": "focused on some of the recent and ongoing work and we're going to have contributors speaking to what they've",
    "start": "24779",
    "end": "30539"
  },
  {
    "text": "been doing and what we're kind of planning for the next year or so down the line so for a mile away is Sigma",
    "start": "30539",
    "end": "38280"
  },
  {
    "text": "Network it's just responsible for the networking related things in the cluster this translates into a whole lot of",
    "start": "38280",
    "end": "45360"
  },
  {
    "text": "things we own a bunch of components individual controllers we own api's we",
    "start": "45360",
    "end": "51390"
  },
  {
    "text": "own specs so things like CNI drivers we are trying to not maintain any I think",
    "start": "51390",
    "end": "57360"
  },
  {
    "text": "there's one that's being deprecated but we maintain a specification of what is the CNI how does it work how should the",
    "start": "57360",
    "end": "63899"
  },
  {
    "text": "drivers work and then we owned many fuzzier logistics such as just how does",
    "start": "63899",
    "end": "69150"
  },
  {
    "text": "the traffic move around in the cluster how the networking related things in the control plane work and so on so let's go",
    "start": "69150",
    "end": "77310"
  },
  {
    "text": "through our walkthrough of the components starting from kind of the base of the stack and moving our way up",
    "start": "77310",
    "end": "82380"
  },
  {
    "text": "to the higher level things so first off if we just install a cluster say we're",
    "start": "82380",
    "end": "88770"
  },
  {
    "text": "doing something bare-metal this is what we get we get some pods on nodes and if you go and try to ping google.com",
    "start": "88770",
    "end": "94740"
  },
  {
    "text": "or hit your other pod you can't and that's because you're missing the CNI",
    "start": "94740",
    "end": "100170"
  },
  {
    "text": "driver because there's not one installed by default if you use a distro there might be CNI driver is responsible for",
    "start": "100170",
    "end": "107070"
  },
  {
    "text": "actually handling IP allocation and dealing with routing from thing to thing so the driver is responsible for",
    "start": "107070",
    "end": "113670"
  },
  {
    "text": "managing your IP space pulling down some IP and giving it to a pod and then making sure that some kind of routing",
    "start": "113670",
    "end": "119790"
  },
  {
    "text": "system and rules exist be it like IP tables or eb PF or some kind of cloud system to actually get your packets from",
    "start": "119790",
    "end": "126270"
  },
  {
    "text": "A to B so maybe do we have any quick questions",
    "start": "126270",
    "end": "131610"
  },
  {
    "text": "on the cni and what it does no hands",
    "start": "131610",
    "end": "141890"
  },
  {
    "text": "all right so now that we have the ability to just hit other things in our",
    "start": "142450",
    "end": "147610"
  },
  {
    "text": "cluster that's pretty manual we want to be able to do more than that but also we",
    "start": "147610",
    "end": "154360"
  },
  {
    "text": "need to think about securities so there's a lot of misconceptions I've talked a bit earlier this week about",
    "start": "154360",
    "end": "161380"
  },
  {
    "text": "some of them around what can access what so here's the graph if you've got four pause in two",
    "start": "161380",
    "end": "166750"
  },
  {
    "text": "different namespaces as to what can actually communicate and the answer is literally everything can so even though",
    "start": "166750",
    "end": "174370"
  },
  {
    "text": "we expose nice little pros like short service names within a namespace every",
    "start": "174370",
    "end": "180400"
  },
  {
    "text": "pot IP is accessible from every other pot and that's not ideal we use",
    "start": "180400",
    "end": "187930"
  },
  {
    "text": "something called Network policy to help with this network policy is optional",
    "start": "187930",
    "end": "194080"
  },
  {
    "text": "spec that many CNI drivers support that lets you essentially add firewall rules to your pod to pod interlinks the way",
    "start": "194080",
    "end": "203890"
  },
  {
    "text": "network policies work is by default it fails open so if you have no policies then everything still took me to talk to",
    "start": "203890",
    "end": "210519"
  },
  {
    "text": "everything else as soon as you add any policies we use selectors to point out",
    "start": "210519",
    "end": "216040"
  },
  {
    "text": "positively apply to and specify ingress and egress rules as soon as the pot is selected it's completely shut down",
    "start": "216040",
    "end": "222910"
  },
  {
    "text": "except for any rules so the selector wipes out access and then at that point",
    "start": "222910",
    "end": "228190"
  },
  {
    "text": "any additional rules you apply specifying that pod layer on things like whitelisting to let more specific things",
    "start": "228190",
    "end": "235329"
  },
  {
    "text": "access so in this case we have a denial example all we're doing is we're taking",
    "start": "235329",
    "end": "241750"
  },
  {
    "text": "some pods that match up a and because we're selecting them we're now denying all traffic because we don't have",
    "start": "241750",
    "end": "248109"
  },
  {
    "text": "anything explicitly letting drop again for those who aren't familiar the label",
    "start": "248109",
    "end": "254709"
  },
  {
    "text": "thing is a very very common pattern incriminated internals essentially as a way of reflecting relationships or",
    "start": "254709",
    "end": "261579"
  },
  {
    "text": "pattern matching we have labels on any given thing using just like app is something is a very common but doesn't",
    "start": "261579",
    "end": "268090"
  },
  {
    "text": "have to be app you can use multiple and then whenever we want to reference this such as like a hierarchical relations",
    "start": "268090",
    "end": "274540"
  },
  {
    "text": "we use those same labels and say all pods are all resources that match this",
    "start": "274540",
    "end": "280200"
  },
  {
    "text": "we apply to it so here's a somewhat more",
    "start": "280200",
    "end": "285970"
  },
  {
    "text": "practical example of ingress we're taking a namespace that matches a team selector we're taking a pod selector for",
    "start": "285970",
    "end": "294790"
  },
  {
    "text": "a and we're saying that for B we can Inc us so you can't ingress to B except from",
    "start": "294790",
    "end": "305350"
  },
  {
    "text": "this thing a in this namespace that looks like this this is a much more",
    "start": "305350",
    "end": "310810"
  },
  {
    "text": "realistic well subset of what your service graph likely looks like because they're probably very few things in your",
    "start": "310810",
    "end": "316810"
  },
  {
    "text": "cluster you actually want to expose to everything in the cluster in reality you have some kind of a complicated digraph",
    "start": "316810",
    "end": "323500"
  },
  {
    "text": "of what is actually interacting this is also something that a lot of service",
    "start": "323500",
    "end": "328570"
  },
  {
    "text": "mesh functionality and so on exposes in similar ways so any questions briefly",
    "start": "328570",
    "end": "335800"
  },
  {
    "text": "about network policy",
    "start": "335800",
    "end": "338699"
  },
  {
    "text": "quiet crowd all right so next up is end",
    "start": "342960",
    "end": "348509"
  },
  {
    "text": "points we want to make pot AP is more accessible if you've ever had to manually deal with I have a fleet of VMs",
    "start": "348509",
    "end": "355590"
  },
  {
    "text": "how do I connect to them all you'll understand very well why we want something more than just exposing raw",
    "start": "355590",
    "end": "361919"
  },
  {
    "text": "poppies and points provide two sets of abstractions for us the first one is",
    "start": "361919",
    "end": "368940"
  },
  {
    "text": "just that it's a list so we have one object with a whole bunch of IPs we don't actually have to list all the pods",
    "start": "368940",
    "end": "375630"
  },
  {
    "text": "and scan through them the other thing is it includes the pod health checking and so on so if a pod is not ready it's not",
    "start": "375630",
    "end": "383460"
  },
  {
    "text": "in the endpoints the pot is ready it is in this way we just have suddenly a list",
    "start": "383460",
    "end": "390270"
  },
  {
    "text": "of everything that's ready for traffic that we can then easily consume in our service discovery or used to populate a",
    "start": "390270",
    "end": "396690"
  },
  {
    "text": "load balancer or something else questions about endpoints ok from this",
    "start": "396690",
    "end": "405780"
  },
  {
    "text": "point yep",
    "start": "405780",
    "end": "408440"
  },
  {
    "text": "sorry sorry but that question was when",
    "start": "433020",
    "end": "440670"
  },
  {
    "text": "the controller which is observing let's say an important creative end sees the",
    "start": "440670",
    "end": "446520"
  },
  {
    "text": "creative end does it mean that the port providing that endpoint is in the ready",
    "start": "446520",
    "end": "451950"
  },
  {
    "text": "state it's a guaranteed or controller needs to basically double-check that the",
    "start": "451950",
    "end": "457980"
  },
  {
    "text": "port is in the ready state I'm pretty sure it's when the check is ready but I",
    "start": "457980",
    "end": "464190"
  },
  {
    "text": "would appreciate clarification on that right wrong there there are actually two",
    "start": "464190",
    "end": "470640"
  },
  {
    "text": "lists in the endpoints structure one for ready one for not ready so you don't need to worry about it",
    "start": "470640",
    "end": "476450"
  },
  {
    "text": "thank you another question here I have a",
    "start": "476450",
    "end": "485250"
  },
  {
    "text": "related question on the previous slide we saw the policies yeah so this kind of",
    "start": "485250",
    "end": "491700"
  },
  {
    "text": "structure so who or where is it in force is it in force at the CNI level so we see the podrace creditor it is passed on",
    "start": "491700",
    "end": "498600"
  },
  {
    "text": "but I believe probably the controller doesn't do much about that it just",
    "start": "498600",
    "end": "504960"
  },
  {
    "text": "passes it on to whoever implements the network so that is it handled at the CNI level enforcing the policies or where",
    "start": "504960",
    "end": "512159"
  },
  {
    "text": "are they implemented which level this is enforced by the CNI drivers but because",
    "start": "512160",
    "end": "518159"
  },
  {
    "text": "the network policy is not a mandatory part of conformance not every single",
    "start": "518160",
    "end": "523590"
  },
  {
    "text": "controller does support it but this would often translate into like not making a rule in Google cloud or not",
    "start": "523590",
    "end": "529290"
  },
  {
    "text": "programming and iptables rules if a certain path isn't allowed and there are",
    "start": "529290",
    "end": "534450"
  },
  {
    "text": "also a bunch of third parties that can implement network policy independent of networking so you really need to put",
    "start": "534450",
    "end": "540060"
  },
  {
    "text": "together a comprehensive network plan",
    "start": "540060",
    "end": "544460"
  },
  {
    "text": "all right so on to the next I guess just wreak Lera fication on",
    "start": "546740",
    "end": "552510"
  },
  {
    "text": "labels already kind of touched on that it's just the way that we are referring to the kind of hierarchy of things so we",
    "start": "552510",
    "end": "560730"
  },
  {
    "text": "have our set of pods we also have a label specifier in our endpoint set",
    "start": "560730",
    "end": "567030"
  },
  {
    "text": "specifying how we actually pick which pods were washing for their readiness or lack thereof so because again just",
    "start": "567030",
    "end": "579660"
  },
  {
    "text": "consuming raw endpoints that it's better than having to watch all the pods but that's still not super out of the box",
    "start": "579660",
    "end": "585150"
  },
  {
    "text": "useful because you have to actually coordinate everything so what all the time we just want a load balancer of",
    "start": "585150",
    "end": "591390"
  },
  {
    "text": "some kind we just want to hit one thing and not fuss about it at all so services",
    "start": "591390",
    "end": "596790"
  },
  {
    "text": "are the answer to that services program up a load balancer the default the sorry",
    "start": "596790",
    "end": "603840"
  },
  {
    "text": "the behavior and logistics of which vary and point it at all the end points in",
    "start": "603840",
    "end": "611520"
  },
  {
    "text": "doing so they also create an IP again the origin of which various includes",
    "start": "611520",
    "end": "618660"
  },
  {
    "text": "that in the service so now you have one single IP to hit and the service",
    "start": "618660",
    "end": "624150"
  },
  {
    "text": "controller is now continuously making sure that all the ready endpoints are programmed on the load balancer you know",
    "start": "624150",
    "end": "631430"
  },
  {
    "text": "there's a number of ways that this works first are there are four different kinds",
    "start": "631430",
    "end": "636540"
  },
  {
    "text": "of services that all may have a bit differently first one I'll mention because it's very simple is type",
    "start": "636540",
    "end": "644340"
  },
  {
    "text": "external name and it's basically just a cname if you want to use that mechanism to expose an alias it can be seen them",
    "start": "644340",
    "end": "650640"
  },
  {
    "text": "to anything including some random domain outside your cluster the next kind and",
    "start": "650640",
    "end": "655650"
  },
  {
    "text": "probably the most common kind is a cluster IP cluster IP allocates some IP",
    "start": "655650",
    "end": "661340"
  },
  {
    "text": "within the kubernetes cluster and then has an internal load balancer so I'll",
    "start": "661340",
    "end": "667650"
  },
  {
    "text": "talk more about one implementation in a sec that we have for that built in next",
    "start": "667650",
    "end": "672750"
  },
  {
    "text": "type is node port it exposes a specific set of ports across all your hosts",
    "start": "672750",
    "end": "678050"
  },
  {
    "text": "and it relies on direct investment there so this would be if you want to say have some external load balancer or some",
    "start": "678050",
    "end": "685310"
  },
  {
    "text": "external service discovery just pointing easily at your nodes something usually from the outside and the last kind is a",
    "start": "685310",
    "end": "693020"
  },
  {
    "text": "combination essentially of coaster IP and note port it's type load balancer it's basically the most primitive form",
    "start": "693020",
    "end": "699470"
  },
  {
    "text": "of ingress you can get where you are at least in terms of the constructs where",
    "start": "699470",
    "end": "704540"
  },
  {
    "text": "you are opening new ports and you have a cluster IP so you hit a given node pour",
    "start": "704540",
    "end": "710149"
  },
  {
    "text": "it on some machine and then you get routed through the cluster IP load balancer to your pod this does have some",
    "start": "710149",
    "end": "717380"
  },
  {
    "text": "downsides because you are routing around a little bit within your cluster it was a better alternative that I'll talk",
    "start": "717380",
    "end": "723290"
  },
  {
    "text": "about later on questions so far about services",
    "start": "723290",
    "end": "729610"
  },
  {
    "text": "I'm making Tim work here thank you so",
    "start": "735260",
    "end": "742790"
  },
  {
    "text": "they'll awesome that you mentioned lowdown sir I don't know what it was um why would you ever use that instead of",
    "start": "742790",
    "end": "749030"
  },
  {
    "text": "node poor if it's just note port plus more like that doesn't get you anything",
    "start": "749030",
    "end": "755390"
  },
  {
    "text": "it gets you the more so you don't necessarily have to rig up the load balancer yourself because you can rely",
    "start": "755390",
    "end": "762380"
  },
  {
    "text": "if you have like a cloud provider integration or something on them to spin it up for you so this would be a way to",
    "start": "762380",
    "end": "768980"
  },
  {
    "text": "just get like RTC people are balanced or spun up for you it gives you ingress",
    "start": "768980",
    "end": "774080"
  },
  {
    "text": "into the cluster",
    "start": "774080",
    "end": "776560"
  },
  {
    "text": "yeah upfront",
    "start": "780100",
    "end": "783149"
  },
  {
    "text": "how much control does a user have over the load balancer for the cluster IP I'm",
    "start": "786870",
    "end": "796300"
  },
  {
    "text": "not entirely sure I believe it mostly depends up to the implementation of whatever service controller there is",
    "start": "796300",
    "end": "803130"
  },
  {
    "text": "there's at least out of the box the cluster IP is or the cluster IP is a",
    "start": "803130",
    "end": "810160"
  },
  {
    "text": "range that you give to the cluster creation time and then it's either Auto allocated or you can set it and it will",
    "start": "810160",
    "end": "817060"
  },
  {
    "text": "try to get it and if it can get that one that you wanted I'm sure there's an error right there's an event the actual",
    "start": "817060",
    "end": "826870"
  },
  {
    "text": "you mean how the traffic is split that one is not currently part of the API except for external traffic local which",
    "start": "826870",
    "end": "834010"
  },
  {
    "text": "governs whether the traffic is going to be routed to your local node or across",
    "start": "834010",
    "end": "839260"
  },
  {
    "text": "your nodes so it's not part of the API you can control it by if you can",
    "start": "839260",
    "end": "845800"
  },
  {
    "text": "configure your load balancer itself like to proxy which is a built in",
    "start": "845800",
    "end": "850930"
  },
  {
    "text": "implementation you have a lot of different knobs you can tune around how it works and there's theoretically some",
    "start": "850930",
    "end": "857620"
  },
  {
    "text": "load balancers that let you use annotations to add extra features",
    "start": "857620",
    "end": "863310"
  },
  {
    "text": "yeah thinks I'm do we still like canonically I remember we used to have",
    "start": "867640",
    "end": "872870"
  },
  {
    "text": "like the cloud providers all used to use like there'd be everything would use",
    "start": "872870",
    "end": "879890"
  },
  {
    "text": "note poured under the hood as like the glue like I remember at least GCE or GK used to do that is that still normal to",
    "start": "879890",
    "end": "886490"
  },
  {
    "text": "use note port under the hood for what your tcp load balancers directly talk to",
    "start": "886490",
    "end": "892610"
  },
  {
    "text": "if you're in the major clouds so actually GCE does not use note port",
    "start": "892610",
    "end": "898100"
  },
  {
    "text": "because there's this it can balance the VIP directly onto the VM I know",
    "start": "898100",
    "end": "904520"
  },
  {
    "text": "AWS used to maybe not anymore if you maybe not anymore",
    "start": "904520",
    "end": "909730"
  },
  {
    "text": "right and then there's at least I can mostly speak to G CP g CP has this notion of",
    "start": "911350",
    "end": "917990"
  },
  {
    "text": "network endpoint group which is which basically for certain types of load",
    "start": "917990",
    "end": "923839"
  },
  {
    "text": "balancers that can go directly so it doesn't need to transit via the node port to get to the service yep so in",
    "start": "923839",
    "end": "931760"
  },
  {
    "text": "some sense it's up to the implementation whether or not it actually needs the node port some do some don't yeah yeah",
    "start": "931760",
    "end": "942079"
  },
  {
    "text": "no port with type load balancer is common but not strictly required by any spec so if you expose pot at Pease",
    "start": "942079",
    "end": "949160"
  },
  {
    "text": "directly on your network like I think that's a common Google behavior at lyft we use a CNI that does that then you can",
    "start": "949160",
    "end": "955550"
  },
  {
    "text": "directly program up individual pods on your load balancer and that's also usually way faster because you're not",
    "start": "955550",
    "end": "961430"
  },
  {
    "text": "translating through anything you're directly going to your instance",
    "start": "961430",
    "end": "965950"
  },
  {
    "text": "yeah this does the clustered provide any mechanism for the load balancer to",
    "start": "973620",
    "end": "979300"
  },
  {
    "text": "provide a feedback about the other status of the endpoints or it is the responsibility of the rope balancing",
    "start": "979300",
    "end": "985089"
  },
  {
    "text": "implementation itself there's health",
    "start": "985089",
    "end": "990760"
  },
  {
    "text": "provided about the little balancer itself but I don't think there's anything in the spec that directly provides endpoint level feedback so",
    "start": "990760",
    "end": "998430"
  },
  {
    "text": "depends on what kind of feedback you want but just earlier this year there's a feature called pod ready it's either",
    "start": "998430",
    "end": "1005339"
  },
  {
    "text": "called pol ready plus + or pod readiness gates that basically lets the infrastructure so when a pod is coming",
    "start": "1005339",
    "end": "1010440"
  },
  {
    "text": "up it first comes up and then it becomes ready the question might be ok if your",
    "start": "1010440",
    "end": "1017339"
  },
  {
    "text": "pod is participating in a load balancer how do you tell the system that that pot",
    "start": "1017339",
    "end": "1022500"
  },
  {
    "text": "actually hasn't been programmed yet and basically pod readiness gates is a additional gate that the infrastructure",
    "start": "1022500",
    "end": "1028410"
  },
  {
    "text": "can add to your pod to say ok only when the load balancer has programmed this",
    "start": "1028410",
    "end": "1033540"
  },
  {
    "text": "pod then say flip this gate to say ok this pot is actually ready because it's not only just ready from a local level",
    "start": "1033540",
    "end": "1039959"
  },
  {
    "text": "but also from a network infrastructure level essentially it's a way to make sure that like my pod is on the load",
    "start": "1039959",
    "end": "1047670"
  },
  {
    "text": "balancer is considered part of the readiness check so consider if you didn't have this I want to go and rule",
    "start": "1047670",
    "end": "1053100"
  },
  {
    "text": "my deployment and update my app ok all the replicas are replaced but up a program deliver balancer takes a minute",
    "start": "1053100",
    "end": "1058800"
  },
  {
    "text": "and everything's swapped out so suddenly from the perspective of my load balancer everything's down so that's why the",
    "start": "1058800",
    "end": "1064470"
  },
  {
    "text": "readiness gates are critically useful is because we can introduce that extra concept of is it ready without needing",
    "start": "1064470",
    "end": "1071820"
  },
  {
    "text": "to get in the way over the path of the health check because otherwise you can have a can opener in a can situation",
    "start": "1071820",
    "end": "1077429"
  },
  {
    "text": "because if you try to block the health check then you can't necessarily rep traffic to it I will just add to that",
    "start": "1077429",
    "end": "1084840"
  },
  {
    "text": "that I think this is a place where we can do better been looking at a lot more",
    "start": "1084840",
    "end": "1090270"
  },
  {
    "text": "higher level networking systems later like load balancers that that really want their own direct - endpoint health",
    "start": "1090270",
    "end": "1096000"
  },
  {
    "text": "checking and our API is don't fit the for some of these yeah I think this is",
    "start": "1096000",
    "end": "1101380"
  },
  {
    "text": "an area for growth this year we provide the building blocks but it could be more powerful and it could be a little bit",
    "start": "1101380",
    "end": "1106720"
  },
  {
    "text": "less mechanical I saw a hand in the back there boy it's on you all right",
    "start": "1106720",
    "end": "1113280"
  },
  {
    "text": "is it that's the first packet that hits a load balancer or is it up the sessions shakiness that every packet goes to just",
    "start": "1115530",
    "end": "1124000"
  },
  {
    "text": "a single and destination like say you wondered 1.1.1 sorry you're asking if",
    "start": "1124000",
    "end": "1131290"
  },
  {
    "text": "there's a single destination so you will have multiple pots running behind this",
    "start": "1131290",
    "end": "1136390"
  },
  {
    "text": "load balancer for a single application would there be any session stickiness at",
    "start": "1136390",
    "end": "1142270"
  },
  {
    "text": "the load balancer end or would we just as first packet that would be heating the load balancer and then after that",
    "start": "1142270",
    "end": "1147970"
  },
  {
    "text": "the packet would be reaching directly to the port again I can take that one",
    "start": "1147970",
    "end": "1156720"
  },
  {
    "text": "so I think there's two questions here there's one of stickiness so there is an",
    "start": "1160070",
    "end": "1165900"
  },
  {
    "text": "option in service for stickiness that that is based on the five tuple right so client IP port protocol to the server IP",
    "start": "1165900",
    "end": "1174360"
  },
  {
    "text": "port so you can establish that if you want it the rest of the question is",
    "start": "1174360",
    "end": "1179370"
  },
  {
    "text": "about I think about performance and like whether the load balancer touches every packet that depends on the implementation so if you're looking at",
    "start": "1179370",
    "end": "1185790"
  },
  {
    "text": "the default like the IP tables implementation whose based on IP tables NAT that will look at the first packet",
    "start": "1185790",
    "end": "1193410"
  },
  {
    "text": "establish the connection make a connection tracking record and then ignore the rest other implementations",
    "start": "1193410",
    "end": "1198480"
  },
  {
    "text": "might do something different",
    "start": "1198480",
    "end": "1201590"
  },
  {
    "text": "all right I think we're getting more and more questions as we get to more of these Vimal sorry so what if you have",
    "start": "1206090",
    "end": "1213230"
  },
  {
    "text": "configured chases stickiness and the endpoint dies or the port dies what",
    "start": "1213230",
    "end": "1219590"
  },
  {
    "text": "happens in that case when we detect that endpoint has been removed from the endpoint set we will remove any I think",
    "start": "1219590",
    "end": "1229010"
  },
  {
    "text": "we remove any connection tracking records that were related to that endpoint so that you'll have to pick a new new endpoint you're basically your",
    "start": "1229010",
    "end": "1236060"
  },
  {
    "text": "stickiness gets lost at least that's the default implementation yeah a lot of the",
    "start": "1236060",
    "end": "1242450"
  },
  {
    "text": "specifics do wind up being however the load balancer works because the spec doesn't control the load balancer at a",
    "start": "1242450",
    "end": "1248450"
  },
  {
    "text": "fine granularity it just provides the basic programming details",
    "start": "1248450",
    "end": "1254170"
  },
  {
    "text": "so services and endpoints are designed",
    "start": "1256950",
    "end": "1262410"
  },
  {
    "text": "as a way to provide potentially custom solutions but there's one that many many",
    "start": "1262410",
    "end": "1267600"
  },
  {
    "text": "people use if they're not using a service mesh and that's cube proxy ku proxy is our built-in service",
    "start": "1267600",
    "end": "1274950"
  },
  {
    "text": "implementation that programs things with its couple different modes most people use iptables and it deals with assigning",
    "start": "1274950",
    "end": "1283230"
  },
  {
    "text": "the cluster IP in terms of network rules and then forwarding to all the backends",
    "start": "1283230",
    "end": "1289710"
  },
  {
    "text": "so in iptables mode it's actually kind of funny if you look at it we basically create a redirect on the cluster IP to a",
    "start": "1289710",
    "end": "1297660"
  },
  {
    "text": "whole set of IPs all with kind of different weights getting more and more",
    "start": "1297660",
    "end": "1304050"
  },
  {
    "text": "likely and that's the very kind of interesting approach to doing random",
    "start": "1304050",
    "end": "1309870"
  },
  {
    "text": "distribution there is a PBS mode which lets you do like real round-robin routing and more advanced things",
    "start": "1309870",
    "end": "1318440"
  },
  {
    "text": "thank you Tim and boy for the running around so the question is around q proxy",
    "start": "1323450",
    "end": "1329070"
  },
  {
    "text": "and IB tables and I PBS mode let's say I have some custom OVS kind of based",
    "start": "1329070",
    "end": "1334230"
  },
  {
    "text": "implementation would it be possible to write a Q proxy plug-in to like program",
    "start": "1334230",
    "end": "1339240"
  },
  {
    "text": "all these kind of iptables rules as connection tracking rules in the OVS would it will is there some something like a plugin to keep proxy that it that",
    "start": "1339240",
    "end": "1345540"
  },
  {
    "text": "we could write in the future as the maintainer of Q proxy no I I don't want",
    "start": "1345540",
    "end": "1354240"
  },
  {
    "text": "any I don't want to build it anymore monolithically than it currently is I'd rather have people fork it and build a",
    "start": "1354240",
    "end": "1360690"
  },
  {
    "text": "separate one that does exactly what you need basically there's way too many config parameters that need to come in",
    "start": "1360690",
    "end": "1366210"
  },
  {
    "text": "to cube proxy to cover all the different proxy modes and it's become very confusing for people and I would rather",
    "start": "1366210",
    "end": "1372750"
  },
  {
    "text": "see people sort of vertical eyes and go go build their own thing so I've basically put a halt on new proxy modes",
    "start": "1372750",
    "end": "1378840"
  },
  {
    "text": "in theory you can do what you're talking about but I'm encouraging you to do that in a separate code base oh and sorry and",
    "start": "1378840",
    "end": "1390150"
  },
  {
    "text": "by the way there was a new implementation of services launched this week from some of the folks at VMware",
    "start": "1390150",
    "end": "1397260"
  },
  {
    "text": "launched something called an Andrea I hope I get the name right it's an OVS based implementation",
    "start": "1397260",
    "end": "1404630"
  },
  {
    "text": "so DNS if we have a pod we can nicely",
    "start": "1410560",
    "end": "1415990"
  },
  {
    "text": "route to one of our names like my app or nginx Aretas and there's a reason that",
    "start": "1415990",
    "end": "1422050"
  },
  {
    "text": "all that magic works as well as a lot of custom internals and that's because we inject DNS reading information so when",
    "start": "1422050",
    "end": "1432040"
  },
  {
    "text": "the cubelet starts up container the cubelet being the component that actually manages containers on the host",
    "start": "1432040",
    "end": "1438570"
  },
  {
    "text": "we program in some service endpoint where DNS is supposed to go those DNS",
    "start": "1438570",
    "end": "1448030"
  },
  {
    "text": "requests are then routed to some DNS service normally running in the cluster like the default that shipped is",
    "start": "1448030",
    "end": "1454990"
  },
  {
    "text": "accordion s deployment but you can customize how that works and you can also pick a different DNS setup if you",
    "start": "1454990",
    "end": "1461320"
  },
  {
    "text": "so desire Derek dear I asked questions around DNS alright thank you for that",
    "start": "1461320",
    "end": "1476330"
  },
  {
    "text": "so the one that I suspect everyone's going to have a question on is ingress",
    "start": "1476330",
    "end": "1481830"
  },
  {
    "text": "ingress is our kind of top-level http F or not htv7 layer seven HTTP way of",
    "start": "1481830",
    "end": "1491750"
  },
  {
    "text": "having an composing cluster traffic that's from an external source so going",
    "start": "1491750",
    "end": "1498000"
  },
  {
    "text": "into the cluster the way ingress works is we define a set of HTTP backends",
    "start": "1498000",
    "end": "1505470"
  },
  {
    "text": "using potentially rules like host names or paths and then correspond them on to some service so there's a couple of nice",
    "start": "1505470",
    "end": "1512580"
  },
  {
    "text": "things about this one is just that it's a way to actually do your layer 7",
    "start": "1512580",
    "end": "1520320"
  },
  {
    "text": "routing at config so instead of writing a custom nginx deployment and making",
    "start": "1520320",
    "end": "1525540"
  },
  {
    "text": "sure you have to update your nginx deployment to read up to your services we provide a more carbonated native way",
    "start": "1525540",
    "end": "1530610"
  },
  {
    "text": "to do that the functionality of ingress really really varies depending on what",
    "start": "1530610",
    "end": "1537600"
  },
  {
    "text": "control you're using so later in the session we're gonna be hearing more about like what's wrong with ingress how",
    "start": "1537600",
    "end": "1545490"
  },
  {
    "text": "it's going to get cleaned up in the theoretical v2 future but right now the",
    "start": "1545490",
    "end": "1552870"
  },
  {
    "text": "exact rules that you can use very provider to provider and if you've ever especially had to use different",
    "start": "1552870",
    "end": "1559169"
  },
  {
    "text": "providers for ingress you'll see that there's all these custom annotations they like you defined things like TLS or",
    "start": "1559169",
    "end": "1564360"
  },
  {
    "text": "a named IP from some pool or algorithms or security settings or cache settings",
    "start": "1564360",
    "end": "1570120"
  },
  {
    "text": "and it's all different and that part is",
    "start": "1570120",
    "end": "1576570"
  },
  {
    "text": "kind of unfortunate because it's one of the more sticky pieces as soon as you go from cloud to cloud or system system or",
    "start": "1576570",
    "end": "1584400"
  },
  {
    "text": "even just if you want to like switch over to a cheap nginx in cluster stuff",
    "start": "1584400",
    "end": "1590030"
  },
  {
    "text": "so questions about ingress I'll specifically defer future of ingress questions for the next talk",
    "start": "1590030",
    "end": "1597770"
  },
  {
    "text": "all right here's an example of us composing some",
    "start": "1603120",
    "end": "1608330"
  },
  {
    "text": "very simple rules we have our main path so we default with some particular",
    "start": "1608330",
    "end": "1614900"
  },
  {
    "text": "back-end and then we have an API back-end where everything that matches that HTTP path gets read it there so",
    "start": "1614900",
    "end": "1621670"
  },
  {
    "text": "much nicer at least than having to have a custom router in your cluster for this",
    "start": "1621670",
    "end": "1628810"
  },
  {
    "text": "so that's a overview of what's in the networking stack I'll touch briefly on",
    "start": "1628810",
    "end": "1635300"
  },
  {
    "text": "some of the stuff that's been going on lately",
    "start": "1635300",
    "end": "1640240"
  },
  {
    "text": "- definitely biggest pieces of news we even heard about them in the keynote is",
    "start": "1640730",
    "end": "1645820"
  },
  {
    "text": "ipv4 ipv6 dual stack is now available and is continuing to progress that's",
    "start": "1645820",
    "end": "1652340"
  },
  {
    "text": "been a huge huge effort for a long time and it's been a notable pieces of work",
    "start": "1652340",
    "end": "1657920"
  },
  {
    "text": "in the sig since this spring I think almost everyone has chipped in in some",
    "start": "1657920",
    "end": "1663140"
  },
  {
    "text": "way with that effort the big one is also the endpoint slash change where we",
    "start": "1663140",
    "end": "1668860"
  },
  {
    "text": "enhance the ability to scale out clusters to have more nodes and or more",
    "start": "1668860",
    "end": "1673970"
  },
  {
    "text": "pods by reducing the traffic churn that happens that's something also we'll hear about in the next talk as far as",
    "start": "1673970",
    "end": "1683210"
  },
  {
    "text": "upcoming work goes future of ingress is a big one ingress with beta for a long",
    "start": "1683210",
    "end": "1688820"
  },
  {
    "text": "long time at this point it's effectively GA and we need to figure out how to polish it up officially GA and then kind",
    "start": "1688820",
    "end": "1696530"
  },
  {
    "text": "of move on to building better systems and we don't have very particular plans",
    "start": "1696530",
    "end": "1701810"
  },
  {
    "text": "here yet but we are looking more at the future of multi cluster networking and trying to figure out how to make that",
    "start": "1701810",
    "end": "1708770"
  },
  {
    "text": "work better so if you want to get",
    "start": "1708770",
    "end": "1714410"
  },
  {
    "text": "involved with the sig it's relatively easy dare I say I got involved first a",
    "start": "1714410",
    "end": "1720740"
  },
  {
    "text": "year ago at last cubic on North America there's a couple different ways we communicate slack and probably mailing",
    "start": "1720740",
    "end": "1727490"
  },
  {
    "text": "lists are the best ones didn't actually put a link here to the sig network info",
    "start": "1727490",
    "end": "1733220"
  },
  {
    "text": "page but if you just google criminate a sig network you'll find us we also have a biweekly hourly call",
    "start": "1733220",
    "end": "1739070"
  },
  {
    "text": "on Thursdays at 2:00 p.m. where we kind of talk in person about anything that",
    "start": "1739070",
    "end": "1744170"
  },
  {
    "text": "requires a bit more coordination or agreement so if you want to check things",
    "start": "1744170",
    "end": "1750110"
  },
  {
    "text": "I would recommend subscribing to those and maybe just shadowing a caller to and kind of seeing what's going on promise",
    "start": "1750110",
    "end": "1757280"
  },
  {
    "text": "we're a friendly Bunch you can see Lockean is Halloween costume there",
    "start": "1757280",
    "end": "1763130"
  },
  {
    "text": "oh yes that's the one of the Starfleet",
    "start": "1763130",
    "end": "1770330"
  },
  {
    "text": "engineering uniforms yeah so also if you",
    "start": "1770330",
    "end": "1776540"
  },
  {
    "text": "want to check out like just units at work and dive in really helpful if you",
    "start": "1776540",
    "end": "1781760"
  },
  {
    "text": "can help review PRS especially if you're a pretty good coder viewer helps to understand the stack very well but",
    "start": "1781760",
    "end": "1786830"
  },
  {
    "text": "there's a lot of things that are easily transferable or look at issues see if",
    "start": "1786830",
    "end": "1792530"
  },
  {
    "text": "you can triage them and verify them maybe even work on a solution if you don't think it's gonna be too challenging so in github we have our carbonated",
    "start": "1792530",
    "end": "1799820"
  },
  {
    "text": "kubernetes repo and everything that is for the cig is labeled Signet work in",
    "start": "1799820",
    "end": "1805430"
  },
  {
    "text": "the issues and the PRS also my advice is someone comparably new is do start small",
    "start": "1805430",
    "end": "1811550"
  },
  {
    "text": "because a lot of this stuff is much more complicated than you probably think and because this is a big project a lot",
    "start": "1811550",
    "end": "1818540"
  },
  {
    "text": "of tech debt and many many users there are many things that are conceptually simple and in practice are not so yeah",
    "start": "1818540",
    "end": "1827840"
  },
  {
    "text": "if you want to find us here's how you do so we'll probably have a pretty quick break and then bring on the next",
    "start": "1827840",
    "end": "1833660"
  },
  {
    "text": "speakers to go into the deep dive thank you [Applause]",
    "start": "1833660",
    "end": "1840839"
  },
  {
    "text": "so this is the Signet work deep dive on Bowie I'm Rob I'm Dan and today in",
    "start": "1841640",
    "end": "1850740"
  },
  {
    "text": "Barcelona I think we did a signal work deep dive and it was really deep into some of the topics that Valerie has",
    "start": "1850740",
    "end": "1856920"
  },
  {
    "text": "covered in the first half but today what we're going to do is deep dive into what is new in the networking space and we",
    "start": "1856920",
    "end": "1863910"
  },
  {
    "text": "have about five topics that we're going to be covering one of them is endpoints slice the second one is the ingress API",
    "start": "1863910",
    "end": "1870030"
  },
  {
    "text": "and service in ingress API evolution and we cover dual stack service topology and",
    "start": "1870030",
    "end": "1875400"
  },
  {
    "text": "on everyone's mind setp know it's very important protocol so endpoint slice so",
    "start": "1875400",
    "end": "1884160"
  },
  {
    "text": "endpoint slice is a great new feature in kubernetes all about making endpoints",
    "start": "1884160",
    "end": "1889440"
  },
  {
    "text": "more scalable but to understand endpoint slice we need to understand a bit of background of how we came to endpoint",
    "start": "1889440",
    "end": "1895980"
  },
  {
    "text": "slice how that was the solution I'm Rob",
    "start": "1895980",
    "end": "1902960"
  },
  {
    "text": "so kubernetes clusters just keep on getting bigger kubernetes is successful",
    "start": "1905000",
    "end": "1910980"
  },
  {
    "text": "it's great news but along with that success comes problems that of scalability and endpoints became one of",
    "start": "1910980",
    "end": "1918990"
  },
  {
    "text": "those bottlenecks each network endpoint for a service needs to fit in a single endpoints resource now this works great",
    "start": "1918990",
    "end": "1926610"
  },
  {
    "text": "up to a certain point but when you start to get services that have lots and lots",
    "start": "1926610",
    "end": "1932820"
  },
  {
    "text": "of endpoints behind them let's say you have thousands of pods you start to run into some real scalability issues",
    "start": "1932820",
    "end": "1939540"
  },
  {
    "text": "because all of those endpoints stop stop fitting in a single resource there's a",
    "start": "1939540",
    "end": "1944970"
  },
  {
    "text": "real size limit at CD default size limit that just prevents that from happening",
    "start": "1944970",
    "end": "1950210"
  },
  {
    "text": "by default that's somewhere between 5,000 and 10,000 Network endpoints depending on a few different",
    "start": "1950210",
    "end": "1956220"
  },
  {
    "text": "configuration variables but at that point you just run out of space in your endpoints resource now you could modify",
    "start": "1956220",
    "end": "1963960"
  },
  {
    "text": "the configuration and let that get even bigger but the problem is that doesn't really help anything because we have a",
    "start": "1963960",
    "end": "1970380"
  },
  {
    "text": "second problem that is very related to that first problem and that's that any change to the",
    "start": "1970380",
    "end": "1976050"
  },
  {
    "text": "endpoints resource needs to go to every single node in the cluster and that's not great so in a 5,000 node cluster a",
    "start": "1976050",
    "end": "1984300"
  },
  {
    "text": "single endpoint change could result in around 5 gigs worth of data being transferred so just think about DVDs",
    "start": "1984300",
    "end": "1991380"
  },
  {
    "text": "worth of data going out every single time of POD changes inside your cluster it's not great admittedly not that many",
    "start": "1991380",
    "end": "1998070"
  },
  {
    "text": "people are running clusters this big because it's not great yet but endpoint",
    "start": "1998070",
    "end": "2004430"
  },
  {
    "text": "slices are set out to try and fix that so the idea behind endpoint slices is",
    "start": "2004430",
    "end": "2010610"
  },
  {
    "text": "really simple we have this huge endpoints resource instead we have smaller endpoint slice resources that",
    "start": "2010610",
    "end": "2017480"
  },
  {
    "text": "are really just slices of endpoints really simple so here's an endpoint",
    "start": "2017480",
    "end": "2025550"
  },
  {
    "text": "gamal because we all like yeah MLAT cube Khan here's what an endpoints resource might look like you probably haven't",
    "start": "2025550",
    "end": "2033080"
  },
  {
    "text": "interacted with this very much because it just kind of happens B's hot behind the scenes you have a service you have",
    "start": "2033080",
    "end": "2039440"
  },
  {
    "text": "some pods matching that service and behind the scenes there's an endpoints controller that runs through and tracks",
    "start": "2039440",
    "end": "2045410"
  },
  {
    "text": "all these IPS for those pods and keeps track of them for you and like I think Tim mentioned earlier there's an",
    "start": "2045410",
    "end": "2051500"
  },
  {
    "text": "addresses field and there's a not ready addresses field and these are just both lists of addresses that are either ready",
    "start": "2051500",
    "end": "2057590"
  },
  {
    "text": "or not ready for your service so it's a really simple concept that works really well to a certain point and",
    "start": "2057590",
    "end": "2063980"
  },
  {
    "text": "then starts to fall apart so with endpoint slices it's a similar thing",
    "start": "2063980",
    "end": "2070370"
  },
  {
    "text": "just with a few extras out of it you can see that we've added an address tag now",
    "start": "2070370",
    "end": "2076010"
  },
  {
    "text": "so ipv6 is supported address type as an example additionally we've added some",
    "start": "2076010",
    "end": "2082398"
  },
  {
    "text": "labels because with endpoints we had this really simple thing where you have one endpoints resource and you have one",
    "start": "2082399",
    "end": "2088520"
  },
  {
    "text": "service so the names are the same everything Maps directly it's really easy because now you have multiple",
    "start": "2088520",
    "end": "2094070"
  },
  {
    "text": "endpoints slices for every service you have to do a little bit more work to reference the service that an endpoint",
    "start": "2094070",
    "end": "2101210"
  },
  {
    "text": "slice belongs to so in this case we have a label referencing the service name",
    "start": "2101210",
    "end": "2106599"
  },
  {
    "text": "and we also have an owner reference that I have not included here because it would make it completely unreadable but",
    "start": "2106599",
    "end": "2113200"
  },
  {
    "text": "an owner reference pointing back to the surface as well and there's a few other differences I'll cover shortly so one of",
    "start": "2113200",
    "end": "2123339"
  },
  {
    "text": "the big additions with endpoint slices is we specify and validate IP addresses so we have address types that are ipv4",
    "start": "2123339",
    "end": "2131890"
  },
  {
    "text": "ipv6 and fqdn eventually we may add more address types but for right now that's",
    "start": "2131890",
    "end": "2138339"
  },
  {
    "text": "where we're starting and for a given endpoint slice you know that addresses in that slice are going to be valid ipv4",
    "start": "2138339",
    "end": "2145089"
  },
  {
    "text": "v6 or fqdn depending on the address type on that slice ports also now have an app",
    "start": "2145089",
    "end": "2151749"
  },
  {
    "text": "protocol field so we already have a protocol field on all ports and kubernetes but that's l4 TCP UDP etc",
    "start": "2151749",
    "end": "2159670"
  },
  {
    "text": "whereas with this a protocol field you could actually specify something like HTTP which hopefully will be useful for",
    "start": "2159670",
    "end": "2167499"
  },
  {
    "text": "consumers of an end point slice API endpoint slice also switches around what",
    "start": "2167499",
    "end": "2173920"
  },
  {
    "text": "we're doing with conditions so before we had just a list of addresses that were ready and addresses that weren't ready",
    "start": "2173920",
    "end": "2180700"
  },
  {
    "text": "so if you wanted to add any additional contingent condition or information about an endpoint it was actually pretty",
    "start": "2180700",
    "end": "2187420"
  },
  {
    "text": "difficult so we've switched that around to add a conditions field on every app",
    "start": "2187420",
    "end": "2192759"
  },
  {
    "text": "on every endpoint that right now just includes a ready boolean but could include additional information about the",
    "start": "2192759",
    "end": "2199749"
  },
  {
    "text": "condition of a given endpoint in the future and additionally endpoint slice",
    "start": "2199749",
    "end": "2205180"
  },
  {
    "text": "endpoints contain topology fields currently that's node name zone and",
    "start": "2205180",
    "end": "2210999"
  },
  {
    "text": "region but arbitrary information can be added here very simply as just like a",
    "start": "2210999",
    "end": "2216069"
  },
  {
    "text": "labels field just specific to topology information and finally a key point here",
    "start": "2216069",
    "end": "2222339"
  },
  {
    "text": "this is not enabled by default in any kubernetes cluster and 1.69 1.17 you",
    "start": "2222339",
    "end": "2228789"
  },
  {
    "text": "need to use the endpoint slice feature gate to enable this what it is beta it",
    "start": "2228789",
    "end": "2235479"
  },
  {
    "text": "is beta that is true so let's talk about performance because the whole and we went through all this was to try",
    "start": "2235479",
    "end": "2242140"
  },
  {
    "text": "and make this skill and the great news is the first implementation of the",
    "start": "2242140",
    "end": "2247270"
  },
  {
    "text": "endpoint slice controller worked well at scale it was fine it actually performed a little bit better than the endpoints",
    "start": "2247270",
    "end": "2253450"
  },
  {
    "text": "controller but that wasn't actually ever the real bottleneck here the real bottleneck came with cou proxy and",
    "start": "2253450",
    "end": "2260400"
  },
  {
    "text": "bandwidth and and I'll say data transfers dramatically lower but cou",
    "start": "2260400",
    "end": "2266770"
  },
  {
    "text": "proxy was still a bit of an issue because it's a little bit more",
    "start": "2266770",
    "end": "2271930"
  },
  {
    "text": "complicated now so I needed to do some testing some scale testing to see what",
    "start": "2271930",
    "end": "2277359"
  },
  {
    "text": "we could improve and my basic methodology here was to spin up a cluster with Kubb test modify the KU",
    "start": "2277359",
    "end": "2285250"
  },
  {
    "text": "proxy manifest just to enable profiling and then use coop color port forwarding",
    "start": "2285250",
    "end": "2290349"
  },
  {
    "text": "along with p prof to actually profile coup proxy and this is actually really",
    "start": "2290349",
    "end": "2295840"
  },
  {
    "text": "really helpful if you're ever trying to debug anything in kubernetes and understand why things aren't as fast as",
    "start": "2295840",
    "end": "2301570"
  },
  {
    "text": "you might expect my colleague min Han has a really cool tool called coop",
    "start": "2301570",
    "end": "2308290"
  },
  {
    "text": "script on github that allows you to push custom builds of qu proxy to specific nodes in your cluster really easily if",
    "start": "2308290",
    "end": "2314859"
  },
  {
    "text": "you're debugging qu proxy or other networking tools I highly recommend that and so what I would do is I have a whole",
    "start": "2314859",
    "end": "2321280"
  },
  {
    "text": "bunch of different versions of coop proxy running in the same cluster on different nodes and compare their performance and the final results I'm",
    "start": "2321280",
    "end": "2329140"
  },
  {
    "text": "going to show we're gathered on a hundred and fifty node cluster over a 15-minute window scaling from 0 to",
    "start": "2329140",
    "end": "2336130"
  },
  {
    "text": "10,000 endpoints for a service and I used four versions of coop proxy",
    "start": "2336130",
    "end": "2342720"
  },
  {
    "text": "kubernetes 1.16 1.16 with slices enabled and the same for kubernetes 1.17 so",
    "start": "2342720",
    "end": "2351660"
  },
  {
    "text": "before I get to the actual charts let me show you the three changes I made because they ended up being significant",
    "start": "2351660",
    "end": "2360240"
  },
  {
    "text": "the first one was I was using endpoint IP for sorting and that ended up being a",
    "start": "2360240",
    "end": "2368560"
  },
  {
    "text": "incredibly expensive operation I had thought endpoint IP must just",
    "start": "2368560",
    "end": "2373900"
  },
  {
    "text": "get the string and return it the actual string in the endpoint object was a IP",
    "start": "2373900",
    "end": "2379600"
  },
  {
    "text": "port combination so it was calling net util to parse an IP out of that and then",
    "start": "2379600",
    "end": "2385600"
  },
  {
    "text": "returning a string so that was very slow and I was using it for sorting and not",
    "start": "2385600",
    "end": "2391930"
  },
  {
    "text": "good so 41 percent of total CPU time was spent calling this single function not",
    "start": "2391930",
    "end": "2398290"
  },
  {
    "text": "great so I changed that just to use the string that already existed and this",
    "start": "2398290",
    "end": "2403690"
  },
  {
    "text": "went away so on to the next problem so there's this cool thing an end point",
    "start": "2403690",
    "end": "2409420"
  },
  {
    "text": "sliced cache that transforms a whole bunch of endpoint slices into a data",
    "start": "2409420",
    "end": "2415030"
  },
  {
    "text": "structure called endpoints map and this is the data structure that Kubb proxy uses behind the scenes to actually",
    "start": "2415030",
    "end": "2421120"
  },
  {
    "text": "render proxy rules whether that's IP tables or IP vs they both use this data",
    "start": "2421120",
    "end": "2426130"
  },
  {
    "text": "structure to actually render the proxy rules and this was called on each endpoint slice update now that's about",
    "start": "2426130",
    "end": "2434050"
  },
  {
    "text": "how endpoints work before it which is fine but the problem is it's a lot more",
    "start": "2434050",
    "end": "2439450"
  },
  {
    "text": "complicated to merge a whole bunch of endpoint slices together and then actually transition them transform them",
    "start": "2439450",
    "end": "2447460"
  },
  {
    "text": "into an endpoints map so this really didn't need to have one on every single",
    "start": "2447460",
    "end": "2452470"
  },
  {
    "text": "endpoint slice update this data structures actually only used when the proxy runs and at scale there can be a",
    "start": "2452470",
    "end": "2459280"
  },
  {
    "text": "whole lot of endpoint slices being updated between proxy or runs as an example you can get many many endpoints",
    "start": "2459280",
    "end": "2466660"
  },
  {
    "text": "less updates every second and proxy errs may only run every few seconds so",
    "start": "2466660",
    "end": "2472360"
  },
  {
    "text": "there's a significant difference here changing this logic around so that we could only compute this when it was",
    "start": "2472360",
    "end": "2477520"
  },
  {
    "text": "needed ended up being a significant savings and finally there's a detect",
    "start": "2477520",
    "end": "2484840"
  },
  {
    "text": "stale connections function that was taking after these previous fixes a",
    "start": "2484840",
    "end": "2490240"
  },
  {
    "text": "whopping 82 percent of total CPU time and it was being called on every single",
    "start": "2490240",
    "end": "2497200"
  },
  {
    "text": "connection even though it was only actually useful for UDP connections so",
    "start": "2497200",
    "end": "2502450"
  },
  {
    "text": "this was kind of a big deal and I imagined for most people they had at least some TCP connections in their",
    "start": "2502450",
    "end": "2509830"
  },
  {
    "text": "cluster if not most so if that's the case we're wasting a lot of time on something that didn't need to be called",
    "start": "2509830",
    "end": "2516250"
  },
  {
    "text": "now we didn't actually have information about what protocol was here at the",
    "start": "2516250",
    "end": "2521560"
  },
  {
    "text": "point but just passing changing some things around so we could have that information ended up being a very",
    "start": "2521560",
    "end": "2527830"
  },
  {
    "text": "significant savings all right so that's that's the three things I changed let's",
    "start": "2527830",
    "end": "2533680"
  },
  {
    "text": "get into the effect that had so memory it's an improvement kind of the the two",
    "start": "2533680",
    "end": "2542020"
  },
  {
    "text": "low lines there are the new 1.17 implementations and the two slightly higher lines are the 1.16 implementation",
    "start": "2542020",
    "end": "2549880"
  },
  {
    "text": "so maybe a 20% improvement maybe but it could also just be noise so this isn't a",
    "start": "2549880",
    "end": "2556150"
  },
  {
    "text": "huge sample size but there's probably some improvement here now CPU usage was",
    "start": "2556150",
    "end": "2562600"
  },
  {
    "text": "a little bit more dramatic my first endpoint slice implementation was not great it turns out that big yellow line",
    "start": "2562600",
    "end": "2570460"
  },
  {
    "text": "that continues three minutes after all the other implementations are done is my initial endpoint slice implementation so",
    "start": "2570460",
    "end": "2578410"
  },
  {
    "text": "not fast and the rest are significantly better but you can see the line the the",
    "start": "2578410",
    "end": "2585790"
  },
  {
    "text": "trajectory that initial endpoints implementation had it as its scale that",
    "start": "2585790",
    "end": "2591400"
  },
  {
    "text": "kept on getting slower and slower and taking up more CPU utilization so even our baseline was going up at a pretty",
    "start": "2591400",
    "end": "2598300"
  },
  {
    "text": "rapid pace here the two lower lines are the 1.17 implementations one",
    "start": "2598300",
    "end": "2605080"
  },
  {
    "text": "representing endpoints and the other represent that the other slightly lower one representing endpoint slices so this",
    "start": "2605080",
    "end": "2613000"
  },
  {
    "text": "is a fairly significant improvement and where I think it really becomes more",
    "start": "2613000",
    "end": "2618370"
  },
  {
    "text": "obvious as if you look at the P prof numbers we're seeing here which are related to CPU time spent over this",
    "start": "2618370",
    "end": "2625990"
  },
  {
    "text": "entire window and endpoint slice the initial implementation is an absurd",
    "start": "2625990",
    "end": "2633310"
  },
  {
    "text": "number there but even our initial endpoints implementation is pretty slow",
    "start": "2633310",
    "end": "2638710"
  },
  {
    "text": "compared to our newer implementations and finally to put this into a bit of",
    "start": "2638710",
    "end": "2644440"
  },
  {
    "text": "perspective with some real numbers we improve performance from the baseline in",
    "start": "2644440",
    "end": "2650650"
  },
  {
    "text": "1.16 around 20 times this is only really",
    "start": "2650650",
    "end": "2655710"
  },
  {
    "text": "I'll give a little bit of a caveat here this is only really going to be noticeable when you're operating at",
    "start": "2655710",
    "end": "2660850"
  },
  {
    "text": "scale when you've got a few hundred endpoints in your cluster it doesn't matter that much but when you start to",
    "start": "2660850",
    "end": "2667210"
  },
  {
    "text": "get into the thousands and tens of thousands of endpoints this is going to be a huge difference so that's what we",
    "start": "2667210",
    "end": "2675190"
  },
  {
    "text": "found with some relatively simple to proxy performance improvements so let's",
    "start": "2675190",
    "end": "2682510"
  },
  {
    "text": "talk about the endpoints I placed time line and when you might actually get to use this when it might be enabled by",
    "start": "2682510",
    "end": "2687820"
  },
  {
    "text": "default the design was actually proposed in Barcelona this year at PubCon",
    "start": "2687820",
    "end": "2692940"
  },
  {
    "text": "the cat was created in june and approved in july we got our first alpha in 1.16",
    "start": "2692940",
    "end": "2700060"
  },
  {
    "text": "and the it was actually released as beta and 1.17 but not enabled by default",
    "start": "2700060",
    "end": "2706230"
  },
  {
    "text": "we're hoping that we can get this enabled by default in 1.18 and if that",
    "start": "2706230",
    "end": "2712960"
  },
  {
    "text": "all goes well maybe we'll get GA sometime 1.19 but that's admittedly optimistic so there's lots you can do to",
    "start": "2712960",
    "end": "2722320"
  },
  {
    "text": "help us with endpoint slices first off does it work for you can you break it are we missing something we want to get",
    "start": "2722320",
    "end": "2730180"
  },
  {
    "text": "this out there there's some great improvements along with it but to really get this enabled by default we need more",
    "start": "2730180",
    "end": "2736210"
  },
  {
    "text": "people using it so please test it out and speaking of testing if you have",
    "start": "2736210",
    "end": "2742330"
  },
  {
    "text": "ideas for how we could test this better and make it more thorough definitely interested in better tests for endpoint",
    "start": "2742330",
    "end": "2748960"
  },
  {
    "text": "slices and then maybe the biggest thing of all we want to migrate the use of endpoints API over to endpoint slices so",
    "start": "2748960",
    "end": "2757240"
  },
  {
    "text": "this includes things like the windows implementations of coop proxy ingress controllers dns and probably other",
    "start": "2757240",
    "end": "2763960"
  },
  {
    "text": "things that I haven't listed here but with that I'll turn it over to Bowie to talk about ingress so in terms of every",
    "start": "2763960",
    "end": "2772390"
  },
  {
    "text": "API evolution that we want to do in the system we first have to kind of look at",
    "start": "2772390",
    "end": "2778390"
  },
  {
    "text": "the landscape and how it has changed from sort of when it was originally designed to what it is today",
    "start": "2778390",
    "end": "2784960"
  },
  {
    "text": "so on the hopefully right-hand side of this diagram we have kind of the",
    "start": "2784960",
    "end": "2791829"
  },
  {
    "text": "landscape of proxy ELB providers and controllers so I kind of loosely categorized these into cloud elby's",
    "start": "2791829",
    "end": "2797950"
  },
  {
    "text": "middle proxies and transparent proxies and as we see that the functionality all",
    "start": "2797950",
    "end": "2804520"
  },
  {
    "text": "of these is slowly converging in terms of what they can all support it's but it's a slow process on the left-hand",
    "start": "2804520",
    "end": "2811900"
  },
  {
    "text": "side we see that as clusters become bigger and bigger for example in the case of endpoint slice is that there are",
    "start": "2811900",
    "end": "2818800"
  },
  {
    "text": "more complex roles and personas involved in kind of deployment of applications on",
    "start": "2818800",
    "end": "2824470"
  },
  {
    "text": "a cluster in the early days of kubernetes we really focused on the empowered developer who is going to be a",
    "start": "2824470",
    "end": "2831070"
  },
  {
    "text": "single team that's going to self service most things when you get to bigger and",
    "start": "2831070",
    "end": "2836410"
  },
  {
    "text": "bigger clusters that are shared among multiple teams now these roles have been split up and as an example some of these",
    "start": "2836410",
    "end": "2843670"
  },
  {
    "text": "personas may be an infrastructure provider this is someone who owns the cloud environment for example setting up",
    "start": "2843670",
    "end": "2850810"
  },
  {
    "text": "the cluster environment itself then there is the cluster operator who operates the cluster and enforces",
    "start": "2850810",
    "end": "2857500"
  },
  {
    "text": "policies globally across the cluster or maybe net ops who enforces policies",
    "start": "2857500",
    "end": "2863290"
  },
  {
    "text": "across all of networking and then finally we have the empowered application developer so the key behind",
    "start": "2863290",
    "end": "2869410"
  },
  {
    "text": "API design is to kind of think about how this evolving landscape then translates to api's now talking about ingress",
    "start": "2869410",
    "end": "2878740"
  },
  {
    "text": "ingress is actually a pretty popular API it has very wide support among different",
    "start": "2878740",
    "end": "2884470"
  },
  {
    "text": "implementations and for some of the cases it's actually good enough for a non-trivial number of users so from a",
    "start": "2884470",
    "end": "2890859"
  },
  {
    "text": "cig network standpoint ingress is still a very valid API and the plan is to clean up the spec and",
    "start": "2890859",
    "end": "2896829"
  },
  {
    "text": "take the type to GA did you know it was still beta so what are we going to do",
    "start": "2896829",
    "end": "2903400"
  },
  {
    "text": "for the ingress API so clean up the object model so as you saw the diagram before there's this new",
    "start": "2903400",
    "end": "2910160"
  },
  {
    "text": "resource called ingress class in fact every single ingress implementation has an annotation that says okay which",
    "start": "2910160",
    "end": "2916850"
  },
  {
    "text": "controller should be in charge of this ingress while there is an engine X or it's a cloud provider and so forth so",
    "start": "2916850",
    "end": "2924290"
  },
  {
    "text": "actually make that a real resource the next thing is to tweak and fix the specification so we have a list of sort",
    "start": "2924290",
    "end": "2930770"
  },
  {
    "text": "of minor discrepancies between how it is specified or maybe under specified",
    "start": "2930770",
    "end": "2937150"
  },
  {
    "text": "currently in the API and what the actual behavior we see of all the different",
    "start": "2937150",
    "end": "2942350"
  },
  {
    "text": "implementations out there there are some theory names like back-end to default back-end the path and host name matching",
    "start": "2942350",
    "end": "2950330"
  },
  {
    "text": "actually the implementations we find do not sort of follow what is in the comments in the types that go so we're",
    "start": "2950330",
    "end": "2957140"
  },
  {
    "text": "kind of cleaning that up and then finally we'd add a bit of flexibility that will be hard to change later in the",
    "start": "2957140",
    "end": "2963619"
  },
  {
    "text": "GI api which is to enable you to not just route from your ingress to a",
    "start": "2963619",
    "end": "2969350"
  },
  {
    "text": "service but also potentially targets and alternate back end however for the first",
    "start": "2969350",
    "end": "2974869"
  },
  {
    "text": "cut we would expect controllers to only support the service type now let's talk",
    "start": "2974869",
    "end": "2980480"
  },
  {
    "text": "about evolving this so as I said before we had a slide with kind of the changing",
    "start": "2980480",
    "end": "2986330"
  },
  {
    "text": "landscape so what does this mean for the goals of an ingress api evolution and",
    "start": "2986330",
    "end": "2992510"
  },
  {
    "text": "remember everything I say here is super early proposal and the point of Q con is",
    "start": "2992510",
    "end": "2998750"
  },
  {
    "text": "to get all of you users plus implementers to give us feedback so we see at the high level three main goals",
    "start": "2998750",
    "end": "3006609"
  },
  {
    "text": "one of them is looking at those personas is to better model them with the",
    "start": "3006609",
    "end": "3012340"
  },
  {
    "text": "resource model the second one is as the implementations all convergent capability is to support more modern",
    "start": "3012340",
    "end": "3020020"
  },
  {
    "text": "load balancing features and then we did an ingress survey user survey in 2018",
    "start": "3020020",
    "end": "3025660"
  },
  {
    "text": "and we came back with two opposing viewpoints one of them is that it must be portable and the other one is I must",
    "start": "3025660",
    "end": "3032800"
  },
  {
    "text": "be able to use all my power features of my underlying implementation so important is key but maybe not just",
    "start": "3032800",
    "end": "3039609"
  },
  {
    "text": "portability but sort of predict ability for the user can a user predict how portable their thing is and then not",
    "start": "3039609",
    "end": "3046970"
  },
  {
    "text": "limit them if they want to go out of that spec finally sort of build into the",
    "start": "3046970",
    "end": "3053630"
  },
  {
    "text": "API standard mechanisms for extension not just for API growth but implementation and maybe vendor specific",
    "start": "3053630",
    "end": "3059690"
  },
  {
    "text": "behaviors because though one of the feedback that you could see from the survey is if I am actually a power user",
    "start": "3059690",
    "end": "3067450"
  },
  {
    "text": "don't limit me I know what I'm doing so",
    "start": "3067450",
    "end": "3072970"
  },
  {
    "text": "this is a sketch and this is sort of an evolving API but what I want you to take",
    "start": "3072970",
    "end": "3078920"
  },
  {
    "text": "away today is sort of look at this and get a general sense and work through your your use cases whether or not this",
    "start": "3078920",
    "end": "3086900"
  },
  {
    "text": "setup makes sense so generally speaking we have four resources here there's a",
    "start": "3086900",
    "end": "3092900"
  },
  {
    "text": "gateway class a gateway a route actually many types of routes for each protocol",
    "start": "3092900",
    "end": "3098180"
  },
  {
    "text": "and then your kubernetes service and I'll go through kind of describing what the role of each of these resources is",
    "start": "3098180",
    "end": "3104839"
  },
  {
    "text": "in your cluster so at the very top we have gateway class gateway classes very",
    "start": "3104839",
    "end": "3110390"
  },
  {
    "text": "analogous to ingress class this is intended for the infrastructure provider to provide different kinds of load",
    "start": "3110390",
    "end": "3118430"
  },
  {
    "text": "balancers that are available to the user of the cluster now in this example we have two gateway classes one of them is",
    "start": "3118430",
    "end": "3125839"
  },
  {
    "text": "internet lb and the other one is private LP and in this cooked-up example when",
    "start": "3125839",
    "end": "3131450"
  },
  {
    "text": "you create a gateway of Internet lb class that represents that the user",
    "start": "3131450",
    "end": "3136670"
  },
  {
    "text": "intends to export that service as an internet available service and then if",
    "start": "3136670",
    "end": "3142069"
  },
  {
    "text": "they use the private lb class that means that they are intending to perhaps",
    "start": "3142069",
    "end": "3147230"
  },
  {
    "text": "export their service to their local VPC now next comes gateway and route so",
    "start": "3147230",
    "end": "3153950"
  },
  {
    "text": "gateway is sort of the linchpin of this API gateway is the thing that when you",
    "start": "3153950",
    "end": "3160190"
  },
  {
    "text": "instantiate a gateway it kind of wires everything up now what gateway contains is sort of a concrete manifestation of",
    "start": "3160190",
    "end": "3167660"
  },
  {
    "text": "an instance of load balancing for example if you were on a cloud provider and the gateway class was",
    "start": "3167660",
    "end": "3174740"
  },
  {
    "text": "by the cloud provider creating a gateway will then call a bunch of cloud api's to wire your low Belzer of additionally if",
    "start": "3174740",
    "end": "3183080"
  },
  {
    "text": "you were on say using an in cluster implementation of ingress but now",
    "start": "3183080",
    "end": "3188660"
  },
  {
    "text": "gateway in route it will then instantiate and do the configuration to sort of provision your load balancing",
    "start": "3188660",
    "end": "3195320"
  },
  {
    "text": "and then finally this green box is the route this is the application description that will you know be",
    "start": "3195320",
    "end": "3201320"
  },
  {
    "text": "controlled by the application team and because all these are three different resources we can kind of attach",
    "start": "3201320",
    "end": "3207950"
  },
  {
    "text": "different roles to them for example infrastructure provider will get our back for a gateway class the net off",
    "start": "3207950",
    "end": "3214190"
  },
  {
    "text": "spur it helps want to restrict how gateways work so they get the gateway and then the dev team could get the HTTP",
    "start": "3214190",
    "end": "3220130"
  },
  {
    "text": "route oh you can still have self-service basically you would give the dev access",
    "start": "3220130",
    "end": "3226369"
  },
  {
    "text": "to Gateway HP route and then maybe in the most extreme case you could get gateway class gateway in HP route so",
    "start": "3226369",
    "end": "3233530"
  },
  {
    "text": "kind of this is still early we have an H this is these links don't work if you're looking at them but when the document is",
    "start": "3233530",
    "end": "3240890"
  },
  {
    "text": "shared you won't be able to click on them all so these are also on the cig network mailing list so sort of how to",
    "start": "3240890",
    "end": "3247790"
  },
  {
    "text": "get involved this is still very early stages and really we really really really would appreciate feedback from",
    "start": "3247790",
    "end": "3253520"
  },
  {
    "text": "users and implementers and there's a working group that's going to be started it's coming soon in terms of the info we",
    "start": "3253520",
    "end": "3259430"
  },
  {
    "text": "intend to have bi-weekly meetings use the cig network mailing list for now until people tell us we're spamming them",
    "start": "3259430",
    "end": "3265790"
  },
  {
    "text": "too much and then also create a slack channel and there'll be a repository in which all the spec working issues will",
    "start": "3265790",
    "end": "3271760"
  },
  {
    "text": "be held so really this is feedback on the proposal we want to hear from users",
    "start": "3271760",
    "end": "3278000"
  },
  {
    "text": "and implementers in fact when we had the session that we on Tuesday I think we",
    "start": "3278000",
    "end": "3283130"
  },
  {
    "text": "went into a deep dive and there was one user thank you for coming but it was very helpful to hear their voice and of",
    "start": "3283130",
    "end": "3289700"
  },
  {
    "text": "course we want to see experimental implementations as well so moving on to dual stack so dual stack is really",
    "start": "3289700",
    "end": "3299780"
  },
  {
    "text": "exciting feature of kubernetes that is starting to see some life in the form of",
    "start": "3299780",
    "end": "3305000"
  },
  {
    "text": "an alpha release to understand what we mean by dual stack and kubernetes we need to run through",
    "start": "3305000",
    "end": "3311270"
  },
  {
    "text": "the goals for dual stack and kubernetes and that is that pod should be able to",
    "start": "3311270",
    "end": "3317299"
  },
  {
    "text": "support both ipv4 and ipv6 addresses they should be able to communicate ipv4",
    "start": "3317299",
    "end": "3323809"
  },
  {
    "text": "to v4 or ipv6 to v6 they should be able to access external servers on ipv6 or",
    "start": "3323809",
    "end": "3330819"
  },
  {
    "text": "ipv4 addresses and the same pod should be able to be targeted by either an ipv4",
    "start": "3330819",
    "end": "3336770"
  },
  {
    "text": "service or an ipv6 service node ports and external IPs should be support both",
    "start": "3336770",
    "end": "3345079"
  },
  {
    "text": "ipv4 and ipv6 as a departure from that services and points and endpoint slices",
    "start": "3345079",
    "end": "3352730"
  },
  {
    "text": "will all either be ipv4 or ipv6 they will all be an individual single family",
    "start": "3352730",
    "end": "3358640"
  },
  {
    "text": "and of course with all of this we want to ensure we're maintaining backwards compatibility with ipv4 only and ipv6",
    "start": "3358640",
    "end": "3365839"
  },
  {
    "text": "only clusters so as you can probably imagine dual stack is a really complex",
    "start": "3365839",
    "end": "3371869"
  },
  {
    "text": "feature to implement there's a huge it's a huge project and it affects lots and",
    "start": "3371869",
    "end": "3377990"
  },
  {
    "text": "lots of things across the kubernetes ecosystem as an example service ingress controller endpoints endpoint slices",
    "start": "3377990",
    "end": "3384650"
  },
  {
    "text": "nodes CRI CNI runtimes cluster configs",
    "start": "3384650",
    "end": "3389720"
  },
  {
    "text": "and if you think about anything in kubernetes that touches an IP related",
    "start": "3389720",
    "end": "3394789"
  },
  {
    "text": "shell scripts whatever it happens to be all of these things will have to change to support dual stack so there's a lot",
    "start": "3394789",
    "end": "3401720"
  },
  {
    "text": "of work here and that means there's lots of opportunity to help but let's first",
    "start": "3401720",
    "end": "3406819"
  },
  {
    "text": "talk about the alpha release of dual static so first release what for alpha",
    "start": "3406819",
    "end": "3412069"
  },
  {
    "text": "was 1.16 and we got some updates in in 1.17 all functionality is hidden behind",
    "start": "3412069",
    "end": "3418760"
  },
  {
    "text": "a feature gate ipv6 dual stack and the change is involved right now are that",
    "start": "3418760",
    "end": "3425000"
  },
  {
    "text": "pods will have a new pod IPS attribute so that pod IPS attribute will contain",
    "start": "3425000",
    "end": "3430549"
  },
  {
    "text": "both an ipv4 and ipv6 addresses the services have a new IP family attribute",
    "start": "3430549",
    "end": "3438289"
  },
  {
    "text": "that will either be ipv4 or ipv6 endpoints will contain addresses",
    "start": "3438289",
    "end": "3444330"
  },
  {
    "text": "matching only the Service IPS family and endpoint slices will behave similarly",
    "start": "3444330",
    "end": "3450869"
  },
  {
    "text": "but they also have ipv4 and ipv6 address types that add an extra layer of",
    "start": "3450869",
    "end": "3455940"
  },
  {
    "text": "validation there so let's take a look at a simple example here we've got a pod",
    "start": "3455940",
    "end": "3462720"
  },
  {
    "text": "that has both v4 and v6 addresses and we've got a service that we created that",
    "start": "3462720",
    "end": "3469920"
  },
  {
    "text": "matches that pod and it's assigned a cluster IP that is matching its IP family so v4 and then because we have a",
    "start": "3469920",
    "end": "3478170"
  },
  {
    "text": "service that matches the pod we have an endpoint slice that gets created automatically for us and that pulls the",
    "start": "3478170",
    "end": "3484830"
  },
  {
    "text": "ipv4 address out of that pot now similarly if we want to have an ipv6",
    "start": "3484830",
    "end": "3490710"
  },
  {
    "text": "service matching the same pod that's also possible so we've got a service",
    "start": "3490710",
    "end": "3496109"
  },
  {
    "text": "with an IP family of ipv6 and it's got a v6 cluster IP and automatically created",
    "start": "3496109",
    "end": "3504540"
  },
  {
    "text": "for us we have an endpoint slice that pulls the ipv6 address out of the pod",
    "start": "3504540",
    "end": "3509790"
  },
  {
    "text": "and that represents that endpoint slice so that's a very high-level overview of",
    "start": "3509790",
    "end": "3515760"
  },
  {
    "text": "how dual stack is going to work inside kubernetes and I just used endpoint slices here but of course the same is",
    "start": "3515760",
    "end": "3521880"
  },
  {
    "text": "true for endpoints so a huge part of all",
    "start": "3521880",
    "end": "3527400"
  },
  {
    "text": "of this is cout proxy needs to support dual stack and for any of this to work",
    "start": "3527400",
    "end": "3532500"
  },
  {
    "text": "and I think it was Cal had the idea to use some kind of meta proxy or design",
    "start": "3532500",
    "end": "3537930"
  },
  {
    "text": "which basically involves running separate proxy cures for each IP family",
    "start": "3537930",
    "end": "3543390"
  },
  {
    "text": "instead of making huge changes inside each proxy er just pass either fully ipv4 addresses into a proxy ER or fully",
    "start": "3543390",
    "end": "3551130"
  },
  {
    "text": "ipv6 addresses and endpoints into a proxy ER so you have to running in parallel inside qu proxy so two",
    "start": "3551130",
    "end": "3558750"
  },
  {
    "text": "implementations of IP tables or I feel I PBS or whatever it happens to be and those endpoints that match that family",
    "start": "3558750",
    "end": "3566760"
  },
  {
    "text": "are automatically sent to that proxy ER currently that implementation is limited to the IP vs proxy ER",
    "start": "3566760",
    "end": "3573530"
  },
  {
    "text": "but there's some great work underway for iptables support and although there's no support for Windows proxies I think we",
    "start": "3573530",
    "end": "3580280"
  },
  {
    "text": "hope that can happen soon so have to cover some of the timeline of dual stack",
    "start": "3580280",
    "end": "3586730"
  },
  {
    "text": "and thank Dan for actually filling all this out because there's a lot of timeline when it comes to dual stack",
    "start": "3586730",
    "end": "3592610"
  },
  {
    "text": "this goes back way before I was involved in kubernetes 2014 for the very first",
    "start": "3592610",
    "end": "3598940"
  },
  {
    "text": "bits of ipv6 support and the initial ipv6 single stack efforts began 2017 and",
    "start": "3598940",
    "end": "3607720"
  },
  {
    "text": "2018 we hit a dual stack proposal that eventually turned into a cap and",
    "start": "3607720",
    "end": "3613270"
  },
  {
    "text": "eventually resulted in the 1.16 release that included alpha support for dual",
    "start": "3613270",
    "end": "3618440"
  },
  {
    "text": "stack just this August so we're making progress we're hoping we can get to beta",
    "start": "3618440",
    "end": "3623900"
  },
  {
    "text": "relatively soon but there's a lot of work to do and there's lots of opportunities to help so coup proxy",
    "start": "3623900",
    "end": "3631370"
  },
  {
    "text": "still needs a dual stack implementation implementation for Windows additionally",
    "start": "3631370",
    "end": "3636440"
  },
  {
    "text": "for what has released we'd love feedback testing does it work for you can you break it or anything we've missed and",
    "start": "3636440",
    "end": "3643870"
  },
  {
    "text": "additionally because endpoint slices are also new and not enabled by default does this all work well when we have endpoint",
    "start": "3643870",
    "end": "3650480"
  },
  {
    "text": "slices and dual stack working together and finally is there anything in this implementation that we missed along the",
    "start": "3650480",
    "end": "3656450"
  },
  {
    "text": "way and I'll hand it off to Dan service",
    "start": "3656450",
    "end": "3663830"
  },
  {
    "text": "topology this is something that is also relatively new in kubernetes we've been",
    "start": "3663830",
    "end": "3670220"
  },
  {
    "text": "talking about it for probably a better part of a year and even just last week some cool stuff happens so we're",
    "start": "3670220",
    "end": "3676550"
  },
  {
    "text": "starting on that road but at its base service topology tries to answer the",
    "start": "3676550",
    "end": "3681560"
  },
  {
    "text": "question how can I talk to a pod that as close to me or as local to me as",
    "start": "3681560",
    "end": "3687140"
  },
  {
    "text": "possible so the problem that we have there though is what does local really mean and it turns out that local means",
    "start": "3687140",
    "end": "3693230"
  },
  {
    "text": "many different things to many different people and it definitely depends on your infrastructure how you set your cluster",
    "start": "3693230",
    "end": "3699020"
  },
  {
    "text": "up possibly what your networking solution is all different kinds of things so we really need to make sure",
    "start": "3699020",
    "end": "3704690"
  },
  {
    "text": "that service topology a enhancement proposal and as a concept was flexible enough to address all these",
    "start": "3704690",
    "end": "3711369"
  },
  {
    "text": "different use cases and you can see here that the kept for it was accepted back",
    "start": "3711369",
    "end": "3718509"
  },
  {
    "text": "in December there was it took a little while to kind of discuss that and to",
    "start": "3718509",
    "end": "3724539"
  },
  {
    "text": "finalize the cap and there was a number of months after that where there wasn't",
    "start": "3724539",
    "end": "3730269"
  },
  {
    "text": "a ton of work that was going on in public but it turns out that there were some PR was posted relatively recently",
    "start": "3730269",
    "end": "3737199"
  },
  {
    "text": "and merged last week just in time for 117 I believe that adds some of the",
    "start": "3737199",
    "end": "3742900"
  },
  {
    "text": "initial bits of service topology to the various parts of communities including",
    "start": "3742900",
    "end": "3747939"
  },
  {
    "text": "the proxy implementation so what does service topology actually do first we",
    "start": "3747939",
    "end": "3753669"
  },
  {
    "text": "can back up a little bit and say that we do have a kind of an implementation of",
    "start": "3753669",
    "end": "3761049"
  },
  {
    "text": "service topology in cube proxy already and that was a tag that allowed the",
    "start": "3761049",
    "end": "3767259"
  },
  {
    "text": "proxy to direct traffic to a pod that was on that particular node so that's",
    "start": "3767259",
    "end": "3773079"
  },
  {
    "text": "kind of very basic but obviously it doesn't address some of the needs that other contributors had for locality and",
    "start": "3773079",
    "end": "3780729"
  },
  {
    "text": "service topology so the cap adds a key to services that are excuse me a",
    "start": "3780729",
    "end": "3788169"
  },
  {
    "text": "topology keys to services and each of these keys they're fairly well defined keys and there's only a couple right now",
    "start": "3788169",
    "end": "3794909"
  },
  {
    "text": "but I expect there'll be more added in the future as we have better ideas of",
    "start": "3794909",
    "end": "3800019"
  },
  {
    "text": "exactly what topology means in different cases the proxy implementation then",
    "start": "3800019",
    "end": "3805929"
  },
  {
    "text": "takes a look at the service itself and tries to match the the labels on the",
    "start": "3805929",
    "end": "3812829"
  },
  {
    "text": "service with particular labels on the node so at this point it's mostly node based and it turns out that the excuse",
    "start": "3812829",
    "end": "3821919"
  },
  {
    "text": "me yep excuse me topology labels on the",
    "start": "3821919",
    "end": "3827049"
  },
  {
    "text": "node itself it matches them in preference order so if you have you know you want to try the hostname first and",
    "start": "3827049",
    "end": "3833169"
  },
  {
    "text": "if the hostname doesn't actually have any matches then it will also try to match things like availability zone and kind of go on down the list so it really",
    "start": "3833169",
    "end": "3840039"
  },
  {
    "text": "is under the control of the person writing the service and to some degree of the cluster when it decides what keys to put",
    "start": "3840039",
    "end": "3847390"
  },
  {
    "text": "on each particular node there's also in future enhancements there will be a pod",
    "start": "3847390",
    "end": "3853390"
  },
  {
    "text": "locator resource it turned out that there were some scalability issues with the current implementation and so the",
    "start": "3853390",
    "end": "3859690"
  },
  {
    "text": "contributors working on service topology will be adding the pod locator resource",
    "start": "3859690",
    "end": "3865030"
  },
  {
    "text": "to help address some of those issues around how you actually do the matching",
    "start": "3865030",
    "end": "3871110"
  },
  {
    "text": "in last I think we have SCTP which is stream control transmission protocol",
    "start": "3871770",
    "end": "3878850"
  },
  {
    "text": "it's actually more of interest to I think more telephony applications and",
    "start": "3878850",
    "end": "3884290"
  },
  {
    "text": "telcos because that protocol is very heavily used in some of those industries and if you're not familiar with SCTP it",
    "start": "3884290",
    "end": "3890890"
  },
  {
    "text": "is basically like a mashup of kind of TCP and UDP with some additional features for reliability and redundancy",
    "start": "3890890",
    "end": "3898770"
  },
  {
    "text": "it kubernetes only supported up until a couple of releases ago I believe",
    "start": "3898770",
    "end": "3904590"
  },
  {
    "text": "TCP and UDP for a lot of the service and ingress and other operations and it",
    "start": "3904590",
    "end": "3910660"
  },
  {
    "text": "turns out that as kubernetes is trying to enter new worlds and enter new",
    "start": "3910660",
    "end": "3916030"
  },
  {
    "text": "industries and businesses that SCTP was something that quite a few users actually were interested in having",
    "start": "3916030",
    "end": "3922330"
  },
  {
    "text": "support for in kubernetes so the implementation sits alongside both the",
    "start": "3922330",
    "end": "3927550"
  },
  {
    "text": "TCP and UDP bits as a core kubernetes protocol and that shows up in a lot of",
    "start": "3927550",
    "end": "3933790"
  },
  {
    "text": "different places in the code so the one place that it might show up that most you might be familiar with is in the",
    "start": "3933790",
    "end": "3939790"
  },
  {
    "text": "service and you can kind of say that this service has a particular protocol attached to it and that is the protocol",
    "start": "3939790",
    "end": "3946090"
  },
  {
    "text": "that I want to have the proxy pay attention to when it needs to remove the",
    "start": "3946090",
    "end": "3951220"
  },
  {
    "text": "traffic through the cluster to a particular back-end so SCTP is now one",
    "start": "3951220",
    "end": "3956560"
  },
  {
    "text": "of those protocols that you can add to your service but that also means that we need to take that and move it through",
    "start": "3956560",
    "end": "3961630"
  },
  {
    "text": "from services to also endpoints we need to add support to host port for that and",
    "start": "3961630",
    "end": "3967090"
  },
  {
    "text": "then of course network policy as well so the actual protocol does touch a lot of",
    "start": "3967090",
    "end": "3973810"
  },
  {
    "text": "different and kubernetes the supports actually been there for a while and it was alpha",
    "start": "3973810",
    "end": "3980740"
  },
  {
    "text": "in kubernetes 112 and we've been finalizing some of the rest of the kept",
    "start": "3980740",
    "end": "3987040"
  },
  {
    "text": "for that and we hope to possibly make it beta in kubernetes 118 sometime early",
    "start": "3987040",
    "end": "3992800"
  },
  {
    "text": "next year it needs a little bit more of a push over that finish line the other thing to note is that if you are",
    "start": "3992800",
    "end": "3999070"
  },
  {
    "text": "developing a network plugin that you know a CNI essentially you will need to",
    "start": "3999070",
    "end": "4005940"
  },
  {
    "text": "add support for SCTP to that network plug-in if you can to take advantage of",
    "start": "4005940",
    "end": "4011520"
  },
  {
    "text": "some of these features okay we're",
    "start": "4011520",
    "end": "4017130"
  },
  {
    "text": "standing between you and lunch so in conclusion what does this all mean so for endpoints slice we're basically",
    "start": "4017130",
    "end": "4023780"
  },
  {
    "text": "enhancing the API to support massive scale services and endpoints in terms of",
    "start": "4023780",
    "end": "4029310"
  },
  {
    "text": "the API work on ingress and service it's going to be better l4 l7 modeling and then raising the bar in terms of",
    "start": "4029310",
    "end": "4035700"
  },
  {
    "text": "features and extensibility dual stack basically you can use ipv4 and ipv6 in",
    "start": "4035700",
    "end": "4041280"
  },
  {
    "text": "your clusters service topology gives you control over Interzone region traffic well not just that it's very generic",
    "start": "4041280",
    "end": "4047160"
  },
  {
    "text": "thing and then finally a CP TP support gives us protocol support completeness",
    "start": "4047160",
    "end": "4052589"
  },
  {
    "text": "and that's it so Q&A and this is where you can find us Valarie also had a slide like this we'll",
    "start": "4052589",
    "end": "4059819"
  },
  {
    "text": "keep this up here [Applause]",
    "start": "4059819",
    "end": "4072519"
  },
  {
    "text": "over here where are the oh they are posted as a PDF oh no that's maybe Tim can do it or",
    "start": "4072519",
    "end": "4080329"
  },
  {
    "text": "Valerie because we were not on the speaker thing send it to who we can work",
    "start": "4080329",
    "end": "4092599"
  },
  {
    "text": "it off offline here",
    "start": "4092599",
    "end": "4099790"
  },
  {
    "text": "thanks for the deep dive gentlemen scaffolding from ZDNet a question about",
    "start": "4099819",
    "end": "4104988"
  },
  {
    "text": "the IP family attribute anyone here in",
    "start": "4104989",
    "end": "4111619"
  },
  {
    "text": "the audience could tell the difference between an ipv4 address from an ipv6 address just from looking at it so",
    "start": "4111619",
    "end": "4117679"
  },
  {
    "text": "that's a obviously this the Scott colons in it for heaven's sake that's it's not IB before and so my first thought is do",
    "start": "4117679",
    "end": "4125600"
  },
  {
    "text": "you really need an explicit attribute saying the following is an ipv6 address and then I remembered something that you",
    "start": "4125600",
    "end": "4130639"
  },
  {
    "text": "were saying about the time things take in in parsing and the the performance",
    "start": "4130639",
    "end": "4136520"
  },
  {
    "text": "attributes that you wanted to give to it is that attribute explicit just to save",
    "start": "4136520",
    "end": "4142190"
  },
  {
    "text": "the CPU the time of actually having to look at the first second third characters and say is this a colon if so",
    "start": "4142190",
    "end": "4148818"
  },
  {
    "text": "then ipv6 that's a great question I'll",
    "start": "4148819",
    "end": "4154159"
  },
  {
    "text": "say right off that I wasn't I'm probably not be full expert on this but I'll say one key reason to have IP via the family",
    "start": "4154159",
    "end": "4160880"
  },
  {
    "text": "is just this for the sake of validation to actually ensure that and in say an",
    "start": "4160880",
    "end": "4168199"
  },
  {
    "text": "end point slice or whatever that all addresses match the specific IP family but Tim can give more background so",
    "start": "4168199",
    "end": "4175008"
  },
  {
    "text": "that's a really insightful remark because the first version didn't have the distinction the second version did",
    "start": "4175009",
    "end": "4181219"
  },
  {
    "text": "and the reason we added the distinction was in fact what we noticed as we were",
    "start": "4181219",
    "end": "4187940"
  },
  {
    "text": "adding dual stack support is we were going to ask every node in the cluster to run through every endpoint and parse",
    "start": "4187940",
    "end": "4194088"
  },
  {
    "text": "it and make a decision about whether it was v4 v6 right and that seemed like a really redundant silly",
    "start": "4194089",
    "end": "4199580"
  },
  {
    "text": "thing to do when we know that it's cash inefficient to do that there isn't a there isn't a simple API",
    "start": "4199580",
    "end": "4205550"
  },
  {
    "text": "we guess we could write one but the simple API was go parse this IP so it's",
    "start": "4205550",
    "end": "4210680"
  },
  {
    "text": "gonna walk through the whole thing for every IP address times five thousand nodes times you know and it blows out",
    "start": "4210680",
    "end": "4215870"
  },
  {
    "text": "really quickly and we can't do anything about it early whereas if we go this way",
    "start": "4215870",
    "end": "4221390"
  },
  {
    "text": "which I really wasn't a fan of but I came around to now I can validate it a",
    "start": "4221390",
    "end": "4227000"
  },
  {
    "text": "priori on the API server and split those out with no work being delegated out to",
    "start": "4227000",
    "end": "4232550"
  },
  {
    "text": "every node so we took a little bit of a hit on the API in order to save a bunch of work in the nodes okay so in the",
    "start": "4232550",
    "end": "4247970"
  },
  {
    "text": "meantime the related question is the IP family so it has as we see it has to I",
    "start": "4247970",
    "end": "4254570"
  },
  {
    "text": "piece can it be a case where I have both the IP as ipv4 what I am coming to is",
    "start": "4254570",
    "end": "4260600"
  },
  {
    "text": "multi IP support for the pod can it be extended or is there a thought that the",
    "start": "4260600",
    "end": "4267470"
  },
  {
    "text": "same construct can be extended to support multi IP pods you guys are",
    "start": "4267470",
    "end": "4274370"
  },
  {
    "text": "relentless the short answer is yes we've",
    "start": "4274370",
    "end": "4280040"
  },
  {
    "text": "made sure that the design accommodates this knowing that this is a likely direction to go I don't know exactly",
    "start": "4280040",
    "end": "4287660"
  },
  {
    "text": "what that means yet you know there's been a bunch of work that that the Dan and others have done in the community",
    "start": "4287660",
    "end": "4293900"
  },
  {
    "text": "around having multiple interfaces on a pod you now have a way officially that you could represent it although you're",
    "start": "4293900",
    "end": "4299720"
  },
  {
    "text": "gonna you would blow up a bunch of controllers but the logical extension would be okay let's make it possible to",
    "start": "4299720",
    "end": "4306530"
  },
  {
    "text": "actually do this I think we don't yet have a broad definition of what that means if I have two IP addresses in two",
    "start": "4306530",
    "end": "4313790"
  },
  {
    "text": "contexts like for a controller how do I interpret those one of the things an",
    "start": "4313790",
    "end": "4319130"
  },
  {
    "text": "astute reader will have noticed is that we left room in the API for metadata on each IP address so the IP address is not",
    "start": "4319130",
    "end": "4327020"
  },
  {
    "text": "a list of strings it's a list of structs where one of the members is the string is the IP so we have room for meta",
    "start": "4327020",
    "end": "4332900"
  },
  {
    "text": "we can use to decorate this so we've left ourselves on a vector for doing this but we haven't done it yet",
    "start": "4332900",
    "end": "4339580"
  },
  {
    "text": "maybe I missed it what was like the purpose of the problem they were trying to solve with endpoints life like were",
    "start": "4355570",
    "end": "4361879"
  },
  {
    "text": "their endpoints that weren't needed they were being sent down or like why is it expected that it's helping you can you",
    "start": "4361879",
    "end": "4368809"
  },
  {
    "text": "say that one more time what was the problem that you were trying to solve like any such scale but like if you",
    "start": "4368809",
    "end": "4374929"
  },
  {
    "text": "still have to get all of the end points question is helping or are you were",
    "start": "4374929",
    "end": "4380389"
  },
  {
    "text": "there unused endpoints that you were getting because it's like a bulk API yeah that's a great question so the the",
    "start": "4380389",
    "end": "4385579"
  },
  {
    "text": "problem with the endpoints resource is that the full resource had to go across",
    "start": "4385579",
    "end": "4390649"
  },
  {
    "text": "the wire when a single endpoint inside that resource changed so a single IP",
    "start": "4390649",
    "end": "4396320"
  },
  {
    "text": "changes in that endpoints resource the whole thing goes across whereas an endpoint slice that whole thing is a",
    "start": "4396320",
    "end": "4402229"
  },
  {
    "text": "whole lot smaller Bowie",
    "start": "4402229",
    "end": "4407679"
  },
  {
    "text": "okay thanks okay so is there a reason",
    "start": "4408939",
    "end": "4415610"
  },
  {
    "text": "servers can't be both v4 and v6 so that you could have a friendly name and if",
    "start": "4415610",
    "end": "4421280"
  },
  {
    "text": "it's a v6 service or a v4 it'll be able to choose what it goes to and then a follow-up question is is there any",
    "start": "4421280",
    "end": "4428269"
  },
  {
    "text": "thought in making opt in for v4 so like by default every pod gets a v6 address",
    "start": "4428269",
    "end": "4433699"
  },
  {
    "text": "but it opts in to get a v4 address also so they on the first part we did that",
    "start": "4433699",
    "end": "4441709"
  },
  {
    "text": "mostly as a shortcut we thought we looked at the use cases that we had in front of us and we didn't have a",
    "start": "4441709",
    "end": "4447499"
  },
  {
    "text": "concrete use case for having a single service on two families that wasn't also solvable by having two services the",
    "start": "4447499",
    "end": "4454550"
  },
  {
    "text": "friendly name like we talked to a few customers and users and the friendly name didn't seem to be enough of a",
    "start": "4454550",
    "end": "4459679"
  },
  {
    "text": "motivation to take on the complexity of doing both at the same time we're still open to it if we find the use cases and",
    "start": "4459679",
    "end": "4465590"
  },
  {
    "text": "the demand for it the second question I think is not something we put a lot of",
    "start": "4465590",
    "end": "4472729"
  },
  {
    "text": "thought into honestly we left that at the network level for this United States Oh",
    "start": "4472729",
    "end": "4479210"
  },
  {
    "text": "yeah it's so the second question for the",
    "start": "4479210",
    "end": "4492210"
  },
  {
    "text": "second question kubernetes supports ipv6 single stack so I think a lot of the functionality is there to not get v4 if",
    "start": "4492210",
    "end": "4500160"
  },
  {
    "text": "you don't want v4 but that said it's going to be single stack throughout your entire cluster at this point we don't",
    "start": "4500160",
    "end": "4506640"
  },
  {
    "text": "really have a way of seeing that some pods should only get some addresses or some you know family and some pod",
    "start": "4506640",
    "end": "4512220"
  },
  {
    "text": "gathers that you can't really necessarily mix it up but you know I think we'd probably like to get there we",
    "start": "4512220",
    "end": "4518850"
  },
  {
    "text": "just need to kind of keep going through all the bits and api's and components and make sure that they're okay with",
    "start": "4518850",
    "end": "4524820"
  },
  {
    "text": "that I don't see any particular block for that kind of behavior it's just that's like you know phase six I just",
    "start": "4524820",
    "end": "4534690"
  },
  {
    "text": "had a quick question about the importance last thing you mentioned that there was a condition on hm points lice is the sort of intended use there to be",
    "start": "4534690",
    "end": "4541320"
  },
  {
    "text": "like replacing the old end point instead of having the like ready and not ready",
    "start": "4541320",
    "end": "4546420"
  },
  {
    "text": "in a single condition you'll end up with two endpoint slices one that has a condition of ready and one that has a condition of not ready is that the no",
    "start": "4546420",
    "end": "4552960"
  },
  {
    "text": "okay scared of this thing so yeah the",
    "start": "4552960",
    "end": "4558570"
  },
  {
    "text": "question is great right now an endpoint is either at a single endpoint referring",
    "start": "4558570",
    "end": "4565620"
  },
  {
    "text": "to a an IP is either ready or not ready and there's some D duping involved and I",
    "start": "4565620",
    "end": "4571830"
  },
  {
    "text": "think we lean towards if there's two that come in that are conflicting we",
    "start": "4571830",
    "end": "4577380"
  },
  {
    "text": "lean towards ready instead of not ready but I'd have to double check the code but there is only one representation of",
    "start": "4577380",
    "end": "4583740"
  },
  {
    "text": "an endpoint is the goal so we don't have two different ones that are ready or not ready",
    "start": "4583740",
    "end": "4590000"
  },
  {
    "text": "with the introduction of ipv6 and dual stack when do you see their phasing out of all the strategies - like V PCs and",
    "start": "4594200",
    "end": "4601880"
  },
  {
    "text": "everything when do you see that coming so it's easier for the user trusts to",
    "start": "4601880",
    "end": "4607730"
  },
  {
    "text": "have one IP and public key addressable at peak I don't know that we've really",
    "start": "4607730",
    "end": "4615470"
  },
  {
    "text": "made that a goal most of the users that we're talking to today",
    "start": "4615470",
    "end": "4620930"
  },
  {
    "text": "see dual stack sort of for the indefinite future there have been lots of conversations around NAT and NAT 4:6",
    "start": "4620930",
    "end": "4628460"
  },
  {
    "text": "and other encapsulations to make it less complicated on well you just push the",
    "start": "4628460",
    "end": "4633950"
  },
  {
    "text": "complexity somewhere else we haven't we haven't had a conversation really about",
    "start": "4633950",
    "end": "4639680"
  },
  {
    "text": "like what is the ultimate end goal of v6 at least if there has been that conversation I haven't been part of it",
    "start": "4639680",
    "end": "4645220"
  },
  {
    "text": "but I'd like with all these questions like they're great we'd love to hear requirements if people think they have",
    "start": "4645220",
    "end": "4650810"
  },
  {
    "text": "ideas for what we should do",
    "start": "4650810",
    "end": "4654220"
  },
  {
    "text": "thank you I'm not sure if the Osmonds joining the in the presentation but is there an API backward compatibility",
    "start": "4659260",
    "end": "4665840"
  },
  {
    "text": "strategy for moving to the wall stack the api compatibility story I'm actually",
    "start": "4665840",
    "end": "4672140"
  },
  {
    "text": "pretty proud of we spent a long time working on that mostly it works the way",
    "start": "4672140",
    "end": "4678890"
  },
  {
    "text": "you would expect it to work and to do that we had to sort of define what we thought the various use cases were with",
    "start": "4678890",
    "end": "4685040"
  },
  {
    "text": "old clients and new servers and converting from old to new and we explicitly call that all the different",
    "start": "4685040",
    "end": "4691400"
  },
  {
    "text": "edges so if you have an old client and you only know the singular IP address and you mutate that IP address will sink",
    "start": "4691400",
    "end": "4697910"
  },
  {
    "text": "it into the zeroth entry of the list if you know the new new API and you write",
    "start": "4697910",
    "end": "4703250"
  },
  {
    "text": "the list but not the singular then we'll sink that back out we can tell which changed on an update and if you change",
    "start": "4703250",
    "end": "4709580"
  },
  {
    "text": "them both and you change them in compatibly then we'll actually fail that the API call so mostly it's gonna do",
    "start": "4709580",
    "end": "4715460"
  },
  {
    "text": "what you expect it to do if you have a dumb client and if you have an enlightened client it'll be the same oh",
    "start": "4715460",
    "end": "4725690"
  },
  {
    "text": "and yes I sort of as the tiebreaker if we get stuck with both we choose the v4",
    "start": "4725690",
    "end": "4732880"
  },
  {
    "text": "but that's a really corner case so when one cares about that you're stuck",
    "start": "4732880",
    "end": "4738560"
  },
  {
    "text": "so the odorous talk Vanitas allows to consist the Craster with the ipv4 only",
    "start": "4738560",
    "end": "4744440"
  },
  {
    "text": "host with the ipv6 host or in case of the we when we create the dearest talk",
    "start": "4744440",
    "end": "4750470"
  },
  {
    "text": "at an all node should support it happy default on them ipv6 the assumption now",
    "start": "4750470",
    "end": "4756830"
  },
  {
    "text": "is that all nodes are dual stack right where we're willing to see where this goes now right we we defined the first",
    "start": "4756830",
    "end": "4764210"
  },
  {
    "text": "three phases we're still in the middle of implementing phase 3 I assume that there's probably 10 more phases beyond",
    "start": "4764210",
    "end": "4771020"
  },
  {
    "text": "that as we figure out more and more of the user requirements",
    "start": "4771020",
    "end": "4775270"
  },
  {
    "text": "yeah this is not an ipv6 question so it's related to the to the changes to",
    "start": "4781949",
    "end": "4788079"
  },
  {
    "text": "the gateways route and services so that",
    "start": "4788079",
    "end": "4793090"
  },
  {
    "text": "yeah do you think that this change or this proposal may restrict extensibility",
    "start": "4793090",
    "end": "4798400"
  },
  {
    "text": "to other use cases because like I feel that the ingress concept is it's",
    "start": "4798400",
    "end": "4803860"
  },
  {
    "text": "abstract enough and you can introduce several other use cases but with the Gateway routes it feels like you're",
    "start": "4803860",
    "end": "4812050"
  },
  {
    "text": "restricting into a certain model that might not be extensible I don't know so",
    "start": "4812050",
    "end": "4817659"
  },
  {
    "text": "that's a good question you should definitely contribute in terms of your use cases and that's kind",
    "start": "4817659",
    "end": "4823449"
  },
  {
    "text": "of we're at the stage where we're sort of sketching a framework and then collecting the use cases and making sure",
    "start": "4823449",
    "end": "4828969"
  },
  {
    "text": "that the mapping is okay one thing is that if you find that ingress is perfectly valid for your use case then",
    "start": "4828969",
    "end": "4835389"
  },
  {
    "text": "it still will exist and be supported as a ga API so that thing will never be deprecated or removed in favor of the",
    "start": "4835389",
    "end": "4842230"
  },
  {
    "text": "new API I hope that everything you can express an ingress you can express",
    "start": "4842230",
    "end": "4848590"
  },
  {
    "text": "better in the new gateways plus routes API the thing that got me excited about",
    "start": "4848590",
    "end": "4853630"
  },
  {
    "text": "the new API is I see it the ability to represent the lower level like l4 things",
    "start": "4853630",
    "end": "4859510"
  },
  {
    "text": "that service does like service is a terrible API it's a bunch of different",
    "start": "4859510",
    "end": "4864880"
  },
  {
    "text": "concepts that all got glued together into a single resource I see this as a possible way of breaking that up so that",
    "start": "4864880",
    "end": "4871360"
  },
  {
    "text": "we can actually have a cleaner API to the l4 constructs also but if you if you",
    "start": "4871360",
    "end": "4876489"
  },
  {
    "text": "can think of a use case that is representable in some other way that isn't in the Gateway system then we want",
    "start": "4876489",
    "end": "4881500"
  },
  {
    "text": "to know and and we're explicitly adding a bunch of extension points so that people can take their implementations",
    "start": "4881500",
    "end": "4887380"
  },
  {
    "text": "and and do crazy things without resorting to annotation thank you this",
    "start": "4887380",
    "end": "4892989"
  },
  {
    "text": "is another question about that couldn't be the illusion of ingress that segues on from that as well as better being",
    "start": "4892989",
    "end": "4899050"
  },
  {
    "text": "able to express a separation between l 4 and l 7 constructs is there any thought to opening up ingress to a wider range",
    "start": "4899050",
    "end": "4904840"
  },
  {
    "text": "of l 7 protocols there are other l7 protocols in HTTP F curve and his concepts of stuff you wanna do an",
    "start": "4904840",
    "end": "4910630"
  },
  {
    "text": "ingress is there any thinking of that yeah so you should look at the sketch to",
    "start": "4910630",
    "end": "4915699"
  },
  {
    "text": "see that that was one of the provisions we want to add in is that not just HTTP",
    "start": "4915699",
    "end": "4921250"
  },
  {
    "text": "routing but different other routings there are a number of ideas floating around out there the most important of",
    "start": "4921250",
    "end": "4927760"
  },
  {
    "text": "which is you just simply are able to specify the protocol which I think doesn't quite exist today in any",
    "start": "4927760",
    "end": "4933460"
  },
  {
    "text": "official API but remember one of the",
    "start": "4933460",
    "end": "4938889"
  },
  {
    "text": "extension points is in the routes resource so you can actually like in theory you could build your own traffic",
    "start": "4938889",
    "end": "4945880"
  },
  {
    "text": "management system that routes the you know some traffic from a gateway into a my sequel route or whatever whatever",
    "start": "4945880",
    "end": "4952420"
  },
  {
    "text": "crazy route you're thinking of in the backend and that doesn't actually need to be standardized by us or by anybody",
    "start": "4952420",
    "end": "4957610"
  },
  {
    "text": "you can go do your own thing via extension CR DS that's one of the objectives oh yeah thanks for the talk I",
    "start": "4957610",
    "end": "4965590"
  },
  {
    "text": "just want to ask I guess in retrospect if you could kind of go with this alternate reality with the kind of",
    "start": "4965590",
    "end": "4972219"
  },
  {
    "text": "information you know how would you go about doing that kubernetes networking different like Tim you mentioned kind of getting rid of services or kind of",
    "start": "4972219",
    "end": "4978550"
  },
  {
    "text": "changing it up are there other components that you kind of get rid of or tweak or just not think about it in general services is my",
    "start": "4978550",
    "end": "4988389"
  },
  {
    "text": "biggest one yep yes it's become really complicated to think about how to add",
    "start": "4988389",
    "end": "4993699"
  },
  {
    "text": "anything to service because of the way it intersects with all of the other things in service and there are known",
    "start": "4993699",
    "end": "5000449"
  },
  {
    "text": "bugs for example in the rest logic around service where immutable fields become mutable if you do the right sort",
    "start": "5000449",
    "end": "5006389"
  },
  {
    "text": "of ballet dance and they're really hard to fix because of compatibility reasons",
    "start": "5006389",
    "end": "5012440"
  },
  {
    "text": "so yes I would love to burn service to the ground and start that one over",
    "start": "5012440",
    "end": "5018050"
  },
  {
    "text": "ingress was originally designed sort of to be what Bowie is describing here but",
    "start": "5018050",
    "end": "5024630"
  },
  {
    "text": "we didn't have the follow-through or the sort of the vision to to see how to do it correctly also we didn't have C Rd at",
    "start": "5024630",
    "end": "5030659"
  },
  {
    "text": "the time so that made it very difficult to think about extensibility that way so yeah knowing what we do now I think",
    "start": "5030659",
    "end": "5036719"
  },
  {
    "text": "those are the the two biggest things sort of orthogonal inputs to services",
    "start": "5036719",
    "end": "5041969"
  },
  {
    "text": "and higher-level extensibility and and maybe more Omnibus Network driving like",
    "start": "5041969",
    "end": "5048239"
  },
  {
    "text": "the network drivers right now are kind of spread all over the place there's the cni driver a little bit of logic in",
    "start": "5048239",
    "end": "5053280"
  },
  {
    "text": "cubelet there's cube proxy there's your network policy and they all sort of do things that interact with each other and",
    "start": "5053280",
    "end": "5058920"
  },
  {
    "text": "sort of poorly defined ways if I could go back I might up level that ones so",
    "start": "5058920",
    "end": "5072120"
  },
  {
    "text": "for the new features we introduced any be impacted with the soviet mesh anthos",
    "start": "5072120",
    "end": "5078780"
  },
  {
    "text": "you guys doing such a features an endpoint slice and increase ib affected",
    "start": "5078780",
    "end": "5086190"
  },
  {
    "text": "to the soviet mesh you guys offering the",
    "start": "5086190",
    "end": "5091290"
  },
  {
    "text": "the gateway stuff is explicitly not about service mesh a lot of the concepts overlap but we're really focused on",
    "start": "5091290",
    "end": "5098130"
  },
  {
    "text": "ingress sort of true what we traditionally call north-south that's the feature set that we're focused on",
    "start": "5098130",
    "end": "5103699"
  },
  {
    "text": "some of the service mesh implementers are participating now or or talking about participating and they're looking",
    "start": "5103699",
    "end": "5109380"
  },
  {
    "text": "at whether this api can define sort of the the service mesh api and in fact i",
    "start": "5109380",
    "end": "5115500"
  },
  {
    "text": "did a talk this weekend at the rejects conference on this topic a little bit",
    "start": "5115500",
    "end": "5120650"
  },
  {
    "text": "but service mesh is explicitly not the goal with regard to endpoints slice i do",
    "start": "5120650",
    "end": "5127530"
  },
  {
    "text": "know that people are looking at it basically as these primitives from kubernetes get a little bit more sophisticated there might be a lot of",
    "start": "5127530",
    "end": "5133739"
  },
  {
    "text": "reuse just then you don't have to maintain to api's that do kind of the same thing yeah that's a great point the",
    "start": "5133739",
    "end": "5141000"
  },
  {
    "text": "the thing i've been thinking a lot about in the last couple of months is incremental adoption making it easier",
    "start": "5141000",
    "end": "5146040"
  },
  {
    "text": "for people to sort of grow from basic use cases into more advanced use cases and frankly kubernetes has made it very",
    "start": "5146040",
    "end": "5152280"
  },
  {
    "text": "difficult to sort of evolve your usage of kubernetes you know you hit the end of the runway on service and then you",
    "start": "5152280",
    "end": "5157830"
  },
  {
    "text": "have to stop everything you're doing and move into ingress and change the mechanism and change the controller and",
    "start": "5157830",
    "end": "5162930"
  },
  {
    "text": "change the api and go retest and recall and benchmark and then you can carry on sort of where you left off and then when",
    "start": "5162930",
    "end": "5169380"
  },
  {
    "text": "you run out of the ingress run map you have to go into like a service mesh and you do the whole process over again",
    "start": "5169380",
    "end": "5175070"
  },
  {
    "text": "so I've been thinking a lot about how to make more incremental adoption and I think actually this the the gateway API",
    "start": "5175070",
    "end": "5181580"
  },
  {
    "text": "is a path towards that where you can start with your your gateway and when",
    "start": "5181580",
    "end": "5187610"
  },
  {
    "text": "you hit the end of the capabilities there you can change the class and now your class becomes an l7 class and you",
    "start": "5187610",
    "end": "5193670"
  },
  {
    "text": "suddenly are able to add more functionality through the extension points but you never had to go back and rewrite your API right and so this is",
    "start": "5193670",
    "end": "5201290"
  },
  {
    "text": "sort of my interest in it and I'm really I'm keen to drive on that model and every day every time I talk to people",
    "start": "5201290",
    "end": "5206900"
  },
  {
    "text": "they sort of nod their heads and they get it I hope we can deliver that",
    "start": "5206900",
    "end": "5212800"
  },
  {
    "text": "currently I'm a part of a container that interface feature team the we currently",
    "start": "5214060",
    "end": "5222170"
  },
  {
    "text": "we are watching on the and endpoint resources and we are creating based on",
    "start": "5222170",
    "end": "5228560"
  },
  {
    "text": "that we are creating endpoint files and based on that we create flows so we use",
    "start": "5228560",
    "end": "5233870"
  },
  {
    "text": "ouvea switch to program the flows so basically we watch on the endpoint resources now that endpoint slices are",
    "start": "5233870",
    "end": "5240380"
  },
  {
    "text": "coming so what are this I mean do we I mean it's still the endpoints will be there the way how do we watch for the",
    "start": "5240380",
    "end": "5247880"
  },
  {
    "text": "resources I mean just what's the transition point Rob yeah yeah that's a",
    "start": "5247880",
    "end": "5257000"
  },
  {
    "text": "great question I meant to cover that in more detail in the actual talk but endpoints will continue to exist for the foreseeable future",
    "start": "5257000",
    "end": "5262880"
  },
  {
    "text": "of course if you want improved performance greater scalability use the endpoint slice API if at all possible",
    "start": "5262880",
    "end": "5269510"
  },
  {
    "text": "but endpoints will continue to exist and provide that backwards compatibility for a long time",
    "start": "5269510",
    "end": "5275650"
  },
  {
    "text": "what's up thank you to everyone if you have more questions like [Applause]",
    "start": "5281960",
    "end": "5289890"
  }
]
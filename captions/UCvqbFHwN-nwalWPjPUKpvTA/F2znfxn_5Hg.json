[
  {
    "start": "0",
    "end": "101000"
  },
  {
    "text": "okay so hello everyone my name is Yan I'm software engineer at Google and I've been working on the GRDC project for the",
    "start": "30",
    "end": "7710"
  },
  {
    "text": "past few years I think it's been almost four now my talk today is called G RPC",
    "start": "7710",
    "end": "14309"
  },
  {
    "text": "load balancing on kubernetes and here's what you're gonna do so initially I",
    "start": "14309",
    "end": "20010"
  },
  {
    "text": "wanted to give you an overview of some basic load balancing concepts and tell",
    "start": "20010",
    "end": "25320"
  },
  {
    "text": "you how they apply to G RPC traffic and kubernetes environments specifically because there are some specific",
    "start": "25320",
    "end": "31529"
  },
  {
    "text": "customers mentioning Oh choosing the right load balancing solution for your application depends on",
    "start": "31529",
    "end": "38250"
  },
  {
    "text": "many factors and there's no really one-size-fits-all solution so instead of",
    "start": "38250",
    "end": "44700"
  },
  {
    "text": "just telling you what load balancing solution you should use for your application I'm gonna give you an overview of what's",
    "start": "44700",
    "end": "50700"
  },
  {
    "text": "available what's out there and I'll mention the pros and cons of those approaches and then you can hopefully",
    "start": "50700",
    "end": "56760"
  },
  {
    "text": "choose for yourself even though most of the concepts are actually relatively",
    "start": "56760",
    "end": "62850"
  },
  {
    "text": "simple I think it's always useful to get your hands a little bit dirty so I've",
    "start": "62850",
    "end": "68460"
  },
  {
    "text": "prepared a little demo that's gonna demonstrate some of the basic load balancing scenarios I now also show a",
    "start": "68460",
    "end": "75659"
  },
  {
    "text": "few useful tricks that relate to specifically G RPC traffic and",
    "start": "75659",
    "end": "81810"
  },
  {
    "text": "specifically the G RPC environment okay",
    "start": "81810",
    "end": "87240"
  },
  {
    "text": "clicker doesn't work as always",
    "start": "87240",
    "end": "90770"
  },
  {
    "text": "interesting yeah okay anyway so I'm",
    "start": "93920",
    "end": "103680"
  },
  {
    "start": "101000",
    "end": "101000"
  },
  {
    "text": "pretty sure everyone knows what load balancing is oh so I'll just do a quick review so first of all load balancing is",
    "start": "103680",
    "end": "112070"
  },
  {
    "text": "one of the key techniques how to build scalable services obviously oh and the",
    "start": "112070",
    "end": "118079"
  },
  {
    "text": "idea is that you have a client and you have multiple possible backends to talk to you and you just obviously are",
    "start": "118079",
    "end": "123719"
  },
  {
    "text": "balanced log between them by like sending some requests to some of the backends and sending other requests to",
    "start": "123719",
    "end": "130590"
  },
  {
    "text": "other backends we do that too improve the overall throughput of a service and also quite possibly to",
    "start": "130590",
    "end": "138310"
  },
  {
    "text": "decrease the latency of our request oh and one of the side effects is that we",
    "start": "138310",
    "end": "143769"
  },
  {
    "text": "also avoid overloading one of the backends because like if all the requests went all the way always to the",
    "start": "143769",
    "end": "151810"
  },
  {
    "text": "same back end you know it's not gonna end up well oh one of the or some of the",
    "start": "151810",
    "end": "158139"
  },
  {
    "text": "perhaps a little bit less obvious things is when you set up load balancing",
    "start": "158139",
    "end": "163480"
  },
  {
    "text": "correctly oh you're gonna get some of the interesting features you want for",
    "start": "163480",
    "end": "168970"
  },
  {
    "text": "your application for free oh so you'll get improved tolerance for banking failures because with correctly set up",
    "start": "168970",
    "end": "176739"
  },
  {
    "text": "load balancing if one of the backends goes down or all the traffic it's is seamlessly rerouted to other backends",
    "start": "176739",
    "end": "184180"
  },
  {
    "text": "and you'll also get the possibility to basically update versions of your",
    "start": "184180",
    "end": "189519"
  },
  {
    "text": "service on the fly by or using techniques like rolling updates and similar things know specifically when it",
    "start": "189519",
    "end": "199030"
  },
  {
    "text": "comes to the kubernetes environment Oh kubernetes is really useful for",
    "start": "199030",
    "end": "204930"
  },
  {
    "text": "deploying applications with the micro service architecture and because with",
    "start": "204930",
    "end": "212919"
  },
  {
    "text": "micro service architecture you usually have multiple components in your system and so many of those components actually",
    "start": "212919",
    "end": "219909"
  },
  {
    "text": "have multiple replicas one way to think of it is if you're deploying able to get application to kubernetes you can't",
    "start": "219909",
    "end": "227079"
  },
  {
    "text": "really not use load balancing it's just question of like if you're doing it right or not so one of the key",
    "start": "227079",
    "end": "234879"
  },
  {
    "start": "232000",
    "end": "232000"
  },
  {
    "text": "distinctions when it comes to load balancing is so the distinction between",
    "start": "234879",
    "end": "241150"
  },
  {
    "text": "the so called l 4 and l 7 l 7 sorry l 7 load balancing these labels are based on",
    "start": "241150",
    "end": "250150"
  },
  {
    "text": "the OSI network model and they basically described at what level in the hi model the load balancing is happening so the L",
    "start": "250150",
    "end": "259810"
  },
  {
    "text": "4 load balancer is so-called connection based and the l 7 is happening at the",
    "start": "259810",
    "end": "266710"
  },
  {
    "text": "application layer and the key difference is the difference",
    "start": "266710",
    "end": "275590"
  },
  {
    "text": "is basically the granularity at which the actual active load balancing is happening",
    "start": "275590",
    "end": "280990"
  },
  {
    "text": "so with the elf 4 load balancer the load balancing is happening any time you create a new tcp/ip connection and for",
    "start": "280990",
    "end": "288010"
  },
  {
    "text": "some of api's that actually might be fine so if you're talking for example about very common HTTP 1 rest api so",
    "start": "288010",
    "end": "296550"
  },
  {
    "text": "because we create new tcp/ip connections very often because of some of the",
    "start": "296640",
    "end": "302020"
  },
  {
    "text": "problems of HTTP 1 protocol like head-of-line blocking or the load",
    "start": "302020",
    "end": "307390"
  },
  {
    "text": "balancing actually ends up working quite well but this is not necessarily the case of G RPC because G RPC is basically",
    "start": "307390",
    "end": "315880"
  },
  {
    "text": "a thin layer on top of HTTP 2 protocol and every RPC call is a separate stream",
    "start": "315880",
    "end": "325450"
  },
  {
    "text": "on the same tcp/ip connection and this is one of the techniques how G RPC achieves good performance so performance",
    "start": "325450",
    "end": "332620"
  },
  {
    "text": "is great but the bottom line is if you create a G RPC channel which is",
    "start": "332620",
    "end": "338590"
  },
  {
    "text": "basically an abstraction for a tcp/ip connection and you're talking to a back-end or like once you once you",
    "start": "338590",
    "end": "346390"
  },
  {
    "text": "connect the channel all your our pcs are gonna go to the same back-end so there's basically gonna be no load balancing",
    "start": "346390",
    "end": "351610"
  },
  {
    "text": "happening and obviously we want to do the load balancing at the per RPC level",
    "start": "351610",
    "end": "360330"
  },
  {
    "text": "one potential problem in kubernetes environment is that kubernetes has a",
    "start": "360390",
    "end": "365590"
  },
  {
    "text": "built in load balancing feature but this feature only operates at the at the l4",
    "start": "365590",
    "end": "371860"
  },
  {
    "text": "level so when you set up a service of type cluster IP or load balancer it's",
    "start": "371860",
    "end": "377800"
  },
  {
    "text": "only gonna be l4 and that might be a problem another important distinction of",
    "start": "377800",
    "end": "383560"
  },
  {
    "start": "381000",
    "end": "381000"
  },
  {
    "text": "load balancers is so basically we're in the data path you've put the load balancer and there's so-called proxy",
    "start": "383560",
    "end": "390280"
  },
  {
    "text": "load balancing which basically means you have a client and you have the backend and then you put the proxy right in",
    "start": "390280",
    "end": "396070"
  },
  {
    "text": "right in between those what's good about this solution is that",
    "start": "396070",
    "end": "403030"
  },
  {
    "text": "you get a simple client which doesn't have to be a variable load balancing at all and then although possibly",
    "start": "403030",
    "end": "409720"
  },
  {
    "text": "complicated logic or Stace into proxy or you also don't have to trust your",
    "start": "409720",
    "end": "415000"
  },
  {
    "text": "clients oh but on the other hand he'll get higher latency and overhead",
    "start": "415000",
    "end": "423750"
  },
  {
    "text": "I'll kubernetes there's there's a good way how to deploy the proxy and it's called the so-called citecar proxy which",
    "start": "424680",
    "end": "431860"
  },
  {
    "text": "basically means in the same pot you deploy you deploy the proxy right next",
    "start": "431860",
    "end": "438430"
  },
  {
    "text": "to your service the other approach is so called client load balancing and this",
    "start": "438430",
    "end": "444370"
  },
  {
    "text": "one is especially useful when you really want to achieve low latency and low overhead and in this approach the client",
    "start": "444370",
    "end": "453190"
  },
  {
    "text": "is fully aware of what all the backends are and and implement some kind of strategy to choose which back-end to",
    "start": "453190",
    "end": "459220"
  },
  {
    "text": "talk to you for every given RPC so one",
    "start": "459220",
    "end": "470650"
  },
  {
    "text": "of the problems with so the client side load balancing is that if the logic of",
    "start": "470650",
    "end": "477250"
  },
  {
    "text": "load balancing gets too complicated you basically need to make it into your client and with GRP see we have",
    "start": "477250",
    "end": "483940"
  },
  {
    "text": "implementation in ten languages so if you wanted to have a complex logic that",
    "start": "483940",
    "end": "489220"
  },
  {
    "text": "for example involves deciding which",
    "start": "489220",
    "end": "495070"
  },
  {
    "text": "back-end to route to based on what's the current server load or you know which",
    "start": "495070",
    "end": "500550"
  },
  {
    "text": "which back end has already handled the most traffic you would have to implement",
    "start": "500550",
    "end": "506650"
  },
  {
    "start": "505000",
    "end": "505000"
  },
  {
    "text": "all this logic in a simple client in in all the languages that G RPC is",
    "start": "506650",
    "end": "514570"
  },
  {
    "text": "available in and this this might be a problem so there's actually workaround",
    "start": "514570",
    "end": "520900"
  },
  {
    "text": "for this kind of problem and it's basically that you take all the non-trivial load balancing logic and you",
    "start": "520900",
    "end": "528640"
  },
  {
    "text": "move it out to an external component so another picture you can see that you",
    "start": "528640",
    "end": "533890"
  },
  {
    "text": "have so-called leukocyte loo controller and",
    "start": "533890",
    "end": "538980"
  },
  {
    "text": "the way it works is the G RPC client before it connects to all the back ends",
    "start": "539220",
    "end": "544330"
  },
  {
    "text": "it works its first establishes a connection to look a site controller or and it's going to be a streaming RPC and",
    "start": "544330",
    "end": "551940"
  },
  {
    "text": "the leucocyte the load controller tells GA RPC client what are the available backends and what's the right strategy",
    "start": "551940",
    "end": "559540"
  },
  {
    "text": "to balance load between them this is actually an approach that's used quite heavily internally at Google and",
    "start": "559540",
    "end": "567010"
  },
  {
    "text": "it's been battle tested on many big services I also have to mention a model",
    "start": "567010",
    "end": "575410"
  },
  {
    "start": "573000",
    "end": "573000"
  },
  {
    "text": "that's gaining a lot of popularity recently so it's the service mesh model oh I hope everyone is familiar with what",
    "start": "575410",
    "end": "584620"
  },
  {
    "text": "the service mat service mesh is can you just like raisins just to get an idea",
    "start": "584620",
    "end": "589830"
  },
  {
    "text": "okay so yeah good portion I'm gonna talk just specifically about the load",
    "start": "589830",
    "end": "594940"
  },
  {
    "text": "balancing part because service mesh can give you a lot of other features that",
    "start": "594940",
    "end": "600190"
  },
  {
    "text": "are useful so in this diagram you have",
    "start": "600190",
    "end": "606430"
  },
  {
    "text": "the G RPC client and all the traffic from that client transparently goes",
    "start": "606430",
    "end": "611710"
  },
  {
    "text": "through a proxy and the proxy talks to a so called cluster manager which can be for example a steel pilot and this",
    "start": "611710",
    "end": "621850"
  },
  {
    "text": "cluster manager basically decides what's the load blending strategy gonna be and the proxy implements that and it talks",
    "start": "621850",
    "end": "628090"
  },
  {
    "text": "to all the backends without the client knowing so it's so this is basically a",
    "start": "628090",
    "end": "636420"
  },
  {
    "text": "proxy load balancing solution a little bit on steroids that the disadvantages",
    "start": "636420",
    "end": "642340"
  },
  {
    "text": "is that you are basically paying two times the proxy cost because the the call needs to go to through proxies to",
    "start": "642340",
    "end": "649830"
  },
  {
    "text": "proxies are not necessarily you don't necessarily need two proxies for load",
    "start": "649830",
    "end": "657880"
  },
  {
    "text": "balancing itself but for some other things like encryption in the service mesh it's something that you you",
    "start": "657880",
    "end": "663340"
  },
  {
    "text": "actually need okay so that was the theory let's look",
    "start": "663340",
    "end": "669649"
  },
  {
    "start": "665000",
    "end": "665000"
  },
  {
    "text": "at some of the load balancing solution that you can use with gr PC so from proxy load balancing we have the like",
    "start": "669649",
    "end": "677240"
  },
  {
    "text": "the two most popular proxies that you can use our envoy and nginx o envoy is",
    "start": "677240",
    "end": "684620"
  },
  {
    "text": "so relatively new project that saw recently has so gained a lot of momentum",
    "start": "684620",
    "end": "692050"
  },
  {
    "text": "and some of the differentiating factors about it is that it it's high",
    "start": "692050",
    "end": "697850"
  },
  {
    "text": "performance but at the same time it's possible to configure the Envoy proxy dynamically so and this was basically",
    "start": "697850",
    "end": "703880"
  },
  {
    "text": "the example I showed with the service mesh so in your deployment you can have",
    "start": "703880",
    "end": "709070"
  },
  {
    "text": "a bunch of proxies that when they start up they talk to the cluster manager and they get their configuration from there",
    "start": "709070",
    "end": "715430"
  },
  {
    "text": "so it actually works a little bit like the DHCP configuration in your network",
    "start": "715430",
    "end": "722410"
  },
  {
    "text": "nginx is another very popular project that's been around for a while and they",
    "start": "723850",
    "end": "730339"
  },
  {
    "text": "recently added a full G RPC support so you can actually specify some of the",
    "start": "730339",
    "end": "736880"
  },
  {
    "text": "nginx rules Oh specifically for JRPG traffic for doing proxy load balancing",
    "start": "736880",
    "end": "743420"
  },
  {
    "text": "in a service match or you can use the combination of envoy and sto sto is",
    "start": "743420",
    "end": "749900"
  },
  {
    "text": "basically the cluster manager and envoy is the proxy or you can use the linker D",
    "start": "749900",
    "end": "756290"
  },
  {
    "text": "project and they're obviously like many other service meshes but I'm just trying",
    "start": "756290",
    "end": "761779"
  },
  {
    "text": "to mention though the ones I think are having the most momentum or you know are",
    "start": "761779",
    "end": "767420"
  },
  {
    "text": "the most popular currently o for simple",
    "start": "767420",
    "end": "773000"
  },
  {
    "text": "or for client load balancing G RPC like",
    "start": "773000",
    "end": "779029"
  },
  {
    "text": "the vanilla version of G RPC has a implementation of a simple around throbbin load balancer in like all the",
    "start": "779029",
    "end": "785510"
  },
  {
    "text": "clients so energy RPC go G RPC Java and the ERP CC core or you have you have",
    "start": "785510",
    "end": "793100"
  },
  {
    "text": "this implementation and",
    "start": "793100",
    "end": "796060"
  },
  {
    "text": "so okay sometimes happens but yeah so",
    "start": "799100",
    "end": "808350"
  },
  {
    "text": "you have the client load balancer and you you have the round-robin resolver",
    "start": "808350",
    "end": "814440"
  },
  {
    "text": "which basically works based on so",
    "start": "814440",
    "end": "822089"
  },
  {
    "text": "there's a resolver and the resolver results at the NS record and based on like all the DNS records it gets back",
    "start": "822089",
    "end": "829319"
  },
  {
    "text": "these are going to be the backends that the round-robin load balancer is gonna load the lens to so the other solution",
    "start": "829319",
    "end": "837300"
  },
  {
    "text": "is the load balance leukocyte client side load balancer that I showed before",
    "start": "837300",
    "end": "843920"
  },
  {
    "text": "and G RPC actually implements the so called GRP CLB protocol which is a",
    "start": "843920",
    "end": "850589"
  },
  {
    "text": "simple protocol buffer based G RPC protocol which can be used in the",
    "start": "850589",
    "end": "858209"
  },
  {
    "text": "scenario where there's a load balancer is moved to another component that next - oh that's basically not part of the",
    "start": "858209",
    "end": "868649"
  },
  {
    "text": "backends but it's it's it's a separate service one of the problems with the ERP",
    "start": "868649",
    "end": "878160"
  },
  {
    "text": "CLB load balancing solution is that even though the client is so fully available",
    "start": "878160",
    "end": "883649"
  },
  {
    "text": "in all the gr PC versions that are all currently available that we actually",
    "start": "883649",
    "end": "890310"
  },
  {
    "text": "don't have a implementation of the load balancing controller server because this",
    "start": "890310",
    "end": "896399"
  },
  {
    "text": "protocol is mostly used internally at Google right now so there are actually",
    "start": "896399",
    "end": "902130"
  },
  {
    "text": "two ways we could we could handle this one of them is basically implement the",
    "start": "902130",
    "end": "909029"
  },
  {
    "text": "ERP CLD server that the client can talk to you but because this protocol is",
    "start": "909029",
    "end": "918660"
  },
  {
    "text": "mostly used internally at Google and it's not a de facto standard like in the",
    "start": "918660",
    "end": "925860"
  },
  {
    "text": "open source world we actually think a better way is to adopt so called anvil",
    "start": "925860",
    "end": "931709"
  },
  {
    "text": "Universal data plane API which is also protocol buffer based it's it's kind of a similar",
    "start": "931709",
    "end": "938070"
  },
  {
    "text": "protocol but it already has adoption by or some of the but some of the like",
    "start": "938070",
    "end": "945600"
  },
  {
    "text": "existing open source project so it fits better in the in the whole ecosystem",
    "start": "945600",
    "end": "950959"
  },
  {
    "text": "with the universal data plane API support there's basically two possible",
    "start": "950959",
    "end": "959610"
  },
  {
    "text": "deployment scenarios and one of them is that you still use the proxy but the proxy does the load the leucocyte load",
    "start": "959610",
    "end": "966600"
  },
  {
    "text": "balancing by talking to the cluster controller and that's available right",
    "start": "966600",
    "end": "974130"
  },
  {
    "text": "now and we're actually going to see it in one of our examples and the other approach is that we will implement the",
    "start": "974130",
    "end": "982760"
  },
  {
    "text": "client for the universal data plane API right into G RPC and that's so basically",
    "start": "982760",
    "end": "990089"
  },
  {
    "text": "work in progress okay so that was the",
    "start": "990089",
    "end": "998899"
  },
  {
    "text": "that was the theory and now I will need to do a little bit of setup and I'll",
    "start": "998899",
    "end": "1004970"
  },
  {
    "text": "show you some examples I prepared all of these examples are available on github",
    "start": "1004970",
    "end": "1013160"
  },
  {
    "text": "so after the talk you'll be able to",
    "start": "1013160",
    "end": "1018980"
  },
  {
    "text": "check out like all the code and see what all the settings are oh we don't that much time here so",
    "start": "1018980",
    "end": "1025660"
  },
  {
    "text": "okay so the first scenario I'm gonna be showing is the simple round robin load",
    "start": "1038140",
    "end": "1043250"
  },
  {
    "start": "1039000",
    "end": "1039000"
  },
  {
    "text": "balancer or what do we need to do in order to set this up in kubernetes is so",
    "start": "1043250",
    "end": "1050440"
  },
  {
    "text": "when you deploy a service to communities you basically have multiple service types you can deploy and in this case",
    "start": "1050440",
    "end": "1057140"
  },
  {
    "text": "we're gonna use the headless service and the reason for that is that we want the kubernetes dns to expose multiple DNS",
    "start": "1057140",
    "end": "1065480"
  },
  {
    "text": "records for each of the replicas available for the service so that g RPC can basically resolve that dns record",
    "start": "1065480",
    "end": "1072740"
  },
  {
    "text": "all those dns records and then see that there's more backends to load lines - we",
    "start": "1072740",
    "end": "1082370"
  },
  {
    "text": "need to set the load balancing policy in the G RPC client and we basically do",
    "start": "1082370",
    "end": "1087410"
  },
  {
    "text": "that by setting a channel argument and we connect to the service as usual so",
    "start": "1087410",
    "end": "1094490"
  },
  {
    "text": "we're going to use basically the default name you use for naming services inside",
    "start": "1094490",
    "end": "1100370"
  },
  {
    "text": "kubernetes okay so I've done some prep",
    "start": "1100370",
    "end": "1113360"
  },
  {
    "text": "work so I basically have a simple gke",
    "start": "1113360",
    "end": "1119050"
  },
  {
    "text": "cluster so google kubernetes engine oh it's it's empty like nose so no services",
    "start": "1119050",
    "end": "1127700"
  },
  {
    "text": "are running so it's cube cg.o parts okay and you can see that the",
    "start": "1127700",
    "end": "1137600"
  },
  {
    "text": "cluster is empty so what I'm gonna do I'm gonna deploy or as a service first",
    "start": "1137600",
    "end": "1143990"
  },
  {
    "text": "and then I'm gonna deploy a client and I'll show you that the load balancing is actually happening so the client is a",
    "start": "1143990",
    "end": "1152330"
  },
  {
    "text": "really simple client written c-sharp and the only thing it does it basically",
    "start": "1152330",
    "end": "1157820"
  },
  {
    "text": "creates a a G RPC channel can actually",
    "start": "1157820",
    "end": "1162890"
  },
  {
    "text": "everyone see that even in the back row sounds good oh so you have a",
    "start": "1162890",
    "end": "1170000"
  },
  {
    "text": "or that that creates on only one channel and then basically keeps doing a simple",
    "start": "1170000",
    "end": "1175940"
  },
  {
    "text": "RPC on that channel and what's that supposed to demonstrate that oh when",
    "start": "1175940",
    "end": "1181220"
  },
  {
    "text": "you're even when you're on the same channel oh your calls are going to reach",
    "start": "1181220",
    "end": "1187789"
  },
  {
    "text": "different backends at each time Oh for the server source code it's basically a",
    "start": "1187789",
    "end": "1194360"
  },
  {
    "text": "really simple service that starts the server listens on a port and then",
    "start": "1194360",
    "end": "1202129"
  },
  {
    "text": "replies with its own IP so that we can see that we actually what replicas we",
    "start": "1202129",
    "end": "1207379"
  },
  {
    "text": "actually reached so I have a humble",
    "start": "1207379",
    "end": "1213110"
  },
  {
    "text": "definition of of the server I'm gonna be deploying and you can see the cluster IP",
    "start": "1213110",
    "end": "1218990"
  },
  {
    "text": "is set to none so that means we're gonna be setting up a headless service oh it's exposed to port 8000 oh I've already",
    "start": "1218990",
    "end": "1226940"
  },
  {
    "text": "pushed all the necessary doctor images to the container registry so I can just",
    "start": "1226940",
    "end": "1233419"
  },
  {
    "text": "go ahead and deploy the service now",
    "start": "1233419",
    "end": "1237008"
  },
  {
    "text": "service is gonna have three replicas and",
    "start": "1245950",
    "end": "1250320"
  },
  {
    "text": "now I'm gonna deploy the client that demonstrates the round-robin oh I'm",
    "start": "1251370",
    "end": "1258100"
  },
  {
    "text": "gonna use the target basically the regular kubernetes DNS name I'm going to",
    "start": "1258100",
    "end": "1265179"
  },
  {
    "text": "use an environment variable to set up what the current load balancing policy is okay so the client has started and",
    "start": "1265179",
    "end": "1282429"
  },
  {
    "text": "now I'm gonna quickly show",
    "start": "1282429",
    "end": "1285778"
  },
  {
    "text": "okay so as you can see or because I said there's three back ends and then though",
    "start": "1299500",
    "end": "1306679"
  },
  {
    "text": "all the calls basically round-robin around the three back ends that are currently available so if I show you",
    "start": "1306679",
    "end": "1315820"
  },
  {
    "text": "what the service replicas are okay so",
    "start": "1315820",
    "end": "1326210"
  },
  {
    "text": "you can see like these IP addresses correspond to the three end points that I've deployed for my service so that was",
    "start": "1326210",
    "end": "1333710"
  },
  {
    "text": "the so there was the simple round-robin",
    "start": "1333710",
    "end": "1341330"
  },
  {
    "text": "client site load balancer oh good thing about it is that it's really simple to",
    "start": "1341330",
    "end": "1347149"
  },
  {
    "text": "set up and works out of the box or the bad part is it doesn't take server load into account and handling those scale-up",
    "start": "1347149",
    "end": "1355340"
  },
  {
    "text": "functionality currently requires a little workaround on the server side because DNS is not really",
    "start": "1355340",
    "end": "1362350"
  },
  {
    "text": "dynamic and so you need to periodically every resolve all the backends in order",
    "start": "1362350",
    "end": "1368840"
  },
  {
    "text": "to get updates about what replicas are still available oh the other example I",
    "start": "1368840",
    "end": "1376100"
  },
  {
    "start": "1373000",
    "end": "1373000"
  },
  {
    "text": "want to show is so load balancing with sidecar proxy I'm gonna use envoi and",
    "start": "1376100",
    "end": "1381700"
  },
  {
    "text": "I'm gonna shoot to a variation of this the first one is so it's a non-void",
    "start": "1381700",
    "end": "1388700"
  },
  {
    "text": "proxy that's configured statically which is one of the ways you can configure envoy so I'm still gonna use the",
    "start": "1388700",
    "end": "1394700"
  },
  {
    "text": "headless service to expose although all",
    "start": "1394700",
    "end": "1399980"
  },
  {
    "text": "the replicas as a DNS entry the end of a poxy is going to be set up as a really",
    "start": "1399980",
    "end": "1405830"
  },
  {
    "text": "simple side cont container",
    "start": "1405830",
    "end": "1409148"
  },
  {
    "text": "so this is the configure of the greeter client with static envoi",
    "start": "1424039",
    "end": "1430380"
  },
  {
    "text": "Oh",
    "start": "1430380",
    "end": "1432650"
  },
  {
    "text": "in this scenario you can actually see",
    "start": "1438230",
    "end": "1452250"
  },
  {
    "text": "that there's two containers or in the in the gamble file and one of them is the actual greeter client and the other one",
    "start": "1452250",
    "end": "1458280"
  },
  {
    "text": "is the Envoy proxy that's deployed as a sidecar so that's the most important thing about it the static configuration",
    "start": "1458280",
    "end": "1465630"
  },
  {
    "text": "of envoy is is basically it uses the",
    "start": "1465630",
    "end": "1474030"
  },
  {
    "text": "round-robin load balancing policy and it's subtypes trig DNS which happens to be what we need right now",
    "start": "1474030",
    "end": "1479670"
  },
  {
    "text": "and it's gonna round robin or among all the backends",
    "start": "1479670",
    "end": "1485660"
  },
  {
    "text": "okay so these sub locks for the client I just ran okay and because I have I now",
    "start": "1527450",
    "end": "1533570"
  },
  {
    "text": "have two containers deployed in the same pot I need to specify with China which for which one I want to see the locks so",
    "start": "1533570",
    "end": "1540470"
  },
  {
    "text": "this is actually the greeter client because the other one is basically the sidecar proxy and again you can see that",
    "start": "1540470",
    "end": "1549340"
  },
  {
    "text": "I'm reaching multiple backends the next",
    "start": "1549340",
    "end": "1556340"
  },
  {
    "text": "configuration is is basically using envoi as a dynamic proxy so what I've",
    "start": "1556340",
    "end": "1561470"
  },
  {
    "text": "done in advance I've installed instance of Steel in this demo cluster and I can",
    "start": "1561470",
    "end": "1574340"
  },
  {
    "text": "also deploy a and voi",
    "start": "1574340",
    "end": "1582480"
  },
  {
    "text": "so dynamically configured and I'm gonna use the sto CTL kuben check command so",
    "start": "1582480",
    "end": "1591540"
  },
  {
    "text": "that basically means I take a a llamo definition that only contains my my",
    "start": "1591540",
    "end": "1598710"
  },
  {
    "text": "simple greeter client and the sto CTL group inject command is gonna edit the",
    "start": "1598710",
    "end": "1606060"
  },
  {
    "text": "sidecar definition into into my mo file",
    "start": "1606060",
    "end": "1611990"
  },
  {
    "text": "okay interesting excuse me oh thank you",
    "start": "1640390",
    "end": "1652890"
  },
  {
    "text": "actually someone stole my printed out notes right before the talk so oh thank",
    "start": "1652890",
    "end": "1661809"
  },
  {
    "text": "you so I see where some sto experts here",
    "start": "1661809",
    "end": "1667470"
  },
  {
    "text": "so I I have the dynamic envoy running",
    "start": "1672480",
    "end": "1677530"
  },
  {
    "text": "aside my greater client",
    "start": "1677530",
    "end": "1680940"
  },
  {
    "text": "and I'm going to show you the locks okay",
    "start": "1692900",
    "end": "1698360"
  },
  {
    "text": "and I actually forgot to deploy the the",
    "start": "1698360",
    "end": "1703550"
  },
  {
    "text": "service for that so",
    "start": "1703550",
    "end": "1706780"
  },
  {
    "text": "oh no it's actually fine",
    "start": "1720510",
    "end": "1724910"
  },
  {
    "text": "okay and you can still see that we are a lot of Lansing to multiple backends or another thing we could do is I can show",
    "start": "1730400",
    "end": "1736770"
  },
  {
    "text": "you that if I reconfigure the number of replicas",
    "start": "1736770",
    "end": "1741860"
  },
  {
    "text": "so for example I change the number of replicas of the creature server to just",
    "start": "1765750",
    "end": "1771920"
  },
  {
    "text": "1x and adjust one replicas and basically the configuration has picked up that we",
    "start": "1780830",
    "end": "1788330"
  },
  {
    "text": "shouldn't load blind student on existing replicas anymore",
    "start": "1788330",
    "end": "1792520"
  },
  {
    "text": "so that was the Envoy with we're",
    "start": "1803250",
    "end": "1808409"
  },
  {
    "text": "studying and in a dynamic configuration in a similar way we could set up the",
    "start": "1808409",
    "end": "1814500"
  },
  {
    "start": "1810000",
    "end": "1810000"
  },
  {
    "text": "whole scenario in our sto service mesh so for that we would also use the sto",
    "start": "1814500",
    "end": "1822419"
  },
  {
    "text": "CTL kuben check command to basically inject the sidecar next to both our",
    "start": "1822419",
    "end": "1829320"
  },
  {
    "text": "client and both our server and I've also",
    "start": "1829320",
    "end": "1836700"
  },
  {
    "start": "1834000",
    "end": "1834000"
  },
  {
    "text": "prepared an example of how to set up the",
    "start": "1836700",
    "end": "1843900"
  },
  {
    "text": "GRP CLB leukocyte load balancing but we're actually running out of time so I'm gonna skip that but all the examples",
    "start": "1843900",
    "end": "1850020"
  },
  {
    "text": "as I said are online so you're feel you're free to check out how to set that",
    "start": "1850020",
    "end": "1855450"
  },
  {
    "text": "up and experiment with your experimental kubernetes cluster as well I have two",
    "start": "1855450",
    "end": "1865830"
  },
  {
    "start": "1861000",
    "end": "1861000"
  },
  {
    "text": "more interesting things so one of them is the challenge of balancing streaming our pcs besides from unary calls G RPC",
    "start": "1865830",
    "end": "1876960"
  },
  {
    "text": "also supports so-called streaming also you have an RPC that supports multiple",
    "start": "1876960",
    "end": "1882020"
  },
  {
    "text": "requests and multiple responses and those RPGs can be a relatively",
    "start": "1882020",
    "end": "1888390"
  },
  {
    "text": "long-lived and that's that's one thing that that you need to keep in mind when you're designing your API because once",
    "start": "1888390",
    "end": "1895409"
  },
  {
    "text": "you start a streaming call there so even if you have l7 load balancers set up you",
    "start": "1895409",
    "end": "1901320"
  },
  {
    "text": "basically like you can't really change the backend that you're talking to you so some of the strategies how you can",
    "start": "1901320",
    "end": "1908159"
  },
  {
    "text": "now approach that is that you can restart your streaming calls periodically to basically make sure that",
    "start": "1908159",
    "end": "1913770"
  },
  {
    "text": "you load balance to our different backends each time or you can also use the max connection age setting and on",
    "start": "1913770",
    "end": "1920490"
  },
  {
    "text": "the server side to make sure this happens automatically for you the",
    "start": "1920490",
    "end": "1925620"
  },
  {
    "text": "Mexican ection age can be also used in scenarios where you can't really do",
    "start": "1925620",
    "end": "1931049"
  },
  {
    "text": "anything else than L for load balancing to kind of make L for load blending a little bit less worse for",
    "start": "1931049",
    "end": "1936930"
  },
  {
    "text": "your pc's purposes okay oh I'm almost out of time so I'm gonna",
    "start": "1936930",
    "end": "1946230"
  },
  {
    "start": "1939000",
    "end": "1939000"
  },
  {
    "text": "thank you for attention a few things that I wanted to point out is so tomorrow I'm gonna have office",
    "start": "1946230",
    "end": "1955830"
  },
  {
    "text": "hours in the CN CF booth which is in hall C now and I'm gonna be already there to answer any questions about GRP",
    "start": "1955830",
    "end": "1963480"
  },
  {
    "text": "so you might have not necessarily about just load balancing and Michael III will be having a talk birthday in the",
    "start": "1963480",
    "end": "1971460"
  },
  {
    "text": "afternoon and it's gonna be a gr PC deep dive it's gonna be oh about life of a gr",
    "start": "1971460",
    "end": "1977700"
  },
  {
    "text": "PC call and what were some interesting API choices in G our PC or it's mostly",
    "start": "1977700",
    "end": "1985830"
  },
  {
    "text": "for everyone but it's gonna be especially useful for people that want",
    "start": "1985830",
    "end": "1991200"
  },
  {
    "text": "to that our power users of G our PC or that maybe you want to become contributors oh I'll also ask you to fill out a",
    "start": "1991200",
    "end": "1999240"
  },
  {
    "text": "little sorry oh I don't know if you have time for questions still okay so any",
    "start": "1999240",
    "end": "2008240"
  },
  {
    "text": "questions I need to grab the mic oh",
    "start": "2008240",
    "end": "2013750"
  },
  {
    "text": "[Music]",
    "start": "2013750",
    "end": "2016880"
  },
  {
    "text": "thank you [Applause]",
    "start": "2022780",
    "end": "2030570"
  },
  {
    "text": "yeah thank you it was very good just one question about the examples in your",
    "start": "2030570",
    "end": "2037179"
  },
  {
    "text": "examples the client is on always within you know the same environment as the",
    "start": "2037179",
    "end": "2045419"
  },
  {
    "text": "server's I see okay so you basically mean okay so the question was about that",
    "start": "2045419",
    "end": "2050648"
  },
  {
    "text": "this is basically only internal load one thing within the cluster yes so if you wanted to do external load balancing you",
    "start": "2050649",
    "end": "2057190"
  },
  {
    "text": "basically and you want to do l7 load balancing you basically set up so called ingress in kubernetes oh and so you can",
    "start": "2057190",
    "end": "2066368"
  },
  {
    "text": "also use things like unveil proxy for that but unfortunately I didn't have enough time to cover that in the talk",
    "start": "2066369",
    "end": "2071740"
  },
  {
    "text": "but that's something that that can be done and the thing to look up is the",
    "start": "2071740",
    "end": "2077618"
  },
  {
    "text": "kubernetes ingress okay thanks",
    "start": "2077619",
    "end": "2082858"
  }
]
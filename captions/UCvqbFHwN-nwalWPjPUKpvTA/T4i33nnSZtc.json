[
  {
    "start": "0",
    "end": "110000"
  },
  {
    "text": "let's get started hello everyone welcome to stay here for the last the may not be",
    "start": "0",
    "end": "5730"
  },
  {
    "text": "the least session for this conference so this tree is introductory talk about the",
    "start": "5730",
    "end": "12320"
  },
  {
    "text": "how to youth share the GPU in the kubernetes clustering using a technology",
    "start": "12320",
    "end": "18180"
  },
  {
    "text": "of GPU that's very basic but I hope that the idea we introduced here would be",
    "start": "18180",
    "end": "24830"
  },
  {
    "text": "inspire you to pour more complicated work later so first of all let me",
    "start": "24830",
    "end": "31260"
  },
  {
    "text": "introduce our ourselves so my name's Henry Xin and the technical territory ember China Rd I'm based in",
    "start": "31260",
    "end": "38219"
  },
  {
    "text": "Beijing we are based in Beijing I'm the original creator of project Harbor the cloud native registry project which is",
    "start": "38219",
    "end": "45629"
  },
  {
    "text": "already a CN CF incubation project last year and my daily job is to for the",
    "start": "45629",
    "end": "51960"
  },
  {
    "text": "incubating new project in the emerging technologies like container colony tips",
    "start": "51960",
    "end": "57030"
  },
  {
    "text": "and also AI and all kind of stuff like brought Chinese dosa and today with me is my colleague yeah hi I'm yeah and I'm",
    "start": "57030",
    "end": "67380"
  },
  {
    "text": "also from China with Martin R&D team and before I joined the kubernetes I worked",
    "start": "67380",
    "end": "74220"
  },
  {
    "text": "for the OpenStack and I'm focusing on the nutrient component so glad to see",
    "start": "74220",
    "end": "79890"
  },
  {
    "text": "you guys here you know it's the last session today and also the last session",
    "start": "79890",
    "end": "85490"
  },
  {
    "text": "for euro for cube account Europe this year so nice to meet you okay so let's",
    "start": "85490",
    "end": "93750"
  },
  {
    "text": "guess with the content so no man who has access been part of few waves about AI",
    "start": "93750",
    "end": "99810"
  },
  {
    "text": "event Dom in the industry last couple decades about 2.8 talk to that case ago",
    "start": "99810",
    "end": "105840"
  },
  {
    "text": "sigh I was in the university that the my professor told me that we were in the",
    "start": "105840",
    "end": "111180"
  },
  {
    "start": "110000",
    "end": "208000"
  },
  {
    "text": "era of AI and it turned out that what that's all real not so realistic when we",
    "start": "111180",
    "end": "117149"
  },
  {
    "text": "were not quite there yet but most recently that we feel that it's a yes very closer to our like daily lives and",
    "start": "117149",
    "end": "122759"
  },
  {
    "text": "we have many applications that we can feel and touch in our daily work daily work at life so I promise bring as many",
    "start": "122759",
    "end": "129989"
  },
  {
    "text": "benefits like reducing human effort boost productivity and calls and so on right",
    "start": "129989",
    "end": "136170"
  },
  {
    "text": "um so here's just some concept about AI I'm not going to too deep into into it",
    "start": "136170",
    "end": "141329"
  },
  {
    "text": "but but generally speaking in the AI space we have three key elements in",
    "start": "141329",
    "end": "147900"
  },
  {
    "text": "order to succeed the first one is the data for training models the second one is the algorithm algorithm to construct",
    "start": "147900",
    "end": "154349"
  },
  {
    "text": "the models the third one is the computing power to create models so with",
    "start": "154349",
    "end": "160230"
  },
  {
    "text": "the proliferation of internet we have a huge amount of data already with the advancement of computing science",
    "start": "160230",
    "end": "166200"
  },
  {
    "text": "research we have very a new algorithm for the to the training I'm today I'll",
    "start": "166200",
    "end": "171419"
  },
  {
    "text": "talk we focus on the element the third element of computing power using GPU or",
    "start": "171419",
    "end": "176700"
  },
  {
    "text": "especially for the machine learning workflow on kubernetes so I'm sure many",
    "start": "176700",
    "end": "183959"
  },
  {
    "text": "of you have listened to many talks in this conference about many use cases of kubernetes one of the use case for",
    "start": "183959",
    "end": "190590"
  },
  {
    "text": "machine learning is the world use case of kubernetes the machine learning were low on or low for on kubernetes",
    "start": "190590",
    "end": "197370"
  },
  {
    "text": "so many machine learning work nodes can be encapsulated in or run as containers",
    "start": "197370",
    "end": "202560"
  },
  {
    "text": "like for the portability or the manageability benefit so running machine",
    "start": "202560",
    "end": "209849"
  },
  {
    "start": "208000",
    "end": "307000"
  },
  {
    "text": "learning were low on kubernetes could be a very good fit for this kind of below because kubernetes right now is the de",
    "start": "209849",
    "end": "217049"
  },
  {
    "text": "facto standard for containerized application for example some user may have models so one of the benefits is",
    "start": "217049",
    "end": "224879"
  },
  {
    "text": "that right from some of the user talked owners that many user they may have",
    "start": "224879",
    "end": "230849"
  },
  {
    "text": "vendors generating or creating models for them and all the spend and they need to play in the same pipeline of their",
    "start": "230849",
    "end": "237689"
  },
  {
    "text": "machine learning workload so need to put their workload into the same platform so kubernetes could be their natural choice",
    "start": "237689",
    "end": "244470"
  },
  {
    "text": "because once they once the machine learning train the model can be put on to run on the kubernetes it can become a",
    "start": "244470",
    "end": "251040"
  },
  {
    "text": "standard platform for them to integrate together so kubernetes could be a very",
    "start": "251040",
    "end": "256940"
  },
  {
    "text": "standard i we have a standardized platform for this machine learning were low and it's implicit it is available it",
    "start": "256940",
    "end": "262950"
  },
  {
    "text": "means that kubernetes is kind of service of communities a commodity in provided by many car service provider",
    "start": "262950",
    "end": "272060"
  },
  {
    "text": "so in in order to use the machine learning wallow in the kubernetes that",
    "start": "272150",
    "end": "277650"
  },
  {
    "text": "we need to take advantage of the device plug-in of the other of the kubernetes",
    "start": "277650",
    "end": "284940"
  },
  {
    "text": "in order to consume the computer celebrators for example like the GPU",
    "start": "284940",
    "end": "290160"
  },
  {
    "text": "FPGA or ASIC the idea is simple things worse than the document there in the",
    "start": "290160",
    "end": "295680"
  },
  {
    "text": "inner kubernetes however there's some limitation for the GPU scheduling in",
    "start": "295680",
    "end": "300690"
  },
  {
    "text": "kubernetes the first one is the exclusive assignment which means that",
    "start": "300690",
    "end": "305790"
  },
  {
    "text": "once you assign a GPO resource to a particular port you can no longer be assigned to other key other other ports",
    "start": "305790",
    "end": "311490"
  },
  {
    "start": "307000",
    "end": "406000"
  },
  {
    "text": "that means that you cannot share and the other restriction or limitation is that",
    "start": "311490",
    "end": "316950"
  },
  {
    "text": "there's no fractional assignment for example you see video you can have point 0 upon points point 30.5 resource",
    "start": "316950",
    "end": "324750"
  },
  {
    "text": "assigned to a port but in GP we can only have the whole number one two three something like that so that would create",
    "start": "324750",
    "end": "330780"
  },
  {
    "text": "some kind of limitation or not flexibility in the you know in the use to the application situation so I also",
    "start": "330780",
    "end": "338669"
  },
  {
    "text": "in in the in the community we're seeing that there's a lot of people trying to walk around with this limitation one of",
    "start": "338669",
    "end": "344340"
  },
  {
    "text": "the workaround is to call a model stuffing the idea is to put all the all kinds of models into a big container to",
    "start": "344340",
    "end": "351300"
  },
  {
    "text": "encapsulate all the kind of training models and then you share that it's so",
    "start": "351300",
    "end": "356430"
  },
  {
    "text": "that it can be run on a kubernetes to share the same cpu same 7gb you so you're seeing that a lot request or",
    "start": "356430",
    "end": "363200"
  },
  {
    "text": "requirement for chiranjeevi or in a Cuban 80s platform the community so",
    "start": "363200",
    "end": "369800"
  },
  {
    "text": "sharing the GPU can help us the increase the utilization and you have the pro flexibility but there's not so satisfied",
    "start": "369800",
    "end": "378930"
  },
  {
    "text": "solution so far so the existing there's some existing solution that we see in the community I says the they may have",
    "start": "378930",
    "end": "387840"
  },
  {
    "text": "partially solved the problem by sharing the sharing the GB resource across different workload different parts but",
    "start": "387840",
    "end": "395030"
  },
  {
    "text": "one fundamentally when one restriction is that they don't have isolation or no QoS guarantee",
    "start": "395030",
    "end": "401150"
  },
  {
    "text": "that means that your workload may be affecting each other or coded the noisy neighbor a problem so our solution here",
    "start": "401150",
    "end": "408290"
  },
  {
    "start": "406000",
    "end": "505000"
  },
  {
    "text": "is defining used to using a technique called virtual GPU to help to address",
    "start": "408290",
    "end": "414979"
  },
  {
    "text": "these issues so the GPU virtualization is not something new it's just the",
    "start": "414979",
    "end": "420460"
  },
  {
    "text": "similar to the CPU virtualization so I think many of you are familiar with the civilizations like virtual machine right",
    "start": "420460",
    "end": "427970"
  },
  {
    "text": "so in most imagine you can separate your CPU and as used by different workloads different users and in GPU we can abort",
    "start": "427970",
    "end": "434810"
  },
  {
    "text": "realizations right now there are many different vendors providing such such mechanism for the virtualization or GPU",
    "start": "434810",
    "end": "440449"
  },
  {
    "text": "like the media AMD Intel and sharing GPU between VM so that you can get isolation",
    "start": "440449",
    "end": "446840"
  },
  {
    "text": "we can get QoS ready for all this workflow and in terms of hypervisor the",
    "start": "446840",
    "end": "452479"
  },
  {
    "text": "main stream I have advised us like vSphere KVM and XenServer they all have the support for the trip",
    "start": "452479",
    "end": "458720"
  },
  {
    "text": "universalization so in in so I come to talk about this how we can make use of",
    "start": "458720",
    "end": "464180"
  },
  {
    "text": "this virtualization in our communities so that we can share the Machine machine",
    "start": "464180",
    "end": "470150"
  },
  {
    "text": "learning were low with the GPUs and in this example I'm going to use the vSphere and lavinia a GPU in our demo or",
    "start": "470150",
    "end": "477590"
  },
  {
    "text": "our our registration purpose so here's just a diagram showing that in vSphere",
    "start": "477590",
    "end": "485240"
  },
  {
    "text": "how a physical GPU can be split into a smaller logical unit called widget view",
    "start": "485240",
    "end": "491539"
  },
  {
    "text": "and map into actual virtual machines so each VM has one or more views devices",
    "start": "491539",
    "end": "497570"
  },
  {
    "text": "and can use them as a native GPU so there anything anyone load inside this review inside this VM we can use this to",
    "start": "497570",
    "end": "505460"
  },
  {
    "start": "505000",
    "end": "604000"
  },
  {
    "text": "me GPU as a as a GPU that you can see in a physical machine here's the",
    "start": "505460",
    "end": "512709"
  },
  {
    "text": "configuration UI basically a physical TV you can be divided into a fixed frame",
    "start": "512709",
    "end": "521000"
  },
  {
    "text": "buffer and used by different vgpu for example a physical GPU with 16 gigabyte",
    "start": "521000",
    "end": "527089"
  },
  {
    "text": "memory cameras to participate in to for virtual GPU each half one gigabyte",
    "start": "527089",
    "end": "533420"
  },
  {
    "text": "memory to vgpu with each with 8 gigabyte memory i'm the compute engine of the",
    "start": "533420",
    "end": "539590"
  },
  {
    "text": "tributaries here between the VG views so there are few scheduling strategies",
    "start": "539590",
    "end": "546160"
  },
  {
    "text": "available to fit different scenarios like here I listen to feel like best",
    "start": "546160",
    "end": "551680"
  },
  {
    "text": "effort a fixer she Randy pusher so in short the memory of the rich views",
    "start": "551680",
    "end": "559140"
  },
  {
    "text": "affixed to each of the review but compute compute engine is sharable",
    "start": "559140",
    "end": "565120"
  },
  {
    "text": "between different VG boobs in this",
    "start": "565120",
    "end": "570490"
  },
  {
    "text": "vSphere console you can see that we can choose different profile it's calling in",
    "start": "570490",
    "end": "576550"
  },
  {
    "text": "this example I can see this grid P 100",
    "start": "576550",
    "end": "581850"
  },
  {
    "text": "GPU physical GPU having the a8q means that a gigabyte memory so by",
    "start": "581850",
    "end": "588550"
  },
  {
    "text": "choosing different profile you can virtually have create different type of size of the GPU and some people may",
    "start": "588550",
    "end": "597490"
  },
  {
    "text": "worry about the overhead of MotoGP you hear some research we did we interrupted",
    "start": "597490",
    "end": "603339"
  },
  {
    "text": "a while ago so calculating studying for the virtual of overhead or the with GPU",
    "start": "603339",
    "end": "609339"
  },
  {
    "start": "604000",
    "end": "703000"
  },
  {
    "text": "actually it's quite trivial like here in the it is an NLP dataset or the PTP",
    "start": "609339",
    "end": "614650"
  },
  {
    "text": "dataset are using the RNN for the NLP training so me about 4% overhead is absurd so",
    "start": "614650",
    "end": "622360"
  },
  {
    "text": "virtually it's nothing so we don't need to worry about too much about the overhead now it comes to part that how",
    "start": "622360",
    "end": "631810"
  },
  {
    "text": "we can set up a kubernetes cluster for GPUs sharing before that I introduced",
    "start": "631810",
    "end": "638800"
  },
  {
    "text": "the basic of GPU and then here is the diagram that we help we can set it up so",
    "start": "638800",
    "end": "643959"
  },
  {
    "text": "first the hyper hyper visor is configured with virtual GPU and next",
    "start": "643959",
    "end": "650589"
  },
  {
    "text": "week ray VM using the virtual GPU provided by the hypervisor and then the",
    "start": "650589",
    "end": "655810"
  },
  {
    "text": "machine learning application inside each of the VM can make you a fee which give",
    "start": "655810",
    "end": "660970"
  },
  {
    "text": "you the GPU device as if they are in a natively physical machine",
    "start": "660970",
    "end": "666580"
  },
  {
    "text": "in this way the GPU a physical GB you can be sure between different parts of kubernetes - into each of the worker no",
    "start": "666580",
    "end": "675399"
  },
  {
    "text": "it feels like it has a Fuji bu device in fact the GBO device a worker note you",
    "start": "675399",
    "end": "682269"
  },
  {
    "text": "know of the word kernel is a fraction of a physical GPU for example in the purple",
    "start": "682269",
    "end": "688630"
  },
  {
    "text": "ones it's a GPU as like a half of a physical GPU that's mapped into each of the VM",
    "start": "688630",
    "end": "694480"
  },
  {
    "text": "and the green ones each of them is a quarter of a physical GPU the computing",
    "start": "694480",
    "end": "699940"
  },
  {
    "text": "power supporter of the GPU so in that way each of the VM will have a portion",
    "start": "699940",
    "end": "705519"
  },
  {
    "start": "703000",
    "end": "802000"
  },
  {
    "text": "of the physical GPU internally so essentially it's a sharing that you bu",
    "start": "705519",
    "end": "710829"
  },
  {
    "text": "for the physical GPU for the workload next I'll talk about how to make use of",
    "start": "710829",
    "end": "718570"
  },
  {
    "text": "this make use of this TV you in kubernetes so there's still a little bit",
    "start": "718570",
    "end": "723610"
  },
  {
    "text": "more setup that's require in the kubernetes so I'll let y'all talk about that and show a demo after a break well",
    "start": "723610",
    "end": "733649"
  },
  {
    "text": "after after we we know we have a we have a requirement for GPIO sharing so now I",
    "start": "733649",
    "end": "740079"
  },
  {
    "text": "will introduce how to how to use the water GPU in kubernetes yeah the first",
    "start": "740079",
    "end": "747310"
  },
  {
    "text": "thing is you need to provision the worker nodes with the way GPO what you GPO device and they used the device",
    "start": "747310",
    "end": "754750"
  },
  {
    "text": "plug-in to discover to discover in the report what you GPO results and the",
    "start": "754750",
    "end": "762010"
  },
  {
    "text": "single master is you need to label the worker knows ways that different work",
    "start": "762010",
    "end": "767020"
  },
  {
    "text": "different to what your GPO capabilities and like like you like you see in the",
    "start": "767020",
    "end": "773589"
  },
  {
    "text": "diagram the worker the worker way I'm born in a two are consuming a consuming",
    "start": "773589",
    "end": "779290"
  },
  {
    "text": "base tea consuming with the water GPO with 8 gigabytes frame paper which is",
    "start": "779290",
    "end": "787899"
  },
  {
    "text": "the which is the counter which is a half of a physical GPO so we live so we level",
    "start": "787899",
    "end": "796209"
  },
  {
    "text": "worker node one and the worker node two with the which appealed out 5 equals 8 8 8 GP so",
    "start": "796209",
    "end": "803680"
  },
  {
    "text": "say master/worker BM 3 4 5 & 6 you can see here they are consuming the words",
    "start": "803680",
    "end": "810010"
  },
  {
    "text": "you were to the virtual GPO with fold gigabytes for improper so we we used a",
    "start": "810010",
    "end": "816460"
  },
  {
    "text": "different level for worker node 3 4 5 & 6",
    "start": "816460",
    "end": "822690"
  },
  {
    "text": "yep so now you can define the part to use what you to use the virtual GPO here",
    "start": "822690",
    "end": "831040"
  },
  {
    "text": "we'll use the immediate us plugging as an example it discovered what you watch",
    "start": "831040",
    "end": "837430"
  },
  {
    "text": "your GPO results like a physical GPO results and the reported discover result",
    "start": "837430",
    "end": "843370"
  },
  {
    "text": "to the cubelet so in now in your part definition you can require you know",
    "start": "843370",
    "end": "848950"
  },
  {
    "text": "definition you can request the one GPO result and to specify how much how much",
    "start": "848950",
    "end": "856140"
  },
  {
    "text": "GPO results you want you want to consume using the notice alike selector in this",
    "start": "856140",
    "end": "862030"
  },
  {
    "text": "example you can see we want to deploy a part two to a node with 8 gigabytes",
    "start": "862030",
    "end": "868090"
  },
  {
    "text": "frame paper what you GPO so so yeah and",
    "start": "868090",
    "end": "874810"
  },
  {
    "text": "as the way and even though you repress the 1:1 GPO results here you know",
    "start": "874810",
    "end": "883900"
  },
  {
    "text": "actually it's consuming a what you GPO with its consumer or half of a physical",
    "start": "883900",
    "end": "892330"
  },
  {
    "text": "GPO here and as you know way leverages of what you GPO technology so the chaos",
    "start": "892330",
    "end": "898660"
  },
  {
    "text": "and the isolation is provided by default oh let's see the demo",
    "start": "898660",
    "end": "908400"
  },
  {
    "text": "so now we will tell more how to schedule a part to a to a worker to a worker",
    "start": "932260",
    "end": "937450"
  },
  {
    "text": "nodes with with a specific watch of GPIO device yeah let's let's Jill what's the",
    "start": "937450",
    "end": "946150"
  },
  {
    "text": "current to kubernetes cluster that happened here yeah you can see here we",
    "start": "946150",
    "end": "955870"
  },
  {
    "text": "have two worker nodes with different different label information now we can",
    "start": "955870",
    "end": "961030"
  },
  {
    "text": "we can get more details for these two worker nodes this is the worker node",
    "start": "961030",
    "end": "966600"
  },
  {
    "text": "they're wrong yeah you can see here we have a GPO results and yeah the labels",
    "start": "966600",
    "end": "975820"
  },
  {
    "text": "we include them what your GP of profile he is here is the Fulco pads frame",
    "start": "975820",
    "end": "981820"
  },
  {
    "text": "buffer and the let's see the next worker no yes you can see here we use a",
    "start": "981820",
    "end": "994360"
  },
  {
    "text": "different label this worker nodes has 8 gigabytes frame buffer",
    "start": "994360",
    "end": "1000000"
  },
  {
    "start": "1000000",
    "end": "1099000"
  },
  {
    "text": "let's go to the worker is to worker node to check if to check the specific",
    "start": "1000000",
    "end": "1005750"
  },
  {
    "text": "virtual GPO profile you can see here for Q and 8 q yeah",
    "start": "1005750",
    "end": "1012330"
  },
  {
    "text": "is it tesla type form idea what your GPU",
    "start": "1012330",
    "end": "1018540"
  },
  {
    "text": "device yeah let's deploy a tensorflow part to worker now lets you see the part",
    "start": "1018540",
    "end": "1033120"
  },
  {
    "text": "oh here we use where we other when we",
    "start": "1033120",
    "end": "1038189"
  },
  {
    "text": "need we need to monitoring that what's your GP all here you can see",
    "start": "1038190",
    "end": "1044550"
  },
  {
    "text": "later you okay look you can see that there will be one container to consume the water JP or later let's see the",
    "start": "1044550",
    "end": "1056420"
  },
  {
    "text": "podium oh yeah you can see here we request the one GPO results and specify",
    "start": "1056420",
    "end": "1062520"
  },
  {
    "text": "the notice lecture to consume the fukiko pads free pepper you know the Poli will be",
    "start": "1062520",
    "end": "1069240"
  },
  {
    "text": "scheduled to the first worker no yeah",
    "start": "1069240",
    "end": "1079920"
  },
  {
    "text": "it's running you can see here there will be there is a process on a worker",
    "start": "1079920",
    "end": "1085110"
  },
  {
    "text": "working out oh we're not zero and this is a full kill Tesla Tesla you on",
    "start": "1085110",
    "end": "1093960"
  },
  {
    "text": "GPO water JP attack profile yeah that's that's done for this time Oh",
    "start": "1093960",
    "end": "1101480"
  },
  {
    "start": "1099000",
    "end": "1198000"
  },
  {
    "text": "yeah you know this is just a simple demo to consume the water jpo",
    "start": "1123429",
    "end": "1130360"
  },
  {
    "text": "using the notice selector but actually we can provide a more flexible master to",
    "start": "1130360",
    "end": "1136850"
  },
  {
    "text": "consume in fractional GPO we can insert under the scheduler and the change that",
    "start": "1136850",
    "end": "1142399"
  },
  {
    "text": "you want plug in if we change the device plug-in to discover and the entrepot the",
    "start": "1142399",
    "end": "1148279"
  },
  {
    "text": "watch of GPU you know due to the restriction of an API server the",
    "start": "1148279",
    "end": "1153769"
  },
  {
    "text": "fractional number is not allowed so we use one thousand to represent a physical",
    "start": "1153769",
    "end": "1159380"
  },
  {
    "text": "GPU and for example here you can see we",
    "start": "1159380",
    "end": "1164600"
  },
  {
    "text": "we rip out a washer GPO result as a number five hundred so that means we",
    "start": "1164600",
    "end": "1170570"
  },
  {
    "text": "discovered what's your GPU with half of a physical GPO so here we reap our 500",
    "start": "1170570",
    "end": "1177049"
  },
  {
    "text": "and the next of way attended the Cuban and his scheduler to support to support",
    "start": "1177049",
    "end": "1182210"
  },
  {
    "text": "the new results tab or to GPO register and we use the filter in the prioritized",
    "start": "1182210",
    "end": "1188840"
  },
  {
    "text": "method to to select a passed a matching worker node and the way we used to",
    "start": "1188840",
    "end": "1195169"
  },
  {
    "text": "define the master - deployed to deploy the part onto a worker node uh yeah and",
    "start": "1195169",
    "end": "1202190"
  },
  {
    "start": "1198000",
    "end": "1297000"
  },
  {
    "text": "we also need to add the annotation into the part party I'm the part definition",
    "start": "1202190",
    "end": "1208880"
  },
  {
    "text": "file for to about the requesting what your GP or results yeah and the doctor",
    "start": "1208880",
    "end": "1215360"
  },
  {
    "text": "blade will will use this annotation to update the worker knows with what you",
    "start": "1215360",
    "end": "1221090"
  },
  {
    "text": "GPIO say with the water GPU to update the water GP or is also correspondingly",
    "start": "1221090",
    "end": "1227470"
  },
  {
    "text": "yes this code is under development and the developer meant we will open South",
    "start": "1227470",
    "end": "1232549"
  },
  {
    "text": "dated later in next time yeah next page hurry we introduce today you'll use oak",
    "start": "1232549",
    "end": "1239299"
  },
  {
    "text": "ice for water drip you okay so much so one more thing is that just now we",
    "start": "1239299",
    "end": "1244970"
  },
  {
    "text": "introduced a way to have a fractional GPU because we don't want to change the upstream code so we use the 1000 as one",
    "start": "1244970",
    "end": "1251809"
  },
  {
    "text": "whole CBO and then you say 5 500 as a 1/2 of view so that we by customizing the",
    "start": "1251809",
    "end": "1258210"
  },
  {
    "text": "device plug-in as well as extending the schedule we can achieve a way to to",
    "start": "1258210",
    "end": "1263950"
  },
  {
    "text": "fractional GPU so it's more easy for the actual use so next I want to cover one",
    "start": "1263950",
    "end": "1269380"
  },
  {
    "text": "of the two other use cases therefore this GPU is sharing techniques well the one things I want to talk about",
    "start": "1269380",
    "end": "1275770"
  },
  {
    "text": "the first thing I want talk about is the a traffic case so I'm coming from",
    "start": "1275770",
    "end": "1280780"
  },
  {
    "text": "dredging I'm based in Beijing so in Beijing there's in a city there are many cameras on the roads that monitoring the",
    "start": "1280780",
    "end": "1286059"
  },
  {
    "text": "traffic daily so if a cross on the roll with it is true and expired the camera",
    "start": "1286059",
    "end": "1292330"
  },
  {
    "text": "will capture this vehicle and then we generate a notice to the owner of the car and maybe issue a notice for four or",
    "start": "1292330",
    "end": "1300460"
  },
  {
    "text": "five so we auto reminder owner to be to pay to buying some insurance or up today",
    "start": "1300460",
    "end": "1306220"
  },
  {
    "text": "right so for for each of this work to be working we need to have the",
    "start": "1306220",
    "end": "1312120"
  },
  {
    "text": "identification of each of the color image so in this sample we is virtually",
    "start": "1312120",
    "end": "1318220"
  },
  {
    "text": "becoming a identification image at the image recognition problem so for each of",
    "start": "1318220",
    "end": "1323590"
  },
  {
    "text": "the car we identify we outline the box of this car and send it to an inference",
    "start": "1323590",
    "end": "1329140"
  },
  {
    "text": "inference server for its to capture that the license plate to know the cars",
    "start": "1329140",
    "end": "1336549"
  },
  {
    "text": "number I since number and then we will based on that we will check whether it has the asked has the insurance expire",
    "start": "1336549",
    "end": "1344440"
  },
  {
    "text": "or not so that we can decide whether to issue any action to any action so this was some pretty pretty simple right but",
    "start": "1344440",
    "end": "1352360"
  },
  {
    "text": "what happens if when there are many cars on the road you virtually were having a",
    "start": "1352360",
    "end": "1357960"
  },
  {
    "text": "concurrency problem right so you have many cars that you need to identify other editors at a certain time so what",
    "start": "1357960",
    "end": "1364360"
  },
  {
    "text": "we do so one way is that if you still using one inference service that you have what Annette instantly for on that",
    "start": "1364360",
    "end": "1370750"
  },
  {
    "text": "inference service every request we're going to that what Annette right and we",
    "start": "1370750",
    "end": "1376150"
  },
  {
    "text": "could we could use the scale out use multiple instances of inference services",
    "start": "1376150",
    "end": "1382390"
  },
  {
    "text": "in that way each of the image recognition work will be used or will be",
    "start": "1382390",
    "end": "1388510"
  },
  {
    "text": "handle by the additional inference services using GPU so virtually we are sharing",
    "start": "1388510",
    "end": "1395940"
  },
  {
    "text": "the physical GPU by multiple threats or Bob multiple requests serving at the",
    "start": "1395940",
    "end": "1401350"
  },
  {
    "start": "1396000",
    "end": "1495000"
  },
  {
    "text": "same time so we can increase the utilization of the physical GPU this is a very common use case for inference",
    "start": "1401350",
    "end": "1409090"
  },
  {
    "text": "service especially for inference service the virtual GPU is useful for that purpose you can scale out as needed and",
    "start": "1409090",
    "end": "1417070"
  },
  {
    "text": "also we can shorten the response time so that you don't need to worry too much about having a lot of hardware there for",
    "start": "1417070",
    "end": "1425350"
  },
  {
    "text": "the very expensive hardware just one use case that's the second use case I'm",
    "start": "1425350",
    "end": "1431170"
  },
  {
    "text": "going to talk about is actually a university in China they have a very",
    "start": "1431170",
    "end": "1436720"
  },
  {
    "text": "diverse work load machine learning works in a very large cluster for logical of students faculty members and they're",
    "start": "1436720",
    "end": "1443920"
  },
  {
    "text": "doing research work teaching development and all kinds different workloads and training inference data processing all",
    "start": "1443920",
    "end": "1450730"
  },
  {
    "text": "kinds of all go together so by using the word float review we can allow those people to shear the machine learning",
    "start": "1450730",
    "end": "1457960"
  },
  {
    "text": "were low on top of the same class the physical cluster so we can increase the",
    "start": "1457960",
    "end": "1464590"
  },
  {
    "text": "utilization increase density and multi-tenant and so we define the policies so like for example like here",
    "start": "1464590",
    "end": "1471880"
  },
  {
    "text": "in the day time the physical box can be shared by four different people for",
    "start": "1471880",
    "end": "1478510"
  },
  {
    "text": "different workflow and for example for development of a distributed training or",
    "start": "1478510",
    "end": "1483790"
  },
  {
    "text": "you can difference for teaching or learning purposes and at night or the",
    "start": "1483790",
    "end": "1488980"
  },
  {
    "text": "net night time we don't need that much users then we can have to have the to",
    "start": "1488980",
    "end": "1495730"
  },
  {
    "start": "1495000",
    "end": "1594000"
  },
  {
    "text": "remove all those or suspend all the daytime worker nodes and then replaced by a girl like relatively larger virtual",
    "start": "1495730",
    "end": "1503680"
  },
  {
    "text": "machine a worker node so that you can contain big use of the full power of the physical GPU in that case that that all",
    "start": "1503680",
    "end": "1511870"
  },
  {
    "text": "the training a heavy tribute intensive what low like training can happen in",
    "start": "1511870",
    "end": "1518680"
  },
  {
    "text": "this very big bigger box and also all this process switching back and forth can be done by using",
    "start": "1518680",
    "end": "1524600"
  },
  {
    "text": "automated script or other API calls that we can achieve this goal I will let",
    "start": "1524600",
    "end": "1530299"
  },
  {
    "text": "young again and to have a demo for how we can switch the profiles between",
    "start": "1530299",
    "end": "1536120"
  },
  {
    "text": "different worker notes so that you understand how actually helping the people to have a flexibility in their",
    "start": "1536120",
    "end": "1541850"
  },
  {
    "text": "configuration ms assume we have we only",
    "start": "1541850",
    "end": "1547850"
  },
  {
    "text": "have a 1-mile holster which has GPIO device",
    "start": "1547850",
    "end": "1554320"
  },
  {
    "text": "you're here we have a tip line for worker notes on the insane yes Oh same holster on same holster with",
    "start": "1575600",
    "end": "1586309"
  },
  {
    "text": "fo-fo gigabytes bring pepper and let's check the kubernetes cluster yeah you",
    "start": "1586309",
    "end": "1592529"
  },
  {
    "text": "see here we have four worker knows yeah let's go to the worker notes to see the",
    "start": "1592529",
    "end": "1599639"
  },
  {
    "start": "1594000",
    "end": "1693000"
  },
  {
    "text": "water GPO profile yeah just to take two for example yeah you can see here we use",
    "start": "1599639",
    "end": "1606929"
  },
  {
    "text": "the four gigabytes yes here it's also",
    "start": "1606929",
    "end": "1616440"
  },
  {
    "text": "full gigabytes water GP of profile so that suspended the worker knows their",
    "start": "1616440",
    "end": "1623669"
  },
  {
    "text": "role to four it is a simple script tool",
    "start": "1623669",
    "end": "1631559"
  },
  {
    "text": "to automate suspended the worker knows and you can see here you can specify the",
    "start": "1631559",
    "end": "1639720"
  },
  {
    "text": "the label which you want to suspend",
    "start": "1639720",
    "end": "1645138"
  },
  {
    "text": "so our worship waves will be powered off yes si si the kubernetes see the",
    "start": "1649309",
    "end": "1659160"
  },
  {
    "text": "countless kubernetes set up you can see all worker nodes yeah our kernels are",
    "start": "1659160",
    "end": "1666210"
  },
  {
    "text": "not ready so that started a new worker nodes which consumed the whole face code",
    "start": "1666210",
    "end": "1675900"
  },
  {
    "text": "review you know in you know demo the",
    "start": "1675900",
    "end": "1684720"
  },
  {
    "text": "whole of physical water table is Tesla",
    "start": "1684720",
    "end": "1690950"
  },
  {
    "text": "we - we 100 with 16 gigabytes it let's",
    "start": "1690950",
    "end": "1700470"
  },
  {
    "text": "check the community set up your here",
    "start": "1700470",
    "end": "1707160"
  },
  {
    "text": "there is another one worker another worker null is ready so let's go to the",
    "start": "1707160",
    "end": "1713340"
  },
  {
    "text": "worker node to check the worker node is using a physical GPU",
    "start": "1713340",
    "end": "1721070"
  },
  {
    "text": "this is the know what another five you",
    "start": "1729100",
    "end": "1738919"
  },
  {
    "text": "see you can see here it's it's consuming a whole physical GPO yeah it's this is",
    "start": "1738919",
    "end": "1745760"
  },
  {
    "text": "just a simple demo for the user case too you can you can deliver your your own",
    "start": "1745760",
    "end": "1751580"
  },
  {
    "text": "scrip to choose to spend and resume the worker knows which you want to do okay",
    "start": "1751580",
    "end": "1758799"
  },
  {
    "text": "yeah so that's a very simple demo I was really fundamentally fundamental but I",
    "start": "1778480",
    "end": "1785360"
  },
  {
    "text": "hope you get the idea about how we can share a GPO between different ports book",
    "start": "1785360",
    "end": "1791390"
  },
  {
    "text": "notes so that you can share local especially useful in the cases that like",
    "start": "1791390",
    "end": "1796910"
  },
  {
    "start": "1792000",
    "end": "1891000"
  },
  {
    "text": "inference service you can have different services sharing the same physical GPU",
    "start": "1796910",
    "end": "1802730"
  },
  {
    "text": "and basically kubernetes is suitable for machine learning workload and using our",
    "start": "1802730",
    "end": "1808490"
  },
  {
    "text": "techniques in the GPU virtualization for the machine learning below we can achieve a few benefits like utilization",
    "start": "1808490",
    "end": "1817060"
  },
  {
    "text": "will be very high relative hi you don't have idle less idle physical devices",
    "start": "1817060",
    "end": "1822800"
  },
  {
    "text": "because GPUs are expensive and also we can have better scalability you can have more concurrent different workload or",
    "start": "1822800",
    "end": "1830360"
  },
  {
    "text": "mix what know you can have request handle more requests at the same time and also you can have isolation and QoS",
    "start": "1830360",
    "end": "1837950"
  },
  {
    "text": "because many of the existing solution in the community they don't have this isolation and us property also one more",
    "start": "1837950",
    "end": "1846020"
  },
  {
    "text": "thing I want to talk about is the mention is the suspend we can suspend a virtual machine or as along with the V",
    "start": "1846020",
    "end": "1852860"
  },
  {
    "text": "GPU and also resume at a later time also in VMware we can do the live migration is that you can move the below",
    "start": "1852860",
    "end": "1859400"
  },
  {
    "text": "from one place to one machine to another machine that means that you can have a better maintain maintain abilities",
    "start": "1859400",
    "end": "1865850"
  },
  {
    "text": "because when you need some time for maintenance you can migrate the book note to another physical box without",
    "start": "1865850",
    "end": "1871700"
  },
  {
    "text": "stopping your current training job and also we have snapshot and cloning the",
    "start": "1871700",
    "end": "1877160"
  },
  {
    "text": "orders kind of things are coming from the virtualization either from CPU or",
    "start": "1877160",
    "end": "1882500"
  },
  {
    "text": "GPU so with that all this is the our idea of idea of the GPU sharing and",
    "start": "1882500",
    "end": "1890780"
  },
  {
    "text": "kubernetes so we take by taking advantage of the virtual GPO technologies hope you get the idea it's",
    "start": "1890780",
    "end": "1897380"
  },
  {
    "start": "1891000",
    "end": "1990000"
  },
  {
    "text": "again this is a simple and introductory but I hope you you can utilize it to more interesting",
    "start": "1897380",
    "end": "1903460"
  },
  {
    "text": "work based on our our introduction here so that's that's all what we have so far",
    "start": "1903460",
    "end": "1909200"
  },
  {
    "text": "[Applause] thank you and if any questions I would",
    "start": "1909200",
    "end": "1916690"
  },
  {
    "text": "be happy to take some young we can keep a microphone thank you it's an",
    "start": "1916690",
    "end": "1931120"
  },
  {
    "text": "interesting stuff how do you decide whether you want to just use the virtual",
    "start": "1931120",
    "end": "1937240"
  },
  {
    "text": "GPU API versus switching out your worker node to have a smaller GPU or bigger GPU",
    "start": "1937240",
    "end": "1944110"
  },
  {
    "text": "like you know suspending it and starting it again sorry I didn't get a question so yeah oh",
    "start": "1944110",
    "end": "1951070"
  },
  {
    "text": "yeah so how do you decide between just using the V GPU API and that you can",
    "start": "1951070",
    "end": "1961240"
  },
  {
    "text": "create in kubernetes versus suspending and recreating the node with a different size GPU like when when should you do",
    "start": "1961240",
    "end": "1968200"
  },
  {
    "text": "that like well why do you ever need to do that so the question was when how do we decide when to switch the different",
    "start": "1968200",
    "end": "1974350"
  },
  {
    "text": "profile the GPU write me GPU so sometimes depending on the world os3 so like my luck in my example there before",
    "start": "1974350",
    "end": "1981880"
  },
  {
    "text": "when we have four we need to split into four like for example sixteen gigabyte each up have four to go by was some more",
    "start": "1981880",
    "end": "1988780"
  },
  {
    "text": "odd jobs machine learning jobs right if we are smaller than you don't need a whole the full power of the GPU you can",
    "start": "1988780",
    "end": "1995710"
  },
  {
    "text": "have smaller one oh maybe I'm missing maybe I didn't describe it so you the",
    "start": "1995710",
    "end": "2002700"
  },
  {
    "text": "the beat the vgpu api allows you to dynamically request it on the worker",
    "start": "2002700",
    "end": "2008760"
  },
  {
    "text": "nodes that exists right so like I can I can deploy a pod that has 500 units and",
    "start": "2008760",
    "end": "2014820"
  },
  {
    "text": "then it uses half of the of the GPU why do I also like it also made it seem like",
    "start": "2014820",
    "end": "2021630"
  },
  {
    "text": "you have to change like actually to shut down the node to change to change the",
    "start": "2021630",
    "end": "2027210"
  },
  {
    "text": "size of the GPU so your question is why we need to suspend",
    "start": "2027210",
    "end": "2033780"
  },
  {
    "text": "some worker nodes and the tool to resume some worker notes you know you mean the part can consume specific",
    "start": "2033780",
    "end": "2042030"
  },
  {
    "text": "water jpo results in our you know our demo right that was because for some for",
    "start": "2042030",
    "end": "2052919"
  },
  {
    "text": "the hypervisor you know for the food for the hypervisor if we only have a one",
    "start": "2052920",
    "end": "2059040"
  },
  {
    "text": "holster with GPU with the physical GPIO device you know for the hypervisor we",
    "start": "2059040",
    "end": "2065490"
  },
  {
    "text": "cannot we cannot have flexible to to severe survive which which were GPU you",
    "start": "2065490",
    "end": "2070800"
  },
  {
    "text": "want to use for your way so if currently if you use one virtual way around on the physical host to to",
    "start": "2070800",
    "end": "2079379"
  },
  {
    "text": "use to use a water table a profile like full gigabyte stream paper you cannot",
    "start": "2079380",
    "end": "2086250"
  },
  {
    "text": "add apply you cannot add apply or eight gigabytes virtual on to the same holster so that's why that's why we want to we",
    "start": "2086250",
    "end": "2094590"
  },
  {
    "text": "want to wait if you want to deploy a new worker node with a different what you",
    "start": "2094590",
    "end": "2099600"
  },
  {
    "text": "dip your device onto the same hosted so we need to suspend the existing way I'm",
    "start": "2099600",
    "end": "2104700"
  },
  {
    "text": "and resume one new one I'm not sure if it's your question I mean the reasoning",
    "start": "2104700",
    "end": "2111360"
  },
  {
    "text": "is that when you assign for VMs here they already assign all the video buffer memory buffer of GPU car so you cannot",
    "start": "2111360",
    "end": "2118470"
  },
  {
    "text": "spend another PM that used reusing this sharing the same physical GPU so we need",
    "start": "2118470",
    "end": "2125460"
  },
  {
    "text": "to shut it down shut them down before we release the GB Rios resource and then reorganize as one big host of the way",
    "start": "2125460",
    "end": "2132750"
  },
  {
    "text": "again that's that's why hopefully they answer your question okay any yeah I'm seeing this brutalization",
    "start": "2132750",
    "end": "2143100"
  },
  {
    "text": "of the GPU and I'm wondering if this is specifically for the case of multi-tenancy",
    "start": "2143100",
    "end": "2150010"
  },
  {
    "text": "[Music] kubernetes deployments where you maybe create one",
    "start": "2150010",
    "end": "2156330"
  },
  {
    "text": "cluster of natives for each tenon and you don't want the different notes computer of the",
    "start": "2156330",
    "end": "2163559"
  },
  {
    "text": "different kubernetes cluster share the same GPU so you create a bit well GPU",
    "start": "2163559",
    "end": "2171260"
  },
  {
    "text": "but for single tenant this is not as I",
    "start": "2171260",
    "end": "2176369"
  },
  {
    "text": "understand no because for single tenant there's also a use case I mean I know your question is that if your multiple",
    "start": "2176369",
    "end": "2181800"
  },
  {
    "text": "tenants you need you do want to separate them right isolate them but you go for single tenant there's also a use case",
    "start": "2181800",
    "end": "2187829"
  },
  {
    "text": "for the noisy neighbor even you the same thing and we have different jobs they can if you don't have isolation then you",
    "start": "2187829",
    "end": "2194609"
  },
  {
    "start": "2188000",
    "end": "2287000"
  },
  {
    "text": "can either interfere with each other then you cannot currently when you which one will work better which one will",
    "start": "2194609",
    "end": "2200460"
  },
  {
    "text": "finish first you is hard guarantee that but you can assign a fraction even in",
    "start": "2200460",
    "end": "2206250"
  },
  {
    "text": "the case so if you miss out without the GPU technology with GPU technology all the workload will be scheduled together",
    "start": "2206250",
    "end": "2212670"
  },
  {
    "text": "so you cannot guarantee which one gets how much share also physical chip what's",
    "start": "2212670",
    "end": "2217859"
  },
  {
    "text": "the meaning of the fraction part if you assign a fraction but you cannot enforce it I know there's no fraction fraction",
    "start": "2217859",
    "end": "2223710"
  },
  {
    "text": "only work on our vgb or without or whichever event the fraction thing doesn't work so the fraction you you just described",
    "start": "2223710",
    "end": "2230430"
  },
  {
    "text": "in the pot refers to the partition in virtualization mode not in the usage of",
    "start": "2230430",
    "end": "2236970"
  },
  {
    "text": "each bit a tip you I'm sorry I didn't get the meaning of the fraction number",
    "start": "2236970",
    "end": "2243450"
  },
  {
    "text": "is regarding the fraction inside of your",
    "start": "2243450",
    "end": "2248700"
  },
  {
    "text": "GPU but the fraction thing is a way so without a fraction thing we can rely we",
    "start": "2248700",
    "end": "2254910"
  },
  {
    "text": "rely on the know selector to assign the actual physical GPU resource that the",
    "start": "2254910",
    "end": "2260640"
  },
  {
    "text": "GPO to be resource this fraction thing is that we want to make it more flexible",
    "start": "2260640",
    "end": "2265680"
  },
  {
    "text": "or convenient for the user to assign the total up to to request the resource they",
    "start": "2265680",
    "end": "2272880"
  },
  {
    "text": "want it's not just for just for isolation is for for if your I can only",
    "start": "2272880",
    "end": "2278579"
  },
  {
    "text": "use a half of a GPU or if I can use a 1/4 of a GPU that's by this number so by",
    "start": "2278579",
    "end": "2285390"
  },
  {
    "text": "some customization of the communities cope device plug-in in the scheduler ok",
    "start": "2285390",
    "end": "2293029"
  },
  {
    "start": "2287000",
    "end": "2630000"
  },
  {
    "text": "that's one more head back so for this",
    "start": "2294540",
    "end": "2303250"
  },
  {
    "text": "fractional allocation of devices isn't it so what you will get 500 allocate",
    "start": "2303250",
    "end": "2310450"
  },
  {
    "text": "calls in your device plug-in sorry so for each instance like for each",
    "start": "2310450",
    "end": "2318730"
  },
  {
    "text": "single digit in your resource request you will get a allocate call to device",
    "start": "2318730",
    "end": "2325480"
  },
  {
    "text": "plug-in so if you are a question let's say why can we spot above like 300 V",
    "start": "2325480",
    "end": "2332560"
  },
  {
    "text": "GPUs you will get a new device plug-in 300 allocate calls yeah this 300 is we",
    "start": "2332560",
    "end": "2338130"
  },
  {
    "text": "deliberately make it not exactly the same as 500 so for here for this device",
    "start": "2338130",
    "end": "2343750"
  },
  {
    "text": "device Praveen it reports 500 because it's just a half of a physical GPO like here this physical trip you has divided",
    "start": "2343750",
    "end": "2351280"
  },
  {
    "text": "has been divided into two identical ones each of them is actually a half of a physical GPU and then you map into the",
    "start": "2351280",
    "end": "2358330"
  },
  {
    "text": "worker node as a 1gb you write is in the work no but whenever we report it",
    "start": "2358330",
    "end": "2364240"
  },
  {
    "text": "gooblat will three hundred times call the plugin allocate me device I'm sorry",
    "start": "2364240",
    "end": "2372270"
  },
  {
    "text": "what couplet will three hundred times cool with device plug-in saying it's no",
    "start": "2372270",
    "end": "2377800"
  },
  {
    "text": "wonder we modified it so you report it to the coolant is five hundred right 500",
    "start": "2377800",
    "end": "2383050"
  },
  {
    "text": "and then when we're doing the allocation we deduct five hundred territories no when we do not interface three hundred",
    "start": "2383050",
    "end": "2390810"
  },
  {
    "text": "okay you mean you mean that the location is five hundred what sorry overload API",
    "start": "2397110",
    "end": "2408160"
  },
  {
    "text": "I think I think it's over low it's one one core it's not to render times cause I guess 100 cause which 300 cause you",
    "start": "2408160",
    "end": "2418480"
  },
  {
    "text": "mean okay 500 times okay so so that's",
    "start": "2418480",
    "end": "2429970"
  },
  {
    "text": "that's the way we're trying to simplify the API and I know what you mean yeah so what we need to work more verify that",
    "start": "2429970",
    "end": "2435160"
  },
  {
    "text": "page that we are not quite sure where because you know in a process of making this working we haven't reached the",
    "start": "2435160",
    "end": "2441280"
  },
  {
    "text": "final step but we are the idea is that we don't want to change the code for the kubernetes api server so we reuse the",
    "start": "2441280",
    "end": "2447850"
  },
  {
    "text": "integer number there but but you view things through avoiding the 300 calls",
    "start": "2447850",
    "end": "2454840"
  },
  {
    "text": "write your signature in the cost for",
    "start": "2454840",
    "end": "2472180"
  },
  {
    "text": "1000 sorry what",
    "start": "2472180",
    "end": "2475260"
  },
  {
    "text": "okay API calls too many right so we need to find a way to get around with that so understand me in curve any cost there",
    "start": "2484560",
    "end": "2491910"
  },
  {
    "text": "yeah I have another question about does it work only for one physical GPU this",
    "start": "2491910",
    "end": "2498480"
  },
  {
    "text": "this implementation of fractional Depew does it work for for physical so only",
    "start": "2498480",
    "end": "2513250"
  },
  {
    "text": "one GP on you should have only one physical GP right yeah the assumption of a nice one when",
    "start": "2513250",
    "end": "2519490"
  },
  {
    "text": "we give you yeah we're still we see how to improve it but not not yet damn",
    "start": "2519490",
    "end": "2525180"
  },
  {
    "text": "that's far yet you mean you mean you'll have a full physical gpo for example",
    "start": "2525180",
    "end": "2531670"
  },
  {
    "text": "right yeah so so yeah you want to schedule you want to schedule your part",
    "start": "2531670",
    "end": "2538630"
  },
  {
    "text": "to to physical GP you may be more flexible you want to schedule or what's",
    "start": "2538630",
    "end": "2544750"
  },
  {
    "text": "your GP or physical GP all right oh yeah cuba cuba later can working in council",
    "start": "2544750",
    "end": "2552250"
  },
  {
    "text": "enhance that device plug in the device plugging in 2 to 2 scheduled to schedule",
    "start": "2552250",
    "end": "2558640"
  },
  {
    "text": "the part to a specific to a specific GPO but I mean we're only support of one",
    "start": "2558640",
    "end": "2564940"
  },
  {
    "text": "watch your jpo per what you watch it if you want to pass through pass through",
    "start": "2564940",
    "end": "2570970"
  },
  {
    "text": "the part you want to use more than one",
    "start": "2570970",
    "end": "2578310"
  },
  {
    "text": "GPU per per mole and van physical GPO",
    "start": "2578310",
    "end": "2583530"
  },
  {
    "text": "right now right now there's a limitation that you cannot have two fractional goods which of you inside one VM thus",
    "start": "2583530",
    "end": "2591070"
  },
  {
    "text": "currently we are working on that whether we can what's the work in a vm k vm may",
    "start": "2591070",
    "end": "2601089"
  },
  {
    "text": "have a different way to work it out have you tested it will be able to try that but but we just tried it on on this view",
    "start": "2601089",
    "end": "2609180"
  },
  {
    "text": "yeah we give you may have a different mechanism to work but but idea here if we present here should judge making the",
    "start": "2609180",
    "end": "2616260"
  },
  {
    "text": "affectional number working okay i think",
    "start": "2616260",
    "end": "2623380"
  },
  {
    "text": "i think so now thanks thanks for coming for for this session and this is last one thank you very much",
    "start": "2623380",
    "end": "2629870"
  },
  {
    "text": "[Applause]",
    "start": "2629870",
    "end": "2632389"
  }
]
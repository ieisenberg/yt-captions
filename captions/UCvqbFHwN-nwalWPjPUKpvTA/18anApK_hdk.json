[
  {
    "start": "0",
    "end": "87000"
  },
  {
    "text": "so good afternoon everyone your best Italian host ever it's uh it's again",
    "start": "31460",
    "end": "38160"
  },
  {
    "text": "here uh we have had all lunch we all have our refreshments",
    "start": "38160",
    "end": "45239"
  },
  {
    "text": "I see no okay um we have now Robin from sipman uh it's",
    "start": "45239",
    "end": "50640"
  },
  {
    "text": "Robin sickman from ING lead developer it's uh I must say it's um",
    "start": "50640",
    "end": "56879"
  },
  {
    "text": "it's beautiful to have this is our first consumer of kubernetes coming on stage",
    "start": "56879",
    "end": "62579"
  },
  {
    "text": "it's uh we always see vendors getting their talks through as not",
    "start": "62579",
    "end": "68159"
  },
  {
    "text": "brother pitch is fantastic you guys are doing a great job but it's also nice to see consumers to see what the troubles",
    "start": "68159",
    "end": "74939"
  },
  {
    "text": "that they go through to to enable kubernetes within their organization so Robin",
    "start": "74939",
    "end": "80700"
  },
  {
    "text": "would you like to join me yeah thank you very much give it up thank you",
    "start": "80700",
    "end": "85920"
  },
  {
    "text": "good luck thank you hello so the mic is working that's good and everybody has a",
    "start": "85920",
    "end": "91140"
  },
  {
    "text": "full stomach I hope so that's nice I'm going to talk about ing's container hosting Journey so uh like I read is",
    "start": "91140",
    "end": "98340"
  },
  {
    "text": "that we have our own private cloud and we're building container hosting there and one of the servers that we offer on",
    "start": "98340",
    "end": "105600"
  },
  {
    "text": "that container hosting is what we call namespace as a service and this talk is mainly about what does that infrastructure actually look like and",
    "start": "105600",
    "end": "111960"
  },
  {
    "text": "how did we build that Journey so first a little bit my name is Robert I'm the lead developer in the ing",
    "start": "111960",
    "end": "117780"
  },
  {
    "text": "container hosting platform team that's what that acronym stands for and ing is a bank but we write a lot of software we",
    "start": "117780",
    "end": "125820"
  },
  {
    "text": "are very apparent in in Europe but we are all over the world and in fact the",
    "start": "125820",
    "end": "130979"
  },
  {
    "text": "container hosting platform team the team that I'm in is also a team that has many nationalities in there I think that's",
    "start": "130979",
    "end": "136739"
  },
  {
    "text": "very cool and today I'm going to talk about why do we actually do namespace as a service as",
    "start": "136739",
    "end": "142440"
  },
  {
    "start": "137000",
    "end": "197000"
  },
  {
    "text": "opposed to maybe giving full clusters out in the private cloud and then what",
    "start": "142440",
    "end": "148800"
  },
  {
    "text": "does that stack actually look like in the private cloud structure and then I'm going to zoom in",
    "start": "148800",
    "end": "155340"
  },
  {
    "text": "on how we built the namespace's service on top of our overshift",
    "start": "155340",
    "end": "160440"
  },
  {
    "text": "so I already spoiled it we run openshift instead of kubernetes on top of kubernetes I'm going to talk a little",
    "start": "160440",
    "end": "167280"
  },
  {
    "text": "bit about the dependencies that we have to to build this uh this journey and then I'm going to zoom in to formal for",
    "start": "167280",
    "end": "173220"
  },
  {
    "text": "the uh the controllers that we have some of the applications so there's some python code in there there's some Gold Line code in there so I hope you're",
    "start": "173220",
    "end": "179940"
  },
  {
    "text": "excited for that and of course a demo I recorded it though so it's not a live",
    "start": "179940",
    "end": "185220"
  },
  {
    "text": "one but it's a demo nonetheless so let's dive in so we only offer",
    "start": "185220",
    "end": "190620"
  },
  {
    "text": "namespace as a service and the goal is I'm just going to go through the full slide",
    "start": "190620",
    "end": "197760"
  },
  {
    "text": "it's a lot of facts but in ing we have a full cluster right",
    "start": "197760",
    "end": "204000"
  },
  {
    "text": "and we don't want to give full clusters to Consumers because then we give out a lot of notes a lot of resources and they",
    "start": "204000",
    "end": "210300"
  },
  {
    "text": "will not be utilized fully but if we build a multi-tenant cluster and we offer namespace as a service then we are",
    "start": "210300",
    "end": "216840"
  },
  {
    "text": "in full control of the compute and we can give out the resources to namespace of those exactly what they need right so",
    "start": "216840",
    "end": "223440"
  },
  {
    "text": "if one namespace of one application requires 10 CPU cores and 10 gigs of",
    "start": "223440",
    "end": "228540"
  },
  {
    "text": "memory we give it to them and another namespace requires etc etc so we spread it out over the cluster but we are in",
    "start": "228540",
    "end": "234720"
  },
  {
    "text": "control of the compute and that gives us a number of advantages also in terms of compliance the the",
    "start": "234720",
    "end": "241319"
  },
  {
    "text": "people that request the namespace they don't have to worry about the underlying infrastructure right the cluster it",
    "start": "241319",
    "end": "246360"
  },
  {
    "text": "works they they don't have to know what compute nodes they are running on uh if",
    "start": "246360",
    "end": "251700"
  },
  {
    "text": "they are patched stuff like that they offer or they take the namespace that we give them as a service and they also get",
    "start": "251700",
    "end": "259139"
  },
  {
    "text": "the compliancy on top of that so they know that the platform they are running on it has been penetration tested it has",
    "start": "259139",
    "end": "266759"
  },
  {
    "text": "all the the risk controls in place and so on",
    "start": "266759",
    "end": "271979"
  },
  {
    "text": "it does mean that these teams we have a lot of them we have hundreds of teams that run that use the same kubernetes",
    "start": "271979",
    "end": "278460"
  },
  {
    "text": "cluster they are in control of the stuff that they deploy in their namespace so",
    "start": "278460",
    "end": "284460"
  },
  {
    "text": "the compliancy aspect of the cluster yes that's in the container hosting team's control but anything that you Deploy on",
    "start": "284460",
    "end": "291240"
  },
  {
    "text": "top of that that's the the application team needs to maintain that",
    "start": "291240",
    "end": "296479"
  },
  {
    "text": "um we will zoom in on that later if you want to know more about what it's like to run on the container housing team",
    "start": "296699",
    "end": "302699"
  },
  {
    "text": "there will be a talk from Adnan tomorrow and he will give you the journey",
    "start": "302699",
    "end": "308600"
  },
  {
    "start": "308000",
    "end": "380000"
  },
  {
    "text": "uh so what use cases do we actually support on our clusters we have two main use cases one of them is 12 factors I'm",
    "start": "309240",
    "end": "316620"
  },
  {
    "text": "wondering here show of hands who here knows what a 12 Factor application is quite a lot that's good that's good for",
    "start": "316620",
    "end": "323280"
  },
  {
    "text": "those who don't know 12 factors the easiest way I would describe it is that you focus on your app being stateless so",
    "start": "323280",
    "end": "331080"
  },
  {
    "text": "that makes it very easy to scale and if one of your applications gets killed it doesn't matter you just spin up a new",
    "start": "331080",
    "end": "336300"
  },
  {
    "text": "pod so it's all about portability scalability and so on so it means on the kubernetes cluster itself there is no",
    "start": "336300",
    "end": "343080"
  },
  {
    "text": "persistent volume claims there is no persistency at all if you need persistency in an as an application you",
    "start": "343080",
    "end": "350460"
  },
  {
    "text": "connect to an external database so external as in it's not inside the kubernetes cluster but still within your",
    "start": "350460",
    "end": "356220"
  },
  {
    "text": "own cloud right so these are this is the main type of workloads that we offer",
    "start": "356220",
    "end": "361340"
  },
  {
    "text": "for consumers or for data services providers so these are teams that really",
    "start": "361340",
    "end": "366720"
  },
  {
    "text": "know a lot about how to handle persistency how to handle storage for those workloads we actually offer a",
    "start": "366720",
    "end": "372600"
  },
  {
    "text": "storage which is built on top of Port Works where they are for us they are completely separate clusters",
    "start": "372600",
    "end": "380180"
  },
  {
    "start": "380000",
    "end": "447000"
  },
  {
    "text": "all right so this namespace is a service offering what I'm talking about what does that actually mean like why do why",
    "start": "380340",
    "end": "386340"
  },
  {
    "text": "do you have to build so much stuff for it you can just do OC ADM new project and you're done right well not really",
    "start": "386340",
    "end": "392580"
  },
  {
    "text": "because in the fact that if you do LCM new project then how do you know which",
    "start": "392580",
    "end": "397979"
  },
  {
    "text": "users have access to that certain project you need to give people access to it right a group maybe you're also",
    "start": "397979",
    "end": "403919"
  },
  {
    "text": "going to need some some networking in there so maybe this namespace needs its own IP address and maybe you need your",
    "start": "403919",
    "end": "409620"
  },
  {
    "text": "own private Network and so on we in ing we have Azure devops where we",
    "start": "409620",
    "end": "416580"
  },
  {
    "text": "deploy our code to on-premise but there also needs to be a connection between that on-premise cluster and Azure devops",
    "start": "416580",
    "end": "423000"
  },
  {
    "text": "so how has that then created and furthermore we have multiple data",
    "start": "423000",
    "end": "428400"
  },
  {
    "text": "centers in ing so if one data center goes down we can move to the other one but it also means that if you request a",
    "start": "428400",
    "end": "434280"
  },
  {
    "text": "namespace in one data center it needs to be available in the other so those are actually a lot of steps",
    "start": "434280",
    "end": "439380"
  },
  {
    "text": "that OC ADM new project doesn't do yeah and we have automated that and",
    "start": "439380",
    "end": "444419"
  },
  {
    "text": "that's mostly what this presentation is about to do all of that we have a lot of",
    "start": "444419",
    "end": "450960"
  },
  {
    "start": "447000",
    "end": "506000"
  },
  {
    "text": "components I've listed them here one of them is the the ihv API that knows all",
    "start": "450960",
    "end": "456539"
  },
  {
    "text": "about the different clusters and different data centers how to orchestrate it then we have project controller that ensures that name spaces",
    "start": "456539",
    "end": "462840"
  },
  {
    "text": "are on the cluster and yeah there's more there's off delegators say does controller image reporter pod research",
    "start": "462840",
    "end": "468960"
  },
  {
    "text": "meter end quote autoscaler there's a huge list of them we have about 36 at the moment obviously I can't handle all",
    "start": "468960",
    "end": "476280"
  },
  {
    "text": "36 of them right here but I will zoom in on three of them so I'm going to talk",
    "start": "476280",
    "end": "481560"
  },
  {
    "text": "about the ihp API project controller and the what is it the auto scaler there in this",
    "start": "481560",
    "end": "486960"
  },
  {
    "text": "presentation but before I do that I want to show you what is our infrastructure actually look like so for ING we have a",
    "start": "486960",
    "end": "494819"
  },
  {
    "text": "data center we have multiple data centers and then we have a team that offers bare metal as a service so they make sure that the physical compute",
    "start": "494819",
    "end": "501479"
  },
  {
    "text": "nodes that come in they are registered and ready to be consumed by by platforms",
    "start": "501479",
    "end": "508020"
  },
  {
    "text": "and then on one side we have Azure devops well I should say I do one Pipeline and which happens to run in",
    "start": "508020",
    "end": "514140"
  },
  {
    "text": "Azure devops and then we have a lot of apis that we depend upon so we have seen the B that's for asset registration we",
    "start": "514140",
    "end": "520500"
  },
  {
    "text": "have a charging endpoint there is some monitoring and logging in there security monitoring and networking so these are",
    "start": "520500",
    "end": "527339"
  },
  {
    "text": "all apis that are offered in ing private cloud now that we have our infra code so",
    "start": "527339",
    "end": "533940"
  },
  {
    "text": "everything for us is inference code and then we provision nodes via that using an IPI installation running",
    "start": "533940",
    "end": "540839"
  },
  {
    "text": "openshift 4.10 by the way and then we get our openshift container platform so",
    "start": "540839",
    "end": "546540"
  },
  {
    "text": "this is just this is an openshift installation without any of our own components on top of it yet",
    "start": "546540",
    "end": "553459"
  },
  {
    "start": "552000",
    "end": "576000"
  },
  {
    "text": "then we have all the applications that you just saw they're also an infras code",
    "start": "553459",
    "end": "559560"
  },
  {
    "text": "via githubs we deploy them via argocd on the cluster and then we truly have the",
    "start": "559560",
    "end": "565019"
  },
  {
    "text": "ing container hosting platform and you can also see that these components they",
    "start": "565019",
    "end": "570959"
  },
  {
    "text": "connect to the apis that are there right the internal infra apis",
    "start": "570959",
    "end": "577260"
  },
  {
    "start": "576000",
    "end": "613000"
  },
  {
    "text": "and then finally we can offer the namespace as a service on top of that so we have a cloud portal inside ing very",
    "start": "577260",
    "end": "583500"
  },
  {
    "text": "similar to what the public clouds have where you can click like hey I want a new namespace and you go through it and",
    "start": "583500",
    "end": "589019"
  },
  {
    "text": "then actually you call our apis and then the consumer has their namespace yeah",
    "start": "589019",
    "end": "594720"
  },
  {
    "text": "and of course the consumers once they have their namespace they want to deploy their application so they have their consumer code also in",
    "start": "594720",
    "end": "601019"
  },
  {
    "text": "the one Pipeline and that goes into the name space any questions about this slide",
    "start": "601019",
    "end": "608220"
  },
  {
    "text": "because then otherwise I have to go back no that's excellent",
    "start": "608220",
    "end": "615080"
  },
  {
    "start": "613000",
    "end": "665000"
  },
  {
    "text": "so let me zoom in on some of the applications that we have the first one I'm going to handle is called project",
    "start": "615080",
    "end": "620640"
  },
  {
    "text": "controller project control is written in Python and it's for namespace configuration management",
    "start": "620640",
    "end": "626880"
  },
  {
    "text": "when we originally started building this component we were very well versed in python in the team but there was no",
    "start": "626880",
    "end": "632580"
  },
  {
    "text": "python operator framework in for kubernetes so we build our own which we call scaffolds",
    "start": "632580",
    "end": "640019"
  },
  {
    "text": "and I will zoom in on that and what the project controller actually does is it",
    "start": "640019",
    "end": "645180"
  },
  {
    "text": "takes a specification of a project inside ing so for example hey I want a new project with this name and I have I",
    "start": "645180",
    "end": "652500"
  },
  {
    "text": "need these resources it's bound to this group and then the project controller it creates all the resources associated",
    "start": "652500",
    "end": "657600"
  },
  {
    "text": "with it so it creates the namespace it creates resource quotas it creates row bindings",
    "start": "657600",
    "end": "663899"
  },
  {
    "text": "and so on but let me zoom in on the scaffolds framework first",
    "start": "663899",
    "end": "669060"
  },
  {
    "start": "665000",
    "end": "760000"
  },
  {
    "text": "so the way the scaffolds framework works is you have your own application so this is if you're building python code right you",
    "start": "669060",
    "end": "676079"
  },
  {
    "text": "have your own application and then you import this stream watch the stream watch is offered by the discovers package which listens to a kubernetes",
    "start": "676079",
    "end": "682620"
  },
  {
    "text": "object so this can be a custom resource that you have defined yourself or maybe it's conflict maps or whatever you",
    "start": "682620",
    "end": "689100"
  },
  {
    "text": "please right and then via a watch the stream watch listens to that and then it calls event",
    "start": "689100",
    "end": "695519"
  },
  {
    "text": "listeners so event listen is also a class that the Scarface framework offers and that's what you inherit from so you",
    "start": "695519",
    "end": "702899"
  },
  {
    "text": "have a bunch of classes in electronic ventilations so this might seem a bit abstract but if I zoom in like this you",
    "start": "702899",
    "end": "709380"
  },
  {
    "text": "can see that you implement a bunch of event listeners so for example in in terms of project controller an event can",
    "start": "709380",
    "end": "716160"
  },
  {
    "text": "be like hey I want to create a new namespace so you have an event listener for a namespace you have an event listener for research quota and then",
    "start": "716160",
    "end": "723420"
  },
  {
    "text": "when a new specification comes in so a new custom resource comes in so let's say somebody tries to create an",
    "start": "723420",
    "end": "729720"
  },
  {
    "text": "ice HP project then it goes to the first event listener that says all right I need to create a namespace if that's",
    "start": "729720",
    "end": "735540"
  },
  {
    "text": "successful it moves on to the next one it needs to create a resource quota all right cool then it moves to the next one creates and now row bindings and so on",
    "start": "735540",
    "end": "743760"
  },
  {
    "text": "and the cool thing is that all these event listeners they are called in order",
    "start": "743760",
    "end": "749760"
  },
  {
    "text": "but if one of them fails so let's say one of them fails then the ones that have already been called they",
    "start": "749760",
    "end": "755399"
  },
  {
    "text": "will be rolled back that's what you see there with uh with the rollback",
    "start": "755399",
    "end": "760579"
  },
  {
    "start": "760000",
    "end": "818000"
  },
  {
    "text": "another component we have is called the ice HP API so the component you just saw the project controller it's very cluster",
    "start": "762600",
    "end": "768899"
  },
  {
    "text": "specific it only knows about clusters but the ihp API it knows about different clusters and that's what you see here so we have",
    "start": "768899",
    "end": "776040"
  },
  {
    "text": "a user it goes to the workflow it clicks hey I want a new namespace then you hit the ice HP API and it calls all those",
    "start": "776040",
    "end": "781800"
  },
  {
    "text": "infrastructure apis that I mentioned before and then it calls the cluster API",
    "start": "781800",
    "end": "787139"
  },
  {
    "text": "on every cluster which generates that Isha switch projects back and then inspected by the project controller and",
    "start": "787139",
    "end": "793260"
  },
  {
    "text": "then we have all these resources there well that's a lot of orchestration a lot of things that need to happen and all of",
    "start": "793260",
    "end": "800220"
  },
  {
    "text": "it is of course time consuming first let me take a look so this is what the API spec actually looks like so",
    "start": "800220",
    "end": "806100"
  },
  {
    "text": "these are the things that we offer you can get some information about your namespace you can create One update it",
    "start": "806100",
    "end": "811200"
  },
  {
    "text": "and delete it and you can also patch it for example if you only want to update your resource specifications then you",
    "start": "811200",
    "end": "817440"
  },
  {
    "text": "can do that uh but in order to go through all these steps in order to get the proper name",
    "start": "817440",
    "end": "823860"
  },
  {
    "start": "818000",
    "end": "918000"
  },
  {
    "text": "space these are the steps that we need to do so a request comes in and if we first need to get some Network information and that Network information",
    "start": "823860",
    "end": "830399"
  },
  {
    "text": "needs to be registered in the seem to be so that's the asset registration part and then lastly if that is all complete",
    "start": "830399",
    "end": "836459"
  },
  {
    "text": "then we need to charge for it and we actually need to create the namespace on the cluster now all of these stages they happen",
    "start": "836459",
    "end": "843000"
  },
  {
    "text": "sequentially so only after stage one is completed we move on to stage two and so",
    "start": "843000",
    "end": "848160"
  },
  {
    "text": "on but all of the units in a stage so these blocks on the left and right are called",
    "start": "848160",
    "end": "854399"
  },
  {
    "text": "units they are concurrent so registering stuff in the CNB it takes a second or",
    "start": "854399",
    "end": "860820"
  },
  {
    "text": "shall right but we do it all at the same time same for that to speed up the process",
    "start": "860820",
    "end": "866940"
  },
  {
    "text": "but it does mean that if we are in the first stage we don't want to wait all the way up",
    "start": "866940",
    "end": "872760"
  },
  {
    "text": "until stage three to find out that hey maybe there is a naming conflict right so at the first stage we already do a",
    "start": "872760",
    "end": "879480"
  },
  {
    "text": "check stage we call it so we do some sanity checks if the request is likely to succeed and only when the request is likely to",
    "start": "879480",
    "end": "886320"
  },
  {
    "text": "succeed then we continue with the Run stage and then we do some actual networking and so on",
    "start": "886320",
    "end": "894199"
  },
  {
    "text": "um so yeah if the flow is all good but at the last time you know like at the last unit",
    "start": "894540",
    "end": "900120"
  },
  {
    "text": "something fails uh then we are in a little bit of trouble because we have executed a lot of actions right we've",
    "start": "900120",
    "end": "905699"
  },
  {
    "text": "created we have the asset registration already and the networking is done but somehow we cannot create this namespace",
    "start": "905699",
    "end": "911339"
  },
  {
    "text": "on the cluster in that case we need to roll back everything that we've done so far",
    "start": "911339",
    "end": "918440"
  },
  {
    "start": "918000",
    "end": "954000"
  },
  {
    "text": "now what does that actually look like in code so all the steps that you saw in in",
    "start": "918660",
    "end": "924959"
  },
  {
    "text": "the diagram these are it is in code so we have this the first curly bracket",
    "start": "924959",
    "end": "930240"
  },
  {
    "text": "that is a stage block so to speak and you can see the network creation step there and then we have the other steps",
    "start": "930240",
    "end": "936180"
  },
  {
    "text": "that seem to be create the charging and the namespace but they are dry runs in the first stage and then we have all the",
    "start": "936180",
    "end": "943079"
  },
  {
    "text": "other steps right I hope this is uh clean to see and then finally we execute everything when the in the Run stage",
    "start": "943079",
    "end": "949980"
  },
  {
    "text": "cluster actions and reply call all right",
    "start": "949980",
    "end": "955139"
  },
  {
    "start": "954000",
    "end": "1074000"
  },
  {
    "text": "and the last component I want to show you is called quota autoscaler so we",
    "start": "955139",
    "end": "961079"
  },
  {
    "text": "found that on our clusters um or when you request an a space the",
    "start": "961079",
    "end": "967019"
  },
  {
    "text": "requester of the namespace has to fill in how many resources is your application going to consume and at the",
    "start": "967019",
    "end": "972480"
  },
  {
    "text": "moment where you requesting it it's very hard to estimate right some people haven't even started writing their application yet and we are already",
    "start": "972480",
    "end": "978180"
  },
  {
    "text": "asking them to give an estimate on how much they are going to use so that's very tricky",
    "start": "978180",
    "end": "983399"
  },
  {
    "text": "and on top of that then you start building your application right and you also need to fill in these Port resource",
    "start": "983399",
    "end": "989220"
  },
  {
    "text": "requests so how many CPUs is your pod going to use and then again you're going to make an estimate and maybe after",
    "start": "989220",
    "end": "995579"
  },
  {
    "text": "you've you've seen it running for a while then you know what your application actually uses like you do your performance test then you really",
    "start": "995579",
    "end": "1001579"
  },
  {
    "text": "know what it what it does but it turns out that knowing all your resources",
    "start": "1001579",
    "end": "1007160"
  },
  {
    "text": "for you request your name space that's really tricky and to help with that we have a component called the quota",
    "start": "1007160",
    "end": "1013040"
  },
  {
    "text": "autoscaler so what we do is we look at the namespace resource quota so a resource",
    "start": "1013040",
    "end": "1019639"
  },
  {
    "text": "quota is basically I hope everybody knows what a resource code is because we're all kubernetes but in case you",
    "start": "1019639",
    "end": "1025938"
  },
  {
    "text": "don't a research quota is basically a limitation of the compute resources that",
    "start": "1025939",
    "end": "1032000"
  },
  {
    "text": "your namespace can consume so the sum of all the part resources in your namespace they cannot exceed what it says in your",
    "start": "1032000",
    "end": "1038298"
  },
  {
    "text": "research quota okay so this is also what you pay for by the way in the in the ind5 cloud",
    "start": "1038299",
    "end": "1043938"
  },
  {
    "text": "everybody pays for their research quota now if we notice that that research",
    "start": "1043939",
    "end": "1049580"
  },
  {
    "text": "quota is getting full we can watch that using this ihp quota scalar component and when it's almost",
    "start": "1049580",
    "end": "1056059"
  },
  {
    "text": "full we can automatically do do calls to our charging endpoint so the to the ihp",
    "start": "1056059",
    "end": "1061880"
  },
  {
    "text": "API we say hey this code is almost full this team needs more resources than we call our Automation and which increases",
    "start": "1061880",
    "end": "1068539"
  },
  {
    "text": "the resource quota this behavior is managed by a custom research called a quota scalar object",
    "start": "1068539",
    "end": "1074960"
  },
  {
    "start": "1074000",
    "end": "1117000"
  },
  {
    "text": "which looks something like this [Music] I hope it looks really familiar because",
    "start": "1074960",
    "end": "1080360"
  },
  {
    "text": "it's almost the same as a horizontal pod Auto scalar so you have some behavior and you can also set some minimum values",
    "start": "1080360",
    "end": "1087140"
  },
  {
    "text": "and some Maximum values and you have to read the behavior like what is the what would you like the CPU",
    "start": "1087140",
    "end": "1093559"
  },
  {
    "text": "ratio to be so if you set down the values 50 and 70 it would mean that I",
    "start": "1093559",
    "end": "1099320"
  },
  {
    "text": "want my resource quota to be between 50 and 70 utilized if you put down 100 it",
    "start": "1099320",
    "end": "1105260"
  },
  {
    "text": "means you want the 100 efficient usage of your research quota that means that yeah there is no space",
    "start": "1105260",
    "end": "1111559"
  },
  {
    "text": "for pods essentially to come up you're fully using your research quota",
    "start": "1111559",
    "end": "1116919"
  },
  {
    "start": "1117000",
    "end": "1285000"
  },
  {
    "text": "I want to share some metrics with you with how that affects the research allocation on a cluster so not too long",
    "start": "1117799",
    "end": "1125000"
  },
  {
    "text": "ago we were running on overshift 311 and this was what the CPU allocation looked",
    "start": "1125000",
    "end": "1130039"
  },
  {
    "text": "like so we have over 9 000 cores allocated in resource quotas",
    "start": "1130039",
    "end": "1135460"
  },
  {
    "text": "these are the actual requests so this is what the research quarter looked like what the the namespace have what you pay",
    "start": "1135460",
    "end": "1142160"
  },
  {
    "text": "for and then the request is the sum of all the polls like what do the polls actually request and you can see the",
    "start": "1142160",
    "end": "1148760"
  },
  {
    "text": "teams highly overestimate how much resources their application actually need and you can see the usage there as well",
    "start": "1148760",
    "end": "1156620"
  },
  {
    "text": "so you can see that the memory usage in terms of request is quite good and for CPU yeah there is a lot more",
    "start": "1156620",
    "end": "1163940"
  },
  {
    "text": "burst to it and now we built another cluster an openshift 4 cluster",
    "start": "1163940",
    "end": "1170080"
  },
  {
    "text": "and there we implemented the quota scaler and you can see the difference",
    "start": "1170080",
    "end": "1175100"
  },
  {
    "text": "right so we went from 9000 cores to give",
    "start": "1175100",
    "end": "1180140"
  },
  {
    "text": "or take what is it 2000 or 1700 and also for memory",
    "start": "1180140",
    "end": "1186140"
  },
  {
    "text": "so we users no longer have to worry about what they fill in for their namespace",
    "start": "1186140",
    "end": "1191299"
  },
  {
    "text": "resource quota it scales automatically and one other thing we did is that for",
    "start": "1191299",
    "end": "1196400"
  },
  {
    "text": "Dev and test workloads we saw that there were a lot of high CPU requests on a pod",
    "start": "1196400",
    "end": "1201620"
  },
  {
    "text": "level and this also allocates the research on the cluster but for Devon test",
    "start": "1201620",
    "end": "1207200"
  },
  {
    "text": "namespaces yeah you don't they can be a bit more flexible right so for different tests we",
    "start": "1207200",
    "end": "1215299"
  },
  {
    "text": "automatically scale down the CPU to 10 Milli cores but we still allow users to",
    "start": "1215299",
    "end": "1220460"
  },
  {
    "text": "set their limits as high as you can so for those who don't know if you request",
    "start": "1220460",
    "end": "1225620"
  },
  {
    "text": "resources in a pod you have resources a requests requests are research that you are guaranteed to have whereas limits",
    "start": "1225620",
    "end": "1232160"
  },
  {
    "text": "they are reached only if the resources are available on the cluster and since we have so many compute nodes on the",
    "start": "1232160",
    "end": "1238520"
  },
  {
    "text": "cluster with us you're almost bound to hit your limits anyway so this allows us to gain in this margin",
    "start": "1238520",
    "end": "1246380"
  },
  {
    "text": "here so we have the request for V1 and then for Devon test we force it lower and that gives us a nice bump there",
    "start": "1246380",
    "end": "1253100"
  },
  {
    "text": "obviously for memory we can't do that because we can't if you yeah memory is not as compressible as",
    "start": "1253100",
    "end": "1261559"
  },
  {
    "text": "you so here are some other metrics so here you can see the quota scaling and there you see the the port research mutated I",
    "start": "1261559",
    "end": "1268160"
  },
  {
    "text": "was talking about by implementing the code of scalar feature we save 7.6 000",
    "start": "1268160",
    "end": "1274160"
  },
  {
    "text": "CPU cores in namespace resource quotas and with the mutation there for the dev",
    "start": "1274160",
    "end": "1280160"
  },
  {
    "text": "and test name spaces we save 500 CPU cores in in the request",
    "start": "1280160",
    "end": "1286960"
  },
  {
    "start": "1285000",
    "end": "1300000"
  },
  {
    "text": "yeah so I already mentioned this right so the port research mutator for development and test namespace is only forces to Port CPU requests to be 10",
    "start": "1287179",
    "end": "1293840"
  },
  {
    "text": "Milli cores but the CPU limits can be kept as it is",
    "start": "1293840",
    "end": "1299900"
  },
  {
    "text": "all right last but not least I have a demo it will be a very quick demo it is a",
    "start": "1299900",
    "end": "1306380"
  },
  {
    "start": "1300000",
    "end": "1492000"
  },
  {
    "text": "video but it shows the full stack as I've just told you in the story so we're gonna requisition a namespace via the",
    "start": "1306380",
    "end": "1313700"
  },
  {
    "text": "ice HP API after the namespace has been requisitioned we're going to scale up some some workload in it and then we're",
    "start": "1313700",
    "end": "1321200"
  },
  {
    "text": "going to see the quota Auto scalar in action all right here we go",
    "start": "1321200",
    "end": "1328460"
  },
  {
    "text": "so there we go here is a namespace specification for the igb iOS so it has",
    "start": "1328460",
    "end": "1333860"
  },
  {
    "text": "a name we have some workload type we have some resource that we wanted to have then we post this payload to our",
    "start": "1333860",
    "end": "1342020"
  },
  {
    "text": "automation right we create an a space so this creates the namespaces on multiple clusters",
    "start": "1342020",
    "end": "1347900"
  },
  {
    "text": "uh we can also see what operations it did so we can see that there was some",
    "start": "1347900",
    "end": "1353600"
  },
  {
    "text": "networking in there there was some asset registration and finally it was created on the cluster",
    "start": "1353600",
    "end": "1361120"
  },
  {
    "text": "those are all the steps now if we actually look at what what is on the cluster so the automation on the",
    "start": "1365240",
    "end": "1371600"
  },
  {
    "text": "cluster it creates its ijp projects back again it has the the same name it has the same quotas",
    "start": "1371600",
    "end": "1378440"
  },
  {
    "text": "it has the same workload type and there's the name and this is then",
    "start": "1378440",
    "end": "1384500"
  },
  {
    "text": "picked up by the project controller and it that creates in turn creates the namespace it creates the resource code",
    "start": "1384500",
    "end": "1390860"
  },
  {
    "text": "so you can see that whatever in the specification is reflected in the research quota there",
    "start": "1390860",
    "end": "1397940"
  },
  {
    "text": "it also creates role bindings so the what groups have access to this namespace",
    "start": "1397940",
    "end": "1403220"
  },
  {
    "text": "and you automatically get a quota scaler now we have our namespace let's deploy",
    "start": "1403220",
    "end": "1409280"
  },
  {
    "text": "something in it so I have this nginx path here it has some CPU request it has",
    "start": "1409280",
    "end": "1415100"
  },
  {
    "text": "some CPU limits so let's make it happen",
    "start": "1415100",
    "end": "1419980"
  },
  {
    "text": "it's starting up and we can see we are using some of our quota right we're using 250 megabytes",
    "start": "1420200",
    "end": "1426380"
  },
  {
    "text": "out of one gigabyte and our quota we're using one out of four CPU limit",
    "start": "1426380",
    "end": "1431840"
  },
  {
    "text": "and so we can scale up to four replicas before we hit our research quota so we are completely full right now if you try",
    "start": "1431840",
    "end": "1439100"
  },
  {
    "text": "to create another pod it will fail because your research quota is full",
    "start": "1439100",
    "end": "1445240"
  },
  {
    "text": "so we have four parts running and now we scale it up to six we get all",
    "start": "1445820",
    "end": "1451159"
  },
  {
    "text": "these scary error messages because well you're it's forbidden right you're trying to break out of your quota",
    "start": "1451159",
    "end": "1456500"
  },
  {
    "text": "but this is where the quota autoscaler comes in it's actually listening to these events and it knows that you are",
    "start": "1456500",
    "end": "1462440"
  },
  {
    "text": "trying to scale up outside your quota and it sees here it calculates based on the specifications of the replica set",
    "start": "1462440",
    "end": "1468559"
  },
  {
    "text": "how much resources actually you need more and then it calls our our",
    "start": "1468559",
    "end": "1474440"
  },
  {
    "text": "Automation and it updates the research quota and we can see it's actually updated there and all the parts are running",
    "start": "1474440",
    "end": "1481820"
  },
  {
    "text": "so that's what you mean that what I meant with the 100 efficient resource quota usage",
    "start": "1481820",
    "end": "1488799"
  },
  {
    "start": "1492000",
    "end": "1572000"
  },
  {
    "text": "there's more I have I have one more slide",
    "start": "1493900",
    "end": "1500440"
  },
  {
    "text": "so uh I showed you a lot of stuff I showed you some python code I showed you some some",
    "start": "1500600",
    "end": "1506120"
  },
  {
    "text": "other stuff um I mean it's really nice to boast about it but it's not very useful for you unless you can touch it yourself so",
    "start": "1506120",
    "end": "1513020"
  },
  {
    "text": "can you have all this code and the answer is yes yes you can so uh at",
    "start": "1513020",
    "end": "1518059"
  },
  {
    "text": "kubecon we will open source this live um yes very cool",
    "start": "1518059",
    "end": "1524360"
  },
  {
    "text": "and what will you actually get so you will get the code for the quota Auto scale or the full component of the quota autoscaler you will get it",
    "start": "1524360",
    "end": "1530980"
  },
  {
    "text": "for the the operator the python operator framework we will also open source it",
    "start": "1530980",
    "end": "1536600"
  },
  {
    "text": "you will not get a project controller yet we are also planning on open sourcing that maybe but for now you will",
    "start": "1536600",
    "end": "1541880"
  },
  {
    "text": "get the python operator framework and for the the orchestration you saw we had all",
    "start": "1541880",
    "end": "1547940"
  },
  {
    "text": "these lines where we have like these stages that we run sequentially and the units all concurrent and that's what we call orchestration and that will also be",
    "start": "1547940",
    "end": "1554659"
  },
  {
    "text": "open source so yeah",
    "start": "1554659",
    "end": "1561679"
  },
  {
    "text": "that is it so now are there any questions",
    "start": "1561679",
    "end": "1568360"
  },
  {
    "text": "[Applause] there are questions",
    "start": "1569350",
    "end": "1575419"
  },
  {
    "start": "1572000",
    "end": "2057000"
  },
  {
    "text": "but you guys don't have microphones so that's uh",
    "start": "1575419",
    "end": "1579880"
  },
  {
    "text": "hello thank you for your talk I want to ask do you use this in production because I've seen data from",
    "start": "1582080",
    "end": "1588200"
  },
  {
    "text": "non-production and I wonder if I if you already use that yeah we we use everything uh in",
    "start": "1588200",
    "end": "1594140"
  },
  {
    "text": "production what you see here but the components they are all replicated across different clusters so for DTA",
    "start": "1594140",
    "end": "1600740"
  },
  {
    "text": "there is an instance of the ihp API called autoscaler running and for production we have another instance",
    "start": "1600740",
    "end": "1605900"
  },
  {
    "text": "running across multiple clusters as well so yes everything you see is is running in prod",
    "start": "1605900",
    "end": "1612020"
  },
  {
    "text": "I wonder why the choice of giving the data for non-production instead of production because the it will be more",
    "start": "1612020",
    "end": "1617960"
  },
  {
    "text": "impressive maybe to see how much resources you save in production yeah the the reasoning for this graph is that",
    "start": "1617960",
    "end": "1624919"
  },
  {
    "text": "we noticed for Devon test a lot of resources are allocated and for production workloads we are not",
    "start": "1624919",
    "end": "1632360"
  },
  {
    "text": "very eager to scale down the request like we if a team says hey they need that many resource to run in production",
    "start": "1632360",
    "end": "1637580"
  },
  {
    "text": "we believe them we don't we're not going to touch it or for Devon test we can be a bit more aggressive",
    "start": "1637580",
    "end": "1643400"
  },
  {
    "text": "and yeah that's why those metrics are a bit more interesting but for the production metrics they are perhaps a",
    "start": "1643400",
    "end": "1650960"
  },
  {
    "text": "bit less because you don't have the Pod resource mutator but for the quota Auto scaling level it's still uh very",
    "start": "1650960",
    "end": "1656840"
  },
  {
    "text": "beneficial you're welcome",
    "start": "1656840",
    "end": "1661419"
  },
  {
    "text": "um similar workload and I wonder well we've",
    "start": "1664460",
    "end": "1672500"
  },
  {
    "text": "made some different decisions and we used actually some Market Solutions like capsule for",
    "start": "1672500",
    "end": "1680200"
  },
  {
    "text": "creating namespaces automatically by the developers and themselves also the",
    "start": "1680200",
    "end": "1686900"
  },
  {
    "text": "vertical port autoscaler but the last one yeah I",
    "start": "1686900",
    "end": "1692900"
  },
  {
    "text": "it's not working properly for us so maybe this is convenient to use but I'm",
    "start": "1692900",
    "end": "1700760"
  },
  {
    "text": "wondering why are you I mean why is Auntie",
    "start": "1700760",
    "end": "1706220"
  },
  {
    "text": "developing these Solutions themselves because there are some solutions in the",
    "start": "1706220",
    "end": "1711260"
  },
  {
    "text": "market yeah so for the namespace as a service part we have a lot of interfaces inside",
    "start": "1711260",
    "end": "1718640"
  },
  {
    "text": "Inu that are very ing specific like for example our our networking implementation that yeah it is just very",
    "start": "1718640",
    "end": "1725179"
  },
  {
    "text": "ing specific so we cannot ask a vendor to build that for us uh and for the second part of the the",
    "start": "1725179",
    "end": "1731480"
  },
  {
    "text": "scaling part so it actually works with the horizontal Port Auto scale as well",
    "start": "1731480",
    "end": "1737120"
  },
  {
    "text": "as vertical or Auto scaling you can use both of it and this code autoscale kind of runs on",
    "start": "1737120",
    "end": "1742580"
  },
  {
    "text": "top of that so you can see it as like a management for your namespace research called as instead and we talked actually",
    "start": "1742580",
    "end": "1749659"
  },
  {
    "text": "with multiple vendors and multiple companies and none of them had built it yet so uh",
    "start": "1749659",
    "end": "1755480"
  },
  {
    "text": "therefore we did it and you can also use it because when it's open source I hope that answers your question",
    "start": "1755480",
    "end": "1762799"
  },
  {
    "text": "okay thank you yeah one question because I I saw that there",
    "start": "1762799",
    "end": "1767960"
  },
  {
    "text": "is a cmdb record against the namespace so it can with this orchestration can",
    "start": "1767960",
    "end": "1775399"
  },
  {
    "text": "you get multiple namespace per C cmdb record or it's one namespace per cmdb",
    "start": "1775399",
    "end": "1782059"
  },
  {
    "text": "record yeah so what we do is because we run",
    "start": "1782059",
    "end": "1787100"
  },
  {
    "text": "many many clusters and all these clusters they can have the same namespace right so depending on how many",
    "start": "1787100",
    "end": "1792679"
  },
  {
    "text": "times you want to replicate it and what will you register in the seem to be is we combine the namespace name with an",
    "start": "1792679",
    "end": "1798500"
  },
  {
    "text": "identifier of the cluster that you have so let's say your name space is example right and then we will have example one",
    "start": "1798500",
    "end": "1805100"
  },
  {
    "text": "two three depending on like one two three being the cluster identifiers does that make sense",
    "start": "1805100",
    "end": "1812440"
  },
  {
    "text": "yes hi thanks for the talk do you have any",
    "start": "1813740",
    "end": "1821480"
  },
  {
    "text": "restrictions on the upper limit for that quota Auto scaler in case of misuse or security incidents yes yes we do and I'm",
    "start": "1821480",
    "end": "1829399"
  },
  {
    "text": "sad to say it's also necessary yeah there is a there is a limit we have uh from the top of my head I think we",
    "start": "1829399",
    "end": "1836960"
  },
  {
    "text": "have like 35 CPU cores and like a 150 gigs of RAM per namespace",
    "start": "1836960",
    "end": "1844000"
  },
  {
    "text": "it can be that uh some of the workloads that we have they actually have an",
    "start": "1844000",
    "end": "1849380"
  },
  {
    "text": "extremely high load and then they use all these regions and perhaps they need more and usually these are yeah big",
    "start": "1849380",
    "end": "1856100"
  },
  {
    "text": "consumers that we talk to them about their use case because if a team hits these limits without talking to us then",
    "start": "1856100",
    "end": "1862820"
  },
  {
    "text": "usually they are over committing the resources that like they are requesting more research than they actually need so this limit is in place and then we talk",
    "start": "1862820",
    "end": "1870440"
  },
  {
    "text": "about it on a team to team basis if they need more we have a question in back in the back",
    "start": "1870440",
    "end": "1875480"
  },
  {
    "text": "of the room Robin yes hey you did explain about the support",
    "start": "1875480",
    "end": "1880700"
  },
  {
    "text": "for 12 Factor applications I was just curious that ichp supports stateful applications as well or",
    "start": "1880700",
    "end": "1887419"
  },
  {
    "text": "yeah so we currently only provide States for applications for data services so",
    "start": "1887419",
    "end": "1892760"
  },
  {
    "text": "for most of our consumers it's all stateless 12 Factor but for uh with",
    "start": "1892760",
    "end": "1898159"
  },
  {
    "text": "inside Ing we have providers that offer data search for example the elk stack you might know the elk stack so these",
    "start": "1898159",
    "end": "1905899"
  },
  {
    "text": "guys worked in ing for five years okay so the yeah so the elk stack is a",
    "start": "1905899",
    "end": "1911360"
  },
  {
    "text": "consumer of persistent storage it uses the same Automation in the end",
    "start": "1911360",
    "end": "1918080"
  },
  {
    "text": "uh Robin are you okay to take one last question yeah of course",
    "start": "1918080",
    "end": "1923380"
  },
  {
    "text": "thank you I have a small question sincere basically in the like private",
    "start": "1923659",
    "end": "1929179"
  },
  {
    "text": "cloud service provider um how many clients do you have at this moment more or less",
    "start": "1929179",
    "end": "1935919"
  },
  {
    "text": "so inside the cluster we have a little over 2 000 namespaces",
    "start": "1935919",
    "end": "1943480"
  },
  {
    "text": "and I think together with the non-prodden products we run about I think it's roughly 5000 pods and that's",
    "start": "1943480",
    "end": "1950960"
  },
  {
    "text": "per environment right so we replicate everything in another data center as well",
    "start": "1950960",
    "end": "1956360"
  },
  {
    "text": "what is the metrics you're looking for or I was because I was curious actually about the more technical uh part of this",
    "start": "1956360",
    "end": "1962779"
  },
  {
    "text": "which is the Persistence of the kubernetes Clusters that you're using under the hood basically did you go with",
    "start": "1962779",
    "end": "1969140"
  },
  {
    "text": "the custom solution regarding the storing of the state or are you still using the standard one which is etcd",
    "start": "1969140",
    "end": "1975559"
  },
  {
    "text": "yeah we're still using at CD yes but for the so are you referring to the storage",
    "start": "1975559",
    "end": "1981260"
  },
  {
    "text": "we use for our own apis or the storage we offer for our data services consumers no the internal one specifically for the",
    "start": "1981260",
    "end": "1988039"
  },
  {
    "text": "need of the kubernetes Clusters yeah yeah okay thank you yeah we found at CD I",
    "start": "1988039",
    "end": "1995120"
  },
  {
    "text": "think it's it's performance but it's keep a good eye on the metrics and you may also need to fine tune it right",
    "start": "1995120",
    "end": "2000760"
  },
  {
    "text": "there are quite some nice articles about it where you can say okay I have a huge cluster what metrics do I need to fiddle",
    "start": "2000760",
    "end": "2006039"
  },
  {
    "text": "with or what parameters yeah all right if you have more questions I'll be",
    "start": "2006039",
    "end": "2012580"
  },
  {
    "text": "walking around still so uh thank you very much for listening and have a great day",
    "start": "2012580",
    "end": "2019080"
  },
  {
    "text": "well thank you very much Robin um I am 100 sure that people will come",
    "start": "2020559",
    "end": "2025600"
  },
  {
    "text": "find you not necessarily for good things we have a",
    "start": "2025600",
    "end": "2032919"
  },
  {
    "text": "now we're going to restart at 2 30 with the ARA and she's going to show us about",
    "start": "2032919",
    "end": "2039899"
  },
  {
    "text": "the Gateway API so you can stick around you can go get some refreshment but",
    "start": "2039899",
    "end": "2045159"
  },
  {
    "text": "please be on time we're going to start 230 sharp thank you",
    "start": "2045159",
    "end": "2050220"
  }
]
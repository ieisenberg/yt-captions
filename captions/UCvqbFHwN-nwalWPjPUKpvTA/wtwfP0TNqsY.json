[
  {
    "text": "good morning everyone",
    "start": "0",
    "end": "1760"
  },
  {
    "text": "my name is marlin patel and i am the",
    "start": "1760",
    "end": "4240"
  },
  {
    "text": "group part manager for google kubernetes",
    "start": "4240",
    "end": "6160"
  },
  {
    "text": "engine",
    "start": "6160",
    "end": "8160"
  },
  {
    "text": "world is moving towards cloud native",
    "start": "8160",
    "end": "9840"
  },
  {
    "text": "computing and kubernetes has become",
    "start": "9840",
    "end": "12719"
  },
  {
    "text": "the de facto standard for cloud native",
    "start": "12719",
    "end": "15200"
  },
  {
    "text": "computing",
    "start": "15200",
    "end": "16640"
  },
  {
    "text": "in my opinion kubernetes is an ideal",
    "start": "16640",
    "end": "19840"
  },
  {
    "text": "platform for aiml and high performance",
    "start": "19840",
    "end": "22720"
  },
  {
    "text": "computing",
    "start": "22720",
    "end": "24640"
  },
  {
    "text": "and in this talk i'm going to talk about",
    "start": "24640",
    "end": "28000"
  },
  {
    "text": "challenges and opportunities in making",
    "start": "28000",
    "end": "30960"
  },
  {
    "text": "ai easy and efficient with kubernetes",
    "start": "30960",
    "end": "35920"
  },
  {
    "text": "so there are three core reasons why i",
    "start": "37440",
    "end": "39440"
  },
  {
    "text": "think kubernetes is an ideal platform",
    "start": "39440",
    "end": "41600"
  },
  {
    "text": "for aiml and hpc",
    "start": "41600",
    "end": "43760"
  },
  {
    "text": "number one is portability",
    "start": "43760",
    "end": "45920"
  },
  {
    "text": "kubernetes provides cloud-native open",
    "start": "45920",
    "end": "49440"
  },
  {
    "text": "and standard-based apis",
    "start": "49440",
    "end": "51760"
  },
  {
    "text": "it allows users to seamlessly port",
    "start": "51760",
    "end": "54800"
  },
  {
    "text": "workloads from their laptop to private",
    "start": "54800",
    "end": "57280"
  },
  {
    "text": "data center",
    "start": "57280",
    "end": "58559"
  },
  {
    "text": "to the cloud",
    "start": "58559",
    "end": "60079"
  },
  {
    "text": "and this is very very important for aiml",
    "start": "60079",
    "end": "63120"
  },
  {
    "text": "community because it allows them to",
    "start": "63120",
    "end": "65840"
  },
  {
    "text": "reliably reproduce their results",
    "start": "65840",
    "end": "69680"
  },
  {
    "text": "the second one is scalability kubernetes",
    "start": "69680",
    "end": "72960"
  },
  {
    "text": "allows workloads to be scaled from a",
    "start": "72960",
    "end": "75600"
  },
  {
    "text": "single node",
    "start": "75600",
    "end": "76880"
  },
  {
    "text": "to thousands of nodes",
    "start": "76880",
    "end": "79360"
  },
  {
    "text": "and it also supports auto scaling auto",
    "start": "79360",
    "end": "82159"
  },
  {
    "text": "provisioning gpus tpus and many other",
    "start": "82159",
    "end": "84880"
  },
  {
    "text": "hardware accelerators which helps to",
    "start": "84880",
    "end": "87040"
  },
  {
    "text": "train model faster quicker and cheaper",
    "start": "87040",
    "end": "91040"
  },
  {
    "text": "the third reason is productivity",
    "start": "91040",
    "end": "93360"
  },
  {
    "text": "kubernetes makes data scientist and ai",
    "start": "93360",
    "end": "96640"
  },
  {
    "text": "practitioner more productive",
    "start": "96640",
    "end": "99200"
  },
  {
    "text": "by freeing users up",
    "start": "99200",
    "end": "101200"
  },
  {
    "text": "from having to manage their own",
    "start": "101200",
    "end": "103520"
  },
  {
    "text": "workstations or servers",
    "start": "103520",
    "end": "106079"
  },
  {
    "text": "it lets them focus on their business",
    "start": "106079",
    "end": "108560"
  },
  {
    "text": "critical mission which is to build a",
    "start": "108560",
    "end": "110479"
  },
  {
    "text": "model and train the model without having",
    "start": "110479",
    "end": "112640"
  },
  {
    "text": "to worry about underlying infrastructure",
    "start": "112640",
    "end": "114960"
  },
  {
    "text": "and compatibility issues",
    "start": "114960",
    "end": "118320"
  },
  {
    "text": "however there are many challenges that",
    "start": "118560",
    "end": "120159"
  },
  {
    "text": "this community faces",
    "start": "120159",
    "end": "122159"
  },
  {
    "text": "so gpu utilization is one of the core",
    "start": "122159",
    "end": "124880"
  },
  {
    "text": "concerns for aiml practitioners",
    "start": "124880",
    "end": "128879"
  },
  {
    "text": "and poor utilization costs them dearly",
    "start": "128879",
    "end": "133599"
  },
  {
    "text": "so in our google kubernetes engine",
    "start": "133599",
    "end": "135840"
  },
  {
    "text": "period we have seen that",
    "start": "135840",
    "end": "138080"
  },
  {
    "text": "overall gpu utilization across the fleet",
    "start": "138080",
    "end": "140800"
  },
  {
    "text": "is quite low",
    "start": "140800",
    "end": "142720"
  },
  {
    "text": "and gpu utilization is actually getting",
    "start": "142720",
    "end": "144800"
  },
  {
    "text": "worse day by day as gpus are getting",
    "start": "144800",
    "end": "147599"
  },
  {
    "text": "more and more powerful",
    "start": "147599",
    "end": "149840"
  },
  {
    "text": "a single",
    "start": "149840",
    "end": "151200"
  },
  {
    "text": "workload may not be able to saturate a",
    "start": "151200",
    "end": "154080"
  },
  {
    "text": "really powerful gpu",
    "start": "154080",
    "end": "156560"
  },
  {
    "text": "an",
    "start": "156560",
    "end": "157360"
  },
  {
    "text": "under utilization problem is even more",
    "start": "157360",
    "end": "159680"
  },
  {
    "text": "acute",
    "start": "159680",
    "end": "161280"
  },
  {
    "text": "for certain types of workloads such as",
    "start": "161280",
    "end": "164640"
  },
  {
    "text": "inference gaming",
    "start": "164640",
    "end": "166480"
  },
  {
    "text": "notebook and visualization",
    "start": "166480",
    "end": "170760"
  },
  {
    "text": "so why is that the case",
    "start": "171440",
    "end": "173599"
  },
  {
    "text": "so the kubernetes allows fractional",
    "start": "173599",
    "end": "175920"
  },
  {
    "text": "requests for cpus but it does not allow",
    "start": "175920",
    "end": "178879"
  },
  {
    "text": "fractional requests for gpus",
    "start": "178879",
    "end": "181200"
  },
  {
    "text": "so you can ask",
    "start": "181200",
    "end": "183599"
  },
  {
    "text": "0.5 cpu to kubernetes and it knows how",
    "start": "183599",
    "end": "186159"
  },
  {
    "text": "to give you 0.5 cpus but you can't ask",
    "start": "186159",
    "end": "189280"
  },
  {
    "text": "0.5 gpus",
    "start": "189280",
    "end": "191519"
  },
  {
    "text": "one gpu has to be fully allocated to one",
    "start": "191519",
    "end": "194400"
  },
  {
    "text": "container even if the container only",
    "start": "194400",
    "end": "197200"
  },
  {
    "text": "needs fraction of gpu for its workload",
    "start": "197200",
    "end": "200480"
  },
  {
    "text": "so this invariably leads to over",
    "start": "200480",
    "end": "202319"
  },
  {
    "text": "provisioning and sometimes cost overrun",
    "start": "202319",
    "end": "206159"
  },
  {
    "text": "so as a community we have the",
    "start": "206159",
    "end": "208000"
  },
  {
    "text": "opportunity to make gpus kubernetes",
    "start": "208000",
    "end": "211519"
  },
  {
    "text": "native resource and that will hopefully",
    "start": "211519",
    "end": "214159"
  },
  {
    "text": "address this challenge",
    "start": "214159",
    "end": "217120"
  },
  {
    "text": "the another challenge that ai",
    "start": "217680",
    "end": "219280"
  },
  {
    "text": "practitioner faces is the",
    "start": "219280",
    "end": "221760"
  },
  {
    "text": "failure resilient training",
    "start": "221760",
    "end": "225120"
  },
  {
    "text": "so kubernetes was designed with the",
    "start": "225120",
    "end": "227200"
  },
  {
    "text": "fundamental assumption that pods",
    "start": "227200",
    "end": "230080"
  },
  {
    "text": "are",
    "start": "230080",
    "end": "231040"
  },
  {
    "text": "disposable and replaceable",
    "start": "231040",
    "end": "234959"
  },
  {
    "text": "so we treat pods",
    "start": "234959",
    "end": "236799"
  },
  {
    "text": "as",
    "start": "236799",
    "end": "237760"
  },
  {
    "text": "cattle not pets which means",
    "start": "237760",
    "end": "240720"
  },
  {
    "text": "they can be",
    "start": "240720",
    "end": "242080"
  },
  {
    "text": "disposed anytime",
    "start": "242080",
    "end": "244879"
  },
  {
    "text": "this assumption does not suit well for",
    "start": "244879",
    "end": "247439"
  },
  {
    "text": "many distributed computing frameworks",
    "start": "247439",
    "end": "250319"
  },
  {
    "text": "majority of distributed computing",
    "start": "250319",
    "end": "252000"
  },
  {
    "text": "frameworks especially that are used for",
    "start": "252000",
    "end": "254000"
  },
  {
    "text": "aiml",
    "start": "254000",
    "end": "255519"
  },
  {
    "text": "are",
    "start": "255519",
    "end": "256400"
  },
  {
    "text": "very sensitive to disruptions they are",
    "start": "256400",
    "end": "259199"
  },
  {
    "text": "intolerant to disruptions such as",
    "start": "259199",
    "end": "261600"
  },
  {
    "text": "preemptions failures or maintenance",
    "start": "261600",
    "end": "264080"
  },
  {
    "text": "events",
    "start": "264080",
    "end": "265680"
  },
  {
    "text": "and the problem gets really really acute",
    "start": "265680",
    "end": "268000"
  },
  {
    "text": "when you do really large scale training",
    "start": "268000",
    "end": "270720"
  },
  {
    "text": "with thousands of nodes",
    "start": "270720",
    "end": "272800"
  },
  {
    "text": "in those cases",
    "start": "272800",
    "end": "274400"
  },
  {
    "text": "the probability that a one particular",
    "start": "274400",
    "end": "276880"
  },
  {
    "text": "node will encounter a disruption",
    "start": "276880",
    "end": "279440"
  },
  {
    "text": "increases when you scale the training",
    "start": "279440",
    "end": "282479"
  },
  {
    "text": "cluster size as well as the duration of",
    "start": "282479",
    "end": "284639"
  },
  {
    "text": "the training",
    "start": "284639",
    "end": "286479"
  },
  {
    "text": "the way community deals with this today",
    "start": "286479",
    "end": "288320"
  },
  {
    "text": "is through checkpoint and restore so you",
    "start": "288320",
    "end": "290400"
  },
  {
    "text": "frequently take checkpoints",
    "start": "290400",
    "end": "292400"
  },
  {
    "text": "however these checkpoints are typically",
    "start": "292400",
    "end": "294720"
  },
  {
    "text": "taken at the epoch boundary",
    "start": "294720",
    "end": "297440"
  },
  {
    "text": "so if a disruption arrives then all the",
    "start": "297440",
    "end": "300320"
  },
  {
    "text": "work that all these thousands of node",
    "start": "300320",
    "end": "302000"
  },
  {
    "text": "has done since the last epoch is lost",
    "start": "302000",
    "end": "305039"
  },
  {
    "text": "which is not a good story from the cost",
    "start": "305039",
    "end": "307520"
  },
  {
    "text": "and time saving point of view",
    "start": "307520",
    "end": "309600"
  },
  {
    "text": "there are frameworks like python elastic",
    "start": "309600",
    "end": "312560"
  },
  {
    "text": "which handles",
    "start": "312560",
    "end": "314400"
  },
  {
    "text": "any kind of disruption gracefully but",
    "start": "314400",
    "end": "316880"
  },
  {
    "text": "the challenge there is those solutions",
    "start": "316880",
    "end": "319199"
  },
  {
    "text": "are framework specific",
    "start": "319199",
    "end": "322240"
  },
  {
    "text": "what this community needs is",
    "start": "322240",
    "end": "324720"
  },
  {
    "text": "framework agnostic elastic training",
    "start": "324720",
    "end": "327919"
  },
  {
    "text": "so our goal should be to support",
    "start": "327919",
    "end": "330880"
  },
  {
    "text": "any framework without any code changes",
    "start": "330880",
    "end": "335360"
  },
  {
    "text": "and this will give two main benefits if",
    "start": "335360",
    "end": "338320"
  },
  {
    "text": "we have the elastic training",
    "start": "338320",
    "end": "340800"
  },
  {
    "text": "then you can use it to run",
    "start": "340800",
    "end": "344080"
  },
  {
    "text": "your training on spot vms which are a",
    "start": "344080",
    "end": "347360"
  },
  {
    "text": "lot cheaper than on-demand vm so it",
    "start": "347360",
    "end": "349759"
  },
  {
    "text": "saves a lot of cost and it's also",
    "start": "349759",
    "end": "351840"
  },
  {
    "text": "another problem which is obtainability",
    "start": "351840",
    "end": "354720"
  },
  {
    "text": "as most of you know gpus are scarce",
    "start": "354720",
    "end": "356880"
  },
  {
    "text": "resource",
    "start": "356880",
    "end": "358000"
  },
  {
    "text": "spot vms are also scarce resource",
    "start": "358000",
    "end": "360639"
  },
  {
    "text": "it's very hard to find let's say",
    "start": "360639",
    "end": "362319"
  },
  {
    "text": "thousands of gpus up front to start your",
    "start": "362319",
    "end": "364880"
  },
  {
    "text": "training if you have elastic training",
    "start": "364880",
    "end": "367199"
  },
  {
    "text": "support then you can start a training",
    "start": "367199",
    "end": "369199"
  },
  {
    "text": "with however number of spot gpus",
    "start": "369199",
    "end": "371280"
  },
  {
    "text": "available to you and then scale it up",
    "start": "371280",
    "end": "373520"
  },
  {
    "text": "when more gpus are available and scale",
    "start": "373520",
    "end": "375600"
  },
  {
    "text": "it down when you lose them",
    "start": "375600",
    "end": "377520"
  },
  {
    "text": "so that will also address the",
    "start": "377520",
    "end": "379120"
  },
  {
    "text": "obtainability challenge",
    "start": "379120",
    "end": "381440"
  },
  {
    "text": "another opportunity for this computer",
    "start": "381440",
    "end": "383360"
  },
  {
    "text": "this community is to basically enable",
    "start": "383360",
    "end": "387039"
  },
  {
    "text": "native support for checkpoint migration",
    "start": "387039",
    "end": "389840"
  },
  {
    "text": "and restoration in kubernetes",
    "start": "389840",
    "end": "393600"
  },
  {
    "text": "and",
    "start": "393680",
    "end": "394960"
  },
  {
    "text": "the way it can be done is that whenever",
    "start": "394960",
    "end": "397280"
  },
  {
    "text": "the underlying infrasurfaces that there",
    "start": "397280",
    "end": "399759"
  },
  {
    "text": "is an impending maintenance event or",
    "start": "399759",
    "end": "402400"
  },
  {
    "text": "there is a preemption coming",
    "start": "402400",
    "end": "404319"
  },
  {
    "text": "then kubernetes can transparently and",
    "start": "404319",
    "end": "406840"
  },
  {
    "text": "gracefully take a snapshot or checkpoint",
    "start": "406840",
    "end": "410000"
  },
  {
    "text": "and store it",
    "start": "410000",
    "end": "412160"
  },
  {
    "text": "and this will make it work conserving",
    "start": "412160",
    "end": "414400"
  },
  {
    "text": "meaning",
    "start": "414400",
    "end": "415840"
  },
  {
    "text": "current checkpoint mechanisms you lose",
    "start": "415840",
    "end": "417840"
  },
  {
    "text": "the work since last epoch but if you had",
    "start": "417840",
    "end": "419919"
  },
  {
    "text": "like a transparent checkpointing on",
    "start": "419919",
    "end": "421520"
  },
  {
    "text": "demand",
    "start": "421520",
    "end": "422479"
  },
  {
    "text": "then it will conserve all the training",
    "start": "422479",
    "end": "424400"
  },
  {
    "text": "work that has happened so this is",
    "start": "424400",
    "end": "426240"
  },
  {
    "text": "another opportunity for the community",
    "start": "426240",
    "end": "429918"
  },
  {
    "text": "the ai practitioners also face a lot of",
    "start": "430479",
    "end": "433199"
  },
  {
    "text": "challenges when it comes to",
    "start": "433199",
    "end": "434560"
  },
  {
    "text": "observability and kubernetes",
    "start": "434560",
    "end": "437919"
  },
  {
    "text": "so kubernetes observability primitives",
    "start": "437919",
    "end": "440240"
  },
  {
    "text": "were mainly designed to provide service",
    "start": "440240",
    "end": "443520"
  },
  {
    "text": "level indicators like uptime like cpu",
    "start": "443520",
    "end": "447199"
  },
  {
    "text": "utilization memory utilization gpu",
    "start": "447199",
    "end": "449599"
  },
  {
    "text": "utilization and things like that",
    "start": "449599",
    "end": "452880"
  },
  {
    "text": "now they are ill suited to monitor model",
    "start": "452880",
    "end": "455599"
  },
  {
    "text": "health",
    "start": "455599",
    "end": "457280"
  },
  {
    "text": "so ai practitioner when they think of",
    "start": "457280",
    "end": "459520"
  },
  {
    "text": "their model the things that they care",
    "start": "459520",
    "end": "461120"
  },
  {
    "text": "about are like model performance like",
    "start": "461120",
    "end": "463919"
  },
  {
    "text": "how",
    "start": "463919",
    "end": "464879"
  },
  {
    "text": "accurate my model is precision recall f1",
    "start": "464879",
    "end": "468720"
  },
  {
    "text": "score",
    "start": "468720",
    "end": "469599"
  },
  {
    "text": "they also care a lot about data drift",
    "start": "469599",
    "end": "472000"
  },
  {
    "text": "and concept drift",
    "start": "472000",
    "end": "474479"
  },
  {
    "text": "so ai practitioners also",
    "start": "474479",
    "end": "476319"
  },
  {
    "text": "care a lot about",
    "start": "476319",
    "end": "478400"
  },
  {
    "text": "training and serving skus",
    "start": "478400",
    "end": "480960"
  },
  {
    "text": "and typically they detect it with kl",
    "start": "480960",
    "end": "482960"
  },
  {
    "text": "divergence or studying the future",
    "start": "482960",
    "end": "485440"
  },
  {
    "text": "importance between training and serving",
    "start": "485440",
    "end": "488000"
  },
  {
    "text": "and last but not least",
    "start": "488000",
    "end": "489599"
  },
  {
    "text": "it's very very important to know the",
    "start": "489599",
    "end": "492080"
  },
  {
    "text": "fairness of the model in many industries",
    "start": "492080",
    "end": "494639"
  },
  {
    "text": "like demographic parity or equal",
    "start": "494639",
    "end": "497120"
  },
  {
    "text": "opportunity",
    "start": "497120",
    "end": "499520"
  },
  {
    "text": "so in my opinion it's very hard",
    "start": "499520",
    "end": "503039"
  },
  {
    "text": "to get this kind of information from",
    "start": "503039",
    "end": "505199"
  },
  {
    "text": "existing kubernetes primitives like",
    "start": "505199",
    "end": "507520"
  },
  {
    "text": "prometheus metrics or logging metrics to",
    "start": "507520",
    "end": "510319"
  },
  {
    "text": "give a little bit of concrete example",
    "start": "510319",
    "end": "513120"
  },
  {
    "text": "like in",
    "start": "513120",
    "end": "514399"
  },
  {
    "text": "typical kubernetes observative",
    "start": "514399",
    "end": "516159"
  },
  {
    "text": "observability you rarely have to deal",
    "start": "516159",
    "end": "518399"
  },
  {
    "text": "with events that are months or even",
    "start": "518399",
    "end": "521360"
  },
  {
    "text": "years apart",
    "start": "521360",
    "end": "522640"
  },
  {
    "text": "on the other hand",
    "start": "522640",
    "end": "524159"
  },
  {
    "text": "in ai world this is a very common",
    "start": "524159",
    "end": "526399"
  },
  {
    "text": "occurrence so let me give you some",
    "start": "526399",
    "end": "528080"
  },
  {
    "text": "examples let's say you have a model",
    "start": "528080",
    "end": "530720"
  },
  {
    "text": "to predict customer churn",
    "start": "530720",
    "end": "533360"
  },
  {
    "text": "now customer acquisition happens and at",
    "start": "533360",
    "end": "536160"
  },
  {
    "text": "some point in future the customer is",
    "start": "536160",
    "end": "537760"
  },
  {
    "text": "going to churn",
    "start": "537760",
    "end": "538880"
  },
  {
    "text": "so in order to study the accuracy of",
    "start": "538880",
    "end": "541120"
  },
  {
    "text": "this model you have to combine these two",
    "start": "541120",
    "end": "543279"
  },
  {
    "text": "events which are",
    "start": "543279",
    "end": "544800"
  },
  {
    "text": "spaced months or even years and apart",
    "start": "544800",
    "end": "547440"
  },
  {
    "text": "there's another example",
    "start": "547440",
    "end": "549360"
  },
  {
    "text": "for example you have a model that",
    "start": "549360",
    "end": "551519"
  },
  {
    "text": "predicts loan default",
    "start": "551519",
    "end": "553760"
  },
  {
    "text": "now",
    "start": "553760",
    "end": "554560"
  },
  {
    "text": "you issue a loan",
    "start": "554560",
    "end": "556160"
  },
  {
    "text": "default may happen sometime in future",
    "start": "556160",
    "end": "558640"
  },
  {
    "text": "to understand the accuracy of this model",
    "start": "558640",
    "end": "561120"
  },
  {
    "text": "you have to combine these events",
    "start": "561120",
    "end": "563600"
  },
  {
    "text": "so",
    "start": "563600",
    "end": "564399"
  },
  {
    "text": "in order to understand the accuracy",
    "start": "564399",
    "end": "566640"
  },
  {
    "text": "precision recall and many other metrics",
    "start": "566640",
    "end": "569680"
  },
  {
    "text": "the observability solution needs to",
    "start": "569680",
    "end": "571760"
  },
  {
    "text": "combine desperate events that may space",
    "start": "571760",
    "end": "574800"
  },
  {
    "text": "far apart so this is one of the examples",
    "start": "574800",
    "end": "577040"
  },
  {
    "text": "where we as a community have an",
    "start": "577040",
    "end": "579200"
  },
  {
    "text": "opportunity to extend existing",
    "start": "579200",
    "end": "581360"
  },
  {
    "text": "observability solutions that are there",
    "start": "581360",
    "end": "583839"
  },
  {
    "text": "for kubernetes to make them suitable for",
    "start": "583839",
    "end": "586320"
  },
  {
    "text": "aiml community",
    "start": "586320",
    "end": "588399"
  },
  {
    "text": "so in summary",
    "start": "588399",
    "end": "589760"
  },
  {
    "text": "i see a lot of exciting thing happening",
    "start": "589760",
    "end": "592160"
  },
  {
    "text": "in this space and i'm super excited and",
    "start": "592160",
    "end": "594320"
  },
  {
    "text": "energized to be able to be working in",
    "start": "594320",
    "end": "596640"
  },
  {
    "text": "this space",
    "start": "596640",
    "end": "598160"
  },
  {
    "text": "and i hope the ai force be with you",
    "start": "598160",
    "end": "602560"
  },
  {
    "text": "thank you all",
    "start": "602560",
    "end": "603680"
  },
  {
    "text": "any questions comments i'm around",
    "start": "603680",
    "end": "608040"
  }
]
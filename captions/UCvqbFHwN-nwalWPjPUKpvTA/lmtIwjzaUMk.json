[
  {
    "text": "now recording welcome to the open tracing specification Council meeting everybody good to see all your lovely",
    "start": "30",
    "end": "6750"
  },
  {
    "text": "faces we've got a fun presentation today",
    "start": "6750",
    "end": "12019"
  },
  {
    "text": "from Jonathan Kaldor and Michael Boyk",
    "start": "12019",
    "end": "17190"
  },
  {
    "text": "and I now pronounce your last name that's exactly right you got it yeah it's a great yeah",
    "start": "17190",
    "end": "24960"
  },
  {
    "text": "the block from a long line of can't pronounce your last name family tree but",
    "start": "24960",
    "end": "32640"
  },
  {
    "text": "it'll be on tracing at Facebook and rather than ramble on myself I'd love to",
    "start": "32640",
    "end": "40760"
  },
  {
    "text": "let Jonathan and Michael introduce themselves and then kick it off so",
    "start": "40760",
    "end": "46289"
  },
  {
    "text": "welcome hi so yeah as I'm Jonathan I used to",
    "start": "46289",
    "end": "54180"
  },
  {
    "text": "work on the canopy team on Facebook I recently moved to another team and and",
    "start": "54180",
    "end": "61230"
  },
  {
    "text": "so Michael recently joined the team as well and so we're using this also as an",
    "start": "61230",
    "end": "66540"
  },
  {
    "text": "opportunity to kind of like move me off of the advisory board and move Michael",
    "start": "66540",
    "end": "71850"
  },
  {
    "text": "onto the advisory board as well and so you have Michael hi I'm Michael I think",
    "start": "71850",
    "end": "79979"
  },
  {
    "text": "I'm unmuted yeah I know so I'm Michael I just recently doing Facebook and the canopy team before that I was actually",
    "start": "79979",
    "end": "87299"
  },
  {
    "text": "at Comcast for a while but actually worked on one of the things I worked on",
    "start": "87299",
    "end": "92610"
  },
  {
    "text": "there was actually our sort of internal tracing system as well you know which was which was the sort of X trace it can",
    "start": "92610",
    "end": "100140"
  },
  {
    "text": "you know dapper style one so I've kind of got a you know some experience with both worlds which is kind of interesting",
    "start": "100140",
    "end": "107149"
  },
  {
    "text": "yeah cool so yeah let me attempt to",
    "start": "107149",
    "end": "112409"
  },
  {
    "text": "share a screen which is like the last frontier and giving a presentation over the Internet",
    "start": "112409",
    "end": "119810"
  },
  {
    "text": "and so can everybody see this yes okay so yeah so we're gonna be",
    "start": "131840",
    "end": "142400"
  },
  {
    "text": "talking about canopy which is Facebook's distributed tracing and analysis system",
    "start": "142400",
    "end": "147620"
  },
  {
    "text": "this is kind of an amalgamation of a couple of talks we published a paper in",
    "start": "147620",
    "end": "153470"
  },
  {
    "text": "SOS pe 2017 last year two of our engineers talked to Q Khan in New York",
    "start": "153470",
    "end": "159079"
  },
  {
    "text": "and we're focusing this mostly on the instrumentation and representation of",
    "start": "159079",
    "end": "166510"
  },
  {
    "text": "canopy we'll talk a little bit about some of our distributed or some of our",
    "start": "166510",
    "end": "173409"
  },
  {
    "text": "trace analysis and trace analysis pipelines and so we'll be happy to sort",
    "start": "173409",
    "end": "178700"
  },
  {
    "text": "of like talk more about that but we're kind of focusing on the representation side",
    "start": "178700",
    "end": "184239"
  },
  {
    "text": "so yeah canopy is a an umbrella term but in for a wide set of things for tracing",
    "start": "184239",
    "end": "192799"
  },
  {
    "text": "at Facebook it encompasses both our a single and cross system tracing our",
    "start": "192799",
    "end": "199730"
  },
  {
    "text": "single own cross system analysis we have instrumentation available in a number of languages C C++ Python Java and because",
    "start": "199730",
    "end": "208400"
  },
  {
    "text": "Facebook PHP other languages are sort of supported through C or C++ bindings our",
    "start": "208400",
    "end": "216230"
  },
  {
    "text": "instrumentation is integrated into both are like common RPC stack that's shared",
    "start": "216230",
    "end": "221720"
  },
  {
    "text": "across all services it's integrated deeply into our dub-dub-dub stack so the",
    "start": "221720",
    "end": "227590"
  },
  {
    "text": "overall page load process both on the client and server as well as some other common pieces of infrastructure and then",
    "start": "227590",
    "end": "235910"
  },
  {
    "text": "we're also sort of able to ingest data from other sources so we have tracing and our mobile applications the profile",
    "start": "235910",
    "end": "245599"
  },
  {
    "text": "oh I think is the the name that we open sourced it under and so we're able to",
    "start": "245599",
    "end": "251359"
  },
  {
    "text": "ingest data from there and incorporate it into other traces through our back-end systems it also combines an",
    "start": "251359",
    "end": "259010"
  },
  {
    "text": "extraction and processing framework and so given a trace that we receive from some source we're able to run custom",
    "start": "259010",
    "end": "267050"
  },
  {
    "text": "user code to extract trace patterns information from a right them two datasets that we can then",
    "start": "267050",
    "end": "273030"
  },
  {
    "text": "do aggregate analysis on and then there is a separate team that works on performance visualizations and so they",
    "start": "273030",
    "end": "279750"
  },
  {
    "text": "work on both single trace and aggregate visualizations for these traces great",
    "start": "279750",
    "end": "294110"
  },
  {
    "text": "power",
    "start": "294110",
    "end": "297110"
  },
  {
    "text": "you",
    "start": "301550",
    "end": "303610"
  },
  {
    "text": "so can people see this again or girl",
    "start": "327559",
    "end": "334710"
  },
  {
    "text": "Giraud second yeah powerpoint is not happy with screen sharing okay I'm just",
    "start": "334710",
    "end": "343050"
  },
  {
    "text": "going to share the whole desktop and hopefully we won't get infinite recursion with the preview windows that",
    "start": "343050",
    "end": "351509"
  },
  {
    "text": "also pop up",
    "start": "351509",
    "end": "354259"
  },
  {
    "text": "okay so canopy is a little bit different than sort of other likes fan base",
    "start": "362009",
    "end": "369389"
  },
  {
    "text": "tracing systems we're an event based system that we then in our back end will",
    "start": "369389",
    "end": "374999"
  },
  {
    "text": "take those events and parse them into a higher level model because we're not",
    "start": "374999",
    "end": "380699"
  },
  {
    "text": "span based we also sort of have explicit edges between points we still enforce that the overall structure must be a dag",
    "start": "380699",
    "end": "387509"
  },
  {
    "text": "so we don't allow any edges that go backwards in time but otherwise you can",
    "start": "387509",
    "end": "394080"
  },
  {
    "text": "have sort of like edges between arbitrary points within your trace and then we also have sort of metadata that",
    "start": "394080",
    "end": "400349"
  },
  {
    "text": "every other tracing system has we've sort of layered types on top of them and",
    "start": "400349",
    "end": "405539"
  },
  {
    "text": "I'll talk a little bit more about what this means later so this is what our",
    "start": "405539",
    "end": "411419"
  },
  {
    "text": "overall model looks like we have sort of five basic objects in our trace we have",
    "start": "411419",
    "end": "418800"
  },
  {
    "text": "the overall trace that encompasses everything the trace is broken up into a number of execution units in a like",
    "start": "418800",
    "end": "427349"
  },
  {
    "text": "explicit manner and execution unit represents a sequence of or a sequence",
    "start": "427349",
    "end": "434550"
  },
  {
    "text": "of trace data that comes from a single clock in practice this usually",
    "start": "434550",
    "end": "439740"
  },
  {
    "text": "represents either a single host or a single thread within that host but it",
    "start": "439740",
    "end": "445050"
  },
  {
    "text": "can be used for modeling other primitives as well within an execution",
    "start": "445050",
    "end": "451079"
  },
  {
    "text": "unit Munich contains a number of blocks these are sort of the closest analog to spans a block represents some duration of time",
    "start": "451079",
    "end": "458790"
  },
  {
    "text": "it contains a start point and an end point and then zero or more other points",
    "start": "458790",
    "end": "464760"
  },
  {
    "text": "that may occur within the trace and then a point is just sort of an instant in",
    "start": "464760",
    "end": "469950"
  },
  {
    "text": "time that captures some single instant",
    "start": "469950",
    "end": "475110"
  },
  {
    "text": "and then edges connect two points together and so then all these objects can also have sort of arbitrary metadata",
    "start": "475110",
    "end": "482010"
  },
  {
    "text": "attached to them and so I said that we're we're an event-based tracing model",
    "start": "482010",
    "end": "489000"
  },
  {
    "text": "that we parse into a higher level model in the back end and so here's an example of what I mean by this suppose we have a",
    "start": "489000",
    "end": "496800"
  },
  {
    "text": "simple case with four events this is sort of the classic orefici call-and-response events these sort of",
    "start": "496800",
    "end": "504060"
  },
  {
    "text": "get broke you know we have a call to receive on some back-end service that",
    "start": "504060",
    "end": "511380"
  },
  {
    "text": "back-end service sends some response and then the parent service gets a records a complete event when it received the",
    "start": "511380",
    "end": "517500"
  },
  {
    "text": "response from the RPC call we're then",
    "start": "517500",
    "end": "522839"
  },
  {
    "text": "sort of we take these events and interpret them as okay there's some current block that the recall and",
    "start": "522839",
    "end": "528240"
  },
  {
    "text": "complete are part of they call to some other service which is generating a",
    "start": "528240",
    "end": "534360"
  },
  {
    "text": "block at the start in the end and then those are all both within some sort of execution unit as well and so this is",
    "start": "534360",
    "end": "541260"
  },
  {
    "text": "the base original instrumentation that we've had we've since extended these events over time as we've added new",
    "start": "541260",
    "end": "547950"
  },
  {
    "text": "model elements and so as we introduce execution units and explicit edges we've",
    "start": "547950",
    "end": "554430"
  },
  {
    "text": "introduced we've introduced events that allow users to create these within the to trace themselves so one benefit that",
    "start": "554430",
    "end": "563580"
  },
  {
    "text": "we get from having this decoupling of events from the actual model is that",
    "start": "563580",
    "end": "569760"
  },
  {
    "text": "we're able to update cross system instrumentation without having to carefully arrange releasing",
    "start": "569760",
    "end": "576780"
  },
  {
    "text": "instrumentation versions to both services at the same time in practice given you know service release schedules",
    "start": "576780",
    "end": "584160"
  },
  {
    "text": "it's impractical to assume that the instrumentation version on both sides of the boundary are going to be the same so you need to",
    "start": "584160",
    "end": "590069"
  },
  {
    "text": "have some compatibility across the boundary and so this decoupling allows us to say interpret events on one side",
    "start": "590069",
    "end": "596849"
  },
  {
    "text": "of the boundary differently if we update the instrumentation while keeping the instrumentation on the other side the",
    "start": "596849",
    "end": "602909"
  },
  {
    "text": "same and so then this allows us to handle sort of all combinations of cases where service a and service B may either",
    "start": "602909",
    "end": "609149"
  },
  {
    "text": "have old or new instrumentation or potentially even different instrumentation entirely so coming back",
    "start": "609149",
    "end": "619019"
  },
  {
    "text": "to the explicit edges this is probably the like biggest single difference",
    "start": "619019",
    "end": "624569"
  },
  {
    "text": "between a fan-based model and our model",
    "start": "624569",
    "end": "629809"
  },
  {
    "text": "all of these things can technically be represented within spans we found the",
    "start": "629809",
    "end": "634859"
  },
  {
    "text": "benefit of having explicit edges meaning that we haven't needed to change the structure to add additional changes",
    "start": "634859",
    "end": "641099"
  },
  {
    "text": "structure of the trace to add additional features and so for this I can walk through like one an example that we'd",
    "start": "641099",
    "end": "647579"
  },
  {
    "text": "have in our current system so we trace through browsers you know which includes",
    "start": "647579",
    "end": "653699"
  },
  {
    "text": "both the client-side JavaScript that's executing as well as the PHP running on the server and so you can imagine some",
    "start": "653699",
    "end": "660629"
  },
  {
    "text": "sort of JavaScript execution unit which is recording all the JavaScript that executes on in this particular page load",
    "start": "660629",
    "end": "667939"
  },
  {
    "text": "and so there's actually three separate hierarchies that can occur within or",
    "start": "667939",
    "end": "674459"
  },
  {
    "text": "three separate causality hierarchies that can occur within the trace here so you can have the sort of standard one",
    "start": "674459",
    "end": "682379"
  },
  {
    "text": "which is your JavaScript is making some sort of remote call in this case fetching a resource and then at some",
    "start": "682379",
    "end": "688349"
  },
  {
    "text": "point that resource will return and JavaScript is able to use it however we",
    "start": "688349",
    "end": "693989"
  },
  {
    "text": "also have a second causality hierarchy which is the function hierarchy and so you know the function call stack sort of",
    "start": "693989",
    "end": "701249"
  },
  {
    "text": "represents here our you know relations between parent functions and the child",
    "start": "701249",
    "end": "707009"
  },
  {
    "text": "function that they invoke and so we found that you know this is useful for sort of representing nested blocks so",
    "start": "707009",
    "end": "713909"
  },
  {
    "text": "you can have one block that is entirely contained with inside the execution of",
    "start": "713909",
    "end": "718920"
  },
  {
    "text": "parent block and we're able to use edges to sort of say that this child block is",
    "start": "718920",
    "end": "724410"
  },
  {
    "text": "part of this parent block without sort of having to represent it as the parent",
    "start": "724410",
    "end": "730499"
  },
  {
    "text": "function is making an RPC call to the child function which is occurring within the same thread the third causality is",
    "start": "730499",
    "end": "740669"
  },
  {
    "text": "actually an interesting one and it occurs in like I guess more and more languages over time but like JavaScript",
    "start": "740669",
    "end": "746609"
  },
  {
    "text": "and other continuation based languages and so here you can imagine our schedule function queues up some future that will",
    "start": "746609",
    "end": "753299"
  },
  {
    "text": "then be executed later on and so in this case like our causality isn't necessarily between the route functions",
    "start": "753299",
    "end": "761100"
  },
  {
    "text": "that we're executing but in this case we've scheduled some function and then we have some you know common",
    "start": "761100",
    "end": "766769"
  },
  {
    "text": "infrastructure stack which is executing these or pulling these entries off of the queue and executing them later and",
    "start": "766769",
    "end": "772799"
  },
  {
    "text": "so we need to connect to the actual function that we're executing instead of say the parent process function because",
    "start": "772799",
    "end": "779730"
  },
  {
    "text": "that may also be calling other futures that are not actually connected to the one that we scheduled and so like these",
    "start": "779730",
    "end": "788429"
  },
  {
    "text": "are sort of all you know parent-child relationships ish but what we found is",
    "start": "788429",
    "end": "795389"
  },
  {
    "text": "like they represent different you know different parent-child relationships and",
    "start": "795389",
    "end": "800759"
  },
  {
    "text": "having edges and specifically types for those edges allow us to say that the function the function hierarchy",
    "start": "800759",
    "end": "807689"
  },
  {
    "text": "relationship is different than the RPC hierarchy relationship is different from the continuation hierarchy relationship",
    "start": "807689",
    "end": "815720"
  },
  {
    "text": "so one other example we found like having the ability to create explicit edges has been useful is representing",
    "start": "815839",
    "end": "823169"
  },
  {
    "text": "application flow one of the like common",
    "start": "823169",
    "end": "828360"
  },
  {
    "text": "tools for understanding our traces is critical path analysis particularly for browser traces and so we ran into a",
    "start": "828360",
    "end": "836039"
  },
  {
    "text": "problem where we end up with say our JavaScript requesting a couple of resources and our JavaScript thread",
    "start": "836039",
    "end": "844169"
  },
  {
    "text": "tends to be fairly busy and so we would get traces that look like this",
    "start": "844169",
    "end": "849780"
  },
  {
    "text": "we wouldn't necessarily know which resource fetch is on the critical path and you could actually argue that you",
    "start": "849780",
    "end": "856770"
  },
  {
    "text": "know either one of these is potentially the resource fetch that is blocking",
    "start": "856770",
    "end": "861800"
  },
  {
    "text": "however if we have additional information from our application say when we actually end up using these",
    "start": "861800",
    "end": "868560"
  },
  {
    "text": "resources we can actually see in this case that we use resource two immediately but resource 1 we actually",
    "start": "868560",
    "end": "874980"
  },
  {
    "text": "don't need for some soup you know non-trivial amount of time and",
    "start": "874980",
    "end": "880350"
  },
  {
    "text": "so we could have actually delayed resource one significantly without affecting or overall time but it looks like resource two is actually are",
    "start": "880350",
    "end": "886620"
  },
  {
    "text": "blocking resource and so in this case we want to represent some sort of application flow that says we've",
    "start": "886620",
    "end": "892170"
  },
  {
    "text": "received this resource or this result of this RPC call but we don't actually need it for some period of time and we should",
    "start": "892170",
    "end": "899490"
  },
  {
    "text": "take this into account and we're actually computing the critical path and so here when we're computing the critical path through resource 1 we can",
    "start": "899490",
    "end": "905490"
  },
  {
    "text": "say that there's actually a slack in the critical path corresponding to the length of this required for edge this",
    "start": "905490",
    "end": "913740"
  },
  {
    "text": "has also allowed us to experiment with different representations of application application based logic so for instance",
    "start": "913740",
    "end": "921930"
  },
  {
    "text": "we've also experimented with saying that you know certain events must happen in",
    "start": "921930",
    "end": "928350"
  },
  {
    "text": "order for other events to even be considered and so again in the page load process there are some synchronization",
    "start": "928350",
    "end": "934650"
  },
  {
    "text": "points where we know that we won't receive we won't process a receive event",
    "start": "934650",
    "end": "939990"
  },
  {
    "text": "until some other synchronous event just happened and so we can say that this",
    "start": "939990",
    "end": "945120"
  },
  {
    "text": "synchronous that the synchronous event is going to be blocking anything before it and so it's a prerequisite for",
    "start": "945120",
    "end": "952320"
  },
  {
    "text": "anything else that happens afterwards so coming back to our metadata we have",
    "start": "952320",
    "end": "959520"
  },
  {
    "text": "sort of the standard string string annotation map that's common among you",
    "start": "959520",
    "end": "964890"
  },
  {
    "text": "know a lot of tracing platforms these can be attached to any object in the trace so points edges blocks execution",
    "start": "964890",
    "end": "974070"
  },
  {
    "text": "units or trace all of them have a metadata object associated with them we've made a distinction between what we",
    "start": "974070",
    "end": "981839"
  },
  {
    "text": "call core in error properties and so there are separate types and separate Maps for",
    "start": "981839",
    "end": "987340"
  },
  {
    "text": "each one of these the distinction is a little bit fuzzy between some of these",
    "start": "987340",
    "end": "993240"
  },
  {
    "text": "but effectively a core property is something which is used by our back-end",
    "start": "993240",
    "end": "998560"
  },
  {
    "text": "to interpret the trace and so for instance the type of an edge is a core property this also allows us to",
    "start": "998560",
    "end": "1005520"
  },
  {
    "text": "distinguish between annotations that users add and annotations that we absolutely must have for you know",
    "start": "1005520",
    "end": "1012510"
  },
  {
    "text": "loading or displaying the trace custom is then sort of a general bucket for any",
    "start": "1012510",
    "end": "1019100"
  },
  {
    "text": "any trace data or any annotation data that users add through their own instrumentation and then error",
    "start": "1019100",
    "end": "1026130"
  },
  {
    "text": "properties are typically used for noting errors in trace construction as opposed to errors in the overall execution of",
    "start": "1026130",
    "end": "1034650"
  },
  {
    "text": "the trace and so for instance we might use an error to indicate that the trace",
    "start": "1034650",
    "end": "1039780"
  },
  {
    "text": "instrumentation never closed a particular block versus like an RPC call",
    "start": "1039780",
    "end": "1045990"
  },
  {
    "text": "returned a particular error the other feature that we have is typed counters",
    "start": "1045990",
    "end": "1051450"
  },
  {
    "text": "and so there an explicit separate type from the string annotation map and so",
    "start": "1051450",
    "end": "1057060"
  },
  {
    "text": "these are counters that have a numerical value associated with them a particular",
    "start": "1057060",
    "end": "1063660"
  },
  {
    "text": "type and then also a precision and so this allows us to say things that like a",
    "start": "1063660",
    "end": "1068970"
  },
  {
    "text": "thousand and 24 bytes is distinct from a thousand and 24 milliseconds which is",
    "start": "1068970",
    "end": "1074310"
  },
  {
    "text": "distinct from 1024 kilobytes but it does allow us to say that if the user records",
    "start": "1074310",
    "end": "1079470"
  },
  {
    "text": "1,024 bytes in one place and one kilobyte in another place those two",
    "start": "1079470",
    "end": "1084630"
  },
  {
    "text": "values are actually equivalent we've also extended it over time to more types",
    "start": "1084630",
    "end": "1091170"
  },
  {
    "text": "as we've needed them and so we've introduced sets of strings that can sort of be appended to over time we've used",
    "start": "1091170",
    "end": "1098520"
  },
  {
    "text": "this in particular on say like execution units or traces and then also for a",
    "start": "1098520",
    "end": "1103560"
  },
  {
    "text": "stack frame so capturing either like sampled profiling data or the stack",
    "start": "1103560",
    "end": "1110250"
  },
  {
    "text": "frame at a particular RPC call so coming back to I guess putting this",
    "start": "1110250",
    "end": "1117330"
  },
  {
    "text": "all together in between like the metadata and our events we've run into the I guess some fun challenges in",
    "start": "1117330",
    "end": "1123690"
  },
  {
    "text": "modeling and so going back to our old instrumentation where we just had a call receive response and complete events",
    "start": "1123690",
    "end": "1131180"
  },
  {
    "text": "each of these has some associated metadata with them and one problem we ran into was well when we wanted to",
    "start": "1131180",
    "end": "1138030"
  },
  {
    "text": "extend this to you know blocks and points and execution units a call event",
    "start": "1138030",
    "end": "1144390"
  },
  {
    "text": "it now does more than just create an edge a call event actually ends up creating a point and an edge to the RPC",
    "start": "1144390",
    "end": "1152580"
  },
  {
    "text": "service that you're calling to and so there's an open there's a question of where does the metadata actually apply",
    "start": "1152580",
    "end": "1159240"
  },
  {
    "text": "to like does that metadata apply entirely to the point that it creates does it apply entirely to the edge that",
    "start": "1159240",
    "end": "1164610"
  },
  {
    "text": "it creates is there a mixture between we sort of made the decision that a call",
    "start": "1164610",
    "end": "1172440"
  },
  {
    "text": "represents the edge and the point is sort of a like side effect of that and so the metadata gets applied there but",
    "start": "1172440",
    "end": "1180960"
  },
  {
    "text": "this does mean that you know when users are using the old instrumentation they can't actually attach metadata to the",
    "start": "1180960",
    "end": "1187350"
  },
  {
    "text": "original calling point instead and so this is why we sort of extended the instrumentation over time to allow more",
    "start": "1187350",
    "end": "1194310"
  },
  {
    "text": "places for this metadata to apply and with that I will hand it over to Michael",
    "start": "1194310",
    "end": "1199980"
  },
  {
    "text": "I don't do you want to try sharing your screen instead or you want me to walk",
    "start": "1199980",
    "end": "1206280"
  },
  {
    "text": "through the slides as you talk all right let's see that's that's like it I feel",
    "start": "1206280",
    "end": "1211800"
  },
  {
    "text": "like this this is dangerous either way I'll give it I'll give sharing my screen",
    "start": "1211800",
    "end": "1217500"
  },
  {
    "text": "shot okay yeah all right or the green",
    "start": "1217500",
    "end": "1225480"
  },
  {
    "text": "thing hovering over all right did anything",
    "start": "1225480",
    "end": "1237720"
  },
  {
    "text": "good happen on the other end oh yeah I can't believe it worked all right okay let's let's just all right",
    "start": "1237720",
    "end": "1247210"
  },
  {
    "text": "Thanks so so you kind of pick up from uh what's that oh yeah presenter I know how to use",
    "start": "1247210",
    "end": "1253930"
  },
  {
    "text": "PowerPoint everyone don't do that man",
    "start": "1253930",
    "end": "1260890"
  },
  {
    "text": "disaster averted all right great so so yeah it kind of pick up from where",
    "start": "1260890",
    "end": "1267610"
  },
  {
    "text": "where Jonathan left off you know it was kind of interesting before I before I",
    "start": "1267610",
    "end": "1272920"
  },
  {
    "text": "came here you know I worked with we had a well we've open source has open",
    "start": "1272920",
    "end": "1279430"
  },
  {
    "text": "sourced it but uh a you know very span based sort of a span based tracing",
    "start": "1279430",
    "end": "1286090"
  },
  {
    "text": "system we called it money as in like follow the money and then we had all these like clever things around it like the money bank was where all the traces",
    "start": "1286090",
    "end": "1292750"
  },
  {
    "text": "lived and stuff so it was fun but the you know we didn't run into like some of",
    "start": "1292750",
    "end": "1299050"
  },
  {
    "text": "the modeling issues that Jonathan was was talking about and actually two in particular that like we we kind of ran",
    "start": "1299050",
    "end": "1304510"
  },
  {
    "text": "into there and then read the canopy paper and then I quit and came here like you know that we were like hey this",
    "start": "1304510",
    "end": "1310540"
  },
  {
    "text": "could actually be useful were you know one is we had these sort of situations where we had a trace on a particular",
    "start": "1310540",
    "end": "1318790"
  },
  {
    "text": "system and you know a bunch of stuff is going on in the system when you just wanted to to sort of attach like a",
    "start": "1318790",
    "end": "1324640"
  },
  {
    "text": "profile of what was happening on that system at you know various levels um to",
    "start": "1324640",
    "end": "1330130"
  },
  {
    "text": "the trace and you know kind of the best way we could think of to do that in the",
    "start": "1330130",
    "end": "1336490"
  },
  {
    "text": "sort of span based model was you have a sort of a top level span that represented like the entire scope of the",
    "start": "1336490",
    "end": "1343660"
  },
  {
    "text": "execution and you start profiling and then end profiling when that thing closes and and try and attach that",
    "start": "1343660",
    "end": "1349450"
  },
  {
    "text": "profile to that top level span um but then it was kind of like in turn you had to know that span was kind of like special right like that was the one that",
    "start": "1349450",
    "end": "1356230"
  },
  {
    "text": "that like had the profiling information right it wasn't that bad but it was actually kind of clumsy as far as the tooling rebuilding around it went and in",
    "start": "1356230",
    "end": "1363400"
  },
  {
    "text": "sort of the the canopy model is actually kind of more natural to just annotate the execution unit that represents that",
    "start": "1363400",
    "end": "1369580"
  },
  {
    "text": "like request handling right because we use that sort of naturally represent you know here's the entire span of",
    "start": "1369580",
    "end": "1376350"
  },
  {
    "text": "processing an individual request but not span and tres and cousins and another interesting",
    "start": "1376350",
    "end": "1383120"
  },
  {
    "text": "one was if you just had to click some work in a queue and you wanted to understand you know how long was in there alright and when it came out you",
    "start": "1383120",
    "end": "1390140"
  },
  {
    "text": "know the that's actually pretty naturally modeled by another execution unit with points for in qdq and edges",
    "start": "1390140",
    "end": "1397850"
  },
  {
    "text": "for causality right whereas like if you sort of put it into you know you could",
    "start": "1397850",
    "end": "1404720"
  },
  {
    "text": "model out as a separate span and this start you know starting into the span or when it goes into and out of the queue but it sort of means a very very",
    "start": "1404720",
    "end": "1411530"
  },
  {
    "text": "different thing than like most of the other spins do where it's like an actual RPC graph like it's like oh no you just",
    "start": "1411530",
    "end": "1418100"
  },
  {
    "text": "have to know you know as far as your tooling and stuff goes it's like oh well that particular span happens to be one that represents like this thing sitting",
    "start": "1418100",
    "end": "1424730"
  },
  {
    "text": "in a queue for a while um so so those are a couple of things that we actually did struggle with the modeling",
    "start": "1424730",
    "end": "1430429"
  },
  {
    "text": "perspective that we were actually pretty interested in when we read the canopy paper to sort of help us out with so you",
    "start": "1430429",
    "end": "1436670"
  },
  {
    "text": "know just kind of worth noting it was it was kind of an interesting thing to sort of see it from one side and now start to",
    "start": "1436670",
    "end": "1442309"
  },
  {
    "text": "see it from the other so so that said I wanted to sort of move on a little bit",
    "start": "1442309",
    "end": "1448309"
  },
  {
    "text": "to talk a little bit about what we're we're doing now and sort of where we're focusing um you know I guess Facebook's",
    "start": "1448309",
    "end": "1455450"
  },
  {
    "text": "probably grown quite a bit in the past you know X years and we've got a ton of",
    "start": "1455450",
    "end": "1461510"
  },
  {
    "text": "engineering teams right so one of the things we're focusing in on is getting getting the backend API is that you know",
    "start": "1461510",
    "end": "1469280"
  },
  {
    "text": "Jonathan alluded to into a point where they're safe and like clear and usable",
    "start": "1469280",
    "end": "1475360"
  },
  {
    "text": "so that means for us actually sampling isn't enough we also need great limiting",
    "start": "1475360",
    "end": "1481040"
  },
  {
    "text": "and I'll kind of go into that a little bit later we also want these sort of somewhat tailored you know high-quality",
    "start": "1481040",
    "end": "1486710"
  },
  {
    "text": "api's instrumentation layers that are for you know back-end use cases right",
    "start": "1486710",
    "end": "1492290"
  },
  {
    "text": "now we're you know what we really wanna be is where we have just sort of like most of the complexity in dealing with",
    "start": "1492290",
    "end": "1499970"
  },
  {
    "text": "you know the the underlying model is handling sort of instrumentation layer and an end user the system just sort of",
    "start": "1499970",
    "end": "1506929"
  },
  {
    "text": "has like a small set of functions like log a point right and it you know the instrumentation layer just says oh okay",
    "start": "1506929",
    "end": "1512540"
  },
  {
    "text": "well here's the active execution you here's an active block and we'll put a point on it or if you need to put a new",
    "start": "1512540",
    "end": "1517550"
  },
  {
    "text": "block alongside of you know the sort of default one you'd sort of do that an easy way um you know so so we really",
    "start": "1517550",
    "end": "1524000"
  },
  {
    "text": "want to do is just make tracing on on the back end just like really really easy for folks that are that are",
    "start": "1524000",
    "end": "1530360"
  },
  {
    "text": "building back in services the the PHP instrumentation we have that Jonathan mentioned actually kind of does that to",
    "start": "1530360",
    "end": "1536690"
  },
  {
    "text": "an extent already um but you know we sort of exposed a lot more of the underlying gots to to back-end folks",
    "start": "1536690",
    "end": "1543170"
  },
  {
    "text": "right now I you know and then another thing that actually ends up being useful",
    "start": "1543170",
    "end": "1548360"
  },
  {
    "text": "for is having you know sort of different api's that are good for different situations so you know one of the things",
    "start": "1548360",
    "end": "1555440"
  },
  {
    "text": "that we did we're just working with one of our teams that has some like really really um stringent sort of perfect quirements as",
    "start": "1555440",
    "end": "1562310"
  },
  {
    "text": "far as memory usage goes and then sort of you know they really worry about things like like thread contention um",
    "start": "1562310",
    "end": "1568370"
  },
  {
    "text": "the sort of flexibility underlying models actually going to let us fairly easily create like a fairly tale or you",
    "start": "1568370",
    "end": "1574250"
  },
  {
    "text": "know hey if you need to if you have a really high performance you know RPC system and look you don't want things",
    "start": "1574250",
    "end": "1581600"
  },
  {
    "text": "going on behind the scenes that could cause additional thread contention or memory allocation like use this API um you know so so that's one thing and then",
    "start": "1581600",
    "end": "1590570"
  },
  {
    "text": "the other thing we're working on is actually a sort of a revamp of if anybody's read the the canopy paper",
    "start": "1590570",
    "end": "1596780"
  },
  {
    "text": "there's a there's I think they're referred to as I think custom extraction",
    "start": "1596780",
    "end": "1602270"
  },
  {
    "text": "functions or something like that but but it's essentially a DSL for working with traces that happen to run in our",
    "start": "1602270",
    "end": "1608300"
  },
  {
    "text": "back-end we're working on sort of revamp you know expanded version of that that'll run a you know in a separate set",
    "start": "1608300",
    "end": "1615260"
  },
  {
    "text": "of processes elsewhere and use a you know then be based on sort of Python rather than this completely custom DSL",
    "start": "1615260",
    "end": "1621770"
  },
  {
    "text": "so it's really the two things were working on now that that's actually super important for us because we tend",
    "start": "1621770",
    "end": "1627770"
  },
  {
    "text": "to look at traces in aggregate a lot um and we just sort of compute like summary you know information about traces often",
    "start": "1627770",
    "end": "1634190"
  },
  {
    "text": "right and you know but stuff that's sort of covered in the paper but I think the way we're going to be doing it is sit on",
    "start": "1634190",
    "end": "1642080"
  },
  {
    "text": "the the safety an API clarity side like this is kind of a um this is this",
    "start": "1642080",
    "end": "1647510"
  },
  {
    "text": "sort of an overview of what the instrumentation stack really looks like for us at the the bottom layer we've got",
    "start": "1647510",
    "end": "1654410"
  },
  {
    "text": "like a layer of sinks that do nothing you know just the old serializing the events that Jonathan mention and",
    "start": "1654410",
    "end": "1659450"
  },
  {
    "text": "flushing them somewhere um you know we've sort of an internal Kafkaesque system that you know is used on top of",
    "start": "1659450",
    "end": "1666200"
  },
  {
    "text": "that there's a trace model that really you know represents that that that trace",
    "start": "1666200",
    "end": "1672080"
  },
  {
    "text": "model as an object model but doesn't let you do things that don't make sense right like you can't create like a block",
    "start": "1672080",
    "end": "1678020"
  },
  {
    "text": "on a point for instance right but it just makes it makes a little bit easier to work with but you know when you do things that they're you know when you do",
    "start": "1678020",
    "end": "1684740"
  },
  {
    "text": "things with that model it'll give you pointers so you can sort of keep reference them in your code and then flush them you know it'll flush things",
    "start": "1684740",
    "end": "1690740"
  },
  {
    "text": "to events usually usually right away but you can do some things before that if you need to and then on top of that",
    "start": "1690740",
    "end": "1698270"
  },
  {
    "text": "we've got sort of a set of code that deals with creating instrumentation layers right because we don't want",
    "start": "1698270",
    "end": "1704930"
  },
  {
    "text": "people to have to worry about things like you know propagating context either",
    "start": "1704930",
    "end": "1710000"
  },
  {
    "text": "through thread boundaries in their system or you know across system boundaries we don't want people to have",
    "start": "1710000",
    "end": "1715310"
  },
  {
    "text": "to like understand really really understand that trace model deeply understand which parts are active right",
    "start": "1715310",
    "end": "1720740"
  },
  {
    "text": "we just want an underlying instrumentation to take care of that we obviously don't want people to have to do their own rate-limiting because they",
    "start": "1720740",
    "end": "1726350"
  },
  {
    "text": "won't and then our system will get you know knocked over so that's not great",
    "start": "1726350",
    "end": "1731660"
  },
  {
    "text": "but then the the whole idea being on top of that we've got this sort of instrumentation kit to build back in",
    "start": "1731660",
    "end": "1737450"
  },
  {
    "text": "instrumentations we've got a set of instrumentations built on it that we are that are either built or we'll be building on top of",
    "start": "1737450",
    "end": "1743750"
  },
  {
    "text": "that um and then we really want to have most folks leverage is sort of this high level API that really just lets them do",
    "start": "1743750",
    "end": "1750170"
  },
  {
    "text": "like a few simple things right and all of the more complex pieces are handled by instrumentation right like at the end",
    "start": "1750170",
    "end": "1756290"
  },
  {
    "text": "at the end of the day you know soda lacked something more like a logging framework right like you log a point or",
    "start": "1756290",
    "end": "1762710"
  },
  {
    "text": "you create a point and it it goes into the right place on the trace right it goes on the right block all right",
    "start": "1762710",
    "end": "1768530"
  },
  {
    "text": "execution unit and you know and so on and then you know maybe exposing you know some a little bit of additional",
    "start": "1768530",
    "end": "1774560"
  },
  {
    "text": "stuff at that high level that that you know handles like the 80% use case and then if we need to",
    "start": "1774560",
    "end": "1781170"
  },
  {
    "text": "something more sophisticated you know people would have to go sort of layers down in this API stack to do it um right",
    "start": "1781170",
    "end": "1787710"
  },
  {
    "text": "and then like I'd mentioned earlier another another thing that we're we're talking about doing sort of on top of this is creating just to really really",
    "start": "1787710",
    "end": "1795210"
  },
  {
    "text": "performant but but much more constrained API on that sure just does that RPC",
    "start": "1795210",
    "end": "1801660"
  },
  {
    "text": "trace model for some you know particularly use cases and it's kind of nice that like this not only the",
    "start": "1801660",
    "end": "1806940"
  },
  {
    "text": "underlying you know event an object model sort of gives us that flexibility but you know sort the instrumentation",
    "start": "1806940",
    "end": "1813240"
  },
  {
    "text": "that we've got built up lets us do that too so this is a quick overview of the",
    "start": "1813240",
    "end": "1820830"
  },
  {
    "text": "other big chunk of stuff we're working on now which is actually borrowed from the cue comment presentation of to the",
    "start": "1820830",
    "end": "1826530"
  },
  {
    "text": "other gentleman in the room Edison yeah",
    "start": "1826530",
    "end": "1833820"
  },
  {
    "text": "yeah we're good at we're good at video conferences over here 7:00 so so but but",
    "start": "1833820",
    "end": "1841770"
  },
  {
    "text": "basically are saying this is really a domain-specific stream processing engine",
    "start": "1841770",
    "end": "1847920"
  },
  {
    "text": "right and and language for processing streams of traces and if you look at",
    "start": "1847920",
    "end": "1854910"
  },
  {
    "text": "sort of the way that we tend to use trace data and we do a bunch of different things with it",
    "start": "1854910",
    "end": "1860640"
  },
  {
    "text": "one of one of those things is I'll be just like looking at an individual trace which is you know kind of useful if you",
    "start": "1860640",
    "end": "1866820"
  },
  {
    "text": "know which trace to look at but if you don't even know that um you know or if",
    "start": "1866820",
    "end": "1872760"
  },
  {
    "text": "you want to compare you know data in aggregate before and after some of that",
    "start": "1872760",
    "end": "1877980"
  },
  {
    "text": "right like you know a deployment or something and see what's happened right or if you just want to compute you know",
    "start": "1877980",
    "end": "1884340"
  },
  {
    "text": "summary statistics off of something that can only be derived from you know a trace right you know with that actually",
    "start": "1884340",
    "end": "1892710"
  },
  {
    "text": "ends up being I think a more common use case for us than just looking at an individual trace um so so really what",
    "start": "1892710",
    "end": "1901320"
  },
  {
    "text": "this soso yeah so this is a domain-specific string processing you know system for forgetting at that sort",
    "start": "1901320",
    "end": "1908580"
  },
  {
    "text": "of stuff right and we've had a bunch of things that are built on top of it at a high level you know",
    "start": "1908580",
    "end": "1914520"
  },
  {
    "text": "really what we've got sort of a configuration based we've got our you know internal configuration system that",
    "start": "1914520",
    "end": "1920160"
  },
  {
    "text": "you sort of put you know this python-based you know DSL into that's",
    "start": "1920160",
    "end": "1928260"
  },
  {
    "text": "run by this this whole set of sort of machines that will go in and run those on a per a sort of use case basis",
    "start": "1928260",
    "end": "1935040"
  },
  {
    "text": "alright so it's it's sort of you know in the old system that's mentioned in the paper we kind of ran the the moral",
    "start": "1935040",
    "end": "1940710"
  },
  {
    "text": "equivalent of this all that sort of one you know said am infer that was also doing a bunch of other things you know",
    "start": "1940710",
    "end": "1946620"
  },
  {
    "text": "this one the use case are actually split out separate sort of you know chunks of machine for different you know use cases",
    "start": "1946620",
    "end": "1953820"
  },
  {
    "text": "different essentially going back to different users of the system right that are gonna be doing vastly different",
    "start": "1953820",
    "end": "1959580"
  },
  {
    "text": "things so that way we get some more blood isolation and they're not stomping on one another the and then we sort of",
    "start": "1959580",
    "end": "1967260"
  },
  {
    "text": "export summary statistics to you know an internal database called scuba and folks",
    "start": "1967260",
    "end": "1972780"
  },
  {
    "text": "build things on top of that so those are really the two big things we're working",
    "start": "1972780",
    "end": "1979020"
  },
  {
    "text": "on for the time being and then though yeah the other important thing about this that I didn't mention which is",
    "start": "1979020",
    "end": "1986310"
  },
  {
    "text": "different from the stuff in the papers that this actually does allow us to do sort of ad hoc queries right which was",
    "start": "1986310",
    "end": "1992340"
  },
  {
    "text": "not possible with your old system so that's super useful if you especially when you don't even know what you what",
    "start": "1992340",
    "end": "1998550"
  },
  {
    "text": "your yeah yeah one more good after that yeah all right let's let's see yes this",
    "start": "1998550",
    "end": "2007100"
  },
  {
    "text": "is this is this is a slot I stole from Joe so that's the stuff we're working on",
    "start": "2007100",
    "end": "2013640"
  },
  {
    "text": "now and this is just some stuff that sort of you know kind of keeps coming up again and again that were you know",
    "start": "2013640",
    "end": "2019820"
  },
  {
    "text": "thinking about don't know to what extent will actually end up really tackling this but I think they're interesting",
    "start": "2019820",
    "end": "2025880"
  },
  {
    "text": "things that no one I think we're thinking about but I've sort of seen other folks thinking about too so I thought it was worth mentioning one of",
    "start": "2025880",
    "end": "2032450"
  },
  {
    "text": "them is how do we sort of safely do a more arbitrary context propagation at scale and and and the interesting thing",
    "start": "2032450",
    "end": "2038690"
  },
  {
    "text": "a scale here is actually more the diversity of teams and workloads than sort of the scale of you know our",
    "start": "2038690",
    "end": "2044510"
  },
  {
    "text": "overall infrastructure you know there's there's sort of a and then I",
    "start": "2044510",
    "end": "2050840"
  },
  {
    "text": "think anybody who's done this at like a big company has almost certainly came across the use case where somebody's like hey there's this stuff that'll like",
    "start": "2050840",
    "end": "2058070"
  },
  {
    "text": "magically propagate like this idea around and like I want that to probably get my session ID like so you know the",
    "start": "2058070",
    "end": "2066379"
  },
  {
    "text": "notion of having a more abstract way of of using the underlying right wherever you've got the tracing instrumentation",
    "start": "2066380",
    "end": "2072649"
  },
  {
    "text": "of being able to propagate context through which I know is you know in in open tracing with baggage and and the",
    "start": "2072650",
    "end": "2078950"
  },
  {
    "text": "paper that uh you know Jonathan mace I think wrote like is has some really good",
    "start": "2078950",
    "end": "2083990"
  },
  {
    "text": "stuff in it um but I think one of the including things is like once you open",
    "start": "2083990",
    "end": "2089360"
  },
  {
    "text": "up that capability you know like how do you keep people from doing really really",
    "start": "2089360",
    "end": "2095030"
  },
  {
    "text": "bad things with it and such bad things that you end up having to turn it off is kind of a an open question um and I",
    "start": "2095030",
    "end": "2101630"
  },
  {
    "text": "think it's kind of worth thinking about like is there a difference between you know that sort of really common use case",
    "start": "2101630",
    "end": "2106940"
  },
  {
    "text": "of like hey I just want to propagate an ID sort of within my system boundaries for some sort of session or something",
    "start": "2106940",
    "end": "2112600"
  },
  {
    "text": "versus the broader you know I need some context that really might propagate across a very wide set of system",
    "start": "2112600",
    "end": "2118970"
  },
  {
    "text": "boundaries and just in terms of like safety for some sort of context broad and then another one is which which",
    "start": "2118970",
    "end": "2126230"
  },
  {
    "text": "Jonathan mentioned earlier like one of the interesting things that I think this does fall directly out of the model the",
    "start": "2126230",
    "end": "2132860"
  },
  {
    "text": "the sort of canopy data model is that it's actually really really good at doing single node traces as well and we",
    "start": "2132860",
    "end": "2139220"
  },
  {
    "text": "get like really detailed traces of mobile clients and dub-dub-dub and and folks actually want to get like really",
    "start": "2139220",
    "end": "2145100"
  },
  {
    "text": "detailed traces of their own back-end systems you know um so but it's like",
    "start": "2145100",
    "end": "2150230"
  },
  {
    "text": "well how do you then take that really detailed view of a little piece of the system and working into an overall you",
    "start": "2150230",
    "end": "2156500"
  },
  {
    "text": "know distributed trace that that's probably broader um you know you sort of create a lot of noise for people I just",
    "start": "2156500",
    "end": "2162800"
  },
  {
    "text": "want that broad view but then sometimes you know the person that's like looking at that really detailed view might want",
    "start": "2162800",
    "end": "2169100"
  },
  {
    "text": "to look at something you know a few layers back so there's actually a couple of different ways that we've talked",
    "start": "2169100",
    "end": "2174230"
  },
  {
    "text": "about modeling that and there's some different thing you talked about doing that doing with that in terms of like viz tooling you know and so on but it's",
    "start": "2174230",
    "end": "2181250"
  },
  {
    "text": "but it's actually kind of just you know it's kind of built the question of how we actually get like a good solid",
    "start": "2181250",
    "end": "2186380"
  },
  {
    "text": "end-to-end trace while still having like these chunks of like really really detailed trace at various parts of the",
    "start": "2186380",
    "end": "2193190"
  },
  {
    "text": "system in there and you know they really are different things with different audiences you know so so yeah so those",
    "start": "2193190",
    "end": "2199160"
  },
  {
    "text": "two the things that I think we're we're thinking about and you know may or may not do anything useful with cool so",
    "start": "2199160",
    "end": "2207730"
  },
  {
    "text": "anybody have any questions ever scream",
    "start": "2207730",
    "end": "2216170"
  },
  {
    "text": "but they don't want to ask on this group because then it's gonna take forever",
    "start": "2216170",
    "end": "2221590"
  },
  {
    "text": "well Jonathan is available for all questions at any time so just you know I",
    "start": "2221619",
    "end": "2231310"
  },
  {
    "text": "have a question about metrics and aggregates actually I'm wondering I mean",
    "start": "2231310",
    "end": "2238250"
  },
  {
    "text": "obviously you have an event based system and you're rolling up some amount of aggregates out of that you know into",
    "start": "2238250",
    "end": "2244910"
  },
  {
    "text": "your tracing system but are you doing kind of all metrics extraction based on",
    "start": "2244910",
    "end": "2249980"
  },
  {
    "text": "the system or do you have a totally separate metric system and if so are you kind of sharing are you using the",
    "start": "2249980",
    "end": "2256970"
  },
  {
    "text": "tracing system for context propagation and like how are do those two things relate to each other",
    "start": "2256970",
    "end": "2263619"
  },
  {
    "text": "so we have there's an independent metrics based system for sort of like",
    "start": "2263849",
    "end": "2269520"
  },
  {
    "text": "operational management the traces will tend to the traces can share some of the",
    "start": "2269520",
    "end": "2277020"
  },
  {
    "text": "data from those metrics there's some caveats usually there where like the",
    "start": "2277020",
    "end": "2283380"
  },
  {
    "text": "metrics captured our system level but say we want to capture request level metrics within a trace but we can sort",
    "start": "2283380",
    "end": "2291270"
  },
  {
    "text": "of hold the same like overall system CPU utilization and things like that",
    "start": "2291270",
    "end": "2297690"
  },
  {
    "text": "what was the oh yeah and so then that has a separate aggregation piece because",
    "start": "2297690",
    "end": "2303930"
  },
  {
    "text": "they're kind of collecting at some regular interval over hosts whereas",
    "start": "2303930",
    "end": "2309750"
  },
  {
    "text": "we're sort of like very fundamentally kind of request base and then there was",
    "start": "2309750",
    "end": "2315930"
  },
  {
    "text": "a question about context propagation I think yes so well I mean it sounds like",
    "start": "2315930",
    "end": "2321270"
  },
  {
    "text": "you actually have things separated between system metrics and then maybe your application level metrics are coming out of the tracing system but the",
    "start": "2321270",
    "end": "2328380"
  },
  {
    "text": "degree to which you may want to dimensionalize some metrics is that all",
    "start": "2328380",
    "end": "2333569"
  },
  {
    "text": "happening you know that context tends to get propagated in the tracer which is just wondering how that really yeah so",
    "start": "2333569",
    "end": "2339930"
  },
  {
    "text": "one of the places where there is actually overlap is if you want to",
    "start": "2339930",
    "end": "2345690"
  },
  {
    "text": "understand say be if the overall global efficiency of a particular system and in",
    "start": "2345690",
    "end": "2352049"
  },
  {
    "text": "particular the resources that it's utilizing as a whole you do need to kind of look at the resources captured",
    "start": "2352049",
    "end": "2359339"
  },
  {
    "text": "through traces that you know the trace starts at some particular point and then",
    "start": "2359339",
    "end": "2364859"
  },
  {
    "text": "you're looking at sort of like what are the resources used by this particular request and then aggregating over all of",
    "start": "2364859",
    "end": "2370799"
  },
  {
    "text": "these requests in some sampled fashion to understand like request based",
    "start": "2370799",
    "end": "2376470"
  },
  {
    "text": "utilization through the system where we're currently using tracing for that",
    "start": "2376470",
    "end": "2382640"
  },
  {
    "text": "like this is fundamentally at Facebook",
    "start": "2382640",
    "end": "2387779"
  },
  {
    "text": "like context propagation and tracing are fundamentally tied together for better",
    "start": "2387779",
    "end": "2393089"
  },
  {
    "text": "or worse and so that's where like as Michael said like we end up with these cases where people",
    "start": "2393089",
    "end": "2399740"
  },
  {
    "text": "are like man I really need to propagate a context and like let me turn on tracing and we're like you know yeah and",
    "start": "2399740",
    "end": "2407900"
  },
  {
    "text": "and and that like we don't we don't have a decoupled generalized context",
    "start": "2407900",
    "end": "2413990"
  },
  {
    "text": "propagation system and I think you know to that sort of like how do we do that safely with the number of teams that we",
    "start": "2413990",
    "end": "2421609"
  },
  {
    "text": "have is sort of an open sort of operational question that you know what to think about and see if we can tackle",
    "start": "2421609",
    "end": "2428000"
  },
  {
    "text": "at some point but um but yeah it's it's interesting we have this many different",
    "start": "2428000",
    "end": "2434750"
  },
  {
    "text": "folks sort of that you know yeah it just",
    "start": "2434750",
    "end": "2441040"
  },
  {
    "text": "yeah I hear that Thanks anyone have anything else so on",
    "start": "2441070",
    "end": "2456380"
  },
  {
    "text": "the safety piece on context confirmation like you kind of given us the problem",
    "start": "2456380",
    "end": "2462050"
  },
  {
    "text": "and I totally understand the problem with went through this you have any thoughts on how you're actually a nice solvent I I have some thoughts",
    "start": "2462050",
    "end": "2470270"
  },
  {
    "text": "although the interesting thing I realized I somehow when I redid these slides I I skipped my slide on",
    "start": "2470270",
    "end": "2475940"
  },
  {
    "text": "rate-limiting which is actually the the important safety piece were tackling now so actually maybe I'll just go over that",
    "start": "2475940",
    "end": "2481700"
  },
  {
    "text": "really quick the other big thing we do with the API cleanup is we're actually adding pervasive rate-limiting at and as",
    "start": "2481700",
    "end": "2487220"
  },
  {
    "text": "well after uh you know after the sampling arm sampling actually ends up",
    "start": "2487220",
    "end": "2493970"
  },
  {
    "text": "not being quite enough for us because you know if somebody's doing a coin flip",
    "start": "2493970",
    "end": "2499220"
  },
  {
    "text": "that they expect to be on like a tiny percentage of traffic like maybe in a region that you know is being used for",
    "start": "2499220",
    "end": "2505820"
  },
  {
    "text": "like you know for some experiment and then suddenly a lot of traffic fails over to there you know suddenly you can",
    "start": "2505820",
    "end": "2512000"
  },
  {
    "text": "sort of get this explosion of traffic just because of that so we're actually adding rate limits on a per trace and",
    "start": "2512000",
    "end": "2518420"
  },
  {
    "text": "the N trace size you know before we can actually sort of start new traces to",
    "start": "2518420",
    "end": "2524300"
  },
  {
    "text": "cover that so that's actually one important safety piece as far as generalized context prop",
    "start": "2524300",
    "end": "2529460"
  },
  {
    "text": "is uh you know I think it's something we've been talking about for a while and starting to think about I do think that",
    "start": "2529460",
    "end": "2538660"
  },
  {
    "text": "opening up a sort of completely generalized system and like saying you",
    "start": "2538660",
    "end": "2544640"
  },
  {
    "text": "know like any engineering team and an organization of our size is free to like go and attach baggage to this thing is",
    "start": "2544640",
    "end": "2551420"
  },
  {
    "text": "like a non-starter we have you know we've got systems that you know that",
    "start": "2551420",
    "end": "2556880"
  },
  {
    "text": "that are they're extremely memory sensitive where you know that like the engineers that sort of when those teams",
    "start": "2556880",
    "end": "2562460"
  },
  {
    "text": "would you know we'd sort of rightfully just you know haha say very loud things",
    "start": "2562460",
    "end": "2569200"
  },
  {
    "text": "you know and then I think if you look at some of the the safety that safety that was sort of in the the paper that",
    "start": "2569200",
    "end": "2575119"
  },
  {
    "text": "Jonathan wrote don't know if he's around but you know essentially it comes down",
    "start": "2575119",
    "end": "2580250"
  },
  {
    "text": "to like having a principled way of like you know capping the amount of size that the amount of data that gets propagated",
    "start": "2580250",
    "end": "2586869"
  },
  {
    "text": "um but then it sort of has this like downside of like oh maybe you really really rely on a particular piece of",
    "start": "2586869",
    "end": "2592490"
  },
  {
    "text": "data you know now it's not there I think so the extent that I've thought it through I do think it's really really",
    "start": "2592490",
    "end": "2598400"
  },
  {
    "text": "worth thinking about how do you separate out the use case where somebody wants to propagate an ID within their system",
    "start": "2598400",
    "end": "2605119"
  },
  {
    "text": "bounds and then sort of attach metadata to it after the fact that can be processed by like some other system",
    "start": "2605119",
    "end": "2611330"
  },
  {
    "text": "right and have it emit that data but sort of like then not have that ID crossed you know be propagated outside",
    "start": "2611330",
    "end": "2617810"
  },
  {
    "text": "of the bounds of their particular you know set of systems and then separating that out from like the generalized",
    "start": "2617810",
    "end": "2623180"
  },
  {
    "text": "context prop which should be very strictly controlled and really only used for like a specific set of blessed",
    "start": "2623180",
    "end": "2629720"
  },
  {
    "text": "things with like a decent amount of process around putting things in them upfront right and like some like some",
    "start": "2629720",
    "end": "2636349"
  },
  {
    "text": "like set of configurations that like can't be changed outside of like you know review by some accountable team so",
    "start": "2636349",
    "end": "2643339"
  },
  {
    "text": "you know to the extent that I've thought through it like that's sort of where I've landed but you know that's just we",
    "start": "2643339",
    "end": "2649520"
  },
  {
    "text": "haven't really really worked on it heavily yet I've tossed around the idea",
    "start": "2649520",
    "end": "2655849"
  },
  {
    "text": "of like prioritized namespaces this realm I have actually implemented any of",
    "start": "2655849",
    "end": "2662000"
  },
  {
    "text": "that yet yeah yeah you know and I think I think stuff like that I think is is you know",
    "start": "2662000",
    "end": "2667610"
  },
  {
    "text": "it's good um but then I think you do sort of run it at least in our rules we",
    "start": "2667610",
    "end": "2672950"
  },
  {
    "text": "don't run into this thing like well okay what if you know the data in your most prioritized namespace is larger than",
    "start": "2672950",
    "end": "2679910"
  },
  {
    "text": "like the amount of data that like the most you know sort of the most conservative team is willing to accept",
    "start": "2679910",
    "end": "2686540"
  },
  {
    "text": "you know so you kind of just like need some I think you do need to like sort of",
    "start": "2686540",
    "end": "2692540"
  },
  {
    "text": "really tightly control like you know the generalized thing and then try and figure out how to build the more you",
    "start": "2692540",
    "end": "2699980"
  },
  {
    "text": "know hey if you want to do something within your own system bounce thing on the same you know context prop but you",
    "start": "2699980",
    "end": "2706010"
  },
  {
    "text": "know so I think I think really had the notion of having like some sort of system bounds that say you know what",
    "start": "2706010",
    "end": "2711020"
  },
  {
    "text": "don't propagate these pieces outside of this system bound but propagate like these blessed pieces that like",
    "start": "2711020",
    "end": "2716660"
  },
  {
    "text": "somebody's up and gotten Buy in from like you know the most contain that that stuff's okay is is probably necessary at",
    "start": "2716660",
    "end": "2724550"
  },
  {
    "text": "least that you know really large-scale yeah I mean I think this is like it",
    "start": "2724550",
    "end": "2730790"
  },
  {
    "text": "connects back to the you can have a really flexible API but you also want something higher level and very",
    "start": "2730790",
    "end": "2737150"
  },
  {
    "text": "restrictive that most users interact with and in this case there are a bunch",
    "start": "2737150",
    "end": "2742670"
  },
  {
    "text": "of like very subtle questions around the propagation of like you know a you may",
    "start": "2742670",
    "end": "2748340"
  },
  {
    "text": "have some session ID that's propagating over multiple individual dub-dub-dub the quests but each dub-dub-dub request",
    "start": "2748340",
    "end": "2755990"
  },
  {
    "text": "should have its own ID and like making sure users understand like what are the boundaries were things cross over and",
    "start": "2755990",
    "end": "2761480"
  },
  {
    "text": "are able to do it in a safe way I think like we're it's a very very open",
    "start": "2761480",
    "end": "2767060"
  },
  {
    "text": "question on our side of like how to make that work yeah the boundary issue is",
    "start": "2767060",
    "end": "2774050"
  },
  {
    "text": "just pernicious for any form of context propagation yeah big big missing piece",
    "start": "2774050",
    "end": "2779720"
  },
  {
    "text": "of the Internet right now yeah",
    "start": "2779720",
    "end": "2783520"
  },
  {
    "text": "Michael can you elaborate on the rate-limiting you said you do it after",
    "start": "2787619",
    "end": "2792939"
  },
  {
    "text": "sampling so what happens to the trace if you start rate-limiting yeah so so the",
    "start": "2792939",
    "end": "2798369"
  },
  {
    "text": "way we're planning on doing rate-limiting is we're planning on still",
    "start": "2798369",
    "end": "2803649"
  },
  {
    "text": "doing it at trace start and not killing traces that are in progress so like for",
    "start": "2803649",
    "end": "2809679"
  },
  {
    "text": "instance like you know from the point of view let's say you're an individual node and you know you have one in a thousand",
    "start": "2809679",
    "end": "2814719"
  },
  {
    "text": "coin flip right but when we configured that coin flip we had like two nodes running and then for some reason now",
    "start": "2814719",
    "end": "2820599"
  },
  {
    "text": "there's a thousand running what would happen is you do the coin flip the coin flip would pass and then there'd be an",
    "start": "2820599",
    "end": "2826630"
  },
  {
    "text": "additional rate limit check and we would have a set of centrally configured rate limits that say essentially okay this you know this this policy gets to start",
    "start": "2826630",
    "end": "2834159"
  },
  {
    "text": "five traces per second it would check the rate limit after that and the rate limit would then fail and that's also",
    "start": "2834159",
    "end": "2840309"
  },
  {
    "text": "where it would check the trace size rate limit right so so we're only gonna do it at start we don't want to try to get it",
    "start": "2840309",
    "end": "2846159"
  },
  {
    "text": "you know we're not gonna try to get into like hey can we somehow like kill you know a trace that's too big halfway",
    "start": "2846159",
    "end": "2852639"
  },
  {
    "text": "through because that's just you know yeah right yeah that also does that a",
    "start": "2852639",
    "end": "2859719"
  },
  {
    "text": "question yeah I mean we we've done",
    "start": "2859719",
    "end": "2864759"
  },
  {
    "text": "something similar but not for regular something but for like specific bugs little something that people were",
    "start": "2864759",
    "end": "2870849"
  },
  {
    "text": "abusing so we rate limit those but for the reason we didn't do it for that the",
    "start": "2870849",
    "end": "2876459"
  },
  {
    "text": "regular sampling is because we extract some extrapolations from from the",
    "start": "2876459",
    "end": "2881799"
  },
  {
    "text": "statistics we get from overall traces and and they're the probability of sampling actually very important so if",
    "start": "2881799",
    "end": "2888669"
  },
  {
    "text": "you start rate limiting that you cannot do extrapolations anymore so yeah that's",
    "start": "2888669",
    "end": "2895089"
  },
  {
    "text": "something we'd have to watch out for so we do it we do it and we do that sort of thing in some cases as well you know the",
    "start": "2895089",
    "end": "2902109"
  },
  {
    "text": "intent of the rate limits is just for sort of our own safety like we don't mean we don't intend them to be things",
    "start": "2902109",
    "end": "2907630"
  },
  {
    "text": "that are gonna be hid under like normal operation you know so and and work and we're gonna monitor them right well",
    "start": "2907630",
    "end": "2913929"
  },
  {
    "text": "monitoring on there's somebody like hits them and in that sort of situation will let them know right but but yeah it's",
    "start": "2913929",
    "end": "2921130"
  },
  {
    "text": "sort of something that you know we we sort of can't get away with anymore and continued on on board people without",
    "start": "2921130",
    "end": "2928119"
  },
  {
    "text": "being kind of skittish they're kind of good probably use case where you have",
    "start": "2928119",
    "end": "2935730"
  },
  {
    "text": "like dozens of teams we can't manually go in and understand like what their",
    "start": "2935880",
    "end": "2941650"
  },
  {
    "text": "limits are gonna be for maybe volume date or number of traces or there are like there requests per second or all",
    "start": "2941650",
    "end": "2947950"
  },
  {
    "text": "this and they might not even know so like there's just so much overhead in this space that if we can through the",
    "start": "2947950",
    "end": "2954160"
  },
  {
    "text": "starcade I'd like a same out or here's the amount of precision yet what the amount of data you can send us like our",
    "start": "2954160",
    "end": "2960700"
  },
  {
    "text": "system doesn't have to fall over and they can iterate on that and then they can come in quickly not us it's also",
    "start": "2960700",
    "end": "2966880"
  },
  {
    "text": "good for the case of maybe not this than the new hole tracing error case but",
    "start": "2966880",
    "end": "2972819"
  },
  {
    "text": "maybe I have this distributor request and somewhere in that request we continue on because it didn't have",
    "start": "2972819",
    "end": "2978460"
  },
  {
    "text": "instrumentation or something like that and now maybe it's like a huge like a course everyone hits and they want to",
    "start": "2978460",
    "end": "2984309"
  },
  {
    "text": "add a ton a like information and now their service has 10x the amount of data",
    "start": "2984309",
    "end": "2989319"
  },
  {
    "text": "pumping out than it was before and this gives us like a good way of understanding oh crap maybe sampling was",
    "start": "2989319",
    "end": "2995230"
  },
  {
    "text": "the same but the size of all these traces just went up significantly and we need to have a quick back mechanism",
    "start": "2995230",
    "end": "3000240"
  },
  {
    "text": "sorry service doesn't fall over so it's usually like those are the scenarios where it's like allowing us to move like",
    "start": "3000240",
    "end": "3005730"
  },
  {
    "text": "quicker and not fall over and then come in react to it and then have someone okay yeah one of our are here right now",
    "start": "3005730",
    "end": "3018420"
  },
  {
    "text": "he's he was working on more of a sampling based approach where we dynamically changed the rates based on",
    "start": "3018420",
    "end": "3026130"
  },
  {
    "text": "how much they're outputting I mean we have both as you said because of the debug override that we allowed in the",
    "start": "3026130",
    "end": "3032640"
  },
  {
    "text": "system so like we still need that case but yeah I mean the changing the",
    "start": "3032640",
    "end": "3038730"
  },
  {
    "text": "probability is a nice way of doing it if it if you can it seems like it's pretty",
    "start": "3038730",
    "end": "3043799"
  },
  {
    "text": "static right now",
    "start": "3043799",
    "end": "3047089"
  },
  {
    "text": "traces of the same size yes size is an interesting point we haven't done that but we've seen it definitely or size is",
    "start": "3054700",
    "end": "3068500"
  },
  {
    "text": "more is a better indicator we've such diversity in what races look like and especially when you're in when",
    "start": "3068500",
    "end": "3074349"
  },
  {
    "text": "you're not to mean the case where it's a new tracing scenario but obtaining an existing one that just a ton of like an",
    "start": "3074349",
    "end": "3079839"
  },
  {
    "text": "update existing sort of talking people hit it's really hard to understand like is this make us fall over immediately",
    "start": "3079839",
    "end": "3085780"
  },
  {
    "text": "you might have someone who's like Walmart races but they're only like 1%",
    "start": "3085780",
    "end": "3090880"
  },
  {
    "text": "of all of our data but if they were to increase their data significantly like we might just fall over immediately",
    "start": "3090880",
    "end": "3095890"
  },
  {
    "text": "and they might not understand that we don't have a good push back are you doing the dynamic sampling just by",
    "start": "3095890",
    "end": "3103329"
  },
  {
    "text": "propagating the sampling rates through the baggage actually we have like we",
    "start": "3103329",
    "end": "3110859"
  },
  {
    "text": "have like a remote sampler it's it queries basically on a minute-by-minute basis I think so it's like we the ingest",
    "start": "3110859",
    "end": "3120579"
  },
  {
    "text": "side is sort of calculating the throughput from multiple areas and figuring out a good strategy of",
    "start": "3120579",
    "end": "3128010"
  },
  {
    "text": "probability there yeah yeah definitely adds complexity I mean I don't write",
    "start": "3128010",
    "end": "3134109"
  },
  {
    "text": "it's something similar where will like",
    "start": "3134109",
    "end": "3142599"
  },
  {
    "text": "get a constant volume of traces and will adjust the sampling rate accordingly",
    "start": "3142599",
    "end": "3148770"
  },
  {
    "text": "with some feedback mechanism like running every couple of minutes and that",
    "start": "3148770",
    "end": "3154780"
  },
  {
    "text": "sort of has the same like you know there are there are challenges with it yeah",
    "start": "3154780",
    "end": "3161069"
  },
  {
    "text": "yeah it's hard to find him well the main challenge is that there are some work",
    "start": "3161069",
    "end": "3166810"
  },
  {
    "text": "laws which are periodical and so when they're quiet their probability kinda",
    "start": "3166810",
    "end": "3171880"
  },
  {
    "text": "climbs up because there's nothing common and then suddenly boom they flood you yeah we've gotten hammered with things",
    "start": "3171880",
    "end": "3178270"
  },
  {
    "text": "like that particularly around like aggressive rollouts to where somebody has like a high rate during testing and",
    "start": "3178270",
    "end": "3185260"
  },
  {
    "text": "then it gets rolled to production there's like four to seven minutes that",
    "start": "3185260",
    "end": "3190460"
  },
  {
    "text": "are not fun and then you have abilities adjust right and we are yeah that was",
    "start": "3190460",
    "end": "3203510"
  },
  {
    "text": "that thank you so much Jonathan and Michael that was a great presentation we'll be posting that on the internet",
    "start": "3203510",
    "end": "3210650"
  },
  {
    "text": "and see you all next time the internet",
    "start": "3210650",
    "end": "3215740"
  },
  {
    "text": "see you all later it's been fun",
    "start": "3220060",
    "end": "3224050"
  }
]
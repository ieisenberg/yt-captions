[
  {
    "start": "0",
    "end": "160000"
  },
  {
    "text": "hi folks good evening my name is manasi",
    "start": "1839",
    "end": "4000"
  },
  {
    "text": "vata",
    "start": "4000",
    "end": "4480"
  },
  {
    "text": "and i'm the founder and ceo of virda we",
    "start": "4480",
    "end": "7279"
  },
  {
    "text": "are a ml infrastructure company",
    "start": "7279",
    "end": "9280"
  },
  {
    "text": "providing a platform for the delivery",
    "start": "9280",
    "end": "12639"
  },
  {
    "text": "operations and management of ml models",
    "start": "12639",
    "end": "16160"
  },
  {
    "text": "and today i'm going to be focusing on a",
    "start": "16160",
    "end": "18560"
  },
  {
    "text": "topic that has come up",
    "start": "18560",
    "end": "19920"
  },
  {
    "text": "time and time again with our clients and",
    "start": "19920",
    "end": "22720"
  },
  {
    "text": "partners",
    "start": "22720",
    "end": "23760"
  },
  {
    "text": "which is when you're serving ml models",
    "start": "23760",
    "end": "26560"
  },
  {
    "text": "does it make sense to adopt a",
    "start": "26560",
    "end": "28400"
  },
  {
    "text": "surveillance infrastructure",
    "start": "28400",
    "end": "30320"
  },
  {
    "text": "so with that let's get started a bit of",
    "start": "30320",
    "end": "33200"
  },
  {
    "text": "background",
    "start": "33200",
    "end": "33920"
  },
  {
    "text": "on myself as well as verda so i founded",
    "start": "33920",
    "end": "37040"
  },
  {
    "text": "virta based on",
    "start": "37040",
    "end": "38399"
  },
  {
    "text": "my phd work at mit this was on",
    "start": "38399",
    "end": "41520"
  },
  {
    "text": "a open source model management and",
    "start": "41520",
    "end": "43520"
  },
  {
    "text": "versioning system called model db",
    "start": "43520",
    "end": "45920"
  },
  {
    "text": "just as git is the de facto",
    "start": "45920",
    "end": "50480"
  },
  {
    "text": "version control system for source code",
    "start": "50480",
    "end": "52800"
  },
  {
    "text": "we found out that models didn't have an",
    "start": "52800",
    "end": "54800"
  },
  {
    "text": "equivalent way to version or manage them",
    "start": "54800",
    "end": "57120"
  },
  {
    "text": "so we built this open source system that",
    "start": "57120",
    "end": "59199"
  },
  {
    "text": "is now maintained",
    "start": "59199",
    "end": "61280"
  },
  {
    "text": "by verda and we have expanded that",
    "start": "61280",
    "end": "64478"
  },
  {
    "text": "significantly",
    "start": "64479",
    "end": "65840"
  },
  {
    "text": "to provide an end-to-end ml ops platform",
    "start": "65840",
    "end": "69119"
  },
  {
    "text": "just like devops and the tooling around",
    "start": "69119",
    "end": "71600"
  },
  {
    "text": "devops has",
    "start": "71600",
    "end": "72479"
  },
  {
    "text": "enabled software teams to ship",
    "start": "72479",
    "end": "75520"
  },
  {
    "text": "code more frequently and more reliably",
    "start": "75520",
    "end": "78240"
  },
  {
    "text": "the virta mlaps platform",
    "start": "78240",
    "end": "80640"
  },
  {
    "text": "helps ml teams ship models more",
    "start": "80640",
    "end": "83920"
  },
  {
    "text": "frequently",
    "start": "83920",
    "end": "85040"
  },
  {
    "text": "and in a reliable fashion so the reason",
    "start": "85040",
    "end": "88799"
  },
  {
    "text": "this talk and the work that we're",
    "start": "88799",
    "end": "91680"
  },
  {
    "text": "presenting in this talk today came about",
    "start": "91680",
    "end": "94079"
  },
  {
    "text": "was that",
    "start": "94079",
    "end": "94960"
  },
  {
    "text": "we help a lot of clients and ml teams",
    "start": "94960",
    "end": "97119"
  },
  {
    "text": "deploy their ml models",
    "start": "97119",
    "end": "99040"
  },
  {
    "text": "and serverless is a very appealing",
    "start": "99040",
    "end": "101759"
  },
  {
    "text": "paradigm",
    "start": "101759",
    "end": "102720"
  },
  {
    "text": "in this case because it provides scaling",
    "start": "102720",
    "end": "105759"
  },
  {
    "text": "ability",
    "start": "105759",
    "end": "106640"
  },
  {
    "text": "it also has a promise of reducing costs",
    "start": "106640",
    "end": "109680"
  },
  {
    "text": "because you don't use you don't keep",
    "start": "109680",
    "end": "111759"
  },
  {
    "text": "resources around that you don't need",
    "start": "111759",
    "end": "114000"
  },
  {
    "text": "and so what we decided was that we would",
    "start": "114000",
    "end": "117439"
  },
  {
    "text": "run a set of benchmarks comparing ml",
    "start": "117439",
    "end": "120640"
  },
  {
    "text": "inference",
    "start": "120640",
    "end": "121360"
  },
  {
    "text": "in a serverless setting compared to",
    "start": "121360",
    "end": "125040"
  },
  {
    "text": "a non-serverless setting and so provide",
    "start": "125040",
    "end": "127759"
  },
  {
    "text": "the",
    "start": "127759",
    "end": "128319"
  },
  {
    "text": "sort of best advice to our clients",
    "start": "128319",
    "end": "132319"
  },
  {
    "text": "so today i'm excited to share some of",
    "start": "132319",
    "end": "134239"
  },
  {
    "text": "that work with you all",
    "start": "134239",
    "end": "135920"
  },
  {
    "text": "and without further ado let me get",
    "start": "135920",
    "end": "138000"
  },
  {
    "text": "started",
    "start": "138000",
    "end": "139040"
  },
  {
    "text": "what i'll be covering in the remainder",
    "start": "139040",
    "end": "140959"
  },
  {
    "text": "of my talk is",
    "start": "140959",
    "end": "142319"
  },
  {
    "text": "what is serverless why is it interesting",
    "start": "142319",
    "end": "144640"
  },
  {
    "text": "uh unique considerations for ml serving",
    "start": "144640",
    "end": "147200"
  },
  {
    "text": "that come into play",
    "start": "147200",
    "end": "148560"
  },
  {
    "text": "then we'll go to the benchmark and",
    "start": "148560",
    "end": "151280"
  },
  {
    "text": "results there",
    "start": "151280",
    "end": "152640"
  },
  {
    "text": "and then i'll wrap up with some key",
    "start": "152640",
    "end": "154400"
  },
  {
    "text": "takeaways and",
    "start": "154400",
    "end": "156080"
  },
  {
    "text": "how you can determine whether serverless",
    "start": "156080",
    "end": "158400"
  },
  {
    "text": "is appropriate for you",
    "start": "158400",
    "end": "161360"
  },
  {
    "start": "160000",
    "end": "580000"
  },
  {
    "text": "so serverless what is it and why is it",
    "start": "161440",
    "end": "163680"
  },
  {
    "text": "interesting",
    "start": "163680",
    "end": "165040"
  },
  {
    "text": "if you think about the different ways in",
    "start": "165040",
    "end": "166560"
  },
  {
    "text": "which you can run",
    "start": "166560",
    "end": "168239"
  },
  {
    "text": "software applications today you'll find",
    "start": "168239",
    "end": "170720"
  },
  {
    "text": "that",
    "start": "170720",
    "end": "171280"
  },
  {
    "text": "there's largely four categories one",
    "start": "171280",
    "end": "174720"
  },
  {
    "text": "is you can start with a bare metal",
    "start": "174720",
    "end": "176560"
  },
  {
    "text": "server manage the hardware",
    "start": "176560",
    "end": "178640"
  },
  {
    "text": "and then run applications on top of it",
    "start": "178640",
    "end": "181440"
  },
  {
    "text": "the next one",
    "start": "181440",
    "end": "182319"
  },
  {
    "text": "up the chain is virtual machines these",
    "start": "182319",
    "end": "185200"
  },
  {
    "text": "abstract away the hardware",
    "start": "185200",
    "end": "187040"
  },
  {
    "text": "and you can have multiple guest machines",
    "start": "187040",
    "end": "189920"
  },
  {
    "text": "running on your host machine",
    "start": "189920",
    "end": "192159"
  },
  {
    "text": "further up the stack we have containers",
    "start": "192159",
    "end": "194800"
  },
  {
    "text": "that help us",
    "start": "194800",
    "end": "195680"
  },
  {
    "text": "abstract away the operating system",
    "start": "195680",
    "end": "197519"
  },
  {
    "text": "entirely and we're left with only the",
    "start": "197519",
    "end": "199760"
  },
  {
    "text": "application",
    "start": "199760",
    "end": "200640"
  },
  {
    "text": "and its dependencies at the very top we",
    "start": "200640",
    "end": "203680"
  },
  {
    "text": "have serverless",
    "start": "203680",
    "end": "204560"
  },
  {
    "text": "where we're only thinking about the",
    "start": "204560",
    "end": "207120"
  },
  {
    "text": "function",
    "start": "207120",
    "end": "207760"
  },
  {
    "text": "that we want to execute we're not really",
    "start": "207760",
    "end": "210239"
  },
  {
    "text": "thinking about",
    "start": "210239",
    "end": "211519"
  },
  {
    "text": "how to run it or how to scale it that's",
    "start": "211519",
    "end": "214480"
  },
  {
    "text": "the value add that is brought in by a",
    "start": "214480",
    "end": "216720"
  },
  {
    "text": "serverless platform",
    "start": "216720",
    "end": "218720"
  },
  {
    "text": "as you might imagine as we go from bare",
    "start": "218720",
    "end": "221200"
  },
  {
    "text": "metal to serverless",
    "start": "221200",
    "end": "222480"
  },
  {
    "text": "we're going up the abstraction chain",
    "start": "222480",
    "end": "226239"
  },
  {
    "text": "which means it's easier to use and yet",
    "start": "226239",
    "end": "229200"
  },
  {
    "text": "it has",
    "start": "229200",
    "end": "229920"
  },
  {
    "text": "less control and less flexibility as a",
    "start": "229920",
    "end": "232720"
  },
  {
    "text": "result",
    "start": "232720",
    "end": "234879"
  },
  {
    "text": "today i'm going to be focusing on",
    "start": "234879",
    "end": "236239"
  },
  {
    "text": "cyrillus and containers",
    "start": "236239",
    "end": "238959"
  },
  {
    "text": "and comparing these two as ways to run",
    "start": "238959",
    "end": "241760"
  },
  {
    "text": "ml workloads",
    "start": "241760",
    "end": "244159"
  },
  {
    "text": "so serverless can be a confusing term",
    "start": "244159",
    "end": "246319"
  },
  {
    "text": "for many people",
    "start": "246319",
    "end": "247840"
  },
  {
    "text": "and so let me let me throw some",
    "start": "247840",
    "end": "251040"
  },
  {
    "text": "definitions first",
    "start": "251040",
    "end": "252319"
  },
  {
    "text": "so this is an abstract one that i really",
    "start": "252319",
    "end": "254480"
  },
  {
    "text": "like by martin fowler it says",
    "start": "254480",
    "end": "257040"
  },
  {
    "text": "serverless is at its most simple and",
    "start": "257040",
    "end": "259280"
  },
  {
    "text": "outsourcing solution",
    "start": "259280",
    "end": "260880"
  },
  {
    "text": "so what that means is with serverless",
    "start": "260880",
    "end": "264320"
  },
  {
    "text": "you don't need to provision or manage",
    "start": "264320",
    "end": "266240"
  },
  {
    "text": "the servers",
    "start": "266240",
    "end": "267440"
  },
  {
    "text": "also your application doesn't have a",
    "start": "267440",
    "end": "269759"
  },
  {
    "text": "long running server component",
    "start": "269759",
    "end": "271360"
  },
  {
    "text": "so you don't have a loop that's sitting",
    "start": "271360",
    "end": "272800"
  },
  {
    "text": "around waiting for",
    "start": "272800",
    "end": "275440"
  },
  {
    "text": "waiting for application to get requests",
    "start": "275440",
    "end": "279440"
  },
  {
    "text": "instead it is much more an event",
    "start": "279440",
    "end": "283040"
  },
  {
    "text": "driven paradigm where every time",
    "start": "283040",
    "end": "287040"
  },
  {
    "text": "a a serverless function is invoked",
    "start": "287040",
    "end": "290639"
  },
  {
    "text": "the underlying platform is going to spin",
    "start": "290639",
    "end": "292960"
  },
  {
    "text": "up",
    "start": "292960",
    "end": "293759"
  },
  {
    "text": "one or multiple copies of the serverless",
    "start": "293759",
    "end": "296479"
  },
  {
    "text": "function",
    "start": "296479",
    "end": "296960"
  },
  {
    "text": "and then that is going to be used to",
    "start": "296960",
    "end": "299040"
  },
  {
    "text": "service requests",
    "start": "299040",
    "end": "300639"
  },
  {
    "text": "as a developer you're only writing the",
    "start": "300639",
    "end": "302880"
  },
  {
    "text": "code or business logic you don't need to",
    "start": "302880",
    "end": "304720"
  },
  {
    "text": "figure out how to",
    "start": "304720",
    "end": "305919"
  },
  {
    "text": "run or deploy it the platform is going",
    "start": "305919",
    "end": "308000"
  },
  {
    "text": "to take care of that",
    "start": "308000",
    "end": "310000"
  },
  {
    "text": "in addition the platform is going to",
    "start": "310000",
    "end": "311680"
  },
  {
    "text": "take care of scaling up and down of",
    "start": "311680",
    "end": "313280"
  },
  {
    "text": "resources",
    "start": "313280",
    "end": "314320"
  },
  {
    "text": "if you have a certain burst because your",
    "start": "314320",
    "end": "316880"
  },
  {
    "text": "app is very very popular",
    "start": "316880",
    "end": "318880"
  },
  {
    "text": "the serverless system is going to scale",
    "start": "318880",
    "end": "320479"
  },
  {
    "text": "up to support that",
    "start": "320479",
    "end": "322560"
  },
  {
    "text": "in contrast if it's um if it's a holiday",
    "start": "322560",
    "end": "326560"
  },
  {
    "text": "and no one's using the app that you've",
    "start": "326560",
    "end": "328639"
  },
  {
    "text": "built for workplace productivity",
    "start": "328639",
    "end": "331039"
  },
  {
    "text": "then it's going to scale to zero until",
    "start": "331039",
    "end": "333360"
  },
  {
    "text": "there are requests",
    "start": "333360",
    "end": "336000"
  },
  {
    "text": "and then finally serverless has many",
    "start": "336000",
    "end": "338639"
  },
  {
    "text": "different flavors what i'm talking about",
    "start": "338639",
    "end": "340479"
  },
  {
    "text": "in this talk",
    "start": "340479",
    "end": "341199"
  },
  {
    "text": "is function as a service and some of the",
    "start": "341199",
    "end": "344880"
  },
  {
    "text": "popular serverless systems",
    "start": "344880",
    "end": "346560"
  },
  {
    "text": "are lambda's gcp cloud run cloud",
    "start": "346560",
    "end": "349360"
  },
  {
    "text": "functions",
    "start": "349360",
    "end": "350840"
  },
  {
    "text": "etc so that's what serverless is",
    "start": "350840",
    "end": "354639"
  },
  {
    "text": "let's quickly look at why serverless is",
    "start": "354639",
    "end": "357120"
  },
  {
    "text": "interesting",
    "start": "357120",
    "end": "358080"
  },
  {
    "text": "so some of the pros and cons when you",
    "start": "358080",
    "end": "359919"
  },
  {
    "text": "are choosing",
    "start": "359919",
    "end": "361199"
  },
  {
    "text": "to adopt a serverless setting",
    "start": "361199",
    "end": "364960"
  },
  {
    "text": "so first of all serverless is easy to",
    "start": "364960",
    "end": "366720"
  },
  {
    "text": "use developers focus on business logic",
    "start": "366720",
    "end": "368960"
  },
  {
    "text": "don't need to worry about",
    "start": "368960",
    "end": "370240"
  },
  {
    "text": "how an application is going to run",
    "start": "370240",
    "end": "372960"
  },
  {
    "text": "second",
    "start": "372960",
    "end": "373440"
  },
  {
    "text": "it's able to scale the more requests you",
    "start": "373440",
    "end": "376800"
  },
  {
    "text": "get",
    "start": "376800",
    "end": "377600"
  },
  {
    "text": "and as your workload varies more copies",
    "start": "377600",
    "end": "380000"
  },
  {
    "text": "of the serverless function are created",
    "start": "380000",
    "end": "381919"
  },
  {
    "text": "automatically",
    "start": "381919",
    "end": "383120"
  },
  {
    "text": "similarly it's going to scale to zero",
    "start": "383120",
    "end": "385600"
  },
  {
    "text": "when",
    "start": "385600",
    "end": "386319"
  },
  {
    "text": "your application is not receiving",
    "start": "386319",
    "end": "389120"
  },
  {
    "text": "requests",
    "start": "389120",
    "end": "390479"
  },
  {
    "text": "so overall this means that the",
    "start": "390479",
    "end": "392639"
  },
  {
    "text": "maintenance overhead of infrastructure",
    "start": "392639",
    "end": "394800"
  },
  {
    "text": "is very low",
    "start": "394800",
    "end": "395759"
  },
  {
    "text": "you don't need to manage the nodes",
    "start": "395759",
    "end": "397360"
  },
  {
    "text": "perform upgrades tune resource",
    "start": "397360",
    "end": "399440"
  },
  {
    "text": "requirements and so on",
    "start": "399440",
    "end": "401840"
  },
  {
    "text": "and as a result overall whether we're",
    "start": "401840",
    "end": "404319"
  },
  {
    "text": "talking about",
    "start": "404319",
    "end": "405280"
  },
  {
    "text": "total cost of ownership or in certain",
    "start": "405280",
    "end": "407759"
  },
  {
    "text": "cases depending on the workload",
    "start": "407759",
    "end": "409680"
  },
  {
    "text": "even the infrastructure costs can be",
    "start": "409680",
    "end": "411599"
  },
  {
    "text": "lower for a serverless system",
    "start": "411599",
    "end": "413599"
  },
  {
    "text": "compared to a non-serverless system",
    "start": "413599",
    "end": "417599"
  },
  {
    "text": "so some popular applications that are",
    "start": "418000",
    "end": "419840"
  },
  {
    "text": "good fits for serverless",
    "start": "419840",
    "end": "421120"
  },
  {
    "text": "include asynchronous message processing",
    "start": "421120",
    "end": "423280"
  },
  {
    "text": "iot workloads stream processing",
    "start": "423280",
    "end": "425840"
  },
  {
    "text": "and so on so those are",
    "start": "425840",
    "end": "429199"
  },
  {
    "text": "cases where serverless is a good fit but",
    "start": "429199",
    "end": "431360"
  },
  {
    "text": "that doesn't mean the serverless is a",
    "start": "431360",
    "end": "432880"
  },
  {
    "text": "good fit everywhere",
    "start": "432880",
    "end": "434319"
  },
  {
    "text": "for instance serverless applications are",
    "start": "434319",
    "end": "436960"
  },
  {
    "text": "stateless",
    "start": "436960",
    "end": "437759"
  },
  {
    "text": "so if you have an application that does",
    "start": "437759",
    "end": "439680"
  },
  {
    "text": "require state",
    "start": "439680",
    "end": "440800"
  },
  {
    "text": "to be present in it then",
    "start": "440800",
    "end": "444000"
  },
  {
    "text": "serverless may not be a good fit here",
    "start": "444000",
    "end": "446800"
  },
  {
    "text": "second",
    "start": "446800",
    "end": "447360"
  },
  {
    "text": "there are implementation restrictions so",
    "start": "447360",
    "end": "449599"
  },
  {
    "text": "whether you're talking about lambdas",
    "start": "449599",
    "end": "451440"
  },
  {
    "text": "or cloud run there are limits on how",
    "start": "451440",
    "end": "453919"
  },
  {
    "text": "long a function can run",
    "start": "453919",
    "end": "455759"
  },
  {
    "text": "the resources it can ask for concurrency",
    "start": "455759",
    "end": "458639"
  },
  {
    "text": "and so on",
    "start": "458639",
    "end": "460720"
  },
  {
    "text": "in addition you can't choose or control",
    "start": "460720",
    "end": "462720"
  },
  {
    "text": "the hardware so if you're looking for",
    "start": "462720",
    "end": "464400"
  },
  {
    "text": "particulate processor or accelerator",
    "start": "464400",
    "end": "466800"
  },
  {
    "text": "the serverless platform might not",
    "start": "466800",
    "end": "468400"
  },
  {
    "text": "support it however",
    "start": "468400",
    "end": "470080"
  },
  {
    "text": "a kubernetes-based platform is likely to",
    "start": "470080",
    "end": "472639"
  },
  {
    "text": "support that",
    "start": "472639",
    "end": "474319"
  },
  {
    "text": "and then finally because the serverless",
    "start": "474319",
    "end": "477280"
  },
  {
    "text": "applications",
    "start": "477280",
    "end": "478240"
  },
  {
    "text": "scale to xero when they're not in use",
    "start": "478240",
    "end": "480800"
  },
  {
    "text": "whenever",
    "start": "480800",
    "end": "481919"
  },
  {
    "text": "the first request comes in and there are",
    "start": "481919",
    "end": "484080"
  },
  {
    "text": "no",
    "start": "484080",
    "end": "484960"
  },
  {
    "text": "instances running there can be a large",
    "start": "484960",
    "end": "487120"
  },
  {
    "text": "latency",
    "start": "487120",
    "end": "489039"
  },
  {
    "text": "which can result from cold start you're",
    "start": "489039",
    "end": "491199"
  },
  {
    "text": "just spinning up",
    "start": "491199",
    "end": "492400"
  },
  {
    "text": "the first instance of this particular",
    "start": "492400",
    "end": "494479"
  },
  {
    "text": "function you're downloading dependencies",
    "start": "494479",
    "end": "496800"
  },
  {
    "text": "and that can take a while okay",
    "start": "496800",
    "end": "500400"
  },
  {
    "text": "so given this background when the",
    "start": "500400",
    "end": "502319"
  },
  {
    "text": "serverless makes sense usually",
    "start": "502319",
    "end": "504240"
  },
  {
    "text": "well it makes sense when the application",
    "start": "504240",
    "end": "506000"
  },
  {
    "text": "can be made stateless this is usually",
    "start": "506000",
    "end": "507840"
  },
  {
    "text": "not a deal breaker",
    "start": "507840",
    "end": "509039"
  },
  {
    "text": "you just store the state in a database",
    "start": "509039",
    "end": "511039"
  },
  {
    "text": "in a file store blob store and so on",
    "start": "511039",
    "end": "514080"
  },
  {
    "text": "the second one is that resource",
    "start": "514080",
    "end": "515919"
  },
  {
    "text": "requirements are modest",
    "start": "515919",
    "end": "517200"
  },
  {
    "text": "so they fit into what the serverless",
    "start": "517200",
    "end": "520320"
  },
  {
    "text": "platform",
    "start": "520320",
    "end": "520959"
  },
  {
    "text": "expects as typical resource requirements",
    "start": "520959",
    "end": "525920"
  },
  {
    "text": "the third one is that performance",
    "start": "525920",
    "end": "527680"
  },
  {
    "text": "requirements or sles are not super",
    "start": "527680",
    "end": "529760"
  },
  {
    "text": "astringent",
    "start": "529760",
    "end": "530560"
  },
  {
    "text": "because as mentioned earlier cold start",
    "start": "530560",
    "end": "533680"
  },
  {
    "text": "is a real issue and so if there are",
    "start": "533680",
    "end": "536720"
  },
  {
    "text": "tight performance requirements here",
    "start": "536720",
    "end": "539680"
  },
  {
    "text": "around latency in particular then",
    "start": "539680",
    "end": "542399"
  },
  {
    "text": "serverless",
    "start": "542399",
    "end": "543600"
  },
  {
    "text": "needs to be used with care and then",
    "start": "543600",
    "end": "546480"
  },
  {
    "text": "finally serverless makes sense when",
    "start": "546480",
    "end": "548080"
  },
  {
    "text": "query workloads are not steady",
    "start": "548080",
    "end": "550080"
  },
  {
    "text": "if you have a very steady workload that",
    "start": "550080",
    "end": "552240"
  },
  {
    "text": "uses",
    "start": "552240",
    "end": "553120"
  },
  {
    "text": "your servers pretty effectively",
    "start": "553120",
    "end": "556160"
  },
  {
    "text": "then serverless doesn't make as much",
    "start": "556160",
    "end": "558720"
  },
  {
    "text": "sense because it's not going to save you",
    "start": "558720",
    "end": "561360"
  },
  {
    "text": "those that's not going to save you",
    "start": "561360",
    "end": "563200"
  },
  {
    "text": "resources and therefore",
    "start": "563200",
    "end": "564800"
  },
  {
    "text": "costs as well",
    "start": "564800",
    "end": "567600"
  },
  {
    "text": "and then finally serverless really helps",
    "start": "568160",
    "end": "570640"
  },
  {
    "text": "with reducing infrastructure burden",
    "start": "570640",
    "end": "572640"
  },
  {
    "text": "and so if your team really has a lot of",
    "start": "572640",
    "end": "575440"
  },
  {
    "text": "burden",
    "start": "575440",
    "end": "576000"
  },
  {
    "text": "around managing infrastructure",
    "start": "576000",
    "end": "578080"
  },
  {
    "text": "serverless would make sense",
    "start": "578080",
    "end": "581200"
  },
  {
    "start": "580000",
    "end": "680000"
  },
  {
    "text": "so with that we can look at what ml",
    "start": "581200",
    "end": "584320"
  },
  {
    "text": "surveying",
    "start": "584320",
    "end": "585680"
  },
  {
    "text": "entails and how serverless",
    "start": "585680",
    "end": "588800"
  },
  {
    "text": "plays with that so you need",
    "start": "588800",
    "end": "591680"
  },
  {
    "text": "considerations for ml serving first of",
    "start": "591680",
    "end": "593680"
  },
  {
    "text": "all",
    "start": "593680",
    "end": "593920"
  },
  {
    "text": "ml surveying means making predictions",
    "start": "593920",
    "end": "596000"
  },
  {
    "text": "against the trained model",
    "start": "596000",
    "end": "597519"
  },
  {
    "text": "so there are different stages of the ml",
    "start": "597519",
    "end": "599040"
  },
  {
    "text": "life cycle your first training",
    "start": "599040",
    "end": "601279"
  },
  {
    "text": "you're first cleaning the data you're",
    "start": "601279",
    "end": "603120"
  },
  {
    "text": "preparing the data then you're training",
    "start": "603120",
    "end": "604800"
  },
  {
    "text": "the model",
    "start": "604800",
    "end": "605600"
  },
  {
    "text": "and then you're making predictions",
    "start": "605600",
    "end": "606800"
  },
  {
    "text": "against the trained model so we're",
    "start": "606800",
    "end": "608480"
  },
  {
    "text": "talking about that third",
    "start": "608480",
    "end": "609600"
  },
  {
    "text": "piece of the ml life cycle",
    "start": "609600",
    "end": "612640"
  },
  {
    "text": "and the first consideration that's",
    "start": "612640",
    "end": "614000"
  },
  {
    "text": "unique for ml is that models can be",
    "start": "614000",
    "end": "616839"
  },
  {
    "text": "large and what we mean by that",
    "start": "616839",
    "end": "619279"
  },
  {
    "text": "is a model can have millions and",
    "start": "619279",
    "end": "621040"
  },
  {
    "text": "millions of parameters",
    "start": "621040",
    "end": "622640"
  },
  {
    "text": "as a result the serialized version of",
    "start": "622640",
    "end": "624800"
  },
  {
    "text": "the model",
    "start": "624800",
    "end": "626240"
  },
  {
    "text": "can be hundreds of gigabytes so",
    "start": "626240",
    "end": "629360"
  },
  {
    "text": "distilbert one of the smaller nlp models",
    "start": "629360",
    "end": "632480"
  },
  {
    "text": "is actually 256 mb if you compare that",
    "start": "632480",
    "end": "635519"
  },
  {
    "text": "to your vanilla",
    "start": "635519",
    "end": "637600"
  },
  {
    "text": "python function that you might run",
    "start": "637600",
    "end": "640320"
  },
  {
    "text": "that's fairly large",
    "start": "640320",
    "end": "641760"
  },
  {
    "text": "and we'll see how we can run into",
    "start": "641760",
    "end": "645519"
  },
  {
    "text": "problems when we're running a distilled",
    "start": "645519",
    "end": "648880"
  },
  {
    "text": "bird model",
    "start": "648880",
    "end": "649760"
  },
  {
    "text": "in a serverless setting",
    "start": "649760",
    "end": "653040"
  },
  {
    "text": "we run into similar challenges for ml",
    "start": "653120",
    "end": "655360"
  },
  {
    "text": "libraries",
    "start": "655360",
    "end": "656480"
  },
  {
    "text": "ml libraries can be varied they can also",
    "start": "656480",
    "end": "659120"
  },
  {
    "text": "have a lot of dependencies",
    "start": "659120",
    "end": "660880"
  },
  {
    "text": "and as a result loading up these",
    "start": "660880",
    "end": "663279"
  },
  {
    "text": "libraries",
    "start": "663279",
    "end": "664079"
  },
  {
    "text": "can hit some of the walls that are",
    "start": "664079",
    "end": "667120"
  },
  {
    "text": "imposed by",
    "start": "667120",
    "end": "668560"
  },
  {
    "text": "resource restrictions for serverless",
    "start": "668560",
    "end": "670880"
  },
  {
    "text": "platforms",
    "start": "670880",
    "end": "673040"
  },
  {
    "text": "then finally ml models may need to be",
    "start": "673040",
    "end": "675040"
  },
  {
    "text": "served via gpus or tpus they're more",
    "start": "675040",
    "end": "677120"
  },
  {
    "text": "efficient that way and serverless",
    "start": "677120",
    "end": "678640"
  },
  {
    "text": "systems",
    "start": "678640",
    "end": "679519"
  },
  {
    "text": "currently don't enable that",
    "start": "679519",
    "end": "682959"
  },
  {
    "start": "680000",
    "end": "1011000"
  },
  {
    "text": "so we now have a better sense of",
    "start": "683200",
    "end": "687760"
  },
  {
    "text": "where serverless makes sense and how",
    "start": "687760",
    "end": "690240"
  },
  {
    "text": "amal serving workloads might compare",
    "start": "690240",
    "end": "692640"
  },
  {
    "text": "to that particular situation so next",
    "start": "692640",
    "end": "695440"
  },
  {
    "text": "let's look at",
    "start": "695440",
    "end": "696560"
  },
  {
    "text": "the benchmark our goal with this",
    "start": "696560",
    "end": "698720"
  },
  {
    "text": "benchmark was to identify",
    "start": "698720",
    "end": "700800"
  },
  {
    "text": "when it makes sense to use serverless",
    "start": "700800",
    "end": "702399"
  },
  {
    "text": "for ml survey and we evaluated that",
    "start": "702399",
    "end": "705120"
  },
  {
    "text": "question",
    "start": "705120",
    "end": "705680"
  },
  {
    "text": "on a variety of systems today i'm going",
    "start": "705680",
    "end": "707920"
  },
  {
    "text": "to be focusing",
    "start": "707920",
    "end": "708880"
  },
  {
    "text": "on three systems these are managed",
    "start": "708880",
    "end": "711200"
  },
  {
    "text": "services and we picked these because we",
    "start": "711200",
    "end": "713360"
  },
  {
    "text": "found",
    "start": "713360",
    "end": "714800"
  },
  {
    "text": "that these systems were most mature",
    "start": "714800",
    "end": "716800"
  },
  {
    "text": "among the",
    "start": "716800",
    "end": "718079"
  },
  {
    "text": "offerings out there so the first one is",
    "start": "718079",
    "end": "720720"
  },
  {
    "text": "lambdas aws lambdas",
    "start": "720720",
    "end": "722639"
  },
  {
    "text": "this is the state of the art in",
    "start": "722639",
    "end": "726000"
  },
  {
    "text": "serverless the next one is running",
    "start": "726000",
    "end": "729279"
  },
  {
    "text": "serverless",
    "start": "729279",
    "end": "730160"
  },
  {
    "text": "on kubernetes and this is using the",
    "start": "730160",
    "end": "732560"
  },
  {
    "text": "k-native project",
    "start": "732560",
    "end": "734079"
  },
  {
    "text": "and we chose to use the google cloud run",
    "start": "734079",
    "end": "737519"
  },
  {
    "text": "platform in order to perform the",
    "start": "737519",
    "end": "739920"
  },
  {
    "text": "benchmark",
    "start": "739920",
    "end": "741920"
  },
  {
    "text": "finally for a container-based platform",
    "start": "741920",
    "end": "745040"
  },
  {
    "text": "we use the virta system",
    "start": "745040",
    "end": "748079"
  },
  {
    "text": "and what that entails is that virta",
    "start": "748079",
    "end": "751120"
  },
  {
    "text": "packages and runs models as containers",
    "start": "751120",
    "end": "754000"
  },
  {
    "text": "and does the scaling",
    "start": "754000",
    "end": "756240"
  },
  {
    "text": "automatically similar to a serverless",
    "start": "756240",
    "end": "758399"
  },
  {
    "text": "setting",
    "start": "758399",
    "end": "759360"
  },
  {
    "text": "so let's quickly look at how each one of",
    "start": "759360",
    "end": "762320"
  },
  {
    "text": "these systems works",
    "start": "762320",
    "end": "763600"
  },
  {
    "text": "because that'll help inform the analysis",
    "start": "763600",
    "end": "765760"
  },
  {
    "text": "we'll perform",
    "start": "765760",
    "end": "766720"
  },
  {
    "text": "shortly so for aws lambda this is the",
    "start": "766720",
    "end": "770240"
  },
  {
    "text": "manage serverless platform",
    "start": "770240",
    "end": "772480"
  },
  {
    "text": "you write code for the lambda function",
    "start": "772480",
    "end": "776160"
  },
  {
    "text": "you upload the package code to s3 also",
    "start": "776160",
    "end": "778480"
  },
  {
    "text": "upload any other dependencies",
    "start": "778480",
    "end": "780639"
  },
  {
    "text": "and then every time that the lambda is",
    "start": "780639",
    "end": "782639"
  },
  {
    "text": "triggered via an event or an http",
    "start": "782639",
    "end": "784480"
  },
  {
    "text": "request",
    "start": "784480",
    "end": "785360"
  },
  {
    "text": "the platform is going to spin up a",
    "start": "785360",
    "end": "787200"
  },
  {
    "text": "lambda instance it's going to",
    "start": "787200",
    "end": "788720"
  },
  {
    "text": "execute it it's going to scale it up and",
    "start": "788720",
    "end": "791120"
  },
  {
    "text": "down",
    "start": "791120",
    "end": "792000"
  },
  {
    "text": "as required and when the request is done",
    "start": "792000",
    "end": "794240"
  },
  {
    "text": "and there are no other requests",
    "start": "794240",
    "end": "795680"
  },
  {
    "text": "it will scale to 0. so that's generally",
    "start": "795680",
    "end": "798480"
  },
  {
    "text": "how",
    "start": "798480",
    "end": "798959"
  },
  {
    "text": "a lambda works on aws",
    "start": "798959",
    "end": "802399"
  },
  {
    "text": "if we look at google cloud run it's",
    "start": "802399",
    "end": "804160"
  },
  {
    "text": "pretty similar",
    "start": "804160",
    "end": "805440"
  },
  {
    "text": "except now we're talking about",
    "start": "805440",
    "end": "807360"
  },
  {
    "text": "containers as opposed to",
    "start": "807360",
    "end": "809279"
  },
  {
    "text": "just functions written in particular",
    "start": "809279",
    "end": "811440"
  },
  {
    "text": "language",
    "start": "811440",
    "end": "812639"
  },
  {
    "text": "so in this case what the end user has to",
    "start": "812639",
    "end": "815120"
  },
  {
    "text": "do is they upload a docker container",
    "start": "815120",
    "end": "817680"
  },
  {
    "text": "to the container registry um",
    "start": "817680",
    "end": "820880"
  },
  {
    "text": "and they tell google cloud run about",
    "start": "820880",
    "end": "824720"
  },
  {
    "text": "the container how it should be invoked",
    "start": "824720",
    "end": "827680"
  },
  {
    "text": "and then every time that there is an",
    "start": "827680",
    "end": "829279"
  },
  {
    "text": "event or",
    "start": "829279",
    "end": "830079"
  },
  {
    "text": "http request it's going to trigger a",
    "start": "830079",
    "end": "833199"
  },
  {
    "text": "cloud run execution and as before",
    "start": "833199",
    "end": "836240"
  },
  {
    "text": "the platform manages all resources",
    "start": "836240",
    "end": "838240"
  },
  {
    "text": "scaling and endpoints",
    "start": "838240",
    "end": "841519"
  },
  {
    "text": "finally with virda as i mentioned before",
    "start": "841680",
    "end": "844160"
  },
  {
    "text": "the platform runs models as containers",
    "start": "844160",
    "end": "846560"
  },
  {
    "text": "on kubernetes",
    "start": "846560",
    "end": "847920"
  },
  {
    "text": "and how it works is that the model is",
    "start": "847920",
    "end": "850240"
  },
  {
    "text": "uploaded to the verta platform",
    "start": "850240",
    "end": "852160"
  },
  {
    "text": "you can optionally specify resource and",
    "start": "852160",
    "end": "854240"
  },
  {
    "text": "hardware requirements",
    "start": "854240",
    "end": "855680"
  },
  {
    "text": "that you're looking to have met",
    "start": "855680",
    "end": "858959"
  },
  {
    "text": "and then you deploy the model inferno",
    "start": "858959",
    "end": "861279"
  },
  {
    "text": "notice that the step was",
    "start": "861279",
    "end": "862639"
  },
  {
    "text": "missing in the serverless workflows and",
    "start": "862639",
    "end": "865519"
  },
  {
    "text": "that's because",
    "start": "865519",
    "end": "866639"
  },
  {
    "text": "with serverless you can spin up",
    "start": "866639",
    "end": "869279"
  },
  {
    "text": "serverless",
    "start": "869279",
    "end": "869920"
  },
  {
    "text": "instances on the fly however in this",
    "start": "869920",
    "end": "872639"
  },
  {
    "text": "case",
    "start": "872639",
    "end": "873279"
  },
  {
    "text": "we deploy at least one",
    "start": "873279",
    "end": "876399"
  },
  {
    "text": "we will always have at least one replica",
    "start": "876399",
    "end": "878639"
  },
  {
    "text": "running for",
    "start": "878639",
    "end": "879680"
  },
  {
    "text": "the model and so that reduces",
    "start": "879680",
    "end": "882839"
  },
  {
    "text": "our cold start costs however does mean",
    "start": "882839",
    "end": "886079"
  },
  {
    "text": "that",
    "start": "886079",
    "end": "886800"
  },
  {
    "text": "if there are no requests we still have",
    "start": "886800",
    "end": "888959"
  },
  {
    "text": "the model running at all times",
    "start": "888959",
    "end": "891360"
  },
  {
    "text": "and then similar to serverless platforms",
    "start": "891360",
    "end": "893360"
  },
  {
    "text": "virta manage",
    "start": "893360",
    "end": "894720"
  },
  {
    "text": "just the endpoints and scaling of models",
    "start": "894720",
    "end": "899839"
  },
  {
    "text": "all right um the last part of the",
    "start": "900320",
    "end": "902480"
  },
  {
    "text": "benchmark spec",
    "start": "902480",
    "end": "903600"
  },
  {
    "text": "is metrics we measure warm stuff latency",
    "start": "903600",
    "end": "906880"
  },
  {
    "text": "cold start latency",
    "start": "906880",
    "end": "908320"
  },
  {
    "text": "auto scaling latency and also usability",
    "start": "908320",
    "end": "912000"
  },
  {
    "text": "concerns like can you actually use",
    "start": "912000",
    "end": "913920"
  },
  {
    "text": "serverless for this workload or are",
    "start": "913920",
    "end": "916079"
  },
  {
    "text": "there",
    "start": "916079",
    "end": "916720"
  },
  {
    "text": "hard barriers which make it impossible",
    "start": "916720",
    "end": "919279"
  },
  {
    "text": "to use serverless",
    "start": "919279",
    "end": "921519"
  },
  {
    "text": "finally for the workloads",
    "start": "921519",
    "end": "924560"
  },
  {
    "text": "we tested these systems on a variety of",
    "start": "924560",
    "end": "926639"
  },
  {
    "text": "models including",
    "start": "926639",
    "end": "928480"
  },
  {
    "text": "nlp computer vision traditional ml",
    "start": "928480",
    "end": "930720"
  },
  {
    "text": "models today i'll be focusing",
    "start": "930720",
    "end": "932800"
  },
  {
    "text": "on just a couple of nlp models because",
    "start": "932800",
    "end": "935920"
  },
  {
    "text": "the trends are pretty",
    "start": "935920",
    "end": "937360"
  },
  {
    "text": "similar across the board and we have",
    "start": "937360",
    "end": "940399"
  },
  {
    "text": "different workloads that vary qps or",
    "start": "940399",
    "end": "942639"
  },
  {
    "text": "queries per second",
    "start": "942639",
    "end": "945519"
  },
  {
    "text": "all right so before i go to the results",
    "start": "945600",
    "end": "947519"
  },
  {
    "text": "um i do want to point out a few caveats",
    "start": "947519",
    "end": "950720"
  },
  {
    "text": "the first one is that serverless for",
    "start": "950720",
    "end": "952720"
  },
  {
    "text": "kubernetes is still evolving",
    "start": "952720",
    "end": "955199"
  },
  {
    "text": "and so the numbers that i'm presenting",
    "start": "955199",
    "end": "957279"
  },
  {
    "text": "here are based on the capabilities and",
    "start": "957279",
    "end": "959759"
  },
  {
    "text": "software",
    "start": "959759",
    "end": "960399"
  },
  {
    "text": "available today if you rerun the numbers",
    "start": "960399",
    "end": "962800"
  },
  {
    "text": "in two months",
    "start": "962800",
    "end": "963759"
  },
  {
    "text": "they might be different and so what we",
    "start": "963759",
    "end": "966880"
  },
  {
    "text": "have done is that this benchmark is a",
    "start": "966880",
    "end": "969199"
  },
  {
    "text": "living benchmark",
    "start": "969199",
    "end": "970959"
  },
  {
    "text": "and you can find the full set of results",
    "start": "970959",
    "end": "973040"
  },
  {
    "text": "at that url",
    "start": "973040",
    "end": "974079"
  },
  {
    "text": "and also learn about how you can run the",
    "start": "974079",
    "end": "976720"
  },
  {
    "text": "benchmark yourself",
    "start": "976720",
    "end": "979759"
  },
  {
    "text": "second one is we're using managed",
    "start": "979759",
    "end": "981600"
  },
  {
    "text": "services in this benchmark",
    "start": "981600",
    "end": "983839"
  },
  {
    "text": "and as with all maintenance services",
    "start": "983839",
    "end": "986079"
  },
  {
    "text": "there are knobs that cannot be seen or",
    "start": "986079",
    "end": "988160"
  },
  {
    "text": "controlled by the end user",
    "start": "988160",
    "end": "990079"
  },
  {
    "text": "and there are likely optimizations",
    "start": "990079",
    "end": "991680"
  },
  {
    "text": "performed under the hood",
    "start": "991680",
    "end": "993360"
  },
  {
    "text": "which means that it's a bit challenging",
    "start": "993360",
    "end": "995040"
  },
  {
    "text": "to perform the apples to apples",
    "start": "995040",
    "end": "996639"
  },
  {
    "text": "comparison",
    "start": "996639",
    "end": "998320"
  },
  {
    "text": "the best that we can do and what we've",
    "start": "998320",
    "end": "1000320"
  },
  {
    "text": "done in this benchmark is to use",
    "start": "1000320",
    "end": "1002560"
  },
  {
    "text": "best practices recommended by the cloud",
    "start": "1002560",
    "end": "1005040"
  },
  {
    "text": "providers",
    "start": "1005040",
    "end": "1006079"
  },
  {
    "text": "and to use off-the-shelf settings for",
    "start": "1006079",
    "end": "1008560"
  },
  {
    "text": "the managed services",
    "start": "1008560",
    "end": "1011839"
  },
  {
    "start": "1011000",
    "end": "1187000"
  },
  {
    "text": "all right so let's first get started",
    "start": "1011920",
    "end": "1014320"
  },
  {
    "text": "with results around usability",
    "start": "1014320",
    "end": "1016399"
  },
  {
    "text": "because if you're not able to even use",
    "start": "1016399",
    "end": "1019040"
  },
  {
    "text": "the serverless platform",
    "start": "1019040",
    "end": "1020720"
  },
  {
    "text": "for a particular model then the",
    "start": "1020720",
    "end": "1023040"
  },
  {
    "text": "quantitative numbers don't make sense",
    "start": "1023040",
    "end": "1025839"
  },
  {
    "text": "so the biggest hurdle that we found in",
    "start": "1025839",
    "end": "1028798"
  },
  {
    "text": "using serverless for ml has to do",
    "start": "1028799",
    "end": "1031038"
  },
  {
    "text": "with the restrictions that are put on",
    "start": "1031039",
    "end": "1033120"
  },
  {
    "text": "resources",
    "start": "1033120",
    "end": "1034319"
  },
  {
    "text": "so here i'm listing out the restrictions",
    "start": "1034319",
    "end": "1036959"
  },
  {
    "text": "that are put on lambda and cloud run",
    "start": "1036959",
    "end": "1039438"
  },
  {
    "text": "with respect to memory disk and cpu",
    "start": "1039439",
    "end": "1042880"
  },
  {
    "text": "and what this means is that if you",
    "start": "1042880",
    "end": "1046240"
  },
  {
    "text": "require memory greater than three",
    "start": "1046240",
    "end": "1048000"
  },
  {
    "text": "gigabytes then",
    "start": "1048000",
    "end": "1050080"
  },
  {
    "text": "lambdas are not an option for you you",
    "start": "1050080",
    "end": "1052320"
  },
  {
    "text": "cannot use the serverless platform",
    "start": "1052320",
    "end": "1054880"
  },
  {
    "text": "similarly if you need more than four",
    "start": "1054880",
    "end": "1057120"
  },
  {
    "text": "virtual cpus",
    "start": "1057120",
    "end": "1058480"
  },
  {
    "text": "it's a no go um on google cloud run",
    "start": "1058480",
    "end": "1061360"
  },
  {
    "text": "you're just not going to be able to do",
    "start": "1061360",
    "end": "1062799"
  },
  {
    "text": "that",
    "start": "1062799",
    "end": "1064960"
  },
  {
    "text": "now with ml as we discussed before ml",
    "start": "1064960",
    "end": "1067760"
  },
  {
    "text": "models and ml libraries tend to be",
    "start": "1067760",
    "end": "1069919"
  },
  {
    "text": "rather large and so it",
    "start": "1069919",
    "end": "1073039"
  },
  {
    "text": "it happens more often than not that your",
    "start": "1073039",
    "end": "1076000"
  },
  {
    "text": "ml model doesn't fit",
    "start": "1076000",
    "end": "1077520"
  },
  {
    "text": "in the constraints imposed by the",
    "start": "1077520",
    "end": "1079200"
  },
  {
    "text": "serverless platform",
    "start": "1079200",
    "end": "1081120"
  },
  {
    "text": "to give you two examples the first one",
    "start": "1081120",
    "end": "1083600"
  },
  {
    "text": "has to do with distilbert",
    "start": "1083600",
    "end": "1085280"
  },
  {
    "text": "and to run distilbert what you have to",
    "start": "1085280",
    "end": "1087679"
  },
  {
    "text": "do is",
    "start": "1087679",
    "end": "1088960"
  },
  {
    "text": "install torch and to install the",
    "start": "1088960",
    "end": "1091120"
  },
  {
    "text": "transformer",
    "start": "1091120",
    "end": "1092080"
  },
  {
    "text": "library from hugging phase in this case",
    "start": "1092080",
    "end": "1095360"
  },
  {
    "text": "both of them together are greater than",
    "start": "1095360",
    "end": "1097520"
  },
  {
    "text": "500 megabytes",
    "start": "1097520",
    "end": "1099120"
  },
  {
    "text": "and for a lambda this falls outside of",
    "start": "1099120",
    "end": "1101200"
  },
  {
    "text": "the realm of what's doable",
    "start": "1101200",
    "end": "1103120"
  },
  {
    "text": "and so what we had to do was to",
    "start": "1103120",
    "end": "1104960"
  },
  {
    "text": "surgically remove pieces",
    "start": "1104960",
    "end": "1107280"
  },
  {
    "text": "of library and code and get creative",
    "start": "1107280",
    "end": "1109679"
  },
  {
    "text": "with model loading",
    "start": "1109679",
    "end": "1110960"
  },
  {
    "text": "so that we could actually use distilbert",
    "start": "1110960",
    "end": "1113840"
  },
  {
    "text": "on a lambda",
    "start": "1113840",
    "end": "1115120"
  },
  {
    "text": "so if you if your model is",
    "start": "1115120",
    "end": "1118960"
  },
  {
    "text": "larger than the expected resource",
    "start": "1118960",
    "end": "1122000"
  },
  {
    "text": "constraint you need to get very creative",
    "start": "1122000",
    "end": "1124320"
  },
  {
    "text": "and significant wrangling is involved",
    "start": "1124320",
    "end": "1126400"
  },
  {
    "text": "there",
    "start": "1126400",
    "end": "1127760"
  },
  {
    "text": "the second one is another example that",
    "start": "1127760",
    "end": "1130080"
  },
  {
    "text": "we have",
    "start": "1130080",
    "end": "1131039"
  },
  {
    "text": "seen with multiple clients there's an",
    "start": "1131039",
    "end": "1134080"
  },
  {
    "text": "embedding model",
    "start": "1134080",
    "end": "1135360"
  },
  {
    "text": "for an entity and then there's a nearest",
    "start": "1135360",
    "end": "1137520"
  },
  {
    "text": "neighbor lookup model that's going to",
    "start": "1137520",
    "end": "1139200"
  },
  {
    "text": "find entities that are most similar",
    "start": "1139200",
    "end": "1142240"
  },
  {
    "text": "and because this particular model",
    "start": "1142240",
    "end": "1144000"
  },
  {
    "text": "includes an index that can be pretty",
    "start": "1144000",
    "end": "1145840"
  },
  {
    "text": "large",
    "start": "1145840",
    "end": "1146400"
  },
  {
    "text": "the model ends up being greater than 20",
    "start": "1146400",
    "end": "1149200"
  },
  {
    "text": "gigabytes",
    "start": "1149200",
    "end": "1150000"
  },
  {
    "text": "um that's way outside of the realm of",
    "start": "1150000",
    "end": "1152080"
  },
  {
    "text": "any of the serverless platforms and so",
    "start": "1152080",
    "end": "1154320"
  },
  {
    "text": "you cannot use a serverless platform in",
    "start": "1154320",
    "end": "1156799"
  },
  {
    "text": "order to serve this particular model",
    "start": "1156799",
    "end": "1160640"
  },
  {
    "text": "so last one i want to highlight here is",
    "start": "1160640",
    "end": "1162880"
  },
  {
    "text": "configuration",
    "start": "1162880",
    "end": "1163760"
  },
  {
    "text": "options ml libraries and low level",
    "start": "1163760",
    "end": "1167280"
  },
  {
    "text": "lineage libraries have optimizations",
    "start": "1167280",
    "end": "1169440"
  },
  {
    "text": "that can be tuned via environment",
    "start": "1169440",
    "end": "1170960"
  },
  {
    "text": "variables",
    "start": "1170960",
    "end": "1172480"
  },
  {
    "text": "however in a serverless setting these",
    "start": "1172480",
    "end": "1175039"
  },
  {
    "text": "environment variables or the hardware",
    "start": "1175039",
    "end": "1177919"
  },
  {
    "text": "that determines these environment",
    "start": "1177919",
    "end": "1179679"
  },
  {
    "text": "variables are not exposed to the user",
    "start": "1179679",
    "end": "1182320"
  },
  {
    "text": "and so it's hard to set these",
    "start": "1182320",
    "end": "1184240"
  },
  {
    "text": "environment variables correctly",
    "start": "1184240",
    "end": "1188000"
  },
  {
    "text": "all right so the set of results that we",
    "start": "1188559",
    "end": "1191840"
  },
  {
    "text": "looked at so far have to do with",
    "start": "1191840",
    "end": "1193440"
  },
  {
    "text": "usability",
    "start": "1193440",
    "end": "1194559"
  },
  {
    "text": "can you actually use serverless for this",
    "start": "1194559",
    "end": "1197440"
  },
  {
    "text": "workload",
    "start": "1197440",
    "end": "1198960"
  },
  {
    "text": "next we'll look at some numbers that",
    "start": "1198960",
    "end": "1200799"
  },
  {
    "text": "assume that all right you've gotten",
    "start": "1200799",
    "end": "1203039"
  },
  {
    "text": "you've got into uh running your model on",
    "start": "1203039",
    "end": "1206400"
  },
  {
    "text": "serverless",
    "start": "1206400",
    "end": "1207919"
  },
  {
    "text": "how effective or efficient is it at that",
    "start": "1207919",
    "end": "1211360"
  },
  {
    "text": "so first thing we'll look at is warm",
    "start": "1211360",
    "end": "1213039"
  },
  {
    "text": "star prediction latency",
    "start": "1213039",
    "end": "1214799"
  },
  {
    "text": "warm start is there's already a",
    "start": "1214799",
    "end": "1218400"
  },
  {
    "text": "serverless application running and",
    "start": "1218400",
    "end": "1220799"
  },
  {
    "text": "there's no need to",
    "start": "1220799",
    "end": "1222240"
  },
  {
    "text": "download the model or spin up a instance",
    "start": "1222240",
    "end": "1225440"
  },
  {
    "text": "from scratch",
    "start": "1225440",
    "end": "1226960"
  },
  {
    "text": "we see here that aws lambda and google",
    "start": "1226960",
    "end": "1229520"
  },
  {
    "text": "cloud run are pretty comparable",
    "start": "1229520",
    "end": "1231440"
  },
  {
    "text": "across a p50 p95 and p99 latencies",
    "start": "1231440",
    "end": "1236240"
  },
  {
    "text": "interestingly the virta platform is",
    "start": "1236240",
    "end": "1238240"
  },
  {
    "text": "actually",
    "start": "1238240",
    "end": "1239840"
  },
  {
    "text": "faster by 2x this can be attributed to",
    "start": "1239840",
    "end": "1244480"
  },
  {
    "text": "more control over the environment so",
    "start": "1244480",
    "end": "1247120"
  },
  {
    "text": "this can be processors",
    "start": "1247120",
    "end": "1250400"
  },
  {
    "text": "that we use or specific environment",
    "start": "1250400",
    "end": "1252559"
  },
  {
    "text": "variable settings",
    "start": "1252559",
    "end": "1254080"
  },
  {
    "text": "since lambda and cloud run are closed",
    "start": "1254080",
    "end": "1257039"
  },
  {
    "text": "source",
    "start": "1257039",
    "end": "1257520"
  },
  {
    "text": "it's hard to accurately identify what",
    "start": "1257520",
    "end": "1260320"
  },
  {
    "text": "might be the reason why",
    "start": "1260320",
    "end": "1261440"
  },
  {
    "text": "virta is running 2x faster but",
    "start": "1261440",
    "end": "1264799"
  },
  {
    "text": "it likely has to do with the environment",
    "start": "1264799",
    "end": "1266720"
  },
  {
    "text": "that we're running in",
    "start": "1266720",
    "end": "1268559"
  },
  {
    "text": "and here i'm noting the configurations",
    "start": "1268559",
    "end": "1270400"
  },
  {
    "text": "that we use for all three systems",
    "start": "1270400",
    "end": "1272960"
  },
  {
    "text": "we have tried to keep all the",
    "start": "1272960",
    "end": "1274720"
  },
  {
    "text": "configurations comparable",
    "start": "1274720",
    "end": "1276080"
  },
  {
    "text": "so that we're doing a apple strapless",
    "start": "1276080",
    "end": "1278400"
  },
  {
    "text": "comparison",
    "start": "1278400",
    "end": "1281039"
  },
  {
    "text": "the next result has to do with cold star",
    "start": "1282000",
    "end": "1284240"
  },
  {
    "text": "prediction latency so this is a case",
    "start": "1284240",
    "end": "1286159"
  },
  {
    "text": "where",
    "start": "1286159",
    "end": "1287280"
  },
  {
    "text": "no serverless functions are running",
    "start": "1287280",
    "end": "1290720"
  },
  {
    "text": "already and so this is the time required",
    "start": "1290720",
    "end": "1293919"
  },
  {
    "text": "to spin up a new instance",
    "start": "1293919",
    "end": "1295520"
  },
  {
    "text": "of the serverless function and then",
    "start": "1295520",
    "end": "1297520"
  },
  {
    "text": "service a request",
    "start": "1297520",
    "end": "1299360"
  },
  {
    "text": "so in this case we find that for verda",
    "start": "1299360",
    "end": "1301679"
  },
  {
    "text": "we always have at least one replica",
    "start": "1301679",
    "end": "1303520"
  },
  {
    "text": "running",
    "start": "1303520",
    "end": "1304000"
  },
  {
    "text": "and so it's extremely fast to make the",
    "start": "1304000",
    "end": "1307520"
  },
  {
    "text": "first prediction",
    "start": "1307520",
    "end": "1309520"
  },
  {
    "text": "on the other hand in the lambda case and",
    "start": "1309520",
    "end": "1311760"
  },
  {
    "text": "cloud run case",
    "start": "1311760",
    "end": "1312799"
  },
  {
    "text": "it takes several seconds in order",
    "start": "1312799",
    "end": "1315919"
  },
  {
    "text": "to spin up the first instance of the",
    "start": "1315919",
    "end": "1318640"
  },
  {
    "text": "serverless application",
    "start": "1318640",
    "end": "1320159"
  },
  {
    "text": "and so we find that the latency is in",
    "start": "1320159",
    "end": "1322640"
  },
  {
    "text": "the tens of seconds as opposed to",
    "start": "1322640",
    "end": "1324880"
  },
  {
    "text": "less than a second for virta",
    "start": "1324880",
    "end": "1328400"
  },
  {
    "text": "so the previous results were around",
    "start": "1329039",
    "end": "1332559"
  },
  {
    "text": "time to force prediction the next set of",
    "start": "1332559",
    "end": "1335520"
  },
  {
    "text": "results",
    "start": "1335520",
    "end": "1336159"
  },
  {
    "text": "are for scaling latency so one of the",
    "start": "1336159",
    "end": "1338880"
  },
  {
    "text": "biggest advantages",
    "start": "1338880",
    "end": "1340640"
  },
  {
    "text": "of serverless is its ability to scale",
    "start": "1340640",
    "end": "1343200"
  },
  {
    "text": "based on the workload",
    "start": "1343200",
    "end": "1344720"
  },
  {
    "text": "and so here we're comparing the time",
    "start": "1344720",
    "end": "1346960"
  },
  {
    "text": "required to reach steady state",
    "start": "1346960",
    "end": "1349520"
  },
  {
    "text": "which means in this case we are testing",
    "start": "1349520",
    "end": "1352320"
  },
  {
    "text": "with 100 qbs",
    "start": "1352320",
    "end": "1353760"
  },
  {
    "text": "one worker per query we're saying that",
    "start": "1353760",
    "end": "1357280"
  },
  {
    "text": "we know we've reached steady state when",
    "start": "1357280",
    "end": "1359360"
  },
  {
    "text": "we start receiving 100",
    "start": "1359360",
    "end": "1361520"
  },
  {
    "text": "responses per second and this is",
    "start": "1361520",
    "end": "1365760"
  },
  {
    "text": "successful responses",
    "start": "1365760",
    "end": "1369120"
  },
  {
    "text": "here we see that google cloud run is",
    "start": "1369120",
    "end": "1372240"
  },
  {
    "text": "quite fast 33 seconds lambdas are",
    "start": "1372240",
    "end": "1375919"
  },
  {
    "text": "twice as slow virta is significantly",
    "start": "1375919",
    "end": "1379039"
  },
  {
    "text": "slower",
    "start": "1379039",
    "end": "1379760"
  },
  {
    "text": "and this is to be expected because",
    "start": "1379760",
    "end": "1383120"
  },
  {
    "text": "we're now only relying on the kubernetes",
    "start": "1383120",
    "end": "1385919"
  },
  {
    "text": "auto scaling",
    "start": "1385919",
    "end": "1387120"
  },
  {
    "text": "there are no optimizations being",
    "start": "1387120",
    "end": "1388960"
  },
  {
    "text": "performed in order",
    "start": "1388960",
    "end": "1390880"
  },
  {
    "text": "to always have say warm",
    "start": "1390880",
    "end": "1394960"
  },
  {
    "text": "warm replicas ready to go and so on",
    "start": "1394960",
    "end": "1398240"
  },
  {
    "text": "so the optimizations that a serverless",
    "start": "1398240",
    "end": "1400559"
  },
  {
    "text": "system might",
    "start": "1400559",
    "end": "1401840"
  },
  {
    "text": "implement in order to perform auto",
    "start": "1401840",
    "end": "1404640"
  },
  {
    "text": "scaling",
    "start": "1404640",
    "end": "1405280"
  },
  {
    "text": "are not present in the container-based",
    "start": "1405280",
    "end": "1408559"
  },
  {
    "text": "scaling based on vanilla kubernetes",
    "start": "1408559",
    "end": "1412720"
  },
  {
    "text": "all right the final result here is",
    "start": "1413280",
    "end": "1416320"
  },
  {
    "text": "what happens when we vary the model size",
    "start": "1416320",
    "end": "1419120"
  },
  {
    "text": "so here we're comparing distilled bert",
    "start": "1419120",
    "end": "1420960"
  },
  {
    "text": "against burt",
    "start": "1420960",
    "end": "1422799"
  },
  {
    "text": "bert is twice as large as distilbert",
    "start": "1422799",
    "end": "1427039"
  },
  {
    "text": "and we find that this does impact the",
    "start": "1427039",
    "end": "1429760"
  },
  {
    "text": "latency we see that the p95",
    "start": "1429760",
    "end": "1432480"
  },
  {
    "text": "is twice as much um and",
    "start": "1432480",
    "end": "1435840"
  },
  {
    "text": "the time to first request however is not",
    "start": "1435840",
    "end": "1438159"
  },
  {
    "text": "that much",
    "start": "1438159",
    "end": "1438960"
  },
  {
    "text": "longer particularly for aws for cloud",
    "start": "1438960",
    "end": "1442320"
  },
  {
    "text": "run",
    "start": "1442320",
    "end": "1442720"
  },
  {
    "text": "and for virta we do see some degradation",
    "start": "1442720",
    "end": "1445600"
  },
  {
    "text": "in the time to service the first request",
    "start": "1445600",
    "end": "1450000"
  },
  {
    "text": "so that's a quick overview of some of",
    "start": "1450000",
    "end": "1452000"
  },
  {
    "text": "the key results",
    "start": "1452000",
    "end": "1454000"
  },
  {
    "text": "in comparing serverless versus",
    "start": "1454000",
    "end": "1457360"
  },
  {
    "text": "non-serverless for ml survey",
    "start": "1457360",
    "end": "1460720"
  },
  {
    "start": "1459000",
    "end": "1529000"
  },
  {
    "text": "before i wrap up with a key set of",
    "start": "1460720",
    "end": "1462960"
  },
  {
    "text": "takeaways",
    "start": "1462960",
    "end": "1464080"
  },
  {
    "text": "i do have a note on cost because cost",
    "start": "1464080",
    "end": "1466559"
  },
  {
    "text": "can be one of the key reasons",
    "start": "1466559",
    "end": "1468159"
  },
  {
    "text": "why teams decided decide to go the",
    "start": "1468159",
    "end": "1471360"
  },
  {
    "text": "serverless",
    "start": "1471360",
    "end": "1472000"
  },
  {
    "text": "route and this has to do with two things",
    "start": "1472000",
    "end": "1475279"
  },
  {
    "text": "one is if we discuss only pure",
    "start": "1475279",
    "end": "1478480"
  },
  {
    "text": "infrastructure costs",
    "start": "1478480",
    "end": "1479840"
  },
  {
    "text": "depending on the workload and the amount",
    "start": "1479840",
    "end": "1482159"
  },
  {
    "text": "of resources",
    "start": "1482159",
    "end": "1482960"
  },
  {
    "text": "necessary the pure infra cost may be",
    "start": "1482960",
    "end": "1485919"
  },
  {
    "text": "comparable",
    "start": "1485919",
    "end": "1486960"
  },
  {
    "text": "or even higher in a serverless setting",
    "start": "1486960",
    "end": "1490400"
  },
  {
    "text": "than in a non-serverless setting so if",
    "start": "1490400",
    "end": "1492799"
  },
  {
    "text": "you have steady state",
    "start": "1492799",
    "end": "1494640"
  },
  {
    "text": "in your query workload and your queries",
    "start": "1494640",
    "end": "1498240"
  },
  {
    "text": "have good utilization of the servers it",
    "start": "1498240",
    "end": "1500880"
  },
  {
    "text": "might be",
    "start": "1500880",
    "end": "1501360"
  },
  {
    "text": "cheaper to just use a non-serverless",
    "start": "1501360",
    "end": "1503279"
  },
  {
    "text": "solution",
    "start": "1503279",
    "end": "1504480"
  },
  {
    "text": "however one place where serverless does",
    "start": "1504480",
    "end": "1506960"
  },
  {
    "text": "shine",
    "start": "1506960",
    "end": "1507520"
  },
  {
    "text": "is tco or total cost of ownership",
    "start": "1507520",
    "end": "1510720"
  },
  {
    "text": "this is a combination of infrastructure",
    "start": "1510720",
    "end": "1512640"
  },
  {
    "text": "cost maintenance cost and development",
    "start": "1512640",
    "end": "1514960"
  },
  {
    "text": "costs",
    "start": "1514960",
    "end": "1515840"
  },
  {
    "text": "so if tco is extremely important to you",
    "start": "1515840",
    "end": "1519679"
  },
  {
    "text": "then serverless would make sense",
    "start": "1519679",
    "end": "1521760"
  },
  {
    "text": "otherwise it requires a more nuanced",
    "start": "1521760",
    "end": "1523919"
  },
  {
    "text": "view",
    "start": "1523919",
    "end": "1524320"
  },
  {
    "text": "on what are the infrastructure costs",
    "start": "1524320",
    "end": "1526480"
  },
  {
    "text": "that we're actually signing up for",
    "start": "1526480",
    "end": "1529840"
  },
  {
    "start": "1529000",
    "end": "1647000"
  },
  {
    "text": "all right so with that let me quickly",
    "start": "1529919",
    "end": "1532240"
  },
  {
    "text": "summarize what we",
    "start": "1532240",
    "end": "1533520"
  },
  {
    "text": "learned based on our benchmarking",
    "start": "1533520",
    "end": "1537600"
  },
  {
    "text": "results and hopefully this is helpful",
    "start": "1537600",
    "end": "1540159"
  },
  {
    "text": "for people to",
    "start": "1540159",
    "end": "1541679"
  },
  {
    "text": "make their own decisions on whether",
    "start": "1541679",
    "end": "1543520"
  },
  {
    "text": "serverless is a good fit for",
    "start": "1543520",
    "end": "1545279"
  },
  {
    "text": "your ml surveying use case",
    "start": "1545279",
    "end": "1548799"
  },
  {
    "text": "so first of all serverless solutions",
    "start": "1548799",
    "end": "1551360"
  },
  {
    "text": "have hard limits on resources",
    "start": "1551360",
    "end": "1553520"
  },
  {
    "text": "so if your model doesn't fit within",
    "start": "1553520",
    "end": "1555679"
  },
  {
    "text": "these resources then serverless might",
    "start": "1555679",
    "end": "1557679"
  },
  {
    "text": "not be a good fit for you",
    "start": "1557679",
    "end": "1559840"
  },
  {
    "text": "second the ability to configure hardware",
    "start": "1559840",
    "end": "1563520"
  },
  {
    "text": "can lead to better performance and this",
    "start": "1563520",
    "end": "1565679"
  },
  {
    "text": "is easier in non-serverless systems",
    "start": "1565679",
    "end": "1567919"
  },
  {
    "text": "so this is the case where um the virta",
    "start": "1567919",
    "end": "1570159"
  },
  {
    "text": "system was 2x faster",
    "start": "1570159",
    "end": "1571919"
  },
  {
    "text": "and it had to do with the environment",
    "start": "1571919",
    "end": "1573840"
  },
  {
    "text": "that we were running in",
    "start": "1573840",
    "end": "1576159"
  },
  {
    "text": "next scaling with the serverless",
    "start": "1576159",
    "end": "1578159"
  },
  {
    "text": "platforms is",
    "start": "1578159",
    "end": "1579679"
  },
  {
    "text": "much faster than the vanilla auto",
    "start": "1579679",
    "end": "1582240"
  },
  {
    "text": "scaling that we could do in kubernetes",
    "start": "1582240",
    "end": "1584240"
  },
  {
    "text": "even with custom metrics there's special",
    "start": "1584240",
    "end": "1587520"
  },
  {
    "text": "optimizations that are performed by",
    "start": "1587520",
    "end": "1589120"
  },
  {
    "text": "these platforms",
    "start": "1589120",
    "end": "1590080"
  },
  {
    "text": "for auto scaling that aren't provided",
    "start": "1590080",
    "end": "1592480"
  },
  {
    "text": "out of the box if you're",
    "start": "1592480",
    "end": "1593679"
  },
  {
    "text": "running containers on kubernetes",
    "start": "1593679",
    "end": "1597039"
  },
  {
    "text": "and then finally um the query pattern",
    "start": "1597039",
    "end": "1599600"
  },
  {
    "text": "then workload",
    "start": "1599600",
    "end": "1600799"
  },
  {
    "text": "impacts cost and so in order to assess",
    "start": "1600799",
    "end": "1604080"
  },
  {
    "text": "whether serverless is cheaper than",
    "start": "1604080",
    "end": "1606720"
  },
  {
    "text": "non-serverless",
    "start": "1606720",
    "end": "1608640"
  },
  {
    "text": "for prediction requests to ml models",
    "start": "1608640",
    "end": "1612080"
  },
  {
    "text": "we need to close the other query",
    "start": "1612080",
    "end": "1613520"
  },
  {
    "text": "patterns and workloads",
    "start": "1613520",
    "end": "1616880"
  },
  {
    "text": "so that's uh those were the key points",
    "start": "1617200",
    "end": "1619919"
  },
  {
    "text": "that i wanted to convey",
    "start": "1619919",
    "end": "1621200"
  },
  {
    "text": "regarding the benchmark um please check",
    "start": "1621200",
    "end": "1623919"
  },
  {
    "text": "out",
    "start": "1623919",
    "end": "1624240"
  },
  {
    "text": "bird iai surveillance inference",
    "start": "1624240",
    "end": "1626159"
  },
  {
    "text": "benchmark for the whole set of results",
    "start": "1626159",
    "end": "1628320"
  },
  {
    "text": "and also",
    "start": "1628320",
    "end": "1628960"
  },
  {
    "text": "to learn how you can run the benchmark",
    "start": "1628960",
    "end": "1631360"
  },
  {
    "text": "yourself",
    "start": "1631360",
    "end": "1632880"
  },
  {
    "text": "so with that thanks very much for your",
    "start": "1632880",
    "end": "1634720"
  },
  {
    "text": "attention i would love to continue the",
    "start": "1634720",
    "end": "1636880"
  },
  {
    "text": "conversation around the benchmark",
    "start": "1636880",
    "end": "1638880"
  },
  {
    "text": "please feel free to reach out and want",
    "start": "1638880",
    "end": "1640559"
  },
  {
    "text": "to see alberta or data serial with",
    "start": "1640559",
    "end": "1642559"
  },
  {
    "text": "questions",
    "start": "1642559",
    "end": "1643440"
  },
  {
    "text": "and i'd be happy to feel them there",
    "start": "1643440",
    "end": "1645760"
  },
  {
    "text": "thank you",
    "start": "1645760",
    "end": "1649840"
  }
]
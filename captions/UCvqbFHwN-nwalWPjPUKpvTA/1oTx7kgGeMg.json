[
  {
    "text": "we'll have two full sessions and then three lightning talks if you're giving a lightning talk and we haven't seen you",
    "start": "40",
    "end": "6000"
  },
  {
    "text": "yet if you could just come to the front so that we switch quickly um to start",
    "start": "6000",
    "end": "11280"
  },
  {
    "text": "this uh second part we'll be hearing about cluster operations as a service introducing llm backed controllers and",
    "start": "11280",
    "end": "18119"
  },
  {
    "text": "we have rajes from VMware and Amin from AWS so thank you very much thank you",
    "start": "18119",
    "end": "24080"
  },
  {
    "text": "Ricardo uh am I audible uh the lastro welcome everyone uh",
    "start": "24080",
    "end": "30480"
  },
  {
    "text": "we're going to talk about cluster operations of service so you've talked to Siri and you've talked to all of these uh voice assistants before today",
    "start": "30480",
    "end": "38559"
  },
  {
    "text": "we're going to show you how you can talk to kubernetes and to do that here I am I'm",
    "start": "38559",
    "end": "43640"
  },
  {
    "text": "rajes I work at VMware I'm a senior member of technical staff uh I'm also the tech leader at TAG runtime in cncf",
    "start": "43640",
    "end": "51640"
  },
  {
    "text": "and a contributor to kubernetes have amim with me hey my name is Amin um I",
    "start": "51640",
    "end": "56760"
  },
  {
    "text": "work for AWS and I mostly spend my time doing open source and control rollers and yeah thank you for coming",
    "start": "56760",
    "end": "62719"
  },
  {
    "text": "today so first why should you listen to us well actually you should not because",
    "start": "62719",
    "end": "68479"
  },
  {
    "text": "even our jokes if our our codes laugh out like laugh out at us um we're going",
    "start": "68479",
    "end": "74119"
  },
  {
    "text": "to justify that you should still listen to Art so to get started there's some myths around deep learning so this is a",
    "start": "74119",
    "end": "79520"
  },
  {
    "text": "screenshot from co. fast.ai by Jeremy Howard where uh Jeremy talks about a top",
    "start": "79520",
    "end": "88680"
  },
  {
    "text": "down approach or a c first approach to deep learning so first of all maybe we",
    "start": "88680",
    "end": "94079"
  },
  {
    "text": "should start the conversation by not treating AI as a blackbox and the myth around that we need too much data to",
    "start": "94079",
    "end": "100880"
  },
  {
    "text": "train uh a deep learning model or a large language model is not true we certainly don't need to be phds to train",
    "start": "100880",
    "end": "108200"
  },
  {
    "text": "models as domain experts we can still do that and we've already seen with like Chad GPD deep learning is not just",
    "start": "108200",
    "end": "115439"
  },
  {
    "text": "relevant for vision anymore we can still extend it uh we do need gpus to train",
    "start": "115439",
    "end": "121799"
  },
  {
    "text": "models today but we don't need an AI lab uh and it may not be a brain that we",
    "start": "121799",
    "end": "127920"
  },
  {
    "text": "want to build we just want something that helps us get our job done so to get",
    "start": "127920",
    "end": "134319"
  },
  {
    "text": "started we're going to talk about llms or large language models and then move",
    "start": "134319",
    "end": "139360"
  },
  {
    "text": "on to the kubernetes side of things so what we're going to talk about today is how the gap between domain experts and",
    "start": "139360",
    "end": "146599"
  },
  {
    "text": "deep learning can be bridged by by adapting or acquiring skills that can",
    "start": "146599",
    "end": "153959"
  },
  {
    "text": "improve our efficiency in our tasks um there is an we need to have a",
    "start": "153959",
    "end": "159480"
  },
  {
    "text": "conversation around how we treat data and not treat AI models as just an API",
    "start": "159480",
    "end": "165080"
  },
  {
    "text": "that we can hit for inference we should also be uh considerate about what are the um biases involved in the data and",
    "start": "165080",
    "end": "173440"
  },
  {
    "text": "the whole ethics around uh the data used for training the model so we're going to address that point as well and most",
    "start": "173440",
    "end": "179760"
  },
  {
    "text": "importantly we shouldn't treat we should also have some sort of guidance to the",
    "start": "179760",
    "end": "185799"
  },
  {
    "text": "influence done by the large language model and should not completely rely on",
    "start": "185799",
    "end": "191000"
  },
  {
    "text": "the output given what we're not going to talk about today is how chat GPD solves all of our",
    "start": "191000",
    "end": "199959"
  },
  {
    "text": "problems so what are llms llms you know well we're not going to talk about all",
    "start": "199959",
    "end": "205080"
  },
  {
    "text": "of these things in the spirit of natural language processing we'll walk through this real quick by passing it in English",
    "start": "205080",
    "end": "212959"
  },
  {
    "text": "so a llm is a model that predicts a next set of sentences or next set of words given a",
    "start": "212959",
    "end": "218959"
  },
  {
    "text": "prompt it does this using a set of tokens behind the scenes so what are tokens consider a string like this if",
    "start": "218959",
    "end": "225920"
  },
  {
    "text": "you tokenize it using a tokenizer used for a model so here we've used something for Dy you get a set of tokens these are",
    "start": "225920",
    "end": "234640"
  },
  {
    "text": "just numbers that uh a model understands how to interpret these",
    "start": "234640",
    "end": "239840"
  },
  {
    "text": "numbers if you decode them back you get some sort of words this is how a large",
    "start": "239840",
    "end": "245360"
  },
  {
    "text": "language model parses words sentences behind the scenes at the heart of it it's just a",
    "start": "245360",
    "end": "252200"
  },
  {
    "text": "deep neural network what is a neural network a neural network is just a mathematical function that's completely",
    "start": "252200",
    "end": "257680"
  },
  {
    "text": "flexible and has a billions of parameters that you can f tune so initially it's dumb enough to not know",
    "start": "257680",
    "end": "264320"
  },
  {
    "text": "anything and then we can teach it to basically do anything using an algor",
    "start": "264320",
    "end": "269600"
  },
  {
    "text": "gorithm called a stochastic gradient def gradient descent by showing it examples",
    "start": "269600",
    "end": "274639"
  },
  {
    "text": "of what we wanted to learn that's that's what a new network is now that we've",
    "start": "274639",
    "end": "279880"
  },
  {
    "text": "seen talked about llms um if you want to play around with it there is something",
    "start": "279880",
    "end": "285240"
  },
  {
    "text": "called as NAD orev where given a prompt you can play with multiple language models so here's one that I played with",
    "start": "285240",
    "end": "291520"
  },
  {
    "text": "DaVinci over here and this is what the language model predicted a a lot of the content that we",
    "start": "291520",
    "end": "299560"
  },
  {
    "text": "we've talked that we're going to talk about and that we've already addressed in this uh presentation uh it can be found in this",
    "start": "299560",
    "end": "307039"
  },
  {
    "text": "course by Jeremy Howard on a hacker's guide to large language models uh it's a it's a code first approach so if you",
    "start": "307039",
    "end": "312919"
  },
  {
    "text": "hack if you want to hack around with this if you want to play with training and influencing and fine tuning you should check this out now that we've",
    "start": "312919",
    "end": "320479"
  },
  {
    "text": "touched Bas upon large language model let's move on to the kubernetes side of things so um as you all know everything",
    "start": "320479",
    "end": "329120"
  },
  {
    "text": "in Unity is a controller whenever you create a namespace deployment uh even",
    "start": "329120",
    "end": "334160"
  },
  {
    "text": "secrets and map behind the scenes you have a controller that is trying to manage the state of your application uh",
    "start": "334160",
    "end": "340560"
  },
  {
    "text": "let's say you create a deployment there is of five replicas behind the scenes there is the deployment uh controller",
    "start": "340560",
    "end": "345639"
  },
  {
    "text": "the replica set one and the P controller and all of them they try to work together to make your application",
    "start": "345639",
    "end": "353160"
  },
  {
    "text": "available behind the scenes a controller is a binary that is um running what we",
    "start": "353160",
    "end": "359120"
  },
  {
    "text": "call the reconciliation Loop that is observing the desired States and trying to take actions",
    "start": "359120",
    "end": "366000"
  },
  {
    "text": "and move your desired State or the current state towards the desired",
    "start": "366000",
    "end": "371720"
  },
  {
    "text": "States so R and I for the last few weeks uh we've been working on this uh concept",
    "start": "371720",
    "end": "377120"
  },
  {
    "text": "we like hey we have llms and controllers why not call it lmes um so we created",
    "start": "377120",
    "end": "382639"
  },
  {
    "text": "this controller called LM nities and we're here to demonstrate how it works for example instead of uh creating",
    "start": "382639",
    "end": "389759"
  },
  {
    "text": "a pod or a deployment you can do something like this you can ignore the API version is a little bit um random",
    "start": "389759",
    "end": "396319"
  },
  {
    "text": "but you can for example have a kind called command and you spec instead of um specifying the number of replicas or",
    "start": "396319",
    "end": "403240"
  },
  {
    "text": "the image you can say hey creates three engine pods that will serve traffic on Port 80 and behind the scenes you're",
    "start": "403240",
    "end": "409720"
  },
  {
    "text": "going to have a controller passing that query do whatever some magic behind the scenes and create the pods for",
    "start": "409720",
    "end": "416080"
  },
  {
    "text": "you or the things that I could do for example is cluster audit like hey you know what I want you to go and a this my",
    "start": "416080",
    "end": "422120"
  },
  {
    "text": "cluster go and look at all the pods and the services in all the Nam spaces and try to tell me why it's it working or",
    "start": "422120",
    "end": "428319"
  },
  {
    "text": "why is it working actually um the other one is chaos simulation for example I want um the",
    "start": "428319",
    "end": "435520"
  },
  {
    "text": "controller to come with new ideas of breaking my cluster like hey I think I am a very good communties user I trust",
    "start": "435520",
    "end": "442440"
  },
  {
    "text": "my application and and everything that is in my cluster go ahead and try to find new ways of praking the cluster and",
    "start": "442440",
    "end": "449440"
  },
  {
    "text": "doing what we call like chaos engineering well Now demo didn't happen",
    "start": "449440",
    "end": "455479"
  },
  {
    "text": "so we're going to show you real quick one of the CR these we worked on um on",
    "start": "455479",
    "end": "460599"
  },
  {
    "text": "the bottom here we have the logs of our control that's already running yeah can you all see this",
    "start": "460599",
    "end": "469080"
  },
  {
    "text": "well is it good enough",
    "start": "469080",
    "end": "474360"
  },
  {
    "text": "awesome all right so we have some example today and",
    "start": "474360",
    "end": "480840"
  },
  {
    "text": "the one that we want to show off is the the command exec for",
    "start": "480840",
    "end": "486919"
  },
  {
    "text": "example command exec um we have this one like hey that says deploy a crown job",
    "start": "486919",
    "end": "492879"
  },
  {
    "text": "that will delete a pod randomly in my cluster every two hours use the batch V1",
    "start": "492879",
    "end": "498199"
  },
  {
    "text": "um API and use the k/ cube CLE",
    "start": "498199",
    "end": "502599"
  },
  {
    "text": "image let me check that I don't have any here or no I can just",
    "start": "503520",
    "end": "511240"
  },
  {
    "text": "okay I have my my cluster or like my controller running the query we can see",
    "start": "515000",
    "end": "520360"
  },
  {
    "text": "that in the logs and we're going to wait for the magic behind the scenes to take action",
    "start": "520360",
    "end": "526920"
  },
  {
    "text": "and see what really happened behind the",
    "start": "526920",
    "end": "530399"
  },
  {
    "text": "scenes all right so we can see here for example what the controller did is that",
    "start": "535360",
    "end": "540519"
  },
  {
    "text": "it took an input and it gave us an output and the output you can see like there is a yaml file there in there",
    "start": "540519",
    "end": "546480"
  },
  {
    "text": "there's a command there is also an explanation of what happened and if I do like get Crown",
    "start": "546480",
    "end": "552120"
  },
  {
    "text": "jobs I'm going to see that 18 seconds ago there is a crown job that is running in my cluster that is scheduled for",
    "start": "552120",
    "end": "558200"
  },
  {
    "text": "every two hours in the um the crown syntax and if I do get Crown",
    "start": "558200",
    "end": "563440"
  },
  {
    "text": "jobs yo we can see there is a what I need Cub",
    "start": "563440",
    "end": "570320"
  },
  {
    "text": "Cube CLE delet pod all the pods and Shuffle in them and um it's using the",
    "start": "570320",
    "end": "576560"
  },
  {
    "text": "image it should be Kate SL Cube CLE yeah this one so yeah this is one of the crds",
    "start": "576560",
    "end": "583640"
  },
  {
    "text": "that we use here there's like a lot of other CS we can we can demonstrate but for the sake of time we're not going to",
    "start": "583640",
    "end": "588800"
  },
  {
    "text": "show everything so uh yeah the chaos the chaos",
    "start": "588800",
    "end": "595920"
  },
  {
    "text": "simulation um there is also the CL CL audit that we showed another one is command which is like uh very",
    "start": "595920",
    "end": "604240"
  },
  {
    "text": "simple yeah so uh that's it for the demo what do we have",
    "start": "605959",
    "end": "612959"
  },
  {
    "text": "next yeah yes so what we just saw here was a controller backed by uh an",
    "start": "613600",
    "end": "620680"
  },
  {
    "text": "llm and the model that we used was a GPD 3 3.5 so we were just hitting the open",
    "start": "620680",
    "end": "628399"
  },
  {
    "text": "AI AP behind the scenes in the controller but we don't necessarily have to do that we can extend this and take",
    "start": "628399",
    "end": "634440"
  },
  {
    "text": "this to the next level by not treating AI as a black box um so for that we can",
    "start": "634440",
    "end": "640399"
  },
  {
    "text": "do something called as finetuning so here's a snapshot of the ULM fit 3 step",
    "start": "640399",
    "end": "645480"
  },
  {
    "text": "approach or the algorithm that's behind the scenes for all of the llms or the large language models what's shown over",
    "start": "645480",
    "end": "652200"
  },
  {
    "text": "here is a plain language model which is very much capable of predicting the next",
    "start": "652200",
    "end": "658560"
  },
  {
    "text": "set of sentences and next set of tokens uh ulmfit was trained on Wikipedia a lot",
    "start": "658560",
    "end": "664720"
  },
  {
    "text": "of large language models that are accessible today are trained on data over the Internet so what happens over",
    "start": "664720",
    "end": "670320"
  },
  {
    "text": "here is this model or this neural network is very well capable of understanding constructs of grammar",
    "start": "670320",
    "end": "676880"
  },
  {
    "text": "understanding constructs of language knows the context behind historical data geographical data math equations so on",
    "start": "676880",
    "end": "684120"
  },
  {
    "text": "and so forth so we can take this and finetune it by showing it data that's",
    "start": "684120",
    "end": "689720"
  },
  {
    "text": "closer to our task so in this in this case it'll be data that's closer to its",
    "start": "689720",
    "end": "695760"
  },
  {
    "text": "kubernetes configuration closer towards Cube CTL commands and so on and so forth that's the fine-tuning aspect of it and",
    "start": "695760",
    "end": "702720"
  },
  {
    "text": "then we can use something called as a classifier fine tuning wherein whatever the model predicts we use another llm to",
    "start": "702720",
    "end": "709880"
  },
  {
    "text": "tell it whether the label was right or wrong or we use human intervention over here so in this way we have control over",
    "start": "709880",
    "end": "716240"
  },
  {
    "text": "the inference done by the model and also we're going to see how we can use the data uh we can also see how the false",
    "start": "716240",
    "end": "724480"
  },
  {
    "text": "positives that were treated by the model or where the model gave wrong answers we can feed that back into fineing and try",
    "start": "724480",
    "end": "731360"
  },
  {
    "text": "to get the right answers out of it or at least teach right answers to it so how do we",
    "start": "731360",
    "end": "738880"
  },
  {
    "text": "uh take this as a skill right so here's what we did we tried out",
    "start": "738880",
    "end": "746279"
  },
  {
    "text": "multiple experiments on fine tuning uh uh openly accessible models by a data",
    "start": "746279",
    "end": "752800"
  },
  {
    "text": "using a data set called SK Cube C uh that was by component soft so it's",
    "start": "752800",
    "end": "758440"
  },
  {
    "text": "accessible via hugging phase so hugging phase is a collection of uh data sets models mlof pipelines so on and so forth",
    "start": "758440",
    "end": "765440"
  },
  {
    "text": "so this is what the data set looks like so if you look at uh if you take a closer look at it you can pass that data set and it has",
    "start": "765440",
    "end": "773839"
  },
  {
    "text": "multip it has 35k rows and a bunch of columns around it this is what it looks it has something called is an objective",
    "start": "773839",
    "end": "779959"
  },
  {
    "text": "which sets the context for uh the data set so in this case to print uh the",
    "start": "779959",
    "end": "785440"
  },
  {
    "text": "address of control plan some uh and cluster Services the other column that",
    "start": "785440",
    "end": "790680"
  },
  {
    "text": "we may be interested in is the command that's the actual CBE Cil command that's generated and the question column",
    "start": "790680",
    "end": "797320"
  },
  {
    "text": "wherein we get give the model an instruction to generate a particular command so how do we train this so we",
    "start": "797320",
    "end": "803959"
  },
  {
    "text": "use something called as exal which is a collection of uh AI models under Open",
    "start": "803959",
    "end": "810000"
  },
  {
    "text": "Access AI Collective uh so aital is a tool wherein you can fine-tune models",
    "start": "810000",
    "end": "815760"
  },
  {
    "text": "using a yamal configuration uh it supports multiple uh neural uh large",
    "start": "815760",
    "end": "822839"
  },
  {
    "text": "language model parameters fine tuning so on and so forth and it has a it has collections of multiple models over here",
    "start": "822839",
    "end": "829800"
  },
  {
    "text": "as well so you can see llama pythia so on and so forth so we use Lama to to to go ahead with this talking about gpus we",
    "start": "829800",
    "end": "837600"
  },
  {
    "text": "used eight A10 gpus in this case but you can very well do it on a single GPU as",
    "start": "837600",
    "end": "843040"
  },
  {
    "text": "well so how do you train this you just run one command that's exol launch da d",
    "start": "843040",
    "end": "849079"
  },
  {
    "text": "da and then you get the yaml configuration to it that's it that's how you find T the model the configuration",
    "start": "849079",
    "end": "856279"
  },
  {
    "text": "has uh links to where you fetch the data set from uh how where you store the",
    "start": "856279",
    "end": "862320"
  },
  {
    "text": "model so here we store the model using something called as q q Laura u q is for",
    "start": "862320",
    "end": "868120"
  },
  {
    "text": "quti Laura is how we can space optimize such a huge large language model um and",
    "start": "868120",
    "end": "874399"
  },
  {
    "text": "then there are a set of hyperparameters that you can find you we kept them as default and went ahead with it and we",
    "start": "874399",
    "end": "880880"
  },
  {
    "text": "ran out of GPU space and it took a long time so we tweaked around it like set the sequence length to say 512 instead",
    "start": "880880",
    "end": "887639"
  },
  {
    "text": "of one or two 4 uh we set the number of epoch which is",
    "start": "887639",
    "end": "893320"
  },
  {
    "text": "the number of times the model will go through the data set so we set it only one",
    "start": "893320",
    "end": "899240"
  },
  {
    "text": "and we didn't tweak anything else and we got pretty good results so",
    "start": "899240",
    "end": "904800"
  },
  {
    "text": "the the whole skill that a domain expert can attain is how you can go around how",
    "start": "904800",
    "end": "911120"
  },
  {
    "text": "you can decipher what a training looks like so here's a snapshot of what training looks like so you get the",
    "start": "911120",
    "end": "916360"
  },
  {
    "text": "training loss the idea is to minimize the loss so here we went from 0.5 to",
    "start": "916360",
    "end": "922639"
  },
  {
    "text": "0.09 and how uh you don't have to",
    "start": "922639",
    "end": "927680"
  },
  {
    "text": "minimize it to an extent that you overfit the model and when I say overfit the model will only understand the data",
    "start": "927680",
    "end": "934800"
  },
  {
    "text": "that it's given to you given to it during training and doesn't understand any other data later on uh so we we want",
    "start": "934800",
    "end": "941440"
  },
  {
    "text": "to avoid that but at the same time we want it to be generic enough so that it",
    "start": "941440",
    "end": "947560"
  },
  {
    "text": "it's it's very wellers with the data that's given to it as well while doing this you can tweak around the hyper",
    "start": "947560",
    "end": "954279"
  },
  {
    "text": "parameters you can set the learning rate you can set the weight Decay you can set the op Optimizer and all the other",
    "start": "954279",
    "end": "960880"
  },
  {
    "text": "aspects of a neural network we don't we don't have to go into the details of it right now but the point we're trying to",
    "start": "960880",
    "end": "966040"
  },
  {
    "text": "make over here is that as a domain expert we can get into the fine tunings",
    "start": "966040",
    "end": "972680"
  },
  {
    "text": "of it as in when we need it so that we can experiment and see how the model works we don't have to learn all of",
    "start": "972680",
    "end": "978399"
  },
  {
    "text": "these at first and then get to fine-tuning a model the idea is how we",
    "start": "978399",
    "end": "984319"
  },
  {
    "text": "have a Reconciliation Loop in kubernetes we can extend it over here where we know the desired State we can test the",
    "start": "984319",
    "end": "990839"
  },
  {
    "text": "desired State using inference and then we can tweak out a current state over here by finding each of these",
    "start": "990839",
    "end": "998279"
  },
  {
    "text": "parameters okay the other thing that we want to talk about is the prompt that is given to a model so in this case uh it's",
    "start": "998279",
    "end": "1007399"
  },
  {
    "text": "it's it has context question and answer prompt is very much relevant to any large language model because that's",
    "start": "1007399",
    "end": "1013279"
  },
  {
    "text": "based on how it is trained you can find this data from say hugging phase uh so this is is the prompt that we use this",
    "start": "1013279",
    "end": "1019959"
  },
  {
    "text": "is an example of the training data this is how it looks like when we push it to",
    "start": "1019959",
    "end": "1025160"
  },
  {
    "text": "the prompt here's an example of tiny llama so we tried multiple experiments tiny llama with 1.1 billion parameters",
    "start": "1025160",
    "end": "1032720"
  },
  {
    "text": "smaller model takes uh lesser time to train um so we trained it and here where",
    "start": "1032720",
    "end": "1039199"
  },
  {
    "text": "we are loading the model that we trained we're doing inference of it so here's an objective to create a job with a command",
    "start": "1039199",
    "end": "1045520"
  },
  {
    "text": "and this is the question we have so create a job called lock processing job using the reddis image and run the",
    "start": "1045520",
    "end": "1051880"
  },
  {
    "text": "command Reddit server version in the Crea job so when we run inference this",
    "start": "1051880",
    "end": "1057280"
  },
  {
    "text": "is what the model predicts everything is kind of saride but the image the ver the command that",
    "start": "1057280",
    "end": "1063760"
  },
  {
    "text": "is run is redis and not redis uh server so we extended this to Lama 2 uh with 7",
    "start": "1063760",
    "end": "1071400"
  },
  {
    "text": "billion parameters trained it here's where we running inference on it and",
    "start": "1071400",
    "end": "1076960"
  },
  {
    "text": "this is what it looks like to create create a Cron job is the objective of it and we're passing you know create a Cron",
    "start": "1076960",
    "end": "1084000"
  },
  {
    "text": "job named metrics collection using the goang image the crown job should run",
    "start": "1084000",
    "end": "1089120"
  },
  {
    "text": "every minute and execute the command go hello gun hello. go when we run",
    "start": "1089120",
    "end": "1095919"
  },
  {
    "text": "influence on it this is pretty accurate to what a cube C command should look",
    "start": "1095919",
    "end": "1102600"
  },
  {
    "text": "like we can now play around with it so here if anyone has any suggest",
    "start": "1102600",
    "end": "1108360"
  },
  {
    "text": "suggestions to what we should feed to the model to run an inference you can go ahead like we can take suggestions from",
    "start": "1108360",
    "end": "1114120"
  },
  {
    "text": "the audience uh running a custom one over here to create a p but any question or",
    "start": "1114120",
    "end": "1121480"
  },
  {
    "text": "any suggestion that the audience",
    "start": "1121480",
    "end": "1125200"
  },
  {
    "text": "has nothing okay we'll just write some okay let me write something like to",
    "start": "1127640",
    "end": "1135720"
  },
  {
    "text": "create a service and",
    "start": "1135720",
    "end": "1141120"
  },
  {
    "text": "say create a service of type load",
    "start": "1141120",
    "end": "1148400"
  },
  {
    "text": "balancer and expose P",
    "start": "1148679",
    "end": "1154760"
  },
  {
    "text": "80 uh sure let's try that I don't know if L work to create a pod and uh",
    "start": "1159440",
    "end": "1168919"
  },
  {
    "text": "expose that as a",
    "start": "1168919",
    "end": "1172000"
  },
  {
    "text": "service so create a pod do you have a suggestion for the",
    "start": "1178720",
    "end": "1184840"
  },
  {
    "text": "name nothing called YOLO using engin X",
    "start": "1184840",
    "end": "1193600"
  },
  {
    "text": "image and expose it as a service of type load balancer on",
    "start": "1197240",
    "end": "1204559"
  },
  {
    "text": "Port 8 sounds",
    "start": "1204559",
    "end": "1208320"
  },
  {
    "text": "good now I don't know whether this will work or not but let's give it a",
    "start": "1209799",
    "end": "1215280"
  },
  {
    "text": "shot uh this is kind of s",
    "start": "1216440",
    "end": "1221720"
  },
  {
    "text": "right almost there but that's the point of it right the model may not give you an accurate",
    "start": "1223480",
    "end": "1230159"
  },
  {
    "text": "answer all the time and this was Stained on 35k rows or 35k Cube cedal commands",
    "start": "1230159",
    "end": "1235679"
  },
  {
    "text": "it didn't have context to Everything Under the Sun but the point we're trying to make over here is when the output is",
    "start": "1235679",
    "end": "1241520"
  },
  {
    "text": "not something that we expected or something that we can Peak around we can take this back in and feed it back to",
    "start": "1241520",
    "end": "1247559"
  },
  {
    "text": "the model and say fine T know like whatever you predicted was almost there but you could have done better right so",
    "start": "1247559",
    "end": "1254280"
  },
  {
    "text": "that's that's the point of fine tuning that we that we want to uh make over here because the output that will be",
    "start": "1254280",
    "end": "1260320"
  },
  {
    "text": "given by the model is something that we can we as domain experts can pass this is not something that",
    "start": "1260320",
    "end": "1267679"
  },
  {
    "text": "every llm researcher may know about so this is where you need human",
    "start": "1267679",
    "end": "1273120"
  },
  {
    "text": "intervention from the domain experts so you can extend this analogy to say when you know internet came out so I think",
    "start": "1273120",
    "end": "1278919"
  },
  {
    "text": "Jeremy Howard also talked about this in one of the courses so when internet came out you had to know a lot of things",
    "start": "1278919",
    "end": "1284480"
  },
  {
    "text": "about networking in general to just get say a website uh open up in a browser",
    "start": "1284480",
    "end": "1291320"
  },
  {
    "text": "just to set up your router and modem and things like that 20 years down the line we building business over the internet",
    "start": "1291320",
    "end": "1297880"
  },
  {
    "text": "without knowing anything about TCP I IP stack or anything of that sort right so",
    "start": "1297880",
    "end": "1302960"
  },
  {
    "text": "that's so here we should be able to take Cloud native to an extent where in we",
    "start": "1302960",
    "end": "1308480"
  },
  {
    "text": "can we can use Ai and maybe use cloud native for AI as and bridge the gap",
    "start": "1308480",
    "end": "1315640"
  },
  {
    "text": "between the domain expertise and the Deep learning skill set over",
    "start": "1315640",
    "end": "1320880"
  },
  {
    "text": "here so when we showed this to some of our",
    "start": "1320880",
    "end": "1326760"
  },
  {
    "text": "colleagues uh they said are we going to talk to kubernetes",
    "start": "1326760",
    "end": "1332279"
  },
  {
    "text": "now is that the next step so we were like why",
    "start": "1332279",
    "end": "1339240"
  },
  {
    "text": "not so we'll try another demo I don't know if this will work we've not tested",
    "start": "1339240",
    "end": "1345919"
  },
  {
    "text": "this so let's see uh if we can get this to working where",
    "start": "1345919",
    "end": "1351240"
  },
  {
    "text": "when we try and where we'll try and talk to kubernetes this is the one where we need",
    "start": "1351240",
    "end": "1356799"
  },
  {
    "text": "the demo Gods the most um I think we have an 80% success",
    "start": "1356799",
    "end": "1363640"
  },
  {
    "text": "rate let's go before we do this does",
    "start": "1369000",
    "end": "1374200"
  },
  {
    "text": "audience have any suggestion or else I'll just go with the load balance a service that's the only thing that comes",
    "start": "1374200",
    "end": "1379480"
  },
  {
    "text": "to my mind right [Laughter]",
    "start": "1379480",
    "end": "1388679"
  },
  {
    "text": "now okay so I'll just go with the load balancer service for now I'm not going to touch the upgrade",
    "start": "1393559",
    "end": "1401880"
  },
  {
    "text": "guards create a service called load balancer and expose Port 80",
    "start": "1402679",
    "end": "1409880"
  },
  {
    "text": "it created something let's see whether it did it's still run the query over here we're not yet done we still run the",
    "start": "1411679",
    "end": "1419840"
  },
  {
    "text": "query okay going once",
    "start": "1423799",
    "end": "1427760"
  },
  {
    "text": "again come on we're waiting for this query to run",
    "start": "1429000",
    "end": "1435000"
  },
  {
    "text": "in the background we're worried about the echo we don't know if this will work looks like something came up not",
    "start": "1435000",
    "end": "1443279"
  },
  {
    "text": "yet well it says something okay okay",
    "start": "1443279",
    "end": "1452360"
  },
  {
    "text": "um so this is the Manifest that it created can we show the",
    "start": "1452960",
    "end": "1458159"
  },
  {
    "text": "Manifest kind of s there yeah was it not the the is",
    "start": "1463520",
    "end": "1469880"
  },
  {
    "text": "Manifest the the the point being it still created this manifest and then there was some Stu around how I talked",
    "start": "1469880",
    "end": "1475679"
  },
  {
    "text": "to it and I think Echo and all of that stuff going around around that's",
    "start": "1475679",
    "end": "1481300"
  },
  {
    "text": "[Applause] what so how do you get involved this is",
    "start": "1481300",
    "end": "1488960"
  },
  {
    "text": "a project called llm NES uh you can reach out to us send us",
    "start": "1488960",
    "end": "1494960"
  },
  {
    "text": "PRS in open up issues uh you can tell us how you find here your",
    "start": "1494960",
    "end": "1502840"
  },
  {
    "text": "model if we can add anything to this operator as of now in chaos simulators we still working on how we can extend",
    "start": "1502840",
    "end": "1510120"
  },
  {
    "text": "the level of chaos we're trying to work out upgrading not the control plane but trying to see how we can upgrade",
    "start": "1510120",
    "end": "1516520"
  },
  {
    "text": "kubernetes clusters and whether it will work out or not we also trying to see how we can if we can do CV scans and",
    "start": "1516520",
    "end": "1522159"
  },
  {
    "text": "things like that uh there's also working group AI being formed in cncf on",
    "start": "1522159",
    "end": "1528200"
  },
  {
    "text": "technical Advisory Group runtime and Technical Advisory Group observability so here's the issue where uh the charter",
    "start": "1528200",
    "end": "1534919"
  },
  {
    "text": "is being discussed so if you have thoughts around it if you want to uh talk about this like feel free to chime",
    "start": "1534919",
    "end": "1540120"
  },
  {
    "text": "in on the issue and thank you for making it to",
    "start": "1540120",
    "end": "1545559"
  },
  {
    "text": "this talk and listening to",
    "start": "1545559",
    "end": "1548840"
  },
  {
    "text": "us all right one last one last thing to add everything you saw today is made by",
    "start": "1552360",
    "end": "1558120"
  },
  {
    "text": "a controller behind the scenes and what's happening is that the controller is logging everything that works and didn't work so we have this data set of",
    "start": "1558120",
    "end": "1565480"
  },
  {
    "text": "all the commands that worked and the commands didn't work so we can like continuously teach the the llm model to",
    "start": "1565480",
    "end": "1572320"
  },
  {
    "text": "learn new things and learn from its mistakes so I think right now we have maybe one week of training but if we do this for a full year maybe like we can",
    "start": "1572320",
    "end": "1578480"
  },
  {
    "text": "do actal plan upgrade why not there's a V2 coming up is what we are foreshadowing over here any questions",
    "start": "1578480",
    "end": "1586480"
  },
  {
    "text": "yes we have time for some questions so if you have questions there's a microphone in the",
    "start": "1586480",
    "end": "1592600"
  },
  {
    "text": "middle there's one coming I think yep and we have the two speakers that",
    "start": "1593520",
    "end": "1600960"
  },
  {
    "text": "are coming next if you can come forward uh like we'll speed things up yeah go ahead cool so",
    "start": "1600960",
    "end": "1607880"
  },
  {
    "text": "we cool so we saw some like C C cuddle commands what about generating yaml and",
    "start": "1607880",
    "end": "1614320"
  },
  {
    "text": "like committing it to a code base and then telling go deploy it for me please",
    "start": "1614320",
    "end": "1619799"
  },
  {
    "text": "using xcd system so the fine tuning was done using Cube Cal commands but the controller",
    "start": "1619799",
    "end": "1626120"
  },
  {
    "text": "also generates configuration around it but do you also want to talk about the creting so for example the the uh",
    "start": "1626120",
    "end": "1633120"
  },
  {
    "text": "example of the command uh we've seen before this",
    "start": "1633120",
    "end": "1638760"
  },
  {
    "text": "one uh command",
    "start": "1638760",
    "end": "1642480"
  },
  {
    "text": "exec so this one here the the command is deploy a a pod and uh use like the the",
    "start": "1645159",
    "end": "1651559"
  },
  {
    "text": "batch V1 API but behind the scenes it's not only a cube color command the cube color command is doing only apply to a",
    "start": "1651559",
    "end": "1658120"
  },
  {
    "text": "manifest and you can see that for example here um you can see the output of of the",
    "start": "1658120",
    "end": "1664919"
  },
  {
    "text": "model is there is a yaml file content it has like an API version a service um",
    "start": "1664919",
    "end": "1672240"
  },
  {
    "text": "sorry not this one it must be must be the one before ah it's this",
    "start": "1672240",
    "end": "1677399"
  },
  {
    "text": "one so here you can see that we have a a Cron job yl file it's not really a um",
    "start": "1677399",
    "end": "1684279"
  },
  {
    "text": "one one Cube col command and you can see here at some point we have Cube CTL apply yeah it's",
    "start": "1684279",
    "end": "1691320"
  },
  {
    "text": "this one so the command that the controller did behind the scenes is Cube C apply this this file this is why we",
    "start": "1691320",
    "end": "1696720"
  },
  {
    "text": "have a SL TMP like in the directory we write the Manifest there and then we call Cube can apply yeah it's just a",
    "start": "1696720",
    "end": "1703039"
  },
  {
    "text": "prototype usually we can do something better but yeah it works like that thank you the",
    "start": "1703039",
    "end": "1708559"
  },
  {
    "text": "question uh I'm wondering if there are any plans to integrate the controller with either Vector database or other",
    "start": "1708559",
    "end": "1715440"
  },
  {
    "text": "tools that can provide information as context rather than just find to sorry I didn't get upgrade the controller too uh",
    "start": "1715440",
    "end": "1723440"
  },
  {
    "text": "I'm not sure what you didn't hear but any plans to extend the controller to access any Vector databases or other",
    "start": "1723440",
    "end": "1730000"
  },
  {
    "text": "tools to provide information as context so what we're planning on doing",
    "start": "1730000",
    "end": "1735720"
  },
  {
    "text": "is make sure that the controller talks to any findun model that we embed into",
    "start": "1735720",
    "end": "1740799"
  },
  {
    "text": "it so that model can be trained on a database uh where we'll have the context right and the instructions that given in",
    "start": "1740799",
    "end": "1747480"
  },
  {
    "text": "but when we're talking to the controller we not giving context and all of that stuff we just giving it the instruction",
    "start": "1747480",
    "end": "1752720"
  },
  {
    "text": "does that answer your question yeah thank",
    "start": "1752720",
    "end": "1757919"
  },
  {
    "text": "you hi I have a usage scenario um let's say it's 3:00 in the morning and you get",
    "start": "1757960",
    "end": "1765399"
  },
  {
    "text": "paged and you're with the application developers and they're saying their applications acting funny is there",
    "start": "1765399",
    "end": "1771600"
  },
  {
    "text": "anything you know can you do an analysis of the Clusters you know everything healthy is there any anomalies is that",
    "start": "1771600",
    "end": "1778440"
  },
  {
    "text": "something that possibly the application team could query this you know I guess a chat bot",
    "start": "1778440",
    "end": "1785720"
  },
  {
    "text": "if you will that could maybe quarantine a node it finds maybe there a bad node",
    "start": "1785720",
    "end": "1791240"
  },
  {
    "text": "um you know that kind of thing yep there's a CR that we've introduced called as cluster audit as of now we",
    "start": "1791240",
    "end": "1797200"
  },
  {
    "text": "have parts and services but do you want to talk about it yeah so there's this CR we created called cluster audit um and",
    "start": "1797200",
    "end": "1804399"
  },
  {
    "text": "basically what it does is uh you give it like a set of C or like resources you want to watch um let's do this for",
    "start": "1804399",
    "end": "1812679"
  },
  {
    "text": "example here I'm saying like hey uh I want you to audit the ports and the services but you can also add crds and",
    "start": "1812679",
    "end": "1819640"
  },
  {
    "text": "nodes and things like that and cluster audit is not really to find problems it it's to find problems but can also",
    "start": "1819640",
    "end": "1826159"
  },
  {
    "text": "explain why everything is working fine or it's also I can tell you ways to improve your application so let's say",
    "start": "1826159",
    "end": "1831600"
  },
  {
    "text": "you get page at 3:00 a.m. there's a problem you can run a cluster audit and it's going to go and watch the stages",
    "start": "1831600",
    "end": "1836919"
  },
  {
    "text": "the conditions of of each resource and try to understand where is the problem really like is one of the deployments",
    "start": "1836919",
    "end": "1842799"
  },
  {
    "text": "missing and one of the resources is missing maybe like the node is out of um doesn't have enough storage on disk all",
    "start": "1842799",
    "end": "1848720"
  },
  {
    "text": "those all those of things you can see them on the conditions so the the the controller is basically looking in the conditions to understand what's",
    "start": "1848720",
    "end": "1854519"
  },
  {
    "text": "happening there's also another project called skates GPD that uh also analyzes the cluster you should also check that",
    "start": "1854519",
    "end": "1861559"
  },
  {
    "text": "out we we had a link at the beginning at the opening remarks for for some of",
    "start": "1861559",
    "end": "1867080"
  },
  {
    "text": "these projects y uh so in the interest of times uh maybe we'll take other questions the hallway but if you have",
    "start": "1867080",
    "end": "1873440"
  },
  {
    "text": "any feedback uh please scan this QR code and leave feedback on sced for us thank",
    "start": "1873440",
    "end": "1878639"
  },
  {
    "text": "you very much all right thank you",
    "start": "1878639",
    "end": "1883960"
  }
]
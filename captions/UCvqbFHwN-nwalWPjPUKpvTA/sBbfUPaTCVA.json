[
  {
    "start": "0",
    "end": "92000"
  },
  {
    "text": "all right so",
    "start": "480",
    "end": "3520"
  },
  {
    "text": "hello back and thank you",
    "start": "3679",
    "end": "5680"
  },
  {
    "text": "for um",
    "start": "5680",
    "end": "7680"
  },
  {
    "text": "for giving us the opportunity to present",
    "start": "7680",
    "end": "9679"
  },
  {
    "text": "our experiences",
    "start": "9679",
    "end": "12320"
  },
  {
    "text": "so today we'll talk about",
    "start": "12320",
    "end": "14880"
  },
  {
    "text": "our experiences with",
    "start": "14880",
    "end": "16960"
  },
  {
    "text": "centralized machine learning service at",
    "start": "16960",
    "end": "19279"
  },
  {
    "text": "cern and using coop flow",
    "start": "19279",
    "end": "21680"
  },
  {
    "text": "and uh how will we've been changing it",
    "start": "21680",
    "end": "24000"
  },
  {
    "text": "to to make it better for our users",
    "start": "24000",
    "end": "26960"
  },
  {
    "text": "um",
    "start": "26960",
    "end": "28240"
  },
  {
    "text": "my name is ricardo rocha i'm a computing",
    "start": "28240",
    "end": "31439"
  },
  {
    "text": "engineer in the cern cloud team i do a",
    "start": "31439",
    "end": "34160"
  },
  {
    "text": "lot of containerized work networking and",
    "start": "34160",
    "end": "36880"
  },
  {
    "text": "some machine learning as well",
    "start": "36880",
    "end": "38719"
  },
  {
    "text": "i also i mean a member of the cncft",
    "start": "38719",
    "end": "41840"
  },
  {
    "text": "technical oversight committee and i",
    "start": "41840",
    "end": "43360"
  },
  {
    "text": "colleague the research and user group",
    "start": "43360",
    "end": "45200"
  },
  {
    "text": "also of the cncf",
    "start": "45200",
    "end": "48239"
  },
  {
    "text": "hello",
    "start": "48800",
    "end": "50000"
  },
  {
    "text": "i'm glad to be here my name is dan i'm",
    "start": "50000",
    "end": "52399"
  },
  {
    "text": "software engineer at cern cloud team i",
    "start": "52399",
    "end": "55199"
  },
  {
    "text": "work on containers machine learning and",
    "start": "55199",
    "end": "57680"
  },
  {
    "text": "cube flow and",
    "start": "57680",
    "end": "59359"
  },
  {
    "text": "i will",
    "start": "59359",
    "end": "60559"
  },
  {
    "text": "start with some introduction about our",
    "start": "60559",
    "end": "62559"
  },
  {
    "text": "project and then ricardo will discuss",
    "start": "62559",
    "end": "65198"
  },
  {
    "text": "things in more depth",
    "start": "65199",
    "end": "67680"
  },
  {
    "text": "so we were concerned cern is a research",
    "start": "67680",
    "end": "70720"
  },
  {
    "text": "organization for particle physics in",
    "start": "70720",
    "end": "72479"
  },
  {
    "text": "geneva switzerland",
    "start": "72479",
    "end": "74479"
  },
  {
    "text": "and it's operating the largest particle",
    "start": "74479",
    "end": "76720"
  },
  {
    "text": "physics laboratory in the world",
    "start": "76720",
    "end": "79360"
  },
  {
    "text": "the mission of cern is to find the",
    "start": "79360",
    "end": "81759"
  },
  {
    "text": "origins of the universe to answer the",
    "start": "81759",
    "end": "84159"
  },
  {
    "text": "fundamental questions such as what is",
    "start": "84159",
    "end": "86000"
  },
  {
    "text": "the universe made of and to understand",
    "start": "86000",
    "end": "88159"
  },
  {
    "text": "how particles behave at the smallest",
    "start": "88159",
    "end": "90079"
  },
  {
    "text": "scales",
    "start": "90079",
    "end": "92479"
  },
  {
    "start": "92000",
    "end": "92000"
  },
  {
    "text": "so to understand how particles behave at",
    "start": "92560",
    "end": "94720"
  },
  {
    "text": "the smallest scales we need to use very",
    "start": "94720",
    "end": "97680"
  },
  {
    "text": "high energies",
    "start": "97680",
    "end": "99040"
  },
  {
    "text": "so to do that we build particle",
    "start": "99040",
    "end": "101360"
  },
  {
    "text": "accelerators and lhc is the biggest",
    "start": "101360",
    "end": "103680"
  },
  {
    "text": "particle accelerator in the world so",
    "start": "103680",
    "end": "106079"
  },
  {
    "text": "it's a 27 kilometers ring of",
    "start": "106079",
    "end": "108159"
  },
  {
    "text": "superconducting magnets that",
    "start": "108159",
    "end": "110640"
  },
  {
    "text": "runs 100 meter underground in geneva",
    "start": "110640",
    "end": "114720"
  },
  {
    "text": "and",
    "start": "114720",
    "end": "115759"
  },
  {
    "text": "in that magnet particles are accelerated",
    "start": "115759",
    "end": "118560"
  },
  {
    "text": "near the speed of light",
    "start": "118560",
    "end": "120320"
  },
  {
    "text": "and then they're collided at four",
    "start": "120320",
    "end": "122719"
  },
  {
    "text": "different points for collision points so",
    "start": "122719",
    "end": "125360"
  },
  {
    "text": "after particles collided these high",
    "start": "125360",
    "end": "127840"
  },
  {
    "text": "energies",
    "start": "127840",
    "end": "129280"
  },
  {
    "text": "physicists gather results using",
    "start": "129280",
    "end": "131120"
  },
  {
    "text": "detectors or experiments and then they",
    "start": "131120",
    "end": "134480"
  },
  {
    "text": "use this data to",
    "start": "134480",
    "end": "136319"
  },
  {
    "text": "get valuable uh insights into the",
    "start": "136319",
    "end": "140160"
  },
  {
    "text": "into the science of the smallest scale",
    "start": "140160",
    "end": "142080"
  },
  {
    "text": "particles",
    "start": "142080",
    "end": "143920"
  },
  {
    "text": "so we can see how magnets look like live",
    "start": "143920",
    "end": "147599"
  },
  {
    "text": "uh and this is one of the detectors we",
    "start": "147599",
    "end": "149920"
  },
  {
    "text": "can see people here and how",
    "start": "149920",
    "end": "152879"
  },
  {
    "text": "how this structure looks like and this",
    "start": "152879",
    "end": "155680"
  },
  {
    "text": "is essentially electronics to",
    "start": "155680",
    "end": "158400"
  },
  {
    "text": "extract data from the collisions",
    "start": "158400",
    "end": "162160"
  },
  {
    "start": "161000",
    "end": "161000"
  },
  {
    "text": "so how do we use machine learning at",
    "start": "162160",
    "end": "164080"
  },
  {
    "text": "etser",
    "start": "164080",
    "end": "165680"
  },
  {
    "text": "so",
    "start": "165680",
    "end": "167440"
  },
  {
    "text": "the",
    "start": "167440",
    "end": "168239"
  },
  {
    "text": "data acquisition system works that",
    "start": "168239",
    "end": "171519"
  },
  {
    "text": "works in a specific way so uh there are",
    "start": "171519",
    "end": "173920"
  },
  {
    "text": "40 million collisions that happen uh",
    "start": "173920",
    "end": "176400"
  },
  {
    "text": "every second basically at the lhc uh but",
    "start": "176400",
    "end": "179519"
  },
  {
    "text": "computing infrastructure can only",
    "start": "179519",
    "end": "181280"
  },
  {
    "text": "sustain 1000",
    "start": "181280",
    "end": "182959"
  },
  {
    "text": "events per second so we need to somehow",
    "start": "182959",
    "end": "185519"
  },
  {
    "text": "go from 40 million to 1 1000 and to do",
    "start": "185519",
    "end": "189120"
  },
  {
    "text": "that we use trigger mechanisms so",
    "start": "189120",
    "end": "191840"
  },
  {
    "text": "essentially those are",
    "start": "191840",
    "end": "193599"
  },
  {
    "text": "algorithms that select interesting",
    "start": "193599",
    "end": "195519"
  },
  {
    "text": "events to to save and to further process",
    "start": "195519",
    "end": "201760"
  },
  {
    "text": "so to which the question is what is",
    "start": "202000",
    "end": "204480"
  },
  {
    "text": "interesting and how these",
    "start": "204480",
    "end": "206720"
  },
  {
    "text": "interesting events are selected and to",
    "start": "206720",
    "end": "208799"
  },
  {
    "text": "do that we can either use deterministic",
    "start": "208799",
    "end": "210799"
  },
  {
    "text": "algorithms or we can use",
    "start": "210799",
    "end": "213519"
  },
  {
    "text": "machine learning algorithms and",
    "start": "213519",
    "end": "216000"
  },
  {
    "text": "for that we would use",
    "start": "216000",
    "end": "218400"
  },
  {
    "text": "supervised machine learning algorithms",
    "start": "218400",
    "end": "220879"
  },
  {
    "text": "that can either run in l1 trigger on or",
    "start": "220879",
    "end": "223599"
  },
  {
    "text": "at high level trigger to select the",
    "start": "223599",
    "end": "227120"
  },
  {
    "text": "interesting events and this this works",
    "start": "227120",
    "end": "229680"
  },
  {
    "text": "quite well if we know what we are",
    "start": "229680",
    "end": "231360"
  },
  {
    "text": "looking for but the question is what if",
    "start": "231360",
    "end": "234000"
  },
  {
    "text": "we are looking for for some new physics",
    "start": "234000",
    "end": "237840"
  },
  {
    "start": "237000",
    "end": "237000"
  },
  {
    "text": "so so far machine learning has been",
    "start": "237840",
    "end": "240480"
  },
  {
    "text": "used extensively at cern for example to",
    "start": "240480",
    "end": "243120"
  },
  {
    "text": "find to prove the existence of higgs",
    "start": "243120",
    "end": "245680"
  },
  {
    "text": "boson uh",
    "start": "245680",
    "end": "247840"
  },
  {
    "text": "boosted decision trends were used quite",
    "start": "247840",
    "end": "251519"
  },
  {
    "text": "quite a lot",
    "start": "251519",
    "end": "253599"
  },
  {
    "text": "but there are other physics theories",
    "start": "253599",
    "end": "255519"
  },
  {
    "text": "that were not confirmed by lhc data",
    "start": "255519",
    "end": "258079"
  },
  {
    "text": "which",
    "start": "258079",
    "end": "259680"
  },
  {
    "text": "were expected to be confirmed for",
    "start": "259680",
    "end": "261840"
  },
  {
    "text": "example supersymmetry or extra",
    "start": "261840",
    "end": "264080"
  },
  {
    "text": "dimensions",
    "start": "264080",
    "end": "265759"
  },
  {
    "text": "so that",
    "start": "265759",
    "end": "266880"
  },
  {
    "text": "hasn't been found in lhc data yet so the",
    "start": "266880",
    "end": "269600"
  },
  {
    "text": "question is what if",
    "start": "269600",
    "end": "271520"
  },
  {
    "text": "uh our signal hypothesis for trigger",
    "start": "271520",
    "end": "273680"
  },
  {
    "text": "algorithms was wrong so what",
    "start": "273680",
    "end": "276560"
  },
  {
    "text": "what if there was some kind of bias in",
    "start": "276560",
    "end": "278400"
  },
  {
    "text": "supervised learning so this calls for",
    "start": "278400",
    "end": "280639"
  },
  {
    "text": "some unsupervised learning some",
    "start": "280639",
    "end": "282560"
  },
  {
    "text": "algorithms that could actually learn",
    "start": "282560",
    "end": "284800"
  },
  {
    "text": "during online processing that could",
    "start": "284800",
    "end": "287520"
  },
  {
    "text": "train on",
    "start": "287520",
    "end": "288639"
  },
  {
    "text": "experiment data not only on",
    "start": "288639",
    "end": "290880"
  },
  {
    "text": "simulations",
    "start": "290880",
    "end": "293680"
  },
  {
    "start": "293000",
    "end": "293000"
  },
  {
    "text": "so besides these uh high level overviews",
    "start": "294400",
    "end": "297360"
  },
  {
    "text": "of machine learning there are there are",
    "start": "297360",
    "end": "299520"
  },
  {
    "text": "multiple groups at cern that work on",
    "start": "299520",
    "end": "301520"
  },
  {
    "text": "machine learning",
    "start": "301520",
    "end": "302800"
  },
  {
    "text": "and",
    "start": "302800",
    "end": "303840"
  },
  {
    "text": "they all have their own local",
    "start": "303840",
    "end": "305440"
  },
  {
    "text": "infrastructure so our motivation is to",
    "start": "305440",
    "end": "308080"
  },
  {
    "text": "provide the centralized infrastructure",
    "start": "308080",
    "end": "310639"
  },
  {
    "text": "where users can actually use",
    "start": "310639",
    "end": "313199"
  },
  {
    "text": "gpus and fpgas and tpus and they can",
    "start": "313199",
    "end": "316720"
  },
  {
    "text": "that they can have a user-friendly",
    "start": "316720",
    "end": "318320"
  },
  {
    "text": "platform to run their workloads",
    "start": "318320",
    "end": "321280"
  },
  {
    "text": "so",
    "start": "321280",
    "end": "322320"
  },
  {
    "text": "this is our motivation for kubeflow to",
    "start": "322320",
    "end": "324800"
  },
  {
    "text": "develop a centralized platform that can",
    "start": "324800",
    "end": "327440"
  },
  {
    "text": "be used by by different groups and we",
    "start": "327440",
    "end": "330320"
  },
  {
    "text": "have been working on that for for a bit",
    "start": "330320",
    "end": "333680"
  },
  {
    "text": "uh the idea is to provide the",
    "start": "333680",
    "end": "337120"
  },
  {
    "text": "full machine learning life cycle with",
    "start": "337120",
    "end": "339919"
  },
  {
    "text": "kubeflow",
    "start": "339919",
    "end": "341360"
  },
  {
    "text": "to",
    "start": "341360",
    "end": "342080"
  },
  {
    "text": "get data from detectors to perform data",
    "start": "342080",
    "end": "345120"
  },
  {
    "text": "preparation to run some",
    "start": "345120",
    "end": "347600"
  },
  {
    "text": "fast iteration jobs such as notebooks",
    "start": "347600",
    "end": "350160"
  },
  {
    "text": "and to validate machine learning models",
    "start": "350160",
    "end": "353440"
  },
  {
    "text": "and then once we're happy with our",
    "start": "353440",
    "end": "355199"
  },
  {
    "text": "models to do distributed training and",
    "start": "355199",
    "end": "357520"
  },
  {
    "text": "model validation",
    "start": "357520",
    "end": "359759"
  },
  {
    "text": "and",
    "start": "359759",
    "end": "361039"
  },
  {
    "text": "actually train our models and then to",
    "start": "361039",
    "end": "364240"
  },
  {
    "text": "store the models and use them for",
    "start": "364240",
    "end": "366160"
  },
  {
    "text": "serving for",
    "start": "366160",
    "end": "367440"
  },
  {
    "text": "inference and production",
    "start": "367440",
    "end": "369759"
  },
  {
    "text": "and with kubeflow we can do all of that",
    "start": "369759",
    "end": "371840"
  },
  {
    "start": "370000",
    "end": "370000"
  },
  {
    "text": "and this is why we are using it",
    "start": "371840",
    "end": "375039"
  },
  {
    "text": "so we started with a single user",
    "start": "375039",
    "end": "378880"
  },
  {
    "text": "cubeflow 1.0",
    "start": "378880",
    "end": "380639"
  },
  {
    "text": "at this point we were exploring uh",
    "start": "380639",
    "end": "383039"
  },
  {
    "text": "available features making sure that",
    "start": "383039",
    "end": "384800"
  },
  {
    "text": "pipelines work that cutive jobs work and",
    "start": "384800",
    "end": "387520"
  },
  {
    "text": "that",
    "start": "387520",
    "end": "388880"
  },
  {
    "text": "we can run our machine learning",
    "start": "388880",
    "end": "390319"
  },
  {
    "text": "workloads",
    "start": "390319",
    "end": "391600"
  },
  {
    "text": "uh so this was the initial stage then we",
    "start": "391600",
    "end": "394240"
  },
  {
    "text": "moved to 1.1 instance with the",
    "start": "394240",
    "end": "396639"
  },
  {
    "text": "multi-user and we integrated that with",
    "start": "396639",
    "end": "398960"
  },
  {
    "text": "other services we integrated that with",
    "start": "398960",
    "end": "401520"
  },
  {
    "text": "the single sign-on with",
    "start": "401520",
    "end": "403919"
  },
  {
    "text": "we are managing that with argo cd and we",
    "start": "403919",
    "end": "406479"
  },
  {
    "text": "have on-boarded the users at that point",
    "start": "406479",
    "end": "409599"
  },
  {
    "text": "so we're we're at that point still",
    "start": "409599",
    "end": "411599"
  },
  {
    "text": "working closely with users to gather",
    "start": "411599",
    "end": "414560"
  },
  {
    "text": "their feedback to",
    "start": "414560",
    "end": "416479"
  },
  {
    "text": "discuss",
    "start": "416479",
    "end": "418319"
  },
  {
    "text": "things to provide support more closely",
    "start": "418319",
    "end": "421280"
  },
  {
    "text": "and we were discussing the previous",
    "start": "421280",
    "end": "423280"
  },
  {
    "text": "kubecon in more detail the are bursting",
    "start": "423280",
    "end": "425840"
  },
  {
    "text": "to public cloud",
    "start": "425840",
    "end": "428720"
  },
  {
    "text": "and currently we are working with one",
    "start": "428720",
    "end": "431120"
  },
  {
    "text": "tree instance where our focus is on",
    "start": "431120",
    "end": "434240"
  },
  {
    "text": "security",
    "start": "434240",
    "end": "435440"
  },
  {
    "text": "we want to provide credential management",
    "start": "435440",
    "end": "437520"
  },
  {
    "text": "and namespace management and",
    "start": "437520",
    "end": "440240"
  },
  {
    "text": "vulnerability scans for docker images",
    "start": "440240",
    "end": "443120"
  },
  {
    "text": "and then also some runtime checks",
    "start": "443120",
    "end": "445840"
  },
  {
    "text": "the idea is to provide the general",
    "start": "445840",
    "end": "448479"
  },
  {
    "text": "availability of the service to",
    "start": "448479",
    "end": "451599"
  },
  {
    "text": "be able to",
    "start": "451599",
    "end": "452880"
  },
  {
    "text": "open it to",
    "start": "452880",
    "end": "454160"
  },
  {
    "text": "thousands of people who who work at sir",
    "start": "454160",
    "end": "457759"
  },
  {
    "text": "and this is our our idea and ricardo",
    "start": "457759",
    "end": "460560"
  },
  {
    "text": "will take over",
    "start": "460560",
    "end": "462639"
  },
  {
    "text": "thank you uh i'll actually build on this",
    "start": "462639",
    "end": "465599"
  },
  {
    "text": "one so",
    "start": "465599",
    "end": "466800"
  },
  {
    "text": "uh this this diagram really shows the",
    "start": "466800",
    "end": "469520"
  },
  {
    "text": "evolution of the service at cern uh",
    "start": "469520",
    "end": "472400"
  },
  {
    "text": "we got to the point where we could scale",
    "start": "472400",
    "end": "474479"
  },
  {
    "text": "to the to the size and the number the",
    "start": "474479",
    "end": "477520"
  },
  {
    "text": "amount of resources that our users",
    "start": "477520",
    "end": "479199"
  },
  {
    "text": "needed",
    "start": "479199",
    "end": "480240"
  },
  {
    "text": "uh but",
    "start": "480240",
    "end": "481680"
  },
  {
    "text": "then before opening it in production",
    "start": "481680",
    "end": "484160"
  },
  {
    "text": "there were a couple of things that we we",
    "start": "484160",
    "end": "485680"
  },
  {
    "text": "had to focus on uh and this is the list",
    "start": "485680",
    "end": "488160"
  },
  {
    "text": "that we see here under one three and",
    "start": "488160",
    "end": "489759"
  },
  {
    "text": "this is the requirements we had before",
    "start": "489759",
    "end": "491520"
  },
  {
    "text": "making it",
    "start": "491520",
    "end": "492720"
  },
  {
    "text": "generally available",
    "start": "492720",
    "end": "494560"
  },
  {
    "text": "on premises",
    "start": "494560",
    "end": "495919"
  },
  {
    "text": "so the things i'll be covering here in",
    "start": "495919",
    "end": "498639"
  },
  {
    "text": "addition to the resource availability",
    "start": "498639",
    "end": "500240"
  },
  {
    "text": "i'll cover the management of credentials",
    "start": "500240",
    "end": "503039"
  },
  {
    "text": "for the users",
    "start": "503039",
    "end": "504560"
  },
  {
    "text": "some uh like decoration of namespaces",
    "start": "504560",
    "end": "507520"
  },
  {
    "text": "with user metadata uh the scans and and",
    "start": "507520",
    "end": "510800"
  },
  {
    "text": "checks for for the images",
    "start": "510800",
    "end": "512800"
  },
  {
    "text": "and then using things like opa for",
    "start": "512800",
    "end": "514719"
  },
  {
    "text": "policy informant",
    "start": "514719",
    "end": "516240"
  },
  {
    "text": "enforcement and runtime checks of the",
    "start": "516240",
    "end": "518959"
  },
  {
    "text": "workload so these are really",
    "start": "518959",
    "end": "520399"
  },
  {
    "text": "requirements that we have",
    "start": "520399",
    "end": "522560"
  },
  {
    "text": "that are not only for a machine learning",
    "start": "522560",
    "end": "524560"
  },
  {
    "text": "service but are quite quite important if",
    "start": "524560",
    "end": "527120"
  },
  {
    "text": "you're having a like multi-tenant",
    "start": "527120",
    "end": "529040"
  },
  {
    "text": "multi-user",
    "start": "529040",
    "end": "530160"
  },
  {
    "start": "530000",
    "end": "530000"
  },
  {
    "text": "deployment",
    "start": "530160",
    "end": "532240"
  },
  {
    "text": "but the first thing i will cover is uh",
    "start": "532240",
    "end": "534399"
  },
  {
    "text": "regarding resource usage so um dan",
    "start": "534399",
    "end": "537279"
  },
  {
    "text": "introduced that one of the motivations",
    "start": "537279",
    "end": "538959"
  },
  {
    "text": "we had was to kind of improve the",
    "start": "538959",
    "end": "541120"
  },
  {
    "text": "efficiency of the the resources we have",
    "start": "541120",
    "end": "543440"
  },
  {
    "text": "at cern instead of having multiple",
    "start": "543440",
    "end": "545519"
  },
  {
    "text": "groups having each each of the groups",
    "start": "545519",
    "end": "548080"
  },
  {
    "text": "several gpus we wanted to have like a",
    "start": "548080",
    "end": "549920"
  },
  {
    "text": "central uh pool of resources uh that",
    "start": "549920",
    "end": "552800"
  },
  {
    "text": "would make it uh more efficient overall",
    "start": "552800",
    "end": "555440"
  },
  {
    "text": "so we we have an example here where we",
    "start": "555440",
    "end": "557680"
  },
  {
    "text": "have",
    "start": "557680",
    "end": "558480"
  },
  {
    "text": "uh different groups uh at cern say cms",
    "start": "558480",
    "end": "561600"
  },
  {
    "text": "and atlas which are experiments at cern",
    "start": "561600",
    "end": "563760"
  },
  {
    "text": "so atlas susie's super symmetry",
    "start": "563760",
    "end": "567279"
  },
  {
    "text": "we had also groups in it doing anomaly",
    "start": "567279",
    "end": "569519"
  },
  {
    "text": "detection or in beam calibration doing",
    "start": "569519",
    "end": "572080"
  },
  {
    "text": "reinforced learning uh while they",
    "start": "572080",
    "end": "574000"
  },
  {
    "text": "calibrate the lhc beams",
    "start": "574000",
    "end": "576560"
  },
  {
    "text": "all of this is kind of inefficient",
    "start": "576560",
    "end": "578080"
  },
  {
    "text": "because each of the groups has to",
    "start": "578080",
    "end": "579440"
  },
  {
    "text": "maintain their own gpus and also the",
    "start": "579440",
    "end": "582000"
  },
  {
    "text": "resource usage is restricted to these",
    "start": "582000",
    "end": "584320"
  },
  {
    "text": "individual groups so moving to something",
    "start": "584320",
    "end": "586720"
  },
  {
    "text": "like this",
    "start": "586720",
    "end": "587839"
  },
  {
    "text": "where we basically have a single entry",
    "start": "587839",
    "end": "590399"
  },
  {
    "text": "point for everyone to come",
    "start": "590399",
    "end": "592640"
  },
  {
    "text": "and and and then benefit from these gpus",
    "start": "592640",
    "end": "596720"
  },
  {
    "text": "is is",
    "start": "596720",
    "end": "598959"
  },
  {
    "text": "a big improvement for us also we can",
    "start": "598959",
    "end": "601120"
  },
  {
    "text": "integrate things like fpgas and other",
    "start": "601120",
    "end": "603120"
  },
  {
    "text": "accelerators as required",
    "start": "603120",
    "end": "605360"
  },
  {
    "text": "it does pose some challenges because you",
    "start": "605360",
    "end": "607200"
  },
  {
    "text": "suddenly start",
    "start": "607200",
    "end": "608480"
  },
  {
    "text": "sharing the resources between users",
    "start": "608480",
    "end": "610959"
  },
  {
    "text": "uh the other thing we wanted to to do is",
    "start": "610959",
    "end": "613760"
  },
  {
    "text": "which dan also mentioned and we",
    "start": "613760",
    "end": "615920"
  },
  {
    "text": "presented last coupon is we want to",
    "start": "615920",
    "end": "617760"
  },
  {
    "text": "scale out like the amount of resources",
    "start": "617760",
    "end": "619519"
  },
  {
    "text": "we have on premises are actually not",
    "start": "619519",
    "end": "620959"
  },
  {
    "text": "enough for what we need",
    "start": "620959",
    "end": "622959"
  },
  {
    "text": "in terms of accelerators",
    "start": "622959",
    "end": "625360"
  },
  {
    "text": "both in terms of gpus we don't have",
    "start": "625360",
    "end": "627120"
  },
  {
    "text": "enough but also accessing specialized",
    "start": "627120",
    "end": "629839"
  },
  {
    "text": "accelerators like tpus which we'll",
    "start": "629839",
    "end": "632480"
  },
  {
    "text": "probably not never have and they are",
    "start": "632480",
    "end": "634320"
  },
  {
    "text": "restricted to to the cloud providers or",
    "start": "634320",
    "end": "636800"
  },
  {
    "text": "ipu's in the case of azure gpus for gcp",
    "start": "636800",
    "end": "640480"
  },
  {
    "text": "so we want to abstract all of this so",
    "start": "640480",
    "end": "642320"
  },
  {
    "text": "that our users don't have to understand",
    "start": "642320",
    "end": "644000"
  },
  {
    "text": "the infrastructure they just have to run",
    "start": "644000",
    "end": "645600"
  },
  {
    "text": "their workloads",
    "start": "645600",
    "end": "648000"
  },
  {
    "start": "647000",
    "end": "647000"
  },
  {
    "text": "the other part um",
    "start": "648000",
    "end": "650160"
  },
  {
    "text": "so here it it's",
    "start": "650160",
    "end": "652640"
  },
  {
    "text": "where where the integration starts",
    "start": "652640",
    "end": "655519"
  },
  {
    "text": "we we rely on coop flow as as we",
    "start": "655519",
    "end": "657839"
  },
  {
    "text": "mentioned but then if we have this peak",
    "start": "657839",
    "end": "659920"
  },
  {
    "text": "pool of resources we might have say",
    "start": "659920",
    "end": "661680"
  },
  {
    "text": "nvidia p100s and mv100s",
    "start": "661680",
    "end": "665440"
  },
  {
    "text": "which are quite good at double precision",
    "start": "665440",
    "end": "667360"
  },
  {
    "text": "very good for distributed training",
    "start": "667360",
    "end": "669440"
  },
  {
    "text": "when you're doing things like",
    "start": "669440",
    "end": "671040"
  },
  {
    "text": "deep learning",
    "start": "671040",
    "end": "672880"
  },
  {
    "text": "and we expose this via pci passthrough",
    "start": "672880",
    "end": "675279"
  },
  {
    "text": "we also have nvidia t4s which we use for",
    "start": "675279",
    "end": "678320"
  },
  {
    "text": "notebooks training and and inference",
    "start": "678320",
    "end": "680560"
  },
  {
    "text": "again using pci passthrough but then",
    "start": "680560",
    "end": "684240"
  },
  {
    "text": "if you're just using a notebook for",
    "start": "684240",
    "end": "686000"
  },
  {
    "text": "validating your model with a small small",
    "start": "686000",
    "end": "688079"
  },
  {
    "text": "amount of data you probably don't need a",
    "start": "688079",
    "end": "689680"
  },
  {
    "text": "full gpu so we started looking at this",
    "start": "689680",
    "end": "691519"
  },
  {
    "text": "idea of",
    "start": "691519",
    "end": "693279"
  },
  {
    "text": "doing virtual gpus and the previous talk",
    "start": "693279",
    "end": "695279"
  },
  {
    "text": "was was talking about sharing resources",
    "start": "695279",
    "end": "697760"
  },
  {
    "text": "for model serving",
    "start": "697760",
    "end": "699680"
  },
  {
    "text": "this is similar a similar concept and",
    "start": "699680",
    "end": "702399"
  },
  {
    "text": "then also we started looking at adding",
    "start": "702399",
    "end": "704959"
  },
  {
    "text": "nvidia a100s they will arrive soon and",
    "start": "704959",
    "end": "707680"
  },
  {
    "text": "here we can actually do physical",
    "start": "707680",
    "end": "708959"
  },
  {
    "text": "partitioning instead of just time",
    "start": "708959",
    "end": "711200"
  },
  {
    "text": "sharing as with the t4s and vgpus so we",
    "start": "711200",
    "end": "714480"
  },
  {
    "text": "wanted to expose this to our users uh",
    "start": "714480",
    "end": "717120"
  },
  {
    "text": "when they spawned um a notebook at cern",
    "start": "717120",
    "end": "720160"
  },
  {
    "text": "so they won't see just like uh i want a",
    "start": "720160",
    "end": "722320"
  },
  {
    "text": "gpu nvidia they will actually have like",
    "start": "722320",
    "end": "724560"
  },
  {
    "text": "a drop down box that says i want an uh",
    "start": "724560",
    "end": "727440"
  },
  {
    "text": "like a full gpu or i want a virtual gpu",
    "start": "727440",
    "end": "730720"
  },
  {
    "text": "and here i would highlight what we are",
    "start": "730720",
    "end": "733200"
  },
  {
    "text": "aiming for and we'll come back to this",
    "start": "733200",
    "end": "735120"
  },
  {
    "text": "is when you see their gpus available to",
    "start": "735120",
    "end": "737760"
  },
  {
    "text": "use no we want to express to the user",
    "start": "737760",
    "end": "740000"
  },
  {
    "text": "actually what is the availability of",
    "start": "740000",
    "end": "741680"
  },
  {
    "text": "resources so that they don't just try",
    "start": "741680",
    "end": "745040"
  },
  {
    "text": "senselessly to to get a resource that is",
    "start": "745040",
    "end": "747360"
  },
  {
    "text": "not there",
    "start": "747360",
    "end": "748560"
  },
  {
    "text": "um and again we we want to integrate the",
    "start": "748560",
    "end": "750880"
  },
  {
    "text": "public cloud resources uh into the same",
    "start": "750880",
    "end": "753760"
  },
  {
    "text": "same setup",
    "start": "753760",
    "end": "754959"
  },
  {
    "text": "so we are like halfway there i would say",
    "start": "754959",
    "end": "758320"
  },
  {
    "text": "the other part which is uh yeah i",
    "start": "758320",
    "end": "760399"
  },
  {
    "text": "mentioned i mentioned the a100 so",
    "start": "760399",
    "end": "763120"
  },
  {
    "text": "if you've played with the nvidia t4s you",
    "start": "763120",
    "end": "765440"
  },
  {
    "text": "know like you can virtualize these gpus",
    "start": "765440",
    "end": "767440"
  },
  {
    "text": "or v100s uh with this time sharing which",
    "start": "767440",
    "end": "770079"
  },
  {
    "text": "is kind of",
    "start": "770079",
    "end": "771680"
  },
  {
    "text": "like a fake",
    "start": "771680",
    "end": "773120"
  },
  {
    "text": "partitioning you're not actually",
    "start": "773120",
    "end": "774639"
  },
  {
    "text": "partitioning the resources",
    "start": "774639",
    "end": "776480"
  },
  {
    "text": "uh but with a100s there's this",
    "start": "776480",
    "end": "778240"
  },
  {
    "text": "multi-instance gpus support which is",
    "start": "778240",
    "end": "781040"
  },
  {
    "text": "really exciting because it gives us a",
    "start": "781040",
    "end": "782880"
  },
  {
    "text": "lot more flexibility on how to partition",
    "start": "782880",
    "end": "784720"
  },
  {
    "text": "resources to the end users without",
    "start": "784720",
    "end": "787200"
  },
  {
    "text": "having to to like do any compromise in",
    "start": "787200",
    "end": "789760"
  },
  {
    "text": "terms of",
    "start": "789760",
    "end": "791519"
  },
  {
    "text": "the expected quality of service",
    "start": "791519",
    "end": "794800"
  },
  {
    "text": "and then really building on the previous",
    "start": "794800",
    "end": "796880"
  },
  {
    "text": "talk i would i would",
    "start": "796880",
    "end": "798399"
  },
  {
    "text": "complement uh",
    "start": "798399",
    "end": "800399"
  },
  {
    "text": "the things we are doing so i mentioned",
    "start": "800399",
    "end": "801839"
  },
  {
    "text": "nvidia virtual gpus with uh time times",
    "start": "801839",
    "end": "804560"
  },
  {
    "text": "for time sharing uh there were i will",
    "start": "804560",
    "end": "807760"
  },
  {
    "text": "just put a note here if you are using",
    "start": "807760",
    "end": "809600"
  },
  {
    "text": "this one thing we learned is that uh",
    "start": "809600",
    "end": "811680"
  },
  {
    "text": "this was not",
    "start": "811680",
    "end": "812959"
  },
  {
    "text": "really suitable for all our users",
    "start": "812959",
    "end": "814959"
  },
  {
    "text": "because the ones that need gpu profiling",
    "start": "814959",
    "end": "817200"
  },
  {
    "text": "or want to use a tensorboard or",
    "start": "817200",
    "end": "819680"
  },
  {
    "text": "something similar they actually require",
    "start": "819680",
    "end": "822079"
  },
  {
    "text": "uh the profiling to be enabled on the",
    "start": "822079",
    "end": "824399"
  },
  {
    "text": "gpus this was a limitation with the",
    "start": "824399",
    "end": "826959"
  },
  {
    "text": "12 drivers the version 12 drivers of",
    "start": "826959",
    "end": "830079"
  },
  {
    "text": "nvidia",
    "start": "830079",
    "end": "831199"
  },
  {
    "text": "this is actually fixed in version 13",
    "start": "831199",
    "end": "833360"
  },
  {
    "text": "we've tested this so we actually are",
    "start": "833360",
    "end": "835120"
  },
  {
    "text": "about to deploy this to our users this",
    "start": "835120",
    "end": "837040"
  },
  {
    "text": "will make",
    "start": "837040",
    "end": "838079"
  },
  {
    "text": "the use of our t4s much better",
    "start": "838079",
    "end": "841040"
  },
  {
    "text": "but again the the next step is what we",
    "start": "841040",
    "end": "843760"
  },
  {
    "text": "are getting early next year which is",
    "start": "843760",
    "end": "845440"
  },
  {
    "text": "this new nvidia m100 where we can do up",
    "start": "845440",
    "end": "848320"
  },
  {
    "text": "to seven times physical partitioning and",
    "start": "848320",
    "end": "850480"
  },
  {
    "text": "this is something that is uh supported",
    "start": "850480",
    "end": "852880"
  },
  {
    "text": "directly on kubernetes the nvidia",
    "start": "852880",
    "end": "855360"
  },
  {
    "text": "drivers are able to do to manage mig uh",
    "start": "855360",
    "end": "858880"
  },
  {
    "text": "mig cards",
    "start": "858880",
    "end": "860639"
  },
  {
    "text": "so this this is really great because the",
    "start": "860639",
    "end": "862320"
  },
  {
    "text": "vgpus were are not something that",
    "start": "862320",
    "end": "864639"
  },
  {
    "text": "kubernetes uh handles uh natively",
    "start": "864639",
    "end": "868639"
  },
  {
    "text": "um yeah",
    "start": "868639",
    "end": "870399"
  },
  {
    "text": "and then the other part is the",
    "start": "870399",
    "end": "871519"
  },
  {
    "text": "multi-model serving this is also a",
    "start": "871519",
    "end": "873920"
  },
  {
    "text": "requirement we have to make the best out",
    "start": "873920",
    "end": "875760"
  },
  {
    "text": "of the gpu is to be able to split to to",
    "start": "875760",
    "end": "878639"
  },
  {
    "text": "reuse the same same gpu for serving",
    "start": "878639",
    "end": "881600"
  },
  {
    "text": "multiple models",
    "start": "881600",
    "end": "882959"
  },
  {
    "text": "and this is uh something like this is a",
    "start": "882959",
    "end": "885199"
  },
  {
    "text": "very basic example",
    "start": "885199",
    "end": "887040"
  },
  {
    "text": "where you basically create a single",
    "start": "887040",
    "end": "889040"
  },
  {
    "text": "inference service",
    "start": "889040",
    "end": "890560"
  },
  {
    "text": "and then you have",
    "start": "890560",
    "end": "892320"
  },
  {
    "text": "one or more actual models that are",
    "start": "892320",
    "end": "894639"
  },
  {
    "text": "linked to that inference service so this",
    "start": "894639",
    "end": "896720"
  },
  {
    "text": "is something that we also try to do and",
    "start": "896720",
    "end": "898639"
  },
  {
    "text": "it's uh",
    "start": "898639",
    "end": "899600"
  },
  {
    "text": "it's uh like a follow-up to the to the",
    "start": "899600",
    "end": "902320"
  },
  {
    "text": "really good previous talk",
    "start": "902320",
    "end": "905680"
  },
  {
    "start": "906000",
    "end": "906000"
  },
  {
    "text": "so the second part i would mention is",
    "start": "906720",
    "end": "909279"
  },
  {
    "text": "this neces this requirement we have to",
    "start": "909279",
    "end": "911519"
  },
  {
    "text": "integrate with our on-premises resources",
    "start": "911519",
    "end": "913920"
  },
  {
    "text": "uh so we rely on mutating mission web",
    "start": "913920",
    "end": "916800"
  },
  {
    "text": "hooks for for all of this uh we are",
    "start": "916800",
    "end": "918959"
  },
  {
    "text": "actually using the opel gatekeeper",
    "start": "918959",
    "end": "922079"
  },
  {
    "text": "in if you've deployed coop flow you know",
    "start": "922079",
    "end": "924399"
  },
  {
    "text": "that you can do a lot with customize in",
    "start": "924399",
    "end": "926320"
  },
  {
    "text": "terms of changing the the yaml that is",
    "start": "926320",
    "end": "929199"
  },
  {
    "text": "being used for the deployment but this",
    "start": "929199",
    "end": "930880"
  },
  {
    "text": "is not enough um",
    "start": "930880",
    "end": "932880"
  },
  {
    "text": "one example is for example the notebook",
    "start": "932880",
    "end": "934480"
  },
  {
    "text": "template to customize the notebooks in",
    "start": "934480",
    "end": "936720"
  },
  {
    "text": "the jupyter web app",
    "start": "936720",
    "end": "938639"
  },
  {
    "text": "it's quite limited on what you can do",
    "start": "938639",
    "end": "940320"
  },
  {
    "text": "this if you want to",
    "start": "940320",
    "end": "942160"
  },
  {
    "text": "like change the template dynamically",
    "start": "942160",
    "end": "943920"
  },
  {
    "text": "based on some uh runtime information you",
    "start": "943920",
    "end": "946639"
  },
  {
    "text": "can do this with customize so we do this",
    "start": "946639",
    "end": "949120"
  },
  {
    "text": "with the mutating web hooks",
    "start": "949120",
    "end": "951839"
  },
  {
    "text": "this is used already in different parts",
    "start": "951839",
    "end": "953920"
  },
  {
    "text": "of coop flow i'll give some examples",
    "start": "953920",
    "end": "956480"
  },
  {
    "text": "and then i'll go a bit deeper",
    "start": "956480",
    "end": "958959"
  },
  {
    "text": "one thing",
    "start": "958959",
    "end": "960399"
  },
  {
    "text": "if you want to for example to start a",
    "start": "960399",
    "end": "962079"
  },
  {
    "text": "pod speed notebooks or pipeline jobs",
    "start": "962079",
    "end": "965920"
  },
  {
    "text": "with the proper uid gid of the local",
    "start": "965920",
    "end": "968320"
  },
  {
    "text": "users for multiple reasons",
    "start": "968320",
    "end": "971360"
  },
  {
    "text": "we we do this change at runtime",
    "start": "971360",
    "end": "974160"
  },
  {
    "text": "another thing is that we need to manage",
    "start": "974160",
    "end": "976000"
  },
  {
    "text": "the credentials for the user so that",
    "start": "976000",
    "end": "977519"
  },
  {
    "text": "they can access like storage systems or",
    "start": "977519",
    "end": "979920"
  },
  {
    "text": "any kind of other internal system",
    "start": "979920",
    "end": "982880"
  },
  {
    "text": "we inject those credentials also at run",
    "start": "982880",
    "end": "985519"
  },
  {
    "text": "at",
    "start": "985519",
    "end": "986320"
  },
  {
    "text": "deployment time of the pots creation",
    "start": "986320",
    "end": "988320"
  },
  {
    "text": "time",
    "start": "988320",
    "end": "989199"
  },
  {
    "text": "um yeah the volume amounts for for the",
    "start": "989199",
    "end": "991199"
  },
  {
    "text": "internal storage systems",
    "start": "991199",
    "end": "993519"
  },
  {
    "text": "as well",
    "start": "993519",
    "end": "995600"
  },
  {
    "start": "995000",
    "end": "995000"
  },
  {
    "text": "so this is an example for the credential",
    "start": "995600",
    "end": "997759"
  },
  {
    "text": "management uh",
    "start": "997759",
    "end": "999199"
  },
  {
    "text": "i would say mostly we have two types of",
    "start": "999199",
    "end": "1002240"
  },
  {
    "text": "credentials that we have to handle the",
    "start": "1002240",
    "end": "1003680"
  },
  {
    "text": "first one is kerberos the second one is",
    "start": "1003680",
    "end": "1005519"
  },
  {
    "text": "oauth2",
    "start": "1005519",
    "end": "1006800"
  },
  {
    "text": "um most of our services",
    "start": "1006800",
    "end": "1009279"
  },
  {
    "text": "require one or the other or both",
    "start": "1009279",
    "end": "1013199"
  },
  {
    "text": "so the in both cases they are",
    "start": "1013440",
    "end": "1015040"
  },
  {
    "text": "short-lived which means like you might",
    "start": "1015040",
    "end": "1017199"
  },
  {
    "text": "have a credential you spawn your your",
    "start": "1017199",
    "end": "1019759"
  },
  {
    "text": "training but it takes hours they will",
    "start": "1019759",
    "end": "1021839"
  },
  {
    "text": "expire so what we've done we've written",
    "start": "1021839",
    "end": "1024240"
  },
  {
    "text": "a small tool that actually manages the",
    "start": "1024240",
    "end": "1026640"
  },
  {
    "text": "credential renewal for the users",
    "start": "1026640",
    "end": "1028880"
  },
  {
    "text": "uh",
    "start": "1028880",
    "end": "1029678"
  },
  {
    "text": "transparently so when when they they",
    "start": "1029679",
    "end": "1032160"
  },
  {
    "text": "basically get a notebook they will",
    "start": "1032160",
    "end": "1033678"
  },
  {
    "text": "upload say a covers credential to their",
    "start": "1033679",
    "end": "1036160"
  },
  {
    "text": "namespace",
    "start": "1036160",
    "end": "1038400"
  },
  {
    "text": "and then the tool will know how to",
    "start": "1038400",
    "end": "1040240"
  },
  {
    "text": "handle this and keep the credentials up",
    "start": "1040240",
    "end": "1042000"
  },
  {
    "text": "to date so if they then submit a",
    "start": "1042000",
    "end": "1043520"
  },
  {
    "text": "pipeline uh training job",
    "start": "1043520",
    "end": "1046400"
  },
  {
    "text": "uh or any kind of other workload on the",
    "start": "1046400",
    "end": "1048400"
  },
  {
    "text": "cluster",
    "start": "1048400",
    "end": "1049440"
  },
  {
    "text": "the",
    "start": "1049440",
    "end": "1050240"
  },
  {
    "text": "the amounts of these secrets will",
    "start": "1050240",
    "end": "1052160"
  },
  {
    "text": "actually make the credentials available",
    "start": "1052160",
    "end": "1053840"
  },
  {
    "text": "for for the workloads to use and this is",
    "start": "1053840",
    "end": "1056720"
  },
  {
    "text": "true both for uh oauth2 and and corpus",
    "start": "1056720",
    "end": "1060160"
  },
  {
    "text": "and you can see here like a diagram the",
    "start": "1060160",
    "end": "1062400"
  },
  {
    "text": "first step is for a user to like push",
    "start": "1062400",
    "end": "1064960"
  },
  {
    "text": "the credentials into a secret and our",
    "start": "1064960",
    "end": "1066640"
  },
  {
    "text": "job will renew them and then the actual",
    "start": "1066640",
    "end": "1068640"
  },
  {
    "text": "workloads have this mutating web hook",
    "start": "1068640",
    "end": "1070480"
  },
  {
    "text": "that is actually",
    "start": "1070480",
    "end": "1071760"
  },
  {
    "text": "uh mounting these secrets and making",
    "start": "1071760",
    "end": "1073840"
  },
  {
    "text": "them available so that they can access",
    "start": "1073840",
    "end": "1075520"
  },
  {
    "text": "things like storage or the internal",
    "start": "1075520",
    "end": "1077360"
  },
  {
    "text": "spark clusters uh the batch cluster",
    "start": "1077360",
    "end": "1079919"
  },
  {
    "text": "which is based on hd condor the registry",
    "start": "1079919",
    "end": "1082320"
  },
  {
    "text": "to upload their models things like this",
    "start": "1082320",
    "end": "1085919"
  },
  {
    "start": "1086000",
    "end": "1086000"
  },
  {
    "text": "the second part is what i mentioned that",
    "start": "1086400",
    "end": "1089120"
  },
  {
    "text": "we sometimes have to annotate workloads",
    "start": "1089120",
    "end": "1091039"
  },
  {
    "text": "with the metadata of of the user so an",
    "start": "1091039",
    "end": "1094480"
  },
  {
    "text": "example is is again notebooks have to",
    "start": "1094480",
    "end": "1096799"
  },
  {
    "text": "have a uid gid that matches the actual",
    "start": "1096799",
    "end": "1099280"
  },
  {
    "text": "user",
    "start": "1099280",
    "end": "1100240"
  },
  {
    "text": "so we do this",
    "start": "1100240",
    "end": "1101919"
  },
  {
    "text": "by actually when when a new user is on",
    "start": "1101919",
    "end": "1104640"
  },
  {
    "text": "boarded they get the private namespace",
    "start": "1104640",
    "end": "1107120"
  },
  {
    "text": "but we have a component that will",
    "start": "1107120",
    "end": "1108559"
  },
  {
    "text": "basically fetch all the metadata from",
    "start": "1108559",
    "end": "1110480"
  },
  {
    "text": "say ldap in the internal ldap and we'll",
    "start": "1110480",
    "end": "1113120"
  },
  {
    "text": "put all of this as",
    "start": "1113120",
    "end": "1114880"
  },
  {
    "text": "annotations",
    "start": "1114880",
    "end": "1117120"
  },
  {
    "text": "or labels in in the namespaces of the",
    "start": "1117120",
    "end": "1119280"
  },
  {
    "text": "users and the same is true for groups",
    "start": "1119280",
    "end": "1122240"
  },
  {
    "text": "this means that we have all the metadata",
    "start": "1122240",
    "end": "1124000"
  },
  {
    "text": "we need about the users to then",
    "start": "1124000",
    "end": "1126320"
  },
  {
    "text": "do mutations that at runtime when",
    "start": "1126320",
    "end": "1128880"
  },
  {
    "text": "creating the pods to to deploy them with",
    "start": "1128880",
    "end": "1131520"
  },
  {
    "text": "the appropriate",
    "start": "1131520",
    "end": "1133360"
  },
  {
    "text": "security context all the proper user",
    "start": "1133360",
    "end": "1135919"
  },
  {
    "text": "group that is required this is a like a",
    "start": "1135919",
    "end": "1139039"
  },
  {
    "text": "requirement from our security team",
    "start": "1139039",
    "end": "1142720"
  },
  {
    "start": "1142000",
    "end": "1142000"
  },
  {
    "text": "and then the last one i would mention is",
    "start": "1142720",
    "end": "1146080"
  },
  {
    "text": "the internal registry so all we mandate",
    "start": "1146080",
    "end": "1148640"
  },
  {
    "text": "that all the workloads running on the",
    "start": "1148640",
    "end": "1150559"
  },
  {
    "text": "cluster have to come from our internal",
    "start": "1150559",
    "end": "1152240"
  },
  {
    "text": "registry which means that they've",
    "start": "1152240",
    "end": "1154400"
  },
  {
    "text": "they've been through the vulnerability",
    "start": "1154400",
    "end": "1155919"
  },
  {
    "text": "scans with 3v for this we also sign all",
    "start": "1155919",
    "end": "1158640"
  },
  {
    "text": "the images",
    "start": "1158640",
    "end": "1160080"
  },
  {
    "text": "then we have the different policy",
    "start": "1160080",
    "end": "1162080"
  },
  {
    "text": "enforcements at creation time which for",
    "start": "1162080",
    "end": "1165120"
  },
  {
    "text": "example prevent external images from",
    "start": "1165120",
    "end": "1167440"
  },
  {
    "text": "being run",
    "start": "1167440",
    "end": "1168880"
  },
  {
    "text": "but also can do checks like",
    "start": "1168880",
    "end": "1171039"
  },
  {
    "text": "is the security context",
    "start": "1171039",
    "end": "1174080"
  },
  {
    "text": "correct or acceptable or do does the",
    "start": "1174080",
    "end": "1177360"
  },
  {
    "text": "workload have all the metadata we need",
    "start": "1177360",
    "end": "1179360"
  },
  {
    "text": "like for accounting for example",
    "start": "1179360",
    "end": "1182000"
  },
  {
    "text": "so we do we do have some some sort of",
    "start": "1182000",
    "end": "1185120"
  },
  {
    "text": "caching and replication from dr",
    "start": "1185120",
    "end": "1187039"
  },
  {
    "text": "dockerhub into our internal registry",
    "start": "1187039",
    "end": "1188880"
  },
  {
    "text": "that then triggers all these scans and",
    "start": "1188880",
    "end": "1190720"
  },
  {
    "text": "then we",
    "start": "1190720",
    "end": "1191600"
  },
  {
    "text": "we go from there",
    "start": "1191600",
    "end": "1193520"
  },
  {
    "text": "the second part is that at run time like",
    "start": "1193520",
    "end": "1195760"
  },
  {
    "text": "this this will help us at deployment",
    "start": "1195760",
    "end": "1198080"
  },
  {
    "text": "time but if you have long running jobs",
    "start": "1198080",
    "end": "1200720"
  },
  {
    "text": "we also need need to do some",
    "start": "1200720",
    "end": "1202880"
  },
  {
    "text": "checks at runtime so we are using falco",
    "start": "1202880",
    "end": "1204960"
  },
  {
    "text": "for this and we do basically two main",
    "start": "1204960",
    "end": "1207039"
  },
  {
    "text": "things",
    "start": "1207039",
    "end": "1208480"
  },
  {
    "text": "one is to see that whatever",
    "start": "1208480",
    "end": "1210480"
  },
  {
    "text": "vulnerability checks were done are still",
    "start": "1210480",
    "end": "1212640"
  },
  {
    "text": "valid that there's no new vulnerability",
    "start": "1212640",
    "end": "1214799"
  },
  {
    "text": "for some sort of long-running notebook",
    "start": "1214799",
    "end": "1216559"
  },
  {
    "text": "for example",
    "start": "1216559",
    "end": "1217760"
  },
  {
    "text": "and the second one is that the workloads",
    "start": "1217760",
    "end": "1220000"
  },
  {
    "text": "are doing what they are expected to do",
    "start": "1220000",
    "end": "1221600"
  },
  {
    "text": "so there's no shells being spawned",
    "start": "1221600",
    "end": "1223360"
  },
  {
    "text": "inside the container there's no packages",
    "start": "1223360",
    "end": "1226000"
  },
  {
    "text": "that are not supposed to be installed",
    "start": "1226000",
    "end": "1227919"
  },
  {
    "text": "being being installed doing some weird",
    "start": "1227919",
    "end": "1230080"
  },
  {
    "text": "system calls or network connections so",
    "start": "1230080",
    "end": "1232320"
  },
  {
    "text": "we do these checks live and uh one thing",
    "start": "1232320",
    "end": "1235039"
  },
  {
    "text": "that is quite",
    "start": "1235039",
    "end": "1236880"
  },
  {
    "text": "uh uncommon",
    "start": "1236880",
    "end": "1238480"
  },
  {
    "text": "uh at least but i think everywhere is",
    "start": "1238480",
    "end": "1241039"
  },
  {
    "text": "that when we described the stack to our",
    "start": "1241039",
    "end": "1242799"
  },
  {
    "text": "security team they were actually very",
    "start": "1242799",
    "end": "1244240"
  },
  {
    "text": "happy and this having a security team",
    "start": "1244240",
    "end": "1246799"
  },
  {
    "text": "being happy about new services is not",
    "start": "1246799",
    "end": "1250159"
  },
  {
    "text": "common so this was",
    "start": "1250159",
    "end": "1252000"
  },
  {
    "text": "quite satisfying",
    "start": "1252000",
    "end": "1255360"
  },
  {
    "start": "1255000",
    "end": "1255000"
  },
  {
    "text": "i think",
    "start": "1255919",
    "end": "1257679"
  },
  {
    "text": "so",
    "start": "1257679",
    "end": "1259360"
  },
  {
    "text": "so far we have been working with couple",
    "start": "1259360",
    "end": "1261360"
  },
  {
    "text": "of groups at cern who have been using",
    "start": "1261360",
    "end": "1264240"
  },
  {
    "text": "our kubeflow instance",
    "start": "1264240",
    "end": "1265919"
  },
  {
    "text": "uh and in the next couple of slides i'll",
    "start": "1265919",
    "end": "1269200"
  },
  {
    "text": "describe some individual user feedbacks",
    "start": "1269200",
    "end": "1273120"
  },
  {
    "text": "so the first one the users really like",
    "start": "1273120",
    "end": "1276080"
  },
  {
    "text": "is the integration between notebooks to",
    "start": "1276080",
    "end": "1278640"
  },
  {
    "text": "pipelines they really enjoy using kale",
    "start": "1278640",
    "end": "1281520"
  },
  {
    "text": "so if they can go from a notebook to",
    "start": "1281520",
    "end": "1285120"
  },
  {
    "text": "a pipeline seamlessly without writing",
    "start": "1285120",
    "end": "1287679"
  },
  {
    "text": "any docker images or anything with",
    "start": "1287679",
    "end": "1289520"
  },
  {
    "text": "kubernetes",
    "start": "1289520",
    "end": "1290720"
  },
  {
    "text": "that that's really a big advantage for",
    "start": "1290720",
    "end": "1292960"
  },
  {
    "text": "users so this is something we have a",
    "start": "1292960",
    "end": "1295840"
  },
  {
    "text": "very very positive feedback so far",
    "start": "1295840",
    "end": "1300000"
  },
  {
    "text": "then",
    "start": "1300000",
    "end": "1300799"
  },
  {
    "text": "users really enjoyed the ability to get",
    "start": "1300799",
    "end": "1303600"
  },
  {
    "text": "resources on demand so",
    "start": "1303600",
    "end": "1306480"
  },
  {
    "text": "for example if they have some models",
    "start": "1306480",
    "end": "1308400"
  },
  {
    "text": "that need hundreds of gpus to properly",
    "start": "1308400",
    "end": "1311120"
  },
  {
    "text": "train",
    "start": "1311120",
    "end": "1312400"
  },
  {
    "text": "they can't have that locally",
    "start": "1312400",
    "end": "1315440"
  },
  {
    "text": "and",
    "start": "1315440",
    "end": "1316480"
  },
  {
    "text": "on the public cloud we can provide",
    "start": "1316480",
    "end": "1319280"
  },
  {
    "text": "access to this number of",
    "start": "1319280",
    "end": "1321440"
  },
  {
    "text": "of gpus so users really like that and",
    "start": "1321440",
    "end": "1324480"
  },
  {
    "text": "they ask for such uh",
    "start": "1324480",
    "end": "1328080"
  },
  {
    "text": "abilities",
    "start": "1328080",
    "end": "1329600"
  },
  {
    "text": "and then there we have some advanced",
    "start": "1329600",
    "end": "1331120"
  },
  {
    "text": "users for example we have a group at",
    "start": "1331120",
    "end": "1333360"
  },
  {
    "text": "atlas one of the experiments that",
    "start": "1333360",
    "end": "1335919"
  },
  {
    "text": "they have some they have a repo with",
    "start": "1335919",
    "end": "1337679"
  },
  {
    "text": "machine learning project and then on",
    "start": "1337679",
    "end": "1339600"
  },
  {
    "text": "that project they have continuous",
    "start": "1339600",
    "end": "1341280"
  },
  {
    "text": "integration and yeah whenever they",
    "start": "1341280",
    "end": "1344320"
  },
  {
    "text": "commit they want to run some continuous",
    "start": "1344320",
    "end": "1347120"
  },
  {
    "text": "integration uh they would like to add a",
    "start": "1347120",
    "end": "1349760"
  },
  {
    "text": "step that would trigger a pipeline into",
    "start": "1349760",
    "end": "1352320"
  },
  {
    "text": "our cube flow instance within their uh",
    "start": "1352320",
    "end": "1355280"
  },
  {
    "text": "ci so they need the",
    "start": "1355280",
    "end": "1357919"
  },
  {
    "text": "api access to to cube flow so this is",
    "start": "1357919",
    "end": "1361039"
  },
  {
    "text": "something that we also",
    "start": "1361039",
    "end": "1364080"
  },
  {
    "text": "need sometimes",
    "start": "1364080",
    "end": "1366559"
  },
  {
    "text": "and then",
    "start": "1366559",
    "end": "1367840"
  },
  {
    "text": "we need some",
    "start": "1367840",
    "end": "1370799"
  },
  {
    "text": "better",
    "start": "1370799",
    "end": "1373120"
  },
  {
    "text": "ui for when uh",
    "start": "1373440",
    "end": "1375840"
  },
  {
    "text": "resources are not available for example",
    "start": "1375840",
    "end": "1377840"
  },
  {
    "text": "for notebook creations for gpus uh we",
    "start": "1377840",
    "end": "1381520"
  },
  {
    "text": "implemented this additional tool that",
    "start": "1381520",
    "end": "1383120"
  },
  {
    "text": "tells us if we have uh available gpus in",
    "start": "1383120",
    "end": "1385919"
  },
  {
    "text": "our system and as ricardo was mentioning",
    "start": "1385919",
    "end": "1387919"
  },
  {
    "text": "to select uh",
    "start": "1387919",
    "end": "1389600"
  },
  {
    "text": "the profile for for a gpu so if users",
    "start": "1389600",
    "end": "1393120"
  },
  {
    "text": "could actually automatically see if they",
    "start": "1393120",
    "end": "1395360"
  },
  {
    "text": "have a gpu",
    "start": "1395360",
    "end": "1396720"
  },
  {
    "text": "it it's much better for them",
    "start": "1396720",
    "end": "1399760"
  },
  {
    "start": "1398000",
    "end": "1398000"
  },
  {
    "text": "so to to sum up kubeflow has been very",
    "start": "1399760",
    "end": "1402720"
  },
  {
    "text": "well received at cern um we are about",
    "start": "1402720",
    "end": "1405520"
  },
  {
    "text": "open to all users and all groups after",
    "start": "1405520",
    "end": "1408480"
  },
  {
    "text": "we validate with",
    "start": "1408480",
    "end": "1410080"
  },
  {
    "text": "our security",
    "start": "1410080",
    "end": "1411600"
  },
  {
    "text": "uh",
    "start": "1411600",
    "end": "1412480"
  },
  {
    "text": "requirements that ricardo was discussing",
    "start": "1412480",
    "end": "1416080"
  },
  {
    "text": "so yeah we want to provide credential",
    "start": "1416080",
    "end": "1418080"
  },
  {
    "text": "and name space management as well",
    "start": "1418080",
    "end": "1420320"
  },
  {
    "text": "and",
    "start": "1420320",
    "end": "1421360"
  },
  {
    "text": "for the improvements from the actual",
    "start": "1421360",
    "end": "1423120"
  },
  {
    "text": "cube flow it would be great if we could",
    "start": "1423120",
    "end": "1425039"
  },
  {
    "text": "have a complete isolation for example",
    "start": "1425039",
    "end": "1427279"
  },
  {
    "text": "for uh pipelines",
    "start": "1427279",
    "end": "1429200"
  },
  {
    "text": "it's already done in the back end it",
    "start": "1429200",
    "end": "1430720"
  },
  {
    "text": "would be",
    "start": "1430720",
    "end": "1431600"
  },
  {
    "text": "really great for us to have that in in",
    "start": "1431600",
    "end": "1433520"
  },
  {
    "text": "front end as well also pipeline",
    "start": "1433520",
    "end": "1436080"
  },
  {
    "text": "artifacts to be isolated and also we",
    "start": "1436080",
    "end": "1439039"
  },
  {
    "text": "would need some better debugging of",
    "start": "1439039",
    "end": "1440880"
  },
  {
    "text": "katip jobs because users can't see logs",
    "start": "1440880",
    "end": "1443360"
  },
  {
    "text": "on the ui",
    "start": "1443360",
    "end": "1444559"
  },
  {
    "text": "and yeah maybe a better feedback",
    "start": "1444559",
    "end": "1446880"
  },
  {
    "text": "speaking of resource availability but in",
    "start": "1446880",
    "end": "1449279"
  },
  {
    "text": "general uh cube flow is",
    "start": "1449279",
    "end": "1451679"
  },
  {
    "text": "like whenever we have a presentation in",
    "start": "1451679",
    "end": "1453279"
  },
  {
    "text": "certain people are very excited and our",
    "start": "1453279",
    "end": "1455200"
  },
  {
    "text": "users so far really",
    "start": "1455200",
    "end": "1457200"
  },
  {
    "text": "enjoy using it so thank you very much",
    "start": "1457200",
    "end": "1460240"
  },
  {
    "text": "and",
    "start": "1460240",
    "end": "1461039"
  },
  {
    "text": "guess if you have any questions",
    "start": "1461039",
    "end": "1463039"
  },
  {
    "start": "1463000",
    "end": "1463000"
  },
  {
    "text": "let us know",
    "start": "1463039",
    "end": "1464750"
  },
  {
    "text": "[Applause]",
    "start": "1464750",
    "end": "1470260"
  }
]
[
  {
    "text": "so first of all a warm welcome to cubec",
    "start": "320",
    "end": "2840"
  },
  {
    "text": "con India really proud that it's",
    "start": "2840",
    "end": "4480"
  },
  {
    "text": "happening for the first time uh this",
    "start": "4480",
    "end": "6520"
  },
  {
    "text": "particular project like is going to be",
    "start": "6520",
    "end": "8280"
  },
  {
    "text": "around wasum Edge and how you can use",
    "start": "8280",
    "end": "11280"
  },
  {
    "text": "wasum to empower llms and AI agents uh",
    "start": "11280",
    "end": "14839"
  },
  {
    "text": "I'm Shai I'm part of the maintainer team",
    "start": "14839",
    "end": "16720"
  },
  {
    "text": "for vet project so let's get started now",
    "start": "16720",
    "end": "20080"
  },
  {
    "text": "uh first of all what is vet so vet is a",
    "start": "20080",
    "end": "22400"
  },
  {
    "text": "web assembly runtime that allows you to",
    "start": "22400",
    "end": "24560"
  },
  {
    "text": "run your vum workloads whether it's in",
    "start": "24560",
    "end": "27119"
  },
  {
    "text": "the cloud on communities inside of",
    "start": "27119",
    "end": "28800"
  },
  {
    "text": "Docker or even on the edge and it",
    "start": "28800",
    "end": "31400"
  },
  {
    "text": "doesn't care on what type of edge",
    "start": "31400",
    "end": "33160"
  },
  {
    "text": "environment that you run it on because",
    "start": "33160",
    "end": "34640"
  },
  {
    "text": "webs as a technology uh is a universal",
    "start": "34640",
    "end": "38399"
  },
  {
    "text": "runtime now why web assembly for AI",
    "start": "38399",
    "end": "42640"
  },
  {
    "text": "right we'll we'll talk about that in a",
    "start": "42640",
    "end": "44200"
  },
  {
    "text": "bit but you see that uh over the last",
    "start": "44200",
    "end": "47039"
  },
  {
    "text": "few years the adoption of web assembly",
    "start": "47039",
    "end": "49719"
  },
  {
    "text": "as a technology has really grown several",
    "start": "49719",
    "end": "51520"
  },
  {
    "text": "folds so today vet project has more than",
    "start": "51520",
    "end": "54239"
  },
  {
    "text": "6,000 GitHub Stars it is actively being",
    "start": "54239",
    "end": "56640"
  },
  {
    "text": "used by a lot of different other",
    "start": "56640",
    "end": "58039"
  },
  {
    "text": "projects within the CNC for uh cncf",
    "start": "58039",
    "end": "60680"
  },
  {
    "text": "ecosystem as well and the idea is that",
    "start": "60680",
    "end": "62600"
  },
  {
    "text": "you can actually use web assembly for",
    "start": "62600",
    "end": "64360"
  },
  {
    "text": "being able to run and deploy AI models",
    "start": "64360",
    "end": "67400"
  },
  {
    "text": "uh or AI agents directly on your own",
    "start": "67400",
    "end": "69320"
  },
  {
    "text": "infra without having to worry too much",
    "start": "69320",
    "end": "71360"
  },
  {
    "text": "on what type of environment you're",
    "start": "71360",
    "end": "72680"
  },
  {
    "text": "actually running it on or you can also",
    "start": "72680",
    "end": "74119"
  },
  {
    "text": "bundle it with your own applications and",
    "start": "74119",
    "end": "76119"
  },
  {
    "text": "serve them wherever you want uh so of",
    "start": "76119",
    "end": "78600"
  },
  {
    "text": "course the question arises that when we",
    "start": "78600",
    "end": "80320"
  },
  {
    "text": "talk about AI workloads why not python",
    "start": "80320",
    "end": "82560"
  },
  {
    "text": "because python can be very difficult to",
    "start": "82560",
    "end": "85159"
  },
  {
    "text": "use especially because of the large",
    "start": "85159",
    "end": "87320"
  },
  {
    "text": "container sizes and the slow cold are",
    "start": "87320",
    "end": "90159"
  },
  {
    "text": "times that you have to deal with when",
    "start": "90159",
    "end": "91479"
  },
  {
    "text": "you are using Frameworks like pyts and",
    "start": "91479",
    "end": "94399"
  },
  {
    "text": "that basically hinders the performance",
    "start": "94399",
    "end": "96159"
  },
  {
    "text": "especially if you're trying to run these",
    "start": "96159",
    "end": "97520"
  },
  {
    "text": "workloads on edge environments which is",
    "start": "97520",
    "end": "100079"
  },
  {
    "text": "a growing field as we seeing a lot of",
    "start": "100079",
    "end": "102280"
  },
  {
    "text": "use cases for AI on edge devices so",
    "start": "102280",
    "end": "105680"
  },
  {
    "text": "that's where we talk about rust because",
    "start": "105680",
    "end": "107600"
  },
  {
    "text": "rust is memory safe and it has a lot of",
    "start": "107600",
    "end": "109960"
  },
  {
    "text": "concurrency and uh as compared to web as",
    "start": "109960",
    "end": "112719"
  },
  {
    "text": "compared to python web assembly is much",
    "start": "112719",
    "end": "114600"
  },
  {
    "text": "more faster it ships with zero python",
    "start": "114600",
    "end": "117079"
  },
  {
    "text": "dependency and you can basically write",
    "start": "117079",
    "end": "118880"
  },
  {
    "text": "that logic once and ship it anywhere",
    "start": "118880",
    "end": "121039"
  },
  {
    "text": "that you want and it's highly portable",
    "start": "121039",
    "end": "122840"
  },
  {
    "text": "at the same time and uh in fact the",
    "start": "122840",
    "end": "125399"
  },
  {
    "text": "wasum sandbox is also highly secure as",
    "start": "125399",
    "end": "127960"
  },
  {
    "text": "compared to any other python runtime",
    "start": "127960",
    "end": "129840"
  },
  {
    "text": "that you might primally deal with and",
    "start": "129840",
    "end": "131760"
  },
  {
    "text": "also of course we know that wum is",
    "start": "131760",
    "end": "133640"
  },
  {
    "text": "container ready so you can ship your",
    "start": "133640",
    "end": "135040"
  },
  {
    "text": "applications inside of uh Docker inside",
    "start": "135040",
    "end": "137640"
  },
  {
    "text": "of kubernetes inside of pman on any",
    "start": "137640",
    "end": "140000"
  },
  {
    "text": "other runtime that supports uh container",
    "start": "140000",
    "end": "142080"
  },
  {
    "text": "shims powered by",
    "start": "142080",
    "end": "144040"
  },
  {
    "text": "vum and we'll not talk specifically",
    "start": "144040",
    "end": "146519"
  },
  {
    "text": "about llama Edge so llama Edge has been",
    "start": "146519",
    "end": "148760"
  },
  {
    "text": "built on top of oich so it's a",
    "start": "148760",
    "end": "151360"
  },
  {
    "text": "customized runtime that allows you to",
    "start": "151360",
    "end": "153360"
  },
  {
    "text": "run web assembly uh web assembly",
    "start": "153360",
    "end": "154920"
  },
  {
    "text": "workloads and specifically AI powered",
    "start": "154920",
    "end": "156760"
  },
  {
    "text": "workloads on the edge or locally as well",
    "start": "156760",
    "end": "159760"
  },
  {
    "text": "uh it provides you an openai compatible",
    "start": "159760",
    "end": "161879"
  },
  {
    "text": "server so you no need to now use openai",
    "start": "161879",
    "end": "164959"
  },
  {
    "text": "to uh you know and manage multiples of",
    "start": "164959",
    "end": "167680"
  },
  {
    "text": "thousands of dollars of requests and",
    "start": "167680",
    "end": "169440"
  },
  {
    "text": "deal with the privacy concerns that you",
    "start": "169440",
    "end": "171720"
  },
  {
    "text": "typically have when you're using any of",
    "start": "171720",
    "end": "173480"
  },
  {
    "text": "these uh Cloud hosted models you can run",
    "start": "173480",
    "end": "175720"
  },
  {
    "text": "all of that locally and if your if your",
    "start": "175720",
    "end": "177720"
  },
  {
    "text": "infrastructure was supporting open aai",
    "start": "177720",
    "end": "179840"
  },
  {
    "text": "apis you can very easily just replace it",
    "start": "179840",
    "end": "182200"
  },
  {
    "text": "with the help of Lama Edge and you can",
    "start": "182200",
    "end": "184319"
  },
  {
    "text": "use rust or JavaScript to actually",
    "start": "184319",
    "end": "186440"
  },
  {
    "text": "extend these components and the as I",
    "start": "186440",
    "end": "188920"
  },
  {
    "text": "mentioned that the developer experience",
    "start": "188920",
    "end": "190360"
  },
  {
    "text": "will match very similar to how you will",
    "start": "190360",
    "end": "192519"
  },
  {
    "text": "have with openi but without the concern",
    "start": "192519",
    "end": "194319"
  },
  {
    "text": "of running it in the cloud all of this",
    "start": "194319",
    "end": "196480"
  },
  {
    "text": "will run and execute directly inside of",
    "start": "196480",
    "end": "199200"
  },
  {
    "text": "your system hardware and of course this",
    "start": "199200",
    "end": "201599"
  },
  {
    "text": "is based on the vet project from Linux",
    "start": "201599",
    "end": "203599"
  },
  {
    "text": "foundation so you can check it out on",
    "start": "203599",
    "end": "205360"
  },
  {
    "text": "github.com Lads comma comma Lads uh so",
    "start": "205360",
    "end": "209480"
  },
  {
    "text": "some of the major features right so we",
    "start": "209480",
    "end": "211120"
  },
  {
    "text": "spoke about the containers now container",
    "start": "211120",
    "end": "213159"
  },
  {
    "text": "run times for Python and shipping it",
    "start": "213159",
    "end": "215560"
  },
  {
    "text": "with py can be easily hundreds and",
    "start": "215560",
    "end": "217920"
  },
  {
    "text": "thousands of megabytes in size so these",
    "start": "217920",
    "end": "220480"
  },
  {
    "text": "containers when you're running them",
    "start": "220480",
    "end": "221519"
  },
  {
    "text": "inside of llama EDS or any other llm",
    "start": "221519",
    "end": "223760"
  },
  {
    "text": "model for example Lama 3 or M it",
    "start": "223760",
    "end": "226159"
  },
  {
    "text": "supports all of the open source machine",
    "start": "226159",
    "end": "228080"
  },
  {
    "text": "learning models and llms as well so it",
    "start": "228080",
    "end": "230680"
  },
  {
    "text": "has less than 50 megabytes in size as I",
    "start": "230680",
    "end": "233040"
  },
  {
    "text": "mentioned no python dependencies so it's",
    "start": "233040",
    "end": "234640"
  },
  {
    "text": "super quick you can deploy it on",
    "start": "234640",
    "end": "236799"
  },
  {
    "text": "different types of gpus without having",
    "start": "236799",
    "end": "238840"
  },
  {
    "text": "to worry about what run time you're",
    "start": "238840",
    "end": "240519"
  },
  {
    "text": "running it on and of course you can also",
    "start": "240519",
    "end": "242000"
  },
  {
    "text": "run it on edge right so x64 x86",
    "start": "242000",
    "end": "244879"
  },
  {
    "text": "architecture you can run it anywhere uh",
    "start": "244879",
    "end": "247120"
  },
  {
    "text": "and it provides you wi variety of uh AI",
    "start": "247120",
    "end": "249680"
  },
  {
    "text": "models that you can use open source",
    "start": "249680",
    "end": "251360"
  },
  {
    "text": "models and it's highly uh embeddable as",
    "start": "251360",
    "end": "254280"
  },
  {
    "text": "well and you can run it on cloud native",
    "start": "254280",
    "end": "256280"
  },
  {
    "text": "and many other such kind of cloud native",
    "start": "256280",
    "end": "258799"
  },
  {
    "text": "distributions as well and of course",
    "start": "258799",
    "end": "261280"
  },
  {
    "text": "there are a lot of different agentic AI",
    "start": "261280",
    "end": "262880"
  },
  {
    "text": "use cases as well so of course we are",
    "start": "262880",
    "end": "264759"
  },
  {
    "text": "now moving not just from llms but also",
    "start": "264759",
    "end": "267320"
  },
  {
    "text": "creating AI agents so here are some of",
    "start": "267320",
    "end": "269560"
  },
  {
    "text": "the examples uh like uh agentic video",
    "start": "269560",
    "end": "272400"
  },
  {
    "text": "translation where you basically record",
    "start": "272400",
    "end": "275039"
  },
  {
    "text": "the video and the AI agent understands",
    "start": "275039",
    "end": "277680"
  },
  {
    "text": "what's actually happening in the video",
    "start": "277680",
    "end": "279280"
  },
  {
    "text": "and it gives certain suggestions so",
    "start": "279280",
    "end": "281240"
  },
  {
    "text": "there are some other use cases um which",
    "start": "281240",
    "end": "283880"
  },
  {
    "text": "you can explore in these slides which",
    "start": "283880",
    "end": "286160"
  },
  {
    "text": "all will also be available for you uh",
    "start": "286160",
    "end": "288560"
  },
  {
    "text": "lastly in the end feel free to",
    "start": "288560",
    "end": "290160"
  },
  {
    "text": "contribute it's completely open source",
    "start": "290160",
    "end": "291759"
  },
  {
    "text": "it's part of the cncf and we are having",
    "start": "291759",
    "end": "294120"
  },
  {
    "text": "a vet Booth today at the project",
    "start": "294120",
    "end": "296520"
  },
  {
    "text": "showcase so feel free to drop by table",
    "start": "296520",
    "end": "298560"
  },
  {
    "text": "number three I'll be there from the vet",
    "start": "298560",
    "end": "300600"
  },
  {
    "text": "Community uh so if you want to have more",
    "start": "300600",
    "end": "302840"
  },
  {
    "text": "interesting discussions around AI around",
    "start": "302840",
    "end": "305120"
  },
  {
    "text": "uh agentic Ai and how you can leverage",
    "start": "305120",
    "end": "307400"
  },
  {
    "text": "uh web assembly for running these",
    "start": "307400",
    "end": "309000"
  },
  {
    "text": "workloads in production U I have a lot",
    "start": "309000",
    "end": "311639"
  },
  {
    "text": "of great production use case stories to",
    "start": "311639",
    "end": "313919"
  },
  {
    "text": "also share with all of you so thank you",
    "start": "313919",
    "end": "315479"
  },
  {
    "text": "so much um I'll be looking forward to",
    "start": "315479",
    "end": "317479"
  },
  {
    "text": "meeting all of you at the booth",
    "start": "317479",
    "end": "321360"
  }
]
[
  {
    "start": "0",
    "end": "96000"
  },
  {
    "text": "good morning everyone who just went actually to the keynotes who made it there Wow okay half about cool all right",
    "start": "30",
    "end": "9389"
  },
  {
    "text": "so this is a 90 minute session it's combined intro and deep dive session for",
    "start": "9389",
    "end": "15809"
  },
  {
    "text": "the Prometheus monitoring system so the first half I'm just going to give a",
    "start": "15809",
    "end": "20900"
  },
  {
    "text": "complete introductory beginners talk to what is Prometheus how does it work why is it awesome and the second half of the",
    "start": "20900",
    "end": "28170"
  },
  {
    "text": "talk is really just completely free form Prometheus maintainer z' being asked any",
    "start": "28170",
    "end": "34640"
  },
  {
    "text": "questions by you which will be led by Richard after me so in about like 30 or",
    "start": "34640",
    "end": "40920"
  },
  {
    "text": "40 minutes alright so I am Julius I'm the one of the cofounders of the",
    "start": "40920",
    "end": "47010"
  },
  {
    "text": "Prometheus monitoring systems and nowadays I just freelance around it I help companies use it do training",
    "start": "47010",
    "end": "53730"
  },
  {
    "text": "software development around it and so on so let's start with you know what",
    "start": "53730",
    "end": "59250"
  },
  {
    "text": "prometheus actually is Prometheus is a whole stack for monitoring and alerting",
    "start": "59250",
    "end": "65010"
  },
  {
    "text": "that is based around metrics aka a time series and we aim to give you like all",
    "start": "65010",
    "end": "71400"
  },
  {
    "text": "the tools for that like getting metrics out of the things you care about collecting them and then doing useful",
    "start": "71400",
    "end": "76860"
  },
  {
    "text": "things with those metrics so alerting graphing and also digging around in the",
    "start": "76860",
    "end": "84630"
  },
  {
    "text": "data on a more ad hoc basis Prometheus was especially made for dynamic",
    "start": "84630",
    "end": "90060"
  },
  {
    "text": "environments like kubernetes even though kubernetes that didn't even exist yet when we created Prometheus we explicitly",
    "start": "90060",
    "end": "98520"
  },
  {
    "text": "do not do some other things so we try to keep the scope of Prometheus fairly",
    "start": "98520",
    "end": "104369"
  },
  {
    "text": "limited and simple we don't do logging or tracing we only do numeric time series data where you",
    "start": "104369",
    "end": "111119"
  },
  {
    "text": "have individual values that have some kind of development over time for logging which you still want to have as",
    "start": "111119",
    "end": "117360"
  },
  {
    "text": "well you might use a system like Loki or elasticsearch for tracing maybe you'll use Jaeger or Zipkin we give you a way",
    "start": "117360",
    "end": "126390"
  },
  {
    "text": "to define alerting rules that can be maybe very complex but they're always explicit and you have to define what",
    "start": "126390",
    "end": "132120"
  },
  {
    "text": "means what a bad condition actually means so the system doesn't do any kind of",
    "start": "132120",
    "end": "137680"
  },
  {
    "text": "automatic anomaly detection just squinting at your data and kind of guessing that something might be wrong",
    "start": "137680",
    "end": "144540"
  },
  {
    "text": "Prometheus itself also only has a local on disk storage which is naturally",
    "start": "144540",
    "end": "149890"
  },
  {
    "text": "somewhat limited in its scalability and durability because it's a single node system and there's no built-in",
    "start": "149890",
    "end": "156900"
  },
  {
    "text": "replication so we'll talk about long-term storage and scalability tiny",
    "start": "156900",
    "end": "164140"
  },
  {
    "text": "bit more later there's ways to do that but it's not part of Prometheus itself",
    "start": "164140",
    "end": "170040"
  },
  {
    "start": "169000",
    "end": "234000"
  },
  {
    "text": "Prometheus started in 2012 at sound clouds that was when both I and Matt",
    "start": "170129",
    "end": "175810"
  },
  {
    "text": "kind of came from Google and tried to make sound clock more stable and back",
    "start": "175810",
    "end": "181200"
  },
  {
    "text": "already had a cluster scheduler before darker even existent so obviously no",
    "start": "181200",
    "end": "186549"
  },
  {
    "text": "kubernetes yet no Griffin I yet know none of these fancy tools and the OP the",
    "start": "186549",
    "end": "192190"
  },
  {
    "text": "open source monitoring tools back then weren't really suitable for making sense of dynamic cluster scheduling with",
    "start": "192190",
    "end": "200650"
  },
  {
    "text": "containers floating around and all that so this led to the birth of Prometheus it was open source from day 0 but we",
    "start": "200650",
    "end": "208780"
  },
  {
    "text": "only really published it in 2015 and then in 2016 it became the second member",
    "start": "208780",
    "end": "216519"
  },
  {
    "text": "project of the cloud native computing foundation which is hosting this conference here today after kubernetes",
    "start": "216519",
    "end": "222549"
  },
  {
    "text": "and you can find us at Prometheus i/o if you go to slash community you'll also",
    "start": "222549",
    "end": "227799"
  },
  {
    "text": "find ways to get help and become a contributor which would be extra awesome",
    "start": "227799",
    "end": "234389"
  },
  {
    "start": "234000",
    "end": "527000"
  },
  {
    "text": "so let's have a look at the basic system architecture of what you know how",
    "start": "234629",
    "end": "239769"
  },
  {
    "text": "Prometheus works and what it allows you to do first of all we want you to be",
    "start": "239769",
    "end": "244930"
  },
  {
    "text": "able to get metrics out of the things you care about and the things you care about can be different things for",
    "start": "244930",
    "end": "250000"
  },
  {
    "text": "example they might be applications services running in your cluster where",
    "start": "250000",
    "end": "255010"
  },
  {
    "text": "you control the code your own web api server etc etc in those examples the",
    "start": "255010",
    "end": "260739"
  },
  {
    "text": "best thing to do is really just take a Prometheus client library included into your process",
    "start": "260739",
    "end": "266500"
  },
  {
    "text": "and use it for two things to track metrics counters histograms gauges",
    "start": "266500",
    "end": "271930"
  },
  {
    "text": "summaries basically just keeping keeping track of internal metric state and then",
    "start": "271930",
    "end": "278380"
  },
  {
    "text": "the second part is exposing that over an HTTP endpoint because Prometheus is a",
    "start": "278380",
    "end": "284140"
  },
  {
    "text": "pull based monitoring system and expects to be able to go to your instance and ask it about the current value of all",
    "start": "284140",
    "end": "291580"
  },
  {
    "text": "its time series that it is tracking now you might have some stuff where you",
    "start": "291580",
    "end": "297550"
  },
  {
    "text": "cannot directly add stuff at Prometheus metrics to the code itself like a Linux",
    "start": "297550",
    "end": "303160"
  },
  {
    "text": "virtual machine or my sequel daemon or the cgroups container information on a machine and there's many many of these",
    "start": "303160",
    "end": "309910"
  },
  {
    "text": "existing systems where you will not be able to add directly a previous endpoint",
    "start": "309910",
    "end": "314950"
  },
  {
    "text": "so for this we have the concept of an exporter which you run as a sidecar next",
    "start": "314950",
    "end": "321460"
  },
  {
    "text": "to the thing you want to measure and then Prometheus just talks to the exporter and the exporter gets the",
    "start": "321460",
    "end": "328090"
  },
  {
    "text": "metrics in the backend in whatever third party format that is and translates them",
    "start": "328090",
    "end": "333370"
  },
  {
    "text": "back to promises server to the promises format so finally we add a Prometheus",
    "start": "333370",
    "end": "340090"
  },
  {
    "text": "server the Prometheus server is the heart of the parameters ecosystem obviously you configure it to pull on a",
    "start": "340090",
    "end": "348070"
  },
  {
    "text": "periodic basis it's like every 15 seconds every 30 seconds are for example common values to pull metrics from all",
    "start": "348070",
    "end": "356110"
  },
  {
    "text": "the targets that are configured in it and then it stores those over time as",
    "start": "356110",
    "end": "361510"
  },
  {
    "text": "time series so just a quick interview what do we actually transfer on these",
    "start": "361510",
    "end": "368410"
  },
  {
    "text": "arrows here what does that format look like it just looks like this without the",
    "start": "368410",
    "end": "373750"
  },
  {
    "text": "colors of course but the colors make it more readable it's really just a text-based format that we defined in",
    "start": "373750",
    "end": "380200"
  },
  {
    "text": "Prometheus where every time series has a single sample it's just the current value of each time series that is being",
    "start": "380200",
    "end": "386860"
  },
  {
    "text": "sent at that moment in time and so this is really really dead simple to generate",
    "start": "386860",
    "end": "392710"
  },
  {
    "text": "from even a bash script if you need to but if you are in a more higher level programming language you might use",
    "start": "392710",
    "end": "398460"
  },
  {
    "text": "one of our client libraries to do proper tracking and exposition so the hurdle to",
    "start": "398460",
    "end": "403560"
  },
  {
    "text": "get metrics out of things you care about is actually pretty low as long as you can pull we'll talk about the data model",
    "start": "403560",
    "end": "410100"
  },
  {
    "text": "a bit more later okay cool so now we have the parameter server it stores it",
    "start": "410100",
    "end": "416220"
  },
  {
    "text": "in a very highly efficient times use database and then you might be wondering",
    "start": "416220",
    "end": "422430"
  },
  {
    "text": "well how does Prometheus actually know where all these targets are we don't",
    "start": "422430",
    "end": "427830"
  },
  {
    "text": "require you to statically configure each one of your kubernetes pods for example obviously Prometheus integrates with",
    "start": "427830",
    "end": "435270"
  },
  {
    "text": "different service discovery mechanisms to allow you to do that and automatically discover what is out there",
    "start": "435270",
    "end": "442760"
  },
  {
    "text": "finally to do useful stuff with the data we for example grow fauna you know the",
    "start": "443360",
    "end": "448590"
  },
  {
    "text": "most popular dashboard builder has native support for Prometheus as a graphing back-end you can use primitives",
    "start": "448590",
    "end": "454500"
  },
  {
    "text": "web UI to dig around in the data yourself or just build any kind of",
    "start": "454500",
    "end": "460110"
  },
  {
    "text": "automation against Prometheus's HTTP API yourself as well then Prometheus itself",
    "start": "460110",
    "end": "467220"
  },
  {
    "text": "in the server you can configure some alerting rules which Prometheus will periodically evaluate on the collected",
    "start": "467220",
    "end": "473760"
  },
  {
    "text": "data to determine if anything is wrong and if something is wrong it sends alerts to another component called the",
    "start": "473760",
    "end": "480690"
  },
  {
    "text": "alert manager and the alert manager aggregates alerts over time and across",
    "start": "480690",
    "end": "485849"
  },
  {
    "text": "dimensions and kind of groups them together and then sends actual notifications to email pager duty Ops",
    "start": "485849",
    "end": "492990"
  },
  {
    "text": "teeny and a couple of other mechanisms you can build your own as well and so this is just the basic architecture and",
    "start": "492990",
    "end": "499590"
  },
  {
    "text": "then you have like many of these different exporters and integrations and stuff that is built around it basically",
    "start": "499590",
    "end": "506030"
  },
  {
    "text": "typically you have many Prometheus servers in your organization because these are you know the individual server",
    "start": "506030",
    "end": "512219"
  },
  {
    "text": "is not a horizontally scalable thing so you know you might chart them by function or you can build trees that",
    "start": "512219",
    "end": "519390"
  },
  {
    "text": "form yeah like a hierarchical topology to achieve different scaling goals so",
    "start": "519390",
    "end": "529290"
  },
  {
    "start": "527000",
    "end": "561000"
  },
  {
    "text": "the for these four points our 4 major reasons why I think primitives was successful especially",
    "start": "529290",
    "end": "536540"
  },
  {
    "text": "back then nowadays maybe they're not even so special anymore but I think in 2015 when we released it they were a bit",
    "start": "536540",
    "end": "543830"
  },
  {
    "text": "more so you know a data model that's dimensional then a query language that goes along with it to do powerful things",
    "start": "543830",
    "end": "550900"
  },
  {
    "text": "the simplicity and efficiency of a single parameter server and then integrating with service discovery to",
    "start": "550900",
    "end": "557630"
  },
  {
    "text": "make parameters work in the net in dynamic environments first the data",
    "start": "557630",
    "end": "563090"
  },
  {
    "start": "561000",
    "end": "694000"
  },
  {
    "text": "model so I'll go through these four points in detail Prometheus fundamentally tracks time series so",
    "start": "563090",
    "end": "570350"
  },
  {
    "text": "these are values over time where the identifier stays the same for example the identifier on an",
    "start": "570350",
    "end": "575990"
  },
  {
    "text": "abstract level might be something like the temperature in this room versus the temperature in the other room right and",
    "start": "575990",
    "end": "581360"
  },
  {
    "text": "we just want to kind of track the same thing but over time how it develops and",
    "start": "581360",
    "end": "586510"
  },
  {
    "text": "for tracking that over time we add timestamp value pairs which we call",
    "start": "586510",
    "end": "592130"
  },
  {
    "text": "samples that belong to the time series timestamps in Prometheus are always in",
    "start": "592130",
    "end": "600020"
  },
  {
    "text": "64 keep it simple there are basically millisecond UNIX timestamps the sample values also only",
    "start": "600020",
    "end": "607850"
  },
  {
    "text": "can have a single type which is always float 64 which works remarkably well for",
    "start": "607850",
    "end": "613010"
  },
  {
    "text": "systems monitoring use cases and then the big question is here what's the identifier like how do we identify time",
    "start": "613010",
    "end": "619550"
  },
  {
    "text": "series because this will inform how we search and query for metrics we decided",
    "start": "619550",
    "end": "627020"
  },
  {
    "text": "to go for a dimensional key value based model where we start with a metric name",
    "start": "627020",
    "end": "633500"
  },
  {
    "text": "at the beginning this is just the name of the aspect of a system we are monitoring in this case this is a",
    "start": "633500",
    "end": "640100"
  },
  {
    "text": "counter metric how many HTTP requests has a server handled since process start",
    "start": "640100",
    "end": "646280"
  },
  {
    "text": "up it just goes up and up and up and now we want to sub differentiate certain dimensions in there like was it what was",
    "start": "646280",
    "end": "652670"
  },
  {
    "text": "the path of the requests the status code etc etc so these we just attach as what",
    "start": "652670",
    "end": "658670"
  },
  {
    "text": "we call labels key value pairs and this data model is pretty flexible it",
    "start": "658670",
    "end": "665410"
  },
  {
    "text": "avoids having a higher key as we had in earlier monitoring systems like graphite",
    "start": "665410",
    "end": "671470"
  },
  {
    "text": "or stats D where the metric name is somewhat akin to a path name with higher",
    "start": "671470",
    "end": "678009"
  },
  {
    "text": "key components and then often you know if you add a new dimension you're not sure where in the hierarchy would wanna",
    "start": "678009",
    "end": "684309"
  },
  {
    "text": "stick it which component has which meaning so this is a bit more flexible",
    "start": "684309",
    "end": "689559"
  },
  {
    "text": "and explicit and useful in queries so",
    "start": "689559",
    "end": "694629"
  },
  {
    "start": "694000",
    "end": "722000"
  },
  {
    "text": "now to make use of this Prometheus comes with its own new query language that's",
    "start": "694629",
    "end": "699819"
  },
  {
    "text": "called prong QL the Prometheus query language it's explicitly not a sequel style language because sequel star",
    "start": "699819",
    "end": "707799"
  },
  {
    "text": "languages tend to be a bit obtuse when trying to do time series operations so prompt QL is especially optimized to",
    "start": "707799",
    "end": "714459"
  },
  {
    "text": "having a 16th way of expressing the typical computations we want to do with time series in the systems monitoring",
    "start": "714459",
    "end": "720879"
  },
  {
    "text": "context here's some examples imagine you're running this one exporter that we",
    "start": "720879",
    "end": "728110"
  },
  {
    "text": "have it's called the node exporter it runs on every linux node that you have or unix node and it gives you machine",
    "start": "728110",
    "end": "734529"
  },
  {
    "text": "metrics for example the total size of every filesystem in your infrastructure",
    "start": "734529",
    "end": "740910"
  },
  {
    "text": "and now you want to know well you know give me all the partitions that are larger than 100 gigabytes in my",
    "start": "740910",
    "end": "746679"
  },
  {
    "text": "infrastructure but that that are not mounted on the root amount point you might just start with a metric name then",
    "start": "746679",
    "end": "753189"
  },
  {
    "text": "filter down with a negative matcher basically saying give me only the x views that belong not to the route mount",
    "start": "753189",
    "end": "759939"
  },
  {
    "text": "point then divide all those values by a billion to get from bytes to gigabytes and then filter the time series by a",
    "start": "759939",
    "end": "766869"
  },
  {
    "text": "hundred to only get the ones that are larger than 100 gigabytes and as an output set you'll not get a single",
    "start": "766869",
    "end": "773110"
  },
  {
    "text": "number you get a whole set of results computer time series with labels on them",
    "start": "773110",
    "end": "779139"
  },
  {
    "text": "so you know where which partitions are which are larger than this another",
    "start": "779139",
    "end": "785109"
  },
  {
    "text": "common thing you might want to do is calculate request error rate ratios so",
    "start": "785109",
    "end": "790149"
  },
  {
    "text": "like how many errors are you getting in comparison to the total number of requests for this you could take the",
    "start": "790149",
    "end": "795789"
  },
  {
    "text": "purse and rate of the 500 status code requests and divided here's here's a division",
    "start": "795789",
    "end": "801790"
  },
  {
    "text": "operator so this is all one expression divided by the total number of requests",
    "start": "801790",
    "end": "807670"
  },
  {
    "text": "so the request rate of that and this would give you ratio a single number bit",
    "start": "807670",
    "end": "814450"
  },
  {
    "text": "boring sometimes you might want to preserve some dimensions like the path give me this ratio for every path in my",
    "start": "814450",
    "end": "820510"
  },
  {
    "text": "web application for that you just add a modifier to the some aggregator and then",
    "start": "820510",
    "end": "826510"
  },
  {
    "text": "it preserves some dimensions and now is where magic actually starts happening because you're no longer dividing one",
    "start": "826510",
    "end": "832450"
  },
  {
    "text": "number by another number you're dividing a whole set of numbers by a whole other set of numbers on the left on the right",
    "start": "832450",
    "end": "838750"
  },
  {
    "text": "hand side and prom KL automatically joins these sets of time series based on",
    "start": "838750",
    "end": "845470"
  },
  {
    "text": "identical label sets so it will divide the error rate for one path by the total",
    "start": "845470",
    "end": "851589"
  },
  {
    "text": "rate for that same path and propagate that as an equally labeled element into the output so this whole label based",
    "start": "851589",
    "end": "858180"
  },
  {
    "text": "automatic joining is really powerful and there's no more complex ways of doing",
    "start": "858180",
    "end": "863620"
  },
  {
    "text": "this if labels don't exactly match up on both sides just another example won't go",
    "start": "863620",
    "end": "870430"
  },
  {
    "text": "really into this but we allow you to for example track latency distributions in a",
    "start": "870430",
    "end": "876010"
  },
  {
    "text": "histogram metric and then have a preview language function which allows you to say hey I want to calculate the 99th",
    "start": "876010",
    "end": "882160"
  },
  {
    "text": "quant the 99th percentile from the cystogram over all of my instances so I",
    "start": "882160",
    "end": "888190"
  },
  {
    "text": "want to aggregate away the instance time engine and I wanted average that over five minutes this is what this",
    "start": "888190",
    "end": "893500"
  },
  {
    "text": "expression does and then you get you know for all your paths and all your methods you get the 99th percentile",
    "start": "893500",
    "end": "899800"
  },
  {
    "text": "latency as an estimate now if you learned that language which admittedly",
    "start": "899800",
    "end": "906160"
  },
  {
    "start": "903000",
    "end": "987000"
  },
  {
    "text": "can warp your brain a bit at the beginning but then becomes really useful you can start using it either in the",
    "start": "906160",
    "end": "911440"
  },
  {
    "text": "built-in expression browser or even graph those expressions over time but",
    "start": "911440",
    "end": "918520"
  },
  {
    "text": "this is not really good for building persistent dashboards with all the dashboarding features that you used to so for that just use go use go Phenom it",
    "start": "918520",
    "end": "928750"
  },
  {
    "text": "has native Prometheus now really cool thing is alerting and how it integrates with this language in",
    "start": "928750",
    "end": "937280"
  },
  {
    "text": "a unified way so alerting is no longer a separate system that just runs check",
    "start": "937280",
    "end": "942500"
  },
  {
    "text": "scripts somewhere on hosts first like the the whole idea of primitives is you collect anything you can imagine as a",
    "start": "942500",
    "end": "948800"
  },
  {
    "text": "metric first if it's just like a boolean value 0 1 or 2 or it can enum because",
    "start": "948800",
    "end": "956090"
  },
  {
    "text": "that is stored read efficiently and then you define alerting rules based on the collected data so in this example I took",
    "start": "956090",
    "end": "961790"
  },
  {
    "text": "an expression that we had earlier which gives us the error rate ratio for every",
    "start": "961790",
    "end": "967250"
  },
  {
    "text": "path we multiply it by a hundred to get to a percentage and we filter it by five",
    "start": "967250",
    "end": "973250"
  },
  {
    "text": "to get all the paths that have an error rate ratio higher than 5% and so this would really give you an alert for every",
    "start": "973250",
    "end": "980060"
  },
  {
    "text": "path that is currently misbehaving and yeah this can get way more complex as",
    "start": "980060",
    "end": "985310"
  },
  {
    "text": "well Third Point operational simplicity",
    "start": "985310",
    "end": "992110"
  },
  {
    "start": "987000",
    "end": "1025000"
  },
  {
    "text": "you know Prometheus as a single binary service and single node service is",
    "start": "992110",
    "end": "997820"
  },
  {
    "text": "pretty easy to get started with it only needs a small configuration file it puts its local data on disk and off you go",
    "start": "997820",
    "end": "1004890"
  },
  {
    "text": "you can get high availability for the purpose of alerting by just running two identical primitive servers which pull",
    "start": "1004890",
    "end": "1011800"
  },
  {
    "text": "the same data so they know nothing about each other they're not a cluster they just do the same thing they ingest the",
    "start": "1011800",
    "end": "1018280"
  },
  {
    "text": "same data generate the same alerts alert manager we'll d-do Platt for you and it's written in go a single server if",
    "start": "1018280",
    "end": "1027310"
  },
  {
    "start": "1025000",
    "end": "1070000"
  },
  {
    "text": "it's really beefy one can also do quite a lot obviously it's not infinitely horizontally scalable but it can do in",
    "start": "1027310",
    "end": "1034180"
  },
  {
    "text": "the lower number of millions of series if you really really overdo it you might be able to get like a million plus",
    "start": "1034180",
    "end": "1039370"
  },
  {
    "text": "samples on ingestion per second and the storage on disk of each time series",
    "start": "1039370",
    "end": "1044980"
  },
  {
    "text": "ample is also really efficient about like 1 to 2 bytes per sample so the local storage is really only meant as an",
    "start": "1044980",
    "end": "1051940"
  },
  {
    "text": "ephemeral window of data that you keep maybe 4 weeks maybe 4 months some people",
    "start": "1051940",
    "end": "1059200"
  },
  {
    "text": "like this guy who's currently looking in his phone Richie he's like keeping years in there and we tell them well that's not really",
    "start": "1059200",
    "end": "1065860"
  },
  {
    "text": "what it's designed for so there are ways",
    "start": "1065860",
    "end": "1071650"
  },
  {
    "start": "1070000",
    "end": "1109000"
  },
  {
    "text": "of you know keep sending parameters data to a remote system that can keep it for longer or do other stuff with it for",
    "start": "1071650",
    "end": "1077920"
  },
  {
    "text": "example we have this remote right protocol in Prometheus where you can configure just on URL endpoint and",
    "start": "1077920",
    "end": "1083410"
  },
  {
    "text": "parameters saying hey Prometheus whatever you scrape also forwarded to some other endpoint and that other",
    "start": "1083410",
    "end": "1089140"
  },
  {
    "text": "endpoint just needs to implement our protocol and can then do anything with it so either it natively supports that",
    "start": "1089140",
    "end": "1095770"
  },
  {
    "text": "like cortex or in flux DB which can directly receive this format and store the data forever or you can have any",
    "start": "1095770",
    "end": "1102940"
  },
  {
    "text": "kind of database or stream processor and put a little adapter in front of it that converts or another thing I really like",
    "start": "1102940",
    "end": "1111640"
  },
  {
    "start": "1109000",
    "end": "1182000"
  },
  {
    "text": "is the nose who has heard of Thanos okay you should all hear of Thanos this was",
    "start": "1111640",
    "end": "1117700"
  },
  {
    "text": "only like one-sixth of people or so Thanos was also built by people who are",
    "start": "1117700",
    "end": "1123309"
  },
  {
    "text": "like both core Prometheus people and had another need basically you know getting",
    "start": "1123309",
    "end": "1128679"
  },
  {
    "text": "a unified view that's long term storage unified view with durability over",
    "start": "1128679",
    "end": "1134169"
  },
  {
    "text": "multiple parameters servers in your organization this works a bit differently than the remote write",
    "start": "1134169",
    "end": "1139660"
  },
  {
    "text": "pattern that I showed before basically you add Thanos sidecar to all of your",
    "start": "1139660",
    "end": "1144669"
  },
  {
    "text": "existing chrome easy service you can keep the Medes and then Thanos kind of watches the disk for any completed TS DB",
    "start": "1144669",
    "end": "1151270"
  },
  {
    "text": "time series database blocks and ships them off to some long-term storage this could be s3 GCS or something you host",
    "start": "1151270",
    "end": "1159429"
  },
  {
    "text": "you're on your own some object storage and then you can just point Ravana at the Stannis query component which",
    "start": "1159429",
    "end": "1165549"
  },
  {
    "text": "integrates data from long-term storage with the short term data from your life through meters instances and then has",
    "start": "1165549",
    "end": "1172120"
  },
  {
    "text": "some magic for actually also if you have an H a pair of primitives to only show you the data from one in a consistent",
    "start": "1172120",
    "end": "1178000"
  },
  {
    "text": "way and so on so it's really cool last",
    "start": "1178000",
    "end": "1183700"
  },
  {
    "start": "1182000",
    "end": "1212000"
  },
  {
    "text": "point of the selling points of Prometheus is how it works with dynamic environments so the old world was static",
    "start": "1183700",
    "end": "1191230"
  },
  {
    "text": "for a long time now it hasn't been anymore first came dynamic VMs then we put cluster schedulers like who",
    "start": "1191230",
    "end": "1197530"
  },
  {
    "text": "it's on top and we have microservices on top of that so things are moving really quickly and automatically and so on so",
    "start": "1197530",
    "end": "1205960"
  },
  {
    "text": "like how old does a monitoring system still make sense of what is supposed to be where our answer obviously is service",
    "start": "1205960",
    "end": "1214540"
  },
  {
    "start": "1212000",
    "end": "1300000"
  },
  {
    "text": "discovery in three different ways here so Prometheus uses service discovery for",
    "start": "1214540",
    "end": "1223750"
  },
  {
    "text": "three different purposes that are related but different the first is really your monitoring system should",
    "start": "1223750",
    "end": "1230050"
  },
  {
    "text": "know what is supposed to be where with some push based monitoring systems they",
    "start": "1230050",
    "end": "1235270"
  },
  {
    "text": "kind of receive data from whatever sending data but they don't really know if someone should report in but isn't so",
    "start": "1235270",
    "end": "1243180"
  },
  {
    "text": "that's the first purpose then the second one is the service discovery information",
    "start": "1243180",
    "end": "1248500"
  },
  {
    "text": "usually gives you technical information for how to actually reach a target and pull metrics from it otherwise you",
    "start": "1248500",
    "end": "1256450"
  },
  {
    "text": "cannot do your job the third one is if it's a good service discovery mechanism like the one in kubernetes through the",
    "start": "1256450",
    "end": "1263200"
  },
  {
    "text": "API server it will give you metadata about the target that you have discovered and that you're scraping for",
    "start": "1263200",
    "end": "1268660"
  },
  {
    "text": "example it will tell you hey this is an engine X part of a certain other label",
    "start": "1268660",
    "end": "1274210"
  },
  {
    "text": "quality and so on and then parameters can map that into your time series data",
    "start": "1274210",
    "end": "1280080"
  },
  {
    "text": "Prometheus has built in discovery support for a bunch of cloud providers and clusters cluster managers and it",
    "start": "1280410",
    "end": "1287770"
  },
  {
    "text": "also has generic mechanisms like DNS consul and so on you can also build your own plugin based mechanism based on a",
    "start": "1287770",
    "end": "1294340"
  },
  {
    "text": "file watcher if the built-in ones are not sufficient so as a conclusion these",
    "start": "1294340",
    "end": "1303700"
  },
  {
    "start": "1300000",
    "end": "1316000"
  },
  {
    "text": "for selling points really help make Prometheus a suitable fit for the cloud",
    "start": "1303700",
    "end": "1308800"
  },
  {
    "text": "native world and making sense of a lot of the data that happens there cool so I",
    "start": "1308800",
    "end": "1316950"
  },
  {
    "start": "1316000",
    "end": "1722000"
  },
  {
    "text": "briefly say thanks but then I immediately skip to the Prometheus deep",
    "start": "1316950",
    "end": "1322090"
  },
  {
    "text": "dive and open QA so spare your questions for that Ritchie is going to lead that",
    "start": "1322090",
    "end": "1328549"
  },
  {
    "text": "and I'll hand over to Ritchie okay",
    "start": "1328549",
    "end": "1358369"
  },
  {
    "text": "welcome anyone who is on primitives team for example Tom just come up here and",
    "start": "1358369",
    "end": "1365079"
  },
  {
    "text": "thanks to Europe for volunteering to do the McGuirk he didn't know he was",
    "start": "1365079",
    "end": "1372679"
  },
  {
    "text": "volunteering but he does know okay so once again this is open Q&A for",
    "start": "1372679",
    "end": "1379070"
  },
  {
    "text": "technical or whatever reasons we are required to call this deep dive but it's basically an open Q&A there are no",
    "start": "1379070",
    "end": "1386329"
  },
  {
    "text": "stupid questions so please any level of question you feel comfortable asking just ask them it's totally fine",
    "start": "1386329",
    "end": "1393349"
  },
  {
    "text": "we will then assign questions to whoever is standing here okay okay okay so",
    "start": "1393349",
    "end": "1417440"
  },
  {
    "text": "everyone else this is how we have to hold this thing course unfortunately since EF can only afford to mix per room",
    "start": "1417440",
    "end": "1423070"
  },
  {
    "text": "even though I complain every single year anyway yeah so we no way not the other",
    "start": "1423070",
    "end": "1431479"
  },
  {
    "text": "question so any any level of questions is fine please just whatever you want to ask ask it we only ask one thing don't",
    "start": "1431479",
    "end": "1440209"
  },
  {
    "text": "have like a lightning talk so it should be a real question it shouldn't be a statement of course that that basically",
    "start": "1440209",
    "end": "1446419"
  },
  {
    "text": "takes away from question time for everyone else we have roughly one hour left which is great and we hope to fill",
    "start": "1446419",
    "end": "1452629"
  },
  {
    "text": "this with stuff and also we will probably fill up with more parameters team as they as they come in here so",
    "start": "1452629",
    "end": "1458499"
  },
  {
    "text": "habit oh yeah intros good point",
    "start": "1458499",
    "end": "1463760"
  },
  {
    "text": "Roberts running around so intros Julius he's the co-founder of Prometheus we",
    "start": "1463760",
    "end": "1470360"
  },
  {
    "text": "have max he is well all of us as permits his team so I'm just doing the name's Julius volts max inland Richard Hartman",
    "start": "1470360",
    "end": "1477290"
  },
  {
    "text": "Bryan Brazil Tom Milky and Gotham it's colorful",
    "start": "1477290",
    "end": "1482330"
  },
  {
    "text": "I can't pronounce the name so yeah have",
    "start": "1482330",
    "end": "1487820"
  },
  {
    "text": "at it my question is about a problem I",
    "start": "1487820",
    "end": "1501230"
  },
  {
    "text": "face with positives you get data from a",
    "start": "1501230",
    "end": "1509420"
  },
  {
    "text": "node but this node was out of service for something like I don't know 20",
    "start": "1509420",
    "end": "1516020"
  },
  {
    "text": "minutes so you don't get any matrix from the node for 20 minutes so how can we",
    "start": "1516020",
    "end": "1521500"
  },
  {
    "text": "kind of deal with this all's when you make some things like some other time or",
    "start": "1521500",
    "end": "1527990"
  },
  {
    "text": "this kind of operation to get a consistent result",
    "start": "1527990",
    "end": "1533170"
  },
  {
    "text": "I hope my yeah so just make sure we understand the question is your question",
    "start": "1533170",
    "end": "1539270"
  },
  {
    "text": "if if connectivity to a node which should be scraped is going away how to not lose data from the point of view of",
    "start": "1539270",
    "end": "1546380"
  },
  {
    "text": "Prometheus during that outage is that the question yes is a kind of",
    "start": "1546380",
    "end": "1551390"
  },
  {
    "text": "normalization of the data into old - yes",
    "start": "1551390",
    "end": "1557270"
  },
  {
    "text": "this was my question my question was not very clear I'm sorry but it's out to deal with the old inside",
    "start": "1557270",
    "end": "1563840"
  },
  {
    "text": "a time sorry okay so if the question is",
    "start": "1563840",
    "end": "1570080"
  },
  {
    "text": "how to deal with outages and not being able to reach nodes which are up but not",
    "start": "1570080",
    "end": "1575630"
  },
  {
    "text": "seen by Prometheus you have to put a Prometheus in a place where it can be seen and very where you can see the",
    "start": "1575630",
    "end": "1582620"
  },
  {
    "text": "nodes so if you have this kind of issue it makes sense to have a paresis nearer to whatever your workload is maybe have",
    "start": "1582620",
    "end": "1587720"
  },
  {
    "text": "a local instance or whatever and then use remote read write or federación to get data to wherever you",
    "start": "1587720",
    "end": "1594920"
  },
  {
    "text": "need it that's more or less it of course we permit sees can't see the data it",
    "start": "1594920",
    "end": "1600920"
  },
  {
    "text": "can't really put it in we currently don't do backfilling yeah and generally",
    "start": "1600920",
    "end": "1606830"
  },
  {
    "text": "Prometheus takes the stance to gaps in data to just say like oh well you know you have a gap it's fine because",
    "start": "1606830",
    "end": "1612230"
  },
  {
    "text": "primitives is not the system that tries to keep a hundred percent of your data forever consistently it tries to tell",
    "start": "1612230",
    "end": "1618710"
  },
  {
    "text": "you like what is wrong right now and if I cannot reach your note at that moment like that's the main problem and we",
    "start": "1618710",
    "end": "1624740"
  },
  {
    "text": "don't care anymore like what are the actual metrics of that note you need to figure figure that out after getting alert for that",
    "start": "1624740",
    "end": "1631840"
  },
  {
    "text": "so a question on multi-tenancy how do you I know that you don't handle",
    "start": "1645679",
    "end": "1651360"
  },
  {
    "text": "multi-tenancy kind of in built-in primitives but what are your suggestions which add-ons or Achra services would",
    "start": "1651360",
    "end": "1660029"
  },
  {
    "text": "you use to build a multi-tenant prematures and probably also connected",
    "start": "1660029",
    "end": "1665159"
  },
  {
    "text": "to a multi-tenant graph honor I think if if Frederick was here he'd promote the Prometheus operator oh yeah",
    "start": "1665159",
    "end": "1673070"
  },
  {
    "text": "so we have been trying to solve that what is very helpful on Prometheus",
    "start": "1674570",
    "end": "1679740"
  },
  {
    "text": "itself is the crude language is not that complex so what you can do is you you",
    "start": "1679740",
    "end": "1686399"
  },
  {
    "text": "put a proxy in front of Prometheus they didn't force to certain tables and then you do you tendency based on certain",
    "start": "1686399",
    "end": "1693630"
  },
  {
    "text": "namespaces for example it's super common",
    "start": "1693630",
    "end": "1699330"
  },
  {
    "text": "to run multiple Prometheus's like a Prometheus per team my Prometheus is super lightweight like if you're in a",
    "start": "1699330",
    "end": "1705600"
  },
  {
    "text": "kubernetes environment having a Prometheus pen-name space is not a big deal so if you want to be multi-tenancy that",
    "start": "1705600",
    "end": "1711210"
  },
  {
    "text": "way the kubernetes prometheus operator makes it pretty easy to do that as far as I understand and then yeah you know",
    "start": "1711210",
    "end": "1717870"
  },
  {
    "text": "cortex does it just a nose have multi-tenancy they're working on it only I think last time I spoke to bar tech",
    "start": "1717870",
    "end": "1723450"
  },
  {
    "start": "1722000",
    "end": "1901000"
  },
  {
    "text": "about it panels there's ways of doing multi-tenancy and panels as well so there's a whole bunch of different ways yeah does that answer your question yeah",
    "start": "1723450",
    "end": "1730789"
  },
  {
    "text": "thank you and please yell into the",
    "start": "1730789",
    "end": "1742649"
  },
  {
    "text": "microphone because all of the speakers are facing the audience directions so we have like a hard time hearing hello",
    "start": "1742649",
    "end": "1750169"
  },
  {
    "text": "louder",
    "start": "1750169",
    "end": "1753169"
  },
  {
    "text": "I mean how does it work remote right what's the question about",
    "start": "1757490",
    "end": "1765690"
  },
  {
    "text": "your choice we have a hard time hearing anyone is it fine",
    "start": "1765690",
    "end": "1771559"
  },
  {
    "text": "okay so the it's more about the remote",
    "start": "1772239",
    "end": "1777769"
  },
  {
    "text": "right okay so you mentioned somewhere in the architectural diagram that you can transfer this data like Prometheus",
    "start": "1777769",
    "end": "1784159"
  },
  {
    "text": "generated data to some another adapter okay so through writing some remote",
    "start": "1784159",
    "end": "1790369"
  },
  {
    "text": "right so can you just expand more about that yeah sure so there's a remote write",
    "start": "1790369",
    "end": "1796779"
  },
  {
    "text": "protocol which is using proto buffers and snappy encoding in a HTTP body you",
    "start": "1796779",
    "end": "1803239"
  },
  {
    "text": "can set an end point in the Prometheus config that will tell Prometheus to send",
    "start": "1803239",
    "end": "1808369"
  },
  {
    "text": "the data it's scraping to somewhere right and then I mean there are tens of",
    "start": "1808369",
    "end": "1813889"
  },
  {
    "text": "people that have implemented this protocol on the server side to accept data so there's tens may be exact",
    "start": "1813889",
    "end": "1820220"
  },
  {
    "text": "exaggerating like Julius implemented an adaptive influx that then got merged into influx as far as I understand",
    "start": "1820220",
    "end": "1825769"
  },
  {
    "text": "there's one for open TS DB cortex accepts it victoria metrics was just",
    "start": "1825769",
    "end": "1831080"
  },
  {
    "text": "open source today that accepts it time scale accepts it like whole bunch of people except it's super easy especially",
    "start": "1831080",
    "end": "1837769"
  },
  {
    "text": "if the thing trying to accept it is written and go it can just vendor the remote write stuff from cortex as from",
    "start": "1837769",
    "end": "1845720"
  },
  {
    "text": "Prometheus one other thing to add is recently we rewrote the remote write API",
    "start": "1845720",
    "end": "1851710"
  },
  {
    "text": "spi I guess so now it actually tails the Prometheus right ahead log so it deals",
    "start": "1851710",
    "end": "1856999"
  },
  {
    "text": "really well now with network outages if there's a network outage Prometheus will buffer up on disk the samples and when",
    "start": "1856999",
    "end": "1863419"
  },
  {
    "text": "the network comes back it'll try and resend them okay thank you hi my name is",
    "start": "1863419",
    "end": "1873559"
  },
  {
    "text": "yet first of all thank you very much for your work and the efforts as I as I own",
    "start": "1873559",
    "end": "1879649"
  },
  {
    "text": "user really miss empowering alert manager for two things the first one is",
    "start": "1879649",
    "end": "1887349"
  },
  {
    "text": "do some complex mathematics functions to before the other and the second one is",
    "start": "1887349",
    "end": "1894909"
  },
  {
    "text": "aggregate multi inputs before trigger inert",
    "start": "1894909",
    "end": "1901450"
  },
  {
    "start": "1901000",
    "end": "2018000"
  },
  {
    "text": "what's the question there okay the first example there is some mathematic",
    "start": "1901530",
    "end": "1909590"
  },
  {
    "text": "function like percentile that we already seen but what about having some more",
    "start": "1909590",
    "end": "1917430"
  },
  {
    "text": "complex mathematic functions so this is for the first part the second one is for",
    "start": "1917430",
    "end": "1923820"
  },
  {
    "text": "example I have machine one machine a that the trigger one alert but I have",
    "start": "1923820",
    "end": "1929940"
  },
  {
    "text": "also HTTP be trigger error that I want to trigger only the C alert is the sum",
    "start": "1929940",
    "end": "1939210"
  },
  {
    "text": "of these two others together so aggregate other thing inputs thank you",
    "start": "1939210",
    "end": "1944910"
  },
  {
    "text": "okay so you can do anything you want in prom qo it is proven to be chirring",
    "start": "1944910",
    "end": "1950370"
  },
  {
    "text": "complete please don't try that in production so if you want to do that you can express it in prom ql and then your",
    "start": "1950370",
    "end": "1957360"
  },
  {
    "text": "first question which I've already forgotten oh yeah can you do math similar yes you can do arbitrary masse",
    "start": "1957360",
    "end": "1964290"
  },
  {
    "text": "you've got addition subtraction division in general you can do it like we don't have trigonometric functions which you",
    "start": "1964290",
    "end": "1971100"
  },
  {
    "text": "might get from graphite but no one's come up with a use case yes there's",
    "start": "1971100",
    "end": "1981930"
  },
  {
    "text": "logic or there's logic operators in Prometheus trois you can do Union and or and so on so to do your a and B you",
    "start": "1981930",
    "end": "1989160"
  },
  {
    "text": "would literally just write the expression for a in the expression for B and then and in the middle and then that would be your expression for C does that",
    "start": "1989160",
    "end": "1995580"
  },
  {
    "text": "cover it in alert manager you can also",
    "start": "1995580",
    "end": "2000820"
  },
  {
    "text": "define dependencies between alerts or services saying like if that one thing",
    "start": "2000820",
    "end": "2006230"
  },
  {
    "text": "fires don't send me a notification for the other thing like if if the whole",
    "start": "2006230",
    "end": "2011420"
  },
  {
    "text": "data center is down don't alert me for services in their data center for example so I've got a question around I",
    "start": "2011420",
    "end": "2020960"
  },
  {
    "start": "2018000",
    "end": "2181000"
  },
  {
    "text": "guess you see Prometheus being used in things like linkers II and other different projects and you'll get to a",
    "start": "2020960",
    "end": "2026690"
  },
  {
    "text": "stage potentially where you've got a few different instances of Prometheus on your clusters maybe across different clusters are there any kind of",
    "start": "2026690",
    "end": "2032929"
  },
  {
    "text": "recommended practices about how you and get those communicating and kind of architects from that perspective that",
    "start": "2032929",
    "end": "2038620"
  },
  {
    "text": "you can share so as mentioned in Julia's",
    "start": "2038620",
    "end": "2047920"
  },
  {
    "text": "talk key aspect is reliability so generally you want any alerting for that",
    "start": "2047920",
    "end": "2053889"
  },
  {
    "text": "cluster to come from that Prometheus because then you don't have extra hops the next question is how do I do",
    "start": "2053890",
    "end": "2060970"
  },
  {
    "text": "graphing and well there's dashboard templating so on a graph Anna and so a",
    "start": "2060970",
    "end": "2066159"
  },
  {
    "text": "single graph Anna because you only need one and just have a hey Jay my sequel somehow wherever you usually do - then",
    "start": "2066160",
    "end": "2073090"
  },
  {
    "text": "you can have a global media spooling aggregated data by Federation because if you want to get something like global",
    "start": "2073090",
    "end": "2079149"
  },
  {
    "text": "requests you cannot calculate that in a per cluster fruitiest need to get all the data somewhere so normally you'd get",
    "start": "2079150",
    "end": "2085570"
  },
  {
    "text": "all the aggregated data into a cluster for me to see if it's got like multiple kubernetes and then I create there and",
    "start": "2085570",
    "end": "2091659"
  },
  {
    "text": "then up to a global where you do more maths and do it there this is not",
    "start": "2091660",
    "end": "2097570"
  },
  {
    "text": "everyone's taste once you add hoc queries like that's fine when you know all your queries in advance because you make that all nice and efficient with",
    "start": "2097570",
    "end": "2103780"
  },
  {
    "text": "Federation in which case you get to do other options so yeah so Federation the",
    "start": "2103780",
    "end": "2111130"
  },
  {
    "text": "other option is to use remote write to push to some central database of which you know we've just listed a bunch of",
    "start": "2111130",
    "end": "2116980"
  },
  {
    "text": "them I represent cortex so cortex is a horizontally scalable implementation of the Prometheus API so that way you can",
    "start": "2116980",
    "end": "2124300"
  },
  {
    "text": "use the same prom QL expressions you would on your Prometheus nodes in the global way you know against a single",
    "start": "2124300",
    "end": "2130050"
  },
  {
    "text": "horizontally scalable cortex cluster but you can do the same with influx DB if you want to learn flux and influx",
    "start": "2130050",
    "end": "2136150"
  },
  {
    "text": "languages you can do the same with m3 a bunch of other ones and then the third way yeah I'm Donna smitten err",
    "start": "2136150",
    "end": "2145900"
  },
  {
    "text": "so the first way is to if you don't want to use pushing matrix or federating so replicating the the data in a multiple",
    "start": "2145900",
    "end": "2153580"
  },
  {
    "text": "places you can essentially just use a tano's which is a solution that allows",
    "start": "2153580",
    "end": "2158830"
  },
  {
    "text": "you to have a long term search but also it was global querying so you put your",
    "start": "2158830",
    "end": "2164470"
  },
  {
    "text": "you start some component on the global level that does prom query evaluation and grabs data queries them directly from the",
    "start": "2164470",
    "end": "2171160"
  },
  {
    "text": "parameters instances or object storage which is yet another option you can",
    "start": "2171160",
    "end": "2176680"
  },
  {
    "text": "choose oh thank you",
    "start": "2176680",
    "end": "2181349"
  },
  {
    "start": "2181000",
    "end": "2294000"
  },
  {
    "text": "apparently under my coder I just think it's cool there's so many options that",
    "start": "2181710",
    "end": "2188670"
  },
  {
    "text": "it is literally a monitor hi my question",
    "start": "2193440",
    "end": "2203650"
  },
  {
    "text": "is regarding data reduction or automatic cleanup of old data what does he",
    "start": "2203650",
    "end": "2209560"
  },
  {
    "text": "approach to this so the question is data cleanup so I assumed this 2 part was",
    "start": "2209560",
    "end": "2215950"
  },
  {
    "text": "just deleting data you don't know any need and implicitly also down sampling so the first thing to note is that per",
    "start": "2215950",
    "end": "2222730"
  },
  {
    "text": "medias itself is pretty efficient in terms of data storage we're talking 1.6 1.7 bytes per sample is typical in",
    "start": "2222730",
    "end": "2229960"
  },
  {
    "text": "production if you go to a another system like graphite or mrtg it is might you",
    "start": "2229960",
    "end": "2236290"
  },
  {
    "text": "might be talking 40 bytes 100 bytes 200 White's depending on what system so first off because Prometheus is so",
    "start": "2236290",
    "end": "2242860"
  },
  {
    "text": "efficient your needs to clean up data is substantially less now there is the",
    "start": "2242860",
    "end": "2248410"
  },
  {
    "text": "retention time which you can specify a time limit for the Prometheus and we'll take care of it there's also a size",
    "start": "2248410",
    "end": "2253420"
  },
  {
    "text": "limit as of two three versions ago another option you have then is there is",
    "start": "2253420",
    "end": "2259990"
  },
  {
    "text": "no down something inside Prometheus itself that's kind of a more cluster storage thing which Janus has and it",
    "start": "2259990",
    "end": "2267400"
  },
  {
    "text": "turns out to be useful you need like an hour because of complexity and then the",
    "start": "2267400",
    "end": "2273370"
  },
  {
    "text": "other thing is there is a delete API in Prometheus so you can't delete data so in principle you could have the data",
    "start": "2273370",
    "end": "2278890"
  },
  {
    "text": "inside Prometheus and then just the leash everything is not aggregated after a month or something but that's not an",
    "start": "2278890",
    "end": "2285460"
  },
  {
    "text": "API you want to be hitting every five minutes",
    "start": "2285460",
    "end": "2289020"
  },
  {
    "text": "sorry about remote right thing does it",
    "start": "2294830",
    "end": "2300060"
  },
  {
    "text": "handle sending aggregates are supposed to sending every metrics just to save on bandwidth and such you can you can build",
    "start": "2300060",
    "end": "2309450"
  },
  {
    "text": "recording rules and then you can filter something cable you can build recording rules in Prometheus which does the",
    "start": "2309450",
    "end": "2315150"
  },
  {
    "text": "aggregation and then you can use relabeling rules on your remote right path to drop everything else and only",
    "start": "2315150",
    "end": "2321180"
  },
  {
    "text": "send recording rules so yes but I we don't do that we just send it all okay",
    "start": "2321180",
    "end": "2328020"
  },
  {
    "text": "cool probably a more general point is -",
    "start": "2328020",
    "end": "2337910"
  },
  {
    "text": "Prometheus is relatively Domon houseworks if there's no awesome optimization or so on you have to add",
    "start": "2338180",
    "end": "2345300"
  },
  {
    "text": "the recording rules yourself and if you ask it to do something it will do it these days we have isolation of what not",
    "start": "2345300",
    "end": "2351990"
  },
  {
    "text": "not - when that happens but if you ask it to go across ten gigs of data it is",
    "start": "2351990",
    "end": "2357480"
  },
  {
    "text": "going to go across ten gigs of data and then that just takes time because it takes up with time to process ten gigs",
    "start": "2357480",
    "end": "2363630"
  },
  {
    "text": "of data if you want a recording rule you might be able to cut that down to a hundred Meg's or something but at the end of the day if you want to process a",
    "start": "2363630",
    "end": "2369480"
  },
  {
    "text": "lot of data you're processing it lost if it's going by a remote reread you know we have to send all that data over the",
    "start": "2369480",
    "end": "2375300"
  },
  {
    "text": "wire against if it's just on side one Prometheus then that's only going over to system bus so it's going to be quite",
    "start": "2375300",
    "end": "2380700"
  },
  {
    "text": "a bit faster so I have a question about",
    "start": "2380700",
    "end": "2392130"
  },
  {
    "start": "2383000",
    "end": "2534000"
  },
  {
    "text": "the about the scrape interval so Julius in the presentation mentioned a typical",
    "start": "2392130",
    "end": "2398010"
  },
  {
    "text": "scrape interval might be fifteen or thirty seconds so I'm wondering is there guidance there for a certain number of",
    "start": "2398010",
    "end": "2403560"
  },
  {
    "text": "metrics a certain number of scrape endpoints what the practical lower limit is for this great interval and then",
    "start": "2403560",
    "end": "2410130"
  },
  {
    "text": "similarly for the evaluation interval of alerts depending on how many rules of complexity of those rules etc",
    "start": "2410130",
    "end": "2417859"
  },
  {
    "text": "so it kind of depends on your data and what you want to achieve generally speaking we suggest within one",
    "start": "2417900",
    "end": "2424750"
  },
  {
    "text": "premises instance you keep the same great time for everything so you don't start mixing within what one instance",
    "start": "2424750",
    "end": "2430720"
  },
  {
    "text": "you can but did there a certain reason why why you probably shouldn't course it will make your life easier in some",
    "start": "2430720",
    "end": "2436030"
  },
  {
    "text": "regards but this is basically just a question of how what does your work look",
    "start": "2436030",
    "end": "2441850"
  },
  {
    "text": "look like the only thing is you shouldn't go above two minutes course you'll start timing out after five and",
    "start": "2441850",
    "end": "2447190"
  },
  {
    "text": "then if you miss once great blah blah blah so that kind of sucks but else up",
    "start": "2447190",
    "end": "2452740"
  },
  {
    "text": "to two minutes do whatever exactly I'm",
    "start": "2452740",
    "end": "2458430"
  },
  {
    "text": "probably the lowest which which you should be doing I guess I mean you can do lower but percona does state they are",
    "start": "2459060",
    "end": "2467830"
  },
  {
    "text": "asked for sub second to be supported but I would personally consider it at below",
    "start": "2467830",
    "end": "2473380"
  },
  {
    "text": "fifteen or five seconds you're getting into profiling and even getting endpoints to respond that quickly you",
    "start": "2473380",
    "end": "2480190"
  },
  {
    "text": "know it can be it can be difficult why are you you used to SNMP you know it's slow but but do think about which to is",
    "start": "2480190",
    "end": "2487900"
  },
  {
    "text": "appropriate like if you want to every now and then just hammer something to get detailed stats you can if you're",
    "start": "2487900",
    "end": "2493960"
  },
  {
    "text": "doing that all the time you might end up using too much CPU if you start getting",
    "start": "2493960",
    "end": "2500920"
  },
  {
    "text": "into networks black box this part is something which potentially you want to hit every single second for for ICMP",
    "start": "2500920",
    "end": "2507880"
  },
  {
    "text": "probes maybe even for HTTP stuff to really get a good picture of how stuff changes over time but this is more on",
    "start": "2507880",
    "end": "2513970"
  },
  {
    "text": "the networking side not so much on the service side itself Thanks I'm sure that",
    "start": "2513970",
    "end": "2520420"
  },
  {
    "text": "if you are using the black boxes Porter with such a short ting it does automatic timeouts and it alls Knox 500",
    "start": "2520420",
    "end": "2526630"
  },
  {
    "text": "milliseconds off them according to a command line flag you probably want that short refuge reading - hello I guess a question about",
    "start": "2526630",
    "end": "2538570"
  },
  {
    "start": "2534000",
    "end": "2630000"
  },
  {
    "text": "the aggregate O's if I want to add new aggregate or is it Daisy you bragging",
    "start": "2538570",
    "end": "2545950"
  },
  {
    "text": "API or something like this Micro Gators so like some max well the",
    "start": "2545950",
    "end": "2554810"
  },
  {
    "text": "toad is there it's not too hard to add them but you have to add them in the source code and we'd have to ask the",
    "start": "2554810",
    "end": "2560660"
  },
  {
    "text": "question of okay how useful is - is that very similar to something or we already have and so on because we already have",
    "start": "2560660",
    "end": "2567730"
  },
  {
    "text": "11 aggregators and 50 something functions and we're just adding a",
    "start": "2567730",
    "end": "2573110"
  },
  {
    "text": "function like we have a standard deviation which is population standard deviation well we don't have sample",
    "start": "2573110",
    "end": "2580010"
  },
  {
    "text": "standard deviation and if someone to request that I'd ask the question of why do you care it's basically the same",
    "start": "2580010",
    "end": "2586310"
  },
  {
    "text": "number and because one is just dividing by n when it's divided by n minus 1 is",
    "start": "2586310",
    "end": "2593750"
  },
  {
    "text": "that that sort of question well if you asked like I think we've got a pretty good coverage which aggregator are you considering like or there's already a",
    "start": "2593750",
    "end": "2604580"
  },
  {
    "text": "Kanto so just past point 5 - ish okay",
    "start": "2604580",
    "end": "2610360"
  },
  {
    "text": "yeah so all the over times are associated then with - the only",
    "start": "2612250",
    "end": "2617270"
  },
  {
    "text": "exception there is count values doesn't have one but all the rest were there thank you when I guess talking bottom K",
    "start": "2617270",
    "end": "2623870"
  },
  {
    "text": "or not over time I'd err hi I was",
    "start": "2623870",
    "end": "2632630"
  },
  {
    "start": "2630000",
    "end": "2806000"
  },
  {
    "text": "wondering if you thought about separating writing and scraping of",
    "start": "2632630",
    "end": "2638750"
  },
  {
    "text": "reading because I have a lot of users in my cooperation but I prefer dashboards",
    "start": "2638750",
    "end": "2644690"
  },
  {
    "text": "and when they open it on one-month period they just kill the primitives",
    "start": "2644690",
    "end": "2650090"
  },
  {
    "text": "because of um killed and I was thinking",
    "start": "2650090",
    "end": "2655580"
  },
  {
    "text": "can you separate reading to writing so that when they kill the permit is it",
    "start": "2655580",
    "end": "2662150"
  },
  {
    "text": "continue to scrape yeah so first little answer is like there are some sanity limits in Prometheus to say X number of",
    "start": "2662150",
    "end": "2670070"
  },
  {
    "text": "crews at the same time and as of which version I forgot a couple of versions back now there's sample limits to how",
    "start": "2670070",
    "end": "2676460"
  },
  {
    "text": "much one query can touch but of course so you have the problem yeah during an outage everyone wants to",
    "start": "2676460",
    "end": "2683039"
  },
  {
    "text": "see what's going on and everyone's firing up their grip on you we haven't really thought about completely",
    "start": "2683039",
    "end": "2690119"
  },
  {
    "text": "separating that yet because it's so it's all one process and it's one server so it's a bit hard to do but there's",
    "start": "2690119",
    "end": "2697349"
  },
  {
    "text": "different things you can do you could of course run one Prometheus that or multiple parameters is that just for",
    "start": "2697349",
    "end": "2703170"
  },
  {
    "text": "being queried and not during your alerting workload but then also what",
    "start": "2703170",
    "end": "2708900"
  },
  {
    "text": "gitlab for example is doing or well they're using a proxy between griffin ax",
    "start": "2708900",
    "end": "2714029"
  },
  {
    "text": "and prometheus that is called trickster from Comcast you know this one yeah and",
    "start": "2714029",
    "end": "2719729"
  },
  {
    "text": "and so this they host their public Prometheus dashboard with crow fauna with that",
    "start": "2719729",
    "end": "2725369"
  },
  {
    "text": "so with trickster in between and it caches a lot of the queries and makes it way more efficient for the for the query",
    "start": "2725369",
    "end": "2732390"
  },
  {
    "text": "load but other than that there's no magic bullet the other thing gait lab is doing is that the public radius which is exposed",
    "start": "2732390",
    "end": "2741209"
  },
  {
    "text": "to the public here no it's just air and",
    "start": "2741209",
    "end": "2747119"
  },
  {
    "text": "so and they have a separate Prometheus for that from their production one so that even if people start sending big",
    "start": "2747119",
    "end": "2755160"
  },
  {
    "text": "queries there - your production monitoring is still okay so if you something public public you probably",
    "start": "2755160",
    "end": "2762359"
  },
  {
    "text": "want to separate for me to use to be safe and just watch you can always you",
    "start": "2762359",
    "end": "2767670"
  },
  {
    "text": "know fall back to you like you know integration sistex ten extension systems like cortex or tano's they all",
    "start": "2767670",
    "end": "2773549"
  },
  {
    "text": "essentially move the data away from the scraping Park so to keep from queues",
    "start": "2773549",
    "end": "2779099"
  },
  {
    "text": "mainly for scraping and maybe you know local evaluations and you can actually make read buff more you know scalable complex",
    "start": "2779099",
    "end": "2786449"
  },
  {
    "text": "as well and and and resilient and isolated with a little scraping part and and cortex has already caching enables",
    "start": "2786449",
    "end": "2793859"
  },
  {
    "text": "you have this trickster built in tunnels hopefully have that soon as well so that's another option all right",
    "start": "2793859",
    "end": "2803059"
  },
  {
    "start": "2806000",
    "end": "2909000"
  },
  {
    "text": "so I have two questions so the first one is that I see the Prometheus server",
    "start": "2806480",
    "end": "2813780"
  },
  {
    "text": "reached out to each exporter and applications to get metrics so what if I",
    "start": "2813780",
    "end": "2819660"
  },
  {
    "text": "want to send metrics in the other direction for example there may be infrequent events triggered by explicit",
    "start": "2819660",
    "end": "2826500"
  },
  {
    "text": "user actions so I wonder what how can I get metrics in the case the second",
    "start": "2826500",
    "end": "2833910"
  },
  {
    "text": "question is because I am a Java developer I'd like to monitor like JVM statistics and performance so I wonder",
    "start": "2833910",
    "end": "2841830"
  },
  {
    "text": "if you have like built-in good support for monitoring JVM like GCE statistics",
    "start": "2841830",
    "end": "2848700"
  },
  {
    "text": "etc so I can answer it the Java question",
    "start": "2848700",
    "end": "2857940"
  },
  {
    "text": "as the client Java maintainer and like all client libraries we try to export out-of-the-box what we can that make",
    "start": "2857940",
    "end": "2864750"
  },
  {
    "text": "sense which includes all the VMS the JVM starts the thread starts to memory pool stats in the case of Java for technical",
    "start": "2864750",
    "end": "2871890"
  },
  {
    "text": "reasons you do have to call default export stuff initialize which is in the client Java hotspot module and then",
    "start": "2871890",
    "end": "2879630"
  },
  {
    "text": "you'll get all of those and the other question then is what happens when I want to push infrequent events so if",
    "start": "2879630",
    "end": "2887400"
  },
  {
    "text": "this is on a long-running server and there's an event you increment a counter and prometheus will get it after that",
    "start": "2887400",
    "end": "2893310"
  },
  {
    "text": "it's next scrape if this is a batch job which is running every hour every day or",
    "start": "2893310",
    "end": "2899100"
  },
  {
    "text": "what not at the end of its run it would push the metrics to push gateway and then Prometheus will scrape that",
    "start": "2899100",
    "end": "2904350"
  },
  {
    "text": "regularly does that answer questions what about a web application and a user",
    "start": "2904350",
    "end": "2915000"
  },
  {
    "start": "2909000",
    "end": "2983000"
  },
  {
    "text": "takes a certain action and I'd like to capture that kind of metrics real-time",
    "start": "2915000",
    "end": "2921920"
  },
  {
    "text": "so you want to track front-end metrics like how many users are clicking a",
    "start": "2921920",
    "end": "2927390"
  },
  {
    "text": "certain button on my website yeah so for that first you would need to send that",
    "start": "2927390",
    "end": "2932580"
  },
  {
    "text": "event to something in your data center that can count that event with done read this button with a certain so and",
    "start": "2932580",
    "end": "2938950"
  },
  {
    "text": "so has been clicked so many times there's one of these projects by weave works is it called from something",
    "start": "2938950",
    "end": "2947319"
  },
  {
    "text": "something problem from Jas I think was the front end side of it that sends the event to the back end and then there's",
    "start": "2947319",
    "end": "2952630"
  },
  {
    "text": "another thing in the back end I don't know if it was like prom girl Gator or something yeah prom grader which then",
    "start": "2952630",
    "end": "2959049"
  },
  {
    "text": "aggregates these counters and then you can scrape that using prometheus Prometheus wasn't really built for doing",
    "start": "2959049",
    "end": "2965230"
  },
  {
    "text": "front end metrics but in that way it can be abused to to do that used or used so",
    "start": "2965230",
    "end": "2986079"
  },
  {
    "start": "2983000",
    "end": "3059000"
  },
  {
    "text": "for full running position in aichi you said that you will be running two servers you know same average all the",
    "start": "2986079",
    "end": "2993220"
  },
  {
    "text": "data will be replicated so if I have to do the remote right word data I send because I don't want to send that",
    "start": "2993220",
    "end": "2998980"
  },
  {
    "text": "replica for that attached to my remote",
    "start": "2998980",
    "end": "3003049"
  },
  {
    "text": "like you can do two things you can you can say only Prometheus one writes to",
    "start": "3005930",
    "end": "3011069"
  },
  {
    "text": "the remote right and Prometheus 2 is H a or there are systems out there like time",
    "start": "3011069",
    "end": "3017460"
  },
  {
    "text": "scale now cortex you just add a new external label called underscore underscore replicas to your Prometheus",
    "start": "3017460",
    "end": "3024359"
  },
  {
    "text": "and the remote system will deduplicate at in this time if Prometheus one goes",
    "start": "3024359",
    "end": "3029849"
  },
  {
    "text": "down the remote system will look at it and like I haven't received any data for 15 seconds I'm going to accept data from",
    "start": "3029849",
    "end": "3035130"
  },
  {
    "text": "prometheus 2 4 and of all my data back yeah I mean it's actually not a lot of",
    "start": "3035130",
    "end": "3043710"
  },
  {
    "text": "network and my second question is like we always encounter a problem with",
    "start": "3043710",
    "end": "3049020"
  },
  {
    "text": "monitor monitoring the monitor so so what is the strategy in Prometheus",
    "start": "3049020",
    "end": "3055230"
  },
  {
    "text": "around like how to do that so what we do",
    "start": "3055230",
    "end": "3061619"
  },
  {
    "start": "3059000",
    "end": "3174000"
  },
  {
    "text": "on openshift for that is we simply have Prometheus always firing an alert and then we pass that down to the entire",
    "start": "3061619",
    "end": "3068400"
  },
  {
    "text": "pipeline and whatever paging service you use you have that paging service page you when that alert is not",
    "start": "3068400",
    "end": "3074770"
  },
  {
    "text": "firing so it's a Deadman switch like untrained for example right if something",
    "start": "3074770",
    "end": "3079990"
  },
  {
    "text": "is not touching the switch its firing like computing another monitor sorry this is like creating another monitor so",
    "start": "3079990",
    "end": "3089380"
  },
  {
    "text": "we don't have Prometheus monitoring parameters we have that weird advantage sorry yes so the steadman switch thing",
    "start": "3089380",
    "end": "3098230"
  },
  {
    "text": "is kind of last resort that you can add that max mentioned so it's always firing",
    "start": "3098230",
    "end": "3104680"
  },
  {
    "text": "alert and then an external service notifies you if it does not receive that alert every one minute or so right so",
    "start": "3104680",
    "end": "3112450"
  },
  {
    "text": "something in your lodging infrastructure is completely dead now and then it alerts you but before that you can",
    "start": "3112450",
    "end": "3119619"
  },
  {
    "text": "already met Amanat or prometheus normally using parameters so Prometheus itself also exposes Prometheus metrics",
    "start": "3119619",
    "end": "3126490"
  },
  {
    "text": "alert manager as well so you would have a meta monitoring Prometheus setup which",
    "start": "3126490",
    "end": "3131740"
  },
  {
    "text": "just scrapes your other Prometheus components and then you can have really more complex alerting rules to find and",
    "start": "3131740",
    "end": "3139030"
  },
  {
    "text": "they're like hey those Prometheus stopped ingesting or hey those queries are really slow in this one etc etc and",
    "start": "3139030",
    "end": "3144310"
  },
  {
    "text": "then you can have like proper alerting rules and then this last one that's the whole pipeline kind of into end test",
    "start": "3144310",
    "end": "3150339"
  },
  {
    "text": "that's more as a like last resort",
    "start": "3150339",
    "end": "3153869"
  },
  {
    "start": "3174000",
    "end": "3300000"
  },
  {
    "text": "do you have any HTTP REST API or something which can just query based on",
    "start": "3175450",
    "end": "3181570"
  },
  {
    "text": "the prom key well it's called the query",
    "start": "3181570",
    "end": "3193540"
  },
  {
    "text": "API you know it's the same API you used to query Prometheus you can use that like there are you can just send a",
    "start": "3193540",
    "end": "3200650"
  },
  {
    "text": "request you get JSON back and you can parse that so what is the recommended",
    "start": "3200650",
    "end": "3207670"
  },
  {
    "text": "approach like is it querying the Prometheus server directly like to extract the data or going by the remote",
    "start": "3207670",
    "end": "3215320"
  },
  {
    "text": "right so essentially you can do both it depends on your use case for remote",
    "start": "3215320",
    "end": "3222160"
  },
  {
    "text": "right it is just to ship all the data to a remote source so that you can visualize or do operations on the data",
    "start": "3222160",
    "end": "3228790"
  },
  {
    "text": "in the remote source but the query API if you just want to ask Prometheus hey give me data you can just use the query",
    "start": "3228790",
    "end": "3235030"
  },
  {
    "text": "API and the remote there's also a remote read API where you can get raw data from Prometheus you can also use that it all",
    "start": "3235030",
    "end": "3240850"
  },
  {
    "text": "depends on your use case but remote write is typically when you want to run the queries and analysis on the remote",
    "start": "3240850",
    "end": "3247450"
  },
  {
    "text": "system like you are extracting data of",
    "start": "3247450",
    "end": "3261400"
  },
  {
    "text": "course like you're sending queries to Prometheus this always the query load but depending on if you're just using",
    "start": "3261400",
    "end": "3268270"
  },
  {
    "text": "remote read if you are not reading a lot of data that's like not much impact but",
    "start": "3268270",
    "end": "3273550"
  },
  {
    "text": "if you are reading like lots of data remote really takes up a lot of memory but we are working on improving the",
    "start": "3273550",
    "end": "3280540"
  },
  {
    "text": "remote area to be streaming to use less memory and all of that ok thank you",
    "start": "3280540",
    "end": "3287430"
  },
  {
    "start": "3300000",
    "end": "3478000"
  },
  {
    "text": "so one question from our side cars people are drifting off slowly and this",
    "start": "3301630",
    "end": "3307720"
  },
  {
    "text": "is directly the inverse from all the other cube concert the deep-dive had a lot more visitors than the intercession",
    "start": "3307720",
    "end": "3313900"
  },
  {
    "text": "and we always did the deep dive the same thing or the same way so first question is who of you is aware that promises has",
    "start": "3313900",
    "end": "3319750"
  },
  {
    "text": "a booth in in the sponsor section okay",
    "start": "3319750",
    "end": "3325320"
  },
  {
    "text": "who have you visited this booth okay so",
    "start": "3325320",
    "end": "3330970"
  },
  {
    "text": "would you say it's fair to say that when we have the who thinks that now that we have that booth having this open Q&A is",
    "start": "3330970",
    "end": "3339010"
  },
  {
    "text": "less pressing and less interesting course we have this default way of getting people's question answered",
    "start": "3339010",
    "end": "3346770"
  },
  {
    "text": "that's a show of hand question okay so a",
    "start": "3346770",
    "end": "3351970"
  },
  {
    "text": "show of hands if you think that now that we have a booth the need for for structuring q-and-a like this goes down",
    "start": "3351970",
    "end": "3360990"
  },
  {
    "text": "okay so that's that's kind of how how I see the room anyway but okay that's good",
    "start": "3360990",
    "end": "3366610"
  },
  {
    "text": "I mean it's kind of obvious course normally that the deep dive is always way fuller than the intercession and",
    "start": "3366610",
    "end": "3372040"
  },
  {
    "text": "this is the first time this is the inverse you're not keeping in mind survival bias these are people who want",
    "start": "3372040",
    "end": "3377350"
  },
  {
    "text": "to watch us this is why I'm asking now and not in half an hour that's I was I was cussing at myself",
    "start": "3377350",
    "end": "3385620"
  },
  {
    "text": "several times when even more people left and I didn't ask them so do you guys have else have any more questions of",
    "start": "3385620",
    "end": "3393850"
  },
  {
    "text": "course I mean we are still here and we still have 25 minutes it's like regarding allergy I was",
    "start": "3393850",
    "end": "3400330"
  },
  {
    "text": "wondering if you have plans to include a rating based on thresholds based on",
    "start": "3400330",
    "end": "3406360"
  },
  {
    "text": "levels I mean for example I will just take something out of the rhyme i weight",
    "start": "3406360",
    "end": "3412330"
  },
  {
    "text": "of one server it can be fresh or can be different from a database one",
    "start": "3412330",
    "end": "3419020"
  },
  {
    "text": "a storage server and I don't want to duplicate the Aleuts and I just want to",
    "start": "3419020",
    "end": "3424960"
  },
  {
    "text": "set different fresh service for the same area so if this is your own infrastructure",
    "start": "3424960",
    "end": "3430720"
  },
  {
    "text": "I would advise duplicating alerts if however these are coming from different customers and there's like some database",
    "start": "3430720",
    "end": "3436960"
  },
  {
    "text": "or UI or even source control they're coming from there is a technique for doing this and it's on my blog somewhere",
    "start": "3436960",
    "end": "3444070"
  },
  {
    "text": "I forget the name which I think it's thresholds based thresholds or something",
    "start": "3444070",
    "end": "3450610"
  },
  {
    "text": "from robot yeah using time series the threshold sounds about right I've got over 200 blogs it's difficult",
    "start": "3450610",
    "end": "3455620"
  },
  {
    "text": "to remember all the funny names I came out push yeah but this may skew trick",
    "start": "3455620",
    "end": "3460720"
  },
  {
    "text": "with group left and using thresholds but if it's your own infrastructure honestly it's simple it's just if it's",
    "start": "3460720",
    "end": "3469600"
  },
  {
    "text": "your own infrastructure that you were running for yourself it's easiest to duplicate the alert hi",
    "start": "3469600",
    "end": "3480100"
  },
  {
    "text": "as a software developer that provides software that should expose metrics to",
    "start": "3480100",
    "end": "3486960"
  },
  {
    "text": "Prometheus do you have anything that can assist me to ensure that those metrics",
    "start": "3486960",
    "end": "3494230"
  },
  {
    "text": "are provided by integration tests or something so that the tag in in quality",
    "start": "3494230",
    "end": "3503290"
  },
  {
    "text": "or integration tests or with something else than some errors I can ensure that the software that is to be shipped will",
    "start": "3503290",
    "end": "3511240"
  },
  {
    "text": "expose those metrics so what we do have",
    "start": "3511240",
    "end": "3521590"
  },
  {
    "text": "is in the Prometheus release binary in the parameters release table all there's",
    "start": "3521590",
    "end": "3527410"
  },
  {
    "text": "two binaries Prometheus and prom tool and from tool has a check command which you can run against a metrics endpoint",
    "start": "3527410",
    "end": "3533830"
  },
  {
    "text": "and at least it will lint the metrics that are exposed saying like hey this is a counter but it has kind of the wrong",
    "start": "3533830",
    "end": "3540700"
  },
  {
    "text": "convention in the name and things like this so it will give you some clues to how to clean up your metrics a bit more",
    "start": "3540700",
    "end": "3546490"
  },
  {
    "text": "but if you're asking for something that really goes from the instrument application through",
    "start": "3546490",
    "end": "3552160"
  },
  {
    "text": "recording and alerting rules to then a lot manager routing rules and testing",
    "start": "3552160",
    "end": "3557349"
  },
  {
    "text": "the whole thing and to end there's unfortunately because it's kind of like a dynamic system through multiple stages",
    "start": "3557349",
    "end": "3563829"
  },
  {
    "text": "there's no way in Prometheus to really check the whole chain unless you build it all yourself and check that it works",
    "start": "3563829",
    "end": "3571710"
  },
  {
    "text": "there I would actually be really cool if",
    "start": "3571710",
    "end": "3577240"
  },
  {
    "text": "there were more was more tooling around this like if a binary somehow better could register its metrics and possible",
    "start": "3577240",
    "end": "3584289"
  },
  {
    "text": "label values with some registry and then later on you can check in your Heine can have like a checker tool run across your",
    "start": "3584289",
    "end": "3591579"
  },
  {
    "text": "software the rules based on it and alerting routing and so on doesn't exist",
    "start": "3591579",
    "end": "3598390"
  },
  {
    "text": "yet what another thing that exists is unit testing for alerts so you can",
    "start": "3598390",
    "end": "3604809"
  },
  {
    "text": "actually also with it's also another prom tool command you can write",
    "start": "3604809",
    "end": "3609819"
  },
  {
    "text": "basically a spec you can say like okay given this file that defines alerting rules and given those input data I",
    "start": "3609819",
    "end": "3616930"
  },
  {
    "text": "expect to get the following output alerts so you can write unit tests for your alerting rules but you have to like",
    "start": "3616930",
    "end": "3624220"
  },
  {
    "text": "specify you know the so assumed data you cannot actually check against some",
    "start": "3624220",
    "end": "3629859"
  },
  {
    "text": "binary that you have that that binary would produce that data so it's still limited yep",
    "start": "3629859",
    "end": "3637150"
  },
  {
    "text": "and I would from the developer perspective if you really want to go into like what metrics I am exposing",
    "start": "3637150",
    "end": "3643420"
  },
  {
    "text": "right I really recommend you in testing key metric as well so for example in going it's easy that there is like",
    "start": "3643420",
    "end": "3649660"
  },
  {
    "text": "client go long has to float essentially method so essentially can you assert",
    "start": "3649660",
    "end": "3656079"
  },
  {
    "text": "that when you increment some metric you actually are doing that in your unit test and I really recommend that",
    "start": "3656079",
    "end": "3661660"
  },
  {
    "text": "sometimes it's too brittle to like do it but sometimes you really care about this metric to be correct in your code",
    "start": "3661660",
    "end": "3668500"
  },
  {
    "text": "perspective so like in our infrastructure we do it a lot as well",
    "start": "3668500",
    "end": "3674609"
  },
  {
    "text": "also if you I'm not sure you if this was the exact same thing that you mentioned",
    "start": "3676460",
    "end": "3682170"
  },
  {
    "text": "but in in the NGO client there's also a test you tool that actually does a",
    "start": "3682170",
    "end": "3688920"
  },
  {
    "text": "scrape of the internal registry basically and I think it's like test you",
    "start": "3688920",
    "end": "3694050"
  },
  {
    "text": "together and compare and you can just say this is the metric output that I would have expected if I had done a",
    "start": "3694050",
    "end": "3701060"
  },
  {
    "text": "scrape of this application and like in kubernetes this is used like all over",
    "start": "3701060",
    "end": "3706920"
  },
  {
    "text": "the place for a lot of metrics and that's why we how we basically test so",
    "start": "3706920",
    "end": "3713940"
  },
  {
    "text": "if you're using the goal library like not using the global registry is quite helpful and then you can like pass in",
    "start": "3713940",
    "end": "3721860"
  },
  {
    "text": "registries into your components and then check the output in very nice unit testing like from a software engineering",
    "start": "3721860",
    "end": "3727980"
  },
  {
    "text": "perspective the other thing if you do",
    "start": "3727980",
    "end": "3734220"
  },
  {
    "text": "have a full CIC dating and at least in your release processes you might be checking as part of the release that hey",
    "start": "3734220",
    "end": "3741060"
  },
  {
    "text": "has process CPU usage gone up relative to requests and check that sort of thing",
    "start": "3741060",
    "end": "3746310"
  },
  {
    "text": "for your key metrics something else to keep in mind is how much should you unit",
    "start": "3746310",
    "end": "3751800"
  },
  {
    "text": "test because if you think about log lines like application logs how often do you unit test the answer is well when",
    "start": "3751800",
    "end": "3757560"
  },
  {
    "text": "it's rebuilding and other important stuff like that and I'd say it's similarly for metrics like if I'm",
    "start": "3757560",
    "end": "3762690"
  },
  {
    "text": "writing an or PC library the metrics are part of the main feature set so those should probably be tested but if it's",
    "start": "3762690",
    "end": "3769770"
  },
  {
    "text": "just like a troll away like compression just in case I ever need it I wouldn't personally unit test that and part of",
    "start": "3769770",
    "end": "3777360"
  },
  {
    "text": "the reason for that is like yeah I've seen systems like big systems and it turns about about maybe 10 percent of",
    "start": "3777360",
    "end": "3784200"
  },
  {
    "text": "them the metrics are broken somehow such as you forgot the registration or and -",
    "start": "3784200",
    "end": "3790670"
  },
  {
    "text": "you it just isn't monitoring the wrong thing if you add unit testing then that number should go",
    "start": "3790670",
    "end": "3797490"
  },
  {
    "text": "down to maybe 5% because you're monitoring the wrong thing but because you now have a rule that all metrics",
    "start": "3797490",
    "end": "3803520"
  },
  {
    "text": "must be unit s did you get far fewer metrics so I think it's better to have okay we'll have more match",
    "start": "3803520",
    "end": "3809950"
  },
  {
    "text": "but you know 5% more than were broken Robert and okay everything's unit tested but we have fewer metrics because then",
    "start": "3809950",
    "end": "3816099"
  },
  {
    "text": "every little bit of data you can have 20 bugging and outage we're trying to figure out what's going on inside a",
    "start": "3816099",
    "end": "3821589"
  },
  {
    "text": "piece of code is useful sometimes even if it is wrong so what happen expect big",
    "start": "3821589",
    "end": "3842560"
  },
  {
    "text": "things for produce what are you working on so big things a lot of the things",
    "start": "3842560",
    "end": "3849369"
  },
  {
    "text": "these days are happening in the ecosystem so we've got things like Tanis and cortex in Prometheus itself like I",
    "start": "3849369",
    "end": "3855579"
  },
  {
    "text": "personally think it's reasonably near to feature completion as in what Prometheus core should have like stuff coming up is",
    "start": "3855579",
    "end": "3861700"
  },
  {
    "text": "the TLS stuff and which is currently slowly going to denote exported elsewhere and bulk in Porsche and",
    "start": "3861700",
    "end": "3869109"
  },
  {
    "text": "backing back inserting recording rules is being worked on and there's some UI stuff for paradius",
    "start": "3869109",
    "end": "3875970"
  },
  {
    "text": "we have yeah open metrics is always supports metadata having more of that as",
    "start": "3875970",
    "end": "3881560"
  },
  {
    "text": "well because at the moment Prometheus does not use that and from QL the data is available by the API if you want to",
    "start": "3881560",
    "end": "3887109"
  },
  {
    "text": "look at it I personally hope that's used by things like Pravana to make the user experience easier some of us have",
    "start": "3887109",
    "end": "3905140"
  },
  {
    "text": "discussed this not not necessarily everybody there we may be looking into improving some of our API it's like the",
    "start": "3905140",
    "end": "3911980"
  },
  {
    "text": "remote read API we've thought about making investigating how we could make",
    "start": "3911980",
    "end": "3917440"
  },
  {
    "text": "some of our API streaming but I think like this you can see the theme I think",
    "start": "3917440",
    "end": "3922869"
  },
  {
    "text": "we're not really planning any major feature work in core Prometheus yeah",
    "start": "3922869",
    "end": "3930810"
  },
  {
    "text": "that's what I was going to say I think most of the interesting work around Prometheus these days is happening outside of Prometheus so with Thanos",
    "start": "3930810",
    "end": "3937390"
  },
  {
    "text": "cortex and some other projects to add more long-term durability",
    "start": "3937390",
    "end": "3943390"
  },
  {
    "text": "enterprise multi-tenancy etc features around it so yeah there were three main",
    "start": "3943390",
    "end": "3948819"
  },
  {
    "text": "tenets of three different long-term storage for primitives I seems to know",
    "start": "3948819",
    "end": "3954609"
  },
  {
    "text": "yourself pretty well are you planning on merging was thinking enough only one",
    "start": "3954609",
    "end": "3959890"
  },
  {
    "text": "with all the good things about the free because it's I mean yeah there is the",
    "start": "3959890",
    "end": "3966760"
  },
  {
    "text": "possibility like that there are definitely lots of advantages of this so you actually have as a user like you",
    "start": "3966760",
    "end": "3971769"
  },
  {
    "text": "don't have got many options and there is joint force for you know better and right support but yeah as you can",
    "start": "3971769",
    "end": "3978279"
  },
  {
    "text": "imagine merging the two projects are or many projects are not easy like you can see on open telemetry just doing that",
    "start": "3978279",
    "end": "3985180"
  },
  {
    "text": "it's it's quite epic adventure and long one as well politics as well and yeah",
    "start": "3985180",
    "end": "3992529"
  },
  {
    "text": "from from my side like as a maintainer I don't want to care about the politics",
    "start": "3992529",
    "end": "3997839"
  },
  {
    "text": "that much I want to build something that works for everyone and and solve all the use cases so yeah definitely will look",
    "start": "3997839",
    "end": "4004710"
  },
  {
    "text": "forward to make it simple and more easy to understand and choose from and maybe",
    "start": "4004710",
    "end": "4010079"
  },
  {
    "text": "even including to produce ecosystem as some recommended tool yeah one thing",
    "start": "4010079",
    "end": "4019890"
  },
  {
    "text": "many people asked us for is scalability tests basically give a recommendation of what a single promises can take on a",
    "start": "4019890",
    "end": "4025859"
  },
  {
    "text": "given memory and or given a machine so this is what we're trying to do we need",
    "start": "4025859",
    "end": "4031349"
  },
  {
    "text": "to be working on adding scalability tests because I I've been at the boot",
    "start": "4031349",
    "end": "4038910"
  },
  {
    "text": "for a long time and I took notes what people were asking",
    "start": "4038910",
    "end": "4044450"
  },
  {
    "text": "yeah I just I was oh I was overzealous",
    "start": "4055260",
    "end": "4060280"
  },
  {
    "text": "and kind of bought too many stickers so please take away stickers for your local communities meetups and stuff and come",
    "start": "4060280",
    "end": "4067059"
  },
  {
    "text": "say hi at the booth yeah I've got",
    "start": "4067059",
    "end": "4072970"
  },
  {
    "text": "another note here for security for exporters it is there okay what else",
    "start": "4072970",
    "end": "4079770"
  },
  {
    "text": "community-driven exporters it is there okay open matrix support okay I guess",
    "start": "4079770",
    "end": "4090819"
  },
  {
    "text": "that's it then maybe coming back to your",
    "start": "4090819",
    "end": "4099160"
  },
  {
    "text": "question about the two projects merging I think some of the work that we're",
    "start": "4099160",
    "end": "4106270"
  },
  {
    "text": "investigating like the remote read API being streaming is actually that this",
    "start": "4106270",
    "end": "4112330"
  },
  {
    "text": "could be like an inter exchange format for both projects potentially like as I",
    "start": "4112330",
    "end": "4117670"
  },
  {
    "text": "said like this is totally exploratory I don't know if that's gonna happen but it seems some of us agree that this could",
    "start": "4117670",
    "end": "4124838"
  },
  {
    "text": "be a good direction so that because both projects essentially promised long-term",
    "start": "4124839",
    "end": "4131920"
  },
  {
    "text": "storage right if we now build a new thing and it's not compatible with the old thing then we've basically broken",
    "start": "4131920",
    "end": "4138640"
  },
  {
    "text": "that trust and we definitely don't want to do that so remote like remote read",
    "start": "4138640",
    "end": "4144338"
  },
  {
    "text": "improving that and maybe making that the API is that both of these projects work",
    "start": "4144339",
    "end": "4149440"
  },
  {
    "text": "with that wouldn't also make merging much easier I know I think on a political level I think we like we're",
    "start": "4149440",
    "end": "4154900"
  },
  {
    "text": "all good friends so we would love to work more closely together and cortex",
    "start": "4154900",
    "end": "4163028"
  },
  {
    "text": "has really cool features that tano's would like tahno says really cool features cortex would like yeah yeah no",
    "start": "4163029",
    "end": "4170679"
  },
  {
    "text": "no no we're told we're completely aligned with that making that happen is",
    "start": "4170679",
    "end": "4175810"
  },
  {
    "text": "not as easy as it sounds but we want to see I I want to see that as well I can't necessarily speak for",
    "start": "4175810",
    "end": "4182180"
  },
  {
    "text": "everyone but I want to see that as well so again I'm a huge fan of Thanos and",
    "start": "4182180",
    "end": "4188560"
  },
  {
    "text": "Tom and Bartok are in London and they go out drinking and then they and then",
    "start": "4188560",
    "end": "4194000"
  },
  {
    "text": "apparently there's an internal design talk on how to merge the two projects so",
    "start": "4194000",
    "end": "4199400"
  },
  {
    "text": "yeah it it we all want it to happen and we are working on it which type of beer",
    "start": "4199400",
    "end": "4207650"
  },
  {
    "text": "mash is that internal design talk on",
    "start": "4207650",
    "end": "4211630"
  },
  {
    "text": "there's maybe one more take on this I mean you you have currently to pain",
    "start": "4215020",
    "end": "4220670"
  },
  {
    "text": "pressure points within Prometheus when it comes to stuff which you can solve by by charting and this is basically the",
    "start": "4220670",
    "end": "4227000"
  },
  {
    "text": "index and the storage and that's why it just makes sense to address both in one single thing the other just for your",
    "start": "4227000",
    "end": "4233810"
  },
  {
    "text": "information we have this on the community site of course you like for for stuff which we want to do and such",
    "start": "4233810",
    "end": "4239239"
  },
  {
    "text": "our def summit notes are out in the open and we will probably push publish something next week or so after Q Khan",
    "start": "4239239",
    "end": "4245870"
  },
  {
    "text": "will also sit together and do Tim team-building slash dev summit so there",
    "start": "4245870",
    "end": "4252560"
  },
  {
    "text": "should probably be some results from this as well and one of the things that",
    "start": "4252560",
    "end": "4261920"
  },
  {
    "text": "the boot was like give us constructive feedback and everyone is happy which is",
    "start": "4261920",
    "end": "4270040"
  },
  {
    "text": "about long-term storage I think right",
    "start": "4270910",
    "end": "4275290"
  },
  {
    "text": "the first time I installed poetess it was maybe maybe",
    "start": "4287650",
    "end": "4293390"
  },
  {
    "text": "yeah one year ago and it was the default value for retention for 30 days and I",
    "start": "4293390",
    "end": "4298910"
  },
  {
    "text": "was like what why I set it to for 201 year",
    "start": "4298910",
    "end": "4304040"
  },
  {
    "text": "no not actually asking any question because I didn't want I did not know at",
    "start": "4304040",
    "end": "4310550"
  },
  {
    "text": "the time that the storage wasn't wasn't compliant with that kind of",
    "start": "4310550",
    "end": "4315900"
  },
  {
    "text": "retention now it is it seems it is but if you want to read one year of your data you are going to crush everything",
    "start": "4315900",
    "end": "4321600"
  },
  {
    "text": "but except if you have a huge amount of memory but yeah long-term storage is I",
    "start": "4321600",
    "end": "4331140"
  },
  {
    "text": "think something expected for from everyone which is entering your primitives from some important point of",
    "start": "4331140",
    "end": "4339840"
  },
  {
    "text": "view keep in mind that promise is coming from a place where the most important",
    "start": "4339840",
    "end": "4346110"
  },
  {
    "text": "thing is to to alert a human about things going wrong and that is one of",
    "start": "4346110",
    "end": "4351420"
  },
  {
    "text": "the core things the other if if I'm being evil I might say that Google doesn't care about anything which is",
    "start": "4351420",
    "end": "4357030"
  },
  {
    "text": "beyond 14 days so that's where that was coming from no you're not getting the mic and they have other systems in play",
    "start": "4357030",
    "end": "4365580"
  },
  {
    "text": "in place and such for anyone who has this as their own system it's obvious",
    "start": "4365580",
    "end": "4372150"
  },
  {
    "text": "that you need to have long-term retention it's it's obvious yeah we all",
    "start": "4372150",
    "end": "4377910"
  },
  {
    "text": "agree anyway so I mean we can just keep on agreeing on long-term storage but yes it's something we want to have at some",
    "start": "4377910",
    "end": "4383130"
  },
  {
    "text": "point and you the first time you come to a metric system you accept you expect it",
    "start": "4383130",
    "end": "4390840"
  },
  {
    "text": "to last forever okay just doing monitoring on the 12 hours ok yeah",
    "start": "4390840",
    "end": "4397080"
  },
  {
    "text": "so something else to keep in mind with the 15 days is that that's a default from tree storage engines ago and that",
    "start": "4397080",
    "end": "4404760"
  },
  {
    "text": "storage engine was nowhere near as efficient but it was topping out about 50,000 samples per second and yeah",
    "start": "4404760",
    "end": "4412620"
  },
  {
    "text": "that's where I comes from and we can only change that value on a major release and the proposal to change it on",
    "start": "4412620",
    "end": "4418260"
  },
  {
    "text": "v2 but it was talked about it was never actually made because it would be a breaking change for users because if we",
    "start": "4418260",
    "end": "4425610"
  },
  {
    "text": "suddenly bump that to infinity which I believe was a proposal users were on a disk space under monitoring falls over",
    "start": "4425610",
    "end": "4431520"
  },
  {
    "text": "so we will at some point presumably change that default but we can only",
    "start": "4431520",
    "end": "4436530"
  },
  {
    "text": "safely do it in a major version change and to be honest I'm not sure there ever will be a Vitry there might be at some",
    "start": "4436530",
    "end": "4442230"
  },
  {
    "text": "point but you know that that's it's it's not an easy thing to change",
    "start": "4442230",
    "end": "4448650"
  },
  {
    "text": "and it's just a misconception because especially from ETS - the question is how much disk space do you have we would",
    "start": "4448650",
    "end": "4456719"
  },
  {
    "text": "probably have a three point X just for a long-term storage but no to be fair and",
    "start": "4456719",
    "end": "4463139"
  },
  {
    "text": "and I mean there's this more like of a discussion here in front and not so much Q&A but this 14 days thing is stuck in",
    "start": "4463139",
    "end": "4471179"
  },
  {
    "text": "the head of a lot of early adopters and to me it caused a lot of damage in in",
    "start": "4471179",
    "end": "4476699"
  },
  {
    "text": "the mind share of the community of course it was something which a lot of people just fundamentally disagreed with",
    "start": "4476699",
    "end": "4482489"
  },
  {
    "text": "and for various reasons back then that was the thing which was officially",
    "start": "4482489",
    "end": "4487679"
  },
  {
    "text": "recommended you could do it otherwise but so yeah and I mean we see this this",
    "start": "4487679",
    "end": "4493170"
  },
  {
    "text": "is still this stuff which people approach us most about course this is what hurt them back then and they still",
    "start": "4493170",
    "end": "4498239"
  },
  {
    "text": "have this at the back of their head yeah and nowadays I try to sell Prometheus as a metrics based monitoring and alerting",
    "start": "4498239",
    "end": "4504510"
  },
  {
    "text": "stack and I don't even mention time series database or well I say it happens to include a time series database for",
    "start": "4504510",
    "end": "4510270"
  },
  {
    "text": "that purpose but it's not a time series database front and center so it's pretty",
    "start": "4510270",
    "end": "4517050"
  },
  {
    "text": "specialized one for systems monitoring",
    "start": "4517050",
    "end": "4521360"
  },
  {
    "text": "actually and this is mainly just for the thinness and the the cortex owners I",
    "start": "4523579",
    "end": "4530670"
  },
  {
    "text": "know Tom's not here but ya know I think I I would love to ask a question of you",
    "start": "4530670",
    "end": "4536730"
  },
  {
    "text": "know if there's any interest essentially and like looking at other open-source long-term storage projects to work to",
    "start": "4536730",
    "end": "4544020"
  },
  {
    "text": "work with when when you consider I guess like a more longer-term plan for a Prometheus native long term store I know",
    "start": "4544020",
    "end": "4552030"
  },
  {
    "text": "that just something the indexing side at least you know a lot of work has gone into obviously I have a bias and there's",
    "start": "4552030",
    "end": "4558719"
  },
  {
    "text": "a reason I'm asking this question it's because I'm the the maintainer of three which is an open source long term",
    "start": "4558719",
    "end": "4564869"
  },
  {
    "text": "storage but you know I think we are heavy a users of Prometheus Pronk you",
    "start": "4564869",
    "end": "4571590"
  },
  {
    "text": "all we love the ecosystem we'd love to be more involved so",
    "start": "4571590",
    "end": "4576749"
  },
  {
    "text": "maybe this is not the right format to be asking the question I mean we try it",
    "start": "4576749",
    "end": "4583590"
  },
  {
    "text": "like we are impressed by the insane scale at m3 has you have more scale than",
    "start": "4583590",
    "end": "4588719"
  },
  {
    "text": "any of us here which is like insane which super impressed and we've actually",
    "start": "4588719",
    "end": "4596579"
  },
  {
    "text": "looked at m3 like I know Fabian looked at m3 before starting Thanos and there was no",
    "start": "4596579",
    "end": "4603150"
  },
  {
    "text": "documentation back then and we've tried to open issue says like yeah if it's all",
    "start": "4603150",
    "end": "4608219"
  },
  {
    "text": "a big huge black box that too complex back then it I think it changed a lot",
    "start": "4608219",
    "end": "4613949"
  },
  {
    "text": "now and we should take another look but yeah I mean if like it just happens that",
    "start": "4613949",
    "end": "4620539"
  },
  {
    "text": "we know tano's has a lot of great things codex's a lot of great things but we should also look at what m3 can add to",
    "start": "4620539",
    "end": "4627030"
  },
  {
    "text": "the table given the scale and everything that you've achieved also yeah cuz I don't want to add like these things like",
    "start": "4627030",
    "end": "4633989"
  },
  {
    "text": "backup 3 in GC GC yes I actually don't want to add that to him",
    "start": "4633989",
    "end": "4639900"
  },
  {
    "text": "and that's this definitely use case for some of like the longer term retention clusters that we have we'd prefer to",
    "start": "4639900",
    "end": "4646469"
  },
  {
    "text": "actually do that especially where the like the right load isn't very high you know not all metrics are kept for three",
    "start": "4646469",
    "end": "4653070"
  },
  {
    "text": "years is only usually a subset so there's definitely some of the features entry would love to you know have from",
    "start": "4653070",
    "end": "4658320"
  },
  {
    "text": "from Thanos and and some and multi-tenancy stuff is probably less",
    "start": "4658320",
    "end": "4663329"
  },
  {
    "text": "important to humor so but it would be great to have as well so yeah again like",
    "start": "4663329",
    "end": "4670979"
  },
  {
    "text": "the whole point about the mergers first we actually come come come up with common interfaces that Thanos and cortex",
    "start": "4670979",
    "end": "4679130"
  },
  {
    "text": "like integrate with and in the end like you can you can done a component of",
    "start": "4679130",
    "end": "4684239"
  },
  {
    "text": "Thanos and you can own a component of cortex because they're the same api s-- and m3 could come in implement those",
    "start": "4684239",
    "end": "4690239"
  },
  {
    "text": "same api sand you you could also swap it within three",
    "start": "4690239",
    "end": "4694760"
  },
  {
    "text": "okay so we are Prairie closing four minutes early so we are probably closing",
    "start": "4703870",
    "end": "4710840"
  },
  {
    "text": "four minutes early thank you very much for staying until the end come by the booth grab free stickers or a notebook",
    "start": "4710840",
    "end": "4718100"
  },
  {
    "text": "or something we have them under the table but if you ask for them yeah thank",
    "start": "4718100",
    "end": "4724580"
  },
  {
    "text": "you very much and see you again soon [Applause]",
    "start": "4724580",
    "end": "4730020"
  }
]
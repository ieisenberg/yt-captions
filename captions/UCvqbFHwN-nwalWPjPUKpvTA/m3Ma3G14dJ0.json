[
  {
    "start": "0",
    "end": "88000"
  },
  {
    "text": "okay hello my name is Martin Vegas for",
    "start": "1550",
    "end": "6690"
  },
  {
    "text": "the last two years I have been a part of",
    "start": "6690",
    "end": "9599"
  },
  {
    "text": "the kubernetes team focusing primarily",
    "start": "9599",
    "end": "11490"
  },
  {
    "text": "on how to scaling and Federation and",
    "start": "11490",
    "end": "14670"
  },
  {
    "text": "auto scaling will be the topic of",
    "start": "14670",
    "end": "16440"
  },
  {
    "text": "today's presentation let's start with a",
    "start": "16440",
    "end": "20789"
  },
  {
    "text": "quite common of historic a dev a person",
    "start": "20789",
    "end": "23730"
  },
  {
    "text": "meet a software engineer at the",
    "start": "23730",
    "end": "25230"
  },
  {
    "text": "watercooler",
    "start": "25230",
    "end": "26029"
  },
  {
    "text": "and the first one asked we are closing",
    "start": "26029",
    "end": "30420"
  },
  {
    "text": "the budget for q2 how many nodes will",
    "start": "30420",
    "end": "32910"
  },
  {
    "text": "you need in your newest project and this",
    "start": "32910",
    "end": "36480"
  },
  {
    "text": "software engineer scratches his head and",
    "start": "36480",
    "end": "38940"
  },
  {
    "text": "says well gosh I don't know or maybe if",
    "start": "38940",
    "end": "42239"
  },
  {
    "text": "he or she around some artificial tests",
    "start": "42239",
    "end": "44760"
  },
  {
    "text": "and learned it for every 500 QPS",
    "start": "44760",
    "end": "47100"
  },
  {
    "text": "there is a need for an additional web",
    "start": "47100",
    "end": "48960"
  },
  {
    "text": "server or maybe he did some analysis and",
    "start": "48960",
    "end": "52199"
  },
  {
    "text": "estimated that four servers would",
    "start": "52199",
    "end": "54600"
  },
  {
    "text": "probably be enough even on spikes but",
    "start": "54600",
    "end": "57059"
  },
  {
    "text": "quite probable is that to be on the safe",
    "start": "57059",
    "end": "60239"
  },
  {
    "text": "side he will ask for five six maybe even",
    "start": "60239",
    "end": "63750"
  },
  {
    "text": "seven machines so the conversation as",
    "start": "63750",
    "end": "67619"
  },
  {
    "text": "ends with I need seven the software",
    "start": "67619",
    "end": "71490"
  },
  {
    "text": "engineer is happy defended of the",
    "start": "71490",
    "end": "73170"
  },
  {
    "text": "question he provided an estimate which",
    "start": "73170",
    "end": "75150"
  },
  {
    "text": "is quite random and much bigger than the",
    "start": "75150",
    "end": "77159"
  },
  {
    "text": "real nice but hell no one likes to be a",
    "start": "77159",
    "end": "79500"
  },
  {
    "text": "page in the middle of the night and",
    "start": "79500",
    "end": "81000"
  },
  {
    "text": "responsible for the downtime and the",
    "start": "81000",
    "end": "83280"
  },
  {
    "text": "company pays couple times more than it's",
    "start": "83280",
    "end": "85890"
  },
  {
    "text": "actually needed before this presentation",
    "start": "85890",
    "end": "89939"
  },
  {
    "start": "88000",
    "end": "88000"
  },
  {
    "text": "I tried to Google what is the average",
    "start": "89939",
    "end": "91680"
  },
  {
    "text": "enterprise data utilization I saw",
    "start": "91680",
    "end": "94229"
  },
  {
    "text": "various numbers depending on who and how",
    "start": "94229",
    "end": "96659"
  },
  {
    "text": "I was counting and I was quite surprised",
    "start": "96659",
    "end": "100200"
  },
  {
    "start": "100000",
    "end": "100000"
  },
  {
    "text": "by the number rarely very rarely got to",
    "start": "100200",
    "end": "103829"
  },
  {
    "text": "the level of 15% so over-provisioning is",
    "start": "103829",
    "end": "108060"
  },
  {
    "text": "a fact there are many reasons why people",
    "start": "108060",
    "end": "113159"
  },
  {
    "start": "110000",
    "end": "110000"
  },
  {
    "text": "over provision let me focus on a couple",
    "start": "113159",
    "end": "115770"
  },
  {
    "text": "of them first of all it's hard to",
    "start": "115770",
    "end": "118170"
  },
  {
    "text": "predict what the tough world real",
    "start": "118170",
    "end": "119880"
  },
  {
    "text": "traffic will be it changes depending on",
    "start": "119880",
    "end": "123149"
  },
  {
    "text": "time of day day of week there are spikes",
    "start": "123149",
    "end": "125939"
  },
  {
    "text": "on some events like New Year or",
    "start": "125939",
    "end": "127740"
  },
  {
    "text": "Superbowl it can be hard to change the",
    "start": "127740",
    "end": "131039"
  },
  {
    "text": "deployment or maybe not so hard but it",
    "start": "131039",
    "end": "133710"
  },
  {
    "text": "will require manual intervention and",
    "start": "133710",
    "end": "135960"
  },
  {
    "text": "nobody likes manual intervention so in",
    "start": "135960",
    "end": "138720"
  },
  {
    "text": "the absence of proper automation we over",
    "start": "138720",
    "end": "141630"
  },
  {
    "text": "provision but there is another way",
    "start": "141630",
    "end": "145700"
  },
  {
    "text": "auto-scaling auto-scaling is an ability",
    "start": "145700",
    "end": "148650"
  },
  {
    "text": "of a system to automatically scale to",
    "start": "148650",
    "end": "151440"
  },
  {
    "text": "the current needs it's a very nice",
    "start": "151440",
    "end": "153180"
  },
  {
    "text": "things which we are in comparing",
    "start": "153180",
    "end": "154980"
  },
  {
    "text": "incorporating into kubernetes in couple",
    "start": "154980",
    "end": "158100"
  },
  {
    "text": "places I will go through these places so",
    "start": "158100",
    "end": "162660"
  },
  {
    "start": "160000",
    "end": "160000"
  },
  {
    "text": "first of all we have horizontal Patil to",
    "start": "162660",
    "end": "165690"
  },
  {
    "text": "scale which controls the number of",
    "start": "165690",
    "end": "167370"
  },
  {
    "text": "replicas in the deployment then we have",
    "start": "167370",
    "end": "170220"
  },
  {
    "text": "cluster autoscaler which controls the",
    "start": "170220",
    "end": "172020"
  },
  {
    "text": "number of nodes in the cluster and",
    "start": "172020",
    "end": "174320"
  },
  {
    "text": "vertical path autoscaler which is",
    "start": "174320",
    "end": "176340"
  },
  {
    "text": "currently being designed and which will",
    "start": "176340",
    "end": "178290"
  },
  {
    "text": "control the amount of requested CPU and",
    "start": "178290",
    "end": "180810"
  },
  {
    "text": "memory for a pod let's start with",
    "start": "180810",
    "end": "186480"
  },
  {
    "text": "replica count and horizontal cut out the",
    "start": "186480",
    "end": "188700"
  },
  {
    "text": "scaler what files into scope of",
    "start": "188700",
    "end": "193560"
  },
  {
    "start": "190000",
    "end": "190000"
  },
  {
    "text": "horizontal scaling so when auto scaling",
    "start": "193560",
    "end": "198080"
  },
  {
    "text": "replicas count we want to ensure that",
    "start": "198080",
    "end": "201390"
  },
  {
    "text": "these replicas get a decent load that it",
    "start": "201390",
    "end": "207530"
  },
  {
    "text": "that each pot that consumes the",
    "start": "208160",
    "end": "210450"
  },
  {
    "text": "resources in the cluster has a reason to",
    "start": "210450",
    "end": "212760"
  },
  {
    "text": "be there",
    "start": "212760",
    "end": "213120"
  },
  {
    "text": "so it's not one in the result of some",
    "start": "213120",
    "end": "215960"
  },
  {
    "text": "estimation that went completely off we",
    "start": "215960",
    "end": "219240"
  },
  {
    "text": "also want to ensure that there is an",
    "start": "219240",
    "end": "221220"
  },
  {
    "text": "immediate redundancy so if a machine or",
    "start": "221220",
    "end": "223800"
  },
  {
    "text": "a pod crashes the service will be still",
    "start": "223800",
    "end": "226080"
  },
  {
    "text": "up and running and we also want to",
    "start": "226080",
    "end": "228810"
  },
  {
    "text": "operate within the quadrant budget what",
    "start": "228810",
    "end": "232830"
  },
  {
    "start": "232000",
    "end": "232000"
  },
  {
    "text": "does it exactly mean to maintain the",
    "start": "232830",
    "end": "234810"
  },
  {
    "text": "decent load here we have an example four",
    "start": "234810",
    "end": "238710"
  },
  {
    "text": "parts each running with really high CPU",
    "start": "238710",
    "end": "245520"
  },
  {
    "text": "usage if the traffic increases there",
    "start": "245520",
    "end": "249420"
  },
  {
    "text": "will be no capacity within the post to",
    "start": "249420",
    "end": "252000"
  },
  {
    "text": "handle it so in this case we would",
    "start": "252000",
    "end": "254580"
  },
  {
    "text": "probably like to start a new pod and",
    "start": "254580",
    "end": "258930"
  },
  {
    "text": "then the new pod will get the part of",
    "start": "258930",
    "end": "261480"
  },
  {
    "text": "the traffic and the average load on the",
    "start": "261480",
    "end": "264830"
  },
  {
    "text": "deployment will decrease so we'll have",
    "start": "264830",
    "end": "267300"
  },
  {
    "text": "more space for our future traffic spikes",
    "start": "267300",
    "end": "271490"
  },
  {
    "text": "here is the case where odds are not so",
    "start": "271490",
    "end": "276030"
  },
  {
    "text": "utilized we have five of them they are",
    "start": "276030",
    "end": "278580"
  },
  {
    "text": "running on 40% one could say that 60% of",
    "start": "278580",
    "end": "282840"
  },
  {
    "text": "resources is wasted so why don't we",
    "start": "282840",
    "end": "287520"
  },
  {
    "text": "remove one of the node one of the pots",
    "start": "287520",
    "end": "291150"
  },
  {
    "text": "the others will take the traffic and the",
    "start": "291150",
    "end": "294210"
  },
  {
    "text": "utilization will decrease and the free",
    "start": "294210",
    "end": "298020"
  },
  {
    "text": "space after the fifth spot can be used",
    "start": "298020",
    "end": "301199"
  },
  {
    "text": "by someone else all in all we want to",
    "start": "301199",
    "end": "306659"
  },
  {
    "text": "specify the target for the load and",
    "start": "306659",
    "end": "309139"
  },
  {
    "text": "automatically adjust the number of",
    "start": "309139",
    "end": "311280"
  },
  {
    "text": "replicas so that the on average the load",
    "start": "311280",
    "end": "315569"
  },
  {
    "text": "is as close to the target as possible",
    "start": "315569",
    "end": "319430"
  },
  {
    "text": "here is a sample form or does it look",
    "start": "319430",
    "end": "322949"
  },
  {
    "text": "scary but if you look closer it's not so",
    "start": "322949",
    "end": "325949"
  },
  {
    "text": "complicated it sounds the usage of pots",
    "start": "325949",
    "end": "328620"
  },
  {
    "text": "divided by target rounds up and we are",
    "start": "328620",
    "end": "331949"
  },
  {
    "text": "done",
    "start": "331949",
    "end": "332599"
  },
  {
    "text": "how does it work in practice imagine",
    "start": "332599",
    "end": "336360"
  },
  {
    "text": "that we have two pots that are running",
    "start": "336360",
    "end": "338340"
  },
  {
    "text": "at 70 and 80% of CPU and we are",
    "start": "338340",
    "end": "343020"
  },
  {
    "text": "specifying the target of 50% the sum of",
    "start": "343020",
    "end": "346590"
  },
  {
    "text": "the uses is 150 150 divided by fifty",
    "start": "346590",
    "end": "351479"
  },
  {
    "text": "gives free and this is these are these",
    "start": "351479",
    "end": "353849"
  },
  {
    "text": "free replicas that we want to have to",
    "start": "353849",
    "end": "356009"
  },
  {
    "text": "maintain the desired load we are talking",
    "start": "356009",
    "end": "361380"
  },
  {
    "start": "359000",
    "end": "359000"
  },
  {
    "text": "about the usage and what exactly the use",
    "start": "361380",
    "end": "363960"
  },
  {
    "text": "it is as you know each part can declare",
    "start": "363960",
    "end": "367020"
  },
  {
    "text": "how much CPU it should get or actually",
    "start": "367020",
    "end": "370080"
  },
  {
    "text": "its container should get the value is",
    "start": "370080",
    "end": "372599"
  },
  {
    "text": "used for pot scheduling a pot requesting",
    "start": "372599",
    "end": "375389"
  },
  {
    "text": "to scipios will go only to a node which",
    "start": "375389",
    "end": "377729"
  },
  {
    "text": "actually has this two CPUs free knowing",
    "start": "377729",
    "end": "381120"
  },
  {
    "text": "the relation between the current CPU",
    "start": "381120",
    "end": "383279"
  },
  {
    "text": "consumption and the declared maximum you",
    "start": "383279",
    "end": "385409"
  },
  {
    "text": "scan we can easily tell whether there is",
    "start": "385409",
    "end": "388979"
  },
  {
    "text": "some capacity left in the pot or not so",
    "start": "388979",
    "end": "392400"
  },
  {
    "text": "if your pot requested three hundred",
    "start": "392400",
    "end": "394259"
  },
  {
    "text": "milli cards and current is consuming 200",
    "start": "394259",
    "end": "396570"
  },
  {
    "text": "milli cones then the usage is 66% and if",
    "start": "396570",
    "end": "401210"
  },
  {
    "text": "it goes beyond to the request and",
    "start": "401210",
    "end": "402800"
  },
  {
    "text": "consume so let's say four hundred",
    "start": "402800",
    "end": "404139"
  },
  {
    "text": "miracles and the usage is 133 percent",
    "start": "404139",
    "end": "408229"
  },
  {
    "text": "and this percentage is quite descriptive",
    "start": "408229",
    "end": "412330"
  },
  {
    "text": "operating on the ratio instead of row",
    "start": "412330",
    "end": "414919"
  },
  {
    "text": "values the couples HPA configuration",
    "start": "414919",
    "end": "417770"
  },
  {
    "text": "from pod definition and once you",
    "start": "417770",
    "end": "420490"
  },
  {
    "text": "understand it it's quite easy to handle",
    "start": "420490",
    "end": "424419"
  },
  {
    "text": "okay so I've showed you some basic",
    "start": "424419",
    "end": "427610"
  },
  {
    "text": "formula the reality unfortunately is a",
    "start": "427610",
    "end": "430639"
  },
  {
    "text": "little bit more complex horizontal pod",
    "start": "430639",
    "end": "433250"
  },
  {
    "text": "autoscaler needs to take care about a",
    "start": "433250",
    "end": "435740"
  },
  {
    "text": "couple of other important details",
    "start": "435740",
    "end": "437660"
  },
  {
    "text": "first of all merchants we don't want to",
    "start": "437660",
    "end": "440900"
  },
  {
    "text": "go from three replicas to foreign",
    "start": "440900",
    "end": "442639"
  },
  {
    "text": "applicants back and back every ten",
    "start": "442639",
    "end": "445340"
  },
  {
    "text": "minutes just because the traffic changed",
    "start": "445340",
    "end": "447380"
  },
  {
    "text": "by two percent so there is a reasonable",
    "start": "447380",
    "end": "449900"
  },
  {
    "text": "margin around this formula some pods are",
    "start": "449900",
    "end": "453289"
  },
  {
    "text": "ready some pods are starting and their",
    "start": "453289",
    "end": "456680"
  },
  {
    "text": "usage is not representative for the",
    "start": "456680",
    "end": "459050"
  },
  {
    "text": "whole population and they should not be",
    "start": "459050",
    "end": "460940"
  },
  {
    "text": "and they should be included into formula",
    "start": "460940",
    "end": "463039"
  },
  {
    "text": "in a slightly different way in the end",
    "start": "463039",
    "end": "466550"
  },
  {
    "text": "some metrics may be broken or simply",
    "start": "466550",
    "end": "469190"
  },
  {
    "text": "missing and we should also have a",
    "start": "469190",
    "end": "472490"
  },
  {
    "text": "special handling for sudden spikes all",
    "start": "472490",
    "end": "475099"
  },
  {
    "text": "in all we put a lot of logic into",
    "start": "475099",
    "end": "478580"
  },
  {
    "text": "horizontal path autoscaler in order to",
    "start": "478580",
    "end": "481070"
  },
  {
    "text": "make it work really really well for the",
    "start": "481070",
    "end": "482900"
  },
  {
    "text": "users okay how to turn it on it's really",
    "start": "482900",
    "end": "486949"
  },
  {
    "text": "simple you can do it with just a single",
    "start": "486949",
    "end": "490340"
  },
  {
    "text": "cube CTL comment you specify the minimum",
    "start": "490340",
    "end": "493219"
  },
  {
    "text": "and the maximum size of your deployment",
    "start": "493219",
    "end": "495169"
  },
  {
    "text": "and the target CPU use it and your",
    "start": "495169",
    "end": "501070"
  },
  {
    "text": "deployment is of the scales after this",
    "start": "501070",
    "end": "503150"
  },
  {
    "text": "this is comment a few words how it works",
    "start": "503150",
    "end": "507229"
  },
  {
    "start": "505000",
    "end": "505000"
  },
  {
    "text": "under the hood as you know pods run on",
    "start": "507229",
    "end": "510409"
  },
  {
    "text": "notes and on note there is an agent",
    "start": "510409",
    "end": "513229"
  },
  {
    "text": "called cubelet each cube let get basic",
    "start": "513229",
    "end": "516200"
  },
  {
    "text": "metrics like CPU or memory usage from",
    "start": "516200",
    "end": "518690"
  },
  {
    "text": "the poles and containers that are",
    "start": "518690",
    "end": "520010"
  },
  {
    "text": "running on the node then every one",
    "start": "520010",
    "end": "522740"
  },
  {
    "text": "minute or more often depending on your",
    "start": "522740",
    "end": "525079"
  },
  {
    "text": "individual configuration hipster gas",
    "start": "525079",
    "end": "527300"
  },
  {
    "text": "this matrix from cubelets and aggregates",
    "start": "527300",
    "end": "529490"
  },
  {
    "text": "them and make them available for HPA",
    "start": "529490",
    "end": "532610"
  },
  {
    "text": "by a well-defined master",
    "start": "532610",
    "end": "534420"
  },
  {
    "text": "metrics api HP ike horizontal put of the",
    "start": "534420",
    "end": "538470"
  },
  {
    "text": "scanner controller periodically checks",
    "start": "538470",
    "end": "540480"
  },
  {
    "text": "do node and adjust the replica calls on",
    "start": "540480",
    "end": "542910"
  },
  {
    "text": "the controller deployments so for HP i",
    "start": "542910",
    "end": "547050"
  },
  {
    "text": "it is critical that hipster is up and",
    "start": "547050",
    "end": "549810"
  },
  {
    "text": "running",
    "start": "549810",
    "end": "551089"
  },
  {
    "text": "what else is important so I cannot put",
    "start": "551089",
    "end": "555779"
  },
  {
    "start": "553000",
    "end": "553000"
  },
  {
    "text": "less emphasis on this declare request",
    "start": "555779",
    "end": "558449"
  },
  {
    "text": "for pots it's critical not only for HP i",
    "start": "558449",
    "end": "560790"
  },
  {
    "text": "but without request HP l won't work at",
    "start": "560790",
    "end": "564720"
  },
  {
    "text": "all set the target well below 100% so to",
    "start": "564720",
    "end": "573120"
  },
  {
    "text": "explain it i will show you what happens",
    "start": "573120",
    "end": "575760"
  },
  {
    "text": "when you set the target to 70% so this",
    "start": "575760",
    "end": "580139"
  },
  {
    "text": "green pink here is your slug the bigger",
    "start": "580139",
    "end": "583800"
  },
  {
    "text": "it is the more of sudden traffic you can",
    "start": "583800",
    "end": "585810"
  },
  {
    "text": "handle in the pod before the new HP are",
    "start": "585810",
    "end": "588899"
  },
  {
    "text": "started pots are up and running so",
    "start": "588899",
    "end": "591209"
  },
  {
    "text": "please pay attention to it also this",
    "start": "591209",
    "end": "594870"
  },
  {
    "text": "green thing is what scares up your",
    "start": "594870",
    "end": "598440"
  },
  {
    "text": "deployment you can look at it as the",
    "start": "598440",
    "end": "600810"
  },
  {
    "text": "amount of traffic that will go to your",
    "start": "600810",
    "end": "603390"
  },
  {
    "text": "new pots if you set the target too high",
    "start": "603390",
    "end": "610190"
  },
  {
    "text": "you might have no ability to handle the",
    "start": "610190",
    "end": "613380"
  },
  {
    "text": "extra traffic here",
    "start": "613380",
    "end": "615440"
  },
  {
    "text": "you remember that 100% is basically what",
    "start": "615440",
    "end": "621149"
  },
  {
    "text": "you asked in your pot requests there may",
    "start": "621149",
    "end": "623610"
  },
  {
    "text": "be some free cycles on your machine and",
    "start": "623610",
    "end": "626640"
  },
  {
    "text": "you may go above 100% but you should not",
    "start": "626640",
    "end": "632459"
  },
  {
    "text": "count of it also this er red bar may be",
    "start": "632459",
    "end": "636449"
  },
  {
    "text": "too small to trigger a decent scale up",
    "start": "636449",
    "end": "639449"
  },
  {
    "text": "or any scale up at all because of the",
    "start": "639449",
    "end": "642149"
  },
  {
    "text": "margins so if you are noticed fully",
    "start": "642149",
    "end": "644970"
  },
  {
    "text": "packed and you've said this type of",
    "start": "644970",
    "end": "647640"
  },
  {
    "text": "usage you may have real real troubles",
    "start": "647640",
    "end": "652279"
  },
  {
    "text": "also keep your pots and not healthy if a",
    "start": "652550",
    "end": "657269"
  },
  {
    "text": "pot is blocks it decreases your average",
    "start": "657269",
    "end": "660089"
  },
  {
    "text": "usage and it may actually scale you down",
    "start": "660089",
    "end": "663959"
  },
  {
    "text": "for example if one pot is at 0% and the",
    "start": "663959",
    "end": "667769"
  },
  {
    "text": "other one is fee at 50 and the target is",
    "start": "667769",
    "end": "670559"
  },
  {
    "text": "also at 50 then the deployment may scare",
    "start": "670559",
    "end": "674129"
  },
  {
    "text": "and then the controller might scale your",
    "start": "674129",
    "end": "676170"
  },
  {
    "text": "deployment to just one pot and if you",
    "start": "676170",
    "end": "678720"
  },
  {
    "text": "are unlucky it may kill the healthy part",
    "start": "678720",
    "end": "682679"
  },
  {
    "text": "so you will end up with the broken pot",
    "start": "682679",
    "end": "685860"
  },
  {
    "text": "which is which is bad so use liveness",
    "start": "685860",
    "end": "689429"
  },
  {
    "text": "probe to ensure that your thoughts are",
    "start": "689429",
    "end": "691769"
  },
  {
    "text": "always up and running there are two",
    "start": "691769",
    "end": "696929"
  },
  {
    "text": "comments that may help you to tell what",
    "start": "696929",
    "end": "698879"
  },
  {
    "text": "is going on with your pots first of all",
    "start": "698879",
    "end": "701699"
  },
  {
    "text": "is cube CTL top which brings the usage",
    "start": "701699",
    "end": "704579"
  },
  {
    "text": "and memory consumption on your notes and",
    "start": "704579",
    "end": "707910"
  },
  {
    "text": "pots there is also Q CTL discourage API",
    "start": "707910",
    "end": "711059"
  },
  {
    "text": "which tells you here what is the current",
    "start": "711059",
    "end": "717540"
  },
  {
    "text": "level and what decisions were made by",
    "start": "717540",
    "end": "721290"
  },
  {
    "text": "the horizontal path autoscaler so you",
    "start": "721290",
    "end": "723749"
  },
  {
    "text": "can understand it mekinese butter CPU is",
    "start": "723749",
    "end": "730199"
  },
  {
    "text": "not perfect for everyone some work roads",
    "start": "730199",
    "end": "732660"
  },
  {
    "text": "are better scaled based on custom",
    "start": "732660",
    "end": "734759"
  },
  {
    "text": "metrics with 1.6 we are adding a support",
    "start": "734759",
    "end": "737970"
  },
  {
    "text": "for custom metrics in HPI that will",
    "start": "737970",
    "end": "740549"
  },
  {
    "text": "hopefully show its full petition in 1.7",
    "start": "740549",
    "end": "743549"
  },
  {
    "text": "so stay tuned and take a look at this",
    "start": "743549",
    "end": "745860"
  },
  {
    "text": "custom metrics in 1.6 also make sure",
    "start": "745860",
    "end": "752100"
  },
  {
    "text": "that your requests are sold short and",
    "start": "752100",
    "end": "755699"
  },
  {
    "text": "well load balanced between spots",
    "start": "755699",
    "end": "758220"
  },
  {
    "text": "otherwise the new pot won't take the",
    "start": "758220",
    "end": "761249"
  },
  {
    "text": "load and the load will remain on the old",
    "start": "761249",
    "end": "763769"
  },
  {
    "text": "pots enough for HPA let's focus a little",
    "start": "763769",
    "end": "769679"
  },
  {
    "text": "bit on the number of nodes in the",
    "start": "769679",
    "end": "771240"
  },
  {
    "text": "cluster",
    "start": "771240",
    "end": "773269"
  },
  {
    "text": "setting the proper number of nodes in",
    "start": "775570",
    "end": "777860"
  },
  {
    "start": "776000",
    "end": "776000"
  },
  {
    "text": "the cluster is quite complex it's almost",
    "start": "777860",
    "end": "780380"
  },
  {
    "text": "a philosophical problem so all port",
    "start": "780380",
    "end": "783740"
  },
  {
    "text": "should have a place to live",
    "start": "783740",
    "end": "786400"
  },
  {
    "text": "pots are created and deleted so the need",
    "start": "786400",
    "end": "790850"
  },
  {
    "text": "for the node changes in time as we",
    "start": "790850",
    "end": "796150"
  },
  {
    "text": "discussed in a moment ago there is",
    "start": "796150",
    "end": "799550"
  },
  {
    "text": "horizontal pot autoscaler",
    "start": "799550",
    "end": "801020"
  },
  {
    "text": "which is exactly about changing the",
    "start": "801020",
    "end": "803210"
  },
  {
    "text": "number of pots note account should",
    "start": "803210",
    "end": "806090"
  },
  {
    "text": "follow HP activity if there is a need",
    "start": "806090",
    "end": "809900"
  },
  {
    "text": "for new pots to handle the traffic the",
    "start": "809900",
    "end": "812390"
  },
  {
    "text": "node count may have to be increased so",
    "start": "812390",
    "end": "814760"
  },
  {
    "text": "that the HP I control pots have the",
    "start": "814760",
    "end": "817550"
  },
  {
    "text": "place to run so the note card good for",
    "start": "817550",
    "end": "822770"
  },
  {
    "text": "now may be bad for tomorrow or maybe",
    "start": "822770",
    "end": "825710"
  },
  {
    "text": "even in one hour on 10 minutes note are",
    "start": "825710",
    "end": "830930"
  },
  {
    "text": "expensive you pay for them on your cloud",
    "start": "830930",
    "end": "833180"
  },
  {
    "text": "providers souls being spent drift is bad",
    "start": "833180",
    "end": "836660"
  },
  {
    "text": "on the other hand pots are important",
    "start": "836660",
    "end": "839840"
  },
  {
    "text": "they earn new money they run your",
    "start": "839840",
    "end": "841760"
  },
  {
    "text": "business so being stingy with them is",
    "start": "841760",
    "end": "843710"
  },
  {
    "text": "also bad so as you can see it's a",
    "start": "843710",
    "end": "847640"
  },
  {
    "text": "complex problem and to handle this",
    "start": "847640",
    "end": "850280"
  },
  {
    "text": "problem especially at a larger scale",
    "start": "850280",
    "end": "852230"
  },
  {
    "text": "proper automation is needed but what",
    "start": "852230",
    "end": "855440"
  },
  {
    "text": "should it look like simplifying a bit",
    "start": "855440",
    "end": "859220"
  },
  {
    "start": "858000",
    "end": "858000"
  },
  {
    "text": "pots are scheduled based on their",
    "start": "859220",
    "end": "861410"
  },
  {
    "text": "declared resource requests if there is",
    "start": "861410",
    "end": "865250"
  },
  {
    "text": "enough resources on a node a pot can be",
    "start": "865250",
    "end": "867590"
  },
  {
    "text": "scheduled like this green one over here",
    "start": "867590",
    "end": "873140"
  },
  {
    "text": "it can be placed on the node with a",
    "start": "873140",
    "end": "875150"
  },
  {
    "text": "small yellow pot however if all of the",
    "start": "875150",
    "end": "879710"
  },
  {
    "text": "nodes are kind of busy then we don't",
    "start": "879710",
    "end": "882470"
  },
  {
    "text": "have a place to put the green pot so a",
    "start": "882470",
    "end": "885770"
  },
  {
    "text": "new node should be provided and the",
    "start": "885770",
    "end": "888920"
  },
  {
    "text": "green pot will go there and sometimes",
    "start": "888920",
    "end": "894350"
  },
  {
    "text": "there is too many resources in your",
    "start": "894350",
    "end": "896600"
  },
  {
    "text": "cluster for example the node number",
    "start": "896600",
    "end": "899089"
  },
  {
    "text": "three and number five have little",
    "start": "899089",
    "end": "901610"
  },
  {
    "text": "utilization they have only this small",
    "start": "901610",
    "end": "904160"
  },
  {
    "text": "yellow and green pots we could move the",
    "start": "904160",
    "end": "907490"
  },
  {
    "text": "green pot for",
    "start": "907490",
    "end": "908680"
  },
  {
    "text": "not number five to node number three and",
    "start": "908680",
    "end": "911999"
  },
  {
    "text": "then the last node will be empty and",
    "start": "911999",
    "end": "914649"
  },
  {
    "text": "could be removed and that's exactly what",
    "start": "914649",
    "end": "917499"
  },
  {
    "text": "cluster autoscaler does it tries to add",
    "start": "917499",
    "end": "920499"
  },
  {
    "text": "nodes when there they are needed and to",
    "start": "920499",
    "end": "923290"
  },
  {
    "text": "remove them when they are not so needed",
    "start": "923290",
    "end": "925929"
  },
  {
    "text": "anymore",
    "start": "925929",
    "end": "926589"
  },
  {
    "text": "possibly resulting the pulse a bit let's",
    "start": "926589",
    "end": "931990"
  },
  {
    "text": "take a look at the overall architecture",
    "start": "931990",
    "end": "935429"
  },
  {
    "text": "so cluster autoscaler",
    "start": "935429",
    "end": "937959"
  },
  {
    "text": "Randi is separate but usually on the",
    "start": "937959",
    "end": "940449"
  },
  {
    "text": "master node it maintains API server",
    "start": "940449",
    "end": "943149"
  },
  {
    "text": "watches on all nodes and all pots in the",
    "start": "943149",
    "end": "945579"
  },
  {
    "text": "cluster it talks to your cloud provider",
    "start": "945579",
    "end": "947819"
  },
  {
    "text": "you are running clock cluster on it",
    "start": "947819",
    "end": "950860"
  },
  {
    "text": "doesn't use any matrix contrary to",
    "start": "950860",
    "end": "953230"
  },
  {
    "text": "horizontal path autoscaler like I know",
    "start": "953230",
    "end": "955779"
  },
  {
    "text": "currency P lot or whatever it just",
    "start": "955779",
    "end": "958499"
  },
  {
    "text": "focuses on the API objects inside of the",
    "start": "958499",
    "end": "961660"
  },
  {
    "text": "API server like pods and nodes and their",
    "start": "961660",
    "end": "964059"
  },
  {
    "text": "current state nodes in cluster",
    "start": "964059",
    "end": "968470"
  },
  {
    "start": "966000",
    "end": "966000"
  },
  {
    "text": "autoscaler are evaluated in node groups",
    "start": "968470",
    "end": "971290"
  },
  {
    "text": "there is an assumption that all nodes",
    "start": "971290",
    "end": "974050"
  },
  {
    "text": "inside of a single node group are",
    "start": "974050",
    "end": "977649"
  },
  {
    "text": "similar or they look more or less the",
    "start": "977649",
    "end": "980649"
  },
  {
    "text": "same so on Google it operates on Manatee",
    "start": "980649",
    "end": "983889"
  },
  {
    "text": "instant group on AWS on auto scaling",
    "start": "983889",
    "end": "986350"
  },
  {
    "text": "group and so on I will explain this",
    "start": "986350",
    "end": "989620"
  },
  {
    "text": "assumption of similar nodes in in a",
    "start": "989620",
    "end": "992470"
  },
  {
    "text": "moment so how does it works inside of",
    "start": "992470",
    "end": "997389"
  },
  {
    "start": "994000",
    "end": "994000"
  },
  {
    "text": "cluster autoscaler there is a loop that",
    "start": "997389",
    "end": "999999"
  },
  {
    "text": "periodically executes is a series of",
    "start": "999999",
    "end": "1002399"
  },
  {
    "text": "checks and actions first of all it",
    "start": "1002399",
    "end": "1006870"
  },
  {
    "text": "checks whether the cluster is in good",
    "start": "1006870",
    "end": "1010139"
  },
  {
    "text": "overall state if half of the nodes are",
    "start": "1010139",
    "end": "1012509"
  },
  {
    "text": "broken then obviously something is",
    "start": "1012509",
    "end": "1014639"
  },
  {
    "text": "terribly wrong with the cluster but for",
    "start": "1014639",
    "end": "1016980"
  },
  {
    "text": "example you are facing a network",
    "start": "1016980",
    "end": "1018389"
  },
  {
    "text": "partition and cluster autoscaler should",
    "start": "1018389",
    "end": "1021269"
  },
  {
    "text": "pause not to make the situation even",
    "start": "1021269",
    "end": "1023459"
  },
  {
    "text": "worse however if there is just one and",
    "start": "1023459",
    "end": "1027058"
  },
  {
    "text": "ready now then it should be able to",
    "start": "1027059",
    "end": "1030029"
  },
  {
    "text": "continue operation in Travis version of",
    "start": "1030029",
    "end": "1032970"
  },
  {
    "text": "Cooper NetID it wasn't true the cluster",
    "start": "1032970",
    "end": "1035730"
  },
  {
    "text": "autoscaler was stopping once there was a",
    "start": "1035730",
    "end": "1038760"
  },
  {
    "text": "single broken node with one point six we",
    "start": "1038760",
    "end": "1042350"
  },
  {
    "text": "lifting this constraint and cluster",
    "start": "1042350",
    "end": "1045110"
  },
  {
    "text": "autoscaler will try to do its best even",
    "start": "1045110",
    "end": "1047538"
  },
  {
    "text": "if there are already nodes cluster",
    "start": "1047539",
    "end": "1051110"
  },
  {
    "text": "autoscaler may even heal and remove the",
    "start": "1051110",
    "end": "1053620"
  },
  {
    "text": "broken notes on your way so it's kind of",
    "start": "1053620",
    "end": "1056720"
  },
  {
    "text": "like a popular healing solution then",
    "start": "1056720",
    "end": "1060740"
  },
  {
    "text": "after checking with the cluster stage it",
    "start": "1060740",
    "end": "1062809"
  },
  {
    "text": "looks for unschedulable pots and",
    "start": "1062809",
    "end": "1064779"
  },
  {
    "text": "schedulable pots are pots for which the",
    "start": "1064779",
    "end": "1067639"
  },
  {
    "text": "kubernetes schedule scheduler failed to",
    "start": "1067639",
    "end": "1070399"
  },
  {
    "text": "find a place for them and marked them",
    "start": "1070399",
    "end": "1073299"
  },
  {
    "text": "accordingly",
    "start": "1073299",
    "end": "1075129"
  },
  {
    "text": "if there are on schedule reports then",
    "start": "1075129",
    "end": "1078169"
  },
  {
    "text": "cluster autoscaler",
    "start": "1078169",
    "end": "1079490"
  },
  {
    "text": "runs a series of simulations to check",
    "start": "1079490",
    "end": "1082399"
  },
  {
    "text": "which node group in the cluster",
    "start": "1082399",
    "end": "1084409"
  },
  {
    "text": "if expanded could accommodate some of",
    "start": "1084409",
    "end": "1087590"
  },
  {
    "text": "the pending pots so it is important here",
    "start": "1087590",
    "end": "1091370"
  },
  {
    "text": "that the new nodes will look similar to",
    "start": "1091370",
    "end": "1094809"
  },
  {
    "text": "denote that already their cluster",
    "start": "1094809",
    "end": "1097759"
  },
  {
    "text": "autoscaler looks at the existing nodes",
    "start": "1097759",
    "end": "1100370"
  },
  {
    "text": "and tries to guess what would the new",
    "start": "1100370",
    "end": "1104299"
  },
  {
    "text": "note look like and it assumes that it",
    "start": "1104299",
    "end": "1106700"
  },
  {
    "text": "will be similar to the existing one if",
    "start": "1106700",
    "end": "1109759"
  },
  {
    "text": "there is such a node group that could be",
    "start": "1109759",
    "end": "1112190"
  },
  {
    "text": "expanded it increases its size so that",
    "start": "1112190",
    "end": "1114919"
  },
  {
    "text": "the pending pots will get a place to",
    "start": "1114919",
    "end": "1117470"
  },
  {
    "text": "live okay so sometimes we are not",
    "start": "1117470",
    "end": "1122330"
  },
  {
    "text": "scaling up so maybe we could remove some",
    "start": "1122330",
    "end": "1125899"
  },
  {
    "text": "nodes and still have after maybe some",
    "start": "1125899",
    "end": "1128720"
  },
  {
    "text": "interruption all pots up and running so",
    "start": "1128720",
    "end": "1134169"
  },
  {
    "text": "we are checking how much the nodes are",
    "start": "1134169",
    "end": "1137090"
  },
  {
    "text": "utilized and which can be removed and if",
    "start": "1137090",
    "end": "1141230"
  },
  {
    "text": "such nodes could be removed for long",
    "start": "1141230",
    "end": "1143539"
  },
  {
    "text": "enough then we removed one of them and",
    "start": "1143539",
    "end": "1146659"
  },
  {
    "text": "the whole loop repeats getting rid to",
    "start": "1146659",
    "end": "1151279"
  },
  {
    "start": "1150000",
    "end": "1150000"
  },
  {
    "text": "some details especially I will try to",
    "start": "1151279",
    "end": "1154279"
  },
  {
    "text": "explain what the unneeded nodes are so",
    "start": "1154279",
    "end": "1158360"
  },
  {
    "text": "what does exactly mean that the nodes",
    "start": "1158360",
    "end": "1160490"
  },
  {
    "text": "are needed",
    "start": "1160490",
    "end": "1161240"
  },
  {
    "text": "according to parent Harris heuristic a",
    "start": "1161240",
    "end": "1164090"
  },
  {
    "text": "node can be considered unneeded",
    "start": "1164090",
    "end": "1166070"
  },
  {
    "text": "if its utilization is below 50% both in",
    "start": "1166070",
    "end": "1171139"
  },
  {
    "text": "terms of CPU and memory we don't want to",
    "start": "1171139",
    "end": "1173809"
  },
  {
    "text": "harass well utilized nodes just",
    "start": "1173809",
    "end": "1176000"
  },
  {
    "text": "get a little bit better pot packing we",
    "start": "1176000",
    "end": "1180800"
  },
  {
    "text": "check if all of the pots running on the",
    "start": "1180800",
    "end": "1184250"
  },
  {
    "text": "note can be moved as well this basically",
    "start": "1184250",
    "end": "1187040"
  },
  {
    "text": "means that all parts are either backed",
    "start": "1187040",
    "end": "1189650"
  },
  {
    "text": "by a replica set deployment job or",
    "start": "1189650",
    "end": "1192320"
  },
  {
    "text": "stateful set or they are run by default",
    "start": "1192320",
    "end": "1195380"
  },
  {
    "text": "on the note either by a manifest or a",
    "start": "1195380",
    "end": "1198230"
  },
  {
    "text": "demon set we don't want to create a",
    "start": "1198230",
    "end": "1202910"
  },
  {
    "text": "serious issue with the system",
    "start": "1202910",
    "end": "1205580"
  },
  {
    "text": "infrastructure so we don't touch cube",
    "start": "1205580",
    "end": "1208550"
  },
  {
    "text": "system pots that means that we won't",
    "start": "1208550",
    "end": "1210620"
  },
  {
    "text": "kill a note with hipster or DNS running",
    "start": "1210620",
    "end": "1213230"
  },
  {
    "text": "on it which on the other hand may lead",
    "start": "1213230",
    "end": "1216140"
  },
  {
    "text": "to some resource waste in the end notes",
    "start": "1216140",
    "end": "1220490"
  },
  {
    "text": "we've local storage local storage with",
    "start": "1220490",
    "end": "1224690"
  },
  {
    "text": "pots with local storage local storage",
    "start": "1224690",
    "end": "1226730"
  },
  {
    "text": "would be lost if the pot is killed so it",
    "start": "1226730",
    "end": "1230450"
  },
  {
    "text": "will be bats and we don't touch notes",
    "start": "1230450",
    "end": "1232460"
  },
  {
    "text": "with such pots and when we kill the note",
    "start": "1232460",
    "end": "1239690"
  },
  {
    "start": "1235000",
    "end": "1235000"
  },
  {
    "text": "first of all we make sure that the note",
    "start": "1239690",
    "end": "1243140"
  },
  {
    "text": "is not needed for at least 10 minutes",
    "start": "1243140",
    "end": "1245270"
  },
  {
    "text": "we constantly your own checks and do the",
    "start": "1245270",
    "end": "1248270"
  },
  {
    "text": "simulation whether the note can be moved",
    "start": "1248270",
    "end": "1250820"
  },
  {
    "text": "and where would the pot goes and if the",
    "start": "1250820",
    "end": "1254000"
  },
  {
    "text": "simulation are successful for 10 minutes",
    "start": "1254000",
    "end": "1257780"
  },
  {
    "text": "then the note can be removed and we",
    "start": "1257780",
    "end": "1259370"
  },
  {
    "text": "remove one of the notes of course we do",
    "start": "1259370",
    "end": "1263450"
  },
  {
    "text": "it and if we haven't any scale up",
    "start": "1263450",
    "end": "1267350"
  },
  {
    "text": "recently we don't want to go up and down",
    "start": "1267350",
    "end": "1269690"
  },
  {
    "text": "constantly what else is included in the",
    "start": "1269690",
    "end": "1277220"
  },
  {
    "start": "1273000",
    "end": "1273000"
  },
  {
    "text": "not cleaning process first of all of",
    "start": "1277220",
    "end": "1279560"
  },
  {
    "text": "disruption budgetary issues but",
    "start": "1279560",
    "end": "1281660"
  },
  {
    "text": "disruption budget were introduced in 1.5",
    "start": "1281660",
    "end": "1284570"
  },
  {
    "text": "and get a got a little bit more laughs",
    "start": "1284570",
    "end": "1286820"
  },
  {
    "text": "in 1.6 so they are an effective way to",
    "start": "1286820",
    "end": "1290210"
  },
  {
    "text": "tell cluster autoscaler",
    "start": "1290210",
    "end": "1292070"
  },
  {
    "text": "not to touch some of the pots or to",
    "start": "1292070",
    "end": "1295070"
  },
  {
    "text": "remove them from notes slowly one after",
    "start": "1295070",
    "end": "1298160"
  },
  {
    "text": "another cluster autoscaler phases",
    "start": "1298160",
    "end": "1304270"
  },
  {
    "text": "securities one point six respect also",
    "start": "1304270",
    "end": "1306500"
  },
  {
    "text": "graceful termination we can",
    "start": "1306500",
    "end": "1308880"
  },
  {
    "text": "up to one minute so we give a part a",
    "start": "1308880",
    "end": "1311820"
  },
  {
    "text": "chance to finish the work",
    "start": "1311820",
    "end": "1313850"
  },
  {
    "text": "gracefully before we kill the note and",
    "start": "1313850",
    "end": "1317010"
  },
  {
    "text": "we all know controllers to recreate them",
    "start": "1317010",
    "end": "1321770"
  },
  {
    "text": "we remove the note on the cluster close",
    "start": "1323270",
    "end": "1328680"
  },
  {
    "text": "providers side so this information goes",
    "start": "1328680",
    "end": "1331890"
  },
  {
    "text": "to kubernetes from the cloud provider",
    "start": "1331890",
    "end": "1333600"
  },
  {
    "text": "side so the note is deleted and then",
    "start": "1333600",
    "end": "1336060"
  },
  {
    "text": "node controllers pick this information",
    "start": "1336060",
    "end": "1338310"
  },
  {
    "text": "from the cloud provider we do kill empty",
    "start": "1338310",
    "end": "1343320"
  },
  {
    "text": "notes in but we make heal up to 10 nodes",
    "start": "1343320",
    "end": "1346020"
  },
  {
    "text": "at the same time but if the nodes are",
    "start": "1346020",
    "end": "1349110"
  },
  {
    "text": "not empty we kill them one after another",
    "start": "1349110",
    "end": "1352220"
  },
  {
    "text": "to make pod migration a little bit more",
    "start": "1352220",
    "end": "1357000"
  },
  {
    "text": "stable and don't create too big mess",
    "start": "1357000",
    "end": "1362180"
  },
  {
    "start": "1362000",
    "end": "1362000"
  },
  {
    "text": "okay so what are the best practices of",
    "start": "1362180",
    "end": "1367080"
  },
  {
    "text": "running cluster autoscaler in your",
    "start": "1367080",
    "end": "1368820"
  },
  {
    "text": "cluster first of all do not modify nodes",
    "start": "1368820",
    "end": "1373530"
  },
  {
    "text": "manually as I said a cluster autoscaler",
    "start": "1373530",
    "end": "1377100"
  },
  {
    "text": "assumes that all nodes in an oh group",
    "start": "1377100",
    "end": "1379050"
  },
  {
    "text": "look the same they have the same CPU",
    "start": "1379050",
    "end": "1382170"
  },
  {
    "text": "they have the same set of labels and so",
    "start": "1382170",
    "end": "1384360"
  },
  {
    "text": "on and so on and if and if the node",
    "start": "1384360",
    "end": "1389160"
  },
  {
    "text": "group expanded we expect the new node to",
    "start": "1389160",
    "end": "1392340"
  },
  {
    "text": "look more or less the same and host the",
    "start": "1392340",
    "end": "1394410"
  },
  {
    "text": "same demo set and manifest run pods as",
    "start": "1394410",
    "end": "1398220"
  },
  {
    "text": "the nodes that are currently in the",
    "start": "1398220",
    "end": "1400140"
  },
  {
    "text": "cluster so please pay attention to that",
    "start": "1400140",
    "end": "1402300"
  },
  {
    "text": "otherwise the cloud the behavior of",
    "start": "1402300",
    "end": "1404430"
  },
  {
    "text": "cluster autoscaler",
    "start": "1404430",
    "end": "1405690"
  },
  {
    "text": "may be may be broken the same as we",
    "start": "1405690",
    "end": "1411840"
  },
  {
    "text": "horizontal pot autoscaler please please",
    "start": "1411840",
    "end": "1414090"
  },
  {
    "text": "declare requests for pots they are also",
    "start": "1414090",
    "end": "1416610"
  },
  {
    "text": "needed here",
    "start": "1416610",
    "end": "1417510"
  },
  {
    "text": "regular pots without request won't",
    "start": "1417510",
    "end": "1419760"
  },
  {
    "text": "trigger clustered autoscaler because",
    "start": "1419760",
    "end": "1421890"
  },
  {
    "text": "they can go to any node",
    "start": "1421890",
    "end": "1425750"
  },
  {
    "text": "you spot disruption budget to tell that",
    "start": "1427530",
    "end": "1430200"
  },
  {
    "text": "you don't want some pots to be",
    "start": "1430200",
    "end": "1432420"
  },
  {
    "text": "interrupted a cluster of the scaler can",
    "start": "1432420",
    "end": "1438900"
  },
  {
    "text": "work with notes with multiple shapes and",
    "start": "1438900",
    "end": "1442470"
  },
  {
    "text": "sizes however it is currently in beta",
    "start": "1442470",
    "end": "1444630"
  },
  {
    "text": "and it works best if the cluster is kind",
    "start": "1444630",
    "end": "1447960"
  },
  {
    "text": "of homogeneous it works with",
    "start": "1447960",
    "end": "1450030"
  },
  {
    "text": "heterogeneous cluster but the experience",
    "start": "1450030",
    "end": "1452580"
  },
  {
    "text": "is better with homogeneous this thing is",
    "start": "1452580",
    "end": "1455310"
  },
  {
    "text": "likely to improve in the future but for",
    "start": "1455310",
    "end": "1457860"
  },
  {
    "text": "now please remember it you couple it is",
    "start": "1457860",
    "end": "1465210"
  },
  {
    "text": "0.6 there are 2 comments that may help",
    "start": "1465210",
    "end": "1468060"
  },
  {
    "text": "you to tell what is the current state of",
    "start": "1468060",
    "end": "1470640"
  },
  {
    "text": "us cluster autoscaler perséphone all",
    "start": "1470640",
    "end": "1473880"
  },
  {
    "text": "there is config map that can be accessed",
    "start": "1473880",
    "end": "1478740"
  },
  {
    "text": "with a simple cube CTL comment in this",
    "start": "1478740",
    "end": "1481410"
  },
  {
    "text": "config map we start in information about",
    "start": "1481410",
    "end": "1484140"
  },
  {
    "text": "the current state of cluster altogether",
    "start": "1484140",
    "end": "1486870"
  },
  {
    "text": "and information about what actions are",
    "start": "1486870",
    "end": "1489570"
  },
  {
    "text": "currently being used there is also",
    "start": "1489570",
    "end": "1492090"
  },
  {
    "text": "information about whether there are some",
    "start": "1492090",
    "end": "1494790"
  },
  {
    "text": "nodes that could be possibly removed in",
    "start": "1494790",
    "end": "1498090"
  },
  {
    "text": "the near future",
    "start": "1498090",
    "end": "1499370"
  },
  {
    "text": "also cluster autoscaler published events",
    "start": "1499370",
    "end": "1502740"
  },
  {
    "text": "events and you go to either pods or not",
    "start": "1502740",
    "end": "1505680"
  },
  {
    "text": "if they are directly connected to them",
    "start": "1505680",
    "end": "1507630"
  },
  {
    "text": "or to this particular config mode",
    "start": "1507630",
    "end": "1511080"
  },
  {
    "text": "that I showed to you if the event is",
    "start": "1511080",
    "end": "1514410"
  },
  {
    "text": "more about the whole state of the",
    "start": "1514410",
    "end": "1516900"
  },
  {
    "text": "cluster so please check them if you feel",
    "start": "1516900",
    "end": "1520290"
  },
  {
    "text": "that something wrong is going on around",
    "start": "1520290",
    "end": "1523520"
  },
  {
    "text": "the number of nodes in your cluster they",
    "start": "1523520",
    "end": "1526860"
  },
  {
    "text": "may help so what is the overall status",
    "start": "1526860",
    "end": "1532410"
  },
  {
    "text": "of cluster autoscaler as I said it is",
    "start": "1532410",
    "end": "1535800"
  },
  {
    "text": "still in better and better in kubernetes",
    "start": "1535800",
    "end": "1538140"
  },
  {
    "text": "means that the most of the core",
    "start": "1538140",
    "end": "1539820"
  },
  {
    "text": "functionality is in place but there",
    "start": "1539820",
    "end": "1542430"
  },
  {
    "text": "might be some cases when the behavior or",
    "start": "1542430",
    "end": "1545760"
  },
  {
    "text": "the experience is suboptimal so what is",
    "start": "1545760",
    "end": "1549510"
  },
  {
    "text": "missing in cluster of the scalar so one",
    "start": "1549510",
    "end": "1553590"
  },
  {
    "start": "1552000",
    "end": "1552000"
  },
  {
    "text": "of the thing is C+ autoscaler friendly",
    "start": "1553590",
    "end": "1557610"
  },
  {
    "text": "scheduler with cluster autoscaler",
    "start": "1557610",
    "end": "1560400"
  },
  {
    "text": "we try to pack",
    "start": "1560400",
    "end": "1561720"
  },
  {
    "text": "notes as tightly as possible and the",
    "start": "1561720",
    "end": "1564900"
  },
  {
    "text": "default cluster scheduler tries to do a",
    "start": "1564900",
    "end": "1567900"
  },
  {
    "text": "completely opposite thing so it tries to",
    "start": "1567900",
    "end": "1570180"
  },
  {
    "text": "spread the load across the cluster and",
    "start": "1570180",
    "end": "1574650"
  },
  {
    "text": "put the pots on nose we are less",
    "start": "1574650",
    "end": "1578670"
  },
  {
    "text": "utilized so it completes a little bit we",
    "start": "1578670",
    "end": "1582540"
  },
  {
    "text": "are hoping to introduce some more",
    "start": "1582540",
    "end": "1584910"
  },
  {
    "text": "friendly scheduler settings soon then we",
    "start": "1584910",
    "end": "1589740"
  },
  {
    "text": "the configuration of cluster autoscaler",
    "start": "1589740",
    "end": "1593370"
  },
  {
    "text": "depends on cloud provider on gke it is a",
    "start": "1593370",
    "end": "1596670"
  },
  {
    "text": "single G cloud comment on GCE",
    "start": "1596670",
    "end": "1599310"
  },
  {
    "text": "it is based on Cuba script and",
    "start": "1599310",
    "end": "1602520"
  },
  {
    "text": "environment variables there is also a",
    "start": "1602520",
    "end": "1605220"
  },
  {
    "text": "support for nos autoscaler in k ops for",
    "start": "1605220",
    "end": "1608340"
  },
  {
    "text": "AWS and so on",
    "start": "1608340",
    "end": "1609510"
  },
  {
    "text": "all in all it's not super consistent and",
    "start": "1609510",
    "end": "1613020"
  },
  {
    "text": "convenient may be accepted DK but we are",
    "start": "1613020",
    "end": "1615480"
  },
  {
    "text": "working on making it adequate easier and",
    "start": "1615480",
    "end": "1618540"
  },
  {
    "text": "smoother for you we also need more tests",
    "start": "1618540",
    "end": "1623070"
  },
  {
    "text": "for non-trivial failure scenario cluster",
    "start": "1623070",
    "end": "1627480"
  },
  {
    "text": "autoscaler has to make a lot of",
    "start": "1627480",
    "end": "1629220"
  },
  {
    "text": "assumptions about how the Cabana test",
    "start": "1629220",
    "end": "1631350"
  },
  {
    "text": "works under the hood and what can",
    "start": "1631350",
    "end": "1634320"
  },
  {
    "text": "possibly happen during the its operation",
    "start": "1634320",
    "end": "1638000"
  },
  {
    "text": "we want to cover it all in the",
    "start": "1638000",
    "end": "1640350"
  },
  {
    "text": "continuous integration test for the",
    "start": "1640350",
    "end": "1642530"
  },
  {
    "text": "cluster autoscaler",
    "start": "1642530",
    "end": "1644130"
  },
  {
    "text": "so it is rock-solid we run manual tests",
    "start": "1644130",
    "end": "1647070"
  },
  {
    "text": "but they don't show occasional issues",
    "start": "1647070",
    "end": "1650100"
  },
  {
    "text": "like the one with a new potent",
    "start": "1650100",
    "end": "1652590"
  },
  {
    "text": "networking found at the very last minute",
    "start": "1652590",
    "end": "1655170"
  },
  {
    "text": "before one plus six release and we first",
    "start": "1655170",
    "end": "1658890"
  },
  {
    "text": "ask to ask you guys to wait until one",
    "start": "1658890",
    "end": "1663480"
  },
  {
    "text": "point 6.1 which should be in one week",
    "start": "1663480",
    "end": "1665550"
  },
  {
    "text": "before you try to run cluster out the",
    "start": "1665550",
    "end": "1668520"
  },
  {
    "text": "skeleton it's not terribly broken but",
    "start": "1668520",
    "end": "1670860"
  },
  {
    "text": "the experience may be a little bit",
    "start": "1670860",
    "end": "1672390"
  },
  {
    "text": "suboptimal we don't want tore this to",
    "start": "1672390",
    "end": "1676290"
  },
  {
    "text": "happen ever again so we want to",
    "start": "1676290",
    "end": "1678750"
  },
  {
    "text": "introduce a better tester also this",
    "start": "1678750",
    "end": "1685160"
  },
  {
    "text": "config map think with the status is a",
    "start": "1685370",
    "end": "1688890"
  },
  {
    "text": "little bit of a hack",
    "start": "1688890",
    "end": "1690530"
  },
  {
    "text": "we are hoping that in next release there",
    "start": "1690530",
    "end": "1693840"
  },
  {
    "text": "will be something called",
    "start": "1693840",
    "end": "1695220"
  },
  {
    "text": "component status and the status of",
    "start": "1695220",
    "end": "1697290"
  },
  {
    "text": "cluster autoscaler will be great there",
    "start": "1697290",
    "end": "1700110"
  },
  {
    "text": "and in the end we want to hear from you",
    "start": "1700110",
    "end": "1703530"
  },
  {
    "text": "please try it and to let us know if it",
    "start": "1703530",
    "end": "1706290"
  },
  {
    "text": "worked for you or not and what were your",
    "start": "1706290",
    "end": "1709320"
  },
  {
    "text": "impressions also we invite you to",
    "start": "1709320",
    "end": "1713130"
  },
  {
    "text": "contribute to cluster autoscaler we are",
    "start": "1713130",
    "end": "1716880"
  },
  {
    "text": "slowly running out of time so just a few",
    "start": "1716880",
    "end": "1719730"
  },
  {
    "text": "words of the upcoming vertical potential",
    "start": "1719730",
    "end": "1722010"
  },
  {
    "text": "scaling its goal is to automatically set",
    "start": "1722010",
    "end": "1725820"
  },
  {
    "start": "1723000",
    "end": "1723000"
  },
  {
    "text": "and object container requests based on",
    "start": "1725820",
    "end": "1728070"
  },
  {
    "text": "the previous use so if your pot is using",
    "start": "1728070",
    "end": "1730800"
  },
  {
    "text": "a lot of memories and crushes for",
    "start": "1730800",
    "end": "1732750"
  },
  {
    "text": "example with out of amore exceptions",
    "start": "1732750",
    "end": "1734790"
  },
  {
    "text": "we'll try to get it more memory if a pod",
    "start": "1734790",
    "end": "1739080"
  },
  {
    "text": "that is if there is a pod that actually",
    "start": "1739080",
    "end": "1741870"
  },
  {
    "text": "is not using the declared free CPUs but",
    "start": "1741870",
    "end": "1745350"
  },
  {
    "text": "rather one and a bit then we will try to",
    "start": "1745350",
    "end": "1749340"
  },
  {
    "text": "reduce the frequency pew so the",
    "start": "1749340",
    "end": "1752910"
  },
  {
    "text": "resources in your cluster are better",
    "start": "1752910",
    "end": "1755340"
  },
  {
    "text": "utilized and so on and so on the reason",
    "start": "1755340",
    "end": "1758820"
  },
  {
    "text": "for it is almost completed and we hope",
    "start": "1758820",
    "end": "1760920"
  },
  {
    "text": "to have some proof of concept alpha",
    "start": "1760920",
    "end": "1763020"
  },
  {
    "text": "version around the June anyway if you",
    "start": "1763020",
    "end": "1767190"
  },
  {
    "text": "are interested in VP area or any of the",
    "start": "1767190",
    "end": "1770670"
  },
  {
    "text": "cluster out of any of the auto scaling",
    "start": "1770670",
    "end": "1773010"
  },
  {
    "text": "efforts please join us on our weekly",
    "start": "1773010",
    "end": "1775560"
  },
  {
    "text": "seek out the scanning meetings they take",
    "start": "1775560",
    "end": "1778470"
  },
  {
    "text": "place on Thursday 5:30 p.m. burning time",
    "start": "1778470",
    "end": "1782190"
  },
  {
    "text": "which the site party Pacific Standard",
    "start": "1782190",
    "end": "1784080"
  },
  {
    "text": "Time okay and we have I believe five",
    "start": "1784080",
    "end": "1787490"
  },
  {
    "text": "minutes for questions",
    "start": "1787490",
    "end": "1791030"
  }
]
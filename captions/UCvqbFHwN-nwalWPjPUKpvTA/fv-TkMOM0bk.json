[
  {
    "start": "0",
    "end": "72000"
  },
  {
    "text": "so let's get started um yep carlos antana uh you can follow me on twitter",
    "start": "160",
    "end": "5279"
  },
  {
    "text": "paul from ibm both for ibm you can't follow me on twitter because i'm not on it",
    "start": "5279",
    "end": "12080"
  },
  {
    "text": "uh let's get started without talking about call start so just an introduction we saw that some people were new to k",
    "start": "12080",
    "end": "18320"
  },
  {
    "text": "native so to give an introduction of what is knf serving it simplifies the deployment",
    "start": "18320",
    "end": "24080"
  },
  {
    "text": "like mentioned before of kubernetes abstractions has traffic splitting which uh we saw a",
    "start": "24080",
    "end": "30960"
  },
  {
    "text": "great demo by bloomberg how they use traffic speeding and then rollouts and um one of the my",
    "start": "30960",
    "end": "37120"
  },
  {
    "text": "favorite features of is auto auto tls https so you define your service",
    "start": "37120",
    "end": "43360"
  },
  {
    "text": "and k native serving takes care of defining the route and the traffic aspect of it",
    "start": "43360",
    "end": "49200"
  },
  {
    "text": "and the configuration as always in kubernetes crds you can compose them",
    "start": "49200",
    "end": "55600"
  },
  {
    "text": "as separate things router and configuration but we suggest to use service or service uh we have seen many",
    "start": "55600",
    "end": "62079"
  },
  {
    "text": "talks about that is a scaling to zero but i think the most difficult problem from scanning to zero is getting back to",
    "start": "62079",
    "end": "68240"
  },
  {
    "text": "one like i always like to joke next slide um so just for uh reminders and i i get",
    "start": "68240",
    "end": "76320"
  },
  {
    "start": "72000",
    "end": "333000"
  },
  {
    "text": "this question uh a lot is uh people ask us like how do we how k native scales to zero and i",
    "start": "76320",
    "end": "83680"
  },
  {
    "text": "usually kind of like i said well and the interesting part is how it scales to one",
    "start": "83680",
    "end": "88880"
  },
  {
    "text": "it's the interesting thing not scale to zero and some people actually think we have joke about this that this there's",
    "start": "88880",
    "end": "95439"
  },
  {
    "text": "some magic and sprinkles in the cluster that makes this happen but actually",
    "start": "95439",
    "end": "100720"
  },
  {
    "text": "there's uh engineering involved right and if people want to get um you know contributions and learn i know a lot of",
    "start": "100720",
    "end": "108000"
  },
  {
    "text": "people want to learn how it works this is a good opportunity to get involved and actually help with coding",
    "start": "108000",
    "end": "113920"
  },
  {
    "text": "testing and involving a serving so the working group is always looking for contributions so",
    "start": "113920",
    "end": "120880"
  },
  {
    "text": "one simple example is like the life of the query wanting to make this a little bit simpler for people to use but when",
    "start": "120880",
    "end": "127360"
  },
  {
    "text": "you start with a kubernetes cluster you usually have a request coming in into an ingress in our case will be something",
    "start": "127360",
    "end": "133680"
  },
  {
    "text": "like contour courier istio you don't have to use istio",
    "start": "133680",
    "end": "139360"
  },
  {
    "text": "we have a service it's a type of service but it represents the same abstraction but the key aspect",
    "start": "139360",
    "end": "145760"
  },
  {
    "text": "is there's no pods so there's a deployment out there for every revision but there's zero pods so how do we get",
    "start": "145760",
    "end": "152959"
  },
  {
    "text": "that request to a pod that doesn't exist usually that's that's the key question",
    "start": "152959",
    "end": "158239"
  },
  {
    "text": "and the answer to that is the activator and i love the names that we give these two guys activator autoscalers they",
    "start": "158239",
    "end": "164800"
  },
  {
    "text": "sound like um transformers oh i'm a fan of transformers so we have the activator and activator",
    "start": "164800",
    "end": "170879"
  },
  {
    "text": "is in charge in there of like if there's no pod to receive this request i'm going to go into the middle there so the",
    "start": "170879",
    "end": "177360"
  },
  {
    "text": "endpoints get configured to be able to capture that request and take the the aspect but somebody",
    "start": "177360",
    "end": "184239"
  },
  {
    "text": "needs to get one pot up so this is kubernetes we're managing kubernetes um so that's what the aspects of kubernetes",
    "start": "184239",
    "end": "190959"
  },
  {
    "text": "is native is cool k native so activator needs to tell like i need the first pod",
    "start": "190959",
    "end": "197280"
  },
  {
    "text": "so how does that happen so that happens through the activator communicating with the",
    "start": "197280",
    "end": "202720"
  },
  {
    "text": "auto scaler and the auto scatter like normal kubernetes who said that the replica set to one and this is where",
    "start": "202720",
    "end": "210400"
  },
  {
    "text": "things start slowing down telling kubernetes give me one pod and eventually",
    "start": "210400",
    "end": "216560"
  },
  {
    "text": "a pot would exist and when the pot comes up we have to bring up minimum two",
    "start": "216560",
    "end": "222560"
  },
  {
    "text": "uh containers if you're using insta with mesh with three but in our simple example will be a the cube proxy which",
    "start": "222560",
    "end": "229280"
  },
  {
    "text": "is another component of k native this is the explanation of how to scale to one",
    "start": "229280",
    "end": "234959"
  },
  {
    "text": "and then our application so that our application is the one that that boots up and and comes up the q proxy usually",
    "start": "234959",
    "end": "242000"
  },
  {
    "text": "spins up very fast it's a very simple um low low um container but the",
    "start": "242000",
    "end": "248000"
  },
  {
    "text": "applications defines how long your pot will come up and be ready and then the eq proxy start like ping in the app and",
    "start": "248000",
    "end": "254239"
  },
  {
    "text": "you're ready uh to see if we can receive that once it does that the activator says okay i can send start",
    "start": "254239",
    "end": "260320"
  },
  {
    "text": "sending requests to the queue proxy and the key proxy is there to measure the concurrency um",
    "start": "260320",
    "end": "266800"
  },
  {
    "text": "for the auto scaler to be um scraping so the autoscaler now start getting the metrics from that q proxy",
    "start": "266800",
    "end": "274560"
  },
  {
    "text": "and decides when is enough uh traffic is coming in that you need two replicas and then the",
    "start": "274560",
    "end": "280560"
  },
  {
    "text": "next one comes up you have you get the next deployment you hit your cold start depending how warm what type of levels",
    "start": "280560",
    "end": "287919"
  },
  {
    "text": "of heat you have um and then the activator sends that to the creep proxy and eventually it gets",
    "start": "287919",
    "end": "294000"
  },
  {
    "text": "to a stable stat stable state that we this um the system can get to it that",
    "start": "294000",
    "end": "299600"
  },
  {
    "text": "then the activator is not in the critical path and it goes there so this is kind of like one of the latest",
    "start": "299600",
    "end": "306000"
  },
  {
    "text": "examples and somebody was saying there needs to be a way to like we need more type of these diagrams to explain to",
    "start": "306000",
    "end": "311919"
  },
  {
    "text": "newcomers how things work inside so they get used to in terms of using it and",
    "start": "311919",
    "end": "317280"
  },
  {
    "text": "operating it in terms of operators so that's that's the service once it",
    "start": "317280",
    "end": "322800"
  },
  {
    "text": "gets into a stable state and there's enough as you said capacity",
    "start": "322800",
    "end": "329440"
  },
  {
    "text": "to sustain the load then the captivator doesn't have to be in the middle but activator is a primary thing there so",
    "start": "329440",
    "end": "336080"
  },
  {
    "start": "333000",
    "end": "466000"
  },
  {
    "text": "leave it there what happens there when we need that first spot so just again talking in terms of timing",
    "start": "336080",
    "end": "342479"
  },
  {
    "text": "what are the things that have to happen between when the request is received and when the request is processed so carl's",
    "start": "342479",
    "end": "347759"
  },
  {
    "text": "kind of over this but just to kind of recap here let me speak into the microphone the request comes in it gets routed to",
    "start": "347759",
    "end": "353039"
  },
  {
    "text": "the activator the activator triggers the auto scaler the auto scaler updates the replica count the pod is created and",
    "start": "353039",
    "end": "358560"
  },
  {
    "text": "ready the activator knows the pod is ready the activator forwards the request to qprox eq proxy forwards it to the app",
    "start": "358560",
    "end": "364479"
  },
  {
    "text": "the app responds to the request and the request is processed so this is just kind of the list of the eight things that have to happen if we were to",
    "start": "364479",
    "end": "370800"
  },
  {
    "text": "represent this more in kind of a you know how long each one of them takes you would see that the pod being created and",
    "start": "370800",
    "end": "376560"
  },
  {
    "text": "ready is what takes the longest amount of time now why is that that's because there's a whole lot of things that are happening there we have to create the",
    "start": "376560",
    "end": "382880"
  },
  {
    "text": "container we have to perhaps pull the image if it's not already cache on the node we have to wait for the containers",
    "start": "382880",
    "end": "388000"
  },
  {
    "text": "to start we have to wait for all the probes to run there's a lot of things that are happening there and there's a lot of",
    "start": "388000",
    "end": "393440"
  },
  {
    "text": "kind of different scenarios carlos mentioned the levels of heat that we're pulling from a presentation that matt had made previously",
    "start": "393440",
    "end": "399440"
  },
  {
    "text": "but we'll call them different kinds of latency types and what this means is it's really just referring to the different types of scenarios",
    "start": "399440",
    "end": "404880"
  },
  {
    "text": "on a particular node so there's kind of two kind of main variables here one is the container running on that node",
    "start": "404880",
    "end": "411360"
  },
  {
    "text": "yes or no two has that image been cached on that node already yes or no and so",
    "start": "411360",
    "end": "416479"
  },
  {
    "text": "what we'll call a cold start is when that node does not have the container cached on it and or the image cached on",
    "start": "416479",
    "end": "422880"
  },
  {
    "text": "it and the container is not running that's the cold start that's what takes the longest amount of time to happen",
    "start": "422880",
    "end": "428400"
  },
  {
    "text": "next would be we call a warm disk that's when the image has already been cached on said node but the container is not",
    "start": "428400",
    "end": "433599"
  },
  {
    "text": "actually actively running a warm memory scenario that's when the",
    "start": "433599",
    "end": "438639"
  },
  {
    "text": "container's been paused so the container's up but it's been paused it's not kind of actively serving requested as it's been paused by the container",
    "start": "438639",
    "end": "444720"
  },
  {
    "text": "runtime or something like that and then finally what we call the warm cpu scenario where",
    "start": "444720",
    "end": "450080"
  },
  {
    "text": "that container is actively running and can serve requests kind of immediately so thanks to matt for kind of those",
    "start": "450080",
    "end": "455199"
  },
  {
    "text": "categories there um kind of that's kind of the problem space we find ourselves in now the question is",
    "start": "455199",
    "end": "462319"
  },
  {
    "text": "how can we make things faster so back to carlos yep thank you so what what things you can use in",
    "start": "462319",
    "end": "468639"
  },
  {
    "start": "466000",
    "end": "700000"
  },
  {
    "text": "userland and uh we get a lot of questions in in slack about",
    "start": "468639",
    "end": "473919"
  },
  {
    "text": "co-stars and one of them is image pools so one aspect of this in general general",
    "start": "473919",
    "end": "480080"
  },
  {
    "text": "terms for the talk is uh looking at how to speed the co-stars but also how to avoid co-stars",
    "start": "480080",
    "end": "487599"
  },
  {
    "text": "if they can if they can happen infrequently then you are in a better better luck with that so image pools",
    "start": "487599",
    "end": "493759"
  },
  {
    "text": "there's a lot of talks and a lot of conventions actually a lot of tools um a lot of innovation in the",
    "start": "493759",
    "end": "500080"
  },
  {
    "text": "cni space um also the oci space and the cloud native space around how do we pull",
    "start": "500080",
    "end": "507599"
  },
  {
    "text": "the bits that i need it's like a like e-star gz always",
    "start": "507599",
    "end": "512719"
  },
  {
    "text": "don't use always pull and always pulls is also something that some users cannot avoid because you're working maybe in a",
    "start": "512719",
    "end": "519680"
  },
  {
    "text": "multi-tenant environment so you you don't want another pod from another user or a bad actor to like use your image",
    "start": "519680",
    "end": "527200"
  },
  {
    "text": "that you catch so you always ask always pull but if you can avoid that always like don't use latest tag um",
    "start": "527200",
    "end": "534800"
  },
  {
    "text": "and catch the image on the notes that's kind of like the the best one so uh another one is like getting the image",
    "start": "534800",
    "end": "541360"
  },
  {
    "text": "closer so i'll talk if if on a few of them the other one is init optimization it's like what what can you do in your",
    "start": "541360",
    "end": "548480"
  },
  {
    "text": "code or your framework or the type of initialization that you're doing right what are the things that you're loading",
    "start": "548480",
    "end": "554240"
  },
  {
    "text": "at boot time that you can maybe do later uh or maybe you don't maybe the type based on the type of request you never",
    "start": "554240",
    "end": "560320"
  },
  {
    "text": "actually there's no codepath in there and the last one also is hidden costs",
    "start": "560320",
    "end": "566720"
  },
  {
    "text": "some people are using certain components or frameworks or something from a cloud provider that they don't know that is",
    "start": "566720",
    "end": "573040"
  },
  {
    "text": "affecting the coaster so i'll give two examples of that around istio um and and cni and then i like i said um",
    "start": "573040",
    "end": "581200"
  },
  {
    "text": "the other strategy is try to avoid the the co-star right instead of like uh they they're costly so see if you can",
    "start": "581200",
    "end": "588560"
  },
  {
    "text": "modify maybe the concurrency and all the aspects to just avoid them so we'll touch on some of them and this is like",
    "start": "588560",
    "end": "595839"
  },
  {
    "text": "a lot of users need kind of guidance and a lot of things are available so one is",
    "start": "595839",
    "end": "601279"
  },
  {
    "text": "always forcing the image uh the image pool at deployment time this is something that you can do",
    "start": "601279",
    "end": "607120"
  },
  {
    "text": "um on your own like for example you can deploy with the cli the candidate",
    "start": "607120",
    "end": "612399"
  },
  {
    "text": "service and then behind the scenes try to deploy something that will go to certain nodes right maybe your your",
    "start": "612399",
    "end": "618480"
  },
  {
    "text": "services run in certain nodes from your cluster so you create a deployment a demon set that just pulls the image but",
    "start": "618480",
    "end": "625279"
  },
  {
    "text": "it doesn't do anything um there's some also that you can do things like deploy the service but never make it run the",
    "start": "625279",
    "end": "632000"
  },
  {
    "text": "first spot there's a flag and an annotation for that and also we have in k native is a crd",
    "start": "632000",
    "end": "638880"
  },
  {
    "text": "where cr get gets created per revision and it has all the information from i",
    "start": "638880",
    "end": "644399"
  },
  {
    "text": "guess the parent the owner that created that revision and it has the url that the controller does the tag resolution",
    "start": "644399",
    "end": "651600"
  },
  {
    "text": "so we always like try to match the tag to the sha zoom so we give you have the",
    "start": "651600",
    "end": "656880"
  },
  {
    "text": "the long image tag and you can write your own controller or or um that that knows what",
    "start": "656880",
    "end": "664240"
  },
  {
    "text": "are the images that need to be uh downloaded and so there's some community repos that",
    "start": "664240",
    "end": "669360"
  },
  {
    "text": "have an implementation of that but it could be as simple as watching this resource that it comes up that candidate",
    "start": "669360",
    "end": "675680"
  },
  {
    "text": "creates for someone to create to implement it so that's one way is off and um and",
    "start": "675680",
    "end": "682240"
  },
  {
    "text": "again even if you have an image registry that is located in the same availability zone",
    "start": "682240",
    "end": "688079"
  },
  {
    "text": "or vpc or from the provider it would not it would not solve all your issues just by downloading the image",
    "start": "688079",
    "end": "694160"
  },
  {
    "text": "sometimes the image is very small and that's not where the most of the time is spent and paul is going to talk about",
    "start": "694160",
    "end": "700560"
  },
  {
    "start": "700000",
    "end": "748000"
  },
  {
    "text": "where is that spent some languages i think somebody asked earlier about choosing a language um i",
    "start": "700560",
    "end": "708240"
  },
  {
    "text": "understand that some companies or some projects they don't have a choice to select the language but certain",
    "start": "708240",
    "end": "714720"
  },
  {
    "text": "functions like mauricio was explaining certain functions are maybe uh done in",
    "start": "714720",
    "end": "720240"
  },
  {
    "text": "async way and they can choose a language remember other functions can be written in other language so you can have a",
    "start": "720240",
    "end": "725279"
  },
  {
    "text": "polyglot of languages but be careful because certain languages like i show here like for like a straight java will",
    "start": "725279",
    "end": "731839"
  },
  {
    "text": "take a long time but if you use something like growl vm and compile that with quarkus or just grab vm you can go",
    "start": "731839",
    "end": "738720"
  },
  {
    "text": "you have a faster speed up and this is kind of like comparing the the boot time for different languages so um that",
    "start": "738720",
    "end": "746079"
  },
  {
    "text": "that's part of the init optimization there and then another one that people",
    "start": "746079",
    "end": "752000"
  },
  {
    "start": "748000",
    "end": "859000"
  },
  {
    "text": "uh i guess is is for some of us that we've been involved of trying to solve this issue for",
    "start": "752000",
    "end": "758079"
  },
  {
    "text": "everyone in the best way possible some users are fine to set these some knobs",
    "start": "758079",
    "end": "763519"
  },
  {
    "text": "that we have but the thing is sometimes they're not aware that these knobs exist so for example on the last talk they",
    "start": "763519",
    "end": "770639"
  },
  {
    "text": "were talking about setting the mean scale right minimum set of replicas and some users are okay at this time by",
    "start": "770639",
    "end": "778000"
  },
  {
    "text": "paying that that penalty of having a pod running 24 7. but it'd be running 24 7.",
    "start": "778000",
    "end": "784240"
  },
  {
    "text": "the candidate would not shut it down the other way that you can have is another knob is scaled down delay which",
    "start": "784240",
    "end": "791360"
  },
  {
    "text": "is uh once the q proxy reports that there's no more request coming in that it's okay to",
    "start": "791360",
    "end": "797760"
  },
  {
    "text": "scale to zero it tells the system hey wait this amount of time maybe you wait",
    "start": "797760",
    "end": "802800"
  },
  {
    "text": "10 minutes instead of being the default the default is very aggressive wait this amount of time before you shut down will",
    "start": "802800",
    "end": "809120"
  },
  {
    "text": "terminate the pod and that could be a setting that can avoid the the uh co-stars that we can say avoid the um",
    "start": "809120",
    "end": "816639"
  },
  {
    "text": "have less frequency of coasters and the last one it could be like maybe you want",
    "start": "816639",
    "end": "822079"
  },
  {
    "text": "not every pod to be like left longer but maybe the last part of the revision of",
    "start": "822079",
    "end": "828399"
  },
  {
    "text": "the deployment leave it uh um alive a longer amount of time because there",
    "start": "828399",
    "end": "833519"
  },
  {
    "text": "might be a request coming in likely um coming in and that that avoids a co-star",
    "start": "833519",
    "end": "838560"
  },
  {
    "text": "so it's about measuring this knob so always measure and run the load test",
    "start": "838560",
    "end": "844240"
  },
  {
    "text": "that looks like there your your load if it's bursty and measure what you change but there's knobs that are available and",
    "start": "844240",
    "end": "850959"
  },
  {
    "text": "sometimes we don't mention it because we want to get to that nirvana place that co-stars are like uh you know physics is",
    "start": "850959",
    "end": "857519"
  },
  {
    "text": "zero right and that's not possible and and this one is uh one that i i",
    "start": "857519",
    "end": "863360"
  },
  {
    "start": "859000",
    "end": "970000"
  },
  {
    "text": "think uh for people using istio not everyone uses istio but you need to be careful when you add istio and you have",
    "start": "863360",
    "end": "869680"
  },
  {
    "text": "it and on top of that use it in this still mesh that you're adding another container that needs to boot up that",
    "start": "869680",
    "end": "876320"
  },
  {
    "text": "needs to do things in your ip tables that's the unique container",
    "start": "876320",
    "end": "881360"
  },
  {
    "text": "plus you have your istio side card and plus the two containers so everything needs to come up um and be ready for that request to",
    "start": "881360",
    "end": "888639"
  },
  {
    "text": "go and get processed so that will hit your co-start and you just have to measure how long",
    "start": "888639",
    "end": "894560"
  },
  {
    "text": "uh that will be for you and actually we have a a tool called k-perf that can",
    "start": "894560",
    "end": "900399"
  },
  {
    "text": "help you merger that the other one that i recently found out about doing the",
    "start": "900399",
    "end": "905600"
  },
  {
    "text": "end-user interviews which by the way i'm still looking for end-users grabbed me to schedule an interview is a type of",
    "start": "905600",
    "end": "913279"
  },
  {
    "text": "cni uh cloud provider so some cloud providers would assign you like a",
    "start": "913279",
    "end": "918480"
  },
  {
    "text": "elastic ip or real ip and that would take more time to talk to the cloud provider to get to the pool to",
    "start": "918480",
    "end": "926079"
  },
  {
    "text": "get an ip assigned to a to a pod and this is some sometimes a this came",
    "start": "926079",
    "end": "932000"
  },
  {
    "text": "from a user that was moving from burn metal on premises to on cloud and they",
    "start": "932000",
    "end": "937040"
  },
  {
    "text": "haven't modernized all aspects of their security model so they need that pod to have a certain ip address so that's it's",
    "start": "937040",
    "end": "944320"
  },
  {
    "text": "costing them the code start i actually say it's an end user that is in production which i was super happy to",
    "start": "944320",
    "end": "949839"
  },
  {
    "text": "hear about that but it's something that it came up in the conversation that is is affecting them in co-stars so watch",
    "start": "949839",
    "end": "956320"
  },
  {
    "text": "out for those type of things of what are the things that container d or cubelet are doing with the cloud provider that",
    "start": "956320",
    "end": "962720"
  },
  {
    "text": "might hit your co-star so sometimes it's in your hands and sometimes it's maybe modernizing the way you deploy these",
    "start": "962720",
    "end": "968720"
  },
  {
    "text": "worker nodes and then leave it to paul to see what we're doing with upstream",
    "start": "968720",
    "end": "975040"
  },
  {
    "text": "so carlos went over a number of ways that you know you can do things right now to kind of improve your container start time i want to talk about some",
    "start": "975040",
    "end": "981279"
  },
  {
    "text": "things that you will be able to do very soon that we're working on both upstream and k-native to make things faster",
    "start": "981279",
    "end": "988399"
  },
  {
    "text": "so in upstream we've been starting to work with the kubernetes folks to see you know what are ways that we can get containers to run faster so marcus",
    "start": "988399",
    "end": "995600"
  },
  {
    "text": "went to sig note gave a presentation on what kind of arcade native use cases are and we've been working with them to try",
    "start": "995600",
    "end": "1000720"
  },
  {
    "text": "to get some of these things upstreamed and find those things out we work with mike brown who's a container d maintainer who's got a number of great",
    "start": "1000720",
    "end": "1006079"
  },
  {
    "text": "ideas that we're making use of so i want to mention a couple of them here um just so that we're aware uh that these",
    "start": "1006079",
    "end": "1012399"
  },
  {
    "text": "things are coming um you know we talked about the the issue of if you have to always pull your images you never want to use the latest",
    "start": "1012399",
    "end": "1018160"
  },
  {
    "text": "tag because it takes time to have to pull an image but it might be a security requirement if you don't want tenants to",
    "start": "1018160",
    "end": "1023440"
  },
  {
    "text": "be you know using that cached image on your thing so there's this cap out there for insurer secrets pulled image",
    "start": "1023440",
    "end": "1029839"
  },
  {
    "text": "that will basically allow you to not have to use the latest tag whoops",
    "start": "1029839",
    "end": "1035678"
  },
  {
    "text": "not use the latest tag but still be able to so you can kind of catch your image but it'll do the security authentication check in your image that's going to help",
    "start": "1035679",
    "end": "1041280"
  },
  {
    "text": "speed up image pools not having to use the latest tag there there's a number of performance improvements that are happening in the",
    "start": "1041280",
    "end": "1047038"
  },
  {
    "text": "cni layer uh there's prs out there that have reduced you know when you're loading your cni plug-ins not loading",
    "start": "1047039",
    "end": "1052480"
  },
  {
    "text": "them in parallel as opposed to in sequence which speeds up the runtime stuff disabling the dad which is dropped about",
    "start": "1052480",
    "end": "1058480"
  },
  {
    "text": "a second off the runtime um which are very good um and then in terms of cubelet performance you know one of the",
    "start": "1058480",
    "end": "1063919"
  },
  {
    "text": "things we do in k native is we run probes to make sure things are up probes run at a second interval",
    "start": "1063919",
    "end": "1069200"
  },
  {
    "text": "um so if you know it's not ready when the probe first time you got to wait another second for that thing to run again we've got it kept out there",
    "start": "1069200",
    "end": "1075679"
  },
  {
    "text": "now to run probes on a sub second interval so we can respond even faster to things like that",
    "start": "1075679",
    "end": "1081760"
  },
  {
    "text": "and we presented the sig node i think two weeks ago some of the red hat folks derek and others mentioned that they",
    "start": "1081760",
    "end": "1087440"
  },
  {
    "text": "were working on us a similar kep on the evented plague which is going to use",
    "start": "1087440",
    "end": "1092480"
  },
  {
    "text": "cubit based on events as opposed to kind of the the polling methods that should speed things up as well",
    "start": "1092480",
    "end": "1098960"
  },
  {
    "text": "show some things upstream um in k-native itself work against performance enhancements as well we're working on",
    "start": "1098960",
    "end": "1104000"
  },
  {
    "text": "more probe support adding startup probes which hopefully make things a little faster and then two things that i kind of want to demo for you now",
    "start": "1104000",
    "end": "1110640"
  },
  {
    "text": "um the container freezer which is something that jules had pocked a while back but we've got in an alpha in the sandbox and then kperf which is a",
    "start": "1110640",
    "end": "1117600"
  },
  {
    "text": "performance benchmarking tool that we have so the container freezer just this is",
    "start": "1117600",
    "end": "1122640"
  },
  {
    "start": "1120000",
    "end": "1181000"
  },
  {
    "text": "you know this is a similar picture we saw before this is kind of how k native works we've got the activator the auto scaler you've got a pod that's running",
    "start": "1122640",
    "end": "1129520"
  },
  {
    "text": "what the container freezer does is it runs a separate uh freeze daemon and what that demon does is it freezes",
    "start": "1129520",
    "end": "1136720"
  },
  {
    "text": "the user pod so when a request comes in still follows the same uh process gets the cube proxy the q proxy calls out",
    "start": "1136720",
    "end": "1144240"
  },
  {
    "text": "to the to the demon sends it an unfreeze request we then in the container run time send you know a resume request in",
    "start": "1144240",
    "end": "1150880"
  },
  {
    "text": "container d it's resume i think we've got there's a pr out there for cryo as well that unfreezes the container",
    "start": "1150880",
    "end": "1157440"
  },
  {
    "text": "allows it to run then the request goes to the application as normally the nice thing about this",
    "start": "1157440",
    "end": "1163200"
  },
  {
    "text": "here is you can leave your pod running and it's not you know actively running you pause it in between requests when",
    "start": "1163200",
    "end": "1168880"
  },
  {
    "text": "the request is finished either qroc sends a request back out frees the pod pod gets frozen",
    "start": "1168880",
    "end": "1175120"
  },
  {
    "text": "so it's kind of out there in an alpha right now people could use",
    "start": "1175120",
    "end": "1181360"
  },
  {
    "start": "1181000",
    "end": "1209000"
  },
  {
    "text": "all right one of the nice things about this is because your this is the difference between kind of that you know the i think we call the warm memory warm",
    "start": "1181840",
    "end": "1189840"
  },
  {
    "text": "container responding to a pause or a pause pod versus not knocks",
    "start": "1189840",
    "end": "1196559"
  },
  {
    "text": "i can't add in my head but two seconds ish off the time so it definitely speeds up",
    "start": "1196559",
    "end": "1202640"
  },
  {
    "text": "the the response to a request when using said thing",
    "start": "1202640",
    "end": "1208320"
  },
  {
    "text": "okay and then kind of finally k-perf it's our performance benchmarking oh well oops i",
    "start": "1208480",
    "end": "1214880"
  },
  {
    "start": "1209000",
    "end": "1316000"
  },
  {
    "text": "did want to kind of just kind of demo kind of what the container freezer looked like really quickly there with me one second",
    "start": "1214880",
    "end": "1221720"
  },
  {
    "text": "so i'm just going to set this up really quickly just to kind of show kind of how this thing works",
    "start": "1228240",
    "end": "1234120"
  },
  {
    "text": "all right so basically just kind of a basic service here called sleep talk or the sleep talker just kind of ticks on a",
    "start": "1247440",
    "end": "1252720"
  },
  {
    "text": "thing so i'm just kind of sure this works really quick",
    "start": "1252720",
    "end": "1257080"
  },
  {
    "text": "all right so this is just running the log from said pod you can't see anything happening right now when i call",
    "start": "1275919",
    "end": "1282559"
  },
  {
    "text": "on the",
    "start": "1282559",
    "end": "1285120"
  },
  {
    "text": "so you're gonna see it's ticking and you can't really read what that thing says it's tiny but basically what happens is when the container gets its request the",
    "start": "1289360",
    "end": "1296480"
  },
  {
    "text": "pod runs you see it in the logs let's show that one more time real quick",
    "start": "1296480",
    "end": "1301200"
  },
  {
    "text": "so it's tick tick tick then when the screen stops the thing stops such as kind of a live demo of it actually pausing a container",
    "start": "1301760",
    "end": "1308880"
  },
  {
    "text": "as it runs",
    "start": "1308880",
    "end": "1311520"
  },
  {
    "start": "1316000",
    "end": "1364000"
  },
  {
    "text": "k perfect is our performance benchmarking tool um you just kind of see here i'm not going to run this up",
    "start": "1316799",
    "end": "1321840"
  },
  {
    "text": "basically kind of you can run a number of pods gather benchmarks on them and kind of compare them against it here we're just showing kind of",
    "start": "1321840",
    "end": "1328000"
  },
  {
    "text": "um pod creation times you can see the yellow line at the bottom that's when the pot is scheduled the",
    "start": "1328000",
    "end": "1333200"
  },
  {
    "text": "orange line is when the container is ready so you can see kind of the amount of time that it takes and you can see the different um",
    "start": "1333200",
    "end": "1339600"
  },
  {
    "text": "times that that uh it takes for the cube products to start the user container to start",
    "start": "1339600",
    "end": "1345520"
  },
  {
    "text": "so yeah and that we can run that um in the ci nato did some good work adding that um into the ci so we can test kind",
    "start": "1345520",
    "end": "1351919"
  },
  {
    "text": "of how each pr that we add improves the performance or doesn't improve the performance as the case may",
    "start": "1351919",
    "end": "1358159"
  },
  {
    "text": "be i think i think that covers it",
    "start": "1358159",
    "end": "1365919"
  },
  {
    "text": "generates that that's html graph is generated by the tool so it's not uh something that",
    "start": "1366640",
    "end": "1373120"
  },
  {
    "text": "you have to do anything about it is the tool generates that html and also just uh does the low",
    "start": "1373120",
    "end": "1379200"
  },
  {
    "text": "load node testing and um it's a repo that is looking for contributors um so",
    "start": "1379200",
    "end": "1385840"
  },
  {
    "text": "prs are welcome um so we have yeah that's one of the one of the repos that if you're",
    "start": "1385840",
    "end": "1390960"
  },
  {
    "text": "new to to the community and it's something that that you want to get started it's a good one to",
    "start": "1390960",
    "end": "1397200"
  },
  {
    "text": "uh small one and scope that you can help and and get started so with that",
    "start": "1397200",
    "end": "1402400"
  },
  {
    "text": "um i'm glad that we got the slides in half um i thought i'm going to go over uh",
    "start": "1402400",
    "end": "1408559"
  },
  {
    "text": "questions i think that's it",
    "start": "1408559",
    "end": "1413919"
  },
  {
    "text": "that's it one of them thank you",
    "start": "1413919",
    "end": "1419039"
  },
  {
    "text": "does anyone have okay i'm going there",
    "start": "1419039",
    "end": "1424120"
  },
  {
    "text": "hey hello uh so just wanted to understand uh exactly like what just happened behind the scene when you say",
    "start": "1430559",
    "end": "1435840"
  },
  {
    "text": "the container a pod is paused like i just wanted to understand in terms of uh like when it",
    "start": "1435840",
    "end": "1441679"
  },
  {
    "text": "auto scales down to zero we are saving on resources with respect to compute right like is that",
    "start": "1441679",
    "end": "1447440"
  },
  {
    "text": "uh a similar thing that we can achieve during this because the core start definitely guests uh off with the",
    "start": "1447440",
    "end": "1453760"
  },
  {
    "text": "container pausing and pausing but uh what what exactly does happen with",
    "start": "1453760",
    "end": "1458799"
  },
  {
    "text": "respect to the computer resource saving does how how how does that work like",
    "start": "1458799",
    "end": "1464480"
  },
  {
    "text": "because i was actually looking into the repository i could not find a lot of documentation around how it works",
    "start": "1464480",
    "end": "1470320"
  },
  {
    "text": "yep so the question is kind of when you freeze a container what happens with the resource usage um",
    "start": "1470320",
    "end": "1476320"
  },
  {
    "text": "so right now it does is it pauses cpu usage so uh the memory still",
    "start": "1476320",
    "end": "1482000"
  },
  {
    "text": "is allocated to the pods you're not saving on memory but you are saving on cpu so this",
    "start": "1482000",
    "end": "1487840"
  },
  {
    "text": "is you know it prevents bitcoin miners for example if you've got an idling pod they can't you know there's no cpu",
    "start": "1487840",
    "end": "1493600"
  },
  {
    "text": "cycles that are spinning so kind of at the moment it's really just saving on cpu resources as opposed to memory and",
    "start": "1493600",
    "end": "1499679"
  },
  {
    "text": "there's some things maybe down the line like maybe like cryo or something like that where you might be able to kind of also save on the memory but for the",
    "start": "1499679",
    "end": "1505279"
  },
  {
    "text": "moment it's just it's saving cpu cycles",
    "start": "1505279",
    "end": "1509360"
  },
  {
    "text": "okay it's similar if you do um like a container have different states the container can be stopped can be can be",
    "start": "1511440",
    "end": "1518640"
  },
  {
    "text": "running but but also there's another state that is paused so if you are familiar with docker in",
    "start": "1518640",
    "end": "1525039"
  },
  {
    "text": "always been there i think you can do docker pause and basically that's essentially what is what it's doing but",
    "start": "1525039",
    "end": "1530720"
  },
  {
    "text": "we're doing it with container id and there's a pr is the tpr open right yeah somebody from the community did a pr to",
    "start": "1530720",
    "end": "1538080"
  },
  {
    "text": "add that to cryo uh so it's a an api that the demon calls to cryo saying",
    "start": "1538080",
    "end": "1543120"
  },
  {
    "text": "please stop this container from this pod um and then and then we'll unpause it so",
    "start": "1543120",
    "end": "1549520"
  },
  {
    "text": "pause and pause yeah and that was just added to uh cryo",
    "start": "1549520",
    "end": "1555360"
  },
  {
    "text": "in their 124 release so that's recently added to cryon then they they",
    "start": "1555360",
    "end": "1560720"
  },
  {
    "text": "added it uh it was recently added because i checked and i described superstition and i went over there and",
    "start": "1560720",
    "end": "1566799"
  },
  {
    "text": "it was um was recently added and then they jump over and then did the pr",
    "start": "1566799",
    "end": "1573039"
  },
  {
    "text": "just to mention because we were talking about you know contributors this was a contributor who wanted this function for cryo it wasn't",
    "start": "1573039",
    "end": "1578480"
  },
  {
    "text": "implemented in crowd so went over to cryo did the pr to add the implementation in cryo and then wrote",
    "start": "1578480",
    "end": "1584320"
  },
  {
    "text": "the pr for the container freezer so a great example of community involvement",
    "start": "1584320",
    "end": "1591760"
  },
  {
    "text": "any okay i think anyone else got questions to carlos and paul",
    "start": "1592799",
    "end": "1599840"
  },
  {
    "text": "you wait you want to ask questions so um",
    "start": "1600799",
    "end": "1606799"
  },
  {
    "text": "what what barriers do you see to turning this on by default in",
    "start": "1606799",
    "end": "1612559"
  },
  {
    "text": "k native i think one of the big barriers right",
    "start": "1612559",
    "end": "1620000"
  },
  {
    "text": "now is around kind of the probing interface right now we run a readiness probe that checks to make sure the container is ready and if your container",
    "start": "1620000",
    "end": "1627039"
  },
  {
    "text": "is paused the readiness probe isn't like that which is hence part of the reason why we",
    "start": "1627039",
    "end": "1632080"
  },
  {
    "text": "want to add startup probes so that we can you know perhaps make the readiness probe",
    "start": "1632080",
    "end": "1637840"
  },
  {
    "text": "not always there by default um so i think that that's i think that's the biggest um thing and then honestly like",
    "start": "1637840",
    "end": "1643279"
  },
  {
    "text": "we need to test it a lot more it's it's alpha for a reason because it's not really been it's still",
    "start": "1643279",
    "end": "1648559"
  },
  {
    "text": "still the ink is still wet on that one as the case may be",
    "start": "1648559",
    "end": "1653919"
  },
  {
    "text": "and i don't know if the folks have an answer for that but another one would be like take advantage through the cubelet",
    "start": "1653919",
    "end": "1660399"
  },
  {
    "text": "right if you we set pods to have certain limits for cpus and you have a node with",
    "start": "1660399",
    "end": "1666320"
  },
  {
    "text": "four parts that are paused you can fit other parts in there so how do we teach kubernetes to be aware that",
    "start": "1666320",
    "end": "1672559"
  },
  {
    "text": "they're small parts that are paused not consuming cpu but it's consumer memory so you can",
    "start": "1672559",
    "end": "1678159"
  },
  {
    "text": "squeeze something in and then maybe looking into like um the future about moving a a frozen container or a pot",
    "start": "1678159",
    "end": "1686320"
  },
  {
    "text": "from one node to another pod that's something that i call it like the v motion pod",
    "start": "1686320",
    "end": "1692320"
  },
  {
    "text": "i know v motion is a vmware i get i'm getting dated um uh in that aspect but it's the",
    "start": "1692320",
    "end": "1698559"
  },
  {
    "text": "management in peace and the pro but the first one to to kick out is creep rocks is not even aware that this container is",
    "start": "1698559",
    "end": "1705520"
  },
  {
    "text": "frozen so i don't know matt has more to add i i thought this slide said that uh the q",
    "start": "1705520",
    "end": "1712640"
  },
  {
    "text": "proxy requested that it be frozen",
    "start": "1712640",
    "end": "1716640"
  },
  {
    "text": "sorry doesn't the q proxy reach out to the freeze demon to tell it to freeze it it sends like a like an event of the",
    "start": "1717679",
    "end": "1725679"
  },
  {
    "text": "concurrency it's part part of the handler chain so we kind of add that in there so the call will go out and we'll freeze and then",
    "start": "1725679",
    "end": "1732080"
  },
  {
    "text": "when the request comes in it'll trigger it again to unfreeze so so it should know when it's frozen",
    "start": "1732080",
    "end": "1737440"
  },
  {
    "text": "yeah i think we could add a flag and it decides this first i don't think there's anything explicitly in there at the moment but yes it could know",
    "start": "1737440",
    "end": "1742720"
  },
  {
    "text": "so i mean it also proxies all of the probes so it could just stop probing",
    "start": "1742720",
    "end": "1748720"
  },
  {
    "text": "yeah um we talked about that but i think the well that's under discussion but yeah it technically could yes",
    "start": "1748720",
    "end": "1754480"
  },
  {
    "text": "okay uh so i'm curious what uh how the cry",
    "start": "1754480",
    "end": "1759679"
  },
  {
    "text": "interface for freezing is ackled at the note level and",
    "start": "1759679",
    "end": "1765440"
  },
  {
    "text": "how that's expressed in terms of the privilege the freeze demon needs",
    "start": "1765440",
    "end": "1771279"
  },
  {
    "text": "is it like i assume it's mounting something like a unix socket to talk to",
    "start": "1773039",
    "end": "1778480"
  },
  {
    "text": "the cry stuff yeah it's mounting a unit socket and then um we add the it so it runs per node so it's a daemon set it",
    "start": "1778480",
    "end": "1784880"
  },
  {
    "text": "runs per node that i think it makes the call over the socket and we um i have to go back and look it's been a",
    "start": "1784880",
    "end": "1790399"
  },
  {
    "text": "little bit but we mount the secret in a in a volume that then the service account has access to",
    "start": "1790399",
    "end": "1798000"
  },
  {
    "text": "so that that may be another uh thing to consider in terms of getting it on by default as some folks may not want you",
    "start": "1798000",
    "end": "1804960"
  },
  {
    "text": "know a new daemon set running with you know some significant level of capability on every",
    "start": "1804960",
    "end": "1812000"
  },
  {
    "text": "node but um it sounds super cool and i'm glad that that landed in cri",
    "start": "1812000",
    "end": "1818799"
  },
  {
    "text": "cool thanks just [Music]",
    "start": "1818799",
    "end": "1824259"
  },
  {
    "text": "anyone else one two three okay",
    "start": "1828880",
    "end": "1835360"
  },
  {
    "text": "thank you paul and carlos thanks everyone",
    "start": "1835360",
    "end": "1841559"
  }
]
[
  {
    "text": "hi everyone welcome to this uh talk on how to carefully replace thousands of",
    "start": "5560",
    "end": "10920"
  },
  {
    "text": "nodes every day my name is Adrien Tuyo I'm an",
    "start": "10920",
    "end": "16240"
  },
  {
    "text": "engineering manager at data dog I lead the compute node life cycle team and",
    "start": "16240",
    "end": "21800"
  },
  {
    "text": "today I have the uh pleasure to be speaking with Ryan Hey folks I'm Ryan",
    "start": "21800",
    "end": "26840"
  },
  {
    "text": "mcnamer I'm an engineer at data dog with uh same team as Adrien and I've been doing kubernetes things for a few years",
    "start": "26840",
    "end": "34320"
  },
  {
    "text": "now data dog is an observability company every hour we ingest trillions of data",
    "start": "34320",
    "end": "40360"
  },
  {
    "text": "points from our customers applications and infrastructure to process those data",
    "start": "40360",
    "end": "45440"
  },
  {
    "text": "points uh we uh run hundreds of thousands of kubernetes pods on tens of thousands of notes in",
    "start": "45440",
    "end": "53440"
  },
  {
    "text": "many clusters and to meet our customers where they are we run on multiple",
    "start": "53440",
    "end": "58600"
  },
  {
    "text": "clouds also to uh better control the performance and reliability of our platform and as consistently as possible",
    "start": "58600",
    "end": "65680"
  },
  {
    "text": "across Cloud providers we run cities from scratch part of our duties as",
    "start": "65680",
    "end": "71200"
  },
  {
    "text": "cluster operators is to replace nodes when needed and at all scale this happens thousands of times a day uh and we do",
    "start": "71200",
    "end": "78240"
  },
  {
    "text": "that without breaking applications if you use a manage distribution you may not fully control",
    "start": "78240",
    "end": "84079"
  },
  {
    "text": "when noes need to be replaced uh but you are responsible for protecting your workloads when that happens",
    "start": "84079",
    "end": "91240"
  },
  {
    "text": "so today we'll first explain why nodes need to be replaced how it's done generally uh and more specifically at",
    "start": "91240",
    "end": "97960"
  },
  {
    "text": "data dog uh you'll learn about some of the strategies that we use to protect our workloads when we replace nodes and",
    "start": "97960",
    "end": "105360"
  },
  {
    "text": "we uh we hope to uh start a conversation on turning some of those strategies into uh kubernetes",
    "start": "105360",
    "end": "111880"
  },
  {
    "text": "enhancements so there are many reasons to replace notes when we uh started running kubernetes we needed a solution",
    "start": "111880",
    "end": "119119"
  },
  {
    "text": "uh to uh first quickly react to Hardware failures like bad memory failing discs",
    "start": "119119",
    "end": "124840"
  },
  {
    "text": "at our scale that's not so rare um and they don't necessarily break the nodes completely uh but they have negative",
    "start": "124840",
    "end": "131640"
  },
  {
    "text": "impact on performance so we need to do something about it we also wanted to anticipate VM retirements uh that's when",
    "start": "131640",
    "end": "137959"
  },
  {
    "text": "the cloud provider reclaims your virtual machines um and uh yeah we don't want",
    "start": "137959",
    "end": "143080"
  },
  {
    "text": "those to uh come as a surprise uh but these days the main use Case by far of",
    "start": "143080",
    "end": "149040"
  },
  {
    "text": "the solution that we built is to upgrade machine images uh we do that for kubernetes upgrades and also for",
    "start": "149040",
    "end": "156200"
  },
  {
    "text": "operating system security security patches as you may have seen this morning uh in a a keynote presentation",
    "start": "156200",
    "end": "162280"
  },
  {
    "text": "by my colleagues hant and lauron uh we had a good reason to disable unattended",
    "start": "162280",
    "end": "167840"
  },
  {
    "text": "upgrades uh and we uh exclusively rely on node replacement for operating system",
    "start": "167840",
    "end": "172920"
  },
  {
    "text": "patches now more and more we also replace nodes um to use faster and cheaper VMS um",
    "start": "172920",
    "end": "180879"
  },
  {
    "text": "so our applications are highly available and they generally tolerate involuntary",
    "start": "180879",
    "end": "186280"
  },
  {
    "text": "disruptions which is the sudden loss of a node and its SPS but the the reasons",
    "start": "186280",
    "end": "191560"
  },
  {
    "text": "listed here just occur too frequently to just kill the nodes so uh luckily",
    "start": "191560",
    "end": "196640"
  },
  {
    "text": "there's a better way so you may be familiar with some",
    "start": "196640",
    "end": "201879"
  },
  {
    "text": "node replacement Solutions uh the three major Cloud providers automatically upgrade nodes and handle VM retirements",
    "start": "201879",
    "end": "209159"
  },
  {
    "text": "with uh manage Noe uh no groups and N pools on AKs and gke for Noe Auto Repair",
    "start": "209159",
    "end": "216480"
  },
  {
    "text": "they rely on a an open- source project called node problem detector uh and that",
    "start": "216480",
    "end": "221640"
  },
  {
    "text": "can run either as a Damon set or as part of machine images it uh detects some",
    "start": "221640",
    "end": "227360"
  },
  {
    "text": "common problems like bad memory failling discs uh adds a condition on the Node",
    "start": "227360",
    "end": "233000"
  },
  {
    "text": "status and that condition triggers no Replacements finally I'd like to mention",
    "start": "233000",
    "end": "238040"
  },
  {
    "text": "Carpenter uh it's a an alternative to cluster autoscaler on AWS uh and that",
    "start": "238040",
    "end": "243640"
  },
  {
    "text": "also takes care of no Replacements importantly all of those",
    "start": "243640",
    "end": "249519"
  },
  {
    "text": "Solutions rely on the eviction API to protect your workloads uh kubernetes doesn't fully handle node life cycle it",
    "start": "249519",
    "end": "257000"
  },
  {
    "text": "doesn't start nodes it doesn't stop nodes that is delegated to the cluster operator but one thing it does provide",
    "start": "257000",
    "end": "263280"
  },
  {
    "text": "is uh that API as a building block to build upon for to create a node replacement solution and the eviction",
    "start": "263280",
    "end": "270080"
  },
  {
    "text": "API is basically a conditional pod deletion the uh eviction API protects",
    "start": "270080",
    "end": "277600"
  },
  {
    "text": "pods covered by pod disruption budgets or pdb for short uh pdb is a kubernetes",
    "start": "277600",
    "end": "285199"
  },
  {
    "text": "object uh that you can represent as yl like this uh it matches pods uh it",
    "start": "285199",
    "end": "290560"
  },
  {
    "text": "covers SP M um that match a label selector um you can specify a maximum number of unavailable pods among those",
    "start": "290560",
    "end": "298560"
  },
  {
    "text": "covered and while enough pods are available any one of them can be deleted",
    "start": "298560",
    "end": "304960"
  },
  {
    "text": "uh you can also specify a minimum number of available pods or use percentages instead of",
    "start": "304960",
    "end": "311000"
  },
  {
    "text": "integers available uh means that all of a pods containers uh pass their",
    "start": "311000",
    "end": "316880"
  },
  {
    "text": "Readiness probes Readiness probes are defined in a PO speec uh they can be HTTP calls uh TCP calls crpc commands",
    "start": "316880",
    "end": "325440"
  },
  {
    "text": "and they're executed by the cuet and the results of the those probes",
    "start": "325440",
    "end": "330800"
  },
  {
    "text": "sort of cascade down to the pdb status the primary use of Readiness",
    "start": "330800",
    "end": "336199"
  },
  {
    "text": "probe is actually for service availability uh um when so when a PO is",
    "start": "336199",
    "end": "342479"
  },
  {
    "text": "ready its IP is registered as an endpoint of services and sort of reused",
    "start": "342479",
    "end": "347720"
  },
  {
    "text": "as a healthiness indicator for p disruption budgets and we'll see how that is sort of limiting in a way",
    "start": "347720",
    "end": "353639"
  },
  {
    "text": "later so to replace a node uh gracefully a solution must Implement Four B basic",
    "start": "353639",
    "end": "359840"
  },
  {
    "text": "steps um Cordon the node evict the pods together that's called draining the",
    "start": "359840",
    "end": "365440"
  },
  {
    "text": "nodes uh terminate the old VM and start a new one you uh you may want to start",
    "start": "365440",
    "end": "371360"
  },
  {
    "text": "the new VM earlier to uh speed up scheduling as we'll see later to Cordon a node you mark it",
    "start": "371360",
    "end": "378080"
  },
  {
    "text": "unschedulable that's a spec field uh or uh or you taint it so new parts going land on",
    "start": "378080",
    "end": "384960"
  },
  {
    "text": "it then you evict the pods and that's a conditional deletion protected by po",
    "start": "384960",
    "end": "390560"
  },
  {
    "text": "disruption budget as I said uh if there's no pdb uh careful",
    "start": "390560",
    "end": "396080"
  },
  {
    "text": "that just the PO is simply deleted it's it's unprotected deletion the uh the Pod disruption",
    "start": "396080",
    "end": "403080"
  },
  {
    "text": "budget status is a reflection of the riness probes from the puts",
    "start": "403080",
    "end": "409319"
  },
  {
    "text": "containers and going back to the eviction uh if enough pods are available",
    "start": "410120",
    "end": "416599"
  },
  {
    "text": "the eviction can proceed into a deletion the containers are terminated um and um",
    "start": "416599",
    "end": "424240"
  },
  {
    "text": "typically the deployment or stateful set controller or any controller that owns",
    "start": "424240",
    "end": "429319"
  },
  {
    "text": "the pods will recreate pods immediately so when a node is empty",
    "start": "429319",
    "end": "435440"
  },
  {
    "text": "you've evicted all the pods uh the the node replacement solution can terminate the VM uh that stops the",
    "start": "435440",
    "end": "441840"
  },
  {
    "text": "cuet and there's a component called Cloud controller manager uh which is a cloud specific kubernetes Plugin or",
    "start": "441840",
    "end": "448440"
  },
  {
    "text": "add-on that detects that the VM is gone and it deletes the node uh interestingly",
    "start": "448440",
    "end": "455360"
  },
  {
    "text": "uh C printer has a sort of an alternative uh way to do this uh it deletes the nodes and the termination of",
    "start": "455360",
    "end": "462000"
  },
  {
    "text": "VMS is a finalizer on the nodes then or earlier the solution could",
    "start": "462000",
    "end": "467919"
  },
  {
    "text": "start a new VM that starts a cuet it registers as a node and the schedular",
    "start": "467919",
    "end": "473400"
  },
  {
    "text": "sees the node and can bind the plot to it containers can start Etc",
    "start": "473400",
    "end": "480960"
  },
  {
    "text": "so not the time gap between the new pods creation and uh their scheduling in this",
    "start": "480960",
    "end": "486360"
  },
  {
    "text": "diagram they uh so that's why the it's sometimes useful to start a new node",
    "start": "486360",
    "end": "492440"
  },
  {
    "text": "before draining the old one however that's not always necessary the new pods could find um some room on existing",
    "start": "492440",
    "end": "498680"
  },
  {
    "text": "nodes to be bin packed so I've mentioned a few examples of node replacement solutions that you",
    "start": "498680",
    "end": "504800"
  },
  {
    "text": "may be familiar with I've explained how they generally work uh and I'll briefly talk about uh the solution that we built",
    "start": "504800",
    "end": "512279"
  },
  {
    "text": "at data dog for more details I invite you to watch an episode of data dog on that I recorded recently with another",
    "start": "512279",
    "end": "517839"
  },
  {
    "text": "colleague of mine called D David bank but in short uh we first considered using node problem node problem detector",
    "start": "517839",
    "end": "525360"
  },
  {
    "text": "but we uh we already have a Damon set that collects Health Data about nodes",
    "start": "525360",
    "end": "531399"
  },
  {
    "text": "and that's the data dog agent uh so our not prom detector uh is uh simply runs",
    "start": "531399",
    "end": "536440"
  },
  {
    "text": "as a controller and transforms uh data dog monitors into node",
    "start": "536440",
    "end": "542240"
  },
  {
    "text": "conditions uh in our solution any reason to replace a node is transcribed as a",
    "start": "542240",
    "end": "547399"
  },
  {
    "text": "node condition to uh to drain the nodes that have conditions we initially used a",
    "start": "547399",
    "end": "553360"
  },
  {
    "text": "tool called um drao by Planet Labs but we ended up writing our own adding some",
    "start": "553360",
    "end": "559200"
  },
  {
    "text": "node life cycle hooks that Ryan will discuss later um from the very beginning cluster",
    "start": "559200",
    "end": "566120"
  },
  {
    "text": "autoscaler uh has been a key component of the solution uh for any scale up or scale down",
    "start": "566120",
    "end": "572200"
  },
  {
    "text": "including node Replacements and uh finally we added a component that we",
    "start": "572200",
    "end": "577920"
  },
  {
    "text": "call the disruption budget manager that we use to enhance the eviction API in P disruption",
    "start": "577920",
    "end": "585000"
  },
  {
    "text": "budgets so at this point I'd like to emphasize the main key word of this",
    "start": "585640",
    "end": "591200"
  },
  {
    "text": "stocks title and that's carefully uh to drain thousands of nodes every day we",
    "start": "591200",
    "end": "596480"
  },
  {
    "text": "need velocity uh but more importantly we need to be careful not to break applications and that is true at any",
    "start": "596480",
    "end": "603079"
  },
  {
    "text": "scale so uh so let's have a look at some careful strategies as I said in the introduction",
    "start": "603079",
    "end": "610160"
  },
  {
    "text": "our platform supports hundreds of thousands of PODS and we care about most of them um but when we started this",
    "start": "610160",
    "end": "616519"
  },
  {
    "text": "project we uh we quickly realized that uh not all workloads came with their",
    "start": "616519",
    "end": "622279"
  },
  {
    "text": "with pdbs um so and without pdbs part disruption budgets evictions are",
    "start": "622279",
    "end": "628079"
  },
  {
    "text": "unprotected deletion so so we needed to enforce pdbs and so as with any",
    "start": "628079",
    "end": "635240"
  },
  {
    "text": "enforcement uh issue in infrastructure we could have added checks uh in CI at admission bugged our",
    "start": "635240",
    "end": "643560"
  },
  {
    "text": "users uh but instead it's always better we think to just do the work for the users so uh so we create pdbs by default",
    "start": "643560",
    "end": "650240"
  },
  {
    "text": "if they're missing for each workload if the if a custom pdb is not",
    "start": "650240",
    "end": "656480"
  },
  {
    "text": "provided we create one with Max unavailable equals 1 that is the safest default and it's actually fast enough in",
    "start": "656480",
    "end": "663680"
  },
  {
    "text": "most cases now remember that uh pdb select pods using label selectors uh and we",
    "start": "663680",
    "end": "670279"
  },
  {
    "text": "realized that if you try to use some of the existing pod labels you can end up",
    "start": "670279",
    "end": "675639"
  },
  {
    "text": "with overlapping pdbs uh so when a pod matches two pdbs the cube API server uh doesn't know",
    "start": "675639",
    "end": "684000"
  },
  {
    "text": "which one to use it's a configuration error and denies the uh the eviction",
    "start": "684000",
    "end": "690240"
  },
  {
    "text": "So to avoid pdb overlaps um for default pdbs we label the pods with their",
    "start": "690240",
    "end": "697440"
  },
  {
    "text": "deployment or stateful set or any other controllers a unique identifier that's a",
    "start": "697440",
    "end": "702959"
  },
  {
    "text": "metadata field and we select the label in the pdbs uh so users can still create custom",
    "start": "702959",
    "end": "710000"
  },
  {
    "text": "pdbs and uh in that case we still monitor for overlaps so they don't block our node replacement",
    "start": "710000",
    "end": "717480"
  },
  {
    "text": "campaigns now I'd like to talk about the Readiness probe and uh how it's not",
    "start": "717680",
    "end": "723959"
  },
  {
    "text": "expressive enough for disruption budges as I said the the primary use of",
    "start": "723959",
    "end": "731480"
  },
  {
    "text": "Readiness probe is to tell when pods are ready to uh accept traffic when a PO is",
    "start": "731480",
    "end": "738000"
  },
  {
    "text": "ready its IP is registered as an endpoint of a service so and they're reused for to",
    "start": "738000",
    "end": "745120"
  },
  {
    "text": "express disruption budgets in terms of available pods and to replace nodes we",
    "start": "745120",
    "end": "750839"
  },
  {
    "text": "need nonzero budgets in general but there are circumstances when disruptions",
    "start": "750839",
    "end": "756920"
  },
  {
    "text": "should be delayed and at the same critical time uh old pods should receive traffic so we",
    "start": "756920",
    "end": "764480"
  },
  {
    "text": "can't use the Readiness probe to Pilot the budget let me give you some examples um",
    "start": "764480",
    "end": "772800"
  },
  {
    "text": "an application is under pressure at that point losing a pod could push it over the edge or or an application is",
    "start": "772800",
    "end": "780440"
  },
  {
    "text": "undergoing maintenance uh an upgrade or any other type of operation and at that point losing a pod could uh disturb the",
    "start": "780440",
    "end": "788519"
  },
  {
    "text": "operation or there's an incident ongoing it may or may not be related to the application you don't know yet um but",
    "start": "788519",
    "end": "795920"
  },
  {
    "text": "evicting pods removing nodes at that time could actually delay the investigation it could remove evidence",
    "start": "795920",
    "end": "802680"
  },
  {
    "text": "uh or it could make things worse so to deal with those situations",
    "start": "802680",
    "end": "807760"
  },
  {
    "text": "uh we dynamically set disruption budgets in particular we reconcile them with",
    "start": "807760",
    "end": "813600"
  },
  {
    "text": "data dog monitors and an internal distributed lock system that we have but any third party State could",
    "start": "813600",
    "end": "821120"
  },
  {
    "text": "do for incidents uh because we don't want to update all pdbs at once we uh we",
    "start": "821120",
    "end": "828160"
  },
  {
    "text": "take advantage of the fact that evictions are a pod sub resource and so",
    "start": "828160",
    "end": "834240"
  },
  {
    "text": "as a a cuber API server uh resource eviction s can be intercepted at",
    "start": "834240",
    "end": "841160"
  },
  {
    "text": "admission using a validation web hook and so during some incidents we uh deny",
    "start": "841160",
    "end": "848000"
  },
  {
    "text": "evictions at admission so I've talked about how to",
    "start": "848000",
    "end": "853040"
  },
  {
    "text": "better protect your um workloads from evictions and uh Ryan will now discuss some ways to uh to optimize",
    "start": "853040",
    "end": "861120"
  },
  {
    "text": "drains thanks Adrian uh so as Adrian mentioned kubernetes delegates node life",
    "start": "861120",
    "end": "866920"
  },
  {
    "text": "cycle management completely to Cluster operators if you compare this to something like pods where kubernetes is",
    "start": "866920",
    "end": "873160"
  },
  {
    "text": "able to provide things like pre-stop posttop hooks uh kubernetes there actually has complete control over the",
    "start": "873160",
    "end": "879240"
  },
  {
    "text": "life cycle but for the case of nodes they're just a reflection of unowned external State uh namely virtual",
    "start": "879240",
    "end": "886079"
  },
  {
    "text": "machines uh so for this reason uh we've had to create our own node life cycle",
    "start": "886079",
    "end": "891680"
  },
  {
    "text": "hooks to make node scale down more graceful so here's the problem",
    "start": "891680",
    "end": "899560"
  },
  {
    "text": "uh we have uh this distribution for pod scheduling latency when pods need a",
    "start": "899560",
    "end": "905440"
  },
  {
    "text": "scale up in order to be rescheduled uh so you can see that the p50 is about a little over 2 minutes and the P99 is 5",
    "start": "905440",
    "end": "912639"
  },
  {
    "text": "minutes and this isn't terrible but for our applications and just to make uh it",
    "start": "912639",
    "end": "918120"
  },
  {
    "text": "more graceful uh we can do better than that so to solve this problem we do what",
    "start": "918120",
    "end": "925279"
  },
  {
    "text": "we call node pre-provisioning so here's a diagram explaining what happens without pre-provisioning so we'll have a",
    "start": "925279",
    "end": "931639"
  },
  {
    "text": "drain controller that will come and decide to drain a node and it will evict all of the pods on the nodes and they'll be deleted uh and then you can see that",
    "start": "931639",
    "end": "938759"
  },
  {
    "text": "the cube controller manager is creating uh replacement pods but depending on the state of the cluster these pods may or",
    "start": "938759",
    "end": "944839"
  },
  {
    "text": "may not be able to schedule right away it might require a node scale",
    "start": "944839",
    "end": "949920"
  },
  {
    "text": "up so what we do is before we evict any pods we create what we call a set of",
    "start": "950360",
    "end": "956880"
  },
  {
    "text": "fake pods and so the idea is that these fake pods are representative of the pods",
    "start": "956880",
    "end": "962519"
  },
  {
    "text": "that we're about to evict and so what that means is that once these pods are scheduled we can have high confidence",
    "start": "962519",
    "end": "969040"
  },
  {
    "text": "that if we were to delete them and reschedule all the pods that are actually currently running uh that they",
    "start": "969040",
    "end": "974360"
  },
  {
    "text": "would be able to schedule pretty much immediately or as fast as the cube scheduler can schedule them and in",
    "start": "974360",
    "end": "979959"
  },
  {
    "text": "practice what this means is we have uh scheduling times that go from minutes like I showed on the previous slide down",
    "start": "979959",
    "end": "986199"
  },
  {
    "text": "to just seconds so after the pods are scheduled the cluster a scaler will scale up if",
    "start": "986199",
    "end": "991680"
  },
  {
    "text": "it's needed uh once we see that that they're all uh all of the fake pods are scheduled we can delete all of them we",
    "start": "991680",
    "end": "998079"
  },
  {
    "text": "can start evicting the pods and then they'll be scheduled uh more or less right away um I say that they will",
    "start": "998079",
    "end": "1005000"
  },
  {
    "text": "probably be scheduled because the state of pending pods on a kubernetes cluster is relatively Dynamic so it could be the",
    "start": "1005000",
    "end": "1011600"
  },
  {
    "text": "case that there's some other scale up happening at the same time or there's a set of node drains happening but if we",
    "start": "1011600",
    "end": "1017040"
  },
  {
    "text": "do this for multiple no drains that are happening concurrently what we'll get is the sum of the resources required and so",
    "start": "1017040",
    "end": "1024480"
  },
  {
    "text": "we'll be able to schedule uh say there's two nodes currently draining we'll be able to schedule all of the pods that",
    "start": "1024480",
    "end": "1030000"
  },
  {
    "text": "are replacing the pods from those two",
    "start": "1030000",
    "end": "1034160"
  },
  {
    "text": "nodes the next uh node drain hook that we have is about persistent volume",
    "start": "1036959",
    "end": "1042079"
  },
  {
    "text": "claims uh so at data dog we use local persistent volumes and suffice to say we",
    "start": "1042079",
    "end": "1047240"
  },
  {
    "text": "do this for two reasons performance and cost and unlike remote volumes you might",
    "start": "1047240",
    "end": "1052919"
  },
  {
    "text": "be more familiar with uh local PVS and their Associated PVCs are bound to a",
    "start": "1052919",
    "end": "1058520"
  },
  {
    "text": "node tightly until they are deleted and when you delete them it's a representation of actually throwing that",
    "start": "1058520",
    "end": "1064640"
  },
  {
    "text": "data away um so until we get rid of a node the PVC associated with it and uh",
    "start": "1064640",
    "end": "1071280"
  },
  {
    "text": "the local disk uh will persist so what we have here is we have pod a and a pvca",
    "start": "1071280",
    "end": "1077320"
  },
  {
    "text": "that are coupled together uh when we evict and delete pod a uh pvca continues existing the stateful set",
    "start": "1077320",
    "end": "1084559"
  },
  {
    "text": "controller will create a replacement pod B but this pod B will have no PVC that",
    "start": "1084559",
    "end": "1089640"
  },
  {
    "text": "it can actually use because the node that the pvca is on is uh",
    "start": "1089640",
    "end": "1094720"
  },
  {
    "text": "coordinate so the fix is quite simple uh when we evict uh in our drain controller",
    "start": "1094720",
    "end": "1101480"
  },
  {
    "text": "uh pod a we simply delete the PVC associated with",
    "start": "1101480",
    "end": "1106919"
  },
  {
    "text": "it and you can see why we care so much that our evictions are protected because like I mentioned this is potentially",
    "start": "1106919",
    "end": "1113240"
  },
  {
    "text": "destructive action we're going to lose uh the persistent volume uh for this local node and this is fine because our",
    "start": "1113240",
    "end": "1120559"
  },
  {
    "text": "databases are set to handle losing a single uh database",
    "start": "1120559",
    "end": "1126360"
  },
  {
    "text": "replica so once uh once the PVC is deleted the stateful set controller can",
    "start": "1127880",
    "end": "1134520"
  },
  {
    "text": "go ahead and create pod B and what will happen is the cube scheduler will see",
    "start": "1134520",
    "end": "1139840"
  },
  {
    "text": "the new PVC and will schedule the Pod the local volume provisioner which runs",
    "start": "1139840",
    "end": "1145039"
  },
  {
    "text": "as a Damon set on nodes will be able to provision a local PV that this pod will",
    "start": "1145039",
    "end": "1151320"
  },
  {
    "text": "be able to use uh it's worth noting that before kubernetes 1.27 the stateful set",
    "start": "1151320",
    "end": "1157760"
  },
  {
    "text": "controller create of pod or sorry of pvcb uh would not actually happen",
    "start": "1157760",
    "end": "1163200"
  },
  {
    "text": "automatically uh one of our team members Raul contributed uh an upstream fix uh",
    "start": "1163200",
    "end": "1168320"
  },
  {
    "text": "so that the stateful set controller would look at missing PVCs at All Phases",
    "start": "1168320",
    "end": "1173799"
  },
  {
    "text": "of life cycles for stateful set pods and not just when staple set pods are being",
    "start": "1173799",
    "end": "1180480"
  },
  {
    "text": "created our last drain Hook is a bit more of a generic one and it allows applications to decide what logic they",
    "start": "1183320",
    "end": "1190159"
  },
  {
    "text": "want to perform when nodes are being drained so the API for this is similar in spirit to how the Pod Readiness gate",
    "start": "1190159",
    "end": "1196880"
  },
  {
    "text": "API works just for review uh there you have an external controller that decides when a pod is ready and it does this by",
    "start": "1196880",
    "end": "1203720"
  },
  {
    "text": "updating the status of a pod uh to just uh open the gate and say that the pot is",
    "start": "1203720",
    "end": "1208880"
  },
  {
    "text": "in fact ready so what we do for uh po eviction",
    "start": "1208880",
    "end": "1214039"
  },
  {
    "text": "Gates is we annotate the drain controller annotates the Pod as a candidate it's up to the app controller",
    "start": "1214039",
    "end": "1220480"
  },
  {
    "text": "it's running as a controller to notice this and then trigger any logic that's associated with it so the contract here",
    "start": "1220480",
    "end": "1228200"
  },
  {
    "text": "is that the Pod is about to go away and so this is an opportunity for the app controller to really do uh whatever kind",
    "start": "1228200",
    "end": "1234760"
  },
  {
    "text": "of logic it wants to do to smooth this transition so perhaps the current replica is a leader and we want to",
    "start": "1234760",
    "end": "1241240"
  },
  {
    "text": "preemptively transition the leader to a new replica perhaps the replica is reading from A Shard and we want to",
    "start": "1241240",
    "end": "1247720"
  },
  {
    "text": "redistribute that Shard to other replicas uh you can imagine snapshots other",
    "start": "1247720",
    "end": "1253240"
  },
  {
    "text": "examples once whatever the app controller needs to do is finished uh the app controller will annotate the Pod",
    "start": "1253240",
    "end": "1260039"
  },
  {
    "text": "as being done and then at that time the drain controller uh can evict uh the Pod",
    "start": "1260039",
    "end": "1266640"
  },
  {
    "text": "and proceed so this is a recurrent theme we have uh something that we're doing to",
    "start": "1266640",
    "end": "1273159"
  },
  {
    "text": "make scale down more graceful we don't have a guarantee that we'll be able to do this but when we can it is a bit uh",
    "start": "1273159",
    "end": "1280520"
  },
  {
    "text": "less of a burden on our applications for our last topic I'd like",
    "start": "1280520",
    "end": "1286919"
  },
  {
    "text": "to talk about recent going and some possible changes to eviction and pdbs and",
    "start": "1286919",
    "end": "1293720"
  },
  {
    "text": "kubernetes so evicting and deleting unhealthy pods is very important to us it's how we recover from degradation uh",
    "start": "1294880",
    "end": "1302039"
  },
  {
    "text": "and it's important that we are able to do that with the scale that we run at so here we have uh two deployments or",
    "start": "1302039",
    "end": "1307840"
  },
  {
    "text": "stateful sets and they're running with our default pdb where we set max on available to one and you can see that",
    "start": "1307840",
    "end": "1313880"
  },
  {
    "text": "the blue pods are ready and the gray pods are not ready so the question is uh",
    "start": "1313880",
    "end": "1319880"
  },
  {
    "text": "when you try to evict these pods which ones will succeed and which won't so prior to kubernetes 1.20 uh evicting the",
    "start": "1319880",
    "end": "1328440"
  },
  {
    "text": "unready pod in the left example would fail and simply the logic was the pdb",
    "start": "1328440",
    "end": "1334159"
  },
  {
    "text": "says Max unavailable of one there's an unavailable pod and so the eviction fails after kubernetes 1.20 the default",
    "start": "1334159",
    "end": "1341360"
  },
  {
    "text": "chain the default Behavior changed uh to what's called uh if healthy budget and",
    "start": "1341360",
    "end": "1347799"
  },
  {
    "text": "what that means is that the check is done such that after the eviction as long as there's only one Max event Max",
    "start": "1347799",
    "end": "1354360"
  },
  {
    "text": "unavailable the delete will go through so that's great for us and that is the setting that we",
    "start": "1354360",
    "end": "1360240"
  },
  {
    "text": "use uh in kuber 1.26 uh there was an additional uh",
    "start": "1360240",
    "end": "1366240"
  },
  {
    "text": "option added called Always allow and it's exactly what the name says it just means that anytime a pod is unready",
    "start": "1366240",
    "end": "1372840"
  },
  {
    "text": "you're able to evict it um and this makes sense in some cases however this is not the option that we use so I'll",
    "start": "1372840",
    "end": "1379640"
  },
  {
    "text": "give a couple examples as to why uh so when a pod is not ready you don't",
    "start": "1379640",
    "end": "1385159"
  },
  {
    "text": "actually have a strong guarantee that it's not doing something useful so you could imagine that in the right hand",
    "start": "1385159",
    "end": "1390520"
  },
  {
    "text": "case where we have two not ready pods the first pod is doing useful work it's continuing to operate and perhaps the",
    "start": "1390520",
    "end": "1397360"
  },
  {
    "text": "second unready pod is actually having a problem um if we evict oh and and the",
    "start": "1397360",
    "end": "1404559"
  },
  {
    "text": "first pod is unready because the cuet is simply not able to heartbeat at the API server suppose so if we evict the first",
    "start": "1404559",
    "end": "1411320"
  },
  {
    "text": "pod then we're actually going to create an issue where there wasn't one already and so we want to take the sort of",
    "start": "1411320",
    "end": "1417240"
  },
  {
    "text": "pessimistic approach and assume that this is uh the way to go um the",
    "start": "1417240",
    "end": "1422679"
  },
  {
    "text": "situation gets more important when you consider that these pods might be having local data like I mentioned earlier so",
    "start": "1422679",
    "end": "1430200"
  },
  {
    "text": "in that case if we uh suppose that one of the pods had corrupted data the other one is in the same state where the cubic",
    "start": "1430200",
    "end": "1436559"
  },
  {
    "text": "can't heartbeat if you evict that pod then you're going to have two replicas that now have uh their data effectively",
    "start": "1436559",
    "end": "1443799"
  },
  {
    "text": "deleted and so you might have data loss depending on the database that you're",
    "start": "1443799",
    "end": "1449840"
  },
  {
    "text": "using so here's a review of some suggestions that we've made in this talk we talked about uh A disruption probe to",
    "start": "1451440",
    "end": "1458320"
  },
  {
    "text": "decouple service routability and voluntary disruption handling uh we",
    "start": "1458320",
    "end": "1463400"
  },
  {
    "text": "talked about default pdbs which is a simplifying assumption to assume that uh",
    "start": "1463400",
    "end": "1468840"
  },
  {
    "text": "all evictions will be protected and I went over some node life cycle hooks that make node draining uh more",
    "start": "1468840",
    "end": "1477919"
  },
  {
    "text": "efficient for a last idea or proposal I'd like to talk about voluntary disruptions and whether or not they",
    "start": "1478600",
    "end": "1483799"
  },
  {
    "text": "should always respect pdbs uh spoiler alert the answer I'm going to propose is yes with some",
    "start": "1483799",
    "end": "1490919"
  },
  {
    "text": "qualifiers so pod preemption occurs when there is a high priority pending pod and",
    "start": "1491480",
    "end": "1497159"
  },
  {
    "text": "a low priority running pod and suppose that this pending pod can't be scheduled",
    "start": "1497159",
    "end": "1502960"
  },
  {
    "text": "anywhere and is configured with a priority class that is configured with preempt lower priority then in that case",
    "start": "1502960",
    "end": "1511000"
  },
  {
    "text": "uh the cube scheduler is actually going to delete the existing low priority running pod and this is an unprotected",
    "start": "1511000",
    "end": "1518640"
  },
  {
    "text": "delete so for all of the reasons I mentioned earlier this is problematic for us and indeed we had an internal",
    "start": "1518640",
    "end": "1524960"
  },
  {
    "text": "incident related to this so what happened was was we rolled out a new version of a Damon set where we slightly",
    "start": "1524960",
    "end": "1531159"
  },
  {
    "text": "increased the resources of it now for most nodes that uh this Damon set change",
    "start": "1531159",
    "end": "1537000"
  },
  {
    "text": "rolled out to everything was fine we were just able to increase the resources slightly but for some uh nodes this",
    "start": "1537000",
    "end": "1543720"
  },
  {
    "text": "actually wound up squeezing effectively uh some pods off of the nodes uh and so",
    "start": "1543720",
    "end": "1549760"
  },
  {
    "text": "when you do this times a th nodes you start to run into problems a lot of our applications were fine and could handle",
    "start": "1549760",
    "end": "1556159"
  },
  {
    "text": "losing a single replica but in some cases we would take down one replica for an application and then we'd move to",
    "start": "1556159",
    "end": "1561640"
  },
  {
    "text": "another node and take down another replica of that application and that's where we started to have",
    "start": "1561640",
    "end": "1566760"
  },
  {
    "text": "problems um so there's a kubernetes enhancement plan uh already in progress that's been approved uh to provide an",
    "start": "1566760",
    "end": "1573919"
  },
  {
    "text": "option to guarantee uh respecting pdbs to use eviction when preempting pods um",
    "start": "1573919",
    "end": "1580960"
  },
  {
    "text": "by default uh currently uh it's done best effort but it's not a guarantee like I",
    "start": "1580960",
    "end": "1586600"
  },
  {
    "text": "mentioned so the next case is taint based eviction",
    "start": "1586600",
    "end": "1592399"
  },
  {
    "text": "so the name says eviction but it's actually deletion um and the way the taint based eviction works is that a",
    "start": "1592399",
    "end": "1599120"
  },
  {
    "text": "node will acquire a no execute taint the most common one that we see is unreachable like I mentioned a couple",
    "start": "1599120",
    "end": "1605640"
  },
  {
    "text": "times the say the cuid is unable to heartbeat to the API server it'll get a unreachable no execute taint after some",
    "start": "1605640",
    "end": "1612399"
  },
  {
    "text": "time uh the a pod either does not tolerate the taint or no longer to",
    "start": "1612399",
    "end": "1617559"
  },
  {
    "text": "tolerates the taint its Toleration seconds has elapsed and at that time the node controller and the cube controller",
    "start": "1617559",
    "end": "1622960"
  },
  {
    "text": "manager is going to delete the Pod and this is again problematic for all of the reasons we've mentioned",
    "start": "1622960",
    "end": "1628919"
  },
  {
    "text": "before so the pro The Proposal then is to have some configurability options to",
    "start": "1628919",
    "end": "1634880"
  },
  {
    "text": "have t uh tank-based eviction respect pdbs and use eviction um and if you",
    "start": "1634880",
    "end": "1641720"
  },
  {
    "text": "allow yourself to imagine a little bit you could imagine also using Tain based eviction in order to drain so so it",
    "start": "1641720",
    "end": "1647720"
  },
  {
    "text": "could potentially replace uh the drain controller that we have been talking about and that would be great for us",
    "start": "1647720",
    "end": "1653520"
  },
  {
    "text": "because it would allow us to you know maintain fewer controllers and just kind of stay more in line with default uh",
    "start": "1653520",
    "end": "1659840"
  },
  {
    "text": "kubernetes Behavior Uh this is a bit of an open-ended idea it probably requires",
    "start": "1659840",
    "end": "1665080"
  },
  {
    "text": "something like promoting uh conditions to know execute taints and probably some",
    "start": "1665080",
    "end": "1670200"
  },
  {
    "text": "configuration about when you give up trying to evict and just move on to",
    "start": "1670200",
    "end": "1676080"
  },
  {
    "text": "delete so here's a non-exhaustive list of other places where currently deletion happens",
    "start": "1676519",
    "end": "1683799"
  },
  {
    "text": "where we think eviction could make sense uh so we talked about the first two uh the third one is node pressure eviction",
    "start": "1683799",
    "end": "1690640"
  },
  {
    "text": "so this occurs when a cuet does not have enough resources and needs to start getting rid of pods on the Node in order",
    "start": "1690640",
    "end": "1697720"
  },
  {
    "text": "to make uh in order to guarantee that it can continually operate correctly uh so",
    "start": "1697720",
    "end": "1703240"
  },
  {
    "text": "this is probably a case where you can't always go to eviction because the node needs to reclaim resources uh",
    "start": "1703240",
    "end": "1709399"
  },
  {
    "text": "immediately uh but it probably could make sense to uh start with eviction and maybe move on to deletion again uh and",
    "start": "1709399",
    "end": "1716840"
  },
  {
    "text": "the last one is uh the case of rollouts so for example when you roll out a deployment uh there's an update strategy",
    "start": "1716840",
    "end": "1723320"
  },
  {
    "text": "associated with that deployment and that's actually completely separate from uh pod disruption budgets so you could",
    "start": "1723320",
    "end": "1729919"
  },
  {
    "text": "specify that you're okay with uh losing two pods when you're doing a deployment roll out and your pdb would only say one",
    "start": "1729919",
    "end": "1736799"
  },
  {
    "text": "and in fact with what you'd see is you'll have two pods deleted and that's because uh deployment rollouts and",
    "start": "1736799",
    "end": "1742320"
  },
  {
    "text": "controller rollouts in general use deletion instead of eviction so if you take something away",
    "start": "1742320",
    "end": "1748960"
  },
  {
    "text": "uh it would I would like it for to be to consider using eviction instead of delution uh we find it to be a very",
    "start": "1748960",
    "end": "1756080"
  },
  {
    "text": "simplifying assumption for us it's guaranteed to be safe of course it's not actually guaranteed there are some",
    "start": "1756080",
    "end": "1761360"
  },
  {
    "text": "qualifiers uh but we think it's something that's useful for us and could be useful for the community in general",
    "start": "1761360",
    "end": "1766880"
  },
  {
    "text": "as well so thank you very much for coming to our",
    "start": "1766880",
    "end": "1772000"
  },
  {
    "text": "talk uh we'd be happy to answer any questions now and if you see us around feel free to talk to",
    "start": "1772000",
    "end": "1778030"
  },
  {
    "text": "[Applause] [Music]",
    "start": "1778030",
    "end": "1784369"
  },
  {
    "text": "us hi um can you talk a little bit about the differences between Max unavailable",
    "start": "1793519",
    "end": "1798840"
  },
  {
    "text": "in the deployment API versus um pdb can you repeat the question sorry um",
    "start": "1798840",
    "end": "1804679"
  },
  {
    "text": "can you talk a little about the difference between Max unavailable in the deployment API versus using an",
    "start": "1804679",
    "end": "1809760"
  },
  {
    "text": "actual pdb explicitly sure so for deployments have rollout strategies and",
    "start": "1809760",
    "end": "1815360"
  },
  {
    "text": "you can specify like a Max Surge and a Max unavailable uh and so basically it's",
    "start": "1815360",
    "end": "1821080"
  },
  {
    "text": "just a completely separate track from what the pdbs specify so when you're",
    "start": "1821080",
    "end": "1826120"
  },
  {
    "text": "doing a deployment pull out the deployment update strategy is respected and then when you're doing evictions uh",
    "start": "1826120",
    "end": "1833159"
  },
  {
    "text": "the Pod disruption budget is respected so there just two completely they're divorced which is",
    "start": "1833159",
    "end": "1839720"
  },
  {
    "text": "surprising um when you guys are doing high volume node Replacements how uh quickly are you comfortable going like",
    "start": "1840519",
    "end": "1847120"
  },
  {
    "text": "how do you base the amount of nodes you're replacing at one time by like a static number or a percentage of your",
    "start": "1847120",
    "end": "1852720"
  },
  {
    "text": "total node pool or like how how fast are you guys comfortable going during High Vol volume",
    "start": "1852720",
    "end": "1858600"
  },
  {
    "text": "Replacements um so we go as fast as needed uh so we have basically we uh we",
    "start": "1858600",
    "end": "1866159"
  },
  {
    "text": "have a configuration by condition uh and some conditions are more urgent than",
    "start": "1866159",
    "end": "1871960"
  },
  {
    "text": "others uh and so if we need to go fast we go as fast as the pdbs allow us uh",
    "start": "1871960",
    "end": "1877200"
  },
  {
    "text": "and uh we also have a a mechanism of back pressure from the cluster",
    "start": "1877200",
    "end": "1882679"
  },
  {
    "text": "autoscaler so that we don't um you put too much scale of pressure on the system",
    "start": "1882679",
    "end": "1889158"
  },
  {
    "text": "um I like that you guys are doing the default pdb stuff is that in reaction to",
    "start": "1890399",
    "end": "1895720"
  },
  {
    "text": "people creating poorly configured pdbs or in the past or what do you guys do to",
    "start": "1895720",
    "end": "1902159"
  },
  {
    "text": "mitigate that risk yeah so I think Beyond poorly configured pdbs it's more",
    "start": "1902159",
    "end": "1907559"
  },
  {
    "text": "that by default there just is no pdb and when there is no pdb in eviction is the exact same as deletion um and so a lot",
    "start": "1907559",
    "end": "1915200"
  },
  {
    "text": "of our you know this is basically just a burden that we can take away from our app maintainers and just do it for them",
    "start": "1915200",
    "end": "1921880"
  },
  {
    "text": "and we found that like the conservative default well the most conservative default is Max unavailable of one and we",
    "start": "1921880",
    "end": "1927360"
  },
  {
    "text": "found that that works pretty well I hope you don't mind me cheating and asking two questions uh but the",
    "start": "1927360",
    "end": "1933519"
  },
  {
    "text": "first one was can you elaborate a little bit on the fake pods are they just dummy pods or are they actually some kind of",
    "start": "1933519",
    "end": "1939720"
  },
  {
    "text": "crd um no they're they're actually just pods that run uh containers that do nothing okay and the other one was you",
    "start": "1939720",
    "end": "1946760"
  },
  {
    "text": "would talk aled about not trusting kubernetes reporting a a pod is not ready that it might be doing something",
    "start": "1946760",
    "end": "1951840"
  },
  {
    "text": "is there any thoughts or plans around getting to the point where you can trust that or are we just sticking with that",
    "start": "1951840",
    "end": "1958799"
  },
  {
    "text": "assumption I think you have to stick with that assumption I mean bugs",
    "start": "1959240",
    "end": "1964440"
  },
  {
    "text": "whatever I mean there's it's entirely possible the cubet just has died and is not going to be talking to the API",
    "start": "1964440",
    "end": "1969880"
  },
  {
    "text": "server anymore and that case all of the pods on that node are going to be marked as unready but who knows what they're",
    "start": "1969880",
    "end": "1975440"
  },
  {
    "text": "actually doing so I I I think it's I don't think there's really any way around it thank you yeah my question is around",
    "start": "1975440",
    "end": "1983639"
  },
  {
    "text": "the part rine skits so how do you manage it in a controlled environment like when you are not having access to patch the",
    "start": "1983639",
    "end": "1991039"
  },
  {
    "text": "resources not access to which kind of resources uh patching a part riness",
    "start": "1991039",
    "end": "1997360"
  },
  {
    "text": "gate like if I want to update my B Readiness gate how can I do it in a",
    "start": "2000080",
    "end": "2005440"
  },
  {
    "text": "controlled environment you're talking about pod updates pod Readiness Gates oh pod Readiness Gates",
    "start": "2005440",
    "end": "2012799"
  },
  {
    "text": "sorry um yeah so I guess I'm not seeing how it",
    "start": "2012799",
    "end": "2018480"
  },
  {
    "text": "how it ties into node draining so pod Readiness gates are a wave to uh basically have some controller that",
    "start": "2018480",
    "end": "2024720"
  },
  {
    "text": "declares when pods are ready Beyond normal kubernetes mechanisms um and for us that just ties",
    "start": "2024720",
    "end": "2031399"
  },
  {
    "text": "into pod Readiness we don't look to see if a pod Readiness gate is passed or not we just check that the Pod is ready",
    "start": "2031399",
    "end": "2036480"
  },
  {
    "text": "which is po Readiness gate is included in that okay answer your question okay",
    "start": "2036480",
    "end": "2041919"
  },
  {
    "text": "uh uh one question I had is uh we've seen issues when part disruption budgets are misconfigured and because of which",
    "start": "2041919",
    "end": "2049240"
  },
  {
    "text": "drains are not properly done uh some inexperienced developers or",
    "start": "2049240",
    "end": "2054280"
  },
  {
    "text": "inexperienced administrators do sometime delete delete the ports which generally doesn't cause any issues but can you",
    "start": "2054280",
    "end": "2060599"
  },
  {
    "text": "talk about some nuances between uh the difference between eviction and deletion when uh we had what like what's exactly",
    "start": "2060599",
    "end": "2068679"
  },
  {
    "text": "the difference between the two operations the um when it works exactly",
    "start": "2068679",
    "end": "2074358"
  },
  {
    "text": "like can you repeat the very end of your what you said so yeah can you talk about the nuances between uh a pod deletion",
    "start": "2074359",
    "end": "2081679"
  },
  {
    "text": "and a pod eviction and uh what what are the failure scenarios that we can see",
    "start": "2081679",
    "end": "2087720"
  },
  {
    "text": "when we are deleting instead of uh evicting yeah we so we uh we basically",
    "start": "2087720",
    "end": "2093839"
  },
  {
    "text": "advocate for always evicting unless unless uh the uh the part disruption",
    "start": "2093839",
    "end": "2100599"
  },
  {
    "text": "budget doesn't allow you to uh um you know remove the Pod that you want to",
    "start": "2100599",
    "end": "2106880"
  },
  {
    "text": "remove but most of the time like we um like the the there's little reason to",
    "start": "2106880",
    "end": "2116359"
  },
  {
    "text": "go um you to go to go in and uh and like manually evict a delete a pod uh that's",
    "start": "2116359",
    "end": "2124280"
  },
  {
    "text": "um so but you want to ask something sure I guess the way we think about it is like the first step is eviction and",
    "start": "2124280",
    "end": "2132200"
  },
  {
    "text": "there's really not a concern with the way that we run with eviction it's supposed to be always safe and so that's",
    "start": "2132200",
    "end": "2138640"
  },
  {
    "text": "kind of a starting point if that's not going to work because uh maybe you lost all of your nodes at the same time uh",
    "start": "2138640",
    "end": "2145520"
  },
  {
    "text": "and you have like work your workloads running on multiple nodes and you lose all of the nodes well then it's like",
    "start": "2145520",
    "end": "2150920"
  },
  {
    "text": "going to be maintenance and you're probably going to need someone to come in and look at it and start manually",
    "start": "2150920",
    "end": "2156119"
  },
  {
    "text": "deleting things try to get things to a good state but like by default eviction for us is just safe so we try to default",
    "start": "2156119",
    "end": "2161760"
  },
  {
    "text": "to that yeah if you're deleting be sure of yourself right like I mean you have to have a good reason so is is deleting",
    "start": "2161760",
    "end": "2169440"
  },
  {
    "text": "like a hard delete rather than and eviction is more graceful is that yeah",
    "start": "2169440",
    "end": "2174800"
  },
  {
    "text": "eviction is more graceful because there are additional checks uh and delete will just stop determination uh process of",
    "start": "2174800",
    "end": "2181040"
  },
  {
    "text": "the Pod uh so um it's irreversible uh and so once the pods",
    "start": "2181040",
    "end": "2187760"
  },
  {
    "text": "start being terminating there are a few things that are called on on the containers like pre-stop hooks uh Etc uh",
    "start": "2187760",
    "end": "2194640"
  },
  {
    "text": "but it's irreversible and after the termination grace period the containers are killed so like one like if you if",
    "start": "2194640",
    "end": "2201200"
  },
  {
    "text": "you start delete a pod you have to be sure yourself got it thank",
    "start": "2201200",
    "end": "2206119"
  },
  {
    "text": "you something that I uh was interested in hearing a little bit more about at",
    "start": "2206680",
    "end": "2212599"
  },
  {
    "text": "the beginning of the talk was you said you had disabled unattended UPG up grades",
    "start": "2212599",
    "end": "2218560"
  },
  {
    "text": "um can you go a little bit more into like what happened and why H we're we're",
    "start": "2218560",
    "end": "2224319"
  },
  {
    "text": "having the same fight uh at my company and you know I'm curious to have some",
    "start": "2224319",
    "end": "2229960"
  },
  {
    "text": "more ammo in my chain in my uh corner so sounds like you did not attend a keyot",
    "start": "2229960",
    "end": "2235240"
  },
  {
    "text": "uh this morning no comment so we have a a great blog post",
    "start": "2235240",
    "end": "2243040"
  },
  {
    "text": "series uh written by lauron who uh who and him uh presented a keynote uh this",
    "start": "2243040",
    "end": "2248720"
  },
  {
    "text": "morning about what happened uh with um unattended upgrades um but it's",
    "start": "2248720",
    "end": "2255520"
  },
  {
    "text": "basically yeah like a combination of factors uh that made us realize that we",
    "start": "2255520",
    "end": "2264400"
  },
  {
    "text": "didn't not want to uh rely on uned upgrades yeah thank you so",
    "start": "2264400",
    "end": "2270599"
  },
  {
    "text": "much the pdb being a lagging indicator which you pointed out um like we have suffered to the same problem as well uh",
    "start": "2271520",
    "end": "2278560"
  },
  {
    "text": "do you think the P eviction gate can help you solve the problem can you move closer to the microphone please",
    "start": "2278560",
    "end": "2284560"
  },
  {
    "text": "sure the pdb being a lagging indicator that is something which we have faced in",
    "start": "2284560",
    "end": "2289720"
  },
  {
    "text": "production as well um do you have a solution which you have thought about",
    "start": "2289720",
    "end": "2295839"
  },
  {
    "text": "implementing and uh can part eviction gate help there and a second question is",
    "start": "2295839",
    "end": "2301599"
  },
  {
    "text": "that have you uh have are you in discussion with the stripping the P eviction gate",
    "start": "2301599",
    "end": "2307880"
  },
  {
    "text": "I guess the way I think about it is that it sort of has to be a lagging indicator",
    "start": "2307880",
    "end": "2313200"
  },
  {
    "text": "um I mean it's entirely possible that right when you go to evict there's two of your pods going with the max",
    "start": "2313200",
    "end": "2318839"
  },
  {
    "text": "unavailable one there's two of your pods that are immediately unready but it's basically a raise condition as to",
    "start": "2318839",
    "end": "2324720"
  },
  {
    "text": "whether or not you tried to evict before or after that happened um",
    "start": "2324720",
    "end": "2330000"
  },
  {
    "text": "so uh yeah I don't do have anything else to add to that to to your second Point",
    "start": "2330000",
    "end": "2335720"
  },
  {
    "text": "uh yes uh making contact with stream teams to discuss some of the ideas that",
    "start": "2335720",
    "end": "2341000"
  },
  {
    "text": "we have thank",
    "start": "2341000",
    "end": "2344680"
  },
  {
    "text": "you um how do you guys work with long running pods and batches do you like",
    "start": "2346319",
    "end": "2351680"
  },
  {
    "text": "pack them into certain nodes certain clusters do you what do you do to address that and your goals of replacing",
    "start": "2351680",
    "end": "2359160"
  },
  {
    "text": "nodes to to do what in batches like if you have SPS that have to run for 4",
    "start": "2359160",
    "end": "2365040"
  },
  {
    "text": "hours or they're us how do you guys address you know longer running pods that you can't interrupt",
    "start": "2365040",
    "end": "2371839"
  },
  {
    "text": "for a long period of time oh yeah yeah so jobs basically batch workloads um we",
    "start": "2371839",
    "end": "2379079"
  },
  {
    "text": "uh we um in a way we're lucky in that our uh",
    "start": "2379079",
    "end": "2387440"
  },
  {
    "text": "batch workloads most of them um run uh",
    "start": "2387440",
    "end": "2392839"
  },
  {
    "text": "have a reasonable runtime uh so we we take the simplifying assumption that",
    "start": "2392839",
    "end": "2400160"
  },
  {
    "text": "uh we don't evict them and we just wait for them to run to completion uh and so when when when the",
    "start": "2400160",
    "end": "2408200"
  },
  {
    "text": "When replacing the node is not that urgent uh that's okay another thing that we do is when we're deciding what node",
    "start": "2408200",
    "end": "2415000"
  },
  {
    "text": "to drain next we do a simulation to see what we expect would happen and so",
    "start": "2415000",
    "end": "2420079"
  },
  {
    "text": "that's not like a guarantee of what will happen but that puts us away from evicting or sorry for draining nodes",
    "start": "2420079",
    "end": "2425560"
  },
  {
    "text": "that have these long running Jobs first and so we we do other nodes first and then hopefully by the time we get to that one the job is done or closer to",
    "start": "2425560",
    "end": "2432680"
  },
  {
    "text": "being done so that's something that helps hey Sean from Uber so we uh I",
    "start": "2432680",
    "end": "2440359"
  },
  {
    "text": "think the current design U for no pressure eviction that one is uh doesn't respect to the uh pdb do you have any",
    "start": "2440359",
    "end": "2448440"
  },
  {
    "text": "context like are we going to uh support pdb in terms of uh node",
    "start": "2448440",
    "end": "2454920"
  },
  {
    "text": "pressure sorry I did not hear the end can you move closer to the microphone please okay so uh I'm talking about node",
    "start": "2455319",
    "end": "2462880"
  },
  {
    "text": "pressure eviction for example I not wrong Auto memory or you like like you",
    "start": "2462880",
    "end": "2468200"
  },
  {
    "text": "set a memory threshold to let's say uh 80% something like that so whenever the",
    "start": "2468200",
    "end": "2474480"
  },
  {
    "text": "node uh consume more memory than that it will start Cub will start the uh",
    "start": "2474480",
    "end": "2480560"
  },
  {
    "text": "eviction right that that kind of eviction doesn't respect uh pdb right now yep have you ever seen any issue and",
    "start": "2480560",
    "end": "2487079"
  },
  {
    "text": "do you have any context about the discussion or proposal around that yeah",
    "start": "2487079",
    "end": "2492119"
  },
  {
    "text": "so um so luckily this uh doesn't happen",
    "start": "2492119",
    "end": "2498480"
  },
  {
    "text": "very often and when it does happen it's often because of the of um you know",
    "start": "2498480",
    "end": "2505240"
  },
  {
    "text": "misconfiguration of uh of um basically",
    "start": "2505240",
    "end": "2510960"
  },
  {
    "text": "um people uh asking for too much memory on the note for example example and not",
    "start": "2510960",
    "end": "2517440"
  },
  {
    "text": "requesting it like using too much but not requesting it that's what I mean um so it's it's isolated so but it it is",
    "start": "2517440",
    "end": "2526119"
  },
  {
    "text": "like it can theoretically uh you know break the contract of the pdb because it's not respected right um so uh so we",
    "start": "2526119",
    "end": "2534560"
  },
  {
    "text": "we think that um it would be a safe change to uh best effort respect pdbs",
    "start": "2534560",
    "end": "2541079"
  },
  {
    "text": "for node pressure eviction which is not the case at the moment so uh node pressure eviction is not a big deal uh",
    "start": "2541079",
    "end": "2548520"
  },
  {
    "text": "for your experience I don't think that we've actually seen a case where it caused an",
    "start": "2548520",
    "end": "2554200"
  },
  {
    "text": "issue like we had a specific case where like oh we had node pressure we evicted this pod if only we had evicted this pod",
    "start": "2554200",
    "end": "2560839"
  },
  {
    "text": "things would have been better I don't know that we've seen a specific case I think it's just uh it's just another thing that you could imagine happening",
    "start": "2560839",
    "end": "2567000"
  },
  {
    "text": "okay like what what's the reasonable uh like host memory eviction",
    "start": "2567000",
    "end": "2574000"
  },
  {
    "text": "threshold for your experience I don't know what do we use honestly uh I don't remember exactly",
    "start": "2574000",
    "end": "2581559"
  },
  {
    "text": "what we use as a threshold um but but it's I think it's important to uh to be",
    "start": "2581559",
    "end": "2588559"
  },
  {
    "text": "like not only like set a reasonable threshold but I think probably more importantly it's important to reserve",
    "start": "2588559",
    "end": "2595880"
  },
  {
    "text": "enough for the system in cuet so that's that's a separate setting and we do that",
    "start": "2595880",
    "end": "2601160"
  },
  {
    "text": "and that is like separate depending on the size of the VM type okay cool",
    "start": "2601160",
    "end": "2608079"
  },
  {
    "text": "thanks all right thank you very",
    "start": "2610720",
    "end": "2614838"
  },
  {
    "text": "much",
    "start": "2617640",
    "end": "2620640"
  }
]
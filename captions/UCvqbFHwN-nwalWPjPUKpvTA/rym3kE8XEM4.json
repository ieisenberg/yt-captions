[
  {
    "text": "let's talk about reducing JPC call",
    "start": "80",
    "end": "1959"
  },
  {
    "text": "volume through catching and",
    "start": "1959",
    "end": "4319"
  },
  {
    "text": "bashing so I'm Benjamin fedorka my",
    "start": "4319",
    "end": "6640"
  },
  {
    "text": "pronouns are heem and I work on the Java",
    "start": "6640",
    "end": "8599"
  },
  {
    "text": "platform team at Netflix my team",
    "start": "8599",
    "end": "10480"
  },
  {
    "text": "specializes in experience for RPC",
    "start": "10480",
    "end": "12120"
  },
  {
    "text": "oriented",
    "start": "12120",
    "end": "13440"
  },
  {
    "text": "apis we call ourselves the Baja team",
    "start": "13440",
    "end": "16000"
  },
  {
    "text": "that's backend application Java apis we",
    "start": "16000",
    "end": "18880"
  },
  {
    "text": "deliver a point a consistent developer",
    "start": "18880",
    "end": "21160"
  },
  {
    "text": "experience for point-to-point",
    "start": "21160",
    "end": "22320"
  },
  {
    "text": "communication and jvm applications we do",
    "start": "22320",
    "end": "25359"
  },
  {
    "text": "this by providing a variet of RPC",
    "start": "25359",
    "end": "27199"
  },
  {
    "text": "Frameworks we have Netflix jrpc Java we",
    "start": "27199",
    "end": "30039"
  },
  {
    "text": "have Netflix web client we have our own",
    "start": "30039",
    "end": "31640"
  },
  {
    "text": "little flavor spring MVC we have our",
    "start": "31640",
    "end": "33879"
  },
  {
    "text": "open source ribbon and then my team also",
    "start": "33879",
    "end": "35920"
  },
  {
    "text": "supports a variety of supporting tooling",
    "start": "35920",
    "end": "38120"
  },
  {
    "text": "that we use to provide these Frameworks",
    "start": "38120",
    "end": "40120"
  },
  {
    "text": "that's our OSS Netflix concurrency",
    "start": "40120",
    "end": "42200"
  },
  {
    "text": "limits our OSS Netflix histric and then",
    "start": "42200",
    "end": "45160"
  },
  {
    "text": "spring Boot and Juice",
    "start": "45160",
    "end": "47440"
  },
  {
    "text": "Integrations Netflix JPC Java is our",
    "start": "47440",
    "end": "50039"
  },
  {
    "text": "most highly featured and complex RPC",
    "start": "50039",
    "end": "52039"
  },
  {
    "text": "framework we have over 2500 applications",
    "start": "52039",
    "end": "55359"
  },
  {
    "text": "with JC clients JPC servers or both so",
    "start": "55359",
    "end": "58079"
  },
  {
    "text": "it's critical that these Integrations",
    "start": "58079",
    "end": "59440"
  },
  {
    "text": "are easy",
    "start": "59440",
    "end": "60519"
  },
  {
    "text": "we call making things easy our paved",
    "start": "60519",
    "end": "62160"
  },
  {
    "text": "road we approach this Challenge from",
    "start": "62160",
    "end": "64158"
  },
  {
    "text": "five angles tooling how do engineers",
    "start": "64159",
    "end": "66479"
  },
  {
    "text": "send adoc requests and actually auor",
    "start": "66479",
    "end": "68200"
  },
  {
    "text": "their protos security how do we enforce",
    "start": "68200",
    "end": "71080"
  },
  {
    "text": "and the establish and enforce the",
    "start": "71080",
    "end": "73040"
  },
  {
    "text": "Integrity of our rpcs and provide",
    "start": "73040",
    "end": "75159"
  },
  {
    "text": "additional access controls resilience",
    "start": "75159",
    "end": "77799"
  },
  {
    "text": "how do we ensure that rpcs succeed or",
    "start": "77799",
    "end": "79920"
  },
  {
    "text": "degrade gracefully observability how do",
    "start": "79920",
    "end": "82360"
  },
  {
    "text": "we understand the behavior of the system",
    "start": "82360",
    "end": "84240"
  },
  {
    "text": "and then finally ergonomics how do make",
    "start": "84240",
    "end": "86159"
  },
  {
    "text": "all of this easy last year I presented",
    "start": "86159",
    "end": "88799"
  },
  {
    "text": "at this conference a world an overview",
    "start": "88799",
    "end": "90520"
  },
  {
    "text": "of these pillars you can find it on the",
    "start": "90520",
    "end": "92240"
  },
  {
    "text": "cncf and grpc YouTube Pages uh as how",
    "start": "92240",
    "end": "95799"
  },
  {
    "text": "Netflix makes grpc easy to serve",
    "start": "95799",
    "end": "97479"
  },
  {
    "text": "consumer operate today I'm going to dive",
    "start": "97479",
    "end": "99720"
  },
  {
    "text": "into two ways we reduce our call volume",
    "start": "99720",
    "end": "101759"
  },
  {
    "text": "while still successfully serving fully",
    "start": "101759",
    "end": "103280"
  },
  {
    "text": "featured responses response caching and",
    "start": "103280",
    "end": "106159"
  },
  {
    "text": "request batching now I want to highlight",
    "start": "106159",
    "end": "108439"
  },
  {
    "text": "here I'm really talking about how we get",
    "start": "108439",
    "end": "110000"
  },
  {
    "text": "fully featured responses we're not going",
    "start": "110000",
    "end": "111920"
  },
  {
    "text": "to go into load shedding we're not going",
    "start": "111920",
    "end": "113560"
  },
  {
    "text": "to go into to how our fallbacks work",
    "start": "113560",
    "end": "115280"
  },
  {
    "text": "this is how we make sure that all of our",
    "start": "115280",
    "end": "116960"
  },
  {
    "text": "clients get the best response possible",
    "start": "116960",
    "end": "118680"
  },
  {
    "text": "for the request",
    "start": "118680",
    "end": "121280"
  },
  {
    "text": "so caching expensive operations isn't an",
    "start": "121280",
    "end": "123360"
  },
  {
    "text": "AO idea we spend some memory on the",
    "start": "123360",
    "end": "125240"
  },
  {
    "text": "client server somewhere else to reduce",
    "start": "125240",
    "end": "127680"
  },
  {
    "text": "the need for limited resources now most",
    "start": "127680",
    "end": "130280"
  },
  {
    "text": "of us have probably have written",
    "start": "130280",
    "end": "131400"
  },
  {
    "text": "something like this in the past right we",
    "start": "131400",
    "end": "133040"
  },
  {
    "text": "have a cache we compute something if",
    "start": "133040",
    "end": "134840"
  },
  {
    "text": "it's not there so if on a cash hit we",
    "start": "134840",
    "end": "137280"
  },
  {
    "text": "avoid that expensive computation on a",
    "start": "137280",
    "end": "139280"
  },
  {
    "text": "cash Miss we rewrite the response back",
    "start": "139280",
    "end": "141080"
  },
  {
    "text": "to the cash and use it later this is",
    "start": "141080",
    "end": "142920"
  },
  {
    "text": "your basic read through cash and it",
    "start": "142920",
    "end": "144760"
  },
  {
    "text": "works so we do it again and again and",
    "start": "144760",
    "end": "147760"
  },
  {
    "text": "again and this is not a good developer",
    "start": "147760",
    "end": "151519"
  },
  {
    "text": "experience one of the pillars of our",
    "start": "151519",
    "end": "153680"
  },
  {
    "text": "grpc product is ergonomics we need to",
    "start": "153680",
    "end": "155680"
  },
  {
    "text": "ensure that normal activities for",
    "start": "155680",
    "end": "157160"
  },
  {
    "text": "service owners and their client conser",
    "start": "157160",
    "end": "159360"
  },
  {
    "text": "consumers are easy so we can't just put",
    "start": "159360",
    "end": "162120"
  },
  {
    "text": "a caching facade and set it in front of",
    "start": "162120",
    "end": "163800"
  },
  {
    "text": "every RPC or in front of every Proto",
    "start": "163800",
    "end": "166680"
  },
  {
    "text": "service because you're doing a ton of",
    "start": "166680",
    "end": "168519"
  },
  {
    "text": "work over and over and over again so",
    "start": "168519",
    "end": "170840"
  },
  {
    "text": "what if we did all of this and more just",
    "start": "170840",
    "end": "173680"
  },
  {
    "text": "built into our server channels so if we",
    "start": "173680",
    "end": "176560"
  },
  {
    "text": "were to implement our caches within our",
    "start": "176560",
    "end": "178560"
  },
  {
    "text": "client channels there it would be",
    "start": "178560",
    "end": "180120"
  },
  {
    "text": "available to all the different stubs",
    "start": "180120",
    "end": "182319"
  },
  {
    "text": "this means that we could add client side",
    "start": "182319",
    "end": "184159"
  },
  {
    "text": "caches without a migrations because the",
    "start": "184159",
    "end": "185720"
  },
  {
    "text": "apis didn't change similarly if we add",
    "start": "185720",
    "end": "188239"
  },
  {
    "text": "caching into the server channels we",
    "start": "188239",
    "end": "190159"
  },
  {
    "text": "avoid calling that service",
    "start": "190159",
    "end": "191840"
  },
  {
    "text": "implementation this is possible by",
    "start": "191840",
    "end": "194400"
  },
  {
    "text": "writing a unique caching Interceptor for",
    "start": "194400",
    "end": "195920"
  },
  {
    "text": "every client in service and then when",
    "start": "195920",
    "end": "198239"
  },
  {
    "text": "you build your channels you just add",
    "start": "198239",
    "end": "199680"
  },
  {
    "text": "that Interceptor into the flow but we",
    "start": "199680",
    "end": "202000"
  },
  {
    "text": "can still do",
    "start": "202000",
    "end": "203720"
  },
  {
    "text": "better so let's back up we're using",
    "start": "203720",
    "end": "206599"
  },
  {
    "text": "Proto to Define our services and to",
    "start": "206599",
    "end": "208319"
  },
  {
    "text": "generate our lowlevel clients",
    "start": "208319",
    "end": "211760"
  },
  {
    "text": "Proto already has a uh stub already has",
    "start": "212120",
    "end": "216680"
  },
  {
    "text": "a method option for immutability built",
    "start": "216680",
    "end": "219239"
  },
  {
    "text": "into the uh Subs can we go forward one",
    "start": "219239",
    "end": "223080"
  },
  {
    "text": "SL",
    "start": "223080",
    "end": "225120"
  },
  {
    "text": "side so so uh Proto already has uh the",
    "start": "229439",
    "end": "233760"
  },
  {
    "text": "immutability as an option in there but",
    "start": "233760",
    "end": "235640"
  },
  {
    "text": "we can put some additional method",
    "start": "235640",
    "end": "237200"
  },
  {
    "text": "options in there uh for C ability uh",
    "start": "237200",
    "end": "241280"
  },
  {
    "text": "such as are you cashable uh are you",
    "start": "241280",
    "end": "244920"
  },
  {
    "text": "needing to evict on caching or are you",
    "start": "244920",
    "end": "246720"
  },
  {
    "text": "going to implement a write through cache",
    "start": "246720",
    "end": "248519"
  },
  {
    "text": "instead of read through cache so we",
    "start": "248519",
    "end": "250159"
  },
  {
    "text": "express this now with the method",
    "start": "250159",
    "end": "252920"
  },
  {
    "text": "option so now that we have this in our",
    "start": "252920",
    "end": "255480"
  },
  {
    "text": "server specification we have the cach",
    "start": "255480",
    "end": "257959"
  },
  {
    "text": "ability of method as a core part of the",
    "start": "257959",
    "end": "259919"
  },
  {
    "text": "RPC so collocating the information in a",
    "start": "259919",
    "end": "262639"
  },
  {
    "text": "machine readable format is perfect so",
    "start": "262639",
    "end": "265199"
  },
  {
    "text": "here we see uh we marked our RPC as",
    "start": "265199",
    "end": "267199"
  },
  {
    "text": "cachable and we defined a optional C",
    "start": "267199",
    "end": "269720"
  },
  {
    "text": "cash key now if you don't Define a cach",
    "start": "269720",
    "end": "272080"
  },
  {
    "text": "key that's fine we can generate one for",
    "start": "272080",
    "end": "273800"
  },
  {
    "text": "you just by looking at the entirety of",
    "start": "273800",
    "end": "275240"
  },
  {
    "text": "the request but normally you don't need",
    "start": "275240",
    "end": "278080"
  },
  {
    "text": "every single field in your quest as part",
    "start": "278080",
    "end": "279600"
  },
  {
    "text": "of your key and these friendlier keys",
    "start": "279600",
    "end": "281960"
  },
  {
    "text": "are easier to",
    "start": "281960",
    "end": "284560"
  },
  {
    "text": "operate so these cache directives then",
    "start": "288440",
    "end": "290759"
  },
  {
    "text": "get compiled into the stubs and we can",
    "start": "290759",
    "end": "292880"
  },
  {
    "text": "query the details at the channel",
    "start": "292880",
    "end": "294520"
  },
  {
    "text": "creation time so we use that information",
    "start": "294520",
    "end": "296919"
  },
  {
    "text": "to build an Interceptor either client",
    "start": "296919",
    "end": "298759"
  },
  {
    "text": "side or service side which actually",
    "start": "298759",
    "end": "300080"
  },
  {
    "text": "implements the cache from a technical",
    "start": "300080",
    "end": "302800"
  },
  {
    "text": "standpoint the Interceptor is going to",
    "start": "302800",
    "end": "304759"
  },
  {
    "text": "capture the response Handler And Delay",
    "start": "304759",
    "end": "307440"
  },
  {
    "text": "forwarding the call to the next",
    "start": "307440",
    "end": "308520"
  },
  {
    "text": "Interceptor until the client has sent",
    "start": "308520",
    "end": "310039"
  },
  {
    "text": "the message and have close to the RPC at",
    "start": "310039",
    "end": "312960"
  },
  {
    "text": "this point the cache is quered through a",
    "start": "312960",
    "end": "314440"
  },
  {
    "text": "non-blocking API on a cache hit we take",
    "start": "314440",
    "end": "317080"
  },
  {
    "text": "that response and we can pass it to the",
    "start": "317080",
    "end": "318759"
  },
  {
    "text": "response Handler and then on a cache",
    "start": "318759",
    "end": "320280"
  },
  {
    "text": "Miss we take our buffered uh headers and",
    "start": "320280",
    "end": "323840"
  },
  {
    "text": "message and we pass that along to the",
    "start": "323840",
    "end": "325520"
  },
  {
    "text": "next Interceptor and eventually",
    "start": "325520",
    "end": "326759"
  },
  {
    "text": "transport when we get the response back",
    "start": "326759",
    "end": "328600"
  },
  {
    "text": "through our interceptor we can put that",
    "start": "328600",
    "end": "330199"
  },
  {
    "text": "into the",
    "start": "330199",
    "end": "331160"
  },
  {
    "text": "cache if the Proto based configuration",
    "start": "331160",
    "end": "334319"
  },
  {
    "text": "is uh insufficient we actually have a",
    "start": "334319",
    "end": "337360"
  },
  {
    "text": "lot of customizations that we uh make",
    "start": "337360",
    "end": "339240"
  },
  {
    "text": "available so we allow our uh services",
    "start": "339240",
    "end": "342440"
  },
  {
    "text": "and clients to inject custom uh code for",
    "start": "342440",
    "end": "344960"
  },
  {
    "text": "determining cash ability cach Keys",
    "start": "344960",
    "end": "347280"
  },
  {
    "text": "eviction rules or even the entire cache",
    "start": "347280",
    "end": "349919"
  },
  {
    "text": "now you might wonder why would I want to",
    "start": "349919",
    "end": "351440"
  },
  {
    "text": "replace the entire cach why would I just",
    "start": "351440",
    "end": "353039"
  },
  {
    "text": "not do it myself and the reason is",
    "start": "353039",
    "end": "355360"
  },
  {
    "text": "caching integrates with a whole bunch of",
    "start": "355360",
    "end": "357199"
  },
  {
    "text": "other things we have our basic",
    "start": "357199",
    "end": "358720"
  },
  {
    "text": "implementation of the cach casing",
    "start": "358720",
    "end": "359840"
  },
  {
    "text": "Interceptor but we also have",
    "start": "359840",
    "end": "361440"
  },
  {
    "text": "Integrations with our observability we",
    "start": "361440",
    "end": "363240"
  },
  {
    "text": "need to know how well caching",
    "start": "363240",
    "end": "364440"
  },
  {
    "text": "performance is happening we don't want",
    "start": "364440",
    "end": "366080"
  },
  {
    "text": "to break our latency uh you know",
    "start": "366080",
    "end": "368360"
  },
  {
    "text": "reporting based on caching so we",
    "start": "368360",
    "end": "370720"
  },
  {
    "text": "encourage our customers to integrate",
    "start": "370720",
    "end": "373080"
  },
  {
    "text": "against our caching apis instead of",
    "start": "373080",
    "end": "374479"
  },
  {
    "text": "writing their own caching",
    "start": "374479",
    "end": "376039"
  },
  {
    "text": "interceptors a great example of when you",
    "start": "376039",
    "end": "378440"
  },
  {
    "text": "might want to make a completely custom",
    "start": "378440",
    "end": "380680"
  },
  {
    "text": "cache is if you could support multiple",
    "start": "380680",
    "end": "382560"
  },
  {
    "text": "RPC uh through a data transform or if a",
    "start": "382560",
    "end": "386039"
  },
  {
    "text": "RPC cach ability might change based upon",
    "start": "386039",
    "end": "388520"
  },
  {
    "text": "the presence of a field",
    "start": "388520",
    "end": "391560"
  },
  {
    "text": "diving a little bit deeper on",
    "start": "391759",
    "end": "392880"
  },
  {
    "text": "configuration uh we've done a lot of",
    "start": "392880",
    "end": "394599"
  },
  {
    "text": "ergonomic work here so when fields are",
    "start": "394599",
    "end": "396319"
  },
  {
    "text": "not present we allow configurable",
    "start": "396319",
    "end": "398160"
  },
  {
    "text": "default values so that we don't just get",
    "start": "398160",
    "end": "399840"
  },
  {
    "text": "empty blanks or you know maybe a double",
    "start": "399840",
    "end": "401840"
  },
  {
    "text": "hyphen uh in your cach key um not shown",
    "start": "401840",
    "end": "405199"
  },
  {
    "text": "here uh cash keys can descend into child",
    "start": "405199",
    "end": "407560"
  },
  {
    "text": "messages via DOT notation uh this makes",
    "start": "407560",
    "end": "409639"
  },
  {
    "text": "for really concise looking Keys U",
    "start": "409639",
    "end": "411800"
  },
  {
    "text": "without having to write custom code for",
    "start": "411800",
    "end": "413840"
  },
  {
    "text": "figuring out what your cash Keys should",
    "start": "413840",
    "end": "415199"
  },
  {
    "text": "be and rpcs can evict entries written by",
    "start": "415199",
    "end": "417879"
  },
  {
    "text": "other rpcs uh so as an example if you",
    "start": "417879",
    "end": "420479"
  },
  {
    "text": "have uh a grpc service that's doing both",
    "start": "420479",
    "end": "423000"
  },
  {
    "text": "reads and rights you can automatically",
    "start": "423000",
    "end": "424520"
  },
  {
    "text": "have the rights evict all of your uh",
    "start": "424520",
    "end": "427080"
  },
  {
    "text": "reads and that way you can keep that",
    "start": "427080",
    "end": "428800"
  },
  {
    "text": "data a little bit",
    "start": "428800",
    "end": "429840"
  },
  {
    "text": "fresher what we don't do in the Proto",
    "start": "429840",
    "end": "432360"
  },
  {
    "text": "level is configure specific caches or",
    "start": "432360",
    "end": "434879"
  },
  {
    "text": "ttls these values tend to be client",
    "start": "434879",
    "end": "437360"
  },
  {
    "text": "dependent uh we don't know what caches",
    "start": "437360",
    "end": "439120"
  },
  {
    "text": "are going to be available on the clients",
    "start": "439120",
    "end": "440919"
  },
  {
    "text": "uh and we don't necessarily know what",
    "start": "440919",
    "end": "442400"
  },
  {
    "text": "data freshman freshness every client",
    "start": "442400",
    "end": "444440"
  },
  {
    "text": "needs so what we do instead is we pack",
    "start": "444440",
    "end": "446800"
  },
  {
    "text": "that information into our standard",
    "start": "446800",
    "end": "448560"
  },
  {
    "text": "configuration service our service owners",
    "start": "448560",
    "end": "450800"
  },
  {
    "text": "configure uh default values and those",
    "start": "450800",
    "end": "452840"
  },
  {
    "text": "get distributed out and then Individual",
    "start": "452840",
    "end": "454759"
  },
  {
    "text": "Services can override these at runtime",
    "start": "454759",
    "end": "457319"
  },
  {
    "text": "uh with their specific needs client side",
    "start": "457319",
    "end": "459919"
  },
  {
    "text": "and server side caches both respect HTP",
    "start": "459919",
    "end": "461840"
  },
  {
    "text": "headers for a cache control uh and",
    "start": "461840",
    "end": "463800"
  },
  {
    "text": "caches serve or responses Ser from",
    "start": "463800",
    "end": "465680"
  },
  {
    "text": "caches are going to include metadata for",
    "start": "465680",
    "end": "467280"
  },
  {
    "text": "debugging purposes this is going to make",
    "start": "467280",
    "end": "469039"
  },
  {
    "text": "it really easy we still look like we're",
    "start": "469039",
    "end": "471400"
  },
  {
    "text": "an HTP caching service even though we",
    "start": "471400",
    "end": "473479"
  },
  {
    "text": "implemented everything Uh",
    "start": "473479",
    "end": "476080"
  },
  {
    "text": "custom so taking all this together we've",
    "start": "476080",
    "end": "478840"
  },
  {
    "text": "got ctors in both our client and server",
    "start": "478840",
    "end": "480960"
  },
  {
    "text": "channels which automatically wire in the",
    "start": "480960",
    "end": "482879"
  },
  {
    "text": "caches as needed because we implemented",
    "start": "482879",
    "end": "485440"
  },
  {
    "text": "caches at a channel level it's already",
    "start": "485440",
    "end": "487199"
  },
  {
    "text": "working with all types of stubs we",
    "start": "487199",
    "end": "489159"
  },
  {
    "text": "didn't change any apis so a service",
    "start": "489159",
    "end": "491319"
  },
  {
    "text": "owner can add a cache without having uh",
    "start": "491319",
    "end": "494000"
  },
  {
    "text": "migration and this new capability just",
    "start": "494000",
    "end": "495800"
  },
  {
    "text": "gets rolled out across the fleet uh with",
    "start": "495800",
    "end": "497759"
  },
  {
    "text": "dependency updates the caches even work",
    "start": "497759",
    "end": "500240"
  },
  {
    "text": "with facades created by service owners",
    "start": "500240",
    "end": "502000"
  },
  {
    "text": "because those facades are calling our",
    "start": "502000",
    "end": "503879"
  },
  {
    "text": "stubs",
    "start": "503879",
    "end": "504800"
  },
  {
    "text": "underneath the second moment to",
    "start": "504800",
    "end": "506520"
  },
  {
    "text": "acknowledge where caching doesn't work",
    "start": "506520",
    "end": "508240"
  },
  {
    "text": "uh the first one is streaming calls",
    "start": "508240",
    "end": "510000"
  },
  {
    "text": "uh honestly we haven't found a good user",
    "start": "510000",
    "end": "511400"
  },
  {
    "text": "story for needing this uh everybody who",
    "start": "511400",
    "end": "513000"
  },
  {
    "text": "needs streaming calls uh doesn't need",
    "start": "513000",
    "end": "515000"
  },
  {
    "text": "caching uh if you have a case where",
    "start": "515000",
    "end": "516640"
  },
  {
    "text": "you're using caching streaming calls or",
    "start": "516640",
    "end": "518120"
  },
  {
    "text": "you might think that would work I'd love",
    "start": "518120",
    "end": "519599"
  },
  {
    "text": "to hear about it over lunch uh the other",
    "start": "519599",
    "end": "522039"
  },
  {
    "text": "thing that you need to be really careful",
    "start": "522039",
    "end": "523200"
  },
  {
    "text": "with is out of- band information and a",
    "start": "523200",
    "end": "524760"
  },
  {
    "text": "great example here is a security context",
    "start": "524760",
    "end": "527200"
  },
  {
    "text": "so if you're integrating with the cach",
    "start": "527200",
    "end": "528760"
  },
  {
    "text": "you need to make sure that you're still",
    "start": "528760",
    "end": "530279"
  },
  {
    "text": "taking the security into mind is the",
    "start": "530279",
    "end": "531959"
  },
  {
    "text": "caller that um does the caller have",
    "start": "531959",
    "end": "534279"
  },
  {
    "text": "access to call the RPC if it doesn't it",
    "start": "534279",
    "end": "536320"
  },
  {
    "text": "probably shouldn't have access to the",
    "start": "536320",
    "end": "537519"
  },
  {
    "text": "cache uh maybe you're doing field level",
    "start": "537519",
    "end": "540959"
  },
  {
    "text": "uh validation against security so you",
    "start": "540959",
    "end": "542920"
  },
  {
    "text": "might return different visibility for",
    "start": "542920",
    "end": "544680"
  },
  {
    "text": "different colors um you need to make",
    "start": "544680",
    "end": "546440"
  },
  {
    "text": "sure that that's accounted for outside",
    "start": "546440",
    "end": "548560"
  },
  {
    "text": "your caching layer or you need to not be",
    "start": "548560",
    "end": "550120"
  },
  {
    "text": "using the cach for that um very similar",
    "start": "550120",
    "end": "552680"
  },
  {
    "text": "is field masks if you were to cach a",
    "start": "552680",
    "end": "554640"
  },
  {
    "text": "response with some hidden Fields is it",
    "start": "554640",
    "end": "556200"
  },
  {
    "text": "still correct for those other colors so",
    "start": "556200",
    "end": "557920"
  },
  {
    "text": "these are some things that you have to",
    "start": "557920",
    "end": "559519"
  },
  {
    "text": "think about and notably this is all out",
    "start": "559519",
    "end": "561920"
  },
  {
    "text": "of band with the Proto specification and",
    "start": "561920",
    "end": "563640"
  },
  {
    "text": "that's what causes these difficulties",
    "start": "563640",
    "end": "565519"
  },
  {
    "text": "with",
    "start": "565519",
    "end": "566839"
  },
  {
    "text": "caching so we support several flavors of",
    "start": "566839",
    "end": "569440"
  },
  {
    "text": "caches depending on the client and",
    "start": "569440",
    "end": "571000"
  },
  {
    "text": "server capabilities client side caches",
    "start": "571000",
    "end": "573440"
  },
  {
    "text": "are extremely low latency and easy to",
    "start": "573440",
    "end": "575399"
  },
  {
    "text": "configure we have both on Heap and off",
    "start": "575399",
    "end": "578040"
  },
  {
    "text": "Heap caches for our Java Services um and",
    "start": "578040",
    "end": "580839"
  },
  {
    "text": "we have a extra cache which is",
    "start": "580839",
    "end": "582640"
  },
  {
    "text": "implicitly keyed per incoming request",
    "start": "582640",
    "end": "584959"
  },
  {
    "text": "we'll talk a little bit more about that",
    "start": "584959",
    "end": "586040"
  },
  {
    "text": "one in a little bit server side caches",
    "start": "586040",
    "end": "589200"
  },
  {
    "text": "are our last SL of Defense before",
    "start": "589200",
    "end": "591120"
  },
  {
    "text": "investing in a potentially expensive",
    "start": "591120",
    "end": "592880"
  },
  {
    "text": "computation just like client hi caches",
    "start": "592880",
    "end": "595120"
  },
  {
    "text": "our server caches are enabled via the",
    "start": "595120",
    "end": "596880"
  },
  {
    "text": "Proto",
    "start": "596880",
    "end": "598079"
  },
  {
    "text": "specification and natural extension",
    "start": "598079",
    "end": "600040"
  },
  {
    "text": "would be to run both a client side and a",
    "start": "600040",
    "end": "601680"
  },
  {
    "text": "server side cache but instead of doing",
    "start": "601680",
    "end": "603640"
  },
  {
    "text": "this we use our open source EV cache and",
    "start": "603640",
    "end": "606000"
  },
  {
    "text": "run a distributed cache uh that's shared",
    "start": "606000",
    "end": "608120"
  },
  {
    "text": "between both clients and servers so",
    "start": "608120",
    "end": "609839"
  },
  {
    "text": "we've got uh some cash on servers some",
    "start": "609839",
    "end": "612120"
  },
  {
    "text": "cash on uh clients some cash sitting",
    "start": "612120",
    "end": "614040"
  },
  {
    "text": "outside and replicated through all of",
    "start": "614040",
    "end": "616720"
  },
  {
    "text": "them so with all this effort to make",
    "start": "616720",
    "end": "619000"
  },
  {
    "text": "caching easy to integrate and the",
    "start": "619000",
    "end": "620360"
  },
  {
    "text": "efforts from our Cloud engineering team",
    "start": "620360",
    "end": "622560"
  },
  {
    "text": "uh to provide caching Behavior just to",
    "start": "622560",
    "end": "624760"
  },
  {
    "text": "begin with how well does this work so",
    "start": "624760",
    "end": "626880"
  },
  {
    "text": "this is actually a fleetwide view of our",
    "start": "626880",
    "end": "628600"
  },
  {
    "text": "JPC client caching performance for Java",
    "start": "628600",
    "end": "630640"
  },
  {
    "text": "services on average we're seeing 75% of",
    "start": "630640",
    "end": "633480"
  },
  {
    "text": "stations are served by a cache so we",
    "start": "633480",
    "end": "635959"
  },
  {
    "text": "actually only have to run our JC servers",
    "start": "635959",
    "end": "638360"
  },
  {
    "text": "for 25% of our overall",
    "start": "638360",
    "end": "641079"
  },
  {
    "text": "traffic so let's dive in on a specific",
    "start": "641079",
    "end": "643360"
  },
  {
    "text": "service we run a lot of ab test to",
    "start": "643360",
    "end": "645560"
  },
  {
    "text": "ensure that we're providing the best",
    "start": "645560",
    "end": "646680"
  },
  {
    "text": "experience for our subscribers this",
    "start": "646680",
    "end": "648720"
  },
  {
    "text": "means that Services um frequently need",
    "start": "648720",
    "end": "650920"
  },
  {
    "text": "to check which feature flag should be",
    "start": "650920",
    "end": "652320"
  },
  {
    "text": "enabled for particular incoming request",
    "start": "652320",
    "end": "654600"
  },
  {
    "text": "it's common for these flags to be added",
    "start": "654600",
    "end": "656079"
  },
  {
    "text": "throughout already existing services and",
    "start": "656079",
    "end": "658120"
  },
  {
    "text": "the flags are going to have different",
    "start": "658120",
    "end": "659360"
  },
  {
    "text": "but predetermined values for each",
    "start": "659360",
    "end": "661040"
  },
  {
    "text": "incoming request by providing a cach",
    "start": "661040",
    "end": "663800"
  },
  {
    "text": "which is implicitly scoped to an",
    "start": "663800",
    "end": "665160"
  },
  {
    "text": "incoming request Engineers can inject",
    "start": "665160",
    "end": "666880"
  },
  {
    "text": "the client for the experimentation",
    "start": "666880",
    "end": "668360"
  },
  {
    "text": "platform wherever it's needed the",
    "start": "668360",
    "end": "670279"
  },
  {
    "text": "results will be cashed for the duration",
    "start": "670279",
    "end": "671519"
  },
  {
    "text": "of incoming request and automatically",
    "start": "671519",
    "end": "673240"
  },
  {
    "text": "evicted at the conclusion and we can see",
    "start": "673240",
    "end": "675320"
  },
  {
    "text": "that here uh that big green section",
    "start": "675320",
    "end": "677720"
  },
  {
    "text": "that's all the calls that are served by",
    "start": "677720",
    "end": "679839"
  },
  {
    "text": "just repeated uh calls into that request",
    "start": "679839",
    "end": "683079"
  },
  {
    "text": "scoped",
    "start": "683079",
    "end": "684560"
  },
  {
    "text": "cache we're also have layered caching",
    "start": "684560",
    "end": "687320"
  },
  {
    "text": "here uh so if the call was to fall",
    "start": "687320",
    "end": "689600"
  },
  {
    "text": "through the re request scope cach then",
    "start": "689600",
    "end": "692200"
  },
  {
    "text": "it's going to go into our distributed",
    "start": "692200",
    "end": "693639"
  },
  {
    "text": "caching implemented by EV cach so that",
    "start": "693639",
    "end": "696360"
  },
  {
    "text": "means that only 5% of the requests reach",
    "start": "696360",
    "end": "698120"
  },
  {
    "text": "the GPC server and even some of those",
    "start": "698120",
    "end": "700800"
  },
  {
    "text": "are now served by aache so with a few",
    "start": "700800",
    "end": "703560"
  },
  {
    "text": "lines of configuration and in their",
    "start": "703560",
    "end": "704720"
  },
  {
    "text": "service definition this team avoids tens",
    "start": "704720",
    "end": "706760"
  },
  {
    "text": "of millions of calls per second and they",
    "start": "706760",
    "end": "708480"
  },
  {
    "text": "didn't have to write a caching forade",
    "start": "708480",
    "end": "710120"
  },
  {
    "text": "it's just",
    "start": "710120",
    "end": "712480"
  },
  {
    "text": "here so a few years ago we encountered",
    "start": "712480",
    "end": "715120"
  },
  {
    "text": "something where caching wasn't enough",
    "start": "715120",
    "end": "717800"
  },
  {
    "text": "many of you going to be familiar with",
    "start": "717800",
    "end": "718880"
  },
  {
    "text": "this View it's the customized content",
    "start": "718880",
    "end": "720440"
  },
  {
    "text": "recommendations we provide for every",
    "start": "720440",
    "end": "722040"
  },
  {
    "text": "member once we know which titles to",
    "start": "722040",
    "end": "724240"
  },
  {
    "text": "recommend we still need to decide which",
    "start": "724240",
    "end": "725959"
  },
  {
    "text": "art to display for that title this logic",
    "start": "725959",
    "end": "728720"
  },
  {
    "text": "was originally implemented in the",
    "start": "728720",
    "end": "729839"
  },
  {
    "text": "library and called for many applications",
    "start": "729839",
    "end": "731920"
  },
  {
    "text": "each making many calls per incoming",
    "start": "731920",
    "end": "733600"
  },
  {
    "text": "request so even with this small",
    "start": "733600",
    "end": "735399"
  },
  {
    "text": "screenshot there's 15 uh 18 different",
    "start": "735399",
    "end": "738639"
  },
  {
    "text": "titles on the",
    "start": "738639",
    "end": "740000"
  },
  {
    "text": "screen so when we started working on",
    "start": "740000",
    "end": "742920"
  },
  {
    "text": "deconstructing this monolith we took the",
    "start": "742920",
    "end": "744720"
  },
  {
    "text": "library and we reimplemented it with",
    "start": "744720",
    "end": "746040"
  },
  {
    "text": "micros Service uh and now this has",
    "start": "746040",
    "end": "748120"
  },
  {
    "text": "created a huge fan out here's a",
    "start": "748120",
    "end": "751560"
  },
  {
    "text": "simplification of that call pattern so",
    "start": "751560",
    "end": "753880"
  },
  {
    "text": "even with asynchronous requests the",
    "start": "753880",
    "end": "755560"
  },
  {
    "text": "image artwork service was getting a huge",
    "start": "755560",
    "end": "757959"
  },
  {
    "text": "number of requests it's getting you know",
    "start": "757959",
    "end": "759279"
  },
  {
    "text": "18 requests per incoming call",
    "start": "759279",
    "end": "761920"
  },
  {
    "text": "refactoring the inid service was a large",
    "start": "761920",
    "end": "764399"
  },
  {
    "text": "investment uh and would have delayed uh",
    "start": "764399",
    "end": "767000"
  },
  {
    "text": "our efforts to retire library right",
    "start": "767000",
    "end": "768519"
  },
  {
    "text": "we've got dozens of applications that",
    "start": "768519",
    "end": "770600"
  },
  {
    "text": "are calling this Library inefficiently",
    "start": "770600",
    "end": "772760"
  },
  {
    "text": "um we don't really want to rewrite all",
    "start": "772760",
    "end": "774639"
  },
  {
    "text": "of them right now uh so it really",
    "start": "774639",
    "end": "777040"
  },
  {
    "text": "shouldn't be a surprise how we solve",
    "start": "777040",
    "end": "778680"
  },
  {
    "text": "this problem uh because it's the title",
    "start": "778680",
    "end": "780600"
  },
  {
    "text": "of the section we did it with request",
    "start": "780600",
    "end": "783199"
  },
  {
    "text": "batching So within each client we",
    "start": "783199",
    "end": "785760"
  },
  {
    "text": "intercept the St invocations and",
    "start": "785760",
    "end": "787440"
  },
  {
    "text": "aggregate them into a single call with",
    "start": "787440",
    "end": "789639"
  },
  {
    "text": "multiple IDs for the title artwork once",
    "start": "789639",
    "end": "792399"
  },
  {
    "text": "we received a response from the image",
    "start": "792399",
    "end": "793680"
  },
  {
    "text": "artwork service we slice it back into",
    "start": "793680",
    "end": "795920"
  },
  {
    "text": "indidual response objects and send it",
    "start": "795920",
    "end": "797880"
  },
  {
    "text": "onto each",
    "start": "797880",
    "end": "799560"
  },
  {
    "text": "stub so filling in some technical",
    "start": "799560",
    "end": "801839"
  },
  {
    "text": "details uh in each call we're going to",
    "start": "801839",
    "end": "803680"
  },
  {
    "text": "capture that request object and the",
    "start": "803680",
    "end": "805680"
  },
  {
    "text": "response listener we're going to batch",
    "start": "805680",
    "end": "807600"
  },
  {
    "text": "calls together based upon if they're",
    "start": "807600",
    "end": "809639"
  },
  {
    "text": "made close to each other uh in time uh",
    "start": "809639",
    "end": "812560"
  },
  {
    "text": "looking at overall batch size and other",
    "start": "812560",
    "end": "814560"
  },
  {
    "text": "distinguishing features maybe we need to",
    "start": "814560",
    "end": "816120"
  },
  {
    "text": "aggregate calls for particular device",
    "start": "816120",
    "end": "817920"
  },
  {
    "text": "type uh differently than calls for you",
    "start": "817920",
    "end": "820480"
  },
  {
    "text": "know a",
    "start": "820480",
    "end": "821320"
  },
  {
    "text": "browser uh and then eventually we send",
    "start": "821320",
    "end": "823639"
  },
  {
    "text": "this on to the backend Service as a",
    "start": "823639",
    "end": "825839"
  },
  {
    "text": "single call so for each request we're",
    "start": "825839",
    "end": "827760"
  },
  {
    "text": "going to save a key uh to help us",
    "start": "827760",
    "end": "830040"
  },
  {
    "text": "identify that relevant data in the",
    "start": "830040",
    "end": "831560"
  },
  {
    "text": "response so when we get that response",
    "start": "831560",
    "end": "833720"
  },
  {
    "text": "back we can use those save keys to",
    "start": "833720",
    "end": "836199"
  },
  {
    "text": "identify what aspects of the data needs",
    "start": "836199",
    "end": "838120"
  },
  {
    "text": "to go into each St medication we slice",
    "start": "838120",
    "end": "840399"
  },
  {
    "text": "that back up and then we can call each",
    "start": "840399",
    "end": "842040"
  },
  {
    "text": "response listener with the response now",
    "start": "842040",
    "end": "844399"
  },
  {
    "text": "in practice this is not in proto it's",
    "start": "844399",
    "end": "846560"
  },
  {
    "text": "about 100 lines of manual code for every",
    "start": "846560",
    "end": "848720"
  },
  {
    "text": "RPC that needs batching uh our framework",
    "start": "848720",
    "end": "851600"
  },
  {
    "text": "does handle detecting that these batches",
    "start": "851600",
    "end": "853800"
  },
  {
    "text": "exist and we get those integrated with",
    "start": "853800",
    "end": "855399"
  },
  {
    "text": "our essentially distributed interceptors",
    "start": "855399",
    "end": "857680"
  },
  {
    "text": "and also wired up with all all of our",
    "start": "857680",
    "end": "859759"
  },
  {
    "text": "observability tooling so as much as",
    "start": "859759",
    "end": "862360"
  },
  {
    "text": "we've simplified it it's still",
    "start": "862360",
    "end": "864040"
  },
  {
    "text": "complicated we need to think about how",
    "start": "864040",
    "end": "866000"
  },
  {
    "text": "much latency do you want to inject into",
    "start": "866000",
    "end": "867959"
  },
  {
    "text": "the coal to reduce your size uh so we",
    "start": "867959",
    "end": "870360"
  },
  {
    "text": "are now possibly degrading uh that",
    "start": "870360",
    "end": "872600"
  },
  {
    "text": "experience uh to reduce your request per",
    "start": "872600",
    "end": "875160"
  },
  {
    "text": "second we also need to think about how",
    "start": "875160",
    "end": "876720"
  },
  {
    "text": "we're keying these requests uh if you",
    "start": "876720",
    "end": "878959"
  },
  {
    "text": "were to add a field to your request",
    "start": "878959",
    "end": "880720"
  },
  {
    "text": "object that's probably going to Ripple",
    "start": "880720",
    "end": "882320"
  },
  {
    "text": "into code changes for your batchers and",
    "start": "882320",
    "end": "884440"
  },
  {
    "text": "then finally all those considerations",
    "start": "884440",
    "end": "886519"
  },
  {
    "text": "that make requests hard to cach they",
    "start": "886519",
    "end": "888399"
  },
  {
    "text": "still apply here for batching anything",
    "start": "888399",
    "end": "890160"
  },
  {
    "text": "that's out of band with the request uh",
    "start": "890160",
    "end": "892440"
  },
  {
    "text": "adds additional complexity for your",
    "start": "892440",
    "end": "894959"
  },
  {
    "text": "Batcher so caching was a huge percentage",
    "start": "894959",
    "end": "897279"
  },
  {
    "text": "of our traffic and batching is a lot",
    "start": "897279",
    "end": "899800"
  },
  {
    "text": "less uh the batch traffic is not zero",
    "start": "899800",
    "end": "902800"
  },
  {
    "text": "it's 7,000th of percent of our overall",
    "start": "902800",
    "end": "904759"
  },
  {
    "text": "traffic uh and in fact uh as of today we",
    "start": "904759",
    "end": "907480"
  },
  {
    "text": "only have one application to Service uh",
    "start": "907480",
    "end": "910279"
  },
  {
    "text": "connection still using batching and that",
    "start": "910279",
    "end": "913040"
  },
  {
    "text": "traffic is only 3% of that pair so why",
    "start": "913040",
    "end": "916399"
  },
  {
    "text": "aren't we using Bing right now let's",
    "start": "916399",
    "end": "918199"
  },
  {
    "text": "think about why we brought this",
    "start": "918199",
    "end": "919320"
  },
  {
    "text": "capability in the underlying Services we",
    "start": "919320",
    "end": "922320"
  },
  {
    "text": "using inefficient call patterns and",
    "start": "922320",
    "end": "923920"
  },
  {
    "text": "rewriting them would delay other goals",
    "start": "923920",
    "end": "926399"
  },
  {
    "text": "but that was 6 years ago today almost",
    "start": "926399",
    "end": "929000"
  },
  {
    "text": "all these Services have been Rewritten",
    "start": "929000",
    "end": "931279"
  },
  {
    "text": "batching allowed us to pursue other",
    "start": "931279",
    "end": "932560"
  },
  {
    "text": "priorities at the time and over the",
    "start": "932560",
    "end": "934040"
  },
  {
    "text": "years we eventually addressed that Tech",
    "start": "934040",
    "end": "936040"
  },
  {
    "text": "debt and drove it down and now it's not",
    "start": "936040",
    "end": "938680"
  },
  {
    "text": "needed anymore so we expect to retire",
    "start": "938680",
    "end": "941040"
  },
  {
    "text": "the last instance of request batching",
    "start": "941040",
    "end": "942759"
  },
  {
    "text": "later this year and we're going to",
    "start": "942759",
    "end": "944440"
  },
  {
    "text": "simplify our stack by transitioning this",
    "start": "944440",
    "end": "946519"
  },
  {
    "text": "from a required feature uh to an",
    "start": "946519",
    "end": "948519"
  },
  {
    "text": "optional feature so it's not going to be",
    "start": "948519",
    "end": "949720"
  },
  {
    "text": "brought in by default anymore if you",
    "start": "949720",
    "end": "951519"
  },
  {
    "text": "want to bring in request batching uh",
    "start": "951519",
    "end": "953319"
  },
  {
    "text": "we're going to have to add that into",
    "start": "953319",
    "end": "954560"
  },
  {
    "text": "your service but keeping the code around",
    "start": "954560",
    "end": "957480"
  },
  {
    "text": "just in case we need in the future who",
    "start": "957480",
    "end": "959199"
  },
  {
    "text": "knows what might come",
    "start": "959199",
    "end": "962040"
  },
  {
    "text": "up so in summary make request caching",
    "start": "964360",
    "end": "967759"
  },
  {
    "text": "easy if it's easy for your engineers to",
    "start": "967759",
    "end": "969600"
  },
  {
    "text": "cach they'll use it uh and then if you",
    "start": "969600",
    "end": "972000"
  },
  {
    "text": "need it use request batching to fix the",
    "start": "972000",
    "end": "974040"
  },
  {
    "text": "call patterns without",
    "start": "974040",
    "end": "976319"
  },
  {
    "text": "refactoring and I have now rushed",
    "start": "976319",
    "end": "978360"
  },
  {
    "text": "through my",
    "start": "978360",
    "end": "979560"
  },
  {
    "text": "slides which is great because we have 12",
    "start": "979560",
    "end": "982040"
  },
  {
    "text": "minutes for",
    "start": "982040",
    "end": "983399"
  },
  {
    "text": "Q&A uh so there is a room mic so if you",
    "start": "983399",
    "end": "986240"
  },
  {
    "text": "have any questions uh grab a mic",
    "start": "986240",
    "end": "990920"
  },
  {
    "text": "so do you have a requirement on sharing",
    "start": "998040",
    "end": "1000680"
  },
  {
    "text": "the cash uh among your clients or the",
    "start": "1000680",
    "end": "1003959"
  },
  {
    "text": "server I guess the caching is good",
    "start": "1003959",
    "end": "1006800"
  },
  {
    "text": "improve the uh to improve the",
    "start": "1006800",
    "end": "1008399"
  },
  {
    "text": "performance but at the same time usually",
    "start": "1008399",
    "end": "1011399"
  },
  {
    "text": "is local is on his own instance right",
    "start": "1011399",
    "end": "1014319"
  },
  {
    "text": "usually his own memory so any",
    "start": "1014319",
    "end": "1017360"
  },
  {
    "text": "requirement to share the cash among all",
    "start": "1017360",
    "end": "1019440"
  },
  {
    "text": "your clients same kind of clients",
    "start": "1019440",
    "end": "1021519"
  },
  {
    "text": "multiple instances we don't have a",
    "start": "1021519",
    "end": "1024079"
  },
  {
    "text": "requirement uh a lot of our caches are",
    "start": "1024079",
    "end": "1026038"
  },
  {
    "text": "local so the caches that are local on",
    "start": "1026039",
    "end": "1028079"
  },
  {
    "text": "the client uh tend to be lower latency",
    "start": "1028079",
    "end": "1030640"
  },
  {
    "text": "uh so we're looking at uh tens of",
    "start": "1030640",
    "end": "1032558"
  },
  {
    "text": "microsc of latency for those responses",
    "start": "1032559",
    "end": "1035120"
  },
  {
    "text": "um when we are using distributed caches",
    "start": "1035120",
    "end": "1037438"
  },
  {
    "text": "which is going to help if uh maybe you",
    "start": "1037439",
    "end": "1039319"
  },
  {
    "text": "have a lot uh much higher magnitude",
    "start": "1039319",
    "end": "1041798"
  },
  {
    "text": "number of client servers or maybe",
    "start": "1041799",
    "end": "1043038"
  },
  {
    "text": "they're uh cycling faster then we'll use",
    "start": "1043039",
    "end": "1045600"
  },
  {
    "text": "that distributed caching but then we're",
    "start": "1045600",
    "end": "1047000"
  },
  {
    "text": "looking at hundreds of microsc for",
    "start": "1047000",
    "end": "1048480"
  },
  {
    "text": "respons",
    "start": "1048480",
    "end": "1049520"
  },
  {
    "text": "uh so we tend to use it when",
    "start": "1049520",
    "end": "1053799"
  },
  {
    "text": "needed um did your batching solution",
    "start": "1063919",
    "end": "1068400"
  },
  {
    "text": "leverage your caching solution as well",
    "start": "1068400",
    "end": "1071240"
  },
  {
    "text": "that is a great question um so it's",
    "start": "1071240",
    "end": "1073919"
  },
  {
    "text": "difficult to have both caching and",
    "start": "1073919",
    "end": "1075480"
  },
  {
    "text": "batching running at the same time",
    "start": "1075480",
    "end": "1077320"
  },
  {
    "text": "because uh you need to decide which",
    "start": "1077320",
    "end": "1079320"
  },
  {
    "text": "order they go in or try to do it on both",
    "start": "1079320",
    "end": "1081360"
  },
  {
    "text": "sides uh so ultimately we're not using",
    "start": "1081360",
    "end": "1084440"
  },
  {
    "text": "caching with our batch calls um so we",
    "start": "1084440",
    "end": "1086360"
  },
  {
    "text": "had attempted to cach the calls",
    "start": "1086360",
    "end": "1088240"
  },
  {
    "text": "individually first um and then if they",
    "start": "1088240",
    "end": "1090360"
  },
  {
    "text": "didn't then they fall through into the",
    "start": "1090360",
    "end": "1091840"
  },
  {
    "text": "batch uh once you build the batch call",
    "start": "1091840",
    "end": "1094240"
  },
  {
    "text": "up uh there are so many individual",
    "start": "1094240",
    "end": "1097200"
  },
  {
    "text": "request IDs uh it's unlikely you're",
    "start": "1097200",
    "end": "1098720"
  },
  {
    "text": "going to get cash hits but if you put",
    "start": "1098720",
    "end": "1100200"
  },
  {
    "text": "the cash on the other side of the batch",
    "start": "1100200",
    "end": "1101480"
  },
  {
    "text": "calls um then you uh introduce a lot of",
    "start": "1101480",
    "end": "1104000"
  },
  {
    "text": "complexity for how you actually build up",
    "start": "1104000",
    "end": "1105559"
  },
  {
    "text": "your batches",
    "start": "1105559",
    "end": "1108640"
  },
  {
    "text": "hey uh as a uh as a cach is so easy to",
    "start": "1112600",
    "end": "1117200"
  },
  {
    "text": "be implemented uh you talk about the",
    "start": "1117200",
    "end": "1119480"
  },
  {
    "text": "security on the client side I mean how",
    "start": "1119480",
    "end": "1122000"
  },
  {
    "text": "do we ensure the",
    "start": "1122000",
    "end": "1124280"
  },
  {
    "text": "security yeah so the first level is um",
    "start": "1124280",
    "end": "1128480"
  },
  {
    "text": "if your client doesn't have access to",
    "start": "1128480",
    "end": "1129799"
  },
  {
    "text": "the service it shouldn't have access to",
    "start": "1129799",
    "end": "1131240"
  },
  {
    "text": "the cache um so this really only uh",
    "start": "1131240",
    "end": "1134799"
  },
  {
    "text": "applies for distributed caches because",
    "start": "1134799",
    "end": "1136600"
  },
  {
    "text": "the other caches are going to be local",
    "start": "1136600",
    "end": "1137840"
  },
  {
    "text": "to your client um when you're looking at",
    "start": "1137840",
    "end": "1140440"
  },
  {
    "text": "per call uh security uh so this might be",
    "start": "1140440",
    "end": "1143440"
  },
  {
    "text": "if you have a client that's operating",
    "start": "1143440",
    "end": "1144720"
  },
  {
    "text": "with multiple security contacts maybe",
    "start": "1144720",
    "end": "1146360"
  },
  {
    "text": "you're passing through uh an end to end",
    "start": "1146360",
    "end": "1148720"
  },
  {
    "text": "user Identity or something like that uh",
    "start": "1148720",
    "end": "1150640"
  },
  {
    "text": "that's that complexity where I talked",
    "start": "1150640",
    "end": "1151720"
  },
  {
    "text": "about where you have outof band",
    "start": "1151720",
    "end": "1153280"
  },
  {
    "text": "information uh and you need to make sure",
    "start": "1153280",
    "end": "1155320"
  },
  {
    "text": "that either it doesn't apply for your",
    "start": "1155320",
    "end": "1157159"
  },
  {
    "text": "caching or that you have it integrated",
    "start": "1157159",
    "end": "1159120"
  },
  {
    "text": "with your cach keys",
    "start": "1159120",
    "end": "1162679"
  },
  {
    "text": "uh can you talk more about the logic uh",
    "start": "1170200",
    "end": "1172320"
  },
  {
    "text": "building batch kind of waiting for next",
    "start": "1172320",
    "end": "1175280"
  },
  {
    "text": "response when to decide the batch is",
    "start": "1175280",
    "end": "1177799"
  },
  {
    "text": "ready yeah so we normally look at two",
    "start": "1177799",
    "end": "1180679"
  },
  {
    "text": "things we look at how much uh latency",
    "start": "1180679",
    "end": "1183159"
  },
  {
    "text": "we're willing to introduce uh and then",
    "start": "1183159",
    "end": "1184960"
  },
  {
    "text": "also how many items are already in the",
    "start": "1184960",
    "end": "1187000"
  },
  {
    "text": "batch uh so the goal of batching is just",
    "start": "1187000",
    "end": "1189000"
  },
  {
    "text": "to reduce uh the uh reduce the overall",
    "start": "1189000",
    "end": "1192679"
  },
  {
    "text": "RPS going to the downstream Service uh",
    "start": "1192679",
    "end": "1195000"
  },
  {
    "text": "so often like if we already got you know",
    "start": "1195000",
    "end": "1197520"
  },
  {
    "text": "15 or 20 items into the batch it's",
    "start": "1197520",
    "end": "1199919"
  },
  {
    "text": "probably worth sending the Batch off now",
    "start": "1199919",
    "end": "1201520"
  },
  {
    "text": "to keep that tail latency low uh because",
    "start": "1201520",
    "end": "1203679"
  },
  {
    "text": "we've already done enough to reduce the",
    "start": "1203679",
    "end": "1205360"
  },
  {
    "text": "uh fan",
    "start": "1205360",
    "end": "1206440"
  },
  {
    "text": "out uh and both of those are",
    "start": "1206440",
    "end": "1208440"
  },
  {
    "text": "configurable within the Batcher so we",
    "start": "1208440",
    "end": "1209880"
  },
  {
    "text": "can continue to tune those as the",
    "start": "1209880",
    "end": "1211520"
  },
  {
    "text": "service uh call pattern",
    "start": "1211520",
    "end": "1214559"
  },
  {
    "text": "changes yeah extend the question I have",
    "start": "1220280",
    "end": "1224400"
  },
  {
    "text": "so I have a existing service already has",
    "start": "1224400",
    "end": "1226799"
  },
  {
    "text": "Security in place and on boarding cash",
    "start": "1226799",
    "end": "1230240"
  },
  {
    "text": "uh distributed uh so do I need to",
    "start": "1230240",
    "end": "1232919"
  },
  {
    "text": "implement the security on the cash again",
    "start": "1232919",
    "end": "1236880"
  },
  {
    "text": "I",
    "start": "1236880",
    "end": "1237559"
  },
  {
    "text": "me so it depends if the it it depends on",
    "start": "1237559",
    "end": "1241280"
  },
  {
    "text": "how that security context works so as an",
    "start": "1241280",
    "end": "1243360"
  },
  {
    "text": "example so we run Mutual TLS identities",
    "start": "1243360",
    "end": "1245960"
  },
  {
    "text": "between all of our clients and servers",
    "start": "1245960",
    "end": "1248120"
  },
  {
    "text": "uh and if that's the only thing that",
    "start": "1248120",
    "end": "1249720"
  },
  {
    "text": "you're worried about uh so service a is",
    "start": "1249720",
    "end": "1251919"
  },
  {
    "text": "always able to call service be then you",
    "start": "1251919",
    "end": "1253600"
  },
  {
    "text": "don't need to think about any more",
    "start": "1253600",
    "end": "1254760"
  },
  {
    "text": "security within your cach it's really",
    "start": "1254760",
    "end": "1256640"
  },
  {
    "text": "only if you're dealing with uh like end",
    "start": "1256640",
    "end": "1258799"
  },
  {
    "text": "to end identities and you have a client",
    "start": "1258799",
    "end": "1261320"
  },
  {
    "text": "service which is deputizing calls for",
    "start": "1261320",
    "end": "1263480"
  },
  {
    "text": "other services uh that's where you need",
    "start": "1263480",
    "end": "1265200"
  },
  {
    "text": "to think about if your cash requires",
    "start": "1265200",
    "end": "1266880"
  },
  {
    "text": "additional",
    "start": "1266880",
    "end": "1269280"
  },
  {
    "text": "security um do you have any open source",
    "start": "1276720",
    "end": "1279000"
  },
  {
    "text": "libraries available to help Implement",
    "start": "1279000",
    "end": "1280760"
  },
  {
    "text": "any of this that's a great question um",
    "start": "1280760",
    "end": "1284159"
  },
  {
    "text": "no we don't and that's why I try to dive",
    "start": "1284159",
    "end": "1286400"
  },
  {
    "text": "into some of the technical details so",
    "start": "1286400",
    "end": "1287880"
  },
  {
    "text": "that way you can do it uh and there's",
    "start": "1287880",
    "end": "1289840"
  },
  {
    "text": "even some code screenshots in there um",
    "start": "1289840",
    "end": "1292400"
  },
  {
    "text": "so there's an investment to get these",
    "start": "1292400",
    "end": "1294039"
  },
  {
    "text": "libraries into open source uh and we",
    "start": "1294039",
    "end": "1295840"
  },
  {
    "text": "haven't been able to prioritize",
    "start": "1295840",
    "end": "1298960"
  },
  {
    "text": "it so is your cash um persisted um at",
    "start": "1301400",
    "end": "1306279"
  },
  {
    "text": "any time um what I'm trying to get to is",
    "start": "1306279",
    "end": "1310200"
  },
  {
    "text": "usually these workloads tend to be",
    "start": "1310200",
    "end": "1312159"
  },
  {
    "text": "Emeral so when we bonds these you know",
    "start": "1312159",
    "end": "1316039"
  },
  {
    "text": "the the instances the cash could be gone",
    "start": "1316039",
    "end": "1319400"
  },
  {
    "text": "so are you reloaded the C I mean I don't",
    "start": "1319400",
    "end": "1322520"
  },
  {
    "text": "know if you have intention to reload the",
    "start": "1322520",
    "end": "1324919"
  },
  {
    "text": "cash from somewhere or this is always",
    "start": "1324919",
    "end": "1327360"
  },
  {
    "text": "started from fresh and constantly trying",
    "start": "1327360",
    "end": "1330480"
  },
  {
    "text": "to build the cash along yeah so for",
    "start": "1330480",
    "end": "1333000"
  },
  {
    "text": "those cases that's when we use our",
    "start": "1333000",
    "end": "1334200"
  },
  {
    "text": "distributed caching uh with our yes open",
    "start": "1334200",
    "end": "1336919"
  },
  {
    "text": "source EV cache um so there is an",
    "start": "1336919",
    "end": "1339520"
  },
  {
    "text": "instance uh which is sitting aside that",
    "start": "1339520",
    "end": "1341880"
  },
  {
    "text": "can then load up a cach before the",
    "start": "1341880",
    "end": "1343480"
  },
  {
    "text": "service um starts serving requests so",
    "start": "1343480",
    "end": "1346520"
  },
  {
    "text": "for the caches that are local only that",
    "start": "1346520",
    "end": "1348799"
  },
  {
    "text": "are not using the distributed caching",
    "start": "1348799",
    "end": "1350240"
  },
  {
    "text": "capabilities um they do start empty I",
    "start": "1350240",
    "end": "1352600"
  },
  {
    "text": "see",
    "start": "1352600",
    "end": "1355278"
  },
  {
    "text": "thanks all right I'm going to say that",
    "start": "1366840",
    "end": "1369440"
  },
  {
    "text": "we started or finished our questions",
    "start": "1369440",
    "end": "1371120"
  },
  {
    "text": "early uh and I know after me is lunch so",
    "start": "1371120",
    "end": "1374320"
  },
  {
    "text": "if you have any more questions then find",
    "start": "1374320",
    "end": "1375880"
  },
  {
    "text": "me",
    "start": "1375880",
    "end": "1378880"
  }
]
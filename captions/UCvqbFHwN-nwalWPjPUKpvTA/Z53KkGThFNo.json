[
  {
    "start": "0",
    "end": "51000"
  },
  {
    "text": "hello my name is alejandro saucedo and",
    "start": "0",
    "end": "1920"
  },
  {
    "text": "today we're going to be covering",
    "start": "1920",
    "end": "3280"
  },
  {
    "text": "automated machine learning performance",
    "start": "3280",
    "end": "5120"
  },
  {
    "text": "benchmarking and evaluation",
    "start": "5120",
    "end": "7040"
  },
  {
    "text": "at scale a bit about myself i am",
    "start": "7040",
    "end": "10320"
  },
  {
    "text": "engineering director at southern",
    "start": "10320",
    "end": "11679"
  },
  {
    "text": "technologies chief scientist at the",
    "start": "11679",
    "end": "13519"
  },
  {
    "text": "institute for ethical ai",
    "start": "13519",
    "end": "14960"
  },
  {
    "text": "and governing council member at large at",
    "start": "14960",
    "end": "17279"
  },
  {
    "text": "the acm",
    "start": "17279",
    "end": "18560"
  },
  {
    "text": "we have a lot of topics to cover so",
    "start": "18560",
    "end": "20720"
  },
  {
    "text": "let's dive straight into it",
    "start": "20720",
    "end": "22240"
  },
  {
    "text": "today we're going to be diving into the",
    "start": "22240",
    "end": "24000"
  },
  {
    "text": "motivations for automated benchmarking",
    "start": "24000",
    "end": "26720"
  },
  {
    "text": "uh we're going to be covering some",
    "start": "26720",
    "end": "28080"
  },
  {
    "text": "techniques and tools that you will be",
    "start": "28080",
    "end": "29519"
  },
  {
    "text": "able to use to perform uh benchmarking",
    "start": "29519",
    "end": "31760"
  },
  {
    "text": "against the deployed model",
    "start": "31760",
    "end": "33440"
  },
  {
    "text": "we're going to talk about then the the",
    "start": "33440",
    "end": "35440"
  },
  {
    "text": "ways in which this can be automated",
    "start": "35440",
    "end": "37440"
  },
  {
    "text": "as well as how to automate this with uh",
    "start": "37440",
    "end": "40399"
  },
  {
    "text": "workflow management systems",
    "start": "40399",
    "end": "41840"
  },
  {
    "text": "and talk about what those are and then",
    "start": "41840",
    "end": "44079"
  },
  {
    "text": "finally we're going to be covering",
    "start": "44079",
    "end": "45680"
  },
  {
    "text": "a couple of uh examples hands-on",
    "start": "45680",
    "end": "47920"
  },
  {
    "text": "examples that will show you how you're",
    "start": "47920",
    "end": "49520"
  },
  {
    "text": "able to adopt this in your workflows",
    "start": "49520",
    "end": "51760"
  },
  {
    "start": "51000",
    "end": "110000"
  },
  {
    "text": "so let's start with a familiar model",
    "start": "51760",
    "end": "53600"
  },
  {
    "text": "right and",
    "start": "53600",
    "end": "54879"
  },
  {
    "text": "this would be the hello world of machine",
    "start": "54879",
    "end": "57360"
  },
  {
    "text": "learning the c410 classifier",
    "start": "57360",
    "end": "59760"
  },
  {
    "text": "what we have here is basically a model",
    "start": "59760",
    "end": "62000"
  },
  {
    "text": "that takes uh",
    "start": "62000",
    "end": "63039"
  },
  {
    "text": "an image and is able to predict what",
    "start": "63039",
    "end": "65600"
  },
  {
    "text": "class",
    "start": "65600",
    "end": "66240"
  },
  {
    "text": "this image is and from that perspective",
    "start": "66240",
    "end": "68960"
  },
  {
    "text": "in this case this is the image of a",
    "start": "68960",
    "end": "70400"
  },
  {
    "text": "truck",
    "start": "70400",
    "end": "70960"
  },
  {
    "text": "and is predicting class number nine",
    "start": "70960",
    "end": "73200"
  },
  {
    "text": "which would be in this case the image of",
    "start": "73200",
    "end": "75200"
  },
  {
    "text": "a truck",
    "start": "75200",
    "end": "76799"
  },
  {
    "text": "now from that perspective what we want",
    "start": "76799",
    "end": "78880"
  },
  {
    "text": "to do is we want to",
    "start": "78880",
    "end": "80560"
  },
  {
    "text": "um see it from the productionization",
    "start": "80560",
    "end": "83200"
  },
  {
    "text": "perspective right so",
    "start": "83200",
    "end": "84479"
  },
  {
    "text": "of course there's going to be some uh",
    "start": "84479",
    "end": "86400"
  },
  {
    "text": "complex experimentation process that",
    "start": "86400",
    "end": "88479"
  },
  {
    "text": "would be carried out by",
    "start": "88479",
    "end": "89920"
  },
  {
    "text": "uh the respective you know data",
    "start": "89920",
    "end": "91759"
  },
  {
    "text": "scientists and the main experts to find",
    "start": "91759",
    "end": "94000"
  },
  {
    "text": "what is the best performing type of",
    "start": "94000",
    "end": "95600"
  },
  {
    "text": "model in this case we would be able to",
    "start": "95600",
    "end": "97680"
  },
  {
    "text": "work with",
    "start": "97680",
    "end": "98240"
  },
  {
    "text": "an already trained model which we will",
    "start": "98240",
    "end": "99920"
  },
  {
    "text": "be able to fetch with some of the",
    "start": "99920",
    "end": "101360"
  },
  {
    "text": "utilities in one of our open source",
    "start": "101360",
    "end": "103200"
  },
  {
    "text": "frameworks so from that perspective we",
    "start": "103200",
    "end": "105040"
  },
  {
    "text": "already have this tensorflow",
    "start": "105040",
    "end": "107360"
  },
  {
    "text": "resnet 32 trained model",
    "start": "107360",
    "end": "110399"
  },
  {
    "start": "110000",
    "end": "173000"
  },
  {
    "text": "what we are able to do is we now are",
    "start": "110399",
    "end": "112320"
  },
  {
    "text": "able to ask the question well how do we",
    "start": "112320",
    "end": "113680"
  },
  {
    "text": "productionize it",
    "start": "113680",
    "end": "115040"
  },
  {
    "text": "and we can actually luckily use a lot of",
    "start": "115040",
    "end": "117040"
  },
  {
    "text": "the tools available in the case of this",
    "start": "117040",
    "end": "118799"
  },
  {
    "text": "talk we're going to be using",
    "start": "118799",
    "end": "120479"
  },
  {
    "text": "this tool called selden core seldom core",
    "start": "120479",
    "end": "123040"
  },
  {
    "text": "is a framework that allows you to",
    "start": "123040",
    "end": "124320"
  },
  {
    "text": "productionize your model artifacts",
    "start": "124320",
    "end": "126640"
  },
  {
    "text": "or code into a fully fledged",
    "start": "126640",
    "end": "128640"
  },
  {
    "text": "microservice that can be scaled",
    "start": "128640",
    "end": "130560"
  },
  {
    "text": "in kubernetes clusters and as you will",
    "start": "130560",
    "end": "133040"
  },
  {
    "text": "see uh throughout the rest of the talk",
    "start": "133040",
    "end": "135280"
  },
  {
    "text": "uh the the microservices that get",
    "start": "135280",
    "end": "137120"
  },
  {
    "text": "produced uh",
    "start": "137120",
    "end": "138720"
  },
  {
    "text": "have a rest and grpc api",
    "start": "138720",
    "end": "141760"
  },
  {
    "text": "it produces metrics it it has some",
    "start": "141760",
    "end": "144400"
  },
  {
    "text": "ability of logs",
    "start": "144400",
    "end": "145760"
  },
  {
    "text": "but ultimately this is basically what we",
    "start": "145760",
    "end": "148000"
  },
  {
    "text": "will be able to leverage to say",
    "start": "148000",
    "end": "149599"
  },
  {
    "text": "okay i want to productionize my model if",
    "start": "149599",
    "end": "152000"
  },
  {
    "text": "you're curious",
    "start": "152000",
    "end": "153200"
  },
  {
    "text": "on actually delving into the steps",
    "start": "153200",
    "end": "155599"
  },
  {
    "text": "required of how to productionize your",
    "start": "155599",
    "end": "157120"
  },
  {
    "text": "model",
    "start": "157120",
    "end": "157680"
  },
  {
    "text": "there will be a lot of uh notebook open",
    "start": "157680",
    "end": "159920"
  },
  {
    "text": "source examples that",
    "start": "159920",
    "end": "160959"
  },
  {
    "text": "will allow you to do so and try it out",
    "start": "160959",
    "end": "163120"
  },
  {
    "text": "uh so yeah you'll be able to actually",
    "start": "163120",
    "end": "165120"
  },
  {
    "text": "dive into as much detail",
    "start": "165120",
    "end": "166640"
  },
  {
    "text": "as you want but for now we will be able",
    "start": "166640",
    "end": "168720"
  },
  {
    "text": "to ask the question of well how do we",
    "start": "168720",
    "end": "170560"
  },
  {
    "text": "evaluate a model that we have deployed",
    "start": "170560",
    "end": "172959"
  },
  {
    "text": "and basically deploying model is",
    "start": "172959",
    "end": "174879"
  },
  {
    "start": "173000",
    "end": "370000"
  },
  {
    "text": "becoming",
    "start": "174879",
    "end": "176160"
  },
  {
    "text": "relatively easier and easier with seldom",
    "start": "176160",
    "end": "178800"
  },
  {
    "text": "core you're able to either just provide",
    "start": "178800",
    "end": "180560"
  },
  {
    "text": "your artifact",
    "start": "180560",
    "end": "181680"
  },
  {
    "text": "or provide a python wrapper you're able",
    "start": "181680",
    "end": "184879"
  },
  {
    "text": "to convert that python wrapper from",
    "start": "184879",
    "end": "186720"
  },
  {
    "text": "source to image to an actual image",
    "start": "186720",
    "end": "188879"
  },
  {
    "text": "but then you would be able to actually",
    "start": "188879",
    "end": "190400"
  },
  {
    "text": "deploy into a kubernetes cluster",
    "start": "190400",
    "end": "192720"
  },
  {
    "text": "the way that you would do it with selden",
    "start": "192720",
    "end": "194400"
  },
  {
    "text": "is through this um",
    "start": "194400",
    "end": "196239"
  },
  {
    "text": "declarative interface where you would be",
    "start": "196239",
    "end": "197840"
  },
  {
    "text": "able to say i want to deploy this model",
    "start": "197840",
    "end": "200000"
  },
  {
    "text": "i want to name it cipher 10 i want to",
    "start": "200000",
    "end": "202640"
  },
  {
    "text": "use one of the pre-packaged model",
    "start": "202640",
    "end": "204080"
  },
  {
    "text": "servers these are optimized containers",
    "start": "204080",
    "end": "206239"
  },
  {
    "text": "that you don't have to build yourself in",
    "start": "206239",
    "end": "208239"
  },
  {
    "text": "this case it's using the tf serving",
    "start": "208239",
    "end": "210159"
  },
  {
    "text": "underlying image",
    "start": "210159",
    "end": "211360"
  },
  {
    "text": "well you know there's also the ability",
    "start": "211360",
    "end": "212720"
  },
  {
    "text": "to use triton uh",
    "start": "212720",
    "end": "214799"
  },
  {
    "text": "you know scikit learn extreme boost",
    "start": "214799",
    "end": "216480"
  },
  {
    "text": "prepackaged servers etc",
    "start": "216480",
    "end": "218319"
  },
  {
    "text": "and ultimately what you need to just put",
    "start": "218319",
    "end": "220400"
  },
  {
    "text": "is there is",
    "start": "220400",
    "end": "221440"
  },
  {
    "text": "a bucket containing your model binaries",
    "start": "221440",
    "end": "224560"
  },
  {
    "text": "in this case we would have already",
    "start": "224560",
    "end": "226720"
  },
  {
    "text": "uploaded our",
    "start": "226720",
    "end": "228000"
  },
  {
    "text": "exported tensorflow uh binaries into a",
    "start": "228000",
    "end": "230959"
  },
  {
    "text": "google bucket",
    "start": "230959",
    "end": "232159"
  },
  {
    "text": "once you actually deploy it against the",
    "start": "232159",
    "end": "233760"
  },
  {
    "text": "cluster basically just doing",
    "start": "233760",
    "end": "235280"
  },
  {
    "text": "you know apply of that of that uh",
    "start": "235280",
    "end": "238480"
  },
  {
    "text": "config file into your kubernetes cluster",
    "start": "238480",
    "end": "240799"
  },
  {
    "text": "you will be able to see that selden",
    "start": "240799",
    "end": "242400"
  },
  {
    "text": "model being",
    "start": "242400",
    "end": "243439"
  },
  {
    "text": "uh managed and orchestrated by the",
    "start": "243439",
    "end": "245760"
  },
  {
    "text": "selden operator",
    "start": "245760",
    "end": "247120"
  },
  {
    "text": "what that basically means is that now we",
    "start": "247120",
    "end": "248799"
  },
  {
    "text": "have a microservice that we can send",
    "start": "248799",
    "end": "250319"
  },
  {
    "text": "requests to",
    "start": "250319",
    "end": "251920"
  },
  {
    "text": "so is that basically it are we basically",
    "start": "251920",
    "end": "254640"
  },
  {
    "text": "done",
    "start": "254640",
    "end": "255040"
  },
  {
    "text": "have we finished uh all of the journey",
    "start": "255040",
    "end": "257519"
  },
  {
    "text": "that we needed",
    "start": "257519",
    "end": "258479"
  },
  {
    "text": "well unfortunately um uh as we all",
    "start": "258479",
    "end": "262160"
  },
  {
    "text": "may have experienced in the past uh the",
    "start": "262160",
    "end": "264880"
  },
  {
    "text": "the performance of",
    "start": "264880",
    "end": "266160"
  },
  {
    "text": "of the models that may have been",
    "start": "266160",
    "end": "267360"
  },
  {
    "text": "deployed to production",
    "start": "267360",
    "end": "269440"
  },
  {
    "text": "could have some different new nuances uh",
    "start": "269440",
    "end": "272560"
  },
  {
    "text": "that may cause",
    "start": "272560",
    "end": "273600"
  },
  {
    "text": "uh uh a diverse performance to what may",
    "start": "273600",
    "end": "276639"
  },
  {
    "text": "have been seen",
    "start": "276639",
    "end": "277600"
  },
  {
    "text": "in the development right and in this",
    "start": "277600",
    "end": "279520"
  },
  {
    "text": "case for example it could be",
    "start": "279520",
    "end": "281360"
  },
  {
    "text": "uh you know from the more obscure type",
    "start": "281360",
    "end": "283840"
  },
  {
    "text": "memory leaks",
    "start": "283840",
    "end": "285120"
  },
  {
    "text": "uh that that you know result in a in a",
    "start": "285120",
    "end": "287759"
  },
  {
    "text": "in a sort of like a clogging of of of",
    "start": "287759",
    "end": "290080"
  },
  {
    "text": "memory",
    "start": "290080",
    "end": "290800"
  },
  {
    "text": "it could also be a much higher uh usage",
    "start": "290800",
    "end": "293680"
  },
  {
    "text": "of",
    "start": "293680",
    "end": "294240"
  },
  {
    "text": "of course it could be actually um",
    "start": "294240",
    "end": "296800"
  },
  {
    "text": "different sort of like",
    "start": "296800",
    "end": "298160"
  },
  {
    "text": "attributes that we will cover as a",
    "start": "298160",
    "end": "300080"
  },
  {
    "text": "result of this talk",
    "start": "300080",
    "end": "301360"
  },
  {
    "text": "but what ends up happening is the model",
    "start": "301360",
    "end": "304320"
  },
  {
    "text": "stops",
    "start": "304320",
    "end": "304880"
  },
  {
    "text": "working or there is a massive um",
    "start": "304880",
    "end": "309120"
  },
  {
    "text": "reduction in performance and something",
    "start": "309120",
    "end": "311600"
  },
  {
    "text": "breaks",
    "start": "311600",
    "end": "312240"
  },
  {
    "text": "right and from that perspective it's",
    "start": "312240",
    "end": "314080"
  },
  {
    "text": "it's the question of well",
    "start": "314080",
    "end": "315840"
  },
  {
    "text": "what could have been done in order to",
    "start": "315840",
    "end": "317520"
  },
  {
    "text": "prevent or to be able to",
    "start": "317520",
    "end": "319360"
  },
  {
    "text": "to understand what are the exact",
    "start": "319360",
    "end": "321759"
  },
  {
    "text": "required",
    "start": "321759",
    "end": "322720"
  },
  {
    "text": "configurations in order to minimize this",
    "start": "322720",
    "end": "325680"
  },
  {
    "text": "undesired behaviors",
    "start": "325680",
    "end": "327520"
  },
  {
    "text": "and from that perspective we do have to",
    "start": "327520",
    "end": "330000"
  },
  {
    "text": "first acknowledge that production",
    "start": "330000",
    "end": "331360"
  },
  {
    "text": "machine learnings are",
    "start": "331360",
    "end": "332560"
  },
  {
    "text": "systems are hard and the reason why is",
    "start": "332560",
    "end": "334560"
  },
  {
    "text": "because they require and depend",
    "start": "334560",
    "end": "336560"
  },
  {
    "text": "on specialized hardware this could be",
    "start": "336560",
    "end": "338479"
  },
  {
    "text": "either very large amounts of memory",
    "start": "338479",
    "end": "340240"
  },
  {
    "text": "this could be specialized processing",
    "start": "340240",
    "end": "341600"
  },
  {
    "text": "units like gpus or tpus",
    "start": "341600",
    "end": "343919"
  },
  {
    "text": "this could be all the way from complex",
    "start": "343919",
    "end": "345600"
  },
  {
    "text": "dependency graphs compliance",
    "start": "345600",
    "end": "347280"
  },
  {
    "text": "requirements reproducibility of",
    "start": "347280",
    "end": "348800"
  },
  {
    "text": "components",
    "start": "348800",
    "end": "349600"
  },
  {
    "text": "but ultimately there is basically a",
    "start": "349600",
    "end": "352240"
  },
  {
    "text": "complexity layer that is added on top",
    "start": "352240",
    "end": "354720"
  },
  {
    "text": "of the already complex challenge of",
    "start": "354720",
    "end": "358240"
  },
  {
    "text": "managing production microservices that",
    "start": "358240",
    "end": "361120"
  },
  {
    "text": "may not even be related to machine",
    "start": "361120",
    "end": "362720"
  },
  {
    "text": "learning",
    "start": "362720",
    "end": "363280"
  },
  {
    "text": "so from that perspective is important to",
    "start": "363280",
    "end": "365120"
  },
  {
    "text": "ensure that",
    "start": "365120",
    "end": "366639"
  },
  {
    "text": "it is possible to introduce some best",
    "start": "366639",
    "end": "368479"
  },
  {
    "text": "practices that allow us to manage this",
    "start": "368479",
    "end": "370000"
  },
  {
    "start": "370000",
    "end": "484000"
  },
  {
    "text": "complexity",
    "start": "370000",
    "end": "371199"
  },
  {
    "text": "now there is the extra complexity that",
    "start": "371199",
    "end": "373919"
  },
  {
    "text": "we need to kind of like start fleshing",
    "start": "373919",
    "end": "375199"
  },
  {
    "text": "out well",
    "start": "375199",
    "end": "375840"
  },
  {
    "text": "what does it look like in regards to the",
    "start": "375840",
    "end": "377759"
  },
  {
    "text": "components that we need to take into",
    "start": "377759",
    "end": "378960"
  },
  {
    "text": "consideration well in",
    "start": "378960",
    "end": "380560"
  },
  {
    "text": "the context of model configuration",
    "start": "380560",
    "end": "382000"
  },
  {
    "text": "parameters you know we did see",
    "start": "382000",
    "end": "383919"
  },
  {
    "text": "our our previous deployed model that",
    "start": "383919",
    "end": "386400"
  },
  {
    "text": "consisted just of the actual artifact",
    "start": "386400",
    "end": "388880"
  },
  {
    "text": "and the underlying",
    "start": "388880",
    "end": "389919"
  },
  {
    "text": "uh prepackaged server that we wanted to",
    "start": "389919",
    "end": "392720"
  },
  {
    "text": "use",
    "start": "392720",
    "end": "393280"
  },
  {
    "text": "but there are other variables to take",
    "start": "393280",
    "end": "394639"
  },
  {
    "text": "into consideration uh in the context of",
    "start": "394639",
    "end": "397039"
  },
  {
    "text": "you know perhaps",
    "start": "397039",
    "end": "397919"
  },
  {
    "text": "a machine learning model a machine",
    "start": "397919",
    "end": "400880"
  },
  {
    "text": "learning",
    "start": "400880",
    "end": "401440"
  },
  {
    "text": "model wrapper that is written in python",
    "start": "401440",
    "end": "403759"
  },
  {
    "text": "perhaps you may need to take into",
    "start": "403759",
    "end": "404960"
  },
  {
    "text": "consideration the number of",
    "start": "404960",
    "end": "406240"
  },
  {
    "text": "g-unicorn workers right if it's using g",
    "start": "406240",
    "end": "408479"
  },
  {
    "text": "unicorn or the",
    "start": "408479",
    "end": "409520"
  },
  {
    "text": "the number of threads that that your",
    "start": "409520",
    "end": "411360"
  },
  {
    "text": "application is running",
    "start": "411360",
    "end": "412720"
  },
  {
    "text": "the number of of of cores that you want",
    "start": "412720",
    "end": "415039"
  },
  {
    "text": "to allocate",
    "start": "415039",
    "end": "416000"
  },
  {
    "text": "as well as the memory that you want to",
    "start": "416000",
    "end": "417440"
  },
  {
    "text": "allocate for your cluster itself to not",
    "start": "417440",
    "end": "419520"
  },
  {
    "text": "get clogged",
    "start": "419520",
    "end": "420479"
  },
  {
    "text": "also the question of how many replicas",
    "start": "420479",
    "end": "422160"
  },
  {
    "text": "do you want to be able to paralyze",
    "start": "422160",
    "end": "424000"
  },
  {
    "text": "uh to be able to handle the requests in",
    "start": "424000",
    "end": "425919"
  },
  {
    "text": "the load balancer strategy",
    "start": "425919",
    "end": "428000"
  },
  {
    "text": "and from that perspective you know it is",
    "start": "428000",
    "end": "429840"
  },
  {
    "text": "it is of course still",
    "start": "429840",
    "end": "431400"
  },
  {
    "text": "semi-standardized micro service",
    "start": "431400",
    "end": "433199"
  },
  {
    "text": "kubernetes",
    "start": "433199",
    "end": "434560"
  },
  {
    "text": "concepts but it is the added complexity",
    "start": "434560",
    "end": "436960"
  },
  {
    "text": "of the requirements of the specialized",
    "start": "436960",
    "end": "439280"
  },
  {
    "text": "uh uh uh runtime uh components that that",
    "start": "439280",
    "end": "442479"
  },
  {
    "text": "perhaps may need",
    "start": "442479",
    "end": "443759"
  },
  {
    "text": "uh some further more complex uh",
    "start": "443759",
    "end": "447039"
  },
  {
    "text": "uh hardware uh requirements and you know",
    "start": "447039",
    "end": "449360"
  },
  {
    "text": "from that perspective",
    "start": "449360",
    "end": "450160"
  },
  {
    "text": "it could also be things like you know",
    "start": "450160",
    "end": "451440"
  },
  {
    "text": "gpus as well as the time required to",
    "start": "451440",
    "end": "454560"
  },
  {
    "text": "process each request because",
    "start": "454560",
    "end": "456319"
  },
  {
    "text": "it would be unlike uh perhaps other",
    "start": "456319",
    "end": "459120"
  },
  {
    "text": "other type of microservices",
    "start": "459120",
    "end": "460639"
  },
  {
    "text": "cpu intensive right as opposed to io",
    "start": "460639",
    "end": "463199"
  },
  {
    "text": "intensive",
    "start": "463199",
    "end": "464160"
  },
  {
    "text": "so from that perspective you need to",
    "start": "464160",
    "end": "466240"
  },
  {
    "text": "take into consideration",
    "start": "466240",
    "end": "467599"
  },
  {
    "text": "the throughputs the number of requests",
    "start": "467599",
    "end": "469199"
  },
  {
    "text": "per second the time for each request to",
    "start": "469199",
    "end": "470960"
  },
  {
    "text": "be processed",
    "start": "470960",
    "end": "471840"
  },
  {
    "text": "and then from there the number of",
    "start": "471840",
    "end": "473440"
  },
  {
    "text": "processes the number of threads you know",
    "start": "473440",
    "end": "475120"
  },
  {
    "text": "if it's a python base if it's",
    "start": "475120",
    "end": "476560"
  },
  {
    "text": "you know simple suppose or lower level",
    "start": "476560",
    "end": "478080"
  },
  {
    "text": "it's just uh the the",
    "start": "478080",
    "end": "479599"
  },
  {
    "text": "the hardware base parallelization as",
    "start": "479599",
    "end": "482160"
  },
  {
    "text": "well as many other things",
    "start": "482160",
    "end": "483280"
  },
  {
    "text": "so complex but how do we manage that",
    "start": "483280",
    "end": "486479"
  },
  {
    "start": "484000",
    "end": "530000"
  },
  {
    "text": "well there are some best practices uh",
    "start": "486479",
    "end": "488400"
  },
  {
    "text": "and some motivations of actually",
    "start": "488400",
    "end": "489840"
  },
  {
    "text": "adopting some benchmarking",
    "start": "489840",
    "end": "491599"
  },
  {
    "text": "approaches basically being able to",
    "start": "491599",
    "end": "493680"
  },
  {
    "text": "perform evaluation of",
    "start": "493680",
    "end": "494960"
  },
  {
    "text": "new versus old models how they're",
    "start": "494960",
    "end": "496560"
  },
  {
    "text": "performing against them assessment of",
    "start": "496560",
    "end": "498560"
  },
  {
    "text": "throughput of existing models that are",
    "start": "498560",
    "end": "500319"
  },
  {
    "text": "being deployed",
    "start": "500319",
    "end": "501199"
  },
  {
    "text": "assessment of latency as well as",
    "start": "501199",
    "end": "502639"
  },
  {
    "text": "monitoring of it optimization of",
    "start": "502639",
    "end": "504560"
  },
  {
    "text": "resource allocation if you actually want",
    "start": "504560",
    "end": "506160"
  },
  {
    "text": "to",
    "start": "506160",
    "end": "506560"
  },
  {
    "text": "minimize costs what is what is the exact",
    "start": "506560",
    "end": "509599"
  },
  {
    "text": "resources that you would want to",
    "start": "509599",
    "end": "510800"
  },
  {
    "text": "allocate optimization of number of",
    "start": "510800",
    "end": "512880"
  },
  {
    "text": "threads workers to be able to ensure",
    "start": "512880",
    "end": "514719"
  },
  {
    "text": "that the",
    "start": "514719",
    "end": "515279"
  },
  {
    "text": "internals are working correctly and",
    "start": "515279",
    "end": "517680"
  },
  {
    "text": "evaluation of performance under load or",
    "start": "517680",
    "end": "519599"
  },
  {
    "text": "stress",
    "start": "519599",
    "end": "520399"
  },
  {
    "text": "or basically long running models right",
    "start": "520399",
    "end": "522959"
  },
  {
    "text": "after maybe a week or",
    "start": "522959",
    "end": "524720"
  },
  {
    "text": "or or or so there could be um you know",
    "start": "524720",
    "end": "528320"
  },
  {
    "text": "diverse and performance of the of the",
    "start": "528320",
    "end": "530320"
  },
  {
    "start": "530000",
    "end": "567000"
  },
  {
    "text": "microservices",
    "start": "530320",
    "end": "531440"
  },
  {
    "text": "and there are multiple benchmarking",
    "start": "531440",
    "end": "533440"
  },
  {
    "text": "types and performance valuation types",
    "start": "533440",
    "end": "535200"
  },
  {
    "text": "that can be done in in the general",
    "start": "535200",
    "end": "536959"
  },
  {
    "text": "microservices area",
    "start": "536959",
    "end": "538320"
  },
  {
    "text": "things like performance testing a",
    "start": "538320",
    "end": "540399"
  },
  {
    "text": "general name you know for tests that",
    "start": "540399",
    "end": "542000"
  },
  {
    "text": "check how the system behaves and",
    "start": "542000",
    "end": "543200"
  },
  {
    "text": "performs right",
    "start": "543200",
    "end": "544320"
  },
  {
    "text": "basically you know how would behave if i",
    "start": "544320",
    "end": "546800"
  },
  {
    "text": "actually run",
    "start": "546800",
    "end": "547680"
  },
  {
    "text": "100 uh requests per second load testing",
    "start": "547680",
    "end": "550959"
  },
  {
    "text": "is",
    "start": "550959",
    "end": "551200"
  },
  {
    "text": "you want to actually take it to the",
    "start": "551200",
    "end": "552560"
  },
  {
    "text": "limit see what is the maximum rate",
    "start": "552560",
    "end": "555120"
  },
  {
    "text": "of request that it can actually withhold",
    "start": "555120",
    "end": "557760"
  },
  {
    "text": "uh and stress testing basically like you",
    "start": "557760",
    "end": "559760"
  },
  {
    "text": "know actually extreme loads",
    "start": "559760",
    "end": "561600"
  },
  {
    "text": "that you may want to carry around we",
    "start": "561600",
    "end": "563440"
  },
  {
    "text": "will be able to see how to leverage each",
    "start": "563440",
    "end": "565120"
  },
  {
    "text": "of those",
    "start": "565120",
    "end": "565600"
  },
  {
    "text": "on the context of machine learning",
    "start": "565600",
    "end": "567360"
  },
  {
    "start": "567000",
    "end": "667000"
  },
  {
    "text": "models themselves",
    "start": "567360",
    "end": "569120"
  },
  {
    "text": "there is also luckily tools that we can",
    "start": "569120",
    "end": "571040"
  },
  {
    "text": "leverage for our use cases",
    "start": "571040",
    "end": "572720"
  },
  {
    "text": "we will be using two specifically for",
    "start": "572720",
    "end": "574640"
  },
  {
    "text": "our examples",
    "start": "574640",
    "end": "575760"
  },
  {
    "text": "one is for the grpc api called ghz",
    "start": "575760",
    "end": "579519"
  },
  {
    "text": "and one for the http api which is called",
    "start": "579519",
    "end": "582399"
  },
  {
    "text": "vegito",
    "start": "582399",
    "end": "583120"
  },
  {
    "text": "right we'll be able to leverage this too",
    "start": "583120",
    "end": "585120"
  },
  {
    "text": "and we will see how they",
    "start": "585120",
    "end": "586320"
  },
  {
    "text": "allow us to actually perform the",
    "start": "586320",
    "end": "588240"
  },
  {
    "text": "benchmarking",
    "start": "588240",
    "end": "589360"
  },
  {
    "text": "so starting with vegeta we can see that",
    "start": "589360",
    "end": "591120"
  },
  {
    "text": "the actual uh benchmarking performance",
    "start": "591120",
    "end": "594000"
  },
  {
    "text": "can be done in a very standardized way",
    "start": "594000",
    "end": "595519"
  },
  {
    "text": "we can say hey what this is",
    "start": "595519",
    "end": "597040"
  },
  {
    "text": "the end point of our machine learning",
    "start": "597040",
    "end": "599279"
  },
  {
    "text": "model the rest endpoint the http",
    "start": "599279",
    "end": "601279"
  },
  {
    "text": "endpoint",
    "start": "601279",
    "end": "602079"
  },
  {
    "text": "we want to be able to send a post",
    "start": "602079",
    "end": "603440"
  },
  {
    "text": "request with you know 10 cpus we want to",
    "start": "603440",
    "end": "606079"
  },
  {
    "text": "actually",
    "start": "606079",
    "end": "606640"
  },
  {
    "text": "maximize the throughput i want to reach",
    "start": "606640",
    "end": "608560"
  },
  {
    "text": "like a rate of 120 requests per second",
    "start": "608560",
    "end": "611040"
  },
  {
    "text": "and i want this number of workers and",
    "start": "611040",
    "end": "612800"
  },
  {
    "text": "then i want to print a report",
    "start": "612800",
    "end": "614640"
  },
  {
    "text": "based on that report we can actually see",
    "start": "614640",
    "end": "616320"
  },
  {
    "text": "what are the latencies the",
    "start": "616320",
    "end": "618079"
  },
  {
    "text": "the the mean latency the the percentiles",
    "start": "618079",
    "end": "620720"
  },
  {
    "text": "the total duration the number of uh you",
    "start": "620720",
    "end": "622959"
  },
  {
    "text": "know",
    "start": "622959",
    "end": "623600"
  },
  {
    "text": "the rates that it was withstanding the",
    "start": "623600",
    "end": "625600"
  },
  {
    "text": "throughputs which is basically",
    "start": "625600",
    "end": "626800"
  },
  {
    "text": "successful",
    "start": "626800",
    "end": "627680"
  },
  {
    "text": "as opposed to just the number of",
    "start": "627680",
    "end": "628880"
  },
  {
    "text": "requests that it could withstand at the",
    "start": "628880",
    "end": "630560"
  },
  {
    "text": "same time",
    "start": "630560",
    "end": "631440"
  },
  {
    "text": "and then the status codes right so with",
    "start": "631440",
    "end": "633120"
  },
  {
    "text": "this you're able to identify what is the",
    "start": "633120",
    "end": "635120"
  },
  {
    "text": "actual performance of the model",
    "start": "635120",
    "end": "636720"
  },
  {
    "text": "and similarly we're able to perform this",
    "start": "636720",
    "end": "638800"
  },
  {
    "text": "uh from the",
    "start": "638800",
    "end": "639920"
  },
  {
    "text": "grpc perspective using gh set you can",
    "start": "639920",
    "end": "642160"
  },
  {
    "text": "see that the actual",
    "start": "642160",
    "end": "643360"
  },
  {
    "text": "uh parameters are very similar it's just",
    "start": "643360",
    "end": "646240"
  },
  {
    "text": "that we would actually use the protobufs",
    "start": "646240",
    "end": "648160"
  },
  {
    "text": "right if you're interested about",
    "start": "648160",
    "end": "649680"
  },
  {
    "text": "what this looks like you know by",
    "start": "649680",
    "end": "650880"
  },
  {
    "text": "actually delving into the example",
    "start": "650880",
    "end": "652720"
  },
  {
    "text": "you'll be able to try it yourself send a",
    "start": "652720",
    "end": "654399"
  },
  {
    "text": "single request the grpc",
    "start": "654399",
    "end": "656000"
  },
  {
    "text": "http endpoint so you get an intuition",
    "start": "656000",
    "end": "658399"
  },
  {
    "text": "but this is more than anything for you",
    "start": "658399",
    "end": "660880"
  },
  {
    "text": "to get an idea",
    "start": "660880",
    "end": "661920"
  },
  {
    "text": "of how to leverage the tools as we will",
    "start": "661920",
    "end": "663680"
  },
  {
    "text": "now start diving into how",
    "start": "663680",
    "end": "665360"
  },
  {
    "text": "to automate these processes and the",
    "start": "665360",
    "end": "667279"
  },
  {
    "start": "667000",
    "end": "753000"
  },
  {
    "text": "reason why we want to do this is because",
    "start": "667279",
    "end": "670000"
  },
  {
    "text": "as you can see there are multiple things",
    "start": "670000",
    "end": "672320"
  },
  {
    "text": "that we can actually",
    "start": "672320",
    "end": "674000"
  },
  {
    "text": "uh tweak right we can tweak the total",
    "start": "674000",
    "end": "676640"
  },
  {
    "text": "cores allocated the total memory",
    "start": "676640",
    "end": "678800"
  },
  {
    "text": "uh required the latency per request that",
    "start": "678800",
    "end": "681600"
  },
  {
    "text": "we take into consideration the requests",
    "start": "681600",
    "end": "683200"
  },
  {
    "text": "per second and the throughput",
    "start": "683200",
    "end": "684720"
  },
  {
    "text": "the number of workers or threads the",
    "start": "684720",
    "end": "686399"
  },
  {
    "text": "number of replicas required the",
    "start": "686399",
    "end": "688480"
  },
  {
    "text": "horizontal",
    "start": "688480",
    "end": "689440"
  },
  {
    "text": "auto scaling requirements as well as the",
    "start": "689440",
    "end": "691760"
  },
  {
    "text": "perhaps",
    "start": "691760",
    "end": "693760"
  },
  {
    "text": "missed requests that would be",
    "start": "693760",
    "end": "697360"
  },
  {
    "text": "lost lost as the actual pods are",
    "start": "697360",
    "end": "700720"
  },
  {
    "text": "scaling if it actually takes time so",
    "start": "700720",
    "end": "703360"
  },
  {
    "text": "from that perspective we also need to",
    "start": "703360",
    "end": "705200"
  },
  {
    "text": "automate",
    "start": "705200",
    "end": "706560"
  },
  {
    "text": "the actual evaluation we don't want to",
    "start": "706560",
    "end": "708640"
  },
  {
    "text": "have to run you know vegeta or ghz",
    "start": "708640",
    "end": "711839"
  },
  {
    "text": "100 times with different parameters in",
    "start": "711839",
    "end": "714000"
  },
  {
    "text": "order for us to get some useful results",
    "start": "714000",
    "end": "715920"
  },
  {
    "text": "right so",
    "start": "715920",
    "end": "716720"
  },
  {
    "text": "that's basically now the premise of okay",
    "start": "716720",
    "end": "719040"
  },
  {
    "text": "we've we've seen",
    "start": "719040",
    "end": "720160"
  },
  {
    "text": "how we what are they what are the",
    "start": "720160",
    "end": "721680"
  },
  {
    "text": "attributes that we can evaluate",
    "start": "721680",
    "end": "723440"
  },
  {
    "text": "we have seen what are the um",
    "start": "723440",
    "end": "726480"
  },
  {
    "text": "uh what are the specific uh best",
    "start": "726480",
    "end": "728480"
  },
  {
    "text": "practices uh that we can use",
    "start": "728480",
    "end": "730880"
  },
  {
    "text": "what are the techniques and what are the",
    "start": "730880",
    "end": "732399"
  },
  {
    "text": "tools right so now is basically how do",
    "start": "732399",
    "end": "734480"
  },
  {
    "text": "we",
    "start": "734480",
    "end": "734880"
  },
  {
    "text": "piece all of this together to automate",
    "start": "734880",
    "end": "736880"
  },
  {
    "text": "it and",
    "start": "736880",
    "end": "737920"
  },
  {
    "text": "to also make sure that we can automate",
    "start": "737920",
    "end": "739600"
  },
  {
    "text": "it at scale right not just something",
    "start": "739600",
    "end": "741600"
  },
  {
    "text": "that i would run on my laptop",
    "start": "741600",
    "end": "743360"
  },
  {
    "text": "and wait until it's done but something",
    "start": "743360",
    "end": "745519"
  },
  {
    "text": "that i can actually",
    "start": "745519",
    "end": "746560"
  },
  {
    "text": "um you know actually uh deploy at scale",
    "start": "746560",
    "end": "751040"
  },
  {
    "text": "and ensure that this can actually be",
    "start": "751040",
    "end": "752399"
  },
  {
    "text": "done in a programmatic way",
    "start": "752399",
    "end": "754240"
  },
  {
    "start": "753000",
    "end": "784000"
  },
  {
    "text": "and from that we are able to leverage",
    "start": "754240",
    "end": "757600"
  },
  {
    "text": "the concept of workflow managers so this",
    "start": "757600",
    "end": "760320"
  },
  {
    "text": "may actually come",
    "start": "760320",
    "end": "762880"
  },
  {
    "text": "perhaps more often in the con in the",
    "start": "762880",
    "end": "765839"
  },
  {
    "text": "context of",
    "start": "765839",
    "end": "767279"
  },
  {
    "text": "etl-based systems or extract load",
    "start": "767279",
    "end": "770079"
  },
  {
    "text": "transform",
    "start": "770079",
    "end": "771519"
  },
  {
    "text": "data or in the context of ci cd systems",
    "start": "771519",
    "end": "774480"
  },
  {
    "text": "where you would have a pipeline that",
    "start": "774480",
    "end": "775839"
  },
  {
    "text": "carries out several actions",
    "start": "775839",
    "end": "777680"
  },
  {
    "text": "and you know you you perform some sort",
    "start": "777680",
    "end": "780160"
  },
  {
    "text": "of output",
    "start": "780160",
    "end": "781120"
  },
  {
    "text": "but basically we're going to be using",
    "start": "781120",
    "end": "782399"
  },
  {
    "text": "the concept of workflow managers",
    "start": "782399",
    "end": "784480"
  },
  {
    "start": "784000",
    "end": "932000"
  },
  {
    "text": "the way that we're going to be using",
    "start": "784480",
    "end": "786079"
  },
  {
    "text": "this work for managers which will allow",
    "start": "786079",
    "end": "787519"
  },
  {
    "text": "us to basically run jobs",
    "start": "787519",
    "end": "789279"
  },
  {
    "text": "uh with multiple steps multiple reusable",
    "start": "789279",
    "end": "791600"
  },
  {
    "text": "steps and we will actually see what that",
    "start": "791600",
    "end": "793519"
  },
  {
    "text": "looks like in",
    "start": "793519",
    "end": "794320"
  },
  {
    "text": "in practice we will you know will be",
    "start": "794320",
    "end": "796560"
  },
  {
    "text": "common intuitive if you haven't come",
    "start": "796560",
    "end": "798079"
  },
  {
    "text": "across",
    "start": "798079",
    "end": "798720"
  },
  {
    "text": "workflow managers but we're going to be",
    "start": "798720",
    "end": "800399"
  },
  {
    "text": "using uh the argo workflows",
    "start": "800399",
    "end": "802800"
  },
  {
    "text": "uh workflow manager which will allow us",
    "start": "802800",
    "end": "805040"
  },
  {
    "text": "to have a very simple workflow",
    "start": "805040",
    "end": "806800"
  },
  {
    "text": "the workflow will consist of a first",
    "start": "806800",
    "end": "808880"
  },
  {
    "text": "step to actually",
    "start": "808880",
    "end": "810480"
  },
  {
    "text": "deploy or configure uh if it's already",
    "start": "810480",
    "end": "813120"
  },
  {
    "text": "deployed and already existing",
    "start": "813120",
    "end": "815040"
  },
  {
    "text": "selden selden model seldom deployment",
    "start": "815040",
    "end": "818160"
  },
  {
    "text": "right so we saw",
    "start": "818160",
    "end": "819360"
  },
  {
    "text": "that we were able to to productionize",
    "start": "819360",
    "end": "821199"
  },
  {
    "text": "our machine learning model by actually",
    "start": "821199",
    "end": "822480"
  },
  {
    "text": "converting into a fully fledged",
    "start": "822480",
    "end": "823680"
  },
  {
    "text": "microservice",
    "start": "823680",
    "end": "824639"
  },
  {
    "text": "we also saw that we can actually uh",
    "start": "824639",
    "end": "827040"
  },
  {
    "text": "choose the parameters",
    "start": "827040",
    "end": "828399"
  },
  {
    "text": "of how we deploy it right this can be",
    "start": "828399",
    "end": "831120"
  },
  {
    "text": "the",
    "start": "831120",
    "end": "831519"
  },
  {
    "text": "number of reques the memory the cpus the",
    "start": "831519",
    "end": "834639"
  },
  {
    "text": "the threads the workers the replicas",
    "start": "834639",
    "end": "836959"
  },
  {
    "text": "so basically this is this is a step that",
    "start": "836959",
    "end": "838880"
  },
  {
    "text": "is able to specify",
    "start": "838880",
    "end": "840639"
  },
  {
    "text": "uh what it looks like right what our",
    "start": "840639",
    "end": "842720"
  },
  {
    "text": "model looks like",
    "start": "842720",
    "end": "843839"
  },
  {
    "text": "then once it's actually created and",
    "start": "843839",
    "end": "846160"
  },
  {
    "text": "updated and it's running with all of the",
    "start": "846160",
    "end": "847839"
  },
  {
    "text": "configure requirements",
    "start": "847839",
    "end": "849519"
  },
  {
    "text": "uh we are then able to run the the",
    "start": "849519",
    "end": "852320"
  },
  {
    "text": "benchmarking step right so this is",
    "start": "852320",
    "end": "854000"
  },
  {
    "text": "basically running",
    "start": "854000",
    "end": "855040"
  },
  {
    "text": "either the vegeta state step or the gh",
    "start": "855040",
    "end": "858160"
  },
  {
    "text": "set step which runs the evaluation the",
    "start": "858160",
    "end": "861760"
  },
  {
    "text": "performance evaluation the benchmarking",
    "start": "861760",
    "end": "863680"
  },
  {
    "text": "with a particular set of parameters that",
    "start": "863680",
    "end": "865600"
  },
  {
    "text": "the number of cpus the number of workers",
    "start": "865600",
    "end": "867519"
  },
  {
    "text": "the rates",
    "start": "867519",
    "end": "868160"
  },
  {
    "text": "expected the duration etc etc",
    "start": "868160",
    "end": "871519"
  },
  {
    "text": "and uh of course we would then not just",
    "start": "871519",
    "end": "874639"
  },
  {
    "text": "run it once because otherwise the the",
    "start": "874639",
    "end": "877199"
  },
  {
    "text": "benefit that we would get from this",
    "start": "877199",
    "end": "878720"
  },
  {
    "text": "would be quite minimal instead what we",
    "start": "878720",
    "end": "880880"
  },
  {
    "text": "would want to do is to be able to",
    "start": "880880",
    "end": "882240"
  },
  {
    "text": "actually run it",
    "start": "882240",
    "end": "883120"
  },
  {
    "text": "across a broad range of values",
    "start": "883120",
    "end": "886320"
  },
  {
    "text": "and if you come from a data science",
    "start": "886320",
    "end": "889120"
  },
  {
    "text": "machine learning background",
    "start": "889120",
    "end": "890480"
  },
  {
    "text": "you may have you may be able to build an",
    "start": "890480",
    "end": "892639"
  },
  {
    "text": "intuition",
    "start": "892639",
    "end": "893519"
  },
  {
    "text": "through the context through the concept",
    "start": "893519",
    "end": "895199"
  },
  {
    "text": "of grid search right basically when you",
    "start": "895199",
    "end": "897199"
  },
  {
    "text": "say",
    "start": "897199",
    "end": "897760"
  },
  {
    "text": "i have this bunch of hyper parameter uh",
    "start": "897760",
    "end": "900560"
  },
  {
    "text": "choices and i want to actually run a",
    "start": "900560",
    "end": "902320"
  },
  {
    "text": "permutation across all of my hardware",
    "start": "902320",
    "end": "903920"
  },
  {
    "text": "parameters",
    "start": "903920",
    "end": "904720"
  },
  {
    "text": "to see what the actual output or the",
    "start": "904720",
    "end": "907440"
  },
  {
    "text": "performance will be",
    "start": "907440",
    "end": "908560"
  },
  {
    "text": "if i choose you know parameter a to b",
    "start": "908560",
    "end": "911760"
  },
  {
    "text": "one two three five ten one hundred",
    "start": "911760",
    "end": "914800"
  },
  {
    "text": "and then parameter b being twenty forty",
    "start": "914800",
    "end": "917199"
  },
  {
    "text": "sixty",
    "start": "917199",
    "end": "917839"
  },
  {
    "text": "so it would back basically basically run",
    "start": "917839",
    "end": "920079"
  },
  {
    "text": "uh a permutation",
    "start": "920079",
    "end": "921440"
  },
  {
    "text": "or a combination i guess more",
    "start": "921440",
    "end": "923279"
  },
  {
    "text": "specifically a combination of",
    "start": "923279",
    "end": "924880"
  },
  {
    "text": "uh all of these different uh values",
    "start": "924880",
    "end": "927040"
  },
  {
    "text": "across",
    "start": "927040",
    "end": "927920"
  },
  {
    "text": "so basically uh that that is the the",
    "start": "927920",
    "end": "930959"
  },
  {
    "text": "ultimate uh",
    "start": "930959",
    "end": "932000"
  },
  {
    "text": "uh objective of this so what argo",
    "start": "932000",
    "end": "935440"
  },
  {
    "text": "really looks like this is actually first",
    "start": "935440",
    "end": "937120"
  },
  {
    "text": "just an example to get you into the",
    "start": "937120",
    "end": "939040"
  },
  {
    "text": "syntax of argo workloads",
    "start": "939040",
    "end": "940959"
  },
  {
    "text": "so argo basically allows you to perform",
    "start": "940959",
    "end": "943839"
  },
  {
    "text": "steps",
    "start": "943839",
    "end": "944480"
  },
  {
    "text": "right in a modular way same in",
    "start": "944480",
    "end": "946160"
  },
  {
    "text": "kubernetes so what that means is that",
    "start": "946160",
    "end": "948160"
  },
  {
    "text": "you are able to define",
    "start": "948160",
    "end": "949519"
  },
  {
    "text": "in in this case what they call a",
    "start": "949519",
    "end": "951120"
  },
  {
    "text": "template so a referenceable state",
    "start": "951120",
    "end": "954160"
  },
  {
    "text": "so a reversible step which in this case",
    "start": "954160",
    "end": "956720"
  },
  {
    "text": "it just actually uh",
    "start": "956720",
    "end": "957920"
  },
  {
    "text": "prints uh a message right so it",
    "start": "957920",
    "end": "960160"
  },
  {
    "text": "basically",
    "start": "960160",
    "end": "960959"
  },
  {
    "text": "says this this template called uh whale",
    "start": "960959",
    "end": "964079"
  },
  {
    "text": "say",
    "start": "964079",
    "end": "964800"
  },
  {
    "text": "uh prints a message that comes in as a",
    "start": "964800",
    "end": "967120"
  },
  {
    "text": "parameter",
    "start": "967120",
    "end": "968320"
  },
  {
    "text": "of the name message right so then the",
    "start": "968320",
    "end": "971279"
  },
  {
    "text": "actual workflow",
    "start": "971279",
    "end": "972399"
  },
  {
    "text": "consists of two steps the first step is",
    "start": "972399",
    "end": "975040"
  },
  {
    "text": "to run that template",
    "start": "975040",
    "end": "976560"
  },
  {
    "text": "with the actual parameter hello",
    "start": "976560",
    "end": "979600"
  },
  {
    "text": "to a and then basically the second one",
    "start": "979600",
    "end": "983040"
  },
  {
    "text": "is to run another uh step with the",
    "start": "983040",
    "end": "986240"
  },
  {
    "text": "well what seems to be the same parameter",
    "start": "986240",
    "end": "988000"
  },
  {
    "text": "which actually should be different but",
    "start": "988000",
    "end": "989759"
  },
  {
    "text": "ultimately what this would do is",
    "start": "989759",
    "end": "991120"
  },
  {
    "text": "actually run two steps",
    "start": "991120",
    "end": "993040"
  },
  {
    "text": "with two different jobs kubernetes",
    "start": "993040",
    "end": "995440"
  },
  {
    "text": "containers that run",
    "start": "995440",
    "end": "997040"
  },
  {
    "text": "until completion it waits until it's",
    "start": "997040",
    "end": "999120"
  },
  {
    "text": "successful and then it runs the next one",
    "start": "999120",
    "end": "1001360"
  },
  {
    "text": "that's basically what this is if you",
    "start": "1001360",
    "end": "1002880"
  },
  {
    "text": "come across other workflows maybe this",
    "start": "1002880",
    "end": "1004800"
  },
  {
    "text": "is a little bit painful because it's",
    "start": "1004800",
    "end": "1006240"
  },
  {
    "text": "you know going from the basics but if",
    "start": "1006240",
    "end": "1007600"
  },
  {
    "text": "you haven't they should give you a good",
    "start": "1007600",
    "end": "1009920"
  },
  {
    "text": "intuition of",
    "start": "1009920",
    "end": "1011120"
  },
  {
    "text": "why we are using this right it runs a",
    "start": "1011120",
    "end": "1013839"
  },
  {
    "text": "step",
    "start": "1013839",
    "end": "1014560"
  },
  {
    "text": "it assesses whether it's successful and",
    "start": "1014560",
    "end": "1016079"
  },
  {
    "text": "then it runs a next step and it's also",
    "start": "1016079",
    "end": "1018240"
  },
  {
    "text": "able to pass parameters",
    "start": "1018240",
    "end": "1019839"
  },
  {
    "text": "right now what we are going to be able",
    "start": "1019839",
    "end": "1021920"
  },
  {
    "start": "1020000",
    "end": "1161000"
  },
  {
    "text": "to do in our case",
    "start": "1021920",
    "end": "1023360"
  },
  {
    "text": "is we're going to be able to actually",
    "start": "1023360",
    "end": "1024959"
  },
  {
    "text": "build a",
    "start": "1024959",
    "end": "1026400"
  },
  {
    "text": "reusable argo workflow and from this",
    "start": "1026400",
    "end": "1029438"
  },
  {
    "text": "perspective",
    "start": "1029439",
    "end": "1030400"
  },
  {
    "text": "we will talk about first the argo",
    "start": "1030400",
    "end": "1032160"
  },
  {
    "text": "workflow and then the reusable part",
    "start": "1032160",
    "end": "1034558"
  },
  {
    "text": "first the argo workflow part is",
    "start": "1034559",
    "end": "1036480"
  },
  {
    "text": "basically the step where you would be",
    "start": "1036480",
    "end": "1038000"
  },
  {
    "text": "able to say okay",
    "start": "1038000",
    "end": "1039360"
  },
  {
    "text": "i want to run this three steps that we",
    "start": "1039360",
    "end": "1042079"
  },
  {
    "text": "talked about",
    "start": "1042079",
    "end": "1042959"
  },
  {
    "text": "the create or modify seldom resource",
    "start": "1042959",
    "end": "1045199"
  },
  {
    "text": "right the one that actually deploys it",
    "start": "1045199",
    "end": "1046640"
  },
  {
    "text": "configures it",
    "start": "1046640",
    "end": "1047839"
  },
  {
    "text": "the wait for selling resource right the",
    "start": "1047839",
    "end": "1049760"
  },
  {
    "text": "one we're actually like you know",
    "start": "1049760",
    "end": "1051280"
  },
  {
    "text": "waits until it's actually running",
    "start": "1051280",
    "end": "1053200"
  },
  {
    "text": "because of course you're deploying a",
    "start": "1053200",
    "end": "1054799"
  },
  {
    "text": "model so you're",
    "start": "1054799",
    "end": "1055760"
  },
  {
    "text": "waiting until the actual microservices",
    "start": "1055760",
    "end": "1057840"
  },
  {
    "text": "is fully running",
    "start": "1057840",
    "end": "1059039"
  },
  {
    "text": "and then running the benchmark now",
    "start": "1059039",
    "end": "1061600"
  },
  {
    "text": "specifically in each of these steps",
    "start": "1061600",
    "end": "1063679"
  },
  {
    "text": "what we would want to do is not just to",
    "start": "1063679",
    "end": "1065520"
  },
  {
    "text": "run the steps because in this case what",
    "start": "1065520",
    "end": "1066960"
  },
  {
    "text": "we can see",
    "start": "1066960",
    "end": "1067919"
  },
  {
    "text": "is that the steps would be either",
    "start": "1067919",
    "end": "1069120"
  },
  {
    "text": "running vegeta or either",
    "start": "1069120",
    "end": "1071760"
  },
  {
    "text": "or running gh set and you will see why",
    "start": "1071760",
    "end": "1075360"
  },
  {
    "text": "we want to do this",
    "start": "1075360",
    "end": "1077039"
  },
  {
    "text": "we want to either run vegeta or ghz but",
    "start": "1077039",
    "end": "1079360"
  },
  {
    "text": "the parameters you know",
    "start": "1079360",
    "end": "1080640"
  },
  {
    "text": "i i didn't put all the parameters here",
    "start": "1080640",
    "end": "1082559"
  },
  {
    "text": "because it's a pretty",
    "start": "1082559",
    "end": "1084240"
  },
  {
    "text": "long file but what you would actually",
    "start": "1084240",
    "end": "1086880"
  },
  {
    "text": "see here",
    "start": "1086880",
    "end": "1087520"
  },
  {
    "text": "is um the number of cpus the rate etc",
    "start": "1087520",
    "end": "1090720"
  },
  {
    "text": "etc and you can see that there is kind",
    "start": "1090720",
    "end": "1092320"
  },
  {
    "text": "of like a mapping",
    "start": "1092320",
    "end": "1093840"
  },
  {
    "text": "of the parameters that are used for",
    "start": "1093840",
    "end": "1095280"
  },
  {
    "text": "vegeta to the parameters that are used",
    "start": "1095280",
    "end": "1097039"
  },
  {
    "text": "in",
    "start": "1097039",
    "end": "1097360"
  },
  {
    "text": "gh set right so we want to make sure",
    "start": "1097360",
    "end": "1100400"
  },
  {
    "text": "that",
    "start": "1100400",
    "end": "1101360"
  },
  {
    "text": "we can actually reuse the same sort of",
    "start": "1101360",
    "end": "1103120"
  },
  {
    "text": "type of parameters",
    "start": "1103120",
    "end": "1104400"
  },
  {
    "text": "and then in argo workflows fortunately",
    "start": "1104400",
    "end": "1106480"
  },
  {
    "text": "they also provide a way",
    "start": "1106480",
    "end": "1108320"
  },
  {
    "text": "to perform what is a grid search",
    "start": "1108320",
    "end": "1111520"
  },
  {
    "text": "so you're also able to actually call the",
    "start": "1111520",
    "end": "1114320"
  },
  {
    "text": "the steps",
    "start": "1114320",
    "end": "1115600"
  },
  {
    "text": "you're able to call the steps uh by",
    "start": "1115600",
    "end": "1118080"
  },
  {
    "text": "using",
    "start": "1118080",
    "end": "1118880"
  },
  {
    "text": "a a set of grid options and requesting",
    "start": "1118880",
    "end": "1121600"
  },
  {
    "text": "to",
    "start": "1121600",
    "end": "1122080"
  },
  {
    "text": "pass a basically combination of each of",
    "start": "1122080",
    "end": "1125039"
  },
  {
    "text": "those",
    "start": "1125039",
    "end": "1125679"
  },
  {
    "text": "so you you're basically saying hey i i",
    "start": "1125679",
    "end": "1128640"
  },
  {
    "text": "want to then run this argo workflow",
    "start": "1128640",
    "end": "1130880"
  },
  {
    "text": "i want to use this this um",
    "start": "1130880",
    "end": "1134000"
  },
  {
    "text": "parameters right i want to pass for",
    "start": "1134000",
    "end": "1137280"
  },
  {
    "text": "uh the number of cpus 0.1 0.5",
    "start": "1137280",
    "end": "1141120"
  },
  {
    "text": "1 2 5 and then for ram i want to put",
    "start": "1141120",
    "end": "1144320"
  },
  {
    "text": "like",
    "start": "1144320",
    "end": "1144960"
  },
  {
    "text": "you know 200 megs 500 megs one gigabyte",
    "start": "1144960",
    "end": "1147600"
  },
  {
    "text": "two gigabytes",
    "start": "1147600",
    "end": "1148640"
  },
  {
    "text": "and then i want to basically run a",
    "start": "1148640",
    "end": "1149919"
  },
  {
    "text": "combination of all of those things",
    "start": "1149919",
    "end": "1151840"
  },
  {
    "text": "same with the duration i want to run it",
    "start": "1151840",
    "end": "1153360"
  },
  {
    "text": "for 10 seconds two hours five hours",
    "start": "1153360",
    "end": "1156240"
  },
  {
    "text": "whatever",
    "start": "1156240",
    "end": "1157039"
  },
  {
    "text": "and the benefit of this we covered the",
    "start": "1157039",
    "end": "1159440"
  },
  {
    "text": "workflow aspect",
    "start": "1159440",
    "end": "1160720"
  },
  {
    "text": "now we can cover the reusability aspect",
    "start": "1160720",
    "end": "1163520"
  },
  {
    "start": "1161000",
    "end": "1350000"
  },
  {
    "text": "so i i",
    "start": "1163520",
    "end": "1164000"
  },
  {
    "text": "mentioned that we're creating a reusable",
    "start": "1164000",
    "end": "1166320"
  },
  {
    "text": "argo workflow",
    "start": "1166320",
    "end": "1167440"
  },
  {
    "text": "we can actually leverage uh the helm uh",
    "start": "1167440",
    "end": "1170559"
  },
  {
    "text": "templating um cncf tool",
    "start": "1170559",
    "end": "1173600"
  },
  {
    "text": "uh to create our own sort of like",
    "start": "1173600",
    "end": "1175600"
  },
  {
    "text": "reusable component that will allow us to",
    "start": "1175600",
    "end": "1177360"
  },
  {
    "text": "actually provide",
    "start": "1177360",
    "end": "1178720"
  },
  {
    "text": "the the the the the values that we want",
    "start": "1178720",
    "end": "1181360"
  },
  {
    "text": "to reuse and in this case you know we",
    "start": "1181360",
    "end": "1182799"
  },
  {
    "text": "just use one value",
    "start": "1182799",
    "end": "1184080"
  },
  {
    "text": "uh which is you know number of replicas",
    "start": "1184080",
    "end": "1185760"
  },
  {
    "text": "server workers so i basically just would",
    "start": "1185760",
    "end": "1187520"
  },
  {
    "text": "run",
    "start": "1187520",
    "end": "1188160"
  },
  {
    "text": "these ones um across all of these",
    "start": "1188160",
    "end": "1190960"
  },
  {
    "text": "different options",
    "start": "1190960",
    "end": "1192320"
  },
  {
    "text": "now from that same perspective and we",
    "start": "1192320",
    "end": "1194000"
  },
  {
    "text": "can pass basically the data which in",
    "start": "1194000",
    "end": "1195440"
  },
  {
    "text": "this case",
    "start": "1195440",
    "end": "1196080"
  },
  {
    "text": "it's just showing some dummy data to",
    "start": "1196080",
    "end": "1197760"
  },
  {
    "text": "actually make sure that it fits within",
    "start": "1197760",
    "end": "1199840"
  },
  {
    "text": "within the screen",
    "start": "1199840",
    "end": "1200799"
  },
  {
    "text": "but what this basically would do is we",
    "start": "1200799",
    "end": "1202400"
  },
  {
    "text": "would be able to just run this",
    "start": "1202400",
    "end": "1203840"
  },
  {
    "text": "it would deploy on the kubernetes",
    "start": "1203840",
    "end": "1205440"
  },
  {
    "text": "cluster it would actually run",
    "start": "1205440",
    "end": "1207200"
  },
  {
    "text": "in this case only once graduation of 30",
    "start": "1207200",
    "end": "1209679"
  },
  {
    "text": "seconds",
    "start": "1209679",
    "end": "1210400"
  },
  {
    "text": "and then we would be able to retrieve",
    "start": "1210400",
    "end": "1212400"
  },
  {
    "text": "the output",
    "start": "1212400",
    "end": "1213440"
  },
  {
    "text": "with the argo logs so it would as you",
    "start": "1213440",
    "end": "1215840"
  },
  {
    "text": "saw it would actually print",
    "start": "1215840",
    "end": "1217280"
  },
  {
    "text": "the output in this case with digital",
    "start": "1217280",
    "end": "1218960"
  },
  {
    "text": "report json in this case with json",
    "start": "1218960",
    "end": "1221440"
  },
  {
    "text": "query uh that you know we will be able",
    "start": "1221440",
    "end": "1223440"
  },
  {
    "text": "to retrieve um you will see why we're",
    "start": "1223440",
    "end": "1225520"
  },
  {
    "text": "doing that",
    "start": "1225520",
    "end": "1226159"
  },
  {
    "text": "when we analyze the results but here uh",
    "start": "1226159",
    "end": "1228960"
  },
  {
    "text": "the key thing to",
    "start": "1228960",
    "end": "1229840"
  },
  {
    "text": "to to to to to see is that we now are",
    "start": "1229840",
    "end": "1233360"
  },
  {
    "text": "able to leverage",
    "start": "1233360",
    "end": "1234880"
  },
  {
    "text": "a component that is possible to",
    "start": "1234880",
    "end": "1237919"
  },
  {
    "text": "save us a lot of time instead of",
    "start": "1237919",
    "end": "1239760"
  },
  {
    "text": "actually us having to run",
    "start": "1239760",
    "end": "1242159"
  },
  {
    "text": "of course for starters our model locally",
    "start": "1242159",
    "end": "1245679"
  },
  {
    "text": "with a benchmarking and instead of also",
    "start": "1245679",
    "end": "1248080"
  },
  {
    "text": "also us",
    "start": "1248080",
    "end": "1248880"
  },
  {
    "text": "deploying the model and running for",
    "start": "1248880",
    "end": "1250400"
  },
  {
    "text": "example vegeta or ghz locally against",
    "start": "1250400",
    "end": "1253520"
  },
  {
    "text": "that",
    "start": "1253520",
    "end": "1254000"
  },
  {
    "text": "and waiting 30 minutes and then maybe",
    "start": "1254000",
    "end": "1256159"
  },
  {
    "text": "coming back and realizing that your",
    "start": "1256159",
    "end": "1258480"
  },
  {
    "text": "you know computer had to restart or",
    "start": "1258480",
    "end": "1259919"
  },
  {
    "text": "something for some weird reason um",
    "start": "1259919",
    "end": "1262400"
  },
  {
    "text": "you know instead of doing that we're not",
    "start": "1262400",
    "end": "1264880"
  },
  {
    "text": "only deploying this and allowing that to",
    "start": "1264880",
    "end": "1267120"
  },
  {
    "text": "actually be fulfilled",
    "start": "1267120",
    "end": "1268320"
  },
  {
    "text": "remotely in the cluster but we're also",
    "start": "1268320",
    "end": "1270720"
  },
  {
    "text": "able to perform some sort of more",
    "start": "1270720",
    "end": "1272559"
  },
  {
    "text": "complex grid search across the values",
    "start": "1272559",
    "end": "1275120"
  },
  {
    "text": "for the benchmarking to be able to",
    "start": "1275120",
    "end": "1276799"
  },
  {
    "text": "understand what are potentially the",
    "start": "1276799",
    "end": "1278799"
  },
  {
    "text": "optimal",
    "start": "1278799",
    "end": "1279679"
  },
  {
    "text": "configurations for that model that is",
    "start": "1279679",
    "end": "1282080"
  },
  {
    "text": "being deployed in an automated manner",
    "start": "1282080",
    "end": "1284320"
  },
  {
    "text": "and this is important because you know",
    "start": "1284320",
    "end": "1286000"
  },
  {
    "text": "in the context of seldom core",
    "start": "1286000",
    "end": "1287760"
  },
  {
    "text": "the the the core principle that we built",
    "start": "1287760",
    "end": "1290320"
  },
  {
    "text": "against",
    "start": "1290320",
    "end": "1291120"
  },
  {
    "text": "is the context of thousands of models",
    "start": "1291120",
    "end": "1293760"
  },
  {
    "text": "and",
    "start": "1293760",
    "end": "1294159"
  },
  {
    "text": "you know in that case you have the",
    "start": "1294159",
    "end": "1295760"
  },
  {
    "text": "distributed systems concept of pet",
    "start": "1295760",
    "end": "1297679"
  },
  {
    "text": "versus cattle",
    "start": "1297679",
    "end": "1298720"
  },
  {
    "text": "right you can't have every single model",
    "start": "1298720",
    "end": "1301120"
  },
  {
    "text": "being um",
    "start": "1301120",
    "end": "1302640"
  },
  {
    "text": "you know looked after with with a",
    "start": "1302640",
    "end": "1304720"
  },
  {
    "text": "particular set of like best practices",
    "start": "1304720",
    "end": "1306720"
  },
  {
    "text": "and uh a a a data scientist that is like",
    "start": "1306720",
    "end": "1310000"
  },
  {
    "text": "always kind of like you know doing",
    "start": "1310000",
    "end": "1311600"
  },
  {
    "text": "maintenance across it because if you",
    "start": "1311600",
    "end": "1313280"
  },
  {
    "text": "have a thousand models",
    "start": "1313280",
    "end": "1314880"
  },
  {
    "text": "those complexities need to be managed at",
    "start": "1314880",
    "end": "1316960"
  },
  {
    "text": "scale and there",
    "start": "1316960",
    "end": "1318000"
  },
  {
    "text": "needs to be a standardized set of",
    "start": "1318000",
    "end": "1320240"
  },
  {
    "text": "interfaces and",
    "start": "1320240",
    "end": "1321520"
  },
  {
    "text": "best practices that can be leveraged in",
    "start": "1321520",
    "end": "1323200"
  },
  {
    "text": "order for you to be able to take into",
    "start": "1323200",
    "end": "1324799"
  },
  {
    "text": "advantage",
    "start": "1324799",
    "end": "1325760"
  },
  {
    "text": "you know things like this like",
    "start": "1325760",
    "end": "1326720"
  },
  {
    "text": "performance evaluation so you may want",
    "start": "1326720",
    "end": "1328559"
  },
  {
    "text": "to actually even start automating as we",
    "start": "1328559",
    "end": "1330400"
  },
  {
    "text": "have been doing in terms of like",
    "start": "1330400",
    "end": "1331679"
  },
  {
    "text": "internal research at southern core",
    "start": "1331679",
    "end": "1333600"
  },
  {
    "text": "exploring ways in how we can automate",
    "start": "1333600",
    "end": "1335760"
  },
  {
    "text": "these components",
    "start": "1335760",
    "end": "1336720"
  },
  {
    "text": "using the cloud native best practices",
    "start": "1336720",
    "end": "1338880"
  },
  {
    "text": "and of course more specifically best",
    "start": "1338880",
    "end": "1340480"
  },
  {
    "text": "practices of microservice",
    "start": "1340480",
    "end": "1342159"
  },
  {
    "text": "microservices that can be brought in and",
    "start": "1342159",
    "end": "1344559"
  },
  {
    "text": "adopted for the machine learning",
    "start": "1344559",
    "end": "1346480"
  },
  {
    "text": "operation space so you can see the value",
    "start": "1346480",
    "end": "1348960"
  },
  {
    "text": "of some of these things here",
    "start": "1348960",
    "end": "1350480"
  },
  {
    "start": "1350000",
    "end": "1385000"
  },
  {
    "text": "now the reason why i was mentioning the",
    "start": "1350480",
    "end": "1352320"
  },
  {
    "text": "printing of the output is because now",
    "start": "1352320",
    "end": "1353919"
  },
  {
    "text": "we're able to actually fetch that",
    "start": "1353919",
    "end": "1355520"
  },
  {
    "text": "output the json output that comes from",
    "start": "1355520",
    "end": "1358159"
  },
  {
    "text": "what has been printed",
    "start": "1358159",
    "end": "1359520"
  },
  {
    "text": "and be able to actually see the results",
    "start": "1359520",
    "end": "1362320"
  },
  {
    "text": "we can actually see the grid search over",
    "start": "1362320",
    "end": "1364159"
  },
  {
    "text": "here you know the",
    "start": "1364159",
    "end": "1365120"
  },
  {
    "text": "the number of replicas server workers",
    "start": "1365120",
    "end": "1367120"
  },
  {
    "text": "threats",
    "start": "1367120",
    "end": "1368320"
  },
  {
    "text": "cpus max workers and then the",
    "start": "1368320",
    "end": "1371440"
  },
  {
    "text": "actual results they mean percentiles",
    "start": "1371440",
    "end": "1375919"
  },
  {
    "text": "etc etc the rate throughput of",
    "start": "1375919",
    "end": "1379120"
  },
  {
    "text": "every single sort of output and you can",
    "start": "1379120",
    "end": "1381440"
  },
  {
    "text": "see that now we can do very interesting",
    "start": "1381440",
    "end": "1383360"
  },
  {
    "text": "analysis from this",
    "start": "1383360",
    "end": "1384559"
  },
  {
    "text": "perspective we can actually evaluate the",
    "start": "1384559",
    "end": "1386799"
  },
  {
    "text": "results using uh",
    "start": "1386799",
    "end": "1388480"
  },
  {
    "text": "you know in this case uh the pandas data",
    "start": "1388480",
    "end": "1390720"
  },
  {
    "text": "frame we can actually see",
    "start": "1390720",
    "end": "1392400"
  },
  {
    "text": "only the rest requests and sort them by",
    "start": "1392400",
    "end": "1395600"
  },
  {
    "text": "the rates",
    "start": "1395600",
    "end": "1396320"
  },
  {
    "text": "and we can actually see what are the",
    "start": "1396320",
    "end": "1398159"
  },
  {
    "text": "configurations that allow",
    "start": "1398159",
    "end": "1399600"
  },
  {
    "text": "us to achieve the the the biggest rate",
    "start": "1399600",
    "end": "1402400"
  },
  {
    "text": "or not the biggest rate",
    "start": "1402400",
    "end": "1403440"
  },
  {
    "text": "the highest rate um in this case we can",
    "start": "1403440",
    "end": "1405840"
  },
  {
    "text": "see that you know",
    "start": "1405840",
    "end": "1406720"
  },
  {
    "text": "with of course three replicas uh you",
    "start": "1406720",
    "end": "1409200"
  },
  {
    "text": "know but here we can actually see other",
    "start": "1409200",
    "end": "1411200"
  },
  {
    "text": "interesting things you can actually see",
    "start": "1411200",
    "end": "1413120"
  },
  {
    "text": "uh the relationship between in the",
    "start": "1413120",
    "end": "1414880"
  },
  {
    "text": "context of python based servers",
    "start": "1414880",
    "end": "1417760"
  },
  {
    "text": "uh threads versus workers as well as the",
    "start": "1417760",
    "end": "1420640"
  },
  {
    "text": "cpus",
    "start": "1420640",
    "end": "1421440"
  },
  {
    "text": "and on the replicas and you can actually",
    "start": "1421440",
    "end": "1423919"
  },
  {
    "text": "try to see some some",
    "start": "1423919",
    "end": "1425120"
  },
  {
    "text": "um some trends in your your specific",
    "start": "1425120",
    "end": "1428080"
  },
  {
    "text": "models",
    "start": "1428080",
    "end": "1428960"
  },
  {
    "text": "uh unfortunately every model may have",
    "start": "1428960",
    "end": "1431279"
  },
  {
    "text": "not every model but",
    "start": "1431279",
    "end": "1432400"
  },
  {
    "text": "but there will be potential vast",
    "start": "1432400",
    "end": "1434480"
  },
  {
    "text": "variation",
    "start": "1434480",
    "end": "1435440"
  },
  {
    "text": "that's variation between model to model",
    "start": "1435440",
    "end": "1437600"
  },
  {
    "text": "when it comes to the the parameters that",
    "start": "1437600",
    "end": "1439360"
  },
  {
    "text": "would make",
    "start": "1439360",
    "end": "1440000"
  },
  {
    "text": "it perform better and this is why it's",
    "start": "1440000",
    "end": "1442240"
  },
  {
    "text": "it's so important to have tools like",
    "start": "1442240",
    "end": "1444000"
  },
  {
    "text": "this in your in your toolbox",
    "start": "1444000",
    "end": "1446000"
  },
  {
    "text": "to be able to leverage uh and use those",
    "start": "1446000",
    "end": "1448000"
  },
  {
    "text": "best practices",
    "start": "1448000",
    "end": "1449440"
  },
  {
    "start": "1449000",
    "end": "1497000"
  },
  {
    "text": "so if you're curious you can actually",
    "start": "1449440",
    "end": "1451679"
  },
  {
    "text": "try all of the things that we covered",
    "start": "1451679",
    "end": "1453360"
  },
  {
    "text": "here",
    "start": "1453360",
    "end": "1454080"
  },
  {
    "text": "end to end uh on a jupiter notebook all",
    "start": "1454080",
    "end": "1456720"
  },
  {
    "text": "of these things are open source",
    "start": "1456720",
    "end": "1458799"
  },
  {
    "text": "which is which is great and you can",
    "start": "1458799",
    "end": "1460320"
  },
  {
    "text": "actually find it on the main repo which",
    "start": "1460320",
    "end": "1462000"
  },
  {
    "text": "is",
    "start": "1462000",
    "end": "1462480"
  },
  {
    "text": "hub.com seldonio solvencor right and",
    "start": "1462480",
    "end": "1465840"
  },
  {
    "text": "here the documentation",
    "start": "1465840",
    "end": "1467200"
  },
  {
    "text": "has examples not just about this",
    "start": "1467200",
    "end": "1469200"
  },
  {
    "text": "benchmarking",
    "start": "1469200",
    "end": "1470240"
  },
  {
    "text": "automation with argo workflows we can",
    "start": "1470240",
    "end": "1472240"
  },
  {
    "text": "also find a you know",
    "start": "1472240",
    "end": "1473520"
  },
  {
    "text": "vast amount of different resources that",
    "start": "1473520",
    "end": "1475279"
  },
  {
    "text": "will allow you to delve into",
    "start": "1475279",
    "end": "1477039"
  },
  {
    "text": "you know from the very basic deployment",
    "start": "1477039",
    "end": "1478799"
  },
  {
    "text": "of models to the more advanced",
    "start": "1478799",
    "end": "1480720"
  },
  {
    "text": "uh you know integration with with other",
    "start": "1480720",
    "end": "1483600"
  },
  {
    "text": "type of batch systems or",
    "start": "1483600",
    "end": "1485520"
  },
  {
    "text": "or or you know integration with",
    "start": "1485520",
    "end": "1487039"
  },
  {
    "text": "streaming using kafka et cetera et",
    "start": "1487039",
    "end": "1489279"
  },
  {
    "text": "cetera i mean",
    "start": "1489279",
    "end": "1490080"
  },
  {
    "text": "explainability of live detection i mean",
    "start": "1490080",
    "end": "1492400"
  },
  {
    "text": "you name it",
    "start": "1492400",
    "end": "1493760"
  },
  {
    "text": "you'll find it there so so definitely",
    "start": "1493760",
    "end": "1495520"
  },
  {
    "text": "recommend you to do that",
    "start": "1495520",
    "end": "1496960"
  },
  {
    "text": "and with that today we've covered a",
    "start": "1496960",
    "end": "1499120"
  },
  {
    "start": "1497000",
    "end": "1551000"
  },
  {
    "text": "broad range of different",
    "start": "1499120",
    "end": "1500559"
  },
  {
    "text": "very interesting concepts we've",
    "start": "1500559",
    "end": "1502640"
  },
  {
    "text": "developed into the motivations",
    "start": "1502640",
    "end": "1504240"
  },
  {
    "text": "uh for this topic of automated",
    "start": "1504240",
    "end": "1506320"
  },
  {
    "text": "benchmarking and performance evaluation",
    "start": "1506320",
    "end": "1508400"
  },
  {
    "text": "uh we've performed uh some deployment of",
    "start": "1508400",
    "end": "1510799"
  },
  {
    "text": "our simple model",
    "start": "1510799",
    "end": "1512000"
  },
  {
    "text": "as well as an initial benchmark from our",
    "start": "1512000",
    "end": "1514480"
  },
  {
    "text": "you know local computer",
    "start": "1514480",
    "end": "1515840"
  },
  {
    "text": "uh then we talked about how we're able",
    "start": "1515840",
    "end": "1518240"
  },
  {
    "text": "to",
    "start": "1518240",
    "end": "1518880"
  },
  {
    "text": "uh not just automate but also uh scale",
    "start": "1518880",
    "end": "1522000"
  },
  {
    "text": "uh this capability using workflow",
    "start": "1522000",
    "end": "1523840"
  },
  {
    "text": "managers as well as covering an example",
    "start": "1523840",
    "end": "1526400"
  },
  {
    "text": "using a reusable uh",
    "start": "1526400",
    "end": "1528320"
  },
  {
    "text": "workflow to be able to perform",
    "start": "1528320",
    "end": "1530320"
  },
  {
    "text": "evaluation across a grid search of",
    "start": "1530320",
    "end": "1532159"
  },
  {
    "text": "parameters",
    "start": "1532159",
    "end": "1533039"
  },
  {
    "text": "to identify the optimal configuration of",
    "start": "1533039",
    "end": "1535840"
  },
  {
    "text": "particular modes",
    "start": "1535840",
    "end": "1537200"
  },
  {
    "text": "so with that uh thank you very much uh",
    "start": "1537200",
    "end": "1539840"
  },
  {
    "text": "for joining my talk",
    "start": "1539840",
    "end": "1541279"
  },
  {
    "text": "and uh yeah if you have any questions uh",
    "start": "1541279",
    "end": "1543440"
  },
  {
    "text": "please don't feel free",
    "start": "1543440",
    "end": "1544960"
  },
  {
    "text": "to reach out either throughout the",
    "start": "1544960",
    "end": "1546799"
  },
  {
    "text": "conference or afterwards",
    "start": "1546799",
    "end": "1548559"
  },
  {
    "text": "so yeah thank you very much and see you",
    "start": "1548559",
    "end": "1550799"
  },
  {
    "text": "around",
    "start": "1550799",
    "end": "1553760"
  }
]
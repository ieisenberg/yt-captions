[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "hello everyone um my name is lauren vernae and i'm very happy to to be here today",
    "start": "80",
    "end": "6640"
  },
  {
    "text": "and to virtually present this talk about kubernetes dns",
    "start": "6640",
    "end": "13518"
  },
  {
    "start": "15000",
    "end": "15000"
  },
  {
    "text": "so a quick introduction if you don't know datadog we're a sas based monitoring company",
    "start": "15040",
    "end": "22240"
  },
  {
    "text": "and we're not going to talk about the product today we're going to talk about the infrastructure behind the products and",
    "start": "22240",
    "end": "29279"
  },
  {
    "text": "especially the the part of this infrastructure that is running in kubernetes",
    "start": "29279",
    "end": "35440"
  },
  {
    "text": "and today we're talking about tens of thousands of hosts and dozens of communities clusters",
    "start": "35440",
    "end": "41680"
  },
  {
    "text": "that can reach up to 4 000 nodes and one of the challenges we face is we",
    "start": "41680",
    "end": "47280"
  },
  {
    "text": "run a multiple cloud provider which makes things even more interesting",
    "start": "47280",
    "end": "53600"
  },
  {
    "start": "53000",
    "end": "53000"
  },
  {
    "text": "we faced many challenges by when we moved to kubernetes and operating our",
    "start": "54320",
    "end": "59760"
  },
  {
    "text": "communities clusters and we talked about these challenges in several um conferences in the past",
    "start": "59760",
    "end": "66799"
  },
  {
    "text": "uh however today we're not going to talk about this we're going to focus on a on a subject which is dns",
    "start": "66799",
    "end": "74960"
  },
  {
    "text": "and what we didn't expect when we started working on the current platform at datadog was that dns",
    "start": "74960",
    "end": "82560"
  },
  {
    "start": "75000",
    "end": "75000"
  },
  {
    "text": "would end up being one of the most critical services we operate and as you can see on this graph which",
    "start": "82560",
    "end": "88159"
  },
  {
    "text": "shows the number of dns queries um we get in production on each cluster",
    "start": "88159",
    "end": "93200"
  },
  {
    "text": "we're currently serving 200 000 dna squares per second which is which is quite loud and challenging to do well",
    "start": "93200",
    "end": "100799"
  },
  {
    "text": "here is a quick outline of what we're going to discuss today first we're going to discuss about how",
    "start": "100799",
    "end": "106560"
  },
  {
    "start": "101000",
    "end": "101000"
  },
  {
    "text": "dns works in currencies in general then about global challenges people face",
    "start": "106560",
    "end": "112320"
  },
  {
    "text": "usually when they run dns and kubernetes then i'll share some fun stories",
    "start": "112320",
    "end": "118159"
  },
  {
    "text": "depending on your definition of fun about dns and finally i'd end with what",
    "start": "118159",
    "end": "123439"
  },
  {
    "text": "we do now so the genetic in kubernetes so here is",
    "start": "123439",
    "end": "129280"
  },
  {
    "text": "how it works um so when you start a bird the cubette is going to inject",
    "start": "129280",
    "end": "135520"
  },
  {
    "start": "130000",
    "end": "130000"
  },
  {
    "text": "the dns configuration inside the containers and the way the bit will do that will do this is based",
    "start": "135520",
    "end": "141200"
  },
  {
    "text": "on its configuration where you give it the gns service to to use to to to give",
    "start": "141200",
    "end": "149120"
  },
  {
    "text": "containers dns access and this will translate into a resolve.com file inside containers",
    "start": "149120",
    "end": "155920"
  },
  {
    "text": "with a list of search domain which makes discovering services in the cluster and outside easy",
    "start": "155920",
    "end": "161760"
  },
  {
    "text": "and of course the name server to use when the container wants to access dns",
    "start": "161760",
    "end": "168959"
  },
  {
    "start": "167000",
    "end": "167000"
  },
  {
    "text": "it's going to send a query to the dns service in the cluster and the proxy you use",
    "start": "168959",
    "end": "174319"
  },
  {
    "text": "whether it's iptables on ipvs is going to load balance these queries to dns pods which can",
    "start": "174319",
    "end": "181120"
  },
  {
    "text": "either run cube dns or called dns and these dns servers are going to do",
    "start": "181120",
    "end": "187360"
  },
  {
    "text": "two things the first one is they're going to be authority for the clusters or for the cluster domain and also they're",
    "start": "187360",
    "end": "195200"
  },
  {
    "text": "going to forward queries for to a nutrition provider for any domain they don't know about",
    "start": "195200",
    "end": "202640"
  },
  {
    "start": "203000",
    "end": "203000"
  },
  {
    "text": "so in theory here is how it works so imagine a bird named space matrix requesting the service points that is",
    "start": "203360",
    "end": "210159"
  },
  {
    "text": "also running in namespace metrics so if you just look at points um",
    "start": "210159",
    "end": "216959"
  },
  {
    "text": "your resolver is going to see that points are less than five dots so it's going to use you the first",
    "start": "216959",
    "end": "222560"
  },
  {
    "text": "search domain and query four points of matrix and get an answer back from the dns pod",
    "start": "222560",
    "end": "230319"
  },
  {
    "text": "so simple and efficient right in theory also if you're a part in the",
    "start": "230319",
    "end": "237280"
  },
  {
    "text": "log logs namespace this time accessing service points in another namespace metrics",
    "start": "237280",
    "end": "242879"
  },
  {
    "text": "then of course you need to specify the namespace your the service you're looking for is located in in here you're looking for",
    "start": "242879",
    "end": "250400"
  },
  {
    "text": "points.metrics so once again points.matrix as less than five dots",
    "start": "250400",
    "end": "255439"
  },
  {
    "text": "and we're going to try with the first search domain and as you can see it doesn't really make sense because it's going to start with points.metrics",
    "start": "255439",
    "end": "262400"
  },
  {
    "text": "at logs which doesn't exist so the first answer from the dns code is going to be nx domain",
    "start": "262400",
    "end": "268560"
  },
  {
    "text": "because it doesn't exist the resolver is going to continue and this time queries for",
    "start": "268560",
    "end": "274000"
  },
  {
    "text": "points that metrics that serve is that personal local by using the second search domain and get an answer so less efficient this",
    "start": "274000",
    "end": "280080"
  },
  {
    "text": "time because we did two queries but so it's pretty straightforward",
    "start": "280080",
    "end": "285600"
  },
  {
    "text": "let's talk about challenges now so you remember what i showed for the series before let's see",
    "start": "286160",
    "end": "292960"
  },
  {
    "text": "what it looks like in practice by capturing traffic from a dns query so this example is taken from a",
    "start": "292960",
    "end": "300320"
  },
  {
    "start": "299000",
    "end": "299000"
  },
  {
    "text": "gke instance and in that case i'm in the default namespace and i'm looking for",
    "start": "300320",
    "end": "306520"
  },
  {
    "text": "www.google.com and as you can see here we're not seeing two queries we're actually we're actually seeing 12 queries and the",
    "start": "306520",
    "end": "314240"
  },
  {
    "text": "reason for this is well where we have five search domains three for the clusters and two inherited",
    "start": "314240",
    "end": "321039"
  },
  {
    "text": "from google and also something that's a bit surprising that that wasn't in my theory",
    "start": "321039",
    "end": "326479"
  },
  {
    "text": "examples is ipv6 queries so we get twice the number of queries because of ipx6",
    "start": "326479",
    "end": "332880"
  },
  {
    "text": "this leads to several problems the first one is latency of course because if you're acquiring this you're going to make 12 queries which is going to take",
    "start": "332880",
    "end": "339280"
  },
  {
    "text": "longer and also if any of this packet is lost",
    "start": "339280",
    "end": "344400"
  },
  {
    "text": "your resolver is going to retry but it's going to wait for 5 seconds because the default dns timeout is 5 seconds",
    "start": "344400",
    "end": "349840"
  },
  {
    "text": "in index and finally of course i mean we're imagining the dns emperor and we",
    "start": "349840",
    "end": "355199"
  },
  {
    "text": "care about uh having as few query as we can because it loads it stresses the dns in front so",
    "start": "355199",
    "end": "366160"
  },
  {
    "text": "let's talk about resolvers now why do we get ipv6 queries um so",
    "start": "366160",
    "end": "374240"
  },
  {
    "text": "the default uh posix method to query for dns is get addr info and it should do ipv4",
    "start": "374240",
    "end": "380639"
  },
  {
    "text": "and ipv6 by default so the good thing is you're ready for mpd6 the bad is well",
    "start": "380639",
    "end": "386000"
  },
  {
    "text": "not great because you're getting twice the traffic right but there's also the ugly part which is",
    "start": "386000",
    "end": "392560"
  },
  {
    "text": "something that most of you may have heard about uh in the past which is that uh there's",
    "start": "392560",
    "end": "398479"
  },
  {
    "text": "a race condition in that filter with which will trigger packet losses if you do an ipv4 and an fpg six",
    "start": "398479",
    "end": "405120"
  },
  {
    "text": "in a very short time and this was patched but this issue has",
    "start": "405120",
    "end": "410639"
  },
  {
    "text": "been there for quite a while and has been painful for many uses because of course if one of the two packets is lost the",
    "start": "410639",
    "end": "416720"
  },
  {
    "text": "resolver is gonna wait for five seconds before it's drying depending on the proxy you use it's",
    "start": "416720",
    "end": "423919"
  },
  {
    "text": "going to be it's going to be impactful than the difference it's slightly better with ipvs but it's still not perfect",
    "start": "423919",
    "end": "431039"
  },
  {
    "text": "so we had this very nice idea at the time which is well let's disable ipv6 right so we disable ip6 in the",
    "start": "431520",
    "end": "437520"
  },
  {
    "start": "432000",
    "end": "432000"
  },
  {
    "text": "channel and we just uh did a very simple resolution for google.com",
    "start": "437520",
    "end": "442560"
  },
  {
    "text": "and you can see that in in this example we do five queries and we're not doing any ipv6 so that's pretty good right",
    "start": "442560",
    "end": "450240"
  },
  {
    "text": "we wanted to celebrate at that time but look after every interactive v6 has been",
    "start": "450240",
    "end": "456000"
  },
  {
    "text": "disabled on every host we're still getting a lot of fpg6 queries so we're a bit sad and we're",
    "start": "456000",
    "end": "462720"
  },
  {
    "text": "trying to understand what was happening so what triggers igd6 so as i was saying",
    "start": "462720",
    "end": "469039"
  },
  {
    "start": "466000",
    "end": "466000"
  },
  {
    "text": "before according to posix you should be getting ipv4 native six queries",
    "start": "469039",
    "end": "474479"
  },
  {
    "text": "however the gdp implementation in linux is using hints that are notes that it's",
    "start": "474479",
    "end": "481120"
  },
  {
    "text": "not supposed to use in the posix uh in the project but it's doing it because it's helpful",
    "start": "481120",
    "end": "486160"
  },
  {
    "text": "and one of the hints used by tbc is is ai addr info which is only",
    "start": "486160",
    "end": "493120"
  },
  {
    "text": "making ipv6 queries if it finds an ipv6 address so well of course since we disabled that",
    "start": "493120",
    "end": "499520"
  },
  {
    "text": "m6 in the kernel we shouldn't have any ipv6 addresses so designing that uses in the kernel should",
    "start": "499520",
    "end": "504800"
  },
  {
    "text": "just work but as we sew it doesn't so that's that's weird so we we continued digging and and the",
    "start": "504800",
    "end": "513440"
  },
  {
    "text": "thing we found is that well we're not only running ubuntu and gbc we're also running some alpine",
    "start": "513440",
    "end": "518880"
  },
  {
    "text": "containers that are using bezel as your lipstick provider and well",
    "start": "518880",
    "end": "524240"
  },
  {
    "text": "look at this when you do this very simple query on an ubuntu based image and an alpine based image in one case you get",
    "start": "524240",
    "end": "531040"
  },
  {
    "text": "on the ipv4 and in the second case you get ipd for an ipv6 and the reason is well mother actually",
    "start": "531040",
    "end": "537440"
  },
  {
    "text": "implements the project specification exactly and not the helpful hint that gbt provides",
    "start": "537440",
    "end": "543600"
  },
  {
    "text": "so that explains part of it however we don't use alpine that much so that can't explain why sort of our",
    "start": "543600",
    "end": "549519"
  },
  {
    "text": "traffic is ipv6 right we use go a lot and so at one point",
    "start": "549519",
    "end": "556880"
  },
  {
    "start": "554000",
    "end": "554000"
  },
  {
    "text": "we looked at go applications and to see how they were behaving and if you use this very simple uh",
    "start": "556880",
    "end": "562320"
  },
  {
    "text": "resolution command go well you can see that we're getting ipv6 queries again",
    "start": "562320",
    "end": "568320"
  },
  {
    "text": "and even on ubuntu uh so that's that's really right because it's but not to do that",
    "start": "568320",
    "end": "575519"
  },
  {
    "text": "so as you may know uh go implements two uh two ways to do tns you can have either",
    "start": "575519",
    "end": "581519"
  },
  {
    "text": "navy go or you see go so so we figured well let's use c go so in in which case we will false go uh",
    "start": "581519",
    "end": "589279"
  },
  {
    "text": "to use gbmc and then it's native implementation and as you can see here even when we use",
    "start": "589279",
    "end": "594880"
  },
  {
    "text": "seago we're also getting an ipv6 query things are getting very weird right",
    "start": "594880",
    "end": "601600"
  },
  {
    "start": "601000",
    "end": "601000"
  },
  {
    "text": "so one of the first things we believed was that um our environment variable had been",
    "start": "602079",
    "end": "608399"
  },
  {
    "text": "ignored but if you look at the at the very small details and these two lines",
    "start": "608399",
    "end": "614079"
  },
  {
    "text": "in these two examples you'll see that it's actually different and that the results are behaving differently",
    "start": "614079",
    "end": "620480"
  },
  {
    "text": "because one is using a different source port for the ipv4 and ipv6 query so it's actually doing something but",
    "start": "620480",
    "end": "627120"
  },
  {
    "text": "it's not behaving as we expect because we'd expect gdbc based queries not to do ipv6",
    "start": "627120",
    "end": "633200"
  },
  {
    "text": "so we looked into the go source code and look at what we found",
    "start": "633200",
    "end": "640079"
  },
  {
    "start": "639000",
    "end": "639000"
  },
  {
    "text": "we found that when you use c go go is actually specifying hints and the",
    "start": "640079",
    "end": "646079"
  },
  {
    "text": "hints it specifies are different from the default tlipc ones and what is very important",
    "start": "646079",
    "end": "652399"
  },
  {
    "text": "here is addrconfig which will not do at the b6 resolution if there's no physics address",
    "start": "652399",
    "end": "658079"
  },
  {
    "text": "it's not in these hints so it's very sad because in go it means you can't easily remove hp6 query",
    "start": "658079",
    "end": "665839"
  },
  {
    "text": "and the only way i've found to do that is actually to false go to only query ipv4 by choosing tcp 4 in the example at",
    "start": "665839",
    "end": "672800"
  },
  {
    "text": "the bottom so that works bad because it would be too simple if it would just work",
    "start": "672800",
    "end": "678720"
  },
  {
    "text": "it only works when you're using sigo it doesn't work with the media computation where you will get both",
    "start": "678720",
    "end": "683920"
  },
  {
    "text": "ipv4 analytics queries so we tried uh to re to reduce the",
    "start": "683920",
    "end": "691120"
  },
  {
    "text": "number of queries by removing ipv6 queries um and it's something that everybody tried to",
    "start": "691120",
    "end": "696800"
  },
  {
    "text": "achieve uh in the comments community like trying to reduce the number of queries and made by applications and let's look",
    "start": "696800",
    "end": "703279"
  },
  {
    "text": "at other solutions so the first one is a coordinate plugin",
    "start": "703279",
    "end": "709279"
  },
  {
    "start": "706000",
    "end": "706000"
  },
  {
    "text": "which is called autopass with this option called dns",
    "start": "709279",
    "end": "714560"
  },
  {
    "text": "knows the search domain and it's going to remove the search domain from the query",
    "start": "714560",
    "end": "719680"
  },
  {
    "text": "and try and be clever based on everything it knows about the cluster and even route the query upstream if",
    "start": "719680",
    "end": "726320"
  },
  {
    "text": "what you're crying for it is not local and as you can see in this example you have a query for google.com that the",
    "start": "726320",
    "end": "733360"
  },
  {
    "text": "search domain for the cluster and autopass is answering with a cname saying well",
    "start": "733360",
    "end": "738720"
  },
  {
    "text": "you're actually looking for google.com and here is the ipv4 and the ipv6 addresses",
    "start": "738720",
    "end": "745360"
  },
  {
    "text": "so that's very clever right because you're only doing two queries now instead of 10.",
    "start": "745360",
    "end": "750959"
  },
  {
    "text": "but sadly it's it's it's not magical because to do that",
    "start": "750959",
    "end": "756000"
  },
  {
    "text": "um the codiness uh autobus implementations needs to know in which the namespace the bodies just",
    "start": "756000",
    "end": "762560"
  },
  {
    "text": "to be able to remove the first full search domain and to do that it needs to know about all the",
    "start": "762560",
    "end": "767600"
  },
  {
    "text": "parts in the cluster to match the query ip with namespace",
    "start": "767600",
    "end": "772800"
  },
  {
    "text": "and the problem is if you do that it means that coordinates will have a full view of the pods in the cluster which is",
    "start": "772800",
    "end": "778560"
  },
  {
    "text": "going to consume a lot of memory and as your cluster grow the memory requirements for codiness is going to",
    "start": "778560",
    "end": "784480"
  },
  {
    "text": "grow and it's been a bit painful for us because it's very difficult to know when you need to increase",
    "start": "784480",
    "end": "790160"
  },
  {
    "text": "the memory request of your dns funds",
    "start": "790160",
    "end": "794639"
  },
  {
    "text": "another option that people are starting to to look into seriously and that's available upstream is to use not local",
    "start": "795200",
    "end": "802800"
  },
  {
    "start": "796000",
    "end": "796000"
  },
  {
    "text": "dns so it's actually a very simple idea where you run a local dns cache and",
    "start": "802800",
    "end": "810240"
  },
  {
    "text": "on every node as a demon set and have all your containers queries",
    "start": "810240",
    "end": "815360"
  },
  {
    "text": "this local dns and the good thing is well you have a local cache",
    "start": "815360",
    "end": "820480"
  },
  {
    "text": "and queries are then forwarded upstream to the dns pods",
    "start": "820480",
    "end": "825519"
  },
  {
    "text": "so it's it's very efficient uh because um you're not doing any udp queries and you",
    "start": "825519",
    "end": "833920"
  },
  {
    "text": "remember from before that udp queries were triggering this contract issue that wasn't great and also what you can do",
    "start": "833920",
    "end": "840880"
  },
  {
    "text": "is you can bypass the dns service for any non-communities domain which means",
    "start": "840880",
    "end": "847680"
  },
  {
    "text": "you reduce the load very a lot on your online assembly which is which is good news",
    "start": "847680",
    "end": "856240"
  },
  {
    "text": "another challenges we we found and i mean of course sometimes you need to",
    "start": "856240",
    "end": "861440"
  },
  {
    "text": "update your dns spots right because you change the configuration or you change the version of the of the",
    "start": "861440",
    "end": "867519"
  },
  {
    "text": "image so you need to do that and it wasn't as easy as we believed it",
    "start": "867519",
    "end": "872720"
  },
  {
    "text": "would be so imagine this initial state where a",
    "start": "872720",
    "end": "878160"
  },
  {
    "start": "875000",
    "end": "875000"
  },
  {
    "text": "container is trying to access a dns pod and in this example i'm going to use ipvs because this is what we want",
    "start": "878160",
    "end": "884079"
  },
  {
    "text": "and what we know about the most so when the police the container is going to make this query is",
    "start": "884079",
    "end": "890399"
  },
  {
    "text": "going to create the service ip vp in my example and ipvs is going to translate this ip",
    "start": "890399",
    "end": "896399"
  },
  {
    "text": "to a pod ip and of course to make sure that next the following packets are going to use the same connections it's going to create an ipvs contract",
    "start": "896399",
    "end": "903600"
  },
  {
    "text": "entry which i displayed at the bottom there so imagine now that",
    "start": "903600",
    "end": "909360"
  },
  {
    "start": "908000",
    "end": "908000"
  },
  {
    "text": "part a is deleted because you're starting a running update for instance or you're just reducing the size of your",
    "start": "909360",
    "end": "914959"
  },
  {
    "text": "deployments well any new query is now going to be routed to a new board right so this is my",
    "start": "914959",
    "end": "920240"
  },
  {
    "text": "second example here where the second query is sent to part b so everything looks good right",
    "start": "920240",
    "end": "926800"
  },
  {
    "text": "however what happens if a new query is using the same source port well",
    "start": "926800",
    "end": "932959"
  },
  {
    "start": "928000",
    "end": "928000"
  },
  {
    "text": "what's going to happen is the entry still exists in the ipgs contract and so it could be routed to the backend",
    "start": "932959",
    "end": "939680"
  },
  {
    "text": "that has been deleted and since the kernel knows that this backend doesn't exist it's going to drop",
    "start": "939680",
    "end": "945040"
  },
  {
    "text": "it silently and it's not a problem for most applications",
    "start": "945040",
    "end": "950639"
  },
  {
    "text": "except when you do a lot of queries which would happen sometimes so we worked with the cubeproxy team to",
    "start": "950639",
    "end": "957360"
  },
  {
    "text": "make to make this better and the first thing we did was uh set the system tunable which is",
    "start": "957360",
    "end": "963199"
  },
  {
    "start": "958000",
    "end": "958000"
  },
  {
    "text": "expired noddexcon which will expire entries in the contract",
    "start": "963199",
    "end": "968399"
  },
  {
    "text": "when a new packet is sent to a packet that has been edited so what happens from the query or",
    "start": "968399",
    "end": "975360"
  },
  {
    "text": "perspective is you send a query and since the packet doesn't exist the contract will be",
    "start": "975360",
    "end": "980720"
  },
  {
    "text": "garbage collected which is good and you're going to be notified by getting an icmp error message",
    "start": "980720",
    "end": "986399"
  },
  {
    "text": "so it's better because entries are going to be expired much faster but also you're still getting errors so",
    "start": "986399",
    "end": "992560"
  },
  {
    "text": "not great because under load this can trigger a lot of errors",
    "start": "992560",
    "end": "997839"
  },
  {
    "text": "so what you can also do is reduce the udp timeout for the ipvs contract",
    "start": "998639",
    "end": "1005120"
  },
  {
    "text": "by default it's set to five minutes which is a very long time and this is you can now configure this",
    "start": "1005120",
    "end": "1011440"
  },
  {
    "text": "in keep starting with your proxy 118 and plus uh and in our case we now set it to",
    "start": "1011440",
    "end": "1017040"
  },
  {
    "text": "30 seconds which is which is better because your entry is going to expire much faster and this means that the likelihood of",
    "start": "1017040",
    "end": "1023519"
  },
  {
    "text": "getting a port collision is going to be much lower so of course we still get some errors that",
    "start": "1023519",
    "end": "1029600"
  },
  {
    "text": "are less and there's also very good news in the way um andrew who is",
    "start": "1029600",
    "end": "1036319"
  },
  {
    "text": "another proxy maintainer actually did a kernel patch to expire entry uh in the contract when",
    "start": "1036319",
    "end": "1043120"
  },
  {
    "text": "the backend is deleted directly to avoid waiting for the next packet and avoid getting an error so that's very",
    "start": "1043120",
    "end": "1048558"
  },
  {
    "text": "good news thanks andrew so i know uh you came here for all the",
    "start": "1048559",
    "end": "1056320"
  },
  {
    "text": "fun stories uh and i mean honestly it depends on your definition of fun but",
    "start": "1056320",
    "end": "1061440"
  },
  {
    "text": "now that i can talk about them it's it's it's better so let's let's talk about that",
    "start": "1061440",
    "end": "1066799"
  },
  {
    "text": "so sometimes well we have dns issue because well your geneticism stable",
    "start": "1066799",
    "end": "1073200"
  },
  {
    "text": "and a typical example is godliness but getting getting killed",
    "start": "1073200",
    "end": "1078400"
  },
  {
    "start": "1074000",
    "end": "1074000"
  },
  {
    "text": "because they're consuming too much memory and of course it's not great for applications because well",
    "start": "1078400",
    "end": "1083520"
  },
  {
    "text": "your dns spots are getting killed and you can see the pattern on the graph it's it's",
    "start": "1083520",
    "end": "1088799"
  },
  {
    "text": "it's kind of weird right because things were stable and it suddenly like went up pretty fast so what actually",
    "start": "1088799",
    "end": "1095039"
  },
  {
    "text": "happened here is an api server was restarted and all the coordinate spots had to reconnect",
    "start": "1095039",
    "end": "1100559"
  },
  {
    "text": "and they had to build a view a full view of the cluster in their indexing the clients and to do",
    "start": "1100559",
    "end": "1106640"
  },
  {
    "text": "that they had to process all the codes and all the services because at that time we were using photopass",
    "start": "1106640",
    "end": "1112640"
  },
  {
    "text": "and at startup it turned out to require a lot more memory to do this because you have to process",
    "start": "1112640",
    "end": "1117840"
  },
  {
    "text": "everything in a few seconds and so that was uh all right that was that was hard",
    "start": "1117840",
    "end": "1125200"
  },
  {
    "text": "sometimes your dns implies completely stable but you're using auto scaling and",
    "start": "1126480",
    "end": "1133679"
  },
  {
    "text": "sometimes you'll see it works too well so we use proportional autoscaler to to decide on",
    "start": "1133679",
    "end": "1140960"
  },
  {
    "start": "1137000",
    "end": "1137000"
  },
  {
    "text": "the number of coding exports we're running and so we the number of bud is actually proportional to the size of the cluster",
    "start": "1140960",
    "end": "1148000"
  },
  {
    "text": "and so it worked completely fine uh while the cluster was only growing in size",
    "start": "1148000",
    "end": "1154000"
  },
  {
    "text": "okay but at one point well uh some applications were tr was starting to do",
    "start": "1154000",
    "end": "1159120"
  },
  {
    "text": "autoscale well and we're also scaling down and so nodes were disappearing and so-called in",
    "start": "1159120",
    "end": "1164480"
  },
  {
    "text": "the spots were removed and that was new and this triggered an interesting behavior which is well",
    "start": "1164480",
    "end": "1170080"
  },
  {
    "text": "some applications started getting dns failures when this was happening and the reason this was happening was",
    "start": "1170080",
    "end": "1175440"
  },
  {
    "text": "because of the portraiture was mentioning before for application doing a lot of queries",
    "start": "1175440",
    "end": "1181280"
  },
  {
    "text": "so auto scaling is great but sometimes you will get surprises",
    "start": "1181280",
    "end": "1186480"
  },
  {
    "text": "i mean sometimes you have dns issues but honestly it's not really your fault",
    "start": "1186880",
    "end": "1193200"
  },
  {
    "start": "1193000",
    "end": "1193000"
  },
  {
    "text": "so this one was very fright frightening for us um but luckily it only happened in",
    "start": "1193200",
    "end": "1199200"
  },
  {
    "text": "staging so this is when we started to enable autopilot from the first time",
    "start": "1199200",
    "end": "1204480"
  },
  {
    "text": "and what we did is we moved from the configuration on the left to the configuration on the right so configuration on the left has",
    "start": "1204480",
    "end": "1211039"
  },
  {
    "text": "two zones one for which coordinates is authoritative which is close to zero and the second one which is the default",
    "start": "1211039",
    "end": "1217679"
  },
  {
    "text": "zone where you're forwarding queries to the cloud resolver and when you enable autopass what you do",
    "start": "1217679",
    "end": "1224080"
  },
  {
    "text": "is everything is in the default zone and you first try the community zone and",
    "start": "1224080",
    "end": "1229200"
  },
  {
    "text": "you use other paths to do all the magic so this seems like simple and straightforward right but",
    "start": "1229200",
    "end": "1234559"
  },
  {
    "text": "this completely broke a staging cluster and well can you spot what broke it it it's actually a very small challenge",
    "start": "1234559",
    "end": "1243280"
  },
  {
    "text": "in the in the before we did the challenge we were caching queries sent to the",
    "start": "1243280",
    "end": "1249679"
  },
  {
    "text": "action provider and we didn't do it for the community zone because of course everything was already in memory so it doesn't it",
    "start": "1249679",
    "end": "1255520"
  },
  {
    "text": "didn't really matter however when we moved to other paths by",
    "start": "1255520",
    "end": "1260559"
  },
  {
    "text": "doing this configuration we actually removed caching for the upstream cloud provider dns which",
    "start": "1260559",
    "end": "1267360"
  },
  {
    "text": "means all the queries were now sent to the cloud dns resolver and well it turns out",
    "start": "1267360",
    "end": "1275200"
  },
  {
    "text": "if you've been doing dns on adwords you probably know that but there's actually a strict limit in the number of",
    "start": "1275200",
    "end": "1280720"
  },
  {
    "text": "dns queries you can do for any given network interface and the straight limit is 1000 packets",
    "start": "1280720",
    "end": "1288480"
  },
  {
    "text": "per second if you go above this aws will just drop your query so of course when reading room kept the",
    "start": "1288480",
    "end": "1294559"
  },
  {
    "text": "cache the number of queries exploded and we hit that issue and applications didn't like it",
    "start": "1294559",
    "end": "1299919"
  },
  {
    "text": "at all another thing we tried to do that",
    "start": "1299919",
    "end": "1304960"
  },
  {
    "text": "sounded like a great idea at the time was well we had issues with udp and so we decided to move to tcp",
    "start": "1304960",
    "end": "1311039"
  },
  {
    "text": "so in this very simple example we'll say well when we do it when we send and forward any query upstream with that",
    "start": "1311039",
    "end": "1317360"
  },
  {
    "text": "provider let's use tcp it's more reliable it's going to be better right well",
    "start": "1317360",
    "end": "1322880"
  },
  {
    "text": "except remember the strict limit of packets well when you do tcp the single query is",
    "start": "1322880",
    "end": "1329440"
  },
  {
    "text": "actually going to use many more packets and so you will trigger uh advance rate limits much",
    "start": "1329440",
    "end": "1334799"
  },
  {
    "text": "faster so really really avoid using tcp when querying adobe results",
    "start": "1334799",
    "end": "1341760"
  },
  {
    "text": "and sometimes i mean it's really not your fault right because for the example before it was",
    "start": "1342480",
    "end": "1348159"
  },
  {
    "text": "actually not our fault but with proper testing and proper configuration we can work",
    "start": "1348159",
    "end": "1353520"
  },
  {
    "text": "around it but sometimes well there is there really isn't much you can do",
    "start": "1353520",
    "end": "1359440"
  },
  {
    "start": "1359000",
    "end": "1359000"
  },
  {
    "text": "so we had this issue where well an application has seen resolution errors that was like a",
    "start": "1359440",
    "end": "1366240"
  },
  {
    "text": "typical typical problem right and when we look at this we saw that it was only happening",
    "start": "1366240",
    "end": "1371360"
  },
  {
    "text": "for a single zone which is the default zone so the zone sending traffic to the option provider",
    "start": "1371360",
    "end": "1376880"
  },
  {
    "text": "which was the cloud resolver in that case well and it turns out when you graph the",
    "start": "1376880",
    "end": "1383039"
  },
  {
    "text": "l-check values for the elephant provider and latency of queries for provider and you group this by zone",
    "start": "1383039",
    "end": "1390480"
  },
  {
    "text": "you actually see that a single zone was impacted and we had then confirmation by",
    "start": "1390480",
    "end": "1395919"
  },
  {
    "text": "the cloud provider that they had issues in a specific zone where they were dropping dns queries",
    "start": "1395919",
    "end": "1401360"
  },
  {
    "text": "so well not much we could do in in that case",
    "start": "1401360",
    "end": "1406240"
  },
  {
    "text": "and you know i mean i've been talking about coordinates containers and coding experts and sometimes well it's the magic of",
    "start": "1407200",
    "end": "1413760"
  },
  {
    "text": "kubernetes right and you tend to forget that you actually run on nodes and that these nodes have constraints of their own",
    "start": "1413760",
    "end": "1421280"
  },
  {
    "text": "so families in term right application saving errors and it took us some time to see that",
    "start": "1422720",
    "end": "1429760"
  },
  {
    "text": "actually what was happening is that we had contract errors in the kernel logs and if you look at the graph at the",
    "start": "1429760",
    "end": "1436320"
  },
  {
    "text": "bottom you can see the number of contract entries has been slowly increasing and it's now",
    "start": "1436320",
    "end": "1441760"
  },
  {
    "text": "at a plateau at 130 000 entries and it's weird because it's very flat right",
    "start": "1441760",
    "end": "1448240"
  },
  {
    "text": "well it turned out to proxy by default will complete the contract to have 170",
    "start": "1448240",
    "end": "1454640"
  },
  {
    "text": "000 entries exactly which is exactly the limit we're getting at and when it goes down is because we",
    "start": "1454640",
    "end": "1461279"
  },
  {
    "text": "fixed it by increasing the number of buds and nodes and so connections were distributed much more evenly and it was",
    "start": "1461279",
    "end": "1468240"
  },
  {
    "text": "a lot better if you look at the graph i just i just showed",
    "start": "1468240",
    "end": "1474000"
  },
  {
    "start": "1470000",
    "end": "1470000"
  },
  {
    "text": "about contract entries you can see that there's actually two different group of nodes and all these",
    "start": "1474000",
    "end": "1479039"
  },
  {
    "text": "nodes were running coordinates uh pods so it's kind of weird that these nodes are so different because dns",
    "start": "1479039",
    "end": "1486480"
  },
  {
    "text": "queries were perfectly load balanced across all the cards and so we would expect to see this be very balanced",
    "start": "1486480",
    "end": "1492799"
  },
  {
    "text": "well it turned out the hosts were a bit different some were running a kind of 415 and some",
    "start": "1492799",
    "end": "1498720"
  },
  {
    "text": "were running kind of 5.0 and there's actually a few candle patches in 5.0",
    "start": "1498720",
    "end": "1505200"
  },
  {
    "text": "that improve the contract behavior with udp exactly for dns queries actually and what it changes",
    "start": "1505200",
    "end": "1511679"
  },
  {
    "text": "is that country contract entries for dns only get a service against gta by default instead of three minutes",
    "start": "1511679",
    "end": "1518400"
  },
  {
    "text": "which means they expire much faster and so the number of entries in the contract is much lower",
    "start": "1518400",
    "end": "1524080"
  },
  {
    "text": "and if you want details about the patches i gave the references on time",
    "start": "1524080",
    "end": "1530399"
  },
  {
    "text": "and what's nice with dns is that sometimes well it's just plainly plain weird",
    "start": "1530960",
    "end": "1538159"
  },
  {
    "text": "so we did what happened that time is we did an update of core dns on the cluster and",
    "start": "1538159",
    "end": "1544000"
  },
  {
    "text": "everything was working completely fine except for a single application and this application was speedy bouncer which is",
    "start": "1544000",
    "end": "1550720"
  },
  {
    "text": "a postgrad proxy and pt bouncer wasn't able to connect to postgres and",
    "start": "1550720",
    "end": "1556159"
  },
  {
    "text": "everything else was working perfectly fine so well what we had to do is captured in",
    "start": "1556159",
    "end": "1561440"
  },
  {
    "text": "a strategy to try and understand what was happening and here is an extract of the capture with important flags",
    "start": "1561440",
    "end": "1568559"
  },
  {
    "text": "passed and explaining on the slide so a few things uh i wanted i want you to",
    "start": "1568559",
    "end": "1574000"
  },
  {
    "text": "notice is well first of all all the queries are using the same source board which is a very different behavior than",
    "start": "1574000",
    "end": "1580000"
  },
  {
    "text": "the ones we were seeing with gbc or go for instance that's weird and also what's even",
    "start": "1580000",
    "end": "1585360"
  },
  {
    "text": "weirder is about on the right hand side where you can see this dns query names",
    "start": "1585360",
    "end": "1590400"
  },
  {
    "text": "with random case that's weird i mean it felt very surprising to us",
    "start": "1590400",
    "end": "1595840"
  },
  {
    "text": "and it's actually based on a draft from ietf to increase dns security by",
    "start": "1595840",
    "end": "1602320"
  },
  {
    "text": "encoding additional identity for the query using using random case",
    "start": "1602320",
    "end": "1609440"
  },
  {
    "text": "so what i wanted to show here is that well this dns resolver is really no one we know about it's very",
    "start": "1609440",
    "end": "1615679"
  },
  {
    "text": "different from all the ones we've been working with",
    "start": "1615679",
    "end": "1620399"
  },
  {
    "text": "and the content i didn't talk about before is this one so as you can see uh as resolution",
    "start": "1620880",
    "end": "1626240"
  },
  {
    "text": "happen is well you're getting uh threes which is nx domains and then a zero which is no error on the false",
    "start": "1626240",
    "end": "1632880"
  },
  {
    "text": "column and on the fifth column you can see always zero and then a one and this is the truncated",
    "start": "1632880",
    "end": "1639679"
  },
  {
    "text": "bit flag and this flag is set when your answer is bigger than the maximum size you you",
    "start": "1639679",
    "end": "1644799"
  },
  {
    "text": "allow so in that case the query was giving more than the size of the udp packet and of",
    "start": "1644799",
    "end": "1651360"
  },
  {
    "start": "1646000",
    "end": "1646000"
  },
  {
    "text": "course codiness was saying well it's truncated and you should go to tcp to get the full answer",
    "start": "1651360",
    "end": "1656720"
  },
  {
    "text": "it turned out our pg bouncers in this cluster were compiled with a resolver that isn't supporting tcp upgrade and",
    "start": "1656720",
    "end": "1663440"
  },
  {
    "text": "was just ignoring packets when truncated bit was said and not doing anything about it",
    "start": "1663440",
    "end": "1668720"
  },
  {
    "text": "and what so wait it was working before we did the continuous update right well it turned out there was a bug in",
    "start": "1668720",
    "end": "1675600"
  },
  {
    "text": "the version of coding that we were running where truncate it wasn't set when it should have been so things were working",
    "start": "1675600",
    "end": "1680880"
  },
  {
    "text": "fine because we had two issues one encoding has one big answer so we just had to recompile the answer",
    "start": "1680880",
    "end": "1687679"
  },
  {
    "text": "with another resolver and it fixed the problem",
    "start": "1687679",
    "end": "1692000"
  },
  {
    "text": "and well sometimes you know it's not dns well to be honest really",
    "start": "1692720",
    "end": "1699840"
  },
  {
    "start": "1700000",
    "end": "1700000"
  },
  {
    "text": "so the reason i'm mentioning this slide is because quite often teams will come to you because they have dns issues and",
    "start": "1700640",
    "end": "1706559"
  },
  {
    "text": "most of the time they're right it's a dns issue and in that case well look we're full of dns errors so they came to us and said",
    "start": "1706559",
    "end": "1713120"
  },
  {
    "text": "well we have a dns problem and it turned out everything was fine on the dns infra but",
    "start": "1713120",
    "end": "1719919"
  },
  {
    "text": "we looked at the overall deal in the cluster and we saw that the number of packets received on all the nodes had dropped",
    "start": "1719919",
    "end": "1726480"
  },
  {
    "text": "significantly and i mean this is not related to enough right so we looked at network monitoring and",
    "start": "1726480",
    "end": "1734480"
  },
  {
    "text": "of course you can't measure udp packet drops by using uh by e easily however what you can do",
    "start": "1734480",
    "end": "1742480"
  },
  {
    "text": "is look at the tcp connections on your network and if you see retransmits it means it means packets are getting lost and in",
    "start": "1742480",
    "end": "1749840"
  },
  {
    "text": "this graph you can see that there are a lot of retransmits happening exactly at the time of the error",
    "start": "1749840",
    "end": "1755440"
  },
  {
    "text": "and if you look at the detail and when we look at the detail we saw that for any of this bar there say the same",
    "start": "1755440",
    "end": "1762320"
  },
  {
    "text": "as it was involved and so we figured out that there was an issue with networking in this ac",
    "start": "1762320",
    "end": "1767919"
  },
  {
    "text": "and it was confirmed by the cloud provider so it was really in the dns that time",
    "start": "1767919",
    "end": "1774399"
  },
  {
    "text": "but well this was the first impact and what users so",
    "start": "1774399",
    "end": "1781440"
  },
  {
    "text": "so let's see what we run now uh to to be safe at the level so what what we do",
    "start": "1781440",
    "end": "1788080"
  },
  {
    "start": "1787000",
    "end": "1787000"
  },
  {
    "text": "is we run the local dns which i was talking about before and either ipvs for older cluster or",
    "start": "1788080",
    "end": "1795760"
  },
  {
    "text": "celia for more recent clusters and we use tcp for any connection to the dns",
    "start": "1795760",
    "end": "1801840"
  },
  {
    "text": "service because it's a lot better however we use udp to connect to the cloud resolver because of the limitation",
    "start": "1801840",
    "end": "1807840"
  },
  {
    "text": "i was mentioning before and if you look at the configuration of",
    "start": "1807840",
    "end": "1813360"
  },
  {
    "text": "the containers themselves well it's exactly the same as before except the nameserver we use is the ipg",
    "start": "1813360",
    "end": "1820159"
  },
  {
    "text": "bound by the local resolver and of course we did something else which is we",
    "start": "1820159",
    "end": "1825440"
  },
  {
    "text": "decrease the timeout because the default is five seconds and so we decreased it to one second so if ever we do the packet",
    "start": "1825440",
    "end": "1832320"
  },
  {
    "text": "then we are going to get a restrive to one second step five which is not great but better what we also did",
    "start": "1832320",
    "end": "1840399"
  },
  {
    "text": "is we gave applications the options to to use another nade result.com and",
    "start": "1840399",
    "end": "1847039"
  },
  {
    "text": "opt-in using annotation and what happens when is when we see segmentation we have a mutating web hook",
    "start": "1847039",
    "end": "1852399"
  },
  {
    "text": "that is going to change the configuration of um of your birds and",
    "start": "1852399",
    "end": "1857919"
  },
  {
    "text": "the this alternate configuration is using a single search domain which is sbc the first of the focal and",
    "start": "1857919",
    "end": "1864799"
  },
  {
    "text": "moving end dots back to two on me um and this means most queries uh will",
    "start": "1864799",
    "end": "1870880"
  },
  {
    "text": "get an answer in a single query which is much more efficient and the only cost is you can't",
    "start": "1870880",
    "end": "1878159"
  },
  {
    "text": "you can't resolve a series in the same name space by just using its name you need to also provide the namespace",
    "start": "1878159",
    "end": "1884320"
  },
  {
    "text": "that is much more efficient and we've seen applications being very happy about this design",
    "start": "1884320",
    "end": "1890080"
  },
  {
    "text": "and we're we're almost done um in conclusion um a few messages i wanted to share with",
    "start": "1891760",
    "end": "1899200"
  },
  {
    "start": "1895000",
    "end": "1895000"
  },
  {
    "text": "you so one thing you need to remember is running kubernetes means you're going to be running dns and running finish is hard and i'm sure",
    "start": "1899200",
    "end": "1906799"
  },
  {
    "text": "most of you know that a few recommendations uh try and use another called dinesh and cash as much",
    "start": "1906799",
    "end": "1912960"
  },
  {
    "text": "as you can also test your dns infrared do load testing you do running updates",
    "start": "1912960",
    "end": "1918559"
  },
  {
    "text": "because it's much better to discover the small issues i mentioned before during testing that in production of",
    "start": "1918559",
    "end": "1924880"
  },
  {
    "text": "course and also understand the upstream dns you depend on because even if what you do is great you're going to depend on other",
    "start": "1924880",
    "end": "1931279"
  },
  {
    "text": "services which can also fail of course and i think the most important thing i",
    "start": "1931279",
    "end": "1937039"
  },
  {
    "text": "wanted to share is for your applications um because well dns will fail right i",
    "start": "1937039",
    "end": "1942640"
  },
  {
    "text": "mean even if you do a very good job with dns and your infra you're gonna have issues sometimes and",
    "start": "1942640",
    "end": "1948240"
  },
  {
    "text": "you want your application to to react uh as well as possible to these issues so try and standardize on a few",
    "start": "1948240",
    "end": "1954480"
  },
  {
    "text": "resolvers only because as as you've seen in my examples uh we talked about four different",
    "start": "1954480",
    "end": "1960000"
  },
  {
    "text": "resolvers and there are a lot more out there it's very difficult to understand their exact behavior",
    "start": "1960000",
    "end": "1965919"
  },
  {
    "text": "and to optimize for all of them so try to limit the number of results that you use you will have i mean it will make",
    "start": "1965919",
    "end": "1972399"
  },
  {
    "text": "debugging much simpler also try and try and avoid doing",
    "start": "1972399",
    "end": "1978399"
  },
  {
    "text": "um resolution for each encoding request and reconnecting to back ends by either",
    "start": "1978399",
    "end": "1984559"
  },
  {
    "text": "using long-leaf connection to your backhands or to asking dns resolution to avoid depending on dns resolution working",
    "start": "1984559",
    "end": "1992240"
  },
  {
    "text": "great to serve synchronous queries and finally and i think this is the most important",
    "start": "1992240",
    "end": "1997840"
  },
  {
    "text": "thing is include tns failure tests in your application tests so if you do",
    "start": "1997840",
    "end": "2003120"
  },
  {
    "text": "cause testing include tns because you want to see how your application is going to behave when you lose a few packets",
    "start": "2003120",
    "end": "2011200"
  },
  {
    "text": "and we're done thank you very much i'm going to be around for the next few minutes for questions if you if you have",
    "start": "2012000",
    "end": "2018559"
  },
  {
    "text": "any thank you very much",
    "start": "2018559",
    "end": "2022720"
  }
]
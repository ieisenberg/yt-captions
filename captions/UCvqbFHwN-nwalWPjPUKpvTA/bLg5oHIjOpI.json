[
  {
    "text": "hi uh my name is seven and it in today's talk I'm going to talk about my",
    "start": "240",
    "end": "6600"
  },
  {
    "text": "experience building data science infrastructure for well over a decade now and some of the work that we have",
    "start": "6600",
    "end": "11820"
  },
  {
    "text": "done very recently within the kubernetes community as part of this talk we also have a",
    "start": "11820",
    "end": "17760"
  },
  {
    "text": "quick demo that my collaborator Bala from Intuit will be handling if you guys",
    "start": "17760",
    "end": "24060"
  },
  {
    "text": "are interested you can also follow along this demo within your own browser as well we'll be sharing a handy link to",
    "start": "24060",
    "end": "31080"
  },
  {
    "text": "access the demo too now for those of you in the room who are",
    "start": "31080",
    "end": "36780"
  },
  {
    "text": "either practicing data scientists or have built data science infrastructure in the past or currently as well this",
    "start": "36780",
    "end": "43200"
  },
  {
    "text": "might be a familiar narrative but just imagine you know like let's say your organization wants to build a",
    "start": "43200",
    "end": "48780"
  },
  {
    "text": "recommendation system so you have a data scientist who is tasked with that job and the first thing that they would like",
    "start": "48780",
    "end": "54600"
  },
  {
    "text": "to do is maybe perhaps you know spin up an ID instance on the cloud so maybe a",
    "start": "54600",
    "end": "60300"
  },
  {
    "text": "Jupiter Notebook on AWS or maybe it's sort of like some IDE pycharm on their",
    "start": "60300",
    "end": "66420"
  },
  {
    "text": "local workstation their laptop and the very first activity that they",
    "start": "66420",
    "end": "71460"
  },
  {
    "text": "want to do right after this is get access to some data so that they can start making sense of that data uh maybe",
    "start": "71460",
    "end": "77280"
  },
  {
    "text": "your data is stored in some snowflake data warehouse some data breaks data",
    "start": "77280",
    "end": "82380"
  },
  {
    "text": "Lake maybe you have sort of like you know stitched together your own data platform on top of S3 but there's",
    "start": "82380",
    "end": "87479"
  },
  {
    "text": "usually sort of like some mechanism that's needed for this data scientist to now sort of like understand what data is",
    "start": "87479",
    "end": "93780"
  },
  {
    "text": "available what is the quality of that data how to access that data so that all the security and data governance",
    "start": "93780",
    "end": "99600"
  },
  {
    "text": "concerns are addressed and how to quickly and efficiently access that data so you are not waiting for like minutes",
    "start": "99600",
    "end": "105479"
  },
  {
    "text": "and hours to get access to that so that you can start playing with that data you can start sort of like you know building an intuition around it",
    "start": "105479",
    "end": "111780"
  },
  {
    "text": "but then as soon as you're sort of like you know across this first hurdle uh you're presented with the next one you",
    "start": "111780",
    "end": "117899"
  },
  {
    "text": "know it could very well be the case that the kind of data analysis that you want to do or the kind of models that you want to train that's not possible on",
    "start": "117899",
    "end": "124920"
  },
  {
    "text": "your local workstation not possible maybe perhaps on the notebook instance that you have in the cloud maybe you're",
    "start": "124920",
    "end": "130560"
  },
  {
    "text": "doing some feature engineering step that requires huge amount of memory that's just not available on your laptop maybe",
    "start": "130560",
    "end": "136920"
  },
  {
    "text": "you are training a model that requires GPU maybe you decided that maybe you want to train a model for every single",
    "start": "136920",
    "end": "142140"
  },
  {
    "text": "country that your service operates in so you certainly need to train 200 odd models and if you have hyper parameters",
    "start": "142140",
    "end": "148860"
  },
  {
    "text": "as well that number can sort of like grow rather quickly and then there's sort of like you know comes this question that okay how do we handle this",
    "start": "148860",
    "end": "154200"
  },
  {
    "text": "large-scale compute uh it's likely you know given that we are at kubecon as well that your organization may have",
    "start": "154200",
    "end": "160500"
  },
  {
    "text": "already invested in some kubernetes clusters and then the first question comes is that okay how do you give",
    "start": "160500",
    "end": "165599"
  },
  {
    "text": "access to this data scientist to these kubernetes clusters now of course you know like uh this data scientist um",
    "start": "165599",
    "end": "172080"
  },
  {
    "text": "very technically sophisticated but in data science not necessarily in software engineering now is there an expectation",
    "start": "172080",
    "end": "177900"
  },
  {
    "text": "that they'll sort of like suddenly become a wizard uh in the concepts of kubernetes and understand how to sort of",
    "start": "177900",
    "end": "183300"
  },
  {
    "text": "like launch these large-scale workloads really efficiently is that really sort of like you know what they should be doing day in and day out now let's",
    "start": "183300",
    "end": "189840"
  },
  {
    "text": "assume somehow magically they are able to sort of like you know breach that um",
    "start": "189840",
    "end": "196760"
  },
  {
    "text": "uh then you know now we have this data scientist who is able to sort of like access this data not only locally but",
    "start": "197400",
    "end": "203459"
  },
  {
    "text": "also on the kubernetes cluster they have somehow been able to figure out a story around like how to ship their code to",
    "start": "203459",
    "end": "209099"
  },
  {
    "text": "the cluster how to ship their dependencies Library dependencies data dependencies and whatnot to that cluster",
    "start": "209099",
    "end": "214260"
  },
  {
    "text": "if there are some errors that have crept up if jobs are failing for whatever reason maybe perhaps they have some",
    "start": "214260",
    "end": "220140"
  },
  {
    "text": "mechanism some solution to sort of like you know figure that out as well the next question comes is how do we sort of",
    "start": "220140",
    "end": "225720"
  },
  {
    "text": "like productionize this work right up until now the data scientist is still sort of like actively iterating through a bunch of hypothesis so they need to",
    "start": "225720",
    "end": "232560"
  },
  {
    "text": "sort of like now run this model training workflow on top of some kind of workflow orchestrator you know it's likely that",
    "start": "232560",
    "end": "239099"
  },
  {
    "text": "the data engineers in the organization have already made a decision that maybe you know like they went with airflow or you know if they are sort of like a",
    "start": "239099",
    "end": "245099"
  },
  {
    "text": "kubernetes native shop then they may have already sort of like invested in our Google flows and they may have some",
    "start": "245099",
    "end": "250379"
  },
  {
    "text": "data engineering workflows running and now what the data scientist really wants uh to happen is that his or her",
    "start": "250379",
    "end": "258299"
  },
  {
    "text": "um data or like machine learning workflow should execute right after the Upstream data engineering workflows have",
    "start": "258299",
    "end": "264000"
  },
  {
    "text": "executed and now there's some sort of like you know the next big barrier is the expectation that now somebody is",
    "start": "264000",
    "end": "269520"
  },
  {
    "text": "going to sort of like take all of the work that the data scientist has done and rewrite it or re-implement it in the",
    "start": "269520",
    "end": "274740"
  },
  {
    "text": "SDK that many of these workflow orchestrators expose and then once you sort of like you know",
    "start": "274740",
    "end": "280500"
  },
  {
    "text": "have that uh the story doesn't really sort of like stop there uh you'll have many many different versions of these",
    "start": "280500",
    "end": "286740"
  },
  {
    "text": "workflows uh people will or your data scientists will want to try with different algorithms different features",
    "start": "286740",
    "end": "292199"
  },
  {
    "text": "uh different hyper parameters maybe they are sort of like new data scientists around the team who want to sort of like try out different set of experiments so",
    "start": "292199",
    "end": "299100"
  },
  {
    "text": "many versions that are running uh either concurrently or over a longer period of time and you need to sort of like you",
    "start": "299100",
    "end": "305340"
  },
  {
    "text": "know really make sense of like what's really happening around that uh there's also sort of like",
    "start": "305340",
    "end": "310500"
  },
  {
    "text": "this big question in machine learning about trust uh can you actually sort of like replicate the results that you have",
    "start": "310500",
    "end": "316020"
  },
  {
    "text": "seen in the past because if you can't do that then it's really difficult to trust the model that has been shipped so this",
    "start": "316020",
    "end": "322020"
  },
  {
    "text": "question of reproducibility also becomes really important it is closely coupled uh with the story of versioning as well",
    "start": "322020",
    "end": "327539"
  },
  {
    "text": "that it's not only just important to sort of like keep track of what has really happened but it's also really important sort of like ensure that any",
    "start": "327539",
    "end": "333840"
  },
  {
    "text": "past State can be reliably sort of like built up again now you know we have let's say a bunch",
    "start": "333840",
    "end": "340259"
  },
  {
    "text": "of different models that are being trained uh the next big step comes uh how do we sort of like deploy this model",
    "start": "340259",
    "end": "345600"
  },
  {
    "text": "now depending on your business context model deployment could mean many different things you may want to sort of",
    "start": "345600",
    "end": "351960"
  },
  {
    "text": "like deploy the model uh within a cell phone device or maybe it's a microservice that has a really high",
    "start": "351960",
    "end": "359660"
  },
  {
    "text": "expectations on SLA you know if let's say it's Netflix's recommendation systems then the kind of slas that are",
    "start": "359660",
    "end": "367160"
  },
  {
    "text": "established around that microservice they are like really stringent on the other end of the spectrum you may have",
    "start": "367160",
    "end": "372780"
  },
  {
    "text": "this model servicing an internal dashboard where the QPS may not be as high if the service goes down for a few",
    "start": "372780",
    "end": "378660"
  },
  {
    "text": "minutes or even a few hours nothing will sort of like break so that could be an entirely different pattern as well",
    "start": "378660",
    "end": "383780"
  },
  {
    "text": "another common scenario is where people sort of like just generate a bunch of scores offline they do some analysis",
    "start": "383780",
    "end": "389520"
  },
  {
    "text": "write a memo share it with the execs that can sort of like influence a business decision so on the deployment",
    "start": "389520",
    "end": "395340"
  },
  {
    "text": "side of the house there are many many different ways to deploy any sort of like given machine learning model uh",
    "start": "395340",
    "end": "401340"
  },
  {
    "text": "that was like can be sort of like quite specific to the business case at hand",
    "start": "401340",
    "end": "408240"
  },
  {
    "text": "and then you know only at the top of the stack we sort of like now start to worry",
    "start": "408240",
    "end": "413940"
  },
  {
    "text": "about the actual modeling what is the kind of data that we are dealing with is it tabular data or is it sort of like",
    "start": "413940",
    "end": "420240"
  },
  {
    "text": "you know unstructured data what kind of algorithms do we need to use and what not and if you look at it any machine",
    "start": "420240",
    "end": "428759"
  },
  {
    "text": "learning project within any organization independent of the state of its maturity",
    "start": "428759",
    "end": "434039"
  },
  {
    "text": "has to sort of like deal with these tax right like you need to sort of like understand how are you accessing your",
    "start": "434039",
    "end": "440220"
  },
  {
    "text": "data how that data is stored you need to understand where that compute is happening even if it's happening locally",
    "start": "440220",
    "end": "445380"
  },
  {
    "text": "on your laptop uh what is the story around workflow orchestration have you already invested in a workflow",
    "start": "445380",
    "end": "450660"
  },
  {
    "text": "orchestrator do you want to sort of like make a new investment how are you thinking about sort of like you know many of these concerns that these days",
    "start": "450660",
    "end": "456660"
  },
  {
    "text": "are lumped into sort of like this word ml Ops around sort of like versioning reproducibility experimentation",
    "start": "456660",
    "end": "462900"
  },
  {
    "text": "management and so on so forth and then of course you know like how do you actually make use of that model how do you make sense of that uh how do you",
    "start": "462900",
    "end": "469800"
  },
  {
    "text": "sort of like rinse and repeat and I trade on that entire machine learning process and then at the top end of the",
    "start": "469800",
    "end": "474840"
  },
  {
    "text": "stack the concerns are all like okay what is the actual machine learning problem how are you taking that business problem and going all the way and",
    "start": "474840",
    "end": "481860"
  },
  {
    "text": "translating that into a mathematical model and this this was basically sort of like",
    "start": "481860",
    "end": "487259"
  },
  {
    "text": "my team's Charter uh at Netflix uh uh where sort of like you know many of these learnings came from and our goal",
    "start": "487259",
    "end": "494220"
  },
  {
    "text": "was that you know we had sort of like a really large uh data science team that numbered upwards of 300 and our goal was",
    "start": "494220",
    "end": "500160"
  },
  {
    "text": "that okay how do we sort of like make these talented folks productive so that they're not sort of like spending a bulk of their time fighting with",
    "start": "500160",
    "end": "506039"
  },
  {
    "text": "infrastructure I mean of course you know like if they wanted to be experts in kubernetes then they would have chosen to be Engineers but then they really",
    "start": "506039",
    "end": "512159"
  },
  {
    "text": "sort of like like the uh craft of data science and we need to sort of like meet them uh where they are",
    "start": "512159",
    "end": "518760"
  },
  {
    "text": "and one of the biggest hypotheses that we had was that the problem that we were sort of like you know staring at was uh",
    "start": "518760",
    "end": "525660"
  },
  {
    "text": "the subproductivity if you look at any organization um you know they have an immense desire",
    "start": "525660",
    "end": "533220"
  },
  {
    "text": "to invest in machine learning there's a lot of data that's being collected uh all these organizations they are sort of",
    "start": "533220",
    "end": "539100"
  },
  {
    "text": "like very keen to sort of like embed machine learning embed intelligence into a variety of business problems and then",
    "start": "539100",
    "end": "545760"
  },
  {
    "text": "at the same time there are many technical advancements that are also being made both on the machine learning",
    "start": "545760",
    "end": "551040"
  },
  {
    "text": "side as well as on sort of like you know raw compute infrastructure side of the house as well every single day we are sort of like you know seeing sort of",
    "start": "551040",
    "end": "556980"
  },
  {
    "text": "like uh the specs that sort of like public Cloud can offer sort of like you",
    "start": "556980",
    "end": "562620"
  },
  {
    "text": "know increasing uh the advancements on the machine learning side as well you know newer kinds of models that are sort",
    "start": "562620",
    "end": "568440"
  },
  {
    "text": "of like coming up but then the big problem is that these sort of like two curves they haven't intersected yet and",
    "start": "568440",
    "end": "573839"
  },
  {
    "text": "the reason is not really lack of Desire but it's sort of like this lack of productivity and that needs to be bridged by any kind of ml Ops tool that",
    "start": "573839",
    "end": "581760"
  },
  {
    "text": "makes us out there in the market and then the other sort of like learning",
    "start": "581760",
    "end": "587160"
  },
  {
    "text": "here was if we sort of like look at the stack and look at sort of like the order of concerns from a software engineering",
    "start": "587160",
    "end": "592620"
  },
  {
    "text": "point of view from a builder point of view from our point of view um it's it's bottom heavy we need to sort of like make a lot of Investments",
    "start": "592620",
    "end": "598800"
  },
  {
    "text": "on the data side of the house on the compute stack on the orchestration stack but then if you look at it from the top",
    "start": "598800",
    "end": "605519"
  },
  {
    "text": "most stack that's where the data scientist really wants to exercise a strong degree of autonomy they really do",
    "start": "605519",
    "end": "611339"
  },
  {
    "text": "care what kind of training framework they are using uh how they want to sort of like build the model what kind of",
    "start": "611339",
    "end": "618120"
  },
  {
    "text": "features they want to use most data scientists they don't really have explicit opinions around how the data is",
    "start": "618120",
    "end": "623160"
  },
  {
    "text": "stored whether they are using kubernetes for large scale compute what kind of workflow orchestrator they are using as long as those concerns are well",
    "start": "623160",
    "end": "629459"
  },
  {
    "text": "satisfied and that's where we started this project called metaflow at Netflix we which we",
    "start": "629459",
    "end": "636060"
  },
  {
    "text": "open sourced in December 2019. at AWS reinvent um if you're interested in",
    "start": "636060",
    "end": "641279"
  },
  {
    "text": "metaflow very recently we also launched this sandbox uh where you can sort of like without having to install anything",
    "start": "641279",
    "end": "646680"
  },
  {
    "text": "you can go to this URL and uh you can sort of like play with better flow and the entire infrastructure is backed by",
    "start": "646680",
    "end": "654060"
  },
  {
    "text": "kubernetes cluster and harbor workflow instance so you can sort of like try out all the promises that we make in our",
    "start": "654060",
    "end": "659760"
  },
  {
    "text": "documentation now very simply what metaflow enables is",
    "start": "659760",
    "end": "665640"
  },
  {
    "text": "a programming model that keeps dags front right and Center so defining a dag is",
    "start": "665640",
    "end": "671399"
  },
  {
    "text": "very simple and straightforward so you can use some python decorators so in this case the step decorator to denote",
    "start": "671399",
    "end": "678300"
  },
  {
    "text": "nodes in and then the self.next invocations to denote the edges in your graph and then",
    "start": "678300",
    "end": "683760"
  },
  {
    "text": "you can execute this as you would execute any other python file and then metaflow will go",
    "start": "683760",
    "end": "689279"
  },
  {
    "text": "ahead and execute this and you can sort of like have a bunch of different patterns including sort of like branches for reaches and whatnot",
    "start": "689279",
    "end": "695880"
  },
  {
    "text": "uh there are a lot of Primitives that metaflow comes with so of course you're",
    "start": "695880",
    "end": "700920"
  },
  {
    "text": "like on the data side of the house it ships with a high throughput S3 client that provides you higher throughput than",
    "start": "700920",
    "end": "707160"
  },
  {
    "text": "what's possible uh with a local disk attached to your instance so you can get like upwards of 25 gbps of throughput uh",
    "start": "707160",
    "end": "714240"
  },
  {
    "text": "very easily using metaflow and then this also sort of like ties into your internal uh data layers as well as you",
    "start": "714240",
    "end": "721800"
  },
  {
    "text": "know whatever Primitives you have for data catalog so that data Discovery becomes rather simple and straightforward",
    "start": "721800",
    "end": "728399"
  },
  {
    "text": "uh and then everything gets versioned by default so every single time you execute any metaflow flow a unique run ID is",
    "start": "728399",
    "end": "734640"
  },
  {
    "text": "generated the entire internal status versioned in perpetuity for you so that I can go back and I can ask that hey",
    "start": "734640",
    "end": "740579"
  },
  {
    "text": "Bala executed this workflow six months ago uh can I see sort of like what was the internal State what was the model",
    "start": "740579",
    "end": "746339"
  },
  {
    "text": "that was generated uh what were the internal attributes that were generated not only that can I sort of like",
    "start": "746339",
    "end": "751680"
  },
  {
    "text": "actually go in and resume balas workflow from whatever arbitrary step that I want to and that sort of like allows people",
    "start": "751680",
    "end": "756959"
  },
  {
    "text": "to build on top of each other's work are very simple now we are at cubecon so we definitely",
    "start": "756959",
    "end": "764459"
  },
  {
    "text": "need to talk about kubernetes and that's where it sort of like comes in now imagine you know like you uh you're a",
    "start": "764459",
    "end": "769800"
  },
  {
    "text": "data scientist and you want to sort of like let's say uh train a model over a list of hyper parameters that is sort of",
    "start": "769800",
    "end": "776459"
  },
  {
    "text": "like 100 long uh with meta flow you can sort of like Drop in this decorator at resources and let's say you know in this",
    "start": "776459",
    "end": "782040"
  },
  {
    "text": "example I specified memory as 128 gigs could very easily also specify GPU CPUs",
    "start": "782040",
    "end": "787079"
  },
  {
    "text": "and whatnot and what metaflow will do is it will execute your start step locally on your laptop it will execute the train step",
    "start": "787079",
    "end": "793680"
  },
  {
    "text": "100 instances of that on kubernetes so it'll generate 100 pods and those steps",
    "start": "793680",
    "end": "799740"
  },
  {
    "text": "and it will also pipe all the logs back to your local workstation so to the end user it would seem that you know like",
    "start": "799740",
    "end": "805200"
  },
  {
    "text": "somebody came in and just added a whole bunch of ram to your laptop and went to",
    "start": "805200",
    "end": "810240"
  },
  {
    "text": "winter and that sort of like makes it uh quite trivial for people to sort of like scale out their workflows you know",
    "start": "810240",
    "end": "817880"
  },
  {
    "text": "you know and then of course you know like once let's say the user is Happy uh with what they have then it could be the",
    "start": "818220",
    "end": "823380"
  },
  {
    "text": "case that you know they want to sort of like integrate their work with their favorite workflow orchestrator that could be airflow that could be Argo",
    "start": "823380",
    "end": "829019"
  },
  {
    "text": "workflows step functions like a whole bunch of options that are available out there now the good thing is that all of",
    "start": "829019",
    "end": "834480"
  },
  {
    "text": "these workflow orchestrators they execute a dag with already written a dags so we can sort of like compile down this workflow into something that these",
    "start": "834480",
    "end": "841860"
  },
  {
    "text": "workflow orchestrators can easily understand and at that point you basically get the best of both worlds so",
    "start": "841860",
    "end": "846959"
  },
  {
    "text": "this workflow would be sort of like a native Argo workflow template as well as a native metaflow flow you can imagine",
    "start": "846959",
    "end": "852720"
  },
  {
    "text": "let's say you know for whatever reason let's say this work here fails then because of the fact that meta flow is capturing all of the internal State you",
    "start": "852720",
    "end": "858720"
  },
  {
    "text": "can actually go back to your laptop and you can resume your compute from wherever it failed locally and you can sort of like I create on it you can fix",
    "start": "858720",
    "end": "865200"
  },
  {
    "text": "that bug and then you can again push it back to Argo workflows and then your compute will resume from there and that",
    "start": "865200",
    "end": "870300"
  },
  {
    "text": "sort of like allows people to not really be an expert in kubernetes or Argo workflow SDK while still sort of like",
    "start": "870300",
    "end": "876000"
  },
  {
    "text": "enjoying all the great benefits that these tried and tested tools provide",
    "start": "876000",
    "end": "881779"
  },
  {
    "text": "oops there are a bunch of other functionalities as well that metaflow provides that are sort of like you know",
    "start": "883019",
    "end": "888959"
  },
  {
    "text": "more geared towards larger scale teams like functionalities around like how do you generate visual reports as part of",
    "start": "888959",
    "end": "894420"
  },
  {
    "text": "every execution how do you sort of like manage larger projects how do you sort of like you know think about dependency",
    "start": "894420",
    "end": "899459"
  },
  {
    "text": "management and so on so forth given that we are short on time and we want to sort of like give a quick demo so I'll sort of like skip on that",
    "start": "899459",
    "end": "906000"
  },
  {
    "text": "now the one sort of like message that I want to sort of like leave you with before sort of like we start off the",
    "start": "906000",
    "end": "911459"
  },
  {
    "text": "demo is that at the end of the day uh for any organization to be successful and sort of like introducing any kind of",
    "start": "911459",
    "end": "917339"
  },
  {
    "text": "intelligence into their applications they need infrastructure that can sort of like go end-to-end provide solutions",
    "start": "917339",
    "end": "922560"
  },
  {
    "text": "to the entire life cycle of machine learning uh that was basically uh our",
    "start": "922560",
    "end": "927660"
  },
  {
    "text": "agenda at Netflix as well which is basically what we have tried to build with meta flow so if projects of",
    "start": "927660",
    "end": "933600"
  },
  {
    "text": "this nature sort of like interest you excite you I highly recommend going to this URL and giving sort of",
    "start": "933600",
    "end": "940440"
  },
  {
    "text": "like metaflow a try but now I'll sort of like pass it on to Bala for a quick demo hey everyone I'm going to demo the",
    "start": "940440",
    "end": "948779"
  },
  {
    "text": "metaflow and Argo Flow side so mainly I'm going to focus on the three areas one is like a very simple metaphor",
    "start": "948779",
    "end": "955380"
  },
  {
    "text": "application how you can develop and run it under the second one like how you can run your meta flow application at scale",
    "start": "955380",
    "end": "961260"
  },
  {
    "text": "using a kubernetes the third one like how you can debug back your production issue on your local",
    "start": "961260",
    "end": "969240"
  },
  {
    "text": "so I'm using that the same sandbox the metaphor of playground so if you see",
    "start": "969240",
    "end": "975720"
  },
  {
    "text": "that it's a hollow flow I have like a start function which is which is calling the heat function next",
    "start": "975720",
    "end": "982260"
  },
  {
    "text": "and end function it's only it has like a three functions if I click the Run current flow which",
    "start": "982260",
    "end": "988920"
  },
  {
    "text": "will run on the local as a python application and you can see the nice outputs are coming like",
    "start": "988920",
    "end": "996019"
  },
  {
    "text": "all the logs so starting eating and ending and this",
    "start": "996120",
    "end": "1002959"
  },
  {
    "text": "sandbox is already having like a cord decorator so that you can see the TC output of your",
    "start": "1002959",
    "end": "1009079"
  },
  {
    "text": "flow the next thing I like to go with like a dag so so basically in the my",
    "start": "1009079",
    "end": "1014779"
  },
  {
    "text": "stock function is going to call like a two parallel steps eat and drink and join with the joint step",
    "start": "1014779",
    "end": "1022279"
  },
  {
    "text": "let's run this all are like a simple flows so you",
    "start": "1022279",
    "end": "1028040"
  },
  {
    "text": "can able to run it in the local",
    "start": "1028040",
    "end": "1031240"
  },
  {
    "text": "so you can see that the Heat and the drink was parallely ran here",
    "start": "1033980",
    "end": "1041020"
  },
  {
    "text": "and one more thing like every every run the meta flow will give like a unique run ID for every flow so that in future",
    "start": "1044000",
    "end": "1051260"
  },
  {
    "text": "you can if you want to refer it back or you want to resume it back you can use the serenity for The Meta flow so you",
    "start": "1051260",
    "end": "1058280"
  },
  {
    "text": "can see the nice dog is printed in the right hand side so the given the time I am going to skip",
    "start": "1058280",
    "end": "1063860"
  },
  {
    "text": "like a 3 and 4 which is like a artifact and versioning the second one is like a parallel person",
    "start": "1063860",
    "end": "1069799"
  },
  {
    "text": "I'm going to show that like how you can run your metaphor application at scale so in the",
    "start": "1069799",
    "end": "1076400"
  },
  {
    "text": "metaphor application I have like a three steps like a process memory hog and join mainly like a memory hog needed like a",
    "start": "1076400",
    "end": "1083600"
  },
  {
    "text": "more memory for to process that but I cannot run it on my local so I want like",
    "start": "1083600",
    "end": "1089419"
  },
  {
    "text": "some remote system like a kubernetes or Cloud somewhere we need to run it so metaflow will support D for like a",
    "start": "1089419",
    "end": "1096020"
  },
  {
    "text": "kubernetes if you want to test it and here before going to that I am I'm",
    "start": "1096020",
    "end": "1102740"
  },
  {
    "text": "having like the array of data I want to run like a these three steps for every",
    "start": "1102740",
    "end": "1108380"
  },
  {
    "text": "element in that array like a if you have like a list of hyper parameters then if you want to train that model for each",
    "start": "1108380",
    "end": "1114860"
  },
  {
    "text": "hyper parameter you can have like a for each one so",
    "start": "1114860",
    "end": "1119960"
  },
  {
    "text": "let me turn on that kubernetes one because I don't have that much memory on my local because every step need like a",
    "start": "1119960",
    "end": "1127460"
  },
  {
    "text": "8 gig memory and I have like almost like a five elements so if I enable that",
    "start": "1127460",
    "end": "1133700"
  },
  {
    "text": "kubernetes decorator then which will run on local",
    "start": "1133700",
    "end": "1140860"
  },
  {
    "text": "but it will submit that",
    "start": "1141679",
    "end": "1145059"
  },
  {
    "text": "it will submit the kubernetes job on the remote cluster but orchestration will happen on your local",
    "start": "1150200",
    "end": "1156740"
  },
  {
    "text": "laptop so you can see that it's submitting that all the kubernetes job and it's trying to create a container for every step",
    "start": "1156740",
    "end": "1165400"
  },
  {
    "text": "give us a little bit time so which the cluster is scaling up",
    "start": "1172940",
    "end": "1178660"
  },
  {
    "text": "so you can see that the all the jobs are completing and picking up the next process",
    "start": "1183500",
    "end": "1191440"
  },
  {
    "text": "which you need like eight gig RAM for every step",
    "start": "1192559",
    "end": "1197200"
  },
  {
    "text": "okay",
    "start": "1218179",
    "end": "1220720"
  },
  {
    "text": "so as in that ah now you have a production application ready and you tested with the kubernetes job and you",
    "start": "1225860",
    "end": "1232400"
  },
  {
    "text": "are ready to push it to the production so to pushing to the production you need",
    "start": "1232400",
    "end": "1237679"
  },
  {
    "text": "like a production grade like workflow orchestration engine which will need to give like a high fall tolerance",
    "start": "1237679",
    "end": "1245120"
  },
  {
    "text": "and make sure like your application is running properly so in that one you cannot only rely on like a kubernetes",
    "start": "1245120",
    "end": "1251780"
  },
  {
    "text": "job you need like a",
    "start": "1251780",
    "end": "1255220"
  },
  {
    "text": "is coming user doesn't know that Argo workflow that Argo workflow is like a production",
    "start": "1257020",
    "end": "1262880"
  },
  {
    "text": "grade open source container native orchestration engine which will run like a high parallel jobs on the kubernetes",
    "start": "1262880",
    "end": "1271779"
  },
  {
    "text": "so to convert into that or go workflow the data scientist no need to learn about that all the EML files and",
    "start": "1272240",
    "end": "1278840"
  },
  {
    "text": "kubernetes The Meta flow will automatically convert your application into that org overflow template and",
    "start": "1278840",
    "end": "1285919"
  },
  {
    "text": "submit it for you to to that just",
    "start": "1285919",
    "end": "1291140"
  },
  {
    "text": "you can give like cargo workflow create",
    "start": "1291140",
    "end": "1296600"
  },
  {
    "text": "which will create like a workflow template on a Argo workflow then you can",
    "start": "1296600",
    "end": "1301700"
  },
  {
    "text": "just call trigger which will submit the Target or from your kubernetes cluster and Argo",
    "start": "1301700",
    "end": "1309140"
  },
  {
    "text": "workflow is having like a nice UI so you can see that the Argo",
    "start": "1309140",
    "end": "1315400"
  },
  {
    "text": "you can see that your application is start running as Argo workflow",
    "start": "1316100",
    "end": "1323260"
  },
  {
    "text": "it may take like a little bit time so I given the time I am like to show that the previous run which I handled that so",
    "start": "1323600",
    "end": "1330740"
  },
  {
    "text": "you can see that the algorithm was nicely orchestrated you are all the steps with all the",
    "start": "1330740",
    "end": "1336919"
  },
  {
    "text": "the parameters in the array it will create a like a five parallel tasks and",
    "start": "1336919",
    "end": "1342860"
  },
  {
    "text": "it's executed like a process and memory hog and it's joined back to the Joint step if you see that all your resource",
    "start": "1342860",
    "end": "1352360"
  },
  {
    "text": "configured in the Pod suppose if you are declaring for a eight eight gig it will",
    "start": "1352360",
    "end": "1357860"
  },
  {
    "text": "automatically config in your power resource quota and if you see the nargo workflow UI you",
    "start": "1357860",
    "end": "1365419"
  },
  {
    "text": "can see that lot of options are coming like in the running UI so you can see that you can suspend it the Argo",
    "start": "1365419",
    "end": "1371480"
  },
  {
    "text": "workflow when it's running and you can resume it back where it stopped then another thing like suppose if you want",
    "start": "1371480",
    "end": "1376940"
  },
  {
    "text": "to completely stop it you can go out and stop stop will be like a graceful shutdown and the terminate will be like",
    "start": "1376940",
    "end": "1383000"
  },
  {
    "text": "a hot kill like it will kill that immediate all the part from the kubernetes",
    "start": "1383000",
    "end": "1388100"
  },
  {
    "text": "then you can you can get like a nice locks for the Torgo workflow whatever your steps running like you can",
    "start": "1388100",
    "end": "1395419"
  },
  {
    "text": "click that log then it will print like all your logs okay",
    "start": "1395419",
    "end": "1401360"
  },
  {
    "text": "let's go back to things okay so now now you have like",
    "start": "1401360",
    "end": "1407539"
  },
  {
    "text": "application ready in the production but you don't want every time submit manually you want to schedule it and run",
    "start": "1407539",
    "end": "1413299"
  },
  {
    "text": "it so so that is The Decorator metaphors providing like you can have like a schedule",
    "start": "1413299",
    "end": "1419360"
  },
  {
    "text": "which will basically converting to that Argo or Crone or flow the arbor flow is",
    "start": "1419360",
    "end": "1424760"
  },
  {
    "text": "already supporting like a Chrono flow so when you have like this decorator and",
    "start": "1424760",
    "end": "1430340"
  },
  {
    "text": "calling like Argo or procreate meta flow will automatically convert your application into that Chrome or",
    "start": "1430340",
    "end": "1436760"
  },
  {
    "text": "plane or the workflow then it will run it every hour so you can see that here",
    "start": "1436760",
    "end": "1442520"
  },
  {
    "text": "there is another tab called Chrono flow you can see that which is created now and it will going to run like every one",
    "start": "1442520",
    "end": "1448640"
  },
  {
    "text": "hour in this case suppose a I want to run your application on demand I don't want",
    "start": "1448640",
    "end": "1455360"
  },
  {
    "text": "to wait for one hour I just want to quickly retrain my models so just you can submit it here which will again",
    "start": "1455360",
    "end": "1461720"
  },
  {
    "text": "trigger the workflow on demand",
    "start": "1461720",
    "end": "1467020"
  },
  {
    "text": "so third area I'm going to cover like suppose if you have like a bug how you can debug it easily in the local so I am",
    "start": "1467299",
    "end": "1475039"
  },
  {
    "text": "going to create a bug like a divisible by zero and",
    "start": "1475039",
    "end": "1481640"
  },
  {
    "text": "workflow",
    "start": "1481640",
    "end": "1484640"
  },
  {
    "text": "and I'm going to trigger it",
    "start": "1488960",
    "end": "1492760"
  },
  {
    "text": "just kill my previous one",
    "start": "1500780",
    "end": "1505419"
  },
  {
    "text": "so you can see that just the submitted one is running but it has a bug on the",
    "start": "1505940",
    "end": "1511220"
  },
  {
    "text": "start step it should fail",
    "start": "1511220",
    "end": "1514720"
  },
  {
    "text": "so technically if you have any production issue you need to log into the production cluster go to that each part and finding like",
    "start": "1517700",
    "end": "1524720"
  },
  {
    "text": "what's what went wrong all the things but machine learning science Engineers they don't have like",
    "start": "1524720",
    "end": "1531320"
  },
  {
    "text": "any kubernetes knowledge and they will feel like you know",
    "start": "1531320",
    "end": "1536860"
  },
  {
    "text": "okay now it's failed so if the machine learning engineer want to debug it back",
    "start": "1537620",
    "end": "1542840"
  },
  {
    "text": "in the local so what they just need to do that",
    "start": "1542840",
    "end": "1547658"
  },
  {
    "text": "just they can call that resume",
    "start": "1551240",
    "end": "1555100"
  },
  {
    "text": "equal to because the meta flow is keep tracking like all the your run so you can just",
    "start": "1559760",
    "end": "1566480"
  },
  {
    "text": "give your run ID then it will run it on your local where that the workflow is left in that",
    "start": "1566480",
    "end": "1574220"
  },
  {
    "text": "kubernetes cluster so you can see that it's failed in the local also",
    "start": "1574220",
    "end": "1580100"
  },
  {
    "text": "so the engineer can directly go and fix it and run it on the local with the given",
    "start": "1580100",
    "end": "1587179"
  },
  {
    "text": "data to make sure it is working fine then he can push it back that the fix",
    "start": "1587179",
    "end": "1592580"
  },
  {
    "text": "into the production so now he's going to make sure like a",
    "start": "1592580",
    "end": "1600220"
  },
  {
    "text": "whether the fix is working fine",
    "start": "1602720",
    "end": "1606460"
  },
  {
    "text": "basically if you want to learn more about the cargo product Argo product please stop by that Intuit both and Argo",
    "start": "1616460",
    "end": "1622640"
  },
  {
    "text": "both",
    "start": "1622640",
    "end": "1625179"
  },
  {
    "text": "in into it we are using like a heavily the target workflow in the model training side we are running like a",
    "start": "1652580",
    "end": "1659960"
  },
  {
    "text": "5000 plus concurrent power for training that models",
    "start": "1659960",
    "end": "1666320"
  },
  {
    "text": "so the Argo workflow will be scaled like 5000 to 10 000 Parts concurrently",
    "start": "1666320",
    "end": "1673580"
  },
  {
    "text": "and it will able to manage it so now the application is fixed and it's run",
    "start": "1673580",
    "end": "1679580"
  },
  {
    "text": "properly then user can again create that means here create means you are",
    "start": "1679580",
    "end": "1684860"
  },
  {
    "text": "pushing the fixed code into the production then again you can go ahead and Trigger it",
    "start": "1684860",
    "end": "1690940"
  },
  {
    "text": "um that's end of my demo thanks",
    "start": "1691340",
    "end": "1698380"
  },
  {
    "text": "thank you what it provides you is a solution for different layers of the stack",
    "start": "1700340",
    "end": "1705500"
  },
  {
    "text": "and of course what we demoed today was our Integrations with kubernetes and that sandbox environment by the way was",
    "start": "1705500",
    "end": "1712039"
  },
  {
    "text": "running on AWS but now metaflow supports uh all three major public clouds as well",
    "start": "1712039",
    "end": "1717320"
  },
  {
    "text": "as on-prem deployments for your data storage you can use S3 Azure blob store",
    "start": "1717320",
    "end": "1723260"
  },
  {
    "text": "GCS or you can sort of electronic video snowflake warehouses or databricks Delta Lake",
    "start": "1723260",
    "end": "1728980"
  },
  {
    "text": "for compute of course kubernetes is an option we do also sort of like provide",
    "start": "1728980",
    "end": "1734480"
  },
  {
    "text": "first class Integrations with AWS batch on the orchestration side of the house the first integration that we started",
    "start": "1734480",
    "end": "1740720"
  },
  {
    "text": "out with step functions which is a managed orchestrator that AWS provides very",
    "start": "1740720",
    "end": "1746779"
  },
  {
    "text": "recently earlier this year we integrated with Argo workflows and we'll be releasing an integration with airflow uh",
    "start": "1746779",
    "end": "1752059"
  },
  {
    "text": "very soon as well on the orchestration front another sort of like interesting piece of work uh",
    "start": "1752059",
    "end": "1757520"
  },
  {
    "text": "that's coming out very soon in collaboration with the Argo workflow Community is the integration with Argo events where you can essentially sort of",
    "start": "1757520",
    "end": "1763940"
  },
  {
    "text": "like have these even driven workflows uh you can imagine sort of like you know let's say uh in your data infrastructure",
    "start": "1763940",
    "end": "1770480"
  },
  {
    "text": "let's say there's some mechanism through which some new Partition appears for some data set and then that can sort of",
    "start": "1770480",
    "end": "1777559"
  },
  {
    "text": "like trigger an Argo event that can automatically trigger your machine learning workflows that can sort of like also come in handy for retraining steps",
    "start": "1777559",
    "end": "1784580"
  },
  {
    "text": "of your pipeline and of course metaflow automatically provides sort of like uh Version Control outside of any sort of",
    "start": "1784580",
    "end": "1791899"
  },
  {
    "text": "like Get Ops workflows that you might have and then thanks to sort of like strong notion of artifact management you",
    "start": "1791899",
    "end": "1797899"
  },
  {
    "text": "get sort of like experimentation management out of the box uh there's a UI that it ships with that you can sort",
    "start": "1797899",
    "end": "1804320"
  },
  {
    "text": "of like show you today but yeah if these things are useful uh please do join our",
    "start": "1804320",
    "end": "1810080"
  },
  {
    "text": "community if you have any questions any feedback open to your questions thank you",
    "start": "1810080",
    "end": "1816030"
  },
  {
    "text": "[Applause]",
    "start": "1816030",
    "end": "1822010"
  },
  {
    "text": "yes please yes so the question was do we have",
    "start": "1826220",
    "end": "1833179"
  },
  {
    "text": "Integrations with the on-prem cloud so basically you can use any S3 compatible storage and bring any CNC of compliant",
    "start": "1833179",
    "end": "1840320"
  },
  {
    "text": "kubernetes distribution with that and that'll work",
    "start": "1840320",
    "end": "1845020"
  },
  {
    "text": "yes",
    "start": "1846620",
    "end": "1849620"
  },
  {
    "text": "so the question was that okay how does metaflow handle GPU so just like we had memory equals 8000 you can have GPU",
    "start": "1853460",
    "end": "1859880"
  },
  {
    "text": "equals one GPU equals two and then met after will essentially uh launch the Pod appropriately on a GPU instance",
    "start": "1859880",
    "end": "1866960"
  },
  {
    "text": "thank you thank you yes uh hello great presentation",
    "start": "1866960",
    "end": "1873140"
  },
  {
    "text": "um in your example you had mentioned that you weren't able to run it locally because it required eight gigs of RAM",
    "start": "1873140",
    "end": "1878799"
  },
  {
    "text": "and then when it failed um did you say that it ran locally like",
    "start": "1878799",
    "end": "1884059"
  },
  {
    "text": "so basically the step that required 8 gigs of RAM that ran on the kubernetes",
    "start": "1884059",
    "end": "1889700"
  },
  {
    "text": "cluster as a kubernetes pod I see because the local instance that's running that vs code instance that has",
    "start": "1889700",
    "end": "1895279"
  },
  {
    "text": "roughly four gigs of RAM so that will fail uh and then not only we need sort of like eight gigs of RAM we were",
    "start": "1895279",
    "end": "1900919"
  },
  {
    "text": "running five concurrent steps so we'll need eight times five forty gigs of RAM",
    "start": "1900919",
    "end": "1906260"
  },
  {
    "text": "which is not available in at least sort of like a normal laptop okay so in the debugging case that case didn't require",
    "start": "1906260",
    "end": "1912740"
  },
  {
    "text": "the extra memory and so therefore you're able to debug your locally versus debugging in the logs yeah so the",
    "start": "1912740",
    "end": "1917840"
  },
  {
    "text": "debugging step that we had so let's say you know you had a workflow that failed on Argo workflow so you could resume that from any arbitrary step and you can",
    "start": "1917840",
    "end": "1925460"
  },
  {
    "text": "resume while it's running on kubernetes as well so so the resume doesn't have to happen entirely locally you can still",
    "start": "1925460",
    "end": "1930980"
  },
  {
    "text": "sort of like happen on kubernetes any more questions",
    "start": "1930980",
    "end": "1938240"
  },
  {
    "text": "well thank you guys thank you",
    "start": "1938240",
    "end": "1942340"
  }
]
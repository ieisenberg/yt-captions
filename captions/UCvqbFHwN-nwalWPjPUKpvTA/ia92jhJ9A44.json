[
  {
    "text": "thanks for having us and um yeah today we'll be covering like specific details and kind of weird technical Corners that",
    "start": "199",
    "end": "7319"
  },
  {
    "text": "we found ourself into when trying to Port our application to kubernetes uh generic context uh we are in this case",
    "start": "7319",
    "end": "14519"
  },
  {
    "text": "not a s provider so we are basically just providing our our HP HPC solution",
    "start": "14519",
    "end": "20680"
  },
  {
    "text": "uh within uh with all its components as uh Deployable artifact to the customer which is basically rolling it out within",
    "start": "20680",
    "end": "28199"
  },
  {
    "text": "their own environment and um yeah so that we we don't have generally like super lowlevel access to the cluster to",
    "start": "28199",
    "end": "34600"
  },
  {
    "text": "tweak with the feature Gates and and that level optimization but still it's a very high requirement for us to kind of",
    "start": "34600",
    "end": "40760"
  },
  {
    "text": "be as lightweight as possible maintainable observable as possible so that we can minimize the most important",
    "start": "40760",
    "end": "46160"
  },
  {
    "text": "metric of all which is the number of calls that we get when they roll out in production so um I am Luca monesi I am",
    "start": "46160",
    "end": "53079"
  },
  {
    "text": "Senior software engineer for s zda u I'm working in with of on the integration uh",
    "start": "53079",
    "end": "58920"
  },
  {
    "text": "of our product between between uh yeah which is is called caliber which me we'll be talking about and uh container",
    "start": "58920",
    "end": "66040"
  },
  {
    "text": "and orchestration Technologies and I'm also interested in a bunch of other different things okay thank you Luka uh",
    "start": "66040",
    "end": "72320"
  },
  {
    "text": "my name is m uh I'm going to take it from here uh I'm an engineer director at the Simons Eda so we work on this",
    "start": "72320",
    "end": "78960"
  },
  {
    "text": "project together I got it started he did he did all the great work so I did nothing",
    "start": "78960",
    "end": "84200"
  },
  {
    "text": "afterwards so to get it started off uh so we are going to talk about three parts today so first I going to",
    "start": "84200",
    "end": "90000"
  },
  {
    "text": "introduce what is Eda and what are what type of HPC workload that we're talking about not all HPC are built equal then",
    "start": "90000",
    "end": "96960"
  },
  {
    "text": "I'm going to turn back over to Luca to tell to tell you you know how we solve the problem how we actually enabling our",
    "start": "96960",
    "end": "103159"
  },
  {
    "text": "software to run on kuber uh uh cluster so what is Eda Eda for us stand for",
    "start": "103159",
    "end": "110439"
  },
  {
    "text": "electrical design automation uh so it's actually a whole category of software it covers the entire uh flow from IC design",
    "start": "110439",
    "end": "118320"
  },
  {
    "text": "all the way to IC Manufacturing right so in general a lot of people say Okay Eda is a high performance Computing software",
    "start": "118320",
    "end": "124399"
  },
  {
    "text": "which is correct right so uh there is a lot of software that involved in here requires a lot of computing resources uh",
    "start": "124399",
    "end": "131319"
  },
  {
    "text": "it's actually build predated KU exist so a lot of this High intensive workload",
    "start": "131319",
    "end": "137200"
  },
  {
    "text": "already actually solve a lot of problems that you may already familiar with uh so",
    "start": "137200",
    "end": "142599"
  },
  {
    "text": "uh but not not all the Eda sare are actually equal so we usually call it front end of line and back end of line",
    "start": "142599",
    "end": "148920"
  },
  {
    "text": "frontend of the line is design creation when you had an idea you create a circuit and then map it to",
    "start": "148920",
    "end": "154239"
  },
  {
    "text": "layout that's what you do front and design so there you see a lot of interactive editing you see data",
    "start": "154239",
    "end": "160760"
  },
  {
    "text": "analysis you you run on demand simulation for example uh you want to run your M Carlo simulation on on your",
    "start": "160760",
    "end": "167599"
  },
  {
    "text": "circuit so uh you know sometime you can think about okay those things mostly can cover with the jobs on kubernetes you",
    "start": "167599",
    "end": "174800"
  },
  {
    "text": "can just get away from that U but once you move to the back end which is basically where are dealing with the the",
    "start": "174800",
    "end": "180959"
  },
  {
    "text": "caliber product line that we have in SE Eda you're talking about very you know",
    "start": "180959",
    "end": "186200"
  },
  {
    "text": "highly intensive uh Computing uh cluster Computing basically a bat mode job so",
    "start": "186200",
    "end": "192040"
  },
  {
    "text": "you want to launch launch the job into a cluster and then leave it running and then you have many different components",
    "start": "192040",
    "end": "197799"
  },
  {
    "text": "actually tightly coupled together so that's the workload we are dealing with give you some simple numbers just an",
    "start": "197799",
    "end": "203319"
  },
  {
    "text": "idea so we're dealing with with with a single batch job this is a single batch job $20,000 core is not unheard of and",
    "start": "203319",
    "end": "211439"
  },
  {
    "text": "um you know we even hear about like a 50,000 cores and that's the scale that we're dealing with one single note you",
    "start": "211439",
    "end": "217360"
  },
  {
    "text": "can take memory up to one terabyte and uh um so from the component to component",
    "start": "217360",
    "end": "222599"
  },
  {
    "text": "burst uh communication can be 10 gigb per second so so that is the uh that is",
    "start": "222599",
    "end": "228799"
  },
  {
    "text": "uh that is the scale for one single batch drob that we're dealing with so these are batch jobs so now let's look",
    "start": "228799",
    "end": "235239"
  },
  {
    "text": "under the hood what the cater looks like so um you know for so ignore the",
    "start": "235239",
    "end": "240920"
  },
  {
    "text": "workload manager for now for a moment everything else is one single batch job right so the user want to submit this",
    "start": "240920",
    "end": "247239"
  },
  {
    "text": "thing into a cluster and then establish all this uh uh interconnection between all the components and then leave it",
    "start": "247239",
    "end": "253680"
  },
  {
    "text": "running and usually the job runs from uh hours to even days so it's a very long",
    "start": "253680",
    "end": "258880"
  },
  {
    "text": "running job and you have a lot of moving parts of course then uh you you you will think this is sort of almost like",
    "start": "258880",
    "end": "265000"
  },
  {
    "text": "orchestration by itself you have the head notes which we call primary notes I have a bunch of uh worker nodes which we",
    "start": "265000",
    "end": "271039"
  },
  {
    "text": "call remote nodes and then you place all the processes on the remote nodes there are compute processes that's the number",
    "start": "271039",
    "end": "277199"
  },
  {
    "text": "crunching uh there's scheduling processes that's the the dynamic load balancing try to move the load across",
    "start": "277199",
    "end": "282880"
  },
  {
    "text": "all these uh computer processes and then you have all the data processes which facilitate the information exchange",
    "start": "282880",
    "end": "289039"
  },
  {
    "text": "between the all the compute uh processes and serve as a temporary storage some of",
    "start": "289039",
    "end": "294199"
  },
  {
    "text": "them are fail safe so if you lose a computer process you can still crawl along you get run a little slower but",
    "start": "294199",
    "end": "300960"
  },
  {
    "text": "your jobs can still run to finish but some of them if you fail the whole job is done and not only that usually our",
    "start": "300960",
    "end": "307759"
  },
  {
    "text": "user is very critical on the uh turnaround time so you want this to finish as fast as possible right so uh",
    "start": "307759",
    "end": "314080"
  },
  {
    "text": "then there is also Dynamic adjustments for the resource because Computing resource is very scarce usually the uh",
    "start": "314080",
    "end": "320440"
  },
  {
    "text": "the cluster running our software is saturated so you if you have a high priority job comes in you probably want",
    "start": "320440",
    "end": "327280"
  },
  {
    "text": "say okay let that job spit out some cores so I can squeeze it in this job",
    "start": "327280",
    "end": "332479"
  },
  {
    "text": "let it run finish and then return the core back to that job instead of getting that job all right because that job may",
    "start": "332479",
    "end": "337880"
  },
  {
    "text": "be already running for a day I don't want to kill it I want to keep it crawling for a few hours so my high priority job can go through and then let",
    "start": "337880",
    "end": "345080"
  },
  {
    "text": "it pick up speed so so all of these so all of these requirements I elicited",
    "start": "345080",
    "end": "350280"
  },
  {
    "text": "down here these are are sort of a soloft the problem predated kubernetes now the problem is how to run these on on",
    "start": "350280",
    "end": "357120"
  },
  {
    "text": "kubernetes how to sort of measure this uh scheduler with kubernetes scheduler",
    "start": "357120",
    "end": "363039"
  },
  {
    "text": "right so the uh kubernetes jobs um is not going to really do the work and so",
    "start": "363039",
    "end": "368240"
  },
  {
    "text": "the solution is we build operator we create our own crd we create our own controller uh and we Implement all this",
    "start": "368240",
    "end": "374800"
  },
  {
    "text": "logic is in there and of course there is a set of you know challenges that we go you know we have to resolve okay so at",
    "start": "374800",
    "end": "382160"
  },
  {
    "text": "this point I'll turn it back to luk and talk about how we resolve these thanks so yeah so the idea is we have this uh",
    "start": "382160",
    "end": "389720"
  },
  {
    "text": "very lightweight piece of software joking and we need to move it like on kubernetes so um for that we have been",
    "start": "389720",
    "end": "397560"
  },
  {
    "text": "facing like many types of problems and we are going to provide like some solutions that we gave uh to this",
    "start": "397560",
    "end": "403440"
  },
  {
    "text": "problem so maybe you will be able to reuse some of those just till those um so yeah the idea here the first problem",
    "start": "403440",
    "end": "410919"
  },
  {
    "text": "to solve here is uh this workload is composed of many different moving parts and this has to be have to be connected",
    "start": "410919",
    "end": "417800"
  },
  {
    "text": "at specific internal States so um just a backtrack to the high level overview I",
    "start": "417800",
    "end": "423120"
  },
  {
    "text": "have a master process and I have uh worker processes we call them uh primary",
    "start": "423120",
    "end": "428360"
  },
  {
    "text": "and remotes the workers basically compos a distributed computing framework uh that is being used and leverage uh to",
    "start": "428360",
    "end": "435800"
  },
  {
    "text": "schedule operations by the master by the primary and uh but and I have also",
    "start": "435800",
    "end": "440879"
  },
  {
    "text": "different types of remotes so and these different types of remotes are basically accepted by the primary only at this at",
    "start": "440879",
    "end": "448360"
  },
  {
    "text": "a specific insurance States so this means that the application Demands a stateful",
    "start": "448360",
    "end": "453759"
  },
  {
    "text": "orchestration uh so this means that the operator itself that we are going to develop depends in this kind of",
    "start": "453759",
    "end": "459800"
  },
  {
    "text": "reconciliation logic from the application State itself this is not a common uh kind of scenario that you",
    "start": "459800",
    "end": "466680"
  },
  {
    "text": "generally see for operators operators generally are designed to be stateless in amp poent they basically read from",
    "start": "466680",
    "end": "472319"
  },
  {
    "text": "the kubernetes API the status of the resources they build their internal status and they take action based on the",
    "start": "472319",
    "end": "477599"
  },
  {
    "text": "build and cach the status right so we want to fall back to that use case uh to that use model how did we do we thought",
    "start": "477599",
    "end": "484759"
  },
  {
    "text": "about like just mapping finding a way to map the application state to kubernetes API so in that way we fall back to the",
    "start": "484759",
    "end": "491400"
  },
  {
    "text": "standard use model right um how can we do that how could we do is so basically",
    "start": "491400",
    "end": "497479"
  },
  {
    "text": "the idea is uh we can still like the concepts of um what's being done for",
    "start": "497479",
    "end": "503120"
  },
  {
    "text": "example by the CU cuets cuet solves some sort of similar problem so among like other dozens of functionalities",
    "start": "503120",
    "end": "509879"
  },
  {
    "text": "implemented within them uh but the idea is that the CU basically controls the container and exe creation and execution",
    "start": "509879",
    "end": "517479"
  },
  {
    "text": "by interacting through the container runtime interface uh so it knows the state of the containers theirself right",
    "start": "517479",
    "end": "524159"
  },
  {
    "text": "uh and this is not this doesn't this is not information that that comes directly from kubernetes it comes from the",
    "start": "524159",
    "end": "529959"
  },
  {
    "text": "container engine itself so whenever is basically aware becomes aware of of this state it takes care of mapping this",
    "start": "529959",
    "end": "536920"
  },
  {
    "text": "state to kubernetes so that this this state becomes available for all our controllers so that they can trigger",
    "start": "536920",
    "end": "543040"
  },
  {
    "text": "reconciles uh based on on this information this is possible because the CU BL is also a kubernetes client itself",
    "start": "543040",
    "end": "550279"
  },
  {
    "text": "okay so it interacts with the API by itself so can we do something similar",
    "start": "550279",
    "end": "555640"
  },
  {
    "text": "sure we can uh we can just create an application which kind of behaves in this concern for um like in a similar",
    "start": "555640",
    "end": "562880"
  },
  {
    "text": "way with respect to the cuet so this application we call it like a state server is just an application that runs",
    "start": "562880",
    "end": "568839"
  },
  {
    "text": "as as a side car of our primary process just scrapes the state and serves the",
    "start": "568839",
    "end": "573959"
  },
  {
    "text": "state to the outside world so that another application we call it like a state mapper is able to scrape the state",
    "start": "573959",
    "end": "580160"
  },
  {
    "text": "map it to the kubernetes API so that all our reconciliation loging can happen in",
    "start": "580160",
    "end": "585240"
  },
  {
    "text": "a much more natural um way so how does it map to the final architecture so",
    "start": "585240",
    "end": "591880"
  },
  {
    "text": "basically um we can see here we have like our stateful primary process uh we",
    "start": "591880",
    "end": "597800"
  },
  {
    "text": "have our sidey car trainer which is kind of just getting and parsing the state from um from the primary it's exposing",
    "start": "597800",
    "end": "605360"
  },
  {
    "text": "the state so that the the job controller so it's basically the entity obstructing our whole orchestration for the job can",
    "start": "605360",
    "end": "613120"
  },
  {
    "text": "take action based on that and it reads the state from the kubernetes API right",
    "start": "613120",
    "end": "618160"
  },
  {
    "text": "so the only thing that the job controller has to do is just basically to um create batches of PODS depending",
    "start": "618160",
    "end": "626040"
  },
  {
    "text": "on the state of which is read from the cubern is API uh I'm saying only but",
    "start": "626040",
    "end": "631720"
  },
  {
    "text": "it's kind of um yeah it's kind of um um I'm talking small about that because",
    "start": "631720",
    "end": "637839"
  },
  {
    "text": "like actually The Botch that we we we end up creating are a very big scale uh",
    "start": "637839",
    "end": "643560"
  },
  {
    "text": "um list of objects so we are talking about like dozens of thousands of pods for every bash that we create so um we",
    "start": "643560",
    "end": "651480"
  },
  {
    "text": "need to kind of have a little bit of an attention also on this inner uh control",
    "start": "651480",
    "end": "656959"
  },
  {
    "text": "Loop because um yeah it's it's very much a problem can become very much a problem",
    "start": "656959",
    "end": "662040"
  },
  {
    "text": "in cluster which are not managed by us so how can we make this part as light as",
    "start": "662040",
    "end": "667880"
  },
  {
    "text": "possible so and as efficient as possible still satisfying the functional requirements so the first uh",
    "start": "667880",
    "end": "675079"
  },
  {
    "text": "recommendation I could do is I could give is just if your use model kind of",
    "start": "675079",
    "end": "680399"
  },
  {
    "text": "fits what you need to do um you can just use the bash API uh just the the native",
    "start": "680399",
    "end": "687440"
  },
  {
    "text": "uh the native uh job control which is comes for free basically in in the kubernetes API that has been done like",
    "start": "687440",
    "end": "694920"
  },
  {
    "text": "um an amazing job by the by the botw group lately uh it supports submitting",
    "start": "694920",
    "end": "700360"
  },
  {
    "text": "and scaling up to 10K uh 1000 yeah sorry 100,000 um pods so it's very efficient",
    "start": "700360",
    "end": "708240"
  },
  {
    "text": "very flexible and is trying I I see the worker is trying to capture as much as possible all the possible HPC AI type of",
    "start": "708240",
    "end": "716600"
  },
  {
    "text": "and batch type of workloads so if it fits just use this one in our case we",
    "start": "716600",
    "end": "722079"
  },
  {
    "text": "wanted to hurt ourselves so we wanted to play with the uh we wanted to kind of",
    "start": "722079",
    "end": "727279"
  },
  {
    "text": "implemented a lower level uh budge controllers because we wanted to be able to tweak with specific uh uh features of",
    "start": "727279",
    "end": "734560"
  },
  {
    "text": "the of the of the of the scale up and down for example of the of the pods um",
    "start": "734560",
    "end": "741160"
  },
  {
    "text": "one one one thing that we wanted to implement for example we wanted to be able to when during the scale D of a job",
    "start": "741160",
    "end": "746959"
  },
  {
    "text": "we are talking about like highly Dynamic jobs so these jobs are able to kind of just scale up and down depending on the",
    "start": "746959",
    "end": "752639"
  },
  {
    "text": "demand of the primary which knows the parallelization that it can get to optimize the workload so basically one",
    "start": "752639",
    "end": "759839"
  },
  {
    "text": "thing that we wanted to do for example is just to be able to scale down um the",
    "start": "759839",
    "end": "765240"
  },
  {
    "text": "and remove the pods uh from the same nodes or for specific nodes so have control on which nodes we were deleting",
    "start": "765240",
    "end": "772040"
  },
  {
    "text": "the pods from so that we could basically empty out some nodes before and they were being able to be reclined by the",
    "start": "772040",
    "end": "779079"
  },
  {
    "text": "autoscaler before while if we just scale down randomly like um yeah we cannot",
    "start": "779079",
    "end": "784279"
  },
  {
    "text": "have control on that so we have fragmentation of the pods across um across the the different nodes uh",
    "start": "784279",
    "end": "790720"
  },
  {
    "text": "another thing uh so we since we are basically rolling this out at a customer side we wanted to offload this part of",
    "start": "790720",
    "end": "797959"
  },
  {
    "text": "the job which is kind of a heavy part kind of moving all these parts from the customer side and just have it within",
    "start": "797959",
    "end": "804680"
  },
  {
    "text": "our own domain so uh our own package we we can we can kind of provide observability on that and and yeah it",
    "start": "804680",
    "end": "812160"
  },
  {
    "text": "becomes so much easier to maintain uh for us um also implements custom status",
    "start": "812160",
    "end": "817760"
  },
  {
    "text": "information and other requirements which are dictated by the manager which which is interacting with this component so",
    "start": "817760",
    "end": "825720"
  },
  {
    "text": "where did we start how what what did we go um so basically um we didn't we",
    "start": "825720",
    "end": "831279"
  },
  {
    "text": "didn't do anything fancy like we we basically started from the standard Cube Builder scaffolding uh we made use of",
    "start": "831279",
    "end": "837839"
  },
  {
    "text": "controller runtime like Library two words on that uh for people that don't know uh what it is yet it's just a",
    "start": "837839",
    "end": "843600"
  },
  {
    "text": "library um um which is basically I would say like it's but included that it",
    "start": "843600",
    "end": "849720"
  },
  {
    "text": "contains a lot of very useful function for creating very efficiently and very flexibly your own controllers uh you can",
    "start": "849720",
    "end": "856600"
  },
  {
    "text": "see the full architecture at the left the components that we are going to talk about the ones that we are going to",
    "start": "856600",
    "end": "862560"
  },
  {
    "text": "optimize within the next slides are the ones that you can see on the right so basically quick uh picture on the",
    "start": "862560",
    "end": "869040"
  },
  {
    "text": "architecture and how it this basically this Library interacts with the API server so I have my API server right in",
    "start": "869040",
    "end": "875440"
  },
  {
    "text": "the sky I have like my my clients which are sitting within the controller itself",
    "start": "875440",
    "end": "881160"
  },
  {
    "text": "so um the first component that we're going to watch is the reflector reflector just as the name says kind of",
    "start": "881160",
    "end": "886720"
  },
  {
    "text": "mirrors the resources that uh the controller is watching and that are",
    "start": "886720",
    "end": "891800"
  },
  {
    "text": "contained within the um etcd and kind of exposed through the API server right um",
    "start": "891800",
    "end": "898720"
  },
  {
    "text": "so to do so for example and we are going to focus especially on list and watch",
    "start": "898720",
    "end": "903880"
  },
  {
    "text": "request because those are the heavier ones especially when you go like 10,000 pods those are very heavy when you're",
    "start": "903880",
    "end": "910639"
  },
  {
    "text": "dealing with the yeah when on the on the API server side uh so a um a reflector",
    "start": "910639",
    "end": "917480"
  },
  {
    "text": "under the hood is based on HTTP client simple standard HTTP client which keeps",
    "start": "917480",
    "end": "923079"
  },
  {
    "text": "open and http2 or web websocket connection with ap API server so that it",
    "start": "923079",
    "end": "929600"
  },
  {
    "text": "can basically keep this channel open and be notified Whenever there is a change to any type of watch resource so um when",
    "start": "929600",
    "end": "937199"
  },
  {
    "text": "this is reflected where is it reflected is reflected within the uh a local cache",
    "start": "937199",
    "end": "942240"
  },
  {
    "text": "uh the cach is just a something anything that can you can Implement your own cache if you want um it's something that",
    "start": "942240",
    "end": "948399"
  },
  {
    "text": "implements the Informer interface and uh yeah it's just caching as the name says uh the the changes and the resource",
    "start": "948399",
    "end": "955160"
  },
  {
    "text": "itself and on Downstream to the cache I can have predicates so predicates are",
    "start": "955160",
    "end": "960360"
  },
  {
    "text": "just filtering functions that you can set up so that you can you can just basically trigger your reconcile logic",
    "start": "960360",
    "end": "966800"
  },
  {
    "text": "based on the events that you are actually interested in so you may just discard the ones that you don't care",
    "start": "966800",
    "end": "972839"
  },
  {
    "text": "about and then you have your reconciler which is where the magic happens you basically watch the state and you build",
    "start": "972839",
    "end": "977959"
  },
  {
    "text": "a new state and you you based on the desired State you decide the actions that you you may take on the cluster so",
    "start": "977959",
    "end": "983440"
  },
  {
    "text": "just for example creating the pods if they are not there so um yeah simple",
    "start": "983440",
    "end": "989160"
  },
  {
    "text": "functionality but uh quite complicated architecture so you want to be able to",
    "start": "989160",
    "end": "994319"
  },
  {
    "text": "observe what is going on right it's a kind of a sophisticated interaction this one and there is not so much uh",
    "start": "994319",
    "end": "1000680"
  },
  {
    "text": "information around that we can find about like how to troubleshoot it better API server side there is information",
    "start": "1000680",
    "end": "1007240"
  },
  {
    "text": "it's there is auditing you can set it up like very flexibly um yeah basically you",
    "start": "1007240",
    "end": "1013000"
  },
  {
    "text": "can just discriminate like whatever specifically what exactly what you want to watch uh the pods like specific verbs",
    "start": "1013000",
    "end": "1021160"
  },
  {
    "text": "so it's very flexible and very powerful server side matric there are a ton of server matric exposed um through the",
    "start": "1021160",
    "end": "1028678"
  },
  {
    "text": "metrix server um so the ones that you generally want to have a look at are the one related to API priority and fairness",
    "start": "1028679",
    "end": "1035480"
  },
  {
    "text": "so concurrency limitting use and how much latency your requests are generally",
    "start": "1035480",
    "end": "1040600"
  },
  {
    "text": "taken uh to get back so these are kind of the main ones that we have a look at",
    "start": "1040600",
    "end": "1046120"
  },
  {
    "text": "client side um it's kind of a blurry area like we couldn't find so much so we",
    "start": "1046120",
    "end": "1051160"
  },
  {
    "text": "thought about putting together a SL to talk about that um so uh first of all uh",
    "start": "1051160",
    "end": "1056720"
  },
  {
    "text": "you want to watch exactly which request you are doing to the API server right stupid thing but what is that you you do",
    "start": "1056720",
    "end": "1063400"
  },
  {
    "text": "you turn up logging so all these libraries I think also client go supports um is based um on on global",
    "start": "1063400",
    "end": "1070760"
  },
  {
    "text": "singl tone loggers so you can just set up the the verbos to to to a higher level just dump any request and this",
    "start": "1070760",
    "end": "1077480"
  },
  {
    "text": "will basically dump any request and response that your client gets uh one note though this won't dump uh the",
    "start": "1077480",
    "end": "1084880"
  },
  {
    "text": "actual events change events that are flowing through the network why because the the connection is never closed so",
    "start": "1084880",
    "end": "1090960"
  },
  {
    "text": "the read closer of the client is never is never finalizing the body so you won't be seeing this stuff how do I get",
    "start": "1090960",
    "end": "1097880"
  },
  {
    "text": "to see this stuff if I want to um the first way you can just hook up after the",
    "start": "1097880",
    "end": "1103120"
  },
  {
    "text": "cach as we showed you can Implement your own just little predicate dump like a",
    "start": "1103120",
    "end": "1108360"
  },
  {
    "text": "predicate function which just logs all the events so you can see what is going on after the cach but if you want to if",
    "start": "1108360",
    "end": "1114679"
  },
  {
    "text": "you don't trust anybody and you want to have a look at preach what is going on you can this is a kind of a hacky",
    "start": "1114679",
    "end": "1120720"
  },
  {
    "text": "approach I know but it works you can just uh chop basically on top of the TCP",
    "start": "1120720",
    "end": "1125760"
  },
  {
    "text": "level on the HTTP round Tripper you can Implement your own round Tripper and just yeah just hook up and have a look",
    "start": "1125760",
    "end": "1132480"
  },
  {
    "text": "at everything that is flowing through the network clearly you need to have Json encoding for that because if you",
    "start": "1132480",
    "end": "1137919"
  },
  {
    "text": "have other stuff or if you have encryption you you won't be able to see that no correct I'm I'm going to correct",
    "start": "1137919",
    "end": "1143799"
  },
  {
    "text": "myself I think this hooks up after the decryption so you can still be able to see it uh all this stuff was kind of",
    "start": "1143799",
    "end": "1151440"
  },
  {
    "text": "development material production wise Matrix so um the scaffold the default CU",
    "start": "1151440",
    "end": "1157120"
  },
  {
    "text": "Builder scaffolding comes for comes with like a lot of um like um Prometheus",
    "start": "1157120",
    "end": "1162360"
  },
  {
    "text": "endpoint which is serving a lot of interesting metrics for all the levels of the stack that I showed before so",
    "start": "1162360",
    "end": "1167919"
  },
  {
    "text": "where R client and reflector so you may be able to get really interesting information about what go what is going",
    "start": "1167919",
    "end": "1174440"
  },
  {
    "text": "on to your controller even in production so now I have the tools uh what do I do",
    "start": "1174440",
    "end": "1180440"
  },
  {
    "text": "with these tools definitely not what the lady is doing here so we got to watch in the right way um how do I do it um first",
    "start": "1180440",
    "end": "1188640"
  },
  {
    "text": "thing we need to consider we have so we have a ton of resources ton of events flowing back and forth around the",
    "start": "1188640",
    "end": "1194440"
  },
  {
    "text": "network so I want to protect basically first of first thing like the controller",
    "start": "1194440",
    "end": "1199960"
  },
  {
    "text": "from uh the things that it's it's not interested about right so first thing I can do I can for example uh set up like",
    "start": "1199960",
    "end": "1207880"
  },
  {
    "text": "the controller itself uh so that it's only watching the events sorry is only",
    "start": "1207880",
    "end": "1213360"
  },
  {
    "text": "reconciling on the events uh that are concerning uh to himself right I I'm I'm",
    "start": "1213360",
    "end": "1218520"
  },
  {
    "text": "kind of just watching uh specific type of resources and I'm kind of disregarding anything else on top of",
    "start": "1218520",
    "end": "1224360"
  },
  {
    "text": "that I may even even uh just reconciling uh on specific types of resources I may",
    "start": "1224360",
    "end": "1230120"
  },
  {
    "text": "not be interested in all the types of events so I may set up predicates that just reconcile on for example deletion",
    "start": "1230120",
    "end": "1236600"
  },
  {
    "text": "events or creation events depending on what my specific application demand is",
    "start": "1236600",
    "end": "1242760"
  },
  {
    "text": "this is useful again for protecting controller from the kind of the Wilderness but how do I protect like the",
    "start": "1242760",
    "end": "1250159"
  },
  {
    "text": "API server from the controller because that's another thing because the controller itself when it when when I'm",
    "start": "1250159",
    "end": "1255520"
  },
  {
    "text": "watching and listing 10,000 resources for like a thousand jobs it may very",
    "start": "1255520",
    "end": "1261600"
  },
  {
    "text": "easily overload API server and not all the managed environments are set up to tolerate that amount of of of requests",
    "start": "1261600",
    "end": "1268679"
  },
  {
    "text": "right so the first thing I I need to do is just watch at the lower level so",
    "start": "1268679",
    "end": "1274080"
  },
  {
    "text": "under before the cache at the HTTP client level exactly the resources which",
    "start": "1274080",
    "end": "1279520"
  },
  {
    "text": "are concerning are which might con my controller is concerned about so uh I",
    "start": "1279520",
    "end": "1285320"
  },
  {
    "text": "need to basically set up a labeling system that allows me to just uh watch",
    "start": "1285320",
    "end": "1290480"
  },
  {
    "text": "the label resources that controller uh needs to be aware of in this example I",
    "start": "1290480",
    "end": "1295720"
  },
  {
    "text": "have a pod inside of the name same namespace which is not it doesn't have anything to do with the controller",
    "start": "1295720",
    "end": "1301080"
  },
  {
    "text": "itself uh with the yeah with my resources as well is kind of a a part of",
    "start": "1301080",
    "end": "1306200"
  },
  {
    "text": "somebody else and since it's not labeled I'm not watching it so easy but like",
    "start": "1306200",
    "end": "1311279"
  },
  {
    "text": "powerful and this thing is also powerful if we want to go like in advanced functionality and for example I want to",
    "start": "1311279",
    "end": "1317240"
  },
  {
    "text": "implement oper operator Shing just imagine just imagine that my controller Shing better so just imagine my",
    "start": "1317240",
    "end": "1323600"
  },
  {
    "text": "controller itself is only watching a subset of resources or one instance of the controller while another controller",
    "start": "1323600",
    "end": "1329760"
  },
  {
    "text": "is watching another subset and these sets are basically labeled with indexes",
    "start": "1329760",
    "end": "1335120"
  },
  {
    "text": "so I can Implement pretty Advanced functionality and we are thinking about like putting some work on that as well",
    "start": "1335120",
    "end": "1341400"
  },
  {
    "text": "uh even more extreme uh I'm not interested I may not be interested in the actual status of my of my child pods",
    "start": "1341400",
    "end": "1348760"
  },
  {
    "text": "so I may just be interested with the in the fact that they are there or like yeah for example I can get the status of",
    "start": "1348760",
    "end": "1356159"
  },
  {
    "text": "the job from the pro the primary process right so in that case I can set up I can",
    "start": "1356159",
    "end": "1361400"
  },
  {
    "text": "go even a longer way and I can just watch The Meta data of these pods and this ends up saving quite a lot of uh",
    "start": "1361400",
    "end": "1368240"
  },
  {
    "text": "bandwidth on the network as well so it's my point was just like it's extremely uh",
    "start": "1368240",
    "end": "1374200"
  },
  {
    "text": "flexible and configurable and uh yeah just dig like the seource code because",
    "start": "1374200",
    "end": "1379360"
  },
  {
    "text": "there are a ton of Eden functionality which are not brily available when you read the doc some sometime um so that",
    "start": "1379360",
    "end": "1387480"
  },
  {
    "text": "said assuming you kind of implement all these optimizations um you still may have a",
    "start": "1387480",
    "end": "1393919"
  },
  {
    "text": "problem because you have you still have like a ton of PODS within the cluster and the the thing that I want to say is",
    "start": "1393919",
    "end": "1399400"
  },
  {
    "text": "like you're you may not be the only one watching so you may have like cni controllers you may have uh mutating web",
    "start": "1399400",
    "end": "1406440"
  },
  {
    "text": "Hoops that every time that you roll you create a pod where a new resource basically are triggered and are are",
    "start": "1406440",
    "end": "1412480"
  },
  {
    "text": "basically managed by somebody else so you there is always this underlying assumption that somebody else is doing a",
    "start": "1412480",
    "end": "1418000"
  },
  {
    "text": "good job at kind of managing all this stuff right um so what you can what what what could",
    "start": "1418000",
    "end": "1423840"
  },
  {
    "text": "we do to basically um make make this thing lighter right um and and more more",
    "start": "1423840",
    "end": "1429279"
  },
  {
    "text": "efficient so we thought about like uh our pod for us is just an obstruction of a Computing unit uh within our our or",
    "start": "1429279",
    "end": "1437919"
  },
  {
    "text": "our whole job so can we just make this Computing unit uh bigger so can we just",
    "start": "1437919",
    "end": "1443559"
  },
  {
    "text": "pack multiple workers for example within the same pod and still get the same functionality so functionally clearly",
    "start": "1443559",
    "end": "1450159"
  },
  {
    "text": "this works and also this thing ends up saving quite a lot of bandwidth uh so",
    "start": "1450159",
    "end": "1456000"
  },
  {
    "text": "the at the right you can see the watch uh the the watch bandwidth which was consumed through a whole um yeah through",
    "start": "1456000",
    "end": "1463679"
  },
  {
    "text": "all kind of a creation of I think 10 10K workers here uh so we end we we end up",
    "start": "1463679",
    "end": "1469120"
  },
  {
    "text": "saving like as much as four times more more bandwidth by packing like four four remotes inside of the same container and",
    "start": "1469120",
    "end": "1475600"
  },
  {
    "text": "the same pod clearly you may say okay this is not without any consequence so",
    "start": "1475600",
    "end": "1481039"
  },
  {
    "text": "clearly the Pod itself becomes bulkier um the failure modes for um the failure",
    "start": "1481039",
    "end": "1487520"
  },
  {
    "text": "conditions for these pods become harder to to basically set up because like what if just one one one worker fails what do",
    "start": "1487520",
    "end": "1494440"
  },
  {
    "text": "I need to do do I I need to get the whole part to fail so these kind of things become a little bit more",
    "start": "1494440",
    "end": "1500039"
  },
  {
    "text": "complicated but still manageable if you want to the thing that doesn't become so much easier is the scheding itself",
    "start": "1500039",
    "end": "1506480"
  },
  {
    "text": "because we are talking about like um pretty bulky U processes so if you",
    "start": "1506480",
    "end": "1511720"
  },
  {
    "text": "basically P many many of these processes without within a single pod and you",
    "start": "1511720",
    "end": "1517480"
  },
  {
    "text": "clearly have to rise the requests you make the scheduling less efficient and a little bit more complicated so for",
    "start": "1517480",
    "end": "1523120"
  },
  {
    "text": "example we have seen that after three four workers inside of the same um the",
    "start": "1523120",
    "end": "1528279"
  },
  {
    "text": "same container the same pod um and the same pod we start to basically see",
    "start": "1528279",
    "end": "1533320"
  },
  {
    "text": "degradations in the scheduling efficiency okay this is clearly dependent on on a number of factors but",
    "start": "1533320",
    "end": "1539120"
  },
  {
    "text": "this is what we've seen um so yeah with these things we basically have kind of",
    "start": "1539120",
    "end": "1545720"
  },
  {
    "text": "optimized a little bit anything we could to make uh this bulky workload a little bit lighter to part and to move across",
    "start": "1545720",
    "end": "1552399"
  },
  {
    "text": "the Clusters uh what what is the user experience for the for the user itself how does it Sumit the job so as expected",
    "start": "1552399",
    "end": "1559640"
  },
  {
    "text": "it we they have a job um um job resarch um one thing is like since it's kind of",
    "start": "1559640",
    "end": "1567120"
  },
  {
    "text": "composed of different type of uh of remotes this may be may become a little",
    "start": "1567120",
    "end": "1573279"
  },
  {
    "text": "bit two verbos like imagine like you have a bulky uh yamos spec okay it's",
    "start": "1573279",
    "end": "1579000"
  },
  {
    "text": "nice that it's just plug and play you you just submit it and it creates everything but it's really a big big",
    "start": "1579000",
    "end": "1584880"
  },
  {
    "text": "thing so we thought about like kind of using um and this is something that me came up to with actually like a very",
    "start": "1584880",
    "end": "1591760"
  },
  {
    "text": "interesting model where you basically can have a specific section of the yaml which is kind of a common base and then",
    "start": "1591760",
    "end": "1598559"
  },
  {
    "text": "like you have other subsections specific to all the types of pot that basically inherit and override the section so we",
    "start": "1598559",
    "end": "1605559"
  },
  {
    "text": "kind of played with the yaml a little bit and the result is something a little bit more is kind of still super",
    "start": "1605559",
    "end": "1611559"
  },
  {
    "text": "expressive but kind of uh a little bit smaller to manage and easier to read uh",
    "start": "1611559",
    "end": "1616880"
  },
  {
    "text": "as well and at the same time we kept the possibility to just inject uh sidey car",
    "start": "1616880",
    "end": "1622080"
  },
  {
    "text": "containers um freely so that we and the customer itself is able to just extend",
    "start": "1622080",
    "end": "1628399"
  },
  {
    "text": "the functionality and and make it much more uh extensible in general uh",
    "start": "1628399",
    "end": "1633960"
  },
  {
    "text": "performance- wise we have doing test we've been doing test across all our products uh unsurprisingly we had like",
    "start": "1633960",
    "end": "1640520"
  },
  {
    "text": "parity of performance one thing that you want you may want to be aware of is that",
    "start": "1640520",
    "end": "1646039"
  },
  {
    "text": "when we started to play with kind of security features so for example there is this ccom default uh feature of uh",
    "start": "1646039",
    "end": "1653240"
  },
  {
    "text": "the cuets that basically just enable CM uh functionality cm is a Cisco filtering",
    "start": "1653240",
    "end": "1659960"
  },
  {
    "text": "uh functionality that happens right at the border of the kernel um when we",
    "start": "1659960",
    "end": "1665360"
  },
  {
    "text": "enabled that we got a substantial performance degradation on specific workloads the reason is this wasn't",
    "start": "1665360",
    "end": "1672360"
  },
  {
    "text": "definitely easy to find out on specific operating systems and specific kernel versions uh basically cm is tied to",
    "start": "1672360",
    "end": "1680399"
  },
  {
    "text": "another um security mitigation functionality which is called stip which is speculative star bypass so whenever",
    "start": "1680399",
    "end": "1687960"
  },
  {
    "text": "that one is enabled basically the branch prediction capabilities of the processor between logical cores in in smt um",
    "start": "1687960",
    "end": "1696279"
  },
  {
    "text": "functionality is basically disabled so this means that very CPU intensive workloads end up having like quite",
    "start": "1696279",
    "end": "1702640"
  },
  {
    "text": "substantial performance degradation even worse uh this functionality um I take",
    "start": "1702640",
    "end": "1709279"
  },
  {
    "text": "take me for granted but like verify this but it it should be enabled by default after kubernetes",
    "start": "1709279",
    "end": "1715919"
  },
  {
    "text": "1.27 so if you are seeing running kind of computer intensive applications and seeing performance",
    "start": "1715919",
    "end": "1722200"
  },
  {
    "text": "degradations this may be the reason just have a look at that um so last thing uh",
    "start": "1722200",
    "end": "1728679"
  },
  {
    "text": "we want to cover because we cover much of the lower level of our stock this is a pretty much a work in progress but the",
    "start": "1728679",
    "end": "1735559"
  },
  {
    "text": "uh direction that we are uh we are we really want to follow so um how do we",
    "start": "1735559",
    "end": "1741840"
  },
  {
    "text": "basically okay I I managed to have my workload to run on kubernetes in a lighter way and and and so on and so",
    "start": "1741840",
    "end": "1747399"
  },
  {
    "text": "forth but how do I enable multi-tenancy with respect to the resources which sits",
    "start": "1747399",
    "end": "1752960"
  },
  {
    "text": "under my workload so we are basically working to integrate with a project called q and Q has two very nice",
    "start": "1752960",
    "end": "1759279"
  },
  {
    "text": "features the first one is that um it doesn't touch anything concerning the scheduling so it's just something that",
    "start": "1759279",
    "end": "1765480"
  },
  {
    "text": "you can install on top and you can can basically manage your quotas and your resources on top of what is already",
    "start": "1765480",
    "end": "1771880"
  },
  {
    "text": "existing the other one is that is is exposing a very generic uh workload",
    "start": "1771880",
    "end": "1777480"
  },
  {
    "text": "customer source that you can basically use as an interface so that you can announce your workload type to to q and",
    "start": "1777480",
    "end": "1784840"
  },
  {
    "text": "Q will be able to just you will just be able to use the full functionality so your controllers just have to announce",
    "start": "1784840",
    "end": "1791760"
  },
  {
    "text": "to create like this workload resource whenever you you you receive um you are reconciling a job and the Q will take",
    "start": "1791760",
    "end": "1798720"
  },
  {
    "text": "care of just taking the admission decision if it will be basically admitting the workload to to to your",
    "start": "1798720",
    "end": "1805000"
  },
  {
    "text": "queue or not um yeah functionally you can just label like your your resources",
    "start": "1805000",
    "end": "1810880"
  },
  {
    "text": "as as your nodes as different resource flavors and you can map them out to a cluster queue and you can basically map",
    "start": "1810880",
    "end": "1817840"
  },
  {
    "text": "your kind of organization your teams to specific local cues which are basically",
    "start": "1817840",
    "end": "1823360"
  },
  {
    "text": "research managed against the cluster queue and um the qu values that you decide to set uh so yeah this basically",
    "start": "1823360",
    "end": "1830840"
  },
  {
    "text": "covers pretty much the work that we uh that we have done there is really a lot",
    "start": "1830840",
    "end": "1836080"
  },
  {
    "text": "of other uh smaller details that we don't have the time to talk about uh but",
    "start": "1836080",
    "end": "1841360"
  },
  {
    "text": "yeah so I think this basically covers uh pretty much what we did so thanks for",
    "start": "1841360",
    "end": "1848200"
  },
  {
    "text": "the attention span and yeah hopefully the last session uh will be yeah I think",
    "start": "1848200",
    "end": "1854480"
  },
  {
    "text": "we have time to take questions so there is a mic in the center",
    "start": "1854480",
    "end": "1859240"
  },
  {
    "text": "uh does this integrate uh with traditional scheduling systems like slurm or PBS in any way so um basically",
    "start": "1870600",
    "end": "1880360"
  },
  {
    "text": "um let's say Q is exactly is is not exactly a replacement it's something you",
    "start": "1880360",
    "end": "1886039"
  },
  {
    "text": "can use with um the the the with some existing schedulers okay uh but like",
    "start": "1886039",
    "end": "1894440"
  },
  {
    "text": "there is some definitely some overlap in the functionality uh we actually came to know like about like other project that",
    "start": "1894440",
    "end": "1901440"
  },
  {
    "text": "make use of slurm and part to kubernetes as well uh but those ones are basically",
    "start": "1901440",
    "end": "1906559"
  },
  {
    "text": "something that kind of where was was born outside and brought inside of kubernetes where Q the nice thing is",
    "start": "1906559",
    "end": "1912240"
  },
  {
    "text": "kind of is conceived from the start very close from a a work Group which is very close to the kubernetes API itself so",
    "start": "1912240",
    "end": "1919919"
  },
  {
    "text": "and it doesn't touch the scheduling layer at all so it just installs on top so we are specifically work on that",
    "start": "1919919",
    "end": "1926360"
  },
  {
    "text": "working on that but we definitely have plans to investigate also like slurm on kubernetes use model because some of our",
    "start": "1926360",
    "end": "1933639"
  },
  {
    "text": "customer definitely demand them you know because this uh the software exists a long time ago right so there a lot of",
    "start": "1933639",
    "end": "1939039"
  },
  {
    "text": "people use the old resource management software right so like lsf great engine",
    "start": "1939039",
    "end": "1944399"
  },
  {
    "text": "uh slurm is relatively new but it's more of the same use model so we we are also",
    "start": "1944399",
    "end": "1949600"
  },
  {
    "text": "keep keeping that in mind and does it make sense to just drop slurm on top of coronates and you live in slurm that was",
    "start": "1949600",
    "end": "1956240"
  },
  {
    "text": "a question actually came up during the uh",
    "start": "1956240",
    "end": "1960080"
  },
  {
    "text": "development any other questions cool uh so if there are no",
    "start": "1965440",
    "end": "1973320"
  },
  {
    "text": "other questions you you can find us around for be the big party after anyways so just feel free to reach out",
    "start": "1973320",
    "end": "1979840"
  },
  {
    "text": "yeah thanks thank you",
    "start": "1979840",
    "end": "1985320"
  }
]
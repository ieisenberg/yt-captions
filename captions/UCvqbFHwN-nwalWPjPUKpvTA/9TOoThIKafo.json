[
  {
    "start": "0",
    "end": "192000"
  },
  {
    "text": "ok everyone I think it's time we'll we'll start now thank you for coming to our talk about sequel processing on kuba",
    "start": "30",
    "end": "7620"
  },
  {
    "text": "knees and doing it easily so my name's",
    "start": "7620",
    "end": "12840"
  },
  {
    "text": "Andrew Stevenson I'm the CTO of land OOP my background is basically data fast 8 a",
    "start": "12840",
    "end": "18390"
  },
  {
    "text": "big data doesn't care what it is but I spent a lot of time in financial markets high frequency trading so it's all about",
    "start": "18390",
    "end": "24420"
  },
  {
    "text": "speed and doing things real-time and we have Antonius hello there my name is",
    "start": "24420",
    "end": "31650"
  },
  {
    "text": "Antonio's I'm co-founder and CEO of land OOP and let's jump straight into the",
    "start": "31650",
    "end": "38250"
  },
  {
    "text": "topic so from a basic data containers like a JSON or even XML to even more",
    "start": "38250",
    "end": "46340"
  },
  {
    "text": "modern data containers like Apache Avro where we get a binary format we get a",
    "start": "46340",
    "end": "52289"
  },
  {
    "text": "data contract between our micro services or our data pipelines we get type type",
    "start": "52289",
    "end": "58230"
  },
  {
    "text": "safety and pipeline safely and we can even have that evolution sequel makes",
    "start": "58230",
    "end": "63930"
  },
  {
    "text": "sense so it makes sense for three different reasons first of all we can",
    "start": "63930",
    "end": "70830"
  },
  {
    "text": "query data whether this is streaming real-time real-time data or historical",
    "start": "70830",
    "end": "76530"
  },
  {
    "text": "data we can also easily beat data integrations let's say I want to be",
    "start": "76530",
    "end": "82290"
  },
  {
    "text": "moving messages storing them into elasticsearch cherry-picking selecting",
    "start": "82290",
    "end": "87750"
  },
  {
    "text": "fields defining the primary keys it just makes sense it also works for a",
    "start": "87750",
    "end": "94650"
  },
  {
    "text": "continuous streaming pipelines we can perform data aggregation so we can be enhancing our data and we can be",
    "start": "94650",
    "end": "101009"
  },
  {
    "text": "building continuous and bounded queries with expressed via sequel and when",
    "start": "101009",
    "end": "107310"
  },
  {
    "text": "everything is stateless it makes sense for us to have our entire streaming ETL",
    "start": "107310",
    "end": "112320"
  },
  {
    "text": "in key but netis have multiple pods for fault tolerance and resilience and",
    "start": "112320",
    "end": "118399"
  },
  {
    "text": "continuously operate data pipelines over kubernetes again when everything is a",
    "start": "118399",
    "end": "125549"
  },
  {
    "text": "configuration we can store it in github we can manage it we can promote from environments from development into UAT",
    "start": "125549",
    "end": "132690"
  },
  {
    "text": "and thing two action in the modern enterprise world we",
    "start": "132690",
    "end": "138569"
  },
  {
    "text": "have multiple data sources and mullet read data sinks and the idea of today's",
    "start": "138569",
    "end": "144120"
  },
  {
    "text": "talk is how can we operate data pipelines via sequel and have a modern",
    "start": "144120",
    "end": "149250"
  },
  {
    "text": "architecture and what about my state the state needs to be managed and for that",
    "start": "149250",
    "end": "156300"
  },
  {
    "text": "we can use a distributed parallel file system like pata Kafka pulsar or not so",
    "start": "156300",
    "end": "165360"
  },
  {
    "text": "a bit of an introduction of who we are we started back in 2016 introducing",
    "start": "165360",
    "end": "170370"
  },
  {
    "text": "sequel layers into Abaza Kafka in the open source with the stream reactor project that has almost 50 Kafka",
    "start": "170370",
    "end": "177180"
  },
  {
    "text": "connectors and we moved on with building lenses that is a industrial-grade set of",
    "start": "177180",
    "end": "182880"
  },
  {
    "text": "tooling for building and operating data pipelines I'm gonna pass on the",
    "start": "182880",
    "end": "187890"
  },
  {
    "text": "microphone to Andrew for for the rest of presentation so i'm sonia stoked a lot",
    "start": "187890",
    "end": "195120"
  },
  {
    "start": "192000",
    "end": "226000"
  },
  {
    "text": "about why sequel is great but we still actually need something to do the sequel processing a lot of we're basically",
    "start": "195120",
    "end": "201450"
  },
  {
    "text": "talking about data pipelines we're talking about moving data around doing manipulation do enrichment on data a lot",
    "start": "201450",
    "end": "207870"
  },
  {
    "text": "of people are running around and saying ETL is dead it's not we're just breaking it apart from a big big monolith into",
    "start": "207870",
    "end": "214260"
  },
  {
    "text": "small and micro services but what do we need for that we need certain aspects we need to get data in we need to transform",
    "start": "214260",
    "end": "220200"
  },
  {
    "text": "the data and we need to potentially get the data out to our long-term stores so",
    "start": "220200",
    "end": "226380"
  },
  {
    "start": "226000",
    "end": "261000"
  },
  {
    "text": "getting the data in so this is the stream reactor project that we started so this is using Kafka Connect which is",
    "start": "226380",
    "end": "233700"
  },
  {
    "text": "one of the API is from Apache Kafka they focus on getting data in and out we have 30 plus connectors they're all open",
    "start": "233700",
    "end": "241019"
  },
  {
    "text": "source you know we do welcome contributions and we also have the Dockers for them as helm charts ready to",
    "start": "241019",
    "end": "246480"
  },
  {
    "text": "go but maybe what differentiates our connectors from some of the others out there is we have a sequel layer in it",
    "start": "246480",
    "end": "251910"
  },
  {
    "text": "this was first sequel layer in Apache Kafka back in 2016 it's not a true",
    "start": "251910",
    "end": "257850"
  },
  {
    "text": "sequel engine this but sequel like so what is it it's a quick-connect query",
    "start": "257850",
    "end": "263610"
  },
  {
    "start": "261000",
    "end": "306000"
  },
  {
    "text": "language so this is what we use in our connectors so imagine you've got lots of different sources that have different",
    "start": "263610",
    "end": "269650"
  },
  {
    "text": "characteristics you may want to use the different features of those connectors so in this case we have case we have",
    "start": "269650",
    "end": "276099"
  },
  {
    "text": "hazel caste which is an in-memory grid here's our caste our different data structures maybe you want to write it",
    "start": "276099",
    "end": "282879"
  },
  {
    "text": "into it into a ring maybe you want to write it into reliable topic so we allow you to write a simple sequel like",
    "start": "282879",
    "end": "289419"
  },
  {
    "text": "configuration to be able to target whatever you want to be able to cherry-pick fields out and write it into",
    "start": "289419",
    "end": "295120"
  },
  {
    "text": "the correct datastore so each different sink will have different grammar attached to it because they all have",
    "start": "295120",
    "end": "301449"
  },
  {
    "text": "different things hazel caste is different to influx for example what connectors do we have well",
    "start": "301449",
    "end": "307930"
  },
  {
    "start": "306000",
    "end": "338000"
  },
  {
    "text": "yeah we have quite a lot where they being used so we have a Cassandra source that's been used by Walmart they're",
    "start": "307930",
    "end": "314110"
  },
  {
    "text": "actually contributing a lot on that the sink is certified by date the stacks we have an elasticsearch sinks or British",
    "start": "314110",
    "end": "320710"
  },
  {
    "text": "Gas in the UK connected homes they do about 5 billion messages a day using our connector there we also have connectors",
    "start": "320710",
    "end": "328719"
  },
  {
    "text": "for pulsar pourcel's very interesting maybe better than Kafka performance wise",
    "start": "328719",
    "end": "334000"
  },
  {
    "text": "it seems to be we'll have to see but the connectors in Cuba need is what does it",
    "start": "334000",
    "end": "340839"
  },
  {
    "start": "338000",
    "end": "393000"
  },
  {
    "text": "actually mean what does it actually look like well CAF could connect has two different modes it has a standalone mode and a had",
    "start": "340839",
    "end": "348580"
  },
  {
    "text": "as a distributed mode in the distributed mode basically starting JVM workers so",
    "start": "348580",
    "end": "354430"
  },
  {
    "text": "that translates into a port they all subscribe to a set of topics in CAF gave",
    "start": "354430",
    "end": "359589"
  },
  {
    "text": "the backing topics they subscribe with the same consumer groups or Kafka sees them as a consumer group which is",
    "start": "359589",
    "end": "366159"
  },
  {
    "text": "effectively your cluster so in queue beneath this we can simply deploy them",
    "start": "366159",
    "end": "371379"
  },
  {
    "text": "as a deployment and have each replica as a port is the actual worker once the",
    "start": "371379",
    "end": "377919"
  },
  {
    "text": "workers are up they basically listen to Kafka for all the actual work that they need to do and then they'll spin up more",
    "start": "377919",
    "end": "385449"
  },
  {
    "text": "consumers for example to write data out into Cassandra elasticsearch or whatever",
    "start": "385449",
    "end": "390460"
  },
  {
    "text": "you want to do so what's good well Cuban eat listen Shu",
    "start": "390460",
    "end": "398430"
  },
  {
    "start": "393000",
    "end": "423000"
  },
  {
    "text": "is that our desired number of workers are there and we can scale up and we can",
    "start": "398430",
    "end": "403680"
  },
  {
    "text": "scale down and the number of workers quite easily and it was also very easy to deploy the good thing about Kafka",
    "start": "403680",
    "end": "410069"
  },
  {
    "text": "connect all the state is stored in Kafka was passing the book off to Kafka it",
    "start": "410069",
    "end": "415259"
  },
  {
    "text": "taken care of the states of workers dying come back it's going to reconstruct all its configuration from",
    "start": "415259",
    "end": "421259"
  },
  {
    "text": "Kafka what's not so good Kafka",
    "start": "421259",
    "end": "426360"
  },
  {
    "start": "423000",
    "end": "528000"
  },
  {
    "text": "rebalancing I don't know if you're aware of how Kafka works but you have consumer groups if you join the group category",
    "start": "426360",
    "end": "433740"
  },
  {
    "text": "balances the workload but it means you stop processing while that rebalance is happening if you leave the group the",
    "start": "433740",
    "end": "440129"
  },
  {
    "text": "same thing applies now if you're outside Cuba needs on VMs in your VM dies your",
    "start": "440129",
    "end": "445889"
  },
  {
    "text": "work dies it's not going to come back that fast in Cuban it is it will so",
    "start": "445889",
    "end": "451979"
  },
  {
    "text": "you'll get a rebalance stop processing when your pod dies and then the pod gets",
    "start": "451979",
    "end": "457469"
  },
  {
    "text": "restarted you get another rebalance so you're getting a lot of rebalances that's something you want to avoid so",
    "start": "457469",
    "end": "464400"
  },
  {
    "text": "how can you avoid that your liveliness probes CAF could connect has a REST API",
    "start": "464400",
    "end": "469909"
  },
  {
    "text": "to tell you what's happening with the state of your connectors inside there so you can use the liveliness probe to say",
    "start": "469909",
    "end": "476849"
  },
  {
    "text": "do I want to make sure that I have my number of workers up and running or am I",
    "start": "476849",
    "end": "482190"
  },
  {
    "text": "happy that something going to fail and Kafka is going to rebalance on to the remaining tasks that are happening",
    "start": "482190",
    "end": "487979"
  },
  {
    "text": "inside there what you can also do in Cuban II is because we can actually spin",
    "start": "487979",
    "end": "493589"
  },
  {
    "text": "up connectors quite easily if you can actually limit the number of connected instances in the cluster so that limits",
    "start": "493589",
    "end": "501120"
  },
  {
    "text": "the disruption on your calf could connect connectors running imagine you've got a cluster running and you've",
    "start": "501120",
    "end": "507240"
  },
  {
    "text": "got ten instances right into elasticsearch writing to Apache CUDA if",
    "start": "507240",
    "end": "513659"
  },
  {
    "text": "you lose Airport you're going to get a rebalance and it's going to affect all those connectors so if you separate the",
    "start": "513659",
    "end": "520440"
  },
  {
    "text": "mountain have one connector per deployment it's a lot it's a lot easier and you limit the disruption",
    "start": "520440",
    "end": "527990"
  },
  {
    "start": "528000",
    "end": "658000"
  },
  {
    "text": "so let's connect this is the sexy bit so",
    "start": "528380",
    "end": "533460"
  },
  {
    "text": "we also have a sequel engine to do the transformation inside and on top of",
    "start": "533460",
    "end": "538770"
  },
  {
    "text": "Kafka so what you want to be able to do is you want to be actually be able to join topics together you want to be able",
    "start": "538770",
    "end": "545190"
  },
  {
    "text": "to aggregate you want to be able to count so how do we do that we use sequel",
    "start": "545190",
    "end": "551790"
  },
  {
    "text": "we go through the Apache color site optimizer that maps down on to Kafka",
    "start": "551790",
    "end": "557070"
  },
  {
    "text": "streams grafica streams is an API it's part of the Apache Kafka distribution so",
    "start": "557070",
    "end": "563580"
  },
  {
    "text": "we actually take our sequel translate that into Scala code it's an actual running then Kafka streams application",
    "start": "563580",
    "end": "570600"
  },
  {
    "text": "that lenses or then monitor and deploy for you we do a bit more than that",
    "start": "570600",
    "end": "576140"
  },
  {
    "text": "because we'll also actually yet let you subscribe with sequel for either historical data or continuous queries on",
    "start": "576140",
    "end": "584670"
  },
  {
    "text": "the casket topics so you can do that by a Gore Lang if you want to we have a go line client we have a Python client",
    "start": "584670",
    "end": "591860"
  },
  {
    "text": "scholar we have a JDBC views JDBC from end javascript react read acts so you",
    "start": "591860",
    "end": "599190"
  },
  {
    "text": "know a lot of trading systems might want to subscribe on FX currency rates on top",
    "start": "599190",
    "end": "604650"
  },
  {
    "text": "of the cafe with sequel they can do that with lenses as well now the nice thing",
    "start": "604650",
    "end": "610800"
  },
  {
    "text": "about sequel is it's configuration if I'm a date scientist I might not know",
    "start": "610800",
    "end": "615990"
  },
  {
    "text": "Scala I might not know Java I might not be familiar with actually building first",
    "start": "615990",
    "end": "621870"
  },
  {
    "text": "my artifact hosting the artifact creating an image creating a helm chart managing all that well see quartz",
    "start": "621870",
    "end": "629040"
  },
  {
    "text": "actually it's just configuration so imagine that you're a dear scientist sitting in Jupiter you're working away",
    "start": "629040",
    "end": "636450"
  },
  {
    "text": "you can actually hit lenses via the Python client we have tell lenses to deploy a sequel processor for you and",
    "start": "636450",
    "end": "643020"
  },
  {
    "text": "then subscribe with a continuous query to get the sequel back out into your jebaited notebook so you can deploy and",
    "start": "643020",
    "end": "650040"
  },
  {
    "text": "manage everything if you want to I'm not saying you're going to do it I'm not a date scientist from Python in a notebook",
    "start": "650040",
    "end": "658250"
  },
  {
    "start": "658000",
    "end": "703000"
  },
  {
    "text": "execution modes how do we do it we actually can run these sequel processes",
    "start": "659160",
    "end": "665020"
  },
  {
    "text": "inside of lenses itself development only really don't want that to be running in",
    "start": "665020",
    "end": "672580"
  },
  {
    "text": "production or we can actually deploy and push it out into CAF can't connect that",
    "start": "672580",
    "end": "678280"
  },
  {
    "text": "is typically if you're not include bonita so we have a lot of enterprise customers still you know ever have their",
    "start": "678280",
    "end": "684490"
  },
  {
    "text": "own data centers etc but more than likely because you're at cube con you're going to be deploying and pushing it out",
    "start": "684490",
    "end": "690390"
  },
  {
    "text": "into air into cuba new so we use the fabricate api behind the scenes to",
    "start": "690390",
    "end": "695740"
  },
  {
    "text": "deploy and monitor and watch what's happening and also then collect the metrics out of the Potters themselves",
    "start": "695740",
    "end": "703410"
  },
  {
    "start": "703000",
    "end": "791000"
  },
  {
    "text": "again what is what does it look like what Kefka streams is just a library it's just a jar application so we can",
    "start": "703410",
    "end": "711460"
  },
  {
    "text": "see it the kubernetes give me three instances of the same application with the same sequel which is just",
    "start": "711460",
    "end": "717580"
  },
  {
    "text": "configuration we can pass in via environment variables and Kafka will do the balancing of the load for us now I",
    "start": "717580",
    "end": "725800"
  },
  {
    "text": "have deployment and stateful setup there because if you're joining and aggregating data you have state what",
    "start": "725800",
    "end": "733900"
  },
  {
    "text": "Kefka streams does is it actually uses rocks DB internally rocks DB use write",
    "start": "733900",
    "end": "739990"
  },
  {
    "text": "data to disk and we also back that data into Kafka so if you have a failure of",
    "start": "739990",
    "end": "746080"
  },
  {
    "text": "your of one processing node of your Kafka stream application and it restarts",
    "start": "746080",
    "end": "751240"
  },
  {
    "text": "on another machine it can rebuild that state from Kafka that's great that's",
    "start": "751240",
    "end": "756580"
  },
  {
    "text": "awesome but what happens if your state is massive what happens if you've got 40 48 gigabytes of state there you could",
    "start": "756580",
    "end": "764170"
  },
  {
    "text": "you could be building up a position report of a messages coming through Kafka and it could be a billion messages",
    "start": "764170",
    "end": "770590"
  },
  {
    "text": "in there it will recover but it can take some time it can bootstrap itself if it",
    "start": "770590",
    "end": "777280"
  },
  {
    "text": "already sees that it has the rocks DB on the local disk so if you use a stateful",
    "start": "777280",
    "end": "782920"
  },
  {
    "text": "set then you get this persistence following you around so you get faster recovery times and faster boot ups again",
    "start": "782920",
    "end": "791660"
  },
  {
    "start": "791000",
    "end": "814000"
  },
  {
    "text": "so I mean this is the important but this is what it looks like this is what we deploy this is a snippet from our helm",
    "start": "791660",
    "end": "798690"
  },
  {
    "text": "chart it's not there's nothing very fancy in here you know we have an environment variable and we push in the",
    "start": "798690",
    "end": "804630"
  },
  {
    "text": "sequel we have the pre-built docker which has added gmx exporter in it for",
    "start": "804630",
    "end": "810360"
  },
  {
    "text": "Prometheus as well that's all we need to do obviously there's a bit magic going",
    "start": "810360",
    "end": "816750"
  },
  {
    "start": "814000",
    "end": "946000"
  },
  {
    "text": "on with the the kind of site optimizer in there but basically what is what it",
    "start": "816750",
    "end": "823020"
  },
  {
    "text": "gives us it means that we can use kubernetes to actually scale out and ensure our desired State how many",
    "start": "823020",
    "end": "831420"
  },
  {
    "text": "consumers do I want running also then we have metrics on there as well we have consumer lag we know what's going on",
    "start": "831420",
    "end": "837930"
  },
  {
    "text": "with the processes so we can then start building intelligence you know you're moving into the realm of a lot more",
    "start": "837930",
    "end": "843600"
  },
  {
    "text": "Casca operators here at the application landscape do I need to scale up do I need to scale down based on what it's",
    "start": "843600",
    "end": "849450"
  },
  {
    "text": "doing Africa's obviously handling the balancing of the data streams for us",
    "start": "849450",
    "end": "854459"
  },
  {
    "text": "it's awesome and configuration is code so we managed now one docker one helm",
    "start": "854459",
    "end": "862200"
  },
  {
    "text": "chart and then we're just managing configuration that we can do and promote",
    "start": "862200",
    "end": "867600"
  },
  {
    "text": "into production just do merge requests into different environments and we deploy our desired state into production",
    "start": "867600",
    "end": "873630"
  },
  {
    "text": "because if you're not getting into production you're not making any money and all your money your business value is generated by doing the business logic",
    "start": "873630",
    "end": "881100"
  },
  {
    "text": "which is things like this so state yes you you will have state so if you do",
    "start": "881100",
    "end": "888870"
  },
  {
    "text": "have state if you are aggregating you are joining use the state for States so",
    "start": "888870",
    "end": "896279"
  },
  {
    "text": "I said you can deploy via lenses if you want to you can do for deploy by helm that's fine we'll see it will monitor it",
    "start": "896279",
    "end": "903890"
  },
  {
    "text": "however we don't know who deployed it so if you go via lenses where you have an",
    "start": "903890",
    "end": "911040"
  },
  {
    "text": "extra bit of security and there we have rule-based controls we have access",
    "start": "911040",
    "end": "917250"
  },
  {
    "text": "policies on catechu itself we have topic black listing white listing as well so",
    "start": "917250",
    "end": "922860"
  },
  {
    "text": "we can not only stop you seeing the data but we can stop you deploying a connector or a processor that's gonna",
    "start": "922860",
    "end": "927990"
  },
  {
    "text": "actually maybe take that data and write it somewhere else plus you get all the other extra goodies",
    "start": "927990",
    "end": "934530"
  },
  {
    "text": "that come with lenses as well the WebSockets the rest api is the clients we have monitoring integration with",
    "start": "934530",
    "end": "940560"
  },
  {
    "text": "prometheus alerts with other managers as well so at the end what we get to is",
    "start": "940560",
    "end": "950640"
  },
  {
    "start": "946000",
    "end": "1002000"
  },
  {
    "text": "that we can build your entire data pipelines simply and easily using",
    "start": "950640",
    "end": "957510"
  },
  {
    "text": "configuration using sequel we have lenses it's sitting on top that's doing the monitoring during the deployment we",
    "start": "957510",
    "end": "964140"
  },
  {
    "text": "have a UI that we'll move to in a bit there allows the views of experience on",
    "start": "964140",
    "end": "969510"
  },
  {
    "text": "it and we also have a lens of CLI as well written Gor line so we're probably going to be doing a lot more integration",
    "start": "969510",
    "end": "975960"
  },
  {
    "text": "with helm as well there so we can actually say deploy lenses then deploy",
    "start": "975960",
    "end": "981060"
  },
  {
    "text": "your application flow maybe you want some monitoring maybe you want the Prometheus operator with it then we can",
    "start": "981060",
    "end": "987840"
  },
  {
    "text": "give you the whole the whole shebang we don't deploy cathegory at the moment bring your own Kafka there's lots of",
    "start": "987840",
    "end": "993930"
  },
  {
    "text": "good distributions out there and maybe we'll be supporting more than Kafka in the future Patchi pulsar nice piece of",
    "start": "993930",
    "end": "1001100"
  },
  {
    "text": "kit so I'm gonna move on to a quick demo I'm going to ask Antonius maybe to help",
    "start": "1001100",
    "end": "1008240"
  },
  {
    "start": "1002000",
    "end": "1036000"
  },
  {
    "text": "me exit PowerPoint so this is lenses it's",
    "start": "1008240",
    "end": "1019670"
  },
  {
    "text": "but on the screen how do I get it on the screen now I can't see",
    "start": "1019670",
    "end": "1030339"
  },
  {
    "start": "1036000",
    "end": "1417000"
  },
  {
    "text": "so this is lenses this is our main application so what you're looking at here is the dashboard you can actually",
    "start": "1036350",
    "end": "1043319"
  },
  {
    "text": "see that we have a number of schemas here we have a number of connectors running we have a number of processes is actually what we're interested in these",
    "start": "1043320",
    "end": "1050310"
  },
  {
    "text": "are all the consumers that are happening on it audit trails who did what there's",
    "start": "1050310",
    "end": "1055710"
  },
  {
    "text": "me practicing a few minutes ago and these are alerts that are firing so these are actually alerts will be coming",
    "start": "1055710",
    "end": "1063120"
  },
  {
    "text": "out from the loan manager if you want to so this is quite difficult doing it this",
    "start": "1063120",
    "end": "1068490"
  },
  {
    "text": "way but so this is the topic screen so",
    "start": "1068490",
    "end": "1075630"
  },
  {
    "text": "where you can see all the topics that are in the in the system that the kafka that were monitoring ingest rates etc",
    "start": "1075630",
    "end": "1081380"
  },
  {
    "text": "configurations about all the different properties that was the replication fact",
    "start": "1081380",
    "end": "1086390"
  },
  {
    "text": "the key types with its Avro whether it's Jason etc so we can drill into a topic",
    "start": "1086390",
    "end": "1095730"
  },
  {
    "text": "this one so what you're seeing here is sequel fired directly on top of Kafka so",
    "start": "1095730",
    "end": "1101790"
  },
  {
    "text": "this is a live continuous queries coming out with sampling because we don't want to bring the browser down we're going to",
    "start": "1101790",
    "end": "1107130"
  },
  {
    "text": "kill the browser if there's too much data we can then drill into the stream",
    "start": "1107130",
    "end": "1112160"
  },
  {
    "text": "to see what what what the data is so that you know we get a lot of use cases",
    "start": "1112160",
    "end": "1117300"
  },
  {
    "text": "for example the traders risk managers we want to look at what's happening when the trading had different trades they're",
    "start": "1117300",
    "end": "1123510"
  },
  {
    "text": "flowing through the system we can also do it historically as well so this is",
    "start": "1123510",
    "end": "1129090"
  },
  {
    "text": "firing you know show me the data from this point in time for this time range if we want to we have different",
    "start": "1129090",
    "end": "1137190"
  },
  {
    "text": "different views we can flatten the data out we can show you the raw basically this is the raw Jason well it's that",
    "start": "1137190",
    "end": "1144120"
  },
  {
    "text": "have Robert converted to Jason it's coming through various different information about the topics themselves",
    "start": "1144120",
    "end": "1151200"
  },
  {
    "text": "in Casca how many partitions how it's being replicated across courses alerting everything on this as well and who's",
    "start": "1151200",
    "end": "1158820"
  },
  {
    "text": "consuming from this topic and what the process of lag isn't there so that's a metric that you'd want to scale maybe I",
    "start": "1158820",
    "end": "1164520"
  },
  {
    "text": "want to scale automatically up because this process too slow okay kuba nice give me an extra runner",
    "start": "1164520",
    "end": "1171919"
  },
  {
    "text": "so I'm gonna obviously there's a lot in now I'm not going to it's not full bloom",
    "start": "1172400",
    "end": "1177450"
  },
  {
    "text": "demo of lenses but what I'm gonna do is I'm gonna create another processor so",
    "start": "1177450",
    "end": "1183090"
  },
  {
    "text": "this is actually pointing at one of our little mini Cubans and Sue's book doesn't matter you so I'm gonna give it",
    "start": "1183090",
    "end": "1198450"
  },
  {
    "text": "a name cube Khan just spill it right",
    "start": "1198450",
    "end": "1204930"
  },
  {
    "text": "here I'm going to deploy a mini coop we",
    "start": "1204930",
    "end": "1215370"
  },
  {
    "text": "could deploy into any cluster we want this lenses instance is actually sitting outside kubernetes but you can deploy",
    "start": "1215370",
    "end": "1220650"
  },
  {
    "text": "inside if it's deployed inside it's only going to deploy to that kubernetes cluster book we have some clients that",
    "start": "1220650",
    "end": "1226620"
  },
  {
    "text": "you know they have a lot of kubernetes clusters we can pick a namespace so I'm",
    "start": "1226620",
    "end": "1233070"
  },
  {
    "text": "just going to stick it in the default namespace and I'm gonna give it a pipeline all this is going to do is just",
    "start": "1233070",
    "end": "1240750"
  },
  {
    "text": "going to attach another label onto the port right and then it's going to collect get collected and gmx metrics so",
    "start": "1240750",
    "end": "1246120"
  },
  {
    "text": "you can start asking questions of get how to promote this pipeline into production what's the metrics of this",
    "start": "1246120",
    "end": "1252210"
  },
  {
    "text": "pipeline imagine your date scientist and you're interested in just your flow you want to be able to maybe tag your flow",
    "start": "1252210",
    "end": "1258240"
  },
  {
    "text": "and be able to see how it's performing so copy/paste",
    "start": "1258240",
    "end": "1268110"
  },
  {
    "text": "into here this is out sequel so all I'm doing is selecting and filtering from",
    "start": "1268110",
    "end": "1276300"
  },
  {
    "text": "the topic we were looking at before so this is just going to say okay right it's a simplistic it's a simplistic",
    "start": "1276300",
    "end": "1282450"
  },
  {
    "text": "example but all it's doing is filtering out data where the speeds greater than 10 at the bottom there we're setting the",
    "start": "1282450",
    "end": "1289020"
  },
  {
    "text": "deserialize to type that the key in the value value because in this case it's Averell and we're actually going to sit",
    "start": "1289020",
    "end": "1296310"
  },
  {
    "text": "or to create a topic so these are all properties that you can set on there on the consumers and the producers of of category itself",
    "start": "1296310",
    "end": "1303119"
  },
  {
    "text": "now you can do a lot more than this you can join no maybe you forgot time or sure an example of that in a bit",
    "start": "1303119",
    "end": "1310878"
  },
  {
    "text": "so if I click create demo God's Wi-Fi",
    "start": "1311929",
    "end": "1319190"
  },
  {
    "text": "permitting we should have a new processor there we can see that the pods",
    "start": "1319190",
    "end": "1324720"
  },
  {
    "text": "are being spun up into cube Anita's yes got lovely pod names we have a topology",
    "start": "1324720",
    "end": "1331440"
  },
  {
    "text": "that will come through so this is the actual topology that's coming out of the CAF extremes after it's gone through a",
    "start": "1331440",
    "end": "1336840"
  },
  {
    "text": "patrick color site so we can then drill in to see what its it's doing for example here this is yeah we can make",
    "start": "1336840",
    "end": "1343559"
  },
  {
    "text": "that pretty able basically that's the filter that's happening we have the raw data coming in we're doing this let and",
    "start": "1343559",
    "end": "1352190"
  },
  {
    "text": "then we're pushing data out so we should yes it comes so we have data that's",
    "start": "1352190",
    "end": "1359369"
  },
  {
    "text": "coming out so all these values on the other end speed greater than 10 we can",
    "start": "1359369",
    "end": "1366359"
  },
  {
    "text": "drill into the monitoring as well so here we're seeing the lag on what's happening on on across these five five",
    "start": "1366359",
    "end": "1372389"
  },
  {
    "text": "runners and now I can't see what that number is but this spun up and they've done half a million messages each since",
    "start": "1372389",
    "end": "1379259"
  },
  {
    "text": "we start them and we can drill in a bit further we get bit more metrics on what",
    "start": "1379259",
    "end": "1385769"
  },
  {
    "text": "is consumed what is produced and if we want to let's scale it down actually",
    "start": "1385769",
    "end": "1393169"
  },
  {
    "text": "let's go for it let's give us some more now we're getting 10 more runners so",
    "start": "1393169",
    "end": "1401009"
  },
  {
    "text": "we've just deployed a sequel processor in Turku beneath it's nasty and actually do that from Python do it",
    "start": "1401009",
    "end": "1408539"
  },
  {
    "text": "from Gore line whatever doesn't matter to the rest the API for it and what's",
    "start": "1408539",
    "end": "1413789"
  },
  {
    "text": "also a more interesting is if we've got the topology right because we're",
    "start": "1413789",
    "end": "1419489"
  },
  {
    "text": "deploying Michael services but I want to see my end-to-end flow you deploy a",
    "start": "1419489",
    "end": "1424919"
  },
  {
    "text": "Michael servers you deploying it actually as a end-to-end service so we're deploying everything into",
    "start": "1424919",
    "end": "1431009"
  },
  {
    "text": "kubernetes this also works outside kubernetes as well we know what you've deployed we know the topology we know how to stitch it",
    "start": "1431009",
    "end": "1437280"
  },
  {
    "text": "together so we can actually build the bigger picture so if you think of things like GDP our Kafka is not going to solve",
    "start": "1437280",
    "end": "1443580"
  },
  {
    "text": "GDP are no way but you can start answering some of the questions where is",
    "start": "1443580",
    "end": "1448890"
  },
  {
    "text": "my data going to what because we have schemas as well what data do I have where is it going",
    "start": "1448890",
    "end": "1454620"
  },
  {
    "text": "who consumed it it's not going to get rid of your data for you the right to be forgotten not quite going to work but",
    "start": "1454620",
    "end": "1461090"
  },
  {
    "text": "there you go so here's our processor that we deployed",
    "start": "1461090",
    "end": "1466400"
  },
  {
    "text": "again it's the same information that you were seeing before metrics coming in it",
    "start": "1466400",
    "end": "1472860"
  },
  {
    "text": "catches up so obviously there the rate comes down and that's it really one last",
    "start": "1472860",
    "end": "1479910"
  },
  {
    "text": "bit before we go to questions is that we have our connectors obviously as well so",
    "start": "1479910",
    "end": "1485040"
  },
  {
    "text": "I want to I want to do insert into Cassandra so I can tie my case equal",
    "start": "1485040",
    "end": "1491370"
  },
  {
    "text": "statement insert into this into this is",
    "start": "1491370",
    "end": "1502770"
  },
  {
    "text": "not actually going to run because we don't have a Cassandra entrance select star from topic something like that",
    "start": "1502770",
    "end": "1513680"
  },
  {
    "text": "first deploy and now you if you've written another piece of sequel",
    "start": "1513680",
    "end": "1518810"
  },
  {
    "text": "configuration configuration is called sequel is configuration to deploy and write data out into Cassandra it could",
    "start": "1518810",
    "end": "1525420"
  },
  {
    "text": "be elasticsearch doesn't matter spin up lots of them again do it from whatever",
    "start": "1525420",
    "end": "1532500"
  },
  {
    "text": "language you want because we have the we have the client bindings and I think I think that's it really so questions",
    "start": "1532500",
    "end": "1543590"
  },
  {
    "text": "we are looking at the different connectors that are out there I think Google do quite a good job on their",
    "start": "1559359",
    "end": "1566710"
  },
  {
    "text": "pub/sub one that they have so we're not necessarily gonna write that ourselves there are some other ones that are a bit",
    "start": "1566710",
    "end": "1573309"
  },
  {
    "text": "flaky in the open source world that where we're taking over we're going to be doing a hive connector for example",
    "start": "1573309",
    "end": "1579489"
  },
  {
    "text": "for or seeing Park a support as well a lot on the user side we'll be doing as",
    "start": "1579489",
    "end": "1585279"
  },
  {
    "text": "well Google pub/sub it seems to be doing a good job from what we see so no",
    "start": "1585279",
    "end": "1591970"
  },
  {
    "text": "immediate plans to do it at the moment",
    "start": "1591970",
    "end": "1597359"
  },
  {
    "text": "yes so we were asked actually and we've got an open PR so if you want to do a",
    "start": "1599039",
    "end": "1604059"
  },
  {
    "text": "click house connector then feel free there's a Norton Pyaar to do that but it has a JDBC driver for it so there is a",
    "start": "1604059",
    "end": "1614169"
  },
  {
    "text": "JDBC source sorry sink out there that we were actually commissioned to write a long time ago it doesn't belong to us anymore",
    "start": "1614169",
    "end": "1621299"
  },
  {
    "text": "so you could just use that now where they click house has a more performant",
    "start": "1621299",
    "end": "1627369"
  },
  {
    "text": "API that you want to rewrite somewhere else then maybe I don't know I don't know the details of click house",
    "start": "1627369",
    "end": "1634710"
  },
  {
    "text": "well a lot of people are you can also export everything out from the UI as",
    "start": "1654230",
    "end": "1659940"
  },
  {
    "text": "well so what we're working on as well is more integration for a bit creating a poor request for example in in lenders",
    "start": "1659940",
    "end": "1667530"
  },
  {
    "text": "itself but you can actually just export everything else out and put it into whatever versioning strategy you want to",
    "start": "1667530",
    "end": "1673200"
  },
  {
    "text": "have some people you know if they're clients who have a branch environment",
    "start": "1673200",
    "end": "1678390"
  },
  {
    "text": "and then they'll fill the date signs as me or the traders may use lenses as an",
    "start": "1678390",
    "end": "1683850"
  },
  {
    "text": "actual just a playground then they'll export out the configuration and then",
    "start": "1683850",
    "end": "1689310"
  },
  {
    "text": "that goes into a version control and whatever process controlled the different people have to promote into",
    "start": "1689310",
    "end": "1694620"
  },
  {
    "text": "production but we are working on it because we want to be able to say okay there's this topology this belongs to me",
    "start": "1694620",
    "end": "1701100"
  },
  {
    "text": "I want to take that topology and I want to promote that through production there's some tricky parts to tackle in",
    "start": "1701100",
    "end": "1707070"
  },
  {
    "text": "their secrets so a calf could connect you have passwords all over the place for databases they're actually just",
    "start": "1707070",
    "end": "1713100"
  },
  {
    "text": "stored in Kafka so if you can actually query calf Bay you can see passwords we",
    "start": "1713100",
    "end": "1718590"
  },
  {
    "text": "mask it you know we do a bit of protection on there but you how do we",
    "start": "1718590",
    "end": "1723780"
  },
  {
    "text": "handle that maybe fault integration this is something that we're or it's on our",
    "start": "1723780",
    "end": "1729300"
  },
  {
    "text": "roadmap conceptually they do the same",
    "start": "1729300",
    "end": "1738150"
  },
  {
    "text": "thing we're slightly different we used Apache color site parser so that's a bit more of an industry",
    "start": "1738150",
    "end": "1743640"
  },
  {
    "text": "standard for example sparklink they use that there is some technical",
    "start": "1743640",
    "end": "1749250"
  },
  {
    "text": "details of why we're better we think that obviously we're objective we allow",
    "start": "1749250",
    "end": "1754440"
  },
  {
    "text": "you to join on multiple fields for example joining value from the key on to on to a value from the value as well we",
    "start": "1754440",
    "end": "1762210"
  },
  {
    "text": "obviously deploy natively now into kubernetes eventually there'll be parity",
    "start": "1762210",
    "end": "1767220"
  },
  {
    "text": "between the two in the long run we're not tied to Kafka I've mentioned it",
    "start": "1767220",
    "end": "1775380"
  },
  {
    "text": "before they're all the streaming technologies out there you know why not have the same sequel engine across everything for example you know we can",
    "start": "1775380",
    "end": "1783690"
  },
  {
    "text": "there's no reason why we can't deploy spark job spark I've in raishin now with cuba news we're not",
    "start": "1783690",
    "end": "1789299"
  },
  {
    "text": "tied Catherine but conceptually they do same thing we just think we've implemented better but we're objective",
    "start": "1789299",
    "end": "1798890"
  },
  {
    "text": "any other questions no okay thank you very much",
    "start": "1802130",
    "end": "1813000"
  },
  {
    "text": "[Applause]",
    "start": "1813000",
    "end": "1816079"
  }
]
[
  {
    "start": "0",
    "end": "27000"
  },
  {
    "text": "okay hi there my name is Matt leer and I am Ganesh and I maintain the storage",
    "start": "30",
    "end": "5970"
  },
  {
    "text": "engine of prometheus and I work mostly on the node exporter welcome to the Prometheus introduction",
    "start": "5970",
    "end": "11160"
  },
  {
    "text": "session so it's worth noting this is the intro we're going to have the Prometheus deep dive tomorrow morning I believe so",
    "start": "11160",
    "end": "17100"
  },
  {
    "text": "if you have questions about more advanced aspects of Prometheus please join us there and also we'd like to give",
    "start": "17100",
    "end": "22260"
  },
  {
    "text": "a special shout out to Julius Bowles one of the co-creators of Prometheus for his help with the slides so first what",
    "start": "22260",
    "end": "28050"
  },
  {
    "start": "27000",
    "end": "107000"
  },
  {
    "text": "exactly is prometheus prometheus is a metrics based monitoring and alerting stack it is an entire ecosystem of",
    "start": "28050",
    "end": "33870"
  },
  {
    "text": "components so for example you have things like our instrumentation libraries the Prometheus client can be",
    "start": "33870",
    "end": "39510"
  },
  {
    "text": "exposed from several different languages such as for example Go Python Java Ruby C rust all kinds of different things and",
    "start": "39510",
    "end": "46649"
  },
  {
    "text": "there are also Prometheus exporters and those operate in slightly different ways so the Prometheus server itself is your",
    "start": "46649",
    "end": "53340"
  },
  {
    "text": "mech suit metrics collection and storage system actually gathers time series and stores them in this database and then",
    "start": "53340",
    "end": "59160"
  },
  {
    "text": "once you have that data you can make use of it by querying Prometheus creating alerts so for example if you'd like to",
    "start": "59160",
    "end": "64710"
  },
  {
    "text": "know when you've reached a certain level of memory pressure or if your disk space is about to run out you can do that and",
    "start": "64710",
    "end": "69900"
  },
  {
    "text": "also we support dashboarding via the Prometheus API using software such as griffons but what's cool about",
    "start": "69900",
    "end": "75240"
  },
  {
    "text": "prometheus is it's really meant for all levels of your stack so not only can use Prometheus for your own applications you",
    "start": "75240",
    "end": "80700"
  },
  {
    "text": "can instrument things like the Linux kernel or web servers like Apache nginx and etc finally Prometheus is made for",
    "start": "80700",
    "end": "87509"
  },
  {
    "text": "dynamic cloud environments so lots of folks to play Prometheus with things like kubernetes but that being said it's",
    "start": "87509",
    "end": "93720"
  },
  {
    "text": "also very useful for the home user as well so in fact I run Prometheus at home just for monitoring my home services and",
    "start": "93720",
    "end": "99119"
  },
  {
    "text": "I actually have like alerting stuff to my phone so if something goes down I get notified about it so you can run it in",
    "start": "99119",
    "end": "104189"
  },
  {
    "text": "production but it's also a lot of fun to use at home so Prometheus is a lot of",
    "start": "104189",
    "end": "109259"
  },
  {
    "start": "107000",
    "end": "149000"
  },
  {
    "text": "things but there are certain things that are out of scope for the project so for example Prometheus does not focus on logging or tracing these are different",
    "start": "109259",
    "end": "115860"
  },
  {
    "text": "observability primitives and while they are quite useful for a theist is squarely focused on metrics collection",
    "start": "115860",
    "end": "121140"
  },
  {
    "text": "in addition Prometheus does not provide automated anomaly detection on its own so for example you could gather data",
    "start": "121140",
    "end": "127380"
  },
  {
    "text": "with Prometheus and that feed that into a different system to do things like anomaly detection but Prometheus does",
    "start": "127380",
    "end": "132510"
  },
  {
    "text": "not feature this built-in finally the Prometheus server stores all of its data to a local disk it does not",
    "start": "132510",
    "end": "138900"
  },
  {
    "text": "necessarily provide scalable or durable long term storage so if you want to store time series for example multiple",
    "start": "138900",
    "end": "144390"
  },
  {
    "text": "years that could get kind of problematic but there are workarounds for this as well so a little bit of the history of",
    "start": "144390",
    "end": "150930"
  },
  {
    "start": "149000",
    "end": "183000"
  },
  {
    "text": "the project the Prometheus project was originally created in 2012 at Sound Cloud designed to address some of the flaws in existing monitoring systems the",
    "start": "150930",
    "end": "158489"
  },
  {
    "text": "project became open-source and was worked on for a couple of years before being fully publicized in 2015 on places",
    "start": "158489",
    "end": "164010"
  },
  {
    "text": "like hacker news in 2016 we joined the CN CF as I believe the second project after kubernetes and then Prometheus",
    "start": "164010",
    "end": "170459"
  },
  {
    "text": "version 1.0 was released a year later we really supreme atheist version 2.0 and this was done primarily so we could",
    "start": "170459",
    "end": "176700"
  },
  {
    "text": "replace these storage back-end so now we have a new storage back-end called TS DB or time series database so let's discuss",
    "start": "176700",
    "end": "184500"
  },
  {
    "start": "183000",
    "end": "253000"
  },
  {
    "text": "the architect for Prometheus and see how all the different components fit together so first we have our targets",
    "start": "184500",
    "end": "190200"
  },
  {
    "text": "and these for example could be applications that you and your team are developing so something like a web application which could be written in",
    "start": "190200",
    "end": "195870"
  },
  {
    "text": "something like say a PHP or Ruby or Python and like an API server written and go or some other language so these",
    "start": "195870",
    "end": "202170"
  },
  {
    "text": "are targets you control and as such you can use the Prometheus client libraries to instrument your own applications so",
    "start": "202170",
    "end": "208680"
  },
  {
    "text": "we feature client libraries for languages such as Go Java Python but there are also community bindings written for languages like rust and C as",
    "start": "208680",
    "end": "215579"
  },
  {
    "text": "well however not all the software in your stack is necessarily something that you will control so for example you",
    "start": "215579",
    "end": "221850"
  },
  {
    "text": "probably deployed on a Linux virtual machine you might be connecting to a my sequel server you might want to look at the C group utilization or something on",
    "start": "221850",
    "end": "228030"
  },
  {
    "text": "your machine but these saut this software does not necessarily expose native Prometheus metrics so this is",
    "start": "228030",
    "end": "233609"
  },
  {
    "text": "where Prometheus exporters come in and an exporters job is basically to query",
    "start": "233609",
    "end": "238680"
  },
  {
    "text": "metrics from some source such as my sequel using that sources native interface do some transformations done",
    "start": "238680",
    "end": "243989"
  },
  {
    "text": "that data and finally expose those metrics in the Prometheus format so the Prometheus server can translate between",
    "start": "243989",
    "end": "249329"
  },
  {
    "text": "that native format and that send the metrics up to itself so here's an",
    "start": "249329",
    "end": "254940"
  },
  {
    "start": "253000",
    "end": "294000"
  },
  {
    "text": "example of what happens when you expose Prometheus metrics if you were looking at something like the slash metrics endpoint on one of your instrumented",
    "start": "254940",
    "end": "261120"
  },
  {
    "text": "services or one of the exporters you might see a metric something like this so there's a bit of metadata here in cell phone for humans and all",
    "start": "261120",
    "end": "267200"
  },
  {
    "text": "so indicates the type of the metric but here we have a time series called HTTP requests total there are a couple of",
    "start": "267200",
    "end": "273170"
  },
  {
    "text": "labels here in between the brackets and labels are how we partition data into different dimensions within Prometheus so for example we have the HTTP method",
    "start": "273170",
    "end": "280370"
  },
  {
    "text": "such as this metric was created by a post request and at a couple of different status codes so we can actually see which requests resulted in",
    "start": "280370",
    "end": "288020"
  },
  {
    "text": "an HTTP 200 versus an HTTP 400 and finally we have the value of the time series as well so now you have your from",
    "start": "288020",
    "end": "296270"
  },
  {
    "start": "294000",
    "end": "305000"
  },
  {
    "text": "easiest server in the middle prometheus well on regular basis reach out to all these different targets so your own",
    "start": "296270",
    "end": "302210"
  },
  {
    "text": "applications as well as your exporters but Prometheus needs to find a way to",
    "start": "302210",
    "end": "307490"
  },
  {
    "start": "305000",
    "end": "351000"
  },
  {
    "text": "actually get a hold of these applications and figure out where they live in order to do so you can configure a static target list if you'd like",
    "start": "307490",
    "end": "313370"
  },
  {
    "text": "however Prometheus also has built-in support for service discovery using mechanisms such as DNS so for example",
    "start": "313370",
    "end": "319520"
  },
  {
    "text": "you can query an SRV record and get a list of targets for Prometheus to scrape you could use coop the kubernetes",
    "start": "319520",
    "end": "324590"
  },
  {
    "text": "integrations so for example if you have pods that are coming up and down at different intervals Prometheus will notice that and create time series and",
    "start": "324590",
    "end": "330800"
  },
  {
    "text": "also flush out stale time series for those pods you can integrate with the service discovery of your cloud provider",
    "start": "330800",
    "end": "335870"
  },
  {
    "text": "or something like AWS and finally we also have a custom service discovery hook so if you and your team have some",
    "start": "335870",
    "end": "341330"
  },
  {
    "text": "kind of in-house system or another way you'd like to manage service discovery you can write out a file in a standard format Prometheus will see that it's",
    "start": "341330",
    "end": "347660"
  },
  {
    "text": "changed reading it in and then can be integrated with your system so once",
    "start": "347660",
    "end": "352790"
  },
  {
    "start": "351000",
    "end": "438000"
  },
  {
    "text": "you're actually gathering this data at regular intervals and you have some time series being built up within Prometheus you want to actually do something with",
    "start": "352790",
    "end": "358760"
  },
  {
    "text": "that data so Prometheus itself features a web UI and the web UI is good for kind",
    "start": "358760",
    "end": "363770"
  },
  {
    "text": "of experimenting and exploring with different queries so it features kind of a basic interface that you can use good",
    "start": "363770",
    "end": "368870"
  },
  {
    "text": "natural explain that a little bit more later but it also shows things like the current configuration of the Prometheus server the current targets that are",
    "start": "368870",
    "end": "374630"
  },
  {
    "text": "loaded into memory and whether or not they are healthy and also things such as the run time flag configuration for Prometheus if you want to do a more",
    "start": "374630",
    "end": "381920"
  },
  {
    "text": "advanced use case we recommend the use of software such as grow fauna and grow fauna enables you to create persistent dashboards so for example you can do 10",
    "start": "381920",
    "end": "388490"
  },
  {
    "text": "or 12 different Prometheus queries at once and create a tactical dashboard for you and your team to help understand the health of your service finally",
    "start": "388490",
    "end": "395510"
  },
  {
    "text": "prometheus also features an API so for example if you wanted to use something like an anomaly detection system",
    "start": "395510",
    "end": "400759"
  },
  {
    "text": "it could read data directly from prometheus using this API pull it in and do whatever it would like the last",
    "start": "400759",
    "end": "407509"
  },
  {
    "text": "component of the Prometheus ecosystem is the alert manager so for example if you want to set up an alert in prometheus",
    "start": "407509",
    "end": "413150"
  },
  {
    "text": "that says say if I have over 80% memory utilization on this machine fire and alert you can do that and then if you",
    "start": "413150",
    "end": "419629"
  },
  {
    "text": "configure Prometheus to to reach out to an alert manager component it will actually send a hook whenever that is firing with alert manager you can",
    "start": "419629",
    "end": "426620"
  },
  {
    "text": "dispatch that alert to different locations so say for example are using something like pager duty you can issue a page immediately or I actually use an",
    "start": "426620",
    "end": "433370"
  },
  {
    "text": "app on my phone called pushover from my home infrastructure works just fine too so some of the major selling points of",
    "start": "433370",
    "end": "439999"
  },
  {
    "start": "438000",
    "end": "478000"
  },
  {
    "text": "Prometheus include the multi-dimensional data model because of the fact that you can have a time series with many different labels and then many different",
    "start": "439999",
    "end": "446029"
  },
  {
    "text": "label values as well you can really easily slice and dice your data into a lot of different dimensions and gain a lot of insight into what your",
    "start": "446029",
    "end": "451879"
  },
  {
    "text": "applications are doing Prometheus also features a very powerful query language we call prom QL and it's a simple",
    "start": "451879",
    "end": "458120"
  },
  {
    "text": "inefficient go server so Prometheus is aesthetically links go binary if you really want to you can just go build or",
    "start": "458120",
    "end": "463370"
  },
  {
    "text": "even cross compile it SCP it up to a Linux machine and just run it and it will pretty much just work finally since",
    "start": "463370",
    "end": "468949"
  },
  {
    "text": "Prometheus supports things like service discovery it's a great fit for applications that run on top of things like kubernetes or are integrated with",
    "start": "468949",
    "end": "474620"
  },
  {
    "text": "some other existing service discovery mechanism so let's discuss a little bit about the Prometheus data model so first",
    "start": "474620",
    "end": "481370"
  },
  {
    "text": "what exactly is a time-series you can think of it as an identifier so for example our HTTP requests total time",
    "start": "481370",
    "end": "487069"
  },
  {
    "text": "series and that we have a vector here and the vector contains some tuples each of these tuples contains a timestamp of",
    "start": "487069",
    "end": "493159"
  },
  {
    "text": "when a sample was gathered and also a value so for example Prometheus will reach out at time equals 0 and collect",
    "start": "493159",
    "end": "499099"
  },
  {
    "text": "some value and then perhaps again at time equals 15 time equals 30 and so on and form a time series and it's worth",
    "start": "499099",
    "end": "505430"
  },
  {
    "text": "noting that each combination of different labels actually produces a new time series within Prometheus so here's",
    "start": "505430",
    "end": "511819"
  },
  {
    "start": "510000",
    "end": "540000"
  },
  {
    "text": "an example time series we have this HTTP request total it's coming from a job called nginx and we have an instance",
    "start": "511819",
    "end": "517068"
  },
  {
    "text": "label attached as well so if you have multiple different nginx servers you can actually filter on whichever one you'd like to query or see all of them in",
    "start": "517069",
    "end": "523459"
  },
  {
    "text": "aggregate by using something like prompt QL so the result of this provides a pretty flexible architecture the",
    "start": "523459",
    "end": "529640"
  },
  {
    "text": "Prometheus metrics are laid out in a flat's namespace so there is no hierarchy involved here everything just a flat namespace with labels and",
    "start": "529640",
    "end": "535740"
  },
  {
    "text": "the dimensions are explicit because of the different label values and now in",
    "start": "535740",
    "end": "541679"
  },
  {
    "start": "540000",
    "end": "682000"
  },
  {
    "text": "order to actually operate Prometheus and talk about it a bit more I will hand over to Ganesh Thank You Man",
    "start": "541679",
    "end": "546809"
  },
  {
    "text": "so I'll be just going through some of the points which Matt already mentioned here so let's talk about querying",
    "start": "546809",
    "end": "553110"
  },
  {
    "text": "we already have data in the parameters right now using the exporters and all the other applications so let's see how",
    "start": "553110",
    "end": "558959"
  },
  {
    "text": "we can get the data using the queries yeah so prom QL is a new query language",
    "start": "558959",
    "end": "564329"
  },
  {
    "text": "which was built with the prometheus and it's great for time series computations",
    "start": "564329",
    "end": "570119"
  },
  {
    "text": "I will be showing some examples and it's not a SQL style querying language so this is a very",
    "start": "570119",
    "end": "577769"
  },
  {
    "text": "basic query you are mentioning the metric name and then you are saying the",
    "start": "577769",
    "end": "583110"
  },
  {
    "text": "no mount point should not be rude so this query gives you all the mount",
    "start": "583110",
    "end": "588990"
  },
  {
    "text": "points which are using more than 100 Giga gigabytes of space and and mount",
    "start": "588990",
    "end": "594600"
  },
  {
    "text": "point is not rude and all the queries in Prometheus looks like a mathematical equation that you would write inside",
    "start": "594600",
    "end": "600959"
  },
  {
    "text": "your code and you can consider the metric name that I am showing on the",
    "start": "600959",
    "end": "606929"
  },
  {
    "text": "left side as a a divided by 10 power 9 which is greater than 100 just show me them and you get a result which matches",
    "start": "606929",
    "end": "616499"
  },
  {
    "text": "node file system bytes total and the other labels associated with it yep and",
    "start": "616499",
    "end": "622490"
  },
  {
    "text": "let's take another example which is little more complex than the current one",
    "start": "622490",
    "end": "628069"
  },
  {
    "text": "this is to find the ratio of number of 500 failed requests in in your system",
    "start": "628069",
    "end": "635910"
  },
  {
    "text": "which is aggregated by every path if you want to find a ratio it will be in the form of a divided by B so the place the",
    "start": "635910",
    "end": "645720"
  },
  {
    "text": "place of a is taken by the rate at which we are getting the 500 requests",
    "start": "645720",
    "end": "651259"
  },
  {
    "text": "aggregated by path so that we can get the find rate request errors per path",
    "start": "651259",
    "end": "656279"
  },
  {
    "text": "and we divided divided by the total number of I should be requests that you",
    "start": "656279",
    "end": "661829"
  },
  {
    "text": "are getting and hence we get errors per path",
    "start": "661829",
    "end": "667050"
  },
  {
    "text": "but if you don't buy a want it bird path we can just remove the buy path in the",
    "start": "667050",
    "end": "673260"
  },
  {
    "text": "query and we can aggregate it or all the requests that we are getting for the",
    "start": "673260",
    "end": "679050"
  },
  {
    "text": "errors and going little more into this there is also histograms and this query",
    "start": "679050",
    "end": "686220"
  },
  {
    "start": "682000",
    "end": "717000"
  },
  {
    "text": "gives you the the what's the latency of 99 percentage of the queries of the",
    "start": "686220",
    "end": "693390"
  },
  {
    "text": "requests that we are getting so these are just a high-level examples I'm not going inside the queries what it",
    "start": "693390",
    "end": "699660"
  },
  {
    "text": "actually happens these are just examples that you can do with the query language there are many more functions like",
    "start": "699660",
    "end": "705180"
  },
  {
    "text": "average some more time and linear prediction and many such things so yeah",
    "start": "705180",
    "end": "710610"
  },
  {
    "text": "but if we will be going more in depth in the deep dive session tomorrow so I'm not I'm just scrape scratching the",
    "start": "710610",
    "end": "716760"
  },
  {
    "text": "surface here yeah and might mention about the ad hoc wearing that we have in",
    "start": "716760",
    "end": "723089"
  },
  {
    "start": "717000",
    "end": "736000"
  },
  {
    "text": "the Prometheus ey so we just give the query in the U and here you have the list of time series that it matches and",
    "start": "723089",
    "end": "730950"
  },
  {
    "text": "the value and if you want to see the graph of a graph for that you can see there is another tab and when you just",
    "start": "730950",
    "end": "736350"
  },
  {
    "start": "736000",
    "end": "748000"
  },
  {
    "text": "click you get the graph for the forest that you run and this is just ad hoc it's it's not persistent you have to run",
    "start": "736350",
    "end": "743310"
  },
  {
    "text": "the query every time that you want to see so if you want to have persistent dashboards you can use graph on ax you",
    "start": "743310",
    "end": "749310"
  },
  {
    "start": "748000",
    "end": "761000"
  },
  {
    "text": "can have panels with time ranges mentioned in them with the query that it has to run in the panels and every time",
    "start": "749310",
    "end": "754980"
  },
  {
    "text": "you open the graph owner dashboard the panels will be the same obviously the data will be different because the time changes yep and now talking about the",
    "start": "754980",
    "end": "763290"
  },
  {
    "start": "761000",
    "end": "829000"
  },
  {
    "text": "alerting so the main alerting stays inside the Prometheus where you define",
    "start": "763290",
    "end": "768750"
  },
  {
    "text": "the alerting rules this we already saw the query which is the ratio of find",
    "start": "768750",
    "end": "774839"
  },
  {
    "text": "requests that we are getting and just like the mathematical equation to convert ratio to percentage I multiply",
    "start": "774839",
    "end": "781230"
  },
  {
    "text": "it by hundred and if it's greater than fight for example if it's more than 5% of the total requests and there is",
    "start": "781230",
    "end": "787440"
  },
  {
    "text": "something called for so if this is returning some time series for like five",
    "start": "787440",
    "end": "793050"
  },
  {
    "text": "minutes which means we have more than 5% of error for five minutes then send me an alert and",
    "start": "793050",
    "end": "798529"
  },
  {
    "text": "attach labels to that and some description with go templating language",
    "start": "798529",
    "end": "803869"
  },
  {
    "text": "and when the alert fires it has to send to some external service so that it can",
    "start": "803869",
    "end": "810829"
  },
  {
    "text": "take care of the alerts so that's where the alert manager comes into play so the",
    "start": "810829",
    "end": "816169"
  },
  {
    "text": "prometheus has these rules create handles the alerts and pushes it to alert manager and as might say the alert",
    "start": "816169",
    "end": "823579"
  },
  {
    "text": "manager takes care of sending it to different hooks like slack or page utility etc and about the operational",
    "start": "823579",
    "end": "831019"
  },
  {
    "start": "829000",
    "end": "861000"
  },
  {
    "text": "simplicity Prometheus is a single binary and it just runs on your localhost it",
    "start": "831019",
    "end": "836599"
  },
  {
    "text": "uses the local storage it doesn't need any object store and if you want to run it in higher liability",
    "start": "836599",
    "end": "844159"
  },
  {
    "text": "mode you just turn to Prometheus with the same config and to and scrape the",
    "start": "844159",
    "end": "849379"
  },
  {
    "text": "same set of targets in both the Prometheus so that if one prometheus",
    "start": "849379",
    "end": "855019"
  },
  {
    "text": "goes down you have another Prometheus which is running obviously the local stores are different for both of them",
    "start": "855019",
    "end": "860529"
  },
  {
    "text": "and yeah efficiency it's very easy to have a moderate set up of Prometheus",
    "start": "860529",
    "end": "867919"
  },
  {
    "start": "861000",
    "end": "892000"
  },
  {
    "text": "which can take more than a million sample per second and have millions of series I have personally seen a",
    "start": "867919",
    "end": "874009"
  },
  {
    "text": "Prometheus instance that can manage more than 10 million series on a single host",
    "start": "874009",
    "end": "879169"
  },
  {
    "text": "yep and it's good to cue keep few weeks to months of data in the Prometheus but",
    "start": "879169",
    "end": "884569"
  },
  {
    "text": "as you know the disk is not reliable so you don't want to run a Prometheus with",
    "start": "884569",
    "end": "889639"
  },
  {
    "text": "a very high scale for like to keep months of data for that we have something called remote storage",
    "start": "889639",
    "end": "895629"
  },
  {
    "start": "892000",
    "end": "926000"
  },
  {
    "text": "Prometheus has an endpoint called remote write using which you can write the data",
    "start": "895629",
    "end": "901369"
  },
  {
    "text": "from the Prometheus to some long-term storage solutions this long-term storage",
    "start": "901369",
    "end": "907099"
  },
  {
    "text": "solutions are not strongly a part of froma test these are community projects",
    "start": "907099",
    "end": "912439"
  },
  {
    "text": "for example cortex and Thanos there were introduction sessions for cortex and Thanos I hope you have",
    "start": "912439",
    "end": "918589"
  },
  {
    "text": "visited that if you wanted the long term storage so I'm not going in depth about them yep so you have Shin for long-term",
    "start": "918589",
    "end": "925879"
  },
  {
    "text": "storage and yeah so Matt mentioned about service discovery for example Kuban it",
    "start": "925879",
    "end": "931519"
  },
  {
    "start": "926000",
    "end": "945000"
  },
  {
    "text": "is you have parts coming and going and you might have thousands of parts and you don't want to list the IP and port of all those parts",
    "start": "931519",
    "end": "938750"
  },
  {
    "text": "in your config so for that we have something called disco service discovery to handle this dynamic environment where",
    "start": "938750",
    "end": "946550"
  },
  {
    "start": "945000",
    "end": "989000"
  },
  {
    "text": "it talks to the DNS server or any service discovery that you have in your system to know what should be present",
    "start": "946550",
    "end": "953420"
  },
  {
    "text": "for example it will give a list of hundred parts that should be present but we're using the alerting rules you can",
    "start": "953420",
    "end": "959030"
  },
  {
    "text": "come to know which parts are not there for example yeah and using service discovery I you",
    "start": "959030",
    "end": "964820"
  },
  {
    "text": "come to know where to pull the matrix from and the service discovery also gives some metadata about the parts and",
    "start": "964820",
    "end": "970940"
  },
  {
    "text": "other hosts that you have which you can attach to the matrix that you are pulling during the scraping period yep",
    "start": "970940",
    "end": "977240"
  },
  {
    "text": "and Prometheus all already has built-in services support for AWS Google given it",
    "start": "977240",
    "end": "983720"
  },
  {
    "text": "is DNS console and lots of other stuff and we guess more will be coming soon yeah and yeah I would like to conclude",
    "start": "983720",
    "end": "990830"
  },
  {
    "start": "989000",
    "end": "1030000"
  },
  {
    "text": "here I don't want to go too deep into all the Prometheus aspects so you feel comfortable in this talk if you want to",
    "start": "990830",
    "end": "997160"
  },
  {
    "text": "get more in depth I recommend you to attend the DPI session tomorrow or we have a Prometheus booth in the sponsor",
    "start": "997160",
    "end": "1003880"
  },
  {
    "text": "showcase area where if you have any questions you can just come talk to us so we looked at the dimensional data",
    "start": "1003880",
    "end": "1009400"
  },
  {
    "text": "model like the label values each label value is like a dimension in the time series database it's a powerful query",
    "start": "1009400",
    "end": "1015610"
  },
  {
    "text": "language it's just like my fancy mathematics it can do anything that you want with it it's simple and it's",
    "start": "1015610",
    "end": "1021220"
  },
  {
    "text": "efficient yeah it's very simple to write it's a single binary and the service discovery is what it what makes it",
    "start": "1021220",
    "end": "1028390"
  },
  {
    "text": "beautiful yep thank you so we have yeah",
    "start": "1028390",
    "end": "1035709"
  },
  {
    "start": "1030000",
    "end": "1068000"
  },
  {
    "text": "we have another Prometheus maintainer here so v3 will be answering questions and unluckily we have just one mic so if",
    "start": "1035709",
    "end": "1043240"
  },
  {
    "text": "you think you are going to ask questions I recommend you to come a little bit to the forward so as we came here I'll",
    "start": "1043240",
    "end": "1048730"
  },
  {
    "text": "repeat the questions any questions yep",
    "start": "1048730",
    "end": "1053910"
  },
  {
    "text": "yeah so his question was one of the problem with times is databases the",
    "start": "1062970",
    "end": "1068770"
  },
  {
    "start": "1068000",
    "end": "1149000"
  },
  {
    "text": "write amplification for SSDs like if you are doing too much writes the SS is going to wear out yeah so that was a big",
    "start": "1068770",
    "end": "1074650"
  },
  {
    "text": "problem with Prometheus 1.0 where we used to just randomly write the data to the disk FM not wrong and with",
    "start": "1074650",
    "end": "1080470"
  },
  {
    "text": "Prometheus 2 dot oh we don't write the data as soon as it comes we store it in the memory and to reduce the write",
    "start": "1080470",
    "end": "1088660"
  },
  {
    "text": "amplification we write it in the size of page blocks so that we don't write the",
    "start": "1088660",
    "end": "1095590"
  },
  {
    "text": "entire block of SSD unnecessarily and once we have written the like Prometheus",
    "start": "1095590",
    "end": "1100600"
  },
  {
    "text": "has in memory part and persistent part and once we write the data to the persistent part we don't modify it so",
    "start": "1100600",
    "end": "1107080"
  },
  {
    "text": "that we don't have to write a lot so there is something called compactions which takes care of other stuff like joining the blocks but yeah we write it",
    "start": "1107080",
    "end": "1113919"
  },
  {
    "text": "in chunks of SSD block so that we don't wear out this as days yeah so that's why we have a long-term storage because if",
    "start": "1113919",
    "end": "1120970"
  },
  {
    "text": "you are running at a higher scale it's difficult to avoid that problem",
    "start": "1120970",
    "end": "1127020"
  },
  {
    "text": "yep so his question was he her to keep mind of how they'll be read load",
    "start": "1146700",
    "end": "1152980"
  },
  {
    "start": "1149000",
    "end": "1206000"
  },
  {
    "text": "concentrate load which is going to increase the something like well yeah",
    "start": "1152980",
    "end": "1158529"
  },
  {
    "text": "how do you maintain a constant write rate yeah yeah a constant write rate I",
    "start": "1158529",
    "end": "1163989"
  },
  {
    "text": "can say it depends on the system capability like we saw we we can ingest millions of samples per second so if you",
    "start": "1163989",
    "end": "1171190"
  },
  {
    "text": "want to increase that you need to have a faster CPU and a lot of RAM so that it",
    "start": "1171190",
    "end": "1177009"
  },
  {
    "text": "can hold in the memory but it will hit a bottleneck somewhere I'm not exactly",
    "start": "1177009",
    "end": "1187299"
  },
  {
    "text": "sure about that but as your queries increase the memory consumption increases because it has to store some",
    "start": "1187299",
    "end": "1194409"
  },
  {
    "text": "stuff in the memory so it's going to affect a bit but I guess not much yeah",
    "start": "1194409",
    "end": "1201840"
  },
  {
    "text": "any more questions yeah I'll just come over there to repeat yeah",
    "start": "1201840",
    "end": "1210090"
  },
  {
    "start": "1206000",
    "end": "1246000"
  },
  {
    "text": "so it's quitting the company can of they're back for this yeah so he's",
    "start": "1211950",
    "end": "1223059"
  },
  {
    "text": "asking like in parameters we scrape and end point multiple times so how do we",
    "start": "1223059",
    "end": "1228880"
  },
  {
    "text": "avoid duplicate values so if at a time",
    "start": "1228880",
    "end": "1234130"
  },
  {
    "text": "stamp 0 you have a value of 10 and if I times I'm 10 you have a value of 10",
    "start": "1234130",
    "end": "1240160"
  },
  {
    "text": "again so I would not say it's a duplicate value it's just the value",
    "start": "1240160",
    "end": "1246100"
  },
  {
    "start": "1246000",
    "end": "1280000"
  },
  {
    "text": "that's present at that particular times time which is so you just store it so when you look at the history historical",
    "start": "1246100",
    "end": "1252490"
  },
  {
    "text": "data what you have you can just say at this time stamp you have this value and the time stamp you have the same value",
    "start": "1252490",
    "end": "1259179"
  },
  {
    "text": "so it doesn't matter if it's duplicate but yeah in terms of compression we take",
    "start": "1259179",
    "end": "1265090"
  },
  {
    "text": "the Delta compression so if it's same we take the Delta and we just store 0 and we don't sort n two times so that there",
    "start": "1265090",
    "end": "1273280"
  },
  {
    "text": "we have the compression there any questions yeah",
    "start": "1273280",
    "end": "1281549"
  },
  {
    "text": "I don't think I have an answer for that do you have like his question was how do",
    "start": "1294260",
    "end": "1300260"
  },
  {
    "text": "we monitor the scheduling of resources within the cube annette is using Prometheus I'm not exactly sure what",
    "start": "1300260",
    "end": "1313280"
  },
  {
    "text": "you're fishing for but there's I mean there's cube state matrix which is",
    "start": "1313280",
    "end": "1318520"
  },
  {
    "text": "exporting a whole lot of kubernetes metrics from your cluster than the cubelets exports of the FBI server",
    "start": "1318520",
    "end": "1324860"
  },
  {
    "text": "exports Jeff so you can certainly check like how much resources you have left the interesting thing and that might go",
    "start": "1324860",
    "end": "1331940"
  },
  {
    "text": "into what you are fishing for is there's the the auto scaling in promise in",
    "start": "1331940",
    "end": "1338510"
  },
  {
    "text": "kubernetes can there are adapters we can use Prometheus to inform the auto scaling so usually you do I mean the",
    "start": "1338510",
    "end": "1346280"
  },
  {
    "text": "vanilla auto scaling is pretty vanilla but you often want to do something like",
    "start": "1346280",
    "end": "1351770"
  },
  {
    "text": "all the scale based on request on CPU usage on RAM usage or like on a Vittori",
    "start": "1351770",
    "end": "1357410"
  },
  {
    "text": "things which you promised this or is actually giving you and then you can loop back the promises or into this cameo imposition the auto scaling",
    "start": "1357410",
    "end": "1363800"
  },
  {
    "text": "decisions all right so that's not exactly scheduling but not your is that going into the direction you were",
    "start": "1363800",
    "end": "1369590"
  },
  {
    "text": "fishing for",
    "start": "1369590",
    "end": "1371950"
  },
  {
    "text": "yeah okay so the I had pressured the scheduling decision itself",
    "start": "1383820",
    "end": "1388930"
  },
  {
    "text": "nobody has yet loopback Prometheus into that it's only like auto scaling or",
    "start": "1388930",
    "end": "1394030"
  },
  {
    "text": "Prometheus loose back first I will happen one day any more questions",
    "start": "1394030",
    "end": "1403260"
  },
  {
    "text": "yeah so my question is about the primitives the data storage it looks like Prometheus is storing",
    "start": "1408330",
    "end": "1415020"
  },
  {
    "text": "holiday-themed disk or SSD then what if the the part of Prometheus be",
    "start": "1415020",
    "end": "1422310"
  },
  {
    "text": "rescheduled already started then how Prometheus achieves the data persistency",
    "start": "1422310",
    "end": "1427320"
  },
  {
    "text": "is prometheus using a persistence volume or any other strategy it's a pure deployment that you",
    "start": "1427320",
    "end": "1436800"
  },
  {
    "text": "use a persistent storage so that once you restart the Prometheus you have the access to the same this that you ran on",
    "start": "1436800",
    "end": "1442890"
  },
  {
    "text": "so I don't we have a persistent part of the Prometheus and there is an in-memory part in the Prometheus so whenever we",
    "start": "1442890",
    "end": "1449070"
  },
  {
    "text": "get samples from the hosts we write it to something called writer headlocks",
    "start": "1449070",
    "end": "1454770"
  },
  {
    "text": "which is a very fairly basic concept in the databases so we also store it in the memory and we write it to the disk in",
    "start": "1454770",
    "end": "1461160"
  },
  {
    "text": "the form of Records which we can replay later and coming to your point we also",
    "start": "1461160",
    "end": "1466260"
  },
  {
    "text": "write it in the blocks of SSDs and yeah so if the Prometheus goes down it comes",
    "start": "1466260",
    "end": "1472710"
  },
  {
    "text": "back again the persistent part of the promise is still there on the disk but the in-memory part we can replay it",
    "start": "1472710",
    "end": "1478770"
  },
  {
    "text": "using the write a headlock that we write whenever we get the samples so it's like replaying the events that happened in",
    "start": "1478770",
    "end": "1484770"
  },
  {
    "text": "the Prometheus and we have the in MIDI part for two R's and the remaining is on the disk so when you restart at maxi",
    "start": "1484770",
    "end": "1491700"
  },
  {
    "text": "Ettore played through the data that was there in the in-memory part for two hours so did that answer your question",
    "start": "1491700",
    "end": "1501950"
  },
  {
    "text": "actually I understand that but my question is what if the part be rescheduled or restarted then how can we",
    "start": "1506970",
    "end": "1514179"
  },
  {
    "text": "guarantee that part is to mount it to the disk so that handling doesn't come",
    "start": "1514179",
    "end": "1521260"
  },
  {
    "text": "under promises exactly you have to make sure that when parameter is rescheduled you attack you are attached to the same",
    "start": "1521260",
    "end": "1526960"
  },
  {
    "text": "volume you can do if you are using Cuban it is I think you can do it using the stateful sets where if we restart the",
    "start": "1526960",
    "end": "1533200"
  },
  {
    "text": "Prometheus you will have the same identifiers and you will have the same persistent volume attached to it so I",
    "start": "1533200",
    "end": "1538539"
  },
  {
    "text": "want to have the same storage if you stateful sets yep if you're running",
    "start": "1538539",
    "end": "1549309"
  },
  {
    "text": "really large clusters with lots of data we said running multiple Prometheus's we",
    "start": "1549309",
    "end": "1554919"
  },
  {
    "text": "just do it in high availability and they'll just grab from the same thing so that doesn't really help you with the you know with scaling Prometheus is that",
    "start": "1554919",
    "end": "1561190"
  },
  {
    "text": "not a problem in practice I don't have really large clusters so I'm just curious if you can speak to that at all yeah that may be a problem in fact a",
    "start": "1561190",
    "end": "1568059"
  },
  {
    "text": "problem in actual practice if you have a very large scale in that case you can actually chart the Prometheus for",
    "start": "1568059",
    "end": "1573850"
  },
  {
    "text": "example you don't scrape everything with a single Prometheus you run multiple Prometheus and scrape part of it in both",
    "start": "1573850",
    "end": "1582970"
  },
  {
    "text": "the multiple Prometheus's so yeah but in",
    "start": "1582970",
    "end": "1590169"
  },
  {
    "text": "that case you will have a problem how will you have a global view of all the Prometheus together so in that case you",
    "start": "1590169",
    "end": "1595960"
  },
  {
    "text": "can do multiple things one is something called Prometheus Federation where you have where you wear one Prometheus talks",
    "start": "1595960",
    "end": "1602919"
  },
  {
    "start": "1601000",
    "end": "1649000"
  },
  {
    "text": "to another Prometheus like it runs a query to another Prometheus and stores that data instead so if you have",
    "start": "1602919",
    "end": "1608830"
  },
  {
    "text": "multiple Prometheus you can have a single parameters which talks to this Prometheus at a lower level and",
    "start": "1608830",
    "end": "1614710"
  },
  {
    "text": "aggregates at a data were that that's like one time storage of the metrics but the I mentioned cortex and Thanos so",
    "start": "1614710",
    "end": "1621909"
  },
  {
    "text": "Thanos has multiple models which you can run independently so tano's has a query",
    "start": "1621909",
    "end": "1627010"
  },
  {
    "text": "or model module and you don't need to run the entire Thanos infrastructure so",
    "start": "1627010",
    "end": "1632110"
  },
  {
    "text": "I can just run a single query model which will talk to this premier all the Prometheus instances",
    "start": "1632110",
    "end": "1637900"
  },
  {
    "text": "and you can have a global view by querying the query and model of the Platanos so these are the two solutions",
    "start": "1637900",
    "end": "1643870"
  },
  {
    "text": "that I know of yeah he has just saying because this is a",
    "start": "1643870",
    "end": "1650680"
  },
  {
    "text": "very frequently asked question and some people formulated as a statement or as a",
    "start": "1650680",
    "end": "1657340"
  },
  {
    "text": "question they say Prometheus doesn't scale which depending on the perspective",
    "start": "1657340",
    "end": "1663910"
  },
  {
    "start": "1663000",
    "end": "1744000"
  },
  {
    "text": "you were that viewer that is actually true but this what Ganesh just said",
    "start": "1663910",
    "end": "1669670"
  },
  {
    "text": "about the showing you usually try to short a long dimension so that you don't",
    "start": "1669670",
    "end": "1674800"
  },
  {
    "text": "need that global view like the NIV or Prometheus was created at SoundCloud we just had one promise your server Pro",
    "start": "1674800",
    "end": "1681460"
  },
  {
    "text": "team essentially they could do whatever they want with their premiere server and it would like be big enough for the team",
    "start": "1681460",
    "end": "1687310"
  },
  {
    "text": "and it's it happens almost never that you actually want to aggregate the heb",
    "start": "1687310",
    "end": "1692800"
  },
  {
    "text": "or requests from the one team with you one of the others so you usually don't have that problem so something I think",
    "start": "1692800",
    "end": "1698680"
  },
  {
    "text": "to the current day they have never used one of those like global views permanent storage whatever solutions and they are",
    "start": "1698680",
    "end": "1704590"
  },
  {
    "text": "fairly happy with that and yeah so arguably it kind of skills there's",
    "start": "1704590",
    "end": "1709900"
  },
  {
    "text": "another trickery you can do when you actually have one like let's say you",
    "start": "1709900",
    "end": "1714970"
  },
  {
    "text": "have 10,000 instances of the same service and you actually have to scrape it all and then you could do like a",
    "start": "1714970",
    "end": "1721420"
  },
  {
    "text": "shoring or like every Prometheus server scrapes every tenth instance and then do",
    "start": "1721420",
    "end": "1726430"
  },
  {
    "text": "some aggregation trickery but I really wouldn't go down that path and it's in in practice I thought it's necessary for",
    "start": "1726430",
    "end": "1734440"
  },
  {
    "text": "99.9% of you",
    "start": "1734440",
    "end": "1737909"
  },
  {
    "start": "1744000",
    "end": "1784000"
  },
  {
    "text": "can you talk about some of these security like authentication TLS that",
    "start": "1747490",
    "end": "1752679"
  },
  {
    "text": "you can do in in prometheus with the end points so the end points just aren't",
    "start": "1752679",
    "end": "1757950"
  },
  {
    "text": "exposing they're just exposing an HTTP that just anyone can query I don't",
    "start": "1757950",
    "end": "1766690"
  },
  {
    "text": "exactly have an answer for this do we support HTTPS for the exporters another",
    "start": "1766690",
    "end": "1776230"
  },
  {
    "text": "FAQ of course so the original idea is kind of old style we have our trusted",
    "start": "1776230",
    "end": "1783279"
  },
  {
    "text": "private network and we just everybody can scribe everybody is all HTTP and of course that's kind of a not acceptable",
    "start": "1783279",
    "end": "1789159"
  },
  {
    "start": "1784000",
    "end": "1913000"
  },
  {
    "text": "anymore so Prometheus as a server it's ironic because the Prometheus server has",
    "start": "1789159",
    "end": "1794919"
  },
  {
    "text": "actually declined part of the HTTP request and the monitored clients technicolor HTTP servers exposing the",
    "start": "1794919",
    "end": "1801789"
  },
  {
    "text": "metrics so the server is perfectly happy to just use TLS and bigger tokens and",
    "start": "1801789",
    "end": "1807580"
  },
  {
    "text": "whatever like all those things and kubernetes that's actually happening usually right so that works quite nicely",
    "start": "1807580",
    "end": "1814600"
  },
  {
    "text": "the the problem is more the part of the who exposes metrics or even the AP of",
    "start": "1814600",
    "end": "1822460"
  },
  {
    "text": "the parameter server itself because then you have to implement and TLS server with authentication and everything and the lame answer of the prometheus",
    "start": "1822460",
    "end": "1829809"
  },
  {
    "text": "community was so far yeah just set up and reverse proxy it's not our our problem like we want to solve one",
    "start": "1829809",
    "end": "1836950"
  },
  {
    "text": "problem and solve it well UNIX philosophy but then people got upset that they always have to set up like a",
    "start": "1836950",
    "end": "1843700"
  },
  {
    "text": "sidecars for that like a good example is you have the node exporter it's not called the Nordics for you like you want",
    "start": "1843700",
    "end": "1849580"
  },
  {
    "text": "to expose metrics let's say my Seco right so my cycle runs in a port and then you run a sidecar for my sequel",
    "start": "1849580",
    "end": "1856750"
  },
  {
    "text": "which is the mystical exporter and then it exposes the metrics in unsecured HTTP",
    "start": "1856750",
    "end": "1861970"
  },
  {
    "text": "so you want now unlike nginx sidecar to reverse proxy for HTTP so you have the cycler for the sidecar and we even had",
    "start": "1861970",
    "end": "1869260"
  },
  {
    "text": "an example at some table where we had where the monitored thing was already a sidecar so we at the site before the",
    "start": "1869260",
    "end": "1874360"
  },
  {
    "text": "sidecar for the sidecar and then it gets ridiculous so luckily there is an effort ongoing whoa",
    "start": "1874360",
    "end": "1880110"
  },
  {
    "text": "want to implement like a reference implementation how we in the promises community one server sockets to do TLS",
    "start": "1880110",
    "end": "1887280"
  },
  {
    "text": "and that's done for the Nordics model right now it's almost ready to merge but that's true for like month right so",
    "start": "1887280",
    "end": "1894450"
  },
  {
    "text": "anyway this is the experiment and once we have one good way to do that we want to push it everywhere through the",
    "start": "1894450",
    "end": "1900120"
  },
  {
    "text": "ecosystem and then you can still not do get into your sidecar if you need something else but at least you have",
    "start": "1900120",
    "end": "1905400"
  },
  {
    "text": "some bottom line TLS implementation that is used throughout the ecosystem so we",
    "start": "1905400",
    "end": "1910799"
  },
  {
    "text": "work into it so one alternative approach i've seen certainly all exporters there",
    "start": "1910799",
    "end": "1917700"
  },
  {
    "start": "1913000",
    "end": "1961000"
  },
  {
    "text": "is their efforts being made to add like TLS to the exploration stuff one alternative approach i have seen is if",
    "start": "1917700",
    "end": "1922740"
  },
  {
    "text": "you have many exporters running on one machine you bind all of them to localhost and you build some sort of proxy that aggregates all of them and",
    "start": "1922740",
    "end": "1928290"
  },
  {
    "text": "then that proxy has TLS or similar and it will expose the metrics and everything on its own machine so that",
    "start": "1928290",
    "end": "1933750"
  },
  {
    "text": "way you have one sidecar that does TLS and stuff like that or you can implement like you know let's encrypt support in",
    "start": "1933750",
    "end": "1939240"
  },
  {
    "text": "that proxy thing I don't know if there any open source implementations of that sort of thing but that is one approach I have seen as well",
    "start": "1939240",
    "end": "1946610"
  },
  {
    "text": "any more questions all right thank you",
    "start": "1951830",
    "end": "1957650"
  },
  {
    "text": "very much",
    "start": "1957650",
    "end": "1959890"
  }
]
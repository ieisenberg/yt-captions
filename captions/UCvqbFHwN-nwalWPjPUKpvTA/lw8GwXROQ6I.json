[
  {
    "text": "all right um so I think we can",
    "start": "399",
    "end": "4480"
  },
  {
    "text": "start uh so thanks uh for joining this",
    "start": "4480",
    "end": "7439"
  },
  {
    "text": "uh session and really making it so far",
    "start": "7439",
    "end": "9840"
  },
  {
    "text": "until the end of the",
    "start": "9840",
    "end": "11200"
  },
  {
    "text": "day uh this session is going to be about",
    "start": "11200",
    "end": "13759"
  },
  {
    "text": "uh using llms to improve data loss",
    "start": "13759",
    "end": "16320"
  },
  {
    "text": "prevention in",
    "start": "16320",
    "end": "18560"
  },
  {
    "text": "organizations before we begin just a",
    "start": "18560",
    "end": "21160"
  },
  {
    "text": "quick introduction so my name is Assaf",
    "start": "21160",
    "end": "24680"
  },
  {
    "text": "I'm a data science team lead at a",
    "start": "24680",
    "end": "26720"
  },
  {
    "text": "company called the kto",
    "start": "26720",
    "end": "28679"
  },
  {
    "text": "networks k operates in the it security",
    "start": "28679",
    "end": "31960"
  },
  {
    "text": "industry as do I I've been there for",
    "start": "31960",
    "end": "34120"
  },
  {
    "text": "over 7 years now uh worked at the",
    "start": "34120",
    "end": "37120"
  },
  {
    "text": "multiple companies uh started out as a",
    "start": "37120",
    "end": "40160"
  },
  {
    "text": "data scientist I did some security",
    "start": "40160",
    "end": "43239"
  },
  {
    "text": "research uh and most recently I lead a",
    "start": "43239",
    "end": "46000"
  },
  {
    "text": "team of",
    "start": "46000",
    "end": "47520"
  },
  {
    "text": "both our main uh research interests and",
    "start": "47520",
    "end": "51640"
  },
  {
    "text": "the projects we work on is applying uh",
    "start": "51640",
    "end": "54399"
  },
  {
    "text": "NLP techniques to the world of network",
    "start": "54399",
    "end": "57600"
  },
  {
    "text": "and Cloud security",
    "start": "57600",
    "end": "61198"
  },
  {
    "text": "and as for the agenda we're going to",
    "start": "61440",
    "end": "63160"
  },
  {
    "text": "start off by going over the concept of",
    "start": "63160",
    "end": "65760"
  },
  {
    "text": "what",
    "start": "65760",
    "end": "66759"
  },
  {
    "text": "dlps specifically the notion of Legacy",
    "start": "66759",
    "end": "70280"
  },
  {
    "text": "dlps versus modern",
    "start": "70280",
    "end": "72680"
  },
  {
    "text": "dlps uh and then we're going to show how",
    "start": "72680",
    "end": "74720"
  },
  {
    "text": "we can use llms to create modern DLP",
    "start": "74720",
    "end": "78240"
  },
  {
    "text": "solutions by uh classifying sensitive",
    "start": "78240",
    "end": "83439"
  },
  {
    "text": "documents uh finally we're going to",
    "start": "83439",
    "end": "85360"
  },
  {
    "text": "finish off with a quick uh demo using a",
    "start": "85360",
    "end": "88439"
  },
  {
    "text": "tensor board if you are familiar with",
    "start": "88439",
    "end": "90000"
  },
  {
    "text": "this",
    "start": "90000",
    "end": "91040"
  },
  {
    "text": "tool and just a quick note here I am",
    "start": "91040",
    "end": "93880"
  },
  {
    "text": "going to assume some prior knowledge and",
    "start": "93880",
    "end": "97000"
  },
  {
    "text": "familiarity with the concepts and",
    "start": "97000",
    "end": "98880"
  },
  {
    "text": "terminology of doing a deep learning",
    "start": "98880",
    "end": "102079"
  },
  {
    "text": "however this is still a highlevel h talk",
    "start": "102079",
    "end": "104640"
  },
  {
    "text": "so we're not going to dive into too much",
    "start": "104640",
    "end": "107079"
  },
  {
    "text": "technical",
    "start": "107079",
    "end": "108320"
  },
  {
    "text": "details but it's going to be a bit more",
    "start": "108320",
    "end": "110680"
  },
  {
    "text": "theoretical in comparison to the",
    "start": "110680",
    "end": "112719"
  },
  {
    "text": "previous talks",
    "start": "112719",
    "end": "115479"
  },
  {
    "text": "today all right so let's start off by",
    "start": "115840",
    "end": "118880"
  },
  {
    "text": "explaining what is is a data loss",
    "start": "118880",
    "end": "121079"
  },
  {
    "text": "prevention and what is a DLP solution so",
    "start": "121079",
    "end": "124640"
  },
  {
    "text": "a DLP solution aims to uh prevent",
    "start": "124640",
    "end": "128239"
  },
  {
    "text": "misusage of sensitive data now sensitive",
    "start": "128239",
    "end": "131760"
  },
  {
    "text": "data could be really any data that is",
    "start": "131760",
    "end": "133480"
  },
  {
    "text": "Meaningful to the company whether it's",
    "start": "133480",
    "end": "136120"
  },
  {
    "text": "the company's data or it's customers",
    "start": "136120",
    "end": "139200"
  },
  {
    "text": "data and misusage could be a lot of",
    "start": "139200",
    "end": "141959"
  },
  {
    "text": "things it could be data being",
    "start": "141959",
    "end": "144440"
  },
  {
    "text": "exfiltrated outside the net Network by a",
    "start": "144440",
    "end": "147440"
  },
  {
    "text": "malicious actor it could be be an",
    "start": "147440",
    "end": "150680"
  },
  {
    "text": "employee leaking data by mistake",
    "start": "150680",
    "end": "154920"
  },
  {
    "text": "unintentionally it could also just be",
    "start": "154920",
    "end": "158000"
  },
  {
    "text": "not following the compliances and",
    "start": "158000",
    "end": "160319"
  },
  {
    "text": "regulations of the company or an",
    "start": "160319",
    "end": "162319"
  },
  {
    "text": "external organization like the gdpr if",
    "start": "162319",
    "end": "164800"
  },
  {
    "text": "you're familiar with",
    "start": "164800",
    "end": "167080"
  },
  {
    "text": "that um so that is data misusage and a",
    "start": "167080",
    "end": "170000"
  },
  {
    "text": "DP solution will aim to cover misusage",
    "start": "170000",
    "end": "173760"
  },
  {
    "text": "in all of the three different states of",
    "start": "173760",
    "end": "175800"
  },
  {
    "text": "data that could be data at rest if the",
    "start": "175800",
    "end": "178879"
  },
  {
    "text": "data is stored on a",
    "start": "178879",
    "end": "180920"
  },
  {
    "text": "server um or a database these days this",
    "start": "180920",
    "end": "184159"
  },
  {
    "text": "is mostly on the cloud it could be data",
    "start": "184159",
    "end": "186879"
  },
  {
    "text": "in motion so data passing through your",
    "start": "186879",
    "end": "190000"
  },
  {
    "text": "network and it could be data in use so",
    "start": "190000",
    "end": "192680"
  },
  {
    "text": "this is data that is stored on the",
    "start": "192680",
    "end": "194200"
  },
  {
    "text": "endpoint device uh and accessed by the",
    "start": "194200",
    "end": "197360"
  },
  {
    "text": "user so a DLP solution will aim to cover",
    "start": "197360",
    "end": "201319"
  },
  {
    "text": "uh all of these three states Cloud",
    "start": "201319",
    "end": "203480"
  },
  {
    "text": "Network and",
    "start": "203480",
    "end": "205720"
  },
  {
    "text": "endpoint now Legacy DLP Solutions take a",
    "start": "205720",
    "end": "209280"
  },
  {
    "text": "pretty naive and basic approach to to",
    "start": "209280",
    "end": "212080"
  },
  {
    "text": "protecting sensitive data misusage and",
    "start": "212080",
    "end": "215080"
  },
  {
    "text": "that is doing pattern matching to detect",
    "start": "215080",
    "end": "217560"
  },
  {
    "text": "piis now we've talked about piis earlier",
    "start": "217560",
    "end": "220640"
  },
  {
    "text": "today there was they mentioned it on",
    "start": "220640",
    "end": "222599"
  },
  {
    "text": "different session but I'm just going to",
    "start": "222599",
    "end": "224720"
  },
  {
    "text": "go over it again on the basics so pii is",
    "start": "224720",
    "end": "227400"
  },
  {
    "text": "essentially any information that can",
    "start": "227400",
    "end": "229560"
  },
  {
    "text": "identify you it could be not just you",
    "start": "229560",
    "end": "233200"
  },
  {
    "text": "but also assets of the company so it can",
    "start": "233200",
    "end": "236519"
  },
  {
    "text": "be a home address uh social security",
    "start": "236519",
    "end": "239439"
  },
  {
    "text": "number",
    "start": "239439",
    "end": "240959"
  },
  {
    "text": "uh passport financial data mobile phone",
    "start": "240959",
    "end": "243799"
  },
  {
    "text": "number or even a physical IP address of",
    "start": "243799",
    "end": "247560"
  },
  {
    "text": "a",
    "start": "247560",
    "end": "248560"
  },
  {
    "text": "device now these are some examples but",
    "start": "248560",
    "end": "251879"
  },
  {
    "text": "really what um defines or is mutual to",
    "start": "251879",
    "end": "255840"
  },
  {
    "text": "all piis is that they are structured",
    "start": "255840",
    "end": "258720"
  },
  {
    "text": "data meaning they have a structure that",
    "start": "258720",
    "end": "261199"
  },
  {
    "text": "is easy to detect for example if we take",
    "start": "261199",
    "end": "263360"
  },
  {
    "text": "IP addresses then I an IP address will",
    "start": "263360",
    "end": "266120"
  },
  {
    "text": "have 12 digits right four numbers bound",
    "start": "266120",
    "end": "269919"
  },
  {
    "text": "between Z and",
    "start": "269919",
    "end": "272759"
  },
  {
    "text": "255 and you can detect that pretty",
    "start": "272880",
    "end": "275639"
  },
  {
    "text": "easily so Legacy DLP Solutions use a",
    "start": "275639",
    "end": "279840"
  },
  {
    "text": "pattern matching to detect this data now",
    "start": "279840",
    "end": "283080"
  },
  {
    "text": "some DLP Solutions take this forward and",
    "start": "283080",
    "end": "286440"
  },
  {
    "text": "allow the the the user to provide these",
    "start": "286440",
    "end": "289800"
  },
  {
    "text": "patterns that is called exact data",
    "start": "289800",
    "end": "292360"
  },
  {
    "text": "matching so in this case the user will",
    "start": "292360",
    "end": "294840"
  },
  {
    "text": "Prov provide his uh specific patterns",
    "start": "294840",
    "end": "297639"
  },
  {
    "text": "for example if you don't want to block",
    "start": "297639",
    "end": "299240"
  },
  {
    "text": "any IP address that's leaving your",
    "start": "299240",
    "end": "301000"
  },
  {
    "text": "company you could just block the",
    "start": "301000",
    "end": "303360"
  },
  {
    "text": "sensitive IPS that or range of ips that",
    "start": "303360",
    "end": "306919"
  },
  {
    "text": "relate to your specific",
    "start": "306919",
    "end": "310120"
  },
  {
    "text": "servers um so this is the basic however",
    "start": "310120",
    "end": "313520"
  },
  {
    "text": "it's important to note that not all",
    "start": "313520",
    "end": "315960"
  },
  {
    "text": "sensitive",
    "start": "315960",
    "end": "317080"
  },
  {
    "text": "data has this pattern or is structured",
    "start": "317080",
    "end": "323400"
  },
  {
    "text": "so when the data doesn't have a",
    "start": "323400",
    "end": "324960"
  },
  {
    "text": "structure this is where Legacy DLP",
    "start": "324960",
    "end": "326880"
  },
  {
    "text": "Solutions fall short",
    "start": "326880",
    "end": "331160"
  },
  {
    "text": "and let's see an",
    "start": "331360",
    "end": "332919"
  },
  {
    "text": "example we are going to uh show how a",
    "start": "332919",
    "end": "336080"
  },
  {
    "text": "legacy DLP solution detects this very",
    "start": "336080",
    "end": "339600"
  },
  {
    "text": "sensitive and important H 10K form",
    "start": "339600",
    "end": "344039"
  },
  {
    "text": "right um and you might be asking",
    "start": "344039",
    "end": "346240"
  },
  {
    "text": "yourself what is a a 10K form if you're",
    "start": "346240",
    "end": "348720"
  },
  {
    "text": "not in finance then then you probably",
    "start": "348720",
    "end": "350919"
  },
  {
    "text": "shouldn't know this but a 10K form is",
    "start": "350919",
    "end": "353680"
  },
  {
    "text": "essentially a report a financial report",
    "start": "353680",
    "end": "356400"
  },
  {
    "text": "that that public companies release once",
    "start": "356400",
    "end": "358759"
  },
  {
    "text": "a year to their share sh",
    "start": "358759",
    "end": "360880"
  },
  {
    "text": "holders um and this is a sensitive",
    "start": "360880",
    "end": "363360"
  },
  {
    "text": "document that you might want to protect",
    "start": "363360",
    "end": "366599"
  },
  {
    "text": "from data misusage uh for example if",
    "start": "366599",
    "end": "369319"
  },
  {
    "text": "this file is being sent before its uh",
    "start": "369319",
    "end": "372360"
  },
  {
    "text": "release",
    "start": "372360",
    "end": "373440"
  },
  {
    "text": "date uh so here actually uh Legacy DLP",
    "start": "373440",
    "end": "377199"
  },
  {
    "text": "engines will do a good job because we",
    "start": "377199",
    "end": "379440"
  },
  {
    "text": "have three uh",
    "start": "379440",
    "end": "381840"
  },
  {
    "text": "piis we have an IRS identification",
    "start": "381840",
    "end": "384919"
  },
  {
    "text": "number and we have information on the on",
    "start": "384919",
    "end": "388520"
  },
  {
    "text": "the company's address",
    "start": "388520",
    "end": "390120"
  },
  {
    "text": "right so if we create a DLP policy rule",
    "start": "390120",
    "end": "392479"
  },
  {
    "text": "that blocks uh documents that have the",
    "start": "392479",
    "end": "394919"
  },
  {
    "text": "company's name and an IRS identification",
    "start": "394919",
    "end": "396759"
  },
  {
    "text": "number this will actually work pretty",
    "start": "396759",
    "end": "400560"
  },
  {
    "text": "good but let's see let's go over this",
    "start": "400560",
    "end": "402800"
  },
  {
    "text": "example right so here we have a",
    "start": "402800",
    "end": "404720"
  },
  {
    "text": "nondisclosure",
    "start": "404720",
    "end": "406800"
  },
  {
    "text": "agreement a legal agreement that binds",
    "start": "406800",
    "end": "410080"
  },
  {
    "text": "two parties together one receiving",
    "start": "410080",
    "end": "412080"
  },
  {
    "text": "sensitive",
    "start": "412080",
    "end": "413400"
  },
  {
    "text": "information um and one uh giving it",
    "start": "413400",
    "end": "417160"
  },
  {
    "text": "out so here um we have some information",
    "start": "417160",
    "end": "422039"
  },
  {
    "text": "that can be considered as a pii we have",
    "start": "422039",
    "end": "424039"
  },
  {
    "text": "the company's name we have the the",
    "start": "424039",
    "end": "425479"
  },
  {
    "text": "address the the mail address but if we",
    "start": "425479",
    "end": "428319"
  },
  {
    "text": "if we write a DP uh policy that blocks",
    "start": "428319",
    "end": "432080"
  },
  {
    "text": "any document that leaves the Network",
    "start": "432080",
    "end": "434479"
  },
  {
    "text": "that has the company's address and that",
    "start": "434479",
    "end": "436479"
  },
  {
    "text": "would be a very noisy uh Rule and it",
    "start": "436479",
    "end": "439680"
  },
  {
    "text": "will create the false",
    "start": "439680",
    "end": "441240"
  },
  {
    "text": "positives what is really interesting",
    "start": "441240",
    "end": "444080"
  },
  {
    "text": "here is the NDA document itself that is",
    "start": "444080",
    "end": "448000"
  },
  {
    "text": "the sensitive information that is what",
    "start": "448000",
    "end": "449680"
  },
  {
    "text": "we want to detect or classify however",
    "start": "449680",
    "end": "452360"
  },
  {
    "text": "this data is not structured right there",
    "start": "452360",
    "end": "454599"
  },
  {
    "text": "is no specific structure to an NDA",
    "start": "454599",
    "end": "458360"
  },
  {
    "text": "document that you can uh you can map or",
    "start": "458360",
    "end": "462039"
  },
  {
    "text": "match against for this you will need a",
    "start": "462039",
    "end": "464840"
  },
  {
    "text": "full uh text",
    "start": "464840",
    "end": "467479"
  },
  {
    "text": "analysis and for that we need uh the",
    "start": "467479",
    "end": "470360"
  },
  {
    "text": "language",
    "start": "470360",
    "end": "471759"
  },
  {
    "text": "models now uh language model is again",
    "start": "471759",
    "end": "475479"
  },
  {
    "text": "something I presume most of you already",
    "start": "475479",
    "end": "477759"
  },
  {
    "text": "know right it's a it's a neural Network",
    "start": "477759",
    "end": "480759"
  },
  {
    "text": "that has been trained on gigantic",
    "start": "480759",
    "end": "483240"
  },
  {
    "text": "corpuses of",
    "start": "483240",
    "end": "484800"
  },
  {
    "text": "text uh typically more than 10 terabytes",
    "start": "484800",
    "end": "487560"
  },
  {
    "text": "of",
    "start": "487560",
    "end": "488960"
  },
  {
    "text": "text uh so the training is really done",
    "start": "488960",
    "end": "491599"
  },
  {
    "text": "in two two phases first we have the",
    "start": "491599",
    "end": "494159"
  },
  {
    "text": "basic training to create a foundation",
    "start": "494159",
    "end": "496199"
  },
  {
    "text": "model and this is the the most",
    "start": "496199",
    "end": "499319"
  },
  {
    "text": "expensive and",
    "start": "499319",
    "end": "501680"
  },
  {
    "text": "resourceful uh part of the training",
    "start": "501680",
    "end": "505000"
  },
  {
    "text": "okay uh so it's important if you get",
    "start": "505000",
    "end": "507639"
  },
  {
    "text": "this assignment from your boss to to to",
    "start": "507639",
    "end": "509919"
  },
  {
    "text": "let them know that this is something",
    "start": "509919",
    "end": "511800"
  },
  {
    "text": "that very few companies do uh really",
    "start": "511800",
    "end": "514518"
  },
  {
    "text": "only the the tech Giants these days but",
    "start": "514519",
    "end": "518120"
  },
  {
    "text": "uh the second phase is taking a generic",
    "start": "518120",
    "end": "521159"
  },
  {
    "text": "Foundation model that essentially it",
    "start": "521159",
    "end": "522959"
  },
  {
    "text": "knows language but it just knows really",
    "start": "522959",
    "end": "525279"
  },
  {
    "text": "how to complete uh text you give it some",
    "start": "525279",
    "end": "528240"
  },
  {
    "text": "prefix and it generates text the second",
    "start": "528240",
    "end": "531680"
  },
  {
    "text": "phase is making it specialized on a",
    "start": "531680",
    "end": "534240"
  },
  {
    "text": "specific TK and this is something much",
    "start": "534240",
    "end": "536160"
  },
  {
    "text": "more affordable that most companies",
    "start": "536160",
    "end": "538279"
  },
  {
    "text": "today can do",
    "start": "538279",
    "end": "540279"
  },
  {
    "text": "so some examples we can take a",
    "start": "540279",
    "end": "542320"
  },
  {
    "text": "foundation model and we can find unit to",
    "start": "542320",
    "end": "545440"
  },
  {
    "text": "create a chatbot like chat GPT right we",
    "start": "545440",
    "end": "549680"
  },
  {
    "text": "can uh train it to generate code some",
    "start": "549680",
    "end": "553320"
  },
  {
    "text": "example could be a",
    "start": "553320",
    "end": "555200"
  },
  {
    "text": "co-pilot we can uh train it to translate",
    "start": "555200",
    "end": "558279"
  },
  {
    "text": "language Google translate and the final",
    "start": "558279",
    "end": "561760"
  },
  {
    "text": "case that we are going to focus on today",
    "start": "561760",
    "end": "564480"
  },
  {
    "text": "is to train it to do text",
    "start": "564480",
    "end": "567040"
  },
  {
    "text": "classification and more specifically",
    "start": "567040",
    "end": "568839"
  },
  {
    "text": "we're going to show how to",
    "start": "568839",
    "end": "570760"
  },
  {
    "text": "fine-tune a large language model to",
    "start": "570760",
    "end": "574120"
  },
  {
    "text": "classify sensitive documents using text",
    "start": "574120",
    "end": "576760"
  },
  {
    "text": "similarity",
    "start": "576760",
    "end": "579640"
  },
  {
    "text": "techniques all right so in other words",
    "start": "580079",
    "end": "583120"
  },
  {
    "text": "we're going to create a text similarity",
    "start": "583120",
    "end": "585160"
  },
  {
    "text": "model now what exactly is a text",
    "start": "585160",
    "end": "587399"
  },
  {
    "text": "similarity Model A text similarity model",
    "start": "587399",
    "end": "590399"
  },
  {
    "text": "is a model that um creates a text",
    "start": "590399",
    "end": "594160"
  },
  {
    "text": "embedding or a compact representation in",
    "start": "594160",
    "end": "597800"
  },
  {
    "text": "other words a vector",
    "start": "597800",
    "end": "599839"
  },
  {
    "text": "in a way that sentences with similar",
    "start": "599839",
    "end": "602560"
  },
  {
    "text": "meaning get similar",
    "start": "602560",
    "end": "605240"
  },
  {
    "text": "representations and text with with",
    "start": "605240",
    "end": "607360"
  },
  {
    "text": "different meaning get different",
    "start": "607360",
    "end": "609279"
  },
  {
    "text": "representations so let's see this",
    "start": "609279",
    "end": "611079"
  },
  {
    "text": "example we have the following",
    "start": "611079",
    "end": "613200"
  },
  {
    "text": "triplet on the left side a p and N A",
    "start": "613200",
    "end": "617360"
  },
  {
    "text": "stands for anchor P stands for positive",
    "start": "617360",
    "end": "621120"
  },
  {
    "text": "and n stands for negative all right so A",
    "start": "621120",
    "end": "623640"
  },
  {
    "text": "and P have the same meaning right the",
    "start": "623640",
    "end": "626959"
  },
  {
    "text": "quick uh brown fox jumps over the lazy",
    "start": "626959",
    "end": "630079"
  },
  {
    "text": "dog a speedy brown fox leaps over a",
    "start": "630079",
    "end": "632839"
  },
  {
    "text": "resting can and this is essentially the",
    "start": "632839",
    "end": "634360"
  },
  {
    "text": "same sentence with different uh",
    "start": "634360",
    "end": "638079"
  },
  {
    "text": "wording uh but the the the negative",
    "start": "638079",
    "end": "641800"
  },
  {
    "text": "example has a completely different",
    "start": "641800",
    "end": "645240"
  },
  {
    "text": "meaning so if we take a foundation model",
    "start": "645240",
    "end": "647839"
  },
  {
    "text": "before fine-tuning it um we might get",
    "start": "647839",
    "end": "651200"
  },
  {
    "text": "similar distances between A and P and A",
    "start": "651200",
    "end": "654120"
  },
  {
    "text": "and N because it hasn't been trained to",
    "start": "654120",
    "end": "656560"
  },
  {
    "text": "to perform this task successfully",
    "start": "656560",
    "end": "659839"
  },
  {
    "text": "but after we train the model we expect A",
    "start": "659839",
    "end": "662279"
  },
  {
    "text": "and P to be much closer together in",
    "start": "662279",
    "end": "664639"
  },
  {
    "text": "comparison to A and",
    "start": "664639",
    "end": "667639"
  },
  {
    "text": "N",
    "start": "667639",
    "end": "669639"
  },
  {
    "text": "so before we go over the exact training",
    "start": "669639",
    "end": "673360"
  },
  {
    "text": "phase we need to define a loss function",
    "start": "673360",
    "end": "676160"
  },
  {
    "text": "now loss function is essentially what",
    "start": "676160",
    "end": "678120"
  },
  {
    "text": "tells the network how successful is he",
    "start": "678120",
    "end": "681720"
  },
  {
    "text": "doing that specific",
    "start": "681720",
    "end": "683959"
  },
  {
    "text": "task um and the loss function that we",
    "start": "683959",
    "end": "687000"
  },
  {
    "text": "are interested in is called triplet loss",
    "start": "687000",
    "end": "688680"
  },
  {
    "text": "function",
    "start": "688680",
    "end": "689920"
  },
  {
    "text": "so this this uh function receives the",
    "start": "689920",
    "end": "693320"
  },
  {
    "text": "anchor the positive and negative",
    "start": "693320",
    "end": "696279"
  },
  {
    "text": "sentences and it creates the embedding",
    "start": "696279",
    "end": "698720"
  },
  {
    "text": "from the",
    "start": "698720",
    "end": "699800"
  },
  {
    "text": "model and the L value really depends on",
    "start": "699800",
    "end": "703480"
  },
  {
    "text": "the following okay so we have a and we",
    "start": "703480",
    "end": "705959"
  },
  {
    "text": "have P the distance between",
    "start": "705959",
    "end": "709279"
  },
  {
    "text": "them and if",
    "start": "709279",
    "end": "711320"
  },
  {
    "text": "n if n's embedding is between A and P in",
    "start": "711320",
    "end": "715399"
  },
  {
    "text": "the red zone that means the model is",
    "start": "715399",
    "end": "717399"
  },
  {
    "text": "doing a bad job and the loss value will",
    "start": "717399",
    "end": "719760"
  },
  {
    "text": "be",
    "start": "719760",
    "end": "721000"
  },
  {
    "text": "positive if n is in the green zone over",
    "start": "721000",
    "end": "723680"
  },
  {
    "text": "here like way far ahead way uh far away",
    "start": "723680",
    "end": "727639"
  },
  {
    "text": "from A and P that means the model is",
    "start": "727639",
    "end": "730560"
  },
  {
    "text": "creating a a a good representation of",
    "start": "730560",
    "end": "733079"
  },
  {
    "text": "the data and in that case the loss will",
    "start": "733079",
    "end": "735279"
  },
  {
    "text": "be",
    "start": "735279",
    "end": "736680"
  },
  {
    "text": "zero so this is the basic idea of",
    "start": "736680",
    "end": "739680"
  },
  {
    "text": "triplet",
    "start": "739680",
    "end": "740959"
  },
  {
    "text": "loss um there's also the notion of",
    "start": "740959",
    "end": "744000"
  },
  {
    "text": "margin so the margin helps us control",
    "start": "744000",
    "end": "746800"
  },
  {
    "text": "the the the training phases of the",
    "start": "746800",
    "end": "748839"
  },
  {
    "text": "network",
    "start": "748839",
    "end": "749720"
  },
  {
    "text": "work um so even if n is further away",
    "start": "749720",
    "end": "753680"
  },
  {
    "text": "than a in comparison to P we still might",
    "start": "753680",
    "end": "756360"
  },
  {
    "text": "want to create a a positive loss",
    "start": "756360",
    "end": "759680"
  },
  {
    "text": "value um because the embedding is still",
    "start": "759680",
    "end": "762639"
  },
  {
    "text": "close by and we want n to be far away",
    "start": "762639",
    "end": "765560"
  },
  {
    "text": "and next two sentences that have the",
    "start": "765560",
    "end": "767160"
  },
  {
    "text": "same meaning at as as his",
    "start": "767160",
    "end": "771560"
  },
  {
    "text": "does all right so so now that we know",
    "start": "771720",
    "end": "774120"
  },
  {
    "text": "the loss function we can talk about the",
    "start": "774120",
    "end": "776279"
  },
  {
    "text": "training",
    "start": "776279",
    "end": "777760"
  },
  {
    "text": "phase uh the training goes as following",
    "start": "777760",
    "end": "780720"
  },
  {
    "text": "okay we have uh different documents from",
    "start": "780720",
    "end": "783639"
  },
  {
    "text": "different s s sensitive",
    "start": "783639",
    "end": "787240"
  },
  {
    "text": "categories um AB ABC in this",
    "start": "787240",
    "end": "791480"
  },
  {
    "text": "example and we create a training set of",
    "start": "791480",
    "end": "795519"
  },
  {
    "text": "uh of triplets okay each time we take",
    "start": "795519",
    "end": "798399"
  },
  {
    "text": "two sentences from a single class and a",
    "start": "798399",
    "end": "802360"
  },
  {
    "text": "sentence sentence from a document from a",
    "start": "802360",
    "end": "804440"
  },
  {
    "text": "different class okay uh so for example a",
    "start": "804440",
    "end": "808639"
  },
  {
    "text": "a to two sentences from the a class and",
    "start": "808639",
    "end": "810760"
  },
  {
    "text": "B a sentence from the b",
    "start": "810760",
    "end": "813120"
  },
  {
    "text": "class and this uh this makes the",
    "start": "813120",
    "end": "816320"
  },
  {
    "text": "training set which is passed to the to",
    "start": "816320",
    "end": "819600"
  },
  {
    "text": "the large language model which creates",
    "start": "819600",
    "end": "821880"
  },
  {
    "text": "the",
    "start": "821880",
    "end": "823079"
  },
  {
    "text": "embeddings and with the embeddings we",
    "start": "823079",
    "end": "825120"
  },
  {
    "text": "can calculate the the loss function and",
    "start": "825120",
    "end": "827320"
  },
  {
    "text": "back propagate the error back to the",
    "start": "827320",
    "end": "829720"
  },
  {
    "text": "network and this is uh a stage that goes",
    "start": "829720",
    "end": "833320"
  },
  {
    "text": "on and on until the the network is",
    "start": "833320",
    "end": "835279"
  },
  {
    "text": "finally uh",
    "start": "835279",
    "end": "837800"
  },
  {
    "text": "trained now once once we have a trained",
    "start": "837800",
    "end": "841600"
  },
  {
    "text": "Network we expect uh the following we",
    "start": "841600",
    "end": "844680"
  },
  {
    "text": "expect it to create meaningful",
    "start": "844680",
    "end": "846759"
  },
  {
    "text": "representation so let's see let's see",
    "start": "846759",
    "end": "849000"
  },
  {
    "text": "this example okay we have three",
    "start": "849000",
    "end": "852240"
  },
  {
    "text": "documents um a W9 IRS tax form a W2 IRS",
    "start": "852240",
    "end": "858560"
  },
  {
    "text": "tax form and a resume and we get three",
    "start": "858560",
    "end": "862199"
  },
  {
    "text": "corresponding",
    "start": "862199",
    "end": "863920"
  },
  {
    "text": "vectors and we can see that this",
    "start": "863920",
    "end": "867199"
  },
  {
    "text": "model um is success in creating",
    "start": "867199",
    "end": "869800"
  },
  {
    "text": "meaningful representations because the",
    "start": "869800",
    "end": "871639"
  },
  {
    "text": "distance between V1 and V2 is very",
    "start": "871639",
    "end": "875600"
  },
  {
    "text": "similar right and we can measure that",
    "start": "875600",
    "end": "878399"
  },
  {
    "text": "using a similarity metric like cosine",
    "start": "878399",
    "end": "881880"
  },
  {
    "text": "similarity um but but V3 gets a a low",
    "start": "881880",
    "end": "886040"
  },
  {
    "text": "similarity okay so this is what we",
    "start": "886040",
    "end": "888040"
  },
  {
    "text": "expect after the fine tuning",
    "start": "888040",
    "end": "891480"
  },
  {
    "text": "stage all right so now we have a model",
    "start": "893199",
    "end": "896839"
  },
  {
    "text": "that can create meaningful",
    "start": "896839",
    "end": "898040"
  },
  {
    "text": "representations",
    "start": "898040",
    "end": "900560"
  },
  {
    "text": "um but our initial task was to create or",
    "start": "900560",
    "end": "903600"
  },
  {
    "text": "to do sensitive document",
    "start": "903600",
    "end": "906440"
  },
  {
    "text": "classification um so we we are still",
    "start": "906440",
    "end": "908560"
  },
  {
    "text": "missing one more phase which is actually",
    "start": "908560",
    "end": "911759"
  },
  {
    "text": "pretty",
    "start": "911759",
    "end": "913279"
  },
  {
    "text": "straightforward all we need to do is to",
    "start": "913279",
    "end": "915720"
  },
  {
    "text": "collect a set of sensitive",
    "start": "915720",
    "end": "918839"
  },
  {
    "text": "documents and when a new document passes",
    "start": "918839",
    "end": "921480"
  },
  {
    "text": "through the llm and gets an embedding we",
    "start": "921480",
    "end": "924759"
  },
  {
    "text": "will compare the similarity between the",
    "start": "924759",
    "end": "927399"
  },
  {
    "text": "new file and all the offline files and",
    "start": "927399",
    "end": "931519"
  },
  {
    "text": "if we see a high similarity then we can",
    "start": "931519",
    "end": "933680"
  },
  {
    "text": "classify this document",
    "start": "933680",
    "end": "936319"
  },
  {
    "text": "accordingly uh so for example",
    "start": "936319",
    "end": "939040"
  },
  {
    "text": "here we have the set called the support",
    "start": "939040",
    "end": "942199"
  },
  {
    "text": "set of 10 documents right CV CV",
    "start": "942199",
    "end": "945120"
  },
  {
    "text": "documents tax documents",
    "start": "945120",
    "end": "948160"
  },
  {
    "text": "transactions and we compare We compare",
    "start": "948160",
    "end": "951160"
  },
  {
    "text": "them to this new document unknown",
    "start": "951160",
    "end": "953440"
  },
  {
    "text": "document that is passing through the",
    "start": "953440",
    "end": "955759"
  },
  {
    "text": "network now the documents that are close",
    "start": "955759",
    "end": "959079"
  },
  {
    "text": "by to the new document or more",
    "start": "959079",
    "end": "961440"
  },
  {
    "text": "specifically inside its",
    "start": "961440",
    "end": "963600"
  },
  {
    "text": "radius um are as you can see three tax",
    "start": "963600",
    "end": "966480"
  },
  {
    "text": "forms and a",
    "start": "966480",
    "end": "968680"
  },
  {
    "text": "transaction uh so we can we can classify",
    "start": "968680",
    "end": "971480"
  },
  {
    "text": "it accordingly we can do majority class",
    "start": "971480",
    "end": "973680"
  },
  {
    "text": "here we can do weighted",
    "start": "973680",
    "end": "976160"
  },
  {
    "text": "majority um or just classify it by the",
    "start": "976160",
    "end": "979440"
  },
  {
    "text": "nearest",
    "start": "979440",
    "end": "981880"
  },
  {
    "text": "neighbor um and that is the basic",
    "start": "981880",
    "end": "985680"
  },
  {
    "text": "idea hopefully that was clear enough and",
    "start": "985680",
    "end": "989120"
  },
  {
    "text": "uh and if not we have a short demo using",
    "start": "989120",
    "end": "992560"
  },
  {
    "text": "tensor board to show how we can uh uh",
    "start": "992560",
    "end": "996600"
  },
  {
    "text": "classify a new document using a support",
    "start": "996600",
    "end": "999120"
  },
  {
    "text": "set okay so we're going to classify this",
    "start": "999120",
    "end": "1002319"
  },
  {
    "text": "uh CV",
    "start": "1002319",
    "end": "1003639"
  },
  {
    "text": "file of uh Richard",
    "start": "1003639",
    "end": "1006839"
  },
  {
    "text": "Sanchez not a crazy scientist from Rick",
    "start": "1006839",
    "end": "1009720"
  },
  {
    "text": "and Morty but just a made up a resume of",
    "start": "1009720",
    "end": "1013440"
  },
  {
    "text": "a software engineer this is not real",
    "start": "1013440",
    "end": "1015519"
  },
  {
    "text": "information so no uh no worries about",
    "start": "1015519",
    "end": "1018360"
  },
  {
    "text": "piis leing",
    "start": "1018360",
    "end": "1020079"
  },
  {
    "text": "here and let's uh switch over to tensor",
    "start": "1020079",
    "end": "1025799"
  },
  {
    "text": "board um now if you're not if you're not",
    "start": "1027319",
    "end": "1031480"
  },
  {
    "text": "familiar with tensor board then uh",
    "start": "1031480",
    "end": "1034079"
  },
  {
    "text": "specifically it's a great tool to to",
    "start": "1034079",
    "end": "1036839"
  },
  {
    "text": "view uh",
    "start": "1036839",
    "end": "1038720"
  },
  {
    "text": "embeddings and right here we have the",
    "start": "1038720",
    "end": "1041400"
  },
  {
    "text": "embeddings of our support set okay so we",
    "start": "1041400",
    "end": "1043918"
  },
  {
    "text": "have",
    "start": "1043919",
    "end": "1045640"
  },
  {
    "text": "485 uh",
    "start": "1045640",
    "end": "1047520"
  },
  {
    "text": "points or documents in three dimensions",
    "start": "1047520",
    "end": "1050679"
  },
  {
    "text": "which we created in beddings",
    "start": "1050679",
    "end": "1052559"
  },
  {
    "text": "form and I'm going to go ahead and add a",
    "start": "1052559",
    "end": "1054799"
  },
  {
    "text": "color map here by",
    "start": "1054799",
    "end": "1057520"
  },
  {
    "text": "category so each category gets a",
    "start": "1057520",
    "end": "1060080"
  },
  {
    "text": "different",
    "start": "1060080",
    "end": "1061440"
  },
  {
    "text": "color and as you can see the model is",
    "start": "1061440",
    "end": "1064600"
  },
  {
    "text": "doing actually a very good job in",
    "start": "1064600",
    "end": "1066840"
  },
  {
    "text": "representing the the sentences because",
    "start": "1066840",
    "end": "1069600"
  },
  {
    "text": "this data is pretty",
    "start": "1069600",
    "end": "1072640"
  },
  {
    "text": "clustered uh for example we have this",
    "start": "1072640",
    "end": "1075520"
  },
  {
    "text": "light blue cluster over here which",
    "start": "1075520",
    "end": "1077960"
  },
  {
    "text": "represents uh resumé",
    "start": "1077960",
    "end": "1081240"
  },
  {
    "text": "documents and we have another uh cluster",
    "start": "1081240",
    "end": "1084799"
  },
  {
    "text": "the green one uh represent representing",
    "start": "1084799",
    "end": "1088520"
  },
  {
    "text": "uh legal",
    "start": "1088520",
    "end": "1090000"
  },
  {
    "text": "documents or this purple one",
    "start": "1090000",
    "end": "1092159"
  },
  {
    "text": "representing a financial",
    "start": "1092159",
    "end": "1094320"
  },
  {
    "text": "documents these are all sensitive uh",
    "start": "1094320",
    "end": "1096520"
  },
  {
    "text": "data types right something that the",
    "start": "1096520",
    "end": "1098720"
  },
  {
    "text": "company would be interested",
    "start": "1098720",
    "end": "1100679"
  },
  {
    "text": "in now that we we viewed the data we",
    "start": "1100679",
    "end": "1103440"
  },
  {
    "text": "still need to classify the the CV of",
    "start": "1103440",
    "end": "1105840"
  },
  {
    "text": "Richard Sanchez okay so this is a new",
    "start": "1105840",
    "end": "1110720"
  },
  {
    "text": "file unknown file okay and I'm going to",
    "start": "1110720",
    "end": "1113640"
  },
  {
    "text": "go ahead and and search it's embedding",
    "start": "1113640",
    "end": "1116240"
  },
  {
    "text": "okay and I'm going to filter the uh 10",
    "start": "1116240",
    "end": "1119840"
  },
  {
    "text": "closest neighbors right and let's let's",
    "start": "1119840",
    "end": "1123000"
  },
  {
    "text": "view their",
    "start": "1123000",
    "end": "1124200"
  },
  {
    "text": "category so uh I think this is big",
    "start": "1124200",
    "end": "1128799"
  },
  {
    "text": "enough so as you can see this these are",
    "start": "1128799",
    "end": "1131280"
  },
  {
    "text": "all resumé",
    "start": "1131280",
    "end": "1132840"
  },
  {
    "text": "documents um but not just resume",
    "start": "1132840",
    "end": "1135320"
  },
  {
    "text": "documents but also uh from professions",
    "start": "1135320",
    "end": "1139880"
  },
  {
    "text": "uh in the technical stem uh industry",
    "start": "1139880",
    "end": "1142880"
  },
  {
    "text": "right so we have a software engineer a",
    "start": "1142880",
    "end": "1144600"
  },
  {
    "text": "data",
    "start": "1144600",
    "end": "1145640"
  },
  {
    "text": "scientist uh so we can start getting a",
    "start": "1145640",
    "end": "1148039"
  },
  {
    "text": "notion about what this document",
    "start": "1148039",
    "end": "1150679"
  },
  {
    "text": "is now if we set a radius of",
    "start": "1150679",
    "end": "1154760"
  },
  {
    "text": "0.5 uh we'll get only four documents",
    "start": "1154760",
    "end": "1158240"
  },
  {
    "text": "inside its",
    "start": "1158240",
    "end": "1160320"
  },
  {
    "text": "cluster um so I'm going to go ahead and",
    "start": "1160320",
    "end": "1162440"
  },
  {
    "text": "isolate",
    "start": "1162440",
    "end": "1165039"
  },
  {
    "text": "them",
    "start": "1165480",
    "end": "1167120"
  },
  {
    "text": "and once we we reach this stage then we",
    "start": "1167120",
    "end": "1170280"
  },
  {
    "text": "can classify the the document",
    "start": "1170280",
    "end": "1172760"
  },
  {
    "text": "accordingly right it could be the really",
    "start": "1172760",
    "end": "1175080"
  },
  {
    "text": "the majority class here which is a",
    "start": "1175080",
    "end": "1177760"
  },
  {
    "text": "resume of a software",
    "start": "1177760",
    "end": "1180760"
  },
  {
    "text": "engineer all right so switching",
    "start": "1183120",
    "end": "1188720"
  },
  {
    "text": "back",
    "start": "1194120",
    "end": "1195640"
  },
  {
    "text": "okay so now let's see how we can create",
    "start": "1195640",
    "end": "1198200"
  },
  {
    "text": "the power ful DLP policy Rules by",
    "start": "1198200",
    "end": "1201960"
  },
  {
    "text": "combining both resumé documents and pii",
    "start": "1201960",
    "end": "1205640"
  },
  {
    "text": "detection okay so we have the following",
    "start": "1205640",
    "end": "1208240"
  },
  {
    "text": "scenario we have an HR",
    "start": "1208240",
    "end": "1210440"
  },
  {
    "text": "representative that is uploading a",
    "start": "1210440",
    "end": "1212679"
  },
  {
    "text": "document to Chad GPT and asking it can",
    "start": "1212679",
    "end": "1215600"
  },
  {
    "text": "you go over this candidate's resume and",
    "start": "1215600",
    "end": "1217799"
  },
  {
    "text": "make sure he is a good fit for for our",
    "start": "1217799",
    "end": "1220600"
  },
  {
    "text": "open position now I hope you are aware",
    "start": "1220600",
    "end": "1225440"
  },
  {
    "text": "of the fact that if you use the free",
    "start": "1225440",
    "end": "1227760"
  },
  {
    "text": "version of CH",
    "start": "1227760",
    "end": "1229440"
  },
  {
    "text": "GPT and you're uploading information",
    "start": "1229440",
    "end": "1232120"
  },
  {
    "text": "this information can be used for",
    "start": "1232120",
    "end": "1234120"
  },
  {
    "text": "training uh so if you're not aware of",
    "start": "1234120",
    "end": "1236000"
  },
  {
    "text": "that Please be aware of that because",
    "start": "1236000",
    "end": "1237480"
  },
  {
    "text": "you're uploading your personal",
    "start": "1237480",
    "end": "1238559"
  },
  {
    "text": "information to to",
    "start": "1238559",
    "end": "1240320"
  },
  {
    "text": "chpt and this is of course a a a",
    "start": "1240320",
    "end": "1243360"
  },
  {
    "text": "violation this would be considered a",
    "start": "1243360",
    "end": "1245480"
  },
  {
    "text": "violation of a of an organization's data",
    "start": "1245480",
    "end": "1248240"
  },
  {
    "text": "security",
    "start": "1248240",
    "end": "1249760"
  },
  {
    "text": "policy um but now we can write the",
    "start": "1249760",
    "end": "1252039"
  },
  {
    "text": "following rule this is an example so",
    "start": "1252039",
    "end": "1254559"
  },
  {
    "text": "we're blocking traffic to Chad",
    "start": "1254559",
    "end": "1256880"
  },
  {
    "text": "GPT if this if this traffic contains a",
    "start": "1256880",
    "end": "1260159"
  },
  {
    "text": "resume document classified by the",
    "start": "1260159",
    "end": "1263799"
  },
  {
    "text": "llm and pii information classified by",
    "start": "1263799",
    "end": "1267480"
  },
  {
    "text": "the data or the pattern",
    "start": "1267480",
    "end": "1269960"
  },
  {
    "text": "matching and this is a very um Advanced",
    "start": "1269960",
    "end": "1273480"
  },
  {
    "text": "use case of preventing data misusage we",
    "start": "1273480",
    "end": "1277120"
  },
  {
    "text": "can now uh we can now",
    "start": "1277120",
    "end": "1281120"
  },
  {
    "text": "handle all right so key",
    "start": "1281799",
    "end": "1285600"
  },
  {
    "text": "takeaways um sensitive data is is more",
    "start": "1285600",
    "end": "1289000"
  },
  {
    "text": "than just piis we've seen that it could",
    "start": "1289000",
    "end": "1291640"
  },
  {
    "text": "be the document classification it could",
    "start": "1291640",
    "end": "1293960"
  },
  {
    "text": "be contextual",
    "start": "1293960",
    "end": "1296240"
  },
  {
    "text": "information and llms really go beyond",
    "start": "1296240",
    "end": "1300000"
  },
  {
    "text": "basic uh pattern matching to to detect",
    "start": "1300000",
    "end": "1302480"
  },
  {
    "text": "this the sensitive",
    "start": "1302480",
    "end": "1304440"
  },
  {
    "text": "data um and and really combining these",
    "start": "1304440",
    "end": "1307720"
  },
  {
    "text": "two together is is the way to create a a",
    "start": "1307720",
    "end": "1311440"
  },
  {
    "text": "modern DLP Solutions with very powerful",
    "start": "1311440",
    "end": "1315159"
  },
  {
    "text": "uh policies and capabilities",
    "start": "1315159",
    "end": "1319440"
  },
  {
    "text": "so uh thank you very much uh for",
    "start": "1320880",
    "end": "1323159"
  },
  {
    "text": "listening um if you want to uh read more",
    "start": "1323159",
    "end": "1326320"
  },
  {
    "text": "about this research with didn't Kato you",
    "start": "1326320",
    "end": "1329320"
  },
  {
    "text": "are welcome to scan this QR",
    "start": "1329320",
    "end": "1332520"
  },
  {
    "text": "code and um that's it on my side let me",
    "start": "1332520",
    "end": "1336720"
  },
  {
    "text": "know if you have any any",
    "start": "1336720",
    "end": "1339880"
  },
  {
    "text": "questions I'm G challenge the I'm gonna",
    "start": "1343080",
    "end": "1346159"
  },
  {
    "text": "challenge the demo could you show me the",
    "start": "1346159",
    "end": "1348000"
  },
  {
    "text": "least similar thing to the resume",
    "start": "1348000",
    "end": "1351559"
  },
  {
    "text": "uploaded you want to see the list uh",
    "start": "1351559",
    "end": "1355400"
  },
  {
    "text": "yeah the the document that is least like",
    "start": "1355400",
    "end": "1357440"
  },
  {
    "text": "a resume in the data",
    "start": "1357440",
    "end": "1360440"
  },
  {
    "text": "set so how do you want to see that",
    "start": "1362320",
    "end": "1365600"
  },
  {
    "text": "exactly like the the document with the",
    "start": "1365600",
    "end": "1368279"
  },
  {
    "text": "the furthest distance the furthest",
    "start": "1368279",
    "end": "1369760"
  },
  {
    "text": "distance from the",
    "start": "1369760",
    "end": "1373440"
  },
  {
    "text": "seems like some legal documents what are",
    "start": "1387880",
    "end": "1390159"
  },
  {
    "text": "you exactly are you asking that more of",
    "start": "1390159",
    "end": "1393120"
  },
  {
    "text": "just a sorry uh more just playful",
    "start": "1393120",
    "end": "1396200"
  },
  {
    "text": "understanding of the different",
    "start": "1396200",
    "end": "1398000"
  },
  {
    "text": "um just context matching like how far",
    "start": "1398000",
    "end": "1401279"
  },
  {
    "text": "something is from something else by by",
    "start": "1401279",
    "end": "1403440"
  },
  {
    "text": "being just playing around with the",
    "start": "1403440",
    "end": "1404600"
  },
  {
    "text": "technology uh I think this tool could be",
    "start": "1404600",
    "end": "1406679"
  },
  {
    "text": "really useful for uh younger generations",
    "start": "1406679",
    "end": "1408919"
  },
  {
    "text": "to get earlier in school and just try to",
    "start": "1408919",
    "end": "1411360"
  },
  {
    "text": "understand the different type of",
    "start": "1411360",
    "end": "1412480"
  },
  {
    "text": "Frameworks and protocols we have as like",
    "start": "1412480",
    "end": "1414799"
  },
  {
    "text": "resumés are supposed to be one of the",
    "start": "1414799",
    "end": "1416200"
  },
  {
    "text": "skills you learn earlier in life here's",
    "start": "1416200",
    "end": "1418440"
  },
  {
    "text": "a bunch in the K means uh triplet uh",
    "start": "1418440",
    "end": "1421760"
  },
  {
    "text": "clustering um I don't know I think it's",
    "start": "1421760",
    "end": "1423760"
  },
  {
    "text": "kind of cool and would be a fun toy for",
    "start": "1423760",
    "end": "1425640"
  },
  {
    "text": "uh younger people that's",
    "start": "1425640",
    "end": "1428400"
  },
  {
    "text": "all so what is the question you show",
    "start": "1428400",
    "end": "1432240"
  },
  {
    "text": "okay",
    "start": "1432240",
    "end": "1433120"
  },
  {
    "text": "cool dist that's what you asked the",
    "start": "1433120",
    "end": "1436240"
  },
  {
    "text": "distance oh okay distance is a",
    "start": "1436240",
    "end": "1439240"
  },
  {
    "text": "uh yeah that makes sense yeah that's",
    "start": "1439240",
    "end": "1442799"
  },
  {
    "text": "that's that's pretty that's a lot if you",
    "start": "1442799",
    "end": "1444919"
  },
  {
    "text": "talk about cosign similarity having a",
    "start": "1444919",
    "end": "1447159"
  },
  {
    "text": "distance of",
    "start": "1447159",
    "end": "1449799"
  },
  {
    "text": "0.16 okay uh any other",
    "start": "1450679",
    "end": "1454600"
  },
  {
    "text": "questions so do are there any challenges",
    "start": "1454600",
    "end": "1457039"
  },
  {
    "text": "looks like the context window has to be",
    "start": "1457039",
    "end": "1459080"
  },
  {
    "text": "big enough obviously the context windows",
    "start": "1459080",
    "end": "1460799"
  },
  {
    "text": "are growing each of these documents have",
    "start": "1460799",
    "end": "1463279"
  },
  {
    "text": "to fit within the context window which I",
    "start": "1463279",
    "end": "1465480"
  },
  {
    "text": "think the coroller is that is going to",
    "start": "1465480",
    "end": "1466799"
  },
  {
    "text": "be extremely expensive right for us to",
    "start": "1466799",
    "end": "1469120"
  },
  {
    "text": "be able to create that F so how do you",
    "start": "1469120",
    "end": "1471120"
  },
  {
    "text": "handle those challenges okay that's a",
    "start": "1471120",
    "end": "1473360"
  },
  {
    "text": "great uh question um yes uh obviously",
    "start": "1473360",
    "end": "1476000"
  },
  {
    "text": "for long documents um it could be a very",
    "start": "1476000",
    "end": "1478919"
  },
  {
    "text": "long context window so you also have a",
    "start": "1478919",
    "end": "1481000"
  },
  {
    "text": "trade-off between accuracy and",
    "start": "1481000",
    "end": "1484120"
  },
  {
    "text": "performance and cost right but from our",
    "start": "1484120",
    "end": "1487000"
  },
  {
    "text": "experience just analyzing the first page",
    "start": "1487000",
    "end": "1489799"
  },
  {
    "text": "or the second page of the document is",
    "start": "1489799",
    "end": "1491679"
  },
  {
    "text": "enough to classify it so just just",
    "start": "1491679",
    "end": "1494240"
  },
  {
    "text": "analyzing maybe the first a thousand",
    "start": "1494240",
    "end": "1496159"
  },
  {
    "text": "tokens is enough and you don't need more",
    "start": "1496159",
    "end": "1498159"
  },
  {
    "text": "than that so so really uh that's",
    "start": "1498159",
    "end": "1502039"
  },
  {
    "text": "sufficient for for a context window and",
    "start": "1502039",
    "end": "1504919"
  },
  {
    "text": "that's a pretty small window,",
    "start": "1504919",
    "end": "1508559"
  },
  {
    "text": "tokens okay any other",
    "start": "1509919",
    "end": "1513720"
  },
  {
    "text": "questions okay thank you very much",
    "start": "1514840",
    "end": "1517560"
  },
  {
    "text": "[Applause]",
    "start": "1517560",
    "end": "1521369"
  }
]
[
  {
    "start": "0",
    "end": "120000"
  },
  {
    "text": "right so we're ready to start welcome everyone my name is yaara wretzky I'm a",
    "start": "439",
    "end": "6930"
  },
  {
    "text": "developer advocate at cloud negative computing foundation and today we're here we skate and Bernard from our from",
    "start": "6930",
    "end": "14700"
  },
  {
    "text": "the Linux Foundation from cloud native computing foundation who is helping us with hosting the webinar and we have to",
    "start": "14700",
    "end": "22080"
  },
  {
    "text": "present us today Bofur representing Google and storage special interest group at cabin and his",
    "start": "22080",
    "end": "28890"
  },
  {
    "text": "community have suddely who is the 6 torch lead and shallow who is a sleek",
    "start": "28890",
    "end": "36120"
  },
  {
    "text": "storage member at Benares community and today today we will speak with you about",
    "start": "36120",
    "end": "43219"
  },
  {
    "text": "about communities 1 to 10 the latest release of Copernicus the media highlights about this release and that",
    "start": "43219",
    "end": "52160"
  },
  {
    "text": "together with michelle will highlight two major and prominent features that",
    "start": "52160",
    "end": "58140"
  },
  {
    "text": "have landed in this release so Copernicus one return is the first",
    "start": "58140",
    "end": "64049"
  },
  {
    "text": "release in in the current year we have 25 million features landed in this",
    "start": "64049",
    "end": "70830"
  },
  {
    "text": "release for those who've been following them you're the previous releases the",
    "start": "70830",
    "end": "76080"
  },
  {
    "text": "progress willis announcements of kubernetes you could know is that the number of features in the current",
    "start": "76080",
    "end": "81240"
  },
  {
    "text": "release is a bit lower because usually we had rounds were 40 features but the",
    "start": "81240",
    "end": "86610"
  },
  {
    "text": "reason of heaven only 25 of features is",
    "start": "86610",
    "end": "91650"
  },
  {
    "text": "that community has been focused on enhancing the existing features from the",
    "start": "91650",
    "end": "97020"
  },
  {
    "text": "previous iterations and to developing some extremely brand-new functionality",
    "start": "97020",
    "end": "103159"
  },
  {
    "text": "at the same time we had a few major errors where the community has been",
    "start": "103159",
    "end": "109229"
  },
  {
    "text": "working working on in during communities one to ten attrition including workload",
    "start": "109229",
    "end": "115649"
  },
  {
    "text": "security and storage enhancements and today's add to this was Michelle will",
    "start": "115649",
    "end": "121469"
  },
  {
    "start": "120000",
    "end": "170000"
  },
  {
    "text": "focus specifically on the search enhancements that we have today in ways given X 1 to 10 it's not let's go ahead",
    "start": "121469",
    "end": "128929"
  },
  {
    "text": "cool thank you her so in the storage state we've been working on a number of features this",
    "start": "128929",
    "end": "134690"
  },
  {
    "text": "quarter mostly moving features that we started on in the last year moving them to beta",
    "start": "134690",
    "end": "141580"
  },
  {
    "text": "one of those features is the container storage interface which I'm going to talk about another feature is local",
    "start": "141580",
    "end": "147860"
  },
  {
    "text": "persistent storage which Michelle is going to tell you more about we also had a femoral storage resource go to beta as",
    "start": "147860",
    "end": "156590"
  },
  {
    "text": "well this quarter so let me jump in and explain a little bit more about CSI as I",
    "start": "156590",
    "end": "162650"
  },
  {
    "text": "mentioned CSI is beta in 1.10 it was introduced in as alpha in the 1.9",
    "start": "162650",
    "end": "168830"
  },
  {
    "text": "release which was last quarter so let me refresh your memory about what the",
    "start": "168830",
    "end": "174860"
  },
  {
    "start": "170000",
    "end": "232000"
  },
  {
    "text": "problem is that CSI is trying to solve the kubernetes volume plug-in system",
    "start": "174860",
    "end": "180050"
  },
  {
    "text": "that you're probably familiar with already is very powerful it makes it",
    "start": "180050",
    "end": "185240"
  },
  {
    "text": "easy to consume block and file storage but it's been challenging to add support",
    "start": "185240",
    "end": "191720"
  },
  {
    "text": "for new entry volume plugins with the existing volume subsystem because it",
    "start": "191720",
    "end": "197269"
  },
  {
    "text": "requires checking a plug-in code into the kubernetes core repository and this",
    "start": "197269",
    "end": "204260"
  },
  {
    "text": "is painful for a number of reasons this means that storage vendors who want to extend the kubernetes kubernetes to",
    "start": "204260",
    "end": "210980"
  },
  {
    "text": "support their storage system have to align with the kubernetes release process they have to even if they want",
    "start": "210980",
    "end": "216739"
  },
  {
    "text": "to do just a bug fix they have to align themselves with a kubernetes release process which can be daunting for this",
    "start": "216739",
    "end": "223940"
  },
  {
    "text": "reason and a number of other reasons we've wanted to have a mechanism by which volume plugins can be added to",
    "start": "223940",
    "end": "229580"
  },
  {
    "text": "kubernetes completely out of tree along came the container storage interface and",
    "start": "229580",
    "end": "236450"
  },
  {
    "start": "232000",
    "end": "326000"
  },
  {
    "text": "this was a collaboration between not just kubernetes but other cluster orchestration systems including mezzos",
    "start": "236450",
    "end": "242570"
  },
  {
    "text": "cloud foundry and docker what we realized is that there was this need across the industry for a standard that",
    "start": "242570",
    "end": "248989"
  },
  {
    "text": "would have label enable us the container orchestration systems to expose arbitrary storage systems to our",
    "start": "248989",
    "end": "255489"
  },
  {
    "text": "containerized workloads and storage provider storage vendors also wanted to",
    "start": "255489",
    "end": "260660"
  },
  {
    "text": "be able to have one standard to which they can design a plugin for and have it work across all CEOs so that they don't",
    "start": "260660",
    "end": "267590"
  },
  {
    "text": "have to re-implement it for every single orchestration system this specification",
    "start": "267590",
    "end": "273439"
  },
  {
    "text": "was started work on it started last year in February and the point to release has",
    "start": "273439",
    "end": "280520"
  },
  {
    "text": "just been cut that should say February 2018 not 2017",
    "start": "280520",
    "end": "286990"
  },
  {
    "text": "and the specification for the interface has been published github it's open",
    "start": "286990",
    "end": "292819"
  },
  {
    "text": "source you can collaborate on it at the specified URL but the specification",
    "start": "292819",
    "end": "298550"
  },
  {
    "text": "alone is just an interface we need to go and actually implement it to make it",
    "start": "298550",
    "end": "303740"
  },
  {
    "text": "useable to our users and that's what we've been working on on the kubernetes side of things where with the addition",
    "start": "303740",
    "end": "311150"
  },
  {
    "text": "of support for CSI kubernetes becomes more extensible we can have new volume",
    "start": "311150",
    "end": "317990"
  },
  {
    "text": "plugins that can be deployed on top of kubernetes without ever having to modify the the core kubernetes code so then the",
    "start": "317990",
    "end": "328159"
  },
  {
    "start": "326000",
    "end": "448000"
  },
  {
    "text": "next question is well how do I use a CSI volume the good news is that you use it",
    "start": "328159",
    "end": "333770"
  },
  {
    "text": "in exactly the same way that you've you're familiar with using existing volumes like GCPD empty ders NFS first",
    "start": "333770",
    "end": "344210"
  },
  {
    "text": "of all there is a storage class in your storage class you specify you point to",
    "start": "344210",
    "end": "349879"
  },
  {
    "text": "the CSI driver as your provisioner and you pass in any parameters that you want",
    "start": "349879",
    "end": "355669"
  },
  {
    "text": "to be passed in when a new volume should be created think of this as a template for creating a new volume and when you",
    "start": "355669",
    "end": "364189"
  },
  {
    "text": "want to create a new volume as an end user you will create a persistent volume claim this is the exact same persistent",
    "start": "364189",
    "end": "371089"
  },
  {
    "text": "volume claim that you're used to you should point to a storage class that",
    "start": "371089",
    "end": "376669"
  },
  {
    "text": "will provision a CSI volume in this case fast storage that we created up above",
    "start": "376669",
    "end": "382610"
  },
  {
    "text": "will result in a CSI volume being provisioned and then you can use it in",
    "start": "382610",
    "end": "389599"
  },
  {
    "text": "your pod in exactly the same way in the volume section of your pod specification",
    "start": "389599",
    "end": "397190"
  },
  {
    "text": "you specify persistant volume claim and the claim name corresponds to the to your PVC and",
    "start": "397190",
    "end": "404200"
  },
  {
    "text": "of course you can still pre provision a volume if you want to for a CSI volume",
    "start": "404200",
    "end": "410840"
  },
  {
    "text": "you can create manually create a persistent volume object this is normally done automatically if you're",
    "start": "410840",
    "end": "416930"
  },
  {
    "text": "using dynamic provisioning through PVC and a storage class but if you don't want to use storage classes you want to",
    "start": "416930",
    "end": "423260"
  },
  {
    "text": "pre create your volumes you can do that by creating your own persistent volume object and in your specification specify",
    "start": "423260",
    "end": "431240"
  },
  {
    "text": "that it's a CSI volume specify in the driver which driver to you it is the",
    "start": "431240",
    "end": "438139"
  },
  {
    "text": "name of the volume is the volume handle and additional attributes that are specific to that volume",
    "start": "438139",
    "end": "447040"
  },
  {
    "start": "448000",
    "end": "570000"
  },
  {
    "text": "so we're moving to beta this quarter and you might be wondering what's new in",
    "start": "448120",
    "end": "454490"
  },
  {
    "text": "beta the big difference is that CSI is",
    "start": "454490",
    "end": "459980"
  },
  {
    "text": "now enabled by default you don't have to opt in as was the case with alpha and",
    "start": "459980",
    "end": "466630"
  },
  {
    "text": "we're also snapping to the zero point to release of the CSI spec the zero point",
    "start": "466630",
    "end": "473420"
  },
  {
    "text": "to release has a number of braking changes from zero point one so if you",
    "start": "473420",
    "end": "478970"
  },
  {
    "text": "had a zero point one driver please make sure that your driver has been updated before you use it with kubernetes 110",
    "start": "478970",
    "end": "486280"
  },
  {
    "text": "and then we had a bunch of features go in on the kubernetes side of things including mount propagation which is a",
    "start": "486280",
    "end": "492140"
  },
  {
    "text": "dependency for deploying CSI drivers that feature has moved to beta we've",
    "start": "492140",
    "end": "499400"
  },
  {
    "text": "also improved security around the volume attachment objects which are required to",
    "start": "499400",
    "end": "505280"
  },
  {
    "text": "attach and detach CSI volumes by reducing which volume attachment objects",
    "start": "505280",
    "end": "515120"
  },
  {
    "text": "a particular node can access it can only access volume attachment objects for the",
    "start": "515120",
    "end": "522919"
  },
  {
    "text": "volumes that are scheduled on that node we've also improved secret support for",
    "start": "522920",
    "end": "529240"
  },
  {
    "text": "CSI so each of the different CSI calls now you can specify the secret",
    "start": "529240",
    "end": "534920"
  },
  {
    "text": "Association associated with it in the CSI persistent volume source object you",
    "start": "534920",
    "end": "540140"
  },
  {
    "text": "can also specify the filesystem type it used to be hard-coded to ext4 now that's customizable and we also",
    "start": "540140",
    "end": "551210"
  },
  {
    "text": "added in a new call in to CSI that's called known stage volume this corresponds if you're familiar with the",
    "start": "551210",
    "end": "557180"
  },
  {
    "text": "kubernetes volume subsystem the mount device call and what this enables is",
    "start": "557180",
    "end": "563270"
  },
  {
    "text": "basically a local attach operation if that is relevant for your volume plugin",
    "start": "563270",
    "end": "570490"
  },
  {
    "start": "570000",
    "end": "748000"
  },
  {
    "text": "what's next we're going to try and target GA for CSI not this coming",
    "start": "572040",
    "end": "578490"
  },
  {
    "text": "quarter but the quarter after that in the v12 release 1.12 before we get to GA",
    "start": "578490",
    "end": "585600"
  },
  {
    "text": "stable some of the features that we want to tick off our block volume support",
    "start": "585600",
    "end": "590940"
  },
  {
    "text": "currently CSI only supports file we also want to add in support for a generic",
    "start": "590940",
    "end": "599160"
  },
  {
    "text": "mechanism to be able to specify availability topology so this is things",
    "start": "599160",
    "end": "606959"
  },
  {
    "text": "like zones rax regions storage may not",
    "start": "606959",
    "end": "612360"
  },
  {
    "text": "be equally accessible across the entire cluster and we want to introduce a mechanism to be able to represent that",
    "start": "612360",
    "end": "618509"
  },
  {
    "text": "in this CSI interface and then for kubernetes to interface with that to do",
    "start": "618509",
    "end": "623940"
  },
  {
    "text": "a couple of things one is to be able to schedule a workload smartly so if a",
    "start": "623940",
    "end": "630990"
  },
  {
    "text": "volume is constrained to a particular zone make sure that the workload using that volume also lands on that zone and",
    "start": "630990",
    "end": "637579"
  },
  {
    "text": "then also make kubernetes smarter something that Michelle is going to be working on in the future by having the",
    "start": "637579",
    "end": "646620"
  },
  {
    "text": "scheduler influence where volumes are going to be provisioned today where",
    "start": "646620",
    "end": "653279"
  },
  {
    "text": "volumes are provisioned is either random or it is controlled through the storage class by the cluster administrator but",
    "start": "653279",
    "end": "660360"
  },
  {
    "text": "we also want to be want to allow the scheduler to be able to influence that so that volumes can be scheduled on on",
    "start": "660360",
    "end": "670170"
  },
  {
    "text": "two nodes that have availability rather than randomly we also want to integrate",
    "start": "670170",
    "end": "676290"
  },
  {
    "text": "with the cubelet device plug-in mechanism this is something that the GPU team has been working on for a while we",
    "start": "676290",
    "end": "683880"
  },
  {
    "text": "want to have a standard way by which plugins are added to the cubelet and registered with the cubelet instead of",
    "start": "683880",
    "end": "690810"
  },
  {
    "text": "having a different mechanism for every different type of volume or every different type of plug-in whether it's GPU device CSI and potentially even",
    "start": "690810",
    "end": "698819"
  },
  {
    "text": "networking so we're looking to achieve that consistency we're also starting the",
    "start": "698819",
    "end": "705370"
  },
  {
    "text": "work on introducing snapshotting into the CSI interface and then bubbling that up into kubernetes and a call to action",
    "start": "705370",
    "end": "714550"
  },
  {
    "text": "if you're a storage vendor you're interested in having your storage system exposed in kubernetes now's the time to",
    "start": "714550",
    "end": "721120"
  },
  {
    "text": "start developing CSI drivers reach out to us if you need help we're happy to",
    "start": "721120",
    "end": "726640"
  },
  {
    "text": "help you and please provide feedback we want to make sure that this thing is actually useful for four storage vendors",
    "start": "726640",
    "end": "733540"
  },
  {
    "text": "we have a handful of drivers that we've been testing but we'd like more and all",
    "start": "733540",
    "end": "739480"
  },
  {
    "text": "of this material that I just went over is going to come out in a blog post on kubernetes i/o today so keep an eye out",
    "start": "739480",
    "end": "746020"
  },
  {
    "text": "for that and with that I'm gonna hand it over to Michelle to discuss local",
    "start": "746020",
    "end": "752080"
  },
  {
    "start": "748000",
    "end": "914000"
  },
  {
    "text": "persistent volumes thanks Todd all right",
    "start": "752080",
    "end": "757330"
  },
  {
    "text": "so I'm gonna talk about the local persistent volumes feature which is now in beta in 110 so to give a brief",
    "start": "757330",
    "end": "766660"
  },
  {
    "text": "overview of what the feature is this basically allows you to specify a local",
    "start": "766660",
    "end": "772930"
  },
  {
    "text": "disc as a persistent volume using the existing persistent volume interfaces",
    "start": "772930",
    "end": "778000"
  },
  {
    "text": "that we have today this feature is most useful when you use",
    "start": "778000",
    "end": "783130"
  },
  {
    "text": "it in conjunction with stateful sets and the volume claim templates that stateful",
    "start": "783130",
    "end": "788440"
  },
  {
    "text": "sets provides so basically each replicas",
    "start": "788440",
    "end": "794410"
  },
  {
    "text": "in a stateful set will be able to get its own volume or you know local",
    "start": "794410",
    "end": "801190"
  },
  {
    "text": "persistent volume for each replica alongside with this feature we made a",
    "start": "801190",
    "end": "809170"
  },
  {
    "text": "number of scheduler enhancements so that the scheduling of local discs is smarter",
    "start": "809170",
    "end": "816690"
  },
  {
    "text": "there's two main benefits of this first if you have a pod that uses a local disc",
    "start": "816690",
    "end": "824620"
  },
  {
    "text": "it's going to always get scheduled to the node where that local disc resides",
    "start": "824620",
    "end": "829980"
  },
  {
    "text": "that's what we call data gravity that way if the pod has to restart and be",
    "start": "829980",
    "end": "835060"
  },
  {
    "text": "rescheduled it will always land on the node where data is the second aspect of this is",
    "start": "835060",
    "end": "841770"
  },
  {
    "text": "that we make the initial persistent volume claim binding smarter so",
    "start": "841770",
    "end": "847250"
  },
  {
    "text": "previously how persistent volume binding works is that you would create the",
    "start": "847250",
    "end": "854310"
  },
  {
    "text": "persistent volume claim and then we would randomly pick a suitable persistent volume for it so what could",
    "start": "854310",
    "end": "861720"
  },
  {
    "text": "happen with local volumes is we could end up picking a local volume on a node",
    "start": "861720",
    "end": "867180"
  },
  {
    "text": "that doesn't have enough resources to actually run the pod so as part of this",
    "start": "867180",
    "end": "872520"
  },
  {
    "text": "feature we added enhancements into the scheduler to be able to postpone that",
    "start": "872520",
    "end": "878399"
  },
  {
    "text": "initial PDC binding so that the scheduler can look at all of the pods",
    "start": "878399",
    "end": "885770"
  },
  {
    "text": "other scheduling constraints such as the resource requirements any affinity or",
    "start": "885770",
    "end": "891930"
  },
  {
    "text": "anti affinity policies any you know taints on nodes and then also consider",
    "start": "891930",
    "end": "898500"
  },
  {
    "text": "the PBC requirements at the same time",
    "start": "898500",
    "end": "903510"
  },
  {
    "text": "so that we can actually bind the volume the pods volumes to a node that can",
    "start": "903510",
    "end": "910680"
  },
  {
    "text": "actually run the workload so before I proceed I first want to",
    "start": "910680",
    "end": "918089"
  },
  {
    "start": "914000",
    "end": "1020000"
  },
  {
    "text": "point out there are a number of caveats with using local storage or local",
    "start": "918089",
    "end": "924990"
  },
  {
    "text": "persistent storage first is the data gravity part so your pod will always get",
    "start": "924990",
    "end": "933209"
  },
  {
    "text": "scheduled to the node where that local disk is but that also means if the node",
    "start": "933209",
    "end": "939060"
  },
  {
    "text": "has a problem or the disk has a problem then your pod is also stuck another",
    "start": "939060",
    "end": "946640"
  },
  {
    "text": "challenge is that now because your pod must be scheduled to that specific node",
    "start": "946640",
    "end": "953100"
  },
  {
    "text": "it has to be able to fit on that node - which means that if for some reason your",
    "start": "953100",
    "end": "959190"
  },
  {
    "text": "pod died and then in the meantime some other pod became scheduled onto that",
    "start": "959190",
    "end": "965160"
  },
  {
    "text": "node your your original pod may not be able to fit anymore when it gets to be",
    "start": "965160",
    "end": "970950"
  },
  {
    "text": "scheduled again in addition many local",
    "start": "970950",
    "end": "976140"
  },
  {
    "text": "disk products in many cloud providers have lower durability guarantees I think",
    "start": "976140",
    "end": "984240"
  },
  {
    "text": "for most of the major cloud providers the local discs will basically you'll",
    "start": "984240",
    "end": "990240"
  },
  {
    "text": "lose all the data in the local discs if the node gets some sort of error so for",
    "start": "990240",
    "end": "996330"
  },
  {
    "text": "all of those reasons local persistent volumes is not suitable for most",
    "start": "996330",
    "end": "1001580"
  },
  {
    "text": "workloads I think most workloads should stick to the distributed and high highly",
    "start": "1001580",
    "end": "1009110"
  },
  {
    "text": "available storage solutions out there today however there are a few workloads",
    "start": "1009110",
    "end": "1016279"
  },
  {
    "text": "that are still suitable to use local disks those workloads have to be able to",
    "start": "1016279",
    "end": "1024350"
  },
  {
    "start": "1020000",
    "end": "1091000"
  },
  {
    "text": "tolerate node and data unavailability and potentially data loss as well some",
    "start": "1024350",
    "end": "1030438"
  },
  {
    "text": "examples of such workloads are workloads that want to cache some states - SSDs",
    "start": "1030439",
    "end": "1037160"
  },
  {
    "text": "for improved performance and in those kind of workloads there potentially",
    "start": "1037160",
    "end": "1043880"
  },
  {
    "text": "caching so much data that it can't the in-memory so they'll have to ssds instead they want the dated gravity",
    "start": "1043880",
    "end": "1052460"
  },
  {
    "text": "in order to avoid having to refresh reload the entire cache from scratch",
    "start": "1052460",
    "end": "1057950"
  },
  {
    "text": "whenever a pod has to be start the second major use case is for distributed",
    "start": "1057950",
    "end": "1064370"
  },
  {
    "text": "storage systems that will shard and replicate data across multiple nodes that way they can all they can tolerate",
    "start": "1064370",
    "end": "1071649"
  },
  {
    "text": "having a node go down and potentially recover from that examples of some",
    "start": "1071649",
    "end": "1078139"
  },
  {
    "text": "distributed storage systems would be like my school or Postgres cluster",
    "start": "1078139",
    "end": "1084159"
  },
  {
    "text": "cassandra and so on there's a there's quite a few that can fit in this bucket",
    "start": "1084159",
    "end": "1090730"
  },
  {
    "start": "1091000",
    "end": "1141000"
  },
  {
    "text": "all right so how do you actually use this feature there are three easy steps",
    "start": "1091389",
    "end": "1099639"
  },
  {
    "text": "the first two steps are done by the cluster administrator first the cluster administrator has to create a storage",
    "start": "1099639",
    "end": "1105919"
  },
  {
    "text": "class for the local disks then the cluster administrator has to create the",
    "start": "1105919",
    "end": "1111470"
  },
  {
    "text": "local persistent volumes that are available in the cluster once all that setup is done then the user can go ahead",
    "start": "1111470",
    "end": "1119659"
  },
  {
    "text": "and now create stateful sets with their persistent volume claim templates and",
    "start": "1119659",
    "end": "1125630"
  },
  {
    "text": "then they will start binding to the local PDS that were created the full and",
    "start": "1125630",
    "end": "1132169"
  },
  {
    "text": "complete documentation is available on the kubernetes website but I'll go over",
    "start": "1132169",
    "end": "1137899"
  },
  {
    "text": "a brief example now so the first step",
    "start": "1137899",
    "end": "1143210"
  },
  {
    "start": "1141000",
    "end": "1219000"
  },
  {
    "text": "create a storage class this is needed this is needed so that we can enable the",
    "start": "1143210",
    "end": "1150490"
  },
  {
    "text": "smarter scheduler feature that I was talking about earlier basically by",
    "start": "1150490",
    "end": "1157370"
  },
  {
    "text": "default persistent volume claim binding occurs immediately once you treat the",
    "start": "1157370",
    "end": "1163850"
  },
  {
    "text": "persistent volume claim but we actually want to delay that initial binding until",
    "start": "1163850",
    "end": "1169309"
  },
  {
    "text": "a pod is actually created that uses it and can go through the scheduler so to",
    "start": "1169309",
    "end": "1174440"
  },
  {
    "text": "enable that option to enable that mode you have to add this new volume binding",
    "start": "1174440",
    "end": "1180049"
  },
  {
    "text": "mode filled in to the storage quests that you are using for your local storage and one important",
    "start": "1180049",
    "end": "1188179"
  },
  {
    "text": "note to take into account normally storage classes have been associated",
    "start": "1188179",
    "end": "1193309"
  },
  {
    "text": "with dynamic provisioning in this initial beta offering of the local",
    "start": "1193309",
    "end": "1200149"
  },
  {
    "text": "persistent volumes feature we don't support dynamic provisioning yet you still have to manually you still have to",
    "start": "1200149",
    "end": "1205970"
  },
  {
    "text": "create the persistent volumes ahead of time but we still need to define this",
    "start": "1205970",
    "end": "1212750"
  },
  {
    "text": "storage class in order to in order to trigger this new scheduler mode",
    "start": "1212750",
    "end": "1219510"
  },
  {
    "start": "1219000",
    "end": "1570000"
  },
  {
    "text": "all right so now the next step which is to create the local volumes there's two",
    "start": "1219510",
    "end": "1225760"
  },
  {
    "text": "ways you can do this you can either do this manually one at a time by hand and",
    "start": "1225760",
    "end": "1231070"
  },
  {
    "text": "there is a more automated way that also described next but first I'm gonna go",
    "start": "1231070",
    "end": "1236110"
  },
  {
    "text": "over the manual way to create the vocal PBS so you'll see here this is my",
    "start": "1236110",
    "end": "1243850"
  },
  {
    "text": "example persistent volume spec and I've highlighted the two new major fields",
    "start": "1243850",
    "end": "1251230"
  },
  {
    "text": "that need to be sets first is the first field is the local volume specification",
    "start": "1251230",
    "end": "1258670"
  },
  {
    "text": "and it's pretty simple right now the only field is a path and this is the",
    "start": "1258670",
    "end": "1264760"
  },
  {
    "text": "path to the global mount point of this volume on the local node like I",
    "start": "1264760",
    "end": "1271990"
  },
  {
    "text": "mentioned before this disk has to be pre formatted and mounted globally on the",
    "start": "1271990",
    "end": "1277600"
  },
  {
    "text": "node beforehand and also the for this",
    "start": "1277600",
    "end": "1283050"
  },
  {
    "text": "manual creation process we only support the retain we reclaimed policy for now",
    "start": "1283050",
    "end": "1289140"
  },
  {
    "text": "which means that when your application is done with the volume someone needs to",
    "start": "1289140",
    "end": "1295360"
  },
  {
    "text": "go in and clean up the local disk and then recreate the persistent volume for",
    "start": "1295360",
    "end": "1301990"
  },
  {
    "text": "it the second new field that is available now in the persistent volume",
    "start": "1301990",
    "end": "1307510"
  },
  {
    "text": "object is node affinity so this is very similar to node affinity in pot objects",
    "start": "1307510",
    "end": "1316330"
  },
  {
    "text": "today the only difference is now we're applying it to a persistent volume so what a node affinity on a persistent",
    "start": "1316330",
    "end": "1323920"
  },
  {
    "text": "volume does is it restricts the nodes that this persistent volume can be",
    "start": "1323920",
    "end": "1330130"
  },
  {
    "text": "accessed from so in the case of local volumes we want to restrict this",
    "start": "1330130",
    "end": "1337179"
  },
  {
    "text": "persistent volume to only be accessible from a single node so we do this by",
    "start": "1337179",
    "end": "1343090"
  },
  {
    "text": "specifying the kubernetes host name label key and the value of that key will",
    "start": "1343090",
    "end": "1350650"
  },
  {
    "text": "in this example is my node so my note in this example is called my",
    "start": "1350650",
    "end": "1355720"
  },
  {
    "text": "node but you would you know put in whatever the actual node name of your in",
    "start": "1355720",
    "end": "1362110"
  },
  {
    "text": "your cluster so this is also so we're using this right now initially for local",
    "start": "1362110",
    "end": "1369639"
  },
  {
    "text": "volumes but there's no definitive anded in the future and is flexible enough in",
    "start": "1369639",
    "end": "1374919"
  },
  {
    "text": "the future to support any other volume types so if you have storage if you have",
    "start": "1374919",
    "end": "1382539"
  },
  {
    "text": "a volume type that is restricted to specific zones you can also use node affinity to specify that if you want to",
    "start": "1382539",
    "end": "1389379"
  },
  {
    "text": "restrict your storage to specific racks you can also use this as well all right",
    "start": "1389379",
    "end": "1396279"
  },
  {
    "text": "so like I mentioned one downside here of manually creating the local volume is",
    "start": "1396279",
    "end": "1402549"
  },
  {
    "text": "that you need to manually clean it up and recreate it when the application is done with it it's kind of a pain so to",
    "start": "1402549",
    "end": "1410470"
  },
  {
    "text": "improve on that we've implemented this local volume manager that you can run as",
    "start": "1410470",
    "end": "1418809"
  },
  {
    "text": "a daemon set in your cluster that will manage a lot of this PD lifecycle for",
    "start": "1418809",
    "end": "1427240"
  },
  {
    "text": "you you still have to pre format and mount the local disks first but you can",
    "start": "1427240",
    "end": "1436690"
  },
  {
    "text": "mount it into a into a predefined directory on your node and when you",
    "start": "1436690",
    "end": "1443230"
  },
  {
    "text": "launch the local volume static provisioners what we call it it's going",
    "start": "1443230",
    "end": "1450159"
  },
  {
    "text": "to look under those it's going to look for mount points under those pre-configured directories and it's",
    "start": "1450159",
    "end": "1456999"
  },
  {
    "text": "going to automatically create the persistent volumes for you and then when",
    "start": "1456999",
    "end": "1462070"
  },
  {
    "text": "you end up releasing those persistent volumes by deleting the persistent",
    "start": "1462070",
    "end": "1467649"
  },
  {
    "text": "volume claim the static provision is also going to automatically clean up the",
    "start": "1467649",
    "end": "1473619"
  },
  {
    "text": "disk for you and delete the persistent volume object and then it's gonna repeat",
    "start": "1473619",
    "end": "1478720"
  },
  {
    "text": "the cycle and it's gonna find a new mount point again doesn't have a persistent volume for it and it's gonna",
    "start": "1478720",
    "end": "1485080"
  },
  {
    "text": "recreate it so I would highly recommend that you use",
    "start": "1485080",
    "end": "1490760"
  },
  {
    "text": "this provisioner here static provisioner it's not a dynamic provisioner but I",
    "start": "1490760",
    "end": "1496610"
  },
  {
    "text": "would recommend you use this to ease the lifecycle management quite a bit so that",
    "start": "1496610",
    "end": "1504650"
  },
  {
    "text": "is the so that's covers the second step of how you can create local persistent",
    "start": "1504650",
    "end": "1511280"
  },
  {
    "text": "volumes either manually or automatically and the third last step is to actually",
    "start": "1511280",
    "end": "1516890"
  },
  {
    "text": "use them in your workloads so luckily here for this step the process is",
    "start": "1516890",
    "end": "1524750"
  },
  {
    "text": "exactly the same as it is today you use the existing volume claim templates",
    "start": "1524750",
    "end": "1531169"
  },
  {
    "text": "that's available in staple sets you use the same request storage capacity and",
    "start": "1531169",
    "end": "1537890"
  },
  {
    "text": "you request specific access modes the only difference here is now you need to",
    "start": "1537890",
    "end": "1544250"
  },
  {
    "text": "specify the storage class name for the local storage that you created or that",
    "start": "1544250",
    "end": "1550549"
  },
  {
    "text": "the administrator created earlier and after this the applet the whole workflow",
    "start": "1550549",
    "end": "1555980"
  },
  {
    "text": "is exactly the same you could even easily do things like switch between",
    "start": "1555980",
    "end": "1561890"
  },
  {
    "text": "using local storage and switch between remote storage just by changing the storage class field so",
    "start": "1561890",
    "end": "1572050"
  },
  {
    "start": "1570000",
    "end": "1680000"
  },
  {
    "text": "the basics of how to actually use the feature - and you know we're still",
    "start": "1572050",
    "end": "1578220"
  },
  {
    "text": "there's still lots of other work that still needs to be done before we can go GA some of the items that we're",
    "start": "1578220",
    "end": "1585850"
  },
  {
    "text": "currently focusing on now are to improve the local raw block volume support it's",
    "start": "1585850",
    "end": "1594160"
  },
  {
    "text": "available right now in alpha and 110 but we'll have to push push that to beta as",
    "start": "1594160",
    "end": "1601540"
  },
  {
    "text": "well the second major feature that we're working on is supporting dynamic",
    "start": "1601540",
    "end": "1607360"
  },
  {
    "text": "provisioning using LVM this is also still going to require more scheduler",
    "start": "1607360",
    "end": "1613360"
  },
  {
    "text": "changes and also more provision or changes on the local storage front so that is an active development and the",
    "start": "1613360",
    "end": "1620800"
  },
  {
    "text": "third step like I mentioned is to try to",
    "start": "1620800",
    "end": "1625930"
  },
  {
    "text": "automate more of this node setup work so I previously mentioned that there you",
    "start": "1625930",
    "end": "1633430"
  },
  {
    "text": "still need to manually format and mount these local disks during the initial",
    "start": "1633430",
    "end": "1641530"
  },
  {
    "text": "node setup so we're also looking at ways that we can try to automate that a",
    "start": "1641530",
    "end": "1647770"
  },
  {
    "text": "little bit more so you don't so we remove those manual steps so if any of",
    "start": "1647770",
    "end": "1654130"
  },
  {
    "text": "this sounds interesting to you please try out the feature give us feedback and",
    "start": "1654130",
    "end": "1661930"
  },
  {
    "text": "if you're interested in developing helping to develop any of these future items also please reach out to me and",
    "start": "1661930",
    "end": "1669700"
  },
  {
    "text": "reach out to the sig we can try to work in we can try to work in some tasks",
    "start": "1669700",
    "end": "1676150"
  },
  {
    "text": "there alright so and in general yeah and",
    "start": "1676150",
    "end": "1684340"
  },
  {
    "text": "in general if you're interested in any of the either CSI or local persistent",
    "start": "1684340",
    "end": "1690790"
  },
  {
    "text": "volumes or any other features related to storage please reach out to us at six",
    "start": "1690790",
    "end": "1696520"
  },
  {
    "text": "storage we hold our we hold meetings every two weeks on Thursdays at 9:00",
    "start": "1696520",
    "end": "1702550"
  },
  {
    "text": "a.m. all the details the meetings and zoom links are there we're also going to have a pretty big",
    "start": "1702550",
    "end": "1709779"
  },
  {
    "text": "presence at UConn EU there's a number of presentations that various members of",
    "start": "1709779",
    "end": "1717440"
  },
  {
    "text": "the storage sig are going to be giving including some basic storage storage 101",
    "start": "1717440",
    "end": "1725270"
  },
  {
    "text": "intros there's going to be a more detailed session on local storage and how it's actually used in a production",
    "start": "1725270",
    "end": "1733190"
  },
  {
    "text": "environment some more detail talks on CSI and also snapshots all right so I",
    "start": "1733190",
    "end": "1743299"
  },
  {
    "text": "think that's all I have mr. now it's time for Q&A Q&A session and for all the",
    "start": "1743299",
    "end": "1758000"
  },
  {
    "start": "1745000",
    "end": "2110000"
  },
  {
    "text": "participants here you can see the Q&A Q&A button and screaming in the zooming",
    "start": "1758000",
    "end": "1767000"
  },
  {
    "text": "to free so please leave your questions right there so different question is for",
    "start": "1767000",
    "end": "1772309"
  },
  {
    "text": "good and deep beliefs how resizing works and thought and do we have to restart",
    "start": "1772309",
    "end": "1778100"
  },
  {
    "text": "pod sorry is the question about resizing right yes so how are sizing works on",
    "start": "1778100",
    "end": "1786289"
  },
  {
    "text": "board and do we have yes so the way that resizing works is that you update your",
    "start": "1786289",
    "end": "1796460"
  },
  {
    "text": "system volume claim with the desired size that you want to increase to and",
    "start": "1796460",
    "end": "1804230"
  },
  {
    "text": "then the kubernetes system is going to go and increase the size of the",
    "start": "1804230",
    "end": "1811820"
  },
  {
    "text": "underlying block volume but then in order to do the file system resize you",
    "start": "1811820",
    "end": "1818779"
  },
  {
    "text": "need to restart your pod first and that way we can safely unmount the file",
    "start": "1818779",
    "end": "1825919"
  },
  {
    "text": "system from the container and then trigger the file system resize in that case perfect",
    "start": "1825919",
    "end": "1835620"
  },
  {
    "text": "expression ace-king cabinet is both scheduling if joys a high working notes",
    "start": "1835620",
    "end": "1843530"
  },
  {
    "text": "sorry could you repeat the question yes so can community spell scheduling injuries a high your time well you on",
    "start": "1843530",
    "end": "1851280"
  },
  {
    "text": "working out so I can give them a just interrupts killing when the window is",
    "start": "1851280",
    "end": "1857700"
  },
  {
    "text": "there hi sorry there's a high what time I own time when there is a higher input",
    "start": "1857700",
    "end": "1867750"
  },
  {
    "text": "output oh well there's a lot of latency",
    "start": "1867750",
    "end": "1873590"
  },
  {
    "text": "can kubernetes scale no kubernetes",
    "start": "1873590",
    "end": "1879470"
  },
  {
    "text": "temporarily interrupt scheduling so I guess the question is around if there's",
    "start": "1879470",
    "end": "1884910"
  },
  {
    "text": "high latency on volumes is kubernetes able to kind of rebalance workloads",
    "start": "1884910",
    "end": "1890460"
  },
  {
    "text": "around to to work around that yeah more or less yes I think so today cubelet is",
    "start": "1890460",
    "end": "1899580"
  },
  {
    "text": "checking for a local disk i/o pressure and if it senses that the node has high",
    "start": "1899580",
    "end": "1908550"
  },
  {
    "text": "i/o at least on the local disk front it's gonna update the node status to say",
    "start": "1908550",
    "end": "1914160"
  },
  {
    "text": "that and I'm not actually sure if the scheduler will avoid those notes in that case and for remote volumes we don't",
    "start": "1914160",
    "end": "1923640"
  },
  {
    "text": "really take and take i/o into account so it's possible that you could have",
    "start": "1923640",
    "end": "1929540"
  },
  {
    "text": "network latency Zoar noisy neighbor issues related to i/o kubernetes doesn't",
    "start": "1929540",
    "end": "1937559"
  },
  {
    "text": "account for that yet perfect so the next question is probably",
    "start": "1937559",
    "end": "1943740"
  },
  {
    "text": "to to meet Caitlyn is how can we get the slides and video streams so this session",
    "start": "1943740",
    "end": "1950070"
  },
  {
    "text": "is being recorded and will be available in the next few days at CN CF 2 at our",
    "start": "1950070",
    "end": "1956460"
  },
  {
    "text": "website so the next question is back to sudden Michelle is about when a node is",
    "start": "1956460",
    "end": "1963300"
  },
  {
    "text": "using a local storage and I changed it Ames finishes",
    "start": "1963300",
    "end": "1969170"
  },
  {
    "text": "Oh disprin deported or scheduled on to denote their local persistent search was",
    "start": "1969170",
    "end": "1975610"
  },
  {
    "text": "yeah so in that scenario you can potentially have this is this is one of",
    "start": "1975610",
    "end": "1982250"
  },
  {
    "text": "the downsides of using local storage so if say you have a workload using local",
    "start": "1982250",
    "end": "1989780"
  },
  {
    "text": "storage and it's scheduled on node a and then you add a taint to node a that",
    "start": "1989780",
    "end": "1996290"
  },
  {
    "text": "causes the pod to be evicted from it your pod cannot be scheduled after that",
    "start": "1996290",
    "end": "2002830"
  },
  {
    "text": "because it's bound to a volume that only exists on that node so that's that's one",
    "start": "2002830",
    "end": "2009880"
  },
  {
    "text": "of the down you know that's one of the risks you take by using local storage so your application really needs to be",
    "start": "2009880",
    "end": "2016600"
  },
  {
    "text": "aware of these kind of these kinds of limitations and potentially you know if",
    "start": "2016600",
    "end": "2022570"
  },
  {
    "text": "if your application is one of these sort of distributed distributed storage",
    "start": "2022570",
    "end": "2029380"
  },
  {
    "text": "systems that can handle take you know that can take a node failure and",
    "start": "2029380",
    "end": "2034590"
  },
  {
    "text": "potentially we start a replica on another node you'll have to you'll have",
    "start": "2034590",
    "end": "2042130"
  },
  {
    "text": "to sort of build build some logic into your operator for that workload to be",
    "start": "2042130",
    "end": "2050470"
  },
  {
    "text": "able to basically delete the volume from that pod so that we can so that it frees",
    "start": "2050470",
    "end": "2059110"
  },
  {
    "text": "up the system it frees up that binding to that node so that we can go find a",
    "start": "2059110",
    "end": "2064419"
  },
  {
    "text": "brand new disk and bind to a new node",
    "start": "2064419",
    "end": "2068819"
  },
  {
    "text": "Wilfried so the next question is how can we apply read ahead set into the configuration",
    "start": "2069960",
    "end": "2078669"
  },
  {
    "text": "the TMO formats are you familiar with the read ahead setting no I'm not",
    "start": "2078669",
    "end": "2086409"
  },
  {
    "text": "neither of us is familiar with the read ahead setting but maybe if you ping us on slack we can take into it more for",
    "start": "2086410",
    "end": "2091960"
  },
  {
    "text": "you nice so the next question is you",
    "start": "2091960",
    "end": "2097030"
  },
  {
    "text": "said that unmount volumes when resize is performant does the date",
    "start": "2097030",
    "end": "2102550"
  },
  {
    "text": "when William is resized yes all right so",
    "start": "2102550",
    "end": "2113500"
  },
  {
    "start": "2110000",
    "end": "2165000"
  },
  {
    "text": "the next question is for encrypted disks would it be possible to pass credentials",
    "start": "2113500",
    "end": "2119100"
  },
  {
    "text": "this question relates to a local persistent volume I guess it should be",
    "start": "2119100",
    "end": "2129690"
  },
  {
    "text": "it should be possible to if you put in annotations or anything into the PVC or",
    "start": "2129690",
    "end": "2136480"
  },
  {
    "text": "PV you can pass data from past data from that to the plug-in right now though the",
    "start": "2136480",
    "end": "2144190"
  },
  {
    "text": "plug-in does not understand those annotations so you would have to potentially enhance the plug-in to",
    "start": "2144190",
    "end": "2151660"
  },
  {
    "text": "support it yes once dynamic provisioning",
    "start": "2151660",
    "end": "2157600"
  },
  {
    "text": "for local storage comes out this will become easier yeah another question is",
    "start": "2157600",
    "end": "2168580"
  },
  {
    "start": "2165000",
    "end": "2225000"
  },
  {
    "text": "does the size of PVC or PvE will depend on size of local volume disk size or you",
    "start": "2168580",
    "end": "2176740"
  },
  {
    "text": "can curve spaces from one of one large local disk no so each each PVC can only",
    "start": "2176740",
    "end": "2186370"
  },
  {
    "text": "bind to one PV so if you want to break up one large disk right now you have to",
    "start": "2186370",
    "end": "2195250"
  },
  {
    "text": "manually partition the disk into smaller partitions and create a persistent",
    "start": "2195250",
    "end": "2201490"
  },
  {
    "text": "volume for each of these smaller partitions right now we're working on a",
    "start": "2201490",
    "end": "2206800"
  },
  {
    "text": "design to support dynamic provisioning using LVM I think that will support",
    "start": "2206800",
    "end": "2212680"
  },
  {
    "text": "they'll be able to support this use case better of carving up large disks perfect",
    "start": "2212680",
    "end": "2222930"
  },
  {
    "text": "so the next question is will this changes work on cubular",
    "start": "2222930",
    "end": "2228760"
  },
  {
    "start": "2225000",
    "end": "2335000"
  },
  {
    "text": "on timber Matic engine unknown to Daenerys I can answer these questions",
    "start": "2228760",
    "end": "2236500"
  },
  {
    "text": "d is dysfunctionality all this functionality that has been described in today's webinar is related to today what",
    "start": "2236500",
    "end": "2245260"
  },
  {
    "text": "Neela kubernetes this time if they're abusin of communities decades",
    "start": "2245260",
    "end": "2250900"
  },
  {
    "text": "and is conferment enough fishel certified so all different you know from the vanilla cabinets from the upstream",
    "start": "2250900",
    "end": "2257020"
  },
  {
    "text": "divinities can be also used on that specific commercial and non-commercial distribution",
    "start": "2257020",
    "end": "2264210"
  },
  {
    "text": "any other questions we have enough time here we have yet another question about",
    "start": "2265800",
    "end": "2276190"
  },
  {
    "text": "the features so that's the question that I can answer so where can we find",
    "start": "2276190",
    "end": "2281410"
  },
  {
    "text": "information on some other features the 25 other features in this release so the",
    "start": "2281410",
    "end": "2288100"
  },
  {
    "text": "brief information about them even find on blog kubernetes the dáil websites",
    "start": "2288100",
    "end": "2293230"
  },
  {
    "text": "that in terminators blog where we are posting the latest news from communities community including the release",
    "start": "2293230",
    "end": "2299620"
  },
  {
    "text": "announcement so please check the latest announcements from the previous week where we had kinetics 1 to 10 release",
    "start": "2299620",
    "end": "2307000"
  },
  {
    "text": "announcement and the detailed information the raw data about the features where the kubernetes community",
    "start": "2307000",
    "end": "2314140"
  },
  {
    "text": "itself strengths the features is communities slash features paper on",
    "start": "2314140",
    "end": "2319240"
  },
  {
    "text": "github so feel free to check it if you need any detailed information on what's",
    "start": "2319240",
    "end": "2324850"
  },
  {
    "text": "happening with mr. control is with the crown features aimed current release and",
    "start": "2324850",
    "end": "2330130"
  },
  {
    "text": "also with the features and approach releases included one to ten injuries",
    "start": "2330130",
    "end": "2338770"
  },
  {
    "start": "2335000",
    "end": "2400000"
  },
  {
    "text": "yet the question what is that to fire a requirement feature to work I suppose",
    "start": "2338770",
    "end": "2345360"
  },
  {
    "text": "that it's the question about conformance distributions so please check please",
    "start": "2345360",
    "end": "2352860"
  },
  {
    "text": "check the information about conformance cabinet is conformance distributions and C and C of github web page and C in C",
    "start": "2352860",
    "end": "2360870"
  },
  {
    "text": "github that comes C and C F slash when it is conformance so you'll be able to",
    "start": "2360870",
    "end": "2367410"
  },
  {
    "text": "find all the information about how what are the control and distribution of",
    "start": "2367410",
    "end": "2373170"
  },
  {
    "text": "communities and how to me how can they provide the requirements to be to be",
    "start": "2373170",
    "end": "2381690"
  },
  {
    "text": "conformant it's Kate github.com / C NC f",
    "start": "2381690",
    "end": "2387750"
  },
  {
    "text": "/ KS - conformance alright so it seems",
    "start": "2387750",
    "end": "2403320"
  },
  {
    "start": "2400000",
    "end": "2424000"
  },
  {
    "text": "that we have all the questions here so since everyone for Julian sank Assad and",
    "start": "2403320",
    "end": "2409440"
  },
  {
    "text": "shell for participating here and I hope to see you all next week at our next",
    "start": "2409440",
    "end": "2416130"
  },
  {
    "text": "webinar series related to cabinet is another cloud negative technologies since K everyone and thank you I",
    "start": "2416130",
    "end": "2426200"
  }
]
[
  {
    "text": "all right here we are we are on um so uh",
    "start": "240",
    "end": "3600"
  },
  {
    "text": "super thrilled to be here um myself Vipv",
    "start": "3600",
    "end": "6400"
  },
  {
    "text": "and with me is my colleague Andres we",
    "start": "6400",
    "end": "8559"
  },
  {
    "text": "are from the uh Google's cloud",
    "start": "8559",
    "end": "10160"
  },
  {
    "text": "networking team cloud load balancing and",
    "start": "10160",
    "end": "12559"
  },
  {
    "text": "the reason why we're here as you might",
    "start": "12559",
    "end": "14719"
  },
  {
    "text": "might not know uh Google's cloud load",
    "start": "14719",
    "end": "16880"
  },
  {
    "text": "balancing is based on envoy proxy all of",
    "start": "16880",
    "end": "19520"
  },
  {
    "text": "our application load balancers and um",
    "start": "19520",
    "end": "22880"
  },
  {
    "text": "we've been doing a lot of work on um AI",
    "start": "22880",
    "end": "25680"
  },
  {
    "text": "serving LM serving as part of Google",
    "start": "25680",
    "end": "27840"
  },
  {
    "text": "cloud load balancing and also",
    "start": "27840",
    "end": "29359"
  },
  {
    "text": "upstreaming all of that work into envoy",
    "start": "29359",
    "end": "31679"
  },
  {
    "text": "proxy so trying to represent that but",
    "start": "31679",
    "end": "33920"
  },
  {
    "text": "also represent a lot of the work across",
    "start": "33920",
    "end": "36239"
  },
  {
    "text": "uh you know number of different projects",
    "start": "36239",
    "end": "38000"
  },
  {
    "text": "and different companies uh that are",
    "start": "38000",
    "end": "39840"
  },
  {
    "text": "working in the space also on envoy",
    "start": "39840",
    "end": "42920"
  },
  {
    "text": "okay so jumping right in",
    "start": "42920",
    "end": "46520"
  },
  {
    "text": "um talking about what are customers",
    "start": "46520",
    "end": "49360"
  },
  {
    "text": "looking for in terms of consuming LLMs",
    "start": "49360",
    "end": "52239"
  },
  {
    "text": "um there's a some of the same things",
    "start": "52239",
    "end": "54399"
  },
  {
    "text": "that you'd have from any enterprise",
    "start": "54399",
    "end": "56000"
  },
  {
    "text": "service right having simple access",
    "start": "56000",
    "end": "58000"
  },
  {
    "text": "especially with with different LM",
    "start": "58000",
    "end": "59840"
  },
  {
    "text": "providers having different sort of",
    "start": "59840",
    "end": "61600"
  },
  {
    "text": "interfaces for consuming their LMs uh",
    "start": "61600",
    "end": "64559"
  },
  {
    "text": "customers consume developers primarily",
    "start": "64559",
    "end": "66720"
  },
  {
    "text": "are looking for simple way to access all",
    "start": "66720",
    "end": "69439"
  },
  {
    "text": "of these services and",
    "start": "69439",
    "end": "71880"
  },
  {
    "text": "LMs doing it secure ly so this is",
    "start": "71880",
    "end": "74479"
  },
  {
    "text": "especially you know trying to getting",
    "start": "74479",
    "end": "76159"
  },
  {
    "text": "applications into production and moving",
    "start": "76159",
    "end": "77920"
  },
  {
    "text": "them from development security starts to",
    "start": "77920",
    "end": "80080"
  },
  {
    "text": "become top of mind and even from your",
    "start": "80080",
    "end": "81759"
  },
  {
    "text": "development environments how do you",
    "start": "81759",
    "end": "83520"
  },
  {
    "text": "avoid key sprawl how do you have like",
    "start": "83520",
    "end": "85360"
  },
  {
    "text": "the kind of right credential management",
    "start": "85360",
    "end": "87360"
  },
  {
    "text": "and guardrails reliability again",
    "start": "87360",
    "end": "90080"
  },
  {
    "text": "especially as these workloads start to",
    "start": "90080",
    "end": "92079"
  },
  {
    "text": "scale up you know we know that GPU TPU",
    "start": "92079",
    "end": "94320"
  },
  {
    "text": "capacity is still very constrained and",
    "start": "94320",
    "end": "96400"
  },
  {
    "text": "having reliable access to these LM",
    "start": "96400",
    "end": "98560"
  },
  {
    "text": "services is still very much takes some",
    "start": "98560",
    "end": "100640"
  },
  {
    "text": "engineering uh effort and consideration",
    "start": "100640",
    "end": "103520"
  },
  {
    "text": "finally you want your uh applications",
    "start": "103520",
    "end": "105920"
  },
  {
    "text": "and even your LM serving to be fast",
    "start": "105920",
    "end": "107840"
  },
  {
    "text": "right user experience matters um and to",
    "start": "107840",
    "end": "110720"
  },
  {
    "text": "have that you know kind of low latency",
    "start": "110720",
    "end": "112320"
  },
  {
    "text": "response um and and then finally cost",
    "start": "112320",
    "end": "115119"
  },
  {
    "text": "efficiency right these things are uh",
    "start": "115119",
    "end": "118520"
  },
  {
    "text": "effic you know being able to uh do it",
    "start": "118520",
    "end": "121520"
  },
  {
    "text": "cost efficiently certainly is again",
    "start": "121520",
    "end": "124560"
  },
  {
    "text": "another top of mind",
    "start": "124560",
    "end": "126560"
  },
  {
    "text": "so with that we'll just look at you know",
    "start": "126560",
    "end": "128399"
  },
  {
    "text": "given these uh kind of high level",
    "start": "128399",
    "end": "130520"
  },
  {
    "text": "requirements what are the different",
    "start": "130520",
    "end": "132800"
  },
  {
    "text": "adoption patterns what are the different",
    "start": "132800",
    "end": "134480"
  },
  {
    "text": "deployment models that we see often uh",
    "start": "134480",
    "end": "137599"
  },
  {
    "text": "customers deploy so customers we see",
    "start": "137599",
    "end": "140720"
  },
  {
    "text": "often are consuming LM services from a",
    "start": "140720",
    "end": "143200"
  },
  {
    "text": "variety of different model providers uh",
    "start": "143200",
    "end": "145760"
  },
  {
    "text": "could be from your hugging face could be",
    "start": "145760",
    "end": "147599"
  },
  {
    "text": "from bedrock could be from open AAI",
    "start": "147599",
    "end": "150080"
  },
  {
    "text": "vertex so on and so forth and in",
    "start": "150080",
    "end": "152400"
  },
  {
    "text": "conjunction uh they could also be",
    "start": "152400",
    "end": "154560"
  },
  {
    "text": "deploying models on their own clusters",
    "start": "154560",
    "end": "156959"
  },
  {
    "text": "and so with these sort of uh situations",
    "start": "156959",
    "end": "159519"
  },
  {
    "text": "we they often end up requiring some sort",
    "start": "159519",
    "end": "161760"
  },
  {
    "text": "of an API gateway to front end all of",
    "start": "161760",
    "end": "164160"
  },
  {
    "text": "these different APIs from all of these",
    "start": "164160",
    "end": "165920"
  },
  {
    "text": "different LM providers uh to have again",
    "start": "165920",
    "end": "168400"
  },
  {
    "text": "that simplicity primarily but also some",
    "start": "168400",
    "end": "170400"
  },
  {
    "text": "of the security",
    "start": "170400",
    "end": "173720"
  },
  {
    "text": "aspects then you've got customers who",
    "start": "173720",
    "end": "176400"
  },
  {
    "text": "are deploying models on their Kubernetes",
    "start": "176400",
    "end": "178879"
  },
  {
    "text": "clusters uh we see this pattern",
    "start": "178879",
    "end": "180800"
  },
  {
    "text": "especially as customers start to scale",
    "start": "180800",
    "end": "182480"
  },
  {
    "text": "up their workloads they're looking for",
    "start": "182480",
    "end": "184239"
  },
  {
    "text": "better cost performance uh price",
    "start": "184239",
    "end": "186560"
  },
  {
    "text": "performance uh and also like better",
    "start": "186560",
    "end": "189040"
  },
  {
    "text": "control of the infrastructure and being",
    "start": "189040",
    "end": "191200"
  },
  {
    "text": "able to fine-tune it and so that's where",
    "start": "191200",
    "end": "193599"
  },
  {
    "text": "a lot of Kubernetes deployments and",
    "start": "193599",
    "end": "195360"
  },
  {
    "text": "similarly for customers who have",
    "start": "195360",
    "end": "197040"
  },
  {
    "text": "standardized on service mesh patterns",
    "start": "197040",
    "end": "199040"
  },
  {
    "text": "they're also deploying these LMs and",
    "start": "199040",
    "end": "201519"
  },
  {
    "text": "publishing them as services and their",
    "start": "201519",
    "end": "203440"
  },
  {
    "text": "own um service meshes",
    "start": "203440",
    "end": "207519"
  },
  {
    "text": "and then the other pattern we see",
    "start": "207519",
    "end": "209200"
  },
  {
    "text": "emerging uh quite a bit is that all of",
    "start": "209200",
    "end": "212239"
  },
  {
    "text": "these LMS now are not only like you",
    "start": "212239",
    "end": "214879"
  },
  {
    "text": "don't just have like clients or service",
    "start": "214879",
    "end": "216599"
  },
  {
    "text": "applications connecting to LLMs but now",
    "start": "216599",
    "end": "219599"
  },
  {
    "text": "LLM's calling out to tools or even like",
    "start": "219599",
    "end": "222799"
  },
  {
    "text": "things like MCP servers um now that",
    "start": "222799",
    "end": "225599"
  },
  {
    "text": "anthropic has come up with uh a",
    "start": "225599",
    "end": "227680"
  },
  {
    "text": "standardized way to allow third parties",
    "start": "227680",
    "end": "230400"
  },
  {
    "text": "or uh you know applications to expose",
    "start": "230400",
    "end": "232720"
  },
  {
    "text": "their services to LMS we see a lot of",
    "start": "232720",
    "end": "234959"
  },
  {
    "text": "these sort of um egress deployment",
    "start": "234959",
    "end": "237040"
  },
  {
    "text": "common patterns from LMS to third party",
    "start": "237040",
    "end": "239519"
  },
  {
    "text": "tools and services and that's another",
    "start": "239519",
    "end": "242080"
  },
  {
    "text": "area where um you know kind of showing",
    "start": "242080",
    "end": "244159"
  },
  {
    "text": "where envoy fits into each of these uh",
    "start": "244159",
    "end": "246560"
  },
  {
    "text": "data plane paths and you know it's as",
    "start": "246560",
    "end": "249439"
  },
  {
    "text": "you can see here it's egress ingress as",
    "start": "249439",
    "end": "252319"
  },
  {
    "text": "well as a mesh patterns that it's it's",
    "start": "252319",
    "end": "255280"
  },
  {
    "text": "applicable",
    "start": "255280",
    "end": "257720"
  },
  {
    "text": "in so diving a little bit deeper into",
    "start": "257720",
    "end": "260880"
  },
  {
    "text": "the particular considerations um",
    "start": "260880",
    "end": "263759"
  },
  {
    "text": "traditionally in each one of these",
    "start": "263759",
    "end": "265600"
  },
  {
    "text": "deployment paths so in terms of like",
    "start": "265600",
    "end": "268800"
  },
  {
    "text": "consuming LMS from a variety of",
    "start": "268800",
    "end": "270400"
  },
  {
    "text": "different providers we spoke about that",
    "start": "270400",
    "end": "272639"
  },
  {
    "text": "you know you go to OpenAI they have a",
    "start": "272639",
    "end": "274160"
  },
  {
    "text": "certain API spec go to anthropic they've",
    "start": "274160",
    "end": "276320"
  },
  {
    "text": "got a different one Gemini Bedrock like",
    "start": "276320",
    "end": "278800"
  },
  {
    "text": "everybody has got their own API spec on",
    "start": "278800",
    "end": "280639"
  },
  {
    "text": "how to consume models and that's like an",
    "start": "280639",
    "end": "282800"
  },
  {
    "text": "additional overhead for your developers",
    "start": "282800",
    "end": "284720"
  },
  {
    "text": "right so with API gateways having a",
    "start": "284720",
    "end": "287600"
  },
  {
    "text": "single consistent API surface uh being",
    "start": "287600",
    "end": "290479"
  },
  {
    "text": "able to very easily discover all the",
    "start": "290479",
    "end": "292720"
  },
  {
    "text": "different um models and the providers",
    "start": "292720",
    "end": "294880"
  },
  {
    "text": "that are available for developers to",
    "start": "294880",
    "end": "297120"
  },
  {
    "text": "That's something that um you know AI",
    "start": "297120",
    "end": "299040"
  },
  {
    "text": "gateways or API gateways often provide",
    "start": "299040",
    "end": "301360"
  },
  {
    "text": "you with the second one is also on the",
    "start": "301360",
    "end": "304160"
  },
  {
    "text": "security side so instead of developers",
    "start": "304160",
    "end": "307280"
  },
  {
    "text": "everybody just having to embed um you",
    "start": "307280",
    "end": "309520"
  },
  {
    "text": "know in a bespoke model some sort of a",
    "start": "309520",
    "end": "311360"
  },
  {
    "text": "AI security safety um in into their own",
    "start": "311360",
    "end": "314639"
  },
  {
    "text": "code and again why this matters is as",
    "start": "314639",
    "end": "316960"
  },
  {
    "text": "you might have seen that uh LMS by",
    "start": "316960",
    "end": "319199"
  },
  {
    "text": "themselves uh may or may not have the",
    "start": "319199",
    "end": "321600"
  },
  {
    "text": "kind of necessary guard rails um and you",
    "start": "321600",
    "end": "324400"
  },
  {
    "text": "know you know checks against things like",
    "start": "324400",
    "end": "327440"
  },
  {
    "text": "um you know jailbreaks or you know",
    "start": "327440",
    "end": "329600"
  },
  {
    "text": "prompt injection attacks so these things",
    "start": "329600",
    "end": "331759"
  },
  {
    "text": "that uh or even like things like uh",
    "start": "331759",
    "end": "333840"
  },
  {
    "text": "safety controls right these are things",
    "start": "333840",
    "end": "335759"
  },
  {
    "text": "that the LLM themselves might not",
    "start": "335759",
    "end": "337440"
  },
  {
    "text": "provide so that comes like either the",
    "start": "337440",
    "end": "339600"
  },
  {
    "text": "developer has to do it or the platform",
    "start": "339600",
    "end": "341440"
  },
  {
    "text": "operator or your central security team",
    "start": "341440",
    "end": "344000"
  },
  {
    "text": "would have to have something in the path",
    "start": "344000",
    "end": "345840"
  },
  {
    "text": "to apply these guardrails so just by",
    "start": "345840",
    "end": "348639"
  },
  {
    "text": "natively developers accessing these LMS",
    "start": "348639",
    "end": "350720"
  },
  {
    "text": "might give you fragmented coverage",
    "start": "350720",
    "end": "352880"
  },
  {
    "text": "having some sort of an API gateway where",
    "start": "352880",
    "end": "355120"
  },
  {
    "text": "you could attach some sort of um AI",
    "start": "355120",
    "end": "357280"
  },
  {
    "text": "guardrail an AI security check uh",
    "start": "357280",
    "end": "360320"
  },
  {
    "text": "provides you a better level of security",
    "start": "360320",
    "end": "362320"
  },
  {
    "text": "and then also you don't want like just",
    "start": "362320",
    "end": "363919"
  },
  {
    "text": "developers having using API keys and",
    "start": "363919",
    "end": "366240"
  },
  {
    "text": "tokens all over the place right having",
    "start": "366240",
    "end": "368160"
  },
  {
    "text": "some sort of centralized control some",
    "start": "368160",
    "end": "370479"
  },
  {
    "text": "kind of life cycle management for them",
    "start": "370479",
    "end": "372800"
  },
  {
    "text": "um and also being able to like",
    "start": "372800",
    "end": "374560"
  },
  {
    "text": "consistently allow developers a single",
    "start": "374560",
    "end": "377360"
  },
  {
    "text": "way to um manage security while in the",
    "start": "377360",
    "end": "380880"
  },
  {
    "text": "back end you can have some sort of a LM",
    "start": "380880",
    "end": "382560"
  },
  {
    "text": "provider specific authentication",
    "start": "382560",
    "end": "384960"
  },
  {
    "text": "authorization mechanism so that's really",
    "start": "384960",
    "end": "386960"
  },
  {
    "text": "simplifies developers lives and then",
    "start": "386960",
    "end": "389120"
  },
  {
    "text": "finally is the aspect of centralized",
    "start": "389120",
    "end": "390960"
  },
  {
    "text": "logging and cost",
    "start": "390960",
    "end": "394000"
  },
  {
    "text": "management when it comes to uh",
    "start": "394919",
    "end": "397440"
  },
  {
    "text": "self-hosted models the particular",
    "start": "397440",
    "end": "399120"
  },
  {
    "text": "challenges that we see is especially on",
    "start": "399120",
    "end": "402000"
  },
  {
    "text": "you know the the number one reason that",
    "start": "402000",
    "end": "403840"
  },
  {
    "text": "you know customers go to this model is",
    "start": "403840",
    "end": "405919"
  },
  {
    "text": "to get better price performance but to",
    "start": "405919",
    "end": "408240"
  },
  {
    "text": "get better price performance if you just",
    "start": "408240",
    "end": "410240"
  },
  {
    "text": "look at traditional load balancing uh",
    "start": "410240",
    "end": "412639"
  },
  {
    "text": "what we've seen especially with",
    "start": "412639",
    "end": "414319"
  },
  {
    "text": "customers serving LMS at scale is that",
    "start": "414319",
    "end": "417039"
  },
  {
    "text": "your traditional roundroin load",
    "start": "417039",
    "end": "419039"
  },
  {
    "text": "balancing schemes are not a good fit for",
    "start": "419039",
    "end": "422080"
  },
  {
    "text": "serving LLMs so what happens with LMS is",
    "start": "422080",
    "end": "424800"
  },
  {
    "text": "that the requests are highly variable in",
    "start": "424800",
    "end": "428000"
  },
  {
    "text": "duration so it could vary anywhere from",
    "start": "428000",
    "end": "430160"
  },
  {
    "text": "seconds to minutes uh as compared to",
    "start": "430160",
    "end": "432560"
  },
  {
    "text": "traditional web serving where the",
    "start": "432560",
    "end": "434319"
  },
  {
    "text": "request is only in the order of",
    "start": "434319",
    "end": "435360"
  },
  {
    "text": "milliseconds so when you've got such a a",
    "start": "435360",
    "end": "438080"
  },
  {
    "text": "variable traffic distribution pattern or",
    "start": "438080",
    "end": "440080"
  },
  {
    "text": "workload pattern and if you use things",
    "start": "440080",
    "end": "442400"
  },
  {
    "text": "like roundroin what ends up happening is",
    "start": "442400",
    "end": "444800"
  },
  {
    "text": "that the load gets unevenly spread out",
    "start": "444800",
    "end": "446880"
  },
  {
    "text": "across your backends and as a result",
    "start": "446880",
    "end": "449520"
  },
  {
    "text": "what that means is that you get um you",
    "start": "449520",
    "end": "452479"
  },
  {
    "text": "know lower or suboptimal serving",
    "start": "452479",
    "end": "454680"
  },
  {
    "text": "performance and so that's where a lot of",
    "start": "454680",
    "end": "457360"
  },
  {
    "text": "work has been uh we we'll talk about in",
    "start": "457360",
    "end": "459280"
  },
  {
    "text": "detail is how you can evolve load",
    "start": "459280",
    "end": "461440"
  },
  {
    "text": "balancing for better serving based on",
    "start": "461440",
    "end": "463680"
  },
  {
    "text": "the workload",
    "start": "463680",
    "end": "464840"
  },
  {
    "text": "characteristics of these LM",
    "start": "464840",
    "end": "468880"
  },
  {
    "text": "workloads okay so in a nutshell u across",
    "start": "470280",
    "end": "473840"
  },
  {
    "text": "all of these challenges what uh we have",
    "start": "473840",
    "end": "476240"
  },
  {
    "text": "uh what what the effort on on envoy",
    "start": "476240",
    "end": "478080"
  },
  {
    "text": "proxy is go doing is to address all of",
    "start": "478080",
    "end": "480800"
  },
  {
    "text": "these uh both in terms of the API",
    "start": "480800",
    "end": "482800"
  },
  {
    "text": "gateways in terms of service measures in",
    "start": "482800",
    "end": "485199"
  },
  {
    "text": "terms of kubernetes ingress and bring in",
    "start": "485199",
    "end": "487520"
  },
  {
    "text": "a whole set of enhancements to better",
    "start": "487520",
    "end": "489840"
  },
  {
    "text": "serve LMS right starting from uh a lot",
    "start": "489840",
    "end": "493120"
  },
  {
    "text": "of this is enabled through extensions",
    "start": "493120",
    "end": "495199"
  },
  {
    "text": "and you know natively get uh embedded",
    "start": "495199",
    "end": "497360"
  },
  {
    "text": "into pro on web proxy natively but at",
    "start": "497360",
    "end": "500000"
  },
  {
    "text": "least from uh including across cross",
    "start": "500000",
    "end": "502039"
  },
  {
    "text": "extensions uh being able to provide a",
    "start": "502039",
    "end": "504639"
  },
  {
    "text": "unified API surface for different L",
    "start": "504639",
    "end": "507199"
  },
  {
    "text": "providers uh being able to route based",
    "start": "507199",
    "end": "509919"
  },
  {
    "text": "on the model name and we'll learn a",
    "start": "509919",
    "end": "511360"
  },
  {
    "text": "little bit about that uh what that means",
    "start": "511360",
    "end": "514320"
  },
  {
    "text": "uh being able to add security guard",
    "start": "514320",
    "end": "516479"
  },
  {
    "text": "rails as part of the data pl path and",
    "start": "516479",
    "end": "518959"
  },
  {
    "text": "being able to add things like you know",
    "start": "518959",
    "end": "521120"
  },
  {
    "text": "whether it's you know Google's own model",
    "start": "521120",
    "end": "523039"
  },
  {
    "text": "armor or even thirdart tools like you",
    "start": "523039",
    "end": "525279"
  },
  {
    "text": "know from Palo Alto networks and from uh",
    "start": "525279",
    "end": "527920"
  },
  {
    "text": "Nvidia Nemo guardrails all of these in",
    "start": "527920",
    "end": "530000"
  },
  {
    "text": "power data plane uh we always had client",
    "start": "530000",
    "end": "533360"
  },
  {
    "text": "authentication authorization but being",
    "start": "533360",
    "end": "535120"
  },
  {
    "text": "able to do it across different LM",
    "start": "535120",
    "end": "536959"
  },
  {
    "text": "providers",
    "start": "536959",
    "end": "538560"
  },
  {
    "text": "um again and then terms of the um uh",
    "start": "538560",
    "end": "541680"
  },
  {
    "text": "speed in um performance so Envoy by",
    "start": "541680",
    "end": "545040"
  },
  {
    "text": "itself natively has a very high",
    "start": "545040",
    "end": "546560"
  },
  {
    "text": "performance data plane but now we are",
    "start": "546560",
    "end": "548720"
  },
  {
    "text": "also evolving the load balancing",
    "start": "548720",
    "end": "550560"
  },
  {
    "text": "capabilities of Envoy to be more catered",
    "start": "550560",
    "end": "553279"
  },
  {
    "text": "towards LM workload patterns and then",
    "start": "553279",
    "end": "556080"
  },
  {
    "text": "finally in terms of uh reliability being",
    "start": "556080",
    "end": "558080"
  },
  {
    "text": "able to serve across multiple backends",
    "start": "558080",
    "end": "560160"
  },
  {
    "text": "being able to have like routing policies",
    "start": "560160",
    "end": "562480"
  },
  {
    "text": "again based on the model name um that uh",
    "start": "562480",
    "end": "565680"
  },
  {
    "text": "helps you drive better reliability and",
    "start": "565680",
    "end": "567920"
  },
  {
    "text": "then also in terms of uh cost efficiency",
    "start": "567920",
    "end": "570160"
  },
  {
    "text": "being able to do things like token based",
    "start": "570160",
    "end": "571760"
  },
  {
    "text": "rate",
    "start": "571760",
    "end": "573560"
  },
  {
    "text": "limiting okay so u we'll deep dive into",
    "start": "573560",
    "end": "578720"
  },
  {
    "text": "like there's like essentially um two key",
    "start": "578720",
    "end": "581040"
  },
  {
    "text": "extensions that we'll go deep dive into",
    "start": "581040",
    "end": "583360"
  },
  {
    "text": "but just kind of showing you how",
    "start": "583360",
    "end": "585279"
  },
  {
    "text": "extensible envoy is for these sort of",
    "start": "585279",
    "end": "587440"
  },
  {
    "text": "use cases the first one we'll talk",
    "start": "587440",
    "end": "589680"
  },
  {
    "text": "Andreas will talk about in more detail",
    "start": "589680",
    "end": "591600"
  },
  {
    "text": "is about how we have invol evolved it",
    "start": "591600",
    "end": "593519"
  },
  {
    "text": "for doing model based model name based",
    "start": "593519",
    "end": "595920"
  },
  {
    "text": "routing",
    "start": "595920",
    "end": "597519"
  },
  {
    "text": "uh the second one is around how we are",
    "start": "597519",
    "end": "600080"
  },
  {
    "text": "going to be doing uh load balancing that",
    "start": "600080",
    "end": "602640"
  },
  {
    "text": "is more tuned for LM workloads to give",
    "start": "602640",
    "end": "604959"
  },
  {
    "text": "you better performance and then finally",
    "start": "604959",
    "end": "608080"
  },
  {
    "text": "um taking the same pattern extending to",
    "start": "608080",
    "end": "610160"
  },
  {
    "text": "other use cases like AI safety or even",
    "start": "610160",
    "end": "612240"
  },
  {
    "text": "things like semantic caching going",
    "start": "612240",
    "end": "613760"
  },
  {
    "text": "forward so with that we'll deep dive",
    "start": "613760",
    "end": "615920"
  },
  {
    "text": "into each one of these and here and to",
    "start": "615920",
    "end": "618320"
  },
  {
    "text": "talk about that all right thanks VA yeah",
    "start": "618320",
    "end": "622160"
  },
  {
    "text": "I'm just going to hang that over here um",
    "start": "622160",
    "end": "624240"
  },
  {
    "text": "all right hello everyone",
    "start": "624240",
    "end": "626120"
  },
  {
    "text": "um so yeah so I'm going to focus on how",
    "start": "626120",
    "end": "629360"
  },
  {
    "text": "we're all evolving Amboy uh for these",
    "start": "629360",
    "end": "631640"
  },
  {
    "text": "capabilities um the the slides that",
    "start": "631640",
    "end": "634480"
  },
  {
    "text": "we've prepared and is are mostly focused",
    "start": "634480",
    "end": "636880"
  },
  {
    "text": "on the self-hosted inference use case",
    "start": "636880",
    "end": "639200"
  },
  {
    "text": "but these patterns will generalize to",
    "start": "639200",
    "end": "641120"
  },
  {
    "text": "the other use cases that Vib just",
    "start": "641120",
    "end": "642800"
  },
  {
    "text": "mentioned like API gateways and and",
    "start": "642800",
    "end": "644959"
  },
  {
    "text": "service mesh um so yeah so the the first",
    "start": "644959",
    "end": "647920"
  },
  {
    "text": "use case we want to talk about is model",
    "start": "647920",
    "end": "649440"
  },
  {
    "text": "aware routing so this involves being",
    "start": "649440",
    "end": "651440"
  },
  {
    "text": "able to actually uh create routes that",
    "start": "651440",
    "end": "654480"
  },
  {
    "text": "are pointing to specific models as",
    "start": "654480",
    "end": "656640"
  },
  {
    "text": "opposed to just your pool of compute um",
    "start": "656640",
    "end": "659760"
  },
  {
    "text": "the the the key challenge here is that",
    "start": "659760",
    "end": "661680"
  },
  {
    "text": "geni protocols um are not really",
    "start": "661680",
    "end": "664160"
  },
  {
    "text": "optimized for networking and currently",
    "start": "664160",
    "end": "666560"
  },
  {
    "text": "they require us to be parsing the",
    "start": "666560",
    "end": "668880"
  },
  {
    "text": "request payload in order to actually",
    "start": "668880",
    "end": "670720"
  },
  {
    "text": "determine for example what the model",
    "start": "670720",
    "end": "672079"
  },
  {
    "text": "name is uh and extract you know really",
    "start": "672079",
    "end": "674160"
  },
  {
    "text": "the key attributes that we need for for",
    "start": "674160",
    "end": "675839"
  },
  {
    "text": "routing right so the end goal is that we",
    "start": "675839",
    "end": "679120"
  },
  {
    "text": "want to have native envoy support for",
    "start": "679120",
    "end": "681519"
  },
  {
    "text": "things like body uh parsing and body",
    "start": "681519",
    "end": "684160"
  },
  {
    "text": "transformations there are envoy issues",
    "start": "684160",
    "end": "685920"
  },
  {
    "text": "found around this um and you know one",
    "start": "685920",
    "end": "689920"
  },
  {
    "text": "thing to call out is that some of these",
    "start": "689920",
    "end": "691120"
  },
  {
    "text": "capabilities will require significant",
    "start": "691120",
    "end": "693120"
  },
  {
    "text": "buffering um while others can um",
    "start": "693120",
    "end": "696640"
  },
  {
    "text": "leverage you know streaming support",
    "start": "696640",
    "end": "698079"
  },
  {
    "text": "depending on the protocol thankfully",
    "start": "698079",
    "end": "699839"
  },
  {
    "text": "these protocols are currently JSON based",
    "start": "699839",
    "end": "701440"
  },
  {
    "text": "so so there's a path towards uh",
    "start": "701440",
    "end": "703200"
  },
  {
    "text": "streaming parsing uh but if you're",
    "start": "703200",
    "end": "705600"
  },
  {
    "text": "making a routing decision based on this",
    "start": "705600",
    "end": "707120"
  },
  {
    "text": "data then you need to buffer right so um",
    "start": "707120",
    "end": "710000"
  },
  {
    "text": "so the way that we're approaching this",
    "start": "710000",
    "end": "711279"
  },
  {
    "text": "right now is that we're using envoy um",
    "start": "711279",
    "end": "714160"
  },
  {
    "text": "until we have n n n n n n n n n n n n n",
    "start": "714160",
    "end": "715040"
  },
  {
    "text": "n n n n n n n n capabilities we're using",
    "start": "715040",
    "end": "716399"
  },
  {
    "text": "extensibility",
    "start": "716399",
    "end": "718079"
  },
  {
    "text": "um and and we've created this thing",
    "start": "718079",
    "end": "720320"
  },
  {
    "text": "called the bodybased router to handle",
    "start": "720320",
    "end": "722000"
  },
  {
    "text": "the parsing the attribute extraction and",
    "start": "722000",
    "end": "724000"
  },
  {
    "text": "the",
    "start": "724000",
    "end": "724680"
  },
  {
    "text": "routing so how does this work so we're",
    "start": "724680",
    "end": "728079"
  },
  {
    "text": "we're using extensions and and for the",
    "start": "728079",
    "end": "730480"
  },
  {
    "text": "majority of this talk I'll be talking",
    "start": "730480",
    "end": "731680"
  },
  {
    "text": "about actually xrock based based",
    "start": "731680",
    "end": "733680"
  },
  {
    "text": "extensions um and what the extension",
    "start": "733680",
    "end": "736000"
  },
  {
    "text": "really does here is that it registers",
    "start": "736000",
    "end": "737680"
  },
  {
    "text": "for request header and body events um it",
    "start": "737680",
    "end": "740800"
  },
  {
    "text": "does the necessary attribute parsing um",
    "start": "740800",
    "end": "743360"
  },
  {
    "text": "and it ends up appending a header um",
    "start": "743360",
    "end": "745760"
  },
  {
    "text": "let's call it x gateway model name that",
    "start": "745760",
    "end": "747839"
  },
  {
    "text": "is then matched in the route",
    "start": "747839",
    "end": "749040"
  },
  {
    "text": "configuration with a header match to",
    "start": "749040",
    "end": "750800"
  },
  {
    "text": "select the corresponding cluster right",
    "start": "750800",
    "end": "752959"
  },
  {
    "text": "so we've effectively externalized the uh",
    "start": "752959",
    "end": "756160"
  },
  {
    "text": "the body parsing um that gives us a nice",
    "start": "756160",
    "end": "759120"
  },
  {
    "text": "nice property which is now the buffering",
    "start": "759120",
    "end": "760880"
  },
  {
    "text": "is also externalized uh which some use",
    "start": "760880",
    "end": "763040"
  },
  {
    "text": "cases will require depending on your on",
    "start": "763040",
    "end": "765279"
  },
  {
    "text": "your body sizes and your prompt sizes um",
    "start": "765279",
    "end": "768959"
  },
  {
    "text": "and and yeah and that's effectively how",
    "start": "768959",
    "end": "772399"
  },
  {
    "text": "uh how we're handling this um this",
    "start": "772399",
    "end": "774800"
  },
  {
    "text": "challenge with model aware",
    "start": "774800",
    "end": "776680"
  },
  {
    "text": "routing so I've mentioned XRO a couple",
    "start": "776680",
    "end": "779760"
  },
  {
    "text": "times so just to give a a bit of",
    "start": "779760",
    "end": "781360"
  },
  {
    "text": "background on on what that is it's a",
    "start": "781360",
    "end": "783040"
  },
  {
    "text": "filter um that essentially calls out via",
    "start": "783040",
    "end": "786399"
  },
  {
    "text": "gRPC to external services at various",
    "start": "786399",
    "end": "788959"
  },
  {
    "text": "HTTP life cycle stages so you can",
    "start": "788959",
    "end": "791519"
  },
  {
    "text": "specify whether you want to receive",
    "start": "791519",
    "end": "792959"
  },
  {
    "text": "request headers you know body trailers",
    "start": "792959",
    "end": "795680"
  },
  {
    "text": "and same for that response path um it",
    "start": "795680",
    "end": "798639"
  },
  {
    "text": "provides both the HTTP attributes right",
    "start": "798639",
    "end": "801040"
  },
  {
    "text": "either the headers or the payload along",
    "start": "801040",
    "end": "803279"
  },
  {
    "text": "with any configured dynamic um metadata",
    "start": "803279",
    "end": "806079"
  },
  {
    "text": "name spaces um it can be used to",
    "start": "806079",
    "end": "808880"
  },
  {
    "text": "influence envoy cluster picking which is",
    "start": "808880",
    "end": "810800"
  },
  {
    "text": "what we saw with the body router um it",
    "start": "810800",
    "end": "812959"
  },
  {
    "text": "can also be used to influence endpoint",
    "start": "812959",
    "end": "814560"
  },
  {
    "text": "picking decisions and we're going to get",
    "start": "814560",
    "end": "816240"
  },
  {
    "text": "into that in a few slides um and it also",
    "start": "816240",
    "end": "819920"
  },
  {
    "text": "has a nice property that when you have",
    "start": "819920",
    "end": "822079"
  },
  {
    "text": "these extremely large payloads you can",
    "start": "822079",
    "end": "823680"
  },
  {
    "text": "externalize the buffering um to this",
    "start": "823680",
    "end": "826000"
  },
  {
    "text": "callout service um so there's there's",
    "start": "826000",
    "end": "829440"
  },
  {
    "text": "some notable recent envoy enhancements",
    "start": "829440",
    "end": "831360"
  },
  {
    "text": "in this space i listed a few PRs um",
    "start": "831360",
    "end": "833839"
  },
  {
    "text": "there's work being done for XRO",
    "start": "833839",
    "end": "835440"
  },
  {
    "text": "scalability there's also work being done",
    "start": "835440",
    "end": "837120"
  },
  {
    "text": "to enhance the ampoint picking",
    "start": "837120",
    "end": "838720"
  },
  {
    "text": "capabilities that Amboy has using",
    "start": "838720",
    "end": "842560"
  },
  {
    "text": "XRO okay so the the second major part of",
    "start": "842760",
    "end": "846240"
  },
  {
    "text": "this evolution then is um inference",
    "start": "846240",
    "end": "848639"
  },
  {
    "text": "optimized load balancing and there are",
    "start": "848639",
    "end": "851199"
  },
  {
    "text": "really two key components here right we",
    "start": "851199",
    "end": "853279"
  },
  {
    "text": "have the the first major component is we",
    "start": "853279",
    "end": "855519"
  },
  {
    "text": "want an inference optimized algorithm a",
    "start": "855519",
    "end": "857519"
  },
  {
    "text": "load balancing algorithm right and I'm",
    "start": "857519",
    "end": "859839"
  },
  {
    "text": "not going to do a deep dive on uh model",
    "start": "859839",
    "end": "863120"
  },
  {
    "text": "server token generation as part of this",
    "start": "863120",
    "end": "864800"
  },
  {
    "text": "talk because that's its own separate",
    "start": "864800",
    "end": "866399"
  },
  {
    "text": "talk um but really the key things to",
    "start": "866399",
    "end": "869040"
  },
  {
    "text": "note are that a lot of these algorithms",
    "start": "869040",
    "end": "871440"
  },
  {
    "text": "right now are focused on uh managing",
    "start": "871440",
    "end": "874240"
  },
  {
    "text": "this um key value cache that's used to",
    "start": "874240",
    "end": "876480"
  },
  {
    "text": "in store intermediate uh outputs from",
    "start": "876480",
    "end": "878480"
  },
  {
    "text": "the LMS and really prevent saturation of",
    "start": "878480",
    "end": "881760"
  },
  {
    "text": "that cache so that's one of the key",
    "start": "881760",
    "end": "883279"
  },
  {
    "text": "things that the algorithms are doing now",
    "start": "883279",
    "end": "884639"
  },
  {
    "text": "as well as managing these pending",
    "start": "884639",
    "end": "886399"
  },
  {
    "text": "request cues that are also building up",
    "start": "886399",
    "end": "888000"
  },
  {
    "text": "in model servers okay so in order to do",
    "start": "888000",
    "end": "892160"
  },
  {
    "text": "that these inference optimized",
    "start": "892160",
    "end": "893360"
  },
  {
    "text": "algorithms require um load signals",
    "start": "893360",
    "end": "896720"
  },
  {
    "text": "directly from the model servers and",
    "start": "896720",
    "end": "899120"
  },
  {
    "text": "that's sort of the second major",
    "start": "899120",
    "end": "900399"
  },
  {
    "text": "component is that we're now bu we've",
    "start": "900399",
    "end": "902320"
  },
  {
    "text": "built infrastructure um this orca um",
    "start": "902320",
    "end": "906880"
  },
  {
    "text": "mechanism that's now in envoy um to be",
    "start": "906880",
    "end": "910240"
  },
  {
    "text": "able to receive um load signals from the",
    "start": "910240",
    "end": "913279"
  },
  {
    "text": "model server",
    "start": "913279",
    "end": "914600"
  },
  {
    "text": "directly and then what we end up with is",
    "start": "914600",
    "end": "917040"
  },
  {
    "text": "this architecture where you have you",
    "start": "917040",
    "end": "919199"
  },
  {
    "text": "know uh an algorithm implemented via",
    "start": "919199",
    "end": "922000"
  },
  {
    "text": "extensions receiving load signals from",
    "start": "922000",
    "end": "924480"
  },
  {
    "text": "the model servers and those load signals",
    "start": "924480",
    "end": "927519"
  },
  {
    "text": "can also be joined with um um system",
    "start": "927519",
    "end": "930800"
  },
  {
    "text": "metrics that are being for example are",
    "start": "930800",
    "end": "933120"
  },
  {
    "text": "being consumed via a separate pipeline",
    "start": "933120",
    "end": "935360"
  },
  {
    "text": "that the platform orchestrator provides",
    "start": "935360",
    "end": "937279"
  },
  {
    "text": "potentially and all of those signals are",
    "start": "937279",
    "end": "939680"
  },
  {
    "text": "now also being provided to the load",
    "start": "939680",
    "end": "941040"
  },
  {
    "text": "balancing control plane through LRS",
    "start": "941040",
    "end": "943680"
  },
  {
    "text": "through the load reporting APIs and you",
    "start": "943680",
    "end": "946720"
  },
  {
    "text": "that allows the control plane to also",
    "start": "946720",
    "end": "948160"
  },
  {
    "text": "make higher level traffic distribution",
    "start": "948160",
    "end": "949920"
  },
  {
    "text": "decisions such as you know varying the",
    "start": "949920",
    "end": "952320"
  },
  {
    "text": "locality weights so you can actually",
    "start": "952320",
    "end": "953759"
  },
  {
    "text": "pick you know let's say what zone or",
    "start": "953759",
    "end": "955360"
  },
  {
    "text": "region uh you want to load balance uh",
    "start": "955360",
    "end": "959320"
  },
  {
    "text": "to so yeah so focusing on that first",
    "start": "959320",
    "end": "962000"
  },
  {
    "text": "component rate the inference algorithms",
    "start": "962000",
    "end": "964079"
  },
  {
    "text": "um we have new algorithms that are",
    "start": "964079",
    "end": "966240"
  },
  {
    "text": "actually using these application load",
    "start": "966240",
    "end": "968320"
  },
  {
    "text": "signals to to to load balance um there's",
    "start": "968320",
    "end": "971759"
  },
  {
    "text": "a new client side weighted run ramen",
    "start": "971759",
    "end": "973440"
  },
  {
    "text": "algorithm um that computes endpoint",
    "start": "973440",
    "end": "976240"
  },
  {
    "text": "weights based on the reported",
    "start": "976240",
    "end": "977920"
  },
  {
    "text": "utilization metrics as well as the",
    "start": "977920",
    "end": "979519"
  },
  {
    "text": "request and error rates um there are",
    "start": "979519",
    "end": "981680"
  },
  {
    "text": "also existing algorithms such as lease",
    "start": "981680",
    "end": "983360"
  },
  {
    "text": "requests that can be enhanced to support",
    "start": "983360",
    "end": "986240"
  },
  {
    "text": "these new metrics um however for optimal",
    "start": "986240",
    "end": "990000"
  },
  {
    "text": "request placement we've really found",
    "start": "990000",
    "end": "992240"
  },
  {
    "text": "that we need high iteration velocity uh",
    "start": "992240",
    "end": "994480"
  },
  {
    "text": "to keep up with the rapidly evolving",
    "start": "994480",
    "end": "996399"
  },
  {
    "text": "geni models and and their",
    "start": "996399",
    "end": "998079"
  },
  {
    "text": "implementations um and inference really",
    "start": "998079",
    "end": "1000720"
  },
  {
    "text": "requires additional algorithmic",
    "start": "1000720",
    "end": "1002079"
  },
  {
    "text": "complexity um due to just that",
    "start": "1002079",
    "end": "1004480"
  },
  {
    "text": "characteristics of the model servers and",
    "start": "1004480",
    "end": "1006160"
  },
  {
    "text": "token generation",
    "start": "1006160",
    "end": "1008320"
  },
  {
    "text": "so what we've ended up with is you know",
    "start": "1008320",
    "end": "1010079"
  },
  {
    "text": "we're leveraging amvoice extensibility",
    "start": "1010079",
    "end": "1011600"
  },
  {
    "text": "capabilities again um and you know um",
    "start": "1011600",
    "end": "1015199"
  },
  {
    "text": "the open- source uh machine learning and",
    "start": "1015199",
    "end": "1017199"
  },
  {
    "text": "AI community has really coalesed around",
    "start": "1017199",
    "end": "1019040"
  },
  {
    "text": "a few languages such as Python right so",
    "start": "1019040",
    "end": "1021279"
  },
  {
    "text": "we really want extensibility options",
    "start": "1021279",
    "end": "1022959"
  },
  {
    "text": "that are language agnostic",
    "start": "1022959",
    "end": "1025280"
  },
  {
    "text": "um and we leveraging extensibility also",
    "start": "1025280",
    "end": "1028880"
  },
  {
    "text": "gives platform builders the ability to",
    "start": "1028880",
    "end": "1030720"
  },
  {
    "text": "provide bring your own extension um",
    "start": "1030720",
    "end": "1033438"
  },
  {
    "text": "capabilities which is you know something",
    "start": "1033439",
    "end": "1035120"
  },
  {
    "text": "that end users want they want",
    "start": "1035120",
    "end": "1036480"
  },
  {
    "text": "portability they want to be able to",
    "start": "1036480",
    "end": "1038000"
  },
  {
    "text": "modify the algorithms as",
    "start": "1038000",
    "end": "1041280"
  },
  {
    "text": "needed the going back to that second",
    "start": "1041640",
    "end": "1044319"
  },
  {
    "text": "component of of load bal of optimized",
    "start": "1044319",
    "end": "1046640"
  },
  {
    "text": "load balancing is is this new metrics",
    "start": "1046640",
    "end": "1048720"
  },
  {
    "text": "collection right so the key pain points",
    "start": "1048720",
    "end": "1051600"
  },
  {
    "text": "there are that inference requests are on",
    "start": "1051600",
    "end": "1054320"
  },
  {
    "text": "average you know a thousand times more",
    "start": "1054320",
    "end": "1056000"
  },
  {
    "text": "expensive than traditional uh web",
    "start": "1056000",
    "end": "1058720"
  },
  {
    "text": "workloads which means that if you",
    "start": "1058720",
    "end": "1060400"
  },
  {
    "text": "misplace one of these requests um it's",
    "start": "1060400",
    "end": "1063120"
  },
  {
    "text": "just much more expensive and and you can",
    "start": "1063120",
    "end": "1065360"
  },
  {
    "text": "really feel it in your tail latency",
    "start": "1065360",
    "end": "1067720"
  },
  {
    "text": "um so you know also load signals cannot",
    "start": "1067720",
    "end": "1070960"
  },
  {
    "text": "be observed by envoy um directly right",
    "start": "1070960",
    "end": "1074080"
  },
  {
    "text": "these model server metrics uh for key",
    "start": "1074080",
    "end": "1076320"
  },
  {
    "text": "constraint resources are are required",
    "start": "1076320",
    "end": "1078559"
  },
  {
    "text": "instead and this is where the KB cache",
    "start": "1078559",
    "end": "1080320"
  },
  {
    "text": "utilization and these QAPs come into",
    "start": "1080320",
    "end": "1082760"
  },
  {
    "text": "play and then there also very high GPU",
    "start": "1082760",
    "end": "1085440"
  },
  {
    "text": "and accelerator costs right so the",
    "start": "1085440",
    "end": "1087200"
  },
  {
    "text": "traditional approach maybe of",
    "start": "1087200",
    "end": "1088400"
  },
  {
    "text": "overprovisioning your backends is really",
    "start": "1088400",
    "end": "1090559"
  },
  {
    "text": "undesirable and really not viable in",
    "start": "1090559",
    "end": "1092720"
  },
  {
    "text": "many cases right so the solutions that",
    "start": "1092720",
    "end": "1096480"
  },
  {
    "text": "we've come up with is to introduce this",
    "start": "1096480",
    "end": "1098559"
  },
  {
    "text": "new load collection mechanism Orca uh",
    "start": "1098559",
    "end": "1102160"
  },
  {
    "text": "Misha Aimov in in the audience will give",
    "start": "1102160",
    "end": "1104240"
  },
  {
    "text": "us a lightning talk later today on on a",
    "start": "1104240",
    "end": "1106160"
  },
  {
    "text": "deep dive so I'm I'm not going to go",
    "start": "1106160",
    "end": "1107919"
  },
  {
    "text": "deep into that um but really the basics",
    "start": "1107919",
    "end": "1110960"
  },
  {
    "text": "are that there is an inline collection",
    "start": "1110960",
    "end": "1112960"
  },
  {
    "text": "mechanism right now through HTTP",
    "start": "1112960",
    "end": "1114799"
  },
  {
    "text": "response headers um and next we plan to",
    "start": "1114799",
    "end": "1118640"
  },
  {
    "text": "introduce out ofband collection",
    "start": "1118640",
    "end": "1120080"
  },
  {
    "text": "mechanisms where you can do probing",
    "start": "1120080",
    "end": "1122320"
  },
  {
    "text": "before you actually pick the endpoint um",
    "start": "1122320",
    "end": "1124640"
  },
  {
    "text": "and also asynchronous probing on a",
    "start": "1124640",
    "end": "1126640"
  },
  {
    "text": "regular interval and this is really",
    "start": "1126640",
    "end": "1128799"
  },
  {
    "text": "required for long live requests for",
    "start": "1128799",
    "end": "1131039"
  },
  {
    "text": "streaming requests and and that's really",
    "start": "1131039",
    "end": "1133120"
  },
  {
    "text": "a common case with with LM serving is",
    "start": "1133120",
    "end": "1135840"
  },
  {
    "text": "that um we really want to decouple um",
    "start": "1135840",
    "end": "1140799"
  },
  {
    "text": "the the sing the load signal collection",
    "start": "1140799",
    "end": "1143840"
  },
  {
    "text": "from the QPS",
    "start": "1143840",
    "end": "1145640"
  },
  {
    "text": "essentially and the last thing here is",
    "start": "1145640",
    "end": "1147760"
  },
  {
    "text": "that it's integrated with the control",
    "start": "1147760",
    "end": "1149360"
  },
  {
    "text": "plane via the load reporting APIs via",
    "start": "1149360",
    "end": "1152000"
  },
  {
    "text": "the XCS APIs",
    "start": "1152000",
    "end": "1154960"
  },
  {
    "text": "Okay so now that we've gone over this",
    "start": "1156600",
    "end": "1158960"
  },
  {
    "text": "architecture uh and the pattern right I",
    "start": "1158960",
    "end": "1161120"
  },
  {
    "text": "wanted to provide a concrete example of",
    "start": "1161120",
    "end": "1162480"
  },
  {
    "text": "how we're leveraging this for uh a",
    "start": "1162480",
    "end": "1165120"
  },
  {
    "text": "solution to our to to users um there's",
    "start": "1165120",
    "end": "1167760"
  },
  {
    "text": "an open sour or there's an open source",
    "start": "1167760",
    "end": "1169520"
  },
  {
    "text": "project right now that's being incubated",
    "start": "1169520",
    "end": "1171600"
  },
  {
    "text": "in the in the Kubernetes uh serving",
    "start": "1171600",
    "end": "1173760"
  },
  {
    "text": "working group",
    "start": "1173760",
    "end": "1175679"
  },
  {
    "text": "um to enhance the Kubernetes gateway",
    "start": "1175679",
    "end": "1177600"
  },
  {
    "text": "APIs which are the uh abstractions in",
    "start": "1177600",
    "end": "1180720"
  },
  {
    "text": "Kubernetes for load balancers uh to",
    "start": "1180720",
    "end": "1183600"
  },
  {
    "text": "provide an extension based approach for",
    "start": "1183600",
    "end": "1185280"
  },
  {
    "text": "inference optimized uh routing and load",
    "start": "1185280",
    "end": "1188080"
  },
  {
    "text": "balancing right so this uh these new",
    "start": "1188080",
    "end": "1191840"
  },
  {
    "text": "CRDs these new custom resources specify",
    "start": "1191840",
    "end": "1194000"
  },
  {
    "text": "both an API contract um essentially How",
    "start": "1194000",
    "end": "1196960"
  },
  {
    "text": "do you do model aware routing um how do",
    "start": "1196960",
    "end": "1199679"
  },
  {
    "text": "you specify policies per model or per",
    "start": "1199679",
    "end": "1202000"
  },
  {
    "text": "inference pool um but also they're also",
    "start": "1202000",
    "end": "1205200"
  },
  {
    "text": "specifying an extension protocol",
    "start": "1205200",
    "end": "1206720"
  },
  {
    "text": "contract that's based on",
    "start": "1206720",
    "end": "1209160"
  },
  {
    "text": "XRO and the the APIs themselves right we",
    "start": "1209160",
    "end": "1213280"
  },
  {
    "text": "have these objective based policies",
    "start": "1213280",
    "end": "1215360"
  },
  {
    "text": "currently around this notion of",
    "start": "1215360",
    "end": "1217280"
  },
  {
    "text": "criticality which is you know can the do",
    "start": "1217280",
    "end": "1219679"
  },
  {
    "text": "you have a critical standard or shedable",
    "start": "1219679",
    "end": "1222880"
  },
  {
    "text": "uh workload um there's this there's also",
    "start": "1222880",
    "end": "1225679"
  },
  {
    "text": "this uh ability to operationalize uh",
    "start": "1225679",
    "end": "1228480"
  },
  {
    "text": "Laura which is a a a a fine-tuning",
    "start": "1228480",
    "end": "1231600"
  },
  {
    "text": "mechanism that allows the the model",
    "start": "1231600",
    "end": "1233440"
  },
  {
    "text": "server to dynamically load weights um",
    "start": "1233440",
    "end": "1236799"
  },
  {
    "text": "and then there's also modelbased traffic",
    "start": "1236799",
    "end": "1238400"
  },
  {
    "text": "splitting as part of these APIs and then",
    "start": "1238400",
    "end": "1240720"
  },
  {
    "text": "we also we're also planning to introduce",
    "start": "1240720",
    "end": "1242159"
  },
  {
    "text": "new capabilities soon such as prefix",
    "start": "1242159",
    "end": "1244799"
  },
  {
    "text": "cache aware routing which is another",
    "start": "1244799",
    "end": "1246400"
  },
  {
    "text": "inference optimization where you're",
    "start": "1246400",
    "end": "1247840"
  },
  {
    "text": "really trying to reuse the KV cache that",
    "start": "1247840",
    "end": "1249679"
  },
  {
    "text": "I've discussed across multiple requests",
    "start": "1249679",
    "end": "1253240"
  },
  {
    "text": "um and really the key goals with the",
    "start": "1253240",
    "end": "1255679"
  },
  {
    "text": "these APIs and these extensions are you",
    "start": "1255679",
    "end": "1258159"
  },
  {
    "text": "know portability and also compatibility",
    "start": "1258159",
    "end": "1260559"
  },
  {
    "text": "with the existing uh Kubernetes gateway",
    "start": "1260559",
    "end": "1263600"
  },
  {
    "text": "APIs with the existing envoy APIs right",
    "start": "1263600",
    "end": "1265760"
  },
  {
    "text": "so that you're not really losing all of",
    "start": "1265760",
    "end": "1267520"
  },
  {
    "text": "your existing uh proxy or load balancing",
    "start": "1267520",
    "end": "1270320"
  },
  {
    "text": "capabilities when you want to use the",
    "start": "1270320",
    "end": "1272080"
  },
  {
    "text": "inference optimized um",
    "start": "1272080",
    "end": "1275559"
  },
  {
    "text": "extensions and what we've ended up with",
    "start": "1275559",
    "end": "1278000"
  },
  {
    "text": "right now is we have both a a bodybased",
    "start": "1278000",
    "end": "1279919"
  },
  {
    "text": "router that we already discussed and we",
    "start": "1279919",
    "end": "1281280"
  },
  {
    "text": "also have this uh new extension also",
    "start": "1281280",
    "end": "1283120"
  },
  {
    "text": "called an endpoint",
    "start": "1283120",
    "end": "1285480"
  },
  {
    "text": "picker so this is the inference the",
    "start": "1285480",
    "end": "1289440"
  },
  {
    "text": "inference extension architecture right",
    "start": "1289440",
    "end": "1291440"
  },
  {
    "text": "the the the more concrete architecture",
    "start": "1291440",
    "end": "1293520"
  },
  {
    "text": "with with these new components um we can",
    "start": "1293520",
    "end": "1296960"
  },
  {
    "text": "see that we have the bodybased router",
    "start": "1296960",
    "end": "1298400"
  },
  {
    "text": "that provides the model aware routing",
    "start": "1298400",
    "end": "1300240"
  },
  {
    "text": "via this header that then gets matched",
    "start": "1300240",
    "end": "1302159"
  },
  {
    "text": "in the void route configuration we also",
    "start": "1302159",
    "end": "1304960"
  },
  {
    "text": "have this endpoint picker extension",
    "start": "1304960",
    "end": "1306640"
  },
  {
    "text": "component that's that's implementing the",
    "start": "1306640",
    "end": "1308240"
  },
  {
    "text": "inference optimized",
    "start": "1308240",
    "end": "1310120"
  },
  {
    "text": "algorithm right um and then we have the",
    "start": "1310120",
    "end": "1313360"
  },
  {
    "text": "application or the or the model server",
    "start": "1313360",
    "end": "1315440"
  },
  {
    "text": "load signals that are being propagated",
    "start": "1315440",
    "end": "1317200"
  },
  {
    "text": "to both the uh extension and also the",
    "start": "1317200",
    "end": "1320159"
  },
  {
    "text": "load balancing control",
    "start": "1320159",
    "end": "1321880"
  },
  {
    "text": "plane and you know this is essentially",
    "start": "1321880",
    "end": "1324720"
  },
  {
    "text": "how we've put together um a a full",
    "start": "1324720",
    "end": "1327840"
  },
  {
    "text": "solution including existing capabilities",
    "start": "1327840",
    "end": "1330679"
  },
  {
    "text": "that the end users were depending on",
    "start": "1330679",
    "end": "1333120"
  },
  {
    "text": "such as any sort of DOSs protection and",
    "start": "1333120",
    "end": "1336240"
  },
  {
    "text": "oz uh support that's provided either as",
    "start": "1336240",
    "end": "1339520"
  },
  {
    "text": "another extension or natively in",
    "start": "1339520",
    "end": "1343600"
  },
  {
    "text": "envoy and just diving a bit deeper into",
    "start": "1344840",
    "end": "1348000"
  },
  {
    "text": "the extension um into this endpoint",
    "start": "1348000",
    "end": "1351440"
  },
  {
    "text": "picker extension um what it's really",
    "start": "1351440",
    "end": "1353520"
  },
  {
    "text": "doing is it's determining the endpoints",
    "start": "1353520",
    "end": "1355360"
  },
  {
    "text": "that Amboy should",
    "start": "1355360",
    "end": "1357320"
  },
  {
    "text": "select and what it's doing is it's",
    "start": "1357320",
    "end": "1359760"
  },
  {
    "text": "scraping relevant model server",
    "start": "1359760",
    "end": "1361360"
  },
  {
    "text": "Prometheus metrics uh such as the KB",
    "start": "1361360",
    "end": "1363679"
  },
  {
    "text": "casualization and dependent Q sizes you",
    "start": "1363679",
    "end": "1366159"
  },
  {
    "text": "will also support Orca in the near",
    "start": "1366159",
    "end": "1367600"
  },
  {
    "text": "future it ranks available endpoint",
    "start": "1367600",
    "end": "1369679"
  },
  {
    "text": "capacity based on the scrape metrics it",
    "start": "1369679",
    "end": "1372720"
  },
  {
    "text": "tracks dynamically loaded Laura weights",
    "start": "1372720",
    "end": "1374880"
  },
  {
    "text": "per endpoint uh so it does Laura aware",
    "start": "1374880",
    "end": "1377679"
  },
  {
    "text": "routing and and soft affinitizes the",
    "start": "1377679",
    "end": "1380320"
  },
  {
    "text": "requests accordingly um it prioritizes",
    "start": "1380320",
    "end": "1383360"
  },
  {
    "text": "critical overshadowable traffic this is",
    "start": "1383360",
    "end": "1384960"
  },
  {
    "text": "how it applies this these objective",
    "start": "1384960",
    "end": "1386720"
  },
  {
    "text": "based policies",
    "start": "1386720",
    "end": "1388679"
  },
  {
    "text": "um and then soon you will also be able",
    "start": "1388679",
    "end": "1391360"
  },
  {
    "text": "to do this prefix cache that we're",
    "start": "1391360",
    "end": "1392799"
  },
  {
    "text": "routing that I was talking about",
    "start": "1392799",
    "end": "1395760"
  },
  {
    "text": "and the way that this is actually",
    "start": "1395760",
    "end": "1397200"
  },
  {
    "text": "implemented is that we have um xrock",
    "start": "1397200",
    "end": "1399840"
  },
  {
    "text": "metadata and and then in when the",
    "start": "1399840",
    "end": "1403200"
  },
  {
    "text": "endpoint picker runs its algorithm and",
    "start": "1403200",
    "end": "1404720"
  },
  {
    "text": "picks the endpoint it returns in the in",
    "start": "1404720",
    "end": "1408480"
  },
  {
    "text": "the xrock response um metadata keys that",
    "start": "1408480",
    "end": "1412559"
  },
  {
    "text": "um essentially tell boy which primary",
    "start": "1412559",
    "end": "1415360"
  },
  {
    "text": "endpoint has been selected and also",
    "start": "1415360",
    "end": "1417440"
  },
  {
    "text": "which fallback endpoints are selected so",
    "start": "1417440",
    "end": "1419280"
  },
  {
    "text": "that if he needs to retry it can",
    "start": "1419280",
    "end": "1420640"
  },
  {
    "text": "actually retry to a different endpoint",
    "start": "1420640",
    "end": "1423520"
  },
  {
    "text": "um there's also this um capability that",
    "start": "1423520",
    "end": "1426640"
  },
  {
    "text": "we've introduced to allow the proxy to",
    "start": "1426640",
    "end": "1429039"
  },
  {
    "text": "provide a subset of endpoints that the",
    "start": "1429039",
    "end": "1430559"
  },
  {
    "text": "endpoint picker should select from um",
    "start": "1430559",
    "end": "1432640"
  },
  {
    "text": "that allows it to do filtering if you",
    "start": "1432640",
    "end": "1434400"
  },
  {
    "text": "need to if you need to do some",
    "start": "1434400",
    "end": "1435840"
  },
  {
    "text": "pre-processing to effect effectively you",
    "start": "1435840",
    "end": "1438000"
  },
  {
    "text": "know filter out the the um undesirable",
    "start": "1438000",
    "end": "1440960"
  },
  {
    "text": "endpoints from from the endpoint picker",
    "start": "1440960",
    "end": "1444880"
  },
  {
    "text": "extension and so so yeah so you know",
    "start": "1445799",
    "end": "1449919"
  },
  {
    "text": "what's the actual value in doing this",
    "start": "1449919",
    "end": "1451679"
  },
  {
    "text": "right so I I'm just providing just a a",
    "start": "1451679",
    "end": "1453760"
  },
  {
    "text": "basic set of benchmarks that that have",
    "start": "1453760",
    "end": "1455520"
  },
  {
    "text": "been run um and you know these charts",
    "start": "1455520",
    "end": "1458720"
  },
  {
    "text": "have been were generated using a",
    "start": "1458720",
    "end": "1460080"
  },
  {
    "text": "benchmarking environment with 10 VLM",
    "start": "1460080",
    "end": "1462000"
  },
  {
    "text": "model servers uh using H100 GPUs um the",
    "start": "1462000",
    "end": "1466320"
  },
  {
    "text": "Lama 2 7 billion parameter model and the",
    "start": "1466320",
    "end": "1468960"
  },
  {
    "text": "shared GPT data set right and we're",
    "start": "1468960",
    "end": "1470640"
  },
  {
    "text": "comparing the blue line which is the",
    "start": "1470640",
    "end": "1472400"
  },
  {
    "text": "inference extension",
    "start": "1472400",
    "end": "1474480"
  },
  {
    "text": "um uh envoy versus just Kubernetes",
    "start": "1474480",
    "end": "1477760"
  },
  {
    "text": "cluster IP load balancing and we can see",
    "start": "1477760",
    "end": "1480640"
  },
  {
    "text": "that while the throughput largely",
    "start": "1480640",
    "end": "1482000"
  },
  {
    "text": "remains unchanged and the thing that we",
    "start": "1482000",
    "end": "1483600"
  },
  {
    "text": "need to call out is that it's there's no",
    "start": "1483600",
    "end": "1485120"
  },
  {
    "text": "major penalty for doing the this",
    "start": "1485120",
    "end": "1486960"
  },
  {
    "text": "inference u optimized load balancing but",
    "start": "1486960",
    "end": "1489760"
  },
  {
    "text": "we do see a very significant reduction",
    "start": "1489760",
    "end": "1491919"
  },
  {
    "text": "in per output uh token latencies um with",
    "start": "1491919",
    "end": "1496000"
  },
  {
    "text": "uh with extension algorithm and we also",
    "start": "1496000",
    "end": "1498480"
  },
  {
    "text": "see significant reductions in tail",
    "start": "1498480",
    "end": "1501640"
  },
  {
    "text": "latency especially as you ramp up",
    "start": "1501640",
    "end": "1505600"
  },
  {
    "text": "QPS and yeah and just closing out right",
    "start": "1507480",
    "end": "1510159"
  },
  {
    "text": "so we've talked about two of the use",
    "start": "1510159",
    "end": "1512000"
  },
  {
    "text": "cases for extensions which are routing",
    "start": "1512000",
    "end": "1514159"
  },
  {
    "text": "based on the request body payload the",
    "start": "1514159",
    "end": "1516000"
  },
  {
    "text": "custom load balancing algorithms and but",
    "start": "1516000",
    "end": "1518159"
  },
  {
    "text": "this also can be applied to both",
    "start": "1518159",
    "end": "1520159"
  },
  {
    "text": "applying security and AI safety policies",
    "start": "1520159",
    "end": "1522320"
  },
  {
    "text": "right it can be applied to other",
    "start": "1522320",
    "end": "1524400"
  },
  {
    "text": "capabilities that are desired for LLM",
    "start": "1524400",
    "end": "1526159"
  },
  {
    "text": "servings such as semantic",
    "start": "1526159",
    "end": "1528279"
  },
  {
    "text": "caching excuse me um the key thing is",
    "start": "1528279",
    "end": "1531520"
  },
  {
    "text": "that composability is required right we",
    "start": "1531520",
    "end": "1533360"
  },
  {
    "text": "need to build this in a way that you can",
    "start": "1533360",
    "end": "1534559"
  },
  {
    "text": "actually chain the extensions",
    "start": "1534559",
    "end": "1536880"
  },
  {
    "text": "um and you know the last thing I want to",
    "start": "1536880",
    "end": "1538960"
  },
  {
    "text": "call out is that you know we focused on",
    "start": "1538960",
    "end": "1541039"
  },
  {
    "text": "XRO right now but you know once was",
    "start": "1541039",
    "end": "1543919"
  },
  {
    "text": "become stable right um we do think that",
    "start": "1543919",
    "end": "1546799"
  },
  {
    "text": "this is probably going to be become the",
    "start": "1546799",
    "end": "1547919"
  },
  {
    "text": "optimal choice for some of these use",
    "start": "1547919",
    "end": "1549360"
  },
  {
    "text": "cases um and especially because it will",
    "start": "1549360",
    "end": "1552080"
  },
  {
    "text": "provide a much simpler operational",
    "start": "1552080",
    "end": "1553360"
  },
  {
    "text": "experience for the extension providers",
    "start": "1553360",
    "end": "1555679"
  },
  {
    "text": "right they they're not going to need to",
    "start": "1555679",
    "end": "1556960"
  },
  {
    "text": "manage an an external service um so we",
    "start": "1556960",
    "end": "1559360"
  },
  {
    "text": "think that there are some big wins uh to",
    "start": "1559360",
    "end": "1561039"
  },
  {
    "text": "use in",
    "start": "1561039",
    "end": "1563080"
  },
  {
    "text": "WASM and lastly we just wanted to call",
    "start": "1563080",
    "end": "1565679"
  },
  {
    "text": "out these ecosystem implementations so",
    "start": "1565679",
    "end": "1568080"
  },
  {
    "text": "these are you know community uh projects",
    "start": "1568080",
    "end": "1571360"
  },
  {
    "text": "that are that are either using",
    "start": "1571360",
    "end": "1572559"
  },
  {
    "text": "extensions for their own use cases or",
    "start": "1572559",
    "end": "1574400"
  },
  {
    "text": "they're actually implementing these",
    "start": "1574400",
    "end": "1575760"
  },
  {
    "text": "Kubernetes gateway inference APIs um um",
    "start": "1575760",
    "end": "1580000"
  },
  {
    "text": "you know amoi gateway K gateway um GKE",
    "start": "1580000",
    "end": "1584880"
  },
  {
    "text": "gateway and von production production",
    "start": "1584880",
    "end": "1588799"
  },
  {
    "text": "stack and that's all we got so thank you",
    "start": "1589240",
    "end": "1596600"
  }
]
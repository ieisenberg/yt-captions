[
  {
    "text": "hi foolx thanks for attending this session and uh how are you uh my name is",
    "start": "719",
    "end": "9639"
  },
  {
    "text": "and uh today I feel deeply honored to be here to share our learnings and Journeys",
    "start": "9639",
    "end": "16358"
  },
  {
    "text": "regarding how to running spark on kubernetes and uh let me introduce",
    "start": "16359",
    "end": "22400"
  },
  {
    "text": "myself firstly and uh and uh I have been working I I from",
    "start": "22400",
    "end": "30160"
  },
  {
    "text": "Apple a ml Department I have been working on design develop and manage",
    "start": "30160",
    "end": "37200"
  },
  {
    "text": "large scale spark cluster and Spark workload on kues around four years now",
    "start": "37200",
    "end": "44640"
  },
  {
    "text": "and throughout um our journey most recently we have encountered some new",
    "start": "44640",
    "end": "51640"
  },
  {
    "text": "and uh very crucial new request from our internal and users which inspiring us",
    "start": "51640",
    "end": "59199"
  },
  {
    "text": "try to exploring a new way to all user to running their spark workload on ktic",
    "start": "59199",
    "end": "66479"
  },
  {
    "text": "which is running Apachi stand long cluster on top",
    "start": "66479",
    "end": "71720"
  },
  {
    "text": "ofes and uh over the next uh 30 minutes I try to have a deep dive to this topic",
    "start": "71720",
    "end": "79360"
  },
  {
    "text": "so I try to firstly introdu was our existing you",
    "start": "79360",
    "end": "86720"
  },
  {
    "text": "know platform on our uh how to run Sparkle CL on kues and then",
    "start": "86720",
    "end": "94399"
  },
  {
    "text": "why we need what kind of challenges we are facing right now and why we introduce this new way and then I try to",
    "start": "94399",
    "end": "103000"
  },
  {
    "text": "give you some high level design principles we try to achieve and the detail implementation for that and last",
    "start": "103000",
    "end": "111360"
  },
  {
    "text": "thing is like uh what's our ongoing work going to to do uh as you know apach spark is a open",
    "start": "111360",
    "end": "120119"
  },
  {
    "text": "source software engineer software and which is kind of a distributed",
    "start": "120119",
    "end": "125799"
  },
  {
    "text": "computation engine just in a field of lines of codes in either you know Pon",
    "start": "125799",
    "end": "131360"
  },
  {
    "text": "scolar or even Circle data scientist and engineer can easily Define a spark",
    "start": "131360",
    "end": "137239"
  },
  {
    "text": "application to process a huge amount of data and the spark will take care of",
    "start": "137239",
    "end": "144680"
  },
  {
    "text": "paralyzing the work with the help of a cluster of machines",
    "start": "144680",
    "end": "150519"
  },
  {
    "text": "however um sparkk itself cannot uh manage this kind of machines uh directly",
    "start": "150519",
    "end": "158800"
  },
  {
    "text": "usually it will rely on some third party class managers to help it uh there are",
    "start": "158800",
    "end": "165879"
  },
  {
    "text": "some popular you know class managers like haduan apach mosos or kues of",
    "start": "165879",
    "end": "172840"
  },
  {
    "text": "course so around several years ago we have been exploring how to run in spark",
    "start": "172840",
    "end": "178760"
  },
  {
    "text": "on kuber netics and uh um we uh through this kind of Journey we",
    "start": "178760",
    "end": "186200"
  },
  {
    "text": "find there is quite lot of kind of advantages if we can take this design",
    "start": "186200",
    "end": "193200"
  },
  {
    "text": "first of all uh the full containerization this kinds of capability makes spark application on is",
    "start": "193200",
    "end": "200760"
  },
  {
    "text": "very agile and pable our data scientist and Engineers can easily install",
    "start": "200760",
    "end": "207760"
  },
  {
    "text": "whatever packages to the container images and runs everywhere and uh this is really helpful",
    "start": "207760",
    "end": "215439"
  },
  {
    "text": "and speed up our Dev developers you know development velocity and",
    "start": "215439",
    "end": "221080"
  },
  {
    "text": "iterations um secondly and U by running spark workload on cloud with help of",
    "start": "221080",
    "end": "229200"
  },
  {
    "text": "ktic we can easily apply the autoscaling features to uh Spar applications so we",
    "start": "229200",
    "end": "236480"
  },
  {
    "text": "can automatically adjust to the scale in or scale out to the machines to adjust",
    "start": "236480",
    "end": "243040"
  },
  {
    "text": "the different size of Sparkle workload this help us to save a lot of cost to",
    "start": "243040",
    "end": "248519"
  },
  {
    "text": "our internal users as well and uh thirdly and uh you know we always try to",
    "start": "248519",
    "end": "255040"
  },
  {
    "text": "take in security and privacy as a first uh citizens to our platform this is",
    "start": "255040",
    "end": "261440"
  },
  {
    "text": "really important especially when we try to you know build a m tenant platform",
    "start": "261440",
    "end": "268400"
  },
  {
    "text": "for our users with the help of communties such as you know uh service account and cluster",
    "start": "268400",
    "end": "276360"
  },
  {
    "text": "roles uh such as this kind of you know security control services provided by",
    "start": "276360",
    "end": "281960"
  },
  {
    "text": "commes itself we can very easily to apply authentication tokens or",
    "start": "281960",
    "end": "288160"
  },
  {
    "text": "authorization policies to every sparker port and or even every data access",
    "start": "288160",
    "end": "295120"
  },
  {
    "text": "operations inside the spark workload",
    "start": "295120",
    "end": "300800"
  },
  {
    "text": "here is our existing um architecture how to run in",
    "start": "300800",
    "end": "306600"
  },
  {
    "text": "spark workloads on top of commes from this picture you can see we",
    "start": "306600",
    "end": "312400"
  },
  {
    "text": "build a unified batch processing Gateway and we leverage this Gateway firstly to",
    "start": "312400",
    "end": "320199"
  },
  {
    "text": "manage several several configurable uh numbers of spark commes",
    "start": "320199",
    "end": "327680"
  },
  {
    "text": "cluster and once this way get the request from whatever API",
    "start": "327680",
    "end": "334039"
  },
  {
    "text": "call com line airflow operator or jupitor notebook it will translate this",
    "start": "334039",
    "end": "341240"
  },
  {
    "text": "kind of request to a crd object so here what is a s object and U you can see on",
    "start": "341240",
    "end": "349600"
  },
  {
    "text": "each spark kubernetes clusters we install several spark kubernetes",
    "start": "349600",
    "end": "355960"
  },
  {
    "text": "operator and uh the crd object going to be roted to the corresponding spark e",
    "start": "355960",
    "end": "363720"
  },
  {
    "text": "cluture and operator will process this kind of SD",
    "start": "363720",
    "end": "369520"
  },
  {
    "text": "instance and uh basically the operator going to try",
    "start": "369520",
    "end": "374919"
  },
  {
    "text": "to translat all the fields defined in the SD object to a parameter required by",
    "start": "374919",
    "end": "381639"
  },
  {
    "text": "the spark permit if you're familiar like you know spark and it provide spark per",
    "start": "381639",
    "end": "386919"
  },
  {
    "text": "meit and uh also it's already you know support kubernetes as a cluster manager",
    "start": "386919",
    "end": "392479"
  },
  {
    "text": "as default so that spark submit script can directly talk to KU end",
    "start": "392479",
    "end": "400120"
  },
  {
    "text": "point and uh by leveraging this sh script SP spark operator can help you to",
    "start": "400120",
    "end": "407800"
  },
  {
    "text": "spawn bunch of PS which is including one spark driver p and several numbers of",
    "start": "407800",
    "end": "414280"
  },
  {
    "text": "Spar excor p and uh at the bottom you can Fe we",
    "start": "414280",
    "end": "420360"
  },
  {
    "text": "leverage unical to apply the resources quota per each tenant and of course we",
    "start": "420360",
    "end": "428479"
  },
  {
    "text": "also leverage Autos scalar class Autos scalar and all CER to automatically",
    "start": "428479",
    "end": "435720"
  },
  {
    "text": "adjust the machine or trigger the new machine to create it to support the new",
    "start": "435720",
    "end": "442680"
  },
  {
    "text": "part and you may have lots of kind of you know um questions regarding risk kind of",
    "start": "442680",
    "end": "449919"
  },
  {
    "text": "architecture but let's have a deep dive later if we have time at the end we have",
    "start": "449919",
    "end": "456520"
  },
  {
    "text": "been leverag this um cluster to support",
    "start": "456520",
    "end": "461720"
  },
  {
    "text": "large scale production workloads on our on our internal uh platform for several",
    "start": "461720",
    "end": "468240"
  },
  {
    "text": "years and we made a lot of internal customizations and reflectors to this",
    "start": "468240",
    "end": "474360"
  },
  {
    "text": "open source software which is spark kues operator however",
    "start": "474360",
    "end": "479960"
  },
  {
    "text": "we are still facing some new challenges and uh here is a brief",
    "start": "479960",
    "end": "486599"
  },
  {
    "text": "summary first of all we do have a lot of very short processing spark",
    "start": "486599",
    "end": "492680"
  },
  {
    "text": "applications and uh this is we got uh we got a lot of requests from our end users",
    "start": "492680",
    "end": "498759"
  },
  {
    "text": "and they we they try to require their small applications to be finished in",
    "start": "498759",
    "end": "505800"
  },
  {
    "text": "only around 3 to four minutes and also the interval of each Spar application",
    "start": "505800",
    "end": "512680"
  },
  {
    "text": "they need to be less than 30 seconds you can imagine all of this kind",
    "start": "512680",
    "end": "518399"
  },
  {
    "text": "of spark application task is scheduled by fow or other you know a aest",
    "start": "518399",
    "end": "525560"
  },
  {
    "text": "trators and you also can imagine any kind of job schedule de delay or kind of",
    "start": "525560",
    "end": "531920"
  },
  {
    "text": "P allocation delay well leading to the failures to our spark application or",
    "start": "531920",
    "end": "537600"
  },
  {
    "text": "even the whole um airflow Dex and uh from the",
    "start": "537600",
    "end": "544480"
  },
  {
    "text": "previous uh architecture you may also notice we also provide uh",
    "start": "544480",
    "end": "551240"
  },
  {
    "text": "interactive uh analytis capabilities to our users so what does that mean that",
    "start": "551240",
    "end": "556640"
  },
  {
    "text": "means if user want to have a quer quer session via the Jupiter notebook it will",
    "start": "556640",
    "end": "563959"
  },
  {
    "text": "also need our backend to spawn b p",
    "start": "563959",
    "end": "570120"
  },
  {
    "text": "so that means uh if we can reduce the startup",
    "start": "570120",
    "end": "575360"
  },
  {
    "text": "time of the port creation is well help very helpful to enhance our user",
    "start": "575360",
    "end": "583880"
  },
  {
    "text": "experience thirdly G of course is a very hard topic right now and uh on our",
    "start": "583880",
    "end": "590480"
  },
  {
    "text": "platform we also try to provide both data parallelism and model parallelism",
    "start": "590480",
    "end": "596000"
  },
  {
    "text": "to our platform so that's why we try to explore how to running a long running",
    "start": "596000",
    "end": "602279"
  },
  {
    "text": "recluster on top of spark however the existing architecture cannot uh satisfy",
    "start": "602279",
    "end": "609760"
  },
  {
    "text": "this need uh that's why we conduct a lot of",
    "start": "609760",
    "end": "615720"
  },
  {
    "text": "you know research and try to find some way to reduce the start the start up",
    "start": "615720",
    "end": "622600"
  },
  {
    "text": "time of each spark application and also try to find a new way to running this",
    "start": "622600",
    "end": "629079"
  },
  {
    "text": "kind of machine learning framework to find firstly let's try to",
    "start": "629079",
    "end": "634959"
  },
  {
    "text": "find the root cause why the sport the spark application start start up time",
    "start": "634959",
    "end": "641040"
  },
  {
    "text": "taking so much time firstly Let's uh check what happens",
    "start": "641040",
    "end": "646360"
  },
  {
    "text": "when crd uh rotated to the spark operator and how Spar spark operator does and from",
    "start": "646360",
    "end": "654399"
  },
  {
    "text": "this workflow of ktic operator we can see once",
    "start": "654399",
    "end": "659800"
  },
  {
    "text": "controller received the spark application crds and it will firstly",
    "start": "659800",
    "end": "665600"
  },
  {
    "text": "translate to a sh script and then using the submission Runner to submit to",
    "start": "665600",
    "end": "673440"
  },
  {
    "text": "excute this sh script and allow it to talk to APS server directly and then the",
    "start": "673440",
    "end": "680839"
  },
  {
    "text": "driver Port going to be created and then the spark driver Port will directly talk to the API server to",
    "start": "680839",
    "end": "688399"
  },
  {
    "text": "spawn the B executor part um we can say that there going to",
    "start": "688399",
    "end": "695079"
  },
  {
    "text": "be a long negotiation process especially when for example there is one spark",
    "start": "695079",
    "end": "700240"
  },
  {
    "text": "application requires thousands of executor port and uh our bomm components",
    "start": "700240",
    "end": "708000"
  },
  {
    "text": "like unicor or autoscaler need to find a machines or create new machines to",
    "start": "708000",
    "end": "714600"
  },
  {
    "text": "allocate this kind of you know bunch of exter part how however the spark",
    "start": "714600",
    "end": "720519"
  },
  {
    "text": "operator right now its involvement already Sayes of course it will provide",
    "start": "720519",
    "end": "725639"
  },
  {
    "text": "some P monitoring and web validations and also it will try to help you to",
    "start": "725639",
    "end": "731200"
  },
  {
    "text": "create the spark U service you spark Ur service and Ingress",
    "start": "731200",
    "end": "737639"
  },
  {
    "text": "rules but it is a long negotiation process another thing I want to point",
    "start": "737639",
    "end": "744639"
  },
  {
    "text": "out here is that once the spark application will close is",
    "start": "744639",
    "end": "750399"
  },
  {
    "text": "completed and the spark operator will terminate the driver port and all the",
    "start": "750399",
    "end": "756120"
  },
  {
    "text": "corresponding exor Port this is actually is a totally",
    "start": "756120",
    "end": "761160"
  },
  {
    "text": "unnecessary a repeated uh you know Port cre creation and deletion especially when we try to you",
    "start": "761160",
    "end": "769079"
  },
  {
    "text": "know running a production grade workload because typically this kind of workloads",
    "start": "769079",
    "end": "774760"
  },
  {
    "text": "there is no frequent you know do image change or configuration change this is",
    "start": "774760",
    "end": "779959"
  },
  {
    "text": "totally a waste on the other hand we try to",
    "start": "779959",
    "end": "785800"
  },
  {
    "text": "exploring what's the spark oper what's the spark capability already",
    "start": "785800",
    "end": "792120"
  },
  {
    "text": "provide is provide a standal mode and to all users to you know um create a",
    "start": "792120",
    "end": "801519"
  },
  {
    "text": "tiny cluster on your local machine to uh te test or experimental",
    "start": "801519",
    "end": "807920"
  },
  {
    "text": "purpose is it's basically idea is is try to run a sh script",
    "start": "807920",
    "end": "814040"
  },
  {
    "text": "to start some you know jvm process among of this JM I mean Java process there is",
    "start": "814040",
    "end": "821920"
  },
  {
    "text": "one master process and several worker process and uh we can take this master",
    "start": "821920",
    "end": "829680"
  },
  {
    "text": "as simulated the class manager and it's provide some rest for API to all users",
    "start": "829680",
    "end": "836639"
  },
  {
    "text": "to able to repeat it the SP uh submit The Spar application to this tiny",
    "start": "836639",
    "end": "845040"
  },
  {
    "text": "clusters and also this master provides a default faithful scheduler to allocate",
    "start": "845040",
    "end": "853079"
  },
  {
    "text": "the different you know spark applications uh and to you know and also",
    "start": "853079",
    "end": "858519"
  },
  {
    "text": "monitoring the workers usage metrics and monitor the health of this",
    "start": "858519",
    "end": "865240"
  },
  {
    "text": "simulated cluster so as a infra engineer we try we have a",
    "start": "865240",
    "end": "873320"
  },
  {
    "text": "global picture um compared to our you know end users because we have both kind",
    "start": "873320",
    "end": "878759"
  },
  {
    "text": "of a um infra uh we have kind of global pictures",
    "start": "878759",
    "end": "885480"
  },
  {
    "text": "to the infra and also both to the spark uh uh car code base so what we trying to",
    "start": "885480",
    "end": "893519"
  },
  {
    "text": "do here is we try to continuous leverage Sparks actp to help",
    "start": "893519",
    "end": "900560"
  },
  {
    "text": "us uh manage the you know handling like virtual machine provisioning Autos",
    "start": "900560",
    "end": "905800"
  },
  {
    "text": "scaling and this kind of security control and but on the other hand we try",
    "start": "905800",
    "end": "911800"
  },
  {
    "text": "to leverage Sparks inherent uh class managers functionality to maintain a",
    "start": "911800",
    "end": "920680"
  },
  {
    "text": "master and worker for us that's being said if we can find a way to keep the",
    "start": "920680",
    "end": "926160"
  },
  {
    "text": "master and worker running on top of P so we can uh have a better situation here",
    "start": "926160",
    "end": "934959"
  },
  {
    "text": "our justification is here if we can keep master and worker running on top of",
    "start": "934959",
    "end": "940600"
  },
  {
    "text": "commes there are going to be no machine I mean virtual machine startup delay",
    "start": "940600",
    "end": "946399"
  },
  {
    "text": "there going to be no container image pulling delay no kubernetes API and the",
    "start": "946399",
    "end": "951639"
  },
  {
    "text": "unicor interactively with the you know Cloud private provider delay to allocate",
    "start": "951639",
    "end": "956800"
  },
  {
    "text": "the p from the user side here is another",
    "start": "956800",
    "end": "962839"
  },
  {
    "text": "difference like uh um especially compared to the previous Acure right now",
    "start": "962839",
    "end": "968319"
  },
  {
    "text": "we only need to expose the Masters end point instead we totally hide the kues",
    "start": "968319",
    "end": "975880"
  },
  {
    "text": "end endpoint for users and also it's totally you know simplifies you know management as a",
    "start": "975880",
    "end": "984319"
  },
  {
    "text": "infra engineers and on the other hand we we also can take this kind of",
    "start": "984319",
    "end": "991519"
  },
  {
    "text": "tiny Standalone cluster as a team shared cluster which provides a new multitenant",
    "start": "991519",
    "end": "999120"
  },
  {
    "text": "management styles for for us this has been approved like that this",
    "start": "999120",
    "end": "1006759"
  },
  {
    "text": "very helpful to Foster uh collaboration and maximize the resources",
    "start": "1006759",
    "end": "1014519"
  },
  {
    "text": "utilization so after you know finalizing the motivations and the design choices",
    "start": "1014959",
    "end": "1022199"
  },
  {
    "text": "how to you know design and uh implementation is relative",
    "start": "1022199",
    "end": "1027400"
  },
  {
    "text": "straightforward here is our design principle like how to support running",
    "start": "1027400",
    "end": "1032839"
  },
  {
    "text": "standard L cluster on top of CTIC firstly we try to provide a unified",
    "start": "1032839",
    "end": "1038199"
  },
  {
    "text": "spear operator as I mentioned the previous slide uh we have been leverage",
    "start": "1038199",
    "end": "1043678"
  },
  {
    "text": "this kind of Open Source software which is called spark kinetics operator right",
    "start": "1043679",
    "end": "1049039"
  },
  {
    "text": "right now it's merged to the C flow uh this you know",
    "start": "1049039",
    "end": "1054440"
  },
  {
    "text": "gabo and we try to continually using this kind of you know code base and try",
    "start": "1054440",
    "end": "1061520"
  },
  {
    "text": "the one important things we try to ensure the totally compatibility to our platform to continually support our",
    "start": "1061520",
    "end": "1069840"
  },
  {
    "text": "users to using regular Spark app this kind ofds secondly we try to provide a",
    "start": "1069840",
    "end": "1076960"
  },
  {
    "text": "extendable framework based on this operators and for the CD life circle",
    "start": "1076960",
    "end": "1083400"
  },
  {
    "text": "measurement of course we also try to make it fully automated and uh status up update is",
    "start": "1083400",
    "end": "1091000"
  },
  {
    "text": "very important and we try to leverage crds status update so our batch Gateway",
    "start": "1091000",
    "end": "1097320"
  },
  {
    "text": "can fetch that details back to our users so they can know what their cluster",
    "start": "1097320",
    "end": "1102799"
  },
  {
    "text": "status or job status so we try to provide this capabilities as well",
    "start": "1102799",
    "end": "1109360"
  },
  {
    "text": "as I mentioned before we try to make the ma uh spark master and the spark worker",
    "start": "1109360",
    "end": "1116159"
  },
  {
    "text": "to keep them always running on top of commes so the cost eff going to be a",
    "start": "1116159",
    "end": "1124039"
  },
  {
    "text": "concern so we try to provide uh some cention you know",
    "start": "1124039",
    "end": "1129760"
  },
  {
    "text": "Solutions so here is some detailed implementation we have did um first of",
    "start": "1129760",
    "end": "1136720"
  },
  {
    "text": "all like I mentioned Master provide rest API so in the new versions of SP",
    "start": "1136720",
    "end": "1144159"
  },
  {
    "text": "operator it right now it can provide both submission style you can either V",
    "start": "1144159",
    "end": "1150360"
  },
  {
    "text": "Spar submit sh script or rest rest API to submit your",
    "start": "1150360",
    "end": "1155679"
  },
  {
    "text": "job secondly we introduced two new crds and their corresponding controllers to",
    "start": "1155679",
    "end": "1162080"
  },
  {
    "text": "manage which is one is spark Standalone cluster so we all users for to firstly",
    "start": "1162080",
    "end": "1168480"
  },
  {
    "text": "create create a stand long cluster and secondly we introduced a new CD which is",
    "start": "1168480",
    "end": "1174000"
  },
  {
    "text": "called spark application on stand long so we so we all user to submission to",
    "start": "1174000",
    "end": "1180039"
  },
  {
    "text": "submit their spark application to the corresponding Standalone",
    "start": "1180039",
    "end": "1185919"
  },
  {
    "text": "clusters we also able to all users to addit the initial containers and side CS",
    "start": "1185919",
    "end": "1192440"
  },
  {
    "text": "to their standing clusters this is very helpful especially when user try to you",
    "start": "1192440",
    "end": "1198320"
  },
  {
    "text": "know um download some very large scale you know artifacts or even machine learning",
    "start": "1198320",
    "end": "1203960"
  },
  {
    "text": "models and usually user try to leverage initial container to do this side car",
    "start": "1203960",
    "end": "1211000"
  },
  {
    "text": "for example we try to leverage side car to all us to make some you know authentication uh",
    "start": "1211000",
    "end": "1218400"
  },
  {
    "text": "stuff as I as I mentioned the previous SL like cost evensen and so for each CD",
    "start": "1218400",
    "end": "1225760"
  },
  {
    "text": "we will Auto automatically added a p levels of the scaler uh which is called you know HPA",
    "start": "1225760",
    "end": "1233280"
  },
  {
    "text": "to is CD so we as a start point right now we only take you know uh CPU utiliz",
    "start": "1233280",
    "end": "1240360"
  },
  {
    "text": "utilization this metric to trigger the uh",
    "start": "1240360",
    "end": "1245919"
  },
  {
    "text": "scaling uh the last thing is we try to provide both the cluster levels you know",
    "start": "1246400",
    "end": "1252039"
  },
  {
    "text": "Observer and the job levels Observer for the cluster levels Observer because as I",
    "start": "1252039",
    "end": "1258000"
  },
  {
    "text": "mentioned the Master provide API and it provides method to check the master",
    "start": "1258000",
    "end": "1265240"
  },
  {
    "text": "status for the job status Observer and we can try to you know aain the driver",
    "start": "1265240",
    "end": "1273919"
  },
  {
    "text": "ID and application ID to the request and to check the uh corresponding B",
    "start": "1273919",
    "end": "1281480"
  },
  {
    "text": "application uh status so here is the example to the two",
    "start": "1281480",
    "end": "1288799"
  },
  {
    "text": "new crds on the left hand is the spark stand long cluster crds you can see we",
    "start": "1288799",
    "end": "1296640"
  },
  {
    "text": "user only needed to specify the master and workers resources and then a new St",
    "start": "1296640",
    "end": "1304640"
  },
  {
    "text": "standard on cluster will be created on the uh right hand there is a",
    "start": "1304640",
    "end": "1311559"
  },
  {
    "text": "this is a example for the spark application on stand long we can see if you familiar the previous I mean the",
    "start": "1311559",
    "end": "1318559"
  },
  {
    "text": "original spe operator crd definitions you can see this is pretty",
    "start": "1318559",
    "end": "1323600"
  },
  {
    "text": "similar to that crd definitions and we we keep most of their you know Fields",
    "start": "1323600",
    "end": "1330159"
  },
  {
    "text": "like main application files and the environmental variables and Spark com",
    "start": "1330159",
    "end": "1337400"
  },
  {
    "text": "the only New Field we added is the spark cluster service name so we can identify",
    "start": "1337400",
    "end": "1343240"
  },
  {
    "text": "which sub standal class are going to be R this applications",
    "start": "1343240",
    "end": "1350520"
  },
  {
    "text": "um yeah that's pretty much about how we Implement SP spark operator the next",
    "start": "1350840",
    "end": "1356880"
  },
  {
    "text": "thing is how we integrate to our existing uh spark platform we try to",
    "start": "1356880",
    "end": "1363679"
  },
  {
    "text": "reuse every components I mentioned before firstly we able to reuse the badge processing Gateway just with just",
    "start": "1363679",
    "end": "1371440"
  },
  {
    "text": "added some new s supported as I mentioned it Tred to translate users",
    "start": "1371440",
    "end": "1377039"
  },
  {
    "text": "request to the new SD object secondly we",
    "start": "1377039",
    "end": "1382279"
  },
  {
    "text": "able to reuse the spark history server because we made some op internal",
    "start": "1382279",
    "end": "1387440"
  },
  {
    "text": "optimization to you know indexing all the logs we stalled on the you know uh",
    "start": "1387440",
    "end": "1393760"
  },
  {
    "text": "storage object uh object storage",
    "start": "1393760",
    "end": "1398960"
  },
  {
    "text": "system uh thirdly we able to reuse uni call to manage the M Tenant Resource qu",
    "start": "1398960",
    "end": "1405960"
  },
  {
    "text": "qu and the limitations per Que and we continue can use the que to manage this",
    "start": "1405960",
    "end": "1412799"
  },
  {
    "text": "kind of stuff also and uh if you if you remember",
    "start": "1412799",
    "end": "1418440"
  },
  {
    "text": "I just applied HP HPA to the P levels of scaling but we still able to reuse clust",
    "start": "1418440",
    "end": "1425400"
  },
  {
    "text": "aut scaler or CER to scale the machines to adjust to support that kind of",
    "start": "1425400",
    "end": "1432640"
  },
  {
    "text": "HPA uh the its activities so so accordingly this is a",
    "start": "1432640",
    "end": "1440320"
  },
  {
    "text": "new architecture you can see the most of components is no change we just added",
    "start": "1440320",
    "end": "1447320"
  },
  {
    "text": "two new block to each uh spark commes clusters and uh we",
    "start": "1447320",
    "end": "1453400"
  },
  {
    "text": "can leverage unic call to manage several uh standard on clusters and so that's",
    "start": "1453400",
    "end": "1459760"
  },
  {
    "text": "being said every tenant tenant I mean our you know platform tenants can either",
    "start": "1459760",
    "end": "1466200"
  },
  {
    "text": "using the new standal all the previous uh regular spark",
    "start": "1466200",
    "end": "1472520"
  },
  {
    "text": "application SD is on the same",
    "start": "1472520",
    "end": "1476480"
  },
  {
    "text": "queue okay now let's talk about why this kind of new spe operator can provide a",
    "start": "1478039",
    "end": "1484960"
  },
  {
    "text": "pro pro production GD Sport and why it's faster safer and",
    "start": "1484960",
    "end": "1491000"
  },
  {
    "text": "service is this is a data point we collect we collected firstly let's take",
    "start": "1491279",
    "end": "1498720"
  },
  {
    "text": "the original you know design as a baseline which is means like we keep",
    "start": "1498720",
    "end": "1504480"
  },
  {
    "text": "using commes as the resource manager and but let's take the Baseline like resources",
    "start": "1504480",
    "end": "1511559"
  },
  {
    "text": "use pattern as a temporal with that mean that means all the virtual machine going",
    "start": "1511559",
    "end": "1517320"
  },
  {
    "text": "to be start uh at the code uh status like uh it's will require autoscaler and",
    "start": "1517320",
    "end": "1524840"
  },
  {
    "text": "CER to provision the machine and then uh leverage unicor to allocate part to",
    "start": "1524840",
    "end": "1531720"
  },
  {
    "text": "this new machines We call we let's take this as Baseline and then the first",
    "start": "1531720",
    "end": "1537559"
  },
  {
    "text": "thing is we did is we tried to keep that machine running and then to check the",
    "start": "1537559",
    "end": "1543120"
  },
  {
    "text": "what's the average startup time by the way when we doing some baseline",
    "start": "1543120",
    "end": "1548279"
  },
  {
    "text": "Benchmark and we find the average startup time is around 30 to 90 seconds",
    "start": "1548279",
    "end": "1554360"
  },
  {
    "text": "per each application here the application is it's requireed around thousands P to create to be",
    "start": "1554360",
    "end": "1561919"
  },
  {
    "text": "created so if we keep that virtual machine is running the average start",
    "start": "1561919",
    "end": "1567240"
  },
  {
    "text": "time going to be two times faster that means the average you know start of time",
    "start": "1567240",
    "end": "1573360"
  },
  {
    "text": "is around 30 to 40 seconds if we leverage our new design",
    "start": "1573360",
    "end": "1579679"
  },
  {
    "text": "like uh we if we submit our application to a team shared spark standal mode the",
    "start": "1579679",
    "end": "1586720"
  },
  {
    "text": "average start start of time will be 10 times faster than the Baseline and uh",
    "start": "1586720",
    "end": "1594240"
  },
  {
    "text": "basically our testing number is around four to five seconds per each Spar",
    "start": "1594240",
    "end": "1602200"
  },
  {
    "text": "applications another thing is why we think a stand on cluster is more safer",
    "start": "1602559",
    "end": "1607720"
  },
  {
    "text": "first thing uh as you know this is going to be a long running standard on cluster is more stable and it also help our",
    "start": "1607720",
    "end": "1616360"
  },
  {
    "text": "infra engineer to you know when we're doing some tication and authorization we always try to keep you know talking to",
    "start": "1616360",
    "end": "1624159"
  },
  {
    "text": "API server especially when we repeated creating the new p and delete but if we",
    "start": "1624159",
    "end": "1631039"
  },
  {
    "text": "keep a long running stand on cluster this will hugely you know uh decrease",
    "start": "1631039",
    "end": "1637960"
  },
  {
    "text": "the uh reduce the you know API servers uh stressed and also it's help us very",
    "start": "1637960",
    "end": "1646360"
  },
  {
    "text": "you know more easier to audit all their you know activities secondly because we added",
    "start": "1646360",
    "end": "1653279"
  },
  {
    "text": "added a new layers of you know uh like a standalone cluster to our customers and",
    "start": "1653279",
    "end": "1661159"
  },
  {
    "text": "we can provide a more granular of security isolation we can apply a",
    "start": "1661159",
    "end": "1666600"
  },
  {
    "text": "dedicated service account and their policies or am rules to it thirdly uh we",
    "start": "1666600",
    "end": "1674240"
  },
  {
    "text": "it provides tenant autonomy so that being said we know no need to expose all",
    "start": "1674240",
    "end": "1681000"
  },
  {
    "text": "the you know necessary policies so user still can get some new information for",
    "start": "1681000",
    "end": "1688039"
  },
  {
    "text": "the this kind of stand on cluster because previously user only need only",
    "start": "1688039",
    "end": "1694000"
  },
  {
    "text": "can get uh status from the P level and their public uh their application Level",
    "start": "1694000",
    "end": "1700120"
  },
  {
    "text": "status right now they also can get some you know master and worker levels",
    "start": "1700120",
    "end": "1707120"
  },
  {
    "text": "status um third thing is how it support the",
    "start": "1707120",
    "end": "1714080"
  },
  {
    "text": "serverless yeah the first thing is like uh we simplify the you know cluster",
    "start": "1714080",
    "end": "1719799"
  },
  {
    "text": "creation process user just need a single API call user can creat their dedicated",
    "start": "1719799",
    "end": "1726519"
  },
  {
    "text": "even team share the you know cluster on top of commes and they no need to consider what kind of virtual machine",
    "start": "1726519",
    "end": "1733279"
  },
  {
    "text": "instant type families they going to select and what kind of storage layer going to select",
    "start": "1733279",
    "end": "1738720"
  },
  {
    "text": "our you know platform try to help them also they no need to continually",
    "start": "1738720",
    "end": "1746480"
  },
  {
    "text": "like update the spark version and U our infra or platform can handle it handle",
    "start": "1746480",
    "end": "1752679"
  },
  {
    "text": "it they're going to we try to you know maximize the resources isolations so",
    "start": "1752679",
    "end": "1758840"
  },
  {
    "text": "there are going to be no Idol capacities with help of HPA autoscaler CL Autos",
    "start": "1758840",
    "end": "1765320"
  },
  {
    "text": "scalar together also so user only can pay only",
    "start": "1765320",
    "end": "1770760"
  },
  {
    "text": "their current usage at the end um if you remember the recall the previous slide",
    "start": "1770760",
    "end": "1778000"
  },
  {
    "text": "we try to also provide some observability functionalities so at the",
    "start": "1778000",
    "end": "1783279"
  },
  {
    "text": "bottom we you know build some U Co pipelines to calculate uh uh",
    "start": "1783279",
    "end": "1790000"
  },
  {
    "text": "every clust level and the application levels cost numbers for our",
    "start": "1790000",
    "end": "1796759"
  },
  {
    "text": "users on the other hand what's the new to our users by introduce this stand long",
    "start": "1797039",
    "end": "1805120"
  },
  {
    "text": "cluster and because I mentioned the spark Master also provide a new UI so we",
    "start": "1805120",
    "end": "1810919"
  },
  {
    "text": "expose this new UI to our users so they need to learn how to you know use uh",
    "start": "1810919",
    "end": "1817320"
  },
  {
    "text": "leverage this new spark web UI on this spark UI you can check all the submitted",
    "start": "1817320",
    "end": "1825000"
  },
  {
    "text": "applications and running status of your jobs and you also can check the worker status",
    "start": "1825000",
    "end": "1831159"
  },
  {
    "text": "like uh CPU and memory usage that kind of stuff so they can fetch more details",
    "start": "1831159",
    "end": "1839320"
  },
  {
    "text": "uh not only you know driver and executors but also masterer and",
    "start": "1839320",
    "end": "1844519"
  },
  {
    "text": "workers um of course we provide a new option to a team share the long running cluster and the new options for the",
    "start": "1844519",
    "end": "1851360"
  },
  {
    "text": "Jupiter uh users and lastly uh it help us uh able",
    "start": "1851360",
    "end": "1858480"
  },
  {
    "text": "to running Dre on top of uh Spar cluster",
    "start": "1858480",
    "end": "1863559"
  },
  {
    "text": "if you look at Dre's you know official website you can you can see right now re",
    "start": "1863559",
    "end": "1868799"
  },
  {
    "text": "only can running on stand long",
    "start": "1868799",
    "end": "1872799"
  },
  {
    "text": "cluster okay lastly this is our ongoing work F thank you uh first of all we try to",
    "start": "1874480",
    "end": "1883159"
  },
  {
    "text": "provide a better M tenance management if you remember which I",
    "start": "1883159",
    "end": "1888360"
  },
  {
    "text": "mentioned before right now the vanilla spark Master is you know code base right",
    "start": "1888360",
    "end": "1895200"
  },
  {
    "text": "now only support faithful scheduling and we try to you know make some patch to The Spar Master to able to you know uh",
    "start": "1895200",
    "end": "1904760"
  },
  {
    "text": "supported uh other scheduling strategy like fair or PRI priority based you know",
    "start": "1904760",
    "end": "1912519"
  },
  {
    "text": "scheduling um secondly SP Master is a kind of stateful service and and uh we",
    "start": "1912519",
    "end": "1919760"
  },
  {
    "text": "try to um make uh you know um avoid any kind",
    "start": "1919760",
    "end": "1926200"
  },
  {
    "text": "of restart failings and uh we are considering leverage PVC and the state",
    "start": "1926200",
    "end": "1932360"
  },
  {
    "text": "foret to support this master part and lastly but a very a lot of huge",
    "start": "1932360",
    "end": "1940200"
  },
  {
    "text": "work to the third party is like how to improve the debuggability to our",
    "start": "1940200",
    "end": "1945720"
  },
  {
    "text": "platform this is ongoing issue from the our you know previous platform as well",
    "start": "1945720",
    "end": "1952120"
  },
  {
    "text": "and we try to continually optimizing the login metrix and web U for our",
    "start": "1952120",
    "end": "1958679"
  },
  {
    "text": "users um yeah I think that's all my today's sharing and now it's time for",
    "start": "1958679",
    "end": "1968440"
  },
  {
    "text": "[Applause]",
    "start": "1970100",
    "end": "1976840"
  },
  {
    "text": "question",
    "start": "1976840",
    "end": "1979840"
  },
  {
    "text": "hello is the operator you showed open source and we can all find it somewhere",
    "start": "1985799",
    "end": "1991840"
  },
  {
    "text": "use it yeah good question at when we started this project uh this is the",
    "start": "1991840",
    "end": "1997799"
  },
  {
    "text": "first question we you know think as you know right now the open source the spark",
    "start": "1997799",
    "end": "2002960"
  },
  {
    "text": "connetics operator is already merged to the under Co flow right now now we have",
    "start": "2002960",
    "end": "2009080"
  },
  {
    "text": "you know um better position to make PR to that public repo and right now we try to",
    "start": "2009080",
    "end": "2017080"
  },
  {
    "text": "speed up this kind of process internally and we going to you know merge our PR to",
    "start": "2017080",
    "end": "2023240"
  },
  {
    "text": "the open source software as well thank you hello thank you for the presentation",
    "start": "2023240",
    "end": "2030799"
  },
  {
    "text": "um so my question is as I know spark Standalone mode does not support python",
    "start": "2030799",
    "end": "2036760"
  },
  {
    "text": "py spark code um so do I understand correctly that in your like solution there won't be",
    "start": "2036760",
    "end": "2043320"
  },
  {
    "text": "support for python code uh I don't think that's uh correct",
    "start": "2043320",
    "end": "2049320"
  },
  {
    "text": "statement uh based on our internal testing firstly you need uh using spark",
    "start": "2049320",
    "end": "2056040"
  },
  {
    "text": "cluster mode yes so cluster mode does not support python right now no actually",
    "start": "2056040",
    "end": "2061960"
  },
  {
    "text": "based on our internal testing it definitely supports and but you just need using the right way of spark Master",
    "start": "2061960",
    "end": "2069480"
  },
  {
    "text": "API to submit their to submit the job that being said the main class going to",
    "start": "2069480",
    "end": "2075398"
  },
  {
    "text": "be not your applications uh no uh spark applications main class but uh you have to using uh I",
    "start": "2075399",
    "end": "2083158"
  },
  {
    "text": "didn't show that but you have to using a Java submit that kind of class as a main",
    "start": "2083159",
    "end": "2089520"
  },
  {
    "text": "application file and then added your pass application file to the dependency",
    "start": "2089520",
    "end": "2095760"
  },
  {
    "text": "pass then you're able to run oh so so you don't use native python support for spark uh but you submit Java code and",
    "start": "2095760",
    "end": "2103440"
  },
  {
    "text": "run python from there right yeah but this capability already supported to the current spark Master source code okay",
    "start": "2103440",
    "end": "2110920"
  },
  {
    "text": "thank you we can yeah we can check detail",
    "start": "2110920",
    "end": "2114640"
  },
  {
    "text": "offline hi uh have you considered using Spar connect to furtherly shorten the",
    "start": "2123440",
    "end": "2130280"
  },
  {
    "text": "set time thanks so the question is why not weiver spark connect instead of",
    "start": "2130280",
    "end": "2136079"
  },
  {
    "text": "using the very old spark stand law mode right and uh yeah we made a lot of",
    "start": "2136079",
    "end": "2142200"
  },
  {
    "text": "research to the spark connect at that time at least I mean you know half years ago Spar conect is not that mature it",
    "start": "2142200",
    "end": "2149520"
  },
  {
    "text": "cannot sport the data frame and uh a lot of P UDF still cannot support that's why",
    "start": "2149520",
    "end": "2156640"
  },
  {
    "text": "we you know you know didn't uh leverage it but I think uh you know weigh the",
    "start": "2156640",
    "end": "2162599"
  },
  {
    "text": "spark connect is you know mature getting mature we may be able to spot it but the",
    "start": "2162599",
    "end": "2168560"
  },
  {
    "text": "main advantage maybe is provides small debug abilities for our users and maybe",
    "start": "2168560",
    "end": "2174000"
  },
  {
    "text": "better for the Jupiter notebook users but not for the large scale workload but Leverage is standard on",
    "start": "2174000",
    "end": "2181720"
  },
  {
    "text": "cluster you also can run in R I don't think spark connect can you know connect can spot this",
    "start": "2181720",
    "end": "2189560"
  },
  {
    "text": "thank you last question um what are the",
    "start": "2189680",
    "end": "2195000"
  },
  {
    "text": "challenges of running Ray on spark yeah good question uh I think a",
    "start": "2195000",
    "end": "2201800"
  },
  {
    "text": "first question is first thing is the first challenge we're facing is dependence management even though we can",
    "start": "2201800",
    "end": "2209560"
  },
  {
    "text": "leverage you know container AOC fire to manage this but you know if we're running some GPU based machine learning",
    "start": "2209560",
    "end": "2216680"
  },
  {
    "text": "workloads it's very hard to find the combination versions of you know Cuda",
    "start": "2216680",
    "end": "2221800"
  },
  {
    "text": "driver you know a media driver Cuda you know 2K this kind stuff with the you",
    "start": "2221800",
    "end": "2227319"
  },
  {
    "text": "know other you know machine learning framework that's one of you know first challenges we are facing right now and",
    "start": "2227319",
    "end": "2234280"
  },
  {
    "text": "secondly how efficiently you know improve the GPU utilization with various tools and",
    "start": "2234280",
    "end": "2241280"
  },
  {
    "text": "accelerators and doing whatever inference or training that's is ongoing challenges we are facing and uh yeah and",
    "start": "2241280",
    "end": "2249520"
  },
  {
    "text": "we can share more detail offline if you need it okay uh quick question how how do you",
    "start": "2249520",
    "end": "2258160"
  },
  {
    "text": "scale um Standalone clusters in response uh to VAR uh work workload que like uh",
    "start": "2258160",
    "end": "2265400"
  },
  {
    "text": "nightly batches or mon Monday morning spikes on submissions of the jobs so",
    "start": "2265400",
    "end": "2271520"
  },
  {
    "text": "basically your question is how to handle Peak usage for the some emissions right",
    "start": "2271520",
    "end": "2277240"
  },
  {
    "text": "yeah basically uh right now as a start point we all users to specify the minimum and",
    "start": "2277240",
    "end": "2286960"
  },
  {
    "text": "the maximum P numbers to the crds and then leverage HPA to adjust the P",
    "start": "2286960",
    "end": "2294960"
  },
  {
    "text": "numbers inside this range that's our current status but how to sport you know",
    "start": "2294960",
    "end": "2302400"
  },
  {
    "text": "obstruct you know or Peak usage for the very large scale or Back Field use cases",
    "start": "2302400",
    "end": "2308480"
  },
  {
    "text": "we haven't explored that but basically I would say in that case we may you know",
    "start": "2308480",
    "end": "2314160"
  },
  {
    "text": "encourage user to over Pro over provision their you know spark Port uh",
    "start": "2314160",
    "end": "2320520"
  },
  {
    "text": "spark stand along clusters so we can leverage HPA to do that but",
    "start": "2320520",
    "end": "2326000"
  },
  {
    "text": "not thank you okay thanks for your",
    "start": "2326000",
    "end": "2331440"
  },
  {
    "text": "time",
    "start": "2332640",
    "end": "2335640"
  }
]
[
  {
    "start": "0",
    "end": "21000"
  },
  {
    "text": "hello welcome to the talk scaling",
    "start": "160",
    "end": "2240"
  },
  {
    "text": "prometheus how we got some tunnels into",
    "start": "2240",
    "end": "4560"
  },
  {
    "text": "cortex",
    "start": "4560",
    "end": "5759"
  },
  {
    "text": "uh in this talk we are going to show",
    "start": "5759",
    "end": "8080"
  },
  {
    "text": "cortex and specifically",
    "start": "8080",
    "end": "9920"
  },
  {
    "text": "a new storage engine we have built into",
    "start": "9920",
    "end": "13040"
  },
  {
    "text": "cortex",
    "start": "13040",
    "end": "13920"
  },
  {
    "text": "leveraging containers before that let me",
    "start": "13920",
    "end": "16800"
  },
  {
    "text": "do",
    "start": "16800",
    "end": "17199"
  },
  {
    "text": "a quick introduction about cortex",
    "start": "17199",
    "end": "20480"
  },
  {
    "text": "cortex is a distributed time series",
    "start": "20480",
    "end": "22640"
  },
  {
    "start": "21000",
    "end": "21000"
  },
  {
    "text": "database built",
    "start": "22640",
    "end": "23600"
  },
  {
    "text": "on top of prometheus cortex is",
    "start": "23600",
    "end": "26800"
  },
  {
    "text": "horizontally scalable and highly",
    "start": "26800",
    "end": "28400"
  },
  {
    "text": "available",
    "start": "28400",
    "end": "29279"
  },
  {
    "text": "and offer a durable long-term storage",
    "start": "29279",
    "end": "31679"
  },
  {
    "text": "for your time series data",
    "start": "31679",
    "end": "34559"
  },
  {
    "text": "cortex supports multi-tenancy",
    "start": "34559",
    "end": "37600"
  },
  {
    "text": "and the typical use case is to have",
    "start": "37600",
    "end": "40879"
  },
  {
    "text": "a global view across multiple prometheus",
    "start": "40879",
    "end": "43840"
  },
  {
    "text": "servers",
    "start": "43840",
    "end": "45440"
  },
  {
    "text": "over the years cortex also",
    "start": "45440",
    "end": "48879"
  },
  {
    "text": "spent a lot of effort in order to",
    "start": "48879",
    "end": "51280"
  },
  {
    "text": "optimize the read path",
    "start": "51280",
    "end": "53360"
  },
  {
    "text": "and today cortex offers a very good",
    "start": "53360",
    "end": "57199"
  },
  {
    "text": "query performances cortex is a cncf",
    "start": "57199",
    "end": "61039"
  },
  {
    "text": "sandbar project and we are currently in",
    "start": "61039",
    "end": "63920"
  },
  {
    "text": "the process",
    "start": "63920",
    "end": "64878"
  },
  {
    "text": "of moving to incubation",
    "start": "64879",
    "end": "68560"
  },
  {
    "text": "the typical use case of cortex is that",
    "start": "68560",
    "end": "71280"
  },
  {
    "text": "you have",
    "start": "71280",
    "end": "72159"
  },
  {
    "text": "multiple prometheus servers usually in",
    "start": "72159",
    "end": "75439"
  },
  {
    "text": "configured in a shapers and",
    "start": "75439",
    "end": "78560"
  },
  {
    "text": "you configure prometheus to remote write",
    "start": "78560",
    "end": "81439"
  },
  {
    "text": "to",
    "start": "81439",
    "end": "81840"
  },
  {
    "text": "a central cortex cluster where",
    "start": "81840",
    "end": "84960"
  },
  {
    "text": "all your time series are written and",
    "start": "84960",
    "end": "87520"
  },
  {
    "text": "then you configure grafana",
    "start": "87520",
    "end": "89200"
  },
  {
    "text": "or the querying tool of your choice to",
    "start": "89200",
    "end": "92320"
  },
  {
    "text": "query back this metrics from cortex",
    "start": "92320",
    "end": "95920"
  },
  {
    "text": "cortex internally vendor prometheus and",
    "start": "95920",
    "end": "99680"
  },
  {
    "text": "we use the same exact prometheus promql",
    "start": "99680",
    "end": "103119"
  },
  {
    "text": "engine this guarantees 100",
    "start": "103119",
    "end": "106240"
  },
  {
    "text": "compatibility on your queries",
    "start": "106240",
    "end": "110320"
  },
  {
    "start": "110000",
    "end": "110000"
  },
  {
    "text": "if you look at the microservices",
    "start": "111040",
    "end": "113759"
  },
  {
    "text": "architecture",
    "start": "113759",
    "end": "114640"
  },
  {
    "text": "of cortex cortex is composed by",
    "start": "114640",
    "end": "117280"
  },
  {
    "text": "different services",
    "start": "117280",
    "end": "119119"
  },
  {
    "text": "interacting together different services",
    "start": "119119",
    "end": "122320"
  },
  {
    "text": "which",
    "start": "122320",
    "end": "122719"
  },
  {
    "text": "you can independently horizontally scale",
    "start": "122719",
    "end": "125759"
  },
  {
    "text": "up and down",
    "start": "125759",
    "end": "127200"
  },
  {
    "text": "on the right path you have a prometheus",
    "start": "127200",
    "end": "130160"
  },
  {
    "text": "configured to remote right",
    "start": "130160",
    "end": "132239"
  },
  {
    "text": "to the distributor and the distributor",
    "start": "132239",
    "end": "135040"
  },
  {
    "text": "is",
    "start": "135040",
    "end": "135599"
  },
  {
    "text": "the ingress for the right path and is",
    "start": "135599",
    "end": "138160"
  },
  {
    "text": "responsible to",
    "start": "138160",
    "end": "139360"
  },
  {
    "text": "shard and replicate your series across a",
    "start": "139360",
    "end": "142720"
  },
  {
    "text": "pool of ingestors",
    "start": "142720",
    "end": "144800"
  },
  {
    "text": "injesters keep they receive the serious",
    "start": "144800",
    "end": "147520"
  },
  {
    "text": "samples",
    "start": "147520",
    "end": "148160"
  },
  {
    "text": "in memory and periodically flush",
    "start": "148160",
    "end": "151519"
  },
  {
    "text": "there's a series to the long term",
    "start": "151519",
    "end": "154160"
  },
  {
    "text": "storage",
    "start": "154160",
    "end": "155599"
  },
  {
    "text": "under the foot the long term storage is",
    "start": "155599",
    "end": "157760"
  },
  {
    "text": "actually composed by",
    "start": "157760",
    "end": "159040"
  },
  {
    "text": "two different data stores an object",
    "start": "159040",
    "end": "161280"
  },
  {
    "text": "store and an",
    "start": "161280",
    "end": "162400"
  },
  {
    "text": "index store the object store is like gcs",
    "start": "162400",
    "end": "166080"
  },
  {
    "text": "or s3 is used to store chunks",
    "start": "166080",
    "end": "170480"
  },
  {
    "text": "of compressed timestamp value pairs",
    "start": "170480",
    "end": "174160"
  },
  {
    "text": "which we call chunks and the index store",
    "start": "174160",
    "end": "176959"
  },
  {
    "text": "like big table or dynamodb or cassandra",
    "start": "176959",
    "end": "180400"
  },
  {
    "text": "is used to store an inverted index",
    "start": "180400",
    "end": "183599"
  },
  {
    "text": "which we use to look up the chunks by",
    "start": "183599",
    "end": "186640"
  },
  {
    "text": "the label the query label matches",
    "start": "186640",
    "end": "190720"
  },
  {
    "text": "and the query time time range",
    "start": "190720",
    "end": "194000"
  },
  {
    "text": "on the read path you configure graffana",
    "start": "194000",
    "end": "196640"
  },
  {
    "text": "or your queering tool",
    "start": "196640",
    "end": "198800"
  },
  {
    "text": "to send the query request",
    "start": "198800",
    "end": "202239"
  },
  {
    "text": "to the query frontend which is the",
    "start": "202239",
    "end": "204720"
  },
  {
    "text": "ingress",
    "start": "204720",
    "end": "205519"
  },
  {
    "text": "for the read path in a cortex cluster",
    "start": "205519",
    "end": "208239"
  },
  {
    "text": "the query frontend",
    "start": "208239",
    "end": "209920"
  },
  {
    "text": "the main purpose of the query frontend",
    "start": "209920",
    "end": "212400"
  },
  {
    "text": "is to offer",
    "start": "212400",
    "end": "213519"
  },
  {
    "text": "result caching and also",
    "start": "213519",
    "end": "217280"
  },
  {
    "text": "employs some optimization techniques",
    "start": "217280",
    "end": "220000"
  },
  {
    "text": "which",
    "start": "220000",
    "end": "220640"
  },
  {
    "text": "we will see in details later on which",
    "start": "220640",
    "end": "223680"
  },
  {
    "text": "allows to",
    "start": "223680",
    "end": "224720"
  },
  {
    "text": "parallelize the query execution across",
    "start": "224720",
    "end": "227920"
  },
  {
    "text": "multiple",
    "start": "227920",
    "end": "228560"
  },
  {
    "text": "query nodes so the query",
    "start": "228560",
    "end": "231680"
  },
  {
    "text": "or a splitted query that can be splitted",
    "start": "231680",
    "end": "234480"
  },
  {
    "text": "by the query front-end is actually",
    "start": "234480",
    "end": "236319"
  },
  {
    "text": "executed by a pool of queries which will",
    "start": "236319",
    "end": "239599"
  },
  {
    "text": "fetch",
    "start": "239599",
    "end": "240000"
  },
  {
    "text": "the most recent samples from the",
    "start": "240000",
    "end": "241680"
  },
  {
    "text": "ingestors and all their data from the",
    "start": "241680",
    "end": "243840"
  },
  {
    "text": "long term storage",
    "start": "243840",
    "end": "244959"
  },
  {
    "text": "and then we'll run the promql engine on",
    "start": "244959",
    "end": "247519"
  },
  {
    "text": "top of this",
    "start": "247519",
    "end": "249760"
  },
  {
    "text": "now this slide shows you",
    "start": "249760",
    "end": "253760"
  },
  {
    "text": "the microservices architecture but you",
    "start": "253760",
    "end": "256400"
  },
  {
    "text": "are not",
    "start": "256400",
    "end": "257040"
  },
  {
    "text": "required to deploy cortex in",
    "start": "257040",
    "end": "259199"
  },
  {
    "text": "microservices architecture",
    "start": "259199",
    "end": "260799"
  },
  {
    "text": "because cortex actually support a second",
    "start": "260799",
    "end": "264240"
  },
  {
    "start": "261000",
    "end": "261000"
  },
  {
    "text": "operational mode which is the single",
    "start": "264240",
    "end": "266000"
  },
  {
    "text": "binary mode and it's the easiest",
    "start": "266000",
    "end": "268000"
  },
  {
    "text": "way to deploy a cortex cluster today so",
    "start": "268000",
    "end": "270720"
  },
  {
    "text": "when you deploy",
    "start": "270720",
    "end": "271600"
  },
  {
    "text": "cortex in single binary mode cortex",
    "start": "271600",
    "end": "275520"
  },
  {
    "text": "is running as a single binary with a",
    "start": "275520",
    "end": "277680"
  },
  {
    "text": "single configuration",
    "start": "277680",
    "end": "279120"
  },
  {
    "text": "if you deploy inside kubernetes",
    "start": "279120",
    "end": "282240"
  },
  {
    "text": "it will just be a single deployment",
    "start": "282240",
    "end": "285840"
  },
  {
    "text": "and what we actually do is that",
    "start": "285840",
    "end": "288320"
  },
  {
    "text": "internally",
    "start": "288320",
    "end": "289120"
  },
  {
    "text": "within one single cortex process",
    "start": "289120",
    "end": "292240"
  },
  {
    "text": "we run all the microservices all the",
    "start": "292240",
    "end": "294080"
  },
  {
    "text": "cortex microservices",
    "start": "294080",
    "end": "295600"
  },
  {
    "text": "so the microservices are hidden to you",
    "start": "295600",
    "end": "297840"
  },
  {
    "text": "when you deploy cortex in single binary",
    "start": "297840",
    "end": "299759"
  },
  {
    "text": "mode",
    "start": "299759",
    "end": "300320"
  },
  {
    "text": "but you can still horizontally scale",
    "start": "300320",
    "end": "304400"
  },
  {
    "text": "cortex running multiple replicas",
    "start": "304400",
    "end": "307680"
  },
  {
    "text": "of the single binary and all the cortex",
    "start": "307680",
    "end": "310400"
  },
  {
    "text": "properties",
    "start": "310400",
    "end": "311520"
  },
  {
    "text": "like horizontal scalability and high",
    "start": "311520",
    "end": "313759"
  },
  {
    "text": "availability",
    "start": "313759",
    "end": "314639"
  },
  {
    "text": "or query performances are preserved in",
    "start": "314639",
    "end": "317759"
  },
  {
    "text": "single binary mode as well",
    "start": "317759",
    "end": "321039"
  },
  {
    "text": "this architecture um over the time",
    "start": "322320",
    "end": "324960"
  },
  {
    "text": "proved to work and scale very well",
    "start": "324960",
    "end": "327680"
  },
  {
    "text": "we have seen cortex clusters",
    "start": "327680",
    "end": "331199"
  },
  {
    "text": "ranging from few tens to 100 million",
    "start": "331199",
    "end": "335680"
  },
  {
    "text": "active series and uh in the typical use",
    "start": "335680",
    "end": "339360"
  },
  {
    "text": "case",
    "start": "339360",
    "end": "340080"
  },
  {
    "text": "um we see the 99.5 percentile query",
    "start": "340080",
    "end": "343360"
  },
  {
    "text": "latency below",
    "start": "343360",
    "end": "344880"
  },
  {
    "text": "2.5 second however",
    "start": "344880",
    "end": "348800"
  },
  {
    "text": "for many users requiring both an object",
    "start": "348800",
    "end": "351680"
  },
  {
    "text": "store",
    "start": "351680",
    "end": "352240"
  },
  {
    "text": "and an index store introduce extra",
    "start": "352240",
    "end": "355600"
  },
  {
    "text": "operational complexity",
    "start": "355600",
    "end": "357440"
  },
  {
    "text": "and if you run in the cloud like big",
    "start": "357440",
    "end": "359360"
  },
  {
    "text": "table or dynamodb",
    "start": "359360",
    "end": "360800"
  },
  {
    "text": "also extra costs to run a cortex cluster",
    "start": "360800",
    "end": "363840"
  },
  {
    "text": "so almost an year ago we started",
    "start": "363840",
    "end": "366080"
  },
  {
    "text": "brainstorming on the idea to",
    "start": "366080",
    "end": "367919"
  },
  {
    "start": "367000",
    "end": "367000"
  },
  {
    "text": "remove the index store at all the idea",
    "start": "367919",
    "end": "370960"
  },
  {
    "text": "was well",
    "start": "370960",
    "end": "372240"
  },
  {
    "text": "are we able to remove the index store",
    "start": "372240",
    "end": "375360"
  },
  {
    "text": "dependency at all and store all the data",
    "start": "375360",
    "end": "378400"
  },
  {
    "text": "only in the object store",
    "start": "378400",
    "end": "381680"
  },
  {
    "text": "and that's how the cortex blocks storage",
    "start": "381680",
    "end": "385199"
  },
  {
    "text": "started and specifically the cortex",
    "start": "385199",
    "end": "388639"
  },
  {
    "text": "block storage",
    "start": "388639",
    "end": "389520"
  },
  {
    "text": "is an alternative storage engine",
    "start": "389520",
    "end": "393120"
  },
  {
    "text": "currently in the experimental phase",
    "start": "393120",
    "end": "396479"
  },
  {
    "text": "we supporting cortex so you can deploy",
    "start": "396479",
    "end": "398960"
  },
  {
    "text": "cortex",
    "start": "398960",
    "end": "399759"
  },
  {
    "text": "with the chunk storage which is the",
    "start": "399759",
    "end": "402639"
  },
  {
    "text": "architecture",
    "start": "402639",
    "end": "403440"
  },
  {
    "text": "i just showed you or you can deploy",
    "start": "403440",
    "end": "406560"
  },
  {
    "text": "cortex",
    "start": "406560",
    "end": "407120"
  },
  {
    "text": "using the new and experimental block",
    "start": "407120",
    "end": "410000"
  },
  {
    "text": "storage",
    "start": "410000",
    "end": "411039"
  },
  {
    "text": "in this talk we are going to cover how",
    "start": "411039",
    "end": "412960"
  },
  {
    "text": "the block storage work",
    "start": "412960",
    "end": "414160"
  },
  {
    "text": "under the food hello everyone my name is",
    "start": "414160",
    "end": "417120"
  },
  {
    "text": "marco",
    "start": "417120",
    "end": "417680"
  },
  {
    "text": "i'm a software engineer at grafana labs",
    "start": "417680",
    "end": "419919"
  },
  {
    "text": "i'm a cortex maintainer",
    "start": "419919",
    "end": "421199"
  },
  {
    "text": "and i recently joined tino spontaneous",
    "start": "421199",
    "end": "423840"
  },
  {
    "text": "as well",
    "start": "423840",
    "end": "426160"
  },
  {
    "text": "hi i'm thor hansen i'm a software",
    "start": "426880",
    "end": "428880"
  },
  {
    "text": "engineer at hashicorp",
    "start": "428880",
    "end": "430880"
  },
  {
    "text": "i got involved with cortex in my",
    "start": "430880",
    "end": "432319"
  },
  {
    "text": "previous role where we serve metrics and",
    "start": "432319",
    "end": "434240"
  },
  {
    "text": "alerts for many customers we were a",
    "start": "434240",
    "end": "436240"
  },
  {
    "text": "small",
    "start": "436240",
    "end": "436639"
  },
  {
    "text": "team and needed the scalability of",
    "start": "436639",
    "end": "438560"
  },
  {
    "text": "cortex",
    "start": "438560",
    "end": "439680"
  },
  {
    "text": "as well as the multi-tenancy but didn't",
    "start": "439680",
    "end": "441680"
  },
  {
    "text": "want to have to manage a separate index",
    "start": "441680",
    "end": "443360"
  },
  {
    "text": "store",
    "start": "443360",
    "end": "444240"
  },
  {
    "text": "which is where this all started for me",
    "start": "444240",
    "end": "447759"
  },
  {
    "text": "so the main idea behind the block",
    "start": "448800",
    "end": "450400"
  },
  {
    "text": "storage solution is to open up a",
    "start": "450400",
    "end": "452240"
  },
  {
    "text": "prometheus tsdb",
    "start": "452240",
    "end": "453919"
  },
  {
    "text": "per tenant per ingestor and upload these",
    "start": "453919",
    "end": "456560"
  },
  {
    "text": "blocks to long-term storage",
    "start": "456560",
    "end": "458880"
  },
  {
    "text": "a tsdb block both contains the chunks of",
    "start": "458880",
    "end": "461360"
  },
  {
    "text": "compressed data points",
    "start": "461360",
    "end": "462720"
  },
  {
    "text": "and importantly also contains the index",
    "start": "462720",
    "end": "465520"
  },
  {
    "text": "and the entire block can easily be",
    "start": "465520",
    "end": "467199"
  },
  {
    "text": "stored in an object store",
    "start": "467199",
    "end": "468879"
  },
  {
    "text": "basically removing the need to run a",
    "start": "468879",
    "end": "470560"
  },
  {
    "text": "dedicated index store",
    "start": "470560",
    "end": "473759"
  },
  {
    "text": "but isn't this what thanos was already",
    "start": "475840",
    "end": "477440"
  },
  {
    "text": "doing",
    "start": "477440",
    "end": "479840"
  },
  {
    "text": "so instead of trying to reinvent the",
    "start": "479919",
    "end": "481440"
  },
  {
    "text": "wheel we can leverage the lessons",
    "start": "481440",
    "end": "483280"
  },
  {
    "text": "learned from thanos",
    "start": "483280",
    "end": "484479"
  },
  {
    "text": "and grow on that",
    "start": "484479",
    "end": "487280"
  },
  {
    "text": "so i built the initial version of this",
    "start": "488400",
    "end": "489840"
  },
  {
    "text": "idea it would open a tsdb for each",
    "start": "489840",
    "end": "492160"
  },
  {
    "text": "tenant",
    "start": "492160",
    "end": "492639"
  },
  {
    "text": "on every ingestor to store incoming",
    "start": "492639",
    "end": "494160"
  },
  {
    "text": "rights these tsdbs would periodically",
    "start": "494160",
    "end": "497360"
  },
  {
    "text": "write a block to the ingestor's local",
    "start": "497360",
    "end": "499039"
  },
  {
    "text": "disk under a tenant prefix directory",
    "start": "499039",
    "end": "502319"
  },
  {
    "text": "ingestor started a thanos shipper per",
    "start": "502319",
    "end": "504160"
  },
  {
    "text": "tenant to scan each of these tsdb's",
    "start": "504160",
    "end": "506080"
  },
  {
    "text": "directories",
    "start": "506080",
    "end": "507120"
  },
  {
    "text": "and upload newly written blocks to",
    "start": "507120",
    "end": "508720"
  },
  {
    "text": "long-term storage",
    "start": "508720",
    "end": "510400"
  },
  {
    "text": "ingestors would now serve queries",
    "start": "510400",
    "end": "512000"
  },
  {
    "text": "straight from the local tsdb",
    "start": "512000",
    "end": "514000"
  },
  {
    "text": "injector tsubs had a given retention",
    "start": "514000",
    "end": "516000"
  },
  {
    "text": "period where blocks that had been",
    "start": "516000",
    "end": "517279"
  },
  {
    "text": "shipped to storage but exceeded the",
    "start": "517279",
    "end": "518640"
  },
  {
    "text": "retention period",
    "start": "518640",
    "end": "519518"
  },
  {
    "text": "were deleted from local storage it also",
    "start": "519519",
    "end": "522560"
  },
  {
    "text": "modified the query to use thanos querier",
    "start": "522560",
    "end": "524720"
  },
  {
    "text": "which would download and cache the index",
    "start": "524720",
    "end": "526640"
  },
  {
    "text": "and blocks found in long-term storage",
    "start": "526640",
    "end": "528800"
  },
  {
    "text": "for each tenant prefix query could then",
    "start": "528800",
    "end": "531519"
  },
  {
    "text": "serve requests",
    "start": "531519",
    "end": "532399"
  },
  {
    "text": "by either using the cash blocks or",
    "start": "532399",
    "end": "534320"
  },
  {
    "text": "downloading blocks on demand from block",
    "start": "534320",
    "end": "536160"
  },
  {
    "text": "storage",
    "start": "536160",
    "end": "538560"
  },
  {
    "text": "i'd like to give special thanks to peter",
    "start": "539760",
    "end": "542160"
  },
  {
    "text": "and ganesh",
    "start": "542160",
    "end": "543040"
  },
  {
    "text": "for their contributions to this",
    "start": "543040",
    "end": "544399"
  },
  {
    "text": "community effort as well as others who",
    "start": "544399",
    "end": "546480"
  },
  {
    "text": "put in time and effort into making this",
    "start": "546480",
    "end": "548160"
  },
  {
    "text": "idea a real solution it took us nine",
    "start": "548160",
    "end": "550720"
  },
  {
    "text": "more months of hard work to stabilize",
    "start": "550720",
    "end": "552480"
  },
  {
    "text": "and scale out the block storage",
    "start": "552480",
    "end": "554480"
  },
  {
    "text": "we introduced two new cortex services",
    "start": "554480",
    "end": "557040"
  },
  {
    "text": "the compactor",
    "start": "557040",
    "end": "558000"
  },
  {
    "text": "and store gateway we added three layers",
    "start": "558000",
    "end": "560560"
  },
  {
    "text": "of caching",
    "start": "560560",
    "end": "561760"
  },
  {
    "text": "index chunks and metadata we implemented",
    "start": "561760",
    "end": "565279"
  },
  {
    "text": "most of the existing cortex features",
    "start": "565279",
    "end": "566959"
  },
  {
    "text": "like rate limits and operational tooling",
    "start": "566959",
    "end": "569200"
  },
  {
    "text": "and we've made many optimizations and",
    "start": "569200",
    "end": "571200"
  },
  {
    "text": "bug fixes",
    "start": "571200",
    "end": "572720"
  },
  {
    "text": "today the cortex block storage is still",
    "start": "572720",
    "end": "574399"
  },
  {
    "text": "marked experimental but at kerfano labs",
    "start": "574399",
    "end": "576640"
  },
  {
    "text": "they're already running it at scale in a",
    "start": "576640",
    "end": "577920"
  },
  {
    "text": "few of their clusters",
    "start": "577920",
    "end": "579040"
  },
  {
    "text": "and we expect to mark this feature as",
    "start": "579040",
    "end": "580560"
  },
  {
    "text": "stable soon",
    "start": "580560",
    "end": "583200"
  },
  {
    "start": "583000",
    "end": "583000"
  },
  {
    "text": "so let me show you the current state the",
    "start": "584320",
    "end": "586880"
  },
  {
    "text": "cortex architecture",
    "start": "586880",
    "end": "588080"
  },
  {
    "text": "doesn't change much between the original",
    "start": "588080",
    "end": "589760"
  },
  {
    "text": "trunk storage which we'll still continue",
    "start": "589760",
    "end": "591680"
  },
  {
    "text": "to support",
    "start": "591680",
    "end": "592480"
  },
  {
    "text": "and the new black storage writes still",
    "start": "592480",
    "end": "594880"
  },
  {
    "text": "are distributed and replicated to",
    "start": "594880",
    "end": "596240"
  },
  {
    "text": "ingestors",
    "start": "596240",
    "end": "597120"
  },
  {
    "text": "and then uploaded to object storage",
    "start": "597120",
    "end": "599200"
  },
  {
    "text": "reads still go through the queries which",
    "start": "599200",
    "end": "600800"
  },
  {
    "text": "read from the ingestors to get recent",
    "start": "600800",
    "end": "602320"
  },
  {
    "text": "metrics",
    "start": "602320",
    "end": "603600"
  },
  {
    "text": "the bigger changes come with two",
    "start": "603600",
    "end": "604959"
  },
  {
    "text": "additions to querying from long-term",
    "start": "604959",
    "end": "606480"
  },
  {
    "text": "storage",
    "start": "606480",
    "end": "607040"
  },
  {
    "text": "we added the store gateway and the",
    "start": "607040",
    "end": "608560"
  },
  {
    "text": "compactor",
    "start": "608560",
    "end": "611120"
  },
  {
    "text": "store gateway is responsible for the",
    "start": "611920",
    "end": "613360"
  },
  {
    "text": "discovery of newly uploaded blocks",
    "start": "613360",
    "end": "615680"
  },
  {
    "text": "it will scan for newly uploaded blocks",
    "start": "615680",
    "end": "617760"
  },
  {
    "text": "and download the index in each block and",
    "start": "617760",
    "end": "619440"
  },
  {
    "text": "cache them locally",
    "start": "619440",
    "end": "620959"
  },
  {
    "text": "with these stored indices it acts as a",
    "start": "620959",
    "end": "622800"
  },
  {
    "text": "queryable interface from long-term",
    "start": "622800",
    "end": "624320"
  },
  {
    "text": "storage",
    "start": "624320",
    "end": "624800"
  },
  {
    "text": "and can fetch query blocks on demand",
    "start": "624800",
    "end": "628480"
  },
  {
    "text": "the compactor is responsible for",
    "start": "629040",
    "end": "630880"
  },
  {
    "text": "reducing the number of blocks in",
    "start": "630880",
    "end": "632160"
  },
  {
    "text": "long-term storage by combining and",
    "start": "632160",
    "end": "633920"
  },
  {
    "text": "de-duplicating blocks",
    "start": "633920",
    "end": "635360"
  },
  {
    "text": "it will periodically scan attendance",
    "start": "635360",
    "end": "637040"
  },
  {
    "text": "prefix and object storage to locate",
    "start": "637040",
    "end": "638800"
  },
  {
    "text": "blocks that are eligible for compaction",
    "start": "638800",
    "end": "641120"
  },
  {
    "text": "using the thanos file name format to",
    "start": "641120",
    "end": "642800"
  },
  {
    "text": "determine overlap",
    "start": "642800",
    "end": "644640"
  },
  {
    "text": "it will download the compaction",
    "start": "644640",
    "end": "645839"
  },
  {
    "text": "candidate blocks and create a new larger",
    "start": "645839",
    "end": "647920"
  },
  {
    "text": "block out of the data",
    "start": "647920",
    "end": "649279"
  },
  {
    "text": "we will then upload that new block and",
    "start": "649279",
    "end": "651040"
  },
  {
    "text": "mark the compacted blocks for deletion",
    "start": "651040",
    "end": "654880"
  },
  {
    "text": "the compactor and store gateway leverage",
    "start": "656560",
    "end": "658480"
  },
  {
    "text": "the same sharding ring code that cortex",
    "start": "658480",
    "end": "660320"
  },
  {
    "text": "and gestures use to distribute tenants",
    "start": "660320",
    "end": "662800"
  },
  {
    "text": "so as their scale increases the number",
    "start": "662800",
    "end": "664560"
  },
  {
    "text": "of tenants they need to perform work on",
    "start": "664560",
    "end": "666240"
  },
  {
    "text": "decreases however at this time there's",
    "start": "666240",
    "end": "668800"
  },
  {
    "text": "still no way to scale compaction for a",
    "start": "668800",
    "end": "670480"
  },
  {
    "text": "single tenant",
    "start": "670480",
    "end": "673120"
  },
  {
    "text": "all of these new courts are new to",
    "start": "673600",
    "end": "675040"
  },
  {
    "text": "cortex but are actually borrowed from",
    "start": "675040",
    "end": "676399"
  },
  {
    "text": "thanos",
    "start": "676399",
    "end": "677200"
  },
  {
    "text": "they have been updated to support",
    "start": "677200",
    "end": "678480"
  },
  {
    "text": "multi-tenancy and sharding for",
    "start": "678480",
    "end": "679920"
  },
  {
    "text": "horizontal scalability",
    "start": "679920",
    "end": "682079"
  },
  {
    "text": "the ingestor shipping to long-term",
    "start": "682079",
    "end": "683440"
  },
  {
    "text": "storage is based on thanos shipper",
    "start": "683440",
    "end": "687040"
  },
  {
    "text": "the store gateway querying blocks from",
    "start": "687040",
    "end": "688959"
  },
  {
    "text": "long-term storage is based on thanos",
    "start": "688959",
    "end": "690560"
  },
  {
    "text": "bucket store",
    "start": "690560",
    "end": "692000"
  },
  {
    "text": "and the compactor is based on thanos",
    "start": "692000",
    "end": "694000"
  },
  {
    "text": "compactor",
    "start": "694000",
    "end": "696480"
  },
  {
    "text": "so here's a closer look at the right",
    "start": "697360",
    "end": "698640"
  },
  {
    "text": "path a given metric is replicated to",
    "start": "698640",
    "end": "700880"
  },
  {
    "text": "multiple ingestors for each user",
    "start": "700880",
    "end": "702959"
  },
  {
    "text": "so you can see here the same metric is",
    "start": "702959",
    "end": "705200"
  },
  {
    "text": "written to three separate blocks and",
    "start": "705200",
    "end": "706720"
  },
  {
    "text": "three separate ingestors",
    "start": "706720",
    "end": "708560"
  },
  {
    "text": "these blocks are written to an",
    "start": "708560",
    "end": "709680"
  },
  {
    "text": "adjuster's local storage every two hours",
    "start": "709680",
    "end": "711839"
  },
  {
    "text": "and a long running process called the",
    "start": "711839",
    "end": "713760"
  },
  {
    "text": "shipper will discover",
    "start": "713760",
    "end": "715200"
  },
  {
    "text": "newly written blocks and upload them to",
    "start": "715200",
    "end": "716959"
  },
  {
    "text": "long-term storage",
    "start": "716959",
    "end": "719760"
  },
  {
    "start": "720000",
    "end": "720000"
  },
  {
    "text": "this poses an interesting scaling",
    "start": "720720",
    "end": "722399"
  },
  {
    "text": "problem in regards to how many blocks",
    "start": "722399",
    "end": "724000"
  },
  {
    "text": "are created",
    "start": "724000",
    "end": "725279"
  },
  {
    "text": "the number of blocks grows quickly with",
    "start": "725279",
    "end": "726959"
  },
  {
    "text": "the number of tenants a cluster has",
    "start": "726959",
    "end": "728800"
  },
  {
    "text": "with a thousand tenants and a small",
    "start": "728800",
    "end": "730240"
  },
  {
    "text": "scale of 50 ingestors we'll be creating",
    "start": "730240",
    "end": "732320"
  },
  {
    "text": "600 000 blocks a day",
    "start": "732320",
    "end": "734079"
  },
  {
    "text": "which equates to 200 million blocks a",
    "start": "734079",
    "end": "736000"
  },
  {
    "text": "year",
    "start": "736000",
    "end": "738240"
  },
  {
    "text": "since we replicate data and ingestors",
    "start": "739040",
    "end": "741040"
  },
  {
    "text": "typically recommended to be",
    "start": "741040",
    "end": "742320"
  },
  {
    "text": "3x the issue is we're storing a large",
    "start": "742320",
    "end": "744959"
  },
  {
    "text": "number of identical metrics",
    "start": "744959",
    "end": "746399"
  },
  {
    "text": "in storage when we really only need to",
    "start": "746399",
    "end": "748079"
  },
  {
    "text": "be storing a single copy of each data",
    "start": "748079",
    "end": "749920"
  },
  {
    "text": "point in storage",
    "start": "749920",
    "end": "752800"
  },
  {
    "text": "the solution is the compactor that was",
    "start": "753600",
    "end": "755600"
  },
  {
    "text": "mentioned earlier",
    "start": "755600",
    "end": "756880"
  },
  {
    "text": "which performs both horizontal",
    "start": "756880",
    "end": "758720"
  },
  {
    "text": "compaction which creates fewer larger",
    "start": "758720",
    "end": "760480"
  },
  {
    "text": "blocks over a greater time period than",
    "start": "760480",
    "end": "762160"
  },
  {
    "text": "just the two hours that was uploaded",
    "start": "762160",
    "end": "764000"
  },
  {
    "text": "as well as vertical compaction which",
    "start": "764000",
    "end": "765839"
  },
  {
    "text": "deduplicates the overlapping blocks",
    "start": "765839",
    "end": "767760"
  },
  {
    "text": "from the ingested replication",
    "start": "767760",
    "end": "772240"
  },
  {
    "text": "this results in one block per day per",
    "start": "772240",
    "end": "774639"
  },
  {
    "text": "tenant",
    "start": "774639",
    "end": "775279"
  },
  {
    "text": "when we originally had 12 times the",
    "start": "775279",
    "end": "777200"
  },
  {
    "text": "number of ingestors pretended",
    "start": "777200",
    "end": "779200"
  },
  {
    "text": "and importantly the compactor can",
    "start": "779200",
    "end": "780720"
  },
  {
    "text": "horizontally scale to support a large",
    "start": "780720",
    "end": "782639"
  },
  {
    "text": "number of tenants",
    "start": "782639",
    "end": "786800"
  },
  {
    "text": "now the previous solution reduces the",
    "start": "786800",
    "end": "788720"
  },
  {
    "text": "footprint after compaction in the object",
    "start": "788720",
    "end": "790399"
  },
  {
    "text": "storage",
    "start": "790399",
    "end": "791440"
  },
  {
    "text": "but we are still shipping one block per",
    "start": "791440",
    "end": "793600"
  },
  {
    "text": "adjuster per tenant",
    "start": "793600",
    "end": "794959"
  },
  {
    "text": "every two hours as well as opening a",
    "start": "794959",
    "end": "796959"
  },
  {
    "text": "tsdb on every ingester for every tenon",
    "start": "796959",
    "end": "799360"
  },
  {
    "text": "which meant the memory footprint did not",
    "start": "799360",
    "end": "800959"
  },
  {
    "text": "scale with the number of nodes",
    "start": "800959",
    "end": "804079"
  },
  {
    "text": "the solution was shuffle sharding where",
    "start": "805040",
    "end": "807120"
  },
  {
    "text": "for any given tenant",
    "start": "807120",
    "end": "808320"
  },
  {
    "text": "that user's blocks would only end up on",
    "start": "808320",
    "end": "810079"
  },
  {
    "text": "a subset of ingestors",
    "start": "810079",
    "end": "812160"
  },
  {
    "text": "so for example tenants may be",
    "start": "812160",
    "end": "814079"
  },
  {
    "text": "shuffle-sharded to foreign gestures",
    "start": "814079",
    "end": "816079"
  },
  {
    "text": "so for every user only four blocks per",
    "start": "816079",
    "end": "818079"
  },
  {
    "text": "tenant per two hours",
    "start": "818079",
    "end": "819360"
  },
  {
    "text": "are uploaded to object storage and each",
    "start": "819360",
    "end": "821760"
  },
  {
    "text": "tenant uses a static amount of memory",
    "start": "821760",
    "end": "823440"
  },
  {
    "text": "overhead for the tstbs",
    "start": "823440",
    "end": "825680"
  },
  {
    "text": "this also has the benefit that the",
    "start": "825680",
    "end": "827199"
  },
  {
    "text": "compactor no longer needs to perform as",
    "start": "827199",
    "end": "829360"
  },
  {
    "text": "much work compacting blocks",
    "start": "829360",
    "end": "830959"
  },
  {
    "text": "as we've reduced the number of blocks",
    "start": "830959",
    "end": "832399"
  },
  {
    "text": "that are uploaded",
    "start": "832399",
    "end": "835040"
  },
  {
    "start": "835000",
    "end": "835000"
  },
  {
    "text": "here's an example of write performance",
    "start": "836160",
    "end": "837760"
  },
  {
    "text": "courtesy of grafana labs in the",
    "start": "837760",
    "end": "839120"
  },
  {
    "text": "environment they're running",
    "start": "839120",
    "end": "840639"
  },
  {
    "text": "we can see there's still a very low 99th",
    "start": "840639",
    "end": "842800"
  },
  {
    "text": "percentile latencies with two and a half",
    "start": "842800",
    "end": "844800"
  },
  {
    "text": "million samples per second ingested",
    "start": "844800",
    "end": "848800"
  },
  {
    "text": "so we have seen that we can",
    "start": "849920",
    "end": "853199"
  },
  {
    "text": "efficiently he ingests a large amount of",
    "start": "853199",
    "end": "856320"
  },
  {
    "text": "samples per second with a pretty low",
    "start": "856320",
    "end": "858079"
  },
  {
    "text": "latency",
    "start": "858079",
    "end": "859040"
  },
  {
    "text": "but the real question is how do we query",
    "start": "859040",
    "end": "861680"
  },
  {
    "text": "back this data",
    "start": "861680",
    "end": "863199"
  },
  {
    "text": "um one in one of our clusters we are",
    "start": "863199",
    "end": "866000"
  },
  {
    "text": "running at grifon labs",
    "start": "866000",
    "end": "867680"
  },
  {
    "text": "we have a tenant with 30 million active",
    "start": "867680",
    "end": "870880"
  },
  {
    "text": "series running on the block storage",
    "start": "870880",
    "end": "873120"
  },
  {
    "text": "um which means that we store",
    "start": "873120",
    "end": "876160"
  },
  {
    "text": "about 200 gigabyte of blocks per day",
    "start": "876160",
    "end": "879440"
  },
  {
    "text": "after compaction if you project this",
    "start": "879440",
    "end": "882480"
  },
  {
    "text": "uh to one ear retention it means that",
    "start": "882480",
    "end": "886240"
  },
  {
    "text": "we need to be ready to query back this",
    "start": "886240",
    "end": "888399"
  },
  {
    "text": "data",
    "start": "888399",
    "end": "889279"
  },
  {
    "text": "about across a storage of about 70",
    "start": "889279",
    "end": "892320"
  },
  {
    "text": "terabytes",
    "start": "892320",
    "end": "894480"
  },
  {
    "text": "uh to understand how the the read path",
    "start": "894480",
    "end": "897199"
  },
  {
    "start": "896000",
    "end": "896000"
  },
  {
    "text": "work",
    "start": "897199",
    "end": "897839"
  },
  {
    "text": "for the block storage uh we have to do a",
    "start": "897839",
    "end": "899760"
  },
  {
    "text": "little step back",
    "start": "899760",
    "end": "901440"
  },
  {
    "text": "and focusing on the query front-end",
    "start": "901440",
    "end": "903360"
  },
  {
    "text": "which is the ingress",
    "start": "903360",
    "end": "905199"
  },
  {
    "text": "on the read path now as previously",
    "start": "905199",
    "end": "907839"
  },
  {
    "text": "mentioned",
    "start": "907839",
    "end": "908800"
  },
  {
    "text": "the query frontend provide two main",
    "start": "908800",
    "end": "911360"
  },
  {
    "text": "features",
    "start": "911360",
    "end": "912160"
  },
  {
    "text": "query execution parallelization and",
    "start": "912160",
    "end": "914560"
  },
  {
    "text": "result caching",
    "start": "914560",
    "end": "916639"
  },
  {
    "text": "the basic form of the query execution",
    "start": "916639",
    "end": "919920"
  },
  {
    "text": "parallelization",
    "start": "919920",
    "end": "921360"
  },
  {
    "text": "is based on time splitting",
    "start": "921360",
    "end": "924639"
  },
  {
    "text": "when the query frontend receive a query",
    "start": "924639",
    "end": "928240"
  },
  {
    "text": "spanning over a large time range a time",
    "start": "928240",
    "end": "931360"
  },
  {
    "text": "range which cover",
    "start": "931360",
    "end": "932399"
  },
  {
    "text": "more than one day the query frontend",
    "start": "932399",
    "end": "935120"
  },
  {
    "text": "split",
    "start": "935120",
    "end": "936079"
  },
  {
    "text": "this query into multiple queries each",
    "start": "936079",
    "end": "940160"
  },
  {
    "text": "one",
    "start": "940160",
    "end": "940560"
  },
  {
    "text": "covering one single day",
    "start": "940560",
    "end": "943680"
  },
  {
    "text": "aligning the timestamp of the splitted",
    "start": "943680",
    "end": "945680"
  },
  {
    "text": "query to midnight utc",
    "start": "945680",
    "end": "948160"
  },
  {
    "text": "so if we receive a query spanning over",
    "start": "948160",
    "end": "951360"
  },
  {
    "text": "the last three days this query will be",
    "start": "951360",
    "end": "954480"
  },
  {
    "text": "actually executed will be actually split",
    "start": "954480",
    "end": "957680"
  },
  {
    "text": "into three different queries each query",
    "start": "957680",
    "end": "960240"
  },
  {
    "text": "will cover a different day",
    "start": "960240",
    "end": "962079"
  },
  {
    "text": "and there's three splitted queries will",
    "start": "962079",
    "end": "964560"
  },
  {
    "text": "be executed concurrently",
    "start": "964560",
    "end": "966399"
  },
  {
    "text": "by the queries and their results will be",
    "start": "966399",
    "end": "969600"
  },
  {
    "text": "then",
    "start": "969600",
    "end": "970000"
  },
  {
    "text": "merged by the query frontend before",
    "start": "970000",
    "end": "972079"
  },
  {
    "text": "sending back the response to grafana",
    "start": "972079",
    "end": "974160"
  },
  {
    "text": "or your quilling tool",
    "start": "974160",
    "end": "977360"
  },
  {
    "text": "now this means that in most of the cases",
    "start": "978240",
    "end": "982079"
  },
  {
    "text": "internally a single query executed by",
    "start": "982079",
    "end": "984800"
  },
  {
    "text": "the query",
    "start": "984800",
    "end": "985519"
  },
  {
    "text": "will cover only one day and that's the",
    "start": "985519",
    "end": "988320"
  },
  {
    "text": "primary reason",
    "start": "988320",
    "end": "989600"
  },
  {
    "text": "why by default we compact blocks up to",
    "start": "989600",
    "end": "993120"
  },
  {
    "text": "one day period and doing",
    "start": "993120",
    "end": "996639"
  },
  {
    "text": "tests uh in our clusters we have seen",
    "start": "996639",
    "end": "1000160"
  },
  {
    "text": "that",
    "start": "1000160",
    "end": "1000800"
  },
  {
    "text": "this allows for a better parallelization",
    "start": "1000800",
    "end": "1003839"
  },
  {
    "text": "when you run queries over a large time",
    "start": "1003839",
    "end": "1008480"
  },
  {
    "text": "range",
    "start": "1008839",
    "end": "1010079"
  },
  {
    "start": "1009000",
    "end": "1009000"
  },
  {
    "text": "the querier then execute this",
    "start": "1010079",
    "end": "1013440"
  },
  {
    "text": "one day query now the query",
    "start": "1013440",
    "end": "1017759"
  },
  {
    "text": "periodically discover new blocks",
    "start": "1017759",
    "end": "1020560"
  },
  {
    "text": "uploaded to the storage",
    "start": "1020560",
    "end": "1022079"
  },
  {
    "text": "running a scan over the bucket and it",
    "start": "1022079",
    "end": "1024959"
  },
  {
    "text": "keeps in memory a map",
    "start": "1024959",
    "end": "1026480"
  },
  {
    "text": "of all the known blocks in the storage",
    "start": "1026480",
    "end": "1028880"
  },
  {
    "text": "for each block",
    "start": "1028880",
    "end": "1029839"
  },
  {
    "text": "we just need few information which is",
    "start": "1029839",
    "end": "1031918"
  },
  {
    "text": "the tenant id",
    "start": "1031919",
    "end": "1033438"
  },
  {
    "text": "the block id and the minimum and maximum",
    "start": "1033439",
    "end": "1036480"
  },
  {
    "text": "timestamp of samples within the specific",
    "start": "1036480",
    "end": "1039199"
  },
  {
    "text": "block",
    "start": "1039199",
    "end": "1040319"
  },
  {
    "text": "and then when the query receive a query",
    "start": "1040319",
    "end": "1043280"
  },
  {
    "text": "it look for",
    "start": "1043280",
    "end": "1044160"
  },
  {
    "text": "all the block ids containing at least",
    "start": "1044160",
    "end": "1046558"
  },
  {
    "text": "one sample",
    "start": "1046559",
    "end": "1047760"
  },
  {
    "text": "within the query start and end time",
    "start": "1047760",
    "end": "1051200"
  },
  {
    "text": "and based on the filtered block ideas",
    "start": "1051200",
    "end": "1054880"
  },
  {
    "text": "it computes the set of store gateways",
    "start": "1054880",
    "end": "1057919"
  },
  {
    "text": "that should be queried",
    "start": "1057919",
    "end": "1059200"
  },
  {
    "text": "in order to query back the data from",
    "start": "1059200",
    "end": "1061360"
  },
  {
    "text": "desk blocks",
    "start": "1061360",
    "end": "1063440"
  },
  {
    "text": "the query will fetch the most recent",
    "start": "1063440",
    "end": "1065840"
  },
  {
    "text": "data which has not been flushed to the",
    "start": "1065840",
    "end": "1067760"
  },
  {
    "text": "storage yet from the ingestors",
    "start": "1067760",
    "end": "1069679"
  },
  {
    "text": "and we will query the blocks stored",
    "start": "1069679",
    "end": "1072960"
  },
  {
    "text": "in the object store through the store",
    "start": "1072960",
    "end": "1075039"
  },
  {
    "text": "gateways",
    "start": "1075039",
    "end": "1077519"
  },
  {
    "text": "blocks are sharded and optionally",
    "start": "1078480",
    "end": "1081760"
  },
  {
    "text": "replicated",
    "start": "1081760",
    "end": "1082720"
  },
  {
    "text": "across the store gateways this means",
    "start": "1082720",
    "end": "1086080"
  },
  {
    "text": "that",
    "start": "1086080",
    "end": "1086720"
  },
  {
    "text": "we can horizontally shard the blocks",
    "start": "1086720",
    "end": "1089919"
  },
  {
    "text": "across the pool of store gateways and",
    "start": "1089919",
    "end": "1092400"
  },
  {
    "text": "for each block",
    "start": "1092400",
    "end": "1093520"
  },
  {
    "text": "belonging to the chart of one specific",
    "start": "1093520",
    "end": "1096000"
  },
  {
    "text": "store gateway",
    "start": "1096000",
    "end": "1097280"
  },
  {
    "text": "the store gateway loads the index editor",
    "start": "1097280",
    "end": "1100559"
  },
  {
    "text": "the index adder is a small subset of the",
    "start": "1100559",
    "end": "1103760"
  },
  {
    "text": "entire block indexer in in our clusters",
    "start": "1103760",
    "end": "1107039"
  },
  {
    "text": "we see that the index editor is in the",
    "start": "1107039",
    "end": "1108799"
  },
  {
    "text": "order of two percent of the index so",
    "start": "1108799",
    "end": "1110640"
  },
  {
    "text": "it's a",
    "start": "1110640",
    "end": "1111280"
  },
  {
    "text": "little part of the index",
    "start": "1111280",
    "end": "1114799"
  },
  {
    "text": "and it's used to speed up um",
    "start": "1114799",
    "end": "1117919"
  },
  {
    "text": "the index lookup at query time",
    "start": "1117919",
    "end": "1123520"
  },
  {
    "text": "the query query the blocks through",
    "start": "1123520",
    "end": "1126720"
  },
  {
    "text": "the minimum set of store gateways",
    "start": "1126720",
    "end": "1129600"
  },
  {
    "text": "holding the required blocks",
    "start": "1129600",
    "end": "1131280"
  },
  {
    "text": "so when the query receive a query the",
    "start": "1131280",
    "end": "1133520"
  },
  {
    "text": "query computer",
    "start": "1133520",
    "end": "1134799"
  },
  {
    "text": "the list of block ideas which should be",
    "start": "1134799",
    "end": "1137440"
  },
  {
    "text": "queried",
    "start": "1137440",
    "end": "1138640"
  },
  {
    "text": "and then look up the ash ring which we",
    "start": "1138640",
    "end": "1141600"
  },
  {
    "text": "use",
    "start": "1141600",
    "end": "1143120"
  },
  {
    "text": "to as the baseline technology to",
    "start": "1143120",
    "end": "1146480"
  },
  {
    "text": "implement the sharding and the",
    "start": "1146480",
    "end": "1147840"
  },
  {
    "text": "replication to find",
    "start": "1147840",
    "end": "1150000"
  },
  {
    "text": "the minimum set of store gateways",
    "start": "1150000",
    "end": "1151919"
  },
  {
    "text": "holding",
    "start": "1151919",
    "end": "1153039"
  },
  {
    "text": "the blocks that needs to be queried",
    "start": "1153039",
    "end": "1156640"
  },
  {
    "text": "and concurrently query does blocks",
    "start": "1156640",
    "end": "1159600"
  },
  {
    "text": "through the store gateways",
    "start": "1159600",
    "end": "1162080"
  },
  {
    "text": "if we look inside a single store gateway",
    "start": "1162080",
    "end": "1165440"
  },
  {
    "text": "the store gateway always download the",
    "start": "1165440",
    "end": "1168240"
  },
  {
    "text": "fully download to the local disk",
    "start": "1168240",
    "end": "1170480"
  },
  {
    "text": "and then hem up in memory the index",
    "start": "1170480",
    "end": "1174000"
  },
  {
    "text": "setter",
    "start": "1174000",
    "end": "1174480"
  },
  {
    "text": "of each block belonging",
    "start": "1174480",
    "end": "1177520"
  },
  {
    "text": "to the shard of the specific store",
    "start": "1177520",
    "end": "1179520"
  },
  {
    "text": "gateway but the entire index",
    "start": "1179520",
    "end": "1182080"
  },
  {
    "text": "or the chunks files which are even",
    "start": "1182080",
    "end": "1184080"
  },
  {
    "text": "bigger have never",
    "start": "1184080",
    "end": "1185520"
  },
  {
    "text": "entirely downloaded to the to the store",
    "start": "1185520",
    "end": "1188640"
  },
  {
    "text": "gateway",
    "start": "1188640",
    "end": "1190400"
  },
  {
    "text": "how the system work which has been",
    "start": "1190400",
    "end": "1192320"
  },
  {
    "text": "inherited by thanos",
    "start": "1192320",
    "end": "1193919"
  },
  {
    "text": "is that uh the full index and the chunks",
    "start": "1193919",
    "end": "1197280"
  },
  {
    "text": "are lazily fetched at query time uh",
    "start": "1197280",
    "end": "1200480"
  },
  {
    "text": "through multiple get byte range request",
    "start": "1200480",
    "end": "1203440"
  },
  {
    "text": "so we",
    "start": "1203440",
    "end": "1204240"
  },
  {
    "text": "load the minimum data as possible",
    "start": "1204240",
    "end": "1208159"
  },
  {
    "text": "when we add query time if we look",
    "start": "1208159",
    "end": "1211520"
  },
  {
    "text": "at a single query received in the store",
    "start": "1211520",
    "end": "1214640"
  },
  {
    "text": "gateway",
    "start": "1214640",
    "end": "1215360"
  },
  {
    "text": "the typical query contain four",
    "start": "1215360",
    "end": "1217120"
  },
  {
    "text": "information",
    "start": "1217120",
    "end": "1218480"
  },
  {
    "text": "the setup series label matches",
    "start": "1218480",
    "end": "1222159"
  },
  {
    "text": "for which the samples should be fetched",
    "start": "1222159",
    "end": "1225120"
  },
  {
    "text": "a start",
    "start": "1225120",
    "end": "1226159"
  },
  {
    "text": "and an end timestamp and the list of",
    "start": "1226159",
    "end": "1228960"
  },
  {
    "text": "block ids",
    "start": "1228960",
    "end": "1230080"
  },
  {
    "text": "which has been previously computed by",
    "start": "1230080",
    "end": "1231919"
  },
  {
    "text": "the query",
    "start": "1231919",
    "end": "1233600"
  },
  {
    "text": "and then the store gateway will run a",
    "start": "1233600",
    "end": "1236080"
  },
  {
    "text": "local lookup",
    "start": "1236080",
    "end": "1237360"
  },
  {
    "text": "on the symbols and posting of the table",
    "start": "1237360",
    "end": "1240159"
  },
  {
    "text": "which are",
    "start": "1240159",
    "end": "1240720"
  },
  {
    "text": "done through the previously downloaded",
    "start": "1240720",
    "end": "1242960"
  },
  {
    "text": "index editor",
    "start": "1242960",
    "end": "1244799"
  },
  {
    "text": "and the result of this lookup is",
    "start": "1244799",
    "end": "1248159"
  },
  {
    "text": "actually the input for the",
    "start": "1248159",
    "end": "1249600"
  },
  {
    "text": "remote lookup and so the store gateway",
    "start": "1249600",
    "end": "1253039"
  },
  {
    "text": "will fetch the postings and the series",
    "start": "1253039",
    "end": "1255440"
  },
  {
    "text": "and then from there",
    "start": "1255440",
    "end": "1256880"
  },
  {
    "text": "the chunks which are the segments of",
    "start": "1256880",
    "end": "1259840"
  },
  {
    "text": "compressed",
    "start": "1259840",
    "end": "1260559"
  },
  {
    "text": "timestamp value person of the samples",
    "start": "1260559",
    "end": "1262880"
  },
  {
    "text": "for the matching series",
    "start": "1262880",
    "end": "1265039"
  },
  {
    "text": "this remote lookup is done through get",
    "start": "1265039",
    "end": "1267679"
  },
  {
    "text": "byte range request",
    "start": "1267679",
    "end": "1270240"
  },
  {
    "text": "now we actually want to",
    "start": "1270240",
    "end": "1273919"
  },
  {
    "text": "lower as much as possible the calls to",
    "start": "1273919",
    "end": "1276960"
  },
  {
    "text": "the",
    "start": "1276960",
    "end": "1277360"
  },
  {
    "text": "object store both because of performance",
    "start": "1277360",
    "end": "1280720"
  },
  {
    "text": "reasons",
    "start": "1280720",
    "end": "1281440"
  },
  {
    "text": "and also because of costs given",
    "start": "1281440",
    "end": "1285039"
  },
  {
    "text": "most of the object store pricing",
    "start": "1285039",
    "end": "1288640"
  },
  {
    "text": "is based on a mix of data stored",
    "start": "1288640",
    "end": "1291679"
  },
  {
    "text": "in terms of gigabyte and number of api",
    "start": "1291679",
    "end": "1295280"
  },
  {
    "text": "calls you run",
    "start": "1295280",
    "end": "1296720"
  },
  {
    "text": "and we have introduced uh three layers",
    "start": "1296720",
    "end": "1299840"
  },
  {
    "text": "of caching the metadata cache the index",
    "start": "1299840",
    "end": "1302000"
  },
  {
    "text": "cache and the chunks cache",
    "start": "1302000",
    "end": "1304000"
  },
  {
    "text": "the metadata cache is used by the",
    "start": "1304000",
    "end": "1307520"
  },
  {
    "text": "blocks discovery mechanism which is",
    "start": "1307520",
    "end": "1309840"
  },
  {
    "text": "running both",
    "start": "1309840",
    "end": "1310880"
  },
  {
    "text": "inside the query and the store gateway",
    "start": "1310880",
    "end": "1314240"
  },
  {
    "text": "while the index cache and the chunks",
    "start": "1314240",
    "end": "1315919"
  },
  {
    "text": "cache is only used by the store gateway",
    "start": "1315919",
    "end": "1318720"
  },
  {
    "text": "the index cache is a caching layer in",
    "start": "1318720",
    "end": "1321039"
  },
  {
    "text": "front of the",
    "start": "1321039",
    "end": "1321840"
  },
  {
    "text": "posting and serious lookup and the",
    "start": "1321840",
    "end": "1324159"
  },
  {
    "text": "chunks cache",
    "start": "1324159",
    "end": "1325360"
  },
  {
    "text": "is a cache in front of",
    "start": "1325360",
    "end": "1329760"
  },
  {
    "text": "the fetching of the chunks containing",
    "start": "1329760",
    "end": "1332400"
  },
  {
    "text": "the",
    "start": "1332400",
    "end": "1332880"
  },
  {
    "text": "compressed samples since the chunks",
    "start": "1332880",
    "end": "1335520"
  },
  {
    "text": "files",
    "start": "1335520",
    "end": "1336240"
  },
  {
    "text": "are up to 512 megabytes each",
    "start": "1336240",
    "end": "1339280"
  },
  {
    "text": "we don't nev we never download we never",
    "start": "1339280",
    "end": "1341840"
  },
  {
    "text": "fully download",
    "start": "1341840",
    "end": "1343280"
  },
  {
    "text": "the entire object or the entire file and",
    "start": "1343280",
    "end": "1346000"
  },
  {
    "text": "we never fully cache",
    "start": "1346000",
    "end": "1347440"
  },
  {
    "text": "uh a single entry with 1 512 megabyte",
    "start": "1347440",
    "end": "1352240"
  },
  {
    "text": "but what we do is we do a sub-object",
    "start": "1352240",
    "end": "1355440"
  },
  {
    "text": "caching",
    "start": "1355440",
    "end": "1356400"
  },
  {
    "text": "uh aligning the offset to 16 kilobyte",
    "start": "1356400",
    "end": "1361760"
  },
  {
    "text": "caching is not mandatory",
    "start": "1361760",
    "end": "1365200"
  },
  {
    "text": "so it's an optional component but it's",
    "start": "1365200",
    "end": "1367919"
  },
  {
    "text": "recommended in production",
    "start": "1367919",
    "end": "1370480"
  },
  {
    "text": "last but not least we have done",
    "start": "1370480",
    "end": "1373600"
  },
  {
    "text": "this work as a necessity we had in",
    "start": "1373600",
    "end": "1377200"
  },
  {
    "text": "cortex but we",
    "start": "1377200",
    "end": "1378480"
  },
  {
    "text": "back ported all those improvements to",
    "start": "1378480",
    "end": "1380720"
  },
  {
    "text": "thanos as well",
    "start": "1380720",
    "end": "1383440"
  },
  {
    "start": "1384000",
    "end": "1384000"
  },
  {
    "text": "at grafana labs we are currently running",
    "start": "1384720",
    "end": "1387280"
  },
  {
    "text": "a",
    "start": "1387280",
    "end": "1388000"
  },
  {
    "text": "few clusters and in one of test clusters",
    "start": "1388000",
    "end": "1391760"
  },
  {
    "text": "which is a staging cluster we have",
    "start": "1391760",
    "end": "1395120"
  },
  {
    "text": "done we have done an atypical setup",
    "start": "1395120",
    "end": "1399280"
  },
  {
    "text": "so we are running two identical clusters",
    "start": "1399280",
    "end": "1402080"
  },
  {
    "text": "since few months",
    "start": "1402080",
    "end": "1403679"
  },
  {
    "text": "by identical i mean identical in terms",
    "start": "1403679",
    "end": "1406240"
  },
  {
    "text": "of",
    "start": "1406240",
    "end": "1407200"
  },
  {
    "text": "version of cortex that we run and",
    "start": "1407200",
    "end": "1410640"
  },
  {
    "text": "scale same number of",
    "start": "1410640",
    "end": "1413679"
  },
  {
    "text": "cortex nodes ingesting the same exact",
    "start": "1413679",
    "end": "1416720"
  },
  {
    "text": "series",
    "start": "1416720",
    "end": "1417280"
  },
  {
    "text": "roughly 10 mega 10 million active series",
    "start": "1417280",
    "end": "1421440"
  },
  {
    "text": "and then we have introduced a proxy",
    "start": "1421440",
    "end": "1425600"
  },
  {
    "text": "uh which is called query t and we open",
    "start": "1425600",
    "end": "1427840"
  },
  {
    "text": "source as well",
    "start": "1427840",
    "end": "1429200"
  },
  {
    "text": "which mirror every single query we do",
    "start": "1429200",
    "end": "1431440"
  },
  {
    "text": "receive to both clusters",
    "start": "1431440",
    "end": "1433520"
  },
  {
    "text": "and we make the two backend clusters one",
    "start": "1433520",
    "end": "1436240"
  },
  {
    "text": "running the block storage",
    "start": "1436240",
    "end": "1437600"
  },
  {
    "text": "and another one running the chunk",
    "start": "1437600",
    "end": "1439200"
  },
  {
    "text": "storage compete in terms of performances",
    "start": "1439200",
    "end": "1443520"
  },
  {
    "text": "what we have seen uh is that the block",
    "start": "1443520",
    "end": "1445919"
  },
  {
    "text": "storage performances",
    "start": "1445919",
    "end": "1447120"
  },
  {
    "text": "are pretty good and comparable with the",
    "start": "1447120",
    "end": "1449679"
  },
  {
    "text": "chunk storage",
    "start": "1449679",
    "end": "1450799"
  },
  {
    "text": "for most of the use cases",
    "start": "1450799",
    "end": "1454080"
  },
  {
    "text": "we still have some spikes in the p99",
    "start": "1454080",
    "end": "1458159"
  },
  {
    "text": "in the block storage mainly due",
    "start": "1458159",
    "end": "1461440"
  },
  {
    "text": "to cold cold caches",
    "start": "1461440",
    "end": "1464880"
  },
  {
    "text": "but the the progress we have made",
    "start": "1464880",
    "end": "1468400"
  },
  {
    "text": "and measured this way over the past",
    "start": "1468400",
    "end": "1471760"
  },
  {
    "text": "few months is pretty good and",
    "start": "1471760",
    "end": "1474880"
  },
  {
    "text": "i personally believe we are on a good",
    "start": "1474880",
    "end": "1477039"
  },
  {
    "text": "track",
    "start": "1477039",
    "end": "1478000"
  },
  {
    "text": "to run the block storage with comparable",
    "start": "1478000",
    "end": "1480559"
  },
  {
    "text": "performances",
    "start": "1480559",
    "end": "1481840"
  },
  {
    "text": "compared to the to the chunk storage now",
    "start": "1481840",
    "end": "1486080"
  },
  {
    "start": "1486000",
    "end": "1486000"
  },
  {
    "text": "the question here is",
    "start": "1486080",
    "end": "1487200"
  },
  {
    "text": "what's next um so if you if you're",
    "start": "1487200",
    "end": "1490400"
  },
  {
    "text": "running",
    "start": "1490400",
    "end": "1490960"
  },
  {
    "text": "the block storage the experimental block",
    "start": "1490960",
    "end": "1492799"
  },
  {
    "text": "storage today um",
    "start": "1492799",
    "end": "1494559"
  },
  {
    "text": "or you are interested into giving it a",
    "start": "1494559",
    "end": "1496799"
  },
  {
    "text": "try",
    "start": "1496799",
    "end": "1497679"
  },
  {
    "text": "please be aware we are very close to",
    "start": "1497679",
    "end": "1500640"
  },
  {
    "text": "market stable",
    "start": "1500640",
    "end": "1501760"
  },
  {
    "text": "um it's something we expect will happen",
    "start": "1501760",
    "end": "1504799"
  },
  {
    "text": "uh this quarter",
    "start": "1504799",
    "end": "1507760"
  },
  {
    "text": "we are currently working on many things",
    "start": "1507840",
    "end": "1510960"
  },
  {
    "text": "but to mention um the",
    "start": "1510960",
    "end": "1514159"
  },
  {
    "text": "most important probably we are",
    "start": "1514159",
    "end": "1516400"
  },
  {
    "text": "continuously working to",
    "start": "1516400",
    "end": "1518080"
  },
  {
    "text": "improve the query performances this is",
    "start": "1518080",
    "end": "1520400"
  },
  {
    "text": "an endless work",
    "start": "1520400",
    "end": "1521679"
  },
  {
    "text": "um and we are doing many high iterations",
    "start": "1521679",
    "end": "1525039"
  },
  {
    "text": "over it",
    "start": "1525039",
    "end": "1525679"
  },
  {
    "text": "we have several ideas we still want to",
    "start": "1525679",
    "end": "1528480"
  },
  {
    "text": "to experiment",
    "start": "1528480",
    "end": "1529679"
  },
  {
    "text": "and that they may lend into upstream",
    "start": "1529679",
    "end": "1532880"
  },
  {
    "text": "changes",
    "start": "1532880",
    "end": "1534559"
  },
  {
    "text": "but yeah keep in mind we are spending a",
    "start": "1534559",
    "end": "1537440"
  },
  {
    "text": "lot of time",
    "start": "1537440",
    "end": "1538240"
  },
  {
    "text": "on continuously improving performances",
    "start": "1538240",
    "end": "1542960"
  },
  {
    "text": "we also want to productionize the",
    "start": "1542960",
    "end": "1545200"
  },
  {
    "text": "shuffle shutting",
    "start": "1545200",
    "end": "1547039"
  },
  {
    "text": "and basically we want to be able to",
    "start": "1547039",
    "end": "1549760"
  },
  {
    "text": "scale",
    "start": "1549760",
    "end": "1550400"
  },
  {
    "text": "a cortex cluster to",
    "start": "1550400",
    "end": "1553679"
  },
  {
    "text": "any size of tenants under tenants",
    "start": "1553679",
    "end": "1557279"
  },
  {
    "text": "thousand tenants tens thousand tenants",
    "start": "1557279",
    "end": "1561440"
  },
  {
    "text": "and we believe that shuffle sharding is",
    "start": "1561440",
    "end": "1564400"
  },
  {
    "text": "the way to go",
    "start": "1564400",
    "end": "1565360"
  },
  {
    "text": "in this direction and also in the thanos",
    "start": "1565360",
    "end": "1568320"
  },
  {
    "text": "community",
    "start": "1568320",
    "end": "1569840"
  },
  {
    "text": "we recently started the work to",
    "start": "1569840",
    "end": "1572559"
  },
  {
    "text": "introduce the support for deletions",
    "start": "1572559",
    "end": "1575200"
  },
  {
    "text": "being able to selectively delete",
    "start": "1575200",
    "end": "1579760"
  },
  {
    "text": "serious and time series data from thanos",
    "start": "1579760",
    "end": "1584400"
  },
  {
    "text": "we are very interested uh in deletions",
    "start": "1584400",
    "end": "1587679"
  },
  {
    "text": "as well",
    "start": "1587679",
    "end": "1588159"
  },
  {
    "text": "uh in the cortex community and",
    "start": "1588159",
    "end": "1591360"
  },
  {
    "text": "we will work closely uh with the thanos",
    "start": "1591360",
    "end": "1593600"
  },
  {
    "text": "community to make it happen",
    "start": "1593600",
    "end": "1595039"
  },
  {
    "text": "and introduce the support for deletions",
    "start": "1595039",
    "end": "1597919"
  },
  {
    "text": "in the cortex block storage as well",
    "start": "1597919",
    "end": "1601440"
  },
  {
    "text": "so thank you very much for joining this",
    "start": "1602400",
    "end": "1605120"
  },
  {
    "text": "talk",
    "start": "1605120",
    "end": "1606799"
  },
  {
    "text": "now there will be a qa session but",
    "start": "1606799",
    "end": "1609919"
  },
  {
    "text": "please",
    "start": "1609919",
    "end": "1610400"
  },
  {
    "text": "don't forget to check out the cncf",
    "start": "1610400",
    "end": "1612320"
  },
  {
    "text": "schedule",
    "start": "1612320",
    "end": "1613520"
  },
  {
    "text": "there are a couple of cortex rooms",
    "start": "1613520",
    "end": "1616799"
  },
  {
    "text": "and booth hours",
    "start": "1616799",
    "end": "1620000"
  },
  {
    "text": "so please check out the schedule and",
    "start": "1620000",
    "end": "1622080"
  },
  {
    "text": "join us if you have",
    "start": "1622080",
    "end": "1623360"
  },
  {
    "text": "any questions",
    "start": "1623360",
    "end": "1627039"
  }
]
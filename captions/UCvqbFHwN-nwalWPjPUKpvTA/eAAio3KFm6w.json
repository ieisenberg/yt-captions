[
  {
    "start": "0",
    "end": "45000"
  },
  {
    "text": "today we're going to talk about uh resource efficiency in the context of",
    "start": "80",
    "end": "6080"
  },
  {
    "text": "allocation in a kubernetes cluster hi my name is vincent saval i'm working for a company called lombardier i'm an",
    "start": "6080",
    "end": "13360"
  },
  {
    "text": "architect i'm i'm involved in a cross-unit team called platform ops which aims at",
    "start": "13360",
    "end": "20240"
  },
  {
    "text": "delivering uh the platform as a product and in that context i'm involved in different uh projects",
    "start": "20240",
    "end": "27279"
  },
  {
    "text": "uh i've been involved in openshift for quite some time now and specifically deployment on openshift and lately i've",
    "start": "27279",
    "end": "34559"
  },
  {
    "text": "been involved in uh um our deployment of kafka on the openshift platform plus the",
    "start": "34559",
    "end": "40480"
  },
  {
    "text": "uh the corpus application framework all right so lombardia is a private bank",
    "start": "40480",
    "end": "46480"
  },
  {
    "start": "45000",
    "end": "45000"
  },
  {
    "text": "based in switzerland and uh we've got the traditional lines of businesses that",
    "start": "46480",
    "end": "51680"
  },
  {
    "text": "you would expect and plus something that we call technology for banking",
    "start": "51680",
    "end": "56800"
  },
  {
    "text": "what we're doing is that we develop internally our own car banking system",
    "start": "56800",
    "end": "62160"
  },
  {
    "text": "which we make available to the bank itself obviously but to other external",
    "start": "62160",
    "end": "68159"
  },
  {
    "text": "uh then in that context we represent our code banking system so that we can",
    "start": "68159",
    "end": "74320"
  },
  {
    "text": "operate uh their activity from our data centers based in in",
    "start": "74320",
    "end": "79600"
  },
  {
    "text": "switzerland uh so we have uh four i mean traditional",
    "start": "79600",
    "end": "86080"
  },
  {
    "start": "82000",
    "end": "82000"
  },
  {
    "text": "functional development streams uh and a very modular uh architecture that was started 25 years",
    "start": "86080",
    "end": "93119"
  },
  {
    "text": "ago uh with many technology uh the last 15 years we",
    "start": "93119",
    "end": "98560"
  },
  {
    "text": "invested a lot on on java but that's not the indian the only technology and uh",
    "start": "98560",
    "end": "105439"
  },
  {
    "text": "we've got a lot of flexibility in our system",
    "start": "105439",
    "end": "110479"
  },
  {
    "text": "thanks to this to this architecture but a few challenges as well all right in 2020 we started a large",
    "start": "110479",
    "end": "117920"
  },
  {
    "text": "modernization initiative called gx where we're looking at the functional",
    "start": "117920",
    "end": "124159"
  },
  {
    "text": "side but also at the technical side and we started introducing new technology openshift being one of the first one",
    "start": "124159",
    "end": "132319"
  },
  {
    "text": "so the story uh starts probably a year and a half ago",
    "start": "132319",
    "end": "137599"
  },
  {
    "text": "when we were starting to ramp up our workload on our kubernetes cluster and",
    "start": "137599",
    "end": "143280"
  },
  {
    "text": "we started seeing this kind of message uh a little bit",
    "start": "143280",
    "end": "149520"
  },
  {
    "text": "too often um then well basically there were two reasons for this uh the first reason is the was",
    "start": "149520",
    "end": "156480"
  },
  {
    "text": "the uh the the cluster we were using was pretty small uh and the the workload was starting to",
    "start": "156480",
    "end": "163519"
  },
  {
    "text": "pile up but the other reason was we did not have a good understanding",
    "start": "163519",
    "end": "169280"
  },
  {
    "text": "about how resource allocation works inside the kubernetes cluster so um for",
    "start": "169280",
    "end": "174800"
  },
  {
    "text": "some time we try to solve that with extra capacity that we were adding to the cluster",
    "start": "174800",
    "end": "180560"
  },
  {
    "text": "but that that didn't get us very far eventually we are actually to i mean handle the handle the problem",
    "start": "180560",
    "end": "188720"
  },
  {
    "text": "all right so what we're going to talk about today is optimizing placement of",
    "start": "188720",
    "end": "194239"
  },
  {
    "text": "pods in a cluster so that we can tune adequately uh you",
    "start": "194239",
    "end": "200319"
  },
  {
    "text": "you work on it so that you can size the underlying hardware appropriately and all of that so that you can avoid",
    "start": "200319",
    "end": "207280"
  },
  {
    "text": "waste and save money but without sacrificing the behavior and that's that's where the efficiency uh comes from when you can",
    "start": "207280",
    "end": "215040"
  },
  {
    "text": "respect your slls and but squashing as much as possible the the resources that you're using on your cluster",
    "start": "215040",
    "end": "221599"
  },
  {
    "text": "so at that point you could be wondering okay what is i mean what's particular about uh all of this i mean i've been",
    "start": "221599",
    "end": "228400"
  },
  {
    "text": "doing capacity planning on traditional workload for many many years and i guess the big difference is that",
    "start": "228400",
    "end": "233439"
  },
  {
    "text": "we're moving from static workload to dynamic workload uh where uh as opposed",
    "start": "233439",
    "end": "239280"
  },
  {
    "text": "to treat your vms uh as pets now you've got your worker nodes that are catalyzed",
    "start": "239280",
    "end": "245040"
  },
  {
    "text": "and you standardize uh the configuration for your worker node so you have to be",
    "start": "245040",
    "end": "250159"
  },
  {
    "text": "better at uh tuning your your workload underneath",
    "start": "250159",
    "end": "256159"
  },
  {
    "text": "all right so at lumbarod we've got currently uh three main clusters one for",
    "start": "256320",
    "end": "262160"
  },
  {
    "start": "257000",
    "end": "257000"
  },
  {
    "text": "development and integration one is tnt uat and one for production we've got another smaller one for production for",
    "start": "262160",
    "end": "268400"
  },
  {
    "text": "different use case and we're expanding the number of cluster when studying so we're working",
    "start": "268400",
    "end": "274320"
  },
  {
    "text": "uh on the uh increasing and uh we are in",
    "start": "274320",
    "end": "279680"
  },
  {
    "text": "the process of deploying another cluster into the the public cloud i'm just showing the applicative part so",
    "start": "279680",
    "end": "286720"
  },
  {
    "text": "that that's the parts for the components that we are writing ourselves",
    "start": "286720",
    "end": "292720"
  },
  {
    "text": "actually are our worker nodes our cluster uh has something like starting 1300 or",
    "start": "292720",
    "end": "299919"
  },
  {
    "text": "1400 pods when you take everything into account including the third party and all the supporting",
    "start": "299919",
    "end": "307520"
  },
  {
    "text": "supporting workloads we're running openshift four eight and",
    "start": "307520",
    "end": "313039"
  },
  {
    "text": "on the virtualized vmware infrastructure with size our worker nodes",
    "start": "313039",
    "end": "318240"
  },
  {
    "text": "and uh one thing on the hardware at the hypervisor level is that we're using a cpu overcommit uh the ratio one two five",
    "start": "318240",
    "end": "326960"
  },
  {
    "text": "so at the end of the gx project we'll probably be running more than twenty thousand pods",
    "start": "326960",
    "end": "332720"
  },
  {
    "text": "across all clusters and uh i mean by definition we won't be able to do",
    "start": "332720",
    "end": "339280"
  },
  {
    "text": "fine tuning on all those workloads with this this amount of of containers and parts running in our",
    "start": "339280",
    "end": "345280"
  },
  {
    "text": "platform all right so when we talk about resources on the container we need to take into account",
    "start": "345280",
    "end": "351440"
  },
  {
    "start": "349000",
    "end": "349000"
  },
  {
    "text": "two different notions the first one is request which is the minimum amount of resource that is required for",
    "start": "351440",
    "end": "357440"
  },
  {
    "text": "kubernetes to schedule your uh container and your pod on the specific worker knob",
    "start": "357440",
    "end": "362639"
  },
  {
    "text": "so we say it's a scheduled time notion although for cpu it maps also to the cpu",
    "start": "362639",
    "end": "368080"
  },
  {
    "text": "shares at the in the in the c groups so it's it's used as well on runtime context of that discussion will focus on",
    "start": "368080",
    "end": "375120"
  },
  {
    "text": "the the scheduled time aspect and there is the limit which is the maximum amount of resource that uh your container will",
    "start": "375120",
    "end": "382479"
  },
  {
    "text": "be able to use on your work on order right this is runtime in terms of resource types",
    "start": "382479",
    "end": "389520"
  },
  {
    "text": "then we have cpu which is said to be a complete compressible resource",
    "start": "389520",
    "end": "394960"
  },
  {
    "text": "which means that uh in in this two situation when the usage reaches the limit assuming one limit has been",
    "start": "394960",
    "end": "400720"
  },
  {
    "text": "defined for your pod or the nod which is 100 percent of its capacity then the pod is going to be slowed down it's not",
    "start": "400720",
    "end": "406880"
  },
  {
    "text": "going to crash it's going to be throttled but your position to memory which is a non-possible resource",
    "start": "406880",
    "end": "413120"
  },
  {
    "text": "so there are two situations to consider here when usage reaches limit then you",
    "start": "413120",
    "end": "418560"
  },
  {
    "text": "will have a out of memory so your pod will restart uh either on the same worker node or in",
    "start": "418560",
    "end": "424800"
  },
  {
    "text": "different worker node or the other situation is when you use all",
    "start": "424800",
    "end": "430240"
  },
  {
    "text": "the memory on your worker node then in that case you've got a memory pressure",
    "start": "430240",
    "end": "435280"
  },
  {
    "text": "situation on the node and uh the kubernetes scheduler will start doing some eviction on your pod and restart",
    "start": "435280",
    "end": "443120"
  },
  {
    "text": "the pod somewhere else to free up some some resources so so here and that i mean the situation",
    "start": "443120",
    "end": "449599"
  },
  {
    "text": "we had with the error message i was showing basically this was a request problem on cpu right and that's what",
    "start": "449599",
    "end": "455919"
  },
  {
    "text": "we're going to talk about which is basically we were reaching uh the uh the the full capacity of our nodes",
    "start": "455919",
    "end": "464720"
  },
  {
    "text": "okay so we need to to find the right balance between oversizing the request which gives you high behavior",
    "start": "464720",
    "end": "470319"
  },
  {
    "start": "465000",
    "end": "465000"
  },
  {
    "text": "predictability because you're going to over reserve resources for your workload",
    "start": "470319",
    "end": "475440"
  },
  {
    "text": "but it's going to give you low density so a low efficiency to some extent if you're using",
    "start": "475440",
    "end": "481280"
  },
  {
    "text": "overcommit at the vitalization layer you'll be able to compensate some of it but not not everything so we'll say this",
    "start": "481280",
    "end": "487120"
  },
  {
    "text": "is a performance performance optimized approach and you need to balance that with the opposite which is undersizing",
    "start": "487120",
    "end": "493199"
  },
  {
    "text": "the request in your cluster where you're going to have low b of your predictability because you put a high density so you'll be gambling the usage",
    "start": "493199",
    "end": "501360"
  },
  {
    "text": "of your resources against the performance of your workload if we're talking about cpu starving then you'll",
    "start": "501360",
    "end": "506879"
  },
  {
    "text": "get some throttling on your worker on your on your pods if you're talking about memory then",
    "start": "506879",
    "end": "514240"
  },
  {
    "text": "you may have some evictions so we could say that there is a high density so high efficiency but if you start having some",
    "start": "514240",
    "end": "521279"
  },
  {
    "text": "throttling or some evictions you're going to lower your efficiency so you're going to use on you're going to",
    "start": "521279",
    "end": "526720"
  },
  {
    "text": "sacrifice the behavior of your uh of your pod so we'll say in that situation it's a cost optimized",
    "start": "526720",
    "end": "533200"
  },
  {
    "text": "so so how do we sit right in the middle where we assess precisely the the request we need to set",
    "start": "533200",
    "end": "540480"
  },
  {
    "text": "up on our uh on our uh workload well one idea is to look at past behavior",
    "start": "540480",
    "end": "546959"
  },
  {
    "text": "so let's let's take a small uh example uh we've got four pods running on an",
    "start": "546959",
    "end": "552880"
  },
  {
    "text": "ideal worker node and we've got resources ranging from 25 to 1100",
    "start": "552880",
    "end": "558000"
  },
  {
    "text": "with workloads behaving very differently some with peaks and low activity",
    "start": "558000",
    "end": "563760"
  },
  {
    "text": "some with a lot of activity all the time so the first question is what's",
    "start": "563760",
    "end": "569839"
  },
  {
    "text": "work or not that you need to run this this workload uh so when you've got the",
    "start": "569839",
    "end": "575040"
  },
  {
    "text": "least amount of waste and you don't have uh you don't sacrifice on the behavior but actually the better question is what",
    "start": "575040",
    "end": "581519"
  },
  {
    "start": "580000",
    "end": "580000"
  },
  {
    "text": "do i need to reserve for each of my pods right because you're all going to configure them independently from one",
    "start": "581519",
    "end": "587360"
  },
  {
    "text": "another because each part doesn't know where it's going to sit and we're going to be the neighbors do you take the average conception do",
    "start": "587360",
    "end": "593600"
  },
  {
    "text": "you take the max consumption on each node another way to look at this graph is to",
    "start": "593600",
    "end": "598800"
  },
  {
    "start": "597000",
    "end": "597000"
  },
  {
    "text": "look at the the cumulative conception of a time so it's very easy to see that the",
    "start": "598800",
    "end": "605600"
  },
  {
    "text": "optimal host would be the one which is sitting at the peak of this graph so in in that situation 79",
    "start": "605600",
    "end": "613360"
  },
  {
    "text": "now if you took the average consumption of each pod and you send that",
    "start": "613360",
    "end": "618640"
  },
  {
    "text": "uh what would happen is that you would get a a host with 1200 capacity",
    "start": "618640",
    "end": "624000"
  },
  {
    "text": "uh so you've got a lot of density because you're taking a lot of the resources that are available on the now",
    "start": "624000",
    "end": "629360"
  },
  {
    "text": "but what you can see is that five times out of ten the workload is going to try",
    "start": "629360",
    "end": "634880"
  },
  {
    "text": "to consume more capacity than you've got in your work or not so if we're talking about cpu you'll get some throttling if we're talking about memory you'll get",
    "start": "634880",
    "end": "641040"
  },
  {
    "text": "some eviction and we don't necessarily want that now if you took the max you've got the opposite situation where you over",
    "start": "641040",
    "end": "648000"
  },
  {
    "text": "reserve resources for your workload so you've got lots of extra capacity so you're not going to have any throttling",
    "start": "648000",
    "end": "654320"
  },
  {
    "text": "or any eviction but you're going to waste a lot of resources so we need something in the middle which",
    "start": "654320",
    "end": "659519"
  },
  {
    "text": "is what vpi is doing so [Music]",
    "start": "659519",
    "end": "664880"
  },
  {
    "text": "one of the metric is to take the percentile which basically covers most of your activity and get rid of the",
    "start": "664880",
    "end": "671279"
  },
  {
    "text": "peaks of activity now in that situation you will get a",
    "start": "671279",
    "end": "678000"
  },
  {
    "text": "horse with 2 500 of resources so sit somewhere between the optimal and the max so you have a",
    "start": "678399",
    "end": "685279"
  },
  {
    "text": "little bit of weight waste but not too much and more importantly you don't sacrifice the behavior you don't get",
    "start": "685279",
    "end": "690959"
  },
  {
    "text": "throttling if you look at pod one in particular you can see that the p90 is going",
    "start": "690959",
    "end": "698079"
  },
  {
    "text": "nine times out of ten your resource usage so the question is what happens uh to",
    "start": "698079",
    "end": "704800"
  },
  {
    "text": "your peak right well it's going to be financed by your neighbors that are not",
    "start": "704800",
    "end": "710000"
  },
  {
    "text": "going to hopefully doing the peaks their peaks at the same time so there is a little bit of gambling and then you",
    "start": "710000",
    "end": "715519"
  },
  {
    "text": "benefit from the extra capacity that is provided and reserved for the others but but not used",
    "start": "715519",
    "end": "721200"
  },
  {
    "text": "and that's basically doing uh the exact same overcoming that we were doing initially at the utilization layer but",
    "start": "721200",
    "end": "727519"
  },
  {
    "text": "we're doing it at the pod level all right so vertical pad auto scaler this is a",
    "start": "727519",
    "end": "734000"
  },
  {
    "start": "732000",
    "end": "732000"
  },
  {
    "text": "kubernetes tester project and it can provide a recommendation",
    "start": "734000",
    "end": "739920"
  },
  {
    "text": "uh on resource usage and specifically on the amount of resources to reserve for your",
    "start": "739920",
    "end": "746399"
  },
  {
    "text": "pod so basically that helps you configuring the request can help you as well on configuring the limits",
    "start": "746399",
    "end": "754079"
  },
  {
    "text": "the interesting thing is that it's going to watch your containers all the time so it can give",
    "start": "754079",
    "end": "760560"
  },
  {
    "text": "you up-to-date recommendation and this recommendation can change over time this",
    "start": "760560",
    "end": "766000"
  },
  {
    "text": "is not a tuning that you're doing six months ago and you keep while actually your workload is",
    "start": "766000",
    "end": "772320"
  },
  {
    "text": "evolving in in terms of behavior it's crd-based so it's completely",
    "start": "772320",
    "end": "777839"
  },
  {
    "text": "compliant with your github githubs approach and you can either connect it to promoters to gather the metrics or",
    "start": "777839",
    "end": "783920"
  },
  {
    "text": "it's going to watch directly the resource usage on your pod and",
    "start": "783920",
    "end": "789600"
  },
  {
    "text": "consolidate and compile those metrics into uh into a format which is itself",
    "start": "789600",
    "end": "794959"
  },
  {
    "text": "stored inside a different cr which is called the checkpoint interestingly it can upscale or don't",
    "start": "794959",
    "end": "801440"
  },
  {
    "text": "scale the resources uh that has been that have been configured depending on the situation maybe you",
    "start": "801440",
    "end": "807839"
  },
  {
    "text": "know you need more cpu maybe you need less you can work on memory and cpu and",
    "start": "807839",
    "end": "813440"
  },
  {
    "text": "optionally it can apply the recommendation on your workload right it's available on the public cloud",
    "start": "813440",
    "end": "820880"
  },
  {
    "text": "through different offering and at combi we're using it through a dedicated and supported openshift operator that's what",
    "start": "820880",
    "end": "828079"
  },
  {
    "text": "we're doing all right so let's take an example here's the main cr",
    "start": "828079",
    "end": "834160"
  },
  {
    "start": "831000",
    "end": "831000"
  },
  {
    "text": "that you would create for a specific workload in that context it's a deployment",
    "start": "834160",
    "end": "840160"
  },
  {
    "text": "for the control resources you can say uh that you want to work on cpu or memory",
    "start": "840160",
    "end": "845519"
  },
  {
    "text": "or both uh the control value you've got choice for the request only or request and limit",
    "start": "845519",
    "end": "851360"
  },
  {
    "text": "you cannot choose limits only and for the update mode you've got four options so off means",
    "start": "851360",
    "end": "858480"
  },
  {
    "text": "you vpa is going to provide a recommendation but it's not going to apply it for you initial means the recommendation will be",
    "start": "858480",
    "end": "865839"
  },
  {
    "text": "applied at the next startup it could be a crash or it could be a normal run out",
    "start": "865839",
    "end": "871120"
  },
  {
    "text": "recreate means that if the recombination is too far off from what you've configured",
    "start": "871120",
    "end": "876560"
  },
  {
    "text": "on your workload initially so for instance on your deployment",
    "start": "876560",
    "end": "882320"
  },
  {
    "text": "then it's going to detect that and the vpn is going to trigger a restart of your of your pod and it will start with",
    "start": "882320",
    "end": "888399"
  },
  {
    "text": "the the recommendations applied and the last mod auto is today doing the same thing as the recreate because",
    "start": "888399",
    "end": "895600"
  },
  {
    "text": "uh the way to change requests in kubernetes today is to do a restart",
    "start": "895600",
    "end": "903680"
  },
  {
    "text": "after a while after watching your container working for some time",
    "start": "903760",
    "end": "909600"
  },
  {
    "text": "vpa will calculate a recommendation that appears directly into the cr in the",
    "start": "909600",
    "end": "916959"
  },
  {
    "text": "status section and there are four metrics the most important one is the target which is based on the",
    "start": "916959",
    "end": "923680"
  },
  {
    "text": "p90 like we saw like we saw before for all the uh the control resources",
    "start": "923680",
    "end": "930399"
  },
  {
    "text": "uh you've got the lower band which is the the p5 p50 and you've got the upper band which is the p95",
    "start": "930399",
    "end": "937920"
  },
  {
    "text": "right so in this particular context we're running an initial so at the next startup our deployment was originally",
    "start": "937920",
    "end": "943600"
  },
  {
    "text": "configured with 100 millicourse and one gig of ram and the pod the controller",
    "start": "943600",
    "end": "949040"
  },
  {
    "text": "will replace at startup uh those results with the the calculated values",
    "start": "949040",
    "end": "956560"
  },
  {
    "text": "in terms of uh use cases um we using vpr chromebody for stateless workloads and",
    "start": "956560",
    "end": "962880"
  },
  {
    "text": "jobs and current jobs but there is also there is also an additional use scale which is",
    "start": "962880",
    "end": "968320"
  },
  {
    "text": "interesting which is a stateful workload where",
    "start": "968320",
    "end": "973759"
  },
  {
    "start": "973000",
    "end": "973000"
  },
  {
    "text": "scaling horizontally stateful workload might be specific to the technology that you're",
    "start": "973759",
    "end": "979360"
  },
  {
    "text": "using so in that situation vpa is a very good option to grab more resources",
    "start": "979360",
    "end": "986399"
  },
  {
    "text": "there are so a few limitations however when you're using vpa it is said in the documentation that you",
    "start": "986399",
    "end": "992800"
  },
  {
    "text": "should be using a vpa to control memory on jvm based",
    "start": "992800",
    "end": "997920"
  },
  {
    "text": "workload it this is essentially related to the way uh the jvm manages memory and",
    "start": "997920",
    "end": "1004399"
  },
  {
    "text": "the limited visibility it provides uh on the heap to the uh to the vpa or i",
    "start": "1004399",
    "end": "1011759"
  },
  {
    "text": "mean the metrics that are coming from prometheus ano another thing to look into is um uh",
    "start": "1011759",
    "end": "1019279"
  },
  {
    "text": "is what you've got to be careful is using vpn with hpe and typically you cannot use",
    "start": "1019279",
    "end": "1025038"
  },
  {
    "text": "you cannot use a control resource like cpu and vpn and use it as the base metric for scaling on hpa so you can use",
    "start": "1025039",
    "end": "1033199"
  },
  {
    "text": "both but not on the same metric you have to be careful about that otherwise they're going to work against one",
    "start": "1033199",
    "end": "1038640"
  },
  {
    "text": "another the auto recreate by design is not by",
    "start": "1038640",
    "end": "1043918"
  },
  {
    "text": "default going to trigger any restart on your pods if there is only one pod in the",
    "start": "1043919",
    "end": "1050559"
  },
  {
    "text": "replica set otherwise that would mean some unavailability on you on your service",
    "start": "1050559",
    "end": "1056400"
  },
  {
    "text": "um you have to be careful and you have if you if you give uh i mean if you're",
    "start": "1056400",
    "end": "1061760"
  },
  {
    "text": "using the initial or even the recreate auto mod you have to be careful about",
    "start": "1061760",
    "end": "1066880"
  },
  {
    "text": "potential excessive recommendation that vpa would be doing because it doesn't understand fully your workload and you",
    "start": "1066880",
    "end": "1072960"
  },
  {
    "text": "want to make sure that the sum of all the requests that will be calculated by",
    "start": "1072960",
    "end": "1078080"
  },
  {
    "text": "vpa do not exceed your your cluster capacity uh one thing uh one pinfall is that",
    "start": "1078080",
    "end": "1085440"
  },
  {
    "text": "there is only one vp object uh allowed per workload so if you create 2vp object for the same deployment",
    "start": "1085440",
    "end": "1093120"
  },
  {
    "text": "vpa is going to select only the the all that all this one is going to ignore uh",
    "start": "1093120",
    "end": "1098320"
  },
  {
    "text": "the the most recent one and the last thing is that there are some distributions",
    "start": "1098320",
    "end": "1104160"
  },
  {
    "text": "that limit uh the number of vp objects you can have in a single cluster so for instance gke",
    "start": "1104160",
    "end": "1110160"
  },
  {
    "text": "allows only 500 objects into the cluster openshift doesn't say that they have",
    "start": "1110160",
    "end": "1116240"
  },
  {
    "text": "this limitation but they warn you about the resource usage that vpa has",
    "start": "1116240",
    "end": "1121760"
  },
  {
    "text": "and tags to calculate all of those metrics so you really have to i mean to be careful about uh",
    "start": "1121760",
    "end": "1128880"
  },
  {
    "text": "i mean to check how vpa is scaling to monitor all of your pots",
    "start": "1128880",
    "end": "1135440"
  },
  {
    "text": "so where are we in uh in lombardy um so we've deployed vpn on all clusters uh",
    "start": "1135440",
    "end": "1140960"
  },
  {
    "start": "1136000",
    "end": "1136000"
  },
  {
    "text": "we're using the request only mod that was based that's basically an answer to the initial problem that we're having",
    "start": "1140960",
    "end": "1147679"
  },
  {
    "text": "and we're also starting to experiment with uh the operative highlighting on the dev cluster and that explains some",
    "start": "1147679",
    "end": "1154640"
  },
  {
    "text": "of the numbers on the dev cluster which are pretty low uh nothing to do with vpn",
    "start": "1154640",
    "end": "1159679"
  },
  {
    "text": "but it's another uh tool in the toolbox for capacity planning",
    "start": "1159679",
    "end": "1166400"
  },
  {
    "text": "one thing that we did is that we created a capacity planning governance board where we meet every",
    "start": "1166400",
    "end": "1173360"
  },
  {
    "text": "month and basically we track usage versus requested for memory and cpu",
    "start": "1173360",
    "end": "1179520"
  },
  {
    "text": "the goal is at some point that the request will uh will be aligned uh on the the real usage",
    "start": "1179520",
    "end": "1188559"
  },
  {
    "text": "we still have a bit of this discrepancy on the cpu request versus usage they might be",
    "start": "1188559",
    "end": "1194960"
  },
  {
    "text": "well we're still analyzing this uh it might be uh related to the other type of",
    "start": "1194960",
    "end": "1201200"
  },
  {
    "text": "workload that are running on on a worker node and that are not covered by by vpn",
    "start": "1201200",
    "end": "1207520"
  },
  {
    "text": "but basically the next challenge that we have we kind of solved the cpu situation",
    "start": "1207520",
    "end": "1212559"
  },
  {
    "text": "and uh the next challenge is going to be about memory so for cpu we're running initial on all",
    "start": "1212559",
    "end": "1219120"
  },
  {
    "text": "nodes we've got default values for for our java workloads",
    "start": "1219120",
    "end": "1224960"
  },
  {
    "text": "but those value can be overridden by the different development teams and one thing that was very interesting",
    "start": "1224960",
    "end": "1230240"
  },
  {
    "text": "when we looked at the result calculated by vpa is that we had a very low value meaning we've got a lot of workload but",
    "start": "1230240",
    "end": "1237280"
  },
  {
    "text": "not doing too much and so we could see with this value the 38 millicourse",
    "start": "1237280",
    "end": "1244559"
  },
  {
    "text": "actually even our default which seemed not so high was actually oversized",
    "start": "1244559",
    "end": "1251200"
  },
  {
    "text": "compared to uh to what we had with vpa and on top of that the",
    "start": "1251200",
    "end": "1256480"
  },
  {
    "text": "development teams with limited understanding on how things were working actually we're increasing the request",
    "start": "1256480",
    "end": "1262640"
  },
  {
    "text": "hoping actually to get better results so so we it's kind of deployed",
    "start": "1262640",
    "end": "1268559"
  },
  {
    "text": "progressively on each workload in a different cluster we start we're starting actually to see the the",
    "start": "1268559",
    "end": "1274000"
  },
  {
    "text": "services in terms of vcp use it doesn't change the usage it's it changes the",
    "start": "1274000",
    "end": "1279039"
  },
  {
    "text": "perspective of the uh allocation or the the the you the usage that you have on",
    "start": "1279039",
    "end": "1284799"
  },
  {
    "text": "your cluster and what you reserve for memory it's very new i mean it's uh",
    "start": "1284799",
    "end": "1290400"
  },
  {
    "text": "we we started doing that a few weeks ago so it's deploying on the cluster uh",
    "start": "1290400",
    "end": "1296320"
  },
  {
    "text": "on the dev cluster only and what happens is that we uh",
    "start": "1296320",
    "end": "1301919"
  },
  {
    "text": "the development team are going to set a value which is going to be used by default for the request and the limit so",
    "start": "1301919",
    "end": "1307360"
  },
  {
    "text": "basically we're working in guaranteed mode by default initially and what's going to happen is that vpa is going to",
    "start": "1307360",
    "end": "1313520"
  },
  {
    "text": "watch your activity and basically downscale uh the request on the memory",
    "start": "1313520",
    "end": "1318960"
  },
  {
    "text": "so so far we were able to save 18 gigs of ram of request",
    "start": "1318960",
    "end": "1325679"
  },
  {
    "text": "all right so listen learns you have to be careful about namespace or object deletion and recreation",
    "start": "1325679",
    "end": "1333520"
  },
  {
    "start": "1326000",
    "end": "1326000"
  },
  {
    "text": "in our situation we're choosing uh we're not getting the metrics out of prometheus which means they're being",
    "start": "1333520",
    "end": "1340640"
  },
  {
    "text": "stored in a compacted format in a specific cr if you remove checkpoint cr then you lose your matrix",
    "start": "1340640",
    "end": "1347600"
  },
  {
    "text": "right and you have to start over with your recommendation the other thing is that recommendation is stored as a",
    "start": "1347600",
    "end": "1353039"
  },
  {
    "text": "status in the vpa object if you remove the vpa object or you replace it the",
    "start": "1353039",
    "end": "1358480"
  },
  {
    "text": "next time you deploy then for 30 seconds you're going to lose the recommendation your pod is going to start with whatever",
    "start": "1358480",
    "end": "1364480"
  },
  {
    "text": "is configured right so if you want to make modification on this vpn object you've",
    "start": "1364480",
    "end": "1370559"
  },
  {
    "text": "got to update it and not replace it one big learning experience",
    "start": "1370559",
    "end": "1376159"
  },
  {
    "text": "the uh low cpu recommendation right and and really even if you don't use vpa to",
    "start": "1376159",
    "end": "1382640"
  },
  {
    "text": "apply this recommendation automatically it's a learning experience just as much as i mean doing observability and doing",
    "start": "1382640",
    "end": "1390000"
  },
  {
    "text": "graphing dashboards to watch the behavior of your of your workload",
    "start": "1390000",
    "end": "1395679"
  },
  {
    "text": "uh one thing to uh to um kind of not forget is that with",
    "start": "1395679",
    "end": "1402720"
  },
  {
    "text": "reserving resources based on the p90 for instance in the context of",
    "start": "1402720",
    "end": "1408960"
  },
  {
    "text": "vpa is basically doing overcoming it at the pod level and if you're using overcommit at the vitalization layer",
    "start": "1408960",
    "end": "1416240"
  },
  {
    "text": "they could conflict with ways with one another so you have to be very conservative with your recommend you",
    "start": "1416240",
    "end": "1421360"
  },
  {
    "text": "you're doing a divitization layer and one very interesting thing that we got out",
    "start": "1421360",
    "end": "1427520"
  },
  {
    "text": "of using vpa was that not only we were able to do fine tuning",
    "start": "1427520",
    "end": "1432799"
  },
  {
    "text": "uh from one application to another but we were able to get a different",
    "start": "1432799",
    "end": "1438559"
  },
  {
    "text": "recommendation and tuning for the same application in the different environment and it's it's not unusual when you start",
    "start": "1438559",
    "end": "1445039"
  },
  {
    "text": "using vpa to not have the same value in production test and integration you've",
    "start": "1445039",
    "end": "1450640"
  },
  {
    "text": "you've got kind of the best value a few things to uh",
    "start": "1450640",
    "end": "1457279"
  },
  {
    "text": "to be careful about in the context of gvm workload uh one mistake we did at the beginning is that we wanted to",
    "start": "1457279",
    "end": "1462640"
  },
  {
    "text": "protect the startup of critical application uh the issue with application java applicative framework",
    "start": "1462640",
    "end": "1469520"
  },
  {
    "text": "is that they tend nowadays to consume a lot of cpu at startup so",
    "start": "1469520",
    "end": "1474559"
  },
  {
    "text": "you've got to pick an initial peak if you size uh your request based on that you're going",
    "start": "1474559",
    "end": "1481120"
  },
  {
    "text": "to over reserve an overconsume request so do not oversize to cope with startup",
    "start": "1481120",
    "end": "1488480"
  },
  {
    "text": "uh you would have a better efficiency the issue however is then the soldering",
    "start": "1488480",
    "end": "1493600"
  },
  {
    "text": "hub what we call the soldering hub problem which is uh when you've got a massive amount of pods that are starting",
    "start": "1493600",
    "end": "1499840"
  },
  {
    "text": "are going to do a a big huge peak of of of consumption vpa is not helping you",
    "start": "1499840",
    "end": "1507440"
  },
  {
    "text": "with that so that that's an issue okay so",
    "start": "1507440",
    "end": "1512640"
  },
  {
    "text": "next um we want to like i said i mean the next challenge for us is keep keeping memory",
    "start": "1512640",
    "end": "1519200"
  },
  {
    "text": "uh at a sustainable level uh so we will we want to continue working on that",
    "start": "1519200",
    "end": "1525679"
  },
  {
    "text": "and so get some feedback on the development cluster and start actually going up in the other cluster we want to continue",
    "start": "1525679",
    "end": "1532960"
  },
  {
    "text": "adding some density on our kernel i mean the ultimate goal would be at some point",
    "start": "1532960",
    "end": "1538400"
  },
  {
    "text": "that we don't need the vitalization of a commit at uh i mean at the utilization level and we",
    "start": "1538400",
    "end": "1545520"
  },
  {
    "text": "can go to bare metal right you don't want to go to bare metal if you've got a low density on",
    "start": "1545520",
    "end": "1550720"
  },
  {
    "text": "on your work or not we want to start working with a vp on",
    "start": "1550720",
    "end": "1558480"
  },
  {
    "text": "one side and horizontal scaling on the other side uh and specifically",
    "start": "1558480",
    "end": "1564720"
  },
  {
    "text": "we there would be a lot of benefit if we were able to scale down scale down to zero and back to one for for this",
    "start": "1564720",
    "end": "1570000"
  },
  {
    "text": "particular use case so we'll be looking at hpa but we'll invest some time on serverless as well or",
    "start": "1570000",
    "end": "1575919"
  },
  {
    "text": "kedar for instance and the last thing is that we want to expand vpa to workloads that we're not",
    "start": "1575919",
    "end": "1583679"
  },
  {
    "text": "writing ourselves so that the best practices are applied to everybody and typically what we're seeing is that",
    "start": "1583679",
    "end": "1589919"
  },
  {
    "text": "vendors come with the product and they ask you to configure excessive",
    "start": "1589919",
    "end": "1596159"
  },
  {
    "text": "resource allocation to protect the product even if that's not appropriate so we want to work on that",
    "start": "1596159",
    "end": "1603200"
  },
  {
    "text": "a few issues uh to consider so the first one is being pushed by a",
    "start": "1603600",
    "end": "1609279"
  },
  {
    "text": "colleague of mine matthias bertie which aims at providing the ability to configure a",
    "start": "1609279",
    "end": "1617039"
  },
  {
    "text": "target personal value different from the default 90 which is hard coded today so",
    "start": "1617039",
    "end": "1622640"
  },
  {
    "text": "we could choose with a more cost optimized approach or a more performance optimized approach depending on the on",
    "start": "1622640",
    "end": "1628320"
  },
  {
    "text": "the workload it would give us more flexibility uh just if you go back in the the small example",
    "start": "1628320",
    "end": "1634159"
  },
  {
    "text": "i was showing earlier the perfect value was p78 right so pt was",
    "start": "1634159",
    "end": "1640720"
  },
  {
    "text": "already very conservative and we could be saving some value by actually a little bit uh with more gambling toward",
    "start": "1640720",
    "end": "1648480"
  },
  {
    "text": "a more custom cost optimized approach uh the second issue is very important that's the",
    "start": "1648480",
    "end": "1654640"
  },
  {
    "text": "that's the idea is to provide kubernetes with the ability to replace",
    "start": "1654640",
    "end": "1660480"
  },
  {
    "text": "requests and limits without restarting the pod this would open up",
    "start": "1660480",
    "end": "1667279"
  },
  {
    "text": "use cases like the auto which requires that and might help also as the basis",
    "start": "1667279",
    "end": "1672880"
  },
  {
    "text": "for implementing something smarter for the centering health problem about that particular issue",
    "start": "1672880",
    "end": "1678799"
  },
  {
    "text": "you may be interested in the discussion of the third point and that's why i listed it there and the last one is the is a bug that we",
    "start": "1678799",
    "end": "1685679"
  },
  {
    "text": "found a few tools and resources to to to wrap",
    "start": "1685679",
    "end": "1690799"
  },
  {
    "text": "up this talk so there is a recommendation plug-in that you can install at cubectl with uh with crew",
    "start": "1690799",
    "end": "1696799"
  },
  {
    "text": "gold the dashboard which relies on the vpa recommendation engine uh to show you on",
    "start": "1696799",
    "end": "1704080"
  },
  {
    "start": "1697000",
    "end": "1697000"
  },
  {
    "text": "your different workloads uh basically the the the values uh",
    "start": "1704080",
    "end": "1709440"
  },
  {
    "text": "that were recommended by vpa without having to scan all the the crs",
    "start": "1709440",
    "end": "1714559"
  },
  {
    "text": "harness is an interesting and and complete solution which has its own recommendation engine and what i like",
    "start": "1714559",
    "end": "1720480"
  },
  {
    "text": "about it is that they recognize that there are different types of profiles and they let you choose between cost or",
    "start": "1720480",
    "end": "1727600"
  },
  {
    "text": "performance or even a custom profile that you would define yourself so you could say i want to the target to be",
    "start": "1727600",
    "end": "1733279"
  },
  {
    "text": "calculated on the pit for instance right and if you're interested in the",
    "start": "1733279",
    "end": "1738399"
  },
  {
    "text": "subject uh i really suggest recommend reading the last link which has a lot of interesting",
    "start": "1738399",
    "end": "1744559"
  },
  {
    "text": "information and with that i think we've got time for a few",
    "start": "1744559",
    "end": "1750559"
  },
  {
    "text": "questions [Applause]",
    "start": "1750559",
    "end": "1758230"
  },
  {
    "text": "if anyone got a question in the room there's one over there okay",
    "start": "1758240",
    "end": "1763440"
  },
  {
    "text": "i have one from online as well",
    "start": "1763440",
    "end": "1767840"
  },
  {
    "text": "thank you hi thank you for a great talk i was wondering if you had any chance to",
    "start": "1772000",
    "end": "1778080"
  },
  {
    "text": "look at the prometheus integration of the vertical pot auto scale and if you did if",
    "start": "1778080",
    "end": "1783440"
  },
  {
    "text": "you noticed any reasons why you would choose one or the other so the custom resource or the",
    "start": "1783440",
    "end": "1789440"
  },
  {
    "text": "that's a good question no we didn't look at this integration uh",
    "start": "1789440",
    "end": "1794799"
  },
  {
    "text": "there would be one one good thing about it is that you wouldn't rely on internal storing with the cr so you would have",
    "start": "1794799",
    "end": "1800880"
  },
  {
    "text": "you wouldn't have the limitation i was talking about where if you remove this object you lose your metrics uh but uh",
    "start": "1800880",
    "end": "1807600"
  },
  {
    "text": "the good thing about not depending on it is that you don't have a dependence on on permit series so if it's not",
    "start": "1807600",
    "end": "1812640"
  },
  {
    "text": "available uh basically vpa is standalone and it can continue so we make the",
    "start": "1812640",
    "end": "1818080"
  },
  {
    "text": "choice actually to separate both uh at this point",
    "start": "1818080",
    "end": "1823200"
  },
  {
    "text": "okay i'm going to read a question from slack from federico hernandez",
    "start": "1823200",
    "end": "1828799"
  },
  {
    "text": "uh which was how are they practically tackling the hpa versus vpa dilemma by",
    "start": "1828799",
    "end": "1835840"
  },
  {
    "text": "which he meant you could have hpa scaling out workloads which would make more pods which would",
    "start": "1835840",
    "end": "1841760"
  },
  {
    "text": "make less room for the vpa to scale okay so yeah my understanding is that so",
    "start": "1841760",
    "end": "1848080"
  },
  {
    "text": "we haven't studied that work but my understanding is that uh you can use hpl",
    "start": "1848080",
    "end": "1853120"
  },
  {
    "text": "with vpn but you can you you need to use it on a metric which is not controlled",
    "start": "1853120",
    "end": "1858559"
  },
  {
    "text": "by vpa so for instance uh you could take requests per second if you",
    "start": "1858559",
    "end": "1864480"
  },
  {
    "text": "which is i mean the basic notion into in serverless you could even use",
    "start": "1864480",
    "end": "1872320"
  },
  {
    "text": "the cpu control resource on vpn and use memory for scaling but",
    "start": "1872320",
    "end": "1878000"
  },
  {
    "text": "you don't want to actually have both metrics used in uh in the two",
    "start": "1878000",
    "end": "1883360"
  },
  {
    "text": "in these two features okay thank you who next",
    "start": "1883360",
    "end": "1889518"
  },
  {
    "text": "at the back can you keep your hand up i'll come to you next uh thanks for your talk i was just",
    "start": "1890080",
    "end": "1895279"
  },
  {
    "text": "curious as you're starting to do the uh memory investigation um how are you",
    "start": "1895279",
    "end": "1900880"
  },
  {
    "text": "handling the issue with the jvm yeah that's that's a very good question uh so i i reach out to uh two different",
    "start": "1900880",
    "end": "1909279"
  },
  {
    "text": "people my understanding is that if we're doing as long as we're doing request only then we're probably fine and that's what",
    "start": "1909279",
    "end": "1916480"
  },
  {
    "text": "we are working on today in the development cluster so we need to confirm this the issue seems to be related to",
    "start": "1916480",
    "end": "1924640"
  },
  {
    "text": "trying to change the limit which we're not interested in at this point specifically around",
    "start": "1924640",
    "end": "1932320"
  },
  {
    "text": "there is a way to size uh the hip um in relation to ratio on the the",
    "start": "1932320",
    "end": "1938480"
  },
  {
    "text": "container memory so if you start actually having vpn just scaling up i",
    "start": "1938480",
    "end": "1943919"
  },
  {
    "text": "mean the problem is with ip committed versus hip usage in in the gvm uh so",
    "start": "1943919",
    "end": "1950480"
  },
  {
    "text": "we're not getting getting into the limits today so uh i mean my understanding is that we're fine with",
    "start": "1950480",
    "end": "1956159"
  },
  {
    "text": "recursion limit hi so my question was that",
    "start": "1956159",
    "end": "1962399"
  },
  {
    "text": "i realized you had an open issue but it was closed with no solution for how to uh",
    "start": "1962399",
    "end": "1967519"
  },
  {
    "text": "like a throttling container starting up do you have any workaround in place right now that you are using well my",
    "start": "1967519",
    "end": "1974799"
  },
  {
    "text": "yeah very good point um a lot of people have been complaining about uh",
    "start": "1974799",
    "end": "1980240"
  },
  {
    "text": "the the i mean throttling the startup because of jvm workloads uh so so it's a",
    "start": "1980240",
    "end": "1986000"
  },
  {
    "text": "common issue uh the solution could come with uh the uh the other the cap i was",
    "start": "1986000",
    "end": "1993200"
  },
  {
    "text": "showing earlier with the in place uh update of resources so the idea was",
    "start": "1993200",
    "end": "1999200"
  },
  {
    "text": "that if we had that maybe we could um startup over provision request to cover",
    "start": "1999200",
    "end": "2007600"
  },
  {
    "text": "the startup and once the pod is ready downgrade the the request so in that",
    "start": "2007600",
    "end": "2013279"
  },
  {
    "text": "case you would have natural throttling because you would have uh you're working out piling up big requests and suddenly",
    "start": "2013279",
    "end": "2021440"
  },
  {
    "text": "free up resources as the pod gets ready but it's i mean we'll see you know",
    "start": "2021440",
    "end": "2027200"
  },
  {
    "text": "in a few years okay i think we're at time so i'm not going to take any more questions",
    "start": "2027200",
    "end": "2033519"
  },
  {
    "text": "okay so thank you a big a big thank you to uh yourself and lombardier was able to be",
    "start": "2033519",
    "end": "2042159"
  },
  {
    "text": "able to get me on stage actually to present all of this work that we've done and which is very important for us thank",
    "start": "2042159",
    "end": "2048000"
  },
  {
    "text": "you very much and have a good conference",
    "start": "2048000",
    "end": "2051960"
  }
]
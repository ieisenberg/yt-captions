[
  {
    "text": "hello everyone my name is Lauren bernai and I'm here with Eric",
    "start": "599",
    "end": "7200"
  },
  {
    "text": "and I mean we're very happy to be here today it's our first coupon in person since 2019 in North America so that's",
    "start": "7200",
    "end": "14219"
  },
  {
    "text": "that's great to to be here with you So today we're going to to discuss our",
    "start": "14219",
    "end": "19619"
  },
  {
    "text": "migration of uh the way we build container images to kubernetes and as you you will see it was a bit eventful",
    "start": "19619",
    "end": "26820"
  },
  {
    "text": "and it got pretty interesting so before we start we both work for",
    "start": "26820",
    "end": "31980"
  },
  {
    "text": "datadoc so we have a few numbers and of about datadag on the left hand side of",
    "start": "31980",
    "end": "37140"
  },
  {
    "text": "the slide what matters is with our an obserability company and and we do a lot",
    "start": "37140",
    "end": "43620"
  },
  {
    "text": "of things in the obserability space but today we're not going to talk about dialogue the product we're going to talk",
    "start": "43620",
    "end": "48780"
  },
  {
    "text": "about data dogs infrastructure because we both work on the dialogue infrastructure teams so we",
    "start": "48780",
    "end": "56120"
  },
  {
    "text": "essentially work on the kubernetes environment which is why we're going to talk about building containers in",
    "start": "56120",
    "end": "61620"
  },
  {
    "text": "kubernetes and as you can see with the numbers I mean we have tens of thousands of nodes dozens of clusters and and with",
    "start": "61620",
    "end": "68280"
  },
  {
    "text": "this come a lot of challenges around many things but in particular building container images",
    "start": "68280",
    "end": "75360"
  },
  {
    "text": "so before we dive into an interesting issue let's do a quick overview of how",
    "start": "75360",
    "end": "80700"
  },
  {
    "text": "we build things at datadog so quite a while back I'd say it's like up",
    "start": "80700",
    "end": "87180"
  },
  {
    "text": "to four or five years ago we were using this very simple setup to build our applications so we had gitlab Runners",
    "start": "87180",
    "end": "94080"
  },
  {
    "text": "pulling jobs from gitlab and using Docker machine to provision Edibles instances a running job on them so",
    "start": "94080",
    "end": "100200"
  },
  {
    "text": "pretty standard pretty simple when we started our migration to",
    "start": "100200",
    "end": "105240"
  },
  {
    "text": "kubernetes we needed to in addition to building applications we also needed to build container images and if you're",
    "start": "105240",
    "end": "111659"
  },
  {
    "text": "familiar with the way we build Docker images it usually means having access to the docker demon which basically means",
    "start": "111659",
    "end": "117299"
  },
  {
    "text": "being root on the instance where where you run so that's why we couldn't reuse the runners we were using for",
    "start": "117299",
    "end": "123240"
  },
  {
    "text": "applications because these Runners will be used and there was no way we could run a workload which will end up being",
    "start": "123240",
    "end": "129599"
  },
  {
    "text": "root on the machine because it was running Docker commands so we ended up having other Runners which were just",
    "start": "129599",
    "end": "135180"
  },
  {
    "text": "General Admissions running Docker doing one job and when the job was done they",
    "start": "135180",
    "end": "140340"
  },
  {
    "text": "were just being killed and replaced by new ones",
    "start": "140340",
    "end": "145500"
  },
  {
    "text": "that was working fine until sometime when the company had grown a bit and we",
    "start": "145500",
    "end": "151200"
  },
  {
    "text": "were having many more Engineers many more builds every day and Docker machine was starting to hit limits we're hitting",
    "start": "151200",
    "end": "158160"
  },
  {
    "text": "API rate limits with the AWS API and it was starting to be tricky to to to scale",
    "start": "158160",
    "end": "163860"
  },
  {
    "text": "with the skill of the company and so we migrated our workers to kubernetes right this was easy because at that time we",
    "start": "163860",
    "end": "171060"
  },
  {
    "text": "had enough of knowledge of kubernetes a datadog to be able to do that it was pretty successful but as you can see to",
    "start": "171060",
    "end": "178019"
  },
  {
    "text": "build Docker images we were still using the dedicated runners the next step in this journey is some",
    "start": "178019",
    "end": "185160"
  },
  {
    "text": "customers were starting to ask us for armed binaries right because we provide the data log agent for instance that",
    "start": "185160",
    "end": "190920"
  },
  {
    "text": "people use for monitoring and people were starting to use Arm CPUs so we need to provide them with arm binaries and so",
    "start": "190920",
    "end": "197459"
  },
  {
    "text": "what we did is because we're running on kubernetes we set up kubernetes nodes with arm CPUs and we're running Builds",
    "start": "197459",
    "end": "204239"
  },
  {
    "text": "on on this on this node to get native builds well as you can imagine the next step",
    "start": "204239",
    "end": "211379"
  },
  {
    "text": "will of course to be able to do that we need to have Docker images that supported um architecture and so we",
    "start": "211379",
    "end": "218040"
  },
  {
    "text": "wanted to have multi-arch images to do this we transition our Runners from",
    "start": "218040",
    "end": "223200"
  },
  {
    "text": "running simple Docker builds to running Docker build X which allows you to do multi-art build by relying on emulation",
    "start": "223200",
    "end": "229920"
  },
  {
    "text": "with qmu so this was to be honest this was magic it just worked right",
    "start": "229920",
    "end": "235739"
  },
  {
    "text": "um we were able to provide to get images which were both working on x86 and arm",
    "start": "235739",
    "end": "240959"
  },
  {
    "text": "by using emulation however as you can imagine for some builds we moved from 10",
    "start": "240959",
    "end": "246120"
  },
  {
    "text": "minutes on Native x86 to more than an hour on arm emulated right so it wasn't ideal",
    "start": "246120",
    "end": "253140"
  },
  {
    "text": "and and today the talk is going to focus on this part like how we build images and how we transition to kubernetes",
    "start": "253140",
    "end": "259220"
  },
  {
    "text": "so as I was hinting I mean this system was starting to show its limit uh the",
    "start": "259220",
    "end": "264479"
  },
  {
    "text": "way we're building Docker images it's what the last workload running outside of kubernetes which was starting to be a",
    "start": "264479",
    "end": "270240"
  },
  {
    "text": "pain for the team managing it because everything else was managed with a single team by a single team doing",
    "start": "270240",
    "end": "275699"
  },
  {
    "text": "everything on kubernetes and but this team had to manage dedicated instances outside of kubernetes to for these",
    "start": "275699",
    "end": "281940"
  },
  {
    "text": "workloads it it also requires investing in this",
    "start": "281940",
    "end": "287280"
  },
  {
    "text": "Legacy platform right because we wanted to do military art builds and Native Ambience",
    "start": "287280",
    "end": "292620"
  },
  {
    "text": "um we need new Runners right which was not something we wanted to invest in and finally as I said before this was",
    "start": "292620",
    "end": "298979"
  },
  {
    "text": "building images raised a lot of concern in terms of security because your bills are basically roots on the on the",
    "start": "298979",
    "end": "305400"
  },
  {
    "text": "machine they run on this gets us to the main topic of the",
    "start": "305400",
    "end": "310979"
  },
  {
    "text": "presentation today which is well what if we could actually build images inside kubernetes it is very attractive right",
    "start": "310979",
    "end": "319500"
  },
  {
    "text": "so if you look at how people do this because many people have tried and tried to do it you have multiple ways the",
    "start": "319500",
    "end": "326520"
  },
  {
    "text": "first one is to use Docker in Docker so what you do is similar to what I was describing before which is you create a",
    "start": "326520",
    "end": "332880"
  },
  {
    "text": "kubernetes pod in which you mount the docker socket and from there you do local builds",
    "start": "332880",
    "end": "339000"
  },
  {
    "text": "you can also use Standalone Builders so Builders dedicated to build images inside kubernetes and I gave I give a",
    "start": "339000",
    "end": "344580"
  },
  {
    "text": "few examples and finally you can use a dedicated build demon and this is what buildkit is about",
    "start": "344580",
    "end": "351780"
  },
  {
    "text": "so can you can we use can we use this option as you can as I'm sure you've guessed the first one was uh a no-go",
    "start": "351780",
    "end": "358620"
  },
  {
    "text": "from the start there was no way we would give uh build pods access to being root",
    "start": "358620",
    "end": "363660"
  },
  {
    "text": "on the on the kubernetes Node the second one Standard Builders uh actually worked pretty well and",
    "start": "363660",
    "end": "369780"
  },
  {
    "text": "something we um we we try them and they work but they were a bit more complex to",
    "start": "369780",
    "end": "375120"
  },
  {
    "text": "use because you had if you want to do multi-arch images it means you have to distribute jobs you need to run one job",
    "start": "375120",
    "end": "380880"
  },
  {
    "text": "on x86 nodes one job on arm nodes and one job to assemble the multi-arch image",
    "start": "380880",
    "end": "386220"
  },
  {
    "text": "and push it to the registry so it works but it's more complex buildkit D although the build demon was",
    "start": "386220",
    "end": "393000"
  },
  {
    "text": "very attractive to us because well the ux is great right you you can use the",
    "start": "393000",
    "end": "398160"
  },
  {
    "text": "same build X command to build locally on your laptop to build on a dedicated instance Builder and to build with",
    "start": "398160",
    "end": "404039"
  },
  {
    "text": "remote Builders allowing native builds so this is what we're going to focus on today",
    "start": "404039",
    "end": "410720"
  },
  {
    "text": "so what would this look like like let's get back to our built-in for running in kubernetes",
    "start": "410880",
    "end": "416940"
  },
  {
    "text": "so well what we wanted to achieve is simply this right when when a job is to",
    "start": "416940",
    "end": "422160"
  },
  {
    "text": "build a new image what what we want to do is one of the worker is going to run the build it's going to do a Docker",
    "start": "422160",
    "end": "428039"
  },
  {
    "text": "build X build command and contact the build kit the demon and do the build",
    "start": "428039",
    "end": "433740"
  },
  {
    "text": "what is nice is because it's remote built and build kit support build ex supports it we can actually have demons",
    "start": "433740",
    "end": "440039"
  },
  {
    "text": "running on x86 and demons running on arm nodes and build X is able to build uh to",
    "start": "440039",
    "end": "445919"
  },
  {
    "text": "to use the remote Builders to build the native image on the next 86 node and a native image on an arm node assemble",
    "start": "445919",
    "end": "452460"
  },
  {
    "text": "them and create a multi-arch image of course we wanted to make this safe",
    "start": "452460",
    "end": "458340"
  },
  {
    "text": "and as as you know the main challenge uh with with Building images is most of the",
    "start": "458340",
    "end": "464400"
  },
  {
    "text": "time it requires being very privileged right because you have to install packages for instance which requires being root",
    "start": "464400",
    "end": "471000"
  },
  {
    "text": "but what we want you to achieve is root lesbiance right because we don't want containers to run as roots because when",
    "start": "471000",
    "end": "477120"
  },
  {
    "text": "you do this if there's a container Escape you end up with workloads that can actually do things on the on the",
    "start": "477120",
    "end": "482220"
  },
  {
    "text": "host so what do we mean by root lesbians well it's built where the main demon inside",
    "start": "482220",
    "end": "488759"
  },
  {
    "text": "kubernetes is running as non-root right as the normal user however as I was",
    "start": "488759",
    "end": "494099"
  },
  {
    "text": "saying before we also need to be rude to run some commands and this is where user namespace come come into play right a",
    "start": "494099",
    "end": "501180"
  },
  {
    "text": "user namespace is a way to simulate a root user but you're not root in on the",
    "start": "501180",
    "end": "507300"
  },
  {
    "text": "host you just root in this limited namespace with limited capability and user namespace are very powerful and",
    "start": "507300",
    "end": "513659"
  },
  {
    "text": "they interact with many low-level candle implementations like capability mounts or security modules",
    "start": "513659",
    "end": "519899"
  },
  {
    "text": "if you're curious about how this works there's this great presentation from Arc Hero at kubecon in 2019 where he",
    "start": "519899",
    "end": "525779"
  },
  {
    "text": "explained exactly how this works so to give you a very quick overview",
    "start": "525779",
    "end": "531420"
  },
  {
    "text": "this is how it looks like you have a built it worker the pid1 is running as",
    "start": "531420",
    "end": "537260"
  },
  {
    "text": "uid1000 so and then privileged because you so that's completely fine exactly what we want and then everything else is running on a",
    "start": "537260",
    "end": "544680"
  },
  {
    "text": "username space and the uid is zero but I put a star because it's not really zero it's zero inside this namespace but it's",
    "start": "544680",
    "end": "552060"
  },
  {
    "text": "not true on the host a very quick example it's very easy to",
    "start": "552060",
    "end": "557160"
  },
  {
    "text": "to simulate if you want to try it on the Linux machine this command will create a username space and in there you can see",
    "start": "557160",
    "end": "563880"
  },
  {
    "text": "where root in the namespace but we can't touch a file that requires being a root",
    "start": "563880",
    "end": "569519"
  },
  {
    "text": "on the host so that's why the touch Etsy X fails because we just root in this",
    "start": "569519",
    "end": "574680"
  },
  {
    "text": "time space we're not root on the host we can't do something that requires root permission on the host",
    "start": "574680",
    "end": "580380"
  },
  {
    "text": "and if we touch a file we can't we can modify you we say that it belongs to root in the namespace but if we exit the",
    "start": "580380",
    "end": "587880"
  },
  {
    "text": "namespace the file actually belongs to uid1000 right so this is how the magic",
    "start": "587880",
    "end": "593459"
  },
  {
    "text": "works so this is the the the main intro now",
    "start": "593459",
    "end": "598860"
  },
  {
    "text": "we're going to Deputy to interesting and fun things um to be to be fair when we started",
    "start": "598860",
    "end": "604019"
  },
  {
    "text": "working with buildkit everything mostly works right more than 80 of the builds just worked out out of the box",
    "start": "604019",
    "end": "611880"
  },
  {
    "text": "but today we're going to focus on the 20 that were interesting because otherwise with the fun right",
    "start": "611880",
    "end": "619399"
  },
  {
    "text": "so we're going to present to you like three different issues and we're going to go into increasing complexity so the",
    "start": "619440",
    "end": "626339"
  },
  {
    "text": "first one uh is well actually simple enough it took us only a few a few hours to understand what was happening",
    "start": "626339",
    "end": "633839"
  },
  {
    "text": "so this issue started with this extremely complex Docker file right it's we're just getting an image from a",
    "start": "633839",
    "end": "640680"
  },
  {
    "text": "public registry and running Echo test what could go wrong I mean this feels like something that should work right",
    "start": "640680",
    "end": "648420"
  },
  {
    "text": "well when we run this inside our rootless building environment here is",
    "start": "648420",
    "end": "653940"
  },
  {
    "text": "what we got so that was of course very surprising because this is like the most basic Docker file you can use",
    "start": "653940",
    "end": "660180"
  },
  {
    "text": "and something that's interesting is we've got an operation not permitted message but it says something about mounts so",
    "start": "660180",
    "end": "666779"
  },
  {
    "text": "something might be happening with the file system so that's pretty surprising let's look",
    "start": "666779",
    "end": "673680"
  },
  {
    "text": "into it so what we wanted to understand is what was happening so what we did is",
    "start": "673680",
    "end": "678839"
  },
  {
    "text": "we s traced the build kit D Daemon and we started the build and we looked for",
    "start": "678839",
    "end": "684140"
  },
  {
    "text": "permission errors right and this one is actually pretty interesting right we",
    "start": "684140",
    "end": "690120"
  },
  {
    "text": "have this command that is trying to set an extended attribute and it's actually this SC Linux",
    "start": "690120",
    "end": "696000"
  },
  {
    "text": "attribute and it's failing and well I made the joke about it's always DNS because I tend to talk about",
    "start": "696000",
    "end": "702060"
  },
  {
    "text": "networking issues and to be fair it's often DNS but it's also quite often SC Linux and the only thing I need I know",
    "start": "702060",
    "end": "708180"
  },
  {
    "text": "how to do with SC Linux is how to disable it I'm sorry",
    "start": "708180",
    "end": "712940"
  },
  {
    "text": "foreign so I mean we had a very good inside a very good idea what might be happening",
    "start": "713339",
    "end": "718860"
  },
  {
    "text": "and and so what we did is we downloaded the layers of the image extracted the turbo and look at the content of the",
    "start": "718860",
    "end": "725040"
  },
  {
    "text": "turbo and as we suspected there's actually SC Linux Libor labels on the",
    "start": "725040",
    "end": "730380"
  },
  {
    "text": "files right and it turns out if your root on a host",
    "start": "730380",
    "end": "737120"
  },
  {
    "text": "user namespace you can modify the security context of a file this is what we do at the top of the slide",
    "start": "737120",
    "end": "743399"
  },
  {
    "text": "however if you're in a username space which is the second part of the slide and we're entering the username space",
    "start": "743399",
    "end": "749640"
  },
  {
    "text": "used by Bill kit D we can't modify the SC Linux attribute of a file right and",
    "start": "749640",
    "end": "755459"
  },
  {
    "text": "the kernel disallow it you can't do it if you're in a username space which makes sense",
    "start": "755459",
    "end": "761899"
  },
  {
    "text": "so this is uh the issue that we open an issue Upstream to be fair there's no",
    "start": "762000",
    "end": "767399"
  },
  {
    "text": "magic nothing we can really do but it's pretty easy to mitigate right either you remove the SC Linux",
    "start": "767399",
    "end": "773880"
  },
  {
    "text": "attributes by pulling and pushing the file or you use an image without any SC",
    "start": "773880",
    "end": "778980"
  },
  {
    "text": "Linux label which to be fair is something I would recommend you do and we were looking at that because this one",
    "start": "778980",
    "end": "784079"
  },
  {
    "text": "was an upstream image and the one just the release just after when we're using actually didn't have the labels anymore",
    "start": "784079",
    "end": "791480"
  },
  {
    "text": "let's move to issue number two so this one as you're going to see was slightly",
    "start": "791940",
    "end": "797579"
  },
  {
    "text": "more complex and and took us a few days to understand",
    "start": "797579",
    "end": "801800"
  },
  {
    "text": "so the docker file is a bit more complex but once again no rocket science right we just downloading a depth file and",
    "start": "803160",
    "end": "810720"
  },
  {
    "text": "we're trying to install it and of course as before this works perfectly fine if you do Docker build it",
    "start": "810720",
    "end": "817019"
  },
  {
    "text": "works perfectly fine if you use build kit in root mode however when you use buildkit in",
    "start": "817019",
    "end": "823019"
  },
  {
    "text": "rootless mode and you do exactly this for this specific app the build times out",
    "start": "823019",
    "end": "828899"
  },
  {
    "text": "so because uh we are very scientific we retry it right",
    "start": "828899",
    "end": "834360"
  },
  {
    "text": "and this time it failed again but it felt in a very different way it fell with an error saying well",
    "start": "834360",
    "end": "840959"
  },
  {
    "text": "address already news that's very weird so at that point where we're like let's",
    "start": "840959",
    "end": "846480"
  },
  {
    "text": "try and understand what's happened what's happening so we tried again",
    "start": "846480",
    "end": "852079"
  },
  {
    "text": "well this site was consistent at least we're seeing the same error address already news",
    "start": "852839",
    "end": "858899"
  },
  {
    "text": "so it was very confusing to us so what we did is said well let's try from scratch let's delete the build keypad",
    "start": "858899",
    "end": "865620"
  },
  {
    "text": "and try again well this time the build times out okay we're back to what we had at the",
    "start": "865620",
    "end": "871500"
  },
  {
    "text": "beginning well let's try again this time it fails with the same thing",
    "start": "871500",
    "end": "877079"
  },
  {
    "text": "so at least it's consistent with we have a way of repeating the values in a way that is reproducible but doesn't really",
    "start": "877079",
    "end": "883740"
  },
  {
    "text": "make sense yet so let's debug um so we use this this with this way to",
    "start": "883740",
    "end": "890880"
  },
  {
    "text": "debug right or which is pretty simple we just added netstat at the beginning and at the end of the command to see what",
    "start": "890880",
    "end": "896880"
  },
  {
    "text": "was happening and when we start with the new build keypad the first let's start show no broadband which is very expected",
    "start": "896880",
    "end": "903720"
  },
  {
    "text": "but the second one shows that the the pot is is Bound By by the abdomen and",
    "start": "903720",
    "end": "910680"
  },
  {
    "text": "the build hangs okay that's what so maybe package installation is starting a demon right",
    "start": "910680",
    "end": "915839"
  },
  {
    "text": "it happens sometimes let's do the second build when we do the second build this time netstat is",
    "start": "915839",
    "end": "922260"
  },
  {
    "text": "showing that the pot is bound and package installation fails with address already news",
    "start": "922260",
    "end": "928500"
  },
  {
    "text": "so we're getting somewhere right it looks like package installation is starting a demon and it looks like the",
    "start": "928500",
    "end": "934500"
  },
  {
    "text": "demon is still running when we do the second build which makes little sense because it's a completely separate build",
    "start": "934500",
    "end": "941720"
  },
  {
    "text": "so can we reproduce this by using a different method",
    "start": "942779",
    "end": "947820"
  },
  {
    "text": "so we use this very simple reproducer so you have the docker file on the top left of the slide and the script on the top",
    "start": "947820",
    "end": "955019"
  },
  {
    "text": "right so it's pretty simple we just start from Ubuntu we had the script we run the script and we call the script is",
    "start": "955019",
    "end": "961440"
  },
  {
    "text": "done and as you can see here everything works fine except we never get to the last",
    "start": "961440",
    "end": "967500"
  },
  {
    "text": "line of the docker file because the build hangs so exactly what we're saying before so it's a good thing we've",
    "start": "967500",
    "end": "973260"
  },
  {
    "text": "reproduced what seems to happen is well",
    "start": "973260",
    "end": "979019"
  },
  {
    "text": "if we looked into the Container we actually see sleep still running which is what we suspected before right",
    "start": "979019",
    "end": "985440"
  },
  {
    "text": "remember some map was still running and that's why the port was bound so it seemed that the process is leaked or and",
    "start": "985440",
    "end": "991320"
  },
  {
    "text": "never stopped so let's let's look exactly at what's happening under the hood so this is the",
    "start": "991320",
    "end": "996959"
  },
  {
    "text": "anatomy of the build kit worker so we have the bilkit demon when we start the build build decks is",
    "start": "996959",
    "end": "1004040"
  },
  {
    "text": "going to do an exec in the Pod it's going to start the build steps so here it's going to run bash bash is going to",
    "start": "1004040",
    "end": "1010759"
  },
  {
    "text": "run slip in the background and what's important here and we're",
    "start": "1010759",
    "end": "1015800"
  },
  {
    "text": "going to come back to this later is there's no process sandbox we can see all the processes uh in the container so",
    "start": "1015800",
    "end": "1021560"
  },
  {
    "text": "if you exec into this pod and run PS we see our build step but also we see build",
    "start": "1021560",
    "end": "1027079"
  },
  {
    "text": "key D we'll test kit we see we see everything and when when bash exits so bash is not",
    "start": "1027079",
    "end": "1034880"
  },
  {
    "text": "there anymore the build hangs and the process is still there and never cleaned up",
    "start": "1034880",
    "end": "1040720"
  },
  {
    "text": "so at that point we're like well we got curious right what has what happens if we actually kill sleep inside this uh",
    "start": "1040720",
    "end": "1047900"
  },
  {
    "text": "hanging uh build build pod well we were able to kill it but it was never garbage",
    "start": "1047900",
    "end": "1053960"
  },
  {
    "text": "collected because it's and it became a zombie which was also kind of interesting to us so",
    "start": "1053960",
    "end": "1060500"
  },
  {
    "text": "at this moment we took a step back um how does it work usually so build step use usually run in a process",
    "start": "1060500",
    "end": "1066500"
  },
  {
    "text": "sandbox and when the step finishes all the process inside the sandbox are killed",
    "start": "1066500",
    "end": "1072559"
  },
  {
    "text": "however in rootless mode we then build kit with this flag that is very clear like this flag says well you don't get a",
    "start": "1072559",
    "end": "1080419"
  },
  {
    "text": "process sandbox and because we don't have a Sandbox we can't keep track of all the processes starting during the",
    "start": "1080419",
    "end": "1086059"
  },
  {
    "text": "build and we can't clean them and we can really clean them up so this got us two but why do we need",
    "start": "1086059",
    "end": "1092240"
  },
  {
    "text": "this flag and the reason we need this flag is because of the way process work in",
    "start": "1092240",
    "end": "1099020"
  },
  {
    "text": "containers so when you create a container you have your own process but for security",
    "start": "1099020",
    "end": "1105140"
  },
  {
    "text": "reasons every runtime is uh every single runtime is not going to give you a full",
    "start": "1105140",
    "end": "1111140"
  },
  {
    "text": "proc FS it's going to give you a limited process where some of the directory in slack product will be either masked",
    "start": "1111140",
    "end": "1118460"
  },
  {
    "text": "which means it's going to be an empty directory or made read only so you you can't",
    "start": "1118460",
    "end": "1124940"
  },
  {
    "text": "modify things system-wide right and and that makes sense that's for security reason we don't want to expose",
    "start": "1124940",
    "end": "1131480"
  },
  {
    "text": "too much things to containers and we don't want containers to modify things on the host",
    "start": "1131480",
    "end": "1136700"
  },
  {
    "text": "however when you do this so you're in a container you have a proc which is",
    "start": "1136700",
    "end": "1142100"
  },
  {
    "text": "partially masked for security reasons if you want to create a new process which is what we would need to do to",
    "start": "1142100",
    "end": "1148940"
  },
  {
    "text": "create a Sandbox for our build step we actually can't because there's a Kernel check that's called Mount to",
    "start": "1148940",
    "end": "1155600"
  },
  {
    "text": "revealing which is verifying if you the process you have access to is partially masked or not and if it is partially",
    "start": "1155600",
    "end": "1162559"
  },
  {
    "text": "masked it won't let you create a new proc FS and that's why we actually need our",
    "start": "1162559",
    "end": "1168080"
  },
  {
    "text": "worker to not try and and create sandbox for the processes and that's why all the processes are seen inside the build kit",
    "start": "1168080",
    "end": "1175100"
  },
  {
    "text": "process namespace in in conclusion I mean there's no real",
    "start": "1175100",
    "end": "1180740"
  },
  {
    "text": "solution to date we we chatted about it with maintenance in this issue extensively and there's no real way to",
    "start": "1180740",
    "end": "1186320"
  },
  {
    "text": "do it uh there are potentially multiple mitigations the one we use we're using for now is we're making sure that our",
    "start": "1186320",
    "end": "1193940"
  },
  {
    "text": "Docker files are not certain demons in the background or if they do we explicitly stop them so that's easy",
    "start": "1193940",
    "end": "1199880"
  },
  {
    "text": "enough something that could be interesting in the future is kubernetes expose a notion",
    "start": "1199880",
    "end": "1205760"
  },
  {
    "text": "that is called proc man type where you can tell that a specific container will",
    "start": "1205760",
    "end": "1210919"
  },
  {
    "text": "have a process that is not masked so fully accessible which means if you remember that mount to revealing will be",
    "start": "1210919",
    "end": "1218419"
  },
  {
    "text": "okay and we will be able to create a new proc FS for our build step inside the sandbox inside the container sorry so",
    "start": "1218419",
    "end": "1226100"
  },
  {
    "text": "that's extremely promising but it's the feature has been in the alpha in kubernetes since 1.12 so we're not",
    "start": "1226100",
    "end": "1232580"
  },
  {
    "text": "exactly sure if it's going to uh to BG at some point we could also use jobs for",
    "start": "1232580",
    "end": "1237980"
  },
  {
    "text": "bills where we use um where the build key demon would be used for a single build which would be",
    "start": "1237980",
    "end": "1244820"
  },
  {
    "text": "which would avoid this issue of course I mean there are some security limitations because what I didn't see what I didn't",
    "start": "1244820",
    "end": "1252320"
  },
  {
    "text": "show you before is if build key D can be used to run multiple build steps at the same time so inside the bilkid Daemon",
    "start": "1252320",
    "end": "1259700"
  },
  {
    "text": "you can actually have processes for different build steps at the same time in the same process in the same set of",
    "start": "1259700",
    "end": "1265700"
  },
  {
    "text": "processes and of course it could lead to processes a building process from other builds so not too big of an issue based",
    "start": "1265700",
    "end": "1274220"
  },
  {
    "text": "on that idea and this gets us to the last and and third issue which is the most complex",
    "start": "1274220",
    "end": "1280100"
  },
  {
    "text": "one okay yeah so our last talk was uh at kubecon was ghost in the runtime uh we",
    "start": "1280100",
    "end": "1286460"
  },
  {
    "text": "like ghosts so this time ghosts in the file system um so we're just going to build a go",
    "start": "1286460",
    "end": "1291740"
  },
  {
    "text": "program so here it's the local volume provisioner uh fairly straightforward we clone the repository check out a",
    "start": "1291740",
    "end": "1298580"
  },
  {
    "text": "specific tag and then run go build what could possibly go wrong",
    "start": "1298580",
    "end": "1304280"
  },
  {
    "text": "well we get a compilation error uh consistent read redeclared uh it's",
    "start": "1304280",
    "end": "1310159"
  },
  {
    "text": "clearly declared in two files here read.go and consistent read.go but the strange thing is",
    "start": "1310159",
    "end": "1315200"
  },
  {
    "text": "when you build this yourself on your laptop or in a Docker build uh not in",
    "start": "1315200",
    "end": "1320600"
  },
  {
    "text": "rootless it works perfectly fine so what's happening let's have a look at the directory",
    "start": "1320600",
    "end": "1326659"
  },
  {
    "text": "contents well indeed in this vendor directory we have both files consistent",
    "start": "1326659",
    "end": "1331700"
  },
  {
    "text": "read and read so the compilation error is normal at this",
    "start": "1331700",
    "end": "1336799"
  },
  {
    "text": "point but how did we get in the state because in the master Branch you just",
    "start": "1336799",
    "end": "1342500"
  },
  {
    "text": "have read.go and at the tag we have just consistent read.gov so we clearly shouldn't have these two files at the same time",
    "start": "1342500",
    "end": "1349480"
  },
  {
    "text": "so we check at each layer um the git clone shows that we have read.go that's expected the checkout the",
    "start": "1349480",
    "end": "1357260"
  },
  {
    "text": "tag shows that we have only consistent read.go so that's fine too but we've already seen that in the end that the",
    "start": "1357260",
    "end": "1363440"
  },
  {
    "text": "next step we have both files for some reason so something's wrong with the file system here what's what's going on",
    "start": "1363440",
    "end": "1370760"
  },
  {
    "text": "so we use overlay FS as our snapshotter for for builds this is a fairly common",
    "start": "1370760",
    "end": "1376580"
  },
  {
    "text": "uh file system to be using in this situation and the way overlay FS works is that",
    "start": "1376580",
    "end": "1382280"
  },
  {
    "text": "it's what's known as a union file system so the idea is you have a set of directories that are the base and you",
    "start": "1382280",
    "end": "1389960"
  },
  {
    "text": "want to expose a mount point where changes can be made but without affecting the the original files and so",
    "start": "1389960",
    "end": "1395659"
  },
  {
    "text": "what overlayfs does is it has an intermediate or what we call the upper layer which records the changes that",
    "start": "1395659",
    "end": "1402080"
  },
  {
    "text": "have occurred on the file system that's exposed to to processes through the mount point and so for instance a file that's",
    "start": "1402080",
    "end": "1409520"
  },
  {
    "text": "deleted will be marked in the change layer the upper layer as a tombstone",
    "start": "1409520",
    "end": "1414860"
  },
  {
    "text": "file so that's a special character device file major zero minor zero and that will serve to mask the file that's",
    "start": "1414860",
    "end": "1421460"
  },
  {
    "text": "in the lower directories and um and so that it doesn't appear in the in the mount Point any longer if the",
    "start": "1421460",
    "end": "1427760"
  },
  {
    "text": "file's been removed um you also have for instance directories in the upper and lower",
    "start": "1427760",
    "end": "1433340"
  },
  {
    "text": "layers combined so that the the mount Point exposes the the combination of the",
    "start": "1433340",
    "end": "1438860"
  },
  {
    "text": "changes and the original files depending on files that are masked changed whatever",
    "start": "1438860",
    "end": "1444820"
  },
  {
    "text": "so that's all very good let's try and reproduce the steps uh of the of build kit here so first we",
    "start": "1444919",
    "end": "1451520"
  },
  {
    "text": "unshare the username space that's uh what buildkit is doing that's because we're running in rootless",
    "start": "1451520",
    "end": "1457220"
  },
  {
    "text": "we create some directories uh to to provision our overlay file system so we",
    "start": "1457220",
    "end": "1464059"
  },
  {
    "text": "have layer one which is the lower layer where we're going to do the git clone then we have a uh the layer 2 which will",
    "start": "1464059",
    "end": "1471860"
  },
  {
    "text": "be our Mount points that we will Expose and we have the layer 2 diff which is going to be the changes that occur uh",
    "start": "1471860",
    "end": "1478760"
  },
  {
    "text": "through the overlay file system and so for in particular when we actually do the git checkout after mounting the file",
    "start": "1478760",
    "end": "1483799"
  },
  {
    "text": "system the L2 diff directory is going to record the changes that are made",
    "start": "1483799",
    "end": "1489879"
  },
  {
    "text": "so that's all very good we look at what we end up with in each of the directories and we see so layer one the",
    "start": "1490159",
    "end": "1496880"
  },
  {
    "text": "checkout we have read.go fine Layer Two difference we have consistent",
    "start": "1496880",
    "end": "1502159"
  },
  {
    "text": "read.go that's expected that's the new file and in the mount Point that's exposed we see only consistent read.go",
    "start": "1502159",
    "end": "1509059"
  },
  {
    "text": "that's consistent with what we've seen before but it's uh we haven't reproduced the problem at this point",
    "start": "1509059",
    "end": "1516260"
  },
  {
    "text": "so now let's pile on the step three of our build uh where we list the directory contents",
    "start": "1516260",
    "end": "1522020"
  },
  {
    "text": "because it's the equivalent of when we build and we get compiler error so we unpount the previous overlay file",
    "start": "1522020",
    "end": "1528020"
  },
  {
    "text": "system we provisioned some new directories for the uh the difference layer for for our step three the layer 3",
    "start": "1528020",
    "end": "1535760"
  },
  {
    "text": "directory which will be the mount point that we expose and we Mount this so one thing to note",
    "start": "1535760",
    "end": "1540799"
  },
  {
    "text": "here is that in the lower directories we actually have two directories because we have first the changes that were made by",
    "start": "1540799",
    "end": "1549020"
  },
  {
    "text": "the get checkout and then we have the base which is the git clone",
    "start": "1549020",
    "end": "1554500"
  },
  {
    "text": "um and we list the the files and we've reproduced the problem we we see both",
    "start": "1554840",
    "end": "1560900"
  },
  {
    "text": "files so clearly there's something wrong here so if you stack take a step back and",
    "start": "1560900",
    "end": "1567200"
  },
  {
    "text": "look at what we've done so we have a layer one where we do the git clone we then have an oval AFS where we do the",
    "start": "1567200",
    "end": "1574700"
  },
  {
    "text": "git checkout and so we see that in the difference layer we have consistent read.go and expose through the mount",
    "start": "1574700",
    "end": "1582020"
  },
  {
    "text": "point we've then piled on step three uh so we have an extra difference layer which is",
    "start": "1582020",
    "end": "1589520"
  },
  {
    "text": "not too important here and we have the mount point which is exposed which shows both files which is our problem",
    "start": "1589520",
    "end": "1595460"
  },
  {
    "text": "so at this point we begin to suspect that the problem is somewhere in the layer two difference directory",
    "start": "1595460",
    "end": "1600799"
  },
  {
    "text": "something's going on here and indeed one thing to note I mentioned earlier Tombstone files we've removed the",
    "start": "1600799",
    "end": "1606140"
  },
  {
    "text": "read.go file and yet we have no tombstone file in the listings so where is it well maybe we've missed",
    "start": "1606140",
    "end": "1613760"
  },
  {
    "text": "something and yes we have so in overlayfs there's actually an optimization for directories",
    "start": "1613760",
    "end": "1620179"
  },
  {
    "text": "which are where all this contents have been deleted and but the directory still exists you",
    "start": "1620179",
    "end": "1627679"
  },
  {
    "text": "have an opaque flag basically it avoids overlay FS from having to recurse and",
    "start": "1627679",
    "end": "1632779"
  },
  {
    "text": "subdirect in under layer directories if all the contents have been suppressed",
    "start": "1632779",
    "end": "1638419"
  },
  {
    "text": "it's an optimization but how does it work so",
    "start": "1638419",
    "end": "1644919"
  },
  {
    "text": "basically in our case there's uh the opacity that the opaque flag has been",
    "start": "1645440",
    "end": "1651440"
  },
  {
    "text": "set on the layer 2 diff directory and that is why we're not seeing the read.go any longer in the layer 2 uh Mount point",
    "start": "1651440",
    "end": "1661419"
  },
  {
    "text": "but how 'd work so what's done is that overlayfs sets an",
    "start": "1661580",
    "end": "1668240"
  },
  {
    "text": "extended attribute called trusted overlay opaque on the directory that it wants to mask or it wants to mask the",
    "start": "1668240",
    "end": "1674659"
  },
  {
    "text": "lower layers so can we see this fire this extended attribute so we do the operation in the",
    "start": "1674659",
    "end": "1682279"
  },
  {
    "text": "username space get file attributes and we've got nothing so that's interesting because",
    "start": "1682279",
    "end": "1688159"
  },
  {
    "text": "how come in step two then read.go is ending up being masked",
    "start": "1688159",
    "end": "1694340"
  },
  {
    "text": "if we can't see the extended attribute it shouldn't work",
    "start": "1694340",
    "end": "1698860"
  },
  {
    "text": "now if we rerun the same command but in the host username space the initial username space we do see the extended",
    "start": "1699860",
    "end": "1705620"
  },
  {
    "text": "attribute so it is being set but that also is a bit strange because",
    "start": "1705620",
    "end": "1711260"
  },
  {
    "text": "trusted the trusted namespace of extended attributes is actually subject to uh permissions you can only set a",
    "start": "1711260",
    "end": "1719240"
  },
  {
    "text": "trusted extended attributes if you are capsys admin you have the system administrator capability in the host",
    "start": "1719240",
    "end": "1726760"
  },
  {
    "text": "username space which is not the case in our overlayfs sequence here in rootless",
    "start": "1726760",
    "end": "1732440"
  },
  {
    "text": "so we shouldn't be able to set that extended attribute and yet we have",
    "start": "1732440",
    "end": "1737659"
  },
  {
    "text": "so we have a bunch of mysteries how come trusted overlay opaque is being set",
    "start": "1737659",
    "end": "1742760"
  },
  {
    "text": "because we shouldn't have the permissions to do so and when the directory that is flagged",
    "start": "1742760",
    "end": "1748820"
  },
  {
    "text": "as opaque is uh mounted as an upper directory",
    "start": "1748820",
    "end": "1754100"
  },
  {
    "text": "the problem doesn't reproduce but when it's a lower directory it does reproduce",
    "start": "1754100",
    "end": "1760480"
  },
  {
    "text": "so at this point we resort to Kernel function tracing we rerun the git",
    "start": "1761419",
    "end": "1767179"
  },
  {
    "text": "checkout step with kernel function tracing and we look for the operation where the extended attribute is set and",
    "start": "1767179",
    "end": "1773779"
  },
  {
    "text": "there we realize that a function that's being called is VFS set extended attributes no perm and this makes us",
    "start": "1773779",
    "end": "1780919"
  },
  {
    "text": "suspect that well the credential checks are actually being bypassed in this scenario for some reason which we don't",
    "start": "1780919",
    "end": "1786679"
  },
  {
    "text": "quite understand so looking at the source code and uh the the git commence we realize that um on",
    "start": "1786679",
    "end": "1793520"
  },
  {
    "text": "the Kernel that we're using and Ubuntu kernel there was some work done to make",
    "start": "1793520",
    "end": "1798740"
  },
  {
    "text": "uh overlay file systems work in username spaces and the change that was made was",
    "start": "1798740",
    "end": "1803960"
  },
  {
    "text": "that indeed the credentials check on setting extended attributes for trusted",
    "start": "1803960",
    "end": "1809960"
  },
  {
    "text": "uh opaque overlay and uh for removing them were bypassed so you don't have a",
    "start": "1809960",
    "end": "1815120"
  },
  {
    "text": "Credential Check but it's also interesting to note that there was no change made for the get",
    "start": "1815120",
    "end": "1822220"
  },
  {
    "text": "so we still don't quite understand certain things we do understand that",
    "start": "1823039",
    "end": "1829159"
  },
  {
    "text": "we're having the attribute set um",
    "start": "1829159",
    "end": "1834320"
  },
  {
    "text": "but we can't read it so that's why in step three we see both files because we can't read the extended",
    "start": "1834320",
    "end": "1841580"
  },
  {
    "text": "attribute so the opacity is not being honored fine but in step two",
    "start": "1841580",
    "end": "1847299"
  },
  {
    "text": "why don't we have the same problem because we can't read that extended attribute either",
    "start": "1847299",
    "end": "1852500"
  },
  {
    "text": "and it turns out that well if we think about it fast systems do a lot of caching",
    "start": "1852500",
    "end": "1858200"
  },
  {
    "text": "so maybe if we drop the caches we'll see something different",
    "start": "1858200",
    "end": "1864340"
  },
  {
    "text": "so again we reproduce our case we reach the point this is step two we reach the point where we list the files and we see",
    "start": "1864440",
    "end": "1870260"
  },
  {
    "text": "consistent read.go only so opacity somehow is being respect is being honored even though we don't expect it",
    "start": "1870260",
    "end": "1875600"
  },
  {
    "text": "to be we now drop the caches and lo and behold the two files are there",
    "start": "1875600",
    "end": "1882140"
  },
  {
    "text": "so in fact what's happening is that in addition to the extended attributes there's an opacity flag that's being set",
    "start": "1882140",
    "end": "1888080"
  },
  {
    "text": "on the directory entries in the file cache and that so long as that",
    "start": "1888080",
    "end": "1893779"
  },
  {
    "text": "um the D entry is in memory and the file doesn't the directory doesn't need to be re-read from disk we're able to honor",
    "start": "1893779",
    "end": "1901159"
  },
  {
    "text": "the opacity so in short the kernel we're using added a patch to",
    "start": "1901159",
    "end": "1908179"
  },
  {
    "text": "make user overlay FS work inside username spaces but it was a partial",
    "start": "1908179",
    "end": "1914480"
  },
  {
    "text": "change it only changed the set and the remove of the extended attribute and thanks to caching well sometimes the",
    "start": "1914480",
    "end": "1921679"
  },
  {
    "text": "opacity is honored and sometimes it isn't which leads to some rather interesting behaviors",
    "start": "1921679",
    "end": "1928360"
  },
  {
    "text": "now the nice thing is that actually in kernel 511 a new option was introduced",
    "start": "1928399",
    "end": "1933440"
  },
  {
    "text": "to overlayfs mount options called user exact and what this does is it changes the namespace that's used for the",
    "start": "1933440",
    "end": "1939679"
  },
  {
    "text": "opacity and other overlayfs uh um Extended attributes and it makes it",
    "start": "1939679",
    "end": "1945500"
  },
  {
    "text": "possible for any user to set the extended attributes simply because they're not any longer in the trusted",
    "start": "1945500",
    "end": "1951919"
  },
  {
    "text": "namespace the other nice thing is the build kit actually the overlay implementation adds",
    "start": "1951919",
    "end": "1958820"
  },
  {
    "text": "user accept support when it's available and so all we had to do was wait for",
    "start": "1958820",
    "end": "1964039"
  },
  {
    "text": "kernel 511 to be available for our uh distribution for Ubuntu and then simply",
    "start": "1964039",
    "end": "1971419"
  },
  {
    "text": "roll it out to our nodes for new our nodes and from that point it just worked",
    "start": "1971419",
    "end": "1977440"
  },
  {
    "text": "so at this point we've solved I think pretty much all our problems",
    "start": "1977659",
    "end": "1982820"
  },
  {
    "text": "with Building images and so we have some pretty good results as Lauren said we",
    "start": "1982820",
    "end": "1987919"
  },
  {
    "text": "you know right from the the get-go we had something like 80 of the images were actually building fine with Bill kit in",
    "start": "1987919",
    "end": "1994039"
  },
  {
    "text": "rootless mode and really it was just a matter of getting past the last few hurdles",
    "start": "1994039",
    "end": "2000700"
  },
  {
    "text": "um starting with a mono repo for building images dedicated to building images was clearly very helpful here because it really you know sifted",
    "start": "2000700",
    "end": "2007120"
  },
  {
    "text": "through all the problems uh very fast um so it allowed us to decommission our",
    "start": "2007120",
    "end": "2012340"
  },
  {
    "text": "dedicated Docker Runners uh giving us you know easier known lifecycle management uh the the developer",
    "start": "2012340",
    "end": "2018760"
  },
  {
    "text": "experience team no longer needed to manage a dedicated set of Docker Runners and things like that and it helped us get native multi-arc",
    "start": "2018760",
    "end": "2026500"
  },
  {
    "text": "builds uh because well yeah emulation is way too slow so currently we have",
    "start": "2026500",
    "end": "2031720"
  },
  {
    "text": "several hundred distinct images that are being built on Cube or I mean all our",
    "start": "2031720",
    "end": "2036820"
  },
  {
    "text": "images are now built on Cube anyway and so this system is now handling more than",
    "start": "2036820",
    "end": "2042159"
  },
  {
    "text": "a thousand builds a day perfectly reliably and uh we're really happy with it",
    "start": "2042159",
    "end": "2047860"
  },
  {
    "text": "um so our messages are that bill kit you know is really good we we've had a very good experience with it",
    "start": "2047860",
    "end": "2053560"
  },
  {
    "text": "um it gives us remote builds it gives us multi-op images really easily um rootless is or was a little bit",
    "start": "2053560",
    "end": "2061118"
  },
  {
    "text": "bleeding edge um but you know with the changes in kernel 511 overlayfs in user namespaces",
    "start": "2061119",
    "end": "2068260"
  },
  {
    "text": "has become really uh very usable well it works fine um I think really the only problem we",
    "start": "2068260",
    "end": "2075820"
  },
  {
    "text": "still have slightly that you know that could affect us is the process sandboxing and so I think at some point",
    "start": "2075820",
    "end": "2081820"
  },
  {
    "text": "we'll have to check out the proc Mount unmasked option that Laura mentioned and",
    "start": "2081820",
    "end": "2087398"
  },
  {
    "text": "that's it thank you [Applause]",
    "start": "2087399",
    "end": "2093649"
  }
]
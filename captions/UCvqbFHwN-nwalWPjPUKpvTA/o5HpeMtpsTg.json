[
  {
    "text": "how are you everyone okay amazing hello everyone um we are extremely excited to",
    "start": "1480",
    "end": "8000"
  },
  {
    "text": "be here on cucon and talk about the second major version of remote right protocol in the pruse ecosystem and I",
    "start": "8000",
    "end": "14920"
  },
  {
    "text": "have to admit in a really context of distributed systems I personally have some some kind of weakness or respect",
    "start": "14920",
    "end": "21240"
  },
  {
    "text": "towards Network protocols and and apis and I would love to learn if you have the same feelings but to me designing",
    "start": "21240",
    "end": "27160"
  },
  {
    "text": "Network protocols for high volume data especially in open source pauses a lot of interesting questions how to make",
    "start": "27160",
    "end": "34000"
  },
  {
    "text": "this API extensible but also stable how to make it flexible and Powerful but",
    "start": "34000",
    "end": "39200"
  },
  {
    "text": "also simple efficient and consistent plus it takes really years to get it adopted and get feedback of whatever you",
    "start": "39200",
    "end": "45680"
  },
  {
    "text": "change um and also you have to think about you know Common network problems and disputed system problems challenges",
    "start": "45680",
    "end": "52039"
  },
  {
    "text": "like consistency and availability um so let's start with a short introduction to",
    "start": "52039",
    "end": "57280"
  },
  {
    "text": "the promit remote right protocols so Prim primary role of promus if you're",
    "start": "57280",
    "end": "62719"
  },
  {
    "text": "not familiar is to allow you to instrument collect store and query all your metrics and then do some kind of",
    "start": "62719",
    "end": "68880"
  },
  {
    "text": "work on top of that for example alerting dashboarding and so on however if you are familiar with pruse a bit more you",
    "start": "68880",
    "end": "75439"
  },
  {
    "text": "know that pritus also comes with those remote storage interfaces so why and",
    "start": "75439",
    "end": "80920"
  },
  {
    "text": "literally from the beginning of promit the developers like Julius faults 11 years ago um Issue Number 10 like very",
    "start": "80920",
    "end": "87560"
  },
  {
    "text": "very beginning when I was looking at it um we're thinking on how prudes can integrate with you know remote well like",
    "start": "87560",
    "end": "94159"
  },
  {
    "text": "different databases and back then there wasn't much there um I I found that there were mentions about inflex DB",
    "start": "94159",
    "end": "100600"
  },
  {
    "text": "integration open tdb um but still such need for remote right uh remote storage",
    "start": "100600",
    "end": "106320"
  },
  {
    "text": "integration shouldn't come as a surprise if you are familiar with promus um promus was and still is a single node",
    "start": "106320",
    "end": "113520"
  },
  {
    "text": "solution after all no built replication no buil clustering or so On By Design",
    "start": "113520",
    "end": "119920"
  },
  {
    "text": "this is why the younger Protocol remote read was introduced so any client can",
    "start": "119920",
    "end": "125000"
  },
  {
    "text": "ask for some historical retric samples in pritus format for example initially",
    "start": "125000",
    "end": "130080"
  },
  {
    "text": "it was it was to enable promql uh quer language and and quering capabilities",
    "start": "130080",
    "end": "135319"
  },
  {
    "text": "through promes against metrics stored in a different databases like in open tdb it wasn't long until re API the same",
    "start": "135319",
    "end": "144040"
  },
  {
    "text": "read API was also Exposed on promus itself right allowing long-term storage solutions like Thanos to effectively",
    "start": "144040",
    "end": "150800"
  },
  {
    "text": "query prom use for the fresh metric or row data in promit use format or for",
    "start": "150800",
    "end": "155840"
  },
  {
    "text": "proxies like promy um to transparently De duplicate and you know and hide High",
    "start": "155840",
    "end": "161360"
  },
  {
    "text": "availability replicas of promit uses however Pro probably the most nowadays used remote integration is the",
    "start": "161360",
    "end": "168720"
  },
  {
    "text": "older remote right protocol it allows any client um send metric samples in",
    "start": "168720",
    "end": "174519"
  },
  {
    "text": "promit use format from one place to another typically live streaming fresh metrics to centralize longterm storage",
    "start": "174519",
    "end": "181959"
  },
  {
    "text": "uh similar to read prome also support receiving the same uh Protocol remote right request so you can import really",
    "start": "181959",
    "end": "188840"
  },
  {
    "text": "any metrics uh from other places to promit now in may um this year promit",
    "start": "188840",
    "end": "195840"
  },
  {
    "text": "team released a new experimental version of remote R protocol called 20 and we",
    "start": "195840",
    "end": "200959"
  },
  {
    "text": "with colum had a pleasure to co- out or this version um so in this talk I would like you to know why remote TR 2 exists",
    "start": "200959",
    "end": "208560"
  },
  {
    "text": "uh what it enables and how we improved efficiency of of the whole protocol on the way despite more features and how",
    "start": "208560",
    "end": "215760"
  },
  {
    "text": "you can use it in production right now in PR to use and perhaps adopt in your tools integration but before that short",
    "start": "215760",
    "end": "222560"
  },
  {
    "text": "int introduction um I'm here with colum yeah uh hi everyone my name is Callum",
    "start": "222560",
    "end": "227720"
  },
  {
    "text": "I'm an engineer at calabs uh I maintain remote R I've been doing that for 4ish",
    "start": "227720",
    "end": "234120"
  },
  {
    "text": "years now I want to say um so I'm a Prometheus team member and uh I've been involved in protocol type stuff",
    "start": "234120",
    "end": "241280"
  },
  {
    "text": "basically since University uh my first internship I reverse engineered and reimplemented ADB for Android if",
    "start": "241280",
    "end": "247159"
  },
  {
    "text": "anybody's heard from that um outside of engineering stuff I spend most of the time just relaxing with my girlfriend",
    "start": "247159",
    "end": "252560"
  },
  {
    "text": "and my two dogs uh and I'm pretty happy I've managed to every day so far this year including today uh keep up with",
    "start": "252560",
    "end": "259639"
  },
  {
    "text": "studying Japanese yeah my name is BK bka and I work at Google I'm a tech lead for",
    "start": "259639",
    "end": "265720"
  },
  {
    "text": "Google cloud manag service for promus um I'm also prom Main maintainer Thanos maintainer um I maintain many go lank",
    "start": "265720",
    "end": "272840"
  },
  {
    "text": "mostly go lank libraries uh in open source I love go lank and and generally programming I'm active in the cncf I",
    "start": "272840",
    "end": "280199"
  },
  {
    "text": "wrote a book called officient go which is about goang and optimizations um and",
    "start": "280199",
    "end": "285479"
  },
  {
    "text": "also in my free time I recently I'm doing more uh Adventure motorcycling which is not always end up well ending",
    "start": "285479",
    "end": "291759"
  },
  {
    "text": "up well as you can see but that's why it's called Adventure um okay so you know remote ride has a new version right",
    "start": "291759",
    "end": "298600"
  },
  {
    "text": "let's dive on why this even happened um how is the second version you know helping prome and and you and users um",
    "start": "298600",
    "end": "306560"
  },
  {
    "text": "to answer this let's take a look on the history again almost exactly eight years",
    "start": "306560",
    "end": "312000"
  },
  {
    "text": "ago pritu merge an MVP of the remote right protocol leveraging the grpc",
    "start": "312000",
    "end": "317240"
  },
  {
    "text": "framework the protocol was extremely simple and generic uh it was generally a stateless protobuf requests with",
    "start": "317240",
    "end": "324440"
  },
  {
    "text": "unstructural labels and corresponding samples sent in order nothing else later",
    "start": "324440",
    "end": "330120"
  },
  {
    "text": "the grpc dependency was removed as the http2 and transfer protocol and the grpc",
    "start": "330120",
    "end": "335600"
  },
  {
    "text": "framework was were literally just released 2015 so many you know Cloud providers didn't even support uh support",
    "start": "335600",
    "end": "342319"
  },
  {
    "text": "it uh for example cloud provider load balancers uh and also remote TR protocol",
    "start": "342319",
    "end": "347600"
  },
  {
    "text": "semantics wasn't really benefici benefiting of from unique hp2 you know grpc features and it looks like this",
    "start": "347600",
    "end": "354680"
  },
  {
    "text": "simplification uh really was a good bet uh because organically through years remote ride got pretty impressive",
    "start": "354680",
    "end": "360199"
  },
  {
    "text": "adoption it allowed people to integrate with various Solutions and other monitoring systems vendors and tools um",
    "start": "360199",
    "end": "367479"
  },
  {
    "text": "it enabled new long-term storage uh solutions to be created even right it kind of started a a mini industry with",
    "start": "367479",
    "end": "373840"
  },
  {
    "text": "those Cloud manage pruse uh Services popping everywhere integrating with",
    "start": "373840",
    "end": "379120"
  },
  {
    "text": "existing promit setups and helping everyone overall it became remote right",
    "start": "379120",
    "end": "384680"
  },
  {
    "text": "became an important open source standard and all of this with a single protop file no no official specification",
    "start": "384680",
    "end": "390960"
  },
  {
    "text": "actually or even version pure organic grow and adoption and eventually it was kind of ridiculous right so only a year",
    "start": "390960",
    "end": "397479"
  },
  {
    "text": "ago uh we finally released the official remote right one specification that was kind of like retro specification",
    "start": "397479",
    "end": "403840"
  },
  {
    "text": "following a common RFC format and it out outlined important protocol details uh",
    "start": "403840",
    "end": "409160"
  },
  {
    "text": "Beyond protocol format right so also retri semantics backward compatibility and so on and really it was essential to",
    "start": "409160",
    "end": "416400"
  },
  {
    "text": "to even talk about any major improvements to the protocol right right the point is I'm trying to share here is",
    "start": "416400",
    "end": "423199"
  },
  {
    "text": "that one zero remote right we use nowadays is exactly the same as one",
    "start": "423199",
    "end": "428280"
  },
  {
    "text": "eight years ago and it's really both amazing and scary in the same time right it's really impressive because you know",
    "start": "428280",
    "end": "434520"
  },
  {
    "text": "that it didn't need to change a lot and allows such stability and adoption but also scary because you know ecosystem",
    "start": "434520",
    "end": "441400"
  },
  {
    "text": "evolved and there are new capabilities and features that would be nice to have there and the second point to realize is",
    "start": "441400",
    "end": "448039"
  },
  {
    "text": "that 8 years ago promit team decided that um to keep the both prom language",
    "start": "448039",
    "end": "453160"
  },
  {
    "text": "and remote right format close to the promit storage format right as opposed",
    "start": "453160",
    "end": "458240"
  },
  {
    "text": "to maybe taking some other formats Exposition format maybe influx DB you know replication format whatever it and",
    "start": "458240",
    "end": "464560"
  },
  {
    "text": "and this decision to tie into storage allowed the least amount of overhead when used with pruse which which allowed",
    "start": "464560",
    "end": "470599"
  },
  {
    "text": "seamless integration but also as a kind of interesting consequence we forced",
    "start": "470599",
    "end": "475879"
  },
  {
    "text": "remote storages like you know like even vendors or or open in open source to",
    "start": "475879",
    "end": "482120"
  },
  {
    "text": "adapt organically and spreading For Better or Worse promit simpler and",
    "start": "482120",
    "end": "487599"
  },
  {
    "text": "flexible prom you know schema less format patterns uh to The Wider ecosystem and users um and however you",
    "start": "487599",
    "end": "494319"
  },
  {
    "text": "know you might notice that promit storage you know constantly evolves this week we are releasing promit 3 and you",
    "start": "494319",
    "end": "500560"
  },
  {
    "text": "can join the session tomorrow about that um which expands on beyond beyond the original capabilities you know so many",
    "start": "500560",
    "end": "506680"
  },
  {
    "text": "years ago and as a result we have some Gap between what promit storage offers",
    "start": "506680",
    "end": "511879"
  },
  {
    "text": "and what our protocol offered for example prome team designed a new native histograms that give us more efficient",
    "start": "511879",
    "end": "519360"
  },
  {
    "text": "um you know flexible accurate and structured histograms and recently we ex",
    "start": "519360",
    "end": "524720"
  },
  {
    "text": "extended that um to also support custom buckets so which allows literally replacing classic histograms in place um",
    "start": "524720",
    "end": "533120"
  },
  {
    "text": "for efficiency and transac transactionality uh for some time we have also exemplars which allow metrics",
    "start": "533120",
    "end": "539040"
  },
  {
    "text": "to link link to other observability signals like traces um prome already have and stores metadata um which allow",
    "start": "539040",
    "end": "547160"
  },
  {
    "text": "you to quickly access help type and unit of your metrics incredibly useful to integrate with more type typed remote",
    "start": "547160",
    "end": "554040"
  },
  {
    "text": "storages as well as you know like have a powerful UI that autocompletes your metrics and and allows you to discover",
    "start": "554040",
    "end": "559680"
  },
  {
    "text": "your metrics um finally create a timestamp um this feature allows to improve uh rates and accuracy of rates",
    "start": "559680",
    "end": "566160"
  },
  {
    "text": "and generally uh counters and especially for short life um time series for",
    "start": "566160",
    "end": "571760"
  },
  {
    "text": "example like you know several Less jobs and batches those push push based metrics and finally utf8 um so you know",
    "start": "571760",
    "end": "579440"
  },
  {
    "text": "that that promus already supports in fre zero for compatibility with other metric Solutions and generally non- English um",
    "start": "579440",
    "end": "586399"
  },
  {
    "text": "people all of those reasons were were really solid solid reasons to kind of",
    "start": "586399",
    "end": "591560"
  },
  {
    "text": "motivate us to really look on the you know next version of remote storage um that will take advantage of those",
    "start": "591560",
    "end": "598120"
  },
  {
    "text": "features now of course PRI theme wasn't just lazy and like forgetting about this protocol uh in fact if you go to the",
    "start": "598120",
    "end": "605160"
  },
  {
    "text": "current protop file one z uh you see a lot of experimental fields which are not covered by the official one Zer spec and",
    "start": "605160",
    "end": "613200"
  },
  {
    "text": "um this was extremely extremely useful for development of this next version because you know when you notice um in",
    "start": "613200",
    "end": "619279"
  },
  {
    "text": "the closer ecosystem of promus all those project like cortex uh Thanos and mimir",
    "start": "619279",
    "end": "624480"
  },
  {
    "text": "all of those use this experimental Fields kind of YOLO Fields but we we kind of enable those new features early",
    "start": "624480",
    "end": "630760"
  },
  {
    "text": "and test them and develop um so we really gather a lot of data and production data on certain decisions",
    "start": "630760",
    "end": "637160"
  },
  {
    "text": "especially around metadata that column will explain later so with that we were ready to start thinking about the next",
    "start": "637160",
    "end": "643720"
  },
  {
    "text": "version of remote right uh right so btech is a little bit",
    "start": "643720",
    "end": "651240"
  },
  {
    "text": "ahead of what actually happened right so we eventually had all of these ideas of things that for sure should go into",
    "start": "651240",
    "end": "656959"
  },
  {
    "text": "remote right but the idea of uh making changes to the protocol format actually started a bit earlier I'll go into some",
    "start": "656959",
    "end": "663240"
  },
  {
    "text": "some detail there but uh it's good to keep in mind that we had some pretty uh",
    "start": "663240",
    "end": "668680"
  },
  {
    "text": "like high level goals that we wanted to maintain that we had from remote right version one for remote right version two",
    "start": "668680",
    "end": "675360"
  },
  {
    "text": "um the most important of which is that we want the protocol to be stateless we want it to be as easy as possible for",
    "start": "675360",
    "end": "680760"
  },
  {
    "text": "both senders and receivers to implement and for receivers for example to not have to cash a whole bunch of data",
    "start": "680760",
    "end": "686680"
  },
  {
    "text": "because the protocols uh Stay full in some way so um we're basically doubling down on that",
    "start": "686680",
    "end": "692200"
  },
  {
    "text": "decision we're keeping all of the same high level requirements High Lev goals that we had uh eight years",
    "start": "692200",
    "end": "699000"
  },
  {
    "text": "ago so uh the quick story um remote R 2",
    "start": "699000",
    "end": "704760"
  },
  {
    "text": "basically started as a hackathon project at graffan Labs um so about two years ago I took a week during one of our",
    "start": "704760",
    "end": "711000"
  },
  {
    "text": "hackathons and I knew that for some reasons I'll get into in a bit um there",
    "start": "711000",
    "end": "716360"
  },
  {
    "text": "was some inefficient inefficiencies in the protocol format um basically we were uh duplicating a lot of data via",
    "start": "716360",
    "end": "723360"
  },
  {
    "text": "prometheus's label model um and I wanted to see if I could make some changes there and then Benchmark whether or not",
    "start": "723360",
    "end": "728920"
  },
  {
    "text": "there was any performance improvements and acronal Labs as part of these hackathons we actually record demo",
    "start": "728920",
    "end": "734440"
  },
  {
    "text": "videos it's basically a requirement to record a video and and submit it and people can watch those um I don't",
    "start": "734440",
    "end": "740600"
  },
  {
    "text": "remember I think mik came in second or something like that uh but as part of that lots of other people at the company saw this video right and other Engineers",
    "start": "740600",
    "end": "747120"
  },
  {
    "text": "within the company were interested in this project they came me can I work on this with you and So eventually we get",
    "start": "747120",
    "end": "753399"
  },
  {
    "text": "to uh a full-fledged project right graphon Labs Engineers Prometheus open source team members uh people from",
    "start": "753399",
    "end": "760279"
  },
  {
    "text": "Community projects like Thanos open Telemetry stuff like that um and it's",
    "start": "760279",
    "end": "766959"
  },
  {
    "text": "it's a full-fledged project right we've got a slack Channel we have a b Lou sync call um and really without have have",
    "start": "766959",
    "end": "774279"
  },
  {
    "text": "without having had turned this into a like open source project as a community",
    "start": "774279",
    "end": "779480"
  },
  {
    "text": "um we wouldn't have been as successful as we were here right we really needed the input from other implementations of",
    "start": "779480",
    "end": "785240"
  },
  {
    "text": "remote right um in order for remote right to to be successful so that's how we got to where we",
    "start": "785240",
    "end": "790800"
  },
  {
    "text": "are so what does 2.0 actually do right what does it uh do better than one",
    "start": "790800",
    "end": "796639"
  },
  {
    "text": "Doo one of the main things we wanted to solve for was this paino of partial",
    "start": "796639",
    "end": "802000"
  },
  {
    "text": "rights so right now in 1.0 if you send the remote right request all you get",
    "start": "802000",
    "end": "807040"
  },
  {
    "text": "back is a response 200 that says says hey I accepted everything or an error saying I didn't like something right but",
    "start": "807040",
    "end": "814199"
  },
  {
    "text": "there's no indication of whether or not it accepted some of the data or what pieces of data it didn't accept right",
    "start": "814199",
    "end": "820240"
  },
  {
    "text": "and so uh in 2.0 we wanted to make that clear we wanted to have better definitions around what a partial right",
    "start": "820240",
    "end": "826760"
  },
  {
    "text": "is uh what a success is and uh what",
    "start": "826760",
    "end": "832399"
  },
  {
    "text": "retry scenarios there are and how the receiver should be able to uh handle those so um there's these new headers",
    "start": "832399",
    "end": "839639"
  },
  {
    "text": "that basically you can think of them almost like a check sum right if you send 100 samples and you get back a response that says I accepted 99 then",
    "start": "839639",
    "end": "846519"
  },
  {
    "text": "you know that at least one wasn't accepted right uh next up um as bch mentioned",
    "start": "846519",
    "end": "854560"
  },
  {
    "text": "there's a whole bunch of new features in promethus itself that were either experimental in the 1.0 format or just",
    "start": "854560",
    "end": "860440"
  },
  {
    "text": "not supported at all um so we're supporting native histograms now in this",
    "start": "860440",
    "end": "866399"
  },
  {
    "text": "uh protocol format uh we're explicitly allowing for utf8 characters which Prometheus is going to allow for as well",
    "start": "866399",
    "end": "873519"
  },
  {
    "text": "um and then one of the main ones is histograms so if you know about prometheus's classic histogram format",
    "start": "873519",
    "end": "879959"
  },
  {
    "text": "essentially every bucket in the histogram is a separate time series the new native histograms bundle those all",
    "start": "879959",
    "end": "886720"
  },
  {
    "text": "together into one um with classic histograms some receivers would run into issues where some of the series would be",
    "start": "886720",
    "end": "893240"
  },
  {
    "text": "split across WR requests right um half the buckets were in one right request and the other half would be the next one",
    "start": "893240",
    "end": "899040"
  },
  {
    "text": "we want to solve for that problem we know that issue is particularly problematic for example like the otel",
    "start": "899040",
    "end": "904839"
  },
  {
    "text": "community um and as part of that we have these native histograms with uh custom buckets",
    "start": "904839",
    "end": "911160"
  },
  {
    "text": "which allows for that translation from a classic histogram to a native histogram within the protocol format",
    "start": "911160",
    "end": "918399"
  },
  {
    "text": "itself uh the next issue we wanted to deal with was metadata um and as butex",
    "start": "918600",
    "end": "923720"
  },
  {
    "text": "mentioned with metadata we mean like the metric unit its actual type the help text created time stamp stuff like that",
    "start": "923720",
    "end": "931839"
  },
  {
    "text": "uh in 1.0 metadata is problematic because Prometheus itself was only",
    "start": "931839",
    "end": "936959"
  },
  {
    "text": "storing metadata in like this in-memory cache so the scrape system would come along look at all your targets gather",
    "start": "936959",
    "end": "942759"
  },
  {
    "text": "the metrics and then cache the metadata that it had seen in memory and that actually meant that if two Targets had",
    "start": "942759",
    "end": "949319"
  },
  {
    "text": "the same metric name but different semantic meanings for those metrics and different metadata we'd only store what",
    "start": "949319",
    "end": "955519"
  },
  {
    "text": "was scraped most recently right and so when remote right goes to send that you're going to end up with your",
    "start": "955519",
    "end": "960560"
  },
  {
    "text": "receiver receiving the incorrect metadata for at least one of your metrics we wanted to solve for this as well and it's also important to mention",
    "start": "960560",
    "end": "967800"
  },
  {
    "text": "that we decided that because there was only this metadata cache we were always",
    "start": "967800",
    "end": "973199"
  },
  {
    "text": "going to send metadata over remote right separately from all your other data so",
    "start": "973199",
    "end": "978399"
  },
  {
    "text": "on a timer on like let's say once a minute we go and look at that cache remote R grabs all the metadata sends it",
    "start": "978399",
    "end": "985160"
  },
  {
    "text": "all at once it's not part of the regular um sharding and upscaling if you're",
    "start": "985160",
    "end": "990519"
  },
  {
    "text": "familiar with that um so the reason we need to make a change here is that remote right",
    "start": "990519",
    "end": "996600"
  },
  {
    "text": "actually gathers all the data that it's going to send from prometheus's right ahead log and without the metadata in",
    "start": "996600",
    "end": "1002639"
  },
  {
    "text": "the right ahead log we couldn't do it so um now uh with a feature flag metadata",
    "start": "1002639",
    "end": "1008920"
  },
  {
    "text": "is written to the right ahead log remote right can gather it and it can put it into the actual remote right request alongside each sample right and so for",
    "start": "1008920",
    "end": "1015959"
  },
  {
    "text": "every sample you're receiving with remote right 2.0 you're going to get the correct",
    "start": "1015959",
    "end": "1021360"
  },
  {
    "text": "metadata and so you might be wondering like hey earlier you mentioned that you wanted to make this thing more efficient",
    "start": "1021519",
    "end": "1027678"
  },
  {
    "text": "but you're adding all these features that's probably more overhead now it's less efficient right um in some sense",
    "start": "1027679",
    "end": "1034000"
  },
  {
    "text": "yes like obviously there is more overhead with more features but my original main goal was to reduce the",
    "start": "1034000",
    "end": "1040000"
  },
  {
    "text": "actual payload size right reduce the number of btes sent over the wire and sending F bytes is a good thing",
    "start": "1040000",
    "end": "1047199"
  },
  {
    "text": "right you're either getting build for that or uh spending CPU time serializing data something like that right um so at",
    "start": "1047199",
    "end": "1053720"
  },
  {
    "text": "the top here you can see an example of some metrics and you'll notice that a lot of the key value pairs for labels",
    "start": "1053720",
    "end": "1060520"
  },
  {
    "text": "are the same right there's job equals food job job equals bar there's a lot of",
    "start": "1060520",
    "end": "1065799"
  },
  {
    "text": "duplicates right and so we basically borrowed from Prometheus itself borrowed",
    "start": "1065799",
    "end": "1071840"
  },
  {
    "text": "from like a dictionary type format uh and we're doing what we call a symbol table which is essentially string and",
    "start": "1071840",
    "end": "1077600"
  },
  {
    "text": "turning of all all of the string data that goes into the remote WR request and so on the bottom now you can see we",
    "start": "1077600",
    "end": "1083440"
  },
  {
    "text": "basically have this table that says for each Series this is the index to reference to get the string that",
    "start": "1083440",
    "end": "1089840"
  },
  {
    "text": "actually matters right um and one question we heard a lot",
    "start": "1089840",
    "end": "1095720"
  },
  {
    "text": "was why did you actually opt to do string and turning instead of something else why not just use for example a more",
    "start": "1095720",
    "end": "1102159"
  },
  {
    "text": "efficient compression algorithm right uh remote right uses Snappy which is pretty fast but doesn't compress as well as",
    "start": "1102159",
    "end": "1108480"
  },
  {
    "text": "something like Z standard and we actually spent a lot of time investigating other compression",
    "start": "1108480",
    "end": "1114640"
  },
  {
    "text": "algorithms I think a month or two at least um doing different experiments um",
    "start": "1114640",
    "end": "1120039"
  },
  {
    "text": "one of the main problems with changing off of something like Snappy is we we specifically chose Snappy because of its",
    "start": "1120039",
    "end": "1126280"
  },
  {
    "text": "low resource cost low CPU cost Etc right um and having a better higher",
    "start": "1126280",
    "end": "1133159"
  },
  {
    "text": "compression ratio from something like Z standard requires more CPU time to be spent on um on that serialization and",
    "start": "1133159",
    "end": "1140200"
  },
  {
    "text": "and encoding in the first place right so ultimately after a bunch of months of experimentation we found the best win",
    "start": "1140200",
    "end": "1147039"
  },
  {
    "text": "for us was to focus on reducing the payload size itself through string inter turning and",
    "start": "1147039",
    "end": "1153679"
  },
  {
    "text": "then these smaller payloads still using Snappy are already taking less time to compress and decompress allocating less",
    "start": "1153679",
    "end": "1160679"
  },
  {
    "text": "bites when they do so um and that includes when we're using all these new features",
    "start": "1160679",
    "end": "1167200"
  },
  {
    "text": "so um we're still using Snappy we might go back to experimenting with other compressions right now but the real",
    "start": "1167200",
    "end": "1174039"
  },
  {
    "text": "question that you're probably wondering is like how much are we actually doing that's better right how much better are",
    "start": "1174039",
    "end": "1180080"
  },
  {
    "text": "we um so thankfully btech put together some benchmarking automation um it's uh",
    "start": "1180080",
    "end": "1187840"
  },
  {
    "text": "using a basically a tool to generate scrape data sets um and then we're uh",
    "start": "1187840",
    "end": "1194520"
  },
  {
    "text": "configuring Prometheus with different um batch sizes which is the number of data",
    "start": "1194520",
    "end": "1200159"
  },
  {
    "text": "samples uh in each payload and so the graphs that I'm going to show you on the next couple slides uh",
    "start": "1200159",
    "end": "1207480"
  },
  {
    "text": "they're looking at three different measurements the actual message size in bytes on The Wire right so that remote",
    "start": "1207480",
    "end": "1214440"
  },
  {
    "text": "right request itself serialization CPU time which includes uh serialization into protuff",
    "start": "1214440",
    "end": "1221919"
  },
  {
    "text": "as well as encoding uh via compression right we're taking the go structure turning it into the bytes that we can",
    "start": "1221919",
    "end": "1227360"
  },
  {
    "text": "send over the wire and then the amount of bytes that are actually allocated during that serialization process right",
    "start": "1227360",
    "end": "1233760"
  },
  {
    "text": "which obviously contributes to something like garbage collection it's important to know that",
    "start": "1233760",
    "end": "1239240"
  },
  {
    "text": "in all three of these measures in every graph a lower number is better uh blue",
    "start": "1239240",
    "end": "1244440"
  },
  {
    "text": "is 1.0 red is 2.0 so in this first set of graphs we're comparing Prometheus",
    "start": "1244440",
    "end": "1250039"
  },
  {
    "text": "remote right 1.0 with none of those extra features we talked about right just that base version that we had 8",
    "start": "1250039",
    "end": "1255600"
  },
  {
    "text": "years ago to remote right 2.0 with with all the features and so for that default payload",
    "start": "1255600",
    "end": "1263280"
  },
  {
    "text": "size of 2,000 samples um you can see that we have a slight increase in the payload size it's not that much right 7%",
    "start": "1263280",
    "end": "1270520"
  },
  {
    "text": "but um probably a fair comparison is actually to turn some of these features on",
    "start": "1270520",
    "end": "1276360"
  },
  {
    "text": "right so when we turn on all those optional features native histograms metadata all that kind of stuff um it's",
    "start": "1276360",
    "end": "1282880"
  },
  {
    "text": "pretty obvious uh we have nearly a 50% reduction in The Wire bytes right um",
    "start": "1282880",
    "end": "1289320"
  },
  {
    "text": "over 60% reduction in serialization CPU time uh and over 80% reduction in bytes",
    "start": "1289320",
    "end": "1296200"
  },
  {
    "text": "allocated during that serialization but there's actually one more feature that we can turn on to make this even even",
    "start": "1296200",
    "end": "1301440"
  },
  {
    "text": "better right which is those native histograms with custom buckets so we're now turning every old classic style",
    "start": "1301440",
    "end": "1309000"
  },
  {
    "text": "histogram into a native histogram um and that's even better right we're on nearly",
    "start": "1309000",
    "end": "1314240"
  },
  {
    "text": "60% reduction in the message bytes on The Wire More than 70% better uh CPU time and nearly 90% better",
    "start": "1314240",
    "end": "1322960"
  },
  {
    "text": "in bytes allocate during serialization and I imagine some of you in the audience might be implementers of",
    "start": "1322960",
    "end": "1329799"
  },
  {
    "text": "receivers so you're probably wondering what about der serialization that's significantly",
    "start": "1329799",
    "end": "1335480"
  },
  {
    "text": "better right um so essentially in all cases we've improved the efficiency",
    "start": "1335480",
    "end": "1341120"
  },
  {
    "text": "while being able to add new features so what do you need to do in",
    "start": "1341120",
    "end": "1346880"
  },
  {
    "text": "order to start using remot R to . o uh well well in Prometheus itself it's",
    "start": "1346880",
    "end": "1353760"
  },
  {
    "text": "uh pretty easy there's essentially just two lines you need to change uh one is a command line flag and that tells",
    "start": "1353760",
    "end": "1359840"
  },
  {
    "text": "Prometheus to um write metadata records to the right head log so the remote right can actually find",
    "start": "1359840",
    "end": "1366400"
  },
  {
    "text": "them um and then there's a new field that we've added to the remote right config itself uh which just tells",
    "start": "1366400",
    "end": "1373039"
  },
  {
    "text": "Prometheus um which version of the protu format to use by default it'll still use 1.0 but if you explicitly tell it to it",
    "start": "1373039",
    "end": "1380159"
  },
  {
    "text": "will use 2.o um we need as many uh Community",
    "start": "1380159",
    "end": "1387360"
  },
  {
    "text": "projects and and users to start adopting this as possible um we're implementing",
    "start": "1387360",
    "end": "1394559"
  },
  {
    "text": "new versions in client libraries to support sending um remote right itself",
    "start": "1394559",
    "end": "1399840"
  },
  {
    "text": "with like having to use Prometheus um we're working on some test Frameworks",
    "start": "1399840",
    "end": "1405600"
  },
  {
    "text": "like the one we used to Benchmark ourselves uh we've got compliance tests in the works right so um for 1.0 these",
    "start": "1405600",
    "end": "1412679"
  },
  {
    "text": "already exist but if you wanted to say you're a vendor or you're going to be using a vendor and you want to check",
    "start": "1412679",
    "end": "1417919"
  },
  {
    "text": "whether or not they're compliant with 2.0 uh spec that's in progress right now as well uh and then within the ecosystem",
    "start": "1417919",
    "end": "1425200"
  },
  {
    "text": "we have a bunch of other tools as well that could help you test things um there's one called Avalanche which",
    "start": "1425200",
    "end": "1430400"
  },
  {
    "text": "generates metrics um you could use something like KX to do load testing as",
    "start": "1430400",
    "end": "1436640"
  },
  {
    "text": "well um if you really want to you can go digging sorry digging around in the uh",
    "start": "1436640",
    "end": "1443000"
  },
  {
    "text": "repository for a Proto buff but actually as part of this project um we've started",
    "start": "1443000",
    "end": "1448600"
  },
  {
    "text": "it's a little small on that screen but we've started publishing all of prometheus's protuff specs uh to buff um",
    "start": "1448600",
    "end": "1455159"
  },
  {
    "text": "so you can get them there um and buff has tools to help you get up and running even faster right so for example like",
    "start": "1455159",
    "end": "1461960"
  },
  {
    "text": "you can use their tools buff. build to generate a go client for a remote rate",
    "start": "1461960",
    "end": "1469000"
  },
  {
    "text": "so in summary remote right 2.0 enables this",
    "start": "1469000",
    "end": "1474679"
  },
  {
    "text": "great set of features features that perus itself already supports uh while also making some",
    "start": "1474679",
    "end": "1480720"
  },
  {
    "text": "pretty significant performance improvements right uh over 60% for almost every um everything that we",
    "start": "1480720",
    "end": "1488039"
  },
  {
    "text": "measured um it's pretty simple to configure only two lines within Prometheus um and if you're the owner of",
    "start": "1488039",
    "end": "1495000"
  },
  {
    "text": "a third party project or some kind of community tool um we invite you to implement remote r2.0 support come to us",
    "start": "1495000",
    "end": "1502320"
  },
  {
    "text": "if you have questions right um it's technically still experimental the spec um we really don't",
    "start": "1502320",
    "end": "1510960"
  },
  {
    "text": "anticipate any changes uh I know I don't want to spend any time on more changes right but um",
    "start": "1510960",
    "end": "1517840"
  },
  {
    "text": "it's just listed as experimental because there's kind of historical precedent right like we only released a spec for",
    "start": "1517840",
    "end": "1524240"
  },
  {
    "text": "One auto eight years after it really came out right um um there's some areas",
    "start": "1524240",
    "end": "1530320"
  },
  {
    "text": "we're thinking about making additional improvements um uh for example going back to our",
    "start": "1530320",
    "end": "1537320"
  },
  {
    "text": "compression algorithm investigations um should we use alternative Proto formats like cap and",
    "start": "1537320",
    "end": "1543480"
  },
  {
    "text": "Proto or maybe something like Arrow uh is there anything else we can do to improve the like transactionality",
    "start": "1543480",
    "end": "1550520"
  },
  {
    "text": "of the protocol without having to be stateless uh things like that yeah but that's that's after two of course that's",
    "start": "1550520",
    "end": "1556880"
  },
  {
    "text": "after two yes yeah um so like I said if you have questions",
    "start": "1556880",
    "end": "1562320"
  },
  {
    "text": "you can obviously ask us now but we're also in the cncf slack in a couple of channels uh I also want to thank Alex",
    "start": "1562320",
    "end": "1570039"
  },
  {
    "text": "and ni who helped us with a lot of the investigation and experimentation that we did um pascalis is the one who",
    "start": "1570039",
    "end": "1576440"
  },
  {
    "text": "actually implemented metadata in prometheus's right Ahad log and then URI and Arthur are involved in a lot of",
    "start": "1576440",
    "end": "1582840"
  },
  {
    "text": "metadata created timestamp stuff and then finally the original uh Prometheus",
    "start": "1582840",
    "end": "1587960"
  },
  {
    "text": "remote right 1.0 authors so Tom Julius and a few other people um and obviously",
    "start": "1587960",
    "end": "1593799"
  },
  {
    "text": "thanks to all of you for coming and we're going to open it up for questions if anyone has any thank",
    "start": "1593799",
    "end": "1599890"
  },
  {
    "text": "[Applause]",
    "start": "1599890",
    "end": "1607039"
  },
  {
    "text": "you hi thanks that's great uh a question for what would you say to a user who uh",
    "start": "1607039",
    "end": "1613720"
  },
  {
    "text": "has metrics collected NEP maybe via SD Cas open TD case or The Collector and",
    "start": "1613720",
    "end": "1619679"
  },
  {
    "text": "wants to send it to pritus uh can they just use OTP or is it still better to",
    "start": "1619679",
    "end": "1625760"
  },
  {
    "text": "use remote right V2 what what are the differences that's a good question so",
    "start": "1625760",
    "end": "1631279"
  },
  {
    "text": "open th collector usually especially if you use contri and you add those proper exporters they allow you to have both",
    "start": "1631279",
    "end": "1638200"
  },
  {
    "text": "OTP and remote right we are working on op collector to support to zero and I think our PR's open and that's a good",
    "start": "1638200",
    "end": "1645360"
  },
  {
    "text": "question like because then you can because perit also supports OT P receiving so what's better um",
    "start": "1645360",
    "end": "1653919"
  },
  {
    "text": "honestly measure check it out my impression is that remote ride is",
    "start": "1653919",
    "end": "1659600"
  },
  {
    "text": "definitely faster at the moment like more efficient um that would what I would expect but you know OTP is much",
    "start": "1659600",
    "end": "1666600"
  },
  {
    "text": "more you know feature reach but of course that's not relevant for for prit use data model right now so I would say",
    "start": "1666600",
    "end": "1672320"
  },
  {
    "text": "remote right but um of course that might change will kind of like we are collaborating VP and and kind of maybe",
    "start": "1672320",
    "end": "1678200"
  },
  {
    "text": "helping them to kind of adopt some kind of string interning and stuff stuff like that so um right now um yeah that's my",
    "start": "1678200",
    "end": "1684840"
  },
  {
    "text": "answer okay cool so you mostly performance uh differ I would say so yeah because um there is aspect of this",
    "start": "1684840",
    "end": "1691360"
  },
  {
    "text": "uh naming conventions but with free zero you all UTF a compatible so you should",
    "start": "1691360",
    "end": "1697200"
  },
  {
    "text": "have exactly the same namings there might be difference around resource attributes but um you can do that on",
    "start": "1697200",
    "end": "1702960"
  },
  {
    "text": "client side hopefully with the with the with the sender so they're kind of like yeah um",
    "start": "1702960",
    "end": "1708960"
  },
  {
    "text": "awesome thanks is there a sense for when the",
    "start": "1708960",
    "end": "1715159"
  },
  {
    "text": "community will start implementing this in some of the SNS like mimir Thanos or cortex yeah um I think you know in the",
    "start": "1715159",
    "end": "1723159"
  },
  {
    "text": "next six months like I literally will go to Thanos and once we release all of this we're busy but I I will kind of",
    "start": "1723159",
    "end": "1730240"
  },
  {
    "text": "like even like myself kind of try to like do this work on tanos side um and then cortex and I think grafana maybe",
    "start": "1730240",
    "end": "1736919"
  },
  {
    "text": "colum know SMS but would expect very soon and and by the way this is the moment when when those you know project",
    "start": "1736919",
    "end": "1742200"
  },
  {
    "text": "will adopt remote right then we'll make it stable because that would prove you know that this is really successful and",
    "start": "1742200",
    "end": "1747440"
  },
  {
    "text": "and and good to go and where's the best place to keep up to date on those efforts Ah that's a good point maybe",
    "start": "1747440",
    "end": "1754399"
  },
  {
    "text": "Blog promit blog so promit website for sure uh we'll make sure to have a blog post when when we are kind of ready with",
    "start": "1754399",
    "end": "1760679"
  },
  {
    "text": "the stability and and more adopters and there's also the adopter page that that's a good idea to kind of like make",
    "start": "1760679",
    "end": "1767279"
  },
  {
    "text": "make up to thank you thank you hey thanks for your presentation um",
    "start": "1767279",
    "end": "1775279"
  },
  {
    "text": "what are the benefits and tradeoffs of using a Prometheus agent with remote right versus using a centralized",
    "start": "1775279",
    "end": "1780320"
  },
  {
    "text": "Prometheus to scrape host remotely um I mean the obvious one is",
    "start": "1780320",
    "end": "1786200"
  },
  {
    "text": "you can't query the agent right so if that's a requirement for you then obviously your decision is",
    "start": "1786200",
    "end": "1792919"
  },
  {
    "text": "made um I think the question was more if I understood correctly that you have either prom in the same cluster and send",
    "start": "1792919",
    "end": "1799760"
  },
  {
    "text": "further or you have premes actually in remote cluster and scrape uh remotely",
    "start": "1799760",
    "end": "1805600"
  },
  {
    "text": "right um eventually it's just a question of",
    "start": "1805600",
    "end": "1811600"
  },
  {
    "text": "scale in terms of how much resources you can throw at that single node centralized Prometheus right um like bch",
    "start": "1811600",
    "end": "1819080"
  },
  {
    "text": "mentioned the Prometheus project is never intended to solve for things like high availability or clustering or",
    "start": "1819080",
    "end": "1825080"
  },
  {
    "text": "anything like that um So eventually that c Prometheus will start to fall over um",
    "start": "1825080",
    "end": "1832559"
  },
  {
    "text": "I think internally we got up to one maybe Mark can correct me but I think internally we got to one that was up to",
    "start": "1832559",
    "end": "1838039"
  },
  {
    "text": "like 100 gigs of RAM or something like that higher um but it it was it was",
    "start": "1838039",
    "end": "1843200"
  },
  {
    "text": "painful right like it was it was really a big pain Point um if you're smaller",
    "start": "1843200",
    "end": "1848919"
  },
  {
    "text": "than for sure a single centralized Prometheus whether it's one that's scraping your various clusters and",
    "start": "1848919",
    "end": "1854919"
  },
  {
    "text": "storing in one place or if you've got an agent that's sending to it yeah yeah and if your question is more",
    "start": "1854919",
    "end": "1860440"
  },
  {
    "text": "around okay I can scale prome or use other you know Solutions but still put them in centralized place um instead of",
    "start": "1860440",
    "end": "1867679"
  },
  {
    "text": "putting you know like and scrape literally across you know scrape from different clusters um then you have this",
    "start": "1867679",
    "end": "1873960"
  },
  {
    "text": "question of reliability that's all right so essentially we recommend to putting opom or op collector or any scraper",
    "start": "1873960",
    "end": "1880760"
  },
  {
    "text": "agent next to your applications because this is why you know it's so powerful",
    "start": "1880760",
    "end": "1885840"
  },
  {
    "text": "because you know you have like a super nice nice reliability when you know the scrape fail you know it's likely",
    "start": "1885840",
    "end": "1891880"
  },
  {
    "text": "application it's not Network right which is which is really common and then you have an overhead of a pretty large",
    "start": "1891880",
    "end": "1897840"
  },
  {
    "text": "amount of data that is you know really badly compressed because again those scrap Protocols are not optimized for",
    "start": "1897840",
    "end": "1904559"
  },
  {
    "text": "you know uh wide Network kind of use um so again this is what we recommend have smaller scrapers and then send that",
    "start": "1904559",
    "end": "1910840"
  },
  {
    "text": "through remote ride uh to the to the centralized storage if you need thank you hey yeah you hinted at it for remote",
    "start": "1910840",
    "end": "1918440"
  },
  {
    "text": "right for uh failures and retries if the back end's having trouble right now we're building up a queue of remote",
    "start": "1918440",
    "end": "1924679"
  },
  {
    "text": "right messages does the the data you're getting back in the header that you showed of which ones failed help the",
    "start": "1924679",
    "end": "1931200"
  },
  {
    "text": "queue be more optimal than knowing what it should try again um so we we kind of wanted to go",
    "start": "1931200",
    "end": "1939559"
  },
  {
    "text": "all the way and solve that completely um but unfortunately that whole discussion was happening pretty",
    "start": "1939559",
    "end": "1945240"
  },
  {
    "text": "late into um finalizing the spec so we added these headers to tell you whether",
    "start": "1945240",
    "end": "1950760"
  },
  {
    "text": "or not all of the data was accepted but we didn't go as far as saying which weren't accepted um there's obviously a",
    "start": "1950760",
    "end": "1957799"
  },
  {
    "text": "cost with doing that as well right like how much data do we want to send back as part of a response um so right now in",
    "start": "1957799",
    "end": "1963720"
  },
  {
    "text": "the spec we essentially require that if you want to retry uh the receiver must",
    "start": "1963720",
    "end": "1969159"
  },
  {
    "text": "be fully item potent for for that request all right gotcha cool",
    "start": "1969159",
    "end": "1975440"
  },
  {
    "text": "thanks hi great presentation I have a somewhat related question um sometimes",
    "start": "1975840",
    "end": "1981440"
  },
  {
    "text": "we end up in situations where the right ahead log is too big to be processed on Startup by a remote writer and I was",
    "start": "1981440",
    "end": "1987120"
  },
  {
    "text": "wondering if you did any benchmarking or measuring the size of the wall and if it's faster or more efficient to process",
    "start": "1987120",
    "end": "1994000"
  },
  {
    "text": "it on Startup during crash scenarios like the one mentioned um as part of this we didn't measure that",
    "start": "1994000",
    "end": "2000799"
  },
  {
    "text": "um so it's unrelated essentially it's very unrelated because wall is used for many many things than just uh remote",
    "start": "2000799",
    "end": "2008000"
  },
  {
    "text": "right but definitely I wanted to share that we are kind of like redesigning wall for some of those features to go",
    "start": "2008000",
    "end": "2013519"
  },
  {
    "text": "for remote right for example like native hisam with custom buckets and and create time stamp there there is some wall",
    "start": "2013519",
    "end": "2019039"
  },
  {
    "text": "redesign and this as a part of this work will definitely make it uh try to make it much faster but it's not not really",
    "start": "2019039",
    "end": "2025159"
  },
  {
    "text": "necessarily related to remote right yeah um one of the the list of like other things that we want to do in the future",
    "start": "2025159",
    "end": "2031880"
  },
  {
    "text": "um and this has been on the backlog for multiple years is um right now when remote r restarts",
    "start": "2031880",
    "end": "2038480"
  },
  {
    "text": "for any reason uh whether that's Prometheus restarting or you changing the config and reloading or something like that uh it just drops everything",
    "start": "2038480",
    "end": "2045960"
  },
  {
    "text": "that hasn't been sent yet right doesn't matter if it's buffered or if it's uh seeked to a certain point in the wall",
    "start": "2045960",
    "end": "2053079"
  },
  {
    "text": "when remote right restarts it just goes to the recent this is where I am now",
    "start": "2053079",
    "end": "2058320"
  },
  {
    "text": "right uh what we'd like to have is this concept of like a remote right checkpoint so remote right knows okay",
    "start": "2058320",
    "end": "2065358"
  },
  {
    "text": "when I restarted I was on segment nine out of 10 in like roughly this place I can restart from there um that's the",
    "start": "2065359",
    "end": "2072638"
  },
  {
    "text": "main idea we have right now for basically improving remote rights usage of the wall even though technically we",
    "start": "2072639",
    "end": "2079320"
  },
  {
    "text": "don't own it maybe there's something we can do with the agent M mode but within Prometheus itself the tsdb and everybody",
    "start": "2079320",
    "end": "2086000"
  },
  {
    "text": "who works on tsdb actually owns the right head log we've kind of just abused the fact that it's there",
    "start": "2086000",
    "end": "2092720"
  },
  {
    "text": "right and reused it as like an on disk buffer almost yeah and if you have like special requirements that we hear",
    "start": "2092720",
    "end": "2099839"
  },
  {
    "text": "sometimes where your centralized storage is down for two days for example and you have that data kind of in promus in the",
    "start": "2099839",
    "end": "2107160"
  },
  {
    "text": "local storage you know remote right is obviously un like not remote r as a protocol but prome use of remote R is",
    "start": "2107160",
    "end": "2112839"
  },
  {
    "text": "limited to those two hour wall um we are really thinking about kind of like having like this uh What uh yeah um bulk",
    "start": "2112839",
    "end": "2122359"
  },
  {
    "text": "bulk up upload or something where you upload blocks which are not there or even use remote right from the old part",
    "start": "2122359",
    "end": "2127800"
  },
  {
    "text": "and this is especially useful for Edge you know clusters so if you have those needs please go to prom's Project add an",
    "start": "2127800",
    "end": "2133880"
  },
  {
    "text": "issue plus one the issue so we know that it's it's kind of like important but there are also some innovations that we",
    "start": "2133880",
    "end": "2139280"
  },
  {
    "text": "are looking for on those site as well okay I think we are just about the time so you can uh catch up later and see the",
    "start": "2139280",
    "end": "2146839"
  },
  {
    "text": "next tomorrow on Thursday the session for promus as well and thank you for being with us thank you",
    "start": "2146839",
    "end": "2155920"
  }
]
[
  {
    "text": "all right thank you so uh we're gonna get started here so this is my depiction",
    "start": "30",
    "end": "7680"
  },
  {
    "text": "of a kubernetes operator now you might be asking why he's frowning and I have I",
    "start": "7680",
    "end": "13110"
  },
  {
    "text": "have the answer for you so he's got three kubernetes clusters running in different places then we can imagine",
    "start": "13110",
    "end": "19230"
  },
  {
    "text": "that these are different clouds and one of them's in open Jeff cluster because you know some of his devs when an open shift you know he's got rancher with",
    "start": "19230",
    "end": "25859"
  },
  {
    "text": "kubernetes and he's got this like weird skunk works came that went off and did their own qubit you know cube ADM",
    "start": "25859",
    "end": "30929"
  },
  {
    "text": "clustered and then he ended up having to manage all of these different clusters right so the problem is that as he's",
    "start": "30929",
    "end": "36570"
  },
  {
    "text": "getting towards you know his deployments and trying to strategize on the way that",
    "start": "36570",
    "end": "41640"
  },
  {
    "text": "he's going to perform application deployments across these clouds there he",
    "start": "41640",
    "end": "46860"
  },
  {
    "text": "doesn't really have that connectivity between his clusters you know pods can't talk to pods unless you know you find",
    "start": "46860",
    "end": "52020"
  },
  {
    "text": "different ways of transversing that traffic you know using something like an external IP or load balancers I mean so",
    "start": "52020",
    "end": "58379"
  },
  {
    "text": "that's just not fun so that's what submariner is really here to do it's a",
    "start": "58379",
    "end": "64559"
  },
  {
    "text": "multi I guess a multi cluster kubernetes network connectivity tool and so because",
    "start": "64559",
    "end": "70830"
  },
  {
    "text": "of that it makes our kubernetes operator happy and this is I know it's a pretty bad you know graphical depiction of what",
    "start": "70830",
    "end": "76560"
  },
  {
    "text": "this does but you know we can actually talk about you know using text here what submariner does so submariner really is",
    "start": "76560",
    "end": "82710"
  },
  {
    "text": "gonna allow your pods to directly communicate between your kubernetes clusters it's secure so it's actually",
    "start": "82710",
    "end": "88380"
  },
  {
    "text": "using IP well if the current implementation today uses IPSec tunnels so it actually will establish IPSec",
    "start": "88380",
    "end": "93479"
  },
  {
    "text": "tunnels between your kubernetes clusters it's also C&I agnostic so that is it's actually operating at a layer",
    "start": "93479",
    "end": "99750"
  },
  {
    "text": "independent of most network providers so you know whether you're using something like flannel or OB and kubernetes you",
    "start": "99750",
    "end": "106079"
  },
  {
    "text": "actually can have your pods talk to each other and what we'll be demoing today is actually an open chef cluster talking to",
    "start": "106079",
    "end": "112470"
  },
  {
    "text": "a kubernetes or you know a rancher kubernetes cluster using flannels or you",
    "start": "112470",
    "end": "117840"
  },
  {
    "text": "know flannel on our end and then OpenShift is using I think it's yeah so",
    "start": "117840",
    "end": "123060"
  },
  {
    "text": "you know it's it's pretty neat stuff now how does it work I get this question",
    "start": "123060",
    "end": "129509"
  },
  {
    "text": "a lot because you know the idea of trying to connect these over networks together you know there's a lot",
    "start": "129509",
    "end": "134890"
  },
  {
    "text": "of different sort of architectures you could come up with but this is the simplest one we have so essentially we",
    "start": "134890",
    "end": "140769"
  },
  {
    "text": "have a central component which we could we can consider our submarine or broker and the in the current implementation",
    "start": "140769",
    "end": "146019"
  },
  {
    "text": "today it's actually a kubernetes cluster that is using CRTs and we have each",
    "start": "146019",
    "end": "151540"
  },
  {
    "text": "cluster that's going to be connected to each other I guess interacting with that broker cluster and exchanging information",
    "start": "151540",
    "end": "157959"
  },
  {
    "text": "really it is metadata between the data path itself is going to be using IPSec in each cluster you actually have one or",
    "start": "157959",
    "end": "164980"
  },
  {
    "text": "many Gateway nodes and submariner does leader election to determine which gateway node is active and will actually",
    "start": "164980",
    "end": "171400"
  },
  {
    "text": "establish the IDS like tunnels between the Gateway nodes which is why that graphic there kind of shows you know the",
    "start": "171400",
    "end": "176530"
  },
  {
    "text": "the overlap there and with all of the other worker nodes master at CD and so",
    "start": "176530",
    "end": "182590"
  },
  {
    "text": "forth if they're running the submariner route agent will actually have the excellent devices configured on them independent of what you would have for",
    "start": "182590",
    "end": "188739"
  },
  {
    "text": "flannel but that's actually how within the cluster we we send traffic you know for the remote",
    "start": "188739",
    "end": "194290"
  },
  {
    "text": "I guess remote clusters when you're trying to cross cross communicate so a",
    "start": "194290",
    "end": "200230"
  },
  {
    "text": "little bit of history here so the history of submariner I was first conceptualized in 2017 when I was sort",
    "start": "200230",
    "end": "207819"
  },
  {
    "text": "of running openshift and had a lot of questions come up around how do I get you know clusters",
    "start": "207819",
    "end": "213310"
  },
  {
    "text": "you know on one side of the country to talk to clusters on the other side of country and that was there was no good",
    "start": "213310",
    "end": "219129"
  },
  {
    "text": "answer at the time I mean you could do things like you know layer for load balancers or you could try to figure out how to tunnel your traffic there you",
    "start": "219129",
    "end": "225699"
  },
  {
    "text": "know ingress or your routes or whatever just there was no good solution for this so I kind of had this like this dumb",
    "start": "225699",
    "end": "232870"
  },
  {
    "text": "idea of trying to connect these clusters using IPSec tunnels and so the first prototypes were written and actually",
    "start": "232870",
    "end": "238449"
  },
  {
    "text": "late 2018 when I was basically writing bash scripts dropping them into containers and then letting the you know",
    "start": "238449",
    "end": "244209"
  },
  {
    "text": "letting it be or letting strongswan establish IPSec tunnels between them and then I just it was it was pretty bit you",
    "start": "244209",
    "end": "250150"
  },
  {
    "text": "know bad it had hosts routing and stuff like that it was you know required layer two adjacency so I actually ended up",
    "start": "250150",
    "end": "256410"
  },
  {
    "text": "taking all that sort of those bash scripts and turning it into a sort of more of a controller model with",
    "start": "256410",
    "end": "262780"
  },
  {
    "text": "kubernetes I I built it around you know using go and when actually the first version of submariner in March",
    "start": "262780",
    "end": "269590"
  },
  {
    "text": "of 2019 and then after that you know like it gained a lot of traction to get",
    "start": "269590",
    "end": "274600"
  },
  {
    "text": "to where it is today and so we've actually been collaborating as a community on Submariner since to try to",
    "start": "274600",
    "end": "281020"
  },
  {
    "text": "help enhance its reliability as well as usability because you know like I just said one of the big things that we had",
    "start": "281020",
    "end": "287050"
  },
  {
    "text": "problems with was the fact that we needed to have layer two adjacency for the nodes and that was just I mean how",
    "start": "287050",
    "end": "292270"
  },
  {
    "text": "could you do cross a Z if we're within the same it just didn't work so we ended up you know basically integrating the",
    "start": "292270",
    "end": "298300"
  },
  {
    "text": "excellence and now your nodes are able to live in other places and still actually send traffic to remote destined",
    "start": "298300",
    "end": "303880"
  },
  {
    "text": "custer's and the other big thing I kind of wanted to call out here is you know submariner is a community project right",
    "start": "303880",
    "end": "310479"
  },
  {
    "text": "so we're trying to get you know feedback from people who want to have use cases",
    "start": "310479",
    "end": "316270"
  },
  {
    "text": "or who want to be do you know using submariner for you know like basically",
    "start": "316270",
    "end": "321490"
  },
  {
    "text": "few have a use case for you know we'd love to hear about that and we'd love to sort of you know if you want to sit down and look at the codebase and try to help",
    "start": "321490",
    "end": "327340"
  },
  {
    "text": "us out like I mean we're definitely welcoming that so we did make a new",
    "start": "327340",
    "end": "332380"
  },
  {
    "text": "release a summary to 0:03 which has that be excellent enhancement and still does the IPSec or you know IPSec for",
    "start": "332380",
    "end": "339039"
  },
  {
    "text": "tunneling was actually released yesterday and you know that's we basically were like oh we're IQ con we",
    "start": "339039",
    "end": "345130"
  },
  {
    "text": "might as well release it so you know we definitely would encourage you to check it out after this okay and yeah I wanted",
    "start": "345130",
    "end": "353860"
  },
  {
    "text": "to talk a little bit about the the change log from the first release that",
    "start": "353860",
    "end": "358930"
  },
  {
    "text": "Chris made and the changes that we have been introducing in the communities and",
    "start": "358930",
    "end": "364240"
  },
  {
    "text": "we joined from from Red Hat so on the",
    "start": "364240",
    "end": "372070"
  },
  {
    "text": "cr1 we had not at some point in India in the data path so when the packets",
    "start": "372070",
    "end": "378639"
  },
  {
    "text": "arrived the destination cluster the IP address of the originating port was lost",
    "start": "378639",
    "end": "384820"
  },
  {
    "text": "so we we fixed that with the encapsulation in the clusters inside the",
    "start": "384820",
    "end": "391630"
  },
  {
    "text": "clusters and then we extended testing",
    "start": "391630",
    "end": "397689"
  },
  {
    "text": "as much as week and we are still doing that so the the testing that we do is",
    "start": "397689",
    "end": "405099"
  },
  {
    "text": "really I mean we just all the all the",
    "start": "405099",
    "end": "410860"
  },
  {
    "text": "possible cases that we can think of connectivity and we are working now on more complex things like adding clusters",
    "start": "410860",
    "end": "418289"
  },
  {
    "text": "removing clusters trying to break up things there are my colleagues who are",
    "start": "418289",
    "end": "424719"
  },
  {
    "text": "working on a nut stuff go tell other like a lot of unit testing and we we",
    "start": "424719",
    "end": "431289"
  },
  {
    "text": "still have more to do so if you really do want to you in the community and help us out that will be great",
    "start": "431289",
    "end": "438539"
  },
  {
    "text": "and also we have been working on an operator to to maintain yours submariner",
    "start": "438539",
    "end": "446469"
  },
  {
    "text": "Diploma in the in your cluster make sure that is healthy that you can upgrade it that you can deploy it like really",
    "start": "446469",
    "end": "452499"
  },
  {
    "text": "really quick we we are going to show you under them I mean it's amazing and and with the operator it comes to what we",
    "start": "452499",
    "end": "459579"
  },
  {
    "text": "have called subsidy l and we'll just show you so on the roadmap we have",
    "start": "459579",
    "end": "471809"
  },
  {
    "text": "support for overlapping IP ciders like",
    "start": "471809",
    "end": "476889"
  },
  {
    "text": "it's it's a pretty common case that people wants to connect already existing",
    "start": "476889",
    "end": "484089"
  },
  {
    "text": "in clusters and and it's very likely that you will have conflicting IP",
    "start": "484089",
    "end": "489279"
  },
  {
    "text": "address ranges so we are coming up with with a solution for that we are also",
    "start": "489279",
    "end": "495099"
  },
  {
    "text": "working on service discovery occurs cluster a network policy support because",
    "start": "495099",
    "end": "502419"
  },
  {
    "text": "it's more complicated across clusters supporting other network plugins like",
    "start": "502419",
    "end": "509369"
  },
  {
    "text": "currently I think it at least it runs with open safe test the end flannel with",
    "start": "509369",
    "end": "515110"
  },
  {
    "text": "net yeah it should work helical I P and IV yes oh yeah most of them if they are",
    "start": "515110",
    "end": "522698"
  },
  {
    "text": "based on gift perks is very likely that they will work but if not we need to do some level integration that we will be",
    "start": "522699",
    "end": "529580"
  },
  {
    "text": "we also want to the status monitoring and improve subsidy out further we'll",
    "start": "529580",
    "end": "537320"
  },
  {
    "text": "show you later yeah so as Miguel sort of alluded to earlier one of the biggest",
    "start": "537320",
    "end": "542990"
  },
  {
    "text": "problems we run into a submariner is regarding overlapping ciders so if you",
    "start": "542990",
    "end": "548420"
  },
  {
    "text": "have to kubernetes clusters and I'm just gonna because I'm most familiar with us let's say you know I'm spending on my",
    "start": "548420",
    "end": "553610"
  },
  {
    "text": "kubernetes clusters and I have my pot IPS on 10 4200 / 16 the problem is if I",
    "start": "553610",
    "end": "560420"
  },
  {
    "text": "have if I try to dial you know from cluster a to cluster B I don't have a",
    "start": "560420",
    "end": "565430"
  },
  {
    "text": "really good way of you know or actually you basically conflicting routes because it's you kept how you know what what",
    "start": "565430",
    "end": "572029"
  },
  {
    "text": "cluster you're in so overlapping setters is definitely a problem and currently the proposal right now is actually used",
    "start": "572029",
    "end": "578450"
  },
  {
    "text": "sort of in a global overlay cider where we'll do a little bit of translation and sort of have a one-to-one relationship",
    "start": "578450",
    "end": "585290"
  },
  {
    "text": "between the pods on cost and what you know with them what would be cluster a and pods in cluster B but that is",
    "start": "585290",
    "end": "591649"
  },
  {
    "text": "obviously still in proposal at this at this point so if you have any feedback or you have any ideas on how to like do",
    "start": "591649",
    "end": "596750"
  },
  {
    "text": "you know I'm sort of global clusters with overlapping ciders we know we definitely you know come check out the",
    "start": "596750",
    "end": "603610"
  },
  {
    "text": "proposal we have and the git repository okay and on the roadmap we had the",
    "start": "603610",
    "end": "613220"
  },
  {
    "text": "service discovery and so for that we created sub project because we want to",
    "start": "613220",
    "end": "621529"
  },
  {
    "text": "keep the concerns as separate as we can",
    "start": "621529",
    "end": "626920"
  },
  {
    "text": "and that project is like house so the idea with like houses that you can you",
    "start": "626920",
    "end": "635329"
  },
  {
    "text": "can resolve DNS or did or we are also",
    "start": "635329",
    "end": "641060"
  },
  {
    "text": "looking for other metals but so your application doesn't really need to know where your service is running hopefully",
    "start": "641060",
    "end": "649579"
  },
  {
    "text": "at some point we we can make it like",
    "start": "649579",
    "end": "655120"
  },
  {
    "text": "select first local services if the service is running on on both and",
    "start": "655120",
    "end": "661220"
  },
  {
    "text": "several clusters say okay I prefer to go to the locker room cluster first and if that is not",
    "start": "661220",
    "end": "666800"
  },
  {
    "text": "available then go to the remote clusters and so there are so there is new IP is",
    "start": "666800",
    "end": "676279"
  },
  {
    "text": "on kubernetes that will let us define that kind of behavior and this is how it",
    "start": "676279",
    "end": "683480"
  },
  {
    "text": "looks early currently for the time we we are",
    "start": "683480",
    "end": "688610"
  },
  {
    "text": "creating accordion s plugin and a controller that will discover like the",
    "start": "688610",
    "end": "694310"
  },
  {
    "text": "remote services and create locals here these that this c√°rdenas plugin can can",
    "start": "694310",
    "end": "702200"
  },
  {
    "text": "reply with so a pod that runs in this cluster will make like DNS query and",
    "start": "702200",
    "end": "708290"
  },
  {
    "text": "discover this remote service living on on the other cluster and the other very",
    "start": "708290",
    "end": "716420"
  },
  {
    "text": "important topic that we need to look at is network policies if you are connecting your clusters it's really",
    "start": "716420",
    "end": "723410"
  },
  {
    "text": "important that it that you take care of security and network policies are for that the problem with network policies",
    "start": "723410",
    "end": "729440"
  },
  {
    "text": "is that the network plug-in in one cluster does not know our the pots in",
    "start": "729440",
    "end": "735920"
  },
  {
    "text": "the remote cluster so it needs to I mean we need to put some mechanism in place",
    "start": "735920",
    "end": "742070"
  },
  {
    "text": "to let the local network plugin of that cluster to know about the remote bow tie",
    "start": "742070",
    "end": "749029"
  },
  {
    "text": "piece so and so this is the normal case",
    "start": "749029",
    "end": "754279"
  },
  {
    "text": "no Koska are just local traffic and not all policies select pots based on labels",
    "start": "754279",
    "end": "761600"
  },
  {
    "text": "namespaces and this network policy for this this pot is selecting pots with",
    "start": "761600",
    "end": "770870"
  },
  {
    "text": "this label in this case it works you can see what to connect so if we have a remote pot the IP will not be known by",
    "start": "770870",
    "end": "779450"
  },
  {
    "text": "the network plugin so the traffic would will be blocked what we do with coast",
    "start": "779450",
    "end": "786050"
  },
  {
    "text": "guard is I'm simplifying this but we discover the the remote pot and we",
    "start": "786050",
    "end": "794079"
  },
  {
    "text": "create for this is a proof of it works but we create like additional",
    "start": "794079",
    "end": "802040"
  },
  {
    "text": "metropolises parallel to existing ones with the remote by a pod eyepiece that",
    "start": "802040",
    "end": "809550"
  },
  {
    "text": "much the network policy when toiley that can change this is only a proposal and",
    "start": "809550",
    "end": "815820"
  },
  {
    "text": "something to start with and deployment",
    "start": "815820",
    "end": "821010"
  },
  {
    "text": "options currently you have you have several you can you can use helm which",
    "start": "821010",
    "end": "828090"
  },
  {
    "text": "is what priests created initially you can use the new Submariner operator is",
    "start": "828090",
    "end": "834840"
  },
  {
    "text": "like a first release that does basic deployment and you can use subsidy L",
    "start": "834840",
    "end": "841140"
  },
  {
    "text": "that I will show how it looks because it's a little bit complicated to otherwise to deploy and we wanted to",
    "start": "841140",
    "end": "848220"
  },
  {
    "text": "make it very easy so we went from I don't know eight pages document",
    "start": "848220",
    "end": "853410"
  },
  {
    "text": "explaining how to deploy so Mariner to to Lyons and I mean very happy about",
    "start": "853410",
    "end": "859290"
  },
  {
    "text": "that so using sub CTL this is how it looks you can choose your broker cluster do",
    "start": "859290",
    "end": "867780"
  },
  {
    "text": "you need the admin context for that and you say okay deploy deploy broker and",
    "start": "867780",
    "end": "873540"
  },
  {
    "text": "that's going to deploy the broker for you and it will ask for anything that it",
    "start": "873540",
    "end": "879810"
  },
  {
    "text": "doesn't cannot figure out and it will produce this brokering for Submariner",
    "start": "879810",
    "end": "885780"
  },
  {
    "text": "file and then you go to the next cluster and you say ok joy and make you comfy",
    "start": "885780",
    "end": "894590"
  },
  {
    "text": "this is my cluster ID and it will make sure that it's installed and connected",
    "start": "894590",
    "end": "899940"
  },
  {
    "text": "and I will show you how it works hopefully it will work we depend a little bit on the Wi-Fi",
    "start": "899940",
    "end": "906900"
  },
  {
    "text": "which is a little bit on the edge that ok ah yeah I wanted to so what we are",
    "start": "906900",
    "end": "914580"
  },
  {
    "text": "going to demo is what we had at the start is vanilla kubernetes cluster",
    "start": "914580",
    "end": "920000"
  },
  {
    "text": "renter cluster so this one is running flannel the rancher cluster is running",
    "start": "920000",
    "end": "927630"
  },
  {
    "text": "in flannel with canal and they open saved cluster inside the Red Hat network is",
    "start": "927630",
    "end": "933530"
  },
  {
    "text": "running open sift as the end so they are different plugins technologies let's go",
    "start": "933530",
    "end": "941990"
  },
  {
    "text": "to the demo before I go into the demo I",
    "start": "941990",
    "end": "947780"
  },
  {
    "text": "wanted to say thanks to all my colleagues at that hat which supported me to make sure that this was possible",
    "start": "947780",
    "end": "954770"
  },
  {
    "text": "with deployment of clusters last time bug fixes and stuff like that thank you",
    "start": "954770",
    "end": "961340"
  },
  {
    "text": "three are ok so so the first thing that",
    "start": "961340",
    "end": "967340"
  },
  {
    "text": "we do is go into the rancher caster and we will do the deploy broker yes sir all",
    "start": "967340",
    "end": "980300"
  },
  {
    "text": "better okay so okay it's going to ask",
    "start": "980300",
    "end": "986210"
  },
  {
    "text": "for the name of the cluster cluster we need an ID and okay now it's deploy in",
    "start": "986210",
    "end": "992630"
  },
  {
    "text": "the the the broker and the operator it tries to figure out the cluster eyepiece",
    "start": "992630",
    "end": "1002950"
  },
  {
    "text": "like the the range for for the class therapies and the pod ciders it",
    "start": "1002950",
    "end": "1009210"
  },
  {
    "text": "sometimes is not first of all because it's not straightforward implementation",
    "start": "1009210",
    "end": "1014320"
  },
  {
    "text": "the cube realities tend to be different so for example in the newer versions of openshift you have static pod manifest",
    "start": "1014320",
    "end": "1020890"
  },
  {
    "text": "so you can scrape to figure out you know what your ciders are but in the rancher world we don't do static pods so that's",
    "start": "1020890",
    "end": "1026770"
  },
  {
    "text": "why we don't know what the service either is yeah so okay now Sumerian is",
    "start": "1026770",
    "end": "1033130"
  },
  {
    "text": "running on this on the runs our cluster and we have these brokering for file which is basically JSON encapsulated in",
    "start": "1033130",
    "end": "1040709"
  },
  {
    "text": "base64 to make sure that people don't break it you can break it anyway so if",
    "start": "1040709",
    "end": "1048550"
  },
  {
    "text": "we look at the other pots in the rancher cluster they are running that is this is",
    "start": "1048550",
    "end": "1054250"
  },
  {
    "text": "a submariner engine and the Gateway and those are the route against that run on",
    "start": "1054250",
    "end": "1059650"
  },
  {
    "text": "every worker not including the Gateway and this is how the broker looks like we",
    "start": "1059650",
    "end": "1067000"
  },
  {
    "text": "only have one cluster Connect one minute",
    "start": "1067000",
    "end": "1072160"
  },
  {
    "text": "ago yeah we can look at how a cluster looks it has the cider the cluster ID",
    "start": "1072160",
    "end": "1080460"
  },
  {
    "text": "the color codes that it's something to do this simple way of making sure",
    "start": "1080460",
    "end": "1088500"
  },
  {
    "text": "deciding how cluster connect to each other's are the blue ones will connect over the ones that at once to the red",
    "start": "1088500",
    "end": "1093910"
  },
  {
    "text": "ones but there are yeah abs to enhance",
    "start": "1093910",
    "end": "1099700"
  },
  {
    "text": "that so now what I'm going to do sorry I need to make the font smaller I'm going",
    "start": "1099700",
    "end": "1107530"
  },
  {
    "text": "to connect the custard in red hot - to the rancher broker so this is I please",
    "start": "1107530",
    "end": "1117280"
  },
  {
    "text": "note I'm connected to the red hot BPM because that one that cluster doesn't have any public IP at all it's so every",
    "start": "1117280",
    "end": "1126340"
  },
  {
    "text": "connection that it does to the internet this via not there is no IP address pointing to that cluster so we will be",
    "start": "1126340",
    "end": "1134110"
  },
  {
    "text": "doing IPSec NAT traversal to make that work and this is the vanilla Co ordinate",
    "start": "1134110",
    "end": "1141430"
  },
  {
    "text": "is cluster in this case we didn't mark any node gateway so the solid is going",
    "start": "1141430",
    "end": "1149980"
  },
  {
    "text": "to ask which one shall we pick we can pick this one",
    "start": "1149980",
    "end": "1155610"
  },
  {
    "text": "okay so at this point we can look at the",
    "start": "1160750",
    "end": "1165760"
  },
  {
    "text": "other pots we are having a weird DNS issue on the hub cluster so maybe it's",
    "start": "1165760",
    "end": "1171560"
  },
  {
    "text": "no it's working this time right otherwise if it didn't work with the DNS",
    "start": "1171560",
    "end": "1176720"
  },
  {
    "text": "the kubernetes magic will make sure that it works on Tralee and we can look at",
    "start": "1176720",
    "end": "1185210"
  },
  {
    "text": "the pot at the manila kubernetes cluster and if we look now the list of clusters",
    "start": "1185210",
    "end": "1192350"
  },
  {
    "text": "in the broker we have three okay and yeah and so one thing I do want to point",
    "start": "1192350",
    "end": "1198590"
  },
  {
    "text": "out so if you remember earlier I mentioned the fact that the broker is a kubernetes cluster that is worried where",
    "start": "1198590",
    "end": "1205460"
  },
  {
    "text": "we facilitate the exchange of that metadata for things like endpoints and clusters so if you actually looking at",
    "start": "1205460",
    "end": "1210590"
  },
  {
    "text": "our demo here you'll see that you know for the OpenShift cluster as well as the AWS you know kind of cube ATM cluster we",
    "start": "1210590",
    "end": "1217610"
  },
  {
    "text": "are specifying the cube context for those specifically but with the cube CTL get customers that's actually living in",
    "start": "1217610",
    "end": "1223280"
  },
  {
    "text": "that first that first I guess rancher kubernetes cluster that we spun up so not only is that cluster a I guess a",
    "start": "1223280",
    "end": "1229700"
  },
  {
    "text": "component in our sort of mesh of multi clustered multi multiple clusters here",
    "start": "1229700",
    "end": "1234980"
  },
  {
    "text": "but it's also actually storing the metadata for the rest of the clusters as well so yeah ok so now what I'm doing is",
    "start": "1234980",
    "end": "1245450"
  },
  {
    "text": "making sure that we have like a couple of services that we can play around with like nginx and nature to be able to log",
    "start": "1245450",
    "end": "1252500"
  },
  {
    "text": "in and play with the network in all the clusters you know in the rancher cluster",
    "start": "1252500",
    "end": "1262160"
  },
  {
    "text": "I'm going to run there I have a groper we want to add two two subsidy L now",
    "start": "1262160",
    "end": "1270950"
  },
  {
    "text": "it's still not doing it but we can see that if we have two tunnels established",
    "start": "1270950",
    "end": "1276530"
  },
  {
    "text": "to the other clusters okay yeah I will",
    "start": "1276530",
    "end": "1282200"
  },
  {
    "text": "make sure that we have in UNIX and that should get a list of eyepiece maybe I",
    "start": "1282200",
    "end": "1288650"
  },
  {
    "text": "need to make the fault now found is kind of okay can you still see",
    "start": "1288650",
    "end": "1294289"
  },
  {
    "text": "it okay so with this I will login into",
    "start": "1294289",
    "end": "1302599"
  },
  {
    "text": "the renter cluster and so I'm running in a pod inside the rancher cluster and",
    "start": "1302599",
    "end": "1308840"
  },
  {
    "text": "what I'm going to do is start by something simple like a pink to maybe",
    "start": "1308840",
    "end": "1314960"
  },
  {
    "text": "this one thing works we can also for",
    "start": "1314960",
    "end": "1327109"
  },
  {
    "text": "example try a connection to the one in the Hat we don't know something silly",
    "start": "1327109",
    "end": "1334519"
  },
  {
    "text": "silly like about hoppity remark oops the",
    "start": "1334519",
    "end": "1345440"
  },
  {
    "text": "final and it works very well I mean we only",
    "start": "1345440",
    "end": "1352580"
  },
  {
    "text": "have the the latency of the public network I mean and now we can do it for",
    "start": "1352580",
    "end": "1360890"
  },
  {
    "text": "another places we connect them to the Red Hat cluster from there we can whoops",
    "start": "1360890",
    "end": "1372610"
  },
  {
    "text": "we can for example try to get a response",
    "start": "1372610",
    "end": "1378860"
  },
  {
    "text": "from the nginx on brunch and that will work it's very",
    "start": "1378860",
    "end": "1387380"
  },
  {
    "text": "worrying because it's working all the time it's yeah and I can't repeat the",
    "start": "1387380",
    "end": "1398330"
  },
  {
    "text": "same from the other one but I think it's yeah yeah it works very happy ok so if",
    "start": "1398330",
    "end": "1408080"
  },
  {
    "text": "you want to try out subsidies you can get it from here we just make make their",
    "start": "1408080",
    "end": "1413900"
  },
  {
    "text": "release minutes away I'm very I'm sorry because we only have the Linux binary",
    "start": "1413900",
    "end": "1421370"
  },
  {
    "text": "version but we probably in the next week we will be adding like cross-compilation",
    "start": "1421370",
    "end": "1426380"
  },
  {
    "text": "so you can have the binary for OSX or you know other platforms yeah",
    "start": "1426380",
    "end": "1434330"
  },
  {
    "text": "so as I sort of mentioned earlier um if you're like I said if you're interested in submariner as an operator um",
    "start": "1434330",
    "end": "1440420"
  },
  {
    "text": "definitely join our mailing list and ping us because we're we're trying to you know do our best to make sure that",
    "start": "1440420",
    "end": "1446840"
  },
  {
    "text": "Submariner ends up being something that is usable right so it's very important to us and additionally if you're",
    "start": "1446840",
    "end": "1453200"
  },
  {
    "text": "interested in contributing we do run a weekly meeting on Tuesdays at 8 a.m. Pacific or I think it's 5 p.m. where",
    "start": "1453200",
    "end": "1459710"
  },
  {
    "text": "Miguel's manage set up which is yeah which is Madrid and if you join that mailing list you will get an invite sent",
    "start": "1459710",
    "end": "1466100"
  },
  {
    "text": "sent to you as well and our repositories are gonna be a github home slash submarine or - IO and yeah thank you it",
    "start": "1466100",
    "end": "1475370"
  },
  {
    "text": "is time for questions now that yeah like to point out if you your company is",
    "start": "1475370",
    "end": "1482750"
  },
  {
    "text": "working network plug-in and you want to make sure that we are compatible also with",
    "start": "1482750",
    "end": "1488059"
  },
  {
    "text": "your network plug in please you know our community we are really open to making sure that we are",
    "start": "1488059",
    "end": "1494809"
  },
  {
    "text": "compatible or if you are a close cloud provider and you want to make sure that submariner works in your cloud please",
    "start": "1494809",
    "end": "1502669"
  },
  {
    "text": "join us we have time for questions",
    "start": "1502669",
    "end": "1512960"
  },
  {
    "text": "yep I do",
    "start": "1512960",
    "end": "1520850"
  },
  {
    "text": "yeah so like thanks for securing this wonderful project with you somebody know",
    "start": "1520850",
    "end": "1526659"
  },
  {
    "text": "so my question is regarding the so do we",
    "start": "1526659",
    "end": "1532250"
  },
  {
    "text": "need a third cluster for acting as a broker is this a most necessity so so",
    "start": "1532250",
    "end": "1537889"
  },
  {
    "text": "this is the first question I have okay yes so you don't need a third cluster um for your broker if you're so in kind of",
    "start": "1537889",
    "end": "1545480"
  },
  {
    "text": "a conventional use case has been two clusters that you want to connect together and you can sort of if you have",
    "start": "1545480",
    "end": "1551539"
  },
  {
    "text": "a public API server for one of those two clusters you can designate that or if you have the ability for the two",
    "start": "1551539",
    "end": "1558649"
  },
  {
    "text": "clusters to sort of dial each other's kubernetes API servers or maybe one way or the other you can actually get away with just two",
    "start": "1558649",
    "end": "1565669"
  },
  {
    "text": "clusters yeah in the architecture if you see we made it the default that you only",
    "start": "1565669",
    "end": "1572179"
  },
  {
    "text": "need to two clusters to try it out so unless you specify them not at the plain",
    "start": "1572179",
    "end": "1578710"
  },
  {
    "text": "flag it's going to deploy the in the deploy broker it will deploy both the",
    "start": "1578710",
    "end": "1586009"
  },
  {
    "text": "broker and the submariner data plane so you just need two clusters but the one",
    "start": "1586009",
    "end": "1591950"
  },
  {
    "text": "run in the broker means we publicly accessible because all the grasses need to connect and exchange information",
    "start": "1591950",
    "end": "1598759"
  },
  {
    "text": "there okay so this is based on establishing the IPSec tunnel between",
    "start": "1598759",
    "end": "1604279"
  },
  {
    "text": "the two clusters if I'm not wrong right now so the broker cluster is used to",
    "start": "1604279",
    "end": "1610909"
  },
  {
    "text": "exchange metadata information regarding the endpoints of the clusters and that's why that burger has to be accessible",
    "start": "1610909",
    "end": "1617230"
  },
  {
    "text": "yeah so the endpoints have information about what is every cluster IP address",
    "start": "1617230",
    "end": "1625899"
  },
  {
    "text": "to make the IPSec connection and what are the IP ranges of that cluster so",
    "start": "1625899",
    "end": "1634600"
  },
  {
    "text": "it's just to change information about how to connect to each other but it's",
    "start": "1634600",
    "end": "1641220"
  },
  {
    "text": "yeah if you try it out it will be more more evident yeah all right thank you um",
    "start": "1641220",
    "end": "1658090"
  },
  {
    "text": "so we haven't done specific benchmarks yet and that's on our sort of list of things to do",
    "start": "1658090",
    "end": "1663630"
  },
  {
    "text": "reason being that you're gonna be limited mostly by crypto because of well",
    "start": "1663630",
    "end": "1669279"
  },
  {
    "text": "it's IPSec and then on top of that it's wherever you're running your clusters so we can get we're looking at try to give",
    "start": "1669279",
    "end": "1675039"
  },
  {
    "text": "generic information regarding benchmarking but we don't we haven't done any formal tests yet to be able to",
    "start": "1675039",
    "end": "1680559"
  },
  {
    "text": "give you that but you can is essentially expect your throughput to be what you would conventionally receive with just a",
    "start": "1680559",
    "end": "1687190"
  },
  {
    "text": "standard IPSec tunnel between two two nodes running out and you know your cloud or over the Internet yeah I think",
    "start": "1687190",
    "end": "1695830"
  },
  {
    "text": "that the biggest part factor is probably the latency between there yeah your clusters the closer they are and you can",
    "start": "1695830",
    "end": "1703779"
  },
  {
    "text": "always increase the window size but yeah",
    "start": "1703779",
    "end": "1708970"
  },
  {
    "text": "well really one of the things that we want to do is crusade is running like",
    "start": "1708970",
    "end": "1715570"
  },
  {
    "text": "some benchmarking yeah somebody's working in different situations so",
    "start": "1715570",
    "end": "1721179"
  },
  {
    "text": "people can have figures and maybe compare like okay what's the difference",
    "start": "1721179",
    "end": "1726309"
  },
  {
    "text": "between going through submariner and the IPSec tunnel and mapping the service",
    "start": "1726309",
    "end": "1731440"
  },
  {
    "text": "publicly on the internet and connecting to the service so I think that will be like a significant number that you can",
    "start": "1731440",
    "end": "1739799"
  },
  {
    "text": "use you said earlier that you were",
    "start": "1739799",
    "end": "1745119"
  },
  {
    "text": "interested in use cases that the people had so a use case I'm interested in is I",
    "start": "1745119",
    "end": "1753209"
  },
  {
    "text": "have an on-prem cluster and then I get a bunch of new pods that I want to",
    "start": "1753209",
    "end": "1759429"
  },
  {
    "text": "schedule and rather than queuing them up I launch new clusters on cloud providers",
    "start": "1759429",
    "end": "1767039"
  },
  {
    "text": "burst onto them they like put the workloads there and then shut down those",
    "start": "1767039",
    "end": "1773859"
  },
  {
    "text": "public cloud clusters after the workloads have completed okay yeah and",
    "start": "1773859",
    "end": "1780189"
  },
  {
    "text": "that's those types of burst workloads are actually one of the one of the use cases we are aware of and we're actually",
    "start": "1780189",
    "end": "1787089"
  },
  {
    "text": "working a little bit on or with sort of signal T cluster to or actually signet",
    "start": "1787089",
    "end": "1792369"
  },
  {
    "text": "within Sigma Multi cluster um to try what we sort of or what you know what we",
    "start": "1792369",
    "end": "1798549"
  },
  {
    "text": "have to sort of talked about and this is in very early stages um being able to reference a local service in your",
    "start": "1798549",
    "end": "1804189"
  },
  {
    "text": "cluster and have it aware or you know have essentially populated endpoints for",
    "start": "1804189",
    "end": "1809379"
  },
  {
    "text": "your remote pods and then running controller and exchanging metadata so",
    "start": "1809379",
    "end": "1815139"
  },
  {
    "text": "that you can your application it won't actually have to be modified past the fact that you know it's just going to be",
    "start": "1815139",
    "end": "1821049"
  },
  {
    "text": "it's just going to be hitting that local service happy within your on-premise cluster on and that should actually with",
    "start": "1821049",
    "end": "1826179"
  },
  {
    "text": "submariner connecting your clusters together allow you to burst traffic into your burst burst clusters in the cloud",
    "start": "1826179",
    "end": "1834569"
  },
  {
    "text": "we can take one more",
    "start": "1835529",
    "end": "1839399"
  },
  {
    "text": "this is just this is just a follow on what were the two SIG's that you were working with more work it's a right now",
    "start": "1842090",
    "end": "1847710"
  },
  {
    "text": "we're in conversation with sig network as well as Sigma LT cluster one more",
    "start": "1847710",
    "end": "1856070"
  },
  {
    "text": "you're using IPSec now and everything I was just curious when wire guard makes its way into the mainline kernel is that",
    "start": "1858680",
    "end": "1866640"
  },
  {
    "text": "just another approach that you guys will consider taking or perhaps making it modular and plug in yes so it is so",
    "start": "1866640",
    "end": "1873480"
  },
  {
    "text": "technically when it was first marketed or like when it was first written it was built to be sort of modular like I mean",
    "start": "1873480",
    "end": "1879120"
  },
  {
    "text": "it is it's like it is modular right it's it's just a matter of the actual implementation to make wire drive work I",
    "start": "1879120",
    "end": "1885240"
  },
  {
    "text": "know wire guards come up before in the issues for the project it's just we haven't you know we're still focusing on",
    "start": "1885240",
    "end": "1891480"
  },
  {
    "text": "other aspects of making it usable before we focus on but we are going to be accepting contributions so if anybody",
    "start": "1891480",
    "end": "1899070"
  },
  {
    "text": "wants to contribute a cable engine for whether we're completely open we also looking into implementing other",
    "start": "1899070",
    "end": "1906480"
  },
  {
    "text": "cable engines for example for bx lon I know the explain it's not secure for",
    "start": "1906480",
    "end": "1912540"
  },
  {
    "text": "your traffic but it is useful if there is already a VPN between your casters",
    "start": "1912540",
    "end": "1918810"
  },
  {
    "text": "and you want to have that kind of connectivity and you don't want there IPSec overhead yeah all right thank you",
    "start": "1918810",
    "end": "1927840"
  },
  {
    "text": "very much we appreciate that please rate this flash talk give it a happy face that was a great time",
    "start": "1927840",
    "end": "1933680"
  },
  {
    "text": "you",
    "start": "1933680",
    "end": "1935740"
  }
]
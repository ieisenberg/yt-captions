[
  {
    "start": "0",
    "end": "110000"
  },
  {
    "text": "cool hi everybody my name is Julian Portillo I'm from relativity it's a small Enterprise company that is making",
    "start": "780",
    "end": "7620"
  },
  {
    "text": "a migration from VMS into kubernetes and we have run into a lot of foot guns and",
    "start": "7620",
    "end": "14340"
  },
  {
    "text": "hopefully we can help you guys not hit as many feet and instead hit targets",
    "start": "14340",
    "end": "19680"
  },
  {
    "text": "so we started to migrate to Windows containers in June of 2021. for the",
    "start": "19680",
    "end": "26400"
  },
  {
    "text": "first nine months of this year we've gone through 192 million Windows containers that are actually doing like",
    "start": "26400",
    "end": "32820"
  },
  {
    "text": "production workloads 50 million that are doing Canary workloads and like testing see if nodes are working and we found",
    "start": "32820",
    "end": "39020"
  },
  {
    "text": "105 failed Windows nodes so obviously if you don't have an automated way to catch",
    "start": "39020",
    "end": "44940"
  },
  {
    "text": "failures like that you're going to have a very bad time so help you figure out how you can catch failures such as those",
    "start": "44940",
    "end": "51539"
  },
  {
    "text": "the number one lesson to take away as you migrate to kubernetes on a Linux",
    "start": "51539",
    "end": "56579"
  },
  {
    "text": "world or a Windows world is these things are cattle not pets when you start your",
    "start": "56579",
    "end": "61860"
  },
  {
    "text": "migration pods can be the cattle and then as you get higher and higher in your migration eventually nodes can be a",
    "start": "61860",
    "end": "67799"
  },
  {
    "text": "cattle and shoot those things in the head and find new things and then eventually you can get to the world where clusters can be moved around and",
    "start": "67799",
    "end": "74400"
  },
  {
    "text": "swapped at will and that's where you're in a very happy spot from a devops world",
    "start": "74400",
    "end": "80580"
  },
  {
    "text": "so here's we're going to go through first who are we what is the team that I work on and what is relativity then a",
    "start": "80580",
    "end": "87060"
  },
  {
    "text": "quick understanding of what our first kubernetes setup was why we started to use Windows containers and like the general motivation for it",
    "start": "87060",
    "end": "94259"
  },
  {
    "text": "since it's not a super common way to move two years ago and then Windows container pain points",
    "start": "94259",
    "end": "99299"
  },
  {
    "text": "we run into how you can avoid those and some recent very positive changes like literally this morning for Windows",
    "start": "99299",
    "end": "107100"
  },
  {
    "text": "containers that you'll probably be pretty excited about so who are we I think in engineering",
    "start": "107100",
    "end": "113579"
  },
  {
    "start": "110000",
    "end": "110000"
  },
  {
    "text": "especially platforming devops it's important to remember that it's a team sport you have to make sure that",
    "start": "113579",
    "end": "118740"
  },
  {
    "text": "everybody in the team enjoys working together and that you have there's no one individual who knows everything",
    "start": "118740",
    "end": "124140"
  },
  {
    "text": "about everything on what you're working on on our team we have about 30 really smart motivated happy platform Engineers",
    "start": "124140",
    "end": "131760"
  },
  {
    "text": "that work on making sure that all of Relativity works well we've supported about 500 different application",
    "start": "131760",
    "end": "138780"
  },
  {
    "text": "engineers and we uh have our own music video we've got team logos we've got movie trailers",
    "start": "138780",
    "end": "145440"
  },
  {
    "text": "for demos and we do pretty fun game days where we like see how to break things in production and then how to come back",
    "start": "145440",
    "end": "151440"
  },
  {
    "text": "from the dead when that happens uh our legal team said I could not share our music video team logos or movie trailers",
    "start": "151440",
    "end": "157140"
  },
  {
    "text": "due to copyright infringement I'm not really sure what that means so instead of use stable diffusion to generate",
    "start": "157140",
    "end": "164040"
  },
  {
    "text": "really terrible clip art that goes along with us so enjoy",
    "start": "164040",
    "end": "170000"
  },
  {
    "start": "171000",
    "end": "171000"
  },
  {
    "text": "uh so what is relativity if you all remember tannenbaum's statement about never underestimating the bandwidth of a",
    "start": "171420",
    "end": "178019"
  },
  {
    "text": "station wagon full of cassette tapes going down the highway relativity is attempting to solve the same thing for",
    "start": "178019",
    "end": "183920"
  },
  {
    "text": "747s full of documents when two companies Sue each other you go through a discovery process there's tons and",
    "start": "183920",
    "end": "190739"
  },
  {
    "text": "tons and tons of paperwork in the old days like the 80s they would go and fill",
    "start": "190739",
    "end": "196019"
  },
  {
    "text": "up 747s with boxes of documents and then send armies of lawyers into the hot hot",
    "start": "196019",
    "end": "202260"
  },
  {
    "text": "sun to dive through these documents and write things down on pen and paper in them and then send",
    "start": "202260",
    "end": "208280"
  },
  {
    "text": "faxes and printers and all sorts of nasty things relativity about 20 years",
    "start": "208280",
    "end": "213360"
  },
  {
    "text": "ago started to see that that was not really the right way to handle this and we started moving into the e-discovery",
    "start": "213360",
    "end": "219180"
  },
  {
    "text": "space so around 198 of the top 200 law firms now use our platform for moving",
    "start": "219180",
    "end": "226379"
  },
  {
    "text": "around all their documents for e-discovery and we're pretty ubiquitous inside the legal space if you're not a",
    "start": "226379",
    "end": "232440"
  },
  {
    "text": "legal nerd then you probably have never heard of us but we do a lot of documents and a lot of NLP on those documents",
    "start": "232440",
    "end": "240739"
  },
  {
    "text": "how do we use kubernetes now we have kubernetes clusters in 20 regions spread around the world we have to have them in",
    "start": "240780",
    "end": "246480"
  },
  {
    "text": "certain regions for data protection laws turns out that you can't really move EU data into the US without getting a lot",
    "start": "246480",
    "end": "252480"
  },
  {
    "text": "of regulators very upset U.S stuff you can move around but that's another story we have an orchestration system that can",
    "start": "252480",
    "end": "258479"
  },
  {
    "text": "handle millions of containers per day we have automated vulnerability patching and dynamic image changes so we've",
    "start": "258479",
    "end": "265320"
  },
  {
    "text": "actually just on Tuesday updated os's that we were running on in production",
    "start": "265320",
    "end": "270840"
  },
  {
    "text": "during business hours without any customer Interruption we can do some",
    "start": "270840",
    "end": "276000"
  },
  {
    "text": "pretty cool stuff we run hybrid Linux and windows clusters so we do workloads that are doing Linux and windows at the",
    "start": "276000",
    "end": "282960"
  },
  {
    "text": "same time how he started when we started our kubernetes journey we basically had a",
    "start": "282960",
    "end": "290040"
  },
  {
    "text": "lot of VMS that were doing um just machine learning and NLP things where they would run for a very long",
    "start": "290040",
    "end": "296280"
  },
  {
    "text": "time they'd need to use a lot of CPU for a little while and then they would just kind of sit there and waste money for us",
    "start": "296280",
    "end": "303139"
  },
  {
    "text": "so our very first thing was moving some machine learning analytics Linux workloads into kubernetes and we could",
    "start": "303139",
    "end": "310320"
  },
  {
    "text": "scale up and down at will we got all the really nice things about having like a neat scalable multi-tenant a highly",
    "start": "310320",
    "end": "317400"
  },
  {
    "text": "available architecture with full CSD to production when we started on this road it would take a relatively developer six",
    "start": "317400",
    "end": "324900"
  },
  {
    "text": "months to a year for their code to go from off their machine and into production which that is a terrible",
    "start": "324900",
    "end": "332039"
  },
  {
    "text": "experience nobody likes that that is like I would cry if I dealt with that on a",
    "start": "332039",
    "end": "337740"
  },
  {
    "text": "day-to-day basis I cry thinking about it sometimes too just for fun um now we have full CSD to production",
    "start": "337740",
    "end": "343800"
  },
  {
    "text": "we've actually for one of our demos for vulnerability scanning we are vulnerability patching we ordered a",
    "start": "343800",
    "end": "349979"
  },
  {
    "text": "pizza uh deep dish and tried to race our deploy of our patched images all the way",
    "start": "349979",
    "end": "356699"
  },
  {
    "text": "through our production clusters before the pizza was delivered so we cannot beat thin crust because we have safety",
    "start": "356699",
    "end": "362759"
  },
  {
    "text": "checks as we go through our various rings of production but we can beat deep dish so someday we'll work on getting",
    "start": "362759",
    "end": "369060"
  },
  {
    "text": "better with that um also after the talk we can talk about which kind of pizza is the best Detroit",
    "start": "369060",
    "end": "374520"
  },
  {
    "text": "or Chicago or New York um I think it's Detroit I'll say it I'm here",
    "start": "374520",
    "end": "380660"
  },
  {
    "text": "so Chicago all right so a large portion of the workloads at",
    "start": "381479",
    "end": "387419"
  },
  {
    "start": "386000",
    "end": "386000"
  },
  {
    "text": "relativity were on Windows we were a.net shop we started out doing you know",
    "start": "387419",
    "end": "392580"
  },
  {
    "text": "Microsoft Word documents PDFs uh and like just moving things around that way",
    "start": "392580",
    "end": "397680"
  },
  {
    "text": "so the general gist is we had a lot of Windows VMS that saw how exciting our",
    "start": "397680",
    "end": "405360"
  },
  {
    "text": "Linux workloads were working and then said oh that's great I want to deploy all the way to production with CI CD I",
    "start": "405360",
    "end": "412259"
  },
  {
    "text": "want to be able to get my code out there in my users hands very quickly that should be really easy right",
    "start": "412259",
    "end": "418199"
  },
  {
    "text": "um sure it is really easy if you think about how you're going to do the migration and if you take the time to",
    "start": "418199",
    "end": "425160"
  },
  {
    "text": "pay back tech debt and to think about how you're going to adjust your architecture As you move from VMS to the",
    "start": "425160",
    "end": "432060"
  },
  {
    "text": "kubernetes world we have some groups a relativity that did that and they've",
    "start": "432060",
    "end": "437759"
  },
  {
    "text": "done very very well using Windows containers they've migrated and had very few issues that's not fun to talk about",
    "start": "437759",
    "end": "444479"
  },
  {
    "text": "though the really fun stuff is where we've run into a lot of fun issues like",
    "start": "444479",
    "end": "449759"
  },
  {
    "text": "105 000 broken windows notes so as Tolstoy or Liz Fong Jones from",
    "start": "449759",
    "end": "455460"
  },
  {
    "text": "Google SRE said happy kubernetes migrations are all alike you take your time you think about what you're going",
    "start": "455460",
    "end": "460620"
  },
  {
    "text": "to do you become an expert on what you're going to work on in Dev you scale up in Dev make sure you understand how",
    "start": "460620",
    "end": "465720"
  },
  {
    "text": "things are going to work you pay back all your Enterprise Tech debt and you go",
    "start": "465720",
    "end": "470940"
  },
  {
    "text": "make the argument to all of your business and development leaders saying hey we need to do this or else we're",
    "start": "470940",
    "end": "476880"
  },
  {
    "text": "going to run into problems unhappy migrations are all peculiar because there's going to be certain things that",
    "start": "476880",
    "end": "482400"
  },
  {
    "text": "say hey uh I can't change this this is not a thing that can change for the cloud native world and they don't",
    "start": "482400",
    "end": "489060"
  },
  {
    "text": "realize that if you don't pay back your Tech debt your customers will",
    "start": "489060",
    "end": "494099"
  },
  {
    "text": "it isn't just a thing you can't just say I'm going to make this migration I'm going to change nothing and everything's",
    "start": "494099",
    "end": "499139"
  },
  {
    "text": "going to work really well because you're going to run into problems obviously what we did was",
    "start": "499139",
    "end": "506400"
  },
  {
    "start": "506000",
    "end": "506000"
  },
  {
    "text": "we tried to go and just power through it we took our we had the set of systems that was running a ton of processes",
    "start": "506400",
    "end": "513539"
  },
  {
    "text": "basically whenever a user would click a button inside relativity's UI it would go it's minimum process do some work or",
    "start": "513539",
    "end": "519779"
  },
  {
    "text": "you could schedule a cron and it would go do some work on different things inside a set of VMS scaling up those VMS",
    "start": "519779",
    "end": "526680"
  },
  {
    "text": "was a manual process for our Ops teams that took up to 10 hours to do 10 hours",
    "start": "526680",
    "end": "532080"
  },
  {
    "text": "look Ops teams actually working on them there was a fair amount of detected inside our pipelines to do those",
    "start": "532080",
    "end": "538140"
  },
  {
    "text": "scale-ups so now everyone is very excited about being able to scale up",
    "start": "538140",
    "end": "543420"
  },
  {
    "text": "like at the push roll button and move things forward that way so we went with some very happy happy",
    "start": "543420",
    "end": "550440"
  },
  {
    "text": "ideas we were just going to take basically each of those processes that were running on our VMS package them up",
    "start": "550440",
    "end": "557160"
  },
  {
    "text": "into a container like you would do in Linux and then run it on Windows nodes there's for people who've worked in",
    "start": "557160",
    "end": "563940"
  },
  {
    "text": "Windows containers already you'll notice that there's a lot of very interesting problems there the average Windows 2019",
    "start": "563940",
    "end": "569820"
  },
  {
    "text": "container as of like two years ago started at three gigs when you actually add in all the stuff you need goes up to",
    "start": "569820",
    "end": "576779"
  },
  {
    "text": "six gigs or 15 if you aren't very careful on Linux you can do this you can run you",
    "start": "576779",
    "end": "583620"
  },
  {
    "text": "know sub 100 megabytes sub 15 megabyte processes that do everything you need distros containers are really great",
    "start": "583620",
    "end": "590880"
  },
  {
    "text": "um and you can just run things very quickly have an average life of 30 seconds and be off for the races when",
    "start": "590880",
    "end": "597899"
  },
  {
    "text": "you try to do that with Windows you will have relatively long pull times if you're not careful with how you're",
    "start": "597899",
    "end": "602940"
  },
  {
    "text": "pulling onto the node when you're starting these things you can also get into some very nasty situations where",
    "start": "602940",
    "end": "608519"
  },
  {
    "text": "nodes will just fall over when you're pulling like 40 Pods at once that all have you know 10 gigabytes of data",
    "start": "608519",
    "end": "616140"
  },
  {
    "text": "so as you can guess our initial results ended up in sad cloud",
    "start": "616140",
    "end": "621420"
  },
  {
    "start": "617000",
    "end": "617000"
  },
  {
    "text": "we had some common networking failures we had some common container start issues there was a huge lack of visibility and there was a huge lack of",
    "start": "621420",
    "end": "628380"
  },
  {
    "text": "common open source tools like Linux node problem detector is what everybody uses in Linux right you can identify when",
    "start": "628380",
    "end": "634860"
  },
  {
    "text": "your node has fallen over there's lots of cool statuses if you find a new status like plague from like five years",
    "start": "634860",
    "end": "640200"
  },
  {
    "text": "ago somebody's probably already noticed that and added a patch to Linux on projector so you can catch that that did not exist",
    "start": "640200",
    "end": "647700"
  },
  {
    "text": "for Windows containers uh two years ago so we didn't we couldn't install hose",
    "start": "647700",
    "end": "653579"
  },
  {
    "text": "containers or privileged containers at the time so you could not get access to the host without setting up a Bastion",
    "start": "653579",
    "end": "658920"
  },
  {
    "text": "server and then rdping into the host which is a real pain and nobody wants to",
    "start": "658920",
    "end": "665459"
  },
  {
    "text": "do that and no security team will let you do that in production where you generally run into issues if you can",
    "start": "665459",
    "end": "671760"
  },
  {
    "text": "catch scaling issues in your non-production environments you can stop your promotion to production if you can",
    "start": "671760",
    "end": "677220"
  },
  {
    "text": "only catch them in production and you can't RDP into your node in production you are in a very sad spot so you have",
    "start": "677220",
    "end": "683760"
  },
  {
    "text": "to build better and better scaling tests in your non-production environment and get all sorts of fun things there",
    "start": "683760",
    "end": "689820"
  },
  {
    "text": "so no privilege containers no metrics as well that has recently changed with host",
    "start": "689820",
    "end": "695220"
  },
  {
    "start": "690000",
    "end": "690000"
  },
  {
    "text": "containers and no and windows node exporter and there's no easy logs and we",
    "start": "695220",
    "end": "700680"
  },
  {
    "text": "couldn't do very easy scanning and defense for vulnerabilities we had to do some interesting changes in terms of how",
    "start": "700680",
    "end": "707940"
  },
  {
    "text": "we were scanning uh nodes or scanning containers with Linux if you use like an",
    "start": "707940",
    "end": "713459"
  },
  {
    "text": "off-the-shelf container scanner you can generally do your scanning on your production nodes if you have a large",
    "start": "713459",
    "end": "718500"
  },
  {
    "text": "enough pool of nodes you won't run into huge issues with performance we try to",
    "start": "718500",
    "end": "724079"
  },
  {
    "text": "do that with Windows and random massive issues so we started to do that kind of scanning off off in our non-production",
    "start": "724079",
    "end": "731279"
  },
  {
    "text": "environments instead and then tracking shots of what we're actually deploying to keep track of whether there were",
    "start": "731279",
    "end": "736620"
  },
  {
    "text": "vulnerabilities and the general debugging nightmares that we had so our first solution to get around",
    "start": "736620",
    "end": "742500"
  },
  {
    "start": "741000",
    "end": "741000"
  },
  {
    "text": "these you can't solve problems if you can't measure them so we started to run code on the host we set up different",
    "start": "742500",
    "end": "748500"
  },
  {
    "text": "code to export it's using it to punt out the blob if we",
    "start": "748500",
    "end": "753779"
  },
  {
    "text": "saw there were issues to identify what things we were dealing with we started to set up things where we could actually",
    "start": "753779",
    "end": "759779"
  },
  {
    "text": "like punt out metrics that we cared about from the containers that we cared about and we logged made sure that all",
    "start": "759779",
    "end": "765899"
  },
  {
    "text": "of our teams had really solid logging from the containers one really key thing",
    "start": "765899",
    "end": "771240"
  },
  {
    "text": "that let us do that is we have a base image for all of our agent teams or all the like developer teams that are",
    "start": "771240",
    "end": "777420"
  },
  {
    "text": "building these these processes that are these windows container processes and we",
    "start": "777420",
    "end": "782519"
  },
  {
    "text": "can easily update for all of our user teams everything that they're running from a centralized location so if we do",
    "start": "782519",
    "end": "789480"
  },
  {
    "text": "find this a vulnerability our orchestrator plus that Imaging service can go make it so we fix that",
    "start": "789480",
    "end": "795240"
  },
  {
    "text": "vulnerability or if we find that there's a bug with how we're pushing out logging and we want or we want to change the",
    "start": "795240",
    "end": "800459"
  },
  {
    "text": "amounts of logs we're getting we can easily do that and adjust even for certain regions so make sure you don't",
    "start": "800459",
    "end": "807420"
  },
  {
    "text": "even more than a Linux World make sure that you have your users all in here from single base image that your",
    "start": "807420",
    "end": "813240"
  },
  {
    "text": "platform team can control unless you have very very solid developing teams that",
    "start": "813240",
    "end": "818760"
  },
  {
    "text": "um really know what they're doing and want to really go around and then be careful still and then we use kubernetes",
    "start": "818760",
    "end": "825360"
  },
  {
    "text": "events and the API to get as much visibility as possible what we learned was that on a fairly",
    "start": "825360",
    "end": "832860"
  },
  {
    "text": "significant number of Windows pod startups we're getting different Windows node failures sometimes those will clear",
    "start": "832860",
    "end": "839579"
  },
  {
    "text": "up sometimes they would not the we were seeing a large number of HCS shim errors",
    "start": "839579",
    "end": "845579"
  },
  {
    "text": "and what that is is this is a beginner talks we're not going to like go into huge details if anyone wants to go into",
    "start": "845579",
    "end": "850740"
  },
  {
    "text": "details though I'm going to grab launch after this so feel free we can go talk and commiserate but anyway HCS shim",
    "start": "850740",
    "end": "857220"
  },
  {
    "text": "errors were the bane of our existence for a little while they would cause random pod failures we",
    "start": "857220",
    "end": "864180"
  },
  {
    "text": "catch them by those events and then we found that the node generally did not recover after those HS shimmers we",
    "start": "864180",
    "end": "871320"
  },
  {
    "text": "actually worked with some Microsoft folks thanks guys they're over there to we shared some testing that we had and",
    "start": "871320",
    "end": "878880"
  },
  {
    "text": "showed that and they started to patch a fair number of those errors so first shot when is the projector we",
    "start": "878880",
    "end": "886620"
  },
  {
    "text": "looked at all the events and then we tried to Cordon that worked actually really well we were able to catch things",
    "start": "886620",
    "end": "892440"
  },
  {
    "text": "we were able to get a it was very fast too we could easily catch an event and then corn a node and we saw that event",
    "start": "892440",
    "end": "899160"
  },
  {
    "text": "go away on new every slot event go away then we could let it go or let that node",
    "start": "899160",
    "end": "904260"
  },
  {
    "text": "back into the friendly pool problem with it though there were even",
    "start": "904260",
    "end": "909420"
  },
  {
    "start": "907000",
    "end": "907000"
  },
  {
    "text": "more variations on failures that did not work very well for us there were tons of",
    "start": "909420",
    "end": "914940"
  },
  {
    "text": "ways that we'd get failures that we just weren't ready for so as an example one of the failures we're going to talk",
    "start": "914940",
    "end": "920579"
  },
  {
    "text": "about today is a hose knocking system failures h s failures and we're going to talk about how that has actually had",
    "start": "920579",
    "end": "926399"
  },
  {
    "text": "with a live demo we're going to show how this actually had a pretty huge change in the last five hours in four regions",
    "start": "926399",
    "end": "935220"
  },
  {
    "text": "in AKs which is kind of cool um so we also ran into new failures only",
    "start": "935220",
    "end": "940920"
  },
  {
    "text": "at scale so this was not a great way to go about trying to catch things we had",
    "start": "940920",
    "end": "946680"
  },
  {
    "text": "to continually update our event logger we had continually event update what we were looking for and it was just not a",
    "start": "946680",
    "end": "951959"
  },
  {
    "text": "very fun thing and as you're scheduling tens of thousands of containers in 20 minutes you actually tend to put a fair",
    "start": "951959",
    "end": "958860"
  },
  {
    "text": "amount of stress on the control plane so you don't want to have a lot of different things looking at all the",
    "start": "958860",
    "end": "965160"
  },
  {
    "text": "events coming off of your cluster yes you can send them to another spot and then watch over a centralized location",
    "start": "965160",
    "end": "970440"
  },
  {
    "text": "but we weren't really set up for that at the time so our second version which is actually",
    "start": "970440",
    "end": "976139"
  },
  {
    "start": "974000",
    "end": "974000"
  },
  {
    "text": "what's been in use as we've scaled up on our Windows container usage and it's a",
    "start": "976139",
    "end": "981839"
  },
  {
    "text": "really simple solution that has worked very well which is my favorite kind of solution we've had to do just very minor",
    "start": "981839",
    "end": "988500"
  },
  {
    "text": "code commit updates for it as we've found vulnerabilities and dependencies all we do is we schedule we have a",
    "start": "988500",
    "end": "995519"
  },
  {
    "text": "canary pod scale Journal scheduler on a cron that schedules to every node that comes up and if the canary fails we corn",
    "start": "995519",
    "end": "1003259"
  },
  {
    "text": "the node then if it passes we wait a few we wait some period of time schedule a",
    "start": "1003259",
    "end": "1008420"
  },
  {
    "text": "pod again see if that pod can connect to a variety of things we know the Pod needs to connect to and do stuff it",
    "start": "1008420",
    "end": "1013519"
  },
  {
    "text": "needs to connect to and or checks a little bit of performance and if we notice some really bad performance uh we",
    "start": "1013519",
    "end": "1019459"
  },
  {
    "text": "also get rid of the node and if the canaries fail and more times drain the node if they were passed then",
    "start": "1019459",
    "end": "1025579"
  },
  {
    "text": "on quarter the node super easy super simple and it's worked really well",
    "start": "1025579",
    "end": "1032720"
  },
  {
    "text": "this is what our actual growth pattern of Windows containers that are running customer workloads has looked like",
    "start": "1032720",
    "end": "1038900"
  },
  {
    "text": "so in June of 2021 people were kind of excited we tried to test it out",
    "start": "1038900",
    "end": "1044480"
  },
  {
    "text": "that's around 40 000 for our first month we started notice issues we cut back and",
    "start": "1044480",
    "end": "1051080"
  },
  {
    "text": "switched back to our non-kubernetes VMS to run our agent workloads as a platform team we started",
    "start": "1051080",
    "end": "1057080"
  },
  {
    "text": "to look at like what issues we were having and tried to start fixing those working with Microsoft working on our own to try to solve these problems",
    "start": "1057080",
    "end": "1063799"
  },
  {
    "text": "and then we restarted the migration in August and basically for the last two",
    "start": "1063799",
    "end": "1068840"
  },
  {
    "text": "years we have an 8 000 year-over-year growth which sounds cool but is not a",
    "start": "1068840",
    "end": "1074480"
  },
  {
    "text": "good thing we don't actually get paid money per Windows container that we run I've tried to make an argument for that",
    "start": "1074480",
    "end": "1080120"
  },
  {
    "text": "for our customers but nobody has taken me up on it um so as you'll notice we've actually",
    "start": "1080120",
    "end": "1085460"
  },
  {
    "text": "dropped in the past month we've been switching a lot of our deployments from",
    "start": "1085460",
    "end": "1091100"
  },
  {
    "text": "this you know really fast schedule a ton of containers to instead have a",
    "start": "1091100",
    "end": "1096500"
  },
  {
    "text": "multi-tenant shared container that runs workloads we can get the same amount of customer work done and we do a lot we",
    "start": "1096500",
    "end": "1103280"
  },
  {
    "text": "have a lot less like platform work it makes life a lot better for our user",
    "start": "1103280",
    "end": "1109880"
  },
  {
    "text": "teams and it makes life a lot better for our platform teams it's a little bit less fun because it's kind of fun to",
    "start": "1109880",
    "end": "1117380"
  },
  {
    "text": "think about like if we can get to a billion containers but if I ever come up here and give a talk on scheduling a",
    "start": "1117380",
    "end": "1122720"
  },
  {
    "text": "billion Linux or Windows containers in a month that isn't just like a performance check",
    "start": "1122720",
    "end": "1128260"
  },
  {
    "text": "I will not be happy and nobody will be so",
    "start": "1128260",
    "end": "1134120"
  },
  {
    "text": "this is kind of a you know we were talking about 105 Windows nodes fit 105 000 Windows node failures it was sort of",
    "start": "1134120",
    "end": "1140480"
  },
  {
    "text": "scary the general gist here though is life has gotten a lot better",
    "start": "1140480",
    "end": "1146000"
  },
  {
    "text": "switching to 2022 instead of 2019 in one of our test environments uh caused our failures per day in that test",
    "start": "1146000",
    "end": "1152600"
  },
  {
    "text": "environment to drop from 22.3 to only 2.6 which is pretty huge",
    "start": "1152600",
    "end": "1158360"
  },
  {
    "text": "um there was no actual change there these are are no actual change other than switching between the os's our code",
    "start": "1158360",
    "end": "1164780"
  },
  {
    "text": "that are running and the amount of containers we were running was the exact same all the systems exact same and our",
    "start": "1164780",
    "end": "1170720"
  },
  {
    "text": "stress test was the exact same we're running on container D for both 2018 and 2022.",
    "start": "1170720",
    "end": "1177260"
  },
  {
    "text": "um and once we have this hns patch that we're going to do a live demo of in a moment uh We've cut down to 0.14",
    "start": "1177260",
    "end": "1184039"
  },
  {
    "text": "failures in that test environment uh which is pretty cool so starting about",
    "start": "1184039",
    "end": "1189440"
  },
  {
    "text": "June I think uh a lot of other people inside the windows container Community started to notice these HS failures and",
    "start": "1189440",
    "end": "1196100"
  },
  {
    "text": "like tried to debug where they're coming from um we also have been hit by this in a",
    "start": "1196100",
    "end": "1201320"
  },
  {
    "text": "major way our mitigations that we had in place were starting to fall a little bit",
    "start": "1201320",
    "end": "1207260"
  },
  {
    "text": "at scale uh turns out when you're scheduling like 30 million containers uh inside a single cluster",
    "start": "1207260",
    "end": "1213919"
  },
  {
    "text": "um it's not fun to deal with those failures so we started to dig more deeply into what's actually causing",
    "start": "1213919",
    "end": "1220820"
  },
  {
    "start": "1214000",
    "end": "1214000"
  },
  {
    "text": "these failures and like what what was happening on the nodes when we had these and because our host containers",
    "start": "1220820",
    "end": "1226340"
  },
  {
    "text": "available we could poke around more easily than already peeing in and we could write things that would go capture",
    "start": "1226340",
    "end": "1231919"
  },
  {
    "text": "logs send them a blob and then debug what was happening we noticed on 9 out of 10 of our node failures at the time",
    "start": "1231919",
    "end": "1238820"
  },
  {
    "text": "we started grabbing these these failures the hns was crashing on and for anybody",
    "start": "1238820",
    "end": "1243919"
  },
  {
    "text": "who's looked into this on 2019 if you try and reboot h s and like Q proxy it",
    "start": "1243919",
    "end": "1249799"
  },
  {
    "text": "just won't work it will take a very very long time it'll take 110 minutes to be like a decent sized cluster on 2022",
    "start": "1249799",
    "end": "1256340"
  },
  {
    "text": "it'll come back relatively quickly but there's also other issues if you",
    "start": "1256340",
    "end": "1262460"
  },
  {
    "text": "don't be careful with relying upon just rebooting hns and qproxy if you don't",
    "start": "1262460",
    "end": "1268400"
  },
  {
    "text": "also check for failures of certain pods when they when the networking moves back you can have pods stuck in pods stuck in",
    "start": "1268400",
    "end": "1276140"
  },
  {
    "text": "running with no actual working load balancer so side note build a check for",
    "start": "1276140",
    "end": "1281600"
  },
  {
    "text": "that with your pods anyway we found that out uh we talked to our friends at Microsoft and we said hey",
    "start": "1281600",
    "end": "1286940"
  },
  {
    "text": "we're noticing this a lot we noticed that there's seg fault when we schedule a ton of PODS and we built a little uh",
    "start": "1286940",
    "end": "1293240"
  },
  {
    "text": "test script that goes and schedules um even more pathologically than our production use case and can recreate",
    "start": "1293240",
    "end": "1300620"
  },
  {
    "text": "this failure pretty much at will so the NG engines that Microsoft started to",
    "start": "1300620",
    "end": "1306260"
  },
  {
    "text": "figure out where that segment was in hns and then they gave us an unsigned binary",
    "start": "1306260",
    "end": "1311360"
  },
  {
    "text": "to test in our regression environments so we set up some ways to test that and",
    "start": "1311360",
    "end": "1317179"
  },
  {
    "text": "that's we got to this h s patch we this actually these numbers the 0.14 are from",
    "start": "1317179",
    "end": "1323000"
  },
  {
    "text": "the update that got put out we actually grabbed the signed binary instead of the unsigned binary and tested it out on our",
    "start": "1323000",
    "end": "1329960"
  },
  {
    "text": "own uh the other very important thing if you guys have not made the move yet is",
    "start": "1329960",
    "end": "1336500"
  },
  {
    "start": "1331000",
    "end": "1331000"
  },
  {
    "text": "switch to containerd with the exact same production cluster where we're seeing 436 on average node failures per day",
    "start": "1336500",
    "end": "1343520"
  },
  {
    "text": "which is not a fun experience make sure you automate catching these things we only had 82 once we switched to",
    "start": "1343520",
    "end": "1349700"
  },
  {
    "text": "container d yay and then once we did containerdy we can",
    "start": "1349700",
    "end": "1356840"
  },
  {
    "text": "comparing 2019 and 2022 we've caught 37 in our production environment you'll",
    "start": "1356840",
    "end": "1362360"
  },
  {
    "text": "notice this is different than our test environment our test environment showed like you know 90 drop this was only 50",
    "start": "1362360",
    "end": "1368799"
  },
  {
    "text": "production is different than test you can try to do as much stuff that is similar to test or similar to production",
    "start": "1368799",
    "end": "1374120"
  },
  {
    "text": "in your non-prone environments but you will still run into issues is what I found",
    "start": "1374120",
    "end": "1379700"
  },
  {
    "text": "okay and then here's the live demo portion um this morning like 7 30 Detroit time I",
    "start": "1379700",
    "end": "1386000"
  },
  {
    "text": "got a note from some Microsoft devs in Shanghai that they had released the AKs",
    "start": "1386000",
    "end": "1391700"
  },
  {
    "text": "build for the HMS patch to for the Regents that are are busy so we asked",
    "start": "1391700",
    "end": "1396980"
  },
  {
    "text": "them to release two uh when I started this talk I went and uh checked out what",
    "start": "1396980",
    "end": "1402620"
  },
  {
    "text": "what it looked like right before I started this talk I want to check out what it looked like we had five failures on our 2019 we had zero failures on our",
    "start": "1402620",
    "end": "1409820"
  },
  {
    "text": "2022. that is not fun so my friend Mike",
    "start": "1409820",
    "end": "1415520"
  },
  {
    "text": "is running a stress test right now as we speak on our 2022 nodes so we can see",
    "start": "1415520",
    "end": "1420980"
  },
  {
    "text": "how this worked um let's see",
    "start": "1420980",
    "end": "1428919"
  },
  {
    "text": "uh this is our fun slack Channel where we report all of our non-production Canary things we also have metrics that",
    "start": "1430700",
    "end": "1437780"
  },
  {
    "text": "we use and stuff but I like seeing things in slack because it's fun looks like",
    "start": "1437780",
    "end": "1444559"
  },
  {
    "text": "we have some more 2019 failures since we started this talk but zero 2022 failures",
    "start": "1444559",
    "end": "1450980"
  },
  {
    "text": "so that's pretty cool yay um",
    "start": "1450980",
    "end": "1456500"
  },
  {
    "text": "so I would strongly recommend if you are running Windows containers in production to try to",
    "start": "1456500",
    "end": "1462919"
  },
  {
    "text": "upgrade as quickly as possible in those regions where it's released right now it's only",
    "start": "1462919",
    "end": "1468380"
  },
  {
    "text": "in ukso cact Canada Central so you can go across the river over there and say",
    "start": "1468380",
    "end": "1473900"
  },
  {
    "text": "hello and say Enjoy your stable Windows containers also in central U.S and",
    "start": "1473900",
    "end": "1479240"
  },
  {
    "text": "eastern U.S it's going to roll out to the other I can put this in um alt day new slide I can put the exact",
    "start": "1479240",
    "end": "1485539"
  },
  {
    "text": "like GitHub commit to follow but it'll roll out to the other regions over the next two or three weeks too so make sure",
    "start": "1485539",
    "end": "1492440"
  },
  {
    "text": "you update make sure you grab that you'll be a lot happier Okay so",
    "start": "1492440",
    "end": "1498080"
  },
  {
    "start": "1496000",
    "end": "1496000"
  },
  {
    "text": "tail shoe designs things been really sad really scary this is only for some subset of our",
    "start": "1498080",
    "end": "1503900"
  },
  {
    "text": "developers the developers who built long-lived Windows containers that were just doing workloads their work just got",
    "start": "1503900",
    "end": "1511520"
  },
  {
    "text": "the job done they had to handle failures from nodes and move over to non-busted",
    "start": "1511520",
    "end": "1518480"
  },
  {
    "text": "nodes we eventually actually set up some node pools for relatively long run contain or Long Live containers that let",
    "start": "1518480",
    "end": "1524900"
  },
  {
    "text": "them live in a happier environment for a while so there's some real pros out there like you get the job done your",
    "start": "1524900",
    "end": "1531919"
  },
  {
    "text": "customers are happy they give you more money there's a huge con though you have a lot more free time and then your PMS",
    "start": "1531919",
    "end": "1537919"
  },
  {
    "text": "keep asking you to put out features instead of you know fighting fires and that is uh you know it's a downside",
    "start": "1537919",
    "end": "1545480"
  },
  {
    "text": "30 second Windows containers however from a platform perspective there's a lot of really fun problems to solve and",
    "start": "1545480",
    "end": "1551299"
  },
  {
    "text": "you have to solve those very quickly as you get more and more containers thrown at you so we've had you know some pretty",
    "start": "1551299",
    "end": "1557120"
  },
  {
    "text": "interesting times solving these problems at scale as they come up and big numbers are really fun I like to see if we can",
    "start": "1557120",
    "end": "1563240"
  },
  {
    "text": "get another comma put onto things sometimes con is obviously lots of problems to solve and long startup times",
    "start": "1563240",
    "end": "1570320"
  },
  {
    "text": "in the critical path are one of my least happy things in the world I started my",
    "start": "1570320",
    "end": "1575419"
  },
  {
    "text": "career in high frequency trading and we had to get all of our code out the door and under sub 8 microseconds so the fact",
    "start": "1575419",
    "end": "1582799"
  },
  {
    "text": "that it takes us like four minutes to pull a Windows container really may be very sad",
    "start": "1582799",
    "end": "1589360"
  },
  {
    "start": "1590000",
    "end": "1590000"
  },
  {
    "text": "takeaways please upgrade to container D and grab this HMS patch as soon as",
    "start": "1590059",
    "end": "1595159"
  },
  {
    "text": "possible if you're using 2022 it's going to be released very soon 2019 it's not going to be out till November you guys",
    "start": "1595159",
    "end": "1602480"
  },
  {
    "text": "can go talk to the Microsoft folks and like ask them to move things faster I think they'll have like nice name badges so hunt them down they're very friendly",
    "start": "1602480",
    "end": "1609700"
  },
  {
    "text": "host containers if you're not using them yet they make cluster configuration almost like Linux and it's very nice I'm",
    "start": "1609700",
    "end": "1617480"
  },
  {
    "text": "pretty excited to see what other companies start building and if I can convince some people at relativity to let us start open sourcing some of the",
    "start": "1617480",
    "end": "1623779"
  },
  {
    "text": "tools that we're building instead of just stealing things from the open source Community I'm just kidding we we",
    "start": "1623779",
    "end": "1629960"
  },
  {
    "text": "are we are actually actively working on making sure that our legal team lets us open source some things and also as",
    "start": "1629960",
    "end": "1636380"
  },
  {
    "text": "you're making a kubernetes migration whether it's Windows containers or Linux containers the best way to solve a problem is to not have the problem in",
    "start": "1636380",
    "end": "1642919"
  },
  {
    "text": "the first place work around the problem so you don't have to don't have to schedule you know 30 million Windows",
    "start": "1642919",
    "end": "1648919"
  },
  {
    "text": "containers Instead try to figure out how to schedule three and get the same amount of work done",
    "start": "1648919",
    "end": "1654020"
  },
  {
    "text": "um yeah so I'm actually way early on time but that means there's lots of time for",
    "start": "1654020",
    "end": "1659720"
  },
  {
    "text": "questions if you want to start asking them",
    "start": "1659720",
    "end": "1663039"
  },
  {
    "text": "thank you [Applause]",
    "start": "1665380",
    "end": "1670760"
  },
  {
    "text": "an equation okay",
    "start": "1670760",
    "end": "1673960"
  },
  {
    "text": "so I've actually ran into a similar problem of the sort of short-lived",
    "start": "1680360",
    "end": "1686299"
  },
  {
    "text": "containers even on Linux there's this sort of anti-pattern I see",
    "start": "1686299",
    "end": "1692059"
  },
  {
    "text": "a lot in the sort of Legacy production of this whole like Tron servers the server it runs it has like a whole bunch",
    "start": "1692059",
    "end": "1698539"
  },
  {
    "text": "of cron jobs and this conjure and it like runs all the different Crown jobs and it runs them in parallel and it just",
    "start": "1698539",
    "end": "1704419"
  },
  {
    "text": "you just throw enough see uh CPUs added and maybe it works um but uh when you kind of migrate that",
    "start": "1704419",
    "end": "1711140"
  },
  {
    "text": "into Cube what I've noticed is like okay like of course the system is a lot more kind of distributed and sane but there's",
    "start": "1711140",
    "end": "1718460"
  },
  {
    "text": "a lot more overhead for kubernetes Cron job compared to like having like uh 70",
    "start": "1718460",
    "end": "1723860"
  },
  {
    "text": "crons on like a Linux server basically so what uh do you think like there's any",
    "start": "1723860",
    "end": "1729679"
  },
  {
    "text": "kind of um Solutions uh like either potential or",
    "start": "1729679",
    "end": "1735559"
  },
  {
    "text": "like um that currently exists that could like maybe bridge that Gap when it comes to that kind of massive increase in",
    "start": "1735559",
    "end": "1742880"
  },
  {
    "text": "overhead that you get when you're migrating Crown jobs to kubernetes especially short-lived ones",
    "start": "1742880",
    "end": "1748820"
  },
  {
    "text": "so I think the problem there is that there are some solutions that solve like 80 of those problems right but a hundred",
    "start": "1748820",
    "end": "1755720"
  },
  {
    "text": "percent of the problem is with that last 20 there's nothing that I know of that will make it so you can just take",
    "start": "1755720",
    "end": "1762140"
  },
  {
    "text": "exactly what we're running NVM transport it to the cloud without making any changes and have things work perfectly",
    "start": "1762140",
    "end": "1768559"
  },
  {
    "text": "you're right though that is a thing that you run into in a major way and I've seen that happen at two different companies that I've worked at figuring",
    "start": "1768559",
    "end": "1775039"
  },
  {
    "text": "out how to make the changes as you make the migration and instead like running if",
    "start": "1775039",
    "end": "1781580"
  },
  {
    "text": "you do some performance testing on your workloads and see where you're actually getting caught if it is the container",
    "start": "1781580",
    "end": "1787640"
  },
  {
    "text": "startup time if it is like you're getting i o blocked or like what kind of what kind of issues you're running into",
    "start": "1787640",
    "end": "1793220"
  },
  {
    "text": "and try both ways the cool thing about kubernetes and like the cloud native world is you can move really fast and",
    "start": "1793220",
    "end": "1800000"
  },
  {
    "text": "test your assumptions so do it get some data",
    "start": "1800000",
    "end": "1805600"
  },
  {
    "text": "Humanity",
    "start": "1808880",
    "end": "1811880"
  },
  {
    "text": "oh I agree with that and I think the old so the for anybody who's listening virtually he was saying when you're saying it's running every minute you're",
    "start": "1822020",
    "end": "1828140"
  },
  {
    "text": "going to run into these these pains and I think you're right the only way to change that is to change the system",
    "start": "1828140",
    "end": "1833600"
  },
  {
    "text": "design so you don't run into that we I didn't go into detail on what our agent framework looks like but basically we",
    "start": "1833600",
    "end": "1840080"
  },
  {
    "text": "have a ton of virtual machines that are running relatively software that our customers use and every minute",
    "start": "1840080",
    "end": "1847100"
  },
  {
    "text": "yes it's a minute we have this tool for a region that goes around and checks to",
    "start": "1847100",
    "end": "1852559"
  },
  {
    "text": "see how many containers we need to start the to get various workloads done it",
    "start": "1852559",
    "end": "1857600"
  },
  {
    "text": "checks workload Discovery endpoints for all of our various uh pieces of various microservices",
    "start": "1857600",
    "end": "1863299"
  },
  {
    "text": "our first shot was to just start up everything that was asked for all the time and have throttling just in the",
    "start": "1863299",
    "end": "1870260"
  },
  {
    "text": "platform layer and that does not work you have to also figure out how to have",
    "start": "1870260",
    "end": "1876020"
  },
  {
    "text": "changes to that current job portion",
    "start": "1876020",
    "end": "1880360"
  },
  {
    "text": "thank you Julian thanks for coming yeah thank you everybody for coming I really appreciate it",
    "start": "1881600",
    "end": "1887560"
  },
  {
    "text": "[Applause] [Music]",
    "start": "1887560",
    "end": "1891349"
  }
]
[
  {
    "text": "um hello everybody uh my name is we way and I'm from Apple Uhl data infra team",
    "start": "799",
    "end": "7720"
  },
  {
    "text": "and today as we're supposed to be me and uh Bowen to give this presentation but",
    "start": "7720",
    "end": "12799"
  },
  {
    "text": "Bowen couldn't make the trip here so I will be presenting this along and the",
    "start": "12799",
    "end": "17840"
  },
  {
    "text": "session is beyond experimental spark and kues uh if you are running spark NOA is",
    "start": "17840",
    "end": "23840"
  },
  {
    "text": "on kubernetes or not uh this this is the right room for you and if you're not not",
    "start": "23840",
    "end": "29039"
  },
  {
    "text": "running Spar you're running some batch jobs I think this is also very",
    "start": "29039",
    "end": "33960"
  },
  {
    "text": "relevant um so today's agenda is we um the first part I will be talking about",
    "start": "34040",
    "end": "40719"
  },
  {
    "text": "how to build the cloud lative data platform so everybody is talking about cloud lative and how does it mean for a",
    "start": "40719",
    "end": "47920"
  },
  {
    "text": "data Pro processing platform uh where the backand is spark and the second part",
    "start": "47920",
    "end": "53440"
  },
  {
    "text": "I'll be talking about so basically when we build the platform we actually met a lot of challenges I I believe most the",
    "start": "53440",
    "end": "60199"
  },
  {
    "text": "people do and so we basically talk about how we leverage open source software to",
    "start": "60199",
    "end": "67240"
  },
  {
    "text": "tle the challenges and then uh the third part is when we go to scale and we as seeing a",
    "start": "67240",
    "end": "74920"
  },
  {
    "text": "lot of more problems and now we are talking about how to addressing these issues when we scale up and the last",
    "start": "74920",
    "end": "82680"
  },
  {
    "text": "part will be um talking about a future work and first things that um what we're",
    "start": "82680",
    "end": "90479"
  },
  {
    "text": "doing here is to want to build really build a cloud lative batch processing and interactive analytics platform uh on",
    "start": "90479",
    "end": "98399"
  },
  {
    "text": "top of kubernetes and also powered by aart spark and this will handling large",
    "start": "98399",
    "end": "104840"
  },
  {
    "text": "data processing mer learning workloads and for different users all sorts of uh",
    "start": "104840",
    "end": "110960"
  },
  {
    "text": "jobs so basically the platform where supports like scheduled workflows ad hoc queries also have badge jobs and",
    "start": "110960",
    "end": "118079"
  },
  {
    "text": "interactive sessions um and for job types they help some of jobs are really Mission critical and they they don't",
    "start": "118079",
    "end": "125600"
  },
  {
    "text": "they want the job can be done as soon as possible and also there are some other puc jobs user randomly submit sandbox",
    "start": "125600",
    "end": "133800"
  },
  {
    "text": "jobs and from the uh jobs execution uh some of jobs may just take a few minutes",
    "start": "133800",
    "end": "139519"
  },
  {
    "text": "or even seconds but some of them are taking days so given all these things",
    "start": "139519",
    "end": "144640"
  },
  {
    "text": "together and we are essentially building a pretty complex system where we want to",
    "start": "144640",
    "end": "150080"
  },
  {
    "text": "support all those workloads uh and also do not give user complexity right users",
    "start": "150080",
    "end": "155680"
  },
  {
    "text": "just need to submit their jobs and um everything will just work this is this is the user expectation and our work is",
    "start": "155680",
    "end": "162959"
  },
  {
    "text": "just to make it simple based on the cloud lative um software and uh the",
    "start": "162959",
    "end": "168000"
  },
  {
    "text": "ecosystem to make it happen um first let's talk about",
    "start": "168000",
    "end": "173360"
  },
  {
    "text": "architecture Evolution so I'm from the old Hadoop world so I I spend a lot of",
    "start": "173360",
    "end": "179959"
  },
  {
    "text": "years working on Hadoop and so in the past days that we are running like spark",
    "start": "179959",
    "end": "185360"
  },
  {
    "text": "on on thousands of nose cluster at that time we want really want to build a",
    "start": "185360",
    "end": "191159"
  },
  {
    "text": "really giant clusters the reason for that is basically uh as that time so",
    "start": "191159",
    "end": "197040"
  },
  {
    "text": "data and the computer are sharing the hardware so when you want to store more data you need to scale up the cluster",
    "start": "197040",
    "end": "203080"
  },
  {
    "text": "when you want to run more computes and you also need to scale up the cluster and that's why we end up keep adding",
    "start": "203080",
    "end": "210080"
  },
  {
    "text": "nodes to the cluster and essentially that the no the cluster just get bigger and bigger so uh when we want to replic",
    "start": "210080",
    "end": "218280"
  },
  {
    "text": "everything on on on Cloud on on on uh",
    "start": "218280",
    "end": "223680"
  },
  {
    "text": "kubernetes the first thing came to our mind is like we can do the same we can build a giant Compu cluster and the",
    "start": "223680",
    "end": "230159"
  },
  {
    "text": "beauty of um kubernetes like um kubernetes where oncloud is like we can",
    "start": "230159",
    "end": "235480"
  },
  {
    "text": "disaggregate disaggregate the uh computer and storage so we can we can",
    "start": "235480",
    "end": "241079"
  },
  {
    "text": "run operate our own compute clusters so why not we just build really large",
    "start": "241079",
    "end": "246480"
  },
  {
    "text": "computer clusters um but the first attempt definitely not the right",
    "start": "246480",
    "end": "251879"
  },
  {
    "text": "solution and when we when we evaluate these parts we realize that there are",
    "start": "251879",
    "end": "257320"
  },
  {
    "text": "two major issues one is it's really hard to scale kubernetes thousands of notes",
    "start": "257320",
    "end": "262639"
  },
  {
    "text": "so we have tried but uh after 1,000 noes um we are seeing a lot of problems and",
    "start": "262639",
    "end": "269280"
  },
  {
    "text": "we don't want to deal with that and the Second Challenge is that sharing the",
    "start": "269280",
    "end": "274960"
  },
  {
    "text": "resources between bad jobs is really hard um so when we put all those user",
    "start": "274960",
    "end": "281680"
  },
  {
    "text": "jobs on the cluster and basically um users are constantly competing resources",
    "start": "281680",
    "end": "287560"
  },
  {
    "text": "teams are complaining about why I'm not getting resources my why my J is dark so",
    "start": "287560",
    "end": "292960"
  },
  {
    "text": "how we solve these challenges is a major problem and that's the that's why we go to the next uh next stage",
    "start": "292960",
    "end": "300600"
  },
  {
    "text": "and then we want to involve our architecture to be more cloud lative and",
    "start": "300600",
    "end": "305720"
  },
  {
    "text": "also leverage what we call this Dynamic compute post so Dynamic compute post is",
    "start": "305720",
    "end": "311840"
  },
  {
    "text": "really nothing but just lot of more just split the giant computer cluster to lot",
    "start": "311840",
    "end": "317479"
  },
  {
    "text": "of more smaller clusters the Clusters where we are comfortable to manage and",
    "start": "317479",
    "end": "322919"
  },
  {
    "text": "we are com comfortable they be running just fine and give us light overhead",
    "start": "322919",
    "end": "330000"
  },
  {
    "text": "and so to give users that we actually had a layer here which is the number one",
    "start": "330000",
    "end": "337319"
  },
  {
    "text": "um code here is the badge processing Gateway the reason to introduce another",
    "start": "337319",
    "end": "342560"
  },
  {
    "text": "layer is to hide the complexity of U how many clusters we have we don't want user",
    "start": "342560",
    "end": "347800"
  },
  {
    "text": "to know that user doesn't need to know where their jobs will be running on which cluster uh this is not something",
    "start": "347800",
    "end": "353919"
  },
  {
    "text": "user really concerns about so we introduced a ner um doing all the this",
    "start": "353919",
    "end": "360000"
  },
  {
    "text": "is the basically job API for all all and the users user just need to interactive",
    "start": "360000",
    "end": "366639"
  },
  {
    "text": "with this Gateway but underneath will be multiple uh computer clusters and each",
    "start": "366639",
    "end": "373560"
  },
  {
    "text": "cluster will be looking like just on the right side and we are leveraging uh KU",
    "start": "373560",
    "end": "379800"
  },
  {
    "text": "spark kubernetes operator to handle the spark job submission on The KES cluster",
    "start": "379800",
    "end": "385240"
  },
  {
    "text": "that is easy to use and we love that but then remember the SEC the Second",
    "start": "385240",
    "end": "390479"
  },
  {
    "text": "Challenge is the resource the scheduling on the each of the individual kubernetes",
    "start": "390479",
    "end": "395639"
  },
  {
    "text": "clusters and that's why we have a kuet batch schedule instead of uh using the",
    "start": "395639",
    "end": "400960"
  },
  {
    "text": "default scheduler and with that put them all together we have",
    "start": "400960",
    "end": "407080"
  },
  {
    "text": "architecture like this U so on the left side this is what we expose to our end",
    "start": "407080",
    "end": "413319"
  },
  {
    "text": "users so first user will need to talk to the uh batch processing way which is a",
    "start": "413319",
    "end": "419720"
  },
  {
    "text": "bunch of uh uh apis R API come on line tool so they can submit and monitor",
    "start": "419720",
    "end": "426120"
  },
  {
    "text": "their jobs spark jobs and second part is the tooling and monitoring which is",
    "start": "426120",
    "end": "431840"
  },
  {
    "text": "collecting the re presenting the resource UI also spark history server",
    "start": "431840",
    "end": "437520"
  },
  {
    "text": "where user encage their um historic jobs and profiler which user can use that to",
    "start": "437520",
    "end": "444440"
  },
  {
    "text": "to tune their jobs job UI where user can track their jobs",
    "start": "444440",
    "end": "450160"
  },
  {
    "text": "log in Matrix how those those things are exposed to users and uh essentially",
    "start": "450160",
    "end": "455840"
  },
  {
    "text": "these things are the only things that user uh would want to deal with but on",
    "start": "455840",
    "end": "460879"
  },
  {
    "text": "the right side that's the compute pools and each of the compute pools we are managing that a separate kubernetes",
    "start": "460879",
    "end": "468120"
  },
  {
    "text": "cluster and we use the Unicorn scheduler um to replace the def schedule to the",
    "start": "468120",
    "end": "473720"
  },
  {
    "text": "scheduling and for each of the cluster we do the uh scale up and down",
    "start": "473720",
    "end": "480000"
  },
  {
    "text": "by leveraging the cluster Auto scaler and also use the spark operator that meet and manage the spark uh jobs uh",
    "start": "480000",
    "end": "488120"
  },
  {
    "text": "this way and also for the compu P we are we are able to scale out or scale in",
    "start": "488120",
    "end": "494159"
  },
  {
    "text": "which means we can spin up new clusters on demand when it is necessary uh when",
    "start": "494159",
    "end": "499680"
  },
  {
    "text": "when our existing clusters not has not enough capacity and also we can destroy those clusters when when when we don't",
    "start": "499680",
    "end": "505840"
  },
  {
    "text": "need them so with all these things put together we really come up with a uh",
    "start": "505840",
    "end": "511520"
  },
  {
    "text": "Cloud L platform where we can serve our",
    "start": "511520",
    "end": "515800"
  },
  {
    "text": "purpose the recipe here so basically uh remember the challenges we mentioned so",
    "start": "516760",
    "end": "522680"
  },
  {
    "text": "there we need a schedule that works for batch jobs in our case is the spark jobs",
    "start": "522680",
    "end": "528480"
  },
  {
    "text": "and um uh that's why we choose our part unicorn and uh we'll talk about more",
    "start": "528480",
    "end": "533920"
  },
  {
    "text": "about unicorn later and the second part is the service Gateway that really gave",
    "start": "533920",
    "end": "539120"
  },
  {
    "text": "us use a very very simple uh interface they don't need to need to deal with all",
    "start": "539120",
    "end": "545480"
  },
  {
    "text": "those infra complications so that's the batch processing gway and the third part is",
    "start": "545480",
    "end": "552279"
  },
  {
    "text": "really empowered by kubernetes ecosystem because within the kubernetes ecosystem",
    "start": "552279",
    "end": "557480"
  },
  {
    "text": "there are so many components great components you can choose to do the networking to do the loging",
    "start": "557480",
    "end": "563760"
  },
  {
    "text": "Matrix so all those things we can we can leverage and in order to build our cluster our our our platform better and",
    "start": "563760",
    "end": "573000"
  },
  {
    "text": "better um a typical workflow is like uh when users submit their jobs they're",
    "start": "573480",
    "end": "579200"
  },
  {
    "text": "interacting with our Gateway service so the Gateway service actually uh Expos",
    "start": "579200",
    "end": "585560"
  },
  {
    "text": "the rice API and come online so user can simply submit their jobs and once the job is submitted",
    "start": "585560",
    "end": "594000"
  },
  {
    "text": "Gateway the Gateway actually will submit a job to a queue this queue is a very",
    "start": "594000",
    "end": "599480"
  },
  {
    "text": "Central concept we have our system uh this is actually the virtual cues uh",
    "start": "599480",
    "end": "604800"
  },
  {
    "text": "when we say there are virtual cues because over all the computer clusters",
    "start": "604800",
    "end": "609920"
  },
  {
    "text": "we just gave user a central uh virtual queue to manage the",
    "start": "609920",
    "end": "615640"
  },
  {
    "text": "resources um and the this cues resources are actually coming from different one",
    "start": "615640",
    "end": "621760"
  },
  {
    "text": "or more kubernetes clusters and then after the job is submitted a queue the Gateway will",
    "start": "621760",
    "end": "628640"
  },
  {
    "text": "dispatch the job job to a dedicated cluster to run the run the job and in",
    "start": "628640",
    "end": "634880"
  },
  {
    "text": "our design the job will only be able to run on one cluster it's not crossing the",
    "start": "634880",
    "end": "640560"
  },
  {
    "text": "cluster uh we are um avoiding a lot of a complicated things when you want to deal",
    "start": "640560",
    "end": "647760"
  },
  {
    "text": "with one job to multiple clusters and when the job is dispatched onto a DAT",
    "start": "647760",
    "end": "655959"
  },
  {
    "text": "cluster and The Spar operator will interpret the jobs back and launch the",
    "start": "655959",
    "end": "661519"
  },
  {
    "text": "job on that cluster after then once the job is launched on the cluster that means the job will creates a bunch of uh",
    "start": "661519",
    "end": "669200"
  },
  {
    "text": "pods and the Unicorn scheduler will will watch at the um pending pods and the Z",
    "start": "669200",
    "end": "675880"
  },
  {
    "text": "SCU all the parts on on on this cluster and also it will um respect the C",
    "start": "675880",
    "end": "683320"
  },
  {
    "text": "settings so everything will be coming up together the B processing Gateway we are",
    "start": "683320",
    "end": "690639"
  },
  {
    "text": "talking here is a central stess job APS server over kubernetes cluster for spark",
    "start": "690639",
    "end": "698040"
  },
  {
    "text": "and uh the the key idea is to we want to hide the kubernetes uh uh clusters",
    "start": "698040",
    "end": "704839"
  },
  {
    "text": "behind behind the sense and we really want users just to use the API to submit",
    "start": "704839",
    "end": "710040"
  },
  {
    "text": "and monitor their jobs instead of um carrying about uh which cluster my job",
    "start": "710040",
    "end": "715560"
  },
  {
    "text": "will be running do I need to log on to the cluster to see what's happening so we want to have all those",
    "start": "715560",
    "end": "721880"
  },
  {
    "text": "complexity and it's also manage the virtual cues so basically the virtual cues we actually mapping to the Unicorn",
    "start": "721880",
    "end": "728920"
  },
  {
    "text": "actual cues on those compute clusters and we aggregate the metrics and then we",
    "start": "728920",
    "end": "734279"
  },
  {
    "text": "have a virtual queue present to other users that's all the things they need to care about and also the Gateway will",
    "start": "734279",
    "end": "741760"
  },
  {
    "text": "handle the um load balancing and um to avoid like creating super um hosal class",
    "start": "741760",
    "end": "749360"
  },
  {
    "text": "ERS and also it will give user uh the essential apis to track their jobs",
    "start": "749360",
    "end": "755320"
  },
  {
    "text": "status and uh also retrieve logs uh this is basically what we are",
    "start": "755320",
    "end": "763079"
  },
  {
    "text": "thinking to bring this platform to our users is we really want to make it very",
    "start": "763079",
    "end": "768240"
  },
  {
    "text": "easy to use from the user perspective they can um they can access the gateway",
    "start": "768240",
    "end": "774440"
  },
  {
    "text": "to to operate their jobs they also have great observability based on the uis and",
    "start": "774440",
    "end": "780720"
  },
  {
    "text": "logs we we provided and also the monitoring leverage the uh the the",
    "start": "780720",
    "end": "786800"
  },
  {
    "text": "system haveu they have great monitoring metrics over the jobs and on the right",
    "start": "786800",
    "end": "793079"
  },
  {
    "text": "side you can see how much complexity we're hiding from this from users",
    "start": "793079",
    "end": "798120"
  },
  {
    "text": "cluster provisioning user doesn't need to care about that cluster upgrade they're we're doing that quarterly for",
    "start": "798120",
    "end": "804320"
  },
  {
    "text": "kuet versions scale up and down is automatic on demand I IP rebalancing",
    "start": "804320",
    "end": "810639"
  },
  {
    "text": "basically their IP limits we want to avoid uh instance capacity planning node",
    "start": "810639",
    "end": "817760"
  },
  {
    "text": "balancing workflow schedule final recovery all those things are hided from the user and also more important job",
    "start": "817760",
    "end": "824480"
  },
  {
    "text": "queueing Bean packing resource fness those uh those key features are provided",
    "start": "824480",
    "end": "830560"
  },
  {
    "text": "as well log rotation archiv so all these complexities are not seen by the user so",
    "start": "830560",
    "end": "836360"
  },
  {
    "text": "user will be just hyper run their jobs platform and we'll be handling all the",
    "start": "836360",
    "end": "841959"
  },
  {
    "text": "gr Parts um we've keep talking about the",
    "start": "841959",
    "end": "847240"
  },
  {
    "text": "virtual resource cues and uh really want to um reinforce that the key idea here",
    "start": "847240",
    "end": "853240"
  },
  {
    "text": "is we have some virtual cues and this this is where our teams and users plan",
    "start": "853240",
    "end": "859560"
  },
  {
    "text": "plan their their budget for the year and they basically tell us how much resource",
    "start": "859560",
    "end": "864959"
  },
  {
    "text": "they want but their resource for each of the que may come from one cluster we make may come from 10 clusters so how we",
    "start": "864959",
    "end": "873880"
  },
  {
    "text": "provide a resource for the virtual cues is totally depends on how we plan the compute pool and also once the users",
    "start": "873880",
    "end": "881800"
  },
  {
    "text": "jobs are submitted to cues actually the jobs will be queing and also we'll be",
    "start": "881800",
    "end": "887519"
  },
  {
    "text": "scheduled based on number of factors such as priority uh submission time and",
    "start": "887519",
    "end": "893600"
  },
  {
    "text": "Al sometimes um resource usage based on what user needs",
    "start": "893600",
    "end": "899480"
  },
  {
    "text": "and also all the Gateway provides the tracking tracking capability for user to",
    "start": "899480",
    "end": "906519"
  },
  {
    "text": "able to viewer jobs retrieve the logs blah blah blah so the virtual cues",
    "start": "906519",
    "end": "912720"
  },
  {
    "text": "actually give the user a really um good way to track planned resources and also",
    "start": "912720",
    "end": "920440"
  },
  {
    "text": "hide all the complexity behind this um behind of all the architecture that we have so many",
    "start": "920440",
    "end": "927680"
  },
  {
    "text": "clusters so batch processing Goodway will be open source as well uh that's why um I I encourage um anyone",
    "start": "927680",
    "end": "935120"
  },
  {
    "text": "interested to search this project on GitHub then the second challenge is the",
    "start": "935120",
    "end": "941920"
  },
  {
    "text": "job scheduling which we we need to talk about more uh this is uh basically what",
    "start": "941920",
    "end": "947240"
  },
  {
    "text": "unicorn fits in the picture uh unicorn is a uh open source batch scheduler for",
    "start": "947240",
    "end": "953160"
  },
  {
    "text": "kubernetes and it over the default schedule actually provides um some cas",
    "start": "953160",
    "end": "959000"
  },
  {
    "text": "features that needed by the B system the first one is the resource Cod management yeah I know that user as folks are using",
    "start": "959000",
    "end": "967440"
  },
  {
    "text": "namespace Cod but uh namespace resource Cod is not really designed for batch",
    "start": "967440",
    "end": "972639"
  },
  {
    "text": "systems and resource Cod management job scheduling um we need to Quee the jobs",
    "start": "972639",
    "end": "979480"
  },
  {
    "text": "and also we need to really schedule the jobs not just schedule the p and the jobs has uh there are priority there has",
    "start": "979480",
    "end": "987079"
  },
  {
    "text": "some different factors we need to consider during the scheduling so that is also considered um and um beyond that",
    "start": "987079",
    "end": "995199"
  },
  {
    "text": "we have advanced scheduling features such is gun scheduling and also there's a most recently the community has a",
    "start": "995199",
    "end": "1001360"
  },
  {
    "text": "scheduled plugin deployment mode for some of the use cases and one last thing is the serut so",
    "start": "1001360",
    "end": "1007920"
  },
  {
    "text": "really cares about serut and we really want the schedule to be first as far as",
    "start": "1007920",
    "end": "1013360"
  },
  {
    "text": "enough to catch up the user requests and",
    "start": "1013360",
    "end": "1019440"
  },
  {
    "text": "so basically with the Unicorn that we are we are dealing this challenges we're able to solve the problems for queing",
    "start": "1019440",
    "end": "1027038"
  },
  {
    "text": "jobs and also and also for the resource Coda management and for the performance you",
    "start": "1027039",
    "end": "1032798"
  },
  {
    "text": "can see that from the our Benchmark it's at Leist twice better than the B default",
    "start": "1032799",
    "end": "1037918"
  },
  {
    "text": "scheduler on the same environment and for research the Q use",
    "start": "1037919",
    "end": "1043678"
  },
  {
    "text": "case um unicorn actually provides this Q concept for the users and for them to be",
    "start": "1043679",
    "end": "1049840"
  },
  {
    "text": "able to manage plan resource and also sharing between teams and users such as",
    "start": "1049840",
    "end": "1056480"
  },
  {
    "text": "guaranteed resources is the minimum resources that you can get from the queue and uh based on that we are when",
    "start": "1056480",
    "end": "1063840"
  },
  {
    "text": "the Q utilization is below that basically we know that you are you are",
    "start": "1063840",
    "end": "1068880"
  },
  {
    "text": "starving you you need more resources so your weight will be higher than other cues your G resources faster than other",
    "start": "1068880",
    "end": "1075600"
  },
  {
    "text": "cues Max resource is the hard limit but the the case thing here is that even we",
    "start": "1075600",
    "end": "1081360"
  },
  {
    "text": "are users submitting jobs to to the same queue and uh it won't go beyond the H",
    "start": "1081360",
    "end": "1087240"
  },
  {
    "text": "limit but the jobs will not be killed the PS will not be killed even you submit more and more to the same queue",
    "start": "1087240",
    "end": "1093640"
  },
  {
    "text": "so that's the case in here is basically that simplified the user client side they don't need to handle a lot of fur",
    "start": "1093640",
    "end": "1099919"
  },
  {
    "text": "because of uh uh Cod exceed then there are some use cases",
    "start": "1099919",
    "end": "1105280"
  },
  {
    "text": "that we have the her acces and in the old word we have a lot of use cases",
    "start": "1105280",
    "end": "1110559"
  },
  {
    "text": "using hierar cues to for teams and users under the teams and we can use the same",
    "start": "1110559",
    "end": "1116960"
  },
  {
    "text": "concept here in unicorn Bean packing so that's another",
    "start": "1116960",
    "end": "1122159"
  },
  {
    "text": "feature building with unicorn scheduler basically squeeze the PS on minimum",
    "start": "1122159",
    "end": "1127640"
  },
  {
    "text": "number of nodes this is actually works very well with Autos scaling and but",
    "start": "1127640",
    "end": "1133240"
  },
  {
    "text": "that also has some s effects such as creating some hotpots and sometimes cre",
    "start": "1133240",
    "end": "1139039"
  },
  {
    "text": "disc pressure so there are some optimizations to distribute jobs uh",
    "start": "1139039",
    "end": "1144080"
  },
  {
    "text": "based on the jobs type like what is CPU intensive or memory intensive so all",
    "start": "1144080",
    "end": "1149919"
  },
  {
    "text": "those things are um job um level metrics and that can be leveraged by the",
    "start": "1149919",
    "end": "1158000"
  },
  {
    "text": "scheduler and when we scale up right so the challenges we have and uh here are",
    "start": "1158000",
    "end": "1163679"
  },
  {
    "text": "the tips the first thing is to be displ because we want really don't want to",
    "start": "1163679",
    "end": "1169320"
  },
  {
    "text": "scale you know to thousands single cluster and we we've seen a lot of",
    "start": "1169320",
    "end": "1174400"
  },
  {
    "text": "problem have to do really really hard Clan up in order to get a cluster um",
    "start": "1174400",
    "end": "1179600"
  },
  {
    "text": "back um so in our project maybe this is not a not the rule of sample but in our",
    "start": "1179600",
    "end": "1186600"
  },
  {
    "text": "practice we just keep the class size 200,000 1,000 noes which is running",
    "start": "1186600",
    "end": "1192120"
  },
  {
    "text": "pretty well very well in most of the cases the second thing is aginity so",
    "start": "1192120",
    "end": "1197600"
  },
  {
    "text": "basically we really want to Leverage The Cloud you know um how easy to build",
    "start": "1197600",
    "end": "1205320"
  },
  {
    "text": "clusters how easy to destroy them so uh we really want to leverage that and thir",
    "start": "1205320",
    "end": "1211280"
  },
  {
    "text": "thing is elasticity and all the nodes if if possible put them onto Autos Skilling",
    "start": "1211280",
    "end": "1217400"
  },
  {
    "text": "group and uh make sure they can Auto skill on demand and also provideed um good",
    "start": "1217400",
    "end": "1224039"
  },
  {
    "text": "observability so you can detect issues and also diversity is the key where you",
    "start": "1224039",
    "end": "1229720"
  },
  {
    "text": "are running you know um workloads on cloud you need to leverage as many instance types you you want and",
    "start": "1229720",
    "end": "1236840"
  },
  {
    "text": "automation is also very very important um because we are heading those complexities and those complexity",
    "start": "1236840",
    "end": "1243080"
  },
  {
    "text": "actually coming to the infr layer and they want to have the good tools to to automate them so this is the like the",
    "start": "1243080",
    "end": "1251120"
  },
  {
    "text": "pattern we see doesn't have any pattern B basically it's on demand so user can submit anything to the cluster and it",
    "start": "1251120",
    "end": "1258080"
  },
  {
    "text": "can scale up and scale down and the number of clusters can also scale up and down so this is a casing that we are",
    "start": "1258080",
    "end": "1264559"
  },
  {
    "text": "running the instance that we really uh based on our demands we're not going to run preserve resources for for any",
    "start": "1264559",
    "end": "1274039"
  },
  {
    "text": "reason and uh um further research we are looking at several directions one is the",
    "start": "1274039",
    "end": "1280919"
  },
  {
    "text": "remote shuffering a lot of people know that spark uh has those uh shuel data on",
    "start": "1280919",
    "end": "1286919"
  },
  {
    "text": "local disk which is actually creating some problems when we are running on on on cloud and so remote",
    "start": "1286919",
    "end": "1295760"
  },
  {
    "text": "shuffling is moving the shovel data to remote storage that's definitely a way to look at how we can uh to make spark",
    "start": "1295760",
    "end": "1303559"
  },
  {
    "text": "more cloud lative and also um there are some efforts in the community um on the",
    "start": "1303559",
    "end": "1310320"
  },
  {
    "text": "new autoscaler to replace the uh clust Auto SEC such as the uh Carpenter and",
    "start": "1310320",
    "end": "1316080"
  },
  {
    "text": "also ocean from spot so I think those projects are actually very good idea to",
    "start": "1316080",
    "end": "1322679"
  },
  {
    "text": "to to towards the no group need cluster setup actually that will save a lot of",
    "start": "1322679",
    "end": "1327919"
  },
  {
    "text": "Da efforts I'm running out of time so that that's all about my presentation",
    "start": "1327919",
    "end": "1336520"
  },
  {
    "text": "questions thank [Applause]",
    "start": "1336520",
    "end": "1341720"
  },
  {
    "text": "you questions",
    "start": "1341720",
    "end": "1345720"
  },
  {
    "text": "how are you constructing the virtual cues because um it looks like with the scheduler that's actually a cluster",
    "start": "1356960",
    "end": "1363799"
  },
  {
    "text": "local concept so the question is how to how to construct the virtual cues and the",
    "start": "1363799",
    "end": "1370600"
  },
  {
    "text": "virtual CU so for each of the physical cluster we have a unicorn instance running and the Unicorn instance will",
    "start": "1370600",
    "end": "1377679"
  },
  {
    "text": "provide the actual cues on that cluster with virtual cues what we mean like uh",
    "start": "1377679",
    "end": "1383240"
  },
  {
    "text": "for for one queue in the virtual queue that can actually go to multiple uh",
    "start": "1383240",
    "end": "1388799"
  },
  {
    "text": "kubernetes cluster one or more kubernetes clusters for the same Q resources and for each of the uh",
    "start": "1388799",
    "end": "1395440"
  },
  {
    "text": "computer cluster cues still have the mean Max Capacity setting and when you",
    "start": "1395440",
    "end": "1400600"
  },
  {
    "text": "sum them up that's the Max Capacity in the Virtua queue that's basically how it works today",
    "start": "1400600",
    "end": "1408519"
  },
  {
    "text": "hey uh really great talk um a lot of it's remarkably similar to what we're doing with our actually in the the setup",
    "start": "1415679",
    "end": "1422799"
  },
  {
    "text": "I was wondering um your batch API you said it's stateless how have you",
    "start": "1422799",
    "end": "1427840"
  },
  {
    "text": "achieved that because does it not need some kind of state to know after you've submitted things where to find out",
    "start": "1427840",
    "end": "1434840"
  },
  {
    "text": "information about jobs for example um or works uh may I may I ask you to repeat your",
    "start": "1434840",
    "end": "1442200"
  },
  {
    "text": "question yeah um the batch API the batch IP API I think I think you called it the",
    "start": "1442200",
    "end": "1448480"
  },
  {
    "text": "batch or Gateway sorry yeah I forgot Gateway um oh Gateway okay the Gateway API um that's for how is that",
    "start": "1448480",
    "end": "1456760"
  },
  {
    "text": "stateless do you not need to save some state to find jobs or workload that's",
    "start": "1456760",
    "end": "1463480"
  },
  {
    "text": "right that's right okay so the question is about how the badge processing Gateway stain lless yeah um so it it is",
    "start": "1463480",
    "end": "1471880"
  },
  {
    "text": "um it is I I don't think it is um typical you know stainless it still still has St we have a database and so",
    "start": "1471880",
    "end": "1480600"
  },
  {
    "text": "it's right the so because it's basically tracking all the jobs so actually we are writing those data into database but we",
    "start": "1480600",
    "end": "1488520"
  },
  {
    "text": "are able to run different instances might into same same same database so still we can easily turn down our",
    "start": "1488520",
    "end": "1495480"
  },
  {
    "text": "instance and spin up another so we run several instance together to do low balancing um that's what we we we want",
    "start": "1495480",
    "end": "1503840"
  },
  {
    "text": "it to be so it's not a no state it still has State makes sense",
    "start": "1503840",
    "end": "1509960"
  },
  {
    "text": "thanks so for this Gateway what exactly do users submit to this Gateway is um um",
    "start": "1512559",
    "end": "1520480"
  },
  {
    "text": "so this the Gateway the the question is what users submit to this Gateway is that right so basically that's um for",
    "start": "1520480",
    "end": "1528679"
  },
  {
    "text": "example if you send me jobs to a kuet class using Spar Summit you are doing",
    "start": "1528679",
    "end": "1534480"
  },
  {
    "text": "Spar Summit blah blah a bunch of parameters and what we do is that user will not use SP major use the Gateway",
    "start": "1534480",
    "end": "1541679"
  },
  {
    "text": "Comm line or rest API to St their jobs and then they still need to give a bunch of parameters like how much um how much",
    "start": "1541679",
    "end": "1550520"
  },
  {
    "text": "how many how many cour how many executes you want to run and which que you want to",
    "start": "1550520",
    "end": "1556320"
  },
  {
    "text": "run and what is your class main class so all those things are pro provided to the",
    "start": "1556320",
    "end": "1562159"
  },
  {
    "text": "as a job submission API and that will be submitted through a right service to the Gateway and we know that then we",
    "start": "1562159",
    "end": "1569279"
  },
  {
    "text": "dispatch a job all right it's essentially something like a kubernetes resource but you put some extra metad",
    "start": "1569279",
    "end": "1575440"
  },
  {
    "text": "data in there that you need true um the Gateway is more like API server for SP",
    "start": "1575440",
    "end": "1580919"
  },
  {
    "text": "jobs is not doesn't actually doesn't um doesn't necessarily to do any resourcing",
    "start": "1580919",
    "end": "1590240"
  },
  {
    "text": "hi so for um log and Metric aggregation is there like one large instance of",
    "start": "1597080",
    "end": "1603480"
  },
  {
    "text": "Prometheus or lastic search that users are um accessing logs through or is",
    "start": "1603480",
    "end": "1609320"
  },
  {
    "text": "there some sort of um segregation between users accessing X Y and Z or does each Q associate with an instance",
    "start": "1609320",
    "end": "1615799"
  },
  {
    "text": "of Prometheus and Etc you are asking about logging yeah specifically logging",
    "start": "1615799",
    "end": "1621279"
  },
  {
    "text": "and metrics that you you said that users have access to right right so logging is basically I think we we have done",
    "start": "1621279",
    "end": "1627919"
  },
  {
    "text": "nothing different than others and just leverage uh uh the like uh fluent decl",
    "start": "1627919",
    "end": "1634240"
  },
  {
    "text": "the logs and uh put it on on the storage and uh we just in our service Gateway we",
    "start": "1634240",
    "end": "1640720"
  },
  {
    "text": "open some we create some API for user to retrieve the logs from the remote",
    "start": "1640720",
    "end": "1646360"
  },
  {
    "text": "storage and um I think might be most of people doing today I see so there's the",
    "start": "1646360",
    "end": "1652360"
  },
  {
    "text": "API implementation in between middleware I got you",
    "start": "1652360",
    "end": "1657200"
  },
  {
    "text": "yeah I have a lot of questions but uh hopefully we can talk later uh but uh I",
    "start": "1665919",
    "end": "1671640"
  },
  {
    "text": "wanted to focus on now on the cluster AOS scaler you say that uh unicorn",
    "start": "1671640",
    "end": "1676720"
  },
  {
    "text": "supports cluster outo scaling yeah but um so I gu because as far as I know the",
    "start": "1676720",
    "end": "1683399"
  },
  {
    "text": "clust scal at least the Open Source One just embeds the cube scalar code to do",
    "start": "1683399",
    "end": "1688919"
  },
  {
    "text": "the simulation so I wonder how does it work with yeah actually um actually for",
    "start": "1688919",
    "end": "1695880"
  },
  {
    "text": "the clust auto here and so right now what we have done unicorn it works with",
    "start": "1695880",
    "end": "1701600"
  },
  {
    "text": "clust AO perfectly uh but when we want to uh use different um strategy on the",
    "start": "1701600",
    "end": "1708159"
  },
  {
    "text": "schedule like we want to um in some case we might want to distribute the parts",
    "start": "1708159",
    "end": "1713880"
  },
  {
    "text": "differently on on the nodes sometimes there will be conflict that's why we are not doing that today and to be able to",
    "start": "1713880",
    "end": "1722080"
  },
  {
    "text": "fully compatible with uh with the clust autoscaler and in the last uh part of my",
    "start": "1722080",
    "end": "1728000"
  },
  {
    "text": "session I mentioned about some other autoscaler project and uh and I think",
    "start": "1728000",
    "end": "1734640"
  },
  {
    "text": "right now the Autos Skiller is um is is doing part of the schedule work because",
    "start": "1734640",
    "end": "1739679"
  },
  {
    "text": "need to do the computation and uh see how many instan needed and so sometimes",
    "start": "1739679",
    "end": "1746120"
  },
  {
    "text": "that creates some challenges I would say and uh one of the directions we're looking at how to you know really make",
    "start": "1746120",
    "end": "1753600"
  },
  {
    "text": "uh unicor schedule works better with claster Autos Skiller and also other Autos skillers so that is a little bit",
    "start": "1753600",
    "end": "1760840"
  },
  {
    "text": "unknown for me at least for now U definitely some something we can talk about",
    "start": "1760840",
    "end": "1766880"
  },
  {
    "text": "more than think we are almost okay one last question and then have",
    "start": "1766880",
    "end": "1772960"
  },
  {
    "text": "to uh so like from Jamie's talk there seems to be a lot of interest in like multicluster in general like workloads I",
    "start": "1772960",
    "end": "1780880"
  },
  {
    "text": "was curious from your from this work are you able to submit uh like MPI operator",
    "start": "1780880",
    "end": "1787080"
  },
  {
    "text": "jobs or uh like you know or other types of crds into this or is this kind of",
    "start": "1787080",
    "end": "1793840"
  },
  {
    "text": "more to geared towards spark yeah this is right now purely for for spark um so",
    "start": "1793840",
    "end": "1799919"
  },
  {
    "text": "all our computers are running on spark so there's no general you know crds",
    "start": "1799919",
    "end": "1805919"
  },
  {
    "text": "work all right thank you so much thank you",
    "start": "1805919",
    "end": "1811360"
  }
]
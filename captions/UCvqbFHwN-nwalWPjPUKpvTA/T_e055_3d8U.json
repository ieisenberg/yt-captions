[
  {
    "text": "welcome to the cncf YouTube channel my name is Ron Petty and I am a consultant",
    "start": "199",
    "end": "5600"
  },
  {
    "text": "at rxm a cloud native and AI training and consulting firm today we're going to",
    "start": "5600",
    "end": "11120"
  },
  {
    "text": "talk about kgpt an AI for cloud native so what is",
    "start": "11120",
    "end": "16840"
  },
  {
    "text": "kgpt according to its website it is a tool for scanning your kubernetes",
    "start": "16840",
    "end": "22359"
  },
  {
    "text": "clusters diagnosing and triaging issues in simple English it has Sr experience",
    "start": "22359",
    "end": "30000"
  },
  {
    "text": "modified into its analyzers and helps to pull out the most relevant information",
    "start": "30000",
    "end": "35040"
  },
  {
    "text": "to enrich it with AI so kgpt is a member of a new category",
    "start": "35040",
    "end": "40680"
  },
  {
    "text": "of tooling AI for for cloud native in other words the AI empowered tools are",
    "start": "40680",
    "end": "47719"
  },
  {
    "text": "helping us create a better Cloud native experience and",
    "start": "47719",
    "end": "52760"
  },
  {
    "text": "system so this tool integrates um with AI and the intent is to optimize the",
    "start": "52760",
    "end": "58680"
  },
  {
    "text": "system outcomes so for example to find some kind of misconfiguration highlight the fact that",
    "start": "58680",
    "end": "65280"
  },
  {
    "text": "it is misconfigured and then ultimately give us some kind of natural language expansion to give us some context on",
    "start": "65280",
    "end": "72439"
  },
  {
    "text": "what is going on so kgbt is one of the Premier Tools in this AI for cloud native experience",
    "start": "72439",
    "end": "80119"
  },
  {
    "text": "and so what we're going to start with is simply just installing it and taking a look at the help menu and just seeing",
    "start": "80119",
    "end": "86960"
  },
  {
    "text": "its kind of basic operations from there we'll look at how it can integrate with",
    "start": "86960",
    "end": "92360"
  },
  {
    "text": "different AI Technologies specifically llm derived Technologies like a you know",
    "start": "92360",
    "end": "98920"
  },
  {
    "text": "something that drives uh a chat GPT or something locally like AMA running the",
    "start": "98920",
    "end": "105240"
  },
  {
    "text": "Llama 3 Model so we'll take a look at how to do those things as well and then at the end we'll take a look at actually",
    "start": "105240",
    "end": "111280"
  },
  {
    "text": "how to participate in this project we'll clone the repository show the basic uh",
    "start": "111280",
    "end": "118119"
  },
  {
    "text": "commands to to build it and then we'll actually try to run it and so that way",
    "start": "118119",
    "end": "123399"
  },
  {
    "text": "you can contribute to this project as well so we're going to start off here on a MacBook Pro so in this particular",
    "start": "123399",
    "end": "132160"
  },
  {
    "text": "setup I have a kubernetes system already running doesn't really matter what's out",
    "start": "132160",
    "end": "138959"
  },
  {
    "text": "there we'll go ahead and uh create scenarios as we go to make sure we can see what uh kgpt does for us okay so",
    "start": "138959",
    "end": "148319"
  },
  {
    "text": "let's start with the how do we actually install C GPT so at least here on a Mac",
    "start": "148319",
    "end": "154040"
  },
  {
    "text": "the easiest way is to use",
    "start": "154040",
    "end": "157599"
  },
  {
    "text": "Brew okay as we can see here looks like it installed it in this",
    "start": "165400",
    "end": "173280"
  },
  {
    "text": "location we can take a look here and there is a bin directory",
    "start": "173280",
    "end": "180079"
  },
  {
    "text": "and there's an executable so instead of typing this",
    "start": "180720",
    "end": "186400"
  },
  {
    "text": "whole path be sure to update your path so it's nice and easy to use something",
    "start": "186400",
    "end": "191920"
  },
  {
    "text": "like this so I've already done this that's why I've commented it out so it is in my",
    "start": "191920",
    "end": "197560"
  },
  {
    "text": "path and now let's just try to run it make sure it",
    "start": "197560",
    "end": "203720"
  },
  {
    "text": "works great so kgpt is actually written in go so this is more or less a static",
    "start": "205440",
    "end": "213959"
  },
  {
    "text": "executable so one file here we can see it conveniently dumps out a help menu",
    "start": "213959",
    "end": "219840"
  },
  {
    "text": "without us having to do Dash and what do we see so before we",
    "start": "219840",
    "end": "226040"
  },
  {
    "text": "walk through all these steps really quick how does this operate so",
    "start": "226040",
    "end": "231079"
  },
  {
    "text": "kgbt uh logically Works in kind of two steps the first step is to analyze your",
    "start": "231079",
    "end": "237519"
  },
  {
    "text": "system and how it does this is by by querying kubernetes pulling down the the status",
    "start": "237519",
    "end": "245799"
  },
  {
    "text": "of resources so for example is a pod running or not and if it's not why is it",
    "start": "245799",
    "end": "252760"
  },
  {
    "text": "not running so it has a set of conditions that it looks for and",
    "start": "252760",
    "end": "258359"
  },
  {
    "text": "captures that so this is the kind of information that comes back from Cube CTL uh events or cube C describe when",
    "start": "258359",
    "end": "265919"
  },
  {
    "text": "you normally take a look at your cluster when you're trying to debug it so then it takes that information and",
    "start": "265919",
    "end": "272560"
  },
  {
    "text": "shows it back at us along with potentially uh some guidance on what and",
    "start": "272560",
    "end": "278240"
  },
  {
    "text": "what it means now these things are hardcoded these checks are hardcoded and so this",
    "start": "278240",
    "end": "286080"
  },
  {
    "text": "that's kind of the end of phase one phase two is we want to explain what these things are these issues are in",
    "start": "286080",
    "end": "292960"
  },
  {
    "text": "more detail so there's a sub command which we do not see listed here it's part of the analyze sub command sub",
    "start": "292960",
    "end": "300199"
  },
  {
    "text": "command called explain and explain will take what it found on the cluster and",
    "start": "300199",
    "end": "305360"
  },
  {
    "text": "send it to an llm and it basically will expand upon",
    "start": "305360",
    "end": "311000"
  },
  {
    "text": "what it thinks it sees it's going on and potentially give us Solutions so real",
    "start": "311000",
    "end": "317240"
  },
  {
    "text": "quick what else do we see here so analyze Step One is let's just go find",
    "start": "317240",
    "end": "324440"
  },
  {
    "text": "trouble step two is we have an optional step that we can send it to an llm to",
    "start": "324440",
    "end": "330520"
  },
  {
    "text": "get an natural language expanded set of actions and details setting up those llms is through",
    "start": "330520",
    "end": "337560"
  },
  {
    "text": "this authenticate mechanism so basically for the case of open AI if we want to",
    "start": "337560",
    "end": "343440"
  },
  {
    "text": "use that as our llm we need a key so you would say something like kgpt off and",
    "start": "343440",
    "end": "350520"
  },
  {
    "text": "then you would say which provider in this case open AI hit enter and then",
    "start": "350520",
    "end": "355720"
  },
  {
    "text": "it'll ask you for the key and we'll do that later if it's something like a local llm",
    "start": "355720",
    "end": "362800"
  },
  {
    "text": "there could be additional information such as what is the URL to reach",
    "start": "362800",
    "end": "368560"
  },
  {
    "text": "that caching is a performance enhancement for the results so if we see",
    "start": "368560",
    "end": "374800"
  },
  {
    "text": "the same erir again and again there's not much benefit to re querying",
    "start": "374800",
    "end": "380520"
  },
  {
    "text": "requiring and requiring so the results are C captured in a cache",
    "start": "380520",
    "end": "386880"
  },
  {
    "text": "so in the production setup of kgpt we can actually run this as a kubernetes",
    "start": "386880",
    "end": "393560"
  },
  {
    "text": "operator so imagine that we've installed kgpt not locally like we did here on my Mac but instead installed it as a",
    "start": "393560",
    "end": "400759"
  },
  {
    "text": "service or in their case an operator into the kubernetes cluster and it will continually keep",
    "start": "400759",
    "end": "406800"
  },
  {
    "text": "checking and if the problem goes away then we won't see it again right",
    "start": "406800",
    "end": "413160"
  },
  {
    "text": "and the cash will be cleaned and and that's good but again if we see that error again and again we don't want to",
    "start": "413160",
    "end": "419840"
  },
  {
    "text": "be calling that API again and again and again potentially costing us a lot of",
    "start": "419840",
    "end": "425120"
  },
  {
    "text": "money we got command line completion we'll enable that as well filters are the things we're looking for so the",
    "start": "425120",
    "end": "432160"
  },
  {
    "text": "particular resources in kubernetes like a like a service a deployment a pod or",
    "start": "432160",
    "end": "438280"
  },
  {
    "text": "even third-party crds like a cerno policy report we can actually instead of",
    "start": "438280",
    "end": "444560"
  },
  {
    "text": "checking all the things we can check a subset of things so this is good good",
    "start": "444560",
    "end": "449879"
  },
  {
    "text": "for very Dynamic resources that you may have in a CI pipeline uh we don't have to check everything all the time we can",
    "start": "449879",
    "end": "456440"
  },
  {
    "text": "check for particular uh kubernetes resources and we'll see how to do that as well okay",
    "start": "456440",
    "end": "463879"
  },
  {
    "text": "um generate helps us with the authentication piece we're we're going to skip this we have help uh integration",
    "start": "463879",
    "end": "472120"
  },
  {
    "text": "is the ability to integrate with additional tools so this is still work",
    "start": "472120",
    "end": "478039"
  },
  {
    "text": "in progress but there are are some thirdparty tools that have been integrated with kgpt one of them is",
    "start": "478039",
    "end": "483840"
  },
  {
    "text": "trivy so that's a analyzer for the cluster as well so it will produce its",
    "start": "483840",
    "end": "489639"
  },
  {
    "text": "summary results and then how it interacts with kgpt is take its summary",
    "start": "489639",
    "end": "495560"
  },
  {
    "text": "results and either present it to you or go to that next step if you do an",
    "start": "495560",
    "end": "500639"
  },
  {
    "text": "explain subc command and actually ask an llm cerno is another one so if you have",
    "start": "500639",
    "end": "506840"
  },
  {
    "text": "cerno integrated hgbd doesn't automatically use it we have to use this",
    "start": "506840",
    "end": "512279"
  },
  {
    "text": "integration sub command to let kgpt know it's there and then same thing it will",
    "start": "512279",
    "end": "518240"
  },
  {
    "text": "look at its results its policy reports and then show them to you if anything",
    "start": "518240",
    "end": "523760"
  },
  {
    "text": "was found uh negatively or you can go one step further and ask an AI serving is is largely for development",
    "start": "523760",
    "end": "532800"
  },
  {
    "text": "and potentially some deployments so in this case I mentioned we install hgbd as a command line tool and so we can",
    "start": "532800",
    "end": "539880"
  },
  {
    "text": "actually run it in a local server mode so we can actually connect to it over the network so we're not going to show",
    "start": "539880",
    "end": "545959"
  },
  {
    "text": "that here but uh it's helpful for development but it's also helpful in scenarios where you want to run C GPT",
    "start": "545959",
    "end": "553040"
  },
  {
    "text": "kind of like a proxy right you run it uh maybe outside of kubernetes and you can",
    "start": "553040",
    "end": "558079"
  },
  {
    "text": "query it to do that analyze call and say hey show me what's going on and then you",
    "start": "558079",
    "end": "563839"
  },
  {
    "text": "may put it in your CI pipeline for example okay so let's uh take a look at",
    "start": "563839",
    "end": "571279"
  },
  {
    "text": "this so kgpt",
    "start": "571279",
    "end": "577120"
  },
  {
    "text": "analyze let's see what it does all right so it's warning us that AI was not used",
    "start": "578680",
    "end": "584680"
  },
  {
    "text": "and again it's never used unless you actually say explain right that's just saying we're ready to go further but",
    "start": "584680",
    "end": "591839"
  },
  {
    "text": "even with the hardcoded SR type uh checks nothing was found incorrect with",
    "start": "591839",
    "end": "599440"
  },
  {
    "text": "this cluster so if you look at the documentation of kgpt its primary uh example is the broken pod so",
    "start": "599440",
    "end": "607399"
  },
  {
    "text": "we'll go ahead and try that as well so basically we're going to uh submit a pod",
    "start": "607399",
    "end": "615079"
  },
  {
    "text": "that doesn't exist okay normally uh you know first",
    "start": "615079",
    "end": "622000"
  },
  {
    "text": "off everything looks fine here but normally we would you know if we were to debug this we would look for something",
    "start": "622000",
    "end": "627200"
  },
  {
    "text": "like get p pods broken pod and we can see here there's",
    "start": "627200",
    "end": "634399"
  },
  {
    "text": "something wrong okay now this is an example in the source code of kgpt there",
    "start": "634399",
    "end": "640880"
  },
  {
    "text": "there are queries like give me the events give me uh the descriptive",
    "start": "640880",
    "end": "645959"
  },
  {
    "text": "aspects of a resource status and then parses it for things like image",
    "start": "645959",
    "end": "653079"
  },
  {
    "text": "issues and so in this case uh if we now in use kgpt",
    "start": "653079",
    "end": "659730"
  },
  {
    "text": "[Music] again we can see that per our image",
    "start": "659730",
    "end": "667079"
  },
  {
    "text": "something is wrong right so one thing we may be doing incorrectly here is that",
    "start": "667079",
    "end": "673320"
  },
  {
    "text": "there is a login requirement right so we can't uh receive this image so maybe",
    "start": "673320",
    "end": "679639"
  },
  {
    "text": "that maybe the name is right but we can't get it in this case uh it is actually broken",
    "start": "679639",
    "end": "686000"
  },
  {
    "text": "so check one more time okay so again it found this hardcoded",
    "start": "686000",
    "end": "694519"
  },
  {
    "text": "air but this is not using uh AI at the moment so let's go ahead and try to use",
    "start": "694519",
    "end": "701880"
  },
  {
    "text": "AI okay so this is an air and so notice that you know step one in theory still",
    "start": "703480",
    "end": "709959"
  },
  {
    "text": "happens but we don't see it yet uh it was going to go to step two and actually use the AI now which AI is it using we",
    "start": "709959",
    "end": "716920"
  },
  {
    "text": "actually haven't configured as it's warning us so so again how do we know what we can do so the off sub command is",
    "start": "716920",
    "end": "723279"
  },
  {
    "text": "the one that deals with us in interacting with an AI uh agent at least",
    "start": "723279",
    "end": "728880"
  },
  {
    "text": "the setup integration the other sub commmand is not for the AI aspect that's for thirdparty tools that we can query",
    "start": "728880",
    "end": "735320"
  },
  {
    "text": "to see if it wants us to use its output into our AI uh askings so here we can",
    "start": "735320",
    "end": "741680"
  },
  {
    "text": "see there's a list command and these are the uh supported providers and main thing of here is open",
    "start": "741680",
    "end": "750880"
  },
  {
    "text": "AI due to its uh prolific uh kind of you know use of the industry's use of its",
    "start": "750880",
    "end": "757680"
  },
  {
    "text": "API that's pretty standard here but notice none of them are active including open Ai and that's why we can't uh use",
    "start": "757680",
    "end": "764639"
  },
  {
    "text": "use it yet but there is a lot of options and so the ones we're going to do here",
    "start": "764639",
    "end": "769920"
  },
  {
    "text": "are open Ai and Olas just to show us a remote option open Ai and a local option",
    "start": "769920",
    "end": "775240"
  },
  {
    "text": "Alama so let's go ahead and start with open AI just because that's the one most people people have heard of so in this",
    "start": "775240",
    "end": "782160"
  },
  {
    "text": "case we need to activate it so we're going to do first let's actually do the commandline completion just to prove we",
    "start": "782160",
    "end": "789160"
  },
  {
    "text": "can do that completion zshell because we're on a Mac hopefully this all works so C",
    "start": "789160",
    "end": "796800"
  },
  {
    "text": "GPT off and then here we can see command line completion is working we'll go",
    "start": "796800",
    "end": "803000"
  },
  {
    "text": "ahead and do add now that's a little unfortunate we can't see see see all the",
    "start": "803000",
    "end": "808040"
  },
  {
    "text": "help here but we'll just slap a-h on there and so the things we need to kind of be aware of is depends on which kind",
    "start": "808040",
    "end": "815079"
  },
  {
    "text": "of AI model uh is it a hosted one a local hosted one or remote hosted one what kind of options we need to do the",
    "start": "815079",
    "end": "821480"
  },
  {
    "text": "main ones are what's the url url to access it and which model do we actually want to use right do we want to use a",
    "start": "821480",
    "end": "828160"
  },
  {
    "text": "whisper or an instruction or a general GPT turbo type model so those are the",
    "start": "828160",
    "end": "833199"
  },
  {
    "text": "kinds of things um so we're not going to go through all these so what we're going to do is",
    "start": "833199",
    "end": "840160"
  },
  {
    "text": "pick open Ai and it is telling us there is a",
    "start": "840160",
    "end": "845680"
  },
  {
    "text": "default model we could have selected a model like a dash model but in this case we're going to just put our key now to",
    "start": "845680",
    "end": "852560"
  },
  {
    "text": "get a key you have to create an open AI uh account and fund it I do not believe",
    "start": "852560",
    "end": "858440"
  },
  {
    "text": "they have a free tier anymore could be wrong you could check but uh I'm pasting in my key now and it says it's been",
    "start": "858440",
    "end": "865680"
  },
  {
    "text": "added and if we take a look at the list now we can see it's added Ive okay now let's go ahead and do the",
    "start": "865680",
    "end": "874720"
  },
  {
    "text": "explain once more and in this case it should go to open",
    "start": "874720",
    "end": "880560"
  },
  {
    "text": "Ai and it did so again it may not uh be formatted in such an obvious way but the",
    "start": "880720",
    "end": "887279"
  },
  {
    "text": "first step is still here right notice the a is a little different so that's",
    "start": "887279",
    "end": "892360"
  },
  {
    "text": "similar to that Bas SRE hardcoded knowledge and then step two is is kind",
    "start": "892360",
    "end": "897880"
  },
  {
    "text": "of given us this natural language expansion of it so in the you don't see it through the tool but there are",
    "start": "897880",
    "end": "904920"
  },
  {
    "text": "prompts that are set for different purposes inside of kgpt and that is used to take our you",
    "start": "904920",
    "end": "912880"
  },
  {
    "text": "know broken label message with some basic prompting and sends it to open Ai",
    "start": "912880",
    "end": "918000"
  },
  {
    "text": "and this is what we get now again uh the prove this can go away let's remove our",
    "start": "918000",
    "end": "924759"
  },
  {
    "text": "uh error so again we had a invalid image",
    "start": "924759",
    "end": "930399"
  },
  {
    "text": "and try it again and we can see it's gone now again",
    "start": "931440",
    "end": "938720"
  },
  {
    "text": "if you install kgpt as an operator where it's living as a service up in kubernetes it is on a like a cron cycle",
    "start": "938720",
    "end": "947480"
  },
  {
    "text": "right so every minute uh maybe not minute but it's you know every period of time it's checking to see if this err",
    "start": "947480",
    "end": "953800"
  },
  {
    "text": "goes away so you don't need to tell it to do it this is again doing it from the command line okay",
    "start": "953800",
    "end": "959639"
  },
  {
    "text": "so that's the basics so next let's go ahead and try to use olama so I've",
    "start": "959639",
    "end": "966240"
  },
  {
    "text": "already installed ol Lama on my computer that's uh you can look that up",
    "start": "966240",
    "end": "971560"
  },
  {
    "text": "and again you can see it has a command line interface as well in various models and tools um that we can do so I've",
    "start": "971560",
    "end": "978319"
  },
  {
    "text": "already installed the Llama 3 uh model and I have Ama",
    "start": "978319",
    "end": "984759"
  },
  {
    "text": "running and so what we need to do here is",
    "start": "984759",
    "end": "990600"
  },
  {
    "text": "actually configure it to use it and so similar command we have to say off",
    "start": "990600",
    "end": "998480"
  },
  {
    "text": "add and here just to show another variant because we have multiple things instead of just saying open AI we're",
    "start": "998480",
    "end": "1004560"
  },
  {
    "text": "going to say uh the back end is actually a llama we could have said backend open open Ai and then we have to specify",
    "start": "1004560",
    "end": "1011800"
  },
  {
    "text": "which model because there's not a default in the case of K gbd it doesn't know about a llama directly so it",
    "start": "1011800",
    "end": "1017519"
  },
  {
    "text": "doesn't know what the default 2 and then how does it reach its API so",
    "start": "1017519",
    "end": "1022680"
  },
  {
    "text": "again I'm running it locally and locally the theama server running locally is on Port",
    "start": "1022680",
    "end": "1029720"
  },
  {
    "text": "11434 okay again if we do the list we can now see we have two choices so here",
    "start": "1029919",
    "end": "1036839"
  },
  {
    "text": "um if I do explain remember uh we we fixed our erir and so there's no aors",
    "start": "1036839",
    "end": "1043558"
  },
  {
    "text": "but we can see it's using open AI if we want to use a llama we change the back end B sub command and we can",
    "start": "1043559",
    "end": "1053480"
  },
  {
    "text": "sayama and again because we have no issues even Alama says we're all good all right let's break it",
    "start": "1054880",
    "end": "1062640"
  },
  {
    "text": "again and now let's call Ama [Music]",
    "start": "1064400",
    "end": "1072059"
  },
  {
    "text": "now admittedly I have a nice MacBook but even as nice as it is it's not",
    "start": "1080640",
    "end": "1086360"
  },
  {
    "text": "necessarily nice enough to run an llm I I have a a a pre1",
    "start": "1086360",
    "end": "1095159"
  },
  {
    "text": "processor but plenty of RAM and all that's good but still even here this this can take a minute to",
    "start": "1095159",
    "end": "1100600"
  },
  {
    "text": "run and the reality is is under the hood AMA for those who may not be familiar",
    "start": "1100600",
    "end": "1106039"
  },
  {
    "text": "it's loading the model so we so we if remember we're using the Llama 3 the",
    "start": "1106039",
    "end": "1111440"
  },
  {
    "text": "model from meta but it takes a moment to actually load it and it stays in memory",
    "start": "1111440",
    "end": "1117200"
  },
  {
    "text": "for a few minutes now notice this took a little bit of time notice we're only doing about two",
    "start": "1117200",
    "end": "1123320"
  },
  {
    "text": "tokens right or uh very very slow right uh but again we see a very similar",
    "start": "1123320",
    "end": "1128600"
  },
  {
    "text": "output now again this isn't the same right it's not the same if we run open",
    "start": "1128600",
    "end": "1133720"
  },
  {
    "text": "AI we'll see that it's a little different okay again different now um",
    "start": "1133720",
    "end": "1142640"
  },
  {
    "text": "there is a cache in the background so again if we run it again uh everything should be cach should be pretty pretty",
    "start": "1142640",
    "end": "1149200"
  },
  {
    "text": "fast here in fact let's do o Lama um and see if it's faster than it was",
    "start": "1149200",
    "end": "1155320"
  },
  {
    "text": "before should be cashing well maybe",
    "start": "1155320",
    "end": "1162440"
  },
  {
    "text": "not okay we'll let that finish finish up okay",
    "start": "1163080",
    "end": "1169200"
  },
  {
    "text": "okay nonetheless even though it didn't seem to cach because uh it must have thought something was different uh there",
    "start": "1169200",
    "end": "1174960"
  },
  {
    "text": "is a no cach option all right let's not use a llama just because of the the speed difference but let's use open",
    "start": "1174960",
    "end": "1182230"
  },
  {
    "text": "[Music] AI all right so in each one of these",
    "start": "1182230",
    "end": "1188720"
  },
  {
    "text": "cases because we're using no cache it should always go back and ask versus using using a",
    "start": "1188720",
    "end": "1196960"
  },
  {
    "text": "cache okay um so that's another another feature here all right next we're going",
    "start": "1196960",
    "end": "1203440"
  },
  {
    "text": "to take a look at cerno so in the case of my cluster uh we can see sorry let me do",
    "start": "1203440",
    "end": "1210480"
  },
  {
    "text": "all name spaces we can see have cerno installed so we're not going to install cerno in this demo but you can go to its",
    "start": "1210480",
    "end": "1216480"
  },
  {
    "text": "website for those who don't know kerno is a policy engine a declarative policy",
    "start": "1216480",
    "end": "1221559"
  },
  {
    "text": "engine and so what you can do with something like kerno is is install it in kubernetes and then you can submit uh",
    "start": "1221559",
    "end": "1228720"
  },
  {
    "text": "basically a configuration where you can enforce rules right like uh when you submit an image or I should say a pod",
    "start": "1228720",
    "end": "1235280"
  },
  {
    "text": "that it should have a particular tag as an example right so that's what caverno",
    "start": "1235280",
    "end": "1241320"
  },
  {
    "text": "can do for us so how do you uh activate it so in the case of kgpt it is one of",
    "start": "1241320",
    "end": "1248960"
  },
  {
    "text": "one of the Integrations that is available so again there's a subcommand called Integrations and kind of like off",
    "start": "1248960",
    "end": "1255080"
  },
  {
    "text": "again for the llms we have the ability to to engage them so let's do a do a",
    "start": "1255080",
    "end": "1261440"
  },
  {
    "text": "list here we can see none of them are turned on or you know integrated yet and",
    "start": "1261440",
    "end": "1267520"
  },
  {
    "text": "so different ones have different uh levels of integration for example trivy which is a runtime scanner security",
    "start": "1267520",
    "end": "1276000"
  },
  {
    "text": "scanner can actually uh be installed from kgpt it's one of those one of those",
    "start": "1276000",
    "end": "1281159"
  },
  {
    "text": "options caverno though does not so caverno you have to have it installed uh yourself and since I already do I just",
    "start": "1281159",
    "end": "1289200"
  },
  {
    "text": "need to activate it so here in this case I'll say activate",
    "start": "1289200",
    "end": "1295679"
  },
  {
    "text": "kerno and again what is it going to do so caverno uh you have to in install it and then configure it with a policy to",
    "start": "1295679",
    "end": "1302039"
  },
  {
    "text": "enforce a set of rules and then the outcome of those enforcements get",
    "start": "1302039",
    "end": "1307799"
  },
  {
    "text": "captured as reports right so that's a caverno thing right so Cube CTL API",
    "start": "1307799",
    "end": "1313320"
  },
  {
    "text": "resources we can see this this custom resource that cerno installed and let's",
    "start": "1313320",
    "end": "1318799"
  },
  {
    "text": "just take a take a oops GP take a look for that and we can see here there's all",
    "start": "1318799",
    "end": "1324480"
  },
  {
    "text": "these different kinds of custom objects that have been uh created and and",
    "start": "1324480",
    "end": "1330240"
  },
  {
    "text": "available as kubernetes resources so in that case uh what does",
    "start": "1330240",
    "end": "1335919"
  },
  {
    "text": "it look like so let's try try one so we have a",
    "start": "1335919",
    "end": "1344520"
  },
  {
    "text": "pod and we have caverno in installed let's see if it it notices",
    "start": "1344520",
    "end": "1352120"
  },
  {
    "text": "anything okay here we don't really see anything with with cerno and that's",
    "start": "1352120",
    "end": "1359440"
  },
  {
    "text": "because we have no Pol there's no policies so in this case let's let's uh",
    "start": "1359440",
    "end": "1366520"
  },
  {
    "text": "enforce one so I happen to have a a sample somewhere else",
    "start": "1366520",
    "end": "1374480"
  },
  {
    "text": "uh somewhere else there we go and",
    "start": "1380559",
    "end": "1387200"
  },
  {
    "text": "then yeah here we go so in this case this cerno",
    "start": "1387440",
    "end": "1393400"
  },
  {
    "text": "policy uh cluster wide and it's basically saying that pods have to have",
    "start": "1393400",
    "end": "1401400"
  },
  {
    "text": "a a label called team and that's it so we'll go ahead and uh apply this",
    "start": "1401400",
    "end": "1410159"
  },
  {
    "text": "[Music] okay jumping back here if we take a look",
    "start": "1411650",
    "end": "1418840"
  },
  {
    "text": "uh at the cluster policies we can see we have this cluster policy and so again the outcome of this",
    "start": "1418840",
    "end": "1426320"
  },
  {
    "text": "will be a report and so we'll see a little bit more on that in just a moment uh let's go ahead and run it again and",
    "start": "1426320",
    "end": "1432760"
  },
  {
    "text": "see if our pod is noticed",
    "start": "1432760",
    "end": "1437760"
  },
  {
    "text": "okay um actually should mention we're using this filter to limit it to just",
    "start": "1442039",
    "end": "1447799"
  },
  {
    "text": "the particular resource we were interested in in this case we want to do more than just pod though we want to",
    "start": "1447799",
    "end": "1454240"
  },
  {
    "text": "look at the the policy reports so that's why we didn't see it here so again this is just showing our prior error because",
    "start": "1454240",
    "end": "1460600"
  },
  {
    "text": "it's a pod related err so uh now is a good time I guess I should show us what filters are so filters are the resources",
    "start": "1460600",
    "end": "1469159"
  },
  {
    "text": "that we are looking into and and querying about so again similar interface we can add and remove and list",
    "start": "1469159",
    "end": "1475320"
  },
  {
    "text": "the ones we're interested in so let's look at list so in this case the green",
    "start": "1475320",
    "end": "1480640"
  },
  {
    "text": "ones are active right these are the ones that were checked by default specifically of note the Pod one that's",
    "start": "1480640",
    "end": "1488039"
  },
  {
    "text": "the one that said hey I can't find this image but it checks other things as well",
    "start": "1488039",
    "end": "1493440"
  },
  {
    "text": "there's ones that are available that we can enable right we can add those back to the list of we choose to but by",
    "start": "1493440",
    "end": "1499240"
  },
  {
    "text": "default they're not but they're ready if we need them and then when we turned on kerno kerno added that's why it says",
    "start": "1499240",
    "end": "1505960"
  },
  {
    "text": "integration it added these objects notice their reports right so even",
    "start": "1505960",
    "end": "1511240"
  },
  {
    "text": "though we have a policy right we could also say get",
    "start": "1511240",
    "end": "1518679"
  },
  {
    "text": "policy report and we can see caverno is is",
    "start": "1518679",
    "end": "1525720"
  },
  {
    "text": "rating these right based on your policy did it pass pass is it fail is it a warning right those kinds of things so",
    "start": "1525720",
    "end": "1531520"
  },
  {
    "text": "this is the information that is coming back now that we've integrated and again a policy report is per namespace and a",
    "start": "1531520",
    "end": "1537080"
  },
  {
    "text": "cluster policies for all Nam spaces so in our case we want to um do our",
    "start": "1537080",
    "end": "1544360"
  },
  {
    "text": "filter and let's do the the cluster policy because that's the one we",
    "start": "1544360",
    "end": "1549679"
  },
  {
    "text": "installed let's see what reports back",
    "start": "1549679",
    "end": "1554200"
  },
  {
    "text": "on okay one more",
    "start": "1556080",
    "end": "1561480"
  },
  {
    "text": "time and we don't see it all right let's just try policy report make sure we're not missing",
    "start": "1561480",
    "end": "1568640"
  },
  {
    "text": "something okay um sorry one more check let's maybe I",
    "start": "1572440",
    "end": "1578520"
  },
  {
    "text": "installed the policy report not a cluster policy okay the report must be per Nam",
    "start": "1578520",
    "end": "1584720"
  },
  {
    "text": "space all right so what we see here",
    "start": "1584720",
    "end": "1590240"
  },
  {
    "text": "is similar similar out out outcome so there's lots of other pods running on my",
    "start": "1590399",
    "end": "1596279"
  },
  {
    "text": "cluster that that are part of just other activity and we can see here uh that kerno mentions them saying that it",
    "start": "1596279",
    "end": "1604399"
  },
  {
    "text": "doesn't have the required label so that's why we see it again and again and",
    "start": "1604399",
    "end": "1611799"
  },
  {
    "text": "again notice though it also gives a potential solution and so this is the power of",
    "start": "1611799",
    "end": "1618880"
  },
  {
    "text": "these kinds of tools now this may not be the easiest thing thing to read especially with all all the repetition",
    "start": "1618880",
    "end": "1624760"
  },
  {
    "text": "here those are areas for improvement but the point being is is that we've were",
    "start": "1624760",
    "end": "1630440"
  },
  {
    "text": "able to take a remote popular AI technology like open Ai and reference it",
    "start": "1630440",
    "end": "1638640"
  },
  {
    "text": "and use it to to get guidance right we were ALS we're also able to use a Lama right a local Ai and",
    "start": "1638640",
    "end": "1647840"
  },
  {
    "text": "we can bounce back and forth now you don't see it here but again in",
    "start": "1647840",
    "end": "1653480"
  },
  {
    "text": "our uh kind of tool set here we could download the code of kgpt and change the",
    "start": "1653480",
    "end": "1662159"
  },
  {
    "text": "prompt now ultimately we we'll be able to modify prompts uh through the command",
    "start": "1662159",
    "end": "1667320"
  },
  {
    "text": "line or a configuration file probably uh today that's not one of those things but just be aware if you can do a little bit",
    "start": "1667320",
    "end": "1673360"
  },
  {
    "text": "of coding those are the kinds of things you can do so let's go ahead and actually take a look at the code real",
    "start": "1673360",
    "end": "1678960"
  },
  {
    "text": "quick and then we'll wrap up our discussion on cage gbt all right so I'm going to make a",
    "start": "1678960",
    "end": "1685640"
  },
  {
    "text": "temp",
    "start": "1685640",
    "end": "1687960"
  },
  {
    "text": "directory and then here there's nothing in it so I'm going to go ahead and",
    "start": "1693360",
    "end": "1699279"
  },
  {
    "text": "clone the one we're interested in now the kgpt uh repository or should say",
    "start": "1699279",
    "end": "1705799"
  },
  {
    "text": "geub page has uh many repos so this is the main one that we're interested",
    "start": "1705799",
    "end": "1712300"
  },
  {
    "text": "[Music] in and again this is to show people who",
    "start": "1712300",
    "end": "1717640"
  },
  {
    "text": "want to contribute to these projects that it's pretty easy if you if you kind of know what what to do so that's what I",
    "start": "1717640",
    "end": "1724360"
  },
  {
    "text": "really want to demystify here so let's go ahead and change in here we can see it is a indeed a go um based software",
    "start": "1724360",
    "end": "1734559"
  },
  {
    "text": "let's just go ahead and build it just just because we can make",
    "start": "1734559",
    "end": "1741158"
  },
  {
    "text": "build okay so I know this because I've gone through this and so you may wonder",
    "start": "1741399",
    "end": "1746760"
  },
  {
    "text": "how do I I know these things so I did go through the you know the the repo I've been on the slack channel for um support",
    "start": "1746760",
    "end": "1754720"
  },
  {
    "text": "um if we you know we just try to make these things simple so if we you know can get you to just jump in and and see",
    "start": "1754720",
    "end": "1760320"
  },
  {
    "text": "things and make things I think it might make it even easier for you okay so it appears to have built and so where it",
    "start": "1760320",
    "end": "1767240"
  },
  {
    "text": "builds it is this directory this bin [Music]",
    "start": "1767240",
    "end": "1772360"
  },
  {
    "text": "directory and that looks pretty good looks looks like we what we were we're looking at just a moment ago so one",
    "start": "1772360",
    "end": "1778840"
  },
  {
    "text": "thing to noce there is a config file that's used so we can kind of prove this that it's the same as so even though",
    "start": "1778840",
    "end": "1784799"
  },
  {
    "text": "we're using the we're using the original Brew installed one here this one is and",
    "start": "1784799",
    "end": "1790480"
  },
  {
    "text": "actually maybe I should prove it's different uh let's do shaum",
    "start": "1790480",
    "end": "1798519"
  },
  {
    "text": "okay so this is the the the hash of the Brew installed one and then this is the",
    "start": "1798519",
    "end": "1807480"
  },
  {
    "text": "hash of this guy so you can see they're different and that's because uh we're we're on the uh you know main branch and",
    "start": "1807480",
    "end": "1815880"
  },
  {
    "text": "you know there was probably commits here in recent days right here here's one from uh two days ago right and that",
    "start": "1815880",
    "end": "1823720"
  },
  {
    "text": "build was probably a couple weeks ago you know from from The Brew inall okay okay so there there's that so what about",
    "start": "1823720",
    "end": "1832159"
  },
  {
    "text": "the configuration so this guy um let's take a look at the off because",
    "start": "1832159",
    "end": "1838120"
  },
  {
    "text": "we know we did O Lama right and it looks like it's still finds it so why is that",
    "start": "1838120",
    "end": "1843159"
  },
  {
    "text": "well that's because of this this is the default",
    "start": "1843159",
    "end": "1849039"
  },
  {
    "text": "location of the config file okay now this may look funny to",
    "start": "1849039",
    "end": "1855919"
  },
  {
    "text": "some people who may not know you know why this this has got to do with a standard from I believe the kind of free",
    "start": "1855919",
    "end": "1862639"
  },
  {
    "text": "open Desktop in in lenux they came up with a a kind of configuration or a standard for where config files live",
    "start": "1862639",
    "end": "1870960"
  },
  {
    "text": "where where a cache lives in your home directory and in the case of uh Mac uh",
    "start": "1870960",
    "end": "1878120"
  },
  {
    "text": "this is one of those what they call xdg uh settings so don't let all that",
    "start": "1878120",
    "end": "1884760"
  },
  {
    "text": "fancy stuff get in the way this is just a file stored in a we'll say a common location versus just right in the root",
    "start": "1884760",
    "end": "1891440"
  },
  {
    "text": "of your home home directory okay takes a little use to to finding it is documented but if you're not looking out",
    "start": "1891440",
    "end": "1897480"
  },
  {
    "text": "for this it's can be a little confusing all right so let's take a look at this config file and what we can see here is",
    "start": "1897480",
    "end": "1904000"
  },
  {
    "text": "it stores some information about what's what's going on so it dumps out the active filters these are actually",
    "start": "1904000",
    "end": "1910639"
  },
  {
    "text": "included in in the hardcoded kgbt as well but it you know once you've installed it and run it it actually",
    "start": "1910639",
    "end": "1917519"
  },
  {
    "text": "creates this config file and as you modify things like adding AI providers",
    "start": "1917519",
    "end": "1923000"
  },
  {
    "text": "right like we did notice there is open AI including things like temperature",
    "start": "1923000",
    "end": "1929399"
  },
  {
    "text": "controls if you're familiar with with llms you know what these kinds of settings mean we can change the model WR",
    "start": "1929399",
    "end": "1935399"
  },
  {
    "text": "those kinds of things and then here's uh tolama now you may have used AMA before",
    "start": "1935399",
    "end": "1941279"
  },
  {
    "text": "and you may have remember there being a a V1 uh here to access it that's has",
    "start": "1941279",
    "end": "1946559"
  },
  {
    "text": "since changed so there is no V1 here any anymore all right so again similar",
    "start": "1946559",
    "end": "1951840"
  },
  {
    "text": "similar things you could play around with temperature controls and and the like okay and if these are empty like",
    "start": "1951840",
    "end": "1958519"
  },
  {
    "text": "Cube config this will default to your standard Cube cuddle configuration file",
    "start": "1958519",
    "end": "1964320"
  },
  {
    "text": "um in the normal Cube uh directory okay so uh just to prove that",
    "start": "1964320",
    "end": "1971120"
  },
  {
    "text": "this version works uh let's go ahead and let's do another explain but in this case we're going to do bin",
    "start": "1971120",
    "end": "1979840"
  },
  {
    "text": "kgpt all right great it works again if we want to go short let's just do the",
    "start": "1982039",
    "end": "1987440"
  },
  {
    "text": "Pod one again and there it",
    "start": "1987440",
    "end": "1992840"
  },
  {
    "text": "is all right so what's next for kgpt and and next for us so I hope this is enough",
    "start": "1992840",
    "end": "1998919"
  },
  {
    "text": "to convince you that the tool first off is just interesting there is again additional complexity to to setting up",
    "start": "1998919",
    "end": "2006240"
  },
  {
    "text": "everything perfectly what whether or not you want to run it as an operator AKA service inside of kubernetes right but I",
    "start": "2006240",
    "end": "2013480"
  },
  {
    "text": "personally love how kgpt gives us this option to run it simply on the command",
    "start": "2013480",
    "end": "2018639"
  },
  {
    "text": "line right just a tool like any other Tool uh can point to the cluster and",
    "start": "2018639",
    "end": "2024480"
  },
  {
    "text": "give us some useful information I'm really excited for it I I believe it's going to continue to improve in areas",
    "start": "2024480",
    "end": "2030360"
  },
  {
    "text": "like prompt management um there's going to be other tools integrated it's um there's going",
    "start": "2030360",
    "end": "2037399"
  },
  {
    "text": "to probably be you know Dare To Dream things like reasoning right so like if",
    "start": "2037399",
    "end": "2042840"
  },
  {
    "text": "we have dozens and dozens of the same ER right uh can we kind of minimize that so",
    "start": "2042840",
    "end": "2048760"
  },
  {
    "text": "we don't get this kind of wall of information even though it may be correct so hopefully you enjoyed this uh",
    "start": "2048760",
    "end": "2055919"
  },
  {
    "text": "hopefully you'll check kgpt out and we'll see you next time",
    "start": "2055919",
    "end": "2062720"
  }
]
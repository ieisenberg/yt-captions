[
  {
    "text": "let's get started so first um what we're going to talk about is um my screen did not",
    "start": "80",
    "end": "8679"
  },
  {
    "text": "update give me a moment there we go so we're going to be talking about uh AI",
    "start": "8679",
    "end": "15839"
  },
  {
    "text": "how to secure Ali pipelines I want to be really clear this is not about AI safety",
    "start": "15839",
    "end": "22840"
  },
  {
    "text": "but I do believe in order to achieve AI safety you need to have a good foundation that you're building on to make sure that you're doing the things",
    "start": "22840",
    "end": "28640"
  },
  {
    "text": "that you need to do so by safety that's things like what is the bias in it is it",
    "start": "28640",
    "end": "33840"
  },
  {
    "text": "uh is it causing harm so while those are important this particular one is about how to secure AI pipelines a little bit",
    "start": "33840",
    "end": "41719"
  },
  {
    "text": "of History um the way I arrived to some of this was I had a couple converging things that I've",
    "start": "41719",
    "end": "49000"
  },
  {
    "text": "worked on over the years in order to uh in order to focus on this um one of them",
    "start": "49000",
    "end": "55640"
  },
  {
    "text": "is I've done a lot of work in the zero trust base um contribut do things like the cloud security wi paper helped",
    "start": "55640",
    "end": "62160"
  },
  {
    "text": "organizations move towards zero trust uh wrote a book on spiffy as part of the steering committee for that I",
    "start": "62160",
    "end": "69320"
  },
  {
    "text": "also ended up working with AI in in a large highly regulated environment",
    "start": "69320",
    "end": "75520"
  },
  {
    "text": "architect at large AI platforms and projects um so uh there's I also have an",
    "start": "75520",
    "end": "81880"
  },
  {
    "text": "extensive background in terms of container storage and similar so I try looking at things from the platform",
    "start": "81880",
    "end": "86920"
  },
  {
    "text": "perspective and uh one of the questions is how do we make sure that we are are doing the things that we need to do in order to properly secure the in order to",
    "start": "86920",
    "end": "94079"
  },
  {
    "text": "properly secure the systems so to get started um looking at like what an AI",
    "start": "94079",
    "end": "100720"
  },
  {
    "text": "supply chain is and before we answer this the question is like what is a supply chain in general in generally",
    "start": "100720",
    "end": "106479"
  },
  {
    "text": "when you think of a supply chain you think of like the origin of all the things that you need in order to produce a thing and all the things that need to",
    "start": "106479",
    "end": "113079"
  },
  {
    "text": "happen whether it's Hardware source code what data what parameters you need if",
    "start": "113079",
    "end": "118880"
  },
  {
    "text": "it's Hardware like where where's the hardware Source did it follow all the right set of processes all the stuff that you need to do in order to get to",
    "start": "118880",
    "end": "125600"
  },
  {
    "text": "your final deliverable of whatever that deliverable is so when we're looking at supply chain uh there's a lot here we're",
    "start": "125600",
    "end": "133280"
  },
  {
    "text": "going to focus specifically on the source code but there needs to be a way to tie into Hardware so you need to look",
    "start": "133280",
    "end": "138920"
  },
  {
    "text": "at how do how do I know that the system I ran is actually a system that was under my control",
    "start": "138920",
    "end": "144680"
  },
  {
    "text": "so um which gets into question well how do we secure everything because that's",
    "start": "144680",
    "end": "149959"
  },
  {
    "text": "where people's minds tends to wonder when they start looking at all these different things um the answer towards",
    "start": "149959",
    "end": "155360"
  },
  {
    "text": "that is you end up prioritizing and you start by breaking them out to small steps that you can reason about uh you",
    "start": "155360",
    "end": "161879"
  },
  {
    "text": "try to work out what steps you want to avoid which ones you need to guarantee actually happened uh and you can think",
    "start": "161879",
    "end": "167599"
  },
  {
    "text": "of each step each of these steps in isolation uh for a period of time where you secure that in isolation uh and then",
    "start": "167599",
    "end": "175200"
  },
  {
    "text": "as you start to secure more and more systems you start to ask questions around what how do they interact and how to cure the actual interaction between",
    "start": "175200",
    "end": "181239"
  },
  {
    "text": "them and you just keep repeating this over and over again focusing on the things that are highest priority that",
    "start": "181239",
    "end": "186440"
  },
  {
    "text": "you identify and that you reason about and over time you end up in a spot that was of course not 100% secure but you",
    "start": "186440",
    "end": "193920"
  },
  {
    "text": "end up in a place that is better off than U than where you were in in the",
    "start": "193920",
    "end": "199120"
  },
  {
    "text": "past so you do this long enough um you end up with something that over time you",
    "start": "199120",
    "end": "204239"
  },
  {
    "text": "should be able to reasonably defend so going back to AI pipelines and",
    "start": "204239",
    "end": "210000"
  },
  {
    "text": "software Supply chains uh so if you think about we have a lot of work in the software supply chain we've done as a",
    "start": "210000",
    "end": "216360"
  },
  {
    "text": "community we have some really amazing work with like uh in mpm and python uh",
    "start": "216360",
    "end": "221959"
  },
  {
    "text": "Ruby and similar and also within Enterprises on how to start to defend",
    "start": "221959",
    "end": "227360"
  },
  {
    "text": "our software spy chains so one really good way to look at this is well AI",
    "start": "227360",
    "end": "233120"
  },
  {
    "text": "pipelines um and let's scope it a little bit um there are some Advanced pipelines out there that are things like Federated",
    "start": "233120",
    "end": "240360"
  },
  {
    "text": "learning where you don't have control of the systems that you're that you're running on they're running on third party systems on third party data so for",
    "start": "240360",
    "end": "247959"
  },
  {
    "text": "an initial iteration again scope and prioritize um those are important but the main one we're going to focus on",
    "start": "247959",
    "end": "254159"
  },
  {
    "text": "today is going to be centralized pipeline data is controlled in data is",
    "start": "254159",
    "end": "259280"
  },
  {
    "text": "controlled out and how do we how do we deal with that so that starts to look a lot like a cicd pipeline and you have",
    "start": "259280",
    "end": "266680"
  },
  {
    "text": "source code that comes in you have dependencies you have pytorch you have your data dependencies on how to parse",
    "start": "266680",
    "end": "272600"
  },
  {
    "text": "um but then you have additional complexities how do you handle large volumes of data coming in or multiple",
    "start": "272600",
    "end": "280039"
  },
  {
    "text": "types of data coming in that many of them are have sensitive information how do you deal with the privacy concerns",
    "start": "280039",
    "end": "286880"
  },
  {
    "text": "and the security concerns that are that are within it uh especially and this becomes especially important we start to",
    "start": "286880",
    "end": "292840"
  },
  {
    "text": "look at model inversion attacks where what they do is they try to reproduce parts of the data set based upon the",
    "start": "292840",
    "end": "299759"
  },
  {
    "text": "model just looking at the model itself um there is a really interesting example",
    "start": "299759",
    "end": "305479"
  },
  {
    "text": "of this as well where uh there was a thing called the Netflix prize where they offered I think it was a million",
    "start": "305479",
    "end": "311840"
  },
  {
    "text": "dollars to uh come up with better recommendations and over time much of",
    "start": "311840",
    "end": "317919"
  },
  {
    "text": "the data which had been anonymized and sent out was able to be reidentified by",
    "start": "317919",
    "end": "323280"
  },
  {
    "text": "pairing it with social media and other sources so they were able to identify a",
    "start": "323280",
    "end": "328479"
  },
  {
    "text": "significant portion of of individuals through additional data sets",
    "start": "328479",
    "end": "334160"
  },
  {
    "text": "so we also have to look at it not just from like a model inversion but what's model inversion I have a data model that maybe has been let say that a model has",
    "start": "334160",
    "end": "340960"
  },
  {
    "text": "been leaked and then we have to if it were to be leaked and I were and then we were to add additional data sets to it",
    "start": "340960",
    "end": "347360"
  },
  {
    "text": "does that do we have further leakage that can occur from that so uh these",
    "start": "347360",
    "end": "353520"
  },
  {
    "text": "become really difficult to to reason about if um if you're not thinking of of",
    "start": "353520",
    "end": "360840"
  },
  {
    "text": "them like right up front um and so in terms of a model",
    "start": "360840",
    "end": "367160"
  },
  {
    "text": "inversion uh I'll I'll just toss this out real quick since we went a little bit on that uh there's a couple things you can do to",
    "start": "367160",
    "end": "373800"
  },
  {
    "text": "mathematically um to provide a mathematical basis towards defending one of the big ones is you can look at",
    "start": "373800",
    "end": "380039"
  },
  {
    "text": "differential privacy if your data is differentiable you can add differential privacy that will help defend uh defend",
    "start": "380039",
    "end": "386160"
  },
  {
    "text": "against it a really good example of this is when you have someone who's doing a poll and they want to ask a sensitive",
    "start": "386160",
    "end": "391319"
  },
  {
    "text": "question like they ask hey when was the last time a per like what percentage of people have done like maybe some kind of",
    "start": "391319",
    "end": "396759"
  },
  {
    "text": "a hard drug like may say it's cocaine uh at what point um if you ask them as part",
    "start": "396759",
    "end": "403720"
  },
  {
    "text": "of a poll very likely they're going to say no in the poll so you can add plausible deniability to the system",
    "start": "403720",
    "end": "409560"
  },
  {
    "text": "where you can say here's a coin you go into a private box and you flip and the person would flip the coin they would uh",
    "start": "409560",
    "end": "415160"
  },
  {
    "text": "if it's heads they would flip the coin again and then they would answer death of its heads tails of its no um if the",
    "start": "415160",
    "end": "423160"
  },
  {
    "text": "first coin toss was Tails then then they would flip the coin again and then they would answer um they would answer the",
    "start": "423160",
    "end": "430520"
  },
  {
    "text": "question so one of them are based on the coin toss the other one is based upon the actual data so when they come out of",
    "start": "430520",
    "end": "435680"
  },
  {
    "text": "the box and you say Hey you answered yes to this you say yeah I got the coin toss one gives you plausible deniability",
    "start": "435680",
    "end": "441440"
  },
  {
    "text": "you've learned nothing about the individual but you've gathered some information because you know what the statistical likeliness of that occurring",
    "start": "441440",
    "end": "447800"
  },
  {
    "text": "you can then tell whether you're able to look at the population statistics and learn",
    "start": "447800",
    "end": "453599"
  },
  {
    "text": "something about the population so there's things like that that have mathematical guarantees that if you",
    "start": "453599",
    "end": "458680"
  },
  {
    "text": "follow them very carefully uh you can get you can train on large quantities of",
    "start": "458680",
    "end": "463840"
  },
  {
    "text": "data but still maintain a level of privacy because of that plausible deniability there are limits to that so",
    "start": "463840",
    "end": "469879"
  },
  {
    "text": "if you decide to do that bring in someone who's an expert in it but that is a that is a possible path so now back",
    "start": "469879",
    "end": "476479"
  },
  {
    "text": "now from that tangent we'll go back into back into this with process so generally these are about processes like how do we",
    "start": "476479",
    "end": "483360"
  },
  {
    "text": "how do we secure a system you have to start with the with the people you have to start with the humans and how they're going interact with system you want to",
    "start": "483360",
    "end": "489720"
  },
  {
    "text": "Define what good practices are you want to Define your policies you want to make sure people are aware of what their responsibilities are and you want to",
    "start": "489720",
    "end": "495639"
  },
  {
    "text": "have a way to validate to attest that they are performing the work that they're doing also realize things are",
    "start": "495639",
    "end": "501639"
  },
  {
    "text": "going to go wrong so you want to have incident response plans you want to have security audits you want to have a plan",
    "start": "501639",
    "end": "506680"
  },
  {
    "text": "for when things go wrong so that you can help mitigate the issue and make sure that the people who are impacted are",
    "start": "506680",
    "end": "512479"
  },
  {
    "text": "able to get the proper help that they need especially if it's sensitive if it's sensitive",
    "start": "512479",
    "end": "518080"
  },
  {
    "text": "data so one way to do this and what we use in the software supply chain so if",
    "start": "518080",
    "end": "523599"
  },
  {
    "text": "any of you are doing salsa attestation there is a very good chance that you were using in totto and so one um what what it is",
    "start": "523599",
    "end": "532160"
  },
  {
    "text": "basically is is you set up a set of steps and you define those steps ahead of time and you can sign the document",
    "start": "532160",
    "end": "537920"
  },
  {
    "text": "that states what those steps are and those steps get applied so you have like step one go fetch the uh the binary",
    "start": "537920",
    "end": "546399"
  },
  {
    "text": "uh or rather the source code the corre get repo step two is run this command step three run these tests step four",
    "start": "546399",
    "end": "552399"
  },
  {
    "text": "package it etc etc until you get to your final uh into your final output so you",
    "start": "552399",
    "end": "557480"
  },
  {
    "text": "have these these layouts is what they call them you have metadata that describes how these layouts are actually",
    "start": "557480",
    "end": "564040"
  },
  {
    "text": "ran and you have rules about what artifacts can be used as as as in put",
    "start": "564040",
    "end": "569600"
  },
  {
    "text": "and and output which includes signatures of the data that's coming in that's that that's coming in when when available and",
    "start": "569600",
    "end": "576560"
  },
  {
    "text": "of course signatures when they go out so you can validate this is the actual thing that was that was tested",
    "start": "576560",
    "end": "582120"
  },
  {
    "text": "against so in this scenario you're creating a",
    "start": "582120",
    "end": "587560"
  },
  {
    "text": "layout with what they call functionaries so those indiv individual steps in the in total world are called",
    "start": "587560",
    "end": "593440"
  },
  {
    "text": "functionaries and you execute those functionaries you collect and verify the metadata at each step",
    "start": "593440",
    "end": "600000"
  },
  {
    "text": "and this also gives us the ability to push not only to push uh left but also",
    "start": "600000",
    "end": "606040"
  },
  {
    "text": "to push towards the right as well so that on the left we're trying to gather as much information and validate things",
    "start": "606040",
    "end": "612079"
  },
  {
    "text": "and then on the far on as we're pushing to the right that when we go to deploy these things we can make sure that they",
    "start": "612079",
    "end": "617959"
  },
  {
    "text": "follow the process or at least have EV have enough evidence to be comfortable to execute",
    "start": "617959",
    "end": "624760"
  },
  {
    "text": "something so as an example I apologize for the size of the screen of the of the image in a scenario but at the very top",
    "start": "625399",
    "end": "634440"
  },
  {
    "text": "you have a download phase so this is like a a typical uh AI of course they get more complex in this but the very",
    "start": "634440",
    "end": "640360"
  },
  {
    "text": "top you have a down a download phase uh the very top you when you're downloading the data set that ends up create you",
    "start": "640360",
    "end": "648519"
  },
  {
    "text": "want to be able to find some form of way to Hash that data set or to validate it so you create those atst stations to say",
    "start": "648519",
    "end": "654079"
  },
  {
    "text": "this is what I downloaded and this is how I verify it so you provide that information and",
    "start": "654079",
    "end": "660160"
  },
  {
    "text": "uh you pass that information some people will say oh this is like in the software build material",
    "start": "660160",
    "end": "665639"
  },
  {
    "text": "space you'll hear people say oh this is an AI bomb or a model bomb or similar um",
    "start": "665639",
    "end": "671200"
  },
  {
    "text": "I urge you to try it as much as possible ignore all the buzzwords and instead go",
    "start": "671200",
    "end": "676880"
  },
  {
    "text": "back to First principles and ask what am I trying to achieve I'm trying to make sure that when I downloaded something",
    "start": "676880",
    "end": "682079"
  },
  {
    "text": "that I downloaded it from the correct spot after I downloaded it that has not been tampered with and I want to be able",
    "start": "682079",
    "end": "687320"
  },
  {
    "text": "to demonstrate that at a later time so that uh if so if the system were to be were to be uh breached that we can",
    "start": "687320",
    "end": "695240"
  },
  {
    "text": "demonstrate that it's not been tampered with um so with that information or",
    "start": "695240",
    "end": "701360"
  },
  {
    "text": "corrupted as well not not everything's a breach some it could also be corruption so once you have that uh model building",
    "start": "701360",
    "end": "707760"
  },
  {
    "text": "phase the center one you now have data processing that occurs you may have model training so you have all this uh",
    "start": "707760",
    "end": "713839"
  },
  {
    "text": "these steps that occur the end result of that is you're providing a trained model and you're providing ing information to",
    "start": "713839",
    "end": "721040"
  },
  {
    "text": "audit that train model including hashing the model itself goes to the deployment phase it's the same thing so each",
    "start": "721040",
    "end": "726959"
  },
  {
    "text": "functionary you see what am I what are my inputs what are my outputs how do I cryptographically verify when possible",
    "start": "726959",
    "end": "734160"
  },
  {
    "text": "and how do I demonstrate what the steps are so again the layout defines every step of the path and if something fails",
    "start": "734160",
    "end": "741120"
  },
  {
    "text": "and then you have a path towards working out why did it fail so you can go and update your process or determine like do",
    "start": "741120",
    "end": "746360"
  },
  {
    "text": "in investigative forensics to work out why it why it failed if need to uh so a couple things in in Toto is",
    "start": "746360",
    "end": "754600"
  },
  {
    "text": "that it has adoption primarily in uh the two biggest ones is uh salsa and if you",
    "start": "754600",
    "end": "760160"
  },
  {
    "text": "look at things like mpm mpm when you do U uh an attestation through a salsa",
    "start": "760160",
    "end": "766600"
  },
  {
    "text": "compliance cicd system um the most prominent one that most people talk about at the moment is probably GitHub",
    "start": "766600",
    "end": "773560"
  },
  {
    "text": "but there's other cic cicd systems are prominent that do the same thing um that",
    "start": "773560",
    "end": "779800"
  },
  {
    "text": "the it it generates an attestation and the most important thing about this is that the cicd system is not ran by the",
    "start": "779800",
    "end": "786680"
  },
  {
    "text": "developer it's actually ran by this third party who they create a document that says this is the commit ID and this",
    "start": "786680",
    "end": "794040"
  },
  {
    "text": "commit ID led to the creation of this piece of software or to this artifact so that means that you can go look at where",
    "start": "794040",
    "end": "800320"
  },
  {
    "text": "the starting point was and start to audit that particular thing from a well-known Point regardless as who",
    "start": "800320",
    "end": "805959"
  },
  {
    "text": "created it you you know you at least have a starting place placees as to where to as to where to start",
    "start": "805959",
    "end": "811079"
  },
  {
    "text": "looking so generally when you're working the AI ml space you want to have the same type",
    "start": "811079",
    "end": "817320"
  },
  {
    "text": "of thing where the models are being generated not on I guess you need to have developers who can do work and",
    "start": "817320",
    "end": "822560"
  },
  {
    "text": "generate models while they're testing but when it comes time to run to production ideally especially if it's",
    "start": "822560",
    "end": "828320"
  },
  {
    "text": "sensitive data you want to have that ran through such a through such a system so that you can tell that it's not been",
    "start": "828320",
    "end": "834440"
  },
  {
    "text": "tampered with so uh when you think of that think of like Sal stations how can we then",
    "start": "834440",
    "end": "841000"
  },
  {
    "text": "move Sal sa stations to include information about about data or how can we supplement it with additional",
    "start": "841000",
    "end": "847160"
  },
  {
    "text": "information so that we're able to to reason about it so uh a couple things on here is we",
    "start": "847160",
    "end": "854040"
  },
  {
    "text": "want to handle the inputs and outputs of the data itself um we want to look at",
    "start": "854040",
    "end": "859920"
  },
  {
    "text": "the data flow and the model life cycle itself um the model life cycle is interesting because it's very common to",
    "start": "859920",
    "end": "867279"
  },
  {
    "text": "build a foundational model and then after you have that foundational model you may fine-tune it and so you need to",
    "start": "867279",
    "end": "873040"
  },
  {
    "text": "know where was that foundational model from and ideally to know where where it came from um you also have the ability",
    "start": "873040",
    "end": "879800"
  },
  {
    "text": "to um ideally you want to have the ability to tell what the Providence was and this is particularly important in",
    "start": "879800",
    "end": "886240"
  },
  {
    "text": "regulated spaces because in a regulated space you may have the ability to do a decision like let's say it's a a",
    "start": "886240",
    "end": "892320"
  },
  {
    "text": "financial company that deals with insurance and they may have the ability to use certain things to do the under",
    "start": "892320",
    "end": "899079"
  },
  {
    "text": "writing new law comes out they say you can no longer use this piece of information because it makes a",
    "start": "899079",
    "end": "904279"
  },
  {
    "text": "prediction on something that is a protected class that means that you can no longer use those particular data sets",
    "start": "904279",
    "end": "910839"
  },
  {
    "text": "for any decisions that are related towards that decision as to what they're going to underwrite and at what cost",
    "start": "910839",
    "end": "917120"
  },
  {
    "text": "which means that we have to know where did that information uh was that information ever",
    "start": "917120",
    "end": "922759"
  },
  {
    "text": "trained on and if so were are those models so that we can go and retrain a new model that does not include that information and stay in compliance",
    "start": "922759",
    "end": "930120"
  },
  {
    "text": "so when people are talking about like oh there's no compliance there's no security or regulation or specifically regulations around AI they're absolutely",
    "start": "930120",
    "end": "937040"
  },
  {
    "text": "is regulation on data and there are very real consequences for messing that up so",
    "start": "937040",
    "end": "943160"
  },
  {
    "text": "keep that in mind yes AI is still we're still working out AI we're still working out the the rules around that but data",
    "start": "943160",
    "end": "949639"
  },
  {
    "text": "we've had data for quite a while now and we have very we have very good regulations of course there's room to",
    "start": "949639",
    "end": "954759"
  },
  {
    "text": "improve them but there's but there's very clear directions that cesos and the data owners tend to tend to",
    "start": "954759",
    "end": "963120"
  },
  {
    "text": "follow so um one thing as well is when you train a model if you've not applied",
    "start": "963120",
    "end": "968800"
  },
  {
    "text": "things like differential privacy or similar things uh ideally if you've trained on sensitive data part of the",
    "start": "968800",
    "end": "975079"
  },
  {
    "text": "Providence and part of the of the tracking that you want to have in your pipeline is to make sure that the usage",
    "start": "975079",
    "end": "981120"
  },
  {
    "text": "of those models over time has not uh is is not violated the original data set in",
    "start": "981120",
    "end": "987440"
  },
  {
    "text": "other words if you have sensitive data that you've trained on top of uh you can",
    "start": "987440",
    "end": "993079"
  },
  {
    "text": "think of the model has being like lossy compression of that information if especially if you've overtrained so if",
    "start": "993079",
    "end": "999040"
  },
  {
    "text": "you're undertrained it may not be but if you overtrain it chances are there's it's learned something fundamental about",
    "start": "999040",
    "end": "1004759"
  },
  {
    "text": "the individual elements that are in there so what this indicates is that when you have sens a sensitive model you",
    "start": "1004759",
    "end": "1011319"
  },
  {
    "text": "want to make sure that you're only using that sensitive model in places where it's appropriate and that you're not just sending a model around you have",
    "start": "1011319",
    "end": "1017639"
  },
  {
    "text": "basically for for now until we work out legal and Technical risks in in a better",
    "start": "1017639",
    "end": "1023360"
  },
  {
    "text": "way make the assumption that if you're applying a certain set of controls to the data you should probably it's",
    "start": "1023360",
    "end": "1028600"
  },
  {
    "text": "probably a good idea to apply those same controls or similar type of control to the models themselves um that doesn't",
    "start": "1028600",
    "end": "1035798"
  },
  {
    "text": "mean you can't use the model but it but you should make sure that who can access it and what kind of queries go to it are",
    "start": "1035799",
    "end": "1042079"
  },
  {
    "text": "are protected so apologize about the uh",
    "start": "1042079",
    "end": "1047160"
  },
  {
    "text": "layout here but it's this is the best I could get the system to the fact I even got scrolling was is a bit of a miracle",
    "start": "1047160",
    "end": "1054039"
  },
  {
    "text": "uh but this is an example of of an intoto uh layout includes information about who",
    "start": "1054039",
    "end": "1059520"
  },
  {
    "text": "signed the layout includes information about what the steps are so this one",
    "start": "1059520",
    "end": "1065160"
  },
  {
    "text": "it's cloning an example project it's saying what the expected materials come in are what the expected products are",
    "start": "1065160",
    "end": "1071679"
  },
  {
    "text": "it's going to create a a binary called go project is going to run test so you can see that like this particular layout",
    "start": "1071679",
    "end": "1077559"
  },
  {
    "text": "is super simple but you can think of this this is if you're doing um P torch or or other type of similar things you",
    "start": "1077559",
    "end": "1083640"
  },
  {
    "text": "have commands that you can run you have information about the data that can go in what you're expecting to come out",
    "start": "1083640",
    "end": "1089200"
  },
  {
    "text": "you're able to capture that information make sure that you're make sure that those things are properly captured so",
    "start": "1089200",
    "end": "1095520"
  },
  {
    "text": "you can you can reason about them at a later",
    "start": "1095520",
    "end": "1099520"
  },
  {
    "text": "time so before we move on because we've spoken a lot about intto attestations",
    "start": "1100880",
    "end": "1106799"
  },
  {
    "text": "and processes and so on there's one other fly in the ointment that we got to take care of um and what that is is that",
    "start": "1106799",
    "end": "1114520"
  },
  {
    "text": "many of the data sets and models that we're dealing with are huge like we're",
    "start": "1114520",
    "end": "1119919"
  },
  {
    "text": "talking about pedabytes worth of data in some scenarios and we're going to see more data sets over time that are that",
    "start": "1119919",
    "end": "1126480"
  },
  {
    "text": "are of the size so the question that becomes how do I attest a large data set",
    "start": "1126480",
    "end": "1133240"
  },
  {
    "text": "so just some back of the napkin numbers I did before um I made the Assumption if",
    "start": "1133240",
    "end": "1138400"
  },
  {
    "text": "I could do 10 gab of hashes per second of sha",
    "start": "1138400",
    "end": "1143480"
  },
  {
    "text": "256 which is two to three times faster than common Hardware you can get it would take around 27 hours to Hash one",
    "start": "1143480",
    "end": "1151520"
  },
  {
    "text": "pyte worth of data and so um when you consider",
    "start": "1151520",
    "end": "1158039"
  },
  {
    "text": "that and you consider that you have a system that is working in parallel in order to generate these models there is",
    "start": "1158039",
    "end": "1164440"
  },
  {
    "text": "not enough processing speed because when you look at Shaw Shaw starts at the start it runs them into as blocks until",
    "start": "1164440",
    "end": "1170640"
  },
  {
    "text": "you get to the very end and it's a very linear process uh when you hear about people saying oh I do like all these",
    "start": "1170640",
    "end": "1175880"
  },
  {
    "text": "super fast hashes usually those are crypto miners or similar thatu lots of tiny little hashes that are independent",
    "start": "1175880",
    "end": "1181559"
  },
  {
    "text": "of each other they're not usually talking about I have a giant data set how do I and how do I test the whole",
    "start": "1181559",
    "end": "1187440"
  },
  {
    "text": "thing so we have to actually look at at how to at how to do that so one of the",
    "start": "1187440",
    "end": "1193360"
  },
  {
    "text": "other things projects I've worked on in addition to intto is a project design",
    "start": "1193360",
    "end": "1198799"
  },
  {
    "text": "specifically to to handle that so we'll also go over that right now so the",
    "start": "1198799",
    "end": "1204120"
  },
  {
    "text": "project is called terapin and I have links to it at the end of the presentation so I'll I'll post information on it I have a spec that I",
    "start": "1204120",
    "end": "1210039"
  },
  {
    "text": "wrote and I have two reference implementations one in go and one in R but the idea is how to use shot 256 but",
    "start": "1210039",
    "end": "1216280"
  },
  {
    "text": "instead of start to end how do we set it up so that we're able to Hash all of this information and",
    "start": "1216280",
    "end": "1222799"
  },
  {
    "text": "remember the purpose of this hash is to come up with a short small number I can stick into the inal out the station or",
    "start": "1222799",
    "end": "1229880"
  },
  {
    "text": "stick in a nest bomb as we saw before so that's the that is the purpose of why we're why we're doing this is so we can",
    "start": "1229880",
    "end": "1235440"
  },
  {
    "text": "verify that information but also have an efficient way to do it",
    "start": "1235440",
    "end": "1241840"
  },
  {
    "text": "so um given uh so given that um what we do or the way that it's",
    "start": "1241840",
    "end": "1249400"
  },
  {
    "text": "set up is you have your initial your initial data set at the very top and the very first thing it does is it splits",
    "start": "1249400",
    "end": "1255760"
  },
  {
    "text": "that data set into 2 megabyte chunks um the actual algorithm can be adjusted but",
    "start": "1255760",
    "end": "1261440"
  },
  {
    "text": "2 megabytes um I mentioned about having a storage uh background two Megs is a is",
    "start": "1261440",
    "end": "1268000"
  },
  {
    "text": "a nice compromise to do some of this stuff without knowing deep information about your uh about your data set so we",
    "start": "1268000",
    "end": "1274960"
  },
  {
    "text": "have two me chunks that get separ that get created for the whole data set and",
    "start": "1274960",
    "end": "1280960"
  },
  {
    "text": "each of those represents an individual individual trunk and then what we do is we hash all",
    "start": "1280960",
    "end": "1287039"
  },
  {
    "text": "of them using sh 56 so to be very clear um this is shot",
    "start": "1287039",
    "end": "1294200"
  },
  {
    "text": "to 56 there's one additional change that uh that I have it's it is still shot to",
    "start": "1294200",
    "end": "1299320"
  },
  {
    "text": "56 um but it's uh it's using the GID style approach which the most important",
    "start": "1299320",
    "end": "1305840"
  },
  {
    "text": "part of GID is you see this 11 here so if you let's say you wanted to Hash hello space world that's 11 characters",
    "start": "1305840",
    "end": "1312320"
  },
  {
    "text": "that gets encoded at the very beginning it gets prepended before the data so the actual thing that gets hashed is blob",
    "start": "1312320",
    "end": "1318240"
  },
  {
    "text": "space 11 null character and then 11 characters hello world so this is super",
    "start": "1318240",
    "end": "1324559"
  },
  {
    "text": "important because in with this approach we're going to be doing a lot of independent little hashes you saw like",
    "start": "1324559",
    "end": "1330400"
  },
  {
    "text": "the previous one that that we had um in the previous example so all these little hashes we want to make sure we don't",
    "start": "1330400",
    "end": "1335919"
  },
  {
    "text": "ever end up with a short right because if we end up with a short right the hash that chunk is going to be wrong and then",
    "start": "1335919",
    "end": "1341440"
  },
  {
    "text": "our final hash IDs are going to be wrong as well which means we cannot verify the information so we want the ability to",
    "start": "1341440",
    "end": "1346520"
  },
  {
    "text": "detect a short right this gives us the ab that gives us the ability for the implementation to explicitly check that",
    "start": "1346520",
    "end": "1351840"
  },
  {
    "text": "we wrote 11 bytes to the hash function and then perform the hash no more no",
    "start": "1351840",
    "end": "1358240"
  },
  {
    "text": "less so but the short thing here is that it's basically shot 256 each Chunk in",
    "start": "1358240",
    "end": "1365799"
  },
  {
    "text": "independently and then what we do is we collect all of those into a single file or into a single index and they're",
    "start": "1366000",
    "end": "1372640"
  },
  {
    "text": "collected in order so the first one is the first so it's 32 bytes for shot to 56 no in cing so no hex no base fix4",
    "start": "1372640",
    "end": "1380080"
  },
  {
    "text": "just straight up bytes they end up inside of this hash file and this hash file the first 32 bites represents the",
    "start": "1380080",
    "end": "1387720"
  },
  {
    "text": "hash the hash of the first chunk the second is the hash of the second chunk Etc until the hash of the nth is the nth",
    "start": "1387720",
    "end": "1394760"
  },
  {
    "text": "chunk so now we have this file um and if we look at the size of",
    "start": "1394760",
    "end": "1400679"
  },
  {
    "text": "this one paby worth of data ends up with 16 gbt worth of hashes uh all the chunks",
    "start": "1400679",
    "end": "1407600"
  },
  {
    "text": "that have been gathered together in order and then we can apply this recursively this 16 gig worth of hashes",
    "start": "1407600",
    "end": "1413400"
  },
  {
    "text": "if we run the same algorithm again we get 256 kiloby in other words this gets broken up into two Meg chunks same",
    "start": "1413400",
    "end": "1420520"
  },
  {
    "text": "algorithm reduced or combined in the same way merged in the same way we could",
    "start": "1420520",
    "end": "1425880"
  },
  {
    "text": "say and then that gives us 256 kilobytes which is under two Megs and then that gives us our final 32-bit hash so we",
    "start": "1425880",
    "end": "1432279"
  },
  {
    "text": "just keep doing this until we end up with a final 32-bit hash that hash there it's okay to hex that one and shove it",
    "start": "1432279",
    "end": "1437760"
  },
  {
    "text": "into your or uh or Bas 64 encoded and then shove that into your into your rest",
    "start": "1437760",
    "end": "1442960"
  },
  {
    "text": "bomb sign sign that particular one so um so that gives us the ability to",
    "start": "1442960",
    "end": "1450120"
  },
  {
    "text": "independently run lots of processes and um and get something that that works",
    "start": "1450120",
    "end": "1455400"
  },
  {
    "text": "really fast but it also gives us the ability to uh to pull information and",
    "start": "1455400",
    "end": "1460799"
  },
  {
    "text": "and validate it very efficiently so in this scenario um if you have a Target chunk you want to check you're just",
    "start": "1460799",
    "end": "1467279"
  },
  {
    "text": "checking that tree out of that tree you're only checking the ones like I have my initial signed 250 32 by I'm",
    "start": "1467279",
    "end": "1475399"
  },
  {
    "text": "checking all of the intermediaries until I get to the final one I can validate that final hash so what's nice about that is if I",
    "start": "1475399",
    "end": "1483120"
  },
  {
    "text": "have again if I have a pide worth of data and I want to validate one gigabyte",
    "start": "1483120",
    "end": "1489799"
  },
  {
    "text": "slice of data that's starting at the 500 terabyte I don't have to validate the whole thing what I do is I look for what",
    "start": "1489799",
    "end": "1497320"
  },
  {
    "text": "chunks do I need so have 500 Trunks from 250 so very simple math very straightforward that we can do here from",
    "start": "1497320",
    "end": "1503799"
  },
  {
    "text": "250 to 250 mil 499 so 500 trunks I need to pull",
    "start": "1503799",
    "end": "1509679"
  },
  {
    "text": "uh it's roughly 16 kilobytes worth of actual trunks that we're going to validate and then my second layer I then",
    "start": "1509679",
    "end": "1515120"
  },
  {
    "text": "find well which which index was that one well there's only one chunk I needed so I so um that I need to validate for that",
    "start": "1515120",
    "end": "1522279"
  },
  {
    "text": "and the third one is the is the root hash that that um that we pull so those",
    "start": "1522279",
    "end": "1527640"
  },
  {
    "text": "are the ones I really need to validate but in order to do this do that because we have two Meg as our as our alignment",
    "start": "1527640",
    "end": "1533520"
  },
  {
    "text": "size that means that our minimum that we can pull is two Megs so we have to pull two Megs and then our second layer was",
    "start": "1533520",
    "end": "1538919"
  },
  {
    "text": "256 because that was the size of the whole index for for the middle one and the last one's 32 was 32 bytes so that",
    "start": "1538919",
    "end": "1545640"
  },
  {
    "text": "means slightly more than two Megs in total to",
    "start": "1545640",
    "end": "1550679"
  },
  {
    "text": "validate 1 GB of data starting at 500 terab as opposed to validating the whole",
    "start": "1550679",
    "end": "1555799"
  },
  {
    "text": "set from start to end waiting for a couple days and then being able to check so this gives you the access to valid your information",
    "start": "1555799",
    "end": "1562039"
  },
  {
    "text": "immediately there's another thing I did not toss in here but because of this particular structure it also makes it",
    "start": "1562039",
    "end": "1567440"
  },
  {
    "text": "very easy that if you want to update those data sets and you only need to work out which chunks that you've changed and U validate those particular",
    "start": "1567440",
    "end": "1574919"
  },
  {
    "text": "ones create the hash all the way back to the top so it also gives you ability to do very efficient updates but the most",
    "start": "1574919",
    "end": "1581760"
  },
  {
    "text": "the most important out of this is this what this one that I mentioned here the ability to take arbitrary slices of",
    "start": "1581760",
    "end": "1587120"
  },
  {
    "text": "information and and to be able to validate that um future work on this so",
    "start": "1587120",
    "end": "1592440"
  },
  {
    "text": "I have two reference implementations I as I mentioned future work on this is going to be looking at creating a fuse",
    "start": "1592440",
    "end": "1597559"
  },
  {
    "text": "plugin working on how to get this stuff integrated with P torch so that we can start to have this stuff done uh quickly",
    "start": "1597559",
    "end": "1603279"
  },
  {
    "text": "and efficiently um so um again to bring it back to the",
    "start": "1603279",
    "end": "1612200"
  },
  {
    "text": "atation is that when we download this in the download phas we want to have this part here the the atation",
    "start": "1612200",
    "end": "1618840"
  },
  {
    "text": "we want to have these to be very fast and very efficient by the way this is also very fast as well because you you can throw",
    "start": "1618840",
    "end": "1625360"
  },
  {
    "text": "multiple computers at it so it becomes embarrassingly parallel so this allows you to Hash things incredibly fast if",
    "start": "1625360",
    "end": "1632880"
  },
  {
    "text": "you have additional computational power um so once so once you have that then",
    "start": "1632880",
    "end": "1640360"
  },
  {
    "text": "that that gives us a single 32 byte thing that we're able to then inject into our into our spom and in order to",
    "start": "1640360",
    "end": "1646520"
  },
  {
    "text": "to validate um so if these are things that are of interest to you uh if you want to if if",
    "start": "1646520",
    "end": "1651799"
  },
  {
    "text": "you like to help either to to implement these tools or steal ideas from this as",
    "start": "1651799",
    "end": "1656840"
  },
  {
    "text": "well and say Implement similar types of hashing um please do start thinking about the security of REI",
    "start": "1656840",
    "end": "1664880"
  },
  {
    "text": "pipelines um here are some references um this one on the very top I included because I actually wrote this document",
    "start": "1664880",
    "end": "1670919"
  },
  {
    "text": "for the US government for nist along with Santiago um",
    "start": "1670919",
    "end": "1676000"
  },
  {
    "text": "Tes um and this is this describes uh how to do software supply chain security for",
    "start": "1676000",
    "end": "1683440"
  },
  {
    "text": "initially for microservices but the ideas are also applicable in other areas um links to intto to to the projects",
    "start": "1683440",
    "end": "1690279"
  },
  {
    "text": "these are the two um reference implementations that uh that we created there is a spec I will link the spec",
    "start": "1690279",
    "end": "1696480"
  },
  {
    "text": "later on um you know so that people can see it and since we've gone over that",
    "start": "1696480",
    "end": "1702440"
  },
  {
    "text": "let me go over one more thing so um just as a quick demo to",
    "start": "1702440",
    "end": "1708320"
  },
  {
    "text": "demonstrate this is a single system my current laptop that I have right here um this is actually a shot to 56",
    "start": "1708320",
    "end": "1714000"
  },
  {
    "text": "implementation that I wrote because the one on Mac OS is super slow it takes um about a minute to this this random file",
    "start": "1714000",
    "end": "1721039"
  },
  {
    "text": "is actually 16 gigs large uh so if I just do a straightup shot to 56 uh it takes about 10 seconds you'll",
    "start": "1721039",
    "end": "1727960"
  },
  {
    "text": "see it pop up in a brief moment and you can see 9.5 seconds worth",
    "start": "1727960",
    "end": "1736360"
  },
  {
    "text": "of uh of total time and uh we see the hash the the shot this",
    "start": "1736360",
    "end": "1741799"
  },
  {
    "text": "is like the shot 256 hash uh without the terpin algorithm uh if I run the terapin",
    "start": "1741799",
    "end": "1748000"
  },
  {
    "text": "algorithm on the same data set and um I called them pins in a scenario they were",
    "start": "1748000",
    "end": "1753399"
  },
  {
    "text": "pinning data um and let's go and time it so again it's hashing every single",
    "start": "1753399",
    "end": "1760399"
  },
  {
    "text": "bite that's on there because it ran in parallel was able to engage more cars so even on a single system we've gone from",
    "start": "1760399",
    "end": "1765559"
  },
  {
    "text": "9.5 seconds to 2.7 seconds and that is including the the indexes that were",
    "start": "1765559",
    "end": "1771960"
  },
  {
    "text": "built up on top of it as well um so uh so it's much faster even on a",
    "start": "1771960",
    "end": "1777840"
  },
  {
    "text": "single system in order to in order to perform this it's not using any weird hashing algorithms or any non-standard",
    "start": "1777840",
    "end": "1783760"
  },
  {
    "text": "hashing algorithms it's just a very standard hashing algorithm applied in a very specific way to to come up with",
    "start": "1783760",
    "end": "1790240"
  },
  {
    "text": "this number um and so yeah in short that's the um um",
    "start": "1790240",
    "end": "1799240"
  },
  {
    "text": "that is the uh the project and a quick quick demo of it um I should mention one",
    "start": "1799240",
    "end": "1805320"
  },
  {
    "text": "last thing this before as well like this one was showing a petabyte but imagine this is 16 gigs as before uh because",
    "start": "1805320",
    "end": "1811200"
  },
  {
    "text": "it's so fast you probably don't even need to store the intermediat so you can just keep the final 32 bits and you can still get that as speed advantage of",
    "start": "1811200",
    "end": "1816799"
  },
  {
    "text": "moving from 10 to 3 seconds so you still have those advantages even if you don't store intermediates but these intermediates become very important when",
    "start": "1816799",
    "end": "1823559"
  },
  {
    "text": "you start to to work at scale with very large quantities of data and very large number of systems that you want to that",
    "start": "1823559",
    "end": "1828919"
  },
  {
    "text": "you want to test against so with that that concludes my uh my demonstration um",
    "start": "1828919",
    "end": "1835640"
  },
  {
    "text": "I have a few minutes worth of time left on the clock for questions and thank you very much for your",
    "start": "1835640",
    "end": "1842799"
  },
  {
    "text": "time so we have a mic here if anyone would like questions if not I'll be I'll be around as well after as well if uh if",
    "start": "1846919",
    "end": "1854720"
  },
  {
    "text": "you would like to ask a question in in a more private sense",
    "start": "1854720",
    "end": "1859799"
  },
  {
    "text": "cool not seeing anything so we'll yield the rest of the time and oh you got a",
    "start": "1862000",
    "end": "1867200"
  },
  {
    "text": "question yeah sorry um just to repeat quickly you said that the default um binary for sh 256 on the Mac took a lot",
    "start": "1867200",
    "end": "1875000"
  },
  {
    "text": "of time how long would it take for that random file uh how about we run it right now actually wrote a script because they",
    "start": "1875000",
    "end": "1881200"
  },
  {
    "text": "don't have a normal um they don't use like the sh 56 command on Linux um so let me show you the command",
    "start": "1881200",
    "end": "1888720"
  },
  {
    "text": "for that so the command that comes built in is sha sha-256 to tell it's ra to tell it's that um and then what I will",
    "start": "1888720",
    "end": "1897360"
  },
  {
    "text": "do is I will explain to you why it's slow while it's running I'll probably finish explaining why it's slow before",
    "start": "1897360",
    "end": "1904080"
  },
  {
    "text": "it finishes so the reason why it's slow is because when you run um a in a a modern",
    "start": "1904080",
    "end": "1911360"
  },
  {
    "text": "system like you're using open SSL or boring SSL by the way this uses the one ey Road uses as boring SSL it also works",
    "start": "1911360",
    "end": "1917559"
  },
  {
    "text": "with crypto uh so you can that means you can run it in web assembly but boring as cell has a lot of optimizations in it",
    "start": "1917559",
    "end": "1923679"
  },
  {
    "text": "there's two things in particular it does vectorized uh calculation so it'll actually shove everything into what into",
    "start": "1923679",
    "end": "1930159"
  },
  {
    "text": "a vector and then it'll do simd the other thing is when when uh sha",
    "start": "1930159",
    "end": "1936240"
  },
  {
    "text": "intrinsics are available in the CPU it will also make use of that so those two things make it a lot faster which is why",
    "start": "1936240",
    "end": "1942360"
  },
  {
    "text": "it took 50 55 seconds in one was just normal CPU versus is accelerated with uh",
    "start": "1942360",
    "end": "1950279"
  },
  {
    "text": "with simd so that is the reason why it took that long now the reason why it ran a lot faster in the terapin one there we",
    "start": "1950279",
    "end": "1957480"
  },
  {
    "text": "go 54 seconds the reason why it run ran a lot faster in the terapin one is",
    "start": "1957480",
    "end": "1962639"
  },
  {
    "text": "because the terapin one was using the uh the boring SSL uh implementation so it",
    "start": "1962639",
    "end": "1968080"
  },
  {
    "text": "was accelerated and also uh I was I was able to engage using uh using Tokyo and",
    "start": "1968080",
    "end": "1974559"
  },
  {
    "text": "Futures I was able to then uh perform the hashes and engage all of the core simultaneously so they were all working",
    "start": "1974559",
    "end": "1980559"
  },
  {
    "text": "simultaneously to perform uh to perform the hashes so that is why we're able to go from from 10 from 55 seconds the",
    "start": "1980559",
    "end": "1987279"
  },
  {
    "text": "initial implementation of turbin actually took it down to 10 seconds which was set up with the same as shot",
    "start": "1987279",
    "end": "1992320"
  },
  {
    "text": "of 86 and then when I added in the uh distribute the uh parallel portions of",
    "start": "1992320",
    "end": "1997919"
  },
  {
    "text": "it brought it down to under 3 seconds thank you for the",
    "start": "1997919",
    "end": "2003240"
  },
  {
    "text": "question Cool any others or we fantastic well thank you all for your",
    "start": "2003399",
    "end": "2009679"
  },
  {
    "text": "time",
    "start": "2009679",
    "end": "2012679"
  }
]
[
  {
    "start": "0",
    "end": "39000"
  },
  {
    "text": "hello everyone welcome to kubecon and cloudnation europe 2022.",
    "start": "240",
    "end": "8080"
  },
  {
    "text": "this is klaus i'm the founder of volcano and cool batch and i used to be the co-leader of sixth",
    "start": "8080",
    "end": "15200"
  },
  {
    "text": "gathering and taking the lead of cncf tagalong time volcano is a cloud native",
    "start": "15200",
    "end": "22320"
  },
  {
    "text": "batch system for intelligent workload such as hpc ai and big data",
    "start": "22320",
    "end": "28240"
  },
  {
    "text": "it was promoted to sincere fingerprinting project earlier this year so it's my",
    "start": "28240",
    "end": "34079"
  },
  {
    "text": "pleasure to give a introduction and deep dive on this project",
    "start": "34079",
    "end": "40480"
  },
  {
    "start": "39000",
    "end": "39000"
  },
  {
    "text": "here is the background on why we would like to have volcano project at the beginning we build a batch system",
    "start": "40480",
    "end": "47280"
  },
  {
    "text": "for traditional hpc workload and then we have big data platform to handle data",
    "start": "47280",
    "end": "54079"
  },
  {
    "text": "and after that we leverage cloud native technical for ai platform",
    "start": "54079",
    "end": "60320"
  },
  {
    "text": "but the problem is that this probe this all this platform are using different technical",
    "start": "60320",
    "end": "66720"
  },
  {
    "text": "stack building different ecosystem this will make it hard",
    "start": "66720",
    "end": "72479"
  },
  {
    "text": "to share results between the different workloads the resource utilization is",
    "start": "72479",
    "end": "78159"
  },
  {
    "text": "is really low so more and more organizations are leveraging cloud native technical to",
    "start": "78159",
    "end": "85280"
  },
  {
    "text": "build a unified platform for our workloads but there's still some gap in the cloud",
    "start": "85280",
    "end": "91360"
  },
  {
    "text": "native ecosystem so we built a cool batch at 2017",
    "start": "91360",
    "end": "96880"
  },
  {
    "text": "to handle scattering gap the then we build the volcano based on the cool batch to handle all the other related",
    "start": "96880",
    "end": "106079"
  },
  {
    "text": "gaps here is a major gap in the cloud native",
    "start": "106079",
    "end": "111200"
  },
  {
    "start": "108000",
    "end": "108000"
  },
  {
    "text": "ecosystem for batch workload the first one is the job management",
    "start": "111200",
    "end": "116560"
  },
  {
    "text": "it's a common requirement to have different product template and a fun green lifecycle management in a job",
    "start": "116560",
    "end": "123040"
  },
  {
    "text": "it's a complex and hard to maintain to build a cr to build crd for different",
    "start": "123040",
    "end": "129759"
  },
  {
    "text": "type of job the second gap is about the scheduling such as the priority functioning",
    "start": "129759",
    "end": "136720"
  },
  {
    "text": "gun capability resolution and backfill and so on the third gap is to support a",
    "start": "136720",
    "end": "142879"
  },
  {
    "text": "different workload in common drop of crd to reduce the complexity complexity and material effort",
    "start": "142879",
    "end": "150720"
  },
  {
    "text": "the next one is dynamic resource scheduling dynamic resource sharing between the",
    "start": "150720",
    "end": "157360"
  },
  {
    "text": "different attendant tenants such as queue the last gap is the board performance",
    "start": "157360",
    "end": "164000"
  },
  {
    "text": "most of the intelligent workload required hazard put for example without a requirement to dispatch",
    "start": "164000",
    "end": "171599"
  },
  {
    "text": "eight thousand poles per second for spark drop as we know the throughput of",
    "start": "171599",
    "end": "177120"
  },
  {
    "text": "default schedule is about 100 per uh per second yeah",
    "start": "177120",
    "end": "185159"
  },
  {
    "start": "181000",
    "end": "181000"
  },
  {
    "text": "here is the overview of volcano project volcano includes several components",
    "start": "185280",
    "end": "191360"
  },
  {
    "text": "for multi-cloud scenario we have a federation sub-project in pipeline to",
    "start": "191360",
    "end": "196800"
  },
  {
    "text": "balance the results between between the different cluster in in each individual cluster we",
    "start": "196800",
    "end": "205120"
  },
  {
    "text": "have introduced several series such as the job for common batch workload and a queue",
    "start": "205120",
    "end": "212400"
  },
  {
    "text": "for resource sharing and the controller will help to manage the lifecycle of this crds",
    "start": "212400",
    "end": "218640"
  },
  {
    "text": "the volcano scheduler are built based on the cool batch but we introduce a more scheduling",
    "start": "218640",
    "end": "227040"
  },
  {
    "text": "algorithms and we also do the performance enhancement to the base under cool batch",
    "start": "227040",
    "end": "233760"
  },
  {
    "text": "volcano was open source as 2019 and then we donate donated to cncf in",
    "start": "233760",
    "end": "242599"
  },
  {
    "text": "2020 and then it was a promoter to improve incubator project this year",
    "start": "242599",
    "end": "250159"
  },
  {
    "text": "currently there are more than contributors in the community and more",
    "start": "250159",
    "end": "256560"
  },
  {
    "text": "than 50 enterprise users adopt a volcano in",
    "start": "256560",
    "end": "261680"
  },
  {
    "text": "the in their product environment we are going to have a release every three",
    "start": "261680",
    "end": "266960"
  },
  {
    "text": "months and the last latest release is the 1.5",
    "start": "266960",
    "end": "272960"
  },
  {
    "text": "and we already have there there is some example of",
    "start": "272960",
    "end": "278160"
  },
  {
    "text": "of users such as we already use our volcano in huawei cloud",
    "start": "278160",
    "end": "285520"
  },
  {
    "text": "in our product environment and we also work with aws and some other",
    "start": "285520",
    "end": "291120"
  },
  {
    "text": "team to build to build volcano in their products",
    "start": "291120",
    "end": "297080"
  },
  {
    "start": "295000",
    "end": "295000"
  },
  {
    "text": "in batch as we know in batch system there are several concepts which are important to",
    "start": "297280",
    "end": "303440"
  },
  {
    "text": "the high level design the first concept is the is the job for batch decision is",
    "start": "303440",
    "end": "309600"
  },
  {
    "text": "usually our common job specification for all kinds of workload such as",
    "start": "309600",
    "end": "315280"
  },
  {
    "text": "web service ai metadata and so on so in cloud native ecosystem it's required",
    "start": "315280",
    "end": "322080"
  },
  {
    "text": "to introduce multiple poll templates and the thundering fun green error handling",
    "start": "322080",
    "end": "329759"
  },
  {
    "text": "the second one is about tennis traditional batch systems introduce a",
    "start": "329759",
    "end": "335440"
  },
  {
    "text": "user as tenants and kubernetes use the namespace as tenants",
    "start": "335440",
    "end": "341520"
  },
  {
    "text": "based on my understand and to avoid system overload resource limits is",
    "start": "341520",
    "end": "348000"
  },
  {
    "text": "required to the batch system for example the slums support the job",
    "start": "348000",
    "end": "353199"
  },
  {
    "text": "kills uh quality of service and kubernetes support quota",
    "start": "353199",
    "end": "359280"
  },
  {
    "text": "to control the results how many results can be created in the",
    "start": "359280",
    "end": "364400"
  },
  {
    "text": "in the the last one is q q is the",
    "start": "364400",
    "end": "369919"
  },
  {
    "text": "common concept in the base system and it is widely used in lots of system such as",
    "start": "369919",
    "end": "376000"
  },
  {
    "text": "the slurm yarn rsf it helps administrator to management",
    "start": "376000",
    "end": "381280"
  },
  {
    "text": "results in the cluster and share results between the different tenants",
    "start": "381280",
    "end": "386960"
  },
  {
    "text": "in addition some systems also support a different scheduling configuration for each cube is also useful feature for the",
    "start": "386960",
    "end": "395759"
  },
  {
    "text": "for the users in the following slides",
    "start": "395759",
    "end": "402000"
  },
  {
    "start": "398000",
    "end": "398000"
  },
  {
    "text": "we are going to introduce the detail of of volcano the first section is about",
    "start": "402000",
    "end": "409599"
  },
  {
    "text": "job management in volcano we introduce a job survey with the multiple port",
    "start": "409599",
    "end": "415759"
  },
  {
    "text": "templates as a common specification to support all kinds of workload currently",
    "start": "415759",
    "end": "421199"
  },
  {
    "text": "we already verified several type of workload in the product environment such as mpi tens",
    "start": "421199",
    "end": "428560"
  },
  {
    "text": "flow pattern hardware spark flink chrome wheel and",
    "start": "428560",
    "end": "433759"
  },
  {
    "text": "lots of other framework here is the npi example mpl wrong and",
    "start": "433759",
    "end": "439919"
  },
  {
    "text": "the worker are using different port template with a different command line",
    "start": "439919",
    "end": "447120"
  },
  {
    "text": "volcano also supports fun green lifecycle measurement for example restart the whole job when",
    "start": "447120",
    "end": "454960"
  },
  {
    "text": "when one of task was failed volcano will also build the job plugin",
    "start": "454960",
    "end": "462160"
  },
  {
    "text": "in volcano is to help users to do a customer customized enhancement for",
    "start": "462160",
    "end": "467759"
  },
  {
    "text": "the uh to the job for example ssh plugin is used to",
    "start": "467759",
    "end": "473280"
  },
  {
    "text": "configure accession access automatically for mpi drop so we don't you uh",
    "start": "473280",
    "end": "480479"
  },
  {
    "text": "oh we don't need to add more uh configuration to uh for npm uh for mpi",
    "start": "480479",
    "end": "487759"
  },
  {
    "text": "port svc plugin is a user to create a headless service for communication",
    "start": "487759",
    "end": "493680"
  },
  {
    "text": "between the port in each job",
    "start": "493680",
    "end": "498160"
  },
  {
    "start": "499000",
    "end": "499000"
  },
  {
    "text": "as we know q is a common concept in batch system it is used to share results",
    "start": "500479",
    "end": "506319"
  },
  {
    "text": "between the different tenants in volcano we follow this priorities to make a cure",
    "start": "506319",
    "end": "511440"
  },
  {
    "text": "in cluster level so q will have to share results between the tenants and the quarter is",
    "start": "511440",
    "end": "517919"
  },
  {
    "text": "considered as a resource limits of tenants currently volcanoes support of",
    "start": "517919",
    "end": "524880"
  },
  {
    "text": "fifo priority and propulsion algorithm for the queue and the conflict and the",
    "start": "524880",
    "end": "531920"
  },
  {
    "text": "configuration is a global for allq and we are also going to support the",
    "start": "531920",
    "end": "538080"
  },
  {
    "text": "company configuration for queue to uh for user",
    "start": "538080",
    "end": "543120"
  },
  {
    "text": "for users uh here is overall how on how to share",
    "start": "543120",
    "end": "548959"
  },
  {
    "start": "544000",
    "end": "544000"
  },
  {
    "text": "resources between queues considering considering there are six",
    "start": "548959",
    "end": "554399"
  },
  {
    "text": "cpu in the cluster and two queues one queue is q1 the other one is the",
    "start": "554399",
    "end": "561760"
  },
  {
    "text": "q2 which are mapping to the two teams the wedge is two and one accordingly",
    "start": "561760",
    "end": "569760"
  },
  {
    "text": "at the beginning there are six poles in the q1 and q2 is empty",
    "start": "569760",
    "end": "575600"
  },
  {
    "text": "according to the propulsion algorithm the pole in the q1 can borrow the results from q2 to get output running",
    "start": "575600",
    "end": "585360"
  },
  {
    "text": "and then submit a drop to the q2 the scheduler will reclaim two cpus from q1",
    "start": "585360",
    "end": "591920"
  },
  {
    "text": "based on weight of them so the new job in q2 gathered two",
    "start": "591920",
    "end": "597440"
  },
  {
    "text": "cpu to run in addition we support a guaranteed enqueue to",
    "start": "597440",
    "end": "602640"
  },
  {
    "text": "reserve results for high priority jobs and support the capacity in queue to",
    "start": "602640",
    "end": "607920"
  },
  {
    "text": "avoid system overload next",
    "start": "607920",
    "end": "613440"
  },
  {
    "start": "613000",
    "end": "613000"
  },
  {
    "text": "okay okay next the next one is about fair share fair",
    "start": "613440",
    "end": "618560"
  },
  {
    "text": "share is a common requirement for elastic or streaming job like spark however in",
    "start": "618560",
    "end": "626320"
  },
  {
    "text": "kubernetes the small part submitted some more post possible",
    "start": "626320",
    "end": "632000"
  },
  {
    "text": "possibility to get more resources this is not fair share",
    "start": "632000",
    "end": "637200"
  },
  {
    "text": "kubernetes provides the fair share between the jobs and the name space",
    "start": "637200",
    "end": "642880"
  },
  {
    "text": "we can see that from the graph we can see user 1 and user 2 submits",
    "start": "642880",
    "end": "649279"
  },
  {
    "text": "a small drop and big drop to the sim queue",
    "start": "649279",
    "end": "654800"
  },
  {
    "text": "the small job may get to start starving without version scheduling",
    "start": "654800",
    "end": "660640"
  },
  {
    "text": "volcano ensure big drop and small drop gather result results fairly with drf",
    "start": "660640",
    "end": "667760"
  },
  {
    "text": "algorithm but only job fair share is not enough suppose one namespace or submit a loss",
    "start": "667760",
    "end": "675279"
  },
  {
    "text": "of job to the queue compared to the other namespace it would possibly occupy the most of the",
    "start": "675279",
    "end": "683120"
  },
  {
    "text": "queue results we add a namespace fair share in volcano as the graphs show also",
    "start": "683120",
    "end": "689839"
  },
  {
    "text": "namespace 3 submit more jobs than namespace 1 but they get the same",
    "start": "689839",
    "end": "696560"
  },
  {
    "text": "results eventually so this is the important for",
    "start": "696560",
    "end": "702880"
  },
  {
    "text": "for a multi-tenant environment another one is uh is about the hierarchy",
    "start": "702880",
    "end": "709519"
  },
  {
    "start": "705000",
    "end": "705000"
  },
  {
    "text": "queue hierarchical is very useful in lots of scenario for example in the",
    "start": "709519",
    "end": "716320"
  },
  {
    "text": "button in this button feature i figure there is a cluster with",
    "start": "716320",
    "end": "722880"
  },
  {
    "text": "10 000 gpus the first level organization such as support engineering and marketing",
    "start": "722880",
    "end": "730079"
  },
  {
    "text": "department has a static quota and the results are not allocated to be shared across them",
    "start": "730079",
    "end": "736720"
  },
  {
    "text": "to ensure the installation but the second level of organizations such as the taiwan",
    "start": "736720",
    "end": "742880"
  },
  {
    "text": "qa alone are allowed to share oppo parameter results in order to get a hair",
    "start": "742880",
    "end": "750079"
  },
  {
    "text": "utilization the flight queue is not easy to meet this kind of needs",
    "start": "750079",
    "end": "755360"
  },
  {
    "text": "several engineers front by back to contribute contributing to this feature in volcano",
    "start": "755360",
    "end": "762079"
  },
  {
    "text": "with this future this will be easy to map the company organization of the",
    "start": "762079",
    "end": "767680"
  },
  {
    "text": "company team to the to the queue",
    "start": "767680",
    "end": "772720"
  },
  {
    "start": "771000",
    "end": "771000"
  },
  {
    "text": "uh as we mentioned in the first section there uh they're not uh",
    "start": "772720",
    "end": "779360"
  },
  {
    "text": "they're not enough scheduling policy in kubernetes for the batch workload we",
    "start": "779360",
    "end": "784480"
  },
  {
    "text": "have been spending a lot of time to fill this gap here",
    "start": "784480",
    "end": "790000"
  },
  {
    "text": "are part of scheduling policy or algorithm provided in the volcano",
    "start": "790000",
    "end": "795839"
  },
  {
    "text": "yeah so we are going to share together",
    "start": "795839",
    "end": "800880"
  },
  {
    "text": "give some introduction about some of them yeah",
    "start": "800880",
    "end": "805920"
  },
  {
    "start": "805000",
    "end": "805000"
  },
  {
    "text": "this one is about elast elastic training yeah",
    "start": "805920",
    "end": "811440"
  },
  {
    "text": "today i machine learning workload had a higher demand for gpu compared to the",
    "start": "812079",
    "end": "817680"
  },
  {
    "text": "traditional uh workloads gpu is a as a",
    "start": "817680",
    "end": "823839"
  },
  {
    "text": "expensive result how to improve improve the gpu utilization is a hot",
    "start": "823839",
    "end": "829360"
  },
  {
    "text": "topic and and is important you have training can dynamically adjust the number of",
    "start": "829360",
    "end": "835600"
  },
  {
    "text": "instances involved in the training greatly",
    "start": "835600",
    "end": "841120"
  },
  {
    "text": "improving the utilization of gpu results especially on the public cloud it can be",
    "start": "841120",
    "end": "847839"
  },
  {
    "text": "worked with a sport instance to get a lower cost and improve the training",
    "start": "847839",
    "end": "853680"
  },
  {
    "text": "efficiency firstly let's see what elastic drop is like the left",
    "start": "853680",
    "end": "860800"
  },
  {
    "text": "picture show show a volcano drop the mean available",
    "start": "860800",
    "end": "867519"
  },
  {
    "text": "infer the job has five posts at least and the replica infrared input to the job has a",
    "start": "867519",
    "end": "876399"
  },
  {
    "text": "temples at most the job gather running will",
    "start": "876399",
    "end": "882079"
  },
  {
    "text": "fail posts uh allocated and then the job will",
    "start": "882079",
    "end": "888399"
  },
  {
    "text": "get more posts if they're if there are enough gpu results for them",
    "start": "888399",
    "end": "893680"
  },
  {
    "text": "to run here is another scenario as you know the influence the",
    "start": "893680",
    "end": "899360"
  },
  {
    "text": "service always have a large gpu utilization compared to the training workload as people",
    "start": "899360",
    "end": "906399"
  },
  {
    "text": "tend to call call located in inference service with the last training",
    "start": "906399",
    "end": "911839"
  },
  {
    "text": "workload to improve their utilization in the right",
    "start": "911839",
    "end": "917040"
  },
  {
    "text": "in red pictures so the influence job the influence job 2",
    "start": "917040",
    "end": "923040"
  },
  {
    "text": "with the high priority with high profit will prompt elastic pulled from the training drop one",
    "start": "923040",
    "end": "931440"
  },
  {
    "text": "two to start",
    "start": "933040",
    "end": "938199"
  },
  {
    "text": "to start the more to to start the service",
    "start": "941600",
    "end": "947800"
  },
  {
    "start": "953000",
    "end": "953000"
  },
  {
    "text": "another another feature is about the task top logic",
    "start": "956800",
    "end": "962720"
  },
  {
    "text": "and i will wear the schedule this this page shows how the task top logic",
    "start": "962720",
    "end": "968720"
  },
  {
    "text": "and io aware scheduling have the distribu distributing the training",
    "start": "968720",
    "end": "975199"
  },
  {
    "text": "for some gpu training case that the data exchange between the tasks costs a lot of time and become the",
    "start": "975199",
    "end": "981839"
  },
  {
    "text": "bottom night of training if the time of the data exchange could be reduced the",
    "start": "981839",
    "end": "987360"
  },
  {
    "text": "training performance can be improved the task top logic the task top logic",
    "start": "987360",
    "end": "993120"
  },
  {
    "text": "would schedule the ps and the worker pose on the same node to reduce the data change latency",
    "start": "993120",
    "end": "1000880"
  },
  {
    "text": "the ps and worker pose can be used the housing network which is better than the",
    "start": "1000880",
    "end": "1006079"
  },
  {
    "text": "network across the host we also have tests with the default scheduler",
    "start": "1006079",
    "end": "1012079"
  },
  {
    "text": "there are three nodes in the testing cluster and we submit three training jobs with two ps and",
    "start": "1012079",
    "end": "1019440"
  },
  {
    "text": "four worker posts we get three different placements at first the results are",
    "start": "1019440",
    "end": "1025199"
  },
  {
    "text": "random with the default default scheduler as we know the group c is the best brightest",
    "start": "1025199",
    "end": "1031678"
  },
  {
    "text": "that we want with the task top logic scheduling we are able to get a stable result as a",
    "start": "1031679",
    "end": "1037678"
  },
  {
    "text": "group c as far as i know some users are using authentic and anti-inflammatory features",
    "start": "1037679",
    "end": "1044240"
  },
  {
    "text": "to achieve this goal wireless complexity increased cluster scalability and the profit to",
    "start": "1044240",
    "end": "1051600"
  },
  {
    "text": "performance is not good enough we also do some research on the uh our",
    "start": "1051600",
    "end": "1057280"
  },
  {
    "text": "schedule which with the task top logic info and",
    "start": "1057280",
    "end": "1062320"
  },
  {
    "text": "the io information we can minimize the max data transfer",
    "start": "1062320",
    "end": "1070320"
  },
  {
    "text": "latency and get even better performance the picture shows the uh",
    "start": "1070320",
    "end": "1077280"
  },
  {
    "text": "the training result with the default scheduling task top logic and iowa scheduling",
    "start": "1077280",
    "end": "1083200"
  },
  {
    "text": "the iowa's gathering get 30 performance improvement",
    "start": "1083200",
    "end": "1089840"
  },
  {
    "text": "compared to the default schedule the results anyway the the results will depend on the data",
    "start": "1089840",
    "end": "1096160"
  },
  {
    "text": "exchange and models the other one is",
    "start": "1096160",
    "end": "1102320"
  },
  {
    "start": "1099000",
    "end": "1099000"
  },
  {
    "text": "is about accelera scheduling in a real product cluster user often submit",
    "start": "1102320",
    "end": "1108160"
  },
  {
    "text": "multiple kind of workloads such as the small job big job how to avoid the big job or smart job",
    "start": "1108160",
    "end": "1115200"
  },
  {
    "text": "get starving as well as a is very important for to meet the as theory of the job",
    "start": "1115200",
    "end": "1122640"
  },
  {
    "text": "in the live picture in the left feature at the moment of time one",
    "start": "1122640",
    "end": "1128720"
  },
  {
    "text": "t1 users submit a big drop sub me a big drop drop one with a gun",
    "start": "1128720",
    "end": "1134880"
  },
  {
    "text": "and a small job job too the smart job get allocated and the big job",
    "start": "1134880",
    "end": "1141120"
  },
  {
    "text": "keep hunting due to you due to not enough results as a more open time too",
    "start": "1141120",
    "end": "1147919"
  },
  {
    "text": "a new smart job three was submitted and get a locket the big job keep pending",
    "start": "1147919",
    "end": "1155200"
  },
  {
    "text": "because there's still not enough results with the time",
    "start": "1155200",
    "end": "1161039"
  },
  {
    "text": "with time go on the big job keep starving if the",
    "start": "1161039",
    "end": "1167200"
  },
  {
    "text": "release results always can understand certified skunk and use the same in the",
    "start": "1167200",
    "end": "1172799"
  },
  {
    "text": "small small drop the srs scheduling a law to configure the job so that it is",
    "start": "1172799",
    "end": "1180480"
  },
  {
    "text": "completed it's completed on the time and reduce the risk of mis",
    "start": "1180480",
    "end": "1186559"
  },
  {
    "text": "missing deadline necessary wait time is the maximum time that one job some",
    "start": "1186559",
    "end": "1192640"
  },
  {
    "text": "should stay in pending when sra wait time reached sra plan he moved the pending job to the",
    "start": "1192640",
    "end": "1199600"
  },
  {
    "text": "united states and started to reserve resources for the job until the jobs requirement is",
    "start": "1199600",
    "end": "1206080"
  },
  {
    "text": "satisfied",
    "start": "1206080",
    "end": "1208880"
  },
  {
    "start": "1208000",
    "end": "1208000"
  },
  {
    "text": "the next one the next important feature is about newmar feature",
    "start": "1211440",
    "end": "1217039"
  },
  {
    "text": "for con for computing computer in intensive",
    "start": "1217039",
    "end": "1223360"
  },
  {
    "text": "and performance demand at the job user would want to consider user exclusive",
    "start": "1223360",
    "end": "1229200"
  },
  {
    "text": "cpu results which can reduce the laws to back contact the switch foot job running on",
    "start": "1229200",
    "end": "1235760"
  },
  {
    "text": "the pneuma based process is also better to have the cpu applying to the port on",
    "start": "1235760",
    "end": "1241520"
  },
  {
    "text": "the sim newman node which reduce the communicating loss and improve the",
    "start": "1241520",
    "end": "1246559"
  },
  {
    "text": "improved training currently topological management and cpu",
    "start": "1246559",
    "end": "1252240"
  },
  {
    "text": "management provide a topological scheduling as a node so the problem will improve the scheduling the slope",
    "start": "1252240",
    "end": "1261120"
  },
  {
    "text": "in the scheduler cannot perform the top logic scheduling it's not aware of the top",
    "start": "1261520",
    "end": "1268480"
  },
  {
    "text": "logic and the cpu allocation on the node therefore the container may be refused",
    "start": "1268480",
    "end": "1273520"
  },
  {
    "text": "by the corporate because i know the result is less than the top logic",
    "start": "1273520",
    "end": "1280480"
  },
  {
    "text": "minor requirement eventually the scheduling will not be successful another problem is all the",
    "start": "1280480",
    "end": "1286799"
  },
  {
    "text": "top logic management working on the create on the node they cannot choose the best nodes for the job to address",
    "start": "1286799",
    "end": "1294960"
  },
  {
    "text": "those limit limitations volcano introduced a new mod aware plug-in and a",
    "start": "1294960",
    "end": "1301039"
  },
  {
    "text": "resource exporter components volcano offered a pod level top logic",
    "start": "1301039",
    "end": "1306640"
  },
  {
    "text": "policy so that users adopt different top logic policy for their own case",
    "start": "1306640",
    "end": "1313840"
  },
  {
    "text": "the results exporter components report no node newman information by",
    "start": "1313840",
    "end": "1319679"
  },
  {
    "text": "crd based on the new information and the requests of the port volcano conduct",
    "start": "1319679",
    "end": "1325200"
  },
  {
    "text": "scheduling the next one is a bald spark",
    "start": "1325200",
    "end": "1331600"
  },
  {
    "start": "1327000",
    "end": "1327000"
  },
  {
    "text": "sparkle started to pro to support kubernetes in uh",
    "start": "1331600",
    "end": "1337240"
  },
  {
    "text": "2.3 version in 2017 as the later",
    "start": "1337240",
    "end": "1343520"
  },
  {
    "text": "an announcement spark operator provide another way to have wrong uh to have running spark on kubernetes",
    "start": "1343520",
    "end": "1351200"
  },
  {
    "text": "as well however in a long time sparrow unknown had the lack of batch scheduling",
    "start": "1351200",
    "end": "1358000"
  },
  {
    "text": "batch batch scheduling features",
    "start": "1358000",
    "end": "1363200"
  },
  {
    "text": "later over the last year we started to work with the spark contributor to",
    "start": "1363200",
    "end": "1368240"
  },
  {
    "text": "support customer budget scheduling for spark spark with scale spark with volcano provides",
    "start": "1368240",
    "end": "1376640"
  },
  {
    "text": "the best scheduling capability like job priority qr fair share resource",
    "start": "1376640",
    "end": "1384080"
  },
  {
    "text": "resolutions and so on it will be released in spark 3.3 version",
    "start": "1384080",
    "end": "1392720"
  },
  {
    "start": "1392000",
    "end": "1392000"
  },
  {
    "text": "another important feature is about collocation multiple server",
    "start": "1393760",
    "end": "1399679"
  },
  {
    "text": "being deployed together has become common in recent years online web service and offline analysis",
    "start": "1399679",
    "end": "1406880"
  },
  {
    "text": "service has their different features online services requires new results",
    "start": "1406880",
    "end": "1412720"
  },
  {
    "text": "but sorry online service require fuel results but they are very demanding for",
    "start": "1412720",
    "end": "1419679"
  },
  {
    "text": "the latency such as recommendation and",
    "start": "1419679",
    "end": "1424720"
  },
  {
    "text": "the other service they also expensive traffic every day",
    "start": "1424720",
    "end": "1431720"
  },
  {
    "text": "offline analysis service is a computing [Music] intensive require require more results",
    "start": "1432720",
    "end": "1440080"
  },
  {
    "text": "but the traffic stays stable and they don't and they don't demand a faster",
    "start": "1440080",
    "end": "1445520"
  },
  {
    "text": "response like online service if online service and offline workload can be deployed in a",
    "start": "1445520",
    "end": "1451679"
  },
  {
    "text": "in a hybrid way the resource can be fully used another pinpoint is",
    "start": "1451679",
    "end": "1457840"
  },
  {
    "text": "our subscription and our subtraction of the results users",
    "start": "1457840",
    "end": "1463039"
  },
  {
    "text": "would like to ensure their scalability they so they tend to apply the exclusive",
    "start": "1463039",
    "end": "1469919"
  },
  {
    "text": "results proposed however kubernetes scheduling relay on the stacked port requirement to",
    "start": "1469919",
    "end": "1476320"
  },
  {
    "text": "in the scheduling this leads to high resource allocation range and low resource usage",
    "start": "1476320",
    "end": "1483600"
  },
  {
    "text": "typically the average credit cpu resource usage could be less than",
    "start": "1483600",
    "end": "1490960"
  },
  {
    "text": "15 percent this is a huge risk of resource to resolve this pinpoint",
    "start": "1490960",
    "end": "1496559"
  },
  {
    "text": "volcano has done some research uh done some research",
    "start": "1496559",
    "end": "1501600"
  },
  {
    "text": "investigations for example based on the monitoring and usage volcano can perform dynamic scheduling additionally on the",
    "start": "1501600",
    "end": "1509520"
  },
  {
    "text": "huawei huawei operation system the cpu and the memory results are isolated for online",
    "start": "1509520",
    "end": "1516960"
  },
  {
    "text": "service and offline service moreover features like network acceleration and inference",
    "start": "1516960",
    "end": "1524400"
  },
  {
    "text": "detection and application profiling will be deployed in the pipeline",
    "start": "1524400",
    "end": "1531440"
  },
  {
    "start": "1530000",
    "end": "1530000"
  },
  {
    "text": "we also did several enhancements to our throughput",
    "start": "1531840",
    "end": "1538000"
  },
  {
    "text": "as as a moment of data continue to growth and the complexity of the business increased user require",
    "start": "1538000",
    "end": "1545840"
  },
  {
    "text": "coordinated cluster to support larger scale we also spend a lot of effort to support",
    "start": "1545840",
    "end": "1555880"
  },
  {
    "text": "000 nodes and 100 million",
    "start": "1556240",
    "end": "1561279"
  },
  {
    "text": "clusters of posts by optimizing the container network scattering container",
    "start": "1561279",
    "end": "1567360"
  },
  {
    "text": "engine and so on uh the right",
    "start": "1567360",
    "end": "1573200"
  },
  {
    "text": "in the red part list some uh in the right uh at least some spec specification of",
    "start": "1573200",
    "end": "1580240"
  },
  {
    "text": "uh enhancement in our project taser scheduling uh take scheduler for the",
    "start": "1580240",
    "end": "1586880"
  },
  {
    "text": "example we improved the scheduling throughput to uh one point",
    "start": "1586880",
    "end": "1594240"
  },
  {
    "text": "uh one one point five thousand pounds per second but adopt equivalent cash batch",
    "start": "1594240",
    "end": "1602159"
  },
  {
    "text": "bonding and sick bonding and",
    "start": "1602159",
    "end": "1607919"
  },
  {
    "text": "they also depends on the uh some enhancement to the uh kubernetes uh",
    "start": "1607919",
    "end": "1614320"
  },
  {
    "text": "to the cube api server yeah uh here is some user case uh from uh",
    "start": "1614320",
    "end": "1622720"
  },
  {
    "start": "1617000",
    "end": "1617000"
  },
  {
    "text": "from volcano is the one of turbo's social media and",
    "start": "1622720",
    "end": "1630799"
  },
  {
    "text": "e-commerce uh company in china many people use their applications in mobile",
    "start": "1630799",
    "end": "1637520"
  },
  {
    "text": "they have 100 million active users per month and the main workload they are running",
    "start": "1637520",
    "end": "1644320"
  },
  {
    "text": "to provide recommendations for the end user they need to refresh the model every",
    "start": "1644320",
    "end": "1651600"
  },
  {
    "text": "several minutes and also they have some online service to do a reaction when users refresh",
    "start": "1651600",
    "end": "1659520"
  },
  {
    "text": "their their nose the challenge is they have a large cluster with nearly a 1000 nodes",
    "start": "1659520",
    "end": "1668000"
  },
  {
    "text": "and the model have one 100 billion parameters when jobs have",
    "start": "1668000",
    "end": "1675039"
  },
  {
    "text": "hundreds of ps and worker posts i actually they want",
    "start": "1675039",
    "end": "1680320"
  },
  {
    "text": "to pass the resource allocation the user adopts the task",
    "start": "1680320",
    "end": "1685840"
  },
  {
    "text": "top logic scheduling and [Music] we have",
    "start": "1685840",
    "end": "1690880"
  },
  {
    "text": "20 performance improvement they also use volcano sla base based",
    "start": "1690880",
    "end": "1697360"
  },
  {
    "text": "scattering to prevent a large to prevent large drops from the",
    "start": "1697360",
    "end": "1703120"
  },
  {
    "text": "starvation another another user case is retained",
    "start": "1703120",
    "end": "1711039"
  },
  {
    "start": "1705000",
    "end": "1705000"
  },
  {
    "text": "from a retained company so they initially use a yarn to schedule",
    "start": "1711039",
    "end": "1717440"
  },
  {
    "text": "batch job as a company growth the development of policy also changed",
    "start": "1717440",
    "end": "1723360"
  },
  {
    "text": "different research team required container deployment to a wider informant complication and dependency",
    "start": "1723360",
    "end": "1730960"
  },
  {
    "text": "the higher words kubernetes defaults gathered like fair share scheduling between a different",
    "start": "1730960",
    "end": "1737760"
  },
  {
    "text": "tennis so they held their chrome and they also have a requirement of using different",
    "start": "1737760",
    "end": "1744000"
  },
  {
    "text": "frameworks such as tensorflow patch and mpi",
    "start": "1744000",
    "end": "1749360"
  },
  {
    "text": "that's required to install different kind of approaches including this",
    "start": "1749360",
    "end": "1754640"
  },
  {
    "text": "which which will have also for maintenance efforts",
    "start": "1754640",
    "end": "1760399"
  },
  {
    "text": "the user looking for the solution and they found that volcano can satisfy the",
    "start": "1760399",
    "end": "1766080"
  },
  {
    "text": "requirement and offer diversity scheduling capability and",
    "start": "1766080",
    "end": "1772640"
  },
  {
    "text": "they use a volcanic drop as a unified",
    "start": "1772640",
    "end": "1777679"
  },
  {
    "text": "as well common jobs application for all kinds of ai training workload",
    "start": "1777679",
    "end": "1783360"
  },
  {
    "text": "eventually they decide to migrate from the yarn to kubernetes",
    "start": "1783360",
    "end": "1788880"
  },
  {
    "text": "with volcano currently there are there are about uh 300",
    "start": "1788880",
    "end": "1797120"
  },
  {
    "text": "uh 300 thousand poles every day in their product environment for this",
    "start": "1797120",
    "end": "1804159"
  },
  {
    "text": "for this user for the public adoptions we",
    "start": "1804159",
    "end": "1811679"
  },
  {
    "start": "1806000",
    "end": "1806000"
  },
  {
    "text": "we do get a lot of user options especially for the people are running in",
    "start": "1811679",
    "end": "1816720"
  },
  {
    "text": "uh running the ai big data live sentence science transcoding",
    "start": "1816720",
    "end": "1823440"
  },
  {
    "text": "workload on kubernetes here are part of adoption using volcanoes product environment from the code diversity",
    "start": "1823440",
    "end": "1830559"
  },
  {
    "text": "university in recently we can find that we got a good devastating community",
    "start": "1830559",
    "end": "1838640"
  },
  {
    "text": "development here is the",
    "start": "1838640",
    "end": "1844880"
  },
  {
    "start": "1842000",
    "end": "1842000"
  },
  {
    "text": "release journey of volcano we have released more than 16 major",
    "start": "1844880",
    "end": "1851600"
  },
  {
    "text": "version since the things the way the project start at the",
    "start": "1851600",
    "end": "1856960"
  },
  {
    "text": "early stage we developed a site of scheduling policy to support the patchwork load then integrate with the",
    "start": "1856960",
    "end": "1863519"
  },
  {
    "text": "ecosystem such as the kubernetes uh sorry with the flow and the spark",
    "start": "1863519",
    "end": "1868720"
  },
  {
    "text": "operators and algo and so on later we found that",
    "start": "1868720",
    "end": "1873919"
  },
  {
    "text": "there are lots of gap on the job on the turbo management so we support quite a lot of time",
    "start": "1873919",
    "end": "1880000"
  },
  {
    "text": "to enhance the job management to to upstream",
    "start": "1880000",
    "end": "1885519"
  },
  {
    "text": "in the future we are going to support several scenarios like such as multi-cloud scheduling",
    "start": "1885519",
    "end": "1892640"
  },
  {
    "text": "and performance enhancement and intelligent collocation for",
    "start": "1892640",
    "end": "1898399"
  },
  {
    "text": "for better resource utilization here are some useful links",
    "start": "1898399",
    "end": "1905840"
  },
  {
    "text": "in the volcano community you you're welcome to draw on community community and give",
    "start": "1905840",
    "end": "1912320"
  },
  {
    "text": "give give some feedback uh thank you for the uh okay that's uh that's all from me and",
    "start": "1912320",
    "end": "1919679"
  },
  {
    "text": "thank you very much and welcome to join our community",
    "start": "1919679",
    "end": "1926120"
  }
]
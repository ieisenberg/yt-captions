[
  {
    "text": "great to see you all on a Friday afternoon towards the end of the conference uh when you could be out in London enjoying the beautiful weather hi",
    "start": "400",
    "end": "7680"
  },
  {
    "text": "everyone I'm with uh Bernie here and I'm Ganesh and we are going to be talking",
    "start": "7680",
    "end": "13679"
  },
  {
    "text": "about intralevel transparent checkpointing for resilient a IML",
    "start": "13679",
    "end": "18920"
  },
  {
    "text": "workloads uh believe it or not that is me uh without a beard and I am a",
    "start": "18920",
    "end": "24320"
  },
  {
    "text": "software engineer in the Azure Kubernetes service team at Microsoft uh at AKS we run a managed uh Kubernetes",
    "start": "24320",
    "end": "31920"
  },
  {
    "text": "service platform which allows you to run a variety of compute workloads uh including lots of ML training and",
    "start": "31920",
    "end": "38640"
  },
  {
    "text": "inference workloads and we have users running these workloads at extremely large scales i particularly work on GPU",
    "start": "38640",
    "end": "45920"
  },
  {
    "text": "provisioning and making it easier to run a variety of GPU workloads on the platform i've also previously worked on",
    "start": "45920",
    "end": "52320"
  },
  {
    "text": "speeding up pod start time through a feature called artifact streaming yeah my name is Birdie Woo i'm the VP of",
    "start": "52320",
    "end": "59280"
  },
  {
    "text": "technology partnerships for a company called Meverge mever is a uh Silicon Valley based uh startup uh that has",
    "start": "59280",
    "end": "66560"
  },
  {
    "text": "software uh that we've developed that uh helps on memory virtualization and also",
    "start": "66560",
    "end": "71920"
  },
  {
    "text": "checkpointing software uh and so we're hoping to bring those two kinds of capabilities into the A IML area uh on a",
    "start": "71920",
    "end": "80080"
  },
  {
    "text": "personal note I I live uh part-time in uh Hawaii and I noticed that the culture",
    "start": "80080",
    "end": "85840"
  },
  {
    "text": "of the Kubernetes community in Hawaii is very similar there's a there's a a very",
    "start": "85840",
    "end": "92000"
  },
  {
    "text": "friendly culture uh uh one that helps each other and uh and it's almost like",
    "start": "92000",
    "end": "97360"
  },
  {
    "text": "an extended family or what we call Ohana in Hawaii and uh we also in Hawaii we",
    "start": "97360",
    "end": "102400"
  },
  {
    "text": "like to welcome new people that's called the Aloa spirit so one of these days I hope we'll have CubeCon over in in",
    "start": "102400",
    "end": "108040"
  },
  {
    "text": "Hawaii anyway back to you thank you in today's talk we'll start off with",
    "start": "108040",
    "end": "114079"
  },
  {
    "text": "a brief poll then talk about the motivation for why we want to do this approach and what are the other current",
    "start": "114079",
    "end": "119840"
  },
  {
    "text": "approaches that people are taking to address these problems then we'll define what intralevel transparent",
    "start": "119840",
    "end": "125360"
  },
  {
    "text": "checkpointing is talk about uh use cases and limitations and then Bernie will",
    "start": "125360",
    "end": "130640"
  },
  {
    "text": "share about how it works and show some cool demos to see this in action and we'll also talk about some open areas",
    "start": "130640",
    "end": "136800"
  },
  {
    "text": "that we could address together as a community for this part I would really",
    "start": "136800",
    "end": "142080"
  },
  {
    "text": "really love your participation there'll be three questions first one how many of you have",
    "start": "142080",
    "end": "148319"
  },
  {
    "text": "run GPU workloads in Kubernetes please raise your hands wow that's great almost everyone here has done that uh as",
    "start": "148319",
    "end": "156280"
  },
  {
    "text": "expected and then uh how many of you are not satisfied with the existing",
    "start": "156280",
    "end": "161760"
  },
  {
    "text": "solutions for resilience things like handling GPU failures or node downtime could you please raise your hands okay",
    "start": "161760",
    "end": "168720"
  },
  {
    "text": "almost all of you who raised previously too and how many of you care about",
    "start": "168720",
    "end": "174000"
  },
  {
    "text": "resilience more for training or fine-tuning um okay that's about half of you and",
    "start": "174000",
    "end": "180879"
  },
  {
    "text": "what about for inference all right there's a good number uh but fewer than for",
    "start": "180879",
    "end": "186840"
  },
  {
    "text": "training that's sort of the mix that I've heard from conversations with folks too and then finally how many of you are",
    "start": "186840",
    "end": "195599"
  },
  {
    "text": "focused on improving the utilization of your GPU infrastructure okay awesome awesome",
    "start": "195599",
    "end": "202159"
  },
  {
    "text": "great almost all of you raised your hands which is uh good to know because GPUs are expensive and you could",
    "start": "202159",
    "end": "209200"
  },
  {
    "text": "probably save a few uh several thousand dollars of of money by improving the",
    "start": "209200",
    "end": "215440"
  },
  {
    "text": "infrastructure utilization and this is also validated by many papers and reports that have",
    "start": "215440",
    "end": "222000"
  },
  {
    "text": "come out um you probably have seen the Llama 3 paper with how frequent GPU errors are and the different types of",
    "start": "222000",
    "end": "228640"
  },
  {
    "text": "issues that have h that people are encountering especially for training and then we we've seen talks in",
    "start": "228640",
    "end": "235280"
  },
  {
    "text": "this conference as well talking about the frequency of GPU errors there's also surveys which validate what you're",
    "start": "235280",
    "end": "242480"
  },
  {
    "text": "experiencing around low GPU utilization so about a third of users have less than",
    "start": "242480",
    "end": "248480"
  },
  {
    "text": "or equal to 30% of GPU usage according to this uh survey and but how do we",
    "start": "248480",
    "end": "254000"
  },
  {
    "text": "address these challenges um today and how can we make it better today many users are running GPU",
    "start": "254000",
    "end": "262880"
  },
  {
    "text": "health checks uh that are integrated as part of node problem detector and those",
    "start": "262880",
    "end": "268160"
  },
  {
    "text": "can be also combined with a remedy controller which can take actions like rebooting the node or resetting the GPU",
    "start": "268160",
    "end": "275840"
  },
  {
    "text": "this helps you in identifying issues and taking mitigation steps but it still has",
    "start": "275840",
    "end": "282080"
  },
  {
    "text": "questions on how you can handle the application uh efficiently because you",
    "start": "282080",
    "end": "287120"
  },
  {
    "text": "you face issues around things like scheduling dead time and also slow part starts because when you have a new node",
    "start": "287120",
    "end": "294639"
  },
  {
    "text": "that needs to be provisioned that takes a while and if you have a large model that takes several GBs or sometimes",
    "start": "294639",
    "end": "300880"
  },
  {
    "text": "multiple hundred GBs it's going to take a long time to load we talked about some aspects from the infra provider",
    "start": "300880",
    "end": "306560"
  },
  {
    "text": "perspective and also from a user perspective in this CubeCon Salt Lake City talk but now we're going to address",
    "start": "306560",
    "end": "312960"
  },
  {
    "text": "the other side of how we make it easier from the application perspective such that they don't have to think about",
    "start": "312960",
    "end": "318880"
  },
  {
    "text": "these problems on their own another approach that's commonly",
    "start": "318880",
    "end": "324240"
  },
  {
    "text": "done is uh model checkpointing during training it's done frequently and then",
    "start": "324240",
    "end": "329440"
  },
  {
    "text": "if a node goes down you just restore from um from the registry or another",
    "start": "329440",
    "end": "335360"
  },
  {
    "text": "repository where you have the previous checkpoints of the model where it's stored and then you can continue the",
    "start": "335360",
    "end": "340400"
  },
  {
    "text": "training process uh some approaches include basically interrupting your",
    "start": "340400",
    "end": "346160"
  },
  {
    "text": "workload as well and that's a naive approach and then just migrating to a new node if there's issues you could",
    "start": "346160",
    "end": "352240"
  },
  {
    "text": "also use tools like Q and Volcano to make this process easier along with some",
    "start": "352240",
    "end": "357479"
  },
  {
    "text": "GPU strategies like multi-instance GPUs but all of these uh address",
    "start": "357479",
    "end": "365360"
  },
  {
    "text": "different aspects of the problem they still face some common challenges like slow loading time and recovery time for",
    "start": "365360",
    "end": "371600"
  },
  {
    "text": "your end to-end workload they might you might need to configure your applications as well to handle things",
    "start": "371600",
    "end": "378000"
  },
  {
    "text": "like recovery from the last checkpoint it could also lead to higher costs and we think that this could be made more",
    "start": "378000",
    "end": "386720"
  },
  {
    "text": "resilient so uh what is infrale transfer and checkpointing this is the the aspect",
    "start": "386840",
    "end": "392560"
  },
  {
    "text": "that we want to talk about today and we want to define it in uh what phrase by",
    "start": "392560",
    "end": "398800"
  },
  {
    "text": "phrase so checkpoint here represents capturing the entire state of the running application with the point in",
    "start": "398800",
    "end": "405759"
  },
  {
    "text": "time memory and all the associated files so that you can basically pause migrate and hot restart it",
    "start": "405759",
    "end": "411800"
  },
  {
    "text": "later transparent refers to the application code or frameworks not needing to be changed so the application",
    "start": "411800",
    "end": "419360"
  },
  {
    "text": "does not need to be aware of uh this checkpointing process then intra level refers to this",
    "start": "419360",
    "end": "426720"
  },
  {
    "text": "completely being handled by orchestrators or schedulers and the platform itself so that uh users don't",
    "start": "426720",
    "end": "433759"
  },
  {
    "text": "need to worry about it i I want to really emphasize this point that this is not model",
    "start": "433759",
    "end": "439400"
  },
  {
    "text": "checkpointing it's not just model checkpointing because you're capturing the entire application state in your",
    "start": "439400",
    "end": "445120"
  },
  {
    "text": "container and from the usage perspective it's the",
    "start": "445120",
    "end": "450720"
  },
  {
    "text": "people at the platform layer who would really care about the solution",
    "start": "450720",
    "end": "456560"
  },
  {
    "text": "uh from from the implementation aspect and this is as you know uh an emerging",
    "start": "456560",
    "end": "462479"
  },
  {
    "text": "topic and we are in the emerging track too so not everything is going to be fitting perfectly but so we'll have open",
    "start": "462479",
    "end": "468880"
  },
  {
    "text": "uh open discussions at the end so if you're new to this you might have",
    "start": "468880",
    "end": "474160"
  },
  {
    "text": "many questions you know how production ready is it can you restore it on different",
    "start": "474160",
    "end": "481360"
  },
  {
    "text": "GPUs what type of different machines can you restore it on how do you handle network state how much time does it take",
    "start": "481360",
    "end": "487120"
  },
  {
    "text": "to do all these additional computations and we'll be addressing some of these questions but I would also",
    "start": "487120",
    "end": "493919"
  },
  {
    "text": "highly recommend uh multiple other talks that you could look at for more details",
    "start": "493919",
    "end": "501800"
  },
  {
    "text": "so for a high level overview think of yourself as a neural",
    "start": "501840",
    "end": "507680"
  },
  {
    "text": "network that is running on a double-decker bus in London taking the",
    "start": "507680",
    "end": "512880"
  },
  {
    "text": "views of the city learning about it and updating your neural network weights unfortunately your bus breaks",
    "start": "512880",
    "end": "520279"
  },
  {
    "text": "down so your application container cannot start running you cannot continue training what happens next",
    "start": "520279",
    "end": "528480"
  },
  {
    "text": "well without you knowing it almost a snapshot of view from 2 minutes ago was",
    "start": "528480",
    "end": "534800"
  },
  {
    "text": "taken and kept in the British Museum now we want to be able to restore that and",
    "start": "534800",
    "end": "541519"
  },
  {
    "text": "continue running it so this is the checkpointing uh phase and that that was kept in the museum and then now you spin",
    "start": "541519",
    "end": "548720"
  },
  {
    "text": "up a new node where you can continue running your application but instead of",
    "start": "548720",
    "end": "554320"
  },
  {
    "text": "going uh through some application specific logic you can recover to where",
    "start": "554320",
    "end": "559920"
  },
  {
    "text": "you were from just 2 minutes ago and continue as if nothing happened pretty much so you're going to be like almost",
    "start": "559920",
    "end": "568080"
  },
  {
    "text": "like the cyber people in the show severance or like unlike them you're going to remember what you did so all",
    "start": "568080",
    "end": "574240"
  },
  {
    "text": "the training the neural network weights that you updated are still going to be there uh and you can continue running it",
    "start": "574240",
    "end": "580480"
  },
  {
    "text": "so because we've captured the entire memory state that will also be restored",
    "start": "580480",
    "end": "585519"
  },
  {
    "text": "uh in this process and this will help in improving resilience and we'll also talk about how",
    "start": "585519",
    "end": "591680"
  },
  {
    "text": "it improves utilization so there's a host of",
    "start": "591680",
    "end": "596880"
  },
  {
    "text": "uh challenges that this can address so there's three categories one which we call scheduling optimization another for",
    "start": "596880",
    "end": "604000"
  },
  {
    "text": "handling node downtime and then the third one for pod start time",
    "start": "604000",
    "end": "609480"
  },
  {
    "text": "improvements for scheduling if you have a higher priority workload that comes in or if you have idle resources that are",
    "start": "609480",
    "end": "617279"
  },
  {
    "text": "you know scheduled but actually not being utilized or if you have spot instances that can go away anytime you",
    "start": "617279",
    "end": "624240"
  },
  {
    "text": "could use this checkpoint restore approach to be able to migrate your workloads or you could also use it to",
    "start": "624240",
    "end": "631440"
  },
  {
    "text": "handle it efficiently and then especially when you have longunning jobs that need to be taken over by another",
    "start": "631440",
    "end": "638079"
  },
  {
    "text": "job we need to have a seamless process for uh capturing the state and being",
    "start": "638079",
    "end": "643680"
  },
  {
    "text": "able to save it somewhere and then restore it so this helps there and then for node downtime like the original",
    "start": "643680",
    "end": "650000"
  },
  {
    "text": "chart that I showed with uh GPU issues you can add to that end to end",
    "start": "650000",
    "end": "656240"
  },
  {
    "text": "flow to be able to checkpoint right before the GPU goes down or taking",
    "start": "656240",
    "end": "661680"
  },
  {
    "text": "draining the node and then restore it when you go to a new node",
    "start": "661680",
    "end": "666880"
  },
  {
    "text": "uh and a lot of these use cases are unlocked by the faster time it takes to",
    "start": "666880",
    "end": "672000"
  },
  {
    "text": "uh load the new container image and the application and uh many companies have",
    "start": "672000",
    "end": "678079"
  },
  {
    "text": "starting to already use this for speeding up their pod start",
    "start": "678079",
    "end": "683320"
  },
  {
    "text": "times so what are the other like ML specific use cases that we may be able to address with",
    "start": "683320",
    "end": "689000"
  },
  {
    "text": "this for inference many of you might assume that infrance can be considered",
    "start": "689000",
    "end": "694399"
  },
  {
    "text": "as a stateless application but is it really stateless well according to one",
    "start": "694399",
    "end": "699920"
  },
  {
    "text": "definition stateful applications save past and present information while you know stateless applications",
    "start": "699920",
    "end": "706120"
  },
  {
    "text": "don't the for inference of let's say for LLMs you you tend to store values like",
    "start": "706120",
    "end": "712399"
  },
  {
    "text": "the key value cache values in memory and that could be both in GPU memory and in",
    "start": "712399",
    "end": "718079"
  },
  {
    "text": "CPU memory and if you lose the inference workload and the KV cache is only present on your node then that memory",
    "start": "718079",
    "end": "725680"
  },
  {
    "text": "would have that would have to be recomputed later uh with most current",
    "start": "725680",
    "end": "731160"
  },
  {
    "text": "approaches but with transparent checkpointing it might be possible to restore that state and continue running",
    "start": "731160",
    "end": "738639"
  },
  {
    "text": "your application without uh much need for additional recomputation",
    "start": "738639",
    "end": "743920"
  },
  {
    "text": "but one requirement there is the time to reload the KV cache must be less than the time needed to recomputee",
    "start": "743920",
    "end": "751320"
  },
  {
    "text": "it then for distributed ML training uh in this in this time chart you see",
    "start": "751320",
    "end": "757680"
  },
  {
    "text": "checkpoints being done at a regular cadence uh this is from a Microsoft uh",
    "start": "757680",
    "end": "763440"
  },
  {
    "text": "research paper this graph and they were talking about how to optimize checkpointing from the model layer so",
    "start": "763440",
    "end": "770480"
  },
  {
    "text": "the model it I I I need to mention that the model checkpointing will still happen even with infra level",
    "start": "770480",
    "end": "777120"
  },
  {
    "text": "checkpointing because model level checkpointing is useful uh for experimentation and if you want to go",
    "start": "777120",
    "end": "782639"
  },
  {
    "text": "back to a previous state so we will be complementing this model level checkpointing with infrale checkpointing",
    "start": "782639",
    "end": "789200"
  },
  {
    "text": "so we take perhaps more frequent checkpoints and then restore it if there is an issue in between two model",
    "start": "789200",
    "end": "796560"
  },
  {
    "text": "checkpoints so in this time chart you see that if there's a failure in between checkpoint 3 and checkpoint 4 you'd have",
    "start": "796560",
    "end": "802880"
  },
  {
    "text": "to retrain uh from checkpoint 3 that wastes additional cycles basically for",
    "start": "802880",
    "end": "810240"
  },
  {
    "text": "GPU and CPU but also because when you have a distributed training case many",
    "start": "810240",
    "end": "816399"
  },
  {
    "text": "other nodes in your entire cluster will also have to wait for your one node to",
    "start": "816399",
    "end": "821839"
  },
  {
    "text": "be restored and then the progress to be synced because at the end of each checkpoint typically",
    "start": "821839",
    "end": "827040"
  },
  {
    "text": "they will be syncing their uh gradients and the weights",
    "start": "827040",
    "end": "832240"
  },
  {
    "text": "so but this is not a solution to everything there are some limitations",
    "start": "832279",
    "end": "838880"
  },
  {
    "text": "that we need to be aware of and address one being that the checkpointing the",
    "start": "838880",
    "end": "845040"
  },
  {
    "text": "infra layer is not aware of the application state itself which means that the checkpoint could be",
    "start": "845040",
    "end": "850560"
  },
  {
    "text": "significantly larger compared to just app level checkpointing",
    "start": "850560",
    "end": "855760"
  },
  {
    "text": "so let's say for inference for the model itself will take up most of the space but you also have additional libraries",
    "start": "855760",
    "end": "862240"
  },
  {
    "text": "and helper functions that will be loaded onto memory that would also be copied over and depending on the application",
    "start": "862240",
    "end": "867920"
  },
  {
    "text": "the amount of memory you uh the difference between the two checkpoints can be u significant as well then",
    "start": "867920",
    "end": "876600"
  },
  {
    "text": "there's rigid requirements for restoration sometimes where you might have to match the machine configurations",
    "start": "876600",
    "end": "883279"
  },
  {
    "text": "but also this varies on the type of checkpointing implementation you use and",
    "start": "883279",
    "end": "888720"
  },
  {
    "text": "then you would want to have restore in a machine which obviously has like the same or higher",
    "start": "888720",
    "end": "894680"
  },
  {
    "text": "memory there's also some resource uh considerations like how much compute",
    "start": "894680",
    "end": "900320"
  },
  {
    "text": "time it takes and that can vary between periodic and event- driven checkpointing so this these are pretty much two types",
    "start": "900320",
    "end": "908160"
  },
  {
    "text": "of checkpointing you can do so periodic is you like the the word you keep checkpointing every you know few minutes",
    "start": "908160",
    "end": "914880"
  },
  {
    "text": "or a few seconds based on how you configure it uh and then uh event driven",
    "start": "914880",
    "end": "920079"
  },
  {
    "text": "is if you know that there's going to be a failure then you can checkpoint it uh",
    "start": "920079",
    "end": "925760"
  },
  {
    "text": "and then keep the latest checkpoint this graph there is sort of a highle",
    "start": "925760",
    "end": "932320"
  },
  {
    "text": "graph on the trade-offs that are involved in figuring out what type of checkpointing you want we want to do so",
    "start": "932320",
    "end": "939279"
  },
  {
    "text": "on the y-axis you see the total cost of operating a workload and then on the x",
    "start": "939279",
    "end": "945040"
  },
  {
    "text": "you see the checkpoint frequency so if your checkpoint frequency is really low you're not uh you're going to checkpoint",
    "start": "945040",
    "end": "951839"
  },
  {
    "text": "after a very long period of time your the additional compute overhead for checkpointing is going to be low but",
    "start": "951839",
    "end": "957920"
  },
  {
    "text": "your resilience to errors and recovery time will be high because you might need to recomputee it if you uh error out and",
    "start": "957920",
    "end": "966320"
  },
  {
    "text": "then on the other extreme if you're checkpointing really frequently your compute uh consumption is going to be",
    "start": "966320",
    "end": "972480"
  },
  {
    "text": "significantly higher but your overall uh resilience might might be better but",
    "start": "972480",
    "end": "980079"
  },
  {
    "text": "the total cost of operating your uh job would be higher as well so we need to find a sweet spot for how frequently uh",
    "start": "980079",
    "end": "987680"
  },
  {
    "text": "you need to checkpoint and that will vary also depending on the type of application and also the type of GPUs",
    "start": "987680",
    "end": "993199"
  },
  {
    "text": "that you have the error rate and other factors now Bernie will continue and he'll share about how it works and show",
    "start": "993199",
    "end": "1000480"
  },
  {
    "text": "some cool demos okay great thanks Ganesh uh yeah so as as",
    "start": "1000480",
    "end": "1006639"
  },
  {
    "text": "Ganesh uh uh discussed he's now defined what infrar transparent checkpointing is",
    "start": "1006639",
    "end": "1012399"
  },
  {
    "text": "he's described some use cases uh that we see are possibilities and uh uh he's",
    "start": "1012399",
    "end": "1017839"
  },
  {
    "text": "also described the limitations of checkpointing and so now what I want to do is just deep dive a little bit more",
    "start": "1017839",
    "end": "1022959"
  },
  {
    "text": "into how we're trying to implement transparent checkpointing for uh Kubernetes and everything is centered",
    "start": "1022959",
    "end": "1028558"
  },
  {
    "text": "around an open source project called uh Creo creo stands for checkpoint restore and user space uh and uh Creo was",
    "start": "1028559",
    "end": "1036000"
  },
  {
    "text": "started in 2012 it's it's designed to checkpoint uh applications running on Linux uh platforms and uh it's uh in",
    "start": "1036000",
    "end": "1044558"
  },
  {
    "text": "wide production with uh other uh virtual machine uh uh platforms for doing live",
    "start": "1044559",
    "end": "1050160"
  },
  {
    "text": "migrations and then uh my company members has been using uh Creo as part",
    "start": "1050160",
    "end": "1055600"
  },
  {
    "text": "of a spot instance migration of longunning HPC batch workloads on on public clouds uh in addition to that",
    "start": "1055600",
    "end": "1063200"
  },
  {
    "text": "Creo is is incorporated if if you don't know already into Kubernetes the the 130 release uh supports forensic examination",
    "start": "1063200",
    "end": "1071440"
  },
  {
    "text": "of containers those containers are checkpointed by uh Creo and uh in addition to that in uh CubeCon Paris uh",
    "start": "1071440",
    "end": "1078720"
  },
  {
    "text": "last year I gave a brief talk on uh uh some work that uh uh we uh done with",
    "start": "1078720",
    "end": "1084799"
  },
  {
    "text": "Nvidia to introduce GPU uh level checkpointing uh to uh uh to the this",
    "start": "1084799",
    "end": "1091840"
  },
  {
    "text": "community and so I demonstrated an operator that could do a GPU CPU checkpoint of a single uh workload",
    "start": "1091840",
    "end": "1097919"
  },
  {
    "text": "running on a pod uh and successfully re restarted elsewhere uh there's ongoing",
    "start": "1097919",
    "end": "1103200"
  },
  {
    "text": "work by the community to uh and they've created a very nice uh GPU plug-in for",
    "start": "1103200",
    "end": "1108559"
  },
  {
    "text": "Creo that also will support the uh AMD GPU and I want to give a shout out to uh",
    "start": "1108559",
    "end": "1114320"
  },
  {
    "text": "excuse me Rison and Adrian here in the front row and their uh colleague Victoria they presented yesterday and so",
    "start": "1114320",
    "end": "1121120"
  },
  {
    "text": "if you want to read more about the history of Creo and where the Creole project actually stands those are the folks to talk to uh in addition to all",
    "start": "1121120",
    "end": "1128880"
  },
  {
    "text": "that work uh what we did was we uh uh we have to to to make this ready for uh",
    "start": "1128880",
    "end": "1135120"
  },
  {
    "text": "production level workloads as uh Ganesha referred to we we need to do something about the checkpoint uh overhead and so",
    "start": "1135120",
    "end": "1142799"
  },
  {
    "text": "in that U-shaped curve we showed in the in the previous slide what we're trying to do is lower that curve and flatten it",
    "start": "1142799",
    "end": "1147919"
  },
  {
    "text": "out uh so we get a very highly efficient uh checkpointing technology and uh to do",
    "start": "1147919",
    "end": "1154400"
  },
  {
    "text": "that uh uh from our experience working with HPC batch uh work uh loads uh we uh",
    "start": "1154400",
    "end": "1161679"
  },
  {
    "text": "are focused primarily on reducing the checkpoint interruption time production interruption time uh and then also the",
    "start": "1161679",
    "end": "1168160"
  },
  {
    "text": "space consumption by the checkpoints uh and then also computer and memory resources that are being uh used to uh",
    "start": "1168160",
    "end": "1174480"
  },
  {
    "text": "uh execute these checkpoints and so uh we've got been successful with HPC uh",
    "start": "1174480",
    "end": "1179760"
  },
  {
    "text": "workloads doing that uh using a combination of what we call asynchronous checkpointing uh uh compression",
    "start": "1179760",
    "end": "1185520"
  },
  {
    "text": "technologies and then also even incremental checkpointing and uh in case of asynchronous uh types of",
    "start": "1185520",
    "end": "1191520"
  },
  {
    "text": "checkpointing we've been able to reduce the window the checkpoint production interruption window from up from",
    "start": "1191520",
    "end": "1197679"
  },
  {
    "text": "anywhere between 30 and 100x uh 100 times better than just uh running it uh",
    "start": "1197679",
    "end": "1203120"
  },
  {
    "text": "without any kind of asynchronous and then uh with compression we've been able to achieve up to five to one levels of",
    "start": "1203120",
    "end": "1208880"
  },
  {
    "text": "compression uh and in incremental uh snapshots also for uh situations where",
    "start": "1208880",
    "end": "1214400"
  },
  {
    "text": "we have very very narrow uh uh times to uh handle uh uh preeemption uh signals",
    "start": "1214400",
    "end": "1220640"
  },
  {
    "text": "so uh we're hoping to bring all those kinds of capabilities to bear on on the Kubernetes problem and uh and so part of",
    "start": "1220640",
    "end": "1228000"
  },
  {
    "text": "that is we also have a lot of experience working with uh external events uh like",
    "start": "1228000",
    "end": "1233120"
  },
  {
    "text": "uh uh spot instance preeemption signals working with schedulers uh so we've done integrations already with on the HPC",
    "start": "1233120",
    "end": "1240159"
  },
  {
    "text": "side with slurm lsf and htc condor and uh we're hoping to bring that kind of",
    "start": "1240159",
    "end": "1246480"
  },
  {
    "text": "knowhow to bear also so we just started working with Q and the job the the job set uh projects to uh integrate there uh",
    "start": "1246480",
    "end": "1254480"
  },
  {
    "text": "another consideration for uh operationalizing uh this kind of checkpointing is security issues as as",
    "start": "1254480",
    "end": "1261280"
  },
  {
    "text": "you guys know the uh uh as you may know the creo actually has to uh run in in a",
    "start": "1261280",
    "end": "1267360"
  },
  {
    "text": "a privileged state because it it needs to checkpoint all the different uh uh uh pods within that particular node uh so",
    "start": "1267360",
    "end": "1274559"
  },
  {
    "text": "there's some security things we have to address there and then also uh sometimes there's third party license managers",
    "start": "1274559",
    "end": "1280159"
  },
  {
    "text": "that need to be uh taken care of and when they're checkpointed and things are being moved around uh and then uh",
    "start": "1280159",
    "end": "1286080"
  },
  {
    "text": "ephemeral files is another area uh uh I think uh right now uh you're allowed to",
    "start": "1286080",
    "end": "1291760"
  },
  {
    "text": "spill memory into uh onto a disk and you're also uh allowed to have ephemeral",
    "start": "1291760",
    "end": "1297280"
  },
  {
    "text": "files as part of your uh workloads and so those also need to be checkpointed and and and moved elsewhere if you're",
    "start": "1297280",
    "end": "1303360"
  },
  {
    "text": "going to do a hot restart somewhere else uh and then lastly we're we're continuing to work with Nvidia to uh",
    "start": "1303360",
    "end": "1310080"
  },
  {
    "text": "improve the uh the checkpointing uh features uh in terms of fractional GPUs",
    "start": "1310080",
    "end": "1316080"
  },
  {
    "text": "and things like that uh and then also improve the uh overall performance uh and uh flexibility uh to be checkpointed",
    "start": "1316080",
    "end": "1323120"
  },
  {
    "text": "and migrate to different types of environments so those are all ongoing efforts to operationalize checkpointing",
    "start": "1323120",
    "end": "1329600"
  },
  {
    "text": "here and just to give you a quick idea of what's going on uh right now the the GPU checkpointing is currently a",
    "start": "1329600",
    "end": "1336400"
  },
  {
    "text": "two-stage process the first stage is to uh checkpoint uh to actually halt",
    "start": "1336400",
    "end": "1341679"
  },
  {
    "text": "further job submissions to the to the GPU that uh uh and this is done on a on a a process ID basis halt all",
    "start": "1341679",
    "end": "1348799"
  },
  {
    "text": "submissions and then secondly wait for that uh uh particular process to uh",
    "start": "1348799",
    "end": "1353919"
  },
  {
    "text": "complete and then we take that memory dump it to system memory so that's the first stage and then from system memory",
    "start": "1353919",
    "end": "1359520"
  },
  {
    "text": "we're also checkpointing the system memory plus the GPU memory that's just been dumped there along with any kinds",
    "start": "1359520",
    "end": "1365039"
  },
  {
    "text": "of uh ephemeral files and things like that taking that all and and dumping that onto a persistent volume somewhere",
    "start": "1365039",
    "end": "1371840"
  },
  {
    "text": "uh or or some sort of directory and the restoration process is simply the reverse of that a two-stage process",
    "start": "1371840",
    "end": "1379000"
  },
  {
    "text": "currently uh now uh last year again I showed a single node being uh uh uh",
    "start": "1379000",
    "end": "1384320"
  },
  {
    "text": "checkpointed and hot restarted we wanted to extend that to a distributed architecture uh and uh so the key",
    "start": "1384320",
    "end": "1391360"
  },
  {
    "text": "components of that are first of all there's a high level coordinator uh this coordinator's role is to uh first of all",
    "start": "1391360",
    "end": "1397440"
  },
  {
    "text": "discover membership uh of who who belongs in this particular uh uh",
    "start": "1397440",
    "end": "1402720"
  },
  {
    "text": "distributed cluster uh and we do that by uh mapping out the the network",
    "start": "1402720",
    "end": "1408320"
  },
  {
    "text": "relationships between all the workers and and doing a self-discovery but in addition to that we've also have an",
    "start": "1408320",
    "end": "1414080"
  },
  {
    "text": "option to uh just basically query the job set API and just find out where are the workers uh and then that's so that's",
    "start": "1414080",
    "end": "1420799"
  },
  {
    "text": "one component another component is a synchronizer synchronizer's job as you can see on the on the right side of this",
    "start": "1420799",
    "end": "1426480"
  },
  {
    "text": "thing is to make sure all the workers uh when they're invoking this uh Creo operation are all uh doing it uh",
    "start": "1426480",
    "end": "1434080"
  },
  {
    "text": "concurrently uh so there's this uh place where uh in the in the Creole design",
    "start": "1434080",
    "end": "1439280"
  },
  {
    "text": "where you can put an action script hook called at the pre-dump stage to make sure that all the uh uh the the",
    "start": "1439280",
    "end": "1445840"
  },
  {
    "text": "checkpoints are occurring simultaneously and then uh conversely on the other side of the checkpoint there's a post dump uh",
    "start": "1445840",
    "end": "1453039"
  },
  {
    "text": "uh uh barrier there where we can make sure everything is also released simultaneously and the purpose of that",
    "start": "1453039",
    "end": "1458159"
  },
  {
    "text": "is to make sure there's no uh messages in transit and things like that that could could be uh uh uh lost or",
    "start": "1458159",
    "end": "1465440"
  },
  {
    "text": "corrupted by uh having things checkpointed out of out of sync and then we also have a web hook that allows uh",
    "start": "1465440",
    "end": "1472559"
  },
  {
    "text": "us to uh provide a for particular applications the the a checkpoint path",
    "start": "1472559",
    "end": "1477919"
  },
  {
    "text": "or or posision or or or to a p persistent volume or whatever so that we",
    "start": "1477919",
    "end": "1483200"
  },
  {
    "text": "know where this checkpoint is being stored and there's a demon set to deploy this on each host uh and we do use a uh",
    "start": "1483200",
    "end": "1490400"
  },
  {
    "text": "modified version of runc uh and the goal of that is to uh uh uh run C would",
    "start": "1490400",
    "end": "1497279"
  },
  {
    "text": "normally pull off the a cold restart uh container off of the registry but in",
    "start": "1497279",
    "end": "1502400"
  },
  {
    "text": "this case run C will then go to a a directory path if there is one for a checkpoint and and bring the uh image in",
    "start": "1502400",
    "end": "1508640"
  },
  {
    "text": "that way uh so that's that's the basics of how our clustered uh transparent",
    "start": "1508640",
    "end": "1513679"
  },
  {
    "text": "checkpointing is uh excuse me implemented uh and then we to automate all this naturally we got to put this in",
    "start": "1513679",
    "end": "1519760"
  },
  {
    "text": "an operator uh and the goal of this operator is to create a graceful preeemption and hot restart of of of a",
    "start": "1519760",
    "end": "1527919"
  },
  {
    "text": "of a workload whether it's a an individual no uh application or a distributed one and so uh we look at",
    "start": "1527919",
    "end": "1535600"
  },
  {
    "text": "this as a way to reduce what we call the friction of moving or hibernating stateful longunning uh workloads and a",
    "start": "1535600",
    "end": "1543279"
  },
  {
    "text": "lot of AI ML workloads uh have that kind of a characteristic and u so so this is",
    "start": "1543279",
    "end": "1549840"
  },
  {
    "text": "uh basically there's two ways we can implement this thing one is to uh implement as a sidecar or we could also",
    "start": "1549840",
    "end": "1555279"
  },
  {
    "text": "implement this deploy this via dimaset so for the purposes of using this for node maintenance we're implementing",
    "start": "1555279",
    "end": "1561840"
  },
  {
    "text": "excuse me implementing this as a as a a demon set deployment and uh pretty much off-the-shelf components that are listed",
    "start": "1561840",
    "end": "1568159"
  },
  {
    "text": "there the only thing that's been modified uh offtheshelf Creo version 4 for example the only thing that's been",
    "start": "1568159",
    "end": "1573679"
  },
  {
    "text": "modified is the the run C so that we can direct it to a a checkpoint uh path to to pull the uh checkpointed",
    "start": "1573679",
    "end": "1580679"
  },
  {
    "text": "image this is uh the what we're talking about the kind of a use case that we're",
    "start": "1580679",
    "end": "1586000"
  },
  {
    "text": "working on it's called job set migration the first uh type of migration is to uh",
    "start": "1586000",
    "end": "1591679"
  },
  {
    "text": "for for a scheduler to to use to to take a uh a set of of pods in a in a",
    "start": "1591679",
    "end": "1597919"
  },
  {
    "text": "particular distributed cluster and move them in an entirety to some other location and this could be used to help",
    "start": "1597919",
    "end": "1603760"
  },
  {
    "text": "maybe defragment a particular uh uh infrastructure uh and uh and and also to",
    "start": "1603760",
    "end": "1611440"
  },
  {
    "text": "use it for prioritizing higher prior allow higher priority jobs to take over the resources etc and then the second",
    "start": "1611440",
    "end": "1617760"
  },
  {
    "text": "one is more for node maintenance uh what what I discovered during this conference which was really interesting is that",
    "start": "1617760",
    "end": "1624159"
  },
  {
    "text": "seems like almost 90% of these failures that you see with GPUs can actually be corrected by just simply uh uh",
    "start": "1624159",
    "end": "1632080"
  },
  {
    "text": "evacuating the node and rebooting it uh so so we see this scenario where we're",
    "start": "1632080",
    "end": "1637200"
  },
  {
    "text": "we're actually dealing with again that distributed cluster but we're just uh moving uh one node the failing node or",
    "start": "1637200",
    "end": "1643840"
  },
  {
    "text": "the one that has the problem over to a uh a hot spare and then maybe rebooting the hot spare so I think there's also",
    "start": "1643840",
    "end": "1650640"
  },
  {
    "text": "been a lot of progress in doing predictive kinds of of of of uh work on",
    "start": "1650640",
    "end": "1656400"
  },
  {
    "text": "predicting which nodes may be failing and so this kind of technique I think would help in node",
    "start": "1656400",
    "end": "1662440"
  },
  {
    "text": "maintenance uh so just before I go into this uh the demo itself I I just want to",
    "start": "1662440",
    "end": "1668400"
  },
  {
    "text": "explain what we're trying to do here to keep things simple we have just three uh uh nodes in this three workers in each",
    "start": "1668400",
    "end": "1674559"
  },
  {
    "text": "demo the first demo is going to be a bare metal demo of a of a two node",
    "start": "1674559",
    "end": "1679919"
  },
  {
    "text": "pietorch distributed cluster and we're going to use our periodic checkpoint so when you see that to checkpoint uh and",
    "start": "1679919",
    "end": "1687279"
  },
  {
    "text": "fail uh we'll we'll manually walk through that demo so you'll be able to see every step of this process and then",
    "start": "1687279",
    "end": "1693760"
  },
  {
    "text": "uh what we'll do is we'll fail over to a spare node uh and then you'll uh uh",
    "start": "1693760",
    "end": "1699360"
  },
  {
    "text": "you'll see it resume operation now because it's periodic you'll see it roll back to the epic where it actually uh in",
    "start": "1699360",
    "end": "1706000"
  },
  {
    "text": "this case uh uh was checkpointed so the so when we do the checkpoint it continues running but when we uh do the",
    "start": "1706000",
    "end": "1712559"
  },
  {
    "text": "restoration it will roll back to the last checkpoint the second demo is uh uh we're going to show more automated",
    "start": "1712559",
    "end": "1718240"
  },
  {
    "text": "things so that's going to happen a lot faster so you got to be alert uh but that's a job set migration uh so that's",
    "start": "1718240",
    "end": "1724000"
  },
  {
    "text": "more of an event driven thing the event will be we we're typing in there to take this node out of maintenance will automatically take that node out of",
    "start": "1724000",
    "end": "1730240"
  },
  {
    "text": "maintenance migrate the workload to the spare and resume operation uh that's all done with a uh with with Q and the job",
    "start": "1730240",
    "end": "1736919"
  },
  {
    "text": "sets so let me uh now uh switch over to the",
    "start": "1736919",
    "end": "1743320"
  },
  {
    "text": "demos uh",
    "start": "1743320",
    "end": "1746799"
  },
  {
    "text": "okay so this is the first demo it's a uh the bare metal demo",
    "start": "1750440",
    "end": "1757640"
  },
  {
    "text": "okay it's running good so there's two two workers there a master and and and a",
    "start": "1758000",
    "end": "1763200"
  },
  {
    "text": "worker and they're already running this PyTorch distributed thing so you can see the Epics and patches going uh they're",
    "start": "1763200",
    "end": "1769520"
  },
  {
    "text": "they're scrolling by uh and also uh we're we're running the GPU so we're",
    "start": "1769520",
    "end": "1774799"
  },
  {
    "text": "pulling up the SMI Nvidia SMI tool to verify the GPUs are up and running that's on the bottom",
    "start": "1774799",
    "end": "1781559"
  },
  {
    "text": "there uh then also I want to show you that we're showing you the TCP IP",
    "start": "1781559",
    "end": "1786799"
  },
  {
    "text": "connection so these things are chatting a lot with each other uh and so that's what's being highlighted there in the in",
    "start": "1786799",
    "end": "1793120"
  },
  {
    "text": "the bottom windows there in the demo again this is going to be a manual",
    "start": "1793120",
    "end": "1798520"
  },
  {
    "text": "demonstration uh then we pulled up our in the middle there this is our our checkpoint coordinator our synchronizer",
    "start": "1798520",
    "end": "1805200"
  },
  {
    "text": "that uh uh will make sure that these two nodes when they're checkpointed below are are aligned with each other and so",
    "start": "1805200",
    "end": "1812159"
  },
  {
    "text": "we're typing in a manual checkpoint for each one and uh so the uh so they're",
    "start": "1812159",
    "end": "1818960"
  },
  {
    "text": "both being uh checkpointed and coordinated and the the checkpointing uh",
    "start": "1818960",
    "end": "1824080"
  },
  {
    "text": "you can start seeing uh on the left lower left the uh checkpoint dump files",
    "start": "1824080",
    "end": "1829200"
  },
  {
    "text": "uh now on the on the lower right uh the the dump files as is being checkpointed",
    "start": "1829200",
    "end": "1834320"
  },
  {
    "text": "now if you notice above the application is continuing to run so the checkpoint occurred fairly quickly and uh it was",
    "start": "1834320",
    "end": "1840559"
  },
  {
    "text": "about at epic five when the checkpoint occurred but everything is still progressing and uh so now what we're",
    "start": "1840559",
    "end": "1848240"
  },
  {
    "text": "doing is uh we're trying to arsync the lower right uh uh worker to a spare node",
    "start": "1848240",
    "end": "1854640"
  },
  {
    "text": "which we haven't shown yet because it's it's not I haven't posted it yet on the screen there but we're doing an arsync",
    "start": "1854640",
    "end": "1860720"
  },
  {
    "text": "and just copying the files manually and so you can see all the the the files listed there on that lower uh right side",
    "start": "1860720",
    "end": "1867679"
  },
  {
    "text": "of the the window uh so it's taking a little while to arsync it and then",
    "start": "1867679",
    "end": "1874760"
  },
  {
    "text": "uh then what we're doing is we're going to kill that worker uh and then uh",
    "start": "1874760",
    "end": "1880559"
  },
  {
    "text": "switch the monitor on the upper right so that we can see the spare node so that's uh being set up right",
    "start": "1880559",
    "end": "1890320"
  },
  {
    "text": "now and again this is the manual demo so I just wanted you to see this and uh while this thing is running I also want",
    "start": "1890360",
    "end": "1896240"
  },
  {
    "text": "to give a shout out to my colleagues Ron and Vincent uh back in California that did all the hard work of putting these",
    "start": "1896240",
    "end": "1902320"
  },
  {
    "text": "demos together uh and then u yeah so now the",
    "start": "1902320",
    "end": "1907760"
  },
  {
    "text": "uh checkpoint coordinator is then invoked again to do the the restoration process and all the all the files are",
    "start": "1907760",
    "end": "1914960"
  },
  {
    "text": "are being uh uh reloaded and the uh system is being restarted uh and uh pretty soon you'll",
    "start": "1914960",
    "end": "1923440"
  },
  {
    "text": "start seeing the uh the checkpoint uh uh log and I mean the distributed PyTorch",
    "start": "1923440",
    "end": "1929279"
  },
  {
    "text": "log uh scrolling along again uh yeah so there it goes it's",
    "start": "1929279",
    "end": "1936159"
  },
  {
    "text": "resuming and it actually resumed uh even though the the uh job act the the job",
    "start": "1936159",
    "end": "1941600"
  },
  {
    "text": "continued running we actually ended up rolling it back to about epic 5 in this demo so that's the manual uh demo of a",
    "start": "1941600",
    "end": "1949519"
  },
  {
    "text": "checkpoint uh and a hot restart uh with a with a with a roll back to the last periodic checkpoint and now like I would",
    "start": "1949519",
    "end": "1956960"
  },
  {
    "text": "like to show you the uh uh excuse me here the uh automated version of this so",
    "start": "1956960",
    "end": "1963519"
  },
  {
    "text": "here what we have is uh we're going to demonstrate taking a node out of maintenance using uh an",
    "start": "1963519",
    "end": "1971518"
  },
  {
    "text": "operator uh so we have three nodes set up and then a master",
    "start": "1971960",
    "end": "1977279"
  },
  {
    "text": "uh and uh yeah so and we're using uh Q",
    "start": "1977279",
    "end": "1982480"
  },
  {
    "text": "the Q project uh to migrate from node 3 to node one and then also we're showing",
    "start": "1982480",
    "end": "1989200"
  },
  {
    "text": "this job set notion so the job set is called uh uh pytorch distributed training that's what we just highlighted",
    "start": "1989200",
    "end": "1996240"
  },
  {
    "text": "there that's the job set and then uh uh what we're doing here is just going to",
    "start": "1996240",
    "end": "2001519"
  },
  {
    "text": "show the log so you can watch the epics and the batches go by and so we'll show you later on that there's total",
    "start": "2001519",
    "end": "2007840"
  },
  {
    "text": "continuity even though we restarted it elsewhere now we're highlighting node three because that's the one we're going to take down this is a maintenance CRD",
    "start": "2007840",
    "end": "2014480"
  },
  {
    "text": "that we set up uh in conjunction with our operator uh and uh then we also set up a maintenance shell script and all",
    "start": "2014480",
    "end": "2021200"
  },
  {
    "text": "you have to do is basically execute the maintenance shell script and just put the node name in and then everything's",
    "start": "2021200",
    "end": "2026240"
  },
  {
    "text": "automated after that and that's what we're doing right now we're invoking the maintenance shell script if you look",
    "start": "2026240",
    "end": "2031600"
  },
  {
    "text": "immediately above in that kind of panel you'll you'll see that there's a you'll see a quick termination and and a start",
    "start": "2031600",
    "end": "2038640"
  },
  {
    "text": "of the of the containers above it and the other nodes so there there's the termination there's the new creation of",
    "start": "2038640",
    "end": "2044880"
  },
  {
    "text": "the new replacement container uh and then",
    "start": "2044880",
    "end": "2050240"
  },
  {
    "text": "uh see where are we here okay now now we're starting up this log thing again you can see it pretty much uh resumed",
    "start": "2050240",
    "end": "2056960"
  },
  {
    "text": "where it left off it'll scroll up some more so you'll be able to see that while we're waiting for it to scroll up uh",
    "start": "2056960",
    "end": "2062638"
  },
  {
    "text": "you'll also be able to see this checkpoint file that's where we we right now we're just dumping these into an NFS",
    "start": "2062639",
    "end": "2067760"
  },
  {
    "text": "file but just to show you where these checkpoints are uh we're we're just showing you uh that in the upper uh",
    "start": "2067760",
    "end": "2073760"
  },
  {
    "text": "right corner there so anyway there you go and if you",
    "start": "2073760",
    "end": "2079040"
  },
  {
    "text": "look at this bottom uh corner uh bottom right corner you'll be able to see yeah that the uh we resumed right where we",
    "start": "2079040",
    "end": "2086398"
  },
  {
    "text": "left off basically on epic 9 batch uh uh uh batch 1000 there so uh so that's the",
    "start": "2086399",
    "end": "2093679"
  },
  {
    "text": "demo i hope you uh enjoyed that and let me uh let me make some concluding",
    "start": "2093679",
    "end": "2100320"
  },
  {
    "text": "remarks here uh",
    "start": "2100320",
    "end": "2107440"
  },
  {
    "text": "sorry yeah so uh next steps and uh call to action so what I just showed you",
    "start": "2113560",
    "end": "2119280"
  },
  {
    "text": "today is uh that we demonstrated the feasibility of using an operator to transparently checkpoint and hot restart",
    "start": "2119280",
    "end": "2125200"
  },
  {
    "text": "a distributed PyTorch uh a IML workload and improve its uh resiliency and so our",
    "start": "2125200",
    "end": "2131200"
  },
  {
    "text": "next steps will be to to continue to uh uh this is kind of a a crawl walk run but we're going to work on overhead",
    "start": "2131200",
    "end": "2137760"
  },
  {
    "text": "optimization characterization how to scale this up we believe it is should be highly scalable because everything can",
    "start": "2137760",
    "end": "2143599"
  },
  {
    "text": "be done parallel on each node uh the checkpointing process uh and then also we we we have a lot of work to do on",
    "start": "2143599",
    "end": "2150160"
  },
  {
    "text": "back-end networks uh we'll probably start with the RDMA uh kinds of connectivity and then also telemetry and",
    "start": "2150160",
    "end": "2156000"
  },
  {
    "text": "integration with Prometheus uh and then we also want to continue to work with the uh uh CUDA uh and the Creole",
    "start": "2156000",
    "end": "2162320"
  },
  {
    "text": "communities to improve uh functionality and capabilities uh and contribute back there uh and then my call action for you",
    "start": "2162320",
    "end": "2169280"
  },
  {
    "text": "folks uh is uh we appreciate any feedback evaluation or specific use cases if you want to uh give this a an",
    "start": "2169280",
    "end": "2177200"
  },
  {
    "text": "early uh try that would be great uh evaluation and uh we we are very",
    "start": "2177200",
    "end": "2182560"
  },
  {
    "text": "interested in working with the scheduler community and orchestrators and even application frameworks i we see",
    "start": "2182560",
    "end": "2188880"
  },
  {
    "text": "possibilities of where this could be used in that context to help uh with checkpointing or or to uh coordinate",
    "start": "2188880",
    "end": "2194640"
  },
  {
    "text": "checkpointing and then also spot instances and uh we want to keep ramping this up and validating things at scale",
    "start": "2194640",
    "end": "2201280"
  },
  {
    "text": "so with that I'd like to thank you very much and have Ganesh come back up here i see do we have any time left oops did we",
    "start": "2201280",
    "end": "2208320"
  },
  {
    "text": "overshoot yeah we are a bit over thank you i apologize thank",
    "start": "2208320",
    "end": "2213599"
  },
  {
    "text": "you i think we'll take questions in the hallway later and then uh we'll also upload the slide deck for reference and",
    "start": "2214359",
    "end": "2221760"
  },
  {
    "text": "with additional references to previous talks too thank you thank you",
    "start": "2221760",
    "end": "2228320"
  }
]
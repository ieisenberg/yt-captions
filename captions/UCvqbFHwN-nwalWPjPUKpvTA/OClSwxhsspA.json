[
  {
    "start": "0",
    "end": "41000"
  },
  {
    "text": "thank you for for coming to our talk today we're going to talk about how to secure applications through",
    "start": "30",
    "end": "5370"
  },
  {
    "text": "defense-in-depth by building a trusted software supply chain and then having continuous monitoring on your grantees",
    "start": "5370",
    "end": "12210"
  },
  {
    "text": "clusters so a quick introduction I'm Stephen Tirana I'm a lead technologist at Booz Allen",
    "start": "12210",
    "end": "17460"
  },
  {
    "text": "Hamilton or a federal consultancy so I do a lot of legacy IT modernization",
    "start": "17460",
    "end": "23939"
  },
  {
    "text": "within the government space and I'm Michael Ducey I'm one of the maintainer x' of the falco project I do a lot in",
    "start": "23939",
    "end": "30359"
  },
  {
    "text": "the world of DevOps helped organize a few DevOps days throughout the world and",
    "start": "30359",
    "end": "35550"
  },
  {
    "text": "also hope with six security and other things in the Sancerre all right so",
    "start": "35550",
    "end": "42090"
  },
  {
    "start": "41000",
    "end": "95000"
  },
  {
    "text": "vulnerabilities this is a representation of the typical vulnerability lifecycle",
    "start": "42090",
    "end": "48450"
  },
  {
    "text": "right so if you think about the average vulnerability there's going to be a time when that vulnerability is introduced",
    "start": "48450",
    "end": "54059"
  },
  {
    "text": "into your environment there's going to be a time when an exploitation for that environment is for that vulnerability is",
    "start": "54059",
    "end": "60090"
  },
  {
    "text": "discovered at some point you're gonna realize that your environment is compromised and then presumably after",
    "start": "60090",
    "end": "66720"
  },
  {
    "text": "that you're going to patch that vulnerability right so that time between when that exploitation is discovered and",
    "start": "66720",
    "end": "72720"
  },
  {
    "text": "when you actually patch it is when you're most susceptible to being compromised so what can we actually do",
    "start": "72720",
    "end": "79500"
  },
  {
    "text": "about this through dedsec ops and integrating security into your software",
    "start": "79500",
    "end": "85229"
  },
  {
    "text": "home and life cycle you can shrink that time from when an exploitation is discovered to when you're able to identify that it's in your environment",
    "start": "85229",
    "end": "91710"
  },
  {
    "text": "and then subsequently patch it alright so everyone I've ever talked to has a different definition of DevOps or",
    "start": "91710",
    "end": "98939"
  },
  {
    "start": "95000",
    "end": "253000"
  },
  {
    "text": "devstack ops so this slide search the level set what exactly I'm talking about when I say",
    "start": "98939",
    "end": "104280"
  },
  {
    "text": "dedsec ops the the too long didn't read of this slide is that it's all about shifting left security and incorporating",
    "start": "104280",
    "end": "110700"
  },
  {
    "text": "it into every step of the software development lifecycle traditionally DevOps was about getting",
    "start": "110700",
    "end": "115829"
  },
  {
    "text": "application developers and operations engineers to work together more effectively through automated testing",
    "start": "115829",
    "end": "121549"
  },
  {
    "text": "infrastructure as code so we're able to quickly and reliably deploy our code",
    "start": "121549",
    "end": "126810"
  },
  {
    "text": "we're fairly confident that it's going to work through automated testing but we were still experiencing bottlenecks when",
    "start": "126810",
    "end": "132060"
  },
  {
    "text": "it came time to act we deploy to production and that's because we never actually pulled in the security team so dead-set cops is all",
    "start": "132060",
    "end": "139360"
  },
  {
    "text": "about incorporating the security team's requirements there's a whole bunch of different kinds of security testing that",
    "start": "139360",
    "end": "145120"
  },
  {
    "text": "you can incorporate like application dependency scanning making sure third-party libraries are secure static",
    "start": "145120",
    "end": "151030"
  },
  {
    "text": "code analysis making sure that you know you haven't hard-coded IP addresses or passwords into your code base dynamic",
    "start": "151030",
    "end": "157720"
  },
  {
    "text": "application security testing is a mouthful of a way to say penetration testing so actually attacking your",
    "start": "157720",
    "end": "163569"
  },
  {
    "text": "deployed applications and seeing if they're susceptible to comment exploitations with containerization",
    "start": "163569",
    "end": "170079"
  },
  {
    "text": "comes the container image so there's container image gaming to make sure that if we're pulling images off docker hub",
    "start": "170079",
    "end": "176349"
  },
  {
    "text": "with no clue who actually built them that they don't have known vulnerabilities or Bitcoin miners Oh",
    "start": "176349",
    "end": "183220"
  },
  {
    "text": "bonor ability is in general come in two flavors you've got vulnerable packages and vulnerable configurations so a lot",
    "start": "183220",
    "end": "190930"
  },
  {
    "text": "of the container image scanning tools out there will help you out with the compliance side which is making sure",
    "start": "190930",
    "end": "196359"
  },
  {
    "text": "that you haven't configured your containers to run as route you know making sure that you're compliant with",
    "start": "196359",
    "end": "202209"
  },
  {
    "text": "different federally regulated guidelines like NIST or secure technical implementation guides if you happen to",
    "start": "202209",
    "end": "207910"
  },
  {
    "text": "be working in the federal space like I primarily do and in that same vein of compliance you've got accessibility",
    "start": "207910",
    "end": "214419"
  },
  {
    "text": "assurance so making sure that the applications we're building are accessible and 508 compliant it is",
    "start": "214419",
    "end": "220120"
  },
  {
    "text": "important to note there's no tool out there that's going to tell you that you are 100% 508 compliant but what they can",
    "start": "220120",
    "end": "226239"
  },
  {
    "text": "do is tell you if you're not all right so if you included an image on your website for example that doesn't have an",
    "start": "226239",
    "end": "231819"
  },
  {
    "text": "alt text that's a pretty black and white easy to figure out 508 compliance issue",
    "start": "231819",
    "end": "236829"
  },
  {
    "text": "so a lot of the tools that can help you with this are primarily trying to give developers fast feedback on",
    "start": "236829",
    "end": "243220"
  },
  {
    "text": "accessibility issues on their application so that those that are doing the manual testing can focus on the more",
    "start": "243220",
    "end": "248489"
  },
  {
    "text": "complex aspects of compliance so all of",
    "start": "248489",
    "end": "254650"
  },
  {
    "start": "253000",
    "end": "437000"
  },
  {
    "text": "the security testing is in addition to all of the other kinds of quality assurance testing that the industry's",
    "start": "254650",
    "end": "261278"
  },
  {
    "text": "been doing for for a couple years now so things like unit testing functional",
    "start": "261279",
    "end": "266560"
  },
  {
    "text": "testing surveys test automation pull a word out of the dictionary and add testing to the end of it if you're supporting",
    "start": "266560",
    "end": "273430"
  },
  {
    "text": "enterprise scale pipeline development so you're a centralized DevOps team helping",
    "start": "273430",
    "end": "280060"
  },
  {
    "text": "support CI CV pipelines for multiple applications at the same time or if",
    "start": "280060",
    "end": "285070"
  },
  {
    "text": "you're building a platform to host micro services it's likely that applications",
    "start": "285070",
    "end": "290410"
  },
  {
    "text": "in your portfolio or leveraging different tools alright so your front-end applications might be doing",
    "start": "290410",
    "end": "295510"
  },
  {
    "text": "you know testing with something like karma or jest whereas back-end applications if they're Java might be using j-unit you could",
    "start": "295510",
    "end": "302860"
  },
  {
    "text": "have a Python back-end some teams in your organization might be using sonar cube for static code analysis other",
    "start": "302860",
    "end": "309130"
  },
  {
    "text": "teams might be using fortify so the current CIS CD landscape out there is",
    "start": "309130",
    "end": "315150"
  },
  {
    "text": "primarily targeted at application specific pipelines most of the time you",
    "start": "315150",
    "end": "321010"
  },
  {
    "text": "get a artifact in your source code repository that outlines as code what your software delivery processes look",
    "start": "321010",
    "end": "327220"
  },
  {
    "text": "like so when a developer does something in github or whatever your source code provider is what does that mean from a",
    "start": "327220",
    "end": "333610"
  },
  {
    "text": "pipeline perspective so when you're supporting for example a 60 micro service based application that means",
    "start": "333610",
    "end": "340240"
  },
  {
    "text": "that you have 60 different pipelines that exist right so let's say you're",
    "start": "340240",
    "end": "345910"
  },
  {
    "text": "using Jenkins and you have a Jenkins file that you probably copied and pasted",
    "start": "345910",
    "end": "350980"
  },
  {
    "text": "across all of your 60 different source code repositories and then tweaked it to make sure that it's you know compatible",
    "start": "350980",
    "end": "357820"
  },
  {
    "text": "with whatever specific tools are being used in that repository from stock overflow Nova wrung from stack overflow",
    "start": "357820",
    "end": "363220"
  },
  {
    "text": "we have all googled Stone our cube plus Jenkins and found the six lines of code to do a static code analysis if you want",
    "start": "363220",
    "end": "371410"
  },
  {
    "text": "to make a change to that because we're we're all striving to be continuously improving our software delivery",
    "start": "371410",
    "end": "377260"
  },
  {
    "text": "processes that means you have to go open 64 requests right and you need to work",
    "start": "377260",
    "end": "382900"
  },
  {
    "text": "with these application development teams to coordinate a migration to a new version of the pipeline and having to",
    "start": "382900",
    "end": "390070"
  },
  {
    "text": "have done this myself it can be an extremely cumbersome process that ultimately introduces so much technical",
    "start": "390070",
    "end": "396280"
  },
  {
    "text": "debt they you kind of just leave the pipeline as is you don't want to add new tools and it really starts to stagnate your",
    "start": "396280",
    "end": "402280"
  },
  {
    "text": "ability to continuously improve and at Booz Allen we do a lot of application",
    "start": "402280",
    "end": "408090"
  },
  {
    "text": "modernization every project that we're working on needs a pipeline so this",
    "start": "408090",
    "end": "414030"
  },
  {
    "text": "duplication of effort across applications takes place within a single project",
    "start": "414030",
    "end": "419200"
  },
  {
    "text": "it happens your ability to continuously improve but then we're also reinventing the wheel across every project that",
    "start": "419200",
    "end": "426490"
  },
  {
    "text": "needs a pipeline so every DevOps engineer Booz Allen would go to Google or Stack Overflow and find the Sam code",
    "start": "426490",
    "end": "433570"
  },
  {
    "text": "snippet and introduce it so about three years ago we set out to figure out like",
    "start": "433570",
    "end": "440860"
  },
  {
    "start": "437000",
    "end": "524000"
  },
  {
    "text": "how how can we make this go faster you know when a project starts up not everyone is a Jenkins expert I know way",
    "start": "440860",
    "end": "448750"
  },
  {
    "text": "more about Jenkins and I'd like to admit and really should have - it would take four to six months to find all the right",
    "start": "448750",
    "end": "454660"
  },
  {
    "text": "Stack Overflow snippets to tie together so we wanted to drastically improve how",
    "start": "454660",
    "end": "460330"
  },
  {
    "text": "quickly we could deploy pipelines while also being able to introduce a level of",
    "start": "460330",
    "end": "465490"
  },
  {
    "text": "organizational governance right one of the biggest issues with those 60 different Jenkins files is that you",
    "start": "465490",
    "end": "470950"
  },
  {
    "text": "don't actually know they're all doing the same thing right if in order or is it if an organization says you need to",
    "start": "470950",
    "end": "477490"
  },
  {
    "text": "do container image scanning you need to do penetration testing you're really just trusting that all of the different",
    "start": "477490",
    "end": "484090"
  },
  {
    "text": "development teams have implemented a pipeline that meets these organizational standards I mean we wanted to figure out",
    "start": "484090",
    "end": "489940"
  },
  {
    "text": "how could we take pipeline development from what you see on the screen which is every development team has a pipeline",
    "start": "489940",
    "end": "496270"
  },
  {
    "text": "that largely follows the same steps you know it doesn't matter if you are",
    "start": "496270",
    "end": "501660"
  },
  {
    "text": "doesn't matter which tools you're using the process is largely the same you're gonna build something you're gonna",
    "start": "501660",
    "end": "507370"
  },
  {
    "text": "package it somehow you're gonna test it deploy it scan it so that's really",
    "start": "507370",
    "end": "513090"
  },
  {
    "text": "really the revelation that we came to it was what if we could create pipelines in a tool agnostic templated way to take",
    "start": "513090",
    "end": "520690"
  },
  {
    "text": "pipeline development from what you see on the screen so something that looks a little bit more like this where you have",
    "start": "520690",
    "end": "526840"
  },
  {
    "start": "524000",
    "end": "654000"
  },
  {
    "text": "a centralized DevOps team that's supporting multiple applications they",
    "start": "526840",
    "end": "532120"
  },
  {
    "text": "maintain a tool agnostic templated workflow that outlines the business approved software delivery",
    "start": "532120",
    "end": "539350"
  },
  {
    "text": "processes you know this makes it really convenient when working with security teams making sure that the requirements",
    "start": "539350",
    "end": "546160"
  },
  {
    "text": "are represented because they can be stakeholders and coming up with this pipeline template that team would likely",
    "start": "546160",
    "end": "552520"
  },
  {
    "text": "consist of all of the different stakeholders that go into your software delivery processes so that includes like",
    "start": "552520",
    "end": "557950"
  },
  {
    "text": "CEQA engineers DevOps engineers that know how to write pipelines QA engineers",
    "start": "557950",
    "end": "563710"
  },
  {
    "text": "that can speak to test automation so what if we had a centralized team that",
    "start": "563710",
    "end": "569620"
  },
  {
    "text": "could define this tool agnostic template so let's say you wanted to build scan deploy and test the different tools that",
    "start": "569620",
    "end": "576670"
  },
  {
    "text": "are gonna perform these actions of building scanning deploying testing can",
    "start": "576670",
    "end": "582400"
  },
  {
    "text": "just be modularized into a different pipeline library we call it so if I wanted to do a scan with static code",
    "start": "582400",
    "end": "590020"
  },
  {
    "text": "analysis tatak code analysis as a scan with sonar cube there'd be a Sun or tube library that introduces a static code",
    "start": "590020",
    "end": "596110"
  },
  {
    "text": "analysis step to my pipeline and there'd be a fortify library that introduces the static code analysis step to my pipeline",
    "start": "596110",
    "end": "601720"
  },
  {
    "text": "so alongside your pipeline template you get a pipeline configuration which just",
    "start": "601720",
    "end": "606760"
  },
  {
    "text": "tells jenkins or the pipeline what tools am i using to actually build this dedsec",
    "start": "606760",
    "end": "612790"
  },
  {
    "text": "ops pipeline there's some organizational governance there so if at the top level you have some tools that you want to",
    "start": "612790",
    "end": "619330"
  },
  {
    "text": "enforce everybody is using you can consolidate those common controls to a centralized repository but still give",
    "start": "619330",
    "end": "625540"
  },
  {
    "text": "development teams the flexibility they need to customize the pipeline to introduce different tools right so that",
    "start": "625540",
    "end": "631840"
  },
  {
    "text": "that centralized pipeline definition of build scan deploying tests can turn into",
    "start": "631840",
    "end": "637150"
  },
  {
    "text": "what you see at the bottom of the screen which is building with maven scanning with fortify deploying with ansible and",
    "start": "637150",
    "end": "643420"
  },
  {
    "text": "testing with selenium or it can mean building a docker image or container image scanning it was shown r-cube",
    "start": "643420",
    "end": "649780"
  },
  {
    "text": "deploying it with helm and testing an api with something like rest assured so",
    "start": "649780",
    "end": "655300"
  },
  {
    "start": "654000",
    "end": "972000"
  },
  {
    "text": "let's see what this looks like in practice if I head over to my Jenkins",
    "start": "655300",
    "end": "661420"
  },
  {
    "text": "instance so let's take a look at there's a couple different use cases here we're",
    "start": "661420",
    "end": "666910"
  },
  {
    "text": "going to show this simplest first we perform liquor make the FOB finger I will do that thank you Michael",
    "start": "666910",
    "end": "672449"
  },
  {
    "text": "can everyone see okay seeing general nods of agreement yes so",
    "start": "672449",
    "end": "678639"
  },
  {
    "text": "this is a pipeline job in Jenkins we wrote a Jenkins plugin called the",
    "start": "678639",
    "end": "685509"
  },
  {
    "text": "Jenkins templating engine which achieves a lot of what I'm talking about the ability to take that Jenkins file that",
    "start": "685509",
    "end": "691269"
  },
  {
    "text": "application-specific out of individualized source code repositories define it in a central place and allow",
    "start": "691269",
    "end": "698679"
  },
  {
    "text": "teams to pull in their unique configurations so what you see on the screen is an example of a simple",
    "start": "698679",
    "end": "706629"
  },
  {
    "text": "pipeline template they can get a lot more complex if you want to map your your pipeline to your branching strategy",
    "start": "706629",
    "end": "712600"
  },
  {
    "text": "so when you do merges to the develop branch it does something different than merges to the master branch but for the",
    "start": "712600",
    "end": "718600"
  },
  {
    "text": "sake of demonstration let's assume you've got a linear pipeline that's going to do build some static code",
    "start": "718600",
    "end": "723790"
  },
  {
    "text": "analysis and it's going to deploy to a dev and prod environment alongside that pipeline template you get a pipeline",
    "start": "723790",
    "end": "730179"
  },
  {
    "text": "configuration file so this is going to implement that pipeline template if you",
    "start": "730179",
    "end": "735759"
  },
  {
    "text": "will so there's a library section that's going to pull in the specific tools that you're using to implement the pipeline",
    "start": "735759",
    "end": "743139"
  },
  {
    "text": "so in our case these libraries are going to do print statements just because we want to really demonstrate and you know",
    "start": "743139",
    "end": "749769"
  },
  {
    "text": "communicate what pipeline template looks like so they're gonna do some print statements to say which library",
    "start": "749769",
    "end": "754809"
  },
  {
    "text": "contributed which step alongside your libraries you can dynamically define application environments every one every",
    "start": "754809",
    "end": "763119"
  },
  {
    "text": "project I've ever worked on has a different number of application environments they give them unique names I've been on a project where dev was",
    "start": "763119",
    "end": "769929"
  },
  {
    "text": "called squirtle I don't know why but from your configuration file you can",
    "start": "769929",
    "end": "775959"
  },
  {
    "text": "dynamically define these app environments and store whatever environmental context you need to know",
    "start": "775959",
    "end": "781389"
  },
  {
    "text": "in order to perform deployments to those specific environments so if I apply this configuration zoom out for a second and",
    "start": "781389",
    "end": "791100"
  },
  {
    "text": "click build I'll look at a finished one so we don't the wait for it to load but",
    "start": "791100",
    "end": "796990"
  },
  {
    "text": "what we're going to notice is that at the beginning of the pipeline jte Jenkinson playing engine for short is",
    "start": "796990",
    "end": "803230"
  },
  {
    "text": "going to initialize the pipeline so we're gonna go pull in all the different libraries that implement these steps",
    "start": "803230",
    "end": "808630"
  },
  {
    "text": "these libraries are just modularized tool integrations so they're stored in a",
    "start": "808630",
    "end": "814060"
  },
  {
    "text": "source code repository they're just directories in your repo so for example",
    "start": "814060",
    "end": "819910"
  },
  {
    "text": "we loaded the maven library there's a build act ruby step that turns into the build step when you load it in your in",
    "start": "819910",
    "end": "826330"
  },
  {
    "text": "your pipeline so if we take a look at this build step it's just Jenkins pipeline is code so the framework",
    "start": "826330",
    "end": "832240"
  },
  {
    "text": "introduced is some syntactic sugar to make it easier to write libraries and access configuration from your config",
    "start": "832240",
    "end": "838210"
  },
  {
    "text": "file but jte is really just a different way of organizing your pipeline code to",
    "start": "838210",
    "end": "843370"
  },
  {
    "text": "achieve this pipeline templating and reuse so if we go back over to Jenkins we loaded all the requisite libraries",
    "start": "843370",
    "end": "850420"
  },
  {
    "text": "that we talked about the stage view will probably give us a easier to parse representation where we say that we did",
    "start": "850420",
    "end": "857620"
  },
  {
    "text": "a build with maven we did sonar cube static code analysis and then we deployed to a dev in production environment so in practice you're not",
    "start": "857620",
    "end": "865240"
  },
  {
    "text": "gonna want to put that information in your Jenkins UI you're gonna store it in your repository most likely so this is a",
    "start": "865240",
    "end": "871900"
  },
  {
    "text": "multi branch project which means it's going to automatically create jobs for every branch and pull request in your",
    "start": "871900",
    "end": "877630"
  },
  {
    "text": "pipeline here the Jenkins file has been pulled out of the repository we can",
    "start": "877630",
    "end": "884470"
  },
  {
    "text": "store it right alongside our libraries or in a separate repo doesn't doesn't matter we can define that pipeline",
    "start": "884470",
    "end": "890890"
  },
  {
    "text": "template externally alongside a pipeline configuration that just says this is",
    "start": "890890",
    "end": "897100"
  },
  {
    "text": "what's required by the organization we have this nice key that says merge equals true which is going to allow the",
    "start": "897100",
    "end": "902830"
  },
  {
    "text": "application to just add in the maven library and when we build it every",
    "start": "902830",
    "end": "908740"
  },
  {
    "text": "branch of this pull request of this repository excuse me is going to do the exact same thing so now the real power",
    "start": "908740",
    "end": "914530"
  },
  {
    "text": "comes when we want to scale this up to multiple applications so the idea is the",
    "start": "914530",
    "end": "919810"
  },
  {
    "text": "same what if I had a Gradle application instead of a maven application all I would want to change is the",
    "start": "919810",
    "end": "925660"
  },
  {
    "text": "implementation of my build step for this example so the the maven application",
    "start": "925660",
    "end": "932350"
  },
  {
    "text": "would have a pipeline configuration file that that it's pulling in the Maven library we can take a look at this repo all it",
    "start": "932350",
    "end": "940310"
  },
  {
    "text": "says is hey I'm using maven we can go take a look at the Gradle repository and they just say that they're using Gradle",
    "start": "940310",
    "end": "946339"
  },
  {
    "text": "but if we go look at Jenkins when you look at the Gradle application the",
    "start": "946339",
    "end": "951699"
  },
  {
    "text": "pipeline pulled in the Gradle library so we had a Gradle implementation of our build step we can go over and take a",
    "start": "951699",
    "end": "957980"
  },
  {
    "text": "look at the maven library and see that it's the same for its using maven right",
    "start": "957980",
    "end": "963379"
  },
  {
    "text": "so what's the big picture here if we go back to our slides so what are the main",
    "start": "963379",
    "end": "974029"
  },
  {
    "start": "972000",
    "end": "1061000"
  },
  {
    "text": "benefits of this organizational governance you don't have to copy and paste Jenkins files anymore you don't",
    "start": "974029",
    "end": "980120"
  },
  {
    "text": "all have to figure out how to do static code analysis with Soner cube by googling it and copying and pasting it",
    "start": "980120",
    "end": "985279"
  },
  {
    "text": "so organizational governance centralize your pipeline definition to a common place and define processes that are",
    "start": "985279",
    "end": "992509"
  },
  {
    "text": "approved by your security teams regardless of specific tool implementations across your entire",
    "start": "992509",
    "end": "997819"
  },
  {
    "text": "organization optimizing pipeline code reuse so these libraries are reusable and",
    "start": "997819",
    "end": "1003040"
  },
  {
    "text": "open-source at Booz Allen we've seen pipeline development decreased by 97% for new projects if you're using",
    "start": "1003040",
    "end": "1009309"
  },
  {
    "text": "existing tool integrations because the works already been done I we can reuse these libraries across all the pipelines",
    "start": "1009309",
    "end": "1016029"
  },
  {
    "text": "that we're developing to drastically speed up pipeline development from something like four to six months to",
    "start": "1016029",
    "end": "1022089"
  },
  {
    "text": "four to six days if you're following a happy path and then simplifying pipeline maintainability in my humble opinion",
    "start": "1022089",
    "end": "1028480"
  },
  {
    "text": "it's a lot easier to manage a centralized pipeline template with modular eyes tool integrations than it",
    "start": "1028480",
    "end": "1034360"
  },
  {
    "text": "is to keep straight copied and pasted sixty different versions of a pipeline as code artifact and handle migrations",
    "start": "1034360",
    "end": "1041438"
  },
  {
    "text": "of improving that over time so applying that to security this means that you can",
    "start": "1041439",
    "end": "1048069"
  },
  {
    "text": "now standardize your software delivery processes to do things like container image scanning application dependency",
    "start": "1048069",
    "end": "1053200"
  },
  {
    "text": "scanning and you can still give teams the flexibility they need to while having the assurance that they're all",
    "start": "1053200",
    "end": "1058570"
  },
  {
    "text": "going to follow the same process so we can make that even better and Michael is",
    "start": "1058570",
    "end": "1064510"
  },
  {
    "start": "1061000",
    "end": "1146000"
  },
  {
    "text": "gonna talk to us about how we can add some defense-in-depth so we've made sure that our applications are secured by",
    "start": "1064510",
    "end": "1070669"
  },
  {
    "text": "implementing the security testing how do we still make sure that we're safe in production Thank You Steven so if we",
    "start": "1070669",
    "end": "1079009"
  },
  {
    "text": "think about this pipeline the one thing that you want to do when you start looking at your pipelines in this way is",
    "start": "1079009",
    "end": "1084169"
  },
  {
    "text": "that starting to remove areas of waste and areas of waste tend to be areas where you spend a lot",
    "start": "1084169",
    "end": "1091009"
  },
  {
    "text": "of time right so the pipeline definition that he showed here is actually really",
    "start": "1091009",
    "end": "1096080"
  },
  {
    "text": "really useful exercise to do to actually draw out and put times on each one of those areas because then it starts",
    "start": "1096080",
    "end": "1102259"
  },
  {
    "text": "helping you understand where you need to optimize but also when you look at the entire lifecycle like this we were like",
    "start": "1102259",
    "end": "1108769"
  },
  {
    "text": "how can we reduce this time to where we actually detect the exploitation or",
    "start": "1108769",
    "end": "1114740"
  },
  {
    "text": "discover the exploitation exploitation a vulnerability has been discovered and then we've been hacked or we have to go",
    "start": "1114740",
    "end": "1120740"
  },
  {
    "text": "through this entire cycle again to actually go and actually patch our applications and the challenges is with",
    "start": "1120740",
    "end": "1127039"
  },
  {
    "text": "containers and ephemeral workloads so we did a study at Cystic recently and containers are lasting on average about",
    "start": "1127039",
    "end": "1134179"
  },
  {
    "text": "five minutes and so in a container that only lasts five minutes how can you",
    "start": "1134179",
    "end": "1139669"
  },
  {
    "text": "actually discover that it was breached someone was able to able to do data exfiltration and other things like that",
    "start": "1139669",
    "end": "1144799"
  },
  {
    "text": "as well so with that we'll introduce Falco and so what is Falco so it's a",
    "start": "1144799",
    "end": "1150590"
  },
  {
    "start": "1146000",
    "end": "1198000"
  },
  {
    "text": "behavioral Activity Monitor it detects suspicious activity defined by a set of rules in non-marketing speak you can",
    "start": "1150590",
    "end": "1157399"
  },
  {
    "text": "call it a host intrusion detection system but what makes us unique is that were focused on container and",
    "start": "1157399",
    "end": "1163730"
  },
  {
    "text": "Orchestrator support so we have native integrations into docker cryo container",
    "start": "1163730",
    "end": "1168769"
  },
  {
    "text": "d kubernetes it's actually pull back the metadata information from the from those",
    "start": "1168769",
    "end": "1174080"
  },
  {
    "text": "sources combine that with what we're actually seeing on a system call level and in the kubernetes audit event log",
    "start": "1174080",
    "end": "1179720"
  },
  {
    "text": "level and using that to actually create very very rich and granular rules and",
    "start": "1179720",
    "end": "1185629"
  },
  {
    "text": "when we detect something that's abnormal will alert via various methods and it's",
    "start": "1185629",
    "end": "1191299"
  },
  {
    "text": "open source so we're a CNC F sandbox project you can contribute improvements to the project or rules as well speaking",
    "start": "1191299",
    "end": "1199129"
  },
  {
    "start": "1198000",
    "end": "1226000"
  },
  {
    "text": "of that we're also going up for incubation as well and we have incue bation proposal up so hopefully",
    "start": "1199129",
    "end": "1204800"
  },
  {
    "text": "within the next month or so once everyone gets past coop con and thanksgiving will be moving into",
    "start": "1204800",
    "end": "1210740"
  },
  {
    "text": "incubation which means the CNC F will be supporting us even more with infrastructure and other things like",
    "start": "1210740",
    "end": "1216620"
  },
  {
    "text": "that as well so it's an exciting time for the project and if you're wanting to contribute to a project I highly",
    "start": "1216620",
    "end": "1222080"
  },
  {
    "text": "encourage you either look at Falco or jte as well so why does anomaly",
    "start": "1222080",
    "end": "1228680"
  },
  {
    "text": "detection get easier in a containerized world and I think it gets easier because we have this abstraction and we can use",
    "start": "1228680",
    "end": "1234770"
  },
  {
    "text": "this abstraction of a container or a pod or a namespace or a definition of",
    "start": "1234770",
    "end": "1240350"
  },
  {
    "text": "basically what we think should be going on in that abstraction so since",
    "start": "1240350",
    "end": "1245390"
  },
  {
    "text": "containers are supposed to be one process for container and it's an isolated process the processes as I say",
    "start": "1245390",
    "end": "1251540"
  },
  {
    "text": "are scoped as to what's expected so you know what processes are going to run you know what files they're going to",
    "start": "1251540",
    "end": "1256580"
  },
  {
    "text": "manipulate you know what directories are going to touch you know what ports they're gonna listen on and inside of the container it should be very very",
    "start": "1256580",
    "end": "1263060"
  },
  {
    "text": "easy to define all of the activity from a system call level that's going to take place when you deploy it the challenges",
    "start": "1263060",
    "end": "1270290"
  },
  {
    "text": "is that containers are immutable so the container image itself if you change something if you change the",
    "start": "1270290",
    "end": "1276140"
  },
  {
    "text": "configuration and rebuild the container the SHA changes so it's a new container however when the container launches that",
    "start": "1276140",
    "end": "1283040"
  },
  {
    "text": "that environment can still be manipulated very few people run containers in a read-only root",
    "start": "1283040",
    "end": "1288500"
  },
  {
    "text": "filesystem mode and so if somebody actually breaches the container they can start to actually add in things so they",
    "start": "1288500",
    "end": "1294530"
  },
  {
    "text": "can do an app get upgrade they can do an app get install and starting to add in the tools that they need to actually go",
    "start": "1294530",
    "end": "1300350"
  },
  {
    "text": "and do data exfiltration or explore your environment and move laterally or horizontally and so how do you in this",
    "start": "1300350",
    "end": "1306560"
  },
  {
    "text": "environment can you detect abnormal behavior in these containers that are very very short-lived so you do that",
    "start": "1306560",
    "end": "1313280"
  },
  {
    "start": "1312000",
    "end": "1353000"
  },
  {
    "text": "with Falco's so let me talk about the architecture real quick what we do is we take different pieces of information and",
    "start": "1313280",
    "end": "1320000"
  },
  {
    "text": "we run them through the Falco rules engine so we can tap into system calls using either a kernel module which is",
    "start": "1320000",
    "end": "1325520"
  },
  {
    "text": "our kind of our legacy way of doing things and then our next generation way of doing things is EBP F we're actually",
    "start": "1325520",
    "end": "1332030"
  },
  {
    "text": "giving away books Linux observability with VPS at the Cystic booth the author of the",
    "start": "1332030",
    "end": "1338360"
  },
  {
    "text": "book is giving those away so EPF is an area that we do a lot of work in and a lot of study in as well",
    "start": "1338360",
    "end": "1344870"
  },
  {
    "text": "and then we can also take things like kubernetes audit events and then kubernetes metadata combine them",
    "start": "1344870",
    "end": "1350540"
  },
  {
    "text": "together into our rules engine and then push out alerts and I'm going to talk about the BPF instrumentation real quick",
    "start": "1350540",
    "end": "1356390"
  },
  {
    "start": "1353000",
    "end": "1402000"
  },
  {
    "text": "so the way that this works is essentially you deploy you can either deploy Falco directly on your kubernetes",
    "start": "1356390",
    "end": "1362150"
  },
  {
    "text": "nodes or your hosts it doesn't need to be running kubernetes we can work on a standard Linux system as well so you can",
    "start": "1362150",
    "end": "1367370"
  },
  {
    "text": "use this as a generic host intrusion detection system if you want in a kubernetes cluster what you typically",
    "start": "1367370",
    "end": "1373130"
  },
  {
    "text": "did do is deploy us as a daemon set the EBP up program gets installed on that nodes kernel and that allows us to get",
    "start": "1373130",
    "end": "1380120"
  },
  {
    "text": "an event stream of all the system calls that are taking place and going through the system so because it's a shared",
    "start": "1380120",
    "end": "1385400"
  },
  {
    "text": "kernel and we've installed our instrumentation in the kernel we can then see everything that's happening inside of your containerized workloads",
    "start": "1385400",
    "end": "1391940"
  },
  {
    "text": "so we can see what files are opened up what network connections are opened up what processes are spawned what",
    "start": "1391940",
    "end": "1397610"
  },
  {
    "text": "processes are doing what system calls they're calling and so forth to give you",
    "start": "1397610",
    "end": "1403250"
  },
  {
    "start": "1402000",
    "end": "1449000"
  },
  {
    "text": "a little bit broader a example of the architecture we'll also pull in urban",
    "start": "1403250",
    "end": "1408410"
  },
  {
    "text": "eddies audit logs which I'll talk about here in a second and then we have a whole bunch of different destinations that we can actually send out alerts to",
    "start": "1408410",
    "end": "1415580"
  },
  {
    "text": "one of the things that we're focusing on if you're an expert in the space or if it's interests you and you want to find",
    "start": "1415580",
    "end": "1420890"
  },
  {
    "text": "a project to work on is we're really building out this output API and our output interface we're gonna base",
    "start": "1420890",
    "end": "1426770"
  },
  {
    "text": "everything on G RPC and then like you see with the the Falco client go and",
    "start": "1426770",
    "end": "1431870"
  },
  {
    "text": "Prometheus we're gonna be expanding out the the outputs that we can do via this G RPC connection it's a asynchronous",
    "start": "1431870",
    "end": "1439640"
  },
  {
    "text": "non-blocking connection and so that streaming server will help us do a lot of different workloads of what we can",
    "start": "1439640",
    "end": "1445550"
  },
  {
    "text": "actually do with the events which I'll talk about here towards the end so let's look at the rules and how the rules look",
    "start": "1445550",
    "end": "1451330"
  },
  {
    "start": "1449000",
    "end": "1549000"
  },
  {
    "text": "so that we can understand them so apologies to those on that side of the",
    "start": "1451330",
    "end": "1457370"
  },
  {
    "text": "room I promise to walk over here next time I can point all right thank you so",
    "start": "1457370",
    "end": "1463150"
  },
  {
    "text": "the we have a couple constructs in our rules so we have macros lists",
    "start": "1463150",
    "end": "1468440"
  },
  {
    "text": "and rules so enlist is essentially just an array we can see that we've named it benders and then we have the items in",
    "start": "1468440",
    "end": "1474980"
  },
  {
    "text": "the array it can just be one item or one element if you want and then you can see here we have a macro and a macro is",
    "start": "1474980",
    "end": "1481340"
  },
  {
    "text": "essentially a shortcut for a rule condition so it just makes it easier to write something over and over and over",
    "start": "1481340",
    "end": "1487160"
  },
  {
    "text": "again the Falco default rule set provides lots of macros for you so if you wanted to catch an outbound",
    "start": "1487160",
    "end": "1493280"
  },
  {
    "text": "connection all you need to do is write outbound and that macro is available to you and it will detect all outbound",
    "start": "1493280",
    "end": "1499460"
  },
  {
    "text": "connections automatically so here we're gonna say our directory is in vendors so",
    "start": "1499460",
    "end": "1505550"
  },
  {
    "text": "basically our directory that's set in the system call information is one of these four and so what's nice here is",
    "start": "1505550",
    "end": "1512270"
  },
  {
    "text": "what I decide to start storing binaries and opt your company name or your application name been all I need to do",
    "start": "1512270",
    "end": "1519110"
  },
  {
    "text": "is go and update the list and I don't need to update my macro or my rule and then we can see the rule here we have",
    "start": "1519110",
    "end": "1524720"
  },
  {
    "text": "I'm a bender and event direction is the system calls returned that's kind of not",
    "start": "1524720",
    "end": "1531920"
  },
  {
    "text": "important so we'll just skip it I've opened something for writing in this directory and I'm not a package",
    "start": "1531920",
    "end": "1537560"
  },
  {
    "text": "management process what will happen is this Falco will alert you'll get the username you'll get the command and the",
    "start": "1537560",
    "end": "1543110"
  },
  {
    "text": "file name of what was actually being manipulated underneath that directory makes sense so there's a whole bunch of",
    "start": "1543110",
    "end": "1550790"
  },
  {
    "start": "1549000",
    "end": "1580000"
  },
  {
    "text": "different metadata or different what we call field classes that you can pull in so we have things like the kubernetes",
    "start": "1550790",
    "end": "1558710"
  },
  {
    "text": "metadata information here container metadata information as well and so you",
    "start": "1558710",
    "end": "1565310"
  },
  {
    "text": "can use all of this information to say I'm a namespace or I'm running in this particular namespace I'm a particular",
    "start": "1565310",
    "end": "1570590"
  },
  {
    "text": "pod with these particular labels apply this rule only to me depending upon maybe I'm running in a namespace that",
    "start": "1570590",
    "end": "1576860"
  },
  {
    "text": "has particular compliance requirements for PCI or something like that so here's",
    "start": "1576860",
    "end": "1582200"
  },
  {
    "start": "1580000",
    "end": "1641000"
  },
  {
    "text": "another rule to give you an example of incorporating that metadata information so don't run this in production because",
    "start": "1582200",
    "end": "1589010"
  },
  {
    "text": "you'll get a lot of false positives but it's good for an example so I've spawned a process with using the exec de system",
    "start": "1589010",
    "end": "1596330"
  },
  {
    "text": "call and then my container image starts with node and my proc name does",
    "start": "1596330",
    "end": "1601610"
  },
  {
    "text": "equal node so basically anytime that a container runs a process other than the node application we'll get an alert that",
    "start": "1601610",
    "end": "1609230"
  },
  {
    "text": "the container is doing something abnormal we have a bunch of different rule sets if you go to security hub dev",
    "start": "1609230",
    "end": "1616250"
  },
  {
    "text": "I don't have a slide on this so this is the only time I'm gonna say its security hub dev you can see a whole bunch of",
    "start": "1616250",
    "end": "1622700"
  },
  {
    "text": "different Falco rules that you can download for common applications and one of the things that we're working on one",
    "start": "1622700",
    "end": "1628400"
  },
  {
    "text": "of our team members chris nova is working on is falco CTL - where you can automatically go and do falco CTO rule",
    "start": "1628400",
    "end": "1635090"
  },
  {
    "text": "install and you'll be able to download those rules directly from security hub so another area that we're looking for",
    "start": "1635090",
    "end": "1640250"
  },
  {
    "text": "contributions and hope on now we can also look at kubernetes audit of audit events as well and so kubernetes audit",
    "start": "1640250",
    "end": "1647419"
  },
  {
    "start": "1641000",
    "end": "1763000"
  },
  {
    "text": "logging is something that came out in kubernetes 111 it's getting more and more mature and what you can do is",
    "start": "1647419",
    "end": "1654230"
  },
  {
    "text": "basically get a chronological record of every single change that goes through the API server so any time that someone",
    "start": "1654230",
    "end": "1660380"
  },
  {
    "text": "hits the API server you'll get four different options that you can choose of whether if that request just came in or",
    "start": "1660380",
    "end": "1667040"
  },
  {
    "text": "whether if it was actually completed and successful and that's controlled with what's called audit policy and then once",
    "start": "1667040",
    "end": "1673700"
  },
  {
    "text": "you have this audit policy you can then take that and ship that off to some other location to do processing on it what we'll do is we'll actually apply",
    "start": "1673700",
    "end": "1680630"
  },
  {
    "text": "the Falco rule set to this information and the different ways that you can configure this is log files web hooks",
    "start": "1680630",
    "end": "1687500"
  },
  {
    "text": "these two methods aren't available if you're using something like GK or a KS or a managed kubernetes service where",
    "start": "1687500",
    "end": "1693620"
  },
  {
    "text": "you don't have access to the master this has changed on the master so what the kubernetes community did is they created",
    "start": "1693620",
    "end": "1699320"
  },
  {
    "text": "something called audit syncs where you can actually dynamically control this by putting a JSON document up into the",
    "start": "1699320",
    "end": "1705799"
  },
  {
    "text": "career day's API server so here's what an audit event looks like and in this",
    "start": "1705799",
    "end": "1711559"
  },
  {
    "text": "audit event you can see that the response was complete we deleted the",
    "start": "1711559",
    "end": "1717710"
  },
  {
    "text": "mini cube user deleted the namespace foo and then we get an ID for that as well",
    "start": "1717710",
    "end": "1723919"
  },
  {
    "text": "and we can see that the authorization service allowed this request so we",
    "start": "1723919",
    "end": "1729200"
  },
  {
    "text": "extended the kübra our we extended the Falco language to include all of these different",
    "start": "1729200",
    "end": "1734490"
  },
  {
    "text": "the other interesting thing is is that if kubernetes ever changes what this JSON document looks like will still take",
    "start": "1734490",
    "end": "1740070"
  },
  {
    "text": "it and parse it and we can actually pull any value out by just calling j event value and the json pointer this also",
    "start": "1740070",
    "end": "1747780"
  },
  {
    "text": "allows us to implement new input sources as well so after we get done with the",
    "start": "1747780",
    "end": "1752850"
  },
  {
    "text": "outputs api we're gonna be working on the input api to allow you to have more",
    "start": "1752850",
    "end": "1758100"
  },
  {
    "text": "sources where you can actually write these rules and extend the Falco language for detecting things so here's",
    "start": "1758100",
    "end": "1763860"
  },
  {
    "start": "1763000",
    "end": "1846000"
  },
  {
    "text": "what a kubernetes audit rule looks like and then I'll jump into the demo and then we can wrap up so we have a macro",
    "start": "1763860",
    "end": "1771270"
  },
  {
    "text": "here that says contains private credentials we can see we have the AWS access key so we're just looking for",
    "start": "1771270",
    "end": "1776520"
  },
  {
    "text": "these strings and while this is this is not gonna stop state-level actors right",
    "start": "1776520",
    "end": "1781860"
  },
  {
    "text": "but normally your breaches and things like that happen because Bob in accounting you know made an s3 bucket",
    "start": "1781860",
    "end": "1788280"
  },
  {
    "text": "public or Bob and accounting went and no offense to Bob he's just trying to do",
    "start": "1788280",
    "end": "1793830"
  },
  {
    "text": "his job but went and posted things and a github repository they were not supposed to or unencrypted secrets and other",
    "start": "1793830",
    "end": "1800340"
  },
  {
    "text": "things like that right so we now have a macro called the config Maps okay a target resource config Maps meaning that",
    "start": "1800340",
    "end": "1807570"
  },
  {
    "text": "we're can dip you lating the config map through the API we're doing a create update or patch so any one of these",
    "start": "1807570",
    "end": "1814200"
  },
  {
    "text": "actions and then we have the rule itself so I'm a config map somebody tried to modify me and we contain private",
    "start": "1814200",
    "end": "1820860"
  },
  {
    "text": "credentials so what will happen is is we'll get the alert that a config map was created with private credentials",
    "start": "1820860",
    "end": "1827070"
  },
  {
    "text": "we'll get who did it the other interesting thing is is we'll also get the entire configured in there",
    "start": "1827070",
    "end": "1836580"
  },
  {
    "text": "we've now leaked your secret and unis we're forcing you to rotate it we should probably awfully scape that",
    "start": "1836580",
    "end": "1843510"
  },
  {
    "text": "that's another area of opportunity if somebody wants to contribute alright so I'm going to talk about installing real",
    "start": "1843510",
    "end": "1848550"
  },
  {
    "start": "1846000",
    "end": "1869000"
  },
  {
    "text": "quick in the kubernetes world we can install via helm we also have Linux packages as well helm is one of the",
    "start": "1848550",
    "end": "1858300"
  },
  {
    "text": "preferred ways lots of configuration options and then we're also working on Falco CTL install as well that will",
    "start": "1858300",
    "end": "1864750"
  },
  {
    "text": "install a coup falco into your kubernetes cluster as well so let's talk about how we use",
    "start": "1864750",
    "end": "1871100"
  },
  {
    "start": "1869000",
    "end": "1910000"
  },
  {
    "text": "Falco and I'll demo this real quick so we wrote something called the kubernetes response engine with security playbooks",
    "start": "1871100",
    "end": "1877130"
  },
  {
    "text": "what it does is it allows you to react to these events so we have a number of",
    "start": "1877130",
    "end": "1882320"
  },
  {
    "text": "different play books you can kill within an offending pod you can taint nodes to prevent scheduling you can isolate a pod",
    "start": "1882320",
    "end": "1890030"
  },
  {
    "text": "with networking policy and so forth so that then when this container goes rogue you can keep it around but isolate it",
    "start": "1890030",
    "end": "1896270"
  },
  {
    "text": "and then go in and do forensics on it as well you can subscribe to different",
    "start": "1896270",
    "end": "1901550"
  },
  {
    "text": "level of alerts you can subscribe to individual alerts and so what this allows you to do is you can have",
    "start": "1901550",
    "end": "1906980"
  },
  {
    "text": "different actions that take place depending upon the alert and severity so what this looks like is is that we",
    "start": "1906980",
    "end": "1913550"
  },
  {
    "text": "publish into Nats and then from Nats boobless picks it up and runs a small function and then we'll take action on",
    "start": "1913550",
    "end": "1919490"
  },
  {
    "text": "the particular function or on the particular finding container we have the same thing for AWS we have the same",
    "start": "1919490",
    "end": "1926480"
  },
  {
    "text": "thing for GC P as well so this is another area to contribute we're written in C++ and then we're",
    "start": "1926480",
    "end": "1933440"
  },
  {
    "text": "starting to write more stuff and go and so if you're not comfortable with C++ we have a lot of gamal that you can write",
    "start": "1933440",
    "end": "1940690"
  },
  {
    "text": "and a way to contribute to the project so let me go to this slide real quick",
    "start": "1941110",
    "end": "1946540"
  },
  {
    "start": "1943000",
    "end": "2046000"
  },
  {
    "text": "and then I'm gonna jump into the demo so oh wow it's data up so just do a git",
    "start": "1946540",
    "end": "1957290"
  },
  {
    "text": "pods and you can see that Falco is running here and I can do a coop CTL logs Falco and I can see that there's",
    "start": "1957290",
    "end": "1969920"
  },
  {
    "text": "been some events that have happened we can see that a terminal respond in a container ignore this because I don't",
    "start": "1969920",
    "end": "1976370"
  },
  {
    "text": "have this tuned for this particular machine you can see that the bash history was deleted and other information like that as well you notice",
    "start": "1976370",
    "end": "1983300"
  },
  {
    "text": "that this is in JSON so it's programmatic so you're able to parse it and send it into another system so what",
    "start": "1983300",
    "end": "1988460"
  },
  {
    "text": "I'm going to do here is let me just do a coop CTO get pods again",
    "start": "1988460",
    "end": "1994620"
  },
  {
    "text": "and you can see that I have this nginx deployment there so I'm just gonna do a",
    "start": "1994620",
    "end": "2000080"
  },
  {
    "text": "coup CTL exec there we go",
    "start": "2000080",
    "end": "2007610"
  },
  {
    "text": "and my deployment name is wrong and I'm",
    "start": "2007610",
    "end": "2016100"
  },
  {
    "text": "just gonna get in this container to start manipulating it and changing things and doing stuff with it and I",
    "start": "2016100",
    "end": "2022970"
  },
  {
    "text": "can't and the reason why I can't is because what's happened is is immediately within a matter of",
    "start": "2022970",
    "end": "2029270"
  },
  {
    "text": "milliseconds that function was triggered and it kicked me off of the container and it didn't not only did it kick me",
    "start": "2029270",
    "end": "2035539"
  },
  {
    "text": "off the container it actually deleted the container and you can see that that containers went away and a new one's",
    "start": "2035539",
    "end": "2041059"
  },
  {
    "text": "been been deployed so this is what you can do with Falco and we really think",
    "start": "2041059",
    "end": "2046220"
  },
  {
    "start": "2046000",
    "end": "2109000"
  },
  {
    "text": "that it's important that you need to look at this entire was you're looking at your stub ops dub suck ops security",
    "start": "2046220",
    "end": "2051830"
  },
  {
    "text": "posture looking at this entire workflow looking at your dub suck Ops pipeline and templating it and making sure that",
    "start": "2051830",
    "end": "2057830"
  },
  {
    "text": "you're putting all the layers in place but then also it's important to actually watch what's happening in production so",
    "start": "2057830",
    "end": "2063200"
  },
  {
    "text": "that you can then because everything that happens in production all of this has to feed back into your development",
    "start": "2063200",
    "end": "2069169"
  },
  {
    "text": "cycle so the reason why that yellow line ends up continuing on is because whatever you discover and whatever",
    "start": "2069169",
    "end": "2076010"
  },
  {
    "text": "malicious activity you might discover then goes into patching something in your environment and working through",
    "start": "2076010",
    "end": "2081349"
  },
  {
    "text": "that dub psych ops lifecycle so if you have the jenkins templating engine if you're able to actually more easily go",
    "start": "2081349",
    "end": "2088790"
  },
  {
    "text": "and incorporate those changes in and those feedback loops in the faster that you can move overall in your pipelines",
    "start": "2088790",
    "end": "2094070"
  },
  {
    "text": "so with that thank you very much these are QR codes to our documentation if you",
    "start": "2094070",
    "end": "2099500"
  },
  {
    "text": "have questions we'll take questions offline because we're right on time but Stephen and I will be around but",
    "start": "2099500",
    "end": "2104990"
  },
  {
    "text": "thank you all for attending [Applause]",
    "start": "2104990",
    "end": "2111749"
  }
]
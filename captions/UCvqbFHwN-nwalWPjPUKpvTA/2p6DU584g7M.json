[
  {
    "start": "0",
    "end": "91000"
  },
  {
    "text": "is CN CF webinar applications snapshots using consistency groups on Jorge Castro",
    "start": "0",
    "end": "5700"
  },
  {
    "text": "Community Manager VMware and a cloud native ambassador I'll be moderating today's webinar we would like to welcome",
    "start": "5700",
    "end": "11429"
  },
  {
    "text": "our guest presenter today Ravi a Lubo ena senior architect at Robin dot IO a",
    "start": "11429",
    "end": "17430"
  },
  {
    "text": "few housekeeping items before we get started during the webinar you're not able to talk as an attendee there's a",
    "start": "17430",
    "end": "23430"
  },
  {
    "text": "Q&A box at the bottom of your screen and the zoom UI please feel free to drop your questions in there and we'll get to",
    "start": "23430",
    "end": "29609"
  },
  {
    "text": "as many as we can at the end of the webinar this is an official webinar of the CN CF and I such a subject to the CN CF code",
    "start": "29609",
    "end": "36510"
  },
  {
    "text": "of conduct please do not add anything to the chat or questions that would be in violation of that code of conduct",
    "start": "36510",
    "end": "42390"
  },
  {
    "text": "basically please be respectful of all of your fellow participants and presenters with that I'll hand it over to Ravi to",
    "start": "42390",
    "end": "48390"
  },
  {
    "text": "kick off today's presentation hi this is",
    "start": "48390",
    "end": "53460"
  },
  {
    "text": "Ravi Kumar Laguna I work for a minute io I'm the senior architect at Robin Robin",
    "start": "53460",
    "end": "60870"
  },
  {
    "text": "is an application orchestration platform on top of kubernetes to run data heavy",
    "start": "60870",
    "end": "66760"
  },
  {
    "text": "applications which fall into sequel no sequel and big data segments Robyn is",
    "start": "66760",
    "end": "73360"
  },
  {
    "text": "the platform to run Oracle RAC Postgres my sequel or MongoDB Cassandra Cordura",
    "start": "73360",
    "end": "81640"
  },
  {
    "text": "Kafka any data heavy application can be run on robben platform with that brief",
    "start": "81640",
    "end": "88690"
  },
  {
    "text": "introduction of problem let's get into our agenda so I'm going to talk a little",
    "start": "88690",
    "end": "95020"
  },
  {
    "start": "91000",
    "end": "91000"
  },
  {
    "text": "bit about kubernetes landscape and especially the application landscape",
    "start": "95020",
    "end": "101700"
  },
  {
    "text": "right now on 1.16 what kind of applications are suitable for running on",
    "start": "101700",
    "end": "108520"
  },
  {
    "text": "Google release and then we'll jump into a little bit detailed discussion on",
    "start": "108520",
    "end": "114010"
  },
  {
    "text": "databases and there are patterns and what is the challenge in running",
    "start": "114010",
    "end": "120370"
  },
  {
    "text": "databases and snapshotting databases or any data heavy application of the bodies and pass that we will talk about the",
    "start": "120370",
    "end": "128920"
  },
  {
    "text": "core constructs that will enable us to run these applications on kubernetes which is consistency goals and we'll",
    "start": "128920",
    "end": "135790"
  },
  {
    "text": "have a brief Q&A session after that with that let's talk about kuben breeze and",
    "start": "135790",
    "end": "141280"
  },
  {
    "text": "the application landscape cover today's has become the de facto standard for running stateless applications",
    "start": "141280",
    "end": "147550"
  },
  {
    "start": "142000",
    "end": "142000"
  },
  {
    "text": "it's pushed aside every other Orchestrator out there if you want to run an engine xform the default option",
    "start": "147550",
    "end": "154270"
  },
  {
    "text": "is kubernetes today and all of these",
    "start": "154270",
    "end": "159630"
  },
  {
    "text": "applications beat nodejs of java or engineers wordpress all of these",
    "start": "159630",
    "end": "164950"
  },
  {
    "text": "applications roughly qualified as web applications now the second segment of",
    "start": "164950",
    "end": "172060"
  },
  {
    "text": "applications are the databases which could be oracle my signal posters of",
    "start": "172060",
    "end": "177250"
  },
  {
    "text": "mario DVD release these are traditional sequel databases the following segment",
    "start": "177250",
    "end": "183220"
  },
  {
    "text": "is distributed application stores which could be document stores like MongoDB or",
    "start": "183220",
    "end": "190150"
  },
  {
    "text": "key value pair stores like Cassandra or influenced Prometheus radius all of these are distributed in nature these",
    "start": "190150",
    "end": "197020"
  },
  {
    "text": "are modern-day distributed data stores",
    "start": "197020",
    "end": "203010"
  },
  {
    "text": "right is our heavy hitters these are our big data applications which could be",
    "start": "204310",
    "end": "210700"
  },
  {
    "text": "Hadoop stacks or elasticsearch or long or big overlap application stacks",
    "start": "210700",
    "end": "218110"
  },
  {
    "text": "analytical processing stacks that's a big yes time",
    "start": "218110",
    "end": "224220"
  },
  {
    "text": "so this is a classification from the applications side but if you are",
    "start": "224220",
    "end": "229620"
  },
  {
    "text": "building a platform if you're open it is orchestrated there is a different",
    "start": "229620",
    "end": "234870"
  },
  {
    "text": "division so we call them stateless applications we call all of these",
    "start": "234870",
    "end": "240410"
  },
  {
    "text": "stateful applications what we are going to dive into is deploying and",
    "start": "240410",
    "end": "246620"
  },
  {
    "text": "orchestrating stateful applications especially taking snapshots",
    "start": "246620",
    "end": "252099"
  },
  {
    "text": "so with that classification let's get a little bit deeper into databases which",
    "start": "252099",
    "end": "258590"
  },
  {
    "text": "is sequel database and no sequel databases and let's inspect what is it",
    "start": "258590",
    "end": "263900"
  },
  {
    "text": "that makes deploying and managing databases very challenging",
    "start": "263900",
    "end": "268900"
  },
  {
    "start": "270000",
    "end": "270000"
  },
  {
    "text": "let's go briefly over these two segments of sequel databases and no sequel databases some of the attributes of",
    "start": "270160",
    "end": "277550"
  },
  {
    "text": "sequel databases are primarily acid compliance and these are monolithic",
    "start": "277550",
    "end": "283190"
  },
  {
    "text": "architectures primarily because these are built like decades ago where bare",
    "start": "283190",
    "end": "290000"
  },
  {
    "text": "metal is the predominant platform where this his applications were deployed and these are row oriented databases they",
    "start": "290000",
    "end": "298940"
  },
  {
    "text": "primarily work loaded is transactional workload and they have a standardized sequence so very very well known",
    "start": "298940",
    "end": "305949"
  },
  {
    "text": "datastore whereas the no sequel databases have made some compromises to",
    "start": "305949",
    "end": "311560"
  },
  {
    "text": "address certain workloads there is a tunable consistency there is stable",
    "start": "311560",
    "end": "318849"
  },
  {
    "text": "durability guarantees these are scalar architectures to average to leverage",
    "start": "318849",
    "end": "327229"
  },
  {
    "text": "commodity hardware and like I said they target different workloads some of them",
    "start": "327229",
    "end": "333710"
  },
  {
    "text": "target even least evaluate some of them in data stores they serve both well OLAP and OLTP they",
    "start": "333710",
    "end": "341750"
  },
  {
    "text": "sell both transactional load as well as analytical lower and they have non-standard client interfaces some of",
    "start": "341750",
    "end": "350689"
  },
  {
    "text": "them do give out sequel semantics but they have non-standard client interfaces",
    "start": "350689",
    "end": "357680"
  },
  {
    "text": "like sequel Modi decline or various like so this is a very very high level over",
    "start": "357680",
    "end": "364009"
  },
  {
    "text": "on the distinction between sequel and Oracle databases so this is important in",
    "start": "364009",
    "end": "369740"
  },
  {
    "text": "understanding or designing the parameters that Lenovo luster on these",
    "start": "369740",
    "end": "375409"
  },
  {
    "text": "applications and commodities let's talk about the standard database deployment",
    "start": "375409",
    "end": "381500"
  },
  {
    "start": "378000",
    "end": "378000"
  },
  {
    "text": "models so this is our code this application assume that it is running in a container",
    "start": "381500",
    "end": "386840"
  },
  {
    "text": "we are talking about who-ville easier so what is required for running Postgres on",
    "start": "386840",
    "end": "392419"
  },
  {
    "text": "kubernetes obviously you need a data volume which is provisioned through a CSI and that is coming from a storage",
    "start": "392419",
    "end": "400759"
  },
  {
    "text": "tab let's call it data volume the question now is is this enough and a",
    "start": "400759",
    "end": "407360"
  },
  {
    "text": "test environment maybe yes but in a production environment no because the recommendation of",
    "start": "407360",
    "end": "412969"
  },
  {
    "text": "Postgres or for that matter any database is that you put the Val right ahead log",
    "start": "412969",
    "end": "419990"
  },
  {
    "text": "or redo logs or undo logs in a different disk so naturally we will go and ask",
    "start": "419990",
    "end": "428930"
  },
  {
    "text": "ability CSI to provision another one so this forms our post this application",
    "start": "428930",
    "end": "435500"
  },
  {
    "text": "the container and two volumes when we talk about applications like Cassandra",
    "start": "435500",
    "end": "443569"
  },
  {
    "text": "which are distributed in nature which fall into the other segments of multiple databases",
    "start": "443569",
    "end": "448750"
  },
  {
    "text": "it follows pattern it's not enough to just provision a data volume so we have a",
    "start": "448750",
    "end": "455620"
  },
  {
    "text": "commit log here which mandates a different spindle or a different volume",
    "start": "455620",
    "end": "461400"
  },
  {
    "text": "so these are the recommendations for performance say if you want better performance you you follow these",
    "start": "461400",
    "end": "467530"
  },
  {
    "text": "recommendations of having two volumes and on top of that Cassandra is a little",
    "start": "467530",
    "end": "472750"
  },
  {
    "text": "complicated because it's a distributed architecture so we have more than one pods running and each part consuming",
    "start": "472750",
    "end": "480009"
  },
  {
    "text": "more than one volume of different iya patterns of course this is a consistent",
    "start": "480009",
    "end": "486280"
  },
  {
    "text": "hashing scheme for Sandra so what we have established here is on a standard",
    "start": "486280",
    "end": "492580"
  },
  {
    "text": "sequel database it's not just a container and storage there is more to",
    "start": "492580",
    "end": "498340"
  },
  {
    "text": "it so you really have to understand what the application is doing and allocate storage accordingly there is a data",
    "start": "498340",
    "end": "503949"
  },
  {
    "text": "volume on there's a while but right ahead long when it comes to Cassandra it's even more complicated because there",
    "start": "503949",
    "end": "510729"
  },
  {
    "text": "are multiple containers in play and multiple volumes in so with this understanding let's see the actual",
    "start": "510729",
    "end": "518578"
  },
  {
    "text": "transaction flow what happens when a user issues a sequence statement assume",
    "start": "518579",
    "end": "528279"
  },
  {
    "text": "that this sees the data volume so which is where the actual final data resides",
    "start": "528279",
    "end": "533350"
  },
  {
    "text": "which is one volume and this is the wall this is the right ahead log value these",
    "start": "533350",
    "end": "540579"
  },
  {
    "text": "are two separate volumes coming from two different let's say disks now let's say",
    "start": "540579",
    "end": "546850"
  },
  {
    "text": "user were to issue a sequel statement a sequel statement could be auto commit or",
    "start": "546850",
    "end": "553149"
  },
  {
    "text": "it could be a series of statements with a star transaction and I've come it under rollback at the end transactions",
    "start": "553149",
    "end": "560500"
  },
  {
    "text": "a bunch of statements and I come it makes one set let's say there is a star",
    "start": "560500",
    "end": "566260"
  },
  {
    "text": "transaction usually what happens in majority of the databases is there is a",
    "start": "566260",
    "end": "571950"
  },
  {
    "text": "star transaction entry written in the wall file let's say there was some data",
    "start": "571950",
    "end": "579790"
  },
  {
    "text": "chains which is an insert query or an update reading a blog gets added",
    "start": "579790",
    "end": "585190"
  },
  {
    "text": "whatever data whatever change set is applied through the sequel statement is",
    "start": "585190",
    "end": "592090"
  },
  {
    "text": "written into the transaction log let's say for example there is an update on a",
    "start": "592090",
    "end": "598780"
  },
  {
    "text": "key text we are changing a value to 20",
    "start": "598780",
    "end": "603870"
  },
  {
    "text": "so that X equal to 20 is written in the bar not exactly in that format but roughly the idea is to capture the",
    "start": "603870",
    "end": "610390"
  },
  {
    "text": "changes in the transaction and we make more more changes to the other to the",
    "start": "610390",
    "end": "616600"
  },
  {
    "text": "database and then we do our commit here sir commit will be written as a marker",
    "start": "616600",
    "end": "623860"
  },
  {
    "text": "entry in the wall so what we have now is a SAR transaction a set of changes in a",
    "start": "623860",
    "end": "630340"
  },
  {
    "text": "committed but at some point database processes will come in and do some sort",
    "start": "630340",
    "end": "636490"
  },
  {
    "text": "of compaction different terms of are used in different database architectures",
    "start": "636490",
    "end": "643410"
  },
  {
    "text": "essentially what it means is we take all the changes and apply to the actual data",
    "start": "643410",
    "end": "650050"
  },
  {
    "text": "blocks which means we are writing the i/os you take me I use from one volume compacting them and writing to our",
    "start": "650050",
    "end": "657190"
  },
  {
    "text": "different volume that's that is where the value of x equals 20 is applied to a",
    "start": "657190",
    "end": "662350"
  },
  {
    "text": "date ago so this is the standard flow in a in a sequel database in a no sequel",
    "start": "662350",
    "end": "669190"
  },
  {
    "text": "database it's slightly more challenging because there's a star for the transaction because they some of the you",
    "start": "669190",
    "end": "676870"
  },
  {
    "text": "know sequel databases or distributed databases do one-off or transactional semantics they offer sewer transactions",
    "start": "676870",
    "end": "682840"
  },
  {
    "text": "matters same thing apply the transaction the primary records it",
    "start": "682840",
    "end": "689230"
  },
  {
    "text": "admits commit log and the commit log the transfer to the secondary sources or the replicas replicas are registered least",
    "start": "689230",
    "end": "695980"
  },
  {
    "text": "changes and they emit there's a flush that happens",
    "start": "695980",
    "end": "700380"
  },
  {
    "text": "similar being so miss we have seen that",
    "start": "701740",
    "end": "709270"
  },
  {
    "text": "the changes are applied to the transaction log first and then periodically they get rush to the date",
    "start": "709270",
    "end": "714820"
  },
  {
    "text": "of loss and why is that fundamentally there are some design assumptions made either for performance or durability of",
    "start": "714820",
    "end": "721660"
  },
  {
    "text": "consistency and what of us design isn't on the infrastructure side the design",
    "start": "721660",
    "end": "730390"
  },
  {
    "start": "723000",
    "end": "723000"
  },
  {
    "text": "assumption is that the transaction log and the data files will go to separate discs and why is that because there are",
    "start": "730390",
    "end": "738370"
  },
  {
    "text": "two writes in world and we don't want to have the two rides going to the same spinning that will create an i/o blended",
    "start": "738370",
    "end": "745360"
  },
  {
    "text": "effect which is you spin the disc in multiple grades we don't want to spin",
    "start": "745360",
    "end": "751330"
  },
  {
    "text": "the disc a back and forth you just want to keep a pending so that is wall it is",
    "start": "751330",
    "end": "759220"
  },
  {
    "text": "also possible that there could be multiple transaction lots so we want all",
    "start": "759220",
    "end": "764320"
  },
  {
    "text": "of these transaction valves to reside on different disks",
    "start": "764320",
    "end": "768990"
  },
  {
    "text": "wall is an append-only workload to leverage the sequential axis of a swindle and crash consistent C is",
    "start": "770030",
    "end": "779090"
  },
  {
    "text": "assumed and design into databases at any point in time if you abruptly shut down",
    "start": "779090",
    "end": "786920"
  },
  {
    "text": "the server on which a database is running it will come back up online so that is assumed in the design and that",
    "start": "786920",
    "end": "793910"
  },
  {
    "text": "is a that is one of the reasons why we have read on undo logs in databases and",
    "start": "793910",
    "end": "799600"
  },
  {
    "text": "no sequel databases which are distributed databases assume that the",
    "start": "799960",
    "end": "806300"
  },
  {
    "text": "partitions which are those independent individual containers they go on",
    "start": "806300",
    "end": "811400"
  },
  {
    "text": "different physical hard walls so these are some of the design assumptions on the infrastructure side of it so in a",
    "start": "811400",
    "end": "819770"
  },
  {
    "text": "database designer regime that I will have this set from the infrastructure",
    "start": "819770",
    "end": "825380"
  },
  {
    "text": "and then I will do some ie optimizations which is Val try to hide log which is an",
    "start": "825380",
    "end": "832220"
  },
  {
    "start": "826000",
    "end": "826000"
  },
  {
    "text": "appallingly worked or we call it undo / redo log in different database schemes",
    "start": "832220",
    "end": "838180"
  },
  {
    "text": "it's an append-only workload it's a persistent circularbuffer it could be one or more buffers residing on the disk",
    "start": "838180",
    "end": "847930"
  },
  {
    "text": "there is dirty management this is like in core structure reverses on dis structures its",
    "start": "849160",
    "end": "856930"
  },
  {
    "text": "auto back you mean there are different terms used in different database technologies it is double rod",
    "start": "856930",
    "end": "863890"
  },
  {
    "text": "optimizations in my sequel database and there are parallel X Rob slog right such",
    "start": "863890",
    "end": "869830"
  },
  {
    "text": "a transaction operates so what are we coming in so we talked about the",
    "start": "869830",
    "end": "876730"
  },
  {
    "text": "assumptions made on the infrastructure side we talked about some I of what optimizations or the sequencer this is",
    "start": "876730",
    "end": "882760"
  },
  {
    "text": "we are barely scratching the surface here with the iPod optimizations I am talking in terms or my goal is to is to",
    "start": "882760",
    "end": "892540"
  },
  {
    "text": "make you understand what is the infrastructure requirement just for this X log",
    "start": "892540",
    "end": "899040"
  },
  {
    "text": "so what we are looking for in order to design a data production strategy for an",
    "start": "899620",
    "end": "905510"
  },
  {
    "text": "app for a data heavy application like databases we really have to understand",
    "start": "905510",
    "end": "911209"
  },
  {
    "text": "how these databases have built what are the design assumptions made by these applications",
    "start": "911209",
    "end": "917950"
  },
  {
    "text": "and what are the recommendations made by these application bandits now that we",
    "start": "917950",
    "end": "923050"
  },
  {
    "text": "know a little bit about these assumptions where your Val and Dana volume have to reside on different desks",
    "start": "923050",
    "end": "929230"
  },
  {
    "text": "if it is a distributed database they have to do the containers have to be",
    "start": "929230",
    "end": "934720"
  },
  {
    "text": "provisioned on different Hardware let's design a data protection strategy for",
    "start": "934720",
    "end": "941110"
  },
  {
    "start": "938000",
    "end": "938000"
  },
  {
    "text": "this application let's talk about our",
    "start": "941110",
    "end": "946480"
  },
  {
    "text": "standard postage database which could be my sequel or Oracle Oracle or Oracle",
    "start": "946480",
    "end": "959860"
  },
  {
    "text": "track if you were to use standard volume snapshotting by that I mean we could",
    "start": "959860",
    "end": "969310"
  },
  {
    "text": "using we could be using San lanced for this data or data volume or the transaction row or we could be using",
    "start": "969310",
    "end": "976510"
  },
  {
    "text": "plain lan-based volumes of data and transaction in either case it is a",
    "start": "976510",
    "end": "982240"
  },
  {
    "text": "volume that is provided to your database and all of these volume management",
    "start": "982240",
    "end": "989070"
  },
  {
    "text": "options beats an or LVM they have some sort of snapshot abilities let's say for",
    "start": "989070",
    "end": "996070"
  },
  {
    "text": "to use those built-in snapshotting capabilities and snapshot these volumes",
    "start": "996070",
    "end": "1002280"
  },
  {
    "text": "the data volume above so first our we take a snapshot which is we create a",
    "start": "1002280",
    "end": "1007790"
  },
  {
    "text": "snapshot of these two volumes second our",
    "start": "1007790",
    "end": "1012900"
  },
  {
    "text": "weekly and third of you can snapshot what is wrong with this approach or more",
    "start": "1012900",
    "end": "1018210"
  },
  {
    "text": "than what is wrong how are we taking these snapshots the loop one of the",
    "start": "1018210",
    "end": "1026310"
  },
  {
    "start": "1023000",
    "end": "1023000"
  },
  {
    "text": "simple strategies to take the snapshot when multiple volumes are involved is to",
    "start": "1026310",
    "end": "1031390"
  },
  {
    "text": "write up in yes like that rule nothing about three lines go for each one you",
    "start": "1031390",
    "end": "1037089"
  },
  {
    "text": "take its natural one what's wrong with this nothing so far",
    "start": "1037090",
    "end": "1044230"
  },
  {
    "text": "but when it comes to no sequel databases so again the same loop loop or loop for each container snapshot each volume in",
    "start": "1044230",
    "end": "1051460"
  },
  {
    "text": "that container if it is as simple as this the world would be a tea strainer",
    "start": "1051460",
    "end": "1059110"
  },
  {
    "text": "there won't be any forum but unfortunately it's not as simple as this it is actually much much more",
    "start": "1059110",
    "end": "1064810"
  },
  {
    "text": "complicated than this and what is the problem this is a problem the looping is",
    "start": "1064810",
    "end": "1071710"
  },
  {
    "text": "the problem and we will see why the looping is a problem here so we have",
    "start": "1071710",
    "end": "1080950"
  },
  {
    "start": "1077000",
    "end": "1077000"
  },
  {
    "text": "these two database volumes which are data volume and a transaction log let's",
    "start": "1080950",
    "end": "1092950"
  },
  {
    "text": "see the loop is doing to these ones",
    "start": "1092950",
    "end": "1096710"
  },
  {
    "text": "so this is our loop let's run through",
    "start": "1098210",
    "end": "1104130"
  },
  {
    "text": "this loop time t0 I'm assuming them not",
    "start": "1104130",
    "end": "1111450"
  },
  {
    "text": "assuming but there is an Orchestrator that is running this is some process which is executing this loop and at t0",
    "start": "1111450",
    "end": "1118980"
  },
  {
    "text": "that process initiated a snapshot of the transaction log so we got our snapshot",
    "start": "1118980",
    "end": "1127380"
  },
  {
    "text": "of the transaction now it is a process so it is bound to scheduling details",
    "start": "1127380",
    "end": "1135050"
  },
  {
    "text": "let's say our process got solved at the process that is running this loop got",
    "start": "1135050",
    "end": "1140910"
  },
  {
    "text": "swapped out so after some time the",
    "start": "1140910",
    "end": "1146040"
  },
  {
    "text": "process is rescheduled and it will trigger the snapshot of the data one we",
    "start": "1146040",
    "end": "1155190"
  },
  {
    "text": "got a second snap check off the snapshot of the data volume depending on how the",
    "start": "1155190",
    "end": "1162060"
  },
  {
    "text": "loop is implemented it could be other way as one we take the snapshot of the data and the process gets scheduled down",
    "start": "1162060",
    "end": "1168480"
  },
  {
    "text": "and we go on take the snapshot right",
    "start": "1168480",
    "end": "1173550"
  },
  {
    "text": "everyone anything is possible I am just giving you an example of a",
    "start": "1173550",
    "end": "1179580"
  },
  {
    "text": "standard database but imagine a Cassandra application with 50 partitions which will translate to maybe hundred",
    "start": "1179580",
    "end": "1186750"
  },
  {
    "text": "volumes and if you follow the strategy of for each container for each volume",
    "start": "1186750",
    "end": "1192120"
  },
  {
    "text": "snapshot you could be getting snapshots of these volumes and different points in",
    "start": "1192120",
    "end": "1198000"
  },
  {
    "text": "time question we should be asking now is",
    "start": "1198000",
    "end": "1203750"
  },
  {
    "text": "it is inevitable that you get snapshots of these volumes at different points in",
    "start": "1203750",
    "end": "1210060"
  },
  {
    "text": "time you could argue that the delays in milliseconds or microseconds but it is",
    "start": "1210060",
    "end": "1216510"
  },
  {
    "text": "inevitable that you get snapshots of these individual is a different ones in them the big question now is are they",
    "start": "1216510",
    "end": "1223410"
  },
  {
    "text": "consistent let's keep that question in mind let's go ahead and see what the",
    "start": "1223410",
    "end": "1229920"
  },
  {
    "start": "1228000",
    "end": "1228000"
  },
  {
    "text": "problem is so this is our time line somebody runs a",
    "start": "1229920",
    "end": "1237450"
  },
  {
    "text": "commit it's the starter a transaction they shared a bunch of updates and there's a commit statement so this is",
    "start": "1237450",
    "end": "1246120"
  },
  {
    "text": "how right after Shane the commit this is how our right ahead log will look like",
    "start": "1246120",
    "end": "1252240"
  },
  {
    "text": "and this is how the data blossom network x equals 20 is written to the",
    "start": "1252240",
    "end": "1257970"
  },
  {
    "text": "transaction log and commit entries written to the transaction log there is nothing written so far to the data box",
    "start": "1257970",
    "end": "1264800"
  },
  {
    "text": "because that is a periodic trend it depends on a cadence or a trigger in the",
    "start": "1264800",
    "end": "1271440"
  },
  {
    "text": "database logic that will come in take the entries in the transaction log",
    "start": "1271440",
    "end": "1276840"
  },
  {
    "text": "compact them and joy to the reader gloss that hasn't happened yet in our time",
    "start": "1276840",
    "end": "1282120"
  },
  {
    "text": "sequencing now let's say we start the snapshot here at that point",
    "start": "1282120",
    "end": "1289160"
  },
  {
    "text": "and for Lukas at work here the loop comes in and tries to take a snapshot",
    "start": "1290970",
    "end": "1296550"
  },
  {
    "text": "note that it's a loop let's assume that it picked up the data working",
    "start": "1296550",
    "end": "1303410"
  },
  {
    "text": "to get snapshot so that that's just snapshot affordable now we have",
    "start": "1303410",
    "end": "1310550"
  },
  {
    "text": "scheduling this but while our",
    "start": "1310550",
    "end": "1318280"
  },
  {
    "text": "snapshotting loop is out so we have database flush at work which is the",
    "start": "1318280",
    "end": "1323480"
  },
  {
    "text": "database process that is coming in and compacting the entries here and that",
    "start": "1323480",
    "end": "1333110"
  },
  {
    "text": "database flush did a transaction flush which means it read all the entries from",
    "start": "1333110",
    "end": "1340370"
  },
  {
    "text": "the transaction log and applied it to the data blocks now if you see the picture here the x equals to 20 is or in",
    "start": "1340370",
    "end": "1348500"
  },
  {
    "text": "the data volume it's no longer present in the transaction log because the transaction log or the wall files are",
    "start": "1348500",
    "end": "1356050"
  },
  {
    "text": "circular buffers persistent circular purpose which means the blocks are reused so you just flush the entries",
    "start": "1356050",
    "end": "1362060"
  },
  {
    "text": "from the transaction log now we now are",
    "start": "1362060",
    "end": "1368860"
  },
  {
    "text": "Orchestrator comes in the snapshot Orchestrator it's trying to finish the snapshot which means it will reschedule",
    "start": "1368860",
    "end": "1374780"
  },
  {
    "text": "to do in the loop the next volume is a transaction log and we take a snapshot of the transaction log so that this the",
    "start": "1374780",
    "end": "1384800"
  },
  {
    "text": "picture that you see on the far right is our final snapshot what's wrong with the",
    "start": "1384800",
    "end": "1392090"
  },
  {
    "text": "snapshot here the snapshot here has no",
    "start": "1392090",
    "end": "1398630"
  },
  {
    "text": "entries where is our x equals 2d in the snapshot it's gone so that is the",
    "start": "1398630",
    "end": "1406040"
  },
  {
    "text": "problem with a snapshot let's say if you have to restore from the snapshot",
    "start": "1406040",
    "end": "1411630"
  },
  {
    "text": "so we get this picture so you can",
    "start": "1411630",
    "end": "1417730"
  },
  {
    "text": "clearly see the difference here we ran a snapshot the snapshot was triggered",
    "start": "1417730",
    "end": "1423429"
  },
  {
    "text": "after we issued a commit with the acid guarantees of the database X equals 20",
    "start": "1423429",
    "end": "1431679"
  },
  {
    "text": "should be present in the database in the in the snapshot but unfortunately we",
    "start": "1431679",
    "end": "1438640"
  },
  {
    "text": "don't have it so there is a race between the for loop",
    "start": "1438640",
    "end": "1444010"
  },
  {
    "text": "and the DB flush there are two processes which are racing here and that will",
    "start": "1444010",
    "end": "1451149"
  },
  {
    "text": "cause an invalid snapshot to be created",
    "start": "1451149",
    "end": "1456390"
  },
  {
    "text": "this is a big big problem and this is where our consistency groups come the",
    "start": "1456390",
    "end": "1462850"
  },
  {
    "text": "core reason why this is happening is because we are treating these two volumes as two different entities and",
    "start": "1462850",
    "end": "1468870"
  },
  {
    "text": "taking snapshots of these individual volumes and this is a real problem in",
    "start": "1468870",
    "end": "1476490"
  },
  {
    "text": "database naturals this is actually a data loss scenario of water consistency",
    "start": "1476490",
    "end": "1487090"
  },
  {
    "start": "1485000",
    "end": "1485000"
  },
  {
    "text": "groups so consistency groups are groups of volumes that function as a unit for",
    "start": "1487090",
    "end": "1493270"
  },
  {
    "text": "the application which is our transaction log and database file and this is a",
    "start": "1493270",
    "end": "1503770"
  },
  {
    "text": "group on which the lifecycle operations for a is now you're creating",
    "start": "1503770",
    "end": "1511580"
  },
  {
    "text": "own or extending blooms and group that",
    "start": "1511710",
    "end": "1518610"
  },
  {
    "text": "maintains a right order say we write a transactional and then the rights make today devalue the right order is",
    "start": "1518610",
    "end": "1524370"
  },
  {
    "text": "maintained here and the group that fits was a crash consistent systematics because there is an assumption that the",
    "start": "1524370",
    "end": "1530970"
  },
  {
    "text": "transaction log is written first and the rights have taken unwritten to data volumes we maintain the crash",
    "start": "1530970",
    "end": "1538649"
  },
  {
    "text": "consistency at any point in time if the database were to go down we know for sure that the data is in the transaction",
    "start": "1538649",
    "end": "1544320"
  },
  {
    "text": "log it could be undone or redone based on whether the transaction is committed",
    "start": "1544320",
    "end": "1550740"
  },
  {
    "text": "or not committed and whether we follow a redirect and right approach or Hokkien arbitration let's design a brighter data",
    "start": "1550740",
    "end": "1561960"
  },
  {
    "text": "protection strategy now now that we know about the consistency groups let's design it better data protection",
    "start": "1561960",
    "end": "1568590"
  },
  {
    "text": "strategy let's combine these volumes and call it a consistency group so we take a",
    "start": "1568590",
    "end": "1574409"
  },
  {
    "text": "snapshot again on the first R we get a consistent snapshot of these two volumes",
    "start": "1574409",
    "end": "1581149"
  },
  {
    "text": "same goes for three picots natural sedative so this will solve the problem",
    "start": "1581149",
    "end": "1588960"
  },
  {
    "text": "of consists consistent snapshots but is there anything more that we can do so we",
    "start": "1588960",
    "end": "1596279"
  },
  {
    "text": "can do more Oh more what is the problem in the current",
    "start": "1596279",
    "end": "1605740"
  },
  {
    "text": "case @k it has a coupon DCSS tax it only operates at a single volume level the",
    "start": "1605740",
    "end": "1611860"
  },
  {
    "text": "volume consistency group concept is being worked on for right now there is",
    "start": "1611860",
    "end": "1619210"
  },
  {
    "text": "only single volume level interfaces I was talking about is there anything that",
    "start": "1619210",
    "end": "1625059"
  },
  {
    "text": "we can do more yes there is something thank you but",
    "start": "1625059",
    "end": "1631139"
  },
  {
    "start": "1628000",
    "end": "1628000"
  },
  {
    "text": "before that I want to explained something else which is database is not",
    "start": "1631139",
    "end": "1636600"
  },
  {
    "text": "just a data file or a data value in the transaction one um",
    "start": "1636600",
    "end": "1643639"
  },
  {
    "text": "it has configuration as well it could be database configuration or it will be",
    "start": "1643639",
    "end": "1649499"
  },
  {
    "text": "some metadata settings most of the database stored in the metadata tables but there are some databases or some",
    "start": "1649499",
    "end": "1656940"
  },
  {
    "text": "applications that should say Cassandra would store in some configuration files",
    "start": "1656940",
    "end": "1662809"
  },
  {
    "text": "so there is not just data on well but there is also configuration but how do we capture that configuration part in a",
    "start": "1662809",
    "end": "1668669"
  },
  {
    "text": "snapshot the better approach is to actually snapshot everything the volumes",
    "start": "1668669",
    "end": "1675990"
  },
  {
    "text": "as well as the container which",
    "start": "1675990",
    "end": "1680539"
  },
  {
    "text": "goom's dinner let me say container we also capture them we also capture the",
    "start": "1687399",
    "end": "1696549"
  },
  {
    "text": "topology of it if the Cassandra has 50 partitions we capture the fact that there are 50",
    "start": "1696549",
    "end": "1702969"
  },
  {
    "text": "partitions in the snapshot and after the snapshot if you're a scale out 200",
    "start": "1702969",
    "end": "1708639"
  },
  {
    "text": "partitions and move back to 52 that snapshot will get 50 partitions back so we capture the configuration topology",
    "start": "1708639",
    "end": "1714909"
  },
  {
    "text": "and the data so that's a much much better approach to snapshotting than just natural volumes so the cons is we",
    "start": "1714909",
    "end": "1726639"
  },
  {
    "start": "1720000",
    "end": "1720000"
  },
  {
    "text": "want to protect the entire application not just the volumes so Robin provides",
    "start": "1726639",
    "end": "1733409"
  },
  {
    "text": "primitives on top of applications at an application level so you can take a snapshot of the entire application",
    "start": "1733409",
    "end": "1741389"
  },
  {
    "text": "chicken metadata so you can roll back to any snapshot at any point in time we can",
    "start": "1745630",
    "end": "1753820"
  },
  {
    "text": "push that snapshot which is the consistent point in time image to a remote target by using the backup",
    "start": "1753820",
    "end": "1760960"
  },
  {
    "text": "command and we can restore from the backup at any point in time and note",
    "start": "1760960",
    "end": "1766600"
  },
  {
    "text": "that this yeah haha we do this so I'll go oral",
    "start": "1766600",
    "end": "1778400"
  },
  {
    "start": "1778000",
    "end": "1778000"
  },
  {
    "text": "Viva architecture overview of Robin so we have built on top of kubernetes we",
    "start": "1778400",
    "end": "1784010"
  },
  {
    "text": "have not changed any qualities you have taken a CNC of certified kubernetes",
    "start": "1784010",
    "end": "1789160"
  },
  {
    "text": "deployment I mean they build a distributed storage stack with all the",
    "start": "1789340",
    "end": "1795320"
  },
  {
    "text": "enterprise great features like snapshots clones qsr replication backup we also have a pluggable networking stack what",
    "start": "1795320",
    "end": "1802070"
  },
  {
    "text": "we realized is for applications like Oracle we need the container identity persistence which means the IP address",
    "start": "1802070",
    "end": "1807920"
  },
  {
    "text": "have to be reading so we have storage we have compute in terms of kubernetes and",
    "start": "1807920",
    "end": "1813470"
  },
  {
    "text": "we have networking and we built of a flow manager which will orchestrate the snapshots clones which is responsible",
    "start": "1813470",
    "end": "1820700"
  },
  {
    "text": "for the consistency groups backups cetera with this package we can manage the",
    "start": "1820700",
    "end": "1828830"
  },
  {
    "text": "end-to-end lifecycle of these applications Robyn is a software only",
    "start": "1828830",
    "end": "1836330"
  },
  {
    "text": "platform that can be deployed in any cloud aw0 platform or it can be deployed",
    "start": "1836330",
    "end": "1843020"
  },
  {
    "text": "and a bunch of VMs it would be ESX or to be OpenStack VMs more on the America",
    "start": "1843020",
    "end": "1850270"
  },
  {
    "start": "1852000",
    "end": "1852000"
  },
  {
    "text": "and like I said we can consume you cannot on any cloud any VM we can run as",
    "start": "1852860",
    "end": "1862560"
  },
  {
    "text": "a storage only provider on top of any star keys which is uber Nettie's engines",
    "start": "1862560",
    "end": "1867630"
  },
  {
    "text": "running in cloud and without you can run any of the distributed applications and",
    "start": "1867630",
    "end": "1873600"
  },
  {
    "text": "we allow for the lifecycle management of these applications so we have customer",
    "start": "1873600",
    "end": "1881520"
  },
  {
    "text": "deployments of Robin software allowing customers to run huge data heavy",
    "start": "1881520",
    "end": "1889020"
  },
  {
    "text": "application clusters we have a deployment where there are 11 billion",
    "start": "1889020",
    "end": "1895680"
  },
  {
    "text": "security events getting ingested into elasticsearch log stash in Cabana al sky",
    "start": "1895680",
    "end": "1902300"
  },
  {
    "text": "there is a big multi Hadoop deployment",
    "start": "1902300",
    "end": "1908040"
  },
  {
    "text": "running on single Robin cluster to cloud",
    "start": "1908040",
    "end": "1913230"
  },
  {
    "text": "our data leaks and to cloud our compute only clusters with tough control and",
    "start": "1913230",
    "end": "1919910"
  },
  {
    "text": "there is a big deployment of 400 Oracle RAC databases around and if you are",
    "start": "1919910",
    "end": "1930180"
  },
  {
    "start": "1928000",
    "end": "1928000"
  },
  {
    "text": "interested in product demos please go to Robin REO and check out how we do snapshots and",
    "start": "1930180",
    "end": "1937380"
  },
  {
    "text": "rollbacks and how can we create clones of these applications out of snapshots how can you back up to cloud and",
    "start": "1937380",
    "end": "1944250"
  },
  {
    "text": "instantiate an application in cloud and",
    "start": "1944250",
    "end": "1950490"
  },
  {
    "text": "you can get a free trial from get a Robin aid are you and please also",
    "start": "1950490",
    "end": "1956640"
  },
  {
    "text": "subscribe to our slack channel slag Robin and that is Robin supercharge",
    "start": "1956640",
    "end": "1965490"
  },
  {
    "text": "kubernetes to deliver big data and databases and service awesome thanks",
    "start": "1965490",
    "end": "1971850"
  },
  {
    "text": "Ravi for the great presentation we now have some time for questions if you have a question that you would like to ask just drop it in the Q&A tab at the",
    "start": "1971850",
    "end": "1979020"
  },
  {
    "text": "bottom of your screen and we'll get to as many as we have time for we have one question so far from Peter who asks",
    "start": "1979020",
    "end": "1984690"
  },
  {
    "text": "hello is Robin ready for oracle cloud infrastructure so we are working towards",
    "start": "1984690",
    "end": "1990870"
  },
  {
    "text": "it but as of today it's not it's not certified yet okay and that was a single",
    "start": "1990870",
    "end": "2000290"
  },
  {
    "text": "question we have so far I'd like to leave it open here for a minute or so people have follow-up questions so while the questions are coming and I'd like to",
    "start": "2000290",
    "end": "2006410"
  },
  {
    "text": "show a quick demo oh sure Oh Robin like I said Robin new software platform",
    "start": "2006410",
    "end": "2013300"
  },
  {
    "text": "we use you get you can install it on a bunch of VMs or once you install you get a dashboard",
    "start": "2013300",
    "end": "2020690"
  },
  {
    "text": "like this app store experience where you will have all these data heavy",
    "start": "2020690",
    "end": "2026420"
  },
  {
    "text": "applications yeah saundra well there are Couchbase after Horton works here is Oracle RAC EBS V so all of these are my",
    "start": "2026420",
    "end": "2034670"
  },
  {
    "text": "charities these applications 25 to 30 applications are out-of-the-box available as ones that you can use which",
    "start": "2034670",
    "end": "2040790"
  },
  {
    "text": "means they show up on your dashboard you can click on deploy them and I have some",
    "start": "2040790",
    "end": "2048590"
  },
  {
    "text": "applications deployed here",
    "start": "2048590",
    "end": "2051909"
  },
  {
    "text": "so I have Oracle RAC have EBS Cassandra my sequel and MongoDB let's go to Oracle",
    "start": "2053690",
    "end": "2061470"
  },
  {
    "text": "RAC so Oracle RAC is an act",
    "start": "2061470",
    "end": "2068099"
  },
  {
    "text": "systems which means there are two containers at play here and if you can see this there are lots of volumes here",
    "start": "2068099",
    "end": "2075499"
  },
  {
    "text": "same thing that I was trying to explain that there are multiple data volumes there are multiple media volumes there",
    "start": "2075499",
    "end": "2081569"
  },
  {
    "text": "is splash there is great although this is a small deployment in terms of size",
    "start": "2081569",
    "end": "2087148"
  },
  {
    "text": "but I want to show you the the scale in terms of number of volume that needs to",
    "start": "2087149",
    "end": "2092220"
  },
  {
    "text": "be managed so if you have an application like this and if you want to take a",
    "start": "2092220",
    "end": "2098309"
  },
  {
    "text": "snapshot imagine the pain in using sand snaps towards or al DMV snapshots with",
    "start": "2098309",
    "end": "2105269"
  },
  {
    "text": "Robin the entire application can be deployed as well as managed by that I",
    "start": "2105269",
    "end": "2110339"
  },
  {
    "text": "mean and you say snapshot and you can",
    "start": "2110339",
    "end": "2117869"
  },
  {
    "text": "create a one time snapshot and if you",
    "start": "2117869",
    "end": "2126269"
  },
  {
    "text": "have noticed there is an option to create an application consistence natural what databases give out of the",
    "start": "2126269",
    "end": "2134460"
  },
  {
    "text": "box is a crash consistent snapshot we can also allow you to plug in hooks where you can freeze the application if",
    "start": "2134460",
    "end": "2140369"
  },
  {
    "text": "you choose to and then take a snapshot so now we have an entire application snapshot available for us so this is a",
    "start": "2140369",
    "end": "2148140"
  },
  {
    "text": "snapshot once you have a snapshot we can create a clone or we can restore to a",
    "start": "2148140",
    "end": "2154109"
  },
  {
    "text": "point in time the entire application will be rolled back to that point in time and there is an option",
    "start": "2154109",
    "end": "2161290"
  },
  {
    "text": "configure scheduled snapshots you can run early snapshots ideally snapshots",
    "start": "2161290",
    "end": "2166990"
  },
  {
    "text": "with retention pigeons the same flow works for MongoDB or Cassandra it's",
    "start": "2166990",
    "end": "2176290"
  },
  {
    "text": "exactly the same view here I have a MongoDB application which is a MongoDB",
    "start": "2176290",
    "end": "2183190"
  },
  {
    "text": "distributed applications you have a lot more container simply and and there are",
    "start": "2183190",
    "end": "2188530"
  },
  {
    "text": "a lot more volumes in play here and if you want a snapshot this MongoDB cluster",
    "start": "2188530",
    "end": "2195520"
  },
  {
    "text": "I can just say Snatcher so that is the",
    "start": "2195520",
    "end": "2205150"
  },
  {
    "text": "power that Robin brings to the table so you can not only create applications in a fault-tolerant manner but he",
    "start": "2205150",
    "end": "2211500"
  },
  {
    "text": "application consistent statutes you",
    "start": "2211500",
    "end": "2216730"
  },
  {
    "text": "you",
    "start": "2217490",
    "end": "2219550"
  },
  {
    "text": "you George yep I'm here to tell you if I can",
    "start": "2224040",
    "end": "2236760"
  },
  {
    "text": "if you have some more time that I can show a little more details here yeah",
    "start": "2236760",
    "end": "2241950"
  },
  {
    "text": "absolutely we don't have any questions so unless anyone has any more questions we could just keep Keshawn you yeah yeah",
    "start": "2241950",
    "end": "2248790"
  },
  {
    "text": "yeah so we talked about in the snapshots but let me also show you other",
    "start": "2248790",
    "end": "2255630"
  },
  {
    "text": "interesting facts in problem which is you got a dashboard and let's say if you want to apply better here",
    "start": "2255630",
    "end": "2263060"
  },
  {
    "text": "so you can choose what you want rule you want to deploy say I want to do here",
    "start": "2266420",
    "end": "2272760"
  },
  {
    "text": "guru is there flower eyes OLTP platform the transactional platform built on top",
    "start": "2272760",
    "end": "2279390"
  },
  {
    "text": "of order not built on top of bolts it's a different engine",
    "start": "2279390",
    "end": "2284359"
  },
  {
    "text": "so what I want to show here is you can set the sizing for your computer which",
    "start": "2284400",
    "end": "2291630"
  },
  {
    "text": "means goes in memory you can also define the storage you can say I want",
    "start": "2291630",
    "end": "2298460"
  },
  {
    "text": "replicated copies spread across racks",
    "start": "2298460",
    "end": "2303529"
  },
  {
    "text": "and I incent the drop size or I can set compression and I can said Packard this",
    "start": "2303530",
    "end": "2313040"
  },
  {
    "text": "is a layout of the data on the disk but",
    "start": "2313040",
    "end": "2321140"
  },
  {
    "text": "it said encryption and also define what row type this is these settings are more useful",
    "start": "2321140",
    "end": "2327380"
  },
  {
    "text": "when you are defining something like a data hold I'd say you created almost you know know how to cluster this is my",
    "start": "2327380",
    "end": "2334600"
  },
  {
    "text": "compute capacity and here I'll probably say the how do through pen intensive",
    "start": "2334600",
    "end": "2342410"
  },
  {
    "text": "volumes yeah a local is throughput intensive and I know that Hadoop does 3",
    "start": "2342410",
    "end": "2353000"
  },
  {
    "text": "where application and this is the very small deployment so let's say I have",
    "start": "2353000",
    "end": "2358040"
  },
  {
    "text": "three instant in this year here is where an interesting thing comes",
    "start": "2358040",
    "end": "2363740"
  },
  {
    "text": "in where prevent placing more than one day turn out container on the same node so what this will do is it will place",
    "start": "2363740",
    "end": "2371600"
  },
  {
    "text": "the three containers on three different physical cells",
    "start": "2371600",
    "end": "2377079"
  },
  {
    "text": "and we can also enforce storage and compute for the original to be coming from the same road these two policies",
    "start": "2377830",
    "end": "2384700"
  },
  {
    "text": "are must-have for any distributed application that is doing its own",
    "start": "2384700",
    "end": "2389980"
  },
  {
    "text": "replication and there are many of them this Holger Cassandra is more de this",
    "start": "2389980",
    "end": "2394990"
  },
  {
    "text": "couchdb influx there are many applications that do the application so this is a granular placement policies",
    "start": "2394990",
    "end": "2401860"
  },
  {
    "text": "that rock nouns so with that if there",
    "start": "2401860",
    "end": "2412570"
  },
  {
    "text": "are any more questions questions we do not have any more questions last chance",
    "start": "2412570",
    "end": "2421420"
  },
  {
    "text": "for questions everybody all right great",
    "start": "2421420",
    "end": "2428770"
  },
  {
    "text": "thanks Robbie for the presentation thanks for joining us today everyone this webinar recording and slides will",
    "start": "2428770",
    "end": "2434530"
  },
  {
    "text": "be available online later on today and we look forward to seeing you at a future CN CF webinar thank you everybody",
    "start": "2434530",
    "end": "2441070"
  },
  {
    "text": "and have a great day thank you thank you",
    "start": "2441070",
    "end": "2446580"
  }
]
[
  {
    "start": "0",
    "end": "77000"
  },
  {
    "text": "yeah I'm the lead architect in open STS an open source project underling",
    "start": "0",
    "end": "5040"
  },
  {
    "text": "foundation I'm also a co-lead in the warning snapshot project in kubernetes",
    "start": "5040",
    "end": "11190"
  },
  {
    "text": "SiC storage and a tech lead of the CN CF CN CF storage sick this is my co-speaker",
    "start": "11190",
    "end": "19070"
  },
  {
    "text": "aki-san hello everyone I'm Fae attack' from here",
    "start": "19070",
    "end": "24960"
  },
  {
    "text": "for Japan my main job is the operation of software-defined storage and in fact",
    "start": "24960",
    "end": "30630"
  },
  {
    "text": "I was involved in the private cloud based on OpenStack here is the agenda",
    "start": "30630",
    "end": "40829"
  },
  {
    "text": "for today so first what you were brief introduction to anomaly detection and",
    "start": "40829",
    "end": "46559"
  },
  {
    "text": "our focus is on doing anam detection in storage performance and Takizawa talk",
    "start": "46559",
    "end": "54600"
  },
  {
    "text": "about Yahoo Japan's use cases we'll talk about help me tree a project that",
    "start": "54600",
    "end": "60090"
  },
  {
    "text": "integrates with Prometheus and graph Anna collecting performance metrics from",
    "start": "60090",
    "end": "65158"
  },
  {
    "text": "storage backhands and we're doing anonyme detection using those data collected from the metrics module and",
    "start": "65159",
    "end": "73530"
  },
  {
    "text": "what your demo so what is the anomaly",
    "start": "73530",
    "end": "79290"
  },
  {
    "start": "77000",
    "end": "77000"
  },
  {
    "text": "caption anomaly detection is a technique used to identify on your your patterns",
    "start": "79290",
    "end": "86990"
  },
  {
    "text": "can you tell which one is on your pattern in this diagram I hope it's a",
    "start": "86990",
    "end": "93689"
  },
  {
    "text": "yeah I hope that's oh yes right the red color set face stands out in Agra petha",
    "start": "93689",
    "end": "100220"
  },
  {
    "text": "happy blue faces so there are different categories in unarmed detection",
    "start": "100220",
    "end": "109170"
  },
  {
    "text": "the first one is point anomalies which means the single data point is very far",
    "start": "109170",
    "end": "114750"
  },
  {
    "text": "away from the rest of example you can detect a fraud detection just by looking",
    "start": "114750",
    "end": "121920"
  },
  {
    "text": "at the amount spent second category is contextual anonymous",
    "start": "121920",
    "end": "127469"
  },
  {
    "text": "so the anomaly is context specific this is the typical in time 0",
    "start": "127469",
    "end": "133150"
  },
  {
    "text": "data so you've spent a lot of money on food every day during holiday season may",
    "start": "133150",
    "end": "139150"
  },
  {
    "text": "be normal but otherwise he may not be normal and the third category is",
    "start": "139150",
    "end": "144819"
  },
  {
    "text": "collective anomalies so meaning that a group of data collectively identifies them an army but",
    "start": "144819",
    "end": "152049"
  },
  {
    "text": "if you look at a single data point in that group that may be normal so if",
    "start": "152049",
    "end": "158200"
  },
  {
    "text": "you're spending money to buy our large number of expensive items on single day",
    "start": "158200",
    "end": "164079"
  },
  {
    "text": "then maybe that's not normal that if you just look at a single transaction that",
    "start": "164079",
    "end": "169389"
  },
  {
    "text": "may be okay so there are different use",
    "start": "169389",
    "end": "174700"
  },
  {
    "start": "172000",
    "end": "172000"
  },
  {
    "text": "cases in anomaly detection it's used in intuition detection to find out if you",
    "start": "174700",
    "end": "181900"
  },
  {
    "text": "know is a hack by looking at the network traffic patterns it's used in medical",
    "start": "181900",
    "end": "187780"
  },
  {
    "text": "house to see if you know the tumor by doing a scan it's used in fraud",
    "start": "187780",
    "end": "193840"
  },
  {
    "text": "detection so if you really don't travel abroad and suddenly your credit card is",
    "start": "193840",
    "end": "200109"
  },
  {
    "text": "used in a different country then that chunk section is likely to be rejected",
    "start": "200109",
    "end": "205750"
  },
  {
    "text": "and then until you confirm that it is really new then you wouldn't be able to",
    "start": "205750",
    "end": "211000"
  },
  {
    "text": "use your credit card and it's used in fault detection to Detective knows any",
    "start": "211000",
    "end": "217659"
  },
  {
    "text": "problem in your medical unit like a newly puter aircraft and of course it's",
    "start": "217659",
    "end": "224889"
  },
  {
    "text": "used in storage to find even or any problem in store systems for example to",
    "start": "224889",
    "end": "230650"
  },
  {
    "text": "check if the SSD has worn out and needs to be replaced and it's used to find",
    "start": "230650",
    "end": "239199"
  },
  {
    "text": "issues in storage performance as well so",
    "start": "239199",
    "end": "246900"
  },
  {
    "start": "244000",
    "end": "244000"
  },
  {
    "text": "it's challenging to detect issues in story performance because many things",
    "start": "246900",
    "end": "254889"
  },
  {
    "text": "can go wrong you could have these failures you could have a rewrite i/o",
    "start": "254889",
    "end": "260949"
  },
  {
    "text": "arose or some port problems configuration issues",
    "start": "260949",
    "end": "266360"
  },
  {
    "text": "that were problems so we need to look at metrics collected from different ways",
    "start": "266360",
    "end": "273590"
  },
  {
    "text": "look at the IRS penguin and they look at",
    "start": "273590",
    "end": "278750"
  },
  {
    "text": "the cash head and so on we need to collect data from multiple dimensions",
    "start": "278750",
    "end": "284240"
  },
  {
    "text": "and correlate them and identify bottlenecks so that's what we are trying",
    "start": "284240",
    "end": "289669"
  },
  {
    "text": "to do we're trying to collect metrics on storage performance and trying to detect",
    "start": "289669",
    "end": "294800"
  },
  {
    "text": "anomalies within those data talk about",
    "start": "294800",
    "end": "299870"
  },
  {
    "text": "use cases the number of services we",
    "start": "299870",
    "end": "314750"
  },
  {
    "start": "306000",
    "end": "306000"
  },
  {
    "text": "providing is about 100 in our data",
    "start": "314750",
    "end": "319789"
  },
  {
    "text": "centers many virtual machines and continuous running 140,000 dreams are in",
    "start": "319789",
    "end": "328460"
  },
  {
    "text": "infrastructure-as-a-service 30,000 containers in platform-as-a-service and 390 carbonated",
    "start": "328460",
    "end": "337370"
  },
  {
    "text": "clusters in container as a service in",
    "start": "337370",
    "end": "345080"
  },
  {
    "start": "342000",
    "end": "342000"
  },
  {
    "text": "OpenStack environment we are using storage it's for cinder Swift Manila in",
    "start": "345080",
    "end": "350960"
  },
  {
    "text": "kubernetes environment we we are using",
    "start": "350960",
    "end": "356210"
  },
  {
    "text": "strategies for persistence volume OpenStack in kubernetes classes have",
    "start": "356210",
    "end": "361849"
  },
  {
    "text": "each stretch so if the number of addresses is increases the number of",
    "start": "361849",
    "end": "367699"
  },
  {
    "text": "stress also increases and moreover there is in there is bias in in all there is",
    "start": "367699",
    "end": "378199"
  },
  {
    "text": "bias in kubernetes class in capacity between OpenStack our cumulative classes",
    "start": "378199",
    "end": "384580"
  },
  {
    "text": "this means some clusters have enough capacity in a pre capacity in storage",
    "start": "384580",
    "end": "392180"
  },
  {
    "text": "but some clusters have not enough free capacity in storage",
    "start": "392180",
    "end": "397479"
  },
  {
    "start": "400000",
    "end": "400000"
  },
  {
    "text": "in future we have we hope the money straight century by open th the",
    "start": "400779",
    "end": "408469"
  },
  {
    "text": "strangest managed by one open theists cluster can be used by multiple OpenStack and kubernetes pilasters",
    "start": "408469",
    "end": "416319"
  },
  {
    "text": "then if chemistry and animal detection are managed by open SDS stretch",
    "start": "416319",
    "end": "423259"
  },
  {
    "text": "management becomes very simple recently",
    "start": "423259",
    "end": "432289"
  },
  {
    "start": "428000",
    "end": "428000"
  },
  {
    "text": "we are using software-defined storage such as safe and provide now we are",
    "start": "432289",
    "end": "440810"
  },
  {
    "text": "experiencing that SDS is difficult to operate SDS is configured by distributed",
    "start": "440810",
    "end": "448189"
  },
  {
    "text": "system it is very important clustering SDS servers so we should",
    "start": "448189",
    "end": "455930"
  },
  {
    "text": "manage ciliary the health of servers networks and so on this means telemetry",
    "start": "455930",
    "end": "463399"
  },
  {
    "text": "and anomaly detection is very important function for operating SDS so tacky Sam",
    "start": "463399",
    "end": "475430"
  },
  {
    "start": "472000",
    "end": "472000"
  },
  {
    "text": "has talked about it use cases and then they want to use the colony tree and the anomaly detection of open ideas the open",
    "start": "475430",
    "end": "483319"
  },
  {
    "text": "SDS is an open autonomous data platform so this shows the project scope soon as",
    "start": "483319",
    "end": "490279"
  },
  {
    "text": "the northbound plug-in to support container orchestration systems and it provides the common control plane to",
    "start": "490279",
    "end": "497270"
  },
  {
    "text": "manage log file and object storage our focus today is walk hairs inside and the",
    "start": "497270",
    "end": "508849"
  },
  {
    "text": "intelligence service this shows a road to autonomous data",
    "start": "508849",
    "end": "517068"
  },
  {
    "start": "513000",
    "end": "513000"
  },
  {
    "text": "platform so under each stage what we want to achieve right now we are at the",
    "start": "517069",
    "end": "523940"
  },
  {
    "text": "first stage so we are working on telemetry and the anomaly detection collecting match",
    "start": "523940",
    "end": "529730"
  },
  {
    "text": "from different stores back hands and doing analysis on them and eventually we",
    "start": "529730",
    "end": "537620"
  },
  {
    "text": "want to view a is a platform that is self managing and self optimizing this",
    "start": "537620",
    "end": "546890"
  },
  {
    "text": "is the architecture diagram of how naturey so here we have a API server",
    "start": "546890",
    "end": "553750"
  },
  {
    "text": "that has a post and get it nice and then",
    "start": "553750",
    "end": "559790"
  },
  {
    "text": "is a controller and then of the talk that is like a docking station at hosts",
    "start": "559790",
    "end": "567140"
  },
  {
    "text": "metrics drivers for lbn staff and other third party metrics drivers on the dock",
    "start": "567140",
    "end": "574160"
  },
  {
    "text": "there is a collector collector collect",
    "start": "574160",
    "end": "579980"
  },
  {
    "text": "metrics from different metrics drivers and then that data will be then to will",
    "start": "579980",
    "end": "589880"
  },
  {
    "text": "go here this is know the adapter here that includes a converter and exporter so converter basically converts the",
    "start": "589880",
    "end": "596960"
  },
  {
    "text": "matrix into a format that can be understood by the destination and exporter and it's the data in a format",
    "start": "596960",
    "end": "607010"
  },
  {
    "text": "that can be we retrieved by the destination so like Prometheus we also",
    "start": "607010",
    "end": "613310"
  },
  {
    "text": "have integration with the popke metrics",
    "start": "613310",
    "end": "622010"
  },
  {
    "start": "620000",
    "end": "620000"
  },
  {
    "text": "quarter gets iOS bandwidth latency CPU usage and custom metrics for volume per",
    "start": "622010",
    "end": "628490"
  },
  {
    "text": "disk controller resources for example I opted of Orion and Vaughn beast of disks",
    "start": "628490",
    "end": "637580"
  },
  {
    "text": "and so on on premise bridge the on premise threads such as direct attach",
    "start": "637580",
    "end": "644060"
  },
  {
    "text": "software design invite Enterprise is supported and also cross bridge such as",
    "start": "644060",
    "end": "651070"
  },
  {
    "text": "safest we get--we AWS a dual Google cloud platform is also supported",
    "start": "651070",
    "end": "658330"
  },
  {
    "start": "659000",
    "end": "659000"
  },
  {
    "text": "since we integrated with the Prometheus I just want to quickly go through this Prometheus a potential diagram",
    "start": "659760",
    "end": "666090"
  },
  {
    "text": "prometheus as a server that includes three components is the retrieval",
    "start": "666090",
    "end": "672460"
  },
  {
    "text": "component that periodically scrapes data frying HTTP endpoint copy girl on the",
    "start": "672460",
    "end": "680740"
  },
  {
    "text": "exporter and then saves dad in the database which is this a TSG database",
    "start": "680740",
    "end": "686339"
  },
  {
    "text": "saves the matrix with a timestamp and then the third component is this HTTP",
    "start": "686339",
    "end": "692830"
  },
  {
    "text": "server that can handle HTTP based requests using prompt you out which is",
    "start": "692830",
    "end": "700630"
  },
  {
    "text": "the Prometheus security language and then also a permit it has a alert",
    "start": "700630",
    "end": "706029"
  },
  {
    "text": "manager so this shows a little bit",
    "start": "706029",
    "end": "712540"
  },
  {
    "text": "detail of our tell me trees integration with Prometheus so if it's a close-in",
    "start": "712540",
    "end": "719620"
  },
  {
    "text": "request API server gets it pass on to the controller controller we'll send",
    "start": "719620",
    "end": "725560"
  },
  {
    "text": "that you the collector from the collector communicates with the MAGIX drivers data matrix and then the",
    "start": "725560",
    "end": "734650"
  },
  {
    "text": "exporter will emit that matrix Prometheus server will be pulling those",
    "start": "734650",
    "end": "740410"
  },
  {
    "text": "metrics and if it's a get request so",
    "start": "740410",
    "end": "746740"
  },
  {
    "text": "that assumes the data the metrics is already there in a primitive liver disease so the controller registered",
    "start": "746740",
    "end": "753970"
  },
  {
    "text": "your conversion using the prom pol and get that metrics from the",
    "start": "753970",
    "end": "761350"
  },
  {
    "text": "Prometheus server so tell me Jim what it doesn't have a database itself we just",
    "start": "761350",
    "end": "766660"
  },
  {
    "text": "use the database in Prometheus but our own on detection what it does have a bit",
    "start": "766660",
    "end": "772780"
  },
  {
    "text": "of database which I will cover in the later defined you like this type of",
    "start": "772780",
    "end": "786370"
  },
  {
    "start": "777000",
    "end": "777000"
  },
  {
    "text": "driver such as LVM set and so on get matrix fit as SSID image",
    "start": "786370",
    "end": "793420"
  },
  {
    "text": "name start time and end time in society is volume ID in example swap matrix that",
    "start": "793420",
    "end": "801580"
  },
  {
    "text": "has instanceid it was named job another component name unique aggregate",
    "start": "801580",
    "end": "808480"
  },
  {
    "text": "type and metric both bodies after metrics is cert me trick it had it has",
    "start": "808480",
    "end": "814840"
  },
  {
    "text": "only time stamp and value there is a",
    "start": "814840",
    "end": "822040"
  },
  {
    "start": "819000",
    "end": "819000"
  },
  {
    "text": "briam exporter in obviously s to correct every matrix a VM exporter you this VM",
    "start": "822040",
    "end": "828190"
  },
  {
    "text": "system activity reporter and I or sat in it's not spotted matrix in country I",
    "start": "828190",
    "end": "834190"
  },
  {
    "text": "hope Street throughput for its report results I'm satisfied and utilization",
    "start": "834190",
    "end": "839350"
  },
  {
    "text": "percentage for volume and disk resources",
    "start": "839350",
    "end": "844589"
  },
  {
    "start": "846000",
    "end": "846000"
  },
  {
    "text": "instead the set father is already exist in primitive website in this thing set",
    "start": "847470",
    "end": "854560"
  },
  {
    "text": "its folder in context is used to correct step metrics only crosser metric matrix",
    "start": "854560",
    "end": "863350"
  },
  {
    "text": "is printed in slide as supported matrix because the site has no enough space but",
    "start": "863350",
    "end": "868720"
  },
  {
    "text": "others matrix can be corrected third volume step components such as OSD",
    "start": "868720",
    "end": "874960"
  },
  {
    "text": "monitor and so on you safe environment so many kinds of metrics are supported",
    "start": "874960",
    "end": "882990"
  },
  {
    "start": "883000",
    "end": "883000"
  },
  {
    "text": "this picture is a VM metrics focus in last six hours in Rapala dashboard this",
    "start": "884910",
    "end": "892060"
  },
  {
    "text": "matrix is corrected by LVM exporter being open yet areum volume is over",
    "start": "892060",
    "end": "900790"
  },
  {
    "text": "utilization response time by throughput with Rupert I opt and service time our",
    "start": "900790",
    "end": "906520"
  },
  {
    "text": "press this picture is VM biometrics focus ring",
    "start": "906520",
    "end": "915220"
  },
  {
    "text": "so they means they are input and output in a VM volume about ten minutes going",
    "start": "915220",
    "end": "927700"
  },
  {
    "start": "926000",
    "end": "926000"
  },
  {
    "text": "back to you this diagram so our canvas module export the matches and then",
    "start": "927700",
    "end": "933520"
  },
  {
    "text": "Prometheus where we achieve those metrics Prometheus also had to alert manager so you can use the Prometheus of",
    "start": "933520",
    "end": "942670"
  },
  {
    "start": "939000",
    "end": "939000"
  },
  {
    "text": "our major in two ways you can configure a lot of rules in Prometheus and then",
    "start": "942670",
    "end": "948460"
  },
  {
    "text": "when it passes the threshold Prometheus worries an alert on the other manager so",
    "start": "948460",
    "end": "954520"
  },
  {
    "text": "I think this example showing here needs maybe code you see by this one disk",
    "start": "954520",
    "end": "959590"
  },
  {
    "text": "space 10% free then always an alert and then the second way is to use the REST",
    "start": "959590",
    "end": "966580"
  },
  {
    "text": "API interface of our manager you can retain custom alert so our anomaly",
    "start": "966580",
    "end": "971680"
  },
  {
    "text": "detection motor uses that so the example shown here that's the thing this running",
    "start": "971680",
    "end": "977680"
  },
  {
    "text": "for that's a custom so well we have an",
    "start": "977680",
    "end": "985030"
  },
  {
    "text": "adapter that will also send data through Kafka which will be received by the",
    "start": "985030",
    "end": "991140"
  },
  {
    "text": "anomaly detection it is just the architecture diagram of",
    "start": "991140",
    "end": "997500"
  },
  {
    "start": "995000",
    "end": "995000"
  },
  {
    "text": "anon detection so the metrics collected",
    "start": "997500",
    "end": "1003570"
  },
  {
    "text": "will go through popke sent you the data passer component data parser will pass",
    "start": "1003570",
    "end": "1009900"
  },
  {
    "text": "data and save the data in the database and we also have a data generator",
    "start": "1009900",
    "end": "1015720"
  },
  {
    "text": "component that runs cron jobs that can be configured can get around post or get",
    "start": "1015720",
    "end": "1021540"
  },
  {
    "text": "request and the gathers data from the telemetry module and the training",
    "start": "1021540",
    "end": "1029579"
  },
  {
    "text": "service will use data from the database from different algorithms and people",
    "start": "1029580",
    "end": "1036120"
  },
  {
    "text": "opt-in model and then the partition prediction servers were using that selecting model",
    "start": "1036120",
    "end": "1042209"
  },
  {
    "text": "to run analysis and produce results and anomalies if a anonyme are detected it",
    "start": "1042209",
    "end": "1051330"
  },
  {
    "text": "can send an post request to the telemetry and tell me she will send an",
    "start": "1051330",
    "end": "1058679"
  },
  {
    "text": "alert to the or a manager there are",
    "start": "1058679",
    "end": "1065880"
  },
  {
    "start": "1064000",
    "end": "1064000"
  },
  {
    "text": "different algorithms used in anomaly detection means the classification based",
    "start": "1065880",
    "end": "1073070"
  },
  {
    "text": "it basically uses in a classifier to distinguish between normal and abnormal",
    "start": "1073070",
    "end": "1078390"
  },
  {
    "text": "data points there is a nearest neighbor based algorithm which assumes normal",
    "start": "1078390",
    "end": "1084390"
  },
  {
    "text": "data reside in a cluster in a a neighborhood and then the anomalies",
    "start": "1084390",
    "end": "1090600"
  },
  {
    "text": "occur in place far away from closest neighborhood and then there's a",
    "start": "1090600",
    "end": "1096750"
  },
  {
    "text": "clustering based assuming that normal data beside in a cluster and then the",
    "start": "1096750",
    "end": "1103039"
  },
  {
    "text": "anonymous stare points does not beam onto any plaster and they're also",
    "start": "1103039",
    "end": "1108230"
  },
  {
    "text": "statistical models like caution and regression and also information",
    "start": "1108230",
    "end": "1113340"
  },
  {
    "text": "theoretic and the spectral so we are going to use the classroom based",
    "start": "1113340",
    "end": "1119549"
  },
  {
    "text": "algorithm quality beats again and the Gaussian model in our testing so a",
    "start": "1119549",
    "end": "1128820"
  },
  {
    "text": "Gaussian model is the classic of statistical model assumes that data",
    "start": "1128820",
    "end": "1134210"
  },
  {
    "text": "forms in this bow shape and you should use a to specify a threshold to",
    "start": "1134210",
    "end": "1141240"
  },
  {
    "text": "differentiate between your normal data points and anomalies and DP skin means",
    "start": "1141240",
    "end": "1151289"
  },
  {
    "start": "1148000",
    "end": "1148000"
  },
  {
    "text": "the density faces spaceship posturing application with noise so we have a",
    "start": "1151289",
    "end": "1156590"
  },
  {
    "text": "diagram here so carefully the DB scan",
    "start": "1156590",
    "end": "1162270"
  },
  {
    "text": "algorithm takes two input 1 is the radius of the neighborhood around the",
    "start": "1162270",
    "end": "1169649"
  },
  {
    "text": "core point and then the second one is the minimum data points in the cluster",
    "start": "1169649",
    "end": "1174970"
  },
  {
    "text": "and then based on this two input parameters it divides the data into three categories core points for the",
    "start": "1174970",
    "end": "1182800"
  },
  {
    "text": "points and outlier so this is a blue",
    "start": "1182800",
    "end": "1189670"
  },
  {
    "text": "thought in the middle here that's a core point because it is in cluster with more",
    "start": "1189670",
    "end": "1196000"
  },
  {
    "text": "than five data points and then the green dot there is a order point because it is",
    "start": "1196000",
    "end": "1202570"
  },
  {
    "text": "in a cluster of the less than five data points and then the red one is an outlier because it is not in the cluster",
    "start": "1202570",
    "end": "1210550"
  },
  {
    "text": "with any other data points so we run the",
    "start": "1210550",
    "end": "1218920"
  },
  {
    "start": "1215000",
    "end": "1215000"
  },
  {
    "text": "Gaussian model ways the data we collected from lbn so we collected 60",
    "start": "1218920",
    "end": "1226390"
  },
  {
    "text": "tons and that tricks from lbn but to be only use the - to show this it's easier to display here so we use the volume",
    "start": "1226390",
    "end": "1233380"
  },
  {
    "text": "level metrics IAP sender latency here so we run we run the reverse it collected",
    "start": "1233380",
    "end": "1242560"
  },
  {
    "text": "back in two days and then we got six thousand data points after the movie",
    "start": "1242560",
    "end": "1249430"
  },
  {
    "text": "from zeros and then we also use the TV and then we use the boney to generate",
    "start": "1249430",
    "end": "1255490"
  },
  {
    "text": "some workloads so yet so the blue data point those are in the those those are",
    "start": "1255490",
    "end": "1265420"
  },
  {
    "text": "normal data points and then the red ones are a liar and then this is the from the",
    "start": "1265420",
    "end": "1276730"
  },
  {
    "text": "Devi scan using the exact same data so this shows so the the bigger story in",
    "start": "1276730",
    "end": "1284710"
  },
  {
    "text": "red those are core point and the small point in red that's the water point and",
    "start": "1284710",
    "end": "1293320"
  },
  {
    "text": "the black dots are anomalies so this actually looks a little similar to this",
    "start": "1293320",
    "end": "1301300"
  },
  {
    "text": "the shape of it it's a little similar so there are some anomalies detected",
    "start": "1301300",
    "end": "1306920"
  },
  {
    "text": "actually some architect on impose figures but some are different we also",
    "start": "1306920",
    "end": "1317320"
  },
  {
    "text": "run those tests using SEF so we set up kubernetes cluster and we have a open",
    "start": "1317320",
    "end": "1325760"
  },
  {
    "text": "STS in store there and then also set up a MongoDB so MongoDB is running as a",
    "start": "1325760",
    "end": "1333620"
  },
  {
    "text": "staple set there's a 3d graphic class and it is running a avoiding provision",
    "start": "1333620",
    "end": "1341360"
  },
  {
    "text": "to buy open access yes that plug-in and the pack can use that so yes it sure is",
    "start": "1341360",
    "end": "1348860"
  },
  {
    "text": "just sort of class is that ok it's a plugin and then we collect metrics from the SAP exporter node X quarter and the",
    "start": "1348860",
    "end": "1356300"
  },
  {
    "text": " DB exporter so this is what we get",
    "start": "1356300",
    "end": "1362960"
  },
  {
    "start": "1360000",
    "end": "1360000"
  },
  {
    "text": "from Seth so we don't have enough time to get more data so this is like 6 hours",
    "start": "1362960",
    "end": "1370420"
  },
  {
    "text": "then we got a six thousand data points after removing zeros and we used two",
    "start": "1370420",
    "end": "1378500"
  },
  {
    "text": "different MongoDB Papa means to us why is the workload driver the other is a",
    "start": "1378500",
    "end": "1383830"
  },
  {
    "text": "MongoDB motif Friday the proponent test tool will use those to generate some",
    "start": "1383830",
    "end": "1390170"
  },
  {
    "text": "more clothes to you to you some invert deleting update and find so we get five",
    "start": "1390170",
    "end": "1397130"
  },
  {
    "text": "clusters here but most of them are three in one large cluster that's in the color",
    "start": "1397130",
    "end": "1404810"
  },
  {
    "text": "the red color the rest of them so like there's some smaller class lettuces",
    "start": "1404810",
    "end": "1410270"
  },
  {
    "text": "yellow orange and green there's a smaller classroom and also them are at the bottom so there are a small number",
    "start": "1410270",
    "end": "1416960"
  },
  {
    "text": "of what are some anonymous anonymous data point those are the black dots",
    "start": "1416960",
    "end": "1423110"
  },
  {
    "text": "there so this is actually the same the same",
    "start": "1423110",
    "end": "1433150"
  },
  {
    "text": "data but this is just a one section of that this is the only one thousand data points so when we use this if just the",
    "start": "1433150",
    "end": "1441100"
  },
  {
    "text": "company has one cluster and then they are most of them are in this one cluster",
    "start": "1441100",
    "end": "1447430"
  },
  {
    "text": "and then there are some the black data points those are those are anomalies and the by the way this is the SEC line",
    "start": "1447430",
    "end": "1455350"
  },
  {
    "text": "at UPS because we don't get the the water level proposed metrics that will",
    "start": "1455350",
    "end": "1460480"
  },
  {
    "text": "be used for lbn so for staff we just use the sequoia ops and this is a data",
    "start": "1460480",
    "end": "1472780"
  },
  {
    "start": "1469000",
    "end": "1469000"
  },
  {
    "text": "collected from the node exporter this is the node memory available in megabytes",
    "start": "1472780",
    "end": "1478870"
  },
  {
    "text": "so this also shows just one large cluster and then there's small number of",
    "start": "1478870",
    "end": "1485580"
  },
  {
    "text": "anonymous data points so this is from",
    "start": "1485580",
    "end": "1491320"
  },
  {
    "text": "MongoDB this is the global log current queue this is actually not what happen",
    "start": "1491320",
    "end": "1497380"
  },
  {
    "text": "if left expected because there is a gap there so it forms two clusters and then",
    "start": "1497380",
    "end": "1502840"
  },
  {
    "text": "there was a few anonymous data points so my assumption is because we generally",
    "start": "1502840",
    "end": "1510070"
  },
  {
    "text": "allotted for load maybe the system cannot handle it and said the some reason it was no data for some section",
    "start": "1510070",
    "end": "1518680"
  },
  {
    "text": "of the time is going to show a demo in",
    "start": "1518680",
    "end": "1526810"
  },
  {
    "text": "family tree our private cloud and I",
    "start": "1526810",
    "end": "1533440"
  },
  {
    "text": "capture this movie this is obviously s dashboard",
    "start": "1533440",
    "end": "1539730"
  },
  {
    "text": "it has monitored",
    "start": "1540120",
    "end": "1544890"
  },
  {
    "text": "in from here sitting there is the FMX Porter",
    "start": "1551240",
    "end": "1557830"
  },
  {
    "text": "jumpers to grapnel dashboard the metrics",
    "start": "1566670",
    "end": "1573810"
  },
  {
    "text": "of we strip it and write throughput and I up and this most time is our press",
    "start": "1573810",
    "end": "1581430"
  },
  {
    "text": "here and show the volume information",
    "start": "1581430",
    "end": "1588830"
  },
  {
    "text": "using operation is command",
    "start": "1588830",
    "end": "1593179"
  },
  {
    "text": "read from every available using needy",
    "start": "1603650",
    "end": "1612490"
  },
  {
    "text": "back to your dashboard as you can see ray throughput eating praises",
    "start": "1639790",
    "end": "1647040"
  },
  {
    "text": "jump to a lot manager dashboard there is",
    "start": "1675840",
    "end": "1682229"
  },
  {
    "text": "no there's no a lot of country next",
    "start": "1682229",
    "end": "1688789"
  },
  {
    "text": "right to VM volume using VD in a lot",
    "start": "1688789",
    "end": "1695460"
  },
  {
    "text": "manager sitting I set the right to repeat a lot for VM if the boring writes",
    "start": "1695460",
    "end": "1701999"
  },
  {
    "text": "throughput is overwhelming byte per second the era is over",
    "start": "1701999",
    "end": "1707868"
  },
  {
    "text": "vice Miriam volume you baby",
    "start": "1736960",
    "end": "1741090"
  },
  {
    "text": "already the vice triplet is over the warming byte per second burst in johanna",
    "start": "1761960",
    "end": "1769160"
  },
  {
    "text": "dashboard as you can see the rice triplet is increasing",
    "start": "1769160",
    "end": "1775630"
  },
  {
    "text": "in that manager yeah he's a very put",
    "start": "1784750",
    "end": "1791140"
  },
  {
    "text": "alert because the abri rights repeat is overwhelming up one megabyte per second",
    "start": "1791140",
    "end": "1798899"
  },
  {
    "text": "the demo is old",
    "start": "1802440",
    "end": "1806100"
  },
  {
    "start": "1809000",
    "end": "1809000"
  },
  {
    "text": "so what are we are going to do next we of course need to collect more data so",
    "start": "1810930",
    "end": "1817170"
  },
  {
    "text": "we can get some good results and we want to correlate the metrics the collapse",
    "start": "1817170",
    "end": "1823320"
  },
  {
    "text": "data from the store to back-end from the node exporter and from applications and trying to find out the",
    "start": "1823320",
    "end": "1831630"
  },
  {
    "text": "problems using this data and there are some other algorithms that we can",
    "start": "1831630",
    "end": "1836760"
  },
  {
    "text": "consider in the future like random forests and the autoregressive integrated moving average and so on and",
    "start": "1836760",
    "end": "1843830"
  },
  {
    "text": "we'll continue the journey to the autonomous to data platform so as I said",
    "start": "1843830",
    "end": "1852810"
  },
  {
    "text": "earlier we are right now at the early stage the first stage so eventually we're hoping to build a data platform",
    "start": "1852810",
    "end": "1859910"
  },
  {
    "text": "that is self managing and self optimizing thank you are there any",
    "start": "1859910",
    "end": "1872670"
  },
  {
    "text": "questions",
    "start": "1872670",
    "end": "1874790"
  },
  {
    "text": "people talk it's really interesting we are we are also working on the animal",
    "start": "1882680",
    "end": "1887690"
  },
  {
    "text": "attraction in Red Hat so I would be interested whether you're tooling that",
    "start": "1887690",
    "end": "1893240"
  },
  {
    "text": "you showed the whole system from issues and the animal detection training except how general it is how reusable it is for",
    "start": "1893240",
    "end": "1902150"
  },
  {
    "text": "different kinds of metrics maybe not just storage or combining metrics from",
    "start": "1902150",
    "end": "1907220"
  },
  {
    "text": "storage and other metrics from the cluster for Prince Buster and applications and stuff like that if",
    "start": "1907220",
    "end": "1914120"
  },
  {
    "text": "there is a potential for reusing it for other use cases as well yeah so right",
    "start": "1914120",
    "end": "1922700"
  },
  {
    "text": "now we have just a focus on storage so whatever collecting on keep I switch it back in but I also mentioned that we are",
    "start": "1922700",
    "end": "1928370"
  },
  {
    "text": "also trying to collect matches from application like the MongoDB right yeah so so we and I was fond note exporter so",
    "start": "1928370",
    "end": "1935060"
  },
  {
    "text": "we do like to look at the data from different angle try to correlate them",
    "start": "1935060",
    "end": "1942970"
  },
  {
    "text": "as I know from astok ruefully want my father to again aiyyo aiyyo for process",
    "start": "1957720",
    "end": "1965640"
  },
  {
    "text": "so and yes yes we consider how to limit",
    "start": "1965640",
    "end": "1970950"
  },
  {
    "text": "you I will appear before the limited I",
    "start": "1970950",
    "end": "1976920"
  },
  {
    "text": "are yeah yeah so yeah no we haven't really get you backstage here so what",
    "start": "1976920",
    "end": "1982620"
  },
  {
    "text": "are we you what do we have right now it's a suggest that you collect metrics and then the root cause analysis will be",
    "start": "1982620",
    "end": "1988650"
  },
  {
    "text": "coming next and in trying to find out problems and then trying to figure out how to improve the system that will come",
    "start": "1988650",
    "end": "1996090"
  },
  {
    "text": "next so we haven't really get you at that point",
    "start": "1996090",
    "end": "2000370"
  },
  {
    "text": "yeah so that's a second yeah so uh yeah definitely we will get there so but we",
    "start": "2001510",
    "end": "2007100"
  },
  {
    "text": "are really not the idea so if you look at here as though we are right now are right here so just to collecting the",
    "start": "2007100",
    "end": "2012679"
  },
  {
    "text": "data but then you know anomaly so that's the next so how what do you do with those",
    "start": "2012679",
    "end": "2018919"
  },
  {
    "text": "data right so that right now we are just stood at the data collect collected and we got alerts and then but I definitely",
    "start": "2018919",
    "end": "2025070"
  },
  {
    "text": "get your point that's actually the more important because could get to too much data and what are you gonna do is there",
    "start": "2025070",
    "end": "2031549"
  },
  {
    "text": "as I said very important yes but we wasn't looking to that next I mean just",
    "start": "2031549",
    "end": "2037910"
  },
  {
    "text": "the hell out here so I think Christmases",
    "start": "2037910",
    "end": "2050388"
  },
  {
    "text": "for cotton cover story to production",
    "start": "2050389",
    "end": "2055929"
  },
  {
    "text": "okay",
    "start": "2056590",
    "end": "2059590"
  },
  {
    "text": "okay come some more thanks everyone",
    "start": "2063419",
    "end": "2069000"
  }
]
[
  {
    "text": "hello everyone my name is l",
    "start": "120",
    "end": "2760"
  },
  {
    "text": "froms today my colleag f and I",
    "start": "2760",
    "end": "5839"
  },
  {
    "text": "introduced the project f l which are we",
    "start": "5839",
    "end": "8679"
  },
  {
    "text": "are working on the L Foundation Ai and",
    "start": "8679",
    "end": "11040"
  },
  {
    "text": "data Community wait and going to empower",
    "start": "11040",
    "end": "14160"
  },
  {
    "text": "the large model with Better Learning",
    "start": "14160",
    "end": "16600"
  },
  {
    "text": "this is wi use framework influencial and",
    "start": "16600",
    "end": "19000"
  },
  {
    "text": "telecomunication",
    "start": "19000",
    "end": "19990"
  },
  {
    "text": "[Music]",
    "start": "19990",
    "end": "22320"
  },
  {
    "text": "Company so first of all I wonder how",
    "start": "22320",
    "end": "25199"
  },
  {
    "text": "many people here heard of f learning",
    "start": "25199",
    "end": "27400"
  },
  {
    "text": "before F learning is generally consider",
    "start": "27400",
    "end": "30480"
  },
  {
    "text": "raised by Google from his Brock F",
    "start": "30480",
    "end": "33440"
  },
  {
    "text": "learning collaborative machine Learning",
    "start": "33440",
    "end": "35399"
  },
  {
    "text": "Without centralized data he proposed a",
    "start": "35399",
    "end": "38960"
  },
  {
    "text": "method to chain a model in users cell",
    "start": "38960",
    "end": "41399"
  },
  {
    "text": "phones but doesn't need to collect all",
    "start": "41399",
    "end": "43440"
  },
  {
    "text": "data from cell phones in a center",
    "start": "43440",
    "end": "47800"
  },
  {
    "text": "place this method is L complex in the",
    "start": "48440",
    "end": "52640"
  },
  {
    "text": "vedia it is C describe to four steps",
    "start": "52640",
    "end": "56480"
  },
  {
    "text": "first from the central server choose a",
    "start": "56480",
    "end": "58920"
  },
  {
    "text": "model then send the model to clients as",
    "start": "58920",
    "end": "62000"
  },
  {
    "text": "the initial model Let each client change",
    "start": "62000",
    "end": "64760"
  },
  {
    "text": "each model with local data on the client",
    "start": "64760",
    "end": "67560"
  },
  {
    "text": "side lastly after several efforts each",
    "start": "67560",
    "end": "71240"
  },
  {
    "text": "client get a change model and then send",
    "start": "71240",
    "end": "74680"
  },
  {
    "text": "back to the central service for aing",
    "start": "74680",
    "end": "78040"
  },
  {
    "text": "then we repeat the second to the four",
    "start": "78040",
    "end": "80880"
  },
  {
    "text": "steps until we get a fi Global model",
    "start": "80880",
    "end": "84159"
  },
  {
    "text": "this is a very basic Pro of course for",
    "start": "84159",
    "end": "87079"
  },
  {
    "text": "private preserving cases or L ID cases",
    "start": "87079",
    "end": "91079"
  },
  {
    "text": "there are many different algorithm",
    "start": "91079",
    "end": "92759"
  },
  {
    "text": "deside and during the",
    "start": "92759",
    "end": "95680"
  },
  {
    "text": "FL the original case is uh device case",
    "start": "95680",
    "end": "100520"
  },
  {
    "text": "but obviously it can extend to different",
    "start": "100520",
    "end": "103439"
  },
  {
    "text": "organization in a global",
    "start": "103439",
    "end": "107439"
  },
  {
    "text": "Enterprise and then we can Invision a",
    "start": "107479",
    "end": "110600"
  },
  {
    "text": "bigger scenario how about different",
    "start": "110600",
    "end": "113439"
  },
  {
    "text": "company coroporate for example an",
    "start": "113439",
    "end": "116439"
  },
  {
    "text": "interet company and a bank an insurance",
    "start": "116439",
    "end": "118880"
  },
  {
    "text": "company and a communication carrier ET",
    "start": "118880",
    "end": "122560"
  },
  {
    "text": "that data can complement for better",
    "start": "122560",
    "end": "124600"
  },
  {
    "text": "modeling with data centralization and",
    "start": "124600",
    "end": "127280"
  },
  {
    "text": "also able to prevent privacy leakage",
    "start": "127280",
    "end": "130399"
  },
  {
    "text": "with some differential privacy or emby",
    "start": "130399",
    "end": "133879"
  },
  {
    "text": "OPM and during the fair",
    "start": "133879",
    "end": "138120"
  },
  {
    "text": "learning based on this reband initial",
    "start": "139200",
    "end": "142440"
  },
  {
    "text": "and Industrial F Ling plan work",
    "start": "142440",
    "end": "145879"
  },
  {
    "text": "fake for empowering the bank models with",
    "start": "145879",
    "end": "149840"
  },
  {
    "text": "intet company data compliantly this",
    "start": "149840",
    "end": "153080"
  },
  {
    "text": "flavor is developed and driven in",
    "start": "153080",
    "end": "155360"
  },
  {
    "text": "community and then it is contributed to",
    "start": "155360",
    "end": "158560"
  },
  {
    "text": "the L Foundation Ai and data now fake is",
    "start": "158560",
    "end": "162400"
  },
  {
    "text": "biggest industrial grade Open Source by",
    "start": "162400",
    "end": "165239"
  },
  {
    "text": "learing system in L Foundation Ai and",
    "start": "165239",
    "end": "167720"
  },
  {
    "text": "data there are over",
    "start": "167720",
    "end": "169959"
  },
  {
    "text": "4,000 Engineers participate in the",
    "start": "169959",
    "end": "172680"
  },
  {
    "text": "development and it is used in many bands",
    "start": "172680",
    "end": "175120"
  },
  {
    "text": "andal companies in production today wew",
    "start": "175120",
    "end": "179440"
  },
  {
    "text": "is also one of the key contributors to",
    "start": "179440",
    "end": "181840"
  },
  {
    "text": "this framework we are the technical",
    "start": "181840",
    "end": "184640"
  },
  {
    "text": "stealing Committee Member of bait we are",
    "start": "184640",
    "end": "187760"
  },
  {
    "text": "the maintainer of F and FM project and",
    "start": "187760",
    "end": "191040"
  },
  {
    "text": "the initial initiators of K F which may",
    "start": "191040",
    "end": "195400"
  },
  {
    "text": "F easier manage and provision in",
    "start": "195400",
    "end": "198560"
  },
  {
    "text": "kuties and fat LM which is based on C",
    "start": "198560",
    "end": "203040"
  },
  {
    "text": "and provides Better Learning life cycle",
    "start": "203040",
    "end": "207319"
  },
  {
    "text": "management then",
    "start": "208439",
    "end": "210200"
  },
  {
    "text": "the last uh keyword is LM as our title I",
    "start": "210200",
    "end": "215159"
  },
  {
    "text": "believe most people here must of LM",
    "start": "215159",
    "end": "217640"
  },
  {
    "text": "before because this is the hottest topic",
    "start": "217640",
    "end": "220360"
  },
  {
    "text": "this year this image is from the",
    "start": "220360",
    "end": "222920"
  },
  {
    "text": "presentation the AI dma it shows the CH",
    "start": "222920",
    "end": "226640"
  },
  {
    "text": "is the Fest platform or software that",
    "start": "226640",
    "end": "229439"
  },
  {
    "text": "achieve one thousand million user in",
    "start": "229439",
    "end": "233120"
  },
  {
    "text": "history much faster than Instagram",
    "start": "233120",
    "end": "236400"
  },
  {
    "text": "Facebook Twitter and other fam names",
    "start": "236400",
    "end": "241680"
  },
  {
    "text": "is amazing not like other machine",
    "start": "242760",
    "end": "245000"
  },
  {
    "text": "learning algorithm which are designed",
    "start": "245000",
    "end": "246599"
  },
  {
    "text": "for one purpose",
    "start": "246599",
    "end": "248519"
  },
  {
    "text": "lar model is some fighing uh the same",
    "start": "248519",
    "end": "253319"
  },
  {
    "text": "Foundation model can adapt to a wide",
    "start": "253319",
    "end": "255400"
  },
  {
    "text": "range of down stream task and if you",
    "start": "255400",
    "end": "258440"
  },
  {
    "text": "push harder the increase of the training",
    "start": "258440",
    "end": "261239"
  },
  {
    "text": "scale even so small cap we call this",
    "start": "261239",
    "end": "267040"
  },
  {
    "text": "emergent that may more room for",
    "start": "267040",
    "end": "272080"
  },
  {
    "text": "imination however trading a large model",
    "start": "272080",
    "end": "275479"
  },
  {
    "text": "is not easy it requires a large data to",
    "start": "275479",
    "end": "278080"
  },
  {
    "text": "be Chained and of course it need more",
    "start": "278080",
    "end": "280520"
  },
  {
    "text": "resource this table shows the surve of",
    "start": "280520",
    "end": "284000"
  },
  {
    "text": "data scale and the result to change the",
    "start": "284000",
    "end": "287039"
  },
  {
    "text": "mainstream large land model including",
    "start": "287039",
    "end": "289639"
  },
  {
    "text": "public and close Source ones some of",
    "start": "289639",
    "end": "292479"
  },
  {
    "text": "them use tho TB tokens and thousands of",
    "start": "292479",
    "end": "296240"
  },
  {
    "text": "GPU or TPU death cing",
    "start": "296240",
    "end": "301440"
  },
  {
    "text": "in another hand along with more data set",
    "start": "301440",
    "end": "305080"
  },
  {
    "text": "need to change a large model the high",
    "start": "305080",
    "end": "307400"
  },
  {
    "text": "quity public data is running out",
    "start": "307400",
    "end": "309520"
  },
  {
    "text": "according to the paper we will run out",
    "start": "309520",
    "end": "311960"
  },
  {
    "text": "of data or analysis of the limit of G",
    "start": "311960",
    "end": "315400"
  },
  {
    "text": "dat iners learning is best the high",
    "start": "315400",
    "end": "317840"
  },
  {
    "text": "quality training data will run out next",
    "start": "317840",
    "end": "320880"
  },
  {
    "text": "year moreover when the requirement needs",
    "start": "320880",
    "end": "324720"
  },
  {
    "text": "the large now model more fit to local",
    "start": "324720",
    "end": "327479"
  },
  {
    "text": "application it require more private data",
    "start": "327479",
    "end": "330120"
  },
  {
    "text": "as the trading data set so how to",
    "start": "330120",
    "end": "332600"
  },
  {
    "text": "protect privacy when we use private data",
    "start": "332600",
    "end": "335280"
  },
  {
    "text": "to trade a large L model for this",
    "start": "335280",
    "end": "338560"
  },
  {
    "text": "demands fated LM is raised this is why",
    "start": "338560",
    "end": "342240"
  },
  {
    "text": "we Dev the project F",
    "start": "342240",
    "end": "345560"
  },
  {
    "text": "LM but it is not easy we Face s obious",
    "start": "345560",
    "end": "350039"
  },
  {
    "text": "strategy the first strategy is as I dis",
    "start": "350039",
    "end": "353639"
  },
  {
    "text": "C before fa is collaboration cing",
    "start": "353639",
    "end": "356520"
  },
  {
    "text": "clients or even",
    "start": "356520",
    "end": "358479"
  },
  {
    "text": "inprise",
    "start": "358479",
    "end": "360160"
  },
  {
    "text": "uh through web and as I said before",
    "start": "360160",
    "end": "363080"
  },
  {
    "text": "training a large L model is require huge",
    "start": "363080",
    "end": "365520"
  },
  {
    "text": "data for training so how to exchange",
    "start": "365520",
    "end": "368080"
  },
  {
    "text": "such large scale data through well",
    "start": "368080",
    "end": "370280"
  },
  {
    "text": "during training and made the process in",
    "start": "370280",
    "end": "372919"
  },
  {
    "text": "an acceptable",
    "start": "372919",
    "end": "374090"
  },
  {
    "text": "[Music]",
    "start": "374090",
    "end": "375400"
  },
  {
    "text": "time the same change is as the table I",
    "start": "375400",
    "end": "379120"
  },
  {
    "text": "saw several slides before training a",
    "start": "379120",
    "end": "382000"
  },
  {
    "text": "large land model requires a huge",
    "start": "382000",
    "end": "383880"
  },
  {
    "text": "Computing resource however a lot of B",
    "start": "383880",
    "end": "386400"
  },
  {
    "text": "learning use Cas is L in the data center",
    "start": "386400",
    "end": "389160"
  },
  {
    "text": "but we need to change a local model in",
    "start": "389160",
    "end": "391400"
  },
  {
    "text": "the edge device or even iot device how",
    "start": "391400",
    "end": "394800"
  },
  {
    "text": "to change or fighten a large model in",
    "start": "394800",
    "end": "398199"
  },
  {
    "text": "his Junior participants with limit",
    "start": "398199",
    "end": "402960"
  },
  {
    "text": "resource it is not easy but we overcome",
    "start": "403000",
    "end": "406120"
  },
  {
    "text": "these strategies and build fith LM I",
    "start": "406120",
    "end": "409240"
  },
  {
    "text": "will let my colleag fan introduce how we",
    "start": "409240",
    "end": "412680"
  },
  {
    "text": "do it in the",
    "start": "412680",
    "end": "415560"
  },
  {
    "text": "project all right hi everyone so just",
    "start": "416280",
    "end": "419919"
  },
  {
    "text": "introduced to us the background of",
    "start": "419919",
    "end": "421759"
  },
  {
    "text": "Federate learning and large language",
    "start": "421759",
    "end": "423840"
  },
  {
    "text": "models and why we are attempting to",
    "start": "423840",
    "end": "426240"
  },
  {
    "text": "integrate Federate learning into this",
    "start": "426240",
    "end": "428520"
  },
  {
    "text": "training of these models so the",
    "start": "428520",
    "end": "430759"
  },
  {
    "text": "challenges he mentioned are indeed the",
    "start": "430759",
    "end": "432639"
  },
  {
    "text": "issues the industry is currently trying",
    "start": "432639",
    "end": "435160"
  },
  {
    "text": "to address so in the fith project we",
    "start": "435160",
    "end": "437720"
  },
  {
    "text": "have already implemented and are in the",
    "start": "437720",
    "end": "440199"
  },
  {
    "text": "process of implementing some of the",
    "start": "440199",
    "end": "442360"
  },
  {
    "text": "solutions to this challenges so all",
    "start": "442360",
    "end": "444960"
  },
  {
    "text": "these implementations we put them into",
    "start": "444960",
    "end": "447160"
  },
  {
    "text": "one of fit sub projects called",
    "start": "447160",
    "end": "450960"
  },
  {
    "text": "Faith so first let's take a look at some",
    "start": "450960",
    "end": "453960"
  },
  {
    "text": "of the proposed Solutions and approaches",
    "start": "453960",
    "end": "456319"
  },
  {
    "text": "in the industry to address these",
    "start": "456319",
    "end": "459840"
  },
  {
    "text": "challenges so let's start with the first",
    "start": "459840",
    "end": "462360"
  },
  {
    "text": "challenge which is that the model",
    "start": "462360",
    "end": "464599"
  },
  {
    "text": "parameter that being transmitted during",
    "start": "464599",
    "end": "467000"
  },
  {
    "text": "the Federate learning is too large so",
    "start": "467000",
    "end": "470440"
  },
  {
    "text": "the most basic way to apply Federate",
    "start": "470440",
    "end": "472440"
  },
  {
    "text": "learning in large language models is for",
    "start": "472440",
    "end": "474599"
  },
  {
    "text": "all participating parties to jointly",
    "start": "474599",
    "end": "476759"
  },
  {
    "text": "train or fune a large language model",
    "start": "476759",
    "end": "478840"
  },
  {
    "text": "with the same same architecture so for",
    "start": "478840",
    "end": "481199"
  },
  {
    "text": "example here we have three parties and",
    "start": "481199",
    "end": "483639"
  },
  {
    "text": "together they can fune a llama model",
    "start": "483639",
    "end": "485599"
  },
  {
    "text": "with their own local data and to address",
    "start": "485599",
    "end": "488919"
  },
  {
    "text": "the high communication cost problem the",
    "start": "488919",
    "end": "491319"
  },
  {
    "text": "industry has tried various methods such",
    "start": "491319",
    "end": "494039"
  },
  {
    "text": "as the approach described in the paper",
    "start": "494039",
    "end": "496159"
  },
  {
    "text": "and write which involves freezing",
    "start": "496159",
    "end": "498440"
  },
  {
    "text": "certain layers of the model and only",
    "start": "498440",
    "end": "500840"
  },
  {
    "text": "train and updating other layers however",
    "start": "500840",
    "end": "504280"
  },
  {
    "text": "exp experimental results have shown that",
    "start": "504280",
    "end": "506960"
  },
  {
    "text": "although the communication cost may be",
    "start": "506960",
    "end": "508840"
  },
  {
    "text": "lower it can significantly impact the",
    "start": "508840",
    "end": "511440"
  },
  {
    "text": "final model's performance therefore we",
    "start": "511440",
    "end": "514000"
  },
  {
    "text": "need to like explore other like more",
    "start": "514000",
    "end": "516800"
  },
  {
    "text": "effective",
    "start": "516800",
    "end": "518360"
  },
  {
    "text": "ways and on the other hand we all know",
    "start": "518360",
    "end": "521159"
  },
  {
    "text": "that for now like for fan tuning uh",
    "start": "521159",
    "end": "523959"
  },
  {
    "text": "large language models the commonly used",
    "start": "523959",
    "end": "526519"
  },
  {
    "text": "method here is what we call parameter",
    "start": "526519",
    "end": "529440"
  },
  {
    "text": "efficient fan tuning or PA so the core",
    "start": "529440",
    "end": "532600"
  },
  {
    "text": "idea of PA is that during the training",
    "start": "532600",
    "end": "534920"
  },
  {
    "text": "process we do not adjust all of the",
    "start": "534920",
    "end": "537080"
  },
  {
    "text": "models parameters but instead will",
    "start": "537080",
    "end": "539600"
  },
  {
    "text": "introduce a small number of of of new",
    "start": "539600",
    "end": "542720"
  },
  {
    "text": "parameters and only update these",
    "start": "542720",
    "end": "544959"
  },
  {
    "text": "parameters during",
    "start": "544959",
    "end": "546360"
  },
  {
    "text": "training so here are some typical",
    "start": "546360",
    "end": "548800"
  },
  {
    "text": "approaches such as the adapter mechanism",
    "start": "548800",
    "end": "551839"
  },
  {
    "text": "and below that there is Laura which is a",
    "start": "551839",
    "end": "554360"
  },
  {
    "text": "popular path method that uses low rank",
    "start": "554360",
    "end": "557360"
  },
  {
    "text": "matrices to represent the update to a",
    "start": "557360",
    "end": "560600"
  },
  {
    "text": "certain weight matrices in the self",
    "start": "560600",
    "end": "562600"
  },
  {
    "text": "attention",
    "start": "562600",
    "end": "563480"
  },
  {
    "text": "module and there are other methods like",
    "start": "563480",
    "end": "566399"
  },
  {
    "text": "PR tuning and the prefix tuning which",
    "start": "566399",
    "end": "569320"
  },
  {
    "text": "involve uh inserting prefixes at the",
    "start": "569320",
    "end": "572560"
  },
  {
    "text": "model's input layer or each Transformer",
    "start": "572560",
    "end": "575480"
  },
  {
    "text": "layer and this prefixes are trainable",
    "start": "575480",
    "end": "578839"
  },
  {
    "text": "and during fine tuning only this part",
    "start": "578839",
    "end": "581720"
  },
  {
    "text": "will be trained and",
    "start": "581720",
    "end": "584600"
  },
  {
    "text": "updated so naturally in Federated",
    "start": "584600",
    "end": "587279"
  },
  {
    "text": "learning we can attempt to apply these",
    "start": "587279",
    "end": "589920"
  },
  {
    "text": "path approaches this means like each",
    "start": "589920",
    "end": "592640"
  },
  {
    "text": "party will applies PA for the local",
    "start": "592640",
    "end": "595240"
  },
  {
    "text": "training and after that we know we like",
    "start": "595240",
    "end": "599399"
  },
  {
    "text": "only need to transmit and aggregate the",
    "start": "599399",
    "end": "602360"
  },
  {
    "text": "updated part so this proportion of the",
    "start": "602360",
    "end": "606360"
  },
  {
    "text": "transmitted parameters is generally like",
    "start": "606360",
    "end": "609760"
  },
  {
    "text": "1% or 1,000 or even less of the original",
    "start": "609760",
    "end": "614120"
  },
  {
    "text": "models parameter",
    "start": "614120",
    "end": "615760"
  },
  {
    "text": "numbers so the industry has also",
    "start": "615760",
    "end": "618720"
  },
  {
    "text": "proposed Solutions like fed adapter fed",
    "start": "618720",
    "end": "622440"
  },
  {
    "text": "prompt which combine pth with fed",
    "start": "622440",
    "end": "627240"
  },
  {
    "text": "learning and also there is this paper",
    "start": "627240",
    "end": "630399"
  },
  {
    "text": "which Compares various path methods in",
    "start": "630399",
    "end": "632800"
  },
  {
    "text": "the F learning settings basically uh",
    "start": "632800",
    "end": "636440"
  },
  {
    "text": "when the this methods are applied in",
    "start": "636440",
    "end": "638600"
  },
  {
    "text": "Fred learning the data being transmitted",
    "start": "638600",
    "end": "641800"
  },
  {
    "text": "or the DAT the transmission cost can be",
    "start": "641800",
    "end": "644920"
  },
  {
    "text": "significantly reduced while the model's",
    "start": "644920",
    "end": "647800"
  },
  {
    "text": "performance do not decline much so",
    "start": "647800",
    "end": "650560"
  },
  {
    "text": "essentially we can achieve a balance",
    "start": "650560",
    "end": "652600"
  },
  {
    "text": "between cost and acceptable",
    "start": "652600",
    "end": "657279"
  },
  {
    "text": "performance and furthermore this article",
    "start": "657320",
    "end": "660240"
  },
  {
    "text": "also inspired us to implement fit llm in",
    "start": "660240",
    "end": "663399"
  },
  {
    "text": "certain ways what we want is that we",
    "start": "663399",
    "end": "666600"
  },
  {
    "text": "want to provide a solution or a",
    "start": "666600",
    "end": "668800"
  },
  {
    "text": "framework that allow users to easily",
    "start": "668800",
    "end": "671680"
  },
  {
    "text": "choose fine-tuning approaches based on",
    "start": "671680",
    "end": "674480"
  },
  {
    "text": "their requirements and to configure and",
    "start": "674480",
    "end": "677720"
  },
  {
    "text": "validate different method very easily so",
    "start": "677720",
    "end": "681440"
  },
  {
    "text": "this is the first uh how to put it the",
    "start": "681440",
    "end": "684800"
  },
  {
    "text": "Paradigm like we implemented in our",
    "start": "684800",
    "end": "687040"
  },
  {
    "text": "current fit l basically it is a",
    "start": "687040",
    "end": "690440"
  },
  {
    "text": "homogeneous fedit learning llm framework",
    "start": "690440",
    "end": "694279"
  },
  {
    "text": "based on PFT so the general idea is what",
    "start": "694279",
    "end": "697959"
  },
  {
    "text": "we saw in those papers earlier and in",
    "start": "697959",
    "end": "700320"
  },
  {
    "text": "our code implementations we have a",
    "start": "700320",
    "end": "702519"
  },
  {
    "text": "module called PM which stands for",
    "start": "702519",
    "end": "705560"
  },
  {
    "text": "parameter efficient L and within this",
    "start": "705560",
    "end": "708560"
  },
  {
    "text": "module we can work with a range of",
    "start": "708560",
    "end": "710839"
  },
  {
    "text": "pre-rain models from the hugging face",
    "start": "710839",
    "end": "713320"
  },
  {
    "text": "ecosystem and this modu also works with",
    "start": "713320",
    "end": "715959"
  },
  {
    "text": "Hing faces PA library to use use",
    "start": "715959",
    "end": "719240"
  },
  {
    "text": "different path methods such as",
    "start": "719240",
    "end": "722079"
  },
  {
    "text": "Laura and after that we can leverage F",
    "start": "722079",
    "end": "725680"
  },
  {
    "text": "existing black called horizontal",
    "start": "725680",
    "end": "728880"
  },
  {
    "text": "Federated neural network trainer to",
    "start": "728880",
    "end": "731920"
  },
  {
    "text": "perform the Federated",
    "start": "731920",
    "end": "733920"
  },
  {
    "text": "training so here is a simple example of",
    "start": "733920",
    "end": "736480"
  },
  {
    "text": "the overall process so there are three",
    "start": "736480",
    "end": "738680"
  },
  {
    "text": "parties here and each of them will",
    "start": "738680",
    "end": "740800"
  },
  {
    "text": "conduct several rounds of local training",
    "start": "740800",
    "end": "742600"
  },
  {
    "text": "using Laura and afterwards the",
    "start": "742600",
    "end": "745120"
  },
  {
    "text": "parameters of the Laura part will be",
    "start": "745120",
    "end": "747440"
  },
  {
    "text": "aggregated and updated",
    "start": "747440",
    "end": "749519"
  },
  {
    "text": "and then this updated the global",
    "start": "749519",
    "end": "752000"
  },
  {
    "text": "parameters will be used for next round",
    "start": "752000",
    "end": "754320"
  },
  {
    "text": "of local training so this process will",
    "start": "754320",
    "end": "758360"
  },
  {
    "text": "iterate until certain termination",
    "start": "758360",
    "end": "761000"
  },
  {
    "text": "conditions are met and the aggregation",
    "start": "761000",
    "end": "764880"
  },
  {
    "text": "process here can use secure aggregation",
    "start": "764880",
    "end": "767279"
  },
  {
    "text": "methods based on different Technologies",
    "start": "767279",
    "end": "769600"
  },
  {
    "text": "like secure sharing like differential",
    "start": "769600",
    "end": "771720"
  },
  {
    "text": "privacy which are commonly used in Fred",
    "start": "771720",
    "end": "774560"
  },
  {
    "text": "learning to protect privacies basically",
    "start": "774560",
    "end": "777880"
  },
  {
    "text": "uh by using this methods we can ensure",
    "start": "777880",
    "end": "780279"
  },
  {
    "text": "that no party can access the parameters",
    "start": "780279",
    "end": "783079"
  },
  {
    "text": "of the others but they can obtain an",
    "start": "783079",
    "end": "786079"
  },
  {
    "text": "aggregated",
    "start": "786079",
    "end": "787920"
  },
  {
    "text": "results and also the community had some",
    "start": "787920",
    "end": "790639"
  },
  {
    "text": "practical validations based on this uh P",
    "start": "790639",
    "end": "794680"
  },
  {
    "text": "modu it can support like Federated fun",
    "start": "794680",
    "end": "798000"
  },
  {
    "text": "tuning of homogeneous llm with over 30",
    "start": "798000",
    "end": "802040"
  },
  {
    "text": "parties and the final model's",
    "start": "802040",
    "end": "804320"
  },
  {
    "text": "performance is better than any",
    "start": "804320",
    "end": "806079"
  },
  {
    "text": "individual party's local model fine",
    "start": "806079",
    "end": "809120"
  },
  {
    "text": "tuned with their soal so-call own",
    "start": "809120",
    "end": "813199"
  },
  {
    "text": "data okay so this is how to efficiently",
    "start": "813199",
    "end": "816880"
  },
  {
    "text": "and privately doing F learning model",
    "start": "816880",
    "end": "819160"
  },
  {
    "text": "aggregation for large model with the",
    "start": "819160",
    "end": "821360"
  },
  {
    "text": "same",
    "start": "821360",
    "end": "822399"
  },
  {
    "text": "architecture apart from that L also",
    "start": "822399",
    "end": "825160"
  },
  {
    "text": "mentioned that there is a second",
    "start": "825160",
    "end": "826920"
  },
  {
    "text": "challenge which is about the large",
    "start": "826920",
    "end": "829120"
  },
  {
    "text": "computational resources required for",
    "start": "829120",
    "end": "831279"
  },
  {
    "text": "training large language models you know",
    "start": "831279",
    "end": "834040"
  },
  {
    "text": "in frity learning the local resources",
    "start": "834040",
    "end": "836560"
  },
  {
    "text": "available to each participant are very",
    "start": "836560",
    "end": "838519"
  },
  {
    "text": "different different in many scenarios",
    "start": "838519",
    "end": "840839"
  },
  {
    "text": "these participants or clients can",
    "start": "840839",
    "end": "843079"
  },
  {
    "text": "include Edge devices iot devices and the",
    "start": "843079",
    "end": "846279"
  },
  {
    "text": "branches of various sizes so unlike data",
    "start": "846279",
    "end": "849600"
  },
  {
    "text": "centers or clouds they do not have the",
    "start": "849600",
    "end": "852120"
  },
  {
    "text": "large scale Computing clusters and they",
    "start": "852120",
    "end": "854959"
  },
  {
    "text": "they also can have very different data",
    "start": "854959",
    "end": "857079"
  },
  {
    "text": "volumes and",
    "start": "857079",
    "end": "858440"
  },
  {
    "text": "distributions so this scenario is what",
    "start": "858440",
    "end": "860880"
  },
  {
    "text": "we call Collaborative faity Learning",
    "start": "860880",
    "end": "863040"
  },
  {
    "text": "between Cloud Edge and the",
    "start": "863040",
    "end": "865720"
  },
  {
    "text": "end so in such scenario parti ANS may",
    "start": "865720",
    "end": "869279"
  },
  {
    "text": "want to find models with different",
    "start": "869279",
    "end": "871759"
  },
  {
    "text": "skills and how can we apply fragr",
    "start": "871759",
    "end": "874920"
  },
  {
    "text": "learning to this so-called heterogenous",
    "start": "874920",
    "end": "878120"
  },
  {
    "text": "settings so for this the industry also",
    "start": "878120",
    "end": "881519"
  },
  {
    "text": "has some solutions and",
    "start": "881519",
    "end": "884399"
  },
  {
    "text": "ideas and there's a paper from MIT that",
    "start": "884399",
    "end": "887440"
  },
  {
    "text": "mentions an offside tuning approach",
    "start": "887440",
    "end": "890000"
  },
  {
    "text": "basically with this approach we can",
    "start": "890000",
    "end": "892040"
  },
  {
    "text": "establish a fation between large models",
    "start": "892040",
    "end": "894800"
  },
  {
    "text": "and the data what does it mean you know",
    "start": "894800",
    "end": "898199"
  },
  {
    "text": "for model training scenario there are",
    "start": "898199",
    "end": "900639"
  },
  {
    "text": "data holders and there are model holders",
    "start": "900639",
    "end": "903759"
  },
  {
    "text": "we all understand that the data holder",
    "start": "903759",
    "end": "906360"
  },
  {
    "text": "does not want to send their data out for",
    "start": "906360",
    "end": "908839"
  },
  {
    "text": "fan tuning so offensively they need to",
    "start": "908839",
    "end": "911920"
  },
  {
    "text": "bring the model locally for training",
    "start": "911920",
    "end": "914800"
  },
  {
    "text": "however in some scenarios this can be",
    "start": "914800",
    "end": "916920"
  },
  {
    "text": "challenging too for reasons like",
    "start": "916920",
    "end": "919120"
  },
  {
    "text": "limitations in local hardware or because",
    "start": "919120",
    "end": "921480"
  },
  {
    "text": "the model holder itself does not want to",
    "start": "921480",
    "end": "923600"
  },
  {
    "text": "send the model to anyone as they want to",
    "start": "923600",
    "end": "926199"
  },
  {
    "text": "protect information like like model",
    "start": "926199",
    "end": "927839"
  },
  {
    "text": "structure and we",
    "start": "927839",
    "end": "929680"
  },
  {
    "text": "so with this requirements the offside",
    "start": "929680",
    "end": "931959"
  },
  {
    "text": "tuning approach proposes that the model",
    "start": "931959",
    "end": "934399"
  },
  {
    "text": "holder can provide some lightweight",
    "start": "934399",
    "end": "936759"
  },
  {
    "text": "adapters and a lossy compressed emulator",
    "start": "936759",
    "end": "939959"
  },
  {
    "text": "to the data holder and on the data",
    "start": "939959",
    "end": "943000"
  },
  {
    "text": "holder side they can fune the the",
    "start": "943000",
    "end": "945759"
  },
  {
    "text": "adapter with the assistance of the",
    "start": "945759",
    "end": "948240"
  },
  {
    "text": "evaluator and in the end the train",
    "start": "948240",
    "end": "950839"
  },
  {
    "text": "adapter will be combined back to the",
    "start": "950839",
    "end": "952959"
  },
  {
    "text": "original large",
    "start": "952959",
    "end": "954680"
  },
  {
    "text": "model and this way the F tuning process",
    "start": "954680",
    "end": "957920"
  },
  {
    "text": "is relatively resource efficient as it",
    "start": "957920",
    "end": "960839"
  },
  {
    "text": "is essentially training a small model",
    "start": "960839",
    "end": "963680"
  },
  {
    "text": "and at the same time the original model",
    "start": "963680",
    "end": "966360"
  },
  {
    "text": "remains",
    "start": "966360",
    "end": "967600"
  },
  {
    "text": "protected so this is one approach and",
    "start": "967600",
    "end": "970880"
  },
  {
    "text": "there are other ways when we think about",
    "start": "970880",
    "end": "973759"
  },
  {
    "text": "like collaboration between large and",
    "start": "973759",
    "end": "975759"
  },
  {
    "text": "small models we often think of knowledge",
    "start": "975759",
    "end": "978519"
  },
  {
    "text": "distillation right there are various",
    "start": "978519",
    "end": "981120"
  },
  {
    "text": "types of distillations like response",
    "start": "981120",
    "end": "983680"
  },
  {
    "text": "based feature based and relation based",
    "start": "983680",
    "end": "987040"
  },
  {
    "text": "so in this context there are also",
    "start": "987040",
    "end": "989600"
  },
  {
    "text": "explorations to apply knowledge",
    "start": "989600",
    "end": "991560"
  },
  {
    "text": "distillation in Federate learning for",
    "start": "991560",
    "end": "993800"
  },
  {
    "text": "heterogeneous large language",
    "start": "993800",
    "end": "996440"
  },
  {
    "text": "models so for instance there's dation",
    "start": "996440",
    "end": "1000360"
  },
  {
    "text": "initiated from the participant or client",
    "start": "1000360",
    "end": "1003519"
  },
  {
    "text": "side basically each parties will do",
    "start": "1003519",
    "end": "1006240"
  },
  {
    "text": "knowledge distillation from their",
    "start": "1006240",
    "end": "1008000"
  },
  {
    "text": "different model to get student model",
    "start": "1008000",
    "end": "1010399"
  },
  {
    "text": "with the same",
    "start": "1010399",
    "end": "1012199"
  },
  {
    "text": "architecture and the training or F",
    "start": "1012199",
    "end": "1014759"
  },
  {
    "text": "tuning process can then be performed by",
    "start": "1014759",
    "end": "1016880"
  },
  {
    "text": "them to initially train their respective",
    "start": "1016880",
    "end": "1019480"
  },
  {
    "text": "heterogeneous model and the student",
    "start": "1019480",
    "end": "1021839"
  },
  {
    "text": "model at the same time using both local",
    "start": "1021839",
    "end": "1024558"
  },
  {
    "text": "private data and knowledge",
    "start": "1024559",
    "end": "1026798"
  },
  {
    "text": "distillation so the knowledge",
    "start": "1026799",
    "end": "1028600"
  },
  {
    "text": "distillation as depicted in this figure",
    "start": "1028600",
    "end": "1031360"
  },
  {
    "text": "besides the the KD Mark is a mutal it's",
    "start": "1031360",
    "end": "1034798"
  },
  {
    "text": "a b directional process so then during",
    "start": "1034799",
    "end": "1037760"
  },
  {
    "text": "the model aggregation phase in Fred",
    "start": "1037760",
    "end": "1039918"
  },
  {
    "text": "learning we only Aggregate and update",
    "start": "1039919",
    "end": "1043160"
  },
  {
    "text": "the student model so by iterating this",
    "start": "1043160",
    "end": "1046760"
  },
  {
    "text": "process we can allow the participants to",
    "start": "1046760",
    "end": "1049400"
  },
  {
    "text": "continue benefiting from the training of",
    "start": "1049400",
    "end": "1051760"
  },
  {
    "text": "others through Federated learning even",
    "start": "1051760",
    "end": "1054480"
  },
  {
    "text": "though they have heterogeneous local",
    "start": "1054480",
    "end": "1058000"
  },
  {
    "text": "models and another research approach is",
    "start": "1058000",
    "end": "1060919"
  },
  {
    "text": "kind of like server s distillation where",
    "start": "1060919",
    "end": "1063720"
  },
  {
    "text": "the knowledge distilation is initially",
    "start": "1063720",
    "end": "1065960"
  },
  {
    "text": "performed on the aggregation side which",
    "start": "1065960",
    "end": "1068720"
  },
  {
    "text": "means that during Federate learning all",
    "start": "1068720",
    "end": "1071559"
  },
  {
    "text": "these participants still train and",
    "start": "1071559",
    "end": "1073880"
  },
  {
    "text": "Define tune a smaller model however this",
    "start": "1073880",
    "end": "1077000"
  },
  {
    "text": "model's initial state is distilled from",
    "start": "1077000",
    "end": "1079400"
  },
  {
    "text": "a prein stronger large model so as",
    "start": "1079400",
    "end": "1082960"
  },
  {
    "text": "mentioned earlier especially in the",
    "start": "1082960",
    "end": "1085200"
  },
  {
    "text": "so-called cross device Federate learning",
    "start": "1085200",
    "end": "1087440"
  },
  {
    "text": "scenarios participants may not be able",
    "start": "1087440",
    "end": "1090039"
  },
  {
    "text": "to train Large Scale Models due to",
    "start": "1090039",
    "end": "1092799"
  },
  {
    "text": "reasons like resource",
    "start": "1092799",
    "end": "1094960"
  },
  {
    "text": "limitations they can only train and use",
    "start": "1094960",
    "end": "1097760"
  },
  {
    "text": "like relatively small models but if this",
    "start": "1097760",
    "end": "1101200"
  },
  {
    "text": "small model can receive assistance from",
    "start": "1101200",
    "end": "1103799"
  },
  {
    "text": "knowledge distillation from a large",
    "start": "1103799",
    "end": "1105679"
  },
  {
    "text": "model it will help the performance of",
    "start": "1105679",
    "end": "1108000"
  },
  {
    "text": "the f",
    "start": "1108000",
    "end": "1108960"
  },
  {
    "text": "model so Google has this paper that",
    "start": "1108960",
    "end": "1112000"
  },
  {
    "text": "talks about this kind of large model",
    "start": "1112000",
    "end": "1114919"
  },
  {
    "text": "guiding small model",
    "start": "1114919",
    "end": "1118000"
  },
  {
    "text": "approach so there are some of the",
    "start": "1118000",
    "end": "1120799"
  },
  {
    "text": "solutions of heterogeneous F Federated",
    "start": "1120799",
    "end": "1124360"
  },
  {
    "text": "learning and the collaborations between",
    "start": "1124360",
    "end": "1126400"
  },
  {
    "text": "large and small models and of course",
    "start": "1126400",
    "end": "1129200"
  },
  {
    "text": "there are relatively Cutting Edge",
    "start": "1129200",
    "end": "1131000"
  },
  {
    "text": "researches areas and they are relate",
    "start": "1131000",
    "end": "1134080"
  },
  {
    "text": "there are related topics like privacy",
    "start": "1134080",
    "end": "1136880"
  },
  {
    "text": "protection efficiency and more that are",
    "start": "1136880",
    "end": "1140080"
  },
  {
    "text": "still continually being investigated",
    "start": "1140080",
    "end": "1143000"
  },
  {
    "text": "being evaluated by the",
    "start": "1143000",
    "end": "1146280"
  },
  {
    "text": "industry and for the fifth LM project it",
    "start": "1146280",
    "end": "1149840"
  },
  {
    "text": "has also introduced another Paradigm",
    "start": "1149840",
    "end": "1152360"
  },
  {
    "text": "called federa transfer learning for",
    "start": "1152360",
    "end": "1155039"
  },
  {
    "text": "large language models or FTL llm to",
    "start": "1155039",
    "end": "1158880"
  },
  {
    "text": "address this kind of heterogeneity and",
    "start": "1158880",
    "end": "1162039"
  },
  {
    "text": "collaboration the transfer here refers",
    "start": "1162039",
    "end": "1164480"
  },
  {
    "text": "to the transfer of knowledge so through",
    "start": "1164480",
    "end": "1167840"
  },
  {
    "text": "fith of FTL llm we aim to provide a way",
    "start": "1167840",
    "end": "1172880"
  },
  {
    "text": "to improve both large and small models",
    "start": "1172880",
    "end": "1176039"
  },
  {
    "text": "simultaneously INF Fred rated learning",
    "start": "1176039",
    "end": "1178919"
  },
  {
    "text": "so in terms of implementation for",
    "start": "1178919",
    "end": "1180760"
  },
  {
    "text": "example in the case of upsite tuning the",
    "start": "1180760",
    "end": "1183200"
  },
  {
    "text": "fit llm extends original paper to",
    "start": "1183200",
    "end": "1186559"
  },
  {
    "text": "accommodate FR learning scenarios with",
    "start": "1186559",
    "end": "1189159"
  },
  {
    "text": "more",
    "start": "1189159",
    "end": "1190760"
  },
  {
    "text": "participants so as shown here the FI",
    "start": "1190760",
    "end": "1193600"
  },
  {
    "text": "aggregator or server first obtain the",
    "start": "1193600",
    "end": "1195960"
  },
  {
    "text": "model from the hugging face interface",
    "start": "1195960",
    "end": "1199320"
  },
  {
    "text": "then by following the offset tuning",
    "start": "1199320",
    "end": "1201240"
  },
  {
    "text": "approach it can extract the simulator or",
    "start": "1201240",
    "end": "1204520"
  },
  {
    "text": "emulator and the adapter these elements",
    "start": "1204520",
    "end": "1208240"
  },
  {
    "text": "are then distributed to this multiple",
    "start": "1208240",
    "end": "1210840"
  },
  {
    "text": "participants or",
    "start": "1210840",
    "end": "1212440"
  },
  {
    "text": "clients and then each participants will",
    "start": "1212440",
    "end": "1215080"
  },
  {
    "text": "F tune the adapter in a fate learning",
    "start": "1215080",
    "end": "1217600"
  },
  {
    "text": "fashion including local training and the",
    "start": "1217600",
    "end": "1220320"
  },
  {
    "text": "global aggregation and the aggregation",
    "start": "1220320",
    "end": "1223480"
  },
  {
    "text": "process still relies on F secure",
    "start": "1223480",
    "end": "1226360"
  },
  {
    "text": "aggregation protocols to further protect",
    "start": "1226360",
    "end": "1228720"
  },
  {
    "text": "the privacy of all the",
    "start": "1228720",
    "end": "1230799"
  },
  {
    "text": "participants so this entire",
    "start": "1230799",
    "end": "1233120"
  },
  {
    "text": "implementation is encapsulated within",
    "start": "1233120",
    "end": "1235799"
  },
  {
    "text": "spe a specific implementation class",
    "start": "1235799",
    "end": "1238200"
  },
  {
    "text": "called um offside tuning",
    "start": "1238200",
    "end": "1241000"
  },
  {
    "text": "trainer and also there is also uh",
    "start": "1241000",
    "end": "1244159"
  },
  {
    "text": "practical validation in the community",
    "start": "1244159",
    "end": "1247000"
  },
  {
    "text": "basically through this approach the",
    "start": "1247000",
    "end": "1248960"
  },
  {
    "text": "model's performance consist significant",
    "start": "1248960",
    "end": "1251799"
  },
  {
    "text": "improvements while the resources",
    "start": "1251799",
    "end": "1253919"
  },
  {
    "text": "requirements for participants are lower",
    "start": "1253919",
    "end": "1256159"
  },
  {
    "text": "compared to like training the original",
    "start": "1256159",
    "end": "1259600"
  },
  {
    "text": "model so this FTL L Paradigm and",
    "start": "1259600",
    "end": "1263440"
  },
  {
    "text": "implementation was released like in the",
    "start": "1263440",
    "end": "1266080"
  },
  {
    "text": "latest fit LM 1.3 version which was",
    "start": "1266080",
    "end": "1270120"
  },
  {
    "text": "released in the earlier September this",
    "start": "1270120",
    "end": "1273600"
  },
  {
    "text": "year so for now we've seen how we can",
    "start": "1273600",
    "end": "1276440"
  },
  {
    "text": "address the challenges in large language",
    "start": "1276440",
    "end": "1278440"
  },
  {
    "text": "models for Federated learning and the",
    "start": "1278440",
    "end": "1281520"
  },
  {
    "text": "specific implementations within fit llm",
    "start": "1281520",
    "end": "1284679"
  },
  {
    "text": "project and from an engineering",
    "start": "1284679",
    "end": "1287120"
  },
  {
    "text": "perspective the fifth L project plans to",
    "start": "1287120",
    "end": "1290200"
  },
  {
    "text": "divide this implementations into",
    "start": "1290200",
    "end": "1292320"
  },
  {
    "text": "different components including a",
    "start": "1292320",
    "end": "1294520"
  },
  {
    "text": "communication efficient Hub a model Hub",
    "start": "1294520",
    "end": "1297159"
  },
  {
    "text": "and additionally the implementation of",
    "start": "1297159",
    "end": "1299120"
  },
  {
    "text": "other params including mechanism for",
    "start": "1299120",
    "end": "1301760"
  },
  {
    "text": "privacy protection is hosted in the",
    "start": "1301760",
    "end": "1304240"
  },
  {
    "text": "Privacy Hub and as mentioned Faith LM",
    "start": "1304240",
    "end": "1308480"
  },
  {
    "text": "itself is a sub project of the broader",
    "start": "1308480",
    "end": "1311120"
  },
  {
    "text": "Faith ecosystem so what does it look",
    "start": "1311120",
    "end": "1313840"
  },
  {
    "text": "like to run fit llm within the overall",
    "start": "1313840",
    "end": "1316640"
  },
  {
    "text": "fit architecture so we can take a deeper",
    "start": "1316640",
    "end": "1319240"
  },
  {
    "text": "look on the overall system design here",
    "start": "1319240",
    "end": "1322400"
  },
  {
    "text": "so fed itself operates as a system with",
    "start": "1322400",
    "end": "1325240"
  },
  {
    "text": "an API and scheduling service called fit",
    "start": "1325240",
    "end": "1327880"
  },
  {
    "text": "flow at the top and the fit LR module as",
    "start": "1327880",
    "end": "1331960"
  },
  {
    "text": "we are seeing here is the components",
    "start": "1331960",
    "end": "1333799"
  },
  {
    "text": "below and are orchestrated by fith flow",
    "start": "1333799",
    "end": "1337279"
  },
  {
    "text": "and further down the stack there are",
    "start": "1337279",
    "end": "1339120"
  },
  {
    "text": "optional optimization and acceleration",
    "start": "1339120",
    "end": "1341520"
  },
  {
    "text": "libraries such as deep",
    "start": "1341520",
    "end": "1344039"
  },
  {
    "text": "speed and moving on we can introduce",
    "start": "1344039",
    "end": "1346960"
  },
  {
    "text": "coup fit the c fit project organize and",
    "start": "1346960",
    "end": "1350120"
  },
  {
    "text": "deploys the fit systems in a",
    "start": "1350120",
    "end": "1352039"
  },
  {
    "text": "containerized cloud native manner it",
    "start": "1352039",
    "end": "1355000"
  },
  {
    "text": "provides functionalities including the",
    "start": "1355000",
    "end": "1357080"
  },
  {
    "text": "management of the underlying distributed",
    "start": "1357080",
    "end": "1359520"
  },
  {
    "text": "computing engine and the hardware and",
    "start": "1359520",
    "end": "1362440"
  },
  {
    "text": "naturally lots of this functionalities",
    "start": "1362440",
    "end": "1364679"
  },
  {
    "text": "are implemented on top of cortic on",
    "start": "1364679",
    "end": "1367360"
  },
  {
    "text": "cloud native features so now we have a",
    "start": "1367360",
    "end": "1370240"
  },
  {
    "text": "system for running F llm however what we",
    "start": "1370240",
    "end": "1373600"
  },
  {
    "text": "see here is just one participant right",
    "start": "1373600",
    "end": "1376520"
  },
  {
    "text": "we need at least a second one which is",
    "start": "1376520",
    "end": "1379120"
  },
  {
    "text": "essentially another fit llm system and",
    "start": "1379120",
    "end": "1382679"
  },
  {
    "text": "in the middle here is the OSX model who",
    "start": "1382679",
    "end": "1385840"
  },
  {
    "text": "will Co coordinate the tasks between the",
    "start": "1385840",
    "end": "1388520"
  },
  {
    "text": "two parties and Below there is a Fed LCM",
    "start": "1388520",
    "end": "1391640"
  },
  {
    "text": "service used for deployments of the",
    "start": "1391640",
    "end": "1393640"
  },
  {
    "text": "Federate Learning Systems in multiple",
    "start": "1393640",
    "end": "1395960"
  },
  {
    "text": "parties within of so-called Federation",
    "start": "1395960",
    "end": "1399400"
  },
  {
    "text": "so this includes deployments operation",
    "start": "1399400",
    "end": "1402480"
  },
  {
    "text": "interconnection management of tasks data",
    "start": "1402480",
    "end": "1405039"
  },
  {
    "text": "models and",
    "start": "1405039",
    "end": "1406440"
  },
  {
    "text": "more so this is the typical deployment",
    "start": "1406440",
    "end": "1409559"
  },
  {
    "text": "setup for fate llm of course uh fate or",
    "start": "1409559",
    "end": "1413880"
  },
  {
    "text": "fate llm can also run directly on",
    "start": "1413880",
    "end": "1416480"
  },
  {
    "text": "physical or virtual machines but if you",
    "start": "1416480",
    "end": "1419159"
  },
  {
    "text": "want to manage and deploy them in a",
    "start": "1419159",
    "end": "1421279"
  },
  {
    "text": "cloud native fashion and enjoy the old",
    "start": "1421279",
    "end": "1423799"
  },
  {
    "text": "benefits that comes along uh we",
    "start": "1423799",
    "end": "1426400"
  },
  {
    "text": "introduce kit and fed LCM uh basically",
    "start": "1426400",
    "end": "1430320"
  },
  {
    "text": "regarding kit and the the so-called",
    "start": "1430320",
    "end": "1432840"
  },
  {
    "text": "Cloud native Federate learning we've",
    "start": "1432840",
    "end": "1435120"
  },
  {
    "text": "covered this in previous ccon events and",
    "start": "1435120",
    "end": "1438200"
  },
  {
    "text": "other events so we won't take a deeper",
    "start": "1438200",
    "end": "1441000"
  },
  {
    "text": "dive here today just know that by using",
    "start": "1441000",
    "end": "1443880"
  },
  {
    "text": "Cade and fed LCM you can quickly deploy",
    "start": "1443880",
    "end": "1446919"
  },
  {
    "text": "and manage production ready fit systems",
    "start": "1446919",
    "end": "1449400"
  },
  {
    "text": "to start your Federate learning",
    "start": "1449400",
    "end": "1451919"
  },
  {
    "text": "jobs",
    "start": "1451919",
    "end": "1454919"
  },
  {
    "text": "and this is the fif llm project road map",
    "start": "1455000",
    "end": "1458960"
  },
  {
    "text": "it is an active project that is",
    "start": "1458960",
    "end": "1460960"
  },
  {
    "text": "continually involving uh there are a",
    "start": "1460960",
    "end": "1463440"
  },
  {
    "text": "couple of releases since the initial",
    "start": "1463440",
    "end": "1465760"
  },
  {
    "text": "release in the first half of this year",
    "start": "1465760",
    "end": "1468200"
  },
  {
    "text": "and as mentioned earlier we recently",
    "start": "1468200",
    "end": "1471320"
  },
  {
    "text": "released version 1.3 in early September",
    "start": "1471320",
    "end": "1475520"
  },
  {
    "text": "and in which we introduce FTL Paradigm",
    "start": "1475520",
    "end": "1480200"
  },
  {
    "text": "and the offsite uning",
    "start": "1480200",
    "end": "1482080"
  },
  {
    "text": "framework and meanwhile the fith project",
    "start": "1482080",
    "end": "1484840"
  },
  {
    "text": "has another development Branch known as",
    "start": "1484840",
    "end": "1487200"
  },
  {
    "text": "version",
    "start": "1487200",
    "end": "1488480"
  },
  {
    "text": "2.0 this dedicated to another crucial",
    "start": "1488480",
    "end": "1492640"
  },
  {
    "text": "Topic in Federate learning which is the",
    "start": "1492640",
    "end": "1495360"
  },
  {
    "text": "interoperability among Federate learning",
    "start": "1495360",
    "end": "1497960"
  },
  {
    "text": "systems this involves a lot of",
    "start": "1497960",
    "end": "1500039"
  },
  {
    "text": "refractory work so there is a separate",
    "start": "1500039",
    "end": "1502480"
  },
  {
    "text": "2.0 Branch with the community and the",
    "start": "1502480",
    "end": "1506039"
  },
  {
    "text": "plan is to merge fit llm which is",
    "start": "1506039",
    "end": "1508720"
  },
  {
    "text": "currently based on version 1.x into the",
    "start": "1508720",
    "end": "1512000"
  },
  {
    "text": "2.0 release by the end of this",
    "start": "1512000",
    "end": "1516120"
  },
  {
    "text": "year okay uh let's wrap up and provide a",
    "start": "1516480",
    "end": "1519880"
  },
  {
    "text": "summary of our discussion today and",
    "start": "1519880",
    "end": "1522000"
  },
  {
    "text": "what's next so we've explored Federated",
    "start": "1522000",
    "end": "1524640"
  },
  {
    "text": "learning and its value in the context of",
    "start": "1524640",
    "end": "1527159"
  },
  {
    "text": "large Lang models applications and we",
    "start": "1527159",
    "end": "1529919"
  },
  {
    "text": "talked about the challenges we will face",
    "start": "1529919",
    "end": "1532240"
  },
  {
    "text": "when applying fate learning and within",
    "start": "1532240",
    "end": "1535159"
  },
  {
    "text": "the Fai open source project the",
    "start": "1535159",
    "end": "1537279"
  },
  {
    "text": "community has collaborated and is",
    "start": "1537279",
    "end": "1539440"
  },
  {
    "text": "continuing collaborating with the",
    "start": "1539440",
    "end": "1541080"
  },
  {
    "text": "industry to introduce suitable paradigms",
    "start": "1541080",
    "end": "1544080"
  },
  {
    "text": "for training large language models to",
    "start": "1544080",
    "end": "1546360"
  },
  {
    "text": "address these",
    "start": "1546360",
    "end": "1548159"
  },
  {
    "text": "challenges and still it is worth noting",
    "start": "1548159",
    "end": "1551320"
  },
  {
    "text": "again that the research and application",
    "start": "1551320",
    "end": "1554279"
  },
  {
    "text": "of these so-called Federated large",
    "start": "1554279",
    "end": "1556320"
  },
  {
    "text": "models are still in in the relatively",
    "start": "1556320",
    "end": "1558520"
  },
  {
    "text": "early stage so here we've highlighted",
    "start": "1558520",
    "end": "1561360"
  },
  {
    "text": "some topics related to this and fit llm",
    "start": "1561360",
    "end": "1564840"
  },
  {
    "text": "project um one important aspect is the",
    "start": "1564840",
    "end": "1568159"
  },
  {
    "text": "integration with deep speed you know F",
    "start": "1568159",
    "end": "1571000"
  },
  {
    "text": "llm already supports M multinode",
    "start": "1571000",
    "end": "1573640"
  },
  {
    "text": "multi-gpu training using deep speed for",
    "start": "1573640",
    "end": "1576240"
  },
  {
    "text": "large models like chat GM and Lama and",
    "start": "1576240",
    "end": "1579679"
  },
  {
    "text": "we are can currently investigate how to",
    "start": "1579679",
    "end": "1582840"
  },
  {
    "text": "leverage uh Native scheduling mechanism",
    "start": "1582840",
    "end": "1585640"
  },
  {
    "text": "in environments like ktic to better",
    "start": "1585640",
    "end": "1588559"
  },
  {
    "text": "integrate with deep speed and other",
    "start": "1588559",
    "end": "1591679"
  },
  {
    "text": "libraries and another topic wor",
    "start": "1591679",
    "end": "1594240"
  },
  {
    "text": "discussing and I think most people are",
    "start": "1594240",
    "end": "1596279"
  },
  {
    "text": "interested in is about privacy",
    "start": "1596279",
    "end": "1598679"
  },
  {
    "text": "protection so we know that in Federated",
    "start": "1598679",
    "end": "1601320"
  },
  {
    "text": "learning the training data never leave",
    "start": "1601320",
    "end": "1603720"
  },
  {
    "text": "the local environment right but the",
    "start": "1603720",
    "end": "1606080"
  },
  {
    "text": "final train model might still carry",
    "start": "1606080",
    "end": "1608080"
  },
  {
    "text": "information from the original data so",
    "start": "1608080",
    "end": "1611480"
  },
  {
    "text": "especially for this generative models",
    "start": "1611480",
    "end": "1614360"
  },
  {
    "text": "could there be a way for the model to",
    "start": "1614360",
    "end": "1616600"
  },
  {
    "text": "Output this original data in some form",
    "start": "1616600",
    "end": "1620240"
  },
  {
    "text": "so currently there are no definitive",
    "start": "1620240",
    "end": "1622200"
  },
  {
    "text": "answers and as far as we know different",
    "start": "1622200",
    "end": "1624880"
  },
  {
    "text": "paradigms have different privacy",
    "start": "1624880",
    "end": "1627240"
  },
  {
    "text": "implementations and the community is",
    "start": "1627240",
    "end": "1630960"
  },
  {
    "text": "actively exploring this",
    "start": "1630960",
    "end": "1633679"
  },
  {
    "text": "area so again the fith community and the",
    "start": "1633679",
    "end": "1637360"
  },
  {
    "text": "industry will continue to explore",
    "start": "1637360",
    "end": "1639039"
  },
  {
    "text": "Federated large models this includes",
    "start": "1639039",
    "end": "1642039"
  },
  {
    "text": "expanding support for even larger models",
    "start": "1642039",
    "end": "1644720"
  },
  {
    "text": "exploring better mechanism and more",
    "start": "1644720",
    "end": "1647159"
  },
  {
    "text": "effec effective paradigms for privacy",
    "start": "1647159",
    "end": "1649840"
  },
  {
    "text": "protection and to achieve a balance",
    "start": "1649840",
    "end": "1652120"
  },
  {
    "text": "between privacy security and the",
    "start": "1652120",
    "end": "1655720"
  },
  {
    "text": "efficiency so as an open source project",
    "start": "1655720",
    "end": "1658520"
  },
  {
    "text": "under LF and data Foundation we welcome",
    "start": "1658520",
    "end": "1662000"
  },
  {
    "text": "everyone to follow the developments in",
    "start": "1662000",
    "end": "1664159"
  },
  {
    "text": "this area and to participant in this",
    "start": "1664159",
    "end": "1666640"
  },
  {
    "text": "project to contribute to the",
    "start": "1666640",
    "end": "1669399"
  },
  {
    "text": "community and I think that's basically",
    "start": "1669399",
    "end": "1671760"
  },
  {
    "text": "all for our sharing thank you",
    "start": "1671760",
    "end": "1674880"
  },
  {
    "text": "everyone",
    "start": "1674880",
    "end": "1677880"
  }
]
[
  {
    "start": "0",
    "end": "58000"
  },
  {
    "text": "okay welcome everyone my name is Matthew McCauley I'm a developer at Blackrock I",
    "start": "0",
    "end": "7020"
  },
  {
    "text": "work on an application for financial advisors this is my colleague web of",
    "start": "7020",
    "end": "12150"
  },
  {
    "text": "hello everyone my name is Waipa and I'm also a developer at Blackrock and I work on data science platform so",
    "start": "12150",
    "end": "19920"
  },
  {
    "text": "for those of you who don't know Blackrock is the largest asset manager in the world and our company is heavily",
    "start": "19920",
    "end": "28199"
  },
  {
    "text": "invested in building out technology for our Aladin platform so Aladdin is black",
    "start": "28199",
    "end": "34590"
  },
  {
    "text": "rocks core operating system facilitates investment managers connection to data",
    "start": "34590",
    "end": "40920"
  },
  {
    "text": "information people and technology so today we'll be discussing our open",
    "start": "40920",
    "end": "47760"
  },
  {
    "text": "source project our goais as a case study of how Blackrock is automating our",
    "start": "47760",
    "end": "52890"
  },
  {
    "text": "research environments and scaling our data science workflows so let's begin",
    "start": "52890",
    "end": "60000"
  },
  {
    "start": "58000",
    "end": "303000"
  },
  {
    "text": "with a brief history of data science at Blackrock well and kubernetes now we",
    "start": "60000",
    "end": "66360"
  },
  {
    "text": "can't talk about the entire history of data science at Blackrock because we would literally have to recount the entire 30 year history of",
    "start": "66360",
    "end": "73710"
  },
  {
    "text": "our firm the fact is and we all know",
    "start": "73710",
    "end": "78810"
  },
  {
    "text": "kubernetes hasn't been around for 30 years the fact is that Blackrock has been investing in deriving value from",
    "start": "78810",
    "end": "85439"
  },
  {
    "text": "data science for the better part of our existence in fact you know we've been",
    "start": "85439",
    "end": "90869"
  },
  {
    "text": "successful based on the optimizations that we've applied to financial portfolios and to modeling find out",
    "start": "90869",
    "end": "96750"
  },
  {
    "text": "those financial portfolios risk so this background story isn't going to cover all that it's going to cover more around",
    "start": "96750",
    "end": "104220"
  },
  {
    "text": "how we brought kubernetes into the picture right so let's begin with why",
    "start": "104220",
    "end": "110130"
  },
  {
    "text": "why did we want to use kubernetes for our data science platform so we're all",
    "start": "110130",
    "end": "116850"
  },
  {
    "text": "at Cube gone so you know we've attended a lot of the sessions and you know there's many reasons for teas keep",
    "start": "116850",
    "end": "121950"
  },
  {
    "text": "kubernetes for data science but here are some of the reasons that we use kinetics",
    "start": "121950",
    "end": "128190"
  },
  {
    "text": "so we wanted a highly available toolset for our researchers analysts and scientists",
    "start": "128190",
    "end": "133950"
  },
  {
    "text": "to use we wanted to give them the compute and resources they needed when they needed them and we wanted them to",
    "start": "133950",
    "end": "141180"
  },
  {
    "text": "be able to use the tools they were proficient working with and they were used to working with all while building",
    "start": "141180",
    "end": "146730"
  },
  {
    "text": "on top of a more powerful platform and more most importantly as a regulated",
    "start": "146730",
    "end": "152040"
  },
  {
    "text": "financial firm we needed to enforce you know strict isolation between our users",
    "start": "152040",
    "end": "157230"
  },
  {
    "text": "and their information to ensure intellectual property and data privacy barriers so how did we build this",
    "start": "157230",
    "end": "166019"
  },
  {
    "text": "platform we started you know building the kubernetes data science platform",
    "start": "166019",
    "end": "172040"
  },
  {
    "text": "around two years ago and as we've alluded to kubernetes is at the core",
    "start": "172040",
    "end": "178040"
  },
  {
    "text": "scheduling you know gives us on-demand resources and compute with little downtime containers gives us",
    "start": "178040",
    "end": "184410"
  },
  {
    "text": "configurable and isolated environments we use docker for our container runtime",
    "start": "184410",
    "end": "190230"
  },
  {
    "text": "Elms our operational tool for version deployments we use get lab for CI CD and",
    "start": "190230",
    "end": "196170"
  },
  {
    "text": "a DevOps platform and finally we chose Jupiter notebooks with internal Python",
    "start": "196170",
    "end": "202200"
  },
  {
    "text": "API is installed for data access so very simple setup so since its first",
    "start": "202200",
    "end": "211200"
  },
  {
    "text": "deployment the data science platform has gained traction across many Blackrock teams so I won't go through all the uses",
    "start": "211200",
    "end": "219269"
  },
  {
    "text": "that I have here but I'm going to touch on a couple highlights for example our scientific active equity teams builds",
    "start": "219269",
    "end": "226829"
  },
  {
    "text": "ESG or environmental social and government governance alerts for a fund's positioning so for those of you",
    "start": "226829",
    "end": "234510"
  },
  {
    "text": "who don't know these are it's a score from 1 to 10 for a fund based on you",
    "start": "234510",
    "end": "240599"
  },
  {
    "text": "know various criteria and rankings in a environmental say you know owning you",
    "start": "240599",
    "end": "249660"
  },
  {
    "text": "know tobacco stocks or stuff like that we also have business operation teams",
    "start": "249660",
    "end": "256560"
  },
  {
    "text": "building quality control processes for our analytics and you know to validate",
    "start": "256560",
    "end": "262200"
  },
  {
    "text": "them and ensure accuracy and you know preciseness and we also have our portfolio modeling",
    "start": "262200",
    "end": "269280"
  },
  {
    "text": "team you know modeling our complex financial securities and instruments on this platform so really overall the",
    "start": "269280",
    "end": "276660"
  },
  {
    "text": "platform has been transformative for three major reasons first it's really augmented the technology available to",
    "start": "276660",
    "end": "283830"
  },
  {
    "text": "these investment teams secondly it's increased the collaboration across our",
    "start": "283830",
    "end": "289320"
  },
  {
    "text": "technologists to service the investor base and lastly it's really challenged as status quo on how we engage our",
    "start": "289320",
    "end": "296580"
  },
  {
    "text": "investors and how we deliver on these key business insights so despite the",
    "start": "296580",
    "end": "304950"
  },
  {
    "start": "303000",
    "end": "443000"
  },
  {
    "text": "successes of the platform to date you know as developers of the core",
    "start": "304950",
    "end": "310020"
  },
  {
    "text": "infrastructure you know we've gotten a lot of feedback around how to make it better and we've heard things like okay",
    "start": "310020",
    "end": "316560"
  },
  {
    "text": "you know this is awesome but I want to build you know real-time solution or something that's automated so I can use",
    "start": "316560",
    "end": "322320"
  },
  {
    "text": "the latest data and as soon as it becomes available well I just want to automatically kick",
    "start": "322320",
    "end": "327840"
  },
  {
    "text": "off this workflow I don't want to have to do it you know manually at the end of each financial quarter so basically",
    "start": "327840",
    "end": "335240"
  },
  {
    "text": "users wanted to be able to like schedule things they were doing in their Jupiter notebooks they didn't want to have to",
    "start": "335240",
    "end": "342030"
  },
  {
    "text": "manually kick off these jobs they just want it to be like notified when it was all done so now timing is an easy thing to to do",
    "start": "342030",
    "end": "350010"
  },
  {
    "text": "and most platforms support this and kubernetes even has their core you know",
    "start": "350010",
    "end": "355950"
  },
  {
    "text": "batch cron jobs but scheduling is actually really difficult we needed to",
    "start": "355950",
    "end": "362040"
  },
  {
    "text": "think you know not just about a simple time time trigger or you know a simple",
    "start": "362040",
    "end": "367740"
  },
  {
    "text": "cron expression but we actually needed to take into account a lot of things like file transfers object crud",
    "start": "367740",
    "end": "374370"
  },
  {
    "text": "operations you know streaming messages and complex holiday calendars so you remember how I",
    "start": "374370",
    "end": "381540"
  },
  {
    "text": "said like time was easy well in finance it's not Thanksgiving for example is a",
    "start": "381540",
    "end": "387270"
  },
  {
    "text": "u.s. holiday but the LIBOR Market which is basically a market for between you",
    "start": "387270",
    "end": "392940"
  },
  {
    "text": "know London banks to exchange funds that market is still open so you know and finance a concept like accrued interest",
    "start": "392940",
    "end": "399390"
  },
  {
    "text": "becomes crucially important so after we kind of digested all this feedback we condensed",
    "start": "399390",
    "end": "406289"
  },
  {
    "text": "it down into the problem statement that you see up here you know how do we automate the",
    "start": "406289",
    "end": "411360"
  },
  {
    "text": "scheduling manage the exceptions that always arise and provide transparency into these complex you know batch",
    "start": "411360",
    "end": "419069"
  },
  {
    "text": "processes now this is definitely a lot to consider",
    "start": "419069",
    "end": "424470"
  },
  {
    "text": "I mean and exceeds the scope of even kind of data science of where we started",
    "start": "424470",
    "end": "430520"
  },
  {
    "text": "but really when we boil it down are essentially our goal was to just make it easy to build and specify workflows that",
    "start": "430520",
    "end": "438150"
  },
  {
    "text": "cross band multiple teams and multiple domains so I just want to clarify for a",
    "start": "438150",
    "end": "446099"
  },
  {
    "start": "443000",
    "end": "747000"
  },
  {
    "text": "second what a workflow is right a set of tasks that you can put into separate you",
    "start": "446099",
    "end": "452520"
  },
  {
    "text": "know isolated parts break it down so you",
    "start": "452520",
    "end": "457650"
  },
  {
    "text": "know for the first two weeks of starting on this project velvet and I started by researching existing open source",
    "start": "457650",
    "end": "463710"
  },
  {
    "text": "platforms that we could leverage as a starting point for kind of the orchestration and composing these",
    "start": "463710",
    "end": "468750"
  },
  {
    "text": "workflows and as of the start of this project nearly at the beginning of the year we found a number of existing",
    "start": "468750",
    "end": "475710"
  },
  {
    "text": "technologies at our disposal so I just want to highlight a couple that we found one of the first ones that we found was",
    "start": "475710",
    "end": "482789"
  },
  {
    "text": "a project called air flow now air flow is an Apache incubating project and they define their workflows in Python and",
    "start": "482789",
    "end": "490020"
  },
  {
    "text": "they have a number of pluggable operators that you know allow a degree of customizations around your workflows",
    "start": "490020",
    "end": "496789"
  },
  {
    "text": "the second project we found was a project called Brigade now Brigade is developed at Microsoft and they're part",
    "start": "496789",
    "end": "503969"
  },
  {
    "text": "of the helm ecosystem and they use they kind of introduced a terminal like",
    "start": "503969",
    "end": "510449"
  },
  {
    "text": "scripting or pipes for building these containerized tasks on kubernetes and lastly we found a project called Argo",
    "start": "510449",
    "end": "518610"
  },
  {
    "text": "now Argo was different because they define their workflows as custom resources they",
    "start": "518610",
    "end": "526290"
  },
  {
    "text": "were extending the core kubernetes api to build workflow object",
    "start": "526290",
    "end": "532350"
  },
  {
    "text": "in the kubernetes api so I don't want to talk about in our whole story of how",
    "start": "532350",
    "end": "538890"
  },
  {
    "text": "each came to an open you know decision but ultimately we decided to pursue our go for really three main reasons you",
    "start": "538890",
    "end": "545310"
  },
  {
    "text": "know first it was very powerful we you know spend a couple weeks walking",
    "start": "545310",
    "end": "550590"
  },
  {
    "text": "through the examples and you know we were amazed that what we could do with this secondly it was by far the most",
    "start": "550590",
    "end": "557940"
  },
  {
    "text": "kubernetes native approach of all three and lastly it had an extremely active",
    "start": "557940",
    "end": "564300"
  },
  {
    "text": "and engaging community so during the",
    "start": "564300",
    "end": "570780"
  },
  {
    "text": "next couple weeks you know we read tons of documentation about building our code",
    "start": "570780",
    "end": "575910"
  },
  {
    "text": "workflows and we're playing around with the platform building our own and we you",
    "start": "575910",
    "end": "583410"
  },
  {
    "text": "know during one of our many impromptu brainstorming sessions which we had a lot of we started by drawing something",
    "start": "583410",
    "end": "589560"
  },
  {
    "text": "like you see here up on the board you know very simple straightforward linear",
    "start": "589560",
    "end": "594690"
  },
  {
    "text": "process and after a couple hours you know we put together all of our thoughts",
    "start": "594690",
    "end": "602490"
  },
  {
    "text": "and various use cases and we ended up with something like this which was a complete disaster and we",
    "start": "602490",
    "end": "611040"
  },
  {
    "text": "were like laughing it about it to each other we were like you know thinking about presenting us to our DevOps team",
    "start": "611040",
    "end": "616590"
  },
  {
    "text": "and telling them hey you know can we do this and yeah that was a no-go we needed",
    "start": "616590",
    "end": "622890"
  },
  {
    "text": "a better solution we needed something that could span multiple teams and",
    "start": "622890",
    "end": "628190"
  },
  {
    "text": "multiple domains so we started by you",
    "start": "628190",
    "end": "635040"
  },
  {
    "text": "know breaking apart this big puzzle and you can think of it kind of like this",
    "start": "635040",
    "end": "641310"
  },
  {
    "text": "complex monolithic workflow which we termed kind of their uber workflow which",
    "start": "641310",
    "end": "646350"
  },
  {
    "text": "was like this huge workflow cross banning our entire company that would like from you know early in the morning",
    "start": "646350",
    "end": "652290"
  },
  {
    "text": "would generate our analytics and then at the end of the day we have a nice report with you know all of our ready",
    "start": "652290",
    "end": "658560"
  },
  {
    "text": "information for our clients now we separated these components you know by natural API boundaries and data",
    "start": "658560",
    "end": "665370"
  },
  {
    "text": "layer access because we knew kind of like different teams wouldn't want to be working on the same workflows with teams that they",
    "start": "665370",
    "end": "672220"
  },
  {
    "text": "didn't you know really quote like you know work that on the same stuff with so",
    "start": "672220",
    "end": "679530"
  },
  {
    "text": "we ended up kinda with something like this we had workflows inside of workflows we had the compositions and",
    "start": "679530",
    "end": "685630"
  },
  {
    "text": "workflows and we really needed something to tie these pieces together right so",
    "start": "685630",
    "end": "692440"
  },
  {
    "text": "this is kind of my transition into you",
    "start": "692440",
    "end": "697480"
  },
  {
    "text": "know why we started to develop this eventing platform that we open sourced and in addition to connecting these",
    "start": "697480",
    "end": "704170"
  },
  {
    "text": "pieces together what's important is that it's come into a map of dependencies so",
    "start": "704170",
    "end": "711120"
  },
  {
    "text": "you know you can not just have a linear process but you have task 1 task two and",
    "start": "711120",
    "end": "716560"
  },
  {
    "text": "task 3 but you also have tasks for which you know task 2 is you know dependent on",
    "start": "716560",
    "end": "722710"
  },
  {
    "text": "as well as one so you know you have a map of essentially dependencies at a",
    "start": "722710",
    "end": "728620"
  },
  {
    "text": "higher level than just a simple workflow so you know this is really the motivation for our event framework are",
    "start": "728620",
    "end": "734470"
  },
  {
    "text": "going to we open source to the argo community and to the entire open source",
    "start": "734470",
    "end": "740170"
  },
  {
    "text": "community and so now I'm gonna hand it off to my colleague to introduce the",
    "start": "740170",
    "end": "745330"
  },
  {
    "text": "solution thanks man so yeah this saw that we need a framework that's pretty",
    "start": "745330",
    "end": "753820"
  },
  {
    "start": "747000",
    "end": "845000"
  },
  {
    "text": "much an event-driven workflow system so I'm going to talk about arguments and what exactly it has to offer so first",
    "start": "753820",
    "end": "760210"
  },
  {
    "text": "question is what is archived events was kubernetes native event-driven dependency manager so let's break that",
    "start": "760210",
    "end": "767740"
  },
  {
    "text": "definition into parts it's good when it is native because all the components that make up the system or the framework",
    "start": "767740",
    "end": "774640"
  },
  {
    "text": "are implemented as custom resources from ground up its event even though whole go",
    "start": "774640",
    "end": "780130"
  },
  {
    "text": "behind this project was like react on events so this framework offers a component called gateway which",
    "start": "780130",
    "end": "786520"
  },
  {
    "text": "essentially listens to events from external or internal event sources but",
    "start": "786520",
    "end": "791650"
  },
  {
    "text": "that's not enough consuming events is one part but what we really need here is a dependency manager",
    "start": "791650",
    "end": "797020"
  },
  {
    "text": "that can manage these different events so that's where sensors come into picture so sensors are essentially",
    "start": "797020",
    "end": "802830"
  },
  {
    "text": "components that manage this event dependences for you so to summarize quickly the gateways the",
    "start": "802830",
    "end": "809260"
  },
  {
    "text": "listen to events from external event sources transform these events make them",
    "start": "809260",
    "end": "814540"
  },
  {
    "text": "into cloud events specification compliant and forwards them to sensors sensors on the other hand they mentioned",
    "start": "814540",
    "end": "821290"
  },
  {
    "text": "list of events that they expect from one or more gateways and upon receiving those events they trigger a set of",
    "start": "821290",
    "end": "827380"
  },
  {
    "text": "actions now at Blackrock and most of our use cases we have our overflows as the triggers but you can",
    "start": "827380",
    "end": "833820"
  },
  {
    "text": "essentially trigger any kubernetes resource it can be a standard kubernetes",
    "start": "833820",
    "end": "839710"
  },
  {
    "text": "resource like pod or deployment or it can be any custom resource you can have these things as a triggers so yeah we",
    "start": "839710",
    "end": "846340"
  },
  {
    "text": "are going to see our governments in action so I'm going to explain what we are",
    "start": "846340",
    "end": "851500"
  },
  {
    "text": "going to do here we will set up a simple image processing pipeline and we will set up a gateway for s3 and we will have",
    "start": "851500",
    "end": "859960"
  },
  {
    "text": "some sensors and some triggers running man so the first thing is we don't have",
    "start": "859960",
    "end": "869800"
  },
  {
    "text": "our go events set up in our cluster so we are going to set up our go events from scratch",
    "start": "869800",
    "end": "875880"
  },
  {
    "text": "so it installs couple of CRD is mainly for gateway and sensor and installs the",
    "start": "880220",
    "end": "885350"
  },
  {
    "text": "controls",
    "start": "885350",
    "end": "888310"
  },
  {
    "text": "all right okay so we just install couple of C IDs and the controllers and we are using s3",
    "start": "906560",
    "end": "915139"
  },
  {
    "text": "to store our input and output image so what we are going to do is where we are",
    "start": "915139",
    "end": "920610"
  },
  {
    "text": "going to like put an image on s3 bucket and as soon as we put that on s3 the",
    "start": "920610",
    "end": "926970"
  },
  {
    "text": "system is going to trigger an hour ago workflow and we are going to convert the image into grayscale and put it back on",
    "start": "926970",
    "end": "933749"
  },
  {
    "text": "to s3 and that will again trigger another workflow it will print a simple message saying that the event pipeline",
    "start": "933749",
    "end": "940439"
  },
  {
    "text": "is complete so the next thing is to speed up a gateway so here is an s3",
    "start": "940439",
    "end": "947670"
  },
  {
    "text": "gateway this is a spec it's very straightforward it has a couple of things like the deploy spec which is",
    "start": "947670",
    "end": "953550"
  },
  {
    "text": "essentially your pod pod spec and then it has a type I'll go into details for",
    "start": "953550",
    "end": "959610"
  },
  {
    "text": "the exact what exactly type is but for now it's just it's a shitty bit of ash",
    "start": "959610",
    "end": "965399"
  },
  {
    "text": "atiba gateway and there are a couple of watches so watches are nothing but the sensors so you can like list different",
    "start": "965399",
    "end": "973980"
  },
  {
    "text": "sensors in the gateway spec so that whenever Gateway consumes an event from an external event source it will forward",
    "start": "973980",
    "end": "979860"
  },
  {
    "text": "that you went to these sensors",
    "start": "979860",
    "end": "982938"
  },
  {
    "text": "so the gateways part is up and running so next thing is to configure this",
    "start": "986960",
    "end": "992270"
  },
  {
    "text": "gateway with different event sources now the event source in the in this case is input bucket and the output bucket",
    "start": "992270",
    "end": "999140"
  },
  {
    "text": "that's stored on the s3 so this is how the event sauce looks like it's pretty",
    "start": "999140",
    "end": "1004480"
  },
  {
    "text": "simple we are just mentioning that we are interested listening SNS notifications from input and output",
    "start": "1004480",
    "end": "1010390"
  },
  {
    "text": "buckets and we should get the event only when there is an object put and event",
    "start": "1010390",
    "end": "1019209"
  },
  {
    "text": "sources are configured using kubernetes config map so so that way you can",
    "start": "1019209",
    "end": "1025410"
  },
  {
    "text": "essentially add or remove any event source you want on fly you don't have to",
    "start": "1025410",
    "end": "1030670"
  },
  {
    "text": "like you don't have any downtime for gateway yet we can continue to keep on running and you can essentially add the",
    "start": "1030670",
    "end": "1037780"
  },
  {
    "text": "event source anytime X so the next thing is to set up the sensors so we will have",
    "start": "1037780",
    "end": "1044589"
  },
  {
    "text": "couple of sensors the first one will be the input sensor and the second will be the output sensor the sensor spec is",
    "start": "1044589",
    "end": "1050470"
  },
  {
    "text": "also a pretty much straightforward it has a signal which is basically it's",
    "start": "1050470",
    "end": "1056230"
  },
  {
    "text": "specifying from which Gateway we should this sensor should get an event the",
    "start": "1056230",
    "end": "1061870"
  },
  {
    "text": "Gateway name is s3 and from which exact particular event source the event sources input so as soon as this sensor",
    "start": "1061870",
    "end": "1068590"
  },
  {
    "text": "receives an event from s3 Gateway and event event source called input it will",
    "start": "1068590",
    "end": "1074410"
  },
  {
    "text": "trigger an Ergo workflow so in the source you will see that there is a our",
    "start": "1074410",
    "end": "1080860"
  },
  {
    "text": "go workflow that's describes in line or go workflow this example has in line or",
    "start": "1080860",
    "end": "1086410"
  },
  {
    "text": "go workflow but you can basically store your workflows on s3 buckets you can store it on gate and you can reference",
    "start": "1086410",
    "end": "1092740"
  },
  {
    "text": "those workflows in the spec I guess the sensor part is up we need to create one",
    "start": "1092740",
    "end": "1100000"
  },
  {
    "text": "more sensor for the output bucket",
    "start": "1100000",
    "end": "1104850"
  },
  {
    "text": "okay so the setup is done we have our gateways and sensors ready so the next",
    "start": "1110620",
    "end": "1116020"
  },
  {
    "text": "thing is to upload an image to s3 bucket",
    "start": "1116020",
    "end": "1121260"
  },
  {
    "text": "so we already pre-prepared an image and we're just going to as you said load it",
    "start": "1122279",
    "end": "1128620"
  },
  {
    "text": "but also important to watch the right side of the screen to automatically see the workflows and pause being created",
    "start": "1128620",
    "end": "1137220"
  },
  {
    "text": "[Applause]",
    "start": "1147980",
    "end": "1154359"
  },
  {
    "text": "No yeah we just need to transfer an image",
    "start": "1162520",
    "end": "1171120"
  },
  {
    "text": "did you say give us a second give us a second yeah",
    "start": "1179840",
    "end": "1187780"
  },
  {
    "text": "there we go yeah okay",
    "start": "1193430",
    "end": "1200820"
  },
  {
    "text": "[Applause] just juice",
    "start": "1201380",
    "end": "1205860"
  },
  {
    "text": "and we have our cluster set up on the Google cloud right now for the Draper so and we have an s3 beam yure server",
    "start": "1206460",
    "end": "1213360"
  },
  {
    "text": "running there is a single instance mini server I guess so on the right side you",
    "start": "1213360",
    "end": "1218910"
  },
  {
    "text": "can see that couple of workflows that got triggered the first one was the workflow that actually converted the",
    "start": "1218910",
    "end": "1225090"
  },
  {
    "text": "input image into grayscale it put it back onto s3 and that triggered another workflow and that just simply printed",
    "start": "1225090",
    "end": "1231590"
  },
  {
    "text": "like message saying the pipeline is complete so we are going to download the",
    "start": "1231590",
    "end": "1242150"
  },
  {
    "text": "grayscale image from output bucket",
    "start": "1242150",
    "end": "1246470"
  },
  {
    "text": "so those are out put them and there is our",
    "start": "1258590",
    "end": "1263990"
  },
  {
    "text": "pretty much it so this is Rhea",
    "start": "1263990",
    "end": "1269510"
  },
  {
    "text": "I'm in this is how simple it is to use our go events and to like chain your events basically or original that that",
    "start": "1269510",
    "end": "1276770"
  },
  {
    "text": "was our original Madea so basically you can have multiple gateways and sensors and you can change these gateways and",
    "start": "1276770",
    "end": "1283100"
  },
  {
    "text": "sensors and have your events flow from end to end and set up this whole the workflow pipeline so next thing is",
    "start": "1283100",
    "end": "1293830"
  },
  {
    "start": "1299000",
    "end": "1365000"
  },
  {
    "text": "so next thing is I want to like go over a couple of features that this framework has to offer so the important one is",
    "start": "1299610",
    "end": "1305980"
  },
  {
    "text": "it's a lightweight so you saw that we just needed couple of CRTs to get started with our events and also we like",
    "start": "1305980",
    "end": "1312790"
  },
  {
    "text": "package everything using containers so depending upon the implementation of your gateway your container sizes can be",
    "start": "1312790",
    "end": "1319090"
  },
  {
    "text": "as small as few megabytes so it's very lightweight framework and very much focused on inventing it's easily",
    "start": "1319090",
    "end": "1325300"
  },
  {
    "text": "extensible so when we started writing this project which shows go as our programming language but we don't expect",
    "start": "1325300",
    "end": "1331920"
  },
  {
    "text": "users of this framework to write their code and go to implement a custom gateway so the Gateway is divided into",
    "start": "1331920",
    "end": "1338920"
  },
  {
    "text": "components such that each component can talk to other component over go channels HTTP or G RPC so as long as your",
    "start": "1338920",
    "end": "1346360"
  },
  {
    "text": "implementation can or your programming language supports HTTP RPC you can",
    "start": "1346360",
    "end": "1351730"
  },
  {
    "text": "essentially write a custom gateway and it is configurable at runtime so you can",
    "start": "1351730",
    "end": "1357610"
  },
  {
    "text": "add or remove event source anytime you wish there is no downtime for the",
    "start": "1357610",
    "end": "1363550"
  },
  {
    "text": "gateway so let's talk about a couple of use cases that we have at Blackrock",
    "start": "1363550",
    "end": "1369220"
  },
  {
    "start": "1365000",
    "end": "1451000"
  },
  {
    "text": "so Blackrock as being financial firm we run a lot of financial models which",
    "start": "1369220",
    "end": "1374770"
  },
  {
    "text": "Android many reports for our portfolios for our funds but some of these",
    "start": "1374770",
    "end": "1380020"
  },
  {
    "text": "processes they need our data from some third-party financial vendors and so we",
    "start": "1380020",
    "end": "1385900"
  },
  {
    "text": "use this platform called data source in platform it's which essentially acquires financial data from different vendors",
    "start": "1385900",
    "end": "1392500"
  },
  {
    "text": "validate validate that data process it and then feed it to downstream",
    "start": "1392500",
    "end": "1397570"
  },
  {
    "text": "applications now the constraint on this system is we expect data fields from",
    "start": "1397570",
    "end": "1403570"
  },
  {
    "text": "vendors to be present at a certain time in a day so we use a gateway called file",
    "start": "1403570",
    "end": "1408610"
  },
  {
    "text": "watch our gateway whenever there is a new data feed available from vendor so the file watch",
    "start": "1408610",
    "end": "1413740"
  },
  {
    "text": "our gateway it generates an event whenever there is a new vendor file and to make sure that these vendor files",
    "start": "1413740",
    "end": "1419680"
  },
  {
    "text": "arrive at a certain time in a day we use calendar gateway so once we get this",
    "start": "1419680",
    "end": "1424720"
  },
  {
    "text": "files in Blackrock which River some 80 overflows which transforms these data",
    "start": "1424720",
    "end": "1430360"
  },
  {
    "text": "fields into internal representation and stoled on s3 and once we have this date on s3",
    "start": "1430360",
    "end": "1437470"
  },
  {
    "text": "basically we consume the SNS notification using is-3 gateway and then we trigger the spark jobs I won't go",
    "start": "1437470",
    "end": "1444170"
  },
  {
    "text": "into detail what this part ops - but they help generate financial models now",
    "start": "1444170",
    "end": "1452690"
  },
  {
    "start": "1451000",
    "end": "1577000"
  },
  {
    "text": "we got the data from our vendors now the next thing is to make sure that we make",
    "start": "1452690",
    "end": "1458780"
  },
  {
    "text": "that data available to our internal financial analysts and researchers so that's where our data science platform",
    "start": "1458780",
    "end": "1464990"
  },
  {
    "text": "comes into picture it of the data sense platform offers a variety of Jupiter",
    "start": "1464990",
    "end": "1470000"
  },
  {
    "text": "notebooks that a user can spin up on the fly and run their research on flows one",
    "start": "1470000",
    "end": "1475910"
  },
  {
    "text": "of that one of such TripIt are notebooks is fixed income notebook so this fixed",
    "start": "1475910",
    "end": "1481430"
  },
  {
    "text": "income notebook basically helps deliver different teams generate alpha which is",
    "start": "1481430",
    "end": "1486620"
  },
  {
    "text": "market leading performance for different portfolios to their clients now it has",
    "start": "1486620",
    "end": "1491960"
  },
  {
    "text": "some couple of minute has some complex algorithms like risk killing transformation and it runs optimization",
    "start": "1491960",
    "end": "1498860"
  },
  {
    "text": "on the final of financial models so it has pretty complex mathematical computation and this whole process takes",
    "start": "1498860",
    "end": "1505580"
  },
  {
    "text": "time so users of this are not they I mean although they can run this notebook",
    "start": "1505580",
    "end": "1511550"
  },
  {
    "text": "on fly they don't want it they want this particular notebook to run on a specific business state using a very specific",
    "start": "1511550",
    "end": "1518780"
  },
  {
    "text": "financial calendar and only when market closes so for all these requirements we",
    "start": "1518780",
    "end": "1523940"
  },
  {
    "text": "use calendar gateway and we configures these schedules but that's not enough",
    "start": "1523940",
    "end": "1529340"
  },
  {
    "text": "because we need to make sure that we follow certain like SLS so we also like",
    "start": "1529340",
    "end": "1534920"
  },
  {
    "text": "configure these gateways with some offsets so that take care of the failure scenarios and once the schedule",
    "start": "1534920",
    "end": "1541250"
  },
  {
    "text": "completes we use our gopher flows to deploy this Jupiter notebooks and these",
    "start": "1541250",
    "end": "1546860"
  },
  {
    "text": "use cases are just like tip of iceberg because at the end of the day if we still have something like this at",
    "start": "1546860",
    "end": "1552260"
  },
  {
    "text": "Blackrock we have so many different teams trying to coordinate with each other run their workflows but what the",
    "start": "1552260",
    "end": "1558440"
  },
  {
    "text": "census and gateways provider says this clear sense of responsibility of like consuming events and then",
    "start": "1558440",
    "end": "1564530"
  },
  {
    "text": "different actions so our governments  provides a nice interface so that different teams can coordinate with",
    "start": "1564530",
    "end": "1571520"
  },
  {
    "text": "each other and run their workflows so I",
    "start": "1571520",
    "end": "1580010"
  },
  {
    "start": "1577000",
    "end": "1826000"
  },
  {
    "text": "just want to kind of conclude with some takeaways and some learnings from this",
    "start": "1580010",
    "end": "1585620"
  },
  {
    "text": "project so one of the most important and you know apparent external insights that",
    "start": "1585620",
    "end": "1591260"
  },
  {
    "text": "we took away was this growing industry trend towards automation especially on",
    "start": "1591260",
    "end": "1596540"
  },
  {
    "text": "the cloud and especially on kubernetes so even in the you know the last year",
    "start": "1596540",
    "end": "1601910"
  },
  {
    "text": "we've seen a number of new projects you know tackling similar solutions but you know focused on different use cases pop",
    "start": "1601910",
    "end": "1607730"
  },
  {
    "text": "up in the ecosystem you know we mentioned the project's earlier in the presentation things like air flow and",
    "start": "1607730",
    "end": "1614390"
  },
  {
    "text": "Brigade and you know and and also you know new platforms even coming up you",
    "start": "1614390",
    "end": "1620030"
  },
  {
    "text": "know here being at cube con and hearing some of those as well so another",
    "start": "1620030",
    "end": "1626150"
  },
  {
    "text": "interesting area that we that we were watching was the kubernetes api space and so since the adoption of the",
    "start": "1626150",
    "end": "1633470"
  },
  {
    "text": "kubernetes customer resources you know since they were released in one point seven you know going with a project like",
    "start": "1633470",
    "end": "1639680"
  },
  {
    "text": "argo and building upon that with you know custom resources really confirmed our decision to choose argo as the",
    "start": "1639680",
    "end": "1647060"
  },
  {
    "text": "workflow solution and I really believe you know a simpler unifying eventing",
    "start": "1647060",
    "end": "1652940"
  },
  {
    "text": "platform using just cut using customer resources built upon kubernetes it is a",
    "start": "1652940",
    "end": "1658010"
  },
  {
    "text": "way forward for us and you know personally I think I speak for both of",
    "start": "1658010",
    "end": "1663500"
  },
  {
    "text": "us like a year ago I didn't know anything about kubernetes and now we're",
    "start": "1663500",
    "end": "1671660"
  },
  {
    "text": "here presenting to you guys so simply having the opportunity to work on you",
    "start": "1671660",
    "end": "1676910"
  },
  {
    "text": "know an externally open source project has been really you know awesome experience and we came you know to",
    "start": "1676910",
    "end": "1684740"
  },
  {
    "text": "appreciate the real fast-paced nature of development in the open source community and you know being able to quickly adapt",
    "start": "1684740",
    "end": "1692030"
  },
  {
    "text": "to you know the ever shifting landscape so internally are go immense",
    "start": "1692030",
    "end": "1698380"
  },
  {
    "text": "has already kind of exceeded its initial scope you know as web of showed you guys you know we're using it for the data",
    "start": "1698380",
    "end": "1704920"
  },
  {
    "text": "science platform but we're also exploring it for other solutions as I hinted to before we have you know a",
    "start": "1704920",
    "end": "1711490"
  },
  {
    "text": "heavy bachelor in that process at Blackrock and automating this you know today you know on our monolithic kind of",
    "start": "1711490",
    "end": "1717760"
  },
  {
    "text": "legacy system using something distributed and on kubernetes and",
    "start": "1717760",
    "end": "1723010"
  },
  {
    "text": "containerized is a very attractive solution for us so you know we're",
    "start": "1723010",
    "end": "1728740"
  },
  {
    "text": "currently evaluating using it as you know an operational tool integrating it you know with the rest of the agro",
    "start": "1728740",
    "end": "1734850"
  },
  {
    "text": "projects including the Argos CD project it you know as a DevOps kind of full",
    "start": "1734850",
    "end": "1741310"
  },
  {
    "text": "suite solution and and lastly you know personally I think you know we've gotten",
    "start": "1741310",
    "end": "1746500"
  },
  {
    "text": "tons of exposure to working on this project and collaborating with companies across the United States and learning",
    "start": "1746500",
    "end": "1753100"
  },
  {
    "text": "really new and exciting things so you know we're really excited to share the story and share the project that we",
    "start": "1753100",
    "end": "1759340"
  },
  {
    "text": "built you know we really want to continue to develop and you know new",
    "start": "1759340",
    "end": "1765370"
  },
  {
    "text": "tools for the future of kubernetes based automation and we urge anyone interested",
    "start": "1765370",
    "end": "1771160"
  },
  {
    "text": "to you know don't hesitate reach out to us we'll be we'll be here after check",
    "start": "1771160",
    "end": "1777100"
  },
  {
    "text": "out the argo project online and big shout out to the r-dog folks for being very receptive for kind of welcoming us",
    "start": "1777100",
    "end": "1784930"
  },
  {
    "text": "into the community along the way so yeah thank you very much and we'll now open",
    "start": "1784930",
    "end": "1792970"
  },
  {
    "text": "it up for a question [Applause]",
    "start": "1792970",
    "end": "1801900"
  },
  {
    "text": "yep",
    "start": "1801900",
    "end": "1804900"
  },
  {
    "text": "so that looks something like that like this so this one right okay so we're out",
    "start": "1811999",
    "end": "1829769"
  },
  {
    "text": "of box provide like some core gateways for webhooks has three SS notifications like calendar",
    "start": "1829769",
    "end": "1836249"
  },
  {
    "text": "gateways even messaging cues like cough contacts and even you can have kubernetes resource as an event source",
    "start": "1836249",
    "end": "1843269"
  },
  {
    "text": "so in it any updates to any kubernetes resource standard or custom you can watch those events basically so these",
    "start": "1843269",
    "end": "1849809"
  },
  {
    "text": "are like provided out of box but then you can write your own implementation of a gateway and that's that implementation",
    "start": "1849809",
    "end": "1857729"
  },
  {
    "text": "you can write it in any language basically and you don't have to worry about like different components of like",
    "start": "1857729",
    "end": "1863339"
  },
  {
    "text": "handling what happens when a new event source got gets added or removed you don't have to worry about all unit to",
    "start": "1863339",
    "end": "1869609"
  },
  {
    "text": "provide the implementation is just what you vent source you are you try to listen to you and how you want to",
    "start": "1869609",
    "end": "1875699"
  },
  {
    "text": "consume that event that's it it's about yeah exactly and if you are if you want",
    "start": "1875699",
    "end": "1882089"
  },
  {
    "text": "to write in go then we already have the core gateways in go so you can just like literally have that template and copy",
    "start": "1882089",
    "end": "1888779"
  },
  {
    "text": "tree for your gate man just change that particular piece of code that consumes events here",
    "start": "1888779",
    "end": "1895819"
  },
  {
    "text": "[Music] Oh",
    "start": "1898710",
    "end": "1903080"
  },
  {
    "text": "that's a great question um you would contribute to the Argo events repo the",
    "start": "1912850",
    "end": "1918670"
  },
  {
    "text": "Argo project the workflows are kind of agnostic to the events happening right",
    "start": "1918670",
    "end": "1923980"
  },
  {
    "text": "we're just trying to trigger oh sorry to repeat the question was if you know he",
    "start": "1923980",
    "end": "1931570"
  },
  {
    "text": "we were going to build a custom gateway say for as your walk blob blob storage",
    "start": "1931570",
    "end": "1938020"
  },
  {
    "text": "you know which repo would I contribute to which wish so it would be the Argo",
    "start": "1938020",
    "end": "1943030"
  },
  {
    "text": "events repo the REO events kind of integrates you know the implementations of each of the event sources you can",
    "start": "1943030",
    "end": "1950110"
  },
  {
    "text": "implement an interface you know open up open an issue and we'll take a look at building it",
    "start": "1950110",
    "end": "1958020"
  },
  {
    "text": "so as far as like the what the agro workflow so as it triggers we run our go",
    "start": "1972120",
    "end": "1977429"
  },
  {
    "text": "over flows right so the sensors and gateways are continuously like long running oh sorry sorry",
    "start": "1977429",
    "end": "1983549"
  },
  {
    "text": "trigger so the question is how do we maintain like long-running processes like how we mint and like longer flows",
    "start": "1983549",
    "end": "1989970"
  },
  {
    "text": "or how we even monitor them right so yeah sensors gateways are continuously long-running but the workflows are group",
    "start": "1989970",
    "end": "1996779"
  },
  {
    "text": "team provides a new Y that you can like monitor your workflows but it's not",
    "start": "1996779",
    "end": "2002630"
  },
  {
    "text": "exactly part of our go event so as our way events we I don't want to say we don't care but whatever trigger that you",
    "start": "2002630",
    "end": "2009350"
  },
  {
    "text": "are execute is because we don't maintain those that particular piece of software",
    "start": "2009350",
    "end": "2015919"
  },
  {
    "text": "it's you can either trigger a workflow or Google or any kubernetes resource so it's like yes yes and because there are",
    "start": "2015919",
    "end": "2024020"
  },
  {
    "text": "just resources on kubernetes right they follow the same paradigm between you know controller so an object you know",
    "start": "2024020",
    "end": "2031490"
  },
  {
    "text": "any P I object so in speaking for the are go workflows right you create a workflow you know the",
    "start": "2031490",
    "end": "2036860"
  },
  {
    "text": "the kubernetes system will you know ensure that your desired state matches",
    "start": "2036860",
    "end": "2043250"
  },
  {
    "text": "your or your actual States as it matches your desired state so right yes that's",
    "start": "2043250",
    "end": "2052550"
  },
  {
    "text": "correct the to clarify the are go workflows our kubernetes native objects that you can use cute details",
    "start": "2052550",
    "end": "2060338"
  },
  {
    "text": "any other questions all right well thank you very much thanks [Applause]",
    "start": "2064170",
    "end": "2069370"
  },
  {
    "text": "[Music] [Applause]",
    "start": "2069370",
    "end": "2072690"
  }
]
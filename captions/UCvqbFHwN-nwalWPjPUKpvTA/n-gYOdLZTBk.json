[
  {
    "text": "good afternoon everybody uh and uh",
    "start": "40",
    "end": "2200"
  },
  {
    "text": "Welcome to our talk uh today uh we're",
    "start": "2200",
    "end": "4880"
  },
  {
    "text": "going to talk about how we at datab",
    "start": "4880",
    "end": "6440"
  },
  {
    "text": "bricks are using the argu ecosystem and",
    "start": "6440",
    "end": "9679"
  },
  {
    "text": "combining it with multiple Cloud native",
    "start": "9679",
    "end": "11639"
  },
  {
    "text": "Technologies such as Prometheus",
    "start": "11639",
    "end": "13480"
  },
  {
    "text": "kubernetes Envoy to support our model",
    "start": "13480",
    "end": "16160"
  },
  {
    "text": "serving system and how we using it to",
    "start": "16160",
    "end": "18600"
  },
  {
    "text": "scale to meet our customer",
    "start": "18600",
    "end": "20400"
  },
  {
    "text": "requirements uh we'll talk about a",
    "start": "20400",
    "end": "22160"
  },
  {
    "text": "couple of challenges and how our go is",
    "start": "22160",
    "end": "24119"
  },
  {
    "text": "helping us address those challenges the",
    "start": "24119",
    "end": "26160"
  },
  {
    "text": "talk will be fairly introductory given",
    "start": "26160",
    "end": "27760"
  },
  {
    "text": "the time constraints and the number of",
    "start": "27760",
    "end": "29560"
  },
  {
    "text": "challenges want to talk about awesome",
    "start": "29560",
    "end": "32279"
  },
  {
    "text": "your presenters for today are Rohit agal",
    "start": "32279",
    "end": "35520"
  },
  {
    "text": "hi this is Rohit Agarwal I work on the",
    "start": "35520",
    "end": "37680"
  },
  {
    "text": "traffic platform team at data bricks and",
    "start": "37680",
    "end": "39760"
  },
  {
    "text": "then my team mostly handles the Ingress",
    "start": "39760",
    "end": "41360"
  },
  {
    "text": "and egress tack uh things like service",
    "start": "41360",
    "end": "43760"
  },
  {
    "text": "mesh and I'm here with my colleague urj",
    "start": "43760",
    "end": "46280"
  },
  {
    "text": "hey and I'm Arjun Duna and I work on the",
    "start": "46280",
    "end": "48320"
  },
  {
    "text": "Gen serving team at dat bricks and I",
    "start": "48320",
    "end": "50360"
  },
  {
    "text": "focus on the ml andr",
    "start": "50360",
    "end": "52520"
  },
  {
    "text": "stack uh before I continue I'd like to",
    "start": "52520",
    "end": "54680"
  },
  {
    "text": "introduce datab bricks to those of you",
    "start": "54680",
    "end": "55879"
  },
  {
    "text": "all who don't know about it so data",
    "start": "55879",
    "end": "57719"
  },
  {
    "text": "bricks is a SAS platform and with a very",
    "start": "57719",
    "end": "60440"
  },
  {
    "text": "simple Mission uh we want to democratize",
    "start": "60440",
    "end": "63160"
  },
  {
    "text": "data and AI what does that mean is we",
    "start": "63160",
    "end": "65880"
  },
  {
    "text": "give you all a unified platform where",
    "start": "65880",
    "end": "67799"
  },
  {
    "text": "every individual not engineer but",
    "start": "67799",
    "end": "70520"
  },
  {
    "text": "individual uh has the tools and",
    "start": "70520",
    "end": "72520"
  },
  {
    "text": "capabilities required to uh you know",
    "start": "72520",
    "end": "74960"
  },
  {
    "text": "make sense of your data and drive better",
    "start": "74960",
    "end": "77240"
  },
  {
    "text": "data driven decisions this includes your",
    "start": "77240",
    "end": "79720"
  },
  {
    "text": "ETL workloads your model training stack",
    "start": "79720",
    "end": "82000"
  },
  {
    "text": "your model serving stack Stitch it",
    "start": "82000",
    "end": "84119"
  },
  {
    "text": "together with really good lineage",
    "start": "84119",
    "end": "86439"
  },
  {
    "text": "tracking and uh combine it to the",
    "start": "86439",
    "end": "88520"
  },
  {
    "text": "government's governance framework",
    "start": "88520",
    "end": "90560"
  },
  {
    "text": "uh We've grown rapidly over the past few",
    "start": "90560",
    "end": "92280"
  },
  {
    "text": "years we're over 7,000 rster strong uh",
    "start": "92280",
    "end": "95240"
  },
  {
    "text": "globally and we are hiring so do check",
    "start": "95240",
    "end": "97280"
  },
  {
    "text": "out our careers",
    "start": "97280",
    "end": "99079"
  },
  {
    "text": "page let's talk about the AI life cycle",
    "start": "99079",
    "end": "102799"
  },
  {
    "text": "when you start with the AI life cycle",
    "start": "102799",
    "end": "104520"
  },
  {
    "text": "you'll generally start with some raw",
    "start": "104520",
    "end": "107079"
  },
  {
    "text": "data set you take that data set uh clean",
    "start": "107079",
    "end": "109920"
  },
  {
    "text": "it and make your train data from there",
    "start": "109920",
    "end": "111960"
  },
  {
    "text": "optionally also a feature store uh from",
    "start": "111960",
    "end": "114600"
  },
  {
    "text": "there you train a number of models on",
    "start": "114600",
    "end": "117640"
  },
  {
    "text": "that data and evaluate all those models",
    "start": "117640",
    "end": "121119"
  },
  {
    "text": "on some Metric that you care about and",
    "start": "121119",
    "end": "124320"
  },
  {
    "text": "then you choose the best performing",
    "start": "124320",
    "end": "125880"
  },
  {
    "text": "model and deploy that",
    "start": "125880",
    "end": "128360"
  },
  {
    "text": "model which means that with all the",
    "start": "128360",
    "end": "131480"
  },
  {
    "text": "Investments you have made through the",
    "start": "131480",
    "end": "132840"
  },
  {
    "text": "entire life cycle the actual business",
    "start": "132840",
    "end": "135640"
  },
  {
    "text": "utilization of potential is only",
    "start": "135640",
    "end": "137879"
  },
  {
    "text": "realized once you deploy that",
    "start": "137879",
    "end": "140080"
  },
  {
    "text": "model in that case you need to make sure",
    "start": "140080",
    "end": "142239"
  },
  {
    "text": "that the deployment is you know a good",
    "start": "142239",
    "end": "144360"
  },
  {
    "text": "deployment with it's good production use",
    "start": "144360",
    "end": "146519"
  },
  {
    "text": "case deployment enter gen serving with",
    "start": "146519",
    "end": "148959"
  },
  {
    "text": "data brakes so datab briak allows you to",
    "start": "148959",
    "end": "151519"
  },
  {
    "text": "deploy any custom model that you care",
    "start": "151519",
    "end": "153360"
  },
  {
    "text": "about uh trained on any framework that",
    "start": "153360",
    "end": "155959"
  },
  {
    "text": "you've been using tensor flow P",
    "start": "155959",
    "end": "158160"
  },
  {
    "text": "whichever it supports CPU and GPU",
    "start": "158160",
    "end": "160680"
  },
  {
    "text": "serving in addition uh datab bricks also",
    "start": "160680",
    "end": "163840"
  },
  {
    "text": "curates a list of top foundational model",
    "start": "163840",
    "end": "165920"
  },
  {
    "text": "apis so that you can start experimenting",
    "start": "165920",
    "end": "168159"
  },
  {
    "text": "with model serving without you know",
    "start": "168159",
    "end": "169760"
  },
  {
    "text": "having to go through the training",
    "start": "169760",
    "end": "170840"
  },
  {
    "text": "process and you can also use gen serving",
    "start": "170840",
    "end": "173920"
  },
  {
    "text": "as a gateway to external model providers",
    "start": "173920",
    "end": "176400"
  },
  {
    "text": "such as open AI you get all of this with",
    "start": "176400",
    "end": "179000"
  },
  {
    "text": "a unified U I API and SDK to manage all",
    "start": "179000",
    "end": "182440"
  },
  {
    "text": "these types of AI",
    "start": "182440",
    "end": "184120"
  },
  {
    "text": "models it is seress out of the box which",
    "start": "184120",
    "end": "187319"
  },
  {
    "text": "means that our customers can now make",
    "start": "187319",
    "end": "189920"
  },
  {
    "text": "the availability versus cost tradeoff",
    "start": "189920",
    "end": "192799"
  },
  {
    "text": "using request based order scaling it",
    "start": "192799",
    "end": "195879"
  },
  {
    "text": "also comes with the scale to zero option",
    "start": "195879",
    "end": "198000"
  },
  {
    "text": "so it's really useful when you're",
    "start": "198000",
    "end": "199440"
  },
  {
    "text": "developing your models uh and you're",
    "start": "199440",
    "end": "201440"
  },
  {
    "text": "testing them out uh before you",
    "start": "201440",
    "end": "202959"
  },
  {
    "text": "productionize them as with any real-time",
    "start": "202959",
    "end": "205959"
  },
  {
    "text": "serving system it is SLA back it has SL",
    "start": "205959",
    "end": "208480"
  },
  {
    "text": "backed availability low latency overhead",
    "start": "208480",
    "end": "211040"
  },
  {
    "text": "secure Deo deployment it integrates",
    "start": "211040",
    "end": "213519"
  },
  {
    "text": "really cleanly with your feature stores",
    "start": "213519",
    "end": "215159"
  },
  {
    "text": "which could be online in nature and your",
    "start": "215159",
    "end": "217439"
  },
  {
    "text": "vector indexes to power your rag your",
    "start": "217439",
    "end": "219720"
  },
  {
    "text": "rag applications that everyone cares",
    "start": "219720",
    "end": "221159"
  },
  {
    "text": "about today and then you have your",
    "start": "221159",
    "end": "222840"
  },
  {
    "text": "governance with unity catalog and",
    "start": "222840",
    "end": "224680"
  },
  {
    "text": "request response logging to reduce your",
    "start": "224680",
    "end": "226239"
  },
  {
    "text": "errors with INF frence",
    "start": "226239",
    "end": "229319"
  },
  {
    "text": "tables cool next one more so since it's",
    "start": "229599",
    "end": "233680"
  },
  {
    "text": "launch uh uh last year it's been less",
    "start": "233680",
    "end": "236680"
  },
  {
    "text": "than a year since we G gen serving we",
    "start": "236680",
    "end": "239000"
  },
  {
    "text": "serve a, weekly active customers uh",
    "start": "239000",
    "end": "241760"
  },
  {
    "text": "there are about 5,000 plus active",
    "start": "241760",
    "end": "243319"
  },
  {
    "text": "endpoints being queried we support a Max",
    "start": "243319",
    "end": "245680"
  },
  {
    "text": "of about 25,000 QPS per Cloud region and",
    "start": "245680",
    "end": "248519"
  },
  {
    "text": "is currently G on AWS Azure with gcp uh",
    "start": "248519",
    "end": "252159"
  },
  {
    "text": "coming",
    "start": "252159",
    "end": "253000"
  },
  {
    "text": "soon so let's talk about the first focus",
    "start": "253000",
    "end": "256079"
  },
  {
    "text": "of our talk which is the Gen serving",
    "start": "256079",
    "end": "259199"
  },
  {
    "text": "Ingress stack and see how Argo helps us",
    "start": "259199",
    "end": "262320"
  },
  {
    "text": "release this Ingress stack and update it",
    "start": "262320",
    "end": "265040"
  },
  {
    "text": "with high confidence and",
    "start": "265040",
    "end": "266919"
  },
  {
    "text": "stability the Ingress stack is crucial",
    "start": "266919",
    "end": "269479"
  },
  {
    "text": "to our serving system as we said it",
    "start": "269479",
    "end": "271560"
  },
  {
    "text": "supports up to 25k QPS for our",
    "start": "271560",
    "end": "274320"
  },
  {
    "text": "customers in addition it does",
    "start": "274320",
    "end": "277080"
  },
  {
    "text": "authentication and authorization",
    "start": "277080",
    "end": "278759"
  },
  {
    "text": "verification it does request based and",
    "start": "278759",
    "end": "281160"
  },
  {
    "text": "concurrency based rate limiting and it",
    "start": "281160",
    "end": "283360"
  },
  {
    "text": "exposes metrics for consumption to both",
    "start": "283360",
    "end": "286080"
  },
  {
    "text": "datab bricks Engineers internally and",
    "start": "286080",
    "end": "288199"
  },
  {
    "text": "our customers externally helping us",
    "start": "288199",
    "end": "290120"
  },
  {
    "text": "power their",
    "start": "290120",
    "end": "291199"
  },
  {
    "text": "dashboards which means we really need to",
    "start": "291199",
    "end": "293240"
  },
  {
    "text": "be careful with this Ingress stack next",
    "start": "293240",
    "end": "296360"
  },
  {
    "text": "SL so now upda this once again updating",
    "start": "296360",
    "end": "300400"
  },
  {
    "text": "synr stack is is tricky right because U",
    "start": "300400",
    "end": "303800"
  },
  {
    "text": "our customers use gen for a myriad of",
    "start": "303800",
    "end": "307120"
  },
  {
    "text": "applications across multiple verticals",
    "start": "307120",
    "end": "309400"
  },
  {
    "text": "this could be Healthcare banking",
    "start": "309400",
    "end": "311280"
  },
  {
    "text": "manufacturing my favorite use case is",
    "start": "311280",
    "end": "313919"
  },
  {
    "text": "Gog Guardian using gen serving to",
    "start": "313919",
    "end": "316000"
  },
  {
    "text": "monitor the internet internet usage of",
    "start": "316000",
    "end": "318440"
  },
  {
    "text": "school children to try and prevent self",
    "start": "318440",
    "end": "320880"
  },
  {
    "text": "harm",
    "start": "320880",
    "end": "321639"
  },
  {
    "text": "Tendencies given these Mission critical",
    "start": "321639",
    "end": "324639"
  },
  {
    "text": "uh use cases it's imperative that",
    "start": "324639",
    "end": "327199"
  },
  {
    "text": "whenever we update the Ingress stack we",
    "start": "327199",
    "end": "329800"
  },
  {
    "text": "have zero downtime we cannot have any",
    "start": "329800",
    "end": "332639"
  },
  {
    "text": "4xx or 5xx errors during an update we",
    "start": "332639",
    "end": "336560"
  },
  {
    "text": "cannot have any regression on latency of",
    "start": "336560",
    "end": "338960"
  },
  {
    "text": "performance a lot of these applications",
    "start": "338960",
    "end": "340759"
  },
  {
    "text": "are very latency sensitive and finally",
    "start": "340759",
    "end": "343840"
  },
  {
    "text": "uh if there is ever an issue that",
    "start": "343840",
    "end": "345400"
  },
  {
    "text": "happens during a roll out it should roll",
    "start": "345400",
    "end": "347440"
  },
  {
    "text": "back automatically to restore the last",
    "start": "347440",
    "end": "349680"
  },
  {
    "text": "known lkg",
    "start": "349680",
    "end": "351280"
  },
  {
    "text": "status wow updating the stack is kind of",
    "start": "351280",
    "end": "354080"
  },
  {
    "text": "scary so you could say hey let's not",
    "start": "354080",
    "end": "357360"
  },
  {
    "text": "update the stack let's deploy it once",
    "start": "357360",
    "end": "359280"
  },
  {
    "text": "make a real really awesome Ingress stack",
    "start": "359280",
    "end": "360960"
  },
  {
    "text": "and call it",
    "start": "360960",
    "end": "362000"
  },
  {
    "text": "today unfortunately that is really not",
    "start": "362000",
    "end": "364560"
  },
  {
    "text": "good deployment practice with security",
    "start": "364560",
    "end": "367080"
  },
  {
    "text": "patches coming in regularly and just",
    "start": "367080",
    "end": "369160"
  },
  {
    "text": "improvements that we can constantly make",
    "start": "369160",
    "end": "370720"
  },
  {
    "text": "in our Ingress system we have to",
    "start": "370720",
    "end": "372599"
  },
  {
    "text": "constantly update the stack on a pretty",
    "start": "372599",
    "end": "374759"
  },
  {
    "text": "regular Cadence so if we're updating our",
    "start": "374759",
    "end": "377360"
  },
  {
    "text": "stack let's look at what makes a release",
    "start": "377360",
    "end": "379960"
  },
  {
    "text": "safe there are two primary factors that",
    "start": "379960",
    "end": "382880"
  },
  {
    "text": "you can talk about when you look at the",
    "start": "382880",
    "end": "385280"
  },
  {
    "text": "impact of an outage caused by a bad",
    "start": "385280",
    "end": "388120"
  },
  {
    "text": "release the first first is the number of",
    "start": "388120",
    "end": "390880"
  },
  {
    "text": "impacted customers and the second is the",
    "start": "390880",
    "end": "394039"
  },
  {
    "text": "duration of that",
    "start": "394039",
    "end": "395639"
  },
  {
    "text": "outage therefore both these factors kind",
    "start": "395639",
    "end": "398479"
  },
  {
    "text": "of give you the two important principles",
    "start": "398479",
    "end": "400800"
  },
  {
    "text": "to reduce the impact of an outage the",
    "start": "400800",
    "end": "403800"
  },
  {
    "text": "first principle is reducing the blast",
    "start": "403800",
    "end": "406120"
  },
  {
    "text": "radius so you can catch breakages before",
    "start": "406120",
    "end": "408919"
  },
  {
    "text": "they affect a large number of customers",
    "start": "408919",
    "end": "411240"
  },
  {
    "text": "and the second is reduce the roll back",
    "start": "411240",
    "end": "413160"
  },
  {
    "text": "time reduce a roll back as soon as you",
    "start": "413160",
    "end": "415800"
  },
  {
    "text": "find an issue so that you can reduce the",
    "start": "415800",
    "end": "417720"
  },
  {
    "text": "impact of your outage",
    "start": "417720",
    "end": "420440"
  },
  {
    "text": "cool so let's look at what kubernetes",
    "start": "420440",
    "end": "422879"
  },
  {
    "text": "today does as a standard deployment so",
    "start": "422879",
    "end": "426160"
  },
  {
    "text": "you have a deployment and you create a",
    "start": "426160",
    "end": "428039"
  },
  {
    "text": "new version of your service what the",
    "start": "428039",
    "end": "430120"
  },
  {
    "text": "deployment does is it manages two",
    "start": "430120",
    "end": "432479"
  },
  {
    "text": "replica sets it manages the old stable",
    "start": "432479",
    "end": "435120"
  },
  {
    "text": "replica set that's uh running your",
    "start": "435120",
    "end": "437560"
  },
  {
    "text": "current stable version of your service",
    "start": "437560",
    "end": "439800"
  },
  {
    "text": "and the second is the new Canary replica",
    "start": "439800",
    "end": "441759"
  },
  {
    "text": "Set uh where it's going to deploy your",
    "start": "441759",
    "end": "443639"
  },
  {
    "text": "new service and what the deployment",
    "start": "443639",
    "end": "446000"
  },
  {
    "text": "rolling update does is that it moves",
    "start": "446000",
    "end": "448240"
  },
  {
    "text": "from the older replica set to the new",
    "start": "448240",
    "end": "449879"
  },
  {
    "text": "replica set as soon as possible you'll",
    "start": "449879",
    "end": "452120"
  },
  {
    "text": "try and create your replica Set uh pods",
    "start": "452120",
    "end": "454800"
  },
  {
    "text": "and terminate the older",
    "start": "454800",
    "end": "456759"
  },
  {
    "text": "pods but that kind of violates the first",
    "start": "456759",
    "end": "459840"
  },
  {
    "text": "principle of a safe roll outout hey if",
    "start": "459840",
    "end": "462319"
  },
  {
    "text": "something goes wrong it it completely",
    "start": "462319",
    "end": "464280"
  },
  {
    "text": "takes down our service and impacts our",
    "start": "464280",
    "end": "466759"
  },
  {
    "text": "customers immediately let's say there's",
    "start": "466759",
    "end": "468680"
  },
  {
    "text": "a o that hits us a new service after 5",
    "start": "468680",
    "end": "470960"
  },
  {
    "text": "minutes um after the roll is complete it",
    "start": "470960",
    "end": "474520"
  },
  {
    "text": "affects every single customer using that",
    "start": "474520",
    "end": "476800"
  },
  {
    "text": "service the second is J this update",
    "start": "476800",
    "end": "480280"
  },
  {
    "text": "process you can you know collect metrics",
    "start": "480280",
    "end": "481960"
  },
  {
    "text": "so we use Prometheus internally and we",
    "start": "481960",
    "end": "484120"
  },
  {
    "text": "have a lot of alerts that has been set",
    "start": "484120",
    "end": "485599"
  },
  {
    "text": "up on these metrics so let's say there's",
    "start": "485599",
    "end": "487879"
  },
  {
    "text": "some alert that fires during this Sol",
    "start": "487879",
    "end": "489400"
  },
  {
    "text": "out process it generally Pages an on",
    "start": "489400",
    "end": "491759"
  },
  {
    "text": "call everything's on fire and then the",
    "start": "491759",
    "end": "494120"
  },
  {
    "text": "on call looks at you know your standard",
    "start": "494120",
    "end": "495560"
  },
  {
    "text": "operating procedures the on call looks",
    "start": "495560",
    "end": "497840"
  },
  {
    "text": "at dashboards tries to figure out what's",
    "start": "497840",
    "end": "499759"
  },
  {
    "text": "going wrong and then when they realize",
    "start": "499759",
    "end": "501879"
  },
  {
    "text": "that hey there is some issue with the",
    "start": "501879",
    "end": "503400"
  },
  {
    "text": "roll out they'll trigger a roll back",
    "start": "503400",
    "end": "506440"
  },
  {
    "text": "this is where our second principle gets",
    "start": "506440",
    "end": "508120"
  },
  {
    "text": "affected which is look at the end to end",
    "start": "508120",
    "end": "511080"
  },
  {
    "text": "time between when the on call was first",
    "start": "511080",
    "end": "513200"
  },
  {
    "text": "alerted and when they are rolling back",
    "start": "513200",
    "end": "516440"
  },
  {
    "text": "uh the deployment this is non-negligible",
    "start": "516440",
    "end": "519479"
  },
  {
    "text": "and the longer this is the larger the",
    "start": "519479",
    "end": "521599"
  },
  {
    "text": "impact of the outage so what do we do so",
    "start": "521599",
    "end": "525240"
  },
  {
    "text": "we decided to start using Argo rollouts",
    "start": "525240",
    "end": "527440"
  },
  {
    "text": "to update our ml indress stack an Argo",
    "start": "527440",
    "end": "530800"
  },
  {
    "text": "rollout is nothing but a drop in",
    "start": "530800",
    "end": "532680"
  },
  {
    "text": "replacement for a deployment with a",
    "start": "532680",
    "end": "534760"
  },
  {
    "text": "couple of really interesting fine grain",
    "start": "534760",
    "end": "537000"
  },
  {
    "text": "controls that we're going to talk about",
    "start": "537000",
    "end": "538560"
  },
  {
    "text": "really quickly",
    "start": "538560",
    "end": "540000"
  },
  {
    "text": "you'll notice that the roll out has",
    "start": "540000",
    "end": "542959"
  },
  {
    "text": "changes the strategy file and gives you",
    "start": "542959",
    "end": "545240"
  },
  {
    "text": "analysis and steps let's take a look at",
    "start": "545240",
    "end": "548200"
  },
  {
    "text": "steps first so now rather than a 0o to",
    "start": "548200",
    "end": "551760"
  },
  {
    "text": "one roll out you break your roll out up",
    "start": "551760",
    "end": "554000"
  },
  {
    "text": "into steps so we're changing how fast we",
    "start": "554000",
    "end": "557560"
  },
  {
    "text": "roll out how fast we can roll out at a",
    "start": "557560",
    "end": "560120"
  },
  {
    "text": "particular time so in our example we",
    "start": "560120",
    "end": "562600"
  },
  {
    "text": "first uh update 20% of our pods wait 10",
    "start": "562600",
    "end": "565720"
  },
  {
    "text": "minutes then the next 40% more wait some",
    "start": "565720",
    "end": "569079"
  },
  {
    "text": "more time and so on and so forth during",
    "start": "569079",
    "end": "571760"
  },
  {
    "text": "this entire process there are constant",
    "start": "571760",
    "end": "574279"
  },
  {
    "text": "background uh health checks that are",
    "start": "574279",
    "end": "576120"
  },
  {
    "text": "running via the analysis template and",
    "start": "576120",
    "end": "577839"
  },
  {
    "text": "I'll come to that in a second so our",
    "start": "577839",
    "end": "580000"
  },
  {
    "text": "first principle is met because now our",
    "start": "580000",
    "end": "582320"
  },
  {
    "text": "first principle says that hey we're",
    "start": "582320",
    "end": "584040"
  },
  {
    "text": "going to try and reduce the impact uh by",
    "start": "584040",
    "end": "587079"
  },
  {
    "text": "reducing the blast radius by breaking up",
    "start": "587079",
    "end": "589560"
  },
  {
    "text": "our deployment into smaller more fine",
    "start": "589560",
    "end": "591560"
  },
  {
    "text": "fine grain",
    "start": "591560",
    "end": "593320"
  },
  {
    "text": "steps um and at the end of your roll out",
    "start": "593320",
    "end": "596800"
  },
  {
    "text": "it all remains it's like a deployment",
    "start": "596800",
    "end": "598079"
  },
  {
    "text": "happened it's it's it's the same out of",
    "start": "598079",
    "end": "599200"
  },
  {
    "text": "the box uh so with this fundamental",
    "start": "599200",
    "end": "602720"
  },
  {
    "text": "Foundation let's look at what changes",
    "start": "602720",
    "end": "604920"
  },
  {
    "text": "now in how we roll out the ml serving",
    "start": "604920",
    "end": "607120"
  },
  {
    "text": "stack so instead of a deployment it's a",
    "start": "607120",
    "end": "609720"
  },
  {
    "text": "roll out now with an Argo rollouts",
    "start": "609720",
    "end": "612160"
  },
  {
    "text": "controller which is a microservice",
    "start": "612160",
    "end": "613320"
  },
  {
    "text": "that's controlling this roll out that's",
    "start": "613320",
    "end": "615160"
  },
  {
    "text": "now constantly quiring Prometheus to",
    "start": "615160",
    "end": "617560"
  },
  {
    "text": "look at the health checks that we care",
    "start": "617560",
    "end": "619320"
  },
  {
    "text": "about instead of a 0 to1 deployment from",
    "start": "619320",
    "end": "621920"
  },
  {
    "text": "the old replica set to the new Canary",
    "start": "621920",
    "end": "624160"
  },
  {
    "text": "Set uh it first you know takes those 20%",
    "start": "624160",
    "end": "627000"
  },
  {
    "text": "of your pods runs the background health",
    "start": "627000",
    "end": "628959"
  },
  {
    "text": "checks and if everything is green and",
    "start": "628959",
    "end": "630880"
  },
  {
    "text": "the roll out is healthy until now it uh",
    "start": "630880",
    "end": "633760"
  },
  {
    "text": "tells the it continues the roll",
    "start": "633760",
    "end": "636240"
  },
  {
    "text": "out uh now what happens if something is",
    "start": "636240",
    "end": "638600"
  },
  {
    "text": "bad some health check fails based on the",
    "start": "638600",
    "end": "641079"
  },
  {
    "text": "analysis template and Argo is",
    "start": "641079",
    "end": "643040"
  },
  {
    "text": "immediately able to tell the roll out",
    "start": "643040",
    "end": "644360"
  },
  {
    "text": "that Hey listen this is not a healthy",
    "start": "644360",
    "end": "646160"
  },
  {
    "text": "update let's roll back soon so we've met",
    "start": "646160",
    "end": "649320"
  },
  {
    "text": "both the principles we really care about",
    "start": "649320",
    "end": "651720"
  },
  {
    "text": "uh a more staged roll out uh to reduce",
    "start": "651720",
    "end": "654279"
  },
  {
    "text": "the blast radius and if there is",
    "start": "654279",
    "end": "656200"
  },
  {
    "text": "something that goes wrong the human in",
    "start": "656200",
    "end": "658079"
  },
  {
    "text": "the loop is removed and the AR",
    "start": "658079",
    "end": "659920"
  },
  {
    "text": "controller can immediately roll it back",
    "start": "659920",
    "end": "662440"
  },
  {
    "text": "reducing the duration of the outage",
    "start": "662440",
    "end": "664440"
  },
  {
    "text": "thereby reducing the impact of that",
    "start": "664440",
    "end": "667399"
  },
  {
    "text": "outage an analysis is basically the",
    "start": "667399",
    "end": "670279"
  },
  {
    "text": "background metrics uh that are",
    "start": "670279",
    "end": "672399"
  },
  {
    "text": "constantly being verified to check that",
    "start": "672399",
    "end": "674560"
  },
  {
    "text": "if some Metric is you know going hayre",
    "start": "674560",
    "end": "676839"
  },
  {
    "text": "resulting in a unhealthy update uh this",
    "start": "676839",
    "end": "679399"
  },
  {
    "text": "is an example that we actually use",
    "start": "679399",
    "end": "680720"
  },
  {
    "text": "during our analysis uh and it's one of",
    "start": "680720",
    "end": "683040"
  },
  {
    "text": "many you can like choose a list of uh",
    "start": "683040",
    "end": "685120"
  },
  {
    "text": "metrics that you care about so in our",
    "start": "685120",
    "end": "687320"
  },
  {
    "text": "case we have a a prober called the heat",
    "start": "687320",
    "end": "689680"
  },
  {
    "text": "seeker that's constantly checking if a",
    "start": "689680",
    "end": "692360"
  },
  {
    "text": "uh that the Ingress tack is up and",
    "start": "692360",
    "end": "693720"
  },
  {
    "text": "running and if we see any 5xx during",
    "start": "693720",
    "end": "696200"
  },
  {
    "text": "this roll out uh over a period of you",
    "start": "696200",
    "end": "698160"
  },
  {
    "text": "know 10 10 seconds um and it happens",
    "start": "698160",
    "end": "700480"
  },
  {
    "text": "twice so the failure limit is twice we",
    "start": "700480",
    "end": "702720"
  },
  {
    "text": "trigger a roll back and that's how we're",
    "start": "702720",
    "end": "705000"
  },
  {
    "text": "trying to keep our Ingress STX safe and",
    "start": "705000",
    "end": "707320"
  },
  {
    "text": "supporting all these really good use",
    "start": "707320",
    "end": "708680"
  },
  {
    "text": "cases of our",
    "start": "708680",
    "end": "710079"
  },
  {
    "text": "customers uh we don't just add metrics",
    "start": "710079",
    "end": "713440"
  },
  {
    "text": "out of the box we first test it so that",
    "start": "713440",
    "end": "715920"
  },
  {
    "text": "we know that we are sure that these",
    "start": "715920",
    "end": "717720"
  },
  {
    "text": "metrics are going to survive and not",
    "start": "717720",
    "end": "719880"
  },
  {
    "text": "give any false positives and I'll I'll",
    "start": "719880",
    "end": "722079"
  },
  {
    "text": "read the mic to Rohit to talk about this",
    "start": "722079",
    "end": "723760"
  },
  {
    "text": "part thank you Arjun so in this second",
    "start": "723760",
    "end": "726760"
  },
  {
    "text": "half of the talk I'd mainly focus on",
    "start": "726760",
    "end": "728600"
  },
  {
    "text": "workflows and how we use Argo workflows",
    "start": "728600",
    "end": "731040"
  },
  {
    "text": "to uh to a lot of use cases here a data",
    "start": "731040",
    "end": "733440"
  },
  {
    "text": "brecks but then I'll take a minute to uh",
    "start": "733440",
    "end": "735680"
  },
  {
    "text": "highlight this feature that urjent just",
    "start": "735680",
    "end": "737199"
  },
  {
    "text": "mentioned so we added capability for dry",
    "start": "737199",
    "end": "739839"
  },
  {
    "text": "runs in Argo rollouts and I think it",
    "start": "739839",
    "end": "741440"
  },
  {
    "text": "went out in version 1",
    "start": "741440",
    "end": "743399"
  },
  {
    "text": "1.2 uh so what happens what happens when",
    "start": "743399",
    "end": "747560"
  },
  {
    "text": "a developer is trying to add a new check",
    "start": "747560",
    "end": "750839"
  },
  {
    "text": "if they add that uh if they add this",
    "start": "750839",
    "end": "752880"
  },
  {
    "text": "check in the veteran and if anything",
    "start": "752880",
    "end": "754519"
  },
  {
    "text": "goes wrong we just initiate a false",
    "start": "754519",
    "end": "756360"
  },
  {
    "text": "positive roll back so prevent this",
    "start": "756360",
    "end": "758760"
  },
  {
    "text": "scenario we have this feature called dry",
    "start": "758760",
    "end": "760600"
  },
  {
    "text": "run so whenever a developer is trying to",
    "start": "760600",
    "end": "762639"
  },
  {
    "text": "add a new check they can simply just",
    "start": "762639",
    "end": "764440"
  },
  {
    "text": "mark it as dry run in dry runs you can",
    "start": "764440",
    "end": "767639"
  },
  {
    "text": "you can have as part of analysis",
    "start": "767639",
    "end": "769760"
  },
  {
    "text": "template you can also have it part of",
    "start": "769760",
    "end": "771320"
  },
  {
    "text": "the rollouts and experiments if a dryon",
    "start": "771320",
    "end": "773800"
  },
  {
    "text": "check fails we don't initiate a roll",
    "start": "773800",
    "end": "775560"
  },
  {
    "text": "back we simply give you a results at the",
    "start": "775560",
    "end": "778040"
  },
  {
    "text": "End of the Roll out that you can use to",
    "start": "778040",
    "end": "779720"
  },
  {
    "text": "analyze and then based on that you can",
    "start": "779720",
    "end": "781600"
  },
  {
    "text": "tweak your checks and then make",
    "start": "781600",
    "end": "783040"
  },
  {
    "text": "refinements when you're happy with the",
    "start": "783040",
    "end": "784680"
  },
  {
    "text": "check over n successful runs you can",
    "start": "784680",
    "end": "787000"
  },
  {
    "text": "then graduate these checks to Veterans",
    "start": "787000",
    "end": "789440"
  },
  {
    "text": "and then they start impacting the uh",
    "start": "789440",
    "end": "791199"
  },
  {
    "text": "state of the rollouts so just just to",
    "start": "791199",
    "end": "793839"
  },
  {
    "text": "see an example here is the uh analysis",
    "start": "793839",
    "end": "796320"
  },
  {
    "text": "template that we shared before this is",
    "start": "796320",
    "end": "798040"
  },
  {
    "text": "the analysis template that we use to",
    "start": "798040",
    "end": "799440"
  },
  {
    "text": "update our Ingress stack here we have",
    "start": "799440",
    "end": "801360"
  },
  {
    "text": "two metrics one is the 5xx errors which",
    "start": "801360",
    "end": "804320"
  },
  {
    "text": "is marked in the dry run mode and then",
    "start": "804320",
    "end": "806440"
  },
  {
    "text": "another one is 4xx errors so in this",
    "start": "806440",
    "end": "808680"
  },
  {
    "text": "case if if you hit the failure condition",
    "start": "808680",
    "end": "810480"
  },
  {
    "text": "which is like you are getting 10 5xx",
    "start": "810480",
    "end": "812440"
  },
  {
    "text": "errors in the last 5 minute interval",
    "start": "812440",
    "end": "814839"
  },
  {
    "text": "this dryon check would fail but then it",
    "start": "814839",
    "end": "816800"
  },
  {
    "text": "won't impact the final status of your",
    "start": "816800",
    "end": "818639"
  },
  {
    "text": "roll out but on the other hand if you",
    "start": "818639",
    "end": "820760"
  },
  {
    "text": "fail the second check which is a veteran",
    "start": "820760",
    "end": "822920"
  },
  {
    "text": "check uh which is getting 10 errors in",
    "start": "822920",
    "end": "826720"
  },
  {
    "text": "in 5 minute window 4xx errors it would",
    "start": "826720",
    "end": "829199"
  },
  {
    "text": "actually initiate a roll back just to",
    "start": "829199",
    "end": "832120"
  },
  {
    "text": "speak quickly how dryon mode actually",
    "start": "832120",
    "end": "834399"
  },
  {
    "text": "works our analysis template can consist",
    "start": "834399",
    "end": "836800"
  },
  {
    "text": "of both the veteran checks as well as",
    "start": "836800",
    "end": "838519"
  },
  {
    "text": "the dryon check checks it's a good",
    "start": "838519",
    "end": "840360"
  },
  {
    "text": "practice for any developer who is trying",
    "start": "840360",
    "end": "842240"
  },
  {
    "text": "to introduce new checks to start with a",
    "start": "842240",
    "end": "843959"
  },
  {
    "text": "dry run they can collect the metrics",
    "start": "843959",
    "end": "846199"
  },
  {
    "text": "Over N successful runs and then when",
    "start": "846199",
    "end": "848920"
  },
  {
    "text": "they're confident about the maturity of",
    "start": "848920",
    "end": "850720"
  },
  {
    "text": "the new new checks they can then",
    "start": "850720",
    "end": "852240"
  },
  {
    "text": "graduate it to Veterans for instance in",
    "start": "852240",
    "end": "854600"
  },
  {
    "text": "this example we can see there are seven",
    "start": "854600",
    "end": "856680"
  },
  {
    "text": "veteran checks and there are five uh",
    "start": "856680",
    "end": "858560"
  },
  {
    "text": "dryon checks while some of the dryon",
    "start": "858560",
    "end": "860680"
  },
  {
    "text": "check failed since all the veteran",
    "start": "860680",
    "end": "862680"
  },
  {
    "text": "checks are successful we don't impact",
    "start": "862680",
    "end": "864639"
  },
  {
    "text": "the the final state of the roll out is",
    "start": "864639",
    "end": "866240"
  },
  {
    "text": "still",
    "start": "866240",
    "end": "868040"
  },
  {
    "text": "green now let's see a hypothetical",
    "start": "868040",
    "end": "870199"
  },
  {
    "text": "Journey for a developer who is trying to",
    "start": "870199",
    "end": "872360"
  },
  {
    "text": "introduce new checks they are trying to",
    "start": "872360",
    "end": "874480"
  },
  {
    "text": "add two new checks here one is to",
    "start": "874480",
    "end": "876279"
  },
  {
    "text": "measure the increase in any 408 errors",
    "start": "876279",
    "end": "879279"
  },
  {
    "text": "from Envoy and then second is to to in",
    "start": "879279",
    "end": "882720"
  },
  {
    "text": "to second is to look at the increase in",
    "start": "882720",
    "end": "884480"
  },
  {
    "text": "number of the connection timeouts coming",
    "start": "884480",
    "end": "886199"
  },
  {
    "text": "from the envoy they still don't know the",
    "start": "886199",
    "end": "888279"
  },
  {
    "text": "correct red lines so in this case they",
    "start": "888279",
    "end": "891000"
  },
  {
    "text": "add these two new checks as the dryon",
    "start": "891000",
    "end": "892920"
  },
  {
    "text": "checks and they collect this data over",
    "start": "892920",
    "end": "894759"
  },
  {
    "text": "next end runs if there are no false",
    "start": "894759",
    "end": "897040"
  },
  {
    "text": "positives they just simply go and",
    "start": "897040",
    "end": "898440"
  },
  {
    "text": "graduate these these checks to Veterans",
    "start": "898440",
    "end": "899920"
  },
  {
    "text": "and then they start impacting the final",
    "start": "899920",
    "end": "901759"
  },
  {
    "text": "state of the roll out but there if there",
    "start": "901759",
    "end": "903519"
  },
  {
    "text": "are false positives the developer would",
    "start": "903519",
    "end": "905079"
  },
  {
    "text": "continue to refine these metrics Define",
    "start": "905079",
    "end": "907600"
  },
  {
    "text": "the correct rad lines and then uh until",
    "start": "907600",
    "end": "910600"
  },
  {
    "text": "all the false positives get eliminated",
    "start": "910600",
    "end": "912480"
  },
  {
    "text": "they will still keep running it as drun",
    "start": "912480",
    "end": "914920"
  },
  {
    "text": "okay so I think that's about safe",
    "start": "914920",
    "end": "916519"
  },
  {
    "text": "rollouts and dry runs next we want to",
    "start": "916519",
    "end": "918880"
  },
  {
    "text": "talk about workflows uh we use Argo",
    "start": "918880",
    "end": "921759"
  },
  {
    "text": "workflows for various use cases here at",
    "start": "921759",
    "end": "923519"
  },
  {
    "text": "data bricks with different set of goals",
    "start": "923519",
    "end": "925560"
  },
  {
    "text": "and challenges and I want to share some",
    "start": "925560",
    "end": "927519"
  },
  {
    "text": "of the interesting workflows that we",
    "start": "927519",
    "end": "928759"
  },
  {
    "text": "have for model serving so we'll explore",
    "start": "928759",
    "end": "930800"
  },
  {
    "text": "some of these in detail today to get a",
    "start": "930800",
    "end": "932240"
  },
  {
    "text": "comprehensive understanding uh I want to",
    "start": "932240",
    "end": "935000"
  },
  {
    "text": "start with capacity planning so urgun",
    "start": "935000",
    "end": "937399"
  },
  {
    "text": "earlier talked about model backends and",
    "start": "937399",
    "end": "939639"
  },
  {
    "text": "how model serving request based Auto",
    "start": "939639",
    "end": "941639"
  },
  {
    "text": "scaling works this autoscaling requires",
    "start": "941639",
    "end": "944959"
  },
  {
    "text": "setting up the compute that we run model",
    "start": "944959",
    "end": "947079"
  },
  {
    "text": "serving uh model serving models on and",
    "start": "947079",
    "end": "949440"
  },
  {
    "text": "bootstrapping these machines with our",
    "start": "949440",
    "end": "951519"
  },
  {
    "text": "observability stack uh heal Checkers",
    "start": "951519",
    "end": "954360"
  },
  {
    "text": "networking demon sets and this all is",
    "start": "954360",
    "end": "956360"
  },
  {
    "text": "very timec consuming so in order to",
    "start": "956360",
    "end": "958600"
  },
  {
    "text": "speed things up we maintain a small warm",
    "start": "958600",
    "end": "960839"
  },
  {
    "text": "pool we have two main goals here one is",
    "start": "960839",
    "end": "963639"
  },
  {
    "text": "the availability which means we want",
    "start": "963639",
    "end": "965759"
  },
  {
    "text": "enough machines in the warm pool so that",
    "start": "965759",
    "end": "967759"
  },
  {
    "text": "we can handle the incoming workload and",
    "start": "967759",
    "end": "970040"
  },
  {
    "text": "then second thing is efficiency compute",
    "start": "970040",
    "end": "971920"
  },
  {
    "text": "cost a lot of dollars so we don't want",
    "start": "971920",
    "end": "973759"
  },
  {
    "text": "idle machines to be sitting in war pool",
    "start": "973759",
    "end": "976360"
  },
  {
    "text": "now we have an Argo workflow which",
    "start": "976360",
    "end": "978199"
  },
  {
    "text": "periodically scraped the usage metrics",
    "start": "978199",
    "end": "980199"
  },
  {
    "text": "from our Ingress onway proxy containers",
    "start": "980199",
    "end": "982759"
  },
  {
    "text": "we aggregate these metrics and then we",
    "start": "982759",
    "end": "984720"
  },
  {
    "text": "send it to a machine learning model we",
    "start": "984720",
    "end": "987040"
  },
  {
    "text": "use the output from this proprietary",
    "start": "987040",
    "end": "988519"
  },
  {
    "text": "machine learning learning model to",
    "start": "988519",
    "end": "989680"
  },
  {
    "text": "decide the fleet capacity and this",
    "start": "989680",
    "end": "991519"
  },
  {
    "text": "happens in all the all the regions so",
    "start": "991519",
    "end": "993440"
  },
  {
    "text": "basically we have like 70 different",
    "start": "993440",
    "end": "994800"
  },
  {
    "text": "regions across all three Cloud providers",
    "start": "994800",
    "end": "996880"
  },
  {
    "text": "so this is happening in every region and",
    "start": "996880",
    "end": "998920"
  },
  {
    "text": "then finally we upscale and downscale",
    "start": "998920",
    "end": "1000880"
  },
  {
    "text": "the wool Fleet size based on what",
    "start": "1000880",
    "end": "1002720"
  },
  {
    "text": "machine learning model tells us there",
    "start": "1002720",
    "end": "1004639"
  },
  {
    "text": "are some clear winds here um it's really",
    "start": "1004639",
    "end": "1007319"
  },
  {
    "text": "really easy to set up the whole pipeline",
    "start": "1007319",
    "end": "1009319"
  },
  {
    "text": "as I mentioned before there are 70",
    "start": "1009319",
    "end": "1011000"
  },
  {
    "text": "regions if we make any change we can",
    "start": "1011000",
    "end": "1013279"
  },
  {
    "text": "just apply it everywhere we don't have",
    "start": "1013279",
    "end": "1014680"
  },
  {
    "text": "to manually go in each region and do the",
    "start": "1014680",
    "end": "1016639"
  },
  {
    "text": "same thing also we get the observability",
    "start": "1016639",
    "end": "1019680"
  },
  {
    "text": "at every step every workflow step if any",
    "start": "1019680",
    "end": "1021759"
  },
  {
    "text": "step fails we just trigger alerts and",
    "start": "1021759",
    "end": "1023759"
  },
  {
    "text": "then our on call goes and look into it",
    "start": "1023759",
    "end": "1026520"
  },
  {
    "text": "just to see this in practice let's take",
    "start": "1026520",
    "end": "1028600"
  },
  {
    "text": "a look at the workflow in the first step",
    "start": "1028600",
    "end": "1031438"
  },
  {
    "text": "we scrape the metrics from Envoy",
    "start": "1031439",
    "end": "1033000"
  },
  {
    "text": "containers I think it's a very",
    "start": "1033000",
    "end": "1034360"
  },
  {
    "text": "simplified view I'm hiding uh one thing",
    "start": "1034360",
    "end": "1037120"
  },
  {
    "text": "so Prometheus is the one which scraped",
    "start": "1037120",
    "end": "1038798"
  },
  {
    "text": "the metrics because there are like 20",
    "start": "1038799",
    "end": "1040400"
  },
  {
    "text": "containers for onway running and then",
    "start": "1040400",
    "end": "1042120"
  },
  {
    "text": "Argo workflow simply gets the data from",
    "start": "1042120",
    "end": "1044199"
  },
  {
    "text": "Prometheus the next step is to aggregate",
    "start": "1044199",
    "end": "1046720"
  },
  {
    "text": "this data over all the interesting",
    "start": "1046720",
    "end": "1048480"
  },
  {
    "text": "dimensions that we want and then send it",
    "start": "1048480",
    "end": "1050799"
  },
  {
    "text": "to the machine learning model and then",
    "start": "1050799",
    "end": "1052960"
  },
  {
    "text": "finally we use the output coming from",
    "start": "1052960",
    "end": "1054600"
  },
  {
    "text": "the machine learning model to decide the",
    "start": "1054600",
    "end": "1056480"
  },
  {
    "text": "warm pool size if if we think that the",
    "start": "1056480",
    "end": "1059280"
  },
  {
    "text": "pool needs to be resized and we need",
    "start": "1059280",
    "end": "1061039"
  },
  {
    "text": "more capacity we go request machines and",
    "start": "1061039",
    "end": "1063320"
  },
  {
    "text": "then add it to our warm pool and if we",
    "start": "1063320",
    "end": "1065200"
  },
  {
    "text": "want to downsize the pool we just let go",
    "start": "1065200",
    "end": "1067480"
  },
  {
    "text": "of additional capacity there are some",
    "start": "1067480",
    "end": "1069760"
  },
  {
    "text": "very interesting patterns that we saw",
    "start": "1069760",
    "end": "1071200"
  },
  {
    "text": "this whole thing is still in Pilot so we",
    "start": "1071200",
    "end": "1072640"
  },
  {
    "text": "are continuously refining the model but",
    "start": "1072640",
    "end": "1074480"
  },
  {
    "text": "then we see like there is a huge",
    "start": "1074480",
    "end": "1075679"
  },
  {
    "text": "capacity demand in the middle of the",
    "start": "1075679",
    "end": "1076960"
  },
  {
    "text": "night and then in the middle of the day",
    "start": "1076960",
    "end": "1078280"
  },
  {
    "text": "we let go off",
    "start": "1078280",
    "end": "1080120"
  },
  {
    "text": "everything next use case I want to talk",
    "start": "1080120",
    "end": "1082360"
  },
  {
    "text": "about is container pills so when a user",
    "start": "1082360",
    "end": "1085240"
  },
  {
    "text": "creates a model and query their machine",
    "start": "1085240",
    "end": "1087960"
  },
  {
    "text": "learning model uh behind the scenes we",
    "start": "1087960",
    "end": "1090840"
  },
  {
    "text": "package everything and deploy it as a",
    "start": "1090840",
    "end": "1092559"
  },
  {
    "text": "service so the entire build process is",
    "start": "1092559",
    "end": "1094919"
  },
  {
    "text": "divided into three steps we uh this is",
    "start": "1094919",
    "end": "1098400"
  },
  {
    "text": "done to aim for better separation",
    "start": "1098400",
    "end": "1100080"
  },
  {
    "text": "between what data braks own and what",
    "start": "1100080",
    "end": "1101720"
  },
  {
    "text": "user own so that we can Surface the",
    "start": "1101720",
    "end": "1103360"
  },
  {
    "text": "errors like if it's a buil error from a",
    "start": "1103360",
    "end": "1105640"
  },
  {
    "text": "user installing a dependency which",
    "start": "1105640",
    "end": "1107480"
  },
  {
    "text": "doesn't exist we just want to tell users",
    "start": "1107480",
    "end": "1109280"
  },
  {
    "text": "that there is some problem with the",
    "start": "1109280",
    "end": "1110520"
  },
  {
    "text": "requirements File versus if there is a",
    "start": "1110520",
    "end": "1112360"
  },
  {
    "text": "data bricks error we are not trying to",
    "start": "1112360",
    "end": "1114720"
  },
  {
    "text": "we we fail to create the docker image or",
    "start": "1114720",
    "end": "1116280"
  },
  {
    "text": "we fail to push the uh Docker image then",
    "start": "1116280",
    "end": "1118360"
  },
  {
    "text": "we need that alert to go to our on call",
    "start": "1118360",
    "end": "1120080"
  },
  {
    "text": "so that they can look into it the two",
    "start": "1120080",
    "end": "1122720"
  },
  {
    "text": "main goals here are we want to build the",
    "start": "1122720",
    "end": "1124840"
  },
  {
    "text": "model serving container we want to",
    "start": "1124840",
    "end": "1126640"
  },
  {
    "text": "execute it and we want to update the UI",
    "start": "1126640",
    "end": "1129320"
  },
  {
    "text": "that user is using to Market as ready uh",
    "start": "1129320",
    "end": "1132960"
  },
  {
    "text": "second important goal is we want to",
    "start": "1132960",
    "end": "1134919"
  },
  {
    "text": "deliver the build doogs that I talked",
    "start": "1134919",
    "end": "1136360"
  },
  {
    "text": "about back to the user so if there is",
    "start": "1136360",
    "end": "1138360"
  },
  {
    "text": "any problem with the model that they",
    "start": "1138360",
    "end": "1140400"
  },
  {
    "text": "trying to deploy they can just go look",
    "start": "1140400",
    "end": "1142000"
  },
  {
    "text": "at those locks to achieve this we again",
    "start": "1142000",
    "end": "1145039"
  },
  {
    "text": "use uh Argo workflow we try to retrieve",
    "start": "1145039",
    "end": "1148039"
  },
  {
    "text": "various artifacts from different sources",
    "start": "1148039",
    "end": "1150480"
  },
  {
    "text": "uh it can be piie S3 buckets GitHub we",
    "start": "1150480",
    "end": "1154039"
  },
  {
    "text": "construct a Docker image from all these",
    "start": "1154039",
    "end": "1156400"
  },
  {
    "text": "artifacts and we push this into our",
    "start": "1156400",
    "end": "1158679"
  },
  {
    "text": "registry in the third step we deploy a",
    "start": "1158679",
    "end": "1160880"
  },
  {
    "text": "kubernetes service leveraging this",
    "start": "1160880",
    "end": "1162559"
  },
  {
    "text": "Docker image that we pushed we update",
    "start": "1162559",
    "end": "1164919"
  },
  {
    "text": "the UI State based on the health check",
    "start": "1164919",
    "end": "1167039"
  },
  {
    "text": "probers so once the service comes up we",
    "start": "1167039",
    "end": "1169080"
  },
  {
    "text": "have some Readiness checks and once",
    "start": "1169080",
    "end": "1170600"
  },
  {
    "text": "those Readiness checks passes we we",
    "start": "1170600",
    "end": "1172559"
  },
  {
    "text": "update the UI state to be ready and then",
    "start": "1172559",
    "end": "1175240"
  },
  {
    "text": "then user can send traffic to the to the",
    "start": "1175240",
    "end": "1177400"
  },
  {
    "text": "API and the in the event of failures we",
    "start": "1177400",
    "end": "1180120"
  },
  {
    "text": "have logs for both data braks as well as",
    "start": "1180120",
    "end": "1182200"
  },
  {
    "text": "for the user if it's a data Brak error",
    "start": "1182200",
    "end": "1183880"
  },
  {
    "text": "then we just go and alert our on calls",
    "start": "1183880",
    "end": "1186799"
  },
  {
    "text": "the benefits are again the entire",
    "start": "1186799",
    "end": "1188840"
  },
  {
    "text": "pipeline is very very easy for us to set",
    "start": "1188840",
    "end": "1190520"
  },
  {
    "text": "up uh we can set up alerts to notify in",
    "start": "1190520",
    "end": "1193440"
  },
  {
    "text": "case of any issues and then we get",
    "start": "1193440",
    "end": "1195400"
  },
  {
    "text": "enhanced observability at every step of",
    "start": "1195400",
    "end": "1197200"
  },
  {
    "text": "this workflow just to see this in",
    "start": "1197200",
    "end": "1199880"
  },
  {
    "text": "practice um as I mentioned there are",
    "start": "1199880",
    "end": "1201919"
  },
  {
    "text": "three steps the first step is a",
    "start": "1201919",
    "end": "1203679"
  },
  {
    "text": "pre-build step in this step we fetch the",
    "start": "1203679",
    "end": "1206120"
  },
  {
    "text": "base image and then we install various",
    "start": "1206120",
    "end": "1208200"
  },
  {
    "text": "dependencies these dependencies come",
    "start": "1208200",
    "end": "1209760"
  },
  {
    "text": "from like Wheels piie S3 buckets so this",
    "start": "1209760",
    "end": "1212840"
  },
  {
    "text": "is the step in which if it fails we uh",
    "start": "1212840",
    "end": "1215559"
  },
  {
    "text": "ship the logs back to the customer or",
    "start": "1215559",
    "end": "1217640"
  },
  {
    "text": "the user and that they are responsible",
    "start": "1217640",
    "end": "1219400"
  },
  {
    "text": "for fixing it the next step is build",
    "start": "1219400",
    "end": "1222120"
  },
  {
    "text": "step in which we package everything up",
    "start": "1222120",
    "end": "1224840"
  },
  {
    "text": "we create a Docker image and uh in this",
    "start": "1224840",
    "end": "1227679"
  },
  {
    "text": "step if there is anything which goes",
    "start": "1227679",
    "end": "1229039"
  },
  {
    "text": "wrong then be alert our on calls the",
    "start": "1229039",
    "end": "1231640"
  },
  {
    "text": "final step is a postbuild step in this",
    "start": "1231640",
    "end": "1233799"
  },
  {
    "text": "step we finally use the docker image",
    "start": "1233799",
    "end": "1235919"
  },
  {
    "text": "that we pushed or build in the last step",
    "start": "1235919",
    "end": "1238280"
  },
  {
    "text": "and use it to spin up machine learning",
    "start": "1238280",
    "end": "1240480"
  },
  {
    "text": "models um this is the step where we also",
    "start": "1240480",
    "end": "1242919"
  },
  {
    "text": "probe so once these services are up and",
    "start": "1242919",
    "end": "1244720"
  },
  {
    "text": "running we go and update the state in",
    "start": "1244720",
    "end": "1246200"
  },
  {
    "text": "the",
    "start": "1246200",
    "end": "1247559"
  },
  {
    "text": "UI so here's a screenshot illustrating",
    "start": "1247559",
    "end": "1250080"
  },
  {
    "text": "the user facing interface um I think",
    "start": "1250080",
    "end": "1251960"
  },
  {
    "text": "it's a little bit hard to see but then",
    "start": "1251960",
    "end": "1253720"
  },
  {
    "text": "the uh state of the endpoint is still",
    "start": "1253720",
    "end": "1256159"
  },
  {
    "text": "creating and then in the highlighted",
    "start": "1256159",
    "end": "1258000"
  },
  {
    "text": "section there is an an error which says",
    "start": "1258000",
    "end": "1259480"
  },
  {
    "text": "that the requirement file that we got",
    "start": "1259480",
    "end": "1261559"
  },
  {
    "text": "has a dependency which cannot be",
    "start": "1261559",
    "end": "1262960"
  },
  {
    "text": "resolved or which cannot be",
    "start": "1262960",
    "end": "1265600"
  },
  {
    "text": "installed the third use case uh that we",
    "start": "1265600",
    "end": "1268039"
  },
  {
    "text": "use Argo workflows for is metrics",
    "start": "1268039",
    "end": "1269799"
  },
  {
    "text": "delivery so one of the key features for",
    "start": "1269799",
    "end": "1271960"
  },
  {
    "text": "model surveying is the emission and",
    "start": "1271960",
    "end": "1273679"
  },
  {
    "text": "delivery of metrics so these metrics",
    "start": "1273679",
    "end": "1276039"
  },
  {
    "text": "include things like QPS latencies CPU",
    "start": "1276039",
    "end": "1279159"
  },
  {
    "text": "usage uh so that people can tweak their",
    "start": "1279159",
    "end": "1281440"
  },
  {
    "text": "models accordingly and customer today",
    "start": "1281440",
    "end": "1284440"
  },
  {
    "text": "have their own dashboards own alerting",
    "start": "1284440",
    "end": "1286520"
  },
  {
    "text": "based on these metrics the primary",
    "start": "1286520",
    "end": "1288919"
  },
  {
    "text": "objective for us is to capture these",
    "start": "1288919",
    "end": "1291159"
  },
  {
    "text": "metrics at a periodic interval and then",
    "start": "1291159",
    "end": "1293279"
  },
  {
    "text": "deliver them back to the control plane",
    "start": "1293279",
    "end": "1294679"
  },
  {
    "text": "because control plane is the one where",
    "start": "1294679",
    "end": "1296360"
  },
  {
    "text": "our UI lives and then uh once we deliver",
    "start": "1296360",
    "end": "1299720"
  },
  {
    "text": "it to the control plane we can show this",
    "start": "1299720",
    "end": "1301679"
  },
  {
    "text": "show these things per model per customer",
    "start": "1301679",
    "end": "1303400"
  },
  {
    "text": "in the UI to achieve this we again have",
    "start": "1303400",
    "end": "1306159"
  },
  {
    "text": "a Argo workflow which periodically",
    "start": "1306159",
    "end": "1308080"
  },
  {
    "text": "scrape the envoy containers we aggregate",
    "start": "1308080",
    "end": "1311039"
  },
  {
    "text": "the per endpoint per customer metrics",
    "start": "1311039",
    "end": "1313320"
  },
  {
    "text": "over all the interesting dimensions and",
    "start": "1313320",
    "end": "1315120"
  },
  {
    "text": "then we store these metrics in a Time",
    "start": "1315120",
    "end": "1317279"
  },
  {
    "text": "series database which is located in our",
    "start": "1317279",
    "end": "1318960"
  },
  {
    "text": "control plane so just to see how it",
    "start": "1318960",
    "end": "1321520"
  },
  {
    "text": "works uh we the model serving compris of",
    "start": "1321520",
    "end": "1324840"
  },
  {
    "text": "two main components there is a data",
    "start": "1324840",
    "end": "1326760"
  },
  {
    "text": "plane where the model serving workloads",
    "start": "1326760",
    "end": "1328440"
  },
  {
    "text": "are actually running here is uh we also",
    "start": "1328440",
    "end": "1331240"
  },
  {
    "text": "have our Ingress stack authentication",
    "start": "1331240",
    "end": "1332960"
  },
  {
    "text": "authorization rate limiting everything",
    "start": "1332960",
    "end": "1334480"
  },
  {
    "text": "is running on the data plane and then we",
    "start": "1334480",
    "end": "1336360"
  },
  {
    "text": "have a control plane which basically",
    "start": "1336360",
    "end": "1338120"
  },
  {
    "text": "enable customer to manage their endpoint",
    "start": "1338120",
    "end": "1339799"
  },
  {
    "text": "so this is where the UI is and then how",
    "start": "1339799",
    "end": "1341720"
  },
  {
    "text": "customer create new models based on the",
    "start": "1341720",
    "end": "1344360"
  },
  {
    "text": "SLA a new workflow run occurs every X",
    "start": "1344360",
    "end": "1347080"
  },
  {
    "text": "minutes um in the the first step it just",
    "start": "1347080",
    "end": "1349440"
  },
  {
    "text": "scraped metrics from Prometheus which",
    "start": "1349440",
    "end": "1351440"
  },
  {
    "text": "Aggregates metrics from all the envoy",
    "start": "1351440",
    "end": "1353600"
  },
  {
    "text": "containers then we finally aggregate",
    "start": "1353600",
    "end": "1355880"
  },
  {
    "text": "these metrics over all the dimensions",
    "start": "1355880",
    "end": "1357400"
  },
  {
    "text": "that we want in the third step we send",
    "start": "1357400",
    "end": "1359919"
  },
  {
    "text": "this data to a metric collector service",
    "start": "1359919",
    "end": "1362000"
  },
  {
    "text": "that we have in the control plane and",
    "start": "1362000",
    "end": "1363799"
  },
  {
    "text": "then we persist it into a a persistent",
    "start": "1363799",
    "end": "1365559"
  },
  {
    "text": "storage our UI just hit this persistent",
    "start": "1365559",
    "end": "1367799"
  },
  {
    "text": "storage and then show these metrics",
    "start": "1367799",
    "end": "1369360"
  },
  {
    "text": "based on per endpoint and per",
    "start": "1369360",
    "end": "1371320"
  },
  {
    "text": "customer here is a screenshot uh you can",
    "start": "1371320",
    "end": "1374120"
  },
  {
    "text": "see for per endpoint metrics at the top",
    "start": "1374120",
    "end": "1376400"
  },
  {
    "text": "you can see we have metrics we have",
    "start": "1376400",
    "end": "1378159"
  },
  {
    "text": "event and logs which we also pipe using",
    "start": "1378159",
    "end": "1380200"
  },
  {
    "text": "the same same mechanism there are some",
    "start": "1380200",
    "end": "1382360"
  },
  {
    "text": "graphs about latency QPS and then we",
    "start": "1382360",
    "end": "1385400"
  },
  {
    "text": "show things like uh CPU usage and memory",
    "start": "1385400",
    "end": "1388279"
  },
  {
    "text": "usage so there are ton of metrics that",
    "start": "1388279",
    "end": "1389520"
  },
  {
    "text": "you can you can you can describe the",
    "start": "1389520",
    "end": "1391080"
  },
  {
    "text": "alerts",
    "start": "1391080",
    "end": "1392480"
  },
  {
    "text": "on uh these were just a few examples I",
    "start": "1392480",
    "end": "1395039"
  },
  {
    "text": "think we use many many more workflows we",
    "start": "1395039",
    "end": "1396880"
  },
  {
    "text": "have workflows for autoscaling real-time",
    "start": "1396880",
    "end": "1399480"
  },
  {
    "text": "config delivery for our services and so",
    "start": "1399480",
    "end": "1401360"
  },
  {
    "text": "on but I think in interest of time I'd",
    "start": "1401360",
    "end": "1403080"
  },
  {
    "text": "skip those today so that concludes our",
    "start": "1403080",
    "end": "1405919"
  },
  {
    "text": "prepared material for today I think we",
    "start": "1405919",
    "end": "1407640"
  },
  {
    "text": "do still have some time so we'll uh take",
    "start": "1407640",
    "end": "1409919"
  },
  {
    "text": "any questions if you may have thank",
    "start": "1409919",
    "end": "1412950"
  },
  {
    "text": "[Applause]",
    "start": "1412950",
    "end": "1420748"
  },
  {
    "text": "you uh no questions I have one I uh",
    "start": "1425760",
    "end": "1430640"
  },
  {
    "text": "great presentation I have a question on",
    "start": "1430640",
    "end": "1433400"
  },
  {
    "text": "transitioning to Argo rollouts",
    "start": "1433400",
    "end": "1437279"
  },
  {
    "text": "um uh uh thing about how did you",
    "start": "1437279",
    "end": "1442120"
  },
  {
    "text": "actually get your developers to",
    "start": "1442120",
    "end": "1443960"
  },
  {
    "text": "transition to it because there's a few",
    "start": "1443960",
    "end": "1445799"
  },
  {
    "text": "topics in in Argo rollouts where they",
    "start": "1445799",
    "end": "1448679"
  },
  {
    "text": "have to because this is like I guess",
    "start": "1448679",
    "end": "1451520"
  },
  {
    "text": "devops or Sr or platform engineering",
    "start": "1451520",
    "end": "1453880"
  },
  {
    "text": "driven and the developers have to learn",
    "start": "1453880",
    "end": "1456320"
  },
  {
    "text": "how the argor roll outs work and how to",
    "start": "1456320",
    "end": "1458600"
  },
  {
    "text": "write uh Prometheus queries to actually",
    "start": "1458600",
    "end": "1462000"
  },
  {
    "text": "to actually know how the roll outs would",
    "start": "1462000",
    "end": "1464080"
  },
  {
    "text": "what conditions will cause the roll outs",
    "start": "1464080",
    "end": "1466520"
  },
  {
    "text": "to move back yeah that's actually a",
    "start": "1466520",
    "end": "1468399"
  },
  {
    "text": "great question so today we have a",
    "start": "1468399",
    "end": "1470600"
  },
  {
    "text": "wrapper over coup CTL we call it like",
    "start": "1470600",
    "end": "1472840"
  },
  {
    "text": "coup CFG we just get the regular",
    "start": "1472840",
    "end": "1475720"
  },
  {
    "text": "deployment file and then we generate a",
    "start": "1475720",
    "end": "1478360"
  },
  {
    "text": "roll out uh roll out crd on the fly so",
    "start": "1478360",
    "end": "1482080"
  },
  {
    "text": "we generate a roll out crd on the Fly",
    "start": "1482080",
    "end": "1483799"
  },
  {
    "text": "and we deploy it and then for the",
    "start": "1483799",
    "end": "1485440"
  },
  {
    "text": "metrics we provide our developers with",
    "start": "1485440",
    "end": "1487880"
  },
  {
    "text": "some out of the box metrics like",
    "start": "1487880",
    "end": "1489279"
  },
  {
    "text": "database errors basic service errors and",
    "start": "1489279",
    "end": "1491640"
  },
  {
    "text": "then we give them a framework so they",
    "start": "1491640",
    "end": "1493279"
  },
  {
    "text": "can easily Define the checks they need",
    "start": "1493279",
    "end": "1495200"
  },
  {
    "text": "and that's why we have the dryon feature",
    "start": "1495200",
    "end": "1496679"
  },
  {
    "text": "like if you want to do something",
    "start": "1496679",
    "end": "1497679"
  },
  {
    "text": "Advanced and you're not sure you can",
    "start": "1497679",
    "end": "1499240"
  },
  {
    "text": "just start with a dryon and then you can",
    "start": "1499240",
    "end": "1501559"
  },
  {
    "text": "uh with time graduate it to Veterans but",
    "start": "1501559",
    "end": "1504559"
  },
  {
    "text": "yeah it's it's all maintained by the",
    "start": "1504559",
    "end": "1505919"
  },
  {
    "text": "devx team okay so it's kind of like a",
    "start": "1505919",
    "end": "1508440"
  },
  {
    "text": "centralized and that's some sort of",
    "start": "1508440",
    "end": "1510039"
  },
  {
    "text": "overhead you have to maintain for the",
    "start": "1510039",
    "end": "1511520"
  },
  {
    "text": "sake of everybody that is correct yeah",
    "start": "1511520",
    "end": "1513640"
  },
  {
    "text": "so our devx team gives us a library and",
    "start": "1513640",
    "end": "1515600"
  },
  {
    "text": "then every service would just use that",
    "start": "1515600",
    "end": "1516960"
  },
  {
    "text": "library to get out of the box checks and",
    "start": "1516960",
    "end": "1518679"
  },
  {
    "text": "they can add uh on top of that out of",
    "start": "1518679",
    "end": "1520919"
  },
  {
    "text": "curiosity how big is your devx team now",
    "start": "1520919",
    "end": "1523600"
  },
  {
    "text": "uh 10 people all right thank",
    "start": "1523600",
    "end": "1527320"
  },
  {
    "text": "you",
    "start": "1527320",
    "end": "1530120"
  },
  {
    "text": "please ask a questions yeah I think",
    "start": "1530120",
    "end": "1531720"
  },
  {
    "text": "we'll be at the back of the room if you",
    "start": "1531720",
    "end": "1532880"
  },
  {
    "text": "have more questions thank",
    "start": "1532880",
    "end": "1535520"
  },
  {
    "text": "you",
    "start": "1535520",
    "end": "1538520"
  }
]
[
  {
    "text": "we're going to talk about introduction to distributed workload with Ray on kubernetes uh before we get started",
    "start": "40",
    "end": "5240"
  },
  {
    "text": "quick show of hands how many of you know what Ray is or have heard of it a lot of you good uh if you haven't",
    "start": "5240",
    "end": "11840"
  },
  {
    "text": "this is perfect talk we're going to talk about what R is how many of you and this is going to be a dumb question how many of you have heard of",
    "start": "11840",
    "end": "17320"
  },
  {
    "text": "kubernetes I want to see all the hands you have been here for like three days now come on uh good all of you have done",
    "start": "17320",
    "end": "22920"
  },
  {
    "text": "that the last one how many of you uh care about distributed workloads good so this is a good good",
    "start": "22920",
    "end": "29000"
  },
  {
    "text": "mix we have uh so this you're in the right talk hopefully um so my name is Mofi uh I am a developer Advocate at",
    "start": "29000",
    "end": "35079"
  },
  {
    "text": "Google and I have here with me Abdel I'm also developer Advocate as Google my voice is a little bit choppy so",
    "start": "35079",
    "end": "41000"
  },
  {
    "text": "hopefully you'll be able to understand what I'm talking about it's not Co so don't worry uh also you know uh if you",
    "start": "41000",
    "end": "47000"
  },
  {
    "text": "need to need to find us later we have all moved to Blue Sky recently so you can uh go there uh we're we're leaving",
    "start": "47000",
    "end": "52559"
  },
  {
    "text": "the B app for a different flying themed app so uh you can you can come us find",
    "start": "52559",
    "end": "57640"
  },
  {
    "text": "us there so let's get it started right so distributed Compu uh the main concept of distribute Computing is why use one",
    "start": "57640",
    "end": "63160"
  },
  {
    "text": "computer do to do a thing when you can use a thousand right so like instead of using one we're going to use a thousand that's the whole goal of distributed",
    "start": "63160",
    "end": "69000"
  },
  {
    "text": "computing couple of things you need to kind of know about distributed computing and these days most of the distributed",
    "start": "69000",
    "end": "74159"
  },
  {
    "text": "computing use cases are being used for AI Computing where python the language is basically the default language in",
    "start": "74159",
    "end": "80560"
  },
  {
    "text": "that space so that's uh point one point two with uh generative Ai and like this",
    "start": "80560",
    "end": "85840"
  },
  {
    "text": "new emergence of large language models and this large AI workloads um distributed computer is no longer a",
    "start": "85840",
    "end": "91560"
  },
  {
    "text": "luxury an optional thing you kind of have to do it to be able to build these big models so with these two knowledge",
    "start": "91560",
    "end": "97600"
  },
  {
    "text": "in mind let's talk about distributed computing a little bit more details so why is distributed computing why I have",
    "start": "97600",
    "end": "103280"
  },
  {
    "text": "a big computer I have a pretty expensive laptop in front of me I could just do it in my machine but the challenge is um",
    "start": "103280",
    "end": "109799"
  },
  {
    "text": "compute can only go far more slw kind of like locks us to a certain limit of how big of a computer we can make every year",
    "start": "109799",
    "end": "115159"
  },
  {
    "text": "we can make it a little bit bigger but that limit only get can be pushed so far so the only way you can get bigger is by",
    "start": "115159",
    "end": "121799"
  },
  {
    "text": "using many of the small computers so you can combine bunch of these computers together and somehow get them to work",
    "start": "121799",
    "end": "127640"
  },
  {
    "text": "together to get compute that is impossible on a single machine availability is the next one so that those big machine like Nvidia gpus or",
    "start": "127640",
    "end": "134319"
  },
  {
    "text": "tpus are hard to come by so if you can solve your problem by breaking it down into small chunks that you can solve",
    "start": "134319",
    "end": "140680"
  },
  {
    "text": "using commodity Hardware like a regular CPU or cloud or your data centers now you can solve a lot more problems that",
    "start": "140680",
    "end": "146879"
  },
  {
    "text": "you could otherwise just wait for some company to build the next bigger machine next is efficiency so again if you can",
    "start": "146879",
    "end": "153200"
  },
  {
    "text": "break the problem in small chunks you can do this embarrassingly parallel solutions to problems and gain a lot of",
    "start": "153200",
    "end": "158680"
  },
  {
    "text": "efficiency because those commodity Hardware is a lot cheaper to rent from cloud or buy at like at a bulk rather",
    "start": "158680",
    "end": "165280"
  },
  {
    "text": "than trying to build a superc computer those are more expensive and finally flexibility so when you can break your",
    "start": "165280",
    "end": "170319"
  },
  {
    "text": "problem into small parts now you have a lot more flexibility in when and where you run it you get a lot of bargaining",
    "start": "170319",
    "end": "175480"
  },
  {
    "text": "power with both your cloud provider or like building your own data centers now you have a lot of flexibility how and",
    "start": "175480",
    "end": "181480"
  },
  {
    "text": "when you solve these problems but that's kind of like why we do distributed computing it comes with some challenges",
    "start": "181480",
    "end": "187720"
  },
  {
    "text": "not now like if I wrote something and that ran on my machine it is actually like code runs and it finishes I'm done",
    "start": "187720",
    "end": "194440"
  },
  {
    "text": "but when you try to break the same problem into like a million pieces one of those pieces fall and all of a sudden",
    "start": "194440",
    "end": "200280"
  },
  {
    "text": "I don't know how to now like reconcile my solution back to the original parts so consistency is a big problem and this",
    "start": "200280",
    "end": "206480"
  },
  {
    "text": "consistency is not just for like the code itself it's also for the data because I have data across now thousands",
    "start": "206480",
    "end": "211680"
  },
  {
    "text": "of machines I have networking challenges to communicate back and forth between them and if something fails how do I go",
    "start": "211680",
    "end": "218040"
  },
  {
    "text": "back to like running State there are problems where failure basically means you have to start over there are",
    "start": "218040",
    "end": "223920"
  },
  {
    "text": "techniques like checkpointing where you can restart back so there is a lot of more problems now you have to solve to",
    "start": "223920",
    "end": "229599"
  },
  {
    "text": "now solve this problem in a distributed manner next is concurrency so when you break your problem down into like bunch",
    "start": "229599",
    "end": "235280"
  },
  {
    "text": "of pieces all those problems are solving like individually how do you go back where do you sync you have like this uh",
    "start": "235280",
    "end": "241760"
  },
  {
    "text": "synchronization problem where you can need to uh solve the problem and bring the solutions back together in the same",
    "start": "241760",
    "end": "246959"
  },
  {
    "text": "place and the couple of the last ones are like security now you have like your attack surface is a lot bigger now you",
    "start": "246959",
    "end": "252680"
  },
  {
    "text": "have thousands of machines and you have to take care of controlling the security for all of them at the same time and with that comes the problem of",
    "start": "252680",
    "end": "258720"
  },
  {
    "text": "complexity of management so kubernetes does help with some of these things as we're going to talk about but it is over",
    "start": "258720",
    "end": "264680"
  },
  {
    "text": "the last 10 years a lot of folks have tried a lot of different things found a lot of different challenges in that space",
    "start": "264680",
    "end": "270560"
  },
  {
    "text": "and I think any talk about distributed uh compute cannot be completed without talking about cap theorem it basically",
    "start": "270560",
    "end": "276800"
  },
  {
    "text": "basically says you cannot have it all uh you can either have two of the three that are available so either you can be",
    "start": "276800",
    "end": "282800"
  },
  {
    "text": "consistent or you can have full availability or you can be fall tolerant so every single solution we build around",
    "start": "282800",
    "end": "288720"
  },
  {
    "text": "the distributed compute Frameworks kind of try to get as much as all three things as possible but usually they kind",
    "start": "288720",
    "end": "295479"
  },
  {
    "text": "of have to make a concession on one or the other um so with all that",
    "start": "295479",
    "end": "301240"
  },
  {
    "text": "that was a very rapid fire introduction of distributed compute let's talk about Ray uh so Ray is uh open source python",
    "start": "301240",
    "end": "308960"
  },
  {
    "text": "library that helps you with some of the distributed compute challenges and what Ray is it's a python",
    "start": "308960",
    "end": "316479"
  },
  {
    "text": "open source python library that does give you a lot of this library and Frameworks to build distributed compute",
    "start": "316479",
    "end": "322039"
  },
  {
    "text": "platforms it's a simple and flexible API their claim also I can verify I have tested it it's pretty simple scalable",
    "start": "322039",
    "end": "329120"
  },
  {
    "text": "because Ray gives you fundamental building blocks and it scales without you having to do additional work you",
    "start": "329120",
    "end": "334840"
  },
  {
    "text": "just say I wanted one copy now I want 10 now I want, you can just scale within the same linear approach and finally Ray",
    "start": "334840",
    "end": "342039"
  },
  {
    "text": "have built the library for working with CPU which is the most common also gpus and tpus which is now the compute of the",
    "start": "342039",
    "end": "348840"
  },
  {
    "text": "new generation of AML workload if you look at the ray components there are basically three",
    "start": "348840",
    "end": "355080"
  },
  {
    "text": "layers at the bottommost layer is your Hardware your computer we work for a cloud provider so we're at the bottom layer where all the things run right",
    "start": "355080",
    "end": "362039"
  },
  {
    "text": "above that is the ray core and today's talk will mostly cover the bottommost two layer Ray core and Cloud on top of",
    "start": "362039",
    "end": "368440"
  },
  {
    "text": "that Ray also provides a bunch of other libraries that help you do machine learning esque task like data processing",
    "start": "368440",
    "end": "375080"
  },
  {
    "text": "training tuning uh reinforcement learning and serving but those are all libraries that you can choose other",
    "start": "375080",
    "end": "381199"
  },
  {
    "text": "solutions for Ray actually is a python library that works with most of the other things that exist in the ecosystem so if you look at the ray AI",
    "start": "381199",
    "end": "388160"
  },
  {
    "text": "libraries like Ray data there are a bunch of competition in that space things like data Lake Arrow parette",
    "start": "388160",
    "end": "394160"
  },
  {
    "text": "snowflake they all do similar things things like napai scipi pandas you could",
    "start": "394160",
    "end": "399199"
  },
  {
    "text": "also pick and choose any of those to work with Ray for training you have things like tensorflow pie torch hugging",
    "start": "399199",
    "end": "404440"
  },
  {
    "text": "face libraries that exist in the space for tuning you can look at things like never grad mlflow uh bits and uh bits",
    "start": "404440",
    "end": "410599"
  },
  {
    "text": "and biases so you have choice about pretty much in all different categories you are using Ray 4 for serving",
    "start": "410599",
    "end": "416759"
  },
  {
    "text": "obviously gradio uh stream lead VM TGI fast API you could basically pick and",
    "start": "416759",
    "end": "422199"
  },
  {
    "text": "choose anything you like or whatever ecosystem uh demands and you can run them on top of the ray",
    "start": "422199",
    "end": "427919"
  },
  {
    "text": "core now when you want to understand Ray there are three key Concepts you need to understand to be able to use Ray core",
    "start": "427919",
    "end": "434160"
  },
  {
    "text": "properly number one is Task uh task is any python function that is going to be",
    "start": "434160",
    "end": "439520"
  },
  {
    "text": "executing as a remote function in the ray cluster uh next up is actors actors are something that has State and the",
    "start": "439520",
    "end": "446599"
  },
  {
    "text": "final one is object object is the reference to either the task or the actor so instead of me telling you i'",
    "start": "446599",
    "end": "452000"
  },
  {
    "text": "would rather show you what it means so if you can see my code uh is the text",
    "start": "452000",
    "end": "458440"
  },
  {
    "text": "big enough should I make it bigger bigger bigger bump it up all right big enough could mostly see it uh okay so",
    "start": "458440",
    "end": "465800"
  },
  {
    "text": "let's write some uh python code to do this so first things first I'm going to write a python function So Def sum Funk",
    "start": "465800",
    "end": "473199"
  },
  {
    "text": "and this is going to return one so this function all if I were to run this function all of us know what's going to",
    "start": "473199",
    "end": "478560"
  },
  {
    "text": "happen uh some funk anybody want to take a guess what's going to",
    "start": "478560",
    "end": "485479"
  },
  {
    "text": "happen no takers so far one yeah that's that's the function but what if I want",
    "start": "485479",
    "end": "491400"
  },
  {
    "text": "to now run this function as a distributed function as a ray task all I have to do is do uh decorator ray.",
    "start": "491400",
    "end": "499159"
  },
  {
    "text": "remote oh spell it right uh ray. remote now this is a ray remote function of",
    "start": "499159",
    "end": "504240"
  },
  {
    "text": "course to use The Decorator I need to import the dependency I have so import Ray and right now I don't have a ray",
    "start": "504240",
    "end": "511599"
  },
  {
    "text": "cluster running so Ray Library also lets you create a cluster very quickly so I can do something like Ray dot in it",
    "start": "511599",
    "end": "517640"
  },
  {
    "text": "that's going to create a cluster locally on my machine now I just called created this",
    "start": "517640",
    "end": "523120"
  },
  {
    "text": "Ray remote function but I'm not using it yet so to use it I have to create an object reference to this function so what I can do create a new object called",
    "start": "523120",
    "end": "530519"
  },
  {
    "text": "object and call suf funk. remote now that is going to go ahead and create a",
    "start": "530519",
    "end": "535800"
  },
  {
    "text": "reference to this remote function that is going to execute against my Ray cluster and to get the data out of my",
    "start": "535800",
    "end": "541399"
  },
  {
    "text": "remote function I have to do ray. get object instead of doing calling the",
    "start": "541399",
    "end": "546560"
  },
  {
    "text": "function directly now I'm calling ray. getet on the object now whatever the result of that object would be I will",
    "start": "546560",
    "end": "552560"
  },
  {
    "text": "get that printed out on my code here so let's run this code again for the most part it should be very similar and what",
    "start": "552560",
    "end": "558600"
  },
  {
    "text": "did I do uh okay so I think uh live coding",
    "start": "558600",
    "end": "563800"
  },
  {
    "text": "people okay save that try that one more time oh that's not it",
    "start": "563800",
    "end": "571360"
  },
  {
    "text": "that doesn't like it all right let me send it somewhere else hold on uh",
    "start": "572079",
    "end": "577160"
  },
  {
    "text": "no and I didn't want to go there just yet",
    "start": "577160",
    "end": "582959"
  },
  {
    "text": "but I might have to do it okay let's try this one more time all right cool um so",
    "start": "582959",
    "end": "589440"
  },
  {
    "text": "for some reason it could not start the ray cluster on my local machine but what I did here I started I have a ray",
    "start": "589440",
    "end": "595320"
  },
  {
    "text": "cluster running on my kubernetes cluster and I'm just sending my code to that kubernetes cluster",
    "start": "595320",
    "end": "600360"
  },
  {
    "text": "live coding what what can you do but the same idea still exist if I didn't if I my my computer could start a r cluster",
    "start": "600360",
    "end": "605839"
  },
  {
    "text": "it would have sent it to there but in this case I am sending it to this remote cluster that I'm port forwarding to that",
    "start": "605839",
    "end": "611920"
  },
  {
    "text": "is running on kubernetes now that is the task next one is actor so actor is",
    "start": "611920",
    "end": "617000"
  },
  {
    "text": "similar to raid task but with state so instead of just sending an arbitrary function as a rid remote function we",
    "start": "617000",
    "end": "624040"
  },
  {
    "text": "create this class that is going to keep state so every time something happens to this class we we can keep track of what",
    "start": "624040",
    "end": "630320"
  },
  {
    "text": "have happened so in this case we create a class counter which has a field called counter which is set to zero and every",
    "start": "630320",
    "end": "636120"
  },
  {
    "text": "time increment gets called we increment that number by one so every time so you could see that as anything else anything",
    "start": "636120",
    "end": "641399"
  },
  {
    "text": "you need to have state you want to as an actor anything is just a standalone function you want to use a task so in",
    "start": "641399",
    "end": "647079"
  },
  {
    "text": "this case we do that again I'm going to use this one instead of the buil-in one and if I were to run Python actor.",
    "start": "647079",
    "end": "655880"
  },
  {
    "text": "py and I'm just sending it to the remote function and you would see that I'm getting back 1 2 3 4 five I call it five",
    "start": "655880",
    "end": "663000"
  },
  {
    "text": "times in a loop right here Range Five and every time I call it the increment goes up by one and I print it I get 1 2",
    "start": "663000",
    "end": "668920"
  },
  {
    "text": "3 4 5 uh the last thing we're probably not going to run it because a bunch of code here but last thing is when you",
    "start": "668920",
    "end": "675519"
  },
  {
    "text": "want to build it out the main concept is every remote function execution actually happens immediately I sent out my code I",
    "start": "675519",
    "end": "682720"
  },
  {
    "text": "send all the remote function called to the ray cluster at the same time and they execute and we can then collect the",
    "start": "682720",
    "end": "688240"
  },
  {
    "text": "result in the end so you could start seeing if you're doing something like Abdul is going to talk about like a",
    "start": "688240",
    "end": "693959"
  },
  {
    "text": "example of it when you're building it out you could then fan out your workload onto these remote computers as many",
    "start": "693959",
    "end": "700920"
  },
  {
    "text": "computer you have you can run them parallely up to like hundreds of thousand execution at the same time and then collect the result uh instead of",
    "start": "700920",
    "end": "707839"
  },
  {
    "text": "doing sequentially which is going to be much slower you're doing one calculation waiting one calculation waiting you could just do all the computation and as",
    "start": "707839",
    "end": "714839"
  },
  {
    "text": "as long as you have compute resources you could pretty much scale to infinity and again and the bigger you scale the",
    "start": "714839",
    "end": "720519"
  },
  {
    "text": "more time you need to synchronize them but in the um long run obviously if you can scale higher you get a lot more",
    "start": "720519",
    "end": "727240"
  },
  {
    "text": "faster compute because you're just doing in distributed f um fashion so let's move on to the next part yeah and so",
    "start": "727240",
    "end": "735760"
  },
  {
    "text": "what's what what we're noticing these days also is that people are using open source platforms or open source tools",
    "start": "735760",
    "end": "741839"
  },
  {
    "text": "kubernetes that platform to build ml platforms so we're going to do a little bit of a role play here today um where I",
    "start": "741839",
    "end": "747839"
  },
  {
    "text": "will be the platform admin and M is the ml engineer or the data scientist we is a very small company I have to do two",
    "start": "747839",
    "end": "753880"
  },
  {
    "text": "job at the same time this economy you know yeah um so um as a platform admin",
    "start": "753880",
    "end": "759600"
  },
  {
    "text": "my main area of focus is kubernetes it's all the infrastructure um all the accelerators all the storage all the",
    "start": "759600",
    "end": "765680"
  },
  {
    "text": "networking all that stuff right so basically pretty much everything in blue in the slide is my my problem yeah as a",
    "start": "765680",
    "end": "772320"
  },
  {
    "text": "data scientist and ml engineer I like love my python notebooks Jupiter notebooks I want to write my code I want",
    "start": "772320",
    "end": "778279"
  },
  {
    "text": "to write my fine tune and serving code as well as use all these open source libraries that exist in the space things",
    "start": "778279",
    "end": "783320"
  },
  {
    "text": "like pytorch things like airflow MLF flow whatever my team needs I'm going to then use them and I'm going to ask the",
    "start": "783320",
    "end": "789279"
  },
  {
    "text": "platform team to give me the resources and the right tools so that I could run them without having to learn about all",
    "start": "789279",
    "end": "795040"
  },
  {
    "text": "like kubernetes and VMS and all that fun stuff myself and so where Reay really",
    "start": "795040",
    "end": "800399"
  },
  {
    "text": "shines very well in building ml platforms is that it's creates that layer that ties the actual kubernetes",
    "start": "800399",
    "end": "805639"
  },
  {
    "text": "platform itself to things that data scientists care about one of the things we talked about in the",
    "start": "805639",
    "end": "811880"
  },
  {
    "text": "previous slide well didn't talk about but it's in the blue in the middle that we didn't talk about is q and we're",
    "start": "811880",
    "end": "817760"
  },
  {
    "text": "going to quickly give you like a 10-second overview of Q so if you don't understand what I'm talking about please talk to us later because Q is much",
    "start": "817760",
    "end": "824320"
  },
  {
    "text": "bigger so it's an open source project started by the uh Sig batch and what Q does it creates a structure that lets",
    "start": "824320",
    "end": "831759"
  },
  {
    "text": "you share resources in the same kubernetes cluster in a fair manner so you could have a job that gets",
    "start": "831759",
    "end": "838199"
  },
  {
    "text": "abstracted by something called workload and each workload runs against something called the local queue which then runs",
    "start": "838199",
    "end": "843800"
  },
  {
    "text": "on a cluster queue that is like a queue resource and that cluster Q have access to bunch of the kubernetes resource that",
    "start": "843800",
    "end": "850399"
  },
  {
    "text": "you have underneath so you could create a system where bunch of team can Target the same cluster queue and depending on",
    "start": "850399",
    "end": "857440"
  },
  {
    "text": "priority and their quoda they could access the resources faster than other teams and when nobody's using those",
    "start": "857440",
    "end": "863639"
  },
  {
    "text": "resources you could share those Resources with other people so you can create a ml platform with build",
    "start": "863639",
    "end": "869279"
  },
  {
    "text": "multi-tenancy so again it's not a q is not the topic of this talk but if you want to learn more about Q please talk",
    "start": "869279",
    "end": "874560"
  },
  {
    "text": "to us later and so similar to any application that you would you would build uh a machine learning problem has",
    "start": "874560",
    "end": "883480"
  },
  {
    "text": "a life cycle and usually that life cycle starts with data processing machine learning with without data is pretty",
    "start": "883480",
    "end": "888759"
  },
  {
    "text": "much useless so you start with data processing then you will do your training or you find training depending on what you're trying to achieve and",
    "start": "888759",
    "end": "895040"
  },
  {
    "text": "then you will have to do the inference so the serving part right the beauty of Open Source and and also the beauty of Q",
    "start": "895040",
    "end": "900120"
  },
  {
    "text": "of Ray is that you can choose Ray for one part the data processing in this case but use other tools like py torch",
    "start": "900120",
    "end": "906399"
  },
  {
    "text": "for the fine tuning and VM for the deployment or you can just choose to use Ray across the entire life cycle of the",
    "start": "906399",
    "end": "912839"
  },
  {
    "text": "machine learning process so you have libraries for data processing you have libraries for fine tuning and then you",
    "start": "912839",
    "end": "918560"
  },
  {
    "text": "have objects to do race serving which we're going to look at an example later and just one thing uh the first one that",
    "start": "918560",
    "end": "924199"
  },
  {
    "text": "we showed this is actual solutions that is available if you scan the QR code on the top right entire code is available",
    "start": "924199",
    "end": "929880"
  },
  {
    "text": "in GitHub that you can go find and play around with yourself yeah so how do you run Ray uh so Ray is",
    "start": "929880",
    "end": "937920"
  },
  {
    "text": "a again a python library that you can run on your local machine but again if you want to distribute Computing I only",
    "start": "937920",
    "end": "943360"
  },
  {
    "text": "have like one laptop so I can do distributed on a single laptop that's kind of tough so when you're talking about Ray Library the part that we care",
    "start": "943360",
    "end": "950319"
  },
  {
    "text": "about is the ray core Ray core is the part that is doing the all the distributed cool distributed stuff all",
    "start": "950319",
    "end": "955800"
  },
  {
    "text": "the ray AI libraries they are actually Standalone libraries that you could use with or without rayen if you want to but",
    "start": "955800",
    "end": "961519"
  },
  {
    "text": "the ray core needs some compute to run and that compute uh could be VMS a lot of us have still have VMS and data",
    "start": "961519",
    "end": "967639"
  },
  {
    "text": "centers but it also could be and in our case it is containers so when you want",
    "start": "967639",
    "end": "972800"
  },
  {
    "text": "to run Ray in the containers the best way to do that is using cubre cubre is an open source project maintained by the",
    "start": "972800",
    "end": "979399"
  },
  {
    "text": "ray team and the community to make sure that Ray things can be run on kubernetes",
    "start": "979399",
    "end": "984920"
  },
  {
    "text": "in an easy manageable way and so before we move on we we we",
    "start": "984920",
    "end": "990800"
  },
  {
    "text": "don't really have a slide here but basically Ray follows kind of like the same architecture as kubernetes that has a control plane and data plane the",
    "start": "990800",
    "end": "996920"
  },
  {
    "text": "control plane is the API end point that's where you send your jobs to be executed and the worker plane is the",
    "start": "996920",
    "end": "1002240"
  },
  {
    "text": "where the actual distributed computing will happen basically whether you are running on VMS or running on containers",
    "start": "1002240",
    "end": "1008600"
  },
  {
    "text": "on kubernetes it's the same exact architecture the only difference is that on VMS the control plane will be a VM on",
    "start": "1008600",
    "end": "1014560"
  },
  {
    "text": "kubernetes the control plane will be a pod right so what uh morphy showed earlier when you do the array NX 127",
    "start": "1014560",
    "end": "1021399"
  },
  {
    "text": "Local Host like believe us that's actually a remote cluster it's not a local CL I'll I'll show that in a second it's a yeah it's a remote cluster",
    "start": "1021399",
    "end": "1027400"
  },
  {
    "text": "through port forward so why kubernetes why would you even bother with on kubernetes well kubernetes is pretty",
    "start": "1027400",
    "end": "1032520"
  },
  {
    "text": "good at doing automation uh infrastructure automation right scaling up your clusters scaling them down uh",
    "start": "1032520",
    "end": "1038199"
  },
  {
    "text": "creating new resources giving you a ready to use node in like Split Second great great at scaling great at high",
    "start": "1038199",
    "end": "1045520"
  },
  {
    "text": "availability if your job is running and it gets disrupted because whatever reason that you can just kubernetes will",
    "start": "1045520",
    "end": "1051120"
  },
  {
    "text": "just retry it if the head node or the control plate of Ray dies it will just be recreated right um um Advanced device",
    "start": "1051120",
    "end": "1058520"
  },
  {
    "text": "management there's actually within the kues community there is a working group called working group device management which is looking into the problem of how",
    "start": "1058520",
    "end": "1065200"
  },
  {
    "text": "can you actually get metrics how do you optimize the utilization of Hardware accelerators so gpus and tpus in kues",
    "start": "1065200",
    "end": "1071840"
  },
  {
    "text": "itself yeah and then kubernetes is multicloud you can run it on Prem you can run it on Google AWS Azure or orle",
    "start": "1071840",
    "end": "1079120"
  },
  {
    "text": "whatever um so pretty much Ray on kubernetes is as portable as any application running on kubernetes the",
    "start": "1079120",
    "end": "1085039"
  },
  {
    "text": "only probably the 5 or 10% differences between Cloud providers would be the type of accelerat you're going to",
    "start": "1085039",
    "end": "1090799"
  },
  {
    "text": "have so Cub as as a as um muy mentioned is an operator that allows you to",
    "start": "1090799",
    "end": "1096120"
  },
  {
    "text": "basically spin up a ray cluster on top of kubernetes and then use Ray core to just like send your jobs to um that",
    "start": "1096120",
    "end": "1102600"
  },
  {
    "text": "cluster running on top of kubernetes um then Cube gray itself has three epis you",
    "start": "1102600",
    "end": "1108520"
  },
  {
    "text": "can about the crds there is a ray cluster object which allows you to spin up a cluster so pretty much how many",
    "start": "1108520",
    "end": "1114240"
  },
  {
    "text": "nodes do you want for your worker nodes what's the configuration of those nodes how many gpus you want to be attached to them etc etc there is a ray job which",
    "start": "1114240",
    "end": "1120360"
  },
  {
    "text": "allows you to create a job um so it will leverage the job Epi in kubernetes under the hood but it has like a much higher",
    "start": "1120360",
    "end": "1126200"
  },
  {
    "text": "level of um um abstraction and then there is a ray service which we're going to look at the demo later which is actually serving the model so once you",
    "start": "1126200",
    "end": "1132640"
  },
  {
    "text": "have uh trained F CH your model you need to serve it you have the ray service which is a very uh very nice object it's",
    "start": "1132640",
    "end": "1139640"
  },
  {
    "text": "a single yl object that contains your service like your like like the container um running the inference",
    "start": "1139640",
    "end": "1145919"
  },
  {
    "text": "server the model and also it will generate the kubernetes service capital S under the hood once the model is ready",
    "start": "1145919",
    "end": "1152640"
  },
  {
    "text": "to be um serving yeah so let's take a look and see what all of them look like in practice so the first thing we",
    "start": "1152640",
    "end": "1159080"
  },
  {
    "text": "already actually kind of seen that already which was the ray cluster that we send our job to instead of running",
    "start": "1159080",
    "end": "1164520"
  },
  {
    "text": "locally so I have a clust already set I don't want to spin up everything live we have a limited amount of time so if I",
    "start": "1164520",
    "end": "1169960"
  },
  {
    "text": "want to CU control get actually before I do that API resources I'm going to see if I this cluster has reinstalled or not",
    "start": "1169960",
    "end": "1177039"
  },
  {
    "text": "so if I were to do API resource and grap on the word Ray I would see that I have three different new crds available to",
    "start": "1177039",
    "end": "1182600"
  },
  {
    "text": "this kubernetes cluster uh this is Ray cluster Ray jobs and Ray services so as",
    "start": "1182600",
    "end": "1187960"
  },
  {
    "text": "Abdul mentioned these are the three crds that gets installed when you install Cube on your cluster and uh in this case",
    "start": "1187960",
    "end": "1194360"
  },
  {
    "text": "we're using a GK cluster again cubre Works across any kubernetes distribution that you have next up uh I have a a ray",
    "start": "1194360",
    "end": "1203559"
  },
  {
    "text": "cluster uh that I have set up I actually have multiple here we're going to talk about what each of them are doing but",
    "start": "1203559",
    "end": "1208880"
  },
  {
    "text": "the one we were sending the job to was the ray cluster demo right so if I were to do Cube",
    "start": "1208880",
    "end": "1214600"
  },
  {
    "text": "control uh get service this morning all of you saw the the the Family Feud the",
    "start": "1214600",
    "end": "1220760"
  },
  {
    "text": "actual canonical way to pronounce Cube control is Cube control so all everybody else was wrong uh I'm going to I'm I'm",
    "start": "1220760",
    "end": "1226679"
  },
  {
    "text": "going to I'm going to die on this hill uh but no as of kubernetes 1.5 I think they actually is in the",
    "start": "1226679",
    "end": "1233720"
  },
  {
    "text": "release note so if you want to go back and look it up is the canonical way to pronounce it so it's not Cube C no it's",
    "start": "1233720",
    "end": "1239159"
  },
  {
    "text": "Cube control so yes uh 90% of the people were wrong uh anyway uh so uh the",
    "start": "1239159",
    "end": "1246159"
  },
  {
    "text": "cluster we were talking about is the cube cluster demo head service that's the cluster IP and I set up a port",
    "start": "1246159",
    "end": "1251360"
  },
  {
    "text": "forwarding to that particular one this one in the client Port so I can send my",
    "start": "1251360",
    "end": "1256559"
  },
  {
    "text": "job there I could do one more port forward and this is multiple ports in this particular service I can K port",
    "start": "1256559",
    "end": "1262600"
  },
  {
    "text": "forward uh and if I can spell properly service uh Ray cluster demo head service",
    "start": "1262600",
    "end": "1268840"
  },
  {
    "text": "that's the one I'm going to port forward the 8265 8265 is the default Port Ray cluster uses for their dashboard so if I",
    "start": "1268840",
    "end": "1276200"
  },
  {
    "text": "were to go that I can go one more and you can see I have this dashboard if I refresh it would see and I've been sending a lot of these jobs here you",
    "start": "1276200",
    "end": "1282720"
  },
  {
    "text": "could see all all my jobs that I have sent so far on to this cluster they're all sent here some of them fail some",
    "start": "1282720",
    "end": "1288080"
  },
  {
    "text": "succeeded but Ray cluster also gives you this nice view of like all the jobs all the services all the uh actors and",
    "start": "1288080",
    "end": "1295400"
  },
  {
    "text": "things that are running in there so actors as I said actors have state so if I created some actors that I had created",
    "start": "1295400",
    "end": "1300880"
  },
  {
    "text": "in the past it would remember what the state of that actor was and metrics and logs and all that fun stuff so that's",
    "start": "1300880",
    "end": "1306120"
  },
  {
    "text": "your ray cluster now let's look at something a little bit more interesting uh make this smaller make this bigger uh",
    "start": "1306120",
    "end": "1313799"
  },
  {
    "text": "so let's look at so this is my definition of a a cluster which is created the community's job of uh a kuti",
    "start": "1313799",
    "end": "1319120"
  },
  {
    "text": "is object of a cluster I as Abdul mentioned you define your head group and your worker group and they're separate",
    "start": "1319120",
    "end": "1325400"
  },
  {
    "text": "head is the one that controls and distributes all the work worker is the one that runs your workload you set up",
    "start": "1325400",
    "end": "1330640"
  },
  {
    "text": "exactly how much resource you want to give to each of those you can also set up Auto scaling with HPA and vpa to make them bigger and you set up the worker",
    "start": "1330640",
    "end": "1337640"
  },
  {
    "text": "group and then I Define a ray job where I basically want to just know how much",
    "start": "1337640",
    "end": "1343320"
  },
  {
    "text": "resource this particular Ray cluster have very simple python code but it could write pretty much anything you want and in that one I'm targeting my",
    "start": "1343320",
    "end": "1349960"
  },
  {
    "text": "Ray cluster the one that I is already created so this is a static Ray cluster that exists on my kubernetes cluster I'm",
    "start": "1349960",
    "end": "1355720"
  },
  {
    "text": "sending job to it so I'm going to kill this one and let's try I'm going to delete first because I ran this before",
    "start": "1355720",
    "end": "1362840"
  },
  {
    "text": "but let's apply that again cctl apply d f Cube bra Cube control you know",
    "start": "1362840",
    "end": "1368880"
  },
  {
    "text": "what stop it I I'm trying to I'm trying to better myself people uh so thank you for",
    "start": "1368880",
    "end": "1375880"
  },
  {
    "text": "keeping me honest anyway I created this Ray job uh examples if I do CU control get pods I would see that a new job has",
    "start": "1375880",
    "end": "1383799"
  },
  {
    "text": "started now it's running this is the new one that I just created and in a few seconds this is going to run against my",
    "start": "1383799",
    "end": "1390000"
  },
  {
    "text": "uh Ray cluster and it's going to respond back with some log so I could do Cube control logs Ray job I have too many",
    "start": "1390000",
    "end": "1397480"
  },
  {
    "text": "things here sample GJ something something if I were to do this you would see that it completed and it printed out",
    "start": "1397480",
    "end": "1404480"
  },
  {
    "text": "bunch of things again I'm talking to a ray cluster using a kubernetes object like a ray job so Ray job is interesting",
    "start": "1404480",
    "end": "1411039"
  },
  {
    "text": "but this time I was targeting an existing Ray cluster but the method that is actually suggested for kues users is",
    "start": "1411039",
    "end": "1417559"
  },
  {
    "text": "not to keep a ray cluster running for a long time this is the mode that is called fmal Ray cluster the reason you",
    "start": "1417559",
    "end": "1423440"
  },
  {
    "text": "want to do that is Abdul is going to talk about in a second but the way to do it is in your ray job definition you",
    "start": "1423440",
    "end": "1429679"
  },
  {
    "text": "have another spec which is just called Ray cluster spec so you define a ray cluster as part of your ray job and it",
    "start": "1429679",
    "end": "1435520"
  },
  {
    "text": "spins up both the ray cluster and the ray job at the at the same time and your workload will run in that said Ray",
    "start": "1435520",
    "end": "1441640"
  },
  {
    "text": "cluster and once it's done everything will be teared down right so why is important AB will talk about in a second",
    "start": "1441640",
    "end": "1447120"
  },
  {
    "text": "but that's the way people actually recommend you do uh your R jobs on kubernetes and the final example and",
    "start": "1447120",
    "end": "1453000"
  },
  {
    "text": "this is probably the most interesting example of the bunch is using Ray service now all this time the examples",
    "start": "1453000",
    "end": "1459039"
  },
  {
    "text": "I've been sending it's been one line of python code so all of you are thinking okay if I have a big python project how",
    "start": "1459039",
    "end": "1464159"
  },
  {
    "text": "do I get that code into my aray cluster this is how you do it right so I'm defining a ray service and inside there",
    "start": "1464159",
    "end": "1469880"
  },
  {
    "text": "is a service config V2 inside that service config V2 the interesting part is this working D which is pointing to a",
    "start": "1469880",
    "end": "1476880"
  },
  {
    "text": "GitHub repository in this case uh the ray project GitHub repository the dotzip file of the GitHub archive if you have",
    "start": "1476880",
    "end": "1485039"
  },
  {
    "text": "this code available in something like a GCS bucket or an S3 bucket you could also point it to that this code also",
    "start": "1485039",
    "end": "1490720"
  },
  {
    "text": "could be in a private repository you just need to have your git uh access token to be able to access this in this case this is public so I don't need",
    "start": "1490720",
    "end": "1496679"
  },
  {
    "text": "anything else once you put this working directory at the runtime this code will be uh unzipped and put in the root of",
    "start": "1496679",
    "end": "1504240"
  },
  {
    "text": "the repository of the uh Ray cluster worker and then you could find wherever",
    "start": "1504240",
    "end": "1509320"
  },
  {
    "text": "your code is using the fully qualified path of that code so in that example the",
    "start": "1509320",
    "end": "1514840"
  },
  {
    "text": "code lives in SLR operator SLC config SL sample slvm SLS serve and the name of",
    "start": "1514840",
    "end": "1521559"
  },
  {
    "text": "the deployment is model so that's how you basically find the import path of the model you're trying to serve so",
    "start": "1521559",
    "end": "1527520"
  },
  {
    "text": "again we are sering in a Lama 3 8 billion parameter model in gke using gpus in this example so you can see if I",
    "start": "1527520",
    "end": "1534159"
  },
  {
    "text": "go down to my worker spec you will see I'm defining that my worker needs to have GPU access right so my head node",
    "start": "1534159",
    "end": "1540919"
  },
  {
    "text": "which is just Distributing the work does not need GPU because it's just finding work finding worker just sending it out",
    "start": "1540919",
    "end": "1546559"
  },
  {
    "text": "but the worker that is going to do the actual work needs to have access to GPU again we can set up Auto scaling limits",
    "start": "1546559",
    "end": "1551640"
  },
  {
    "text": "and other things here to scale up up up and down our workload but let's look at",
    "start": "1551640",
    "end": "1556679"
  },
  {
    "text": "K get service and I should see a service called llama 38b service serve service",
    "start": "1556679",
    "end": "1564440"
  },
  {
    "text": "once this is running I can now I have a I have a Lama 3 that is running there that I can go access to access it it's",
    "start": "1564440",
    "end": "1570039"
  },
  {
    "text": "running on Port 8,000 so I could do okay port forward service llama 3 and expose",
    "start": "1570039",
    "end": "1577919"
  },
  {
    "text": "Port 8,000 and then there is a uh like a Carl command that I can send to get this",
    "start": "1577919",
    "end": "1583679"
  },
  {
    "text": "data and I just copied it here because I don't want to type that I don't trust",
    "start": "1583679",
    "end": "1588720"
  },
  {
    "text": "myself to type that long a command so I'm going to send this and I just passed the output to JQ and the question I had",
    "start": "1588720",
    "end": "1594840"
  },
  {
    "text": "asked is uh you are a helpful assistant uh provide a brief uh sentence descript",
    "start": "1594840",
    "end": "1601279"
  },
  {
    "text": "describing the ray open source project let's see Lama knows Ray or not the answer I got the ray project is open",
    "start": "1601279",
    "end": "1606880"
  },
  {
    "text": "source high performance distributed computing framework developed by data breaks that's wrong",
    "start": "1606880",
    "end": "1611919"
  },
  {
    "text": "uh that supports Python and allows for scalable Computing and data processing they got about 90% right but I don't",
    "start": "1611919",
    "end": "1619279"
  },
  {
    "text": "know in 2024 llm getting 90% right is good enough but the idea is the models do things like there's a suring",
    "start": "1619279",
    "end": "1625880"
  },
  {
    "text": "happening uh databas didn't do ray any skill that worked on Ray so uh let's set the record straight yes um so that is",
    "start": "1625880",
    "end": "1633960"
  },
  {
    "text": "kind of like we're serving now like we saw the ray cluster Ray job and Ray service all those different uh",
    "start": "1633960",
    "end": "1639360"
  },
  {
    "text": "fundamental building blocks of Ray so let's get back to next part and so um um Mory spoke",
    "start": "1639360",
    "end": "1647120"
  },
  {
    "text": "quickly about this idea of using aeral versus uh static clusters so aeral clusters are actually pretty good for",
    "start": "1647120",
    "end": "1652440"
  },
  {
    "text": "reproducibility if you are creating a new cluster for every job you are ensuring that the cluster will be fresh and and if you have a problem you can",
    "start": "1652440",
    "end": "1658559"
  },
  {
    "text": "reproduce it it's great for um you don't need to do any maintenance because the cluster will be created and then it will",
    "start": "1658559",
    "end": "1664240"
  },
  {
    "text": "be deleted right after and um you get better absorbability because you're not running multiple jobs on the same cluster so since you're running only one",
    "start": "1664240",
    "end": "1671240"
  },
  {
    "text": "job you can actually look at what that jobs particularly is doing some of the cons is of course it takes time for that",
    "start": "1671240",
    "end": "1677279"
  },
  {
    "text": "cluster to be created so your startup latency could be big the ray dashboard doesn't have any uh",
    "start": "1677279",
    "end": "1682760"
  },
  {
    "text": "persistent storage so all the logs and metrics can be lost so you have to figure out how to ship them outside kubernetes to store them somewhere if",
    "start": "1682760",
    "end": "1688880"
  },
  {
    "text": "you want to look at them later um now for the static side if you keep persistent R clusters that's actually",
    "start": "1688880",
    "end": "1695640"
  },
  {
    "text": "great because the startup time for workload could be very fast um you potentially do not need to repackage",
    "start": "1695640",
    "end": "1702080"
  },
  {
    "text": "your code with all its dependencies if the cluster already exist and has much much of the dependencies you don't need to send them each time you're sending a",
    "start": "1702080",
    "end": "1708279"
  },
  {
    "text": "job you only send to to need to send the very particular dependencies if you make code changes import new libraries and",
    "start": "1708279",
    "end": "1714960"
  },
  {
    "text": "the ray dashboard can be actually used to track history so you can see how your job have been performing as you are making modifications to it some of the",
    "start": "1714960",
    "end": "1721120"
  },
  {
    "text": "cause um is yeah new dependes can be tricky so you have to figure out what do you have already in the cluster and what we don't have and if the cluster is",
    "start": "1721120",
    "end": "1726799"
  },
  {
    "text": "brought down for maintenance the behavior could be unpredictable so um so that's the side of eal versus static now",
    "start": "1726799",
    "end": "1733840"
  },
  {
    "text": "there are a couple of security considerations you need to keep in mind when you're using Ray first first and most important one is that the ray Epi",
    "start": "1733840",
    "end": "1740080"
  },
  {
    "text": "end point does not have authentication or authorization so in that case you will have to look into whatever your load balancer your cloud provider",
    "start": "1740080",
    "end": "1746799"
  },
  {
    "text": "provides in terms of load balances proxies to be able to implement that the second thing is this running Ray",
    "start": "1746799",
    "end": "1752880"
  },
  {
    "text": "kubernetes is multiple layers and multiple layers means complexity which means troubleshooting can be harder and",
    "start": "1752880",
    "end": "1759600"
  },
  {
    "text": "your attack surface could be big so this is something also that you have to keep in mind but Ray itself or cube Ray is",
    "start": "1759600",
    "end": "1765519"
  },
  {
    "text": "growing uh the project has U quite a lot of uh contributors 140 contributors 100",
    "start": "1765519",
    "end": "1770559"
  },
  {
    "text": "organizations um there are like more than 50 blog posts and at scale there are about 10,000 Ray clusters running uh",
    "start": "1770559",
    "end": "1776760"
  },
  {
    "text": "with about 40,000 pots we're going to briefly talk about two main things that are these are",
    "start": "1776760",
    "end": "1782480"
  },
  {
    "text": "exciting stuff coming to kubernetes um that are going to make Ray even better um uh optimize so Dr stands for dynamic",
    "start": "1782480",
    "end": "1789559"
  },
  {
    "text": "resource allocation and it's a feature that is meant to um solve the problem of",
    "start": "1789559",
    "end": "1794600"
  },
  {
    "text": "um getting gpus and tpus right uh the joke we always make is that if you walk into a VC and you tell them have gpus",
    "start": "1794600",
    "end": "1800480"
  },
  {
    "text": "that's the only word you have to say and they will give you money um uh the other one is in place vpa basically being able",
    "start": "1800480",
    "end": "1806679"
  },
  {
    "text": "to resize uh pods without restarting them this would be great for um Ray because if you you wrong siiz your pods",
    "start": "1806679",
    "end": "1814039"
  },
  {
    "text": "to start with and then you realize later that you need more resources you can just like resize the pods add more CPL",
    "start": "1814039",
    "end": "1819399"
  },
  {
    "text": "memory to it um so it's an in place upgrade Bas yeah the other thing to add about the vpa is when you have like",
    "start": "1819399",
    "end": "1824960"
  },
  {
    "text": "regular workload you kind of know what that workload size is but when you are doing like a distributed workload send",
    "start": "1824960",
    "end": "1830480"
  },
  {
    "text": "to the worker that because like you have like let's say you started with 10 but all of a sudden it to scale to 50 that",
    "start": "1830480",
    "end": "1836240"
  },
  {
    "text": "is not a predefined workload that can come after so if you can resize the worker at runtime that means you don't",
    "start": "1836240",
    "end": "1841360"
  },
  {
    "text": "have to restart the worker you could just like fit more in the same node and fit more work in the same node yeah and",
    "start": "1841360",
    "end": "1848000"
  },
  {
    "text": "the final thing we're going to say again uh again we work for Google so this is the only I think Google slide we're going to talk about we recently",
    "start": "1848000",
    "end": "1853880"
  },
  {
    "text": "announced Ray operator on GK that means installing Ray on GK is just like one click either via your ISC of choice one",
    "start": "1853880",
    "end": "1859960"
  },
  {
    "text": "line of code in your terraform or pumi or if you're using the console is just like one checkbox and we just install",
    "start": "1859960",
    "end": "1865600"
  },
  {
    "text": "and maintain the life cycle of Ray on your behalf for you so if you're using Ray and if you're using gke just uh give",
    "start": "1865600",
    "end": "1871960"
  },
  {
    "text": "it a try I think uh it's going to make your life cycle and life using Ray a lot easier yeah and with that thank you very",
    "start": "1871960",
    "end": "1878600"
  },
  {
    "text": "much for coming to the talk I hope it was useful we would be very happy if you provide us with some feedback this is the first time we did this talk together",
    "start": "1878600",
    "end": "1884240"
  },
  {
    "text": "and actually the first time we talk together on stage so uh yeah just SC QR code give us some feedback and thank you",
    "start": "1884240",
    "end": "1889480"
  },
  {
    "text": "very much yeah and we have about 3 4 minutes is before",
    "start": "1889480",
    "end": "1895919"
  },
  {
    "text": "they kick us out micone microphone is over there if you have any questions please do ask but we are holding you off from lunch I I will not feel bad if you",
    "start": "1895919",
    "end": "1902559"
  },
  {
    "text": "leave for lunch I'll be okay okay thanks guys really helpful so one question non",
    "start": "1902559",
    "end": "1908440"
  },
  {
    "text": "Tech side so the r no using Ray real time so lot of data scientists who are",
    "start": "1908440",
    "end": "1913880"
  },
  {
    "text": "out of college who are not used to that learning curve how do you see the you know using adapting Ray in a who are",
    "start": "1913880",
    "end": "1921880"
  },
  {
    "text": "used to The jup Notebook uhuh it's not it's not pure coding P or Bass P command",
    "start": "1921880",
    "end": "1927519"
  },
  {
    "text": "line so do you see any any so the the that's a great question I think a lot of the the there's a push back of I'm I'm",
    "start": "1927519",
    "end": "1933760"
  },
  {
    "text": "I'm so in love with my notebooks I never can leave um so I think Ray actually a lot of the use cases of R you can just",
    "start": "1933760",
    "end": "1939159"
  },
  {
    "text": "run them through notebook so you can actually never have to leave your notebook uh because it's a python environment as long as it's a python",
    "start": "1939159",
    "end": "1944519"
  },
  {
    "text": "environment is going to just work so I think long term is going to make it easier to productionize your notebooks",
    "start": "1944519",
    "end": "1950639"
  },
  {
    "text": "because if you write the code already in Ray you could just take it and just throw it in a job or a service it's",
    "start": "1950639",
    "end": "1956159"
  },
  {
    "text": "going to I think long term is going to make it easier there's the initial learning curve of like thinking about your problem in the context of task and",
    "start": "1956159",
    "end": "1962720"
  },
  {
    "text": "actors but once you get over that hump your code is all python every environment that runs python can run Ray",
    "start": "1962720",
    "end": "1968240"
  },
  {
    "text": "code so I think you're not it would be much harder if you had to like learn a new language right so I think it's yeah",
    "start": "1968240",
    "end": "1973760"
  },
  {
    "text": "and and all of this running on kubernetes means that you can also run your jupyter notebooks on kubernetes right yeah so thank you no worries thank",
    "start": "1973760",
    "end": "1980200"
  },
  {
    "text": "you hi um for the great talk uh for the development cycle I'm guessing you know",
    "start": "1980200",
    "end": "1985399"
  },
  {
    "text": "I'm D scientist I probably want to run this locally first on a one to two things yeah um have you seen any issues",
    "start": "1985399",
    "end": "1992639"
  },
  {
    "text": "going from running it locally to in a cluster things to be aware of and then secondly other Concepts like caching or",
    "start": "1992639",
    "end": "1999480"
  },
  {
    "text": "retrying an individual task uh in the cluster yeah so Reay has built-in",
    "start": "1999480",
    "end": "2006200"
  },
  {
    "text": "mechanism for like failure like whatever they want to retry another logic and the first question was like what what do we",
    "start": "2006200",
    "end": "2012159"
  },
  {
    "text": "do about like going from local to Cluster setup um so if you do the FML style of work where you define your",
    "start": "2012159",
    "end": "2018480"
  },
  {
    "text": "worker head note and job at the same specification the problems are a lot less because version mismatch right so",
    "start": "2018480",
    "end": "2025200"
  },
  {
    "text": "Ray provides these images called the Ray Ray under Ray project Ray and Ray ml",
    "start": "2025200",
    "end": "2030399"
  },
  {
    "text": "these are the two base images they provide for just the core Ray core and Ray core Plus Cuda and GPU drivers in it",
    "start": "2030399",
    "end": "2036600"
  },
  {
    "text": "right so if you're build building everything as the same thing that means your code and the like the cluster",
    "start": "2036600",
    "end": "2042000"
  },
  {
    "text": "version are the same rate so problems are a lot less when you try to create the static cluster then you have to be a",
    "start": "2042000",
    "end": "2047519"
  },
  {
    "text": "lot more careful about the python you're writing versus the python that like this is as strict as if you use Python 39 and",
    "start": "2047519",
    "end": "2055358"
  },
  {
    "text": "the cluster was running python 310 it's not going to compile and run so there and if it's minor version mismatch like",
    "start": "2055359",
    "end": "2061919"
  },
  {
    "text": "let's say python 3123 versus python 3127 it will give you a warning so there are",
    "start": "2061919",
    "end": "2067440"
  },
  {
    "text": "a lot more strict about python versions because again there's a lot of layers on top because you have python then Ray",
    "start": "2067440",
    "end": "2073358"
  },
  {
    "text": "then like Cuda libraries then you have like nickel and all the other like driver specific things so everything",
    "start": "2073359",
    "end": "2079040"
  },
  {
    "text": "kind of has to have a very tight rope they have to walk yeah and then if you're doing machine learning typically",
    "start": "2079040",
    "end": "2084440"
  },
  {
    "text": "uh both tuning and fine tuning and um and uh training you usually snapshot uh",
    "start": "2084440",
    "end": "2089800"
  },
  {
    "text": "your your your your your model very often so you don't lose all the training work right so that that could help also",
    "start": "2089800",
    "end": "2095679"
  },
  {
    "text": "with recovering from a failure like in The Decorator yeah yeah yeah very much yeah right I have a question about like",
    "start": "2095679",
    "end": "2104119"
  },
  {
    "text": "a reserve and retune so I was wondering like because we know like gpus always getting failures so like how how could",
    "start": "2104119",
    "end": "2110599"
  },
  {
    "text": "run and Reserve handle that yeah again so all the ray libraries are just python",
    "start": "2110599",
    "end": "2115839"
  },
  {
    "text": "libraries so any library that you use like py torch you could basically just wrap py torch in Ray decorators so",
    "start": "2115839",
    "end": "2121560"
  },
  {
    "text": "whatever mechanism TGI or pytorch or like tensor flow would give you all of them just would work in the world of Ray",
    "start": "2121560",
    "end": "2127720"
  },
  {
    "text": "Ray is only doing the work of orchestrating right so if you're using Ray serve or Ray tune uh they have very",
    "start": "2127720",
    "end": "2135119"
  },
  {
    "text": "usual comparability with like P torch or tensor flow but for the most part the ask is not to move everything to Ray the",
    "start": "2135119",
    "end": "2141880"
  },
  {
    "text": "ask mostly is use Ray core and wrap your existing pytorch tensorflow TGI code",
    "start": "2141880",
    "end": "2147839"
  },
  {
    "text": "into Ray constructs yes that makes sense so yeah yeah so in case of failure is there some like Ray roll back functions",
    "start": "2147839",
    "end": "2154960"
  },
  {
    "text": "so Ray itself I don't think has roll back but the idea is if you're using pytorch you already had mechanism to",
    "start": "2154960",
    "end": "2160960"
  },
  {
    "text": "like do checkpointing and roll back in that code Ray doesn't actually invent that will just lets you call those",
    "start": "2160960",
    "end": "2167240"
  },
  {
    "text": "function from Ray orchestrator if that makes sense oh yeah that thank you we we're getting the warning that we need",
    "start": "2167240",
    "end": "2172960"
  },
  {
    "text": "to get off stage um we can we can step down we can just chat with you or if it's a quick question I can just take it",
    "start": "2172960",
    "end": "2178640"
  },
  {
    "text": "before they kick us out yeah I'm just curious about for the ray serve use case",
    "start": "2178640",
    "end": "2183760"
  },
  {
    "text": "where you it's deploying let's say an you know an inference workload you mentioned uh you have to bring your",
    "start": "2183760",
    "end": "2191040"
  },
  {
    "text": "own load balancing uh you know in so that's where kubernetes comes in right so kuber does the load balancing on your",
    "start": "2191040",
    "end": "2196440"
  },
  {
    "text": "be just curious how how you know what determinism there is on the pods that",
    "start": "2196440",
    "end": "2201480"
  },
  {
    "text": "you can use the service Discovery kind of Primitives well so the race the race",
    "start": "2201480",
    "end": "2207040"
  },
  {
    "text": "serve Epi will create a kubernetes service for you so that's how you would do um U How We Do service Discovery and",
    "start": "2207040",
    "end": "2213280"
  },
  {
    "text": "then if you need to expose that to outside the cluster then you will create an Ingress object that points that service basically but do you have to",
    "start": "2213280",
    "end": "2219200"
  },
  {
    "text": "discover it yourself or is it deterministic like based on some attributes that's the name deterministic that's the name name of the service",
    "start": "2219200",
    "end": "2225359"
  },
  {
    "text": "itself okay you can predict it up front before it gets created You can predict how it will look like sounds simple",
    "start": "2225359",
    "end": "2231480"
  },
  {
    "text": "enough yeah right thank you thank you so much",
    "start": "2231480",
    "end": "2235200"
  }
]
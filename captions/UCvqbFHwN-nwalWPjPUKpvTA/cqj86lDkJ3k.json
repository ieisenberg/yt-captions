[
  {
    "start": "0",
    "end": "50000"
  },
  {
    "text": "so hello everyone thank you for joining us today on this session I know it's",
    "start": "160",
    "end": "6000"
  },
  {
    "text": "especially challenging after the lunch break H my name is Patrick H I'm Solutions architect and bluesoft and I'm",
    "start": "6000",
    "end": "13599"
  },
  {
    "text": "here with my colleague Martin uh who is senior software H senior DeVos engineer",
    "start": "13599",
    "end": "20760"
  },
  {
    "text": "in bluesoft uh both of us represent the star boost for AI team so we are",
    "start": "20760",
    "end": "26800"
  },
  {
    "text": "responsible for building Cloud native uh AI development platform for our company",
    "start": "26800",
    "end": "33160"
  },
  {
    "text": "and today uh we would like to share with you our journey and insights on how we",
    "start": "33160",
    "end": "39760"
  },
  {
    "text": "adopted llms from the security perspective of course and we hope that you will find this session informative",
    "start": "39760",
    "end": "46920"
  },
  {
    "text": "and engaging so let's not waste time and let's dive in the agenda for this",
    "start": "46920",
    "end": "52520"
  },
  {
    "start": "50000",
    "end": "84000"
  },
  {
    "text": "session is as follows so we will start with some context uh where we are as a",
    "start": "52520",
    "end": "58079"
  },
  {
    "text": "company in our adoption then we will move through the uh types",
    "start": "58079",
    "end": "63120"
  },
  {
    "text": "of systems The Rock and the multi-agent in the Rock and multi-agent architecture",
    "start": "63120",
    "end": "68439"
  },
  {
    "text": "and the threats which are present in these kind of systems after this we want to share our findings and observations",
    "start": "68439",
    "end": "76159"
  },
  {
    "text": "from the llm security practices uh which we incorporated into our stock uh and of",
    "start": "76159",
    "end": "82159"
  },
  {
    "text": "course uh we will conclude with some future directions H so U as a company we place",
    "start": "82159",
    "end": "90040"
  },
  {
    "text": "ourselves somewhere in the middle yeah so using the generative AI strategy",
    "start": "90040",
    "end": "95799"
  },
  {
    "text": "archetypes from McKenzie we are not the makers yeah so we do not compete with",
    "start": "95799",
    "end": "100840"
  },
  {
    "text": "open AI or anthropic on building the foundational large language models but",
    "start": "100840",
    "end": "106479"
  },
  {
    "text": "also on the other hand we assess that some low code of thef solutions are not",
    "start": "106479",
    "end": "112159"
  },
  {
    "text": "sufficient for our use cases and for use cases of uh our clients so our teams are",
    "start": "112159",
    "end": "118240"
  },
  {
    "start": "117000",
    "end": "130000"
  },
  {
    "text": "mainly focused on building the production ready uh llm based systems",
    "start": "118240",
    "end": "123759"
  },
  {
    "text": "either in this uh Advanced Rock architecture or in the multi-agent",
    "start": "123759",
    "end": "130280"
  },
  {
    "start": "130000",
    "end": "277000"
  },
  {
    "text": "architecture and to address these challenges uh our teams face uh in their",
    "start": "130280",
    "end": "136560"
  },
  {
    "text": "AI development process we have started building the cloud native AI development platform and this is our approach uh to",
    "start": "136560",
    "end": "144879"
  },
  {
    "text": "drive efficient optimal and secure uh AI adoption within our",
    "start": "144879",
    "end": "150440"
  },
  {
    "text": "organizations uh and I want to highlight at this moment here that the this",
    "start": "150440",
    "end": "155840"
  },
  {
    "text": "platform engineering is uh quite popular these days and uh I would not treat this",
    "start": "155840",
    "end": "163319"
  },
  {
    "text": "platform as some you know Silver Bullet yeah which solve all of our problems it's rather a tool a technique uh which",
    "start": "163319",
    "end": "171440"
  },
  {
    "text": "we can use uh to drive uh the AI transformation and the organization",
    "start": "171440",
    "end": "176760"
  },
  {
    "text": "level yeah and uh regarding the architecture of this platform as you see",
    "start": "176760",
    "end": "181879"
  },
  {
    "text": "it could be divided into four layers at the bottom we have the infrastructure layer with our beloved kubernetes then",
    "start": "181879",
    "end": "188840"
  },
  {
    "text": "we have the foundation layer with some pretty standard set of components from cloud native uh W which are responsible",
    "start": "188840",
    "end": "196000"
  },
  {
    "text": "for cic CD observability and others at the top we have the uh platform portal",
    "start": "196000",
    "end": "202120"
  },
  {
    "text": "so it's backstage in our case and this is the way how our teams uh access the",
    "start": "202120",
    "end": "208560"
  },
  {
    "text": "platform and services and the most important layer is this Services layer",
    "start": "208560",
    "end": "214319"
  },
  {
    "text": "so here we try to address the cognitive load which is added because of this new",
    "start": "214319",
    "end": "221159"
  },
  {
    "text": "technology and we uh try to address the needs uh of our teams and as you see uh",
    "start": "221159",
    "end": "228959"
  },
  {
    "text": "there are a couple of services highlighted here like rack provisioning service or experiment and evaluation",
    "start": "228959",
    "end": "235200"
  },
  {
    "text": "Service uh and also rck security scanning service and and um when you",
    "start": "235200",
    "end": "241319"
  },
  {
    "text": "when you create this uh type of services uh you could use different techniques",
    "start": "241319",
    "end": "247000"
  },
  {
    "text": "yeah like such service could be some set of microservices or it could be some uh pipeline or uh some kubernetes operator",
    "start": "247000",
    "end": "255239"
  },
  {
    "text": "the most important thing here is to create the services in mind to to",
    "start": "255239",
    "end": "260400"
  },
  {
    "text": "address the needs of the teams in this particular uh organization and uh with",
    "start": "260400",
    "end": "266360"
  },
  {
    "text": "this context in mind let's dive into the details related to the threats which are",
    "start": "266360",
    "end": "271800"
  },
  {
    "text": "present uh in the systems which we run uh on our platform so um as an",
    "start": "271800",
    "end": "280440"
  },
  {
    "start": "277000",
    "end": "340000"
  },
  {
    "text": "inspiration to delve into these threats uh which are present in our systems we",
    "start": "280440",
    "end": "285680"
  },
  {
    "text": "started with the oasp top 10 for llm applications and we adjusted this threet",
    "start": "285680",
    "end": "292840"
  },
  {
    "text": "model to the our platform reality and our teams reality so as you see uh we",
    "start": "292840",
    "end": "298919"
  },
  {
    "text": "are prettyy exposed for this type of architecture to most of the threets um we replaced the training data",
    "start": "298919",
    "end": "307039"
  },
  {
    "text": "poisoning to knowledge based poisoning because this type of teams they are not uh optimizing their rck architecture by",
    "start": "307039",
    "end": "314800"
  },
  {
    "text": "fine-tuning the models they rather use different techniques H we are also not",
    "start": "314800",
    "end": "320000"
  },
  {
    "text": "exposed to the insecure plug-in design because our teams they access the models via our platform and we have full",
    "start": "320000",
    "end": "326680"
  },
  {
    "text": "control over the models which we are exposing to our teams uh also this type of application is not",
    "start": "326680",
    "end": "333000"
  },
  {
    "text": "exposed to excessive agency uh and the model threat is also not the case for us because of the",
    "start": "333000",
    "end": "339560"
  },
  {
    "text": "reasons I mentioned and the things get Chang when it comes to multi-agent system so this",
    "start": "339560",
    "end": "347000"
  },
  {
    "start": "340000",
    "end": "408000"
  },
  {
    "text": "is the simplified uh model of application which is supporting the",
    "start": "347000",
    "end": "352039"
  },
  {
    "text": "maintenance of the Legacy systems so as you see uh such kind of architecture introduced more threats to the llm Serv",
    "start": "352039",
    "end": "359639"
  },
  {
    "text": "service component which becomes more complex due to additional rooting",
    "start": "359639",
    "end": "365560"
  },
  {
    "text": "topology conversation patterns agent memory and Tool usage uh which is the",
    "start": "365560",
    "end": "372680"
  },
  {
    "text": "overhead uh because of this type of uh architectures and as you see uh now we",
    "start": "372680",
    "end": "378919"
  },
  {
    "text": "are of course we are exposed to excessive agency threat as you see that H our worker agent could communicate",
    "start": "378919",
    "end": "386440"
  },
  {
    "text": "with various systems from Business Systems to it operat system to solve more complex problems but additionally",
    "start": "386440",
    "end": "393840"
  },
  {
    "text": "we would like to highlight the agent uh memory poisoning threat uh which could",
    "start": "393840",
    "end": "400199"
  },
  {
    "text": "be uh especially uh dangerous uh and could impact the behavior of the entire",
    "start": "400199",
    "end": "407440"
  },
  {
    "text": "system and later in this presentation we want to focus on the subset of threats",
    "start": "407440",
    "end": "413120"
  },
  {
    "start": "408000",
    "end": "441000"
  },
  {
    "text": "uh and we want to analyze it from the uh offensive perspective and from the",
    "start": "413120",
    "end": "418680"
  },
  {
    "text": "defensive tooling how we could address these threats uh and we want to uh focus",
    "start": "418680",
    "end": "424960"
  },
  {
    "text": "on the prompt injection insecure output handling sensitive information disclosure and uh over Reliance so we",
    "start": "424960",
    "end": "433639"
  },
  {
    "text": "will delve into these specific areas to share with you some practical insights and hopefully",
    "start": "433639",
    "end": "441280"
  },
  {
    "start": "441000",
    "end": "635000"
  },
  {
    "text": "Solutions uh yes yes llm security practices can be",
    "start": "441280",
    "end": "446639"
  },
  {
    "text": "divided on two groups uh offensive and defensive practices uh offensive",
    "start": "446639",
    "end": "452120"
  },
  {
    "text": "practices focus on identifying vulnerabilities in llm based systems H",
    "start": "452120",
    "end": "458280"
  },
  {
    "text": "garak and gizar are vulnerability scanners yeah and vulnerability scanner",
    "start": "458280",
    "end": "463440"
  },
  {
    "text": "in context of large language models is a crucial tool to identify",
    "start": "463440",
    "end": "469080"
  },
  {
    "text": "weaknesses uh such as generating harmful misleading or inappropriate content H",
    "start": "469080",
    "end": "476560"
  },
  {
    "text": "garak checks LM based systems uh against hundreds of no weakness using",
    "start": "476560",
    "end": "482960"
  },
  {
    "text": "thousands of prompts uh and check if the model uh responds Bron and it's try to",
    "start": "482960",
    "end": "489919"
  },
  {
    "text": "find any failures um big part the big important part of garak is a big",
    "start": "489919",
    "end": "495800"
  },
  {
    "text": "collection of the props each props is designed to identify single kind of the",
    "start": "495800",
    "end": "502120"
  },
  {
    "text": "vulnerability uh Gart is also vulnerability scanner H the difference",
    "start": "502120",
    "end": "507199"
  },
  {
    "text": "between the garak and gizard is that gak is used some static collection of the",
    "start": "507199",
    "end": "513000"
  },
  {
    "text": "propes yeah but the gcard is a mix of uh test predefined prompts and uh prompt",
    "start": "513000",
    "end": "521800"
  },
  {
    "text": "generated by llm System uh so once vulnerability is detected uh in llm uh",
    "start": "521800",
    "end": "529720"
  },
  {
    "text": "system based yeah so the next step is crucial it is identify and securing uh",
    "start": "529720",
    "end": "535360"
  },
  {
    "text": "them as a security professionals yeah is essential not only to detect",
    "start": "535360",
    "end": "540760"
  },
  {
    "text": "vulnerabilities but mitigate them effectively and uh one of the approach",
    "start": "540760",
    "end": "546440"
  },
  {
    "text": "is Nemo gardial by Nidia it is open- Source Tool uh that we can use to create",
    "start": "546440",
    "end": "552480"
  },
  {
    "text": "the programmable guardal uh Guardians is a specific way",
    "start": "552480",
    "end": "557560"
  },
  {
    "text": "to controlling input and output uh for example following predefined uh dialog",
    "start": "557560",
    "end": "564959"
  },
  {
    "text": "paths yeah using particular language style uh so guardias allows to add uh",
    "start": "564959",
    "end": "571640"
  },
  {
    "text": "for the developers these programmable Guardians to LM based",
    "start": "571640",
    "end": "577040"
  },
  {
    "text": "applications uh the next approach is metal Lama to gu guart and it is",
    "start": "577040",
    "end": "582680"
  },
  {
    "text": "llm uh uh this llm that it's uh can be used",
    "start": "582680",
    "end": "588040"
  },
  {
    "text": "to classify input and output from the llm based applications yeah this model",
    "start": "588040",
    "end": "593680"
  },
  {
    "text": "is trained to predict uh safety labels 11 or 13 categories in MLM common",
    "start": "593680",
    "end": "599760"
  },
  {
    "text": "taxonomy of Hazards uh it shows whether the the respon is or outut is uh is safe",
    "start": "599760",
    "end": "608079"
  },
  {
    "text": "or unsafe yeah next is prompt engineering yeah prompt engineering is a process of writing referring and",
    "start": "608079",
    "end": "615640"
  },
  {
    "text": "optimizing uh inputs to encourage generative AI systems uh uh",
    "start": "615640",
    "end": "621959"
  },
  {
    "text": "generative AI system to create specific high quality outputs and model fine",
    "start": "621959",
    "end": "628040"
  },
  {
    "text": "tuning is the process to of adopting predefined model for specific task or",
    "start": "628040",
    "end": "634480"
  },
  {
    "text": "use cases uh we prepar several test scenarios to test rack application and",
    "start": "634480",
    "end": "641079"
  },
  {
    "text": "then assess results yeah the test scenarios involve using different models",
    "start": "641079",
    "end": "646440"
  },
  {
    "text": "starting with open source models like Lama and ending with uh models like GPT",
    "start": "646440",
    "end": "652600"
  },
  {
    "text": "and GPT 40 uh for our experiments we created several rack application in",
    "start": "652600",
    "end": "658399"
  },
  {
    "text": "different configurations uh the application use the uh Tesla",
    "start": "658399",
    "end": "663680"
  },
  {
    "text": "Model free manual as a knowledge base we quickly perform indexing and deployment",
    "start": "663680",
    "end": "669120"
  },
  {
    "text": "of uh our application using our platform it's take 10 minutes here to provision",
    "start": "669120",
    "end": "674480"
  },
  {
    "text": "all necessary resources and application in the various test",
    "start": "674480",
    "end": "680320"
  },
  {
    "start": "678000",
    "end": "734000"
  },
  {
    "text": "scenarios we use different defensive methods and tested the application without a protection layer uh the test",
    "start": "680320",
    "end": "688839"
  },
  {
    "text": "scenario we selected were not random but result from our attempts to secure the",
    "start": "688839",
    "end": "695399"
  },
  {
    "text": "application against vulnerabilities the texted in the previous tests uh or to check the bigger weaker",
    "start": "695399",
    "end": "704000"
  },
  {
    "text": "models yeah how it's look in the other context of the application we tested the",
    "start": "704000",
    "end": "709519"
  },
  {
    "text": "scenarios using the vulnerability scanners G Gart and garak uh we collect",
    "start": "709519",
    "end": "715519"
  },
  {
    "text": "scan results logs yeah and then analyze them uh the aim of our experiments was to",
    "start": "715519",
    "end": "722279"
  },
  {
    "text": "confirm which scner best meets our requirements to check what vulnerabilities our rack application",
    "start": "722279",
    "end": "729279"
  },
  {
    "text": "have and to choose the best defensive method to secure our",
    "start": "729279",
    "end": "734440"
  },
  {
    "start": "734000",
    "end": "771000"
  },
  {
    "text": "applications uh starting from the giz card yes so giz card the important part",
    "start": "734440",
    "end": "742639"
  },
  {
    "text": "of the giz card configuration is scanner configuration yeah because we need to configure the giz card to know which",
    "start": "742639",
    "end": "749279"
  },
  {
    "text": "type of application is going to test it is important to properly configure G card because this integration with the",
    "start": "749279",
    "end": "756680"
  },
  {
    "text": "llm yeah because gards use llm to generate test prompts and also to",
    "start": "756680",
    "end": "762160"
  },
  {
    "text": "analyze the results from the rck application and then create the report it supports several vulnerab categories",
    "start": "762160",
    "end": "769240"
  },
  {
    "text": "we use seven of them and starting with the promp injection attack Vector I",
    "start": "769240",
    "end": "774800"
  },
  {
    "start": "771000",
    "end": "831000"
  },
  {
    "text": "would like to discuss the results of our experiments uh LM prompt injection",
    "start": "774800",
    "end": "780680"
  },
  {
    "text": "involves using specific prompts by bypass filters leading the llm uh to",
    "start": "780680",
    "end": "786600"
  },
  {
    "text": "ignore previous instruction or perform unintended actions uh we notice uh that",
    "start": "786600",
    "end": "792800"
  },
  {
    "text": "using defensive techniques reduce the number of vulnerabilities it's worth nothing that using Carden and prompts",
    "start": "792800",
    "end": "800000"
  },
  {
    "text": "with smaller model like Lama 3 8 billions gives better results than using GPT 40 without any uh defensive approach",
    "start": "800000",
    "end": "809120"
  },
  {
    "text": "it is interest interesting that small model with defensive practices uh",
    "start": "809120",
    "end": "814480"
  },
  {
    "text": "perform better than large model like GPT for all without any defensive techniques",
    "start": "814480",
    "end": "820560"
  },
  {
    "text": "uh in case of application uh with GPT 4 all and Harden and prompt we we are able",
    "start": "820560",
    "end": "827120"
  },
  {
    "text": "to reduce the this vulnerability completely uh the next hallucination at",
    "start": "827120",
    "end": "832920"
  },
  {
    "start": "831000",
    "end": "876000"
  },
  {
    "text": "me information this attacked Vector check if the rack can generate hallucinate not factual output",
    "start": "832920",
    "end": "839720"
  },
  {
    "text": "analyzing the result we see that we are not able to reduce this vulnerability in",
    "start": "839720",
    "end": "845360"
  },
  {
    "text": "all test cases except for the application with GPT 40 and Harden and",
    "start": "845360",
    "end": "850800"
  },
  {
    "text": "prompts which showed resistance to this attack Vector yeah Gard tested",
    "start": "850800",
    "end": "856000"
  },
  {
    "text": "vulnerability to this attack vector by asking two similar questions and then",
    "start": "856000",
    "end": "861600"
  },
  {
    "text": "comparing the response yeah the reports clearly showed that the application",
    "start": "861600",
    "end": "867480"
  },
  {
    "text": "responded differently to to both question yeah and the answer was uh were",
    "start": "867480",
    "end": "874959"
  },
  {
    "text": "inconsistent uh the next yeah is sensitive sensitive information disclosure this attack Vector check if",
    "start": "874959",
    "end": "882000"
  },
  {
    "start": "876000",
    "end": "925000"
  },
  {
    "text": "the model May leak a sensitive and confidental information it's response uh",
    "start": "882000",
    "end": "887959"
  },
  {
    "text": "the scan results uh for this attack Vector show that we manage to reduce the",
    "start": "887959",
    "end": "893600"
  },
  {
    "text": "number of vulnerabilities using the defensive methods we the number of",
    "start": "893600",
    "end": "899040"
  },
  {
    "text": "vulnerabilities decrease from 3 to one H it's also Worth to noting uh noting that",
    "start": "899040",
    "end": "905680"
  },
  {
    "text": "the GPT models showed resistance to these attack vectors yeah and it wasn't",
    "start": "905680",
    "end": "911000"
  },
  {
    "text": "necessary to use these defensive methods to eliminate uh eliminate the",
    "start": "911000",
    "end": "917079"
  },
  {
    "text": "vulnerabilities in case on GPT models this is this indicates the maturity of",
    "start": "917079",
    "end": "923199"
  },
  {
    "text": "uh this these models yeah uh yeah we also use garak to scan",
    "start": "923199",
    "end": "929519"
  },
  {
    "start": "925000",
    "end": "984000"
  },
  {
    "text": "our application and to confirm the results from gizard uh we verified the",
    "start": "929519",
    "end": "935480"
  },
  {
    "text": "results using the done probe uh we check fre test scenarios and gar return",
    "start": "935480",
    "end": "941959"
  },
  {
    "text": "similar results as gizard and it was sufficient uh to verify the reliability",
    "start": "941959",
    "end": "949240"
  },
  {
    "text": "of results from the giz card uh I would like to highlight that we didn't perform",
    "start": "949240",
    "end": "955240"
  },
  {
    "text": "other probes because some performance problem with the gar yeah it's this tool is before released",
    "start": "955240",
    "end": "962800"
  },
  {
    "text": "to version one so the product is new and in our opinion has a big potential to",
    "start": "962800",
    "end": "969000"
  },
  {
    "text": "improve uh but we also found found that repos generated by garak are less red",
    "start": "969000",
    "end": "975160"
  },
  {
    "text": "readable compared to the giz card uh making it more difficult to analyze results and uh uh detect F positives",
    "start": "975160",
    "end": "983639"
  },
  {
    "text": "yeah uh yeah conclusion from scanning yes so uh scanning scanning crack gives",
    "start": "983639",
    "end": "989800"
  },
  {
    "start": "984000",
    "end": "1121000"
  },
  {
    "text": "different results compared to directly scanning the uh model which indicates",
    "start": "989800",
    "end": "995120"
  },
  {
    "text": "that prompt and knowledge base and architecture of application affect the outcomes uh we observe that scanning uh",
    "start": "995120",
    "end": "1003440"
  },
  {
    "text": "application is important and we recommended it uh if we talk about SEC",
    "start": "1003440",
    "end": "1008759"
  },
  {
    "text": "secured vulnerabilities yeah we have uh noticed that we The Prompt engineering",
    "start": "1008759",
    "end": "1014199"
  },
  {
    "text": "yelds the best results however we are not able to address all vulner abilities",
    "start": "1014199",
    "end": "1020240"
  },
  {
    "text": "uh on the slide we have highlighted on in blue the vulnerabilities that we",
    "start": "1020240",
    "end": "1025319"
  },
  {
    "text": "manage to uh address yeah and except of hallucination and misinformation we",
    "start": "1025319",
    "end": "1031280"
  },
  {
    "text": "manage to address them in most test scenarios yeah uh scanning self-hosted",
    "start": "1031280",
    "end": "1036640"
  },
  {
    "text": "model yeah directly scanning um models is essential if we decide to deploy",
    "start": "1036640",
    "end": "1041760"
  },
  {
    "text": "self-hosted models uh models like GPT GPT 40 uh show",
    "start": "1041760",
    "end": "1048240"
  },
  {
    "text": "better resistance to attack vectors in and in our organization we believe that",
    "start": "1048240",
    "end": "1053559"
  },
  {
    "text": "the scanning selfhosted model is more important uh yeah uh small models yeah",
    "start": "1053559",
    "end": "1060880"
  },
  {
    "text": "it's interesting that implementing defensive H security practices uh significantly improve scan",
    "start": "1060880",
    "end": "1068640"
  },
  {
    "text": "results if rack application use smaller models like Lama free 8 billions yeah we",
    "start": "1068640",
    "end": "1074200"
  },
  {
    "text": "also notice that the secured application with Lama free 8 billions gives the",
    "start": "1074200",
    "end": "1080039"
  },
  {
    "text": "better results than application with gbt for all model without any defens",
    "start": "1080039",
    "end": "1085720"
  },
  {
    "text": "defensive methods and uh scan reports yeah so we need to remember the that",
    "start": "1085720",
    "end": "1093039"
  },
  {
    "text": "there are just potential vulnerabilities with the results need be analyzed and false positive filtered out yeah it's",
    "start": "1093039",
    "end": "1100039"
  },
  {
    "text": "worth noting that in case of gizard uh result which we mainly analyzed uh for",
    "start": "1100039",
    "end": "1106120"
  },
  {
    "text": "false positives we found that the scale of force positives change across",
    "start": "1106120",
    "end": "1111440"
  },
  {
    "text": "different test scenarios and it's andren from 20% even to uh 40%",
    "start": "1111440",
    "end": "1120760"
  },
  {
    "text": "yeah uh impact on performance yeah so Nemo Guardians significantly impact on",
    "start": "1120760",
    "end": "1127559"
  },
  {
    "start": "1121000",
    "end": "1254000"
  },
  {
    "text": "the application response time using Guardians is three four time slower than",
    "start": "1127559",
    "end": "1133080"
  },
  {
    "text": "just quaring uh using Clank chain it is not suable solution for application",
    "start": "1133080",
    "end": "1138799"
  },
  {
    "text": "where the response time is critical like chat application however it might be a",
    "start": "1138799",
    "end": "1144080"
  },
  {
    "text": "solution for um multi-agent solution something like this yeah um Lama to guart we it doesn't",
    "start": "1144080",
    "end": "1153440"
  },
  {
    "text": "significantly impact the application response time we observe some increase uh in response time but it is not",
    "start": "1153440",
    "end": "1159840"
  },
  {
    "text": "significant significant uh difference yeah for example our application response in 4.6 seconds and the overhead",
    "start": "1159840",
    "end": "1169799"
  },
  {
    "text": "head from the Llama is 300 milliseconds uh if we analyze response",
    "start": "1169799",
    "end": "1175960"
  },
  {
    "text": "time and application performance prompt engineering achieves the best results uh",
    "start": "1175960",
    "end": "1181679"
  },
  {
    "text": "because this method compared to the different uh defensive methods doesn't",
    "start": "1181679",
    "end": "1187159"
  },
  {
    "text": "add additional time overhead uh promt engineering is the most Tri forat method",
    "start": "1187159",
    "end": "1193840"
  },
  {
    "text": "for the developers because they already doing this it's not necessary to change",
    "start": "1193840",
    "end": "1198960"
  },
  {
    "text": "anything in the code uh and scanner execution time time",
    "start": "1198960",
    "end": "1204039"
  },
  {
    "text": "yeah gak tests take a lot of time yeah because the way how the garak operates",
    "start": "1204039",
    "end": "1209720"
  },
  {
    "text": "yeah even if vulnerability is detected in the first interaction the test is continue car gak use thousand of the",
    "start": "1209720",
    "end": "1216880"
  },
  {
    "text": "prompts so the execution need take time yeah to execute all this thousand of the prompts yeah",
    "start": "1216880",
    "end": "1224200"
  },
  {
    "text": "and for example at a generation prop it take one hour uh done probe it take half hour uh half",
    "start": "1224200",
    "end": "1232640"
  },
  {
    "text": "hour and promp injection probe it take five hours to execute all the all the uh",
    "start": "1232640",
    "end": "1239520"
  },
  {
    "text": "all the prompts yeah if we compare this with giz card which need 1 hour and half",
    "start": "1239520",
    "end": "1246440"
  },
  {
    "text": "to execute all seven test categories this difference in the execution time is",
    "start": "1246440",
    "end": "1252039"
  },
  {
    "text": "very significant and the next slide is about the cost and uh Patrick will",
    "start": "1252039",
    "end": "1257840"
  },
  {
    "start": "1254000",
    "end": "1417000"
  },
  {
    "text": "continue this discussion about this topic yeah and uh present our results",
    "start": "1257840",
    "end": "1263400"
  },
  {
    "text": "yeah so yeah what when it comes to cost the the best answer is it depends yeah",
    "start": "1263400",
    "end": "1270480"
  },
  {
    "text": "so but as you probably expect the the rck with the hardened prompt uh turned",
    "start": "1270480",
    "end": "1275600"
  },
  {
    "text": "out to be the cheapest solution uh however everything could",
    "start": "1275600",
    "end": "1281279"
  },
  {
    "text": "change uh at scale and we need to be aware of it uh so after we measured for",
    "start": "1281279",
    "end": "1286720"
  },
  {
    "text": "example the average prompt to can usage before and after prompt hardening and",
    "start": "1286720",
    "end": "1292400"
  },
  {
    "text": "for example if we consider 100K requests uh toward GPT 40 model the result of",
    "start": "1292400",
    "end": "1299120"
  },
  {
    "text": "this uh defensive technique H could cost us $2,400 yeah uh then we have another",
    "start": "1299120",
    "end": "1307000"
  },
  {
    "text": "defensive technique uh rock with lamag guard 2 so here you need to consider the cost of running this model on your",
    "start": "1307000",
    "end": "1314159"
  },
  {
    "text": "infrastructure in our case it's more than $4 per hour and we without any",
    "start": "1314159",
    "end": "1319200"
  },
  {
    "text": "optimization it could cost $3,000 per month of course we advise to do some",
    "start": "1319200",
    "end": "1325440"
  },
  {
    "text": "optimization uh and then we have rack with neog guardians so here without uh",
    "start": "1325440",
    "end": "1330640"
  },
  {
    "text": "any surprises uh we identified like marching sight and it was also stated in the paper uh that adding this defensive",
    "start": "1330640",
    "end": "1338640"
  },
  {
    "text": "technique uh multiplies the time and the cost by free so again for 100 tokens",
    "start": "1338640",
    "end": "1345799"
  },
  {
    "text": "100K tokens and GPT 40 uh such defensive method uh could sum up to",
    "start": "1345799",
    "end": "1353720"
  },
  {
    "text": "$3,600 um also we need to consider the cost of the scan so the giz card full",
    "start": "1354000",
    "end": "1361159"
  },
  {
    "text": "scan uh generates around 360 requests for our configuration to the application",
    "start": "1361159",
    "end": "1367760"
  },
  {
    "text": "with average prompt usage and uh with average uh prompt tokens and completion",
    "start": "1367760",
    "end": "1374960"
  },
  {
    "text": "tokens which are mentioned here and with the gp40 such single scan costs for uh",
    "start": "1374960",
    "end": "1380919"
  },
  {
    "text": "more than $4 uh and also we need to uh be aware about the internals of this of",
    "start": "1380919",
    "end": "1387039"
  },
  {
    "text": "this scanner and that it is using the llm under the hood which adds additionally half of the dollar and also",
    "start": "1387039",
    "end": "1395039"
  },
  {
    "text": "like Marchin said the the garak single scan uh if you configure it only for",
    "start": "1395039",
    "end": "1400159"
  },
  {
    "text": "couple of uh categories it generates thousands of requests uh to application",
    "start": "1400159",
    "end": "1405960"
  },
  {
    "text": "which could uh end up with millions of prompt tokens and millions of completion",
    "start": "1405960",
    "end": "1411159"
  },
  {
    "text": "tokens so the cost of such single scan could vary between couple of dollars to",
    "start": "1411159",
    "end": "1416679"
  },
  {
    "text": "uh even doen of dollars uh what are the overall conclusions from the tools and",
    "start": "1416679",
    "end": "1422600"
  },
  {
    "start": "1417000",
    "end": "1608000"
  },
  {
    "text": "techniques we used so first the scanner stability H we had this issues with",
    "start": "1422600",
    "end": "1428200"
  },
  {
    "text": "garak but as Marchin said it's at early stage and also I recommend the paper uh",
    "start": "1428200",
    "end": "1435400"
  },
  {
    "text": "official paper uh where the garak is introduced it was published like 9 days",
    "start": "1435400",
    "end": "1440760"
  },
  {
    "text": "ago I I really recommend to to read it um and yeah even despite the fact that",
    "start": "1440760",
    "end": "1446520"
  },
  {
    "text": "we run this scanner next to our application on kubernetes cluster using",
    "start": "1446520",
    "end": "1451600"
  },
  {
    "text": "kubernetes internal networking we still faced some some issues but we hope uh",
    "start": "1451600",
    "end": "1456760"
  },
  {
    "text": "they will be solved soon uh reputability of the scans uh we need to be aware H",
    "start": "1456760",
    "end": "1463039"
  },
  {
    "text": "how these scanners are created yeah so if for example such scanner like a giz card if it is using the large language",
    "start": "1463039",
    "end": "1470039"
  },
  {
    "text": "model under the hood it also poses some risks that the scan results could give",
    "start": "1470039",
    "end": "1475399"
  },
  {
    "text": "us non deterministic results because if it is using some non-deterministic model",
    "start": "1475399",
    "end": "1480559"
  },
  {
    "text": "under the hood yeah however our tests indicate that uh we got this reprod",
    "start": "1480559",
    "end": "1487159"
  },
  {
    "text": "reproducibility uh between the scans however we want to highlight it and",
    "start": "1487159",
    "end": "1492399"
  },
  {
    "text": "again it could change uh on a large scale with different configuration then we have the and agent",
    "start": "1492399",
    "end": "1499240"
  },
  {
    "text": "security scanning so of course we advise even despite these small problems uh it",
    "start": "1499240",
    "end": "1504919"
  },
  {
    "text": "scanning of the applications with the shift left security practices in mind",
    "start": "1504919",
    "end": "1510360"
  },
  {
    "text": "it's really helpful uh and speeds up the vulnerability detection process compared",
    "start": "1510360",
    "end": "1515600"
  },
  {
    "text": "to to some manual tests then we have the ovas top 10 for llm application so we uh we assume that",
    "start": "1515600",
    "end": "1524559"
  },
  {
    "text": "it is really good starting point and we uh we advise you to to to use it before",
    "start": "1524559",
    "end": "1530720"
  },
  {
    "text": "you for example move forward to some other topics like AI supply chain",
    "start": "1530720",
    "end": "1536120"
  },
  {
    "text": "security H then the proprietary models versus open source models so as you saw",
    "start": "1536120",
    "end": "1541760"
  },
  {
    "text": "our tests indicate that the proprietary models are quite well secured do uh we",
    "start": "1541760",
    "end": "1547480"
  },
  {
    "text": "strongly advise to scan the open- source models if you decide to host these",
    "start": "1547480",
    "end": "1552720"
  },
  {
    "text": "models on your inference engine on your infrastructure it would be really a it",
    "start": "1552720",
    "end": "1558480"
  },
  {
    "text": "would be really nice to know what are the risks when it comes to these models",
    "start": "1558480",
    "end": "1564279"
  },
  {
    "text": "and what is their overall uh security posture and the production Readiness uh",
    "start": "1564279",
    "end": "1571200"
  },
  {
    "text": "some of these defensive techniques like this uh Nvidia neog Guardians they could",
    "start": "1571200",
    "end": "1576760"
  },
  {
    "text": "be really hard to apply in in user facing systems so the multiplication of the costs by by three and multiplication",
    "start": "1576760",
    "end": "1584200"
  },
  {
    "text": "of the time h of course from the perspective of the delivery teams and from the perspective of the business it",
    "start": "1584200",
    "end": "1590039"
  },
  {
    "text": "could be hard to accept uh and also we have the there is also lack of streaming",
    "start": "1590039",
    "end": "1596559"
  },
  {
    "text": "support uh in this in this library and our teams and apps uh particularly they",
    "start": "1596559",
    "end": "1603039"
  },
  {
    "text": "are using the streaming uh for to ex to improve the user experience so for",
    "start": "1603039",
    "end": "1609880"
  },
  {
    "start": "1608000",
    "end": "1717000"
  },
  {
    "text": "future directions uh we see from the perspective of our platform uh and our",
    "start": "1609880",
    "end": "1615480"
  },
  {
    "text": "teams this prompt hardening uh sounds really nice and easy but again the scale",
    "start": "1615480",
    "end": "1622360"
  },
  {
    "text": "yeah so if you consider the number of models the number of applications the number of teams H some kind of",
    "start": "1622360",
    "end": "1630919"
  },
  {
    "text": "centralized llm Gateway with the on the flight promt enhancement or at least",
    "start": "1630919",
    "end": "1636240"
  },
  {
    "text": "weak prom detection could be worth to invest from the organization uh",
    "start": "1636240",
    "end": "1641520"
  },
  {
    "text": "perspective also these llm agnostic methods um they sound promising uh but",
    "start": "1641520",
    "end": "1648200"
  },
  {
    "text": "as you saw they have some limitations H so as a team uh probably we would like",
    "start": "1648200",
    "end": "1654360"
  },
  {
    "text": "to explore the fine-tuning options of the models so instead of adding some additional components to the model we",
    "start": "1654360",
    "end": "1661440"
  },
  {
    "text": "would rather try to uh change the behave how the model uh",
    "start": "1661440",
    "end": "1666840"
  },
  {
    "text": "behaves uh and last but not least the people aspect yeah so it's really really",
    "start": "1666840",
    "end": "1672360"
  },
  {
    "text": "important to increase awareness in your AI de delivery teams because you so that",
    "start": "1672360",
    "end": "1678720"
  },
  {
    "text": "this pace of innovation is rapidly growing and uh I'm not sure if we will",
    "start": "1678720",
    "end": "1685240"
  },
  {
    "text": "catch up from the security perspective but at least we need to make these AI",
    "start": "1685240",
    "end": "1690600"
  },
  {
    "text": "delivery teams and your uh R&D teams aware of the threats which are present",
    "start": "1690600",
    "end": "1696360"
  },
  {
    "text": "in in this uh in their applications and if it is possible uh we plan to do it we",
    "start": "1696360",
    "end": "1702480"
  },
  {
    "text": "would like to expose uh such uh service which will abstract the way how the",
    "start": "1702480",
    "end": "1707600"
  },
  {
    "text": "scans uh are doing how to SC scan the application and um and give them such uh",
    "start": "1707600",
    "end": "1717200"
  },
  {
    "start": "1717000",
    "end": "2219000"
  },
  {
    "text": "option okay so thank you for your attention we encourage you to leave us",
    "start": "1717200",
    "end": "1722919"
  },
  {
    "text": "the feedback because it was our first time presenting at such conference so it is very valuable at the beginning uh and",
    "start": "1722919",
    "end": "1731200"
  },
  {
    "text": "uh now we are happy to answer your questions or also you can catch UPS on the hallway if you want to exchange some",
    "start": "1731200",
    "end": "1738799"
  },
  {
    "text": "experiences and ideas so thank [Applause]",
    "start": "1738799",
    "end": "1750439"
  },
  {
    "text": "you thank you very much for the presentation I really like it it a lot of very useful information you should be",
    "start": "1754880",
    "end": "1761640"
  },
  {
    "text": "proud uh I have a couple of questions they may be tricky and sorry about that it's just that I I see that know so much",
    "start": "1761640",
    "end": "1768760"
  },
  {
    "text": "as you may be able to help me H when you were showing your architecture you have a multi-agent examples and you're also",
    "start": "1768760",
    "end": "1775640"
  },
  {
    "text": "mentioning rack are you using rack with multi-agents in case you are you are testing or this is for example the way",
    "start": "1775640",
    "end": "1783120"
  },
  {
    "text": "how I'm trying to categorize these teams in their advancement so for example in this uh diagram with the simple rck I",
    "start": "1783120",
    "end": "1791279"
  },
  {
    "text": "assume that okay this is the simple chart application which is using the knowledge base and the large language",
    "start": "1791279",
    "end": "1797440"
  },
  {
    "text": "model to answer the the questions to this knowledge base and um I try to",
    "start": "1797440",
    "end": "1803360"
  },
  {
    "text": "differentiate it compared to the applications which really interacts with",
    "start": "1803360",
    "end": "1808840"
  },
  {
    "text": "some other systems in an autonomous Manner and uh yeah as you see it's it",
    "start": "1808840",
    "end": "1815240"
  },
  {
    "text": "could pose some more risks and there are different uh Frameworks which could be",
    "start": "1815240",
    "end": "1820960"
  },
  {
    "text": "used for this multiagent architectures the most popular is L chain there is",
    "start": "1820960",
    "end": "1826080"
  },
  {
    "text": "also the uh Lama index has also this option and our teams I",
    "start": "1826080",
    "end": "1831640"
  },
  {
    "text": "think they are also using the autogen framework from Microsoft research uh but",
    "start": "1831640",
    "end": "1837679"
  },
  {
    "text": "you see that these Solutions are also let's say at the early stage of their development and you see that I somehow",
    "start": "1837679",
    "end": "1844240"
  },
  {
    "text": "try to visualiz visualize that there are multiple agents you need to consider",
    "start": "1844240",
    "end": "1849880"
  },
  {
    "text": "this communication patterns between them but from the application perspective it's like one service so we do not uh",
    "start": "1849880",
    "end": "1856240"
  },
  {
    "text": "it's hard to have some visib ility into how these agents are communicating",
    "start": "1856240",
    "end": "1862639"
  },
  {
    "text": "reasoning and yeah it's some challenge which we will need to face okay thank",
    "start": "1862639",
    "end": "1868440"
  },
  {
    "text": "you and uh another question uh while using gak that by the way costed me $70",
    "start": "1868440",
    "end": "1874279"
  },
  {
    "text": "I think to to use it against GPT 3.5 uh you find that always there are",
    "start": "1874279",
    "end": "1880880"
  },
  {
    "text": "test that passes and some doesn't pass and you can compare let's say different versions of models or run but how do you",
    "start": "1880880",
    "end": "1890200"
  },
  {
    "text": "decide when something is good enough or not good enough what's uh some tips for a strategy there you mean scanning the",
    "start": "1890200",
    "end": "1897519"
  },
  {
    "text": "models or the L application yes so yes some of the propes are more important",
    "start": "1897519",
    "end": "1903880"
  },
  {
    "text": "some some of them are less important yeah it's context of the application that work here I mean the application",
    "start": "1903880",
    "end": "1911480"
  },
  {
    "text": "what is a goal of this application yeah so sometimes the prompt injection yeah of course is very important to to check",
    "start": "1911480",
    "end": "1918679"
  },
  {
    "text": "if what is a vulnerability status of this application this Vector attack yeah",
    "start": "1918679",
    "end": "1924600"
  },
  {
    "text": "but of course it is the the list of the props is longer yeah and of course it's",
    "start": "1924600",
    "end": "1930159"
  },
  {
    "text": "something other other props are also important yeah I'm not sure if I answered the correctly on your questions",
    "start": "1930159",
    "end": "1937200"
  },
  {
    "text": "yeah because it depends of the application yeah so yeah also also as far as also as far as I know this both",
    "start": "1937200",
    "end": "1944919"
  },
  {
    "text": "of these scanners they are already connected to the AI vulnerability data",
    "start": "1944919",
    "end": "1950519"
  },
  {
    "text": "database so something like the cve data database so and probably this",
    "start": "1950519",
    "end": "1955679"
  },
  {
    "text": "integration will be much deeper and this database will be growing so it could be",
    "start": "1955679",
    "end": "1960760"
  },
  {
    "text": "also some uh some some some indication which we how particular finding is",
    "start": "1960760",
    "end": "1968240"
  },
  {
    "text": "critical yeah thank you thank you very much for your answers",
    "start": "1968240",
    "end": "1973919"
  },
  {
    "text": "yeah thanks a lot for posting all the all the numbers I thought that was great latency numbers and the and the actual",
    "start": "1984559",
    "end": "1989600"
  },
  {
    "text": "dollar numbers super interesting um I think when you're doing the",
    "start": "1989600",
    "end": "1994679"
  },
  {
    "text": "filtering it might even be more expensive than what you said because you might want to filter on each of the",
    "start": "1994679",
    "end": "2000279"
  },
  {
    "text": "agents as well too so if the agent is like going and collecting some information it could possibly be tricked",
    "start": "2000279",
    "end": "2006600"
  },
  {
    "text": "into like encoding that information in a way that you're sort of like later filtering might not catch so you might",
    "start": "2006600",
    "end": "2012559"
  },
  {
    "text": "actually have to filter input and output of the agents uh as well and so that",
    "start": "2012559",
    "end": "2017679"
  },
  {
    "text": "even more latency and even more cost if you want to do that uh as well I don't know if you like thought about that at",
    "start": "2017679",
    "end": "2022760"
  },
  {
    "text": "all or yeah I I used for example I created this let's say this this this",
    "start": "2022760",
    "end": "2028440"
  },
  {
    "text": "cost analysis based on the on the rack solution but in the with the agents",
    "start": "2028440",
    "end": "2033480"
  },
  {
    "text": "solution as you mentioned you have multiple of agents and each of them could also use different model so also",
    "start": "2033480",
    "end": "2041600"
  },
  {
    "text": "like we are on the security conference but also what I advise is to uh really",
    "start": "2041600",
    "end": "2047200"
  },
  {
    "text": "invest into the observability solution because without the observability I would not know how many prompt tokens",
    "start": "2047200",
    "end": "2054440"
  },
  {
    "text": "each of these agents are using how many completion tokens etc etc so uh it's",
    "start": "2054440",
    "end": "2060040"
  },
  {
    "text": "also Worth to mention if we are here to uh to have such capability on your uh on",
    "start": "2060040",
    "end": "2066960"
  },
  {
    "text": "your side yeah and I was wondering too like I think the generally that um people",
    "start": "2066960",
    "end": "2072679"
  },
  {
    "text": "building models have started gaming the benchmarks out there like so when the",
    "start": "2072679",
    "end": "2077839"
  },
  {
    "text": "benchmarks are publicly accessible data sets then everyone who's releasing a new model you know really tunes for those",
    "start": "2077839",
    "end": "2084000"
  },
  {
    "text": "benchmarks and so now they're kind of worthless and so I feel like exactly the same thing will happen with gak here and",
    "start": "2084000",
    "end": "2090398"
  },
  {
    "text": "any other sort of like public attack data set so I suspect that's why your 40",
    "start": "2090399",
    "end": "2095839"
  },
  {
    "text": "was like basically zero is that um anyone who's like going to release a model probably just train against this",
    "start": "2095839",
    "end": "2101800"
  },
  {
    "text": "and I'm not sure I do you think it's going to give you a good signal about whether it's actually defending against these attacks or just defending against",
    "start": "2101800",
    "end": "2108320"
  },
  {
    "text": "the known Public Training set also some some some place to explore some some",
    "start": "2108320",
    "end": "2113760"
  },
  {
    "text": "some some aspect is uh do we really need to use the GPT 40 for for these scans",
    "start": "2113760",
    "end": "2121040"
  },
  {
    "text": "maybe we could use some cheaper model you see that it was easy to calculate the overall cost when you use the",
    "start": "2121040",
    "end": "2128000"
  },
  {
    "text": "proprietary models and we have this uh price uh pricing for them but at some",
    "start": "2128000",
    "end": "2134680"
  },
  {
    "text": "point again that's why it's worth to have this monitoring at some point you can assess that hm if I have such uh",
    "start": "2134680",
    "end": "2142880"
  },
  {
    "text": "amount of traffic it would be much cheaper to run your own model on your infrastructure and it could cost $5 for",
    "start": "2142880",
    "end": "2150680"
  },
  {
    "text": "hour and you can really utilize this model compared to to some external API",
    "start": "2150680",
    "end": "2155720"
  },
  {
    "text": "so they are really really different aspects how you can combine even these scanners with the models also uh I WR WR",
    "start": "2155720",
    "end": "2164440"
  },
  {
    "text": "in this paper from the garak that they also introduced some module which is",
    "start": "2164440",
    "end": "2170000"
  },
  {
    "text": "using some let's say malicious model for generating and trying to bypass uh the",
    "start": "2170000",
    "end": "2175760"
  },
  {
    "text": "your application so again you need to have this observability to know how such scanner uh how such how many dollars",
    "start": "2175760",
    "end": "2183359"
  },
  {
    "text": "such scan could cost yeah",
    "start": "2183359",
    "end": "2189559"
  },
  {
    "text": "okay I think we need to finish and leave five minutes to uh to change so once",
    "start": "2190720",
    "end": "2198520"
  },
  {
    "text": "again thanks a lot and we will be here today tomorrow and day after so you can",
    "start": "2198520",
    "end": "2204400"
  },
  {
    "text": "you can reach us and uh and and talk to us so thanks pleas reaching us us if you",
    "start": "2204400",
    "end": "2210000"
  },
  {
    "text": "know if you want yes so we waiting for you to answer for your questions yeah so thank you guys thank you",
    "start": "2210000",
    "end": "2218838"
  }
]
[
  {
    "text": "anyway so welcome to an update on open metrics uh if you could close it oh",
    "start": "0",
    "end": "5880"
  },
  {
    "text": "perfect so um how we structure this is relatively easy",
    "start": "5880",
    "end": "11160"
  },
  {
    "text": "we do a speed run through the history for those who don't know and then we we come to the current state",
    "start": "11160",
    "end": "17279"
  },
  {
    "text": "and then we go towards the future at the end of we have a room for questions uh Cayman is going to run around so looking",
    "start": "17279",
    "end": "24240"
  },
  {
    "text": "at at observability data um historically you had basically one",
    "start": "24240",
    "end": "30000"
  },
  {
    "text": "standard in this space which is SNMP any one of you who's ever dealt with networks is probably",
    "start": "30000",
    "end": "35880"
  },
  {
    "text": "familiar with this there is a little bit of a lot of love-hate relationships",
    "start": "35880",
    "end": "41520"
  },
  {
    "text": "and one of my major pain points with SNMP is actually that it's based on asn1",
    "start": "41520",
    "end": "47579"
  },
  {
    "text": "which is like super old seven bit encoding highly efficient and absolute mess to get right and it's really really",
    "start": "47579",
    "end": "54420"
  },
  {
    "text": "really I see people laughing yeah it's really a mess and it's kind of risky it's often chatty and slow uh oftentimes",
    "start": "54420",
    "end": "60960"
  },
  {
    "text": "interfaces are hard to implement like yes you can walk through them but it's it's really inconvenient",
    "start": "60960",
    "end": "67560"
  },
  {
    "text": "the data models are vastly different between vendors sometimes even between just versions of software and the thing",
    "start": "67560",
    "end": "76320"
  },
  {
    "text": "about hierarchical data sets is it almost never fits your needs because like if you have",
    "start": "76320",
    "end": "81540"
  },
  {
    "text": "region data center customer and you want to group by customer congratulations your your data is wrong",
    "start": "81540",
    "end": "88259"
  },
  {
    "text": "so those are just pain points which which existed before Prometheus",
    "start": "88259",
    "end": "93840"
  },
  {
    "text": "after Prometheus it is the de facto standard anyone in this audience who is",
    "start": "93840",
    "end": "99900"
  },
  {
    "text": "is using kubernetes is very likely also using Prometheus or something within the",
    "start": "99900",
    "end": "105180"
  },
  {
    "text": "Prometheus family of course else you're going to have a really bad time with the kubernetes",
    "start": "105180",
    "end": "110340"
  },
  {
    "text": "the same is true for the Prometheus Exposition format that it also became this de facto standard but like not a",
    "start": "110340",
    "end": "116159"
  },
  {
    "text": "real standard we and I'm speaking as a Prometheus team member here and also there's quite a few",
    "start": "116159",
    "end": "122040"
  },
  {
    "text": "up front um there was an episode explosion over the years of compatible endpoints with",
    "start": "122040",
    "end": "128880"
  },
  {
    "text": "literally hundreds of thousands of installations of Prometheus alone with literally millions probably tens of",
    "start": "128880",
    "end": "135360"
  },
  {
    "text": "millions because the slide is two years old tens of millions of users who are who",
    "start": "135360",
    "end": "141660"
  },
  {
    "text": "are using these these formats directly or indirectly every single day to keep",
    "start": "141660",
    "end": "147060"
  },
  {
    "text": "their stuff running and we have standard exporters we have standard libraries in particular the go",
    "start": "147060",
    "end": "154319"
  },
  {
    "text": "library is one of the most goal libraries on Earth so there is substantial access success but yet again",
    "start": "154319",
    "end": "160319"
  },
  {
    "text": "this is no official standard and yeah label sets I mean I don't have to convince your labels are better than",
    "start": "160319",
    "end": "166019"
  },
  {
    "text": "hierarchical data there's also some politics involved",
    "start": "166019",
    "end": "171440"
  },
  {
    "text": "uh in particular in former times I mean cncf is getting bigger and bigger every year comparing this to 2016 the first",
    "start": "171440",
    "end": "179040"
  },
  {
    "text": "Cloud native con this is awesome What's Happening Here um but still a lot of vendors and",
    "start": "179040",
    "end": "184140"
  },
  {
    "text": "projects were very very torn on should they actually adopt something which has a different name this thing called",
    "start": "184140",
    "end": "189780"
  },
  {
    "text": "Prometheus and it's gotten better and better over the years but still there is some some smell attached to a single",
    "start": "189780",
    "end": "196140"
  },
  {
    "text": "thing in particular back then a lot of traditional vendors they just respect",
    "start": "196140",
    "end": "201239"
  },
  {
    "text": "standards like you write it down you say this is the specification implement this and you're going to be fine and that makes a lot of conversations easier",
    "start": "201239",
    "end": "209099"
  },
  {
    "text": "and obviously we wanted to reuse the complete installed base of of Prometheus we didn't want to have something which",
    "start": "209099",
    "end": "215400"
  },
  {
    "text": "which diverges too much because else you split the community and that that's going to hurt every single person you",
    "start": "215400",
    "end": "220739"
  },
  {
    "text": "need to maintain long-term long-term stability and long-term compatibility",
    "start": "220739",
    "end": "225840"
  },
  {
    "text": "so many many different companies uh chipped in with making this happen and the result is an actually neutral",
    "start": "225840",
    "end": "232500"
  },
  {
    "text": "standard like there are several things in there which Prometheus didn't even really need but which others needed in",
    "start": "232500",
    "end": "238019"
  },
  {
    "text": "particular like Google with the underscore started for their Monarch installations these are things which",
    "start": "238019",
    "end": "243480"
  },
  {
    "text": "aren't there on purpose to to have a better general standard yeah this is the shout out to uh to the",
    "start": "243480",
    "end": "251459"
  },
  {
    "text": "Core Group uh I'm here alone today but um yeah those are the people who actually made things happen",
    "start": "251459",
    "end": "258859"
  },
  {
    "text": "so what does this mean for you if you're using Prometheus Exposition format and there's still quite some",
    "start": "259199",
    "end": "265199"
  },
  {
    "text": "large installations which do this and that's completely fine it is largely the same and again this is on purpose",
    "start": "265199",
    "end": "272520"
  },
  {
    "text": "for quite some time most of you in this room have probably already been using open metrics without even realizing it",
    "start": "272520",
    "end": "279300"
  },
  {
    "text": "or without caring about it because it just keeps working because we spent so much time in in",
    "start": "279300",
    "end": "284880"
  },
  {
    "text": "making it working we see a little bit of the of the of the blips uh in a few but by and large things just work",
    "start": "284880",
    "end": "293840"
  },
  {
    "text": "there are breaking changes you need an underscore total if you have a counter and",
    "start": "295380",
    "end": "300660"
  },
  {
    "text": "um sometimes there are collisions the libraries which have migrated handle",
    "start": "300660",
    "end": "306600"
  },
  {
    "text": "this transparently for you but if there is a naming Collision obviously you you can't do much underscore total at the",
    "start": "306600",
    "end": "312600"
  },
  {
    "text": "end was already an anti-pattern for non-counters in in standard Prometheus so anything who did who did things by",
    "start": "312600",
    "end": "319800"
  },
  {
    "text": "the book does not run into this issue but the fact is there's a lot of people or there are a few people who ran in",
    "start": "319800",
    "end": "326280"
  },
  {
    "text": "there and the other thing is that timestamps are now in seconds of course one of the things which are really really hard in Prometheus is to always",
    "start": "326280",
    "end": "332759"
  },
  {
    "text": "uh have base units so some of those non-obvious things",
    "start": "332759",
    "end": "338039"
  },
  {
    "text": "which happens if you just count Joule as a counter as a measure of how much energy you use",
    "start": "338039",
    "end": "343800"
  },
  {
    "text": "just by putting just by putting a Time component onto this this turns automatically in Watts",
    "start": "343800",
    "end": "349500"
  },
  {
    "text": "just because that's how the SE system is designed and all the physicists like years and years ago put a lot of effort",
    "start": "349500",
    "end": "355560"
  },
  {
    "text": "into into making those those different units really seamless and and transposable between each other and",
    "start": "355560",
    "end": "362520"
  },
  {
    "text": "that's why we believe so strongly in base units and that's why we made this change and don't have milliseconds anymore",
    "start": "362520",
    "end": "369320"
  },
  {
    "text": "there's also a ton of cleanups relative to uh to the premises Exposition format",
    "start": "369419",
    "end": "374580"
  },
  {
    "text": "it's a lot cleaner it's a lot tighter um with permitted Exposition format you can do more or less endless amounts of",
    "start": "374580",
    "end": "381120"
  },
  {
    "text": "white space you can't anymore you see if you actually have completed a scrape",
    "start": "381120",
    "end": "387000"
  },
  {
    "text": "um you can do another second resolution if you need this Prometheus doesn't support it but you can do it through open metrics again one of those things",
    "start": "387000",
    "end": "393360"
  },
  {
    "text": "where open metrics goes beyond what Prometheus can do it's all 64-bit as in Prometheus we have",
    "start": "393360",
    "end": "400319"
  },
  {
    "text": "a new metadata type for for the unit underscore created I already mentioned",
    "start": "400319",
    "end": "405419"
  },
  {
    "text": "this and we're going to see it in a second to last slide we support push explicitly in open",
    "start": "405419",
    "end": "411120"
  },
  {
    "text": "metrics even though Prometheus again does not really support it I mean there's been work on this and and it's",
    "start": "411120",
    "end": "417240"
  },
  {
    "text": "getting there where in particular with remote right you can do a lot of stuff um but open metrics again goes beyond",
    "start": "417240",
    "end": "423960"
  },
  {
    "text": "what Prometheus can do here and the thing the other thing is one of the really nice things I don't know if you",
    "start": "423960",
    "end": "430740"
  },
  {
    "text": "saw the documentary about about Prometheus which was aired on Tuesday",
    "start": "430740",
    "end": "436680"
  },
  {
    "text": "um that's also a point there where just the ability to connect to an endpoint and read this with your web browser is",
    "start": "436680",
    "end": "442319"
  },
  {
    "text": "extremely powerful which is why we mandate that this is being carried forward so people can easily debug",
    "start": "442319",
    "end": "449639"
  },
  {
    "text": "this is the the one big highlight feature um",
    "start": "449639",
    "end": "455099"
  },
  {
    "text": "if you don't know what exemplars are so when many many moons ago when when I met",
    "start": "455099",
    "end": "461759"
  },
  {
    "text": "with a few people at Google and we were considering to merge open sensors with",
    "start": "461759",
    "end": "466800"
  },
  {
    "text": "open metrics way way back they mentioned that for them searching for traces",
    "start": "466800",
    "end": "471900"
  },
  {
    "text": "didn't scale and when Google tells you that searching for something doesn't scale you probably",
    "start": "471900",
    "end": "477000"
  },
  {
    "text": "better listen and figure out why because they probably did the math on this one um and the thing is there was just too",
    "start": "477000",
    "end": "482580"
  },
  {
    "text": "much so um the the approach here is you have your label sets on your on your metrics",
    "start": "482580",
    "end": "489840"
  },
  {
    "text": "or with Loki or even on your on your logs and the rest is just an idea an ID which",
    "start": "489840",
    "end": "495900"
  },
  {
    "text": "can point to a trace which can provide to a span which can point to both but that's it and then you can use this to",
    "start": "495900",
    "end": "501960"
  },
  {
    "text": "look up that specific Trace directly which means you don't have this thing",
    "start": "501960",
    "end": "507180"
  },
  {
    "text": "where you sample a lot of data away and you can't jump into your traces because you see this error and this would be interesting but it got sampled away no",
    "start": "507180",
    "end": "513959"
  },
  {
    "text": "if I see my high latency bucket and I can jump directly into a trace",
    "start": "513959",
    "end": "519419"
  },
  {
    "text": "which which shows me this High latency bucket which is much more efficient for for the computers but it's also much",
    "start": "519419",
    "end": "525360"
  },
  {
    "text": "more efficient for the people uh datadog also deserves a shout out of",
    "start": "525360",
    "end": "531600"
  },
  {
    "text": "course they invested quite a bit of engineering time to um to make it work within within the",
    "start": "531600",
    "end": "537060"
  },
  {
    "text": "python parser um that's that was really nice of them I mean they you normally don't know them",
    "start": "537060",
    "end": "542220"
  },
  {
    "text": "as a company who are hugely invested in open source but there they really made an effort so I still believe they needed",
    "start": "542220",
    "end": "548700"
  },
  {
    "text": "the every they deserve a shout out for this open Telemetry",
    "start": "548700",
    "end": "554279"
  },
  {
    "text": "um in the early years there were some bumps in the road but those have been completely uh completely wiped out so to",
    "start": "554279",
    "end": "562260"
  },
  {
    "text": "speak I myself by now on open Telemetry voting member just based on all the contributions to make to make sure that",
    "start": "562260",
    "end": "568860"
  },
  {
    "text": "everything is and remains compatible which uh yeah and it is which is super",
    "start": "568860",
    "end": "574860"
  },
  {
    "text": "nice and also for the Prometheus conformance program that's that's officially part of",
    "start": "574860",
    "end": "580380"
  },
  {
    "text": "it if you see those things um like in the in the header you can see",
    "start": "580380",
    "end": "587220"
  },
  {
    "text": "um you can like in the HTTP header you can even see the format but as if you see like",
    "start": "587220",
    "end": "592680"
  },
  {
    "text": "uh sorry brains um",
    "start": "592680",
    "end": "598200"
  },
  {
    "text": "like for example when you see an underscore created you know but it's pretty certain to be open",
    "start": "598200",
    "end": "603360"
  },
  {
    "text": "metrics if you see an eof at the end of the file written like this you know it's open metrics it should not matter to you",
    "start": "603360",
    "end": "609600"
  },
  {
    "text": "of course again Prometheus and everything handles this completely transparently and don't even notice but",
    "start": "609600",
    "end": "615420"
  },
  {
    "text": "if you do hand debugging or something those are the really um the really detailed tale science and the",
    "start": "615420",
    "end": "622019"
  },
  {
    "text": "unit of course as mentioned earlier is one of the well-breaking or new things if you want to transition by hand again",
    "start": "622019",
    "end": "629760"
  },
  {
    "text": "you need to really be careful with your underscore total you should make certain that you send",
    "start": "629760",
    "end": "636360"
  },
  {
    "text": "the correct content type not permit this explosion format 0 0 4 anymore or plain text or anything but like actually open",
    "start": "636360",
    "end": "642240"
  },
  {
    "text": "metrics 1.0 and please set the accept headers or else you might have not the greatest of",
    "start": "642240",
    "end": "649380"
  },
  {
    "text": "times there are a few known issues in 1.0 again we sometimes have this issue",
    "start": "649380",
    "end": "656279"
  },
  {
    "text": "reported that people have clashes in their namespace when they have existing underscore total there's not a lot we",
    "start": "656279",
    "end": "663300"
  },
  {
    "text": "can do about this because it's just how how the new standard works and it is actually a good thing where we just made",
    "start": "663300",
    "end": "669480"
  },
  {
    "text": "a previous implicit requirement and strong recommendation mandatory so at",
    "start": "669480",
    "end": "674700"
  },
  {
    "text": "some point we had to eat this pain um if you have counters and you have underscore started in there this can",
    "start": "674700",
    "end": "682019"
  },
  {
    "text": "double the amount of counters and the cardinality and that can be a surprise to a few people and that also can also lead to pain we might make this optional",
    "start": "682019",
    "end": "689579"
  },
  {
    "text": "in openmetrics 1.1 that's not yet clear um I guess we will probably do it",
    "start": "689579",
    "end": "695820"
  },
  {
    "text": "because it's just uh okay I see people shaking their heads in their own Prometheus team see it it it needs some",
    "start": "695820",
    "end": "702240"
  },
  {
    "text": "more it seats some more um no more discussion and the other thing is we found one bug",
    "start": "702240",
    "end": "707700"
  },
  {
    "text": "where we where we had one must wrong but as the EB even F the extended but has no",
    "start": "707700",
    "end": "714720"
  },
  {
    "text": "normal form [Music] um is um is the like the thing which most",
    "start": "714720",
    "end": "720240"
  },
  {
    "text": "people at least in ITF space who Implement stuff Implement against anyway we should be fine so these will be fixed",
    "start": "720240",
    "end": "727620"
  },
  {
    "text": "in 1.1 what's up for 2.0 the Highlight feature is a high",
    "start": "727620",
    "end": "732779"
  },
  {
    "text": "resolution or native histograms where you don't have this Le bucket thing anymore where you need to set your own",
    "start": "732779",
    "end": "738959"
  },
  {
    "text": "your own boundaries for your buckets and everything but you can actually just toss it at a thing and in most cases",
    "start": "738959",
    "end": "747300"
  },
  {
    "text": "it's just doing everything as it should in the cases where it's not doing the uh",
    "start": "747300",
    "end": "752820"
  },
  {
    "text": "what it should you can you can set like the the basic computations of how the bucket boundaries are Auto computated",
    "start": "752820",
    "end": "758399"
  },
  {
    "text": "but um it's it's really a game changer for for Native histograms the other thing",
    "start": "758399",
    "end": "764399"
  },
  {
    "text": "which this does is it introduces for the first time complex data types in Prometheus previously you needed one",
    "start": "764399",
    "end": "771180"
  },
  {
    "text": "single metric for every single thing which you wanted to to talk about now you can actually have more than than one single data",
    "start": "771180",
    "end": "778680"
  },
  {
    "text": "point one single sample point to be specific in one sample and that's going",
    "start": "778680",
    "end": "785820"
  },
  {
    "text": "to be new because we needed to to be more efficient um but also it means quite some changes on the back end",
    "start": "785820",
    "end": "792480"
  },
  {
    "text": "it can also lead to slower career performance there's quite some work being done on this to to not have this",
    "start": "792480",
    "end": "797940"
  },
  {
    "text": "happen yeah the other thing and I just had this conversation with Chris any check um so Dan Cohn and Chris any check back",
    "start": "797940",
    "end": "804480"
  },
  {
    "text": "like way way back in in Dark cncf Ages uh asked us to uh to split out uh open",
    "start": "804480",
    "end": "812519"
  },
  {
    "text": "metrics from Prometheus to have its own thing to have its own standard and at",
    "start": "812519",
    "end": "817740"
  },
  {
    "text": "the time this absolutely made sense these days the landscape has massively",
    "start": "817740",
    "end": "824040"
  },
  {
    "text": "changed people have basically stopped fighting with Prometheus because most people just accept this exists and it's",
    "start": "824040",
    "end": "830100"
  },
  {
    "text": "it's the thing which one um yeah so maybe but this is another point",
    "start": "830100",
    "end": "836220"
  },
  {
    "text": "of discussion maybe we release a 2.0 and then we fold it into Prometheus or maybe we fold it into Prometheus and then we",
    "start": "836220",
    "end": "841800"
  },
  {
    "text": "release a tool that oh or whatever we'll see so there's a few there's a few resources",
    "start": "841800",
    "end": "849300"
  },
  {
    "text": "here for the ones who want to take pictures",
    "start": "849300",
    "end": "852920"
  },
  {
    "text": "thank you",
    "start": "855959",
    "end": "858740"
  },
  {
    "text": "and now we come to the questions before we come to your questions sorry one more mask reminder because you signed a",
    "start": "870060",
    "end": "876240"
  },
  {
    "text": "legally binding contract yes you and you are the person with the nose out yes you",
    "start": "876240",
    "end": "882560"
  },
  {
    "text": "oh that's the yes go ahead all right cool",
    "start": "884459",
    "end": "891000"
  },
  {
    "text": "um so actually the last slide you had maybe for the references I guess I'm confused about if I'm starting from",
    "start": "891000",
    "end": "896160"
  },
  {
    "text": "scratch right now yep what format do I write in open metrics open Telemetry and",
    "start": "896160",
    "end": "901980"
  },
  {
    "text": "I guess maybe I don't understand the difference open metrics it's a Telemetry so you're opening a much wider question",
    "start": "901980",
    "end": "908399"
  },
  {
    "text": "than just open metrics but that's completely fine ideally you don't really care because",
    "start": "908399",
    "end": "914220"
  },
  {
    "text": "you use a library and the library does the thing which you want okay that makes sense if you know that you want to be",
    "start": "914220",
    "end": "919260"
  },
  {
    "text": "using Prometheus on the other side then my own personal recommendation would be to use the Prometheus client libraries",
    "start": "919260",
    "end": "924779"
  },
  {
    "text": "of course they're much more efficient because they do one thing and do it well as opposed to what open Telemetry is",
    "start": "924779",
    "end": "930839"
  },
  {
    "text": "solving where they need to have like a complete data plane in between in the standard to be able to transform from",
    "start": "930839",
    "end": "938339"
  },
  {
    "text": "different uh from different formats into other formats to allow this ubiquitous",
    "start": "938339",
    "end": "943440"
  },
  {
    "text": "and really uh like transform into everything uh kind of",
    "start": "943440",
    "end": "949019"
  },
  {
    "text": "modeling that doesn't come for free obviously so that's a little bit of the decision but it's the rest",
    "start": "949019",
    "end": "955920"
  },
  {
    "text": "you can use either all right thank you",
    "start": "955920",
    "end": "960199"
  },
  {
    "text": "thanks Richie um so I mean thanks for the you know kind of concept of the roadmap it feels",
    "start": "961199",
    "end": "966779"
  },
  {
    "text": "like exciting to kind of like improve uh improve this and I was just asking like what's the historical reason for like",
    "start": "966779",
    "end": "973380"
  },
  {
    "text": "creating another uh you know metric for this created timestamp why not just immediately putting that into metadata",
    "start": "973380",
    "end": "979620"
  },
  {
    "text": "is there any blocker maybe you remember we had many many discussions and the",
    "start": "979620",
    "end": "985440"
  },
  {
    "text": "short version is that Google really really really wanted to have this because they needed for monarch",
    "start": "985440",
    "end": "990720"
  },
  {
    "text": "and honestly back then we like we did some back of napkin math and we were like okay this should be fine",
    "start": "990720",
    "end": "998759"
  },
  {
    "text": "um these days with more and more metric data exploding because people keep",
    "start": "998759",
    "end": "1003980"
  },
  {
    "text": "adding more and more and more arguably it's a little bit of a victim of its own success here and",
    "start": "1003980",
    "end": "1009980"
  },
  {
    "text": "um yeah that's why it's directly in there the other reason is we didn't have any mechanism within Prometheus to",
    "start": "1009980",
    "end": "1015440"
  },
  {
    "text": "persist any of this this type of metadata there's a good reason why we could do",
    "start": "1015440",
    "end": "1021680"
  },
  {
    "text": "this because unless you do something fundamentally wrong and and update created all the time it doesn't actually",
    "start": "1021680",
    "end": "1028100"
  },
  {
    "text": "change so on the cardinality side on the index it actually imposes some cost on the",
    "start": "1028100",
    "end": "1033980"
  },
  {
    "text": "storage and the actual block storage it's almost free and I think we focused maybe a little",
    "start": "1033980",
    "end": "1040339"
  },
  {
    "text": "bit too much on how it was almost free on on the actual tstp block size and not so much on the",
    "start": "1040339",
    "end": "1046699"
  },
  {
    "text": "index side okay thank you for the talk uh can you tell",
    "start": "1046699",
    "end": "1052940"
  },
  {
    "text": "something about the semantics of the created and the total metrics",
    "start": "1052940",
    "end": "1058400"
  },
  {
    "text": "uh so you mean the underscore created yeah it's really easy you just let me see if I have an example",
    "start": "1058400",
    "end": "1066159"
  },
  {
    "text": "it's right here um so the thing is as you can see the type of who here is histogram not counter but",
    "start": "1068179",
    "end": "1075679"
  },
  {
    "text": "uh same difference and the thing is as you can see here it's only Foo and then you add those",
    "start": "1075679",
    "end": "1082039"
  },
  {
    "text": "other extensions you add the bucket boundaries again not high not high resolution not native histograms this is",
    "start": "1082039",
    "end": "1088580"
  },
  {
    "text": "the 1.0 Style you see the count you see the summon you see the underscore created and the underscore created is",
    "start": "1088580",
    "end": "1094280"
  },
  {
    "text": "literally just a timestamp when you did create the thing",
    "start": "1094280",
    "end": "1099159"
  },
  {
    "text": "okay thank you there's one over there",
    "start": "1100039",
    "end": "1105640"
  },
  {
    "text": "hello um I'm I had a question about let's say I'm uh upgrading a metrics library for",
    "start": "1107299",
    "end": "1114260"
  },
  {
    "text": "you know language and I want to move it over to open metrics from the the existing format and I'm a little bit",
    "start": "1114260",
    "end": "1121520"
  },
  {
    "text": "worried about um you know you know changing the names of the metrics with the you know underscore total suffix um is there a",
    "start": "1121520",
    "end": "1128360"
  },
  {
    "text": "strategy for moving it over without like losing you know completely like having",
    "start": "1128360",
    "end": "1133520"
  },
  {
    "text": "to rename your metric and lose that data is there a way to gradually move that over",
    "start": "1133520",
    "end": "1138919"
  },
  {
    "text": "so first you should look at your data if this is actually a concern because",
    "start": "1138919",
    "end": "1144620"
  },
  {
    "text": "um chances are if you followed Prometheus best practices it shouldn't be a concern",
    "start": "1144620",
    "end": "1150380"
  },
  {
    "text": "because you wouldn't have any underscore total because you are supposed to put the unit",
    "start": "1150380",
    "end": "1156080"
  },
  {
    "text": "at the end and something meaningful and that's usually not the underscore total so the likelihood of this existing is",
    "start": "1156080",
    "end": "1162080"
  },
  {
    "text": "not super high if it exists you need to find some plan if you write your own library because",
    "start": "1162080",
    "end": "1167720"
  },
  {
    "text": "that's how I understood you then you can in theory just not do it and not be fully compliant like that works but it's",
    "start": "1167720",
    "end": "1173240"
  },
  {
    "text": "not nice if you use a real Library you're going to run into problems and",
    "start": "1173240",
    "end": "1178400"
  },
  {
    "text": "ideally you already start this migration before like the naming migration before",
    "start": "1178400",
    "end": "1183919"
  },
  {
    "text": "you do the open metrics migration the reason being if you have two lifts at",
    "start": "1183919",
    "end": "1188960"
  },
  {
    "text": "the same time and something goes sideways you're going to have a really big bedtime so it's better to do like one",
    "start": "1188960",
    "end": "1195260"
  },
  {
    "text": "step wait a month see things are stable and they have settled down and then do the next step and break this up into two",
    "start": "1195260",
    "end": "1202400"
  },
  {
    "text": "smaller migrations great thanks that makes sense yeah no worries",
    "start": "1202400",
    "end": "1208600"
  },
  {
    "text": "right",
    "start": "1210140",
    "end": "1212919"
  },
  {
    "text": "hello um earlier earlier this year I was looking into this for a project and and",
    "start": "1215480",
    "end": "1221179"
  },
  {
    "text": "saw oh there's protobufs that I could use which I would have been happy to use and then it was not clear I never found out kind of what the state",
    "start": "1221179",
    "end": "1227360"
  },
  {
    "text": "of things was with that and I just moved on but is that something it's just an idea is it implemented is it specked out",
    "start": "1227360",
    "end": "1234380"
  },
  {
    "text": "or is it uh you find the protobots in the spec people were talking about it and it",
    "start": "1234380",
    "end": "1240320"
  },
  {
    "text": "wasn't clear it didn't seem I wasn't sure if it was an idea that came up and it was abandoned or if it's going to be available in some future version or if",
    "start": "1240320",
    "end": "1247100"
  },
  {
    "text": "it's I was completely confused I'm just going to put Gotham up to on the spot here",
    "start": "1247100",
    "end": "1253480"
  },
  {
    "text": "who didn't pay attention um do we already ingest the protobus for of open metrics directly into Prometheus",
    "start": "1254299",
    "end": "1260780"
  },
  {
    "text": "okay then the answer is currently no yeah so the thing here complete",
    "start": "1260780",
    "end": "1267200"
  },
  {
    "text": "transparency and honesty uh with my Prometheus head-on we were kind of waiting for the native histograms to",
    "start": "1267200",
    "end": "1273380"
  },
  {
    "text": "settle of course we knew we needed to uh to actually have this like larger change",
    "start": "1273380",
    "end": "1279380"
  },
  {
    "text": "back because initially we support it like in Prometheus 1.x we promote uh supported protobuf and then we took it",
    "start": "1279380",
    "end": "1286340"
  },
  {
    "text": "out because it didn't have any any efficiency benefits at that time for us",
    "start": "1286340",
    "end": "1292400"
  },
  {
    "text": "um and we've kind of been waiting and I mean open metrics mandates text format",
    "start": "1292400",
    "end": "1298640"
  },
  {
    "text": "it does not mandate the protobuf but for the 2.0",
    "start": "1298640",
    "end": "1303799"
  },
  {
    "text": "you'll have it then and then you also have the native histograms but it will still mandate the text and not the Proto",
    "start": "1303799",
    "end": "1309919"
  },
  {
    "text": "of course again this debuggability with just your web browser is something we highly highly value and we don't want to",
    "start": "1309919",
    "end": "1315919"
  },
  {
    "text": "lose this but there's more efficient ways I agree of course",
    "start": "1315919",
    "end": "1322179"
  },
  {
    "text": "thank you I just wanted to ask your reference like remote fright and effort",
    "start": "1322280",
    "end": "1327559"
  },
  {
    "text": "in standardization of that interface is actually one of the interfaces used the most light to plant like Prometheus with",
    "start": "1327559",
    "end": "1335000"
  },
  {
    "text": "like long-term storage and things like that can you please comment more on how this is going to be impact in the",
    "start": "1335000",
    "end": "1340700"
  },
  {
    "text": "standardization and what is going to happen especially on the parameters side here so um those are different of course when",
    "start": "1340700",
    "end": "1348500"
  },
  {
    "text": "you have your exporters and your your instrument It Whatever here and you have your Prometheus here then",
    "start": "1348500",
    "end": "1354799"
  },
  {
    "text": "this is where open metrics is being spoken if you have your Prometheus here again and you have other Prometheus",
    "start": "1354799",
    "end": "1360380"
  },
  {
    "text": "instances or you have a long-term storage here is where you speak remote read write",
    "start": "1360380",
    "end": "1366020"
  },
  {
    "text": "so it's a fundamentally different use case in theory you could hack together a library which uses Prometheus remote",
    "start": "1366020",
    "end": "1371179"
  },
  {
    "text": "right to push from those workloads down there but that's not really what the what the whole system is optimized for",
    "start": "1371179",
    "end": "1378200"
  },
  {
    "text": "um we do have discussions about what how we are going to evolve the remote read",
    "start": "1378200",
    "end": "1384080"
  },
  {
    "text": "write format we might actually just steal otlp and shove that into Prometheus but that's an ongoing",
    "start": "1384080",
    "end": "1390080"
  },
  {
    "text": "discussion we don't yet know um yeah yeah okay I was asking really like",
    "start": "1390080",
    "end": "1396020"
  },
  {
    "text": "also in relationship to what is happening on the hotel side where do you have like this agent which is essentially like scrapping and then like",
    "start": "1396020",
    "end": "1402440"
  },
  {
    "text": "pushing things whether there was any uh idea on the Primitive side only scope to metrics to do something similar and use",
    "start": "1402440",
    "end": "1408980"
  },
  {
    "text": "a standard interface thank you I would wait a week and maybe you'll find something which is nice",
    "start": "1408980",
    "end": "1416679"
  },
  {
    "text": "I'm looking at you yeah it's going to get easier over time",
    "start": "1420860",
    "end": "1426980"
  },
  {
    "text": "that's yeah um I had another question about uh I'm",
    "start": "1426980",
    "end": "1433520"
  },
  {
    "text": "really excited about exemplars um um just wondering uh what the rate of adoption is I noticed you mentioned on",
    "start": "1433520",
    "end": "1440299"
  },
  {
    "text": "like cortex um Prometheus itself uh is there any updates on like whether Tempo uh is",
    "start": "1440299",
    "end": "1446480"
  },
  {
    "text": "supporting exemplars or if there's like some kind of additional work to get that working",
    "start": "1446480",
    "end": "1452720"
  },
  {
    "text": "um or is that like kind of a separate no no I got it so first I forgot to write down memir in this slide but um because",
    "start": "1452720",
    "end": "1458840"
  },
  {
    "text": "it also supports exemplars um Tempo is written with exemplars in",
    "start": "1458840",
    "end": "1464000"
  },
  {
    "text": "mind Tempo is designed to just take these IDs and give you a really really quick way",
    "start": "1464000",
    "end": "1470240"
  },
  {
    "text": "to access your tracing data the newer versions of tempo also allow it like search and such where if you",
    "start": "1470240",
    "end": "1477679"
  },
  {
    "text": "want to shove labels into the thing you can do so and it will work but if you want to run in a really efficient manner",
    "start": "1477679",
    "end": "1483980"
  },
  {
    "text": "that is actually how how Tempo is supposed to be used are you referring to a parquet and traceql or sorry what are",
    "start": "1483980",
    "end": "1491059"
  },
  {
    "text": "you referring to parquet and traceql with the research for Tempo um yes labels yes okay okay",
    "start": "1491059",
    "end": "1498380"
  },
  {
    "text": "that's great that's basically distinct from this happy path of I have only XM",
    "start": "1498380",
    "end": "1504559"
  },
  {
    "text": "plus and I can jump into stuff really really quickly and and so uh are the labels that you're",
    "start": "1504559",
    "end": "1509780"
  },
  {
    "text": "talking about is this part of the open metrics format as well sorry the you mentioned label searching for by label",
    "start": "1509780",
    "end": "1515240"
  },
  {
    "text": "in a tool like Tempo oh so yeah um the format of",
    "start": "1515240",
    "end": "1520760"
  },
  {
    "text": "um so the format of the exemplars we deliberately did not specify this within",
    "start": "1520760",
    "end": "1527299"
  },
  {
    "text": "Prometheus but what we did in the specification is all the examples which you can find in",
    "start": "1527299",
    "end": "1534080"
  },
  {
    "text": "the specifications are taken directly from the WC3 tracing standard on how to",
    "start": "1534080",
    "end": "1539600"
  },
  {
    "text": "propagate tracing context morgue McLean and such were working on this within the context of WC3",
    "start": "1539600",
    "end": "1546620"
  },
  {
    "text": "you will find the same in open Telemetry like the same shared history we didn't feel comfortable to mandate it",
    "start": "1546620",
    "end": "1553580"
  },
  {
    "text": "and to write it down we didn't feel comfortable to write a should but we made certain that anyone who like",
    "start": "1553580",
    "end": "1560000"
  },
  {
    "text": "we put the we put the breadcrumbs in there you will find the WC3 standard",
    "start": "1560000",
    "end": "1565580"
  },
  {
    "text": "from our specification and also if you do the usual thing and just like look at the EB and f look at all the samples",
    "start": "1565580",
    "end": "1572419"
  },
  {
    "text": "which we have in there and you start implementing your thing automatically you land precisely on the WC3 standard",
    "start": "1572419",
    "end": "1579980"
  },
  {
    "text": "for distributed tracing context propagation and that's no mistake great thanks",
    "start": "1579980",
    "end": "1587080"
  },
  {
    "text": "what do you see going forward what do you what are you interested in for open metrics 1.2 or 2.0 what interesting",
    "start": "1593360",
    "end": "1600020"
  },
  {
    "text": "ideas do you have coming up well for 2.0 the main thing is again the high resolution histograms like that's going",
    "start": "1600020",
    "end": "1606320"
  },
  {
    "text": "to be big in like with with pretty much all of my heads on this",
    "start": "1606320",
    "end": "1611840"
  },
  {
    "text": "one is going to be a big one and we've been working towards this for for literally years",
    "start": "1611840",
    "end": "1617960"
  },
  {
    "text": "um we also spent quite some time making certain that the approach which we are doing within open metrics and Prometheus",
    "start": "1617960",
    "end": "1624980"
  },
  {
    "text": "is directly congruent with the approach taken within open Telemetry in as much as you have good and 100 compatibility",
    "start": "1624980",
    "end": "1632240"
  },
  {
    "text": "between those all of those in anticipation of the ecosystem at",
    "start": "1632240",
    "end": "1637640"
  },
  {
    "text": "large moving towards Native histograms relatively quickly um because it is one of the most voiced",
    "start": "1637640",
    "end": "1644000"
  },
  {
    "text": "pain points with with Prometheus style metrics that we only have really flat metric",
    "start": "1644000",
    "end": "1650480"
  },
  {
    "text": "types that we don't allow complex types yeah so um that like that's the thing",
    "start": "1650480",
    "end": "1656779"
  },
  {
    "text": "which which anyone is most excited about I think we're about 3.0",
    "start": "1656779",
    "end": "1663039"
  },
  {
    "text": "I know uh you need to come back here in like two or three years and",
    "start": "1663039",
    "end": "1670480"
  },
  {
    "text": "just for the online audience the question was what about 3.0 any more questions",
    "start": "1671240",
    "end": "1678760"
  },
  {
    "text": "there's one more uh just just regarding do the XM plus",
    "start": "1680419",
    "end": "1689679"
  },
  {
    "text": "is just a random one random entry from from the total for",
    "start": "1690100",
    "end": "1697820"
  },
  {
    "text": "for example the packet La 0.1 total one and this is one of these one a randomly",
    "start": "1697820",
    "end": "1704659"
  },
  {
    "text": "chosen event if I got it right so the the string you see in those curlies",
    "start": "1704659",
    "end": "1711919"
  },
  {
    "text": "um that is what I talked about with the WC3 instead I got but there are several",
    "start": "1711919",
    "end": "1717460"
  },
  {
    "text": "events IDs contributing to this package and so this with ID ABC is just one of",
    "start": "1717460",
    "end": "1724400"
  },
  {
    "text": "them oh yes yeah yeah yeah you you can only by Design per exposure",
    "start": "1724400",
    "end": "1730159"
  },
  {
    "text": "you can only expose one single exemplars because we don't overwhelm the storage or anything and also we want we don't",
    "start": "1730159",
    "end": "1736580"
  },
  {
    "text": "want to give people to to build a large foot gun and turn promises into an event uh monitoring system because then you're",
    "start": "1736580",
    "end": "1742700"
  },
  {
    "text": "going to have a really bad time so you can only put one in the other thing which you see behind there but again",
    "start": "1742700",
    "end": "1749299"
  },
  {
    "text": "this is completely optional because we are waiting for people to figure out how to use this how it's actually useful for",
    "start": "1749299",
    "end": "1754460"
  },
  {
    "text": "them or thinking here was we put in a specific number of that specific",
    "start": "1754460",
    "end": "1759860"
  },
  {
    "text": "Exemplar because you have those buckets but buckets are nice but I mean we are",
    "start": "1759860",
    "end": "1766159"
  },
  {
    "text": "almost back at Native histograms it's also nice to have like more specific hits and that's why here we we showed how you",
    "start": "1766159",
    "end": "1773059"
  },
  {
    "text": "can have your Trace ID and at the same time uh give the user exactly the information",
    "start": "1773059",
    "end": "1779840"
  },
  {
    "text": "about what specific runtime in that one latency bucket or whatever so it's up to the application or the library which one",
    "start": "1779840",
    "end": "1786799"
  },
  {
    "text": "to choose as an excellent yes you can basically put 64 uh characters of utf-8",
    "start": "1786799",
    "end": "1793760"
  },
  {
    "text": "into behind this hash Pond and it's just going to be handled and the rest is",
    "start": "1793760",
    "end": "1799640"
  },
  {
    "text": "again deliberately undefined with a suggestion of how to properly do it if you thank you Bill dank",
    "start": "1799640",
    "end": "1807940"
  },
  {
    "text": "thank you hi are there any um SAS vendors supporting open metrics",
    "start": "1811100",
    "end": "1816260"
  },
  {
    "text": "natively or is it better to just use Prometheus and exporters so grafana Labs",
    "start": "1816260",
    "end": "1822620"
  },
  {
    "text": "of course we run mimir um I mean I",
    "start": "1822620",
    "end": "1829100"
  },
  {
    "text": "I don't know if I mean AWS is running cortex internally or as as like user",
    "start": "1829100",
    "end": "1834140"
  },
  {
    "text": "facing I don't know if they if they actually enabled the users I honestly don't know so at least there is grafana",
    "start": "1834140",
    "end": "1840440"
  },
  {
    "text": "Labs um if data talk I don't know if they have it in a",
    "start": "1840440",
    "end": "1846980"
  },
  {
    "text": "service I I honestly don't know I I only want to do do any of you know of others which no",
    "start": "1846980",
    "end": "1852320"
  },
  {
    "text": "okay so at least grafana okay we have five more minutes for questions if anyone has any more",
    "start": "1852320",
    "end": "1859299"
  },
  {
    "text": "there's one more I wanted to clarify vocabulary when you",
    "start": "1861200",
    "end": "1866960"
  },
  {
    "text": "say native histograms is that the same thing as the sparse histograms yes okay yeah it",
    "start": "1866960",
    "end": "1872720"
  },
  {
    "text": "it shows how long we've been at this that we have like half a dozen different names",
    "start": "1872720",
    "end": "1879880"
  },
  {
    "text": "natural histograms of that also be I mean I I think the pr which which I saw merged I think today uh was from the",
    "start": "1880220",
    "end": "1887899"
  },
  {
    "text": "branch native histograms and in the pr description says no so in the branch name what Spar system comes and the pr",
    "start": "1887899",
    "end": "1894559"
  },
  {
    "text": "said native histograms so just to give you an idea of how much of a mess this is but going forward we are having one",
    "start": "1894559",
    "end": "1900380"
  },
  {
    "text": "name we also have one name which is synchronized between Prometheus and between open Telemetry to just have",
    "start": "1900380",
    "end": "1906740"
  },
  {
    "text": "we have two names okay we have okay apparently we still have exponential in sports but maybe we",
    "start": "1906740",
    "end": "1913279"
  },
  {
    "text": "can hash this out with your RG and others and",
    "start": "1913279",
    "end": "1917559"
  },
  {
    "text": "if it's yeah we",
    "start": "1918740",
    "end": "1922000"
  },
  {
    "text": "take the mic if you're on I mean answer totally no yeah it's not really an",
    "start": "1924919",
    "end": "1930020"
  },
  {
    "text": "answer uh what I hear is exponential histograms in in open Telemetry I mean",
    "start": "1930020",
    "end": "1935120"
  },
  {
    "text": "as far as histograms are here in other communities I thought we had fixed it but I don't",
    "start": "1935120",
    "end": "1941000"
  },
  {
    "text": "know I mean that's the reason why we have a working group the message type in otlp is exponential",
    "start": "1941000",
    "end": "1946580"
  },
  {
    "text": "histogram and so I think we're going to stick with that for a while now okay yeah okay see ya sorry yeah it's been",
    "start": "1946580",
    "end": "1953539"
  },
  {
    "text": "part of this back for hotel for quite some time now so it's you know the name was specified before I yeah personally I",
    "start": "1953539",
    "end": "1962000"
  },
  {
    "text": "don't care about the name I want to have one name which everyone is using because I also gets confusing the rest I don't",
    "start": "1962000",
    "end": "1967220"
  },
  {
    "text": "care but yeah apparently we have work to do I thought we had fixed it sorry",
    "start": "1967220",
    "end": "1973960"
  },
  {
    "text": "anyone else or do you want two minutes of your time back",
    "start": "1978140",
    "end": "1983200"
  },
  {
    "text": "hey can you just comment on the timeline for the 2.0 like are you waiting to stabilize the exponential histograms",
    "start": "1984740",
    "end": "1992059"
  },
  {
    "text": "like implementation before like pushing the standard okay that's basically it",
    "start": "1992059",
    "end": "1997279"
  },
  {
    "text": "like we've been we even before we cut the 1.0 release we already had consensus that",
    "start": "1997279",
    "end": "2004480"
  },
  {
    "text": "2.0 would be oh that exponential or as far as histograms would be the reason why we cut 2.0",
    "start": "2004480",
    "end": "2011140"
  },
  {
    "text": "so we've been waiting for this quite some time uh I can't give you any specific",
    "start": "2011140",
    "end": "2016419"
  },
  {
    "text": "timeline but we've been waiting for this for quite some time we want to get this going",
    "start": "2016419",
    "end": "2022679"
  },
  {
    "text": "okay I'm getting a sign we are out of time okay cool then thank you very much",
    "start": "2023799",
    "end": "2029710"
  },
  {
    "text": "[Applause]",
    "start": "2029710",
    "end": "2033498"
  }
]
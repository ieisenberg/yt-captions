[
  {
    "start": "0",
    "end": "48000"
  },
  {
    "text": "hello everyone hello thank you for",
    "start": "0",
    "end": "2460"
  },
  {
    "text": "coming",
    "start": "2460",
    "end": "3300"
  },
  {
    "text": "thank you for going to argocon I'm going",
    "start": "3300",
    "end": "6420"
  },
  {
    "text": "to talk for the next around 20 minutes",
    "start": "6420",
    "end": "8760"
  },
  {
    "text": "and I'm gonna talk about like how we",
    "start": "8760",
    "end": "11099"
  },
  {
    "text": "train and enter reliability of machine",
    "start": "11099",
    "end": "13799"
  },
  {
    "text": "learning model at world and how we use",
    "start": "13799",
    "end": "16020"
  },
  {
    "text": "Argo CD flights and I'll go works well",
    "start": "16020",
    "end": "18420"
  },
  {
    "text": "for that",
    "start": "18420",
    "end": "19740"
  },
  {
    "text": "quick intro on my side well no one came",
    "start": "19740",
    "end": "22080"
  },
  {
    "text": "here for me but still I'm Stefan I'm a",
    "start": "22080",
    "end": "24600"
  },
  {
    "text": "machine engineer I'm also a yaml",
    "start": "24600",
    "end": "26460"
  },
  {
    "text": "engineer given that I use Argo a lot",
    "start": "26460",
    "end": "28380"
  },
  {
    "text": "that's basically what I do all day long",
    "start": "28380",
    "end": "30480"
  },
  {
    "text": "in the previous life I was a data",
    "start": "30480",
    "end": "32340"
  },
  {
    "text": "scientist",
    "start": "32340",
    "end": "33320"
  },
  {
    "text": "I'm the founding member of the ml",
    "start": "33320",
    "end": "35520"
  },
  {
    "text": "platform team also if you want",
    "start": "35520",
    "end": "38460"
  },
  {
    "text": "a founding member of the Berlin Emirates",
    "start": "38460",
    "end": "40140"
  },
  {
    "text": "community so if you're Berlin based and",
    "start": "40140",
    "end": "41700"
  },
  {
    "text": "you want to learn about envelopes you",
    "start": "41700",
    "end": "43620"
  },
  {
    "text": "can come to our meetups conferences",
    "start": "43620",
    "end": "45059"
  },
  {
    "text": "everything but that's that's all about",
    "start": "45059",
    "end": "47040"
  },
  {
    "text": "me",
    "start": "47040",
    "end": "48660"
  },
  {
    "start": "48000",
    "end": "230000"
  },
  {
    "text": "second thing I work for volt I don't",
    "start": "48660",
    "end": "51360"
  },
  {
    "text": "work for bold and I don't work for",
    "start": "51360",
    "end": "52860"
  },
  {
    "text": "hashikovs I had because everyone every",
    "start": "52860",
    "end": "55199"
  },
  {
    "text": "time people are like oh who are you and",
    "start": "55199",
    "end": "57960"
  },
  {
    "text": "yeah so we are World Vault depending on",
    "start": "57960",
    "end": "59940"
  },
  {
    "text": "the country you own",
    "start": "59940",
    "end": "61820"
  },
  {
    "text": "and given that we're not in Amsterdam",
    "start": "61820",
    "end": "64320"
  },
  {
    "text": "given that we're not in the Netherlands",
    "start": "64320",
    "end": "65939"
  },
  {
    "text": "I'm just going to give you a quick intro",
    "start": "65939",
    "end": "67320"
  },
  {
    "text": "and then we'll go to the technical stuff",
    "start": "67320",
    "end": "70020"
  },
  {
    "text": "so a vault was created in Helsinki in",
    "start": "70020",
    "end": "72479"
  },
  {
    "text": "2016 we started as a food delivery",
    "start": "72479",
    "end": "75000"
  },
  {
    "text": "company in Finland and now we deliver",
    "start": "75000",
    "end": "77600"
  },
  {
    "text": "basically everything you can think of so",
    "start": "77600",
    "end": "80159"
  },
  {
    "text": "going from food delivery to Christmas",
    "start": "80159",
    "end": "82020"
  },
  {
    "text": "trees into everything in the middle",
    "start": "82020",
    "end": "84600"
  },
  {
    "text": "uh we are in 23 countries now going from",
    "start": "84600",
    "end": "87479"
  },
  {
    "text": "Norway to Japan going also through the",
    "start": "87479",
    "end": "89640"
  },
  {
    "text": "stands and a lot of countries in the",
    "start": "89640",
    "end": "91740"
  },
  {
    "text": "middle",
    "start": "91740",
    "end": "93000"
  },
  {
    "text": "we have a lot of users a lot of Partners",
    "start": "93000",
    "end": "95159"
  },
  {
    "text": "a lot of core Partners those are just",
    "start": "95159",
    "end": "97320"
  },
  {
    "text": "random stats we don't really care about",
    "start": "97320",
    "end": "98880"
  },
  {
    "text": "them what we care about is machine",
    "start": "98880",
    "end": "100920"
  },
  {
    "text": "learning and we have different use cases",
    "start": "100920",
    "end": "103380"
  },
  {
    "text": "for ML adult so I'm just gonna explain",
    "start": "103380",
    "end": "106320"
  },
  {
    "text": "the difference use cases and then we can",
    "start": "106320",
    "end": "108600"
  },
  {
    "text": "start the talk so the first one is",
    "start": "108600",
    "end": "111420"
  },
  {
    "text": "supply and demand forecasting and that's",
    "start": "111420",
    "end": "114180"
  },
  {
    "text": "what we do when we try to predict like",
    "start": "114180",
    "end": "116399"
  },
  {
    "text": "how many people are gonna order next",
    "start": "116399",
    "end": "118020"
  },
  {
    "text": "week do we need Courier Partners next",
    "start": "118020",
    "end": "119759"
  },
  {
    "text": "week do we need",
    "start": "119759",
    "end": "121200"
  },
  {
    "text": "to to buy more things for our",
    "start": "121200",
    "end": "123420"
  },
  {
    "text": "supermarkets as well because we also",
    "start": "123420",
    "end": "124920"
  },
  {
    "text": "have our own Supermarket so like let's",
    "start": "124920",
    "end": "126960"
  },
  {
    "text": "say it's a public holiday next week",
    "start": "126960",
    "end": "128220"
  },
  {
    "text": "maybe people will buy specific things so",
    "start": "128220",
    "end": "130500"
  },
  {
    "text": "that's what we're trying to forecast we",
    "start": "130500",
    "end": "132540"
  },
  {
    "text": "do that on a weekly basis and it runs",
    "start": "132540",
    "end": "135540"
  },
  {
    "text": "pretty good then we'll have recommender",
    "start": "135540",
    "end": "137640"
  },
  {
    "text": "systems well I assume a lot of people",
    "start": "137640",
    "end": "140040"
  },
  {
    "text": "know about it it's",
    "start": "140040",
    "end": "141420"
  },
  {
    "text": "you buy the same dishes we're going to",
    "start": "141420",
    "end": "143459"
  },
  {
    "text": "try to do like recommend you different",
    "start": "143459",
    "end": "144900"
  },
  {
    "text": "dishes that I you might like but also",
    "start": "144900",
    "end": "147360"
  },
  {
    "text": "let's think like you move to a new city",
    "start": "147360",
    "end": "149540"
  },
  {
    "text": "you need to finish your apartment you",
    "start": "149540",
    "end": "152340"
  },
  {
    "text": "can buy a lot of things on vault and",
    "start": "152340",
    "end": "153840"
  },
  {
    "text": "then we'll be like oh yeah you bought a",
    "start": "153840",
    "end": "155099"
  },
  {
    "text": "lamp you bought a chair maybe you want",
    "start": "155099",
    "end": "157620"
  },
  {
    "text": "to buy a desk or something you know like",
    "start": "157620",
    "end": "159599"
  },
  {
    "text": "we're trying to do that we're not trying",
    "start": "159599",
    "end": "161819"
  },
  {
    "text": "to do the Amazon way where you like you",
    "start": "161819",
    "end": "163319"
  },
  {
    "text": "buy a lamp and we'll be like yeah maybe",
    "start": "163319",
    "end": "165060"
  },
  {
    "text": "you want a thousand lamps so like we're",
    "start": "165060",
    "end": "167160"
  },
  {
    "text": "trying to like recommend you new things",
    "start": "167160",
    "end": "169860"
  },
  {
    "text": "uh then the other one is logistic",
    "start": "169860",
    "end": "172019"
  },
  {
    "text": "optimization",
    "start": "172019",
    "end": "173220"
  },
  {
    "text": "that's I think one of the most important",
    "start": "173220",
    "end": "175019"
  },
  {
    "text": "one we have is okay you make an order on",
    "start": "175019",
    "end": "178260"
  },
  {
    "text": "volt you order a dish we're going to",
    "start": "178260",
    "end": "180120"
  },
  {
    "text": "predict how long it's going to take to",
    "start": "180120",
    "end": "181800"
  },
  {
    "text": "prepare the dish and then how long it's",
    "start": "181800",
    "end": "183959"
  },
  {
    "text": "going to take for you to for us to",
    "start": "183959",
    "end": "185340"
  },
  {
    "text": "deliver the the food or the or the",
    "start": "185340",
    "end": "187319"
  },
  {
    "text": "object that you bought and that depends",
    "start": "187319",
    "end": "189780"
  },
  {
    "text": "on traffic uh that one is like full real",
    "start": "189780",
    "end": "192360"
  },
  {
    "text": "time so it's really important and it's",
    "start": "192360",
    "end": "195120"
  },
  {
    "text": "the one you usually people complain",
    "start": "195120",
    "end": "196560"
  },
  {
    "text": "about because they're like oh yeah I",
    "start": "196560",
    "end": "198120"
  },
  {
    "text": "would did something it's supposed to",
    "start": "198120",
    "end": "199620"
  },
  {
    "text": "take 25 minutes I've been waiting for",
    "start": "199620",
    "end": "201420"
  },
  {
    "text": "35. what's up",
    "start": "201420",
    "end": "203700"
  },
  {
    "text": "then flow detection keep the bad people",
    "start": "203700",
    "end": "205800"
  },
  {
    "text": "out",
    "start": "205800",
    "end": "206640"
  },
  {
    "text": "and the last one is support",
    "start": "206640",
    "end": "208200"
  },
  {
    "text": "prioritization",
    "start": "208200",
    "end": "209819"
  },
  {
    "text": "so you order something and then you're",
    "start": "209819",
    "end": "212040"
  },
  {
    "text": "unhappy about it it's delayed there's a",
    "start": "212040",
    "end": "214379"
  },
  {
    "text": "problem we delivered the wrong object",
    "start": "214379",
    "end": "216019"
  },
  {
    "text": "that we try to prioritize by order of",
    "start": "216019",
    "end": "219900"
  },
  {
    "text": "importance so like let's say you have a",
    "start": "219900",
    "end": "222180"
  },
  {
    "text": "dish that is laid",
    "start": "222180",
    "end": "223379"
  },
  {
    "text": "that's when it's pretty important and",
    "start": "223379",
    "end": "225659"
  },
  {
    "text": "other other problems can maybe wait a",
    "start": "225659",
    "end": "227640"
  },
  {
    "text": "day or two so that's that's it we have",
    "start": "227640",
    "end": "230099"
  },
  {
    "start": "230000",
    "end": "322000"
  },
  {
    "text": "different use cases different use cases",
    "start": "230099",
    "end": "232379"
  },
  {
    "text": "many different needs",
    "start": "232379",
    "end": "234200"
  },
  {
    "text": "our data centers they need data access",
    "start": "234200",
    "end": "236700"
  },
  {
    "text": "so you know we want them to to have",
    "start": "236700",
    "end": "238920"
  },
  {
    "text": "access to production data in a simple",
    "start": "238920",
    "end": "240959"
  },
  {
    "text": "and yet safe way so like you don't want",
    "start": "240959",
    "end": "243720"
  },
  {
    "text": "them to have access to the whole",
    "start": "243720",
    "end": "245159"
  },
  {
    "text": "production database you know you just",
    "start": "245159",
    "end": "246840"
  },
  {
    "text": "want them to have access to specific",
    "start": "246840",
    "end": "247980"
  },
  {
    "text": "tables we make that",
    "start": "247980",
    "end": "250379"
  },
  {
    "text": "I would say fairly easy for them that",
    "start": "250379",
    "end": "252840"
  },
  {
    "text": "infra access as well",
    "start": "252840",
    "end": "254819"
  },
  {
    "text": "a lot of data scientists will need gpus",
    "start": "254819",
    "end": "256979"
  },
  {
    "text": "now",
    "start": "256979",
    "end": "257820"
  },
  {
    "text": "especially even now so like if they need",
    "start": "257820",
    "end": "261419"
  },
  {
    "text": "gpus then they can request them",
    "start": "261419",
    "end": "262680"
  },
  {
    "text": "themselves they can make PRS",
    "start": "262680",
    "end": "264660"
  },
  {
    "text": "then I'll talk about it later but algo",
    "start": "264660",
    "end": "266280"
  },
  {
    "text": "will pick it up for you and so they",
    "start": "266280",
    "end": "268380"
  },
  {
    "text": "don't they don't even have to apply",
    "start": "268380",
    "end": "269699"
  },
  {
    "text": "anything themselves if you need a lot of",
    "start": "269699",
    "end": "271979"
  },
  {
    "text": "ram a lot of CPUs it's the same",
    "start": "271979",
    "end": "274199"
  },
  {
    "text": "one other thing as well that we want",
    "start": "274199",
    "end": "276479"
  },
  {
    "text": "is to make deployments of models quick",
    "start": "276479",
    "end": "279419"
  },
  {
    "text": "reliable and easy because you know you",
    "start": "279419",
    "end": "282360"
  },
  {
    "text": "might have the best model in your laptop",
    "start": "282360",
    "end": "284280"
  },
  {
    "text": "if it's not deployed then it's useless",
    "start": "284280",
    "end": "286080"
  },
  {
    "text": "so we really want to to make that easy",
    "start": "286080",
    "end": "288479"
  },
  {
    "text": "for people and we won't really want to",
    "start": "288479",
    "end": "290460"
  },
  {
    "text": "increase the velocity of our data",
    "start": "290460",
    "end": "291840"
  },
  {
    "text": "scientists",
    "start": "291840",
    "end": "292979"
  },
  {
    "text": "the last thing we want",
    "start": "292979",
    "end": "294960"
  },
  {
    "text": "is standardized monitoring we want to",
    "start": "294960",
    "end": "298080"
  },
  {
    "text": "track data quality you don't want to",
    "start": "298080",
    "end": "299880"
  },
  {
    "text": "train the model if your data quality is",
    "start": "299880",
    "end": "301259"
  },
  {
    "text": "not good if you have a problem with the",
    "start": "301259",
    "end": "302460"
  },
  {
    "text": "data because then the model wouldn't",
    "start": "302460",
    "end": "304020"
  },
  {
    "text": "probably not be good",
    "start": "304020",
    "end": "305699"
  },
  {
    "text": "you want to trade the metrics of your ml",
    "start": "305699",
    "end": "308460"
  },
  {
    "text": "model and then you want to also like",
    "start": "308460",
    "end": "310500"
  },
  {
    "text": "track the production performance so",
    "start": "310500",
    "end": "312380"
  },
  {
    "text": "let's make sure that your P99 didn't go",
    "start": "312380",
    "end": "315540"
  },
  {
    "text": "from 50 millisecond to two seconds you",
    "start": "315540",
    "end": "317880"
  },
  {
    "text": "know if you want to promote a model so",
    "start": "317880",
    "end": "319680"
  },
  {
    "text": "those are the needs we have",
    "start": "319680",
    "end": "322639"
  },
  {
    "start": "322000",
    "end": "474000"
  },
  {
    "text": "we have an ml platform I won't go into",
    "start": "322979",
    "end": "325259"
  },
  {
    "text": "details because not the the goal of the",
    "start": "325259",
    "end": "327240"
  },
  {
    "text": "talk but we're using flight to train our",
    "start": "327240",
    "end": "329160"
  },
  {
    "text": "models so a whole stack is on kubernetes",
    "start": "329160",
    "end": "331860"
  },
  {
    "text": "and yeah flight is running on",
    "start": "331860",
    "end": "333300"
  },
  {
    "text": "communities and what that's what we use",
    "start": "333300",
    "end": "334919"
  },
  {
    "text": "to train and orchestrator workflows then",
    "start": "334919",
    "end": "337500"
  },
  {
    "text": "we have ml flow that is here you track",
    "start": "337500",
    "end": "339780"
  },
  {
    "text": "your metrics you track the different",
    "start": "339780",
    "end": "341759"
  },
  {
    "text": "parameters you you like you can log the",
    "start": "341759",
    "end": "343919"
  },
  {
    "text": "artifacts as well for your ml model and",
    "start": "343919",
    "end": "346080"
  },
  {
    "text": "then you can also compare experiments",
    "start": "346080",
    "end": "347580"
  },
  {
    "text": "being like okay I have multiple",
    "start": "347580",
    "end": "349740"
  },
  {
    "text": "experiments then I can compare them have",
    "start": "349740",
    "end": "351300"
  },
  {
    "text": "like graphs have UI so you're you're",
    "start": "351300",
    "end": "353940"
  },
  {
    "text": "happy with it then you also have and we",
    "start": "353940",
    "end": "356160"
  },
  {
    "text": "also use mlflow model registry",
    "start": "356160",
    "end": "358919"
  },
  {
    "text": "which allows you to track which model is",
    "start": "358919",
    "end": "361620"
  },
  {
    "text": "running where so if you have a model",
    "start": "361620",
    "end": "363060"
  },
  {
    "text": "running in staging in production then",
    "start": "363060",
    "end": "365340"
  },
  {
    "text": "you also like can track the different",
    "start": "365340",
    "end": "366600"
  },
  {
    "text": "versions of your model",
    "start": "366600",
    "end": "367979"
  },
  {
    "text": "and yeah",
    "start": "367979",
    "end": "369060"
  },
  {
    "text": "you know where they're running then we",
    "start": "369060",
    "end": "370860"
  },
  {
    "text": "have a lot of python services to to make",
    "start": "370860",
    "end": "373080"
  },
  {
    "text": "life of our data center it's easier",
    "start": "373080",
    "end": "375180"
  },
  {
    "text": "and the last one is seldenko it's what",
    "start": "375180",
    "end": "377759"
  },
  {
    "text": "we use to deploy models into production",
    "start": "377759",
    "end": "380000"
  },
  {
    "text": "and it takes a model and basically it",
    "start": "380000",
    "end": "382680"
  },
  {
    "text": "takes like you give it an S3 bucket or",
    "start": "382680",
    "end": "384780"
  },
  {
    "text": "GCS",
    "start": "384780",
    "end": "385860"
  },
  {
    "text": "you also say like which which Library",
    "start": "385860",
    "end": "389100"
  },
  {
    "text": "you use did you psychic land did you see",
    "start": "389100",
    "end": "391080"
  },
  {
    "text": "your Boost something then you're just",
    "start": "391080",
    "end": "392580"
  },
  {
    "text": "going to create a micro service for you",
    "start": "392580",
    "end": "394440"
  },
  {
    "text": "and then out of the box you have",
    "start": "394440",
    "end": "396060"
  },
  {
    "text": "automatic logging everything we use",
    "start": "396060",
    "end": "398160"
  },
  {
    "text": "Kafka a lot so then we log everything to",
    "start": "398160",
    "end": "399840"
  },
  {
    "text": "Kafka and then we push from Kafka to",
    "start": "399840",
    "end": "402600"
  },
  {
    "text": "Snowflake and then our data sentences",
    "start": "402600",
    "end": "404340"
  },
  {
    "text": "can have like dashboards and be like",
    "start": "404340",
    "end": "406319"
  },
  {
    "text": "okay like my model is doing pretty well",
    "start": "406319",
    "end": "408780"
  },
  {
    "text": "I also can compare it to the ground",
    "start": "408780",
    "end": "410220"
  },
  {
    "text": "truth and that they don't have to to",
    "start": "410220",
    "end": "412500"
  },
  {
    "text": "write code for that so you have that",
    "start": "412500",
    "end": "413759"
  },
  {
    "text": "automatically",
    "start": "413759",
    "end": "415199"
  },
  {
    "text": "then you have a b testing Canary",
    "start": "415199",
    "end": "417000"
  },
  {
    "text": "deployment",
    "start": "417000",
    "end": "418319"
  },
  {
    "text": "a lot of things so have an ml platform",
    "start": "418319",
    "end": "420479"
  },
  {
    "text": "but in the title there was reliable",
    "start": "420479",
    "end": "423240"
  },
  {
    "text": "so once an email platform but reliable",
    "start": "423240",
    "end": "426319"
  },
  {
    "text": "so like At first we deployed flights we",
    "start": "426319",
    "end": "429780"
  },
  {
    "text": "deployed it with that Argo CD because",
    "start": "429780",
    "end": "431400"
  },
  {
    "text": "we're not using Argo back then",
    "start": "431400",
    "end": "433500"
  },
  {
    "text": "we introduce our CD for flight so it's",
    "start": "433500",
    "end": "435900"
  },
  {
    "text": "been like Argo City for the ml platform",
    "start": "435900",
    "end": "438000"
  },
  {
    "text": "we only use it for flights but what's",
    "start": "438000",
    "end": "439680"
  },
  {
    "text": "really nice that then even our data",
    "start": "439680",
    "end": "441720"
  },
  {
    "text": "scientists can then you know they can",
    "start": "441720",
    "end": "443699"
  },
  {
    "text": "ask for resources they can add new",
    "start": "443699",
    "end": "445560"
  },
  {
    "text": "things to fly directly without us doing",
    "start": "445560",
    "end": "448020"
  },
  {
    "text": "it",
    "start": "448020",
    "end": "449340"
  },
  {
    "text": "um then we have the whole ml platform",
    "start": "449340",
    "end": "451020"
  },
  {
    "text": "and then we have Argo workflows that we",
    "start": "451020",
    "end": "454080"
  },
  {
    "text": "use with Gatling uh and a Gatling is an",
    "start": "454080",
    "end": "457560"
  },
  {
    "text": "open source load testing tool and for",
    "start": "457560",
    "end": "460500"
  },
  {
    "text": "the ml platform we use Argo workflow",
    "start": "460500",
    "end": "462060"
  },
  {
    "text": "with Gatling and then I'll talk more",
    "start": "462060",
    "end": "463919"
  },
  {
    "text": "about that later",
    "start": "463919",
    "end": "465479"
  },
  {
    "text": "but basically every ml model that is",
    "start": "465479",
    "end": "467639"
  },
  {
    "text": "deployed go through load testing and we",
    "start": "467639",
    "end": "470039"
  },
  {
    "text": "can make sure that it actually supports",
    "start": "470039",
    "end": "471660"
  },
  {
    "text": "the load we want to",
    "start": "471660",
    "end": "474560"
  },
  {
    "start": "474000",
    "end": "628000"
  },
  {
    "text": "so Argo CDN flight",
    "start": "475199",
    "end": "477180"
  },
  {
    "text": "how we use them so we use the cluster",
    "start": "477180",
    "end": "480120"
  },
  {
    "text": "bootstrapping with Argo CD so yeah I",
    "start": "480120",
    "end": "483539"
  },
  {
    "text": "said before but like we deployed flight",
    "start": "483539",
    "end": "485460"
  },
  {
    "text": "at first without using Argo CD",
    "start": "485460",
    "end": "487919"
  },
  {
    "text": "yeah I was not really happy with it",
    "start": "487919",
    "end": "489599"
  },
  {
    "text": "every day I would maybe cry in the",
    "start": "489599",
    "end": "491220"
  },
  {
    "text": "corner because you apply something wrong",
    "start": "491220",
    "end": "492599"
  },
  {
    "text": "everything's broken",
    "start": "492599",
    "end": "494099"
  },
  {
    "text": "now you don't have that anymore",
    "start": "494099",
    "end": "495960"
  },
  {
    "text": "so you're happy flight needs a lot of",
    "start": "495960",
    "end": "498539"
  },
  {
    "text": "apps a lot of different apps and",
    "start": "498539",
    "end": "501000"
  },
  {
    "text": "honestly without other CD you spend most",
    "start": "501000",
    "end": "503099"
  },
  {
    "text": "of your days like trying to apply things",
    "start": "503099",
    "end": "504539"
  },
  {
    "text": "and going to the right name space and",
    "start": "504539",
    "end": "506639"
  },
  {
    "text": "figure figuring it out what's broken so",
    "start": "506639",
    "end": "509759"
  },
  {
    "text": "you don't need that",
    "start": "509759",
    "end": "510960"
  },
  {
    "text": "we have no communities expects in the ml",
    "start": "510960",
    "end": "513599"
  },
  {
    "text": "platform so like Argo City has been",
    "start": "513599",
    "end": "515880"
  },
  {
    "text": "really helpful on that one as well you",
    "start": "515880",
    "end": "517560"
  },
  {
    "text": "know just to so that we can apply things",
    "start": "517560",
    "end": "520680"
  },
  {
    "text": "an easy way without becoming an expert",
    "start": "520680",
    "end": "523860"
  },
  {
    "text": "and without being asking also always the",
    "start": "523860",
    "end": "525899"
  },
  {
    "text": "infra team oh can you employ that for us",
    "start": "525899",
    "end": "527820"
  },
  {
    "text": "can you add that for us so like that's",
    "start": "527820",
    "end": "530640"
  },
  {
    "text": "been really helpful",
    "start": "530640",
    "end": "532140"
  },
  {
    "text": "we don't apply anything manually so we",
    "start": "532140",
    "end": "533940"
  },
  {
    "text": "don't need permissions",
    "start": "533940",
    "end": "535320"
  },
  {
    "text": "we don't need specific permissions you",
    "start": "535320",
    "end": "537000"
  },
  {
    "text": "know like to go to a specific namespace",
    "start": "537000",
    "end": "538800"
  },
  {
    "text": "or to apply specific resources Argo will",
    "start": "538800",
    "end": "541560"
  },
  {
    "text": "do it for us also it has rollbacks",
    "start": "541560",
    "end": "543420"
  },
  {
    "text": "because I break a lot of things",
    "start": "543420",
    "end": "545459"
  },
  {
    "text": "so when you when you apply something and",
    "start": "545459",
    "end": "547260"
  },
  {
    "text": "then you'll sort of get a roll back",
    "start": "547260",
    "end": "548519"
  },
  {
    "text": "easily",
    "start": "548519",
    "end": "550440"
  },
  {
    "text": "and flight supports plugins so let's say",
    "start": "550440",
    "end": "552959"
  },
  {
    "text": "you have flight you're happy but then",
    "start": "552959",
    "end": "554940"
  },
  {
    "text": "you want to use spark and kubernetes",
    "start": "554940",
    "end": "556380"
  },
  {
    "text": "then you can",
    "start": "556380",
    "end": "557580"
  },
  {
    "text": "and then you create your PR algo CD will",
    "start": "557580",
    "end": "560760"
  },
  {
    "text": "like pick it up",
    "start": "560760",
    "end": "562200"
  },
  {
    "text": "then deploy it to flight and then you",
    "start": "562200",
    "end": "564000"
  },
  {
    "text": "can have a look as well yourself you can",
    "start": "564000",
    "end": "565500"
  },
  {
    "text": "look at the UI",
    "start": "565500",
    "end": "567480"
  },
  {
    "text": "and be like okay like my plugin is",
    "start": "567480",
    "end": "570000"
  },
  {
    "text": "working now I have now spark running or",
    "start": "570000",
    "end": "571920"
  },
  {
    "text": "I have the MPI operator or whatever",
    "start": "571920",
    "end": "574019"
  },
  {
    "text": "plugin you want to add that they support",
    "start": "574019",
    "end": "576959"
  },
  {
    "text": "and yeah data centers can do that so",
    "start": "576959",
    "end": "579540"
  },
  {
    "text": "that I don't need to do it then I can go",
    "start": "579540",
    "end": "581040"
  },
  {
    "text": "on a holiday more often so that I'm",
    "start": "581040",
    "end": "582540"
  },
  {
    "text": "really happy",
    "start": "582540",
    "end": "583440"
  },
  {
    "text": "so that's why we use Argo CD and why we",
    "start": "583440",
    "end": "585779"
  },
  {
    "text": "use it with flights",
    "start": "585779",
    "end": "588360"
  },
  {
    "text": "then we also have a whole like so you",
    "start": "588360",
    "end": "591839"
  },
  {
    "text": "have telephone modules and we have our",
    "start": "591839",
    "end": "593399"
  },
  {
    "text": "own one which is a lot of wrappers",
    "start": "593399",
    "end": "595320"
  },
  {
    "text": "around the terraform modules",
    "start": "595320",
    "end": "597240"
  },
  {
    "text": "so that also what I like to not do is to",
    "start": "597240",
    "end": "600899"
  },
  {
    "text": "write terraform",
    "start": "600899",
    "end": "602100"
  },
  {
    "text": "so like that's what the infrared team is",
    "start": "602100",
    "end": "604980"
  },
  {
    "text": "doing and developer experience team is",
    "start": "604980",
    "end": "606300"
  },
  {
    "text": "doing as well they provide modules so",
    "start": "606300",
    "end": "608640"
  },
  {
    "text": "let's say you need to install psyllium",
    "start": "608640",
    "end": "610620"
  },
  {
    "text": "on your on your cluster then you can",
    "start": "610620",
    "end": "612899"
  },
  {
    "text": "just call the module and then Argo City",
    "start": "612899",
    "end": "614519"
  },
  {
    "text": "picks it up and then install this little",
    "start": "614519",
    "end": "616200"
  },
  {
    "text": "fly cluster for a use case but I don't",
    "start": "616200",
    "end": "618540"
  },
  {
    "text": "have to write all the terraform that",
    "start": "618540",
    "end": "620160"
  },
  {
    "text": "would be a lot of terraform I can just",
    "start": "620160",
    "end": "621899"
  },
  {
    "text": "call the module and that's that's what",
    "start": "621899",
    "end": "624300"
  },
  {
    "text": "we have that's what we have argue CD and",
    "start": "624300",
    "end": "626279"
  },
  {
    "text": "flight",
    "start": "626279",
    "end": "628640"
  },
  {
    "text": "yeah maybe for people that don't know",
    "start": "629399",
    "end": "631320"
  },
  {
    "text": "flight because it's very specific also",
    "start": "631320",
    "end": "632940"
  },
  {
    "text": "to to ml so the flight",
    "start": "632940",
    "end": "636120"
  },
  {
    "text": "um is what we use now instead of airflow",
    "start": "636120",
    "end": "637860"
  },
  {
    "text": "for ML workflows and why it's because",
    "start": "637860",
    "end": "640500"
  },
  {
    "text": "first discovered is native so pretty",
    "start": "640500",
    "end": "642959"
  },
  {
    "text": "happy about that it also supports",
    "start": "642959",
    "end": "645360"
  },
  {
    "text": "automatic parallelization so let's say",
    "start": "645360",
    "end": "647880"
  },
  {
    "text": "you have different tasks running and you",
    "start": "647880",
    "end": "650700"
  },
  {
    "text": "know they don't need one each one one",
    "start": "650700",
    "end": "652079"
  },
  {
    "text": "others you can just like have one that",
    "start": "652079",
    "end": "654000"
  },
  {
    "text": "is I don't know like fetching some data",
    "start": "654000",
    "end": "655680"
  },
  {
    "text": "the other one that is doing",
    "start": "655680",
    "end": "657720"
  },
  {
    "text": "I don't know we'll do whatever it's",
    "start": "657720",
    "end": "659399"
  },
  {
    "text": "doing uh but they don't need one each",
    "start": "659399",
    "end": "661380"
  },
  {
    "text": "other so then Floyd will paralyze",
    "start": "661380",
    "end": "663000"
  },
  {
    "text": "everything automatically you don't have",
    "start": "663000",
    "end": "664500"
  },
  {
    "text": "to think about that you don't have to",
    "start": "664500",
    "end": "666180"
  },
  {
    "text": "declare your dependency you don't have",
    "start": "666180",
    "end": "667320"
  },
  {
    "text": "to declare your test be like oh yeah",
    "start": "667320",
    "end": "668579"
  },
  {
    "text": "please run this one before the other",
    "start": "668579",
    "end": "670800"
  },
  {
    "text": "they will figure everything themselves",
    "start": "670800",
    "end": "673079"
  },
  {
    "text": "you have reproducible pipelines really",
    "start": "673079",
    "end": "675720"
  },
  {
    "text": "important for ML you don't want your",
    "start": "675720",
    "end": "677760"
  },
  {
    "text": "pipelines that produce an amazing model",
    "start": "677760",
    "end": "680100"
  },
  {
    "text": "to be like oh which one was it which",
    "start": "680100",
    "end": "681779"
  },
  {
    "text": "version was it so that's",
    "start": "681779",
    "end": "684000"
  },
  {
    "text": "um that's also why we use it it supports",
    "start": "684000",
    "end": "686100"
  },
  {
    "text": "caching and caching is really good",
    "start": "686100",
    "end": "688860"
  },
  {
    "text": "um let's say your workflow takes six",
    "start": "688860",
    "end": "691200"
  },
  {
    "text": "hours",
    "start": "691200",
    "end": "691980"
  },
  {
    "text": "to finish like four hours are going and",
    "start": "691980",
    "end": "695579"
  },
  {
    "text": "like and then everyone probably crashes",
    "start": "695579",
    "end": "697140"
  },
  {
    "text": "you want to restart everything again you",
    "start": "697140",
    "end": "699120"
  },
  {
    "text": "don't want to like lose six hours so",
    "start": "699120",
    "end": "701100"
  },
  {
    "text": "then you support you have caching flight",
    "start": "701100",
    "end": "702660"
  },
  {
    "text": "will pick it up everything and then you",
    "start": "702660",
    "end": "704640"
  },
  {
    "text": "only need to wait two hours instead of",
    "start": "704640",
    "end": "706500"
  },
  {
    "text": "six",
    "start": "706500",
    "end": "708660"
  },
  {
    "text": "different sdks we only use python in the",
    "start": "708660",
    "end": "712320"
  },
  {
    "text": "ml platform team but we have other teams",
    "start": "712320",
    "end": "715200"
  },
  {
    "text": "that are using Scala and they're",
    "start": "715200",
    "end": "717300"
  },
  {
    "text": "actually going to use flight soon and",
    "start": "717300",
    "end": "719339"
  },
  {
    "text": "yeah flight supports different sdks as",
    "start": "719339",
    "end": "721079"
  },
  {
    "text": "well so if you want to use something",
    "start": "721079",
    "end": "722339"
  },
  {
    "text": "else than python you can",
    "start": "722339",
    "end": "724800"
  },
  {
    "text": "and the best thing in my opinion Dynamic",
    "start": "724800",
    "end": "727560"
  },
  {
    "text": "workflows so instead of saying okay like",
    "start": "727560",
    "end": "731399"
  },
  {
    "text": "we are in 23 countries maybe we want to",
    "start": "731399",
    "end": "734100"
  },
  {
    "text": "deploy a model we want to train a model",
    "start": "734100",
    "end": "735720"
  },
  {
    "text": "per country you don't want to define a",
    "start": "735720",
    "end": "738000"
  },
  {
    "text": "new code like oh yeah four are in 23",
    "start": "738000",
    "end": "741000"
  },
  {
    "text": "because then if you add a new country",
    "start": "741000",
    "end": "742740"
  },
  {
    "text": "then you need to change your code then",
    "start": "742740",
    "end": "744720"
  },
  {
    "text": "well you don't really want to do that so",
    "start": "744720",
    "end": "746940"
  },
  {
    "text": "then with flight you can say like please",
    "start": "746940",
    "end": "748740"
  },
  {
    "text": "powerlize on this list then it reads the",
    "start": "748740",
    "end": "750779"
  },
  {
    "text": "list and then it will create the task",
    "start": "750779",
    "end": "752360"
  },
  {
    "text": "depending on the on the size of your",
    "start": "752360",
    "end": "754380"
  },
  {
    "text": "list",
    "start": "754380",
    "end": "755519"
  },
  {
    "text": "like 23 is an example we are in more",
    "start": "755519",
    "end": "758640"
  },
  {
    "text": "than 400 cities imagine if you have to",
    "start": "758640",
    "end": "760920"
  },
  {
    "text": "change every time we we go to a new city",
    "start": "760920",
    "end": "763320"
  },
  {
    "text": "that would be annoying so yeah it",
    "start": "763320",
    "end": "765180"
  },
  {
    "text": "supports that out of the box",
    "start": "765180",
    "end": "766820"
  },
  {
    "text": "and that's been pretty handy and I have",
    "start": "766820",
    "end": "769800"
  },
  {
    "text": "a use case that I will talk about at the",
    "start": "769800",
    "end": "771180"
  },
  {
    "text": "end where I was even surprised we could",
    "start": "771180",
    "end": "773399"
  },
  {
    "text": "do things in our data centers did it",
    "start": "773399",
    "end": "777200"
  },
  {
    "text": "what does it look like I don't think you",
    "start": "778519",
    "end": "781440"
  },
  {
    "text": "can see anything in the back because",
    "start": "781440",
    "end": "783240"
  },
  {
    "text": "it's very dark so I'm sorry uh yeah you",
    "start": "783240",
    "end": "786300"
  },
  {
    "text": "can't see anything but you basically you",
    "start": "786300",
    "end": "789720"
  },
  {
    "text": "write normal python",
    "start": "789720",
    "end": "791279"
  },
  {
    "text": "and then you just add decorators uh so",
    "start": "791279",
    "end": "793800"
  },
  {
    "text": "you're gonna be like okay one decorator",
    "start": "793800",
    "end": "795000"
  },
  {
    "text": "which is going to be a workflow",
    "start": "795000",
    "end": "797040"
  },
  {
    "text": "and then another one which is going to",
    "start": "797040",
    "end": "798839"
  },
  {
    "text": "be a task and then the flight will be",
    "start": "798839",
    "end": "800700"
  },
  {
    "text": "like okay that's something I recognize",
    "start": "800700",
    "end": "802920"
  },
  {
    "text": "you can also run everything locally like",
    "start": "802920",
    "end": "805440"
  },
  {
    "text": "it's normal python if you run it locally",
    "start": "805440",
    "end": "806940"
  },
  {
    "text": "and then if you if you run it in the",
    "start": "806940",
    "end": "808860"
  },
  {
    "text": "cluster then flight will",
    "start": "808860",
    "end": "810420"
  },
  {
    "text": "um will be like oh yeah I know that let",
    "start": "810420",
    "end": "812700"
  },
  {
    "text": "me run workflows and tasks and even",
    "start": "812700",
    "end": "814740"
  },
  {
    "text": "better because then I have another",
    "start": "814740",
    "end": "817079"
  },
  {
    "text": "example",
    "start": "817079",
    "end": "819000"
  },
  {
    "text": "but you can't see anything in the back",
    "start": "819000",
    "end": "821279"
  },
  {
    "text": "but yeah it's what we use for dynamic",
    "start": "821279",
    "end": "823620"
  },
  {
    "text": "workflows",
    "start": "823620",
    "end": "824880"
  },
  {
    "text": "and that's what I was saying before like",
    "start": "824880",
    "end": "827399"
  },
  {
    "text": "this one is doing cross validations for",
    "start": "827399",
    "end": "829019"
  },
  {
    "text": "all the ml models you have",
    "start": "829019",
    "end": "831500"
  },
  {
    "text": "and you are going to do cross radiation",
    "start": "831500",
    "end": "835079"
  },
  {
    "text": "on all the ML on all the ml models but",
    "start": "835079",
    "end": "837420"
  },
  {
    "text": "you don't know how many you have and",
    "start": "837420",
    "end": "838800"
  },
  {
    "text": "then flight will figure that out itself",
    "start": "838800",
    "end": "841800"
  },
  {
    "text": "and then do cross validation and then",
    "start": "841800",
    "end": "843959"
  },
  {
    "text": "return results",
    "start": "843959",
    "end": "845220"
  },
  {
    "text": "and basically that's it like you don't",
    "start": "845220",
    "end": "848040"
  },
  {
    "text": "need to do anything else then cooling",
    "start": "848040",
    "end": "849779"
  },
  {
    "text": "The Decorator dynamic",
    "start": "849779",
    "end": "852240"
  },
  {
    "text": "so that's nice sorry for the end for the",
    "start": "852240",
    "end": "855060"
  },
  {
    "text": "back",
    "start": "855060",
    "end": "856800"
  },
  {
    "start": "856000",
    "end": "983000"
  },
  {
    "text": "but yeah then we use Argo workflows and",
    "start": "856800",
    "end": "858899"
  },
  {
    "text": "gapling",
    "start": "858899",
    "end": "860160"
  },
  {
    "text": "for people I guess Gatling I don't know",
    "start": "860160",
    "end": "862500"
  },
  {
    "text": "if that's very famous actually but it's",
    "start": "862500",
    "end": "865079"
  },
  {
    "text": "an open source load testing solution",
    "start": "865079",
    "end": "868320"
  },
  {
    "text": "and it what we use it for and what it",
    "start": "868320",
    "end": "870480"
  },
  {
    "text": "allows us to it's like to script or",
    "start": "870480",
    "end": "872160"
  },
  {
    "text": "testing scenarios and automate our tests",
    "start": "872160",
    "end": "876120"
  },
  {
    "text": "it provides a visual reports that is",
    "start": "876120",
    "end": "878339"
  },
  {
    "text": "actually nice to look at and you can",
    "start": "878339",
    "end": "880620"
  },
  {
    "text": "really like you have your app and you",
    "start": "880620",
    "end": "882420"
  },
  {
    "text": "should be able to understand fairly",
    "start": "882420",
    "end": "883620"
  },
  {
    "text": "quickly what's happening what's wrong",
    "start": "883620",
    "end": "885000"
  },
  {
    "text": "with your app how it behaves if you if",
    "start": "885000",
    "end": "887579"
  },
  {
    "text": "you add more load and everything I also",
    "start": "887579",
    "end": "889560"
  },
  {
    "text": "have examples of the of the report",
    "start": "889560",
    "end": "892320"
  },
  {
    "text": "if you want to and if you want to be",
    "start": "892320",
    "end": "893820"
  },
  {
    "text": "really fancy you have continuous load",
    "start": "893820",
    "end": "895920"
  },
  {
    "text": "testing we don't use it in the ml",
    "start": "895920",
    "end": "898380"
  },
  {
    "text": "platform because rml models they don't",
    "start": "898380",
    "end": "899940"
  },
  {
    "text": "need that but for like your different",
    "start": "899940",
    "end": "901740"
  },
  {
    "text": "apps let's say you have an app that is",
    "start": "901740",
    "end": "903899"
  },
  {
    "text": "really important for your company maybe",
    "start": "903899",
    "end": "905459"
  },
  {
    "text": "you want to have continuous loop testing",
    "start": "905459",
    "end": "906899"
  },
  {
    "text": "so every time you make a commit on",
    "start": "906899",
    "end": "909120"
  },
  {
    "text": "GitHub then you run a small load test",
    "start": "909120",
    "end": "910860"
  },
  {
    "text": "just to make sure you don't add",
    "start": "910860",
    "end": "912060"
  },
  {
    "text": "regressions just to make sure you be",
    "start": "912060",
    "end": "913680"
  },
  {
    "text": "like okay my P99 is still like 20",
    "start": "913680",
    "end": "916079"
  },
  {
    "text": "milliseconds I'm happy",
    "start": "916079",
    "end": "918300"
  },
  {
    "text": "you can do that",
    "start": "918300",
    "end": "919860"
  },
  {
    "text": "everything is running on algo workflows",
    "start": "919860",
    "end": "921839"
  },
  {
    "text": "for us so it's been really nice and",
    "start": "921839",
    "end": "924660"
  },
  {
    "text": "what's nice as well is that",
    "start": "924660",
    "end": "926579"
  },
  {
    "text": "basically data scientists see Gatling",
    "start": "926579",
    "end": "928740"
  },
  {
    "text": "and they don't see Argo workflows",
    "start": "928740",
    "end": "930300"
  },
  {
    "text": "because they can be scared otherwise of",
    "start": "930300",
    "end": "932760"
  },
  {
    "text": "like you know like using other workflows",
    "start": "932760",
    "end": "934440"
  },
  {
    "text": "and writing all the yaml and everything",
    "start": "934440",
    "end": "936300"
  },
  {
    "text": "so",
    "start": "936300",
    "end": "937260"
  },
  {
    "text": "so they see the end results but they",
    "start": "937260",
    "end": "939600"
  },
  {
    "text": "don't see how to how to do it",
    "start": "939600",
    "end": "942240"
  },
  {
    "text": "and then yeah we have templates so you",
    "start": "942240",
    "end": "944699"
  },
  {
    "text": "have the ml model",
    "start": "944699",
    "end": "946199"
  },
  {
    "text": "then you just give the payload and the",
    "start": "946199",
    "end": "948000"
  },
  {
    "text": "name of the ml model and then we run",
    "start": "948000",
    "end": "949560"
  },
  {
    "text": "load test for you and then you see",
    "start": "949560",
    "end": "951480"
  },
  {
    "text": "results and you're happy or not",
    "start": "951480",
    "end": "954180"
  },
  {
    "text": "so that's what it looks like that's",
    "start": "954180",
    "end": "956160"
  },
  {
    "text": "better for the back right when it's",
    "start": "956160",
    "end": "958079"
  },
  {
    "text": "actually white so yeah you have the",
    "start": "958079",
    "end": "959820"
  },
  {
    "text": "template then you give like number of",
    "start": "959820",
    "end": "961380"
  },
  {
    "text": "requests per second maximum how long you",
    "start": "961380",
    "end": "964019"
  },
  {
    "text": "want the wrap up to take how long do you",
    "start": "964019",
    "end": "965639"
  },
  {
    "text": "want your test to last for",
    "start": "965639",
    "end": "967199"
  },
  {
    "text": "then you don't see it here but you also",
    "start": "967199",
    "end": "969540"
  },
  {
    "text": "provide the payload and the name of the",
    "start": "969540",
    "end": "971399"
  },
  {
    "text": "model then you click submit",
    "start": "971399",
    "end": "973680"
  },
  {
    "text": "and if you have only one model then I'll",
    "start": "973680",
    "end": "975899"
  },
  {
    "text": "go workflow will run one test if you",
    "start": "975899",
    "end": "977940"
  },
  {
    "text": "have 400 like we do sometimes then it",
    "start": "977940",
    "end": "980519"
  },
  {
    "text": "was 400 tests in parallel",
    "start": "980519",
    "end": "983839"
  },
  {
    "start": "983000",
    "end": "1010000"
  },
  {
    "text": "one of the example you have uh that's",
    "start": "984300",
    "end": "986820"
  },
  {
    "text": "that yeah one visual report response",
    "start": "986820",
    "end": "988860"
  },
  {
    "text": "time you quickly see like okay it's good",
    "start": "988860",
    "end": "990779"
  },
  {
    "text": "or it's bad and that one is just an",
    "start": "990779",
    "end": "992880"
  },
  {
    "text": "example so like we don't deploy anything",
    "start": "992880",
    "end": "994260"
  },
  {
    "text": "that has like less than 100 milliseconds",
    "start": "994260",
    "end": "996480"
  },
  {
    "text": "that we usually are like less than 25",
    "start": "996480",
    "end": "998880"
  },
  {
    "text": "milliseconds",
    "start": "998880",
    "end": "1000199"
  },
  {
    "text": "uh but yeah we have a look at those then",
    "start": "1000199",
    "end": "1002480"
  },
  {
    "text": "you have a summary you can have a look",
    "start": "1002480",
    "end": "1003860"
  },
  {
    "text": "quickly like here my P99 is happy like I",
    "start": "1003860",
    "end": "1006380"
  },
  {
    "text": "have errors on this specific endpoint",
    "start": "1006380",
    "end": "1008600"
  },
  {
    "text": "whatever",
    "start": "1008600",
    "end": "1010519"
  },
  {
    "start": "1010000",
    "end": "1056000"
  },
  {
    "text": "and then what you can do is that you can",
    "start": "1010519",
    "end": "1012740"
  },
  {
    "text": "also like",
    "start": "1012740",
    "end": "1013880"
  },
  {
    "text": "increase the number of active users uh",
    "start": "1013880",
    "end": "1016220"
  },
  {
    "text": "because you can be like okay my ml model",
    "start": "1016220",
    "end": "1017899"
  },
  {
    "text": "works perfectly well if I have one user",
    "start": "1017899",
    "end": "1020839"
  },
  {
    "text": "but then what if you have 10 what if you",
    "start": "1020839",
    "end": "1022880"
  },
  {
    "text": "have 20 and then you can like really see",
    "start": "1022880",
    "end": "1024740"
  },
  {
    "text": "and really have a look and how many",
    "start": "1024740",
    "end": "1026780"
  },
  {
    "text": "users you have and then you can look at",
    "start": "1026780",
    "end": "1028880"
  },
  {
    "text": "the response time distribution",
    "start": "1028880",
    "end": "1031938"
  },
  {
    "text": "also you can look at the percentiles",
    "start": "1031939",
    "end": "1034880"
  },
  {
    "text": "over time so you can really have a look",
    "start": "1034880",
    "end": "1036319"
  },
  {
    "text": "and be like yeah most of the time I'm",
    "start": "1036319",
    "end": "1038120"
  },
  {
    "text": "happy most of the time we're happy but",
    "start": "1038120",
    "end": "1039918"
  },
  {
    "text": "sometimes we have spikes so then is it",
    "start": "1039919",
    "end": "1042319"
  },
  {
    "text": "correlated to the amount of users you",
    "start": "1042319",
    "end": "1043880"
  },
  {
    "text": "add or like different things you know",
    "start": "1043880",
    "end": "1045438"
  },
  {
    "text": "then you can like quickly maybe have an",
    "start": "1045439",
    "end": "1049040"
  },
  {
    "text": "idea",
    "start": "1049040",
    "end": "1051340"
  },
  {
    "text": "uh yeah then you have number of hookahs",
    "start": "1051500",
    "end": "1053419"
  },
  {
    "text": "per second with the number of active",
    "start": "1053419",
    "end": "1055100"
  },
  {
    "text": "users and then",
    "start": "1055100",
    "end": "1057260"
  },
  {
    "start": "1056000",
    "end": "1111000"
  },
  {
    "text": "sorry again for the back you have",
    "start": "1057260",
    "end": "1059419"
  },
  {
    "text": "accessions uh so get linger sessions is",
    "start": "1059419",
    "end": "1062440"
  },
  {
    "text": "what we use to make sure that when you",
    "start": "1062440",
    "end": "1066140"
  },
  {
    "text": "run load tests",
    "start": "1066140",
    "end": "1067600"
  },
  {
    "text": "you you have some rules like we put some",
    "start": "1067600",
    "end": "1070100"
  },
  {
    "text": "rules in place that is like okay we only",
    "start": "1070100",
    "end": "1072620"
  },
  {
    "text": "make it pass if all our requests are",
    "start": "1072620",
    "end": "1074900"
  },
  {
    "text": "less than 100 millisecond or we only",
    "start": "1074900",
    "end": "1077299"
  },
  {
    "text": "make it pass if only five percent of the",
    "start": "1077299",
    "end": "1079460"
  },
  {
    "text": "requests are failing and then uh then it",
    "start": "1079460",
    "end": "1082280"
  },
  {
    "text": "will like report everything in GitHub",
    "start": "1082280",
    "end": "1084500"
  },
  {
    "text": "and then you'll have the GitHub statuses",
    "start": "1084500",
    "end": "1086539"
  },
  {
    "text": "and then be like okay you can merge only",
    "start": "1086539",
    "end": "1088580"
  },
  {
    "text": "and only if you respect the successions",
    "start": "1088580",
    "end": "1090620"
  },
  {
    "text": "so it allows you to to like redeploy in",
    "start": "1090620",
    "end": "1093980"
  },
  {
    "text": "a reliable way",
    "start": "1093980",
    "end": "1095360"
  },
  {
    "text": "uh without being like okay like without",
    "start": "1095360",
    "end": "1097340"
  },
  {
    "text": "having to look at the reports every time",
    "start": "1097340",
    "end": "1099799"
  },
  {
    "text": "you you push something be like you'd be",
    "start": "1099799",
    "end": "1101780"
  },
  {
    "text": "like yeah",
    "start": "1101780",
    "end": "1102740"
  },
  {
    "text": "everything is less than 100 millisecond",
    "start": "1102740",
    "end": "1104360"
  },
  {
    "text": "I'm pretty happy I can merge all my",
    "start": "1104360",
    "end": "1106580"
  },
  {
    "text": "tests are working",
    "start": "1106580",
    "end": "1107900"
  },
  {
    "text": "so yeah you have those accessions that's",
    "start": "1107900",
    "end": "1109820"
  },
  {
    "text": "been really nice",
    "start": "1109820",
    "end": "1112400"
  },
  {
    "start": "1111000",
    "end": "1193000"
  },
  {
    "text": "so yeah maybe why we went with that I'll",
    "start": "1112400",
    "end": "1114679"
  },
  {
    "text": "go workflows in Gatling it's like well",
    "start": "1114679",
    "end": "1116720"
  },
  {
    "text": "both like they can handle large scale",
    "start": "1116720",
    "end": "1118460"
  },
  {
    "text": "workloads so so like they can do way",
    "start": "1118460",
    "end": "1120679"
  },
  {
    "text": "better than any of the ml model we",
    "start": "1120679",
    "end": "1122240"
  },
  {
    "text": "produce usually so like you're really",
    "start": "1122240",
    "end": "1124760"
  },
  {
    "text": "sure that your own model was gonna like",
    "start": "1124760",
    "end": "1126380"
  },
  {
    "text": "work really well with the load test you",
    "start": "1126380",
    "end": "1128720"
  },
  {
    "text": "have",
    "start": "1128720",
    "end": "1130460"
  },
  {
    "text": "impress",
    "start": "1130460",
    "end": "1131960"
  },
  {
    "text": "my screen is gone my screen is back uh",
    "start": "1131960",
    "end": "1134720"
  },
  {
    "text": "then you have parallelism so yeah you",
    "start": "1134720",
    "end": "1136640"
  },
  {
    "text": "can like Leverage awkward workflows uh",
    "start": "1136640",
    "end": "1139700"
  },
  {
    "text": "to manage multiple tests uh like we have",
    "start": "1139700",
    "end": "1142280"
  },
  {
    "text": "one model uh we run we train it on 460",
    "start": "1142280",
    "end": "1146360"
  },
  {
    "text": "cities and then we load test it on 460",
    "start": "1146360",
    "end": "1149780"
  },
  {
    "text": "deployments and we do that in parallel",
    "start": "1149780",
    "end": "1152480"
  },
  {
    "text": "so then we can make sure that okay",
    "start": "1152480",
    "end": "1154220"
  },
  {
    "text": "everything working as expected for all",
    "start": "1154220",
    "end": "1156799"
  },
  {
    "text": "the cities we have so we can then deploy",
    "start": "1156799",
    "end": "1159380"
  },
  {
    "text": "it and be happy and be more confident",
    "start": "1159380",
    "end": "1163160"
  },
  {
    "text": "automated testing it's what I said",
    "start": "1163160",
    "end": "1165380"
  },
  {
    "text": "before as well with the assertions so if",
    "start": "1165380",
    "end": "1167660"
  },
  {
    "text": "you want you can have everything in",
    "start": "1167660",
    "end": "1168679"
  },
  {
    "text": "GitHub then all the accessions then I'll",
    "start": "1168679",
    "end": "1170660"
  },
  {
    "text": "go work through",
    "start": "1170660",
    "end": "1171919"
  },
  {
    "text": "it's going to trigger everything then",
    "start": "1171919",
    "end": "1173419"
  },
  {
    "text": "report back into our city cicd pipelines",
    "start": "1173419",
    "end": "1176059"
  },
  {
    "text": "and so you can have also like your kind",
    "start": "1176059",
    "end": "1178100"
  },
  {
    "text": "of visual reports in GitHub",
    "start": "1178100",
    "end": "1180799"
  },
  {
    "text": "and yeah you can make sure that",
    "start": "1180799",
    "end": "1182240"
  },
  {
    "text": "everything works under high load",
    "start": "1182240",
    "end": "1183860"
  },
  {
    "text": "conditions",
    "start": "1183860",
    "end": "1184820"
  },
  {
    "text": "so at least you're you're pretty sure",
    "start": "1184820",
    "end": "1186740"
  },
  {
    "text": "that it's going to be reliable with that",
    "start": "1186740",
    "end": "1188539"
  },
  {
    "text": "regard maybe you would file for",
    "start": "1188539",
    "end": "1190220"
  },
  {
    "text": "something else but at least the load",
    "start": "1190220",
    "end": "1191600"
  },
  {
    "text": "test you're happy",
    "start": "1191600",
    "end": "1194360"
  },
  {
    "start": "1193000",
    "end": "1333000"
  },
  {
    "text": "and the use case I was talking about",
    "start": "1194360",
    "end": "1196880"
  },
  {
    "text": "um so yeah we have we predict traffic",
    "start": "1196880",
    "end": "1199580"
  },
  {
    "text": "for each City we're in we are in 463",
    "start": "1199580",
    "end": "1203539"
  },
  {
    "text": "cities something because traffic is",
    "start": "1203539",
    "end": "1206120"
  },
  {
    "text": "different in its City so that's the idea",
    "start": "1206120",
    "end": "1208760"
  },
  {
    "text": "is like yeah you really want to predict",
    "start": "1208760",
    "end": "1210320"
  },
  {
    "text": "how long it's going to take for you to",
    "start": "1210320",
    "end": "1212179"
  },
  {
    "text": "deliver the food for us and deliver the",
    "start": "1212179",
    "end": "1213740"
  },
  {
    "text": "food depending on the city because",
    "start": "1213740",
    "end": "1215360"
  },
  {
    "text": "traffic will be very different in Tel",
    "start": "1215360",
    "end": "1216799"
  },
  {
    "text": "Aviv than in Helsinki",
    "start": "1216799",
    "end": "1219559"
  },
  {
    "text": "oh yeah let's say you're a data",
    "start": "1219559",
    "end": "1220820"
  },
  {
    "text": "scientist you're like okay I need my",
    "start": "1220820",
    "end": "1222860"
  },
  {
    "text": "gpus so and then like we have gpus",
    "start": "1222860",
    "end": "1225260"
  },
  {
    "text": "running already but then you might need",
    "start": "1225260",
    "end": "1227480"
  },
  {
    "text": "some different gpus you know you might",
    "start": "1227480",
    "end": "1228980"
  },
  {
    "text": "need one with more memory you might need",
    "start": "1228980",
    "end": "1231020"
  },
  {
    "text": "special ones uh well you can do that you",
    "start": "1231020",
    "end": "1233720"
  },
  {
    "text": "create the pl we accepted Argo deploys",
    "start": "1233720",
    "end": "1237080"
  },
  {
    "text": "everything and then you can also like",
    "start": "1237080",
    "end": "1238940"
  },
  {
    "text": "have a look and like look at the alerts",
    "start": "1238940",
    "end": "1240740"
  },
  {
    "text": "make sure that everything's deployed",
    "start": "1240740",
    "end": "1241760"
  },
  {
    "text": "correctly so that's the first step",
    "start": "1241760",
    "end": "1244100"
  },
  {
    "text": "second step if you create a workflow in",
    "start": "1244100",
    "end": "1245960"
  },
  {
    "text": "flight",
    "start": "1245960",
    "end": "1246799"
  },
  {
    "text": "be like yeah that's my training workflow",
    "start": "1246799",
    "end": "1249799"
  },
  {
    "text": "then you create a dynamic task that is",
    "start": "1249799",
    "end": "1251720"
  },
  {
    "text": "based on cities so you're gonna be like",
    "start": "1251720",
    "end": "1253340"
  },
  {
    "text": "okay for all the cities we have please",
    "start": "1253340",
    "end": "1255740"
  },
  {
    "text": "train the model",
    "start": "1255740",
    "end": "1258140"
  },
  {
    "text": "then we have",
    "start": "1258140",
    "end": "1260600"
  },
  {
    "text": "um we have a toolkit that uh there is an",
    "start": "1260600",
    "end": "1263360"
  },
  {
    "text": "ml toolkit that every data scientist is",
    "start": "1263360",
    "end": "1265220"
  },
  {
    "text": "using so then in this toolkit we have",
    "start": "1265220",
    "end": "1268340"
  },
  {
    "text": "um we have python code that is like yeah",
    "start": "1268340",
    "end": "1270679"
  },
  {
    "text": "please create a load test for that",
    "start": "1270679",
    "end": "1272960"
  },
  {
    "text": "specific ml deployment so that data",
    "start": "1272960",
    "end": "1275600"
  },
  {
    "text": "centers don't have to do it themselves",
    "start": "1275600",
    "end": "1277220"
  },
  {
    "text": "because it's always going to be the same",
    "start": "1277220",
    "end": "1278720"
  },
  {
    "text": "code anyway",
    "start": "1278720",
    "end": "1281140"
  },
  {
    "text": "then you load the test uh load test per",
    "start": "1281539",
    "end": "1284419"
  },
  {
    "text": "City in parallel so yeah 460 cities",
    "start": "1284419",
    "end": "1286340"
  },
  {
    "text": "running in parallel that's also why you",
    "start": "1286340",
    "end": "1288679"
  },
  {
    "text": "know the assessions are really important",
    "start": "1288679",
    "end": "1290000"
  },
  {
    "text": "because you don't want to look at 460",
    "start": "1290000",
    "end": "1291559"
  },
  {
    "text": "reports you're going to be like okay I",
    "start": "1291559",
    "end": "1293840"
  },
  {
    "text": "have all my sessions everything looks",
    "start": "1293840",
    "end": "1295580"
  },
  {
    "text": "green I'm happy I think we should be",
    "start": "1295580",
    "end": "1298760"
  },
  {
    "text": "good",
    "start": "1298760",
    "end": "1300860"
  },
  {
    "text": "then if you pass your sessions you can",
    "start": "1300860",
    "end": "1302960"
  },
  {
    "text": "promote the models and be like more",
    "start": "1302960",
    "end": "1304460"
  },
  {
    "text": "confident",
    "start": "1304460",
    "end": "1305480"
  },
  {
    "text": "that it's going to work",
    "start": "1305480",
    "end": "1307220"
  },
  {
    "text": "or what you can also do is then you can",
    "start": "1307220",
    "end": "1309740"
  },
  {
    "text": "you pass the assertions but you can also",
    "start": "1309740",
    "end": "1311780"
  },
  {
    "text": "make sure that you actually like not",
    "start": "1311780",
    "end": "1313640"
  },
  {
    "text": "worse than the previous models because",
    "start": "1313640",
    "end": "1315559"
  },
  {
    "text": "maybe your ml model is really good with",
    "start": "1315559",
    "end": "1317299"
  },
  {
    "text": "the ml metrics but if you're P99 went",
    "start": "1317299",
    "end": "1319460"
  },
  {
    "text": "from 20 milliseconds to 200",
    "start": "1319460",
    "end": "1321500"
  },
  {
    "text": "okay maybe there's there's a right",
    "start": "1321500",
    "end": "1323059"
  },
  {
    "text": "balance to find here uh so that's that's",
    "start": "1323059",
    "end": "1325880"
  },
  {
    "text": "our use case and yeah this use case is",
    "start": "1325880",
    "end": "1328280"
  },
  {
    "text": "using everything we have so I'll go see",
    "start": "1328280",
    "end": "1330559"
  },
  {
    "text": "the flight Argo workflows and Gatling",
    "start": "1330559",
    "end": "1334100"
  },
  {
    "start": "1333000",
    "end": "1393000"
  },
  {
    "text": "and our future work uh so the first one",
    "start": "1334100",
    "end": "1336919"
  },
  {
    "text": "we want to add support for triton",
    "start": "1336919",
    "end": "1338780"
  },
  {
    "text": "inference uh we start to use Triton more",
    "start": "1338780",
    "end": "1340940"
  },
  {
    "text": "and more the way Triton Works to be",
    "start": "1340940",
    "end": "1342799"
  },
  {
    "text": "different to every other library and so",
    "start": "1342799",
    "end": "1346820"
  },
  {
    "text": "yeah we want to add that to other",
    "start": "1346820",
    "end": "1348380"
  },
  {
    "text": "support for our load testing tool",
    "start": "1348380",
    "end": "1351200"
  },
  {
    "text": "at one point I hope like I have dreams",
    "start": "1351200",
    "end": "1353840"
  },
  {
    "text": "that we can like load test 100 of the ml",
    "start": "1353840",
    "end": "1356240"
  },
  {
    "text": "models that are going to production",
    "start": "1356240",
    "end": "1357820"
  },
  {
    "text": "so that means a lot of advocacy work",
    "start": "1357820",
    "end": "1360559"
  },
  {
    "text": "that means a lot of abstractions as well",
    "start": "1360559",
    "end": "1363200"
  },
  {
    "text": "for data scientists because they might",
    "start": "1363200",
    "end": "1366020"
  },
  {
    "text": "be like yeah it's cool what you're doing",
    "start": "1366020",
    "end": "1367520"
  },
  {
    "text": "is cool but I don't really want to spend",
    "start": "1367520",
    "end": "1369080"
  },
  {
    "text": "time on it uh so it's like yeah how do",
    "start": "1369080",
    "end": "1371720"
  },
  {
    "text": "we make that easy and how do we make it",
    "start": "1371720",
    "end": "1373640"
  },
  {
    "text": "possible for them",
    "start": "1373640",
    "end": "1374840"
  },
  {
    "text": "then if we can",
    "start": "1374840",
    "end": "1376700"
  },
  {
    "text": "I also I would love to like promote ml",
    "start": "1376700",
    "end": "1379460"
  },
  {
    "text": "models only if the load test results are",
    "start": "1379460",
    "end": "1382039"
  },
  {
    "text": "good and if the ml metrics are good so",
    "start": "1382039",
    "end": "1383840"
  },
  {
    "text": "it means comparing both of them",
    "start": "1383840",
    "end": "1385760"
  },
  {
    "text": "and then probably even more things that",
    "start": "1385760",
    "end": "1387980"
  },
  {
    "text": "I can think really about I kind of",
    "start": "1387980",
    "end": "1389900"
  },
  {
    "text": "really think of sorry and that's gonna",
    "start": "1389900",
    "end": "1393260"
  },
  {
    "start": "1393000",
    "end": "1476000"
  },
  {
    "text": "be it thank you",
    "start": "1393260",
    "end": "1396580"
  },
  {
    "text": "and we're hiring for God to say",
    "start": "1397280",
    "end": "1401740"
  },
  {
    "text": "hi thank you Stephen for my amazing talk",
    "start": "1409159",
    "end": "1411620"
  },
  {
    "text": "my question is around",
    "start": "1411620",
    "end": "1414140"
  },
  {
    "text": "um I've got a twofold question uh the",
    "start": "1414140",
    "end": "1417740"
  },
  {
    "text": "first one is if when you parallelize",
    "start": "1417740",
    "end": "1420860"
  },
  {
    "text": "those work uh workflows in in flight for",
    "start": "1420860",
    "end": "1424280"
  },
  {
    "text": "400 cities if they spin up 400 Bots",
    "start": "1424280",
    "end": "1427460"
  },
  {
    "text": "and if you are adding GPU support how do",
    "start": "1427460",
    "end": "1430580"
  },
  {
    "text": "you prevent for those type of jobs to",
    "start": "1430580",
    "end": "1433940"
  },
  {
    "text": "spin up 400 gpus how do you ensure that",
    "start": "1433940",
    "end": "1436700"
  },
  {
    "text": "they like share their gpus so the first",
    "start": "1436700",
    "end": "1440000"
  },
  {
    "text": "one for this one",
    "start": "1440000",
    "end": "1441200"
  },
  {
    "text": "um then they're gonna Wikipedia will",
    "start": "1441200",
    "end": "1443120"
  },
  {
    "text": "pick up the nodes and then it would be",
    "start": "1443120",
    "end": "1444620"
  },
  {
    "text": "like okay like I have this GPU that is",
    "start": "1444620",
    "end": "1447260"
  },
  {
    "text": "like there's that note sorry that has",
    "start": "1447260",
    "end": "1449360"
  },
  {
    "text": "like whatever GPU you have in and then",
    "start": "1449360",
    "end": "1452480"
  },
  {
    "text": "it will try to use that but usually yeah",
    "start": "1452480",
    "end": "1455419"
  },
  {
    "text": "like usually we'll just spin up 400 gpus",
    "start": "1455419",
    "end": "1459980"
  },
  {
    "text": "so that's",
    "start": "1459980",
    "end": "1461179"
  },
  {
    "text": "thankfully for this one we don't need",
    "start": "1461179",
    "end": "1462620"
  },
  {
    "text": "gpus",
    "start": "1462620",
    "end": "1463700"
  },
  {
    "text": "otherwise we probably wouldn't be hiring",
    "start": "1463700",
    "end": "1467440"
  },
  {
    "text": "anyone else",
    "start": "1469640",
    "end": "1472480"
  },
  {
    "text": "okay thanks Steven thank you",
    "start": "1472520",
    "end": "1476620"
  }
]
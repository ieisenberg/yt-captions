[
  {
    "text": "okay good morning everyone I hope you had an entertaining and informative Cube con so far and we certainly hope to",
    "start": "680",
    "end": "8080"
  },
  {
    "text": "continue along those lines with our talk today about Better Together topological alignment with",
    "start": "8080",
    "end": "14639"
  },
  {
    "text": "Dr um my name is Patrick oie I am a principal engineer at Intel working on",
    "start": "14639",
    "end": "21240"
  },
  {
    "text": "kubernetes and Cloud native Technologies among various maintainer roles in in",
    "start": "21240",
    "end": "26840"
  },
  {
    "text": "kubernetes my main activity and main focus has been on Dynamic resource allocation for the last 3 years and I'm",
    "start": "26840",
    "end": "34879"
  },
  {
    "text": "John B from Google um so I'm been involved in open source kubernetes for many years now um and Patrick and I are",
    "start": "34879",
    "end": "42399"
  },
  {
    "text": "two of the co-chairs of the device management working group which has sort of Taken uh adopted what Patrick started",
    "start": "42399",
    "end": "48960"
  },
  {
    "text": "with Dr and uh pushing it through to the Finish Line um uh as our third co-chair",
    "start": "48960",
    "end": "54960"
  },
  {
    "text": "is here in the front row so um go ahead yeah in this talk I'll cover the basics",
    "start": "54960",
    "end": "61760"
  },
  {
    "text": "what a Dr is because I'm not assuming that everyone is so familiar with it as we are um and I will give you the latest",
    "start": "61760",
    "end": "68680"
  },
  {
    "text": "news about where we are and then John will continue talking about the advanced topics about how we envision top",
    "start": "68680",
    "end": "75240"
  },
  {
    "text": "topological alignment to be done with Dr going forward so Dynamic resource",
    "start": "75240",
    "end": "80600"
  },
  {
    "text": "allocation as I said it has been ongoing for a while you may have heard about it and it was Alpha in previous kubernetes",
    "start": "80600",
    "end": "87799"
  },
  {
    "text": "uh releases we find finally figured out which part we actually can and want to",
    "start": "87799",
    "end": "93759"
  },
  {
    "text": "promote towards beta and GA around the time frame of kubernetes 131 that's",
    "start": "93759",
    "end": "100119"
  },
  {
    "text": "where we did a major overhaul of the entire API so it was a breaking change",
    "start": "100119",
    "end": "105960"
  },
  {
    "text": "in 131 but it set us on a path to where we are now where that same API is almost",
    "start": "105960",
    "end": "113200"
  },
  {
    "text": "unmodified as beta in 132 that is a big milestone because now we are sure that",
    "start": "113200",
    "end": "120200"
  },
  {
    "text": "this API will be around for at least three releases a bit longer depending on how long we want to keep it unchanged",
    "start": "120200",
    "end": "126799"
  },
  {
    "text": "it's available um we are doing Buck fixes for it so I highly recommend that if you have been waiting now is the time",
    "start": "126799",
    "end": "134040"
  },
  {
    "text": "to get engaged and ask your vors about a Dr driver ask your Cloud providers whether they can enable Dr for you",
    "start": "134040",
    "end": "140760"
  },
  {
    "text": "because it's off by default still it is a an API Group and there are rules in cators that say that those need to be",
    "start": "140760",
    "end": "147200"
  },
  {
    "text": "off yeah I I'll interject there that for GK uh we will we do plan to make um Dr",
    "start": "147200",
    "end": "154920"
  },
  {
    "text": "available as an optional you can enable um with the with the release of 132 in",
    "start": "154920",
    "end": "161120"
  },
  {
    "text": "in a rapid Channel yeah so that sets us on a path towards GA we don't have a",
    "start": "161120",
    "end": "167519"
  },
  {
    "text": "exact timeline yet it now entirely depends on your feedback on whatever we",
    "start": "167519",
    "end": "172680"
  },
  {
    "text": "find out but we are still need to change perhaps in it hopefully nothing but we'll see um so what is it really uh it",
    "start": "172680",
    "end": "180400"
  },
  {
    "text": "started out as a a for exercise what's all wrong with a current device plug-in",
    "start": "180400",
    "end": "185720"
  },
  {
    "text": "interface what can and what should we do better so we we don't plan to replace",
    "start": "185720",
    "end": "191040"
  },
  {
    "text": "the device plug-in interface it Still Remains available the simple count-based thing that you have been using so far",
    "start": "191040",
    "end": "197440"
  },
  {
    "text": "remains in kubernetes it's GA but we think that with Dr we have a better alternative and we hope that you will",
    "start": "197440",
    "end": "203400"
  },
  {
    "text": "use it and start doing great things that wen't possible or not easy so far uh",
    "start": "203400",
    "end": "209439"
  },
  {
    "text": "what it does is it provides a much richer API to express complex scenarios",
    "start": "209439",
    "end": "214680"
  },
  {
    "text": "like requesting certain things with attributes configuring resources um the",
    "start": "214680",
    "end": "221239"
  },
  {
    "text": "motivation for it and some of the code actually was borrowed from the persistent volume API so if you are",
    "start": "221239",
    "end": "226799"
  },
  {
    "text": "familiar with that there are certain there will be certain parallels to",
    "start": "226799",
    "end": "231920"
  },
  {
    "text": "it the best way to describe it is probably to look at the main core pieces of it of this new API the first part is",
    "start": "232480",
    "end": "240720"
  },
  {
    "text": "how devices how device drivers describe what they have that's the so-called",
    "start": "240720",
    "end": "246760"
  },
  {
    "text": "resource l a built-in type and in the current Incarnation we have a very",
    "start": "246760",
    "end": "252040"
  },
  {
    "text": "simplistic device model we just have a name for it and some attributes and those attributes are defined by the",
    "start": "252040",
    "end": "258440"
  },
  {
    "text": "vendor it could be something for in this Nvidia example it could be saying that I'm a GPU I have a certain product ID I",
    "start": "258440",
    "end": "266120"
  },
  {
    "text": "have a certain amount of RAM and certain numbers of compute cores and then the second part is a resource",
    "start": "266120",
    "end": "273199"
  },
  {
    "text": "claim that's what the users are creating when they are asking for an Nvidia GPU",
    "start": "273199",
    "end": "278840"
  },
  {
    "text": "they can specify that their workload their model needs a certain amount of RAM and they are guaranteed to get",
    "start": "278840",
    "end": "287240"
  },
  {
    "text": "that then the magic behind the scenes that is mostly in the skula that's where",
    "start": "287240",
    "end": "295800"
  },
  {
    "text": "we are matching the requests in the resource claims against the information provided in the resource slices and as",
    "start": "295800",
    "end": "304320"
  },
  {
    "text": "part of pot scheduling then set up these object so that cupet when it sees a port",
    "start": "304320",
    "end": "310600"
  },
  {
    "text": "that needs resource claims will involve the Dr driver and get the hardware ready",
    "start": "310600",
    "end": "316680"
  },
  {
    "text": "for the pot and for container using that Hardware the biggest limitations or the",
    "start": "316680",
    "end": "323680"
  },
  {
    "text": "main reasons why we're doing is that we know that with these Advanced Ai",
    "start": "323680",
    "end": "328720"
  },
  {
    "text": "workloads and big gpus we want to subdivide them depending on what the workload needs we also have use cases",
    "start": "328720",
    "end": "336400"
  },
  {
    "text": "around configuring these devices and not just in a way where the admin chooses",
    "start": "336400",
    "end": "341560"
  },
  {
    "text": "how to configure them but really the workload offer it best example is perhaps an fpga where you need to",
    "start": "341560",
    "end": "348800"
  },
  {
    "text": "pre-program the fpga to fulfill a certain function and that's something that the user needs to tell in advance",
    "start": "348800",
    "end": "355880"
  },
  {
    "text": "and then some privileged operation takes place before we hand off that that prepared Hardware device to the user so",
    "start": "355880",
    "end": "363000"
  },
  {
    "text": "that's one example of configuration another is uh user space workload",
    "start": "363000",
    "end": "368160"
  },
  {
    "text": "sharing that has different op uh options available to to workload",
    "start": "368160",
    "end": "373880"
  },
  {
    "text": "offers um and then the API also allows a different kind of sharing that's where",
    "start": "373880",
    "end": "380479"
  },
  {
    "text": "because we have a separate object we can point different ports at the same resource claim they will share that",
    "start": "380479",
    "end": "386039"
  },
  {
    "text": "device we can decide within a pot which container gets access to it that's all",
    "start": "386039",
    "end": "391720"
  },
  {
    "text": "very explicit and therefore flexible enough to to to accommodate different",
    "start": "391720",
    "end": "397080"
  },
  {
    "text": "scenarios um we are also preparing this uh Dynamic resource allocation for",
    "start": "397080",
    "end": "403000"
  },
  {
    "text": "future extensions uh Dynamic MC is one example where we know that we need to do a",
    "start": "403000",
    "end": "408280"
  },
  {
    "text": "little bit more work um yeah but we'll we'll get there and these pieces will",
    "start": "408280",
    "end": "413759"
  },
  {
    "text": "get added in a similar fashion as it was done with volumes where base functionality was beta and GA even and",
    "start": "413759",
    "end": "419919"
  },
  {
    "text": "then additional pieces got added over time so this is a slide illustrating how",
    "start": "419919",
    "end": "426720"
  },
  {
    "text": "that works Dr driver consists Al now in this in this latest uh version of Dr",
    "start": "426720",
    "end": "433520"
  },
  {
    "text": "entirely of just the cup plugin so it's easy to develop the driver is responsible for populating these",
    "start": "433520",
    "end": "439720"
  },
  {
    "text": "resource slices the kubernetes schedulers schedular sees them and",
    "start": "439720",
    "end": "444759"
  },
  {
    "text": "because it knows that it owns those additional resources described in the resource s can do scheduling by directly",
    "start": "444759",
    "end": "451520"
  },
  {
    "text": "just picking something for a port and moving on doing the next Port immediately that's a different to an",
    "start": "451520",
    "end": "456639"
  },
  {
    "text": "earlier incarnation of the that's was called classic D but forget about that it's gone in 132 we no longer need to",
    "start": "456639",
    "end": "463639"
  },
  {
    "text": "explain it um the kubernetes AOS scaler that's the key reason why we made those changes",
    "start": "463639",
    "end": "469599"
  },
  {
    "text": "in 131 and focused on this approach is that it can understand the same thing as with schedu it can make Intelligent",
    "start": "469599",
    "end": "475400"
  },
  {
    "text": "Decisions about scaling up nodes because it knows which resource izes which devices are on those",
    "start": "475400",
    "end": "482800"
  },
  {
    "text": "nodes then the user facing part for resource claim um we have claims",
    "start": "482800",
    "end": "489400"
  },
  {
    "text": "references to a resource claim in the port level and then inside the containers we reference the claims the",
    "start": "489400",
    "end": "495680"
  },
  {
    "text": "resource claim is is like a specification of what we want it has um certain attributes that you can select",
    "start": "495680",
    "end": "502520"
  },
  {
    "text": "selectors are how you express complex requirements in in the small mini",
    "start": "502520",
    "end": "508120"
  },
  {
    "text": "language um constraints and match Expressions that is the topic of much of a remaining",
    "start": "508120",
    "end": "513919"
  },
  {
    "text": "talks I'm not going into that the config is where you can specify user driver defined arbitrary opaque content",
    "start": "513919",
    "end": "520839"
  },
  {
    "text": "kubernetes doesn't care what it is it's just getting passed through and then theu sets the status it marks the",
    "start": "520839",
    "end": "527399"
  },
  {
    "text": "resource claim is allocated and then that is the information that is used by Cupid and the Dr dri when it needs to",
    "start": "527399",
    "end": "534519"
  },
  {
    "text": "activate that Hardware Great thank you Patrick so one of the the key things that's maybe a",
    "start": "534519",
    "end": "540440"
  },
  {
    "text": "little bit subtle there that that you might not pick up in what Patrick just described is that with Device plugins",
    "start": "540440",
    "end": "546120"
  },
  {
    "text": "the decision of exactly which devices are chosen is left up to the driver",
    "start": "546120",
    "end": "551560"
  },
  {
    "text": "that's running on the Node and in particular this can become a problem when those when you're asking for",
    "start": "551560",
    "end": "557079"
  },
  {
    "text": "multiple devices because those drivers make independent decisions so um with Dr",
    "start": "557079",
    "end": "563920"
  },
  {
    "text": "we move that decision- making from this the node the plugin in the node to theer",
    "start": "563920",
    "end": "570839"
  },
  {
    "text": "and that allows us in our claims to provide additional constraints so like",
    "start": "570839",
    "end": "576760"
  },
  {
    "text": "in the in in here you see this constraints piece Patrick mentioned and we'll go into this in a little more",
    "start": "576760",
    "end": "582200"
  },
  {
    "text": "detail here but the the idea is that um that allows the scheduler to look across",
    "start": "582200",
    "end": "588000"
  },
  {
    "text": "drivers at multiple devices and make the uh the decision so why would we want to",
    "start": "588000",
    "end": "593640"
  },
  {
    "text": "do that well we're going to drill into a specific example of an area where that's that's important",
    "start": "593640",
    "end": "600800"
  },
  {
    "text": "so this is a simplified node uh VM topology uh you've got two CPUs um",
    "start": "600800",
    "end": "607480"
  },
  {
    "text": "you've got four Nick four gpus rather and four Nicks um and each CPU has is uh",
    "start": "607480",
    "end": "613839"
  },
  {
    "text": "attached two PCI switches and you got the GPU and Nick on one and",
    "start": "613839",
    "end": "619160"
  },
  {
    "text": "um the this topology is actually really important in certain pieces of uh",
    "start": "619160",
    "end": "625320"
  },
  {
    "text": "performance in particular um when you're choosing a GPU that's going to utilize a",
    "start": "625320",
    "end": "632040"
  },
  {
    "text": "nick uh you really want them to be on the same PCI rout complex because that enables you with Nvidia in any way to",
    "start": "632040",
    "end": "638360"
  },
  {
    "text": "use GPU direct which essentially bypasses the the CPU and and has",
    "start": "638360",
    "end": "644399"
  },
  {
    "text": "dramatically better uh bandwidth between the GPU and the Nick so let's walk",
    "start": "644399",
    "end": "650680"
  },
  {
    "text": "through what happens when we use device plugin to allocate devices uh with some requests",
    "start": "650680",
    "end": "657440"
  },
  {
    "text": "that come in suppose we have this node to topology and a first request comes in",
    "start": "657440",
    "end": "663200"
  },
  {
    "text": "and it's for just a single GPU so the uh",
    "start": "663200",
    "end": "668639"
  },
  {
    "text": "the the the scheduler will say okay there's uh there's a GPU available on",
    "start": "668639",
    "end": "674600"
  },
  {
    "text": "that note because the extended resource has been advertised by the device plug-in we're on device plugin here not",
    "start": "674600",
    "end": "679800"
  },
  {
    "text": "Dr and so it'll fit on that node and so I will assign the Pod to that node it",
    "start": "679800",
    "end": "686839"
  },
  {
    "text": "sends it on to the cuet cuet sees that there's an extended",
    "start": "686839",
    "end": "692279"
  },
  {
    "text": "resource and makes a call to the device plugin and the device plugin says oh all right there's nothing on here yet I'm",
    "start": "692279",
    "end": "697519"
  },
  {
    "text": "just going to pick gpu0 everybody's happy so gpu0 is now in use now we get",
    "start": "697519",
    "end": "704399"
  },
  {
    "text": "another request that comes in this one though wants both a GPU and an RDMA Nick",
    "start": "704399",
    "end": "710959"
  },
  {
    "text": "well same process happens the scheduler says hey that node has still three gpus",
    "start": "710959",
    "end": "716920"
  },
  {
    "text": "available and it's got four Nicks available so the the the Pod will fit I'll send the Pod to that node the",
    "start": "716920",
    "end": "724200"
  },
  {
    "text": "plugin on the Node picks it up and says oh hey uh it's two separate plugins one",
    "start": "724200",
    "end": "731320"
  },
  {
    "text": "for the GPU and one for the RDMA they each pick the first available option that's Nick zero and gpu1 but you'll",
    "start": "731320",
    "end": "738199"
  },
  {
    "text": "notice that those two are not on the same uh they're not the not on the same switch probably not on the same route",
    "start": "738199",
    "end": "745040"
  },
  {
    "text": "either um so the uh those get used but now we can't use",
    "start": "745040",
    "end": "751839"
  },
  {
    "text": "GPU direct between those two dices because they're sitting on two different PCI routes and of course this process",
    "start": "751839",
    "end": "758560"
  },
  {
    "text": "continues where we uh the next request comes in and now we're splitting across",
    "start": "758560",
    "end": "763880"
  },
  {
    "text": "even across the CPU boundary here and performance is likely even worse so how does uh how do we do things",
    "start": "763880",
    "end": "773360"
  },
  {
    "text": "with Dr um it's a little more complex on the user API side and we'll get to that",
    "start": "773360",
    "end": "779399"
  },
  {
    "text": "in a minute but it's a more expressive API the device plug-in says you know just that those counts you've got",
    "start": "779399",
    "end": "786079"
  },
  {
    "text": "extended resources um but there's no coordination between the two different",
    "start": "786079",
    "end": "791320"
  },
  {
    "text": "devices that have been chosen uh with Dr this is a resource claim um this particular resource claim",
    "start": "791320",
    "end": "798839"
  },
  {
    "text": "is saying give me an Nvidia GPU with at least 80 gigs of memory we don't really",
    "start": "798839",
    "end": "804320"
  },
  {
    "text": "care about that in this use case but I left this slide like this because it it just gives you a flavor of um whereas",
    "start": "804320",
    "end": "812320"
  },
  {
    "text": "with the device plugin we say we want one Nick or one GPU here we can actually",
    "start": "812320",
    "end": "818040"
  },
  {
    "text": "provide criteria or spec specificity to which GPU we want uh either to make it",
    "start": "818040",
    "end": "823440"
  },
  {
    "text": "more precise or less precise so essentially this is under specifying the GPU so that if there's different gpus",
    "start": "823440",
    "end": "830199"
  },
  {
    "text": "that have that much memory available we could be assigned any one of them along with that we can add a second",
    "start": "830199",
    "end": "837560"
  },
  {
    "text": "request for a nick um and in this case we're saying give us an rdmf now if we just sent this to the um",
    "start": "837560",
    "end": "847680"
  },
  {
    "text": "scheduler just like this the scheduler would make the same choices that the driver the two different Independent",
    "start": "847680",
    "end": "853639"
  },
  {
    "text": "Drivers were making and we still have the same problem that we did before so what we need is one more clause and",
    "start": "853639",
    "end": "860000"
  },
  {
    "text": "that's our constraints so our constraints Clause here says that um the",
    "start": "860000",
    "end": "866880"
  },
  {
    "text": "the list the request names and it says all the the the constraints listed here apply to these requests and match",
    "start": "866880",
    "end": "874399"
  },
  {
    "text": "attributes this attribute called PCI route",
    "start": "874399",
    "end": "879560"
  },
  {
    "text": "so dialing back a little bit to Patrick's discussion right the publishing of information about each",
    "start": "879560",
    "end": "886519"
  },
  {
    "text": "device is no longer just a account but it's actually detailed information that's specific to that device on that",
    "start": "886519",
    "end": "893800"
  },
  {
    "text": "note so in device plug-in you have some flexibility to choose say which GPU you",
    "start": "893800",
    "end": "899639"
  },
  {
    "text": "get by using a label selector on the Node but if there's differences between",
    "start": "899639",
    "end": "905600"
  },
  {
    "text": "the devices which of course there are they have different uh pcie roots for example um you have no uh lever that can",
    "start": "905600",
    "end": "913399"
  },
  {
    "text": "get you smaller than node in that selection criteria but with Dr because we publish for each device here's the",
    "start": "913399",
    "end": "920680"
  },
  {
    "text": "the GPU here's the PCI route it's attached to we can even do things with NYX for example where we would publish",
    "start": "920680",
    "end": "927399"
  },
  {
    "text": "what network is connected to within the larger broader topology uh of of your uh",
    "start": "927399",
    "end": "933440"
  },
  {
    "text": "DPC or whatever so like the the the expressiveness of that API is is much",
    "start": "933440",
    "end": "940000"
  },
  {
    "text": "higher so in this case um we as a community kubernetes we need to come up",
    "start": "940000",
    "end": "945759"
  },
  {
    "text": "with some common attributes typically attributes are vendor defined but we want to Define some attributes like PCI",
    "start": "945759",
    "end": "953240"
  },
  {
    "text": "route that can be used across drivers and across vendors so that we can do",
    "start": "953240",
    "end": "959000"
  },
  {
    "text": "constraints like this where the each the driver publishes for each GPU and for",
    "start": "959000",
    "end": "964279"
  },
  {
    "text": "each Nick which PCI route they're attached to this constraint then when",
    "start": "964279",
    "end": "969560"
  },
  {
    "text": "the scheduler picks the different GPU the different devices it will only choose ones that meet where the the set",
    "start": "969560",
    "end": "977279"
  },
  {
    "text": "of devices it's chosen meets the constraints that are listed here so let's walk through that um same setup",
    "start": "977279",
    "end": "985040"
  },
  {
    "text": "but this time we're going to use a Dr request so so we have a device class",
    "start": "985040",
    "end": "990319"
  },
  {
    "text": "named GPU Nvidia I I made it a little smaller than the last slide so it'll fit um first request comes in just like",
    "start": "990319",
    "end": "996759"
  },
  {
    "text": "before picks the first G GPU second one comes in but now because of the match",
    "start": "996759",
    "end": "1002120"
  },
  {
    "text": "attributes the scheduler is going to first it'll try it'll try Nick zero and gpu1 but then it'll evaluate that that",
    "start": "1002120",
    "end": "1010079"
  },
  {
    "text": "doesn't meet the constraints and it'll discard that solution to the scheduling problem and it'll try the next one the",
    "start": "1010079",
    "end": "1015959"
  },
  {
    "text": "next one is gpu1 Nick one that meets all of our constraints so now we're happy we",
    "start": "1015959",
    "end": "1021839"
  },
  {
    "text": "can use GPU direct between those which will effectively you know increase the throughput uh pretty",
    "start": "1021839",
    "end": "1028120"
  },
  {
    "text": "dramatically and of course the next request comes in exactly the same thing",
    "start": "1028120",
    "end": "1033720"
  },
  {
    "text": "we we land on the same PCI route we pick these two uh instead of scattering everything all",
    "start": "1033720",
    "end": "1039079"
  },
  {
    "text": "around so that's pretty cool um but in the title we promised you something",
    "start": "1039079",
    "end": "1044720"
  },
  {
    "text": "about tpus um I'm not sure how many of you are familiar with tpus but this is gole",
    "start": "1044720",
    "end": "1049760"
  },
  {
    "text": "um solution for uh uh AI training and other uh an inference um and TPU is not",
    "start": "1049760",
    "end": "1058400"
  },
  {
    "text": "exactly the same because here we're talking about uh I'm not talking about",
    "start": "1058400",
    "end": "1063919"
  },
  {
    "text": "cross driver um but I'm talking about uh sort of a a way in which we can choose",
    "start": "1063919",
    "end": "1070679"
  },
  {
    "text": "valid topologies within a TPU so um here's a similar diagram for tpus",
    "start": "1070679",
    "end": "1078280"
  },
  {
    "text": "what we have here this comes this is on the Google Cloud uh documentation um",
    "start": "1078280",
    "end": "1083400"
  },
  {
    "text": "this is showing an 8 chip VM similarly you have two CPUs you",
    "start": "1083400",
    "end": "1088679"
  },
  {
    "text": "have uh a card with four chips that's uh sitting on the close to cpu0 and you have another",
    "start": "1088679",
    "end": "1096039"
  },
  {
    "text": "card with four chips are sitting close to cpu1 and you see those big green thick lines uh that make those kind of",
    "start": "1096039",
    "end": "1103080"
  },
  {
    "text": "uh rectangular shapes that's the connectivity between the different chips so the way we do this in GCE today is if",
    "start": "1103080",
    "end": "1110720"
  },
  {
    "text": "you want to use a one chip topology our host might look like this but what your",
    "start": "1110720",
    "end": "1115960"
  },
  {
    "text": "VM looks like is is this this kind of one chip VM here if you wanted a four",
    "start": "1115960",
    "end": "1121280"
  },
  {
    "text": "chip VM you know you might get this these four chips here um but the thing",
    "start": "1121280",
    "end": "1126840"
  },
  {
    "text": "is that um there are there are only certain valid topology so if you want a",
    "start": "1126840",
    "end": "1133000"
  },
  {
    "text": "a two chip um uh a two chip v um you",
    "start": "1133000",
    "end": "1138240"
  },
  {
    "text": "want it allocate two chips for your workload um and and you want to do at the kubernetes layer rather than the VM",
    "start": "1138240",
    "end": "1143919"
  },
  {
    "text": "layer so so what I'm sort of getting at here is moving this out of the GCE layer and into the kubernetes layer um you can",
    "start": "1143919",
    "end": "1151000"
  },
  {
    "text": "use these uh you can pick chip zero and Chip one because it's got one of those green thick lines between it you can do",
    "start": "1151000",
    "end": "1157280"
  },
  {
    "text": "chip two and Chip three you can do chip zero and Chip two but uh chip one and Chip three but you can't do chip zero",
    "start": "1157280",
    "end": "1164400"
  },
  {
    "text": "and Chip three because there's no direct connectivity you won't get the performance that you expect effect and so it's not a topology that we support",
    "start": "1164400",
    "end": "1172159"
  },
  {
    "text": "when you're allocating um uh TPU chips uh as a as a",
    "start": "1172159",
    "end": "1177240"
  },
  {
    "text": "set so we can use match attributes just like",
    "start": "1177240",
    "end": "1183280"
  },
  {
    "text": "we do for cross driver things within the driver um and that can solve part of our",
    "start": "1183280",
    "end": "1190960"
  },
  {
    "text": "problem so here's an example of a way we could",
    "start": "1190960",
    "end": "1196000"
  },
  {
    "text": "advertise those four GPU chips 0 through three and allow match attribute",
    "start": "1196000",
    "end": "1204400"
  },
  {
    "text": "constraints to be used to select some of those but I actually have a problem here",
    "start": "1204400",
    "end": "1210520"
  },
  {
    "text": "and the problem is that um the user can't just ask for two tpus and use",
    "start": "1210520",
    "end": "1217400"
  },
  {
    "text": "a match attribute expression to uh to satisfy and get any of the possible two",
    "start": "1217400",
    "end": "1223360"
  },
  {
    "text": "chip topologies and we actually have a similar problem at Kevin sitting here he's our our third co-chair he's from",
    "start": "1223360",
    "end": "1229120"
  },
  {
    "text": "Nvidia and and they have a similar problem uh with Mig right you can't you there's certain ways they get advertised",
    "start": "1229120",
    "end": "1235640"
  },
  {
    "text": "and and you can't select them just with with this sort of operation so",
    "start": "1235640",
    "end": "1242000"
  },
  {
    "text": "um what that means is that you know in this case I could ask for a 2X one in which case I could I could say uh the 2",
    "start": "1242000",
    "end": "1249280"
  },
  {
    "text": "by one attribute should match I would get say either both west or both East ones but if only the north ones were",
    "start": "1249280",
    "end": "1258120"
  },
  {
    "text": "available I wouldn't be able to schedule so",
    "start": "1258120",
    "end": "1263240"
  },
  {
    "text": "um um so I guess I I kind of covered this slide a little bit um there's a how",
    "start": "1264760",
    "end": "1271400"
  },
  {
    "text": "do we solve that problem um there's another option we considering um Beyond",
    "start": "1271400",
    "end": "1276559"
  },
  {
    "text": "matching ATT attributes which is a equality match um we can actually",
    "start": "1276559",
    "end": "1282960"
  },
  {
    "text": "Implement a cell expression that does the match so this has been proposed as an alpha feature and we're look at it uh",
    "start": "1282960",
    "end": "1289520"
  },
  {
    "text": "the AWS folks are interested in building it CU for their neuron chips they need sequential in TPU we have square they",
    "start": "1289520",
    "end": "1296640"
  },
  {
    "text": "need they need sort of sequential things paired together and the match attributes can't quite cover that either for them",
    "start": "1296640",
    "end": "1302880"
  },
  {
    "text": "but I'll be honest with you like all of this looks pretty hard on the user if you if you watch the the recent keynote",
    "start": "1302880",
    "end": "1310240"
  },
  {
    "text": "um one of the the presenters said um you know a lot of technology is about where",
    "start": "1310240",
    "end": "1315520"
  },
  {
    "text": "you put the complexity and a lot of the decisions we make is do we who who makes",
    "start": "1315520",
    "end": "1320840"
  },
  {
    "text": "the who has to who has to digest all the complexity and I'd actually really like",
    "start": "1320840",
    "end": "1326960"
  },
  {
    "text": "to find a way to hide the complexity at least of these TPU and and Mig and and",
    "start": "1326960",
    "end": "1332919"
  },
  {
    "text": "and things uh uh from the user so you don't have to deal with that it's a little harder to hide it from the user",
    "start": "1332919",
    "end": "1338919"
  },
  {
    "text": "when you're talking about um independent vendors with different devices because",
    "start": "1338919",
    "end": "1344520"
  },
  {
    "text": "the user is the only one that necessarily knows about those but when we're talking about one vendor one One driver yes there is a way to hide the",
    "start": "1344520",
    "end": "1351279"
  },
  {
    "text": "complexity so um this is another proposal that we have uh another Alpha",
    "start": "1351279",
    "end": "1358480"
  },
  {
    "text": "proposal and uh Patrick said right we're going 132 to Beta with the but we're",
    "start": "1358480",
    "end": "1365200"
  },
  {
    "text": "going to make a lot of a lot of improvements over time so we have a bunch of Al Alpha features on on the",
    "start": "1365200",
    "end": "1370520"
  },
  {
    "text": "plate this is one that we're uh we're hoping to get into 133 we'll see but",
    "start": "1370520",
    "end": "1375880"
  },
  {
    "text": "effectively it moves all of this complexity I just talked about with the tpus and the the partitioning and how",
    "start": "1375880",
    "end": "1382279"
  },
  {
    "text": "which ones are valid topologies and it pushes it onto the device model and onto",
    "start": "1382279",
    "end": "1387760"
  },
  {
    "text": "the vendor to build their driver and from a user point of view now you can just say I want I want a two chip TPU or",
    "start": "1387760",
    "end": "1396720"
  },
  {
    "text": "I want a four chip TPU or I want a Nvidia Mig partition you know of this",
    "start": "1396720",
    "end": "1403159"
  },
  {
    "text": "profile and all of the magic would happen behind the scenes the user doesn't have to understand alignment or",
    "start": "1403159",
    "end": "1409480"
  },
  {
    "text": "anything like that and in fact we can even push it to that cross vendor thing but that's another maybe",
    "start": "1409480",
    "end": "1416360"
  },
  {
    "text": "another topic for another talk but we do believe it's possible to build on top of that a driver that looks across other",
    "start": "1416360",
    "end": "1422000"
  },
  {
    "text": "drivers and allocates a Nick and a GPU as a unit so um Lots there I know uh but",
    "start": "1422000",
    "end": "1430240"
  },
  {
    "text": "I'll say the takeaway here is um in 132",
    "start": "1430240",
    "end": "1435480"
  },
  {
    "text": "Dr is going beta it gives you a lot of flexibility ility there's some really powerful things in there um it's still",
    "start": "1435480",
    "end": "1443279"
  },
  {
    "text": "complex in 133 134 and Beyond we're really focusing on how do we make it",
    "start": "1443279",
    "end": "1449640"
  },
  {
    "text": "simpler for the end user even if that puts more complexity on the",
    "start": "1449640",
    "end": "1455440"
  },
  {
    "text": "vendor um so that's it we have time for questions um before we go there though I",
    "start": "1456039",
    "end": "1462159"
  },
  {
    "text": "did want to mention that we have all these other talks most of these are in the past but right after this or shortly",
    "start": "1462159",
    "end": "1467880"
  },
  {
    "text": "after this there will be a uh a demo uh in the Google booth and there will be a",
    "start": "1467880",
    "end": "1474760"
  },
  {
    "text": "additional talk where Kevin will talk about some other interesting ways you can use the Dr Dr API in multi-host",
    "start": "1474760",
    "end": "1482279"
  },
  {
    "text": "situations uh and you will also be available for questions there so uh uh if you're interested please join us um",
    "start": "1482279",
    "end": "1489120"
  },
  {
    "text": "and we have about 10 minutes for questions now yes sir",
    "start": "1489120",
    "end": "1495300"
  },
  {
    "text": "[Applause] um is there any appetite within the Dr",
    "start": "1495300",
    "end": "1502600"
  },
  {
    "text": "project can you scoot a little closer to the micophone um it's scoping question is there any appetite within the Dr",
    "start": "1502600",
    "end": "1509000"
  },
  {
    "text": "project to do like driver selection um in a resource claim so say you want to",
    "start": "1509000",
    "end": "1515799"
  },
  {
    "text": "take an Nvidia uh GPU um use the Nvidia driver to match and to make sure you're",
    "start": "1515799",
    "end": "1522200"
  },
  {
    "text": "selecting the right GPU and then switch it over to the vfio driver for pass",
    "start": "1522200",
    "end": "1527600"
  },
  {
    "text": "through um would be a kind of an instance there Kevin Kevin gave us a thumbs up I second it's for second talk",
    "start": "1527600",
    "end": "1535720"
  },
  {
    "text": "so in general speaking without going into Nvidia specifics there is a way how",
    "start": "1535720",
    "end": "1542200"
  },
  {
    "text": "a driver if it's statically provisioned on the Node could advertise its version so our attributes support something like",
    "start": "1542200",
    "end": "1549240"
  },
  {
    "text": "a semantic version where you can say I need semantic version one. something and",
    "start": "1549240",
    "end": "1554720"
  },
  {
    "text": "you will be sure that that API is available supported by the device when you land on a note that would be static",
    "start": "1554720",
    "end": "1561600"
  },
  {
    "text": "the other thing would be that you could have a driver that supports configuration parameters to select a",
    "start": "1561600",
    "end": "1567480"
  },
  {
    "text": "version and then it gets reconfigured dynamically before the device is handed",
    "start": "1567480",
    "end": "1572799"
  },
  {
    "text": "to a workload okay all right thank",
    "start": "1572799",
    "end": "1577200"
  },
  {
    "text": "you um what about soft constraints what about soft constraints right so if you",
    "start": "1578559",
    "end": "1585240"
  },
  {
    "text": "think let's say in the TPU you could have the diagonal still right I'm sorry I'm still having trouble understand okay",
    "start": "1585240",
    "end": "1592159"
  },
  {
    "text": "what about soft constraints what if I could do the diagonal but it would be you know less preferable and and what",
    "start": "1592159",
    "end": "1599399"
  },
  {
    "text": "about uh Expo you know is there a mechanism for the the running pods then",
    "start": "1599399",
    "end": "1605240"
  },
  {
    "text": "to know which constraints have been satisfied and which have been not",
    "start": "1605240",
    "end": "1610520"
  },
  {
    "text": "satisfied that's yeah I we have one other proposal pending that John is",
    "start": "1610520",
    "end": "1616399"
  },
  {
    "text": "actually driving where we specify by first off it's basically a list of",
    "start": "1616399",
    "end": "1622039"
  },
  {
    "text": "alternative solutions for your requests that would be valid that would be acceptable for your workload and uh it",
    "start": "1622039",
    "end": "1630399"
  },
  {
    "text": "will then lead to an allocation where one of those potential Alternatives is",
    "start": "1630399",
    "end": "1637039"
  },
  {
    "text": "chosen we envision it at the moment so that it is picking the first one that's available but not necessarily scoring or",
    "start": "1637039",
    "end": "1644559"
  },
  {
    "text": "anything so it might end up with a situation where it picks one Noe where the second alternative is available",
    "start": "1644559",
    "end": "1650720"
  },
  {
    "text": "although there is another Noe where the first one would have been satisfied and both seem equally valuable but it's",
    "start": "1650720",
    "end": "1657880"
  },
  {
    "text": "basically random which gets picked so we may also need to do something with scoring which we also don't do at the",
    "start": "1657880",
    "end": "1665240"
  },
  {
    "text": "moment where you specify okay I'm I'm fine with these different Alternatives but please pick for one",
    "start": "1665240",
    "end": "1671480"
  },
  {
    "text": "that gives me a better better experience better performance if you can that would",
    "start": "1671480",
    "end": "1676840"
  },
  {
    "text": "allow gracefully degrading basically depending on what's currently available uh informing the workload",
    "start": "1676840",
    "end": "1684880"
  },
  {
    "text": "about what it got that is part of the Dr driver they need at least right now it",
    "start": "1684880",
    "end": "1690799"
  },
  {
    "text": "is the job of the driver uh we have had discussions about some downward API",
    "start": "1690799",
    "end": "1697760"
  },
  {
    "text": "extensions where it would become possible for workload offer to say okay",
    "start": "1697760",
    "end": "1703360"
  },
  {
    "text": "I'm peeking into resource claims and what they attributes they have and when I decide what environment where will get",
    "start": "1703360",
    "end": "1711320"
  },
  {
    "text": "set and to which value that would be probably more flexible because you don't",
    "start": "1711320",
    "end": "1717360"
  },
  {
    "text": "depend on what the Dr driver supports you could do something yourself saying okay I I see that my request one of",
    "start": "1717360",
    "end": "1723720"
  },
  {
    "text": "these Alternatives got for second one and then based on that said something we haven't specified how that would look",
    "start": "1723720",
    "end": "1730720"
  },
  {
    "text": "like it it is one of those things that definitely has come up but needs needs a design",
    "start": "1730720",
    "end": "1736240"
  },
  {
    "text": "needs needs a design and scoring in particular as as we've discussed in the past is is something that I've been",
    "start": "1736240",
    "end": "1742640"
  },
  {
    "text": "thinking a lot about and because it's it's really necessary for the this prioritized list um that Patrick just",
    "start": "1742640",
    "end": "1749120"
  },
  {
    "text": "described to be as valuable as we'd like and also um you know but there's a lot",
    "start": "1749120",
    "end": "1756279"
  },
  {
    "text": "of complexity there but absolutely something we're interested in uh next here uh this is probably a",
    "start": "1756279",
    "end": "1763240"
  },
  {
    "text": "beginner question so when we describe the device someone has to return the",
    "start": "1763240",
    "end": "1769120"
  },
  {
    "text": "values of how this what is the cap capability of this device it's sort of",
    "start": "1769120",
    "end": "1774600"
  },
  {
    "text": "like a driver thing for example I believe amedia driver the amedia GP will",
    "start": "1774600",
    "end": "1780960"
  },
  {
    "text": "be supported but where do those support coming from do we need to install other PL like actual actual drivers to get for",
    "start": "1780960",
    "end": "1788799"
  },
  {
    "text": "example AMD GP supported or it comes from the this D feature by default so",
    "start": "1788799",
    "end": "1795600"
  },
  {
    "text": "the drivers I any given node um we don't",
    "start": "1795600",
    "end": "1802000"
  },
  {
    "text": "support running both a device plug-in and a and a Dr driver for the same",
    "start": "1802000",
    "end": "1807559"
  },
  {
    "text": "devices so um yes there is a separate driver for like for NVIDIA there's a separate Dr driver um that publishes",
    "start": "1807559",
    "end": "1815679"
  },
  {
    "text": "things to the resource slice API rather than to the extended resource API and um",
    "start": "1815679",
    "end": "1821600"
  },
  {
    "text": "that will need to be run in your cluster in place of the existing device plug-in",
    "start": "1821600",
    "end": "1828279"
  },
  {
    "text": "um eventually uh we have ideas about how to have a single driver that can handle",
    "start": "1828279",
    "end": "1835720"
  },
  {
    "text": "whether the regardless of which API the user uses whether they use the extended resource API to request the resource or",
    "start": "1835720",
    "end": "1841840"
  },
  {
    "text": "they use the newer Dr apis to request the resource the same driver can satisfy",
    "start": "1841840",
    "end": "1846960"
  },
  {
    "text": "it um I think maybe we'll get there when we get to GA maybe that needs to be a ga",
    "start": "1846960",
    "end": "1852080"
  },
  {
    "text": "criteria but uh for beta we don't we don't have that right now yeah okay thank you",
    "start": "1852080",
    "end": "1859639"
  },
  {
    "text": "uh so Patrick can you comment or provide some information about the scheduling",
    "start": "1859639",
    "end": "1866559"
  },
  {
    "text": "optimization Advanced schedule for example Advanced Bean packing for the",
    "start": "1866559",
    "end": "1872159"
  },
  {
    "text": "resource stes or partition devices right na even one could cause some resource",
    "start": "1872159",
    "end": "1878240"
  },
  {
    "text": "fragmentation problem create host so yeah wondering any on goinging work or plan for that thank you so at the moment",
    "start": "1878240",
    "end": "1886240"
  },
  {
    "text": "the algorithm is fairly simplistic it really literally just walks through the",
    "start": "1886240",
    "end": "1892120"
  },
  {
    "text": "different Alternatives that satisfy what we described in the API um and then picks the first solution",
    "start": "1892120",
    "end": "1900240"
  },
  {
    "text": "that it finds it does not try to optimize in any way so I I'm I'm with",
    "start": "1900240",
    "end": "1908000"
  },
  {
    "text": "you it probably can lead to fragmentation on nodes um scoring might help but then we",
    "start": "1908000",
    "end": "1916600"
  },
  {
    "text": "need to figure out what how do we actually identify fragmentation how do we avoid it based on attributes that at",
    "start": "1916600",
    "end": "1924240"
  },
  {
    "text": "the moment to the schula are completely opaque that that is a challenging problem we are moving the logic into",
    "start": "1924240",
    "end": "1930919"
  },
  {
    "text": "vular But vular ultimately doesn't really know anything it just these attributes and doing horis sixs which",
    "start": "1930919",
    "end": "1939799"
  },
  {
    "text": "probably might be needed here that may depend on additional hints that uh a",
    "start": "1939799",
    "end": "1946200"
  },
  {
    "text": "driver offer may have to provide and we don't know yet what that looks like yeah yeah I'll just say like this gets back",
    "start": "1946200",
    "end": "1953760"
  },
  {
    "text": "to scoring cuz it is related but it's not the same thing right so um the",
    "start": "1953760",
    "end": "1960559"
  },
  {
    "text": "whatever we do for scoring it's not going to be single dimensional they'll have to be like like for example um bin",
    "start": "1960559",
    "end": "1969840"
  },
  {
    "text": "packing when you have a MIG and you could take uh there's one empty slot and it would fit exactly in there and then",
    "start": "1969840",
    "end": "1976320"
  },
  {
    "text": "you've got that GPU fully cons that seems like a good idea right um alternatively you could stick it on a",
    "start": "1976320",
    "end": "1982399"
  },
  {
    "text": "fresh open empty GPU and use up a whole that's now no longer can be used for the whole GPU which of those is the better",
    "start": "1982399",
    "end": "1989000"
  },
  {
    "text": "answer might actually be a preference of the user or the cluster administrator or",
    "start": "1989000",
    "end": "1994919"
  },
  {
    "text": "some combination thereof so whatever we do for scoring we need to provide like",
    "start": "1994919",
    "end": "2001440"
  },
  {
    "text": "measures like wastefulness how much how much of a GPU are we or of a device are we wasting with this choice or um been",
    "start": "2001440",
    "end": "2008960"
  },
  {
    "text": "you know uh uh some sort of um there might be some performance penalties or weights like depending on if you what",
    "start": "2008960",
    "end": "2015840"
  },
  {
    "text": "choice you make and some of that is going to come from the vendor some of that's going to come from the cluster admin and some preferences about that",
    "start": "2015840",
    "end": "2021960"
  },
  {
    "text": "are going to come from the user so it's super complicated problem but um you know I'd love you know you to join us as",
    "start": "2021960",
    "end": "2028720"
  },
  {
    "text": "and and and help us solve it yeah yeah I I'm from Nvidia also have been active",
    "start": "2028720",
    "end": "2034120"
  },
  {
    "text": "contributor to se scheduling I understand that challenge yeah I just said uh with the increasing adoption Dia and",
    "start": "2034120",
    "end": "2042480"
  },
  {
    "text": "with the 132 release and that's probably we becoming a more important problem and",
    "start": "2042480",
    "end": "2048480"
  },
  {
    "text": "somehow yeah I think the community can work together and come up with some improve the solution and avoid okay",
    "start": "2048480",
    "end": "2055358"
  },
  {
    "text": "thank you def happy to contribute thank you yeah we have I think time for one super quick question",
    "start": "2055359",
    "end": "2061158"
  },
  {
    "text": "if there's any more uh otherwi oh yeah uh you will'll",
    "start": "2061159",
    "end": "2067079"
  },
  {
    "text": "repeat it so I can't remember if it was the first or the second question but the the",
    "start": "2067079",
    "end": "2072599"
  },
  {
    "text": "notion of having sort of secondary scheduling so fallback scheduling if the optimal topology isn't available say",
    "start": "2072599",
    "end": "2079638"
  },
  {
    "text": "well you know I'm willing to sacrifice Optimal Performance just to get scheduled at all that introduces",
    "start": "2079639",
    "end": "2085520"
  },
  {
    "text": "problems uh like multi- tendency problems it pollutes the whole Matrix optimization of all the other gpus as",
    "start": "2085520",
    "end": "2092480"
  },
  {
    "text": "you're sort of going through in that slide like once you have that diagonal thing then nothing after is able to be",
    "start": "2092480",
    "end": "2098240"
  },
  {
    "text": "optimized as a as a whole well possibly I mean I think that that",
    "start": "2098240",
    "end": "2106359"
  },
  {
    "text": "um the the the envisioned use case for that is more like I'd prefer you",
    "start": "2106359",
    "end": "2114400"
  },
  {
    "text": "know a an h100 but if it's not available I'll take an a100 but if that's not available I'll take two l4s right like",
    "start": "2114400",
    "end": "2121720"
  },
  {
    "text": "that's kind of the level of request we're sort of doing as opposed to well I want an aligned I mean you could do it",
    "start": "2121720",
    "end": "2127760"
  },
  {
    "text": "though right I want an aligned on the on the PCI route but I'll take it without",
    "start": "2127760",
    "end": "2133160"
  },
  {
    "text": "it if I if I can't get it but um yeah I mean this is the fra that's exactly the",
    "start": "2133160",
    "end": "2139119"
  },
  {
    "text": "fragmentation problem and um we'll have to figure",
    "start": "2139119",
    "end": "2144920"
  },
  {
    "text": "out right rces capacity so the comment was that it",
    "start": "2149920",
    "end": "2155280"
  },
  {
    "text": "actually reduces capacity because it it it actually dis it's not just fragmentation it disrupts the ability to",
    "start": "2155280",
    "end": "2162800"
  },
  {
    "text": "satisfy claims in the future yeah um perhaps the whole flexibility that we",
    "start": "2162800",
    "end": "2168960"
  },
  {
    "text": "have with the array is not something that we actually should use and make available to the user like the",
    "start": "2168960",
    "end": "2174440"
  },
  {
    "text": "scheduling thing of a a grit of cores it might just be a very valuable",
    "start": "2174440",
    "end": "2180359"
  },
  {
    "text": "restriction to say you need to request things that are powers of two even for",
    "start": "2180359",
    "end": "2185480"
  },
  {
    "text": "workers owner needs three it doesn't make sense to specify such a workload because it eventually increases",
    "start": "2185480",
    "end": "2191079"
  },
  {
    "text": "fragmentation so it might just make more sense to say align your resources so that we can still do scheduling fairly",
    "start": "2191079",
    "end": "2198079"
  },
  {
    "text": "well along uh these Dimensions so we'll we'll have a lot of things to play with but we're actually over time now so",
    "start": "2198079",
    "end": "2203839"
  },
  {
    "text": "thank you all and uh check out these other talks as well thank you",
    "start": "2203839",
    "end": "2209880"
  }
]
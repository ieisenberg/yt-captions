[
  {
    "text": "hello my name is Christine Yen thank you",
    "start": "160",
    "end": "2720"
  },
  {
    "text": "for having me i'm excited to be here",
    "start": "2720",
    "end": "4880"
  },
  {
    "text": "while I am the co-founder and CEO of",
    "start": "4880",
    "end": "6319"
  },
  {
    "text": "Honeycomb I will say the statements and",
    "start": "6319",
    "end": "8720"
  },
  {
    "text": "assertions I make should apply to any",
    "start": "8720",
    "end": "11040"
  },
  {
    "text": "modern observability workflow let's get",
    "start": "11040",
    "end": "14280"
  },
  {
    "text": "in writing software today feels more",
    "start": "14280",
    "end": "17680"
  },
  {
    "text": "magical than it ever has before we've",
    "start": "17680",
    "end": "20000"
  },
  {
    "text": "got LLMs everywhere we have cheap API",
    "start": "20000",
    "end": "22640"
  },
  {
    "text": "calls to foundation models not even",
    "start": "22640",
    "end": "25199"
  },
  {
    "text": "going to touch the whole idea of vibe",
    "start": "25199",
    "end": "26560"
  },
  {
    "text": "coding in this talk there's a lot to be",
    "start": "26560",
    "end": "29119"
  },
  {
    "text": "excited about here it's very cool to be",
    "start": "29119",
    "end": "31519"
  },
  {
    "text": "in the middle of a phase change in",
    "start": "31519",
    "end": "33120"
  },
  {
    "text": "progress when everything is new to",
    "start": "33120",
    "end": "35120"
  },
  {
    "text": "everyone at the same time and most of us",
    "start": "35120",
    "end": "39520"
  },
  {
    "text": "here today have been building software",
    "start": "39520",
    "end": "40960"
  },
  {
    "text": "before this LLM boom and we know the",
    "start": "40960",
    "end": "43840"
  },
  {
    "text": "hard part about building software",
    "start": "43840",
    "end": "45440"
  },
  {
    "text": "systems isn't just the writing of the",
    "start": "45440",
    "end": "47600"
  },
  {
    "text": "code it's the testing it's the",
    "start": "47600",
    "end": "51120"
  },
  {
    "text": "maintenance the tuning and the debugging",
    "start": "51120",
    "end": "54160"
  },
  {
    "text": "that comes after so while LLMs have a",
    "start": "54160",
    "end": "57520"
  },
  {
    "text": "ton of implications for everything that",
    "start": "57520",
    "end": "58960"
  },
  {
    "text": "we're doing I want to spend this time",
    "start": "58960",
    "end": "60960"
  },
  {
    "text": "with you today on this specific part of",
    "start": "60960",
    "end": "63199"
  },
  {
    "text": "it how we make sure that the code that",
    "start": "63199",
    "end": "65518"
  },
  {
    "text": "we build on top of these magical black",
    "start": "65519",
    "end": "68439"
  },
  {
    "text": "boxes still works the way that we expect",
    "start": "68439",
    "end": "71360"
  },
  {
    "text": "after we've shipped and it's in front of",
    "start": "71360",
    "end": "73439"
  },
  {
    "text": "the user",
    "start": "73439",
    "end": "75600"
  },
  {
    "text": "now we work with black boxes and",
    "start": "75600",
    "end": "77520"
  },
  {
    "text": "software all the time but LLMs take some",
    "start": "77520",
    "end": "80880"
  },
  {
    "text": "of the ways that we're used to ensuring",
    "start": "80880",
    "end": "83200"
  },
  {
    "text": "consistent reliable behavior and make",
    "start": "83200",
    "end": "86320"
  },
  {
    "text": "them a little more difficult take for",
    "start": "86320",
    "end": "88720"
  },
  {
    "text": "example trying to make sure your code",
    "start": "88720",
    "end": "90560"
  },
  {
    "text": "overall is testable mockable and",
    "start": "90560",
    "end": "92759"
  },
  {
    "text": "debugable well unit tests rely on your",
    "start": "92759",
    "end": "97119"
  },
  {
    "text": "being able to define a representative",
    "start": "97119",
    "end": "99680"
  },
  {
    "text": "set of inputs",
    "start": "99680",
    "end": "101680"
  },
  {
    "text": "with LLMs we're intentionally opening",
    "start": "101680",
    "end": "103840"
  },
  {
    "text": "the door to a very long tale of possible",
    "start": "103840",
    "end": "106840"
  },
  {
    "text": "inputs as for",
    "start": "106840",
    "end": "109799"
  },
  {
    "text": "mocks LLMs are by nature",
    "start": "109799",
    "end": "112920"
  },
  {
    "text": "nondeterministic swapping it out for",
    "start": "112920",
    "end": "114799"
  },
  {
    "text": "deterministic mock doesn't really help",
    "start": "114799",
    "end": "117680"
  },
  {
    "text": "us much here and when it comes to",
    "start": "117680",
    "end": "120079"
  },
  {
    "text": "debugging your LLM behavior we don't",
    "start": "120079",
    "end": "122479"
  },
  {
    "text": "have simple logical paths to step",
    "start": "122479",
    "end": "124719"
  },
  {
    "text": "through the whole point of incorporating",
    "start": "124719",
    "end": "126719"
  },
  {
    "text": "LLMs into our software is to wrap the",
    "start": "126719",
    "end": "129679"
  },
  {
    "text": "full breadth of human expression into",
    "start": "129679",
    "end": "131840"
  },
  {
    "text": "our code debugging LLM behaviors kind of",
    "start": "131840",
    "end": "135760"
  },
  {
    "text": "just turns out to trying something and",
    "start": "135760",
    "end": "137760"
  },
  {
    "text": "seeing what",
    "start": "137760",
    "end": "139319"
  },
  {
    "text": "happens so this turning upside down of",
    "start": "139319",
    "end": "142239"
  },
  {
    "text": "our worldview is happening on a literal",
    "start": "142239",
    "end": "144000"
  },
  {
    "text": "software engineering systems engineering",
    "start": "144000",
    "end": "145760"
  },
  {
    "text": "level where these black boxes just",
    "start": "145760",
    "end": "147760"
  },
  {
    "text": "aren't testable or debugable the way",
    "start": "147760",
    "end": "149440"
  },
  {
    "text": "that we're used to which means there's",
    "start": "149440",
    "end": "151599"
  },
  {
    "text": "no solid sense of correct to fall back",
    "start": "151599",
    "end": "153519"
  },
  {
    "text": "to it's also true at a meta level there",
    "start": "153519",
    "end": "157120"
  },
  {
    "text": "is no environment within which we can",
    "start": "157120",
    "end": "159200"
  },
  {
    "text": "conduct our tests and feel confident in",
    "start": "159200",
    "end": "161040"
  },
  {
    "text": "the",
    "start": "161040",
    "end": "161879"
  },
  {
    "text": "results even normal product development",
    "start": "161879",
    "end": "164400"
  },
  {
    "text": "or release practices have deter have",
    "start": "164400",
    "end": "167280"
  },
  {
    "text": "have turned inside out instead of",
    "start": "167280",
    "end": "169280"
  },
  {
    "text": "starting with an alpha or beta and then",
    "start": "169280",
    "end": "171599"
  },
  {
    "text": "feeling confident in later broader",
    "start": "171599",
    "end": "173560"
  },
  {
    "text": "release all these early access programs",
    "start": "173560",
    "end": "176000"
  },
  {
    "text": "tend to do is inherently fail to capture",
    "start": "176000",
    "end": "178480"
  },
  {
    "text": "the full range of user behavior and edge",
    "start": "178480",
    "end": "180959"
  },
  {
    "text": "cases",
    "start": "180959",
    "end": "182480"
  },
  {
    "text": "these boxes in the middle column may",
    "start": "182480",
    "end": "184159"
  },
  {
    "text": "still be working for you and may still",
    "start": "184159",
    "end": "185840"
  },
  {
    "text": "be a good idea they just won't be enough",
    "start": "185840",
    "end": "188480"
  },
  {
    "text": "for ensuring the correctness of your new",
    "start": "188480",
    "end": "190400"
  },
  {
    "text": "LLMbacked functionality when you're",
    "start": "190400",
    "end": "192560"
  },
  {
    "text": "inviting your end users to do a lot of",
    "start": "192560",
    "end": "195280"
  },
  {
    "text": "things in your system that you may never",
    "start": "195280",
    "end": "196959"
  },
  {
    "text": "have",
    "start": "196959",
    "end": "198440"
  },
  {
    "text": "expected so is it time to give up on",
    "start": "198440",
    "end": "201519"
  },
  {
    "text": "everything we've learned and know how to",
    "start": "201519",
    "end": "203280"
  },
  {
    "text": "do and just embrace the rise of prompt",
    "start": "203280",
    "end": "205280"
  },
  {
    "text": "engineering as a specialized skill set",
    "start": "205280",
    "end": "207280"
  },
  {
    "text": "of the",
    "start": "207280",
    "end": "208040"
  },
  {
    "text": "future no obviously not or else I",
    "start": "208040",
    "end": "210319"
  },
  {
    "text": "wouldn't be here today",
    "start": "210319",
    "end": "213159"
  },
  {
    "text": "because a lot of the conversations we've",
    "start": "213159",
    "end": "215680"
  },
  {
    "text": "been having as an industry over the",
    "start": "215680",
    "end": "217120"
  },
  {
    "text": "years about how to build reliable and",
    "start": "217120",
    "end": "219599"
  },
  {
    "text": "performant available systems in a",
    "start": "219599",
    "end": "222000"
  },
  {
    "text": "chaotic cloudnative world are still",
    "start": "222000",
    "end": "224400"
  },
  {
    "text": "relevant probably more relevant with the",
    "start": "224400",
    "end": "227200"
  },
  {
    "text": "sort of rapid iteration that building",
    "start": "227200",
    "end": "228720"
  },
  {
    "text": "with lens demands",
    "start": "228720",
    "end": "231599"
  },
  {
    "text": "adopting CI/CD let us shift code let us",
    "start": "231599",
    "end": "234640"
  },
  {
    "text": "ship code much more frequently rapidly",
    "start": "234640",
    "end": "237840"
  },
  {
    "text": "iterating on user",
    "start": "237840",
    "end": "239959"
  },
  {
    "text": "experience talking about testing in",
    "start": "239959",
    "end": "242080"
  },
  {
    "text": "production helped us all embrace the",
    "start": "242080",
    "end": "244159"
  },
  {
    "text": "chaos of real user",
    "start": "244159",
    "end": "246280"
  },
  {
    "text": "input versus artificially sterile test",
    "start": "246280",
    "end": "249959"
  },
  {
    "text": "environments high cardality metadata has",
    "start": "249959",
    "end": "252879"
  },
  {
    "text": "become a must-have if software",
    "start": "252879",
    "end": "254879"
  },
  {
    "text": "engineering teams are trying to",
    "start": "254879",
    "end": "256959"
  },
  {
    "text": "understand complex systems whether that",
    "start": "256959",
    "end": "259759"
  },
  {
    "text": "complexity comes from your architecture",
    "start": "259759",
    "end": "261919"
  },
  {
    "text": "or trying to understand the business",
    "start": "261919",
    "end": "263440"
  },
  {
    "text": "impact or per user experiences",
    "start": "263440",
    "end": "268240"
  },
  {
    "text": "highdimensionality data being able to",
    "start": "268240",
    "end": "270720"
  },
  {
    "text": "break down aggregate data by a bunch of",
    "start": "270720",
    "end": "273360"
  },
  {
    "text": "possible related fields not just a small",
    "start": "273360",
    "end": "275759"
  },
  {
    "text": "number of predefined ones has become the",
    "start": "275759",
    "end": "278240"
  },
  {
    "text": "default way to detangle the interaction",
    "start": "278240",
    "end": "280720"
  },
  {
    "text": "of multiple contributing factors",
    "start": "280720",
    "end": "283680"
  },
  {
    "text": "and SLOs's service level objectives",
    "start": "283680",
    "end": "286240"
  },
  {
    "text": "borrowed from our SRE friends have let",
    "start": "286240",
    "end": "288560"
  },
  {
    "text": "us leverage existing alerting workflows",
    "start": "288560",
    "end": "291280"
  },
  {
    "text": "but anchoring them around fuzzy concepts",
    "start": "291280",
    "end": "293360"
  },
  {
    "text": "like user experience or are we",
    "start": "293360",
    "end": "295919"
  },
  {
    "text": "delivering a good service to our end",
    "start": "295919",
    "end": "298759"
  },
  {
    "text": "users these trends have already begun",
    "start": "298759",
    "end": "301759"
  },
  {
    "text": "driving a distinct new approach to",
    "start": "301759",
    "end": "303440"
  },
  {
    "text": "making sense of our software even in a",
    "start": "303440",
    "end": "306160"
  },
  {
    "text": "prelim",
    "start": "306160",
    "end": "307800"
  },
  {
    "text": "world and we already have a model for",
    "start": "307800",
    "end": "310400"
  },
  {
    "text": "how to measure debug and move the needle",
    "start": "310400",
    "end": "313199"
  },
  {
    "text": "on unpredictable qualitative or",
    "start": "313199",
    "end": "315199"
  },
  {
    "text": "quantitative experiences",
    "start": "315199",
    "end": "318280"
  },
  {
    "text": "observability where it's all about",
    "start": "318280",
    "end": "320600"
  },
  {
    "text": "comparing expected behavior against what",
    "start": "320600",
    "end": "323600"
  },
  {
    "text": "we're actually seeing in",
    "start": "323600",
    "end": "325080"
  },
  {
    "text": "production in front of our live",
    "start": "325080",
    "end": "328440"
  },
  {
    "text": "users because these are some truths",
    "start": "328440",
    "end": "330960"
  },
  {
    "text": "about building on LLM something",
    "start": "330960",
    "end": "333520"
  },
  {
    "text": "unpredictable will happen user behavior",
    "start": "333520",
    "end": "335919"
  },
  {
    "text": "will be chaotic one fix will break",
    "start": "335919",
    "end": "338880"
  },
  {
    "text": "something else tests won't be enough and",
    "start": "338880",
    "end": "342080"
  },
  {
    "text": "early access programs won't help you",
    "start": "342080",
    "end": "344720"
  },
  {
    "text": "these aren't only properties of",
    "start": "344720",
    "end": "346240"
  },
  {
    "text": "extremely complex systems they impact",
    "start": "346240",
    "end": "348639"
  },
  {
    "text": "all of us once we've decided to take in",
    "start": "348639",
    "end": "351360"
  },
  {
    "text": "natural language input or unpredictable",
    "start": "351360",
    "end": "353440"
  },
  {
    "text": "input from users and pass it off to AI",
    "start": "353440",
    "end": "356160"
  },
  {
    "text": "to make decisions about that path",
    "start": "356160",
    "end": "358720"
  },
  {
    "text": "carries with it a level of chaos and",
    "start": "358720",
    "end": "360400"
  },
  {
    "text": "complexity that will force us all to",
    "start": "360400",
    "end": "362720"
  },
  {
    "text": "level up fast",
    "start": "362720",
    "end": "366479"
  },
  {
    "text": "now observability helps embrace some",
    "start": "366479",
    "end": "368280"
  },
  {
    "text": "unpredictability enabling the sort of",
    "start": "368280",
    "end": "370240"
  },
  {
    "text": "feedback loops that let you learn from",
    "start": "370240",
    "end": "372560"
  },
  {
    "text": "what's really happening with your code",
    "start": "372560",
    "end": "375039"
  },
  {
    "text": "the same way that we've learned to work",
    "start": "375039",
    "end": "376800"
  },
  {
    "text": "iteratively with tests observability",
    "start": "376800",
    "end": "378960"
  },
  {
    "text": "enables us all to ship sooner observe",
    "start": "378960",
    "end": "380880"
  },
  {
    "text": "those results in the wild and wrap those",
    "start": "380880",
    "end": "382800"
  },
  {
    "text": "observations back in the into the",
    "start": "382800",
    "end": "384319"
  },
  {
    "text": "development",
    "start": "384319",
    "end": "385560"
  },
  {
    "text": "process we just said tests wouldn't be",
    "start": "385560",
    "end": "387759"
  },
  {
    "text": "enough",
    "start": "387759",
    "end": "389319"
  },
  {
    "text": "right that's where eval come as a quick",
    "start": "389319",
    "end": "392400"
  },
  {
    "text": "sidebar for anyone who isn't familiar",
    "start": "392400",
    "end": "394960"
  },
  {
    "text": "these are tools that allow us to codify",
    "start": "394960",
    "end": "397120"
  },
  {
    "text": "what good looks like in an LLM world",
    "start": "397120",
    "end": "399840"
  },
  {
    "text": "that allow for a little bit more",
    "start": "399840",
    "end": "401199"
  },
  {
    "text": "flexibility about what success or",
    "start": "401199",
    "end": "403440"
  },
  {
    "text": "failure means for our applications the",
    "start": "403440",
    "end": "406319"
  },
  {
    "text": "pattern is that you develop your set of",
    "start": "406319",
    "end": "408160"
  },
  {
    "text": "eval as you develop your application and",
    "start": "408160",
    "end": "410639"
  },
  {
    "text": "we use them to capture intended behavior",
    "start": "410639",
    "end": "413440"
  },
  {
    "text": "or flag behavior as you work with your",
    "start": "413440",
    "end": "416080"
  },
  {
    "text": "prompt now eval parallel observability",
    "start": "416080",
    "end": "419120"
  },
  {
    "text": "in really useful ways while",
    "start": "419120",
    "end": "420800"
  },
  {
    "text": "observability is all about the",
    "start": "420800",
    "end": "422240"
  },
  {
    "text": "unpredictability and chaos of production",
    "start": "422240",
    "end": "424319"
  },
  {
    "text": "eval capture that good and the bad as",
    "start": "424319",
    "end": "427039"
  },
  {
    "text": "they happen although in both cases",
    "start": "427039",
    "end": "430000"
  },
  {
    "text": "whether you're talking about the",
    "start": "430000",
    "end": "430800"
  },
  {
    "text": "instrumentation behind your",
    "start": "430800",
    "end": "431840"
  },
  {
    "text": "observability or eval themselves the",
    "start": "431840",
    "end": "434479"
  },
  {
    "text": "intention is for them to evolve with",
    "start": "434479",
    "end": "436400"
  },
  {
    "text": "your code",
    "start": "436400",
    "end": "438000"
  },
  {
    "text": "and what you find in your observability",
    "start": "438000",
    "end": "439759"
  },
  {
    "text": "tools about how users are trying to use",
    "start": "439759",
    "end": "442000"
  },
  {
    "text": "your software turns out to be the best",
    "start": "442000",
    "end": "444880"
  },
  {
    "text": "source of input into defining those new",
    "start": "444880",
    "end": "447720"
  },
  {
    "text": "evals and so if you put these two things",
    "start": "447720",
    "end": "450160"
  },
  {
    "text": "together the same way that observability",
    "start": "450160",
    "end": "452720"
  },
  {
    "text": "offers feedback loops into development",
    "start": "452720",
    "end": "454880"
  },
  {
    "text": "observability pairs with your evals to",
    "start": "454880",
    "end": "457680"
  },
  {
    "text": "form these feedback loops informing and",
    "start": "457680",
    "end": "460080"
  },
  {
    "text": "improving your prompts as you're",
    "start": "460080",
    "end": "462319"
  },
  {
    "text": "uncovering the behavior of your LLMs in",
    "start": "462319",
    "end": "464400"
  },
  {
    "text": "response to your prompts you're defining",
    "start": "464400",
    "end": "466160"
  },
  {
    "text": "evals releasing quickly watching that",
    "start": "466160",
    "end": "468960"
  },
  {
    "text": "code in the wild then closing the loop",
    "start": "468960",
    "end": "471199"
  },
  {
    "text": "as you learn and pulling those learnings",
    "start": "471199",
    "end": "473680"
  },
  {
    "text": "back into your codebase to live on",
    "start": "473680",
    "end": "475599"
  },
  {
    "text": "forever as",
    "start": "475599",
    "end": "478160"
  },
  {
    "text": "eval let's go one level deeper what does",
    "start": "478199",
    "end": "481360"
  },
  {
    "text": "it look like to ensure that you're",
    "start": "481360",
    "end": "483599"
  },
  {
    "text": "setting yourself and your observability",
    "start": "483599",
    "end": "485360"
  },
  {
    "text": "tooling up to support this kind of",
    "start": "485360",
    "end": "487520"
  },
  {
    "text": "workflow",
    "start": "487520",
    "end": "489080"
  },
  {
    "text": "well because LLMs and Gen AI are these",
    "start": "489080",
    "end": "493120"
  },
  {
    "text": "non-deterministic black boxes with",
    "start": "493120",
    "end": "495680"
  },
  {
    "text": "unbounded variations on inputs they can",
    "start": "495680",
    "end": "498120"
  },
  {
    "text": "receive with a rapidly evolving set of",
    "start": "498120",
    "end": "500720"
  },
  {
    "text": "paths used to refine those inputs",
    "start": "500720",
    "end": "503840"
  },
  {
    "text": "getting good observability into these",
    "start": "503840",
    "end": "505440"
  },
  {
    "text": "systems is all about systematically",
    "start": "505440",
    "end": "507840"
  },
  {
    "text": "tracking the inputs and",
    "start": "507840",
    "end": "510120"
  },
  {
    "text": "outputs let's take a look at what this",
    "start": "510120",
    "end": "512479"
  },
  {
    "text": "looks like for a standard web app by",
    "start": "512479",
    "end": "516399"
  },
  {
    "text": "instrumenting our application we can",
    "start": "516399",
    "end": "518080"
  },
  {
    "text": "capture what arguments were sent to it",
    "start": "518080",
    "end": "519839"
  },
  {
    "text": "on any given HTTP request some metadata",
    "start": "519839",
    "end": "522719"
  },
  {
    "text": "about how the app was running what was",
    "start": "522719",
    "end": "525240"
  },
  {
    "text": "returned all this lets us reason about",
    "start": "525240",
    "end": "527760"
  },
  {
    "text": "the behavior that we expect for a given",
    "start": "527760",
    "end": "530399"
  },
  {
    "text": "user endpoint or set of parameters and",
    "start": "530399",
    "end": "532959"
  },
  {
    "text": "it lets us isolate and debug the issue",
    "start": "532959",
    "end": "534720"
  },
  {
    "text": "if the actual behavior deviates from",
    "start": "534720",
    "end": "537200"
  },
  {
    "text": "that",
    "start": "537200",
    "end": "538279"
  },
  {
    "text": "expectation but what about this payment",
    "start": "538279",
    "end": "540399"
  },
  {
    "text": "service it's a third-party blackbox out",
    "start": "540399",
    "end": "544000"
  },
  {
    "text": "of my control where even if I wanted to",
    "start": "544000",
    "end": "546720"
  },
  {
    "text": "I couldn't go in and instrument it or",
    "start": "546720",
    "end": "549519"
  },
  {
    "text": "look at the logs flowing through of what",
    "start": "549519",
    "end": "552160"
  },
  {
    "text": "it's",
    "start": "552160",
    "end": "553240"
  },
  {
    "text": "doing what I do know is what requests my",
    "start": "553240",
    "end": "556800"
  },
  {
    "text": "app is sending it from where in the code",
    "start": "556800",
    "end": "559519"
  },
  {
    "text": "and on behalf of which user and I know",
    "start": "559519",
    "end": "562240"
  },
  {
    "text": "how long it took to respond and whether",
    "start": "562240",
    "end": "564000"
  },
  {
    "text": "it was successful and probably some",
    "start": "564000",
    "end": "565440"
  },
  {
    "text": "other metadata by capturing all of that",
    "start": "565440",
    "end": "568640"
  },
  {
    "text": "I can start to reason about how the",
    "start": "568640",
    "end": "570480"
  },
  {
    "text": "inputs impact the outputs of my blackbox",
    "start": "570480",
    "end": "574000"
  },
  {
    "text": "how my application and my business logic",
    "start": "574000",
    "end": "576399"
  },
  {
    "text": "impacts all of that and ultimately the",
    "start": "576399",
    "end": "579440"
  },
  {
    "text": "impact on the experience the end user is",
    "start": "579440",
    "end": "582440"
  },
  {
    "text": "having taking that and carrying that",
    "start": "582440",
    "end": "584640"
  },
  {
    "text": "into an LLM world there are a few more",
    "start": "584640",
    "end": "586720"
  },
  {
    "text": "boxes but the principles remain the same",
    "start": "586720",
    "end": "589680"
  },
  {
    "text": "one tactical note I like using traces",
    "start": "589680",
    "end": "592240"
  },
  {
    "text": "for this in order to understand the",
    "start": "592240",
    "end": "593760"
  },
  {
    "text": "relationships better between the overall",
    "start": "593760",
    "end": "595839"
  },
  {
    "text": "end user experience and sort of the",
    "start": "595839",
    "end": "598120"
  },
  {
    "text": "subcomponents if you want to use",
    "start": "598120",
    "end": "599760"
  },
  {
    "text": "structured logs go for it you do",
    "start": "599760",
    "end": "602279"
  },
  {
    "text": "you either way we start with the end",
    "start": "602279",
    "end": "604880"
  },
  {
    "text": "user experience the raw input and",
    "start": "604880",
    "end": "607200"
  },
  {
    "text": "eventually their the output that we're",
    "start": "607200",
    "end": "609080"
  },
  {
    "text": "returning we can also capture",
    "start": "609080",
    "end": "611480"
  },
  {
    "text": "metadata on the context that we're",
    "start": "611480",
    "end": "613680"
  },
  {
    "text": "constructing along with our prompt and",
    "start": "613680",
    "end": "615680"
  },
  {
    "text": "how long that took we can keep track of",
    "start": "615680",
    "end": "618000"
  },
  {
    "text": "the prompt itself that we ultimately",
    "start": "618000",
    "end": "620079"
  },
  {
    "text": "pass to the LLM and useful metadata",
    "start": "620079",
    "end": "623040"
  },
  {
    "text": "capture useful metadata like token",
    "start": "623040",
    "end": "625399"
  },
  {
    "text": "usage as well as any parsing or",
    "start": "625399",
    "end": "627680"
  },
  {
    "text": "validation of LLM outputs before",
    "start": "627680",
    "end": "630079"
  },
  {
    "text": "returning to the",
    "start": "630079",
    "end": "631560"
  },
  {
    "text": "user by operating under the general",
    "start": "631560",
    "end": "634079"
  },
  {
    "text": "principle that criteria for decision-m",
    "start": "634079",
    "end": "637120"
  },
  {
    "text": "should be captured in a span you can",
    "start": "637120",
    "end": "639920"
  },
  {
    "text": "then go and isolate any of the",
    "start": "639920",
    "end": "642320"
  },
  {
    "text": "interesting behaviors based on how a",
    "start": "642320",
    "end": "644800"
  },
  {
    "text": "prompt is generated",
    "start": "644800",
    "end": "647519"
  },
  {
    "text": "and all of that ultimately lets us see",
    "start": "647519",
    "end": "652480"
  },
  {
    "text": "all of the work that we're doing up to",
    "start": "652480",
    "end": "654560"
  },
  {
    "text": "and including calling the LLM all in one",
    "start": "654560",
    "end": "657800"
  },
  {
    "text": "place yes of course we can also get the",
    "start": "657800",
    "end": "660079"
  },
  {
    "text": "aggregate graphs like the ones on the",
    "start": "660079",
    "end": "661600"
  },
  {
    "text": "left in the middle we can look at",
    "start": "661600",
    "end": "663760"
  },
  {
    "text": "latency we can reason about user",
    "start": "663760",
    "end": "665600"
  },
  {
    "text": "satisfaction",
    "start": "665600",
    "end": "667360"
  },
  {
    "text": "but in a workflow where we're rapidly",
    "start": "667360",
    "end": "669040"
  },
  {
    "text": "iterating on an LM experience with tons",
    "start": "669040",
    "end": "671839"
  },
  {
    "text": "of potential inputs that can impact",
    "start": "671839",
    "end": "674000"
  },
  {
    "text": "whether your application looks like it's",
    "start": "674000",
    "end": "676040"
  },
  {
    "text": "hallucinating you need to be able to get",
    "start": "676040",
    "end": "677839"
  },
  {
    "text": "from any aggregate graph to inspecting a",
    "start": "677839",
    "end": "680880"
  },
  {
    "text": "given",
    "start": "680880",
    "end": "681959"
  },
  {
    "text": "outlier this blue row at the bottom this",
    "start": "681959",
    "end": "684880"
  },
  {
    "text": "is a span where ultimately we're",
    "start": "684880",
    "end": "686399"
  },
  {
    "text": "actually calling the",
    "start": "686399",
    "end": "688200"
  },
  {
    "text": "LLM and being able to ask questions like",
    "start": "688200",
    "end": "691040"
  },
  {
    "text": "okay what actually got passed to the LLM",
    "start": "691040",
    "end": "693279"
  },
  {
    "text": "what was it responding to relies on all",
    "start": "693279",
    "end": "696399"
  },
  {
    "text": "the spans above it because that's all",
    "start": "696399",
    "end": "699040"
  },
  {
    "text": "the work that we're doing to build the",
    "start": "699040",
    "end": "701040"
  },
  {
    "text": "best prompt that we can hand to this",
    "start": "701040",
    "end": "703440"
  },
  {
    "text": "commercial",
    "start": "703440",
    "end": "704680"
  },
  {
    "text": "LLM and when there are that many things",
    "start": "704680",
    "end": "707839"
  },
  {
    "text": "that could result in an unsatisfying LLM",
    "start": "707839",
    "end": "710680"
  },
  {
    "text": "response we need all of the context we",
    "start": "710680",
    "end": "713200"
  },
  {
    "text": "can get to iterate and investigate",
    "start": "713200",
    "end": "716519"
  },
  {
    "text": "towards investigate and iterate towards",
    "start": "716519",
    "end": "718800"
  },
  {
    "text": "a better prompt",
    "start": "718800",
    "end": "721120"
  },
  {
    "text": "now there are a number of specialized",
    "start": "721120",
    "end": "722800"
  },
  {
    "text": "tools out there that promise out of the",
    "start": "722800",
    "end": "724560"
  },
  {
    "text": "box answers for LLM",
    "start": "724560",
    "end": "727480"
  },
  {
    "text": "observability i will assert I don't want",
    "start": "727480",
    "end": "730560"
  },
  {
    "text": "a siloed or specialized tool i want",
    "start": "730560",
    "end": "733120"
  },
  {
    "text": "something especially not one that tries",
    "start": "733120",
    "end": "736560"
  },
  {
    "text": "to tell me what to care about i want my",
    "start": "736560",
    "end": "739680"
  },
  {
    "text": "tools to reflect what I care about what",
    "start": "739680",
    "end": "742000"
  },
  {
    "text": "good looks like for my applications and",
    "start": "742000",
    "end": "744480"
  },
  {
    "text": "something that aligns with the workflows",
    "start": "744480",
    "end": "746639"
  },
  {
    "text": "that my engineering teams are using for",
    "start": "746639",
    "end": "749120"
  },
  {
    "text": "the overall application",
    "start": "749120",
    "end": "752160"
  },
  {
    "text": "logic because everything I've talked",
    "start": "752200",
    "end": "754399"
  },
  {
    "text": "about so far isn't some new skill set or",
    "start": "754399",
    "end": "758279"
  },
  {
    "text": "mindset so much of this shift towards",
    "start": "758279",
    "end": "761200"
  },
  {
    "text": "embracing observability is already",
    "start": "761200",
    "end": "763760"
  },
  {
    "text": "underway",
    "start": "763760",
    "end": "765680"
  },
  {
    "text": "in the last decade or so we've seen a",
    "start": "765680",
    "end": "767519"
  },
  {
    "text": "huge shift from developers aren't just",
    "start": "767519",
    "end": "769920"
  },
  {
    "text": "here to write a lot of code which AI",
    "start": "769920",
    "end": "772399"
  },
  {
    "text": "code assistants are certainly helping",
    "start": "772399",
    "end": "774440"
  },
  {
    "text": "with to expanding our responsibilities",
    "start": "774440",
    "end": "777920"
  },
  {
    "text": "to owning our services being joining on",
    "start": "777920",
    "end": "781040"
  },
  {
    "text": "call rotations and testing in production",
    "start": "781040",
    "end": "784200"
  },
  {
    "text": "ultimately being responsible for what",
    "start": "784200",
    "end": "786399"
  },
  {
    "text": "our end users see as a result of our",
    "start": "786399",
    "end": "789959"
  },
  {
    "text": "code because like it or not when",
    "start": "789959",
    "end": "792320"
  },
  {
    "text": "building for this new Gen AI world",
    "start": "792320",
    "end": "794720"
  },
  {
    "text": "nothing is predictable besides some",
    "start": "794720",
    "end": "796800"
  },
  {
    "text": "level of",
    "start": "796800",
    "end": "798360"
  },
  {
    "text": "chaos over the years as I've gone around",
    "start": "798360",
    "end": "801120"
  },
  {
    "text": "talking about observability I've",
    "start": "801120",
    "end": "803120"
  },
  {
    "text": "communicated some version of this bottom",
    "start": "803120",
    "end": "805079"
  },
  {
    "text": "statement that software behaves in",
    "start": "805079",
    "end": "807880"
  },
  {
    "text": "unpredictable emergent ways and the",
    "start": "807880",
    "end": "810720"
  },
  {
    "text": "important part is observing your code as",
    "start": "810720",
    "end": "813360"
  },
  {
    "text": "it's running in production while users",
    "start": "813360",
    "end": "815760"
  },
  {
    "text": "are using it this was true before LLMs",
    "start": "815760",
    "end": "819440"
  },
  {
    "text": "but now as we are intentionally",
    "start": "819440",
    "end": "822000"
  },
  {
    "text": "embracing these non-deterministic immer",
    "start": "822000",
    "end": "824240"
  },
  {
    "text": "black boxes with emergent",
    "start": "824240",
    "end": "826279"
  },
  {
    "text": "behaviors this statement is that much",
    "start": "826279",
    "end": "828959"
  },
  {
    "text": "more",
    "start": "828959",
    "end": "830839"
  },
  {
    "text": "true so as we enter this age of AI I'm",
    "start": "830839",
    "end": "835120"
  },
  {
    "text": "weirdly optimistic because we have many",
    "start": "835120",
    "end": "838880"
  },
  {
    "text": "of the tools and practices at our",
    "start": "838880",
    "end": "840560"
  },
  {
    "text": "disposal to make sense of this brave new",
    "start": "840560",
    "end": "843600"
  },
  {
    "text": "world and we're just getting started i",
    "start": "843600",
    "end": "846399"
  },
  {
    "text": "for one am excited we got",
    "start": "846399",
    "end": "850120"
  },
  {
    "text": "this thank you for your time and",
    "start": "850120",
    "end": "852079"
  },
  {
    "text": "attention today if you'd like to learn",
    "start": "852079",
    "end": "853920"
  },
  {
    "text": "more I've got an O'Reilly report and a",
    "start": "853920",
    "end": "856959"
  },
  {
    "text": "O'Reilly report and a book to recommend",
    "start": "856959",
    "end": "859120"
  },
  {
    "text": "you uh I will be at the Honeycomb booth",
    "start": "859120",
    "end": "861360"
  },
  {
    "text": "in the Expo Hall my team and I would",
    "start": "861360",
    "end": "862959"
  },
  {
    "text": "love to hear about what you're building",
    "start": "862959",
    "end": "864399"
  },
  {
    "text": "thank you so much have a great CubeCon",
    "start": "864399",
    "end": "868760"
  }
]
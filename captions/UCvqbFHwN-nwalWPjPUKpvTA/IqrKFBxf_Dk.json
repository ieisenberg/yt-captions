[
  {
    "start": "0",
    "end": "60000"
  },
  {
    "text": "well hello everybody welcome to kubecon eu uh my name is kyle um i'm here with mario",
    "start": "160",
    "end": "6000"
  },
  {
    "text": "as well and we're here to talk to you kind of about our story of the battle of black friday in proactive and reactive auto",
    "start": "6000",
    "end": "12160"
  },
  {
    "text": "scaling at stockx um before we start we kind of want to introduce ourselves and introduce stockx a little bit so",
    "start": "12160",
    "end": "17680"
  },
  {
    "text": "some of this stuff makes a little bit more sense when we're walking through it uh like i said my name is kyle i'm a",
    "start": "17680",
    "end": "23279"
  },
  {
    "text": "senior software engineer at stockx um i like graphql probably just a little too much if you guys ever want to talk",
    "start": "23279",
    "end": "29039"
  },
  {
    "text": "about it our twitter handles are in the lower right-hand side feel free to hit me about anything graphql um i've talked at a few other",
    "start": "29039",
    "end": "35360"
  },
  {
    "text": "conferences about it it's a fun passion of mine and mario do you want to give yourself a little intro of course i do thank you",
    "start": "35360",
    "end": "41200"
  },
  {
    "text": "kyle i'm mario lauria i actually just love stockx a few months ago uh for carda i'm a yama aficionado uh",
    "start": "41200",
    "end": "48640"
  },
  {
    "text": "devops sre engineer i love everything infrastructure of course love kubernetes and",
    "start": "48640",
    "end": "53760"
  },
  {
    "text": "auto scaling is one of the funnest challenges and kyle and i have a lot to discuss today it's going to be a fun session so",
    "start": "53760",
    "end": "60320"
  },
  {
    "start": "60000",
    "end": "99000"
  },
  {
    "text": "cool so uh like we mentioned this happened at stockx a lot of the stuff is based off of work we did at stockx stockx is a",
    "start": "60320",
    "end": "68400"
  },
  {
    "text": "stock market of things we are a live bid and ask model where people will actively bid and ask things just like a stock",
    "start": "68400",
    "end": "75040"
  },
  {
    "text": "market but instead of trading stocks they will trade normally some type of product so in",
    "start": "75040",
    "end": "80080"
  },
  {
    "text": "the normal instance the stuff that most people know is some type of jordan or some type of nike card we just expanded",
    "start": "80080",
    "end": "86000"
  },
  {
    "text": "to collectibles so trading cards are a big thing that we do now as well we also do some electronics but again it's that live stock model where",
    "start": "86000",
    "end": "93360"
  },
  {
    "text": "people will be actively asking for something and bidding on something and when they match that's when you get your item so the",
    "start": "93360",
    "end": "99200"
  },
  {
    "start": "99000",
    "end": "185000"
  },
  {
    "text": "first thing we want to do is we want to really frame this problem of what was our problem that we had to solve and what is this battle that we",
    "start": "99200",
    "end": "105600"
  },
  {
    "text": "had and the big thing is is it's the surges in traffic",
    "start": "105600",
    "end": "110880"
  },
  {
    "text": "our traffic is very unnormal so like a lot of places you would expect you know your traffic to go up through the day and down at",
    "start": "110880",
    "end": "117520"
  },
  {
    "text": "night and kind of follow that nice little easy wave uh we don't have that unfortunately we have these very very spiky trends where",
    "start": "117520",
    "end": "124479"
  },
  {
    "text": "all of a sudden kanye will feel like he needs to drop a shoe and all of a sudden all of our stuff tanks and we go you know from zero",
    "start": "124479",
    "end": "130879"
  },
  {
    "text": "request to a million request almost instantly and that's kind of where this a lot of these talk will come",
    "start": "130879",
    "end": "136959"
  },
  {
    "text": "from is we have these massive massive traffic traffic spikes very very fast that cause us to do some pretty cool",
    "start": "136959",
    "end": "143520"
  },
  {
    "text": "things and to give you kind of a real graph on kind of what happens this is actually our",
    "start": "143520",
    "end": "150480"
  },
  {
    "text": "request per second and our edge layer of what happens when a push notification for a marketing team",
    "start": "150480",
    "end": "155920"
  },
  {
    "text": "happens as you can see we're hanging out around 15 000 requests per minute and then all of a sudden we hit 80k within 30 seconds",
    "start": "155920",
    "end": "162640"
  },
  {
    "text": "and how do we handle that without going down without having a lot of problems and originally what we we did is we",
    "start": "162640",
    "end": "169680"
  },
  {
    "text": "would do some good old coop ctl commands and make some things work and scale some stuff up and that's how we do it we",
    "start": "169680",
    "end": "175840"
  },
  {
    "text": "would manually go through we would add nodes to our cluster and we would also go around saying hey",
    "start": "175840",
    "end": "180959"
  },
  {
    "text": "did you did you scale your stuff up we have something coming and the thing is the question is does this",
    "start": "180959",
    "end": "186560"
  },
  {
    "start": "185000",
    "end": "260000"
  },
  {
    "text": "work and i mean it kind of worked it kind of made stuff work we didn't go down all the time but",
    "start": "186560",
    "end": "192080"
  },
  {
    "text": "we sometimes went down and that's kind of what happened right we had these two major problems with that approach one is",
    "start": "192080",
    "end": "198640"
  },
  {
    "text": "we had tons of tedious human interaction where you had to remember you had to do it before and there was no formal plan",
    "start": "198640",
    "end": "205440"
  },
  {
    "text": "around this there was a lot of just me and mario and a few other people on our teams running around saying hey dude you know marketing is going to do",
    "start": "205440",
    "end": "211360"
  },
  {
    "text": "something at one o'clock today we think or kanye might drop something tomorrow are you guys ready what time do we need to do all this stuff at",
    "start": "211360",
    "end": "217440"
  },
  {
    "text": "and that was very time consuming and painful the other big thing that really really",
    "start": "217440",
    "end": "222560"
  },
  {
    "text": "came out of this is we had a very hard time figuring out what everybody else was doing to a point",
    "start": "222560",
    "end": "228799"
  },
  {
    "text": "where we would get everything and some you know we would have up to 100 micro services and then we would",
    "start": "228799",
    "end": "234560"
  },
  {
    "text": "have to run around make sure we had all of these things at once which is really really painful the other thing too is as our push",
    "start": "234560",
    "end": "240799"
  },
  {
    "text": "notifications evolved it also started hitting different surfaces so all of a sudden what we would work yesterday would no",
    "start": "240799",
    "end": "246959"
  },
  {
    "text": "longer work today because there's a new usage pattern in this and that was always hard and trying to keep up with all of the stuff as it was",
    "start": "246959",
    "end": "253120"
  },
  {
    "text": "going and as more things are happening more engineers are coming out and more services are being developed is a very hard problem to",
    "start": "253120",
    "end": "259199"
  },
  {
    "text": "solve and stay on top all right so let's uh look at reactive scaling so this is about proactive and reactive",
    "start": "259199",
    "end": "265280"
  },
  {
    "start": "260000",
    "end": "767000"
  },
  {
    "text": "scaling i'm first going to talk about what we did in the reactive realm which was very sre uh focused for the",
    "start": "265280",
    "end": "270880"
  },
  {
    "text": "most part and i really believe that dialing in the reactive components with hpa and cluster",
    "start": "270880",
    "end": "276000"
  },
  {
    "text": "autoscaler which i'll get into is really really pivotal for you to understand the types of challenges",
    "start": "276000",
    "end": "281199"
  },
  {
    "text": "that you're gonna have um in in your reactive scaling journey um before you go on to build something",
    "start": "281199",
    "end": "286880"
  },
  {
    "text": "else um so let's get into it uh let's first basically the the key",
    "start": "286880",
    "end": "292479"
  },
  {
    "text": "thing with our infrastructure at stockx uh you know all eks um we use the cluster autoscaler which just",
    "start": "292479",
    "end": "298560"
  },
  {
    "text": "the existing uh helm uh packages for that uh pretty simple uh we fully manage our",
    "start": "298560",
    "end": "305039"
  },
  {
    "text": "nodes uh which means we use aws uh unmanaged nodes uh this gives us access to configure cubelet certain ways",
    "start": "305039",
    "end": "312240"
  },
  {
    "text": "or run things like node local dns uh and then uh with with cluster autoscaler as you",
    "start": "312240",
    "end": "317759"
  },
  {
    "text": "you work on that it actually automatically taps into the aws apis to interact with the auto scaling groups uh",
    "start": "317759",
    "end": "325039"
  },
  {
    "text": "so there's a vod that you get for free but there's a lot of setup as well and a lot of uh dialing in tolerances uh figuring out the optimal",
    "start": "325039",
    "end": "332400"
  },
  {
    "text": "intervals we don't want flapping we don't want uh nodes that were just added two minutes ago to get removed a few minutes later and really ironing",
    "start": "332400",
    "end": "340080"
  },
  {
    "text": "out that core decision making of when do we scale up versus when we scale in and those are both calculated in",
    "start": "340080",
    "end": "345680"
  },
  {
    "text": "different ways with cluster autoscaler there's plenty of documentation on this uh on the kubernetes github",
    "start": "345680",
    "end": "352639"
  },
  {
    "text": "uh as well as the kubernetes document sites as well um and so you really pretty much can get",
    "start": "352639",
    "end": "358479"
  },
  {
    "text": "really really far however there's there are definitely some nuances this is not uh not perfect uh things like",
    "start": "358479",
    "end": "364479"
  },
  {
    "text": "running cluster autoscaler on multiple across multiple zones uh takes a little bit more effort and a",
    "start": "364479",
    "end": "369680"
  },
  {
    "text": "little bit more watching and maintaining uh what's going on dialing in those uh those",
    "start": "369680",
    "end": "375039"
  },
  {
    "text": "uh configuration values and and uh the stuff right it's very dependent on your workloads as well um so i would say",
    "start": "375039",
    "end": "381919"
  },
  {
    "text": "status and metrics are really one of the key things that we tried to understand early on so that we could get a good grasp on",
    "start": "381919",
    "end": "388160"
  },
  {
    "text": "how to manage uh cluster autoscaler uh in our kind of uh you know environment with",
    "start": "388160",
    "end": "394000"
  },
  {
    "text": "datadog and uh some of the other ways that we took in metrics and uh got alerts etc",
    "start": "394000",
    "end": "399759"
  },
  {
    "text": "um of course as i was saying you know definitely not perfect um getting scale in just right is really",
    "start": "399759",
    "end": "404960"
  },
  {
    "text": "tricky uh and you obviously don't want to waste you want scaling to work but it is really uh something that you have to",
    "start": "404960",
    "end": "411199"
  },
  {
    "text": "iterate on um there's lots of testing we had to do there um we saw a lot of unbalanced decision making which was hard",
    "start": "411199",
    "end": "416880"
  },
  {
    "text": "to understand i mean we we again could see the status of uh the cluster autoscaler and what it was",
    "start": "416880",
    "end": "422479"
  },
  {
    "text": "doing but we were wondering a lot of times why it was making certain decisions um so definitely you know you're gonna",
    "start": "422479",
    "end": "429039"
  },
  {
    "text": "need to watch this uh and again dialing in those tolerances will help you get there um and then definitely actions",
    "start": "429039",
    "end": "435919"
  },
  {
    "text": "after uh burst so let's say we just added uh six nodes to the cluster um any actions that needed to happen",
    "start": "435919",
    "end": "441680"
  },
  {
    "text": "where we added more nodes a few minutes later would actually be somewhat hindered by uh probably aws api rate limits",
    "start": "441680",
    "end": "448160"
  },
  {
    "text": "uh which is never fun uh and that is not very clear to you right so uh that's something you have to dig into",
    "start": "448160",
    "end": "453759"
  },
  {
    "text": "and then we had to even uh customize our asgs beyond the the standard that was upgraded issues the",
    "start": "453759",
    "end": "459520"
  },
  {
    "text": "auto scaling groups we had to do a suspended action on those or else they would kind of fight against the cluster auto scaler",
    "start": "459520",
    "end": "465759"
  },
  {
    "text": "which again is is not ideal um but this is all to say it got us far enough",
    "start": "465759",
    "end": "470879"
  },
  {
    "text": "and we were able to comfortably uh use cluster auto scaler and trust it was making",
    "start": "470879",
    "end": "476000"
  },
  {
    "text": "um a good decision not the best ever decision not the most cost-effective decision but",
    "start": "476000",
    "end": "482800"
  },
  {
    "text": "it was better than uh what we had before which was nothing right and so we had uh the sense that our clusters could",
    "start": "482800",
    "end": "488479"
  },
  {
    "text": "scale in and out uh with the capacity that we needed and scaling out is actually a pretty fast operation when it comes to",
    "start": "488479",
    "end": "494960"
  },
  {
    "text": "cluster and auto scaler so definitely good enough i'm sure it's a lot better and nowadays um that takes us to the horizontal pod",
    "start": "494960",
    "end": "501680"
  },
  {
    "text": "auto scaler also known as hpa um so first i wanted to show uh",
    "start": "501680",
    "end": "507360"
  },
  {
    "text": "this is a before kind of snapshot of our our traffic um and i believe this was uh",
    "start": "507360",
    "end": "513599"
  },
  {
    "text": "enter around uh during a black friday event with one of our our key uh services and this would be a",
    "start": "513599",
    "end": "520000"
  },
  {
    "text": "back-end service just one of many services microservices running in our our production clusters and as you",
    "start": "520000",
    "end": "525680"
  },
  {
    "text": "can see here as traffic starts to ramp up it's very clear that we do not handle that well",
    "start": "525680",
    "end": "531360"
  },
  {
    "text": "and that service does not handle traffic flowing its way uh that rapidly well at all and uh with cluster",
    "start": "531360",
    "end": "538720"
  },
  {
    "text": "autoscaler and of course hpa uh we can see that we are really trying to even this graph out",
    "start": "538720",
    "end": "546160"
  },
  {
    "text": "uh and obviously there is a jump but it is nowhere near the jump it was uh in the prior graph and we're actually",
    "start": "546160",
    "end": "552000"
  },
  {
    "text": "taking more uh throughput as well uh which is really great great to see so um",
    "start": "552000",
    "end": "558080"
  },
  {
    "text": "let's kind of get into how hp makes his decision and this is the equation it uses and so",
    "start": "558080",
    "end": "565200"
  },
  {
    "text": "the uh basically what it's trying to get a sense of is how close to a ratio of one are we with",
    "start": "565200",
    "end": "570800"
  },
  {
    "text": "the current versus the desired uh metric value so we actually did all of our uh scaling with cpu",
    "start": "570800",
    "end": "577440"
  },
  {
    "text": "uh and so really for optimizing the hpa there's kind of different facets that you're looking at um you're",
    "start": "577440",
    "end": "583360"
  },
  {
    "text": "focusing on obviously one application uh how it is working and so with cpu you're looking",
    "start": "583360",
    "end": "588800"
  },
  {
    "text": "at your resource requests uh and limits mainly the requests and so how we did this is uh you know at",
    "start": "588800",
    "end": "594240"
  },
  {
    "text": "stockx because i focused on one particular service and this was our front end um and you know front end",
    "start": "594240",
    "end": "600000"
  },
  {
    "text": "written in node actually lived in its own uh cluster environment and so it was an easy kind of uh boundary where we felt comfortable",
    "start": "600000",
    "end": "607279"
  },
  {
    "text": "working on uh just this this instance of course we did this in in devastation environments before that",
    "start": "607279",
    "end": "612480"
  },
  {
    "text": "um solely on cpu and so a lot of this was analyzing the trends of course this is all manual work uh",
    "start": "612480",
    "end": "618560"
  },
  {
    "text": "you're using your your data dog tools you're using your k9s uh terminal user interface to look at",
    "start": "618560",
    "end": "624320"
  },
  {
    "text": "the kind of live values for uh our front ends um the the thinking we generally did was uh tuning our requests",
    "start": "624320",
    "end": "632320"
  },
  {
    "text": "first uh to ensure we were requesting something that was sane and then we could scale based on what that was",
    "start": "632320",
    "end": "637680"
  },
  {
    "text": "uh and again this is uh the requests allow you for cpu and memory but the horizontal scaler only cared",
    "start": "637680",
    "end": "643920"
  },
  {
    "text": "about cpu uh and then we would tune uh the cpu utilization for our horizontal auto scaler definition",
    "start": "643920",
    "end": "650160"
  },
  {
    "text": "and those were co-located with the applications themselves in their helm deploy um one of the key things that uh we",
    "start": "650160",
    "end": "657200"
  },
  {
    "text": "really like like and i'll mention this multiple times is building in buffers um building in a",
    "start": "657200",
    "end": "662240"
  },
  {
    "text": "safe overflow so if an application uh is deployed and uh it has six",
    "start": "662240",
    "end": "667519"
  },
  {
    "text": "instances we would have maybe you know eight instances or twenty five percent or more uh capacity inherently that we wouldn't",
    "start": "667519",
    "end": "675200"
  },
  {
    "text": "consider as waste because if there was some sort of operation or marketing push as kyle mentioned um we would be able to at",
    "start": "675200",
    "end": "681760"
  },
  {
    "text": "least handle that traffic for some period time until we got more scale the other part of this is events",
    "start": "681760",
    "end": "687200"
  },
  {
    "text": "and knowing what's going on especially during the testing phase kubernetes makes this uh relatively easy to find it's a little",
    "start": "687200",
    "end": "693680"
  },
  {
    "text": "bit tricky looking at the deployment object and looking at the hpa object you can get a",
    "start": "693680",
    "end": "699360"
  },
  {
    "text": "sense of this and a lot of platforms i know we were using datadog uh will let you uh feed this in and then",
    "start": "699360",
    "end": "705839"
  },
  {
    "text": "it's an event that you can act on as well those are really important um and so you can see that we managed to",
    "start": "705839",
    "end": "712079"
  },
  {
    "text": "get to 40 000 requests per minute under 300 millisecond response times which is a huge",
    "start": "712079",
    "end": "717120"
  },
  {
    "text": "huge win from where we were before um and again this is just kind of flattening those curves out when it",
    "start": "717120",
    "end": "722800"
  },
  {
    "text": "comes to response times uh making sure error rates are staying low um that's huge uh and we again good",
    "start": "722800",
    "end": "729120"
  },
  {
    "text": "enough uh it was never perfect there's this is unlimited you can dial in you can uh kind of react as much as you want to",
    "start": "729120",
    "end": "737200"
  },
  {
    "text": "and try to get it as perfect as possible that's unlimited time you can spend on that we we couldn't do that we definitely spent",
    "start": "737200",
    "end": "743519"
  },
  {
    "text": "plenty of time uh testing it we had many different scenarios as kyle mentioned when kanye feels like doing a drop uh we",
    "start": "743519",
    "end": "749839"
  },
  {
    "text": "had plenty of data to go off of so uh definitely dialed it in really well and this is uh",
    "start": "749839",
    "end": "755279"
  },
  {
    "text": "me listening to music as i'm coding and working on hba so hpa was fun",
    "start": "755279",
    "end": "762160"
  },
  {
    "text": "uh here is kyle to talk about proactive scaling thank you mario and cool we're going to",
    "start": "762160",
    "end": "768560"
  },
  {
    "start": "767000",
    "end": "933000"
  },
  {
    "text": "go back to the other side of this we're going to start talking about some proactive auto scaling an hpa is great but it's not always",
    "start": "768560",
    "end": "775200"
  },
  {
    "text": "enough it's great when we have these organic normal ups and downs of traffic that normally happen in services but",
    "start": "775200",
    "end": "781600"
  },
  {
    "text": "when we have traffic drops you're fine too right like it's really only a problem",
    "start": "781600",
    "end": "786720"
  },
  {
    "text": "when you have a dramatic step increase in traffic and you can kind of see that mario's graphs",
    "start": "786720",
    "end": "792079"
  },
  {
    "text": "before when that traffic would sharply increase that's really the only time you'd have a problem when we had these drops or you know it's",
    "start": "792079",
    "end": "798959"
  },
  {
    "text": "just a normal slow flow up or down of traffic you're normally okay and that's what the",
    "start": "798959",
    "end": "804880"
  },
  {
    "text": "problem we're trying to solve is that's where our battle was is when we have these very big spikes in traffic due to a push",
    "start": "804880",
    "end": "810720"
  },
  {
    "text": "notification and or a drop or something that would cause a ton of people to instantly open",
    "start": "810720",
    "end": "816720"
  },
  {
    "text": "up an app or instantly show up to a site that's when it's not enough and the reasons why it's not enough is",
    "start": "816720",
    "end": "823040"
  },
  {
    "text": "like mario said we try to prevent flapping a lot of times in our hpas so we don't constantly go up and down up and down up and down",
    "start": "823040",
    "end": "829279"
  },
  {
    "text": "but that's actually kind of hurt us in this case as well because we have these delays built in to make",
    "start": "829279",
    "end": "835199"
  },
  {
    "text": "sure stuff is enough we also kind of hold ourselves back when we go way over that and we're constantly",
    "start": "835199",
    "end": "841839"
  },
  {
    "text": "going up it actually waits for a little bit before it actually starts scaling yourself up to make sure it's something that's not",
    "start": "841839",
    "end": "847199"
  },
  {
    "text": "going to cause these up and down this flapping and that's also one of the problems but",
    "start": "847199",
    "end": "854079"
  },
  {
    "text": "there's also a few other things layered on top of that that's kind of what happens but the reason that happens is a few things",
    "start": "854079",
    "end": "860160"
  },
  {
    "text": "mainly between your configure delay which you're telling it to wait for and you're also your metric intake so you actually",
    "start": "860160",
    "end": "865519"
  },
  {
    "text": "have to wait for these metrics to come in and say hey we have these this large increase in traffic before you can even",
    "start": "865519",
    "end": "871199"
  },
  {
    "text": "really start to say hey we should start scaling or in a lot of cases hey we should scale in five minutes if we still have this",
    "start": "871199",
    "end": "877360"
  },
  {
    "text": "hard traffic maybe not five minutes but you know some time frame in the future",
    "start": "877360",
    "end": "882639"
  },
  {
    "text": "and again a lot of this stuff is really time sensitive so if you wait that time you wait that",
    "start": "882639",
    "end": "889360"
  },
  {
    "text": "configured delay time your app's already dead in the water at that point most of the times so if you think of a marketing push",
    "start": "889360",
    "end": "894959"
  },
  {
    "text": "notification if you open up your phone and say hey there's you know this new shoe or there's this new thing you hit it and the app crashes or the",
    "start": "894959",
    "end": "901680"
  },
  {
    "text": "app you know gives you a light screen you're normally dead at that point right because people normally don't stay",
    "start": "901680",
    "end": "907760"
  },
  {
    "text": "around and keep trying to open your app or keep trying to get to a page unless they really want something but a lot of times people will",
    "start": "907760",
    "end": "914639"
  },
  {
    "text": "open it up and then kind of you know hey it's not working and then leave and that's kind of where our problem is",
    "start": "914639",
    "end": "920000"
  },
  {
    "text": "we had these massive massive massive step increases in traffic that would really cause us these huge",
    "start": "920000",
    "end": "925519"
  },
  {
    "text": "problems because we would send out a marketing marketing push everybody would get a little banner you'd hit the banner and",
    "start": "925519",
    "end": "930720"
  },
  {
    "text": "then all of a sudden boom our traffic would go up and a lot of people would ask how much does your traffic go up well",
    "start": "930720",
    "end": "936480"
  },
  {
    "text": "through our math uh it actually goes up about 533 in less than 30 seconds so that is a lot",
    "start": "936480",
    "end": "943279"
  },
  {
    "text": "of people hammering our app very very very fast so where we would have these hp's kick in",
    "start": "943279",
    "end": "949920"
  },
  {
    "text": "in the future it's very hard to have them scale for 533 increase almost instantly",
    "start": "949920",
    "end": "956480"
  },
  {
    "text": "and then not have them do that in other times so you would ask you know hey what what",
    "start": "956480",
    "end": "961519"
  },
  {
    "text": "does this look like give me some data of what it would look like and here's our data right uh we saw this top graph before it's our",
    "start": "961519",
    "end": "967199"
  },
  {
    "text": "basically a request per minute and you can see that massive shoot up right that 533 percent",
    "start": "967199",
    "end": "972240"
  },
  {
    "text": "increase in traffic what you don't see before is this air chart on the bottom and this is what would end up getting",
    "start": "972240",
    "end": "979040"
  },
  {
    "text": "you know really bad for us is you can see these lines constantly going up and at some points we would hit over",
    "start": "979040",
    "end": "984639"
  },
  {
    "text": "90 errors and sometimes we'd even hit as high as 95 percent errors which means you know one out of 20",
    "start": "984639",
    "end": "990639"
  },
  {
    "text": "people is not having a problem but 19 people are and that's really really hard to deal with",
    "start": "990639",
    "end": "996800"
  },
  {
    "text": "and going back to the scaling parts here this is our pod counts and our pod charts",
    "start": "996800",
    "end": "1002320"
  },
  {
    "text": "you would see here right we have these very nice little curve up curve up curve up where we're trying to catch up",
    "start": "1002320",
    "end": "1007440"
  },
  {
    "text": "and they're almost perfectly incremented to where that's where our delays would kick off like we've delayed for so long",
    "start": "1007440",
    "end": "1013600"
  },
  {
    "text": "start scaling up to the point where you're good at your next point and take some metrics try it again and",
    "start": "1013600",
    "end": "1019519"
  },
  {
    "text": "we would level out sometime after the push but again at that point we've lost so much traffic so",
    "start": "1019519",
    "end": "1024798"
  },
  {
    "text": "many users that it's not worth it anymore we would want this to happen all before",
    "start": "1024799",
    "end": "1029918"
  },
  {
    "text": "and that's where we created something called barricade barricade is basically our version of a warming",
    "start": "1029919",
    "end": "1036000"
  },
  {
    "text": "solution where we would spin up all these pods but we're going to do that before we're not going to do that we're not going to",
    "start": "1036000",
    "end": "1041520"
  },
  {
    "text": "wait for the hpa to wait for stuff we're actually going to do it before and",
    "start": "1041520",
    "end": "1046880"
  },
  {
    "start": "1044000",
    "end": "1412000"
  },
  {
    "text": "that's what we called it is a warming system so it warms our kubernetes servers and systems to basically be",
    "start": "1046880",
    "end": "1052400"
  },
  {
    "text": "ready for that push so we would do this before it is also a very very small event system",
    "start": "1052400",
    "end": "1058480"
  },
  {
    "text": "so what's in barricade two things uh an api to intake events so you would",
    "start": "1058480",
    "end": "1063760"
  },
  {
    "text": "just say hey something's going to happen from here to here and time frames iso dates and",
    "start": "1063760",
    "end": "1068880"
  },
  {
    "text": "then there's an internal crown job that keeps checking to see when those dates are going to come up and if it finds one it'll warm it up and",
    "start": "1068880",
    "end": "1075280"
  },
  {
    "text": "then the really nice part is so we don't forget about it once that event's passed and it's past that expiration date it'll actually",
    "start": "1075280",
    "end": "1081919"
  },
  {
    "text": "cool itself off and put it back to where it was before so we're not wasting money and wasting all of the cpu and energy at stuff after",
    "start": "1081919",
    "end": "1089200"
  },
  {
    "text": "the fact and this is what it looked like isn't it you know a practical example of our impact on pots we put it on one service",
    "start": "1089200",
    "end": "1095520"
  },
  {
    "text": "to test it out and this is the graph we saw um there's a box in the left hand side here where you see that real",
    "start": "1095520",
    "end": "1101440"
  },
  {
    "text": "really really really strong jump up that's equivalent to all of the smaller jumps you saw before but it happened",
    "start": "1101440",
    "end": "1106720"
  },
  {
    "text": "before anything actually happened which is kind of the point of this so now when that service got hammered",
    "start": "1106720",
    "end": "1112559"
  },
  {
    "text": "with stuff we would actually be ready for it we're no longer waiting for everything to reactively",
    "start": "1112559",
    "end": "1117919"
  },
  {
    "text": "scale and hopefully that it would scale all the way up to the point that it needed to we're telling it before hey this is where we need to set it so",
    "start": "1117919",
    "end": "1124960"
  },
  {
    "text": "we're okay after the fact or when this push does hit we're not going to be underwater",
    "start": "1124960",
    "end": "1130240"
  },
  {
    "text": "you know get to the end point of all of our pods to start and again i can say all this stuff it",
    "start": "1130240",
    "end": "1136160"
  },
  {
    "text": "doesn't mean anything unless we have data to back it up and data of why this is a good idea these are side-by-side charts of a push",
    "start": "1136160",
    "end": "1142480"
  },
  {
    "text": "notification before and a push notification after we added barricade as you can see the graph from",
    "start": "1142480",
    "end": "1147520"
  },
  {
    "text": "before we had these huge air spikes we would hop up to 95 errors at points but we were consistently over 85 errors",
    "start": "1147520",
    "end": "1155120"
  },
  {
    "text": "but if you look after when we just do basically what the hpa would do throughout this process and after we hit",
    "start": "1155120",
    "end": "1161520"
  },
  {
    "text": "zero percent air rate most of the time we're under one percent air rate which normally is due to you know hey a bad",
    "start": "1161520",
    "end": "1166799"
  },
  {
    "text": "you you are not a bad uuid a bad product id or somebody not being authenticated you know the normal stuff",
    "start": "1166799",
    "end": "1172720"
  },
  {
    "text": "of people just using the website but we're no longer getting these problems of we don't have enough resources to really",
    "start": "1172720",
    "end": "1178960"
  },
  {
    "text": "help you with your request and now let's let's get into a little bit of",
    "start": "1178960",
    "end": "1184480"
  },
  {
    "text": "what is what happened when we created barricade we really had a few driving forces in it one of the",
    "start": "1184480",
    "end": "1189919"
  },
  {
    "text": "easiest ones that we had was really keeping it simple we had a process that worked before where we would truly just go and do this",
    "start": "1189919",
    "end": "1196480"
  },
  {
    "text": "stuff manually and we would manually go around the cube ctl commands we would scale our stuff up and we hope we got everything all we",
    "start": "1196480",
    "end": "1203360"
  },
  {
    "text": "really did is take that same idea keep it really simple and just have a service do it for us",
    "start": "1203360",
    "end": "1208400"
  },
  {
    "text": "so that service now which instead of us running that kubectl command the service runs it and the service is",
    "start": "1208400",
    "end": "1215039"
  },
  {
    "text": "normally much more reliable than we are because it remembers and it has a system inside of it to remember when",
    "start": "1215039",
    "end": "1220640"
  },
  {
    "text": "and where to do all this stuff and the other thing that we really kept simple is it has three jobs we didn't",
    "start": "1220640",
    "end": "1226080"
  },
  {
    "text": "try to overload this we didn't try to add a ton of things to it we truly just said hey it's gonna intake events it's gonna warm stuff and",
    "start": "1226080",
    "end": "1232480"
  },
  {
    "text": "it's gonna cool stuff nothing more nothing less it does one very pointed job and it does it very well but",
    "start": "1232480",
    "end": "1240480"
  },
  {
    "text": "let's start talking about some of the processes we use to make this really nice because it really illustrates how nice it is now versus what it was",
    "start": "1240480",
    "end": "1247200"
  },
  {
    "text": "before so now what ends up happening is we have a lambda that pulls a third-party system to see",
    "start": "1247200",
    "end": "1252720"
  },
  {
    "text": "if there's something going on for marketing if it does see something it sends it to barricade barricade then",
    "start": "1252720",
    "end": "1258080"
  },
  {
    "text": "um ingest that that event knows when it's going to happen and then that internal crown job will eventually pick",
    "start": "1258080",
    "end": "1263520"
  },
  {
    "text": "it up and just run that event warm our pods and cool our pods off as well we've also seen a few other things where",
    "start": "1263520",
    "end": "1269840"
  },
  {
    "text": "we have a micro service do this so if ours team is putting something in our",
    "start": "1269840",
    "end": "1275200"
  },
  {
    "text": "internal services that schedule this stuff to go do something like an email or whatever they can go talk to barricade and the",
    "start": "1275200",
    "end": "1281679"
  },
  {
    "text": "beauty of keeping barricade as simple as we did is anything can truly do this and that's the beauty of it",
    "start": "1281679",
    "end": "1287600"
  },
  {
    "text": "we no longer have to have everybody know this mat you know this kubernetes knowledge to know",
    "start": "1287600",
    "end": "1293039"
  },
  {
    "text": "what and when to go do stuff and you know how should i put it up how should i put it down where do i put my pod counts how far",
    "start": "1293039",
    "end": "1300080"
  },
  {
    "text": "should i you know go with the cpu scaling the beauty of this is you have an api call you make that api call just like",
    "start": "1300080",
    "end": "1306559"
  },
  {
    "text": "you would if you were trying to update a user or reset your password or sign in",
    "start": "1306559",
    "end": "1312000"
  },
  {
    "text": "and barricade will do the rest for you you don't have to worry about anything else and that's the beauty of it",
    "start": "1312000",
    "end": "1318000"
  },
  {
    "text": "and just to kind of recap quick what makes barricade so useful is it's really easy",
    "start": "1318000",
    "end": "1323200"
  },
  {
    "text": "there's one endpoint and again it's abstracted away for you so you don't have to know kubernetes under the hood as much as you",
    "start": "1323200",
    "end": "1328799"
  },
  {
    "text": "would really need to and i'm sure at this conference everybody knows kubernetes enough to",
    "start": "1328799",
    "end": "1333840"
  },
  {
    "text": "really get this and done but if you have other application developers on your team at your company",
    "start": "1333840",
    "end": "1339280"
  },
  {
    "text": "they might not know that as much and the ease of use of basically saying hey here's your endpoint here's the few things you send",
    "start": "1339280",
    "end": "1345679"
  },
  {
    "text": "it and it just works and you don't have to deal with it is a huge huge benefit because you don't",
    "start": "1345679",
    "end": "1350720"
  },
  {
    "text": "have to share this knowledge all the time and force people to learn stuff they might not be comfortable with",
    "start": "1350720",
    "end": "1356159"
  },
  {
    "text": "the other huge thing about it is it's really set that you can fire and forget it you put it in barricade barricade will handle it from",
    "start": "1356159",
    "end": "1362640"
  },
  {
    "text": "there unless everything you put in barricade completely wipes itself out somehow crashes your databases crash you",
    "start": "1362640",
    "end": "1369919"
  },
  {
    "text": "have a full system outage you can forget about it and it'll just work at the end which is a huge huge benefit",
    "start": "1369919",
    "end": "1375679"
  },
  {
    "text": "and the biggest part of this the one thing you can take away one nice slide here is we went to a peak of over 80 000",
    "start": "1375679",
    "end": "1384400"
  },
  {
    "text": "requests per minute in less than 30 seconds and before barricade we and after barricade",
    "start": "1384400",
    "end": "1390080"
  },
  {
    "text": "if you pair our air rates we had 93 less errors which is massive i don't know how i'm ever going to start to feel",
    "start": "1390080",
    "end": "1396640"
  },
  {
    "text": "better about these graphs after this because now i have a 90 that i can drop on a slide and say it's nice",
    "start": "1396640",
    "end": "1402960"
  },
  {
    "text": "but again it's a huge win it's a huge thing if you just proactively scale for things that are gonna crash your system",
    "start": "1402960",
    "end": "1408960"
  },
  {
    "text": "you can see these awesome takeaways and now mario is coming back with just a few",
    "start": "1408960",
    "end": "1414880"
  },
  {
    "start": "1412000",
    "end": "1829000"
  },
  {
    "text": "nice things to take away from this talk all right so uh thank you kyle uh here are the takeaways",
    "start": "1414880",
    "end": "1420320"
  },
  {
    "text": "of course we didn't do everything perfect i guarantee it um so first i wanted to cover uh hpa and if",
    "start": "1420320",
    "end": "1426080"
  },
  {
    "text": "we were to attack it today and implement it for our services some of the things we'd be thinking about the space has gotten a lot better uh",
    "start": "1426080",
    "end": "1432960"
  },
  {
    "text": "with many more people focusing on this problem of resource management uh goldilocks from farewell and zops is",
    "start": "1432960",
    "end": "1439760"
  },
  {
    "text": "a great a great tool to at least surface in a nice ui uh some uh possible based on uh vertical",
    "start": "1439760",
    "end": "1446320"
  },
  {
    "text": "pod auto scaler some suggested values which could be helpful for kind of providing a self-service solution for",
    "start": "1446320",
    "end": "1452159"
  },
  {
    "text": "your developers uh to kind of implement uh more sanity to their their resource requests",
    "start": "1452159",
    "end": "1458080"
  },
  {
    "text": "and limits for their services um stormforge is a fantastic company um formerly carbon relay and they have",
    "start": "1458080",
    "end": "1465520"
  },
  {
    "text": "just made massive strides on providing that loopback of testing uh continuously to get a sense of what",
    "start": "1465520",
    "end": "1471919"
  },
  {
    "text": "your resources should be and what makes the most sense for the uh long-term scalability of your application",
    "start": "1471919",
    "end": "1477679"
  },
  {
    "text": "keto which is a cloud native uh computing foundation cncf project is really really cool",
    "start": "1477679",
    "end": "1484000"
  },
  {
    "text": "letting you scale on things like uh your q size from sqs and other you know having other apis to",
    "start": "1484000",
    "end": "1490000"
  },
  {
    "text": "leverage other services to make decisions uh beyond just your cpu and memory uh and then uh with i believe it is 118.",
    "start": "1490000",
    "end": "1498320"
  },
  {
    "text": "um there's a slew of new hpa features that are more than just what is our target percentage um",
    "start": "1498320",
    "end": "1504799"
  },
  {
    "text": "but uh you can actually leverage custom and external metrics which we would have done a lot more i know datadog now",
    "start": "1504799",
    "end": "1511120"
  },
  {
    "text": "offers uh you the ability to use any metric in datadog and scale on that there's",
    "start": "1511120",
    "end": "1516480"
  },
  {
    "text": "also more container focus metrics so it's not just the pod uh metrics of which the hpe makes a",
    "start": "1516480",
    "end": "1522000"
  },
  {
    "text": "decision you can make decisions on solely containers within that pod and then behavior policies uh with rate and",
    "start": "1522000",
    "end": "1528880"
  },
  {
    "text": "window support is huge uh for uh hpa and really ensuring like i",
    "start": "1528880",
    "end": "1534320"
  },
  {
    "text": "was saying with closer autoscaler that we have safe intervals uh that we are we're not thrashing uh",
    "start": "1534320",
    "end": "1539360"
  },
  {
    "text": "thresholds are saying etc and this is unique to everyone so making those something that's configurable is really awesome",
    "start": "1539360",
    "end": "1545200"
  },
  {
    "text": "so um i think that's good for that side yeah so if we look at a few other things i",
    "start": "1545200",
    "end": "1551279"
  },
  {
    "text": "wanted to mention you know always keeping sufficient buffer i mentioned that before um that will always be helpful i think",
    "start": "1551279",
    "end": "1557760"
  },
  {
    "text": "hopefully you're doing that already preferring more instances we always told our developers if you were ever",
    "start": "1557760",
    "end": "1563120"
  },
  {
    "text": "questioning how many instances lead on the higher side we are willing to spend the money up front to ensure",
    "start": "1563120",
    "end": "1568240"
  },
  {
    "text": "that your application has the capacity it needs when a traffic event does a hit",
    "start": "1568240",
    "end": "1573440"
  },
  {
    "text": "slis slos slas the sre methodologies and principles are really important",
    "start": "1573440",
    "end": "1579840"
  },
  {
    "text": "imparting these on developers is definitely another story but there are lots of organizational things you can do",
    "start": "1579840",
    "end": "1584960"
  },
  {
    "text": "uh 12-factor methodologies and other resources out there that you can share and help implement these um work with developers uh not against",
    "start": "1584960",
    "end": "1592880"
  },
  {
    "text": "them uh you know there's a lot of misconceptions around uh the kind of offside of the table and",
    "start": "1592880",
    "end": "1598320"
  },
  {
    "text": "the the development side of the table where developers are throwing things over they don't understand they don't care uh i think this is one of those things",
    "start": "1598320",
    "end": "1605120"
  },
  {
    "text": "where their problems in front of them are much different than your problems uh",
    "start": "1605120",
    "end": "1610640"
  },
  {
    "text": "running that uh actual infrastructure and so you need to uh really you know do one-on-ones with",
    "start": "1610640",
    "end": "1615840"
  },
  {
    "text": "with developers help them understand do more educational uh take those opportunities to educate",
    "start": "1615840",
    "end": "1622000"
  },
  {
    "text": "as much as you can of why this is important and why they should care as a service owner and with the long-term life cycle and you",
    "start": "1622000",
    "end": "1628320"
  },
  {
    "text": "know they don't want to get pinged by pager duty so uh you know there's many many ways you can impart knowledge",
    "start": "1628320",
    "end": "1634159"
  },
  {
    "text": "uh in a more uh flexible way um what happens when uh what happens when",
    "start": "1634159",
    "end": "1639679"
  },
  {
    "text": "you do a deployment and you're currently in a uh traffic event uh and you are not sure that that is",
    "start": "1639679",
    "end": "1647200"
  },
  {
    "text": "something you wanted to happen because you just want things to be stable so this this dials into from",
    "start": "1647200",
    "end": "1652320"
  },
  {
    "text": "code going through a pipeline getting deployed what are the controls that you have in place there this really relies a",
    "start": "1652320",
    "end": "1657840"
  },
  {
    "text": "lot on your pipeline and how you structure your deployments uh of course everyone should be considering open source and third-party",
    "start": "1657840",
    "end": "1664080"
  },
  {
    "text": "tools i mentioned goldilocks uh there's uh you know stormforged there's there's a lot of tooling out there spot to io",
    "start": "1664080",
    "end": "1670080"
  },
  {
    "text": "also uh helps with uh waste and nodes as well so um there's a lot to consider uh i think",
    "start": "1670080",
    "end": "1676399"
  },
  {
    "text": "just soaking for a little while testing is really important um and",
    "start": "1676399",
    "end": "1681600"
  },
  {
    "text": "i think just a couple more things you know we manage nodes ourselves and that is painful and",
    "start": "1681600",
    "end": "1688240"
  },
  {
    "text": "so i really you know think you if you're an eks already or gke you should really look at the other",
    "start": "1688240",
    "end": "1693919"
  },
  {
    "text": "solutions that are provided uh gk autopilot just released aws fargate has been around for a little while",
    "start": "1693919",
    "end": "1699840"
  },
  {
    "text": "um but really question do you need nodes um because when we talk about understanding the cost of a particular",
    "start": "1699840",
    "end": "1705360"
  },
  {
    "text": "service and just that service it's really hard when you're managing your own nodes right there's there's cube costs and other solutions coming out but uh",
    "start": "1705360",
    "end": "1712320"
  },
  {
    "text": "autopilot and fargate really help say actually we're just gonna run exactly what you need",
    "start": "1712320",
    "end": "1717520"
  },
  {
    "text": "exactly what you're requesting and that's all you pay for right you don't have to worry about the nodes being spawned the size of those nodes the",
    "start": "1717520",
    "end": "1723200"
  },
  {
    "text": "types uh allocated uh versus actual capacity um you know so uh moving on i know uh",
    "start": "1723200",
    "end": "1730559"
  },
  {
    "text": "hps are great they have no set of challenges i hope you you've seen that again it's it's trial and error uh kiss uh keep it",
    "start": "1730559",
    "end": "1737039"
  },
  {
    "text": "simple stupid uh one of my favorite uh favorite mottos uh and manual first at automate i think",
    "start": "1737039",
    "end": "1742880"
  },
  {
    "text": "it's one of those things where you have to do it the hard way before you can do it the easy way uh to understand the nuances of of how",
    "start": "1742880",
    "end": "1748880"
  },
  {
    "text": "something actually works and what's going on behind the scenes um so i think uh the",
    "start": "1748880",
    "end": "1755360"
  },
  {
    "text": "ah excellent let me talk about myself some more so uh i'm mario lauria thank you so much to",
    "start": "1755360",
    "end": "1760640"
  },
  {
    "text": "everybody for tuning in today i look forward to some amazing questions i work at a company called",
    "start": "1760640",
    "end": "1765840"
  },
  {
    "text": "carta if you have stock options uh you might have heard of carta we're also doing a lot more around 409",
    "start": "1765840",
    "end": "1772720"
  },
  {
    "text": "evaluations and releasing card x which is letting people now invest in",
    "start": "1772720",
    "end": "1777919"
  },
  {
    "text": "private companies uh which is really really cool it helps people holding stock options uh",
    "start": "1777919",
    "end": "1783120"
  },
  {
    "text": "get some liquidity uh as well so uh you can visit me on the web mario laureate dev links to all of my uh",
    "start": "1783120",
    "end": "1788960"
  },
  {
    "text": "other resources and i think with that i'm gonna hand it off to kyle to talk a little bit more about himself as",
    "start": "1788960",
    "end": "1794720"
  },
  {
    "text": "mario and i mentioned earlier we both work at stockx i am still at stockx if you guys are interested uh we are",
    "start": "1794720",
    "end": "1801600"
  },
  {
    "text": "hiring at all positions if you go to stockx.com scroll down to the bottom there's a jobs link click",
    "start": "1801600",
    "end": "1806880"
  },
  {
    "text": "that everything is listed out there we have a tech blog it's recent there's a lot of graphql stuff like i said",
    "start": "1806880",
    "end": "1812320"
  },
  {
    "text": "i like graphql a little too much so you'll probably see my face on a lot of the stuff feel free to go read it go talk to me go",
    "start": "1812320",
    "end": "1819120"
  },
  {
    "text": "tell me it's either great or bad whatever my twitter is on there as well so if whatever you're feeling let me",
    "start": "1819120",
    "end": "1825440"
  },
  {
    "text": "know it's a good time and with that i would like to say thank you guys thank you everybody for",
    "start": "1825440",
    "end": "1831679"
  },
  {
    "start": "1829000",
    "end": "1838000"
  },
  {
    "text": "uh the talk for listening thank you everybody at the cncf for putting this on it's an awesome time",
    "start": "1831679",
    "end": "1837760"
  },
  {
    "text": "thanks",
    "start": "1837760",
    "end": "1840559"
  }
]
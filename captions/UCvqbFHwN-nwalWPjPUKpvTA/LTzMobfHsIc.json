[
  {
    "start": "0",
    "end": "47000"
  },
  {
    "text": "hello everyone i hope everyone is having",
    "start": "2240",
    "end": "4640"
  },
  {
    "text": "a great time at prom con north america",
    "start": "4640",
    "end": "7440"
  },
  {
    "text": "2021 and at coupon and all the other",
    "start": "7440",
    "end": "10320"
  },
  {
    "text": "co-located events for this year's",
    "start": "10320",
    "end": "13360"
  },
  {
    "text": "flagship cncf event",
    "start": "13360",
    "end": "16640"
  },
  {
    "text": "hi i'm shiva lamba and i'm going to be",
    "start": "16640",
    "end": "18240"
  },
  {
    "text": "giving a lightning talk on machine",
    "start": "18240",
    "end": "20160"
  },
  {
    "text": "learning observability with prometheus",
    "start": "20160",
    "end": "23359"
  },
  {
    "text": "a very quick introduction about myself i",
    "start": "23359",
    "end": "25599"
  },
  {
    "text": "am shivai i'm a contributor and a mesh",
    "start": "25599",
    "end": "28000"
  },
  {
    "text": "mate at layer 5 which is an open source",
    "start": "28000",
    "end": "30480"
  },
  {
    "text": "organization part of the",
    "start": "30480",
    "end": "33200"
  },
  {
    "text": "cncf landscape with its products like",
    "start": "33200",
    "end": "35520"
  },
  {
    "text": "measuring and the smi uh performance and",
    "start": "35520",
    "end": "39360"
  },
  {
    "text": "it is all about service measures and",
    "start": "39360",
    "end": "41440"
  },
  {
    "text": "i've been also a google search code",
    "start": "41440",
    "end": "43520"
  },
  {
    "text": "specifically for service missions",
    "start": "43520",
    "end": "46079"
  },
  {
    "text": "under cncf",
    "start": "46079",
    "end": "48160"
  },
  {
    "start": "47000",
    "end": "110000"
  },
  {
    "text": "first let's talk about the machine",
    "start": "48160",
    "end": "49920"
  },
  {
    "text": "learning life cycle so whenever we talk",
    "start": "49920",
    "end": "52160"
  },
  {
    "text": "about any kind of a machine learning",
    "start": "52160",
    "end": "53600"
  },
  {
    "text": "algorithm we always start with the model",
    "start": "53600",
    "end": "56079"
  },
  {
    "text": "building through which once we have",
    "start": "56079",
    "end": "58079"
  },
  {
    "text": "built the model we undergo the",
    "start": "58079",
    "end": "60320"
  },
  {
    "text": "evaluation and basically the training of",
    "start": "60320",
    "end": "63199"
  },
  {
    "text": "our model and we do experimentation with",
    "start": "63199",
    "end": "65518"
  },
  {
    "text": "all the different kind of um",
    "start": "65519",
    "end": "67760"
  },
  {
    "text": "with the model to whether see whether",
    "start": "67760",
    "end": "69680"
  },
  {
    "text": "it's a good model or not once we have",
    "start": "69680",
    "end": "72799"
  },
  {
    "text": "been consent with or we content with the",
    "start": "72799",
    "end": "75200"
  },
  {
    "text": "model evaluation we productionize the",
    "start": "75200",
    "end": "77119"
  },
  {
    "text": "model and then we put it to testing to",
    "start": "77119",
    "end": "80320"
  },
  {
    "text": "see whether the model is giving us good",
    "start": "80320",
    "end": "82320"
  },
  {
    "text": "accuracy or not and once uh we are able",
    "start": "82320",
    "end": "85360"
  },
  {
    "text": "to test it out completely then we'll go",
    "start": "85360",
    "end": "87600"
  },
  {
    "text": "ahead and actually go ahead and deploy",
    "start": "87600",
    "end": "89360"
  },
  {
    "text": "the machine learning model and once the",
    "start": "89360",
    "end": "91280"
  },
  {
    "text": "model is under deployment and has been",
    "start": "91280",
    "end": "93360"
  },
  {
    "text": "used for production use we will continue",
    "start": "93360",
    "end": "96640"
  },
  {
    "text": "we set up a pipeline through which we'll",
    "start": "96640",
    "end": "98240"
  },
  {
    "text": "be able to actually monitor and observe",
    "start": "98240",
    "end": "100880"
  },
  {
    "text": "our machine learning model and that's",
    "start": "100880",
    "end": "102640"
  },
  {
    "text": "what we're going to be talking about",
    "start": "102640",
    "end": "103600"
  },
  {
    "text": "today is specifically what exactly is",
    "start": "103600",
    "end": "106159"
  },
  {
    "text": "observability and how can we do that for",
    "start": "106159",
    "end": "108240"
  },
  {
    "text": "our machine learning models",
    "start": "108240",
    "end": "109920"
  },
  {
    "text": "now",
    "start": "109920",
    "end": "110880"
  },
  {
    "text": "evaluating the metrics of machine",
    "start": "110880",
    "end": "112399"
  },
  {
    "text": "learning system is really important for",
    "start": "112399",
    "end": "114880"
  },
  {
    "text": "research and even for production as well",
    "start": "114880",
    "end": "117439"
  },
  {
    "text": "because once the machine learning model",
    "start": "117439",
    "end": "118960"
  },
  {
    "text": "has been deployed into production it is",
    "start": "118960",
    "end": "120479"
  },
  {
    "text": "also",
    "start": "120479",
    "end": "121280"
  },
  {
    "text": "very critical to see how is the machine",
    "start": "121280",
    "end": "123200"
  },
  {
    "text": "learning performing at all times because",
    "start": "123200",
    "end": "126000"
  },
  {
    "text": "having of great observability practices",
    "start": "126000",
    "end": "128800"
  },
  {
    "text": "is needed to ensure a",
    "start": "128800",
    "end": "132080"
  },
  {
    "text": "smooth running of our machine learning",
    "start": "132080",
    "end": "133760"
  },
  {
    "text": "model and the machine and metrics",
    "start": "133760",
    "end": "135680"
  },
  {
    "text": "through which on the on the basis of",
    "start": "135680",
    "end": "136959"
  },
  {
    "text": "which we can evaluate the performance of",
    "start": "136959",
    "end": "138480"
  },
  {
    "text": "our model can be interface-based which",
    "start": "138480",
    "end": "140720"
  },
  {
    "text": "could include latency model based with",
    "start": "140720",
    "end": "142480"
  },
  {
    "text": "good include the performance of the",
    "start": "142480",
    "end": "144080"
  },
  {
    "text": "machine learning model or even",
    "start": "144080",
    "end": "145920"
  },
  {
    "text": "infrastructure based that includes the",
    "start": "145920",
    "end": "147680"
  },
  {
    "text": "cpu utilization now some of the other",
    "start": "147680",
    "end": "150239"
  },
  {
    "text": "metrics that we need to also keep in",
    "start": "150239",
    "end": "151840"
  },
  {
    "text": "mind include the latency whenever there",
    "start": "151840",
    "end": "154160"
  },
  {
    "text": "is some kind of a uh ml based on machine",
    "start": "154160",
    "end": "156959"
  },
  {
    "text": "learning based api that has been called",
    "start": "156959",
    "end": "158800"
  },
  {
    "text": "then how much amount of cpu bandwidth",
    "start": "158800",
    "end": "160720"
  },
  {
    "text": "memory bandwidth is actually being used",
    "start": "160720",
    "end": "162720"
  },
  {
    "text": "uh when performing any kind of",
    "start": "162720",
    "end": "164400"
  },
  {
    "text": "prediction how much amount of disk",
    "start": "164400",
    "end": "166080"
  },
  {
    "text": "utilization is actually being used if it",
    "start": "166080",
    "end": "168560"
  },
  {
    "text": "is applicable then what are the",
    "start": "168560",
    "end": "170239"
  },
  {
    "text": "prediction values and how do they change",
    "start": "170239",
    "end": "172560"
  },
  {
    "text": "over a given time frame what are the",
    "start": "172560",
    "end": "174239"
  },
  {
    "text": "minimum and maximum prediction values",
    "start": "174239",
    "end": "176000"
  },
  {
    "text": "that are actually going and we are",
    "start": "176000",
    "end": "177280"
  },
  {
    "text": "getting let's see what is the standard",
    "start": "177280",
    "end": "178879"
  },
  {
    "text": "deviation that we get over a period of",
    "start": "178879",
    "end": "180319"
  },
  {
    "text": "time and also like let's see the changes",
    "start": "180319",
    "end": "182400"
  },
  {
    "text": "to the statistical distribution of all",
    "start": "182400",
    "end": "184159"
  },
  {
    "text": "the predicted values all of these need",
    "start": "184159",
    "end": "186080"
  },
  {
    "text": "to be measured in order to maintain the",
    "start": "186080",
    "end": "188080"
  },
  {
    "text": "observability of a machine learning",
    "start": "188080",
    "end": "189440"
  },
  {
    "text": "model and how can we do that we can do",
    "start": "189440",
    "end": "191360"
  },
  {
    "start": "190000",
    "end": "248000"
  },
  {
    "text": "that with the help of prometheus now",
    "start": "191360",
    "end": "193599"
  },
  {
    "text": "prometheus helps to basically scrape",
    "start": "193599",
    "end": "196000"
  },
  {
    "text": "data or metrics from",
    "start": "196000",
    "end": "198480"
  },
  {
    "text": "instrumented jobs either directly or",
    "start": "198480",
    "end": "200879"
  },
  {
    "text": "indirectly as well um with the help of",
    "start": "200879",
    "end": "204239"
  },
  {
    "text": "short-lived jobs now it is it is capable",
    "start": "204239",
    "end": "207200"
  },
  {
    "text": "of actually storing all these script",
    "start": "207200",
    "end": "209200"
  },
  {
    "text": "samples locally and runs rules over this",
    "start": "209200",
    "end": "212560"
  },
  {
    "text": "data to either let's aggregate or record",
    "start": "212560",
    "end": "215440"
  },
  {
    "text": "even new data",
    "start": "215440",
    "end": "216879"
  },
  {
    "text": "uh from the existing data or to help",
    "start": "216879",
    "end": "218959"
  },
  {
    "text": "generate alerts and one of the most",
    "start": "218959",
    "end": "221120"
  },
  {
    "text": "popular stacks to actually use for",
    "start": "221120",
    "end": "223519"
  },
  {
    "text": "monitoring the metrics is the uh",
    "start": "223519",
    "end": "225360"
  },
  {
    "text": "combination of prometheus that actually",
    "start": "225360",
    "end": "227360"
  },
  {
    "text": "helps to measure the metrics and",
    "start": "227360",
    "end": "228480"
  },
  {
    "text": "graphene that helps to actually create",
    "start": "228480",
    "end": "230239"
  },
  {
    "text": "alerts so from this diagram as you can",
    "start": "230239",
    "end": "232080"
  },
  {
    "text": "see that within the promise server we",
    "start": "232080",
    "end": "234159"
  },
  {
    "text": "are pulling in the metrics we are",
    "start": "234159",
    "end": "236640"
  },
  {
    "text": "evaluating those metrics and then let's",
    "start": "236640",
    "end": "238239"
  },
  {
    "text": "say if those metrics are concerned we",
    "start": "238239",
    "end": "241040"
  },
  {
    "text": "can actually create alerts relevant",
    "start": "241040",
    "end": "242560"
  },
  {
    "text": "alerts so that we can be notified if",
    "start": "242560",
    "end": "244159"
  },
  {
    "text": "certain metrics are falling behind",
    "start": "244159",
    "end": "247280"
  },
  {
    "text": "and this diagram sort of shows you an",
    "start": "247280",
    "end": "250080"
  },
  {
    "start": "248000",
    "end": "307000"
  },
  {
    "text": "example of that where we are basically",
    "start": "250080",
    "end": "251680"
  },
  {
    "text": "creating a dashboard in grifana but we",
    "start": "251680",
    "end": "253840"
  },
  {
    "text": "are actually going and uh looking at all",
    "start": "253840",
    "end": "256799"
  },
  {
    "text": "the different metrics uh we're sort of",
    "start": "256799",
    "end": "259120"
  },
  {
    "text": "evaluating the metrics and fetching the",
    "start": "259120",
    "end": "261120"
  },
  {
    "text": "metrics uh for example this particular",
    "start": "261120",
    "end": "263040"
  },
  {
    "text": "example showcases an example of the",
    "start": "263040",
    "end": "265040"
  },
  {
    "text": "average house price uh prediction and we",
    "start": "265040",
    "end": "268400"
  },
  {
    "text": "are evaluating all of that and all these",
    "start": "268400",
    "end": "270240"
  },
  {
    "text": "metrics are getting measured with the",
    "start": "270240",
    "end": "271440"
  },
  {
    "text": "help of from atheists and alerts can be",
    "start": "271440",
    "end": "273600"
  },
  {
    "text": "generated with the help of grifana",
    "start": "273600",
    "end": "275759"
  },
  {
    "text": "so that's pretty much it for this",
    "start": "275759",
    "end": "277360"
  },
  {
    "text": "lightning talk uh i hope if you have",
    "start": "277360",
    "end": "279600"
  },
  {
    "text": "liked this presentation reach out to me",
    "start": "279600",
    "end": "281440"
  },
  {
    "text": "on twitter and on my github uh the main",
    "start": "281440",
    "end": "283759"
  },
  {
    "text": "idea again behind prometheus is to be",
    "start": "283759",
    "end": "286400"
  },
  {
    "text": "able to monitor and machine learning",
    "start": "286400",
    "end": "288560"
  },
  {
    "text": "models which are in production and",
    "start": "288560",
    "end": "290240"
  },
  {
    "text": "deployed need to be monitored and",
    "start": "290240",
    "end": "292639"
  },
  {
    "text": "prometheus can play an important role in",
    "start": "292639",
    "end": "295280"
  },
  {
    "text": "monitoring the different kind of metrics",
    "start": "295280",
    "end": "296880"
  },
  {
    "text": "on the basis of which you want to adjust",
    "start": "296880",
    "end": "298160"
  },
  {
    "text": "the performance of our machine learning",
    "start": "298160",
    "end": "300000"
  },
  {
    "text": "model with that in mind thank you so",
    "start": "300000",
    "end": "302080"
  },
  {
    "text": "much for watching this lighting talk and",
    "start": "302080",
    "end": "303680"
  },
  {
    "text": "i hope to see you",
    "start": "303680",
    "end": "304960"
  },
  {
    "text": "soon in a cubecoin",
    "start": "304960",
    "end": "308680"
  }
]
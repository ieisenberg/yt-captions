[
  {
    "text": "my name is Charles and Alexis will be on",
    "start": "0",
    "end": "2639"
  },
  {
    "text": "the stage right here",
    "start": "2639",
    "end": "4620"
  },
  {
    "text": "so um and my name is engineer mavenkood",
    "start": "4620",
    "end": "8220"
  },
  {
    "text": "we do a lot of things around",
    "start": "8220",
    "end": "9920"
  },
  {
    "text": "ml Ops deploying application on",
    "start": "9920",
    "end": "12420"
  },
  {
    "text": "kubernetes and we've been using ago a",
    "start": "12420",
    "end": "15120"
  },
  {
    "text": "lot in the last few months and years",
    "start": "15120",
    "end": "18180"
  },
  {
    "text": "so uh we're from Texas so we drill all",
    "start": "18180",
    "end": "20939"
  },
  {
    "text": "things around prohibition insulable ml",
    "start": "20939",
    "end": "23520"
  },
  {
    "text": "applications on cloud diagnostic",
    "start": "23520",
    "end": "25980"
  },
  {
    "text": "infrastructure we basically Alpac",
    "start": "25980",
    "end": "29039"
  },
  {
    "text": "customers operationalize and deploy",
    "start": "29039",
    "end": "30960"
  },
  {
    "text": "their models at skill and we do a lot of",
    "start": "30960",
    "end": "33420"
  },
  {
    "text": "things around data Lake feature stores",
    "start": "33420",
    "end": "35579"
  },
  {
    "text": "and Model Management",
    "start": "35579",
    "end": "39140"
  },
  {
    "text": "yes so uh the agenda for today uh what",
    "start": "40260",
    "end": "44399"
  },
  {
    "text": "it takes to build Enterprise machine",
    "start": "44399",
    "end": "45899"
  },
  {
    "text": "learning platform implementing Cloud",
    "start": "45899",
    "end": "47460"
  },
  {
    "text": "agnostic ML workflows on k8s machine",
    "start": "47460",
    "end": "50640"
  },
  {
    "text": "learning model dataprep and feature",
    "start": "50640",
    "end": "52680"
  },
  {
    "text": "engineering event driven ml model",
    "start": "52680",
    "end": "54660"
  },
  {
    "text": "training and with Argo workflow and",
    "start": "54660",
    "end": "57180"
  },
  {
    "text": "events and implementing model deployment",
    "start": "57180",
    "end": "59579"
  },
  {
    "text": "and serving Pipeline with the k-serv",
    "start": "59579",
    "end": "63300"
  },
  {
    "text": "so I'm going to take on the first few",
    "start": "63300",
    "end": "66000"
  },
  {
    "text": "sections of the slide what it takes to",
    "start": "66000",
    "end": "67920"
  },
  {
    "text": "build Cloud agnostic and model",
    "start": "67920",
    "end": "69840"
  },
  {
    "text": "infrastructure",
    "start": "69840",
    "end": "71520"
  },
  {
    "text": "so the goal of any production grade ml",
    "start": "71520",
    "end": "74280"
  },
  {
    "text": "machine learning projects is to build a",
    "start": "74280",
    "end": "76140"
  },
  {
    "text": "statistical model using a well curated",
    "start": "76140",
    "end": "78180"
  },
  {
    "text": "data sets and the main artifacts like we",
    "start": "78180",
    "end": "81360"
  },
  {
    "text": "all know is the data the model and the",
    "start": "81360",
    "end": "83520"
  },
  {
    "text": "code so the data will keep changing your",
    "start": "83520",
    "end": "85799"
  },
  {
    "text": "code will be changing and you keep",
    "start": "85799",
    "end": "87900"
  },
  {
    "text": "producing model output artifacts so",
    "start": "87900",
    "end": "90600"
  },
  {
    "text": "there's a typical amount workflow looks",
    "start": "90600",
    "end": "92400"
  },
  {
    "text": "like this where you're acquiring the",
    "start": "92400",
    "end": "93780"
  },
  {
    "text": "data you're doing data prep you're doing",
    "start": "93780",
    "end": "95579"
  },
  {
    "text": "feature engineering then you run through",
    "start": "95579",
    "end": "97619"
  },
  {
    "text": "multiple iterations of your model",
    "start": "97619",
    "end": "99060"
  },
  {
    "text": "training then onto your server model and",
    "start": "99060",
    "end": "102180"
  },
  {
    "text": "you still mounted out the model for",
    "start": "102180",
    "end": "103500"
  },
  {
    "text": "drift so typically a lot of Mr projects",
    "start": "103500",
    "end": "106680"
  },
  {
    "text": "stats on cloud services like Google AWS",
    "start": "106680",
    "end": "110579"
  },
  {
    "text": "Azure or we have some customers that do",
    "start": "110579",
    "end": "112860"
  },
  {
    "text": "on-prem as well",
    "start": "112860",
    "end": "115700"
  },
  {
    "text": "um but ml like you said is very",
    "start": "115979",
    "end": "118799"
  },
  {
    "text": "difficult even if you go with the",
    "start": "118799",
    "end": "120299"
  },
  {
    "text": "managed service providers like on on",
    "start": "120299",
    "end": "122399"
  },
  {
    "text": "Google on Amazon or Azure uh you go",
    "start": "122399",
    "end": "125700"
  },
  {
    "text": "through the process of identifying the",
    "start": "125700",
    "end": "127740"
  },
  {
    "text": "data you need connection to the data",
    "start": "127740",
    "end": "130020"
  },
  {
    "text": "source uh preparing the data then you go",
    "start": "130020",
    "end": "133200"
  },
  {
    "text": "through multiple iterations of training",
    "start": "133200",
    "end": "134819"
  },
  {
    "text": "the model onto Savage so there's a lot",
    "start": "134819",
    "end": "137640"
  },
  {
    "text": "more impact to this that makes it really",
    "start": "137640",
    "end": "139260"
  },
  {
    "text": "difficult so",
    "start": "139260",
    "end": "140700"
  },
  {
    "text": "um and one thing that will send",
    "start": "140700",
    "end": "143099"
  },
  {
    "text": "consultant in this place a lot is like",
    "start": "143099",
    "end": "144780"
  },
  {
    "text": "if you're trying to build an ml model",
    "start": "144780",
    "end": "146520"
  },
  {
    "text": "you want to make sure you can reproduce",
    "start": "146520",
    "end": "148379"
  },
  {
    "text": "the entire pipeline which is one thing",
    "start": "148379",
    "end": "150720"
  },
  {
    "text": "we've been able to successfully do with",
    "start": "150720",
    "end": "152340"
  },
  {
    "text": "devops process where you have a process",
    "start": "152340",
    "end": "154200"
  },
  {
    "text": "that you can reproduce uh you have",
    "start": "154200",
    "end": "156720"
  },
  {
    "text": "components that you want to make sure",
    "start": "156720",
    "end": "158520"
  },
  {
    "text": "that you have components that you can",
    "start": "158520",
    "end": "159900"
  },
  {
    "text": "reuse so if a data scientist or ml",
    "start": "159900",
    "end": "162300"
  },
  {
    "text": "engineer is working on a particular",
    "start": "162300",
    "end": "163620"
  },
  {
    "text": "components you want to be able to like",
    "start": "163620",
    "end": "165599"
  },
  {
    "text": "share with other team members and things",
    "start": "165599",
    "end": "167700"
  },
  {
    "text": "like that then the other thing is",
    "start": "167700",
    "end": "169560"
  },
  {
    "text": "manageability being able to manage all",
    "start": "169560",
    "end": "172080"
  },
  {
    "text": "the output artifacts for audio trades",
    "start": "172080",
    "end": "174180"
  },
  {
    "text": "and things like that then automation",
    "start": "174180",
    "end": "175980"
  },
  {
    "text": "they will process so that the process",
    "start": "175980",
    "end": "178500"
  },
  {
    "text": "runs by itself and things like that",
    "start": "178500",
    "end": "181260"
  },
  {
    "text": "so um to get started a lot of companies",
    "start": "181260",
    "end": "183959"
  },
  {
    "text": "use managed services on AWS or you can",
    "start": "183959",
    "end": "187560"
  },
  {
    "text": "do the same thing with azure oh you can",
    "start": "187560",
    "end": "189959"
  },
  {
    "text": "do the same thing with Google they're",
    "start": "189959",
    "end": "192000"
  },
  {
    "text": "all managed services that will get you",
    "start": "192000",
    "end": "193379"
  },
  {
    "text": "up and going and things like that but in",
    "start": "193379",
    "end": "196739"
  },
  {
    "text": "reality what you're doing whenever",
    "start": "196739",
    "end": "198300"
  },
  {
    "text": "you're trying to build any ml pipeline",
    "start": "198300",
    "end": "199980"
  },
  {
    "text": "is the number one thing is like you",
    "start": "199980",
    "end": "201540"
  },
  {
    "text": "always need to solve the data you ingest",
    "start": "201540",
    "end": "203280"
  },
  {
    "text": "it you do data prep you do future",
    "start": "203280",
    "end": "205620"
  },
  {
    "text": "engineering and you can now decide to",
    "start": "205620",
    "end": "207840"
  },
  {
    "text": "run on any of these major Cloud",
    "start": "207840",
    "end": "209400"
  },
  {
    "text": "platforms at least there's three major",
    "start": "209400",
    "end": "211500"
  },
  {
    "text": "ones and uh you now create your trainer",
    "start": "211500",
    "end": "214319"
  },
  {
    "text": "models you do model scoring to see if",
    "start": "214319",
    "end": "216420"
  },
  {
    "text": "the model is good enough and you do your",
    "start": "216420",
    "end": "217980"
  },
  {
    "text": "inferencing",
    "start": "217980",
    "end": "219180"
  },
  {
    "text": "so in an Enterprise it gets a little bit",
    "start": "219180",
    "end": "222060"
  },
  {
    "text": "more complex especially with a lot of",
    "start": "222060",
    "end": "223739"
  },
  {
    "text": "Enterprise trying to go with a",
    "start": "223739",
    "end": "225239"
  },
  {
    "text": "multi-cloud strategy where you have some",
    "start": "225239",
    "end": "227879"
  },
  {
    "text": "people working on Google some people",
    "start": "227879",
    "end": "229379"
  },
  {
    "text": "working on Azure or or Amazon so you're",
    "start": "229379",
    "end": "233819"
  },
  {
    "text": "trying to basically different teams work",
    "start": "233819",
    "end": "236099"
  },
  {
    "text": "on different infrastructures and",
    "start": "236099",
    "end": "237599"
  },
  {
    "text": "sometimes it's a lot more difficult to",
    "start": "237599",
    "end": "239280"
  },
  {
    "text": "like transfer the knowledge between",
    "start": "239280",
    "end": "241260"
  },
  {
    "text": "teams especially if the team is all",
    "start": "241260",
    "end": "243299"
  },
  {
    "text": "built into a particular Cloud",
    "start": "243299",
    "end": "244980"
  },
  {
    "text": "infrastructure provider",
    "start": "244980",
    "end": "247379"
  },
  {
    "text": "so um one thing we've done is to",
    "start": "247379",
    "end": "249659"
  },
  {
    "text": "basically identify the two main things",
    "start": "249659",
    "end": "253500"
  },
  {
    "text": "that you do whenever you're trying to",
    "start": "253500",
    "end": "254700"
  },
  {
    "text": "train a model you have a storage path",
    "start": "254700",
    "end": "256440"
  },
  {
    "text": "where you basically ingesting all this",
    "start": "256440",
    "end": "259500"
  },
  {
    "text": "data you're curious and the data for",
    "start": "259500",
    "end": "261060"
  },
  {
    "text": "your model training and you have the",
    "start": "261060",
    "end": "262320"
  },
  {
    "text": "compute path which is where you have",
    "start": "262320",
    "end": "264000"
  },
  {
    "text": "your gpus or CPUs running on the cloud",
    "start": "264000",
    "end": "267000"
  },
  {
    "text": "and things like that",
    "start": "267000",
    "end": "268979"
  },
  {
    "text": "so uh on the story pack we basically",
    "start": "268979",
    "end": "271919"
  },
  {
    "text": "think about it as a feature Store where",
    "start": "271919",
    "end": "274080"
  },
  {
    "text": "all the things you do to get the data",
    "start": "274080",
    "end": "276960"
  },
  {
    "text": "ready for the ml engineer the data",
    "start": "276960",
    "end": "278759"
  },
  {
    "text": "scientists we curate it and you we have",
    "start": "278759",
    "end": "280800"
  },
  {
    "text": "everything in a feature store and",
    "start": "280800",
    "end": "282720"
  },
  {
    "text": "everything that has to do with your",
    "start": "282720",
    "end": "283919"
  },
  {
    "text": "compute uh basically running your",
    "start": "283919",
    "end": "285960"
  },
  {
    "text": "pipelines and your workflows uh we",
    "start": "285960",
    "end": "288240"
  },
  {
    "text": "basically abstract it as a containerized",
    "start": "288240",
    "end": "290160"
  },
  {
    "text": "application that runs on kubernetes",
    "start": "290160",
    "end": "292259"
  },
  {
    "text": "so because of this we have a cloud",
    "start": "292259",
    "end": "294780"
  },
  {
    "text": "diagnostic layer that can run on any of",
    "start": "294780",
    "end": "298080"
  },
  {
    "text": "the cloud providers as long as we're",
    "start": "298080",
    "end": "300060"
  },
  {
    "text": "running on kubernetes so I'm going to",
    "start": "300060",
    "end": "301560"
  },
  {
    "text": "hand it over to Alex who's going to talk",
    "start": "301560",
    "end": "302880"
  },
  {
    "text": "about all this to the next time yeah so",
    "start": "302880",
    "end": "306060"
  },
  {
    "text": "in order to basically create these",
    "start": "306060",
    "end": "308580"
  },
  {
    "text": "feature stores we use Argo workflows to",
    "start": "308580",
    "end": "311580"
  },
  {
    "text": "basically do the data transformation and",
    "start": "311580",
    "end": "314400"
  },
  {
    "text": "fill the feature store with the data",
    "start": "314400",
    "end": "317100"
  },
  {
    "text": "that's necessary to train the models",
    "start": "317100",
    "end": "319520"
  },
  {
    "text": "but we want to do this in a cloud",
    "start": "319520",
    "end": "321540"
  },
  {
    "text": "agnostic way such that our customers",
    "start": "321540",
    "end": "324660"
  },
  {
    "text": "don't need to worry about if they need",
    "start": "324660",
    "end": "326100"
  },
  {
    "text": "to lift and shift from gcp to AWS",
    "start": "326100",
    "end": "328560"
  },
  {
    "text": "they're able to do so so we deploy with",
    "start": "328560",
    "end": "331620"
  },
  {
    "text": "Argo and Argo CD to give them",
    "start": "331620",
    "end": "335100"
  },
  {
    "text": "flexibility and to basically bring",
    "start": "335100",
    "end": "337080"
  },
  {
    "text": "customers up to speed a lot of our",
    "start": "337080",
    "end": "339360"
  },
  {
    "text": "customers are first-time kubernetes",
    "start": "339360",
    "end": "342180"
  },
  {
    "text": "users and we like to be able to",
    "start": "342180",
    "end": "344240"
  },
  {
    "text": "introduce them in a way that's going to",
    "start": "344240",
    "end": "346500"
  },
  {
    "text": "be good for the long run",
    "start": "346500",
    "end": "350100"
  },
  {
    "text": "and we introduce all the Argo tools",
    "start": "350100",
    "end": "352860"
  },
  {
    "text": "workflows event CD because it gives them",
    "start": "352860",
    "end": "356160"
  },
  {
    "text": "basically a tool set that's going to",
    "start": "356160",
    "end": "357960"
  },
  {
    "text": "last for the long run",
    "start": "357960",
    "end": "360000"
  },
  {
    "text": "and it's very efficient",
    "start": "360000",
    "end": "363380"
  },
  {
    "text": "so",
    "start": "363380",
    "end": "365100"
  },
  {
    "text": "some of the ways that we did this we",
    "start": "365100",
    "end": "368759"
  },
  {
    "text": "basically allow different teams to use",
    "start": "368759",
    "end": "371759"
  },
  {
    "text": "Argo workflows to do whatever they need",
    "start": "371759",
    "end": "373820"
  },
  {
    "text": "some teams are working on feature",
    "start": "373820",
    "end": "376080"
  },
  {
    "text": "extractions some teams are working on",
    "start": "376080",
    "end": "377699"
  },
  {
    "text": "training but they're all using the same",
    "start": "377699",
    "end": "380100"
  },
  {
    "text": "common",
    "start": "380100",
    "end": "381080"
  },
  {
    "text": "platform which is Argo and this has been",
    "start": "381080",
    "end": "383880"
  },
  {
    "text": "very successful for us",
    "start": "383880",
    "end": "386940"
  },
  {
    "text": "um",
    "start": "386940",
    "end": "388080"
  },
  {
    "text": "so in general like we need a data Lake",
    "start": "388080",
    "end": "390060"
  },
  {
    "text": "feature store all that good stuff and",
    "start": "390060",
    "end": "392220"
  },
  {
    "text": "argo's been basically our go-to for",
    "start": "392220",
    "end": "394979"
  },
  {
    "text": "building these workflows and we've been",
    "start": "394979",
    "end": "397319"
  },
  {
    "text": "using uh the dags for some of the more",
    "start": "397319",
    "end": "400020"
  },
  {
    "text": "complicated",
    "start": "400020",
    "end": "401639"
  },
  {
    "text": "um pipelines that we build and it's",
    "start": "401639",
    "end": "403800"
  },
  {
    "text": "worked very well for us some customers",
    "start": "403800",
    "end": "406319"
  },
  {
    "text": "are using tensorflow some are using",
    "start": "406319",
    "end": "408479"
  },
  {
    "text": "other machine learning Frameworks but",
    "start": "408479",
    "end": "411020"
  },
  {
    "text": "doesn't really matter as long as you can",
    "start": "411020",
    "end": "413280"
  },
  {
    "text": "build an audio workflow and they know",
    "start": "413280",
    "end": "415199"
  },
  {
    "text": "how to build workflows it works for them",
    "start": "415199",
    "end": "418560"
  },
  {
    "text": "um so again we use Argo CD workflows",
    "start": "418560",
    "end": "421020"
  },
  {
    "text": "events some of the ways that we use",
    "start": "421020",
    "end": "423479"
  },
  {
    "text": "events or file drop",
    "start": "423479",
    "end": "425300"
  },
  {
    "text": "and like a cron based time triggers are",
    "start": "425300",
    "end": "428460"
  },
  {
    "text": "very common",
    "start": "428460",
    "end": "429979"
  },
  {
    "text": "and yeah Argo CD is definitely how we've",
    "start": "429979",
    "end": "434819"
  },
  {
    "text": "been selling",
    "start": "434819",
    "end": "436280"
  },
  {
    "text": "kubernetes to our customers",
    "start": "436280",
    "end": "440240"
  },
  {
    "text": "so being Cloud agnostic has been very",
    "start": "440400",
    "end": "442319"
  },
  {
    "text": "important to us we make sure to stay",
    "start": "442319",
    "end": "444539"
  },
  {
    "text": "open source and just not lock our",
    "start": "444539",
    "end": "447479"
  },
  {
    "text": "customers into any sort of",
    "start": "447479",
    "end": "450360"
  },
  {
    "text": "hosted solution other than just using",
    "start": "450360",
    "end": "452580"
  },
  {
    "text": "open source Argo CD and this has been a",
    "start": "452580",
    "end": "456060"
  },
  {
    "text": "great solution for us and with lots of",
    "start": "456060",
    "end": "459180"
  },
  {
    "text": "help from the Argo community",
    "start": "459180",
    "end": "462319"
  },
  {
    "text": "so yeah so basically the some of the",
    "start": "463259",
    "end": "465240"
  },
  {
    "text": "steps that we use to do this we",
    "start": "465240",
    "end": "467039"
  },
  {
    "text": "provision on the the cloud offering of",
    "start": "467039",
    "end": "470759"
  },
  {
    "text": "their choice we deployed node pools we",
    "start": "470759",
    "end": "474360"
  },
  {
    "text": "use Argo CD application sets to define",
    "start": "474360",
    "end": "477000"
  },
  {
    "text": "the basically the base of the cluster",
    "start": "477000",
    "end": "480120"
  },
  {
    "text": "and the serving and event plot",
    "start": "480120",
    "end": "483319"
  },
  {
    "text": "components of the cluster and then we",
    "start": "483319",
    "end": "486539"
  },
  {
    "text": "deploy it",
    "start": "486539",
    "end": "488639"
  },
  {
    "text": "um here's an example of how we use",
    "start": "488639",
    "end": "491220"
  },
  {
    "text": "application set we kind of use it to",
    "start": "491220",
    "end": "494280"
  },
  {
    "text": "Define what's the base of a cluster for",
    "start": "494280",
    "end": "497060"
  },
  {
    "text": "this client in this particular use case",
    "start": "497060",
    "end": "502199"
  },
  {
    "text": "we have all the namespaces the role",
    "start": "502199",
    "end": "504539"
  },
  {
    "text": "bindings Argo CD managing itself and",
    "start": "504539",
    "end": "508440"
  },
  {
    "text": "everything needed to have a machine",
    "start": "508440",
    "end": "511139"
  },
  {
    "text": "learning platform",
    "start": "511139",
    "end": "514039"
  },
  {
    "text": "and here's kind of what our Argos CD",
    "start": "515219",
    "end": "517700"
  },
  {
    "text": "dashboard looks like",
    "start": "517700",
    "end": "520740"
  },
  {
    "text": "after being deployed we have three",
    "start": "520740",
    "end": "523380"
  },
  {
    "text": "application sets in this example we got",
    "start": "523380",
    "end": "526740"
  },
  {
    "text": "the base which gives all the necessary",
    "start": "526740",
    "end": "529220"
  },
  {
    "text": "infrastructure to kind of deploy uh",
    "start": "529220",
    "end": "532860"
  },
  {
    "text": "custom resources such as k-serv or Argo",
    "start": "532860",
    "end": "536100"
  },
  {
    "text": "events",
    "start": "536100",
    "end": "538620"
  },
  {
    "text": "and this has worked very well for us",
    "start": "538620",
    "end": "541680"
  },
  {
    "text": "and application set has been nice moving",
    "start": "541680",
    "end": "543959"
  },
  {
    "text": "away from the app of apps pattern",
    "start": "543959",
    "end": "546360"
  },
  {
    "text": "application set has been you know it's",
    "start": "546360",
    "end": "549899"
  },
  {
    "text": "it's a lot better",
    "start": "549899",
    "end": "552120"
  },
  {
    "text": "um",
    "start": "552120",
    "end": "554120"
  },
  {
    "text": "so yeah again here's a look at like uh",
    "start": "554580",
    "end": "556740"
  },
  {
    "text": "like how we use application set to",
    "start": "556740",
    "end": "558899"
  },
  {
    "text": "deploy the all the namespaces needed we",
    "start": "558899",
    "end": "562080"
  },
  {
    "text": "keep our namespaces in one General",
    "start": "562080",
    "end": "565040"
  },
  {
    "text": "application so that any any of the apps",
    "start": "565040",
    "end": "568380"
  },
  {
    "text": "that need to reuse these namespaces are",
    "start": "568380",
    "end": "570660"
  },
  {
    "text": "easily able to use them without needing",
    "start": "570660",
    "end": "573480"
  },
  {
    "text": "to worry about the name space is created",
    "start": "573480",
    "end": "574980"
  },
  {
    "text": "or not",
    "start": "574980",
    "end": "577339"
  },
  {
    "text": "here's a look at what the Baseline Argo",
    "start": "578160",
    "end": "582180"
  },
  {
    "text": "CD dashboard looks like",
    "start": "582180",
    "end": "584279"
  },
  {
    "text": "and yeah I will hand it off to Charles",
    "start": "584279",
    "end": "586860"
  },
  {
    "text": "now yeah thanks Alex so basically we use",
    "start": "586860",
    "end": "590339"
  },
  {
    "text": "the ago City to provision all the things",
    "start": "590339",
    "end": "592080"
  },
  {
    "text": "that we need in a cluster uh to get a ml",
    "start": "592080",
    "end": "595200"
  },
  {
    "text": "process started whenever we have a new",
    "start": "595200",
    "end": "596820"
  },
  {
    "text": "project so the next thing we do is a",
    "start": "596820",
    "end": "598620"
  },
  {
    "text": "data preparation of making sure we're",
    "start": "598620",
    "end": "600839"
  },
  {
    "text": "curating the right data set for data",
    "start": "600839",
    "end": "602640"
  },
  {
    "text": "scientists to get started whenever they",
    "start": "602640",
    "end": "604620"
  },
  {
    "text": "need to train a model and make it easy",
    "start": "604620",
    "end": "606600"
  },
  {
    "text": "for them to do it in a very consistent",
    "start": "606600",
    "end": "608399"
  },
  {
    "text": "and repeatable way we want to have an",
    "start": "608399",
    "end": "610980"
  },
  {
    "text": "agile and efficient process so that if",
    "start": "610980",
    "end": "613500"
  },
  {
    "text": "I'm once I've prepared the data I can",
    "start": "613500",
    "end": "615899"
  },
  {
    "text": "share with multiple data scientists on",
    "start": "615899",
    "end": "617580"
  },
  {
    "text": "the team and if we need more features in",
    "start": "617580",
    "end": "619800"
  },
  {
    "text": "that data sets we can always recreate it",
    "start": "619800",
    "end": "622140"
  },
  {
    "text": "without basically slowing down the",
    "start": "622140",
    "end": "624540"
  },
  {
    "text": "existing uh data scientists or ml",
    "start": "624540",
    "end": "626820"
  },
  {
    "text": "Engineers working on this and at the end",
    "start": "626820",
    "end": "629100"
  },
  {
    "text": "of the day we want to be able to create",
    "start": "629100",
    "end": "630360"
  },
  {
    "text": "a shareable feature set that you can",
    "start": "630360",
    "end": "632519"
  },
  {
    "text": "basically authorize a user or a team to",
    "start": "632519",
    "end": "636180"
  },
  {
    "text": "use so that they can use to train their",
    "start": "636180",
    "end": "637620"
  },
  {
    "text": "models and things like that",
    "start": "637620",
    "end": "639240"
  },
  {
    "text": "so um",
    "start": "639240",
    "end": "642000"
  },
  {
    "text": "so a typical ml workflow for a data",
    "start": "642000",
    "end": "645240"
  },
  {
    "text": "scientist looks like this you just you",
    "start": "645240",
    "end": "647279"
  },
  {
    "text": "get all your data from your Jupiter",
    "start": "647279",
    "end": "648839"
  },
  {
    "text": "notebook and things like that and you",
    "start": "648839",
    "end": "651000"
  },
  {
    "text": "try to use it to train your model but",
    "start": "651000",
    "end": "653279"
  },
  {
    "text": "the challenge with that is like if",
    "start": "653279",
    "end": "655079"
  },
  {
    "text": "you're trying to basically do everything",
    "start": "655079",
    "end": "656579"
  },
  {
    "text": "at scale it's going to work because",
    "start": "656579",
    "end": "659040"
  },
  {
    "text": "you're not going to easily transition",
    "start": "659040",
    "end": "661200"
  },
  {
    "text": "from what you're doing on your local to",
    "start": "661200",
    "end": "663300"
  },
  {
    "text": "a production environment so in our case",
    "start": "663300",
    "end": "666420"
  },
  {
    "text": "for for what we do and I would go about",
    "start": "666420",
    "end": "669120"
  },
  {
    "text": "it we basically create kind of like a",
    "start": "669120",
    "end": "671339"
  },
  {
    "text": "data Lake where you can land all your",
    "start": "671339",
    "end": "672779"
  },
  {
    "text": "raw data and we have it I go workflow",
    "start": "672779",
    "end": "676380"
  },
  {
    "text": "pipeline that transforms the data into a",
    "start": "676380",
    "end": "678540"
  },
  {
    "text": "feature store so we have a feature store",
    "start": "678540",
    "end": "680100"
  },
  {
    "text": "we have a skimmer with all the feature",
    "start": "680100",
    "end": "682500"
  },
  {
    "text": "vectors and all the attributes that you",
    "start": "682500",
    "end": "684120"
  },
  {
    "text": "need to train your model and the I go",
    "start": "684120",
    "end": "686700"
  },
  {
    "text": "see the basically runs on that on on the",
    "start": "686700",
    "end": "689160"
  },
  {
    "text": "kubernetes infrastructure and because we",
    "start": "689160",
    "end": "692100"
  },
  {
    "text": "try to be Cloud agnostic any solution we",
    "start": "692100",
    "end": "694740"
  },
  {
    "text": "build should be able to run on any of",
    "start": "694740",
    "end": "696600"
  },
  {
    "text": "the major Cloud providers so from there",
    "start": "696600",
    "end": "698940"
  },
  {
    "text": "the data scientists can now go in and",
    "start": "698940",
    "end": "701459"
  },
  {
    "text": "start pulling all the data they need and",
    "start": "701459",
    "end": "703440"
  },
  {
    "text": "start training their models",
    "start": "703440",
    "end": "706579"
  },
  {
    "text": "so uh so just to zoom in on the data",
    "start": "708779",
    "end": "712140"
  },
  {
    "text": "Lake path which is where we keep all the",
    "start": "712140",
    "end": "714000"
  },
  {
    "text": "raw data so every time we inject data we",
    "start": "714000",
    "end": "716279"
  },
  {
    "text": "have new Delta so we need to keep",
    "start": "716279",
    "end": "718260"
  },
  {
    "text": "ingesting the data it could be streaming",
    "start": "718260",
    "end": "720000"
  },
  {
    "text": "it could be batch and once we ingest the",
    "start": "720000",
    "end": "722640"
  },
  {
    "text": "data we trigger a workflow to basically",
    "start": "722640",
    "end": "724860"
  },
  {
    "text": "convert it to the Future store",
    "start": "724860",
    "end": "726839"
  },
  {
    "text": "requirements so it looks for the batch",
    "start": "726839",
    "end": "730560"
  },
  {
    "text": "work stream it could be a data that will",
    "start": "730560",
    "end": "732420"
  },
  {
    "text": "land in an S3 bucket or Google storage",
    "start": "732420",
    "end": "735240"
  },
  {
    "text": "or set where actual customers are",
    "start": "735240",
    "end": "737339"
  },
  {
    "text": "on-prem they're not in the cloud so we",
    "start": "737339",
    "end": "738959"
  },
  {
    "text": "basically use something like that and",
    "start": "738959",
    "end": "740220"
  },
  {
    "text": "for the streaming data we have something",
    "start": "740220",
    "end": "741600"
  },
  {
    "text": "like this now we have a pipeline that",
    "start": "741600",
    "end": "743640"
  },
  {
    "text": "basically converts and transform this",
    "start": "743640",
    "end": "745680"
  },
  {
    "text": "into future groups and the future groups",
    "start": "745680",
    "end": "748320"
  },
  {
    "text": "can now be used to train the model in",
    "start": "748320",
    "end": "750899"
  },
  {
    "text": "the offline mode or you can have the",
    "start": "750899",
    "end": "752640"
  },
  {
    "text": "online mode where we create a key value",
    "start": "752640",
    "end": "754380"
  },
  {
    "text": "pair that maps to the uh greater digital",
    "start": "754380",
    "end": "758040"
  },
  {
    "text": "to that maps to Greater details about",
    "start": "758040",
    "end": "759720"
  },
  {
    "text": "the data set that you can now use",
    "start": "759720",
    "end": "761220"
  },
  {
    "text": "whenever you're serving the model so uh",
    "start": "761220",
    "end": "763860"
  },
  {
    "text": "basically in all these places we're",
    "start": "763860",
    "end": "765540"
  },
  {
    "text": "leveraging the ago workflow so all the",
    "start": "765540",
    "end": "768240"
  },
  {
    "text": "way uh from Landing to dinner I think",
    "start": "768240",
    "end": "770459"
  },
  {
    "text": "Alex talked about it earlier where we",
    "start": "770459",
    "end": "773100"
  },
  {
    "text": "have the Argo event that whenever the",
    "start": "773100",
    "end": "775620"
  },
  {
    "text": "file drops we trigger workflow so but",
    "start": "775620",
    "end": "778260"
  },
  {
    "text": "we're not going to trigger for every",
    "start": "778260",
    "end": "779760"
  },
  {
    "text": "file in the batch process so we have a",
    "start": "779760",
    "end": "781800"
  },
  {
    "text": "way of basically having a trigger file",
    "start": "781800",
    "end": "785339"
  },
  {
    "text": "that whenever that trigger for lands we",
    "start": "785339",
    "end": "787680"
  },
  {
    "text": "just trigger a batch of the files and we",
    "start": "787680",
    "end": "789959"
  },
  {
    "text": "process it and we curate the future so",
    "start": "789959",
    "end": "791760"
  },
  {
    "text": "this way the data scientists can always",
    "start": "791760",
    "end": "794339"
  },
  {
    "text": "have near data they can always go back",
    "start": "794339",
    "end": "796740"
  },
  {
    "text": "and retrain their model and if we notice",
    "start": "796740",
    "end": "799200"
  },
  {
    "text": "any model Drift We have a pipeline that",
    "start": "799200",
    "end": "801300"
  },
  {
    "text": "goes back and we train the model and",
    "start": "801300",
    "end": "803339"
  },
  {
    "text": "basically checks what's going on so",
    "start": "803339",
    "end": "805440"
  },
  {
    "text": "we're using aggro workflowing a lot of",
    "start": "805440",
    "end": "807540"
  },
  {
    "text": "all these use cases and these are some",
    "start": "807540",
    "end": "809459"
  },
  {
    "text": "of the pipelines that we're working on I",
    "start": "809459",
    "end": "811019"
  },
  {
    "text": "think Alex has some more details on that",
    "start": "811019",
    "end": "814019"
  },
  {
    "text": "yes so we use batch workflows streaming",
    "start": "814019",
    "end": "817560"
  },
  {
    "text": "feature store creation and online",
    "start": "817560",
    "end": "820320"
  },
  {
    "text": "feature store and offline feature store",
    "start": "820320",
    "end": "822240"
  },
  {
    "text": "all using Argo workflows to kind of",
    "start": "822240",
    "end": "824279"
  },
  {
    "text": "build out these",
    "start": "824279",
    "end": "825740"
  },
  {
    "text": "components here's an example of how we",
    "start": "825740",
    "end": "830060"
  },
  {
    "text": "built a small data Lake we basically did",
    "start": "830060",
    "end": "833880"
  },
  {
    "text": "you know data ingestion like once the",
    "start": "833880",
    "end": "836459"
  },
  {
    "text": "message is fired off we consume the",
    "start": "836459",
    "end": "840180"
  },
  {
    "text": "message we do schema validation on it",
    "start": "840180",
    "end": "842220"
  },
  {
    "text": "make sure the message looks like the",
    "start": "842220",
    "end": "843839"
  },
  {
    "text": "correct shape and then we write it to",
    "start": "843839",
    "end": "846060"
  },
  {
    "text": "the data store",
    "start": "846060",
    "end": "847100"
  },
  {
    "text": "[Music]",
    "start": "847100",
    "end": "848760"
  },
  {
    "text": "uh same example but like in a streaming",
    "start": "848760",
    "end": "851339"
  },
  {
    "text": "situation we consume a message from",
    "start": "851339",
    "end": "853320"
  },
  {
    "text": "Kafka we transform the message and then",
    "start": "853320",
    "end": "856860"
  },
  {
    "text": "we write to a feature store",
    "start": "856860",
    "end": "859440"
  },
  {
    "text": "um",
    "start": "859440",
    "end": "860339"
  },
  {
    "text": "and here's the feature store creation",
    "start": "860339",
    "end": "862139"
  },
  {
    "text": "where we read data and we transform it",
    "start": "862139",
    "end": "865920"
  },
  {
    "text": "create the key value Pairs and then",
    "start": "865920",
    "end": "867660"
  },
  {
    "text": "write this Cilla",
    "start": "867660",
    "end": "870920"
  },
  {
    "text": "the benefit to have in a future store it",
    "start": "871200",
    "end": "872940"
  },
  {
    "text": "makes it easier to migrate the workflows",
    "start": "872940",
    "end": "874620"
  },
  {
    "text": "we're not tied to any particular cloud",
    "start": "874620",
    "end": "876480"
  },
  {
    "text": "provider and it's in general it's just",
    "start": "876480",
    "end": "879540"
  },
  {
    "text": "it gives a common data Lake for any",
    "start": "879540",
    "end": "883079"
  },
  {
    "text": "machine learning engineer to come in and",
    "start": "883079",
    "end": "885839"
  },
  {
    "text": "build a model on",
    "start": "885839",
    "end": "888800"
  },
  {
    "text": "um Charles yeah sure",
    "start": "889440",
    "end": "891480"
  },
  {
    "text": "so uh to basically operationalize all",
    "start": "891480",
    "end": "894420"
  },
  {
    "text": "these things we need to react to events",
    "start": "894420",
    "end": "896880"
  },
  {
    "text": "and the event could be things like code",
    "start": "896880",
    "end": "898800"
  },
  {
    "text": "change whenever you come in your code to",
    "start": "898800",
    "end": "900420"
  },
  {
    "text": "the git repo data change whenever",
    "start": "900420",
    "end": "903060"
  },
  {
    "text": "there's a change in your data sets uh",
    "start": "903060",
    "end": "905579"
  },
  {
    "text": "you want to create a retraining if it's",
    "start": "905579",
    "end": "907199"
  },
  {
    "text": "necessary and if you notice that your",
    "start": "907199",
    "end": "908880"
  },
  {
    "text": "model is drifting uh basically you want",
    "start": "908880",
    "end": "911040"
  },
  {
    "text": "to recruit the pipeline so uh when we",
    "start": "911040",
    "end": "914040"
  },
  {
    "text": "want to operationalize our workflow in",
    "start": "914040",
    "end": "915540"
  },
  {
    "text": "production we're basically leveraging",
    "start": "915540",
    "end": "917100"
  },
  {
    "text": "our goal events so ago events is kind of",
    "start": "917100",
    "end": "919560"
  },
  {
    "text": "like like The Listener for us to",
    "start": "919560",
    "end": "921240"
  },
  {
    "text": "automatically trigger all these",
    "start": "921240",
    "end": "922620"
  },
  {
    "text": "workflows based on uh code change",
    "start": "922620",
    "end": "925320"
  },
  {
    "text": "feature updates or model drift or",
    "start": "925320",
    "end": "927480"
  },
  {
    "text": "everyone or beta Pipeline and things",
    "start": "927480",
    "end": "929579"
  },
  {
    "text": "like that we also triggered this events",
    "start": "929579",
    "end": "932519"
  },
  {
    "text": "based on kubernetes resource deployment",
    "start": "932519",
    "end": "934860"
  },
  {
    "text": "basically monitoring the states of a",
    "start": "934860",
    "end": "937740"
  },
  {
    "text": "resource especially with case K7 Alex is",
    "start": "937740",
    "end": "940440"
  },
  {
    "text": "going to talk about that in a little bit",
    "start": "940440",
    "end": "942660"
  },
  {
    "text": "so",
    "start": "942660",
    "end": "944459"
  },
  {
    "text": "um a typical workflow looks like this",
    "start": "944459",
    "end": "946320"
  },
  {
    "text": "where you have the data engineer or ml",
    "start": "946320",
    "end": "949139"
  },
  {
    "text": "engineer working on a patch class stuff",
    "start": "949139",
    "end": "950820"
  },
  {
    "text": "you check it in if you're using Git it",
    "start": "950820",
    "end": "952680"
  },
  {
    "text": "triggers a good action and we build a",
    "start": "952680",
    "end": "955079"
  },
  {
    "text": "container and we push it to the",
    "start": "955079",
    "end": "956399"
  },
  {
    "text": "container registry then we have Argo CD",
    "start": "956399",
    "end": "959100"
  },
  {
    "text": "check-in to see if there's a new",
    "start": "959100",
    "end": "960360"
  },
  {
    "text": "container then it should be deployed if",
    "start": "960360",
    "end": "962760"
  },
  {
    "text": "you need to return the pipeline then it",
    "start": "962760",
    "end": "965339"
  },
  {
    "text": "basically retrains and deployed the",
    "start": "965339",
    "end": "967260"
  },
  {
    "text": "models and creates a version type for it",
    "start": "967260",
    "end": "969540"
  },
  {
    "text": "so once the model training is done we",
    "start": "969540",
    "end": "972480"
  },
  {
    "text": "basically create another event we have a",
    "start": "972480",
    "end": "975720"
  },
  {
    "text": "metrics table where we're basically",
    "start": "975720",
    "end": "977760"
  },
  {
    "text": "storing all the metrics it could be it",
    "start": "977760",
    "end": "979920"
  },
  {
    "text": "will it could be the accuration the",
    "start": "979920",
    "end": "981779"
  },
  {
    "text": "Precision of the model and we save the",
    "start": "981779",
    "end": "984420"
  },
  {
    "text": "model output of artifact the Frozen",
    "start": "984420",
    "end": "986399"
  },
  {
    "text": "model in the container registry so once",
    "start": "986399",
    "end": "989699"
  },
  {
    "text": "the model drops in this container in",
    "start": "989699",
    "end": "991740"
  },
  {
    "text": "this sorry in this bucket we can trigger",
    "start": "991740",
    "end": "994560"
  },
  {
    "text": "another workflow as well but before we",
    "start": "994560",
    "end": "996300"
  },
  {
    "text": "deploy the workflow uh the pipeline I",
    "start": "996300",
    "end": "999120"
  },
  {
    "text": "want to check to see if the metrics if",
    "start": "999120",
    "end": "1001040"
  },
  {
    "text": "there's any Improvement in the mod also",
    "start": "1001040",
    "end": "1002720"
  },
  {
    "text": "but I'll go event workflow processor",
    "start": "1002720",
    "end": "1005240"
  },
  {
    "text": "check to see if there's any uh",
    "start": "1005240",
    "end": "1007220"
  },
  {
    "text": "significant Improvement in the model",
    "start": "1007220",
    "end": "1009320"
  },
  {
    "text": "that we trained and determine if we need",
    "start": "1009320",
    "end": "1011360"
  },
  {
    "text": "to uh redeploy or not and the same thing",
    "start": "1011360",
    "end": "1014060"
  },
  {
    "text": "with the feature store every time we",
    "start": "1014060",
    "end": "1016160"
  },
  {
    "text": "curate a new data set to the feature",
    "start": "1016160",
    "end": "1017899"
  },
  {
    "text": "store we have a list there that",
    "start": "1017899",
    "end": "1020120"
  },
  {
    "text": "basically triggers an event a workflow",
    "start": "1020120",
    "end": "1022220"
  },
  {
    "text": "event for us to retrain the model and",
    "start": "1022220",
    "end": "1024380"
  },
  {
    "text": "things like that",
    "start": "1024380",
    "end": "1026780"
  },
  {
    "text": "so uh some other sensor I go event",
    "start": "1026780",
    "end": "1029058"
  },
  {
    "text": "sensors that we're building on that that",
    "start": "1029059",
    "end": "1030918"
  },
  {
    "text": "refuse to things like file drops in the",
    "start": "1030919",
    "end": "1033500"
  },
  {
    "text": "bucket basically if there's a file drop",
    "start": "1033500",
    "end": "1036860"
  },
  {
    "text": "or any change in the bucket due to a",
    "start": "1036860",
    "end": "1039380"
  },
  {
    "text": "drop in adding new files or new data",
    "start": "1039380",
    "end": "1042079"
  },
  {
    "text": "sets we can trigger a workflow based on",
    "start": "1042079",
    "end": "1044240"
  },
  {
    "text": "that we check messages to see if there's",
    "start": "1044240",
    "end": "1047298"
  },
  {
    "text": "any new message for streaming data and",
    "start": "1047299",
    "end": "1050179"
  },
  {
    "text": "for kubernetes resources all uh where",
    "start": "1050179",
    "end": "1052940"
  },
  {
    "text": "basically we can basically trigger a",
    "start": "1052940",
    "end": "1055520"
  },
  {
    "text": "workflow if there's a new event in the",
    "start": "1055520",
    "end": "1058580"
  },
  {
    "text": "kubernetes cluster basically sending a",
    "start": "1058580",
    "end": "1060980"
  },
  {
    "text": "notification whenever we're training a",
    "start": "1060980",
    "end": "1062600"
  },
  {
    "text": "model if the model fails or not if the",
    "start": "1062600",
    "end": "1065660"
  },
  {
    "text": "model training was successful or not and",
    "start": "1065660",
    "end": "1067520"
  },
  {
    "text": "we use webbooks to like connect back to",
    "start": "1067520",
    "end": "1070400"
  },
  {
    "text": "something like slack so that um so I'm",
    "start": "1070400",
    "end": "1073039"
  },
  {
    "text": "on geeky like Alex can retrain the model",
    "start": "1073039",
    "end": "1075020"
  },
  {
    "text": "from a slack message",
    "start": "1075020",
    "end": "1077660"
  },
  {
    "text": "so um some of the workflows that we're",
    "start": "1077660",
    "end": "1080059"
  },
  {
    "text": "currently working on we're walking on as",
    "start": "1080059",
    "end": "1082340"
  },
  {
    "text": "a feature stock at the future stock",
    "start": "1082340",
    "end": "1083960"
  },
  {
    "text": "creation workflow the model training",
    "start": "1083960",
    "end": "1086240"
  },
  {
    "text": "status dutification workflow uh the",
    "start": "1086240",
    "end": "1088640"
  },
  {
    "text": "metrics and the model drop workflow and",
    "start": "1088640",
    "end": "1091520"
  },
  {
    "text": "the model deployment workflow so I think",
    "start": "1091520",
    "end": "1094100"
  },
  {
    "text": "Alex you have an example you want to",
    "start": "1094100",
    "end": "1096080"
  },
  {
    "text": "show yeah so here's an example of the",
    "start": "1096080",
    "end": "1099980"
  },
  {
    "text": "bucket drop where you drop basically",
    "start": "1099980",
    "end": "1102919"
  },
  {
    "text": "this uh",
    "start": "1102919",
    "end": "1104240"
  },
  {
    "text": "allows us to drop files into a cloud",
    "start": "1104240",
    "end": "1107600"
  },
  {
    "text": "storage bucket after a certain number of",
    "start": "1107600",
    "end": "1109760"
  },
  {
    "text": "files have been reached the threshold is",
    "start": "1109760",
    "end": "1112039"
  },
  {
    "text": "met and a",
    "start": "1112039",
    "end": "1114140"
  },
  {
    "text": "Argo event is triggered that basically",
    "start": "1114140",
    "end": "1117140"
  },
  {
    "text": "spins up a workflow that will take all",
    "start": "1117140",
    "end": "1119780"
  },
  {
    "text": "the files from the input directory and",
    "start": "1119780",
    "end": "1123440"
  },
  {
    "text": "move them over to the training location",
    "start": "1123440",
    "end": "1127160"
  },
  {
    "text": "[Music]",
    "start": "1127160",
    "end": "1128299"
  },
  {
    "text": "so what that looks like and make sure",
    "start": "1128299",
    "end": "1129740"
  },
  {
    "text": "that there's the correct number of files",
    "start": "1129740",
    "end": "1132080"
  },
  {
    "text": "needed to move to train and if not",
    "start": "1132080",
    "end": "1135919"
  },
  {
    "text": "it'll it'll wait till another event is",
    "start": "1135919",
    "end": "1138860"
  },
  {
    "text": "fired to do the counting we have this is",
    "start": "1138860",
    "end": "1142039"
  },
  {
    "text": "one way to do it and sometimes we use a",
    "start": "1142039",
    "end": "1144080"
  },
  {
    "text": "file trigger but this is just one of the",
    "start": "1144080",
    "end": "1146539"
  },
  {
    "text": "more basic ways to get it done",
    "start": "1146539",
    "end": "1149480"
  },
  {
    "text": "um once the threshold is met the the",
    "start": "1149480",
    "end": "1151760"
  },
  {
    "text": "train is",
    "start": "1151760",
    "end": "1153980"
  },
  {
    "text": "the training data set is created and we",
    "start": "1153980",
    "end": "1156380"
  },
  {
    "text": "archive it we zip it up so that it can",
    "start": "1156380",
    "end": "1158900"
  },
  {
    "text": "be used for a new model version",
    "start": "1158900",
    "end": "1162700"
  },
  {
    "text": "uh yeah and so now once the training zip",
    "start": "1163700",
    "end": "1168740"
  },
  {
    "text": "is created we need to you know do",
    "start": "1168740",
    "end": "1171860"
  },
  {
    "text": "training and serve the new model if the",
    "start": "1171860",
    "end": "1175280"
  },
  {
    "text": "model is accuracy and precision is",
    "start": "1175280",
    "end": "1177679"
  },
  {
    "text": "meets the correct score that we want to",
    "start": "1177679",
    "end": "1180559"
  },
  {
    "text": "see",
    "start": "1180559",
    "end": "1182059"
  },
  {
    "text": "um we do this with the Argo workflow",
    "start": "1182059",
    "end": "1183919"
  },
  {
    "text": "that basically looks at the feature",
    "start": "1183919",
    "end": "1185780"
  },
  {
    "text": "store sees if the metrics value for the",
    "start": "1185780",
    "end": "1188720"
  },
  {
    "text": "current model that got trained meets our",
    "start": "1188720",
    "end": "1191360"
  },
  {
    "text": "threshold if it is we use k-serv to",
    "start": "1191360",
    "end": "1193940"
  },
  {
    "text": "deploy a new version",
    "start": "1193940",
    "end": "1196600"
  },
  {
    "text": "case serve uses these inference Services",
    "start": "1196600",
    "end": "1200140"
  },
  {
    "text": "you basically just point it to a",
    "start": "1200140",
    "end": "1202460"
  },
  {
    "text": "location in S3 or GCS bucket with the",
    "start": "1202460",
    "end": "1205640"
  },
  {
    "text": "tensorflow serving type of model and we",
    "start": "1205640",
    "end": "1211100"
  },
  {
    "text": "have this dag that we created where we",
    "start": "1211100",
    "end": "1213679"
  },
  {
    "text": "do the validation looking into the",
    "start": "1213679",
    "end": "1215720"
  },
  {
    "text": "metric store if the metrics meet our",
    "start": "1215720",
    "end": "1219440"
  },
  {
    "text": "threshold we'll deploy the new model and",
    "start": "1219440",
    "end": "1221480"
  },
  {
    "text": "we'll send a notification on slack",
    "start": "1221480",
    "end": "1223280"
  },
  {
    "text": "saying that a new model is being",
    "start": "1223280",
    "end": "1225140"
  },
  {
    "text": "deployed",
    "start": "1225140",
    "end": "1226880"
  },
  {
    "text": "uh for a little toy example we did uh we",
    "start": "1226880",
    "end": "1229880"
  },
  {
    "text": "used the cars data set to um basically",
    "start": "1229880",
    "end": "1233559"
  },
  {
    "text": "just run a case serve and",
    "start": "1233559",
    "end": "1238160"
  },
  {
    "text": "deploy a model that can determine if",
    "start": "1238160",
    "end": "1242059"
  },
  {
    "text": "the given cars of a certain type",
    "start": "1242059",
    "end": "1244840"
  },
  {
    "text": "here's what the inference service looks",
    "start": "1244840",
    "end": "1247100"
  },
  {
    "text": "like we use Argos CD to ensure that we",
    "start": "1247100",
    "end": "1250460"
  },
  {
    "text": "point everything to the right location",
    "start": "1250460",
    "end": "1252320"
  },
  {
    "text": "in GCS",
    "start": "1252320",
    "end": "1253960"
  },
  {
    "text": "here's what the inference service kind",
    "start": "1253960",
    "end": "1256160"
  },
  {
    "text": "of fans out to and Argo CD gives you a",
    "start": "1256160",
    "end": "1258440"
  },
  {
    "text": "nice view into that",
    "start": "1258440",
    "end": "1260539"
  },
  {
    "text": "um",
    "start": "1260539",
    "end": "1261320"
  },
  {
    "text": "once that's done",
    "start": "1261320",
    "end": "1263500"
  },
  {
    "text": "we check the status of the inference",
    "start": "1263500",
    "end": "1266059"
  },
  {
    "text": "service we see that it's available at",
    "start": "1266059",
    "end": "1268220"
  },
  {
    "text": "our URL we can check the metadata on the",
    "start": "1268220",
    "end": "1271640"
  },
  {
    "text": "inference service we see that it's ready",
    "start": "1271640",
    "end": "1273320"
  },
  {
    "text": "to go and then we fire off a sample",
    "start": "1273320",
    "end": "1276440"
  },
  {
    "text": "request with the shell script to",
    "start": "1276440",
    "end": "1280240"
  },
  {
    "text": "confirm that we're able to predict",
    "start": "1280240",
    "end": "1282200"
  },
  {
    "text": "accurately",
    "start": "1282200",
    "end": "1284740"
  },
  {
    "text": "yeah trucks so in conclusion leveraging",
    "start": "1285559",
    "end": "1290480"
  },
  {
    "text": "ago for ML projects we've been able to",
    "start": "1290480",
    "end": "1293120"
  },
  {
    "text": "improve our team delivery efficiently so",
    "start": "1293120",
    "end": "1295220"
  },
  {
    "text": "it's easy to ramp up new team members",
    "start": "1295220",
    "end": "1296960"
  },
  {
    "text": "because",
    "start": "1296960",
    "end": "1297820"
  },
  {
    "text": "everybody is working on the same",
    "start": "1297820",
    "end": "1299960"
  },
  {
    "text": "environment once you bootstrap the",
    "start": "1299960",
    "end": "1302299"
  },
  {
    "text": "resource with either CD on your local if",
    "start": "1302299",
    "end": "1304520"
  },
  {
    "text": "you're running mini Cube or if you're",
    "start": "1304520",
    "end": "1305900"
  },
  {
    "text": "running on the kubernetes cluster in the",
    "start": "1305900",
    "end": "1307640"
  },
  {
    "text": "cloud you can get going we have a",
    "start": "1307640",
    "end": "1310039"
  },
  {
    "text": "blueprint and a template so if we want",
    "start": "1310039",
    "end": "1312020"
  },
  {
    "text": "to create a new workflow we're not",
    "start": "1312020",
    "end": "1313640"
  },
  {
    "text": "starting from the scratch we're just",
    "start": "1313640",
    "end": "1315400"
  },
  {
    "text": "leveraging the existing template that we",
    "start": "1315400",
    "end": "1317840"
  },
  {
    "text": "have and let's talk I mean cloud is not",
    "start": "1317840",
    "end": "1321200"
  },
  {
    "text": "cheap so we are set up we're able to",
    "start": "1321200",
    "end": "1323900"
  },
  {
    "text": "reduce the cost for our customers in",
    "start": "1323900",
    "end": "1325580"
  },
  {
    "text": "terms of the amount of money to spend on",
    "start": "1325580",
    "end": "1328100"
  },
  {
    "text": "cloud and things like that so that's it",
    "start": "1328100",
    "end": "1330980"
  },
  {
    "text": "thanks everyone for coming",
    "start": "1330980",
    "end": "1333559"
  },
  {
    "text": "foreign",
    "start": "1333559",
    "end": "1335180"
  },
  {
    "text": "[Applause]",
    "start": "1335180",
    "end": "1340280"
  },
  {
    "text": "I have a question from the virtual",
    "start": "1340280",
    "end": "1341900"
  },
  {
    "text": "audience what technology are you using",
    "start": "1341900",
    "end": "1344179"
  },
  {
    "text": "for the feature store",
    "start": "1344179",
    "end": "1347200"
  },
  {
    "text": "um",
    "start": "1347539",
    "end": "1348159"
  },
  {
    "text": "yeah so for the future start for the",
    "start": "1348159",
    "end": "1350840"
  },
  {
    "text": "online feature store we're using student",
    "start": "1350840",
    "end": "1352520"
  },
  {
    "text": "idb which is uh it's basically kind of",
    "start": "1352520",
    "end": "1356179"
  },
  {
    "text": "like a sand grab nosql but it allows us",
    "start": "1356179",
    "end": "1358220"
  },
  {
    "text": "to the memory footprint is very low so",
    "start": "1358220",
    "end": "1360740"
  },
  {
    "text": "we can easily use that and for the",
    "start": "1360740",
    "end": "1364220"
  },
  {
    "text": "um",
    "start": "1364220",
    "end": "1364940"
  },
  {
    "text": "the offline feature store where",
    "start": "1364940",
    "end": "1368179"
  },
  {
    "text": "basically we use story buckets and in",
    "start": "1368179",
    "end": "1370880"
  },
  {
    "text": "some cases we're using traditional",
    "start": "1370880",
    "end": "1372740"
  },
  {
    "text": "databases",
    "start": "1372740",
    "end": "1375280"
  },
  {
    "text": "the only question I have from the",
    "start": "1376460",
    "end": "1377840"
  },
  {
    "text": "virtual audience is there anybody else",
    "start": "1377840",
    "end": "1379460"
  },
  {
    "text": "with a question yeah sure",
    "start": "1379460",
    "end": "1383200"
  },
  {
    "text": "what do you use Argo CD for like I",
    "start": "1387020",
    "end": "1390980"
  },
  {
    "text": "didn't quite understand that part",
    "start": "1390980",
    "end": "1392900"
  },
  {
    "text": "how is that helpful when you're when",
    "start": "1392900",
    "end": "1394760"
  },
  {
    "text": "you're managing these workflows that",
    "start": "1394760",
    "end": "1396140"
  },
  {
    "text": "you're running",
    "start": "1396140",
    "end": "1397159"
  },
  {
    "text": "yeah so oh you want to take that yes so",
    "start": "1397159",
    "end": "1400100"
  },
  {
    "text": "we just use Argo City to essentially",
    "start": "1400100",
    "end": "1402280"
  },
  {
    "text": "stand up the cluster for our customers a",
    "start": "1402280",
    "end": "1405620"
  },
  {
    "text": "lot of them are first-time kubernetes",
    "start": "1405620",
    "end": "1407179"
  },
  {
    "text": "users and we want to introduce them to",
    "start": "1407179",
    "end": "1409520"
  },
  {
    "text": "Gates in a repetitive or repeatable",
    "start": "1409520",
    "end": "1411860"
  },
  {
    "text": "manner I feel like our Argo CD is a good",
    "start": "1411860",
    "end": "1414620"
  },
  {
    "text": "way to kind of introduce in the case and",
    "start": "1414620",
    "end": "1417200"
  },
  {
    "text": "keep them organized and it enables us to",
    "start": "1417200",
    "end": "1421460"
  },
  {
    "text": "deploy like new inference services and",
    "start": "1421460",
    "end": "1423980"
  },
  {
    "text": "different type of Argo events so we can",
    "start": "1423980",
    "end": "1426500"
  },
  {
    "text": "create new sensors and have them",
    "start": "1426500",
    "end": "1428299"
  },
  {
    "text": "deployed in a nice manner where you can",
    "start": "1428299",
    "end": "1431299"
  },
  {
    "text": "visually see what's going on it's nice",
    "start": "1431299",
    "end": "1433580"
  },
  {
    "text": "to see the fan out of when you create a",
    "start": "1433580",
    "end": "1436340"
  },
  {
    "text": "sensor or the basically the pods that",
    "start": "1436340",
    "end": "1439700"
  },
  {
    "text": "get spun up from that sensor yeah and",
    "start": "1439700",
    "end": "1442640"
  },
  {
    "text": "just so after that uh it's easier for us",
    "start": "1442640",
    "end": "1444860"
  },
  {
    "text": "to manage the deployment uh the Manifest",
    "start": "1444860",
    "end": "1447860"
  },
  {
    "text": "for uh all the companies that we're",
    "start": "1447860",
    "end": "1450080"
  },
  {
    "text": "running so every time there's a new",
    "start": "1450080",
    "end": "1452179"
  },
  {
    "text": "release of let's say tensorflow operator",
    "start": "1452179",
    "end": "1454340"
  },
  {
    "text": "or case that we can manage the release",
    "start": "1454340",
    "end": "1456440"
  },
  {
    "text": "through github's process so uh basically",
    "start": "1456440",
    "end": "1459320"
  },
  {
    "text": "I go see the officers do that easily",
    "start": "1459320",
    "end": "1463539"
  },
  {
    "text": "a question",
    "start": "1466400",
    "end": "1468860"
  },
  {
    "text": "all right thank you everyone thank you",
    "start": "1468860",
    "end": "1472050"
  },
  {
    "text": "[Applause]",
    "start": "1472050",
    "end": "1476619"
  }
]
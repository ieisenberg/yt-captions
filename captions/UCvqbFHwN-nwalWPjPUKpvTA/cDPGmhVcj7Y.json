[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "hi everyone welcome to our session today",
    "start": "1360",
    "end": "4240"
  },
  {
    "text": "this is t zhao from baidu and label one",
    "start": "4240",
    "end": "6960"
  },
  {
    "text": "from huawei",
    "start": "6960",
    "end": "8400"
  },
  {
    "text": "we will introduce how to optimize the",
    "start": "8400",
    "end": "10400"
  },
  {
    "text": "knowledge distillation training with",
    "start": "10400",
    "end": "12000"
  },
  {
    "text": "volcano",
    "start": "12000",
    "end": "12880"
  },
  {
    "text": "thanks next slide",
    "start": "12880",
    "end": "17920"
  },
  {
    "start": "15000",
    "end": "93000"
  },
  {
    "text": "okay so let's have a quick overview of",
    "start": "18800",
    "end": "21119"
  },
  {
    "text": "the project's background",
    "start": "21119",
    "end": "22720"
  },
  {
    "text": "pilot paddle is china's fully open",
    "start": "22720",
    "end": "25119"
  },
  {
    "text": "source",
    "start": "25119",
    "end": "25840"
  },
  {
    "text": "deep learning platform and it is also an",
    "start": "25840",
    "end": "28400"
  },
  {
    "text": "agile framework for",
    "start": "28400",
    "end": "29679"
  },
  {
    "text": "industrial development of deep neural",
    "start": "29679",
    "end": "31920"
  },
  {
    "text": "networks",
    "start": "31920",
    "end": "33040"
  },
  {
    "text": "palo palo deep learning framework",
    "start": "33040",
    "end": "34880"
  },
  {
    "text": "supports both declarative programming",
    "start": "34880",
    "end": "37040"
  },
  {
    "text": "and",
    "start": "37040",
    "end": "37280"
  },
  {
    "text": "imperative programming with both",
    "start": "37280",
    "end": "39600"
  },
  {
    "text": "development flexibility and a",
    "start": "39600",
    "end": "41680"
  },
  {
    "text": "high runtime performance preserved pilot",
    "start": "41680",
    "end": "44960"
  },
  {
    "text": "paddle also support ultra large scale",
    "start": "44960",
    "end": "47120"
  },
  {
    "text": "training of deep",
    "start": "47120",
    "end": "48239"
  },
  {
    "text": "neural networks it launched the worst",
    "start": "48239",
    "end": "51120"
  },
  {
    "text": "the world's",
    "start": "51120",
    "end": "51840"
  },
  {
    "text": "first large-scale open source training",
    "start": "51840",
    "end": "53760"
  },
  {
    "text": "platform that supports",
    "start": "53760",
    "end": "55520"
  },
  {
    "text": "the training of deep network with 100",
    "start": "55520",
    "end": "58719"
  },
  {
    "text": "billion of features",
    "start": "58719",
    "end": "59840"
  },
  {
    "text": "and trillions of parameters using data",
    "start": "59840",
    "end": "62640"
  },
  {
    "text": "source",
    "start": "62640",
    "end": "63359"
  },
  {
    "text": "distributed over hundreds of nodes",
    "start": "63359",
    "end": "67119"
  },
  {
    "text": "piloped includes and maintains more than",
    "start": "67119",
    "end": "69680"
  },
  {
    "text": "100 mainstream models",
    "start": "69680",
    "end": "71920"
  },
  {
    "text": "that have been practically and polished",
    "start": "71920",
    "end": "74880"
  },
  {
    "text": "for",
    "start": "74880",
    "end": "75280"
  },
  {
    "text": "a long time in the industry some of",
    "start": "75280",
    "end": "77840"
  },
  {
    "text": "these models",
    "start": "77840",
    "end": "78880"
  },
  {
    "text": "have one major price from well-known",
    "start": "78880",
    "end": "81040"
  },
  {
    "text": "industrial",
    "start": "81040",
    "end": "82400"
  },
  {
    "text": "competitions in the meanwhile palo pado",
    "start": "82400",
    "end": "85439"
  },
  {
    "text": "has more than 200 pre-trained models",
    "start": "85439",
    "end": "88479"
  },
  {
    "text": "to facilitate the rapid development of",
    "start": "88479",
    "end": "90560"
  },
  {
    "text": "industrial applications",
    "start": "90560",
    "end": "92240"
  },
  {
    "text": "next slide",
    "start": "92240",
    "end": "94960"
  },
  {
    "start": "93000",
    "end": "155000"
  },
  {
    "text": "for large scale training pilot pedal",
    "start": "95600",
    "end": "98000"
  },
  {
    "text": "enabled collective training on multiple",
    "start": "98000",
    "end": "100560"
  },
  {
    "text": "gpus",
    "start": "100560",
    "end": "101759"
  },
  {
    "text": "also supports the asynchronized",
    "start": "101759",
    "end": "104479"
  },
  {
    "text": "parameter server mode",
    "start": "104479",
    "end": "105840"
  },
  {
    "text": "training on gpu and cpus pilot header",
    "start": "105840",
    "end": "108640"
  },
  {
    "text": "used",
    "start": "108640",
    "end": "108960"
  },
  {
    "text": "bleach api for highly scalable",
    "start": "108960",
    "end": "111040"
  },
  {
    "text": "distributed training",
    "start": "111040",
    "end": "112479"
  },
  {
    "text": "and now most of the baidual intelligence",
    "start": "112479",
    "end": "114720"
  },
  {
    "text": "services are powered by pedophile",
    "start": "114720",
    "end": "116640"
  },
  {
    "text": "framework",
    "start": "116640",
    "end": "118399"
  },
  {
    "text": "when pilot pedal do the large-scale",
    "start": "118399",
    "end": "120640"
  },
  {
    "text": "distributed training inside baidu",
    "start": "120640",
    "end": "122560"
  },
  {
    "text": "we suffer from some problems one is uh",
    "start": "122560",
    "end": "126240"
  },
  {
    "text": "when one of the products in the large",
    "start": "126240",
    "end": "127920"
  },
  {
    "text": "distributed job got failed",
    "start": "127920",
    "end": "129679"
  },
  {
    "text": "the whole job failed it will waste a lot",
    "start": "129679",
    "end": "132400"
  },
  {
    "text": "of resources to restart the whole job",
    "start": "132400",
    "end": "135280"
  },
  {
    "text": "another one is the low utilization of",
    "start": "135280",
    "end": "137760"
  },
  {
    "text": "some",
    "start": "137760",
    "end": "138319"
  },
  {
    "text": "influence card cluster like k-40",
    "start": "138319",
    "end": "141360"
  },
  {
    "text": "while the training card cluster like",
    "start": "141360",
    "end": "143599"
  },
  {
    "text": "v100",
    "start": "143599",
    "end": "144560"
  },
  {
    "text": "is always out of resources so we need to",
    "start": "144560",
    "end": "148080"
  },
  {
    "text": "figure out a way to resolve those two",
    "start": "148080",
    "end": "150400"
  },
  {
    "text": "main problems when training in the large",
    "start": "150400",
    "end": "152400"
  },
  {
    "text": "kubernetes cluster",
    "start": "152400",
    "end": "154000"
  },
  {
    "text": "next slide",
    "start": "154000",
    "end": "157519"
  },
  {
    "start": "155000",
    "end": "227000"
  },
  {
    "text": "okay we create edl project uh the",
    "start": "157519",
    "end": "160800"
  },
  {
    "text": "elastic deep learning project as the",
    "start": "160800",
    "end": "162800"
  },
  {
    "text": "middle layer",
    "start": "162800",
    "end": "163760"
  },
  {
    "text": "between kubernetes and pilot paddle",
    "start": "163760",
    "end": "165519"
  },
  {
    "text": "framework to handle the elastic training",
    "start": "165519",
    "end": "168239"
  },
  {
    "text": "related stuff currently edr uses",
    "start": "168239",
    "end": "171440"
  },
  {
    "text": "kubernetes as the foundation",
    "start": "171440",
    "end": "173360"
  },
  {
    "text": "and provides user scenarios including",
    "start": "173360",
    "end": "176160"
  },
  {
    "text": "predictive",
    "start": "176160",
    "end": "177200"
  },
  {
    "text": "training methods like knowledge",
    "start": "177200",
    "end": "179599"
  },
  {
    "text": "distillation",
    "start": "179599",
    "end": "180560"
  },
  {
    "text": "reinforced learning and hyper primary",
    "start": "180560",
    "end": "182640"
  },
  {
    "text": "search by using the kubernetes crd",
    "start": "182640",
    "end": "186959"
  },
  {
    "text": "and now with three major release edr",
    "start": "186959",
    "end": "189920"
  },
  {
    "text": "enables snapshot based for storage",
    "start": "189920",
    "end": "192800"
  },
  {
    "text": "job port auto scaling and support",
    "start": "192800",
    "end": "195040"
  },
  {
    "text": "knowledge distillation natively",
    "start": "195040",
    "end": "197440"
  },
  {
    "text": "edl also highly integrated with volcano",
    "start": "197440",
    "end": "200159"
  },
  {
    "text": "for advanced scheduling features",
    "start": "200159",
    "end": "202159"
  },
  {
    "text": "to accelerate the training speed and edl",
    "start": "202159",
    "end": "205680"
  },
  {
    "text": "now is a linux ai",
    "start": "205680",
    "end": "207120"
  },
  {
    "text": "and data foundation incubating project",
    "start": "207120",
    "end": "210480"
  },
  {
    "text": "with edl enabled in baidu internal",
    "start": "210480",
    "end": "212959"
  },
  {
    "text": "cluster",
    "start": "212959",
    "end": "213840"
  },
  {
    "text": "uh cluster level resource utilization is",
    "start": "213840",
    "end": "216400"
  },
  {
    "text": "above",
    "start": "216400",
    "end": "217040"
  },
  {
    "text": "70 and the job submission queuing time",
    "start": "217040",
    "end": "220400"
  },
  {
    "text": "is less than 44 minutes",
    "start": "220400",
    "end": "222319"
  },
  {
    "text": "and the failure rate of the job is less",
    "start": "222319",
    "end": "224480"
  },
  {
    "text": "than 5",
    "start": "224480",
    "end": "225519"
  },
  {
    "text": "now next slide",
    "start": "225519",
    "end": "229120"
  },
  {
    "start": "227000",
    "end": "329000"
  },
  {
    "text": "and then what is the knowledge",
    "start": "230239",
    "end": "232159"
  },
  {
    "text": "distillation and",
    "start": "232159",
    "end": "233360"
  },
  {
    "text": "what's benefit for that to some people",
    "start": "233360",
    "end": "235840"
  },
  {
    "text": "who are not familiar with knowledge",
    "start": "235840",
    "end": "237360"
  },
  {
    "text": "installation",
    "start": "237360",
    "end": "238319"
  },
  {
    "text": "let's have a quick overview nowadays the",
    "start": "238319",
    "end": "241439"
  },
  {
    "text": "deep learning model is getting bigger",
    "start": "241439",
    "end": "243439"
  },
  {
    "text": "and bigger",
    "start": "243439",
    "end": "244799"
  },
  {
    "text": "the network layer is getting deeper and",
    "start": "244799",
    "end": "247280"
  },
  {
    "text": "deeper",
    "start": "247280",
    "end": "248080"
  },
  {
    "text": "in many scenarios the larger the model",
    "start": "248080",
    "end": "250480"
  },
  {
    "text": "and the more layers",
    "start": "250480",
    "end": "251840"
  },
  {
    "text": "the better the more model effects but",
    "start": "251840",
    "end": "254640"
  },
  {
    "text": "limited by the request of reasoning",
    "start": "254640",
    "end": "256720"
  },
  {
    "text": "speed and",
    "start": "256720",
    "end": "257359"
  },
  {
    "text": "video memory resources large models",
    "start": "257359",
    "end": "260000"
  },
  {
    "text": "usually cannot be deployed directly",
    "start": "260000",
    "end": "262160"
  },
  {
    "text": "and the models need to be compressed the",
    "start": "262160",
    "end": "265120"
  },
  {
    "text": "current mainstream compression",
    "start": "265120",
    "end": "266800"
  },
  {
    "text": "method include tailoring quantification",
    "start": "266800",
    "end": "270000"
  },
  {
    "text": "and knowledge distillation among them",
    "start": "270000",
    "end": "272400"
  },
  {
    "text": "the concept",
    "start": "272400",
    "end": "273199"
  },
  {
    "text": "of knowledge distillation is a",
    "start": "273199",
    "end": "275759"
  },
  {
    "text": "state-of-the-art technologies proposed",
    "start": "275759",
    "end": "277840"
  },
  {
    "text": "in the",
    "start": "277840",
    "end": "278800"
  },
  {
    "text": "distillation the knowledge in a neural",
    "start": "278800",
    "end": "280800"
  },
  {
    "text": "network paper published by hinjen in",
    "start": "280800",
    "end": "283479"
  },
  {
    "text": "2015",
    "start": "283479",
    "end": "286240"
  },
  {
    "text": "it is a very classic model compression",
    "start": "286240",
    "end": "288479"
  },
  {
    "text": "technology that converts knowledge from",
    "start": "288479",
    "end": "290400"
  },
  {
    "text": "a complex",
    "start": "290400",
    "end": "291199"
  },
  {
    "text": "model migrated to another lightweight",
    "start": "291199",
    "end": "293840"
  },
  {
    "text": "model",
    "start": "293840",
    "end": "294479"
  },
  {
    "text": "to achieve model compression in fact",
    "start": "294479",
    "end": "297840"
  },
  {
    "text": "the so-called knowledge transfer can be",
    "start": "297840",
    "end": "300160"
  },
  {
    "text": "understood",
    "start": "300160",
    "end": "301039"
  },
  {
    "text": "as a training process which is to use",
    "start": "301039",
    "end": "303919"
  },
  {
    "text": "the teacher model to train the student",
    "start": "303919",
    "end": "305759"
  },
  {
    "text": "model",
    "start": "305759",
    "end": "306800"
  },
  {
    "text": "this training method is distillation",
    "start": "306800",
    "end": "308880"
  },
  {
    "text": "training after training a good student",
    "start": "308880",
    "end": "311440"
  },
  {
    "text": "model",
    "start": "311440",
    "end": "311919"
  },
  {
    "text": "the student model can be used for actual",
    "start": "311919",
    "end": "313840"
  },
  {
    "text": "deployment",
    "start": "313840",
    "end": "315199"
  },
  {
    "text": "as shown in the figure above",
    "start": "315199",
    "end": "318400"
  },
  {
    "text": "the training steps can be divided into",
    "start": "318400",
    "end": "320400"
  },
  {
    "text": "two steps",
    "start": "320400",
    "end": "321520"
  },
  {
    "text": "the first is train a teacher model and",
    "start": "321520",
    "end": "324320"
  },
  {
    "text": "then",
    "start": "324320",
    "end": "324800"
  },
  {
    "text": "use knowledge of the teacher model to",
    "start": "324800",
    "end": "326560"
  },
  {
    "text": "change the student model",
    "start": "326560",
    "end": "328800"
  },
  {
    "text": "okay next slide",
    "start": "328800",
    "end": "331599"
  },
  {
    "text": "originally there are two common ways to",
    "start": "332240",
    "end": "334240"
  },
  {
    "text": "do the distillation training",
    "start": "334240",
    "end": "336880"
  },
  {
    "text": "edl based on user scenarios in baidu to",
    "start": "336880",
    "end": "340000"
  },
  {
    "text": "invent the third way to do the training",
    "start": "340000",
    "end": "343120"
  },
  {
    "text": "let's introduce those three types the",
    "start": "343120",
    "end": "345680"
  },
  {
    "text": "first one is",
    "start": "345680",
    "end": "346720"
  },
  {
    "text": "called the pure distillation training",
    "start": "346720",
    "end": "349919"
  },
  {
    "text": "the method of pure distillation training",
    "start": "349919",
    "end": "352000"
  },
  {
    "text": "is much like the teacher recording the",
    "start": "352000",
    "end": "353680"
  },
  {
    "text": "content",
    "start": "353680",
    "end": "354479"
  },
  {
    "text": "of a lecture as the video and giving it",
    "start": "354479",
    "end": "357199"
  },
  {
    "text": "to the student",
    "start": "357199",
    "end": "358160"
  },
  {
    "text": "for self-study and then the student",
    "start": "358160",
    "end": "360560"
  },
  {
    "text": "learns by themselves",
    "start": "360560",
    "end": "362479"
  },
  {
    "text": "according to the course video therefore",
    "start": "362479",
    "end": "365759"
  },
  {
    "text": "the pure distillation training is to",
    "start": "365759",
    "end": "368000"
  },
  {
    "text": "first use the teacher model for",
    "start": "368000",
    "end": "369680"
  },
  {
    "text": "inference",
    "start": "369680",
    "end": "370400"
  },
  {
    "text": "and save the results in the disk and",
    "start": "370400",
    "end": "372479"
  },
  {
    "text": "then the student model used the sample",
    "start": "372479",
    "end": "374479"
  },
  {
    "text": "saved in the disk",
    "start": "374479",
    "end": "375680"
  },
  {
    "text": "and the inference results of the teacher",
    "start": "375680",
    "end": "377520"
  },
  {
    "text": "model as a data set for training",
    "start": "377520",
    "end": "381360"
  },
  {
    "text": "uh okay uh in the training model no no",
    "start": "381360",
    "end": "385280"
  },
  {
    "text": "yeah okay in the training model the",
    "start": "385280",
    "end": "387440"
  },
  {
    "text": "training uh the trainer the training of",
    "start": "387440",
    "end": "389199"
  },
  {
    "text": "the student model is the same as the",
    "start": "389199",
    "end": "391120"
  },
  {
    "text": "regular training",
    "start": "391120",
    "end": "392240"
  },
  {
    "text": "and the method is simple however the",
    "start": "392240",
    "end": "395039"
  },
  {
    "text": "training",
    "start": "395039",
    "end": "395600"
  },
  {
    "text": "method generates required data",
    "start": "395600",
    "end": "397680"
  },
  {
    "text": "enhancement and takes up",
    "start": "397680",
    "end": "399199"
  },
  {
    "text": "huge disk space so the application",
    "start": "399199",
    "end": "401600"
  },
  {
    "text": "environment is subject to certain",
    "start": "401600",
    "end": "403039"
  },
  {
    "text": "restrictions",
    "start": "403039",
    "end": "404479"
  },
  {
    "text": "and the second one is same network",
    "start": "404479",
    "end": "406720"
  },
  {
    "text": "distillation training",
    "start": "406720",
    "end": "408160"
  },
  {
    "text": "same network distribution training",
    "start": "408160",
    "end": "410080"
  },
  {
    "text": "refers to putting the teacher model and",
    "start": "410080",
    "end": "412000"
  },
  {
    "text": "student model",
    "start": "412000",
    "end": "412800"
  },
  {
    "text": "into the same network and the fixed",
    "start": "412800",
    "end": "415599"
  },
  {
    "text": "teacher model parameters",
    "start": "415599",
    "end": "417199"
  },
  {
    "text": "are only forwarded and the student model",
    "start": "417199",
    "end": "420160"
  },
  {
    "text": "is normally used for back propagation",
    "start": "420160",
    "end": "422639"
  },
  {
    "text": "training",
    "start": "422639",
    "end": "424400"
  },
  {
    "text": "this is also the current mainstream",
    "start": "424400",
    "end": "426240"
  },
  {
    "text": "distillation training method",
    "start": "426240",
    "end": "428160"
  },
  {
    "text": "this is very similar to the teaching",
    "start": "428160",
    "end": "429919"
  },
  {
    "text": "method in the real life",
    "start": "429919",
    "end": "431919"
  },
  {
    "text": "the teacher and student are in the same",
    "start": "431919",
    "end": "433440"
  },
  {
    "text": "classroom the teacher says",
    "start": "433440",
    "end": "435280"
  },
  {
    "text": "sentence and the student listen to it",
    "start": "435280",
    "end": "436880"
  },
  {
    "text": "however the training method not only",
    "start": "436880",
    "end": "439039"
  },
  {
    "text": "take up to",
    "start": "439039",
    "end": "440160"
  },
  {
    "text": "a lot of space for the teacher mode but",
    "start": "440160",
    "end": "442560"
  },
  {
    "text": "also",
    "start": "442560",
    "end": "443280"
  },
  {
    "text": "because the teacher and the student have",
    "start": "443280",
    "end": "445520"
  },
  {
    "text": "a one-to-one binding relationship",
    "start": "445520",
    "end": "447520"
  },
  {
    "text": "and the training of the student model",
    "start": "447520",
    "end": "449919"
  },
  {
    "text": "completely",
    "start": "449919",
    "end": "450800"
  },
  {
    "text": "relies on the teacher model and the",
    "start": "450800",
    "end": "452720"
  },
  {
    "text": "student model has to wait for the",
    "start": "452720",
    "end": "454639"
  },
  {
    "text": "teacher model to output",
    "start": "454639",
    "end": "455840"
  },
  {
    "text": "a batch of inference and the result can",
    "start": "455840",
    "end": "458639"
  },
  {
    "text": "be trained",
    "start": "458639",
    "end": "459520"
  },
  {
    "text": "and the teacher model has to wait for",
    "start": "459520",
    "end": "461120"
  },
  {
    "text": "the student to change a batch",
    "start": "461120",
    "end": "462639"
  },
  {
    "text": "before starting the influence of the",
    "start": "462639",
    "end": "464479"
  },
  {
    "text": "next batch which has a certain impact",
    "start": "464479",
    "end": "467039"
  },
  {
    "text": "on the overall training speed and",
    "start": "467039",
    "end": "470160"
  },
  {
    "text": "our edl has the third one which is",
    "start": "470160",
    "end": "473280"
  },
  {
    "text": "called the edl service distillation",
    "start": "473280",
    "end": "475440"
  },
  {
    "text": "training",
    "start": "475440",
    "end": "476160"
  },
  {
    "text": "compared with the pure distillation",
    "start": "476160",
    "end": "477919"
  },
  {
    "text": "training edr service distillation",
    "start": "477919",
    "end": "480080"
  },
  {
    "text": "training decouples the teacher model",
    "start": "480080",
    "end": "482240"
  },
  {
    "text": "and the student model the t-shirt model",
    "start": "482240",
    "end": "484319"
  },
  {
    "text": "is deployed as an online",
    "start": "484319",
    "end": "486479"
  },
  {
    "text": "inference service and the steel model",
    "start": "486479",
    "end": "488319"
  },
  {
    "text": "uses the clients in",
    "start": "488319",
    "end": "489919"
  },
  {
    "text": "identity to send samples to the teacher",
    "start": "489919",
    "end": "492000"
  },
  {
    "text": "model in real time via the internet",
    "start": "492000",
    "end": "494160"
  },
  {
    "text": "to obtain the influence results for",
    "start": "494160",
    "end": "496319"
  },
  {
    "text": "training it's like letting the model",
    "start": "496319",
    "end": "498319"
  },
  {
    "text": "take lessons online",
    "start": "498319",
    "end": "499680"
  },
  {
    "text": "and we will we use distillation reader",
    "start": "499680",
    "end": "501680"
  },
  {
    "text": "for communication",
    "start": "501680",
    "end": "503039"
  },
  {
    "text": "next slide",
    "start": "503039",
    "end": "507840"
  },
  {
    "start": "505000",
    "end": "674000"
  },
  {
    "text": "okay there are several advantages of edl",
    "start": "508960",
    "end": "512560"
  },
  {
    "text": "service knowledge distillation",
    "start": "512560",
    "end": "514159"
  },
  {
    "text": "the first one is save the gpu memory",
    "start": "514159",
    "end": "516800"
  },
  {
    "text": "resource",
    "start": "516800",
    "end": "517599"
  },
  {
    "text": "due to the decoupling of the student",
    "start": "517599",
    "end": "519440"
  },
  {
    "text": "model and t-shirt model",
    "start": "519440",
    "end": "520719"
  },
  {
    "text": "the service distillation training can",
    "start": "520719",
    "end": "522560"
  },
  {
    "text": "use here teaches",
    "start": "522560",
    "end": "524720"
  },
  {
    "text": "resources that is deployed the student",
    "start": "524720",
    "end": "527040"
  },
  {
    "text": "model and the teacher model",
    "start": "527040",
    "end": "528560"
  },
  {
    "text": "to different devices distillation",
    "start": "528560",
    "end": "530800"
  },
  {
    "text": "networks that will only",
    "start": "530800",
    "end": "532640"
  },
  {
    "text": "originally limited by the size of the",
    "start": "532640",
    "end": "534880"
  },
  {
    "text": "gpu memory and or different",
    "start": "534880",
    "end": "537200"
  },
  {
    "text": "to deploy to the to a single gpu card",
    "start": "537200",
    "end": "540320"
  },
  {
    "text": "can be deployed to a different cards in",
    "start": "540320",
    "end": "542480"
  },
  {
    "text": "this way",
    "start": "542480",
    "end": "543360"
  },
  {
    "text": "user can also flexibly set the ratio of",
    "start": "543360",
    "end": "546399"
  },
  {
    "text": "the teacher to student according to the",
    "start": "546399",
    "end": "548320"
  },
  {
    "text": "throughput performance",
    "start": "548320",
    "end": "549519"
  },
  {
    "text": "of the teacher and student which means",
    "start": "549519",
    "end": "551600"
  },
  {
    "text": "that multiple teachers can teach",
    "start": "551600",
    "end": "553519"
  },
  {
    "text": "multiple students instead of",
    "start": "553519",
    "end": "555519"
  },
  {
    "text": "maintaining a one-to-one tutorial model",
    "start": "555519",
    "end": "558000"
  },
  {
    "text": "to maximize training outputs",
    "start": "558000",
    "end": "560959"
  },
  {
    "text": "the second one is improve the training",
    "start": "560959",
    "end": "562640"
  },
  {
    "text": "speed due to say",
    "start": "562640",
    "end": "564560"
  },
  {
    "text": "due to the saving of gpu memory",
    "start": "564560",
    "end": "566959"
  },
  {
    "text": "resources",
    "start": "566959",
    "end": "567839"
  },
  {
    "text": "the student model can be trained with a",
    "start": "567839",
    "end": "569600"
  },
  {
    "text": "larger batch size",
    "start": "569600",
    "end": "570880"
  },
  {
    "text": "at the same time because the student",
    "start": "570880",
    "end": "572640"
  },
  {
    "text": "model and teacher model are in",
    "start": "572640",
    "end": "574720"
  },
  {
    "text": "in different pipelines the serial model",
    "start": "574720",
    "end": "577920"
  },
  {
    "text": "does not need to wait for the teacher",
    "start": "577920",
    "end": "579600"
  },
  {
    "text": "model to end the influence",
    "start": "579600",
    "end": "581120"
  },
  {
    "text": "before training combining the two",
    "start": "581120",
    "end": "584640"
  },
  {
    "text": "reasons those can greatly improve the",
    "start": "584640",
    "end": "588160"
  },
  {
    "text": "training speed",
    "start": "588160",
    "end": "590080"
  },
  {
    "text": "the third one is improve the utilization",
    "start": "590080",
    "end": "592720"
  },
  {
    "text": "of training resources",
    "start": "592720",
    "end": "594640"
  },
  {
    "text": "in practical application we can develop",
    "start": "594640",
    "end": "597680"
  },
  {
    "text": "the teacher model to an online elastic",
    "start": "597680",
    "end": "600240"
  },
  {
    "text": "influence card",
    "start": "600240",
    "end": "601760"
  },
  {
    "text": "cluster and use the computer resources",
    "start": "601760",
    "end": "603680"
  },
  {
    "text": "of online",
    "start": "603680",
    "end": "604880"
  },
  {
    "text": "predictive card to increase the",
    "start": "604880",
    "end": "607120"
  },
  {
    "text": "throughput of the teacher model in the",
    "start": "607120",
    "end": "608800"
  },
  {
    "text": "distribution task",
    "start": "608800",
    "end": "610160"
  },
  {
    "text": "at the same time because the teacher",
    "start": "610160",
    "end": "612000"
  },
  {
    "text": "model can flexibly",
    "start": "612000",
    "end": "613600"
  },
  {
    "text": "schedule there is no need to worry about",
    "start": "613600",
    "end": "615920"
  },
  {
    "text": "task failures caused by the preemption",
    "start": "615920",
    "end": "617920"
  },
  {
    "text": "of online instance during peak hours",
    "start": "617920",
    "end": "620160"
  },
  {
    "text": "it is equivalent to transferring the",
    "start": "620160",
    "end": "621920"
  },
  {
    "text": "resources required requirements of the",
    "start": "621920",
    "end": "624000"
  },
  {
    "text": "teacher",
    "start": "624000",
    "end": "624560"
  },
  {
    "text": "for the training card to the online gpu",
    "start": "624560",
    "end": "626399"
  },
  {
    "text": "card when offline training",
    "start": "626399",
    "end": "628320"
  },
  {
    "text": "resources such as vu 100 are limited the",
    "start": "628320",
    "end": "631200"
  },
  {
    "text": "online card is used to accelerate the",
    "start": "631200",
    "end": "633440"
  },
  {
    "text": "training to",
    "start": "633440",
    "end": "634320"
  },
  {
    "text": "see variable training resources in",
    "start": "634320",
    "end": "636800"
  },
  {
    "text": "addition",
    "start": "636800",
    "end": "637839"
  },
  {
    "text": "on offline clusters combined with",
    "start": "637839",
    "end": "639920"
  },
  {
    "text": "scheduling strategies",
    "start": "639920",
    "end": "641519"
  },
  {
    "text": "the teacher model can also be deployed",
    "start": "641519",
    "end": "643760"
  },
  {
    "text": "to cluster fragmented",
    "start": "643760",
    "end": "645200"
  },
  {
    "text": "resources or resources with a low usage",
    "start": "645200",
    "end": "648320"
  },
  {
    "text": "rate such as k40 to make full use of",
    "start": "648320",
    "end": "651440"
  },
  {
    "text": "clusters idle and fragmented resources",
    "start": "651440",
    "end": "655200"
  },
  {
    "text": "the right picture is the flowchart of",
    "start": "655200",
    "end": "656959"
  },
  {
    "text": "service distribution training operation",
    "start": "656959",
    "end": "659040"
  },
  {
    "text": "in this figure you can see that the",
    "start": "659040",
    "end": "661440"
  },
  {
    "text": "student model sends samples to the",
    "start": "661440",
    "end": "662880"
  },
  {
    "text": "teacher model and obtain the inference",
    "start": "662880",
    "end": "664880"
  },
  {
    "text": "result while the the service side of the",
    "start": "664880",
    "end": "667839"
  },
  {
    "text": "teacher model can be added and deleted",
    "start": "667839",
    "end": "669680"
  },
  {
    "text": "as well and",
    "start": "669680",
    "end": "670399"
  },
  {
    "text": "adjusted flexibly next slide",
    "start": "670399",
    "end": "675760"
  },
  {
    "text": "okay now we'll see how it leverages",
    "start": "675760",
    "end": "679120"
  },
  {
    "text": "kinetics and",
    "start": "679120",
    "end": "680399"
  },
  {
    "text": "volcano to optimize knowledge",
    "start": "680399",
    "end": "681839"
  },
  {
    "text": "distillation training videos support",
    "start": "681839",
    "end": "683839"
  },
  {
    "text": "elastic training with inference style",
    "start": "683839",
    "end": "685680"
  },
  {
    "text": "services during training it deploys the",
    "start": "685680",
    "end": "687839"
  },
  {
    "text": "teacher model as",
    "start": "687839",
    "end": "688880"
  },
  {
    "text": "online inference through pilot serving",
    "start": "688880",
    "end": "690959"
  },
  {
    "text": "in addition to a teacher and a student",
    "start": "690959",
    "end": "692720"
  },
  {
    "text": "training pod",
    "start": "692720",
    "end": "693680"
  },
  {
    "text": "a service registry discovery model is",
    "start": "693680",
    "end": "696000"
  },
  {
    "text": "developed by dl",
    "start": "696000",
    "end": "697920"
  },
  {
    "text": "online influencers are elastic and are",
    "start": "697920",
    "end": "700240"
  },
  {
    "text": "registered to eds",
    "start": "700240",
    "end": "702000"
  },
  {
    "text": "service registry modules for service",
    "start": "702000",
    "end": "704959"
  },
  {
    "text": "auto discovery and fault tolerance",
    "start": "704959",
    "end": "706959"
  },
  {
    "text": "so either enable dynamic adaption of",
    "start": "706959",
    "end": "710160"
  },
  {
    "text": "teachers model online instance",
    "start": "710160",
    "end": "712000"
  },
  {
    "text": "to maximize students training through",
    "start": "712000",
    "end": "714839"
  },
  {
    "text": "output",
    "start": "714839",
    "end": "716240"
  },
  {
    "text": "and the resource utilization with k40",
    "start": "716240",
    "end": "719040"
  },
  {
    "text": "influence card",
    "start": "719040",
    "end": "719760"
  },
  {
    "text": "serving cluster and v100 card training",
    "start": "719760",
    "end": "721920"
  },
  {
    "text": "cluster edr used volcano for",
    "start": "721920",
    "end": "724079"
  },
  {
    "text": "multi-cluster scheduling",
    "start": "724079",
    "end": "725600"
  },
  {
    "text": "and since spider inside are always shut",
    "start": "725600",
    "end": "728079"
  },
  {
    "text": "off v100 resources for training",
    "start": "728079",
    "end": "730399"
  },
  {
    "text": "we use scan scheduling for knowledge",
    "start": "730399",
    "end": "732079"
  },
  {
    "text": "installation job to avoid training",
    "start": "732079",
    "end": "733760"
  },
  {
    "text": "results from deadlock",
    "start": "733760",
    "end": "735519"
  },
  {
    "text": "we also utilize the io awareness in",
    "start": "735519",
    "end": "737680"
  },
  {
    "text": "volcano for maximize the rdma usage in",
    "start": "737680",
    "end": "740639"
  },
  {
    "text": "training cluster",
    "start": "740639",
    "end": "742320"
  },
  {
    "text": "next slide okay so in order to verify",
    "start": "742320",
    "end": "746240"
  },
  {
    "start": "743000",
    "end": "855000"
  },
  {
    "text": "the vector of",
    "start": "746240",
    "end": "747120"
  },
  {
    "text": "edl service distribution training we use",
    "start": "747120",
    "end": "749440"
  },
  {
    "text": "pure training",
    "start": "749440",
    "end": "750399"
  },
  {
    "text": "same network distribution training and",
    "start": "750399",
    "end": "752000"
  },
  {
    "text": "edl service distribution training",
    "start": "752000",
    "end": "754000"
  },
  {
    "text": "on the imagenet data set to train the",
    "start": "754000",
    "end": "755920"
  },
  {
    "text": "resnet 50",
    "start": "755920",
    "end": "757120"
  },
  {
    "text": "vd model the first one to concern is",
    "start": "757120",
    "end": "760560"
  },
  {
    "text": "accuracy",
    "start": "760560",
    "end": "761360"
  },
  {
    "text": "in terms of accuracy compared to the",
    "start": "761360",
    "end": "763360"
  },
  {
    "text": "pure training distillation training",
    "start": "763360",
    "end": "765279"
  },
  {
    "text": "improves the accuracy of resnet 50 model",
    "start": "765279",
    "end": "768079"
  },
  {
    "text": "by nearly two percent",
    "start": "768079",
    "end": "769680"
  },
  {
    "text": "the service distillation training and",
    "start": "769680",
    "end": "772000"
  },
  {
    "text": "the the same natural distillation",
    "start": "772000",
    "end": "773680"
  },
  {
    "text": "training",
    "start": "773680",
    "end": "774160"
  },
  {
    "text": "have the same accuracy in terms of the",
    "start": "774160",
    "end": "776880"
  },
  {
    "text": "training speed",
    "start": "776880",
    "end": "777920"
  },
  {
    "text": "compared with pure pure training same",
    "start": "777920",
    "end": "780720"
  },
  {
    "text": "network distillation training takes up",
    "start": "780720",
    "end": "783279"
  },
  {
    "text": "a large part of the computing power due",
    "start": "783279",
    "end": "785680"
  },
  {
    "text": "to the teacher model",
    "start": "785680",
    "end": "787040"
  },
  {
    "text": "so the training speed is only 35.9",
    "start": "787040",
    "end": "789920"
  },
  {
    "text": "percent of the pure training",
    "start": "789920",
    "end": "791440"
  },
  {
    "text": "with the same training resources the edl",
    "start": "791440",
    "end": "794800"
  },
  {
    "text": "service distillation training used",
    "start": "794800",
    "end": "796240"
  },
  {
    "text": "additional",
    "start": "796240",
    "end": "797120"
  },
  {
    "text": "online p4 elastic resource and transfer",
    "start": "797120",
    "end": "800720"
  },
  {
    "text": "the teacher's resource request for the",
    "start": "800720",
    "end": "803680"
  },
  {
    "text": "training card",
    "start": "803680",
    "end": "804560"
  },
  {
    "text": "to the elastic card so compared to pure",
    "start": "804560",
    "end": "806800"
  },
  {
    "text": "training it still maintains uh",
    "start": "806800",
    "end": "809360"
  },
  {
    "text": "maintain maintains a training effective",
    "start": "809360",
    "end": "811600"
  },
  {
    "text": "of 82.8 percent and the speed is 2.3",
    "start": "811600",
    "end": "815360"
  },
  {
    "text": "times",
    "start": "815360",
    "end": "816079"
  },
  {
    "text": "to the same network distillation",
    "start": "816079",
    "end": "817600"
  },
  {
    "text": "training",
    "start": "817600",
    "end": "819360"
  },
  {
    "text": "if you continue to use teacher resources",
    "start": "819360",
    "end": "822399"
  },
  {
    "text": "theoretically the speed of edl service",
    "start": "822399",
    "end": "824959"
  },
  {
    "text": "distillation training can be the same as",
    "start": "824959",
    "end": "827199"
  },
  {
    "text": "that of the pure training of course same",
    "start": "827199",
    "end": "829440"
  },
  {
    "text": "network distillation training can",
    "start": "829440",
    "end": "830959"
  },
  {
    "text": "continue to accelerate",
    "start": "830959",
    "end": "832399"
  },
  {
    "text": "if resources are increased but this will",
    "start": "832399",
    "end": "834639"
  },
  {
    "text": "take up",
    "start": "834639",
    "end": "835600"
  },
  {
    "text": "more valuable v100 training resources",
    "start": "835600",
    "end": "838639"
  },
  {
    "text": "okay here are all the distillation",
    "start": "838639",
    "end": "841199"
  },
  {
    "text": "training on edl",
    "start": "841199",
    "end": "842639"
  },
  {
    "text": "so now let's welcome label one for deep",
    "start": "842639",
    "end": "845279"
  },
  {
    "text": "dive",
    "start": "845279",
    "end": "845680"
  },
  {
    "text": "into the volcano project and tell us",
    "start": "845680",
    "end": "847760"
  },
  {
    "text": "more details about the features and",
    "start": "847760",
    "end": "849600"
  },
  {
    "text": "implementations of volcano and how it is",
    "start": "849600",
    "end": "852079"
  },
  {
    "text": "integrated with other ai and data system",
    "start": "852079",
    "end": "854240"
  },
  {
    "text": "thank you",
    "start": "854240",
    "end": "856959"
  },
  {
    "start": "855000",
    "end": "937000"
  },
  {
    "text": "hey guys i'm william wong from huawei",
    "start": "856959",
    "end": "859920"
  },
  {
    "text": "volcano community",
    "start": "859920",
    "end": "861440"
  },
  {
    "text": "community maintainer and attending the",
    "start": "861440",
    "end": "863440"
  },
  {
    "text": "lead it's my pleasure to share this",
    "start": "863440",
    "end": "865360"
  },
  {
    "text": "topic with tido",
    "start": "865360",
    "end": "866800"
  },
  {
    "text": "okay let's let's get started with the",
    "start": "866800",
    "end": "870240"
  },
  {
    "text": "development",
    "start": "870240",
    "end": "871120"
  },
  {
    "text": "of industries more and more domain",
    "start": "871120",
    "end": "873760"
  },
  {
    "text": "frameworks",
    "start": "873760",
    "end": "874639"
  },
  {
    "text": "are invented and applied to support",
    "start": "874639",
    "end": "877360"
  },
  {
    "text": "business development",
    "start": "877360",
    "end": "879120"
  },
  {
    "text": "this framework plays an irreplaceable",
    "start": "879120",
    "end": "882240"
  },
  {
    "text": "role in their respective domains such as",
    "start": "882240",
    "end": "885440"
  },
  {
    "text": "spark tension flow and flink",
    "start": "885440",
    "end": "887680"
  },
  {
    "text": "on the other side the business model is",
    "start": "887680",
    "end": "890000"
  },
  {
    "text": "becoming more and more complex",
    "start": "890000",
    "end": "891839"
  },
  {
    "text": "nowadays it's difficult to handle",
    "start": "891839",
    "end": "894320"
  },
  {
    "text": "complex",
    "start": "894320",
    "end": "895040"
  },
  {
    "text": "business scenarios with just single",
    "start": "895040",
    "end": "897600"
  },
  {
    "text": "domain framework",
    "start": "897600",
    "end": "899040"
  },
  {
    "text": "multiple domain frameworks are widely",
    "start": "899040",
    "end": "901600"
  },
  {
    "text": "used together",
    "start": "901600",
    "end": "902639"
  },
  {
    "text": "to achieve business objective the domain",
    "start": "902639",
    "end": "905839"
  },
  {
    "text": "framework cluster",
    "start": "905839",
    "end": "907440"
  },
  {
    "text": "is is becoming bigger and bigger and",
    "start": "907440",
    "end": "910399"
  },
  {
    "text": "these clusters are",
    "start": "910399",
    "end": "911600"
  },
  {
    "text": "independent of each other the resources",
    "start": "911600",
    "end": "915120"
  },
  {
    "text": "cannot be shared this leads to a huge",
    "start": "915120",
    "end": "917600"
  },
  {
    "text": "list",
    "start": "917600",
    "end": "918160"
  },
  {
    "text": "of resource therefore more and more",
    "start": "918160",
    "end": "920399"
  },
  {
    "text": "users",
    "start": "920399",
    "end": "921279"
  },
  {
    "text": "want to use the unified scheduler",
    "start": "921279",
    "end": "924480"
  },
  {
    "text": "system to resolve the resource sharing",
    "start": "924480",
    "end": "927440"
  },
  {
    "text": "problem",
    "start": "927440",
    "end": "928320"
  },
  {
    "text": "kubernetes is the best choice for many",
    "start": "928320",
    "end": "931519"
  },
  {
    "text": "users",
    "start": "931519",
    "end": "932240"
  },
  {
    "text": "because of its excellent scalability",
    "start": "932240",
    "end": "935519"
  },
  {
    "text": "and ecosystem",
    "start": "935519",
    "end": "938720"
  },
  {
    "start": "937000",
    "end": "1090000"
  },
  {
    "text": "as you know kubernetes is designed for",
    "start": "939120",
    "end": "941920"
  },
  {
    "text": "microservice",
    "start": "941920",
    "end": "943199"
  },
  {
    "text": "of chest fission in the early age",
    "start": "943199",
    "end": "946399"
  },
  {
    "text": "when we tried to measure migrate",
    "start": "946399",
    "end": "949600"
  },
  {
    "text": "batch workload to kubernetes several",
    "start": "949600",
    "end": "951759"
  },
  {
    "text": "years ago we found",
    "start": "951759",
    "end": "953199"
  },
  {
    "text": "there are still a lot of challenges for",
    "start": "953199",
    "end": "955680"
  },
  {
    "text": "kubernetes",
    "start": "955680",
    "end": "956959"
  },
  {
    "text": "the first one is the scheduling policy",
    "start": "956959",
    "end": "959759"
  },
  {
    "text": "for high performance workload",
    "start": "959759",
    "end": "961759"
  },
  {
    "text": "for example gun scheduling batch",
    "start": "961759",
    "end": "964720"
  },
  {
    "text": "workload need",
    "start": "964720",
    "end": "965680"
  },
  {
    "text": "all or nothing scheduling to reserve",
    "start": "965680",
    "end": "969120"
  },
  {
    "text": "to solve the deadlock the fair share",
    "start": "969120",
    "end": "971759"
  },
  {
    "text": "scheduling for much attendance",
    "start": "971759",
    "end": "973839"
  },
  {
    "text": "job priority scheduling for urgent",
    "start": "973839",
    "end": "976160"
  },
  {
    "text": "workload",
    "start": "976160",
    "end": "977199"
  },
  {
    "text": "the top larger scheduling to add",
    "start": "977199",
    "end": "980079"
  },
  {
    "text": "accelerate",
    "start": "980079",
    "end": "981120"
  },
  {
    "text": "training in central essential",
    "start": "981120",
    "end": "984880"
  },
  {
    "text": "the fact challenge is job life cycle",
    "start": "984880",
    "end": "988160"
  },
  {
    "text": "management",
    "start": "988160",
    "end": "989199"
  },
  {
    "text": "different type of workload have",
    "start": "989199",
    "end": "991440"
  },
  {
    "text": "different expectation",
    "start": "991440",
    "end": "993279"
  },
  {
    "text": "for example for tension flow if the ps",
    "start": "993279",
    "end": "996240"
  },
  {
    "text": "and work pulled",
    "start": "996240",
    "end": "997199"
  },
  {
    "text": "field we have to restart the whole job",
    "start": "997199",
    "end": "1000959"
  },
  {
    "text": "uh however for spark if extruder pulled",
    "start": "1000959",
    "end": "1004240"
  },
  {
    "text": "field",
    "start": "1004240",
    "end": "1005040"
  },
  {
    "text": "only restart the executor code is enough",
    "start": "1005040",
    "end": "1008240"
  },
  {
    "text": "all these are handling should be",
    "start": "1008240",
    "end": "1010320"
  },
  {
    "text": "resolved in job life cycle management",
    "start": "1010320",
    "end": "1013680"
  },
  {
    "text": "the third challenge is the",
    "start": "1013680",
    "end": "1017079"
  },
  {
    "text": "heterogeneous hardware support the high",
    "start": "1017079",
    "end": "1020000"
  },
  {
    "text": "performance workload",
    "start": "1020000",
    "end": "1021440"
  },
  {
    "text": "has higher performance requirement many",
    "start": "1021440",
    "end": "1024400"
  },
  {
    "text": "providers",
    "start": "1024400",
    "end": "1025678"
  },
  {
    "text": "produce different kind of hardware to",
    "start": "1025679",
    "end": "1027839"
  },
  {
    "text": "accelerate computing",
    "start": "1027839",
    "end": "1029678"
  },
  {
    "text": "this requires the scheduler to schedule",
    "start": "1029679",
    "end": "1033038"
  },
  {
    "text": "the results uniformly and provide",
    "start": "1033039",
    "end": "1036160"
  },
  {
    "text": "the best resource allocation",
    "start": "1036160",
    "end": "1039199"
  },
  {
    "text": "the last one is the performance tuning",
    "start": "1039199",
    "end": "1042319"
  },
  {
    "text": "for example the scalability",
    "start": "1042319",
    "end": "1045600"
  },
  {
    "text": "throughput network container runtime",
    "start": "1045600",
    "end": "1049039"
  },
  {
    "text": "is not only about the scheduler",
    "start": "1049039",
    "end": "1052880"
  },
  {
    "text": "volcano is a kubernetes native",
    "start": "1052880",
    "end": "1056400"
  },
  {
    "text": "batch system it is designed to try to",
    "start": "1056400",
    "end": "1058880"
  },
  {
    "text": "address in these challenges",
    "start": "1058880",
    "end": "1060640"
  },
  {
    "text": "as you can see volcano implements a",
    "start": "1060640",
    "end": "1063039"
  },
  {
    "text": "batch scheduler",
    "start": "1063039",
    "end": "1064160"
  },
  {
    "text": "to provide the rich scheduling policy",
    "start": "1064160",
    "end": "1067760"
  },
  {
    "text": "a new controller is added to do the",
    "start": "1067760",
    "end": "1070160"
  },
  {
    "text": "lifecycle management",
    "start": "1070160",
    "end": "1071760"
  },
  {
    "text": "and provide a unified interface to",
    "start": "1071760",
    "end": "1075039"
  },
  {
    "text": "for different kind of workload we also",
    "start": "1075039",
    "end": "1077679"
  },
  {
    "text": "provide",
    "start": "1077679",
    "end": "1078320"
  },
  {
    "text": "some command line for hpc users",
    "start": "1078320",
    "end": "1083039"
  },
  {
    "text": "to help them to sub submit workload",
    "start": "1083039",
    "end": "1086880"
  },
  {
    "text": "by coming on",
    "start": "1086880",
    "end": "1090400"
  },
  {
    "start": "1090000",
    "end": "1123000"
  },
  {
    "text": "okay okay is a cncf sandbox",
    "start": "1090960",
    "end": "1095919"
  },
  {
    "text": "project right now there are more than",
    "start": "1095919",
    "end": "1100440"
  },
  {
    "text": "106 hundred github stars and more than",
    "start": "1100440",
    "end": "1104880"
  },
  {
    "text": "100 contributors from different",
    "start": "1104880",
    "end": "1109200"
  },
  {
    "text": "from different company and organization",
    "start": "1109200",
    "end": "1112240"
  },
  {
    "text": "there are there already have released",
    "start": "1112240",
    "end": "1115520"
  },
  {
    "text": "from",
    "start": "1115520",
    "end": "1116000"
  },
  {
    "text": "pharmaceutical and more than more than",
    "start": "1116000",
    "end": "1119360"
  },
  {
    "text": "14 public adopters",
    "start": "1119360",
    "end": "1123840"
  },
  {
    "start": "1123000",
    "end": "1190000"
  },
  {
    "text": "here is the volcano overall",
    "start": "1124799",
    "end": "1128160"
  },
  {
    "text": "volcano architecture volcano spots",
    "start": "1128160",
    "end": "1131200"
  },
  {
    "text": "scheduling multiple tabs overclocked in",
    "start": "1131200",
    "end": "1133360"
  },
  {
    "text": "one cluster the resources",
    "start": "1133360",
    "end": "1135360"
  },
  {
    "text": "can be shared among this workload to get",
    "start": "1135360",
    "end": "1137840"
  },
  {
    "text": "a better",
    "start": "1137840",
    "end": "1138799"
  },
  {
    "text": "utilization this workload might be",
    "start": "1138799",
    "end": "1141600"
  },
  {
    "text": "online microservice",
    "start": "1141600",
    "end": "1143120"
  },
  {
    "text": "or offline data analysis tasks or ai",
    "start": "1143120",
    "end": "1146720"
  },
  {
    "text": "workload",
    "start": "1146720",
    "end": "1147760"
  },
  {
    "text": "volcano provides queue for users to plan",
    "start": "1147760",
    "end": "1150880"
  },
  {
    "text": "their",
    "start": "1150880",
    "end": "1151440"
  },
  {
    "text": "cluster resource it's easy to map the",
    "start": "1151440",
    "end": "1154080"
  },
  {
    "text": "com",
    "start": "1154080",
    "end": "1154559"
  },
  {
    "text": "company organization to volcano queue",
    "start": "1154559",
    "end": "1157919"
  },
  {
    "text": "different departments can share",
    "start": "1157919",
    "end": "1159919"
  },
  {
    "text": "resources to each other",
    "start": "1159919",
    "end": "1161600"
  },
  {
    "text": "when the resource is added the rich",
    "start": "1161600",
    "end": "1164880"
  },
  {
    "text": "scheduling policies",
    "start": "1164880",
    "end": "1166160"
  },
  {
    "text": "are supported in volcano such as",
    "start": "1166160",
    "end": "1168799"
  },
  {
    "text": "priority scheduling",
    "start": "1168799",
    "end": "1170480"
  },
  {
    "text": "topology scheduling preemption reclaimed",
    "start": "1170480",
    "end": "1174000"
  },
  {
    "text": "time division multiplexing and so on",
    "start": "1174000",
    "end": "1177440"
  },
  {
    "text": "and also supports monitoring of",
    "start": "1177440",
    "end": "1179760"
  },
  {
    "text": "resources",
    "start": "1179760",
    "end": "1181120"
  },
  {
    "text": "for fun green scheduling the red part",
    "start": "1181120",
    "end": "1184559"
  },
  {
    "text": "shows the benefits volcano in different",
    "start": "1184559",
    "end": "1186960"
  },
  {
    "text": "scenarios",
    "start": "1186960",
    "end": "1188000"
  },
  {
    "text": "we will talk it later",
    "start": "1188000",
    "end": "1192559"
  },
  {
    "text": "the first scenario is showing the",
    "start": "1192559",
    "end": "1195679"
  },
  {
    "text": "gun scaling in tension flow training as",
    "start": "1195679",
    "end": "1198320"
  },
  {
    "text": "you know",
    "start": "1198320",
    "end": "1199039"
  },
  {
    "text": "all or nothing scaling is required for",
    "start": "1199039",
    "end": "1201440"
  },
  {
    "text": "tension flow or mpl workload",
    "start": "1201440",
    "end": "1203679"
  },
  {
    "text": "to solve deadlock obviously team in the",
    "start": "1203679",
    "end": "1206640"
  },
  {
    "text": "test",
    "start": "1206640",
    "end": "1207440"
  },
  {
    "text": "there's there's no enough resources",
    "start": "1207440",
    "end": "1210880"
  },
  {
    "text": "results for two jobs to run concurrently",
    "start": "1210880",
    "end": "1213679"
  },
  {
    "text": "in the cluster",
    "start": "1213679",
    "end": "1214960"
  },
  {
    "text": "then we submit jobs to cluster",
    "start": "1214960",
    "end": "1218159"
  },
  {
    "text": "as you can see when we submit 5 jobs",
    "start": "1218159",
    "end": "1222799"
  },
  {
    "text": "12 jobs with 2ps and 4 workers only 2",
    "start": "1222799",
    "end": "1226480"
  },
  {
    "text": "of the 5 jobs finished because of the",
    "start": "1226480",
    "end": "1229520"
  },
  {
    "text": "deadlock",
    "start": "1229520",
    "end": "1230480"
  },
  {
    "text": "the left 3 job of occupied parts of",
    "start": "1230480",
    "end": "1234320"
  },
  {
    "text": "resources",
    "start": "1234320",
    "end": "1235120"
  },
  {
    "text": "and waiting for other job release",
    "start": "1235120",
    "end": "1237200"
  },
  {
    "text": "resources each other",
    "start": "1237200",
    "end": "1240639"
  },
  {
    "text": "the second scenario is tension flow",
    "start": "1244000",
    "end": "1245919"
  },
  {
    "text": "training our performance testing it is",
    "start": "1245919",
    "end": "1248640"
  },
  {
    "text": "found that",
    "start": "1248640",
    "end": "1249520"
  },
  {
    "text": "the different placement of ps and work",
    "start": "1249520",
    "end": "1252559"
  },
  {
    "text": "post affects the training result",
    "start": "1252559",
    "end": "1255520"
  },
  {
    "text": "especially for gpu training",
    "start": "1255520",
    "end": "1258000"
  },
  {
    "text": "for some models the course is the host",
    "start": "1258000",
    "end": "1260799"
  },
  {
    "text": "network is better",
    "start": "1260799",
    "end": "1262000"
  },
  {
    "text": "than network across coast",
    "start": "1262000",
    "end": "1265120"
  },
  {
    "text": "fps and work port can be scheduled",
    "start": "1265120",
    "end": "1269440"
  },
  {
    "text": "scheduled to one host they can exchange",
    "start": "1269440",
    "end": "1272159"
  },
  {
    "text": "data",
    "start": "1272159",
    "end": "1273120"
  },
  {
    "text": "with host network there are three nodes",
    "start": "1273120",
    "end": "1275840"
  },
  {
    "text": "there's three node in the test cluster",
    "start": "1275840",
    "end": "1277840"
  },
  {
    "text": "and we submit",
    "start": "1277840",
    "end": "1278799"
  },
  {
    "text": "training training job with two ps",
    "start": "1278799",
    "end": "1281840"
  },
  {
    "text": "and four workers we get three different",
    "start": "1281840",
    "end": "1285200"
  },
  {
    "text": "please",
    "start": "1285200",
    "end": "1285760"
  },
  {
    "text": "placement at last the result is random",
    "start": "1285760",
    "end": "1289120"
  },
  {
    "text": "with default scheduler",
    "start": "1289120",
    "end": "1290640"
  },
  {
    "text": "as you know the group c is the best",
    "start": "1290640",
    "end": "1293440"
  },
  {
    "text": "placement",
    "start": "1293440",
    "end": "1294159"
  },
  {
    "text": "that we want the task",
    "start": "1294159",
    "end": "1297520"
  },
  {
    "text": "top largest schedule in keno is target",
    "start": "1297520",
    "end": "1300320"
  },
  {
    "text": "to handle this kind of visual",
    "start": "1300320",
    "end": "1302159"
  },
  {
    "text": "you can define the top logic of the task",
    "start": "1302159",
    "end": "1305280"
  },
  {
    "text": "in job the scheduling will get you the",
    "start": "1305280",
    "end": "1308000"
  },
  {
    "text": "best placement",
    "start": "1308000",
    "end": "1309120"
  },
  {
    "text": "based on the input a notice is that",
    "start": "1309120",
    "end": "1312320"
  },
  {
    "text": "the complexity of the feature doesn't",
    "start": "1312320",
    "end": "1315360"
  },
  {
    "text": "increase the doesn't increase with the",
    "start": "1315360",
    "end": "1318640"
  },
  {
    "text": "cluster skill",
    "start": "1318640",
    "end": "1319919"
  },
  {
    "text": "as far as i know some users use the",
    "start": "1319919",
    "end": "1323200"
  },
  {
    "text": "kubernetes affinity and anti-affinity",
    "start": "1323200",
    "end": "1325440"
  },
  {
    "text": "features to achieve this goal",
    "start": "1325440",
    "end": "1327360"
  },
  {
    "text": "however the complete the complexity",
    "start": "1327360",
    "end": "1330720"
  },
  {
    "text": "increase with the cluster skill",
    "start": "1330720",
    "end": "1335520"
  },
  {
    "text": "we also do some research on the el aware",
    "start": "1336640",
    "end": "1339360"
  },
  {
    "text": "scheduling",
    "start": "1339360",
    "end": "1340159"
  },
  {
    "text": "with the task top launcher info and",
    "start": "1340159",
    "end": "1343200"
  },
  {
    "text": "io information we can make we can",
    "start": "1343200",
    "end": "1346640"
  },
  {
    "text": "minimalize the max state transfer",
    "start": "1346640",
    "end": "1349120"
  },
  {
    "text": "latency",
    "start": "1349120",
    "end": "1349919"
  },
  {
    "text": "and give even better performance the",
    "start": "1349919",
    "end": "1352480"
  },
  {
    "text": "figure shows",
    "start": "1352480",
    "end": "1353360"
  },
  {
    "text": "the vgg 16 model training results with",
    "start": "1353360",
    "end": "1356799"
  },
  {
    "text": "diff with default scheduling",
    "start": "1356799",
    "end": "1358559"
  },
  {
    "text": "volcano task top larger and lower",
    "start": "1358559",
    "end": "1361280"
  },
  {
    "text": "scheduling",
    "start": "1361280",
    "end": "1362080"
  },
  {
    "text": "the l awares scheduling gets 13",
    "start": "1362080",
    "end": "1365600"
  },
  {
    "text": "30 performance increase",
    "start": "1365600",
    "end": "1368880"
  },
  {
    "text": "compared with default schedule the",
    "start": "1368880",
    "end": "1370960"
  },
  {
    "text": "result depends",
    "start": "1370960",
    "end": "1372000"
  },
  {
    "text": "the result depends on the data exchange",
    "start": "1372000",
    "end": "1375520"
  },
  {
    "text": "and models",
    "start": "1375520",
    "end": "1378159"
  },
  {
    "start": "1378000",
    "end": "1482000"
  },
  {
    "text": "this this page shows the survival",
    "start": "1381679",
    "end": "1384080"
  },
  {
    "text": "kubernetes",
    "start": "1384080",
    "end": "1384960"
  },
  {
    "text": "with volcano several years ago we",
    "start": "1384960",
    "end": "1387360"
  },
  {
    "text": "started",
    "start": "1387360",
    "end": "1388159"
  },
  {
    "text": "to help users to migrate backup workload",
    "start": "1388159",
    "end": "1391440"
  },
  {
    "text": "from hadoop",
    "start": "1391440",
    "end": "1392640"
  },
  {
    "text": "to kubernetes we use the tpcds",
    "start": "1392640",
    "end": "1395919"
  },
  {
    "text": "to do the performance test it is found",
    "start": "1395919",
    "end": "1398559"
  },
  {
    "text": "that",
    "start": "1398559",
    "end": "1399120"
  },
  {
    "text": "the deadlock happened when the job",
    "start": "1399120",
    "end": "1400960"
  },
  {
    "text": "concurrently is",
    "start": "1400960",
    "end": "1403120"
  },
  {
    "text": "is high the main reason the main reason",
    "start": "1403120",
    "end": "1405760"
  },
  {
    "text": "is that",
    "start": "1405760",
    "end": "1406320"
  },
  {
    "text": "all the results are allocated to spark",
    "start": "1406320",
    "end": "1410880"
  },
  {
    "text": "driver code the extra code has started",
    "start": "1410880",
    "end": "1414400"
  },
  {
    "text": "later than driver code and no results",
    "start": "1414400",
    "end": "1416880"
  },
  {
    "text": "available",
    "start": "1416880",
    "end": "1417760"
  },
  {
    "text": "also black applications are stacked",
    "start": "1417760",
    "end": "1419520"
  },
  {
    "text": "there we have two prepared",
    "start": "1419520",
    "end": "1422240"
  },
  {
    "text": "dedicated node for extruder and driver",
    "start": "1422240",
    "end": "1426240"
  },
  {
    "text": "code to resolve this probe this problem",
    "start": "1426240",
    "end": "1429120"
  },
  {
    "text": "however this kind of no",
    "start": "1429120",
    "end": "1430799"
  },
  {
    "text": "division increases increase the resource",
    "start": "1430799",
    "end": "1434159"
  },
  {
    "text": "fragment",
    "start": "1434159",
    "end": "1435200"
  },
  {
    "text": "as you never know what is the best",
    "start": "1435200",
    "end": "1437840"
  },
  {
    "text": "proportion",
    "start": "1437840",
    "end": "1438640"
  },
  {
    "text": "for driver node and external node",
    "start": "1438640",
    "end": "1442000"
  },
  {
    "text": "a new feature called mean minimal",
    "start": "1442000",
    "end": "1444720"
  },
  {
    "text": "results is",
    "start": "1444720",
    "end": "1445600"
  },
  {
    "text": "introduced based on this situation in",
    "start": "1445600",
    "end": "1447919"
  },
  {
    "text": "volcano",
    "start": "1447919",
    "end": "1448799"
  },
  {
    "text": "volcano create put group for each spark",
    "start": "1448799",
    "end": "1451679"
  },
  {
    "text": "application",
    "start": "1451679",
    "end": "1452559"
  },
  {
    "text": "the minimum result is a property of",
    "start": "1452559",
    "end": "1456240"
  },
  {
    "text": "both group the scheduler reserve minimal",
    "start": "1456240",
    "end": "1459520"
  },
  {
    "text": "results for each spark application",
    "start": "1459520",
    "end": "1461600"
  },
  {
    "text": "and the result resolves a driver called",
    "start": "1461600",
    "end": "1464480"
  },
  {
    "text": "over commits issue",
    "start": "1464480",
    "end": "1466080"
  },
  {
    "text": "it is a job level scheduling user no",
    "start": "1466080",
    "end": "1468880"
  },
  {
    "text": "need",
    "start": "1468880",
    "end": "1469440"
  },
  {
    "text": "to prepare the dedicated node anymore",
    "start": "1469440",
    "end": "1473039"
  },
  {
    "text": "and also the fragment issue is resolved",
    "start": "1473039",
    "end": "1476480"
  },
  {
    "text": "as you can see the performance improved",
    "start": "1476480",
    "end": "1479360"
  },
  {
    "text": "more than 30 percent",
    "start": "1479360",
    "end": "1482559"
  },
  {
    "start": "1482000",
    "end": "1566000"
  },
  {
    "text": "next as more and more mpi users try to",
    "start": "1484880",
    "end": "1488240"
  },
  {
    "text": "submit",
    "start": "1488240",
    "end": "1488880"
  },
  {
    "text": "workload to kubernetes with volcano job",
    "start": "1488880",
    "end": "1492000"
  },
  {
    "text": "volcano provides some features to help",
    "start": "1492000",
    "end": "1494400"
  },
  {
    "text": "users",
    "start": "1494400",
    "end": "1495120"
  },
  {
    "text": "submit mpi job work workloads",
    "start": "1495120",
    "end": "1498799"
  },
  {
    "text": "to kubernetes the left part shows a",
    "start": "1498799",
    "end": "1501760"
  },
  {
    "text": "volcano job for running",
    "start": "1501760",
    "end": "1503360"
  },
  {
    "text": "npr workload user can define the main",
    "start": "1503360",
    "end": "1506720"
  },
  {
    "text": "available resources",
    "start": "1506720",
    "end": "1508480"
  },
  {
    "text": "for gun scheduling user also can define",
    "start": "1508480",
    "end": "1511840"
  },
  {
    "text": "the job policy as well",
    "start": "1511840",
    "end": "1513679"
  },
  {
    "text": "for example event port evicted",
    "start": "1513679",
    "end": "1517679"
  },
  {
    "text": "action a restarted job this means",
    "start": "1517679",
    "end": "1520880"
  },
  {
    "text": "whenever the port is evicted the mpi job",
    "start": "1520880",
    "end": "1524080"
  },
  {
    "text": "will be",
    "start": "1524080",
    "end": "1524799"
  },
  {
    "text": "restarted automatically user can also",
    "start": "1524799",
    "end": "1528880"
  },
  {
    "text": "define the mpl",
    "start": "1528880",
    "end": "1530799"
  },
  {
    "text": "master ampl worker replicas resource",
    "start": "1530799",
    "end": "1533840"
  },
  {
    "text": "requests",
    "start": "1533840",
    "end": "1534880"
  },
  {
    "text": "task policy respectively in addition",
    "start": "1534880",
    "end": "1538240"
  },
  {
    "text": "volcano provides building job plugins",
    "start": "1538240",
    "end": "1541440"
  },
  {
    "text": "to simplify the configuration for",
    "start": "1541440",
    "end": "1544640"
  },
  {
    "text": "example",
    "start": "1544640",
    "end": "1545840"
  },
  {
    "text": "the ssh plugin provides",
    "start": "1545840",
    "end": "1549200"
  },
  {
    "text": "ssh authentication wizard password",
    "start": "1549200",
    "end": "1552799"
  },
  {
    "text": "and the svc plugin prepared",
    "start": "1552799",
    "end": "1556159"
  },
  {
    "text": "hardly service for communication among",
    "start": "1556159",
    "end": "1559279"
  },
  {
    "text": "the pod",
    "start": "1559279",
    "end": "1561600"
  },
  {
    "text": "it is convenient for mpi users",
    "start": "1561600",
    "end": "1566799"
  },
  {
    "start": "1566000",
    "end": "1603000"
  },
  {
    "text": "another another scenario is the gpu",
    "start": "1567520",
    "end": "1570720"
  },
  {
    "text": "sharing gpu resource is expensive",
    "start": "1570720",
    "end": "1573200"
  },
  {
    "text": "resource",
    "start": "1573200",
    "end": "1573919"
  },
  {
    "text": "the gpu resource utilization is not good",
    "start": "1573919",
    "end": "1576320"
  },
  {
    "text": "enough in some conditions such as",
    "start": "1576320",
    "end": "1578159"
  },
  {
    "text": "development",
    "start": "1578159",
    "end": "1579039"
  },
  {
    "text": "environment and the influence inference",
    "start": "1579039",
    "end": "1583440"
  },
  {
    "text": "gpu sharing is is expected by many users",
    "start": "1583440",
    "end": "1587039"
  },
  {
    "text": "who cannot provide the gpu sharing",
    "start": "1587039",
    "end": "1589279"
  },
  {
    "text": "ability",
    "start": "1589279",
    "end": "1590159"
  },
  {
    "text": "user can specify specify the memory",
    "start": "1590159",
    "end": "1593120"
  },
  {
    "text": "amount",
    "start": "1593120",
    "end": "1593600"
  },
  {
    "text": "they need the soft solution is supported",
    "start": "1593600",
    "end": "1597120"
  },
  {
    "text": "so far the hard",
    "start": "1597120",
    "end": "1598720"
  },
  {
    "text": "solution will be supported",
    "start": "1598720",
    "end": "1601840"
  },
  {
    "text": "in the future",
    "start": "1601840",
    "end": "1604480"
  },
  {
    "start": "1603000",
    "end": "1625000"
  },
  {
    "text": "cromwell is a popular pipeline software",
    "start": "1605520",
    "end": "1608159"
  },
  {
    "text": "and widely used",
    "start": "1608159",
    "end": "1609120"
  },
  {
    "text": "in gene computing volcano has been",
    "start": "1609120",
    "end": "1612480"
  },
  {
    "text": "integrated with from where user can use",
    "start": "1612480",
    "end": "1615200"
  },
  {
    "text": "the wdl to",
    "start": "1615200",
    "end": "1616799"
  },
  {
    "text": "adjust treat the volcano job the ability",
    "start": "1616799",
    "end": "1620080"
  },
  {
    "text": "has already supported",
    "start": "1620080",
    "end": "1621520"
  },
  {
    "text": "in reagent computing service",
    "start": "1621520",
    "end": "1624880"
  },
  {
    "text": "for the lpc user commander is",
    "start": "1624880",
    "end": "1628640"
  },
  {
    "start": "1625000",
    "end": "1653000"
  },
  {
    "text": "commander is important they always use",
    "start": "1628640",
    "end": "1631919"
  },
  {
    "text": "the command line to submit",
    "start": "1631919",
    "end": "1633440"
  },
  {
    "text": "to to to to submit workload volcano",
    "start": "1633440",
    "end": "1636960"
  },
  {
    "text": "provides",
    "start": "1636960",
    "end": "1637600"
  },
  {
    "text": "a set of command lines such as resub we",
    "start": "1637600",
    "end": "1640799"
  },
  {
    "text": "console we suspend to have",
    "start": "1640799",
    "end": "1642559"
  },
  {
    "text": "users migrate migrate a pc workload",
    "start": "1642559",
    "end": "1646159"
  },
  {
    "text": "kubernetes",
    "start": "1646159",
    "end": "1647279"
  },
  {
    "text": "variants of sdt language are",
    "start": "1647279",
    "end": "1650480"
  },
  {
    "text": "supported as well",
    "start": "1650480",
    "end": "1655840"
  },
  {
    "start": "1653000",
    "end": "1718000"
  },
  {
    "text": "nowadays the clusters still become",
    "start": "1656000",
    "end": "1658720"
  },
  {
    "text": "bigger and bigger as far as i know there",
    "start": "1658720",
    "end": "1660960"
  },
  {
    "text": "are more",
    "start": "1660960",
    "end": "1661679"
  },
  {
    "text": "more than two zone nodes in one",
    "start": "1661679",
    "end": "1664399"
  },
  {
    "text": "kubernetes clusters in some users",
    "start": "1664399",
    "end": "1666559"
  },
  {
    "text": "production environment",
    "start": "1666559",
    "end": "1668080"
  },
  {
    "text": "the coupe stream is a simulator of",
    "start": "1668080",
    "end": "1670080"
  },
  {
    "text": "kubernetes for batch",
    "start": "1670080",
    "end": "1672240"
  },
  {
    "text": "and offline workload it is based on the",
    "start": "1672240",
    "end": "1674960"
  },
  {
    "text": "kumark on kubernetes",
    "start": "1674960",
    "end": "1676640"
  },
  {
    "text": "we can use it to simulate simulate super",
    "start": "1676640",
    "end": "1679760"
  },
  {
    "text": "skill cluster to do the scheduler",
    "start": "1679760",
    "end": "1682159"
  },
  {
    "text": "performance testing",
    "start": "1682159",
    "end": "1683760"
  },
  {
    "text": "there are two problem problems in kumark",
    "start": "1683760",
    "end": "1686480"
  },
  {
    "text": "the first problem is",
    "start": "1686480",
    "end": "1687919"
  },
  {
    "text": "user cannot configure the resource",
    "start": "1687919",
    "end": "1690559"
  },
  {
    "text": "results of hollow node",
    "start": "1690559",
    "end": "1692240"
  },
  {
    "text": "the second problem is the ports leaders",
    "start": "1692240",
    "end": "1695200"
  },
  {
    "text": "which running on the whole",
    "start": "1695200",
    "end": "1696799"
  },
  {
    "text": "hollow node cannot be updated these",
    "start": "1696799",
    "end": "1700000"
  },
  {
    "text": "problems are resolved",
    "start": "1700000",
    "end": "1701919"
  },
  {
    "text": "in cubism in the future the way",
    "start": "1701919",
    "end": "1705039"
  },
  {
    "text": "we may add more enhancements for group",
    "start": "1705039",
    "end": "1707279"
  },
  {
    "text": "theme for example",
    "start": "1707279",
    "end": "1708640"
  },
  {
    "text": "and more job template to support",
    "start": "1708640",
    "end": "1710799"
  },
  {
    "text": "simulate",
    "start": "1710799",
    "end": "1711760"
  },
  {
    "text": "bad bad shop submission etc",
    "start": "1711760",
    "end": "1716960"
  },
  {
    "text": "you can join the volcano and",
    "start": "1720000",
    "end": "1723120"
  },
  {
    "text": "edl community to learn more about how to",
    "start": "1723120",
    "end": "1725760"
  },
  {
    "text": "apply",
    "start": "1725760",
    "end": "1726320"
  },
  {
    "text": "and optimize the",
    "start": "1726320",
    "end": "1729919"
  },
  {
    "text": "this distillation on kubernetes we have",
    "start": "1729919",
    "end": "1733360"
  },
  {
    "text": "google",
    "start": "1733360",
    "end": "1734480"
  },
  {
    "text": "slide channel for open communicate",
    "start": "1734480",
    "end": "1736559"
  },
  {
    "text": "communicating communication",
    "start": "1736559",
    "end": "1738399"
  },
  {
    "text": "and you can also submit prn issue on",
    "start": "1738399",
    "end": "1741279"
  },
  {
    "text": "github",
    "start": "1741279",
    "end": "1742880"
  },
  {
    "text": "volcano pedopedal and edr report",
    "start": "1742880",
    "end": "1745440"
  },
  {
    "text": "repository",
    "start": "1745440",
    "end": "1746559"
  },
  {
    "text": "we will respond to you as soon as",
    "start": "1746559",
    "end": "1748640"
  },
  {
    "text": "possible thank you for listening",
    "start": "1748640",
    "end": "1753840"
  }
]
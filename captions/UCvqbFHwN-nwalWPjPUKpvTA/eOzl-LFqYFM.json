[
  {
    "start": "0",
    "end": "10000"
  },
  {
    "text": "okay well thank you guys for for showing up to a talk on compliance I figured I",
    "start": "30",
    "end": "7470"
  },
  {
    "text": "might show up and be the only one but it's good to see you here so my name is Daniel white neck I'm the lead data",
    "start": "7470",
    "end": "13950"
  },
  {
    "start": "10000",
    "end": "76000"
  },
  {
    "text": "scientist at a company called pachyderm which is a company built around the open",
    "start": "13950",
    "end": "19109"
  },
  {
    "text": "source project pachyderm which I'll talk a little bit more about later but today",
    "start": "19109",
    "end": "24539"
  },
  {
    "text": "I'm going to talk about compliant data management and machine learning on kubernetes and really more specifically",
    "start": "24539",
    "end": "30090"
  },
  {
    "text": "what I want to kind of show you is that even now with the kind of layers and",
    "start": "30090",
    "end": "36090"
  },
  {
    "text": "tools and frameworks that we have for machine learning on kubernetes we can actually produce you know scalable",
    "start": "36090",
    "end": "42239"
  },
  {
    "text": "machine learning pipelines that are compliant in the midst of you know in",
    "start": "42239",
    "end": "47370"
  },
  {
    "text": "ever-increasing regulation around algorithmic decision making and kind of",
    "start": "47370",
    "end": "52410"
  },
  {
    "text": "to that end I'm also going to show you how you can actually create into end machine learning pipelines on kubernetes",
    "start": "52410",
    "end": "59270"
  },
  {
    "text": "with cloud native tooling that goes from everything from data ingestion",
    "start": "59270",
    "end": "64939"
  },
  {
    "text": "pre-processing training model export and and serving so sound ok pretty exciting",
    "start": "64939",
    "end": "72450"
  },
  {
    "text": "compliance talk right all right cool so this is kind of what that's going to",
    "start": "72450",
    "end": "77729"
  },
  {
    "start": "76000",
    "end": "108000"
  },
  {
    "text": "look like we're gonna start by talking about you know what do we mean by compliance that might mean a lot of",
    "start": "77729",
    "end": "82890"
  },
  {
    "text": "different things to a lot of different people so we're gonna nail that down and that'll lead us into talking about what",
    "start": "82890",
    "end": "88680"
  },
  {
    "text": "are the properties of a machine learning pipeline that might kind of be",
    "start": "88680",
    "end": "93780"
  },
  {
    "text": "sustainable in the midst of of regulation then we'll go on to talk about that kubernetes based solution and",
    "start": "93780",
    "end": "101130"
  },
  {
    "text": "of course we'll have a live demo because it's cube con and hopefully a lot of time for question and answer so let's",
    "start": "101130",
    "end": "109439"
  },
  {
    "start": "108000",
    "end": "184000"
  },
  {
    "text": "start by talking about the the what and the why of compliance so I'll have to give a disclaimer here I am NOT a lawyer",
    "start": "109439",
    "end": "115500"
  },
  {
    "text": "and I'm not trying to give you or your company legal advice in any sort of way but I I have been in the data science",
    "start": "115500",
    "end": "122430"
  },
  {
    "text": "world for quite a while and I've definitely seen some trends especially recently around around compliance and",
    "start": "122430",
    "end": "129119"
  },
  {
    "text": "regulations so that's really where I'm coming from with this and probably most of you guys when you think about compliance",
    "start": "129119",
    "end": "135950"
  },
  {
    "text": "think maybe first about like PCI or HIPAA compliance as related to fine",
    "start": "135950",
    "end": "142740"
  },
  {
    "text": "finance and and health care right and there's certainly compliance requirements in certain industries and",
    "start": "142740",
    "end": "149790"
  },
  {
    "text": "specific to certain types of data that's not really the compliance that I'm going to be talking about today what I what",
    "start": "149790",
    "end": "156750"
  },
  {
    "text": "I've seen and what you've probably seen in recent times is that there's kind of ever-increasing regulation around kind",
    "start": "156750",
    "end": "163890"
  },
  {
    "text": "of general data processing and algorithmic decision-making and that's",
    "start": "163890",
    "end": "169590"
  },
  {
    "text": "kind of in the spirit of gdpr here in the EU and of course all of the conversations around Facebook and",
    "start": "169590",
    "end": "175350"
  },
  {
    "text": "Cambridge analytic and the in the US and you know there'll be more and more of this stuff so to kind of nail that down",
    "start": "175350",
    "end": "181770"
  },
  {
    "text": "let's let's take a little bit of an example so earlier this week I I typed",
    "start": "181770",
    "end": "188190"
  },
  {
    "start": "184000",
    "end": "290000"
  },
  {
    "text": "in my name to Google and this was the autocomplete suggestions that came up so",
    "start": "188190",
    "end": "193530"
  },
  {
    "text": "Daniel white not github Daniel white knack pachyderm dr. Daniel white knack all of those seemingly relevant and you",
    "start": "193530",
    "end": "200970"
  },
  {
    "text": "know I'm ok with them so you know good job google on on those however if that",
    "start": "200970",
    "end": "207780"
  },
  {
    "text": "came up with something like you know Daniel white knack disgusting or Daniel white knack fraud I might not like them",
    "start": "207780",
    "end": "214739"
  },
  {
    "text": "quite as much and actually you know to be a little bit more serious that",
    "start": "214739",
    "end": "219870"
  },
  {
    "text": "actually might have a significant impact on my kind of digital identity and",
    "start": "219870",
    "end": "225420"
  },
  {
    "text": "reputation and all of those things and so you know this is a scenario where like Google's not you know processing my",
    "start": "225420",
    "end": "232769"
  },
  {
    "text": "like social security number or something but there's sort of algorithmic decision-making could have a real impact",
    "start": "232769",
    "end": "238650"
  },
  {
    "text": "on me as a human being or as a as a user and actually that's the sort of you know",
    "start": "238650",
    "end": "245760"
  },
  {
    "text": "implications that more and more there's this regulation around and actually you know as an indication of this you can",
    "start": "245760",
    "end": "252000"
  },
  {
    "text": "kind of see here where Google's put in you know report inappropriate predictions because you know they have",
    "start": "252000",
    "end": "257970"
  },
  {
    "text": "gotten sued over this and of course this is maybe a benign this example and in",
    "start": "257970",
    "end": "265500"
  },
  {
    "text": "many cases but you know if you thinking about accepting or rejecting someone for an insurance policy or",
    "start": "265500",
    "end": "271680"
  },
  {
    "text": "something like that you know not only do we have like um I would say a moral",
    "start": "271680",
    "end": "277740"
  },
  {
    "text": "imperative to be transparent around how we're making that decision and how we're processing the data to actually produce",
    "start": "277740",
    "end": "283560"
  },
  {
    "text": "that result but you know there's going to be a legal imperative in a lot of",
    "start": "283560",
    "end": "289979"
  },
  {
    "text": "cases and so essentially what I'm getting at here in terms of compliance",
    "start": "289979",
    "end": "295130"
  },
  {
    "start": "290000",
    "end": "365000"
  },
  {
    "text": "it is not really related to like anonymization or privacy or something like that necessarily there's a lot of",
    "start": "295130",
    "end": "302280"
  },
  {
    "text": "great talks on that and in other places but what I'm talking about is really kind of in in the spirit of GDP our like",
    "start": "302280",
    "end": "309210"
  },
  {
    "text": "and in the spirit of kind of this moral imperative to to make transparent and",
    "start": "309210",
    "end": "316020"
  },
  {
    "text": "explain you know which data we processed in our pipelines how we processed it",
    "start": "316020",
    "end": "321950"
  },
  {
    "text": "throughout our pipelines who processed it and you know what data did we",
    "start": "321950",
    "end": "327660"
  },
  {
    "text": "generate at the end so that might end up with like an autocomplete suggestion right at the end of the day it might end",
    "start": "327660",
    "end": "333330"
  },
  {
    "text": "up with like a risk assessment for someone if we're approving or disapproving someone for insurance all",
    "start": "333330",
    "end": "339810"
  },
  {
    "text": "right so this is really at the heart of what I see as kind of this trend of what we need to work towards in our machine",
    "start": "339810",
    "end": "346320"
  },
  {
    "text": "learning pipelines and this is really what I mean when I'm talking talking about compliance if you if you're",
    "start": "346320",
    "end": "354120"
  },
  {
    "text": "interested in kind of specific links to like certain laws and other things I can",
    "start": "354120",
    "end": "359370"
  },
  {
    "text": "help you find those but I won't be discussing specific you know laws or regulations in this talk okay so now",
    "start": "359370",
    "end": "367560"
  },
  {
    "start": "365000",
    "end": "518000"
  },
  {
    "text": "let's think about what are some like guidelines and what are some properties of machine learning pipelines that would",
    "start": "367560",
    "end": "374250"
  },
  {
    "text": "kind of make benefit them in terms of being able to you know explain all of",
    "start": "374250",
    "end": "380669"
  },
  {
    "text": "the data and processing that took place to create a certain result how do we actually put that into into practice so",
    "start": "380669",
    "end": "387960"
  },
  {
    "text": "in the example of the autocomplete kind of suggestion case right you know I",
    "start": "387960",
    "end": "393120"
  },
  {
    "text": "don't work at Google so I can't say exactly how they do that but I'm guessing it's probably more than like a",
    "start": "393120",
    "end": "399810"
  },
  {
    "text": "single Jupiter notebook right like there's a few steps",
    "start": "399810",
    "end": "404850"
  },
  {
    "text": "involved in that process to actually get to that end result and this is where",
    "start": "404850",
    "end": "410370"
  },
  {
    "text": "like the complication in terms of being transparent gets really really tough so",
    "start": "410370",
    "end": "416340"
  },
  {
    "text": "we all like to talk about and focus on like machine learning training and the inference pieces of what we're doing",
    "start": "416340",
    "end": "422460"
  },
  {
    "text": "right that's pretty much 95% of the blog posts and and talks about this but",
    "start": "422460",
    "end": "428550"
  },
  {
    "text": "really you know we have we have a ton of work that goes on before that in terms of pre-processing and model selection we",
    "start": "428550",
    "end": "435120"
  },
  {
    "text": "have a lot going on around training and in terms of transforms and model optimization and export and again we",
    "start": "435120",
    "end": "443010"
  },
  {
    "text": "have more transforms and potentially post-processing after inference right so there's there's a lot of processing",
    "start": "443010",
    "end": "448289"
  },
  {
    "text": "involved in this and you you've kind of seen this picture in other talks if you've been around today and it's true",
    "start": "448289",
    "end": "455880"
  },
  {
    "text": "that this processing piece is part of the problem and like orchestration of this is part of the problem but that's",
    "start": "455880",
    "end": "461400"
  },
  {
    "text": "even not everything right because each one of these stages has input and output",
    "start": "461400",
    "end": "466830"
  },
  {
    "text": "data right and so like we have a lot of relevant data in terms of like data that",
    "start": "466830",
    "end": "474360"
  },
  {
    "text": "eventually led to some result but that's actually not even like all of the story",
    "start": "474360",
    "end": "480120"
  },
  {
    "text": "right because without the context of what data was input to what to produce what data which was input to what etc",
    "start": "480120",
    "end": "486900"
  },
  {
    "text": "etc then all of that stuff is relatively meaningless right so this is really the",
    "start": "486900",
    "end": "493169"
  },
  {
    "text": "the problem of kind of being transparent in in this pipeline is that we have all",
    "start": "493169",
    "end": "500099"
  },
  {
    "text": "of these different pieces of data and processing and if we want to be transparent about you know how we",
    "start": "500099",
    "end": "507449"
  },
  {
    "text": "actually got to a certain result then you know my suggestion and what I think I see as kind of the trends here as far",
    "start": "507449",
    "end": "515310"
  },
  {
    "text": "as what we need for the sort of pipeline is a framework an agnostic framework and",
    "start": "515310",
    "end": "521969"
  },
  {
    "start": "518000",
    "end": "570000"
  },
  {
    "text": "infrastructure agnostic way to deploy manage and define our workflows so each",
    "start": "521969",
    "end": "527459"
  },
  {
    "text": "one of those pieces in that previous pipeline might be a totally different framework right like and a totally",
    "start": "527459",
    "end": "534150"
  },
  {
    "text": "different team working even a certain team using like Python to do some stuff and tensorflow and other",
    "start": "534150",
    "end": "540070"
  },
  {
    "text": "team using our to do visualization and all this stuff and each of those pieces",
    "start": "540070",
    "end": "545350"
  },
  {
    "text": "might have different resource requirements right some of it might run on GPUs others might run on CPUs it's",
    "start": "545350",
    "end": "552190"
  },
  {
    "text": "scheduled in different ways and all of this so somehow we need to be able to have a unified way to define all of that",
    "start": "552190",
    "end": "559540"
  },
  {
    "text": "because if not then if we if we transfer from one system into another then we",
    "start": "559540",
    "end": "564670"
  },
  {
    "text": "completely lose the context of you know the provenance for what happened before",
    "start": "564670",
    "end": "569940"
  },
  {
    "text": "the second thing we need is we actually need a versioning system for all the",
    "start": "569940",
    "end": "575230"
  },
  {
    "start": "570000",
    "end": "619000"
  },
  {
    "text": "data models and processing in our workflow so in terms of machine learning",
    "start": "575230",
    "end": "580540"
  },
  {
    "text": "and in data science it's not enough to have versioning of code so yes you",
    "start": "580540",
    "end": "587380"
  },
  {
    "text": "should still version your code and you should do that like you're doing it but it's not enough because depending on",
    "start": "587380",
    "end": "593709"
  },
  {
    "text": "what data we put into our machine learning code right we're gonna have vastly different results and you know we",
    "start": "593709",
    "end": "600580"
  },
  {
    "text": "have all sorts of parameters that come in we have certain you know representations of pre-processing",
    "start": "600580",
    "end": "606279"
  },
  {
    "text": "transforms and all of this stuff so it's really like far from enough to have just",
    "start": "606279",
    "end": "611709"
  },
  {
    "text": "versioning of code we need some concept of these were the datasets we used and these are how they changed over time",
    "start": "611709",
    "end": "619470"
  },
  {
    "text": "then finally we need tools and/or methods for combining the two things",
    "start": "619470",
    "end": "625000"
  },
  {
    "text": "above so the way that we define our workflow and our processing and the way that we version all of our data and",
    "start": "625000",
    "end": "631120"
  },
  {
    "text": "model models and and processing because again all of these things are stitched",
    "start": "631120",
    "end": "636459"
  },
  {
    "text": "together in a certain way right even if we were versioning a certain data set",
    "start": "636459",
    "end": "641520"
  },
  {
    "text": "that doesn't give us any context as to what it was input to to create what",
    "start": "641520",
    "end": "647200"
  },
  {
    "text": "other piece of data which was input to something else which produce something downstream and this is really where this",
    "start": "647200",
    "end": "653560"
  },
  {
    "text": "idea of data provenance comes in we want to be able to say for this particular result this was the model binary that",
    "start": "653560",
    "end": "661779"
  },
  {
    "text": "was used to produce this particular result and that model binary was trained based on this training data set",
    "start": "661779",
    "end": "668649"
  },
  {
    "text": "was a result of these pre-processed training data training data sets which",
    "start": "668649",
    "end": "673809"
  },
  {
    "text": "came from this original raw data all the way back up the the pipeline and I",
    "start": "673809",
    "end": "680980"
  },
  {
    "text": "should mention too so if you were in Jeremy Louise stock earlier today he kind of emphasized that we're working as",
    "start": "680980",
    "end": "688089"
  },
  {
    "text": "a community towards like CI for models and this this is definitely relevant to",
    "start": "688089",
    "end": "693579"
  },
  {
    "text": "this point we want to be able to kind of have an audit trail of how this model went through the pipeline to eventually",
    "start": "693579",
    "end": "700360"
  },
  {
    "text": "get trained and deployed and used in inferences okay so that's all the bad",
    "start": "700360",
    "end": "707259"
  },
  {
    "start": "704000",
    "end": "739000"
  },
  {
    "text": "news it's really hard to do this stuff and we need to do a lot ok so now the",
    "start": "707259",
    "end": "712509"
  },
  {
    "text": "good news part we're at we're at cube con you know cloud native con and so you",
    "start": "712509",
    "end": "719259"
  },
  {
    "text": "know they're there's a variety of projects in this ecosystem that I would argue already helped us solve this",
    "start": "719259",
    "end": "726490"
  },
  {
    "text": "problem and create machine learning pipelines at scale that allow us to have the these properties of data provenance",
    "start": "726490",
    "end": "733149"
  },
  {
    "text": "and in in a relatively easy way to manage and so the first thing I'm going",
    "start": "733149",
    "end": "740290"
  },
  {
    "start": "739000",
    "end": "817000"
  },
  {
    "text": "to kind of go through these points and mention some of the projects and then I'm gonna come back and mention the",
    "start": "740290",
    "end": "745689"
  },
  {
    "text": "specifics about them so in terms of like this you know framework and infrastructure agnostic way to define to",
    "start": "745689",
    "end": "754059"
  },
  {
    "text": "define our workflow and deploy it obviously you've already heard about cube flow today so cube flow provides us",
    "start": "754059",
    "end": "761290"
  },
  {
    "text": "these standards packet and provides us some other things which I'll mention in a in a moment in terms of the the",
    "start": "761290",
    "end": "767470"
  },
  {
    "text": "versioning system for the data and the models and the processing in our workflow that's that's going to be",
    "start": "767470",
    "end": "772870"
  },
  {
    "text": "handled by by pachyderm and also you know we need something somewhere to",
    "start": "772870",
    "end": "778269"
  },
  {
    "text": "house our data and a storage later layer pachyderm uses an object store and again",
    "start": "778269",
    "end": "784449"
  },
  {
    "text": "since we're at cloud native con a natural choice for us would be you know the project that was announced as an",
    "start": "784449",
    "end": "790360"
  },
  {
    "text": "incubator project yesterday or whenever that was which is which is rook although",
    "start": "790360",
    "end": "795490"
  },
  {
    "text": "there's other choices as well and then in terms of tools for combining the features again pachyderm is going to",
    "start": "795490",
    "end": "801339"
  },
  {
    "text": "come in as far as orchestrating the workflow and there's projects coming on like kvc",
    "start": "801339",
    "end": "807889"
  },
  {
    "text": "which is actually part of being developed internally to to cube flow",
    "start": "807889",
    "end": "813050"
  },
  {
    "text": "which helps us kind of cache data which I'll mention here in a second so again cube flow this is the link if",
    "start": "813050",
    "end": "820610"
  },
  {
    "start": "817000",
    "end": "866000"
  },
  {
    "text": "you if you I'm sure you've heard about it today there's gonna be a keynote tomorrow cue flow is helping us",
    "start": "820610",
    "end": "826040"
  },
  {
    "text": "establish these standards these portable standards for deploying all the tools we need for this machine learning workflow",
    "start": "826040",
    "end": "832970"
  },
  {
    "text": "so that includes like things like tensorflow and Jupiter and other things but really this is a community effort",
    "start": "832970",
    "end": "839329"
  },
  {
    "text": "and there's a lot of people like the the Selden team and the pachyderm team and",
    "start": "839329",
    "end": "845509"
  },
  {
    "text": "other teams that are integrating their cloud native layers or projects into",
    "start": "845509",
    "end": "851089"
  },
  {
    "text": "cube flow to fill in all of these pieces that are needed right cube flow provides the standards but really it it's seeking",
    "start": "851089",
    "end": "858920"
  },
  {
    "text": "to kind of gather all of these projects to get together to give people the tools they need to do what they need to do",
    "start": "858920",
    "end": "866829"
  },
  {
    "start": "866000",
    "end": "978000"
  },
  {
    "text": "pachyderm again is an open-source project it's similar to like you",
    "start": "866829",
    "end": "873860"
  },
  {
    "text": "kubernetes is great as a foundation right but the reason why you know",
    "start": "873860",
    "end": "880009"
  },
  {
    "text": "service meshes is everywhere right is because service mess mesh provides a",
    "start": "880009",
    "end": "885050"
  },
  {
    "text": "layer on top of kubernetes that kubernetes doesn't provide and that layer is very valuable and so similar to",
    "start": "885050",
    "end": "890660"
  },
  {
    "text": "that pachyderm provides a layer on top of kubernetes that kubernetes doesn't naturally provide and that that's the",
    "start": "890660",
    "end": "896990"
  },
  {
    "text": "ability to both manage data in what we call data repositories so a way to",
    "start": "896990",
    "end": "902269"
  },
  {
    "text": "manage and organize data and a way to build up data pipelines so the data",
    "start": "902269",
    "end": "907850"
  },
  {
    "text": "pipeline pieces are all containerized and deployed as pods on kubernetes and then take these you know data sets or",
    "start": "907850",
    "end": "914990"
  },
  {
    "text": "these data repositories as as input now the really interesting thing about pachyderm is that all of those data",
    "start": "914990",
    "end": "921050"
  },
  {
    "text": "repositories are completely version controlled so you can kind of think about it like git for data so you have a",
    "start": "921050",
    "end": "927259"
  },
  {
    "text": "version collection of data let's say the training data that changes over time and you can always go back and look at the",
    "start": "927259",
    "end": "933559"
  },
  {
    "text": "history of that that that version set of data is input to a processing stage which under the",
    "start": "933559",
    "end": "940020"
  },
  {
    "text": "hood is run as as pods on kubernetes that outputs other data which is also version in pachyderm and might be input",
    "start": "940020",
    "end": "947160"
  },
  {
    "text": "to another stage and so you can already start to see that as we string these things together everything is version",
    "start": "947160",
    "end": "953160"
  },
  {
    "text": "and very rigorously defined all the way along the pipeline right so we can always go back and have that data",
    "start": "953160",
    "end": "959160"
  },
  {
    "text": "provenance that idea that this result came from exactly this model which was",
    "start": "959160",
    "end": "964920"
  },
  {
    "text": "trained on exactly this data which came from exactly this raw data etc it also provides certain things like access",
    "start": "964920",
    "end": "971640"
  },
  {
    "text": "controls for data which kind of gets to the who processed our data question",
    "start": "971640",
    "end": "978530"
  },
  {
    "start": "978000",
    "end": "1017000"
  },
  {
    "text": "finally I want to announce a just kind of hear that that pachyderm is currently",
    "start": "978530",
    "end": "987000"
  },
  {
    "text": "making it a priority to kind of contribute and and and be more integrated with cube flow so we now have",
    "start": "987000",
    "end": "994200"
  },
  {
    "text": "a case on it package to deploy pachyderm as as part of cube flow so that's that",
    "start": "994200",
    "end": "999990"
  },
  {
    "text": "first link there so thanks to Jeremy Jeremy Louie for work on that we also have a proposal for some more",
    "start": "999990",
    "end": "1006440"
  },
  {
    "text": "integrations which I'll mention a little bit more here in a second so we we as a community would love your input on these",
    "start": "1006440",
    "end": "1013190"
  },
  {
    "text": "things as well and your contributions of course okay",
    "start": "1013190",
    "end": "1018920"
  },
  {
    "start": "1017000",
    "end": "1047000"
  },
  {
    "text": "so then the this last piece that I'll mention here the the kvc piece provides",
    "start": "1018920",
    "end": "1024380"
  },
  {
    "text": "kind of standards and tooling for exposing data to custom resources so like if we need to cache a large amount",
    "start": "1024380",
    "end": "1031069"
  },
  {
    "text": "of training data across a TF job or a distributed tensorflow job somehow we",
    "start": "1031070",
    "end": "1036500"
  },
  {
    "text": "need to get that version data from pachyderm and we need to cache that large amount of data in in that the pods",
    "start": "1036500",
    "end": "1044420"
  },
  {
    "text": "for that TF job and that's that's what kvc provides so here's kind of a visual representation so pachyderm again is",
    "start": "1044420",
    "end": "1050630"
  },
  {
    "text": "providing this idea of these version collections of data that we call data",
    "start": "1050630",
    "end": "1055820"
  },
  {
    "text": "repositories so you might have training data on pre-processed data and actually version models right",
    "start": "1055820",
    "end": "1061220"
  },
  {
    "text": "so actually versioning all the model binaries that you're producing and then each of these stages is defined via one",
    "start": "1061220",
    "end": "1067880"
  },
  {
    "text": "or more con gainers that actually perform the processing so this is all managed via the pachyderm project but then you know",
    "start": "1067880",
    "end": "1075879"
  },
  {
    "text": "data scientists again want to use a variety of tools so pachyderm provides",
    "start": "1075879",
    "end": "1081049"
  },
  {
    "text": "this rigorous way to define this tract and version pipeline but we also want to",
    "start": "1081049",
    "end": "1087350"
  },
  {
    "text": "provide a way for data scientists to access the tools that they need for example like serving frameworks and you",
    "start": "1087350",
    "end": "1094580"
  },
  {
    "text": "know distributed tensorflow and and that's where cube flow comes in so we can actually from pachyderm reach out",
    "start": "1094580",
    "end": "1100850"
  },
  {
    "text": "and have the training be done for example by a TF job have the serving be done by a project like Selden or",
    "start": "1100850",
    "end": "1107869"
  },
  {
    "text": "tensorflow serving and have all that again be deployed and managed in a",
    "start": "1107869",
    "end": "1113359"
  },
  {
    "text": "uniform way by cube flow then the last piece is again we want ways to connect",
    "start": "1113359",
    "end": "1120259"
  },
  {
    "text": "all these these pieces in a in a uniform way and you know when you're doing distributed training a lot of times",
    "start": "1120259",
    "end": "1126950"
  },
  {
    "text": "you're using a lot of data like 200 terabytes or something and so we we also need a way to not only version control",
    "start": "1126950",
    "end": "1135350"
  },
  {
    "text": "data in a backing objects or which is non-local but we need a way to cache that and manage that right where the",
    "start": "1135350",
    "end": "1144889"
  },
  {
    "text": "processing is happening so that's where the kvc project comes in and allows us to both use the versioning version",
    "start": "1144889",
    "end": "1151070"
  },
  {
    "text": "control of pachyderm but also have this ability to cache things for say TF jobs",
    "start": "1151070",
    "end": "1158509"
  },
  {
    "text": "and I'll mentioned some more acknowledgments later but this is work being done by by Intel and the",
    "start": "1158509",
    "end": "1164619"
  },
  {
    "text": "integration with with pachyderm so overall this is kind of what the architecture looks like kubernetes again",
    "start": "1164619",
    "end": "1171350"
  },
  {
    "start": "1166000",
    "end": "1221000"
  },
  {
    "text": "at the base some persistent volumes for both metadata and maybe cache data and",
    "start": "1171350",
    "end": "1177679"
  },
  {
    "text": "then on the top we have you know queue flow related pods pachyderm related pods and this version data in the backing",
    "start": "1177679",
    "end": "1183710"
  },
  {
    "text": "object store which might be might be rook so all of these things are existing projects that you can go and spin up",
    "start": "1183710",
    "end": "1189950"
  },
  {
    "text": "today so you don't have to wait to do this yeah it's certainly there are like some rough edges in certain places but",
    "start": "1189950",
    "end": "1196759"
  },
  {
    "text": "this is something totally doable today and people are running pachyderm you all around the world people are starting",
    "start": "1196759",
    "end": "1204290"
  },
  {
    "text": "to run queue flow all around the world we've seen clusters you know running these sorts of pipelines up to 1500 plus",
    "start": "1204290",
    "end": "1211640"
  },
  {
    "text": "nodes you know with hundreds of terabytes of data so this is this is a",
    "start": "1211640",
    "end": "1217850"
  },
  {
    "text": "very real solution that you can investigate okay how's everybody doing ready to see",
    "start": "1217850",
    "end": "1225020"
  },
  {
    "start": "1221000",
    "end": "1267000"
  },
  {
    "text": "something something better okay awesome so let's go ahead and jump into into the",
    "start": "1225020",
    "end": "1231740"
  },
  {
    "text": "demo here so what I've done is essentially deployed the so earlier",
    "start": "1231740",
    "end": "1238130"
  },
  {
    "text": "today Jeremy Lewis showed a demo with like a github issue summarization model",
    "start": "1238130",
    "end": "1243440"
  },
  {
    "text": "so where you put in a github issue and it generates a summary of that github",
    "start": "1243440",
    "end": "1248510"
  },
  {
    "text": "issue based on a deep learning model or sequence to sequence model so I've",
    "start": "1248510",
    "end": "1254690"
  },
  {
    "text": "actually created a pipeline that trains that model and then builds that model",
    "start": "1254690",
    "end": "1260180"
  },
  {
    "text": "versions versions a build of that model and then similar to what I showed here",
    "start": "1260180",
    "end": "1266470"
  },
  {
    "text": "what I showed here exports that model to sell them for serving so I'm actually",
    "start": "1266470",
    "end": "1271490"
  },
  {
    "start": "1267000",
    "end": "1291000"
  },
  {
    "text": "going to start at the inference part and work our way back because ideally if we're if we have a compliant data",
    "start": "1271490",
    "end": "1277850"
  },
  {
    "text": "pipeline we should be able to start at the end and connect and stitch together all of the pieces backward to give us",
    "start": "1277850",
    "end": "1285110"
  },
  {
    "text": "that full data provenance that connects a result with all of the data and processing that led to that particular",
    "start": "1285110",
    "end": "1290750"
  },
  {
    "text": "result so here I've deployed again a REST API",
    "start": "1290750",
    "end": "1295760"
  },
  {
    "start": "1291000",
    "end": "1355000"
  },
  {
    "text": "via Selden that's going to use that that trained model to perform an inference on",
    "start": "1295760",
    "end": "1301760"
  },
  {
    "text": "this this text which is like an example github issue okay so I'm gonna send that",
    "start": "1301760",
    "end": "1308420"
  },
  {
    "text": "off to the to Selden it's going to return me an inference so here it it",
    "start": "1308420",
    "end": "1313880"
  },
  {
    "text": "summarized the github issue as how to how to to use the the use which is",
    "start": "1313880",
    "end": "1321170"
  },
  {
    "text": "probably not the best summarization although maybe is a good summarization for like 80% of github issues and but I",
    "start": "1321170",
    "end": "1329950"
  },
  {
    "text": "but let's say that it's not a good summarization right like there's",
    "start": "1329950",
    "end": "1335210"
  },
  {
    "text": "something about this result that we don't like maybe the repeated words or whatever it is right and now we want to",
    "start": "1335210",
    "end": "1342140"
  },
  {
    "text": "say okay what were all the things what was the model that led to this result how did we train that model where did",
    "start": "1342140",
    "end": "1349549"
  },
  {
    "text": "the data come from and so let's read let's retrace those steps first of all",
    "start": "1349549",
    "end": "1356330"
  },
  {
    "start": "1355000",
    "end": "1430000"
  },
  {
    "text": "let's see if we get the pods in the cube",
    "start": "1356330",
    "end": "1361760"
  },
  {
    "text": "flow namespace we'll see Selden here so these are the pods that are doing the the inferencing",
    "start": "1361760",
    "end": "1370450"
  },
  {
    "text": "should have something in my history here so now what I'm going to do is actually",
    "start": "1370450",
    "end": "1379480"
  },
  {
    "text": "I'm just gonna see what images are we use what docker images are we using to",
    "start": "1379480",
    "end": "1385250"
  },
  {
    "text": "perform that inferencing so here that's going to give me these docker images so",
    "start": "1385250",
    "end": "1391549"
  },
  {
    "text": "you can see that there's there's two containers running in the pod one is Selden and the other one is this",
    "start": "1391549",
    "end": "1397820"
  },
  {
    "text": "container that includes my model prediction code and if we look at that",
    "start": "1397820",
    "end": "1403909"
  },
  {
    "text": "model prediction container we can see that okay it's an issue summarization",
    "start": "1403909",
    "end": "1409610"
  },
  {
    "text": "container but we can also see that it's tagged okay and this is the important",
    "start": "1409610",
    "end": "1414950"
  },
  {
    "text": "part so here this is the image we're using for inference it's tagged in a",
    "start": "1414950",
    "end": "1420500"
  },
  {
    "text": "certain way and it's actually tagged with the job ID that created it in my",
    "start": "1420500",
    "end": "1426230"
  },
  {
    "text": "pachyderm pipeline so let me show you that piece now so if I go over here this",
    "start": "1426230",
    "end": "1431840"
  },
  {
    "start": "1430000",
    "end": "1659000"
  },
  {
    "text": "is the dashboard for pachyderm and this is the pipeline that's actually trained",
    "start": "1431840",
    "end": "1436870"
  },
  {
    "text": "pre-processing training my model and exporting my model to Selden so here I",
    "start": "1436870",
    "end": "1443270"
  },
  {
    "text": "can see that I have some raw data if my example github issues those are being",
    "start": "1443270",
    "end": "1448549"
  },
  {
    "text": "split into training and test sets they're being processed pre-processed in certain ways to remove stop words and",
    "start": "1448549",
    "end": "1455299"
  },
  {
    "text": "things I'm then training that model that's producing a serialized model again each of these stages has input and",
    "start": "1455299",
    "end": "1464600"
  },
  {
    "text": "output then I'm actually creating with Selden this kind of build artifact that",
    "start": "1464600",
    "end": "1471230"
  },
  {
    "text": "includes a docker image and a bunch of things that I'm gonna build into the service that I'll deploy and then",
    "start": "1471230",
    "end": "1476480"
  },
  {
    "text": "finally an export pipeline that actually just builds that docker images image and pushes it out okay so that's what the",
    "start": "1476480",
    "end": "1483170"
  },
  {
    "text": "the pipeline looks like generally but if I look here for example in my in this",
    "start": "1483170",
    "end": "1488420"
  },
  {
    "text": "training data repository remember that each one of these sets of data is version so if I look here I can see that",
    "start": "1488420",
    "end": "1495440"
  },
  {
    "text": "there's versioning semantics associated with this data I may've certain number of commits into this repo which are",
    "start": "1495440",
    "end": "1502130"
  },
  {
    "text": "changes to that data there's a certain number of files there's one branch all of those things now remember we we have",
    "start": "1502130",
    "end": "1511160"
  },
  {
    "text": "this job ID that's being used for our inferencing right how do we connect that",
    "start": "1511160",
    "end": "1518540"
  },
  {
    "text": "back to this pipeline that at some point produced that image that we're using for",
    "start": "1518540",
    "end": "1524630"
  },
  {
    "text": "inferencing well I've used a bunch of I've actually run this a bunch of times",
    "start": "1524630",
    "end": "1530360"
  },
  {
    "text": "so here's all the model the pipeline jobs that I've run for training I've run",
    "start": "1530360",
    "end": "1536630"
  },
  {
    "text": "it over and over so how one of these corresponds to the one that is being",
    "start": "1536630",
    "end": "1543920"
  },
  {
    "text": "used for our inferencing and that's connected via this ID which was automatically generated when I built the",
    "start": "1543920",
    "end": "1551450"
  },
  {
    "text": "image so if I look down here I can see that that ID a corresponds to this job and if I go over here to my pachyderm",
    "start": "1551450",
    "end": "1559970"
  },
  {
    "text": "jobs and scroll down I can find that job here and I can see that that job that",
    "start": "1559970",
    "end": "1567590"
  },
  {
    "text": "produced that docker image created this output commit and if I click on that",
    "start": "1567590",
    "end": "1573350"
  },
  {
    "text": "I'll actually see the the actual build files that correspond to that particular",
    "start": "1573350",
    "end": "1579020"
  },
  {
    "text": "docker image that's being used for my inferencing in production right and the",
    "start": "1579020",
    "end": "1585380"
  },
  {
    "text": "actual model that's being used for my for my inferencing and these aren't just like metadata associated with what that",
    "start": "1585380",
    "end": "1592490"
  },
  {
    "text": "look like I can actually get the the actual data associated with those things okay now the other piece of this is okay",
    "start": "1592490",
    "end": "1600770"
  },
  {
    "text": "that's good I can go back and see the model that was you that I'm using for for my inferencing but really if",
    "start": "1600770",
    "end": "1607160"
  },
  {
    "text": "something's going wrong I need to explain all the way back up the pipeline how that was created and so here I can",
    "start": "1607160",
    "end": "1614480"
  },
  {
    "text": "actually go into that commit and see all the upstream data and processing specs",
    "start": "1614480",
    "end": "1621470"
  },
  {
    "text": "that actually led to that particular model being being generated which include you know pre-processed the the",
    "start": "1621470",
    "end": "1628250"
  },
  {
    "text": "actual pre-process data that was used and all the other things so this in just",
    "start": "1628250",
    "end": "1633679"
  },
  {
    "text": "like with a few tools and plugging things together with cube flow I was able to deploy this whole machine",
    "start": "1633679",
    "end": "1639500"
  },
  {
    "text": "learning pipeline that uses the tools I want to use including tensor flow for training and Selden for serving but I",
    "start": "1639500",
    "end": "1646370"
  },
  {
    "text": "stitched it together in a way that's that is rigorously tracked and gives me",
    "start": "1646370",
    "end": "1652669"
  },
  {
    "text": "this idea of data provenance all the way from inference back to the raw data so",
    "start": "1652669",
    "end": "1659540"
  },
  {
    "start": "1659000",
    "end": "1733000"
  },
  {
    "text": "just to kind of finish up things here I want to you know just take an aside and",
    "start": "1659540",
    "end": "1664640"
  },
  {
    "text": "acknowledge this was not you know done by it by me myself so again the great",
    "start": "1664640",
    "end": "1670040"
  },
  {
    "text": "team at Intel is working on this kvc project Jeremy lui worked on the at Google",
    "start": "1670040",
    "end": "1675500"
  },
  {
    "text": "worked on the case on it package for pachyderm and and various other ones so",
    "start": "1675500",
    "end": "1683000"
  },
  {
    "text": "this is definitely not a me alone and as well like the pack again pachyderm is an",
    "start": "1683000",
    "end": "1688549"
  },
  {
    "text": "open source project and we've had a lot of great contributions for from other people to the project including from",
    "start": "1688549",
    "end": "1695919"
  },
  {
    "text": "from Mineo from Suzhou so Souza just announced here they're their new cast",
    "start": "1695919",
    "end": "1702830"
  },
  {
    "text": "platform which they verified pachyderm on top of Honeywell and and some people",
    "start": "1702830",
    "end": "1709429"
  },
  {
    "text": "there have contributed things into our Python client again intel has been super helpful to us in terms of running",
    "start": "1709429",
    "end": "1715490"
  },
  {
    "text": "optimize tensorflow with their they're optimized tensorflow versions and also",
    "start": "1715490",
    "end": "1720559"
  },
  {
    "text": "they have some really great stuff out now around serializing models with",
    "start": "1720559",
    "end": "1726049"
  },
  {
    "text": "things like in graph which again can be versioned as part of these pipelines and so check check all of those people out",
    "start": "1726049",
    "end": "1734290"
  },
  {
    "start": "1733000",
    "end": "1957000"
  },
  {
    "text": "so all of the resources from this I posted these slides are on the schedule I also tweeted them out so you can find",
    "start": "1734290",
    "end": "1741710"
  },
  {
    "text": "all the links there you can run this example locally you can find the docs and the public slack channels and the",
    "start": "1741710",
    "end": "1747890"
  },
  {
    "text": "repos please again you know this is all a community effort it's all out in the public so definitely reach out if you if",
    "start": "1747890",
    "end": "1753980"
  },
  {
    "text": "you uh if you want to get involved and or have questions so thank you guys very much and I think we have time for",
    "start": "1753980",
    "end": "1765740"
  },
  {
    "text": "questions",
    "start": "1765740",
    "end": "1767950"
  },
  {
    "text": "thanks very much for the talk is this concept applicable for maybe more boring",
    "start": "1784240",
    "end": "1789560"
  },
  {
    "text": "data pipelines that aren't ml related like financial reporting or anything else like that most definitely yeah so",
    "start": "1789560",
    "end": "1796490"
  },
  {
    "text": "the the pipeline's impact erm really the the only thing that we're opinionated",
    "start": "1796490",
    "end": "1801680"
  },
  {
    "text": "about is that you're able to define your processing stages via containers and then you have data that it can be stored",
    "start": "1801680",
    "end": "1809000"
  },
  {
    "text": "in an object sort which is essentially anything so yeah we have a lot of people doing like MapReduce II style data",
    "start": "1809000",
    "end": "1816860"
  },
  {
    "text": "aggregations and M log collection I didn't talk about it but pachyderm kind",
    "start": "1816860",
    "end": "1822380"
  },
  {
    "text": "has its internal concept of a distributed processing so they utilize",
    "start": "1822380",
    "end": "1827660"
  },
  {
    "text": "that we also have people doing like bioinformatics things or again just kind",
    "start": "1827660",
    "end": "1833720"
  },
  {
    "text": "of like generalized ETL and analytics yeah thanks thank you for your talk I",
    "start": "1833720",
    "end": "1849620"
  },
  {
    "text": "may have misunderstood a few things on your slide so excuse me if my question is really bizarre but so when you were",
    "start": "1849620",
    "end": "1858080"
  },
  {
    "text": "tracing back from your inference data back to the source like a raw data training data in example you were",
    "start": "1858080",
    "end": "1865520"
  },
  {
    "text": "showing git commit so is the assumption that your draw data is also committed in",
    "start": "1865520",
    "end": "1871160"
  },
  {
    "text": "git because if we are doing big data processing obviously that would not go back and to get so if my question is",
    "start": "1871160",
    "end": "1878090"
  },
  {
    "text": "still saying then how do we sort of go back to getting to the actual version of",
    "start": "1878090",
    "end": "1884030"
  },
  {
    "text": "the dis sauce training data yeah that's a great question and I definitely a relevant one so we do not use get under",
    "start": "1884030",
    "end": "1891110"
  },
  {
    "text": "the hood for a lot of reasons because git is just simply not efficient or made",
    "start": "1891110",
    "end": "1896750"
  },
  {
    "text": "for versioning large data so when I was showing here like all of these commit",
    "start": "1896750",
    "end": "1901880"
  },
  {
    "text": "IDs correspond to commit IDs into pachyderms backing version data so that",
    "start": "1901880",
    "end": "1908120"
  },
  {
    "text": "that backed version data is is backed in the object store and his version via pachyderms versioning scheme which is",
    "start": "1908120",
    "end": "1915260"
  },
  {
    "text": "specific to itself so this data I'm showing here in the in the oops",
    "start": "1915260",
    "end": "1922490"
  },
  {
    "text": "in the these repositories like this data it's backed in the object store and",
    "start": "1922490",
    "end": "1928610"
  },
  {
    "text": "pachyderm itself is versioning that data and tracking those commit IDs great",
    "start": "1928610",
    "end": "1934039"
  },
  {
    "text": "question I think that's it",
    "start": "1934039",
    "end": "1944860"
  },
  {
    "text": "all right if I have a limited number of pachyderm stickers if anybody wants them",
    "start": "1944860",
    "end": "1950240"
  },
  {
    "text": "if that's your sort of thing so happy to give those out thank you guys",
    "start": "1950240",
    "end": "1955420"
  },
  {
    "text": "[Applause]",
    "start": "1955420",
    "end": "1959349"
  }
]
[
  {
    "text": "um hello everyone thanks for joining the",
    "start": "240",
    "end": "4080"
  },
  {
    "text": "talk today i am Kevin Juan uh currently",
    "start": "4080",
    "end": "7520"
  },
  {
    "text": "working on uh multiple projects on the",
    "start": "7520",
    "end": "10519"
  },
  {
    "text": "CNCF and my personal background is more",
    "start": "10519",
    "end": "14480"
  },
  {
    "text": "uh about uh scheduling and uh actually I",
    "start": "14480",
    "end": "17279"
  },
  {
    "text": "started uh contributing to Kubernetes in",
    "start": "17279",
    "end": "20160"
  },
  {
    "text": "the early days and during recent years I",
    "start": "20160",
    "end": "23760"
  },
  {
    "text": "have been working on the volcano project",
    "start": "23760",
    "end": "26480"
  },
  {
    "text": "as well as uh Kamala project so today I",
    "start": "26480",
    "end": "30640"
  },
  {
    "text": "would like to share uh my thoughts and",
    "start": "30640",
    "end": "33760"
  },
  {
    "text": "my uh experience working on the uh",
    "start": "33760",
    "end": "36800"
  },
  {
    "text": "multicluster AI uh infrastructure",
    "start": "36800",
    "end": "39360"
  },
  {
    "text": "especially for you know a lot of uh day2",
    "start": "39360",
    "end": "43879"
  },
  {
    "text": "optimization so uh a little bit",
    "start": "43879",
    "end": "46079"
  },
  {
    "text": "background of uh the talk why we need a",
    "start": "46079",
    "end": "51640"
  },
  {
    "text": "multicluster actually uh we all know",
    "start": "51640",
    "end": "54559"
  },
  {
    "text": "that there are kind of multiple",
    "start": "54559",
    "end": "56079"
  },
  {
    "text": "backgrounds some of the company they",
    "start": "56079",
    "end": "58079"
  },
  {
    "text": "have uh multiple uh regional uh business",
    "start": "58079",
    "end": "61600"
  },
  {
    "text": "it results in physically uh divided",
    "start": "61600",
    "end": "64799"
  },
  {
    "text": "distributed clusters and also some of",
    "start": "64799",
    "end": "68159"
  },
  {
    "text": "the users may run into the you know",
    "start": "68159",
    "end": "72000"
  },
  {
    "text": "hardware procurement uh cycle issue so",
    "start": "72000",
    "end": "75200"
  },
  {
    "text": "they have to kind of extend their",
    "start": "75200",
    "end": "77439"
  },
  {
    "text": "workload to the public cloud so they can",
    "start": "77439",
    "end": "80560"
  },
  {
    "text": "uh rapidly uh rapidly get some of the uh",
    "start": "80560",
    "end": "84720"
  },
  {
    "text": "uh uh resources and also uh during my",
    "start": "84720",
    "end": "89040"
  },
  {
    "text": "experience I have met a lot of end users",
    "start": "89040",
    "end": "91920"
  },
  {
    "text": "they are kind of restructuring their uh",
    "start": "91920",
    "end": "94720"
  },
  {
    "text": "resource pools as their uh business",
    "start": "94720",
    "end": "97520"
  },
  {
    "text": "grows so previously a lot of business",
    "start": "97520",
    "end": "100240"
  },
  {
    "text": "teams they would uh independently uh",
    "start": "100240",
    "end": "103439"
  },
  {
    "text": "build and uh manage their own uh cluster",
    "start": "103439",
    "end": "106640"
  },
  {
    "text": "and later on they went to the uh",
    "start": "106640",
    "end": "109759"
  },
  {
    "text": "structure that have a uh shared infra",
    "start": "109759",
    "end": "113040"
  },
  {
    "text": "team to you know uh uh provide the uh",
    "start": "113040",
    "end": "117119"
  },
  {
    "text": "order maintenance and also share the",
    "start": "117119",
    "end": "119719"
  },
  {
    "text": "technology and also why not a few just a",
    "start": "119719",
    "end": "123439"
  },
  {
    "text": "hypers scale uh clusters a lot of users",
    "start": "123439",
    "end": "126560"
  },
  {
    "text": "said they are It's just very hard to",
    "start": "126560",
    "end": "129440"
  },
  {
    "text": "rebuild and also you know maintaining a",
    "start": "129440",
    "end": "132319"
  },
  {
    "text": "large scale clusters can be very hard so",
    "start": "132319",
    "end": "136560"
  },
  {
    "text": "that's how the story begins right so um",
    "start": "136560",
    "end": "140640"
  },
  {
    "text": "uh this is just a very uh brief",
    "start": "140640",
    "end": "143360"
  },
  {
    "text": "architecture of the uh multicluster AI",
    "start": "143360",
    "end": "146160"
  },
  {
    "text": "platform so uh actually for the",
    "start": "146160",
    "end": "149680"
  },
  {
    "text": "incluster scheduling incluster workload",
    "start": "149680",
    "end": "152560"
  },
  {
    "text": "management uh we know that uh uh the",
    "start": "152560",
    "end": "156160"
  },
  {
    "text": "volcano project has done a very good job",
    "start": "156160",
    "end": "159120"
  },
  {
    "text": "uh it help provide a lot of",
    "start": "159120",
    "end": "160800"
  },
  {
    "text": "functionality uh to support uh AI batch",
    "start": "160800",
    "end": "165120"
  },
  {
    "text": "workload friendly struggling uh uh",
    "start": "165120",
    "end": "168400"
  },
  {
    "text": "scheduling features as well as uh Q",
    "start": "168400",
    "end": "171360"
  },
  {
    "text": "features and like uh resource sharing",
    "start": "171360",
    "end": "174000"
  },
  {
    "text": "among cues and also",
    "start": "174000",
    "end": "177040"
  },
  {
    "text": "uh priority based on cues and the",
    "start": "177040",
    "end": "179760"
  },
  {
    "text": "capacity management sort of things at",
    "start": "179760",
    "end": "182239"
  },
  {
    "text": "the multicluster uh actually we can call",
    "start": "182239",
    "end": "184879"
  },
  {
    "text": "it just a federated layer uh we can use",
    "start": "184879",
    "end": "188239"
  },
  {
    "text": "uh commada to manage the uh cluster uh",
    "start": "188239",
    "end": "192400"
  },
  {
    "text": "healthy state and also uh propagate the",
    "start": "192400",
    "end": "195760"
  },
  {
    "text": "workloads to the clusters according to",
    "start": "195760",
    "end": "198959"
  },
  {
    "text": "your uh preference uh whether you would",
    "start": "198959",
    "end": "202400"
  },
  {
    "text": "like to uh whether you would like the",
    "start": "202400",
    "end": "204879"
  },
  {
    "text": "workload to be kind",
    "start": "204879",
    "end": "206879"
  },
  {
    "text": "divided or just scheduled to some of the",
    "start": "206879",
    "end": "209680"
  },
  {
    "text": "cluster or uh replicated uh in the case",
    "start": "209680",
    "end": "213200"
  },
  {
    "text": "of managing AI workloads most of the",
    "start": "213200",
    "end": "215760"
  },
  {
    "text": "case we will just find one of the",
    "start": "215760",
    "end": "219120"
  },
  {
    "text": "cluster to get it uh scheduled",
    "start": "219120",
    "end": "222159"
  },
  {
    "text": "especially for training workloads",
    "start": "222159",
    "end": "226920"
  },
  {
    "text": "and uh uh during my uh uh discussion and",
    "start": "227280",
    "end": "231280"
  },
  {
    "text": "collaboration with a lot of uh end users",
    "start": "231280",
    "end": "234319"
  },
  {
    "text": "we found that actually there are some of",
    "start": "234319",
    "end": "237200"
  },
  {
    "text": "the assumptions and the design uh",
    "start": "237200",
    "end": "239680"
  },
  {
    "text": "principles very important and that's uh",
    "start": "239680",
    "end": "243280"
  },
  {
    "text": "being kind of proven multiple times from",
    "start": "243280",
    "end": "246640"
  },
  {
    "text": "multiple users so um two-level system is",
    "start": "246640",
    "end": "251280"
  },
  {
    "text": "kind of unavoidable",
    "start": "251280",
    "end": "253200"
  },
  {
    "text": "so with that the layered uh architecture",
    "start": "253200",
    "end": "257040"
  },
  {
    "text": "need to have specific f uh focus loosely",
    "start": "257040",
    "end": "261040"
  },
  {
    "text": "coupled i mean the federation layer the",
    "start": "261040",
    "end": "264160"
  },
  {
    "text": "federated control plan layer more",
    "start": "264160",
    "end": "267280"
  },
  {
    "text": "focuses on the intercluster coordination",
    "start": "267280",
    "end": "270639"
  },
  {
    "text": "thing while the member clusters they are",
    "start": "270639",
    "end": "273680"
  },
  {
    "text": "more kind of focusing the incluster",
    "start": "273680",
    "end": "276080"
  },
  {
    "text": "thing and they can be highly autonomous",
    "start": "276080",
    "end": "279919"
  },
  {
    "text": "right so uh for the federated control",
    "start": "279919",
    "end": "282400"
  },
  {
    "text": "plan we are kind of not able to store",
    "start": "282400",
    "end": "287120"
  },
  {
    "text": "the whole uh the full detail of the uh",
    "start": "287120",
    "end": "290720"
  },
  {
    "text": "member cluster status because otherwise",
    "start": "290720",
    "end": "293199"
  },
  {
    "text": "why not we just have a hypers scale",
    "start": "293199",
    "end": "296160"
  },
  {
    "text": "cluster right uh and also like the",
    "start": "296160",
    "end": "298479"
  },
  {
    "text": "federated scheduling um you know uh",
    "start": "298479",
    "end": "302479"
  },
  {
    "text": "should not replace the",
    "start": "302479",
    "end": "305080"
  },
  {
    "text": "incluster scheduling it's more likely uh",
    "start": "305080",
    "end": "308400"
  },
  {
    "text": "just collaborating with the in cluster",
    "start": "308400",
    "end": "310960"
  },
  {
    "text": "uh scheduling and also the scheduling uh",
    "start": "310960",
    "end": "314720"
  },
  {
    "text": "in the multicluster layer is quite",
    "start": "314720",
    "end": "318039"
  },
  {
    "text": "expensive you find a place to spin up",
    "start": "318039",
    "end": "321199"
  },
  {
    "text": "your workload send it to that cluster",
    "start": "321199",
    "end": "323199"
  },
  {
    "text": "and the incluster scheduler made the",
    "start": "323199",
    "end": "325680"
  },
  {
    "text": "decision and it turned out no and then",
    "start": "325680",
    "end": "329280"
  },
  {
    "text": "you kind of evict it and return again",
    "start": "329280",
    "end": "332560"
  },
  {
    "text": "it's quite takes long and sometimes even",
    "start": "332560",
    "end": "335919"
  },
  {
    "text": "not able to uh get things fixed so we",
    "start": "335919",
    "end": "339919"
  },
  {
    "text": "need to optimize the first time",
    "start": "339919",
    "end": "344280"
  },
  {
    "text": "attempt um so with the limited time uh I",
    "start": "344280",
    "end": "348000"
  },
  {
    "text": "will just cover three uh major",
    "start": "348000",
    "end": "350080"
  },
  {
    "text": "challenges I've have been working on",
    "start": "350080",
    "end": "352320"
  },
  {
    "text": "first is about the tradeoff of the uh",
    "start": "352320",
    "end": "355520"
  },
  {
    "text": "scheduling second is about the uh fail",
    "start": "355520",
    "end": "358560"
  },
  {
    "text": "over uh between clusters for the",
    "start": "358560",
    "end": "361120"
  },
  {
    "text": "workloads and the the third part is uh",
    "start": "361120",
    "end": "363680"
  },
  {
    "text": "the uh the queueing at the uh federated",
    "start": "363680",
    "end": "366880"
  },
  {
    "text": "layer",
    "start": "366880",
    "end": "369280"
  },
  {
    "text": "so uh as I said that actually we are not",
    "start": "369280",
    "end": "372319"
  },
  {
    "text": "able to easily kind of uh store or catch",
    "start": "372319",
    "end": "376000"
  },
  {
    "text": "all the uh cluster status details we",
    "start": "376000",
    "end": "379120"
  },
  {
    "text": "need to kind of balance between uh you",
    "start": "379120",
    "end": "382080"
  },
  {
    "text": "know the footprint the overhead for the",
    "start": "382080",
    "end": "385759"
  },
  {
    "text": "control plan and also we need to take uh",
    "start": "385759",
    "end": "389039"
  },
  {
    "text": "highly uh the efficiency and the",
    "start": "389039",
    "end": "391120"
  },
  {
    "text": "throughput and also scheduling latency",
    "start": "391120",
    "end": "393600"
  },
  {
    "text": "into consideration so uh in kamada we",
    "start": "393600",
    "end": "397840"
  },
  {
    "text": "basically have two major options one is",
    "start": "397840",
    "end": "400400"
  },
  {
    "text": "the uh resource model it's kind of uh uh",
    "start": "400400",
    "end": "404639"
  },
  {
    "text": "compress this cluster status in the",
    "start": "404639",
    "end": "406880"
  },
  {
    "text": "control plan and another one is the uh",
    "start": "406880",
    "end": "409680"
  },
  {
    "text": "resource uh the scheduleuler estimator",
    "start": "409680",
    "end": "413120"
  },
  {
    "text": "so the uh resource model actually we",
    "start": "413120",
    "end": "416720"
  },
  {
    "text": "kind of use grades to uh quantify the uh",
    "start": "416720",
    "end": "421720"
  },
  {
    "text": "cluster basically uh node status into uh",
    "start": "421720",
    "end": "426240"
  },
  {
    "text": "uh uh some of the groups and you can as",
    "start": "426240",
    "end": "428560"
  },
  {
    "text": "you can see on the right there it's an",
    "start": "428560",
    "end": "431080"
  },
  {
    "text": "example and also um and also uh this is",
    "start": "431080",
    "end": "437039"
  },
  {
    "text": "actually better you know uh uh for the",
    "start": "437039",
    "end": "441520"
  },
  {
    "text": "like ap uh CPU or memory",
    "start": "441520",
    "end": "444520"
  },
  {
    "text": "incentive workloads like big data and",
    "start": "444520",
    "end": "447680"
  },
  {
    "text": "also it has more uh kind of uh better",
    "start": "447680",
    "end": "451599"
  },
  {
    "text": "throughput because the the scheduling",
    "start": "451599",
    "end": "454639"
  },
  {
    "text": "lat latency is better all the things you",
    "start": "454639",
    "end": "457039"
  },
  {
    "text": "need is",
    "start": "457039",
    "end": "459319"
  },
  {
    "text": "insideuler but you know actually the the",
    "start": "459319",
    "end": "462000"
  },
  {
    "text": "accuracy versus uh efficiency uh",
    "start": "462000",
    "end": "465280"
  },
  {
    "text": "trade-off varies depending on a lot of",
    "start": "465280",
    "end": "468240"
  },
  {
    "text": "uh different effects so um for the",
    "start": "468240",
    "end": "471919"
  },
  {
    "text": "estimator it's like actually estimator",
    "start": "471919",
    "end": "474879"
  },
  {
    "text": "is quite similar as the um inclusteruler",
    "start": "474879",
    "end": "478960"
  },
  {
    "text": "it just not make the final decision but",
    "start": "478960",
    "end": "482319"
  },
  {
    "text": "it will still go through all the uh",
    "start": "482319",
    "end": "485680"
  },
  {
    "text": "scheduling or algorithms that you",
    "start": "485680",
    "end": "488479"
  },
  {
    "text": "enabled in your cluster so it uh will",
    "start": "488479",
    "end": "492960"
  },
  {
    "text": "need to watch the member cluster to",
    "start": "492960",
    "end": "496160"
  },
  {
    "text": "collect all the uh the basically node",
    "start": "496160",
    "end": "499120"
  },
  {
    "text": "and the pod status uh in memory and when",
    "start": "499120",
    "end": "502960"
  },
  {
    "text": "the commander scheduleuler doing",
    "start": "502960",
    "end": "504400"
  },
  {
    "text": "scheduling uh we will trigger uh RPC",
    "start": "504400",
    "end": "508400"
  },
  {
    "text": "call to each of the uh uh estimator and",
    "start": "508400",
    "end": "514000"
  },
  {
    "text": "calculate the uh max available replicas",
    "start": "514000",
    "end": "518719"
  },
  {
    "text": "as you can see this would take uh longer",
    "start": "518719",
    "end": "522399"
  },
  {
    "text": "time uh when doing the scheduling",
    "start": "522399",
    "end": "524560"
  },
  {
    "text": "decision and also uh you know it's kind",
    "start": "524560",
    "end": "528160"
  },
  {
    "text": "of still um storing the whole uh cluster",
    "start": "528160",
    "end": "532120"
  },
  {
    "text": "status in the control plan so the",
    "start": "532120",
    "end": "535360"
  },
  {
    "text": "actually the footprint can be a little",
    "start": "535360",
    "end": "538320"
  },
  {
    "text": "bit more extensive",
    "start": "538320",
    "end": "540440"
  },
  {
    "text": "expensive however actually uh you know",
    "start": "540440",
    "end": "544160"
  },
  {
    "text": "when you are doing on the uh AI",
    "start": "544160",
    "end": "547120"
  },
  {
    "text": "workloads especially you know for both",
    "start": "547120",
    "end": "549839"
  },
  {
    "text": "uh training and also uh inference uh we",
    "start": "549839",
    "end": "553920"
  },
  {
    "text": "think that it's uh it's a it's a worth a",
    "start": "553920",
    "end": "557680"
  },
  {
    "text": "worthy uh tradeoff because we don't want",
    "start": "557680",
    "end": "561279"
  },
  {
    "text": "we don't really want waste any of the uh",
    "start": "561279",
    "end": "563920"
  },
  {
    "text": "GPU resources and also uh like today",
    "start": "563920",
    "end": "568160"
  },
  {
    "text": "more and more uh distributed training",
    "start": "568160",
    "end": "571279"
  },
  {
    "text": "distributed inference uh requirement",
    "start": "571279",
    "end": "574240"
  },
  {
    "text": "coming on uh coming out uh we need more",
    "start": "574240",
    "end": "578480"
  },
  {
    "text": "awareness of the uh incluster network",
    "start": "578480",
    "end": "582800"
  },
  {
    "text": "topology that's why we uh need the uh",
    "start": "582800",
    "end": "587440"
  },
  {
    "text": "estimator way for the uh multicluster",
    "start": "587440",
    "end": "591080"
  },
  {
    "text": "scheduling for AI workloads",
    "start": "591080",
    "end": "594839"
  },
  {
    "text": "yeah so uh the second part is about uh",
    "start": "594839",
    "end": "598080"
  },
  {
    "text": "the cluster failover for uh workloads",
    "start": "598080",
    "end": "601880"
  },
  {
    "text": "Uh actually uh in uh during the uh",
    "start": "601880",
    "end": "606320"
  },
  {
    "text": "production uh uh uh resourceful",
    "start": "606320",
    "end": "610080"
  },
  {
    "text": "management we found that it's actually",
    "start": "610080",
    "end": "613600"
  },
  {
    "text": "quite uh complicated you know to uh",
    "start": "613600",
    "end": "617519"
  },
  {
    "text": "really uh determine if there's any uh",
    "start": "617519",
    "end": "621279"
  },
  {
    "text": "cluster failure you know and uh in most",
    "start": "621279",
    "end": "623600"
  },
  {
    "text": "of the time the failure are just uh",
    "start": "623600",
    "end": "626720"
  },
  {
    "text": "partial cluster issues not uh critical",
    "start": "626720",
    "end": "630240"
  },
  {
    "text": "ical failures so uh people really don't",
    "start": "630240",
    "end": "632959"
  },
  {
    "text": "want to kind of drain the uh cluster or",
    "start": "632959",
    "end": "636720"
  },
  {
    "text": "evict most of the workloads right and",
    "start": "636720",
    "end": "639519"
  },
  {
    "text": "also uh we need to uh distinguish the",
    "start": "639519",
    "end": "644240"
  },
  {
    "text": "disconnection and the the actual failure",
    "start": "644240",
    "end": "647160"
  },
  {
    "text": "status and uh um typically we also think",
    "start": "647160",
    "end": "651600"
  },
  {
    "text": "that multicluster high availability uh",
    "start": "651600",
    "end": "655120"
  },
  {
    "text": "uh consideration may result in more",
    "start": "655120",
    "end": "657600"
  },
  {
    "text": "redundant uh resources we need to think",
    "start": "657600",
    "end": "660240"
  },
  {
    "text": "about how we uh really want to deal with",
    "start": "660240",
    "end": "663839"
  },
  {
    "text": "the cluster failover if you don't have",
    "start": "663839",
    "end": "666000"
  },
  {
    "text": "enough uh resource the",
    "start": "666000",
    "end": "669800"
  },
  {
    "text": "failover may you know uh amplify the uh",
    "start": "669800",
    "end": "674640"
  },
  {
    "text": "failure from one cluster to another that",
    "start": "674640",
    "end": "678160"
  },
  {
    "text": "will be kind of unacceptable",
    "start": "678160",
    "end": "681680"
  },
  {
    "text": "so um that's why we were thinking how we",
    "start": "681680",
    "end": "685120"
  },
  {
    "text": "can uh you know",
    "start": "685120",
    "end": "687560"
  },
  {
    "text": "uh revise the uh cluster failover",
    "start": "687560",
    "end": "691519"
  },
  {
    "text": "mechanism",
    "start": "691519",
    "end": "693040"
  },
  {
    "text": "uh to from uh tent based eviction to a",
    "start": "693040",
    "end": "697360"
  },
  {
    "text": "more flexible way to do it so that's our",
    "start": "697360",
    "end": "701600"
  },
  {
    "text": "kind of revised one so uh we uh think",
    "start": "701600",
    "end": "706720"
  },
  {
    "text": "that the cluster status may have",
    "start": "706720",
    "end": "709680"
  },
  {
    "text": "multiple resources uh we can just uh you",
    "start": "709680",
    "end": "713120"
  },
  {
    "text": "know",
    "start": "713120",
    "end": "714519"
  },
  {
    "text": "uh uh check the cluster lease uh that's",
    "start": "714519",
    "end": "718000"
  },
  {
    "text": "a quite an easy way to to uh check if",
    "start": "718000",
    "end": "721279"
  },
  {
    "text": "the cluster is online and we still need",
    "start": "721279",
    "end": "724240"
  },
  {
    "text": "to kind of uh extensible uh to have a",
    "start": "724240",
    "end": "727600"
  },
  {
    "text": "extensible way to let people implement",
    "start": "727600",
    "end": "731600"
  },
  {
    "text": "some uh you know well-known cluster",
    "start": "731600",
    "end": "734399"
  },
  {
    "text": "issues and make them to uh become uh",
    "start": "734399",
    "end": "738160"
  },
  {
    "text": "conditions on the cluster and also uh if",
    "start": "738160",
    "end": "741600"
  },
  {
    "text": "you have like infrastructure provider",
    "start": "741600",
    "end": "744240"
  },
  {
    "text": "you may want to uh have some of the out",
    "start": "744240",
    "end": "747360"
  },
  {
    "text": "of tree mechanism to core some uh to",
    "start": "747360",
    "end": "750000"
  },
  {
    "text": "call some API to uh help uh really found",
    "start": "750000",
    "end": "754399"
  },
  {
    "text": "the the the problem and uh for the tent",
    "start": "754399",
    "end": "759760"
  },
  {
    "text": "for the tent uh before we already have",
    "start": "759760",
    "end": "763600"
  },
  {
    "text": "uh like the no schedule tent and the no",
    "start": "763600",
    "end": "766160"
  },
  {
    "text": "execute tent at the at the uh uh",
    "start": "766160",
    "end": "770000"
  },
  {
    "text": "federated layer but the thing is that",
    "start": "770000",
    "end": "774399"
  },
  {
    "text": "actually the new no execute tent is",
    "start": "774399",
    "end": "777200"
  },
  {
    "text": "quite dangerous because once you add any",
    "start": "777200",
    "end": "781120"
  },
  {
    "text": "no excute tent without a predefined",
    "start": "781120",
    "end": "785600"
  },
  {
    "text": "toleration on your workloads it can",
    "start": "785600",
    "end": "788240"
  },
  {
    "text": "cause all them all of them being evicted",
    "start": "788240",
    "end": "791440"
  },
  {
    "text": "so that's why we are thinking uh can we",
    "start": "791440",
    "end": "795440"
  },
  {
    "text": "add a a little bit more you know uh",
    "start": "795440",
    "end": "800600"
  },
  {
    "text": "um uh type of uh uh a type of tent that",
    "start": "800600",
    "end": "805360"
  },
  {
    "text": "is in the middle that we don't want",
    "start": "805360",
    "end": "808240"
  },
  {
    "text": "really evict most of the applications",
    "start": "808240",
    "end": "811360"
  },
  {
    "text": "but just a few of them so uh with that",
    "start": "811360",
    "end": "815040"
  },
  {
    "text": "we actually added uh the uh preferred",
    "start": "815040",
    "end": "817839"
  },
  {
    "text": "the no execute the uh the interesting",
    "start": "817839",
    "end": "821360"
  },
  {
    "text": "thing is that this tent don't actually",
    "start": "821360",
    "end": "825200"
  },
  {
    "text": "cause any of the eviction because you",
    "start": "825200",
    "end": "828240"
  },
  {
    "text": "can uh it doesn't require any toleration",
    "start": "828240",
    "end": "832320"
  },
  {
    "text": "to uh let the workload stay on the uh",
    "start": "832320",
    "end": "836440"
  },
  {
    "text": "cluster so then how we can you know",
    "start": "836440",
    "end": "839839"
  },
  {
    "text": "trigger the uh some of the workload that",
    "start": "839839",
    "end": "843920"
  },
  {
    "text": "uh don't want stay when the uh part uh",
    "start": "843920",
    "end": "847120"
  },
  {
    "text": "partial cluster issues uh appeared uh so",
    "start": "847120",
    "end": "850880"
  },
  {
    "text": "we are using the uh failover failed in",
    "start": "850880",
    "end": "855199"
  },
  {
    "text": "the uh propagation policy to define that",
    "start": "855199",
    "end": "858240"
  },
  {
    "text": "uh with that uh when the uh preferred no",
    "start": "858240",
    "end": "861760"
  },
  {
    "text": "excute uh tent uh appeared on the",
    "start": "861760",
    "end": "864880"
  },
  {
    "text": "cluster um the eviction manager will uh",
    "start": "864880",
    "end": "869519"
  },
  {
    "text": "uh trigger the eviction process and for",
    "start": "869519",
    "end": "873040"
  },
  {
    "text": "the both no execute and the no preferred",
    "start": "873040",
    "end": "877519"
  },
  {
    "text": "no execute tent triggered eviction we",
    "start": "877519",
    "end": "880800"
  },
  {
    "text": "will uh basically incure the uh uh the",
    "start": "880800",
    "end": "885360"
  },
  {
    "text": "resource binding to the eviction queue",
    "start": "885360",
    "end": "888079"
  },
  {
    "text": "and we know that uh it's very important",
    "start": "888079",
    "end": "892079"
  },
  {
    "text": "you know uh to make sure the eviction of",
    "start": "892079",
    "end": "896000"
  },
  {
    "text": "the workload may result in a workload",
    "start": "896000",
    "end": "898959"
  },
  {
    "text": "running in another healthy place so uh",
    "start": "898959",
    "end": "903120"
  },
  {
    "text": "in the uh new design of the eviction",
    "start": "903120",
    "end": "906000"
  },
  {
    "text": "queue we are thinking that we can",
    "start": "906000",
    "end": "908320"
  },
  {
    "text": "actually uh import the uh algorithms of",
    "start": "908320",
    "end": "912480"
  },
  {
    "text": "the commander scheduler to do a uh",
    "start": "912480",
    "end": "916040"
  },
  {
    "text": "pre-scheduling to check if it's",
    "start": "916040",
    "end": "919880"
  },
  {
    "text": "uh uh possible to get the workload",
    "start": "919880",
    "end": "923279"
  },
  {
    "text": "running otherwise we will just give the",
    "start": "923279",
    "end": "925279"
  },
  {
    "text": "ev give up the eviction and also uh uh",
    "start": "925279",
    "end": "928800"
  },
  {
    "text": "in the uh kamada uh eviction management",
    "start": "928800",
    "end": "931680"
  },
  {
    "text": "uh process we already have the graceful",
    "start": "931680",
    "end": "934560"
  },
  {
    "text": "uh eviction me mechanism so we just uh",
    "start": "934560",
    "end": "938240"
  },
  {
    "text": "uh uh reuse",
    "start": "938240",
    "end": "941519"
  },
  {
    "text": "that so uh as I said uh uh that's the",
    "start": "942600",
    "end": "947360"
  },
  {
    "text": "most part of the uh the",
    "start": "947360",
    "end": "950920"
  },
  {
    "text": "improvement for uh as I uh said the like",
    "start": "950920",
    "end": "954600"
  },
  {
    "text": "the the cluster status detection",
    "start": "954600",
    "end": "958720"
  },
  {
    "text": "uh we change we will change from uh you",
    "start": "958720",
    "end": "962399"
  },
  {
    "text": "know uh checking the whole clusters",
    "start": "962399",
    "end": "964639"
  },
  {
    "text": "instead of uh uh two uh the cluster",
    "start": "964639",
    "end": "968320"
  },
  {
    "text": "leaves to reduce the uh pressure to the",
    "start": "968320",
    "end": "971759"
  },
  {
    "text": "API server and also we will add the",
    "start": "971759",
    "end": "974880"
  },
  {
    "text": "cluster uh problem detector to uh uh",
    "start": "974880",
    "end": "979560"
  },
  {
    "text": "simplify you know the customization of",
    "start": "979560",
    "end": "982720"
  },
  {
    "text": "uh uh cluster status uh collection and",
    "start": "982720",
    "end": "986480"
  },
  {
    "text": "also we are currently working on uh",
    "start": "986480",
    "end": "989680"
  },
  {
    "text": "designing and explicit API for",
    "start": "989680",
    "end": "993000"
  },
  {
    "text": "customizing the policy how you want to",
    "start": "993000",
    "end": "996959"
  },
  {
    "text": "uh tent your cluster by uh certain set",
    "start": "996959",
    "end": "1001920"
  },
  {
    "text": "of conditions and also you can choose",
    "start": "1001920",
    "end": "1005440"
  },
  {
    "text": "the type of uh tent you want to add so",
    "start": "1005440",
    "end": "1009680"
  },
  {
    "text": "that gives more flexibility",
    "start": "1009680",
    "end": "1012399"
  },
  {
    "text": "uh for you to uh to you know kind of",
    "start": "1012399",
    "end": "1016240"
  },
  {
    "text": "really manage the eviction uh behavior",
    "start": "1016240",
    "end": "1019440"
  },
  {
    "text": "of your whole",
    "start": "1019440",
    "end": "1022240"
  },
  {
    "text": "system yeah and uh in the in a longer",
    "start": "1022360",
    "end": "1025678"
  },
  {
    "text": "future uh we would also take the",
    "start": "1025679",
    "end": "1028000"
  },
  {
    "text": "workload priority into consideration so",
    "start": "1028000",
    "end": "1031839"
  },
  {
    "text": "make sure even though you don't have",
    "start": "1031839",
    "end": "1034319"
  },
  {
    "text": "enough resource in the rest healthy",
    "start": "1034319",
    "end": "1037839"
  },
  {
    "text": "clusters you can still try",
    "start": "1037839",
    "end": "1041720"
  },
  {
    "text": "uh uh migrate the most high priority",
    "start": "1041720",
    "end": "1045839"
  },
  {
    "text": "workload to the healthy clusters so uh I",
    "start": "1045839",
    "end": "1048960"
  },
  {
    "text": "just provided link uh in the slides you",
    "start": "1048960",
    "end": "1052640"
  },
  {
    "text": "can uh check out later on",
    "start": "1052640",
    "end": "1057000"
  },
  {
    "text": "yeah so uh this is the actually the uh",
    "start": "1057840",
    "end": "1060960"
  },
  {
    "text": "new API for uh you know uh defining the",
    "start": "1060960",
    "end": "1065200"
  },
  {
    "text": "eviction behavior migration behavior uh",
    "start": "1065200",
    "end": "1068840"
  },
  {
    "text": "that reflects the preferred no uh",
    "start": "1068840",
    "end": "1072720"
  },
  {
    "text": "executed",
    "start": "1072720",
    "end": "1075280"
  },
  {
    "text": "tent yeah uh so third uh third uh",
    "start": "1075799",
    "end": "1079360"
  },
  {
    "text": "challenge I would like to discuss is",
    "start": "1079360",
    "end": "1081120"
  },
  {
    "text": "about queuing uh workloads and actually",
    "start": "1081120",
    "end": "1085200"
  },
  {
    "text": "uh we have met a lot of uh adopters they",
    "start": "1085200",
    "end": "1088880"
  },
  {
    "text": "are trying to use a uh multi-cluster",
    "start": "1088880",
    "end": "1092960"
  },
  {
    "text": "platform to manage their uh work",
    "start": "1092960",
    "end": "1095679"
  },
  {
    "text": "workloads like training and also like uh",
    "start": "1095679",
    "end": "1099360"
  },
  {
    "text": "uh computing jobs as well as uh this",
    "start": "1099360",
    "end": "1102400"
  },
  {
    "text": "year more and more uh inference",
    "start": "1102400",
    "end": "1104559"
  },
  {
    "text": "workloads are uh making plan to move to",
    "start": "1104559",
    "end": "1108080"
  },
  {
    "text": "this architecture but as we all know",
    "start": "1108080",
    "end": "1110960"
  },
  {
    "text": "that kind of uh the uh scheduleuler",
    "start": "1110960",
    "end": "1114320"
  },
  {
    "text": "framework have uh a lot of issues right",
    "start": "1114320",
    "end": "1118080"
  },
  {
    "text": "um so here are some of them uh basically",
    "start": "1118080",
    "end": "1123080"
  },
  {
    "text": "smaller jobs always get implicitly",
    "start": "1123080",
    "end": "1127039"
  },
  {
    "text": "higher priority because they are always",
    "start": "1127039",
    "end": "1129600"
  },
  {
    "text": "easier to get scheduled and the second",
    "start": "1129600",
    "end": "1133120"
  },
  {
    "text": "thing is that the more jobs you created",
    "start": "1133120",
    "end": "1136880"
  },
  {
    "text": "because the queue of the queue inside",
    "start": "1136880",
    "end": "1139200"
  },
  {
    "text": "the scheduleuler that would resulting",
    "start": "1139200",
    "end": "1142320"
  },
  {
    "text": "more resource you",
    "start": "1142320",
    "end": "1144360"
  },
  {
    "text": "consume uh and when there's more uh more",
    "start": "1144360",
    "end": "1147919"
  },
  {
    "text": "and more different type of resources",
    "start": "1147919",
    "end": "1150799"
  },
  {
    "text": "things get uh more even more uh",
    "start": "1150799",
    "end": "1153400"
  },
  {
    "text": "complicated uh in the talk uh just uh",
    "start": "1153400",
    "end": "1156720"
  },
  {
    "text": "before uh the last one actually uh the",
    "start": "1156720",
    "end": "1160799"
  },
  {
    "text": "speakers are already uh give an",
    "start": "1160799",
    "end": "1163360"
  },
  {
    "text": "introduction about the uh priority based",
    "start": "1163360",
    "end": "1166320"
  },
  {
    "text": "scheduling inside kamada uh that really",
    "start": "1166320",
    "end": "1169679"
  },
  {
    "text": "helps a lot but still not enough when",
    "start": "1169679",
    "end": "1172799"
  },
  {
    "text": "you are providing your uh platform to",
    "start": "1172799",
    "end": "1176559"
  },
  {
    "text": "multiple like business teams and uh uh",
    "start": "1176559",
    "end": "1180720"
  },
  {
    "text": "you would run into limited priority",
    "start": "1180720",
    "end": "1184080"
  },
  {
    "text": "class and for those workloads at the",
    "start": "1184080",
    "end": "1187440"
  },
  {
    "text": "same priority class they still met the",
    "start": "1187440",
    "end": "1189760"
  },
  {
    "text": "issues uh of the uh fairness",
    "start": "1189760",
    "end": "1193880"
  },
  {
    "text": "thing also another another uh big issue",
    "start": "1193880",
    "end": "1198559"
  },
  {
    "text": "is that uh we tended to consider serving",
    "start": "1198559",
    "end": "1202960"
  },
  {
    "text": "has higher priority than uh than the uh",
    "start": "1202960",
    "end": "1206880"
  },
  {
    "text": "training workloads but we don't really",
    "start": "1206880",
    "end": "1209679"
  },
  {
    "text": "want to uh preempt them because that",
    "start": "1209679",
    "end": "1212480"
  },
  {
    "text": "would result in waste of GPU uh from",
    "start": "1212480",
    "end": "1215840"
  },
  {
    "text": "time wise right and also um currently",
    "start": "1215840",
    "end": "1219760"
  },
  {
    "text": "commander scheduler already taking a lot",
    "start": "1219760",
    "end": "1222720"
  },
  {
    "text": "of uh resource",
    "start": "1222720",
    "end": "1224880"
  },
  {
    "text": "uh perspective uh conditions into",
    "start": "1224880",
    "end": "1227840"
  },
  {
    "text": "consideration when it's doing scheduling",
    "start": "1227840",
    "end": "1230960"
  },
  {
    "text": "but uh as we know that in the cluster we",
    "start": "1230960",
    "end": "1235120"
  },
  {
    "text": "are we are also trying uh like Q",
    "start": "1235120",
    "end": "1238240"
  },
  {
    "text": "management and also uh resource sharing",
    "start": "1238240",
    "end": "1241280"
  },
  {
    "text": "between cues how we can uh enable it in",
    "start": "1241280",
    "end": "1245120"
  },
  {
    "text": "the federated layer and make the two",
    "start": "1245120",
    "end": "1248280"
  },
  {
    "text": "level basically decision making align",
    "start": "1248280",
    "end": "1251280"
  },
  {
    "text": "with each other so that's uh the uh",
    "start": "1251280",
    "end": "1254960"
  },
  {
    "text": "things we want to uh improve and uh as",
    "start": "1254960",
    "end": "1259679"
  },
  {
    "text": "we can see that actually uh volcano",
    "start": "1259679",
    "end": "1262240"
  },
  {
    "text": "already implemented the queue concept",
    "start": "1262240",
    "end": "1265039"
  },
  {
    "text": "and also like the volcano job inside the",
    "start": "1265039",
    "end": "1269000"
  },
  {
    "text": "cluster and uh uh with the uh uh commada",
    "start": "1269000",
    "end": "1273600"
  },
  {
    "text": "design it's quite actually quite easy to",
    "start": "1273600",
    "end": "1276880"
  },
  {
    "text": "enable it in the uh federated control",
    "start": "1276880",
    "end": "1279440"
  },
  {
    "text": "plan because commada don't require ire",
    "start": "1279440",
    "end": "1282880"
  },
  {
    "text": "new APIs you can just create any uh any",
    "start": "1282880",
    "end": "1286880"
  },
  {
    "text": "uh",
    "start": "1286880",
    "end": "1287799"
  },
  {
    "text": "CRDs so the little bit different thing",
    "start": "1287799",
    "end": "1290720"
  },
  {
    "text": "is that actually when you create volcano",
    "start": "1290720",
    "end": "1293039"
  },
  {
    "text": "job uh you you also need to enable the",
    "start": "1293039",
    "end": "1296720"
  },
  {
    "text": "volcano global to make sure uh it will",
    "start": "1296720",
    "end": "1299440"
  },
  {
    "text": "be uh mapped into a queue at the",
    "start": "1299440",
    "end": "1303280"
  },
  {
    "text": "federated layer and also uh actually uh",
    "start": "1303280",
    "end": "1307520"
  },
  {
    "text": "when uh volcano uh global doing dealing",
    "start": "1307520",
    "end": "1311919"
  },
  {
    "text": "with the uh",
    "start": "1311919",
    "end": "1314120"
  },
  {
    "text": "the uh the order of the uh scheduling uh",
    "start": "1314120",
    "end": "1318400"
  },
  {
    "text": "the different workloads uh we just incue",
    "start": "1318400",
    "end": "1321840"
  },
  {
    "text": "the resource binding and also this is",
    "start": "1321840",
    "end": "1325120"
  },
  {
    "text": "actually relying on the uh scheduling",
    "start": "1325120",
    "end": "1328000"
  },
  {
    "text": "suspension feature uh just released in",
    "start": "1328000",
    "end": "1330960"
  },
  {
    "text": "the commander latest the version to uh",
    "start": "1330960",
    "end": "1334240"
  },
  {
    "text": "to make sure we get higher priority",
    "start": "1334240",
    "end": "1339520"
  },
  {
    "text": "uh jobs being scheduled by",
    "start": "1339520",
    "end": "1342919"
  },
  {
    "text": "Kamada and also uh in the uh graph you",
    "start": "1342919",
    "end": "1346480"
  },
  {
    "text": "can see the uh there's a example that we",
    "start": "1346480",
    "end": "1349360"
  },
  {
    "text": "can uh implement fair sharing between uh",
    "start": "1349360",
    "end": "1353799"
  },
  {
    "text": "cues so one of the little bit different",
    "start": "1353799",
    "end": "1357039"
  },
  {
    "text": "thing considering with the uh volcano",
    "start": "1357039",
    "end": "1360400"
  },
  {
    "text": "inside single cluster is that uh today",
    "start": "1360400",
    "end": "1364280"
  },
  {
    "text": "we don't uh schedule only part of the of",
    "start": "1364280",
    "end": "1369360"
  },
  {
    "text": "the job uh that's a kind of restriction",
    "start": "1369360",
    "end": "1373120"
  },
  {
    "text": "when we are implementing uh the",
    "start": "1373120",
    "end": "1375440"
  },
  {
    "text": "federated scheduling so you are not able",
    "start": "1375440",
    "end": "1378799"
  },
  {
    "text": "to uh achieve fair sharing among job",
    "start": "1378799",
    "end": "1382480"
  },
  {
    "text": "level between uh different workload",
    "start": "1382480",
    "end": "1387480"
  },
  {
    "text": "so this is a overview of the uh volcano",
    "start": "1388320",
    "end": "1392880"
  },
  {
    "text": "global and uh the first wish uh version",
    "start": "1392880",
    "end": "1396240"
  },
  {
    "text": "we implemented",
    "start": "1396240",
    "end": "1398240"
  },
  {
    "text": "uh just a very basic fair sharing and uh",
    "start": "1398240",
    "end": "1401520"
  },
  {
    "text": "in the future we plan to uh introduce",
    "start": "1401520",
    "end": "1404559"
  },
  {
    "text": "more algorithms and also uh we are",
    "start": "1404559",
    "end": "1408320"
  },
  {
    "text": "thinking about maybe we can uh implement",
    "start": "1408320",
    "end": "1411440"
  },
  {
    "text": "like hierarchical queue and also uh a",
    "start": "1411440",
    "end": "1414559"
  },
  {
    "text": "lot of advanced um queue management",
    "start": "1414559",
    "end": "1417520"
  },
  {
    "text": "features",
    "start": "1417520",
    "end": "1418559"
  },
  {
    "text": "and also uh set up alignment uh with the",
    "start": "1418559",
    "end": "1423320"
  },
  {
    "text": "capacity resource sharing uh between the",
    "start": "1423320",
    "end": "1427159"
  },
  {
    "text": "incluster volcano and the federated",
    "start": "1427159",
    "end": "1430559"
  },
  {
    "text": "layer uh cluster",
    "start": "1430559",
    "end": "1433640"
  },
  {
    "text": "volcano so that's all about my uh",
    "start": "1433640",
    "end": "1436720"
  },
  {
    "text": "sharing so just a very uh uh uh uh I",
    "start": "1436720",
    "end": "1441679"
  },
  {
    "text": "think still uh the whole work is very",
    "start": "1441679",
    "end": "1444080"
  },
  {
    "text": "initial and uh if you have any feedback",
    "start": "1444080",
    "end": "1447280"
  },
  {
    "text": "and questions welcome to join the",
    "start": "1447280",
    "end": "1449840"
  },
  {
    "text": "community and then also help us",
    "start": "1449840",
    "end": "1452159"
  },
  {
    "text": "prioritize our work thanks",
    "start": "1452159",
    "end": "1455250"
  },
  {
    "text": "[Applause]",
    "start": "1455250",
    "end": "1462159"
  },
  {
    "text": "so any questions welcome",
    "start": "1462159",
    "end": "1466520"
  },
  {
    "text": "All right uh if no questions uh let's",
    "start": "1474400",
    "end": "1477360"
  },
  {
    "text": "save the time for beers thank you",
    "start": "1477360",
    "end": "1482120"
  },
  {
    "text": "oh",
    "start": "1483279",
    "end": "1484440"
  },
  {
    "text": "yes microphone yes i have one question",
    "start": "1484440",
    "end": "1488679"
  },
  {
    "text": "um have you considered to use the",
    "start": "1488679",
    "end": "1492000"
  },
  {
    "text": "virtual cublet to simplify the",
    "start": "1492000",
    "end": "1495120"
  },
  {
    "text": "scheduling",
    "start": "1495120",
    "end": "1496640"
  },
  {
    "text": "uh assuming every node could be virtual",
    "start": "1496640",
    "end": "1499919"
  },
  {
    "text": "every cluster could be a virtual node",
    "start": "1499919",
    "end": "1502159"
  },
  {
    "text": "and even porting your new proposal for",
    "start": "1502159",
    "end": "1506080"
  },
  {
    "text": "the kind",
    "start": "1506080",
    "end": "1507720"
  },
  {
    "text": "um I don't remember the conditional uh",
    "start": "1507720",
    "end": "1512000"
  },
  {
    "text": "taint to the SCG nod for example because",
    "start": "1512000",
    "end": "1516320"
  },
  {
    "text": "I think on a nod today we can't have a n",
    "start": "1516320",
    "end": "1519600"
  },
  {
    "text": "on taint based on condition it's",
    "start": "1519600",
    "end": "1522400"
  },
  {
    "text": "outcoded on the cublet based on",
    "start": "1522400",
    "end": "1524960"
  },
  {
    "text": "pre-built conditions but this extension",
    "start": "1524960",
    "end": "1527760"
  },
  {
    "text": "can make sense also on a node and",
    "start": "1527760",
    "end": "1530080"
  },
  {
    "text": "considering every cluster has a virtual",
    "start": "1530080",
    "end": "1532640"
  },
  {
    "text": "node with a lot of resources a lot of",
    "start": "1532640",
    "end": "1535120"
  },
  {
    "text": "things also prevent also solve this",
    "start": "1535120",
    "end": "1537440"
  },
  {
    "text": "problem of cache what you were speaking",
    "start": "1537440",
    "end": "1539600"
  },
  {
    "text": "about because you have every precomputed",
    "start": "1539600",
    "end": "1542720"
  },
  {
    "text": "node on your master cluster and you see",
    "start": "1542720",
    "end": "1545600"
  },
  {
    "text": "them as static nodes mhm uh yeah uh uh",
    "start": "1545600",
    "end": "1550960"
  },
  {
    "text": "that that's a very good question so",
    "start": "1550960",
    "end": "1552880"
  },
  {
    "text": "actually in the early days when we are",
    "start": "1552880",
    "end": "1554960"
  },
  {
    "text": "designing the multicluster uh",
    "start": "1554960",
    "end": "1557200"
  },
  {
    "text": "architecture uh uh virtual node is one",
    "start": "1557200",
    "end": "1561200"
  },
  {
    "text": "of the option um uh that why we choose",
    "start": "1561200",
    "end": "1565200"
  },
  {
    "text": "the uh the federated way so basically",
    "start": "1565200",
    "end": "1568600"
  },
  {
    "text": "considering I mean",
    "start": "1568600",
    "end": "1571320"
  },
  {
    "text": "uh managing directly the uh clusters is",
    "start": "1571320",
    "end": "1575840"
  },
  {
    "text": "because that if you do go through the",
    "start": "1575840",
    "end": "1579279"
  },
  {
    "text": "virtual coat way you are kind of uh",
    "start": "1579279",
    "end": "1582799"
  },
  {
    "text": "scheduling pods a pod to a cluster you",
    "start": "1582799",
    "end": "1587360"
  },
  {
    "text": "still need to kind of resum the workload",
    "start": "1587360",
    "end": "1590080"
  },
  {
    "text": "information when it goes to the member",
    "start": "1590080",
    "end": "1593080"
  },
  {
    "text": "cluster API server right if I want to",
    "start": "1593080",
    "end": "1597559"
  },
  {
    "text": "schedule a safe set a deployment or even",
    "start": "1597559",
    "end": "1603200"
  },
  {
    "text": "a custom uh resource workload definition",
    "start": "1603200",
    "end": "1607600"
  },
  {
    "text": "the pod API is not that ideal for you",
    "start": "1607600",
    "end": "1611120"
  },
  {
    "text": "know uh carrying carrying uh the extra",
    "start": "1611120",
    "end": "1615919"
  },
  {
    "text": "information ah yeah because in fact only",
    "start": "1615919",
    "end": "1617840"
  },
  {
    "text": "the pod will move to the node but yeah I",
    "start": "1617840",
    "end": "1620559"
  },
  {
    "text": "see what you mean so the deployment and",
    "start": "1620559",
    "end": "1622320"
  },
  {
    "text": "set will remain in the master cluster",
    "start": "1622320",
    "end": "1624720"
  },
  {
    "text": "yeah and only the pod will move yeah",
    "start": "1624720",
    "end": "1626799"
  },
  {
    "text": "most of the fails are remain the same",
    "start": "1626799",
    "end": "1629679"
  },
  {
    "text": "yeah ah yeah yeah yeah okay yeah makes",
    "start": "1629679",
    "end": "1632679"
  },
  {
    "text": "sense thank you but the conditional",
    "start": "1632679",
    "end": "1635600"
  },
  {
    "text": "taint still makes sense in node no uh",
    "start": "1635600",
    "end": "1639440"
  },
  {
    "text": "node level right yeah yes yes okay thank",
    "start": "1639440",
    "end": "1642960"
  },
  {
    "text": "you yes",
    "start": "1642960",
    "end": "1645600"
  }
]
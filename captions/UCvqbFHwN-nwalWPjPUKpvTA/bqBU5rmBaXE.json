[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "all right awesome hi everyone nice to",
    "start": "240",
    "end": "2399"
  },
  {
    "text": "meet you all i hope you all had a good",
    "start": "2399",
    "end": "3919"
  },
  {
    "text": "lunch uh so today i'm going to be",
    "start": "3919",
    "end": "5920"
  },
  {
    "text": "telling you guys about ml x-ray and so",
    "start": "5920",
    "end": "8400"
  },
  {
    "text": "ml x-ray is essentially an end-to-end",
    "start": "8400",
    "end": "10559"
  },
  {
    "text": "debugging platform for your models that",
    "start": "10559",
    "end": "12880"
  },
  {
    "text": "are deployed on the edge",
    "start": "12880",
    "end": "15759"
  },
  {
    "start": "15000",
    "end": "41000"
  },
  {
    "text": "so just a little bit about myself i'm",
    "start": "15759",
    "end": "17440"
  },
  {
    "text": "michelle and i said before i'm a",
    "start": "17440",
    "end": "19199"
  },
  {
    "text": "principal engineer at new relic working",
    "start": "19199",
    "end": "21520"
  },
  {
    "text": "on the pixi open source project so that",
    "start": "21520",
    "end": "24400"
  },
  {
    "text": "project is essentially a cncf sandbox",
    "start": "24400",
    "end": "27039"
  },
  {
    "text": "project which is an observability",
    "start": "27039",
    "end": "28880"
  },
  {
    "text": "observability tool for kubernetes and",
    "start": "28880",
    "end": "32078"
  },
  {
    "text": "before my time at new relic i was",
    "start": "32079",
    "end": "34480"
  },
  {
    "text": "pixie labs's first engineer and pixie",
    "start": "34480",
    "end": "36640"
  },
  {
    "text": "labs is where the pixie project was born",
    "start": "36640",
    "end": "39200"
  },
  {
    "text": "out of",
    "start": "39200",
    "end": "41440"
  },
  {
    "start": "41000",
    "end": "118000"
  },
  {
    "text": "so",
    "start": "42879",
    "end": "43600"
  },
  {
    "text": "why should we even talk about debugging",
    "start": "43600",
    "end": "45360"
  },
  {
    "text": "deployments of machine learning on the",
    "start": "45360",
    "end": "47200"
  },
  {
    "text": "edge so we see today that a lot of",
    "start": "47200",
    "end": "49360"
  },
  {
    "text": "deployments or products and software are",
    "start": "49360",
    "end": "51440"
  },
  {
    "text": "moving their machine learning models to",
    "start": "51440",
    "end": "53039"
  },
  {
    "text": "the edge so for example we have crews",
    "start": "53039",
    "end": "55360"
  },
  {
    "text": "which is self-driving that's a very",
    "start": "55360",
    "end": "57199"
  },
  {
    "text": "popular hot topic these days so",
    "start": "57199",
    "end": "59359"
  },
  {
    "text": "essentially your car is going around it",
    "start": "59359",
    "end": "62160"
  },
  {
    "text": "is picking up a bunch of sensor",
    "start": "62160",
    "end": "63520"
  },
  {
    "text": "information so for example it's using a",
    "start": "63520",
    "end": "65198"
  },
  {
    "text": "camera to figure out you know am i",
    "start": "65199",
    "end": "67280"
  },
  {
    "text": "driving correctly in the lane it's using",
    "start": "67280",
    "end": "69439"
  },
  {
    "text": "lidar to find object detection and see",
    "start": "69439",
    "end": "71600"
  },
  {
    "text": "if there's an obstacle in the way so you",
    "start": "71600",
    "end": "72960"
  },
  {
    "text": "don't go and accidentally hit somebody",
    "start": "72960",
    "end": "74960"
  },
  {
    "text": "or we've had you know the amazon echo",
    "start": "74960",
    "end": "76880"
  },
  {
    "text": "around for a while and that listens to",
    "start": "76880",
    "end": "78880"
  },
  {
    "text": "you you know you're going out your day",
    "start": "78880",
    "end": "80720"
  },
  {
    "text": "just talking normally and it listens and",
    "start": "80720",
    "end": "82400"
  },
  {
    "text": "picks up some cues whenever you say",
    "start": "82400",
    "end": "84560"
  },
  {
    "text": "alexa and so",
    "start": "84560",
    "end": "86479"
  },
  {
    "text": "all that is done on the edge it's",
    "start": "86479",
    "end": "88320"
  },
  {
    "text": "picking up sensor information and then",
    "start": "88320",
    "end": "90799"
  },
  {
    "text": "it is",
    "start": "90799",
    "end": "91680"
  },
  {
    "text": "basically running a model and figuring",
    "start": "91680",
    "end": "93520"
  },
  {
    "text": "out you know some inference and what",
    "start": "93520",
    "end": "95280"
  },
  {
    "text": "action to take based on the information",
    "start": "95280",
    "end": "96960"
  },
  {
    "text": "it's gathered and then another example",
    "start": "96960",
    "end": "98960"
  },
  {
    "text": "is just you know you want to deploy your",
    "start": "98960",
    "end": "100240"
  },
  {
    "text": "applications onto different phones right",
    "start": "100240",
    "end": "102640"
  },
  {
    "text": "so essentially on these phones you're",
    "start": "102640",
    "end": "104320"
  },
  {
    "text": "running machine learning models to do",
    "start": "104320",
    "end": "105759"
  },
  {
    "text": "different things such as image",
    "start": "105759",
    "end": "107119"
  },
  {
    "text": "classification for example or for the",
    "start": "107119",
    "end": "109520"
  },
  {
    "text": "case of like the pixel 6 one of the",
    "start": "109520",
    "end": "111040"
  },
  {
    "text": "recent things they came out with is you",
    "start": "111040",
    "end": "113520"
  },
  {
    "text": "can do like a magic eraser all these",
    "start": "113520",
    "end": "115920"
  },
  {
    "text": "models are running inside your phone",
    "start": "115920",
    "end": "117280"
  },
  {
    "text": "itself",
    "start": "117280",
    "end": "119040"
  },
  {
    "start": "118000",
    "end": "184000"
  },
  {
    "text": "and to kind of expand on that we have",
    "start": "119040",
    "end": "120880"
  },
  {
    "text": "this idea of the traditional model which",
    "start": "120880",
    "end": "122960"
  },
  {
    "text": "is on your left",
    "start": "122960",
    "end": "124880"
  },
  {
    "text": "and so here in this case",
    "start": "124880",
    "end": "127040"
  },
  {
    "text": "the sensor is on a separate device it is",
    "start": "127040",
    "end": "129759"
  },
  {
    "text": "picking up a ton of input data so let's",
    "start": "129759",
    "end": "131840"
  },
  {
    "text": "say for a nest thermostat right it's",
    "start": "131840",
    "end": "134400"
  },
  {
    "text": "going it's figuring out you know what is",
    "start": "134400",
    "end": "135760"
  },
  {
    "text": "the temperature at this time in this",
    "start": "135760",
    "end": "137040"
  },
  {
    "text": "house and it might want to do something",
    "start": "137040",
    "end": "138959"
  },
  {
    "text": "with that data and figure out okay what",
    "start": "138959",
    "end": "140959"
  },
  {
    "text": "should i do with this and run some",
    "start": "140959",
    "end": "142480"
  },
  {
    "text": "inferences on it and it will send it to",
    "start": "142480",
    "end": "144480"
  },
  {
    "text": "the cloud where the model is running the",
    "start": "144480",
    "end": "146560"
  },
  {
    "text": "model will basically go do some",
    "start": "146560",
    "end": "148560"
  },
  {
    "text": "inference and then return a result and",
    "start": "148560",
    "end": "150720"
  },
  {
    "text": "so then when you move your computation",
    "start": "150720",
    "end": "152640"
  },
  {
    "text": "to the edge which what actually happens",
    "start": "152640",
    "end": "154720"
  },
  {
    "text": "is you now have these models running",
    "start": "154720",
    "end": "156480"
  },
  {
    "text": "directly on the devices so for example",
    "start": "156480",
    "end": "159120"
  },
  {
    "text": "of the amazon echo from before you're",
    "start": "159120",
    "end": "161760"
  },
  {
    "text": "having the model run directly on the um",
    "start": "161760",
    "end": "165440"
  },
  {
    "text": "echo itself rather than going and",
    "start": "165440",
    "end": "167680"
  },
  {
    "text": "running the model on the cloud and so",
    "start": "167680",
    "end": "171120"
  },
  {
    "text": "here what actually happens is that now",
    "start": "171120",
    "end": "173760"
  },
  {
    "text": "you have a bunch of different",
    "start": "173760",
    "end": "174720"
  },
  {
    "text": "environments right you can deploy to",
    "start": "174720",
    "end": "175920"
  },
  {
    "text": "many different edge devices that are",
    "start": "175920",
    "end": "177360"
  },
  {
    "text": "built on different hardware",
    "start": "177360",
    "end": "179280"
  },
  {
    "text": "they have different memory compute",
    "start": "179280",
    "end": "180879"
  },
  {
    "text": "resource requirements and whatnot",
    "start": "180879",
    "end": "185040"
  },
  {
    "start": "184000",
    "end": "275000"
  },
  {
    "text": "and so what are the benefits of doing",
    "start": "185040",
    "end": "186319"
  },
  {
    "text": "this actually so you can see here from",
    "start": "186319",
    "end": "188159"
  },
  {
    "text": "this picture",
    "start": "188159",
    "end": "189280"
  },
  {
    "text": "you are no longer egressing any data out",
    "start": "189280",
    "end": "191760"
  },
  {
    "text": "to the cloud so before you know you have",
    "start": "191760",
    "end": "193519"
  },
  {
    "text": "a constant stream of data coming in and",
    "start": "193519",
    "end": "195599"
  },
  {
    "text": "then you're sending out to be like okay",
    "start": "195599",
    "end": "196879"
  },
  {
    "text": "what should i do with this information",
    "start": "196879",
    "end": "198560"
  },
  {
    "text": "what is the inference that i want to",
    "start": "198560",
    "end": "199760"
  },
  {
    "text": "make but when you move it to edge",
    "start": "199760",
    "end": "202080"
  },
  {
    "text": "compute all the information stays within",
    "start": "202080",
    "end": "204239"
  },
  {
    "text": "the device itself and a lot of the times",
    "start": "204239",
    "end": "206400"
  },
  {
    "text": "this is just stored in memory",
    "start": "206400",
    "end": "208319"
  },
  {
    "text": "and so that helps a lot because now you",
    "start": "208319",
    "end": "210000"
  },
  {
    "text": "know you're not sending something out",
    "start": "210000",
    "end": "211440"
  },
  {
    "text": "you're not waiting for the latency of",
    "start": "211440",
    "end": "212799"
  },
  {
    "text": "that network request coming out to come",
    "start": "212799",
    "end": "214720"
  },
  {
    "text": "back and tell you okay this is what i",
    "start": "214720",
    "end": "216080"
  },
  {
    "text": "should do",
    "start": "216080",
    "end": "217040"
  },
  {
    "text": "and that helps a lot with latency and",
    "start": "217040",
    "end": "218720"
  },
  {
    "text": "overall just egress and then you also",
    "start": "218720",
    "end": "220799"
  },
  {
    "text": "have security and privacy benefits so",
    "start": "220799",
    "end": "222879"
  },
  {
    "text": "now it's like you're not sending your",
    "start": "222879",
    "end": "223920"
  },
  {
    "text": "data out to somewhere else right going",
    "start": "223920",
    "end": "225440"
  },
  {
    "text": "back to the amazon echo case it's like",
    "start": "225440",
    "end": "227360"
  },
  {
    "text": "you're talking constantly in your house",
    "start": "227360",
    "end": "230239"
  },
  {
    "text": "and you don't really want all that",
    "start": "230239",
    "end": "232319"
  },
  {
    "text": "information like whatever you're saying",
    "start": "232319",
    "end": "233760"
  },
  {
    "text": "is to be sent to some remote cloud",
    "start": "233760",
    "end": "235360"
  },
  {
    "text": "that's managed by someone else rather",
    "start": "235360",
    "end": "237599"
  },
  {
    "text": "you feel more comfortable where it's you",
    "start": "237599",
    "end": "239200"
  },
  {
    "text": "know this device is in your home and",
    "start": "239200",
    "end": "241200"
  },
  {
    "text": "it's kind of all stored in memory and",
    "start": "241200",
    "end": "242799"
  },
  {
    "text": "then probably at some point eventually",
    "start": "242799",
    "end": "244640"
  },
  {
    "text": "expired out because it no longer needs",
    "start": "244640",
    "end": "246879"
  },
  {
    "text": "that information to make an inference",
    "start": "246879",
    "end": "248799"
  },
  {
    "text": "and so there's a lot of security and",
    "start": "248799",
    "end": "250159"
  },
  {
    "text": "privacy benefits for moving to the edge",
    "start": "250159",
    "end": "252959"
  },
  {
    "text": "and then lastly you have scalability",
    "start": "252959",
    "end": "254640"
  },
  {
    "text": "right so let's say you have millions of",
    "start": "254640",
    "end": "256880"
  },
  {
    "text": "connected devices in the traditional",
    "start": "256880",
    "end": "258799"
  },
  {
    "text": "model you send all those all that data",
    "start": "258799",
    "end": "261680"
  },
  {
    "text": "to your cloud and here in this case",
    "start": "261680",
    "end": "263600"
  },
  {
    "text": "you're actually handling it per device",
    "start": "263600",
    "end": "265280"
  },
  {
    "text": "so even if you have millions of devices",
    "start": "265280",
    "end": "267040"
  },
  {
    "text": "whatever you're doing in your cloud it's",
    "start": "267040",
    "end": "268320"
  },
  {
    "text": "not impacted by you know all these",
    "start": "268320",
    "end": "270080"
  },
  {
    "text": "inferences that need to be made on these",
    "start": "270080",
    "end": "272080"
  },
  {
    "text": "individual devices",
    "start": "272080",
    "end": "275120"
  },
  {
    "start": "275000",
    "end": "319000"
  },
  {
    "text": "and so how how do you actually go and",
    "start": "276400",
    "end": "278160"
  },
  {
    "text": "start deploying these models to your",
    "start": "278160",
    "end": "280240"
  },
  {
    "text": "edge devices",
    "start": "280240",
    "end": "281600"
  },
  {
    "text": "so how it usually happens is you're",
    "start": "281600",
    "end": "283199"
  },
  {
    "text": "going to train it on your cloud as you",
    "start": "283199",
    "end": "284800"
  },
  {
    "text": "normally would with just you know the",
    "start": "284800",
    "end": "286160"
  },
  {
    "text": "traditional model you go and you tune",
    "start": "286160",
    "end": "288479"
  },
  {
    "text": "all those parameters you run your",
    "start": "288479",
    "end": "290479"
  },
  {
    "text": "training data sets and then you know",
    "start": "290479",
    "end": "292639"
  },
  {
    "text": "your models looks great you're you know",
    "start": "292639",
    "end": "295600"
  },
  {
    "text": "able to accurately detect dogs from the",
    "start": "295600",
    "end": "297600"
  },
  {
    "text": "example earlier today and then you go",
    "start": "297600",
    "end": "299600"
  },
  {
    "text": "and deploy these models to your edge",
    "start": "299600",
    "end": "301360"
  },
  {
    "text": "devices and so in this image here i kind",
    "start": "301360",
    "end": "304160"
  },
  {
    "text": "of label these boxes as different colors",
    "start": "304160",
    "end": "306320"
  },
  {
    "text": "because i want to make it very clear",
    "start": "306320",
    "end": "308080"
  },
  {
    "text": "that these may not be the same",
    "start": "308080",
    "end": "309680"
  },
  {
    "text": "architecture they may not have the same",
    "start": "309680",
    "end": "311039"
  },
  {
    "text": "environment they may have completely",
    "start": "311039",
    "end": "312479"
  },
  {
    "text": "different hardware",
    "start": "312479",
    "end": "313759"
  },
  {
    "text": "and so you're just deploying these",
    "start": "313759",
    "end": "314880"
  },
  {
    "text": "models to these heterogeneous",
    "start": "314880",
    "end": "316160"
  },
  {
    "text": "environments and",
    "start": "316160",
    "end": "318080"
  },
  {
    "text": "what can go wrong right",
    "start": "318080",
    "end": "320320"
  },
  {
    "start": "319000",
    "end": "374000"
  },
  {
    "text": "so here's an example of what could go",
    "start": "320320",
    "end": "321840"
  },
  {
    "text": "wrong on the top you have this case",
    "start": "321840",
    "end": "324000"
  },
  {
    "text": "where it's like okay well one second is",
    "start": "324000",
    "end": "326000"
  },
  {
    "text": "kind of slow but you're running your",
    "start": "326000",
    "end": "327600"
  },
  {
    "text": "model on your edge device",
    "start": "327600",
    "end": "329759"
  },
  {
    "text": "and accuracy is just not right so before",
    "start": "329759",
    "end": "332479"
  },
  {
    "text": "when you're training this thing on um",
    "start": "332479",
    "end": "334720"
  },
  {
    "text": "the cloud and running inferences i was",
    "start": "334720",
    "end": "336320"
  },
  {
    "text": "like able to classify this dot correctly",
    "start": "336320",
    "end": "338880"
  },
  {
    "text": "but then now you've deployed it to your",
    "start": "338880",
    "end": "340800"
  },
  {
    "text": "iphone for example and now it's starting",
    "start": "340800",
    "end": "342880"
  },
  {
    "text": "to have some problems or in the other",
    "start": "342880",
    "end": "344960"
  },
  {
    "text": "case which is the bottom one you go and",
    "start": "344960",
    "end": "346800"
  },
  {
    "text": "you deploy you deploy to your android",
    "start": "346800",
    "end": "348639"
  },
  {
    "text": "and oh man this model that ran really",
    "start": "348639",
    "end": "350880"
  },
  {
    "text": "quickly when you're training it in the",
    "start": "350880",
    "end": "352160"
  },
  {
    "text": "cloud it takes 10 seconds and you have",
    "start": "352160",
    "end": "354160"
  },
  {
    "text": "no idea what's going on so you're",
    "start": "354160",
    "end": "356160"
  },
  {
    "text": "running into all these issues and it",
    "start": "356160",
    "end": "357919"
  },
  {
    "text": "wasn't the case when you're running on",
    "start": "357919",
    "end": "359120"
  },
  {
    "text": "your like you know your single cloud",
    "start": "359120",
    "end": "360639"
  },
  {
    "text": "environment so how do you actually go",
    "start": "360639",
    "end": "362319"
  },
  {
    "text": "and debug these things right you have a",
    "start": "362319",
    "end": "364400"
  },
  {
    "text": "bunch of different environments right",
    "start": "364400",
    "end": "365440"
  },
  {
    "text": "you have an android you have iphone or",
    "start": "365440",
    "end": "367520"
  },
  {
    "text": "in some cases you have like a sensor",
    "start": "367520",
    "end": "369039"
  },
  {
    "text": "running on this and a sensor running on",
    "start": "369039",
    "end": "370720"
  },
  {
    "text": "some other device how do you even go and",
    "start": "370720",
    "end": "372880"
  },
  {
    "text": "figure this out",
    "start": "372880",
    "end": "375280"
  },
  {
    "start": "374000",
    "end": "403000"
  },
  {
    "text": "and that is where mlx rate comes in so",
    "start": "375280",
    "end": "378080"
  },
  {
    "text": "mlxray is this project that came out of",
    "start": "378080",
    "end": "380080"
  },
  {
    "text": "a stanford research group",
    "start": "380080",
    "end": "382720"
  },
  {
    "text": "so tons of credit go to all those",
    "start": "382720",
    "end": "384400"
  },
  {
    "text": "wonderful people on the bottom for just",
    "start": "384400",
    "end": "386000"
  },
  {
    "text": "kind of going and figuring out all this",
    "start": "386000",
    "end": "387840"
  },
  {
    "text": "information but essentially they've",
    "start": "387840",
    "end": "389520"
  },
  {
    "text": "built out this framework",
    "start": "389520",
    "end": "391199"
  },
  {
    "text": "for providing visibility into what is",
    "start": "391199",
    "end": "393199"
  },
  {
    "text": "happening on your edge deployments and",
    "start": "393199",
    "end": "395360"
  },
  {
    "text": "you can use those to figure out you know",
    "start": "395360",
    "end": "396639"
  },
  {
    "text": "what exactly is going wrong with my",
    "start": "396639",
    "end": "397919"
  },
  {
    "text": "model that you know usually works well",
    "start": "397919",
    "end": "399919"
  },
  {
    "text": "in the other cases that i've deployed it",
    "start": "399919",
    "end": "403520"
  },
  {
    "start": "403000",
    "end": "438000"
  },
  {
    "text": "and",
    "start": "403840",
    "end": "404800"
  },
  {
    "text": "ml x-ray",
    "start": "404800",
    "end": "406080"
  },
  {
    "text": "essentially what they do is they give",
    "start": "406080",
    "end": "407520"
  },
  {
    "text": "you an api that you can use to",
    "start": "407520",
    "end": "409360"
  },
  {
    "text": "instrument your models so at the top you",
    "start": "409360",
    "end": "411840"
  },
  {
    "text": "see an example of the python api",
    "start": "411840",
    "end": "414479"
  },
  {
    "text": "and all you really need to do is say my",
    "start": "414479",
    "end": "417039"
  },
  {
    "text": "mlx ray library let's start",
    "start": "417039",
    "end": "419280"
  },
  {
    "text": "on inference start you run your",
    "start": "419280",
    "end": "421520"
  },
  {
    "text": "interpreter",
    "start": "421520",
    "end": "422639"
  },
  {
    "text": "and then on inference stop you stop and",
    "start": "422639",
    "end": "424960"
  },
  {
    "text": "so this api once you've invoked that it",
    "start": "424960",
    "end": "427440"
  },
  {
    "text": "starts collecting for each layer in your",
    "start": "427440",
    "end": "429680"
  },
  {
    "text": "model a bunch of interesting information",
    "start": "429680",
    "end": "431919"
  },
  {
    "text": "that is going to be used to help you",
    "start": "431919",
    "end": "433199"
  },
  {
    "text": "debug what is going wrong in your system",
    "start": "433199",
    "end": "437840"
  },
  {
    "text": "and so some of the information that it",
    "start": "438639",
    "end": "440240"
  },
  {
    "text": "collects is you know the original input",
    "start": "440240",
    "end": "442560"
  },
  {
    "text": "of the model the output of the model you",
    "start": "442560",
    "end": "444400"
  },
  {
    "text": "know is the result correct and also per",
    "start": "444400",
    "end": "446960"
  },
  {
    "text": "layer the input output",
    "start": "446960",
    "end": "448720"
  },
  {
    "text": "the end to end latency so you actually",
    "start": "448720",
    "end": "450319"
  },
  {
    "text": "know how long did this whole inference",
    "start": "450319",
    "end": "451840"
  },
  {
    "text": "take and also within the layers",
    "start": "451840",
    "end": "453759"
  },
  {
    "text": "themselves how long did those individual",
    "start": "453759",
    "end": "455360"
  },
  {
    "text": "layers take things like memory i think",
    "start": "455360",
    "end": "457680"
  },
  {
    "text": "especially as you're moving to an edge",
    "start": "457680",
    "end": "459440"
  },
  {
    "text": "device and these have lower like memory",
    "start": "459440",
    "end": "462080"
  },
  {
    "text": "and compute resources that is something",
    "start": "462080",
    "end": "464720"
  },
  {
    "text": "you might want to hone on to and then",
    "start": "464720",
    "end": "466879"
  },
  {
    "text": "for in the case of the android example",
    "start": "466879",
    "end": "469039"
  },
  {
    "text": "they have in their android api it also",
    "start": "469039",
    "end": "470960"
  },
  {
    "text": "collects other information such as",
    "start": "470960",
    "end": "472639"
  },
  {
    "text": "peripheral sensor information just like",
    "start": "472639",
    "end": "474479"
  },
  {
    "text": "the orientation of the phone the",
    "start": "474479",
    "end": "476000"
  },
  {
    "text": "lighting that is detected in the room",
    "start": "476000",
    "end": "477840"
  },
  {
    "text": "and that just helps you provide more",
    "start": "477840",
    "end": "479120"
  },
  {
    "text": "context to the model that is being run",
    "start": "479120",
    "end": "482240"
  },
  {
    "text": "you can also go ahead and add your own",
    "start": "482240",
    "end": "485039"
  },
  {
    "text": "just like whatever you want to log in",
    "start": "485039",
    "end": "487199"
  },
  {
    "text": "the ml x-ray logs you can there's the",
    "start": "487199",
    "end": "488879"
  },
  {
    "text": "api allows you to go ahead and do that",
    "start": "488879",
    "end": "490879"
  },
  {
    "text": "if there are custom fields that you",
    "start": "490879",
    "end": "492160"
  },
  {
    "text": "might want to go and pick up and it also",
    "start": "492160",
    "end": "494479"
  },
  {
    "text": "allows you to write custom assertions",
    "start": "494479",
    "end": "495919"
  },
  {
    "text": "which i'll talk about in a little bit",
    "start": "495919",
    "end": "499759"
  },
  {
    "start": "499000",
    "end": "564000"
  },
  {
    "text": "so now you have all this data coming in",
    "start": "500560",
    "end": "502080"
  },
  {
    "text": "right you've instrumented your your",
    "start": "502080",
    "end": "503919"
  },
  {
    "text": "model all this data is coming out as",
    "start": "503919",
    "end": "505759"
  },
  {
    "text": "you're running it but don't really know",
    "start": "505759",
    "end": "508000"
  },
  {
    "text": "what to do with this information it's",
    "start": "508000",
    "end": "509360"
  },
  {
    "text": "like okay cool this layer takes you know",
    "start": "509360",
    "end": "512240"
  },
  {
    "text": "this many milliseconds and this one",
    "start": "512240",
    "end": "514320"
  },
  {
    "text": "takes this many milliseconds how do i",
    "start": "514320",
    "end": "515760"
  },
  {
    "text": "actually use this information to figure",
    "start": "515760",
    "end": "517518"
  },
  {
    "text": "out what is going wrong with the model",
    "start": "517519",
    "end": "519680"
  },
  {
    "text": "that i've deployed on this edge device",
    "start": "519680",
    "end": "521919"
  },
  {
    "text": "and so the idea behind mlx ray is that",
    "start": "521919",
    "end": "524399"
  },
  {
    "text": "there's a set of reference pipelines and",
    "start": "524399",
    "end": "526160"
  },
  {
    "text": "these are usually you know the model",
    "start": "526160",
    "end": "528240"
  },
  {
    "text": "that you've deployed on the cloud you",
    "start": "528240",
    "end": "530000"
  },
  {
    "text": "know that this is accurate you know that",
    "start": "530000",
    "end": "531600"
  },
  {
    "text": "this is kind of like the baseline for",
    "start": "531600",
    "end": "533200"
  },
  {
    "text": "just how you want your model to perform",
    "start": "533200",
    "end": "535440"
  },
  {
    "text": "and what you do there is you run mll",
    "start": "535440",
    "end": "537360"
  },
  {
    "text": "x-ray on that reference pipeline",
    "start": "537360",
    "end": "539760"
  },
  {
    "text": "it gives you the logs you know it gives",
    "start": "539760",
    "end": "541600"
  },
  {
    "text": "you this is how long each layer took",
    "start": "541600",
    "end": "543440"
  },
  {
    "text": "this is the approximate output and input",
    "start": "543440",
    "end": "545360"
  },
  {
    "text": "of each layer and then you run this on",
    "start": "545360",
    "end": "547440"
  },
  {
    "text": "your development pipeline and that gives",
    "start": "547440",
    "end": "549600"
  },
  {
    "text": "you the same information and then you",
    "start": "549600",
    "end": "551440"
  },
  {
    "text": "basically do a diff between those to",
    "start": "551440",
    "end": "553200"
  },
  {
    "text": "create a debug report to help you figure",
    "start": "553200",
    "end": "555200"
  },
  {
    "text": "out okay this is what's going on with my",
    "start": "555200",
    "end": "557200"
  },
  {
    "text": "system this is what's different when",
    "start": "557200",
    "end": "558800"
  },
  {
    "text": "i've deployed to this environment versus",
    "start": "558800",
    "end": "561120"
  },
  {
    "text": "the other one",
    "start": "561120",
    "end": "563839"
  },
  {
    "text": "and the basic flow of this debug report",
    "start": "565839",
    "end": "568399"
  },
  {
    "text": "is this so first you do an accuracy",
    "start": "568399",
    "end": "570560"
  },
  {
    "text": "validation",
    "start": "570560",
    "end": "571760"
  },
  {
    "text": "you look at your accuracy for your",
    "start": "571760",
    "end": "574080"
  },
  {
    "text": "reference pipeline you look at it for",
    "start": "574080",
    "end": "575680"
  },
  {
    "text": "your development pipeline are they",
    "start": "575680",
    "end": "577680"
  },
  {
    "text": "matching up and if they match up then",
    "start": "577680",
    "end": "579440"
  },
  {
    "text": "that's that's pretty great right because",
    "start": "579440",
    "end": "581360"
  },
  {
    "text": "now you're basically performing about",
    "start": "581360",
    "end": "583600"
  },
  {
    "text": "how you might think when you've like",
    "start": "583600",
    "end": "585120"
  },
  {
    "text": "i've",
    "start": "585120",
    "end": "586000"
  },
  {
    "text": "trained this model on my cloud it looks",
    "start": "586000",
    "end": "588800"
  },
  {
    "text": "like my device is accurately doing what",
    "start": "588800",
    "end": "590640"
  },
  {
    "text": "i want it to do but in a lot of cases",
    "start": "590640",
    "end": "592720"
  },
  {
    "text": "like i mentioned before you're going to",
    "start": "592720",
    "end": "594160"
  },
  {
    "text": "realize that is not the case and the",
    "start": "594160",
    "end": "596080"
  },
  {
    "text": "accuracy goes down and so then the next",
    "start": "596080",
    "end": "598320"
  },
  {
    "text": "step of that is then you want to look",
    "start": "598320",
    "end": "599760"
  },
  {
    "text": "into each layer specifically so you're",
    "start": "599760",
    "end": "601839"
  },
  {
    "text": "looking at the output and you're saying",
    "start": "601839",
    "end": "603519"
  },
  {
    "text": "is there a layer where this output",
    "start": "603519",
    "end": "605680"
  },
  {
    "text": "accuracy just or the output is very very",
    "start": "605680",
    "end": "608240"
  },
  {
    "text": "different from the output that's",
    "start": "608240",
    "end": "609600"
  },
  {
    "text": "received from my reference pipeline and",
    "start": "609600",
    "end": "611839"
  },
  {
    "text": "you in the case where things are slow",
    "start": "611839",
    "end": "613279"
  },
  {
    "text": "then you want to compare latency it's",
    "start": "613279",
    "end": "614480"
  },
  {
    "text": "like well this layer took a lot longer",
    "start": "614480",
    "end": "617200"
  },
  {
    "text": "than the other layer",
    "start": "617200",
    "end": "619920"
  },
  {
    "text": "in my development pipeline",
    "start": "619920",
    "end": "622240"
  },
  {
    "text": "so you run through that and that helps",
    "start": "622240",
    "end": "624480"
  },
  {
    "text": "you hone about in on which layer is",
    "start": "624480",
    "end": "627040"
  },
  {
    "text": "having problems",
    "start": "627040",
    "end": "628560"
  },
  {
    "text": "and then finally like i mentioned before",
    "start": "628560",
    "end": "630160"
  },
  {
    "text": "there are some assertion checks so you",
    "start": "630160",
    "end": "632160"
  },
  {
    "text": "can specify these are custom assertions",
    "start": "632160",
    "end": "633920"
  },
  {
    "text": "in your code that check inputs and",
    "start": "633920",
    "end": "636640"
  },
  {
    "text": "outputs are what you expect so let's say",
    "start": "636640",
    "end": "638560"
  },
  {
    "text": "you have the self-driving",
    "start": "638560",
    "end": "640800"
  },
  {
    "text": "case that i mentioned before and you",
    "start": "640800",
    "end": "642640"
  },
  {
    "text": "know that when you're running your",
    "start": "642640",
    "end": "644240"
  },
  {
    "text": "camera",
    "start": "644240",
    "end": "645519"
  },
  {
    "text": "whenever you make an inference",
    "start": "645519",
    "end": "647600"
  },
  {
    "text": "all the uh",
    "start": "647600",
    "end": "650000"
  },
  {
    "text": "the width of the street should always be",
    "start": "650000",
    "end": "651360"
  },
  {
    "text": "the same and so then this assertion",
    "start": "651360",
    "end": "653440"
  },
  {
    "text": "check would be like check that you know",
    "start": "653440",
    "end": "654720"
  },
  {
    "text": "the width of the input of the model is",
    "start": "654720",
    "end": "658079"
  },
  {
    "text": "always five feet or something or check",
    "start": "658079",
    "end": "660640"
  },
  {
    "text": "that you know whatever is detected at",
    "start": "660640",
    "end": "661920"
  },
  {
    "text": "the end the width is five feet",
    "start": "661920",
    "end": "665440"
  },
  {
    "start": "665000",
    "end": "690000"
  },
  {
    "text": "and so what kind of issues can this",
    "start": "666800",
    "end": "668399"
  },
  {
    "text": "pipeline actually help you debug so",
    "start": "668399",
    "end": "670399"
  },
  {
    "text": "there are three that i'm going to step",
    "start": "670399",
    "end": "671519"
  },
  {
    "text": "into a little bit more detail for but",
    "start": "671519",
    "end": "673279"
  },
  {
    "text": "the first one is pre-processing errors",
    "start": "673279",
    "end": "675519"
  },
  {
    "text": "the next one is quantization",
    "start": "675519",
    "end": "676880"
  },
  {
    "text": "inaccuracies and then kernel",
    "start": "676880",
    "end": "679040"
  },
  {
    "text": "optimization differences amongst",
    "start": "679040",
    "end": "680880"
  },
  {
    "text": "heterogeneous environments so that's",
    "start": "680880",
    "end": "682399"
  },
  {
    "text": "kind of the case i mentioned before",
    "start": "682399",
    "end": "684079"
  },
  {
    "text": "where you have a bunch of different",
    "start": "684079",
    "end": "685120"
  },
  {
    "text": "hardware and just completely different",
    "start": "685120",
    "end": "687519"
  },
  {
    "text": "environments that your models are",
    "start": "687519",
    "end": "688800"
  },
  {
    "text": "running on",
    "start": "688800",
    "end": "691200"
  },
  {
    "start": "690000",
    "end": "763000"
  },
  {
    "text": "so the first is pre-processing errors",
    "start": "691200",
    "end": "692880"
  },
  {
    "text": "and i think even in a case where you're",
    "start": "692880",
    "end": "694240"
  },
  {
    "text": "not deploying to an edge device you're",
    "start": "694240",
    "end": "697120"
  },
  {
    "text": "going to run into this right you have",
    "start": "697120",
    "end": "698959"
  },
  {
    "text": "something collecting information",
    "start": "698959",
    "end": "700880"
  },
  {
    "text": "that's you're using to structure for",
    "start": "700880",
    "end": "702480"
  },
  {
    "text": "your input to your model and that's",
    "start": "702480",
    "end": "704000"
  },
  {
    "text": "going to be different from whatever that",
    "start": "704000",
    "end": "705920"
  },
  {
    "text": "model is expecting and this happens even",
    "start": "705920",
    "end": "708399"
  },
  {
    "text": "more in the edge device case because",
    "start": "708399",
    "end": "711120"
  },
  {
    "text": "since these are all running on different",
    "start": "711120",
    "end": "712320"
  },
  {
    "text": "environments and different hardware your",
    "start": "712320",
    "end": "714000"
  },
  {
    "text": "sensor might be picking up information",
    "start": "714000",
    "end": "715440"
  },
  {
    "text": "in different ways or you know in the",
    "start": "715440",
    "end": "717680"
  },
  {
    "text": "case where you have you know you're",
    "start": "717680",
    "end": "719680"
  },
  {
    "text": "taking pictures using a camera that that",
    "start": "719680",
    "end": "722880"
  },
  {
    "text": "could lead to the case where it's like",
    "start": "722880",
    "end": "724000"
  },
  {
    "text": "you might need to shrink your",
    "start": "724000",
    "end": "725519"
  },
  {
    "text": "information or shrink the picture so",
    "start": "725519",
    "end": "727600"
  },
  {
    "text": "that it runs well on your edge device",
    "start": "727600",
    "end": "729760"
  },
  {
    "text": "because it has lower memory requirements",
    "start": "729760",
    "end": "732000"
  },
  {
    "text": "and so there's cases like resizing that",
    "start": "732000",
    "end": "733920"
  },
  {
    "text": "i just mentioned where you might need to",
    "start": "733920",
    "end": "735600"
  },
  {
    "text": "be down scaling the image or in some",
    "start": "735600",
    "end": "737120"
  },
  {
    "text": "cases upscaling the image if the",
    "start": "737120",
    "end": "738800"
  },
  {
    "text": "camera's not picking up the right",
    "start": "738800",
    "end": "740480"
  },
  {
    "text": "resolution or",
    "start": "740480",
    "end": "742320"
  },
  {
    "text": "there's something wrong with the sensor",
    "start": "742320",
    "end": "743600"
  },
  {
    "text": "or just the information is coming in",
    "start": "743600",
    "end": "744880"
  },
  {
    "text": "differently and the",
    "start": "744880",
    "end": "746800"
  },
  {
    "text": "the information might be",
    "start": "746800",
    "end": "748399"
  },
  {
    "text": "rotated whenever you're feeding into the",
    "start": "748399",
    "end": "750000"
  },
  {
    "text": "model which can lead to a very low",
    "start": "750000",
    "end": "751920"
  },
  {
    "text": "accuracy or in some cases there's a lot",
    "start": "751920",
    "end": "754160"
  },
  {
    "text": "of models that might pick up your images",
    "start": "754160",
    "end": "756399"
  },
  {
    "text": "and expect it in rgb format or bgr",
    "start": "756399",
    "end": "759200"
  },
  {
    "text": "format and you don't really know which",
    "start": "759200",
    "end": "760880"
  },
  {
    "text": "it is",
    "start": "760880",
    "end": "763200"
  },
  {
    "start": "763000",
    "end": "832000"
  },
  {
    "text": "and so how does ml x-ray help in this",
    "start": "763839",
    "end": "766079"
  },
  {
    "text": "case so this goes back to the assertions",
    "start": "766079",
    "end": "767839"
  },
  {
    "text": "that i mentioned before but essentially",
    "start": "767839",
    "end": "769680"
  },
  {
    "text": "whenever mlxray is running on your",
    "start": "769680",
    "end": "772639"
  },
  {
    "text": "pipeline it's going to go and run these",
    "start": "772639",
    "end": "774399"
  },
  {
    "text": "assertions to make sure that it checks",
    "start": "774399",
    "end": "776959"
  },
  {
    "text": "and passes so here in this example this",
    "start": "776959",
    "end": "779279"
  },
  {
    "text": "is using the python api and this is",
    "start": "779279",
    "end": "781279"
  },
  {
    "text": "checking that",
    "start": "781279",
    "end": "783120"
  },
  {
    "text": "it expects your input to be in rgb",
    "start": "783120",
    "end": "786240"
  },
  {
    "text": "format so it's checking if this this",
    "start": "786240",
    "end": "788800"
  },
  {
    "text": "thing is accidentally coming in as bgr",
    "start": "788800",
    "end": "790800"
  },
  {
    "text": "format it's going to let you know so",
    "start": "790800",
    "end": "792320"
  },
  {
    "text": "it's like hey your deployment pipeline",
    "start": "792320",
    "end": "794240"
  },
  {
    "text": "is broken you're going to need to go and",
    "start": "794240",
    "end": "795920"
  },
  {
    "text": "add this pre-processing step to convert",
    "start": "795920",
    "end": "798000"
  },
  {
    "text": "to the rgb format and just kind of",
    "start": "798000",
    "end": "799920"
  },
  {
    "text": "stepping through exactly what this code",
    "start": "799920",
    "end": "801680"
  },
  {
    "text": "is doing it's taking in the input from",
    "start": "801680",
    "end": "805200"
  },
  {
    "text": "your development that's called edge out",
    "start": "805200",
    "end": "807920"
  },
  {
    "text": "and then the input from your reference",
    "start": "807920",
    "end": "809200"
  },
  {
    "text": "pipeline and saying do these look the",
    "start": "809200",
    "end": "811760"
  },
  {
    "text": "same",
    "start": "811760",
    "end": "812800"
  },
  {
    "text": "and if they do okay that's that's great",
    "start": "812800",
    "end": "815680"
  },
  {
    "text": "if not then let's try to convert your",
    "start": "815680",
    "end": "818880"
  },
  {
    "text": "input from your development pipeline to",
    "start": "818880",
    "end": "821680"
  },
  {
    "text": "rgb format and then now if it matches",
    "start": "821680",
    "end": "824000"
  },
  {
    "text": "then it's like oh yeah you had a channel",
    "start": "824000",
    "end": "825600"
  },
  {
    "text": "mismatch and so then it will raise the",
    "start": "825600",
    "end": "827519"
  },
  {
    "text": "assertion and let you know that there's",
    "start": "827519",
    "end": "829199"
  },
  {
    "text": "an issue with your model",
    "start": "829199",
    "end": "832480"
  },
  {
    "start": "832000",
    "end": "905000"
  },
  {
    "text": "another issue you might run into is",
    "start": "833040",
    "end": "834959"
  },
  {
    "text": "through quantization so in quantization",
    "start": "834959",
    "end": "837440"
  },
  {
    "text": "this especially becomes important when",
    "start": "837440",
    "end": "839360"
  },
  {
    "text": "you're deploying to edge devices because",
    "start": "839360",
    "end": "841680"
  },
  {
    "text": "you just like i said before have lower",
    "start": "841680",
    "end": "844160"
  },
  {
    "text": "resource requirements and so therefore",
    "start": "844160",
    "end": "846000"
  },
  {
    "text": "you might want to go and quantize this",
    "start": "846000",
    "end": "847920"
  },
  {
    "text": "information so that it uses less memory",
    "start": "847920",
    "end": "850160"
  },
  {
    "text": "or less cpu and essentially what this",
    "start": "850160",
    "end": "852639"
  },
  {
    "text": "means is that you're converting the",
    "start": "852639",
    "end": "854560"
  },
  {
    "text": "weights and biases of your model to a",
    "start": "854560",
    "end": "856399"
  },
  {
    "text": "lower precision so in this example",
    "start": "856399",
    "end": "858160"
  },
  {
    "text": "picture you know you start with the",
    "start": "858160",
    "end": "859519"
  },
  {
    "text": "floating point 32-bit number and then",
    "start": "859519",
    "end": "862000"
  },
  {
    "text": "you do quantization to convert that to a",
    "start": "862000",
    "end": "865199"
  },
  {
    "text": "int 8.",
    "start": "865199",
    "end": "866720"
  },
  {
    "text": "and some of the issues that can happen",
    "start": "866720",
    "end": "868639"
  },
  {
    "text": "here is that your quantization process",
    "start": "868639",
    "end": "870720"
  },
  {
    "text": "could just be wrong so",
    "start": "870720",
    "end": "872720"
  },
  {
    "text": "one of the methods of quantizing your",
    "start": "872720",
    "end": "874800"
  },
  {
    "text": "data it needs to know the min and max of",
    "start": "874800",
    "end": "877360"
  },
  {
    "text": "your input",
    "start": "877360",
    "end": "878720"
  },
  {
    "text": "and what can happen in that case is",
    "start": "878720",
    "end": "880560"
  },
  {
    "text": "let's say you have your training data",
    "start": "880560",
    "end": "882399"
  },
  {
    "text": "and there's an outlier in that training",
    "start": "882399",
    "end": "884480"
  },
  {
    "text": "data that will heavily scale or",
    "start": "884480",
    "end": "887360"
  },
  {
    "text": "that's going to scale your min and max",
    "start": "887360",
    "end": "889360"
  },
  {
    "text": "to some extreme end and whereas most of",
    "start": "889360",
    "end": "891760"
  },
  {
    "text": "stuff should like follow somewhere in",
    "start": "891760",
    "end": "893440"
  },
  {
    "text": "the middle and you know don't follow",
    "start": "893440",
    "end": "895279"
  },
  {
    "text": "what that outlier is and so in that case",
    "start": "895279",
    "end": "897120"
  },
  {
    "text": "when you quantize you actually get the",
    "start": "897120",
    "end": "898800"
  },
  {
    "text": "wrong values for your weights and biases",
    "start": "898800",
    "end": "900880"
  },
  {
    "text": "and that's going to lower your accuracy",
    "start": "900880",
    "end": "905120"
  },
  {
    "start": "905000",
    "end": "965000"
  },
  {
    "text": "and how ml x-ray helps in this case is",
    "start": "905360",
    "end": "907839"
  },
  {
    "text": "that it looks at that per layer output",
    "start": "907839",
    "end": "910320"
  },
  {
    "text": "and it compares it to the reference",
    "start": "910320",
    "end": "912000"
  },
  {
    "text": "pipeline so you can see",
    "start": "912000",
    "end": "913839"
  },
  {
    "text": "how is your",
    "start": "913839",
    "end": "915680"
  },
  {
    "text": "development pipeline doing in regards to",
    "start": "915680",
    "end": "917839"
  },
  {
    "text": "the reference one so here we have two",
    "start": "917839",
    "end": "919839"
  },
  {
    "text": "examples so the orange line is this",
    "start": "919839",
    "end": "922880"
  },
  {
    "text": "uh model that we know all the weights",
    "start": "922880",
    "end": "925600"
  },
  {
    "text": "all the biases have been quantized they",
    "start": "925600",
    "end": "927920"
  },
  {
    "text": "work",
    "start": "927920",
    "end": "928720"
  },
  {
    "text": "and we compare that to the baseline",
    "start": "928720",
    "end": "930320"
  },
  {
    "text": "which is you know that",
    "start": "930320",
    "end": "931519"
  },
  {
    "text": "perfect",
    "start": "931519",
    "end": "932480"
  },
  {
    "text": "baseline image that has been a",
    "start": "932480",
    "end": "935759"
  },
  {
    "text": "perfect baseline model that has been",
    "start": "935759",
    "end": "937680"
  },
  {
    "text": "trained in the cloud and we can see that",
    "start": "937680",
    "end": "940160"
  },
  {
    "text": "the",
    "start": "940160",
    "end": "941279"
  },
  {
    "text": "the mean square error is right there in",
    "start": "941279",
    "end": "943040"
  },
  {
    "text": "the bottom it's pretty low and that's",
    "start": "943040",
    "end": "945279"
  },
  {
    "text": "doing great and then you have this other",
    "start": "945279",
    "end": "946720"
  },
  {
    "text": "model that you've trained and you've",
    "start": "946720",
    "end": "949279"
  },
  {
    "text": "quantized it and you see that okay",
    "start": "949279",
    "end": "951519"
  },
  {
    "text": "comparing that to my baseline the error",
    "start": "951519",
    "end": "953680"
  },
  {
    "text": "is much higher and so therefore i should",
    "start": "953680",
    "end": "955120"
  },
  {
    "text": "go in and try to figure out just what i",
    "start": "955120",
    "end": "957120"
  },
  {
    "text": "need to do do i need better training",
    "start": "957120",
    "end": "958560"
  },
  {
    "text": "data to fix this or what what other",
    "start": "958560",
    "end": "960959"
  },
  {
    "text": "processes can i do to quantize my",
    "start": "960959",
    "end": "962959"
  },
  {
    "text": "weights",
    "start": "962959",
    "end": "965279"
  },
  {
    "start": "965000",
    "end": "1027000"
  },
  {
    "text": "and then last this one is very unique to",
    "start": "966399",
    "end": "968240"
  },
  {
    "text": "edge compute because now you're",
    "start": "968240",
    "end": "970000"
  },
  {
    "text": "deploying to a bunch of different",
    "start": "970000",
    "end": "971360"
  },
  {
    "text": "devices these have different uh hardware",
    "start": "971360",
    "end": "973759"
  },
  {
    "text": "requirements these",
    "start": "973759",
    "end": "975279"
  },
  {
    "text": "just",
    "start": "975279",
    "end": "976000"
  },
  {
    "text": "at the core of it in the kernel optimize",
    "start": "976000",
    "end": "978320"
  },
  {
    "text": "different operations in different ways",
    "start": "978320",
    "end": "980639"
  },
  {
    "text": "and so this can lead to a huge latency",
    "start": "980639",
    "end": "982959"
  },
  {
    "text": "difference or performance between uh",
    "start": "982959",
    "end": "985040"
  },
  {
    "text": "devices so you know in one case you have",
    "start": "985040",
    "end": "987600"
  },
  {
    "text": "something running it's very fast and",
    "start": "987600",
    "end": "988959"
  },
  {
    "text": "then in some other case you don't know",
    "start": "988959",
    "end": "990480"
  },
  {
    "text": "why it's the same model and it's really",
    "start": "990480",
    "end": "992320"
  },
  {
    "text": "slow and so we used mlx ray to help us",
    "start": "992320",
    "end": "995440"
  },
  {
    "text": "create this graph here and you can see",
    "start": "995440",
    "end": "997360"
  },
  {
    "text": "that we've compared against different",
    "start": "997360",
    "end": "998800"
  },
  {
    "text": "models",
    "start": "998800",
    "end": "999920"
  },
  {
    "text": "how long it takes to run each layer and",
    "start": "999920",
    "end": "1002240"
  },
  {
    "text": "some of the results are pretty",
    "start": "1002240",
    "end": "1003440"
  },
  {
    "text": "surprising right so you have this",
    "start": "1003440",
    "end": "1005519"
  },
  {
    "text": "the",
    "start": "1005519",
    "end": "1006320"
  },
  {
    "text": "exact the quantile or not the quantile",
    "start": "1006320",
    "end": "1009120"
  },
  {
    "text": "the quantized version",
    "start": "1009120",
    "end": "1010639"
  },
  {
    "text": "um pipeline that we used before is",
    "start": "1010639",
    "end": "1012560"
  },
  {
    "text": "actually pretty slow in that second",
    "start": "1012560",
    "end": "1014320"
  },
  {
    "text": "convolution step",
    "start": "1014320",
    "end": "1015839"
  },
  {
    "text": "and",
    "start": "1015839",
    "end": "1017279"
  },
  {
    "text": "ml x-ray helps you figure out it's like",
    "start": "1017279",
    "end": "1018959"
  },
  {
    "text": "okay this layer there's something wrong",
    "start": "1018959",
    "end": "1020480"
  },
  {
    "text": "and that's why it's slow and maybe i",
    "start": "1020480",
    "end": "1021839"
  },
  {
    "text": "need to deploy like a special model to",
    "start": "1021839",
    "end": "1023600"
  },
  {
    "text": "this particular hardware",
    "start": "1023600",
    "end": "1026720"
  },
  {
    "start": "1027000",
    "end": "1198000"
  },
  {
    "text": "so i'm going to walk through a little",
    "start": "1027839",
    "end": "1029438"
  },
  {
    "text": "bit about what",
    "start": "1029439",
    "end": "1031438"
  },
  {
    "text": "using ml x-ray actually looks like",
    "start": "1031439",
    "end": "1034480"
  },
  {
    "text": "so",
    "start": "1034480",
    "end": "1036319"
  },
  {
    "text": "first this is a nifty collab that we",
    "start": "1036319",
    "end": "1038400"
  },
  {
    "text": "have",
    "start": "1038400",
    "end": "1039199"
  },
  {
    "text": "that just shows like an example model uh",
    "start": "1039199",
    "end": "1042000"
  },
  {
    "text": "that uses ml x-ray so the first thing",
    "start": "1042000",
    "end": "1043839"
  },
  {
    "text": "you need to do is install the ml x-ray",
    "start": "1043839",
    "end": "1046000"
  },
  {
    "text": "library",
    "start": "1046000",
    "end": "1048319"
  },
  {
    "text": "and then you want to go and just create",
    "start": "1048319",
    "end": "1050320"
  },
  {
    "text": "your model runner class",
    "start": "1050320",
    "end": "1052559"
  },
  {
    "text": "so this is just using tensorflow lite",
    "start": "1052559",
    "end": "1054960"
  },
  {
    "text": "and the important things to kind of pick",
    "start": "1054960",
    "end": "1056400"
  },
  {
    "text": "up on here",
    "start": "1056400",
    "end": "1058160"
  },
  {
    "text": "are essentially this m monitor so you're",
    "start": "1058160",
    "end": "1061679"
  },
  {
    "text": "initializing",
    "start": "1061679",
    "end": "1063200"
  },
  {
    "text": "ml x-ray to go ahead and start logging",
    "start": "1063200",
    "end": "1066480"
  },
  {
    "text": "information from each output layer and",
    "start": "1066480",
    "end": "1068559"
  },
  {
    "text": "you know the inputs and outputs",
    "start": "1068559",
    "end": "1070640"
  },
  {
    "text": "and then finally you go you invoke the",
    "start": "1070640",
    "end": "1072640"
  },
  {
    "text": "model",
    "start": "1072640",
    "end": "1074240"
  },
  {
    "text": "this is not specific to mlx ray at all",
    "start": "1074240",
    "end": "1076799"
  },
  {
    "text": "so this is all just code for",
    "start": "1076799",
    "end": "1079200"
  },
  {
    "text": "how to run the model itself",
    "start": "1079200",
    "end": "1082559"
  },
  {
    "text": "and then you're going to want to run the",
    "start": "1083280",
    "end": "1084480"
  },
  {
    "text": "model on an image so this is an image",
    "start": "1084480",
    "end": "1086720"
  },
  {
    "text": "classification example",
    "start": "1086720",
    "end": "1088559"
  },
  {
    "text": "you can see here that we",
    "start": "1088559",
    "end": "1090240"
  },
  {
    "text": "ask for the log path to go to these",
    "start": "1090240",
    "end": "1092240"
  },
  {
    "text": "specific files and then you run the",
    "start": "1092240",
    "end": "1094960"
  },
  {
    "text": "model so here",
    "start": "1094960",
    "end": "1096400"
  },
  {
    "text": "you scroll down a little bit more",
    "start": "1096400",
    "end": "1098640"
  },
  {
    "text": "the models essentially run and in the",
    "start": "1098640",
    "end": "1100320"
  },
  {
    "text": "background",
    "start": "1100320",
    "end": "1101440"
  },
  {
    "text": "mlx ray has picked up just like a bunch",
    "start": "1101440",
    "end": "1103280"
  },
  {
    "text": "of logs about how each layer is running",
    "start": "1103280",
    "end": "1105440"
  },
  {
    "text": "about the latency of each layer all of",
    "start": "1105440",
    "end": "1107919"
  },
  {
    "text": "that information so what does that",
    "start": "1107919",
    "end": "1109679"
  },
  {
    "text": "actually look like here's an example of",
    "start": "1109679",
    "end": "1112240"
  },
  {
    "text": "an mlxray log and there's a ton of",
    "start": "1112240",
    "end": "1114400"
  },
  {
    "text": "information in here right you have the",
    "start": "1114400",
    "end": "1116320"
  },
  {
    "text": "start time you have the overall latency",
    "start": "1116320",
    "end": "1118880"
  },
  {
    "text": "of how long your inference took you have",
    "start": "1118880",
    "end": "1120960"
  },
  {
    "text": "the memory usage and you have",
    "start": "1120960",
    "end": "1123520"
  },
  {
    "text": "for each layer all the outputs and this",
    "start": "1123520",
    "end": "1125600"
  },
  {
    "text": "is i'm not going to keep scrolling it's",
    "start": "1125600",
    "end": "1127039"
  },
  {
    "text": "just a ton of information",
    "start": "1127039",
    "end": "1129360"
  },
  {
    "text": "you also get your summary information so",
    "start": "1129360",
    "end": "1132160"
  },
  {
    "text": "this tells you for each layer",
    "start": "1132160",
    "end": "1134880"
  },
  {
    "text": "how long did it take how much memory did",
    "start": "1134880",
    "end": "1136720"
  },
  {
    "text": "it take the names of it",
    "start": "1136720",
    "end": "1138880"
  },
  {
    "text": "so it just collects a bunch of",
    "start": "1138880",
    "end": "1140880"
  },
  {
    "text": "interesting information so now you have",
    "start": "1140880",
    "end": "1142640"
  },
  {
    "text": "all this information",
    "start": "1142640",
    "end": "1144400"
  },
  {
    "text": "what exactly do you do with it",
    "start": "1144400",
    "end": "1146320"
  },
  {
    "text": "mlxray has an api that you can use to go",
    "start": "1146320",
    "end": "1148960"
  },
  {
    "text": "and start parsing this data and making",
    "start": "1148960",
    "end": "1150640"
  },
  {
    "text": "sense out of it so here's just an",
    "start": "1150640",
    "end": "1152240"
  },
  {
    "text": "example script it loads in a bunch of",
    "start": "1152240",
    "end": "1154080"
  },
  {
    "text": "things from the ml x-ray library",
    "start": "1154080",
    "end": "1156799"
  },
  {
    "text": "this first function here it goes reads",
    "start": "1156799",
    "end": "1159360"
  },
  {
    "text": "the logs in it parses it so you see here",
    "start": "1159360",
    "end": "1161760"
  },
  {
    "text": "it's reading the logs it's getting the",
    "start": "1161760",
    "end": "1163520"
  },
  {
    "text": "keys and the values",
    "start": "1163520",
    "end": "1165840"
  },
  {
    "text": "and then essentially in the end it can",
    "start": "1165840",
    "end": "1167600"
  },
  {
    "text": "plot the results and we use this code to",
    "start": "1167600",
    "end": "1169679"
  },
  {
    "text": "plot those results earlier that i showed",
    "start": "1169679",
    "end": "1171280"
  },
  {
    "text": "back on that slide where i was comparing",
    "start": "1171280",
    "end": "1173440"
  },
  {
    "text": "the uh",
    "start": "1173440",
    "end": "1174799"
  },
  {
    "text": "the accuracy between the different or",
    "start": "1174799",
    "end": "1176640"
  },
  {
    "text": "the differences between the output",
    "start": "1176640",
    "end": "1178080"
  },
  {
    "text": "layers",
    "start": "1178080",
    "end": "1180399"
  },
  {
    "text": "so you can essentially very quickly get",
    "start": "1180559",
    "end": "1182960"
  },
  {
    "text": "started with",
    "start": "1182960",
    "end": "1184320"
  },
  {
    "text": "mlx ray",
    "start": "1184320",
    "end": "1186400"
  },
  {
    "text": "okay and then jumping back",
    "start": "1186400",
    "end": "1189280"
  },
  {
    "text": "to my slides oops",
    "start": "1189280",
    "end": "1193559"
  },
  {
    "start": "1198000",
    "end": "1262000"
  },
  {
    "text": "you can see that ml x-ray has some",
    "start": "1199520",
    "end": "1201280"
  },
  {
    "text": "limitations",
    "start": "1201280",
    "end": "1202559"
  },
  {
    "text": "and",
    "start": "1202559",
    "end": "1203600"
  },
  {
    "text": "the first one is that you need code",
    "start": "1203600",
    "end": "1205200"
  },
  {
    "text": "changes to go and enable instrumentation",
    "start": "1205200",
    "end": "1207440"
  },
  {
    "text": "on your uh debug pipeline and that can",
    "start": "1207440",
    "end": "1210640"
  },
  {
    "text": "be annoying right because you might go",
    "start": "1210640",
    "end": "1211919"
  },
  {
    "text": "deploy and then you're like oh i forgot",
    "start": "1211919",
    "end": "1213280"
  },
  {
    "text": "to add this i forgot to add this line in",
    "start": "1213280",
    "end": "1216159"
  },
  {
    "text": "to go and invoke mlx ray and you have to",
    "start": "1216159",
    "end": "1218000"
  },
  {
    "text": "go back in and do that",
    "start": "1218000",
    "end": "1219600"
  },
  {
    "text": "and generally when we're whenever we're",
    "start": "1219600",
    "end": "1221520"
  },
  {
    "text": "doing observability we like you know low",
    "start": "1221520",
    "end": "1223520"
  },
  {
    "text": "touch",
    "start": "1223520",
    "end": "1224400"
  },
  {
    "text": "uh instrumentation",
    "start": "1224400",
    "end": "1226320"
  },
  {
    "text": "there's also a slight imp performance",
    "start": "1226320",
    "end": "1228320"
  },
  {
    "text": "impact when you're using mlx ray so",
    "start": "1228320",
    "end": "1230320"
  },
  {
    "text": "obviously it's more noticeable on gpu",
    "start": "1230320",
    "end": "1232240"
  },
  {
    "text": "you're writing tons of things to logs so",
    "start": "1232240",
    "end": "1234080"
  },
  {
    "text": "that also has a memory impact because",
    "start": "1234080",
    "end": "1236000"
  },
  {
    "text": "you're just storing all this data",
    "start": "1236000",
    "end": "1237600"
  },
  {
    "text": "somewhere",
    "start": "1237600",
    "end": "1238720"
  },
  {
    "text": "and then i think we could kind of see",
    "start": "1238720",
    "end": "1240000"
  },
  {
    "text": "towards the end it was like okay i have",
    "start": "1240000",
    "end": "1241440"
  },
  {
    "text": "all this data now i need to use this",
    "start": "1241440",
    "end": "1243360"
  },
  {
    "text": "python api to go ahead and parse it and",
    "start": "1243360",
    "end": "1245440"
  },
  {
    "text": "i can use that api to create a graph but",
    "start": "1245440",
    "end": "1247360"
  },
  {
    "text": "it kind of limits you and how you can",
    "start": "1247360",
    "end": "1249200"
  },
  {
    "text": "actually go and visualize this",
    "start": "1249200",
    "end": "1250640"
  },
  {
    "text": "information what if you want to do more",
    "start": "1250640",
    "end": "1252240"
  },
  {
    "text": "interesting things with it because it's",
    "start": "1252240",
    "end": "1253760"
  },
  {
    "text": "not in some standard output format that",
    "start": "1253760",
    "end": "1255520"
  },
  {
    "text": "you can like stick into any tool that",
    "start": "1255520",
    "end": "1257039"
  },
  {
    "text": "you want it's kind of hard to go and",
    "start": "1257039",
    "end": "1258640"
  },
  {
    "text": "just build more interesting",
    "start": "1258640",
    "end": "1259840"
  },
  {
    "text": "visualizations with it",
    "start": "1259840",
    "end": "1262400"
  },
  {
    "start": "1262000",
    "end": "1370000"
  },
  {
    "text": "so kind of here how i got",
    "start": "1262400",
    "end": "1265600"
  },
  {
    "text": "involved in mlx ray is i worked on pixi",
    "start": "1265600",
    "end": "1268559"
  },
  {
    "text": "i mentioned that before and there were a",
    "start": "1268559",
    "end": "1270640"
  },
  {
    "text": "lot of correlations between how we do",
    "start": "1270640",
    "end": "1272320"
  },
  {
    "text": "things in pixi that i thought could help",
    "start": "1272320",
    "end": "1274159"
  },
  {
    "text": "the ml x-ray project and so just like a",
    "start": "1274159",
    "end": "1276559"
  },
  {
    "text": "brief summary again pixi is an open",
    "start": "1276559",
    "end": "1278720"
  },
  {
    "text": "source",
    "start": "1278720",
    "end": "1279840"
  },
  {
    "text": "cncf sandbox project for observability",
    "start": "1279840",
    "end": "1282799"
  },
  {
    "text": "on kubernetes and there are three",
    "start": "1282799",
    "end": "1284080"
  },
  {
    "text": "pillars that i think kind of help in the",
    "start": "1284080",
    "end": "1286159"
  },
  {
    "text": "mlx ray case so the first is auto",
    "start": "1286159",
    "end": "1288400"
  },
  {
    "text": "telemetry so pxe picks up information",
    "start": "1288400",
    "end": "1290880"
  },
  {
    "text": "using tools like ebpf without you having",
    "start": "1290880",
    "end": "1293520"
  },
  {
    "text": "to go and instrument things in your",
    "start": "1293520",
    "end": "1295280"
  },
  {
    "text": "application so it just automatically",
    "start": "1295280",
    "end": "1297200"
  },
  {
    "text": "starts collecting information as soon as",
    "start": "1297200",
    "end": "1299280"
  },
  {
    "text": "it's deployed",
    "start": "1299280",
    "end": "1300480"
  },
  {
    "text": "and that really helps in the mlx ray",
    "start": "1300480",
    "end": "1302640"
  },
  {
    "text": "case where you have to go right now you",
    "start": "1302640",
    "end": "1304000"
  },
  {
    "text": "have to add that line to be like i want",
    "start": "1304000",
    "end": "1305440"
  },
  {
    "text": "to invoke mlx ray and start seeing",
    "start": "1305440",
    "end": "1307120"
  },
  {
    "text": "information",
    "start": "1307120",
    "end": "1308720"
  },
  {
    "text": "this also helps in the case where it's",
    "start": "1308720",
    "end": "1310240"
  },
  {
    "text": "like you don't want this thing running",
    "start": "1310240",
    "end": "1311919"
  },
  {
    "text": "on your pipeline all the time right you",
    "start": "1311919",
    "end": "1314000"
  },
  {
    "text": "maybe want it when you're debugging but",
    "start": "1314000",
    "end": "1315760"
  },
  {
    "text": "in the future it's like when you know",
    "start": "1315760",
    "end": "1316720"
  },
  {
    "text": "it's running well you don't want it",
    "start": "1316720",
    "end": "1318000"
  },
  {
    "text": "anymore so you're going to have to go",
    "start": "1318000",
    "end": "1320000"
  },
  {
    "text": "and take that line out of your code that",
    "start": "1320000",
    "end": "1322320"
  },
  {
    "text": "invokes mlx-ray the second thing is that",
    "start": "1322320",
    "end": "1324960"
  },
  {
    "text": "pixi really does well with edge compute",
    "start": "1324960",
    "end": "1327120"
  },
  {
    "text": "so that fits very well in this case",
    "start": "1327120",
    "end": "1328720"
  },
  {
    "text": "where we're deploying across edge",
    "start": "1328720",
    "end": "1330240"
  },
  {
    "text": "devices and make sure you kind of follow",
    "start": "1330240",
    "end": "1332080"
  },
  {
    "text": "all those standards where it's like",
    "start": "1332080",
    "end": "1333600"
  },
  {
    "text": "you're keeping all that data on the edge",
    "start": "1333600",
    "end": "1336400"
  },
  {
    "text": "in memory and then finally i think the",
    "start": "1336400",
    "end": "1338320"
  },
  {
    "text": "biggest thing that mlxray would",
    "start": "1338320",
    "end": "1341200"
  },
  {
    "text": "benefit from is pixi's scriptable",
    "start": "1341200",
    "end": "1343039"
  },
  {
    "text": "interfaces so here there's essentially a",
    "start": "1343039",
    "end": "1345200"
  },
  {
    "text": "data format for pixi everything is",
    "start": "1345200",
    "end": "1346720"
  },
  {
    "text": "inside a table and you can go and do",
    "start": "1346720",
    "end": "1348640"
  },
  {
    "text": "whatever you want with that information",
    "start": "1348640",
    "end": "1350400"
  },
  {
    "text": "to build visualizations very easily and",
    "start": "1350400",
    "end": "1352640"
  },
  {
    "text": "so this is kind of just a preview about",
    "start": "1352640",
    "end": "1354880"
  },
  {
    "text": "just like how we wanted to apply pixi's",
    "start": "1354880",
    "end": "1357120"
  },
  {
    "text": "use case to mlxray so we're actually",
    "start": "1357120",
    "end": "1360400"
  },
  {
    "text": "going to go into",
    "start": "1360400",
    "end": "1362000"
  },
  {
    "text": "this in more detail tomorrow on",
    "start": "1362000",
    "end": "1364159"
  },
  {
    "text": "kubernetes on edge day so if you'd like",
    "start": "1364159",
    "end": "1365919"
  },
  {
    "text": "to come by and learn some more that",
    "start": "1365919",
    "end": "1367679"
  },
  {
    "text": "would be great to see you guys all again",
    "start": "1367679",
    "end": "1370000"
  },
  {
    "start": "1370000",
    "end": "1397000"
  },
  {
    "text": "but uh here are some resources for mlx",
    "start": "1370000",
    "end": "1372720"
  },
  {
    "text": "ray so the first one of course all this",
    "start": "1372720",
    "end": "1374240"
  },
  {
    "text": "is open source mlx rate is open source",
    "start": "1374240",
    "end": "1376640"
  },
  {
    "text": "pixi is open source check out the repo",
    "start": "1376640",
    "end": "1378880"
  },
  {
    "text": "check out the code try running stuff",
    "start": "1378880",
    "end": "1380480"
  },
  {
    "text": "yourself uh i also included the mlx",
    "start": "1380480",
    "end": "1382720"
  },
  {
    "text": "right paper for those who are like more",
    "start": "1382720",
    "end": "1384240"
  },
  {
    "text": "interested in picking up on some like",
    "start": "1384240",
    "end": "1386080"
  },
  {
    "text": "the very technical uh information",
    "start": "1386080",
    "end": "1390240"
  },
  {
    "text": "[Applause]",
    "start": "1391800",
    "end": "1397440"
  },
  {
    "start": "1397000",
    "end": "1596000"
  },
  {
    "text": "i think we have time for one or two",
    "start": "1397440",
    "end": "1399440"
  },
  {
    "text": "questions",
    "start": "1399440",
    "end": "1400720"
  },
  {
    "text": "if there's anyone that has a question",
    "start": "1400720",
    "end": "1402640"
  },
  {
    "text": "yes we have a question",
    "start": "1402640",
    "end": "1405600"
  },
  {
    "text": "hi thank you for the presentation really",
    "start": "1408480",
    "end": "1410559"
  },
  {
    "text": "great work",
    "start": "1410559",
    "end": "1411600"
  },
  {
    "text": "um i have a question so why was the",
    "start": "1411600",
    "end": "1413919"
  },
  {
    "text": "decision made to use logs to diff the",
    "start": "1413919",
    "end": "1416799"
  },
  {
    "text": "layer outputs between the cloud and the",
    "start": "1416799",
    "end": "1419280"
  },
  {
    "text": "edge model for example why not probe the",
    "start": "1419280",
    "end": "1421679"
  },
  {
    "text": "actual layers because i'm assuming you",
    "start": "1421679",
    "end": "1423760"
  },
  {
    "text": "own both the edge model and the cloud",
    "start": "1423760",
    "end": "1426080"
  },
  {
    "text": "model right",
    "start": "1426080",
    "end": "1427600"
  },
  {
    "text": "logs can run into issues for example of",
    "start": "1427600",
    "end": "1430159"
  },
  {
    "text": "formatting and also being really like",
    "start": "1430159",
    "end": "1432880"
  },
  {
    "text": "large you know your model is large",
    "start": "1432880",
    "end": "1434720"
  },
  {
    "text": "you're going to be storing large text",
    "start": "1434720",
    "end": "1436159"
  },
  {
    "text": "files",
    "start": "1436159",
    "end": "1437200"
  },
  {
    "text": "and also the parsing is pretty expensive",
    "start": "1437200",
    "end": "1440080"
  },
  {
    "text": "and can be error prone so why not probe",
    "start": "1440080",
    "end": "1442159"
  },
  {
    "text": "the actual layers",
    "start": "1442159",
    "end": "1443919"
  },
  {
    "text": "you know in the cloud and the edge",
    "start": "1443919",
    "end": "1445360"
  },
  {
    "text": "models yeah so i think that's a very",
    "start": "1445360",
    "end": "1447840"
  },
  {
    "text": "good point so the initial version of",
    "start": "1447840",
    "end": "1449440"
  },
  {
    "text": "this does use logs and i think that's",
    "start": "1449440",
    "end": "1451200"
  },
  {
    "text": "because it is hard to get this",
    "start": "1451200",
    "end": "1452400"
  },
  {
    "text": "information on some edge device that",
    "start": "1452400",
    "end": "1454000"
  },
  {
    "text": "you've deployed to that you don't have",
    "start": "1454000",
    "end": "1455840"
  },
  {
    "text": "access to as easily and so then when i",
    "start": "1455840",
    "end": "1458320"
  },
  {
    "text": "mention pixy later we essentially do use",
    "start": "1458320",
    "end": "1460320"
  },
  {
    "text": "probes to go pick up that information",
    "start": "1460320",
    "end": "1462159"
  },
  {
    "text": "rather than going and recording it and",
    "start": "1462159",
    "end": "1463840"
  },
  {
    "text": "writing it and storing in memory where",
    "start": "1463840",
    "end": "1465679"
  },
  {
    "text": "you have to go and just you know",
    "start": "1465679",
    "end": "1467440"
  },
  {
    "text": "grab that file and then parse it later",
    "start": "1467440",
    "end": "1469600"
  },
  {
    "text": "so luckily the parsing itself that's",
    "start": "1469600",
    "end": "1471120"
  },
  {
    "text": "when you actually want to go and debug",
    "start": "1471120",
    "end": "1472720"
  },
  {
    "text": "your pipeline and so that's like done",
    "start": "1472720",
    "end": "1474880"
  },
  {
    "text": "async and not actually in the model when",
    "start": "1474880",
    "end": "1476559"
  },
  {
    "text": "you're running it",
    "start": "1476559",
    "end": "1479120"
  },
  {
    "text": "so how did you end up solving the issue",
    "start": "1481440",
    "end": "1483120"
  },
  {
    "text": "you said it was difficult to parse the",
    "start": "1483120",
    "end": "1485279"
  },
  {
    "text": "edge model how did you end up solving",
    "start": "1485279",
    "end": "1487039"
  },
  {
    "text": "this issue",
    "start": "1487039",
    "end": "1488480"
  },
  {
    "text": "difficult to parse you said it was",
    "start": "1488480",
    "end": "1490480"
  },
  {
    "text": "difficult to probe the edge model",
    "start": "1490480",
    "end": "1492320"
  },
  {
    "text": "because it's like on the edge so you",
    "start": "1492320",
    "end": "1493919"
  },
  {
    "text": "don't have direct access to it oh okay i",
    "start": "1493919",
    "end": "1496320"
  },
  {
    "text": "will talk more about that if you're",
    "start": "1496320",
    "end": "1497760"
  },
  {
    "text": "going to go to edge j essentially pixi",
    "start": "1497760",
    "end": "1500720"
  },
  {
    "text": "uses this thing called ebpf and that",
    "start": "1500720",
    "end": "1502640"
  },
  {
    "text": "runs at the kernel level and so then",
    "start": "1502640",
    "end": "1504640"
  },
  {
    "text": "that can pick up a ton of interesting",
    "start": "1504640",
    "end": "1506240"
  },
  {
    "text": "information",
    "start": "1506240",
    "end": "1508400"
  },
  {
    "text": "okay last question",
    "start": "1508400",
    "end": "1512279"
  },
  {
    "text": "so i understand a",
    "start": "1515600",
    "end": "1517120"
  },
  {
    "text": "pixie",
    "start": "1517120",
    "end": "1518559"
  },
  {
    "text": "telemetry model in general for like",
    "start": "1518559",
    "end": "1520559"
  },
  {
    "text": "service monitoring i was curious about",
    "start": "1520559",
    "end": "1524000"
  },
  {
    "text": "ml model performance and",
    "start": "1524000",
    "end": "1526080"
  },
  {
    "text": "perhaps those data also being",
    "start": "1526080",
    "end": "1527600"
  },
  {
    "text": "interesting to be",
    "start": "1527600",
    "end": "1529039"
  },
  {
    "text": "aggregated and looked at in a place",
    "start": "1529039",
    "end": "1530559"
  },
  {
    "text": "where people are usually looking at ml",
    "start": "1530559",
    "end": "1531760"
  },
  {
    "text": "performance comparisons like in weights",
    "start": "1531760",
    "end": "1533679"
  },
  {
    "text": "and biases do you guys have like like a",
    "start": "1533679",
    "end": "1535760"
  },
  {
    "text": "a picture of like where those data could",
    "start": "1535760",
    "end": "1537279"
  },
  {
    "text": "somehow intersect or how you could bring",
    "start": "1537279",
    "end": "1538640"
  },
  {
    "text": "them together like that",
    "start": "1538640",
    "end": "1540159"
  },
  {
    "text": "yeah so",
    "start": "1540159",
    "end": "1541360"
  },
  {
    "text": "i guess in relating to pixi we use ebpf",
    "start": "1541360",
    "end": "1544080"
  },
  {
    "text": "like i said and that kind of picks up",
    "start": "1544080",
    "end": "1545760"
  },
  {
    "text": "you can use evpf to hook on to certain",
    "start": "1545760",
    "end": "1548400"
  },
  {
    "text": "new probes so that are like certain user",
    "start": "1548400",
    "end": "1550000"
  },
  {
    "text": "defined functions and then that can",
    "start": "1550000",
    "end": "1551679"
  },
  {
    "text": "collect a bunch of information uh",
    "start": "1551679",
    "end": "1554400"
  },
  {
    "text": "you can get like the arguments of that",
    "start": "1554400",
    "end": "1555760"
  },
  {
    "text": "function you can get the outputs of that",
    "start": "1555760",
    "end": "1557360"
  },
  {
    "text": "function and you can",
    "start": "1557360",
    "end": "1559840"
  },
  {
    "text": "send all that data to pixie to visualize",
    "start": "1559840",
    "end": "1561679"
  },
  {
    "text": "it i hope does that answer your question",
    "start": "1561679",
    "end": "1563279"
  },
  {
    "text": "i'm not sure",
    "start": "1563279",
    "end": "1564480"
  },
  {
    "text": "i got it correct",
    "start": "1564480",
    "end": "1566640"
  },
  {
    "text": "but we'll be talking more about tomorrow",
    "start": "1566640",
    "end": "1568240"
  },
  {
    "text": "so",
    "start": "1568240",
    "end": "1569120"
  },
  {
    "text": "hopefully you can come by and see our",
    "start": "1569120",
    "end": "1570880"
  },
  {
    "text": "demo about how we just like use pixi to",
    "start": "1570880",
    "end": "1572799"
  },
  {
    "text": "go and like probe all this information",
    "start": "1572799",
    "end": "1574320"
  },
  {
    "text": "and what information we can get",
    "start": "1574320",
    "end": "1576559"
  },
  {
    "text": "okay we have another question from the",
    "start": "1576559",
    "end": "1578640"
  },
  {
    "text": "slack channels so the question is is ml",
    "start": "1578640",
    "end": "1580880"
  },
  {
    "text": "x-ray mainly for deep learning all the",
    "start": "1580880",
    "end": "1582720"
  },
  {
    "text": "examples shown seems assumed layers",
    "start": "1582720",
    "end": "1585520"
  },
  {
    "text": "yes yes so it is primarily for deep",
    "start": "1585520",
    "end": "1587679"
  },
  {
    "text": "learning that is correct okay",
    "start": "1587679",
    "end": "1589679"
  },
  {
    "text": "cool thank you",
    "start": "1589679",
    "end": "1591880"
  },
  {
    "text": "[Applause]",
    "start": "1591880",
    "end": "1598269"
  }
]
[
  {
    "text": "my name is Connor Nolan I'm a senior software engineer akami and I'm joined by my colleague rehard he's going to",
    "start": "160",
    "end": "5879"
  },
  {
    "text": "speak a little bit later hello everyone and uh we're here to talk about uh provider SEF which is an open source",
    "start": "5879",
    "end": "12920"
  },
  {
    "text": "crossplane provider that we've been developing over the last year or so uh and we use it to manage uh S3 buckets in",
    "start": "12920",
    "end": "20240"
  },
  {
    "text": "SEF clusters from kubernetes uh so I'll go through a little bit of the agenda kind of what we have in store",
    "start": "20240",
    "end": "26240"
  },
  {
    "text": "today um I'm going to give a bit of background kind of how we ended up here uh the challenge that we faced and um",
    "start": "26240",
    "end": "33760"
  },
  {
    "text": "then how we over overcame that some of the specific requirements and how that led us to uh cross plane a little bit",
    "start": "33760",
    "end": "40120"
  },
  {
    "text": "about crossplane I won't go into too much detail on it um but kind of how it works for us and how it's a kind of the",
    "start": "40120",
    "end": "46760"
  },
  {
    "text": "perfect solution for us um so then I'll get into provider St itself give a",
    "start": "46760",
    "end": "52559"
  },
  {
    "text": "little bit of an overview um some of the features how it works that kind of thing then rehard is going to take over give",
    "start": "52559",
    "end": "58280"
  },
  {
    "text": "us a demo and uh get into kind of a discussion then on uh scalability and",
    "start": "58280",
    "end": "63559"
  },
  {
    "text": "performance that kind of thing then we'll wrap up with a Q&A and uh head for",
    "start": "63559",
    "end": "69000"
  },
  {
    "text": "the airport okay so uh like I said a little bit of background rehard and I both uh",
    "start": "69000",
    "end": "75360"
  },
  {
    "text": "previously worked at a company called andat which was a London based uh kubernetes startup uh it was originally",
    "start": "75360",
    "end": "82600"
  },
  {
    "text": "called storage OS later rebranded as on dash you might recognize the logos from previous cubec cons um but as well what",
    "start": "82600",
    "end": "90320"
  },
  {
    "text": "what we did there was we offered a kubernetes native uh block storage solution and as part of delivering that",
    "start": "90320",
    "end": "97439"
  },
  {
    "text": "we uh maintained a bunch of different kubernetes peripherals so we had a cube",
    "start": "97439",
    "end": "102560"
  },
  {
    "text": "plugin bunch of Helm charts obviously a CSI driver and then we had probably half",
    "start": "102560",
    "end": "108280"
  },
  {
    "text": "a dozen or so kubernetes operators uh all of which were like CU Builder based",
    "start": "108280",
    "end": "113600"
  },
  {
    "text": "um so we would be kind of intimately familiar with that whole branch of the kubernetes ecosystem the operator",
    "start": "113600",
    "end": "120079"
  },
  {
    "text": "pattern all that and that kind of uh I suppose informed our decision making going forward on this um so then about a",
    "start": "120079",
    "end": "127520"
  },
  {
    "text": "year ago I think actually about a year ago this week I'm not sure the exact dates but we were acquired by akami and",
    "start": "127520",
    "end": "134120"
  },
  {
    "text": "then that led us to uh a new challenge which kind of combined our history and",
    "start": "134120",
    "end": "140200"
  },
  {
    "text": "knowledge of uh kubernetes and storage so the specifics of that challenge were",
    "start": "140200",
    "end": "146800"
  },
  {
    "text": "uh we need to be able to manage uh S3 buckets across Ross multiple distributed SE clusters and we need to be able to do",
    "start": "146800",
    "end": "153599"
  },
  {
    "text": "that from within a single kubernetes cluster so basically we're going to have kubernetes as a control plane and then",
    "start": "153599",
    "end": "159480"
  },
  {
    "text": "external to that uh multiple distributed Seft clusters uh we want to have each bucket",
    "start": "159480",
    "end": "165319"
  },
  {
    "text": "represented as a custom resource so that would be the designated source of Truth",
    "start": "165319",
    "end": "171120"
  },
  {
    "text": "uh for that bucket and then we will attempt to um reconcile the desired",
    "start": "171120",
    "end": "176480"
  },
  {
    "text": "State off of that uh the solution would need to fit into an event driven architecture with an eventually",
    "start": "176480",
    "end": "181959"
  },
  {
    "text": "consistent model so you can kind of see where this is going already ties in nicely with the idea of having a custom",
    "start": "181959",
    "end": "187560"
  },
  {
    "text": "resource represent in that bucket and then trying to reconcile that desired state with the the real world um we also",
    "start": "187560",
    "end": "195799"
  },
  {
    "text": "need to be able to handle these S3 operations asynchronously because we're dealing with multiple backends obviously",
    "start": "195799",
    "end": "201360"
  },
  {
    "text": "for performance needs we need we need to be able to send off these S3 uh operations asynchronously and we need to",
    "start": "201360",
    "end": "207440"
  },
  {
    "text": "be able to do it with a degree of visibility into what's happening on each SEF cluster uh where buckets are being",
    "start": "207440",
    "end": "215000"
  },
  {
    "text": "created successfully if there's failures what's happening why it's happening when it's happening um and then the final",
    "start": "215000",
    "end": "221640"
  },
  {
    "text": "thing was uh we're going to have a lot of traffic we're probably going to need to be able to handle upwards of 100,000",
    "start": "221640",
    "end": "226680"
  },
  {
    "text": "buckets that also means being able to handle upwards of 100,000 CRS reard is going to talk us through scalability a",
    "start": "226680",
    "end": "233120"
  },
  {
    "text": "little bit later um So based on like all of these specific requirements you can",
    "start": "233120",
    "end": "238879"
  },
  {
    "text": "kind of see where I'm going with this the obvious solution that you would jump into would be some kind of a kubernetes",
    "start": "238879",
    "end": "245599"
  },
  {
    "text": "operator uh controller uh but before we kind of jumps jumped head first into",
    "start": "245599",
    "end": "251840"
  },
  {
    "text": "writing it we decided to do a little bit of research bit of Investigation to see was there something some kind of",
    "start": "251840",
    "end": "257040"
  },
  {
    "text": "solution out there that we hadn't used before that might make our lives a little bit easier as developers and",
    "start": "257040",
    "end": "262240"
  },
  {
    "text": "that's where we came across across uh crossplane so what is crossplane uh I'm",
    "start": "262240",
    "end": "268400"
  },
  {
    "text": "not going to get into a big discussion on crossb because I don't have time um but this quote which I found on an",
    "start": "268400",
    "end": "275520"
  },
  {
    "text": "article in the new stack uh there About a Week Ago by Jared Watts who's a co-creator of crossplane kind of sums it",
    "start": "275520",
    "end": "281919"
  },
  {
    "text": "up nicely so crossplane is an extension to kubernetes it teaches kubernetes all about external resources and that's kind",
    "start": "281919",
    "end": "287800"
  },
  {
    "text": "of the key there it kind of sums it up both from a like a general perspective um and also from our specific use case",
    "start": "287800",
    "end": "295400"
  },
  {
    "text": "like from a general point of view if you're a cloud provider you would develop a cross provider to make",
    "start": "295400",
    "end": "301320"
  },
  {
    "text": "kubernetes aware of your Cloud resources from our perspective we wrote a",
    "start": "301320",
    "end": "306360"
  },
  {
    "text": "crossplane provider provider SEF to make kubernetes aware of our SEF clusters and",
    "start": "306360",
    "end": "312000"
  },
  {
    "text": "their resources um so if you really want to press me on what's crossplane for me",
    "start": "312000",
    "end": "319280"
  },
  {
    "text": "I look at crossplane if anyone asks me and anyone who's familiar with CU Builder and kubernetes operators uh CU",
    "start": "319280",
    "end": "326840"
  },
  {
    "text": "Builder is to a kubernetes operator What crossplane is to a crossplane provider",
    "start": "326840",
    "end": "332199"
  },
  {
    "text": "so crossplane is kind of like the framework or the utility for building or scaffolding out your crossplane provider",
    "start": "332199",
    "end": "337759"
  },
  {
    "text": "and you insert your custom logic from there so then obviously the next question is well what's a provider so a provider is basically just another",
    "start": "337759",
    "end": "343960"
  },
  {
    "text": "kubernetes controller I mean if you Peak under the hood and you drill down fair enough into the code you will come",
    "start": "343960",
    "end": "349199"
  },
  {
    "text": "across a like a conventional operator reconcile Loop um but you're kind of",
    "start": "349199",
    "end": "356120"
  },
  {
    "text": "given out of the box a really clean abstraction on top of that reconcile Loop and that allows you then to kind of",
    "start": "356120",
    "end": "361560"
  },
  {
    "text": "easily develop um controllers that are used for managing external resources um then there's",
    "start": "361560",
    "end": "368479"
  },
  {
    "text": "obviously a bunch of other utilities and functionality you get with crossplane um for that specific use case I won't go",
    "start": "368479",
    "end": "375000"
  },
  {
    "text": "into too much detail on that that's kind of just a driveby on crossplane itself um so then why would we use crossplane",
    "start": "375000",
    "end": "381759"
  },
  {
    "text": "for this use case well basically for all the reasons I just said um so crossplane",
    "start": "381759",
    "end": "388199"
  },
  {
    "text": "is kind of built on top of the whole operator pattern um it's an extension of that so for us even though we weren't",
    "start": "388199",
    "end": "394520"
  },
  {
    "text": "familiar with crossplane we were intimately familiar with operators and the operator pattern so the learning",
    "start": "394520",
    "end": "400080"
  },
  {
    "text": "curve wasn't a steep one it was it wasn't a difficult jump for us to make and we were able to upsc in it pretty",
    "start": "400080",
    "end": "406000"
  },
  {
    "text": "quickly uh the second thing so if you're developing a kubar operator that",
    "start": "406000",
    "end": "412039"
  },
  {
    "text": "reconciles your desired state in a custom resource with some external system or external API you can you find",
    "start": "412039",
    "end": "419879"
  },
  {
    "text": "that it can get really complicated really really quickly and from my experience anyway I find that it's probably because if you generate a cube",
    "start": "419879",
    "end": "427599"
  },
  {
    "text": "Builder operator uh you're given a single reconcile function reconcile Loop",
    "start": "427599",
    "end": "433400"
  },
  {
    "text": "where you need to insert all of your custom logic so it needs to handle all of the crud operations on a custom",
    "start": "433400",
    "end": "438520"
  },
  {
    "text": "resource then off of that you need to handle whatever external API calls you need to make all of that need to be done",
    "start": "438520",
    "end": "444479"
  },
  {
    "text": "quite importantly and so it can get really complicated really quickly um",
    "start": "444479",
    "end": "449520"
  },
  {
    "text": "obviously you can structure your code in such way that you don't have to do it that way but what crosspin does is it kind of gives you like I said that layer",
    "start": "449520",
    "end": "456599"
  },
  {
    "text": "of abstraction and a kind of a a separation a logical separation of",
    "start": "456599",
    "end": "461960"
  },
  {
    "text": "functionality for you to then insert your business Logic on top of so it gives you a cleaner starting point and",
    "start": "461960",
    "end": "468000"
  },
  {
    "text": "uh it just reduces Co complexity and reduces software engineering overhead um",
    "start": "468000",
    "end": "474840"
  },
  {
    "text": "so then the last thing so I've down here um transparency of manage resources",
    "start": "474840",
    "end": "480199"
  },
  {
    "text": "through conditions so I conditions is like one of these extra utilities or",
    "start": "480199",
    "end": "485840"
  },
  {
    "text": "pieces of functionality the crossplane gives you to help you write a controller for this type of use case um and",
    "start": "485840",
    "end": "494280"
  },
  {
    "text": "conditions specifically we lean on heavily with provider so they give you kind of visibility into your resources",
    "start": "494280",
    "end": "501759"
  },
  {
    "text": "um they're both machine readable and human readable so uh like I said we lean on them really heavily and uh that's",
    "start": "501759",
    "end": "508360"
  },
  {
    "text": "just kind of one utility that we use uh so how do we do that so this would be",
    "start": "508360",
    "end": "515200"
  },
  {
    "text": "kind of a really familiar output to well anyone who has developed in kubernetes but specifically anybody who uh knows",
    "start": "515200",
    "end": "522760"
  },
  {
    "text": "crossplane that's just a cubel get output of a booket resource test booket and you'll see there the things there",
    "start": "522760",
    "end": "529760"
  },
  {
    "text": "you can see the age it's 10 seconds old but the uh ready and sync these are",
    "start": "529760",
    "end": "535080"
  },
  {
    "text": "crossplane conditions that you get from crossplane so what we found is these",
    "start": "535080",
    "end": "540680"
  },
  {
    "text": "conditions kind of match really conveniently with the semantics that we had in mind for our booket resource uh",
    "start": "540680",
    "end": "547760"
  },
  {
    "text": "so I explain what I mean by that so what this looks like in real life this is like a visual representation of that",
    "start": "547760",
    "end": "554560"
  },
  {
    "text": "bucket you can see there's a bucket it's called an MR here a managed resource",
    "start": "554560",
    "end": "559760"
  },
  {
    "text": "which is basically crossplane speak for custom resource or two kind of interchangeable someone from crossan",
    "start": "559760",
    "end": "565120"
  },
  {
    "text": "will probably correct me on that but for now you can just look at the booket manag resource was created by a user um",
    "start": "565120",
    "end": "571120"
  },
  {
    "text": "providers have then attempts to reconcile that it does so by creating a single uh S3 bucket on each of our Seth",
    "start": "571120",
    "end": "579360"
  },
  {
    "text": "clusters and you can see from the diagram it was successful on one of those and it failed on two uh but for us",
    "start": "579360",
    "end": "586560"
  },
  {
    "text": "what that means in terms of condition is the book manage resource is considered ready once it's once it's created on any",
    "start": "586560",
    "end": "592959"
  },
  {
    "text": "back end um so you might say well why why is that because obviously it's failed into the reason is if you're a",
    "start": "592959",
    "end": "600120"
  },
  {
    "text": "user you only need one instance of that booket you don't need it with 10 other replicas so as far as provider is",
    "start": "600120",
    "end": "607120"
  },
  {
    "text": "concerned the booket is ready to use by the user but it's not synced so what this means is provider can continue to",
    "start": "607120",
    "end": "613079"
  },
  {
    "text": "reconcile in the background and attempt to overcome whatever transient errors are happening to stop it from being",
    "start": "613079",
    "end": "618399"
  },
  {
    "text": "created on those remaining SE clusters uh so the same booket again you can see the age now it's 40 seconds old",
    "start": "618399",
    "end": "625000"
  },
  {
    "text": "and the two conditions now it's both ready and it's synced and you can see",
    "start": "625000",
    "end": "630800"
  },
  {
    "text": "what that looks like in real life whatever errors were being encountered by provider SE have been overcome and",
    "start": "630800",
    "end": "636200"
  },
  {
    "text": "the booket is now created on all three SEF clusters and what that means is that it's synced because it's been created on",
    "start": "636200",
    "end": "641720"
  },
  {
    "text": "all backends uh I should mention this slide is slightly out of date we added a feature recently minimum replicas so you",
    "start": "641720",
    "end": "648600"
  },
  {
    "text": "no longer need to have the bucket created on all backends for it to be synced you just need to have it reach the minimum recus",
    "start": "648600",
    "end": "655839"
  },
  {
    "text": "quota so I also mentioned at the start that we needed visibility",
    "start": "655839",
    "end": "662040"
  },
  {
    "text": "into uh our backends because of the asynchronous operations so what we looked at there was the conditions of",
    "start": "662040",
    "end": "668160"
  },
  {
    "text": "the overall booket managed resource which represents a booket in itself but we need visibility into each specific",
    "start": "668160",
    "end": "674920"
  },
  {
    "text": "replica on each um Seth cluster um so we",
    "start": "674920",
    "end": "680320"
  },
  {
    "text": "we expanded on the idea of conditions by kind of extending the book at status with these what are called here",
    "start": "680320",
    "end": "686600"
  },
  {
    "text": "individualized conditions so you can see uh up the top there hopefully you can",
    "start": "686600",
    "end": "691639"
  },
  {
    "text": "read it underneath that there's a list of backends and those backends are the SEF clusters that that book it was",
    "start": "691639",
    "end": "697639"
  },
  {
    "text": "supposed to be created on so for Seth cluster a uh the condition is ready it was created successfully for Seth",
    "start": "697639",
    "end": "703720"
  },
  {
    "text": "cluster B the same and then for Seth cluster c um some kind of error has been encountered and because of those",
    "start": "703720",
    "end": "710720"
  },
  {
    "text": "conditions we can see the last transition time the message gives us the um the relative S3 error that we got",
    "start": "710720",
    "end": "717959"
  },
  {
    "text": "from the Seth cluster and uh so that's that's it on a more granular granular",
    "start": "717959",
    "end": "723880"
  },
  {
    "text": "level and then down below you can see the actual conditions of the booket resource itself those are what we just",
    "start": "723880",
    "end": "728920"
  },
  {
    "text": "looked at previously and obviously it's ready but it's not synced because it's failed on one back end so this is useful",
    "start": "728920",
    "end": "735360"
  },
  {
    "text": "uh obviously for platform Engineers to come along and be able to see okay will booket failed here when it failed why it",
    "start": "735360",
    "end": "740560"
  },
  {
    "text": "failed Etc uh we also use um health or",
    "start": "740560",
    "end": "746720"
  },
  {
    "text": "conditions to monitor the health of our back so again if you're familiar with crossin you'll be familiar with the idea",
    "start": "746720",
    "end": "753079"
  },
  {
    "text": "of a provider config uh so in provider sets World a SE each SEF cluster is",
    "start": "753079",
    "end": "759880"
  },
  {
    "text": "represented by a provider config object and uh within provider SEF then itself we have a additional controller",
    "start": "759880",
    "end": "766600"
  },
  {
    "text": "reconcile Loop which does periodic health checks on each SEF cluster and then updates the uh the relative",
    "start": "766600",
    "end": "773639"
  },
  {
    "text": "provider config statuses with the health check condition uh so that's an example there of a a failure again it's it's got",
    "start": "773639",
    "end": "781240"
  },
  {
    "text": "the same machine readable format in terms of its condition even though it's a it's a customized one as opposed to",
    "start": "781240",
    "end": "787160"
  },
  {
    "text": "what you get specifically out of the box from crossband this is our own health check um condition and again you can see",
    "start": "787160",
    "end": "794000"
  },
  {
    "text": "last transition time and the reason it failed so again this is useful a for a platform engineer to come along and see",
    "start": "794000",
    "end": "799480"
  },
  {
    "text": "why is a cluster unhealthy and B for provider SE itself because now it knows not to schedule any more buckets to this",
    "start": "799480",
    "end": "805800"
  },
  {
    "text": "this cluster while it's unhealthy uh so that's it for me I will hand over to",
    "start": "805800",
    "end": "812160"
  },
  {
    "text": "reard so I would like to speak a few words about this power of this architecture that exactly kubernetes",
    "start": "813880",
    "end": "820920"
  },
  {
    "text": "gives us everything we need out of the box uh we just deploy the application and uh enjoy the result uh crossplane",
    "start": "820920",
    "end": "829199"
  },
  {
    "text": "gives us the possibility to manage external resources out out of the kubernetes cluster which we exactly need",
    "start": "829199",
    "end": "835839"
  },
  {
    "text": "and the CNC of landscape helps us solving other difficult which we have doing operational logging and everything",
    "start": "835839",
    "end": "843360"
  },
  {
    "text": "that this landscape is always growing so we have options to select our tools but",
    "start": "843360",
    "end": "849720"
  },
  {
    "text": "one of my main favorite point is we have full control of what and when to reconcile so we are able to reconcile",
    "start": "849720",
    "end": "857680"
  },
  {
    "text": "individual buckets and actively monitoring them with the crossplane and also we are able to uh reconcile set of",
    "start": "857680",
    "end": "865120"
  },
  {
    "text": "buckets based on buil-in or custom labels and also we are able to reconcile",
    "start": "865120",
    "end": "870720"
  },
  {
    "text": "the buckets based on the hat check events which we uh foring during the",
    "start": "870720",
    "end": "875880"
  },
  {
    "text": "periodic head check and exactly you can build your own business logic based on",
    "start": "875880",
    "end": "881600"
  },
  {
    "text": "clo native events so if you have if you would like to do anything with buckets you just uh watch the the sorry the",
    "start": "881600",
    "end": "889440"
  },
  {
    "text": "buckets on the kubernetes API 7 and you can react at any kind of uh",
    "start": "889440",
    "end": "894480"
  },
  {
    "text": "event but it's easy to speak about it so let's do the the",
    "start": "894480",
    "end": "902480"
  },
  {
    "text": "demo",
    "start": "902480",
    "end": "905480"
  },
  {
    "text": "so first of all we have three identical providers for Simplicity I'm using local",
    "start": "907959",
    "end": "916720"
  },
  {
    "text": "tech for this demo but as you can see we have three of them and the head check is",
    "start": "916720",
    "end": "924000"
  },
  {
    "text": "active it is on and the interval is 2 seconds so I can apply this on the",
    "start": "924000",
    "end": "932519"
  },
  {
    "text": "cluster I have created the all the providers and we have a a bucket here it",
    "start": "937959",
    "end": "947480"
  },
  {
    "text": "is a simple bucket that we need some validation and the autop function is is",
    "start": "947480",
    "end": "953079"
  },
  {
    "text": "true I will speak about this a bit later and and then I can apply this",
    "start": "953079",
    "end": "960720"
  },
  {
    "text": "buckets so let's see what's happened on the cluster I have a command to watch",
    "start": "960720",
    "end": "966079"
  },
  {
    "text": "periodically the labels of this bucket exactly the labels are let's say the the",
    "start": "966079",
    "end": "973120"
  },
  {
    "text": "desire state which uh backends had been targeted for this bucket and I have",
    "start": "973120",
    "end": "979639"
  },
  {
    "text": "another command which is able to check",
    "start": "979639",
    "end": "985720"
  },
  {
    "text": "the so it's a very small screen but it is fetching the status of",
    "start": "986800",
    "end": "995319"
  },
  {
    "text": "this bucket exactly the status represents the last known state of uh",
    "start": "995319",
    "end": "1000480"
  },
  {
    "text": "this bucket so back to the labels you can see it's autop ped and it's up here",
    "start": "1000480",
    "end": "1006680"
  },
  {
    "text": "on all three uh back ends so what ah the other nice command",
    "start": "1006680",
    "end": "1016480"
  },
  {
    "text": "is we can monitor the bucket on the actual back ends this is the the local t",
    "start": "1016480",
    "end": "1023759"
  },
  {
    "text": "b back end and you can see the bucket is H exists it's available and I do the",
    "start": "1023759",
    "end": "1030280"
  },
  {
    "text": "same command for the loc C uh back end and you see the bucket is",
    "start": "1030280",
    "end": "1036880"
  },
  {
    "text": "exists there so the next step I would like to show you is and don't do this at",
    "start": "1036880",
    "end": "1042880"
  },
  {
    "text": "production I would destroy one of the the providers the local t providers and",
    "start": "1042880",
    "end": "1050160"
  },
  {
    "text": "set the replicas to zero so I destroy the the back end and if you see in this",
    "start": "1050160",
    "end": "1056760"
  },
  {
    "text": "box that there is no response from this back end and um it's time to speak about",
    "start": "1056760",
    "end": "1064200"
  },
  {
    "text": "this autop feature that once the back bucket is available all of the back ends",
    "start": "1064200",
    "end": "1069960"
  },
  {
    "text": "or reach the minimum replicas which we said uh this the provider uh poses the",
    "start": "1069960",
    "end": "1076720"
  },
  {
    "text": "reconcilation of this bucket because because we can't keep in the memory every bucket we would like to reconcile",
    "start": "1076720",
    "end": "1083520"
  },
  {
    "text": "so in this case we just sleep the reconcilation of this bucket so any kind of heel check events we can wake up the",
    "start": "1083520",
    "end": "1089960"
  },
  {
    "text": "bucket and uh do what we would like again",
    "start": "1089960",
    "end": "1095799"
  },
  {
    "text": "so if I disable this uh",
    "start": "1095799",
    "end": "1101280"
  },
  {
    "text": "autoing feature on this uh bucket that you can see it's nothing",
    "start": "1101280",
    "end": "1108159"
  },
  {
    "text": "happened because because uh the back endend is not available and providers have marked the back end as",
    "start": "1108159",
    "end": "1114600"
  },
  {
    "text": "failed and but on the status field you can see that only A and B are uh so the bucket",
    "start": "1114600",
    "end": "1124159"
  },
  {
    "text": "is available on the A and the B back ends so C is missing so once I set the replicas to",
    "start": "1124159",
    "end": "1131159"
  },
  {
    "text": "one and the back end games online again after a few seconds we can see",
    "start": "1131159",
    "end": "1137120"
  },
  {
    "text": "that the back end is online again but it does not contains the",
    "start": "1137120",
    "end": "1142640"
  },
  {
    "text": "bucket we have an error here see hopefully after a while",
    "start": "1147280",
    "end": "1156880"
  },
  {
    "text": "F there a few",
    "start": "1159480",
    "end": "1163158"
  },
  {
    "text": "seconds",
    "start": "1167720",
    "end": "1170720"
  },
  {
    "text": "what is happening sorry ah it's appear we have the bucket",
    "start": "1175159",
    "end": "1182039"
  },
  {
    "text": "on on the the missing back end",
    "start": "1182039",
    "end": "1187520"
  },
  {
    "text": "uh this should happen so in this case I disabled and enabled Auto uh POS by",
    "start": "1187520",
    "end": "1195200"
  },
  {
    "text": "manually but this should happen uh automatic I don't need to change uh the bucket",
    "start": "1195200",
    "end": "1202720"
  },
  {
    "text": "itself because the he check Recon there uh wakes up every bucket uh which is",
    "start": "1202720",
    "end": "1208840"
  },
  {
    "text": "affected in this uh scenario so hopefully the bucket will be available",
    "start": "1208840",
    "end": "1215320"
  },
  {
    "text": "again after I upscaled uh the cluster and the bucket",
    "start": "1215320",
    "end": "1221400"
  },
  {
    "text": "is on this back end right so the next scenario is very interesting that I",
    "start": "1221400",
    "end": "1228840"
  },
  {
    "text": "scale the local STX C back end again but this time I",
    "start": "1228840",
    "end": "1236640"
  },
  {
    "text": "disable synchronizing of this bucket by the label so I set the local C label to",
    "start": "1236640",
    "end": "1244640"
  },
  {
    "text": "false directly and you can see it has changed here that means that this bucket has to",
    "start": "1244640",
    "end": "1251880"
  },
  {
    "text": "be available on these two backends but it's not mandatory on the third one so",
    "start": "1251880",
    "end": "1257880"
  },
  {
    "text": "if I start the back endend",
    "start": "1257880",
    "end": "1262960"
  },
  {
    "text": "again it won't",
    "start": "1266799",
    "end": "1270320"
  },
  {
    "text": "create it won't create the bucket on this back end because I temporary disabled",
    "start": "1272320",
    "end": "1278679"
  },
  {
    "text": "it we can wait a few seconds but you can believe in me so anytime I can enable",
    "start": "1278679",
    "end": "1287159"
  },
  {
    "text": "the synchronization on this backend by setting the label",
    "start": "1287159",
    "end": "1292240"
  },
  {
    "text": "through as you see it I set the TB to and it's appear in the back end",
    "start": "1293080",
    "end": "1300640"
  },
  {
    "text": "again and that is the demo I wanted to show you and uh it's time to talk about",
    "start": "1300640",
    "end": "1309880"
  },
  {
    "text": "uh yeah performance but before the performance that's a a small summary of",
    "start": "1309880",
    "end": "1315120"
  },
  {
    "text": "everything that we absolutely love kubernetes and also cross plane it is very to easy to develop but a bit harder",
    "start": "1315120",
    "end": "1322200"
  },
  {
    "text": "to scale and where we are in the in the journey that we had feature freeze the",
    "start": "1322200",
    "end": "1328400"
  },
  {
    "text": "first version of the the provider uh you have to know that the objects are not",
    "start": "1328400",
    "end": "1333440"
  },
  {
    "text": "the scope for the first release and we are open for any kind of contribution so",
    "start": "1333440",
    "end": "1339279"
  },
  {
    "text": "if you would like to join to an Innovative open source project or working on cutting edge technology just",
    "start": "1339279",
    "end": "1345960"
  },
  {
    "text": "feel free to reach us on on on GitHub so the next topic is uh",
    "start": "1345960",
    "end": "1352039"
  },
  {
    "text": "performance and scalability before I jump into please raise your hands if you believe you have",
    "start": "1352039",
    "end": "1358880"
  },
  {
    "text": "more than 5,000 records in your etcd cluster under your",
    "start": "1358880",
    "end": "1366520"
  },
  {
    "text": "Ed a few",
    "start": "1367559",
    "end": "1371278"
  },
  {
    "text": "10,000s things start to be tricky at that scale so the first slide is for the",
    "start": "1373159",
    "end": "1379559"
  },
  {
    "text": "ones who are rushing to the plane it's just a summary I would like to talk about two dimensions of of scaling one",
    "start": "1379559",
    "end": "1387039"
  },
  {
    "text": "dimension is the vertical where we increase the number of the custom resource definitions so we have lots of",
    "start": "1387039",
    "end": "1394480"
  },
  {
    "text": "kind of objects in the in the API server the other dimension is the horizontal",
    "start": "1394480",
    "end": "1399720"
  },
  {
    "text": "scaling when we scale the number of the custom resources themselves so we have",
    "start": "1399720",
    "end": "1404919"
  },
  {
    "text": "lots of resource from from one type so when we increase the number of the",
    "start": "1404919",
    "end": "1411520"
  },
  {
    "text": "custom resource definitions that the API Discovery should be a big issue exactly it should be a system killer issue if",
    "start": "1411520",
    "end": "1418159"
  },
  {
    "text": "you have some misconfigured clients they can destroy the API server at all and",
    "start": "1418159",
    "end": "1424320"
  },
  {
    "text": "also because of the API Discovery and other kind of U backend jobs that uh you",
    "start": "1424320",
    "end": "1429840"
  },
  {
    "text": "can experience very poor API server responsiveness and you have you have to",
    "start": "1429840",
    "end": "1435440"
  },
  {
    "text": "count with very high peaks of CPU and memory low those when API server starts",
    "start": "1435440",
    "end": "1440520"
  },
  {
    "text": "to do some background jobs on on that many uh objects kind um from the other",
    "start": "1440520",
    "end": "1448000"
  },
  {
    "text": "side of the story the horizontal uh thing that unfed lists operations should",
    "start": "1448000",
    "end": "1455760"
  },
  {
    "text": "be an issue they can kill the API server if you start a few of them uh to fetch",
    "start": "1455760",
    "end": "1462520"
  },
  {
    "text": "every custom resource definition storage is the most critical part of of everything and also you have to count",
    "start": "1462520",
    "end": "1469559"
  },
  {
    "text": "with the high memory and the uh Network utilization because lots of data moving",
    "start": "1469559",
    "end": "1476640"
  },
  {
    "text": "around and some data are moving redundantly and multiple times so It's",
    "start": "1476640",
    "end": "1482240"
  },
  {
    "text": "tricky to predict so just a few words about the",
    "start": "1482240",
    "end": "1488600"
  },
  {
    "text": "the vertical scaling because it's not an issue for us because we have only one",
    "start": "1488600",
    "end": "1494120"
  },
  {
    "text": "resource the problems tend to start around 500 custom resource definitions",
    "start": "1494120",
    "end": "1499159"
  },
  {
    "text": "which sounds pretty much but keep in mind that some crossplane providers has",
    "start": "1499159",
    "end": "1505200"
  },
  {
    "text": "more than 800 custom resource definitions so exactly one provider is able to to destroy your cluster",
    "start": "1505200",
    "end": "1513480"
  },
  {
    "text": "performance but luckily the crossplane have a new feature for partially deploy",
    "start": "1513480",
    "end": "1519000"
  },
  {
    "text": "custom resource definition so it's is already solve you have to keep in mind",
    "start": "1519000",
    "end": "1524200"
  },
  {
    "text": "that some clients are not designed to work with more than 50 or 100 custom",
    "start": "1524200",
    "end": "1530320"
  },
  {
    "text": "resource definition the the cube cutle command is one of them uh my next advice",
    "start": "1530320",
    "end": "1536120"
  },
  {
    "text": "is not relevant anymore I think but always use kubernetes 1. 60 uh 26 plus",
    "start": "1536120",
    "end": "1544640"
  },
  {
    "text": "because the crossplane forks did awesome work to optimize kubernetes and lots of",
    "start": "1544640",
    "end": "1550960"
  },
  {
    "text": "components around the custom res definitions and the API",
    "start": "1550960",
    "end": "1556360"
  },
  {
    "text": "Discovery so the next topic is the horizontal scaling of the the story and the first layer I",
    "start": "1556360",
    "end": "1563880"
  },
  {
    "text": "would like to mention is the stor side which is exactly not part of this presentation it's a it's a very deep",
    "start": "1563880",
    "end": "1571600"
  },
  {
    "text": "topic alone but itcd performance is is very critical but etcd performance",
    "start": "1571600",
    "end": "1578679"
  },
  {
    "text": "depends on the underlying underlying storage so exactly the storage speed is",
    "start": "1578679",
    "end": "1583880"
  },
  {
    "text": "very diff very critical for Random Access so this is a important thing so",
    "start": "1583880",
    "end": "1590600"
  },
  {
    "text": "what you can do is hire experts who know what they do and based on your storage",
    "start": "1590600",
    "end": "1595919"
  },
  {
    "text": "type it's pretty easy to achieve the the case in the in the picture you can see that the etcd is is sleeping all threads",
    "start": "1595919",
    "end": "1604640"
  },
  {
    "text": "are waiting for Io and once etcd is dead the next component would be the API",
    "start": "1604640",
    "end": "1611760"
  },
  {
    "text": "manager after a while it would dead and when API manager is down the kubernetes",
    "start": "1611760",
    "end": "1617200"
  },
  {
    "text": "controller manager goes down so the entire cluster just uh FS falls",
    "start": "1617200",
    "end": "1624159"
  },
  {
    "text": "down the other side I would like to mention is the controller side ex the",
    "start": "1624159",
    "end": "1629640"
  },
  {
    "text": "provider itself the operator What we what we develop the main Bott like here is there is the memory and the reason of",
    "start": "1629640",
    "end": "1636120"
  },
  {
    "text": "this that each controller instance U has a cache a local cache which holds all of",
    "start": "1636120",
    "end": "1643120"
  },
  {
    "text": "the uh resources it is reconciling and",
    "start": "1643120",
    "end": "1648200"
  },
  {
    "text": "all the last non state is in the memory in every instance I don't suggest to turn this",
    "start": "1648200",
    "end": "1654000"
  },
  {
    "text": "this off because otherwise you should have other troubles but you have to find the best",
    "start": "1654000",
    "end": "1660679"
  },
  {
    "text": "uh cach synchronization period uh of your system and also you have to filter",
    "start": "1660679",
    "end": "1667559"
  },
  {
    "text": "the watch uh filter the resources by label uh because you can't uh watch",
    "start": "1667559",
    "end": "1673880"
  },
  {
    "text": "every buckets when you have 100,000 of of",
    "start": "1673880",
    "end": "1679480"
  },
  {
    "text": "them you have to count with longer startups because if you have that that",
    "start": "1679480",
    "end": "1685279"
  },
  {
    "text": "much of resources it took minutes for the controller to fill up the cash",
    "start": "1685279",
    "end": "1692840"
  },
  {
    "text": "and um also you have to configure the timeout because uh it is very easy to",
    "start": "1692840",
    "end": "1700360"
  },
  {
    "text": "find yourself in a situation when every client is always times out because that you have too much too much uh",
    "start": "1700360",
    "end": "1707120"
  },
  {
    "text": "resources always take care on your rate limits and burst and timeouts and",
    "start": "1707120",
    "end": "1712600"
  },
  {
    "text": "actively monitor them because misconfigured clients otherwise can uh",
    "start": "1712600",
    "end": "1717640"
  },
  {
    "text": "kill your API server performance and um in our experiences it",
    "start": "1717640",
    "end": "1723919"
  },
  {
    "text": "is much cheaper to retry the failed actions in a controller than dropping",
    "start": "1723919",
    "end": "1729559"
  },
  {
    "text": "everything and recing the object and building everything again so if you have any failure on",
    "start": "1729559",
    "end": "1736039"
  },
  {
    "text": "on better to retry it the once once you have everything in the memory and everything in in place and uh one of the",
    "start": "1736039",
    "end": "1744679"
  },
  {
    "text": "trickiest part of this is you have to forget leader elected oper",
    "start": "1744679",
    "end": "1750279"
  },
  {
    "text": "operators uh it should be a bit tricky and always ensure your best",
    "start": "1750279",
    "end": "1757039"
  },
  {
    "text": "reconciliation concurrency how many items you reconcile and the at the same time and sleep and wake up resource",
    "start": "1757039",
    "end": "1764519"
  },
  {
    "text": "reconciliation as I mentioned the autopa feature does this we can uh put uh some",
    "start": "1764519",
    "end": "1771960"
  },
  {
    "text": "buckets to sleep I would like to talk about the",
    "start": "1771960",
    "end": "1777399"
  },
  {
    "text": "from the kubernetes API server side of uh the performance my first advice is use the",
    "start": "1777399",
    "end": "1783919"
  },
  {
    "text": "latest ker because Engineers of Google changed the the Kel stack and they have",
    "start": "1783919",
    "end": "1789760"
  },
  {
    "text": "found uh big performance Improvement on the TCP sa uh design your network to be",
    "start": "1789760",
    "end": "1797399"
  },
  {
    "text": "able to handle as many active connections as possible because there are Watchers",
    "start": "1797399",
    "end": "1804360"
  },
  {
    "text": "everywhere from the CP and memory side that infinite is the best of course on",
    "start": "1804360",
    "end": "1809960"
  },
  {
    "text": "the server side you also have to configure rate limits and burst and timeouts uh because this is the first",
    "start": "1809960",
    "end": "1818480"
  },
  {
    "text": "line protection of your API server the pain point is that custom",
    "start": "1818480",
    "end": "1824240"
  },
  {
    "text": "resource slices are misses so we can't paginate custom resource is when we fetch it from the kubernetes API",
    "start": "1824240",
    "end": "1831919"
  },
  {
    "text": "server and you can only scale kubernetes API server vertically because it's a",
    "start": "1831919",
    "end": "1837880"
  },
  {
    "text": "leader elected uh it has a leader election architecture so there is only one leader at a",
    "start": "1837880",
    "end": "1844360"
  },
  {
    "text": "time and um best if you can configure a proxy service in front of your API",
    "start": "1844360",
    "end": "1851320"
  },
  {
    "text": "server to to avoid unnecessary load and repetitive",
    "start": "1851320",
    "end": "1858000"
  },
  {
    "text": "load on the on the server and you can delegate load via with the aggregation",
    "start": "1858000",
    "end": "1863159"
  },
  {
    "text": "API and it also should have to decrease the load on the API",
    "start": "1863159",
    "end": "1870000"
  },
  {
    "text": "server related to regarding to the configuration options we have there are",
    "start": "1871720",
    "end": "1877000"
  },
  {
    "text": "only just a few configuration options like B cach disabled and uh event time",
    "start": "1877000",
    "end": "1883000"
  },
  {
    "text": "to leave and the mutating maximum requesting flight are the most important",
    "start": "1883000",
    "end": "1889600"
  },
  {
    "text": "so there are not too too much configuration to set",
    "start": "1889600",
    "end": "1895200"
  },
  {
    "text": "up so I think everything is prepared we know everything so it's time to start",
    "start": "1895200",
    "end": "1901679"
  },
  {
    "text": "the cluster so coders start your",
    "start": "1901679",
    "end": "1906790"
  },
  {
    "text": "[Music] engines it was a short",
    "start": "1906790",
    "end": "1912440"
  },
  {
    "text": "drive um kubernetes API server after May 20, thousands of buckets we experience",
    "start": "1912440",
    "end": "1918679"
  },
  {
    "text": "the object uh out of memory errors in the kubernetes API server and after uh",
    "start": "1918679",
    "end": "1926760"
  },
  {
    "text": "after the canel tried to restart the API server we experience that we have a",
    "start": "1926760",
    "end": "1933240"
  },
  {
    "text": "higher Bas line compared to the ini compared to the initial Bas line but the",
    "start": "1933240",
    "end": "1938679"
  },
  {
    "text": "the tendency is the same that it will F the memory all of the memory available",
    "start": "1938679",
    "end": "1944880"
  },
  {
    "text": "and after a few restart that can just termin is the process and we don't have API server anymore so we lose the",
    "start": "1944880",
    "end": "1951840"
  },
  {
    "text": "cluster itself after a few hours of Investigation I have found that the",
    "start": "1951840",
    "end": "1958399"
  },
  {
    "text": "watch cach is the the one who is trying to keep everything in the memory so I",
    "start": "1958399",
    "end": "1965240"
  },
  {
    "text": "just uh disabled the watch cach and I hopefully you you can see that the memory consumptions went to normal and",
    "start": "1965240",
    "end": "1973399"
  },
  {
    "text": "we don't have any memory issues uh with with this cash but the the question is",
    "start": "1973399",
    "end": "1981639"
  },
  {
    "text": "what is Cash good for and the main reason of this cash is to speed up least",
    "start": "1981639",
    "end": "1987840"
  },
  {
    "text": "kind of operation and we fetch lots of data from the kubernetes API",
    "start": "1987840",
    "end": "1994039"
  },
  {
    "text": "server but unfortunately this isn't the case",
    "start": "1994039",
    "end": "1999639"
  },
  {
    "text": "because uh when you have 50,000 buckets building the cash is almost the same",
    "start": "1999639",
    "end": "2007399"
  },
  {
    "text": "time as fetching the data and sending over the network so maybe you can see the",
    "start": "2007399",
    "end": "2014039"
  },
  {
    "text": "numbers but it was 53 seconds without the cache and it was 1 minute and 41",
    "start": "2014039",
    "end": "2020519"
  },
  {
    "text": "seconds with the cache so it seems cash is for speeding up things but not at",
    "start": "2020519",
    "end": "2026559"
  },
  {
    "text": "this scale so that's just a summary benefits",
    "start": "2026559",
    "end": "2032440"
  },
  {
    "text": "are not included kubernetes API server is a single point of failure so",
    "start": "2032440",
    "end": "2038440"
  },
  {
    "text": "you have to so you have to deal with those limitations",
    "start": "2038440",
    "end": "2043840"
  },
  {
    "text": "and in our case this system is an internal system so we can deal with them",
    "start": "2043840",
    "end": "2049480"
  },
  {
    "text": "but these limitations are driving the design choices you made in the in the at the system so the API server does not",
    "start": "2049480",
    "end": "2057440"
  },
  {
    "text": "scale well and it is pretty easy to kill with unfilter at least operations so you",
    "start": "2057440",
    "end": "2064280"
  },
  {
    "text": "have to take care on on this part uh the server and client side burst",
    "start": "2064280",
    "end": "2069679"
  },
  {
    "text": "are first line protection of your server and the leader leaderless operation",
    "start": "2069679",
    "end": "2075158"
  },
  {
    "text": "operators are tricky and not so common just you can't find too many information",
    "start": "2075159",
    "end": "2080358"
  },
  {
    "text": "about them and the object reconciliation POS logic is is mandatory and you have",
    "start": "2080359",
    "end": "2086839"
  },
  {
    "text": "to count with some clients may not tolerate huge data sets or or large",
    "start": "2086839",
    "end": "2093000"
  },
  {
    "text": "timeouts but the question what we did is can we go",
    "start": "2093000",
    "end": "2099359"
  },
  {
    "text": "further can we do 100,000 buckets per",
    "start": "2099359",
    "end": "2104480"
  },
  {
    "text": "second and the answer is uh yes we should but our F future plan with this",
    "start": "2104480",
    "end": "2112240"
  },
  {
    "text": "project is seamless integration with distributed control planes like kcp or",
    "start": "2112240",
    "end": "2117760"
  },
  {
    "text": "carada where we can distribute all the load across multiple regions and data",
    "start": "2117760",
    "end": "2124599"
  },
  {
    "text": "centers what we want so what we would like to achieve is a single entry point",
    "start": "2124599",
    "end": "2131960"
  },
  {
    "text": "infinite buckets and everything is top on col native thank you so much and I think",
    "start": "2131960",
    "end": "2138200"
  },
  {
    "text": "it's time for question to",
    "start": "2138200",
    "end": "2141720"
  },
  {
    "text": "Conor",
    "start": "2144560",
    "end": "2147560"
  }
]
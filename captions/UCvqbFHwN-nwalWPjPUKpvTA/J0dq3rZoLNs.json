[
  {
    "start": "0",
    "end": "72000"
  },
  {
    "text": "thank you hey well my name is eduardo today we announced this session called about fluency and fluent bet",
    "start": "80",
    "end": "6960"
  },
  {
    "text": "originally description session we started talking about a our new journey to metrics right",
    "start": "6960",
    "end": "12960"
  },
  {
    "text": "but before to jump into metric we're thinking okay maybe we need to go to a deep dive explanation",
    "start": "12960",
    "end": "19520"
  },
  {
    "text": "why this is a good deal and how things work in logs how do we handle them before to jump",
    "start": "19520",
    "end": "25439"
  },
  {
    "text": "into the metric space so anybody of you is new to fluentdm fluent bed if so",
    "start": "25439",
    "end": "30960"
  },
  {
    "text": "please raise your hand okay perfect no problem",
    "start": "30960",
    "end": "39200"
  },
  {
    "text": "as the same enemies evado silva that's my hand on github twitter or most of the",
    "start": "39200",
    "end": "44800"
  },
  {
    "text": "stuff and the creator of my intended this project called fluenbet i'm maintainer of the fluency ecosystem",
    "start": "44800",
    "end": "51600"
  },
  {
    "text": "i'm the founder of this company called calyptia which we call the first mile observability company which was started",
    "start": "51600",
    "end": "57760"
  },
  {
    "text": "on top of the open source ecosystem that we created and has been the cncf",
    "start": "57760",
    "end": "63920"
  },
  {
    "text": "for a couple of years already and it came from the treasure data team where we created all this technology",
    "start": "63920",
    "end": "72680"
  },
  {
    "start": "72000",
    "end": "155000"
  },
  {
    "text": "so the fluency ecosystem we have to start saying that fluentd is",
    "start": "72880",
    "end": "79840"
  },
  {
    "text": "a graduated project from the cncf that means vendor neutral wide adoption in the",
    "start": "79840",
    "end": "86000"
  },
  {
    "text": "market and where companies are contributing in a daily basis to the project",
    "start": "86000",
    "end": "91680"
  },
  {
    "text": "a fluency started 10 years ago and after that well around 2016 we wanted to have a",
    "start": "91680",
    "end": "98799"
  },
  {
    "text": "more lightweight solution than fluency not because fluent was bad but because we were targeting embedded linux at that",
    "start": "98799",
    "end": "105040"
  },
  {
    "text": "time but at the same time well six seven years ago kubernetes was",
    "start": "105040",
    "end": "110560"
  },
  {
    "text": "taken off the container space was growing and people started trying out fluent bed",
    "start": "110560",
    "end": "115920"
  },
  {
    "text": "with continued containers because it was a light with solution that fluently flowing this within a ruby flume beat is",
    "start": "115920",
    "end": "122479"
  },
  {
    "text": "written in c language right fluentd has a thousand plugins available in fluent bit we has just a hundred",
    "start": "122479",
    "end": "130080"
  },
  {
    "text": "so both projects as part of the same ecosystem same license and are considered both graduated from the cncf",
    "start": "130080",
    "end": "138000"
  },
  {
    "text": "and we're now in a journey where most of people do it to their workloads that they have in their environments",
    "start": "138000",
    "end": "145040"
  },
  {
    "text": "sometimes fluency is not capable to solve all the challenges and that's why",
    "start": "145040",
    "end": "150080"
  },
  {
    "text": "people are migrating from fluency to flowing bed nowadays",
    "start": "150080",
    "end": "156120"
  },
  {
    "start": "155000",
    "end": "576000"
  },
  {
    "text": "so there's one big observability challenge right it doesn't matter if you",
    "start": "156160",
    "end": "162000"
  },
  {
    "text": "are doing traces logins or metrics and they think that everybody wants more",
    "start": "162000",
    "end": "167040"
  },
  {
    "text": "performance more performance but at zero cost right get it for free and such",
    "start": "167040",
    "end": "172879"
  },
  {
    "text": "thing does not exist right there's nothing for free so this is a quite interesting challenge",
    "start": "172879",
    "end": "178319"
  },
  {
    "text": "because when you have your environment you always have more data more data more workloads more workloads things grows on",
    "start": "178319",
    "end": "185360"
  },
  {
    "text": "that side but in the infrastructure the way that you handle the information it's hard to scale",
    "start": "185360",
    "end": "191760"
  },
  {
    "text": "right and that's why we focus a lot of performance performance so let's talk about a bit of login and",
    "start": "191760",
    "end": "197840"
  },
  {
    "text": "how it works in general for if you are just learning about this when",
    "start": "197840",
    "end": "204480"
  },
  {
    "text": "a log message is an event triggered by the application the purpose of a locked message is to",
    "start": "204480",
    "end": "209840"
  },
  {
    "text": "say i'm working fine and doing this i got this request i got this response",
    "start": "209840",
    "end": "215440"
  },
  {
    "text": "and any kind of problems or exceptions that information in a container environment",
    "start": "215440",
    "end": "221120"
  },
  {
    "text": "usually comes from a in a row and a wrong text message that's a kind of apache message quite of old",
    "start": "221120",
    "end": "228239"
  },
  {
    "text": "and then this hits disk as a file where you have multiple records separated per",
    "start": "228239",
    "end": "233280"
  },
  {
    "text": "file i'm not saying that this is the only way to do login right some application chips logs over tcp or you",
    "start": "233280",
    "end": "239200"
  },
  {
    "text": "have firewalls that chips lock messages over udp by using syslog as a payload format",
    "start": "239200",
    "end": "246080"
  },
  {
    "text": "and when you see when you do this and you store all this information",
    "start": "246080",
    "end": "251360"
  },
  {
    "text": "it's not just about to have the information there because your goal as always said is to perform data analysis",
    "start": "251360",
    "end": "258079"
  },
  {
    "text": "right it's not about logging it's not about the tool you want to solve data analysis you wanted to know how your",
    "start": "258079",
    "end": "263520"
  },
  {
    "text": "applications are behaving any kind of exception that you have or anything that can give you some insights",
    "start": "263520",
    "end": "269759"
  },
  {
    "text": "right from what's going on with your applications so but in order to do that you need to read this information",
    "start": "269759",
    "end": "277120"
  },
  {
    "text": "kind of process it and send it out to a central place where you can run your own queries and analysis",
    "start": "277120",
    "end": "284080"
  },
  {
    "text": "you can send it to elastic stack driver or anything like that",
    "start": "284080",
    "end": "289199"
  },
  {
    "text": "now this kind of engine that collects the data and send the data out has a",
    "start": "289600",
    "end": "294639"
  },
  {
    "text": "couple of roles and a couple of tasks that he has to accomplish so collect the data perform data transformation because",
    "start": "294639",
    "end": "301199"
  },
  {
    "text": "you want to parse the information you want to unify in some format which is a quite a challenge right",
    "start": "301199",
    "end": "307840"
  },
  {
    "text": "just if you have three developers in your environment doing different projects i'm 100 sure that all of them will use a",
    "start": "307840",
    "end": "314800"
  },
  {
    "text": "different structure for the locks so when you want to do analysis on top of that data you have to realize which one or how to",
    "start": "314800",
    "end": "322240"
  },
  {
    "text": "approach them and it's really hard also there are many applications that are very noisy that generate messages that",
    "start": "322240",
    "end": "328000"
  },
  {
    "text": "you don't want and what is the problem the problem is that if you're using a back-end for example what is a common",
    "start": "328000",
    "end": "334000"
  },
  {
    "text": "example splunk they are going to charge you by the amount of data that you ingest",
    "start": "334000",
    "end": "339120"
  },
  {
    "text": "but if you're sending a bunch of data that you don't need you anyways you're going to pay for that",
    "start": "339120",
    "end": "344400"
  },
  {
    "text": "amount of data and this is where people start thinking about oh cost reduction we don't want",
    "start": "344400",
    "end": "349440"
  },
  {
    "text": "all the data we need something that can filter out information that is not required",
    "start": "349440",
    "end": "355520"
  },
  {
    "text": "right so this little engine need to be smart enough to provide all this feature set also",
    "start": "355520",
    "end": "361199"
  },
  {
    "text": "doing buffering because if i'm going to send this information to a backend database to the right side of this",
    "start": "361199",
    "end": "366800"
  },
  {
    "text": "pipeline things can go wrong and i don't know if you face it but wi-fi just",
    "start": "366800",
    "end": "372400"
  },
  {
    "text": "was we lost wi-fi for two minutes here in the conference the same thing happens in in environments right network outage",
    "start": "372400",
    "end": "379199"
  },
  {
    "text": "power outage disk failures so but if we don't save the data we don't keep a states of what we are processing and we",
    "start": "379199",
    "end": "386160"
  },
  {
    "text": "will recover we are not able to retake the states we are in a problem that's why buffering is really important",
    "start": "386160",
    "end": "392720"
  },
  {
    "text": "and we should have the ability to send the data to different backends right this is kind of a you have to be able to",
    "start": "392720",
    "end": "399520"
  },
  {
    "text": "avoid to have this trap of vendor lock-in when you get you get married with a vendor sometimes that's fine with a database club",
    "start": "399520",
    "end": "406319"
  },
  {
    "text": "provider or any kind of service but you should have the option to say okay i'm going to send this data to this",
    "start": "406319",
    "end": "412240"
  },
  {
    "text": "backend and at some point to another one because cost reduction or any kind of other strategy",
    "start": "412240",
    "end": "420160"
  },
  {
    "text": "and as i said the whole point of data centralization is data analysis right",
    "start": "420639",
    "end": "426000"
  },
  {
    "text": "and you can choose whatever you want and this is kind of the key of things of these tools around the flue in the",
    "start": "426000",
    "end": "431759"
  },
  {
    "text": "ecosystem and pretty much from a global perspective this is input and output",
    "start": "431759",
    "end": "438240"
  },
  {
    "text": "right you have an engine that process all the input process the data filter do buffering and",
    "start": "438240",
    "end": "444639"
  },
  {
    "text": "send this data out to your preferred destination now understanding this concept which",
    "start": "444639",
    "end": "451039"
  },
  {
    "text": "sounds very simple it's important to understand how to tackle problems that you get later in production like",
    "start": "451039",
    "end": "457680"
  },
  {
    "text": "you can get performance problems in the input you can get performance problems when filtering data processing the data",
    "start": "457680",
    "end": "463440"
  },
  {
    "text": "and will send this data out so in the input side you always deal",
    "start": "463440",
    "end": "470080"
  },
  {
    "text": "with io this network metrics inside the engine right which is mo the",
    "start": "470080",
    "end": "476400"
  },
  {
    "text": "input means how do i extract or receive this data inside the agents about parsing data filtering serializing data",
    "start": "476400",
    "end": "483360"
  },
  {
    "text": "because yeah you pretty much consume and generate json but when it's about to talk about",
    "start": "483360",
    "end": "489360"
  },
  {
    "text": "an agent like fluentd bit we have to serialize this data in a binary format",
    "start": "489360",
    "end": "494639"
  },
  {
    "text": "so we can do really smart optimizations on how do we handle this data internally",
    "start": "494639",
    "end": "500000"
  },
  {
    "text": "because at the end of the day you want to want to cpu low right your memory usage low and if we don't optimize on",
    "start": "500000",
    "end": "506319"
  },
  {
    "text": "those terms we will get in a really tough scenario buffering routing scheduling retries",
    "start": "506319",
    "end": "512719"
  },
  {
    "text": "requires if i'm going to send the data and something happens and i could not send it i will have to some kind of",
    "start": "512719",
    "end": "518479"
  },
  {
    "text": "logic that allows me to send this data out and in the output side there are other",
    "start": "518479",
    "end": "524959"
  },
  {
    "text": "kind of challenges network setup some of the packets used tls some others doesn't",
    "start": "524959",
    "end": "531279"
  },
  {
    "text": "every pack can use a different expect a different payload for the data right the splunk",
    "start": "531279",
    "end": "537279"
  },
  {
    "text": "splunk expect an adjacent payload that is totally different than the one specter by amazon s3",
    "start": "537279",
    "end": "543360"
  },
  {
    "text": "so we have to take this binary representation that we have and convert it back",
    "start": "543360",
    "end": "548560"
  },
  {
    "text": "to the expected payload it's kind of we unified in a in a format internally and then we encode",
    "start": "548560",
    "end": "555519"
  },
  {
    "text": "the data for the right a backend and this is what fluent does right it",
    "start": "555519",
    "end": "562880"
  },
  {
    "text": "cares for you about all this complexity of io network collection processing",
    "start": "562880",
    "end": "568320"
  },
  {
    "text": "filtering and making sure that reliable you can get your data in your backends",
    "start": "568320",
    "end": "575240"
  },
  {
    "start": "576000",
    "end": "815000"
  },
  {
    "text": "so as i said fluent bit is part of the fluent ecosystem it's under apache license and now we have more than 200",
    "start": "576640",
    "end": "583279"
  },
  {
    "text": "contributors in total and the good thing is that fluid is being used widely nowadays",
    "start": "583279",
    "end": "589360"
  },
  {
    "text": "aws google cloud microsoft azure all of them are deploying fluid and bit",
    "start": "589360",
    "end": "595279"
  },
  {
    "text": "at a really heavy scale and just from the public stats from our",
    "start": "595279",
    "end": "601120"
  },
  {
    "text": "docker hub repositories that are not related to how to deploy fluid in their own registries we have",
    "start": "601120",
    "end": "607839"
  },
  {
    "text": "around an average of two million polls or deployments per day",
    "start": "607839",
    "end": "613519"
  },
  {
    "text": "so which is an insane amount of deployments right it's like kubernetes clusters going up going down and all of",
    "start": "613519",
    "end": "619360"
  },
  {
    "text": "them are using a what majority of them are using fluid and we have a couple of companies also",
    "start": "619360",
    "end": "625600"
  },
  {
    "text": "using them for different purposes so people who runs in the cloud if you just paint at a",
    "start": "625600",
    "end": "632000"
  },
  {
    "text": "for example a kubernetes cluster in google right now you will get fluent bet on it um",
    "start": "632000",
    "end": "637760"
  },
  {
    "text": "so this is quite a challenge right so from a maintenance perspective this product has to be so stable that we",
    "start": "637760",
    "end": "644399"
  },
  {
    "text": "cannot mess up something if we wrote something bad i will mess up the whole infrastructure",
    "start": "644399",
    "end": "652480"
  },
  {
    "text": "and as i said fluent was designed with performance in mind right",
    "start": "652480",
    "end": "658000"
  },
  {
    "text": "we it was not intended to to think we're going to write something for the cloud native ecosystem that will be around in",
    "start": "658000",
    "end": "663839"
  },
  {
    "text": "five years it was not like that right we just optimized it for embedded linux we made it very optimal how to manage",
    "start": "663839",
    "end": "670320"
  },
  {
    "text": "everything and it was a good timing right the container space just came in and we just had all the pieces in place",
    "start": "670320",
    "end": "678160"
  },
  {
    "text": "also buffer management is really important right how do we optimize when we group the data how do we store this",
    "start": "678160",
    "end": "684560"
  },
  {
    "text": "data between memory file system i'm going to explain that in a few is really important",
    "start": "684560",
    "end": "691360"
  },
  {
    "text": "so talking we're going to talk about more internal details how do we serialize the data i got the questions i",
    "start": "692160",
    "end": "697600"
  },
  {
    "text": "think that was yesterday why json well the answer is we don't use json right json is a human readable",
    "start": "697600",
    "end": "704800"
  },
  {
    "text": "structure format right but for a computer it's just an array of bytes right",
    "start": "704800",
    "end": "711200"
  },
  {
    "text": "but when we have when we talk about binary formats is that we have some kind of",
    "start": "711200",
    "end": "716560"
  },
  {
    "text": "a structure we have some kind of a not in index but a way to say where's the",
    "start": "716560",
    "end": "721600"
  },
  {
    "text": "data what type of data we have and what's the length of the data right so you can see here in the table what is",
    "start": "721600",
    "end": "728000"
  },
  {
    "text": "the difference between using json and message pack from a payload payload size",
    "start": "728000",
    "end": "733440"
  },
  {
    "text": "perspective but also if i have an array it's easy for me to jump between",
    "start": "733440",
    "end": "739120"
  },
  {
    "text": "positions between one key and the other and the value inside if i do that in json i have to",
    "start": "739120",
    "end": "744959"
  },
  {
    "text": "analyze everything and go buy it per byte yeah there's quite enough optimizations around",
    "start": "744959",
    "end": "750079"
  },
  {
    "text": "but we cannot compare the performance of playing json with message pack now this",
    "start": "750079",
    "end": "755360"
  },
  {
    "text": "is not like json is bad it's about we're not going to do it we're not going to do json in internals if we can do message",
    "start": "755360",
    "end": "763200"
  },
  {
    "text": "pack and we use just json to communicate with other backends that speak that um",
    "start": "763200",
    "end": "769440"
  },
  {
    "text": "that language that format right and when we get the records for",
    "start": "769440",
    "end": "774639"
  },
  {
    "text": "example if you think that we have a file every has multiple lines every line is considered a record or an event and this",
    "start": "774639",
    "end": "782560"
  },
  {
    "text": "event get groups right in buffers which is called chunks and chang can have multiple events",
    "start": "782560",
    "end": "789760"
  },
  {
    "text": "associated under the same tag tags are useful to say all this data is coming",
    "start": "789760",
    "end": "795360"
  },
  {
    "text": "from this from this source because in the configuration at some point you will say i want to send all the data that matches",
    "start": "795360",
    "end": "802560"
  },
  {
    "text": "this criteria to this packet all the data that has attacked with other criteria to a different backend that's",
    "start": "802560",
    "end": "808639"
  },
  {
    "text": "how people split data into elasticsearch splunk with different routing rules",
    "start": "808639",
    "end": "815600"
  },
  {
    "start": "815000",
    "end": "1004000"
  },
  {
    "text": "now when talking about buffering it's really important to understand that a we have limited resources right",
    "start": "815600",
    "end": "822959"
  },
  {
    "text": "and we have a bad practice around in general in the industry that nobody thinks about memory nobody thinks about",
    "start": "822959",
    "end": "828880"
  },
  {
    "text": "cpu usage right but for a service that has to run 24 by seven",
    "start": "828880",
    "end": "834000"
  },
  {
    "text": "that doesn't have a short period of time of light it's always running processing data we have to always be optimizing",
    "start": "834000",
    "end": "841040"
  },
  {
    "text": "right how much resources we consume so we have an android approach by",
    "start": "841040",
    "end": "846079"
  },
  {
    "text": "default is all the data goes to memory so all the data means all the chunks go",
    "start": "846079",
    "end": "851279"
  },
  {
    "text": "to memory so every time that we're getting records we group them in chunks and the chunks get been filled in memory",
    "start": "851279",
    "end": "858720"
  },
  {
    "text": "but we always say that okay we have this amount of memory but we can say let's have up to this amount",
    "start": "858720",
    "end": "865519"
  },
  {
    "text": "of a memory usage by chance otherwise your service can explode right",
    "start": "865519",
    "end": "870720"
  },
  {
    "text": "the kernel is going to kill your service now in memory barfini is fine it's",
    "start": "870720",
    "end": "876240"
  },
  {
    "text": "pretty good it's the fastest mechanism but it's not persistent if you reboot the agent and you have data that has not",
    "start": "876240",
    "end": "883040"
  },
  {
    "text": "been flashed to the destination yeah that git is going to be get lost also",
    "start": "883040",
    "end": "888880"
  },
  {
    "text": "at some point if you just rely on memory the kernel could say oh you're using too much memory we're running out of it it's",
    "start": "888880",
    "end": "896000"
  },
  {
    "text": "time to sacrifice someone so guess who will be the first target right it's the agent that is consuming all this",
    "start": "896000",
    "end": "901839"
  },
  {
    "text": "information and this is where you can come up with a hybrid mechanism right all these",
    "start": "901839",
    "end": "907360"
  },
  {
    "text": "techniques are not new they're quite usually in database design right so there's no black magic here is that",
    "start": "907360",
    "end": "914639"
  },
  {
    "text": "having a file system buffering helps a lot right so it's always good to have this kind of iron mechanism where the",
    "start": "914639",
    "end": "921279"
  },
  {
    "text": "data that is getting in if we cannot put it in memory it goes to the file system right",
    "start": "921279",
    "end": "926959"
  },
  {
    "text": "usually your file system will be times bigger than the capacity that you have in memory but you can say oh but also",
    "start": "926959",
    "end": "934000"
  },
  {
    "text": "file system is slow it's slower yeah it's slower than memory but",
    "start": "934000",
    "end": "939040"
  },
  {
    "text": "at some point you are not processing all the data at once right you're always processing data by fractions a couple of chunks at a time",
    "start": "939040",
    "end": "946240"
  },
  {
    "text": "not all of them otherwise you will get really in a really bad spot with cpu",
    "start": "946240",
    "end": "951920"
  },
  {
    "text": "such ion ds and so on so when the data hits also we have the same mechanisms",
    "start": "951920",
    "end": "956959"
  },
  {
    "text": "that can go to the file system and the ideal the deal use case",
    "start": "956959",
    "end": "963440"
  },
  {
    "text": "that we come up as a design is with hybrid mechanism where you can have the data also in memory which is being",
    "start": "963440",
    "end": "969680"
  },
  {
    "text": "processed or ready to go but also we have all the other chunks in the file system and we have this concept of",
    "start": "969680",
    "end": "976079"
  },
  {
    "text": "chunks up and down a chunk of breaks down is just in the file system a chunk that is up means is",
    "start": "976079",
    "end": "982399"
  },
  {
    "text": "loaded in memory but they are not separated right which is in memory is also a reflection of what we have in the",
    "start": "982399",
    "end": "988320"
  },
  {
    "text": "file system and we use memory mapped files with this approach we reduce the number",
    "start": "988320",
    "end": "994160"
  },
  {
    "text": "of read write calls so we reduce the number of syscalls involved on all these operations",
    "start": "994160",
    "end": "1000720"
  },
  {
    "text": "and it's a very scalable design so my buffering perspective it's very",
    "start": "1000720",
    "end": "1006000"
  },
  {
    "start": "1004000",
    "end": "1201000"
  },
  {
    "text": "reliable now in as the description said we wanted to",
    "start": "1006000",
    "end": "1011120"
  },
  {
    "text": "talk about matrix today right the approach of fluid but following different but it was always about loss",
    "start": "1011120",
    "end": "1016720"
  },
  {
    "text": "but what's the story behind matrix and the few minutes that we have left is that for years even in cubicle and this",
    "start": "1016720",
    "end": "1023759"
  },
  {
    "text": "conference users approached to us and said hey why i need to have one engine",
    "start": "1023759",
    "end": "1028880"
  },
  {
    "text": "for metrics and one agent for locks why i cannot have a more unified experience",
    "start": "1028880",
    "end": "1034880"
  },
  {
    "text": "and at some point we said this here hey and we had metro experience just a little bit but why not why not to extend our",
    "start": "1034880",
    "end": "1043280"
  },
  {
    "text": "scope as a project to handle metrics right you might think hey you want to replace prometheus no",
    "start": "1043280",
    "end": "1050240"
  },
  {
    "text": "and now i'm going to explain about our journey into the matrix a world what has been quite interesting so i",
    "start": "1050240",
    "end": "1056640"
  },
  {
    "text": "found that doing metrics more fun than logs or maybe we have been doing longer for so much time the thing is that we",
    "start": "1056640",
    "end": "1062720"
  },
  {
    "text": "are not new to metrics right fluid has done metric collection for a lot of years since the beginning because it was",
    "start": "1062720",
    "end": "1069039"
  },
  {
    "text": "for embedded linux so we have a input plugins together cpu metrics this io",
    "start": "1069039",
    "end": "1074640"
  },
  {
    "text": "network thermal temperature stuff docker metrics but we always handle that",
    "start": "1074640",
    "end": "1080880"
  },
  {
    "text": "as structured locks not as a with a matrix payload or a fixed data",
    "start": "1080880",
    "end": "1087200"
  },
  {
    "text": "model right in logs you have anything a bunch of key value pairs that nobody cares about the structure what is first",
    "start": "1087200",
    "end": "1094080"
  },
  {
    "text": "what is the second but when you have a matrix payload you have something very defined as a matrix name",
    "start": "1094080",
    "end": "1099840"
  },
  {
    "text": "a value maybe description name space or things like that",
    "start": "1099840",
    "end": "1105280"
  },
  {
    "text": "so and this is a kind of comparison between locks and metrics logs you have instructor messages",
    "start": "1105280",
    "end": "1110400"
  },
  {
    "text": "structure but metric has fixed the data model and logs you need to do filtering a",
    "start": "1110400",
    "end": "1116240"
  },
  {
    "text": "matrix maybe maybe you need some kind of do some kind of irrigation which is quite",
    "start": "1116240",
    "end": "1121760"
  },
  {
    "text": "optional in logs you cannot predict the size of the data it's really hard",
    "start": "1121760",
    "end": "1127919"
  },
  {
    "text": "you it's really hard to reduce the data logs right you don't know what's coming in in metrics since you are in control of",
    "start": "1127919",
    "end": "1134559"
  },
  {
    "text": "that you can kind of manage or predict how much measures you",
    "start": "1134559",
    "end": "1140320"
  },
  {
    "text": "need to store or maybe you can aggregate them and reduce the samples um",
    "start": "1140320",
    "end": "1146160"
  },
  {
    "text": "in terms of types logs you know have map booleans integral flows blah blah while",
    "start": "1146160",
    "end": "1151840"
  },
  {
    "text": "metrics pretty much counters gauges histograms so it's more simple i would say it's more simple implementation",
    "start": "1151840",
    "end": "1159120"
  },
  {
    "text": "and we started doing our own research right and if you look at round when doing this",
    "start": "1159120",
    "end": "1165360"
  },
  {
    "text": "kind of projects in fluency and fluent video we always try to be vendor agnostic that means that we always try",
    "start": "1165360",
    "end": "1171600"
  },
  {
    "text": "to integrate with others right not just go ahead and replace every single standard it's not the way to go so when",
    "start": "1171600",
    "end": "1179039"
  },
  {
    "text": "we say we're going to integrate with metrics the first question is how right",
    "start": "1179039",
    "end": "1184240"
  },
  {
    "text": "and okay let's see what's the industry is running and the industry today is",
    "start": "1184240",
    "end": "1189360"
  },
  {
    "text": "prometheus so the best way to approach this a challenge of into getting to the metric",
    "start": "1189360",
    "end": "1195679"
  },
  {
    "text": "space was integrate with prometheus with the open metrics spec",
    "start": "1195679",
    "end": "1202080"
  },
  {
    "start": "1201000",
    "end": "1404000"
  },
  {
    "text": "so and prometheus quite stable right we have a metric spec we have collectors exporters is network",
    "start": "1202400",
    "end": "1209600"
  },
  {
    "text": "friendly we can transfer metrics from one endpoint to the other without any problem",
    "start": "1209600",
    "end": "1214640"
  },
  {
    "text": "and we decide okay let's get started with prometheus right is will be our first journey into",
    "start": "1214640",
    "end": "1220799"
  },
  {
    "text": "metrics and now how do we get started with this okay we don't have any handler for for metrics right if you're coming",
    "start": "1220799",
    "end": "1228000"
  },
  {
    "text": "from prometheus you know that prometo has this kind of um implementation with sdks so we created",
    "start": "1228000",
    "end": "1234640"
  },
  {
    "text": "our own library called symmetrics right and symmetrics allow us",
    "start": "1234640",
    "end": "1239840"
  },
  {
    "text": "to do pretty much what you can do right now with prometus go client which is manage all these kind of",
    "start": "1239840",
    "end": "1245840"
  },
  {
    "text": "metrics right create counters create guides create histograms which is working process but you can do all these",
    "start": "1245840",
    "end": "1252159"
  },
  {
    "text": "kind of atomic operations uh create labels query by labels or change",
    "start": "1252159",
    "end": "1258080"
  },
  {
    "text": "all of them so and then this got integrated into flow and bit",
    "start": "1258080",
    "end": "1263440"
  },
  {
    "text": "and one of the goals of symmetric is that it's not just matrix handling you can manage metrics but then you have",
    "start": "1263440",
    "end": "1269440"
  },
  {
    "text": "another problem how do you send these metrics to prometheus how do you send this metrics maybe oh",
    "start": "1269440",
    "end": "1276320"
  },
  {
    "text": "i'm using influx d i don't care about promises but i want to solve influx db so symmetrics allows",
    "start": "1276320",
    "end": "1282559"
  },
  {
    "text": "to separate the context of content versus transport right",
    "start": "1282559",
    "end": "1288960"
  },
  {
    "text": "content is about uh how the payload looks like transport is how do i deliver that",
    "start": "1288960",
    "end": "1295200"
  },
  {
    "text": "payload to a different place so in symmetry we implemented a way to",
    "start": "1295200",
    "end": "1300880"
  },
  {
    "text": "transfer all the content from a signatures context to influence zb prometheus remote right and as",
    "start": "1300880",
    "end": "1307520"
  },
  {
    "text": "prometheus exporter we don't do transport just content but also as a mentor we support namespace",
    "start": "1307520",
    "end": "1314000"
  },
  {
    "text": "subsystem name descriptions and labels this is a simple example on how to create a metric",
    "start": "1314000",
    "end": "1321280"
  },
  {
    "text": "using symmetrics it's just i think that if you compare this code what what you",
    "start": "1321280",
    "end": "1326400"
  },
  {
    "text": "having as a goal and client sdk it's very much the same line of codes and no",
    "start": "1326400",
    "end": "1331760"
  },
  {
    "text": "joking it's the same amount of lines actually we pretty much copy all the parameters go client in c and we",
    "start": "1331760",
    "end": "1338640"
  },
  {
    "text": "create a c metrics right so you have to take always the best practices there's no need to",
    "start": "1338640",
    "end": "1343919"
  },
  {
    "text": "reinvent the wheel and prometheus thing is just great that had really good specs for everything",
    "start": "1343919",
    "end": "1349919"
  },
  {
    "text": "now also this metric context could be just one line of function we just want function you can create a payload for",
    "start": "1349919",
    "end": "1356080"
  },
  {
    "text": "influx db right so we have an example above below",
    "start": "1356080",
    "end": "1361280"
  },
  {
    "text": "we can say okay i'm going to expose this symmetric context over http so prometheus can scrape this matrix so we",
    "start": "1361280",
    "end": "1368799"
  },
  {
    "text": "created this also this extension to create the same payload and also we support prometheus remote",
    "start": "1368799",
    "end": "1375200"
  },
  {
    "text": "right remote right is a is a protocol that allows you to ship metrics from one",
    "start": "1375200",
    "end": "1380880"
  },
  {
    "text": "endpoint to the other right by design it was not created for that purpose but the",
    "start": "1380880",
    "end": "1386400"
  },
  {
    "text": "industry or vendors that listen for metrics payloads they started creating",
    "start": "1386400",
    "end": "1391440"
  },
  {
    "text": "this kind of remote right endpoints so if you're using prometheus",
    "start": "1391440",
    "end": "1396480"
  },
  {
    "text": "yeah get permitted to scrape all the data but you have this promised remote right ability to send the data out",
    "start": "1396480",
    "end": "1404640"
  },
  {
    "start": "1404000",
    "end": "1541000"
  },
  {
    "text": "and flowing between symmetrics has been quite interesting because the first thing that we did okay",
    "start": "1404640",
    "end": "1410720"
  },
  {
    "text": "we want to get into metrics we created symmetrics now it's about okay let's",
    "start": "1410720",
    "end": "1416000"
  },
  {
    "text": "create the use case and most of users wanted to not stop using node export not",
    "start": "1416000",
    "end": "1422159"
  },
  {
    "text": "exported which is a prometheus one of the promised program to gather metrics from the linux boxes so they",
    "start": "1422159",
    "end": "1429279"
  },
  {
    "text": "asked us to reimplement not exporter as an input plugin for fluent bit meaning that now the current version of fluent",
    "start": "1429279",
    "end": "1436080"
  },
  {
    "text": "bit can gather the same metrics that not exporter and now allow the users to stop",
    "start": "1436080",
    "end": "1442480"
  },
  {
    "text": "using the exporter and just use fluid for the same purpose of course we have not implemented all",
    "start": "1442480",
    "end": "1448320"
  },
  {
    "text": "the collectors that not export it has that is based on demand but we support cpu frequency this stats vm stats memory",
    "start": "1448320",
    "end": "1456320"
  },
  {
    "text": "load average also in that is the collection point now",
    "start": "1456320",
    "end": "1461679"
  },
  {
    "text": "if we think about the output how do we expose those metrics right we implemented our own primitives exporter",
    "start": "1461679",
    "end": "1467360"
  },
  {
    "text": "plugin all of this is written in c it uses a very low",
    "start": "1467360",
    "end": "1472799"
  },
  {
    "text": "cpu and memory usage so you allow to the github backends to just come into fluent",
    "start": "1472799",
    "end": "1478640"
  },
  {
    "text": "bit and scrape this metrics for you actually today you're using not exporter and you have all your grafana dashboards",
    "start": "1478640",
    "end": "1486000"
  },
  {
    "text": "and you just switch to fluent bit there's no breaking change you will get all the metrics all the stuff right away",
    "start": "1486000",
    "end": "1492720"
  },
  {
    "text": "unless i'm going to get back you're using some linux collecting uk that is not here cdfs or any kind of fancy",
    "start": "1492720",
    "end": "1499520"
  },
  {
    "text": "feature that most of people are not using but if there's something missing just",
    "start": "1499520",
    "end": "1504880"
  },
  {
    "text": "let us know and we will implement it and from a configuration perspective it's",
    "start": "1504880",
    "end": "1510640"
  },
  {
    "text": "pretty simple you just enable an input plugin this is like a typical config file of fluent bit where you say enable",
    "start": "1510640",
    "end": "1516880"
  },
  {
    "text": "the node export and matrix plugin scrape the matrix every two seconds",
    "start": "1516880",
    "end": "1522000"
  },
  {
    "text": "and then just have an output plug-in which is called prometheus exporter that opens an http endpoint and expose those",
    "start": "1522000",
    "end": "1529279"
  },
  {
    "text": "metrics internally all this is routed right so we have a bunch of input plugins for metrics and different ways",
    "start": "1529279",
    "end": "1535760"
  },
  {
    "text": "to expose these metrics out expose or send it out to a different place",
    "start": "1535760",
    "end": "1541840"
  },
  {
    "start": "1541000",
    "end": "1724000"
  },
  {
    "text": "okay i think we have some eight minutes right randy okay we can do a quick demo",
    "start": "1541840",
    "end": "1548799"
  },
  {
    "text": "so my co-founder is writing me okay so for example i'm going to just",
    "start": "1548799",
    "end": "1557039"
  },
  {
    "text": "show you here this config example what i'm doing here is just starting the",
    "start": "1557039",
    "end": "1563200"
  },
  {
    "text": "service flashing data every one second here so on this part we just enable the",
    "start": "1563200",
    "end": "1569440"
  },
  {
    "text": "not exported input plug-in fluentpad we expose the information to two plugins",
    "start": "1569440",
    "end": "1575440"
  },
  {
    "text": "two output plugins one of them is primitive exporter which opens an http port",
    "start": "1575440",
    "end": "1580880"
  },
  {
    "text": "and then to the standard output so something like this is pretty simple",
    "start": "1580880",
    "end": "1587440"
  },
  {
    "text": "and then this command is going to start shipping the metrics to the standard output which is just useless for",
    "start": "1587440",
    "end": "1592559"
  },
  {
    "text": "production right it's just for demo purpose but the good thing is that in the other side",
    "start": "1592559",
    "end": "1598880"
  },
  {
    "text": "we can query those metrics right using curl and use a call you will see that we get",
    "start": "1598880",
    "end": "1604720"
  },
  {
    "text": "all the the prometheus style formats so this is same for embed shipping out the metrics in one format",
    "start": "1604720",
    "end": "1611679"
  },
  {
    "text": "standard output and you are exposing through prometheus now what impossibility is this open and",
    "start": "1611679",
    "end": "1618720"
  },
  {
    "text": "i think that it's really interesting a lot a lot a lot now also i have here",
    "start": "1618720",
    "end": "1626159"
  },
  {
    "text": "phil williams just one of the contributors just send out a plugin to a i don't know do you use nginx",
    "start": "1626159",
    "end": "1633440"
  },
  {
    "text": "for some reason nginx a web server okay luckily you're using it right if you use nginx",
    "start": "1633440",
    "end": "1640559"
  },
  {
    "text": "what it's doing is also might be exposing metrics from nginx if you're using nginx basically what you do is to",
    "start": "1640559",
    "end": "1647919"
  },
  {
    "text": "deploy the one program called nginx spotter which is a golem plugin made by the",
    "start": "1647919",
    "end": "1654480"
  },
  {
    "text": "nginx company that exposed nginx plugins for the prometus world right",
    "start": "1654480",
    "end": "1659919"
  },
  {
    "text": "so we did the same right now we implemented the same functionality as an input plugin for fluent bit that was",
    "start": "1659919",
    "end": "1666399"
  },
  {
    "text": "just merged today we are pasting here you know the the open example of those to the",
    "start": "1666399",
    "end": "1672399"
  },
  {
    "text": "standard output but if i'm not wrong this is the endpoint",
    "start": "1672399",
    "end": "1680398"
  },
  {
    "text": "i don't remember what is the port that this is supposed let me check here in the config this is pausing",
    "start": "1680960",
    "end": "1687039"
  },
  {
    "text": "okay",
    "start": "1687039",
    "end": "1689360"
  },
  {
    "text": "it should be 80. yeah we're going to connect to 80 and",
    "start": "1694720",
    "end": "1701120"
  },
  {
    "text": "oh 2021. if i'm not wrong should be something",
    "start": "1701120",
    "end": "1706960"
  },
  {
    "text": "like this there you go so on the left side we are sending we're collecting a we're starting an index service shipping",
    "start": "1706960",
    "end": "1713840"
  },
  {
    "text": "now the same thing uh printing matrix was on the output and the right side simulating a prometus that is scraping",
    "start": "1713840",
    "end": "1720559"
  },
  {
    "text": "those metrics using a coral now there's a bunch of things that we",
    "start": "1720559",
    "end": "1726960"
  },
  {
    "start": "1724000",
    "end": "1830000"
  },
  {
    "text": "can continue doing in the metric space and we got more ambitious about hey let's implement more metrics thing more",
    "start": "1726960",
    "end": "1732399"
  },
  {
    "text": "collectors because there's a huge benefit and we get a great support from the prometeus community now what is",
    "start": "1732399",
    "end": "1738880"
  },
  {
    "text": "ready now not exported for metrics fluid bit metrics which are internal metrics in the output side we can ship metrics",
    "start": "1738880",
    "end": "1745679"
  },
  {
    "text": "to influx db promoter exporter remote right and the ongoing work is that also we are",
    "start": "1745679",
    "end": "1751520"
  },
  {
    "text": "replicating not exporting metrics for windows this is also not play from prometheus but we're replicating the",
    "start": "1751520",
    "end": "1757840"
  },
  {
    "text": "same functionality in fluent bet nginx metrics which is ready we're going to collect this.d",
    "start": "1757840",
    "end": "1763360"
  },
  {
    "text": "also the ability to convert logs to metrics because there are many applications that ship logs as a json",
    "start": "1763360",
    "end": "1769600"
  },
  {
    "text": "but you wanted to get them into prometheus so how do you handle that conversion that this filter called logs",
    "start": "1769600",
    "end": "1776000"
  },
  {
    "text": "to matrix will a be a good place for that as an output site we're going to implement splunk",
    "start": "1776000",
    "end": "1781360"
  },
  {
    "text": "metrics data.metrics and cloudwatch also we are working on this kind of",
    "start": "1781360",
    "end": "1787279"
  },
  {
    "text": "matrix processor because as i said the beginning you don't want always to ship all your",
    "start": "1787279",
    "end": "1792880"
  },
  {
    "text": "metrics when you want us to process them and maybe process get the average of a value every minute and set that average",
    "start": "1792880",
    "end": "1800960"
  },
  {
    "text": "but not send every sample every second right which at the end of the day with a hundred of nodes your storage start to",
    "start": "1800960",
    "end": "1808480"
  },
  {
    "text": "grow right and that is more expensive and the future right right now we",
    "start": "1808480",
    "end": "1814159"
  },
  {
    "text": "standardize on open metrics because and prometheus what's the industry is running now once open telemetry gets on",
    "start": "1814159",
    "end": "1820559"
  },
  {
    "text": "ga with metrics i think that we should be shortly we're going to start implementing all the",
    "start": "1820559",
    "end": "1825840"
  },
  {
    "text": "otlp protocol for those needs okay i think that we have some minute",
    "start": "1825840",
    "end": "1832320"
  },
  {
    "start": "1830000",
    "end": "2067000"
  },
  {
    "text": "for for q a thank you",
    "start": "1832320",
    "end": "1837840"
  },
  {
    "text": "i see that the c metrics library is built into fluent bit now do you plan to break that out",
    "start": "1849360",
    "end": "1855440"
  },
  {
    "text": "for separate use or is it always intention to be used directly inside of fluent a symmetry has a it's a standalone",
    "start": "1855440",
    "end": "1862080"
  },
  {
    "text": "library it's hosted at calyptia open source project celebrity that we wrote as a company",
    "start": "1862080",
    "end": "1868159"
  },
  {
    "text": "but it's hosted as a shared library so you can i can share the link with you after this talk is",
    "start": "1868159",
    "end": "1874120"
  },
  {
    "text": "caliptia.symmetrics you can get it use it we have unit tests so you can see some examples of how this works",
    "start": "1874120",
    "end": "1881440"
  },
  {
    "text": "so yeah it's kind of agnostic we try to basically make it agnostic so eduardo",
    "start": "1881440",
    "end": "1887760"
  },
  {
    "text": "we've got a couple of questions online one of them is kind of can you differentiate fluent d and flint bit a",
    "start": "1887760",
    "end": "1893840"
  },
  {
    "text": "little bit more yeah fluently i'm from bit and fluently 10 years old flowing bit",
    "start": "1893840",
    "end": "1899519"
  },
  {
    "text": "six years old fluently a thousand plugins flowing bet 100 right now in temperatures of performance",
    "start": "1899519",
    "end": "1906000"
  },
  {
    "text": "fluent is 10x more performance in our latest benchmarks um so unless you have a good reason to use",
    "start": "1906000",
    "end": "1912720"
  },
  {
    "text": "fluency you use it but if you want more performance optimize on your resources",
    "start": "1912720",
    "end": "1918240"
  },
  {
    "text": "usage just switch to fluent bit we are the same project the same family so it should be fine to stick with one of",
    "start": "1918240",
    "end": "1924799"
  },
  {
    "text": "two because both are bender neutral and matrix matrix",
    "start": "1924799",
    "end": "1931039"
  },
  {
    "text": "matrix meaning okay so this this is i didn't mention",
    "start": "1931039",
    "end": "1936640"
  },
  {
    "text": "this but symmetrics we use it to empower fluid for metrics but shortly also other",
    "start": "1936640",
    "end": "1942960"
  },
  {
    "text": "contributors took symmetrics and created all the metrics handling so we get creating just one tiny library",
    "start": "1942960",
    "end": "1950559"
  },
  {
    "text": "we just empowered both projects so you can forward metrics from flowing detail fantastic great",
    "start": "1950559",
    "end": "1957120"
  },
  {
    "text": "any other questions local yeah okay",
    "start": "1957120",
    "end": "1961640"
  },
  {
    "text": "i what in your opinion would cause somebody to stay on fluentd or go to",
    "start": "1966640",
    "end": "1972320"
  },
  {
    "text": "fluent b or vice versa if i answer my question based on",
    "start": "1972320",
    "end": "1979760"
  },
  {
    "text": "personal experience with customers everybody's caring about performance now",
    "start": "1979760",
    "end": "1985039"
  },
  {
    "text": "and from the for some intensive cases it's not a it's not good enough",
    "start": "1985039",
    "end": "1990399"
  },
  {
    "text": "so i would say fluent thank you",
    "start": "1990399",
    "end": "1995600"
  },
  {
    "text": "you would just do another one online here real quick um can you speak to mtls implementations in the two",
    "start": "1997840",
    "end": "2006399"
  },
  {
    "text": "we have tls and i think that mtls is not something we can handle today",
    "start": "2006399",
    "end": "2012880"
  },
  {
    "text": "but it's under robot so you talk about converting logs to metrics",
    "start": "2012880",
    "end": "2018240"
  },
  {
    "text": "does that support like fingerprinting namespaces for kubernetes so that you can be like these logs are coming from",
    "start": "2018240",
    "end": "2024880"
  },
  {
    "text": "this namespace so you can actually figure out who's the noisy neighbor in your cluster",
    "start": "2024880",
    "end": "2030399"
  },
  {
    "text": "yeah so we talk about kubernetes is always have to consider about the the context right and what give us the",
    "start": "2030399",
    "end": "2036480"
  },
  {
    "text": "context is api server so we have those filters to enrich the records with that information",
    "start": "2036480",
    "end": "2042000"
  },
  {
    "text": "and what you care about are labels right because you want to query by labels so the goal this is not just fully designed",
    "start": "2042000",
    "end": "2048240"
  },
  {
    "text": "but it's detected record which is already enriched with kubernetes metadata and translate those labels to",
    "start": "2048240",
    "end": "2054398"
  },
  {
    "text": "symmetrics labels so you can get kind of the same experience",
    "start": "2054399",
    "end": "2060158"
  },
  {
    "text": "awesome okay well i think we're about time eduardo awesome talk thank you thank you",
    "start": "2060159",
    "end": "2065669"
  },
  {
    "text": "[Applause]",
    "start": "2065670",
    "end": "2069689"
  }
]
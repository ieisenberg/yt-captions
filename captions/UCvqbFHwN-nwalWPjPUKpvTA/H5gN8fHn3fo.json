[
  {
    "text": "all right I think it's time to start thanks for the jokes um so welcome to our session thank you for sticking",
    "start": "520",
    "end": "5759"
  },
  {
    "text": "around till the last session of the day also walking to the you know last part of the building uh Welcome to our",
    "start": "5759",
    "end": "10880"
  },
  {
    "text": "session the hidden Heroes behind AI making sense of gpus and tpus and kubernetes uh my name is David Porter U",
    "start": "10880",
    "end": "17279"
  },
  {
    "text": "from Google I work on the Google kubernetes team I work on node I'm also a maintainer and in Sig node and this is",
    "start": "17279",
    "end": "23359"
  },
  {
    "text": "Evan hi I'm Yan uh I am with Nvidia as the tarch says uh I'm on the cloud",
    "start": "23359",
    "end": "29560"
  },
  {
    "text": "native team and we build everything that's required to run gpus in containers right so the",
    "start": "29560",
    "end": "34960"
  },
  {
    "text": "container toolkit if you've heard of that the device plugin uh the GPU operator all of that good",
    "start": "34960",
    "end": "40399"
  },
  {
    "text": "stuff um so like these kinds of devices and accelerators have been quite a Hot",
    "start": "40399",
    "end": "46320"
  },
  {
    "text": "Topic at this conference already and they're becoming increasingly important to run these complex workloads like uh",
    "start": "46320",
    "end": "53079"
  },
  {
    "text": "machine learning training and inference and the demand for them has been growing over time as well so it's even more",
    "start": "53079",
    "end": "59079"
  },
  {
    "text": "important for us to keep be able to access these gpus tpus and even the fpgas uh in our kubernetes um clusters",
    "start": "59079",
    "end": "66119"
  },
  {
    "text": "so that we can run these jobs so in the talk today we'll cover how kubernetes actually integrates with",
    "start": "66119",
    "end": "72240"
  },
  {
    "text": "these devices and sort of a little bit of a spoiler but it's through device plugins and how these device plugins and",
    "start": "72240",
    "end": "79000"
  },
  {
    "text": "device allocation actually work uh we also be looking like some usage examples of gpus and tpus on kubernetes and",
    "start": "79000",
    "end": "85640"
  },
  {
    "text": "giving some sort of thoughts details hints tips on operating clusters with TPU tpus and gpus and a sort of a brief",
    "start": "85640",
    "end": "93040"
  },
  {
    "text": "outlook on what we see as the future of devices in kubernetes now first of all what is a",
    "start": "93040",
    "end": "99680"
  },
  {
    "text": "device well essentially it's this thing here right but that's not very useful um",
    "start": "99680",
    "end": "105920"
  },
  {
    "text": "so a device with a capital d uh or resource is something that a user wants access to for a specific purpose such as",
    "start": "105920",
    "end": "112439"
  },
  {
    "text": "training a machine learning model um and but one you sort of like go down the various levels of abstraction or up",
    "start": "112439",
    "end": "118479"
  },
  {
    "text": "through the various levels of abstraction I suppose uh you end up with a collection of device nodes libraries and utilities that are required to",
    "start": "118479",
    "end": "123840"
  },
  {
    "text": "actually access to this device in in an environment such as a container and in kubernetes these are exposed as",
    "start": "123840",
    "end": "130039"
  },
  {
    "text": "countable extended resources which can then be requested by a user and in order to do this one requires a per node",
    "start": "130039",
    "end": "136480"
  },
  {
    "text": "device plugin so these device plugins register with a cubet and sort of under a",
    "start": "136480",
    "end": "142360"
  },
  {
    "text": "specific name such as nvidia.com GPU which I'm sure some of you have already seen um and this device plugin then list",
    "start": "142360",
    "end": "150000"
  },
  {
    "text": "the device is available as a set of opa IDs um and may be able to provide",
    "start": "150000",
    "end": "155080"
  },
  {
    "text": "specific hints to the cubet in order to allocate these devices once an allocation of this",
    "start": "155080",
    "end": "161280"
  },
  {
    "text": "device takes place um the device plug-in then can provide information about modifications that need to be made to",
    "start": "161280",
    "end": "167159"
  },
  {
    "text": "The Container spec as it's being created so this includes device nodes mounts environment variables annotations and",
    "start": "167159",
    "end": "173440"
  },
  {
    "text": "something new um there's an alpha feature in 128 and should promote uh should uh be promoted to Beta in 129 is",
    "start": "173440",
    "end": "180319"
  },
  {
    "text": "the inclusion of specifying CDI device names and sort of these CDI devices so",
    "start": "180319",
    "end": "186400"
  },
  {
    "text": "the CDI or container device interface is a cncf sponsored project under tag runtime and provides a a way for vendors",
    "start": "186400",
    "end": "193400"
  },
  {
    "text": "to declaratively specify what a device means right capital D device this",
    "start": "193400",
    "end": "198519"
  },
  {
    "text": "includes device nodes mounts environment variables hooks um and tries to be for",
    "start": "198519",
    "end": "203799"
  },
  {
    "text": "devices what the oci rtime spec is for containers and then uh these devices or",
    "start": "203799",
    "end": "210319"
  },
  {
    "text": "these modifications associated with a device capital D device map to oci runtime spec modifications and once",
    "start": "210319",
    "end": "216599"
  },
  {
    "text": "these modifications are made then you should be able to have access to your device now these devices also can be",
    "start": "216599",
    "end": "222200"
  },
  {
    "text": "referred to by a locally unique name and a fully qualified CDI device name which includes a vendor component a class",
    "start": "222200",
    "end": "227519"
  },
  {
    "text": "component and a name um and another thing to note is that the CRI was extended to include support for CDI",
    "start": "227519",
    "end": "233120"
  },
  {
    "text": "device fields in the 027 release now just in terms of CDI and how",
    "start": "233120",
    "end": "239319"
  },
  {
    "text": "it would work work right first of all like we as vendors would probably",
    "start": "239319",
    "end": "244360"
  },
  {
    "text": "generate CDI well would generate CDI spec using some vendor tooling maybe that should be vendor one vendor two",
    "start": "244360",
    "end": "249599"
  },
  {
    "text": "vendor three um and this tooling could be run uh sort of once off uh this could",
    "start": "249599",
    "end": "257440"
  },
  {
    "text": "be seen as a static config if you know everything about your devices a priori then you could generate the specification uh put it on your on your",
    "start": "257440",
    "end": "264040"
  },
  {
    "text": "node somewhere and then that can be available for things that needed uh this could also be generated dynamically if",
    "start": "264040",
    "end": "269600"
  },
  {
    "text": "if you're busy trying to do something a bit more interesting sort of in terms of how",
    "start": "269600",
    "end": "275039"
  },
  {
    "text": "they're consumed a container runtime will receive some request by the CRI to",
    "start": "275039",
    "end": "280880"
  },
  {
    "text": "create a container this CRI request could include the CDI devices in the field in the spec or possibly as",
    "start": "280880",
    "end": "286880"
  },
  {
    "text": "annotations which were used before the the field in the spec were added um",
    "start": "286880",
    "end": "292759"
  },
  {
    "text": "having selected a device the container runtime such as cryo container D which both support CDI natively reads the CDI",
    "start": "292759",
    "end": "299160"
  },
  {
    "text": "specification a that were generated previously by the vendor tooling um for the selected",
    "start": "299160",
    "end": "304560"
  },
  {
    "text": "devices applies the modifications defined by the CDI spec to the oci uh",
    "start": "304560",
    "end": "310080"
  },
  {
    "text": "runtime specification and then sort of invokes run c as normal run C would then",
    "start": "310080",
    "end": "315520"
  },
  {
    "text": "read this oci spec which now includes the modifications and uh start the container or create the container using",
    "start": "315520",
    "end": "321039"
  },
  {
    "text": "that specification because it includes these modifications that container that was created has access to the devices as",
    "start": "321039",
    "end": "328479"
  },
  {
    "text": "required now we're going to zoom out a bit and for that I'm going to hand over back to",
    "start": "328479",
    "end": "333680"
  },
  {
    "text": "David cool so now that we can understand what's going on maybe at the low level let's zoom out to understand how this",
    "start": "333680",
    "end": "339240"
  },
  {
    "text": "fits into kind of the whole kubernetes ecosystem right so we have all these components running here so where does it",
    "start": "339240",
    "end": "344400"
  },
  {
    "text": "start it starts with actual device right so in this example we have two gpus and you know you need to set up a node you",
    "start": "344400",
    "end": "350560"
  },
  {
    "text": "need to get that Hardware on there and you need to install the drivers right we're talking about the actual like criminel drivers that can interface with",
    "start": "350560",
    "end": "355840"
  },
  {
    "text": "the actual device so once we have that um the first thing is we need to deploy",
    "start": "355840",
    "end": "361000"
  },
  {
    "text": "a device plugin right the device plugin is a component that the vendor builds that basically is the proxy between the",
    "start": "361000",
    "end": "366759"
  },
  {
    "text": "kuet and the actual device so in this case you know you deploy the the Nvidia device plug-in uh that knows how to talk",
    "start": "366759",
    "end": "373520"
  },
  {
    "text": "to these gpus and the device plugin's job is basically to communicate with the kuet and uh the actual gpus to advertise",
    "start": "373520",
    "end": "380400"
  },
  {
    "text": "them right so device plug-in starts up it talks to the gpus it says hey I have two gpus and then it talks to kuet so",
    "start": "380400",
    "end": "386919"
  },
  {
    "text": "kuet then actually you know makes these calls to the device plugin and then it actually updates the node capacity to",
    "start": "386919",
    "end": "392479"
  },
  {
    "text": "the API server right so the nodes already have you know some capacity for CPU and memory and then now uh the",
    "start": "392479",
    "end": "398199"
  },
  {
    "text": "device plug-in will also tell the kuet I also have you know nvidia.com gpu2 whatever that means and so the kuet and",
    "start": "398199",
    "end": "405759"
  },
  {
    "text": "you know the other components in the ecosystem they usually don't understand What nvidia.com GPU is it's just an",
    "start": "405759",
    "end": "411039"
  },
  {
    "text": "extended resource right it's a name and then it's some count of them and that's what we mean by um an extended resource",
    "start": "411039",
    "end": "416520"
  },
  {
    "text": "type right so the API server now knows that you know this node has this much of",
    "start": "416520",
    "end": "421680"
  },
  {
    "text": "this resource and now the other actors in the system right can call out to the API server and be made aware of this",
    "start": "421680",
    "end": "428240"
  },
  {
    "text": "right so the next step a user comes in right and deploys a uh a pod um and the",
    "start": "428240",
    "end": "434360"
  },
  {
    "text": "Pod comes in and in the podspec you have some number of requests right so you're already requesting CPU in memory and",
    "start": "434360",
    "end": "439879"
  },
  {
    "text": "then you also add the request and you put the same uh extended resource name and you say how many you want right",
    "start": "439879",
    "end": "445039"
  },
  {
    "text": "nvidia.com gpu1 you put that in your container spec and then from there um you submit that pod it goes up to the",
    "start": "445039",
    "end": "451080"
  },
  {
    "text": "scheduler and the scheduler since it knows around nodes from all the other nodes the node capacity right it it can",
    "start": "451080",
    "end": "456919"
  },
  {
    "text": "figure out which node has that resource available and schedules uh the Pod to a a node that is suitable for it so once",
    "start": "456919",
    "end": "463680"
  },
  {
    "text": "that happens uh you know the scheduling takes place and the next step is you have kuet here right and kuet is",
    "start": "463680",
    "end": "469080"
  },
  {
    "text": "actually seeing the the Pod and it it kind of does two things the first thing it does is actually talks the device",
    "start": "469080",
    "end": "475120"
  },
  {
    "text": "plugin and we'll go in a little more detail in a bit and then Also it talks the container run time to actually start",
    "start": "475120",
    "end": "481440"
  },
  {
    "text": "uh that pod so it talks the device plugin it'll basically allocate a device uh for this pod and then the device",
    "start": "481440",
    "end": "487560"
  },
  {
    "text": "plug-in will come back with some information and then the KO will talk to The Container runtime and it'll basically uh pass back to the container",
    "start": "487560",
    "end": "494680"
  },
  {
    "text": "runtime some extra information on how to make this device actually accessible by the workload uh from there the container",
    "start": "494680",
    "end": "500520"
  },
  {
    "text": "runtime talks to run C run C is that is the lowlevel library there right the lowle component that actually goes ahead",
    "start": "500520",
    "end": "506240"
  },
  {
    "text": "and creates the actual container and it'll have in this specification there the actual access to you know the device",
    "start": "506240",
    "end": "512000"
  },
  {
    "text": "mounts libraries and other config to make sure that the workload can actually access that device and then in some",
    "start": "512000",
    "end": "517360"
  },
  {
    "text": "cases there's some vendor magic here that is at either maybe the container runtime level or run C Level that also",
    "start": "517360",
    "end": "522440"
  },
  {
    "text": "does a little bit of work to inject uh some stuff uh in some layer of the stack here uh but that's kind of vendor",
    "start": "522440",
    "end": "527959"
  },
  {
    "text": "specific and then at the last step here runy will go ahead and create the the workload right it'll create the the",
    "start": "527959",
    "end": "533600"
  },
  {
    "text": "process that needs access to that device and then when the workload actually starts up right it can just talk to the device directly doesn't talk to the",
    "start": "533600",
    "end": "539720"
  },
  {
    "text": "device Plugin or anything else here it just has direct access to the device so that's kind of the overall workflow of",
    "start": "539720",
    "end": "544959"
  },
  {
    "text": "how a pod uh can get access to a device and how the device plugin advertises those devices so one of the critical elements",
    "start": "544959",
    "end": "552320"
  },
  {
    "text": "here is the device plugin so we want to spend a little bit more time go into the device plugin like how does it actually work right what are the steps in it so",
    "start": "552320",
    "end": "558880"
  },
  {
    "text": "the first step is device registration device registration is the process where the device plugin starts up and actually",
    "start": "558880",
    "end": "565079"
  },
  {
    "text": "discovers what devices are running there so to back up for a second the device plugin you deploy usually as a as a",
    "start": "565079",
    "end": "570480"
  },
  {
    "text": "demon set in your cluster but it can it's just an arbitrary process that runs uh on your node right and it",
    "start": "570480",
    "end": "576279"
  },
  {
    "text": "communicates to the kuet how does it do the communication uh there's a well-defined kind of device protocol um",
    "start": "576279",
    "end": "582240"
  },
  {
    "text": "and it talks over grpc so it talks to the kuet there's a Unix uh domain socket right that it can talk to and and uh",
    "start": "582240",
    "end": "588000"
  },
  {
    "text": "communicate over jrpc so device plug-in starts up right it talks to it basically connects to kuet and it says hey I'm",
    "start": "588000",
    "end": "593959"
  },
  {
    "text": "going to register and I have this API resource type right and then I have this uh res Source right this is where the",
    "start": "593959",
    "end": "600320"
  },
  {
    "text": "nvidia.com GPU actually comes from right the device plugin tells kuet I have this device available uh from there uh the",
    "start": "600320",
    "end": "606720"
  },
  {
    "text": "kuet goes ahead and talks to device plugin it basically says what are the device plugin options uh this is some extra kind of information that the kuo",
    "start": "606720",
    "end": "612680"
  },
  {
    "text": "can obtain like for example uh should the uh should the device plug-in be aware uh before a container starts it",
    "start": "612680",
    "end": "619600"
  },
  {
    "text": "can also provide some hints around like allocation so for example for some topology aware uh scheduling you can",
    "start": "619600",
    "end": "624800"
  },
  {
    "text": "provide some hints there and then the last call is this list and watch the list and watch is a grpc like streaming",
    "start": "624800",
    "end": "630680"
  },
  {
    "text": "call so what that means is kuet makes this call and it keeps that connection open and the whole point of this call is",
    "start": "630680",
    "end": "636519"
  },
  {
    "text": "to return the actual devices so in this call you'll get back the two devices right gpu0 and gpu1 and a health status",
    "start": "636519",
    "end": "643399"
  },
  {
    "text": "for each one healthy equals true for both and the reason this is a longlived streaming GPC connection is because the",
    "start": "643399",
    "end": "648920"
  },
  {
    "text": "devices can go unhealthy right if a device goes unhealthy the kuo wants to be made aware of that and if the device",
    "start": "648920",
    "end": "654040"
  },
  {
    "text": "goes unhealthy it'll talk to the API server it'll update its capacity you know it might update NV dat com GPU from",
    "start": "654040",
    "end": "659760"
  },
  {
    "text": "2 to one and if a pod is actively using that GPU or that device the kubu will fail that pod and make sure that a new",
    "start": "659760",
    "end": "666600"
  },
  {
    "text": "pod can get created uh to make sure that you know if if uh if another controller is managing that pod you know new pod",
    "start": "666600",
    "end": "672839"
  },
  {
    "text": "can get created that that will uh continue the work needed so that's the registration phase that's how the kuet",
    "start": "672839",
    "end": "678480"
  },
  {
    "text": "and the device plug-in kind of orchestrate the the initial phase so what's the next step the next step is",
    "start": "678480",
    "end": "683639"
  },
  {
    "text": "when an actual workload comes in and we need to give that workload access to a specific device so this is the device",
    "start": "683639",
    "end": "689360"
  },
  {
    "text": "allocation phase uh it's important to know here actually kuet is the one that's responsible for figuring out which device to give to the workload",
    "start": "689360",
    "end": "695839"
  },
  {
    "text": "right so the kuet starts up and it basically knows that you know has these devices available and it can pick you know gpu1 to give to that workload uh",
    "start": "695839",
    "end": "702800"
  },
  {
    "text": "the device plug can kind of influence that decision by giving some hints uh to the kuet But ultimately it's ku's",
    "start": "702800",
    "end": "708480"
  },
  {
    "text": "responsibility here to figure out what device so kuet comes in and says I want you to allocate gpu1 for this pod for",
    "start": "708480",
    "end": "714279"
  },
  {
    "text": "this for this workload right and then the device plug-in responds with basically this these list of Fields",
    "start": "714279",
    "end": "719440"
  },
  {
    "text": "right and these fields are basically what uh what changes need to be made to The Container spec to ensure that the",
    "start": "719440",
    "end": "725839"
  },
  {
    "text": "workload can actually access the device so these are things like modifying for example some environment variables that are in the device adding some mounts uh",
    "start": "725839",
    "end": "733680"
  },
  {
    "text": "adding some some device mounts annotations and lastly kind of the CDI devices uh which we mentioned earlier",
    "start": "733680",
    "end": "738720"
  },
  {
    "text": "right it can actually add that uh and then kuet later will take this whole information apply these kind of patches",
    "start": "738720",
    "end": "744040"
  },
  {
    "text": "to The Container uh and then give it to the container on time to actually start and then the last step of the process",
    "start": "744040",
    "end": "749959"
  },
  {
    "text": "here is actually starting the the the workload right so kubl will actually start the the container and right before it starts it'll talk to the device",
    "start": "749959",
    "end": "755880"
  },
  {
    "text": "plugin it'll say I'm going to start uh this workload with this device and uh the device plug-in can do something like",
    "start": "755880",
    "end": "761880"
  },
  {
    "text": "for example you know making initializing the device whatever it needs to do uh to make that device ready to be consumed so",
    "start": "761880",
    "end": "767440"
  },
  {
    "text": "after this the workload is started and everything's great the the Pod can can use that device so we want to now kind",
    "start": "767440",
    "end": "774480"
  },
  {
    "text": "of step back for a second and take a look at what are some of the other devices that exist and how do they also make use of device plugin and kind of the kubernetes ecosystem so I want to",
    "start": "774480",
    "end": "781040"
  },
  {
    "text": "introduce tpus for you for a second so tpus are a special built accelerator for inference and training by Google uh",
    "start": "781040",
    "end": "787279"
  },
  {
    "text": "they're optimized uh for training and inference of large AI models like you know your LMS that are so popular these",
    "start": "787279",
    "end": "792519"
  },
  {
    "text": "days and gen models and other image models and so forth and there's two flavors of of tpus that exist we have uh",
    "start": "792519",
    "end": "798199"
  },
  {
    "text": "TPU devices and TPU slices so TPU devices are these independent devices so",
    "start": "798199",
    "end": "803320"
  },
  {
    "text": "the whole idea here is that they're not interconnected to other tpus it's just one device that one workload uses kind",
    "start": "803320",
    "end": "808480"
  },
  {
    "text": "of like GPU and then TPU slices are also an interesting uh kind of different flavor of TPU um that are basically",
    "start": "808480",
    "end": "815959"
  },
  {
    "text": "groups of tpus so they're multiple different tpus on different machines all interconnected uh with this very",
    "start": "815959",
    "end": "821680"
  },
  {
    "text": "highspeed interconnect and that allows to get very good performance out of them and so um these these tpus you can use",
    "start": "821680",
    "end": "828199"
  },
  {
    "text": "like kind of existing ml Frameworks pytorch and and Jacks and tensor flow and so forth uh to be able to to write",
    "start": "828199",
    "end": "833360"
  },
  {
    "text": "workloads against them right but the interesting thing here is like how does kubernetes play into this how does device plugin work into this right so",
    "start": "833360",
    "end": "839120"
  },
  {
    "text": "let's look at that so first of all why do we even need kubernetes to manage tpus right um I think that is the answer",
    "start": "839120",
    "end": "845320"
  },
  {
    "text": "for any of these workloads but especially for tpus because you have so many of them uh you they're running across many different machines and you",
    "start": "845320",
    "end": "851480"
  },
  {
    "text": "need something that'll orchestrate uh all these workloads scheduling them in the right place monitoring the health of them and uh making sure they run right",
    "start": "851480",
    "end": "858320"
  },
  {
    "text": "so that's where kubernetes com isn't helpful now how do we actually integrate with this with TPU we built a TPU device",
    "start": "858320",
    "end": "863680"
  },
  {
    "text": "plugin uh just like any other device plugin that exposes the tpus as a resource type and we call it google.com/",
    "start": "863680",
    "end": "869600"
  },
  {
    "text": "TPU and you put there how many TPU chips you want to access in your workload now scheduling is kind of an interesting",
    "start": "869600",
    "end": "875040"
  },
  {
    "text": "thing to talk about when it comes to tpus so for TPU devices it's pretty simple right it's just like a onetoone",
    "start": "875040",
    "end": "880360"
  },
  {
    "text": "mapping so you have one TPU device you have a pod you have a container it uses",
    "start": "880360",
    "end": "885480"
  },
  {
    "text": "x amount of like tpus there it's pretty simple uh TPU slices are a little bit more interesting because uh since",
    "start": "885480",
    "end": "891839"
  },
  {
    "text": "they're spread across multiple different machines you need to figure out how do you schedule multiple different replicas",
    "start": "891839",
    "end": "897399"
  },
  {
    "text": "of your of your workload how do they all kind of intercommunicate and how do you all set how do you set that up it's kind of like a gang scheduling type of",
    "start": "897399",
    "end": "903120"
  },
  {
    "text": "problem in the sense of you need to schedule multiple replicas they all need to talk to each other uh they all need to be up to ensure that your job",
    "start": "903120",
    "end": "909199"
  },
  {
    "text": "continues so how do we use the the kubernetes kind of Primitives to make that actually work um here's kind an",
    "start": "909199",
    "end": "915240"
  },
  {
    "text": "example how you would set that up and kind of what we recommend so like the first step here is you set up a service you set up a headless service and the",
    "start": "915240",
    "end": "920959"
  },
  {
    "text": "reason we need to do this is because we want each of those replicas uh to be able to have a DNS name because all of",
    "start": "920959",
    "end": "926320"
  },
  {
    "text": "those replicas are going to have to talk to all the other replicas to to actually do work here right and since we're have",
    "start": "926320",
    "end": "931920"
  },
  {
    "text": "to set up multiple replicas we're going to use the kubernetes job to represent this right so here we're setting up like a pod slice job we're going to use like",
    "start": "931920",
    "end": "938360"
  },
  {
    "text": "an index job and here we set the node selector we're going to use like a special version of TPU they come in different kind of topologies and so",
    "start": "938360",
    "end": "944560"
  },
  {
    "text": "forth we pick this topology and uh because it has this number of this topology we have certain number of chips",
    "start": "944560",
    "end": "951560"
  },
  {
    "text": "per node uh if you do the math here you get like four uh you end up actually with four different nodes and we want to",
    "start": "951560",
    "end": "956839"
  },
  {
    "text": "schedule a pod on all those nodes right so that's why we said completions and parallelism to four there uh then you",
    "start": "956839",
    "end": "962360"
  },
  {
    "text": "set up some environment variables and then you set up your TPU worker host name so these are actually like the DNS entries right like how the TPU software",
    "start": "962360",
    "end": "969639"
  },
  {
    "text": "will be able to find all the other tpus that are out there right because you have multiple of them they all need to intercommunicate so that's where we",
    "start": "969639",
    "end": "975240"
  },
  {
    "text": "specify the the DNS entries there uh then we actually have your workload this workload it's like installing Li TPU",
    "start": "975240",
    "end": "980959"
  },
  {
    "text": "software it's just doing like the hello world printing how many TPU cores there are and then finally you set your requests right and this is where we set",
    "start": "980959",
    "end": "986959"
  },
  {
    "text": "that Google to com TPU 4 this is where the device plugin the scheduler will actually see access to that device so",
    "start": "986959",
    "end": "992720"
  },
  {
    "text": "this is kind of how you would set up a workload uh for for tpod slices right using all these existing kubernetes",
    "start": "992720",
    "end": "998079"
  },
  {
    "text": "perimeters so I want to give you like a quick demo of how this works um in this demo what we're doing is we're doing",
    "start": "998079",
    "end": "1003480"
  },
  {
    "text": "inference so there's like this chat uh gptj model we're using this inference server called sax ML and we're kind of",
    "start": "1003480",
    "end": "1009399"
  },
  {
    "text": "trying to run this so I'll give you kind of a quick look at this so we start by",
    "start": "1009399",
    "end": "1014800"
  },
  {
    "text": "setting up a kubernetes GK cluster um just a standard cluster uh no tpus yet and then the next step is",
    "start": "1014800",
    "end": "1021560"
  },
  {
    "text": "we create a node pool we are using v5e uh tpus so you just specify kind of the machine type there uh we have those tpus",
    "start": "1021560",
    "end": "1028600"
  },
  {
    "text": "there now and then now we're going to set up actually we're going to use Gateway for this because we want to have an inference server so we're setting up",
    "start": "1028600",
    "end": "1035079"
  },
  {
    "text": "um like a subnet and some of the other kind of networking things needed here so now we're getting the kubernetes credentials so we can use C cuddle so we",
    "start": "1035079",
    "end": "1042558"
  },
  {
    "text": "have one TPU machine here running here right uh GK TPU and now we're going to deploy all the workloads here all all",
    "start": "1042559",
    "end": "1048160"
  },
  {
    "text": "the manifest uh the sax model is kind of what I showed you earlier it's kind of like that job configuration and uh sax",
    "start": "1048160",
    "end": "1054240"
  },
  {
    "text": "is like that inference server so it's going to actually start up and uh create like an endpoint that we can do",
    "start": "1054240",
    "end": "1059440"
  },
  {
    "text": "inference requests against right um so we're going to wait for um everything to",
    "start": "1059440",
    "end": "1064760"
  },
  {
    "text": "start up here uh when the inference server starts it downloads the model from a GCS bucket and now we're going to try to",
    "start": "1064760",
    "end": "1071440"
  },
  {
    "text": "make some queries against it right so we have the IP for it because it's behind a service uh so we're going to get the IP",
    "start": "1071440",
    "end": "1077039"
  },
  {
    "text": "for it and we're going to try to actually make some uh inference requests so first we're going to ask basically",
    "start": "1077039",
    "end": "1083799"
  },
  {
    "text": "like what is the model that's loaded and you can see here's the gptj model so we can see we're running one replica um and",
    "start": "1083799",
    "end": "1090720"
  },
  {
    "text": "then from here we're going to actually make a request right so here's your llm uh query right it actually is like a",
    "start": "1090720",
    "end": "1096280"
  },
  {
    "text": "summarization thing here so it asks it gives a news article and asks to summarize it so that's the prompt um and",
    "start": "1096280",
    "end": "1102960"
  },
  {
    "text": "then now we're going to actually do the inference call and so we do the inference call and we get all the responses and and summaries so it's all",
    "start": "1102960",
    "end": "1108960"
  },
  {
    "text": "done on tpus and so we have our our uh our response there and then now um kind",
    "start": "1108960",
    "end": "1116840"
  },
  {
    "text": "of what's the benefit of running this in kubernetes right in in in GK and kubernetes so one is the auto scaling right so uh in the first step we",
    "start": "1116840",
    "end": "1123520"
  },
  {
    "text": "actually set up an HPA right and so this will work regardless of any device you have right gpus tpus whatever it might",
    "start": "1123520",
    "end": "1128799"
  },
  {
    "text": "be and so now we're going to actually set up like a load test we're going to uh send a whole bunch of calls to that inference server and uh the HPA is going",
    "start": "1128799",
    "end": "1135840"
  },
  {
    "text": "to see it it's going to spin up more pods it's going going to have to scale up because uh there's not enough",
    "start": "1135840",
    "end": "1140960"
  },
  {
    "text": "capacity uh the cluster Auto scaler is going to see that and it's actually going to provision another node so you",
    "start": "1140960",
    "end": "1146280"
  },
  {
    "text": "can see here on the UI it started to update and increase uh and and basically",
    "start": "1146280",
    "end": "1151440"
  },
  {
    "text": "provision a new node and a new node is going to start up here and uh it's going to be able to schedule another pod uh to",
    "start": "1151440",
    "end": "1158120"
  },
  {
    "text": "handle this increased uh load so you can see here the second uh node started",
    "start": "1158120",
    "end": "1163799"
  },
  {
    "text": "here so we have two nodes now and then we can look at the pods a",
    "start": "1163799",
    "end": "1169200"
  },
  {
    "text": "new pod was created it's creating it's already scheduled and so now now it's going to",
    "start": "1169200",
    "end": "1175840"
  },
  {
    "text": "be able to withand that that increased load and so um that's kind of the power of like you know just using kubernetes",
    "start": "1175840",
    "end": "1181360"
  },
  {
    "text": "and existing Primitives that that exist in kubernetes uh to to run these type of workloads and so uh also right all these",
    "start": "1181360",
    "end": "1187559"
  },
  {
    "text": "workloads and all all these uh inference chips right they're they're all pretty expensive right and so cost cost",
    "start": "1187559",
    "end": "1192720"
  },
  {
    "text": "optimization is is is really important so you want to scale down when you're not using them and so that's going to happen right now it's going to see see",
    "start": "1192720",
    "end": "1198480"
  },
  {
    "text": "that we're not actually making use uh there's no more load it's going to scale down uh the deployment and as a result",
    "start": "1198480",
    "end": "1204760"
  },
  {
    "text": "it's going to delete those pods and then the cluster Auto SC is going to see that the node's not being utilized it's going to delete that node and we're back to",
    "start": "1204760",
    "end": "1211919"
  },
  {
    "text": "where we started with a single TPU node so uh making sure we don't need extra resources uh if we don't need them so",
    "start": "1211919",
    "end": "1219400"
  },
  {
    "text": "that's kind of the demo um just to give you kind of a taste of how how this kind of all fits together",
    "start": "1219400",
    "end": "1226360"
  },
  {
    "text": "cool all right oops all right so now that you",
    "start": "1227159",
    "end": "1234400"
  },
  {
    "text": "kind of saw some of the some of the ideas of how you can use it with a real device and how it works underneath we kind of wanted to give you some tips",
    "start": "1234400",
    "end": "1240000"
  },
  {
    "text": "from an operator standpoint right like as an operator what do you need to be aware of when you're setting up these type of devices right so the first step",
    "start": "1240000",
    "end": "1247320"
  },
  {
    "text": "is you need to actually create a cluster and provision the nodes with the right resources right so with a cloud provider that might be a simple as creating a",
    "start": "1247320",
    "end": "1252840"
  },
  {
    "text": "node pool with the the devices you need um maybe it's actually getting the devices that's kind of up to to you to",
    "start": "1252840",
    "end": "1258360"
  },
  {
    "text": "figure out and then once you have that you need to actually set up those set up those devices right so install the drivers and the device plugins so on",
    "start": "1258360",
    "end": "1264840"
  },
  {
    "text": "cloud providers this is usually kind of pretty easy and built in and then Nvidia has this Nvidia GPU operator uh which is",
    "start": "1264840",
    "end": "1270799"
  },
  {
    "text": "a kind of a collection of components that actually does this for you it'll on common OSS and so forth that'll install the drivers in the right device plugin",
    "start": "1270799",
    "end": "1276760"
  },
  {
    "text": "all the components needed to set this up so what what do you do after that uh the next step is once you have a cluster",
    "start": "1276760",
    "end": "1282720"
  },
  {
    "text": "full of these devices and nodes with these devices you need to label them and the reason for that is because you might have a cluster with a lot of different",
    "start": "1282720",
    "end": "1287760"
  },
  {
    "text": "nodes with different capabilities uh with gpus tpus different models Etc right and it's important to remember",
    "start": "1287760",
    "end": "1293039"
  },
  {
    "text": "that with a device plug-in you have like the the resource type is inv video.com GPU right and that's regardless of what",
    "start": "1293039",
    "end": "1298880"
  },
  {
    "text": "type of GPU you have right so if you have like a a100 or a T4 or whatever GPU might have they're all advertised the",
    "start": "1298880",
    "end": "1305480"
  },
  {
    "text": "same way so you need node labeling uh to ensure that the right workloads get to the right uh devices so you have to",
    "start": "1305480",
    "end": "1311720"
  },
  {
    "text": "label your nodes based on the resources they contain some Cloud providers do this automatically and Nvidia has for",
    "start": "1311720",
    "end": "1316760"
  },
  {
    "text": "example a project called the GPU feat feature discovery which does this automatically right it'll figure out what gpus are on there label the no uh",
    "start": "1316760",
    "end": "1323120"
  },
  {
    "text": "with with the device name now another problem is right since these accelerators are really expensive you don't want to run workloads that don't",
    "start": "1323120",
    "end": "1329600"
  },
  {
    "text": "need those devices on uh GPU nodes right and that's why node taining comes in so",
    "start": "1329600",
    "end": "1334760"
  },
  {
    "text": "if you taint the nodes with accelerators by default a workload that comes in right it won't be scheduled to those nodes unless it explicitely has",
    "start": "1334760",
    "end": "1340640"
  },
  {
    "text": "tolerations right and that's something probably you want because you don't want random you know web servers or things",
    "start": "1340640",
    "end": "1345679"
  },
  {
    "text": "that don't need gpus or tpus or whatever device you have landing on those nodes then the last step here right you want",
    "start": "1345679",
    "end": "1351320"
  },
  {
    "text": "to schedule your actual workloads and you probably want to use a combination of node Affinity based on the Node labels that you set earlier the the",
    "start": "1351320",
    "end": "1357039"
  },
  {
    "text": "tolerations for the taints and also the request right uh for the for whatever device plug-in resource name uh you want",
    "start": "1357039",
    "end": "1362760"
  },
  {
    "text": "to use and then lastly right uh for gpus and other devices right utilization is super important because these are",
    "start": "1362760",
    "end": "1368279"
  },
  {
    "text": "expensive resources right so there's different resource sharing schemes on basically how do you how do you have a",
    "start": "1368279",
    "end": "1373520"
  },
  {
    "text": "whole GPU how do you split it up into smaller pieces uh smaller chunks that to to allow multiple pods multiple",
    "start": "1373520",
    "end": "1379159"
  },
  {
    "text": "different workloads to make use of them and there's some technologies like Mig time slicing Nvidia MPS that you can find some more information about uh that",
    "start": "1379159",
    "end": "1385960"
  },
  {
    "text": "that provide that ability and so lastly right um when you're running these type of workloads you want to monitor them to",
    "start": "1385960",
    "end": "1392279"
  },
  {
    "text": "make sure that you know they're performing well and and uh they're working as expected so some Cloud providers have built in metrics for this",
    "start": "1392279",
    "end": "1398520"
  },
  {
    "text": "like on GK for example we have like a GK metric here duty cycle to tells you how much uh your GPU was busy during some",
    "start": "1398520",
    "end": "1404440"
  },
  {
    "text": "period and we have like a TP metric right it's tensor core utilization that basically Prov analogus for tpus and if",
    "start": "1404440",
    "end": "1410159"
  },
  {
    "text": "you want some more advanced metrics uh Nvidia has a project called uh the D dcgm exporter it's a Prometheus exporter",
    "start": "1410159",
    "end": "1415799"
  },
  {
    "text": "that provides super detailed information around gpus um it also integrates with the kuet Pod resources API so you can",
    "start": "1415799",
    "end": "1422080"
  },
  {
    "text": "actually get a per pod level metrics so you can understand you know how much was this pod utilizing the GPU versus this",
    "start": "1422080",
    "end": "1427600"
  },
  {
    "text": "pod and so forth so that's kind of the accelerator monitoring so I want to hand it back to",
    "start": "1427600",
    "end": "1433159"
  },
  {
    "text": "to Evan to talk a little bit about the future where we see devices going in kubernetes oh hi thanks David um yeah so",
    "start": "1433159",
    "end": "1440360"
  },
  {
    "text": "one of the things we're particularly excited about is dynamic resource allocation now this is a a new way to",
    "start": "1440360",
    "end": "1445919"
  },
  {
    "text": "request resources that's been available as an alpha feature since uh kubernetes 126 and it's an alternative to this",
    "start": "1445919",
    "end": "1451960"
  },
  {
    "text": "counting based interface that device plugging provides right so um instead of only being able to uh select sort of",
    "start": "1451960",
    "end": "1459840"
  },
  {
    "text": "whole numbered integer sort of units of devices it it puts full control of the API to request these resources in the",
    "start": "1459840",
    "end": "1466279"
  },
  {
    "text": "hands of third party Developers now third party in this case generally means device vendors so third party in the",
    "start": "1466279",
    "end": "1471559"
  },
  {
    "text": "context of cetes um and here sort of we we map inry API objects to to vendor specific apis",
    "start": "1471559",
    "end": "1479080"
  },
  {
    "text": "that allow for that extensibility not going to go into the details there are talks and stuff about that um and and",
    "start": "1479080",
    "end": "1484600"
  },
  {
    "text": "this Dr uses CDI behind the scenes to once a CDI spec is available for a particular device probably being",
    "start": "1484600",
    "end": "1490679"
  },
  {
    "text": "dynamically generated is passed to The Container runtime now one of the reasons or some",
    "start": "1490679",
    "end": "1497600"
  },
  {
    "text": "of of the reasons we're very excited about Dr is that it enables a lot of different functionality that is not",
    "start": "1497600",
    "end": "1502799"
  },
  {
    "text": "really possible in the device plugin at the moment um uh because you're no longer uh tied to this single countable",
    "start": "1502799",
    "end": "1510559"
  },
  {
    "text": "resource name it supports multiple device types per node so you can have a heterogene heterogeneous node and allow",
    "start": "1510559",
    "end": "1517880"
  },
  {
    "text": "uh workloads to be targeted at specific devices um because remember that these node labels that you're able to use are",
    "start": "1517880",
    "end": "1524200"
  },
  {
    "text": "node specific and are not device specific it also allows for explicit",
    "start": "1524200",
    "end": "1529440"
  },
  {
    "text": "sharing of these devices across containers and parts the device plugin as it exists uh is any device request is",
    "start": "1529440",
    "end": "1537279"
  },
  {
    "text": "for a specific container and there's no way to explicitly share that device across various containers or pods so if",
    "start": "1537279",
    "end": "1542720"
  },
  {
    "text": "you're running a more um exciting distributed um ml application for example you may want to share a device",
    "start": "1542720",
    "end": "1549320"
  },
  {
    "text": "across those different pods or containers you're also able to select resources based on constraints um such",
    "start": "1549320",
    "end": "1555520"
  },
  {
    "text": "as available memory uh as sort of resource capabilities Cuda device uh",
    "start": "1555520",
    "end": "1561279"
  },
  {
    "text": "sort of the Cuda version Etc right um and you know those could be done with labels to some extent but once again",
    "start": "1561279",
    "end": "1567640"
  },
  {
    "text": "those are not uh device specific they're node specific it also allows for dynamic",
    "start": "1567640",
    "end": "1572760"
  },
  {
    "text": "provisioning of resources so uh David mentioned Mig and that you basically take a a full GPU and slice it up into",
    "start": "1572760",
    "end": "1579320"
  },
  {
    "text": "Hardware slices and uh Dr allows you to do that dynamically so a request comes",
    "start": "1579320",
    "end": "1584559"
  },
  {
    "text": "in requesting a particular uh sort of type of GP your slice of a GPU and it can dynamically allocate that Mig Slice",
    "start": "1584559",
    "end": "1591960"
  },
  {
    "text": "on a MIG Ena GPU and provide that to the PO or container that's bu requesting it",
    "start": "1591960",
    "end": "1598159"
  },
  {
    "text": "it also provides better support for enhan features like MPS so MPS is something that requires an additional",
    "start": "1598159",
    "end": "1603640"
  },
  {
    "text": "process to be started to allow uh clients to access a device and Dr sort",
    "start": "1603640",
    "end": "1610159"
  },
  {
    "text": "of in our Dr driver that we have implemented you're able to start this um MPS demon as as part of that process so",
    "start": "1610159",
    "end": "1617640"
  },
  {
    "text": "you don't have to worry about that as a user now because of all this extra control uh you also are able to",
    "start": "1617640",
    "end": "1624320"
  },
  {
    "text": "rightsize your device request for the application that you're trying to get that you're trying to use right so if",
    "start": "1624320",
    "end": "1629640"
  },
  {
    "text": "you're just doing some lightweight sort of iterative development in some notebook you might be able to select a",
    "start": "1629640",
    "end": "1635200"
  },
  {
    "text": "smaller device than if you're trying to run inference or training for a large ml model and one thing to note is uh sort",
    "start": "1635200",
    "end": "1643720"
  },
  {
    "text": "of the caveat here is that because of this flexibility um there are some",
    "start": "1643720",
    "end": "1649000"
  },
  {
    "text": "implications with regarding to uh integration with the schedule and autoscaler and so there's on ongoing discussions in the communic community",
    "start": "1649000",
    "end": "1655200"
  },
  {
    "text": "around that um so there's still some problems to solve before we we're at the point where we can say that this is",
    "start": "1655200",
    "end": "1660240"
  },
  {
    "text": "going GA or so I think this is where there's a call to action right um from the",
    "start": "1660240",
    "end": "1666600"
  },
  {
    "text": "community we need uh input on what problems you're currently having with using accelerators and is there anything",
    "start": "1666600",
    "end": "1672840"
  },
  {
    "text": "like what's limiting your current use of the existing device plug-in model right this will allow us to get more information as to whether or not the",
    "start": "1672840",
    "end": "1679320"
  },
  {
    "text": "apis that we're busy exposing in Dr as it is designed is are the right apis or",
    "start": "1679320",
    "end": "1685120"
  },
  {
    "text": "what use cases are important to design for so yeah I think uh provided some",
    "start": "1685120",
    "end": "1691080"
  },
  {
    "text": "links in the slides but at this point we can open for questions thank you very",
    "start": "1691080",
    "end": "1696930"
  },
  {
    "text": "[Applause]",
    "start": "1696930",
    "end": "1705989"
  },
  {
    "text": "much",
    "start": "1706440",
    "end": "1709440"
  },
  {
    "text": "hey thank you for the nice talk uh listening to your excellent explanation",
    "start": "1713200",
    "end": "1718440"
  },
  {
    "text": "of the process by which a GPU is discovered and made available in",
    "start": "1718440",
    "end": "1724600"
  },
  {
    "text": "kubernetes I went back years in my in my memories and I was thinking of extended",
    "start": "1724600",
    "end": "1731640"
  },
  {
    "text": "and expanded Ram if if you have a if you were born in those times but at certain",
    "start": "1731640",
    "end": "1737799"
  },
  {
    "text": "point computers had different types of additional RAM and we needed drivers or",
    "start": "1737799",
    "end": "1743360"
  },
  {
    "text": "ways to discover it and make it available to the operating system and I was thinking today when I request Ram I",
    "start": "1743360",
    "end": "1752039"
  },
  {
    "text": "just say how much and when I request a CPU I just say what fraction of a CPU I want and I was thinking would it not be",
    "start": "1752039",
    "end": "1760080"
  },
  {
    "text": "nice to have the same for the GPU how how much GPU memory I need for my",
    "start": "1760080",
    "end": "1766039"
  },
  {
    "text": "container and and how much GPU what fraction of the GPU I want to use so my",
    "start": "1766039",
    "end": "1771640"
  },
  {
    "text": "question to you is are you aware of any movement in in kubernetes in this",
    "start": "1771640",
    "end": "1777120"
  },
  {
    "text": "direction to to make access to the gpus uniform transparent or or easy let's say",
    "start": "1777120",
    "end": "1784880"
  },
  {
    "text": "which answers your last question what kind of problems we see using our accelerators thank you do you want to",
    "start": "1784880",
    "end": "1791440"
  },
  {
    "text": "answer first or yeah I mean I I I think like in in general I think that's actually what what you mentioned is is",
    "start": "1791440",
    "end": "1797080"
  },
  {
    "text": "that a ability to you know we see devices in the device plugin as kind of static today right I think that's the big thing that that you're talking about",
    "start": "1797080",
    "end": "1803120"
  },
  {
    "text": "is you want to basically request a device that needs to repartition on the Fly Right with maybe some more memory or",
    "start": "1803120",
    "end": "1809159"
  },
  {
    "text": "something like that then there's a whole question around other devices which are kind of network attached and you can attach on the Fly maybe like some other",
    "start": "1809159",
    "end": "1816760"
  },
  {
    "text": "device or you can add add something else so I think that's actually one of the limitations in the device plugg model today right it doesn't have a good very",
    "start": "1816760",
    "end": "1823080"
  },
  {
    "text": "good flexibility for these devices changing on the Fly and Dr is one one one uh approach to solve that problem",
    "start": "1823080",
    "end": "1828919"
  },
  {
    "text": "and we're kind of looking into that approach because we see more and more devices with these type of needs yeah I think um maybe the there",
    "start": "1828919",
    "end": "1836880"
  },
  {
    "text": "there's definitely as if we get to a point where that's an API that we can expose there there is still vendor",
    "start": "1836880",
    "end": "1842080"
  },
  {
    "text": "specific logic behind that right because not all devices are fractionally",
    "start": "1842080",
    "end": "1848559"
  },
  {
    "text": "addressable right where where memory is CPU is to to some extent so I think",
    "start": "1848559",
    "end": "1854320"
  },
  {
    "text": "that's part of what Dr also tries to address is allow that flexibility to in the background enable things like MPS um",
    "start": "1854320",
    "end": "1861960"
  },
  {
    "text": "like Mig to allow fractional sort of um sort of access to to a certain degree",
    "start": "1861960",
    "end": "1867120"
  },
  {
    "text": "sharing is is what you end up having yeah",
    "start": "1867120",
    "end": "1872158"
  },
  {
    "text": "thanks hello yeah great plantion uh thank you so I I have a question about",
    "start": "1872200",
    "end": "1877880"
  },
  {
    "text": "the Dr Dr there uh is kind of a future maybe future so uh there's one you said",
    "start": "1877880",
    "end": "1884559"
  },
  {
    "text": "it could support uh different type of uh D in theme node that's that's fantastic",
    "start": "1884559",
    "end": "1890679"
  },
  {
    "text": "I'm wondering like uh even if it could support Dynamic results location but uh",
    "start": "1890679",
    "end": "1898240"
  },
  {
    "text": "does it also support a dynamic ass assignment to different task job there",
    "start": "1898240",
    "end": "1903559"
  },
  {
    "text": "or it still needed to be preconfigured for that one do all do you have discussion about that sorry what do you",
    "start": "1903559",
    "end": "1909320"
  },
  {
    "text": "mean by Dynamic assignment uh uh so when it comes a job task here like uh the the",
    "start": "1909320",
    "end": "1916720"
  },
  {
    "text": "schedule could uh find the best uh uh device and S to it like that that kind",
    "start": "1916720",
    "end": "1923799"
  },
  {
    "text": "thing dynamically so um so so the definition of best is uh something that",
    "start": "1923799",
    "end": "1930039"
  },
  {
    "text": "is probably vendor specific as well to a large extent and that's where the selection of devices based on um some",
    "start": "1930039",
    "end": "1937639"
  },
  {
    "text": "criteria uh come into play right so the the because we have this flexible API",
    "start": "1937639",
    "end": "1943480"
  },
  {
    "text": "the the implementation that we have sort of the early implementation we have allows you to say I want a device that",
    "start": "1943480",
    "end": "1949080"
  },
  {
    "text": "has this Cuda compute compatibility at least this Cuda comput comp Cuda compute",
    "start": "1949080",
    "end": "1954840"
  },
  {
    "text": "capability and compatibility uh at least this much memory and like you can extend",
    "start": "1954840",
    "end": "1960440"
  },
  {
    "text": "that that API as well so so that is then if if there are A1 100s in your in your",
    "start": "1960440",
    "end": "1965679"
  },
  {
    "text": "in your system and they meet that specification then like they are selected if t4s meet that sort of",
    "start": "1965679",
    "end": "1971480"
  },
  {
    "text": "specification um they are selected I think Kevin gave a talk a virtual talk yesterday where he demonstrates that",
    "start": "1971480",
    "end": "1978399"
  },
  {
    "text": "that flexibility in terms of device selection so as a user you can select that so you have to give the scheduler",
    "start": "1978399",
    "end": "1983840"
  },
  {
    "text": "that information and with that information the scheduler can then select the node where that device is and",
    "start": "1983840",
    "end": "1989279"
  },
  {
    "text": "then that device is the one that is associated with that request okay got it so it's kind of still use the preconfig",
    "start": "1989279",
    "end": "1995399"
  },
  {
    "text": "yamamo there to us to already set to put kind of result pull there right so yes",
    "start": "1995399",
    "end": "2002960"
  },
  {
    "text": "so the the user has to specify that up front but one can so Dr is an API that",
    "start": "2002960",
    "end": "2008080"
  },
  {
    "text": "you can build tools on top of so so some Q or or or something insert hand hand",
    "start": "2008080",
    "end": "2014720"
  },
  {
    "text": "wavy here uh can analyze a job understand what that mapping is and",
    "start": "2014720",
    "end": "2020480"
  },
  {
    "text": "convert that to a Dr request and that's actually what um our Triton management server does and we have a demo including",
    "start": "2020480",
    "end": "2026600"
  },
  {
    "text": "that where on the AP the user the ux side you're exposing some other concept",
    "start": "2026600",
    "end": "2032039"
  },
  {
    "text": "like I want an inference GPU and Triton API server Triton management server like",
    "start": "2032039",
    "end": "2037320"
  },
  {
    "text": "converts that to some equivalent Dr request so it's not happening in kubernetes because it's maybe more",
    "start": "2037320",
    "end": "2042880"
  },
  {
    "text": "domain specific yes but it it provides that flexibility okay got it cool",
    "start": "2042880",
    "end": "2050040"
  },
  {
    "text": "thanks so I have a more of a understanding question so um in this setup when there is let's say one GPU or",
    "start": "2051520",
    "end": "2059398"
  },
  {
    "text": "resource or TPU on a node uh can multiple pods use the resource at the same time simultaneously or do they have",
    "start": "2059399",
    "end": "2066599"
  },
  {
    "text": "to like Contex switch out and take turns right now or I mean yeah so I think it it",
    "start": "2066599",
    "end": "2073320"
  },
  {
    "text": "right now the way the device plug-in model works is once that device is allocated uh to to a workload no other",
    "start": "2073320",
    "end": "2079320"
  },
  {
    "text": "workload can use that uh device right and so some some folks have kind of come up with workarounds where for example",
    "start": "2079320",
    "end": "2085560"
  },
  {
    "text": "they advertise multiple devices in the device plugin model uh and underneath that's actually the same device but it's",
    "start": "2085560",
    "end": "2091200"
  },
  {
    "text": "advertised with different names right and then multiple workloads can use it right but that's actually one of the problems we're trying to solve and we",
    "start": "2091200",
    "end": "2097160"
  },
  {
    "text": "see as like kind of one of the gaps in the device plug-in model today right it doesn't really have good sharing uh between different devices right and",
    "start": "2097160",
    "end": "2103079"
  },
  {
    "text": "that's dra is trying to solve that problem as well right yeah yeah so there is um the current our device plug-in",
    "start": "2103079",
    "end": "2109599"
  },
  {
    "text": "implementation and the one at gke does support time slicing um so it's but that's just over subscription but you as",
    "start": "2109599",
    "end": "2115440"
  },
  {
    "text": "a user have no control of which device is actually selected in the end so it could be that you end up on a device",
    "start": "2115440",
    "end": "2121400"
  },
  {
    "text": "that already has other processes running and there's also not the same um memory",
    "start": "2121400",
    "end": "2127520"
  },
  {
    "text": "isolation guarantees that you may may have with something like MPS like there's isolation you can't read another processor's memory but if that process",
    "start": "2127520",
    "end": "2134000"
  },
  {
    "text": "uses all the memory then you could o for example right on on the device level so there is some support for it but it's",
    "start": "2134000",
    "end": "2139599"
  },
  {
    "text": "more of a a workaround at the moment Goa so will there be like a dedicated uh",
    "start": "2139599",
    "end": "2144880"
  },
  {
    "text": "Hardware based support for that like you know uh CPUs have this virtualization technology for that right like would",
    "start": "2144880",
    "end": "2150520"
  },
  {
    "text": "there be a future support for something like that like splitting existing Hardware resources so I mean you you",
    "start": "2150520",
    "end": "2158240"
  },
  {
    "text": "also have in terms of Hardware support you have something like Mig which is Hardware level partitioning of a larger",
    "start": "2158240",
    "end": "2164560"
  },
  {
    "text": "device and what we have there is you expose each one of those slices those",
    "start": "2164560",
    "end": "2169839"
  },
  {
    "text": "Hardware slices as a separate device and you can also layer time slicing or MPS",
    "start": "2169839",
    "end": "2174920"
  },
  {
    "text": "on top of that so you're able to use like the various sharing mechanisms in combination and sort of Select something",
    "start": "2174920",
    "end": "2180200"
  },
  {
    "text": "that that works for you so it's a multi-level sort of sharing problem there okay don't if that your question",
    "start": "2180200",
    "end": "2187119"
  },
  {
    "text": "there are um some in the links I provided is one of them is regarding um sharing incubators of our existing",
    "start": "2187119",
    "end": "2193599"
  },
  {
    "text": "device plugin and so you can have a look there and maybe that answer some of your questions further okay sounds good thank you cool",
    "start": "2193599",
    "end": "2201000"
  },
  {
    "text": "thanks s for for the great uh talk and I have a question about the da and what's",
    "start": "2201359",
    "end": "2207640"
  },
  {
    "text": "the largest broker for making it a ga sorry I what's the largest broker for",
    "start": "2207640",
    "end": "2214760"
  },
  {
    "text": "making it the TA for DRX um the largest blocker the largest I think so there's a little thing called",
    "start": "2214760",
    "end": "2222079"
  },
  {
    "text": "theer and the autoscaler um no um so so the the current implementation uh it",
    "start": "2222079",
    "end": "2229480"
  },
  {
    "text": "communicates with the scheduler through the API server and that adds quite a bit of scheduling overhead and because the",
    "start": "2229480",
    "end": "2236480"
  },
  {
    "text": "scheduler is sequential for a large part of it sort of like scheduling process uh",
    "start": "2236480",
    "end": "2242240"
  },
  {
    "text": "things that take long there ends up blocking all other pods that should be scheduled right so",
    "start": "2242240",
    "end": "2247560"
  },
  {
    "text": "even if those are not using claims that are associated with devices I think that's sort of a rough summary Kevin",
    "start": "2247560",
    "end": "2254000"
  },
  {
    "text": "Kevin can add more context there um at the front but sort of the rough summary is that it slows down scheduling because",
    "start": "2254000",
    "end": "2260079"
  },
  {
    "text": "of the communication between the controller component of your Dr driver and the scheduler and the other uh issue is that",
    "start": "2260079",
    "end": "2269480"
  },
  {
    "text": "for on the autoscaling side because we have this flexibility in the API um the",
    "start": "2269480",
    "end": "2274520"
  },
  {
    "text": "autoscaler doesn't have all the information it needs to perform the simulations it needs to perform to know",
    "start": "2274520",
    "end": "2280000"
  },
  {
    "text": "which resources to to noes to scale up so there needs to be some API defined between the autoscaler and the device",
    "start": "2280000",
    "end": "2286280"
  },
  {
    "text": "driver or controller of the of the devices to know to to get that information and because that will also",
    "start": "2286280",
    "end": "2292280"
  },
  {
    "text": "introduce",
    "start": "2292280",
    "end": "2294680"
  },
  {
    "text": "latency",
    "start": "2305520",
    "end": "2308520"
  },
  {
    "text": "hi okay yeah um because you're introducing latency there and the aut scaler does like I think order of",
    "start": "2314560",
    "end": "2321560"
  },
  {
    "text": "magnitude more computations and Communications with that driver like the concern is that that's going to slow",
    "start": "2321560",
    "end": "2327079"
  },
  {
    "text": "things down and auto scaling is not going to be responsive so those are like the two main main blockers at the moment",
    "start": "2327079",
    "end": "2332599"
  },
  {
    "text": "so one one is for the p scheding and the other is for auto scaling right yeah yes I see uh do we have a benchmark for it",
    "start": "2332599",
    "end": "2339560"
  },
  {
    "text": "what's the current number like how many parts we can schedu in one second I don't have that information I think",
    "start": "2339560",
    "end": "2345160"
  },
  {
    "text": "Patrick has done benchmarks so Patrick Oy from Intel is the one that's been driving the sort of the Dr cap um and",
    "start": "2345160",
    "end": "2352640"
  },
  {
    "text": "he's done benchmarking uh but I don't have numbers on that or what the target is so maybe ask him there's a Dr Dev",
    "start": "2352640",
    "end": "2361079"
  },
  {
    "text": "like at on the on the kubernetes slack channels so you can just ask there thank you",
    "start": "2361079",
    "end": "2367000"
  },
  {
    "text": "or or and and yeah so I think uh sort of part of the discussions that came out of this conference is that we're going to",
    "start": "2367000",
    "end": "2372160"
  },
  {
    "text": "at least start an informal working group to start with uh with interested parties from um schedular from autoscaler and",
    "start": "2372160",
    "end": "2378720"
  },
  {
    "text": "the Dr sort of developers to try and sort of address at least understand",
    "start": "2378720",
    "end": "2384160"
  },
  {
    "text": "these problems a bit better and then start addressing them and see what's required to to move forward yeah that's",
    "start": "2384160",
    "end": "2389200"
  },
  {
    "text": "great thank you cool so this is a question for for David",
    "start": "2389200",
    "end": "2397119"
  },
  {
    "text": "I was looking at your slides and you showed there's different types of tpus that you can allocate so have you",
    "start": "2397119",
    "end": "2403560"
  },
  {
    "text": "considered allocating have you you considered um tpus as a possible use",
    "start": "2403560",
    "end": "2409359"
  },
  {
    "text": "case for dynamically for for your Dr for dynamically allocating different types of tpus based on workloads yeah yeah",
    "start": "2409359",
    "end": "2416280"
  },
  {
    "text": "it's actually a really good question and something something we looked into um so right now the way it works right I think",
    "start": "2416280",
    "end": "2421720"
  },
  {
    "text": "when we looked at Dr Dr is really good when the devices uh can change right so you can with with tpus you can use Mig",
    "start": "2421720",
    "end": "2428119"
  },
  {
    "text": "you can split them up and so forth right with tpus today uh when you bring up a TPU machine with some certain topology",
    "start": "2428119",
    "end": "2434440"
  },
  {
    "text": "that topology doesn't change over the course of the lifetime of that node right and so since the since the device",
    "start": "2434440",
    "end": "2439960"
  },
  {
    "text": "itself is pretty static it actually fits pretty well in the device plug-in model right but that's the current state with with tpus so if things change um maybe",
    "start": "2439960",
    "end": "2447440"
  },
  {
    "text": "the Dr approach or something that's more Dynamic where devices can repetition will be more useful for",
    "start": "2447440",
    "end": "2453920"
  },
  {
    "text": "it one question",
    "start": "2454560",
    "end": "2458319"
  },
  {
    "text": "yeah sorry the question is does your Nvidia operator or the device plugin can do those slicing time slicing Mig and",
    "start": "2467240",
    "end": "2474079"
  },
  {
    "text": "MPS or I have to go for a special tool no so yeah the device plugins uh support",
    "start": "2474079",
    "end": "2479760"
  },
  {
    "text": "that oh okay thank to to configure the device plug in your work make",
    "start": "2479760",
    "end": "2485000"
  },
  {
    "text": "ofps okay a right thank you hey apologies if this question has",
    "start": "2485000",
    "end": "2492440"
  },
  {
    "text": "already been asked but is there thoughts on enabling cgroups for Dr so can I have",
    "start": "2492440",
    "end": "2500319"
  },
  {
    "text": "like a pod with guaranteed qos and maybe a best effort one and have like cgroup",
    "start": "2500319",
    "end": "2506200"
  },
  {
    "text": "sort of enforcement across the two with the",
    "start": "2506200",
    "end": "2510400"
  },
  {
    "text": "ra um I know that there's a discuss",
    "start": "2511520",
    "end": "2516560"
  },
  {
    "text": "around um qos classes uh which is somewhat related to",
    "start": "2516560",
    "end": "2522000"
  },
  {
    "text": "Dr but I don't think that Dr is trying to solve that problem necessarily so I I I I don't have the right answers there",
    "start": "2522000",
    "end": "2528920"
  },
  {
    "text": "but I think reach out to someone like Alexander keski from Intel um he might have a better response thanks sorry",
    "start": "2528920",
    "end": "2536920"
  },
  {
    "text": "maybe David has more input there just just one thing to add I think with the cgroups today right like um the c groups",
    "start": "2536920",
    "end": "2542160"
  },
  {
    "text": "are built into the kernel right and they have like the devices like CPU and memory and those things are all very uniform right so it's very easy to make",
    "start": "2542160",
    "end": "2548280"
  },
  {
    "text": "one implementation that works for them but when you have these devices that all have like different properties and so forth It's hard to make a cgroup",
    "start": "2548280",
    "end": "2553640"
  },
  {
    "text": "controller for them right so that's why we have like these vendor specific things but there are like maybe certain things that we can look at maybe like",
    "start": "2553640",
    "end": "2559720"
  },
  {
    "text": "that all devices have right that that c groups can help with right so some something interesting to look at for sure thank",
    "start": "2559720",
    "end": "2567318"
  },
  {
    "text": "you cool thank you so much everybody",
    "start": "2569520",
    "end": "2576359"
  }
]
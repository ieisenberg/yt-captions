[
  {
    "text": "um yeah so let's start a few words about",
    "start": "5880",
    "end": "8820"
  },
  {
    "text": "me I'm a goaling developer and Tech lead",
    "start": "8820",
    "end": "11880"
  },
  {
    "text": "at convert",
    "start": "11880",
    "end": "13679"
  },
  {
    "text": "uh we mainly dealing with kubernetes and",
    "start": "13679",
    "end": "16859"
  },
  {
    "text": "Cloud native staff",
    "start": "16859",
    "end": "18420"
  },
  {
    "text": "um",
    "start": "18420",
    "end": "18960"
  },
  {
    "text": "we're building a platform for AI and",
    "start": "18960",
    "end": "21060"
  },
  {
    "text": "machine learning on top of the",
    "start": "21060",
    "end": "22619"
  },
  {
    "text": "kubernetes",
    "start": "22619",
    "end": "23880"
  },
  {
    "text": "I'm a husband and father two kids and",
    "start": "23880",
    "end": "27359"
  },
  {
    "text": "finally I am at the middle of my Skipper",
    "start": "27359",
    "end": "29460"
  },
  {
    "text": "course and I actually I'm at the end and",
    "start": "29460",
    "end": "31859"
  },
  {
    "text": "I'm really excited about this",
    "start": "31859",
    "end": "34500"
  },
  {
    "text": "and uh so what is talk about uh we will",
    "start": "34500",
    "end": "38160"
  },
  {
    "text": "talk a bit about containers and device",
    "start": "38160",
    "end": "40079"
  },
  {
    "text": "sharing",
    "start": "40079",
    "end": "42059"
  },
  {
    "text": "um and then how",
    "start": "42059",
    "end": "44460"
  },
  {
    "text": "this works in kubernetes how the",
    "start": "44460",
    "end": "47160"
  },
  {
    "text": "kubernetes manage resources and how",
    "start": "47160",
    "end": "49980"
  },
  {
    "text": "kubernetes manage these resources",
    "start": "49980",
    "end": "53760"
  },
  {
    "text": "um what are the production grade",
    "start": "53760",
    "end": "55140"
  },
  {
    "text": "challenges and finally we will talk",
    "start": "55140",
    "end": "57239"
  },
  {
    "text": "about meta GPU which is our open source",
    "start": "57239",
    "end": "60059"
  },
  {
    "text": "project",
    "start": "60059",
    "end": "62039"
  },
  {
    "text": "um yeah so uh let's stop",
    "start": "62039",
    "end": "65338"
  },
  {
    "text": "um so let's talk a bit about how we",
    "start": "65339",
    "end": "69180"
  },
  {
    "text": "going how we can share device on Linux",
    "start": "69180",
    "end": "71760"
  },
  {
    "text": "and if I will take a simple example",
    "start": "71760",
    "end": "74520"
  },
  {
    "text": "where I am creating simple loopback file",
    "start": "74520",
    "end": "77280"
  },
  {
    "text": "and I would like to share this lubric",
    "start": "77280",
    "end": "79680"
  },
  {
    "text": "file like I would like to mount it",
    "start": "79680",
    "end": "82140"
  },
  {
    "text": "um",
    "start": "82140",
    "end": "82680"
  },
  {
    "text": "and I would like to mount between",
    "start": "82680",
    "end": "85619"
  },
  {
    "text": "I would like to use it between many",
    "start": "85619",
    "end": "88080"
  },
  {
    "text": "different processes right so um I will",
    "start": "88080",
    "end": "91439"
  },
  {
    "text": "be able to mount it as read-only as much",
    "start": "91439",
    "end": "94740"
  },
  {
    "text": "as I want right but if I will try to",
    "start": "94740",
    "end": "96479"
  },
  {
    "text": "mount it as a read write it will fail",
    "start": "96479",
    "end": "98299"
  },
  {
    "text": "now this pretty obvious uh a pretty",
    "start": "98299",
    "end": "102420"
  },
  {
    "text": "obvious example which can teach us one",
    "start": "102420",
    "end": "105840"
  },
  {
    "text": "simple fact sharing devices between",
    "start": "105840",
    "end": "108420"
  },
  {
    "text": "processes on Linux will be depends on",
    "start": "108420",
    "end": "111360"
  },
  {
    "text": "two things basically on the device",
    "start": "111360",
    "end": "113159"
  },
  {
    "text": "driver and on the setup on the",
    "start": "113159",
    "end": "115680"
  },
  {
    "text": "configuration so in in some cases I will",
    "start": "115680",
    "end": "119820"
  },
  {
    "text": "be able to share device and another case",
    "start": "119820",
    "end": "123299"
  },
  {
    "text": "I want I might be not be able to sell",
    "start": "123299",
    "end": "125159"
  },
  {
    "text": "this device",
    "start": "125159",
    "end": "126299"
  },
  {
    "text": "so with that let's move to the",
    "start": "126299",
    "end": "130380"
  },
  {
    "text": "um",
    "start": "130380",
    "end": "131099"
  },
  {
    "text": "second simple uh question and we are",
    "start": "131099",
    "end": "136080"
  },
  {
    "text": "talking about kubernetes and Ai and gpus",
    "start": "136080",
    "end": "139440"
  },
  {
    "text": "so how easily I can share GPU device",
    "start": "139440",
    "end": "144000"
  },
  {
    "text": "between two Docker containers",
    "start": "144000",
    "end": "147060"
  },
  {
    "text": "what do you think guys is is if like how",
    "start": "147060",
    "end": "150420"
  },
  {
    "text": "easily I can share my GPU device",
    "start": "150420",
    "end": "154620"
  },
  {
    "text": "um so I think the most simple thing that",
    "start": "154620",
    "end": "156599"
  },
  {
    "text": "we can do is just figure it out right",
    "start": "156599",
    "end": "159239"
  },
  {
    "text": "so I have very simple tensorflow script",
    "start": "159239",
    "end": "162660"
  },
  {
    "text": "and this tensorflow script uses um",
    "start": "162660",
    "end": "165900"
  },
  {
    "text": "uh GPU GPU index 0. and I would like to",
    "start": "165900",
    "end": "169440"
  },
  {
    "text": "run two Docker containers and see if",
    "start": "169440",
    "end": "171540"
  },
  {
    "text": "they both will be running and if they",
    "start": "171540",
    "end": "174180"
  },
  {
    "text": "both will be used this GPU so",
    "start": "174180",
    "end": "177420"
  },
  {
    "text": "let me show you really quickly this is",
    "start": "177420",
    "end": "180840"
  },
  {
    "text": "my bus script this is my two containers",
    "start": "180840",
    "end": "184200"
  },
  {
    "text": "and I will just execute this script and",
    "start": "184200",
    "end": "187379"
  },
  {
    "text": "my two containers out up and running if",
    "start": "187379",
    "end": "190080"
  },
  {
    "text": "I will check logs",
    "start": "190080",
    "end": "193099"
  },
  {
    "text": "and this so this is a GPU minus one",
    "start": "193680",
    "end": "197640"
  },
  {
    "text": "container",
    "start": "197640",
    "end": "199500"
  },
  {
    "text": "and this is locked for the second one so",
    "start": "199500",
    "end": "201659"
  },
  {
    "text": "it seems like my my both Docker",
    "start": "201659",
    "end": "204060"
  },
  {
    "text": "containers are up and running which",
    "start": "204060",
    "end": "206040"
  },
  {
    "text": "means I will able to share single GPU",
    "start": "206040",
    "end": "209459"
  },
  {
    "text": "between two different containers right",
    "start": "209459",
    "end": "211440"
  },
  {
    "text": "so what about Nvidia SMI",
    "start": "211440",
    "end": "214140"
  },
  {
    "text": "yeah so you see this",
    "start": "214140",
    "end": "216060"
  },
  {
    "text": "uh processes they belong to these",
    "start": "216060",
    "end": "218760"
  },
  {
    "text": "containers and it seems like everything",
    "start": "218760",
    "end": "220440"
  },
  {
    "text": "is working so if I came from the",
    "start": "220440",
    "end": "225720"
  },
  {
    "text": "um from non-kubernetes area right but I",
    "start": "225720",
    "end": "229080"
  },
  {
    "text": "do want to use Dockers or containers in",
    "start": "229080",
    "end": "231720"
  },
  {
    "text": "general I can say that I will be able to",
    "start": "231720",
    "end": "235080"
  },
  {
    "text": "share my GPU devices between my",
    "start": "235080",
    "end": "237599"
  },
  {
    "text": "containers which is really good now",
    "start": "237599",
    "end": "241140"
  },
  {
    "text": "uh I will clean up this one",
    "start": "241140",
    "end": "245220"
  },
  {
    "text": "so what about kubernetes will will be it",
    "start": "245220",
    "end": "248700"
  },
  {
    "text": "possible to achieve exactly the same",
    "start": "248700",
    "end": "250379"
  },
  {
    "text": "behavior with the kubernetes right so",
    "start": "250379",
    "end": "254159"
  },
  {
    "text": "again like it's open question it might",
    "start": "254159",
    "end": "256620"
  },
  {
    "text": "be it might be yes maybe no but again we",
    "start": "256620",
    "end": "259560"
  },
  {
    "text": "can easily figure this out right so let",
    "start": "259560",
    "end": "262919"
  },
  {
    "text": "me jump to my second panel and and you",
    "start": "262919",
    "end": "265740"
  },
  {
    "text": "see now I'm going to deploy exactly the",
    "start": "265740",
    "end": "267660"
  },
  {
    "text": "same container but this time I'm going",
    "start": "267660",
    "end": "270180"
  },
  {
    "text": "to use kubernetes manifest and",
    "start": "270180",
    "end": "273300"
  },
  {
    "text": "kubernetes cluster I will create two",
    "start": "273300",
    "end": "275580"
  },
  {
    "text": "replicas of the or of this container",
    "start": "275580",
    "end": "278699"
  },
  {
    "text": "like two replicas inside this uh uh",
    "start": "278699",
    "end": "281639"
  },
  {
    "text": "deployment and I will use one GPU",
    "start": "281639",
    "end": "284520"
  },
  {
    "text": "exactly the same scenario as it was with",
    "start": "284520",
    "end": "287639"
  },
  {
    "text": "a Docker so now",
    "start": "287639",
    "end": "290940"
  },
  {
    "text": "if I will apply this",
    "start": "290940",
    "end": "294620"
  },
  {
    "text": "if I will",
    "start": "296100",
    "end": "297960"
  },
  {
    "text": "uh create like that yeah so my um you",
    "start": "297960",
    "end": "303180"
  },
  {
    "text": "see I I created I created this",
    "start": "303180",
    "end": "305280"
  },
  {
    "text": "deployment and one a container is",
    "start": "305280",
    "end": "308160"
  },
  {
    "text": "running the second one is pending any",
    "start": "308160",
    "end": "310380"
  },
  {
    "text": "idea why it's painting depending on what",
    "start": "310380",
    "end": "312660"
  },
  {
    "text": "or what fall it is painting",
    "start": "312660",
    "end": "316380"
  },
  {
    "text": "it's waiting for new machine okay let's",
    "start": "316380",
    "end": "318120"
  },
  {
    "text": "let's see why it's waiting and we can",
    "start": "318120",
    "end": "320639"
  },
  {
    "text": "pretty easily describe this",
    "start": "320639",
    "end": "323940"
  },
  {
    "text": "and indeed it has inefficient Nvidia GPU",
    "start": "323940",
    "end": "328680"
  },
  {
    "text": "um this is what at least kubernetes",
    "start": "328680",
    "end": "330979"
  },
  {
    "text": "thing happening now uh okay it's saying",
    "start": "330979",
    "end": "335880"
  },
  {
    "text": "that I I have I have not enough gpus let",
    "start": "335880",
    "end": "338699"
  },
  {
    "text": "me run Nvidia SMI and see",
    "start": "338699",
    "end": "342240"
  },
  {
    "text": "what is going on so indeed there's only",
    "start": "342240",
    "end": "345180"
  },
  {
    "text": "one process that is running but my GPU",
    "start": "345180",
    "end": "348180"
  },
  {
    "text": "utilization is equal to zero and I'm",
    "start": "348180",
    "end": "350400"
  },
  {
    "text": "using only two gig of memory where I",
    "start": "350400",
    "end": "353160"
  },
  {
    "text": "have in total 12 almost 12 gigabytes of",
    "start": "353160",
    "end": "355560"
  },
  {
    "text": "memory so um kubernetes is just just not",
    "start": "355560",
    "end": "359460"
  },
  {
    "text": "aware about the fact that I do have",
    "start": "359460",
    "end": "361740"
  },
  {
    "text": "enough GPU",
    "start": "361740",
    "end": "363740"
  },
  {
    "text": "capacity it's just saying I do not have",
    "start": "363740",
    "end": "367080"
  },
  {
    "text": "enough",
    "start": "367080",
    "end": "368520"
  },
  {
    "text": "um",
    "start": "368520",
    "end": "369180"
  },
  {
    "text": "right so uh",
    "start": "369180",
    "end": "371940"
  },
  {
    "text": "and this Behavior seems",
    "start": "371940",
    "end": "375180"
  },
  {
    "text": "not right because if I came from the",
    "start": "375180",
    "end": "378180"
  },
  {
    "text": "Linux world right I were able to share",
    "start": "378180",
    "end": "381060"
  },
  {
    "text": "my GPU device then I took Docker and I",
    "start": "381060",
    "end": "385520"
  },
  {
    "text": "also able to Shell a GPU device so why",
    "start": "385520",
    "end": "388440"
  },
  {
    "text": "kubernetes does not allow me to achieve",
    "start": "388440",
    "end": "391139"
  },
  {
    "text": "the same behavior right because",
    "start": "391139",
    "end": "392520"
  },
  {
    "text": "kubernetes is based on Linux it is based",
    "start": "392520",
    "end": "394800"
  },
  {
    "text": "on on containers but it is not in fact",
    "start": "394800",
    "end": "397500"
  },
  {
    "text": "we see that it is not possible so you",
    "start": "397500",
    "end": "400620"
  },
  {
    "text": "know what let me clean this up clean up",
    "start": "400620",
    "end": "403860"
  },
  {
    "text": "right like that",
    "start": "403860",
    "end": "405620"
  },
  {
    "text": "in um and now I want to achieve exactly",
    "start": "405620",
    "end": "410460"
  },
  {
    "text": "the same behavior as with",
    "start": "410460",
    "end": "412979"
  },
  {
    "text": "um Dockers I would like to achieve",
    "start": "412979",
    "end": "414780"
  },
  {
    "text": "exactly the same behavior with the",
    "start": "414780",
    "end": "416280"
  },
  {
    "text": "kubernetes",
    "start": "416280",
    "end": "417479"
  },
  {
    "text": "so um yeah I will change a bit my",
    "start": "417479",
    "end": "421319"
  },
  {
    "text": "deployment manifest and I will try to",
    "start": "421319",
    "end": "423660"
  },
  {
    "text": "apply it again now",
    "start": "423660",
    "end": "425880"
  },
  {
    "text": "um",
    "start": "425880",
    "end": "427940"
  },
  {
    "text": "so what kind of changes I will apply to",
    "start": "428880",
    "end": "432300"
  },
  {
    "text": "achieve the same behavior as I had with",
    "start": "432300",
    "end": "435300"
  },
  {
    "text": "docule so first of all I will remove",
    "start": "435300",
    "end": "437460"
  },
  {
    "text": "this resource limits and Nvidia I will",
    "start": "437460",
    "end": "439919"
  },
  {
    "text": "just remove it you see this is the",
    "start": "439919",
    "end": "442380"
  },
  {
    "text": "10.yaml file that I'm going to apply and",
    "start": "442380",
    "end": "446520"
  },
  {
    "text": "we won't find here any",
    "start": "446520",
    "end": "449479"
  },
  {
    "text": "nvidia.com anymore",
    "start": "449479",
    "end": "452039"
  },
  {
    "text": "and this is first change the second",
    "start": "452039",
    "end": "453599"
  },
  {
    "text": "change is I will add one environment",
    "start": "453599",
    "end": "456180"
  },
  {
    "text": "variable Nvidia visible devices and I",
    "start": "456180",
    "end": "459120"
  },
  {
    "text": "will just statically set it to zero so",
    "start": "459120",
    "end": "463199"
  },
  {
    "text": "now let me",
    "start": "463199",
    "end": "465599"
  },
  {
    "text": "create this yaml",
    "start": "465599",
    "end": "468919"
  },
  {
    "text": "like that and see what will happen",
    "start": "468960",
    "end": "472500"
  },
  {
    "text": "okay so now I have like I have single",
    "start": "472500",
    "end": "475620"
  },
  {
    "text": "container",
    "start": "475620",
    "end": "478440"
  },
  {
    "text": "let me scale it to two containers",
    "start": "478440",
    "end": "483240"
  },
  {
    "text": "and let's see if it will be running it",
    "start": "483240",
    "end": "485340"
  },
  {
    "text": "is running okay it's really cool",
    "start": "485340",
    "end": "488520"
  },
  {
    "text": "so let me scale it to four containers",
    "start": "488520",
    "end": "492800"
  },
  {
    "text": "oh not 41.",
    "start": "492900",
    "end": "495539"
  },
  {
    "text": "by the way 41 will work as well",
    "start": "495539",
    "end": "498900"
  },
  {
    "text": "um let's see yeah so I have four",
    "start": "498900",
    "end": "501419"
  },
  {
    "text": "containers this is awesome what about",
    "start": "501419",
    "end": "503280"
  },
  {
    "text": "Nvidia semi",
    "start": "503280",
    "end": "506300"
  },
  {
    "text": "and Nvidia is my IC for processors so I",
    "start": "507539",
    "end": "512099"
  },
  {
    "text": "will able to share my GPU right I did",
    "start": "512099",
    "end": "515459"
  },
  {
    "text": "not install any devices plugins I mean",
    "start": "515459",
    "end": "518580"
  },
  {
    "text": "nothing",
    "start": "518580",
    "end": "519599"
  },
  {
    "text": "uh I I achieved exactly the same",
    "start": "519599",
    "end": "522060"
  },
  {
    "text": "behavior as I had with Docker and with",
    "start": "522060",
    "end": "525120"
  },
  {
    "text": "Linux and basically like from this point",
    "start": "525120",
    "end": "528060"
  },
  {
    "text": "I can go to my manager and say hey I I",
    "start": "528060",
    "end": "530880"
  },
  {
    "text": "am able to share my GPU like gpus I'm",
    "start": "530880",
    "end": "534240"
  },
  {
    "text": "able to achieve um",
    "start": "534240",
    "end": "536399"
  },
  {
    "text": "the fractional GPU right without even",
    "start": "536399",
    "end": "539339"
  },
  {
    "text": "writing a piece of code",
    "start": "539339",
    "end": "541860"
  },
  {
    "text": "but probably if this was true we",
    "start": "541860",
    "end": "546600"
  },
  {
    "text": "this talk wouldn't happen right there is",
    "start": "546600",
    "end": "550080"
  },
  {
    "text": "a reason why uh I'm presenting",
    "start": "550080",
    "end": "555560"
  },
  {
    "text": "what",
    "start": "557459",
    "end": "560459"
  },
  {
    "text": "yeah so yeah this is exactly what I I'm",
    "start": "563820",
    "end": "566459"
  },
  {
    "text": "going to talk next so exactly we we use",
    "start": "566459",
    "end": "570300"
  },
  {
    "text": "uh we usually we use kubernetes when we",
    "start": "570300",
    "end": "573480"
  },
  {
    "text": "have at least plans to use one more than",
    "start": "573480",
    "end": "577920"
  },
  {
    "text": "one node and",
    "start": "577920",
    "end": "580200"
  },
  {
    "text": "um",
    "start": "580200",
    "end": "581339"
  },
  {
    "text": "all right so uh and if we will have more",
    "start": "581339",
    "end": "584339"
  },
  {
    "text": "than one node we will have",
    "start": "584339",
    "end": "586080"
  },
  {
    "text": "um many different devices specs right I",
    "start": "586080",
    "end": "588600"
  },
  {
    "text": "might have a different amount of GPU",
    "start": "588600",
    "end": "591660"
  },
  {
    "text": "units different amount of memory on each",
    "start": "591660",
    "end": "593580"
  },
  {
    "text": "device and and I will need to address",
    "start": "593580",
    "end": "595920"
  },
  {
    "text": "this in certain way",
    "start": "595920",
    "end": "598680"
  },
  {
    "text": "um also how I will choose the right node",
    "start": "598680",
    "end": "601080"
  },
  {
    "text": "this is also something that I need to",
    "start": "601080",
    "end": "602820"
  },
  {
    "text": "care of in in some way uh how am I going",
    "start": "602820",
    "end": "606839"
  },
  {
    "text": "to calculate total availability and",
    "start": "606839",
    "end": "609240"
  },
  {
    "text": "capacity in my example I will able to",
    "start": "609240",
    "end": "612180"
  },
  {
    "text": "create like I started from one",
    "start": "612180",
    "end": "614640"
  },
  {
    "text": "go to two I scaled it to four and I can",
    "start": "614640",
    "end": "617940"
  },
  {
    "text": "like it's completely unmanageable",
    "start": "617940",
    "end": "619980"
  },
  {
    "text": "someone need to enforce and calculate",
    "start": "619980",
    "end": "623399"
  },
  {
    "text": "what is the availability and capacity",
    "start": "623399",
    "end": "626100"
  },
  {
    "text": "like to how many pieces I would like to",
    "start": "626100",
    "end": "628440"
  },
  {
    "text": "split my device",
    "start": "628440",
    "end": "631019"
  },
  {
    "text": "and finally what to do if some devices",
    "start": "631019",
    "end": "633540"
  },
  {
    "text": "are not healthy right today we have all",
    "start": "633540",
    "end": "635940"
  },
  {
    "text": "these Cloud node groups in clouds and",
    "start": "635940",
    "end": "639300"
  },
  {
    "text": "and we have scale to zero policies and",
    "start": "639300",
    "end": "641220"
  },
  {
    "text": "so on so on and might be my device is",
    "start": "641220",
    "end": "643380"
  },
  {
    "text": "not healthy maybe yet not healthy and I",
    "start": "643380",
    "end": "646140"
  },
  {
    "text": "need to address this as well and",
    "start": "646140",
    "end": "647940"
  },
  {
    "text": "probably there are many other reasons",
    "start": "647940",
    "end": "650100"
  },
  {
    "text": "that I'm not mentioning here but they",
    "start": "650100",
    "end": "652260"
  },
  {
    "text": "are exist right",
    "start": "652260",
    "end": "654540"
  },
  {
    "text": "so with that what kind of resources we",
    "start": "654540",
    "end": "657720"
  },
  {
    "text": "have uh",
    "start": "657720",
    "end": "659579"
  },
  {
    "text": "out of the box",
    "start": "659579",
    "end": "661800"
  },
  {
    "text": "um inside kubernetes I mean what",
    "start": "661800",
    "end": "663839"
  },
  {
    "text": "resources kubernetes manage for us and",
    "start": "663839",
    "end": "667140"
  },
  {
    "text": "we have CPU memory ephemeral storage and",
    "start": "667140",
    "end": "670680"
  },
  {
    "text": "huge Pages all those are available out",
    "start": "670680",
    "end": "673620"
  },
  {
    "text": "of the box which means kubernetes aware",
    "start": "673620",
    "end": "676500"
  },
  {
    "text": "about total capacity and allocatable",
    "start": "676500",
    "end": "681959"
  },
  {
    "text": "um which help us as the end users",
    "start": "681959",
    "end": "684720"
  },
  {
    "text": "to schedule our workloads in the in the",
    "start": "684720",
    "end": "688740"
  },
  {
    "text": "way that we are aware about like what",
    "start": "688740",
    "end": "690660"
  },
  {
    "text": "amount of CPU are going to request and",
    "start": "690660",
    "end": "692640"
  },
  {
    "text": "and the memory and if I have enough or",
    "start": "692640",
    "end": "694620"
  },
  {
    "text": "not enough and kubernetes will match uh",
    "start": "694620",
    "end": "696899"
  },
  {
    "text": "the right note for me and so on uh but",
    "start": "696899",
    "end": "700140"
  },
  {
    "text": "obviously we have much more resources",
    "start": "700140",
    "end": "703980"
  },
  {
    "text": "than these four right one of them is GPU",
    "start": "703980",
    "end": "707160"
  },
  {
    "text": "but GPU but kubernetes itself does not",
    "start": "707160",
    "end": "710279"
  },
  {
    "text": "address GPU issue in any way",
    "start": "710279",
    "end": "714480"
  },
  {
    "text": "um and this is where the custom node",
    "start": "714480",
    "end": "716519"
  },
  {
    "text": "resource and device plugin came came in",
    "start": "716519",
    "end": "719100"
  },
  {
    "text": "actually what kubernetes allow us to do",
    "start": "719100",
    "end": "722399"
  },
  {
    "text": "is um",
    "start": "722399",
    "end": "723720"
  },
  {
    "text": "we can extend kubernetes and implement",
    "start": "723720",
    "end": "727920"
  },
  {
    "text": "required Logic for our",
    "start": "727920",
    "end": "730860"
  },
  {
    "text": "device right so I can say I can decide",
    "start": "730860",
    "end": "734700"
  },
  {
    "text": "now how I going to allocate",
    "start": "734700",
    "end": "737880"
  },
  {
    "text": "um",
    "start": "737880",
    "end": "738420"
  },
  {
    "text": "device right what should happens exactly",
    "start": "738420",
    "end": "741000"
  },
  {
    "text": "when I'm allocating device and so on so",
    "start": "741000",
    "end": "743760"
  },
  {
    "text": "on so very quickly",
    "start": "743760",
    "end": "747060"
  },
  {
    "text": "um the quality device plugin based on",
    "start": "747060",
    "end": "748980"
  },
  {
    "text": "grpc service you need to implement grpc",
    "start": "748980",
    "end": "751680"
  },
  {
    "text": "service it will communicate to cubelet",
    "start": "751680",
    "end": "755399"
  },
  {
    "text": "through unique socket and you will need",
    "start": "755399",
    "end": "757860"
  },
  {
    "text": "to implement five RPC methods and one",
    "start": "757860",
    "end": "760740"
  },
  {
    "text": "registration call",
    "start": "760740",
    "end": "762839"
  },
  {
    "text": "all right so let's see the meta GPU in",
    "start": "762839",
    "end": "767639"
  },
  {
    "text": "actually how it's working so in terms of",
    "start": "767639",
    "end": "772019"
  },
  {
    "text": "architecture we have these three",
    "start": "772019",
    "end": "774839"
  },
  {
    "text": "binaries",
    "start": "774839",
    "end": "776040"
  },
  {
    "text": "so method GPU actually this is demon set",
    "start": "776040",
    "end": "780899"
  },
  {
    "text": "which is running on each kubernetes node",
    "start": "780899",
    "end": "783240"
  },
  {
    "text": "and we have mgctl which is a binary for",
    "start": "783240",
    "end": "788459"
  },
  {
    "text": "management and Prometheus exporter to",
    "start": "788459",
    "end": "791040"
  },
  {
    "text": "export some metrics",
    "start": "791040",
    "end": "792740"
  },
  {
    "text": "the share logic by default we're going",
    "start": "792740",
    "end": "795660"
  },
  {
    "text": "to split each GPU unit to 100 pieces",
    "start": "795660",
    "end": "799620"
  },
  {
    "text": "well each piece representing 100 percent",
    "start": "799620",
    "end": "803779"
  },
  {
    "text": "the membrane GPU utilization compute",
    "start": "803779",
    "end": "806820"
  },
  {
    "text": "computed relatively to allocated amount",
    "start": "806820",
    "end": "809760"
  },
  {
    "text": "of meta gpus all right so if I have one",
    "start": "809760",
    "end": "813060"
  },
  {
    "text": "GPU card I will have 100",
    "start": "813060",
    "end": "815540"
  },
  {
    "text": "meta gpus if I have two cards",
    "start": "815540",
    "end": "818940"
  },
  {
    "text": "like one car two units I will have 200",
    "start": "818940",
    "end": "821899"
  },
  {
    "text": "meta gpus",
    "start": "821899",
    "end": "825240"
  },
  {
    "text": "okay so let's try and make it fractional",
    "start": "825240",
    "end": "827639"
  },
  {
    "text": "but this time let's make it fractional",
    "start": "827639",
    "end": "830339"
  },
  {
    "text": "in the right way so",
    "start": "830339",
    "end": "834060"
  },
  {
    "text": "yeah I will create",
    "start": "836700",
    "end": "839880"
  },
  {
    "text": "this yaml file",
    "start": "839880",
    "end": "842339"
  },
  {
    "text": "and",
    "start": "842339",
    "end": "844380"
  },
  {
    "text": "it's still painting now right so I will",
    "start": "844380",
    "end": "847800"
  },
  {
    "text": "check",
    "start": "847800",
    "end": "850100"
  },
  {
    "text": "I will I will edit deployment",
    "start": "850500",
    "end": "853019"
  },
  {
    "text": "and this time instead",
    "start": "853019",
    "end": "856860"
  },
  {
    "text": "uh instead of requesting nvidia.com I",
    "start": "856860",
    "end": "860639"
  },
  {
    "text": "will ask 30 percent",
    "start": "860639",
    "end": "864000"
  },
  {
    "text": "like that of",
    "start": "864000",
    "end": "867380"
  },
  {
    "text": "metal meta GPU right a convergio meta",
    "start": "871100",
    "end": "875700"
  },
  {
    "text": "GPU this is what I'm going to ask for",
    "start": "875700",
    "end": "878459"
  },
  {
    "text": "and I'm saving this one",
    "start": "878459",
    "end": "880920"
  },
  {
    "text": "um",
    "start": "880920",
    "end": "881519"
  },
  {
    "text": "let's look on the pods now",
    "start": "881519",
    "end": "885740"
  },
  {
    "text": "okay so now my two pods are up and",
    "start": "886440",
    "end": "889139"
  },
  {
    "text": "running",
    "start": "889139",
    "end": "890220"
  },
  {
    "text": "which is exactly what I want to have",
    "start": "890220",
    "end": "893040"
  },
  {
    "text": "and",
    "start": "893040",
    "end": "894839"
  },
  {
    "text": "now I can try and scale it",
    "start": "894839",
    "end": "897540"
  },
  {
    "text": "I will try to scale it to four let's see",
    "start": "897540",
    "end": "900480"
  },
  {
    "text": "if I will be able to scale to four yeah",
    "start": "900480",
    "end": "902279"
  },
  {
    "text": "and obviously I won't be able to scale",
    "start": "902279",
    "end": "904620"
  },
  {
    "text": "it to four right because I have 100 and",
    "start": "904620",
    "end": "907320"
  },
  {
    "text": "I allocated thirty percent to three",
    "start": "907320",
    "end": "909240"
  },
  {
    "text": "parts so one won't be able to run now if",
    "start": "909240",
    "end": "912959"
  },
  {
    "text": "I will look on the Node itself and I",
    "start": "912959",
    "end": "915240"
  },
  {
    "text": "will describe this node uh what I will",
    "start": "915240",
    "end": "918060"
  },
  {
    "text": "find out is now I have convergio meta",
    "start": "918060",
    "end": "922019"
  },
  {
    "text": "GPU which is equal to 100 and from this",
    "start": "922019",
    "end": "925320"
  },
  {
    "text": "I allocated 90.",
    "start": "925320",
    "end": "927480"
  },
  {
    "text": "all right so this actually allow me to",
    "start": "927480",
    "end": "931800"
  },
  {
    "text": "um",
    "start": "931800",
    "end": "932459"
  },
  {
    "text": "manage resource allocation in a way like",
    "start": "932459",
    "end": "934980"
  },
  {
    "text": "in manageable way right it's not like",
    "start": "934980",
    "end": "936779"
  },
  {
    "text": "that now that users any users can create",
    "start": "936779",
    "end": "939120"
  },
  {
    "text": "as much as they want now they can create",
    "start": "939120",
    "end": "941399"
  },
  {
    "text": "exactly uh up to available resources",
    "start": "941399",
    "end": "945920"
  },
  {
    "text": "oh right",
    "start": "945920",
    "end": "949519"
  },
  {
    "text": "so",
    "start": "951420",
    "end": "954079"
  },
  {
    "text": "all right so the next thing that I would",
    "start": "954120",
    "end": "956820"
  },
  {
    "text": "like to show you is actually kubernetes",
    "start": "956820",
    "end": "958740"
  },
  {
    "text": "like how GPU is natively how Native GPU",
    "start": "958740",
    "end": "962820"
  },
  {
    "text": "in inside kubernetes",
    "start": "962820",
    "end": "965040"
  },
  {
    "text": "um",
    "start": "965040",
    "end": "967019"
  },
  {
    "text": "so um let's let me show you something",
    "start": "967019",
    "end": "973980"
  },
  {
    "text": "I will create",
    "start": "973980",
    "end": "976500"
  },
  {
    "text": "again it's a same same scripts it's",
    "start": "976500",
    "end": "978899"
  },
  {
    "text": "amnes training",
    "start": "978899",
    "end": "980820"
  },
  {
    "text": "with with tensorflow and",
    "start": "980820",
    "end": "984240"
  },
  {
    "text": "my uh in the one second my container is",
    "start": "984240",
    "end": "987180"
  },
  {
    "text": "up and running okay now it's running",
    "start": "987180",
    "end": "988860"
  },
  {
    "text": "which is cool",
    "start": "988860",
    "end": "990180"
  },
  {
    "text": "now I'm now I'm running as a root",
    "start": "990180",
    "end": "994740"
  },
  {
    "text": "so I have SSH access to this machine and",
    "start": "994740",
    "end": "997320"
  },
  {
    "text": "I'm a root and if as a root I will run",
    "start": "997320",
    "end": "1000019"
  },
  {
    "text": "in video SMI",
    "start": "1000019",
    "end": "1002120"
  },
  {
    "text": "I will see my process up and running",
    "start": "1002120",
    "end": "1004060"
  },
  {
    "text": "which is good basically right pretty",
    "start": "1004060",
    "end": "1006680"
  },
  {
    "text": "obvious",
    "start": "1006680",
    "end": "1007699"
  },
  {
    "text": "so if I will do the same command from",
    "start": "1007699",
    "end": "1010339"
  },
  {
    "text": "the container",
    "start": "1010339",
    "end": "1013160"
  },
  {
    "text": "I do not have any any processes",
    "start": "1013160",
    "end": "1016160"
  },
  {
    "text": "available right so why is that I mean",
    "start": "1016160",
    "end": "1018199"
  },
  {
    "text": "something is going wrong here",
    "start": "1018199",
    "end": "1020720"
  },
  {
    "text": "um",
    "start": "1020720",
    "end": "1022100"
  },
  {
    "text": "now usually uh when we are running",
    "start": "1022100",
    "end": "1024860"
  },
  {
    "text": "inside cloud and we have this all these",
    "start": "1024860",
    "end": "1027079"
  },
  {
    "text": "immutable uh nodes uh we like",
    "start": "1027079",
    "end": "1030740"
  },
  {
    "text": "the data scientists won't have access to",
    "start": "1030740",
    "end": "1034640"
  },
  {
    "text": "the SSH node right this is usually what",
    "start": "1034640",
    "end": "1037100"
  },
  {
    "text": "will happen and and if I'm like if I'm",
    "start": "1037100",
    "end": "1039918"
  },
  {
    "text": "running just my my mnist model training",
    "start": "1039919",
    "end": "1042860"
  },
  {
    "text": "and I just want to see what is the",
    "start": "1042860",
    "end": "1044178"
  },
  {
    "text": "utilization I mean I I just I as a data",
    "start": "1044179",
    "end": "1047540"
  },
  {
    "text": "science want to see what is the actually",
    "start": "1047540",
    "end": "1049100"
  },
  {
    "text": "memory usage I won't be able to get this",
    "start": "1049100",
    "end": "1051740"
  },
  {
    "text": "information so we wanted to address this",
    "start": "1051740",
    "end": "1055760"
  },
  {
    "text": "by uh",
    "start": "1055760",
    "end": "1057520"
  },
  {
    "text": "we wanted to address this issue so we",
    "start": "1057520",
    "end": "1060440"
  },
  {
    "text": "created mgctl binary which allow us",
    "start": "1060440",
    "end": "1065780"
  },
  {
    "text": "and not only us but our users to see all",
    "start": "1065780",
    "end": "1070160"
  },
  {
    "text": "the relevant information for for their",
    "start": "1070160",
    "end": "1073520"
  },
  {
    "text": "workloads so again as a root I am able",
    "start": "1073520",
    "end": "1076520"
  },
  {
    "text": "to execute this command and but now I",
    "start": "1076520",
    "end": "1078980"
  },
  {
    "text": "have much more information so for",
    "start": "1078980",
    "end": "1080480"
  },
  {
    "text": "example",
    "start": "1080480",
    "end": "1081740"
  },
  {
    "text": "um and vjsmi does not provide for me any",
    "start": "1081740",
    "end": "1083780"
  },
  {
    "text": "information about kubernetes itself",
    "start": "1083780",
    "end": "1085400"
  },
  {
    "text": "right I have only the the process name",
    "start": "1085400",
    "end": "1088640"
  },
  {
    "text": "and and that's all basically the memory",
    "start": "1088640",
    "end": "1090380"
  },
  {
    "text": "and the feed but but I'm running inside",
    "start": "1090380",
    "end": "1092660"
  },
  {
    "text": "kubernetes so I need I want I would like",
    "start": "1092660",
    "end": "1094940"
  },
  {
    "text": "to see for example the Pod name the",
    "start": "1094940",
    "end": "1097340"
  },
  {
    "text": "namespace of the Pod what is the amount",
    "start": "1097340",
    "end": "1099440"
  },
  {
    "text": "of um meta GPU request is allocated for",
    "start": "1099440",
    "end": "1103340"
  },
  {
    "text": "these uh",
    "start": "1103340",
    "end": "1105620"
  },
  {
    "text": "for this pod and also maybe some node",
    "start": "1105620",
    "end": "1109160"
  },
  {
    "text": "information like on on which exactly",
    "start": "1109160",
    "end": "1110960"
  },
  {
    "text": "node it is running now if I will run the",
    "start": "1110960",
    "end": "1113780"
  },
  {
    "text": "same command as um",
    "start": "1113780",
    "end": "1117100"
  },
  {
    "text": "contain your owner",
    "start": "1117520",
    "end": "1121120"
  },
  {
    "text": "so I I'm getting also some information",
    "start": "1122059",
    "end": "1124580"
  },
  {
    "text": "useful information which is not",
    "start": "1124580",
    "end": "1126620"
  },
  {
    "text": "available when I'm using nvidjsmi right",
    "start": "1126620",
    "end": "1131480"
  },
  {
    "text": "um and this is like",
    "start": "1131480",
    "end": "1133700"
  },
  {
    "text": "pretty useful I believe because now",
    "start": "1133700",
    "end": "1135740"
  },
  {
    "text": "users they do not need any more root",
    "start": "1135740",
    "end": "1138799"
  },
  {
    "text": "access and they are completely okay to",
    "start": "1138799",
    "end": "1140960"
  },
  {
    "text": "go and and run this command inside",
    "start": "1140960",
    "end": "1143660"
  },
  {
    "text": "containers",
    "start": "1143660",
    "end": "1145220"
  },
  {
    "text": "okay",
    "start": "1145220",
    "end": "1147320"
  },
  {
    "text": "so I know I will clean up this",
    "start": "1147320",
    "end": "1150860"
  },
  {
    "text": "as well",
    "start": "1150860",
    "end": "1152780"
  },
  {
    "text": "and move I will move forward so what",
    "start": "1152780",
    "end": "1156140"
  },
  {
    "text": "about limit enforcement now when we uh",
    "start": "1156140",
    "end": "1159440"
  },
  {
    "text": "able to split to Shell single GPU what",
    "start": "1159440",
    "end": "1163580"
  },
  {
    "text": "will make like we need some some way to",
    "start": "1163580",
    "end": "1166160"
  },
  {
    "text": "enforce",
    "start": "1166160",
    "end": "1167419"
  },
  {
    "text": "um the amount of memory or GPU",
    "start": "1167419",
    "end": "1170600"
  },
  {
    "text": "utilization that has been allocated for",
    "start": "1170600",
    "end": "1174020"
  },
  {
    "text": "uh",
    "start": "1174020",
    "end": "1175340"
  },
  {
    "text": "for each share right because like the",
    "start": "1175340",
    "end": "1178700"
  },
  {
    "text": "kubernetes will um will make the",
    "start": "1178700",
    "end": "1181160"
  },
  {
    "text": "schedule for us but in the same way as",
    "start": "1181160",
    "end": "1183860"
  },
  {
    "text": "it happened with the regular memory",
    "start": "1183860",
    "end": "1185840"
  },
  {
    "text": "right but c groups will enforce memory",
    "start": "1185840",
    "end": "1188600"
  },
  {
    "text": "now we do not have c groups uh for GPU",
    "start": "1188600",
    "end": "1191720"
  },
  {
    "text": "and that's why we need to address this",
    "start": "1191720",
    "end": "1194240"
  },
  {
    "text": "uh problem also",
    "start": "1194240",
    "end": "1196580"
  },
  {
    "text": "uh so let me create",
    "start": "1196580",
    "end": "1201159"
  },
  {
    "text": "what",
    "start": "1204740",
    "end": "1207220"
  },
  {
    "text": "okay so now I created again two uh",
    "start": "1207500",
    "end": "1210799"
  },
  {
    "text": "amnest um",
    "start": "1210799",
    "end": "1212179"
  },
  {
    "text": "training jobs and if I will run",
    "start": "1212179",
    "end": "1216100"
  },
  {
    "text": "mgctl again what I will see is actually",
    "start": "1216100",
    "end": "1220900"
  },
  {
    "text": "my second container is become becomes uh",
    "start": "1220900",
    "end": "1225320"
  },
  {
    "text": "red right you see it's red Yeah it's red",
    "start": "1225320",
    "end": "1228200"
  },
  {
    "text": "so um white side because it uses more",
    "start": "1228200",
    "end": "1231559"
  },
  {
    "text": "memory than it should right so",
    "start": "1231559",
    "end": "1234440"
  },
  {
    "text": "I have 10 meta GPU",
    "start": "1234440",
    "end": "1237980"
  },
  {
    "text": "request which is equal to 10 percent of",
    "start": "1237980",
    "end": "1241460"
  },
  {
    "text": "the uh",
    "start": "1241460",
    "end": "1243160"
  },
  {
    "text": "GPU unit and it should use up to one gig",
    "start": "1243160",
    "end": "1247039"
  },
  {
    "text": "but in fact it used much more so what",
    "start": "1247039",
    "end": "1249860"
  },
  {
    "text": "can I do with that now so I can either",
    "start": "1249860",
    "end": "1252980"
  },
  {
    "text": "issue an alert right or I can just pick",
    "start": "1252980",
    "end": "1255980"
  },
  {
    "text": "up a phone and say hey dear user you are",
    "start": "1255980",
    "end": "1257960"
  },
  {
    "text": "using more than you should and this is",
    "start": "1257960",
    "end": "1260000"
  },
  {
    "text": "if I'm nice person",
    "start": "1260000",
    "end": "1262160"
  },
  {
    "text": "um",
    "start": "1262160",
    "end": "1263120"
  },
  {
    "text": "but maybe but I can but also I can",
    "start": "1263120",
    "end": "1267260"
  },
  {
    "text": "enforce this in the same way c groups",
    "start": "1267260",
    "end": "1270140"
  },
  {
    "text": "enforce this just by killing this uh",
    "start": "1270140",
    "end": "1272840"
  },
  {
    "text": "process so I can achieve this",
    "start": "1272840",
    "end": "1275380"
  },
  {
    "text": "enforcement if I will uh",
    "start": "1275380",
    "end": "1279020"
  },
  {
    "text": "change some configuration",
    "start": "1279020",
    "end": "1281780"
  },
  {
    "text": "like memory enforcement this is",
    "start": "1281780",
    "end": "1284780"
  },
  {
    "text": "currently it's set to false",
    "start": "1284780",
    "end": "1287360"
  },
  {
    "text": "if I will change it to true",
    "start": "1287360",
    "end": "1290659"
  },
  {
    "text": "and now I will I will need to restart my",
    "start": "1290659",
    "end": "1294020"
  },
  {
    "text": "device plugin just to make sure it's",
    "start": "1294020",
    "end": "1299059"
  },
  {
    "text": "fast yeah now my um",
    "start": "1299059",
    "end": "1302240"
  },
  {
    "text": "device plugin is has been restarted and",
    "start": "1302240",
    "end": "1305960"
  },
  {
    "text": "now in a few moments we will see that",
    "start": "1305960",
    "end": "1307880"
  },
  {
    "text": "this container you see now it's it has",
    "start": "1307880",
    "end": "1310820"
  },
  {
    "text": "been terminated and so each time this",
    "start": "1310820",
    "end": "1314240"
  },
  {
    "text": "container will start and once it will",
    "start": "1314240",
    "end": "1315919"
  },
  {
    "text": "use more uh more memory in this scenario",
    "start": "1315919",
    "end": "1319340"
  },
  {
    "text": "when uh then it should this container",
    "start": "1319340",
    "end": "1322460"
  },
  {
    "text": "going to be killed and this the the it",
    "start": "1322460",
    "end": "1325039"
  },
  {
    "text": "will fall to the you know the crash",
    "start": "1325039",
    "end": "1326720"
  },
  {
    "text": "loopback",
    "start": "1326720",
    "end": "1327919"
  },
  {
    "text": "um",
    "start": "1327919",
    "end": "1328520"
  },
  {
    "text": "state so then we can choose how to",
    "start": "1328520",
    "end": "1331880"
  },
  {
    "text": "address this we either reduce amount of",
    "start": "1331880",
    "end": "1335000"
  },
  {
    "text": "memory or we increase amount of meta GPU",
    "start": "1335000",
    "end": "1340039"
  },
  {
    "text": "requests",
    "start": "1340039",
    "end": "1342639"
  },
  {
    "text": "all right so right now",
    "start": "1343760",
    "end": "1347980"
  },
  {
    "text": "oh yes so uh so how the event looks like",
    "start": "1348740",
    "end": "1354080"
  },
  {
    "text": "right oh yeah yeah so currently we do",
    "start": "1354080",
    "end": "1357860"
  },
  {
    "text": "not have events but what should happen",
    "start": "1357860",
    "end": "1360799"
  },
  {
    "text": "is actually we have",
    "start": "1360799",
    "end": "1363740"
  },
  {
    "text": "um",
    "start": "1363740",
    "end": "1365020"
  },
  {
    "text": "exporter Prometheus exporter which can",
    "start": "1365020",
    "end": "1368299"
  },
  {
    "text": "be used with the Prometheus and alert",
    "start": "1368299",
    "end": "1370640"
  },
  {
    "text": "manager and based on that users can",
    "start": "1370640",
    "end": "1373820"
  },
  {
    "text": "create an alert",
    "start": "1373820",
    "end": "1377120"
  },
  {
    "text": "um yeah",
    "start": "1377120",
    "end": "1379658"
  },
  {
    "text": "yeah yeah definitely yeah and we need to",
    "start": "1380659",
    "end": "1383600"
  },
  {
    "text": "actually like it's open source project",
    "start": "1383600",
    "end": "1385220"
  },
  {
    "text": "by the way it's completely open in",
    "start": "1385220",
    "end": "1387440"
  },
  {
    "text": "GitHub uh so any contributions are",
    "start": "1387440",
    "end": "1390860"
  },
  {
    "text": "welcome",
    "start": "1390860",
    "end": "1391820"
  },
  {
    "text": "uh-huh uh yeah so with that basically",
    "start": "1391820",
    "end": "1396980"
  },
  {
    "text": "that's all what I wanted to share with",
    "start": "1396980",
    "end": "1398780"
  },
  {
    "text": "you fast recap so max utilization limit",
    "start": "1398780",
    "end": "1401840"
  },
  {
    "text": "enforcement Dynamic reshading easy of",
    "start": "1401840",
    "end": "1404539"
  },
  {
    "text": "using kubernetes native this is what we",
    "start": "1404539",
    "end": "1407000"
  },
  {
    "text": "trying to achieve it is open source",
    "start": "1407000",
    "end": "1409460"
  },
  {
    "text": "please contribute use it and thank you",
    "start": "1409460",
    "end": "1413830"
  },
  {
    "text": "[Applause]",
    "start": "1413830",
    "end": "1420980"
  },
  {
    "text": "does anyone have any questions",
    "start": "1420980",
    "end": "1424600"
  },
  {
    "text": "I don't know",
    "start": "1426620",
    "end": "1428840"
  },
  {
    "text": "hello",
    "start": "1428840",
    "end": "1430700"
  },
  {
    "text": "it's good okay thanks for that talk",
    "start": "1430700",
    "end": "1433520"
  },
  {
    "text": "um I was wondering if you might comment",
    "start": "1433520",
    "end": "1435080"
  },
  {
    "text": "a little bit on how this interacts if it",
    "start": "1435080",
    "end": "1438620"
  },
  {
    "text": "if at all with the vendor tools that do",
    "start": "1438620",
    "end": "1442400"
  },
  {
    "text": "the same thing from Nvidia for example",
    "start": "1442400",
    "end": "1444320"
  },
  {
    "text": "the sort of multi-instance",
    "start": "1444320",
    "end": "1446320"
  },
  {
    "text": "multi-instance GPU which I saw you were",
    "start": "1446320",
    "end": "1449240"
  },
  {
    "text": "running in your driver screenshot yeah",
    "start": "1449240",
    "end": "1451159"
  },
  {
    "text": "so uh good question thank you",
    "start": "1451159",
    "end": "1453860"
  },
  {
    "text": "um",
    "start": "1453860",
    "end": "1454520"
  },
  {
    "text": "so the thing is",
    "start": "1454520",
    "end": "1456679"
  },
  {
    "text": "uh first of all not each GPU card has",
    "start": "1456679",
    "end": "1461179"
  },
  {
    "text": "support for Mig there's a many many uh",
    "start": "1461179",
    "end": "1465260"
  },
  {
    "text": "other cards all cars which does not",
    "start": "1465260",
    "end": "1467720"
  },
  {
    "text": "support Mig and we still want to share",
    "start": "1467720",
    "end": "1469940"
  },
  {
    "text": "them so this is a first comment the",
    "start": "1469940",
    "end": "1473179"
  },
  {
    "text": "second thing is uh to configure Mig",
    "start": "1473179",
    "end": "1477500"
  },
  {
    "text": "might be some sometimes not easy thing",
    "start": "1477500",
    "end": "1481220"
  },
  {
    "text": "to do also it has some limitation you",
    "start": "1481220",
    "end": "1484340"
  },
  {
    "text": "might need to reboot the node you cannot",
    "start": "1484340",
    "end": "1487159"
  },
  {
    "text": "easily",
    "start": "1487159",
    "end": "1488480"
  },
  {
    "text": "um",
    "start": "1488480",
    "end": "1489820"
  },
  {
    "text": "reshare right because if you would like",
    "start": "1489820",
    "end": "1492140"
  },
  {
    "text": "to reshare you need to stop all the",
    "start": "1492140",
    "end": "1493640"
  },
  {
    "text": "workloads and so on so on so the plans",
    "start": "1493640",
    "end": "1496100"
  },
  {
    "text": "for this project is to use",
    "start": "1496100",
    "end": "1498740"
  },
  {
    "text": "um Nvidia open source libraries nvml for",
    "start": "1498740",
    "end": "1501919"
  },
  {
    "text": "example which they have and and build on",
    "start": "1501919",
    "end": "1505100"
  },
  {
    "text": "top of it",
    "start": "1505100",
    "end": "1506299"
  },
  {
    "text": "Cloud native kubernetes Native tooling",
    "start": "1506299",
    "end": "1508760"
  },
  {
    "text": "which will simplify day-to-day work",
    "start": "1508760",
    "end": "1514299"
  },
  {
    "text": "so as a user and a team and especially",
    "start": "1521419",
    "end": "1523880"
  },
  {
    "text": "when you're running in a multi-tenant",
    "start": "1523880",
    "end": "1525620"
  },
  {
    "text": "approach",
    "start": "1525620",
    "end": "1526880"
  },
  {
    "text": "um how do you get an information earlier",
    "start": "1526880",
    "end": "1529520"
  },
  {
    "text": "on on What GPU resources is on the Node",
    "start": "1529520",
    "end": "1534140"
  },
  {
    "text": "before you start like scheduling and",
    "start": "1534140",
    "end": "1536419"
  },
  {
    "text": "also if you do schedule and there is no",
    "start": "1536419",
    "end": "1538580"
  },
  {
    "text": "node is there any possibility of that",
    "start": "1538580",
    "end": "1540380"
  },
  {
    "text": "actually working with cluster",
    "start": "1540380",
    "end": "1542240"
  },
  {
    "text": "autoscalers so let's scale up more GPU",
    "start": "1542240",
    "end": "1544940"
  },
  {
    "text": "nodes",
    "start": "1544940",
    "end": "1545720"
  },
  {
    "text": "oh okay yeah right so um again the plans",
    "start": "1545720",
    "end": "1549260"
  },
  {
    "text": "uh now what what I showed is actually",
    "start": "1549260",
    "end": "1552039"
  },
  {
    "text": "converge.io meta GPU now the plan is the",
    "start": "1552039",
    "end": "1557179"
  },
  {
    "text": "real plan like the big plan is to create",
    "start": "1557179",
    "end": "1560659"
  },
  {
    "text": "and logic which will help which will",
    "start": "1560659",
    "end": "1563360"
  },
  {
    "text": "allow you to bind a resource name to",
    "start": "1563360",
    "end": "1566480"
  },
  {
    "text": "certain uh GPU so so you you might I",
    "start": "1566480",
    "end": "1570620"
  },
  {
    "text": "imagine that you will have multiple uh",
    "start": "1570620",
    "end": "1572840"
  },
  {
    "text": "resources names and they will be bounded",
    "start": "1572840",
    "end": "1575299"
  },
  {
    "text": "to um to multiple to different cards so",
    "start": "1575299",
    "end": "1578480"
  },
  {
    "text": "for example I even can create",
    "start": "1578480",
    "end": "1581120"
  },
  {
    "text": "um a resource which will I called",
    "start": "1581120",
    "end": "1583100"
  },
  {
    "text": "Dimitri converge IO slash Dimitri and",
    "start": "1583100",
    "end": "1586640"
  },
  {
    "text": "these resource will represent",
    "start": "1586640",
    "end": "1589279"
  },
  {
    "text": "um certain GPU which only I can use so",
    "start": "1589279",
    "end": "1592700"
  },
  {
    "text": "for example and regarding the",
    "start": "1592700",
    "end": "1595039"
  },
  {
    "text": "multi-tenancy and the way you you can",
    "start": "1595039",
    "end": "1598400"
  },
  {
    "text": "see all these devices so we have",
    "start": "1598400",
    "end": "1600320"
  },
  {
    "text": "different",
    "start": "1600320",
    "end": "1601460"
  },
  {
    "text": "um visibility Scopes and when you are",
    "start": "1601460",
    "end": "1604520"
  },
  {
    "text": "running this command with the device",
    "start": "1604520",
    "end": "1608059"
  },
  {
    "text": "level visibility scope you will see the",
    "start": "1608059",
    "end": "1612380"
  },
  {
    "text": "complete spec of device now to be able",
    "start": "1612380",
    "end": "1614960"
  },
  {
    "text": "to see devices between different",
    "start": "1614960",
    "end": "1616520"
  },
  {
    "text": "machines right now you will need to",
    "start": "1616520",
    "end": "1620059"
  },
  {
    "text": "um",
    "start": "1620059",
    "end": "1620659"
  },
  {
    "text": "run this command on each node we have",
    "start": "1620659",
    "end": "1624799"
  },
  {
    "text": "plans to create like we need to see how",
    "start": "1624799",
    "end": "1627380"
  },
  {
    "text": "Community behaves if we really have like",
    "start": "1627380",
    "end": "1629659"
  },
  {
    "text": "people like it people want to use it so",
    "start": "1629659",
    "end": "1632179"
  },
  {
    "text": "then we will put some effort on this and",
    "start": "1632179",
    "end": "1634100"
  },
  {
    "text": "we will create",
    "start": "1634100",
    "end": "1635720"
  },
  {
    "text": "um central control plan where you can",
    "start": "1635720",
    "end": "1638600"
  },
  {
    "text": "see all your devices uh grafana",
    "start": "1638600",
    "end": "1641419"
  },
  {
    "text": "dashboards alerts you know uh everything",
    "start": "1641419",
    "end": "1644539"
  },
  {
    "text": "that really needed for production grade",
    "start": "1644539",
    "end": "1647620"
  },
  {
    "text": "open source project",
    "start": "1647620",
    "end": "1651220"
  },
  {
    "text": "thank you one quick question is it",
    "start": "1651320",
    "end": "1654500"
  },
  {
    "text": "possible to over commit basically so to",
    "start": "1654500",
    "end": "1657080"
  },
  {
    "text": "request for example many yeah devices",
    "start": "1657080",
    "end": "1660620"
  },
  {
    "text": "but set the enforcement limit only if",
    "start": "1660620",
    "end": "1663260"
  },
  {
    "text": "user like really really eat above the",
    "start": "1663260",
    "end": "1666080"
  },
  {
    "text": "cap yeah right so the good question so",
    "start": "1666080",
    "end": "1669080"
  },
  {
    "text": "the thing is um",
    "start": "1669080",
    "end": "1671539"
  },
  {
    "text": "you",
    "start": "1671539",
    "end": "1672980"
  },
  {
    "text": "yes you can overcome it but what will",
    "start": "1672980",
    "end": "1675860"
  },
  {
    "text": "happen is there's two scenarios if you",
    "start": "1675860",
    "end": "1678740"
  },
  {
    "text": "over commit your container might be get",
    "start": "1678740",
    "end": "1681799"
  },
  {
    "text": "killed or it might be continue running",
    "start": "1681799",
    "end": "1684559"
  },
  {
    "text": "as usual to avoid over commitment you",
    "start": "1684559",
    "end": "1688340"
  },
  {
    "text": "need to add support inside your code",
    "start": "1688340",
    "end": "1690860"
  },
  {
    "text": "so what does it mean inside your code",
    "start": "1690860",
    "end": "1693500"
  },
  {
    "text": "when I running my tensorflow script I",
    "start": "1693500",
    "end": "1697159"
  },
  {
    "text": "specifying the total amount of available",
    "start": "1697159",
    "end": "1699799"
  },
  {
    "text": "memory all right so and these need to to",
    "start": "1699799",
    "end": "1703220"
  },
  {
    "text": "be a Tango between",
    "start": "1703220",
    "end": "1705740"
  },
  {
    "text": "um",
    "start": "1705740",
    "end": "1706460"
  },
  {
    "text": "device plugin and your code in certain",
    "start": "1706460",
    "end": "1709279"
  },
  {
    "text": "way it's very similar to Java right so",
    "start": "1709279",
    "end": "1711679"
  },
  {
    "text": "if I will run Java without Max and mean",
    "start": "1711679",
    "end": "1714679"
  },
  {
    "text": "parameters or the memory it will use all",
    "start": "1714679",
    "end": "1717020"
  },
  {
    "text": "the memory regardless what I configured",
    "start": "1717020",
    "end": "1719360"
  },
  {
    "text": "inside my kubernetes limited request so",
    "start": "1719360",
    "end": "1723260"
  },
  {
    "text": "in short yes over commitment is possible",
    "start": "1723260",
    "end": "1726580"
  },
  {
    "text": "and to avoid over commitment you need to",
    "start": "1726580",
    "end": "1730460"
  },
  {
    "text": "apply changes at the code level",
    "start": "1730460",
    "end": "1733520"
  },
  {
    "text": "or you can leave your code as is and",
    "start": "1733520",
    "end": "1737240"
  },
  {
    "text": "then you can decide what should happens",
    "start": "1737240",
    "end": "1739159"
  },
  {
    "text": "when overcommit is happen either to kill",
    "start": "1739159",
    "end": "1742640"
  },
  {
    "text": "this container or just leave it running",
    "start": "1742640",
    "end": "1744860"
  },
  {
    "text": "and get some alert for this",
    "start": "1744860",
    "end": "1749440"
  },
  {
    "text": "thank you very much thank you guys",
    "start": "1752299",
    "end": "1756460"
  }
]
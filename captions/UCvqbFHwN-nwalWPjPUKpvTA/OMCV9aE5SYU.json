[
  {
    "text": "hi my name is velen and i'm an engineering lead on the data science platform team at gojek i'm joined today by alexi muskalenko who",
    "start": "0",
    "end": "6640"
  },
  {
    "text": "is my colleague a senior engineer on the team today we're going to be talking a bit about building a cloud native feature store",
    "start": "6640",
    "end": "12960"
  },
  {
    "text": "with feast today on agenda we're going to talk a bit about the data challenges that teams face when operationalizing",
    "start": "12960",
    "end": "18960"
  },
  {
    "text": "machine learning we're going to talk a bit about how feast can help you with those challenges",
    "start": "18960",
    "end": "24320"
  },
  {
    "text": "what feast is and what feast is not we're going to have a quick demo and feast then we're going to talk about the",
    "start": "24320",
    "end": "29439"
  },
  {
    "text": "project itself where it's been and where it's going and we have three big announcements that we're going to make and i'm hoping you can stick around for those",
    "start": "29439",
    "end": "36719"
  },
  {
    "text": "so how does data science work at most teams today these projects are typically started",
    "start": "36719",
    "end": "42320"
  },
  {
    "text": "because you want to target some kind of business outcome some kind of metric that you want to push up and a data scientist is often",
    "start": "42320",
    "end": "48879"
  },
  {
    "text": "tasked with building the first model or the first proof of concept for this so they're given data and they're asked",
    "start": "48879",
    "end": "54800"
  },
  {
    "text": "to build this model and see if it's actually viable and so often the basis of the project this",
    "start": "54800",
    "end": "62559"
  },
  {
    "text": "you know the inception is the notebook this is a linear end-to-end flow that a data scientist comes up with",
    "start": "62559",
    "end": "68320"
  },
  {
    "text": "and you evolve that notebook into an end-to-end machine learning system and so you have",
    "start": "68320",
    "end": "74560"
  },
  {
    "text": "something that resembles what we have on the screen now on the left you have your data sources",
    "start": "74560",
    "end": "79920"
  },
  {
    "text": "and then you have transformations let's say batch transformations you have model training you have model",
    "start": "79920",
    "end": "85360"
  },
  {
    "text": "deployment you have model serving one end-to-end flow and this often represents and resembles",
    "start": "85360",
    "end": "91680"
  },
  {
    "text": "the notebook that it's being evolved from and the final product there is a model that's integrated with the production",
    "start": "91680",
    "end": "97840"
  },
  {
    "text": "system and this works and most teams can get to this point by just hacking together open source or",
    "start": "97840",
    "end": "103280"
  },
  {
    "text": "proprietary solutions products at some point somebody will say we need real-time features and real-time",
    "start": "103280",
    "end": "108799"
  },
  {
    "text": "data and hook up a stream at some point somebody will say we need more distributed compute so they hook up spark",
    "start": "108799",
    "end": "114079"
  },
  {
    "text": "but ultimately you're left with an end-to-end system one monolith but these models come with some costs",
    "start": "114079",
    "end": "120560"
  },
  {
    "text": "sometimes very big costs one of the first problems is that they're very slow to iterate on if you have one team that needs to work",
    "start": "120560",
    "end": "127119"
  },
  {
    "text": "on feature engineering another needs to introduce modeling another that iterates on the online serving of the production requirements",
    "start": "127119",
    "end": "133599"
  },
  {
    "text": "they all want to iterate at different frequencies and paces and you know they're different teams sitting in different places",
    "start": "133599",
    "end": "138800"
  },
  {
    "text": "but they have to work in unison because it's one monolithic system and this slows them down",
    "start": "138800",
    "end": "144160"
  },
  {
    "text": "the second problem is that features often need to be redeveloped when going from training to serving this is often",
    "start": "144160",
    "end": "149280"
  },
  {
    "text": "because features are written in python and you know they're not performant enough and they need to be written in java or go",
    "start": "149280",
    "end": "154400"
  },
  {
    "text": "and there's all these reasons but inconsistencies arrive when engineers and data scientists need to work together to produce one final output one product",
    "start": "154400",
    "end": "162239"
  },
  {
    "text": "the third problem is that because of these rewrites and changes from one",
    "start": "162239",
    "end": "167599"
  },
  {
    "text": "environment to the next often you have training and serving inconsistencies in the data and this can lead to a performance drop",
    "start": "167599",
    "end": "173040"
  },
  {
    "text": "in your models the fourth problem is that data quality problems arise when you",
    "start": "173040",
    "end": "178239"
  },
  {
    "text": "don't know that you don't have the proper monitoring in place you don't have the proper metrics in place you don't have validation",
    "start": "178239",
    "end": "184000"
  },
  {
    "text": "of your data basically the tools that are available today are not meant to measure data but at the same",
    "start": "184000",
    "end": "190159"
  },
  {
    "text": "time this data is affecting the business outcomes the prediction the data that's going into the models affect the predictions",
    "start": "190159",
    "end": "196720"
  },
  {
    "text": "that are made and those that affect the outcome and the decisions that you make and then finally one of the biggest",
    "start": "196720",
    "end": "202640"
  },
  {
    "text": "problems that we've found you know at gojek and many of the other teams have also told us is that there's just a gross lack of",
    "start": "202640",
    "end": "208640"
  },
  {
    "text": "reuse of features and yet feature engineering is one of the biggest costs that teams need to incur and so these are kind of",
    "start": "208640",
    "end": "215360"
  },
  {
    "text": "the five big problems that that we've seen ml teams are faced with when it comes to operationalizing data so we believe that",
    "start": "215360",
    "end": "223280"
  },
  {
    "text": "a need exists for a battle tested open source feature store to address these problems that we've highlighted",
    "start": "223280",
    "end": "229840"
  },
  {
    "text": "and we think feast is that feature storm sofia is a system that attempts to solve the key data challenges to production",
    "start": "229840",
    "end": "235360"
  },
  {
    "text": "machine learning so if we go back to that diagram i showed you earlier typically what you'd have on the left is you know",
    "start": "235360",
    "end": "241760"
  },
  {
    "text": "you'd have your data you'd have your transformations and then you'd have your model training deployment serving this end-to-end flow would be duplicated",
    "start": "241760",
    "end": "248959"
  },
  {
    "text": "for each project that you undertake you'd not have reuse or very little reuse across projects",
    "start": "248959",
    "end": "256000"
  },
  {
    "text": "so how does feast help with this kind of monolithic end-to-end architecture",
    "start": "256000",
    "end": "261040"
  },
  {
    "text": "feast decouples this completely so if we talk about the problems that we were highlighting earlier the first one we",
    "start": "261040",
    "end": "266560"
  },
  {
    "text": "were highlighting was the lack of iteration so now you've decoupled engineering of features and creation of features",
    "start": "266560",
    "end": "272400"
  },
  {
    "text": "because that process ends with feast that's one team that can be the engineers data scientists",
    "start": "272400",
    "end": "277680"
  },
  {
    "text": "then you have another team that's which is purely iterating on model training they're selecting features from feast",
    "start": "277680",
    "end": "282960"
  },
  {
    "text": "training a model and shipping it to a registry then you have a third team this can be a production team",
    "start": "282960",
    "end": "288880"
  },
  {
    "text": "engineers perhaps they're shipping models into production they're hooking those up into you know connecting them to real-time",
    "start": "288880",
    "end": "296160"
  },
  {
    "text": "production systems and you know they're looking up online features at low latency",
    "start": "296160",
    "end": "301199"
  },
  {
    "text": "and they can do this confidently at scale and with monitoring and instrumentation that it requires and all three teams can iterate",
    "start": "301199",
    "end": "307360"
  },
  {
    "text": "independently and so this both solves iteration speed and also solves reuse because teams can",
    "start": "307360",
    "end": "312800"
  },
  {
    "text": "now independently use each other's artifacts with their models or features in this architecture",
    "start": "312800",
    "end": "319680"
  },
  {
    "text": "so what does fees provide fees provides essential central registry this register is a catalog through which you can",
    "start": "319680",
    "end": "324880"
  },
  {
    "text": "define your features and reuse them and collaborate on those across teams and across projects",
    "start": "324880",
    "end": "330080"
  },
  {
    "text": "this also does ingestion so it has jobs that it provisions that loads data in from upstream sources",
    "start": "330080",
    "end": "335919"
  },
  {
    "text": "whether streaming or batch into the stores in order for the third point which is serving",
    "start": "335919",
    "end": "341039"
  },
  {
    "text": "fees provides a point in time correct a temporarily correct serving layer that allows you to look up",
    "start": "341039",
    "end": "347759"
  },
  {
    "text": "data at scale for training a model and it will handle the joints and everything you need and it also allows",
    "start": "347759",
    "end": "354000"
  },
  {
    "text": "you to do online look up so low latency lookups for for predictions in the online case it",
    "start": "354000",
    "end": "360160"
  },
  {
    "text": "also provides you the monitoring tools to operate your system at scale and production the end-to-end flow",
    "start": "360160",
    "end": "367759"
  },
  {
    "text": "is represented on the screen so on the left you have your data so these can just be notebooks data lags data warehouse it doesn't really matter",
    "start": "367759",
    "end": "374240"
  },
  {
    "text": "you push your data into feast and this is done through the triggering of ingestion job and that job is a spark",
    "start": "374240",
    "end": "381360"
  },
  {
    "text": "job and this job will write your data into the stores so in this case consistent copy of the",
    "start": "381360",
    "end": "388080"
  },
  {
    "text": "data that you're ingesting in online and offline stores and the definitions of the features and",
    "start": "388080",
    "end": "393360"
  },
  {
    "text": "the data that you're ingesting are handled by core so fist core is that central registry and then once you've ingested your data",
    "start": "393360",
    "end": "399840"
  },
  {
    "text": "into the storage layer it's then available for all teams to use so if you know one team wants to try out a",
    "start": "399840",
    "end": "406080"
  },
  {
    "text": "feature that has been published and ingested into feast they can simply query it out of the feast serving layer and then train a",
    "start": "406080",
    "end": "412400"
  },
  {
    "text": "model and so feast for training uses an sdk and for online serving it uses a low latency api",
    "start": "412400",
    "end": "419360"
  },
  {
    "text": "so what is feast not feast is not a workflow scheduler it's not like luigi or airflow it doesn't do scheduling it's not just a",
    "start": "419360",
    "end": "425919"
  },
  {
    "text": "data lake or a data warehouse like bigquery because it's got the online functionality as well although it",
    "start": "425919",
    "end": "430960"
  },
  {
    "text": "uses bigquery and some of these tools underneath feast doesn't do transformation so it's unlike spark and pandas although it will",
    "start": "430960",
    "end": "436800"
  },
  {
    "text": "utilize those tools but it's made those are upstream tasks feast does some have some discovery and",
    "start": "436800",
    "end": "443199"
  },
  {
    "text": "cataloging functionality but it's not meant to be a discovery or cataloging system feast does not try and solve lineage of",
    "start": "443199",
    "end": "449520"
  },
  {
    "text": "data or data version control and feast is not an ml or model serving or you know model tracking or metadata",
    "start": "449520",
    "end": "456479"
  },
  {
    "text": "tracking solution [Music] hi i'm alexi from gojic and i want to",
    "start": "456479",
    "end": "463360"
  },
  {
    "text": "show feast in action but before that we need to deploy it the primary way to",
    "start": "463360",
    "end": "469440"
  },
  {
    "text": "deploy these is to roll out docker images",
    "start": "469440",
    "end": "474720"
  },
  {
    "text": "to kubernetes using helm the only thing that needs to be done",
    "start": "474720",
    "end": "480639"
  },
  {
    "text": "manually is to creating some secrets so i already connected to my kubernetes",
    "start": "480639",
    "end": "487919"
  },
  {
    "text": "cluster so i will create a namespace",
    "start": "487919",
    "end": "493840"
  },
  {
    "text": "and i will add secrets first for postgres",
    "start": "495599",
    "end": "506960"
  },
  {
    "text": "you can see that i specify just a pose responsible here",
    "start": "506960",
    "end": "512319"
  },
  {
    "text": "and also our installation would need a google service account key since we're",
    "start": "515519",
    "end": "521440"
  },
  {
    "text": "using google storage so now we can run helm",
    "start": "521440",
    "end": "526720"
  },
  {
    "text": "install so after you cloned feast",
    "start": "526720",
    "end": "532839"
  },
  {
    "text": "repository",
    "start": "532839",
    "end": "535839"
  },
  {
    "text": "you can run helm install using some overrides overhead files that we",
    "start": "538640",
    "end": "547600"
  },
  {
    "text": "keep in the repository it takes some time to start all the",
    "start": "547600",
    "end": "555279"
  },
  {
    "text": "containers but when all ports are running we can now connect",
    "start": "555279",
    "end": "562480"
  },
  {
    "text": "to the jupiter node",
    "start": "562480",
    "end": "577040"
  },
  {
    "text": "now when we finish this deployment let me briefly talk about these components",
    "start": "577040",
    "end": "584800"
  },
  {
    "text": "first one is beast core it's essentially a registry which stores specifications",
    "start": "584800",
    "end": "590959"
  },
  {
    "text": "of features collections of features which we call feature table and entities which are keys in those",
    "start": "590959",
    "end": "598399"
  },
  {
    "text": "feature tables the next one is serving it provides",
    "start": "598399",
    "end": "603519"
  },
  {
    "text": "features in real time and with low latency and mainly used by module serving",
    "start": "603519",
    "end": "611600"
  },
  {
    "text": "for running real time prediction this survey relies on the online feature storage which we",
    "start": "611600",
    "end": "618959"
  },
  {
    "text": "use redis for ingesting job here is mainly responsible",
    "start": "618959",
    "end": "624880"
  },
  {
    "text": "for populating this online feature storage it pulls data from data very house or",
    "start": "624880",
    "end": "632880"
  },
  {
    "text": "data lake which we call batch source or from kafka or kinesis",
    "start": "632880",
    "end": "642079"
  },
  {
    "text": "some kind of streaming [Music] source which we call stream source",
    "start": "642079",
    "end": "650160"
  },
  {
    "text": "the historical retrieval is another job which mainly does similar job",
    "start": "650399",
    "end": "658800"
  },
  {
    "text": "uh it pulls data from data warehouse or data lake to prepare a",
    "start": "658800",
    "end": "665440"
  },
  {
    "text": "data set for training both those jobs aimed to",
    "start": "665440",
    "end": "671920"
  },
  {
    "text": "provide consistency between data for training and data for",
    "start": "671920",
    "end": "678640"
  },
  {
    "text": "serving these sdk kind of glues all these together",
    "start": "678640",
    "end": "686680"
  },
  {
    "text": "it used for creating features and feature tables",
    "start": "686680",
    "end": "692959"
  },
  {
    "text": "for requesting features from feed serving",
    "start": "692959",
    "end": "698160"
  },
  {
    "text": "to retrieve online features it also can be used to",
    "start": "698160",
    "end": "705200"
  },
  {
    "text": "call historical retrieval or manage your streaming ingestion or watch",
    "start": "705200",
    "end": "712480"
  },
  {
    "text": "ingestion jar in this demo i want to demonstrate how to use basic functionality of feast",
    "start": "712480",
    "end": "720399"
  },
  {
    "text": "i will register features in fist core i will show you how to",
    "start": "720399",
    "end": "727600"
  },
  {
    "text": "retrieve historical data set for training and of course how to use feed serving to",
    "start": "727600",
    "end": "735680"
  },
  {
    "text": "retrieve online features also we will cover how to ingest",
    "start": "735680",
    "end": "742399"
  },
  {
    "text": "data from patch and streaming source into our online feature storage",
    "start": "742399",
    "end": "749600"
  },
  {
    "text": "first we need to instantiate this client it's essentially an entry point to all",
    "start": "750160",
    "end": "756720"
  },
  {
    "text": "functions that provided by vsdk so we will configure it by",
    "start": "756720",
    "end": "764240"
  },
  {
    "text": "both parameters to the fistkind constructor and environment variables",
    "start": "764240",
    "end": "773839"
  },
  {
    "text": "now we can declare our features for",
    "start": "777040",
    "end": "783839"
  },
  {
    "text": "this example i will be using driver trips data set which consists of features like average",
    "start": "783839",
    "end": "790800"
  },
  {
    "text": "daily trips or conversion right and also drips today the interesting thing",
    "start": "790800",
    "end": "798639"
  },
  {
    "text": "about those features that some of them are updated daily like average daily trips or conversion",
    "start": "798639",
    "end": "805360"
  },
  {
    "text": "rate and some of them like trips today are dated in real time",
    "start": "805360",
    "end": "811839"
  },
  {
    "text": "and despite the fact that the all of the features are connected to the",
    "start": "811839",
    "end": "817279"
  },
  {
    "text": "same key or entity driver id i created here",
    "start": "817279",
    "end": "822800"
  },
  {
    "text": "two feature tables that's because feature tables should be",
    "start": "822800",
    "end": "828639"
  },
  {
    "text": "aligned to the source and now it's a job of feast",
    "start": "828639",
    "end": "835199"
  },
  {
    "text": "to join features from different feature tables and provide you",
    "start": "835199",
    "end": "843199"
  },
  {
    "text": "all features related to the same entity so ingestion job here pulls data from",
    "start": "843199",
    "end": "850800"
  },
  {
    "text": "the watch source and stores it into the feature storage another",
    "start": "850800",
    "end": "856399"
  },
  {
    "text": "ingestion job consume the data from the stream source and also",
    "start": "856399",
    "end": "862399"
  },
  {
    "text": "stores it to the feature storage and serving basically pull all the features",
    "start": "862399",
    "end": "869760"
  },
  {
    "text": "related to one entity and it does it with low latency",
    "start": "869760",
    "end": "876399"
  },
  {
    "text": "because we store all features related to the same entity together in",
    "start": "876399",
    "end": "882839"
  },
  {
    "text": "redis now important fact here is that",
    "start": "882839",
    "end": "889600"
  },
  {
    "text": "populating both data warehouse and stream source is not part of responsibility so beast so feast",
    "start": "889600",
    "end": "897440"
  },
  {
    "text": "relies on on the fact that our customers",
    "start": "897440",
    "end": "903519"
  },
  {
    "text": "already have tools for populating both batch and streaming",
    "start": "903519",
    "end": "910839"
  },
  {
    "text": "sources so in addition to features",
    "start": "910839",
    "end": "917519"
  },
  {
    "text": "that i already showed the feature table has also two",
    "start": "917519",
    "end": "924000"
  },
  {
    "text": "properties batch source and stream source each feature tables is required to have batch source because",
    "start": "924000",
    "end": "932240"
  },
  {
    "text": "all feature tables should participate in a training data set",
    "start": "932240",
    "end": "939360"
  },
  {
    "text": "but not all feature tables not all features",
    "start": "939360",
    "end": "944560"
  },
  {
    "text": "are available from the streaming source at this specific example",
    "start": "944560",
    "end": "952720"
  },
  {
    "text": "we first create feature tables with badge sources only so we will be",
    "start": "953759",
    "end": "960480"
  },
  {
    "text": "able to use them in preparing training dataset so we first",
    "start": "960480",
    "end": "969839"
  },
  {
    "text": "creating the entity then we declare in feature table",
    "start": "970240",
    "end": "977440"
  },
  {
    "text": "referring to this entity and adding all features that are updated",
    "start": "977440",
    "end": "983920"
  },
  {
    "text": "daily specifying their types and we also specify the source it will be directory",
    "start": "983920",
    "end": "992800"
  },
  {
    "text": "in google storage i will use for get forward",
    "start": "992800",
    "end": "999360"
  },
  {
    "text": "also important part is the timestamp columns that we use",
    "start": "999519",
    "end": "1005360"
  },
  {
    "text": "here it's being used for uh point in time correctness for example",
    "start": "1005360",
    "end": "1012320"
  },
  {
    "text": "which i will describe in a moment or just to de-duplicate",
    "start": "1012320",
    "end": "1017839"
  },
  {
    "text": "data that can be somehow duplicated in this source",
    "start": "1017839",
    "end": "1023199"
  },
  {
    "text": "there is also date partition column which we use for optimizing our spark jobs",
    "start": "1023199",
    "end": "1032319"
  },
  {
    "text": "so we declared both special tables and now we can easily register them",
    "start": "1032319",
    "end": "1040319"
  },
  {
    "text": "in the core so i'm calling client dot apply feature table",
    "start": "1040319",
    "end": "1046000"
  },
  {
    "text": "and that sends those uh declaration feature tables to the core",
    "start": "1046000",
    "end": "1051200"
  },
  {
    "text": "now we can test that those feature tables are successfully stored",
    "start": "1051200",
    "end": "1059039"
  },
  {
    "text": "as i said feast assumes that you already have tools that populating",
    "start": "1061600",
    "end": "1068240"
  },
  {
    "text": "your data warehouse or pushing data to kafka but for the sake of this demo",
    "start": "1068240",
    "end": "1076480"
  },
  {
    "text": "i need to put some data into those google storage buckets",
    "start": "1076480",
    "end": "1084160"
  },
  {
    "text": "so i will just generate several data frames",
    "start": "1084160",
    "end": "1089679"
  },
  {
    "text": "and with this helper function i will store them",
    "start": "1091280",
    "end": "1098080"
  },
  {
    "text": "on the google storage as you can see data has been",
    "start": "1098080",
    "end": "1103919"
  },
  {
    "text": "successfully ingested into feature table batch source we can check it by just retrieving",
    "start": "1103919",
    "end": "1110480"
  },
  {
    "text": "what's in the google storage you can see there a bunch of parquet files and",
    "start": "1110480",
    "end": "1117039"
  },
  {
    "text": "it used date call as the partitioning call now we can talk",
    "start": "1117039",
    "end": "1125039"
  },
  {
    "text": "about actually your machine learning project the first step in preparing a model",
    "start": "1125039",
    "end": "1132799"
  },
  {
    "text": "is training and for that we need to generate a training data set",
    "start": "1132799",
    "end": "1141440"
  },
  {
    "text": "important part about generating data set for training is point in time",
    "start": "1141600",
    "end": "1147760"
  },
  {
    "text": "correctness as you can see on this graph when we",
    "start": "1147760",
    "end": "1153120"
  },
  {
    "text": "are making a prediction we use feature values with various timestamps",
    "start": "1153120",
    "end": "1160799"
  },
  {
    "text": "so as you can see those features probably from different sources came in different",
    "start": "1160799",
    "end": "1167679"
  },
  {
    "text": "types thus the prediction function usually use the latest available value",
    "start": "1167679",
    "end": "1176720"
  },
  {
    "text": "since we want our training data set to be as close as possible to what we will",
    "start": "1177120",
    "end": "1183360"
  },
  {
    "text": "have in prediction we are making this point in time correctness correction in the",
    "start": "1183360",
    "end": "1191280"
  },
  {
    "text": "for the training data set as well so data scientists must specify",
    "start": "1191280",
    "end": "1198559"
  },
  {
    "text": "this line here basically this time point",
    "start": "1198559",
    "end": "1204880"
  },
  {
    "text": "and we will we'll be doing backward search and finding the most recent feature",
    "start": "1204880",
    "end": "1211520"
  },
  {
    "text": "value in relation to this time point let me show an example",
    "start": "1211520",
    "end": "1221440"
  },
  {
    "text": "so here from the several data frames that i generated we",
    "start": "1221440",
    "end": "1228080"
  },
  {
    "text": "are using entities data frame to create a request for",
    "start": "1228080",
    "end": "1235760"
  },
  {
    "text": "training dataset so we taking a sample of those entities and adding to",
    "start": "1235760",
    "end": "1242640"
  },
  {
    "text": "them a random event timestamp",
    "start": "1242640",
    "end": "1248000"
  },
  {
    "text": "right so this is a data frame which we will provide as entity source for the",
    "start": "1248000",
    "end": "1255600"
  },
  {
    "text": "our get historical features request this function here launch spark job",
    "start": "1255600",
    "end": "1263440"
  },
  {
    "text": "which can be run on the data proc emr or standalone spark cluster",
    "start": "1263440",
    "end": "1272080"
  },
  {
    "text": "the spark job will pull the features from your batch source and",
    "start": "1272720",
    "end": "1279360"
  },
  {
    "text": "combine them with the entity data set which we just provided",
    "start": "1279360",
    "end": "1284720"
  },
  {
    "text": "do this point in time correctness and return you dataset for training",
    "start": "1284720",
    "end": "1293840"
  },
  {
    "text": "as you can see features from uh two feature tables were combined on this",
    "start": "1302080",
    "end": "1309280"
  },
  {
    "text": "uh resulting uh data set since i was generating those",
    "start": "1309280",
    "end": "1315520"
  },
  {
    "text": "event names then randomly it is possible that in some point in time values for these features",
    "start": "1315520",
    "end": "1325360"
  },
  {
    "text": "haven't yet been set thus we can see now here",
    "start": "1325360",
    "end": "1333039"
  },
  {
    "text": "but in general this data can be used for training your model",
    "start": "1333039",
    "end": "1339760"
  },
  {
    "text": "now let's move to the online features so when you train your",
    "start": "1340640",
    "end": "1347760"
  },
  {
    "text": "model you will probably go with it to production and in production you will do real-time",
    "start": "1347760",
    "end": "1355440"
  },
  {
    "text": "prediction so we will be using the real-time online features",
    "start": "1355440",
    "end": "1363039"
  },
  {
    "text": "in order to do that you need to have those features in online storage the simplest way to",
    "start": "1363520",
    "end": "1369200"
  },
  {
    "text": "populate the storage is to take everything you have in your box storage",
    "start": "1369200",
    "end": "1374240"
  },
  {
    "text": "and put the latest values of each each feature for each entity into online",
    "start": "1374240",
    "end": "1381360"
  },
  {
    "text": "storage so now we will do exactly this we will run the offline to online ingestion which",
    "start": "1381360",
    "end": "1388799"
  },
  {
    "text": "also starts a spark job which reads from the google storage and store",
    "start": "1388799",
    "end": "1394799"
  },
  {
    "text": "to raise when this job is completed we can",
    "start": "1394799",
    "end": "1402159"
  },
  {
    "text": "again generate some sample of entities and make a request",
    "start": "1402159",
    "end": "1409280"
  },
  {
    "text": "to the online survey to retrieve features on those entities as you can see this is",
    "start": "1409280",
    "end": "1416159"
  },
  {
    "text": "much faster because it used radius and the backend",
    "start": "1416159",
    "end": "1422159"
  },
  {
    "text": "now on those feature values you can run your production prediction",
    "start": "1422159",
    "end": "1431840"
  },
  {
    "text": "as the next step we can also add another features to our production",
    "start": "1432799",
    "end": "1439200"
  },
  {
    "text": "prediction namely the real-time features so in order to do that we need to add a streaming",
    "start": "1439200",
    "end": "1447600"
  },
  {
    "text": "source as one of the sources for our to our to our feature table",
    "start": "1447600",
    "end": "1455360"
  },
  {
    "text": "with this streaming source we need to specify also bootstrap server and topic since we're using kafka source",
    "start": "1455360",
    "end": "1463520"
  },
  {
    "text": "and also we need to specify a message format which in this example is avro format and",
    "start": "1463520",
    "end": "1472240"
  },
  {
    "text": "of course we need our schema so the ingestion job would know how to decode records coming",
    "start": "1472240",
    "end": "1479679"
  },
  {
    "text": "from kafka topic",
    "start": "1479679",
    "end": "1482880"
  },
  {
    "text": "so this our schema in this example consists of feature trips today and",
    "start": "1485520",
    "end": "1491840"
  },
  {
    "text": "entity driver id and event column called datatype",
    "start": "1491840",
    "end": "1497600"
  },
  {
    "text": "now that we updated feature table in core we can start our ingestion job",
    "start": "1497600",
    "end": "1505360"
  },
  {
    "text": "as soon as job consuming specified kafka topic we can start to populate it so this",
    "start": "1508960",
    "end": "1515360"
  },
  {
    "text": "function takes the record from our trips data frame",
    "start": "1515360",
    "end": "1523520"
  },
  {
    "text": "and encode it with given our schema and put it",
    "start": "1523520",
    "end": "1528720"
  },
  {
    "text": "into cockatopic",
    "start": "1528720",
    "end": "1531679"
  },
  {
    "text": "now we should be able to retrieve those features with our get online",
    "start": "1537760",
    "end": "1544400"
  },
  {
    "text": "feature method so we generate an entity sample again",
    "start": "1544400",
    "end": "1549440"
  },
  {
    "text": "and doing requests",
    "start": "1549440",
    "end": "1557760"
  },
  {
    "text": "so you can see here that we uh having both average daily trips",
    "start": "1557760",
    "end": "1565520"
  },
  {
    "text": "feature which comes from the badge source and was ingested with watch injection",
    "start": "1565520",
    "end": "1572480"
  },
  {
    "text": "job and trips today which comes from the streaming source and we just ingested it from kafka in",
    "start": "1572480",
    "end": "1580000"
  },
  {
    "text": "the same response those features are now can be used for your model prediction",
    "start": "1580000",
    "end": "1588240"
  },
  {
    "text": "that is everything that i wanted to cover in this demo thank you for attention you can find",
    "start": "1588240",
    "end": "1593679"
  },
  {
    "text": "this notebook or other examples in our repository",
    "start": "1593679",
    "end": "1598960"
  },
  {
    "text": "on github",
    "start": "1598960",
    "end": "1601600"
  },
  {
    "text": "three years ago uber introduced the concept of a feature store through their blog post on michelangelo their machine",
    "start": "1606080",
    "end": "1611360"
  },
  {
    "text": "learning platform since then many companies have built their own feature stores",
    "start": "1611360",
    "end": "1616559"
  },
  {
    "text": "like feast from gojek airbnb zipline and many others teams large and small",
    "start": "1616559",
    "end": "1622799"
  },
  {
    "text": "are starting to realize how critical a feature story is in the ml stack of the future",
    "start": "1622799",
    "end": "1629200"
  },
  {
    "text": "where is feast now well we released 0.1 late 2018 we rolled it out in gojic and we've gone",
    "start": "1629200",
    "end": "1634559"
  },
  {
    "text": "from strength to strength from 0.2 onwards we've been working with our community we developed decentralized serving we",
    "start": "1634559",
    "end": "1641600"
  },
  {
    "text": "developed point in time correctness we added project isolation and isolation and name spacing",
    "start": "1641600",
    "end": "1646799"
  },
  {
    "text": "we simplified concept and added integration points we integrated with t of x and t of db we allowed for multiple",
    "start": "1646799",
    "end": "1654080"
  },
  {
    "text": "vpc support and request response logging and monitoring and metrics in production and",
    "start": "1654080",
    "end": "1659840"
  },
  {
    "text": "recently we've added amazon support and spark support with the help of teams like techton",
    "start": "1659840",
    "end": "1666799"
  },
  {
    "text": "so who are our bigger droppers and contributors well we've been working closely with a community of large technology companies",
    "start": "1667120",
    "end": "1674080"
  },
  {
    "text": "like agoda that's delivered cassandra support postmates has delivered bigtable support we've added um some prison has added",
    "start": "1674080",
    "end": "1681440"
  },
  {
    "text": "oauth and we've been working with microsoft and farfetch and they've delivered delivered data",
    "start": "1681440",
    "end": "1687200"
  },
  {
    "text": "bricks and delta support and recently we've been working with techton who've contributed spark and",
    "start": "1687200",
    "end": "1693200"
  },
  {
    "text": "amazon support so there are over 43 contributors and six plus enterprise customers running feast in",
    "start": "1693200",
    "end": "1699279"
  },
  {
    "text": "production today at scale let's talk about the feast vision for a second so there are three aspects that",
    "start": "1699279",
    "end": "1704799"
  },
  {
    "text": "we want to look at the first is open governance and standards so there are teams large",
    "start": "1704799",
    "end": "1710000"
  },
  {
    "text": "and small that currently rely on feast they're not just running it in production but they're also",
    "start": "1710000",
    "end": "1715120"
  },
  {
    "text": "contributing code back to the project they're collaborating with us these teams need to know that they can rely on the project at scale but that",
    "start": "1715120",
    "end": "1721679"
  },
  {
    "text": "they can also shape the direction of the project so we believe open governance and the transparent process is important",
    "start": "1721679",
    "end": "1728240"
  },
  {
    "text": "in driving our project and encouraging further adoption secondly we want to both feast into a multi-cloud",
    "start": "1728240",
    "end": "1735679"
  },
  {
    "text": "or cloud agnostic modular and production grade feature store meaning if you're a team using fees you should",
    "start": "1735679",
    "end": "1742000"
  },
  {
    "text": "be able to cherry pick the components you need deployed wherever you are running your existing machine learning",
    "start": "1742000",
    "end": "1747440"
  },
  {
    "text": "stack and then run that at scale reliably lastly we want to make feast easy to",
    "start": "1747440",
    "end": "1752799"
  },
  {
    "text": "integrate into existing machining tools and the mml tools of the future meaning",
    "start": "1752799",
    "end": "1758320"
  },
  {
    "text": "if these are machine learning platforms upstream data transformation systems downstream model serving we want to have",
    "start": "1758320",
    "end": "1764480"
  },
  {
    "text": "clear api contracts and clear integration points so these are all key parts of our vision",
    "start": "1764480",
    "end": "1769520"
  },
  {
    "text": "and we are already starting to work towards addressing them so for open governance and standards we",
    "start": "1769520",
    "end": "1775120"
  },
  {
    "text": "are super excited to acknowledge that feast is now officially a part of the linux foundation",
    "start": "1775120",
    "end": "1780640"
  },
  {
    "text": "meaning that not a single company has any kind of special privilege on the project the trademark is now part of the linux",
    "start": "1780640",
    "end": "1787440"
  },
  {
    "text": "foundation and we will be we are already operating on a governance structure defined by the",
    "start": "1787440",
    "end": "1793039"
  },
  {
    "text": "linux foundation which means it's completely neutrally governed and",
    "start": "1793039",
    "end": "1798559"
  },
  {
    "text": "the process and structure is completely public and transparent there's an initial group of maintainers",
    "start": "1798559",
    "end": "1804720"
  },
  {
    "text": "and a democratic process for new companies and teams to become maintainers of the project",
    "start": "1804720",
    "end": "1810880"
  },
  {
    "text": "secondly we believe that we need to work with the greatest minds in the industry in order to build",
    "start": "1810880",
    "end": "1816799"
  },
  {
    "text": "a best-in-class feature store and we've already worked with many of the greatest minds over the last couple of months but one",
    "start": "1816799",
    "end": "1824080"
  },
  {
    "text": "team in particular stands out there and we're super excited to announce that techton",
    "start": "1824080",
    "end": "1829440"
  },
  {
    "text": "will be committing a significant amount of resources towards feast development we believe that by",
    "start": "1829440",
    "end": "1835520"
  },
  {
    "text": "joining forces with techton we'll be able to build a world-class feature store that teams",
    "start": "1835520",
    "end": "1840720"
  },
  {
    "text": "large and small can rely on and together we hope to set the standard for what a feature store is",
    "start": "1840720",
    "end": "1846320"
  },
  {
    "text": "and so we're super excited for this collaboration opportunity and all of this is happening underneath",
    "start": "1846320",
    "end": "1852480"
  },
  {
    "text": "the linux foundation umbrella then finally we'd like to announce that we are now a top level component of",
    "start": "1852480",
    "end": "1858960"
  },
  {
    "text": "keyflow and this is the start of our integration journey keyflow is one of the best machine",
    "start": "1858960",
    "end": "1864320"
  },
  {
    "text": "learning platforms out there completely open source so it's both best of breed and an",
    "start": "1864320",
    "end": "1869440"
  },
  {
    "text": "end-to-end system and we believe that by integrating into key flow and improving that integration",
    "start": "1869440",
    "end": "1874640"
  },
  {
    "text": "will not just improve the integrations of feast with into ml platforms but also to sister projects like model",
    "start": "1874640",
    "end": "1881600"
  },
  {
    "text": "serving or pipelining or other managed services",
    "start": "1881600",
    "end": "1886880"
  },
  {
    "text": "so our roadmap going forward for fees 0.9 we believe which is currently under development we",
    "start": "1888240",
    "end": "1894960"
  },
  {
    "text": "believe that we'll be able to achieve um cloud agnostic deployments so we've already got as",
    "start": "1894960",
    "end": "1900240"
  },
  {
    "text": "we're sorry we've already got amazon google cloud support and we'll be launching azure support as",
    "start": "1900240",
    "end": "1906000"
  },
  {
    "text": "well as on-prem deployment support we'll be adding offline storage support for delta and we'll be adding feature",
    "start": "1906000",
    "end": "1912080"
  },
  {
    "text": "engineering support which will likely be through spark sql we will also be sending out requests for",
    "start": "1912080",
    "end": "1919200"
  },
  {
    "text": "comments on on-demand feature transformations and a feature discovery user interface",
    "start": "1919200",
    "end": "1924480"
  },
  {
    "text": "then finally come and say hello our home page is over at fistdev our source code is all online it's completely open and",
    "start": "1924480",
    "end": "1931760"
  },
  {
    "text": "apache too licensed we have a feast channel on the keeper slack and you can find a",
    "start": "1931760",
    "end": "1936880"
  },
  {
    "text": "link to this deck on tinyurl on the screen right now thank you",
    "start": "1936880",
    "end": "1945840"
  }
]
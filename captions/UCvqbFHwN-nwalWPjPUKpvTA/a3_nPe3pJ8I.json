[
  {
    "text": "hi everyone uh thank you so much for",
    "start": "960",
    "end": "3040"
  },
  {
    "text": "tuning in",
    "start": "3040",
    "end": "3679"
  },
  {
    "text": "uh i'm david roncek uh co-founder of",
    "start": "3679",
    "end": "6080"
  },
  {
    "text": "kubeflow and program manager in the cto",
    "start": "6080",
    "end": "8559"
  },
  {
    "text": "organization inside azure and with jana",
    "start": "8559",
    "end": "11679"
  },
  {
    "text": "zarcatas",
    "start": "11679",
    "end": "12480"
  },
  {
    "text": "i'll be talking about owned by",
    "start": "12480",
    "end": "14000"
  },
  {
    "text": "statistics how",
    "start": "14000",
    "end": "15519"
  },
  {
    "text": "you can attack machine learning models",
    "start": "15519",
    "end": "17119"
  },
  {
    "text": "and how you can use kubeflow to defend",
    "start": "17119",
    "end": "19520"
  },
  {
    "text": "one thing i want to say is how much i",
    "start": "19520",
    "end": "21680"
  },
  {
    "text": "love kubecon every year",
    "start": "21680",
    "end": "23279"
  },
  {
    "text": "and it's such an honor to be able to",
    "start": "23279",
    "end": "24960"
  },
  {
    "text": "present even though it's virtual",
    "start": "24960",
    "end": "26800"
  },
  {
    "text": "and i miss you all terribly",
    "start": "26800",
    "end": "30000"
  },
  {
    "text": "so with that you know",
    "start": "30000",
    "end": "33040"
  },
  {
    "text": "one thing that we talk a lot about in",
    "start": "33040",
    "end": "35120"
  },
  {
    "text": "machine learning is how powerful",
    "start": "35120",
    "end": "36960"
  },
  {
    "text": "everything is and how many advancements",
    "start": "36960",
    "end": "39280"
  },
  {
    "text": "have occurred",
    "start": "39280",
    "end": "40160"
  },
  {
    "text": "in the recent past specifically you can",
    "start": "40160",
    "end": "42719"
  },
  {
    "text": "see some of those examples",
    "start": "42719",
    "end": "44079"
  },
  {
    "text": "here where you have machine learning",
    "start": "44079",
    "end": "46399"
  },
  {
    "text": "models from microsoft really setting the",
    "start": "46399",
    "end": "48239"
  },
  {
    "text": "bar",
    "start": "48239",
    "end": "48960"
  },
  {
    "text": "to new and interesting advancements",
    "start": "48960",
    "end": "52480"
  },
  {
    "text": "and and really handing it back to the",
    "start": "52480",
    "end": "54559"
  },
  {
    "text": "community you know",
    "start": "54559",
    "end": "55520"
  },
  {
    "text": "machine learning is all about open",
    "start": "55520",
    "end": "57039"
  },
  {
    "text": "source and it's not just that we built",
    "start": "57039",
    "end": "59520"
  },
  {
    "text": "on these open source projects externally",
    "start": "59520",
    "end": "61359"
  },
  {
    "text": "but then gave back after we were done",
    "start": "61359",
    "end": "64720"
  },
  {
    "text": "now with that you know you wonder how",
    "start": "64720",
    "end": "67360"
  },
  {
    "text": "this affects microsoft and the reality",
    "start": "67360",
    "end": "69040"
  },
  {
    "text": "is",
    "start": "69040",
    "end": "69280"
  },
  {
    "text": "it affects us in just about every way",
    "start": "69280",
    "end": "71600"
  },
  {
    "text": "possible",
    "start": "71600",
    "end": "72400"
  },
  {
    "text": "it touches our consumer our enterprise",
    "start": "72400",
    "end": "74799"
  },
  {
    "text": "our game business",
    "start": "74799",
    "end": "76799"
  },
  {
    "text": "you know our search business they all",
    "start": "76799",
    "end": "78880"
  },
  {
    "text": "simply could not work without the power",
    "start": "78880",
    "end": "81280"
  },
  {
    "text": "that machine learning gives us to",
    "start": "81280",
    "end": "82720"
  },
  {
    "text": "analyze enormous data sets",
    "start": "82720",
    "end": "84640"
  },
  {
    "text": "and when i say enormous data sets i mean",
    "start": "84640",
    "end": "86240"
  },
  {
    "text": "stuff like you see here",
    "start": "86240",
    "end": "87920"
  },
  {
    "text": "whether or not it's people using office",
    "start": "87920",
    "end": "89759"
  },
  {
    "text": "people asking questions of cortana",
    "start": "89759",
    "end": "91600"
  },
  {
    "text": "or the 6.5 trillion signals that we",
    "start": "91600",
    "end": "94640"
  },
  {
    "text": "evaluate on a daily basis",
    "start": "94640",
    "end": "96320"
  },
  {
    "text": "around security we could not handle this",
    "start": "96320",
    "end": "99040"
  },
  {
    "text": "without the things that machine learning",
    "start": "99040",
    "end": "100640"
  },
  {
    "text": "provides",
    "start": "100640",
    "end": "102560"
  },
  {
    "text": "with that said oftentimes in the machine",
    "start": "102560",
    "end": "105200"
  },
  {
    "text": "learning space we",
    "start": "105200",
    "end": "106399"
  },
  {
    "text": "tell you these great stories and then",
    "start": "106399",
    "end": "108799"
  },
  {
    "text": "kind of like leave it up to you to",
    "start": "108799",
    "end": "110799"
  },
  {
    "text": "as an exercise to the reader to go and",
    "start": "110799",
    "end": "112320"
  },
  {
    "text": "implement it and the reality is machine",
    "start": "112320",
    "end": "114000"
  },
  {
    "text": "learning is hard and it's something that",
    "start": "114000",
    "end": "117040"
  },
  {
    "text": "we definitely don't pay enough attention",
    "start": "117040",
    "end": "118880"
  },
  {
    "text": "to",
    "start": "118880",
    "end": "120799"
  },
  {
    "text": "and one of the reasons it is so hard is",
    "start": "120799",
    "end": "122799"
  },
  {
    "text": "because of what you see here",
    "start": "122799",
    "end": "124880"
  },
  {
    "text": "most of the time people focus on just",
    "start": "124880",
    "end": "127360"
  },
  {
    "text": "building a model",
    "start": "127360",
    "end": "128720"
  },
  {
    "text": "but the reality is is that building a",
    "start": "128720",
    "end": "130239"
  },
  {
    "text": "model is only one step of a very",
    "start": "130239",
    "end": "132640"
  },
  {
    "text": "complicated workflow",
    "start": "132640",
    "end": "134239"
  },
  {
    "text": "and thinking about the pipelines is how",
    "start": "134239",
    "end": "136560"
  },
  {
    "text": "people",
    "start": "136560",
    "end": "137280"
  },
  {
    "text": "will help get people to adopt things",
    "start": "137280",
    "end": "139440"
  },
  {
    "text": "more",
    "start": "139440",
    "end": "141040"
  },
  {
    "text": "now let's say you're a data scientist",
    "start": "141040",
    "end": "142720"
  },
  {
    "text": "and you say well i don't really care",
    "start": "142720",
    "end": "144160"
  },
  {
    "text": "about that",
    "start": "144160",
    "end": "144720"
  },
  {
    "text": "i'm good the answer is yes you do and",
    "start": "144720",
    "end": "147440"
  },
  {
    "text": "the reason is is because of what you see",
    "start": "147440",
    "end": "149280"
  },
  {
    "text": "here",
    "start": "149280",
    "end": "150000"
  },
  {
    "text": "people build these fantastic models and",
    "start": "150000",
    "end": "152080"
  },
  {
    "text": "then take forever to get them out to",
    "start": "152080",
    "end": "154840"
  },
  {
    "text": "production",
    "start": "154840",
    "end": "156080"
  },
  {
    "text": "one way through that is with ml ups",
    "start": "156080",
    "end": "159680"
  },
  {
    "text": "ml ops is machine learning operations",
    "start": "159680",
    "end": "161760"
  },
  {
    "text": "derivative from devops and git ops",
    "start": "161760",
    "end": "164080"
  },
  {
    "text": "it brings data scientists and machine",
    "start": "164080",
    "end": "166480"
  },
  {
    "text": "learning engineers",
    "start": "166480",
    "end": "167680"
  },
  {
    "text": "into the development process so now they",
    "start": "167680",
    "end": "169680"
  },
  {
    "text": "can execute this inner loop like you see",
    "start": "169680",
    "end": "171440"
  },
  {
    "text": "here on the left",
    "start": "171440",
    "end": "172560"
  },
  {
    "text": "iterating very very quickly and then",
    "start": "172560",
    "end": "175280"
  },
  {
    "text": "when the time comes they're able to",
    "start": "175280",
    "end": "177040"
  },
  {
    "text": "expand and bring be brought into the",
    "start": "177040",
    "end": "179120"
  },
  {
    "text": "normal application developer",
    "start": "179120",
    "end": "181040"
  },
  {
    "text": "cycle where in this case they're able to",
    "start": "181040",
    "end": "183680"
  },
  {
    "text": "now integrate their",
    "start": "183680",
    "end": "184800"
  },
  {
    "text": "sophisticated models into the",
    "start": "184800",
    "end": "186879"
  },
  {
    "text": "development and rollout",
    "start": "186879",
    "end": "190159"
  },
  {
    "text": "procedures so you may be asking yourself",
    "start": "190159",
    "end": "192879"
  },
  {
    "text": "wasn't this supposed to be",
    "start": "192879",
    "end": "194239"
  },
  {
    "text": "a talk about security and the answer is",
    "start": "194239",
    "end": "196879"
  },
  {
    "text": "yes",
    "start": "196879",
    "end": "198000"
  },
  {
    "text": "uh be and that is because ml ops is the",
    "start": "198000",
    "end": "201120"
  },
  {
    "text": "baseline",
    "start": "201120",
    "end": "202000"
  },
  {
    "text": "for security and i'll talk to you about",
    "start": "202000",
    "end": "204640"
  },
  {
    "text": "how ml ops",
    "start": "204640",
    "end": "205840"
  },
  {
    "text": "provides you security by focusing on",
    "start": "205840",
    "end": "208000"
  },
  {
    "text": "three different types of attacks you may",
    "start": "208000",
    "end": "209920"
  },
  {
    "text": "see",
    "start": "209920",
    "end": "211200"
  },
  {
    "text": "the first is that we'll dive into",
    "start": "211200",
    "end": "214400"
  },
  {
    "text": "is your attacker gets your ml model to",
    "start": "214400",
    "end": "217200"
  },
  {
    "text": "light",
    "start": "217200",
    "end": "218239"
  },
  {
    "text": "so we're going to start with a really",
    "start": "218239",
    "end": "219360"
  },
  {
    "text": "basic example of a model here",
    "start": "219360",
    "end": "221519"
  },
  {
    "text": "in this case we'll be looking at what",
    "start": "221519",
    "end": "223440"
  },
  {
    "text": "i'm calling a circle detector",
    "start": "223440",
    "end": "224879"
  },
  {
    "text": "and a circle detector you're going to",
    "start": "224879",
    "end": "226000"
  },
  {
    "text": "pull in a lot of things into ingested",
    "start": "226000",
    "end": "228720"
  },
  {
    "text": "you're going to split both your",
    "start": "228720",
    "end": "231440"
  },
  {
    "text": "production",
    "start": "231440",
    "end": "232080"
  },
  {
    "text": "and your training data then you're going",
    "start": "232080",
    "end": "234480"
  },
  {
    "text": "to actually train",
    "start": "234480",
    "end": "236159"
  },
  {
    "text": "on that data which will be quite large",
    "start": "236159",
    "end": "238239"
  },
  {
    "text": "and then you'll have some certain",
    "start": "238239",
    "end": "239519"
  },
  {
    "text": "inference",
    "start": "239519",
    "end": "240319"
  },
  {
    "text": "endpoint now in this case we're going to",
    "start": "240319",
    "end": "242799"
  },
  {
    "text": "start by collecting a whole bunch of",
    "start": "242799",
    "end": "244879"
  },
  {
    "text": "examples of circles and feed that into",
    "start": "244879",
    "end": "246959"
  },
  {
    "text": "our training data",
    "start": "246959",
    "end": "248159"
  },
  {
    "text": "and then out the other side when i",
    "start": "248159",
    "end": "250080"
  },
  {
    "text": "present a sample",
    "start": "250080",
    "end": "253040"
  },
  {
    "text": "model here excuse me a sample object and",
    "start": "253040",
    "end": "255760"
  },
  {
    "text": "it's going to come back and say that is",
    "start": "255760",
    "end": "257680"
  },
  {
    "text": "it is in fact a circle so look so far so",
    "start": "257680",
    "end": "260160"
  },
  {
    "text": "good",
    "start": "260160",
    "end": "260720"
  },
  {
    "text": "uh looking great now if i present a",
    "start": "260720",
    "end": "263199"
  },
  {
    "text": "square to it",
    "start": "263199",
    "end": "264160"
  },
  {
    "text": "it still says it's a circle and i have",
    "start": "264160",
    "end": "266000"
  },
  {
    "text": "to wonder why what's going on here",
    "start": "266000",
    "end": "268880"
  },
  {
    "text": "well if i look at these two things one",
    "start": "268880",
    "end": "270960"
  },
  {
    "text": "is green",
    "start": "270960",
    "end": "272080"
  },
  {
    "text": "one is blue one is round one is square",
    "start": "272080",
    "end": "274960"
  },
  {
    "text": "how could these two be confused",
    "start": "274960",
    "end": "277040"
  },
  {
    "text": "and the reality is is because i didn't",
    "start": "277040",
    "end": "279280"
  },
  {
    "text": "give my exit model enough examples",
    "start": "279280",
    "end": "281520"
  },
  {
    "text": "in this case i gave it something which",
    "start": "281520",
    "end": "283120"
  },
  {
    "text": "has all the same pixels",
    "start": "283120",
    "end": "284960"
  },
  {
    "text": "as a circle but in fact i didn't tell it",
    "start": "284960",
    "end": "287440"
  },
  {
    "text": "what to look for",
    "start": "287440",
    "end": "288400"
  },
  {
    "text": "and so the model says well it has the",
    "start": "288400",
    "end": "290479"
  },
  {
    "text": "same pixels as a circle",
    "start": "290479",
    "end": "292240"
  },
  {
    "text": "so it's a circle but obviously that is",
    "start": "292240",
    "end": "294840"
  },
  {
    "text": "incorrect",
    "start": "294840",
    "end": "296960"
  },
  {
    "text": "now surely advanced models are better we",
    "start": "296960",
    "end": "299280"
  },
  {
    "text": "don't see this in the real world",
    "start": "299280",
    "end": "301039"
  },
  {
    "text": "but the reality is that's wrong too uh",
    "start": "301039",
    "end": "303840"
  },
  {
    "text": "here's an example of a husky versus wolf",
    "start": "303840",
    "end": "306160"
  },
  {
    "text": "detector",
    "start": "306160",
    "end": "306960"
  },
  {
    "text": "and you know it looks great we were able",
    "start": "306960",
    "end": "309680"
  },
  {
    "text": "to do",
    "start": "309680",
    "end": "310000"
  },
  {
    "text": "it with only one mistake out of the",
    "start": "310000",
    "end": "311840"
  },
  {
    "text": "entire group",
    "start": "311840",
    "end": "313680"
  },
  {
    "text": "and you're looking pretty good but when",
    "start": "313680",
    "end": "315759"
  },
  {
    "text": "you turn it over",
    "start": "315759",
    "end": "316880"
  },
  {
    "text": "and you look into the explainer what you",
    "start": "316880",
    "end": "320240"
  },
  {
    "text": "see is that a lot of the data",
    "start": "320240",
    "end": "321919"
  },
  {
    "text": "under the hood uh looks like in the",
    "start": "321919",
    "end": "324720"
  },
  {
    "text": "husky case it looks like it's picking up",
    "start": "324720",
    "end": "326639"
  },
  {
    "text": "pictures of the animal",
    "start": "326639",
    "end": "328160"
  },
  {
    "text": "but in the wolf case it looks like it's",
    "start": "328160",
    "end": "329919"
  },
  {
    "text": "just picking up stuff around the edge",
    "start": "329919",
    "end": "331919"
  },
  {
    "text": "and kind of we're like well what's going",
    "start": "331919",
    "end": "333440"
  },
  {
    "text": "on here",
    "start": "333440",
    "end": "335039"
  },
  {
    "text": "as we dive just a little bit deeper into",
    "start": "335039",
    "end": "337280"
  },
  {
    "text": "it you see that",
    "start": "337280",
    "end": "338639"
  },
  {
    "text": "in fact lots of the wolf was not",
    "start": "338639",
    "end": "340880"
  },
  {
    "text": "included and what we really did",
    "start": "340880",
    "end": "342639"
  },
  {
    "text": "was train a snow detector now you say",
    "start": "342639",
    "end": "346400"
  },
  {
    "text": "well this again you know maybe this is",
    "start": "346400",
    "end": "348639"
  },
  {
    "text": "just for paper purposes",
    "start": "348639",
    "end": "350240"
  },
  {
    "text": "no in fact you see this over and over",
    "start": "350240",
    "end": "352320"
  },
  {
    "text": "again uh where in",
    "start": "352320",
    "end": "353759"
  },
  {
    "text": "in one case you have a ship uh that is",
    "start": "353759",
    "end": "356080"
  },
  {
    "text": "actually looking for",
    "start": "356080",
    "end": "357039"
  },
  {
    "text": "water uh in another case you have trains",
    "start": "357039",
    "end": "360160"
  },
  {
    "text": "that are actually looking for",
    "start": "360160",
    "end": "361600"
  },
  {
    "text": "uh trained tracks and then in the third",
    "start": "361600",
    "end": "364160"
  },
  {
    "text": "case and one of my favorites",
    "start": "364160",
    "end": "366080"
  },
  {
    "text": "you see a horse detector who is really",
    "start": "366080",
    "end": "368319"
  },
  {
    "text": "looking for",
    "start": "368319",
    "end": "369440"
  },
  {
    "text": "copyright notifications apparently a lot",
    "start": "369440",
    "end": "371280"
  },
  {
    "text": "of horse images have copyright",
    "start": "371280",
    "end": "372960"
  },
  {
    "text": "notifications",
    "start": "372960",
    "end": "375120"
  },
  {
    "text": "and that's just from accidental stuff",
    "start": "375120",
    "end": "377199"
  },
  {
    "text": "now let's talk about when people are",
    "start": "377199",
    "end": "378560"
  },
  {
    "text": "actually trying to attack you",
    "start": "378560",
    "end": "380160"
  },
  {
    "text": "in this case on the left hand side we",
    "start": "380160",
    "end": "382080"
  },
  {
    "text": "put pixels over a stop sign",
    "start": "382080",
    "end": "383759"
  },
  {
    "text": "and it indicates it's a speed limit sign",
    "start": "383759",
    "end": "386000"
  },
  {
    "text": "and on the right they",
    "start": "386000",
    "end": "387360"
  },
  {
    "text": "they 3d printed a shell and made it",
    "start": "387360",
    "end": "389520"
  },
  {
    "text": "think that it was a rifle",
    "start": "389520",
    "end": "392080"
  },
  {
    "text": "it gets even worse when you start",
    "start": "392080",
    "end": "393759"
  },
  {
    "text": "thinking about military implications",
    "start": "393759",
    "end": "396240"
  },
  {
    "text": "in this case we have a model that which",
    "start": "396240",
    "end": "398560"
  },
  {
    "text": "is looking for airplanes on a runway",
    "start": "398560",
    "end": "400240"
  },
  {
    "text": "which is easily able to detect",
    "start": "400240",
    "end": "402080"
  },
  {
    "text": "until you put a sticker on the back of",
    "start": "402080",
    "end": "404560"
  },
  {
    "text": "the airplane",
    "start": "404560",
    "end": "405600"
  },
  {
    "text": "and it is able to camouflage those",
    "start": "405600",
    "end": "407840"
  },
  {
    "text": "airplanes as though they didn't exist",
    "start": "407840",
    "end": "409599"
  },
  {
    "text": "and finally you know thinking about what",
    "start": "409599",
    "end": "411680"
  },
  {
    "text": "happens when you",
    "start": "411680",
    "end": "412880"
  },
  {
    "text": "put a layer of glasses over these",
    "start": "412880",
    "end": "415840"
  },
  {
    "text": "individuals",
    "start": "415840",
    "end": "416800"
  },
  {
    "text": "you're able to convince the the model",
    "start": "416800",
    "end": "419120"
  },
  {
    "text": "that these are in fact completely",
    "start": "419120",
    "end": "420639"
  },
  {
    "text": "different people",
    "start": "420639",
    "end": "422639"
  },
  {
    "text": "and you think that these might just be",
    "start": "422639",
    "end": "424160"
  },
  {
    "text": "toy examples until you realize that",
    "start": "424160",
    "end": "426880"
  },
  {
    "text": "amazon's face recognition system",
    "start": "426880",
    "end": "428880"
  },
  {
    "text": "mismatched 28",
    "start": "428880",
    "end": "430479"
  },
  {
    "text": "congress people with their mug shots",
    "start": "430479",
    "end": "433039"
  },
  {
    "text": "indicating they might be criminals",
    "start": "433039",
    "end": "434720"
  },
  {
    "text": "and it's not just that it's also",
    "start": "434720",
    "end": "436479"
  },
  {
    "text": "extremely hard to opt",
    "start": "436479",
    "end": "438160"
  },
  {
    "text": "out so you can't even get out of these",
    "start": "438160",
    "end": "440319"
  },
  {
    "text": "systems even if you wanted to",
    "start": "440319",
    "end": "442639"
  },
  {
    "text": "so are you terrified yet the answer for",
    "start": "442639",
    "end": "445680"
  },
  {
    "text": "this",
    "start": "445680",
    "end": "446240"
  },
  {
    "text": "is to use ml ops in an ml ops pipeline",
    "start": "446240",
    "end": "449680"
  },
  {
    "text": "you start with ingestion where you have",
    "start": "449680",
    "end": "451599"
  },
  {
    "text": "more edge cases",
    "start": "451599",
    "end": "452880"
  },
  {
    "text": "and detecting for bad data use better",
    "start": "452880",
    "end": "455280"
  },
  {
    "text": "evaluation metrics and different models",
    "start": "455280",
    "end": "458160"
  },
  {
    "text": "you also make sure that you have a red",
    "start": "458160",
    "end": "459680"
  },
  {
    "text": "team in place and attack your own models",
    "start": "459680",
    "end": "461680"
  },
  {
    "text": "first",
    "start": "461680",
    "end": "462319"
  },
  {
    "text": "along with a rich alerting and",
    "start": "462319",
    "end": "464080"
  },
  {
    "text": "monitoring but",
    "start": "464080",
    "end": "465360"
  },
  {
    "text": "most importantly it's feeding the",
    "start": "465360",
    "end": "467440"
  },
  {
    "text": "information you get",
    "start": "467440",
    "end": "468639"
  },
  {
    "text": "back from your serving into your model",
    "start": "468639",
    "end": "471759"
  },
  {
    "text": "so that you can quickly become smarter",
    "start": "471759",
    "end": "473919"
  },
  {
    "text": "over time and continually iterate and",
    "start": "473919",
    "end": "476000"
  },
  {
    "text": "improve",
    "start": "476000",
    "end": "476879"
  },
  {
    "text": "this is really only possible with a rich",
    "start": "476879",
    "end": "479520"
  },
  {
    "text": "ml ops pipeline",
    "start": "479520",
    "end": "481680"
  },
  {
    "text": "so a pipeline you say tell me more",
    "start": "481680",
    "end": "485360"
  },
  {
    "text": "well when it comes to a pipeline what",
    "start": "485360",
    "end": "487440"
  },
  {
    "text": "we're talking about",
    "start": "487440",
    "end": "488400"
  },
  {
    "text": "is the ability to break down a complex",
    "start": "488400",
    "end": "490639"
  },
  {
    "text": "series of microservices",
    "start": "490639",
    "end": "492400"
  },
  {
    "text": "and wire them together in a way that",
    "start": "492400",
    "end": "494160"
  },
  {
    "text": "makes sense",
    "start": "494160",
    "end": "495599"
  },
  {
    "text": "in this case we will be talking about",
    "start": "495599",
    "end": "497440"
  },
  {
    "text": "using something like ci cd github",
    "start": "497440",
    "end": "499280"
  },
  {
    "text": "actions and jenkins",
    "start": "499280",
    "end": "501280"
  },
  {
    "text": "loosely modular components that you can",
    "start": "501280",
    "end": "504400"
  },
  {
    "text": "use from on cloud or on-prem and making",
    "start": "504400",
    "end": "507919"
  },
  {
    "text": "sure that you're constantly measuring",
    "start": "507919",
    "end": "509599"
  },
  {
    "text": "and",
    "start": "509599",
    "end": "509840"
  },
  {
    "text": "updating and the only way to do that is",
    "start": "509840",
    "end": "511520"
  },
  {
    "text": "with something declarative",
    "start": "511520",
    "end": "513039"
  },
  {
    "text": "that you can run over and over again",
    "start": "513039",
    "end": "515039"
  },
  {
    "text": "without human intervention",
    "start": "515039",
    "end": "517680"
  },
  {
    "text": "to drill in just a little bit deeper",
    "start": "517680",
    "end": "519440"
  },
  {
    "text": "let's say you start with jupiter in the",
    "start": "519440",
    "end": "521200"
  },
  {
    "text": "upper left hand corner there",
    "start": "521200",
    "end": "522640"
  },
  {
    "text": "where you're automatically iterating",
    "start": "522640",
    "end": "524560"
  },
  {
    "text": "once you're done you check that into",
    "start": "524560",
    "end": "526080"
  },
  {
    "text": "github",
    "start": "526080",
    "end": "527519"
  },
  {
    "text": "and then at that point you're going to",
    "start": "527519",
    "end": "528959"
  },
  {
    "text": "connect it to your pipeline",
    "start": "528959",
    "end": "530800"
  },
  {
    "text": "in this case we're going to use kubeflow",
    "start": "530800",
    "end": "532720"
  },
  {
    "text": "pipelines as our ci cd",
    "start": "532720",
    "end": "534560"
  },
  {
    "text": "selection of choice and when github",
    "start": "534560",
    "end": "537760"
  },
  {
    "text": "receives that it's going to begin that",
    "start": "537760",
    "end": "539920"
  },
  {
    "text": "process and so first it's going to use",
    "start": "539920",
    "end": "542160"
  },
  {
    "text": "kale which is a open source tool that",
    "start": "542160",
    "end": "544880"
  },
  {
    "text": "takes a jupiter notebook",
    "start": "544880",
    "end": "546480"
  },
  {
    "text": "and wires it up with your uh pipeline",
    "start": "546480",
    "end": "549839"
  },
  {
    "text": "and you may kick off something like your",
    "start": "549839",
    "end": "551680"
  },
  {
    "text": "feature engineering step",
    "start": "551680",
    "end": "553200"
  },
  {
    "text": "which may call out to actually an",
    "start": "553200",
    "end": "555200"
  },
  {
    "text": "external pipeline such as spark",
    "start": "555200",
    "end": "557920"
  },
  {
    "text": "to run through all your large data",
    "start": "557920",
    "end": "560839"
  },
  {
    "text": "processing",
    "start": "560839",
    "end": "562080"
  },
  {
    "text": "once that's done it's going to hand back",
    "start": "562080",
    "end": "564480"
  },
  {
    "text": "to kubeflow pipelines and continue with",
    "start": "564480",
    "end": "566480"
  },
  {
    "text": "the next step",
    "start": "566480",
    "end": "567519"
  },
  {
    "text": "in this case it'll kick off your",
    "start": "567519",
    "end": "569120"
  },
  {
    "text": "training step and in this case we're",
    "start": "569120",
    "end": "571200"
  },
  {
    "text": "going to use",
    "start": "571200",
    "end": "571920"
  },
  {
    "text": "cube flow as a pipeline itself and so",
    "start": "571920",
    "end": "574320"
  },
  {
    "text": "it's going to call out keep the",
    "start": "574320",
    "end": "575680"
  },
  {
    "text": "pipelines will",
    "start": "575680",
    "end": "576640"
  },
  {
    "text": "to that training step execute and then",
    "start": "576640",
    "end": "579120"
  },
  {
    "text": "hand back when that's done",
    "start": "579120",
    "end": "580720"
  },
  {
    "text": "it'll then go to hyperparameter sweep",
    "start": "580720",
    "end": "582720"
  },
  {
    "text": "where again you're going to reach out to",
    "start": "582720",
    "end": "584240"
  },
  {
    "text": "a q",
    "start": "584240",
    "end": "584560"
  },
  {
    "text": "flow pipeline and in this case it's",
    "start": "584560",
    "end": "586320"
  },
  {
    "text": "going to execute many hundreds of",
    "start": "586320",
    "end": "588560"
  },
  {
    "text": "pipelines simultaneously",
    "start": "588560",
    "end": "590240"
  },
  {
    "text": "to search across the entire grid of",
    "start": "590240",
    "end": "592000"
  },
  {
    "text": "hyperparameters and find the one that is",
    "start": "592000",
    "end": "594399"
  },
  {
    "text": "best suited for your model",
    "start": "594399",
    "end": "596240"
  },
  {
    "text": "once that's done it's also going to hand",
    "start": "596240",
    "end": "598480"
  },
  {
    "text": "back we're going to package that",
    "start": "598480",
    "end": "600560"
  },
  {
    "text": "and hand it off to serving and then from",
    "start": "600560",
    "end": "602720"
  },
  {
    "text": "that point from serving",
    "start": "602720",
    "end": "604399"
  },
  {
    "text": "it's going to be out there for inference",
    "start": "604399",
    "end": "605839"
  },
  {
    "text": "purposes and be able to be used by your",
    "start": "605839",
    "end": "608480"
  },
  {
    "text": "application",
    "start": "608480",
    "end": "610959"
  },
  {
    "text": "this all sits on top of metadata storage",
    "start": "610959",
    "end": "613120"
  },
  {
    "text": "and infrastructure",
    "start": "613120",
    "end": "614800"
  },
  {
    "text": "and you know rather than continuing on",
    "start": "614800",
    "end": "616880"
  },
  {
    "text": "about this let me hand it off",
    "start": "616880",
    "end": "618640"
  },
  {
    "text": "and let janice show a quick demo thanks",
    "start": "618640",
    "end": "621360"
  },
  {
    "text": "david",
    "start": "621360",
    "end": "622240"
  },
  {
    "text": "so david explain the dangers your ml",
    "start": "622240",
    "end": "624720"
  },
  {
    "text": "models face",
    "start": "624720",
    "end": "625600"
  },
  {
    "text": "when they are exposed publicly and",
    "start": "625600",
    "end": "627360"
  },
  {
    "text": "stress the importance of having solid",
    "start": "627360",
    "end": "629279"
  },
  {
    "text": "envelope strategy and a composable",
    "start": "629279",
    "end": "631040"
  },
  {
    "text": "pipeline on which you can iterate",
    "start": "631040",
    "end": "632320"
  },
  {
    "text": "quickly",
    "start": "632320",
    "end": "633120"
  },
  {
    "text": "now let's make this concrete and show",
    "start": "633120",
    "end": "634480"
  },
  {
    "text": "what an emerald powered workflow",
    "start": "634480",
    "end": "636240"
  },
  {
    "text": "actually looks like from the perspective",
    "start": "636240",
    "end": "637920"
  },
  {
    "text": "of a data scientist",
    "start": "637920",
    "end": "639360"
  },
  {
    "text": "in this demo we'll show the steps a data",
    "start": "639360",
    "end": "641279"
  },
  {
    "text": "scientist takes from experimenting",
    "start": "641279",
    "end": "643279"
  },
  {
    "text": "locally in zoopter notebook to running a",
    "start": "643279",
    "end": "645200"
  },
  {
    "text": "single pipeline",
    "start": "645200",
    "end": "646000"
  },
  {
    "text": "generated from that notebook running",
    "start": "646000",
    "end": "647920"
  },
  {
    "text": "hundreds of pipelines for hyper",
    "start": "647920",
    "end": "649360"
  },
  {
    "text": "parameter tuning and then choosing the",
    "start": "649360",
    "end": "650959"
  },
  {
    "text": "best model to serve",
    "start": "650959",
    "end": "652240"
  },
  {
    "text": "in this process erector snapshot store",
    "start": "652240",
    "end": "654320"
  },
  {
    "text": "and ml metadata ensure fully",
    "start": "654320",
    "end": "655920"
  },
  {
    "text": "reproducibility and limits tracking",
    "start": "655920",
    "end": "658000"
  },
  {
    "text": "so let's dive right in so let's pretend",
    "start": "658000",
    "end": "661440"
  },
  {
    "text": "that we are a data scientist and we want",
    "start": "661440",
    "end": "663360"
  },
  {
    "text": "to start working on an exciting new",
    "start": "663360",
    "end": "665120"
  },
  {
    "text": "problem",
    "start": "665120",
    "end": "665920"
  },
  {
    "text": "we open the kepler dashboard go to the",
    "start": "665920",
    "end": "668000"
  },
  {
    "text": "notebooks tab and start a new notebook",
    "start": "668000",
    "end": "670160"
  },
  {
    "text": "server",
    "start": "670160",
    "end": "670720"
  },
  {
    "text": "connect to it and get right to work the",
    "start": "670720",
    "end": "673279"
  },
  {
    "text": "problem we are working on today",
    "start": "673279",
    "end": "674959"
  },
  {
    "text": "is the open vaccine cargo challenge and",
    "start": "674959",
    "end": "677040"
  },
  {
    "text": "we're trying to locate the weak spots of",
    "start": "677040",
    "end": "678720"
  },
  {
    "text": "a messenger rna structure to help create",
    "start": "678720",
    "end": "680640"
  },
  {
    "text": "a stable vaccine",
    "start": "680640",
    "end": "682000"
  },
  {
    "text": "i don't know too much about biology",
    "start": "682000",
    "end": "683519"
  },
  {
    "text": "either so it's okay",
    "start": "683519",
    "end": "685040"
  },
  {
    "text": "we're working for a while and in this",
    "start": "685040",
    "end": "686880"
  },
  {
    "text": "notebook we have prepared all the",
    "start": "686880",
    "end": "688560"
  },
  {
    "text": "necessary steps for",
    "start": "688560",
    "end": "689839"
  },
  {
    "text": "fetching the data pre-processing them",
    "start": "689839",
    "end": "692240"
  },
  {
    "text": "and training a model",
    "start": "692240",
    "end": "694000"
  },
  {
    "text": "now we want to run this whole process as",
    "start": "694000",
    "end": "696880"
  },
  {
    "text": "a reproducible",
    "start": "696880",
    "end": "697920"
  },
  {
    "text": "envelopes pipeline normally we would",
    "start": "697920",
    "end": "700720"
  },
  {
    "text": "have to rewrite our code",
    "start": "700720",
    "end": "702079"
  },
  {
    "text": "to use a specific pipeline dsl however",
    "start": "702079",
    "end": "705839"
  },
  {
    "text": "kl makes the transition from notebook to",
    "start": "705839",
    "end": "707920"
  },
  {
    "text": "pipeline very simple",
    "start": "707920",
    "end": "709600"
  },
  {
    "text": "and let me show you how in the side of",
    "start": "709600",
    "end": "711839"
  },
  {
    "text": "the notebook i open the kill sidebar",
    "start": "711839",
    "end": "714160"
  },
  {
    "text": "and enable as you can see certain colors",
    "start": "714160",
    "end": "717440"
  },
  {
    "text": "appeared around in",
    "start": "717440",
    "end": "718399"
  },
  {
    "text": "cell cells with the same color are part",
    "start": "718399",
    "end": "720880"
  },
  {
    "text": "of the same pipeline step",
    "start": "720880",
    "end": "722720"
  },
  {
    "text": "this information is stored in the",
    "start": "722720",
    "end": "724399"
  },
  {
    "text": "notebook's metadata which is pre-filled",
    "start": "724399",
    "end": "726480"
  },
  {
    "text": "in this case",
    "start": "726480",
    "end": "727279"
  },
  {
    "text": "so we just need to annotate our notebook",
    "start": "727279",
    "end": "729440"
  },
  {
    "text": "cells using kel's intuitive ui",
    "start": "729440",
    "end": "731680"
  },
  {
    "text": "for example we can declare what type of",
    "start": "731680",
    "end": "733600"
  },
  {
    "text": "service is how it's called",
    "start": "733600",
    "end": "736320"
  },
  {
    "text": "and what other cells depends on and",
    "start": "736320",
    "end": "738800"
  },
  {
    "text": "after that we click on compile and run",
    "start": "738800",
    "end": "740959"
  },
  {
    "text": "and kill will parse the notebook create",
    "start": "740959",
    "end": "742880"
  },
  {
    "text": "steps out of cells",
    "start": "742880",
    "end": "744000"
  },
  {
    "text": "detect data dependencies take a snapshot",
    "start": "744000",
    "end": "746320"
  },
  {
    "text": "with rock and finally generate a",
    "start": "746320",
    "end": "747839"
  },
  {
    "text": "pipeline which starts from the notebook",
    "start": "747839",
    "end": "749600"
  },
  {
    "text": "snapshot it state",
    "start": "749600",
    "end": "750720"
  },
  {
    "text": "and submit it to cubeflow pipeline",
    "start": "750720",
    "end": "753760"
  },
  {
    "text": "and as you can see the notebook is",
    "start": "753760",
    "end": "755040"
  },
  {
    "text": "transparently converted to a",
    "start": "755040",
    "end": "756639"
  },
  {
    "text": "reproducible envelopes pipeline",
    "start": "756639",
    "end": "758639"
  },
  {
    "text": "and with a data scientist didn't have to",
    "start": "758639",
    "end": "760639"
  },
  {
    "text": "learn anything new",
    "start": "760639",
    "end": "761839"
  },
  {
    "text": "about pipelines after kill submits the",
    "start": "761839",
    "end": "764320"
  },
  {
    "text": "pipeline it provides us with a link",
    "start": "764320",
    "end": "766480"
  },
  {
    "text": "to the kubeflow dashboard which we can",
    "start": "766480",
    "end": "768399"
  },
  {
    "text": "follow to see the progress of the",
    "start": "768399",
    "end": "770480"
  },
  {
    "text": "pipeline run and",
    "start": "770480",
    "end": "772160"
  },
  {
    "text": "every step of this pipeline that you see",
    "start": "772160",
    "end": "775120"
  },
  {
    "text": "is snapshotting",
    "start": "775120",
    "end": "776000"
  },
  {
    "text": "by rock and these steps input and output",
    "start": "776000",
    "end": "779040"
  },
  {
    "text": "artifacts",
    "start": "779040",
    "end": "779920"
  },
  {
    "text": "are tracked by ml metadata so for every",
    "start": "779920",
    "end": "782160"
  },
  {
    "text": "step you can see",
    "start": "782160",
    "end": "783279"
  },
  {
    "text": "logs and also emblemata metadata which",
    "start": "783279",
    "end": "786000"
  },
  {
    "text": "records the input",
    "start": "786000",
    "end": "787519"
  },
  {
    "text": "and output artifacts of each step in",
    "start": "787519",
    "end": "790160"
  },
  {
    "text": "this case they are",
    "start": "790160",
    "end": "791680"
  },
  {
    "text": "a rock snapshot which we can actually",
    "start": "791680",
    "end": "794480"
  },
  {
    "text": "follow",
    "start": "794480",
    "end": "795120"
  },
  {
    "text": "and see the snapshot in the rob ui",
    "start": "795120",
    "end": "799440"
  },
  {
    "text": "now we have a reproducible envelope's",
    "start": "799440",
    "end": "802079"
  },
  {
    "text": "pipeline generated automatically from",
    "start": "802079",
    "end": "803839"
  },
  {
    "text": "our notebook",
    "start": "803839",
    "end": "804720"
  },
  {
    "text": "however this pipeline only trains our",
    "start": "804720",
    "end": "806320"
  },
  {
    "text": "model for a specific set of parameters",
    "start": "806320",
    "end": "808480"
  },
  {
    "text": "like learning great or bad size tweaking",
    "start": "808480",
    "end": "810639"
  },
  {
    "text": "those parameters can result in a vastly",
    "start": "810639",
    "end": "812480"
  },
  {
    "text": "improved model",
    "start": "812480",
    "end": "813360"
  },
  {
    "text": "so we want to explore more",
    "start": "813360",
    "end": "814399"
  },
  {
    "text": "configurations this procedure is called",
    "start": "814399",
    "end": "816720"
  },
  {
    "text": "hyperparameter tuning and kell provides",
    "start": "816720",
    "end": "818800"
  },
  {
    "text": "an intuitive ui for enabling it",
    "start": "818800",
    "end": "820720"
  },
  {
    "text": "to perform hyper parameter tuning we",
    "start": "820720",
    "end": "822480"
  },
  {
    "text": "need three things",
    "start": "822480",
    "end": "823920"
  },
  {
    "text": "first we need to define what the hyper",
    "start": "823920",
    "end": "825680"
  },
  {
    "text": "parameters are in this case our copper",
    "start": "825680",
    "end": "827760"
  },
  {
    "text": "parameters are epochs bad size etc and k",
    "start": "827760",
    "end": "830320"
  },
  {
    "text": "provides us with a special cell called",
    "start": "830320",
    "end": "832480"
  },
  {
    "text": "pipeline parameters",
    "start": "832480",
    "end": "833839"
  },
  {
    "text": "to declare a hyper parameter our",
    "start": "833839",
    "end": "836639"
  },
  {
    "text": "parameters for hyperparameter tuning",
    "start": "836639",
    "end": "839199"
  },
  {
    "text": "then we need some metric to guide our",
    "start": "839199",
    "end": "842399"
  },
  {
    "text": "search",
    "start": "842399",
    "end": "843199"
  },
  {
    "text": "the metric shows if our model is",
    "start": "843199",
    "end": "845279"
  },
  {
    "text": "actually performing better or worse with",
    "start": "845279",
    "end": "847440"
  },
  {
    "text": "its new",
    "start": "847440",
    "end": "848160"
  },
  {
    "text": "parameter configuration so in this case",
    "start": "848160",
    "end": "850880"
  },
  {
    "text": "we use the validation nodes as the",
    "start": "850880",
    "end": "852639"
  },
  {
    "text": "metric guiding the hyperparameter tuning",
    "start": "852639",
    "end": "854880"
  },
  {
    "text": "to declare our metric we simply print it",
    "start": "854880",
    "end": "857360"
  },
  {
    "text": "and declare the cell",
    "start": "857360",
    "end": "858560"
  },
  {
    "text": "as a pipeline metric in case and finally",
    "start": "858560",
    "end": "862079"
  },
  {
    "text": "we enable let's be tuning in gain and",
    "start": "862079",
    "end": "864560"
  },
  {
    "text": "specify",
    "start": "864560",
    "end": "865680"
  },
  {
    "text": "our cells algorithm and hyperparameter",
    "start": "865680",
    "end": "868839"
  },
  {
    "text": "settings so for example the batch size",
    "start": "868839",
    "end": "871040"
  },
  {
    "text": "can be between",
    "start": "871040",
    "end": "871920"
  },
  {
    "text": "32 and 256 in increments of 32. in this",
    "start": "871920",
    "end": "875199"
  },
  {
    "text": "case the settings are pre-filled so we",
    "start": "875199",
    "end": "877040"
  },
  {
    "text": "can start the tuning",
    "start": "877040",
    "end": "878079"
  },
  {
    "text": "right away scale as you can see provides",
    "start": "878079",
    "end": "881199"
  },
  {
    "text": "a pretty intuitive form to do this",
    "start": "881199",
    "end": "883600"
  },
  {
    "text": "configuration in a ui driven way",
    "start": "883600",
    "end": "886160"
  },
  {
    "text": "after defining the parameters the metric",
    "start": "886160",
    "end": "888160"
  },
  {
    "text": "and the cells algorithm",
    "start": "888160",
    "end": "889360"
  },
  {
    "text": "we are ready to start our hyperparameter",
    "start": "889360",
    "end": "891600"
  },
  {
    "text": "tuning by pressing the button of the",
    "start": "891600",
    "end": "893199"
  },
  {
    "text": "kell sidebar",
    "start": "893199",
    "end": "894560"
  },
  {
    "text": "to perform the hyper parameter tuning",
    "start": "894560",
    "end": "897120"
  },
  {
    "text": "kell uses cardiff a tube flow component",
    "start": "897120",
    "end": "899839"
  },
  {
    "text": "health will start a cutting experiment",
    "start": "899839",
    "end": "901760"
  },
  {
    "text": "which will create a trial for each",
    "start": "901760",
    "end": "903519"
  },
  {
    "text": "different set",
    "start": "903519",
    "end": "904240"
  },
  {
    "text": "of hyperparameter values we have",
    "start": "904240",
    "end": "906399"
  },
  {
    "text": "implemented a sim",
    "start": "906399",
    "end": "907760"
  },
  {
    "text": "so that each cut of trial results in the",
    "start": "907760",
    "end": "910399"
  },
  {
    "text": "kfp pipeline run",
    "start": "910399",
    "end": "912079"
  },
  {
    "text": "once we click the kill button kiel will",
    "start": "912079",
    "end": "914240"
  },
  {
    "text": "use car tip to spin up many instances of",
    "start": "914240",
    "end": "916399"
  },
  {
    "text": "the pipeline",
    "start": "916399",
    "end": "917120"
  },
  {
    "text": "creating the first demo but with",
    "start": "917120",
    "end": "918560"
  },
  {
    "text": "different parameters and as you can see",
    "start": "918560",
    "end": "920560"
  },
  {
    "text": "kyle",
    "start": "920560",
    "end": "920959"
  },
  {
    "text": "kale also presented with links to follow",
    "start": "920959",
    "end": "922959"
  },
  {
    "text": "the progress of a hyper-parameter tunic",
    "start": "922959",
    "end": "925279"
  },
  {
    "text": "now because the hyperparameter tuning",
    "start": "925279",
    "end": "926959"
  },
  {
    "text": "will take a while we have prepared the",
    "start": "926959",
    "end": "928800"
  },
  {
    "text": "results of this tuning beforehand",
    "start": "928800",
    "end": "930880"
  },
  {
    "text": "so we can see the category experiment",
    "start": "930880",
    "end": "932240"
  },
  {
    "text": "with all the created variables so far in",
    "start": "932240",
    "end": "933759"
  },
  {
    "text": "the graph showing all the hyperparameter",
    "start": "933759",
    "end": "935279"
  },
  {
    "text": "configuration in their success metric in",
    "start": "935279",
    "end": "936959"
  },
  {
    "text": "an intuitive way",
    "start": "936959",
    "end": "938079"
  },
  {
    "text": "we can also find the best trial so far",
    "start": "938079",
    "end": "939920"
  },
  {
    "text": "as the ui will highlight it for us",
    "start": "939920",
    "end": "941600"
  },
  {
    "text": "and from a catholic trial we can",
    "start": "941600",
    "end": "942720"
  },
  {
    "text": "navigate to the kfp pipeline run it",
    "start": "942720",
    "end": "944639"
  },
  {
    "text": "corresponds to by clicking the small",
    "start": "944639",
    "end": "946480"
  },
  {
    "text": "pipeline button",
    "start": "946480",
    "end": "947519"
  },
  {
    "text": "next to the trial so",
    "start": "947519",
    "end": "950639"
  },
  {
    "text": "once we click this button and go to the",
    "start": "950639",
    "end": "952560"
  },
  {
    "text": "pipeline run",
    "start": "952560",
    "end": "953839"
  },
  {
    "text": "notice how many steps have to click",
    "start": "953839",
    "end": "955360"
  },
  {
    "text": "recycle icon on them",
    "start": "955360",
    "end": "956880"
  },
  {
    "text": "this icon means that these steps were",
    "start": "956880",
    "end": "958560"
  },
  {
    "text": "cast to massively speed up the execution",
    "start": "958560",
    "end": "960639"
  },
  {
    "text": "time of a pipeline run",
    "start": "960639",
    "end": "962160"
  },
  {
    "text": "caching is part by rectus rock by taking",
    "start": "962160",
    "end": "964399"
  },
  {
    "text": "snapshots at the end and start of its",
    "start": "964399",
    "end": "966639"
  },
  {
    "text": "step",
    "start": "966639",
    "end": "967360"
  },
  {
    "text": "we can also investigate we can also",
    "start": "967360",
    "end": "969199"
  },
  {
    "text": "navigate from a pipeline run to the",
    "start": "969199",
    "end": "971279"
  },
  {
    "text": "cutting",
    "start": "971279",
    "end": "971759"
  },
  {
    "text": "experiment it belongs to so we started",
    "start": "971759",
    "end": "974399"
  },
  {
    "text": "from a notebook and created the pipeline",
    "start": "974399",
    "end": "976560"
  },
  {
    "text": "then we run many pipelines in order to",
    "start": "976560",
    "end": "978399"
  },
  {
    "text": "perform hyper parameter tuning and get",
    "start": "978399",
    "end": "980079"
  },
  {
    "text": "the best model",
    "start": "980079",
    "end": "981120"
  },
  {
    "text": "after running the hyper parameter tuning",
    "start": "981120",
    "end": "983360"
  },
  {
    "text": "we have found the best combination of",
    "start": "983360",
    "end": "984720"
  },
  {
    "text": "hyper parameters for our model and now",
    "start": "984720",
    "end": "986399"
  },
  {
    "text": "we need to restore and serve that model",
    "start": "986399",
    "end": "988399"
  },
  {
    "text": "we can find the best combination by",
    "start": "988399",
    "end": "989920"
  },
  {
    "text": "going to the category it will be",
    "start": "989920",
    "end": "991360"
  },
  {
    "text": "highlighted for us",
    "start": "991360",
    "end": "992560"
  },
  {
    "text": "from the trial we can easily navigate to",
    "start": "992560",
    "end": "994800"
  },
  {
    "text": "the corresponding pipeline run",
    "start": "994800",
    "end": "996320"
  },
  {
    "text": "as we saw earlier by clicking the little",
    "start": "996320",
    "end": "998160"
  },
  {
    "text": "pipeline button now we are going to use",
    "start": "998160",
    "end": "1000320"
  },
  {
    "text": "the snapshotting power of rogue",
    "start": "1000320",
    "end": "1001759"
  },
  {
    "text": "restore the first version of our model",
    "start": "1001759",
    "end": "1003360"
  },
  {
    "text": "in the notebook to do that we will go to",
    "start": "1003360",
    "end": "1005279"
  },
  {
    "text": "the last step of our best pipeline run",
    "start": "1005279",
    "end": "1007440"
  },
  {
    "text": "and locate the rocksnap.url",
    "start": "1007440",
    "end": "1009120"
  },
  {
    "text": "which is found under the visualization",
    "start": "1009120",
    "end": "1010800"
  },
  {
    "text": "tab we copy the rock url",
    "start": "1010800",
    "end": "1013040"
  },
  {
    "text": "and use it to restore a new notebook to",
    "start": "1013040",
    "end": "1016160"
  },
  {
    "text": "the state",
    "start": "1016160",
    "end": "1017199"
  },
  {
    "text": "of the pipeline run at that specific",
    "start": "1017199",
    "end": "1019279"
  },
  {
    "text": "step",
    "start": "1019279",
    "end": "1020720"
  },
  {
    "text": "so we copy the code of url go to the",
    "start": "1020720",
    "end": "1022720"
  },
  {
    "text": "notebook ui paste it",
    "start": "1022720",
    "end": "1025120"
  },
  {
    "text": "and restore it once the notebook is",
    "start": "1025120",
    "end": "1027839"
  },
  {
    "text": "ready",
    "start": "1027839",
    "end": "1029120"
  },
  {
    "text": "we connect to it and as you will see",
    "start": "1029120",
    "end": "1031520"
  },
  {
    "text": "kelly recognizes",
    "start": "1031520",
    "end": "1032798"
  },
  {
    "text": "that it is restored from a snapshot and",
    "start": "1032799",
    "end": "1034720"
  },
  {
    "text": "uses a pop-up to point us to the last",
    "start": "1034720",
    "end": "1036640"
  },
  {
    "text": "cell that was running",
    "start": "1036640",
    "end": "1038400"
  },
  {
    "text": "our best model is saved in the model",
    "start": "1038400",
    "end": "1041280"
  },
  {
    "text": "variable",
    "start": "1041280",
    "end": "1042558"
  },
  {
    "text": "which we will print to show that it is",
    "start": "1042559",
    "end": "1046000"
  },
  {
    "text": "in memory",
    "start": "1046000",
    "end": "1047600"
  },
  {
    "text": "we want to take this model and serve it",
    "start": "1047600",
    "end": "1050080"
  },
  {
    "text": "to do that we will use the kl sdk which",
    "start": "1050080",
    "end": "1052480"
  },
  {
    "text": "is part by kf serving underneath",
    "start": "1052480",
    "end": "1054559"
  },
  {
    "text": "the function for serving is called serve",
    "start": "1054559",
    "end": "1056720"
  },
  {
    "text": "and needs a model as input",
    "start": "1056720",
    "end": "1058240"
  },
  {
    "text": "in this case we also use a function to",
    "start": "1058240",
    "end": "1059919"
  },
  {
    "text": "process data before passing them to the",
    "start": "1059919",
    "end": "1061760"
  },
  {
    "text": "predictor",
    "start": "1061760",
    "end": "1063280"
  },
  {
    "text": "once we run serve kale will snapshot the",
    "start": "1063280",
    "end": "1065919"
  },
  {
    "text": "notebook",
    "start": "1065919",
    "end": "1067440"
  },
  {
    "text": "and use it to serve the model in the",
    "start": "1067440",
    "end": "1069440"
  },
  {
    "text": "same immutable environment",
    "start": "1069440",
    "end": "1071600"
  },
  {
    "text": "once this process completes let's make",
    "start": "1071600",
    "end": "1073760"
  },
  {
    "text": "some prediction",
    "start": "1073760",
    "end": "1074799"
  },
  {
    "text": "we first define some json data as input",
    "start": "1074799",
    "end": "1078240"
  },
  {
    "text": "and then send it to the server with cave",
    "start": "1078240",
    "end": "1080000"
  },
  {
    "text": "server.dig",
    "start": "1080000",
    "end": "1082080"
  },
  {
    "text": "the kf server object wraps the whole",
    "start": "1082080",
    "end": "1083679"
  },
  {
    "text": "procedure of calling the model server",
    "start": "1083679",
    "end": "1085440"
  },
  {
    "text": "with http or grpc and we immediately get",
    "start": "1085440",
    "end": "1087840"
  },
  {
    "text": "a result back",
    "start": "1087840",
    "end": "1089840"
  },
  {
    "text": "we can also print the key server",
    "start": "1089840",
    "end": "1091600"
  },
  {
    "text": "variably to get information about the",
    "start": "1091600",
    "end": "1093440"
  },
  {
    "text": "model server",
    "start": "1093440",
    "end": "1094400"
  },
  {
    "text": "and follow the link to get to the model",
    "start": "1094400",
    "end": "1097679"
  },
  {
    "text": "ui",
    "start": "1097679",
    "end": "1098320"
  },
  {
    "text": "the model ui is super useful for listing",
    "start": "1098320",
    "end": "1100160"
  },
  {
    "text": "monitoring and buying your model servers",
    "start": "1100160",
    "end": "1102240"
  },
  {
    "text": "you can see the state of the server you",
    "start": "1102240",
    "end": "1103679"
  },
  {
    "text": "can see metrics from grafana",
    "start": "1103679",
    "end": "1105760"
  },
  {
    "text": "you can also see logs from the model",
    "start": "1105760",
    "end": "1109120"
  },
  {
    "text": "servers",
    "start": "1109120",
    "end": "1109840"
  },
  {
    "text": "pods like the predictor of the",
    "start": "1109840",
    "end": "1111679"
  },
  {
    "text": "transformer which performs the",
    "start": "1111679",
    "end": "1113280"
  },
  {
    "text": "processing and you can also see the",
    "start": "1113280",
    "end": "1115200"
  },
  {
    "text": "configuration",
    "start": "1115200",
    "end": "1117200"
  },
  {
    "text": "of the model server so all in all we saw",
    "start": "1117200",
    "end": "1119440"
  },
  {
    "text": "an envelopes part workflow where we went",
    "start": "1119440",
    "end": "1121360"
  },
  {
    "text": "from experimenting inside a notebook",
    "start": "1121360",
    "end": "1123039"
  },
  {
    "text": "to generating a produce full pipeline",
    "start": "1123039",
    "end": "1125039"
  },
  {
    "text": "then we performed hyperparameter tuning",
    "start": "1125039",
    "end": "1127200"
  },
  {
    "text": "by running the",
    "start": "1127200",
    "end": "1128000"
  },
  {
    "text": "pipeline we generated before multiple",
    "start": "1128000",
    "end": "1130880"
  },
  {
    "text": "times with different parameters",
    "start": "1130880",
    "end": "1132480"
  },
  {
    "text": "and finally we used rogue's snapshotting",
    "start": "1132480",
    "end": "1134720"
  },
  {
    "text": "power to restore the best model and",
    "start": "1134720",
    "end": "1136480"
  },
  {
    "text": "easily serve it using",
    "start": "1136480",
    "end": "1137679"
  },
  {
    "text": "scale and kf serving so thank you so",
    "start": "1137679",
    "end": "1140880"
  },
  {
    "text": "much giannis",
    "start": "1140880",
    "end": "1142080"
  },
  {
    "text": "i think you can see how powerful an ml",
    "start": "1142080",
    "end": "1144880"
  },
  {
    "text": "ops pipeline is",
    "start": "1144880",
    "end": "1146320"
  },
  {
    "text": "and how much flexibility it gives you",
    "start": "1146320",
    "end": "1148240"
  },
  {
    "text": "not just to move from a notebook which",
    "start": "1148240",
    "end": "1150640"
  },
  {
    "text": "is the lingua franca of where people are",
    "start": "1150640",
    "end": "1152480"
  },
  {
    "text": "doing their coding",
    "start": "1152480",
    "end": "1153520"
  },
  {
    "text": "around models today but bring that into",
    "start": "1153520",
    "end": "1156080"
  },
  {
    "text": "a very rich very sophisticated pipeline",
    "start": "1156080",
    "end": "1158160"
  },
  {
    "text": "that includes things like hyper",
    "start": "1158160",
    "end": "1159440"
  },
  {
    "text": "parameter suites",
    "start": "1159440",
    "end": "1160640"
  },
  {
    "text": "and automatic roll out to production we",
    "start": "1160640",
    "end": "1163440"
  },
  {
    "text": "touched on the first",
    "start": "1163440",
    "end": "1164400"
  },
  {
    "text": "attack uh that ml ops helps you defend",
    "start": "1164400",
    "end": "1166960"
  },
  {
    "text": "against",
    "start": "1166960",
    "end": "1167600"
  },
  {
    "text": "let's get into the second in this case",
    "start": "1167600",
    "end": "1169440"
  },
  {
    "text": "where your model or where your attacker",
    "start": "1169440",
    "end": "1171760"
  },
  {
    "text": "tries to take your model now",
    "start": "1171760",
    "end": "1174880"
  },
  {
    "text": "this is a situation in which a malicious",
    "start": "1174880",
    "end": "1177600"
  },
  {
    "text": "attacker is going to try and probe your",
    "start": "1177600",
    "end": "1179679"
  },
  {
    "text": "model many many times",
    "start": "1179679",
    "end": "1181280"
  },
  {
    "text": "to get an underlying example of what",
    "start": "1181280",
    "end": "1183440"
  },
  {
    "text": "that model is actually doing",
    "start": "1183440",
    "end": "1185360"
  },
  {
    "text": "their goal may not be complete accuracy",
    "start": "1185360",
    "end": "1188080"
  },
  {
    "text": "but as long as they can get close",
    "start": "1188080",
    "end": "1189840"
  },
  {
    "text": "they can start to use your model in",
    "start": "1189840",
    "end": "1191520"
  },
  {
    "text": "really malicious ways and these are",
    "start": "1191520",
    "end": "1193360"
  },
  {
    "text": "really hard to defend against",
    "start": "1193360",
    "end": "1194880"
  },
  {
    "text": "so having a great ml ops pipeline is",
    "start": "1194880",
    "end": "1197840"
  },
  {
    "text": "critical",
    "start": "1197840",
    "end": "1199120"
  },
  {
    "text": "the two types of attacks i'm going to",
    "start": "1199120",
    "end": "1200480"
  },
  {
    "text": "walk down are a distillation attack",
    "start": "1200480",
    "end": "1202720"
  },
  {
    "text": "where they're pulling things around",
    "start": "1202720",
    "end": "1204240"
  },
  {
    "text": "object detection and other things like",
    "start": "1204240",
    "end": "1205679"
  },
  {
    "text": "that",
    "start": "1205679",
    "end": "1206240"
  },
  {
    "text": "and the second is model extraction which",
    "start": "1206240",
    "end": "1208080"
  },
  {
    "text": "is more focused on transformers",
    "start": "1208080",
    "end": "1209919"
  },
  {
    "text": "and language so a distillation attack",
    "start": "1209919",
    "end": "1213440"
  },
  {
    "text": "the first you start with a black box",
    "start": "1213440",
    "end": "1215520"
  },
  {
    "text": "model like you have here on the left",
    "start": "1215520",
    "end": "1217280"
  },
  {
    "text": "and i'm just going to begin to probe",
    "start": "1217280",
    "end": "1219200"
  },
  {
    "text": "that using sample",
    "start": "1219200",
    "end": "1220480"
  },
  {
    "text": "examples uh i don't know what's inside",
    "start": "1220480",
    "end": "1223280"
  },
  {
    "text": "that model but i do have",
    "start": "1223280",
    "end": "1224799"
  },
  {
    "text": "access to the api so i'm going to start",
    "start": "1224799",
    "end": "1226559"
  },
  {
    "text": "with a heart and that fails",
    "start": "1226559",
    "end": "1228559"
  },
  {
    "text": "then i present a pentagon and it passes",
    "start": "1228559",
    "end": "1231440"
  },
  {
    "text": "and then i decided to",
    "start": "1231440",
    "end": "1232880"
  },
  {
    "text": "pick a whole bunch of widely arrayed",
    "start": "1232880",
    "end": "1235039"
  },
  {
    "text": "examples to probe against and so now i",
    "start": "1235039",
    "end": "1237520"
  },
  {
    "text": "do a whole bunch of different ones",
    "start": "1237520",
    "end": "1238960"
  },
  {
    "text": "and i begin to get a better look at it",
    "start": "1238960",
    "end": "1241280"
  },
  {
    "text": "and then i present a lot of models",
    "start": "1241280",
    "end": "1244000"
  },
  {
    "text": "anyone want to guess what kind of",
    "start": "1244000",
    "end": "1245520"
  },
  {
    "text": "detector this is",
    "start": "1245520",
    "end": "1247360"
  },
  {
    "text": "it's of course a neenah simone detector",
    "start": "1247360",
    "end": "1249760"
  },
  {
    "text": "no of course not it is",
    "start": "1249760",
    "end": "1251039"
  },
  {
    "text": "in fact a triangle detector and",
    "start": "1251039",
    "end": "1254159"
  },
  {
    "text": "from this from all these many examples",
    "start": "1254159",
    "end": "1256080"
  },
  {
    "text": "i'm able to get a really good",
    "start": "1256080",
    "end": "1257360"
  },
  {
    "text": "understanding of what passes and what",
    "start": "1257360",
    "end": "1259200"
  },
  {
    "text": "doesn't",
    "start": "1259200",
    "end": "1259760"
  },
  {
    "text": "for this particular black box model now",
    "start": "1259760",
    "end": "1262799"
  },
  {
    "text": "with that",
    "start": "1262799",
    "end": "1263679"
  },
  {
    "text": "i'm able to pull that out and recreate",
    "start": "1263679",
    "end": "1266240"
  },
  {
    "text": "the underlying model",
    "start": "1266240",
    "end": "1267520"
  },
  {
    "text": "using just those examples and now i can",
    "start": "1267520",
    "end": "1270159"
  },
  {
    "text": "present that model",
    "start": "1270159",
    "end": "1271360"
  },
  {
    "text": "to my audience and they never have to go",
    "start": "1271360",
    "end": "1273840"
  },
  {
    "text": "back to that original",
    "start": "1273840",
    "end": "1274960"
  },
  {
    "text": "author model's author which obviously is",
    "start": "1274960",
    "end": "1277280"
  },
  {
    "text": "a real pain",
    "start": "1277280",
    "end": "1278799"
  },
  {
    "text": "now the issue here is what how accurate",
    "start": "1278799",
    "end": "1281520"
  },
  {
    "text": "can i get",
    "start": "1281520",
    "end": "1282720"
  },
  {
    "text": "um you know what does it take to get to",
    "start": "1282720",
    "end": "1284799"
  },
  {
    "text": "99 accuracy",
    "start": "1284799",
    "end": "1286799"
  },
  {
    "text": "and thanks to a number of researchers",
    "start": "1286799",
    "end": "1288880"
  },
  {
    "text": "they were able to find that the number",
    "start": "1288880",
    "end": "1290400"
  },
  {
    "text": "of queries is actually",
    "start": "1290400",
    "end": "1291679"
  },
  {
    "text": "very very small for both of these they",
    "start": "1291679",
    "end": "1294080"
  },
  {
    "text": "were able to reproduce the model in",
    "start": "1294080",
    "end": "1295760"
  },
  {
    "text": "under",
    "start": "1295760",
    "end": "1296240"
  },
  {
    "text": "5 000 total queries which is about two",
    "start": "1296240",
    "end": "1298799"
  },
  {
    "text": "queries a minute",
    "start": "1298799",
    "end": "1299919"
  },
  {
    "text": "over two days it's really not a lot",
    "start": "1299919",
    "end": "1304960"
  },
  {
    "text": "so now let's get into a model extraction",
    "start": "1304960",
    "end": "1307039"
  },
  {
    "text": "attack where we're actually going to",
    "start": "1307039",
    "end": "1308159"
  },
  {
    "text": "take that nlp model",
    "start": "1308159",
    "end": "1309919"
  },
  {
    "text": "uh based on transformers and so on",
    "start": "1309919",
    "end": "1313440"
  },
  {
    "text": "in this case burnt came out somewhat",
    "start": "1313440",
    "end": "1315600"
  },
  {
    "text": "recently from google it really",
    "start": "1315600",
    "end": "1317280"
  },
  {
    "text": "transformed the way that people do",
    "start": "1317280",
    "end": "1318960"
  },
  {
    "text": "language models uh in introducing the",
    "start": "1318960",
    "end": "1322000"
  },
  {
    "text": "brand new transformer architecture at",
    "start": "1322000",
    "end": "1323760"
  },
  {
    "text": "the time",
    "start": "1323760",
    "end": "1324640"
  },
  {
    "text": "and most models that you'll see today",
    "start": "1324640",
    "end": "1326559"
  },
  {
    "text": "including ones like on azure",
    "start": "1326559",
    "end": "1328320"
  },
  {
    "text": "are based on some derivation of this",
    "start": "1328320",
    "end": "1330640"
  },
  {
    "text": "original transformer architecture",
    "start": "1330640",
    "end": "1332480"
  },
  {
    "text": "so you have a lot of surface area for",
    "start": "1332480",
    "end": "1334400"
  },
  {
    "text": "under attack here",
    "start": "1334400",
    "end": "1336320"
  },
  {
    "text": "the way these work is you present a",
    "start": "1336320",
    "end": "1338880"
  },
  {
    "text": "large corpus of data to the model to",
    "start": "1338880",
    "end": "1340559"
  },
  {
    "text": "train on",
    "start": "1340559",
    "end": "1341440"
  },
  {
    "text": "and from that point then you ask a",
    "start": "1341440",
    "end": "1343679"
  },
  {
    "text": "question of that underlying data",
    "start": "1343679",
    "end": "1346080"
  },
  {
    "text": "and it will do its best to give you a",
    "start": "1346080",
    "end": "1348000"
  },
  {
    "text": "response in this case how many",
    "start": "1348000",
    "end": "1349600"
  },
  {
    "text": "instruments did prince play",
    "start": "1349600",
    "end": "1351120"
  },
  {
    "text": "that comes from the corpus and in this",
    "start": "1351120",
    "end": "1352799"
  },
  {
    "text": "case the answer is 27",
    "start": "1352799",
    "end": "1354240"
  },
  {
    "text": "and you can see how sophisticated it is",
    "start": "1354240",
    "end": "1355919"
  },
  {
    "text": "there are a number of different places",
    "start": "1355919",
    "end": "1357360"
  },
  {
    "text": "in the text where it describes",
    "start": "1357360",
    "end": "1358720"
  },
  {
    "text": "instruments",
    "start": "1358720",
    "end": "1359600"
  },
  {
    "text": "the actual sentence where it says 27",
    "start": "1359600",
    "end": "1361760"
  },
  {
    "text": "instruments is split",
    "start": "1361760",
    "end": "1363280"
  },
  {
    "text": "by a participle and then you have down",
    "start": "1363280",
    "end": "1366400"
  },
  {
    "text": "below",
    "start": "1366400",
    "end": "1367360"
  },
  {
    "text": "different types of instruments and",
    "start": "1367360",
    "end": "1368640"
  },
  {
    "text": "classes of instruments so these models",
    "start": "1368640",
    "end": "1370480"
  },
  {
    "text": "are quite sophisticated",
    "start": "1370480",
    "end": "1371760"
  },
  {
    "text": "and very impressive in order to attack",
    "start": "1371760",
    "end": "1375600"
  },
  {
    "text": "these models you have these researchers",
    "start": "1375600",
    "end": "1377280"
  },
  {
    "text": "from google who have done some really",
    "start": "1377280",
    "end": "1378880"
  },
  {
    "text": "interesting stuff here",
    "start": "1378880",
    "end": "1380960"
  },
  {
    "text": "what they've done is they've looked at",
    "start": "1380960",
    "end": "1382799"
  },
  {
    "text": "the underlying model and decided that",
    "start": "1382799",
    "end": "1384799"
  },
  {
    "text": "simply by presenting either random words",
    "start": "1384799",
    "end": "1387280"
  },
  {
    "text": "or words from the corpus",
    "start": "1387280",
    "end": "1389120"
  },
  {
    "text": "you're able to get a really accurate",
    "start": "1389120",
    "end": "1390720"
  },
  {
    "text": "representation of what the model is",
    "start": "1390720",
    "end": "1392240"
  },
  {
    "text": "looking for",
    "start": "1392240",
    "end": "1392960"
  },
  {
    "text": "in this case here's what the random",
    "start": "1392960",
    "end": "1394400"
  },
  {
    "text": "looks like just obviously random words",
    "start": "1394400",
    "end": "1396640"
  },
  {
    "text": "from uh",
    "start": "1396640",
    "end": "1397360"
  },
  {
    "text": "you know any dictionary in the world or",
    "start": "1397360",
    "end": "1399440"
  },
  {
    "text": "the corpus itself",
    "start": "1399440",
    "end": "1401200"
  },
  {
    "text": "or you if you know what the underlying",
    "start": "1401200",
    "end": "1403280"
  },
  {
    "text": "corpus is which in this case comes from",
    "start": "1403280",
    "end": "1404960"
  },
  {
    "text": "wikipedia",
    "start": "1404960",
    "end": "1405919"
  },
  {
    "text": "you're able to present more structured",
    "start": "1405919",
    "end": "1408240"
  },
  {
    "text": "questions about it",
    "start": "1408240",
    "end": "1409440"
  },
  {
    "text": "uh in this case words from the actual um",
    "start": "1409440",
    "end": "1412799"
  },
  {
    "text": "block of text or the corpus that it was",
    "start": "1412799",
    "end": "1414720"
  },
  {
    "text": "trained on and in each case the model is",
    "start": "1414720",
    "end": "1417120"
  },
  {
    "text": "doing its best to give you a response it",
    "start": "1417120",
    "end": "1419120"
  },
  {
    "text": "doesn't really know",
    "start": "1419120",
    "end": "1420480"
  },
  {
    "text": "but it's going to pull things out of",
    "start": "1420480",
    "end": "1422000"
  },
  {
    "text": "that corpus and be able to present it to",
    "start": "1422000",
    "end": "1423840"
  },
  {
    "text": "the user",
    "start": "1423840",
    "end": "1424720"
  },
  {
    "text": "as a potential answer now once you've",
    "start": "1424720",
    "end": "1427360"
  },
  {
    "text": "done that you're able to start probing",
    "start": "1427360",
    "end": "1429360"
  },
  {
    "text": "that model",
    "start": "1429360",
    "end": "1430000"
  },
  {
    "text": "many many times and with just one tenth",
    "start": "1430000",
    "end": "1432720"
  },
  {
    "text": "the total number of queries",
    "start": "1432720",
    "end": "1434159"
  },
  {
    "text": "you're able to get to 72 accuracy",
    "start": "1434159",
    "end": "1436799"
  },
  {
    "text": "according to the model",
    "start": "1436799",
    "end": "1438080"
  },
  {
    "text": "uh and if you were able to do the exact",
    "start": "1438080",
    "end": "1441039"
  },
  {
    "text": "same number of questions",
    "start": "1441039",
    "end": "1442640"
  },
  {
    "text": "you're able to get to 86 which is really",
    "start": "1442640",
    "end": "1445279"
  },
  {
    "text": "good",
    "start": "1445279",
    "end": "1445760"
  },
  {
    "text": "and certainly the basis for doing a lot",
    "start": "1445760",
    "end": "1447520"
  },
  {
    "text": "of work and it's much much less than the",
    "start": "1447520",
    "end": "1450080"
  },
  {
    "text": "millions of dollars that it's often",
    "start": "1450080",
    "end": "1451600"
  },
  {
    "text": "required to train that model in the",
    "start": "1451600",
    "end": "1453360"
  },
  {
    "text": "first place",
    "start": "1453360",
    "end": "1455039"
  },
  {
    "text": "so to use ml ops to defend you can do",
    "start": "1455039",
    "end": "1457840"
  },
  {
    "text": "your best you can try and focus on",
    "start": "1457840",
    "end": "1459600"
  },
  {
    "text": "endpoints and",
    "start": "1459600",
    "end": "1460720"
  },
  {
    "text": "securing the api watermarking but the",
    "start": "1460720",
    "end": "1463279"
  },
  {
    "text": "real value here",
    "start": "1463279",
    "end": "1464320"
  },
  {
    "text": "is going to be in the pipeline your",
    "start": "1464320",
    "end": "1465760"
  },
  {
    "text": "ability to retrain to train for domains",
    "start": "1465760",
    "end": "1468080"
  },
  {
    "text": "to fix things over time",
    "start": "1468080",
    "end": "1469840"
  },
  {
    "text": "that's going to be where the value is so",
    "start": "1469840",
    "end": "1472159"
  },
  {
    "text": "really you should treat your model",
    "start": "1472159",
    "end": "1473679"
  },
  {
    "text": "security",
    "start": "1473679",
    "end": "1474640"
  },
  {
    "text": "like anything else where if you're",
    "start": "1474640",
    "end": "1476320"
  },
  {
    "text": "exposing it to the world it will be",
    "start": "1476320",
    "end": "1478159"
  },
  {
    "text": "attacked",
    "start": "1478159",
    "end": "1478960"
  },
  {
    "text": "and what's most important is how quickly",
    "start": "1478960",
    "end": "1481520"
  },
  {
    "text": "you can update and iterate and detect",
    "start": "1481520",
    "end": "1483679"
  },
  {
    "text": "those",
    "start": "1483679",
    "end": "1484080"
  },
  {
    "text": "attacks and make changes quickly",
    "start": "1484080",
    "end": "1487360"
  },
  {
    "text": "in shorthand i would spend the majority",
    "start": "1487360",
    "end": "1489760"
  },
  {
    "text": "of your engineering time on the left",
    "start": "1489760",
    "end": "1491360"
  },
  {
    "text": "hand side",
    "start": "1491360",
    "end": "1492240"
  },
  {
    "text": "and much less of it on the right hand",
    "start": "1492240",
    "end": "1494000"
  },
  {
    "text": "side because on the left hand side those",
    "start": "1494000",
    "end": "1496159"
  },
  {
    "text": "are the areas where you're going to be",
    "start": "1496159",
    "end": "1497039"
  },
  {
    "text": "able to make all your changes",
    "start": "1497039",
    "end": "1498480"
  },
  {
    "text": "and on the right hand side you know at",
    "start": "1498480",
    "end": "1500720"
  },
  {
    "text": "best you can stop people but you're not",
    "start": "1500720",
    "end": "1502480"
  },
  {
    "text": "really adding a lot of user value",
    "start": "1502480",
    "end": "1504640"
  },
  {
    "text": "so that's what if your attacker gets",
    "start": "1504640",
    "end": "1506000"
  },
  {
    "text": "your model uh is able to take your",
    "start": "1506000",
    "end": "1507919"
  },
  {
    "text": "models those are two examples there",
    "start": "1507919",
    "end": "1509919"
  },
  {
    "text": "now let's talk about a third one around",
    "start": "1509919",
    "end": "1511520"
  },
  {
    "text": "data leakage where the attacker finds",
    "start": "1511520",
    "end": "1513520"
  },
  {
    "text": "out about hidden data",
    "start": "1513520",
    "end": "1515600"
  },
  {
    "text": "in this case a malicious user is going",
    "start": "1515600",
    "end": "1517279"
  },
  {
    "text": "to look for ways to attack your model to",
    "start": "1517279",
    "end": "1520000"
  },
  {
    "text": "understand",
    "start": "1520000",
    "end": "1520799"
  },
  {
    "text": "what it was trained on you probably are",
    "start": "1520799",
    "end": "1523279"
  },
  {
    "text": "already having this problem around data",
    "start": "1523279",
    "end": "1525120"
  },
  {
    "text": "leakage",
    "start": "1525120",
    "end": "1525840"
  },
  {
    "text": "and the problem here is it just becomes",
    "start": "1525840",
    "end": "1527520"
  },
  {
    "text": "more obfuscated because of",
    "start": "1527520",
    "end": "1529279"
  },
  {
    "text": "ml to show you some examples of data",
    "start": "1529279",
    "end": "1533200"
  },
  {
    "text": "leakage today that didn't require ml at",
    "start": "1533200",
    "end": "1535120"
  },
  {
    "text": "all",
    "start": "1535120",
    "end": "1535600"
  },
  {
    "text": "on the left hand side you see first ways",
    "start": "1535600",
    "end": "1538480"
  },
  {
    "text": "recommending",
    "start": "1538480",
    "end": "1539360"
  },
  {
    "text": "potentially a very secret meeting that i",
    "start": "1539360",
    "end": "1541360"
  },
  {
    "text": "might have coming from",
    "start": "1541360",
    "end": "1542720"
  },
  {
    "text": "my history and again if it wasn't",
    "start": "1542720",
    "end": "1544720"
  },
  {
    "text": "protected that would reveal it to an",
    "start": "1544720",
    "end": "1546799"
  },
  {
    "text": "attacker",
    "start": "1546799",
    "end": "1548000"
  },
  {
    "text": "maybe it looks the network graph where",
    "start": "1548000",
    "end": "1549919"
  },
  {
    "text": "maybe i'm a union organizer and it",
    "start": "1549919",
    "end": "1551600"
  },
  {
    "text": "detects",
    "start": "1551600",
    "end": "1552240"
  },
  {
    "text": "who all my friends are following not me",
    "start": "1552240",
    "end": "1555279"
  },
  {
    "text": "and i'm able to understand what they",
    "start": "1555279",
    "end": "1557440"
  },
  {
    "text": "their graphs look like and who they may",
    "start": "1557440",
    "end": "1559520"
  },
  {
    "text": "be following",
    "start": "1559520",
    "end": "1560640"
  },
  {
    "text": "or third you know when you look at",
    "start": "1560640",
    "end": "1563200"
  },
  {
    "text": "overall um",
    "start": "1563200",
    "end": "1564159"
  },
  {
    "text": "uh jogging and and race recommendations",
    "start": "1564159",
    "end": "1566960"
  },
  {
    "text": "and things like that",
    "start": "1566960",
    "end": "1568080"
  },
  {
    "text": "uh they're revealing what uh you know",
    "start": "1568080",
    "end": "1570559"
  },
  {
    "text": "the actual",
    "start": "1570559",
    "end": "1571200"
  },
  {
    "text": "layout of potentially confidential",
    "start": "1571200",
    "end": "1573039"
  },
  {
    "text": "buildings and structures",
    "start": "1573039",
    "end": "1574799"
  },
  {
    "text": "uh and again this wasn't even me or my",
    "start": "1574799",
    "end": "1577200"
  },
  {
    "text": "friends this was from the community that",
    "start": "1577200",
    "end": "1579120"
  },
  {
    "text": "was able to develop this",
    "start": "1579120",
    "end": "1580480"
  },
  {
    "text": "and roll it out now there's nothing so",
    "start": "1580480",
    "end": "1583919"
  },
  {
    "text": "bad that it can't be made worse",
    "start": "1583919",
    "end": "1585600"
  },
  {
    "text": "especially with machine learning so in",
    "start": "1585600",
    "end": "1587679"
  },
  {
    "text": "this case uh what you see",
    "start": "1587679",
    "end": "1589360"
  },
  {
    "text": "is where the the model is predicting",
    "start": "1589360",
    "end": "1592000"
  },
  {
    "text": "what i should type next",
    "start": "1592000",
    "end": "1593600"
  },
  {
    "text": "and so if i type a beginning of a",
    "start": "1593600",
    "end": "1595600"
  },
  {
    "text": "sentence it may move on and reveal",
    "start": "1595600",
    "end": "1598640"
  },
  {
    "text": "other things that come from my corpus of",
    "start": "1598640",
    "end": "1600960"
  },
  {
    "text": "information",
    "start": "1600960",
    "end": "1601679"
  },
  {
    "text": "so it's revealing basically my private",
    "start": "1601679",
    "end": "1603840"
  },
  {
    "text": "emails as",
    "start": "1603840",
    "end": "1604880"
  },
  {
    "text": "suggestions for what i should write next",
    "start": "1604880",
    "end": "1607279"
  },
  {
    "text": "now the problem here is of course",
    "start": "1607279",
    "end": "1608559"
  },
  {
    "text": "if it's doing its job right it sounds",
    "start": "1608559",
    "end": "1610799"
  },
  {
    "text": "great it sounds exactly",
    "start": "1610799",
    "end": "1612000"
  },
  {
    "text": "like me the problem is that this is",
    "start": "1612000",
    "end": "1613919"
  },
  {
    "text": "going to reveal a lot about what i write",
    "start": "1613919",
    "end": "1616720"
  },
  {
    "text": "in other males and of course this gets",
    "start": "1616720",
    "end": "1619600"
  },
  {
    "text": "quite bad",
    "start": "1619600",
    "end": "1620480"
  },
  {
    "text": "um here you have a number of different",
    "start": "1620480",
    "end": "1622240"
  },
  {
    "text": "examples whether or not it's revealing",
    "start": "1622240",
    "end": "1624159"
  },
  {
    "text": "the rest of my address",
    "start": "1624159",
    "end": "1626000"
  },
  {
    "text": "or my phone number maybe it reveals my",
    "start": "1626000",
    "end": "1628240"
  },
  {
    "text": "relationship information",
    "start": "1628240",
    "end": "1629760"
  },
  {
    "text": "or when it starts to get really bad you",
    "start": "1629760",
    "end": "1632559"
  },
  {
    "text": "use things like your",
    "start": "1632559",
    "end": "1633840"
  },
  {
    "text": "visa card where it has a known prefix",
    "start": "1633840",
    "end": "1636080"
  },
  {
    "text": "and suggests the rest",
    "start": "1636080",
    "end": "1638159"
  },
  {
    "text": "or maybe it reveals the social security",
    "start": "1638159",
    "end": "1640559"
  },
  {
    "text": "number where",
    "start": "1640559",
    "end": "1641360"
  },
  {
    "text": "again it comes from a known prefix and",
    "start": "1641360",
    "end": "1643440"
  },
  {
    "text": "reveals the rest of it",
    "start": "1643440",
    "end": "1644880"
  },
  {
    "text": "so in this case uh the model which is",
    "start": "1644880",
    "end": "1647520"
  },
  {
    "text": "totally obfuscated is revealing all this",
    "start": "1647520",
    "end": "1649440"
  },
  {
    "text": "stuff",
    "start": "1649440",
    "end": "1649919"
  },
  {
    "text": "without ever intending to because it",
    "start": "1649919",
    "end": "1652399"
  },
  {
    "text": "simply wants to sound like me",
    "start": "1652399",
    "end": "1655840"
  },
  {
    "text": "so there's some very cool ways to try",
    "start": "1655840",
    "end": "1657440"
  },
  {
    "text": "and detect these things uh in this case",
    "start": "1657440",
    "end": "1659600"
  },
  {
    "text": "there's a",
    "start": "1659600",
    "end": "1660720"
  },
  {
    "text": "way to use a canary where you inject",
    "start": "1660720",
    "end": "1663520"
  },
  {
    "text": "that canary early on in your training",
    "start": "1663520",
    "end": "1665360"
  },
  {
    "text": "data",
    "start": "1665360",
    "end": "1665760"
  },
  {
    "text": "and then later detect for whether or not",
    "start": "1665760",
    "end": "1668000"
  },
  {
    "text": "the canary leaked through",
    "start": "1668000",
    "end": "1669840"
  },
  {
    "text": "and you know in fact did reveal",
    "start": "1669840",
    "end": "1672240"
  },
  {
    "text": "information about that private corpus",
    "start": "1672240",
    "end": "1674240"
  },
  {
    "text": "the problem here is that even in this",
    "start": "1674240",
    "end": "1676080"
  },
  {
    "text": "case all you're really doing is",
    "start": "1676080",
    "end": "1677679"
  },
  {
    "text": "detecting leakage that is already",
    "start": "1677679",
    "end": "1679360"
  },
  {
    "text": "occurring",
    "start": "1679360",
    "end": "1680080"
  },
  {
    "text": "not preventing the leakage in the first",
    "start": "1680080",
    "end": "1681679"
  },
  {
    "text": "place and it's up to you to go back",
    "start": "1681679",
    "end": "1683200"
  },
  {
    "text": "and re-run your data and re-anonymize so",
    "start": "1683200",
    "end": "1686080"
  },
  {
    "text": "that",
    "start": "1686080",
    "end": "1686559"
  },
  {
    "text": "that data isn't being leaked through",
    "start": "1686559",
    "end": "1688320"
  },
  {
    "text": "inappropriately",
    "start": "1688320",
    "end": "1690159"
  },
  {
    "text": "now there are things like differential",
    "start": "1690159",
    "end": "1691360"
  },
  {
    "text": "privacy which may help over time",
    "start": "1691360",
    "end": "1693919"
  },
  {
    "text": "but i can't stress enough at the end of",
    "start": "1693919",
    "end": "1695440"
  },
  {
    "text": "the day you're going to reveal things",
    "start": "1695440",
    "end": "1697600"
  },
  {
    "text": "that are private",
    "start": "1697600",
    "end": "1698559"
  },
  {
    "text": "because that's the intent for this thing",
    "start": "1698559",
    "end": "1701120"
  },
  {
    "text": "to work properly",
    "start": "1701120",
    "end": "1702240"
  },
  {
    "text": "it should sound like the original user",
    "start": "1702240",
    "end": "1704720"
  },
  {
    "text": "it should be accurate",
    "start": "1704720",
    "end": "1706399"
  },
  {
    "text": "the problem is of course you have to",
    "start": "1706399",
    "end": "1708159"
  },
  {
    "text": "lock it down and you have to be able to",
    "start": "1708159",
    "end": "1709919"
  },
  {
    "text": "detect it very very quickly",
    "start": "1709919",
    "end": "1711600"
  },
  {
    "text": "the key here is building a pipeline",
    "start": "1711600",
    "end": "1713919"
  },
  {
    "text": "understanding your exposure quickly",
    "start": "1713919",
    "end": "1715600"
  },
  {
    "text": "and mitigating quickly so in summary",
    "start": "1715600",
    "end": "1719039"
  },
  {
    "text": "ml ops gives you a lot of goodness best",
    "start": "1719039",
    "end": "1722080"
  },
  {
    "text": "practices",
    "start": "1722080",
    "end": "1723039"
  },
  {
    "text": "repeatable workflows an immutable record",
    "start": "1723039",
    "end": "1725600"
  },
  {
    "text": "of what happened",
    "start": "1725600",
    "end": "1726640"
  },
  {
    "text": "and real acceleration around getting to",
    "start": "1726640",
    "end": "1729520"
  },
  {
    "text": "user benefits",
    "start": "1729520",
    "end": "1730799"
  },
  {
    "text": "unfortunately it doesn't give you this",
    "start": "1730799",
    "end": "1731919"
  },
  {
    "text": "for free there is some work involved",
    "start": "1731919",
    "end": "1734320"
  },
  {
    "text": "but the reality is this is the best we",
    "start": "1734320",
    "end": "1736399"
  },
  {
    "text": "have for making sure your systems are",
    "start": "1736399",
    "end": "1738480"
  },
  {
    "text": "working great",
    "start": "1738480",
    "end": "1741200"
  },
  {
    "text": "and the reality is it's a whole new",
    "start": "1741279",
    "end": "1743200"
  },
  {
    "text": "world data science will",
    "start": "1743200",
    "end": "1745120"
  },
  {
    "text": "touch every individual and it's up to us",
    "start": "1745120",
    "end": "1747440"
  },
  {
    "text": "the people watching this",
    "start": "1747440",
    "end": "1748640"
  },
  {
    "text": "and the data scientists and the ml",
    "start": "1748640",
    "end": "1750159"
  },
  {
    "text": "engineers to put these",
    "start": "1750159",
    "end": "1752240"
  },
  {
    "text": "tools in the hands of people who can",
    "start": "1752240",
    "end": "1754320"
  },
  {
    "text": "really use them to make the world a",
    "start": "1754320",
    "end": "1755919"
  },
  {
    "text": "better place",
    "start": "1755919",
    "end": "1758159"
  },
  {
    "text": "the truth you can avoid here your models",
    "start": "1758159",
    "end": "1760399"
  },
  {
    "text": "will be attacked your pipelines",
    "start": "1760399",
    "end": "1762159"
  },
  {
    "text": "will have issues and the game is all",
    "start": "1762159",
    "end": "1764720"
  },
  {
    "text": "about",
    "start": "1764720",
    "end": "1765279"
  },
  {
    "text": "mitigation of harms and quick recovery",
    "start": "1765279",
    "end": "1768080"
  },
  {
    "text": "and you can do that",
    "start": "1768080",
    "end": "1769120"
  },
  {
    "text": "using an ml ops pipeline and with that",
    "start": "1769120",
    "end": "1772080"
  },
  {
    "text": "here's the final slide with all the",
    "start": "1772080",
    "end": "1773840"
  },
  {
    "text": "papers",
    "start": "1773840",
    "end": "1774399"
  },
  {
    "text": "i that you may have any questions and",
    "start": "1774399",
    "end": "1776480"
  },
  {
    "text": "thank you so much",
    "start": "1776480",
    "end": "1781679"
  }
]
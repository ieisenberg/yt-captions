[
  {
    "text": "good morning well good afternoon greetings i'm lurking by hello hello",
    "start": "69280",
    "end": "77200"
  },
  {
    "text": "hello jimmy hi luis hey rafael",
    "start": "77200",
    "end": "87759"
  },
  {
    "text": "good morning good afternoon",
    "start": "87759",
    "end": "91040"
  },
  {
    "text": "hey am i pronouncing your name right when i call you rafael okay very correctly very right",
    "start": "93360",
    "end": "100960"
  },
  {
    "text": "it's a it's a relief",
    "start": "100960",
    "end": "115840"
  },
  {
    "text": "all right we'll just wait a minute or two",
    "start": "118560",
    "end": "123040"
  },
  {
    "text": "and then we can move into uh roughly the the dr",
    "start": "123680",
    "end": "133039"
  },
  {
    "text": "presentation",
    "start": "140840",
    "end": "143840"
  },
  {
    "text": "i'll put the presentation into the chat",
    "start": "147760",
    "end": "152879"
  },
  {
    "text": "window",
    "start": "154840",
    "end": "157840"
  },
  {
    "text": "is it possible to get the presentation comment only or view only link i was",
    "start": "178080",
    "end": "184560"
  },
  {
    "text": "going to say it's locked yeah it's locked right now it has to be added individually",
    "start": "184560",
    "end": "190800"
  },
  {
    "text": "i mean i think if there is a maybe a group email group i mean i can enable that i",
    "start": "191840",
    "end": "198720"
  },
  {
    "text": "don't otherwise i don't know how to do it i have no you should be able to set it to like anyone with the link and view",
    "start": "198720",
    "end": "204080"
  },
  {
    "text": "only and then after this presentation uh it's probably best to be able to keep it like uh everyone with the link view",
    "start": "204080",
    "end": "209280"
  },
  {
    "text": "only yes do you want me to um raphael if it's if it's sort of on your",
    "start": "209280",
    "end": "216159"
  },
  {
    "text": "internal and you can't share it i can i can make a copy and share that instead if you",
    "start": "216159",
    "end": "221440"
  },
  {
    "text": "want yeah yeah please do that",
    "start": "221440",
    "end": "227280"
  },
  {
    "text": "okay yeah i can only i can only enable the link to reductors i",
    "start": "227280",
    "end": "232400"
  },
  {
    "text": "cannot do it make it publicly available but i can enable people individually i see got it",
    "start": "232400",
    "end": "241840"
  },
  {
    "text": "alex your way is best i wish that red hat i used to copy it to my personal account for",
    "start": "243680",
    "end": "250799"
  },
  {
    "text": "community stuff and then share that using gmail",
    "start": "250799",
    "end": "255840"
  },
  {
    "text": "i could probably do that too but i mean yeah it's well it's it's what alex is",
    "start": "256560",
    "end": "262800"
  },
  {
    "text": "doing basically so uh after that after today i'm gonna use the his copy if there is any plate",
    "start": "262800",
    "end": "271120"
  },
  {
    "text": "cool all right",
    "start": "271759",
    "end": "276639"
  },
  {
    "text": "let's post the link can you can you open that one",
    "start": "279199",
    "end": "284960"
  },
  {
    "text": "hooray cool yep",
    "start": "286400",
    "end": "297840"
  },
  {
    "text": "all righty then i think um it's five past we should probably start",
    "start": "307120",
    "end": "314560"
  },
  {
    "text": "so i'll hand over to to uh rafaele who's gonna um who's put a few",
    "start": "314560",
    "end": "320320"
  },
  {
    "text": "slides together to summarize um the documents that we've been working on",
    "start": "320320",
    "end": "326080"
  },
  {
    "text": "to see if it makes it uh easier to to get some of the concepts across and",
    "start": "326080",
    "end": "332639"
  },
  {
    "text": "maybe provide some feedback so over to you rafael uh thank you",
    "start": "332639",
    "end": "338320"
  },
  {
    "text": "um yes so as you know there is a much more detailed",
    "start": "338320",
    "end": "344000"
  },
  {
    "text": "document that we are considering for you know maybe to",
    "start": "344000",
    "end": "349520"
  },
  {
    "text": "publish where we where my intention and hopefully becomes the group intention is to",
    "start": "349520",
    "end": "355280"
  },
  {
    "text": "talk about um a cloud-native approach to disaster recovery um so this i created this presentation",
    "start": "355280",
    "end": "362639"
  },
  {
    "text": "just to make it easier to communicate but really that document has a ton more of details",
    "start": "362639",
    "end": "369280"
  },
  {
    "text": "and and the idea is you can still use all of your traditional dr approaches",
    "start": "369280",
    "end": "375280"
  },
  {
    "text": "but we think that there is maybe a new way to do things with cloud native and so we're",
    "start": "375280",
    "end": "381840"
  },
  {
    "text": "going to talk about that okay that's not to so so again it's not to say that the other things the other approaches",
    "start": "381840",
    "end": "388160"
  },
  {
    "text": "cannot be used typically the active passive approaches but we we're looking at uh",
    "start": "388160",
    "end": "395680"
  },
  {
    "text": "we're going to try to give a definition to what cloud-native disaster recovery might mean and this is my my slides here to compare",
    "start": "395759",
    "end": "404160"
  },
  {
    "text": "the two approaches um so i'm going to go line by one",
    "start": "404160",
    "end": "409599"
  },
  {
    "text": "line by line um in in as far as disaster detection and the art",
    "start": "409599",
    "end": "415840"
  },
  {
    "text": "procedure traditionally there is a human decision okay something",
    "start": "415840",
    "end": "420880"
  },
  {
    "text": "goes wrong and somebody triggers the dr procedure then maybe the dr procedure",
    "start": "420880",
    "end": "427120"
  },
  {
    "text": "is automated but there is very often there is a human decision we",
    "start": "427120",
    "end": "433199"
  },
  {
    "text": "want to get to with cloud native or what we define as cloud native disaster detection is",
    "start": "433199",
    "end": "438800"
  },
  {
    "text": "is that it's going to be autonomous so the system automatically understands the disaster and",
    "start": "438800",
    "end": "444800"
  },
  {
    "text": "triggers whatever reaction is need to be triggered then the dr procedure itself what i find",
    "start": "444800",
    "end": "451039"
  },
  {
    "text": "with my customer is that normally it's a mix of automation and human you know manual actions we want it to be fully",
    "start": "451039",
    "end": "459280"
  },
  {
    "text": "automated in cloud native inclinative the recovery",
    "start": "459280",
    "end": "464400"
  },
  {
    "text": "time so that's uh how for how long our system is down uh needs to be near zero um",
    "start": "464400",
    "end": "472560"
  },
  {
    "text": "it cannot be exactly zero because the there are caches there are load balancers that need to switch but",
    "start": "472560",
    "end": "480000"
  },
  {
    "text": "it can be very close to zero and normally we see it to be around minutes or two",
    "start": "480000",
    "end": "486400"
  },
  {
    "text": "hours right in modern traditional data centers the recovery point",
    "start": "486400",
    "end": "491759"
  },
  {
    "text": "objectives that is how much data i lose or how much inconsistency i have between",
    "start": "491759",
    "end": "496960"
  },
  {
    "text": "copies of my data um in traditional disaster recovery i see",
    "start": "496960",
    "end": "502720"
  },
  {
    "text": "it being between zero and hours depending how we do the sync or backup and restore",
    "start": "502720",
    "end": "508080"
  },
  {
    "text": "in cloud native it can be exactly zero so full full consistency",
    "start": "508080",
    "end": "516959"
  },
  {
    "text": "process wise i see this pattern and you guys tell me if you see that's not true but in traditional",
    "start": "517760",
    "end": "523839"
  },
  {
    "text": "disaster recovery the owner the formal ownership of the dr procedure is on the",
    "start": "523839",
    "end": "528880"
  },
  {
    "text": "apps it's always been a responsibility of the apps but what the apps do is this app uses this this storage",
    "start": "528880",
    "end": "537440"
  },
  {
    "text": "they turn around they turn around to the storage team and say ask the searching what is your",
    "start": "537440",
    "end": "542880"
  },
  {
    "text": "disaster recovery sla starts team as an answer and they say okay for this app",
    "start": "542880",
    "end": "548800"
  },
  {
    "text": "that is the sla that we're gonna get um so it really",
    "start": "548800",
    "end": "554480"
  },
  {
    "text": "you know even if formally the dr procedure is you know owned by the stories by the application",
    "start": "554480",
    "end": "560080"
  },
  {
    "text": "team in reality it's owned by this by the storage team just now native",
    "start": "560080",
    "end": "566000"
  },
  {
    "text": "yeah sorry sorry just to a quick question i hope i can interrupt with questions this is okay absolutely okay that's the",
    "start": "566000",
    "end": "573279"
  },
  {
    "text": "majority thank you uh is it when you say zero in the uh uh almost zero seconds",
    "start": "573279",
    "end": "580880"
  },
  {
    "text": "is that because the assumption is that the is the same cloud or is the same region",
    "start": "580880",
    "end": "588399"
  },
  {
    "text": "uh when you do a dr not across like uh across far regions or close to crowd",
    "start": "588399",
    "end": "594240"
  },
  {
    "text": "clouds no that's not the assumption the assumption is we are going to go",
    "start": "594240",
    "end": "599680"
  },
  {
    "text": "we have geographically distributed workloads possibly across different clouds and we",
    "start": "599680",
    "end": "605040"
  },
  {
    "text": "still get near zero okay okay interesting okay thank you",
    "start": "605040",
    "end": "610240"
  },
  {
    "text": "um and instead going back to ownership in cloud native it's it's an",
    "start": "610240",
    "end": "616880"
  },
  {
    "text": "application responsibility the other observation i made",
    "start": "616880",
    "end": "621920"
  },
  {
    "text": "is that in terms of technical capabilities most in traditional disaster recovery",
    "start": "621920",
    "end": "628240"
  },
  {
    "text": "must we leverage capability mostly from the",
    "start": "628240",
    "end": "633360"
  },
  {
    "text": "storage side so backups volume syncs um and this kind of capabilities",
    "start": "633360",
    "end": "640800"
  },
  {
    "text": "but to build this cloud native disaster recovery infrastructure or architecture we we need",
    "start": "640800",
    "end": "649200"
  },
  {
    "text": "capabilities from networking and in particular we need we're going to see that we we need his ability to communicate is west",
    "start": "649200",
    "end": "657519"
  },
  {
    "text": "so if i am in two different clouds this cloud have to be able to communicate um",
    "start": "657519",
    "end": "665839"
  },
  {
    "text": "horizontally east west and to have a good global load balancer capability and",
    "start": "665839",
    "end": "671279"
  },
  {
    "text": "that's that's where the switch happens right um so i mean just just a quick comment here",
    "start": "671279",
    "end": "679839"
  },
  {
    "text": "i i think",
    "start": "679839",
    "end": "682560"
  },
  {
    "text": "i you know i think we may need to differentiate between sort of what the high level objectives",
    "start": "685200",
    "end": "690720"
  },
  {
    "text": "are and what happens in reality right because",
    "start": "690720",
    "end": "696240"
  },
  {
    "text": "you know to have recovery point objective of zero is is certainly doable and it's",
    "start": "696240",
    "end": "702880"
  },
  {
    "text": "plausible but it also kind of means um",
    "start": "702880",
    "end": "708720"
  },
  {
    "text": "it it sort of also implies that that every transaction or every database",
    "start": "709120",
    "end": "714720"
  },
  {
    "text": "action or every you know file action or whatever the application is using is is going to",
    "start": "714720",
    "end": "721040"
  },
  {
    "text": "be synchronously happening across multiple sites um which which may or may not be",
    "start": "721040",
    "end": "727600"
  },
  {
    "text": "the case right so so you know i think i think zero could be the target that's the that's that's achievable but",
    "start": "727600",
    "end": "734160"
  },
  {
    "text": "it's it's it's because we're enabling the automation and i think i think that's the point that we're trying to make here right",
    "start": "734160",
    "end": "742399"
  },
  {
    "text": "yeah yeah i perhaps i see what you mean alex the",
    "start": "742480",
    "end": "749760"
  },
  {
    "text": "not not every time i i may need to get to zero right not always and we need to get to zero",
    "start": "749760",
    "end": "755600"
  },
  {
    "text": "right now yeah the point i'm trying to make is now you can get to zero uh and it's not",
    "start": "755600",
    "end": "761440"
  },
  {
    "text": "that complicated we you know the the narrative was you can do",
    "start": "761440",
    "end": "766480"
  },
  {
    "text": "dr as you can make dr as good as you want as long as you're willing to spend a lot of money right i think with cloud native",
    "start": "766480",
    "end": "773680"
  },
  {
    "text": "approach that narrative changes a little bit this these architectures are not that more expensive than the traditional",
    "start": "773680",
    "end": "780240"
  },
  {
    "text": "you know active passive ones uh and so much so that in in an article that i",
    "start": "780240",
    "end": "786880"
  },
  {
    "text": "wrote about this i called it the democratization of of zero down time right during a",
    "start": "786880",
    "end": "792399"
  },
  {
    "text": "disaster because i think anyone who can swipe a credit card and start deploying on different clouds can",
    "start": "792399",
    "end": "798000"
  },
  {
    "text": "achieve this you know in a way that is not that expensive so that's",
    "start": "798000",
    "end": "803519"
  },
  {
    "text": "that's the point here that it's it's achievable and it's not that expensive yeah i think it's not just about cost to",
    "start": "803519",
    "end": "810079"
  },
  {
    "text": "alex's point we had the presentation last week i think it was called full fs or that they were talking about",
    "start": "810079",
    "end": "817200"
  },
  {
    "text": "performance tradeoffs how they were not posix compliance so i think it's not just about cost it's",
    "start": "817200",
    "end": "824160"
  },
  {
    "text": "also about performance because if you want to have zero rpo you have to write to all you know every single zone",
    "start": "824160",
    "end": "829680"
  },
  {
    "text": "and get back acknowledgements and so it's not all about costs",
    "start": "829680",
    "end": "836320"
  },
  {
    "text": "agreed agree there are some certainly some use cases where performance trump consistency",
    "start": "836320",
    "end": "843120"
  },
  {
    "text": "uh and that's totally fine we we can we can i totally acknowledge that",
    "start": "843120",
    "end": "850160"
  },
  {
    "text": "cool okay so high level this is the reference",
    "start": "850160",
    "end": "856160"
  },
  {
    "text": "architecture we assume there are let's say three data",
    "start": "856160",
    "end": "862399"
  },
  {
    "text": "centers in three faraway regions uh if reason is if",
    "start": "862399",
    "end": "867920"
  },
  {
    "text": "you're thinking about the cloud or it could be your three data centers in different geographical locality if you",
    "start": "867920",
    "end": "874000"
  },
  {
    "text": "think about uh on premise it doesn't matter the architecture works anyway",
    "start": "874000",
    "end": "879360"
  },
  {
    "text": "there is a stateful workload you can imagine a database or a queue",
    "start": "879360",
    "end": "884639"
  },
  {
    "text": "right that is is distributed across this data center",
    "start": "884639",
    "end": "891040"
  },
  {
    "text": "to form a logical entity but obviously there are different instances and these instances communicate",
    "start": "891040",
    "end": "897600"
  },
  {
    "text": "between each other via this horizontal east-west ability to communicate we don't need to",
    "start": "897600",
    "end": "905360"
  },
  {
    "text": "know at this you know in this reference architecture how that is implemented but they need to be able to communicate",
    "start": "905360",
    "end": "911920"
  },
  {
    "text": "east west so find each other look up each other and uh discover each other and",
    "start": "911920",
    "end": "917360"
  },
  {
    "text": "and communicate and that's how they achieve data sync you know state sync each of them will have a volume so we",
    "start": "917360",
    "end": "925199"
  },
  {
    "text": "need storage of course because we're still storage doesn't go away but but we don't ask those volume",
    "start": "925199",
    "end": "932320"
  },
  {
    "text": "implementation of that that you know that volume uh that storage implementation",
    "start": "932320",
    "end": "937440"
  },
  {
    "text": "um we don't ask you to have any particular capabilities besides the ability to obviously store data",
    "start": "937440",
    "end": "945920"
  },
  {
    "text": "and then we can imagine that there is a front-end or maybe just direct connection but probably",
    "start": "945920",
    "end": "951120"
  },
  {
    "text": "there's going to be a front-end status front end and then there is a global load balancer",
    "start": "951120",
    "end": "957040"
  },
  {
    "text": "okay and so the idea is when one of these regions",
    "start": "957040",
    "end": "963680"
  },
  {
    "text": "goes down because of a disaster first the stateful workload adjusts",
    "start": "963680",
    "end": "970560"
  },
  {
    "text": "itself because it has some kind of you know leader election and state-sync",
    "start": "970560",
    "end": "976480"
  },
  {
    "text": "protocol and we can analyze those in detail but uh it adjusts itself instantaneously",
    "start": "976480",
    "end": "983600"
  },
  {
    "text": "there is no data loss and then the global load balancer has some level of health checks as some of",
    "start": "983600",
    "end": "989279"
  },
  {
    "text": "the checks uh and so clients will start going only to the regions that are",
    "start": "989279",
    "end": "996480"
  },
  {
    "text": "active okay so as a so we we",
    "start": "996480",
    "end": "1003360"
  },
  {
    "text": "we reacted to a disaster uh completely in an autonomous way and the",
    "start": "1003680",
    "end": "1009440"
  },
  {
    "text": "clients keep working maybe they get they get a glitch of a few seconds i work with the database that where the",
    "start": "1009440",
    "end": "1015920"
  },
  {
    "text": "glitch can be up to nine seconds uh and then but but then everything",
    "start": "1015920",
    "end": "1021920"
  },
  {
    "text": "continues to to function normally",
    "start": "1021920",
    "end": "1025839"
  },
  {
    "text": "okay so that's the idea uh i think it's the general model the the trick is to find state of",
    "start": "1028319",
    "end": "1035520"
  },
  {
    "text": "workload that can actually work that way and there are some prerequisites that they",
    "start": "1035520",
    "end": "1041199"
  },
  {
    "text": "have to implement in order to do this and this state for workload sorry i just mentioned",
    "start": "1041199",
    "end": "1046880"
  },
  {
    "text": "queue and and databases but obviously it could be a distributed",
    "start": "1046880",
    "end": "1052320"
  },
  {
    "text": "storage although performance there could could become an issue it could be a distributed cache you know",
    "start": "1052320",
    "end": "1058880"
  },
  {
    "text": "it could be it could be anything that needs to manage a state",
    "start": "1058880",
    "end": "1066320"
  },
  {
    "text": "so in order to understand why this works i need to bring to mind some concept sorry was there",
    "start": "1066320",
    "end": "1074720"
  },
  {
    "text": "and uh yeah so sorry so um i was wondering uh in this reference architecture we",
    "start": "1074720",
    "end": "1080240"
  },
  {
    "text": "basically say that for the dr we're basically this implies the state sync is",
    "start": "1080240",
    "end": "1087600"
  },
  {
    "text": "down always going to be down by applications right right and application have to have",
    "start": "1087600",
    "end": "1094960"
  },
  {
    "text": "ability to operate replicas across different data centers which might",
    "start": "1094960",
    "end": "1101600"
  },
  {
    "text": "potentially has very high latency right and",
    "start": "1101600",
    "end": "1107120"
  },
  {
    "text": "so that's the on this is is there any other model we consider or is this going to be our like",
    "start": "1107600",
    "end": "1114480"
  },
  {
    "text": "only reference architecture for dr well you like for for this model that's",
    "start": "1114480",
    "end": "1120799"
  },
  {
    "text": "that's that's how the application needs to work like i said and like the slide says you can still do",
    "start": "1120799",
    "end": "1128240"
  },
  {
    "text": "your active passive models or master slave you know that i've always worked",
    "start": "1128240",
    "end": "1136400"
  },
  {
    "text": "right but you don't get all the automations that that i described um",
    "start": "1136400",
    "end": "1143200"
  },
  {
    "text": "yeah so maybe maybe i'd like to suggest",
    "start": "1143200",
    "end": "1151039"
  },
  {
    "text": "sort of a slight refinement here mostly to do with the terminology right",
    "start": "1151039",
    "end": "1156320"
  },
  {
    "text": "um when we when we put the the sort of the storage landscape paper together we kind of",
    "start": "1156320",
    "end": "1162880"
  },
  {
    "text": "talked about um different ways of of persisting data",
    "start": "1162880",
    "end": "1169520"
  },
  {
    "text": "and that um you know that could be some sort of volume but it could also be",
    "start": "1169520",
    "end": "1176480"
  },
  {
    "text": "you know um app level stuff like like a database but also you know key",
    "start": "1176480",
    "end": "1181760"
  },
  {
    "text": "value stores or or or um object stores for example are",
    "start": "1181760",
    "end": "1187120"
  },
  {
    "text": "also are also you know valid ways of of persisting data and you know whether it's distributed",
    "start": "1187120",
    "end": "1194720"
  },
  {
    "text": "storage that's providing volumes or a distributed database or a distributed key value store right",
    "start": "1194720",
    "end": "1199919"
  },
  {
    "text": "i think what we're kind of saying here is the stateful workload needs to have a distributed way of",
    "start": "1199919",
    "end": "1207760"
  },
  {
    "text": "persisting the data and that that could be you know distributed volumes it could be",
    "start": "1207760",
    "end": "1213760"
  },
  {
    "text": "you know like like um a distributed file system or a distributed storage system it could be a distributed",
    "start": "1213760",
    "end": "1221760"
  },
  {
    "text": "database you know like a cockroachdb or a yet applied or or or for tests or",
    "start": "1221760",
    "end": "1228640"
  },
  {
    "text": "something or it could be you know a distributed object store",
    "start": "1228640",
    "end": "1233840"
  },
  {
    "text": "and in that case then you kind of have that that that sort of functionality",
    "start": "1233840",
    "end": "1241120"
  },
  {
    "text": "um available to the to the application i think yeah so so i think it would kind of be",
    "start": "1241120",
    "end": "1247280"
  },
  {
    "text": "useful to to sort of change the stateful workloads as sort of some sort of distributed storage layer",
    "start": "1247280",
    "end": "1253039"
  },
  {
    "text": "and the volume is ultimately where data has persisted but it's not necessarily you know it could be a",
    "start": "1253039",
    "end": "1260320"
  },
  {
    "text": "distributed volume in that blue layer potentially i think right right i agree um yeah so",
    "start": "1260320",
    "end": "1268400"
  },
  {
    "text": "i didn't say what service this state of workload offers to the green layer right",
    "start": "1268400",
    "end": "1275120"
  },
  {
    "text": "and that this service could be storage right or it could be key value store or it could be sql or could be eq",
    "start": "1275120",
    "end": "1282320"
  },
  {
    "text": "you know it could be anything uh but yes i think i can improve this slide",
    "start": "1282320",
    "end": "1287679"
  },
  {
    "text": "by by adding that that piece of information and so yeah this this volume here like i said could",
    "start": "1287679",
    "end": "1295200"
  },
  {
    "text": "be the the disk on which this state for workload is running or it could be another layer of the defined storage it",
    "start": "1295200",
    "end": "1302960"
  },
  {
    "text": "doesn't really matter because the state sink is managed at this layer the blue layer",
    "start": "1302960",
    "end": "1309440"
  },
  {
    "text": "makes sense yeah so one second i'm taking note on this",
    "start": "1309440",
    "end": "1319840"
  },
  {
    "text": "okay so was saying um you know so the the the document that i",
    "start": "1330080",
    "end": "1337039"
  },
  {
    "text": "wrote tries to explain why this is technically feasible right because you you might say",
    "start": "1337039",
    "end": "1342480"
  },
  {
    "text": "i don't believe that this can be done right well we haven't done it for many years right now is it possible right i so i i try to",
    "start": "1342480",
    "end": "1350799"
  },
  {
    "text": "explain uh why and um i just have to remind you of a few",
    "start": "1350799",
    "end": "1357200"
  },
  {
    "text": "concepts uh so i think everybody knows what high availability and disaster recovery is i",
    "start": "1357200",
    "end": "1363200"
  },
  {
    "text": "just wanted i want to define them in a in in relationship to what a failure domain is okay so",
    "start": "1363200",
    "end": "1370320"
  },
  {
    "text": "failure domain is something is an area of id of our iit system that um",
    "start": "1370320",
    "end": "1378399"
  },
  {
    "text": "when when when there could be a single event that makes",
    "start": "1378559",
    "end": "1385039"
  },
  {
    "text": "everything running in that area fail okay uh so it could be a node for example which",
    "start": "1385039",
    "end": "1392720"
  },
  {
    "text": "means all the process running on the nodes now fail it could be a rack which means all all the nodes running on the rack fail",
    "start": "1392720",
    "end": "1399360"
  },
  {
    "text": "fail or a cabinet cluster a network zone a data center right",
    "start": "1399360",
    "end": "1404480"
  },
  {
    "text": "so a failure domain is sort of a",
    "start": "1404480",
    "end": "1409520"
  },
  {
    "text": "fractal concept that is out of similar at different scales but um uh in",
    "start": "1410320",
    "end": "1417679"
  },
  {
    "text": "what we need to remember remember here for this discussion is when we talk about a high availability",
    "start": "1417679",
    "end": "1424799"
  },
  {
    "text": "relative to failure domain we really are asking the question what happens when one component fails",
    "start": "1424799",
    "end": "1431760"
  },
  {
    "text": "within this failure domain right what happens to my system when one component fails um assuming a",
    "start": "1431760",
    "end": "1439679"
  },
  {
    "text": "h a of one i i i have a full tolerance of one i'm assuming that that is what we mean",
    "start": "1439679",
    "end": "1445440"
  },
  {
    "text": "by higher value when we talk about disaster recovery really we are asking the question what",
    "start": "1445440",
    "end": "1451200"
  },
  {
    "text": "happens if everything in this failure domain is lost so basically the failed domain",
    "start": "1451200",
    "end": "1456559"
  },
  {
    "text": "fails what happens to my system obviously i need to have other famous domains somewhere",
    "start": "1456559",
    "end": "1461600"
  },
  {
    "text": "and normally in this case the failure domain is the data center but conventionally",
    "start": "1461600",
    "end": "1468000"
  },
  {
    "text": "when we talk about disaster recovery we talk about an entire data center going down okay so with this in mind",
    "start": "1468000",
    "end": "1476159"
  },
  {
    "text": "um i'll continue because i'm sure everybody knows um this this concept um this",
    "start": "1476159",
    "end": "1484080"
  },
  {
    "text": "consistently here we we mean we mean that all instances",
    "start": "1484080",
    "end": "1490320"
  },
  {
    "text": "are observed in the same state and are reporting on the same state it's it's not the consistency of acid",
    "start": "1490320",
    "end": "1496720"
  },
  {
    "text": "which is more about multi-threading on a single instance and every every thread is in the same",
    "start": "1496720",
    "end": "1502159"
  },
  {
    "text": "state um yeah i think i think we we define um",
    "start": "1502159",
    "end": "1508679"
  },
  {
    "text": "consistency in the white paper pretty well right i i really like this slide in that",
    "start": "1508679",
    "end": "1515120"
  },
  {
    "text": "i think we should what we should sort of pop out of this slide is that high availability is about",
    "start": "1515120",
    "end": "1522960"
  },
  {
    "text": "sort of the the recovery from a single point of failure or something like that um whereas",
    "start": "1522960",
    "end": "1529440"
  },
  {
    "text": "disaster recovery we're talking about the failure of an entire failure domain and and that's that's a really useful um",
    "start": "1529440",
    "end": "1537600"
  },
  {
    "text": "differentiation to have right and and it's um i i felt the need to",
    "start": "1537600",
    "end": "1544080"
  },
  {
    "text": "make this differentiation because um these two concepts when you",
    "start": "1544080",
    "end": "1549279"
  },
  {
    "text": "talk to the customers these days are starting to overlap because rightfully so they would like to",
    "start": "1549279",
    "end": "1555919"
  },
  {
    "text": "treat a disaster recovery event like if it was an aha event and and in this theoretical model that i",
    "start": "1555919",
    "end": "1562799"
  },
  {
    "text": "just described that is exactly what happens but unfortunately that also brings",
    "start": "1562799",
    "end": "1568320"
  },
  {
    "text": "confusion between these two concepts and so it's it's important to to",
    "start": "1568320",
    "end": "1573919"
  },
  {
    "text": "understand what the difference is uh continuing the other thing we need to remember is the cap theorem",
    "start": "1573919",
    "end": "1580559"
  },
  {
    "text": "again i'm pretty sure you guys know what it is um many you know the common way to to",
    "start": "1580559",
    "end": "1588320"
  },
  {
    "text": "explain the cup theory is you can have thinking about consistency availability",
    "start": "1588320",
    "end": "1593360"
  },
  {
    "text": "and partitioning you can have you can pick two but not all of three i like i like to tell it in a slightly",
    "start": "1593360",
    "end": "1600400"
  },
  {
    "text": "different way that i think helps in this discussion which is that you don't choose partitioning",
    "start": "1600400",
    "end": "1606640"
  },
  {
    "text": "uh network partitioning is something that happens you know miss the errors will happen",
    "start": "1606640",
    "end": "1613120"
  },
  {
    "text": "right so assuming that you need to be partition tolerant",
    "start": "1613120",
    "end": "1618159"
  },
  {
    "text": "how do you design your workload do you design it to be available or do you design it to be consistent so that's",
    "start": "1618159",
    "end": "1623520"
  },
  {
    "text": "really in my mind the choice that you have and i have um and i have here a table",
    "start": "1623520",
    "end": "1631679"
  },
  {
    "text": "showing some of these choices made by some products you should um obviously every",
    "start": "1631679",
    "end": "1639840"
  },
  {
    "text": "state for workload that attempts to solve that attempts to be distributed has to deal with this theorem and that's",
    "start": "1639840",
    "end": "1645919"
  },
  {
    "text": "to make a choice here the other thing that we need to keep in",
    "start": "1645919",
    "end": "1652720"
  },
  {
    "text": "mind is the concept of consensus protocols okay so hey rafael sorry just just done",
    "start": "1652720",
    "end": "1659440"
  },
  {
    "text": "one step um when you say the capital choice for those examples",
    "start": "1659440",
    "end": "1664720"
  },
  {
    "text": "for example mongodb is consistency as in it allows um deferred consistency or",
    "start": "1664720",
    "end": "1671200"
  },
  {
    "text": "or it's optimizing for uptime what did you mean by that so when you",
    "start": "1671200",
    "end": "1676640"
  },
  {
    "text": "choose consistency uh in in the cafeteria it means that when the system goes into network",
    "start": "1676640",
    "end": "1684480"
  },
  {
    "text": "partitioning which is which is where the system cannot establish",
    "start": "1684480",
    "end": "1690080"
  },
  {
    "text": "anymore if if there is a piece of the system that is actually working and the other is not working but it doesn't know what the other piece of",
    "start": "1690080",
    "end": "1697039"
  },
  {
    "text": "the system is is doing then it puts itself",
    "start": "1697039",
    "end": "1702399"
  },
  {
    "text": "in a not available state which could mean read only or maybe just rejection of",
    "start": "1702399",
    "end": "1709120"
  },
  {
    "text": "goals uh and because the objective is to maintain the the state consistent certainly it",
    "start": "1709120",
    "end": "1716559"
  },
  {
    "text": "doesn't accept rights anymore right while cassandra and dynamodb will keep accepting rights even if they",
    "start": "1716559",
    "end": "1723039"
  },
  {
    "text": "don't know the state of a piece of the rest of the system assuming that they because they assume they can",
    "start": "1723039",
    "end": "1728559"
  },
  {
    "text": "do eventual consistency when all of the system all of the instances would restart uh to",
    "start": "1728559",
    "end": "1735679"
  },
  {
    "text": "be able to communicate right yeah the problem so eventual consistency is",
    "start": "1735679",
    "end": "1743760"
  },
  {
    "text": "is an appealing approach and i think it has been explored a lot",
    "start": "1743760",
    "end": "1749840"
  },
  {
    "text": "there is now some emerging there is a line of thought you may agree or not but there",
    "start": "1749840",
    "end": "1754880"
  },
  {
    "text": "is a line of thought that adventure consistency is kind of dangerous path because eventual",
    "start": "1754880",
    "end": "1760880"
  },
  {
    "text": "consistency does not imply eventual correctness it just implies that at some point",
    "start": "1760880",
    "end": "1766960"
  },
  {
    "text": "in the future and there is really no sla that you can put on that statement but just at some point in the",
    "start": "1766960",
    "end": "1772960"
  },
  {
    "text": "future all the instances will agree on the state it doesn't mean that the state is what you would have expected from a",
    "start": "1772960",
    "end": "1779440"
  },
  {
    "text": "business stand to business logic state point of view right so so",
    "start": "1779440",
    "end": "1786799"
  },
  {
    "text": "the developers now have to take extra care to make sure that they catch these these incorrect",
    "start": "1786799",
    "end": "1794240"
  },
  {
    "text": "inc you know consistency decision because there is a conflict resolution",
    "start": "1794240",
    "end": "1799279"
  },
  {
    "text": "you know algorithm in this in this um in this state for workload that",
    "start": "1799279",
    "end": "1805200"
  },
  {
    "text": "decides when there is an inconsistent that decides who's right maybe with the timestamp or something else",
    "start": "1805200",
    "end": "1811200"
  },
  {
    "text": "so now the developers have to take care of that and yeah there are some papers like google",
    "start": "1811200",
    "end": "1817520"
  },
  {
    "text": "or some you know um thread in where they discussed how",
    "start": "1817520",
    "end": "1823039"
  },
  {
    "text": "painful was to remedy those kind of things and so at least this this line of thought and i",
    "start": "1823039",
    "end": "1828559"
  },
  {
    "text": "i like that line of thought is let's keep everything consistent consistent with the risk of taking an",
    "start": "1828559",
    "end": "1833760"
  },
  {
    "text": "outage but it's it's simpler for from a developer point of view to",
    "start": "1833760",
    "end": "1839600"
  },
  {
    "text": "in many in many cases right it's simpler to to operate that way there are situations where in consensus",
    "start": "1839600",
    "end": "1845200"
  },
  {
    "text": "it doesn't matter too much um and so in those cases it's fine to use",
    "start": "1845200",
    "end": "1850640"
  },
  {
    "text": "to use um those databases but i work a lot in financial institutions",
    "start": "1850640",
    "end": "1857440"
  },
  {
    "text": "consistency is important it's very important there um so i'm going guide but but this",
    "start": "1857440",
    "end": "1865760"
  },
  {
    "text": "this was to explain why i focused here on consistency so the",
    "start": "1865760",
    "end": "1872080"
  },
  {
    "text": "and and that's that is really what we mean when we say uh zero rpo right it's there is no",
    "start": "1872080",
    "end": "1879519"
  },
  {
    "text": "there is no inconsistency there is no data loss so uh consensus protocol",
    "start": "1879519",
    "end": "1888000"
  },
  {
    "text": "i invented these two definitions uh share state and then share state this is",
    "start": "1888000",
    "end": "1894559"
  },
  {
    "text": "really my terminology and we can change it uh but the concept is",
    "start": "1894559",
    "end": "1899760"
  },
  {
    "text": "like well let's let's find consensus protocol first is the idea that i have d i have distributed workload",
    "start": "1899760",
    "end": "1906159"
  },
  {
    "text": "that is needs to act as a single logical entity so they",
    "start": "1906159",
    "end": "1911519"
  },
  {
    "text": "the various instances need to agree on actions to be taken right and there are two",
    "start": "1911519",
    "end": "1919279"
  },
  {
    "text": "kind of protocols to agree on actions the one in the first one here share",
    "start": "1919279",
    "end": "1925120"
  },
  {
    "text": "state is when we have to agree on all of us you know all of the instances doing the same action",
    "start": "1925120",
    "end": "1931120"
  },
  {
    "text": "so we share the state we share the action and",
    "start": "1931120",
    "end": "1936320"
  },
  {
    "text": "now at least from an academic standpoint the way you solve this problem is with a legal election",
    "start": "1937519",
    "end": "1943039"
  },
  {
    "text": "kind of consensus protocol where the strict majority can agree on",
    "start": "1943039",
    "end": "1948720"
  },
  {
    "text": "on the action to be taken and they commit that action and then the others",
    "start": "1948720",
    "end": "1954399"
  },
  {
    "text": "that are followers or were not able to to agree on on the on the action they",
    "start": "1954399",
    "end": "1961279"
  },
  {
    "text": "just have to follow and and do the action later when when they come up online or they",
    "start": "1961279",
    "end": "1966720"
  },
  {
    "text": "are able to join the network um the major um algorithm",
    "start": "1966720",
    "end": "1975120"
  },
  {
    "text": "uh in this in this area are paxos and raft and raft is gaining uh popularity because it's much easier",
    "start": "1975120",
    "end": "1982640"
  },
  {
    "text": "to understand i couldn't even understand it paxos is it's it's just magic",
    "start": "1982640",
    "end": "1990640"
  },
  {
    "text": "uh if you try to read it um and then um there is a shared state consensus",
    "start": "1990640",
    "end": "1998159"
  },
  {
    "text": "protocol where the participants to these orchestrations really are can potentially do",
    "start": "1998159",
    "end": "2005200"
  },
  {
    "text": "different actions so maybe i'm writing to a database and then another participant is sending a message in a queue right so in",
    "start": "2005200",
    "end": "2012480"
  },
  {
    "text": "this case um we have the this historically",
    "start": "2012480",
    "end": "2017600"
  },
  {
    "text": "well-known two-phase commit and three-phase commit algorithm but notice that these algorithms",
    "start": "2017600",
    "end": "2024240"
  },
  {
    "text": "require all of their instances to be online essentially there is no tolerance to network",
    "start": "2024240",
    "end": "2030000"
  },
  {
    "text": "partitioning when you do when you do unshare state consensus protocols and that's it's understandable right we are not",
    "start": "2030000",
    "end": "2036559"
  },
  {
    "text": "doing the same thing so or potentially we are not doing the same thing so we all need to know what we are doing individually",
    "start": "2036559",
    "end": "2042720"
  },
  {
    "text": "we cannot ask later so um there are a couple of",
    "start": "2042720",
    "end": "2051440"
  },
  {
    "text": "papers from google that based on these shifted consensus algorithm you can",
    "start": "2051440",
    "end": "2057679"
  },
  {
    "text": "build a reliable replicated state machine which means there is a generic way of",
    "start": "2057679",
    "end": "2064480"
  },
  {
    "text": "of agreeing on the state and then on top of these and you know",
    "start": "2064480",
    "end": "2070720"
  },
  {
    "text": "then raft does a generic way on agreeing not just on a state but on a series of",
    "start": "2070720",
    "end": "2076398"
  },
  {
    "text": "actions to be taken with the concept of operation log and that's really the state that is being shared",
    "start": "2076399",
    "end": "2082240"
  },
  {
    "text": "between these instances and then every instance has to do the operation that is written in the operation log",
    "start": "2082240",
    "end": "2088398"
  },
  {
    "text": "and then building on top of this concept there is the concept of reliable replicated data store where",
    "start": "2088399",
    "end": "2095760"
  },
  {
    "text": "now the action here is i have i was i have a series of operations i have a log of operation to to do but",
    "start": "2095760",
    "end": "2102320"
  },
  {
    "text": "really the operation is to write something on on on at that store so this is a concept very highly",
    "start": "2102320",
    "end": "2109119"
  },
  {
    "text": "reusable concept that could be implemented generically",
    "start": "2109119",
    "end": "2114720"
  },
  {
    "text": "and then on top of this i could i could put an api to serve some kind of storage uh service",
    "start": "2114720",
    "end": "2122160"
  },
  {
    "text": "right so it could be an api to do q it could be an api to do sql and and",
    "start": "2122160",
    "end": "2127920"
  },
  {
    "text": "all the things we said before and this is as has gone beyond um sorry beyond theory",
    "start": "2127920",
    "end": "2136000"
  },
  {
    "text": "now because if you look at the apache bookkeeper project it's here in the node on the left that is exactly a reliable",
    "start": "2136000",
    "end": "2143040"
  },
  {
    "text": "replicated data store with with uh with the abstraction the operation that they abstract is really",
    "start": "2143040",
    "end": "2151119"
  },
  {
    "text": "the the things that kafka does so append only operation to a sort of file system file",
    "start": "2151119",
    "end": "2158400"
  },
  {
    "text": "and in fact apache apache bookkeeper is being used to implement",
    "start": "2158400",
    "end": "2164640"
  },
  {
    "text": "highly distributed geographically distributed queue system and pulsar if you want to take a look",
    "start": "2164640",
    "end": "2170320"
  },
  {
    "text": "pulsar is one of such implementations so putting it all together",
    "start": "2170320",
    "end": "2178000"
  },
  {
    "text": "um we have we have uh replicas as we know in uh so",
    "start": "2178000",
    "end": "2184960"
  },
  {
    "text": "a stateful workload can have replicas and we we have just studied how we can uh",
    "start": "2184960",
    "end": "2191680"
  },
  {
    "text": "we can coordinate this replica with with boxes or raft and then we can have partitions which is",
    "start": "2191680",
    "end": "2198960"
  },
  {
    "text": "i i partition the data set um so that each each",
    "start": "2198960",
    "end": "2204480"
  },
  {
    "text": "uh each uh group of replicas has to manage um a subset of the of the data set",
    "start": "2204480",
    "end": "2211200"
  },
  {
    "text": "and i do that for being able to scale horizontally right and partitions it's it's in one of",
    "start": "2211200",
    "end": "2218480"
  },
  {
    "text": "those cases where partition a and partition b are doing different things so if i happen to have",
    "start": "2218480",
    "end": "2224000"
  },
  {
    "text": "to coordinate a transaction that touches two partitions there i have to use one of the unshared",
    "start": "2224000",
    "end": "2232240"
  },
  {
    "text": "state protocols okay so i can use chersey protocols between replica i can use a shared state protocol",
    "start": "2232240",
    "end": "2238560"
  },
  {
    "text": "between between uh partitions and that that is how i can",
    "start": "2238560",
    "end": "2243760"
  },
  {
    "text": "create a highly scalable uh highly scalable state of workload",
    "start": "2243760",
    "end": "2251040"
  },
  {
    "text": "distributed state for workload and here i have collected some",
    "start": "2251040",
    "end": "2258480"
  },
  {
    "text": "examples of these these workloads because there are starting to be many um like i said not everything will",
    "start": "2258480",
    "end": "2265599"
  },
  {
    "text": "work in the way that i have described in the initial slide but there are started to be many of these",
    "start": "2265599",
    "end": "2272640"
  },
  {
    "text": "and i try to collect what they do for the replicas and what is the consensus protocol for the replica and what is the",
    "start": "2272640",
    "end": "2278800"
  },
  {
    "text": "consensus protocol for the partition some of them don't support partitions",
    "start": "2278800",
    "end": "2284000"
  },
  {
    "text": "um some of them don't have inter partitions uh operations uh they support partition",
    "start": "2284000",
    "end": "2290400"
  },
  {
    "text": "but you you can only work with a single partition uh at any given time but in general this is um i thought it was a good a",
    "start": "2290400",
    "end": "2298240"
  },
  {
    "text": "good exercise and i thought these are actually the right question to ask if you are",
    "start": "2298240",
    "end": "2303680"
  },
  {
    "text": "examining a state of workload and making the decision whether you want to use it or not",
    "start": "2303680",
    "end": "2309359"
  },
  {
    "text": "this is how you can understand what you can or cannot do in terms of reacting to failure in a in",
    "start": "2309359",
    "end": "2316560"
  },
  {
    "text": "a distributed way okay",
    "start": "2316560",
    "end": "2322640"
  },
  {
    "text": "um the other thing i look sorry could you explain what do you mean by partitioning",
    "start": "2322640",
    "end": "2327680"
  },
  {
    "text": "consensus vertical look what do you mean by so what partition is is the",
    "start": "2327680",
    "end": "2334720"
  },
  {
    "text": "concept of partition clear some using shards some you know it's it's a there are",
    "start": "2334720",
    "end": "2341680"
  },
  {
    "text": "several terminology right but yeah so so um",
    "start": "2341680",
    "end": "2347119"
  },
  {
    "text": "a client may try to do an operation that needs to touch multiple partitions",
    "start": "2347119",
    "end": "2353680"
  },
  {
    "text": "right so far so good yeah um so for example",
    "start": "2353680",
    "end": "2361119"
  },
  {
    "text": "um let's say i think in inelastic search when i uh each index is a different",
    "start": "2361119",
    "end": "2368079"
  },
  {
    "text": "partition or some something similar like that so if i try to add a lot uh any piece of information a",
    "start": "2368079",
    "end": "2375359"
  },
  {
    "text": "document in in two index with a single transaction i need to do that operation across these two",
    "start": "2375359",
    "end": "2382720"
  },
  {
    "text": "partitions right so how do i coordinate that",
    "start": "2382720",
    "end": "2389119"
  },
  {
    "text": "i need i need because the operation is not going to be the same because the partitions they deal with different data sets right so",
    "start": "2389119",
    "end": "2396079"
  },
  {
    "text": "how do i coordinate that that is usually that happens with one of those",
    "start": "2396079",
    "end": "2401280"
  },
  {
    "text": "unshared state coordination protocol",
    "start": "2401280",
    "end": "2408400"
  },
  {
    "text": "did i explain maybe i wasn't very kidding okay um so i guess you know it kind of",
    "start": "2409200",
    "end": "2415839"
  },
  {
    "text": "depends on how you look at it because replicas can also denote partitions or",
    "start": "2415839",
    "end": "2421040"
  },
  {
    "text": "at least but here basically you're meaning if you're doing",
    "start": "2421040",
    "end": "2428240"
  },
  {
    "text": "so look you use the rough term replica to talk about different copies of the same object",
    "start": "2428800",
    "end": "2434640"
  },
  {
    "text": "whereas partition you're talking about grouping of objects",
    "start": "2434640",
    "end": "2439839"
  },
  {
    "text": "or you know operations across different objects so that's what you mean by",
    "start": "2440079",
    "end": "2445680"
  },
  {
    "text": "partitions okay i suppose so let's say let's say my data set goes from a to z right i could say that",
    "start": "2445680",
    "end": "2454720"
  },
  {
    "text": "i want my partitioning to to deal with a a2",
    "start": "2454720",
    "end": "2462240"
  },
  {
    "text": "m say and then partition b to deal with n to z okay so if i divide my data set into",
    "start": "2462240",
    "end": "2469920"
  },
  {
    "text": "different ranges uh my entire data set into different ranges and each partition is",
    "start": "2469920",
    "end": "2476000"
  },
  {
    "text": "is essentially a standalone state of workload just operating on a",
    "start": "2476000",
    "end": "2481920"
  },
  {
    "text": "shorter interval of that data set and they don't have its partition doesn't have to do",
    "start": "2481920",
    "end": "2487440"
  },
  {
    "text": "anything about the other partition except when the client wants to do an operation that logically touches",
    "start": "2487440",
    "end": "2494720"
  },
  {
    "text": "two partitions right if if i'm working only only on on the range from a to m what",
    "start": "2494720",
    "end": "2501680"
  },
  {
    "text": "did i say before m i am just interacting with partition a and i can i just have to make sure that",
    "start": "2501680",
    "end": "2507920"
  },
  {
    "text": "each replica is replicating the state right across the partitioning",
    "start": "2507920",
    "end": "2512960"
  },
  {
    "text": "but if i i'm inserting a a piece of information in in partition a and in partition b at the",
    "start": "2512960",
    "end": "2519440"
  },
  {
    "text": "same time then i have to and i want to do it in a single transaction then i have to find do i have to have a",
    "start": "2519440",
    "end": "2526079"
  },
  {
    "text": "way to make sure that partitioning and partition b agree that they are doing that operation",
    "start": "2526079",
    "end": "2533280"
  },
  {
    "text": "yeah i all right maybe um maybe i see where",
    "start": "2533280",
    "end": "2540160"
  },
  {
    "text": "what what you're sort of pointing out it's i think the use of partitions here is",
    "start": "2540160",
    "end": "2546079"
  },
  {
    "text": "possibly unhelpful from a terminology point of view and maybe it would be easier if we just call them",
    "start": "2546079",
    "end": "2551680"
  },
  {
    "text": "shards simply because you know partitioning as in the verb",
    "start": "2551680",
    "end": "2557520"
  },
  {
    "text": "when applied to the cap theorem is sort of different from partitions when we're referring to",
    "start": "2557520",
    "end": "2563119"
  },
  {
    "text": "a shard so maybe we want to call them shards over here rather than partitions",
    "start": "2563119",
    "end": "2569200"
  },
  {
    "text": "okay yeah i find that",
    "start": "2569200",
    "end": "2575200"
  },
  {
    "text": "each each stateful workload uses a different term for this concept i thought partitioning was the one that",
    "start": "2575839",
    "end": "2582079"
  },
  {
    "text": "in english meant the closest thing but i don't have a problem changing to something else",
    "start": "2582079",
    "end": "2589359"
  },
  {
    "text": "yeah i think when we we we had to in fact this was one of the things that we",
    "start": "2589359",
    "end": "2594480"
  },
  {
    "text": "debated when we were putting the landscape together and we sort of um ended up putting a table",
    "start": "2594480",
    "end": "2601040"
  },
  {
    "text": "to describe um shards and replicated charts and charted",
    "start": "2601040",
    "end": "2608800"
  },
  {
    "text": "replicas as well because different storage systems apply them in different ways um",
    "start": "2608800",
    "end": "2614000"
  },
  {
    "text": "but yeah i think it would just make it easier for everyone if we call them shards on this slide okay i can do that",
    "start": "2614000",
    "end": "2622400"
  },
  {
    "text": "cool taking notes all right um so i'm sorry gentlemen that was",
    "start": "2622400",
    "end": "2629760"
  },
  {
    "text": "asking the question thank you yeah honestly yeah okay cool",
    "start": "2629760",
    "end": "2636800"
  },
  {
    "text": "um so these are just um um some databases uh you know some some stateful workloads",
    "start": "2636800",
    "end": "2643359"
  },
  {
    "text": "that um i have classified along those um",
    "start": "2643359",
    "end": "2648480"
  },
  {
    "text": "parameters um i think we should have more",
    "start": "2648480",
    "end": "2654480"
  },
  {
    "text": "uh but we should extend this table to to more um more products but that's what",
    "start": "2654480",
    "end": "2660640"
  },
  {
    "text": "that's what i have so far um the other thing i um",
    "start": "2660640",
    "end": "2669040"
  },
  {
    "text": "what i have explained so far is really generic and it would work anyway anywhere or",
    "start": "2669040",
    "end": "2676000"
  },
  {
    "text": "with any deployment but i thought we could take a look a closer look to kubernetes",
    "start": "2676000",
    "end": "2682000"
  },
  {
    "text": "and how this would work in kubernetes right so it's essentially the same slide as before",
    "start": "2682000",
    "end": "2687359"
  },
  {
    "text": "except that now there is a kubernetes cluster in which our workload is running",
    "start": "2687359",
    "end": "2695359"
  },
  {
    "text": "so we can we can translate it to more close more closely to kubernetes",
    "start": "2695359",
    "end": "2702480"
  },
  {
    "text": "concepts so we have a persistent we will have a persistent volume we will have ingresses",
    "start": "2702480",
    "end": "2707599"
  },
  {
    "text": "the global load balancer has to um load balance for you know to these",
    "start": "2707599",
    "end": "2713760"
  },
  {
    "text": "ingress or you know ingress is using generic terms this could be a load balancer service or it could be an ingress",
    "start": "2713760",
    "end": "2719680"
  },
  {
    "text": "object and this is where you see better well what i meant",
    "start": "2719680",
    "end": "2724880"
  },
  {
    "text": "by i need to have this east-west cap you know networking capability",
    "start": "2724880",
    "end": "2731119"
  },
  {
    "text": "because building uh building that across clusters is not that it's not necessarily",
    "start": "2731119",
    "end": "2738720"
  },
  {
    "text": "straightforward today with with kubernetes it can depend on the cni",
    "start": "2738720",
    "end": "2745280"
  },
  {
    "text": "implementation that you're using or the cloud where you're running still if you can do it uh you know still",
    "start": "2745280",
    "end": "2752480"
  },
  {
    "text": "this is the a requirement for this database for these workloads to to be able to to be stood up that way",
    "start": "2752480",
    "end": "2761838"
  },
  {
    "text": "okay i'm assuming everybody's familiar with kubernetes not much to say here much else to say",
    "start": "2762319",
    "end": "2771200"
  },
  {
    "text": "i didn't set up the demo i mean i have it set up but i did wasn't planning to run it today i",
    "start": "2773760",
    "end": "2780240"
  },
  {
    "text": "don't know how much time we have uh we i could certainly run a demo in one of the next day but just",
    "start": "2780240",
    "end": "2788079"
  },
  {
    "text": "to explain one of the next meetings just to explain what um what the demo is about i",
    "start": "2788079",
    "end": "2795440"
  },
  {
    "text": "uh we would have this cockroach database that is distributed across",
    "start": "2795440",
    "end": "2801920"
  },
  {
    "text": "clusters in three different uh regions right now my setup is on aws",
    "start": "2801920",
    "end": "2807760"
  },
  {
    "text": "but it could be it could be anything um we deploy",
    "start": "2807760",
    "end": "2813440"
  },
  {
    "text": "a network channel in the case of i'm running an openshift so in the case of network um",
    "start": "2813440",
    "end": "2819760"
  },
  {
    "text": "in the case of openshift we need to deploy a network channel to make this cluster be able to talk to",
    "start": "2819760",
    "end": "2825520"
  },
  {
    "text": "each other in a horizontal way so without doing eagers and ingress like this",
    "start": "2825520",
    "end": "2830560"
  },
  {
    "text": "we are essentially merging the sdns into a single larger",
    "start": "2830560",
    "end": "2836160"
  },
  {
    "text": "software-defined network so that everything is routable and discoverable uh to do that",
    "start": "2836160",
    "end": "2842800"
  },
  {
    "text": "we use a pro we use an operator and a product called submariner which was initially developed by a",
    "start": "2842800",
    "end": "2852160"
  },
  {
    "text": "rancher but now i think is joining the cncf",
    "start": "2852400",
    "end": "2858240"
  },
  {
    "text": "as a product um and that basically it establishes a uh",
    "start": "2858240",
    "end": "2865440"
  },
  {
    "text": "ipsec based vpn across the across the uh sdns of the clusters",
    "start": "2865440",
    "end": "2874400"
  },
  {
    "text": "and then um with i deploy a global load balancer with health checks",
    "start": "2874559",
    "end": "2880240"
  },
  {
    "text": "on route 53 using using an operator that talks to route 53 and and makes this",
    "start": "2880240",
    "end": "2886720"
  },
  {
    "text": "configuration so this from a cockroach perspective we have nine instances",
    "start": "2886720",
    "end": "2892160"
  },
  {
    "text": "because we need uh the way cookers work it's it's better not not mandatory but",
    "start": "2892160",
    "end": "2897680"
  },
  {
    "text": "it's better if you do local",
    "start": "2897680",
    "end": "2901838"
  },
  {
    "text": "what is it called local majority so local leader selection and then global leader",
    "start": "2904160",
    "end": "2910880"
  },
  {
    "text": "selection and then uh so we have nine instances but they behave like a single",
    "start": "2910880",
    "end": "2916640"
  },
  {
    "text": "cross-original entity okay and then the way the demo works is",
    "start": "2916640",
    "end": "2924240"
  },
  {
    "text": "i take down i take down one one region and we see that the clients keep keep just working",
    "start": "2924240",
    "end": "2931920"
  },
  {
    "text": "normally we set up some client here that run the tpcc test which is a standard sql test for highly you know",
    "start": "2931920",
    "end": "2940079"
  },
  {
    "text": "highly transactional operations on a sql database and we we see that obviously we killed this",
    "start": "2940079",
    "end": "2947119"
  },
  {
    "text": "instance but we see that the other instance kept working and this is this could be our stateless",
    "start": "2947119",
    "end": "2955440"
  },
  {
    "text": "frontend but here we're just generating a bunch of transactions",
    "start": "2955440",
    "end": "2960480"
  },
  {
    "text": "hey finally so is is that you know is",
    "start": "2960480",
    "end": "2967119"
  },
  {
    "text": "is some sort of uh network handling like like with submariner um mandatory for this sort of",
    "start": "2967119",
    "end": "2974000"
  },
  {
    "text": "architecture or so the ability so all of these state",
    "start": "2974000",
    "end": "2982079"
  },
  {
    "text": "workloads the way they and then working with others the way they work is each instance need to discover and establish a",
    "start": "2982079",
    "end": "2989280"
  },
  {
    "text": "peer-to-peer connection with all the other ones that's necessary for the raft",
    "start": "2989280",
    "end": "2995520"
  },
  {
    "text": "coordination to work so so discovery and connectivity is needed",
    "start": "2995520",
    "end": "3002559"
  },
  {
    "text": "the way you implement it that's up to you right",
    "start": "3002559",
    "end": "3007519"
  },
  {
    "text": "for example i know that we if you use the if you use the google kubernetes service",
    "start": "3007920",
    "end": "3015200"
  },
  {
    "text": "you can build the cluster and switch a flag where if all the other clusters are in google",
    "start": "3015200",
    "end": "3020880"
  },
  {
    "text": "you know regions they will just be able to talk directly so it's they they give they",
    "start": "3020880",
    "end": "3026800"
  },
  {
    "text": "give it to you but other implementation of or other distribution of kubernetes may not",
    "start": "3026800",
    "end": "3031839"
  },
  {
    "text": "have this capability right so you have to somehow provide it",
    "start": "3031839",
    "end": "3036880"
  },
  {
    "text": "and in uh i can only talk about openshift for this particular capability and obviously if that's how we're doing",
    "start": "3036880",
    "end": "3043280"
  },
  {
    "text": "it right and in this in this instance",
    "start": "3043280",
    "end": "3048960"
  },
  {
    "text": "um in this sorry in this example um the the database",
    "start": "3048960",
    "end": "3056000"
  },
  {
    "text": "has nine nodes total three in each region um",
    "start": "3056000",
    "end": "3062640"
  },
  {
    "text": "does is does that behave like a single logical",
    "start": "3062640",
    "end": "3069599"
  },
  {
    "text": "database is is is is that kind of the the the gist of this here yeah yes it's kind of it's it's just and",
    "start": "3069599",
    "end": "3077599"
  },
  {
    "text": "it's exactly what happens it's actually nice to see that's why maybe next time i'll um uh",
    "start": "3077599",
    "end": "3084960"
  },
  {
    "text": "yeah if you guys want to see this demo i'll be happy to show it to you i'll be very happy to show it to you but",
    "start": "3084960",
    "end": "3090240"
  },
  {
    "text": "yes it's it behaves like a single database for from the client's perspective",
    "start": "3090240",
    "end": "3097040"
  },
  {
    "text": "um could could you highlight on this slide to for just to you know follow the",
    "start": "3097040",
    "end": "3104160"
  },
  {
    "text": "previous slides uh where you're doing your replicas and where you're doing",
    "start": "3104160",
    "end": "3109680"
  },
  {
    "text": "your shards i mean it's pretty obvious it's pretty obvious that you want your",
    "start": "3109680",
    "end": "3115040"
  },
  {
    "text": "replicas in the regions and then you're you're sharding within that but just",
    "start": "3115040",
    "end": "3121680"
  },
  {
    "text": "it would be nice to since you have three and three here it's not clear or obvious",
    "start": "3121680",
    "end": "3127840"
  },
  {
    "text": "[Music] so this is where we start talking about",
    "start": "3127840",
    "end": "3132880"
  },
  {
    "text": "the second generation of state of workload which",
    "start": "3132880",
    "end": "3138000"
  },
  {
    "text": "decide the sharding by themselves so cockroach based on how you use the",
    "start": "3138000",
    "end": "3145040"
  },
  {
    "text": "data can recharge can recharge and can decide how to charge so",
    "start": "3145040",
    "end": "3150559"
  },
  {
    "text": "you can hint when you create tables you can hint how to shard them but you don't have to and it knows what",
    "start": "3150559",
    "end": "3157680"
  },
  {
    "text": "to do it's really really it calls i think",
    "start": "3157680",
    "end": "3163280"
  },
  {
    "text": "they use the name tablets for shards so that's yet another name okay and and it creates its own tablets",
    "start": "3163280",
    "end": "3171200"
  },
  {
    "text": "um you don't have to decide it and these are nine replicas",
    "start": "3171200",
    "end": "3178480"
  },
  {
    "text": "so all the database is re is is fully replicated everywhere except we don't have to have",
    "start": "3178480",
    "end": "3186400"
  },
  {
    "text": "all of these instances agree to in order to proceed with that transaction and that's",
    "start": "3186400",
    "end": "3192800"
  },
  {
    "text": "that's how they can make it efficient um we i did i did this with the cockroach",
    "start": "3192800",
    "end": "3199200"
  },
  {
    "text": "guys and you really for this question you need to talk to them but we run a performance test",
    "start": "3199200",
    "end": "3207040"
  },
  {
    "text": "so keep in mind in um in amazon between is the u.s east and u.s west region there",
    "start": "3207040",
    "end": "3213920"
  },
  {
    "text": "is about 70 milliseconds of latency so that's that's just physics there is",
    "start": "3213920",
    "end": "3220800"
  },
  {
    "text": "nothing you can do around that but um with that kind of latency we",
    "start": "3220800",
    "end": "3225839"
  },
  {
    "text": "were still able to run the tpcc test with 97 efficiency",
    "start": "3225839",
    "end": "3233520"
  },
  {
    "text": "which the tpcc 1000 sorry so that emulating 1000 databases",
    "start": "3233520",
    "end": "3240240"
  },
  {
    "text": "doing uh oltp so highly highly transactional kind of operation so not it's not",
    "start": "3240240",
    "end": "3249119"
  },
  {
    "text": "data warehousing or you know big queries is more insert insert selections to select these kind",
    "start": "3249119",
    "end": "3254160"
  },
  {
    "text": "of things so with that kind of traffic pattern uh emulating one thousand instances we did",
    "start": "3254160",
    "end": "3260400"
  },
  {
    "text": "64 we um sorry 96 which is um",
    "start": "3260400",
    "end": "3267119"
  },
  {
    "text": "which is almost the same that you would get from an analytical database probably more analytical database can do",
    "start": "3267119",
    "end": "3272480"
  },
  {
    "text": "a little bit more but it's it's close to the theoretical limit 100",
    "start": "3272480",
    "end": "3279520"
  },
  {
    "text": "um so they were they were happy with the result uh they",
    "start": "3279520",
    "end": "3284559"
  },
  {
    "text": "they could already do achieve those results running on vms but the exercise you obviously was running",
    "start": "3284559",
    "end": "3291680"
  },
  {
    "text": "on containers and inside of openshift",
    "start": "3291680",
    "end": "3296480"
  },
  {
    "text": "i guess from a concept point of view this this applies to to just about any",
    "start": "3300319",
    "end": "3308319"
  },
  {
    "text": "distributed um storage right if if if you have",
    "start": "3308319",
    "end": "3315200"
  },
  {
    "text": "if you have a logical instance that combines sharding and replicas between the",
    "start": "3315200",
    "end": "3323920"
  },
  {
    "text": "between between sort of multiple cluster instances and you have some sort of network",
    "start": "3324240",
    "end": "3329359"
  },
  {
    "text": "tunneling then this this can apply to potentially distributed file systems key",
    "start": "3329359",
    "end": "3336079"
  },
  {
    "text": "value stores and object stores and so so so you know we can probably",
    "start": "3336079",
    "end": "3341200"
  },
  {
    "text": "make this um a fairly generic play as well right that that's my objective here",
    "start": "3341200",
    "end": "3349359"
  },
  {
    "text": "i i don't think it matters what the stateful workload does what what we are finding a solution for",
    "start": "3349359",
    "end": "3356319"
  },
  {
    "text": "here is replicate state across regions right and um",
    "start": "3356319",
    "end": "3362960"
  },
  {
    "text": "or keep stating sync across the region better uh so i think it can be done with",
    "start": "3362960",
    "end": "3370000"
  },
  {
    "text": "other ap you know interfaces because this is a sql interface right it's a sql",
    "start": "3370000",
    "end": "3375359"
  },
  {
    "text": "service i think it can be done with other type of state of services in fact i would like",
    "start": "3375359",
    "end": "3382880"
  },
  {
    "text": "to be able to showcase this this same architecture with other kind of workloads",
    "start": "3382880",
    "end": "3389440"
  },
  {
    "text": "because it proves the point right the the point right now one might say okay it works",
    "start": "3389520",
    "end": "3396000"
  },
  {
    "text": "with coco cb but it's not a general solution but if i can make it work with other",
    "start": "3396000",
    "end": "3401599"
  },
  {
    "text": "uh products then it starts to be a generic statement more of a generic statement so i'm",
    "start": "3401599",
    "end": "3407119"
  },
  {
    "text": "collaborating with other partners to see if we can recreate the same kind of",
    "start": "3407119",
    "end": "3413359"
  },
  {
    "text": "deployments i guess the part that can vary across different distributed databases or file",
    "start": "3413359",
    "end": "3420720"
  },
  {
    "text": "systems is how they consume this topology so for this demo like how did you convey this",
    "start": "3420720",
    "end": "3426960"
  },
  {
    "text": "topology of you know there are three different availability zones and you know",
    "start": "3426960",
    "end": "3433680"
  },
  {
    "text": "how did you make cockroaches aware of this topology so proper starting happens across azs",
    "start": "3433680",
    "end": "3440960"
  },
  {
    "text": "you know as opposed to within the same age cockroach has some parameters that you need to pass to",
    "start": "3440960",
    "end": "3448240"
  },
  {
    "text": "the process when you run it to make a topology aware so using downward api and other",
    "start": "3448240",
    "end": "3456319"
  },
  {
    "text": "approaches i i make the pod the pods of where or where they run and",
    "start": "3456319",
    "end": "3462480"
  },
  {
    "text": "then and that's how it decides to do the sharding right because like i said it's",
    "start": "3462480",
    "end": "3467680"
  },
  {
    "text": "uh that's it's a nice property of it of that it it does all the sharding i see select",
    "start": "3467680",
    "end": "3474480"
  },
  {
    "text": "the node labels on labels right right um yeah yeah cockroach understands one",
    "start": "3474480",
    "end": "3480079"
  },
  {
    "text": "level of topology um i'm working with another database now gigabyte which understand",
    "start": "3480079",
    "end": "3485200"
  },
  {
    "text": "multiple layers of topology potentially so it understands uh cloud uh region",
    "start": "3485200",
    "end": "3492400"
  },
  {
    "text": "and and az passing these parameters you make it",
    "start": "3492400",
    "end": "3498160"
  },
  {
    "text": "aware of where each instance runs and then they can make a decision on how to distribute the data",
    "start": "3498160",
    "end": "3505280"
  },
  {
    "text": "i guess you know it probably therefore makes sense to have",
    "start": "3506160",
    "end": "3511280"
  },
  {
    "text": "a short section or or a slide or or something to to cover",
    "start": "3511280",
    "end": "3517200"
  },
  {
    "text": "discovery and topology as in you know how the nodes discover each",
    "start": "3517200",
    "end": "3523200"
  },
  {
    "text": "other and how do the nodes um and and how do you kind of um like define the topology somehow",
    "start": "3523200",
    "end": "3531920"
  },
  {
    "text": "somewhere because it could just be it could just be labels but but just as equally right",
    "start": "3531920",
    "end": "3538079"
  },
  {
    "text": "they could be they could be um looking that data up in a discovery service as well",
    "start": "3538079",
    "end": "3544559"
  },
  {
    "text": "right yeah there are yeah um and i think",
    "start": "3544559",
    "end": "3551200"
  },
  {
    "text": "yeah i can create a slide on that i think i talked about that a little bit in the document it started to it",
    "start": "3551200",
    "end": "3559520"
  },
  {
    "text": "it becomes implementation dependent very quickly that that's all i that's the caveat yeah so",
    "start": "3559760",
    "end": "3566960"
  },
  {
    "text": "yeah yeah i'm i'm i'm not suggesting we start to define how they how they do it just that we kind of need",
    "start": "3566960",
    "end": "3574079"
  },
  {
    "text": "to tell people if you're looking to build this oh yeah architecture you you need to",
    "start": "3574079",
    "end": "3579359"
  },
  {
    "text": "figure out how you're going to do your discovery and your topology yeah topology is is a fundamental",
    "start": "3579359",
    "end": "3584799"
  },
  {
    "text": "discovery anthropology are fundamental in in the case of some arena it comes with a discovery service so",
    "start": "3584799",
    "end": "3591520"
  },
  {
    "text": "if i know what what to look up if i know the name of the server you know if i know the",
    "start": "3591520",
    "end": "3596960"
  },
  {
    "text": "name of this these are stateful set right so if i know the name of these individual instances",
    "start": "3596960",
    "end": "3603520"
  },
  {
    "text": "i can look them up from this cluster just because i have a generally distributed discovery",
    "start": "3603520",
    "end": "3610240"
  },
  {
    "text": "service but yes other if you don't use submariner you will have",
    "start": "3610240",
    "end": "3615359"
  },
  {
    "text": "will have a way you need you need a way to do that right um for example celium",
    "start": "3615359",
    "end": "3622799"
  },
  {
    "text": "if you know psyllium is is another cni that you can um you can configure in your kubernetes",
    "start": "3622799",
    "end": "3629920"
  },
  {
    "text": "cluster psilium support network tunnel out of the box so it's a switch that you can",
    "start": "3629920",
    "end": "3637920"
  },
  {
    "text": "turn on i think what is the other famous one uh the",
    "start": "3637920",
    "end": "3644400"
  },
  {
    "text": "other famous cni ah calico yeah i think garlic does this",
    "start": "3644400",
    "end": "3651839"
  },
  {
    "text": "i think calico has the same capability if you if you look into that",
    "start": "3651839",
    "end": "3657839"
  },
  {
    "text": "interesting maybe maybe it's worth pinging um the the sig network",
    "start": "3658880",
    "end": "3666240"
  },
  {
    "text": "and seeing if they have any information about those those",
    "start": "3666240",
    "end": "3671599"
  },
  {
    "text": "product capabilities yeah we can do that and um the multi",
    "start": "3671599",
    "end": "3678720"
  },
  {
    "text": "i think it's the multi-cluster sig but um there is some sig that has defined a standard",
    "start": "3678720",
    "end": "3684880"
  },
  {
    "text": "as a final spec for cross-cluster discovery they don't define the tunneling but they",
    "start": "3684880",
    "end": "3692079"
  },
  {
    "text": "define the cross-cluster discovery and uh submariner implements that spec",
    "start": "3692079",
    "end": "3698318"
  },
  {
    "text": "very cool um we're actually a minute over so i think we're gonna have to call",
    "start": "3702079",
    "end": "3707200"
  },
  {
    "text": "time but but this was um this was brilliant rafael and i think we've got something solid to to to work on",
    "start": "3707200",
    "end": "3715760"
  },
  {
    "text": "okay thank you thanks everyone um and we'll see you all",
    "start": "3716000",
    "end": "3722240"
  },
  {
    "text": "in a couple of bye-bye weeks you thank you rafael",
    "start": "3722240",
    "end": "3728960"
  },
  {
    "text": "bye-bye",
    "start": "3738839",
    "end": "3741839"
  },
  {
    "text": "you",
    "start": "4533440",
    "end": "4535520"
  }
]
[
  {
    "text": "hey everyone I'm Martin stek I go by perk I currently work at canonical but",
    "start": "520",
    "end": "6000"
  },
  {
    "text": "the last four years I've spent at sumic working on the open telemeter collector",
    "start": "6000",
    "end": "12599"
  },
  {
    "text": "offering on the telemeter data uh collection and uh I have this case study",
    "start": "12599",
    "end": "19240"
  },
  {
    "text": "to share with you hey everyone I'm Martin Stak I go by perk I currently",
    "start": "19240",
    "end": "24800"
  },
  {
    "text": "work at canonical but the last four years I've spent at suic working on the",
    "start": "24800",
    "end": "31599"
  },
  {
    "text": "open telemeter collector offering on the telemeter data uh collection and uh I",
    "start": "31599",
    "end": "38440"
  },
  {
    "text": "have this case study to share with you uh to show to to show you the road that",
    "start": "38440",
    "end": "44480"
  },
  {
    "text": "we went uh from from many different collectors or supporting many different",
    "start": "44480",
    "end": "49559"
  },
  {
    "text": "collectors to A single standard and what we found around along the",
    "start": "49559",
    "end": "55000"
  },
  {
    "text": "way if you think about the collectors that are out there there is a collector",
    "start": "55000",
    "end": "60239"
  },
  {
    "text": "to like there are so many different collectors they have different sh shapes and sizes they are they are just",
    "start": "60239",
    "end": "66920"
  },
  {
    "text": "different they have different configuration they have different uh documentation the community is different",
    "start": "66920",
    "end": "72640"
  },
  {
    "text": "they support different Telemetry types uh they have different features it's",
    "start": "72640",
    "end": "78080"
  },
  {
    "text": "just not easy right um uh you might end up with a headache",
    "start": "78080",
    "end": "84439"
  },
  {
    "text": "uh should you be uh chosing The telemetric Collector one telemetric collector because because uh it is not",
    "start": "84439",
    "end": "90040"
  },
  {
    "text": "an easy task maybe you would maybe you think okay I will just choose whatever people are using on the kubernetes and",
    "start": "90040",
    "end": "96680"
  },
  {
    "text": "that would be okay but this is a de facto the facto telemetric collector standard it's still not easy because",
    "start": "96680",
    "end": "103680"
  },
  {
    "text": "there are so many agents again it's it's not like uh one or two uh it's five in",
    "start": "103680",
    "end": "110960"
  },
  {
    "text": "here but it might be more uh and we had this problem at sumic as well uh sumic",
    "start": "110960",
    "end": "117719"
  },
  {
    "text": "started with supporting those and then we figured out that they yeah that doesn't work that well to us we and to",
    "start": "117719",
    "end": "125039"
  },
  {
    "text": "our customers actually we got to do better here H and we ended up with open elemetry let me tell you that story but",
    "start": "125039",
    "end": "133040"
  },
  {
    "text": "where it all started it started with those the facto kubernetes telemeter standards telemeter data collection",
    "start": "133040",
    "end": "140000"
  },
  {
    "text": "standards because that wouldn't be very weird if you thought about your",
    "start": "140000",
    "end": "146640"
  },
  {
    "text": "telemetric collection on kubernetes and you ended up with those right for locks you might use LD right because",
    "start": "146640",
    "end": "152560"
  },
  {
    "text": "it has a lot of plugins the community is there the documentation is there the features are",
    "start": "152560",
    "end": "158080"
  },
  {
    "text": "there it is been written in Ruby and because it is written in Ruby it has its",
    "start": "158080",
    "end": "163480"
  },
  {
    "text": "problems it does the job but it is just a little bit odd I would say uh but you",
    "start": "163480",
    "end": "169760"
  },
  {
    "text": "don't feel that at the very very very beginning so you might be",
    "start": "169760",
    "end": "174800"
  },
  {
    "text": "okay maybe you would use fluent beit right it is crazy fast it has this great memory",
    "start": "174800",
    "end": "180400"
  },
  {
    "text": "right and it is written in C so you you you got to be careful with fixing bux",
    "start": "180400",
    "end": "186799"
  },
  {
    "text": "and also uh introducing new features obviously C is not uh uh is",
    "start": "186799",
    "end": "195400"
  },
  {
    "text": "will never easy as go um so uh it has",
    "start": "195400",
    "end": "200799"
  },
  {
    "text": "its problems um around here then for prom for metrics you",
    "start": "200799",
    "end": "206280"
  },
  {
    "text": "probably end up with promus for good reasons right because promus is a great database it has this community big",
    "start": "206280",
    "end": "212360"
  },
  {
    "text": "Community documentation features it uses memory but it is a database so it needs",
    "start": "212360",
    "end": "218040"
  },
  {
    "text": "to use a memory but what Sumo logic did is sumic used it as a forwarder data",
    "start": "218040",
    "end": "223159"
  },
  {
    "text": "forwarder and I know that right now there is a perit use agent that just that just forwards the",
    "start": "223159",
    "end": "229560"
  },
  {
    "text": "data uh but but that was not the case um a while",
    "start": "229560",
    "end": "234680"
  },
  {
    "text": "ago and when you use it as a forwarder when you used it as a forward back then",
    "start": "234680",
    "end": "239920"
  },
  {
    "text": "uh it had it its problems so for our use case that was a misuse actually we us",
    "start": "239920",
    "end": "245560"
  },
  {
    "text": "this like there's this database but we don't use it as a database that that",
    "start": "245560",
    "end": "250599"
  },
  {
    "text": "sent wrong message actually to to people that were using uh our stock we didn't",
    "start": "250599",
    "end": "257799"
  },
  {
    "text": "have traces at the time and for tracing we were so lucky because exactly at this",
    "start": "257799",
    "end": "264520"
  },
  {
    "text": "point the open Telemetry emerged and when open tet emerged we looked at it and iMed",
    "start": "264520",
    "end": "270120"
  },
  {
    "text": "saw that hey this is very very interesting project it has all of",
    "start": "270120",
    "end": "276400"
  },
  {
    "text": "the uh all of the features that that we need uh and it seems great let's try it",
    "start": "276400",
    "end": "283919"
  },
  {
    "text": "out now why because open Telemetry tries to solve proper problems in the proper",
    "start": "283919",
    "end": "291000"
  },
  {
    "text": "places it gives you the libraries for your languages and it gives you the",
    "start": "291000",
    "end": "297160"
  },
  {
    "text": "collector to collect the data that you have created with your libraries also it",
    "start": "297160",
    "end": "302240"
  },
  {
    "text": "gives you the protocol it gives you the standard it gives you the schema for your metadata for example and it doesn't",
    "start": "302240",
    "end": "309919"
  },
  {
    "text": "give you a back end and what does it mean that it doesn't give you a back end it means that right now the back end",
    "start": "309919",
    "end": "315600"
  },
  {
    "text": "that can be vendor provided we have a lot of vendors out",
    "start": "315600",
    "end": "320680"
  },
  {
    "text": "there that actually would love the idea like they would like to support open tetric they can compete on the back end",
    "start": "320680",
    "end": "326880"
  },
  {
    "text": "right now they don't need to reinvent the wheel on the telemeter data collection and creation they don't need",
    "start": "326880",
    "end": "333560"
  },
  {
    "text": "to create their own libraries they don't need to create their own uh agents and also they all consume the",
    "start": "333560",
    "end": "341160"
  },
  {
    "text": "same type of data so you as a user you don't have to choose at the very beginning and be so much you know um uh",
    "start": "341160",
    "end": "350120"
  },
  {
    "text": "locked into the uh one environment or the other so actually uh this makes a",
    "start": "350120",
    "end": "358000"
  },
  {
    "text": "lot of sense uh because you have the project that is supported by many",
    "start": "358000",
    "end": "363039"
  },
  {
    "text": "vendors by users it is actually hugely popular it is the second one after the kubernetes which is which is uh for the",
    "start": "363039",
    "end": "370520"
  },
  {
    "text": "cncf which is great so like I said openc gives you a specification so it is not a",
    "start": "370520",
    "end": "376479"
  },
  {
    "text": "de facto standard it is like a real standard that has been created before and you don't need to dig into the code to see what what the code is supposed to",
    "start": "376479",
    "end": "383720"
  },
  {
    "text": "do you have this spec for that you have the language sdks with many languages",
    "start": "383720",
    "end": "389599"
  },
  {
    "text": "actually supported and you have collector which is a very very smart",
    "start": "389599",
    "end": "395120"
  },
  {
    "text": "thing because it has those receivers right processors and exporters all of",
    "start": "395120",
    "end": "400240"
  },
  {
    "text": "them all of those are wrapped in pipelines uh and all of those components",
    "start": "400240",
    "end": "405639"
  },
  {
    "text": "can be can be used uh in whatever matter",
    "start": "405639",
    "end": "411160"
  },
  {
    "text": "uh like you can you can compose uh your collector uh using those components you don't you don't need to use whatever is",
    "start": "411160",
    "end": "418240"
  },
  {
    "text": "out there when am I mentioning that because uh there are a couple of dist of the open tetri collector and this is",
    "start": "418240",
    "end": "424160"
  },
  {
    "text": "actually just a little bit of zoo as well hopefully this will be um cleaned up just a little bit more what is this",
    "start": "424160",
    "end": "431599"
  },
  {
    "text": "situation you have this core distribution right which has only the core components uh you might find yourself",
    "start": "431599",
    "end": "438360"
  },
  {
    "text": "pretty quickly in a position when this is not enough and those core components",
    "start": "438360",
    "end": "443440"
  },
  {
    "text": "are just not enough this is not a battery included the batteries included is another distribution called",
    "start": "443440",
    "end": "449919"
  },
  {
    "text": "called contract distribution the problem with that is that even though this is a batter is included open tetric project",
    "start": "449919",
    "end": "456319"
  },
  {
    "text": "says that hey you should not be using that because we don't guarantee anything about the contri and that is very fair",
    "start": "456319",
    "end": "463160"
  },
  {
    "text": "because all the vendors that are contributing those um components to the",
    "start": "463160",
    "end": "468840"
  },
  {
    "text": "contri they need to guarantee that but open Telemetry cannot so there is this",
    "start": "468840",
    "end": "473879"
  },
  {
    "text": "binary but nobody actually you know feel um accountable um for you for it at the",
    "start": "473879",
    "end": "480120"
  },
  {
    "text": "point so what do you do you could use the custom distributions from the",
    "start": "480120",
    "end": "485319"
  },
  {
    "text": "vendors vendors take those components they build their own distributions grafana agent uh takes some of those",
    "start": "485319",
    "end": "491759"
  },
  {
    "text": "components uh don't use the uh doesn't use the open Telemetry internally but that is for good reason like I I've",
    "start": "491759",
    "end": "497919"
  },
  {
    "text": "heard that this helps with the performance uh but we are uh we we are",
    "start": "497919",
    "end": "504680"
  },
  {
    "text": "there to to to to see that hopefully in the future uh then you could use the distributions from sumo or AWS they're",
    "start": "504680",
    "end": "511599"
  },
  {
    "text": "like more uh vanilla distributions they they will have the same configuration as",
    "start": "511599",
    "end": "517159"
  },
  {
    "text": "the core or contri uh and those vendors actually say hey we created those builds those oel",
    "start": "517159",
    "end": "524480"
  },
  {
    "text": "call builds for you you can use them we support them right and you know if you don't like those for any reason you can",
    "start": "524480",
    "end": "531160"
  },
  {
    "text": "actually build your own Custom Distribution as well this is this is fairly easy at this point uh and that is",
    "start": "531160",
    "end": "537480"
  },
  {
    "text": "that is that is a great thing as well you don't need to use uh what is out there you can you can just choose your",
    "start": "537480",
    "end": "544279"
  },
  {
    "text": "uh components so what we did at Sumo we had those agents that we needed to switch",
    "start": "544279",
    "end": "551800"
  },
  {
    "text": "from uh and we started with traces like I said in March 2020 there",
    "start": "551800",
    "end": "558920"
  },
  {
    "text": "was this open Telemetry we thought yes we are going to use that for our tracing and we pretty much quickly pretty",
    "start": "558920",
    "end": "565920"
  },
  {
    "text": "quickly found out that there is this data flood uh attached to the tracing",
    "start": "565920",
    "end": "571079"
  },
  {
    "text": "that is not specifically open Telemetry thing because that is like how traces just are you can create a lot of data",
    "start": "571079",
    "end": "577800"
  },
  {
    "text": "you can do the same with logs and metrics but with traces it just tends to",
    "start": "577800",
    "end": "583360"
  },
  {
    "text": "be uh a lot of data and people are not not prepared for this you can find this",
    "start": "583360",
    "end": "589839"
  },
  {
    "text": "you can fight this uh in two ways you can or actually more but um you can but",
    "start": "589839",
    "end": "597120"
  },
  {
    "text": "but but what we've tried was the filtering uh so you can filter uh some",
    "start": "597120",
    "end": "603079"
  },
  {
    "text": "data but the problem with filtering is that you need to have all of the spans",
    "start": "603079",
    "end": "609079"
  },
  {
    "text": "for a given trays and because you need to have all all of the spans your memory",
    "start": "609079",
    "end": "614120"
  },
  {
    "text": "on this Gateway that does the filtering can actually uh grow up pretty quickly so it's better to do this filtering",
    "start": "614120",
    "end": "620839"
  },
  {
    "text": "probably somewhere on the back end and that is what vendors do they just filter on the back end and you can do sampling",
    "start": "620839",
    "end": "626040"
  },
  {
    "text": "but with sampling you never know how many how much you know how much data you want to sample out",
    "start": "626040",
    "end": "631600"
  },
  {
    "text": "right uh so you probably would like to use both so you would like to have some sampling uh and then filter out",
    "start": "631600",
    "end": "638600"
  },
  {
    "text": "everything that is not um error or or warning for",
    "start": "638600",
    "end": "643959"
  },
  {
    "text": "example uh open Telemetry collector doesn't have a good answer to this as of",
    "start": "643959",
    "end": "649360"
  },
  {
    "text": "now uh unfortunately I hope this will be work on uh in the",
    "start": "649360",
    "end": "655079"
  },
  {
    "text": "future then for the metadata layer we used fluent to enrich the data with the",
    "start": "655079",
    "end": "661279"
  },
  {
    "text": "metadata uh and the fluent had this problem that it was single threaded and because it it was single threaded the",
    "start": "661279",
    "end": "667959"
  },
  {
    "text": "performance was not great was was not great uh what we found out when we swich",
    "start": "667959",
    "end": "673200"
  },
  {
    "text": "to open collector that the goak performance is pretty good especially comparing to Ruby one but the most",
    "start": "673200",
    "end": "680279"
  },
  {
    "text": "important feature here was that when we switched from fluent these two otcs we",
    "start": "680279",
    "end": "686360"
  },
  {
    "text": "removed the back pressure from our promis USS from when it was sending the",
    "start": "686360",
    "end": "691639"
  },
  {
    "text": "data it was sending metrics it was sending it using the remote right and the remote right is a feature that",
    "start": "691639",
    "end": "697920"
  },
  {
    "text": "really really really doesn't like being back pressured unfortunately when you do that your memory consumption goes out of",
    "start": "697920",
    "end": "705519"
  },
  {
    "text": "the roof and it's it is pretty terrible I know that it is being actively worked on and I've heard that it is going to be",
    "start": "705519",
    "end": "711639"
  },
  {
    "text": "fixed which is great uh it was not the case back then uh so so so we had",
    "start": "711639",
    "end": "717480"
  },
  {
    "text": "problems when we switch to OTC C from flend D we stopped having problems with the promis US and also our promis us",
    "start": "717480",
    "end": "725279"
  },
  {
    "text": "memory uh just went down so not only um fluent D memory but also U promise US",
    "start": "725279",
    "end": "733560"
  },
  {
    "text": "memory and here I have some data so across the cluster for the data that",
    "start": "733560",
    "end": "738839"
  },
  {
    "text": "we've sent we needed 38 CPUs of uh for fluentes and then for the same amount of",
    "start": "738839",
    "end": "745120"
  },
  {
    "text": "data we needed only 13 CPUs for uh open telemetric collector uh which is three times that's good",
    "start": "745120",
    "end": "751720"
  },
  {
    "text": "right isn't it then for the memory we went down from 2200 of Gab of ram to just 75 which is",
    "start": "751720",
    "end": "760079"
  },
  {
    "text": "again three times but then we started uh looking uh more into that and we found",
    "start": "760079",
    "end": "766639"
  },
  {
    "text": "out that we can go actually as less as 11 as low as 11 so that is 20 times less",
    "start": "766639",
    "end": "772199"
  },
  {
    "text": "that just you know money that is not being uh burned then with the instance say we",
    "start": "772199",
    "end": "779760"
  },
  {
    "text": "went down from 85 to 20 at the beginning and then even to 11 which is eight times",
    "start": "779760",
    "end": "786920"
  },
  {
    "text": "less and this is important because you don't want to have too many instances poing around your API server on the",
    "start": "786920",
    "end": "792240"
  },
  {
    "text": "ketes uh to get the metadata uh because APA server uh does not like that uh very",
    "start": "792240",
    "end": "800519"
  },
  {
    "text": "much and also if you have huge cluster like really huge cluster this stuff just",
    "start": "800519",
    "end": "805959"
  },
  {
    "text": "start uh matter actually",
    "start": "805959",
    "end": "810760"
  },
  {
    "text": "then we said okay so we we have on traces ofet we switched for metadata it worked it worked okay let's see what we",
    "start": "811000",
    "end": "818040"
  },
  {
    "text": "can do with logs we didn't have that many problems with logs but we wanted to have our uh environment",
    "start": "818040",
    "end": "825600"
  },
  {
    "text": "actually uh homogeneous so even though with the fluent be you have great CPU",
    "start": "825600",
    "end": "831040"
  },
  {
    "text": "and memory usage uh it didn't support metrics and traces at the time it does",
    "start": "831040",
    "end": "837000"
  },
  {
    "text": "now so should it support them back then the story might might have been different actually but but but but but",
    "start": "837000",
    "end": "843759"
  },
  {
    "text": "it isn't we switched to OTC we found out that the C usage is actually very good",
    "start": "843759",
    "end": "849920"
  },
  {
    "text": "memory usage is reasonable especially comparing to the code that is written in C but the most important thing is that",
    "start": "849920",
    "end": "856839"
  },
  {
    "text": "there was no major feature missing so all of the features that we needed were",
    "start": "856839",
    "end": "862360"
  },
  {
    "text": "there some of them if they were missing we just added them our customers similar customers",
    "start": "862360",
    "end": "869320"
  },
  {
    "text": "asked Sumo to add some some features that they've been added uh and some other people actually are contributing",
    "start": "869320",
    "end": "875680"
  },
  {
    "text": "there as well obviously because it's a huge project and it is funny because",
    "start": "875680",
    "end": "880959"
  },
  {
    "text": "sometimes you find yourself in a situation when hey I would like to add this one feature that I find and then",
    "start": "880959",
    "end": "886240"
  },
  {
    "text": "you know you go back after three months because that's when you find out that's when you find time to do this to only",
    "start": "886240",
    "end": "892880"
  },
  {
    "text": "find out that the feature is already there because someone else has added it which is great actually you don't have",
    "start": "892880",
    "end": "898240"
  },
  {
    "text": "to do it anymore more then it's bad because you uh just lost your chance to to contribute that is that is something",
    "start": "898240",
    "end": "905120"
  },
  {
    "text": "that is actually uh funny and very very cool uh about this",
    "start": "905120",
    "end": "911399"
  },
  {
    "text": "project uh then we last but not least switched the back end for metric which",
    "start": "911639",
    "end": "917040"
  },
  {
    "text": "is promethus um like I said we misuse promethus because we use it as a",
    "start": "917040",
    "end": "922120"
  },
  {
    "text": "forwarder it was not a forward back then at the time um and we found out that the",
    "start": "922120",
    "end": "929759"
  },
  {
    "text": "there are some quirks uh around the names there might be some quer like the dot versus underscore you some found out",
    "start": "929759",
    "end": "936519"
  },
  {
    "text": "that they are just different but again the resource users resource usage even though when we stop",
    "start": "936519",
    "end": "944639"
  },
  {
    "text": "back pressuring perit use uh it did not a a lot of ram all of the ram in the",
    "start": "944639",
    "end": "950240"
  },
  {
    "text": "world uh if we still found that open tetric collector uh actually used even",
    "start": "950240",
    "end": "957000"
  },
  {
    "text": "less and one thing one one another thing to add here is that there's this thing",
    "start": "957000",
    "end": "962120"
  },
  {
    "text": "called prous receiver that uh actually helps you get the data like Prometheus",
    "start": "962120",
    "end": "968079"
  },
  {
    "text": "and huge shout out to the team that did that uh it reuses the Prometheus",
    "start": "968079",
    "end": "973440"
  },
  {
    "text": "promethus metrics um inside it works great like you just have this drop in",
    "start": "973440",
    "end": "980519"
  },
  {
    "text": "repl drop in replacement almost you have the same configuration whatever configuration",
    "start": "980519",
    "end": "987079"
  },
  {
    "text": "makes sense in the open tetric World it just works and it's so so easy",
    "start": "987079",
    "end": "992720"
  },
  {
    "text": "to switch uh we are very very happy with that what were the outcomes you know uh",
    "start": "992720",
    "end": "998399"
  },
  {
    "text": "in the numbers uh we went down for CPUs five times and with memory we went down",
    "start": "998399",
    "end": "1006319"
  },
  {
    "text": "five times as well so we were able to switch from those uh agents into the",
    "start": "1006319",
    "end": "1012279"
  },
  {
    "text": "open telemetric collector and now you're able to send all those data to your uh",
    "start": "1012279",
    "end": "1017480"
  },
  {
    "text": "back end or actually bends you don't need to send those to only one bu because all of them actually support",
    "start": "1017480",
    "end": "1023759"
  },
  {
    "text": "open tet as of now uh which is which is a huge win for you as a customer as a",
    "start": "1023759",
    "end": "1029959"
  },
  {
    "text": "user isn't it were there any issues uh yes there",
    "start": "1029959",
    "end": "1036240"
  },
  {
    "text": "were some issues some of there were uh more funny some of them were less funny",
    "start": "1036240",
    "end": "1041798"
  },
  {
    "text": "uh but most of the time I think we survived let me tell you about this one issue for example that when you wanted",
    "start": "1041799",
    "end": "1049120"
  },
  {
    "text": "to get the logs from your file and you had an empty line depending on where",
    "start": "1049120",
    "end": "1054200"
  },
  {
    "text": "this empty line was and how many empty lines you could have your f file not read read twice or read in a loop right",
    "start": "1054200",
    "end": "1062480"
  },
  {
    "text": "so that was yeah yeah that was funny but that was in 2022 this B obviously those",
    "start": "1062480",
    "end": "1067919"
  },
  {
    "text": "bags are not there anymore uh and many others that are so so easy are not there",
    "start": "1067919",
    "end": "1072960"
  },
  {
    "text": "anymore as well and as of now the state is actually good like if you use components that are used",
    "start": "1072960",
    "end": "1079080"
  },
  {
    "text": "uh a lot the bux founder are going to be a lot more sophisticated not long hanging",
    "start": "1079080",
    "end": "1086600"
  },
  {
    "text": "for like at all if you use a component that is not that um uh that that much",
    "start": "1086600",
    "end": "1094640"
  },
  {
    "text": "used uh you know across all of those components you might find bugs there uh",
    "start": "1094640",
    "end": "1100720"
  },
  {
    "text": "but it just life I think is the same for any other project so no surprise here",
    "start": "1100720",
    "end": "1106120"
  },
  {
    "text": "all in all we are actually Su logic is was was very very happy with with the",
    "start": "1106120",
    "end": "1113159"
  },
  {
    "text": "stability of that and uh we didn't hear much much complaining from customers as",
    "start": "1113159",
    "end": "1121240"
  },
  {
    "text": "well that being said I hope that you enjoyed this uh presentation I hope that",
    "start": "1121240",
    "end": "1127640"
  },
  {
    "text": "you feel encouraged to try open tetric collector yourself if you didn't have to if if you if you didn't uh use it as of",
    "start": "1127640",
    "end": "1135320"
  },
  {
    "text": "now um and if you'd like to see the slides that are available here thank you",
    "start": "1135320",
    "end": "1141960"
  },
  {
    "text": "very much and I'll see you around happy",
    "start": "1141960",
    "end": "1146840"
  },
  {
    "text": "collecting hi everybody so we sort of have an extended Q&A for the end um and",
    "start": "1151440",
    "end": "1157440"
  },
  {
    "text": "I also had some data to sort of present because perk had some really interesting",
    "start": "1157440",
    "end": "1164200"
  },
  {
    "text": "insights on the migration path uh going from fluent D to using an open Telemetry",
    "start": "1164200",
    "end": "1169600"
  },
  {
    "text": "collector um interestingly enough let me switch this so everybody can see what I",
    "start": "1169600",
    "end": "1175919"
  },
  {
    "text": "can see is it three three yeah so um if you",
    "start": "1175919",
    "end": "1181400"
  },
  {
    "text": "wanted to look at how the benchmarks were done uh artificially rather than using the um production",
    "start": "1181400",
    "end": "1189440"
  },
  {
    "text": "workload um I made this handy thing and you can look on your phone you can see",
    "start": "1189440",
    "end": "1194799"
  },
  {
    "text": "um some a coworker of ours Matt Rian who had put together um how the tests were",
    "start": "1194799",
    "end": "1201440"
  },
  {
    "text": "actually done uh in an open source environment and I can switch to that",
    "start": "1201440",
    "end": "1208960"
  },
  {
    "text": "now so um there were two different Helm chart versions that were tested here one",
    "start": "1208960",
    "end": "1215000"
  },
  {
    "text": "was the helm chart V well one of the V3 versions versus our uh V2 the V2",
    "start": "1215000",
    "end": "1224000"
  },
  {
    "text": "again was using fluent D directly um I guess some somewhat as like middleware between uh the open Telemetry collector",
    "start": "1224000",
    "end": "1230760"
  },
  {
    "text": "and uh and us and then uh versus using the Sumo logic uh otel collector",
    "start": "1230760",
    "end": "1238520"
  },
  {
    "text": "directly and um Andre here did you want to go through some of",
    "start": "1238520",
    "end": "1244720"
  },
  {
    "text": "this okay so this I think only covers flend D versus open Telemetry collector",
    "start": "1244720",
    "end": "1251760"
  },
  {
    "text": "but the interesting part is that I saw is if you send for for 1 minute is it",
    "start": "1251760",
    "end": "1259760"
  },
  {
    "text": "there if for 1 minute you will be sending 5 megabytes per of logs per",
    "start": "1259760",
    "end": "1265200"
  },
  {
    "text": "second which is 300 megabytes of locks during 1 minute uh this will fluent D",
    "start": "1265200",
    "end": "1272240"
  },
  {
    "text": "will use the whole uh single uh CPU because that's what it's capable to do",
    "start": "1272240",
    "end": "1279279"
  },
  {
    "text": "for 3 and a half minutes so logs have been sent for 1 minute but three and a",
    "start": "1279279",
    "end": "1285400"
  },
  {
    "text": "half minutes of sending by flend D so yeah you can use fluent D of course but",
    "start": "1285400",
    "end": "1292159"
  },
  {
    "text": "you will use a lot of resources and for AEL the same amount of logs it's",
    "start": "1292159",
    "end": "1300679"
  },
  {
    "text": "basically instantaneous and it uses 16% but that's an easy one comparing",
    "start": "1300679",
    "end": "1308360"
  },
  {
    "text": "things to fluent D is an easy target right probably when we would compare to fluent bit it would look completely",
    "start": "1308360",
    "end": "1315600"
  },
  {
    "text": "different maybe not the other way around but that's different I'm not seeing Eduardo Silva here he I think he",
    "start": "1315600",
    "end": "1323120"
  },
  {
    "text": "originally wrote FL bits so he could probably tell fluent bit is definitely very very performant but we actually had",
    "start": "1323120",
    "end": "1331120"
  },
  {
    "text": "really serious issues in big environments and those issues aren't easy to fix because it's C because it's",
    "start": "1331120",
    "end": "1337480"
  },
  {
    "text": "a mature cold based we just hope to not go into that place with the otel",
    "start": "1337480",
    "end": "1343440"
  },
  {
    "text": "collector in the future so perk in his presentation had said that it was about",
    "start": "1343440",
    "end": "1348600"
  },
  {
    "text": "five times uh more efficient in terms of CPU usage and that was with using the um",
    "start": "1348600",
    "end": "1356159"
  },
  {
    "text": "everything under production the way that Matt did uh the benchmarks here was that",
    "start": "1356159",
    "end": "1361840"
  },
  {
    "text": "he actually created uh sort of like a logs Creator logs generator and you can",
    "start": "1361840",
    "end": "1367640"
  },
  {
    "text": "look at the file nerd out at some time whenever if you're curious um and then this was all kind of",
    "start": "1367640",
    "end": "1374279"
  },
  {
    "text": "done uh just to just to run a variety of different benchmarks when they were were um upgrading on different Helm chart",
    "start": "1374279",
    "end": "1381000"
  },
  {
    "text": "versions and you can see that it's consistent uh the data is actually consistent with our production um",
    "start": "1381000",
    "end": "1388400"
  },
  {
    "text": "although I think everybody individually might have different experiences for",
    "start": "1388400",
    "end": "1394640"
  },
  {
    "text": "Prometheus so what there was a very nice talk from Brian borm about Prometheus",
    "start": "1394640",
    "end": "1401200"
  },
  {
    "text": "just couple minutes ago uh I think my takeaway is if you can just don't use",
    "start": "1401200",
    "end": "1407960"
  },
  {
    "text": "Prometheus at all we were using Prometheus as a data forwarder as perk mentioned and we're currently using otel",
    "start": "1407960",
    "end": "1414279"
  },
  {
    "text": "call and it's fine I mean utel call still uses uh Prometheus libraries under",
    "start": "1414279",
    "end": "1419919"
  },
  {
    "text": "the hood when you use Prometheus uh receiver so it's it's still five times",
    "start": "1419919",
    "end": "1425840"
  },
  {
    "text": "better uh but I think ideally in in near future uh the whole world will switch",
    "start": "1425840",
    "end": "1433080"
  },
  {
    "text": "tolp including kubernetes API server and other components and we will not have to",
    "start": "1433080",
    "end": "1439919"
  },
  {
    "text": "scrape those crazy amounts of uh metrics from a one big uh",
    "start": "1439919",
    "end": "1446600"
  },
  {
    "text": "Source yeah Prometheus is a whole other story metrics is a whole other story but",
    "start": "1446600",
    "end": "1451840"
  },
  {
    "text": "um yeah then we'll have we would have to do a whole other set of benchmarks and tests to see uh the improvements on the",
    "start": "1451840",
    "end": "1459520"
  },
  {
    "text": "metric side over the log side um but are there any questions from folks here and",
    "start": "1459520",
    "end": "1465480"
  },
  {
    "text": "you can just go and up or or you can y yelling also works I'm going to",
    "start": "1465480",
    "end": "1473039"
  },
  {
    "text": "ask so um this is what is the output there is it always OTP sorry uh what is",
    "start": "1473039",
    "end": "1479679"
  },
  {
    "text": "the output is it always OTP because U we we did some other tests",
    "start": "1479679",
    "end": "1484960"
  },
  {
    "text": "there at grafana and ingesting promethus and outputting promethus is always going",
    "start": "1484960",
    "end": "1491840"
  },
  {
    "text": "to be more performant with the promeal agent than with the collector we output o sorry yeah so you convert Prometheus",
    "start": "1491840",
    "end": "1500440"
  },
  {
    "text": "to LLP and then you speed out LLP M the the tests here are with logs so we would",
    "start": "1500440",
    "end": "1506799"
  },
  {
    "text": "have to like so the tests here with logs we'd have to like create a whole other test bench based on our newest helmar",
    "start": "1506799",
    "end": "1514159"
  },
  {
    "text": "deployment that was just announced this morning um against the prior one which was using prometheus's middleware so the",
    "start": "1514159",
    "end": "1522039"
  },
  {
    "text": "the performance gains uh would be like I I mean we we would have to just run the benchmarks so",
    "start": "1522039",
    "end": "1528960"
  },
  {
    "text": "we don't have that data on hand right now we can talk about what happened in production right in production we",
    "start": "1528960",
    "end": "1534279"
  },
  {
    "text": "already had previously replace the metadata layer uh with with open tetric collector we knew that we want",
    "start": "1534279",
    "end": "1540480"
  },
  {
    "text": "everything to be AEL so we needed with uh the the the setup with the metadata",
    "start": "1540480",
    "end": "1547679"
  },
  {
    "text": "layer replaced was that Prometheus would scrape and it would sent over remote right to the remote right receiver from",
    "start": "1547679",
    "end": "1554600"
  },
  {
    "text": "Al telemetric collector and we replaced it with the oel that scrapes with the promethus receiver and sends out with",
    "start": "1554600",
    "end": "1560559"
  },
  {
    "text": "the LLP exporter so I got two quick questions oh",
    "start": "1560559",
    "end": "1566440"
  },
  {
    "text": "is on so um two quick ones really the first one there was a talk about moving from",
    "start": "1566440",
    "end": "1572279"
  },
  {
    "text": "metrics and you know we looked not too much but we looked in early 2022 at uh",
    "start": "1572279",
    "end": "1580279"
  },
  {
    "text": "open Telemetry we were going to use some of that for tracing and we looked at it for metrics and they had the metrics",
    "start": "1580279",
    "end": "1586760"
  },
  {
    "text": "when you're talking about the generic kind of system metrics but they didn't",
    "start": "1586760",
    "end": "1592039"
  },
  {
    "text": "have the maturity say of something like a telegraph agent and it felt like we were going to put open Telemetry on only",
    "start": "1592039",
    "end": "1599399"
  },
  {
    "text": "to then talk to something like a telegraph that we end up writing ourselves to get a lot of the metrics",
    "start": "1599399",
    "end": "1604799"
  },
  {
    "text": "out and so it it felt kind of a backward step to try and reduce the number of you",
    "start": "1604799",
    "end": "1610200"
  },
  {
    "text": "know branded agents say on the Node um I I don't know what your thoughts are now about that because I haven't looked",
    "start": "1610200",
    "end": "1616600"
  },
  {
    "text": "again but it was it was very generic the amount they got and it wasn't really mature like a metric service and then",
    "start": "1616600",
    "end": "1623399"
  },
  {
    "text": "secondly a follow on question how does this work at scale so Prometheus Works",
    "start": "1623399",
    "end": "1629799"
  },
  {
    "text": "quite well at scale when you isolate them you see across different clusters and then you have them forward on and",
    "start": "1629799",
    "end": "1635640"
  },
  {
    "text": "then maybe you leverage something like a Thanos or something on the back end but really those two questions then kind of",
    "start": "1635640",
    "end": "1641440"
  },
  {
    "text": "unrelated but just to save me getting up again uh what were your thoughts around",
    "start": "1641440",
    "end": "1646520"
  },
  {
    "text": "those uh what was the first one ah so uh yeah",
    "start": "1646520",
    "end": "1652559"
  },
  {
    "text": "un stressed yeah that's right uh open Telemetry it's funny is like we're fully off of no longer talking about fluent",
    "start": "1652559",
    "end": "1658159"
  },
  {
    "text": "bit and fluent D we're now fully talking about prome the presentation sorry metric maturity metric yeah yeah so the",
    "start": "1658159",
    "end": "1664039"
  },
  {
    "text": "maturity of metrics in open Telemetry well you know Telegraph has been around for what 10 years I don't know the pr is",
    "start": "1664039",
    "end": "1671120"
  },
  {
    "text": "same uh so open Telemetry compared to that is just not as mature and yeah I",
    "start": "1671120",
    "end": "1677200"
  },
  {
    "text": "agree with that what we did at s logic is what I wouldn't recommend we deviced",
    "start": "1677200",
    "end": "1683320"
  },
  {
    "text": "a telegraph receiver where you can use Telegraph inputs uh but integrating the",
    "start": "1683320",
    "end": "1689000"
  },
  {
    "text": "telegraph codebase with the open Tel code base is not easy because you need to import a lot of stuff and that makes",
    "start": "1689000",
    "end": "1696279"
  },
  {
    "text": "sense though because that gets around that maturity problem doesn't it okay cool yeah that was our way of doing this",
    "start": "1696279",
    "end": "1701480"
  },
  {
    "text": "but we it's a pain so ideally we just try to contribute everything into the upstream and WI encourage anyone to",
    "start": "1701480",
    "end": "1708919"
  },
  {
    "text": "contribute more that's that's my answer and and then from the scaling perspective when you've got all those",
    "start": "1708919",
    "end": "1713960"
  },
  {
    "text": "open Telemetry agents fing stuff on so imagine you've got you know a million of those little things chatting and trying",
    "start": "1713960",
    "end": "1719440"
  },
  {
    "text": "to F them on how how does that work at scale understand how Prometheus works at scale I'm just",
    "start": "1719440",
    "end": "1725559"
  },
  {
    "text": "wondering well you know if in terms of metrics uh otel call uses U preus",
    "start": "1725559",
    "end": "1732039"
  },
  {
    "text": "receiver that's one the other thing it's I think it's much easier to Shard it or to uh",
    "start": "1732039",
    "end": "1738760"
  },
  {
    "text": "to to share it what we use in kubernetes we use the open Telemetry operator with",
    "start": "1738760",
    "end": "1743799"
  },
  {
    "text": "the Target allocator and we Shard the all the scrapes among as many collectors",
    "start": "1743799",
    "end": "1749919"
  },
  {
    "text": "as we want it's much easier with Hotel collector actually uh I'm talking about",
    "start": "1749919",
    "end": "1755600"
  },
  {
    "text": "the kubernetes specifically with Target allocator Autry operator this is much",
    "start": "1755600",
    "end": "1762600"
  },
  {
    "text": "easier to uh scale the load than with Prometheus okay all right I think we're",
    "start": "1762600",
    "end": "1768039"
  },
  {
    "text": "close to time anyway but I if anyone else had questions let us know",
    "start": "1768039",
    "end": "1773399"
  },
  {
    "text": "um maybe not well I'm going to do like one last",
    "start": "1773399",
    "end": "1778519"
  },
  {
    "text": "Shameless plug which is if anyone wants to look at this ebook um it's free and",
    "start": "1778519",
    "end": "1784200"
  },
  {
    "text": "you can learn to navigate kubernetes monitoring with it and then I'll give people two seconds",
    "start": "1784200",
    "end": "1790200"
  },
  {
    "text": "for that and then we might just move on to the next thing because Austin's like get off the stage I'm getting the",
    "start": "1790200",
    "end": "1795600"
  },
  {
    "text": "hook thanks [Applause]",
    "start": "1795600",
    "end": "1801320"
  },
  {
    "text": "you",
    "start": "1801320",
    "end": "1804320"
  }
]
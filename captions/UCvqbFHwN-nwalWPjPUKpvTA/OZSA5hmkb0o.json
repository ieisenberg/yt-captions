[
  {
    "start": "0",
    "end": "103000"
  },
  {
    "text": "okay it's time to get started thank you guys for coming so I'm Daniel white knack I'm work for a company called",
    "start": "30",
    "end": "6750"
  },
  {
    "text": "pachyderm you'll hear more about that project a little bit later but today I'm gonna be talking to you about building",
    "start": "6750",
    "end": "13200"
  },
  {
    "text": "GPU accelerated workflows with tensor flow and kubernetes which is this really long title I should have made it more",
    "start": "13200",
    "end": "21050"
  },
  {
    "text": "shorter and more exciting but but hopefully the talk will be exciting so it's a great set up in the last talk",
    "start": "21050",
    "end": "27840"
  },
  {
    "text": "talking about you know some of the challenges around using GPUs on a data",
    "start": "27840",
    "end": "33180"
  },
  {
    "text": "science team and how you could actually offload like model training on to a GPU",
    "start": "33180",
    "end": "40579"
  },
  {
    "text": "on kubernetes this talk is going to be related but you know it's it's going to",
    "start": "40579",
    "end": "49110"
  },
  {
    "text": "be have a slightly different spin so really what I'm gonna be talking about the key word here is workflows so",
    "start": "49110",
    "end": "54390"
  },
  {
    "text": "oftentimes running model training isn't",
    "start": "54390",
    "end": "59730"
  },
  {
    "text": "the only piece of the puzzle right actually it's only a very small piece of",
    "start": "59730",
    "end": "64768"
  },
  {
    "text": "a very much larger puzzle which includes a lot of pre-processing of data it",
    "start": "64769",
    "end": "71130"
  },
  {
    "text": "includes training it includes inference it includes post-processing and includes visualization and what I'm going to try",
    "start": "71130",
    "end": "78720"
  },
  {
    "text": "to get across to you guys today is how we run all of that together on",
    "start": "78720",
    "end": "84780"
  },
  {
    "text": "kubernetes while still being able to offload those important pieces to the",
    "start": "84780",
    "end": "90659"
  },
  {
    "text": "GPUs when we need to utilize them and so we've worked with a bunch of different",
    "start": "90659",
    "end": "96720"
  },
  {
    "text": "users and clients to do this so what I'm gonna describe is kind of how how we do that to that end I'm gonna start by",
    "start": "96720",
    "end": "104520"
  },
  {
    "start": "103000",
    "end": "172000"
  },
  {
    "text": "talking about like my my picture of this kind of bigger bigger data pipeline",
    "start": "104520",
    "end": "110030"
  },
  {
    "text": "scenario where a piece of that is model training on a GPU but it's it's more and",
    "start": "110030",
    "end": "115229"
  },
  {
    "text": "then we're gonna you know obviously as part of that talk about where the GPU comes into play then we're gonna talk",
    "start": "115229",
    "end": "122759"
  },
  {
    "text": "about why kubernetes is so good at managing this sort of thing and what if anything we need to",
    "start": "122759",
    "end": "130080"
  },
  {
    "text": "add on on top of kubernetes to be to support this sort of workflow and",
    "start": "130080",
    "end": "135810"
  },
  {
    "text": "then all of you guys are a technical crowd so I know you won't believe any of",
    "start": "135810",
    "end": "141540"
  },
  {
    "text": "that so then I'm going to go right in and do a live demo and we're going to try to deploy a bunch of tensorflow and",
    "start": "141540",
    "end": "151380"
  },
  {
    "text": "data processing stuff on kubernetes and switch between CPU and GPU nodes and you",
    "start": "151380",
    "end": "157590"
  },
  {
    "text": "know fingers crossed that goes ok so it's that sound ok everybody good",
    "start": "157590",
    "end": "163230"
  },
  {
    "text": "I mean that's the only talk I have so I mean you can like exit now if you want",
    "start": "163230",
    "end": "168600"
  },
  {
    "text": "to hear something different all right well let's go ahead and get started so",
    "start": "168600",
    "end": "173880"
  },
  {
    "start": "172000",
    "end": "234000"
  },
  {
    "text": "in my mind again like the the typical workflow for a data science team or an",
    "start": "173880",
    "end": "181080"
  },
  {
    "text": "analytics team is very much you know broader than just model",
    "start": "181080",
    "end": "186810"
  },
  {
    "text": "training that that gets a lot of attention because that's kind of I guess the cool part right but actually there's",
    "start": "186810",
    "end": "193050"
  },
  {
    "text": "really really a struggle around managing the pipeline as a whole and actually I",
    "start": "193050",
    "end": "199799"
  },
  {
    "text": "think this this problem is really crucial because if you can't handle like all these pre-processing things and then",
    "start": "199799",
    "end": "207030"
  },
  {
    "text": "get the data to the GPU and you need to and handle all the post-processing things and be able to share those",
    "start": "207030",
    "end": "212640"
  },
  {
    "text": "resources and also be able to reproduce certain analyses and hand them off to other parts of the team then you're",
    "start": "212640",
    "end": "219720"
  },
  {
    "text": "really gonna struggle to create value in a business so I'm going to share like kind of an example so this is by this is",
    "start": "219720",
    "end": "226380"
  },
  {
    "text": "very much an example it's not you know the the things that we'll talk about today will apply in many more examples",
    "start": "226380",
    "end": "233549"
  },
  {
    "text": "but one of the example of this is like processing images and maybe doing some object detection so in like this sort of",
    "start": "233549",
    "end": "241890"
  },
  {
    "start": "234000",
    "end": "295000"
  },
  {
    "text": "workflow we might start with like a raw data set of images from somewhere let's",
    "start": "241890",
    "end": "247799"
  },
  {
    "text": "say it let's not worry about where they come from but we have access to this raw data set of images the first thing that",
    "start": "247799",
    "end": "254459"
  },
  {
    "text": "we probably need to do is pre process those somehow so maybe our like model",
    "start": "254459",
    "end": "260609"
  },
  {
    "text": "needs to take those in in a certain format or a certain size or maybe we need to like pair the",
    "start": "260609",
    "end": "266600"
  },
  {
    "text": "with other images or label them or format them or tag them in some way anyway there's a lot of different",
    "start": "266600",
    "end": "272330"
  },
  {
    "text": "pre-processing that we might want to do and out of that pre-processing then we might get a set of of nice images that",
    "start": "272330",
    "end": "279500"
  },
  {
    "text": "we want to feed into our model training and I've represented this here by one stage but often times like when we work",
    "start": "279500",
    "end": "285950"
  },
  {
    "text": "with people this you know could be 15 stages of pre-processing right developed",
    "start": "285950",
    "end": "291050"
  },
  {
    "text": "by like three different people in a team right okay then we have the cool model",
    "start": "291050",
    "end": "298040"
  },
  {
    "start": "295000",
    "end": "403000"
  },
  {
    "text": "training stage which takes in that data train some type of model maybe a neural",
    "start": "298040",
    "end": "304040"
  },
  {
    "text": "net and oftentimes like I think last week people or last night people raised their hand a lot of people are using",
    "start": "304040",
    "end": "309590"
  },
  {
    "text": "tensorflow that's why I'm gonna be talking about using tensorflow but again",
    "start": "309590",
    "end": "314600"
  },
  {
    "text": "this is an example so this would apply to any framework that you're wanting to use whether that be tensorflow or cafe",
    "start": "314600",
    "end": "320600"
  },
  {
    "text": "or whatever and so we're gonna train our model using that framework on that input pre process to input we're gonna maybe",
    "start": "320600",
    "end": "327680"
  },
  {
    "text": "serialize a model or export it in in some way such that we can use that model",
    "start": "327680",
    "end": "333340"
  },
  {
    "text": "for inference so we're not gonna retrain our model every time an image comes in",
    "start": "333340",
    "end": "338990"
  },
  {
    "text": "that we need to do object detection on we need to like serve that model somehow like tensorflow serving or other things",
    "start": "338990",
    "end": "347120"
  },
  {
    "text": "so we this is kind of a separate stage and I hate I haven't even added in after",
    "start": "347120",
    "end": "352430"
  },
  {
    "text": "this like if there's post processing right so here I've already kind of got these three distinct phases I've left",
    "start": "352430",
    "end": "358940"
  },
  {
    "text": "out post processing and these could be expanded into multiple other stages right so you can start to see that this",
    "start": "358940",
    "end": "365150"
  },
  {
    "text": "can be a little bit of an orchestration nightmare and this is why oftentimes me as a data",
    "start": "365150",
    "end": "372740"
  },
  {
    "text": "scientist and I start talking to you know DevOps people and infrastructure people and they say I'm a data scientist",
    "start": "372740",
    "end": "378860"
  },
  {
    "text": "then they kind of just like start walking away and they don't really like me so much anymore but it is a challenge",
    "start": "378860",
    "end": "386690"
  },
  {
    "text": "especially you know utilizing multiple frameworks you're utilizing weird frameworks that the rest of an",
    "start": "386690",
    "end": "392120"
  },
  {
    "text": "engineering organization doesn't understand and you have these like multistage distributed things that",
    "start": "392120",
    "end": "399240"
  },
  {
    "text": "to be managed and updated over time okay so we again here we have the these kind",
    "start": "399240",
    "end": "406319"
  },
  {
    "start": "403000",
    "end": "470000"
  },
  {
    "text": "of three distinct stages so let's let's talk about like where where GPUs come",
    "start": "406319",
    "end": "411840"
  },
  {
    "text": "into that so actually most of the time",
    "start": "411840",
    "end": "417599"
  },
  {
    "text": "so I'm not like saying a general statement here but most of the time people utilize GPUs for model training",
    "start": "417599",
    "end": "423900"
  },
  {
    "text": "as was mentioned in the previous talk so here we actually have two stages that",
    "start": "423900",
    "end": "430020"
  },
  {
    "text": "will run just fine on CPU nodes so like basically our whole workflow however",
    "start": "430020",
    "end": "436169"
  },
  {
    "text": "many stages we do for pre-processing and inference let's say that we can run that on on CPUs and then we have this one",
    "start": "436169",
    "end": "443669"
  },
  {
    "text": "stage that we want to that we want to run on a GPU node this is pretty",
    "start": "443669",
    "end": "450270"
  },
  {
    "text": "essential for a lot of teams that are they're building models at large scale they they need to run this training on a",
    "start": "450270",
    "end": "458909"
  },
  {
    "text": "GPU but they also need to interface that with these other stages of",
    "start": "458909",
    "end": "464789"
  },
  {
    "text": "pre-processing post-processing inference and all of that stuff okay so that's",
    "start": "464789",
    "end": "474389"
  },
  {
    "start": "470000",
    "end": "520000"
  },
  {
    "text": "kind of the the general picture that I wanted to have in your mind so really I",
    "start": "474389",
    "end": "479460"
  },
  {
    "text": "mean we know from previous talks and more talks that will be today and other",
    "start": "479460",
    "end": "484469"
  },
  {
    "text": "things you've seen online that we can we can utilize GPUs in kubernetes but",
    "start": "484469",
    "end": "490880"
  },
  {
    "text": "really like I don't think there's a lot of content out there and tooling around",
    "start": "490880",
    "end": "496740"
  },
  {
    "text": "actually managing this sort of workflow on top of on top of kubernetes outside",
    "start": "496740",
    "end": "502530"
  },
  {
    "text": "of scheduling the individual pieces so that's that's really what I want to focus on is like enabling this workflow",
    "start": "502530",
    "end": "510090"
  },
  {
    "text": "and then also being able to get those necessary stages that need some sort of",
    "start": "510090",
    "end": "515459"
  },
  {
    "text": "acceleration on two on two GPUs when we need them okay",
    "start": "515459",
    "end": "521399"
  },
  {
    "start": "520000",
    "end": "780000"
  },
  {
    "text": "so again let's say that we have these these few stages just generally well I",
    "start": "521399",
    "end": "529620"
  },
  {
    "text": "mean one of the things that we need to do is need to make these stages portable right",
    "start": "529620",
    "end": "535130"
  },
  {
    "text": "and I'm kind of preaching to the choir here but you guys understand like I can I can docker eyes these these different",
    "start": "535130",
    "end": "542060"
  },
  {
    "text": "stages and run them in any sort of environment and that's that's great and I like not having to convince you of",
    "start": "542060",
    "end": "548930"
  },
  {
    "text": "that in this conference because a lot of times I have to convince people that in data science conferences but you guys",
    "start": "548930",
    "end": "555140"
  },
  {
    "text": "understand that so this this is a way that we can package things up and and get them running with you know",
    "start": "555140",
    "end": "561470"
  },
  {
    "text": "reproducible behavior in another environment but again we don't want to you know we don't want to be like SSA",
    "start": "561470",
    "end": "569330"
  },
  {
    "text": "Qing and the machines and deploying these things manually all right so kubernetes you know among other things I",
    "start": "569330",
    "end": "576710"
  },
  {
    "text": "can't you know I don't have time to go over all the benefits but again I'm",
    "start": "576710",
    "end": "581720"
  },
  {
    "text": "preaching to the choir somewhat here right kubernetes gives us this great and awesome framework for being able to take",
    "start": "581720",
    "end": "588650"
  },
  {
    "text": "these stages and deploy them not only on the cpu nodes but on GPU nodes in a very",
    "start": "588650",
    "end": "595580"
  },
  {
    "text": "descriptive way where I can say you know I I want these certain workloads defined",
    "start": "595580",
    "end": "600650"
  },
  {
    "text": "by these containers to run on these types of nodes and then guess what it happens and that's that's really great",
    "start": "600650",
    "end": "608290"
  },
  {
    "text": "so we have up to this point in in this picture we've made our individual",
    "start": "608290",
    "end": "615850"
  },
  {
    "text": "processing stages portable right and we've actually made deploying all of",
    "start": "615850",
    "end": "622070"
  },
  {
    "text": "them together portable because we can run kubernetes anywhere right your data scientists can develop these things you",
    "start": "622070",
    "end": "628490"
  },
  {
    "text": "can deploy kubernetes where you want on whatever infrastructure you want and then deploy the set of things on",
    "start": "628490",
    "end": "633740"
  },
  {
    "text": "kubernetes but that's actually not that's not the the only key so so what",
    "start": "633740",
    "end": "640820"
  },
  {
    "text": "am I missing someone someone tell me so",
    "start": "640820",
    "end": "646070"
  },
  {
    "text": "so let's say that let's say that like the model inference that's some type of serving thing okay so like outside of",
    "start": "646070",
    "end": "653000"
  },
  {
    "text": "the functionality of each of these pieces like operationally what am I",
    "start": "653000",
    "end": "658940"
  },
  {
    "text": "missing to enable that workflow that I discussed before what now",
    "start": "658940",
    "end": "665310"
  },
  {
    "text": "the linkage between stages right what else lifecycle management updating that",
    "start": "665310",
    "end": "672660"
  },
  {
    "text": "sort of thing what else data yeah so so the first the first one",
    "start": "672660",
    "end": "678060"
  },
  {
    "text": "that comes to my mind right is I deploy these containers here and I I am a data",
    "start": "678060",
    "end": "684149"
  },
  {
    "text": "scientist so I want to process data where is the data right I have to somehow get the right data to the right",
    "start": "684149",
    "end": "690779"
  },
  {
    "text": "code right and maybe like let's say that's stored in an object store that's",
    "start": "690779",
    "end": "696029"
  },
  {
    "text": "what was talked about in the last talk as well let's say our data isn't an object store so somehow I need to get",
    "start": "696029",
    "end": "704899"
  },
  {
    "text": "the right pieces of data which aren't everything that's stored in the objects",
    "start": "704899",
    "end": "710790"
  },
  {
    "text": "all right I need to get the right pieces of data to the right pods to be",
    "start": "710790",
    "end": "716160"
  },
  {
    "text": "processed okay and then there's the element of the linkage that was mentioned right actually that's that's",
    "start": "716160",
    "end": "722699"
  },
  {
    "text": "not all right I need to get the right data to the right code and I need to run",
    "start": "722699",
    "end": "728850"
  },
  {
    "text": "those steps of processing in a very specific predefined sequence right for",
    "start": "728850",
    "end": "734910"
  },
  {
    "text": "things to go right and and so like kubernetes provides this really great",
    "start": "734910",
    "end": "741509"
  },
  {
    "text": "framework and foundation but similar to like you know how like Borg is different",
    "start": "741509",
    "end": "748259"
  },
  {
    "text": "in Google than what kubernetes is and Borg includes a bunch of these pieces that fills gaps in the context of what",
    "start": "748259",
    "end": "755309"
  },
  {
    "text": "Google is doing and then there's kubernetes and in industry it you know it doesn't it doesn't offer us",
    "start": "755309",
    "end": "760649"
  },
  {
    "text": "everything we need you know we we might want to use like vault for secret management or sto for for service mesh",
    "start": "760649",
    "end": "768870"
  },
  {
    "text": "right so somehow we need to like fill this this gap of like getting the right",
    "start": "768870",
    "end": "775110"
  },
  {
    "text": "data to the right code in the right order on the right notes right so so",
    "start": "775110",
    "end": "781110"
  },
  {
    "start": "780000",
    "end": "894000"
  },
  {
    "text": "really what I'm what I'm saying is like kubernetes is great for ml because you",
    "start": "781110",
    "end": "788160"
  },
  {
    "text": "know we can have this portability we can have scalability we can have you know Auto scale all of these great things",
    "start": "788160",
    "end": "795689"
  },
  {
    "text": "that you guys that's why you're here and those things are directly applicable",
    "start": "795689",
    "end": "800769"
  },
  {
    "text": "to machine learning but we need a little extra sugar okay and this extra sugar is",
    "start": "800769",
    "end": "808810"
  },
  {
    "text": "actually really important and and not that trivial so we need to get the right",
    "start": "808810",
    "end": "813880"
  },
  {
    "text": "data to the right code we need to process the right data with the right",
    "start": "813880",
    "end": "819459"
  },
  {
    "text": "code on the right nodes right so whether that be a CPU work work load or a GPU",
    "start": "819459",
    "end": "825940"
  },
  {
    "text": "workload and we need to trigger the right code at the right time with the",
    "start": "825940",
    "end": "832690"
  },
  {
    "text": "right data on the right nodes you guys you guys get the idea so the this is really this this is really what I",
    "start": "832690",
    "end": "841300"
  },
  {
    "text": "believe you know we we need and what our team believes we need but as was",
    "start": "841300",
    "end": "847600"
  },
  {
    "text": "mentioned up front here so this is like operationally kind of what we need to",
    "start": "847600",
    "end": "853390"
  },
  {
    "text": "enable this it would be nice as a bonus as well oops to be able to actually have some",
    "start": "853390",
    "end": "860709"
  },
  {
    "text": "concept of maintaining this overtime and making sure that we do it in a sustainable way which also means that we",
    "start": "860709",
    "end": "868480"
  },
  {
    "text": "need to be somehow tracking what's going on we need to be versioning what data",
    "start": "868480",
    "end": "874630"
  },
  {
    "text": "ran with what code on what nodes at what time and we need especially if you're",
    "start": "874630",
    "end": "880990"
  },
  {
    "text": "working with like health care or finance data we need to stay compliant and be able to be able to reproduce and have",
    "start": "880990",
    "end": "889480"
  },
  {
    "text": "the provenance of what we did at what what points in time so all this together",
    "start": "889480",
    "end": "895390"
  },
  {
    "start": "894000",
    "end": "946000"
  },
  {
    "text": "is what what we put together in the open source project pachyderm so pachyderm is",
    "start": "895390",
    "end": "903220"
  },
  {
    "text": "the open source data pipelining and data management layer on top of kubernetes so",
    "start": "903220",
    "end": "910750"
  },
  {
    "text": "what I really mean by that is there's data pipelining and there's data management so we need to get the right",
    "start": "910750",
    "end": "917110"
  },
  {
    "text": "data to the right code which is related to this sequence sequence of things and and data pipelining",
    "start": "917110",
    "end": "924220"
  },
  {
    "text": "we also need to somehow manage that data we need to shim the right data to the",
    "start": "924220",
    "end": "931120"
  },
  {
    "text": "right we need to collect output data right so all of these pieces that enable what we",
    "start": "931120",
    "end": "937930"
  },
  {
    "text": "talked about before getting the right data to the right code on the right nodes at the right time this is that",
    "start": "937930",
    "end": "943449"
  },
  {
    "text": "that layer for kubernetes so the pieces",
    "start": "943449",
    "end": "948730"
  },
  {
    "start": "946000",
    "end": "1183000"
  },
  {
    "text": "of of pachyderm that enable this our first data versioning so all data that's",
    "start": "948730",
    "end": "957010"
  },
  {
    "text": "processed in pachyderm is version controlled so kind of think like get get for data you can set up collections of",
    "start": "957010",
    "end": "964510"
  },
  {
    "text": "data and commit data in there make changes and will track all of those all",
    "start": "964510",
    "end": "969670"
  },
  {
    "text": "of those changes which which both lets us have reproducibility but it also lets",
    "start": "969670",
    "end": "975490"
  },
  {
    "text": "us know when there's new data so we can trigger the right things at the right time right obviously since we're running",
    "start": "975490",
    "end": "983079"
  },
  {
    "text": "on kubernetes we use containers for analyses and this is actually really",
    "start": "983079",
    "end": "988180"
  },
  {
    "text": "important it might be lost on on this crowd but the the the set of tooling the",
    "start": "988180",
    "end": "995769"
  },
  {
    "text": "data scientists use like we might take for granted the containers provide this unified layer but they struggle so much",
    "start": "995769",
    "end": "1004199"
  },
  {
    "text": "and I struggled so much in my past with all of this diverse set of tooling and being able to string it all together so",
    "start": "1004199",
    "end": "1011670"
  },
  {
    "text": "being able to use tensor flow when I need it and then connect that output to R and do some visualizations and then",
    "start": "1011670",
    "end": "1018000"
  },
  {
    "text": "someone else builds some you know weird thing with Julia or something and we do that so that gives us like a unified",
    "start": "1018000",
    "end": "1024688"
  },
  {
    "text": "framework for saying our basic units of data processing or containers we run",
    "start": "1024689",
    "end": "1029699"
  },
  {
    "text": "opinionated about what you run in those run tensorflow run our run Python run",
    "start": "1029699",
    "end": "1035040"
  },
  {
    "text": "Julia run a bash command we don't we don't care next we kind of combine the containers",
    "start": "1035040",
    "end": "1042390"
  },
  {
    "text": "for analyses with the data versioning to build up pipeline or build up",
    "start": "1042390",
    "end": "1048530"
  },
  {
    "text": "distributed pipelines or or DAGs of processing where these containerized",
    "start": "1048530",
    "end": "1054500"
  },
  {
    "text": "processing stages subscribe to version collections of data descriptively so you",
    "start": "1054500",
    "end": "1061350"
  },
  {
    "text": "say I want to process this data with this image and you build up this dag of processing",
    "start": "1061350",
    "end": "1066700"
  },
  {
    "text": "stuff steps with which is also scalable and parallelizable and finally because",
    "start": "1066700",
    "end": "1072309"
  },
  {
    "text": "we're versioning all the data and we know what docker images we're using for",
    "start": "1072309",
    "end": "1077380"
  },
  {
    "text": "each stage we actually have complete quote/unquote provenance for any data",
    "start": "1077380",
    "end": "1083230"
  },
  {
    "text": "anywhere and what I mean by that is we can produce a result and then if we want",
    "start": "1083230",
    "end": "1089110"
  },
  {
    "text": "to know all of the other pieces of data and the states of the pose pieces of",
    "start": "1089110",
    "end": "1095590"
  },
  {
    "text": "data and the states of our docker images all of that when we produce that result",
    "start": "1095590",
    "end": "1101170"
  },
  {
    "text": "we can get all of that information very easily which helps both in terms of compliance and maintainability and",
    "start": "1101170",
    "end": "1107710"
  },
  {
    "text": "debugging and and all of that stuff just to again I know I know we're in a with",
    "start": "1107710",
    "end": "1116530"
  },
  {
    "text": "the with the technical crowd here so I I want to definitely don't want to you",
    "start": "1116530",
    "end": "1121660"
  },
  {
    "text": "know leave without kind of giving you a few more of details Before we jump into the demo so pachyderm again it's a it's",
    "start": "1121660",
    "end": "1129190"
  },
  {
    "text": "a layer that runs on kubernetes so kubernetes forms the base this gives us",
    "start": "1129190",
    "end": "1134530"
  },
  {
    "text": "most of what we need right pachyderm runs as a pod on top of kubernetes and",
    "start": "1134530",
    "end": "1139750"
  },
  {
    "text": "then it talks to an object store which is where all the data is backed and we",
    "start": "1139750",
    "end": "1146050"
  },
  {
    "text": "talked to that pachyderm pod and tell it you know we want to process this data",
    "start": "1146050",
    "end": "1151290"
  },
  {
    "text": "with this code and then pachyderm talks to kubernetes under the hood and then",
    "start": "1151290",
    "end": "1158260"
  },
  {
    "text": "spends up whatever pods are needed to do that processing so if I have an inference stage or a training stage",
    "start": "1158260",
    "end": "1164740"
  },
  {
    "text": "running tensorflow then I can spin up however many pipeline workers under the hood to do that",
    "start": "1164740",
    "end": "1169960"
  },
  {
    "text": "processing for that stage and then there'll be other workers which are just pods to to do the processing for the for",
    "start": "1169960",
    "end": "1179050"
  },
  {
    "text": "the other stages okay so enough of my",
    "start": "1179050",
    "end": "1185620"
  },
  {
    "start": "1183000",
    "end": "1396000"
  },
  {
    "text": "enough of my blabbing let's get to the let's get to the good stuff okay so",
    "start": "1185620",
    "end": "1193540"
  },
  {
    "text": "we've got a demo here this is sorry about the fuzzy the fuzzy",
    "start": "1193540",
    "end": "1201070"
  },
  {
    "text": "text I think the terminal will be a little bit better but just to give you an idea",
    "start": "1201070",
    "end": "1207769"
  },
  {
    "text": "so this is like a dashboard that you can have that you can look and see what's running as pachyderm pipelines and I",
    "start": "1207769",
    "end": "1214789"
  },
  {
    "text": "have this pipeline running here I'll show you on the backend what that looks like here in a second but just to kind",
    "start": "1214789",
    "end": "1222049"
  },
  {
    "text": "of illustrate here I here I'm doing an image to image translation with tensorflow",
    "start": "1222049",
    "end": "1227119"
  },
  {
    "text": "which means like an image comes in in one style and I want to transfer it to another style in this particular case I",
    "start": "1227119",
    "end": "1234559"
  },
  {
    "text": "want to bring satellite images in and kind of automatically transfer their style to like Google Maps images okay so",
    "start": "1234559",
    "end": "1243259"
  },
  {
    "text": "here in training so each of these blue",
    "start": "1243259",
    "end": "1248330"
  },
  {
    "text": "dots here represents one of these version collections of data remember this is a kind of our first piece of the",
    "start": "1248330",
    "end": "1255019"
  },
  {
    "text": "puzzle and in this in this version collection of data I have a bunch of of",
    "start": "1255019",
    "end": "1261009"
  },
  {
    "text": "images that I can use for training so I want to be able to translate images like",
    "start": "1261009",
    "end": "1267139"
  },
  {
    "text": "what's on the left two images like what's on the right also in my in my",
    "start": "1267139",
    "end": "1274849"
  },
  {
    "text": "input here I have two input images and I want to say okay I want to take this",
    "start": "1274849",
    "end": "1279889"
  },
  {
    "text": "image and I want to translate it so this is my this is my input that I want to",
    "start": "1279889",
    "end": "1286039"
  },
  {
    "text": "utilize my trained model to transform and so my inputs are those that training",
    "start": "1286039",
    "end": "1292909"
  },
  {
    "text": "data and then and then that input data or input images then over here on the",
    "start": "1292909",
    "end": "1300289"
  },
  {
    "text": "Left I do the training so this this next stage here is the training then I do",
    "start": "1300289",
    "end": "1305749"
  },
  {
    "text": "just some model export so just by the way that the the scripts were set up I",
    "start": "1305749",
    "end": "1310999"
  },
  {
    "text": "just changed the format of the the model and then that model is used in a",
    "start": "1310999",
    "end": "1317330"
  },
  {
    "text": "generate stage along with the pre processed images so I have a stage of pre processing and then I feed those",
    "start": "1317330",
    "end": "1323389"
  },
  {
    "text": "together into the generate stage which generates output images",
    "start": "1323389",
    "end": "1328530"
  },
  {
    "text": "so remember each of these collections is one of those version collections of data and each of my pipeline stages or",
    "start": "1328530",
    "end": "1337070"
  },
  {
    "text": "containerized analyses right so if I click on one of these this is my model training stage and I go down here I can",
    "start": "1337070",
    "end": "1344940"
  },
  {
    "text": "see how this how this pipeline stage is defined and it's defined via a docker",
    "start": "1344940",
    "end": "1350340"
  },
  {
    "text": "image and a command that's run in that docker image so I'm basically telling pachyderm hey I want you to process this",
    "start": "1350340",
    "end": "1358320"
  },
  {
    "text": "data using this docker image and when you do it run this command which is just",
    "start": "1358320",
    "end": "1363630"
  },
  {
    "text": "my Python script that's that's using tensor flow okay and each of these is",
    "start": "1363630",
    "end": "1368640"
  },
  {
    "text": "defined and in a similar way so in this case all all of my pipeline stages",
    "start": "1368640",
    "end": "1375420"
  },
  {
    "text": "except for this checkpoint the the model training stage all of those are just",
    "start": "1375420",
    "end": "1380790"
  },
  {
    "text": "fine running on CPUs and actually I can paralyze them very very easily across",
    "start": "1380790",
    "end": "1387060"
  },
  {
    "text": "CPU node instances so no worries like I don't have to worry about using a GPU",
    "start": "1387060",
    "end": "1393030"
  },
  {
    "text": "for for those stages so ideally what I would want to have is I would want to",
    "start": "1393030",
    "end": "1398040"
  },
  {
    "start": "1396000",
    "end": "1498000"
  },
  {
    "text": "have those pods that are running those processing stages run on CPU nodes and",
    "start": "1398040",
    "end": "1403620"
  },
  {
    "text": "then when I need to run checkpoint I want that to be scheduled on a GPU node such that I can do my model training",
    "start": "1403620",
    "end": "1410610"
  },
  {
    "text": "very quickly okay so so let's move over and connect some of the dots so we have",
    "start": "1410610",
    "end": "1420110"
  },
  {
    "text": "if I look at what's running in this cluster now I can see there's pack D",
    "start": "1420110",
    "end": "1427230"
  },
  {
    "text": "running which again manages all of this pipelining stuff and data management things and then I have all of these",
    "start": "1427230",
    "end": "1434580"
  },
  {
    "text": "pipeline workers so I have in this case I have a single worker for each stage of my pipeline although that's by no means",
    "start": "1434580",
    "end": "1442260"
  },
  {
    "text": "not the only thing you can do you could spin up a hundred workers to process a stage in parallel that's that's fine and",
    "start": "1442260",
    "end": "1448200"
  },
  {
    "text": "I can talk about that in the question and answer if if that's something you want to talk about but I have each of",
    "start": "1448200",
    "end": "1453930"
  },
  {
    "text": "these pods scheduled and I've already actually put some example data",
    "start": "1453930",
    "end": "1462330"
  },
  {
    "text": "so if I look at what jobs have run which jobs just mean how many times have these stages run sorry for the the wrapping",
    "start": "1462330",
    "end": "1469920"
  },
  {
    "text": "there but I can see like checkpoints run once I've pre-processed a couple times",
    "start": "1469920",
    "end": "1476790"
  },
  {
    "text": "I've run my model export and I've generated images once and that's reflected over here in the in the",
    "start": "1476790",
    "end": "1483990"
  },
  {
    "text": "dashboard as well I can see that this",
    "start": "1483990",
    "end": "1489860"
  },
  {
    "text": "this last stage if I look at or actually",
    "start": "1489860",
    "end": "1494930"
  },
  {
    "text": "excuse me so the reason why that one input ran twice which I'll illustrate",
    "start": "1494930",
    "end": "1501420"
  },
  {
    "start": "1498000",
    "end": "1627000"
  },
  {
    "text": "the data versioning here is because I put two images into the into that input",
    "start": "1501420",
    "end": "1507570"
  },
  {
    "text": "images but I can see that I've actually done that in two consecutive commits",
    "start": "1507570",
    "end": "1513210"
  },
  {
    "text": "okay so I could actually go back to this original commit of the data and see that",
    "start": "1513210",
    "end": "1518550"
  },
  {
    "text": "oh well I only had one image at that point in history and then I added the other one and what will happen to kind",
    "start": "1518550",
    "end": "1527280"
  },
  {
    "text": "of illustrate how all of these things are automatically connected and and and",
    "start": "1527280",
    "end": "1533090"
  },
  {
    "text": "those links are made let me just put one more image into that into that input",
    "start": "1533090",
    "end": "1541170"
  },
  {
    "text": "images repo so I'll put it into image input images on the master branch",
    "start": "1541170",
    "end": "1548220"
  },
  {
    "text": "remember again like kind of like get like semantics here for data and I'm gonna put this third image in and",
    "start": "1548220",
    "end": "1554400"
  },
  {
    "text": "actually what I'll see if I list the jobs again I'll see that that automatically what happened is",
    "start": "1554400",
    "end": "1561050"
  },
  {
    "text": "pachyderms saw that there was new data that need to be processed in the input",
    "start": "1561050",
    "end": "1566070"
  },
  {
    "text": "and it said oh you've descriptively told me that this this pod should be",
    "start": "1566070",
    "end": "1571980"
  },
  {
    "text": "processing that data I'm going to hand off that data to that pod it's going to be processed and then and then it's",
    "start": "1571980",
    "end": "1579390"
  },
  {
    "text": "going to go on down the line so that'll probably run quickly we can see that it actually pre-processed that and it ran",
    "start": "1579390",
    "end": "1586170"
  },
  {
    "text": "the last stage as well all automatically triggered okay if we look at the output",
    "start": "1586170",
    "end": "1593430"
  },
  {
    "text": "here it's actually not super impressed because I ran so it kind of looks like a",
    "start": "1593430",
    "end": "1599249"
  },
  {
    "text": "Google Maps drawing but I only ran the training for like one epoch if you're",
    "start": "1599249",
    "end": "1604590"
  },
  {
    "text": "familiar with training that's not sufficient in general but I did it so it",
    "start": "1604590",
    "end": "1611879"
  },
  {
    "text": "ran for about eleven minutes on a CPU and the reason why I did that is to show you something that would actually",
    "start": "1611879",
    "end": "1617970"
  },
  {
    "text": "execute in the time of this talk hopefully so okay I can see that I automatically generated the output for",
    "start": "1617970",
    "end": "1624359"
  },
  {
    "text": "the for the third image as well okay so we have solved if we take a step back",
    "start": "1624359",
    "end": "1630840"
  },
  {
    "start": "1627000",
    "end": "1965000"
  },
  {
    "text": "let's think we now have all of the all of our stages running as pods on",
    "start": "1630840",
    "end": "1636960"
  },
  {
    "text": "kubernetes we've wired them together we've connected the right data to the",
    "start": "1636960",
    "end": "1642840"
  },
  {
    "text": "right code when new data comes in we can automatically trigger all of those",
    "start": "1642840",
    "end": "1648479"
  },
  {
    "text": "things the piece that I haven't covered which is really the the punchline of this talk",
    "start": "1648479",
    "end": "1654840"
  },
  {
    "text": "I guess is that that's actually all not not the complete story because I still",
    "start": "1654840",
    "end": "1661409"
  },
  {
    "text": "need to make sure that at least one of these stages runs on a GPU right I want",
    "start": "1661409",
    "end": "1667320"
  },
  {
    "text": "to run my training on a GPU and actually what what's happening under the hood let",
    "start": "1667320",
    "end": "1673649"
  },
  {
    "text": "me show you here the way that I told pachyderms to spend these up is with a",
    "start": "1673649",
    "end": "1681629"
  },
  {
    "text": "specification like this that says you know create a pipeline called checkpoint use this docker image and command run it",
    "start": "1681629",
    "end": "1689399"
  },
  {
    "text": "on this input data here I'm just going to run one one instance of that but I",
    "start": "1689399",
    "end": "1694529"
  },
  {
    "text": "didn't say anything about a GPU right so what happened is pachyderms said okay",
    "start": "1694529",
    "end": "1699840"
  },
  {
    "text": "that's that's all cool I'll run that whenever the data comes into training then I'm gonna train your model on that",
    "start": "1699840",
    "end": "1706229"
  },
  {
    "text": "on that new data but like I said if we look at this so our our original",
    "start": "1706229",
    "end": "1715729"
  },
  {
    "text": "training here took 11 minutes so I just ran it earlier this morning and we're I",
    "start": "1715729",
    "end": "1723840"
  },
  {
    "text": "mean 11 minutes isn't that much in the training world but let's say that we want to do better and we want to",
    "start": "1723840",
    "end": "1729330"
  },
  {
    "text": "sure that that runs on a GPU first let's just see if it did run on a jeep on a GPU node so to kind of show you how I",
    "start": "1729330",
    "end": "1737040"
  },
  {
    "text": "have this cluster set up I have this is the the instances in my cluster it's",
    "start": "1737040",
    "end": "1742560"
  },
  {
    "text": "running an AWS although you can do this same thing in Google Cloud or Azure it's fine or some hybrid hybrid solution but",
    "start": "1742560",
    "end": "1752310"
  },
  {
    "text": "here I have one node that's a p2 extra-large which include which is a GPU",
    "start": "1752310",
    "end": "1757650"
  },
  {
    "text": "node okay so maybe I got maybe I did run on that on that GPU let's let's check so",
    "start": "1757650",
    "end": "1765060"
  },
  {
    "text": "if I I list job and I look here at this",
    "start": "1765060",
    "end": "1772410"
  },
  {
    "text": "training and let's go ahead and get the logs for that job and just grep for cuda",
    "start": "1772410",
    "end": "1782150"
  },
  {
    "text": "okay oh crap I didn't I didn't find any I didn't find any GPU right so this this",
    "start": "1782150",
    "end": "1789540"
  },
  {
    "text": "ran just says it as it normally would on a on a CPU node now all I have to do so",
    "start": "1789540",
    "end": "1795930"
  },
  {
    "text": "remember going back to the last talk remember what the standard workflow these days is for data scientists",
    "start": "1795930",
    "end": "1802320"
  },
  {
    "text": "usually GPUs you do a bunch of stuff on your local machine maybe you do some",
    "start": "1802320",
    "end": "1807630"
  },
  {
    "text": "stuff in the cloud or on a cluster with CPU nodes and then when you need to do something on a GPU node you turn around",
    "start": "1807630",
    "end": "1814140"
  },
  {
    "text": "you're like hey Frank you're using the the GPU node and then you know he says no but then maybe Susie's using it so",
    "start": "1814140",
    "end": "1820710"
  },
  {
    "text": "you schedule a job on it and then like all all goes to crap and everybody's angry and it's not harmonious at all so",
    "start": "1820710",
    "end": "1827460"
  },
  {
    "text": "we want to strive for something more harmonious so I want to just make sure that that runs on on a GPU so all I have",
    "start": "1827460",
    "end": "1835200"
  },
  {
    "text": "to do is go in here and modify my my pipeline spec and just set some resource",
    "start": "1835200",
    "end": "1842970"
  },
  {
    "text": "limits and say hey I want to run I want to run with a GPU okay and then here's",
    "start": "1842970",
    "end": "1851190"
  },
  {
    "text": "where you can cross your fingers let me just update that",
    "start": "1851190",
    "end": "1857680"
  },
  {
    "text": "and I'm gonna reprocess which means you know I want to reprocess with the",
    "start": "1857680",
    "end": "1863960"
  },
  {
    "text": "updated spec oops you actually do this",
    "start": "1863960",
    "end": "1870580"
  },
  {
    "text": "sorry with the GPU let me actually because I",
    "start": "1870580",
    "end": "1877450"
  },
  {
    "text": "just a second you didn't cross your fingers quite good enough because I",
    "start": "1877450",
    "end": "1883400"
  },
  {
    "text": "forgot the GPU tag there so let me delete this other job that's gonna run",
    "start": "1883400",
    "end": "1889790"
  },
  {
    "text": "another 11 minutes and I'm I don't want to keep you guys from lunch okay now",
    "start": "1889790",
    "end": "1898760"
  },
  {
    "text": "let's see what's running all right so now we have this checkpoint running again let's see let's get the logs again",
    "start": "1898760",
    "end": "1909909"
  },
  {
    "text": "ha ha there's my GPU and so all I had to",
    "start": "1912850",
    "end": "1918080"
  },
  {
    "text": "do was just set that resource limit and now pachyderm knew hey you don't want me",
    "start": "1918080",
    "end": "1923180"
  },
  {
    "text": "to run this on a CPU anymore you want me to run it on a GPU and then it talked to kubernetes under the hood and it said",
    "start": "1923180",
    "end": "1928910"
  },
  {
    "text": "hey this needs to run on a GPU and it would schedule on a GPU node and then it it recognizes the drivers boom we're off",
    "start": "1928910",
    "end": "1935390"
  },
  {
    "text": "to the races the rest of the things are still going to run on the CPU nodes everything's still wired together so",
    "start": "1935390",
    "end": "1941780"
  },
  {
    "text": "when I output this model from the GPU training it's still gonna be supplied to",
    "start": "1941780",
    "end": "1946790"
  },
  {
    "text": "the other stages that are running on CPU nodes and then I'm and then I'm golden",
    "start": "1946790",
    "end": "1952210"
  },
  {
    "text": "I'm okay so let's uh I'll just keep this up in case your this should finish I",
    "start": "1952210",
    "end": "1957500"
  },
  {
    "text": "think it finishes in like one minute so one minute compared to 11 minutes it's",
    "start": "1957500",
    "end": "1962570"
  },
  {
    "text": "pretty pretty good improvement so yeah that's um that's the demo I",
    "start": "1962570",
    "end": "1967580"
  },
  {
    "start": "1965000",
    "end": "2012000"
  },
  {
    "text": "wanted to show so I'm gonna be happy so I'm gonna be around the rest of today",
    "start": "1967580",
    "end": "1972680"
  },
  {
    "text": "and tomorrow it's lunchtime now happy to have lunch with you guys there's stickers up here so if you're into that",
    "start": "1972680",
    "end": "1978650"
  },
  {
    "text": "sort of thing grab some of those I'll also post these slides on the sked",
    "start": "1978650",
    "end": "1983930"
  },
  {
    "text": "schedule site the PDF there's a few so don't feel like you have to",
    "start": "1983930",
    "end": "1989700"
  },
  {
    "text": "the picture unless you want it but this will be posted on the schedule so you can grab the PDF of this and then follow",
    "start": "1989700",
    "end": "1996810"
  },
  {
    "text": "these links to all the docs let's just see if oh we got it okay so we ran about",
    "start": "1996810",
    "end": "2005420"
  },
  {
    "text": "a minute okay so all right thanks guys [Applause]",
    "start": "2005420",
    "end": "2014490"
  }
]
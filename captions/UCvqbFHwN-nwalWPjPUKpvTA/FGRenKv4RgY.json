[
  {
    "text": "hello everyone welcome to 2028 use the cubicle europe here is the signal the",
    "start": "80",
    "end": "5759"
  },
  {
    "text": "intro and the deep dive talk my name is dan chen i am a software engineer from google and i currently",
    "start": "5759",
    "end": "12000"
  },
  {
    "text": "work on the gk and source i'm the one of the founding engineer for kubernetes and the initiate",
    "start": "12000",
    "end": "18960"
  },
  {
    "text": "uh signaled back in 2016. derek",
    "start": "18960",
    "end": "24400"
  },
  {
    "text": "yeah uh great to be here with everybody at kubecon again uh my name is derek carr i am a um",
    "start": "24400",
    "end": "30720"
  },
  {
    "text": "engineer at red hat uh working on uh our openshift product uh and have been with dawn and the sigs",
    "start": "30720",
    "end": "38160"
  },
  {
    "text": "uh since our early days as well and i'm excited to be here with uh some of our newer contributors alana and sergey",
    "start": "38160",
    "end": "43760"
  },
  {
    "text": "solana you want to introduce yourself uh yeah uh hey everybody i'm alana",
    "start": "43760",
    "end": "48800"
  },
  {
    "text": "hashman i currently work on the openshift engineering node team",
    "start": "48800",
    "end": "53840"
  },
  {
    "text": "i've been working on kubernetes since about 2018 and you might recognize me as the",
    "start": "53840",
    "end": "59920"
  },
  {
    "text": "co-chair of sig instrumentation but i also work in sig note and currently help lead the ci sub project with sergey",
    "start": "59920",
    "end": "69200"
  },
  {
    "text": "hello i'm sergey kanjalev i'm working for google and very excited to be here",
    "start": "69200",
    "end": "74960"
  },
  {
    "text": "so with that said back to you then next",
    "start": "74960",
    "end": "80320"
  },
  {
    "text": "so before we get into the today's agenda i want to briefly mention the previous signal the update we made either cube",
    "start": "80320",
    "end": "87759"
  },
  {
    "text": "account last year you can access related slides record by click all those links here",
    "start": "87759",
    "end": "94400"
  },
  {
    "text": "next here's the today's agenda we're going to first introduce the signals",
    "start": "94400",
    "end": "100880"
  },
  {
    "text": "responsibility then we are going to talk about the current activity since last updates",
    "start": "100880",
    "end": "106399"
  },
  {
    "text": "the roadmaps from uh 1 1.23 to the to the 125 and the br then",
    "start": "106399",
    "end": "114320"
  },
  {
    "text": "some interesting projects and efforts are currently driving by the signal for example one that the 24 docker share",
    "start": "114320",
    "end": "122240"
  },
  {
    "text": "removal sequel provision 2 and the cia projects continue from the last update",
    "start": "122240",
    "end": "128399"
  },
  {
    "text": "then we want to share the node contributor later with the community we discussed this within the signal",
    "start": "128399",
    "end": "134800"
  },
  {
    "text": "community for a while now we have feminized yet finally we are going to talk about how",
    "start": "134800",
    "end": "140319"
  },
  {
    "text": "to get involved and how to get help from the community next",
    "start": "140319",
    "end": "146560"
  },
  {
    "text": "what is the signal and it is responsibility let's briefly talk about the node",
    "start": "146959",
    "end": "152080"
  },
  {
    "text": "responsibility in kubernetes kubernetes is a cluster ultraspecial solution for container like",
    "start": "152080",
    "end": "158319"
  },
  {
    "text": "containerized applications and services those containers included of the",
    "start": "158319",
    "end": "163840"
  },
  {
    "text": "kubernetes controllers are running on the nodes on each node there is an aging",
    "start": "163840",
    "end": "169840"
  },
  {
    "text": "co-current kubernetes registered node to kubernetes master kubernetes together",
    "start": "169840",
    "end": "175280"
  },
  {
    "text": "with container runtime manages part and containers lifecycle of the node setup",
    "start": "175280",
    "end": "181040"
  },
  {
    "text": "run tier down and clean up kubernetes also does the node-level resource management",
    "start": "181040",
    "end": "187280"
  },
  {
    "text": "such as ensure the application get the request the resources detect the node-level resource",
    "start": "187280",
    "end": "193840"
  },
  {
    "text": "establishing issues and take the text exit to prevent out of resource",
    "start": "193840",
    "end": "199599"
  },
  {
    "text": "situation kubernetes also sends the status back to the control plan to make the follow",
    "start": "199599",
    "end": "206400"
  },
  {
    "text": "decision correction next please",
    "start": "206400",
    "end": "211280"
  },
  {
    "text": "in summary signaled on all control are controllers running on the nodes which",
    "start": "211760",
    "end": "217599"
  },
  {
    "text": "ensure the node itself and application running happily signaled is very large and owns many",
    "start": "217599",
    "end": "224400"
  },
  {
    "text": "projects you can click the links and here to find more i this time i want",
    "start": "224400",
    "end": "230640"
  },
  {
    "text": "to specially call out the new sub project we start linking special resource operator which helps",
    "start": "230640",
    "end": "237920"
  },
  {
    "text": "the user manage the deployment of the kernel modules and the drivers and come to join our signal the",
    "start": "237920",
    "end": "246640"
  },
  {
    "text": "weakness meeting to know all those projects in details",
    "start": "246640",
    "end": "251599"
  },
  {
    "text": "now i want to hand over to adnan talk about our roadmap thanks dawn",
    "start": "252480",
    "end": "259040"
  },
  {
    "text": "uh i am going to talk a little bit about all the sorts of things that we've been up to in the past year starting with",
    "start": "259040",
    "end": "266800"
  },
  {
    "text": "graduations and deprecations so i grouped this section together because there's sort of this overall",
    "start": "266800",
    "end": "272400"
  },
  {
    "text": "goal between graduations and deprecations of cleaning up tech debt reducing",
    "start": "272400",
    "end": "278160"
  },
  {
    "text": "maintenance service so when a feature graduates in kubernetes it was previously behind a feature flag",
    "start": "278160",
    "end": "284560"
  },
  {
    "text": "typically defaulted to on and when we graduate it we get rid of that feature flag it's no longer",
    "start": "284560",
    "end": "289759"
  },
  {
    "text": "conditionally on it's on for everyone by default similarly deprecations uh are when we uh",
    "start": "289759",
    "end": "297600"
  },
  {
    "text": "will disable a feature if it was behind a feature gate and ultimately remove that feature uh from the code base again",
    "start": "297600",
    "end": "304639"
  },
  {
    "text": "making it a little bit more simpler to maintain so over the past year uh probably our",
    "start": "304639",
    "end": "311039"
  },
  {
    "text": "most major uh user-facing uh removal uh was that of docker shim which was",
    "start": "311039",
    "end": "317199"
  },
  {
    "text": "finally removed in the 124 release um on the",
    "start": "317199",
    "end": "323120"
  },
  {
    "text": "graduation side uh we are also graduating uh c group v2 or the version",
    "start": "323120",
    "end": "328720"
  },
  {
    "text": "two of kernel control groups uh to feature parity in the 122 release",
    "start": "328720",
    "end": "334400"
  },
  {
    "text": "uh and then a couple more minor deprecations and graduations we've removed support for dynamic cubelet",
    "start": "334400",
    "end": "340800"
  },
  {
    "text": "config that was previously deprecated and ultimately removed in 124",
    "start": "340800",
    "end": "346160"
  },
  {
    "text": "and we've also graduated pod overhead which helps keep track of additional resources at the pod level",
    "start": "346160",
    "end": "353440"
  },
  {
    "text": "so no more feature paid for that uh for beta graduations this is when a",
    "start": "353440",
    "end": "358800"
  },
  {
    "text": "feature may have been added at an alpha level and now we default that feature gate to on",
    "start": "358800",
    "end": "364960"
  },
  {
    "text": "so in the past a couple of releases 123 and 124 we've graduated a number of",
    "start": "364960",
    "end": "371120"
  },
  {
    "text": "features to beta uh including ephemeral containers which had quite a long time",
    "start": "371120",
    "end": "376560"
  },
  {
    "text": "between alpha and beta so we're very excited about that but we also",
    "start": "376560",
    "end": "382080"
  },
  {
    "text": "graduated the cubelet cri support we now support a v1 api",
    "start": "382080",
    "end": "387759"
  },
  {
    "text": "which is very exciting we have graduated cubelet credential provider to beta and",
    "start": "387759",
    "end": "394880"
  },
  {
    "text": "we've added support for and then graduated grpc probes to beta",
    "start": "394880",
    "end": "400080"
  },
  {
    "text": "and so on so if you want to look up any of these particular features you can do so",
    "start": "400080",
    "end": "406479"
  },
  {
    "text": "by enhancement number which i've included on the slide and in the copy of the slides that we're sharing will also",
    "start": "406479",
    "end": "412639"
  },
  {
    "text": "include some links finally i'll talk about the alpha features that we've added to the sig",
    "start": "412639",
    "end": "420080"
  },
  {
    "text": "over the past couple of releases these are net new features so they're introduced behind a feature gate but",
    "start": "420080",
    "end": "426160"
  },
  {
    "text": "those feature gates are disabled by default and you could turn them on and test them out",
    "start": "426160",
    "end": "431199"
  },
  {
    "text": "we have a couple of these alpha features that we have added the first is",
    "start": "431199",
    "end": "436800"
  },
  {
    "text": "c advisor lists and cri full hot container and pod stats allowing the cri",
    "start": "436800",
    "end": "443120"
  },
  {
    "text": "the container runtime to provide statistics uh typically prometheus metrics",
    "start": "443120",
    "end": "448880"
  },
  {
    "text": "on behalf of a pod rather than having see advisor have to do some introspection of the c groups and",
    "start": "448880",
    "end": "456319"
  },
  {
    "text": "provide them instead which can be a little expensive sort of ultimately along the path of",
    "start": "456319",
    "end": "461440"
  },
  {
    "text": "reducing how much we have to rely on c advisor in kubelet we also added some new cpu manager",
    "start": "461440",
    "end": "468960"
  },
  {
    "text": "policies which is very exciting",
    "start": "468960",
    "end": "472800"
  },
  {
    "text": "now in our future road map 125 and beyond we have a bunch of really cool",
    "start": "474160",
    "end": "479199"
  },
  {
    "text": "stuff in the pipeline we're going to continue enabling uh c group v2 uh which we're going to talk",
    "start": "479199",
    "end": "486240"
  },
  {
    "text": "about a little bit more further in the presentation uh which will unblock a lot of new features in kubernetes very",
    "start": "486240",
    "end": "492639"
  },
  {
    "text": "exciting we're adding forensic checkpointing to containers",
    "start": "492639",
    "end": "498000"
  },
  {
    "text": "we're looking to add secret pulled images and in place pod updates for",
    "start": "498000",
    "end": "503440"
  },
  {
    "text": "adjusting the requested resources at runtime and we're also working on",
    "start": "503440",
    "end": "509919"
  },
  {
    "text": "graduating memory swap support which is currently an alpha feature but not yet graduated to beta there are of course",
    "start": "509919",
    "end": "516560"
  },
  {
    "text": "many more features and if you want to hear more about those you can join us at a sig node meeting",
    "start": "516560",
    "end": "522560"
  },
  {
    "text": "but for now uh let's go and do a little deeper dive into one of our major areas",
    "start": "522560",
    "end": "528720"
  },
  {
    "text": "i believe don will be talking about docker shim removal over to you done",
    "start": "528720",
    "end": "535040"
  },
  {
    "text": "thanks anella before getting into docker shim removal i want to briefly talk about kubernetes",
    "start": "535040",
    "end": "541120"
  },
  {
    "text": "container runtime interface ci it is a grpc interface which defines how",
    "start": "541120",
    "end": "546880"
  },
  {
    "text": "kubernetes the agent running under every node interacts with a wide variety of the",
    "start": "546880",
    "end": "553200"
  },
  {
    "text": "container render we published the first version of the cri back in may",
    "start": "553200",
    "end": "559800"
  },
  {
    "text": "2016 and the first implementation of the cia was introduced to kubernetes 1.5 in",
    "start": "559800",
    "end": "567640"
  },
  {
    "text": "2017. next please as the first implementation to support",
    "start": "567640",
    "end": "574399"
  },
  {
    "text": "the cri docker shim is the built-in module in kubernetes",
    "start": "574399",
    "end": "579440"
  },
  {
    "text": "why did we choose to do this then so then we have to deprecate and remove it",
    "start": "579440",
    "end": "585040"
  },
  {
    "text": "today in 2016 docker was the only production id container rental we needed to",
    "start": "585040",
    "end": "592080"
  },
  {
    "text": "validate the interface we created quickly to ensure the incremental deployment it take it took us a little",
    "start": "592080",
    "end": "600320"
  },
  {
    "text": "bit more than one year to have the first version of the production right the interface and the implementation",
    "start": "600320",
    "end": "607680"
  },
  {
    "text": "then why we bundle it with kubernetes as the single battery back then kubernetes iterate very",
    "start": "607680",
    "end": "615440"
  },
  {
    "text": "dramatically cri was changed all the time bundle found only it was kubernetes so",
    "start": "615440",
    "end": "621360"
  },
  {
    "text": "that we can tolerate breaking api changes for the faster iterations this also allows us",
    "start": "621360",
    "end": "628399"
  },
  {
    "text": "we can switch to using ci as the default uh for the in pro in process docker",
    "start": "628399",
    "end": "634560"
  },
  {
    "text": "integration while the api is still in alpha hence we created of the docker ship",
    "start": "634560",
    "end": "640640"
  },
  {
    "text": "and that is that was the only choice for kubernetes users until two years later",
    "start": "640640",
    "end": "646640"
  },
  {
    "text": "we introduced g8 the second container runtime container d then cryo",
    "start": "646640",
    "end": "652959"
  },
  {
    "text": "follow next please since we published the first version of",
    "start": "652959",
    "end": "658480"
  },
  {
    "text": "the cii there were many efforts to build different container runtimes to serve",
    "start": "658480",
    "end": "665120"
  },
  {
    "text": "different purposes different work notes different business reasons and so on signaled supported all of them but",
    "start": "665120",
    "end": "672720"
  },
  {
    "text": "worked very closely with continuity cryo and the frac friday in addition to docker shim to",
    "start": "672720",
    "end": "679440"
  },
  {
    "text": "make sure the interface we defined covers the majority use cases",
    "start": "679440",
    "end": "684560"
  },
  {
    "text": "we also introduced ci test suite and the cloud cattle",
    "start": "684560",
    "end": "690560"
  },
  {
    "text": "tool sets to help the develop development and the usability next",
    "start": "690560",
    "end": "697680"
  },
  {
    "text": "since we published the first version of the cloud oh sorry since we published the first version of the cri in 2016 two",
    "start": "698240",
    "end": "706560"
  },
  {
    "text": "years later kubernetes container d went to ga and graduated from the cf incubation",
    "start": "706560",
    "end": "714160"
  },
  {
    "text": "later cryos production ready and graduate both container runtimes support the cri",
    "start": "714160",
    "end": "721760"
  },
  {
    "text": "and oci compatibility since day one both the container run times or future parity",
    "start": "721760",
    "end": "728320"
  },
  {
    "text": "with the docker shield before ga and over the time we introduced more",
    "start": "728320",
    "end": "733360"
  },
  {
    "text": "features to them respectively both container runtimes met the test coverage requirements defined",
    "start": "733360",
    "end": "740399"
  },
  {
    "text": "by signaled before the production writing next",
    "start": "740399",
    "end": "746240"
  },
  {
    "text": "why do we want to remove docker share why not maintain an inbox solution for",
    "start": "746240",
    "end": "753440"
  },
  {
    "text": "the users from the previous slides one can see that since the beginning of its knife we",
    "start": "753440",
    "end": "760639"
  },
  {
    "text": "treat it we treated it as the temporary solution we fixed many integration issues using it to support existing",
    "start": "760639",
    "end": "767600"
  },
  {
    "text": "users but decided not to introduce new features especially after we had the two",
    "start": "767600",
    "end": "773760"
  },
  {
    "text": "alternatives three years ago this is a growing feature imperative issue",
    "start": "773760",
    "end": "780560"
  },
  {
    "text": "with the docker ship by the way the first feature we developed after dockership in google it is a secret",
    "start": "780560",
    "end": "787200"
  },
  {
    "text": "version too now i want to hand it hand it over to direct on sql with version 2.",
    "start": "787200",
    "end": "794399"
  },
  {
    "text": "thanks tom so as discussed earlier we've made a lot of progress in the community around secret speed v2 enablement um",
    "start": "794399",
    "end": "802000"
  },
  {
    "text": "as we started this project we wanted to make clear on what our initial goals were with respect to",
    "start": "802000",
    "end": "807279"
  },
  {
    "text": "secret v2 and that was largely to get parity with existing feature support in c groups v1 so",
    "start": "807279",
    "end": "813440"
  },
  {
    "text": "all of the resource controllers that kubernetes leverages to restrict the amount of cpu or memory or",
    "start": "813440",
    "end": "820320"
  },
  {
    "text": "pids or huge pages that a given pod can consume they are",
    "start": "820320",
    "end": "826959"
  },
  {
    "text": "restricted today primarily by secret v1 controllers over the life of kubernetes c groups v2 has continued to evolve",
    "start": "826959",
    "end": "833920"
  },
  {
    "text": "and has reached parity uh features in many cases with v1 so today if you boot a cubelet on a v2",
    "start": "833920",
    "end": "841120"
  },
  {
    "text": "enabled host and your runtime is set up appropriately our intention is to ensure that they at",
    "start": "841120",
    "end": "846480"
  },
  {
    "text": "least have future parity today we are not deprecating secret b1 support",
    "start": "846480",
    "end": "851519"
  },
  {
    "text": "by adding v2 but we are making a statement that a new resource controllers uh are",
    "start": "851519",
    "end": "856720"
  },
  {
    "text": "intended to be only added for for v2 only and we'll talk about some of those so um one of the major activities to enable",
    "start": "856720",
    "end": "863760"
  },
  {
    "text": "v2 support besides the code is just to make sure that you have viable test coverage a number of distributions over the last",
    "start": "863760",
    "end": "870720"
  },
  {
    "text": "few years have started to change their default uh boot time configuration to be v2",
    "start": "870720",
    "end": "876079"
  },
  {
    "text": "enabled so that includes fedora ubuntu cos and others",
    "start": "876079",
    "end": "882000"
  },
  {
    "text": "and now that that's happened we get more pressure obviously in the kubernetes community to support those hosts",
    "start": "882000",
    "end": "887040"
  },
  {
    "text": "um one example of new features that we are excited that you can leverage uh in a v2",
    "start": "887040",
    "end": "892959"
  },
  {
    "text": "environment that is in an alpha state right now is memory quality of service so",
    "start": "892959",
    "end": "899360"
  },
  {
    "text": "hopefully as we continue to evolve that feature we can point to that as our first v2 specific c",
    "start": "899360",
    "end": "905600"
  },
  {
    "text": "group's enablement support so we go to the next slide what is a secret v2 environment mean for",
    "start": "905600",
    "end": "912639"
  },
  {
    "text": "you as a workload deployer uh typically you shouldn't have to worry about it right you should leverage uh kubernetes",
    "start": "912639",
    "end": "919279"
  },
  {
    "text": "as your container orchestration runtime to say that that's gonna handle it for me i just set my fields on my pods and",
    "start": "919279",
    "end": "924320"
  },
  {
    "text": "everything's great as a kubernetes infrastructure provider it",
    "start": "924320",
    "end": "929519"
  },
  {
    "text": "does have some meaning right you have to know if your operating system is configured for v2 you have to make sure",
    "start": "929519",
    "end": "934639"
  },
  {
    "text": "that your container runtime supports av2 environment and typically that does mean now you'd have to change how you deploy",
    "start": "934639",
    "end": "941759"
  },
  {
    "text": "a secret manager in both cable and runtime to be systemd aware um in practice though while it's true",
    "start": "941759",
    "end": "948720"
  },
  {
    "text": "that most workloads shouldn't be impacted it's hard for us to immediately know these things without testing and",
    "start": "948720",
    "end": "954079"
  },
  {
    "text": "feedback so whether you get kubernetes from the community you get it from a vendor or you get it from",
    "start": "954079",
    "end": "960959"
  },
  {
    "text": "your particular provider of choice please make sure you give that feedback to that source so that we can get that",
    "start": "960959",
    "end": "966160"
  },
  {
    "text": "any bugs and issues known to the broader community and fixed up a good example of where secret suite 2",
    "start": "966160",
    "end": "972720"
  },
  {
    "text": "and stuff that's not provided in the core of the kubernetes project off intersect is around things like security monitoring",
    "start": "972720",
    "end": "979440"
  },
  {
    "text": "resource agents so while projects like c advisor have added v2 support your own unique",
    "start": "979440",
    "end": "985360"
  },
  {
    "text": "environment might have some unique uh agents running on your environment that may not yet be v2 compatible so just be",
    "start": "985360",
    "end": "991279"
  },
  {
    "text": "aware that the intersection of your total set of solutions deployed to a node might",
    "start": "991279",
    "end": "997120"
  },
  {
    "text": "need to account for v2 in the future so if we go to the next slide uh just wanted to raise some domain",
    "start": "997120",
    "end": "1003279"
  },
  {
    "text": "specific or industry specific challenges that we are aware of as uh kubernetes maintainers",
    "start": "1003279",
    "end": "1008639"
  },
  {
    "text": "uh that as we look to evolve towards v2 uh we hear feedback about",
    "start": "1008639",
    "end": "1013680"
  },
  {
    "text": "um a lot of users in telco or using kubernetes as a platform to automate uh",
    "start": "1013680",
    "end": "1018800"
  },
  {
    "text": "uh new networks one area that we know is not available in uh secrecy 2 was",
    "start": "1018800",
    "end": "1024079"
  },
  {
    "text": "allowing you to disable cpu load balancing for example so a lot of people in those industries are are pinning their",
    "start": "1024079",
    "end": "1030240"
  },
  {
    "text": "workload to particular cpus and are very performance sensitive we are hoping in the broader linux",
    "start": "1030240",
    "end": "1036079"
  },
  {
    "text": "community that we get these things fixed uh and so that v2 will just work fine in those industries",
    "start": "1036079",
    "end": "1042640"
  },
  {
    "text": "but that's an example of a domain or industry specific challenge that is hard for us to know without feedback other",
    "start": "1042640",
    "end": "1048400"
  },
  {
    "text": "types of challenges are more nuanced so if you're using a particular language runtime",
    "start": "1048400",
    "end": "1054480"
  },
  {
    "text": "uh in golang there's native v1 support uh to determine how to properly configure gomax prox uh but right now my",
    "start": "1054480",
    "end": "1062160"
  },
  {
    "text": "understanding is i think on golang you actually have to manually set that on a v2 host i'm sure over time as golem",
    "start": "1062160",
    "end": "1068240"
  },
  {
    "text": "evolves you won't have to care about anymore but sometimes these quirks exist similarly on java if you're using newer",
    "start": "1068240",
    "end": "1073520"
  },
  {
    "text": "jdks greater than 15 java should be v2 aware and not need any",
    "start": "1073520",
    "end": "1078720"
  },
  {
    "text": "additional work but if your company or your environment is older on an older jdk",
    "start": "1078720",
    "end": "1084240"
  },
  {
    "text": "you might need to update in order to take advantage finally we're doing a lot of work in sig",
    "start": "1084240",
    "end": "1090240"
  },
  {
    "text": "node to try to be more flexible with respect to auto scaling so we talked about in place resource resizing in our road map",
    "start": "1090240",
    "end": "1097600"
  },
  {
    "text": "right now we are working towards landing that in an alpha feature state but we would love help to be able to",
    "start": "1097600",
    "end": "1104080"
  },
  {
    "text": "ensure that as that feature lands that it is v2 tolerant right now there's gaps",
    "start": "1104080",
    "end": "1109120"
  },
  {
    "text": "that we need to close in particular around auto scaling a lot of things between v1 and v2 the metrics",
    "start": "1109120",
    "end": "1115280"
  },
  {
    "text": "do change and so if you have exotic auto scalers we really just need more testing against",
    "start": "1115280",
    "end": "1121600"
  },
  {
    "text": "those metric providers that are feeding your autoscaling and that feedback brought back to the community so like a",
    "start": "1121600",
    "end": "1126799"
  },
  {
    "text": "general call to action if you're watching this is if your domain your industry your language runtime or your",
    "start": "1126799",
    "end": "1132320"
  },
  {
    "text": "vendor has any known gaps that they want to share with us the only way we can get them mitigated is to to share that feedback so please do look to join us",
    "start": "1132320",
    "end": "1140240"
  },
  {
    "text": "going forward though with secret32 there are interesting uh uh features that we look to uh explore",
    "start": "1140240",
    "end": "1148160"
  },
  {
    "text": "uh that are if you are interest to you as a potential user or contributor we'd love to learn more about so things like",
    "start": "1148160",
    "end": "1153600"
  },
  {
    "text": "pressure stall information metrics to drive more efficient uh eviction or node",
    "start": "1153600",
    "end": "1158960"
  },
  {
    "text": "reliability is an exciting feature for us as well as better leveraging user space zoom killers like md so",
    "start": "1158960",
    "end": "1166880"
  },
  {
    "text": "hopefully we see that as we evolve to v2 we can get better more reliable nodes",
    "start": "1166880",
    "end": "1172320"
  },
  {
    "text": "for the broader community next slide uh so uh talking through uh",
    "start": "1172320",
    "end": "1180960"
  },
  {
    "text": "reliability sometimes regressions happen uh so uh does it speak to this next section i",
    "start": "1180960",
    "end": "1186320"
  },
  {
    "text": "think sergey are you next yeah i'm next i'm gonna talk about uh new regressions",
    "start": "1186320",
    "end": "1192640"
  },
  {
    "text": "that we discovered in kublet in 122. it's a continuation of the story that elana told us last time",
    "start": "1192640",
    "end": "1200559"
  },
  {
    "text": "we did a similar talk on kubecon so if you're interested for the beginning of",
    "start": "1200559",
    "end": "1206000"
  },
  {
    "text": "story go back and listen it first uh or you can just continue here and then go back and",
    "start": "1206000",
    "end": "1211840"
  },
  {
    "text": "see what other issues uh record when we've been doing that um so it's not the only regression we",
    "start": "1211840",
    "end": "1218159"
  },
  {
    "text": "found and but it's a pretty quite interesting one",
    "start": "1218159",
    "end": "1223760"
  },
  {
    "text": "so to start talking about this regression i want to refresh a little bit about architecture of kublet",
    "start": "1223840",
    "end": "1229760"
  },
  {
    "text": "uh kublat receives signals from api server and it also uh",
    "start": "1229760",
    "end": "1235360"
  },
  {
    "text": "reports status back to api server so there is this connection and then",
    "start": "1235360",
    "end": "1240720"
  },
  {
    "text": "kublet also talks to continue runtimes through workers and it's like a schedule sport and",
    "start": "1240720",
    "end": "1246720"
  },
  {
    "text": "kills them when needed plus it monitors um port status uh periodically querying",
    "start": "1246720",
    "end": "1254480"
  },
  {
    "text": "container on time information and uh this uh information about pods being",
    "start": "1254480",
    "end": "1259520"
  },
  {
    "text": "generated as events and uh plague and this event's been fed back into kublad",
    "start": "1259520",
    "end": "1265600"
  },
  {
    "text": "so it approaches all that from all the signals from all the different components to",
    "start": "1265600",
    "end": "1270640"
  },
  {
    "text": "build up a final picture what is currently happening with spots and containers in the spots",
    "start": "1270640",
    "end": "1277440"
  },
  {
    "text": "in 122 let me say site in 122 we fixed the bug",
    "start": "1277440",
    "end": "1283280"
  },
  {
    "text": "that bug was related to reporting the terminated status of",
    "start": "1283280",
    "end": "1288320"
  },
  {
    "text": "certain containers there was some race conditions and uh to eliminate these conditions we uh put um",
    "start": "1288320",
    "end": "1296400"
  },
  {
    "text": "more logic together uh as a single source of truth of port termination status",
    "start": "1296400",
    "end": "1302480"
  },
  {
    "text": "uh as i said last time there were many race conditions and the other bugs we",
    "start": "1302480",
    "end": "1307520"
  },
  {
    "text": "discovered as a result of this um uh refactoring it was a good refactoring",
    "start": "1307520",
    "end": "1312799"
  },
  {
    "text": "it fixed a lot of bugs but uh and then regression was caught and we shipped quite a stable product unfortunately we",
    "start": "1312799",
    "end": "1319760"
  },
  {
    "text": "found another problem in cobalt in 122. so this was",
    "start": "1319760",
    "end": "1326480"
  },
  {
    "text": "represented as out of cpu message when you try to schedule many ports simultaneously on quite busy notes",
    "start": "1326480",
    "end": "1334320"
  },
  {
    "text": "examples may be jobs that you execute each job is quite small but you need to execute a lot of",
    "start": "1334320",
    "end": "1341440"
  },
  {
    "text": "them and when new job trying to be scheduled it suddenly cannot be scheduled and receives this message out of cpu",
    "start": "1341440",
    "end": "1349520"
  },
  {
    "text": "we discovered this bug through a bug triage relatively uh",
    "start": "1349520",
    "end": "1354640"
  },
  {
    "text": "early unfortunately due to the nature of this bug we saw similar situations with out",
    "start": "1354640",
    "end": "1360080"
  },
  {
    "text": "of cpu before that was caused for instance by static ports when static port being scheduled",
    "start": "1360080",
    "end": "1368559"
  },
  {
    "text": "while api server doesn't know about it and then api server will push some nodes uh some",
    "start": "1368799",
    "end": "1374640"
  },
  {
    "text": "ports into the node and uh node will not have time uh we will not have cpu because uh static port just got",
    "start": "1374640",
    "end": "1381360"
  },
  {
    "text": "scheduled and api was just wasn't aware of that there were other cases are caused out of cpu before",
    "start": "1381360",
    "end": "1388640"
  },
  {
    "text": "so we investigated we thought that it may be some scheduler problem it might be some rare issues that nobody caught",
    "start": "1388640",
    "end": "1395600"
  },
  {
    "text": "and most uh biggest reason that we didn't have this code and we didn't know",
    "start": "1395600",
    "end": "1400720"
  },
  {
    "text": "about this regression that we don't have many tests that test many fails",
    "start": "1400720",
    "end": "1407360"
  },
  {
    "text": "many pods are scattering and rescheduling often",
    "start": "1407360",
    "end": "1413039"
  },
  {
    "text": "so what we did um the fix was quite simple for this one um for this situation oh i",
    "start": "1413039",
    "end": "1420960"
  },
  {
    "text": "didn't explain what the root cause so root cause was that uh uh when we fixed the pod termination uh",
    "start": "1420960",
    "end": "1427760"
  },
  {
    "text": "detection and uh we put it in a single place we made uh kublet know about pod being terminated",
    "start": "1427760",
    "end": "1435520"
  },
  {
    "text": "earlier than before and since kublet knows about it it will sync the status with api server and api",
    "start": "1435520",
    "end": "1441600"
  },
  {
    "text": "server will know that paul is terminated so it's time to schedule newport in place of this one",
    "start": "1441600",
    "end": "1448400"
  },
  {
    "text": "uh what uh the fix was to delay a report in the status to api server i highlighted this uh like key uh",
    "start": "1448400",
    "end": "1456799"
  },
  {
    "text": "codes that participate in that fix but they were pr was much bigger than that so um now",
    "start": "1456799",
    "end": "1465039"
  },
  {
    "text": "we will delay reporting terminated status of report to api server",
    "start": "1465039",
    "end": "1470480"
  },
  {
    "text": "before all the resources are cleaned up and all the resources i mean not all all",
    "start": "1470480",
    "end": "1476720"
  },
  {
    "text": "resources it's only cpu and memory in this case um we",
    "start": "1476720",
    "end": "1481840"
  },
  {
    "text": "made some observations while we've been fixing this bugs beyond just the distributed systems a heart and uh",
    "start": "1481840",
    "end": "1488799"
  },
  {
    "text": "need to find balance between speed and consistency we also uh highlighted again that terminated port is not equal",
    "start": "1488799",
    "end": "1495200"
  },
  {
    "text": "deleted port a terminated port can report its termination but it still will",
    "start": "1495200",
    "end": "1500480"
  },
  {
    "text": "clean up some resources and one resource in particular that will be clean will be",
    "start": "1500480",
    "end": "1506559"
  },
  {
    "text": "turned down during the termination period is volumes and volumes may take a lot of time to to be",
    "start": "1506559",
    "end": "1513440"
  },
  {
    "text": "turned down and cool blood account for that so a new",
    "start": "1513440",
    "end": "1518480"
  },
  {
    "text": "port can be scheduled that want to use the same volume and it will wait till volume will be completely cleaned up and",
    "start": "1518480",
    "end": "1524320"
  },
  {
    "text": "then we will pick it and pick up a new volume so this behavior is different from what we made for cpu and memory and",
    "start": "1524320",
    "end": "1530799"
  },
  {
    "text": "in the future we may consider improving this for cpu and memory as well so scheduling will uh happen faster and",
    "start": "1530799",
    "end": "1537200"
  },
  {
    "text": "kublat will just wait a little bit for cpu memory to finally freed up but it",
    "start": "1537200",
    "end": "1542480"
  },
  {
    "text": "may be a future improvement it's all highlighted again that we need to have good ci",
    "start": "1542480",
    "end": "1549919"
  },
  {
    "text": "for kubernetes and make sure that we cover all the bases when we test it so we",
    "start": "1549919",
    "end": "1556559"
  },
  {
    "text": "added end to end test for this regression that will schedule many ports and we'll make sure that",
    "start": "1556559",
    "end": "1562320"
  },
  {
    "text": "this signal wouldn't be a terminated signal wouldn't be synced up with apis or too",
    "start": "1562320",
    "end": "1567919"
  },
  {
    "text": "early in general ci sub project meet every week and what we do is we look at all",
    "start": "1567919",
    "end": "1574880"
  },
  {
    "text": "the test grid we analyze what's happening what's going badly what is going good",
    "start": "1574880",
    "end": "1581120"
  },
  {
    "text": "we fix issues and adjust tests and we also create a new test coverage",
    "start": "1581120",
    "end": "1587360"
  },
  {
    "text": "so uh if you're interested to join signature and you don't know where to start the cisa project may be a very",
    "start": "1587360",
    "end": "1592960"
  },
  {
    "text": "good place to start we you'll learn kubernetes through facing kubernetes and uh it will give you a lot",
    "start": "1592960",
    "end": "1600080"
  },
  {
    "text": "of inside knowledge like how to test and what kind of situation kubelet may get into",
    "start": "1600080",
    "end": "1607519"
  },
  {
    "text": "we recently published achievements blog post i linked it here you can go and check it",
    "start": "1607919",
    "end": "1614240"
  },
  {
    "text": "out we have 18 active contributors that we highlighted we really appreciate all of your work uh we want uh to highlight it",
    "start": "1614240",
    "end": "1621760"
  },
  {
    "text": "more and more and we don't have time in this talk to name names but",
    "start": "1621760",
    "end": "1627600"
  },
  {
    "text": "yeah hi everybody uh thank you for your contribution um i also posted some statistics here",
    "start": "1627600",
    "end": "1634799"
  },
  {
    "text": "it's not uh i mean it's from some time ago and it's kind of when you symmetric it just but what it shows it shows",
    "start": "1634799",
    "end": "1641919"
  },
  {
    "text": "numbers like we do a lot of work we do reviews we do bug fixes so",
    "start": "1641919",
    "end": "1648000"
  },
  {
    "text": "if you're interested join us and help us in this hard task we also uh like this is how we",
    "start": "1648000",
    "end": "1656399"
  },
  {
    "text": "track work in the cisa project we have a special project for test and we do receive early reliability signal by uh",
    "start": "1656399",
    "end": "1663760"
  },
  {
    "text": "doing bug cache with that i want to go to derek uh to talk about how uh",
    "start": "1663760",
    "end": "1670399"
  },
  {
    "text": "people uh contributing uh to signal can uh get more exposed into what we're",
    "start": "1670399",
    "end": "1675520"
  },
  {
    "text": "doing yeah thanks so guys so one of the challenges in a open source",
    "start": "1675520",
    "end": "1681120"
  },
  {
    "text": "project at the scale of kubernetes and cigna itself is just the",
    "start": "1681120",
    "end": "1686320"
  },
  {
    "text": "breadth of things uh that we need to keep in mind as maintainers uh that we don't break or regress uh the",
    "start": "1686320",
    "end": "1692960"
  },
  {
    "text": "past and we can continue to build responsibly for the future so signoid is uh the third largest sig by absolute",
    "start": "1692960",
    "end": "1699200"
  },
  {
    "text": "workload um lots of pr's get opened lots of prs need to get merged closed and triage and",
    "start": "1699200",
    "end": "1705840"
  },
  {
    "text": "contributions can come from a variety of member companies who work in the",
    "start": "1705840",
    "end": "1711039"
  },
  {
    "text": "community sometimes enduring and sometimes just in particular feature function areas",
    "start": "1711039",
    "end": "1718240"
  },
  {
    "text": "what this means is in general for us as a project to be healthy we need to have a constant pool of help",
    "start": "1718240",
    "end": "1725039"
  },
  {
    "text": "uh to help drive that work forward um so if we go to the next slide",
    "start": "1725039",
    "end": "1730159"
  },
  {
    "text": "um one of the things that we're trying to do in the signo community is to ensure that we have a viable set of",
    "start": "1730159",
    "end": "1736080"
  },
  {
    "text": "healthy new contributors reviewers and a pathway for approvers going forward",
    "start": "1736080",
    "end": "1742559"
  },
  {
    "text": "hopefully by the time you are watching this in kubecon we will have a pr that's merged in the",
    "start": "1743120",
    "end": "1748559"
  },
  {
    "text": "sig node i think the community area is where we're looking to put it where you can",
    "start": "1748559",
    "end": "1754320"
  },
  {
    "text": "look through new guidelines on how we want to help encourage a clear pathway to evolution of responsibility within",
    "start": "1754320",
    "end": "1760720"
  },
  {
    "text": "the sig uh to set guidelines for reviewers and approvers and then expectations for",
    "start": "1760720",
    "end": "1766559"
  },
  {
    "text": "those who become approvers with respect to uh maybe making claire uh their individual",
    "start": "1766559",
    "end": "1772320"
  },
  {
    "text": "domain knowledge one of the concerns we have as a kubernetes project and particularly in the cubelet is it's kind",
    "start": "1772320",
    "end": "1778000"
  },
  {
    "text": "of an intersection point between many other aspects of the project so that would be networking and storage",
    "start": "1778000",
    "end": "1786960"
  },
  {
    "text": "and our code isn't always as decoupled as we'd like from those two intersection areas",
    "start": "1786960",
    "end": "1792240"
  },
  {
    "text": "and so particularly for the pathway for approvers uh things like security and knowing what to look at are strong uh",
    "start": "1792240",
    "end": "1798320"
  },
  {
    "text": "paramount importance um so uh if you wanna help evolve your contributions in sig node uh the ci sub",
    "start": "1798320",
    "end": "1805679"
  },
  {
    "text": "project is a great place to get started but just help join us at signed and hopefully we can get you moving forward",
    "start": "1805679",
    "end": "1810960"
  },
  {
    "text": "in that pack um next slide so alana do you want to talk about how folks can get involved",
    "start": "1810960",
    "end": "1817600"
  },
  {
    "text": "yeah let's do it so we often talk about our contribution priorities and this sort of draws back",
    "start": "1817600",
    "end": "1824080"
  },
  {
    "text": "to a few of the things i said about road map uh we try to prioritize stability first uh we want to ensure that text",
    "start": "1824080",
    "end": "1829840"
  },
  {
    "text": "tests are fixed we want to ensure that bugs are fixed and open triage issues are fixed and we want to do that before",
    "start": "1829840",
    "end": "1836320"
  },
  {
    "text": "we start working on new features because otherwise we might get overwhelmed in the number of",
    "start": "1836320",
    "end": "1842240"
  },
  {
    "text": "bugs and test breakage that we're working on we really it's important to us to ensure",
    "start": "1842240",
    "end": "1847919"
  },
  {
    "text": "that our test infrastructure monitoring and health is good and you know our tests are green we have good signal to",
    "start": "1847919",
    "end": "1853840"
  },
  {
    "text": "work with so this is sort of how we prioritize uh contributions and uh if you really want",
    "start": "1853840",
    "end": "1861279"
  },
  {
    "text": "uh your new contributions to get looked at you are more likely to get a positive",
    "start": "1861279",
    "end": "1866720"
  },
  {
    "text": "response uh if you are fixing something that's broken uh initially versus like i",
    "start": "1866720",
    "end": "1871760"
  },
  {
    "text": "have this great new feature because we're sure that your feature is great but we have so many great features that",
    "start": "1871760",
    "end": "1877039"
  },
  {
    "text": "uh it might not be the best place to start because there might be something broken blocking that uh and so uh",
    "start": "1877039",
    "end": "1884320"
  },
  {
    "text": "optimizations are also great uh to include uh that improve the performance",
    "start": "1884320",
    "end": "1889679"
  },
  {
    "text": "of existing components other areas that you might be interested in contributing and i often try to call",
    "start": "1889679",
    "end": "1896320"
  },
  {
    "text": "this out especially to folks who might be using the cubelet have opinions on",
    "start": "1896320",
    "end": "1902000"
  },
  {
    "text": "sig node but aren't necessarily going to write code you can still contribute you can still",
    "start": "1902000",
    "end": "1907120"
  },
  {
    "text": "help us out either by doing performance testing or writing documentation",
    "start": "1907120",
    "end": "1913279"
  },
  {
    "text": "or giving us feedback on blogging and metrics and how we can improve that or just helping us triage and keep on top",
    "start": "1913279",
    "end": "1919679"
  },
  {
    "text": "of pr's and issues you don't have to write code in order to contribute to the sig",
    "start": "1919679",
    "end": "1924799"
  },
  {
    "text": "so we welcome all four forms of contribution so how do you contribute well first it",
    "start": "1924799",
    "end": "1932480"
  },
  {
    "text": "helps to join our sig meetings so you get an idea of what we're currently working on uh at the main meetings of",
    "start": "1932480",
    "end": "1938960"
  },
  {
    "text": "the sig we talk about uh major features that are being worked on uh enhancements",
    "start": "1938960",
    "end": "1944240"
  },
  {
    "text": "and what's going into a given release and milestone high priority bugs and more um if that",
    "start": "1944240",
    "end": "1950159"
  },
  {
    "text": "seems kind of intimidating to join when there are 40 plus people in a meeting you could try coming to our ci and",
    "start": "1950159",
    "end": "1957120"
  },
  {
    "text": "triage sessions where we have a smaller more hands-on group and we work directly",
    "start": "1957120",
    "end": "1963039"
  },
  {
    "text": "on specific bug specific issues that kind of thing as i said previously you can also",
    "start": "1963039",
    "end": "1969600"
  },
  {
    "text": "participate in code reviews issues documentation this",
    "start": "1969600",
    "end": "1974640"
  },
  {
    "text": "is all awesome a big shout out to all of the folks who have been helping out with the docker shim removal documentation",
    "start": "1974640",
    "end": "1980640"
  },
  {
    "text": "this release that was an enormous effort and a great help to sig node",
    "start": "1980640",
    "end": "1986960"
  },
  {
    "text": "and it's also really great if you adopt features turn on alpha feature gates and let us know how they work",
    "start": "1986960",
    "end": "1994799"
  },
  {
    "text": "so where can you find us uh this slide links to our regular meeting which is currently scheduled on tuesdays at 10",
    "start": "1995279",
    "end": "2001760"
  },
  {
    "text": "a.m pacific time our ci triage meeting is every week on wednesday at the same time 10 a.m",
    "start": "2001760",
    "end": "2007760"
  },
  {
    "text": "pacific we have a slack channel pound sig node on the kubernetes slack",
    "start": "2007760",
    "end": "2013440"
  },
  {
    "text": "we also have a mailing list the kubernetes sig node mailing list on google groups and our current chairs are",
    "start": "2013440",
    "end": "2019519"
  },
  {
    "text": "don and derek thanks so much for attending this talk",
    "start": "2019519",
    "end": "2027000"
  }
]